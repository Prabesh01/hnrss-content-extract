<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-29T21:37:18.964789+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46419273</id><title>Feynman's Hughes Lectures: 950 pages of notes</title><updated>2025-12-29T21:37:24.483444+00:00</updated><content>&lt;doc fingerprint="3bd95129a833172b"&gt;
  &lt;main&gt;
    &lt;p&gt;These lectures notes run from the fall of 1966 to 1971. Feynman lectured prior to this period and continued on after 1971. With a few exceptions, the actual 2 hours lectures were not dated. However, the volumes in chronological order.&lt;/p&gt;
    &lt;p&gt;I want to stress, again, that these are my personal notes and are only a representation of the lectures I attended. They are to the best of my ability my recreation from memory and my original real time notes. No AV recording system was used in the transcription of my raw notes.&lt;/p&gt;
    &lt;p&gt;Volume 1&lt;lb/&gt; Astronomy, Astrophysics, and Cosmology&lt;lb/&gt; (224 pages)&lt;/p&gt;
    &lt;p&gt;Feynman solicited topic input from the scientists and engineers at the Labs for the coming year. New discoveries were being made in astronomy, astrophysics, and cosmology at the time. This 1966-1967 lecture series focused on these subjects. This volume is unique since, as far as I can tell, Feynman did not lecture on this subject matter at CalTech. While much of the material is now dated, what remains is a look into the mind of Feynman as he worked to explain such topics as stellar evolution, nuclear synthesis, cosmology, “black stars” (aka black holes), and general relativity.&lt;/p&gt;
    &lt;p&gt;I inserted more current content from the web which relates to the 1966-67 lectures with recent experimental observations and discoveries. While this lecture series has been “eclipsed” by the tremendous theoretical and experimental advancements over the past 45 years, I am sure the reader(s) will find in these lectures the power of Feynman’s insight and ability to have fun with a new subject not touched on by him at CalTech in his “normal” class and research work. I trust others, more specialized in the topics of volume 1, can and will contribute to the additional information to further enrich the notes in the future. This editing will best be done when the notes are moved and dropped in a dynamic and editable platform, yet to be identified.&lt;/p&gt;
    &lt;p&gt;The Volume I subject matter was not part of his prior lecture activity, Feynman would talk with some of his CalTech colleagues who worked in the field of astronomy, astrophysics, and cosmology about their work and theories. He would then come to the lecture literally with a (maybe 2 or 3) 3×5 cards and proceed to pour out 2 hours of theory and complex mathematical representations of the topic of the day. This was his genius and almost mystical in his ability to focus his thinking and presentation ability on the most important aspects of a given topic.&lt;/p&gt;
    &lt;p&gt;Volumes 2&lt;lb/&gt; Relativity, Electrostatics, Electrodynamics, Matter-Wave Interaction&lt;lb/&gt; (209 pages)&lt;/p&gt;
    &lt;p&gt;Feynman reflected on how he could teach his original FLP’s volume 2 &amp;amp; 3 differently and better than in his first pass through the subjects five years earlier. The attendees wanted him to lecture a couple years on the subject matter in the original FLP and essentially let him give his revised, enhanced, and expanded lectures. This then led more naturally into QED with a good foundation layer established. Feynman also tailored his lectures more to the level of his audience understanding they were not freshman and sophomore undergraduates but post graduate, doctorate level scientists, employed doing advanced research.&lt;/p&gt;
    &lt;p&gt;Volume 3&lt;lb/&gt; More on Matter-Wave Interaction, Intro to Quantum Mechanics, Scattering Theory, Quantum Theory of Angular Momentum, Intro to Lie Group, SU 2 &amp;amp; 3 “stuff”, Quantum Electrodynamics (QED), Pair Production&lt;lb/&gt; (314 pages)&lt;/p&gt;
    &lt;p&gt;Feynman went on in greater detail to complete his lectures on wave-matter interaction. From there he started into quantum mechanics and his path history formulation. He extended his lectures to include Lie Group theory and the SU 2&amp;amp;3 “Stuff”.&lt;/p&gt;
    &lt;p&gt;Feynman diagrams are discussed in Volume 3 at some length as he went deep into QED theory including such topics as quantum scattering. As better understood today, his diagrams represent a visual language of the complex physical processes at the particle interaction level. I have noted recently that with the power of new computers and new concepts the Feynman diagrams have, arguably, run their course. While this is possibly the case, I would assert that bypassing a fundamental understanding of the Feynman diagram concept makes it hard to understand what replaces them. This is like hand held calculators replacing the need to know the fundamental multiplication tables and being able to check what the calculator is telling you. I personally observed in a number of lectures where Feynman would self-check himself as he was working out the math because he could sense that if he kept going he would not get the right physics. This was his true genius at work. That was truly amazing to both watch and try to absorb in real time.&lt;/p&gt;
    &lt;p&gt;Volume 4&lt;lb/&gt; Molecular Biology&lt;lb/&gt; (65 pages)&lt;/p&gt;
    &lt;p&gt;The Molecular Biology lectures started out and then eventually died out as the year progressed. Feynman found the material challenging to get his head around before the lecture and, therefore, very time consuming. He apparently found a CalTech colleague, Seymour Benzer, who changed from physics to biophysics as a person who stimulated Feynman’s interest in this topic.&lt;/p&gt;
    &lt;p&gt;By consensus the lecture series ended early. Feynman was deep into his own parton theory which was his version of quark theory. He and Gell-Mann were collegial competitors in those days.&lt;/p&gt;
    &lt;p&gt;In preparing these notes for release I decided to include what notes I had of those lectures only to give evidence of Feynman’s interest to explore all the dimensions of science and nature. For those involved in the field these notes will not provide much informational value particularly with all the advancements on research and understanding of molecular biology. The value, I believe, for the reader is how Feynman thought through the subject matter and mentally organized it so he could lecture on it. That might aid teachers in this field to sharpen up their own presentation material. At the end of the volume are my un-transcribed real-time notes that I never got to but I decided to include for those who are into this field.&lt;/p&gt;
    &lt;p&gt;Volume 5&lt;lb/&gt; Mathematical Methods/Techniques in Physics and Engineering&lt;lb/&gt; (163 pages)&lt;/p&gt;
    &lt;p&gt;By some who have seen samples of my notes Volume 5 has been referred to as the “missing lectures” to the FLP “Red Books”. Feynman himself felt that he should have taught the mathematical methods first and then the physics since math is the “language” of physics. Feynman was apparently talked out of starting with a course in math-physics. The attendees at the lab talked him into a year-long lecture on his approach to mathematics as the language of physics.&lt;/p&gt;
    &lt;p&gt;I note here also that the math lectures have been referred on the Reddit by someone as “sophomoric” since all physic students must take similar course work and presumably “master” math while learning the physics. In my own case I wanted to learn the physics and minimize the math, or better said, not confused by the physics because the math was too difficult to grasp.&lt;/p&gt;
    &lt;p&gt;This is how Feynman approached physics and how he taught himself, at an early age, by developing many shortcuts through the math; “Feynman diagrams” were one clear by product of his self learning process. He did not want to get bogged down and distracted from understanding the physics. This is why and how he got involved in the Manhattan Project; he was their math wizard.&lt;/p&gt;
    &lt;p&gt;One story he told of those days: Someone came running into him needing a quick answer to a nuclear decay process that was described by some expansion series like the Sum from 1 to infinity of 1/(1+n^2)[probably not the real one]. Feynman asked how accurately he wanted the answer and the person said 10% would do for now. Feynman said he took a few seconds and said the answer was 1.3 (or something like that); the person was amazed how fast he could give him that and asked how he did it. He said since you told me you only wanted the answer to 10%, it was only necessary to go to the second term in the series expansion and that was good enough for better than 10% accuracy. This story is emblematic of Feynman’s mathematical thinking which is not sophomoric. This is why he made such a contribution to the Manhattan project and ultimately QED. He did indeed “think different”.&lt;/p&gt;
    &lt;p&gt;In my own experience I found in my graduate studies that the some of the professors tended to focus more on the math rigor than in teaching the real physics. In Feynman’s world he “felt” the physics and used the math to express that “feeling” and understanding. Language does not necessarily express the essence of the content contained in the idea being described. One must understand both the power and limitations of the language used when discussing a subject. Words don’t always express what one wants to say; so it is for math and physics.&lt;/p&gt;
    &lt;p&gt;Lecture Sidebars: Another “feature”, or aspect, of the notes is my attempt to capture “side bar” topics. These special topics or thoughts (including some philosophical ones) added color and currency to the lectures as only Feynman could deliver. He was unconstrained in the lecture environment to take off on a sidebar and the attendees both enjoyed and encouraged him to do so.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thehugheslectures.info/the-lectures/"/><published>2025-12-29T10:43:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46419822</id><title>Show HN: See what readers who loved your favorite book/author also loved to read</title><updated>2025-12-29T21:37:24.340523+00:00</updated><content/><link href="https://shepherd.com/bboy/2025"/><published>2025-12-29T11:58:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46419968</id><title>Linux DAW: Help Linux musicians to quickly and easily find the tools they need</title><updated>2025-12-29T21:37:23.664464+00:00</updated><link href="https://linuxdaw.org/"/><published>2025-12-29T12:23:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46419970</id><title>Kidnapped by Deutsche Bahn</title><updated>2025-12-29T21:37:23.502382+00:00</updated><content>&lt;doc fingerprint="5b8d1d547b2d05f1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I Was Kidnapped by Deutsche Bahn and All I Got Was 1.50 EUR&lt;/head&gt;
    &lt;p&gt;If you live in Germany, you have been treated like livestock by Deutsche Bahn (DB). Almost all of my friends have a story: they traveled with DB, got thrown out in the middle of the night in some cow village, and had to wait hours for the next train.&lt;/p&gt;
    &lt;p&gt;I have something better. I was kidnapped.&lt;/p&gt;
    &lt;p&gt;December 24th, 2025. 15:30. Cologne Main Station, Platform 9 D-G.&lt;/p&gt;
    &lt;p&gt;I am taking the RE5 (ID 28521) to my grandmother’s house in Meckenheim. Scheduled departure: 15:32. Scheduled arrival in Bonn: 15:54. From there, the S23 to Meckenheim. A journey of 35 kilometers, or, in DB units, somewhere between forty-five minutes and the heat death of the universe.&lt;/p&gt;
    &lt;p&gt;I wanted to arrive early to spend more time with her. My father, who lives near Troisdorf, was supposed to join us later.&lt;/p&gt;
    &lt;p&gt;I board the train. It is twenty minutes late. I consider this early. At least the train showed up. In DB’s official statistics, a train counts as “on time” if it’s less than six minutes late.1 Cancelled trains are not counted at all.2 If a train doesn’t exist, it cannot be late.&lt;/p&gt;
    &lt;p&gt;The train starts moving. The driver announces there are “issues around Bonn.” He does not specify what kind. No one asks. We have learned not to ask. He suggests we exit at Cologne South and take the subway, or continue to Troisdorf and catch a bus from there.&lt;/p&gt;
    &lt;p&gt;I decide to continue to Troisdorf. My father can just pick me up there and we drive together. The plan adapts.&lt;/p&gt;
    &lt;p&gt;The driver announces the full detour: from Cologne South to Troisdorf to Neuwied to Koblenz. The entire left bank of the Rhine is unavailable. Only then I notice: the driver has been speaking German only. If you were a tourist who got on in Cologne to visit Brühl, thirteen minutes away, you were about to have a very confusing Christmas in Troisdorf.&lt;/p&gt;
    &lt;p&gt;A woman near me is holding chocolates and flowers. She is on the phone with her mother. “Sorry Mama, I’ll be late.” Pause. “Deutsche Bahn.” Pause. Her mother understood.&lt;/p&gt;
    &lt;p&gt;Twenty minutes later. We are approaching Troisdorf. I stand up. I gather my things. My father texts me: he is at the station, waiting.&lt;/p&gt;
    &lt;p&gt;The driver comes back on: “Hello everyone. Apparently we were not registered at Troisdorf station, so we are on the wrong tracks. We cannot stop.”&lt;/p&gt;
    &lt;p&gt;He says this the way someone might say “the coffee machine is broken.”&lt;/p&gt;
    &lt;p&gt;Silence. Laughter. Silence.&lt;/p&gt;
    &lt;p&gt;I watch Troisdorf slide past the window. Somewhere in the parking lot outside the station, my father is sitting in his car, watching his son pass by as livestock.&lt;/p&gt;
    &lt;p&gt;My father calls.&lt;/p&gt;
    &lt;p&gt;“The train couldn’t stop.”&lt;/p&gt;
    &lt;p&gt;“What?”&lt;/p&gt;
    &lt;p&gt;“Next stop is Neuwied.”&lt;/p&gt;
    &lt;p&gt;“Neuwied?” Pause. “That’s in Rheinland-Pfalz.” Pause. “That’s a different federal state.”&lt;/p&gt;
    &lt;p&gt;“Yup.”&lt;/p&gt;
    &lt;p&gt;I was trying to travel 35 kilometers. I was now 63 kilometers from my grandmother’s house. Further away than when I started.&lt;/p&gt;
    &lt;p&gt;There are fifteen stations between Troisdorf and Neuwied. We pass all of them [^6].&lt;/p&gt;
    &lt;p&gt;At some point you stop being a passenger and start being cargo. A cow transporter. Mooohhhhh. A cow transporter going to a cow village. (Germany has a word for this: Kuhdorf. The cows are metaphorical. Usually.) I reached this point around Oberkassel.&lt;/p&gt;
    &lt;p&gt;DB once operated a bus to Llucalcari, a Mallorcan village of seventeen people.3 I wanted to take it home.&lt;/p&gt;
    &lt;p&gt;An English speaker near the doors is getting agitated. “What is happening? Why didn’t we stop?”&lt;/p&gt;
    &lt;p&gt;“We are not registered for this track.”&lt;/p&gt;
    &lt;p&gt;“But where will we stop?”&lt;/p&gt;
    &lt;p&gt;“Neuwied. Fifty-five minutes.”&lt;/p&gt;
    &lt;p&gt;“Fifty-five minutes.” He said it again, quieter. “I am being kidnapped.”&lt;/p&gt;
    &lt;p&gt;My seatmate, who had not looked up from his book in forty minutes, turned a page. “Deutsche Bahn.”&lt;/p&gt;
    &lt;p&gt;I looked up my compensation.4 1.50 EUR. Minimum payout threshold: 4.00 EUR.&lt;/p&gt;
    &lt;p&gt;I had been kidnapped at a loss.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Deutsche Bahn Annual Report 2022: Punctuality - “A stop is considered on time if the scheduled arrival time is exceeded by less than six minutes.” ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bundesrechnungshof Report 2022 - “Komplett ausgefallene Züge werden bei der Pünktlichkeit nicht berücksichtigt.” (Completely cancelled trains are not considered in the punctuality metric.) ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Llucalcari, Mallorca - Mallorca’s smallest village, population 17. Bus route 203 was operated by Autocares Mallorca, an Arriva company and Deutsche Bahn subsidiary, until 2021. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deutsche Bahn: Deutschlandticket Verspätung Erstattung - Official compensation policy for Deutschlandticket delays. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/"/><published>2025-12-29T12:24:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46420453</id><title>Show HN: Vibe coding a bookshelf with Claude Code</title><updated>2025-12-29T21:37:23.372033+00:00</updated><content>&lt;doc fingerprint="6f3d1a956f2fcbfa"&gt;
  &lt;main&gt;
    &lt;p&gt;I own more books than I can read. Not in a charming, aspirational way, but in the practical sense that at some point I stopped knowing what I owned. Somewhere around 500 books, memory stopped being a reliable catalog.&lt;/p&gt;
    &lt;p&gt;For years, I told myself I would fix this. Nothing elaborate, nothing worthy of a startup idea. A spreadsheet would have been enough. I never did it, not because it was hard, but because it was tedious.&lt;/p&gt;
    &lt;p&gt;The gap between intention and execution was small, but it was enough to keep the project permanently parked in the someday pile.&lt;/p&gt;
    &lt;p&gt;By the end of 2025, I had been working with AI agents long enough that this kind of project finally felt possible. Not because they made things more impressive, but because they removed the part I always stalled on. Execution.&lt;/p&gt;
    &lt;p&gt;The bookshelf project is where I clearly understood what my role becomes once execution stops being the bottleneck.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem&lt;/head&gt;
    &lt;p&gt;I tried the obvious tools first. ISBN scanner apps failed on Romanian editions, and Goodreads could not identify obscure publishers or antiquarian finds. Anything even slightly nonstandard came back incomplete or wrong. Partial data felt worse than no data at all, so every attempt ended the same way: a few entries filled in, followed by abandonment.&lt;/p&gt;
    &lt;p&gt;What I needed was not a better app, but a way to tolerate imperfection without the whole system falling apart.&lt;/p&gt;
    &lt;head rend="h2"&gt;The data&lt;/head&gt;
    &lt;p&gt;Every project starts with bad data, and this one started with worse data. One afternoon, I photographed every book I own: spines, covers, duplicates, and the occasional blurry thumb. Four hundred and seventy photos in total. Once the images were on my laptop, I opened Claude.&lt;/p&gt;
    &lt;p&gt;The first steps were mechanical. Renaming files. Converting &lt;code&gt;HEIC&lt;/code&gt; to &lt;code&gt;JPG&lt;/code&gt;. Then
I asked for something real: a script that sends each image to OpenAI's vision
API, extracts author, title, and publisher, normalizes names, resizes images
to avoid wasting tokens, and writes everything to a &lt;code&gt;JSON&lt;/code&gt; file.&lt;/p&gt;
    &lt;p&gt;Claude wrote the script and ran it. It worked. Not perfectly, but well enough to matter.&lt;/p&gt;
    &lt;code&gt;{
  "id": "ZfEPBCMZDaCKm6k0NVJ8F",
  "title": "Simulacre și simulare",
  "author": "Jean Baudrillard",
  "publisher": "Colectia Panopticon",
  "source": "dataset/83.jpg",
},
&lt;/code&gt;
    &lt;p&gt;Roughly 90 percent of the books came back correct. The failures were predictable: poor lighting, damaged covers, unreadable spines. One novel was confidently identified as a 1987 Soviet agricultural manual.&lt;/p&gt;
    &lt;p&gt;I fixed the rest by hand. That decision was not technical, it was judgment. Ninety percent accuracy was enough. Chasing the remaining ten percent would have meant days of edge cases for very little additional value. That was the first moment where my role became clear.&lt;/p&gt;
    &lt;p&gt;Later, when I received a few books for Christmas, we added a second script that runs the same pipeline for new additions. Photo in, metadata and images out.&lt;/p&gt;
    &lt;head rend="h2"&gt;The covers&lt;/head&gt;
    &lt;p&gt;With metadata sorted, covers were still missing. My photos showed spines, not artwork, and I wanted a clean visual representation. Claude suggested using Open Library's API to fetch covers, which mostly worked. Half the covers were low quality or incorrect, and Romanian editions barely existed in the database.&lt;/p&gt;
    &lt;p&gt;We iterated. Claude wrote a second pass, another model call that scored cover quality and flagged bad matches. For flagged books, it fell back to Google Images via SerpAPI. That handled most cases. A few remained: antiquarian finds and obscure Soviet boxing manuals that no database was ever going to have clean assets for.&lt;/p&gt;
    &lt;p&gt;I opened Photoshop and fixed ten covers by hand. For a collection of 460 books, ten manual edits felt like a win.&lt;/p&gt;
    &lt;head rend="h2"&gt;The shelf&lt;/head&gt;
    &lt;p&gt;Once the data and covers were in place, the UI came next. The obvious solution was a grid of covers. It was correct, and it was lifeless. I kept looking at my physical bookshelf instead. What makes it interesting is not the covers, but the spines. Different widths, uneven pressure, colors blending into a single texture.&lt;/p&gt;
    &lt;p&gt;That was the thing I wanted to recreate.&lt;/p&gt;
    &lt;p&gt;Claude did not invent that idea. It executed it. It wrote a script to extract dominant colors from each cover using color quantization, then computed contrasting text colors for readability. The result was better, but still wrong. Every book had the same width, and real books are not like that.&lt;/p&gt;
    &lt;p&gt;Open Library had page counts. We mapped page count to spine width and added slight variation to break the uniformity. At that point, it finally looked like a bookshelf.&lt;/p&gt;
    &lt;code&gt;{
  "id": "ZfEPBCMZDaCKm6k0NVJ8F",
  "title": "Simulacre si simulare",
  "author": "Jean Baudrillard",
  "backgroundColor": "#f0f0ff",
  "color": "#1f1f2e",
  "paddingLeft": 13,
  "paddingRight": 13,
  "height": 384,
  "cover": "/images/bookshelf/simulacre-si-simulare@2x.webp",
  "source": "dataset/83.jpg"
},
&lt;/code&gt;
    &lt;head rend="h2"&gt;The animation&lt;/head&gt;
    &lt;p&gt;Visually, the shelf worked, but it felt static. A real shelf responds to touch. When you run your finger along the spines, they tilt slightly. I asked Claude for an animation, and it came back with a scroll based tilt using Framer Motion.&lt;/p&gt;
    &lt;p&gt;It was close, but wrong. The movement snapped instead of flowing. I did not know why, I just knew it felt off. That was enough.&lt;/p&gt;
    &lt;p&gt;Claude explained the issue immediately. We were updating React state on every scroll event, causing unnecessary re renders. The fix was to use motion values and springs that animate outside React's render cycle. Two minutes later, it was fixed. I spent the next few minutes scrolling back and forth, just watching it move. This was the moment my caution dropped, not because the tool was always right, but because the cost of trying ideas had collapsed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Killing good code&lt;/head&gt;
    &lt;p&gt;That confidence had a downside. I started asking for things I did not need. Infinite scroll seemed sensible. Why render 460 books at once? Claude implemented it, and technically it worked. Memory stayed flat, and the DOM updated correctly.&lt;/p&gt;
    &lt;p&gt;But scrolling broke. The container height desynced, the last books were unreachable, and every attempted fix introduced new jank. The feature worked, but the experience did not. So we removed it. Not because it was broken, but because it was unnecessary. Four hundred and sixty books is not a scale problem. Knowing when to delete working code is not something an AI can decide for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;The stack view&lt;/head&gt;
    &lt;p&gt;The shelf looked great on desktop, but on mobile, horizontal scrolling felt cramped. I wanted an alternative layout: books lying flat, stacked vertically, readable without tilting your head. I pointed Claude at the shelf implementation and asked for a stack view.&lt;/p&gt;
    &lt;p&gt;It read the code, inferred the patterns, and reused them: animation timing, color extraction, scroll based opacity, the same data shape. It built the new component and wired up a toggle between layouts. It worked without explanation. That surprised me more than anything else.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I actually did&lt;/head&gt;
    &lt;p&gt;Claude wrote all the code. So what did I do?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I decided that 90 percent accuracy was enough.&lt;/item&gt;
      &lt;item&gt;I fixed the ten covers no API could find.&lt;/item&gt;
      &lt;item&gt;I rejected a grid because I wanted spines.&lt;/item&gt;
      &lt;item&gt;I deleted infinite scroll because I did not need it.&lt;/item&gt;
      &lt;item&gt;I kept scrolling the animation until it felt right.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Claude handled implementation. I handled taste.&lt;/p&gt;
    &lt;p&gt;After years of false starts, my bookshelf finally exists. Four hundred and sixty books, cataloged and displayed at bookshelf. I almost dismissed Claude Code as hype. Now, the times when I wrote everything by hand feel distant, almost strange.&lt;/p&gt;
    &lt;p&gt;Execution keeps getting cheaper. Taste still does not.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/"/><published>2025-12-29T13:22:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46420670</id><title>Show HN: Per-instance TSP Solver with No Pre-training (1.66% gap on d1291)</title><updated>2025-12-29T21:37:23.274365+00:00</updated><content>&lt;doc fingerprint="3fcede13b13e5896"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;OP here.&lt;/p&gt;
      &lt;p&gt;Most Deep Learning approaches for TSP rely on pre-training with large-scale datasets. I wanted to see if a solver could learn "on the fly" for a specific instance without any priors from other problems.&lt;/p&gt;
      &lt;p&gt;I built a solver using PPO that learns from scratch per instance. It achieved a 1.66% gap on TSPLIB d1291 in about 5.6 hours on a single A100.&lt;/p&gt;
      &lt;p&gt;The Core Idea: My hypothesis was that while optimal solutions are mostly composed of 'minimum edges' (nearest neighbors), the actual difficulty comes from a small number of 'exception edges' outside of that local scope.&lt;/p&gt;
      &lt;p&gt;Instead of pre-training, I designed an inductive bias based on the topological/geometric structure of these exception edges. The agent receives guides on which edges are likely promising based on micro/macro structures, and PPO fills in the gaps through trial and error.&lt;/p&gt;
      &lt;p&gt;It is interesting to see RL reach this level without a dataset. I have open-sourced the code and a Colab notebook for anyone who wants to verify the results or tinker with the 'exception edge' hypothesis.&lt;/p&gt;
      &lt;p&gt;Code &amp;amp; Colab: https://github.com/jivaprime/TSP_exception-edge&lt;/p&gt;
      &lt;p&gt;Happy to answer any questions about the geometric priors or the PPO implementation!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46420670"/><published>2025-12-29T13:43:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46420672</id><title>Libgodc: Write Go Programs for Sega Dreamcast</title><updated>2025-12-29T21:37:22.784226+00:00</updated><content>&lt;doc fingerprint="3d8bf719eda53e81"&gt;
  &lt;main&gt;
    &lt;p&gt;Replaces the standard Go runtime with one designed for the Dreamcast's constraints: memory 16MB RAM, CPU single-core SH-4, no operating system. Provides garbage collection, goroutines, channels, and the core runtime functions.&lt;/p&gt;
    &lt;p&gt;Prerequisites: Go 1.25.3+, &lt;code&gt;make&lt;/code&gt;, and &lt;code&gt;git&lt;/code&gt; must be installed.&lt;/p&gt;
    &lt;code&gt;go install github.com/drpaneas/godc@latest
godc setup
godc doctor # to check (optional)&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Note: The&lt;/p&gt;&lt;code&gt;godc&lt;/code&gt;CLI tool is a separate project that handles toolchain setup and builds.&lt;/quote&gt;
    &lt;p&gt;Create and run a project:&lt;/p&gt;
    &lt;code&gt;mkdir myproject &amp;amp;&amp;amp; cd myproject
godc init
# write you main.go and other *.go files
godc build
godc run&lt;/code&gt;
    &lt;p&gt;See the Quick Start Guide for your first program.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Installation — Setup and configuration&lt;/item&gt;
      &lt;item&gt;Quick Start — First program walkthrough&lt;/item&gt;
      &lt;item&gt;Design — Runtime architecture&lt;/item&gt;
      &lt;item&gt;Effective Dreamcast Go — Best practices&lt;/item&gt;
      &lt;item&gt;KOS Wrappers — Calling C from Go&lt;/item&gt;
      &lt;item&gt;Limitations — What doesn't work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Measured on real hardware (SH-4 @ 200MHz):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Operation&lt;/cell&gt;
        &lt;cell role="head"&gt;Time&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Gosched yield&lt;/cell&gt;
        &lt;cell&gt;~120 ns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Allocation&lt;/cell&gt;
        &lt;cell&gt;~186 ns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Buffered channel&lt;/cell&gt;
        &lt;cell&gt;~1.8 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Context switch&lt;/cell&gt;
        &lt;cell&gt;~6.4 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Unbuffered channel&lt;/cell&gt;
        &lt;cell&gt;~13 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Goroutine spawn&lt;/cell&gt;
        &lt;cell&gt;~31 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GC pause&lt;/cell&gt;
        &lt;cell&gt;72 μs - 6 ms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains working programs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;hello&lt;/code&gt;— Minimal program (debug output)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hello_screen&lt;/code&gt;— Hello World on screen using BIOS font&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;blue_screen&lt;/code&gt;— Minimal graphics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;input&lt;/code&gt;— Controller input&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;goroutines&lt;/code&gt;— Concurrent bouncing balls&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;channels&lt;/code&gt;— Producer/consumer pattern&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;timer&lt;/code&gt;— Frame-rate independent animation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bfont&lt;/code&gt;— BIOS font rendering&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;filesystem&lt;/code&gt;— Directory browser&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;vmu&lt;/code&gt;— VMU LCD and buzzer&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;brkout&lt;/code&gt;— Breakout clone (GPL v2, port of Jim Ursetto's original)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pong&lt;/code&gt;— Pong clone with 1P/2P mode, particle effects, and AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;BSD 3-Clause License. See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/drpaneas/libgodc"/><published>2025-12-29T13:43:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46422009</id><title>Static Allocation with Zig</title><updated>2025-12-29T21:37:22.643403+00:00</updated><content>&lt;doc fingerprint="3e59ba5f80a316c9"&gt;
  &lt;main&gt;
    &lt;p&gt;Over the past few months I've been chipping away at a small Redis-compatible key/value server called &lt;code&gt;kv&lt;/code&gt;. The goal is to have something (mostly) production-ready, while implementing
only a small subset of commands. The world doesn't necessarily need another key/value store, I'm just interested in
implementing it in Zig and learning about some new (to me) techniques for systems programming.&lt;/p&gt;
    &lt;p&gt;One of those techniques is static memory allocation during initialization. The idea here is that all memory is requested and allocated from the OS at startup, and held until termination. I first heard about this while learning about TigerBeetle, and they reference it explicitly in their development style guide dubbed "TigerStyle".&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;All memory must be statically allocated at startup. No memory may be dynamically allocated (or freed and reallocated) after initialization. This avoids unpredictable behavior that can significantly affect performance, and avoids use-after-free. As a second-order effect, it is our experience that this also makes for more efficient, simpler designs that are more performant and easier to maintain and reason about, compared to designs that do not consider all possible memory usage patterns upfront as part of the design.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Although, this isn't as straightforward as it might sound at first. The first question that comes to mind might be: "How much memory do I allocate?" Of course, the answer depends on the system. If we're writing a server, how many concurrent connections do we allow? How much space is each connection allowed to work with? How much data do we expect to process at any given time? Are there limits in response size? Do we need all the data at once, or can it streamed in some fashion?&lt;/p&gt;
    &lt;p&gt;These are all questions that depend on the nature of the system and the context in which it will operate. I believe that going through the exercise of answering these questions is ultimately a good thing, as it seems to have a strong possibility of resulting in more stable systems, and forces us to understand the nature of our program at a deeper level.1&lt;/p&gt;
    &lt;p&gt;On the language front, I feel like Zig is currently the best option out there for doing this with relative ease, considering its design choices around explicit memory allocation and the &lt;code&gt;std.mem.Allocator&lt;/code&gt; interface, which allows
the standard library to ship with a variety of different allocators.&lt;/p&gt;
    &lt;p&gt;Let's take a look at how we can manage static allocation in &lt;code&gt;kv&lt;/code&gt;, considering three areas of request handling in
sequence: connection handling, command parsing, and key/value storage.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A lot of this is pretty new to me, and I'm still wrestling with all these concepts. (And learning Zig!) I'm sure there are better ways of handling this stuff. I'm presenting this as one possible implementation completed as a learning exercise. I'll speak more about the trade-offs and where I think it can go further at the end of this post.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Connection Handling&lt;/head&gt;
    &lt;p&gt;The first thing we have to consider is how data comes into the system, which we'll maintain through the concept of a &lt;code&gt;Connection&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;A connection represents the communication to a particular client that wants to access the key/value store. Since we're using &lt;code&gt;io_uring&lt;/code&gt; for asynchronous I/O, we have to keep some information around through the life-cycle of
a request, so the kernel can use it. The space for that information is what we'll statically allocate and re-use across
different connections as they come and go.&lt;/p&gt;
    &lt;code&gt;const Connection = struct {
	completion: Completion = undefined,
	client: posix.socket_t = undefined,
	
	recv_buffer: *ByteArray,
	send_buffer: *ByteArray,
};
&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Connections also must maintain something called a "completion". This detail is related to integration with&lt;/p&gt;&lt;code&gt;io_uring&lt;/code&gt;, the full details of which are outside the scope of this post. There are some good resources here and here. I also took some inspiration from TigerBeetle's IO module.&lt;/quote&gt;
    &lt;p&gt;During initialization, we create three pools: one for the Connection structs themselves, one for receive buffers (requests), and one for send buffers (responses). When a request comes in to the server, a Connection is pulled from a &lt;code&gt;std.heap.MemoryPool&lt;/code&gt;, and then two buffers are associated with that &lt;code&gt;Connection&lt;/code&gt;. The buffers are
implemented as &lt;code&gt;ByteArray&lt;/code&gt; structs, which are in turn allocated as part of a &lt;code&gt;ByteArrayPool&lt;/code&gt;. The &lt;code&gt;ByteArrayPool&lt;/code&gt;
is custom and uses a free list to keep track of which buffers are available
to reserve for a new connection.&lt;/p&gt;
    &lt;code&gt;const ConnectionPool = struct {
    const Pool = std.heap.MemoryPoolExtra(Connection, .{ .growable = false });

    recv_buffers: ByteArrayPool,
    send_buffers: ByteArrayPool,

    connections: Pool,

    fn init(
        config: Config,
        gpa: std.mem.Allocator,
    ) !ConnectionPool {
        const allocation = config.allocation();
        const recv_size = allocation.connection_recv_size;
        const send_size = allocation.connection_send_size;

        const pool = try Pool.initPreheated(gpa, config.connections_max);
        const recv_buffers = try ByteArrayPool.init(gpa, config.connections_max, recv_size);
        const send_buffers = try ByteArrayPool.init(gpa, config.connections_max, send_size);

        return .{
            .recv_buffers = recv_buffers,
            .send_buffers = send_buffers,
            .connections = pool,
        };
    }
	
...
};
&lt;/code&gt;
    &lt;p&gt;At runtime, connections are created and destroyed (marked as available) using these pools and no actual allocation needs to happen. If no &lt;code&gt;Connection&lt;/code&gt; is available in the pool, the request is rejected and the client will have to try again.&lt;/p&gt;
    &lt;p&gt;This does mean that the server must be configured with an upper limit on the number of connections. Each connection must also have a limit on how much data it can receive and send.&lt;/p&gt;
    &lt;p&gt;At first this might seem limiting, but in practice, it creates a more robust system. Databases in particular will enforce a limit on the number of active connections for that exact reason! For a backend, networked system like &lt;code&gt;kv&lt;/code&gt;,
I would say something like 1000 active connections is a pretty reasonable limit. For a public facing system you'd
likely want more. Of course, this should all be configurable by the user.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;Config&lt;/code&gt; struct given to the &lt;code&gt;ConnectionPool&lt;/code&gt; represents these user-configured options. Note that the &lt;code&gt;Config&lt;/code&gt;
struct has a method &lt;code&gt;.allocation()&lt;/code&gt; which is computed after the options have been set. In this case,
the &lt;code&gt;connection_recv_size&lt;/code&gt; and &lt;code&gt;connection_send_size&lt;/code&gt; depend on other options, such as &lt;code&gt;config.key_count&lt;/code&gt; and
&lt;code&gt;config.key_size_max&lt;/code&gt;. We'll revisit those later.&lt;/p&gt;
    &lt;p&gt;Now that data can get into the system, the next step is to parse out Redis commands.&lt;/p&gt;
    &lt;head rend="h2"&gt;Command Parsing&lt;/head&gt;
    &lt;p&gt;In an attempt to be compatible with Redis (at least a very small subset of it), &lt;code&gt;kv&lt;/code&gt; has to parse incoming commands
following the Redis serialization protocol ("RESP") format.&lt;/p&gt;
    &lt;p&gt;Here's an example of an incoming &lt;code&gt;GET key&lt;/code&gt; command.&lt;/p&gt;
    &lt;code&gt;*2\r\n$3\r\nGET\r\n$3\r\nkey\r\n
&lt;/code&gt;
    &lt;p&gt;I won't go into detail on how these commands are structured, the RESP document will do a much better job there. Basically, what we're looking at is "Here's an array with 2 elements. The first element has 3 characters, with the content &lt;code&gt;GET&lt;/code&gt; and the second element has 3 characters, with the contenhttps://github.com/nickmonad/kvt &lt;code&gt;key&lt;/code&gt;."&lt;/p&gt;
    &lt;p&gt;In order to parse this command, we need to look at the buffer that contains the request data, create some kind of iterator over that buffer, and split each entry on the CRLF &lt;code&gt;\r\n&lt;/code&gt; byte sequence. Here's the signature for &lt;code&gt;parse&lt;/code&gt;,
the function that does just that.&lt;/p&gt;
    &lt;code&gt;pub fn parse(config: Config, alloc: std.mem.Allocator, buf: []const u8) !Command
&lt;/code&gt;
    &lt;p&gt;The allocator is used to create some book-keeping structure as we parse through the command. We need to create a list of &lt;code&gt;[]const u8&lt;/code&gt; slices that points into the whole buffer and then is given to a command's &lt;code&gt;parse()&lt;/code&gt; function, once
we know the command. This has the benefit of being a "zero copy" approach to parsing. No request data needs to be copied,
only pointed to.&lt;/p&gt;
    &lt;p&gt;Zig's &lt;code&gt;std.heap.FixedBufferAllocator&lt;/code&gt; is perfect for this kind of operation. During initialization, we ask for buffer
space from a general purpose allocator, and pass it to the &lt;code&gt;FixedBufferAllocator&lt;/code&gt;. This allocator works as "bump" allocator,
where each internal allocation happens in a linear fashion, up to the amount of available space. The trade-off here is
that memory allocated within the fixed buffer can't be free'd directly. Instead, the entire buffer is reset after use,
which simply resets an index back to &lt;code&gt;0&lt;/code&gt;. (Just about as cheap as an operation can get!)&lt;/p&gt;
    &lt;p&gt;Since our server is single-threaded2 and processes one request at a time, we can re-use this &lt;code&gt;FixedBufferAllocator&lt;/code&gt;
across every request. After the request is processed, the response is copied to a &lt;code&gt;Writer&lt;/code&gt; object backed by the
connection's &lt;code&gt;send&lt;/code&gt; buffer and the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; is reset for the next request.&lt;/p&gt;
    &lt;p&gt;Knowing how much space to give the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; depends again on our system configuration. We need space for
the &lt;code&gt;ArrayList&lt;/code&gt; of parsed command items, and space for any copied list items that are written back as a response during
command execution. Parsing must be able to support the largest possible command (a list &lt;code&gt;PUSH&lt;/code&gt; of maximum size/length) and
copying has to support the largest possible response (again, a maximally sized list).&lt;/p&gt;
    &lt;p&gt;Copying has the extra consideration that we have to actually store the copied list items, which are duplicated when read from the key/value store. During parsing, we just need to keep slices into the request buffer. For the copied items, we need to keep a list of slices that point to the items, and the items themselves. As long as we give the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; space, we can use it for all these (sub-)allocations.&lt;/p&gt;
    &lt;code&gt;pub const Runner = struct {
    config: Config,
    fba: std.heap.FixedBufferAllocator,
    kv: *Store,

    pub fn init(config: Config, gpa: std.mem.Allocator, kv: *Store) !Runner {
        const L = config.list_length_max;
        const V = config.val_size_max;

        // ArrayList([]const u8) of largest possible command.
        // "[L/R]PUSH list item1 item2 ... itemL"
        const parse_cap = (1 + 1 + L);
        const parse_size: u64 = (parse_cap * @sizeOf([]const u8));

        // ArrayList([]const u8) pointing to duplicated values.
        const copy_size = (L * @sizeOf([]const u8));
        const copy_data = (L * V);

        const fba_size: u64 = parse_size + copy_size + copy_data;
        const buffer = try gpa.alloc(u8, fba_size);
        const fba = std.heap.FixedBufferAllocator.init(buffer);

        return .{
            .config = config,
            .fba = fba,
            .kv = kv,
        };
    }
...
};
&lt;/code&gt;
    &lt;p&gt;The underlying &lt;code&gt;Store&lt;/code&gt; will use the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; to allocate an &lt;code&gt;ArrayList&lt;/code&gt; of fixed capacity
(determined by &lt;code&gt;config.list_length_max&lt;/code&gt;) and then use the remaining space in the allocator for the copied data.&lt;/p&gt;
    &lt;p&gt;Hopefully all is clear so far! Now we can move on to the core of the system: key/value storage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key/Value Storage&lt;/head&gt;
    &lt;p&gt;Perhaps obviously, the fundamental data structure in &lt;code&gt;kv&lt;/code&gt; is a hash map, used to associate user provided keys with
user provided values.&lt;/p&gt;
    &lt;p&gt;Without looking too closely at the standard library, if you grab one of the provided hash map implementations, it will accept a &lt;code&gt;std.mem.Allocator&lt;/code&gt; and hold onto the allocator for the lifetime of the map. When a key/value pair
is added to the map, it will use that same allocator and request the appropriate amount of memory to store that data.
This won't work for our case though, since we need to control allocation prior to adding any data to the map.&lt;/p&gt;
    &lt;p&gt;Fortunately, Zig also provides an "unmanaged" version of a hash map. Generally, these unmanaged versions of data structures in the standard library mean that an allocator is not held by the structure itself. It's up to us to provide that allocator when needed. A cool trick we can play with an unmanaged map is ask it to ensure it has enough capacity up front, and then "assume" that capacity during runtime when adding data to it. The hashing and internal details are still handled by the map.&lt;/p&gt;
    &lt;code&gt;var map: std.StringHashMapUnmanaged(Value) = .empty;
try map.ensureTotalCapacity(gpa, capacity);
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;ensure&lt;/code&gt; operation can fail with &lt;code&gt;error.OutOfMemory&lt;/code&gt;, which is OK during initialization. But, assuming this succeeds,
we no longer need to pass an allocator when we store data in the map.&lt;/p&gt;
    &lt;code&gt;store.map.putAssumeCapacity(key, value);
&lt;/code&gt;
    &lt;p&gt;This could in theory fail, in which case there would an assertion failure. It's ultimately up to us to check against the map's available capacity before calling this function. But, again, no allocation is required.&lt;/p&gt;
    &lt;p&gt;Since the map itself doesn't do any allocation at runtime, we have to provide space for incoming keys and values. We'll reuse the same &lt;code&gt;ByteArrayPool&lt;/code&gt; implementation that we used for connection buffers. Basically, we have a big space
allocated for keys and values and the hash map just maintains an association of pointers from keys to values.
The key/value data isn't literally stored "in the map." The allocation that happens in &lt;code&gt;ensureTotalCapacity&lt;/code&gt; is for
the internal book-keeping structure of the map, not for the user data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Navigating the map&lt;/head&gt;
    &lt;p&gt;At the highest level, the primary challenge with storing keys and values in a statically allocated map is that we could get poor utilization of the allocated space, especially when we need to support keys pointed at lists as values.&lt;/p&gt;
    &lt;p&gt;To illustrate this, let's say our map is configured to allocate space for 5 keys and 5 values. If each key maps to one value, we get perfect utilization. At the other extreme, if one key maps to a value containing a list of 5 elements, we have to use all the allocated value space for this one key, preventing other keys from using any value space, causing the map to be "biased". The store wouldn't be able to hold any more key/value pairs, even though there is allocated memory "on the table."&lt;/p&gt;
    &lt;p&gt;Basically, the only way to mitigate this is to make sure there's enough allocated space for every key to hold a list of maximum size. This definitely inflates the amount of space we have to allocate, but the alternative is a system that doesn't support its configured properties. Every key must be able to store a list of maximum size, even if they don't during actual use.&lt;/p&gt;
    &lt;p&gt;Another issue with static allocation in the context of a map is dealing with map deletions. Our &lt;code&gt;std.StringHashMapUnmanaged&lt;/code&gt; structure uses open-addressing and linear probing to place keys in the map when hash
collisions occur. Deletions are tricky because they can break the map's ability to know if a key is actually present
in the map. To handle this, a "tombstone" technique is used to mark a space as logically (but not physically) deleted
in order to preserve accurate lookups.&lt;/p&gt;
    &lt;p&gt;There's a lot more to figure out here, but it's my understanding that a map will have to periodically rehash the keys in order to reclaim space if too many tombstones pile up. When this occurs is still a bit of mystery to me. If it occurs when the map needs to grow to accommodate more key/value pairs, we'll never actually trigger that condition in a static context. If it occurs at some other point, based on number of keys compared to capacity, perhaps that could work. Or maybe, it's up to us to call &lt;code&gt;rehash()&lt;/code&gt; whenever it appears there is no space left,
and try the operation again.&lt;/p&gt;
    &lt;p&gt;All of this considered, I think a custom map implementation is more appropriate for the context of static allocation. This current implementation proves the concept, but definitely leaves room for improvement!&lt;/p&gt;
    &lt;head rend="h2"&gt;Revisiting allocation size&lt;/head&gt;
    &lt;p&gt;Now that we have a method for statically allocating space for these three components (connections, parsing, and storage), we can finally answer the first question: How much space do we allocate?&lt;/p&gt;
    &lt;p&gt;In this current iteration of &lt;code&gt;kv&lt;/code&gt;, the answer can really only be determined after the fact, once configuration has
been set and all the allocations have been made. There are five options that can be configured by the user,
and two derived properties based on those options.&lt;/p&gt;
    &lt;code&gt;pub const Config = struct {
    /// Allocation is a calculated set of values (in bytes), based on the given configuration.
    /// This informs static allocation requested at initialization.
    pub const Allocation = struct {
        connection_recv_size: u64,
        connection_send_size: u64,
    };

    /// Maximum number of concurrent connections.
    connections_max: u32,

    /// Key count is the number of possible keys we can store.
    /// Internally, the store will allocate (key_count * list_length_max) number
    /// of values, such that each key could support the maximum number of list elements.
    key_count: u32,

    /// The maximum allowable key size in bytes.
    key_size_max: u32,
    /// The maximum allowable value size in bytes.
    val_size_max: u32,

    /// The maximum allowable length for a list as a value.
    list_length_max: u32,

    pub fn allocation(config: Config) Allocation {
		// ... calculate recv and send size ....
		
        return .{
            .connection_recv_size = connection_recv_size,
            .connection_send_size = connection_send_size,
        };
    }
};
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;connection_recv_size&lt;/code&gt; and &lt;code&gt;connection_send_size&lt;/code&gt; properties of &lt;code&gt;Allocation&lt;/code&gt; depend on some details of the
RESP protocol, but is mostly informed by our user configuration. In the interest of wrapping this post up,
I'll gloss over those details, and encourage you to check out &lt;code&gt;src/config.zig&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This &lt;code&gt;Config&lt;/code&gt; struct doesn't directly specify every aspect of allocation, but it does provide the basis for it.
Something not listed in the &lt;code&gt;Config&lt;/code&gt; struct directly is the "list item pool", part of the key/value &lt;code&gt;Store&lt;/code&gt; struct.
When keys point to lists as values, there is a linked list backing that value in the hash map, and we need a pool of
structs to assist in the construction and iteration of that linked list.&lt;/p&gt;
    &lt;p&gt;With some reasonable configuration options set, let's see just how much memory we allocate!&lt;/p&gt;
    &lt;code&gt;$ zig build run
config
  connections_max = 1000
  key_count       = 1000
  key_size_max    = 1024
  val_size_max    = 4096
  list_length_max = 50
allocation
  connection_recv_size = 206299
  connection_send_size = 205255
map capacity = 2048, map size = 0, available = 1638
total_requested_bytes = 748213015
ready!
&lt;/code&gt;
    &lt;p&gt;Everything here is measured in bytes, so we're looking at approximately &lt;code&gt;750 MB&lt;/code&gt; of memory for the given configuration.
&lt;code&gt;total_requested_bytes&lt;/code&gt; is a feature of Zig's &lt;code&gt;std.heap.DebugAllocator&lt;/code&gt;. The exact number of bytes will be different
on each run, although it will hover around that value. I think the reason for this is how Zig requests pages of
memory from the OS. It won't always be the same and the OS is very likely doing some fancy book-keeping of its own.&lt;/p&gt;
    &lt;p&gt;If you play around with the configuration options and see how &lt;code&gt;total_requested_bytes&lt;/code&gt; changes, it might be
surprising just how much memory is allocated up-front, before any of it is actually used! For example, if we
double &lt;code&gt;val_size_max&lt;/code&gt; to &lt;code&gt;8192&lt;/code&gt; and &lt;code&gt;list_length_max&lt;/code&gt; to &lt;code&gt;100&lt;/code&gt;, we're looking at about &lt;code&gt;2.8 GB&lt;/code&gt; of allocated memory.&lt;/p&gt;
    &lt;p&gt;In the context of modern servers, this isn't a lot, but it can quickly grow as we adjust these parameters. Should we be asking ourselves: Is this inefficient? What if we don't use all that memory?&lt;/p&gt;
    &lt;p&gt;Like all good engineering decisions, we have to consider them in the context of the problem we're trying to solve, and the guarantees we expect from our systems. With this design, ensuring that each request and each key/value pair can utilize the maximum configured space, seems like a worthy trade-off to make.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;Like most projects, this one took a lot longer than I expected! Trying to incorporate both &lt;code&gt;io_uring&lt;/code&gt; and
static allocation was something I had never done before, but I'm pretty happy with the result.&lt;/p&gt;
    &lt;p&gt;I'm looking forward to improving the internal hash map to better fit a static context, consider alternative allocator implementations to improve memory utilization, and incorporate fuzz testing to find the limits of the system.&lt;/p&gt;
    &lt;p&gt;Checkout the code on GitHub!&lt;/p&gt;
    &lt;head rend="h3"&gt;Notes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;At the risk of stating the obvious, these limits can (and likely should) be configured at runtime by the user. These aren't values that have to be set at compile time and enforced upon all users in every context, although some might be. Again, it depends on which part of the system is using the memory. The point is that once the program starts it will allocate memory, but after that, it does not. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Going with a single-threaded design simplifies a lot! Even though processing in&lt;/p&gt;&lt;code&gt;kv&lt;/code&gt;is single-threaded, it still enjoys the benefits of I/O concurrency via&lt;code&gt;io_uring&lt;/code&gt;. The kernel handles writing responses back out to clients and waiting for that operation to complete, so we don't have to worry (as much) about slow clients. ↩&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nickmonad.blog/2025/static-allocation-with-zig-kv/"/><published>2025-12-29T16:07:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46422412</id><title>GOG is getting acquired by its original co-founder</title><updated>2025-12-29T21:37:22.543203+00:00</updated><content>&lt;doc fingerprint="3a2c3075866c2c55"&gt;
  &lt;main&gt;
    &lt;p&gt;Hey everyone, GOG Team here.&lt;/p&gt;
    &lt;p&gt;Today, Michał Kiciński, one of the co-founders of CD PROJEKT, and the co-founder of GOG, has acquired GOG from CD PROJEKT.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why GOG and Michal Kicinski are getting together&lt;/head&gt;
    &lt;p&gt;We believe the games that shaped us deserve to stay alive: easy to find, buy, download, and play forever. But time is annoyingly good at erasing them. Rights get tangled, compatibility breaks, builds disappear, and a nostalgic evening often turns into a troubleshooting session. That’s the difference between “I’m playing today” (the game lives on) and “I’ll play someday” (the game dies).&lt;/p&gt;
    &lt;p&gt;As Michał put it: “GOG stands for freedom, independence, and genuine control.”&lt;/p&gt;
    &lt;p&gt;GOG has always been built on strong values and clear principles. When Marcin Iwiński and Michał Kiciński first came up with the idea for GOG in 2007, the vision was simple: bring classic games back to players, and make sure that once you buy a game, it truly belongs to you, forever. In a market increasingly defined by mandatory clients and closed ecosystems, that philosophy feels more relevant than ever.&lt;/p&gt;
    &lt;p&gt;This new chapter is about doubling down on that vision. We want to do more to preserve the classics of the past, celebrate standout games of today, and help shape the classics of tomorrow, including new games with real retro spirit.&lt;/p&gt;
    &lt;head rend="h1"&gt;What it means for you&lt;/head&gt;
    &lt;p&gt;First of all, DRM-free is more central to GOG than ever. Your library stays yours to enjoy: same access, same offline installers, same sense of ownership. Your data stays with GOG, and GOG GALAXY remains optional.&lt;/p&gt;
    &lt;p&gt;We’ll keep our relationship with CD PROJEKT. CD PROJEKT RED games will continue to be available on GOG, and upcoming titles from the studio will also be released on the platform.&lt;/p&gt;
    &lt;p&gt;If you’re a GOG Patron, or you donate to support the Preservation Program, those funds stay within GOG. Your support has been huge this year, and we think that with your help, we can undertake even more ambitious rescue missions in 2026 and 2027. We’ll have more to say about that sometime in 2026.&lt;/p&gt;
    &lt;p&gt;GOG will remain independent in its operations. We will continue building a platform that’s ethical, non-predatory, and made to last, while helping indie developers reach the world. We’re also committed to giving the community a stronger voice, with new initiatives planned for 2026.&lt;/p&gt;
    &lt;p&gt;Thanks for being the reason this all matters.&lt;/p&gt;
    &lt;p&gt;A lot of companies sell games. Fewer do the unglamorous work of making sure the games that shaped people’s lives don’t quietly rot into incompatibility.&lt;/p&gt;
    &lt;p&gt;Thanks for caring about this mission with us. We’ll keep you posted as we ship, and in the meantime, you can dig into the full FAQ for the detailed answers.&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h3"&gt;What is happening?&lt;/head&gt;
    &lt;p&gt;Michał Kiciński, the original co-founder of GOG and co-founder of CD PROJEKT, has acquired GOG from CD PROJEKT. GOG will continue operating as GOG, a distinct company, with the same mission to Make Games Live Forever.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is GOG’s position in this?&lt;/head&gt;
    &lt;p&gt;To us at GOG, this feels like the best way to accelerate what is unique about GOG. Michał Kiciński is one of the people who created GOG around a simple idea: bring classic games back, and make sure that once you purchase a game, you have control over it forever. With him acquiring GOG, we keep long-term backing that is aligned with our values: freedom, independence, control, and making games stay playable over time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is Michał Kiciński doing this?&lt;/head&gt;
    &lt;p&gt;Because he wants to preserve and grow the original philosophy behind GOG. In a PC market that keeps moving toward mandatory clients and closed ecosystems, he believes GOG’s approach is more relevant than ever: no lock-in, no forced platforms, sense of ownership. His goal is to keep supporting both gamers and developers, and strengthen GOG’s mission: preserve the classics of the past, celebrate standout games of today, and help shape the classics of tomorrow.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is CD PROJEKT doing this?&lt;/head&gt;
    &lt;p&gt;Selling GOG fits CD PROJEKT’s long-term strategy. CD PROJEKT wants to focus its full attention on creating top-quality RPGs and providing our fans with other forms of entertainment based on our brands. This deal lets CD PROJEKT keep that focus, while GOG gets stronger backing to pursue its own mission.&lt;/p&gt;
    &lt;head rend="h3"&gt;Does the mission of GOG change?&lt;/head&gt;
    &lt;p&gt;No. Our mission remains to Make Games Live Forever.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is DRM-free still central to GOG?&lt;/head&gt;
    &lt;p&gt;Yes. DRM-free is more central to GOG than ever.&lt;/p&gt;
    &lt;head rend="h3"&gt;What happens to my GOG account?&lt;/head&gt;
    &lt;p&gt;Nothing changes. Your account stays a GOG account.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is GOG financially unstable?&lt;/head&gt;
    &lt;p&gt;No. GOG is stable and has had a really encouraging year. In fact, we’ve seen more enthusiasm from gamers towards our mission than ever before.&lt;/p&gt;
    &lt;head rend="h3"&gt;Will my tips or GOG Patrons donations be shared with Michał Kiciński, or any other party?&lt;/head&gt;
    &lt;p&gt;No. These funds stay within GOG to support preservation work, and they are not shared with publishers or other companies.&lt;/p&gt;
    &lt;head rend="h3"&gt;What happens to my library?&lt;/head&gt;
    &lt;p&gt;Nothing. Your library remains yours to enjoy, even if a game gets delisted, as it always has.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can I still download offline installers?&lt;/head&gt;
    &lt;p&gt;Yes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Will you share my data with Michał Kiciński, or other parties?&lt;/head&gt;
    &lt;p&gt;No. GOG remains the controller of your data, and nothing changes here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Will CD PROJEKT RED games continue to release on GOG?&lt;/head&gt;
    &lt;p&gt;CD PROJEKT RED games will continue to be available on GOG, and upcoming titles from the studio will also be released on the platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.gog.com/blog/gog-is-getting-acquired-by-its-original-co-founder-what-it-means-for-you/"/><published>2025-12-29T16:43:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46422812</id><title>Show HN: Evidex – AI Clinical Search (RAG over PubMed/OpenAlex and SOAP Notes)</title><updated>2025-12-29T21:37:22.463764+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.getevidex.com"/><published>2025-12-29T17:17:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46423010</id><title>Nvidia takes $5B stake in Intel under September agreement</title><updated>2025-12-29T21:37:22.251660+00:00</updated><content>&lt;doc fingerprint="2154c16d9c3353a7"&gt;
  &lt;main&gt;
    &lt;p&gt;Dec 29 (Reuters) - Nvidia (NVDA.O) has purchased Intel shares worth $5 billion, the American semiconductor firm (INTC.O) said in a filing on Monday, carrying out a transaction announced in September.&lt;/p&gt;
    &lt;p&gt;The leading AI chip designer said in September it would pay $23.28 per share for Intel common stock, in a deal that is seen as a major financial lifeline for the chipmaker after years of missteps and capital intensive production capacity expansions drained its finances.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The world's most valuable firm has bought over 214.7 million Intel shares at the price set out in the September agreement, in a private placement, according to Monday's filing.&lt;/p&gt;
    &lt;p&gt;U.S. antitrust agencies had cleared Nvidia's investment in Intel, according to a notice posted by the U.S. Federal Trade Commission earlier in December.&lt;/p&gt;
    &lt;p&gt;Nvidia shares were down 1.3% in premarket trading while Intel stock was little changed.&lt;/p&gt;
    &lt;p&gt;Reporting by Arsheeya Bajwa in Bengaluru; Editing by Anil D'Silva&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/legal/transactional/nvidia-takes-5-billion-stake-intel-under-september-agreement-2025-12-29/"/><published>2025-12-29T17:32:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46423521</id><title>The production bug that made me care about undefined behavior</title><updated>2025-12-29T21:37:22.164168+00:00</updated><content>&lt;doc fingerprint="9a79d8188a871a98"&gt;
  &lt;main&gt;&lt;p&gt;Published on 2025-12-27&lt;/p&gt;&lt;p&gt;Discussions: /r/programming, lobsters.&lt;/p&gt;&lt;p&gt;Years ago, I maintained a big C++ codebase at my day job. This product was the bread winner for the company and offered a public HTTP API for online payments. We are talking billions of euros of processed payments a year.&lt;/p&gt;&lt;p&gt;I was not a seasoned C++ developer yet. I knew about undefined behavior of course, but it was an abstract concept, something only beginners fall into. Oh boy was I wrong.&lt;/p&gt;&lt;p&gt;Please note that I am not and never was a C++ expert, and it's been a few years since I have been writing C++ for a living, so hopefully I got the wording and details right, but please tell me if I did not.&lt;/p&gt;&lt;p&gt;In this article I always say 'struct' when I mean 'struct or class'.&lt;/p&gt;&lt;p&gt;So, one day I receive a bug report. There is this HTTP endpoint that returns a simple response to inform the client that the operation either succeeded or had an error:&lt;/p&gt;&lt;code&gt;{
  "error": false,
  "succeeded": true,
}
&lt;/code&gt;&lt;p&gt;or&lt;/p&gt;&lt;code&gt;{
  "error": true,
  "succeeded": false,
}

&lt;/code&gt;&lt;p&gt;The actual format was probably not JSON, it was probably form encoded, I cannot exactly remember, but that does not matter for this bug.&lt;/p&gt;&lt;p&gt;This data model is not ideal but that's what the software did. Obviously, either &lt;code&gt;error&lt;/code&gt; or &lt;code&gt;succeeded&lt;/code&gt; is set but not both or neither (it's a XOR).&lt;/p&gt;&lt;p&gt;Anyway, the bug report says that the client received this reply:&lt;/p&gt;&lt;code&gt;{
  "error": true,
  "succeeded": true
}
&lt;/code&gt;&lt;p&gt;Hmm ok. That should not be possible, it's a bug indeed.&lt;/p&gt;&lt;p&gt;I now look at the code. It's all in one big function, and it's doing lots of database operations, but the shape of the code is very simple:&lt;/p&gt;&lt;code&gt;struct Response {
  bool error;
  bool succeeded;

  std::string data;
};

void handle() {
  Response response;
  
  try {
    // [..] Lots of database operations *not* touching `response`.

    response.succeeded = true;
  } catch(...) {
    response.error = true;
  }
  response.write();
}
&lt;/code&gt;&lt;p&gt;Here is a godbolt link with roughly this code.&lt;/p&gt;&lt;p&gt;There's only one place that sets the &lt;code&gt;succeeded&lt;/code&gt; field. And only one that sets the &lt;code&gt;error&lt;/code&gt; field. No other place in the code touches these two fields.&lt;/p&gt;&lt;p&gt;So now I am flabbergasted. How is that possible that both fields are true? The code is straightforward. Each field is only set once and exclusively. It should be impossible to have both fields with the value &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;At this point, my C developer spider senses are tingling: is &lt;code&gt;Response response;&lt;/code&gt; the culprit? It has to be, right? In C, that's clear undefined behavior to read fields from &lt;code&gt;response&lt;/code&gt;: The C struct is not initialized.&lt;/p&gt;&lt;p&gt;But right after, I stumble upon official C++ examples that use this syntax. So now I am confused. C++ initialization rules are different from C, after all.&lt;/p&gt;&lt;p&gt;Cue a training montage with 80's music of me reading the C++ standard for hours. The short answer is: yes, the rules are different (enough to fill a book, and also they vary by C++ version) and in some conditions, &lt;code&gt;Response response;&lt;/code&gt; is perfectly fine. In some other cases, this is undefined behavior.&lt;/p&gt;&lt;p&gt;In a nutshell: The default initialization rule applies when a variable is declared without an initializer. It's quite complex but I'll try to simplify it here.&lt;/p&gt;&lt;p&gt;Default initialization occurs under certain circumstances when using the syntax &lt;code&gt;T object;&lt;/code&gt; :&lt;/p&gt;&lt;code&gt;T&lt;/code&gt; is a non struct, non array type, e.g. &lt;code&gt;int a;&lt;/code&gt;, no initialization is performed at all. This is obvious undefined behavior.&lt;code&gt;T&lt;/code&gt; is an array, e.g. &lt;code&gt;std::string a[10];&lt;/code&gt;, this is fine: each element is default-initialized. But note that some types do not have default initialization, such as &lt;code&gt;int&lt;/code&gt;: &lt;code&gt;int a[10]&lt;/code&gt; would leave each element uninitialized.&lt;code&gt;T&lt;/code&gt; is a POD (Plain Old Data, pre C++11. The wording in the standard changed with C++11 but the idea remains under the term Trivially Default Constructible) struct, e.g. &lt;code&gt;Foo foo;&lt;/code&gt; no initialization is performed at all. This is akin to doing &lt;code&gt;int a;&lt;/code&gt; and then reading &lt;code&gt;a&lt;/code&gt;. This is obvious undefined behavior.&lt;code&gt;T&lt;/code&gt; is a non-POD struct, e.g. &lt;code&gt;Bar bar;&lt;/code&gt; the default constructor is called, and it is responsible for initializing all fields. It is easy to miss one, or even forget to implement a default constructor entirely, leading to undefined behavior.&lt;p&gt;It's important to distinguish the first and last case: in the first case, no call to the default constructor is emitted by the compiler. In the last case, the default constructor is called. If no default constructor is declared in the struct, the compiler generates one for us, and calls it. This can be confirmed by inspecting the generated assembly.&lt;/p&gt;&lt;p&gt;With this bug, we are in the last case: the &lt;code&gt;Response&lt;/code&gt; type is a non-POD struct (due to the &lt;code&gt;std::string data&lt;/code&gt; field), so the default constructor is called. &lt;code&gt;Response&lt;/code&gt; does not implement a default constructor. This means  that the compiler generates a default constructor for us, and in this generated code, each struct field is default initialized. So, the &lt;code&gt;std::string&lt;/code&gt; constructor is called for the &lt;code&gt;data&lt;/code&gt; field and all is well. Except, the other two fields are not initialized in any way. Oops.&lt;/p&gt;&lt;p&gt;Here is a quick summary:&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Type&lt;/cell&gt;&lt;cell role="head"&gt;Example&lt;/cell&gt;&lt;cell role="head"&gt;Result (Default Init)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Primitive (int, bool, etc)&lt;/cell&gt;&lt;cell&gt;int x;&lt;/cell&gt;&lt;cell&gt;Indeterminate (Garbage value)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;POD / Trivial Struct&lt;/cell&gt;&lt;cell&gt;Point p;&lt;/cell&gt;&lt;cell&gt;Indeterminate (All fields garbage)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Array of Objects&lt;/cell&gt;&lt;cell&gt;std::string x[10];&lt;/cell&gt;&lt;cell&gt;Safe (All strings initialized)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Array of Primitives&lt;/cell&gt;&lt;cell&gt;int x[10];&lt;/cell&gt;&lt;cell&gt;Indeterminate (All garbage)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Non-Trivial Struct&lt;/cell&gt;&lt;cell&gt;Response r;&lt;/cell&gt;&lt;cell&gt;Calls Default Constructor (Structs ok, primitives garbage)&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Any Type (Braces)&lt;/cell&gt;&lt;cell&gt;T obj{};&lt;/cell&gt;&lt;cell&gt;Value Initialized (Safe / Zeroed)&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Thus, the only way to fix the struct without having to fix all call sites is to implement a default constructor that properly initializes every field:&lt;/p&gt;&lt;code&gt;struct Response {
  bool error;
  bool succeeded;

  std::string data;

  Response(): error{false}, succeeded{false}, data{} 
  {
  }
};
&lt;/code&gt;
&lt;p&gt;Here is a godbolt link with this code.&lt;/p&gt;&lt;p&gt;Of course, due to the rule of 6 (when I started to learn C++ it was 3), we now have to implement the default destructor, the default move constructor etc etc etc.&lt;/p&gt;&lt;p&gt;Alternatively, we can define default values for the fields in the struct definition and avoid defining a default constructor:&lt;/p&gt;&lt;code&gt;struct Response {
  bool error = false;
  bool succeeded = false;

  std::string data;
}
&lt;/code&gt;
&lt;p&gt;This way, the default constructor generated by the compiler will initialize all the fields.&lt;/p&gt;&lt;p&gt;My fix at the time was to simply change the call site to:&lt;/p&gt;&lt;code&gt;  Response response{};
&lt;/code&gt;
&lt;p&gt;Here is a godbolt link with this code.&lt;/p&gt;&lt;p&gt;That forces zero initialization of the &lt;code&gt;error&lt;/code&gt; and &lt;code&gt;succeeded&lt;/code&gt; fields as well as default initialization of the &lt;code&gt;data&lt;/code&gt; field. And no need to change the struct definition.&lt;/p&gt;&lt;p&gt;This was my recommendation to my teammates at the time: do not tempt the devil, just always zero initialize when declaring a variable.&lt;/p&gt;&lt;p&gt;It is important to note that in some cases, the declaration syntax &lt;code&gt;Response response;&lt;/code&gt; is perfectly correct, provided that:&lt;/p&gt;&lt;p&gt;Then, the default constructor of the struct is invoked, which invokes the default constructor of each field.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;code&gt;struct Bar {
  std::string s;
  std::vector&amp;lt;std::string&amp;gt; vec;
};

int main() {
  Bar bar;

  // Prints: s=`` v.len=0
  // No undefined behavior.
  printf("s=%s v.len=%zu\n", bar.s.c_str(), bar.vec.size());
}
&lt;/code&gt;
&lt;p&gt;But to know that, you need to inspect each field (recursively) of the struct, or assume that every default constructor initializes each field.&lt;/p&gt;&lt;p&gt;Finally, it's also worth noting that it is only undefined behavior to read an uninitialized value. Simply having uninitialized fields is not undefined behavior. If the fields are never read, or written to with a known value, before being read, there is no undefined behavior.&lt;/p&gt;&lt;p&gt;The compiler (&lt;code&gt;clang&lt;/code&gt;) does not catch this issue even with all warnings enabled. This is frustrating because the compiler happily generates, and calls, a default constructor that does not initialize all the fields. So, the caller is expected to set all the uninitialized fields to some value manually? This is nonsense to me.&lt;/p&gt;&lt;p&gt;&lt;code&gt;clang-tidy&lt;/code&gt; catches the issue. However at the time it was imperfect, quoting my notes from back then:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;clang-tidy&lt;/code&gt;reports this issue when trying to pass such a variable as argument to a function, but that's all. We want to detect all problematic locations, even when the variable is not passed to a function. Also,&lt;code&gt;clang-tidy&lt;/code&gt;only reports one location and exits.&lt;/quote&gt;&lt;p&gt;But now, it seems it has improved, and reports all problematic locations, and not only in function calls, which is great.&lt;/p&gt;&lt;p&gt;I also wrote in my notes at the time that &lt;code&gt;cppcheck&lt;/code&gt; 'spots this without issues', but when I try it today, it does not spot anything even with &lt;code&gt;--enable=all&lt;/code&gt;. So, maybe it's a regression, or I am not using it correctly.&lt;/p&gt;&lt;p&gt;Most experienced C or C++ developers are probably screaming at their screen right now, thinking: just use Address Sanitizer (or ASan for short)!&lt;/p&gt;&lt;p&gt;Let's try it on the problematic code:&lt;/p&gt;&lt;code&gt;$ clang++ main.cpp -Weverything -std=c++11 -g -fsanitize=address,undefined -Wno-padded
$ ./a.out
a.out(46953,0x1f7f4a0c0) malloc: nano zone abandoned due to inability to reserve vm space.
main.cpp:21:41: runtime error: load of value 8, which is not a valid value for type 'bool'
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior main.cpp:21:41 
error=0 success=1
&lt;/code&gt;
&lt;p&gt;Great, the undefined behavior is spotted! Even if the error message is not super clear. This is ASan's way of saying: "I expected a 0 or 1 for this boolean, but I found a random 8 in that memory slot."&lt;/p&gt;&lt;p&gt;We alternatively could also have used Valgrind to the same effect.&lt;/p&gt;&lt;p&gt;But: it means that we now need to have 100% test coverage to be certain that our code does not have undefined behavior. That's a big ask.&lt;/p&gt;&lt;p&gt;Also, in my testing, Address Sanitizer did not always report the issue. That's the nature of the tool: it is meant to be conservative and avoid false positives, to avoid alerting fatigue, but that means it won't catch all issues.&lt;/p&gt;&lt;p&gt;Additionally, these tools have a performance cost and can make the build process a bit more complex.&lt;/p&gt;&lt;p&gt;I wrote a &lt;code&gt;libclang&lt;/code&gt; plugin at the time to catch other instances of this problem in the codebase at build time: https://github.com/gaultier/c/tree/master/libclang-plugin .&lt;/p&gt;&lt;p&gt;Amazingly, there was only one other case in the whole codebase, and it was a false positive because by chance, the caller set the uninitialized fields right after, like this:&lt;/p&gt;&lt;code&gt;Response response;
response.error = false;
response.success = true;
&lt;/code&gt;
&lt;p&gt;I have no idea if this &lt;code&gt;libclang&lt;/code&gt; plugin still works today because I have heard that the &lt;code&gt;libclang&lt;/code&gt; API often has breaking changes.&lt;/p&gt;&lt;p&gt;Remember all these rules we have just gone through? You want more? What if we added some sweet special cases to them?&lt;/p&gt;&lt;p&gt;Some types, when the value is not initialized, do not trigger undefined behavior, if they are used in certain ways:&lt;/p&gt;&lt;code&gt;std::byte&lt;/code&gt;&lt;code&gt;unsigned char&lt;/code&gt;&lt;code&gt;char&lt;/code&gt; if the underlying representation is &lt;code&gt;unsigned&lt;/code&gt;&lt;p&gt;For example, this code is perfectly valid and free of undefined behavior:&lt;/p&gt;&lt;code&gt;    unsigned char c;     // “c” has an indeterminate/erroneous value
 
    unsigned char d = c; // no undefined/erroneous behavior,
                         // but “d” has an indeterminate/erroneous value
 
    assert(c == d);  // holds, but both integral promotions have
                         // undefined/erroneous behavior
&lt;/code&gt;
&lt;p&gt;And this runs perfectly fine under ASan. Clang throws some warnings but compiles fine, and this is valid (in terms of the C++ standard) code.&lt;/p&gt;&lt;p&gt;Now, if we use &lt;code&gt;bool&lt;/code&gt; (for example) instead:&lt;/p&gt;&lt;code&gt;  bool c; 
  bool d = c;
  assert(c == d);
&lt;/code&gt;
&lt;p&gt;This is undefined behavior and immediately triggers ASan errors! Even if the code is the same in terms of type sizes and stack layout!&lt;/p&gt;&lt;p&gt;I do not know why the C++ standard felt the need to muddy the water even more, but they surely had a reason. Right?&lt;/p&gt;&lt;p&gt;Some quick research seems to indicate that these types are special cases to allow code to manipulate raw bytes like memcpy or buffer management without the compiler freaking out. Which...maybe makes sense?&lt;/p&gt;&lt;p&gt;In my opinion, this bug is C++ in a nutshell:&lt;/p&gt;&lt;code&gt;data&lt;/code&gt; field) makes the compiler generate completely different code at the call sites.&lt;p&gt;In contrast I really, really like the 'POD' approach that many languages have taken, from C, to Go, to Rust: a struct is just plain data. Either the compiler forces you to set each field in the struct when creating it, or it does not force you, and in this case, it zero-initializes all unmentioned fields. This is so simple it is obviously correct (but let's not talk about uninitialized padding between fields in C :/ ).&lt;/p&gt;&lt;p&gt;In the end I am thankful for this bug, because it made me aware for the first time that undefined behavior is real and dangerous, for one simple reason: it makes your program behave completely differently than the code. By reading the code, you cannot predict the behavior of the program in any way. The code stopped being the source of truth. Impossible values appear in the program, as if a cosmic ray hit your machine and flipped some bits. And you can very easily, and invisibly, trigger undefined behavior.&lt;/p&gt;&lt;p&gt;We programmers are only humans, and we only internalize that something (data corruption, undefined behavior, data races, etc) is a big real issue when we have been bitten by it and it ruined our day.&lt;/p&gt;&lt;p&gt;Post-Scriptum: This is not a hit piece on C++: C++ paid my bills for 10 years. I have been able to take a mortgage and build a house thanks to C++. But it is also a deeply flawed language, and I would not start a new professional project in C++ today without a very good reason. If you like C++, all the power to you. I just want to raise awareness on this (perhaps) little-known rule in the language that might trip you up.&lt;/p&gt;&lt;p&gt;A commenter posted this Forrest Gump gif that I had completely forgotten about, so thank you :)&lt;/p&gt;&lt;quote&gt;&lt;p&gt;If you enjoy what you're reading, you want to support me, and can afford it: Support me. That allows me to write more cool articles!&lt;/p&gt;&lt;p&gt;This blog is open-source! If you find a problem, please open a Github issue. The content of this blog as well as the code snippets are under the BSD-3 License which I also usually use for all my personal projects. It's basically free for every use but you have to mention me as the original author.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gaultier.github.io/blog/the_production_bug_that_made_me_care_about_undefined_behavior.html"/><published>2025-12-29T18:17:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46423566</id><title>List of domains censored by German ISPs</title><updated>2025-12-29T21:37:21.892778+00:00</updated><content>&lt;doc fingerprint="1ce1d9ea58191f5"&gt;
  &lt;main&gt;
    &lt;p&gt;CUII Liste.de Home Home Gesperrte Domains Domain hinzufügen Domain hinzufügen Bin ich betroffen? Bin ich betroffen? Zensur umgehen Zensur umgehen Über uns Über uns Von der CUII gesperrte Domains Home Home Gesperrte Domains Domain hinzufügen Domain hinzufügen Bin ich betroffen? Bin ich betroffen? Zensur umgehen Zensur umgehen Über uns Über uns&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cuiiliste.de/domains"/><published>2025-12-29T18:21:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424217</id><title>Left Behind: Futurist Fetishists, Prepping and the Abandonment of Earth</title><updated>2025-12-29T21:37:21.320503+00:00</updated><content>&lt;doc fingerprint="22d2d15220e38701"&gt;
  &lt;main&gt;
    &lt;p&gt;Sarah T. Roberts and Mél Hogan&lt;/p&gt;
    &lt;p&gt;This essay has been peer-reviewed by “The New Extremism” special issue editors (Adrienne Massanari and David Golumbia), and the b2o: An Online Journal editorial board.&lt;/p&gt;
    &lt;p&gt;“You know, I hear all these rich guys, for some reason they love space. So they’re rich. I said, ‘let them send the rockets up. What the hell do we have to do it, right?’”&lt;/p&gt;
    &lt;p&gt;— US President Donald Trump, Aug 15 2019 campaign rally,&lt;lb/&gt; Manchester NH (quoted in FOXBusiness 2019)&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Preppers, the Rapture and on Being “Left Behind”&lt;/head&gt;
    &lt;p&gt;At the turn of the millennium, an unexpected success took the mainstream publishing industry completely off-guard. A series of science fiction novels published by a tiny Christian press and depicting the end of the world from a distinctly Christian fundamentalist perspective became a massive, best-selling hit (McAlister 2003). Its themes of survival following a catastrophic global event were not foreign to the universe of science fiction literature; doomsday scenarios resulting in flight from one’s home planet to a celestial otherworld via space travel have served as plot devices in countless books, films and video games. Yet something about the Left Behind series (LaHaye and Jenkins 1995) was distinct.&lt;/p&gt;
    &lt;p&gt;That novelty in this case hinged upon the fact that the dystopian doomsday scenario in question was taken directly from an evangelical Christian Biblical interpretation of the Rapture, the New Testament prophecy that says that believers of Christ would be delivered en masse to Heaven while non-believers would be left to fend for themselves in a ravaged, evil-infected world. Despite, or perhaps because of, its overt Christian Evangelical bent, the series was both a massive commercial success and a cultural phenomenon. Drawing on its Evangelical underpinnings, the series located evil at a point of origin true to its theology and politics: as reported by SF Gate at the height of the its popularity, in 2006, “in [the Left Behind series], set in perfectly apocalyptic New York City, the Antichrist is personified by fictional Romanian Nicolae Carpathia, secretary-general of the United Nations and a People magazine ‘Sexiest Man Alive’” (Lelchuk and Writer 2006).&lt;/p&gt;
    &lt;p&gt;The series went on to spawn a popular, albeit technically flawed, video game (and sequels), in which the conceit is to convert as many non-believers as possible and save them from post-Armageddon eternal terrestrial doom. It also led to the production of several films, the first batch starring former sitcom actor and Evangelical Christian Kirk Cameron, followed by an attempted 2014 reboot featuring Nicolas Cage. Whatever the medium, the heroes of the franchise were no Luddites; indeed, as American Studies scholar Melani McAlister remarked in her expansive essay on the cultural meaning of Left Behind:&lt;/p&gt;
    &lt;p&gt;LaHaye and Jenkins establish their characters as more modern than modern. Making the most of the fact that the events they describe must necessarily be the future (though a rather near-term future, in their view), the novels present a world in which our Tribulation Force members are unfailingly knowledgeable about, and outfitted with, an impressive array of the best possible equipment, from guns to high-end SUVs, from Gulfstream jets to the ‘computer without limitations’ ordered by the Tribulation Force from an underground dealer. (McAlister 2003, 783)&lt;/p&gt;
    &lt;p&gt;The Rapture is a religious event, key to understanding Evangelical Christian theology and practice. But in the Left Behind series, it is also a secular global disaster, which requires skill, determination, tech and ideological dedication to survive. Those who remain on Earth wait for their own opportunity to be spirited away, newly transformed into fully committed believers, to a Christian heaven.&lt;/p&gt;
    &lt;p&gt;While the Left Behind franchise reflects a profoundly sectarian Evangelical Christian eschatology, preoccupation with the coming of end times, whether Christian or secular versions, has become more commonplace and concomitantly more socially acceptable in 21st century American culture—on the rise, however, since the mid-20th century’s preoccupation with escape from nuclear annihilation by a paradoxical technological arms race. This new social acceptability has been enhanced by worsening economic, environmental and social conditions, and bolstered by technological developments designed to accommodate a dystopian, resource-poor future marked by global war, environmental chaos, famine, and/or the end of sustainable human life.&lt;/p&gt;
    &lt;p&gt;What Left Behind did to prepare the Evangelical American psyche for coming horror has been replicated in material form: to prepare for a variety of nightmarish end-times eventualities, people have built bunkers, stockpiled food, hoarded weapons and created structures (many in the form below-ground bunkers, but also silos, geodesic domes and other improbable architectural masterworks) intended to offer the latest technological innovations that can support inhabitants in a variety of post-apocalyptic scenarios.[1] Many are elaborate and spare no innovation or expense to provide for the inhabitants’ creature comforts and well-being as the world above disintegrates into chaos and ruin.&lt;/p&gt;
    &lt;p&gt;There is historical precedence for this new end-of-days prepping, grounded in the mid-20th century Cold War nuclear fallout shelters. A recent article in The Atlantic on the new luxury prepping phenomenon begins with this historical observation: “On July 25, 1961, President John F. Kennedy spoke to the American people of a need ‘new to our shores’ for emergency preparedness, including fallout shelters. The bunkers of that era—Brutalist, cement, with foldout beds and stockpiled food—were designed to protect families in the event that the Cold War turned hot” (Rowen 2017). Decades on, these early escape rooms, and the anxieties that had provoked them, had largely melted away, their remnants anachronistic oddities of another time.&lt;/p&gt;
    &lt;p&gt;One of this article’s authors recalls childhood afternoons in the 1980s playing in a bomb shelter built off a friend’s basement, which had fallen into disuse, never having been deployed in the context of the man-made disaster scenario of post-nuclear holocaust survival. It was a physically and emotionally uncomfortable reminder from another era, lined in cold concrete cinder blocks and plywood bunks. Nonetheless, its builders had gone to pains to decorate and had painted on the cement walls, cheerily but ominously, a wooded nature landscape scene that, aboveground, would have been all but assuredly vaporized, were its builders actually ensconced inside it for the long haul and using it for its intended purpose.&lt;/p&gt;
    &lt;p&gt;In the post-9/11, economically depressed and socially divided America, disaster preparedness has been experiencing a comeback. A new prepper phenomenon has even become the fodder of media empires: Doomsday Preppers, a reality program, airing on cable’s National Geographic Channel from 2011 through 2014, was a ratings hit (National Geographic Channel 2014), which subsequently spawned a number of lookalikes on other networks (Genzlinger 2012). As depicted on these programs, the preppers of the paranoid post-millennium come in all orientations and political persuasions, but lean toward the right of the political spectrum, with strains of individualism and lack of faith in government the predominating common threads among them. A fondness for weaponry of all kinds—but particularly for guns— and means of self-defense are often at the center of the preparations and infrastructure, so that the prepared may defend themselves not only against an enemy, but also against those who were not so well prepared for calamity and unwisely attempt to seek material support or other assistance from their neighbors.&lt;/p&gt;
    &lt;p&gt;Indeed, it is the very preparation involving the arming of one’s self and family in the face of impending disaster that serves as a culture of its own; the gun culture prevalent in the United States is frequently overlaid with prepper culture and, itself, serves as a focal point of strong community formations. The group known as “America’s Largest Right-Wing Militia,” the Georgia III% Security Force, is depicted intimately in VICE’s “Guns in America” series (III% Security Force nd). As explained by VICE, this group “is inspired by the unfounded claim that only three percent of colonists fought against the British in the American Revolution” (VICE 2017). The Georgia Three Percenters fight against what they perceive as attacks on the Second Amendment to the United States Constitution, protecting the people’s right to bear arms. To prepare for what they believe is an imminent war, they gather monthly to train and discuss strategies. This group, led by White, rural working-class people, was especially active in the months leading up to the 2016 US elections, convinced that Hillary Clinton was “plotting to take them [their guns] away” (Zucchino 2016), a likelihood that had no basis in demonstrable fact.&lt;/p&gt;
    &lt;p&gt;Despite its overwhelming association with White culture and people, the group has complicated racial politics, as often eluded to by the militia’s leader Chris Hill in the VICE profile. On camera, Hill explains: “we’re not racist, we’re against racism… we’re against supremacy of all kind—fuck it all—we’re all created equal, but until people can get that fucking message we must be prepared to defend ourselves and each other” (VICE 2017). Who the enemy is remains forever ideological, conceptual, and a perfect opportunity to play with guns to protect a future imaginary of their own making.&lt;/p&gt;
    &lt;p&gt;The hoarding of guns and a lust to use them are the organizing principles of Mel Bernstein’s life; he is described in numerous media accounts (and also self-styled) as the “most armed man in America” (Koenigs 2017). Bernstein collects, rents and sells military-style vehicles and weapons from his 260-acre compound (called “Dragonland”) in Colorado Springs. He also runs a paintball park, motocross park, military museum, gun shop and shooting ranges.&lt;/p&gt;
    &lt;p&gt;One of the 3 percent of Americans who own half the country’s guns (Ingraham 2016). ABC News recently aired a short profile on Bernstein (Koenigs 2017), focusing on his extreme nostalgia and sense of loneliness: five years ago, his wife was killed by a smoke bomb on their property during the filming of reality-TV pilot for the Discovery Channel. He now lives with four human-sized dolls, all of which he has named (Jennifer, Betty, Jill, and one unnamed in the clip), dressed in feminine attire, and posed in the nostalgic 1950s-style diner that is his kitchen. Bernstein legally owns more than 4000 weapons; his bedroom is lined with M16s and assault rifles, sawed-off shotguns, and handguns—but it is the mannequins that push people to question his sanity.&lt;/p&gt;
    &lt;p&gt;The appeal of groups and individuals like the III% militia, Bernstein, and reality TV preppers as the subjects of programs—and their shared overlapping interest in and certainty of near-future impending global calamity—is due in part to the ingenuity with which they conceive and execute their survival goals. Enjoyment, however, often comes with that dose of schadenfreude or superiority endemic to reality TV, undergirded by a tacit mocking of its subjects at all times (Papacharissi &amp;amp; Mendelson 2007; Reiss &amp;amp; Wiltz 2004). In aggregate, a great deal of the appeal lies in looking in on crazy zealots, ridiculous obsessives, and eccentrics who spend their families’ life savings and all of their time burrowing in their backyards or hoarding non-perishables. The unresolved issue at the root of the entire enterprise, as the New York Times preppers TV article points out, is the question of who would even want to survive the disasters for which the preppers are prepping (Genzlinger 2012). For many of the preppers, it is the singular focus on prepping itself from which they derive the satisfaction that blurs so easily into religious fervor. The TV preppers’ solutions to anxieties for the future must always be counterbalanced for viewers by a sense of ridicule and unease provoked by the necessary obsessiveness it takes to plan for disasters that may never come—a global electromagnetic pulse, alien invasion, total environmental collapse, or the need to survive until the rapturous wave arrives to call them to the next stage of existence.&lt;/p&gt;
    &lt;p&gt;While these eccentric, yet mostly unheralded (prior to their profiles on TV) people are easily made the object of humor or scorn through programs like Ultimate Preppers or ABC’s feature on Bernstein, stories about social and financial elites’ machinations in these directions are offered up without the same sort of skepticism. From Steve Bannon to Elon Musk, or from Biosphere 2 to SpaceX, the elite can afford passion projects of immense scale unavailable to even the most ingenious TV prepper. Rather than resolve issues on earth, they look to the stars and into our cells. Perhaps they know something others do not. Feminist philosopher Rosi Braidotti offers a diagnosis:&lt;/p&gt;
    &lt;p&gt;The new necro-technologies operate in a social climate dominated by a political economy of nostalgia and paranoia on the one hand, and euphoria or exaltation on the other. This manic-depressive condition enacts a number of variations: from the fear of the imminent disaster, the catastrophe just waiting to happen, to hurricane Katrina or the next environmental accident. (Braidotti 2012, 9-10)&lt;/p&gt;
    &lt;p&gt;Braidotti draws our attention to the contexts of disaster and how they shape lived experiences in imagined geographies and temporalities—tangible, but made-up; real, but fabricated. For Braidotti, and for philosopher of science Isabelle Stengers, ecological crises induce a cold panic that can be harnessed by technologically and economically élite “Guardians” (Stengers 2015, 27) to offer up a series of seemingly viable non-choices as choices and non-solutions as solutions. Technocratic problem-solving continues to adhere foremost to free-market ideology, which endeavors to maintain or deepen status quo power dynamics, unequal global economies, and to allow for social collapse, all due to a pathological resistance to state- or community-imposed regulation and limits. Because American culture equates money and power with morality and leadership, Stengers suggests that the outcome is a no-choice choice ultimately “between barbarism and barbarism” (Wark 2015), with people and planet held hostage to corporations and those who benefit from them.&lt;/p&gt;
    &lt;p&gt;Whether Earth’s collapse will come due resource extraction, environmental destruction, or war (or a combination thereof), the technocratic élite are not only both predisposed and poised to start anew somehow and somewhere else well beyond the backyard bunker but may even welcome or initiate it by way of inaction in the face of destruction on Earth. The outcome of any such cataclysmic, Earth-destroying catastrophes would yield a Rapture of its own, with the secular believers delivered to a futuristic beyond, and the rest who did not believe, or could not afford to, left behind.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. The Worse the Better: Accelerationism and Nihilism&lt;/head&gt;
    &lt;p&gt;Accelerationism (from the right) is a theoretical counter-proposal to resistance (from the left); a destabilizing force for fighting the ills of capitalism. As Benjamin Noys summarizes it in his Malign Velocities (2014):&lt;/p&gt;
    &lt;p&gt;Instead of rejecting the increasing tempo of capitalist production [proponents] argue that we should embrace and accelerate it. We haven’t seen anything yet as regards what speed can do. Such a counsel seems to be one of cynicism, suggesting we come to terms with capitalism as a dynamic of increasing value by actively becoming hyper-capitalist subjects. What interests me is a further turn of the screw of this narrative: the only way out of capitalism is to take it further, to follow its lines of flight or deterritorialization to the absolute end, to speed-up beyond the limits of production and so to rupture the limit of capital itself. (Noys 2014, i)&lt;/p&gt;
    &lt;p&gt;Accelerationism proposes that we collectively let things unravel to their full extent – socially, politically, economically, environmentally–by stoking, rather than seeking to mitigate–the forces that drive us toward devastation. In the accelerationist imaginary, the future is not about harm reduction, limits or restoration; rather it is a politics driving toward an endgame of the totalizing undoing of capitalism by capitalism.&lt;/p&gt;
    &lt;p&gt;Accelerationism locates resistance to capitalism as a byproduct of capitalism itself that by its nature reproduces it, and that such resistance can never fully stand outside of it to fight it, or really even be complete. It also suggests a foregone and nihilist conclusion to the contemporary status of global humanity, which, it asserts, was completely and inextricably captured within the capitalist orbit. It is thus an ideology offering no new ideas or no possibility for meaningful change beyond the total, inevitable collapse of the global system. In its early instantiations, accelerationism was a declaration about capitalism as a kind of alien invader from the future (Mackay 2012). It sees the outcome of late-stage capitalism as pushed by growth and profit to the point of spectacular self-destruction, an outcome that it welcomes.&lt;/p&gt;
    &lt;p&gt;Accelerationism as a political philosophy, with its goal of bringing about the end of the status quo (capitalism) by accelerating the world into full-blown crisis, has adherents on the left. Some leftists identify with the anti-capitalist endgame and see accelerationism as a means to implement a radical call for anti-work, full automation, and so on (Terranova 2014).[2] Yet, more significantly, it seems to have been taken up by the right, the outcome of a certain nihilism rooted in a sense of inevitability about the end of the world as we know it—due to environmental failures, natural (man-made) disasters and global warming, and so on—and a science fiction-influenced, technologically-driven fascination with concepts of spaceward expansionism, extraction and conquest. This right-wing strain is most commonly identified with Nick Land, once of the Cybernetic Culture Research Unit, or Ccru, at the University of Warwick (UK).&lt;/p&gt;
    &lt;p&gt;As his editor and onetime student Robin Mackay explains in the introduction to a collection of Land’s writings, “Marxists in particular were outraged by Land’s aggressive championing of the sociopathic heresy urging the ‘ever more uninhibited marketization of the processes that are tearing down the social field’—[hence] the acceleration, rather than the critique, of Capitalism’s disintegration of society” (Land 2017, 3).&lt;/p&gt;
    &lt;p&gt;Capitalism demands competition, which, in turn, relies on technological deployments, which, in turn, rely on the exploitation of cheap nature and labor, and reliable but unequal global flows (Moore 2014). Humans are not at the center, they merely serve toward the rendering of a technofuture, and then become superfluous. According to Alex Williams, in Nick Land’s envisioning of a post-capitalist future, “the human can eventually be discarded as mere drag to an abstract planetary intelligence rapidly constructing itself from the bricolaged fragments of former civilisations” (Williams 2013, 2). As for Land, he left his university post and has retreated to Shanghai to ruminate and produce paranoid speculative fiction with an accelerationist bent, his erstwhile right-curious politics having fully morphed into open and unabashed fascism.&lt;/p&gt;
    &lt;p&gt;In sum, what accelerationism as a political philosophy offers its adherents is a profoundly nihilistic view that suspends any hope in the ability of humans to intercede meaningfully in the world as it is. Instead, it hangs its hopes on an End Times of its own, awaiting a sort of secular Rapture that compels acolytes to not only await, but celebrate, the inevitable unravelling of the social order and collapse of the world as we know it For many, its proponents would claim, the worse things get, the better. Sound familiar?&lt;/p&gt;
    &lt;p&gt;When viewed through the dual lens of prepperdom and nihilistic accelerationism—both of which hold out for global disaster with a certain amount of titillation and glee—the large-scale projects for which techno-élites like Musk have become famous can be seen in another light entirely: as dismal, fatalistic projects that have given up any faith (pun intended) in the ability to resolve the human condition or life on Earth, in general, or perhaps, even more specifically, that there would be inherent value in such an effort at all. Indeed, the projects promoted by this technocratic élite do not scope into something favorable for a majority of the world’s inhabitants or life as we now know it; instead, they are so narrowly aimed as to solve very little about the ruinous conditions for vast swaths of the world’s population and, in many cases, quite literally seek to abandon Earth entirely.&lt;/p&gt;
    &lt;p&gt;Examples such Musk’s investments in SpaceX, his ruminations that we are all likely living in a computer simulation, or the desire to colonize Mars, all point toward his belief that life on Earth is largely unsalvageable; his billions of dollars of wealth and his unfettered access to resources therefore follow suit. In this regard, a recent musing from him on Twitter takes on an ominous undertone; his idle, passive musing about migrant children placed in cages in detention centers by the Trump Administration proposes no solution, no alternative, no call to act. Perhaps, in accordance with his world view, he sees no reason to. The game has already been lost and those in the know have moved on.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Dreaming of Post-Earth&lt;/head&gt;
    &lt;p&gt;In the billionaire kingmaker class, Musk is not alone in his post-Earth predilection. Indeed, he is one of several of his echelon looking cynically to science fiction and the après-apocalypse, fantasizing about outlandish ways to spend–and make–profits via projects that deepen long-standing commitments to Western supremacy and colonization, albeit with a futuristic bent. At the 2016 Republican National Convention that heralded the political ascendency of Donald Trump, PayPal billionaire and Gawker/journalism foe Peter Thiel (Thompson 2018) hailed the conquest of Mars as a worthier endeavor than wars in the Middle East. In doing so, Thiel inadvertently showed his ideological hand by invoking both as equivalent games of conquest (Daily Beast 2016). Other projects in this vein include Biosphere 2 (once the province of former Trump advisor and professional propagandist Steve Bannon), HI-SEAS, Apple’s new “Spaceship” headquarters, and the NSA’s Star Trek-inspired control room, all of which posit various offworld-oriented technological solutions to a dying future. It is a future in which capitalism has already played out the dissolution of democracy and social equalities, favoring a libertarian fend-for-yourself approach for those who remain– and those who remain, according to these projects, are overwhelmingly White, wealthy able-bodied people of the Global North.&lt;/p&gt;
    &lt;p&gt;Biosphere 2 was an architectural and ecology project launched in the early 1990s, privately funded by the Texas oil billionaire “ecopreneur” Edward Bass, who, given his industry, likely had certain expertise and foresight related to impending ecological collapse (Atlas Obscura 2013; “Biosphere 2” 2003). Based on science-fiction and architectural futurist concepts of fully-enclosed and self-sufficient human habitation environments known as “arcologies” (Plunkett 2011), Biosphere 2 was an attempt to create Earth-like living conditions within a container–what some early media reports described as “life in a bottle” (Turner 2011). The underlying conceit was that such living habitats would become necessary on Earth or on other planets, after life on this one could no longer be sustained.&lt;/p&gt;
    &lt;p&gt;The project quickly failed on many fronts, at which point future Breitbart News Editor-in-Chief Steven Bannon, at the time a former Goldman Sachs investment banker specializing in media and entertainment investments, was asked to come in to financially salvage the project (Jardin 2016). During this period, Biosphere 2 spiraled down from a quasi-legitimate scientific endeavor into a tourist spectacle, sharing more in common with Xanadu Computerized Houses of the Future (Dells Travel 2014) than legitimate empirical scientific research; lawsuits ensued in short order (Murphy 2016).&lt;/p&gt;
    &lt;p&gt;While Bannon claimed publicly that the Biosphere 2 experiment had been to study the effects of CO2 emissions and climate change in real-time, rather than merely through computer simulation, the entire project became one of fake science, with its focus repeatedly shifting to any story of innovation that could be packaged for the media.&lt;/p&gt;
    &lt;p&gt;In a similar case of earthbound arcologies meant to imagine a future framed by offworld life, the volunteer crew of the latest NASA Hawai’i Space Exploration Analog and Simulation (HI-SEAS) mission remained cloistered for eight months as part of a study to learn how astronauts might interact and problem-solve during long deployments. In HI-SEAS, six volunteers inhabited a fake Mars colony, playing the part of astronauts. Project chronicler Lynn Levy described the project as planning “for the day when the dress rehearsals are over, and we blast off for real” (Gimlet Media, 2018). Here too, however, participants were kept busy with scientific homework: “The HI-SEAS site has Mars-like geology which allows crews to perform high-fidelity geological field work and add to the realism of the mission simulation” (HI-SEAS, n.d.).&lt;/p&gt;
    &lt;p&gt;It is worthy of note that the HI-SEAS site was chosen for its environmental similarities to Mars, but seemingly without any acknowledgment of the irony that the make-believe colony is located on the very much contested and already colonized island of Hawai’i, where active protests are now underway to impede the placement of further telescopic equipment used for astronomical observation atop sacred mountains.&lt;/p&gt;
    &lt;p&gt;A nod to offworld architecture and otherworldly craft was resonant too, in the design of both Apple’s new “Spaceship” headquarters and the NSA’s control room. Both structures were characterized by design demonstrating the desire to have not only control over but also a front row seat to the apocalypse . The new Apple campus, shaped like a flying saucer (or perhaps the ouroboros-like literal form of its longtime “infinite loop” street address) has all the amenities of a city, becoming, much like Star Trek’s Starship Enterprise or a fully-enclosed archology, its own world-within-a-vessel. It operates like a spaceship that has landed on earth rather than one about to take off, and by design uses its surroundings to anchor itself for future generations. The spaceship is surrounded by a thick layer of trees, mostly apricot, maintains a thousand bikes on the site for workers to get around, and has its own energy center that runs mostly off-grid. The spaceship aesthetic and panoptic/open floor work spaces reinstate order and hierarchy through structural and embedded surveillance while suggesting freedom of movement and action. Ample amenities are designed to keep workers on-site and productive, ideally for longer than an eight-hour workday, recalling the company towns of the 18th, 19th and 20th centuries. Not to be outdone, both Google and Facebook have announced employee housing near their expansive campuses (Stangel 2017), in partial response to extraordinary housing costs in Silicon Valley (created by the demand from their own workers).&lt;/p&gt;
    &lt;p&gt;The unbroken circle design of the building creates an inside vs. outside protected space for Apple employees in much the same way that projects from 1950s fallout shelters to Biosphere 2 have sought to seal off a group of the chosen from the others who must remain outside the walls. Indeed, just as the skies part to allow ascendency to Heaven of God’s anointed on the cover of the Left Behind video game (as seen in figure 1), the artistic rendering of the Apple Spaceship shows a similar break in the clouds and sunlight beaming down on its infinite loop.&lt;/p&gt;
    &lt;p&gt;The appeal of science fiction fantasy has been taken up by government agencies, too. In contrast to the Chilean “Synco” or “Project Cybersyn” of the 1970s, which used cybernetic aesthetics to create a work room to respond to economic crises in real time (Medina 2011), the former National Security Agency (NSA) Chief Keith Alexander’s had constructed an “Information Dominance Center” war room (Greenwald 2013). For Chile’s socialist President, Salvador Allende, ‘revolutionary computing’ meant putting workers in control of decisions (Medina 2006, 574–575). This socialist project stands in contrast to the “Information Dominance Center” designed to allow the USA’s NSA virtually one-man control over an increasingly vast network of surreptitious surveillance and data gathering.&lt;/p&gt;
    &lt;p&gt;In the case of both Big Tech and governmental surveillance agencies, undergirding a commitment to the inevitable and imminent time after Earth is the appeal of science fiction aesthetics, concepts and projects, all aimed toward the new goal of having new places and opportunities to conquer, colonize and dominate post-Earth. SpaceX’s goal is to land a person on Mars; closer to home are other instantiations of futuristic fantasy, from the NSA’s Star Trek-inspired control room to Apple’s Spaceship. Hermetically-sealed scientists and volunteers roleplay in extreme environments to ready themselves for off-world living. In all of these examples, the playing out of “accelerationism” is both a chronological and technological acceleration, as well as the strategic buying and use of remaining time–to hide, prepare and come up with exit strategies.&lt;/p&gt;
    &lt;p&gt;What makes these cases so compelling is that they often inadvertently show the élites’ cynical, hubristic and pessimistic hand, a tell that gives away the fact that their technological propositions cannot salvage life on Earth for the masses, and, even worse, that they are no longer interested in trying. These projects all cater to the right’s accelerationist rationale that it is too late to act, too late to come together for collective decision-making, and too late to care, all while disavowing the powerful agency that has gone into making those beliefs into fact (such as in the case of the fossil fuel magnate who bankrolled Biosphere2). The investment is therefore into a future for the prepared and worthy few, and damnation for the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion: Prepping for Pleasure and for Profit&lt;/head&gt;
    &lt;p&gt;For this special issue of b2o, we have explored Musk’s SpaceX, the NSA’s control room, Biosphere 2, HI-SEAS, and Apple’s new “Spaceship” headquarters. In them, we find deep political, ideological and even theological deployments of technology concerned with escape from planet Earth. These projects and structures necessarily downplay and deny their impetus: the deleterious, long-term effects of human-induced, industrial-scale problems such as resource extraction, environmental destruction, and war. The common throughline to these projects is the often unarticulated and disturbing conceit that the viability of Earth to sustain a high quality of life for élites, and, by extension, for the vast majority of the population is no longer assured. In such a scenario, escape to the stars, as best imagined in Cold War-era pulp science fiction, should not only be welcomed but perhaps hastened; a secular Rapture or “Left Behind” for Dawkins-esque technofetishists who pray at the altar of “disruption” and “innovation.”&lt;/p&gt;
    &lt;p&gt;Linked theoretically, conceptually, and politically, both to each other and to their unacknowledged or obfuscated ideological origins in accelerationism and nihilism, these endeavors, and their proponents in government and technology sectors, represent the ultimate preppers, ready to start anew somehow and somewhere else: in a self-contained unit like Biosphere 2 or HI-SEAS, on the newly discovered “habitable” planets, or on Mars.&lt;/p&gt;
    &lt;p&gt;Nick Land’s accelerationist vision of society is one already lost to any means of human intervention ; as such, we should let the process unfold as society proceeds toward inevitable collapse, in order to start anew. It is a grim End Times vision of Biblical proportions; what it lacks in evangelical Christianity it makes up for in a totalizing world view demanding adherence rising to zealotry.&lt;/p&gt;
    &lt;p&gt;For those who are not solely hypercapitalist zealot-purists of a Landian variety and yet are attracted to futurist projects (but a few of which we have catalogued here), acceleration towards cataclysm, as articulated through large-scale prepper projects for an off-World future, has its own draw and proposes its own alluring rewards: the economic incentives of colonization, resource control and a rush to develop, own and extract post-Earth is expected to pay off, financially and figuratively. Woe be unto the rest of us who do not heed the signs and find ourselves left behind.&lt;/p&gt;
    &lt;p&gt;_____&lt;/p&gt;
    &lt;p&gt;Sarah T. Roberts is assistant professor in the department of information studies at UCLA. Her book, Behind the Screen: Content Moderation in the Shadows of Social Media, is out now from Yale University Press.&lt;/p&gt;
    &lt;p&gt;Mél Hogan is assistant professor of Environmental Media at the University of Calgary. She is writing a book about genomic media and DNA data storage in the cloud.&lt;/p&gt;
    &lt;p&gt;_____&lt;/p&gt;
    &lt;p&gt;Notes&lt;/p&gt;
    &lt;p&gt;[1] It is worth noting that geodesic domes were the province and product of Buckminster Fuller, whom Stewart Brand, early Silicon Valley champion and counterculture hero, credited as the inspiration behind his Whole Earth Catalog. Fred Turner, in his chronicle of this period and culture, writes “in retrospect, it is easy to understand Fuller’s appeal to cold war American youth…he simultaneously embraced the pleasures and power associated with the products of technocracy and offered his audiences a way to avoid becoming technocratic drones. Moreover, according to Fuller, the proper deployment of information and technology could literally save the human species from annihilation” (Turner 2010, 57)&lt;/p&gt;
    &lt;p&gt;[2] See also Shukaitis (2009): “one could argue that through much of leftist politics runs the notion of an apocalyptic moment, of some magical event (usually revolution), followed by the creation of a new and better world” (97).&lt;/p&gt;
    &lt;p&gt;_____&lt;/p&gt;
    &lt;p&gt;Works Cited&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Atlas Obscura. 2013. “Biosphere 2: A Glass-Encased Artificial Earth in the Arizona Desert.” Slate (Sep 5).&lt;/item&gt;
      &lt;item&gt;Archer Productions. 1951. “Duck and Cover.”&lt;/item&gt;
      &lt;item&gt;“Biosphere 2.” 2003. Dictionary of American History. Farmington Hills, MI: The Gale Group.&lt;/item&gt;
      &lt;item&gt;Braidotti, Rosi. 2012. The Posthuman. Oxford: Polity Press.&lt;/item&gt;
      &lt;item&gt;The Daily Beast. 2016. “RNC Speaker Peter Thiel: Let’s Go to Mars.” The Daily Beast Cheat Sheet (Jul 22).&lt;/item&gt;
      &lt;item&gt;Dells Travel. 2014. “Retro Attractions: Xanadu—Foam House of Tomorrow.” 2014. Dells.com (Sep 4).&lt;/item&gt;
      &lt;item&gt;FOXBusiness. 2019. “President Trump Says these ‘Rich Guys’ Are ‘Paying a Lot of Rent’ to Launch Rockets.” FOXBusiness (Aug 15).&lt;/item&gt;
      &lt;item&gt;Genzlinger, Neil. 2012. “Doomsday Has Its Day in the Sun.” The New York Times (Mar 11).&lt;/item&gt;
      &lt;item&gt;Gimlet Media. 2018. The Habitat: Life on Mars. Sort Of. Podcast series.&lt;/item&gt;
      &lt;item&gt;Greenwald, Glenn. 2013. “Inside the Mind of NSA Chief Gen Keith Alexander.” The Guardian (Sep 15).&lt;/item&gt;
      &lt;item&gt;Hersher, Rebecca. 2016. “‘Mars Mission’ Crew Emerges From Yearlong Simulation in Hawai’i.” The Two-Way (Aug 29).&lt;/item&gt;
      &lt;item&gt;HI-SEAS. nd. “Hawaii Space Exploration Analog and Simulation.”&lt;/item&gt;
      &lt;item&gt;III% Security Force. nd. “III% Security Force Intel.”&lt;/item&gt;
      &lt;item&gt;Ingraham, Christopher. 2016. “Just Three Percent of Adults Own Half of America’s Guns.” Washington Post (Sep 19).&lt;/item&gt;
      &lt;item&gt;Jardin, Xeni. 2016. “Before Breitbart, Before Trump, Bannon Bullied People in Biosphere 2.” Boing Boing (Aug 26).&lt;/item&gt;
      &lt;item&gt;Koenigs, Michael. 2017. “What the ‘Most Armed Man in America’ Has to Say about Mass Shootings.” ABC News (Nov 9).&lt;/item&gt;
      &lt;item&gt;LaHaye, Tim, and Jerry B. Jenkins. 1995. Left Behind: A Novel of the Earth’s Last Days. Carol Stream, IL: Tyndale House Publishers.&lt;/item&gt;
      &lt;item&gt;Land, Nick. 2017. Fanged Noumena: Collected Writings 1987-2007. Fourth edition. Falmouth and New York, NY: Urbanomic/Sequence Press.&lt;/item&gt;
      &lt;item&gt;Lelchuk, Ilene. 2006. “‘Convert or Die’ Game Divides Christians / Some Ask Wal-Mart to Drop Left Behind.” SFGate (Dec 12).&lt;/item&gt;
      &lt;item&gt;Mackay, Robin. 2012. “Nick Land—An Experiment in Inhumanism.” Umělec Magazine 1.&lt;/item&gt;
      &lt;item&gt;McAlister, Melani. 2003. “Prophecy, Politics, and the Popular: The Left Behind Series and Christian Fundamentalism’s New World Order.” The South Atlantic Quarterly 102:4 (Fall). 773–798.&lt;/item&gt;
      &lt;item&gt;Medina, Eden. 2006. “Designing Freedom, Regulating a Nation: Socialist Cybernetics in Allende’s Chile.” Journal of Latin American Studies 38:3. 571–606.&lt;/item&gt;
      &lt;item&gt;Medina, Eden. 2011. Cybernetic Revolutionaries: Technology and Politics in Allende’s Chile. Cambridge, MA: The MIT Press.&lt;/item&gt;
      &lt;item&gt;Moore, Jason W. 2014. “The Origins of Cheap Nature: From Use-Value to Abstract Social Nature.” Author’s blog (Apr 7).&lt;/item&gt;
      &lt;item&gt;Murphy, Tim. 2016. “Trump’s Campaign CEO Ran a Secretive Sci-Fi Project in the Arizona Desert.” Mother Jones (Aug 26).&lt;/item&gt;
      &lt;item&gt;Musk, Elon. 2018. “I hope the kids are ok.” Twitter (Jun 19).&lt;/item&gt;
      &lt;item&gt;National Geographic Channel. 2014. “Doomsday Preppers Season Four to Premiere Thursday, July 24 on National Geographic Channel.” Press release via TV By the Numbers (Jun 26).&lt;/item&gt;
      &lt;item&gt;Noys, Benjamin. 2014. Malign Velocities: Accelerationism and Capitalism. Alresford, Hants, England: Zero Books.&lt;/item&gt;
      &lt;item&gt;Papacharissi, Zizi and Andrew L. Mendelson. 2007. “An Exploratory Study of Reality Appeal: Uses and Gratifications of Reality TV Shows.” Journal of Broadcasting &amp;amp; Electronic Media 51:2. 355–370.&lt;/item&gt;
      &lt;item&gt;Plunkett, Luke. 2011. “The Real Story Behind Sim City’s Arcologies.” Kotaku (Jul 12).&lt;/item&gt;
      &lt;item&gt;Reiss, Steven and James Wiltz. 2004. “Why People Watch Reality TV.” Media Psychology 6:4. 363–378.&lt;/item&gt;
      &lt;item&gt;Rowen, Ben. 2017. “A Resort for the Apocalypse.” The Atlantic (Mar).&lt;/item&gt;
      &lt;item&gt;Shukaitis, Stevphen. 2009. “Space Is the (Non)Place: Martians, Marxists, and the Outer Space of the Radical Imagination.” The Sociological Review 57:1 (May). 98–113.&lt;/item&gt;
      &lt;item&gt;Stangel, Luke. 2017. “Google and Facebook Are Building the Ultimate Perk: Housing.” CXO Magazine (Nov 14).&lt;/item&gt;
      &lt;item&gt;Stengers, Isabelle. 2015. In Catastrophic Times: Resisting the Coming Barbarism. London: Open Humanities Press.&lt;/item&gt;
      &lt;item&gt;Thompson, Derek. 2018. “The Most Expensive Comment in Internet History?” The Atlantic (Feb 23).&lt;/item&gt;
      &lt;item&gt;Turner, Christopher. 2011. “Ingestion: Planet in a Bottle.” Cabinet 41 (Spring).&lt;/item&gt;
      &lt;item&gt;Turner, Fred. 2010. From Counterculture to Cyberculture: Stewart Brand, the Whole Earth Network, and the Rise of Digital Utopianism. Chicago: University of Chicago Press.&lt;/item&gt;
      &lt;item&gt;VICE. 2017. “Inside America’s Largest Right Wing Militia.” Hysteria (Oct 18).&lt;/item&gt;
      &lt;item&gt;Wark, McKenzie. 2015. “Barbarism or Barbarism?” Public Seminar (Dec 28).&lt;/item&gt;
      &lt;item&gt;Williams, Alex. 2013. “Escape Velocities.” e-flux 46 (Jun).&lt;/item&gt;
      &lt;item&gt;Zucchino, David. 2016. “A Militia Gets Battle Ready for a ‘Gun-Grabbing’ Clinton Presidency.” The New York Times (Nov 4).&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.boundary2.org/2019/08/sarah-t-roberts-and-mel-hogan-left-behind-futurist-fetishists-prepping-and-the-abandonment-of-earth/"/><published>2025-12-29T19:12:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424233</id><title>The Future of Software Development Is Software Developers</title><updated>2025-12-29T21:37:21.218799+00:00</updated><content>&lt;doc fingerprint="3a4391bbd1b90a1f"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been a computer programmer all-told for 43 years. That’s more than half the entire history of electronic programmable computers.&lt;/p&gt;
    &lt;p&gt;In that time, I’ve seen a lot of things change. But I’ve also seen some things stay pretty much exactly the same.&lt;/p&gt;
    &lt;p&gt;I’ve lived through several cycles of technology that, at the time, was hailed as the “end of computer programmers”.&lt;/p&gt;
    &lt;p&gt;WYSIWYG, drag-and-drop editors like Visual Basic and Delphi were going to end the need for programmers.&lt;/p&gt;
    &lt;p&gt;Wizards and macros in Microsoft Office were going to end the need for programmers.&lt;/p&gt;
    &lt;p&gt;Executable UML was going to end the need for programmers.&lt;/p&gt;
    &lt;p&gt;No-Code and Low-Code platforms were going to end the need for programmers.&lt;/p&gt;
    &lt;p&gt;And now, Large Language Models are, I read on a daily basis, going to end the need for programmers.&lt;/p&gt;
    &lt;p&gt;These cycles are nothing new. In the 1970s and 1980s, 4GLs and 5GLs were touted as the end of programmers.&lt;/p&gt;
    &lt;p&gt;And before them, 3GLs like Fortran and COBOL.&lt;/p&gt;
    &lt;p&gt;And before them, compilers like A-0 were going to end the need for programmers who instructed computers in binary by literally punching holes in cards.&lt;/p&gt;
    &lt;p&gt;But it goes back even further, if we consider the earliest (classified) beginning of electronic programmable computers. The first of them, COLOSSUS, was programmed by physically rewiring it.&lt;/p&gt;
    &lt;p&gt;Perhaps the engineers who worked on that machine sneered at the people working on the first stored-program computers for not being “real programmers”.&lt;/p&gt;
    &lt;p&gt;In every cycle, the predictions have turned out to be very, very wrong. The end result hasn’t been fewer programmers, but more programs and more programmers. It’s a $1.5 trillion-a-year example of Jevons Paradox.&lt;/p&gt;
    &lt;p&gt;And here we are again, in another cycle.&lt;/p&gt;
    &lt;p&gt;“But this time it’s different, Jason!”&lt;/p&gt;
    &lt;p&gt;Yes, it certainly is. Different in scale to previous cycles. I don’t recall seeing the claims about Visual Basic or Executable UML on the covers of national newspapers. I don’t recall seeing entire economies betting on 4GLs.&lt;/p&gt;
    &lt;p&gt;And there’s another important distinction: in previous cycles, the technology worked reliably. We really could produce working software faster with VB or with Microsoft Access. This is proving not to be the case with LLMs, which – for the majority of teams – actually slow them down while making the software less reliable and less maintainable. It’s a kind of LOSE-LOSE in most cases. (Unless those teams have addressed the real bottlenecks in their development process.)&lt;/p&gt;
    &lt;p&gt;But all of this is academic. Even if the technology genuinely made a positive difference for more teams, it still wouldn’t mean that we don’t need programmers anymore.&lt;/p&gt;
    &lt;p&gt;The hard part of computer programming isn’t expressing what we want the machine to do in code. The hard part is turning human thinking – with all its wooliness and ambiguity and contradictions – into computational thinking that is logically precise and unambiguous, and that can then be expressed formally in the syntax of a programming language.&lt;/p&gt;
    &lt;p&gt;That was the hard part when programmers were punching holes in cards. It was the hard part when they were typing COBOL code. It was the hard part when they were bringing Visual Basic GUIs to life (presumably to track the killer’s IP address). And it’s the hard part when they’re prompting language models to predict plausible-looking Python.&lt;/p&gt;
    &lt;p&gt;The hard part has always been – and likely will continue to be for many years to come – knowing exactly what to ask for.&lt;/p&gt;
    &lt;p&gt;Edgar Dijkstra called it nearly 50 years ago: we will never be programming in English, or French, or Spanish. Natural languages have not evolved to be precise enough and unambiguous enough. Semantic ambiguity and language entropy will always defeat this ambition.&lt;/p&gt;
    &lt;p&gt;And while pretty much anybody can learn to think that way, not everybody’s going to enjoy it, and not everybody’s going to be good at it. The demand for people who do and people who are will always outstrip supply.&lt;/p&gt;
    &lt;p&gt;Especially if businesses stop hiring and training them for a few years, like they recently have. But these boom-and-bust cycles have also been a regular feature during my career. This one just happens to coincide with a technology hype cycle that presents a convenient excuse.&lt;/p&gt;
    &lt;p&gt;There’s no credible evidence that “AI” is replacing software developers in significant numbers. A combination of over-hiring during the pandemic, rises in borrowing costs, and a data centre gold rush that’s diverting massive funds away from headcount, are doing the heavy lifting here.&lt;/p&gt;
    &lt;p&gt;And there’s no reason to believe that “AI” is going to evolve to the point where it can do what human programmers have to do – understand, reason and learn – anytime soon. AGI seem as far away as it’s always been, and the hard part of computer programming really does require general intelligence.&lt;/p&gt;
    &lt;p&gt;On top of all that, “AI” coding assistants are really nothing like the compilers and code generators of previous cycles. The exact same prompt is very unlikely to produce the exact same computer program. And the code that gets generated is pretty much guaranteed to have issues that a real programmer will need to be able to recognise and address.&lt;/p&gt;
    &lt;p&gt;When I write code, I’m executing it in my head. My internal model of a program isn’t just syntactic, like an LLM’s is. I’m not just matching patterns and predicting tokens to produce statistically plausible code. I actually understand the code.&lt;/p&gt;
    &lt;p&gt;Even the C-suite has noticed the correlation of major outages and incidents proceeding grand claims about how much of that company’s code is “AI”-generated.&lt;/p&gt;
    &lt;p&gt;The folly of many people now claiming that “prompts are the new source code”, and even that entire working systems can be regenerated from the original model inputs, will be revealed to be the nonsense that it is. The problem with getting into a debate with reality is that reality always wins. (And doesn’t even realise it’s in a debate.)&lt;/p&gt;
    &lt;p&gt;So, no, “AI” isn’t the end of programmers. I’m not even sure, 1-3 years from now, that this current mania won’t have just burned itself out, as the bean counters tot up the final scores. And they always win.&lt;/p&gt;
    &lt;p&gt;To folks who say this technology isn’t going anywhere, I would remind them of just how expensive these models are to build and what massive losses they’re incurring. Yes, you could carry on using your local instance of some small model distilled from a hyper-scale model trained today. But as the years roll by, you may find not being able to move on from the programming language and library versions it was trained on a tad constraining.&lt;/p&gt;
    &lt;p&gt;For this reason, I’m skeptical that hyper-scale LLMs have a viable long-term future. They are the Apollo Moon missions of “AI”. In the end, quite probably just not worth it. Maybe we’ll get to visit them in the museums their data centres might become?&lt;/p&gt;
    &lt;p&gt;The foreseeable future of software development is one where perhaps “AI” – in a much more modest form (e.g., a Java coding assistant built atop a basic language model) – is used to generate prototypes, and maybe for inline completion on production code and those sorts of minor things.&lt;/p&gt;
    &lt;p&gt;But, when it matters, there will be a software developer at the wheel. And, if Jevons is to be believed, probably even more of us.&lt;/p&gt;
    &lt;p&gt;Employers, if I were you, I might start hiring now to beat the stampede when everyone wakes up from this fever dream.&lt;/p&gt;
    &lt;p&gt;And then maybe drop me a line if you’re interested in skilling them up in the technical practices that can dramatically shrink delivery lead times while improving reliability and reducing the cost of change, with or without “AI”. That’s a WIN-WIN-WIN.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/"/><published>2025-12-29T19:14:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424262</id><title>All Delisted Steam Games</title><updated>2025-12-29T21:37:20.441809+00:00</updated><content>&lt;doc fingerprint="1f3d89cc94de127a"&gt;
  &lt;main&gt;
    &lt;p&gt;This page gives you direct access to all 1,038 delisted Steam titles on the site. Below each title are the companies it relates to. An * in the title denotes a placeholder page that contains basic details.&lt;/p&gt;
    &lt;p&gt;A&lt;/p&gt;
    &lt;p&gt;B&lt;/p&gt;
    &lt;p&gt;C&lt;/p&gt;
    &lt;p&gt;D&lt;/p&gt;
    &lt;p&gt;E&lt;/p&gt;
    &lt;p&gt;F&lt;/p&gt;
    &lt;p&gt;G&lt;/p&gt;
    &lt;p&gt;H&lt;/p&gt;
    &lt;p&gt;I&lt;/p&gt;
    &lt;p&gt;J&lt;/p&gt;
    &lt;p&gt;K&lt;/p&gt;
    &lt;p&gt;L&lt;/p&gt;
    &lt;p&gt;M&lt;/p&gt;
    &lt;p&gt;N&lt;/p&gt;
    &lt;p&gt;O&lt;/p&gt;
    &lt;p&gt;P&lt;/p&gt;
    &lt;p&gt;Q&lt;/p&gt;
    &lt;p&gt;R&lt;/p&gt;
    &lt;p&gt;S&lt;/p&gt;
    &lt;p&gt;T&lt;/p&gt;
    &lt;p&gt;U&lt;/p&gt;
    &lt;p&gt;V&lt;/p&gt;
    &lt;p&gt;W&lt;/p&gt;
    &lt;p&gt;Y&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://delistedgames.com/all-delisted-steam-games/"/><published>2025-12-29T19:16:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424733</id><title>Meta's ads tools started switching out top-performing ads with AI-generated ones</title><updated>2025-12-29T21:37:20.327604+00:00</updated><content>&lt;doc fingerprint="b5b592b8180daf1c"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Meta's generative AI ads system is having some … senior moments.&lt;/item&gt;
      &lt;item&gt;Advertisers have noticed the platform conjuring up bizarre ads, such as an AI granny.&lt;/item&gt;
      &lt;item&gt;The phenomenon has persisted even after brands switched off some AI-related settings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marketers are finding out the hard way that Meta's AI tools can churn out some very strange ads.&lt;/p&gt;
    &lt;p&gt;Meta CEO Mark Zuckerberg said earlier this year that the company's artificial intelligence had become so advanced that advertisers would no longer need to create their own ads. Brands could simply hand over their bank accounts and campaign objectives and let the AI take the wheel.&lt;/p&gt;
    &lt;p&gt;Some marketers, however, haven't been pleased with the results when they let Meta's AI drive their ad campaigns.&lt;/p&gt;
    &lt;p&gt;Bryan Cano, head of marketing of the "elevated basics" clothing brand True Classic, was aghast when he noticed Meta had switched out his top-performing ad — an attractive millennial man in a matching fleece set, casually posing on a stool — with an AI-generated photo of a cheerful yet unnatural granny sitting in an armchair. True Classic typically targets its Meta ads to men ages 30 to 45.&lt;/p&gt;
    &lt;p&gt;The ad ran on Meta for three days before customers alerted True Classic to it, Cano told Business Insider. He said that while the direction Meta is taking with AI makes sense, he felt the generative-ads tool wasn't yet ready for prime time.&lt;/p&gt;
    &lt;p&gt;"This doesn't just affect our relationship with customers, who were upset by this, but it could also damage relationships with wholesale customers and the relationships we have built with retailers," Cano said.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;How do we go from this… to AI grandma. pic.twitter.com/n3cryUpLaT&lt;/p&gt;— Bryan Cano (@BryanECano) October 24, 2025&lt;/quote&gt;
    &lt;p&gt;Tech companies, including Meta, Google, Amazon, and TikTok, have heralded AI as a way for advertisers to speed up ad creation and enhance the performance of their campaigns. However, many advertisers are wary of ceding too much control to black box systems, particularly since consumers often have an aversion to ads that are obviously generated by AI. The AI granny is a comical example of what can happen when algorithms go unchecked.&lt;/p&gt;
    &lt;p&gt;True Classic isn't the only brand to have a chaotic Meta ad experience recently, thanks to AI.&lt;/p&gt;
    &lt;p&gt;European footwear brand Kirruna noticed Meta's AI had whipped up an ad featuring a model whose leg had twisted around completely the wrong way.&lt;/p&gt;
    &lt;p&gt;Elsewhere, Meta generated an ad for the e-bike company Lectric, asking "What are the easiest eBikes to put in my trunk," which featured the trunk of a car. So far, so normal — except the car also appeared to be flying through clouds. Logan Young, Lectric's VP of digital marketing, said the company managed to catch the ad before it ran.&lt;/p&gt;
    &lt;p&gt;"We turn it all off, pretty much," Young said of Meta's AI-generated ad enhancements.&lt;/p&gt;
    &lt;p&gt;A Meta spokesperson said in a statement that millions of advertisers are finding value and improved performance by using its Advantage+ creative tools.&lt;/p&gt;
    &lt;p&gt;"Advertisers who use our full image generation feature have the opportunity to review the generated images before running their ad. We are continuously improving our products and features based on advertiser feedback," the Meta spokesperson said.&lt;/p&gt;
    &lt;p&gt;Cano of True Classic said the AI granny ad hadn't surfaced as one of the selected ads in its campaign preview, which is why the brand was caught off guard.&lt;/p&gt;
    &lt;head rend="h2"&gt;Surreptitious settings&lt;/head&gt;
    &lt;p&gt;So, what's going on here?&lt;/p&gt;
    &lt;p&gt;Advertisers told Business Insider that the cause of the uncanny valley Meta ads seemed to be two tickbox settings within their accounts — "test new creative features" and "automatic adjustments" — and another group of "Advantage+ creative" settings in the area where advertisers build their campaigns. Advantage+ is the brand name for Meta's suite of AI-powered ad products.&lt;/p&gt;
    &lt;p&gt;Three advertisers also said they'd encountered a problem where Meta automatically switched those toggles to "on," even when they'd explicitly turned them off — meaning they inadvertently spent their budgets on AI-generated ads they didn't intend to run.&lt;/p&gt;
    &lt;p&gt;Rok Hladnik, CEO of the marketing agency Flat Circle, which manages around $100 million in annual Meta ad spending for numerous direct-to-consumer brands, said he has encountered similar issues with Meta auto-generating bizarre ads. His company is now setting aside time two to three mornings a week to manually check that AI enhancements are switched off. The task takes up to an hour per account, he said.&lt;/p&gt;
    &lt;p&gt;"It randomly turns on, even for ads you've turned off for a second time," Hladnik said. "It's a complete mess."&lt;/p&gt;
    &lt;p&gt;Jonas Vonk, founder of the e-commerce business Yuzu Knives, said he became so frustrated by how toggles like the AI-creative feature can be hidden within Meta's settings that he created his own startup, AdsFlow, which helps surface them more clearly for ad buyers.&lt;/p&gt;
    &lt;p&gt;"You really have to dig for them, and switch them all off every time you run an ad," Vonk said of Meta's ad settings.&lt;/p&gt;
    &lt;p&gt;Pieter Van der Auwera, a marketing consultant who runs Meta ads for the Kirruna shoe brand, said the company has had to issue two refunds to customers who complained that the items they received weren't made of the material depicted in ads generated by Meta's AI. (Remarkably, the ad featuring the model with the backward leg did a good job of replicating the real boot, he added.)&lt;/p&gt;
    &lt;p&gt;Van der Auwera said an issue with AI-generated ads is that while Meta provides a preview of ads prelaunch, they need to be opened one by one to check, which can be a time suck when brands run hundreds of different versions.&lt;/p&gt;
    &lt;p&gt;"When I first heard about Meta AI, I was really hopeful and thought it would take away a lot of my work and make my work a lot faster so that I can do more for my clients," Van der Auwera said. "Now, I have more work than before."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.businessinsider.com/meta-ai-generating-bizarre-ads-advantage-plus-2025-10"/><published>2025-12-29T19:51:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424782</id><title>Which Humans?</title><updated>2025-12-29T21:37:20.018815+00:00</updated><link href="https://osf.io/preprints/psyarxiv/5b26t_v1"/><published>2025-12-29T19:57:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424892</id><title>Binance's Trust Wallet extension hacked; users lose $7M</title><updated>2025-12-29T21:37:19.601080+00:00</updated><content>&lt;doc fingerprint="a9b21af80962e137"&gt;
  &lt;main&gt;
    &lt;p&gt;Binance founder Changpeng Zhao — who supposedly has no managerial role at Binance after he and the company were criminally charged in the US — announced that Binance would reimburse users who lost funds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Binance's Trust Wallet extension hacked; users lose $7 million&lt;/head&gt;
    &lt;head rend="h2"&gt;Crypto trader loses $50 million to address poisoning attack&lt;/head&gt;
    &lt;p&gt;After the theft, the victim sent an on-chain message to the scammer, offering a $1 million "bounty" for the return of the remaining funds. They threatened, "We have officially filed a criminal case. With the assistance of law enforcement, cybersecurity agencies, and multiple blockchain protocols, we have already gathered substantial and actionable intelligence regarding your activities." However, there's been no activity from the wallet since the message, and the thief had long since begun laundering the funds via Tornado Cash.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Thief wallet, Etherscan [archive]&lt;/item&gt;
      &lt;item&gt;On-chain message, Etherscan&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Yearn Finance suffers fourth exploit only weeks after third&lt;/head&gt;
    &lt;p&gt;This is Yearn's fourth hack, following the $6.6 million theft in November, an $11 million exploit in 2023, and an $11 million exploit in 2021. Yearn also lost around $1.4 million in 2023 in connection to the Euler Finance attack.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ribbon Finance suffers $2.7 million exploit, plans to use "dormant" users' funds to repay active users&lt;/head&gt;
    &lt;p&gt;Ribbon has announced it will cover $400,000 of the lost funds with its own assets. However, Ribbon is also offering users a lower-than-expected haircut on their assets by assuming that some of the largest affected accounts will not withdraw their assets, having been dormant for several years. While this plan may benefit active users, it seems like it could get very messy if those dormant users do wish to withdraw their assets and discover they've been used to pay others.&lt;/p&gt;
    &lt;head rend="h2"&gt;Binance employee suspended after launching a token and promoting it with company accounts&lt;/head&gt;
    &lt;p&gt;Binance publicly acknowledged that an employee had been suspended for misconduct over the incident. "These actions constitute abuse of their position for personal gain and violate our policies and code of professional conduct," Binance tweeted from its BinanceFutures account. After this announcement, the memecoin token price spiked even further.&lt;/p&gt;
    &lt;p&gt;Earlier this year, Binance fired another employee after discovering they had used inside information to profit from a token sale event.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prysm consensus client bug causes Ethereum validators to lose over $1 million&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Fusaka Mainnet Prysm Incident", Prysm&lt;/item&gt;
      &lt;item&gt;Client Distribution, Clientdiversity.org&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Yearn Finance hacked for the third time&lt;/head&gt;
    &lt;p&gt;$2.4 million of the stolen assets, which were denominated in pxETH, a liquid staking token issued by Redacted Cartel, were recovered after the issuer burned the stolen tokens and reissued them to the team's wallet — essentially, removing the tokens from the hacker's wallet. However, the hacker routed the remaining funds through the Tornado Cash cryptocurrency mixer, which makes recovery substantially more challenging.&lt;/p&gt;
    &lt;p&gt;This is the third time Yearn Finance has been hacked, following an $11 million exploit in 2023 and another $11 million exploit in 2021. Yearn also suffered around $1.4 million in losses in 2023 in connection to the Euler Finance attack.&lt;/p&gt;
    &lt;head rend="h2"&gt;Upbit hacked for $30 million&lt;/head&gt;
    &lt;p&gt;Upbit reimbursed users who had lost funds from company reserves. The exchange was able to freeze around $1.77 million of the stolen assets.&lt;/p&gt;
    &lt;p&gt;This theft occurred exactly six years after Upbit suffered a theft of 342,000 ETH (priced at around $50 million at the time).&lt;/p&gt;
    &lt;head rend="h2"&gt;Aerodrome and Velodrome suffer website takeovers, again&lt;/head&gt;
    &lt;p&gt;This is the second time such an attack has happened to these same platforms, with another DNS hijacking incident occurring almost exactly two years ago. In that instance, users lost around $100,000 when submitting transactions via the scam websites.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cardano founder calls the FBI on a user who says his AI mistake caused a chainsplit&lt;/head&gt;
    &lt;p&gt;Charles Hoskinson, the founder of Cardano, responded with a tweet boasting about how quickly the chain recovered from the catastrophic split, then accused the person of acting maliciously. "It was absolutely personal", Hoskinson wrote, adding that the person's public version of events was merely him "trying to walk it back because he knows the FBI is already involved". Hoskinson added, "There was a premeditated attack from a disgruntled [single pool operator] who spent months in the Fake Fred discord actively looking at ways to harm the brand and reputation of IOG. He targeted my personal pool and it resulted in disruption of the entire cardano network."&lt;/p&gt;
    &lt;p&gt;Hoskinson's decision to involve the FBI horrified some onlookers, including one other engineer at the company who publicly quit after the incident. They wrote, "I've fucked up pen testing in a major way once. I've seen my colleagues do the same. I didn't realize there was a risk of getting raided by the authorities because of that + saying mean things on the Internet."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.web3isgoinggreat.com/?id=trust-wallet-hack"/><published>2025-12-29T20:04:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46425198</id><title>Google is dead. Where do we go now?</title><updated>2025-12-29T21:37:19.527661+00:00</updated><content/><link href="https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/"/><published>2025-12-29T20:29:26+00:00</published></entry></feed>