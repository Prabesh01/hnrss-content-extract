<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-07T16:16:38.276717+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46518804</id><title>Oral microbiome sequencing after taking probiotics</title><updated>2026-01-07T16:16:44.899885+00:00</updated><content>&lt;doc fingerprint="8a7c03af02b6652a"&gt;
  &lt;main&gt;
    &lt;p&gt;Recently, a friend recommended BioGaia Prodentis to me. It is a DTC oral probiotic you can buy online that is supposedly good for oral health. I thought it would be interesting to do some sequencing to see what, if anything, it did to my oral microbiome.&lt;/p&gt;
    &lt;p&gt;BioGaia Prodentis is available online for $20 or less for a month's supply&lt;/p&gt;
    &lt;head rend="h1"&gt;BioGaia&lt;/head&gt;
    &lt;p&gt;BioGaia has a fascinating story. They are a Swedish company, founded over 30 years ago, that exclusively sells probiotics DTC. They have developed multiple strains of Limosilactobacillus reuteri, mainly for gut and oral health. They apparently sell well! Their market cap is around $1Bâ€”impressive for a consumer biotech.&lt;/p&gt;
    &lt;p&gt;Going in, I expected scant evidence for any real benefits to their probiotics, but the data (over 250 clinical studies) is much more complete than I expected.&lt;/p&gt;
    &lt;p&gt;Most notably, their gut probiotic, Protectis, seems to have a significant effect on preventing Necrotizing Enterocolitis (NEC) in premature babies. According to their website:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;5-10% of the smallest premature infants develop NEC, a potentially lethal disorder in which portions of the bowel undergo tissue death.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In March 2025, the FDA granted Breakthrough Therapy Designation to IBP-9414, an L. reuteri probiotic developed by BioGaia spinout IBT.&lt;/p&gt;
    &lt;p&gt;This is not specifically for the oral health product, but it's for sure more science than I expected to see going in.&lt;/p&gt;
    &lt;head rend="h3"&gt;Prodentis&lt;/head&gt;
    &lt;p&gt;BioGaia Prodentis contains two strains of L. reuteri: DSM 17938 and ATCC PTA 5289. The claimed benefits include fresher breath, healthier gums, and outcompeting harmful bacteria.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sequencing with Plasmidsaurus&lt;/head&gt;
    &lt;p&gt;Many readers will be familiar with Plasmidsaurus. Founded in 2021, the team took a relatively simple idea: use massively multiplexed Oxford Nanopore (ONT) to offer complete plasmid sequencing with one day turnaround for $15, and scaled it. Plasmidsaurus quickly became part of biotech's core infrastructure, and spread like wildfire. It also inspired multiple copycats.&lt;/p&gt;
    &lt;p&gt;Compared to Illumina, ONT is faster and has much longer reads, but lower throughput and lower accuracy. This profile is a great fit to many sequencing problems like plasmid QC, where you only need megabases of sequences, but want an answer within 24 hours.&lt;/p&gt;
    &lt;p&gt;Over time, Plasmidsaurus has been adding services, including genome sequencing, RNA-Seq, and microbiome sequencing, all based on ONT sequencing.&lt;/p&gt;
    &lt;p&gt;Plasmidsaurus accepts many kinds of sample for microbiome sequencing&lt;/p&gt;
    &lt;p&gt;I used their 16S sequencing product, which costs $45 for ~5000 reads, plus $15 for DNA extraction. 16S sequencing is an efficient way to amplify and sequence a small amount of DNA (the ubiquitous 16S region) and be able to assign reads to specific species or even strains.&lt;/p&gt;
    &lt;p&gt;This experiment cost me $240 for four samples, and I got data back in around a week. It's very convenient that I no longer have to do my own sequencing. As a side note, you can pay more for more than 5000 reads, but unless you want information on very rare strains (&amp;lt;&amp;lt;1% frequency), this is a waste of money.&lt;/p&gt;
    &lt;p&gt;Sample collection is simple: take 100-250 ÂµL of saliva and mix with 500 ÂµL of Zymo DNA/RNA Shield (which I also had to buy for around $70.) You also need 2 mL screwtop tubes to ship in.&lt;/p&gt;
    &lt;p&gt;The reads are high quality for nanopore sequencing, with a median Q score of 23 (99%+ accuracy). This is more than sufficient accuracy for this experiment. The read length is very tightly distributed around 1500 nt (the length of a typical 16S region).&lt;/p&gt;
    &lt;p&gt;The results provided by Plasmidsaurus include taxonomy tables, per-read assignments, and some basic plots. I include a download of the results at the end of this article, as well as the FASTQ files.&lt;/p&gt;
    &lt;head rend="h1"&gt;The experiment&lt;/head&gt;
    &lt;p&gt;The main idea of the experiment was to see if any L. reuteri would colonize by the end of 30 days of probiotic use, and if so, whether it would persist beyond that. I collected four saliva samples:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;Timing&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;Day -4&lt;/cell&gt;
        &lt;cell&gt;A few days before starting BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;Day -1&lt;/cell&gt;
        &lt;cell&gt;The day before I started BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;The last day of the 30 day course&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;Day 37&lt;/cell&gt;
        &lt;cell&gt;One week after completing the course&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Heatmap of the top 20 species. All species assignments were done by Plasmidsaurus&lt;/p&gt;
    &lt;head rend="h2"&gt;Did L. reuteri colonize?&lt;/head&gt;
    &lt;p&gt;There was no L. reuteri found in any of the samples. I did a manual analysis to check for any possible misassignments, but the closest read was only 91% identical to either L. reuteri strain.&lt;/p&gt;
    &lt;p&gt;The probiotic either (a) didn't colonize the oral cavity; (b) was present only transiently while actively taking the lozenges; (c) was below the detection threshold.&lt;/p&gt;
    &lt;p&gt;Probiotics are generally bad at colonizing, which is why you have to keep taking them. Still, I was surprised not to see a single L. reuteri read in there.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actually changed?&lt;/head&gt;
    &lt;p&gt;Even though the probiotic itself didn't show up, the oral microbiome did change quite a lot.&lt;/p&gt;
    &lt;p&gt;The most striking change was a massive increase in S. salivarius. S. salivarius went from essentially absent to ~20% of my oral microbiome on the last day. However, this happened one week after I stopped taking the probiotic, so it's very unclear if it is related.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;S. mitis&lt;/cell&gt;
        &lt;cell role="head"&gt;S. salivarius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;2.0%&lt;/cell&gt;
        &lt;cell&gt;0.4%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;15.9%&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;10.2%&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;1.0%&lt;/cell&gt;
        &lt;cell&gt;19.3%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We see S. mitis decreasing as S. salivarius increases, while the total Streptococcus fraction stayed roughly stable. It's possible one species replaced the other within the same ecological niche.&lt;/p&gt;
    &lt;p&gt;S. salivarius is itself a probiotic species. The strain BLIS K12 was isolated from a healthy New Zealand child and is sold commercially for oral health. It produces bacteriocins that kill Streptococcus pyogenes (strep throat bacteria).&lt;/p&gt;
    &lt;p&gt;At the same time, V. tobetsuensis increased in abundance from 2.1% to 5.7%. Veillonella bacteria can't eat sugar directlyâ€”they survive by consuming lactate that Streptococcus produces. The S. salivarius bloom is plausibly feeding them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Are these changes real or intra-day variation?&lt;/head&gt;
    &lt;p&gt;There was a lot more variation in species than I expected, especially comparing the two baseline samples. In retrospect, I should have taken multiple samples on the same day, and mixed them to smooth it out.&lt;/p&gt;
    &lt;p&gt;However, there is some light evidence that the variation I see is not just intra-day variation. Specifically, there are several species that stay consistent in frequency across all samples: e.g., Neisseria subflava, Streptococcus viridans, Streptococcus oralis.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;L. reuteri didn't detectably colonize my mouth. Oral probiotics are surprisingly difficult to detect, even if you sample the same day as dosing.&lt;/item&gt;
      &lt;item&gt;S. salivarius increased massively in abundance, but this increase happened after I stopped taking BioGaia&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing can be used to assess oral health. None of the "red complex" bacteria (P. gingivalis, T. forsythia, T. denticola) associated with gum disease were found in any sample.&lt;/item&gt;
      &lt;item&gt;The oral microbiome is dynamic, with huge swings in species abundance over a timeframe of just weeks&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing is very easy and convenient these days thanks to Plasmidsaurus&lt;/item&gt;
      &lt;item&gt;Prodentis tastes good, may help with oral health, and I'd consider taking it again&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.booleanbiotech.com/oral-microbiome-biogaia"/><published>2026-01-06T21:10:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46519303</id><title>Laylo (YC S20) â€“ Head of Growth (Organic and Partners and Loops and AI) â€“ Remote US</title><updated>2026-01-07T16:16:43.939726+00:00</updated><content>&lt;doc fingerprint="b1dc8874f8cd840c"&gt;
  &lt;main&gt;
    &lt;p&gt;The CRM powering iconic musicians and events&lt;/p&gt;
    &lt;p&gt;Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.&lt;/p&gt;
    &lt;p&gt;Role Overview&lt;/p&gt;
    &lt;p&gt;Weâ€™re looking for a Head of Growth (player/coach) to build and run Layloâ€™s growth engine. A 0â†’1 builder who doesnâ€™t just ideate, but ships. Youâ€™ll create great content, run scrappy experiments, and build product growth loops that compound. This is a hands-on role: youâ€™ll set strategy, execute a rapid experiment cadence, measure results, and turn wins into repeatable playbooks.&lt;/p&gt;
    &lt;p&gt;Youâ€™ll focus primarily on non-advertising channels: organic social, influencer/creator collaborations, channel partners, and product growth loops. We value strong taste, speed, and a rigorous learning cadence.&lt;/p&gt;
    &lt;p&gt;Youâ€™ll report directly to the CEO and work closely with Product, Engineering, Design, Partnerships, and Sales. Youâ€™re likely a good fit if youâ€™re excited to open Adobe/Figma/Notion/PostHog and ship something today.&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;p&gt;Youâ€™ll thrive here if you can:&lt;/p&gt;
    &lt;p&gt;Key Responsibilities:&lt;/p&gt;
    &lt;p&gt;What Success Looks Like:&lt;/p&gt;
    &lt;p&gt;What You Bring:&lt;/p&gt;
    &lt;p&gt;How To Apply:&lt;/p&gt;
    &lt;p&gt;Send us your first out-of-the-box idea for your first campaign in this role. Bonus points for mentioning other companies and campaigns you think are relevant.&lt;/p&gt;
    &lt;p&gt;Our founders met while building competing consumer startups. We launched multiple products across consumer and SaaS and talked to thousands of fans and creators in the process. In 2020, we realized one of the biggest pain points artists and events face is actually driving their audience from socials into their own CRM.&lt;/p&gt;
    &lt;p&gt;In 2020, we joined Y Combinatorâ€™s summer batch and began building a product that quickly gained strong early traction. We raised from top-tier investors like Eldridge and Sony and have since grown into a team of 24 exceptional individuals spanning product, sales, and operations.&lt;/p&gt;
    &lt;p&gt;We have a strong written documentation culture. We try to do as much as possible asynchronously to move quickly and efficiently. We have a daily 30 minute standup and team-specific meetings throughout the week.&lt;/p&gt;
    &lt;p&gt;Creators and Brands have a few key moments that drive the majority of their sales and fan engagement, we call them drops. At Laylo, we're building the Drop CRM to make these moments perfect.&lt;/p&gt;
    &lt;p&gt;With Laylo, creators and brands can notify fans the second they drop new content, merch and events. From there, they get a full featured CRM, a dashboard to connect with fans forever in the future, high conversion landing pages and deep analytics to conversions, click throughs and sales.&lt;/p&gt;
    &lt;p&gt;We work with some of biggest creators, brands, records labels and managers in the world to create incredible drop experiences.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/laylo/jobs/ZtLHRXe-head-of-growth"/><published>2026-01-06T21:44:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46520926</id><title>Show HN: SMTP Tunnel â€“ A SOCKS5 proxy disguised as email traffic to bypass DPI</title><updated>2026-01-07T16:16:43.819853+00:00</updated><content>&lt;doc fingerprint="8cf1e0524c113892"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;A high-speed covert tunnel that disguises TCP traffic as SMTP email communication to bypass Deep Packet Inspection (DPI) firewalls.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚â”€â”€â”€â”€â”€â–¶â”‚   Client    â”‚â”€â”€â”€â”€â”€â–¶â”‚   Server    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Internet    â”‚
â”‚  (Browser)  â”‚ TCP  â”‚ SOCKS5:1080 â”‚ SMTP â”‚  Port 587   â”‚ TCP  â”‚              â”‚
â”‚             â”‚â—€â”€â”€â”€â”€â”€â”‚             â”‚â—€â”€â”€â”€â”€â”€â”‚             â”‚â—€â”€â”€â”€â”€â”€â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                    â”‚
                            â”‚   Looks like       â”‚
                            â”‚   Email Traffic    â”‚
                            â–¼                    â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚     DPI Firewall               â”‚
                     â”‚  âœ… Sees: Normal SMTP Session  â”‚
                     â”‚  âŒ Cannot see: Tunnel Data    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ”’ TLS Encryption&lt;/cell&gt;
        &lt;cell&gt;All traffic encrypted with TLS 1.2+ after STARTTLS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ­ DPI Evasion&lt;/cell&gt;
        &lt;cell&gt;Initial handshake mimics real SMTP servers (Postfix)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;âš¡ High Speed&lt;/cell&gt;
        &lt;cell&gt;Binary streaming protocol after handshake - minimal overhead&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ‘¥ Multi-User&lt;/cell&gt;
        &lt;cell&gt;Per-user secrets, IP whitelists, and logging settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ”‘ Authentication&lt;/cell&gt;
        &lt;cell&gt;Per-user pre-shared keys with HMAC-SHA256&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸŒ SOCKS5 Proxy&lt;/cell&gt;
        &lt;cell&gt;Standard proxy interface - works with any application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ“¡ Multiplexing&lt;/cell&gt;
        &lt;cell&gt;Multiple connections over single tunnel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ›¡ï¸ IP Whitelist&lt;/cell&gt;
        &lt;cell&gt;Per-user access control by IP address/CIDR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ“¦ Easy Install&lt;/cell&gt;
        &lt;cell&gt;One-liner server installation with systemd service&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ Client Packages&lt;/cell&gt;
        &lt;cell&gt;Auto-generated ZIP files for each user&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ğŸ”„ Auto-Reconnect&lt;/cell&gt;
        &lt;cell&gt;Client automatically reconnects on connection loss&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;ğŸ“š For in-depth technical details, protocol specifications, and security analysis, see TECHNICAL.md.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Server: Linux VPS with Python 3.8+, port 587 open&lt;/item&gt;
      &lt;item&gt;Client: Windows/macOS/Linux with Python 3.8+&lt;/item&gt;
      &lt;item&gt;Domain name: Required for TLS certificate verification (free options: DuckDNS, No-IP, FreeDNS)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get a free domain pointing to your VPS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ¦† DuckDNS - Recommended, simple and free&lt;/item&gt;
      &lt;item&gt;ğŸŒ No-IP - Free tier available&lt;/item&gt;
      &lt;item&gt;ğŸ†“ FreeDNS - Many domain options&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: &lt;code&gt;myserver.duckdns.org&lt;/code&gt; â†’ &lt;code&gt;203.0.113.50&lt;/code&gt; (your VPS IP)&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/x011/smtp-tunnel-proxy/main/install.sh | sudo bash&lt;/code&gt;
    &lt;p&gt;The installer will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;ğŸ“¥ Download and install everything&lt;/item&gt;
      &lt;item&gt;â“ Ask for your domain name&lt;/item&gt;
      &lt;item&gt;ğŸ” Generate TLS certificates automatically&lt;/item&gt;
      &lt;item&gt;ğŸ‘¤ Offer to create your first user&lt;/item&gt;
      &lt;item&gt;ğŸ”¥ Configure firewall&lt;/item&gt;
      &lt;item&gt;ğŸš€ Start the service&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's it! Your server is ready.&lt;/p&gt;
    &lt;code&gt;smtp-tunnel-adduser bob      # Add user + generate client ZIP
smtp-tunnel-listusers        # List all users
smtp-tunnel-deluser bob      # Remove a user&lt;/code&gt;
    &lt;code&gt;smtp-tunnel-update           # Updates code, preserves config/certs/users&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get your &lt;code&gt;username.zip&lt;/code&gt;file from the server admin&lt;/item&gt;
      &lt;item&gt;Extract the ZIP file&lt;/item&gt;
      &lt;item&gt;Run the launcher:&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;How to Run&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸªŸ Windows&lt;/cell&gt;
        &lt;cell&gt;Double-click &lt;code&gt;start.bat&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ğŸ§ Linux&lt;/cell&gt;
        &lt;cell&gt;Run &lt;code&gt;./start.sh&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ğŸ macOS&lt;/cell&gt;
        &lt;cell&gt;Run &lt;code&gt;./start.sh&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The launcher will automatically install dependencies and start the client.&lt;/p&gt;
    &lt;p&gt;âœ… You should see:&lt;/p&gt;
    &lt;code&gt;SMTP Tunnel Proxy Client
User: alice

[INFO] Starting SMTP Tunnel...
[INFO] SOCKS5 proxy will be available at 127.0.0.1:1080

Connecting to myserver.duckdns.org:587
Connected - binary mode active
SOCKS5 proxy on 127.0.0.1:1080
&lt;/code&gt;
    &lt;code&gt;cd alice
pip install -r requirements.txt
python client.py&lt;/code&gt;
    &lt;code&gt;# Download files
scp root@myserver.duckdns.org:/etc/smtp-tunnel/ca.crt .

# Create config.yaml:
cat &amp;gt; config.yaml &amp;lt;&amp;lt; EOF
client:
  server_host: "myserver.duckdns.org"
  server_port: 587
  socks_port: 1080
  username: "alice"
  secret: "your-secret-from-admin"
  ca_cert: "ca.crt"
EOF

# Run client
python client.py -c config.yaml&lt;/code&gt;
    &lt;p&gt;Set SOCKS5 proxy to: &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Settings â†’ Network Settings â†’ Settings&lt;/item&gt;
      &lt;item&gt;Manual proxy configuration&lt;/item&gt;
      &lt;item&gt;SOCKS Host: &lt;code&gt;127.0.0.1&lt;/code&gt;, Port:&lt;code&gt;1080&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Select SOCKS v5&lt;/item&gt;
      &lt;item&gt;âœ… Check "Proxy DNS when using SOCKS v5"&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install "Proxy SwitchyOmega" extension&lt;/item&gt;
      &lt;item&gt;Create profile with SOCKS5: &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Settings â†’ Network &amp;amp; Internet â†’ Proxy â†’ Manual setup â†’ &lt;code&gt;socks=127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;System Preferences â†’ Network â†’ Advanced â†’ Proxies â†’ SOCKS Proxy â†’ &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;export ALL_PROXY=socks5://127.0.0.1:1080&lt;/code&gt;
    &lt;code&gt;# curl
curl -x socks5h://127.0.0.1:1080 https://ifconfig.me

# git
git config --global http.proxy socks5://127.0.0.1:1080

# Environment variable
export ALL_PROXY=socks5://127.0.0.1:1080&lt;/code&gt;
    &lt;code&gt;# Should show your VPS IP
curl -x socks5://127.0.0.1:1080 https://ifconfig.me&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Listen interface&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.0.0.0&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Listen port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;587&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hostname&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;SMTP hostname (must match certificate)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;mail.example.com&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cert_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TLS certificate path&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;server.crt&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;key_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TLS private key path&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;server.key&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;users_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to users configuration&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;users.yaml&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;log_users&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Global logging setting&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;true&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Each user can have individual settings:&lt;/p&gt;
    &lt;code&gt;users:
  alice:
    secret: "auto-generated-secret"
    # whitelist:              # Optional: restrict to specific IPs
    #   - "192.168.1.100"
    #   - "10.0.0.0/8"        # CIDR notation supported
    # logging: true           # Optional: disable to stop logging this user

  bob:
    secret: "another-secret"
    whitelist:
      - "203.0.113.50"        # Bob can only connect from this IP
    logging: false            # Don't log Bob's activity&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;User's authentication secret&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;whitelist&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Allowed IPs for this user (CIDR supported)&lt;/cell&gt;
        &lt;cell&gt;All IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;logging&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable activity logging for this user&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;true&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;server_host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server domain name&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;server_port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;587&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;socks_port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Local SOCKS5 port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1080&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;socks_host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Local SOCKS5 interface&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;127.0.0.1&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;username&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Your username&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Your authentication secret&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ca_cert&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;CA certificate for verification&lt;/cell&gt;
        &lt;cell&gt;Recommended&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Check status
sudo systemctl status smtp-tunnel

# Restart after config changes
sudo systemctl restart smtp-tunnel

# View logs
sudo journalctl -u smtp-tunnel -n 100

# Uninstall
sudo /opt/smtp-tunnel/uninstall.sh&lt;/code&gt;
    &lt;code&gt;python server.py [-c CONFIG] [-d]

  -c, --config    Config file (default: config.yaml)
  -d, --debug     Enable debug logging&lt;/code&gt;
    &lt;code&gt;python client.py [-c CONFIG] [--server HOST] [--server-port PORT]
                 [-p SOCKS_PORT] [-u USERNAME] [-s SECRET] [--ca-cert FILE] [-d]

  -c, --config      Config file (default: config.yaml)
  --server          Override server domain
  --server-port     Override server port
  -p, --socks-port  Override local SOCKS port
  -u, --username    Your username
  -s, --secret      Override secret
  --ca-cert         CA certificate path
  -d, --debug       Enable debug logging&lt;/code&gt;
    &lt;code&gt;smtp-tunnel-adduser &amp;lt;username&amp;gt; [-u USERS_FILE] [-c CONFIG] [--no-zip]
    Add a new user and generate client package

smtp-tunnel-deluser &amp;lt;username&amp;gt; [-u USERS_FILE] [-f]
    Remove a user (use -f to skip confirmation)

smtp-tunnel-listusers [-u USERS_FILE] [-v]
    List all users (use -v for detailed info)

smtp-tunnel-update
    Update server to latest version (preserves config/certs/users)&lt;/code&gt;
    &lt;code&gt;smtp_proxy/
â”œâ”€â”€ ğŸ“„ server.py               # Server (runs on VPS)
â”œâ”€â”€ ğŸ“„ client.py               # Client (runs locally)
â”œâ”€â”€ ğŸ“„ common.py               # Shared utilities
â”œâ”€â”€ ğŸ“„ generate_certs.py       # Certificate generator
â”œâ”€â”€ ğŸ“„ config.yaml             # Server/client configuration
â”œâ”€â”€ ğŸ“„ users.yaml              # User database
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“„ install.sh              # One-liner server installer
â”œâ”€â”€ ğŸ“„ smtp-tunnel.service     # Systemd unit file
â”œâ”€â”€ ğŸ”§ smtp-tunnel-adduser     # Add user script
â”œâ”€â”€ ğŸ”§ smtp-tunnel-deluser     # Remove user script
â”œâ”€â”€ ğŸ”§ smtp-tunnel-listusers   # List users script
â”œâ”€â”€ ğŸ”§ smtp-tunnel-update      # Update server script
â”œâ”€â”€ ğŸ“„ README.md               # This file
â””â”€â”€ ğŸ“„ TECHNICAL.md            # Technical documentation
&lt;/code&gt;
    &lt;code&gt;/opt/smtp-tunnel/              # Application files
/etc/smtp-tunnel/              # Configuration files
  â”œâ”€â”€ config.yaml
  â”œâ”€â”€ users.yaml
  â”œâ”€â”€ server.crt
  â”œâ”€â”€ server.key
  â””â”€â”€ ca.crt
/usr/local/bin/                # Management commands
  â”œâ”€â”€ smtp-tunnel-adduser
  â”œâ”€â”€ smtp-tunnel-deluser
  â”œâ”€â”€ smtp-tunnel-listusers
  â””â”€â”€ smtp-tunnel-update
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check server is running: &lt;code&gt;systemctl status smtp-tunnel&lt;/code&gt;or&lt;code&gt;ps aux | grep server.py&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check port is open: &lt;code&gt;netstat -tlnp | grep 587&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check firewall: &lt;code&gt;ufw status&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify &lt;code&gt;username&lt;/code&gt;and&lt;code&gt;secret&lt;/code&gt;match in users.yaml&lt;/item&gt;
      &lt;item&gt;Check server time is accurate (within 5 minutes)&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;smtp-tunnel-listusers -v&lt;/code&gt;to verify user exists&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check user's whitelist in users.yaml&lt;/item&gt;
      &lt;item&gt;Your current IP must match a whitelist entry&lt;/item&gt;
      &lt;item&gt;CIDR notation is supported (e.g., &lt;code&gt;10.0.0.0/8&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ensure you're using a domain name, not IP address&lt;/item&gt;
      &lt;item&gt;Verify &lt;code&gt;server_host&lt;/code&gt;matches the certificate hostname&lt;/item&gt;
      &lt;item&gt;Ensure you have the correct &lt;code&gt;ca.crt&lt;/code&gt;from the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Enable detailed logging
python server.py -d
python client.py -d

# View systemd logs
journalctl -u smtp-tunnel -f&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… Always use a domain name for proper TLS verification&lt;/item&gt;
      &lt;item&gt;âœ… Always use &lt;code&gt;ca_cert&lt;/code&gt;to prevent man-in-the-middle attacks&lt;/item&gt;
      &lt;item&gt;âœ… Use &lt;code&gt;smtp-tunnel-adduser&lt;/code&gt;to generate strong secrets automatically&lt;/item&gt;
      &lt;item&gt;âœ… Use per-user IP whitelists if you know client IPs&lt;/item&gt;
      &lt;item&gt;âœ… Protect &lt;code&gt;users.yaml&lt;/code&gt;- contains all user secrets (chmod 600)&lt;/item&gt;
      &lt;item&gt;âœ… Disable logging for sensitive users with &lt;code&gt;logging: false&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;ğŸ“š For detailed security analysis and threat model, see TECHNICAL.md.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This project is provided for educational and authorized use only. Use responsibly and in accordance with applicable laws.&lt;/p&gt;
    &lt;p&gt;This tool is designed for legitimate privacy and censorship circumvention purposes. Users are responsible for ensuring their use complies with applicable laws and regulations.&lt;/p&gt;
    &lt;p&gt;Made with â¤ï¸ for internet freedom&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/x011/smtp-tunnel-proxy"/><published>2026-01-07T00:30:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46520935</id><title>Electronic nose for indoor mold detection and identification</title><updated>2026-01-07T16:16:43.689351+00:00</updated><content/><link href="https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124"/><published>2026-01-07T00:31:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46522308</id><title>On the slow death of scaling</title><updated>2026-01-07T16:16:43.467129+00:00</updated><content/><link href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5877662"/><published>2026-01-07T03:48:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525394</id><title>Optery (YC W22) Hiring a CISO and Web Scraping Engineers (Node) (US and Latam)</title><updated>2026-01-07T16:16:43.182734+00:00</updated><content>&lt;doc fingerprint="ca6bb85f43b74372"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Careers&lt;/head&gt;
    &lt;p&gt;ğŸ’¡Page not loading? Opteryâ€™s Career page uses Cookies to display the full page content. If youâ€™re not seeing anything, try opening the cookie banner (cookie icon in the bottom left corner) and Accept Personalization cookies.&lt;/p&gt;
    &lt;p&gt;ğŸ’¡Page not loading? Opteryâ€™s Career page uses Cookies to display the full page content. If youâ€™re not seeing anything, try opening the cookie banner (cookie icon in the bottom left corner) and Accept Personalization cookies.&lt;/p&gt;
    &lt;p&gt;Ready to safeguard your personal data?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.optery.com/careers/"/><published>2026-01-07T12:00:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525542</id><title>The Eric and Wendy Schmidt Observatory System</title><updated>2026-01-07T16:16:42.315986+00:00</updated><content>&lt;doc fingerprint="f611b05667864f3b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Eric and Wendy Schmidt Observatory System&lt;/head&gt;
    &lt;p&gt;Four novel observatories expanding access and enabling new ways to explore the cosmos&lt;/p&gt;
    &lt;p&gt;The Eric and Wendy Schmidt Observatory System is designed to pioneer a new paradigm for astronomical observatories, fundamentally rethinking how they are conceived, developed, and utilized. This initiative compresses development timelines from decades to years, dramatically lowering barriers to global participation and accelerating the pace of discovery. By uniting rapid development cycles with open data and shared scientific tools, the system empowers researchers everywhere to engage in frontier astrophysics.&lt;/p&gt;
    &lt;head rend="h2"&gt; Strategic Pillars &lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Rapid observatory development leveraging risk-tolerant technical innovation&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Modular designs that leverage economies of scale&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Open data and software for global access&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Global, cross-disciplinary scientific collaboration&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt; Major Projects &lt;/head&gt;
    &lt;p&gt;Through more accessible and responsive scientific infrastructure, the Eric and Wendy Schmidt Observatory System seeks to support discovery for the benefit of all. Explore our projects by clicking the tiles below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Argus Array&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Deep Synoptic Array (DSA)&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Large Fiber Array Spectroscopic Telescope (LFAST)&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Lazuli Space Observatory&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;FirstLight Awards&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.schmidtsciences.org/schmidt-observatory-system/"/><published>2026-01-07T12:19:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525640</id><title>â€œStop Designing Languages. Write Libraries Insteadâ€ (2016)</title><updated>2026-01-07T16:16:42.198934+00:00</updated><content>&lt;doc fingerprint="2fc219af0a3a92d0"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;HomePhilosophyDownloadsDocumentationPeopleCommunityNewsReference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;head&gt;NAVIGATION&lt;/head&gt;
          &lt;head&gt;"Stop Designing Languages. Write Libraries Instead."&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;"Stop Designing Languages. Write Libraries Instead."&lt;/head&gt;
          &lt;p&gt;Patrick S. Li - May 29, 2016&lt;/p&gt;
          &lt;p&gt;I had a friend tell me recently that all programming languages seem very similar to each other. They all have variables, and arrays, a few loop constructs, functions, and some arithmetic constructs. Sure, some languages have fancier features like first-class functions or coroutines, but he doesn't consider himself an expert programmer anyway and doesn't use those features.&lt;/p&gt;
          &lt;p&gt;What really makes a programming language productive for him, he says, are the libraries it comes with. For example, he got into programming by using the popular Ruby on Rails web framework. There is no way that he could have written a full database-driven web stack by himself, nor is he interested in doing so. But thanks to Ruby on Rails, he doesn't have to! So he said that he has no particular opinion about the Ruby programming language, but he absolutely loves Rails. The vast majority of programmers are non-experts, like himself, and the largest gains in productivity for non-experts come from having a wide spectrum of easy-to-use libraries. Subtle language features like first-class functions, and object systems, are lost on them because they don't really use them anyway. Computer scientists should really be spending their time developing new libraries rather than inventing new programming languages.&lt;/p&gt;
          &lt;p&gt;My friend's opinion about programming languages is a common one, and I have heard it repeatedly from experts and non-experts alike. Being a language designer myself, I, of course, don't share this opinion. Here is what I consider to be the purpose of a general-purpose programming language.&lt;/p&gt;
          &lt;p&gt;To start off, I would say that my friend's opinion is completely correct, just incomplete. The greatest productivity gains are indeed the result of having a wide spectrum of libraries. Ruby on Rails is a fantastic framework, and it has enabled thousands (if not millions) of non-experts to build sophisticated websites quickly. So the natural question then is, why isn't there now a Rails framework for every programming language?&lt;/p&gt;
          &lt;p&gt;Some languages that are semantically similar to Ruby do have their own web frameworks. Python, for example, has Django. But as of now, there is still no decent web framework for Java that is as easy to use as Ruby on Rails. Why is that? Are Java developers just not as competent as Ruby programmers? If David Hansson could design and develop Rails by himself, why can't a group of programmers just copy the design to Java? What makes this even more embarrassing is the fact that Java initially marketed itself as the web programming language, because of its applet technology. To emphasize this point, let me add that there is no good web framework for C either, and it is unlikely that there ever will be. Let me assure you that it's not because C programmers are worse than Ruby programmers.&lt;/p&gt;
          &lt;p&gt;Economics is not the reason either. The Tiobe index lists Java and C as the most widely used programming languages today, with Ruby coming in eighth place. There are many times more Java and C programmers than there are Ruby programmers. If someone would just write Java on Rails their framework would have many times more users than Ruby on Rails, and it would instantly propel him to internet fame and fortune.&lt;/p&gt;
          &lt;p&gt;So it's not because of incompetency. Nor is it because of economics. So why else wouldn't someone port Ruby on Rails to Java? Well, simply, because they can't.&lt;/p&gt;
          &lt;p&gt;If you're a knowledgeable Ruby programmer and you take a deep look through an introductory Rails tutorial, you'll notice that pretty much all of the Ruby language features come into play in some way. Rail's ActiveRecords library makes pervasive use of Ruby's meta-programming features. Rail's template system heavily relies upon Ruby's runtime evaluation features. To make your website respond to a user click, you subclass &lt;/p&gt;
          &lt;p&gt;So, completely unbeknownst to my friend, he is actually making heavy use of all those subtle language features that he claimed he never cared about. And this is intentional! Ruby on Rails was designed to make it possible to build websites without understanding type theory, or memory management, or object-oriented design patterns. Rails allow website designers to focus on designing websites, not managing their software infrastructure. My friend is enjoying all the benefits of Ruby without even knowing it, and that's the whole point.&lt;/p&gt;
          &lt;p&gt;Taking a step back, the concept of packaging code into easy-to-use libraries is not new. It's been around even in the days when programs were stored on punched paper tape. There are still vast libraries of assembly code containing useful subroutines. And every programming language ever designed provided some way for common functionality to be reused. To me, this is the primary purpose of a general-purpose programming language, to enable the creation of a wide spectrum of easy-to-use libraries.&lt;/p&gt;
          &lt;p&gt;The design of the programming language directly determines what sort of libraries you can write and how easy they are to use in the end. In the C language, the only major feature provided for enabling reuse is the ability to declare and call functions. So guess what? The majority of C libraries are basically large collections of functions. Ruby on Rails provides a concise way for expressing: do this when the button is clicked. The "do this" part is implemented in Ruby as a first-class function. How would it be implemented in languages like Java which don't support them? Well, the behaviour of first-class functions can be mocked by defining a new event handler class with a single &lt;/p&gt;
          &lt;p&gt;In the early days of software, collections of functions were sufficient in allowing us to code reusable components. A lot of early software was numerical in nature, and there was a library function for every numerical algorithm you would want to run. Numbers go in. Numbers come out. Functions were perfectly adequate for this. Unix and C were also designed in a time when the majority of computing happens in batch mode. You prepare some input data, call a function or run a program, and you get some output data back. But computing has changed radically since the 70's. Nowadays, most interesting programs are interactive. When a user clicks a button, it should do something. It was rare to want to extend the functionality of a library of the 70's. The library provides a collection of useful functions. If one of them does what you want, then use it. If not, then write your own. But with the advent of interactive software, the need for extensible libraries became apparent. Programmers wanted GUI libraries that allowed them to say: when a user clicks a button, please run my code. Java (and C++) provides a limited method for extending an existing library's functionality through its subclassing mechanism. So using a Java library often consists of subclassing a number of magical classes and then overriding a number of magical methods. This style of library became so pervasive at one point that we even gave them a new name. They're called frameworks.&lt;/p&gt;
          &lt;p&gt;I surmise that probably many general purpose programming languages were originally designed because of the author's inability to write a good library for the language that he was using at the time. The initial impetus that got me thinking about designing Stanza, for example, came out of my frustrations with trying to write an easy-to-use game programming library in Java. To handle concurrency, traditional game programming frameworks required sprite behaviours to be programmed using a state machine model. But that's not how we intuitively think about sprites in our heads. Intuitively, we think about a character's behaviour as consisting of a sequence of steps. For example, first the character jumps, and then after he lands he looks to his left and then his right for the nearest enemy. If he sees one then he goes to attack it, otherwise he jumps again. He does this three times, and if he doesn't see an enemy after three jumps, then he takes a short nap. Transforming this sequence of steps into a state machine is an incredibly tedious and error-prone process, and most importantly, feels repetitive. It felt like I was doing the same thing again and again. So the natural question is, can I just make this state machine transformation a library and re-use it? It turns out I couldn't, not in Java at least. The language feature that I needed was some sort of coroutine or continuation mechanism. After some research I found that the Scheme language supports continuations, so the Scheme version of my game programming library was much easier to use than the Java version.&lt;/p&gt;
          &lt;p&gt;Because of its support for continuations, the Scheme version of my game library does not require users to write their sprite behaviour as state machines. But it wasn't better than the Java version in every way. Most importantly, the Java version was statically typed and so the compiler automatically caught many of your mistakes for you. The Scheme version didn't have this ability and thus debugging my games took a bit longer. At this point, the right question to ask would be, well can you write a static-typing library for Scheme that then automatically checks your code for type errors? And the current answer, for now and for the foreseeable future, is no. No mainstream language today allows you to write a library to extend its type system. Stanza doesn't either. It just attempts to provide one that is useful for a wider audience.&lt;/p&gt;
          &lt;p&gt;Since the purpose of general-purpose programming languages are to enable the creation of powerful libraries, this means that different languages can also be characterized by what features they provide that cannot be written as libraries. Stanza provides an optional type system, garbage collection, and a multimethod based object system. But if you don't like Stanza's object system, there is no way to write your own. This is one of the main directions of programming language research. Can we design a language so expressive that library writers can easily write the most appropriate object system, or most appropriate type system, to fit their application? Perhaps one day we'll have such a language. Racket and Shen provide mechanisms for extending their type systems and research on meta-object protocols were attempts at designing extensible object systems. So languages are differentiated by what types of libraries you can write in them and what types of libraries you can't.&lt;/p&gt;
          &lt;p&gt;In summary, the purpose of a general-purpose programming language is to enable the creation of powerful and easy-to-use libraries. The more powerful the language, the easier the libraries are to use. Code that makes use of a perfectly tuned library should read almost like a set of instructions for a coworker. So the next time you come across a particularly elegant library, know that many decades of language research has gone into making that possible. If you're curious about specifically which language features a library makes use of, then you can dig deeper, explore, and appreciate the thought that went into its implementation. If you're not curious about all this subtle language stuff, you can safely ignore it all and get on with your work. That's the whole point.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Site design by Luca Li. Copyright 2015.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lbstanza.org/purpose_of_programming_languages.html"/><published>2026-01-07T12:29:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525888</id><title>A4 Paper Stories</title><updated>2026-01-07T16:16:41.796435+00:00</updated><content>&lt;doc fingerprint="7299db7cc73604b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A4 Paper Stories&lt;/head&gt;
    &lt;p&gt;I sometimes resort to a rather common measuring technique that is neither fast, nor accurate, nor recommended by any standards body and yet it hasn't failed me whenever I have had to use it. I will describe it here, though calling it a technique might be overselling it. Please do not use it for installing kitchen cabinets or anything that will stare back at you every day for the next ten years. It involves one tool: a sheet of A4 paper.&lt;/p&gt;
    &lt;p&gt;Like most sensible people with a reasonable sense of priorities, I do not carry a ruler with me wherever I go. Nevertheless, I often find myself needing to measure something at short notice, usually in situations where a certain amount of inaccuracy is entirely forgivable. When I cannot easily fetch a ruler, I end up doing what many people do and reach for the next best thing, which for me is a sheet of A4 paper, available in abundant supply where I live.&lt;/p&gt;
    &lt;p&gt;From photocopying night-sky charts to serving as a scratch pad for working through mathematical proofs, A4 paper has been a trusted companion since my childhood days. I use it often. If I am carrying a bag, there is almost always some A4 paper inside: perhaps a printed research paper or a mathematical problem I have worked on recently and need to chew on a bit more during my next train ride.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dimensions&lt;/head&gt;
    &lt;p&gt;The dimensions of A4 paper are the solution to a simple, elegant problem. Imagine designing a sheet of paper such that, when you cut it in half parallel to its shorter side, both halves have exactly the same aspect ratio as the original. In other words, if the shorter side has length \( x \) and the longer side has length \( y , \) then \[ \frac{y}{x} = \frac{x}{y / 2} \] which gives us \[ \frac{y}{x} = \sqrt{2}. \] Test it out. Suppose we have \( y/x = \sqrt{2}. \) We cut the paper in half parallel to the shorter side to get two halves, each with shorter side \( x' = y / 2 = x \sqrt{2} / 2 = x / \sqrt{2} \) and longer side \( y' = x. \) Then indeed \[ \frac{y'}{x'} = \frac{x}{x / \sqrt{2}} = \sqrt{2}. \] In fact, we can keep cutting the halves like this and we'll keep getting even smaller sheets with the aspect ratio \( \sqrt{2} \) intact. To summarise, when a sheet of paper has the aspect ratio \( \sqrt{2}, \) bisecting it parallel to the shorter side leaves us with two halves that preserve the aspect ratio. A4 paper has this property.&lt;/p&gt;
    &lt;p&gt;But what are the exact dimensions of A4 and why is it called A4? What does 4 mean here? Like most good answers, this one too begins by considering the numbers \( 0 \) and \( 1. \) Let me elaborate.&lt;/p&gt;
    &lt;p&gt;Let us say we want to make a sheet of paper that is \( 1 \, \mathrm{m}^2 \) in area and has the aspect-ratio-preserving property that we just discussed. What should its dimensions be? We want \[ xy = 1 \, \mathrm{m}^2 \] subject to the condition \[ \frac{y}{x} = \sqrt{2}. \] Solving these two equations gives us \[ x^2 = \frac{1}{\sqrt{2}} \, \mathrm{m}^2 \] from which we obtain \[ x = \frac{1}{\sqrt[4]{2}} \, \mathrm{m}, \quad y = \sqrt[4]{2} \, \mathrm{m}. \] Up to three decimal places, this amounts to \[ x = 0.841 \, \mathrm{m}, \quad y = 1.189 \, \mathrm{m}. \] These are the dimensions of A0 paper. They are precisely the dimensions specified by the ISO standard for it. It is quite large to scribble mathematical solutions on, unless your goal is to make a spectacle of yourself and cause your friends and family to reassess your sanity. So we need something smaller that allows us to work in peace, without inviting commentary or concerns from passersby. We take the A0 paper of size \[ 84.1 \, \mathrm{cm} \times 118.9 \, \mathrm{cm} \] and bisect it to get A1 paper of size \[ 59.4 \, \mathrm{cm} \times 84.1 \, \mathrm{cm}. \] Then we bisect it again to get A2 paper with dimensions \[ 42.0 \, \mathrm{cm} \times 59.4 \, \mathrm{cm}. \] And once again to get A3 paper with dimensions \[ 29.7 \, \mathrm{cm} \times 42.0 \, \mathrm{cm}. \] And then once again to get A4 paper with dimensions \[ 21.0 \, \mathrm{cm} \times 29.7 \, \mathrm{cm}. \] There we have it. The dimensions of A4 paper. These numbers are etched in my memory like the multiplication table of \( 1. \) We can keep going further to get A5, A6, etc. We could, in theory, go all the way up to A\( \infty. \) Hold on, I think I hear someone heckle. What's that? Oh, we can't go all the way to A\( \infty? \) Something about atoms, was it? Hmm. Security! Where's security? Ah yes, thank you, sir. Please show this gentleman out, would you?&lt;/p&gt;
    &lt;p&gt;Sorry for the interruption, ladies and gentlemen. Phew! That fellow! Atoms? Honestly. We, the mathematically inclined, are not particularly concerned with such trivial limitations. We drink our tea from doughnuts. We are not going to let the size of atoms dictate matters, now are we?&lt;/p&gt;
    &lt;p&gt;So I was saying that we can bisect our paper like this and go all the way to A\( \infty. \) That reminds me. Last night I was at a bar in Hoxton and I saw an infinite number of mathematicians walk in. The first one asked, "Sorry to bother you, but would it be possible to have a sheet of A0 paper? I just need something to scribble a few equations on." The second one asked, "If you happen to have one spare, could I please have an A1 sheet?" The third one said, "An A2 would be perfectly fine for me, thank you." Before the fourth one could ask, the bartender disappeared into the back for a moment and emerged with two sheets of A0 paper and said, "Right. That should do it. Do know your limits and split these between yourselves."&lt;/p&gt;
    &lt;p&gt;In general, a sheet of A\( n \) paper has the dimensions \[ 2^{-(2n + 1)/4} \, \mathrm{m} \times 2^{-(2n - 1)/4} \, \mathrm{m}. \] If we plug in \( n = 4, \) we indeed get the dimensions of A4 paper: \[ 0.210 \, \mathrm{m} \times 0.297 \, \mathrm{m}. \]&lt;/p&gt;
    &lt;head rend="h2"&gt;Measuring Stuff&lt;/head&gt;
    &lt;p&gt;Let us now return to the business of measuring things. As I mentioned earlier, the dimensions of A4 are lodged firmly into my memory. Getting hold of a sheet of A4 paper is rarely a challenge where I live. I have accumulated a number of A4 paper stories over the years. Let me share a recent one. I was hanging out with a few folks of the nerd variety one afternoon when the conversation drifted, as it sometimes does, to a nearby computer monitor that happened to be turned off. At some point, someone confidently declared that the screen in front of us was 27 inches. That sounded plausible but we wanted to confirm it. So I reached for my trusted measuring instrument: an A4 sheet of paper. What followed was neither fast, nor especially precise, but it was more than adequate for settling the matter at hand.&lt;/p&gt;
    &lt;p&gt;I lined up the longer edge of the A4 sheet with the width of the monitor. One length. Then I repositioned it and measured a second length. The screen was still sticking out slightly at the end. By eye, drawing on an entirely unjustified confidence built from years of measuring things that never needed measuring, I estimated the remaining bit at about \( 1 \, \mathrm{cm}. \) That gives us a width of \[ 29.7 \, \mathrm{cm} + 29.7 \, \mathrm{cm} + 1.0 \, \mathrm{cm} = 60.4 \, \mathrm{cm}. \] Let us round that down to \( 60 \, \mathrm{cm}. \) For the height, I switched to the shorter edge. One full \( 21 \, \mathrm{cm} \) fit easily. For the remainder, I folded the paper parallel to the shorter side, producing an A5-sized rectangle with dimensions \( 14.8 \, \mathrm{cm} \times 21.0 \, \mathrm{cm}. \) Using the \( 14.8 \, \mathrm{cm} \) edge, I discovered that it overshot the top of the screen slightly. Again, by eye, I estimated the excess at around \( 2 \, \mathrm{cm}. \) That gives us \[ 21.0 \, \mathrm{cm} + 14.8 \, \mathrm{cm} -2.0 \, \mathrm{cm} = 33.8 \, \mathrm{cm}. \] Let us round this up to \( 34 \, \mathrm{cm}. \) The ratio \( 60 / 34 \approx 1.76 \) is quite close to \( 16/9, \) a popular aspect ratio of modern displays. At this point the measurements were looking good. So far, the paper had not embarrassed itself. Invoking the wisdom of the Pythagoreans, we can now estimate the diagonal as \[ \sqrt{(60 \, \mathrm{cm})^2 + (34 \, \mathrm{cm})^2} \approx 68.9 \,\mathrm{cm}. \] Finally, there is the small matter of units. One inch is \( 2.54 \, \mathrm{cm}, \) another figure that has embedded itself in my head. Dividing \( 68.9 \) by \( 2.54 \) gives us roughly \( 27.2 \, \mathrm{in}. \) So yes. It was indeed a \( 27 \)-inch display. My elaborate exercise in showing off my A4 paper skills was now complete. Nobody said anything. A few people looked away in silence. I assumed they were reflecting. I am sure they were impressed deep down. Or perhaps... no, no. They were definitely impressed. I am sure.&lt;/p&gt;
    &lt;p&gt;Hold on. I think I hear another heckle. What is that? There are mobile phone apps that can measure things now? Really? Right. Security. Where's security?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://susam.net/a4-paper-stories.html"/><published>2026-01-07T12:54:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526088</id><title>Show HN: KeelTest â€“ AI-driven VS Code unit test generator with bug discovery</title><updated>2026-01-07T16:16:41.062519+00:00</updated><content>&lt;doc fingerprint="10373b5026f706a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI Tests That Find &lt;lb/&gt;Bugs Before Production&lt;/head&gt;
    &lt;p&gt;Generate pytest suites that actually run - and expose issues in your code. 90% average pass rate. Source bugs flagged with fix suggestions.&lt;/p&gt;
    &lt;p&gt;Free forever Â· 7 credits/month Â· No credit card required&lt;/p&gt;
    &lt;p&gt;* Stats updated weekly. Based on active Alpha usage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Started in 3 Simple Steps&lt;/head&gt;
    &lt;p&gt;KeelTest is a VS Code extension that installs in seconds. No complex setup, no external services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Open VS Code Extensions&lt;/head&gt;
    &lt;p&gt;Press Ctrl+Shift+X (Windows/Linux) or Cmd+Shift+X (Mac) to open the Extensions view in VS Code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Search for KeelTest&lt;/head&gt;
    &lt;p&gt;Type "KeelTest" in the search bar and click Install on the official KeelTest extension.&lt;/p&gt;
    &lt;head rend="h3"&gt;Right-Click and Generate&lt;/head&gt;
    &lt;p&gt;Right-click any Python file in your workspace and select "KeelTest: Generate Tests" to start.&lt;/p&gt;
    &lt;p&gt;Free to install â€¢ Available on VS Code Marketplace â€¢ No credit card required&lt;/p&gt;
    &lt;head rend="h2"&gt;Why developers switch &lt;lb/&gt;to KeelTest&lt;/head&gt;
    &lt;p&gt;Moving beyond simple prompts. We combined static analysis with a multi-step verification pipeline to deliver production-grade tests.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deep Static Analysis&lt;/head&gt;
    &lt;p&gt;Our engine builds a full AST (Abstract Syntax Tree) representation of your code, identifying exactly which branches need coverage and which edge cases are most likely to cause regressions.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Code to Tests in 3 Clicks&lt;/head&gt;
    &lt;head rend="h2"&gt;Start Free, Scale When Ready&lt;/head&gt;
    &lt;p&gt;Join ... developers already on the waitlist for our upcoming premium tiers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Individual Plans&lt;/head&gt;
    &lt;head rend="h4"&gt;Starter&lt;/head&gt;
    &lt;p&gt;For regular development&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Priority queue&lt;/item&gt;
      &lt;item&gt;Usage analytics&lt;/item&gt;
      &lt;item&gt;Bug detection&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Pro&lt;/head&gt;
    &lt;p&gt;For power users&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Priority queue&lt;/item&gt;
      &lt;item&gt;Usage analytics&lt;/item&gt;
      &lt;item&gt;Bug detection&lt;/item&gt;
      &lt;item&gt;Early access to features&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Free&lt;/head&gt;
    &lt;p&gt;Perfect for trying it out&lt;/p&gt;
    &lt;head rend="h4"&gt;Detailed Comparison&lt;/head&gt;
    &lt;p&gt;Everything you get with each tier&lt;/p&gt;
    &lt;head rend="h2"&gt;Real Pass Rates, Not marketing&lt;/head&gt;
    &lt;p&gt;Every test is executed in a sandbox before it reaches your editor. We don't just generate code; we deliver verified functionality.&lt;/p&gt;
    &lt;p&gt;Pass Rate&lt;/p&gt;
    &lt;p&gt;Self-Healing GenerationFailures are automatically fixed by our AI validator before delivery.&lt;/p&gt;
    &lt;p&gt;Source Bug DetectionReal issues in your source code are triaged and clearly flagged.&lt;/p&gt;
    &lt;head rend="h3"&gt;How far your credits go&lt;/head&gt;
    &lt;p&gt;Estimated file generation per month based on complexity&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Complexity&lt;/cell&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Starter&lt;/cell&gt;
        &lt;cell role="head"&gt;Pro&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Small files (â‰¤15 fn)Approx. 15 functions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~7&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~30&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~70&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Medium files (~30 fn)Approx. 30 functions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~3&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~15&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~35&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Large files (~50 fn)Approx. 50 functions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~1&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~7&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~17&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;1 credit = up to 15 functions. Larger files use proportionally more credits.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tests That Actually Test&lt;/head&gt;
    &lt;p&gt;We tested leading AI models on generating unit tests for complex e-commerce logic. KeelTest's agentic approach-combining AI with static code analysis, test validation, and actual execution-achieved a staff-level score of 8.5/10, outperforming pure zero-shot prompts by 54%.&lt;/p&gt;
    &lt;head rend="h3"&gt;Overall Quality ScoreStaff Engineer = 10&lt;/head&gt;
    &lt;head rend="h3"&gt;Detailed Evaluation Criteria&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Criteria&lt;/cell&gt;
        &lt;cell role="head"&gt;KeelTest&lt;/cell&gt;
        &lt;cell role="head"&gt;Model B&lt;/cell&gt;
        &lt;cell role="head"&gt;Model C&lt;/cell&gt;
        &lt;cell role="head"&gt;Model A&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Unit Test Isolation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mocking &amp;amp; Dependency Injection&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Edge Case Coverage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Following Instructions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Technical Correctness&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DateTime/Float Precision&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;"KeelTest demonstrates the deepest understanding of unit testing principles with proper isolation, comprehensive mocking, and dependency injection. It's what a staff engineer would produce."&lt;/p&gt;
    &lt;p&gt;* KeelTest leverages advanced AI models enhanced with static code analysis, automated test validation, and real-time execution feedback-not just raw prompts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://keelcode.dev/keeltest"/><published>2026-01-07T13:22:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526584</id><title>Show HN: RepoReaper â€“ AST-aware, JIT-loading code audit agent (Python/AsyncIO)</title><updated>2026-01-07T16:16:40.595199+00:00</updated><content>&lt;doc fingerprint="a952fc1567f8ad52"&gt;
  &lt;main&gt;
    &lt;p&gt;ğŸ‘‡ Live Demo Access / åœ¨çº¿ä½“éªŒ ğŸ‘‡&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;An intelligent, agentic system for automated architectural analysis and semantic code search.&lt;/p&gt;
    &lt;p&gt;This project transcends traditional "Chat with Code" paradigms by implementing an autonomous Agent that mimics the cognitive process of a Senior Tech Lead. Instead of statically indexing a repository, the system treats the Large Language Model (LLM) as the CPU and the Vector Store as a high-speed Context Cache. The agent dynamically traverses the repository structure, pre-fetching critical contexts into the "cache" (RAG) and performing Just-In-Time (JIT) reads when semantic gaps are detected.&lt;/p&gt;
    &lt;p&gt;In traditional code assistants, RAG (Retrieval-Augmented Generation) is often a static lookup table. In this architecture, we redefine RAG as a Dynamic L2 Cache for the LLM:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Cold Start (Repo Map): The agent first parses the Abstract Syntax Tree (AST) of the entire repository to build a lightweight symbol map (Classes/Functions). This serves as the "index" to the file system.&lt;/item&gt;
      &lt;item&gt;Prefetching (Analysis Phase): During the initial analysis, the agent autonomously selects the most critical 10-20 files based on architectural relevance, parses them, and "warms up" the vector store (the cache).&lt;/item&gt;
      &lt;item&gt;Cache Miss Handling (ReAct Loop): During user Q&amp;amp;A, if the retrieval mechanism (BM25 + Vector) returns insufficient context, the Agent triggers a Just-In-Time (JIT) file read. It autonomously tools the GitHub API to fetch missing files, updates the cache in real-time, and re-generates the answer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Standard text chunking destroys code logic. We utilize Python's &lt;code&gt;ast&lt;/code&gt; module to implement Structure-Aware Chunking.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Logical Boundaries: Code is split by Class and Method definitions, ensuring that a function is never severed in the middle.&lt;/item&gt;
      &lt;item&gt;Context Injection: Large classes are decomposed into methods, but the parent class's signature and docstrings are injected into every child chunk. This ensures the LLM understands the "why" (class purpose) even when looking at the "how" (method implementation).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built on top of &lt;code&gt;asyncio&lt;/code&gt; and &lt;code&gt;httpx&lt;/code&gt;, the system is designed for high-throughput I/O operations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-Blocking Ingestion: Repository parsing, AST extraction, and vector embedding occur concurrently.&lt;/item&gt;
      &lt;item&gt;Worker Scalability: The application runs behind Gunicorn with Uvicorn workers, utilizing a stateless design pattern where the Vector Store Manager synchronizes context via persistent disk storage and shared ChromaDB instances. This allows multiple workers to serve requests without race conditions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Chat Service implements a sophisticated Reasoning + Acting (ReAct) loop:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Query Rewrite: User queries (often vague or in different languages) are first rewritten by an LLM into precise, English-language technical keywords for optimal BM25/Vector retrieval.&lt;/item&gt;
      &lt;item&gt;Self-Correction: If the retrieved context is insufficient, the model does not hallucinate. Instead, it issues a &lt;code&gt;&amp;lt;tool_code&amp;gt;&lt;/code&gt;command to fetch specific file paths from the repository. The system intercepts this command, pulls the fresh data, indexes it, and feeds it back to the model in a single inference cycle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To balance semantic understanding with exact keyword matching, the retrieval engine employs a weighted hybrid approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dense Retrieval (Vector): Uses &lt;code&gt;BAAI/bge-m3&lt;/code&gt;embeddings to find conceptually similar code (e.g., matching "authentication" to "login logic").&lt;/item&gt;
      &lt;item&gt;Sparse Retrieval (BM25): Captures exact variable names, error codes, and specific function signatures that vector embeddings might miss.&lt;/item&gt;
      &lt;item&gt;Reciprocal Rank Fusion (RRF): Results are fused and re-ranked to ensure the highest fidelity context is provided to the LLM.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The architecture is completely language-agnostic but optimized for dual-language environments (English/Chinese).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynamic Prompt Engineering: The system detects the user's input language and hot-swaps the System Prompts to ensure the output format, tone, and technical terminology align with the user's locale.&lt;/item&gt;
      &lt;item&gt;UI Integration: The frontend includes a dedicated language toggle that influences the entire generation pipeline, from the initial architectural report to the final Q&amp;amp;A.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Core: Python 3.10+, FastAPI, AsyncIO&lt;/item&gt;
      &lt;item&gt;LLM Integration: OpenAI SDK (compatible with DeepSeek/SiliconFlow)&lt;/item&gt;
      &lt;item&gt;Vector Database: ChromaDB (Persistent Storage)&lt;/item&gt;
      &lt;item&gt;Search Algorithms: BM25Okapi, Rank-BM25&lt;/item&gt;
      &lt;item&gt;Parsing: Python &lt;code&gt;ast&lt;/code&gt;(Abstract Syntax Trees)&lt;/item&gt;
      &lt;item&gt;Frontend: HTML5, Server-Sent Events (SSE) for real-time streaming, Mermaid.js for architecture diagrams.&lt;/item&gt;
      &lt;item&gt;Deployment: Docker, Gunicorn, Uvicorn.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Session Management: Uses browser &lt;code&gt;sessionStorage&lt;/code&gt;coupled with server-side persistent contexts, allowing users to refresh pages without losing the "warm" cache state.&lt;/item&gt;
      &lt;item&gt;Network Resilience: Implements robust error handling for GitHub API rate limits (403/429) and network timeouts during long-context generation.&lt;/item&gt;
      &lt;item&gt;Memory Efficiency: The &lt;code&gt;VectorStoreManager&lt;/code&gt;is designed to be stateless in memory but stateful on disk, preventing memory leaks in long-running container environments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Prerequisites:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Python 3.9+&lt;/item&gt;
          &lt;item&gt;Valid GitHub Token&lt;/item&gt;
          &lt;item&gt;LLM API Keys (DeepSeek-V3 &amp;amp; SiliconFlow bge-m3 recommended).&lt;/item&gt;
        &lt;/list&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;Clone the Repository&lt;/p&gt;
            &lt;code&gt;git clone [https://github.com/tzzp1224/RepoReaper.git](https://github.com/tzzp1224/RepoReaper.git) cd RepoReaper&lt;/code&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Install Dependencies Using a virtual environment is recommended:&lt;/p&gt;
            &lt;quote&gt;# Create and activate venv python -m venv venv source venv/bin/activate # Windows: venv\Scripts\activate # Install requirements pip install -r requirements.txt&lt;/quote&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Configure Environment Create a&lt;/p&gt;&lt;code&gt;.env&lt;/code&gt;file in the root directory:&lt;quote&gt;# GitHub Personal Access Token GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxx # LLM API Key (e.g., DeepSeek) DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxx # Embedding API Key (SiliconFlow) SILICON_API_KEY=sk-xxxxxxxxxxxxxxx&lt;/quote&gt;&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Start the Service&lt;/p&gt;&lt;p&gt;Option A: Local Run (Universal) Compatible with Windows, macOS, and Linux. Recommended for development:&lt;/p&gt;&lt;quote&gt;python -m app.main&lt;/quote&gt;&lt;p&gt;(Note: Linux users can still use&lt;/p&gt;&lt;code&gt;gunicorn -c gunicorn_conf.py app.main:app&lt;/code&gt;for production deployment)&lt;p&gt;Option B: Docker Run ğŸ³ Run in an isolated container:&lt;/p&gt;&lt;quote&gt;# 1. Build Image docker build -t reporeaper . # 2. Run Container (loading env vars) docker run -d -p 8000:8000 --env-file .env --name reporeaper reporeaper&lt;/quote&gt;&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Access Dashboard Navigate to&lt;/p&gt;&lt;code&gt;http://localhost:8000&lt;/code&gt;. Enter a GitHub repository URL to trigger the autonomous analysis agent.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/tzzp1224/RepoReaper"/><published>2026-01-07T14:15:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526740</id><title>Sugar industry influenced researchers and blamed fat for CVD</title><updated>2026-01-07T16:16:40.380219+00:00</updated><content>&lt;doc fingerprint="e398a9b742a7c320"&gt;
  &lt;main&gt;&lt;p&gt;This article is archived and only made available for historical reference. If youâ€™d like to discover UCSFâ€™s most recent advances in research, education and patient care, please visit the UCSF News Center.&lt;/p&gt;&lt;head rend="h1"&gt;Archive: Sugar Papers Reveal Industry Role in Shifting National Heart Disease Focus to Saturated Fat&lt;/head&gt;&lt;p&gt;A newly discovered cache of industry documents revealed that the sugar industry began working closely with nutrition scientists in the mid-1960s to single out fat and cholesterol as the dietary causes of coronary heart disease and to downplay evidence that sucrose consumption was also a risk factor.&lt;/p&gt;&lt;p&gt;An analysis of those papers by researchers at UC San Francisco appears Sept. 12, 2016, in JAMA Internal Medicine.&lt;/p&gt;&lt;p&gt;The internal industry documents, which were found in public archives, showed that a sugar industry trade organization recognized as early as 1954 that if Americans adopted low-fat diets, then per-capita consumption of sucrose would increase by more than one-third. The trade organization represented 30 international members.&lt;/p&gt;&lt;p&gt;Meanwhile, evidence linking sugar consumption to high blood cholesterol and triglyceride levels â€“ both thought to be risk factors for coronary heart disease â€“ began to emerge in the scientific literature and popular press.&lt;/p&gt;&lt;head rend="h2"&gt;Literature Shaped Public Opinion&lt;/head&gt;&lt;p&gt;After a 1965 spike in media attention to the heart disease risks of sucrose, the sugar industry commissioned Project 226, a literature review written by researchers at the Harvard University School of Public Health Nutrition Department, which was published in the highly respected New England Journal of Medicine (NEJM) in 1967. It concluded there was â€œno doubtâ€ that the only dietary intervention required to prevent coronary heart disease was to reduce dietary cholesterol and substitute polyunsaturated fat for saturated fat in the American diet.&lt;/p&gt;Cristin Kearns, DDS, MBA&lt;p&gt;â€œThe literature review helped shape not only public opinion on what causes heart problems but also the scientific communityâ€™s view of how to evaluate dietary risk factors for heart disease,â€ said lead author Cristin Kearns, DDS, MBA, who discovered the industry documents.&lt;/p&gt;&lt;p&gt;The UCSF researchers analyzed more than 340 documents, totaling 1,582 pages of text, between the sugar industry and two individuals: Roger Adams, then a professor of organic chemistry who served on scientific advisory boards for the sugar industry; and D. Mark Hegsted, one of the Harvard researchers who produced the literature review.&lt;/p&gt;&lt;p&gt;To conduct the literature review, the sugar industry paid the Harvard scientists the equivalent of $50,000 in 2016 dollars, then set the reviewâ€™s objective, contributed articles to be included, and received drafts. Yet the industryâ€™s funding and role were not disclosed in the final NEJM publication.&lt;/p&gt;&lt;p&gt;The literature review heavily criticized studies linking sucrose to heart disease, while ignoring limitations of studies investigating dietary fats. The review argued that blood cholesterol levels were the only significant risk factor for coronary heart disease, which made the high sucrose content of the American diet seem less hazardous than if blood triglycerides were also considered to be a risk factor.&lt;/p&gt;&lt;head rend="h2"&gt;Need for More Transparent Scientific Reviews&lt;/head&gt;Stanton A. Glantz, PhD&lt;p&gt;The authors emphasized that this analysis demonstrates the importance of having scientific reviews written by people without conflicts of interest, as well as the need for financial disclosure in nutrition science.&lt;/p&gt;&lt;p&gt;â€œAs the saying goes, he who pays the piper calls the tune,â€ said senior author Stanton A. Glantz, PhD, UCSF professor of medicine and director of the UCSF Center for Tobacco Control Research and Education. â€œThere are all kinds of ways that you can subtly manipulate the outcome of a study, which industry is very well practiced at.â€&lt;/p&gt;&lt;p&gt;Co-author Laura Schmidt, PhD, who is also principal investigator on the UCSF-led SugarScience initiative, noted that after decades of focusing on saturated fat as the dietary culprit in heart disease, the science is building around sugarâ€™s role, but health policy has only just begun to catch up.&lt;/p&gt;Laura Schmidt, PhD&lt;p&gt;â€œThere is now a considerable body of evidence linking added sugars to hypertension and cardiovascular disease, which is the No. 1 cause of premature death in the developed world,â€ Schmidt said. â€œYet, health policy documents are still inconsistent in citing heart disease risk as a health consequence of added sugars consumption.â€&lt;/p&gt;&lt;p&gt;The study was funded by the UCSF Philip R. Lee Institute for Health Policy Studies; a donation by the Hellmann Family Fund to the UCSF Center for Tobacco Control Research and Education; the UCSF School of Dentistry Department of Orofacial Sciences and Global Oral Health Program; and grants from the National Institute of Dental and Craniofacial Research and the National Cancer Institute.&lt;/p&gt;&lt;p&gt;UCSF is a leading university dedicated to promoting health worldwide through advanced biomedical research, graduate-level education in the life sciences and health professions, and excellence in patient care. It includes top-ranked graduate schools of dentistry, medicine, nursing and pharmacy; a graduate division with nationally renowned programs in basic, biomedical, translational and population sciences; and a preeminent biomedical research enterprise. It also includes UCSF Health, which comprises two top-ranked hospitals, UCSF Medical Center and UCSF Benioff Childrenâ€™s Hospital San Francisco, and other partner and affiliated hospitals and healthcare providers throughout the Bay Area.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ucsf.edu/news/2016/09/404081/sugar-papers-reveal-industry-role-shifting-national-heart-disease-focus"/><published>2026-01-07T14:29:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526933</id><title>LaTeX Coffee Stains [pdf] (2021)</title><updated>2026-01-07T16:16:40.165825+00:00</updated><content/><link href="https://ctan.math.illinois.edu/graphics/pgf/contrib/coffeestains/coffeestains-en.pdf"/><published>2026-01-07T14:46:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527157</id><title>Meditation as Wakeful Relaxation: Unclenching Smooth Muscle</title><updated>2026-01-07T16:16:40.069835+00:00</updated><content/><link href="https://psychotechnology.substack.com/p/meditation-as-wakeful-relaxation"/><published>2026-01-07T15:03:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527161</id><title>Shipmap.org</title><updated>2026-01-07T16:16:39.720300+00:00</updated><content>&lt;doc fingerprint="14b4e15227c5a82f"&gt;
  &lt;main&gt;
    &lt;p&gt;Data: exactEarth &amp;amp; Clarksons&lt;/p&gt;
    &lt;p&gt;Due to popular demand the designers of this map, Kiln, are now selling stunning high-resolution versions of the world Ã¢routesÃ¢ view. There are two versions available: coloured by ship type over the inky-blue base map; or just the ship in a single colour a transparent background so you can overlay or print onto whatever background colour you like. Contact [email protected] for pricing and further information.&lt;/p&gt;
    &lt;p&gt;Yes. You are welcome to embed this map. Please include a link back to Kiln somewhere in the text of your article. Use the following embed code for a fully responsive embed that will adjust to the width of your website. Feel free to change the height and/or give it a fixed width if you prefer.&lt;/p&gt;
    &lt;p&gt;You can see movements of the global merchant fleet over the course of 2012, overlaid on a bathymetric map. You can also see a few statistics such as a counter for emitted CO2 (in thousand tonnes) and maximum freight carried by represented vessels (varying units).&lt;/p&gt;
    &lt;p&gt;You can pan and zoom in the usual ways, and skip back and forward in time using the timeline at the bottom of the screen. The controls at the top right let you show and hide different map layers: port names, the background map, routes (a plot of all recorded vessel positions), and the animated ships view. There are also controls for filtering and colouring by vessel type.&lt;/p&gt;
    &lt;p&gt;The merchant fleet is divided into five categories, each of which has a filter and a CO2 and freight counter for the hour shown on the clock. The ship types and units are as follows:&lt;/p&gt;
    &lt;p&gt;In some cases this is because there are ships navigating via canals or rivers that arenÃ¢t visible on the map. Generally, though, this effect is an artefact of animating a ship between two recorded positions with missing data between, especially when the positions are separated by a narrow strip of land. We may develop the map to remove this effect in the future.&lt;/p&gt;
    &lt;p&gt;Unfortunately the data we are using for the map is incomplete for the first few months of the year: roughly January to April.&lt;/p&gt;
    &lt;p&gt;The map was created by Kiln based on data from the UCL Energy Institute (UCL EI)&lt;/p&gt;
    &lt;p&gt;Website: Duncan Clark &amp;amp; Robin Houston from Kiln&lt;/p&gt;
    &lt;p&gt;Data: Julia Schaumeier &amp;amp; Tristan Smith from the UCL EI&lt;/p&gt;
    &lt;p&gt;Music: Bach Goldberg Variations played by Kimiko Ishizaka&lt;/p&gt;
    &lt;p&gt;UCL EI took data showing location and speed of ships and cross-checked it with another database to get the vessel characteristics, such as engine type and hull measurements. With this information they were able to compute the CO2 emissions for each observed hour, following the approach laid out in the Third IMO Greenhouse Gas Study 2014. Kiln took the resulting dataset and visualized it with WebGL on top of a specially created base map, which shows bathymetry (ocean depth), based on the GEBCO_2014 Grid (version 20150318), as well as continents and major rivers from Natural Earth.&lt;/p&gt;
    &lt;p&gt;Our data sources for shipping positions are exactEarth for AIS data (location/speed) and Clarksons Research UK World Fleet Register (static vessel information). We are very grateful to our funders, the European Climate Foundation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.shipmap.org/"/><published>2026-01-07T15:03:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527471</id><title>We might have been slower to abandon StackOverflow if it wasn't a toxic hellhole</title><updated>2026-01-07T16:16:39.639522+00:00</updated><content>&lt;doc fingerprint="f4f0ed37f679dd8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;We might have been slower to abandon Stack Overflow if it wasn't a toxic hellhole&lt;/head&gt;&lt;p&gt;If you were a software developer prior to 2024, you probably used Stack Overflow. It was a reliable place to find good answers to many technical questions. If you asked any questions there, you probably also know that it was a toxic hellholeâ€”you often got criticized for not having basic knowledge or not understanding error messages.&lt;/p&gt;&lt;p&gt;This isn't exactly a secret. In 2018, Stack Overflow published a blog post entitled Stack Overflow Isn't Very Welcoming. It's Time for That to Change.&lt;/p&gt;&lt;p&gt;I don't know about you, but I never felt like behavior on the site got any better. Any time I asked a question I braced for impact. Was I about to get smacked down?&lt;/p&gt;&lt;p&gt;Recently, a graph of the total number of Stack Overflow questions over time started making rounds on the internet:&lt;/p&gt;&lt;p&gt;This graph shows a steady decline in usage from about 2017 to 2023 and then usage falls off a cliff. In a Reddit posts asking why developers are moving away from Stack Overflow, one user put it pretty succinctly:&lt;/p&gt;&lt;p&gt;"Because I can get an answer from an LLM (which does need to be verified) in less than a minute versus the hours or days I would have to wait to get a toxic and potentially useless reply on stackoverflow. They should really downsize or just kill the company itâ€™s a relic of the past and most developers wonâ€™t miss it."&lt;/p&gt;&lt;p&gt;This is how a lot of us feel. Developer sentiment on generative AI can be mixed, but we know that at least it won't be an asshole to us, unlike many "helpers" on Stack Overflow.&lt;/p&gt;&lt;p&gt;One question I have is if we would have been slower to abandon Stack Overflow if it was a welcoming community. I don't know. Getting answers from generative AI would still have been faster.&lt;/p&gt;&lt;p&gt;I suspect we may have fought a little harder to preserve Stack Overflow in some capacity if it was a positive place. And I think this should be a lesson to other communities out there: instead of relying solely on being necessary, you should also be a positive place. Because when the next thing comes along and makes you less necessary, people won't hesitate to abandon you.&lt;/p&gt;Enjoy this post? Please subscribe to my RSS feed on Feedly or add my RSS XML file to another reader!&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.pcloadletter.dev/blog/abandoning-stackoverflow/"/><published>2026-01-07T15:27:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527533</id><title>US Job Openings Decline to Lowest Level in More Than a Year</title><updated>2026-01-07T16:16:39.514995+00:00</updated><content/><link href="https://www.bloomberg.com/news/articles/2026-01-07/us-job-openings-decline-to-lowest-level-in-more-than-a-year"/><published>2026-01-07T15:32:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527581</id><title>LLM Problems Observed in Humans</title><updated>2026-01-07T16:16:39.188440+00:00</updated><content>&lt;doc fingerprint="b44f0a9d2b235e5a"&gt;
  &lt;main&gt;
    &lt;p&gt;While some are still discussing why computers will never be able to pass the Turing test, I find myself repeatedly facing the idea that as the models improve and humans donÃ¢t, the bar for the test gets raised and eventually humans wonÃ¢t pass the test themselves. HereÃ¢s a list of what used to be LLM failure modes but that are now more commonly observed when talking to people.&lt;/p&gt;
    &lt;p&gt;This has always been an issue in conversations: you ask a seemingly small and limited question, and in return have to listen to what seems like hours of incoherent rambling. Despite exhausting their knowledge of the topic, people will keep on talking about stuff you have no interest in. I find myself searching for the Ã¢stop generatingÃ¢ button, only to remember that all I can do is drop hints, or rudely walk away.&lt;/p&gt;
    &lt;p&gt;The best thing about a good deep conversation is when the other person gets you: you explain a complicated situation you find yourself in, and find some resonance in their replies. That, at least, is what happens when chatting with the recent large models. But when subjecting the limited human mind to the same promptÃ¢a rather long oneÃ¢again and again the information in the prompt somehow gets lost, their focus drifts away, and you have to repeat crucial facts. In such a case, my gut reaction is to see if thereÃ¢s a way to pay to upgrade to a bigger model, only to remember that thereÃ¢s no upgrading of the human brain. At most what you can do is give them a good nightÃ¢s sleep and then they may possibly switch from the Ã¢FastÃ¢ to the Ã¢ThinkingÃ¢ mode, but thatÃ¢s not guaranteed with all people.&lt;/p&gt;
    &lt;p&gt;IÃ¢ve got a lot of interests and on any given day, I may be excited to discuss various topics, from kernels to music to cultures and religions. I know I can put together a prompt to give any of todayÃ¢s leading models and am essentially guaranteed a fresh perspective on the topic of interest. But let me pose the same prompt to people and more often then not the reply will be a polite nod accompanied by clear signs of their thinking something else entirely, or maybe just a summary of the prompt itself, or vague general statements about how things should be. In fact, so rare it is to find someone who knows what I mean that it feels like a magic moment. With the proliferation of genuinely good modelsÃ¢well educated, as it wereÃ¢finding a conversational partner with a good foundation of shared knowledge has become trivial with AI. This does not bode well for my interest in meeting new people.&lt;/p&gt;
    &lt;p&gt;Models with a small context window, or a small number of parameters, seem to have a hard time learning from their mistakes. This should not be a problem for humans: we have a long term memory span measured in decades, with emotional reinforcement of the most crucial memories. And yet, it happens all too often that I must point out the same logical fallacy again and again in the same conversation! Surely, I think, if I point out the mistake in the reasoning, this will count as an important correction that the brain should immediately make use of? As it turns out, there seems to be some kind of a fundamental limitation on how quickly the neural connections can get rewired. Chatting with recent models, who can make use the extra information immediately, has deteriorated my patience regarding having to repeat myself.&lt;/p&gt;
    &lt;p&gt;By this point, itÃ¢s possible to explain what happens in a given situation, and watch the model apply the lessons learned to a similar situation. Not so with humans. When I point out that the same principles would apply elsewhere, their response will be somewhere along the spectrum of total bafflement on the one end and on the other, a face-saving explanation that the comparison doesnÃ¢t apply Ã¢because itÃ¢s differentÃ¢. Indeed the whole point of comparisons is to apply same principles in different situations, so why the excuse? IÃ¢ve learned to take up such discussions with AI and not trouble people with them.&lt;/p&gt;
    &lt;p&gt;This is the opposite issue: given a principle stated in general terms, the person will not be able to apply it in a specific situation. Indeed, IÃ¢ve had a lifetime of observing this very failure mode in myself: given the laws of physics, which are typically Ã¢obviousÃ¢ and easy to understand, I find it very difficult to calculate how long before the next eclipse. More and more, rather than think these things through myself, IÃ¢d just send a quick prompt to the most recent big model, and receive a good answer in seconds. In other words, models threaten to sever me not only from other flawed humans, but from my own Ã¢slowÃ¢ thinking as well!&lt;/p&gt;
    &lt;p&gt;Understood in the medical sense, hallucination refers to when something appears to be real even as you know very well it isnÃ¢t. Having no direct insight into the Ã¢inner mental lifeÃ¢ of models, we claim that every false fact they spit out is a form of hallucination. The meaning of the word is shifting from the medical sense towards the direction of Ã¢just being wrong, and persistently soÃ¢. This has plagued human speech for centuries. As a convenient example, look up some heated debate between proponents of science and those of religion. (As if the two need be in conflict!) When a model exhibits hallucination, often providing more context and evidence will dispel it, but the same trick does not appear to work so well on humans.&lt;/p&gt;
    &lt;p&gt;Where to go from here? One conclusion is that LLMs are damaging the connection people feel with each other, much like a decade before social networks threatened to destroy it by replacing it with a shallower, simulated versions. Another interpretation would be to conclude cynically that itÃ¢s time humans get either enhanced or replaced by a more powerful form of intelligence. IÃ¢d say weÃ¢re not there yet entirely, but that some of the replacement has been effected already: IÃ¢ll never again ask a human to write a computer program shorter than about a thousand lines, since an LLM will do it better.&lt;/p&gt;
    &lt;p&gt;Indeed, why am I even writing this? I asked GPT-5 for additional failure modes and found more additional examples than I could hope to get from a human:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Beyond the failure modes already discussed, humans also exhibit analogues of several newer LLM pathologies: conversations often suffer from instruction drift, where the original goal quietly decays as social momentum takes over; mode collapse, in which people fall back on a small set of safe clichÃƒÂ©s and conversational templates; and reward hacking, where social approval or harmony is optimized at the expense of truth or usefulness. Humans frequently overfit the prompt, responding to the literal wording rather than the underlying intent, and display safety overrefusal, declining to engage with reasonable questions to avoid social or reputational risk. Reasoning is also marked by inconsistency across turns, with contradictions going unnoticed, and by temperature instability, where fatigue, emotion, or audience dramatically alters the quality and style of thought from one moment to the next.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://embd.cc/llm-problems-observed-in-humans"/><published>2026-01-07T15:36:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527600</id><title>Commodore 64 floppy drive has the power to be a computer and runs BASIC</title><updated>2026-01-07T16:16:38.971471+00:00</updated><content>&lt;doc fingerprint="f7845cde6324b9ed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Commodore 64 floppy drive has the power to be a computer â€” bulky 1982 Commodore 1541 5.25 inch drive packs a 1 MHz MOS 6502 CPU&lt;/head&gt;
    &lt;p&gt;10 PRINT "IT WORKS"&lt;/p&gt;
    &lt;p&gt;The Commodore History channel on YouTube has confirmed that the Commodore 1541 floppy disk drives electronics are powerful and capable enough to work as a standalone computer. This 1982 vintage peripheral, designed to add a 5.25-inch floppy disc to the equally ancient Commodore 64, actually has its own processor, RAM, ROM and I/O.&lt;/p&gt;
    &lt;p&gt;Thereâ€™s a 1 MHz MOS 6502 in the floppy drive electronics, which is closely related to the C64â€™s MOS 6510, and exactly the same processor as in the VIC-20. However, Dave from the Commodore History channel did his work with minimal hardware modding, so the resulting â€˜1541 computerâ€™ ended up being rather limited.&lt;/p&gt;
    &lt;p&gt;The video starts with Dave explaining that a channel subscriber had asked about whether the Commodore 1541 floppy disk could work as a general purpose computer â€“ as it was known to pack a MOS 6502 chip, its own RAM, its own I/O chips, alongside the ROMs which help it carry out its day job as a storage device. The CPU is very similar to the C64â€™s MOS 6510, which is just â€œa customized upgrade for the Commodore 64â€ based on the 6502. But the VIC-20 is actually a much closer match, and you can see a comparison in the infographic, below.&lt;/p&gt;
    &lt;p&gt;Turning the 1541 into a VIC-20-a-like was still too much of a stretch for this investigation, as Dave wanted to keep hardware modding off the menu. The VIC-20 owes a lot of its general purpose computing ability to its additional 6560 VIC chip â€“ a custom IC for graphics and sound. It also offers lot more I/O for general purpose computing appeal.&lt;/p&gt;
    &lt;p&gt;Thus, Dave had to wind-back the Commodore clock even further for inspiration. And he decided the first way to demonstrate that the Commodore 1541 floppy disk could work as a general purpose computer was to look at the Commodore KIM-1, the firmâ€™s first, and most simple computer, which would be described as a Single Board Computer (SBC) today.&lt;/p&gt;
    &lt;p&gt;The KIM-1 was programmed using an onboard keypad, punching in values in 6502 machine language, byte-by-byte. Its only display was a set of 6 segmented LCDs. This computer could also be used via Teletype (TTY) over serial connection, and this method was adopted as the way to interface and work with the Commodore 1541.&lt;/p&gt;
    &lt;p&gt;So, the KIM-1 became the new target of the Commodore 1541 as a computer project. Dave found the KIM-1 kernel had already been published, so set about modifying it with code to initialize the 1541, and tweak I/O routines so serial teletype would work. This code was burned onto an EEPROM, and is now available on GitHub.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Commodore 64's original price was $599 in 1982 (~$1,950 in todayâ€™s money)&lt;/item&gt;
      &lt;item&gt;The Commodore 1541 disk drive was originally priced at $399 in 1982 (~$1,300 in todayâ€™s money)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To teletype interface with the pair of 1541 serial connectors, an adaptor / dongle was required. Dave brewed up a USB to RS232 to TTL dongle. The finished MacBook USB to 1541 serial adaptor looks a bit messy, but did the job.&lt;/p&gt;
    &lt;p&gt;Next up, Dave communicated with the 1541, with its freshly baked KIM-1 ROMs, and dongle, via a Minicom terminal on his Mac. His hand typed assembly Hello World code worked first time (as far as we saw in the video).&lt;/p&gt;
    &lt;p&gt;Before signing off, Dave wanted to get a bit nearer to making the 1541 into a VIC-20 by adding a BASIC interpreter. He ported Tiny Basic to the KIM-1 and burned it to a ROM to insert on the 1541's PCB. Again, this worked, making it much quicker to code a Hello World program.&lt;/p&gt;
    &lt;p&gt;The TechTuber made it clear that this 1541 â€˜general purpose computerâ€™ remained very limited without major hardware mods due to its lack of I/O â€“ limiting it to serial terminal use. But we donâ€™t blame him for not wanting to mess with this precious retro hardware too much.&lt;/p&gt;
    &lt;p&gt;This project makes us wonder about the general purpose computing abilities of modern drive controller electronics.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;snemarch&lt;/header&gt;Iirc there was software (can't remember if any commercial games did it, or only demos) back in the day that would offload computation to the 1541 drive, but can't remember any specific titles right now.Reply&lt;lb/&gt;But I did stumble upon Freespin from 2021, which is kinda crazy â€“ it bit-bangs video and sound output ğŸ¤¯&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Jason Ka&lt;/header&gt;I recall that that there was a cartridge for the Commodore 64 that At Least doubled the load speed from the disk drive called â€œMach 5â€. I am wondering how it worked. Would that have had an effect on using the hard drive as it own computer?Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Fruitmaniac&lt;/header&gt;Yup. The C64 didn't have room for a disk controller so they put everything in the drive.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;blppt&lt;/header&gt;Reply&lt;quote/&gt;The 1541 was a buggy mess to the point where it defaulted to something ridiculous like 300 BYTES/sec transfer rates, though the mechanism was capable of much higher.Jason Ka said:I recall that that there was a cartridge for the Commodore 64 that At Least doubled the load speed from the disk drive called â€œMach 5â€. I am wondering how it worked. Would that have had an effect on using the hard drive as it own computer?&lt;lb/&gt;Epyx's Fast Load Cartridge was the popular fix for it---basically all it did was enable the 1541 to transfer at the rate it was originally supposed to.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;BFG-9000&lt;/header&gt;The $400 1541 was initially so unreliable that a host of 3rd party clone external floppy drives from many manufacturers popped up, usually selling for around half that price, and I had one (still have it, and it did not turn out to be as completely compatible as they claimed). All of those also used the $25 6502 because the closest equivalent from Intel in their 8080 was $370 for the chip alone. The low price was why it or a variant was used in many 8-bit computers through the 1970s and 80s from Acorn, Apple, Atari, and CommodoreReply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Tanakoi&lt;/header&gt;Reply&lt;quote/&gt;The original C64 didn't come with a hard drive, and even the floppy drive was an aftermarket purchase.Jason Ka said:I recall that that there was a cartridge for the Commodore 64 that At Least doubled the load speed from the disk drive called â€œMach 5â€. I am wondering how it worked. Would that have had an effect on using the hard drive as it own computer?&lt;lb/&gt;I can't recall its name, but there was one program that made the rounds back then which purported to raise the floppy drive's speed, but would literally make the drive catch fire if run.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomshardware.com/pc-components/cpus/commodore-64-floppy-drive-has-the-power-to-be-a-computer-bulky-1982-commodore-1541-5-25-inch-drive-packs-a-1-mhz-mos-6502-cpu"/><published>2026-01-07T15:37:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527775</id><title>Many Hells of WebDAV: Writing a Client/Server in Go</title><updated>2026-01-07T16:16:38.708073+00:00</updated><content>&lt;doc fingerprint="376b9954f126582c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Many Hells of WebDAV&lt;/head&gt;
    &lt;p&gt;Implementing a WebDAV/CalDAV client and server should be easy! Itâ€™s a well documented spec, standardized in the early 00s, and somewhat widely supported. At least, thatâ€™s the naive assumption we started from when creating one for Homechart.&lt;/p&gt;
    &lt;head rend="h2"&gt;Existing Go Implementations&lt;/head&gt;
    &lt;p&gt;Now before you mention NIH syndrome, yes, we looked at the existing Go implementation, go-webdav. This library was lacking some key features we needed, like server-side collection synchronization, and the interfaces didnâ€™t really align with our data model. This is also going to be a key feature of our product, so we should have some level of ownership for what gets implemented.&lt;/p&gt;
    &lt;head rend="h2"&gt;RFC Breadcrumbs&lt;/head&gt;
    &lt;p&gt;To start creating our client and server, we should read the RFCs, right? Well, where do you start?&lt;/p&gt;
    &lt;p&gt;How about the original, RFC 2518? Ah, looks like it was somewhat superseded by RFC 4918, but weâ€™re not going to tell you which parts! How about those extension RFCs? Thereâ€™s only 7 of themâ€¦&lt;/p&gt;
    &lt;p&gt;Reading through the RFCs, all that our implementation cares about is CRUD for Calendar events. After spending almost a month trying to implement the full RFC spec, we threw in the towel, thereâ€™s just to much legacy cruft that we didnâ€™t need.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reverse Engineering&lt;/head&gt;
    &lt;p&gt;With a decent understanding of the RFC in hand, we instead looked into reverse engineering existing clients and servers by inspecting their requests and responses. This process was MUCH faster, and we quickly had the API mapped out and what kind of requests/responses we needed to support.&lt;/p&gt;
    &lt;p&gt;We started by identifying the clients/servers we wanted to support:&lt;/p&gt;
    &lt;p&gt;Clients:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Calendar&lt;/item&gt;
      &lt;item&gt;DavX&lt;/item&gt;
      &lt;item&gt;Thunderbird&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Servers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple iCloud&lt;/item&gt;
      &lt;item&gt;Google Calendar&lt;/item&gt;
      &lt;item&gt;Radicale&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then ran HTTP proxies or Wireshark to capture the HTTP requests. Because WebDAV is so obtuse, you not only need to inspect the HTTP body, but also the headers!&lt;/p&gt;
    &lt;head rend="h2"&gt;XML in Go&lt;/head&gt;
    &lt;p&gt;As an aside, we spent quite a bit of time trying to make XML work well in Go. The default Go XML library is truly terrible, and we decided to create a wrapper around it for managing XML nodes similar to how JavaScript manages HTML nodes:&lt;/p&gt;
    &lt;code&gt;var davDisplayName = xmel.Element{
  Name:  "displayname",
  Space: davNS,
}

davDisplayName.SetValue("name")
n, err := davResponse.Find(davCollectionType)
davOwner = davOwner.AddChild(davHref.SetValue("http://example.com"))
&lt;/code&gt;
    &lt;p&gt;With WebDAV having such anâ€¦â€œunstructuredâ€ schema to a lot of the requests/responses, this library was key in helping us marshal/unmarshal things without writing a bunch of â€œbest caseâ€ structs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Standards are Just Suggestions&lt;/head&gt;
    &lt;p&gt;When we finally had our MVP built out, we put it to the test: validating our client and server against the existing implementations! For the most part, it worked as expected, but as always, things drift from the RFC.&lt;/p&gt;
    &lt;p&gt;Apple and Google, for instance, donâ€™t implement half of the RFCs, and basically provide a MVP for other clients to use. They donâ€™t really document what they support/donâ€™t support, as WebDAV is supposed to do it via HTTP responses advertising capabilities, but both seem to provide generic responses advertising capabilities they donâ€™t have a lot of the time.&lt;/p&gt;
    &lt;p&gt;The clients were another story. CalDAV clients are all over the place with what they support and how they will request it. Most clients should prefer to support &lt;code&gt;sync-collection&lt;/code&gt; as itâ€™s very efficient, but Apple Calendar doesnâ€™t, and uses ctags and etags instead.&lt;/p&gt;
    &lt;p&gt;As a little fish in a big pond, itâ€™s frustrating dealing with situations where big providers can skirt around some standards or add quirks for their implementations, but Iâ€™m required to follow them to the T because I donâ€™t have their inertia. I canâ€™t file a bug, or a lawsuit, against them claiming nonconformance, theyâ€™ll tell me to get bent. And you see this in other open source libraries too, where theyâ€™re littered with comments about workarounds for Googleâ€™s specific implementation or whatever.&lt;/p&gt;
    &lt;p&gt;I wouldnâ€™t recommend anyone who values their sanity to pursue creating a WebDAV/CalDAV library.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://candid.dev/blog/many-hells-of-webdav"/><published>2026-01-07T15:50:50+00:00</published></entry></feed>