<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-05T19:07:30.828828+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45479006</id><title>Managing context on the Claude Developer Platform</title><updated>2025-10-05T19:07:48.886925+00:00</updated><content>&lt;doc fingerprint="bf43ca3f38eb8046"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Managing context on the Claude Developer Platform&lt;/head&gt;
    &lt;p&gt;Today, we’re introducing new capabilities for managing your agents’ context on the Claude Developer Platform: context editing and the memory tool.&lt;/p&gt;
    &lt;p&gt;With our latest model, Claude Sonnet 4.5, these capabilities enable developers to build AI agents capable of handling long-running tasks at higher performance and without hitting context limits or losing critical information.&lt;/p&gt;
    &lt;head rend="h2"&gt;Context windows have limits, but real work doesn’t&lt;/head&gt;
    &lt;p&gt;As production agents handle more complex tasks and generate more tool results, they often exhaust their effective context windows—leaving developers stuck choosing between cutting agent transcripts or degrading performance. Context management solves this in two ways, helping developers ensure only relevant data stays in context and valuable insights get preserved across sessions.&lt;/p&gt;
    &lt;p&gt;Context editing automatically clears stale tool calls and results from within the context window when approaching token limits. As your agent executes tasks and accumulates tool results, context editing removes stale content while preserving the conversation flow, effectively extending how long agents can run without manual intervention. This also increases the effective model performance as Claude focuses only on relevant context.&lt;/p&gt;
    &lt;p&gt;The memory tool enables Claude to store and consult information outside the context window through a file-based system. Claude can create, read, update, and delete files in a dedicated memory directory stored in your infrastructure that persists across conversations. This allows agents to build up knowledge bases over time, maintain project state across sessions, and reference previous learnings without having to keep everything in context.&lt;/p&gt;
    &lt;p&gt;The memory tool operates entirely client-side through tool calls. Developers manage the storage backend, giving them complete control over where the data is stored and how it’s persisted.&lt;/p&gt;
    &lt;p&gt;Claude Sonnet 4.5 enhances both capabilities with built-in context awareness—tracking available tokens throughout conversations to manage context more effectively.&lt;/p&gt;
    &lt;p&gt;Together, these updates create a system that improves agent performance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable longer conversations by automatically removing stale tool results from context&lt;/item&gt;
      &lt;item&gt;Boost accuracy by saving critical information to memory—and bring that learning across successive agentic sessions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Building long-running agents&lt;/head&gt;
    &lt;p&gt;Claude Sonnet 4.5 is the best model in the world for building agents. These features unlock new possibilities for long-running agents—processing entire codebases, analyzing hundreds of documents, or maintaining extensive tool interaction histories. Context management builds on this foundation, ensuring agents can leverage this expanded capacity efficiently while still handling workflows that extend beyond any fixed limit. Use cases include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Coding: Context editing clears old file reads and test results while memory preserves debugging insights and architectural decisions, enabling agents to work on large codebases without losing progress.&lt;/item&gt;
      &lt;item&gt;Research: Memory stores key findings while context editing removes old search results, building knowledge bases that improve performance over time.&lt;/item&gt;
      &lt;item&gt;Data processing: Agents store intermediate results in memory while context editing clears raw data, handling workflows that would otherwise exceed token limits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Performance improvements with context management&lt;/head&gt;
    &lt;p&gt;On an internal evaluation set for agentic search, we tested how context management improves agent performance on complex, multi-step tasks. The results demonstrate significant gains: combining the memory tool with context editing improved performance by 39% over baseline. Context editing alone delivered a 29% improvement.&lt;/p&gt;
    &lt;p&gt;In a 100-turn web search evaluation, context editing enabled agents to complete workflows that would otherwise fail due to context exhaustion—while reducing token consumption by 84%.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;These capabilities are available today in public beta on the Claude Developer Platform, natively and in Amazon Bedrock and Google Cloud’s Vertex AI. Explore the documentation for context editing and the memory tool, or visit our cookbook to learn more.&lt;/p&gt;
    &lt;p&gt;Anthropic is not affiliated with, endorsed by, or sponsored by CATAN GmbH or CATAN Studio. The CATAN trademark and game are the property of CATAN GmbH.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/news/context-management"/><published>2025-10-05T05:20:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45479165</id><title>Social Cooling (2017)</title><updated>2025-10-05T19:07:48.704945+00:00</updated><content>&lt;doc fingerprint="3ab8db3d68f3a42d"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;LIKE OIL LEADS TO GLOBAL WARMING...&lt;/head&gt;
    &lt;head rend="h2"&gt;DATA LEADS TO SOCIAL COOLING&lt;/head&gt;
    &lt;head rend="h2"&gt;If you feel you are being watched, you change your behavior.&lt;/head&gt;
    &lt;head rend="h2"&gt;Big Data is supercharging this effect.&lt;/head&gt;
    &lt;head rend="h2"&gt;This could limit your desire to take risks or exercise free speech.&lt;/head&gt;
    &lt;head rend="h2"&gt;Over the long term these 'chilling effects' could 'cool down' society.&lt;/head&gt;
    &lt;head rend="h1"&gt;Your data is turned into thousands of different scores.&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;There are stars behind the cloud:&lt;/p&gt;
    &lt;p&gt;Databrokers compare your data to the data of people they know more about. By comparing the patterns they try to guess the likelihood of thousands of details that you may never have disclosed. These are actual examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Religion&lt;/item&gt;
      &lt;item&gt;Rape victim&lt;/item&gt;
      &lt;item&gt;Into dieting&lt;/item&gt;
      &lt;item&gt;Into gardening&lt;/item&gt;
      &lt;item&gt;Number of online friends&lt;/item&gt;
      &lt;item&gt;Number of real friends&lt;/item&gt;
      &lt;item&gt;IQ&lt;/item&gt;
      &lt;item&gt;Political views&lt;/item&gt;
      &lt;item&gt;Had abortion&lt;/item&gt;
      &lt;item&gt;Gullibility&lt;/item&gt;
      &lt;item&gt;Projected sexual orientation&lt;/item&gt;
      &lt;item&gt;Real sexual orientation&lt;/item&gt;
      &lt;item&gt;Reads magazines on travel&lt;/item&gt;
      &lt;item&gt;Reads books on travel&lt;/item&gt;
      &lt;item&gt;Planning to have a baby&lt;/item&gt;
      &lt;item&gt;Communication device preference&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Has house plants&lt;/item&gt;
      &lt;item&gt;Neuroticism&lt;/item&gt;
      &lt;item&gt;Openness&lt;/item&gt;
      &lt;item&gt;Date of Birth&lt;/item&gt;
      &lt;item&gt;Into Fashion&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Parents divorced before the age of 21&lt;/item&gt;
      &lt;item&gt;Economic stability&lt;/item&gt;
      &lt;item&gt;Potential inheritor&lt;/item&gt;
      &lt;item&gt;Extraversion&lt;/item&gt;
      &lt;item&gt;Agreeableness&lt;/item&gt;
      &lt;item&gt;Year house built&lt;/item&gt;
      &lt;item&gt;Smoker in the household&lt;/item&gt;
      &lt;item&gt;Has 'senior needs'&lt;/item&gt;
      &lt;item&gt;Has 'diabetic focus'&lt;/item&gt;
      &lt;item&gt;Easily addictable&lt;/item&gt;
      &lt;item&gt;Physical frailty&lt;/item&gt;
      &lt;item&gt;Gun owner&lt;/item&gt;
      &lt;item&gt;Adult 'empty nester'&lt;/item&gt;
      &lt;item&gt;Education level&lt;/item&gt;
      &lt;item&gt;Runs marathons&lt;/item&gt;
      &lt;item&gt;Into Elvis Memorabilia&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;People are starting to realize that this 'digital reputation' could limit their opportunities.&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;(And that these algorithms are often biased, and built on bad data.)&lt;/p&gt;
    &lt;head rend="h3"&gt;In the news&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;You may not get that dream job if your data suggests you're not a very positive person.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;If you are a woman you may see fewer ads for high paying jobs.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;If you have "bad friends" on social media you might pay more for your loan.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Tinder's algorithms might not show you attractive people if you are not desirable yourself.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Cambridge Analytica created psychological profiles on all Americans to try and dissuade people from voting.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;If you return goods to the store often this will be used against you.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;What you post on social media may influence your odds of getting a tax audit.&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Your health insurer may collect intimate data about your lifestyle, race and more.&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;People are changing their behavior to get better scores.&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;This has good and bad sides.&lt;/p&gt;
    &lt;head rend="h2"&gt;Social Cooling is a name for the long-term negative side effects of living in a reputation economy:&lt;/head&gt;
    &lt;head rend="h3"&gt;1. A culture of conformity&lt;/head&gt;
    &lt;p&gt;Have you ever hesitated to click on a link because you thought your visit might be logged, and it could look bad?&lt;/p&gt;
    &lt;p&gt;More and more people feel this pressure, and they are starting to apply self-censorship.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. A culture of risk-aversion&lt;/head&gt;
    &lt;p&gt;When doctors in New York were given scores this had unexpected results.&lt;lb/&gt; Doctors that tried to help advanced cancer patients had a higher mortality rate, which translated into a lower score.&lt;/p&gt;
    &lt;p&gt;Doctors that didn't try to help were rewarded with high scores, even though their patients died prematurely.&lt;/p&gt;
    &lt;p&gt;Rating systems can create unwanted incentives, and increase pressure to conform to a bureaucratic average.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Increased social rigidity&lt;/head&gt;
    &lt;p&gt;Digital reputation systems are limiting our ability and our will to protest injustice.&lt;/p&gt;
    &lt;p&gt;In China each adult citizen is getting a government mandated "social credit score". This represents how well behaved they are, and is based on crime records, what they say on social media, what they buy, and even the scores of their friends.&lt;/p&gt;
    &lt;p&gt;If you have a low score you can't get a government job, visa, cheap loan, or even a nice online date.&lt;/p&gt;
    &lt;p&gt;Social pressure is the most powerful and most subtle form of control.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; As our weaknesses are mapped..&lt;/p&gt;
    &lt;head rend="h1"&gt;We are becoming too transparent.&lt;/head&gt;
    &lt;head rend="h1"&gt;This is breeding a society where self-censorship and risk-aversion are the new normal.&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Yes, we've had credit ratings before. But this is a whole new scale, with an incredible level of automation, integration and accessibility.&lt;/p&gt;
    &lt;p&gt;The solution?&lt;/p&gt;
    &lt;head rend="h1"&gt;We should compare this problem to Global Warming.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Social Cooling is subtle&lt;/head&gt;The pollution of our social environment is invisible to most people, just like air pollution was at first.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Social Cooling is complex&lt;/head&gt;It cannot be solved by politicians, citizens, entrepreneurs or scientists on their own.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt;Public awareness is still very low.&lt;/head&gt;
    &lt;p&gt;It took 40 years to get the problems with oil on the agenda, and 80 years to get to where we are now.&lt;lb/&gt; We can't take that long with Social Cooling.&lt;/p&gt;
    &lt;head rend="h2"&gt;In the next 10 years we will need to spread a more mature and nuanced perception of data and privacy.&lt;/head&gt;
    &lt;head rend="h2"&gt;As pressure to be perfect rises we will learn what privacy really is:&lt;/head&gt;
    &lt;p/&gt;
    &lt;p&gt;&lt;lb/&gt;Can we still forgive and forget?&lt;/p&gt;
    &lt;head rend="h2"&gt;When algorithms judge everything we do, we need to protect the right to make mistakes.&lt;/head&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt; When everything is remembered as big data, we need the right to have our mistakes forgotten.&lt;/head&gt;
    &lt;p&gt;In our data driven world..&lt;/p&gt;
    &lt;head rend="h2"&gt;Help spread the word&lt;/head&gt;
    &lt;p&gt;These are privacy-friendly sharing buttons.&lt;/p&gt;
    &lt;p&gt;Site by Tijmen Schep - Technology critic, privacy designer and public speaker.&lt;/p&gt;
    &lt;head rend="h2"&gt;Like this? Then also visit Mathwashing.com, HowNormalAmI.eu or cloakingcompany.com.&lt;/head&gt;
    &lt;p&gt;Feel free to re-use content, it's all under a CC-BY 4.0 License.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.socialcooling.com/"/><published>2025-10-05T06:01:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45480106</id><title>Personal data storage is an idea whose time has come</title><updated>2025-10-05T19:07:48.175071+00:00</updated><content>&lt;doc fingerprint="f5359ed38cb08d8d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Personal data storage is an idea whose time has come&lt;/head&gt;
    &lt;p&gt;Back in 2009 Tim Berners-Lee drafted a web-specification for "Socially Aware Cloud Storage":&lt;/p&gt;
    &lt;quote&gt;There is an architecture in which a few existing or Web protocols are gathered together with some glue to make a world wide system in which applications (desktop or web application) can work on top of a layer of commodity read-write storage.&lt;lb/&gt;Crucial design issues are that principals (users) and groups are identifies by URIs, and so are global in scope, and that elements of storage are access controlled using those global identifiers. The result is that storage becomes a commodity, independent of the application running on it.&lt;/quote&gt;
    &lt;p&gt;Several of these ideas were going around in the late 2000s, shortly after the explosive growth of "web2" monoliths like Facebook.&lt;/p&gt;
    &lt;p&gt;Another spiritually similar idea being championed at the time came from the Opera browser folks who wanted to put "a web server in your browser".&lt;/p&gt;
    &lt;p&gt;While 'Opera Unite' never fully materialized, Tim's spec got significant traction some years down the road as one privacy crisis after another made the case for stronger web agency self-evident.&lt;/p&gt;
    &lt;p&gt;In 2015 Tim &amp;amp; co. secured some funding for the Solid Protocol.&lt;/p&gt;
    &lt;quote&gt;Right now we have the worst of both worlds, in which people not only cannot control their data, but also can’t really use it, due to it being spread across a number of different silo-ed websites. Our goal is to develop a web architecture that gives users ownership over their data, including the freedom to switch to new applications in search of better features, pricing, and policies.”&lt;/quote&gt;
    &lt;quote&gt;On the better web Berners-Lee envisions, users control where their data is stored and how it's accessed. For example, social networks would still run in the cloud. But you could store your data locally. Alternately, you could choose a different cloud server run by a company or community you trust.&lt;lb/&gt;You might have different servers for different types of information—for health and fitness data, say—that is completely separate from the one you use for financial records.&lt;/quote&gt;
    &lt;p&gt;To this day, Tim continues to eloquently champion the virtues of the Solid vision.&lt;/p&gt;
    &lt;quote&gt;We have the technical capability to give that power back to the individual. Solid is an open-source interoperable standard that I and my team developed at MIT more than a decade ago. Apps running on Solid don’t implicitly own your data – they have to request it from you and you choose whether to agree, or not. Rather than being in countless separate places on the internet in the hands of whomever it had been resold to, your data is in one place, controlled by you.&lt;lb/&gt;Sharing your information in a smart way can also liberate it. Why is your smartwatch writing your biological data to one silo in one format? Why is your credit card writing your financial data to a second silo in a different format? Why are your YouTube comments, Reddit posts, Facebook updates and tweets all stored in different places? Why is the default expectation that you aren’t supposed to be able to look at any of this stuff? You generate all this data – your actions, your choices, your body, your preferences, your decisions. You should own it. You should be empowered by it.&lt;/quote&gt;
    &lt;p&gt;The Solid Protocol remains an excellent idea and has even culminated in an official web specification, but Solid has not yet amounted to any mainstream adoption on the web. Its primary financial sponsor Inrupt (of which Tim is co-founder &amp;amp; CTO) has focused on the enterprise market as a path to sustainability; it remains to be seen what resources will be directed towards web-scale adoption of Solid.&lt;/p&gt;
    &lt;p&gt;Thankfully those of us who want data ownership and agency in our web applications now don't have to wait. AT Protocol was ushered in by the folks at Bluesky, now with a network of over 30M people strong and increasingly spread across multiple federated platforms/communities like Blacksky or Tangled.&lt;/p&gt;
    &lt;p&gt;While the respective architectures of the Solid and AT protocols are quite different, they're pointing to the same Open Social Web, re-built on the principles of user-sovereign data storage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Personal Data Storage&lt;/head&gt;
    &lt;p&gt;What web-user sovereignty looks like in practice, from the vantage point of atproto, has been expertly illustrated by danabra.mov&lt;/p&gt;
    &lt;quote&gt;Notice that Alice’s handle is now&lt;code&gt;@alice.com&lt;/code&gt;. It is not allocated by a social media company [like facebook.com/alice]. Rather, her handle is the universal “internet handle”, i.e. a domain. Alice owns the&lt;code&gt;alice.com&lt;/code&gt;domain, so she can use it as a handle on any open social app. (On most open social apps, she goes by&lt;code&gt;@alice.com&lt;/code&gt;, but for others she wants a distinct disconnected identity, so she owns another handle she’d rather not share.)&lt;lb/&gt;Bob owns a domain too, even though he isn’t technical. He might not even know what a “domain” is. Bob just thinks of&lt;code&gt;@bob.com&lt;/code&gt;as his “internet handle”. Some open social apps will offer you a free subdomain on registration, just like Gmail gives you a free Gmail address, or may offer an extra flow for buying a domain. You’re not locked into your first choice, and can swap to a different domain later.&lt;lb/&gt;(...) With open social, Alice’s data—her posts, likes, follows, etc—is hosted on the web itself. Alongside her personal site, Alice now has a personal repository of her data.&lt;/quote&gt;
    &lt;p&gt;This new paradigm is made technically possible by what the AT protocol refers to as a Personal Data Server or PDS for short (what Solid calls a Pod).&lt;/p&gt;
    &lt;p&gt;The notion of a 'PDS' quickly comes off as something very technical and nerdy which is why it's not mentioned once in Dan's explainer, even though it's still targeted at an audience of web nerds. But really the only obscure word here is the Server, which in this context is interchangeable with Storage, as in Personal Data Storage.&lt;/p&gt;
    &lt;p&gt;Even regular internet users have some mental model of what personalized data storage entails, especially with the complementary framing of collectively owned and operated data storage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data-banking Coops&lt;/head&gt;
    &lt;p&gt;If you're a regular internet user the PDS paradigm won't move your data from the cloud to your personal computer. Most people will still rely on an institutional cloud service, but instead of data-banking with a shareholder-controlled corporation most people’s data can be entrusted to the equivalent of member-owned credit unions for data storage.&lt;/p&gt;
    &lt;p&gt;One in every three US adults banks with a Credit Union. Achieving similar or better numbers for data storage is far from inconceivable considering how much our collective experience with Big Banking mirrors that of Big Tech/Social.&lt;/p&gt;
    &lt;p&gt;The concept of data cooperatives has already gained a lot of traction in the fediverse with several providers like social.coop, data.coop and cosocial.ca being operational for many years and still going strong. Soon the AT network will have a similarly co-owned institution in Northsky.&lt;/p&gt;
    &lt;p&gt;Whether these providers are strictly cooperatives in the formal sense isn't what's most important here though; any suffuciently transparent, democratic and community-oriented data bank (like the aforementioned Blacksky, or the forthcoming Eurosky) is a valid steward and co-creator of an Open Social.&lt;/p&gt;
    &lt;p&gt;Data Ownership as a conversation changes when data resides primarily with people-governed institutions rather than corporations. Rather than arguing for what kinds of data we ought to be able to download from the corporate silos, the platforms should be asking us what kinds of data they may copy from our servers, and only with strictly temporary allowances.&lt;/p&gt;
    &lt;p&gt;And while the separation of user data and social platform is most fully realized today in the AT network, there are exciting signs of cross-pollination happening in the ongoing development of atproto’s predecessor ActivityPub. I hope to see similar openness towards technological convergence in Solid for a more pluralistic social web.&lt;/p&gt;
    &lt;p&gt;Personal Data Storage has long since escaped containment as a concept pertaining to any specific protocol. Some implementations of it will be more mainstream than others, but pragmatic data coops can be protocol-agnostic and storage formats are transmutable.&lt;/p&gt;
    &lt;p&gt;As long as we have sufficient control of our own data there will always be a way to restart our social graph and digital presence elsewhere in the event of platform collapse. Let’s make the web personal again.&lt;/p&gt;
    &lt;p&gt;See also:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.muni.town/personal-data-storage-idea/"/><published>2025-10-05T09:07:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45480317</id><title>Self hosting 10TB in S3 on a framework laptop and disks</title><updated>2025-10-05T19:07:47.734009+00:00</updated><content>&lt;doc fingerprint="108fdf7d4527a9d6"&gt;
  &lt;main&gt;
    &lt;p&gt;About 5 months ago I made the decision to start self hosting my own S3. I was working on AppGoblin’s SDK tracking of the top 100k Android and iOS apps so was wanting a lot of space, but for cheap.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;I got really lucky with getting a second hand Framework laptop. The laptop was missing it’s screen, and was one of the older ones, so it was perfect for a home server. In addition I bought a “just a bunch of disks” JBOD. The framework laptop is running ZFS + garage S3. &lt;/p&gt;
    &lt;head rend="h2"&gt;I’m happy to report I haven’t thought about this laptop for months&lt;/head&gt;
    &lt;p&gt;I’ve been away, I’ve been working, I’ve been busy, and I’ve definitely been using my S3. But I hadn’t thought about the laptop in 4 months. When I finally logged in, I saw I’ve used 10TB of space and it was patiently waiting for a restart for some upgrades. I nervously restarted, and was so relieved to see everything come right back up.&lt;/p&gt;
    &lt;head rend="h2"&gt;I updated garage s3 with no issues as well&lt;/head&gt;
    &lt;p&gt;I also saw a pending upgrade for garage v1 to v2. This went along without a hitch too. Feels like it’s been a good weekend.&lt;/p&gt;
    &lt;head rend="h2"&gt;I’ve been warned…&lt;/head&gt;
    &lt;p&gt;Just so you know, I understand my use case for ZFS is possibly a bit non standard as I’m using a USB to connect the laptop and JBOD. This initially caused me issues with ZFS when garage was heavily reading and writing (the initial setup had the SQLite metadata also stored on the JBOD/ZFS).&lt;/p&gt;
    &lt;p&gt;I moved my metadata to the laptop, which has so far resolved any ZFS issues again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jamesoclaire.com/2025/10/05/self-hosting-10tb-in-s3-on-a-framework-laptop-disks/"/><published>2025-10-05T09:51:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45480506</id><title>Beginner Guide to VPS Hetzner and Coolify</title><updated>2025-10-05T19:07:47.365810+00:00</updated><content>&lt;doc fingerprint="fe08e21335a407ea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;VPS Setup and Security Checklist: Complete Self-Hosting Guide for 2025&lt;/head&gt;
    &lt;p&gt;I set up my own VPS, documented every step, and ended up with a repeatable deployment pipeline. This is both a checklist for my future self and a guide for anyone curious about self-hosting. Along the way I'll explain why I picked Hetzner and Coolify, and how they compare with other options like DigitalOcean, AWS, Render, or Fly.io.&lt;/p&gt;
    &lt;p&gt;This comprehensive checklist covers every essential step for setting up a secure, production-ready VPS. Each section includes commands, verification steps, and troubleshooting tips based on real-world experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pre-Setup Checklist&lt;/head&gt;
    &lt;p&gt;Before You Begin:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Choose your VPS provider (Hetzner recommended for price/performance)&lt;/item&gt;
      &lt;item&gt;Select server specifications (minimum 1GB RAM, 20GB storage)&lt;/item&gt;
      &lt;item&gt;Note down server IP address and root credentials&lt;/item&gt;
      &lt;item&gt;Prepare your local machine with SSH client&lt;/item&gt;
      &lt;item&gt;Have a strong password generator ready&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Picking the VPS provider&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chose Hetzner Cloud (cheap, fast, reliable in Europe)&lt;/item&gt;
      &lt;item&gt;Alternatives I considered: &lt;list rend="ul"&gt;&lt;item&gt;DigitalOcean → smoother onboarding, great docs, slightly more expensive&lt;/item&gt;&lt;item&gt;AWS Lightsail → decent for small apps, but tied to AWS ecosystem (complex for beginners)&lt;/item&gt;&lt;item&gt;Linode → reliable, but Hetzner wins on price/performance&lt;/item&gt;&lt;item&gt;Render/Fly.io → easier PaaS, but more opinionated and costly at scale&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why Hetzner?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2–3x cheaper for the same specs compared to DO/AWS&lt;/item&gt;
      &lt;item&gt;Strong European datacenter presence (latency advantage for my use case)&lt;/item&gt;
      &lt;item&gt;Transparent pricing and no surprise bills&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Initial Server Setup Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;First Login and System Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Initial login as root&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;ssh root@your-server-ip&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Update package lists and upgrade system&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;apt update &amp;amp;&amp;amp; apt upgrade -y&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify system information&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;uname -a cat /etc/os-release&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h4"&gt;Root Account Security&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Change root password&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;passwd&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Use strong password with mixed case, numbers, symbols
- Store securely in password manager
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create secondary user account&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;adduser your-username&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Choose descriptive username (not 'admin' or 'user')
- Set strong password
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add user to sudo group&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;usermod -aG sudo your-username&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify user groups&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;groups your-username&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Should show: `your-username : your-username sudo`
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test sudo access&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;su - your-username sudo whoami&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Should return: `root`
&lt;/code&gt;
    &lt;head rend="h4"&gt;SSH Key Authentication Setup&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Generate SSH keys on LOCAL machine (not server)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;#### Ed25519 (recommended) ssh-keygen -t ed25519 -C "your-email@example.com" ##### Or RSA if Ed25519 not supported ssh-keygen -t rsa -b 4096 -C "your-email@example.com"&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Display public key on local machine&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;cat ~/.ssh/id_ed25519.pub #### or cat ~/.ssh/id_rsa.pub&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Copy public key to clipboard&lt;/item&gt;
      &lt;item&gt;Create .ssh directory on server (as your user, not root)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;mkdir -p ~/.ssh chmod 700 ~/.ssh&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create authorized_keys file&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;nano ~/.ssh/authorized_keys&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Paste your public key
- Save and exit
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set correct permissions&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;chmod 600 ~/.ssh/authorized_keys&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test SSH key login (from local machine)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;ssh your-username@your-server-ip&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Should login without password prompt
&lt;/code&gt;
    &lt;head rend="h4"&gt;Disable Password Authentication&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Edit SSH configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/ssh/sshd_config&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modify these settings:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;PasswordAuthentication no PubkeyAuthentication yes&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check cloud-init config if exists&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/ssh/sshd_config.d/50-cloud-init.conf&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Set `PasswordAuthentication no` here too if file exists
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test SSH configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo sshd -t&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Should show no errors
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restart SSH service&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo systemctl restart ssh #### or sudo service ssh restart&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify service status&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo systemctl status ssh&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Should show active (running) with green dot
&lt;/code&gt;
    &lt;head rend="h4"&gt;Disable Root Login&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Edit SSH configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/ssh/sshd_config&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Change root login setting&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;PermitRootLogin no&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restart SSH service&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo systemctl restart ssh&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test root login is blocked (from another terminal)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;ssh root@your-server-ip&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Should get "Permission denied"
&lt;/code&gt;
    &lt;head rend="h2"&gt;Firewall Configuration Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;UFW (Uncomplicated Firewall) Setup&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check UFW status&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw status&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set default policies&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw default deny incoming sudo ufw default allow outgoing&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allow SSH before enabling firewall&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw allow ssh #### or if you changed SSH port: sudo ufw allow 2022/tcp&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allow HTTP and HTTPS for web apps&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw allow 80/tcp sudo ufw allow 443/tcp&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable firewall&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw enable&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Type 'y' when prompted
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify firewall rules&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw status verbose&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h4"&gt;Advanced Firewall Configuration&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restrict SSH to your IP (optional but recommended)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw allow from YOUR_IP_ADDRESS to any port 22 sudo ufw delete allow ssh&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Change default SSH port (optional security through obscurity)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/ssh/sshd_config&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Change `Port 22` to `Port 2022` (or your chosen port)
- Update firewall: `sudo ufw allow 2022/tcp`
- Remove old rule: `sudo ufw delete allow 22/tcp`
- Restart SSH: `sudo systemctl restart ssh`
&lt;/code&gt;
    &lt;head rend="h2"&gt;Automatic Updates Setup Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;Unattended Upgrades Configuration&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install unattended-upgrades&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo apt install unattended-upgrades apt-listchanges&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable automatic updates&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo dpkg-reconfigure unattended-upgrades&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Select "Yes" in the dialog
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configure update settings&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/apt/apt.conf.d/50unattended-upgrades&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uncomment security updates line&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;"${distro_id}:${distro_codename}-security";&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configure email notifications (optional)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;Unattended-Upgrade::Mail "your-email@example.com";&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable automatic reboots if needed&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;Unattended-Upgrade::Automatic-Reboot "true"; Unattended-Upgrade::Automatic-Reboot-Time "02:00";&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo unattended-upgrades --dry-run&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check service status&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo systemctl status unattended-upgrades&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h2"&gt;Production Application Deployment Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;Node.js Production Setup&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Node.js LTS&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash - sudo apt-get install -y nodejs&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify installation&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;node --version npm --version&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install PM2 globally&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo npm install -g pm2&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Upload your application files&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;scp -r ./your-app your-username@your-server-ip:~/&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install dependencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;cd ~/your-app npm install --production&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create production build&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;npm run build&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h4"&gt;Process Manager Configuration&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start application with PM2&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;NODE_ENV=production pm2 start app.js --name "your-app"&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configure PM2 for clustering (optional)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;pm2 start app.js -i max --name "your-app-cluster"&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Save PM2 configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;pm2 save&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable PM2 startup&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;pm2 startup #### Run the command it outputs&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test application restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;pm2 restart all pm2 status&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h4"&gt;Reverse Proxy Setup (Nginx)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Nginx&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo apt install nginx&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create site configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/nginx/sites-available/your-app&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Basic Nginx configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;server { listen 80; server_name your-domain.com; location / { proxy_pass http://localhost:3000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_cache_bypass $http_upgrade; } }&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable site&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ln -s /etc/nginx/sites-available/your-app /etc/nginx/sites-enabled/&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test Nginx configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nginx -t&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restart Nginx&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo systemctl restart nginx&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h2"&gt;SSL Certificate Setup Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;Let's Encrypt with Certbot&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Certbot&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo apt install certbot python3-certbot-nginx&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Obtain SSL certificate&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo certbot --nginx -d your-domain.com&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test automatic renewal&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo certbot renew --dry-run&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify SSL grade&lt;/item&gt;
      &lt;item&gt;Visit: https://www.ssllabs.com/ssltest/&lt;/item&gt;
      &lt;item&gt;Should get A or A+ rating&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Monitoring and Maintenance Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;Basic Monitoring Setup&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install monitoring tools&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo apt install htop iotop netstat-nat&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check system resources&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;htop df -h free -h&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monitor logs&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo tail -f /var/log/syslog sudo tail -f /var/log/auth.log&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set up log rotation&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo nano /etc/logrotate.d/your-app&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h4"&gt;Backup Strategy&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create backup script&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;nano ~/backup.sh&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sample backup script&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;#!/bin/bash DATE=$(date +%Y%m%d_%H%M%S) tar -czf ~/backups/app_backup_$DATE.tar.gz ~/your-app #### Add database backup commands if needed&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Make script executable&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;chmod +x ~/backup.sh&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set up automated backups&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;crontab -e&lt;/code&gt;&lt;/quote&gt;
    &lt;code&gt;- Add: `0 2 * * * /home/username/backup.sh`
&lt;/code&gt;
    &lt;head rend="h2"&gt;Troubleshooting Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;Common Issues and Solutions&lt;/head&gt;
    &lt;p&gt;SSH Connection Problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check firewall rules: &lt;code&gt;sudo ufw status&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Verify SSH service: &lt;code&gt;sudo systemctl status ssh&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check SSH logs: &lt;code&gt;sudo tail -f /var/log/auth.log&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Test from different network&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Permission Denied Errors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check file permissions: &lt;code&gt;ls -la&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Verify user groups: &lt;code&gt;groups username&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check sudo configuration: &lt;code&gt;sudo -l&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Service Not Starting:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check service status: &lt;code&gt;sudo systemctl status service-name&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;View service logs: &lt;code&gt;sudo journalctl -u service-name&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check configuration files syntax&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;High Resource Usage:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identify processes: &lt;code&gt;htop&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check disk usage: &lt;code&gt;df -h&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Monitor network: &lt;code&gt;netstat -tulpn&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Review application logs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Final Verification Checklist&lt;/head&gt;
    &lt;head rend="h4"&gt;Security Verification&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test SSH key authentication works&lt;/item&gt;
      &lt;item&gt;Verify password authentication is disabled&lt;/item&gt;
      &lt;item&gt;Confirm root login is blocked&lt;/item&gt;
      &lt;item&gt;Check firewall is active and configured&lt;/item&gt;
      &lt;item&gt;Verify automatic updates are working&lt;/item&gt;
      &lt;item&gt;Test application runs in production mode&lt;/item&gt;
      &lt;item&gt;Confirm SSL certificate is valid&lt;/item&gt;
      &lt;item&gt;Verify backups are being created&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Performance Testing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run basic load test&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;#### Install Apache Bench sudo apt install apache2-utils #### Test with 100 requests, 10 concurrent ab -n 100 -c 10 http://your-domain.com/&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monitor resource usage during load&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;htop&lt;/code&gt;&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check application logs for errors&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;tsx&lt;code&gt;pm2 logs&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h2"&gt;Quick Reference Commands&lt;/head&gt;
    &lt;p&gt;System Information:&lt;/p&gt;
    &lt;quote&gt;tsx&lt;code&gt;htop # System monitor df -h # Disk usage free -h # Memory usage uname -a # System info&lt;/code&gt;&lt;/quote&gt;
    &lt;p&gt;Process Management:&lt;/p&gt;
    &lt;quote&gt;tsx&lt;code&gt;pm2 status # PM2 process status pm2 restart all # Restart all processes pm2 logs # View logs pm2 monit # Real-time monitoring&lt;/code&gt;&lt;/quote&gt;
    &lt;p&gt;Security:&lt;/p&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo ufw status # Firewall status sudo fail2ban-client status # Fail2ban status sudo lynis audit system # Security audit&lt;/code&gt;&lt;/quote&gt;
    &lt;p&gt;Services:&lt;/p&gt;
    &lt;quote&gt;tsx&lt;code&gt;sudo systemctl status nginx # Service status sudo systemctl restart nginx # Restart service sudo journalctl -u nginx # Service logs&lt;/code&gt;&lt;/quote&gt;
    &lt;head rend="h2"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;This checklist provides a complete approach to VPS setup and management. This isn’t just about saving money. It’s about control and understanding. By self-hosting with Hetzner + Coolify, I built muscle memory for devops that paid off in confidence and freedom.&lt;/p&gt;
    &lt;p&gt;If you’ve been meaning to try VPS hosting, consider this a nudge.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bhargav.dev/blog/VPS_Setup_and_Security_Checklist_A_Complete_Self_Hosting_Guide"/><published>2025-10-05T10:39:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45480622</id><title>The deadline isn't when AI outsmarts us – it's when we stop using our own minds</title><updated>2025-10-05T19:07:47.034871+00:00</updated><content>&lt;doc fingerprint="3f37101d29eb8c85"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;“You have 18 months”&lt;/head&gt;
    &lt;head rend="h3"&gt;The real deadline isn’t when AI outsmarts us — it’s when we stop using our own minds.&lt;/head&gt;
    &lt;p&gt;In fitness, there is a concept called “time under tension.” Take a simple squat, where you hold a weight and lower your hips from a standing position. With the same weight, a person can do a squat in two seconds or 10 seconds. The latter is harder, but it also builds more muscle. More time is more tension; more pain is more gain.&lt;/p&gt;
    &lt;p&gt;Thinking benefits from a similar principle of “time under tension.” It is the ability to sit patiently with a group of barely connected or disconnected ideas that allows a thinker to braid them together into something that is combinatorially new. It’s very difficult to defend this idea by describing other people’s thought processes, so I’ll describe my own.&lt;/p&gt;
    &lt;p&gt;A few weeks ago, The Argument Editor-in-Chief Jerusalem Demsas asked me to write an essay about the claim that AI systems would take all of our jobs within 18 months. My initial reaction was … no?&lt;/p&gt;
    &lt;p&gt;The prediction is so stupendously aggressive and almost certainly wrong, so my instinct was there was really nothing more to say on the subject. Certainly not 1,799 words more. But as I sat with the prompt, several pieces of a puzzle began to slide together: a Financial Times essay I’d read, an Atlantic article I liked, a National Assessment of Educational Progress study I’d saved in a tab, an interview with Cal Newport I’d recorded, a Walter Ong book I was encouraged to read, a stray thought I’d had in the gym recently while trying out eccentric pullups for the first time about how time multiplies both pain and gain in fitness settings. The contours of a framework came into view.&lt;/p&gt;
    &lt;p&gt;The problem of the next 18 months isn’t AI disemploying all workers, or students losing competition after competition to nonhuman agents. The problem is whether we will degrade our own capabilities in the presence of new machines. We are so fixated on how technology will outskill us that we miss the many ways that we can deskill ourselves.&lt;/p&gt;
    &lt;p&gt;You have 18 months.&lt;/p&gt;
    &lt;p&gt;That’s the message from several leading AI executives and thinkers about how long people will retain their advantage over artificial intelligence in the workforce. By the summer of 2027, the story goes, AI’s explosion in capabilities will leave carbon-based life forms in the dust. Up to “half of all entry-level white-collar jobs” will be wiped out, and even Nobel Prize-worthy minds will cower in fear that AI’s architects will have built a “country of geniuses in a datacenter.”&lt;/p&gt;
    &lt;p&gt;This doomsday clock seems true enough to many people, because the question I’ve fielded more than any other from parents in the last few months is some version of: “If AI is about to be better than us at everything, what should my children do?” If generative AI is better at coding, diagnosing, and problem-solving than any software programmer, radiologist, or mathematician, then even the traditionally “safe” majors like computer science, medicine, and math could be anything but safe.&lt;/p&gt;
    &lt;p&gt;I understand the anxiety behind the question, but rather than try to forecast the future as it might turn out, I’d prefer to describe reality as it already exists. While we have no idea how AI might make working people obsolete at some imaginary date, we can already see how technology is affecting our capacity to think deeply right now. And I am much more concerned about the decline of thinking people than I am about the rise of thinking machines.&lt;/p&gt;
    &lt;head rend="h3"&gt;The end of writing, the end of reading&lt;/head&gt;
    &lt;p&gt;In March, New York Magazine published the sort of cover story that goes instantly viral, not because of its shock value, but, quite the opposite, because it loudly proclaimed what most people were already thinking: Everybody is using AI to cheat in school.&lt;/p&gt;
    &lt;p&gt;By allowing high-school and college students to summon into existence any essay on any topic, large language models have created an existential crisis for teachers trying to evaluate their students’ ability to actually write. “College is just how well I can use ChatGPT at this point,” one student told New York Magazine. “Massive numbers of students are going to emerge from university with degrees, and into the workforce, who are essentially illiterate,” a professor echoed.&lt;/p&gt;
    &lt;p&gt;The demise of writing matters because writing is not a second thing that happens after thinking. The act of writing is an act of thinking. This is as true for professionals as it is for students. In “Writing is thinking,” an editorial in Nature, the authors argued that “outsourcing the entire writing process to LLMs” deprives scientists of the important work of understanding what they’ve discovered and why it matters.&lt;/p&gt;
    &lt;p&gt;Students, scientists, and anyone else who lets AI do the writing for them will find their screens full of words and their minds emptied of thought.&lt;/p&gt;
    &lt;p&gt;As writing skills have declined, reading has declined even more. “Most of our students are functionally illiterate,” a pseudonymous college professor using the name Hilarius Bookbinder wrote in a March Substack essay on the state of college campuses. “This is not a joke.” Nor is it hyperbole.&lt;/p&gt;
    &lt;p&gt;Achievement scores in literacy and numeracy are declining across the West for the first time in decades, leading the Financial Times reporter John Burn-Murdoch to wonder if humans have “passed peak brain power” at the very moment that we are building machines to think for us. In the U.S., the so-called Nation’s Report Card, published by the NAEP, recently found that average reading scores hit a 32-year low in 2024 — which is troubling, since the data series only goes back 32 years.&lt;/p&gt;
    &lt;p&gt;Of course, Americans are reading words all the time: email, texts, social media newsfeeds, subtitles on Netflix shows. But these words live in writing fragments that hardly require any kind of sustained focus necessary to make sense of a larger text. Indeed, Americans in the digital age don’t seem interested in or capable of sitting with anything longer than a tweet. The share of Americans overall who say they read books for leisure has declined by nearly 40% since the 2000s.&lt;/p&gt;
    &lt;p&gt;Even America’s highest-performing students have essentially stopped reading anything longer than a paragraph. Last year, The Atlantic’s Rose Horowitch reported that students are matriculating into America’s most-elite colleges without having ever read a full book for school. “Daniel Shore, the chair of Georgetown’s English department, told me that his students have trouble staying focused on even a sonnet,” Horowitch wrote.&lt;/p&gt;
    &lt;p&gt;Nat Malkus, an education researcher at the American Enterprise Institute, suggested to me that high schools have chunkified books to prepare students for the reading-comprehension sections of standardized exams. By optimizing the assessment of reading skills, the U.S. education system appears to have accidentally killed book reading.&lt;/p&gt;
    &lt;p&gt;The decline of writing and reading matters because writing and reading are the twin pillars of deep thinking, according to Cal Newport, a computer science professor and the author of several bestselling books, including Deep Work. The modern economy prizes the sort of symbolic logic and systems thinking for which deep reading and writing are the best practice.&lt;/p&gt;
    &lt;p&gt;AI is “the latest in multiple heavyweight entrances into the prize fight against our ability to actually think,” Newport said. The rise of TV corresponded with the decline in per capita newspaper subscriptions and a slow demise of reading for pleasure. Then along came the internet, followed by social media, the smartphone, and streaming TV.&lt;/p&gt;
    &lt;p&gt;“The one-two punch of reading and writing is like the serum we have to take in a superhero comic book to gain the superpower of deep symbolic thinking,” Newport said. “And so I have been ringing this alarm bell that we have to keep taking the serum.”&lt;/p&gt;
    &lt;p&gt;Newport’s warning echoes an observation made by the scholar Walter Ong in his book “Orality and Literacy.” According to Ong, literacy is no passing skill. It was a means of restructuring human thought and knowledge to create space for complex ideas.&lt;/p&gt;
    &lt;p&gt;Stories can be memorized by people who cannot read or write. But nothing as advanced as, say, Newton’s “Principia” could be passed down from generation to generation without the ability to write down calculus formulas. Oral dialects commonly have only a few thousand words, while “the grapholect known as standard English has … at least a million and a half words,” Ong wrote. If reading and writing “rewired” the logic engine of the human brain, the decline of reading and writing are unwiring our cognitive superpower at the very moment that a greater machine appears to be on the horizon.&lt;/p&gt;
    &lt;p&gt;So what should our children study in an age of thinking machines? While I don’t know what field any particular student should major in, I do feel strongly about what skill they should value: It’s the very same skill that I see in decline. It’s the patience to read long and complex texts; to hold conflicting ideas in our heads and enjoy their dissonance; to engage in hand-to-hand combat at the sentence level within a piece of writing — and to value these things at a time when valuing them is a choice, because video entertainment is replacing reading and ChatGPT essays are replacing writing. As AI becomes abundant, there is a clear and present threat that deep human thinking will become scarce.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theargumentmag.com/p/you-have-18-months"/><published>2025-10-05T11:08:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45481008</id><title>86 GB/s bitpacking with ARM SIMD (single thread)</title><updated>2025-10-05T19:07:46.901190+00:00</updated><content>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ashtonsix/perf-portfolio/tree/main/bytepack"/><published>2025-10-05T12:27:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45481298</id><title>Show HN: Pyscn – Python code quality analyzer for vibe coders</title><updated>2025-10-05T19:07:46.160882+00:00</updated><content>&lt;doc fingerprint="9e863d005f1db92f"&gt;
  &lt;main&gt;
    &lt;p&gt;Building with Cursor, Claude, or ChatGPT? pyscn performs structural analysis to keep your codebase maintainable.&lt;/p&gt;
    &lt;code&gt;# Run analysis without installation
uvx pyscn analyze .
# or
pipx run pyscn analyze .&lt;/code&gt;
    &lt;head class="px-3 py-2"&gt;pyscn_20251005.mov&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔍 CFG-based dead code detection – Find unreachable code after exhaustive if-elif-else chains&lt;/item&gt;
      &lt;item&gt;📋 Clone detection with APTED + LSH – Identify refactoring opportunities with tree edit distance&lt;/item&gt;
      &lt;item&gt;🔗 Coupling metrics (CBO) – Track architecture quality and module dependencies&lt;/item&gt;
      &lt;item&gt;📊 Cyclomatic complexity analysis – Spot functions that need breaking down&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;100,000+ lines/sec • Built with Go + tree-sitter&lt;/p&gt;
    &lt;p&gt;Run comprehensive analysis with HTML report&lt;/p&gt;
    &lt;code&gt;pyscn analyze .                              # All analyses with HTML report
pyscn analyze --json .                       # Generate JSON report
pyscn analyze --select complexity .          # Only complexity analysis
pyscn analyze --select deps .                # Only dependency analysis
pyscn analyze --select complexity,deps,deadcode . # Multiple analyses&lt;/code&gt;
    &lt;p&gt;Fast CI-friendly quality gate&lt;/p&gt;
    &lt;code&gt;pyscn check .                      # Quick pass/fail check
pyscn check --max-complexity 15 .  # Custom thresholds&lt;/code&gt;
    &lt;p&gt;Create configuration file&lt;/p&gt;
    &lt;code&gt;pyscn init                         # Generate .pyscn.toml&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;💡 Run&lt;/p&gt;&lt;code&gt;pyscn --help&lt;/code&gt;or&lt;code&gt;pyscn &amp;lt;command&amp;gt; --help&lt;/code&gt;for complete options&lt;/quote&gt;
    &lt;p&gt;Create a &lt;code&gt;.pyscn.toml&lt;/code&gt; file or add &lt;code&gt;[tool.pyscn]&lt;/code&gt; to your &lt;code&gt;pyproject.toml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# .pyscn.toml
[complexity]
max_complexity = 15

[dead_code]
min_severity = "warning"

[output]
directory = "reports"&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;⚙️ Run&lt;/p&gt;&lt;code&gt;pyscn init&lt;/code&gt;to generate a full configuration file with all available options&lt;/quote&gt;
    &lt;code&gt;# Install with pipx (recommended)
pipx install pyscn

# Or run directly with uvx
uvx pyscn&lt;/code&gt;
    &lt;head&gt;Alternative installation methods&lt;/head&gt;
    &lt;code&gt;git clone https://github.com/ludo-technologies/pyscn.git
cd pyscn
make build&lt;/code&gt;
    &lt;code&gt;go install github.com/ludo-technologies/pyscn/cmd/pyscn@latest&lt;/code&gt;
    &lt;code&gt;# .github/workflows/code-quality.yml
name: Code Quality
on: [push, pull_request]

jobs:
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: pip install pyscn
      - name: Quick quality check
        run: pyscn check .
      - name: Generate detailed report
        run: pyscn analyze --json --select complexity,deadcode,deps src/
      - name: Upload report
        uses: actions/upload-artifact@v4
        with:
          name: code-quality-report
          path: .pyscn/reports/&lt;/code&gt;
    &lt;p&gt;📚 Development Guide • Architecture • Testing&lt;/p&gt;
    &lt;p&gt;MIT License — see LICENSE&lt;/p&gt;
    &lt;p&gt;Built with ❤️ using Go and tree-sitter&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ludo-technologies/pyscn"/><published>2025-10-05T13:22:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45481609</id><title>Retiring Test-Ipv6.com</title><updated>2025-10-05T19:07:45.791880+00:00</updated><content>&lt;doc fingerprint="3e399bddbaeb15e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Retiring test-ipv6.com&lt;/head&gt;
    &lt;p&gt;TL;DR: I will retire test-ipv6.com in December 2025.&lt;/p&gt;
    &lt;p&gt;I have provided test-ipv6.com to the public since 2010. I've sunk significant resources - engineering, support, equipment, and hosting fees - into what is a revenue-free product.&lt;/p&gt;
    &lt;p&gt;Without going into details: I feel now is the time for me to refocus my resources within the family.&lt;lb/&gt; I hope people will understand, and respect this decision.&lt;/p&gt;
    &lt;p&gt;I am shutting the site down, with a target of "during winter break" (December) 2025.&lt;/p&gt;
    &lt;p&gt;Mirror operators: Should you wish to keep your mirrors up, they will stop getting updates in December.&lt;/p&gt;
    &lt;p&gt;Service providers: If you have runbooks for your support team based on this site, or based on RIPE-631, you'll need to update those.&lt;/p&gt;
    &lt;p&gt;FAQ:&lt;/p&gt;
    &lt;p&gt;Q: Will I (jfesler) transfer the source?&lt;/p&gt;
    &lt;p&gt;A: These portions are already public.&lt;/p&gt;
    &lt;p&gt;These are already public.&lt;lb/&gt; http://github.com/falling-sky/source&lt;lb/&gt; https://github.com/falling-sky/fsbuilder - used to build what's in source&lt;lb/&gt; https://github.com/falling-sky/mod_ip - the /ip/ handler for Apache&lt;lb/&gt; https://github.com/falling-sky/mtu1280d - the synthetic MTU180 netfilter daemon.&lt;/p&gt;
    &lt;p&gt;The remaining parts, such as geolocation and service provider lookups, I am contractually unable to release. Please do not ask.&lt;/p&gt;
    &lt;p&gt;Q: Will I (jfesler) transfer the domain?&lt;/p&gt;
    &lt;p&gt;A: I’d consider a reputable RIR or NIC organization serving the public interest taking things over.&lt;/p&gt;
    &lt;p&gt;Q: Should mirrors be retired?&lt;/p&gt;
    &lt;p&gt;A: I would suggest it. Once the primary site is retired, I will stop monitoring the functionality of your mirror, and stop providing geolocation and service provider lookups.&lt;/p&gt;
    &lt;p&gt;Q: I have more questions or comments!&lt;/p&gt;
    &lt;p&gt;A: If we ever meet for coffee or beer, ask me then.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://retire.test-ipv6.com/"/><published>2025-10-05T14:11:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45481892</id><title>The QNX Operating System</title><updated>2025-10-05T19:07:45.269597+00:00</updated><content>&lt;doc fingerprint="ff9e891d51a325c6"&gt;
  &lt;main&gt;
    &lt;p&gt;Gordon Bell and Dan Dodge were finishing their time at the University of Waterloo in Ontario in 1979. In pursuit of their masters degrees, they’d worked on a system called Thoth in their real-time operating systems course. Thoth was interesting not only for having been real-time and having featured synchronous message passing, but also for originally having been written in the B programming langue. It was then rewritten in the UW-native Eh language (fitting for a Canadian university), and then finally rewritten in Zed. It is this last, Zed-written, version of Thoth to which Bell and Dodge would have been exposed. Having always been written in a high-level language, the system was portable, and programs were the same regardless of the underlying hardware. Both by convention and by design, Thoth strongly encouraged programs to be structured as networks of communicating processes. As the final project for the RTOS course, students were expected to implement a real-time system of their own. This experience was likely pivotal to their next adventure.&lt;/p&gt;
    &lt;p&gt;The duo’s first year after graduation was a busy one. They moved to Kanata, went to work for Bell-Northern Research (now Nortel), and on the 30th of March in 1980, they founded Quantum Software Systems. To continue their research and experimentation with operating systems, they assembled a microcomputer built around a Motorola 6809. With the release of the IBM PC in September of 1981, Quantum’s efforts shifted to that target. Their goal was to produce a real-time operating system that would enable the PC’s use in factories, communication systems, and anywhere else that emphasized reliability.&lt;/p&gt;
    &lt;p&gt;The first version of Bell and Dodge’s operating system was QUNIX 0.1 (the Q could have been for Quantum, or for Quick, I’ve seen both from former Quantum employees), and it was running on that early, hand-assembled, 8bit microcomputer. This earliest creation was never released outside of Quantum Software as far as I know. QUNIX was a vaguely UNIX-like, microkernel, real-time operating system. I say that it was vaguely UNIX-like because in these early versions, there were some serious differences. In QUNIX, there were CP/M-like things too. Each disk had a drive number prefix, non-disk device files’ names were reserved, and the commands were a bit different from those in UNIX, often simplified to the point of being more CP/M-like than UNIX-like. Another major difference was the directory hierarchy. On a traditional UNIX system, binaries were stored in &lt;code&gt;/bin&lt;/code&gt; or &lt;code&gt;/usr/bin&lt;/code&gt;, configurations in &lt;code&gt;/etc&lt;/code&gt;, and user directories in &lt;code&gt;/home&lt;/code&gt;. On QUNIX, this wasn’t the case. Commands included in the path variable were in &lt;code&gt;/cmds&lt;/code&gt;, configuration files were in &lt;code&gt;/config&lt;/code&gt;, the OS binaries were in &lt;code&gt;/sys&lt;/code&gt;, user directories were &lt;code&gt;/user&lt;/code&gt;, drivers were in &lt;code&gt;/drivers&lt;/code&gt;, and utilities were in &lt;code&gt;/util&lt;/code&gt;. Then, the &lt;code&gt;man&lt;/code&gt; command did not exist, and &lt;code&gt;help&lt;/code&gt; was used instead. Instead of &lt;code&gt;ps&lt;/code&gt;, the system had &lt;code&gt;task&lt;/code&gt; with the labels of father, son, and brother to denote parent and child processes. The first version of QUNIX for the IBM PC was made before the end of 1981, and released either in December of 1981 or January of 1982, making QUNIX the first known microkernel operating system for the PC platform.&lt;/p&gt;
    &lt;p&gt;A fun note from Paul N. Leroux, the bar chart on the monitor in the back left was physically glued to that monitor for another press image. It wasn’t meant to be in this image, but as photo editing tools were essentially non-existent at the time, fixing this would have required them to reshoot. They chose to go to press with bar chart present.&lt;/p&gt;
    &lt;p&gt;With QUNIX 0.4.33 in 1982, QUNIX became the first operating system for the IBM PC to support a hard disk, and in particular, it supported a 5MB Davong HDD. Given that a 10MB disk in 1982 could cost around $3000, it makes sense that the company’s first target was a bit more modest. At this point, however, QUNIX would not boot from an HDD. All of the floppy contents could be copied to a hard disk, but the user would still need to boot from a floppy disk.&lt;/p&gt;
    &lt;p&gt;Even in these early stages of development, the system began getting recognition, and this became a small problem. The name QUNIX was a bit too close to the name UNIX for AT&amp;amp;T. The name of the system was changed to QNX in late 1982 following a Cease and Desist by AT&amp;amp;T. The first official QNX version was released the following year. At the time of the name change the kernel consisted of around 10K line of C, and it handled task scheduling, message passing, and task priority. Everything else was implemented in services that used the microkernel’s message passing to communicate with each other (even drivers, filesystems, and networking). As an important feature, message queues were network transparent so a task on one physical machine could communicate with a task on a separate physical machine on the same network as easily as if it were local. This inherently multitasked and multiuser system allowed 250 simultaneous tasks from 4 to 16 simultaneous users. The system would make extensive use of the 8087 if it was available, and required a minimum of 96K RAM. Loading up the C compiler would require an additional 32K. It’s impressive what the small company achieved on the 8088, even if, for the time, the RAM requirements were quite high. QNX release version 1.0, in March of 1983, running on an IBM PC achieved 29% to 47% the speed of a DEC VAX 11/780 depending upon the task at hand when tested by Rao Mikkilineni at Bell Labs. Sadly, I’ve been unable to find his original write-up of his testing, which was apparently in the publication Personna. If you have information about it, I’d love to get some details. While RV1 was limited to just C and x86 assembly language, the company was hard at work on BASIC, FORTRAN, and Pascal compilers that would utilize common code generators allowing for the mixed-use of languages without losing optimization. With the introduction of GUIs on the Apple Lisa, Xerox systems, and VisiCorp’s Visi-On, Quantum also had plans for windowing as well. According to Quantum’s president Syd Geraghty in InfoWorld on the 21st of March in 1983, the majority of customers were high-end system developers at large corporations. Version 1.0 cost $650 in 1983 (around $2100 in 2025), and that included a C compiler, full-screen editor, the ability to read MS-DOS disks, and full networking support. I haven’t found much information about versions 1.1 through 1.14, but I did find some information about 1.20 released on the 15th of November in 1984. This version brought pattern matching on filenames in the current directory, expanded shell programming, &lt;code&gt;login&lt;/code&gt; was now a separate task with fast user switching and login stacking, &lt;code&gt;TCAP&lt;/code&gt; (think terminfo), &lt;code&gt;ed&lt;/code&gt; was rewritten and supported full-screen visual mode (think Vi), and support for the IBM AT (real-mode) was added. The price of QNX had also fallen to $450.&lt;/p&gt;
    &lt;p&gt;In June of 1981, the Ontario Ministry of Education identified computing as being important for the future, and they wanted to bring computing into their schools. They were also quite aware that some teachers had taken the initiative to bring microcomputers into their classrooms already, and the Commodore PET was the most common for programming courses, while the Apple II was the most common for other educational programs. Targeting many computers would have meant that they’d have rather high software development costs in any attempt to achieve standardization, and it was therefore decided that they’d need a single computer. In 1983, it was found by the ministry and the Canadian Advanced Technology Alliance that no existing computer would fully satisfy the goals of their educational computer. By March that year, some requirements had been drafted: all-in-one PET-like design, headphone output for voice and sound, a trackball, an 80186 CPU, a multitasking operating system, color graphics, voice synthesis, keyboard with accented characters, and networked storage (no physical disk in the computer itself). This machine as described had the sobriquet “bionic beaver.”&lt;/p&gt;
    &lt;p&gt;With the specifications in hand, Robert Arn at CATA created CEMCORP (Canadian Educational Microprocessor Corporation) and won a contract from the ministry for $10 million to develop the initial machines. This resulted in the ICON having been chosen. This machine was initially manufactured by Microtel and it ran QNX from Quantum Software Systems. The first machines were delivered in 1984. Later machines were produced, sold, and supported by Burroughs Canada, and after the merger with Sperry in 1986, by Unisys.&lt;/p&gt;
    &lt;p&gt;The ICON was built around an Intel 80186 clocked at 7.16MHz and 512K RAM. It lacked any local storage having neither a hard disk drive nor floppy disk drive. At boot, the computer grabbed QNX from a local LexICON file server over a 2.5Mbps ARCNET connection, and loaded the OS into RAM. Once loaded, the user logged into the system and his/her home directory was on the file server. Up to 32 of these machines could be on a single LAN. Saving any work to a floppy, meant putting the floppy into the file server, and then copying the file from the LexICON hard disk (early models were 10MB, later models were 64MB) to that floppy. The cost of these machines was high at $2500, but any school need only have paid $495 with the government covering the rest. One incredibly forward thinking feature was the lessonware. This would have been a hypertext system in which educators could have written pages that linked to others building an extensive corpus overtime. Even applications could have been run by simply clicking a link. This model was rejected by the ministry before the ICON shipped, and was replaced by a top-down system with ministry making lesson decisions. This also resulted in the ICON having shipped a QNX CLI with the CEMCORP text editor in the earliest models.&lt;/p&gt;
    &lt;p&gt;The ICON was a project hated by many and loved by many. For detractors, it was seen as expensive and wasteful while not exposing students to industry currents. For supporters, it accomplished all of its goals. It was excellent for programming, and it was excellent at multitasking, networking, and running educational software. The software was also quite reliable. It was QNX doing what QNX does best.&lt;/p&gt;
    &lt;p&gt;From students who used ICONs, we know that it did have educational games, text editors, compilers, word processors, spread sheets, circuit design and simulation software, and CAD software. Of course, being networked machines, some unconventional students figured out ways to hack into other machines over the network, print stuff to other students’ screens, and generally cause some chaos. Combined with audio capabilities (later models even included MIDI support), this apparently got a bit out of hand from time to time.&lt;/p&gt;
    &lt;p&gt;I normally wouldn’t show so many ads, but here is a development that is rather interesting. OS/2 had been announced on the 2nd of April in 1987, and Quantum perceived the OS as a real threat. The comparisons to UNIX were now joined by comparisons to OS/2, and QNX wanted to be certain that people understood QNX to be superior. This advertisement also shows us that QNX had responded to OS/2’s ability to run DOS software by adding that feature to QNX with the QDOS II (invoked as &lt;code&gt;QDOS&lt;/code&gt;) emulator, or by running a DOS application as a task via &lt;code&gt;RUNDOS&lt;/code&gt;. QNX had been ported to the IBM PS/2 as well. This was QNX version 2.&lt;/p&gt;
    &lt;p&gt;As far as I can tell, the release of QNX version 2 was announced on the release date of version 1.2. The release of this version appears to have been quite late, and it occurred in autumn of 1987 (two years after the initial release date given). This release brought protected-mode support for the IBM AT, full LAN support with some networking enhancements ported from BSD, support for files of up to one terabyte in size, up to 32 serial ports in one machine, and a somewhat primitive GUI called House about which I can find nothing but the name.&lt;/p&gt;
    &lt;p&gt;While I couldn’t find anything about the House graphical environment, QNX Windows running the Open Look Window Manager (OLWM) is available.&lt;/p&gt;
    &lt;p&gt;In June of 1987, Quantum Software Systems ceased renting their office space, and they moved into a building they’d had built just for them. Following this, the company would expand the building three times, and finally add another building. So, the company moved from 215 Stafford Road to 175 Terrance Mathews Crescent.&lt;/p&gt;
    &lt;p&gt;As late as 1990, QNX advertisements still mentioned performance on the 80286. This seems more as though Quantum didn’t spend much on marketing rather than not having progressed. In Dan Hildebrand’s An Architectural Overview of QNX from April of 1992, we find that the company had developed QNX versions up to 3.15, and articles about operating systems in the tech press had mentioned QNX as one of the systems that took advantage of features in the 80386.&lt;/p&gt;
    &lt;p&gt;In 1989, Quantum Software Systems began work on a dramatic overhaul of the operating system. This new version would be fully POSIX-compliant and increase performance over the prior generation of QNX operating systems. This version, 4.0, was released in 1991. The kernel now had just 14 calls associated with IPC, network, scheduling, and interrupts, and the kernel weighed in at just 7K (605 LOC), allowing the entire kernel to fit in CPU caches of the time. Unlike earlier versions, messages were no longer queued. Instead, they were copied from process to process. Being POSIX-compliant allowed for the easier porting of software, and it also meant that the directory hierarchy was decidedly more familiar to UNIX veterans. Beyond source compatibility, Quantum was actively working on becoming binary compatible with UNIX as of 1992. In 1994, beyond POSIX and performance, QNX 4.1 introduced the QNX Photon microGUI. This system was developed by Patrick Hayden and Robin Burgener. Much like the underlying system, it was built around a microkernel (around 20K), and it was network transparent. A Photon application could have its interface beamed to another QNX 4 machine at any point in time, or it could be dragged from one device to another just as easily. Photon likewise allowed remote monitoring or control of the user interface. This worked regardless of the device class (desktop, laptop, handheld, server). For those who needed it, the X Windows System (X11R5, Motif Window Manager) was also available, though Photon did implement a binary interface library that was X compatible. Being so lightweight allowed the company to release a demo disk that combined networking, a web browser, web server, graphical environment, file manager, text editor, a vector animation demo, and Towers of Hanoi game onto a single 1.44MB floppy. Unlike prior QNX versions, version 4 required at least an Intel 80386 and VGA graphics card. No 16bit systems were supported.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;KANATA, ONTARIO, September, 1994—QNX Software Systems Ltd., developers of the QNX realtime operating system, announced a unique window system targeted for handheld and embedded applications.&lt;/p&gt;&lt;lb/&gt;According to Rob Oakley, Corporate Communications and Product Management, "the Photon Window System is the first of its kind—a GUI built around a graphical microkernel."&lt;lb/&gt;QNX Software Systems designed the Photon Window System as a graphical microkernel and a team of cooperating processes, basing this design on the company's QNX OS, a microkernel network-distributed system.&lt;lb/&gt;Photon's cooperating processes provide the functionality to scale the system up into a full-featured windowing system or down to fit into resource-constrained environments, like handheld personal computers (HPCs) and compact embedded systems.&lt;lb/&gt;Photon provides a rich widget library that operates much like the X Window System widget set, with an X-inspired API. A Motif-like window manager and a code-generating, visual application builder are also available.&lt;lb/&gt;"Photon is extremely light and fast. It runs in only 256K, yet provides enormous GUI functionality," Oakley said.&lt;lb/&gt;Like the QNX OS itself, Photon is network transparent—an HPC running Photon and QNX, equipped with a wireless LAN interface, becomes a transparent extension of the LAN, able to use all the LAN's resources as if they were integrated directly into the HPC. The power this brings to the HPC user is difficult to appreciate—imagine having the power of 100 Pentiums in the palm of your hand!&lt;lb/&gt;According to Dan Dodge, Vice President R&amp;amp;D, "Photon applications are very network distributed. From the application's perspective, all the resources of all the nodes on the LAN look like a single, logical machine. The environment is so transparent that a user can drag applications from one physical screen to another."&lt;lb/&gt;For example, a user in a factory control environment could walk up to a computer and drag an application from the control screen onto an HPC, and then walk out onto the factory floor with it and interact with the live application.&lt;lb/&gt;Although Photon is aimed at compact environments, its dynamic range is extensive. "Photon's API and rich widget library can support high-performance GUI applications with enough functionality to enter the domain of X, while consuming only a fraction of the resources," said Dodge.&lt;lb/&gt;The QNX operating system is a POSIX-certified realtime OS for Intel and AMD processors. Scalable and modular, QNX fits a wide range of environments, from compact embedded controllers to resource-rich X-based development systems, to distributed realtime systems running hundreds of CPUs.&lt;/quote&gt;
    &lt;p&gt;Versions 4.2, 4.22, and 4.24 all released in 1995. The final version 4 release was 4.25 in 1997. At least one QNX 4 installation ran for over 20 years without a reboot at the ESA. This was possible because peripherals could be hotswapped, drivers could be changed, and network nodes could be added or removed without bringing the system down.&lt;/p&gt;
    &lt;p&gt;Notably, we see that in 1994, Quantum renamed itself to QNX Software Systems Limited. And with a new name and a new version of their operating system, the company won some major installs. From POS systems at FasFax that allowed for real-time sales figures from geographically disparate locations, to video conferencing systems at Georgia State University, to factories, power plants, hospitals, set-top boxes, phone systems, trains, jets, the Space Shuttle, ISPs, and even traffic lights. The price for a single license dropped to around $285 at this time, and by 1995, QNX was the leading real-time OS for x86 systems. The majority of the company’s revenue was from large enterprises.&lt;/p&gt;
    &lt;p&gt;Of course, change was coming in the 1990s, and QSSL knew it. The company took the QNX kernel from version 4.24 and forked it. They had multiple goals with this fork. The system needed to be SMP capable, support POSIX, and be more portable to new hardware. The kernel handled only IPC, message passing, interrupts, and timing. Threading became the minimal unit of scheduling. The new Process Manager then used a loader thread that copied a process’s image into memory freeing the Manager to service other requests while a program continued to load. Naturally, being a real-time system, priority levels were used when scheduling any time-critical process, and new processes inherited the priority of their parent by default. The Process Manager weighed in at 32K (same size as the kernel itself) but added memory allocation, process contexts, resource-manager namespaces, and so on. In this new QNX version, the Process Manager ran inside the microkernel’s address space, but was the only element of the OS to do so. Much of the network stack for this version came from NetBSD, and with that came the ability to use NetBSD network drivers. There was another major change that came from the wider UNIX world, GCC. This naturally meant that language support was quite broadened to include not just C, C++ but all of the other languages supported by the GNU Compiler Collection. This became QNX Neutrino 1.0 released in 1996.&lt;/p&gt;
    &lt;p&gt;On the 19th of October in 1998, QSSL announced QNX Neutrino 2.0 which featured UPM (Universal Process Model). In the words of CTO Dan Dodge:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The premise of UPM is simple. Go beyond the limited MMU protection provided by the other major embedded OSs - where only applications are prevented from corrupting memory - and extend that protection down to services at the kernel level. The result? For the first time, MIPS and PowerPC-based embedded systems can intelligently recover from software faults in drivers, protocol stacks, and custom OS extensions - typically without rebooting.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX was branching into non x86 platforms, and this included PowerPC processors: 401, 403GC, 603e, 821, 823, 860; MIPS processors R4000 and R5000; and naturally all x86 CPUs from the 80386 onward. At this stage, however, the development environment was restricted to QNX 4 and Windows 95/98/NT.&lt;/p&gt;
    &lt;p&gt;This announcement was followed by another about a partnership with Amiga:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Cologne, Germany, November 13 - Amiga Inc. today announced a partnership with QNX Software Systems Ltd. to utilize the QNX realtime operating system (RTOS) as the foundation for the next-generation Amiga architecture. The announcement was made at Computer '98 in Cologne.&lt;/p&gt;
      &lt;p&gt;"The Amiga shook the industry in the 80s with world-leading multimedia architecture," said Jeff Schindler, general manager of Amiga Inc. "QNX's RTOS resembles many of Amiga's unique qualities. It provides the foundation in reaching our vision for the rebirth of Amiga in the new millenium."&lt;/p&gt;
      &lt;p&gt;"We see this partnership as a powerful combination of superior OS technologies, common corporate cultures, and shared business vision," said Dan Dodge, Chief Technology Officer and Cofounder of QNX Software Systems Ltd.&lt;/p&gt;
      &lt;p&gt;About Amiga&lt;/p&gt;
      &lt;p&gt;Amiga Inc. is a technology company targeting the next generation of Amiga architecture with a continued focus on multimedia and the Internet. Since the introduction of the Amiga A1000 in 1985, Amiga has represented the embodiment of the efficient use of memory and hard drive capacity, while pioneering industry developments in multimedia, 32-bit multitasking, and autoconfiguration. Amiga led the industry in combining computer graphics, animation, and film sequences with stereo sound known today as multimedia. Visit http://www.amiga.com and http://www.amiga.de.&lt;/p&gt;
      &lt;p&gt;About QSSL&lt;/p&gt;
      &lt;p&gt;Founded in 1980, QNX Software Systems is one of the top three realtime operating-system vendors in the world, with products licensed in more than a million systems worldwide. The company has established a strong customer base in a variety of industries, including aerospace, telecommunications, medical instrumentation, process control, point-of-sale, consumer electronics, finance, and telephony. With products distributed in over 100 countries, the company is headquartered in Ottawa, Canada.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Amiga port should have been somewhat straightforward considering that Amiga accelerators had been using PowerPC chips, and those chips were now supported by QNX. Gateway’s Amiga team was working closely with QSSL to build a new Amiga (Amiga NG) around the PowerPC G3 and G4 chips running QNX, and these were apparently prototyped as single, dual, and quad processor machines. During alpha testing, Gateway PowerPC boards apparently had some issues, and the two parties blamed one another. By the middle of 1999, Gateway, QSSL, and to some extent Motorola, had poured a hefty sum into the project, and Gateway began insisting on a solid date for the availability of a QNX Neutrino port. Evidently they weren’t satisfied, and I do not believe communication between the two teams, which had one been quite good, was solid by this point. At noon on the 8th of July in 1999, Dan Dodge announced the QNX Developers Network for Amigans. This was followed by another announcement at 15:15 the following day:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Eight months ago we were chosen by Amiga as their foundation OS partner. Our development group was thrilled to be part of the rebirth of such an innovative product. To meet the challenge we knew it would take a tremendous effort on our part. We had a team of people in place working on our part of the Amiga NG soon after the alliance was announced. Over the next few months we involved more and more of our engineering resouces towards making QNX an advanced multi-media platform. Our investment so far has been significant. These are costs we have borne ourselves.&lt;/p&gt;
      &lt;p&gt;It is clear today from Jim's letter that we were not chosen for the next generation Amiga. Naturally we're disappointed. So, where do we stand now? It is not our intent to confuse the Amiga community. We are proud of what we have accomplished and want to include Amigans in what we've achieved. I did make a promise to deliver an operating system and I intend on keeping that promise. I don't want to split the community, nor do I wish to engage in a war of words. I don't ask you to "trust" me or to take me at my word. Both QNX and Amiga have promised to deliver technology into your hands in the very near future. I ask only that your assessment of QNX be based on what we do and what we deliver.&lt;/p&gt;
      &lt;p&gt;Thanks for the overwhelming support we have received so far.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That letter by Jim Collas read, in part:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Dear Amigans,&lt;/p&gt;&lt;p&gt;After months of research and in-depth discussions with all of our technology partners we have decided to use Linux as the primary OS kernel for the new Amiga Operating Environment (OE). I know this decision is a shock to many of you given the previous announcements and activities relative to QNX. This was a very complicated and difficult decision to make and I assure you that I didn't make this decision without a significant amount of research and deliberation. We have been researching Linux since February but didn't finalized our decision until several weeks ago. We were planning to communicate it to the Amiga community in the technology brief that will be released in the next few days.&lt;/p&gt;&lt;p&gt;I am pressed to communicate the Linux decision before the technology brief because of information released by QNX in the last few days. This information had not been reviewed or approved for release by Amiga. In light of our Linux decision, this information is confusing and misleading so I would like to take the time to clarify the situation. I can't disclose any details of the Amiga/QNX discussions because of legally binding confidentiality agreements but I can talk to you about our decision to use the Linux kernel. I think that you will agree that this is the right decision once you understand the reasons for this decision.&lt;/p&gt;&lt;p&gt;Before I continue, I should mention that our technology decision does not reflect negatively on QNX. I believe that QNX is a good company with great technology. I just believe that Linux gives us a better chance of executing our plans successfully. The decision to use QNX as our OS partner on our next generation multimedia convergence computer (MCC) was made late last year. When I took over as president of Amiga in February of this year, I initiated an in-depth review of existing Amiga plans and decisions. As president of Amiga I had to make sure that we were defining a strategy and an execution plan that would allow Amiga and the Amiga community to be successful. We reviewed our strategy, architecture decisions, technology partners, and execution plans. During this review period we also added a number of very talented and experienced people to help us finalize our technology and product decisions. I am confident that we now have a solid and exciting plan that people can have confidence in.&lt;/p&gt;&lt;p&gt;Linux has been picking up substantial momentum over the past year as a viable, open OS alternative in the marketplace. This momentum, the growing commitment to Linux applications from a wide variety of software vendors, and the growing availability of Linux device drivers from hardware vendors, makes it a compelling candidate. Additionally, with all of the significant component suppliers putting resources on writing drivers for Linux it was difficult to get them to port to yet another operating system. Using the Linux OS as a foundation for our Amiga OE allows us to leverage a significant amount of available software drivers and utilities. This allows us to quickly support multiple graphics cards and other peripherals.&lt;/p&gt;&lt;p&gt;Given the above-mentioned advantages, we decided to do an in-depth technical analysis of Linux to determine if it was a suitable OS kernel for our new Amiga operating environment (OE). As we ported parts of our higher level operating environment and AmigaObject architecture to Linux, we discovered some significant performance advantages in the Linux kernel in areas such as distributed object messaging across a network (up to 10X the performance of Windows NT).&lt;/p&gt;&lt;p&gt;Does this mean that the next generation Amiga will not be unique? Absolutely not! Remember that the OS kernel is only one component of the new Amiga OE and the hardware is unique. The revolutionary nature of the Amiga OE is in the way it extends the traditional operating system to provide a host environment for a new class of portable applications - applications that exist in a pervasive networked computing environment. We will be integrating multiple technologies including an efficient windowing environment and a unique user interface. In summary, we decided to use Linux because of the incredible momentum and the fact that it is solid technology and a good foundation for our new Amiga OE.&lt;/p&gt;&lt;p&gt;Additionally, the Linux community is an impressive force that we should be aligned with. We share many common values and objectives with the Linux community. Using Linux as our OS kernel allows us to build a unique and revolutionary operating environment while leveraging the enormous momentum of Linux. The soon to be released technology brief will further explain our architecture and plans for integrating all of the selected technology. Once you read it, I am confident that you will understand the revolutionary nature of the next generation Amiga. I assure you that Amiga and the Amiga community will be a driving force behind the next computer&lt;/p&gt;&lt;lb/&gt;revolution.&lt;/quote&gt;
    &lt;p&gt;As a person using Linux at the time, I believe this to have been the wrong decision. Despite the momentum that Linux had, it wasn’t (still isn’t) as stable, as reliable, or as efficient as QNX. If network performance were a serious consideration, one of the BSDs would have been the better choice. Linux’s hardware support also wasn’t that great in reality. While it could run on quite a bit of kit, it didn’t always support that hardware well, and it didn’t always support all features. Plus, QNX was doing the work to build drivers for the new Amiga. Of course, none of this really mattered. Gateway chose to divest itself of Amiga entirely. The new Amiga Inc. then turned to AmigaOne Partners for Amiga OS 4.&lt;/p&gt;
    &lt;p&gt;QNX Neutrino 2.1 was released in 1999 with support for Java, the Glide API, a wide array of microcontrollers, ARM, StrongARM, and Hitachi SH-4. Interestingly, this release had beta packages including RealPlayer and X in Photon, and it had experimental packages that included Quake 3 Arena and Doom.&lt;/p&gt;
    &lt;p&gt;On the 14th of September in 1999, QNX made an announcement that would shape the future of QNX. The company was partnering with Motorola to develop automobile driver information systems that included in-vehicle navigation, internet access, natural language processing, car audio, multimedia, and vehicle information dashboards. While the Motorola unit responsible for mobileGT wouldn’t last and the unit at IBM working on Java wouldn’t last, QNX would survive and thrive in that segment.&lt;/p&gt;
    &lt;p&gt;QNX version 6 was released on the 18th of January in 2001. The new version was focused on multimedia with streaming video and audio as well as hardware accelerated MPEG encode/decode. The new system included a web based package manager greatly easing the installation of available software. Thankfully, all supported architectures could now be used for developing QNX native software too. Version 6.1 was mostly a patch release and followed later the same year. QSSL was a founding member of the Eclipse Foundation, and QNX software development got quite a bit better with the release of the Momentics Tool Suite on the 4th of June in 2002 (along with QNX 6.2). This was largely the Eclipse IDE combined with a series of plugins that were QNX and Photon oriented.&lt;/p&gt;
    &lt;p&gt;The last release of QNX by QSSL was version 6.3 on the 3rd of June in 2004. This version was visually slightly different, and Voyager was replaced by the Mozilla Suite. The development environment was improved and now offered a clustering framework for the development of networked applications utilizing distributed processing. Among the highlights for this release were SCTP support, IP filter and NAT support, IPv6 support, 2D and 3D graphics layering/compositing, full UTF8 support in Photon, USB2 host support, and support for up to 64GB of RAM on x86 and PPC, up to 1TB on MIPS.&lt;/p&gt;
    &lt;p&gt;On the 27th of October in 2004, QNX Software Systems Limited was purchased by Harman International Industries. Harman specifically wanted to focus on QNX Neutrino in the embedded market, and within that market, specifically on automotive applications where Harman had found a market in audio. Under Harman’s ownership, QNX operated as a separate division led by Dan Dodge as CEO. While QNX did continue to serve networking, medical, and industrial markets, the direction was clear. What had begun with the Motorola partnership in automotive would become the primary market.&lt;/p&gt;
    &lt;p&gt;QNX development continued with 6.3 SP1, SP2, and SP3. Version 6.3.2 was released on the 16th of August in 2006, 6.4 on the 30th of October in 2008, and 6.4.1 in May of 2009. Throughout that time period, QNX had introduced support for Adobe Flash and developed the QNX CAR platform winning a trophy from Adobe for their efforts. This platform was built of modular components allowing manufacturers to mix and match based upon the market segment. QNX was chosen by companies like BMW, Mercedes, Dodge, Toyota, Volkswagen, and Audi. When QNX demoed their automotive systems in the 2007-2009 timeframe, they had concept dashboards. These all ran QNX Neutrino on ARM CPUs (often Freescale i.MX6 or TI Sitara [Cortex A8]) with the EtherCAT motion library, and many demo units had UIs created in Qt5 and QML while a few had hardware accelerated OpenGL interfaces. From 2008 to 2010, QNX had been licensed for use in more than 17 million in-vehicle systems representing an increase of around 130% over those two years. By March of 2010, more than 200 vehicles were already shipping with QNX, and the QNX CAR platform had more than 60 participants. Those participants included 17 auto makers and 26 automotive suppliers.&lt;/p&gt;
    &lt;p&gt;On the 9th of April in 2010, Research in Motion announced their acquisition of QSS from Harman for $200 million:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“RIM is excited about the planned acquisition of QNX Software Systems and we look forward to ongoing collaboration between Harman, QNX and RIM to further integrate and enhance the user experience between smartphones and in-vehicle audio and infotainment systems," said Mike Lazaridis, President and Co-CEO at RIM. "In addition to our interests in expanding the opportunities for QNX in the automotive sector and other markets, we believe the planned acquisition of QNX will also bring other value to RIM in terms of supporting certain unannounced product plans for intelligent peripherals, adding valuable intellectual property to RIM's portfolio and providing long-term synergies for the companies based on the significant and complementary OS expertise that exists within the RIM and QNX teams today."&lt;/p&gt;
      &lt;p&gt;"We welcome the opportunities that a strengthened relationship with RIM will create, as two innovation leaders collaborate to bring new connectivity solutions to the industry," said Dinesh C. Paliwal, Harman's Chairman, President and CEO. "We expect to maintain our close association with QNX and the cutting-edge software solutions it provides to Harman and our customers. We believe our leading customers will fully endorse this move and see it as a major step in advancing seamless connectivity and integration among intelligent devices."&lt;/p&gt;
      &lt;p&gt;"Like Harman, RIM shares our passion for innovation and reliability, so we are absolutely thrilled with this opportunity," said Dan Dodge, CEO, QNX Software Systems. "Moreover, RIM will give us the best of all possible mandates: to continue on our innovation path and to increase investment in our core products, professional services, and go-to-market channels. This is a great time to be a QNX customer, as we focus on collaborating with RIM to create an even more exciting platform for the next generation of connected and embedded devices."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Also in 2010, QNX gained the QNX Safety kernel variant. This was a version of Neutrino that was security hardened specifically for mission critical applications. This variant continues to this day with the most recent version (8.0) having been independently certified by TÜV Rheinland to meet several standards including ISO 26262 ASIL D, IEC 61508 SIL3, IEC 62304 Class C, and ISO/SAE 21434. Aside from security hardening, the QNX Safety variant is still fully compatible with Neutrino’s native APIs and POSIX.&lt;/p&gt;
    &lt;p&gt;In July of 2010, QNX Neutrino 6.5 was released. This version brought performance improvements to the kernel when systems were seeing high memory utilization, the kernel gained zombie reaping, and it gained address space randomization. SMP support was increased, and CPU support was extended to ARMv7 Cortex A-9. The Photon microGUI saw some refinements. As one would expect, version updates were present for everything imported from BSD, Linux, and GNU. This version could make use of the NetBSD’s Pkgsrc tool.&lt;/p&gt;
    &lt;p&gt;Version 6.5 was forked to create both the BlackBerry Tablet OS and BBX shortly after its creation. The first device to see a QNX-derived operating system from RIM was the PlayBook, which featured an OMAP 4430 SoC (1.5 GHz dual-core A9), PowerVR SGX540 GPU, 1GB of RAM, 16GB of eMMC flash, a 1024 by 600 seven inch LCD, Bluetooth, 802.11n, USB2, micro HDMI, a 5MP rear camera, and a 3MP front camera. It measured 5.1 inches by 7.6 inches, was about 2/5 of inch thick, and it weighed just under a pound.&lt;/p&gt;
    &lt;p&gt;The PlayBook was released on the 19th of April in 2011 to mixed reviews. While many loved the webkit browser, user interface, HDMI output, and multitasking, many loathed the requirement of a BlackBerry to get certain apps working. Additionally, there was a dearth of third party applications. This latter complaint did get ameliorated. While at launch there weren’t too many applications, this grew to over 24,000 by the same time the following year. Around 2,465,000 PlayBooks had been sold by June of 2013.&lt;/p&gt;
    &lt;p&gt;The BlackBerry Z10 was released on the 31st of January in 2013 running BBX (officially BlackBerry 10 due to a trademark dispute, and at the launch event for BBX, Research in Motion announced that they were changing their name to BlackBerry Limited). The Z10 was built around a Qualcomm Snapdragon S4 Plus SoC (dual core 1.5GHz Krait CPU, Adreno 225 GPU) for LTE units, or around the TI OMAP 4470 for non-LTE units. The shell was plastic wrapped around a stainless steel inner frame, and the on/off, voice command, and volume buttons on the right side were of metal. While it didn’t have quite the premium feel of an iPhone, it did feel good in the hand. In its dimensions it was 5.1 inches by 2.6 inches, and just over an 1/3 of an inch thick (or just slightly larger than an iPhone 5). It was a slick piece of kit with a high price for the time at $599. The display, however, was excellent. It was a 4.2 inch LCD with a resolution of 1280 by 768 at 355ppi (the iPhone 5 was 326ppi). The device had a 2MP font camera, and an 8MP rear camera capable of HDR, panorama, and 1080p video at 30fps. Wi-Fi was dual band 802.11n, and the device featured Bluetooth, GPS, and NFC. Of course, connectivity didn’t stop there. This device had physical ports: micro USB2, micro HDMI, and 3.5mm audio.&lt;/p&gt;
    &lt;p&gt;BBX made heavy use of gestures with a swipe up from the bottom taking the user to the Home Screen, a swipe to right to hit the App Library, and a swipe to the left going to the BlackBerry Hub. The Hub was a combination of SMS/MMS, email, social media, chat, notifications, and calls in a single unified location. BBX was QNX Neutrino, but it did differ. Multitasking was limited to 8 applications at any one time which I believe to have been done due to the application frameworks. A developer could choose to use C/C++ and the Cascades UI framework, or WebWorks which utilized HTML5 with Zepto.js (JQuery API, but 8.4k compressed), or WebKit, or Adobe AIR (Flash), or Android runtime. With so many different application types, decisions would have had to have been made around resource management, and a best guess at when performance would become unacceptable.&lt;/p&gt;
    &lt;p&gt;BlackBerry had been unable to compete against the iPhone and Android, and BBX was their last, best hope. By 2014, BBX was in the number four spot behind Windows Phone. By 2017, it was clear that they weren’t going to survive in the mobile market. Due to the extreme devotion of their fans, they kept BBX on life support until 2022. Being an amazing OS running on good hardware, why did BBX fail? Likely, the most pressing problem was application support. While BBX could run some Android applications, support was limited. The platform likewise failed to grab many developers as the existing install bases for iOS and Android were enormous. What applications were made for BBX were often of quite low effort. Finally, moving to a touch screen angered BlackBerry’s existing fanbase. For those individuals hanging on to the BlackBerry ecosystem, the keyboard was one of the main reasons why. Removing the physical keyboard made many of those fans feel betrayed. When BlackBerry Limited did release another phone with a physical keyboard, it was a bit too late.&lt;/p&gt;
    &lt;p&gt;On the 20th of September in 2013, BlackBerry Limited announced a 4500 person staff reduction and $1 billion (CAD) loss. On the 23rd, they announced an acquisition by Fairfax Financial Holdings for $9/share. This deal was canceled in November. Instead, John Chen became CEO and initiated a turn around that focused on QNX’s former markets of healthcare, finance, law, and mission critical systems. This focus allowed the company to pick up Ford Motor Company as a QNX customer on the 11th of December in 2014 (Ford had previously used Microsoft Auto).&lt;/p&gt;
    &lt;p&gt;On the 28th of February in 2014, BlackBerry released QNX 6.6. The supported platforms were now the expected x86 and ARM CPUs with no mention of any others. This was a major change despite being a point release. Photon support was removed in favor of the Screen Graphics Subsystem. Screen operates as a lower-level service, and this has the benefit of supporting off-screen rendering and compositing of various image sources, and as QNX software had been increasingly using Qt, HTML5, or OpenGL rather than the toolkits supplied with Photon, this made logical sense.&lt;/p&gt;
    &lt;p&gt;QNX version 7 was released on the 4th of January in 2017 for ARM v7, ARM v8, x86, and AMD64. This release featured a rewritten PCI server with APIs moved out of libc and into libpci, rewritten virtual memory manager, fewer synchronization objects with increased limits, and filesystem encryption was moved into the Encrypted Filesystem package available from QNX Software Centry.&lt;/p&gt;
    &lt;p&gt;By June of 2023, QNX was in over 255 million vehicles around the world, and this would explain why the BlackBerry blog featured a rather large section on automobiles:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The automotive evolution to SDVs and “connected cars” requires an OS capable of speed, safety, and security — while unlocking the power to innovate.&lt;/p&gt;
      &lt;p&gt;"With more than 300 million vehicles capable of over-the-air software updates expected to be on the road globally by 2032, automakers are clamoring for better tools to help them develop compelling technology features in the software-defined vehicle," says Alex Oyler, director of North America at SBD Automotive, a leading global automotive technology research and consulting firm.&lt;/p&gt;
      &lt;p&gt;“Both automakers and suppliers rely on validated software and well-integrated development tools to help them more efficiently build and maintain differentiating software for their fleets,” Oyler adds. "A secured-by-design operating system such as the next generation QNX OS — that seamlessly integrates with other software components on a high-performance system-on-chip — represents the foundation of a safe, secure, and seamless experience for drivers.”&lt;/p&gt;
      &lt;p&gt;In addition, early reviews of the new QNX SDP 8.0 give automotive industry leaders a glimpse into what’s possible.&lt;/p&gt;
      &lt;p&gt;“The combination of our DRIVE Thor centralized computer and the new QNX OS will serve as a powerful foundation on which OEMs can build next-generation automotive systems that offer the highest levels of safety and security,” says Ali Kani, vice president and general manager of automotive at NVIDIA. “This represents another major milestone in a nearly 20-year collaboration with BlackBerry QNX that has helped both companies move to the forefront of the automotive industry.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX 8.0 was officially announced in December of 2023, and the release was made in January of 2024. Version 8.0 was quickly discontinued with 8.0.1 taking its place. Version 8.0.3 was made available on the 21st of March in 2024. This latest release is available for a variety of Aarch64 platforms including the Raspberry Pi, and is also available for AMD64. QNX 8 supports SoCs with up to 64 cores and has near linear performance scaling. The network stack is now based upon FreeBSD 13.2, Wi-Fi 6 support is present with WPA3 and TLS 1.3, Screen can operate fully headless and now supports Vulkan 1.3 and OpenCL 3, and Screen now supports Wayland 1.21. Developers are now encouraged to use LLVM and libc++ 16 though GCC is still available with libstdc++ 12.2. Python 3.11, valgrind, libasan (address sanitizer), libubsan (undefined behavior detection), and libunwind are all available. For the UNIX user land, Toybox has replaced many common GNU utilities.&lt;/p&gt;
    &lt;p&gt;If the Raspberry Pi port caught your attention, this is available free for non-commercial use via QNX Everywhere. The image requires a Raspberry Pi 4 with at least 2GB of RAM and an 8GB or greater MicroSD card.&lt;/p&gt;
    &lt;p&gt;On the 2nd of January in 2025, it was announced that BlackBerry IoT would now be known as QNX. This decision was made largely by BlackBerry responding to their customers who recognized and desired the QNX brand. QNX CEO John Giamatteo stated:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Relaunching the QNX brand is an important step in BlackBerry’s broader strategy to increase our visibility and fortify our leadership within the automotive and embedded industries, with a view to better positioning us for sustained growth and success. The values that QNX stands for have always been a cornerstone for our customers and this brand relaunch honors that strong history while setting the stage for the division to fire on all cylinders and drive smarter, safer, and faster innovation through precision-engineered performance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX is a fascinating operating system. It was extremely well designed from the start, and while it has been rewritten, the core ideas that allowed it survive for 45 years persist to this day. While I am sad that Photon was deprecated, the reasoning is sound. Most vendors using QNX either do not require a GUI, or they implement their own. For example, while Boston Dynamics uses QNX in their robots, they don’t really need Photon, and neither do SpaceX’s Falcon rockets. While cars certainly have displays, most vehicle makers desire their screen interfaces to have a unique look and feel. Of course, just stating these use cases of robots, rockets, and cars speaks to the incredible reliability and versatility of QNX. Better operating systems are possible, and QNX proves it.&lt;/p&gt;
    &lt;p&gt;My dear readers, many of you worked at, ran, or even founded the companies I cover here on ARF, and some of you were present at those companies for the time periods I cover. A few of you have been mentioned by name. All corrections to the record are sincerely welcome, and I would love any additional insights, corrections, or feedback. Please feel free to leave a comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.abortretry.fail/p/the-qnx-operating-system"/><published>2025-10-05T14:47:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45482106</id><title>The Demonization of DeepSeek: How NIST Turned Open Science into a Security Scare</title><updated>2025-10-05T19:07:45.069743+00:00</updated><content/><link href="https://erichartford.com/the-demonization-of-deepseek"/><published>2025-10-05T15:12:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45482333</id><title>Show HN: ASCII Drawing Board</title><updated>2025-10-05T19:07:44.792494+00:00</updated><content>&lt;doc fingerprint="f65ec2ddcce25e37"&gt;
  &lt;main&gt;
    &lt;p&gt;Use the List of Unicode characters as a source of characters for your brush ✦ ◒ ▜ █▓▒░ Unfortunately not all of them will work due to font limitations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.delopsu.com/draw.html"/><published>2025-10-05T15:36:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45482467</id><title>NFS at 40 – Remembering the Sun Microsystems Network File System</title><updated>2025-10-05T19:07:33.724213+00:00</updated><content>&lt;doc fingerprint="2f90b3e32bf72b79"&gt;
  &lt;main&gt;
    &lt;p&gt;This website gathers material related to the Sun Microsystems Network File System, a project that began in 1983 and remains a fundamental technology for today’s distributed computer systems.&lt;/p&gt;
    &lt;p&gt;The occasion which prompted this project was the ~40th anniversary of NFS, celebrated in September 2025 at the MSST Conference in Santa Clara, CA.&lt;/p&gt;
    &lt;p&gt;The core of the collection is design documents, white papers, engineering specifications, conference and journal papers, and standards material. However it also covers marketing materials, trade press, advertising, books, “swag”, and personal ephemera. We’re always looking for new contributions.&lt;/p&gt;
    &lt;p&gt;We’ve organized the material in four sections:&lt;/p&gt;
    &lt;p&gt;Unless otherwise noted, everything is downloadable from this site.&lt;/p&gt;
    &lt;p&gt;A full list of the Internet RFCs related to NFS can be found here.&lt;/p&gt;
    &lt;p&gt;There is also a site, nfsv4bat.org, which seems to include a variety of materials related to NFS after 1995, especially Connectathons. However, be careful: the site is insecure, load times are insanely slow, and it is unclear whether it’s still being maintained.&lt;/p&gt;
    &lt;p&gt;This website was created with the help of (alphabetically) Russel Berg, Russ Cox, Steve Kleiman, Bob Lyon, Tom Lyon, Joseph Moran, Brian Pawlowski, David Rosenthal, and Kate Stout. Please send any comments or suggestions to me, Geoff Arnold, via email. Last updated .&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nfs40.online/"/><published>2025-10-05T15:49:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45482484</id><title>If the University of Chicago won't defend the humanities, who will?</title><updated>2025-10-05T19:07:33.468679+00:00</updated><content>&lt;doc fingerprint="76417213ac8b1428"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;If the University of Chicago Won’t Defend the Humanities, Who Will?&lt;/head&gt;
    &lt;p&gt;Why it matters that the University of Chicago is pausing admissions to doctoral programs in literature, the arts, and languages&lt;/p&gt;
    &lt;p&gt;Listen to more stories on the Noa app.&lt;/p&gt;
    &lt;p&gt;Updated at 1:15 p.m. ET on September 12, 2025&lt;/p&gt;
    &lt;p&gt;The Rockefeller Center Christmas Tree was lit, COVID-19 was still a mysterious respiratory illness in Wuhan, and I was a Ph.D. candidate in a dying field: comparative literature. I was getting ready to Zoom interview for a tenure-track job near Boston that I almost certainly wouldn’t get (and didn’t). Sardined with me in a Greenwich Village coffee shop in December 2019, one of my faculty mentors talked me through, for the thousandth time, the questions I should expect the hiring committee to ask me and dispensed advice about how I should answer them. Then we walked back to his office, lined in handsome foreign-language editions of various novels and works of philosophy, where I would sit for the interview. There, he offered a final piece of wisdom: “Don’t be nervous. It’s just Harvard,” he said, grinning. “It’s not like it’s Chicago.”&lt;/p&gt;
    &lt;p&gt;A joke, but not entirely. For as long as I can remember, and certainly much longer than that, the University of Chicago has been widely viewed as the destination for humanities students and scholars. Some other elite schools might have the coveted Ivy League branding, or a few more famous faculty members, or a couple more dollars to tack onto the salaries of its professors and graduate students. But perhaps nowhere is the study of literature, philosophy, the arts, and languages more valued, their spirit more authentically preserved, their frontiers more doggedly pursued, than at Chicago. The university has had several household names on its humanities faculty, including the firebrand critic Allan Bloom, the novelist Saul Bellow, and the ethicist Martha Nussbaum, as well as scholars who may be less well known to the general public but whose work has been deeply influential in their fields, including the brilliant literary critic Sianne Ngai and Fred Donner, the pathbreaking and Guggenheim-winning historian of early Islam. In short, Chicago is a place for scholars’ scholars. At least, that’s the reputation. And Chicago’s reputation is no doubt why, when the university announced recently that it was reducing Ph.D. admissions for seven departments—among them art history and English language and literature—and outright freezing admissions to others, including classics, the decision was met, in some quarters, with fury and disbelief. “Chicago!” as one stunned academic friend put it in a text to me.&lt;/p&gt;
    &lt;p&gt;In an August 12 email to faculty, Deborah Nelson, Chicago’s arts and humanities dean, said that the changes were necessitated by “this moment of uncertainty” and “evolving fiscal realities.” These bits of bureaucratese appear to be allusions to both the Trump administration’s war on higher education and Chicago’s homegrown financial troubles, which include an eye-popping $6.3 billion in debt. “To be anything but cautious at this moment,” the dean’s email continued, “would be irresponsible.”&lt;/p&gt;
    &lt;p&gt;Chicago’s social-sciences division has also announced doctoral-admissions pauses, primarily in humanistic-leaning programs such as anthropology and social thought, where towering figures including the philosopher Hannah Arendt once taught. What’s happening at Chicago is a particular gut-punch to the humanities, not just at the university itself, but nationally and even globally. The school is, as the classics professor Catherine Kearns put it in a message to me, “a singular center for the pursuit of humanistic knowledge and intellectual growth.” Of the nearly 30 Chicago humanities professors I spoke with for this article, many emphasized that the stakes are much higher than the fate of prospective graduate students or the professors who might teach them. Chicago has long helped to keep alive tiny fields and esoteric areas of humanistic study, particularly in the languages. Without the university’s support, and the continued training of graduate students who can keep these bodies of knowledge going, entire spheres of human learning might eventually blink out.&lt;/p&gt;
    &lt;p&gt;Of course, some might view these comments as self-serving complaints. But the primary fears of the people I spoke with were not about their own careers or futures, but instead about their fields—about knowledge that, once lost, cannot be easily regained. “If you allow a field to die, there’s a loss to something like humanity,” Clifford Ando, a Chicago classicist who has been outspoken about the administration’s maneuvers, told me. “There’s also a real practical risk that a field simply cannot be re-created just because you have books.” I heard this sentiment echoed over and over. “If we stop producing people who are trained or educated to help undergraduates understand the most important things thought or written or painted in human history,” the renowned philosopher Robert Pippin said, “we might not be able to recover that.” Elaine Hadley, an emerita professor of English, told me, “Part of what we do is we’re conservators, keeping a body of knowledge going. We want to innovate and we want to think new things about it, and, you know, we want to make it relevant to the present day, but we’re also trying to keep this knowledge alive.”&lt;/p&gt;
    &lt;p&gt;These responses emphasize the cultural costs of shrinking the number of people trained in humanities fields, rather than focusing on the question of whether universities should be calibrating the production of Ph.D.s to the academic job market. No one I spoke to was insensitive to the pressures their grad students face when confronting the vanishing opportunities for tenure-track employment. But the professors also seemed reluctant to define the success of a program by how many professors it creates—after all, most humanities PhD students at Chicago do not pay tuition and receive stipends to cover their living costs, and getting paid to learn and read is not the worst fate.&lt;/p&gt;
    &lt;p&gt;These faculty perspectives also stood in stark contrast with the reigning image of elite higher educators in right-wing media outlets: that humanities professors are “woke” activists whose primary concern is the political indoctrination of “the youth.” Most of the Chicago faculty I spoke with saw—and defended—their disciplines in terms that were, if anything, conservative. Implicit in their impassioned defenses was the belief that the role of a humanist is to preserve knowledge, safeguard learning from the market and the tides of popular interest, and ward off coarse appeals to economic utility.&lt;/p&gt;
    &lt;p&gt;Depending on whom I asked, the move to scale back humanities doctoral programs is either a prudent acknowledgment of the cratered job market for tenure-track professorships and a wise attempt to protect the university’s humanities division from looming financial and political risks, or it is a cynical effort, under cover of the Trump administration’s assaults, to transfer resources away from “impractical,” unprofitable, and largely jobless fields (such as, say, comparative literature) and toward areas that the university’s senior leadership seems to care about (such as, say, STEM and “innovation”). One faculty member I spoke with mentioned a consulting firm that was brought on to help Chicago as it considers changes to its humanities division, including possibly consolidating the departments from 15 down to eight. Many professors worried that the move to impose uneven changes—reducing admissions in some while halting them in others—may be an attempt to create circumstances that will ultimately make it easier to dissolve the paused programs. “Let no good crisis go unleveraged,” Holly Shissler, an associate professor in the Middle Eastern Studies department, said with a dark laugh. “You engineer a situation in which there are no students, and then you turn around and say, ‘Why are we supporting all these departments and faculty when they have no students?’”&lt;/p&gt;
    &lt;p&gt;When I emailed Nelson and asked whether the changes were part of a plan to kill off the paused departments, she said, “A one-year pause is exactly that—a discrete decision that applies merely to a single admissions cycle.” She seemed to acknowledge, however, that a divisional reorganization could happen. “My goal is to sustain the full scope of our faculty’s research and teaching,” she said. “To do so, we must be open to new ideas and structures.” She added, “There’s no magic number of departments in the arts and humanities.” In the meantime, Chicago’s humanities professors appear largely determined to resist being evaluated in terms of expediency. In a meeting with Nelson a few days after the announcement, 14 out of 15 chairs in the humanities division told the dean that she should pause enrollment in all of their departments or none of them. Targeting some and not others was unacceptable, they argued, because it sent the message that some fields matter and others do not.&lt;/p&gt;
    &lt;p&gt;The department chairs’ wager seems to be that acting as a unified bloc will make reorganizing the division and cutting programs more difficult, even if the division-wide pause causes short-term pain for the next academic year. As anyone who has served on a faculty anywhere can tell you, this degree of cross-department solidarity and willingness to sacrifice for less-favored colleagues is remarkable, and even moving. Last Wednesday afternoon, the dean announced that the chairs had gotten their wish: With the exception of philosophy and music composition (owing to previous pauses in those programs), doctoral admissions will be frozen across the humanities for the 2026–27 academic year.&lt;/p&gt;
    &lt;p&gt;It’s a bittersweet victory, of course, one that will result in fewer doctoral students in the short term and is not guaranteed to strengthen the division in the long term. And it does not settle the most pressing question raised by all this turmoil. If even Chicago is not willing to support and protect American arts and letters, who will? One Chicago administrator, in an attempt to defend the university’s admissions pauses, pointed out that other prestigious peer institutions were expected to make similar announcements about their Ph.D. admissions in the coming weeks, and noted that Harvard is cutting nearly $2 million from its own humanities division. I would like to think that my (and others’) alarm about the future of the humanities is overblown. But the evidence doesn’t give me much hope.&lt;/p&gt;
    &lt;p&gt;The subheading of this article originally incorrectly stated that philosophy was one of the University of Chicago doctoral programs whose graduate admissions were paused.&lt;/p&gt;
    &lt;p&gt;This article originally stated that the University of Chicago’s investments in cryptocurrency are part of its financial troubles. The university maintains that it has not lost money on its cryptocurrency investments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theatlantic.com/culture/archive/2025/08/university-chicago-humanities-doctorate/684004/"/><published>2025-10-05T15:51:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45482516</id><title>BYD Builds World's Fastest Car</title><updated>2025-10-05T19:07:33.142681+00:00</updated><content/><link href="https://www.autotrader.co.uk/content/news/byd-builds-world-s-fastest-car"/><published>2025-10-05T15:54:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483205</id><title>Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR</title><updated>2025-10-05T19:07:32.870920+00:00</updated><content>&lt;doc fingerprint="6c9c320bddd310bf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 2 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have empowered large language models (LLMs) to tackle challenging reasoning tasks such as mathematics and programming. RLVR leverages verifiable outcome rewards to guide policy optimization, enabling LLMs to progressively improve output quality in a grounded and reliable manner. Despite its promise, the RLVR paradigm poses significant challenges, as existing methods often suffer from sparse reward signals and unstable policy gradient updates, particularly in RL-based approaches. To address the challenges, we propose $\textbf{PACS}$, a novel RLVR framework that achieves im$\textbf{P}$licit $\textbf{A}$ctor $\textbf{C}$ritic coupling via a $\textbf{S}$upervised learning framework. By treating the outcome reward as a predictable label, we reformulate the RLVR problem into a supervised learning task over a score function parameterized by the policy model and optimized using cross-entropy loss. A detailed gradient analysis shows that this supervised formulation inherently recovers the classical policy gradient update while implicitly coupling actor and critic roles, yielding more stable and efficient training. Benchmarking on challenging mathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as PPO and GRPO, achieving superior reasoning performance. For instance, PACS achieves 59.78\% at pass@256 on AIME 2025, representing improvements of 13.32 and 14.36 points over PPO and GRPO. This simple yet powerful framework offers a promising avenue for LLMs post-training with verifiable rewards. Our code and data are available as open source at this https URL.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2509.02522"/><published>2025-10-05T17:01:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483275</id><title>Focus Is Saying No</title><updated>2025-10-05T19:07:32.636909+00:00</updated><content>&lt;doc fingerprint="7c5a597f265626ee"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Focus Is Saying No&lt;/head&gt;
    &lt;head rend="h2"&gt;Software Modernization Projects Dilemma (Part 2)&lt;/head&gt;
    &lt;p&gt;This is the second part of a two-part series. Reading the first part is not required, but it is recommended.&lt;/p&gt;
    &lt;p&gt;After working with the same team for two years, I joined another tier 0 product team as a senior software engineer — one of the company’s most critical services handling massive traffic, where any downtime directly impacts revenue.&lt;/p&gt;
    &lt;p&gt;The new team focused primarily on product requirement delivery, and they were working with a legacy codebase that had significant tech debt: deprecated libraries, a cumbersome deployment process, and unstable integration tests etc.&lt;/p&gt;
    &lt;p&gt;Having spent all my time on feature work in my previous team, I worried I wouldn’t grow by doing more of the same. (Looking back now, I realize this assumption was incorrect — working on product features actually contributed significantly to my growth; I’ll unpack that in a future post).&lt;/p&gt;
    &lt;p&gt;The tech debt issues seemed like the perfect opportunity. As a result, I decided to focus on software modernization tasks for my career growth.&lt;/p&gt;
    &lt;p&gt;Two years flew by after joining the new team. I had successfully delivered challenging software modernization tasks — from removing outdated library updates to building a new deployment pipeline. Feeling confident about my contributions, I decided it was time to speak with my manager about promotion.&lt;/p&gt;
    &lt;p&gt;“I want to talk about promotion,” I said confidently in a one-on-one meeting.&lt;/p&gt;
    &lt;p&gt;“I think I’ve made some good progress for the team. Deployment is way simpler and faster now. Our test cases are finally stable. And we’ve basically eliminated all the critical security vulnerabilities.”&lt;/p&gt;
    &lt;p&gt;“So… Does this seem like staff-level work to you?”&lt;/p&gt;
    &lt;p&gt;“You’re doing great work,” my manager replied calmly.&lt;/p&gt;
    &lt;p&gt;“but I have to stack-rank the team, and those tasks aren’t staff-level.”&lt;/p&gt;
    &lt;p&gt;“Because… some lack business value. These tasks aren’t business priorities and had no impact on customers and other teams”&lt;/p&gt;
    &lt;p&gt;“Also, at the staff level, you need to work across teams, influence broader decisions, and build visibility beyond just our team.”&lt;/p&gt;
    &lt;p&gt;The conversation went nowhere. Don’t get me wrong — my manager at the time is a great manager. He is the role model of the team, and helps everyone on the team innovate and deliver results. His feedback was honest and fair.&lt;/p&gt;
    &lt;p&gt;Reflecting on that one-on-one conversation and everything I had done over those two years, I realized how much I had learned. One of the most important lessons is to focus on building a great product.&lt;/p&gt;
    &lt;p&gt;Building a great product doesn’t mean building a perfect system with zero tech debt. Instead, it’s about aligning the team’s efforts toward tasks that drives measurable business impact. And to do that, it takes courage to say no to other tasks.&lt;/p&gt;
    &lt;p&gt;Like Steve Jobs said in a conference talk:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When you think about focusing, you think focusing is about saying yes. No. Focusing is about saying no. The result of that focus is going to be some great products where the total is much greater than the sum of the parts.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Looking back, I realized I had worked on a lot of low-impact projects — tasks that made no impact on users and no impact on the team, like updating outdated libraries. The old library worked fine without any updates. Updating it took weeks of my time but delivered zero value to the team or business. I did it simply because my manager told me to.&lt;/p&gt;
    &lt;p&gt;Early in my career, I said “yes” often. As I got more experience, I learned when to say “no.”&lt;/p&gt;
    &lt;p&gt;Now if my manager asks me to do tasks that I believe add no value to the team or business, I’ll politely say no. Why? Because I’m focusing on building the great product.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medium.com/@HobokenDays/software-modernization-projects-dilemma-part-2-7f6002c4b6f1"/><published>2025-10-05T17:08:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483386</id><title>Fire destroys Korean government's cloud storage system, no backups available</title><updated>2025-10-05T19:07:32.021393+00:00</updated><content>&lt;doc fingerprint="fd40bb1beeb70fe1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;NIRS fire destroys government's cloud storage system, no backups available&lt;/head&gt;
    &lt;p&gt; Published: 01 Oct. 2025, 17:59 &lt;/p&gt;
    &lt;p&gt;A fire at the National Information Resources Service (NIRS)'s Daejeon headquarters destroyed the government’s G-Drive cloud storage system, erasing work files saved individually by some 750,000 civil servants, the Ministry of the Interior and Safety said Wednesday.&lt;/p&gt;
    &lt;p&gt;The fire broke out in the server room on the fifth floor of the center, damaging 96 information systems designated as critical to central government operations, including the G-Drive platform. The G-Drive has been in use since 2018, requiring government officials to store all work documents in the cloud instead of on personal computers. It provided around 30 gigabytes of storage per person.&lt;/p&gt;
    &lt;p&gt;However, due to the system’s large-capacity, low-performance storage structure, no external backups were maintained — meaning all data has been permanently lost.&lt;/p&gt;
    &lt;p&gt;The scale of damage varies by agency. The Ministry of Personnel Management, which had mandated that all documents be stored exclusively on G-Drive, was hit hardest. The Office for Government Policy Coordination, which used the platform less extensively, suffered comparatively less damage.&lt;/p&gt;
    &lt;p&gt;The Personnel Ministry stated that all departments are expected to experience work disruptions. It is currently working to recover alternative data using any files saved locally on personal computers within the past month, along with emails, official documents and printed records.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry noted that official documents created through formal reporting or approval processes were also stored in the government’s Onnara system and may be recoverable once that system is restored.&lt;/p&gt;
    &lt;p&gt;“Final reports and official records submitted to the government are also stored in OnNara, so this is not a total loss,” said a director of public services at the Interior Ministry.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry explained that while most systems at the Daejeon data center are backed up daily to separate equipment within the same center and to a physically remote backup facility, the G-Drive’s structure did not allow for external backups. This vulnerability ultimately left it unprotected.&lt;/p&gt;
    &lt;p&gt;Criticism continues to build regarding the government's data management protocols.&lt;/p&gt;
    &lt;p&gt;This article was originally written in Korean and translated by a bilingual reporter with the help of generative AI tools. It was then edited by a native English-speaking editor. All AI-assisted translations are reviewed and refined by our newsroom.&lt;/p&gt;
    &lt;p&gt;BY JEONG JAE-HONG [[email protected]],D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://koreajoongangdaily.joins.com/news/2025-10-01/national/socialAffairs/NIRS-fire-destroys-governments-cloud-storage-system-no-backups-available/2412936"/><published>2025-10-05T17:20:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483531</id><title>Show HN: ut – Rust based CLI utilities for devs and IT</title><updated>2025-10-05T19:07:31.844618+00:00</updated><content>&lt;doc fingerprint="3eb52433f1893217"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast, lightweight CLI utility toolkit for developers and IT professionals. &lt;code&gt;ut&lt;/code&gt; provides a comprehensive set of commonly-used tools in a single binary, eliminating the need to install and remember multiple utilities or search for random websites to perform simple tasks.&lt;/p&gt;
    &lt;code&gt;cargo install --git https://github.com/ksdme/ut.git&lt;/code&gt;
    &lt;code&gt;ut &amp;lt;TOOL&amp;gt; [OPTIONS]&lt;/code&gt;
    &lt;p&gt;Run &lt;code&gt;ut --help&lt;/code&gt; to see all available tools, or &lt;code&gt;ut &amp;lt;TOOL&amp;gt; --help&lt;/code&gt; for specific tool documentation.&lt;/p&gt;
    &lt;code&gt;├── Encoding
│   ├── base64      - Base64 encode/decode
│   │   ├── encode
│   │   └── decode
│   └── url         - URL encode/decode
│       ├── encode
│       └── decode
├── Hashing
│   └── hash        - Cryptographic hash digests
│       ├── md5
│       ├── sha1
│       ├── sha224
│       ├── sha256
│       ├── sha384
│       └── sha512
├── Data Generation
│   ├── uuid        - Generate UUIDs
│   │   ├── v1
│   │   ├── v3
│   │   ├── v4
│   │   └── v5
│   ├── token       - Generate secure random tokens
│   ├── lorem       - Generate lorem ipsum text
│   └── random      - Generate random numbers
├── Text Processing
│   ├── case        - Convert text case formats
│   │   ├── lower
│   │   ├── upper
│   │   ├── camel
│   │   ├── title
│   │   ├── constant
│   │   ├── header
│   │   ├── sentence
│   │   └── snake
│   ├── pretty-print - Unescape newlines and tabs
│   └── diff        - Compare text with visual output
├── Development Tools
│   ├── calc        - Expression calculator
│   ├── json        - JSON builder and utilities
│   │   └── builder
│   ├── regex       - Interactive regex tester
│   └── datetime    - Parse and convert datetimes
├── Web &amp;amp; Network
│   ├── http        - HTTP utilities
│   │   └── status
│   ├── serve       - Local HTTP file server
│   └── qr          - Generate QR codes
├── Color &amp;amp; Design
│   └── color       - Color utilities
│       └── convert
└── Reference
    └── unicode     - Unicode symbol reference
&lt;/code&gt;
    &lt;p&gt;Encode and decode data using Base64 encoding.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports both standard and URL-safe character sets&lt;/item&gt;
      &lt;item&gt;Can read from files or stdin&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut base64 encode "hello world"
ut base64 decode "aGVsbG8gd29ybGQ="
ut base64 encode --urlsafe "hello world"&lt;/code&gt;
    &lt;p&gt;URL encode and decode text.&lt;/p&gt;
    &lt;code&gt;ut url encode "hello world"
ut url decode "hello%20world"&lt;/code&gt;
    &lt;p&gt;Generate cryptographic hash digests using various algorithms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports MD5, SHA-1, SHA-224, SHA-256, SHA-384, and SHA-512&lt;/item&gt;
      &lt;item&gt;Can read from files or stdin&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut hash sha256 "hello world"
ut hash md5 - &amp;lt; file.txt&lt;/code&gt;
    &lt;p&gt;Generate UUIDs in various versions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;v1: Timestamp-based&lt;/item&gt;
      &lt;item&gt;v3: Namespace + MD5 hash&lt;/item&gt;
      &lt;item&gt;v4: Random&lt;/item&gt;
      &lt;item&gt;v5: Namespace + SHA-1 hash&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut uuid v4
ut uuid v4 --count 5
ut uuid v5 --namespace DNS --name example.com&lt;/code&gt;
    &lt;p&gt;Generate cryptographically secure random tokens.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customizable length and character sets&lt;/item&gt;
      &lt;item&gt;Uses OS-level secure randomness&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut token --length 32
ut token --no-symbols --length 64&lt;/code&gt;
    &lt;p&gt;Generate lorem ipsum placeholder text.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customizable paragraph count and sentence structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut lorem --paragraphs 5
ut lorem --min-sentences 2 --max-sentences 6&lt;/code&gt;
    &lt;p&gt;Generate random numbers within a specified range.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports decimal precision with step parameter&lt;/item&gt;
      &lt;item&gt;Can generate multiple values at once&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut random --min 1 --max 100
ut random --min 0 --max 1 --step 0.01 --count 10&lt;/code&gt;
    &lt;p&gt;Convert text between different case formats.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;lowercase, UPPERCASE, camelCase, snake_case, Title Case, CONSTANT_CASE, Header-Case, Sentence case&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut case lower "Hello World"
ut case camel "hello_world"
ut case snake "HelloWorld"&lt;/code&gt;
    &lt;p&gt;Resolve escaped newlines and tab characters in text.&lt;/p&gt;
    &lt;code&gt;ut pretty-print "hello\nworld\ttab"&lt;/code&gt;
    &lt;p&gt;Compare text contents with visual diff output.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports file comparison or interactive editing&lt;/item&gt;
      &lt;item&gt;Color-coded character-level differences&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut diff -a file1.txt -b file2.txt
ut diff  # Opens editor for both inputs&lt;/code&gt;
    &lt;p&gt;Expression calculator with support for multiple number formats and mathematical functions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports arithmetic operations, exponentiation, functions (sin, cos, tan, log, exp, sqrt, abs, floor, ceil, round)&lt;/item&gt;
      &lt;item&gt;Binary (0b), hexadecimal (0x), and decimal number formats&lt;/item&gt;
      &lt;item&gt;Mathematical constants (pi, e)&lt;/item&gt;
      &lt;item&gt;Results displayed in decimal, hex, and binary&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut calc "2 + 2 * 3"
ut calc "sin(pi / 2)"
ut calc "0xFF + 0b1010"
ut calc "sqrt(16) ^ 2"&lt;/code&gt;
    &lt;p&gt;JSON utilities including a powerful JSON builder.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Build complex JSON structures using dot notation&lt;/item&gt;
      &lt;item&gt;Supports nested objects and arrays&lt;/item&gt;
      &lt;item&gt;Array indexing and append operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut json builder a.b.c=hello a.b.d=world
ut json builder "user.name=John" "user.age=30" "user.tags[]=dev" "user.tags[]=rust"
ut json builder "items[0].id=1" "items[0].name=first" "items[1].id=2"&lt;/code&gt;
    &lt;p&gt;Interactive regex tester with live highlighting.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time pattern matching visualization&lt;/item&gt;
      &lt;item&gt;Multi-color highlighting for capture groups&lt;/item&gt;
      &lt;item&gt;Load test strings from files&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut regex
ut regex --test sample.txt&lt;/code&gt;
    &lt;p&gt;Parse and convert datetimes between timezones.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support for ISO 8601 and custom format strings&lt;/item&gt;
      &lt;item&gt;Convert between timezones&lt;/item&gt;
      &lt;item&gt;"now" keyword for current time&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut datetime now
ut datetime "2025-10-04T15:30:00Z" --target-timezone "Asia/Tokyo"
ut datetime "October 04, 2025 03:30 PM" --source-timezone UTC --parse-format "MonthName Day2, Year4 Hour12:Minute2 AMPM"&lt;/code&gt;
    &lt;p&gt;HTTP utilities including status code lookup.&lt;/p&gt;
    &lt;code&gt;ut http status 404
ut http status  # List all status codes&lt;/code&gt;
    &lt;p&gt;Start a local HTTP file server.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customizable host and port&lt;/item&gt;
      &lt;item&gt;Directory listing support&lt;/item&gt;
      &lt;item&gt;Optional HTTP Basic authentication&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut serve --port 8080
ut serve --directory ./public --auth username:password&lt;/code&gt;
    &lt;p&gt;Generate QR codes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Terminal display or save to PNG file&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut qr "https://example.com"
ut qr "Hello World" --output qrcode.png&lt;/code&gt;
    &lt;p&gt;Color utilities for working with different color formats.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports hex, rgb, rgba, hsl, hwb, lab, lch, oklab, oklch&lt;/item&gt;
      &lt;item&gt;Parses any CSS-compatible color format&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ut color convert "#FF5733"
ut color convert "rgb(255, 87, 51)"
ut color convert "hsl(9, 100%, 60%)"&lt;/code&gt;
    &lt;p&gt;Display Unicode symbol reference table.&lt;/p&gt;
    &lt;code&gt;ut unicode&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fast: Built in Rust for optimal performance&lt;/item&gt;
      &lt;item&gt;Standalone: Single binary with no runtime dependencies&lt;/item&gt;
      &lt;item&gt;Composable: Tools work with stdin/stdout for easy piping&lt;/item&gt;
      &lt;item&gt;Secure: Uses cryptographically secure random number generators where appropriate&lt;/item&gt;
      &lt;item&gt;Cross-platform: Works on Linux, macOS, and Windows&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Run the project
cargo run -- &amp;lt;tool&amp;gt; [args]

# Format code
cargo fmt

# Run tests
cargo test&lt;/code&gt;
    &lt;p&gt;Parts of this project were built using Claude Code, an AI-powered coding assistant, with human oversight and collaboration.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ksdme/ut"/><published>2025-10-05T17:36:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483651</id><title>Callbacks in C++ Using Template Functors – Rich Hickey (1994)</title><updated>2025-10-05T19:07:31.190371+00:00</updated><content>&lt;doc fingerprint="86297b127e6d336d"&gt;
  &lt;main&gt;&lt;p&gt;Copyright 1994 Rich Hickey&lt;/p&gt;&lt;p&gt;INTRODUCTION&lt;/p&gt;&lt;p&gt;One of the many promises of Object-Oriented programming is that it will allow for plug-and-play software design with re-usable components. Designers will pull objects from their library 'shelves' and hook them together to make software. In C++, this hooking together of components can be tricky, particulary if they are separately designed. We are still a long way from interoperable libraries and application components. Callbacks provide a mechanism whereby independently developed objects may be connected together. They are vital for plug and play programming, since the likelihood of Vendor A implementing their library in terms of Vendor B's classes, or your home-brewed classes, is nil.&lt;/p&gt;&lt;p&gt;Callbacks are in wide use, however current implementations differ and most suffer from shortcomings, not the least of which is their lack of generality. This article describes what callbacks are, how they are used, and the criteria for a good callback mechanism. It summarizes current callback methods and their weaknesses. It then describes a flexible, powerful and easy-to-use callback technique based on template functors - objects that behave like functions.&lt;/p&gt;&lt;p&gt;CALLBACK FUNDAMENTALS&lt;/p&gt;&lt;p&gt;What Are Callbacks?&lt;/p&gt;&lt;p&gt;When designing application or sub-system specific components we often know all of the classes with which the component will interact and thus explicity code interfaces in terms of those classes. When designing general purpose or library components however, it is often necessary or desirable to put in hooks for calling unknown objects. What is required is a way for one component to call another without having been written in terms of, or with knowledge of, the other component's type. Such a 'type-blind' call mechanism is often referred to as a callback.&lt;/p&gt;&lt;p&gt;A callback might be used for simple notification, two-way communication, or to distribute work in a process. For instance an application developer might want to have a &lt;code&gt;Button&lt;/code&gt;&amp;#13;
component in a GUI library call an application-specific object when&amp;#13;
clicked upon.  The designer of a data entry component might want to&amp;#13;
offer the capability to call application objects for input validation.&amp;#13;
Collection classes often offer an &lt;code&gt;apply()&lt;/code&gt; function, which&amp;#13;
'applies' a member function of an application object to the items they&amp;#13;
contain.&amp;#13;
&lt;/p&gt;&lt;p&gt;A callback, then, is a way for a component designer to offer a generic connection point which developers can use to establish communication with application objects. At some subsequent point, the component 'calls back' the application object. The communication takes the form of a function call, since this is the way objects interact in C++.&lt;/p&gt;&lt;p&gt;Callbacks are useful in many contexts. If you use any commercial class libraries you have probably seen at least one mechanism for providing callbacks. All callback implementations must address a fundamental problem posed by the C++ type system: How can you build a component such that it can call a member function of another object whose type is unknown at the time the component is designed? C++'s type system requires that we know something of the type of any object whose member functions we wish to call, and is often criticized by fans of other OO languages as being too inflexible to support true component-based design, since all the components have to 'know' about each other. C++'s strong typing has too many advantages to abandon, but addressing this apparent lack of flexibility may encourage the proliferation of robust and interoperable class libraries.&lt;/p&gt;&lt;p&gt;C++ is in fact quite flexible, and the mechanism presented here leverages its flexibility to provide this functionality without language extension. In particular, templates supply a powerful tool for solving problems such as this. If you thought templates were only for container classes, read on!&lt;/p&gt;&lt;p&gt;Callback Terminology&lt;/p&gt;&lt;p&gt;There are three elements in any callback mechanism - the caller, the callback function, and the callee.&lt;/p&gt;&lt;p&gt;The caller is usually an instance of some class, for instance a library component (although it could be a function, like &lt;code&gt;qsort()&lt;/code&gt;), that provides or requires the callback; i.e.  it&amp;#13;
can, or must, call some third party code to perform its work, and uses&amp;#13;
the callback mechanism to do so.  As far as the designer of the caller&amp;#13;
is concerned, the callback is just a way to invoke a process, referred&amp;#13;
to here as the callback function. The caller determines the&amp;#13;
signature of the callback function i.e.  its argument(s) and return&amp;#13;
types.  This makes sense, because it is the caller that has the work to&amp;#13;
do, or the information to convey.  For instance, in the examples above,&amp;#13;
the &lt;code&gt;Button&lt;/code&gt; class may want a callback function with no&amp;#13;
arguments and no return.  It is a simple notification function used by&amp;#13;
the &lt;code&gt;Button&lt;/code&gt; to indicate it has been clicked upon.  The&amp;#13;
&lt;code&gt;DataEntryField&lt;/code&gt; component might want to pass a &lt;code&gt;String&lt;/code&gt;&amp;#13;
to the callback function and get a &lt;code&gt;Boolean&lt;/code&gt; return.&amp;#13;
&lt;/p&gt;&lt;p&gt;A caller may require the callback for just the duration of one function, as with ANSI C's &lt;code&gt;qsort()&lt;/code&gt;, or may want to hold on&amp;#13;
to the callback in order to call back at some later time, as with the&amp;#13;
&lt;code&gt;Button&lt;/code&gt; class.        &lt;/p&gt;&lt;p&gt;The callee is usually a member function of an object of some class, but it can also be a stand-alone function or static member function, that the application designer wishes to be called by the caller component. Note that in the case of a non-static member function a particular object/member-function pair is the callee. The function to be called must be compatible with the signature of the callback function specified by the caller.&lt;/p&gt;&lt;p&gt;Criteria for a Good Callback Mechanism&lt;/p&gt;&lt;p&gt;A callback mechanism in the object oriented model should support both component and application design. Component designers should have a standard, off-the-shelf way of providing callback services, requiring no invention on their part. Flexibility in specifying the number and types of argument and return values should be provided. Since the component may be designed for use in as-yet-unthought-of applications, the component designer should neither need to know, nor dictate, the types of the objects which may be 'called back' by the component.&lt;/p&gt;&lt;p&gt;Application developers, given a component with this standard callback mechanism and some instance of a class with a member function compatible with the callback function signature, should have to do no custom 'glue' coding in order to connect the two together. Nor should they have to modify the callee class or hand-derive a new class. If they want to have the callback invoke a stand-alone, non-member function, that should be supported as well.&lt;/p&gt;&lt;p&gt;To support this behavior the callback mechanism should be:&lt;/p&gt;&lt;p&gt;Object Oriented - Our applications are built with objects. In a C++ application most functionality is contained in member functions, which cannot be invoked via normal ptr-to-functions. Non-static member functions operate upon objects, which have state. Calling such functions is more than just invoking a process, it is operating upon a particular object, thus an object-oriented callback must contain information about which object to call.&lt;/p&gt;&lt;p&gt;Type Safe - Type safety is a fundamental feature and benefit of C++ and any robust C++ callback mechanism must be type safe. That means we must ensure that objects are used in compliance with their specified interfaces, and that type rules are enforced for arguments, return values, and conversions. The best way to ensure this is to have the compiler do the work at compile time.&lt;/p&gt;&lt;p&gt;Non-Coupling - This is the fundamental goal of callbacks - to allow components designed in ignorance of each other to be connected together. If the mechanism somehow introduces a dependancy between caller and callee it has failed in its basic mission.&lt;/p&gt;&lt;p&gt;Non-Type-Intrusive - Some mechanisms for doing callbacks require a modification to, or derivation of, the caller or callee types. The fact that an object is connected to another object in a particular application often has nothing to do with its type. As we'll see below, mechanisms that are type intrusive can reduce the flexibility and increase the complexity of application code.&lt;/p&gt;&lt;p&gt;Generic - The primary differences between different callback situations are the types involved. This suggests that the callback mechanism should be parameterized using templates. Templates insure consistent interfaces and names in all callback situations, and provide a way to have any necessary support code be generated by the compiler, not the user.&lt;/p&gt;&lt;p&gt;Flexible - Experience has shown that callback systems that require an exact match between callback function and callee function signatures are too rigid for real-world use. For instance you may encounter a callback that passes a &lt;code&gt;Derived *&lt;/code&gt; that you want to connect to a callee&amp;#13;
function that takes a &lt;code&gt;Base *&lt;/code&gt;.&amp;#13;
&lt;/p&gt;&lt;p&gt;CURRENT MECHANISMS&lt;/p&gt;&lt;p&gt;Function Model&lt;/p&gt;&lt;p&gt;The simplest callback mechanism is a pointer-to-function, a la ANSI C's &lt;code&gt;qsort()&lt;/code&gt;.  Getting a stand-alone function to act upon a&amp;#13;
particular object, however, usually involves kludges like using static&amp;#13;
or global pointers to indicate the target object, or having the callback&amp;#13;
function take an extra parameter (usually a pointer to the object to act&amp;#13;
upon). The static/global pointer method breaks down when the callback&amp;#13;
relationship exists across calls, i.e.  'I want to connect this Button&amp;#13;
to this X and this other Button to this other X, for the duration of the&amp;#13;
app'.  The extra paramter method, if done type-safely, introduces&amp;#13;
undesirable coupling between the caller and callee types.        &lt;/p&gt;&lt;p&gt;&lt;code&gt;qsort()&lt;/code&gt; achieves its genericity by foregoing type safety.  i.e.,&amp;#13;
in order for it to be ignorant of the types it is manipulating it takes&amp;#13;
untyped (&lt;code&gt;void *&lt;/code&gt;) arguments.  There is nothing to prevent&amp;#13;
someone from calling &lt;code&gt;qsort()&lt;/code&gt; on an array of apples and&amp;#13;
passing a pointer to a function that compares oranges!&amp;#13;
&lt;/p&gt;&lt;p&gt;An example of this typeless mechanism you'll frequently see is the 'apply' function in collections. The purpose of an apply function is to allow a developer to pass a callback to a collection and have it be 'applied' to (called on) each item in the collection. Unfortunately it often looks like this:&lt;/p&gt;&lt;quote&gt;void apply(void (*func)(T &amp;amp;theItem,void *extraStuff),void *theStuff);&lt;/quote&gt;&lt;p&gt;Chances are really good you don't have a function like &lt;code&gt;func&lt;/code&gt; sitting around, so you'll have&amp;#13;
to write one (lots of casting required). And make sure you pass it the&amp;#13;
right stuff. Ugh.                                    &lt;/p&gt;&lt;p&gt;Single Rooted Hierarchy&lt;/p&gt;&lt;p&gt;Beware of callback mechanisms that appear type safe but are in fact not. These mechanisms usually involve some base-of-all-classes like Object or EventHandler, and utilize casts from ptr-to-member-of-derived to ptr-to-member-of-base. Experience has indicated that single-rooted systems are unworkable if components are to come from multiple sources.&lt;/p&gt;&lt;p&gt;Parameterize the Caller&lt;/p&gt;&lt;p&gt;The component designer could parameterize the component on the type of the callee. Such parameterization is inappropriate in many situations and callbacks are one of them. Consider:&lt;/p&gt;&lt;quote&gt;class Button{ public: virtual void click(); //... }; template &amp;lt;class T&amp;gt; class ButtonThatCallsBack:public class Button{ public: ButtonThatCalls(T *who,void (T::*func)(void)): callee(who),callback(func){} void click() { (callee-&amp;gt;*callback)(); } private: T *callee; void (T::*callback)(void); }; class CDPlayer{ public: void play(); //... }; //Connect a CDPlayer and a Button CDPlayer cd; ButtonThatCallsBack&amp;lt;CDPlayer&amp;gt; button(&amp;amp;cd,&amp;amp;CDPlayer::play); button.click(); //calls cd.play()&lt;/quote&gt;&lt;p&gt;A &lt;code&gt;ButtonThatCallsBack&amp;lt;CDPlayer&amp;gt;&lt;/code&gt; would thus 'know'&amp;#13;
about &lt;code&gt;CDPlayer&lt;/code&gt; and provides an interface explicitly based&amp;#13;
on it.  The problem is that this introduces rigidity in the system in&amp;#13;
that the callee type becomes part of the caller type, i.e.  it is&amp;#13;
'type-intrusive'.  All code that creates&amp;#13;
&lt;code&gt;ButtonThatCallsBack&lt;/code&gt; objects must be made aware of the&amp;#13;
callee relationship, increasing coupling in the system.  A&amp;#13;
&lt;code&gt;ButtonThatCallsBack&amp;lt;X&amp;gt; &lt;/code&gt;is of a different type than a&amp;#13;
&lt;code&gt;ButtonThatCallsBack&amp;lt;Y&amp;gt;&lt;/code&gt;, thus preventing by-value&amp;#13;
manipulation.&amp;#13;
&lt;/p&gt;&lt;p&gt;If a component has many callback relationships it quickly becomes unworkable to parameterize them all. Consider a &lt;code&gt;Button&lt;/code&gt;&amp;#13;
that wants to maintain a dynamic list of callees to be notified upon a&amp;#13;
click event. Since the callee type is built into the &lt;code&gt;Button&lt;/code&gt;&amp;#13;
class type, this list must be either homogeneous or typeless.&amp;#13;
&lt;/p&gt;&lt;p&gt;Library code cannot even create &lt;code&gt;ButtonThatCallsBack&lt;/code&gt;&amp;#13;
objects because their instantiation depends on application types.  This&amp;#13;
is a severe constraint.  Consider GUI library code that reads a dialog&amp;#13;
description from a resource file and creates a &lt;code&gt;Dialog&lt;/code&gt;&amp;#13;
object. How can it know that you want the &lt;code&gt;Buttons&lt;/code&gt; in that&amp;#13;
&lt;code&gt;Dialog&lt;/code&gt; to call back &lt;code&gt;CDPlayers&lt;/code&gt;? It can't,&amp;#13;
therefore it can't create the &lt;code&gt;Buttons&lt;/code&gt; for you.&amp;#13;
&lt;/p&gt;&lt;p&gt;Callee Mix-In&lt;/p&gt;&lt;p&gt;The caller component designer can invent an abstract base class to be the target of the callback, and indicate to application developers that they mix-in this base in order to connect their class with the component. I call this the "callee mix-in."&lt;/p&gt;&lt;p&gt;Here the designer of the &lt;code&gt;Button&lt;/code&gt; class wants to&amp;#13;
offer a click notification callback, and so defines a nested class&amp;#13;
&lt;code&gt;Notifiable&lt;/code&gt; with a pure virtual function &lt;code&gt;notify()&lt;/code&gt;&amp;#13;
that has the desired signature.  Clients of the &lt;code&gt;Button&lt;/code&gt;&amp;#13;
class will have to pass to its constructor a pointer to a&amp;#13;
&lt;code&gt;Notifiable&lt;/code&gt;, which the &lt;code&gt;Button&lt;/code&gt; will use (at&amp;#13;
some point later on) for notification of clicks:&amp;#13;
&lt;/p&gt;&lt;quote&gt;class Button{ public: class Notifiable{ public: virtual void notify()=0; }; Button(Notifiable *who):callee(who){} void click() {callee-&amp;gt;notify();} private: Notifiable *callee; }; Given : class CDPlayer{ public: void play(); //... };&lt;/quote&gt;&lt;p&gt;an application developer wishing to have a &lt;code&gt;Button&lt;/code&gt; call&amp;#13;
back a &lt;code&gt;CDPlayer&lt;/code&gt; would have to derive a new class from both&amp;#13;
&lt;code&gt;CDPlayer&lt;/code&gt; and&amp;#13;
&lt;code&gt;Button::Notifiable&lt;/code&gt;, overriding the pure virtual function&amp;#13;
to do the desired work:&amp;#13;
&lt;/p&gt;&lt;quote&gt;class MyCDPlayer:public CDPlayer,public Button::Notifiable{ public: void notify() {play();} };&lt;/quote&gt;&lt;p&gt;and use this class rather than &lt;code&gt;CDPlayer&lt;/code&gt; in the&amp;#13;
application:&amp;#13;
&lt;/p&gt;&lt;quote&gt;MyCDPlayer cd; Button button(&amp;amp;cd); button.click(); //calls cd.play()&lt;/quote&gt;&lt;p&gt;This mechanism is type safe, achieves the decoupling of &lt;code&gt;Button&lt;/code&gt;&amp;#13;
and&amp;#13;
&lt;code&gt;CDPlayer&lt;/code&gt;, and is good magazine article fodder.  It is&amp;#13;
almost useless in practice, however.&amp;#13;
&lt;/p&gt;&lt;p&gt;The problem with the callee mix-in is that it, too, is type-intrusive, i.e. it impacts the type of the callee, in this case by forcing derivation. This has three major flaws. First, the use of multiple inheritance, particularly if the callee is a callee of multiple components, is problematic due to name clashes etc. Second, derivation may be impossible, for instance if the application designer gets &lt;code&gt;CDPlayers&lt;/code&gt; from an unchangeable, untouchable API (library&amp;#13;
designers note: this is a big problem with mix-in based mechanisms in&amp;#13;
general).  The third problem is best demonstrated.  Consider this&amp;#13;
version of &lt;code&gt;CDPlayer&lt;/code&gt;:&amp;#13;
&lt;/p&gt;&lt;quote&gt;class CDPlayer{ public: void play(); void stop(); //... };&lt;/quote&gt;&lt;p&gt;It doesn't seem unreasonable to have an application where one &lt;code&gt;Button&lt;/code&gt;&amp;#13;
calls &lt;code&gt;CDPlayer::play()&lt;/code&gt; and another &lt;code&gt;CDPlayer::stop()&lt;/code&gt;.&amp;#13;
 The mix-in mechanism fails completely here, since it can only support a&amp;#13;
single mapping between caller/callee/member-function, i.e. &lt;code&gt;MyCDPlayer&lt;/code&gt;&amp;#13;
can have only one &lt;code&gt;notify()&lt;/code&gt;.&amp;#13;
&lt;/p&gt;&lt;p&gt;CALLBACKS USING TEMPLATE FUNCTORS&lt;/p&gt;&lt;p&gt;When I first thought about the inter-component callback problem I decided that what was needed was a language extension to support 'bound-pointers', special pointers representing information about an object and a member function of that object, storable and callable much like regular pointers to functions. ARM 5.5 commentary has a brief explanation of why bound pointers were left out.&lt;/p&gt;&lt;p&gt;How would bound pointers work? Ideally you would initialize them with either a regular pointer-to-function or a reference to an object and a pointer-to-member-function. Once initialized, they would behave like normal pointer-to-functions. You could apply the function call &lt;code&gt;operator()&lt;/code&gt; to them to invoke the function. In order to be&amp;#13;
suitable for a callback mechanism, the information about the type of the&amp;#13;
callee would _not_ be part of the type of the bound-pointer. It might&amp;#13;
look something like this:&amp;#13;
&lt;/p&gt;&lt;quote&gt;// Warning - NOT C++ class Fred{ public: void foo(); }; Fred fred; void (* __bound fptr)() = &amp;amp;fred.foo;&lt;/quote&gt;&lt;p&gt;Here &lt;code&gt;fptr&lt;/code&gt; is a bound-pointer to a function that takes&amp;#13;
no arguments and returns &lt;code&gt;void&lt;/code&gt;.  Note that &lt;code&gt;Fred&lt;/code&gt;&amp;#13;
is not part of &lt;code&gt;fptr's&lt;/code&gt; type.  It is initialized with the&amp;#13;
object &lt;code&gt;fred&lt;/code&gt; and a pointer-to-member-function-of-Fred,&amp;#13;
&lt;code&gt;foo&lt;/code&gt;.  Saying:&amp;#13;
&lt;/p&gt;&lt;quote&gt;fptr();&lt;/quote&gt;&lt;p&gt;would invoke &lt;code&gt;foo&lt;/code&gt; on &lt;code&gt;fred&lt;/code&gt;.&amp;#13;
&lt;/p&gt;&lt;p&gt;Such bound-pointers would be ideal for callbacks:&lt;/p&gt;&lt;quote&gt;// Warning - NOT C++ class Button{ public: Button(void (* __bound uponClickDoThis)() ) :notify(uponClickDoThis) {} void click() { notify(); } private: void (* __bound notify)(); }; class CDPlayer{ public: void play(); }; CDPlayer cd; Button button(&amp;amp;cd.play); button.click(); //calls cd.play()&lt;/quote&gt;&lt;p&gt;Bound-pointers would require a non-trivial language extension and some tricky compiler support. Given the extreme undesirability of any new language features I'd hardly propose bound-pointers now. Nevertheless I still consider the bound-pointer concept to be the correct solution for callbacks, and set out to see how close I could get in the current and proposed language. The result is the Callback library described below. As it turns out, the library solution can not only deliver the functionality shown above (albeit with different syntax), it proved more flexible than the language extension would have been!&lt;/p&gt;&lt;p&gt;Returning from the fantasy world of language extension, the library must provide two things for the user. The first is some construct to play the role of the 'bound-pointer'. The second is some method for creating these 'bound-pointers' from either a regular pointer-to-function or an object and a pointer-to-member-function.&lt;/p&gt;&lt;p&gt;In the 'bound-pointer' role we need an object that behaves like a function. Coplien has used the term functor to describe such objects. For our purposes a functor is simply an object that behaves like a pointer-to-function. It has an &lt;code&gt;operator()&lt;/code&gt;&amp;#13;
(the function call operator) which can be used to invoke the function to&amp;#13;
which it points.  The library provides a set of template &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
classes.  They hold any necessary callee data and provide&amp;#13;
pointer-to-function like behavior. Most important, their type has no&amp;#13;
connection whatsoever to the callee type.  Components define their&amp;#13;
callback interface using the &lt;code&gt;Functor&lt;/code&gt; classes.&amp;#13;
&lt;/p&gt;&lt;p&gt;The construct provided by the library for creating functors is an overloaded template function, &lt;code&gt;makeFunctor()&lt;/code&gt;, which&amp;#13;
takes as arguments the callee information (either an object and a&amp;#13;
ptr-to-member-function, or a ptr-to-function) and returns something&amp;#13;
suitable for initializing a&amp;#13;
&lt;code&gt;Functor&lt;/code&gt; object.&amp;#13;
&lt;/p&gt;&lt;p&gt;The resulting mechanism is very easy to use. A complete example:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;callback.h&amp;gt; //include the callback library header #include &amp;lt;iostream.h&amp;gt; class Button{ public: Button(const Functor0 &amp;amp;uponClickDoThis) :notify(uponClickDoThis) {} void click() { notify(); //a call to operator() } private: Functor0 notify; //note - held by value }; //Some application stuff we'd like to connect to Button: class CDPlayer{ public: void play(){cout&amp;lt;&amp;lt;"Playing"&amp;lt;&amp;lt;endl;} void stop(){cout&amp;lt;&amp;lt;"Stopped"&amp;lt;&amp;lt;endl;} }; void wow() {cout&amp;lt;&amp;lt;"Wow!"&amp;lt;&amp;lt;endl;} void main() { CDPlayer cd; //makeFunctor from object and ptr-to-member-function Button playButton(makeFunctor(cd,&amp;amp;CDPlayer::play)); Button stopButton(makeFunctor(cd,&amp;amp;CDPlayer::stop)); //makeFunctor from pointer-to-function Button wowButton(makeFunctor(&amp;amp;wow)); playButton.click(); //calls cd.play() stopButton.click(); //calls cd.stop() wowButton.click(); //calls wow() }&lt;/quote&gt;&lt;p&gt;Voila! A component (&lt;code&gt;Button&lt;/code&gt;) has been connected to&amp;#13;
application objects and functions it knows nothing about and that know&amp;#13;
nothing about &lt;code&gt;Button&lt;/code&gt;, without any custom coding,&amp;#13;
derivation or modification of the objects involved.  And it's type safe.&amp;#13;
&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Button&lt;/code&gt; class designer specifies the callback&amp;#13;
interface in terms of&amp;#13;
&lt;code&gt;Functor0&lt;/code&gt;, a functor that takes no arguments and returns&amp;#13;
&lt;code&gt;void&lt;/code&gt;.  It stores the functor away in its member &lt;code&gt;notify&lt;/code&gt;.&amp;#13;
 When it comes time to call back, it simply calls &lt;code&gt;operator()&lt;/code&gt;&amp;#13;
on the functor.  This looks and feels just like a call via a&amp;#13;
pointer-to-function.&amp;#13;
&lt;/p&gt;&lt;p&gt;Connecting something to a component that uses callbacks is simple. You can just initialize a &lt;code&gt;Functor&lt;/code&gt; with the result&amp;#13;
of an appropriate call to&amp;#13;
&lt;code&gt;makeFunctor()&lt;/code&gt;.  There are two flavors of &lt;code&gt;makeFunctor()&lt;/code&gt;.&amp;#13;
 You can call it with a ptr-to-stand-alone function:&amp;#13;
&lt;/p&gt;&lt;quote&gt;makeFunctor(&amp;amp;wow)&lt;/quote&gt;&lt;p&gt;OR with an object and a pointer-to-member function:&lt;/p&gt;&lt;quote&gt;makeFunctor(cd,&amp;amp;CDPlayer::play)&lt;/quote&gt;&lt;p&gt;I must come clean at this point, and point out that the syntax above for &lt;code&gt;makeFunctor()&lt;/code&gt; is possible only in the proposed language,&amp;#13;
because it requires template members (specifically, the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
constructors would have to be templates).  In the current language the&amp;#13;
same result can be achieved by passing to &lt;code&gt;makeFunctor()&lt;/code&gt; a&amp;#13;
dummy parameter of type ptr-to-the-Functor-type-you-want-to-create. This&amp;#13;
iteration of the callback library requires you pass &lt;code&gt;makeFunctor()&lt;/code&gt;&amp;#13;
the dummy as the first parameter.  Simply cast &lt;code&gt;0&lt;/code&gt; to&amp;#13;
provide this argument:&amp;#13;
&lt;/p&gt;&lt;quote&gt;makeFunctor((Functor0 *)0,&amp;amp;wow) makeFunctor((Functor0 *)0,cd,&amp;amp;CDPlayer::play);&lt;/quote&gt;&lt;p&gt;I will use this current-language syntax from here on.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Button&lt;/code&gt; class above only needs a callback&amp;#13;
function with no arguments that returns &lt;code&gt;void&lt;/code&gt;.  Other&amp;#13;
components may want to pass data to the callback or get a return back.&amp;#13;
The only things distinguishing one functor from another are the number&amp;#13;
and types of the arguments to &lt;code&gt;operator()&lt;/code&gt; and its return&amp;#13;
type, if any. This indicates that functors can be represented in the&amp;#13;
library by (a set of) templates:&amp;#13;
&lt;/p&gt;&lt;quote&gt;//Functor classes provided by the Callback library: Functor0 //not a template - nothing to parameterize Functor1&amp;lt;P1&amp;gt; Functor2&amp;lt;P1,P2&amp;gt; Functor3&amp;lt;P1,P2,P3&amp;gt; Functor4&amp;lt;P1,P2,P3,P4&amp;gt; Functor0wRet&amp;lt;RT&amp;gt; Functor1wRet&amp;lt;P1,RT&amp;gt; Functor2wRet&amp;lt;P1,P2,RT&amp;gt; Functor3wRet&amp;lt;P1,P2,P3,RT&amp;gt; Functor4wRet&amp;lt;P1,P2,P3,P4,RT&amp;gt;&lt;/quote&gt;&lt;p&gt;These are parameterized by the types of their arguments (&lt;code&gt;P1&lt;/code&gt;&amp;#13;
etc) and return value (&lt;code&gt;RT&lt;/code&gt;) if any.  The numbering is&amp;#13;
necessary because we can't overload template class names on number of&amp;#13;
parameters.  '&lt;code&gt;wRet&lt;/code&gt;' is appended to distinguish those with&amp;#13;
return values.  Each has an &lt;code&gt;operator()&lt;/code&gt; with the&amp;#13;
corresponding signature, for example:&amp;#13;
&lt;/p&gt;&lt;quote&gt;template &amp;lt;class P1&amp;gt; class Functor1{ public: void operator()(P1 p1)const; //... }; template &amp;lt;class P1,class P2,class RT&amp;gt; class Functor2wRet{ public: RT operator()(P1 p1,P2 p2)const; //... };&lt;/quote&gt;&lt;p&gt;These &lt;code&gt;Functor&lt;/code&gt; classes are sufficient to meet the&amp;#13;
callback needs of component designers, as they offer a standard and&amp;#13;
consistent way to offer callback services, and a simple mechanism for&amp;#13;
invoking the callback function.  Given these templates in the library, a&amp;#13;
component designer need only pick one with the correct number of&amp;#13;
arguments and specify the desired types as parameters.  Here's the&amp;#13;
&lt;code&gt;DataEntryField&lt;/code&gt; that wants a validation callback that takes&amp;#13;
a &lt;code&gt;const String &amp;amp;&lt;/code&gt; and returns a&amp;#13;
&lt;code&gt;Boolean&lt;/code&gt;:&amp;#13;
&lt;/p&gt;&lt;quote&gt;#include &amp;lt;callback.h&amp;gt; class DataEntryField{ public: DataEntryField(const Functor1wRet&amp;lt;const String &amp;amp;,Boolean&amp;gt; &amp;amp;v): validate(v){} void keyHit(const String &amp;amp; stringSoFar) { if(validate(stringSoFar)) // process it etc... } private: Functor1wRet&amp;lt;const String &amp;amp;,Boolean&amp;gt; validate; //validate has a //Boolean operator()(const String &amp;amp;) };&lt;/quote&gt;&lt;p&gt;These trivial examples just scratch the surface of what you can do given a general purpose callback library such as this. Consider their application to state machines, dispatch tables etc.&lt;/p&gt;&lt;p&gt;The callback library is 100% compile-time type safe. (Where compile time includes template-instantiation time). If you try to make a functor out of something that is not compatible with the functor type you will get a compiler error. All correct virtual function behavior is preserved.&lt;/p&gt;&lt;p&gt;The system is also type flexible. You'll note that throughout this article I have said 'type compatible' rather than 'exactly-matching' when talking about the relationship between the callback function and the callee function. Experience has shown that requiring an exact match makes callbacks too rigid for practical use. If you have done much work with pointer-to-function based interfaces you've probably experienced the frustration of having a pointer to a function 'that would work' yet was not of the exact type required for a match.&lt;/p&gt;&lt;p&gt;To provide flexibility the library supports building a functor out of a callee function that is 'type compatible' with the target functor - it need not have an exactly matching signature. By type compatible I mean a function with the same number of arguments, of types reachable from the functor's argument types by implicit conversion. The return type of the function must be implicitly convertible to the return type of the functor. A functor with no return can be built from a function with a return - the return value is safely ignored.&lt;/p&gt;&lt;quote&gt;//assumes Derived publicly derived from Base void foo(Base &amp;amp;); long bar(Derived &amp;amp;); Functor1&amp;lt;Derived&amp;amp;&amp;gt; f1 = makeFunctor((Functor1&amp;lt;Derived&amp;amp;&amp;gt; *)0,&amp;amp;foo); //ok - will implicitly convert f1 = makeFunctor((Functor1&amp;lt;Derived&amp;amp;&amp;gt; *)0,&amp;amp;bar); //ok - ignores return&lt;/quote&gt;&lt;p&gt;Any necessary argument conversions or ignoring of returns is done by the compiler, i.e. there is no coercion done inside the mechanism or by the user. If the compiler can't get from the arguments passed to the functor to the arguments required by the callee function, the code is rejected at compile time. By allowing the compiler to do the work we get all of the normal conversions of arguments - derived to base, promotion and conversion of built-in types, and user-defined conversions.&lt;/p&gt;&lt;p&gt;The type-flexibility of the library is something that would not have been available in a language extension rendition of bound pointers.&lt;/p&gt;&lt;p&gt;Rounding out the functionality of the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
classes are a default constructor that will also accept &lt;code&gt;0&lt;/code&gt;&amp;#13;
as an initializer, which puts the&amp;#13;
&lt;code&gt;Functor&lt;/code&gt; in a known 'unset' state, and a conversion to&amp;#13;
&lt;code&gt;Boolean&lt;/code&gt; which can be used to test whether the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
is 'set'.  The &lt;code&gt;Functor&lt;/code&gt; classes do not rely on any virtual&amp;#13;
function behavior to work, thus they can be held and copied by-value.&amp;#13;
Thus a &lt;code&gt;Functor&lt;/code&gt; has the same ease-of-use as a regular&amp;#13;
pointer-to-function.&amp;#13;
&lt;/p&gt;&lt;p&gt;At this point you know everything you need to use the callback library. All of the code is in one file, &lt;code&gt;callback.h&lt;/code&gt;.  To&amp;#13;
use a callback in a component class, simply instantiate a &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
with the desired argument types.  To connect some stuff to a component&amp;#13;
that uses &lt;code&gt;Functors&lt;/code&gt; for callbacks, simply call &lt;code&gt;makeFunctor()&lt;/code&gt;&amp;#13;
on the stuff.  Easy.&amp;#13;
&lt;/p&gt;&lt;p&gt;Power Templates&lt;/p&gt;&lt;p&gt;As usual, what is easy for the user is often tricky for the implementor. Given the black-box descriptions above of the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
classes and &lt;code&gt;makeFunctor()&lt;/code&gt; it may be hard to swallow the&amp;#13;
claims of type-safety, transparent conversions, correct virtual function&amp;#13;
behavior etc.  A look behind the curtain reveals not only how it works,&amp;#13;
but also some neat template techniques.  Warning: most people find the&amp;#13;
pointer-to-member and template syntax used in the implementation&amp;#13;
daunting at first.&amp;#13;
&lt;/p&gt;&lt;p&gt;Obviously some sort of magic is going on. How can the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
class, with no knowledge of the type or signature of the callee, ensure&amp;#13;
a type safe call to it, possibly with implicit conversions of the&amp;#13;
arguments?  It can't, so it doesn't.  The actual work must be performed&amp;#13;
by some code that knows both the functor callback signature and&amp;#13;
everything about the callee.  The trick is to get the compiler to&amp;#13;
generate that code, and have the &lt;code&gt;Functor&lt;/code&gt; to point to it.&amp;#13;
Templates can help out all around.&amp;#13;
&lt;/p&gt;&lt;p&gt;The mechanism is spread over three components - the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
class, a &lt;code&gt;Translator&lt;/code&gt; class, and the &lt;code&gt;makeFunctor()&lt;/code&gt;&amp;#13;
function.  All are templates.&amp;#13;
&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Functor&lt;/code&gt; class is parameterized on the types of&amp;#13;
the callback function signature, holds the callee data in a typeless&amp;#13;
manner, and defines a typed &lt;code&gt;operator()&lt;/code&gt; but doesn't&amp;#13;
actually perform the work of calling back. Instead it holds a pointer to&amp;#13;
the actual callback code. When it comes time to call back, it passes the&amp;#13;
typeless data (itself actually), as well as the callback arguments, to&amp;#13;
this pointed-to function.&amp;#13;
&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Translator&lt;/code&gt; class is derived from &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
but is parameterized on both the &lt;code&gt;Functor&lt;/code&gt; type _and_ the&amp;#13;
callee types.  It knows about everything, and is thus able to define a&amp;#13;
fully type-safe static 'thunk' function that takes the typeless &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
data and the callback arguments.  It constructs its &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
base class with a pointer to this static function.  The thunk function&amp;#13;
does the work of calling back, turning the typeless &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
data back into a typed callee and calling the callee.  Since the &lt;code&gt;Translator&lt;/code&gt;&amp;#13;
does the work of converting the callee data to and from untyped data the&amp;#13;
conversions are considered 'safe'. The&amp;#13;
&lt;code&gt;Translator&lt;/code&gt; isA &lt;code&gt;Functor&lt;/code&gt;, so it can be used to&amp;#13;
initialize a &lt;code&gt;Functor&lt;/code&gt;.&amp;#13;
&lt;/p&gt;&lt;p&gt;The &lt;code&gt;makeFunctor()&lt;/code&gt; function takes the callee data,&amp;#13;
creates a&amp;#13;
&lt;code&gt;Translator&lt;/code&gt; out of it and returns the &lt;code&gt;Translator&lt;/code&gt;.&amp;#13;
 Thus the &lt;code&gt;Translator&lt;/code&gt; object exists only briefly as the&amp;#13;
return value of &lt;code&gt;makeFunctor()&lt;/code&gt;, but its creation is enough&amp;#13;
to cause the compiler to lay down the static 'thunk' function, the&amp;#13;
address of which is carried in the &lt;code&gt;Functor&lt;/code&gt; that has been&amp;#13;
initialized with the &lt;code&gt;Translator&lt;/code&gt;.&amp;#13;
&lt;/p&gt;&lt;p&gt;All of this will become clearer with the details.&lt;/p&gt;&lt;p&gt;For each of the 10 &lt;code&gt;Functor&lt;/code&gt; classes there are 2&amp;#13;
&lt;code&gt;Translator&lt;/code&gt; classes and 3 versions of &lt;code&gt;makeFunctor()&lt;/code&gt;.&amp;#13;
 We'll examine a slice of the library here, &lt;code&gt;Functor1&lt;/code&gt; and&amp;#13;
its associated &lt;code&gt;Translators&lt;/code&gt; and &lt;code&gt;makeFunctors&lt;/code&gt;.&amp;#13;
The other &lt;code&gt;Functors&lt;/code&gt; differ only in the number of args and&amp;#13;
return values.&amp;#13;
&lt;/p&gt;&lt;p&gt;The Functors&lt;/p&gt;&lt;p&gt;Since the &lt;code&gt;Functor&lt;/code&gt; objects are the only entities&amp;#13;
held by the caller, they must contain the data about the callee.  With&amp;#13;
some care we can design a base class which can hold, in a typeless&amp;#13;
manner, the callee data, regardless of whether the callee is a&amp;#13;
ptr-to-function or object/ptr-to-member-function combo:&amp;#13;
&lt;/p&gt;&lt;quote&gt;//typeless representation of a function or object/mem-func class FunctorBase{ public: typedef void (FunctorBase::*_MemFunc)(); typedef void (*_Func)(); FunctorBase():callee(0),func(0){} FunctorBase(const void *c,const void *f,size_t sz) { if(c) //must be callee/memfunc { callee = (void *)c; memcpy(memFunc,f,sz); } else //must be ptr-to-func { func = f; } } //for evaluation in conditions //will be changed to bool when bool exists operator int()const{return func||callee;} class DummyInit{ }; //////////////////////////////////////////////////////////////// // Note: this code depends on all ptr-to-mem-funcs being same size // If that is not the case then make memFunc as large as largest //////////////////////////////////////////////////////////////// union{ const void *func; char memFunc[sizeof(_MemFunc)]; }; void *callee; };&lt;/quote&gt;&lt;p&gt;All &lt;code&gt;Functors&lt;/code&gt; are derived (protected) from this base.&amp;#13;
&lt;code&gt;FunctorBase&lt;/code&gt; provides a constructor from typeless args,&amp;#13;
where if &lt;code&gt;c&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt; the callee is a&amp;#13;
pointer-to-function and &lt;code&gt;f&lt;/code&gt; is that pointer, else &lt;code&gt;c&lt;/code&gt;&amp;#13;
is pointer to the callee object and &lt;code&gt;f&lt;/code&gt; is a pointer to a&amp;#13;
pointer-to-member function and &lt;code&gt;sz&lt;/code&gt; is that&amp;#13;
ptr-to-member-function's size (in case an implementation has&amp;#13;
pointer-to-members of differing sizes).  It has a default constructor&amp;#13;
which inits to an 'unset' state, and an &lt;code&gt;operator int&lt;/code&gt; to&amp;#13;
allow for testing the state (set or unset).&amp;#13;
&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Functor&lt;/code&gt; class is a template.  It has a default&amp;#13;
constructor and the required &lt;code&gt;operator()&lt;/code&gt; corresponding to&amp;#13;
its template parameters. It uses the generated copy constructor and&amp;#13;
assignment operators.&amp;#13;
&lt;/p&gt;&lt;quote&gt;/************************* one arg - no return *******************/ template &amp;lt;class P1&amp;gt; class Functor1:protected FunctorBase{ public: Functor1(DummyInit * = 0){} void operator()(P1 p1)const { thunk(*this,p1); } FunctorBase::operator int; protected: typedef void (*Thunk)(const FunctorBase &amp;amp;,P1); Functor1(Thunk t,const void *c,const void *f,size_t sz): FunctorBase(c,f,sz),thunk(t){} private: Thunk thunk; };&lt;/quote&gt;&lt;p&gt;The &lt;code&gt;Functor&lt;/code&gt; class has a protected constructor that&amp;#13;
takes the same typeless args as &lt;code&gt;FunctorBase&lt;/code&gt;, plus an&amp;#13;
additional first argument.  This argument is a pointer to function (the&amp;#13;
thunk function) that takes the same arguments as the &lt;code&gt;operator()&lt;/code&gt;,&amp;#13;
plus an additional first argument of type &lt;code&gt;const FunctorBase &amp;amp;&lt;/code&gt;.&amp;#13;
 The &lt;code&gt;Functor&lt;/code&gt; stores this away (in thunk) and implements&amp;#13;
&lt;code&gt;operator()&lt;/code&gt; by calling &lt;code&gt;thunk()&lt;/code&gt;, passing&amp;#13;
itself and the other arguments.  Thus it is this &lt;code&gt;thunk()&lt;/code&gt;&amp;#13;
function that does the work of 'calling back'.&amp;#13;
&lt;/p&gt;&lt;p&gt;A key issue at this point is whether &lt;code&gt;operator()&lt;/code&gt;&amp;#13;
should be virtual. In the first iteration of my mechanism the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
classes were abstract and the &lt;code&gt;operator()&lt;/code&gt;'s pure virtual.&amp;#13;
To use them for callbacks a set of derived template classes&amp;#13;
parameterized on the callee type was provided. This required that&amp;#13;
functors always be passed and held by reference or pointer and never by&amp;#13;
value. It also required the caller component or the client code maintain&amp;#13;
the derived object for as long as the callback relationship existed. I&amp;#13;
found the maintenance and lifetime issues of these functor objects to be&amp;#13;
problematic, and desired by-value syntax.&amp;#13;
&lt;/p&gt;&lt;p&gt;In the current mechanism the &lt;code&gt;Functor&lt;/code&gt; classes are&amp;#13;
concrete and the &lt;code&gt;operator()&lt;/code&gt; is non-virtual.  They can be&amp;#13;
treated and used just like ptr-to-functions.  In particular, they can be&amp;#13;
stored by value in the component classes.&amp;#13;
&lt;/p&gt;&lt;p&gt;The Translators&lt;/p&gt;&lt;p&gt;Where does the &lt;code&gt;thunk()&lt;/code&gt; come from?  It is generated&amp;#13;
by the compiler as a static member of a template 'translator' class.&amp;#13;
For each&amp;#13;
&lt;code&gt;Functor&lt;/code&gt; class there are two translator classes, one for&amp;#13;
stand-alone functions (&lt;code&gt;FunctionTranslator&lt;/code&gt;) and one for&amp;#13;
member functions (&lt;code&gt;MemberTranslator&lt;/code&gt;). The translator&amp;#13;
classes are parameterized by the type of the &lt;code&gt;Functor&lt;/code&gt; as&amp;#13;
well as the type(s) of the callee.  With this knowledge they can, in a&amp;#13;
fully type-safe manner, perform two important tasks.&amp;#13;
&lt;/p&gt;&lt;p&gt;First, they can initialize the &lt;code&gt;Functor&lt;/code&gt; data.  They&amp;#13;
do this by being publicly derived from the &lt;code&gt;Functor&lt;/code&gt;.  They&amp;#13;
are constructed with typed callee information and which they pass&amp;#13;
(untyped) to the functor's protected constructor.&amp;#13;
&lt;/p&gt;&lt;p&gt;Second, they have a static member function &lt;code&gt;thunk()&lt;/code&gt;,&amp;#13;
which, when passed a &lt;code&gt;FunctorBase&lt;/code&gt;, converts its callee data&amp;#13;
back into typed information, and executes the callback on the callee.&amp;#13;
It is a pointer to this static function which is passed to the &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
constructor.&amp;#13;
&lt;/p&gt;&lt;quote&gt;template &amp;lt;class P1,class Func&amp;gt; class FunctionTranslator1:public Functor1&amp;lt;P1&amp;gt;{ public: FunctionTranslator1(Func f):Functor1&amp;lt;P1&amp;gt;(thunk,0,f,0){} static void thunk(const FunctorBase &amp;amp;ftor,P1 p1) { (Func(ftor.func))(p1); } };&lt;/quote&gt;&lt;p&gt;&lt;code&gt;FunctionTranslator&lt;/code&gt; is the simpler of the two.  It is&amp;#13;
parameterized by the argument type of the &lt;code&gt;Functor&lt;/code&gt; and some&amp;#13;
ptr-to-function type (&lt;code&gt;Func&lt;/code&gt;). Its constructor takes an&amp;#13;
argument of type &lt;code&gt;Func&lt;/code&gt; and passes it and a pointer to its&amp;#13;
static &lt;code&gt;thunk()&lt;/code&gt; function to the base class constructor. The&amp;#13;
thunk function, given a &lt;code&gt;FunctorBase&lt;/code&gt; ftor, casts ftor's&amp;#13;
func member back to its correct type (&lt;code&gt;Func&lt;/code&gt;) and calls it.&amp;#13;
There is an assumption here that the &lt;code&gt;FunctorBase&lt;/code&gt; ftor is&amp;#13;
one initialized by the constructor (or a copy).  There is no danger of&amp;#13;
it being otherwise, since the functors are always initialized with&amp;#13;
matching callee data and thunk functions. This is what is called a&amp;#13;
'safe' cast, since the same entity that removed the type information&amp;#13;
also re-instates it, and can guarantee a match.  If&amp;#13;
&lt;code&gt;Func&lt;/code&gt;'s signature is incompatible with the call, i.e.  if&amp;#13;
it cannot be called with a single argument of type &lt;code&gt;P1&lt;/code&gt;,&amp;#13;
then &lt;code&gt;thunk()&lt;/code&gt; will not compile. If implicit conversions are&amp;#13;
required the compiler will perform them. Note that if &lt;code&gt;func&lt;/code&gt;&amp;#13;
has a return it is safely ignored.&amp;#13;
&lt;/p&gt;&lt;quote&gt;template &amp;lt;class P1,class Callee, class MemFunc&amp;gt; class MemberTranslator1:public Functor1&amp;lt;P1&amp;gt;{ public: MemberTranslator1(Callee &amp;amp;c,const MemFunc &amp;amp;m): Functor1&amp;lt;P1&amp;gt;(thunk,&amp;amp;c,&amp;amp;m,sizeof(MemFunc)){} static void thunk(const FunctorBase &amp;amp;ftor,P1 p1) { Callee *callee = (Callee *)ftor.callee; MemFunc &amp;amp;memFunc(*(MemFunc*)(void *)(ftor.memFunc)); (callee-&amp;gt;*memFunc)(p1); } };&lt;/quote&gt;&lt;p&gt;&lt;code&gt;MemberTranslator&lt;/code&gt; is parameterized by the argument type&amp;#13;
of the&amp;#13;
&lt;code&gt;Functor&lt;/code&gt;, some class type (&lt;code&gt;Callee&lt;/code&gt;), and some&amp;#13;
ptr-to-member-function type (&lt;code&gt;MemFunc&lt;/code&gt;).  Not surprisingly&amp;#13;
it's constructor is passed 2 arguments, a&amp;#13;
&lt;code&gt;Callee&lt;/code&gt; object (by reference) and a ptr-to-member-function,&amp;#13;
both of which are passed, along with the thunk function, to the base&amp;#13;
class constructor.  Once again, the &lt;code&gt;thunk&lt;/code&gt; function casts&amp;#13;
the typeless info back to life, and then calls the member function on&amp;#13;
the object, with the passed parameter.&amp;#13;
&lt;/p&gt;&lt;p&gt;Since the &lt;code&gt;Translator&lt;/code&gt; objects are &lt;code&gt;Functor&lt;/code&gt;&amp;#13;
objects, and fully 'bound' ones at that, they are suitable initializers&amp;#13;
for their corresponding &lt;code&gt;Functor&lt;/code&gt;, using the &lt;code&gt;Functor&lt;/code&gt;'s&amp;#13;
copy constructor.  We needn't worry about the 'chopping' effect since&amp;#13;
the data is all in the base class portion of the &lt;code&gt;Translator&lt;/code&gt;&amp;#13;
class and there are no virtual functions involved.  Thus they are&amp;#13;
perfect candidates for the return value of&amp;#13;
&lt;code&gt;makeFunctor()&lt;/code&gt;!&amp;#13;
&lt;/p&gt;&lt;p&gt;The makeFunctor Functions&lt;/p&gt;&lt;p&gt;For each &lt;code&gt;Functor&lt;/code&gt; class there are three versions of&amp;#13;
&lt;code&gt;makeFunctor()&lt;/code&gt;, one for ptr-to-function and a const and&amp;#13;
non-const version for the object/ptr-to-member-function pair.&amp;#13;
&lt;/p&gt;&lt;quote&gt;template &amp;lt;class P1,class TRT,class TP1&amp;gt; inline FunctionTranslator1&amp;lt;P1,TRT (*)(TP1)&amp;gt; makeFunctor(Functor1&amp;lt;P1&amp;gt;*,TRT (*f)(TP1)) { return FunctionTranslator1&amp;lt;P1,TRT (*)(TP1)&amp;gt;(f); }&lt;/quote&gt;&lt;p&gt;The function version is straightforward. It uses the dummy argument to tell it the type of the functor and merely returns a corresponding &lt;code&gt;FunctionTranslator&lt;/code&gt;. I mentioned above that the &lt;code&gt;Func&lt;/code&gt;&amp;#13;
type parameter of&amp;#13;
&lt;code&gt;FunctionTranslator&lt;/code&gt; was invariably a ptr-to-function type.&amp;#13;
This version of &lt;code&gt;makeFunctor()&lt;/code&gt; ensures that by explicity&amp;#13;
specifying it as such.&amp;#13;
&lt;/p&gt;&lt;quote&gt;template &amp;lt;class P1,class Callee,class TRT,class CallType,class TP1&amp;gt; inline MemberTranslator1&amp;lt;P1,Callee,TRT (CallType::*)(TP1)&amp;gt; makeFunctor(Functor1&amp;lt;P1&amp;gt;*,Callee &amp;amp;c,TRT (CallType::* const &amp;amp;f)(TP1)) { typedef TRT (CallType::*MemFunc)(TP1); return MemberTranslator1&amp;lt;P1,Callee,MemFunc&amp;gt;(c,f); }&lt;/quote&gt;&lt;p&gt;This is the gnarliest bit. Here &lt;code&gt;makeFunctor&lt;/code&gt; is&amp;#13;
parameterized with the type of the argument to the &lt;code&gt;Functor&lt;/code&gt;,&amp;#13;
the type of the callee, the type of the class of which the&amp;#13;
member-function is a member, the argument and return types of the member&amp;#13;
function.  Whew!  We're a long way from&amp;#13;
&lt;code&gt;Stack&amp;lt;T&amp;gt;&lt;/code&gt; land!  Like the ptr-to-function version, it&amp;#13;
uses the dummy first argument of the constructor to determine the type&amp;#13;
of the &lt;code&gt;Functor&lt;/code&gt;. The second argument is a &lt;code&gt;Callee&lt;/code&gt;&amp;#13;
object (by reference).  The third argument is this thing:&amp;#13;
&lt;/p&gt;&lt;quote&gt;TRT (CallType::* const &amp;amp;f)(TP1)&lt;/quote&gt;&lt;p&gt;Here &lt;code&gt;f&lt;/code&gt; is a reference to a constant pointer to a&amp;#13;
member function of&amp;#13;
&lt;code&gt;CallType&lt;/code&gt; taking &lt;code&gt;TP1&lt;/code&gt; and returning &lt;code&gt;TRT&lt;/code&gt;.&amp;#13;
 You might notice that pointer-to-member-functions are all handled by&amp;#13;
reference in the library. On some implementations they can be expensive&amp;#13;
to pass by value and copy. The significant feature here is that the&amp;#13;
function need not be of type pointer-to-member-of-Callee.  This allows&amp;#13;
&lt;code&gt;makeFunctor&lt;/code&gt; to match on (and ultimately work with) a&amp;#13;
ptr-to-member-function of some base of &lt;code&gt;Callee&lt;/code&gt;. It then&amp;#13;
typedefs that bit and returns an appropriate &lt;code&gt;MemberTranslator&lt;/code&gt;.&amp;#13;
&lt;/p&gt;&lt;quote&gt;template &amp;lt;class P1,class Callee,class TRT,class CallType,class TP1&amp;gt; inline MemberTranslator1&amp;lt;P1,const Callee,TRT (CallType::*)(TP1)const&amp;gt; makeFunctor(Functor1&amp;lt;P1&amp;gt;*,const Callee &amp;amp;c,TRT (CallType::* const &amp;amp;f)(TP1)const) { typedef TRT (CallType::*MemFunc)(TP1)const; return MemberTranslator1&amp;lt;P1,const Callee,MemFunc&amp;gt;(c,f); }&lt;/quote&gt;&lt;p&gt;This last variant just ensures that if the &lt;code&gt;Callee&lt;/code&gt; is&amp;#13;
const the member function is also (note the &lt;code&gt;const&lt;/code&gt; at the&amp;#13;
end of the third argument to the constructor - that's where it goes!).&amp;#13;
&lt;/p&gt;&lt;p&gt;That, for each of ten &lt;code&gt;Functors&lt;/code&gt;, is the whole&amp;#13;
implementation.&amp;#13;
&lt;/p&gt;&lt;p&gt;Can Your Compiler Do This?&lt;/p&gt;&lt;p&gt;The callback library has been successfully tested with IBM CSet++ 2.01, Borland C++ 4.02 (no, its not twice as good ;-), and Watcom C++32 10.0. It is ARM compliant with the exception of expecting trivial conversions of template function arguments, which is the behavior of most compilers. I am interested in feedback on how well it works with other implementations.&lt;/p&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;p&gt;Callbacks are a powerful and necessary tool for component based object-oriented development in C++. They can be a tremendous aid to the interoperability of libraries. The template functor system presented here meets all the stated criteria for a good callback mechanism - it is object-oriented, compile-time type-safe, generic, non-type-intrusive, flexible and easy to use. It is sufficiently general to be used in any situation calling for callbacks. It can be implemented in the current language, and somewhat more elegantly in the proposed language.&lt;/p&gt;&lt;p&gt;This implementation of callbacks highlights the power of C++ templates - their type-safety, their code-generation ability and the flexibility they offer by accepting ptr-to-function and ptr-to-member-function type parameters.&lt;/p&gt;&lt;p&gt;Ultimately the greatest benefit is gained when class libraries start using a standard callback system. If callbacks aren't in the components, they can't be retrofitted. Upon publication of this article I am making this Callback library freely available in the hope that it will be adopted by library authors and serve as a starting point for discussion of a standard callback system.&lt;/p&gt;&lt;p&gt;References&lt;/p&gt;&lt;p&gt;Stroustrup, B. The Design and Evolution of C++, Addison-Wesley, Reading, MA 1994&lt;/p&gt;&lt;p&gt;Coplien, J.O. Advanced C++ Programming Styles and Idioms, Addison-Wesley, Reading, MA 1992&lt;/p&gt;&lt;p&gt;Ellis, M.A. and B. Stroustrup. The Annotated C++ Reference Manual, Addison-Wesley, Reading, MA 1990&lt;/p&gt;&lt;p&gt;Lippman, S.B. C++ Primer 2nd Edition, Addison-Wesley, Reading, MA 1991&lt;/p&gt;&lt;p&gt;Acknowledgments&lt;/p&gt;&lt;p&gt;Thanks to my fellow developers at RCS and to Greg Comeau for reviewing and commenting on this article.&lt;/p&gt;&lt;p&gt;About the Author&lt;/p&gt;&lt;p&gt;Rich is Technical Design Lead at Radio Computing Services, a leading software vendor in the radio industry. He designed and teaches the Advanced C++ course at New York University's Information Technologies Institute.&lt;/p&gt;He can be reached at: rhickey@bestweb.net Home&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://www.tutok.sk/fastgl/callback.html"/><published>2025-10-05T17:50:17+00:00</published></entry></feed>