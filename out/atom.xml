<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-08T05:38:26.964578+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45502502</id><title>The evolution of Lua, continued [pdf]</title><updated>2025-10-08T05:38:35.586363+00:00</updated><content/><link href="https://www.lua.org/doc/cola.pdf"/><published>2025-10-07T12:54:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45502541</id><title>Qualcomm to acquire Arduino</title><updated>2025-10-08T05:38:35.290877+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i"/><published>2025-10-07T13:00:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45503867</id><title>Vibe engineering</title><updated>2025-10-08T05:38:35.051376+00:00</updated><content>&lt;doc fingerprint="a3d0c07761f5138d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Vibe engineering&lt;/head&gt;
    &lt;p&gt;7th October 2025&lt;/p&gt;
    &lt;p&gt;I feel like vibe coding is pretty well established now as covering the fast, loose and irresponsible way of building software with AI—entirely prompt-driven, and with no attention paid to how the code actually works. This leaves us with a terminology gap: what should we call the other end of the spectrum, where seasoned professionals accelerate their work with LLMs while staying proudly and confidently accountable for the software they produce?&lt;/p&gt;
    &lt;p&gt;I propose we call this vibe engineering, with my tongue only partially in my cheek.&lt;/p&gt;
    &lt;p&gt;One of the lesser spoken truths of working productively with LLMs as a software engineer on non-toy-projects is that it’s difficult. There’s a lot of depth to understanding how to use the tools, there are plenty of traps to avoid, and the pace at which they can churn out working code raises the bar for what the human participant can and should be contributing.&lt;/p&gt;
    &lt;p&gt;The rise of coding agents—tools like Claude Code (released February 2025), OpenAI’s Codex CLI (April) and Gemini CLI (June) that can iterate on code, actively testing and modifying it until it achieves a specified goal, has dramatically increased the usefulness of LLMs for real-world coding problems.&lt;/p&gt;
    &lt;p&gt;I’m increasingly hearing from experienced, credible software engineers who are running multiple copies of agents at once, tackling several problems in parallel and expanding the scope of what they can take on. I was skeptical of this at first but I’ve started running multiple agents myself now and it’s surprisingly effective, if mentally exhausting!&lt;/p&gt;
    &lt;p&gt;This feels very different from classic vibe coding, where I outsource a simple, low-stakes task to an LLM and accept the result if it appears to work. Most of my tools.simonwillison.net collection (previously) were built like that. Iterating with coding agents to produce production-quality code that I’m confident I can maintain in the future feels like a different process entirely.&lt;/p&gt;
    &lt;p&gt;It’s also become clear to me that LLMs actively reward existing top tier software engineering practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated testing. If your project has a robust, comprehensive and stable test suite agentic coding tools can fly with it. Without tests? Your agent might claim something works without having actually tested it at all, plus any new change could break an unrelated feature without you realizing it. Test-first development is particularly effective with agents that can iterate in a loop.&lt;/item&gt;
      &lt;item&gt;Planning in advance. Sitting down to hack something together goes much better if you start with a high level plan. Working with an agent makes this even more important—you can iterate on the plan first, then hand it off to the agent to write the code.&lt;/item&gt;
      &lt;item&gt;Comprehensive documentation. Just like human programmers, an LLM can only keep a subset of the codebase in its context at once. Being able to feed in relevant documentation lets it use APIs from other areas without reading the code first. Write good documentation first and the model may be able to build the matching implementation from that input alone.&lt;/item&gt;
      &lt;item&gt;Good version control habits. Being able to undo mistakes and understand when and how something was changed is even more important when a coding agent might have made the changes. LLMs are also fiercely competent at Git—they can navigate the history themselves to track down the origin of bugs, and they’re better than most developers at using git bisect. Use that to your advantage.&lt;/item&gt;
      &lt;item&gt;Having effective automation in place. Continuous integration, automated formatting and linting, continuous deployment to a preview environment—all things that agentic coding tools can benefit from too. LLMs make writing quick automation scripts easier as well, which can help them then repeat tasks accurately and consistently next time.&lt;/item&gt;
      &lt;item&gt;A culture of code review. This one explains itself. If you’re fast and productive at code review you’re going to have a much better time working with LLMs than if you’d rather write code yourself than review the same thing written by someone (or something) else.&lt;/item&gt;
      &lt;item&gt;A very weird form of management. Getting good results out of a coding agent feels uncomfortably close to getting good results out of a human collaborator. You need to provide clear instructions, ensure they have the necessary context and provide actionable feedback on what they produce. It’s a lot easier than working with actual people because you don’t have to worry about offending or discouraging them—but any existing management experience you have will prove surprisingly useful.&lt;/item&gt;
      &lt;item&gt;Really good manual QA (quality assurance). Beyond automated tests, you need to be really good at manually testing software, including predicting and digging into edge-cases.&lt;/item&gt;
      &lt;item&gt;Strong research skills. There are dozens of ways to solve any given coding problem. Figuring out the best options and proving an approach has always been important, and remains a blocker on unleashing an agent to write the actual code.&lt;/item&gt;
      &lt;item&gt;The ability to ship to a preview environment. If an agent builds a feature, having a way to safely preview that feature (without deploying it straight to production) makes reviews much more productive and greatly reduces the risk of shipping something broken.&lt;/item&gt;
      &lt;item&gt;An instinct for what can be outsourced to AI and what you need to manually handle yourself. This is constantly evolving as the models and tools become more effective. A big part of working effectively with LLMs is maintaining a strong intuition for when they can best be applied.&lt;/item&gt;
      &lt;item&gt;An updated sense of estimation. Estimating how long a project will take has always been one of the hardest but most important parts of being a senior engineer, especially in organizations where budget and strategy decisions are made based on those estimates. AI-assisted coding makes this even harder—things that used to take a long time are much faster, but estimations now depend on new factors which we’re all still trying to figure out.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you’re going to really exploit the capabilities of these new tools, you need to be operating at the top of your game. You’re not just responsible for writing the code—you’re researching approaches, deciding on high-level architecture, writing specifications, defining success criteria, designing agentic loops, planning QA, managing a growing army of weird digital interns who will absolutely cheat if you give them a chance, and spending so much time on code review.&lt;/p&gt;
    &lt;p&gt;Almost all of these are characteristics of senior software engineers already!&lt;/p&gt;
    &lt;p&gt;AI tools amplify existing expertise. The more skills and experience you have as a software engineer the faster and better the results you can get from working with LLMs and coding agents.&lt;/p&gt;
    &lt;head rend="h4"&gt;“Vibe engineering”, really?&lt;/head&gt;
    &lt;p&gt;Is this a stupid name? Yeah, probably. “Vibes” as a concept in AI feels a little tired at this point. “Vibe coding” itself is used by a lot of developers in a dismissive way. I’m ready to reclaim vibes for something more constructive.&lt;/p&gt;
    &lt;p&gt;I’ve never really liked the artificial distinction between “coders” and “engineers”—that’s always smelled to me a bit like gatekeeping. But in this case a bit of gatekeeping is exactly what we need!&lt;/p&gt;
    &lt;p&gt;Vibe engineering establishes a clear distinction from vibe coding. It signals that this is a different, harder and more sophisticated way of working with AI tools to build production software.&lt;/p&gt;
    &lt;p&gt;I like that this is cheeky and likely to be controversial. This whole space is still absurd in all sorts of different ways. We shouldn’t take ourselves too seriously while we figure out the most productive ways to apply these new tools.&lt;/p&gt;
    &lt;p&gt;I’ve tried in the past to get terms like AI-assisted programming to stick, with approximately zero success. May as well try rubbing some vibes on it and see what happens.&lt;/p&gt;
    &lt;p&gt;I also really like the clear mismatch between “vibes” and “engineering”. It makes the combined term self-contradictory in a way that I find mischievous and (hopefully) sticky.&lt;/p&gt;
    &lt;head rend="h2"&gt;More recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI DevDay 2025 live blog - 6th October 2025&lt;/item&gt;
      &lt;item&gt;Embracing the parallel coding agent lifestyle - 5th October 2025&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2025/Oct/7/vibe-engineering/"/><published>2025-10-07T14:55:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504127</id><title>Show HN: MARS – Personal AI robot for builders (&lt; $2k)</title><updated>2025-10-08T05:38:34.644299+00:00</updated><content>&lt;doc fingerprint="f1df9a7b68a781cd"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey, we’re Axel and Vignesh, cofounders of Innate (&lt;/p&gt;https://www.innate.bot/&lt;p&gt;). We just launched MARS, a general-purpose robot with an open onboard agentic OS built on top of ROS2.&lt;/p&gt;&lt;p&gt;Overview: https://youtu.be/GEOMYDXv6pE&lt;/p&gt;&lt;p&gt;Control demo: https://youtu.be/_Cw5fGa8i3s&lt;/p&gt;&lt;p&gt;Videos of autonomous use-cases: https://docs.innate.bot/welcome/mars-example-use-cases&lt;/p&gt;&lt;p&gt;Quickstart: https://docs.innate.bot/welcome/mars-quick-start.&lt;/p&gt;&lt;p&gt;Our last thread: https://news.ycombinator.com/item?id=42451707&lt;/p&gt;&lt;p&gt;When we started we felt there is currently no good affordable general-purpose that anyone can build on. There’s no lack of demand: hugging face’s SO-100 and LeKiwi are pretty clear successes already; but the hardware is unreliable, the software experience is barebone and keeps changing, and you often need to buy hidden extras to make them work (starting with a computer with a good gpu). The Turtlebots were good, but are getting outdated.&lt;/p&gt;&lt;p&gt;The open-source hobbyist movement lacks really good platforms to build on, and we wanted something robust and accessible. MARS is our attempt at making a first intuitive AI robot for everyone.&lt;/p&gt;&lt;p&gt;What it is:&lt;/p&gt;&lt;p&gt;- It comes assembled and calibrated&lt;/p&gt;&lt;p&gt;- Has onboard compute with a jetson orin nano 8gb&lt;/p&gt;&lt;p&gt;- a 5DoF arm with a wrist camera&lt;/p&gt;&lt;p&gt;- Sensors: RGBD wide-angle cam, 2D LiDAR, speakers&lt;/p&gt;&lt;p&gt;- Control via a dedicated app and a leader arm that plugs in iPhone and Android&lt;/p&gt;&lt;p&gt;- 2 additional USB ports + GPIO pins for extra sensors or effectors.&lt;/p&gt;&lt;p&gt;- And our novel SDK called BASIC that allows to run it like an AI agent with VLAs.&lt;/p&gt;&lt;p&gt;It boots in a minute, can be controlled via phone, programmable in depth with a PC, and the onboard agent lets it see, talk, plan, and act in real-time.&lt;/p&gt;&lt;p&gt;Our SDK BASIC allows to create “behaviors” (our name for programs) ranging from a simple hello world to a very complex long-horizon task involving reasoning, planning, navigation and manipulation. You can create skills that behaviors can run autonomously by training the arm or writing code tools, like for an AI agent.&lt;/p&gt;&lt;p&gt;You can also call the ROS2 topics to control the robot at a low-level. And anything created on top of this SDK can be easily shared with anyone else by just sharing the files.&lt;/p&gt;&lt;p&gt;This is intended for hobbyist builders and education, and we would love to have your feedback!&lt;/p&gt;&lt;p&gt;p.s. If you want to try it, there’s a temporary code HACKERNEWS-INNATE-MARS that lowers the price to $1,799.&lt;/p&gt;&lt;p&gt;p.p.s The hardware and software will be open-sourced too, if some of you want to contribute or help us prepare it properly feel free to join our discord at https://discord.gg/YvqQbGKH&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45504127"/><published>2025-10-07T15:11:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504388</id><title>Launch HN: LlamaFarm (YC W22) – Open-source framework for distributed AI</title><updated>2025-10-08T05:38:34.052168+00:00</updated><content>&lt;doc fingerprint="ed1fa4511bbd11f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Build powerful AI locally, extend anywhere.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;LlamaFarm is an open-source framework for building retrieval-augmented and agentic AI applications. It ships with opinionated defaults (Ollama for local models, Chroma for vector storage) while staying 100% extendable—swap in vLLM, remote OpenAI-compatible hosts, new parsers, or custom stores without rewriting your app.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first developer experience with a single CLI (&lt;code&gt;lf&lt;/code&gt;) that manages projects, datasets, and chat sessions.&lt;/item&gt;
      &lt;item&gt;Production-ready architecture that mirrors server endpoints and enforces schema-based configuration.&lt;/item&gt;
      &lt;item&gt;Composable RAG pipelines you can tailor through YAML, not bespoke code.&lt;/item&gt;
      &lt;item&gt;Extendable everything: runtimes, embedders, databases, extractors, and CLI tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;📺 Video demo (90 seconds): https://youtu.be/W7MHGyN0MdQ&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install the CLI&lt;/p&gt;
        &lt;p&gt;macOS / Linux&lt;/p&gt;
        &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/llama-farm/llamafarm/main/install.sh | bash&lt;/code&gt;
        &lt;p&gt;Windows (via winget)&lt;/p&gt;
        &lt;code&gt;winget install LlamaFarm.CLI&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adjust Ollama context window&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Open the Ollama app, go to Settings → Advanced, and set the context window to match production (e.g., 100K tokens).&lt;/item&gt;
          &lt;item&gt;Larger context windows improve RAG answers when long documents are ingested.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create and run a project&lt;/p&gt;
        &lt;quote&gt;lf init my-project # Generates llamafarm.yaml using the server template lf start # Spins up Docker services &amp;amp; opens the dev chat UI&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start an interactive project chat or send a one-off message&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Interactive project chat (auto-detects namespace/project from llamafarm.yaml)
lf chat

# One-off message
lf chat "Hello, LlamaFarm!"&lt;/code&gt;
    &lt;p&gt;Need the full walkthrough with dataset ingestion and troubleshooting tips? Jump to the Quickstart guide.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Prefer building from source? Clone the repo and follow the steps in Development &amp;amp; Testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run services manually (without Docker auto-start):&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/llama-farm/llamafarm.git
cd llamafarm

# Install Nx globally and bootstrap the workspace
npm install -g nx
nx init --useDotNxInstallation --interactive=false

# Option 1: start both server and RAG worker with one command
nx dev

# Option 2: start services in separate terminals
# Terminal 1
nx start rag
# Terminal 2
nx start server&lt;/code&gt;
    &lt;p&gt;Open another terminal to run &lt;code&gt;lf&lt;/code&gt; commands (installed or built from source). This is equivalent to what &lt;code&gt;lf start&lt;/code&gt; orchestrates automatically.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Own your stack – Run small local models today and swap to hosted vLLM, Together, or custom APIs tomorrow by changing &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Battle-tested RAG – Configure parsers, extractors, embedding strategies, and databases without touching orchestration code.&lt;/item&gt;
      &lt;item&gt;Config over code – Every project is defined by YAML schemas that are validated at runtime and easy to version control.&lt;/item&gt;
      &lt;item&gt;Friendly CLI – &lt;code&gt;lf&lt;/code&gt;handles project bootstrapping, dataset lifecycle, RAG queries, and non-interactive chats.&lt;/item&gt;
      &lt;item&gt;Built to extend – Add a new provider or vector store by registering a backend and regenerating schema types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Initialize a project&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf init my-project&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Creates &lt;code&gt;llamafarm.yaml&lt;/code&gt; from server template.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Start dev stack + chat TUI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf start&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Spins up server, rag worker, monitors Ollama/vLLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Interactive project chat&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opens TUI using project from &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Send single prompt&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat "Explain retrieval augmented generation"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Uses RAG by default; add &lt;code&gt;--no-rag&lt;/code&gt; for pure LLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Preview REST call&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat --curl "What models are configured?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Prints sanitized &lt;code&gt;curl&lt;/code&gt; command.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Create dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets create -s pdf_ingest -b main_db research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validates strategy/database against project config.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Upload files&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets upload research-notes ./docs/*.pdf&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Supports globs and directories.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Process dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets process research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Streams heartbeat dots during long processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Semantic query&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf rag query --database main_db "What did the 2024 FDA letters require?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use &lt;code&gt;--filter&lt;/code&gt;, &lt;code&gt;--include-metadata&lt;/code&gt;, etc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See the CLI reference for full command details and troubleshooting advice.&lt;/p&gt;
    &lt;p&gt;LlamaFarm provides a comprehensive REST API (compatible with OpenAI's format) for integrating with your applications. The API runs at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Chat Completions (OpenAI-compatible)&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What are the FDA requirements?"}
    ],
    "stream": false,
    "rag_enabled": true,
    "database": "main_db"
  }'&lt;/code&gt;
    &lt;p&gt;RAG Query&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "clinical trial requirements",
    "database": "main_db",
    "top_k": 5
  }'&lt;/code&gt;
    &lt;p&gt;Dataset Management&lt;/p&gt;
    &lt;code&gt;# Upload file
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/data \
  -F "file=@document.pdf"

# Process dataset
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/process&lt;/code&gt;
    &lt;p&gt;Check your &lt;code&gt;llamafarm.yaml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;name: my-project        # Your project name
namespace: my-org       # Your namespace&lt;/code&gt;
    &lt;p&gt;Or inspect the file system: &lt;code&gt;~/.llamafarm/projects/{namespace}/{project}/&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;See the complete API Reference for all endpoints, request/response formats, Python/TypeScript clients, and examples.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;llamafarm.yaml&lt;/code&gt; is the source of truth for each project. The schema enforces required fields and documents every extension point.&lt;/p&gt;
    &lt;code&gt;version: v1
name: fda-assistant
namespace: default

runtime:
  provider: openai                   # "openai" for any OpenAI-compatible host, "ollama" for local Ollama
  model: qwen2.5:7b
  base_url: http://localhost:8000/v1 # Point to vLLM, Together, etc.
  api_key: sk-local-placeholder
  instructor_mode: tools             # Optional: json, md_json, tools, etc.

prompts:
  - role: system
    content: &amp;gt;-
      You are an FDA specialist. Answer using short paragraphs and cite document titles when available.

rag:
  databases:
    - name: main_db
      type: ChromaStore
      default_embedding_strategy: default_embeddings
      default_retrieval_strategy: filtered_search
      embedding_strategies:
        - name: default_embeddings
          type: OllamaEmbedder
          config:
            model: nomic-embed-text:latest
      retrieval_strategies:
        - name: filtered_search
          type: MetadataFilteredStrategy
          config:
            top_k: 5
  data_processing_strategies:
    - name: pdf_ingest
      parsers:
        - type: PDFParser_LlamaIndex
          config:
            chunk_size: 1500
            chunk_overlap: 200
      extractors:
        - type: HeadingExtractor
        - type: ContentStatisticsExtractor

datasets:
  - name: research-notes
    data_processing_strategy: pdf_ingest
    database: main_db&lt;/code&gt;
    &lt;p&gt;Configuration reference: Configuration Guide • Extending LlamaFarm&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swap runtimes by pointing to any OpenAI-compatible endpoint (vLLM, Mistral, Anyscale). Update &lt;code&gt;runtime.provider&lt;/code&gt;,&lt;code&gt;base_url&lt;/code&gt;, and&lt;code&gt;api_key&lt;/code&gt;; regenerate schema types if you add a new provider enum.&lt;/item&gt;
      &lt;item&gt;Bring your own vector store by implementing a store backend, adding it to &lt;code&gt;rag/schema.yaml&lt;/code&gt;, and updating the server service registry.&lt;/item&gt;
      &lt;item&gt;Add parsers/extractors to support new file formats or metadata pipelines. Register implementations and extend the schema definitions.&lt;/item&gt;
      &lt;item&gt;Extend the CLI with new Cobra commands under &lt;code&gt;cli/cmd&lt;/code&gt;; the docs include guidance on adding dataset utilities or project tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the Extending guide for step-by-step instructions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
        &lt;cell role="head"&gt;What it Shows&lt;/cell&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FDA Letters Assistant&lt;/cell&gt;
        &lt;cell&gt;Multi-document PDF ingestion, RAG queries, reference-style prompts&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/fda_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Raleigh UDO Planning Helper&lt;/cell&gt;
        &lt;cell&gt;Large ordinance ingestion, long-running processing tips, geospatial queries&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/gov_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;lf datasets&lt;/code&gt; and &lt;code&gt;lf rag query&lt;/code&gt; commands from each example folder to reproduce the flows demonstrated in the docs.&lt;/p&gt;
    &lt;code&gt;# Python server + RAG tests
cd server
uv sync
uv run --group test python -m pytest

# CLI tests
cd ../cli
go test ./...

# RAG tooling smoke tests
cd ../rag
uv sync
uv run python cli.py test

# Docs build (ensures navigation/link integrity)
cd ..
nx build docs&lt;/code&gt;
    &lt;p&gt;Linting: &lt;code&gt;uv run ruff check --fix .&lt;/code&gt; (Python), &lt;code&gt;go fmt ./...&lt;/code&gt; and &lt;code&gt;go vet ./...&lt;/code&gt; (Go).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord – chat with the team, share feedback, find collaborators.&lt;/item&gt;
      &lt;item&gt;GitHub Issues – bug reports and feature requests.&lt;/item&gt;
      &lt;item&gt;Discussions – ideas, RFCs, roadmap proposals.&lt;/item&gt;
      &lt;item&gt;Contributing Guide – code style, testing expectations, doc updates, schema regeneration steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to add a new provider, parser, or example? Start a discussion or open a draft PR—we love extensions!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Licensed under the Apache 2.0 License.&lt;/item&gt;
      &lt;item&gt;Built by the LlamaFarm community and inspired by the broader open-source AI ecosystem. See CREDITS for detailed acknowledgments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build locally. Deploy anywhere. Own your AI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/llama-farm/llamafarm"/><published>2025-10-07T15:30:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504470</id><title>IKEA Catalogs 1951-2021</title><updated>2025-10-08T05:38:32.994918+00:00</updated><content>&lt;doc fingerprint="71c3125f48ed4455"&gt;
  &lt;main&gt;
    &lt;p&gt;Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA catalogue&lt;/head&gt;
    &lt;p&gt;For over 70 years, the IKEA catalogue was produced in Ãlmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s â the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1950s&lt;/item&gt;
      &lt;item&gt;1960s&lt;/item&gt;
      &lt;item&gt;1970s&lt;/item&gt;
      &lt;item&gt;1980s&lt;/item&gt;
      &lt;item&gt;1990s&lt;/item&gt;
      &lt;item&gt;2000s&lt;/item&gt;
      &lt;item&gt;2010s&lt;/item&gt;
      &lt;item&gt;2020s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and youâll be amazed at what you find. In fact, youâll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 yearsâ time, weâll probably shake our heads and give a sigh.&lt;/p&gt;
    &lt;p&gt;IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages.&lt;/p&gt;
    &lt;p&gt;No. The IKEA catalogue has always only shown a selection of whatâs available in the stores. The catalogues from the 1970s and onwards show around 30â50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.&lt;/p&gt;
    &lt;p&gt;Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, weâre happy to help you out if we can. But 70 years is a long time, so we canât promise anything. While youâre waiting for our response you can always browse through the catalogues â the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.&lt;lb/&gt; Browse through stories about IKEA products from 7 decades. &lt;/p&gt;
    &lt;p&gt;IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?&lt;lb/&gt; The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didnât sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikÃ©a-nytt (literally ikÃ©a news). Sometimes it was distributed as a supplement in farming paper Jordbrukarnas FÃ¶reningsblad, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikÃ©a-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, youâll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.&lt;lb/&gt; Browse through all issues of ikÃ©a-nytt.&lt;/p&gt;
    &lt;p&gt;Not really. We do have a few copies of each yearâs IKEA catalogue in our archives, which weâre saving for posterity. They should be handled as little as possible to keep them in good condition, so weâve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!&lt;/p&gt;
    &lt;p&gt;Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once youâve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.&lt;/p&gt;
    &lt;p&gt;Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as itâs not for commercial purposes). Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more.&lt;/p&gt;
    &lt;p&gt;Yes! You can find all press material, including images, information about current exhibitions and much more, in the IKEA Museum press room.&lt;/p&gt;
    &lt;p&gt;At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if youâve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.&lt;/p&gt;
    &lt;p&gt;Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ikeamuseum.com/en/explore/ikea-catalogue/"/><published>2025-10-07T15:35:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504973</id><title>Show HN: Timelinize – Privately organize your own data from everywhere, locally</title><updated>2025-10-08T05:38:32.547440+00:00</updated><content>&lt;doc fingerprint="e64842e6eda1dcc1"&gt;
  &lt;main&gt;
    &lt;p&gt;Timelinize ("time-lynn-eyes") is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.&lt;/p&gt;
    &lt;p&gt;Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.&lt;/p&gt;
    &lt;p&gt;By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.&lt;/p&gt;
    &lt;p&gt;Most apps store your data "in the cloud" and out of your control. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.&lt;/p&gt;
    &lt;p&gt;Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:&lt;/p&gt;
    &lt;p&gt;With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.&lt;/p&gt;
    &lt;p&gt;The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.&lt;/p&gt;
    &lt;p&gt;Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).&lt;/p&gt;
    &lt;p&gt;Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.&lt;/p&gt;
    &lt;p&gt;Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.&lt;/p&gt;
    &lt;p&gt;Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.&lt;/p&gt;
    &lt;p&gt;Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.&lt;/p&gt;
    &lt;p&gt;Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.&lt;/p&gt;
    &lt;p&gt;Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.&lt;/p&gt;
    &lt;p&gt;Customize the map to change its theme, layers, and even make it 3D.&lt;/p&gt;
    &lt;p&gt;The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.&lt;/p&gt;
    &lt;p&gt;Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.&lt;/p&gt;
    &lt;p&gt;An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.&lt;/p&gt;
    &lt;p&gt;Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:&lt;/p&gt;
    &lt;p&gt;Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.&lt;/p&gt;
    &lt;p&gt;For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.&lt;/p&gt;
    &lt;p&gt;Search for pictures and messages by describing them, or find similar items to what you're viewing.&lt;/p&gt;
    &lt;p&gt;All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.&lt;/p&gt;
    &lt;p&gt;The database schema has been meticulously designed and refined to be as adaptable as possible.&lt;/p&gt;
    &lt;p&gt;Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:&lt;/p&gt;
    &lt;p&gt;Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).&lt;/p&gt;
    &lt;p&gt;Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.&lt;/p&gt;
    &lt;p&gt;Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.&lt;/p&gt;
    &lt;p&gt;Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.&lt;/p&gt;
    &lt;p&gt;Collect your data from various sources. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.&lt;/p&gt;
    &lt;p&gt;Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.&lt;/p&gt;
    &lt;p&gt;Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.&lt;/p&gt;
    &lt;p&gt;Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://timelinize.com"/><published>2025-10-07T16:10:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505539</id><title>Seeing like a software company</title><updated>2025-10-08T05:38:32.271449+00:00</updated><content>&lt;doc fingerprint="2615d9162c2d05e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Seeing like a software company&lt;/head&gt;
    &lt;p&gt;The big idea of James C. Scott’s Seeing Like A State can be expressed in three points:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Modern organizations exert control by maximising “legibility”: by altering the system so that all parts of it can be measured, reported on, and so on.&lt;/item&gt;
      &lt;item&gt;However, these organizations are dependent on a huge amount of “illegible” work: work that cannot be tracked or planned for, but is nonetheless essential.&lt;/item&gt;
      &lt;item&gt;Increasing legibility thus often actually lowers efficiency - but the other benefits are high enough that organizations are typically willing to do so regardless.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By “legible”, I mean work that is predictable, well-estimated, has a paper trail, and doesn’t depend on any contingent factors (like the availability of specific people). Quarterly planning, OKRs, and Jira all exist to make work legible. Illegible work is everything else: asking for and giving favors, using tacit knowledge that isn’t or can’t be written down, fitting in unscheduled changes, and drawing on interpersonal relationships. As I’ll argue, tech companies need to support both of these kinds of work.&lt;/p&gt;
    &lt;p&gt;Thinking in terms of legibility and illegibility explains so many of the things that are confusing about large software companies. It explains why companies do many things that seem obviously counter-productive, why the rules in practice are so often out of sync with the rules as written, and why companies are surprisingly willing to tolerate rule-breaking in some contexts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seeing like a state&lt;/head&gt;
    &lt;p&gt;James C. Scott was writing about the “high modernist” movement in governance that produced (among other things) the tidy German forests of the 19th century1. In order to produce wood at scale, the German state demanded legibility: forests that an inspector could visit to tally up the amount of healthy trees. That means that you must be able to walk through the forest - i.e. the underbrush must be controlled - and the trees ought to be ideally laid out in neat rows of a single type.&lt;/p&gt;
    &lt;p&gt;Proponents of legibility often describe their processes as “efficiency measures” or ways to “avoid waste”. But overall, the new “efficient” forests were in fact far less efficient than the old, illegible forests. They produced less wood per year and required more effort to fight disease, because the underbrush proved surprisingly load-bearing to the health of the soil, and the variety of species turned out to have been an asset. The new homogeneous forests could be wiped out by a single parasite or disease in a way that the older, more varied forests could not.&lt;/p&gt;
    &lt;p&gt;However, the advantages of legibility are enormous. Once you know exactly how many trees you have, you can plan ahead, make large trade deals, avoid graft, and so on. To me, this is the most interesting point Scott makes. Large organizations did genuinely think that more legibility would necessarily increase efficiency2. But even when it became clear that that was false, those organizations continued pushing for legibility anyway, because the other advantages were too powerful.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seeing like a software company&lt;/head&gt;
    &lt;p&gt;It’s the same way in software companies. It’s almost a truism among software engineers that a single engineer can be more efficient alone than they can by working as part of a team. That’s why there are so many anecdotes about engineers taking leave to finally get some work done, or about productive work being done on nights and weekends.&lt;/p&gt;
    &lt;p&gt;Likewise, it should be obvious to any practicing engineer that engineer-driven work goes far more swiftly than work that is mandated from above. Engineer-driven work doesn’t need to be translated into something that makes sense, doesn’t need to be actively communicated in all directions, and can in general just be done in the most straightforward and efficient way.&lt;/p&gt;
    &lt;p&gt;This is why tiny software companies are often much better than large software companies at delivering software: it doesn’t matter that the large company is throwing ten times the number of engineers at the problem if the small company is twenty times more efficient3.&lt;/p&gt;
    &lt;p&gt;Why don’t large companies react to this by doing away with all of their processes? Are they stupid? No. The processes that slow engineers down are the same processes that make their work legible to the rest of the company. And that legibility (in dollar terms) is more valuable than being able to produce software more efficiently.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why legibility is valuable to tech companies&lt;/head&gt;
    &lt;p&gt;What does legibility mean to a tech company, in practice? It means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The head of a department knows, to the engineer, all the projects the department is currently working on&lt;/item&gt;
      &lt;item&gt;That head also knows (or can request) a comprehensive list of all the projects the department has shipped in the last quarter&lt;/item&gt;
      &lt;item&gt;That head has the ability to plan work at least one quarter ahead (ideally longer)&lt;/item&gt;
      &lt;item&gt;That head can, in an emergency, direct the entire resources of the department at immediate work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that “shipping high quality software” or “making customers happy” or even “making money” is not on this list. Those are all things tech companies want to do, but they’re not legibility.&lt;/p&gt;
    &lt;p&gt;Our small-but-efficient software company meets only one of these criteria: the ability to pivot to some immediate problem that needs solving. The other information is all locked up in various engineers’ heads, who may or may not remember what they did two months ago (and who certainly won’t be willing to commit to work two months from now). That’s not necessarily a problem, so long as everyone’s on the same page about what needs doing and the product is continuing to improve.&lt;/p&gt;
    &lt;p&gt;A typical large software company meets almost all of these criteria - I say almost, because in some companies or departments the ability to direct immediate work has atrophied (more on that later). But aside from that, large companies are usually very good at cataloguing what is being worked on, remembering what’s been shipped in the past, and planning work in the medium-to-long-term.&lt;/p&gt;
    &lt;p&gt;Why are these capabilities so valuable to a large software company, when small software companies can do without them? This is leaving my area of expertise somewhat, but I’m pretty sure the main answer is large enterprise deals. Making deals with large enterprise customers is fantastically profitable. Any sufficiently large SaaS will thus pivot from small customers to enterprise customers, if it can4. But enterprise deals (a) can take many, many months to set up, and (b) require making long-term feature commitments. An illegible company is not configured to be able to stick with a boring enterprise deal for many months, constantly answering questions and delivering features. Large enterprise customers simply won’t trust a small software company to deliver the things they need over the next year or two.&lt;/p&gt;
    &lt;p&gt;Customers like this typically value legibility very highly, and so demand that their vendors also be legible. In fact, highly legible organizations struggle to communicate at all with organizations that are less legible (and vice versa). They don’t have access to the right bona fides, they don’t talk the same language, and so on. This puts real pressure on growing tech companies to become more legible, even if it hurts their ability to deliver software.&lt;/p&gt;
    &lt;head rend="h3"&gt;Legible assumptions&lt;/head&gt;
    &lt;p&gt;In the pursuit of legibility, large tech companies make simplifying assumptions about the nature of tech work. For instance, they assume:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any engineers with the same job title perform roughly the same.&lt;/item&gt;
      &lt;item&gt;Engineers can be shuffled and reorganized without substantial loss of productivity.&lt;/item&gt;
      &lt;item&gt;A team will maintain the same level of productivity over time, if it has the same number of engineers.&lt;/item&gt;
      &lt;item&gt;Projects can be estimated ahead of time, albeit with some margin for error. The more time spent estimating a project, the more accurate the estimate will become.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, all of these are false. Within the same job title, there is significant variance in engineering ability. Engineers have different skillsets and interests, and will work much more productively on projects that are a good fit for them. Because of this, the productivity of a team has a weak relationship to the number of engineers on the team.&lt;/p&gt;
    &lt;p&gt;Project estimates are largely fantasy. More accurately, they’re performative: the initial estimate determines the kind of engineering work that gets done to deliver by that estimate, not the other way around. For this reason, breaking down a project into parts and estimating each part often delivers a less accurate estimate, because it makes it harder for engineers to align with the overall ship date.&lt;/p&gt;
    &lt;p&gt;However, these assumptions are true enough for their purpose, which is to provide legibility to the executives in charge of the company. Whether the project estimate is accurate or not, it can be used to plan and to communicate with other large organizations (who are themselves typically aware that these estimates ought not to be taken completely seriously).&lt;/p&gt;
    &lt;head rend="h3"&gt;Temporary sanctioned zones of illegibility&lt;/head&gt;
    &lt;p&gt;I mentioned above that large companies sometimes lose the ability to prioritize immediate work. This is because the processes that make work legible also impose a serious delay. Consider the steps that a hypothetical large company might take before beginning to write code on a problem:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Somebody has a product idea.&lt;/item&gt;
      &lt;item&gt;They take that idea to the Product org, where it goes into the “planning” stage. Meetings are had about the idea.&lt;/item&gt;
      &lt;item&gt;Once the Product org formally decide they want to do it, the idea then passes to the Engineering org: into the hands of some council of engineering architects, who are tasked with the initial technical review. They figure out how it fits into the general engineering priorities and give it a very rough time estimate.&lt;/item&gt;
      &lt;item&gt;The VPs and senior managers in the engineering org then negotiate which team will own the work. Often this is a semi-technical, semi-organizational decision (because which service the work should fall into is at least partly a technical question).&lt;/item&gt;
      &lt;item&gt;Finally the work lands on the team. It enters the team planning backlog, where the team technical lead breaks it out into smaller pieces of work.&lt;/item&gt;
      &lt;item&gt;Those smaller pieces of work enter the team ticket backlog, and are estimated in the team’s weekly planning meeting.&lt;/item&gt;
      &lt;item&gt;Finally some of those pieces of work make it into the next sprint, and are picked up by an engineer who can actually do it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m leaving out many crucial parts of this process: the updates on each ticket, which then roll up to higher levels of management, legal and design review, which can themselves take weeks, and then the final steps involved in shipping the change to customers. All of this makes the work very legible, but none of this is compatible with work that has to be done right now. What do you do when there’s a sudden, urgent technical problem - maybe you’re about to overflow your &lt;code&gt;int&lt;/code&gt; ID column on the users table, or some very large customer is experiencing a show-stopping bug?5&lt;/p&gt;
    &lt;p&gt;To solve this kind of problem, tech companies often reserve the right to create temporary zones where illegible work is allowed. Sometimes these are called “virtual teams”, or “strike teams” (or even the colourful name “tiger teams”). They are composed of hand-picked engineers who are trusted by the organization. Often there is no manager assigned at all, but instead some very senior engineer who’s tasked with running the project. These teams are given a loose mandate - like “stop the database from falling over every few days” - and allowed to do basically whatever it takes to get it done.&lt;/p&gt;
    &lt;p&gt;This is a smart compromise between complete illegibility, which as I discussed above would make the company unable to make deals with its richest customers, and complete legibility, which would force even urgent company-killing issues to go through the entire laborious process of scoping, planning and estimating.&lt;/p&gt;
    &lt;p&gt;Even when siloed to a temporary team, sanctioned illegibility still coexists awkwardly with the rest of the organization. Engineers outside the team don’t like seeing other engineers given the freedom to work without the burden of process: either because they’re jealous, or because they’re believers in process and think that such work is unacceptably dangerous. Managers also don’t like extending that level of trust. That’s why sanctioned efforts like this are almost always temporary. The majority of the illegible work that occurs in large organizations is still unsanctioned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Permanent zones of unsanctioned illegibility&lt;/head&gt;
    &lt;p&gt;If you’re an engineer on team A, and you need team B to do some kind of work for you, the formal way to do this is to create an issue in their “planning” backlog and wait for it to go through the entire twelve-step process before it finally makes its way into one of their sprints, where hopefully somebody will pick it up and do it. This can take weeks to months. When what you want is a one-line change, it’s incredibly frustrating to watch your requested work item go through all these steps - each one of which takes many times longer than it would take to simply do the work.&lt;/p&gt;
    &lt;p&gt;The official way around this problem is that team A should anticipate in their planning process that team B will need to do this work, so that piece for team B can enter their backlog at the same time as it enters team A’s backlog. That way (in theory) they should be complete at around the same time6. Any practicing software engineer knows how ridiculous this idea is. You can never anticipate every change that has to be made months before you start writing code.&lt;/p&gt;
    &lt;p&gt;The actual way around this problem is illegible backchannels. An engineer on team A reaches out to an engineer on team B asking “hey, can you make this one-line change for me”. That engineer on team B then does it immediately, maybe creating a ticket, maybe not. Then it’s done! This works great, but it’s illegible because the company can’t expect it or plan for it - it relies on the interpersonal relationships between engineers on different teams, which are very difficult to quantify. If you’re a well-liked engineer, your ability to pull on these backchannels is significantly greater than if you’re brand-new or have a bad reputation. But how well-liked you are is not something companies can officially use when they’re planning projects.&lt;/p&gt;
    &lt;p&gt;Backchannels are a constant presence at all levels of the company. As well as engineer-engineer cross-team backchannels, there are backchannels inside teams, between managers, product managers, and so on. Often when a question is asked formally in a public space, it’s already been rehearsed and workshopped privately with the person who’s answering the question. None of this is or can be documented as part of the formal processes of the company, but it’s load-bearing nonetheless. Many formal processes simply cannot function without the consensus mechanisms or safety valves offered by backchannels.&lt;/p&gt;
    &lt;p&gt;Sometimes backchannels can go badly. Earlier this year I wrote Protecting your time from predators in large tech companies about how some people use backchannels to benefit themselves at the expense of the naive engineers they’re requesting work from. And it never feels good when you get the sense that everyone in a meeting has privately discussed the topic ahead of time except for you. For these reasons, some people think that backchannels themselves are a bad thing, and that all communication should go via formal, legible channels.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sociopaths, clueless, and losers&lt;/head&gt;
    &lt;p&gt;There’s another text which has been as influential to many as Seeing Like A State. This one isn’t a book, but a blog post: The Gervais Principle by Venkatesh Rao. Rao divides organizations into three groups. At the top are the “sociopaths”, who cynically use organizational rules for their own benefit. In middle management are the “clueless”, who are bought into the formal rules of the organization and don’t realise that there’s a deeper game being played above their heads. Below them are the “losers”, who realise there’s a game being played but don’t want to play it. The name “losers” is not a value judgement - I think it’s meant to affectionately pick out people like the leads in Clerks, who are too authentic to get involved in the corporate game.&lt;/p&gt;
    &lt;p&gt;I don’t agree with everything in The Gervais Principle, though I think it’s worth a read (if you’re interested in this stuff, you should also read the excellent Moral Mazes). But the categories here can be very naturally read in terms of legibility. Both sociopaths and losers are engaged with the illegible world of the organization. Sociopaths use this world to climb the ladder, while losers use it to carve out a cosy low-effort niche for themselves.&lt;/p&gt;
    &lt;p&gt;The “clueless” are only engaged with legible processes. They’re the people who, when they want to get promoted, go and look up the formal job ladder and make a plan for how they can exemplify each of the values at the next level. They’re concerned with doing everything by the book. When they’re forced into an encounter with the illegible world, their reaction is to shake their heads and start drafting updates to the legible process that can accommodate some pale approximation of the more-efficient illegible process.&lt;/p&gt;
    &lt;p&gt;I think it’s far too cynical to call these people clueless. Legible process is still very important - after all, it’s the large part of what the organization does. Improving formal processes is still very high-leverage work, even if formal processes can’t ever describe the entirety of how an organization operates. People who are invested in legibility have real value to any tech company.&lt;/p&gt;
    &lt;p&gt;However, thinking about people in Rao’s categories - people who exploit illegibility, people who find it distasteful, and people who use it casually - can be illuminating. Many frequent areas of conflict in software companies stem from the friction between these groups of people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;I write a lot about recognizing and using illegibility in tech companies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Breaking the (formal, legible) rules is sometimes the right thing to do&lt;/item&gt;
      &lt;item&gt;Beware of savvy product managers (and others) exploiting illegible channels to chisel work out of naive engineers&lt;/item&gt;
      &lt;item&gt;Competent engineers should work on “side bets” that are outside the normal planning process&lt;/item&gt;
      &lt;item&gt;Getting promoted to Staff and above has very little to do with the formal job ladder&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In general, advice about illegible processes is what I call “dangerous advice”. It’s dangerous because if you make it legible - for instance, if you announce publicly that you’re getting a piece of work done through backchannels instead of the formal process - you will be punished by the organization even if your management chain wanted you to do it. You can’t speak too loudly about it. It has to stay illegible.&lt;/p&gt;
    &lt;p&gt;I get a lot of negative feedback on these posts from people who say that you should never sidestep the formal process. According to them, if it needs changing, you should change the process instead of going around it. In other words, everything that goes on in a tech company should be legible, and illegible processes should be stamped out and converted to legible ones.&lt;/p&gt;
    &lt;p&gt;I think this view is naive. All organizations - tech companies, social clubs, governments - have both a legible and an illegible side. The legible side is important, past a certain size. It lets the organization do things that would otherwise be impossible: long-term planning, coordination with other very large organizations, and so on. But the illegible side is just as important. It allows for high-efficiency work, offers a release valve for processes that don’t fit the current circumstances, and fills the natural human desire for gossip and soft consensus.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;This is the first example Scott gives, but I promise I did read the whole book. Other examples: the construction of Brasília, Operation Vijiji in Tanzania, and the Soviet attempt to replace individual peasant farms with state-run collectives.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This is a very common false belief today among software engineers.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I don’t think small companies just work harder; plenty of people at large companies work very hard. I also don’t think that small companies just have better engineers - what advantage they have in enthusiasm is often outweighed by the fact that they can’t afford to pay as well.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I was at Zendesk during the height of its pivot.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ironically, the most urgent types of problem typically can be solved via a normal “incident” process - but this itself is usually a zone where the rules are relaxed a bit in order to resolve the incident as quickly as possible. Anyway, here I’m not talking about incidents but about projects that will take a couple of weeks to resolve.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The other, healthier official way is to allow teams to make small changes to other teams’ services themselves. But this only goes so far - the other team will always be the gatekeepers for changes like this, and are always in a position to slow down the change by days or weeks.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News.&lt;/p&gt;
    &lt;p&gt;September 3, 2025 │ Tags: tech companies&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.seangoedecke.com/seeing-like-a-software-company/"/><published>2025-10-07T16:49:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506143</id><title>German government comes out against Chat Control</title><updated>2025-10-08T05:38:31.829413+00:00</updated><content>&lt;doc fingerprint="77d803d92c0426bd"&gt;
  &lt;main&gt;
    &lt;p&gt;Great news and big win for privacy in the EU! 🇪🇺🇩🇪 Germany’s ruling CDU/CSU party made it clear today: there will be no chat control - as pushed for by other EU countries - with this German government.&lt;/p&gt;
    &lt;p&gt;40 Sekunden kurz und präzise: Mit der CDU/CSU wird es keine anlasslose Chatkontrolle geben, wie sie von einigen Staaten in der EU gefordert wird.&lt;/p&gt;
    &lt;p&gt;Oct 7, 2025 · 4:13 PM UTC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xcancel.com/paddi_hansen/status/1975595307800142205"/><published>2025-10-07T17:31:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506268</id><title>Less is more: Recursive reasoning with tiny networks</title><updated>2025-10-08T05:38:31.713552+00:00</updated><content>&lt;doc fingerprint="e51fd9a9ac595e1b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Less is More: Recursive Reasoning with Tiny Networks&lt;/head&gt;
    &lt;p&gt;In this new paper, I propose Tiny Recursion Model (TRM), a recursive reasoning model that achieves amazing scores of 45% on ARC-AGI-1 and 8% on ARC-AGI-2 with a tiny 7M parameters neural network. The idea that one must rely on massive foundational models trained for millions of dollars by some big corporation in order to achieve success on hard tasks is a trap. Currently, there is too much focus on exploiting LLMs rather than devising and expanding new lines of direction. With recursive reasoning, it turns out that “less is more”: you don’t always need to crank up model size in order for a model to reason and solve hard problems. A tiny model pretrained from scratch, recursing on itself and updating its answers over time, can achieve a lot without breaking the bank.&lt;/p&gt;
    &lt;p&gt;This work came to be after I learned about the recent innovative Hierarchical Reasoning Model (HRM). I was amazed that an approach using small models could do so well on hard tasks like the ARC-AGI competition (reaching 40% accuracy when normally only Large Language Models could compete). But I kept thinking that it is too complicated, relying too much on biological arguments about the human brain, and that this recursive reasoning process could be greatly simplified and improved. Tiny Recursion Model (TRM) simplifies recursive reasoning to its core essence, which ultimately has nothing to do with the human brain, does not require any mathematical (fixed-point) theorem, nor any hierarchy.&lt;/p&gt;
    &lt;p&gt;See the paper for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;TLDR&lt;/head&gt;
    &lt;p&gt;Tiny Recursion Model (TRM) recursively improves its predicted answer y with a tiny network. It starts with the embedded input question x and initial embedded answer y and latent z. For up to K improvements steps, it tries to improve its answer y. It does so by i) recursively updating n times its latent z given the question x, current answer y, and current latent z (recursive reasoning), and then ii) updating its answer y given the current answer y and current latent z. This recursive process allows the model to progressively improve its answer (potentially addressing any errors from its previous answer) in an extremely parameter-efficient manner while minimizing overfitting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html"/><published>2025-10-07T17:42:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507195</id><title>The murky economics of the data-centre investment boom</title><updated>2025-10-08T05:38:31.496382+00:00</updated><content/><link href="https://www.economist.com/business/2025/09/30/the-murky-economics-of-the-data-centre-investment-boom"/><published>2025-10-07T18:52:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507398</id><title>Eliminating contrails from flying could be cheap</title><updated>2025-10-08T05:38:31.118678+00:00</updated><content>&lt;doc fingerprint="774ec8726186b74b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Eliminating contrails from flying could be incredibly cheap&lt;/head&gt;
    &lt;head rend="h3"&gt;Could we halve aviation's climate impact at a fraction of the cost of sustainable aviation fuels?&lt;/head&gt;
    &lt;p&gt;Eliminating CO2 emissions from flying is going to be expensive, regardless of the solution the world adopts.1&lt;/p&gt;
    &lt;p&gt;But aviation also contributes to global warming through its non-CO2 effects. Those are mostly “contrails”, which I’ll explain in more detail soon. Getting rid of those could be incredibly cheap. So cheap that it’s difficult to understand why we don’t just go ahead and fix it.&lt;/p&gt;
    &lt;p&gt;On a recent podcast, I spoke to Ian McKay, CEO of Orca Sciences, about this. One of their portfolio projects is Contrails.org. Their solution to eliminating contrails is to accurately forecast and model the atmospheric conditions that generate them, and reroute planes so that they avoid these “contrail-forming” parts of the atmosphere.&lt;/p&gt;
    &lt;p&gt;This is a solution that I hadn’t really paid much attention to, and most people are unaware of. So I thought I’d do a deep dive on contrails; explore how this solution might work; and whether it’s really that cheap.&lt;/p&gt;
    &lt;p&gt;To pre-empt the critics: this solution does not mean the aviation industry can ignore the CO2 impacts of flying. Tackling contrails would not absolve them of responsibility for finding low-carbon alternatives to jet fuel. It’s not a substitute, but an addition. Currently, their non-CO2 impacts are not measured or reported, so bringing more attention to contrails means they’re taking full responsibility for their climate impact, which is not the case at the moment.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are contrails?&lt;/head&gt;
    &lt;p&gt;When you see a plane in the sky, you might see a small, white cloud-like trail behind it. Those are contrails (short for “condensation trails”).&lt;/p&gt;
    &lt;p&gt;Water vapour, soot and other particles (basically pollutants) are emitted from the back of jet engines. Water droplets can condense around these particles, and because it’s pretty cold up there, they can freeze to form ice crystals. Sometimes these white lines are very faint and hard to see. But in some cases, they can form “cirrus clouds”: wispy ones that form at high altitudes.&lt;/p&gt;
    &lt;p&gt;These contrails can have both cooling and warming impacts. I’ve sketched this out in the schematic below.&lt;/p&gt;
    &lt;p&gt;Some sunlight can reflect off of them, rather than passing through to the surface, which has a cooling effect.&lt;/p&gt;
    &lt;p&gt;Most sunlight, though, does pass through, and outgoing irradiation then gets trapped by the cirrus clouds. This has a warming effect, which tends to be larger than the cooling one, so on net, contrails cause warming.&lt;/p&gt;
    &lt;p&gt;Since someone asked about this over email: the fact that there is no sunlight at night, and less during winter, there is less to “reflect” off the top of cirrus clouds. That means the cooling effect is weaker at night, and in winter, and the net warming effect stronger. This means avoiding contrails in winter and at night has an even stronger impact on reducing warming.2&lt;/p&gt;
    &lt;head rend="h2"&gt;What impact do they have on global warming?&lt;/head&gt;
    &lt;p&gt;It’s common to want to compare them to CO2 emissions, but it’s first worth emphasising how different the contributions are in terms of intensity and persistence.&lt;/p&gt;
    &lt;p&gt;Contrails have a strong “effective radiative forcing” effect. This basically measures the net change in energy flow at the top of the atmosphere: and that change in energy flow dictates how much warming is needed at the surface to offset it. But, this warming effective is very short-lived. If we were to stop contrails today, the warming effect would disappear within a day or so.&lt;/p&gt;
    &lt;p&gt;Think of it like a very brief but strong pulse of energy.&lt;/p&gt;
    &lt;p&gt;CO2, on the other hand, has a smaller effect on radiative forcing, but once you emit it, it stays there for centuries or more.&lt;/p&gt;
    &lt;p&gt;I thought this diagram from Contrails.org makes this point clearly. This article by them explains the comparison in much more detail.&lt;/p&gt;
    &lt;p&gt;When we think about the climate impacts of aviation, then, most of the warming from CO2 emissions is not due to the emissions this year, but the cumulative effect (which persists) over the past 70 years. But for contrails, the warming impact is only really from those created very recently (hours to days); the small temperature response decays over months to a few years.&lt;/p&gt;
    &lt;p&gt;You might have heard people say that “more than half of the warming caused by aviation comes from non-CO2 sources”. A big part of that is contrails. But this does not mean that for any given flight, half of the warming is coming from contrails and the other half from burning jet fuel.&lt;/p&gt;
    &lt;p&gt;This apparent ‘half-half’ balance is a coincidence of timing: the cumulative CO₂ effect built up over decades happens to be of similar order to the instantaneous contrail effect for that year. In the chart below you can see the effective radiative forcing caused by CO2 and contrails in 2019. Again, the CO2 emitted in 2019 is just a small part of the warming. Most of comes from emissions built over decades, that stay there. It just so happens that this cumulative amount of warming is not that different from the instantaneous, short-lived impact of contrails in 2019. Eventually more and more CO2 emissions will accumulate, and the share coming from contrails will shrink in relative terms.&lt;/p&gt;
    &lt;p&gt;But as it stands today, we could get rid of around half of the warming impact — maybe slightly less — from aviation, if we were to tackle contrails. The impact would be almost immediate.&lt;/p&gt;
    &lt;p&gt;How, then, do contrails stack up in terms of total warming? They contribute roughly 2% to the world’s effective radiative forcing; tackling them would reduce that by a similar amount.3&lt;/p&gt;
    &lt;p&gt;What this comparison should make extremely clear is that reducing contrails does not mean we don’t also need to tackle CO2 emissions from aviation. Ultimately that is the persistent driver of long-term temperature change. What tackling contrails now would do is slightly reduce the rate of warming (and therefore do something reduce the risks of nearer-term feedbacks that could affect the release of CO2 from natural systems, and also affect long-term temperature change). It is not an excuse or a substitute for finding a way to decarbonise jet fuel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Only a few percent of flights cause most of the warming&lt;/head&gt;
    &lt;p&gt;One crucial reason why eliminating contrails could be so cost-effective is that a very small percentage of flights create the majority of the impact. This means we don’t need to divert or shift the trajectory of all the world’s flights; only a few percent of them.&lt;/p&gt;
    &lt;p&gt;In the chart below, you can see the breakdown of the warming effect across the world’s flights.4 On the left-hand side, we have the share of flights, and on the right, their collective contribution to the total warming impact of contrails.&lt;/p&gt;
    &lt;p&gt;Just 3% of flights generate 80% of the warming. A further 14% generate 29%.&lt;/p&gt;
    &lt;p&gt;You might notice that this sums to 109%. But this is because some flights generate a cooling effect of 9%. Put them together and we get 100%.&lt;/p&gt;
    &lt;p&gt;Most flights — three-quarters of them — barely generate contrails at all and cause no warming or cooling.&lt;/p&gt;
    &lt;p&gt;Some sources cite slightly different numbers for this “80% warming effect”. For example, Contrails.org cite 5% of flights. I’ve seen others quote 2%.5 But the point remains the same: a few percent of the flights completely dominate the climate impact.&lt;/p&gt;
    &lt;head rend="h2"&gt;There are ways to dramatically reduce them&lt;/head&gt;
    &lt;p&gt;So, how can we get rid of these contrails?&lt;/p&gt;
    &lt;p&gt;Contrails with a strong warming impact mostly form in thin regions of the atmosphere, which are cold and humid. If planes fly through these zones of atmosphere, contrails are much more likely to form.&lt;/p&gt;
    &lt;p&gt;The solution, then, is for some planes to take a short detour to avoid them. You can see this in the schematic below.&lt;/p&gt;
    &lt;p&gt;How would we know which planes to re-route and by how much?&lt;/p&gt;
    &lt;p&gt;Using detailed weather forecasts, satellite images, and flight plans, scientists can identify where these zones will be far in advance and work with flight planners to find a way to reroute flights crossing these zones to avoid them. These forecasts and models are what Contrails.org do.&lt;/p&gt;
    &lt;p&gt;Google also launched “Project Contrails” which uses Artificial Intelligence (AI) to build models that can do this.&lt;/p&gt;
    &lt;p&gt;Of course, this wouldn’t work if these planes had to do a severe detour. People would not be happy about a longer flight time. And, the extra fuel that would need to be burned to go the extra distance would eventually cancel out the climate benefits from getting rid of the contrails.&lt;/p&gt;
    &lt;p&gt;The proposed detours typically result in a 1% shift (and again, this is only for a small percentage of flights). That means increasing fuel use and flight time by around 1%. So if your flight is three hours long, it’s only adding an extra two minutes. For a 10-hour flight, six minutes. This seems socially acceptable to me; most people would barely notice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stopping warming from contrails could be incredibly cheap&lt;/head&gt;
    &lt;p&gt;The fact that the warming impact is skewed towards such a small share of flights dramatically reduces the costs.&lt;/p&gt;
    &lt;p&gt;What are the costs associated with implementing this?&lt;/p&gt;
    &lt;p&gt;There are operational costs associated with weather prediction, modelling, and integration into flight planning. Especially with the integration of AI, this is probably not that expensive. A bit more costly is the extra jet fuel that’s needed for rerouted planes.&lt;/p&gt;
    &lt;p&gt;When I spoke with Ian McKay, he suggested the additional cost would be around $5 per flight. I think he meant this as $5 spread across the entire flight (not per passenger). This is also the figure they give on Contrails.org.6 I also think that in this assumption, the costs are spread evenly across the entire airline fleet (regardless of whether they’re rerouted or not). For the small share of rerouted flights alone, the “per flight” cost would be higher.&lt;/p&gt;
    &lt;p&gt;That’s incredibly low. Spreading that over 100 passengers, and each is paying just 5 cents extra.&lt;/p&gt;
    &lt;p&gt;Other studies have reported higher costs, although they’re still incredibly cheap.&lt;/p&gt;
    &lt;p&gt;This paper modelled over 84,000 flights and found that the additional cost of operations and fuel burn for rerouting increased costs by around $1.1 million.7 By my calculations, that’s around $10 to $15 per flight.&lt;/p&gt;
    &lt;p&gt;We can do a very basic back-of-the-envelope calculation to sense-check this. The total fuel cost of flying from Barcelona to Berlin is probably around $2,000.8 If the flight burned 1% extra fuel due to rerouting, the extra cost for the flight would be around $20. Add the operational costs of the forecasting, and this could be $30 to $40. Then spread across all flights, not just the rerouted ones, and this falls back down to the $5 to $10 range again.&lt;/p&gt;
    &lt;p&gt;Transport &amp;amp; Environment (T&amp;amp;E) estimates that the cost could range from $2 to $5 per passenger (or hundreds of dollars per flight).9 They do note that they make very conservative assumptions, and therefore find costs that are 3 to 10 times higher than those from other sources.&lt;/p&gt;
    &lt;p&gt;For a flight in Europe, such as from Barcelona to Berlin, the cost would be €1.20 ($1.88) per passenger. A Transatlantic ticket would be more expensive, around €3.90 for a trip from Paris to New York. Given that an economy ticket from Paris to New York probably costs around €350 to €400, this would increase the cost by around 1%.&lt;/p&gt;
    &lt;p&gt;Perhaps, then, the best estimate is somewhere in the middle: around 50 cents per passenger.&lt;/p&gt;
    &lt;p&gt;Translating this into the cost per tonne of carbon dioxide equivalent — the “carbon abatement” cost — shows how cheap this is compared to many other climate solutions. It’s probably in the range of a few dollars per tonne CO2e. Contrails.org estimates that it’s slightly below $1 per tonne.&lt;/p&gt;
    &lt;p&gt;Switching to “sustainable aviation fuel” currently has an estimated cost in the range of hundreds of dollars per tonne of CO2e avoided.10 Rather than a flight ticket being 1% more expensive, it would be more than double the price. Eliminating contrails is therefore hundreds of times cheaper and can be scaled much more quickly than replacing the entire aircraft fleet or its fuel source.11&lt;/p&gt;
    &lt;head rend="h2"&gt;Why aren’t we doing more to eliminate contrails?&lt;/head&gt;
    &lt;p&gt;When I asked Ian McKay why airlines were not doing more, he gave two main reasons.&lt;/p&gt;
    &lt;p&gt;The first is that even if the cost per flight is low, the total cost across their entire fleet adds up. Let’s take a quick example for British Airways. They operate around 300,000 flights per year. If we reroute 2% of those to avoid contrails, and rerouting increases fuel burn by around 2% (I’m being deliberately harsh here), then I estimate that the additional fuel costs are in the range of $1.2 to $2 million per year.12 Let’s say that the operational costs of forecasting and modelling adds another 50%. That takes us to around $2.5 to $3 million.&lt;/p&gt;
    &lt;p&gt;In 2024, British Airways had an operating profit of around $2.7 billion. Contrail avoidance would therefore be just 0.1% of its operating profits.&lt;/p&gt;
    &lt;p&gt;But I’m not convinced that this cost factor is the main reason. They could pass this cost on to consumers; flight prices vary by a lot more than a few dollars for a variety of factors. They could either make a huge deal of the fact that they’re dramatically cutting their climate impact, and get “PR” buy-in from consumers for that. Or they could keep quiet, and most consumers would never notice the difference in cost.&lt;/p&gt;
    &lt;p&gt;The second — which seems more likely — is that, currently, most people are unaware of the climate impact of contrails. In that sense, airlines can basically ignore it and pretend they don’t exist. By trying to tackle them, they’d only draw more attention. People would then be aware that the climate impact of aviation is even higher than they thought.&lt;/p&gt;
    &lt;p&gt;I still think that the airline that steps up and commits to eliminating contrails — possibly even claiming to have halved its climate impact — would be well-received by many customers. I would see it as reputational gain, rather than a risk.&lt;/p&gt;
    &lt;p&gt;Nonetheless, there are no signs that the aviation industry itself is going to step up. This is where government policy could step in.&lt;/p&gt;
    &lt;p&gt;Rather than an airline leading by example, a country or region could. In a more pro-climate political environment, the United States could have led this effort domestically, mandating that internal flights eliminate their contrails. More likely is the European Union. It has already been making some progress in this direction — not by mandating that airlines pay for contrail avoidance — but by simply reporting these climate impacts in the first place. Earlier this year, its trading system regulations were updated to require airlines to monitor and report non-CO2 impacts. That sounds basic, but it is not the standard across most of the world; these impacts are usually not included. Unsurprisingly, it has received pushback from the aviation industry, with them asking for these reports to be voluntary.&lt;/p&gt;
    &lt;p&gt;Progress will undoubtedly be met with initial resistance, but I still think that regulatory policy seems like the most likely path to widespread implementation.&lt;/p&gt;
    &lt;p&gt;What would help a lot is increasing public awareness of the existence of contrails, their climate impacts, and how inexpensive it could be to eliminate them. There is a general understanding that decarbonising aviation is expensive, and this often means the aviation industry gets more of a free ride. But this is based on replacing jet fuel. If people were aware that it could cut a huge chunk of its footprint at a fraction of the cost, they might be more demanding.&lt;/p&gt;
    &lt;p&gt;Eliminating a few percent of the world’s warming is a big deal when the costs are so small. It seems insane to me that such a cheap solution is sitting there, completely untapped.&lt;/p&gt;
    &lt;p&gt;This could be substituting jet fuel for an alternative such as green hydrogen or biofuels.&lt;lb/&gt;But some suggest that it could be cheaper to keep burning jet fuel and try to capture — and securely store — an equivalent amount of CO2 directly.&lt;/p&gt;
    &lt;p&gt;Their question went further, asking if having some additional warming in winter is actually beneficial as it reduces risks such as cold-related deaths.&lt;lb/&gt;This could be true if the impacts were local. However, the warming that results is both global, and lasts over the long-term (even if the immediate forcing is short-lived, as we’ll come on to).&lt;/p&gt;
    &lt;p&gt;Lee, D. S., Fahey, D. W., Skowron, A., Allen, M. R., Burkhardt, U., Chen, Q., ... &amp;amp; Wilcox, L. J. (2021). The contribution of global aviation to anthropogenic climate forcing for 2000 to 2018. Atmospheric Environment.&lt;/p&gt;
    &lt;p&gt;This is based on data published in the Transport and Environment (T&amp;amp;E) 2024 Report: Contrail avoidance: aviation’s climate opportunity of the decade.&lt;/p&gt;
    &lt;p&gt;Teoh, R., Engberg, Z., Schumann, U., Voigt, C., Shapiro, M., Rohs, S., &amp;amp; Stettler, M. E. (2024). Global aviation contrail climate effects from 2019 to 2021. Atmospheric Chemistry and Physics.&lt;/p&gt;
    &lt;p&gt;Here they say:&lt;lb/&gt;“Better yet, properly implemented, contrail management is low-cost: studies show a fleet-average fuel cost of roughly $5.00 per flight, or less than $1 per tonne of CO2 equivalent warming avoided.”&lt;/p&gt;
    &lt;p&gt;Agarwal, A., Meijer, V. R., Eastham, S. D., Speth, R. L., &amp;amp; Barrett, S. R. (2022). Reanalysis-driven simulations may overestimate persistent contrail formation by 100%–250%. Environmental Research Letters.&lt;/p&gt;
    &lt;p&gt;This assumes burning around 3,000 litres of fuel, weighing around 2.5 tonnes.&lt;lb/&gt;The cost per tonne is around $900.&lt;lb/&gt;That gives a total cost of around $2250.&lt;/p&gt;
    &lt;p&gt;Again, these costs are distributed across all flights, not just those that are rerouted.&lt;/p&gt;
    &lt;p&gt;Watson, M. J., Machado, P. G., Da Silva, A. V., Saltar, Y., Ribeiro, C. O., Nascimento, C. A. O. D., &amp;amp; Dowling, A. W. (2024). Sustainable aviation fuel technologies, costs, emissions, policies, and markets: A critical review. Journal of Cleaner Production.&lt;/p&gt;
    &lt;p&gt;Here’s an ugly, but useful graph from the UK Government’s cost-benefit report on SAFs.&lt;/p&gt;
    &lt;p&gt;This is based on fuel costs ranging from $600 to $1000 per tonne.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sustainabilitybynumbers.com/p/eliminating-contrails"/><published>2025-10-07T19:07:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507936</id><title>Gemini 2.5 Computer Use model</title><updated>2025-10-08T05:38:30.784746+00:00</updated><content>&lt;doc fingerprint="b97269db1c538405"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing the Gemini 2.5 Computer Use model&lt;/head&gt;
    &lt;p&gt;Earlier this year, we mentioned that we're bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the Gemini 2.5 Computer Use model, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;p&gt;While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the full list of supported UI actions or specify additional custom functions to include.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use Model flow&lt;/p&gt;
    &lt;p&gt;The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.&lt;/p&gt;
    &lt;p&gt;After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.&lt;/p&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.&lt;/p&gt;
    &lt;p&gt;Check out a few demos below to see the model in action (shown here at 3X speed).&lt;/p&gt;
    &lt;p&gt;Prompt: “From https://tinyurl.com/pet-care-signup, get all details for any pet with a California residency and add them as a guest in my spa CRM at https://pet-luxe-spa.web.app/. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”&lt;/p&gt;
    &lt;p&gt;Prompt: “My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to sticky-note-jam.web.app and ensure notes are clearly in the right sections. Drag them there if not.”&lt;/p&gt;
    &lt;head rend="h2"&gt;How it performs&lt;/head&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the Gemini 2.5 Computer Use evaluation info and in Browserbase’s blog post. Unless otherwise indicated, scores shown are for computer use tools exposed via API.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks&lt;/p&gt;
    &lt;p&gt;The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency&lt;/p&gt;
    &lt;head rend="h2"&gt;How we approached safety&lt;/head&gt;
    &lt;p&gt;We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.&lt;/p&gt;
    &lt;p&gt;We have trained safety features directly into the model to address these three key risks (described in the Gemini 2.5 Computer Use System Card).&lt;/p&gt;
    &lt;p&gt;Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system's integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Per-step safety service: An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.&lt;/item&gt;
      &lt;item&gt;System instructions: Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in documentation).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additional recommendations for developers on safety measures and best practices can be found in our documentation. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.&lt;/p&gt;
    &lt;head rend="h2"&gt;How early testers have used it&lt;/head&gt;
    &lt;p&gt;Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering Project Mariner, the Firebase Testing Agent, and some agentic capabilities in AI Mode in Search.&lt;/p&gt;
    &lt;p&gt;Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:&lt;/p&gt;
    &lt;head rend="h2"&gt;How to get started&lt;/head&gt;
    &lt;p&gt;Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try it now: In a demo environment hosted by Browserbase.&lt;/item&gt;
      &lt;item&gt;Start building: Dive into our reference and documentation (see Vertex AI docs for enterprise use) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.&lt;/item&gt;
      &lt;item&gt;Join the community: We’re excited to see what you build. Share feedback and help guide our roadmap in our Developer Forum.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/google-deepmind/gemini-computer-use-model/"/><published>2025-10-07T19:49:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45508811</id><title>Metriport (YC S22) is hiring a founding recruiter</title><updated>2025-10-08T05:38:30.257972+00:00</updated><content>&lt;doc fingerprint="b75c73b3cc765a6c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Metriport helps healthcare organizations access, analyze, and exchange patient data in real-time. Our open-source data intelligence platform integrates with all major healthcare IT systems in the US, and taps into comprehensive medical data for 300M+ individuals. Concretely, check out the following resources to learn more about what we actually do:&lt;/p&gt;
      &lt;p&gt;If you want to do work that matters and has a direct impact on people’s lives, you should consider joining us - there’s a good chance that this will be some of the most fulfilling, interesting, and impactful work you do in your career.&lt;lb/&gt; We are looking for our first in-house recruiter to lead efforts of scaling our team with formidable talent, end-to-end. You will be recruiting across all company functions - from engineering, to customer success, to design, and so on.&lt;/p&gt;
      &lt;head rend="h2"&gt;About us&lt;/head&gt;
      &lt;p&gt;The following points are an assortment of the most relevant bits that will give you the gist of where we’re at, why we’ll win, and our company culture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Series A (unannounced), found PMF, multi-million ARR, 90+ customers (including Strive Health, Circle Medical, and Brightside Health), funded by top VCs and angels, have years of runway - and we’re just getting started.&lt;/item&gt;
        &lt;item&gt;We’re a tight-knit, high performing, and passionate team - we work with a consistent intensity and have become a leader in our industry with a fraction of the resources of our competitors. &lt;list rend="ul"&gt;&lt;item&gt;Consistency means we push as hard as humanly possible, while keeping our health and personal lives in check.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Meaningful work is what gets us out of bed, and we just wouldn’t be satisfied by building yet another CRM company.&lt;/item&gt;
        &lt;item&gt;By pedigree, we’re a group of underdogs - we don’t hire based on prestige, but on demonstrated competence and perceived potential.&lt;/item&gt;
        &lt;item&gt;We operate as a relatively flat structure with little red tape, forced structure, or bureaucracy. We just opt to get shit done and foster a collaborative environment with high autonomy - our GitHub commit history and product velocity is a testament to this.&lt;/item&gt;
        &lt;item&gt;The founders set the pace by working 6 days a week in our SF office, but everyone is given full freedom to craft a schedule that’s best for both the team and themselves - team output is measured, “butts in seats” are not.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;About you&lt;/head&gt;
      &lt;p&gt;In a nutshell, we're looking for a founding “full-stack recruiter” with the following specific qualities:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You want to work at a fast-paced startup.&lt;/item&gt;
        &lt;item&gt;You’re excited by working in the intersection of healthcare, data, and AI.&lt;/item&gt;
        &lt;item&gt;You have a strong sense of ownership over your work, and have demonstrated ability to lead others.&lt;/item&gt;
        &lt;item&gt;You’re entrepreneurial minded, and you don’t need a defined playbook to be successful in your role - you’re able to create and own your own systems.&lt;/item&gt;
        &lt;item&gt;When someone scopes out an assignment with a target ETA of 3 weeks, you ask yourself "why can't it be done in 3 days?".&lt;/item&gt;
        &lt;item&gt;You feel that you have a good “taste” for startup talent, developed through your prior recruiting experience.&lt;/item&gt;
        &lt;item&gt;Bonus: you have an engineering background that allows you to vet technical talent thoroughly.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;What you'll be doing&lt;/head&gt;
      &lt;p&gt;From day 1, you’ll be ramped up quickly to expert-level domain knowledge in the healthcare data IT space to help you understand the context of what we’re working towards, all of the projects that our team is currently working on, and what we’ll be working on in the future.&lt;lb/&gt; Every day, you'll be working towards moving the needle on all things related to ensuring we are working with the best talent possible, while reaching aggressive growth goals. Generally, this will look like:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Making the world a better place (but actually).&lt;/item&gt;
        &lt;item&gt;Talent Brand Management: create and manage our public hiring presence - our job site, listings, social media posts, etc.&lt;/item&gt;
        &lt;item&gt;Sourcing: using traditional outreach tools, as well as your own creative approaches, get the best talent possible in our recruiting funnel.&lt;/item&gt;
        &lt;item&gt;Interviewing: schedule, run, and organize multi-stage interviews, including coordinating any travel necessary.&lt;/item&gt;
        &lt;item&gt;Closing: writing offer letters and ensuring they close.&lt;/item&gt;
        &lt;item&gt;Onboarding: help with onboarding new employees when they start and making sure they have everything they need to hit the round running.&lt;/item&gt;
        &lt;item&gt;Payroll/HR: as needed, perform a variety of payroll and HR related tasks like reimbursements, purchase requests, device provisioning, etc.&lt;/item&gt;
        &lt;item&gt;Attending a daily 30 minute remote stand-up at 7:30am PST Mon-Fri (our only regular mandatory meeting).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Requirements&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You have enough technical knowledge to be able to understand our product, what our team is working towards, and where we fit into the healthcare landscape.&lt;/item&gt;
        &lt;item&gt;You’ve worked with, or can quickly learn how to operate, tools like: Surfe, Gem, LinkedIn Recruiter, Pave, Levels, Notion, Slack, Zapier, Excel, etc.&lt;/item&gt;
        &lt;item&gt;You have excellent communication skills, and ideally some prior consulting experience.&lt;/item&gt;
        &lt;item&gt;You’re located in San Francisco or the Bay Area (or willing to relocate).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Competitive equity + compensation package 🚀&lt;/item&gt;
        &lt;item&gt;Top tier full family health insurance, dental, and vision coverage 🦷&lt;/item&gt;
        &lt;item&gt;401(k) retirement plan + matching 💰&lt;/item&gt;
        &lt;item&gt;Flexible work from home or in-office 🏢 &lt;list rend="ul"&gt;&lt;item&gt;Healthy lunches are complimentary when working in-office (and breakfast + dinners as needed) 🍏&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Quarterly company off-sites with the team ⛷️&lt;/item&gt;
        &lt;item&gt;MacBook provided by us 💻&lt;/item&gt;
        &lt;item&gt;Unlimited PTO (we work hard, but trust you to take time you need to be at your best) 🧘♂️&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/metriport/jobs/uq6CuhA-founding-recruiter"/><published>2025-10-07T21:00:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45509243</id><title>Become unbannable from your email</title><updated>2025-10-08T05:38:30.101562+00:00</updated><content/><link href="https://karboosx.net/post/PJOveGVa/become-unbannable-from-your-emailgmail"/><published>2025-10-07T21:39:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45510582</id><title>Study of 1M-year-old skull points to earlier origins of modern humans</title><updated>2025-10-08T05:38:29.808885+00:00</updated><content>&lt;doc fingerprint="f65511fdb8b11bbe"&gt;
  &lt;main&gt;
    &lt;p&gt;A million-year-old human skull suggests that the origins of modern humans may reach back far deeper in time than previously thought and raises the possibility that Homo sapiens first emerged outside of Africa.&lt;/p&gt;
    &lt;p&gt;Leading scientists reached this conclusion after reanalysis of a skull known as Yunxian 2 discovered in China and previously classified as belonging to a member of the primitive human species Homo erectus.&lt;/p&gt;
    &lt;p&gt;After applying sophisticated reconstruction techniques to the skull, scientists believe that it may instead belong to a group called Homo longi (dragon man), closely linked to the elusive Denisovans who lived alongside our own ancestors.&lt;/p&gt;
    &lt;p&gt;This repositioning would make the fossil the closest on record to the split between modern humans and our closest relatives, the Neanderthals and Denisovans, and would radically revise understanding of the last 1m years of human evolution.&lt;/p&gt;
    &lt;p&gt;Prof Chris Stringer, an anthropologist and research leader in human evolution at the Natural History Museum in London, said: “This changes a lot of thinking because it suggests that by 1m years ago our ancestors had already split into distinct groups, pointing to a much earlier and more complex human evolutionary split than previously believed. It more or less doubles the time of origin of Homo sapiens.”&lt;/p&gt;
    &lt;p&gt;The skull was first unearthed in Hubei province in 1990, badly crushed and difficult to interpret. Based on its age and some broad-brush traits, it was assigned as Homo erectus, a group that is thought to have contained direct ancestors of modern humans.&lt;/p&gt;
    &lt;p&gt;The latest work used advanced CT imaging, high-resolution surface scanning and sophisticated digital techniques to produce a virtual reconstruction of the skull. The skull’s large, squat brain case and jutting lower jaw are reminiscent of Homo erectus. But the overall shape and size of the brain case and teeth appear to place it much closer to Homo longi, a species that scientists have recently argued should incorporate the Denisovans.&lt;/p&gt;
    &lt;p&gt;This would push the split between our own ancestors, Neanderthals and Homo longi back by at least 400,000 years and, according to Springer, raises the possibility that our common ancestor – and potentially the first Homo sapiens – lived in western Asia rather than Africa.&lt;/p&gt;
    &lt;p&gt;“This fossil is the closest we’ve got to the ancestor of all those groups,” Stringer said.&lt;/p&gt;
    &lt;p&gt;A computational analysis of a wider selection of fossils suggests that in the last 800,000 years, large-brained humans evolved along just five major branches: Asian erectus, heidelbergensis, sapiens, Neanderthals and Homo longi (including the Denisovans).&lt;/p&gt;
    &lt;p&gt;“We feel that this study is a landmark step towards resolving the ‘muddle in the middle’ [the confusing array of human fossils from between 1m and 300,000 years ago] that has preoccupied palaeoanthropologists for decades,” Stringer said.&lt;/p&gt;
    &lt;p&gt;The findings run counter to some recent analyses based on genetic comparisons of living humans and ancient DNA, meaning the conclusions are likely to be contentious.&lt;/p&gt;
    &lt;p&gt;Dr Frido Welker, an associate professor in human evolution at the University of Copenhagen, who was not involved in the research, said: “It’s exciting to have a digital reconstruction of this important cranium available. If confirmed by additional fossils and genetic evidence, the divergence dating would be surprising indeed. Alternatively, molecular data from the specimen itself could provide insights confirming or disproving the authors’ morphological hypothesis.”&lt;/p&gt;
    &lt;p&gt;The findings are published in the journal Science.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/science/2025/sep/25/study-of-1m-year-old-skull-points-to-earlier-origins-of-modern-humans"/><published>2025-10-08T00:17:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45511265</id><title>Bob Ross paintings to be auctioned to fund US public broadcasting</title><updated>2025-10-08T05:38:29.447312+00:00</updated><content>&lt;doc fingerprint="2e94ab5bb3699eee"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bob Ross paintings to be auctioned to fund US public broadcasting&lt;/head&gt;
    &lt;p&gt;Paintings by celebrated art tutor Bob Ross will be auctioned to help support public television stations that have faced funding cuts under the Trump administration.&lt;/p&gt;
    &lt;p&gt;About 30 of his artworks, which he mostly created on-air during his TV show, the Joy of Painting, in the 80s and 90s, will be auctioned by Bonhams from November.&lt;/p&gt;
    &lt;p&gt;Bob Ross Inc said the auction "ensures Bob's legacy continues to support the very medium that brought his joy and creativity into American homes for decades".&lt;/p&gt;
    &lt;p&gt;It comes after Congress passed Trump's request to strip public broadcast funding, leaving some 330 Public Broadcasting Service (PBS) and National Public Radio (NPR) stations scrambling for a new funding source.&lt;/p&gt;
    &lt;p&gt;Ross' show saw a resurgence during the Covid pandemic, as audiences enjoyed his soft-spoken, paint-along lessons. Misplaced brush strokes, the former Air Force drill sergeant would say, were just "happy accidents". He died at the age of 52 in 1995.&lt;/p&gt;
    &lt;p&gt;Bob Ross Inc said it donated the paintings to American Public Television, and that all of the net proceeds go to local public TV stations nationwide.&lt;/p&gt;
    &lt;p&gt;This includes programmes such as America's Test Kitchen, Julia Child's French Chef Classics and This Old House, the Associated Press news agency reported.&lt;/p&gt;
    &lt;p&gt;In August, the auction of two of Ross' works shattered records, having sold for double and triple what had been expected.&lt;/p&gt;
    &lt;p&gt;Lake Below Snow-Capped Peaks and Cloudy Sky sold for $114,800, while Lake Below Snow-Covered Mountains and Clear Sky sold for $95,750.&lt;/p&gt;
    &lt;p&gt;"I can tell you that Bob would have been quite shy to learn that his paintings are now selling at six figures," Joan Kowalski, the president of Bob Ross Inc, told the New York Post after the lots sold.&lt;/p&gt;
    &lt;p&gt;"He was never really that interested in his finished works, Bob was more fascinated with the process of painting and sharing that with other people."&lt;/p&gt;
    &lt;p&gt;"Truthfully, I can still hear him saying something like, 'You don't want my paintings, you want to create your own and hang them proudly on your wall.'"&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/cly10275v5zo"/><published>2025-10-08T02:06:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45511294</id><title>The paradoxical efficient market hypothesis (2024)</title><updated>2025-10-08T05:38:29.133349+00:00</updated><content>&lt;doc fingerprint="e2dc51eb9937efda"&gt;
  &lt;main&gt;
    &lt;p&gt;by John Allen Paulos&lt;/p&gt;
    &lt;p&gt;Election season has put an increased focus on the stock market, but little attention is ever paid to the Efficient Market Hypothesis (the EMH, for short). As I’ve written in A Mathematician Plays the Stock Market, it is a fundamental and important notion, but it is also a little weird. Its recent formulation derives from the work of Eugene Fama, economist Paul Samuelson, and others in the 1960s. The basic idea, however, dates back more than 100 years when Louis Bachelier, a student of the great French mathematician Henri Poincare, formulated an early version. Roughly, the hypothesis maintains that stock prices reflect all relevant information about the stock. As Fama put it, “In an efficient market, competition among the many intelligent participants leads to a situation where, at any point in time, actual prices of individual securities already reflect the effects of information based both on events that have already occurred and on events which, as of now, the market expects to take place in the future.”&lt;/p&gt;
    &lt;p&gt;The EMH depends crucially on what information is assumed to be reflected in the stock price. The weakest version maintains that all information about past market prices is already reflected in a stock price. A stronger version maintains that all publicly available information about a company is already reflected in its stock price. The strongest version states that information of all sorts, even inside information, is already reflected in the stock price.&lt;/p&gt;
    &lt;p&gt;It was probably this last rather implausible and all-encompassing version of the hypothesis that underlies the joke about the two efficient market theorists walking through town. They notice a hundred dollar bill on the sidewalk and simply ignore it. If it were real, they conclude, someone would have been picked it up already. Even more risible is the question: How many efficient market theorists does it take to change a light bulb? Answer: The answer is none. If the bulb needed changing, the wisdom of the market would have insured that it had already been changed.&lt;/p&gt;
    &lt;p&gt;So why do people think that the market efficiently, and more or less immediately, responds to changes in the conditions for a particular stock or even for the market as a whole? The answer is that investors are always seeking an edge to increase their gains or decrease their losses, and they try to do so in a multitude of ways. They’re on the lookout for new bits of information possibly relevant to a company’s stock price that may be enough to quickly raise or lower it. Because of this swarm of profit-hungry and loss-averse investors, the market rapidly responds to new information, and efficiently – there’s that word again – adjusts prices to reflect it. The changes take place so rapidly, or so the story goes, that even utilizing technical rules or fundamental analyses aren’t fast enough to be fully exploited, and investors who pursue them will see their excess profits shrink to zero.&lt;/p&gt;
    &lt;p&gt;I mentioned above that the EMH is weird. The reason is that it leads to a conclusion that has something of the flavor of the Liar Paradox: “This sentence is false.” How specifically? Well, if a sufficiently large majority of investors believe the hypothesis, they naturally would assume that new information about a stock would very quickly be reflected in its price. They would conclude that since relevant news almost immediately moves the price up or down, and since new developments can’t be predicted, neither can price increases or decreases. Thus those investors who subscribe to the EMH and believe the market is efficient would further believe that looking for trends and analyzing companies’ fundamentals is a waste of time. Believing this, the majority of investors won’t pay much attention to new developments, leaving only the relatively few remaining investors actively searching for an edge. The result is that the market will not respond quickly to new information and thus it will not be efficient. In this way a strong belief in the EMH ensures its falsity.&lt;/p&gt;
    &lt;p&gt;And in the opposite case, if investors believe that the market is not efficient, their belief will induce them to use whatever tools (technical analysis, fundamental analysis, and so on) are at their disposal. They will search diligently for an edge and for opportunities that they believe exist in an inefficient market, and by so doing these profit-seeking investors will ensure that the market becomes efficient.&lt;/p&gt;
    &lt;p&gt;Reiterating and in summary, if a sufficiently large proportion of investors doesn’t believe the EMH, their actions will ensure that it is efficient, and if most investors do believe that the market is efficient, looking for an edge would seem pointless to them and so their inaction will likely result in an inefficient market. Alternatively stated, the Efficient Market Hypothesis is true if and only if a sufficiently large majority of investors believes it to be false. Pleasantly counterintuitive and a bit weird as I said.&lt;/p&gt;
    &lt;p&gt;Of course, I’ve made some big assumptions that may not hold. One is that it’s not clear what “sufficiently large” means, and I’ve ignored the fact that it occasionally requires very few investors to move the market.&lt;/p&gt;
    &lt;p&gt;Another gap in the argument is that any suspected deviations from the EMH can always be attributed to mistakes in pricing models or some other issue. There is also a potent psychological reason that people disbelieve the EMH. Believing it makes it harder to maintain an investor’s self-image as a brilliant financial gunslinger whose keen insight will make him rich.&lt;/p&gt;
    &lt;p&gt;Nevertheless, I think the point remains: the truth or falsity of the EMH is not immutable but depends critically on the beliefs of investors. Furthermore, as the percentage of investors who believe in the hypothesis itself varies, the truth of the hypothesis varies inversely with it.&lt;/p&gt;
    &lt;p&gt;On the whole, however, I suspect most investors disbelieve in it, and so for this reason I think it holds, but only approximately and only most of the time.&lt;/p&gt;
    &lt;p&gt;Post script: That exploitable opportunities tend to gradually disappear is a general phenomenon that occurs in other domains. Steven Jay Gould in his book Full House developed an example from baseball. The absence of .400 hitters in the years since Ted Williams hit .406 in 1941, he argued, was not due to any decline in baseball ability but just the opposite: a gradual increase in the athleticism of all players and a consequent decrease in the disparity between the worst and best players. As players have improved over time, the distribution of batting averages and earned run averages shows less variability. There are fewer bad pitchers facing hitters and fewer bad hitters facing pitchers. The consequence is that .400 batting averages are now rare. The improved athleticism of both hitters and pitchers makes the “market” between them more efficient.&lt;/p&gt;
    &lt;p&gt;This would hold true for other sports, especially newly minted ones that arise suddenly and sometimes even become Olympic events. One might even try to invoke the EMH to explain the variation and stability of so-called prediction markets that purport to estimate candidates’ chances in so-called prediction markets. Investors buy, sell, and borrow shares in candidates as they do with stocks, and, arguably at least, the prediction market becomes more efficient as the election nears.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;p&gt;John Allen Paulos is an emeritus Professor of Mathematics at Temple University and the author of Innumeracy and A Mathematician Reads the Newspaper. These and his other books are available here.&lt;/p&gt;
    &lt;p&gt;Enjoying the content on 3QD? Help keep us going by donating now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://3quarksdaily.com/3quarksdaily/2024/09/the-paradoxical-efficient-market-hypothesis.html"/><published>2025-10-08T02:11:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45511798</id><title>TiVo exiting legacy DVR business</title><updated>2025-10-08T05:38:27.647933+00:00</updated><content>&lt;doc fingerprint="a69b094c49e939ad"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;TiVo Exiting Legacy DVR Business&lt;/head&gt;
    &lt;p&gt;October 6, 2025&lt;/p&gt;
    &lt;p&gt;TiVo, the digital video recording pioneer, has moved on from its legacy DVR technology, focusing instead on its branded operating system software promoting third-party content searches, recommendation, including free ad-supported streaming options and more for smart televisions.&lt;/p&gt;
    &lt;p&gt;“As of Oct. 1, 2025, TiVo has stopped selling Edge DVR hardware products,” the company said in an AI-based message. The recording said that the company and its associates no longer manufacture DVR hardware, “and our remaining inventory is now depleted.”&lt;/p&gt;
    &lt;p&gt;TiVo said it remains “committed to providing support for our DVR customers and will continue to provide support for the foreseeable future.”&lt;/p&gt;
    &lt;p&gt;TiVo in 1999 created the first set-top device enabling users to record and skip ads within television programming. Over the past 25 years, streaming video technology has evolved to the point that major platforms, such as Netflix, Prime Video, Peacock, Hulu, HBO Max and Paramount+, enable users to watch content on their own schedule without the need for separate technology.&lt;/p&gt;
    &lt;p&gt;In early 2024, TiVo discontinued the antenna version of the TiVo Edge from its website. The cable version of the Edge as well as the TiVo Mini LUX and TiVo Stream 4K continue to be available.&lt;/p&gt;
    &lt;p&gt;TiVo also markets separate technology to automakers enabling them to generate royalty revenue from third-party entertainment streamed in automobiles manufactured by Ford and Volkswagen, among others.&lt;/p&gt;
    &lt;p&gt;On the company website, TiVo claims that video consumption by TiVo device users equals more than 5 billion hours per year across more than 3.6 billion devices and vehicles.&lt;/p&gt;
    &lt;p&gt;Subscribe HERE to the FREE Media Play News Daily Newsletter!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mediaplaynews.com/tivo-exiting-legacy-dvr-business/"/><published>2025-10-08T03:36:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45512317</id><title>Without data centers, GDP growth was 0.1% in the first half of 2025</title><updated>2025-10-08T05:38:27.520066+00:00</updated><content>&lt;doc fingerprint="2540c05c68e614ed"&gt;
  &lt;main&gt;
    &lt;p&gt;U.S. GDP growth in the first half of 2025 was almost entirely driven by investment in data centers and information processing technology, according to Harvard economist Jason Furman. Excluding these technology-related categories, Furman calculated in a Sept. 27 post on X.com GDP growth would have been just 0.1% on an annualized basis, a near standstill that underlines the increasingly pivotal role of high-tech infrastructure in shaping macroeconomic outcomes.&lt;/p&gt;
    &lt;p&gt;Furman’s findings, shared online and echoed by financial analysts including Robert Armstrong of the Financial Times‘ Unhedged (the same writer who coined the term “TACO trade’), echo several months of observations on the remarkable surge in data-center infrastructure. In August, Renaissance Macro Research estimated, to date in 2025, the dollar value contributed to GDP growth by AI data-center buildout had surpassed U.S. consumer spending for the first time ever. That’s remarkable considering consumer spending is two-thirds of GDP.&lt;lb/&gt;Technically, as Furman notes, investment in information-processing equipment and software was only 4% of U.S. GDP for the first half of 2025, yet it also accounted for fully 92% of GDP growth over that period. Furman added it’s probably not the case the U.S. economy would have recorded almost no expansion at all absent this buildout, reasoning that “absent the AI boom we would probably have lower interest rates [and] electricity prices, thus some additional growth in other sectors. In very rough terms that could maybe make up about half of what we got from the AI boom.” But still, it’s big. &lt;/p&gt;
    &lt;p&gt;Tech giants such as Microsoft, Google, Amazon, Meta, and Nvidia have poured tens of billions of dollars into building and upgrading data centers, responding to explosive demand for artificial intelligence and large language models that require massive computing resources.&lt;/p&gt;
    &lt;p&gt;Lisa Shallet, chief investment officer for Morgan Stanley Wealth Management, flagged on Sept. 29 that spending was truly massive among the so-called “hyperscalers” who are striving for huge computing, storage and networking capacity.&lt;/p&gt;
    &lt;p&gt;“In recent years, hyperscaler capex on data center and related items has risen fourfold and is nearing $400 billion annually,” she wrote. “The speed of growth and size of the investment are skewing its aggregate economic impact, with the top 10 spenders accounting for nearly a third of all spending … For perspective, it’s estimated that data center-linked spending is adding roughly 100 basis points to U.S. real GDP growth.”&lt;/p&gt;
    &lt;head rend="h2"&gt;The ‘mystery’ of the economy&lt;/head&gt;
    &lt;p&gt;This surge in technology-led growth comes against a backdrop of wider economic sluggishness and paradoxically strong GDP growth. Job creation has slowed, raising concerns that, absent technology investment, the U.S. economy could have slipped into recession. Other sectors—from manufacturing and real estate to retail and services—contributed little or even detracted from overall output in the first half of 2025.&lt;/p&gt;
    &lt;p&gt;And yet, as Apollo Global Management Chief Economist Torsten Sløk has noted, the GDP figures speak of a (statistically) strong economy.&lt;/p&gt;
    &lt;p&gt;“The consensus has been wrong since January,” Sløk said in a note circulated to clients in early October, adding the average of economists’ forecasts has said the U.S. economy would slow down for nine months consecutively. “But the reality is that it has simply not happened … We in the economics profession need to look ourselves in the mirror.”&lt;/p&gt;
    &lt;p&gt;Furman’s analysis adds to the snarky and accurate observation by Rusty Foster of Today in Tabs who quipped: “Our economy might just be three AI data centers in a trench coat”—an allusion to the data-center buildout boom and to the cartoon trope/sight gag of several young boys teaming up to disguise themselves as an adult.&lt;/p&gt;
    &lt;p&gt;Morgan Stanley Chief Economist Michael Gapen ventured a guess on Oct. 6 about “the mystery” of the 2025 economy, “between solid spending data and weak hiring.” He argued that it “can be explained by a corporate sector that absorbed the initial cost of tariffs and reduced unit labor costs and profitability rather than raising prices.”&lt;/p&gt;
    &lt;p&gt;In other words, something that has nothing to do with the data-center buildout that is widely fueling bubble fears, even among Amazon founder Jeff Bezos himself, who insists these data centers are an “industrial bubble” rather than a financial one, and we will all be glad someday to have such incredible computing power at our fingertips with so many hundreds of billions spent. The question of sustainable GDP growth is a separate one.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fortune.com/2025/10/07/data-centers-gdp-growth-zero-first-half-2025-jason-furman-harvard-economist/"/><published>2025-10-08T05:13:53+00:00</published></entry></feed>