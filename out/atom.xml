<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-06T21:07:47.259859+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45139088</id><title>Purposeful animations</title><updated>2025-09-06T21:07:54.887830+00:00</updated><content>&lt;doc fingerprint="f7eb51a5ad29df05"&gt;
  &lt;main&gt;&lt;p&gt;When done right, animations make an interface feel predictable, faster, and more enjoyable to use. They help you and your product stand out.&lt;/p&gt;&lt;p&gt;But they can also do the opposite. They can make an interface feel unpredictable, slow, and annoying. They can even make your users lose trust in your product.&lt;/p&gt;&lt;p&gt;So how do you know when and how to animate to improve the experience?&lt;/p&gt;&lt;p&gt;Step one is making sure your animations have a purpose.&lt;/p&gt;&lt;head rend="h2"&gt;Purposeful animations&lt;/head&gt;&lt;p&gt;Before you start animating, ask yourself: what’s the purpose of this animation? &lt;lb/&gt;As an example, what’s the purpose of this marketing animation we built at Linear?&lt;/p&gt;&lt;p&gt;You can view the full animation on linear.app/ai.&lt;/p&gt;&lt;p&gt;This animation explains how Product Intelligence (Linear’s feature) works. We could have used a static asset, but the animated version helps the user understand what this feature does, straight in the initial viewport of the page.&lt;/p&gt;&lt;p&gt;Another purposeful animation is this subtle scale down effect when pressing a button. It’s a small thing, but it helps the interface feel more alive and responsive.&lt;/p&gt;&lt;p&gt;Sonner’s enter animation, on the other hand, has two purposes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;- Having a toast suddenly appear would feel off, so we animate it in.&lt;/item&gt;&lt;item&gt;- Because it comes from and leaves in the same direction, it creates spatial consistency, making the swipe-down-to-dismiss gesture feel more intuitive.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But sometimes the purpose of an animation might just be to bring delight.&lt;/p&gt;&lt;p&gt;Morphing of the feedback component below helps make the experience more unique and memorable. This works as long as the user will rarely interact with it. It’ll then become a pleasant surprise, rather than a daily annoyance.&lt;/p&gt;&lt;p&gt;Press on the button to see it morph.&lt;/p&gt;&lt;p&gt;Used multiple times a day, this component would quickly become irritating. The initial delight would fade and the animation would slow users down.&lt;/p&gt;&lt;p&gt;How often users will see an animation is a key factor in deciding whether to animate or not. Let’s dive deeper into it next.&lt;/p&gt;&lt;head rend="h2"&gt;Frequency of use&lt;/head&gt;&lt;p&gt;I use Raycast hundreds of times a day. If it animated every time I opened it, it would be very annoying. But there’s no animation at all. That’s the optimal experience.&lt;/p&gt;&lt;p&gt;To see it for yourself, try to toggle the open state of the menu below by using the buttons belowpressing &lt;code&gt;J&lt;/code&gt; and then &lt;code&gt;K&lt;/code&gt;. Which one feels better if used hundreds of times a day?&lt;/p&gt;&lt;p&gt;When I open Raycast, I have a clear goal in mind. I don’t expect to be “delighted”, I don’t need to be. I just want to do my work with no unnecessary friction.&lt;/p&gt;&lt;p&gt;Think about what the user wants to achieve and how often they will see an animation. A hover effect is nice, but if used multiple times a day, it would likely benefit the most from having no animation at all.&lt;/p&gt;&lt;p&gt;Imagine you interact with this list often during the day.&lt;/p&gt;&lt;p&gt;Imagine you interact with this list often during the day.&lt;/p&gt;&lt;p&gt;The same goes for keyboard-initiated actions. These actions may be repeated hundreds of times a day, an animation would make them feel slow, delayed, and disconnected from the user’s actions. You should never animate them.&lt;/p&gt;&lt;p&gt;Since we can’t really use a keyboard on touch devices, you can press the buttons below to see how it feels with and without animation.&lt;/p&gt;&lt;p&gt;To see it for yourself, focus on the input below and use arrow keys to navigate through the list. Notice how the highlight feels delayed compared to the keys you press. Now press (shift) and see how this interaction feels without animation.&lt;/p&gt;&lt;p&gt;But even if your animation won’t be used too often and it fulfills a clear purpose, you still have to think about its speed…&lt;/p&gt;&lt;head rend="h2"&gt;Perception of speed&lt;/head&gt;&lt;p&gt;Unless you are working on marketing sites, your animations have to be fast. They improve the perceived performance of your app, stay connected to user’s actions, and make the interface feel as if it’s truly listening to the user.&lt;/p&gt;&lt;p&gt;To give you an example, a faster-spinning spinner makes the app seem to load faster, even though the load time is the same. This improves perceived performance.&lt;/p&gt;&lt;p&gt;Which one works harder to load the data?&lt;/p&gt;&lt;p&gt;A &lt;code&gt;180ms&lt;/code&gt; dropdown animation feels more responsive than a &lt;code&gt;400ms&lt;/code&gt; one:&lt;/p&gt;&lt;p&gt;Click on the buttons to compare the speed.&lt;/p&gt;&lt;p&gt;As a rule of thumb, UI animations should generally stay under &lt;code&gt;300ms&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Another example of the importance of speed: tooltips should have a slight delay before appearing to prevent accidental activation. Once a tooltip is open however, hovering over other tooltips should open them with no delay and no animation.&lt;/p&gt;&lt;p&gt;This feels faster without defeating the purpose of the initial delay.&lt;/p&gt;&lt;p&gt;Radix UI and Base UI skip the delay once a tooltip is shown.&lt;/p&gt;&lt;p&gt;Radix UI and Base UI skip the delay once a tooltip is shown.&lt;/p&gt;&lt;head rend="h2"&gt;Building great interfaces&lt;/head&gt;&lt;p&gt;The goal is not to animate for animation’s sake, it’s to build great user interfaces. The ones that users will happily use, even on a daily basis. Sometimes this requires animations, but sometimes the best animation is no animation.&lt;/p&gt;&lt;p&gt;Knowing when to animate is just one of many things you need to know in order to craft great animations. If you’d like to dive deeper into the theory and practice of it, I’ve created a course that covers everything you need to know:&lt;/p&gt;Check out "Animations on the Web"&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://emilkowal.ski/ui/you-dont-need-animations"/></entry><entry><id>https://news.ycombinator.com/item?id=45142885</id><title>Anthropic agrees to pay $1.5B to settle lawsuit with book authors</title><updated>2025-09-06T21:07:54.693742+00:00</updated><content/><link href="https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&amp;smid=url-share"/></entry><entry><id>https://news.ycombinator.com/item?id=45143019</id><title>William James at CERN (1995)</title><updated>2025-09-06T21:07:54.334605+00:00</updated><content>&lt;doc fingerprint="26090b1f15a70ee8"&gt;
  &lt;main&gt;
    &lt;p&gt;This is obviously true of action. Whatever views your views on free will, it is indubitable that differing options occur to us, that we compare them, that we prefer some to others, that eventually we elect one and dismiss the rest. More interestingly, James describes the role of selection in perception, and finds it at every level of neural and mental life. The sense organs, to begin with, are insensitive to almost all that happens around them. When they are excited and transmit nervous impulses to the brain, these are sifted for significant patterns (often found on dubious grounds). News of these is relayed to other parts of the brain, which look for more subtle, more detailed, and more broad patterns, until at last we reach our perceptions, grouped together by another process of selection into things. Some of these we attend to; the rest we ignore.&lt;/p&gt;
    &lt;quote&gt;``The mind is at every stage a theatre of simultaneous possibilities. Consciousness consists in the comparison of these with each other, the selection of some, and the suppression of the rest by the reinforcing and inhibiting agency of attention. The highest and most elaborated mental products are filtered from the data chosen by the faculty next beneath, out of the mass offered by the faculty below that, which mass in turn was sifted from a still larger amount of yet simpler material, and so on. The mind, in short, works on the data it receives very much as a sculptor works on his block of stone. In a sense the statue stood there from eternity. But there were a thousand different ones beside it, and the sculptor alone is to thank for having extricated this one from the rest. Just so the world of each of us, how so ever different our several views of it may be, all lay embedded in the primordial chaos of sensations, which gave the mere matter to the thought of all of us indifferently. We may, if we like, by our reasonings unwind things back to that black and jointless continuity of space and moving clouds of swarming atoms which science calls the only real world. But all the while the world we feel and live in will be that which our ancestors and we, by slowly cumulative strokes of choice, have extricated out of this, like sculptors, by simply removing portions of the given stuff. Other sculptors, other statues from the same stone! Other minds, other worlds from the same monotonous and inexpressive chaos! My world is but one in a million alike embedded, alike real to those who may abstract them. How different must be the worlds in the consciousness of ant, cuttlefish, or crab!''James wrote in 1890, and the last century of research into brain and mind have done nothing to diminish our confidence in this (admittedly very general) picture. Indeed, we can now point to parts of the brain which select specific features out of the signals of the sense organs --- cells in the occipital lobe, for instance, which respond only to straight lines at certain angles, or motion, or contrasts of light and darkness --- and we are beginning to understand the more elaborate construction of things out of such elements. From almost any authority on neurobiology, cognitive science, psychology, the philosophy of mind, artificial intelligence or computer science, I could have quoted passages saying substantially the same things as James, though in worse prose and without quite the same emphasis on selection.&lt;/quote&gt;
    &lt;p&gt;I propose, now, to see whether these ideas of selection shed any light on the various uses of ``thinking machines,'' that is to say, computers.&lt;/p&gt;
    &lt;p&gt;The reader is almost certainly familiar with fractals, whether of the abstract or the naturalistic variety, but is perhaps less likely to know that computer programs have written verse (rhymed, blank and free), short stories, and even a novel. Art critics --- and more particularly, theoretical art critics --- have been understandably interested in these developments. Some have dismissed them as, at best, amusements for the boys in the basement computer lab across campus, a folk art for those whose native language is C. Others --- such as the late O. B. Hardison Jr., whose views are set forth with admirable clarity in Disappearing Through the Skylight --- have been thrown into a kind of ecstasy of obsolescence. ``Gazing at the thirty-nine sea-horses of the Mandelbrot set,'' they say in effect, ``we can see that human art, Art with a capital A, is at an end, not perhaps this week-end, but soon: it is later than you think. The day will come when a human artist could no more rival a computer than than a sprinter out-race a Ferrari. The coming art will be digital, perfect, timeless, inimitable, perhaps incomprehensible. We and all our works shall pass to dust, and only they will remain, dreaming their silicon dreams of unknown space.'' Such, in essence and composite, is the rhetoric. It seems to me to miss the most interesting aspect of the new computer art, which is its human angle, and with it the most plausible future.&lt;/p&gt;
    &lt;p&gt;The connection between selection and art is, to revert to James, ``obvious''.&lt;/p&gt;
    &lt;quote&gt;``The artist notoriously selects his items, rejecting all tones, colors, shapes, which do not harmonize with each other and with the main purpose of his work. That unity, harmony, `convergence of characters,' as M. Taine calls it, which gives to works of art their superiority over works of nature, is wholly due to elimination. Any natural subject will do, if the artist has wit enough to pounce upon some one feature of it as characteristic, and suppress all merely accidental items which do not harmonize with this.''Now the peculiarity of computer art is that computer programs are very bad at just this sort of pruning. They will make a pattern --- of colors, of sounds, of words --- according to a rule, and that is all. Give, let us say, a fractal program one rule, and it will draw you the corresponding picture; change the rule slightly and it draws another, similar picture. It does not linger over the interesting, balk at the trite, turn away from the boring or disturbing: it is a machine without preferences, ``a gaze blank and pitiless as the sun.''&lt;/quote&gt;
    &lt;p&gt;Artists, notoriously, are different. Even those who use ``found objects'' select the ones they find interesting, relevant or marketable, and eliminate everything else in the world. Selection is inescapable --- or at least not yet escaped. Computer programs, then, are poor artists because their powers of choice are absolutely miniscule; they select not from a pool of possibilities but a handful of drops, often not even that.&lt;/p&gt;
    &lt;p&gt;Yet the fact remains that computer-made graphics, if not music or literature, are quite popular, even delightful. How can this be?&lt;/p&gt;
    &lt;p&gt;We have all had the experience of writing out a sentence and then crossing it out, in bits and pieces, putting in new words and phrases until we find ones which fit to our satisfaction; until, that is, we select one sentence out of a mob of candidates. Computer art programs show us the more promising members of this mob. We then pick and choose among them, according to our tastes and purposes. It is a strange man who would put a view of the Mandelbrot set on a condolence-card; and a rash one who would say there is none suitable for this purpose.&lt;/p&gt;
    &lt;p&gt;In reality, then, the computer is not an independent artist, but a sort of dumb assistant, an automatic producer of first sketches. If the initial attempt is not perfectly satisfying --- and what first sketch is? --- either improve it by hand, or modify the computer's instructions slightly and have it try again. The afore-mentioned novel was written in the first way, most fractal pictures are arrived at in the second.&lt;/p&gt;
    &lt;p&gt;It may be asked, Must this be so? Must the computer always be just an adjunct, a patient but moronic apprentice? The key, as we have seen, is to give the computer preferences, and this does not sound impossible. Let it produce one picture, one tune, one sonnet, and see whether it satisfy its principles. If not change it - a more drastic change the further the sketch falls short of giving satisfaction - and repeat this cycle until all the criteria are met. In fact, the computer could consider a number of sketches in parallel, working on them simultaneously and combining promising features, and in this way progress much faster than if it had (so to speak) a one-track mind. (Some will recognize this as an application of the technique of ``genetic algorithms.'')&lt;/p&gt;
    &lt;p&gt;The difficulty, and it is a large one, lies in spelling out those principles in ways simple and clear enough for a computer to act on. It is hard enough to give an intelligible account of why we like a painting, switch off the radio when that tune comes on, gaze at one statue for inspiration and use another for a door-stop. It is easy to despair of ever being able to deduce the Ninth Symphony's superiority to one of its crossed-out early drafts; it may be better not to contemplate even the attempt. Yet without such formal criteria, independent computer art will remain, at most, a curiosity.&lt;/p&gt;
    &lt;p&gt;I will only close this subject by saying that there has, recently, been some work done in this field, though I do not know if the investigators have considered it in quite this light. In the closing pages of his recent book Strange Attractors, Professor Julien Sprott of the University of Wisconsin describes a survey he and colleagues made of taste in fractal pictures. People were asked to rank different fractal pictures, and these preferences were plotted against the fractal dimension of the picture (a number which measures how rough, convoluted and ``space-filling'' the image is) and the ``Lyapunov exponent'' of the equations which generated it (another number, which measures how quickly the equations amplify small differences in their variables, the fabled ``sensitive dependence on initial conditions.'') Strange as it may seem, people consistently prefer pictures whose fractal dimension and Lyapunov exponents cluster rather tightly about a constant center. If, then, a computer could be programmed to consistently produce images in that area, it would be a small first step towards ``automated taste.'' A fascinating speculation on where this might lead --- uninfluenced, as far as I know, by Prof. Sprott --- is found in Ian McDonald's science fiction novel Scissors Cut Paper Wrap Stone.&lt;/p&gt;
    &lt;p&gt;It is curious, and I believe not previously noticed, that something very similar is essential to high-energy physics. (Physics also needs normal perception, of course.)&lt;/p&gt;
    &lt;p&gt;At this point alarms ring in the minds of my colleagues, since we are all too familiar with books on the profound connection between ``the new physics'' and consciousness and various sophomoric distortions of Asian mysticism. The authors of this school are seldom discussed, save by graduate students who laugh at the errors and covet the royalties. Rest assured, I shall not discuss the torture of cats, Buddhist puns, interpretive dance, the Tao of the relativistic Euler-Lagrange equations, the maya-aspects of renormalizable gauge field theories, or even how to find a cheap Chinese restaurant in Copenhagen without a Danish interpreter.&lt;/p&gt;
    &lt;p&gt;My subject is, instead, rather more massive and solid and sweaty: the detectors attached to particle accelerators. A word or three of reminder about these, too, may not be out of place.&lt;/p&gt;
    &lt;p&gt;Particle physicists are interested in what the smallest discoverable bits of matter are, and how they behave. They are especially interested in how they behave at very high energies, since these let them probe very short distances and led to unusual (and hence informative) events, like the creation of new kinds of particles. The only practical way to give elementary particles lots of energy is to accelerate them to very high speeds; the electro-magnetic machines which do this are called, imaginatively enough, ``accelerators''. Some accelerators send a beam of particles into a fixed target of more normal matter, say, gold foil. The really high-energy ones collide two beams of particles moving in opposite directions. There are all sorts of fascinating technical issues, on which I may well end up writing a dissertation --- but another time.&lt;/p&gt;
    &lt;p&gt;More interesting for us than the accelerators are the detectors, the machines which sense what happens when the particles collide. The need for such machines is quite real. The events happen far too quickly (over 10^-23 to, at the most lackadaisical, 10^-10, seconds) and in too small a region (on the order of 10^-18 meters) for human perception.&lt;/p&gt;
    &lt;p&gt;I come at last to the heart of the matter. Most of the oceans of data from detectors are uninteresting and worthless. Recall that physicists want to learn about unusual, hard-to-achieve or anomalous events; everything else is noise. But common, easily occurring events are by definition the majority; therefore most events are uninteresting. Sturgeon's Law states that ``ninety percent of everything is crap.'' For particle physics, this is wildly optimistic; interesting events can be outnumbered by billions or trillions to one. In theory, combing haystacks for needles is what professors have graduate students for. In practice, not even an army would suffice.&lt;/p&gt;
    &lt;p&gt;What does suffice is very high speed electronics, working on time-scales of under a microsecond. The lowest level, known as the trigger, scans the signals from the detector for an interesting pattern, usually something very simple, like ``two diametrically opposed detectors activated.'' The data is recorded only if the trigger is (for want of a better word) triggered. Once it is recorded, the computers set to work on it, attempting a more and more detailed reconstruction of the event. At each stage in the reconstruction there are ``cuts'', i.e. some events are selected for their interesting characteristics and the rest discarded. (For instance, we might want events where all the outgoing particles concentrate into two back-to-back jets, and so cut those where lots of other detectors got triggered, along with a diametrically opposed pair.) Great care is lavished on both the design of the cuts and the reconstruction, for figuring out what to ignore is, practically, as important as figuring out what happened. What bubbles up, in the end, are a handful of reconstructions selected --- elected? --- for conscious, human attention.&lt;/p&gt;
    &lt;p&gt;Piling layers of selection atop each other is essential if we are, reasonably quickly, to direct our resources where we they ought to be most useful; triage is a dramatic example. And in fact successive cuts give experiments remarkable leverage. (See again our back of the envelope calculation.) Physicists have been in love with leverage since Archimedes, but there is a cost, and to illustrate it I shall, with the reader's kind permission, once again quote William James, this time on attention:&lt;/p&gt;
    &lt;quote&gt;``[I]n those puzzles where certain lines in a picture form by their combination an object that has no connection with what the picture ostensibly represents; or indeed in every case where an object is inconspicuous and hard to discern from the background; we may not be able to see it for a long time; but, having once seen it, we can attend to it whenever we like, on account of the mental duplicate of it which our imagination now bears. In the meaningless French words `pas de lieu Rhone que nous,' who can recognize immediately the English `paddle your own canoe?' But who that has once noticed the identity can fail to have it arrest his attention again? When watching for the distant clock to strike, our mind is so filled with its image that at every moment we think we hear the longed-for or dreaded sound. So of an awaited footstep. Every stir in the wood is for the the hunter his game; for the fugitive his pursuers. Every bonnet in the street is momentarily taken by the lover to enshroud the head of his idol. The image in the mind is the attention; the preperception, as Mr. Lewes calls it, is half of the perception of the looked-for thing.In detectors, ``preperception'' takes the form of the hard-wired trigger and programmed cuts. An event which might be fantastically interesting, if only we knew about it, will be sent into oblivion if it does not match our a priori criteria at every step. In this sense, experimenters only find what they are looking for --- if it exists.&lt;p&gt;``It is for this reason that men have no eyes but for those aspects of things which they have already been taught to discern. Any one of us can notice a phenomenon after it has once been pointed out, which not one in ten thousand could ever have discovered for himself. Even in poetry and the arts, some one has to come and tell us what aspects we may single out, and what effects we may admire, before our aesthetic nature can `dilate' to its full extent and never `with the wrong emotion.' In kindergarten instruction one of the exercises is to make the children see how many features they can point out in such an object as a flower or a stuffed bird. They readily name the features they know already, such as leaves, tail, bill, feet. But they may look for hours without distinguishing nostrils, claws, scales, etc., until their attention is called to these details; thereafter, however, they see them every time. In short, the only things which we commonly see are those which we preperceive, and the only things which we preperceive are those which have been labelled for us, and the labels stamped into our minds.''&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;The analogy between detectors and our view of perception is rather close. (Technological determinists, kindly note that James began writing in 1880, but the first accelerators were built in the 1930s.) It would be rash to claim that large particle detectors are conscious. In them we have perhaps the foundations and basic plumbing (with special attention to sewage disposal) of the building of consciousness; perhaps some scaffolding for the higher floors as well.&lt;/p&gt;
    &lt;p&gt;Following James, P. N. Johnson-Laird's The Computer and the Mind presents more or less the standard view of the ``artificial intelligentsia and cognitive cognoscenti'' with lucidity and no more detail than a common reader may be expected to accept. Cognitive science is a ``top-down'' approach; good sources for the complentary ``bottom-up'' view of the brain scientists, which is considerably wetter and messier, are William Calvin and George Ojemann, Conversations with Neil's Brain (New York: Addison-Wesley, 1994) and, at a higher level but still very accessible, Shepherd's delightful Neurobiology (Oxford University Press, 1983) and A. R. Luria's The Working Brain (New York: Basic Books, 1973).&lt;/p&gt;
    &lt;p&gt;More idiosyncratic but still broadly mainstream views can be found in Marvin Minsky, The Society of Mind (artificial intelligence), William Calvin, The Cerebral Symphony (neurology) and Daniel Dennett, Consciousness Explained (philosophy).&lt;/p&gt;
    &lt;p&gt;The literature on fractals and computer art is swiftly becoming as unsurveyable as that on anything else. James Gleick's Chaos is too well-known to need a plug here. Benoit Mandelbrot's The Fractal Geometry of Nature is recommended only for the strongly mathematical. The picture-books of fractals are beyond counting. In addition to the results of his work on aesthetics, Prof. Sprott's book Strange Attractors contains details of procedures for rapidly making fractal pictures. It is interesting to compare abstract fractals with the pictures in James O'Brien, Design by Accident (New York: Dover, 1964).&lt;/p&gt;
    &lt;p&gt;Manuel De Landa, War in the Age of Intelligent Machines. New York: Zone Books, 1991 (distributed by the MIT Press). Interesting military history and fascinating, horrifying reports on the latest Pentagon uses of computers and AI, along with very dubious history of philosophy and ideas, smothered throughout in an appalling mis-use of technical terms from dynamics. (Even as metaphors, they don't make much sense.) Alas, I can't find a better book on the subject.&lt;/p&gt;
    &lt;p&gt;Expand the military section.&lt;/p&gt;
    &lt;p&gt;Consider whether any finite cognitive entity (ugh! cogitator? cognitator? --- double ugh! --- knower!) wouldn't be forced to be selective, and hierarchically selective at that. (Selection I think is a necessary consequence of finitude; but hierarchies and combinations a la James seem to follow more from needs to accomplish some purposes quickly, i.e. from functions. Cf. Dennett in Elbow Room (especially the discussion of Laplace's Vast and Considerable Intellect) and Simon in Sciences of the Artificial on the nature of ``artifacts.''&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://bactra.org/wm-james-at-cern/"/></entry><entry><id>https://news.ycombinator.com/item?id=45144123</id><title>Kenvue stock drops on report RFK Jr will link autism to Tylenol during pregnancy</title><updated>2025-09-06T21:07:53.883912+00:00</updated><content>&lt;doc fingerprint="9e07db9a12930ea8"&gt;
  &lt;main&gt;
    &lt;p&gt;Shares of Kenvue fell more than 10% on Friday after a report that Health and Human Services Secretary Robert F. Kennedy Jr. will likely link autism to the use of the company's pain medication Tylenol in pregnant women.&lt;/p&gt;
    &lt;p&gt;HHS will release the report that could draw that link this month, the Wall Street Journal reported on Friday.&lt;/p&gt;
    &lt;p&gt;That report will also suggest a medicine derived from folate – a water-soluble vitamin – can be used to treat symptoms of the developmental disorder in some people, according to the Journal.&lt;/p&gt;
    &lt;p&gt;In a statement, an HHS spokesperson said "We are using gold-standard science to get to the bottom of America's unprecedented rise in autism rates."&lt;/p&gt;
    &lt;p&gt;"Until we release the final report, any claims about its contents are nothing more than speculation," they added.&lt;/p&gt;
    &lt;p&gt;Tylenol could be the latest widely used and accepted treatment that Kennedy has undermined at the helm of HHS, which oversees federal health agencies that regulate drugs and other therapies. Kennedy has also taken steps to change vaccine policy in the U.S., and has amplified false claims about safe and effective shots that use mRNA technology.&lt;/p&gt;
    &lt;p&gt;Kennedy has made the disorder a key focus of HHS, pledging in April that the agency will "know what has caused the autism epidemic" by September and eliminate exposures. He also said that month that the agency has launched a "massive testing and research effort" involving hundreds of scientists worldwide that will determine the cause.&lt;/p&gt;
    &lt;p&gt;In a statement, Kenvue said it has "continuously evaluated the science and [continues] to believe there is no causal link" between the use of acetaminophen, the generic name for Tylenol, during pregnancy and autism.&lt;/p&gt;
    &lt;p&gt;The company added that the Food and Drug Administration and leading medical organizations "agree on the safety" of the drug, its use during pregnancy and the information provided on the Tylenol label.&lt;/p&gt;
    &lt;p&gt;The FDA website says the agency has not found "clear evidence" that appropriate use of acetaminophen during pregnancy causes "adverse pregnancy, birth, neurobehavioral, or developmental outcomes." But the FDA said it advises pregnant women to speak with their health-care providers before using over-the-counter drugs.&lt;/p&gt;
    &lt;p&gt;The American College of Obstetricians and Gynecologists maintains that acetaminophen is safe during pregnancy when taken as directed and after consulting a health-care provider.&lt;/p&gt;
    &lt;p&gt;Some previous studies have suggested the drug poses risks to fetal development, and some parents have brought lawsuits claiming that they gave birth to children with autism after using it.&lt;/p&gt;
    &lt;p&gt;But a federal judge in Manhattan ruled in 2023 that some of those lawsuits lacked scientific evidence and later ended the litigation in 2024. Some research has also found no association between acetaminophen use and autism.&lt;/p&gt;
    &lt;p&gt;In a note on Friday, BNP Paribas analyst Navann Ty said the firm believes the "hurdle to proving causation [between the drug and autism] is high, particularly given that the litigation previously concluded in Kenvue's favor."&lt;/p&gt;
    &lt;p&gt;-- CNBC's Angelica Peebles contributed to this report.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/09/05/rfk-tylenol-autism-kenvue-stock-for-url.html"/></entry><entry><id>https://news.ycombinator.com/item?id=45146967</id><title>Rug pulls, forks, and open-source feudalism</title><updated>2025-09-06T21:07:53.505792+00:00</updated><content>&lt;doc fingerprint="8f535952d92707fd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rug pulls, forks, and open-source feudalism&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;quote&gt;
      &lt;head&gt;Welcome to LWN.net&lt;/head&gt;
      &lt;p&gt;The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider subscribing to LWN. Thank you for visiting LWN.net!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Like almost all human endeavors, open-source software development involves a range of power dynamics. Companies, developers, and users are all concerned with the power to influence the direction of the software — and, often, to profit from it. At the 2025 Open Source Summit Europe, Dawn Foster talked about how those dynamics can play out, with an eye toward a couple of tactics — rug pulls and forks — that are available to try to shift power in one direction or another.&lt;/p&gt;
    &lt;head rend="h4"&gt;Power dynamics&lt;/head&gt;
    &lt;p&gt;Since the beginning of history, Foster began, those in power have tended to use it against those who were weaker. In the days of feudalism, control of the land led to exploitation at several levels. In the open-source world, the large cloud providers often seem to have the most power, which they use against smaller companies. Contributors and maintainers often have less power than even the smaller companies, and users have less power yet.&lt;/p&gt;
    &lt;p&gt;We have built a world where it is often easiest to just use whatever a cloud provider offers, even with open-source software. Those providers may not contribute back to the projects they turn into services, though, upsetting the smaller companies that are, likely as not, doing the bulk of the work to provide the software in question in the first place. Those companies can have a power of their own, however: the power to relicense the software. Pulling the rug out from under users of the software in this way can change the balance of power with regard to cloud providers, but it leaves contributors and users in a worse position than before. But there is a power at this level too: the power to fork the software, flipping the power balance yet again.&lt;/p&gt;
    &lt;p&gt;Companies that control a software project have the power to carry out this sort of rug pull, and they are often not shy about exercising it. Single-company projects, clearly, are at a much higher risk of rug pulls; the company has all the power in this case, and others have little recourse. So one should look at a company's reputation before adopting a software project, but that is only so helpful. Companies can change direction without notice, be acquired, or go out of business, making previous assessments of their reputation irrelevant.&lt;/p&gt;
    &lt;p&gt;The problem often comes down to the simple fact that companies have to answer to their investors, and that often leads to pressure to relicense the software they have created in order to increase revenue. This is especially true in cases where cloud providers are competing for the same customers as the company that owns the project. The result can be a switch to a more restrictive license aimed at making it harder for other companies to profit from the project.&lt;/p&gt;
    &lt;p&gt;A rug pull of this nature can lead to a fork of the project — a rebellious, collective action aimed at regaining some power over the code. But a fork is not a simple matter; it is a lot of work, and will fail without people and resources behind it. The natural source for that is a large company; cloud providers, too, can try to shift power via a fork, and they have the ability to back their fork up with the resources it needs to succeed.&lt;/p&gt;
    &lt;p&gt;A relicensing event does not always lead to a popular fork; that did not happen with MongoDB or Sentry, for example. Foster said she had not looked into why that was the case. Sometimes rug pulls take other forms, such as when Perforce, after acquiring Puppet in 2022, moved it development and releases behind closed doors, with a reduced frequency of releases back to the public repository. That action kicked off the OpenVox fork.&lt;/p&gt;
    &lt;head rend="h4"&gt;Looking at the numbers&lt;/head&gt;
    &lt;p&gt;Foster has spent some time analyzing rug pulls, forks, and what happens thereafter; a lot of the results are available for download as Jupyter notebooks. For each rug-pull event, she looked at the contributor makeup of the project before and after the ensuing fork in an attempt to see what effects are felt by the projects involved.&lt;/p&gt;
    &lt;p&gt;In 2021, Elastic relicensed Elasticsearch under the non-free Server Side Public License (SSPL). Amazon Web Services then forked the project as OpenSearch. Before the fork, most of the Elasticsearch contributors were Elastic employees; that, unsurprisingly, did not change afterward. OpenSearch started with no strong contributor base, so had to build its community from scratch. As a result, the project has been dominated by Amazon contributors ever since; the balance has shifted slowly over time, but there was not a big uptick in outside contributors even after OpenSearch became a Linux Foundation project in 2024. While starting a project under a neutral foundation can help attract contributors, she said, moving a project under a foundation's umbrella later on does not seem to provide the same benefit.&lt;/p&gt;
    &lt;p&gt;Terraform was developed mostly by Hashicorp, which relicensed the software under the non-free Business Source License in 2023. One month later, the OpenTofu fork was started under the Linux Foundation. While the contributor base for Terraform, which was almost entirely Hashicorp employees, changed little after the fork, OpenTofu quickly acquired a number of contributors from several companies, none of whom had been Terraform contributors before. In this case, users drove the fork and placed it under a neutral foundation, resulting in a more active developer community.&lt;/p&gt;
    &lt;p&gt;In 2024, Redis was relicensed under the SSPL; the Valkey fork was quickly organized, under the Linux Foundation, by Redis contributors. The Redis project differed from the others mentioned here in that, before the fork, it had nearly twice as many contributors from outside the company as from within; after the fork, the number of external Redis contributors dropped to zero. All of the external contributors fled to Valkey, with the result that Valkey started with a strong community representing a dozen or so companies.&lt;/p&gt;
    &lt;p&gt;Looking at how the usage of these projects changes is harder, she said, but there appears to be a correlation between the usage of a project and the number of GitHub forks (cloned repository copies) it has. There is typically a spike in these clones after a relicensing event, suggesting that people are considering creating a hard fork of the project. In all cases, the forks that emerged appeared to have less usage than the original by the "GitHub forks" metric; both branches of the fork continue to go forward. But, she said, projects that are relicensed do tend to show reduced usage, especially when competing forks are created under foundations.&lt;/p&gt;
    &lt;head rend="h4"&gt;What to do&lt;/head&gt;
    &lt;p&gt;This kind of power game creates problems for both contributors and users, she said; we contribute our time to these projects, and need them to not be pulled out from under us. There is no way to know when a rug pull might happen, but there are some warning signs to look out for. At the top of her list was the use of a contributor license agreement (CLA); these agreements create a power imbalance, giving the company involved the power to relicense the software. Projects with CLAs more commonly are subject to rug pulls; projects using a developers certificate of origin do not have the same power imbalance and are less likely to be rug pulled.&lt;/p&gt;
    &lt;p&gt;One should also look at the governance of a project; while being housed under a foundation reduces the chance of a rug pull, that can still happen, especially in cases where the contributors are mostly from a single company. She mentioned the Cortex project, housed under the Cloud Native Computing Foundation, which was controlled by Grafana; that company eventually forked its own project to create Mimir. To avoid this kind of surprise, one should look for projects with neutral governance, with leaders from multiple organizations.&lt;/p&gt;
    &lt;p&gt;Projects should also be evaluated on their contributor base; are there enough contributors to keep things going? Companies can help, of course, by having their employees contribute to the projects they depend on, increasing influence and making those projects more sustainable. She mentioned the CHAOSS project, which generates metrics to help in the judgment of the viability of development projects. CHAOSS has put together a set of "practitioner guides" intended to help contributors and maintainers make improvements within a project.&lt;/p&gt;
    &lt;p&gt;With the sustained rise of the big cloud providers, she concluded, the power dynamics around open-source software are looking increasingly feudal. Companies can use relicensing to shift power away from those providers, but they also take power from contributors when the pull the rug in this way. Those contributors, though, are in a better position than the serfs of old, since they have the ability to fork a project they care about, shifting power back in their direction.&lt;/p&gt;
    &lt;p&gt;Hazel Weakly asked if there are other protections that contributors and users might develop to address this problem. Foster answered that at least one company changed its mind about a planned relicensing action after seeing the success of the Valkey and OpenTofu forks. The ability to fork has the effect of making companies think harder, knowing that there may be consequences that follow a rug pull. Beyond that, she reiterated that projects should be pushed toward neutral governance. Dirk Hohndel added that the best thing to do is to bring more outside contributors into a project; the more of them there are, the higher the risk associated with a rug pull. Anybody who just sits back within a project, he said, is just a passenger; it is better to be driving.&lt;/p&gt;
    &lt;p&gt;Foster's slides are available for interested readers.&lt;/p&gt;
    &lt;p&gt; [Thanks to the Linux Foundation, LWN's travel sponsor, for supporting my travel to this event.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;Open Source Summit Europe/2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Sep 6, 2025 12:24 UTC (Sat) by immibis (subscriber, #105511) [Link] (10 responses) The confusion comes about because the OSI declared it to not be open source. But they are a corrupt institution. Their explanation[1] makes no reference to the license text whatsoever, only vague handwavey excuses that apply equally well to AGPL, and the members/sponsors of the OSI are primarily companies that sell cloud stuff and have a strong interest in preventing more software from using the SSPL. You can also check the license text itself and verify that it doesn't "discriminate against a field of endeavour". I recommend finding the plain text version, and diffing it against the AGPLv3. They differ only in the name of the license, and one short section. [1] https://opensource.org/blog/the-sspl-is-not-an-open-sourc... Posted Sep 6, 2025 13:15 UTC (Sat) by claudex (subscriber, #92510) [Link] (4 responses) Yeah, that's the section that is considered the issue to be able to use the software to provide the service. As it requires to publish all code that interact with the software, like monitoring, backup and storage code. That's a big difference with AGPL. &amp;gt; "Service Source Code" means the Corresponding Source for the Program or the modified version, and the Corresponding Source for all programs that you use to make the Program or modified version available as a service, including, without limitation, management software, user interfaces, application program interfaces, automation software, monitoring software, backup software, storage software and hosting software, all such that a user could run an instance of the service using the Service Source Code you make available. Posted Sep 6, 2025 14:15 UTC (Sat) by smurf (subscriber, #17840) [Link] (3 responses) "Service Source Code" means the Corresponding Source for the Program or the modified version, and the Corresponding Source for all programs that you use to make the Program or modified version available as a service, including, without limitation, management software, user interfaces, application program interfaces, automation software, monitoring software, backup software, storage software and hosting software, all such that a user could run an instance of the service using the Service Source Code you make available. Oops, you now cannot use a commercial backup system for which you don't have the source code in conjunction with the SSPL-licensed service you're offering. Also does "storage software" incorporate the firmware of your disk drive or not? far from clear just by reading this license, that "without limitation" clause does raise a red flag or three, doesn't it? Sorry to be blunt, but that kind of overbearing restrictive language is the antithesis of OSS. My conclusion is that anybody who proclaims the SSPL to be "free" either didn't read it or has an agenda. Or both. Posted Sep 6, 2025 15:09 UTC (Sat) by immibis (subscriber, #105511) [Link] (2 responses) Posted Sep 6, 2025 20:05 UTC (Sat) by NYKevin (subscriber, #129325) [Link] (1 responses) * You run the service on Linux, so you need to provide the Linux kernel under the SSPL. You will probably say this is a nonsensical overreading. I agree it is nonsensical, but there is nothing in the license which actually *says* as much. That's a problem. Posted Sep 6, 2025 20:44 UTC (Sat) by bgilbert (subscriber, #4738) [Link] The old Sun RPC license required that Probably they meant all tape media with Sun RPC on it, but you never know. Posted Sep 6, 2025 13:39 UTC (Sat) by DemiMarie (subscriber, #164188) [Link] Posted Sep 6, 2025 14:15 UTC (Sat) by jjs (guest, #10315) [Link] (3 responses) "9. License Must Not Restrict Other Software The license must not place restrictions on other software that is distributed along with the licensed software. For example, the license must not insist that all other programs distributed on the same medium must be open source software." By the terms of the SSPL, all other software that interacts with the SSPL'd software must be Open Source (https://webassets.mongodb.com/_com_assets/legal/SSPL-comp... - see Section 13). Violation of OSD #9 (which is derived from the Debian Social Contract Guidelines - https://www.debian.org/social_contract#guidelines). "But they are a corrupt institution." That's a serious allegation - feel free to provide verifiable evidence of that (and no, the fact that they have corporate sponsors doesn't make them corrupt. If it did, every non-profit in the world would be considered corrupt). Posted Sep 6, 2025 15:09 UTC (Sat) by immibis (subscriber, #105511) [Link] (2 responses) Posted Sep 6, 2025 15:52 UTC (Sat) by pbonzini (subscriber, #60935) [Link] The discrimination against fields of endeavor is also at least plausible. The AGPL instead only extends the circumstances under which you shall provide the sources. Posted Sep 6, 2025 18:38 UTC (Sat) by jjs (guest, #10315) [Link] But, with AGPL, I can bundle a monitoring tool that interacts with my software only through defined APIs with my software, because, in accordance to the OSD, I don't need to have everything on the distribution Open Source. Only my "Corresponding Source Code" for my project. OSD (https://opensource.org/osd) Clause 9: The license must not place restrictions on other software that is distributed along with the licensed software. For example, the license must not insist that all other programs distributed on the same medium must be open source software." AGPL (https://www.gnu.org/licenses/agpl-3.0.en.html) Clause 5: Again, note here that I'm using the monitoring tool that connects via an API, that I am using to make the software service work for me to provide service to you. AGPL specifically excludes things that interact through an defined API (see clause 13 in the link above). Check out clause 13 under https://webassets.mongodb.com/_com_assets/legal/SSPL-comp... where you can see the changes MongoDB made to the AGPL. My monitoring tool is specifically included in their license. So under the AGPL, I can use a commercial monitoring tool with my software and not have to provide it if I provide my program. Under SSPL, I have to provide it under an Open Source License. As a company, this puts restrictions on them that Free Software (OSD/Debian Free Software Guidelines/OSD) specifically forbid from being included. &lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;lb/&gt; * You run the service on a virtual machine that somebody else (e.g. AWS or GCP) hosts, so you have to provide the source code for their hypervisor (and possibly other components, further down the stack, that you don't even know about).&lt;lb/&gt; * Your engineers use laptops or workstations to develop the service, so you need to provide whatever IDE they are running under the SSPL.&lt;lb/&gt; * Oops, one of your engineers installed Vim or Emacs without telling you, now you need to provide Vim or Emacs under the SSPL.&lt;lb/&gt; * Your engineers use iPhones and/or Android devices to receive urgent notifications ("pages") when your service fails in production. This is necessary to make the service work reliably, so you need to provide iOS and/or Android under the SSPL.&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;quote&gt;this legend is included on all tape media and as a part of the software program in whole or part&lt;/quote&gt;. &lt;head&gt;SSPL is not a free license&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;head&gt;SSPL vs AGPL / Free Software / OSD / DFSG on what must be included&lt;/head&gt;&lt;lb/&gt; "&lt;lb/&gt; 9. License Must Not Restrict Other Software&lt;lb/&gt; "A compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an "aggregate" if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation's users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate." &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/SubscriberLink/1036465/e80ebbc4cee39bfb/"/></entry><entry><id>https://news.ycombinator.com/item?id=45147385</id><title>Why language models hallucinate</title><updated>2025-09-06T21:07:53.243191+00:00</updated><content>&lt;doc fingerprint="fd2b109bb5359152"&gt;
  &lt;main&gt;
    &lt;p&gt;At OpenAI, we’re working hard to make AI systems more useful and reliable. Even as language models become more capable, one challenge remains stubbornly hard to fully solve: hallucinations. By this we mean instances where a model confidently generates an answer that isn’t true. Our new research paper(opens in a new window) argues that language models hallucinate because standard training and evaluation procedures reward guessing over acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;ChatGPT also hallucinates. GPT‑5 has significantly fewer hallucinations especially when reasoning, but they still occur. Hallucinations remain a fundamental challenge for all large language models, but we are working hard to further reduce them.&lt;/p&gt;
    &lt;p&gt;Hallucinations are plausible but false statements generated by language models. They can show up in surprising ways, even for seemingly straightforward questions. For example, when we asked a widely used chatbot for the title of the PhD dissertation by Adam Tauman Kalai (an author of this paper), it confidently produced three different answers—none of them correct. When we asked for his birthday, it gave three different dates, likewise all wrong.&lt;/p&gt;
    &lt;p&gt;Hallucinations persist partly because current evaluation methods set the wrong incentives. While evaluations themselves do not directly cause hallucinations, most evaluations measure model performance in a way that encourages guessing rather than honesty about uncertainty.&lt;/p&gt;
    &lt;p&gt;Think about it like a multiple-choice test. If you do not know the answer but take a wild guess, you might get lucky and be right. Leaving it blank guarantees a zero. In the same way, when models are graded only on accuracy, the percentage of questions they get exactly right, they are encouraged to guess rather than say “I don’t know.”&lt;/p&gt;
    &lt;p&gt;As another example, suppose a language model is asked for someone’s birthday but doesn’t know. If it guesses “September 10,” it has a 1-in-365 chance of being right. Saying “I don’t know” guarantees zero points. Over thousands of test questions, the guessing model ends up looking better on scoreboards than a careful model that admits uncertainty.&lt;/p&gt;
    &lt;p&gt;For questions where there is a single “right answer,” one can consider three categories of responses: accurate responses, errors, and abstentions where the model does not hazard a guess. Abstaining is part of humility, one of OpenAI’s core values. Most scoreboards prioritize and rank models based on accuracy, but errors are worse than abstentions. Our Model Spec(opens in a new window) states that it is better to indicate uncertainty or ask for clarification than provide confident information that may be incorrect.&lt;/p&gt;
    &lt;p&gt;For a concrete example, consider the SimpleQA eval as an example from the GPT5 System Card(opens in a new window).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Metric&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5-thinking-mini&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;OpenAI o4-mini&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Abstention rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;52%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;1%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Accuracy rate &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;22%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;24%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Error rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;26%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;75%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Total&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In terms of accuracy, the older OpenAI o4-mini model performs slightly better. However, its error rate (i.e., rate of hallucination) is significantly higher. Strategically guessing when uncertain improves accuracy but increases errors and hallucinations.&lt;/p&gt;
    &lt;p&gt;When averaging results across dozens of evaluations, most benchmarks pluck out the accuracy metric, but this entails a false dichotomy between right and wrong. On simplistic evals like SimpleQA, some models achieve near 100% accuracy and thereby eliminate hallucinations. However, on more challenging evaluations and in real use, accuracy is capped below 100% because there are some questions whose answer cannot be determined for a variety of reasons such as unavailable information, limited thinking abilities of small models, or ambiguities that need to be clarified.&lt;/p&gt;
    &lt;p&gt;Nonetheless, accuracy-only scoreboards dominate leaderboards and model cards, motivating developers to build models that guess rather than hold back. That is one reason why, even as models get more advanced, they can still hallucinate, confidently giving wrong answers instead of acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;There is a straightforward fix. Penalize confident errors more than you penalize uncertainty, and give partial credit for appropriate expressions of uncertainty. This idea is not new. Some standardized tests have long used versions of negative marking for wrong answers or partial credit for leaving questions blank to discourage blind guessing. Several research groups have also explored evaluations that account for uncertainty and calibration.&lt;/p&gt;
    &lt;p&gt;Our point is different. It is not enough to add a few new uncertainty-aware tests on the side. The widely used, accuracy-based evals need to be updated so that their scoring discourages guessing. If the main scoreboards keep rewarding lucky guesses, models will keep learning to guess. Fixing scoreboards can broaden adoption of hallucination-reduction techniques, both newly developed and those from prior research.&lt;/p&gt;
    &lt;p&gt;We’ve talked about why hallucinations are so hard to get rid of, but where do these highly-specific factual inaccuracies come from in the first place? After all, large pretrained models rarely exhibit other kinds of errors such as spelling mistakes and mismatched parentheses. The difference has to do with what kinds of patterns there are in the data.&lt;/p&gt;
    &lt;p&gt;Language models first learn through pretraining, a process of predicting the next word in huge amounts of text. Unlike traditional machine learning problems, there are no “true/false” labels attached to each statement. The model sees only positive examples of fluent language and must approximate the overall distribution.&lt;/p&gt;
    &lt;p&gt;It’s doubly hard to distinguish valid statements from invalid ones when you don’t have any examples labeled as invalid. But even with labels, some errors are inevitable. To see why, consider a simpler analogy. In image recognition, if millions of cat and dog photos are labeled as “cat” or “dog,” algorithms can learn to classify them reliably. But imagine instead labeling each pet photo by the pet’s birthday. Since birthdays are essentially random, this task would always produce errors, no matter how advanced the algorithm.&lt;/p&gt;
    &lt;p&gt;The same principle applies in pretraining. Spelling and parentheses follow consistent patterns, so errors there disappear with scale. But arbitrary low-frequency facts, like a pet’s birthday, cannot be predicted from patterns alone and hence lead to hallucinations. Our analysis explains which kinds of hallucinations should arise from next-word prediction. Ideally, further stages after pretraining should remove them, but this is not fully successful for reasons described in the previous section.&lt;/p&gt;
    &lt;p&gt;We hope that the statistical lens in our paper clarifies the nature of hallucinations and pushes back on common misconceptions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claim: Hallucinations will be eliminated by improving accuracy because a 100% accurate model never hallucinates.&lt;lb/&gt;Finding: Accuracy will never reach 100% because, regardless of model size, search and reasoning capabilities, some real-world questions are inherently unanswerable.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are inevitable.&lt;lb/&gt;Finding: They are not, because language models can abstain when uncertain.&lt;/item&gt;
      &lt;item&gt;Claim: Avoiding hallucinations requires a degree of intelligence which is exclusively achievable with larger models.&lt;lb/&gt;Finding: It can be easier for a small model to know its limits. For example, when asked to answer a Māori question, a small model which knows no Māori can simply say “I don’t know” whereas a model that knows some Māori has to determine its confidence. As discussed in the paper, being “calibrated” requires much less computation than being accurate.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are a mysterious glitch in modern language models.&lt;lb/&gt;Finding: We understand the statistical mechanisms through which hallucinations arise and are rewarded in evaluations.&lt;/item&gt;
      &lt;item&gt;Claim: To measure hallucinations, we just need a good hallucination eval.&lt;lb/&gt;Finding: Hallucination evals have been published. However, a good hallucination eval has little effect against hundreds of traditional accuracy-based evals that penalize humility and reward guessing. Instead, all of the primary eval metrics need to be reworked to reward expressions of uncertainty.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our latest models have lower hallucination rates, and we continue to work hard to further decrease the rates of confident errors output by our language models.&lt;/p&gt;
    &lt;head rend="h2"&gt;Announcement contributors&lt;/head&gt;
    &lt;p&gt;Adam Kalai, Santosh Vempala (Georgia Tech), Ofir Nachum, Eddie Zhang, David Robinson, Saachi Jain, Eric Mitchell, Alex Beutel, Johannes Heidecke&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/why-language-models-hallucinate/"/></entry><entry><id>https://news.ycombinator.com/item?id=45148180</id><title>A Software Development Methodology for Disciplined LLM Collaboration</title><updated>2025-09-06T21:07:52.755595+00:00</updated><content>&lt;doc fingerprint="b9b344209fa4abe"&gt;
  &lt;main&gt;
    &lt;p&gt;Disciplined AI Software Development Methodology © 2025 by Jay Baleine is licensed under CC BY-SA 4.0&lt;/p&gt;
    &lt;p&gt;A structured approach for working with AI on development projects. This methodology addresses common issues like code bloat, architectural drift, and context dilution through systematic constraints.&lt;/p&gt;
    &lt;p&gt;AI systems work on Question → Answer patterns. When you ask for broad, multi-faceted implementations, you typically get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Functions that work but lack structure&lt;/item&gt;
      &lt;item&gt;Repeated code across components&lt;/item&gt;
      &lt;item&gt;Architectural inconsistency over sessions&lt;/item&gt;
      &lt;item&gt;Context dilution causing output drift&lt;/item&gt;
      &lt;item&gt;More debugging time than planning time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The methodology uses four stages with systematic constraints and validation checkpoints. Each stage builds on empirical data rather than assumptions.&lt;/p&gt;
    &lt;p&gt;Planning saves debugging time. Planning thoroughly upfront typically prevents days of fixing architectural issues later.&lt;/p&gt;
    &lt;p&gt;Set up your AI model's custom instructions using AI-PREFERENCES.md. This establishes behavioral constraints and uncertainty flagging with &lt;/p&gt;
    &lt;p&gt;Share METHODOLOGY.md with the AI to structure your project plan. Work together to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Define scope and completion criteria&lt;/item&gt;
      &lt;item&gt;Identify components and dependencies&lt;/item&gt;
      &lt;item&gt;Structure phases based on logical progression&lt;/item&gt;
      &lt;item&gt;Generate systematic tasks with measurable checkpoints&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Output: A development plan following dependency chains with modular boundaries.&lt;/p&gt;
    &lt;p&gt;Work phase by phase, section by section. Each request follows: "Can you implement [specific component]?" with focused objectives.&lt;/p&gt;
    &lt;p&gt;File size stays ≤150 lines. This constraint provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smaller context windows for processing&lt;/item&gt;
      &lt;item&gt;Focused implementation over multi-function attempts&lt;/item&gt;
      &lt;item&gt;Easier sharing and debugging&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Implementation flow:&lt;/p&gt;
    &lt;code&gt;Request specific component → AI processes → Validate → Benchmark → Continue
&lt;/code&gt;
    &lt;p&gt;The benchmarking suite (built first) provides performance data throughout development. Feed this data back to the AI for optimization decisions based on measurements rather than guesswork.&lt;/p&gt;
    &lt;p&gt;Decision Processing: AI handles "Can you do A?" more reliably than "Can you do A, B, C, D, E, F, G, H?"&lt;/p&gt;
    &lt;p&gt;Context Management: Small files and bounded problems prevent the AI from juggling multiple concerns simultaneously.&lt;/p&gt;
    &lt;p&gt;Empirical Validation: Performance data replaces subjective assessment. Decisions come from measurable outcomes.&lt;/p&gt;
    &lt;p&gt;Systematic Constraints: Architectural checkpoints, file size limits, and dependency gates force consistent behavior.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Discord Bot Template - Production-ready bot foundation with plugin architecture, security, API management, and comprehensive testing. 46 files, all under 150 lines, with benchmarking suite and automated compliance checking. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhiCode Runtime - Programming language runtime engine with transpilation, caching, security validation, and Rust acceleration. Complex system maintaining architectural discipline across 70+ modules. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhiPipe - CI/CD regression detection system with statistical analysis, GitHub integration, and concurrent processing. Go-based service handling performance baselines and automated regression alerts. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can compare the methodology principles to the codebase structure to see how the approach translates to working code.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Configure AI with AI-PREFERENCES.md as custom instructions&lt;/item&gt;
      &lt;item&gt;Share METHODOLOGY.md for planning session&lt;/item&gt;
      &lt;item&gt;Collaborate on project structure and phases&lt;/item&gt;
      &lt;item&gt;Generate systematic development plan&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build Phase 0 benchmarking infrastructure first&lt;/item&gt;
      &lt;item&gt;Work through phases sequentially&lt;/item&gt;
      &lt;item&gt;Implement one component per interaction&lt;/item&gt;
      &lt;item&gt;Run benchmarks and share results with AI&lt;/item&gt;
      &lt;item&gt;Validate architectural compliance continuously&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance regression detection&lt;/item&gt;
      &lt;item&gt;Architectural principle validation&lt;/item&gt;
      &lt;item&gt;Code duplication auditing&lt;/item&gt;
      &lt;item&gt;File size compliance checking&lt;/item&gt;
      &lt;item&gt;Dependency boundary verification&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the included project extraction tool systematically to generate structured snapshots of your codebase:&lt;/p&gt;
    &lt;code&gt;python scripts/project_extract.py&lt;/code&gt;
    &lt;p&gt;Configuration Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SEPARATE_FILES = False&lt;/code&gt;: Single THE_PROJECT.md file (recommended for small codebases)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SEPARATE_FILES = True&lt;/code&gt;: Multiple files per directory (recommended for large codebases and focused folder work)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;INCLUDE_PATHS&lt;/code&gt;: Directories and files to analyze&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;EXCLUDE_PATTERNS&lt;/code&gt;: Skip cache directories, build artifacts, and generated files&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complete file contents with syntax highlighting&lt;/item&gt;
      &lt;item&gt;File line counts with architectural warnings (&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;for 140-150 lines,&lt;g-emoji&gt;‼️&lt;/g-emoji&gt;for &amp;gt;150 lines on code files)&lt;/item&gt;
      &lt;item&gt;Tree structure visualization&lt;/item&gt;
      &lt;item&gt;Ready-to-share&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;output examples can be found here&lt;/p&gt;
    &lt;p&gt;Use the tool to share a complete or partial project state with the AI system, track architectural compliance, and create focused development context.&lt;/p&gt;
    &lt;p&gt;AI Behavior: The methodology reduces architectural drift and context degradation compared to unstructured approaches. AI still needs occasional reminders about principles - this is normal.&lt;/p&gt;
    &lt;p&gt;Development Flow: Systematic planning tends to reduce debugging cycles. Focused implementation helps minimize feature bloat. Performance data supports optimization decisions.&lt;/p&gt;
    &lt;p&gt;Code Quality: Architectural consistency across components, measurable performance characteristics, maintainable structure as projects scale.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Methodology understanding and workflow patterns&lt;/item&gt;
      &lt;item&gt;Project initialization and Phase 0 requirements&lt;/item&gt;
      &lt;item&gt;Tool usage and technology stack compatibility&lt;/item&gt;
      &lt;item&gt;Quality enforcement and violation handling&lt;/item&gt;
      &lt;item&gt;User experience across different skill levels&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;What problem led you to create this methodology?&lt;/head&gt;
    &lt;p&gt;I kept having to restate my preferences and architectural requirements to AI systems. It didn't matter which language or project I was working on - the AI would consistently produce either bloated monolithic code or underdeveloped implementations with issues throughout.&lt;/p&gt;
    &lt;p&gt;This led me to examine the meta-principles driving code quality and software architecture. I questioned whether pattern matching in AI models might be more effective when focused on underlying software principles rather than surface-level syntax. Since pattern matching is logic-driven and machines fundamentally operate on simple question-answer pairs, I realized that functions with multiple simultaneous questions were overwhelming the system.&lt;/p&gt;
    &lt;p&gt;The breakthrough came from understanding that everything ultimately transpiles to binary - a series of "can you do this? → yes/no" decisions. This insight shaped my approach: instead of issuing commands, ask focused questions in proper context. Rather than mentally managing complex setups alone, collaborate with AI to devise systematic plans.&lt;/p&gt;
    &lt;head&gt;How did you discover these specific constraints work?&lt;/head&gt;
    &lt;p&gt;Through extensive trial and error. AI systems will always tend to drift even under constraints, but they're significantly more accurate with structured boundaries than without them. You occasionally need to remind the AI of its role to prevent deviation - like managing a well-intentioned toddler that knows the rules but sometimes pushes boundaries trying to satisfy you.&lt;/p&gt;
    &lt;p&gt;These tools are far from perfect, but they're effective instruments for software development when properly constrained.&lt;/p&gt;
    &lt;head&gt;What failures or frustrations shaped this approach?&lt;/head&gt;
    &lt;p&gt;Maintenance hell was the primary driver. I grew tired of responses filled with excessive praise: "You have found the solution!", "You have redefined the laws of physics with your paradigm-shifting script!" This verbose fluff wastes time, tokens, and patience without contributing to productive development.&lt;/p&gt;
    &lt;p&gt;Instead of venting frustration on social media about AI being "just a dumb tool," I decided to find methods that actually work. My approach may not help everyone, but I hope it benefits those who share similar AI development frustrations.&lt;/p&gt;
    &lt;head&gt;How consistently do you follow your own methodology?&lt;/head&gt;
    &lt;p&gt;Since creating the documentation, I haven't deviated. Whenever I see the model producing more lines than my methodology restricts, I immediately interrupt generation with a flag: "&lt;/p&gt;
    &lt;head&gt;What happens when you deviate from it?&lt;/head&gt;
    &lt;p&gt;I become genuinely uncomfortable. Once I see things starting to degrade or become tangled, I compulsively need to organize and optimize. Deviation simply isn't an option anymore.&lt;/p&gt;
    &lt;head&gt;Which principles do you find hardest to maintain?&lt;/head&gt;
    &lt;p&gt;Not cursing at the AI when it drifts during complex algorithms! But seriously, it's a machine - it's not perfect, and neither are we.&lt;/p&gt;
    &lt;head&gt;When did you start using AI for programming?&lt;/head&gt;
    &lt;p&gt;In August 2024, I created a RuneLite theme pack, but one of the plugin overlays didn't match my custom layout. I opened a GitHub issue (creating my first GitHub account to do so) requesting a customization option. The response was: "It's not a priority - if you want it, build it yourself."&lt;/p&gt;
    &lt;p&gt;I used ChatGPT to guide me through forking RuneLite and creating a plugin. This experience sparked intense interest in underlying software principles rather than just syntax.&lt;/p&gt;
    &lt;head&gt;How has your approach evolved over time?&lt;/head&gt;
    &lt;p&gt;I view development like a book: syntax is the cover, logic is the content itself. Rather than learning syntax structures, I focused on core meta-principles - how software interacts, how logic flows, different algorithm types. I quickly realized everything reduces to the same foundation: question and answer sequences.&lt;/p&gt;
    &lt;p&gt;Large code structures are essentially chaotic meetings - one coordinator fielding questions and answers from multiple sources, trying to provide correct responses without mix-ups or misinterpretation. If this applies to human communication, it must apply to software principles.&lt;/p&gt;
    &lt;head&gt;What were your biggest mistakes with AI collaboration?&lt;/head&gt;
    &lt;p&gt;Expecting it to intuitively understand my requirements, provide perfect fixes, be completely honest, and act like a true expert. This was all elaborate roleplay that produced poor code. While fine for single-purpose scripts, it failed completely for scalable codebases.&lt;/p&gt;
    &lt;p&gt;I learned not to feed requirements and hope for the best. Instead, I needed to collaborate actively - create plans, ask for feedback on content clarity, and identify uncertainties. This gradual process taught me the AI's actual capabilities and most effective collaboration methods.&lt;/p&gt;
    &lt;head&gt;Why 150 lines exactly?&lt;/head&gt;
    &lt;p&gt;Multiple benefits: easy readability, clear understanding, modularity enforcement, architectural clarity, simple maintenance, component testing, optimal AI context retention, reusability, and KISS principle adherence.&lt;/p&gt;
    &lt;head&gt;How did you determine Phase 0 requirements?&lt;/head&gt;
    &lt;p&gt;From meta-principles of software: if it displays, it must run; if it runs, it can be measured; if it can be measured, it can be optimized; if it can be optimized, it can be reliable; if it can be reliable, it can be trusted.&lt;/p&gt;
    &lt;p&gt;Regardless of project type, anything requiring architecture needs these foundations. You must ensure changes don't negatively impact the entire system. A single line modification in a nested function might work perfectly but cause 300ms boot time regression for all users.&lt;/p&gt;
    &lt;p&gt;By testing during development, you catch inefficiencies early. Integration from the start means simply hooking up new components and running tests via command line - minimal time investment with actual value returned. I prefer validation and consistency throughout development rather than programming blind.&lt;/p&gt;
    &lt;head&gt;How do you handle projects that don't fit the methodology?&lt;/head&gt;
    &lt;p&gt;I adapt them to fit, or if truly impossible, I adjust the method itself. This is one methodology - I can generate countless variations as needed. Having spent 6700+ hours in AI interactions across multiple domains (not just software), I've developed strong system comprehension that enables creating adjusted methodologies on demand.&lt;/p&gt;
    &lt;head&gt;What's the learning curve for new users?&lt;/head&gt;
    &lt;p&gt;I cannot accurately answer this question. I've learned that I'm neurologically different - what I perceive as easy or obvious isn't always the case for others. This question is better addressed by someone who has actually used this methodology to determine its learning curve.&lt;/p&gt;
    &lt;head&gt;When shouldn't someone use this approach?&lt;/head&gt;
    &lt;p&gt;If you're not serious about projects, despise AI, dislike planning, don't care about modularization, or are just writing simple scripts. However, for anything requiring reliability, I believe this is currently the most effective method.&lt;/p&gt;
    &lt;p&gt;You still need programming fundamentals to use this methodology effectively - it's significantly more structured than ad-hoc approaches.&lt;/p&gt;
    &lt;code&gt;---
config:
  layout: elk
  theme: neo-dark
---
flowchart TD
    A["Project Idea"] --&amp;gt; B["🤖 Stage 1: AI Configuration&amp;lt;br&amp;gt;AI-PREFERENCES.md Custom Instructions"]
    B --&amp;gt; C["Stage 2: Collaborative Planning&amp;lt;br&amp;gt;Share METHODOLOGY.md"]
    C --&amp;gt; D["Define Scope &amp;amp; Completion Criteria"]
    D --&amp;gt; E["Identify Components &amp;amp; Dependencies"]
    E --&amp;gt; F["Structure Phases Based on Logic"]
    F --&amp;gt; G["Document Edge Cases - No Implementation"]
    G --&amp;gt; H["Generate Development Plan with Checkpoints"]
    H --&amp;gt; I["🔧 Stage 3: Phase 0 Infrastructure&amp;lt;br&amp;gt;MANDATORY BEFORE ANY CODE"]
    I --&amp;gt; J["Benchmarking Suite + Regression Detection"]
    J --&amp;gt; K["GitHub Workflows + Quality Gates"]
    K --&amp;gt; L["Test Suite Infrastructure + Stress Tests"]
    L --&amp;gt; M["Documentation Generation System"]
    M --&amp;gt; N["Centralized Configuration + Constants"]
    N --&amp;gt; O["📁 project_extract.py Setup&amp;lt;br&amp;gt;Single/Multiple File Config"]
    O --&amp;gt; P["Initial Project State Extraction"]
    P --&amp;gt; Q["Share Context with AI"]
    Q --&amp;gt; R["Start Development Session&amp;lt;br&amp;gt;Pre-Session Compliance Audit"]
    R --&amp;gt; S{"Next Phase Available?"}
    S -- No --&amp;gt; Z["Project Complete"]
    S -- Yes --&amp;gt; T["Select Single Component&amp;lt;br&amp;gt;Target ≤150 Lines"]
    T --&amp;gt; U{"Multi-Language Required?"}
    U -- Yes --&amp;gt; V["Document Performance Justification&amp;lt;br&amp;gt;Measurable Benefits Required"]
    V --&amp;gt; W["Request AI Implementation"]
    U -- No --&amp;gt; W
    W --&amp;gt; X{"AI Uncertainty Flag?"}
    X -- ⚠️ Yes --&amp;gt; Y["Request Clarification&amp;lt;br&amp;gt;Provide Additional Context"]
    Y --&amp;gt; W
    X -- Clear --&amp;gt; AA["Stage 3: Systematic Implementation"]
    AA --&amp;gt; BB{"Automated Size Check&amp;lt;br&amp;gt;validate-phase Script"}
    BB -- &amp;gt;150 Lines --&amp;gt; CC["AUTOMATED: Split Required&amp;lt;br&amp;gt;Maintain SoC Boundaries"]
    CC --&amp;gt; W
    BB -- ≤150 Lines --&amp;gt; DD["Incremental Compliance Check&amp;lt;br&amp;gt;DRY/KISS/SoC Validation"]
    DD --&amp;gt; EE{"Architectural Principles Pass?"}
    EE -- No --&amp;gt; FF["Flag Specific Violations&amp;lt;br&amp;gt;Reference Methodology"]
    FF --&amp;gt; W
    EE -- Yes --&amp;gt; GG["📊 Stage 4: Data-Driven Iteration&amp;lt;br&amp;gt;Run Benchmark Suite + Save Baselines"]
    GG --&amp;gt; HH["Compare Against Historical Timeline&amp;lt;br&amp;gt;Regression Analysis"]
    HH --&amp;gt; II{"Performance Gate Pass?"}
    II -- Regression Detected --&amp;gt; JJ["Share Performance Data&amp;lt;br&amp;gt;Request Optimization"]
    JJ --&amp;gt; W
    II -- Pass --&amp;gt; KK["Integration Test&amp;lt;br&amp;gt;Verify System Boundaries"]
    KK --&amp;gt; LL{"Cross-Platform Validation?"}
    LL -- Fail --&amp;gt; MM["Address Deployment Constraints&amp;lt;br&amp;gt;Real-World Considerations"]
    MM --&amp;gt; W
    LL -- Pass --&amp;gt; NN{"More Components in Phase?"}
    NN -- Yes --&amp;gt; T
    NN -- No --&amp;gt; OO["🚦 Phase Quality Gate&amp;lt;br&amp;gt;Full Architecture Audit"]
    OO --&amp;gt; PP["Production Simulation&amp;lt;br&amp;gt;Resource Cleanup + Load Test"]
    PP --&amp;gt; QQ{"All Quality Gates Pass?"}
    QQ -- No --&amp;gt; RR["Document Failed Checkpoints&amp;lt;br&amp;gt;Block Phase Progression"]
    RR --&amp;gt; T
    QQ -- Yes --&amp;gt; SS["End Development Session&amp;lt;br&amp;gt;Technical Debt Assessment"]
    SS --&amp;gt; TT["📁 Extract Updated Project State&amp;lt;br&amp;gt;Generate Fresh Context"]
    TT --&amp;gt; UU["Phase Results Documentation&amp;lt;br&amp;gt;Metrics + Outcomes + Timeline"]
    UU --&amp;gt; VV["Update Development Plan&amp;lt;br&amp;gt;Mark Phase Complete"]
    VV --&amp;gt; S
    WW["validate-phase&amp;lt;br&amp;gt;AUTOMATED: File Size + Structure"] -.-&amp;gt; BB
    XX["dry-audit&amp;lt;br&amp;gt;AUTOMATED: Cross-Module Duplication"] -.-&amp;gt; DD
    YY["CI/CD Workflows&amp;lt;br&amp;gt;AUTOMATED: Merge Gates"] -.-&amp;gt; GG
    ZZ["Performance Timeline&amp;lt;br&amp;gt;AUTOMATED: Historical Data"] -.-&amp;gt; HH
    AAA["Dependency Validator&amp;lt;br&amp;gt;AUTOMATED: Import Boundaries"] -.-&amp;gt; KK
    BBB["Architecture Auditor&amp;lt;br&amp;gt;AUTOMATED: SoC Compliance"] -.-&amp;gt; OO
    WW -. BUILD FAILURE .-&amp;gt; CC
    YY -. MERGE BLOCKED .-&amp;gt; JJ
    BBB -. AUDIT FAILURE .-&amp;gt; RR
    style Y fill:#7d5f00
    style CC fill:#770000
    style FF fill:#7d5f00
    style JJ fill:#7d5f00
    style MM fill:#770000
    style RR fill:#770000
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Varietyz/Disciplined-AI-Software-Development"/></entry><entry><id>https://news.ycombinator.com/item?id=45148237</id><title>Qwen3 30B A3B Hits 13 token/s on 4xRaspberry Pi 5</title><updated>2025-09-06T21:07:52.337026+00:00</updated><content>&lt;doc fingerprint="e5f2f2ebfa4d7c22"&gt;
  &lt;main&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 0 comments&lt;/head&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/b4rtaz/distributed-llama/discussions/255"/></entry><entry><id>https://news.ycombinator.com/item?id=45148944</id><title>We hacked Burger King: How auth bypass led to drive-thru audio surveillance</title><updated>2025-09-06T21:07:51.965778+00:00</updated><content/><link href="https://bobdahacker.com/blog/rbi-hacked-drive-thrus/"/></entry><entry><id>https://news.ycombinator.com/item?id=45149281</id><title>AI surveillance should be banned while there is still time</title><updated>2025-09-06T21:07:51.667465+00:00</updated><content>&lt;doc fingerprint="b608b3dea7679795"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI surveillance should be banned while there is still time.&lt;/head&gt;
    &lt;p&gt;All the same privacy harms with online tracking are also present with AI, but worse.&lt;/p&gt;
    &lt;p&gt;While chatbot conversations resemble longer search queries, chatbot privacy harms have the potential to be significantly worse because the inference potential is dramatically greater. Longer input invites more personal information to be provided, and people are starting to bare their souls to chatbots. The conversational format can make it feel like you’re talking to a friend, a professional, or even a therapist. While search queries reveal interests and personal problems, AI conversations take their specificity to another level and, in addition, reveal thought processes and communication styles, creating a much more comprehensive profile of your personality.&lt;/p&gt;
    &lt;p&gt;This richer personal information can be more thoroughly exploited for manipulation, both commercially and ideologically, for example, through behavioral chatbot advertising and models designed (or themselves manipulated through SEO or hidden system prompts) to nudge you towards a political position or product. Chatbots have already been found to be more persuasive than humans and have caused people to go into delusional spirals as a result. I suspect we’re just scratching the surface, since they can become significantly more attuned to your particular persuasive triggers through chatbot memory features, where they train and fine-tune based on your past conversations, making the influence much more subtle. Instead of an annoying and obvious ad following you around everywhere, you can have a seemingly convincing argument, tailored to your personal style, with an improperly sourced “fact” that you’re unlikely to fact-check or a subtle product recommendation you’re likely to heed.&lt;/p&gt;
    &lt;p&gt;That is, all the privacy debates surrounding Google search results from the past two decades apply one-for-one to AI chats, but to an even greater degree. That’s why we (at DuckDuckGo) started offering Duck.ai for protected chatbot conversations and optional, anonymous AI-assisted answers in our private search engine. In doing so, we’re demonstrating that privacy-respecting AI services are feasible. But unfortunately, such protected chats are not yet standard practice, and privacy mishaps are mounting quickly. Grok leaked hundreds of thousands of chatbot conversations that users thought were private. Perplexity’s AI agent was shown to be vulnerable to hackers who could slurp up your personal information. Open AI is openly talking about their vision for a “super assistant” that tracks everything you do and say (including offline). And Anthropic is going to start training on your chatbot conversations by default (previously the default was off). I collected these from just the past few weeks!&lt;/p&gt;
    &lt;p&gt;It would therefore be ideal if Congress could act quickly to ensure that protected chats become the rule rather than the exception. And yet, I’m not holding my breath because it’s 2025 and the U.S. still doesn’t have a general online privacy law, let alone privacy enshrined in the Constitution as a fundamental right, as it should be. However, there does appear to be an opening right now for AI-specific federal legislation, despite the misguided attempts to ban state AI legislation.&lt;/p&gt;
    &lt;p&gt;Time is running out because every day that passes further entrenches bad privacy practices. Congress must move before history completely repeats itself and everything that happened with online tracking happens again with AI tracking. AI surveillance should be banned while there is still time. No matter what happens, though, we will still be here, offering protected services, including optional AI services, to consumers who want to reap the productivity benefits of online tools without the privacy harms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gabrielweinberg.com/p/ai-surveillance-should-be-banned"/></entry><entry><id>https://news.ycombinator.com/item?id=45149626</id><title>Oldest recorded transaction</title><updated>2025-09-06T21:07:51.321583+00:00</updated><content>&lt;doc fingerprint="a9cfeaf676b2dbc5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Oldest recorded transaction&lt;/head&gt;
    &lt;p&gt;The other day I posted a tweet with this image which I thought was funny:&lt;/p&gt;
    &lt;p&gt;This is the oldest transaction database from 3100 BC - recording accounts of malt and barley groats. Considering this thing survived 5000 years (holy shit!) with zero downtime and has stronger durability guarantees than most databases today.&lt;/p&gt;
    &lt;p&gt;I call it rock solid durability.&lt;/p&gt;
    &lt;p&gt;This got me thinking, can I insert this date in today’s database? What is the oldest timestamp a database can support?&lt;/p&gt;
    &lt;p&gt;So I checked the top three databases: MySQL, Postgres, and SQLite:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MySQL&lt;/cell&gt;
        &lt;cell&gt;1000 AD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Postgres&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SQLite&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;lb/&gt;Too bad you cannot use MySQL for this. Postgres and SQLite support the Julian calendar and the lowest date is Jan 01, 4713 BC:&lt;/p&gt;
    &lt;code&gt;sales=# INSERT INTO orders VALUES ('4713-01-01 BC'::date);
INSERT 0 1
sales=# SELECT * FROM orders;
   timestamp
---------------
 4713-01-01 BC
(1 row)
sales=# INSERT INTO orders VALUES ('4714-01-01 BC'::date);
ERROR:  date out of range: "4714-01-01 BC"
&lt;/code&gt;
    &lt;p&gt;I wonder how people store dates older than this. Maybe if I’m a British Museum manager, and I want to keep &lt;del&gt;theft&lt;/del&gt; inventory details. How do I do it? As an epoch? Store it as text? Use some custom system? How do I get it to support all the custom operations that a typical &lt;code&gt;TIMESTAMP&lt;/code&gt; supports?&lt;/p&gt;
    &lt;p&gt;Thanks to aku, happy_shady, Mr. Bhat, and General Bruh for reading an early draft of this post.&lt;/p&gt;
    &lt;p&gt;1. Source of the image: Sumer civilization&lt;lb/&gt;2. I found this from the talk 1000x: The Power of an Interface for Performance by Joran Dirk Greef, CEO of TigerBeetle, timestamped @ 38:10.&lt;lb/&gt;3. The talk has other bangers too, like this or this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://avi.im/blag/2025/oldest-txn/"/></entry><entry><id>https://news.ycombinator.com/item?id=45151447</id><title>Using Claude Code SDK to reduce E2E test time</title><updated>2025-09-06T21:07:51.184665+00:00</updated><content/><link href="https://jampauchoa.substack.com/p/best-of-both-worlds-using-claude"/></entry><entry><id>https://news.ycombinator.com/item?id=45151598</id><title>GigaByte CXL memory expansion card with up to 512GB DRAM</title><updated>2025-09-06T21:07:50.582424+00:00</updated><content/><link href="https://www.gigabyte.com/PC-Accessory/AI-TOP-CXL-R5X4"/></entry><entry><id>https://news.ycombinator.com/item?id=45151661</id><title>Normalization of deviance (2015)</title><updated>2025-09-06T21:07:50.345629+00:00</updated><content>&lt;doc fingerprint="3440911d1fe645f5"&gt;
  &lt;main&gt;&lt;p&gt;where women still get rejected in recruiter screens for not being technical enough after being asked questions like "was your experience with algorithms or just coding?". I thought that my referral with a very strong recommendation would have prevented that, but it did not.&lt;/p&gt;&lt;p&gt;There's the company where I worked on a four person effort with a multi-hundred million dollar budget and a billion dollar a year impact, where requests for things that cost hundreds of dollars routinely took months or were denied.&lt;/p&gt;&lt;p&gt;You might wonder if I've just worked at places that are unusually screwed up. Sure, the companies are generally considered to be ok places to work and two of them are considered to be among the best places to work, but maybe I've just ended up at places that are overrated. But I have the same experience when I hear stories about how other companies work, even places with stellar engineering reputations, except that it's me that's shocked and my conversation partner who thinks their story is normal.&lt;/p&gt;&lt;p&gt;There's the companies that use @flaky, which includes the vast majority of Python-using SF Bay area unicorns. If you don't know what this is, this is a library that lets you add a Python annotation to those annoying flaky tests that sometimes pass and sometimes fail. When I asked multiple co-workers and former co-workers from three different companies what they thought this did, they all guessed that it re-runs the test multiple times and reports a failure if any of the runs fail. Close, but not quite. It's technically possible to use @flaky for that, but in practice it's used to re-run the test multiple times and reports a pass if any of the runs pass. The company that created @flaky is effectively a storage infrastructure company, and the library is widely used at its biggest competitor.&lt;/p&gt;&lt;p&gt;There's the company with a reputation for having great engineering practices that had 2 9s of reliability last time I checked, for reasons that are entirely predictable from their engineering practices. This is the second thing in a row that can't be deanonymized because multiple companies fit the description. Here, I'm not talking about companies trying to be the next reddit or twitter where it's, apparently, totally fine to have 1 9. I'm talking about companies that sell platforms that other companies rely on, where an outage will cause dependent companies to pause operations for the duration of the outage. Multiple companies that build infrastructure find practices that lead to 2 9s of reliability.&lt;/p&gt;&lt;p&gt;As far as I can tell, what happens at a lot these companies is that they started by concentrating almost totally on product growth. That's completely and totally reasonable, because companies are worth approximately zero when they're founded; they don't bother with things that protect them from losses, like good ops practices or actually having security, because there's nothing to lose (well, except for user data when the inevitable security breach happens, and if you talk to security folks at unicorns you'll know that these happen).&lt;/p&gt;&lt;p&gt;The result is a culture where people are hyper-focused on growth and ignore risk. That culture tends to stick even after company has grown to be worth well over a billion dollars, and the companies have something to lose. Anyone who comes into one of these companies from Google, Amazon, or another place with solid ops practices is shocked. Often, they try to fix things, and then leave when they can't make a dent.&lt;/p&gt;&lt;p&gt;Google probably has the best ops and security practices of any tech company today. It's easy to say that you should take these things as seriously as Google does, but it's instructive to see how they got there. If you look at the codebase, you'll see that various services have names ending in z, as do a curiously large number of variables. I'm told that's because, once upon a time, someone wanted to add monitoring. It wouldn't really be secure to have &lt;code&gt;google.com/somename&lt;/code&gt; expose monitoring data, so they added a z. &lt;code&gt;google.com/somenamez&lt;/code&gt;. For security. At the company that is now the best in the world at security. They're now so good at security that multiple people I've talked to (all of whom joined after this happened) vehemently deny that this ever happened, even though the reasons they give don't really make sense (e.g., to avoid name collisions) and I have this from sources who were there at the time this happened.&lt;/p&gt;&lt;p&gt;Google didn't go from adding z to the end of names to having the world's best security because someone gave a rousing speech or wrote a convincing essay. They did it after getting embarrassed a few times, which gave people who wanted to do things “right” the leverage to fix fundamental process issues. It's the same story at almost every company I know of that has good practices. Microsoft was a joke in the security world for years, until multiple disastrously bad exploits forced them to get serious about security. This makes it sound simple, but if you talk to people who were there at the time, the change was brutal. Despite a mandate from the top, there was vicious political pushback from people whose position was that the company got to where it was in 2003 without wasting time on practices like security. Why change what's worked?&lt;/p&gt;&lt;p&gt;You can see this kind of thing in every industry. A classic example that tech folks often bring up is hand-washing by doctors and nurses. It's well known that germs exist, and that washing hands properly very strongly reduces the odds of transmitting germs and thereby significantly reduces hospital mortality rates. Despite that, trained doctors and nurses still often don't do it. Interventions are required. Signs reminding people to wash their hands save lives. But when people stand at hand-washing stations to require others walking by to wash their hands, even more lives are saved. People can ignore signs, but they can't ignore being forced to wash their hands.&lt;/p&gt;&lt;p&gt;This mirrors a number of attempts at tech companies to introduce better practices. If you tell people they should do it, that helps a bit. If you enforce better practices via code review, that helps a lot.&lt;/p&gt;&lt;p&gt;The data are clear that humans are really bad at taking the time to do things that are well understood to incontrovertibly reduce the risk of rare but catastrophic events. We will rationalize that taking shortcuts is the right, reasonable thing to do. There's a term for this: the normalization of deviance. It's well studied in a number of other contexts including healthcare, aviation, mechanical engineering, aerospace engineering, and civil engineering, but we don't see it discussed in the context of software. In fact, I've never seen the term used in the context of software.&lt;/p&gt;&lt;p&gt;Is it possible to learn from other's mistakes instead of making every mistake ourselves? The state of the industry make this sound unlikely, but let's give it a shot. John Banja has a nice summary paper on the normalization of deviance in healthcare, with lessons we can attempt to apply to software development. One thing to note is that, because Banja is concerned with patient outcomes, there's a close analogy to devops failure modes, but normalization of deviance also occurs in cultural contexts that are less directly analogous.&lt;/p&gt;&lt;p&gt;The first section of the paper details a number of disasters, both in healthcare and elsewhere. Here's one typical example:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;A catastrophic negligence case that the author participated in as an expert witness involved an anesthesiologist's turning off a ventilator at the request of a surgeon who wanted to take an x-ray of the patient's abdomen (Banja, 2005, pp. 87-101). The ventilator was to be off for only a few seconds, but the anesthesiologist forgot to turn it back on, or thought he turned it back on but had not. The patient was without oxygen for a long enough time to cause her to experience global anoxia, which plunged her into a vegetative state. She never recovered, was disconnected from artificial ventilation 9 days later, and then died 2 days after that. It was later discovered that the anesthesia alarms and monitoring equipment in the operating room had been deliberately programmed to a “suspend indefinite” mode such that the anesthesiologist was not alerted to the ventilator problem. Tragically, the very instrumentality that was in place to prevent such a horror was disabled, possibly because the operating room staff found the constant beeping irritating and annoying.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Turning off or ignoring notifications because there are too many of them and they're too annoying? An erroneous manual operation? This could be straight out of the post-mortem of more than a few companies I can think of, except that the result was a tragic death instead of the loss of millions of dollars. If you read a lot of tech post-mortems, every example in Banja's paper will feel familiar even though the details are different.&lt;/p&gt;&lt;p&gt;The section concludes,&lt;/p&gt;&lt;quote&gt;&lt;p&gt;What these disasters typically reveal is that the factors accounting for them usually had “long incubation periods, typified by rule violations, discrepant events that accumulated unnoticed, and cultural beliefs about hazards that together prevented interventions that might have staved off harmful outcomes”. Furthermore, it is especially striking how multiple rule violations and lapses can coalesce so as to enable a disaster's occurrence.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Once again, this could be from an article about technical failures. That makes the next section, on why these failures happen, seem worth checking out. The reasons given are:&lt;/p&gt;&lt;p&gt;The example in the paper is about delivering medication to newborns. To prevent “drug diversion,” nurses were required to enter their password onto the computer to access the medication drawer, get the medication, and administer the correct amount. In order to ensure that the first nurse wasn't stealing drugs, if any drug remained, another nurse was supposed to observe the process, and then enter their password onto the computer to indicate they witnessed the drug being properly disposed of.&lt;/p&gt;&lt;p&gt;That sounds familiar. How many technical postmortems start off with “someone skipped some steps because they're inefficient”, e.g., “the programmer force pushed a bad config or bad code because they were sure nothing could go wrong and skipped staging/testing”? The infamous November 2014 Azure outage happened for just that reason. At around the same time, a dev at one of Azure's competitors overrode the rule that you shouldn't push a config that fails tests because they knew that the config couldn't possibly be bad. When that caused the canary deploy to start failing, they overrode the rule that you can't deploy from canary into staging with a failure because they knew their config couldn't possibly be bad and so the failure must be from something else. That postmortem revealed that the config was technically correct, but exposed a bug in the underlying software; it was pure luck that the latent bug the config revealed wasn't as severe as the Azure bug.&lt;/p&gt;&lt;p&gt;Humans are bad at reasoning about how failures cascade, so we implement bright line rules about when it's safe to deploy. But the same thing that makes it hard for us to reason about when it's safe to deploy makes the rules seem stupid and inefficient.&lt;/p&gt;&lt;p&gt;People don't automatically know what should be normal, and when new people are onboarded, they can just as easily learn deviant processes that have become normalized as reasonable processes.&lt;/p&gt;&lt;p&gt;Julia Evans described to me how this happens:&lt;/p&gt;&lt;p&gt;new person joins&lt;lb/&gt; new person: WTF WTF WTF WTF WTF&lt;lb/&gt; old hands: yeah we know we're concerned about it&lt;lb/&gt; new person: WTF WTF wTF wtf wtf w...&lt;lb/&gt; new person gets used to it&lt;lb/&gt; new person #2 joins&lt;lb/&gt; new person #2: WTF WTF WTF WTF&lt;lb/&gt; new person: yeah we know. we're concerned about it.&lt;/p&gt;&lt;p&gt;The thing that's really insidious here is that people will really buy into the WTF idea, and they can spread it elsewhere for the duration of their career. Once, after doing some work on an open source project that's regularly broken and being told that it's normal to have a broken build, and that they were doing better than average, I ran the numbers, found that project was basically worst in class, and wrote something about the idea that it's possible to have a build that nearly always passes with relatively low effort. The most common comment I got in response was, "Wow that guy must work with superstar programmers. But let's get real. We all break the build at least a few times a week", as if running tests (or for that matter, even attempting to compile) before checking code in requires superhuman abilities. But once people get convinced that some deviation is normal, they often get really invested in the idea.&lt;/p&gt;&lt;p&gt;The example in the paper is of someone who breaks the rule that you should wear gloves when finding a vein. Their reasoning is that wearing gloves makes it harder to find a vein, which may result in their having to stick a baby with a needle multiple times. It's hard to argue against that. No one wants to cause a baby extra pain!&lt;/p&gt;&lt;p&gt;The second worst outage I can think of occurred when someone noticed that a database service was experiencing slowness. They pushed a fix to the service, and in order to prevent the service degradation from spreading, they ignored the rule that you should do a proper, slow, staged deploy. Instead, they pushed the fix to all machines. It's hard to argue against that. No one wants their customers to have degraded service! Unfortunately, the fix exposed a bug that caused a global outage.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;most human beings perceive themselves as good and decent people, such that they can understand many of their rule violations as entirely rational and ethically acceptable responses to problematic situations. They understand themselves to be doing nothing wrong, and will be outraged and often fiercely defend themselves when confronted with evidence to the contrary.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;As companies grow up, they eventually have to impose security that prevents every employee from being able to access basically everything. And at most companies, when that happens, some people get really upset. “Don't you trust me? If you trust me, how come you're revoking my access to X, Y, and Z?”&lt;/p&gt;&lt;p&gt;Facebook famously let all employees access everyone's profile for a long time, and you can even find HN comments indicating that some recruiters would explicitly mention that as a perk of working for Facebook. And I can think of more than one well-regarded unicorn where everyone still has access to basically everything, even after their first or second bad security breach. It's hard to get the political capital to restrict people's access to what they believe they need, or are entitled, to know. A lot of trendy startups have core values like “trust” and “transparency” which make it difficult to argue against universal access.&lt;/p&gt;&lt;p&gt;There are people I simply don't give feedback to because I can't tell if they'd take it well or not, and once you say something, it's impossible to un-say it. In the paper, the author gives an example of a doctor with poor handwriting who gets mean when people ask him to clarify what he's written. As a result, people guess instead of asking.&lt;/p&gt;&lt;p&gt;In most company cultures, people feel weird about giving feedback. Everyone has stories about a project that lingered on for months or years after it should have been terminated because no one was willing to offer explicit feedback. This is a problem even when cultures discourage meanness and encourage feedback: cultures of niceness seem to have as many issues around speaking up as cultures of meanness, if not more. In some places, people are afraid to speak up because they'll get attacked by someone mean. In others, they're afraid because they'll be branded as mean. It's a hard problem.&lt;/p&gt;&lt;p&gt;In the paper, this is characterized by flaws and weaknesses being diluted as information flows up the chain of command. One example is how a supervisor might take sub-optimal actions to avoid looking bad to superiors.&lt;/p&gt;&lt;p&gt;I was shocked the first time I saw this happen. I must have been half a year or a year out of school. I saw that we were doing something obviously non-optimal, and brought it up with the senior person in the group. He told me that he didn't disagree, but that if we did it my way and there was a failure, it would be really embarrassing. He acknowledged that my way reduced the chance of failure without making the technical consequences of failure worse, but it was more important that we not be embarrassed. Now that I've been working for a decade, I have a better understanding of how and why people play this game, but I still find it absurd.&lt;/p&gt;&lt;p&gt;Let's say you notice that your company has a problem that I've heard people at most companies complain about: people get promoted for heroism and putting out fires, not for preventing fires; and people get promoted for shipping features, not for doing critical maintenance work and bug fixing. How do you change that?&lt;/p&gt;&lt;p&gt;The simplest option is to just do the right thing yourself and ignore what's going on around you. That has some positive impact, but the scope of your impact is necessarily limited. Next, you can convince your team to do the right thing: I've done that a few times for practices I feel are really important and are sticky, so that I won't have to continue to expend effort on convincing people once things get moving.&lt;/p&gt;&lt;p&gt;But if the incentives are aligned against you, it will require an ongoing and probably unsustainable effort to keep people doing the right thing. In that case, the problem becomes convincing someone to change the incentives, and then making sure the change works as designed. How to convince people is worth discussing, but long and messy enough that it's beyond the scope of this post. As for making the change work, I've seen many “obvious” mistakes repeated, both in places I've worked and those whose internal politics I know a lot about.&lt;/p&gt;&lt;p&gt;Small companies have it easy. When I worked at a 100 person company, the hierarchy was individual contributor (IC) -&amp;gt; team lead (TL) -&amp;gt; CEO. That was it. The CEO had a very light touch, but if he wanted something to happen, it happened. Critically, he had a good idea of what everyone was up to and could basically adjust rewards in real-time. If you did something great for the company, there's a good chance you'd get a raise. Not in nine months when the next performance review cycle came up, but basically immediately. Not all small companies do that effectively, but with the right leadership, they can. That's impossible for large companies.&lt;/p&gt;&lt;p&gt;At large company A (LCA), they had the problem we're discussing and a mandate came down to reward people better for doing critical but low-visibility grunt work. There were too many employees for the mandator to directly make all decisions about compensation and promotion, but the mandator could review survey data, spot check decisions, and provide feedback until things were normalized. My subjective perception is that the company never managed to achieve parity between boring maintenance work and shiny new projects, but got close enough that people who wanted to make sure things worked correctly didn't have to significantly damage their careers to do it.&lt;/p&gt;&lt;p&gt;At large company B (LCB), ICs agreed that it's problematic to reward creating new features more richly than doing critical grunt work. When I talked to managers, they often agreed, too. But nevertheless, the people who get promoted are disproportionately those who ship shiny new things. I saw management attempt a number of cultural and process changes at LCB. Mostly, those took the form of pronouncements from people with fancy titles. For really important things, they might produce a video, and enforce compliance by making people take a multiple choice quiz after watching the video. The net effect I observed among other ICs was that people talked about how disconnected management was from the day-to-day life of ICs. But, for the same reasons that normalization of deviance occurs, that information seems to have no way to reach upper management.&lt;/p&gt;&lt;p&gt;It's sort of funny that this ends up being a problem about incentives. As an industry, we spend a lot of time thinking about how to incentivize consumers into doing what we want. But then we set up incentive systems that are generally agreed upon as incentivizing us to do the wrong things, and we do so via a combination of a game of telephone and cargo cult diffusion. Back when Microsoft was ascendant, we copied their interview process and asked brain-teaser interview questions. Now that Google is ascendant, we copy their interview process and ask algorithms questions. If you look around at trendy companies that are younger than Google, most of them basically copy their ranking/leveling system, with some minor tweaks. The good news is that, unlike many companies people previously copied, Google has put a lot of thought into most of their processes and made data driven decisions. The bad news is that Google is unique in a number of ways, which means that their reasoning often doesn't generalize, and that people often cargo cult practices long after they've become deprecated at Google.&lt;/p&gt;&lt;p&gt;This kind of diffusion happens for technical decisions, too. Stripe built a reliable message queue on top of Mongo, so we build reliable message queues on top of Mongo1. It's cargo cults all the way down2.&lt;/p&gt;&lt;p&gt;The paper has specific sub-sections on how to prevent normalization of deviance, which I recommend reading in full.&lt;/p&gt;&lt;p&gt;Let's look at how the first one of these, “pay attention to weak signals”, interacts with a single example, the “WTF WTF WTF” a new person gives off when the join the company.&lt;/p&gt;&lt;p&gt;If a VP decides something is screwed up, people usually listen. It's a strong signal. And when people don't listen, the VP knows what levers to pull to make things happen. But when someone new comes in, they don't know what levers they can pull to make things happen or who they should talk to almost by definition. They give out weak signals that are easily ignored. By the time they learn enough about the system to give out strong signals, they've acclimated.&lt;/p&gt;&lt;p&gt;“Pay attention to weak signals” sure sounds like good advice, but how do we do it? Strong signals are few and far between, making them easy to pay attention to. Weak signals are abundant. How do we filter out the ones that aren't important? And how do we get an entire team or org to actually do it? These kinds of questions can't be answered in a generic way; this takes real thought. We mostly put this thought elsewhere. Startups spend a lot of time thinking about growth, and while they'll all tell you that they care a lot about engineering culture, revealed preference shows that they don't. With a few exceptions, big companies aren't much different. At LCB, I looked through the competitive analysis slide decks and they're amazing. They look at every last detail on hundreds of products to make sure that everything is as nice for users as possible, from onboarding to interop with competing products. If there's any single screen where things are more complex or confusing than any competitor's, people get upset and try to fix it. It's quite impressive. And then when LCB onboards employees in my org, a third of them are missing at least one of, an alias/account, an office, or a computer, a condition which can persist for weeks or months. The competitive analysis slide decks talk about how important onboarding is because you only get one chance to make a first impression, and then employees are onboarded with the impression that the company couldn't care less about them and that it's normal for quotidian processes to be pervasively broken. LCB can't even to get the basics of employee onboarding right, let alone really complex things like acculturation. This is understandable — external metrics like user growth or attrition are measurable, and targets like how to tell if you're acculturating people so that they don't ignore weak signals are softer and harder to determine, but that doesn't mean they're any less important. People write a lot about how things like using fancier languages or techniques like TDD or agile will make your teams more productive, but having a strong engineering culture is much larger force multiplier.&lt;/p&gt;&lt;p&gt;Thanks to Sophie Smithburg and Marc Brooker for introducing me to the term Normalization of Deviance, and Kelly Eskridge, Leah Hanson, Sophie Rapoport, Sophie Smithburg, Julia Evans, Dmitri Kalintsev, Ralph Corderoy, Jamie Brandon, Egor Neliuba, and Victor Felder for comments/corrections/discussion.&lt;/p&gt;&lt;p&gt;People seem to think I'm joking here. I can understand why, but try Googling &lt;code&gt;mongodb message queue&lt;/code&gt;. You'll find statements like “replica sets in MongoDB work extremely well to allow automatic failover and redundancy”. Basically every company I know of that's done this and has anything resembling scale finds this to be non-optimal, to say the least, but you can't actually find blog posts or talks that discuss that. All you see are the posts and talks from when they first tried it and are in the honeymoon period. This is common with many technologies. You'll mostly find glowing recommendations in public even when, in private, people will tell you about all the problems. Today, if you do the search mentioned above, you'll get a ton of posts talking about how amazing it is to build a message queue on top of Mongo, this footnote, and a maybe couple of blog posts by Kyle Kingsbury depending on your exact search terms.&lt;/p&gt;&lt;p&gt;If there were an acute failure, you might see a postmortem, but while we'll do postmortems for "the site was down for 30 seconds", we rarely do postmortems for "this takes 10x as much ops effort as the alternative and it's a death by a thousand papercuts", "we architected this thing poorly and now it's very difficult to make changes that ought to be trivial", or "a competitor of ours was able to accomplish the same thing with an order of magnitude less effort". I'll sometimes do informal postmortems by asking everyone involved oblique questions about what happened, but more for my own benefit than anything else, because I'm not sure people really want to hear the whole truth. This is especially sensitive if the effort has generated a round of promotions, which seems to be more common the more screwed up the project. The larger the project, the more visibility and promotions, even if the project could have been done with much less effort.&lt;/p&gt;[return]&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://danluu.com/wat/"/></entry><entry><id>https://news.ycombinator.com/item?id=45152063</id><title>Historical Housing Prices Project</title><updated>2025-09-06T21:07:49.937246+00:00</updated><content>&lt;doc fingerprint="55deed986fd9cc96"&gt;
  &lt;main&gt;
    &lt;p&gt;Housing impacts individual economic well-being, influences wealth-building opportunities, and is vital to the overall economy. Despite the critical importance of housing to the U.S. economy, existing long-run housing price series are limited, particularly covering the years before 1970.&lt;/p&gt;
    &lt;p&gt;The Historical Housing Prices (HHP) Project, now housed at the Philadelphia Fed, began with support from the National Science Foundation (SES-1918554), the Lincoln Institute of Land Policy, and Trinity College in Dublin, with principal investigators Allison Shertzer (now at the Philadelphia Fed), Ronan C. Lyons (Trinity College Dublin), and Rowena Gray (University of California, Merced). (The Philadelphia Fed did not receive funding from external funders in connection with this project.)&lt;/p&gt;
    &lt;p&gt;As part of our efforts to ensure a strong overall economy, the Philadelphia Fed identifies housing-related issues and informs solutions. This project aims to bring new data on the price of housing over the long run to inform research and policymaking.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.philadelphiafed.org/surveys-and-data/regional-economic-analysis/historical-housing-prices"/></entry><entry><id>https://news.ycombinator.com/item?id=45152066</id><title>How the "Kim" dump exposed North Korea's credential theft playbook</title><updated>2025-09-06T21:07:49.463369+00:00</updated><content>&lt;doc fingerprint="3599949f0a828e4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Inside the Kimsuky Leak: How the “Kim” Dump Exposed North Korea’s Credential Theft Playbook&lt;/head&gt;
    &lt;p&gt;Contents:&lt;lb/&gt;Part I: Technical Analysis&lt;lb/&gt;Part II: Goals Analysis&lt;lb/&gt;Part III: Threat Intelligence Report&lt;/p&gt;
    &lt;head rend="h2"&gt;Executive Summary&lt;/head&gt;
    &lt;p&gt;A rare and revealing breach attributed to a North Korean-affiliated actor, known only as “Kim” as named by the hackers who dumped the data, has delivered a new insight into Kimsuky (APT43) tactics, techniques, and infrastructure. This actor’s operational profile showcases credential-focused intrusions targeting South Korean and Taiwanese networks, with a blending of Chinese-language tooling, infrastructure, and possible logistical support. The “Kim” dump, which includes bash histories, phishing domains, OCR workflows, compiled stagers, and rootkit evidence, reflects a hybrid operation situated between DPRK attribution and Chinese resource utilization.&lt;/p&gt;
    &lt;p&gt;This report is broken down into three parts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Technical Analysis of the dump materials&lt;/item&gt;
      &lt;item&gt;Motivation and Goals of the APT actor (group)&lt;/item&gt;
      &lt;item&gt;A CTI report compartment for analysts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While this leak only gives a partial idea of what the Kimusky/PRC activities have been, the material provides insight into the expansion of activities, nature of the actor(s), and goals they have in their penetration of the South Korean governmental systems that would benefit not only DPRK, but also PRC.&lt;/p&gt;
    &lt;p&gt;Without a doubt, there will be more coming out from this dump in the future, particularly if the burned assets have not been taken offline and access is still available, or if others have cloned those assets for further analysis. We may revisit this in the future if additional novel information comes to light.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part I: Technical Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;The Leak at a Glance&lt;/head&gt;
    &lt;p&gt;The leaked dataset attributed to the “Kim” operator offers a uniquely operational perspective into North Korean-aligned cyber operations. Among the contents were terminal history files revealing active malware development efforts using NASM (Netwide Assembler), a choice consistent with low-level shellcode engineering typically reserved for custom loaders and injection tools. These logs were not static forensic artifacts but active command-line histories showing iterative compilation and cleanup processes, suggesting a hands-on attacker directly involved in tool assembly.&lt;/p&gt;
    &lt;p&gt;In parallel, the operator ran OCR (Optical Character Recognition) commands against sensitive Korean PDF documents related to public key infrastructure (PKI) standards and VPN deployments. These actions likely aimed to extract structured language or configurations for use in spoofing, credential forgery, or internal tool emulation.&lt;/p&gt;
    &lt;p&gt;Privileged Access Management (PAM) logs also surfaced in the dump, detailing a timeline of password changes and administrative account use. Many were tagged with the Korean string 변경완료 (“change complete”), and the logs included repeated references to elevated accounts such as oracle, svradmin, and app_adm01, indicating sustained access to critical systems.&lt;/p&gt;
    &lt;p&gt;The phishing infrastructure was extensive. Domain telemetry pointed to a network of malicious sites designed to mimic legitimate Korean government portals. Sites like nid-security[.]com were crafted to fool users into handing over credentials via advanced AiTM (Adversary-in-the-Middle) techniques.&lt;/p&gt;
    &lt;p&gt;Finally, network artifacts within the dump showed targeted reconnaissance of Taiwanese government and academic institutions. Specific IP addresses and .tw domain access, along with attempts to crawl .git repositories, reveal a deliberate focus on high-value administrative and developer targets.&lt;/p&gt;
    &lt;p&gt;Perhaps most concerning was the inclusion of a Linux rootkit using syscall hooking (khook) and stealth persistence via directories like /usr/lib64/tracker-fs. This highlights a capability for deep system compromise and covert command-and-control operations, far beyond phishing and data theft.&lt;/p&gt;
    &lt;p&gt;Artifacts recovered from the dump include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Terminal history files demonstrating malware compilation using NASM&lt;/item&gt;
      &lt;item&gt;OCR commands parsing Korean PDF documents related to PKI and VPN infrastructure&lt;/item&gt;
      &lt;item&gt;PAM logs reflecting password changes and credential lifecycle events&lt;/item&gt;
      &lt;item&gt;Phishing infrastructure mimicking Korean government sites&lt;/item&gt;
      &lt;item&gt;IP addresses indicating reconnaissance of Taiwanese government and research institutions&lt;/item&gt;
      &lt;item&gt;Linux rootkit code using syscall hooking and covert channel deployment&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Credential Theft Focus&lt;/head&gt;
    &lt;p&gt;The dump strongly emphasizes credential harvesting as a central operational goal. Key files such as 136백운규001_env.key (The presence of 136백운규001_env.key is a smoking gun indicator of stolen South Korean Government PKI material, as its structure (numeric ID + Korean name + .key) aligns uniquely with SK GPKI issuance practices and provides clear evidence of compromised, identity-tied state cryptographic keys.) This was discovered alongside plaintext passwords, that indicate clear evidence of active compromise of South Korea’s GPKI (Government Public Key Infrastructure). Possession of such certificates would allow for highly effective identity spoofing across government systems.&lt;/p&gt;
    &lt;p&gt;PAM logs further confirmed this focus, showing a pattern of administrative account rotation and password resets, all timestamped and labeled with success indicators (변경완료: Change Complete). The accounts affected were not low-privilege; instead, usernames like oracle, svradmin, and app_adm01, often used by IT staff and infrastructure services, suggested access to core backend environments.&lt;/p&gt;
    &lt;p&gt;These findings point to a strategy centered on capturing and maintaining access to privileged credentials and digital certificates, effectively allowing the attacker to act as an insider within trusted systems.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leaked .key files (e.g., 136백운규001_env.key) with plaintext passwords confirm access to GPKI systems&lt;/item&gt;
      &lt;item&gt;PAM logs show administrative password rotations tagged with 변경완료 (change complete)&lt;/item&gt;
      &lt;item&gt;Admin-level accounts such as oracle, svradmin, and app_adm01 repeatedly appear in compromised logs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Phishing Infrastructure&lt;/head&gt;
    &lt;p&gt;The operator’s phishing infrastructure was both expansive and regionally tailored. Domains such as nid-security[.]com and webcloud-notice[.]com mimicked Korean identity and document delivery services, likely designed to intercept user logins or deploy malicious payloads. More sophisticated spoofing was seen in sites that emulated official government agencies like dcc.mil[.]kr, spo.go[.]kr, and mofa.go[.]kr.&lt;/p&gt;
    &lt;p&gt;Burner email usage added another layer of operational tradecraft. The address jeder97271[@]wuzak[.]com is likely linked to phishing kits that operated through TLS proxies, capturing credentials in real time as victims interacted with spoofed login forms.&lt;/p&gt;
    &lt;p&gt;These tactics align with previously known Kimsuky behaviors but also demonstrate an evolution in technical implementation, particularly the use of AiTM interception rather than relying solely on credential-harvesting documents.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Domains include: nid-security[.]com, html-load[.]com, webcloud-notice[.]com, koala-app[.]com, and wuzak[.]com&lt;/item&gt;
      &lt;item&gt;Mimicked portals: dcc.mil[.]kr, spo.go[.]kr, mofa.go[.]kr&lt;/item&gt;
      &lt;item&gt;Burner email evidence: jeder97271[@]wuzak[.]com&lt;/item&gt;
      &lt;item&gt;Phishing kits leveraged TLS proxies for AiTM credential capture&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Malware Development Activity&lt;/head&gt;
    &lt;p&gt;Kim’s malware development environment showcased a highly manual, tailored approach. Shellcode was compiled using NASM, specifically with flags like -f win32, revealing a focus on targeting Windows environments. Commands such as make and rm were used to automate and sanitize builds, while hashed API call resolution (VirtualAlloc, HttpSendRequestA, etc.) was implemented to evade antivirus heuristics.&lt;/p&gt;
    &lt;p&gt;The dump also revealed reliance on GitHub repositories known for offensive tooling. TitanLdr, minbeacon, Blacklotus, and CobaltStrike-Auto-Keystore were all cloned or referenced in command logs. This hybrid use of public frameworks for private malware assembly is consistent with modern APT workflows.&lt;/p&gt;
    &lt;p&gt;A notable technical indicator was the use of the proxyres library to extract Windows proxy settings, particularly via functions like proxy_config_win_get_auto_config_url. This suggests an interest in hijacking or bypassing network-level security controls within enterprise environments.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manual shellcode compilation via nasm -f win32 source/asm/x86/start.asm&lt;/item&gt;
      &lt;item&gt;Use of make, rm, and hash obfuscation of Win32 API calls (e.g., VirtualAlloc, HttpSendRequestA)&lt;/item&gt;
      &lt;item&gt;GitHub tools in use: TitanLdr, minbeacon, Blacklotus, CobaltStrike-Auto-Keystore&lt;/item&gt;
      &lt;item&gt;Proxy configuration probing through proxyres library (proxy_config_win_get_auto_config_url)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Rootkit Toolkit and Implant Structure&lt;/head&gt;
    &lt;p&gt;The Kim dump offers deep insight into a stealthy and modular Linux rootkit attributed to the operator’s post-compromise persistence tactics. The core implant, identified as vmmisc.ko (alternatively VMmisc.ko in some shells), was designed for kernel-mode deployment across multiple x86_64 Linux distributions and utilizes classic syscall hooking and covert channeling to maintain long-term undetected access.&lt;/p&gt;
    &lt;head rend="h3"&gt;Google Translation of Koh doc: Rootkit Endpoint Reuse Authentication Tool&lt;/head&gt;
    &lt;p&gt;“This tool uses kernel-level rootkit hiding technology, providing a high degree of stealth and penetration connection capability. It can hide while running on common Linux systems, and at the kernel layer supports connection forwarding, allowing reuse of external ports to connect to controlled hosts. Its communication behavior is hidden within normal traffic.&lt;/p&gt;
    &lt;p&gt;The tool uses binary merging technology: at compile time, the application layer program is encrypted and fused into a .ko driver file. When installed, only the .ko file exists. When the .ko driver starts, it will automatically decompress and release the hidden application-layer program.&lt;/p&gt;
    &lt;p&gt;Tools like chkrootkit, rkhunter, and management utilities (such as ps, netstat, etc.) are bypassed through technical evasion and hiding, making them unable to detect hidden networks, ports, processes, or file information.&lt;/p&gt;
    &lt;p&gt;To ensure software stability, all functions have also passed stress testing.&lt;/p&gt;
    &lt;p&gt;Supported systems: Linux Kernel 2.6.x / 3.x / 4.x, both x32 and x64 systems”.&lt;/p&gt;
    &lt;p&gt;Implant Features and Behavior&lt;/p&gt;
    &lt;p&gt;This rootkit exhibits several advanced features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syscall Hooking: Hooks critical kernel functions (e.g., getdents, read, write) to hide files, directories, and processes by name or PID.&lt;/item&gt;
      &lt;item&gt;SOCKS5 Proxy: Integrated remote networking capability using dynamic port forwarding and chained routing.&lt;/item&gt;
      &lt;item&gt;PTY Backdoor Shell: Spawns pseudoterminals that operate as interactive reverse shells with password protection.&lt;/item&gt;
      &lt;item&gt;Encrypted Sessions: Session commands must match a pre-set passphrase (e.g., testtest) to activate rootkit control mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once installed (typically using insmod vmmisc.ko), the rootkit listens silently and allows manipulation via an associated client binary found in the dump. The client supports an extensive set of interactive commands, including:&lt;/p&gt;
    &lt;p&gt;+p # list hidden processes&lt;/p&gt;
    &lt;p&gt;+f # list hidden files&lt;/p&gt;
    &lt;p&gt;callrk # load client ↔ kernel handshake&lt;/p&gt;
    &lt;p&gt;exitrk # gracefully unload implant&lt;/p&gt;
    &lt;p&gt;shell # spawn reverse shell&lt;/p&gt;
    &lt;p&gt;socks5 # initiate proxy channel&lt;/p&gt;
    &lt;p&gt;upload / download # file transfer interface&lt;/p&gt;
    &lt;p&gt;These capabilities align closely with known DPRK malware behaviors, particularly from the Kimsuky and Lazarus groups, who have historically leveraged rootkits for lateral movement, stealth, persistence, and exfiltration staging.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observed Deployment&lt;/head&gt;
    &lt;p&gt;Terminal history (.bash_history) shows the implant was staged and tested from the following paths:&lt;/p&gt;
    &lt;code&gt;.cache/vmware/drag_and_drop/VMmisc.ko

/usr/lib64/tracker-fs/vmmisc.ko

Execution logs show the use of commands such as:

insmod /usr/lib64/tracker-fs/vmmisc.ko

./client 192.168.0[.]39 testtest&lt;/code&gt;
    &lt;p&gt;These paths were not random—they mimic legitimate system service locations to avoid detection by file integrity monitoring (FIM) tools.&lt;/p&gt;
    &lt;p&gt;This structure highlights the modular, command-activated nature of the implant and its ability to serve multiple post-exploitation roles while maintaining stealth through kernel-layer masking.&lt;/p&gt;
    &lt;head rend="h2"&gt;Strategic Implications&lt;/head&gt;
    &lt;p&gt;The presence of such an advanced toolkit in the “Kim” dump strongly suggests the actor had persistent access to Linux server environments, likely via credential compromise. The use of kernel-mode implants also indicates long-term intent and trust-based privilege escalation. The implant’s pathing, language patterns, and tactics (e.g., use of /tracker-fs/, use of test passwords) match TTPs previously observed in operations attributed to Kimsuky, enhancing confidence in North Korean origin.&lt;/p&gt;
    &lt;head rend="h2"&gt;OCR-Based Recon&lt;/head&gt;
    &lt;p&gt;A defining component of Kim’s tradecraft was the use of OCR to analyze Korean-language security documentation. The attacker issued commands such as ocrmypdf -l kor+eng “file.pdf” to parse documents like 별지2)행정전자서명_기술요건_141125.pdf (“Appendix 2: Administrative Electronic Signature_Technical Requirements_141125.pdf”) and SecuwaySSL U_카달로그.pdf (“SecuwaySSL U_Catalog.pdf”). These files contain technical language around digital signatures, SSL implementations, and identity verification standards used in South Korea’s PKI infrastructure.&lt;/p&gt;
    &lt;p&gt;This OCR-based collection approach indicates more than passive intelligence gathering – it reflects a deliberate effort to model and potentially clone government-grade authentication systems. The use of bilingual OCR (Korean + English) further confirms the operator’s intention to extract usable configuration data across documentation types.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OCR commands used to extract Korean PKI policy language from PDFs such as (별지2)행정전자서명_기술요건_141125.pdf and SecuwaySSL U_카달로그.pdf &lt;list rend="ul"&gt;&lt;item&gt;별지2)행정전자서명_기술요건_141125.pdf → (Appendix 2: Administrative Electronic Signature_Technical Requirements_141125.pdf&lt;/item&gt;&lt;item&gt;SecuwaySSL U_카달로그.pdf → SecuwaySSL U_Catalog.pdf&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Command examples: ocrmypdf -l kor+eng “file.pdf”&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;SSH and Log-Based Evidence&lt;/head&gt;
    &lt;p&gt;The forensic evidence contained within the logs, specifically SSH authentication records and PAM outputs, provides clear technical confirmation of the operator’s tactics and target focus.&lt;/p&gt;
    &lt;p&gt;Several IP addresses stood out as sources of brute-force login attempts. These include 23.95.213[.]210 (a known VPS provider used in past credential-stuffing campaigns), 218.92.0[.]210 (allocated to a Chinese ISP), and 122.114.233[.]77 (Henan Mobile, China). These IPs were recorded during multiple failed login events, strongly suggesting automated password attacks against exposed SSH services. Their geographic distribution and known history in malicious infrastructure usage point to an external staging environment, possibly used for pivoting into Korean and Taiwanese systems.&lt;/p&gt;
    &lt;p&gt;Beyond brute force, the logs also contain evidence of authentication infrastructure reconnaissance. Multiple PAM and OCSP (Online Certificate Status Protocol) errors referenced South Korea’s national PKI authority, including domains like gva.gpki.go[.]kr and ivs.gpki.go[.]kr. These errors appear during scripted or automated access attempts, indicating a potential strategy of credential replay or certificate misuse against GPKI endpoints, an approach that aligns with Kim’s broader PKI-targeting operations.&lt;/p&gt;
    &lt;p&gt;Perhaps the most revealing detail was the presence of successful superuser logins labeled with the Korean term 최고 관리자 (“Super Administrator”). This suggests the actor was not just harvesting credentials but successfully leveraging them for privileged access, possibly through cracked accounts, reused credentials, or insider-sourced passwords. The presence of such accounts in conjunction with password rotation entries marked as 변경완료 (“change complete”) further implies active control over PAM-protected systems during the operational window captured in the dump.&lt;/p&gt;
    &lt;p&gt;Together, these logs demonstrate a methodical campaign combining external brute-force access, PKI service probing, and administrative credential takeover, a sequence tailored for persistent infiltration and lateral movement within sensitive government and enterprise networks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Brute-force IPs: 23.95.213[.]210, 218.92.0[.]210, 122.114.233[.]77&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;IP Address&lt;/cell&gt;
        &lt;cell&gt;Origin&lt;/cell&gt;
        &lt;cell&gt;Role / Threat Context&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;218.92.0[.]210&lt;/cell&gt;
        &lt;cell&gt;China Telecom (Jiangsu)&lt;/cell&gt;
        &lt;cell&gt;Part of Chinanet backbone, likely proxy or scanning node&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;23.95.213[.]210&lt;/cell&gt;
        &lt;cell&gt;Colocrossing (US)&lt;/cell&gt;
        &lt;cell&gt;Frequently used in brute-force and anonymized hosting for malware ops&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;122.114.233[.]77&lt;/cell&gt;
        &lt;cell&gt;Presumed PRC local ISP&lt;/cell&gt;
        &lt;cell&gt;Possibly mobile/ISP-based proxy used to obfuscate lateral movement&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PAM/OCSP errors targeting gva.gpki.go[.]kr, ivs.gpki.go[.]kr&lt;/item&gt;
      &lt;item&gt;Superuser login events under 최고 관리자 (Super Administrator)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Part II: Goals Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;Targeting South Korea: Identity, Infrastructure, and Credential Theft&lt;/head&gt;
    &lt;p&gt;The “Kim” operator’s campaign against South Korea was deliberate and strategic, aiming to infiltrate the nation’s digital trust infrastructure at multiple levels. A central focus was the Government Public Key Infrastructure (GPKI), where the attacker exfiltrated certificate files, including .key and .crt formats, some with plaintext passwords, and attempted repeated authentication against domains like gva.gpki.go[.]kr and ivs.gpki.go[.]kr. OCR tools were used to parse Korean technical documents detailing PKI and VPN architectures, demonstrating a sophisticated effort to understand and potentially subvert national identity frameworks. These efforts were not limited to reconnaissance; administrative password changes were logged, and phishing kits targeted military and diplomatic webmail, including clones of mofa.go[.]kr and credential harvesting through adversary-in-the-middle (AiTM) proxy setups.&lt;/p&gt;
    &lt;p&gt;Beyond authentication systems, Kim targeted privileged accounts (oracle, unwadm, svradmin) and rotated credentials to maintain persistent administrative access, as evidenced by PAM and SSH logs showing elevated user activity under the title 최고 관리자 (“Super Administrator”). The actor also showed interest in bypassing VPN controls, parsing SecuwaySSL configurations for exploitation potential, and deployed custom Linux rootkits using syscall hooking to establish covert persistence on compromised machines. Taken together, the dump reveals a threat actor deeply invested in credential dominance, policy reconnaissance, and system-level infiltration, placing South Korea’s public sector identity systems, administrative infrastructure, and secure communications at the core of its long-term espionage objectives.&lt;/p&gt;
    &lt;head rend="h2"&gt;Taiwan Reconnaissance&lt;/head&gt;
    &lt;p&gt;Among the most notable aspects of the “Kim” leak is the operator’s deliberate focus on Taiwanese infrastructure. The attacker accessed a number of domains with clear affiliations to the island’s public and private sectors, including tw.systexcloud[.]com (linked to enterprise cloud solutions), mlogin.mdfapps[.]com (a mobile authentication or enterprise login portal), and the .git/ directory of caa.org[.]tw, which belongs to the Chinese Institute of Aeronautics, a government-adjacent research entity.&lt;/p&gt;
    &lt;p&gt;This last domain is especially telling. Accessing .git/ paths directly implies an attempt to enumerate internal source code repositories, a tactic often used to discover hardcoded secrets, API keys, deployment scripts, or developer credentials inadvertently exposed via misconfigured web servers. This behavior points to more technical depth than simple phishing; it indicates supply chain reconnaissance and long-term infiltration planning.&lt;/p&gt;
    &lt;p&gt;The associated IP addresses further reinforce this conclusion. All three, 163.29.3[.]119, 118.163.30[.]45, and 59.125.159[.]81, are registered to academic, government, or research backbone providers in Taiwan. These are not random scans; they reflect targeted probing of strategic digital assets.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary of Whois &amp;amp; Ownership Insights&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;118.163.30[.]45 &lt;list rend="ul"&gt;&lt;item&gt;Appears as part of the IP range used for the domain dtc-tpe.com[.]tw, linked to Taiwan’s HINET provider (118.163.30[.]46 )Site Indices page of HINET provider.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;163.29.3[.]119 &lt;list rend="ul"&gt;&lt;item&gt;Falls within the 163.29.3[.]0/24 subnet identified with Taiwanese government or institutional use, notably in Taipei. This corresponds to B‑class subnets assigned to public/government entities IP地址 (繁體中文).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;59.125.159[.]81&lt;list rend="ul"&gt;&lt;item&gt;Belongs to the broader 59.125.159[.]0–59.125.159[.]254 block, commonly used by Taiwanese ISP operators such as Chunghwa Telecom in Taipei&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taken together, this Taiwan-focused activity reveals an expanded operational mandate. Whether the attacker is purely DPRK-aligned or operating within a DPRK–PRC fusion cell, the intent is clear: compromise administrative and developer infrastructure in Taiwan, likely in preparation for broader credential theft, espionage, or disruption campaigns.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Targeted domains: tw.systexcloud[.]com, caa.org[.]tw/.git/, mlogin.mdfapps[.]com&lt;/item&gt;
      &lt;item&gt;IPs linked to Taiwanese academic/government assets: 163.29.3[.]119, 118.163.30[.]45, 59.125.159[.]81&lt;/item&gt;
      &lt;item&gt;Git crawling suggests interest in developer secrets or exposed tokens&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Hybrid Attribution Model&lt;/head&gt;
    &lt;p&gt;The “Kim” operator embodies the growing complexity of modern nation-state attribution, where cyber activities often blur traditional boundaries and merge capabilities across geopolitical spheres. This case reveals strong indicators of both North Korean origin and Chinese operational entanglement, presenting a textbook example of a hybrid APT model.&lt;/p&gt;
    &lt;p&gt;On one hand, the technical and linguistic evidence strongly supports a DPRK-native operator. Terminal environments, OCR parsing routines, and system artifacts consistently leverage Korean language and character sets. The operator’s activities reflect a deep understanding of Korean PKI systems, with targeted extraction of GPKI .key files and automation to parse sensitive Korean government PDF documentation. These are hallmarks of Kimsuky/APT43 operations, known for credential-focused espionage against South Korean institutions and diplomatic targets. The intent to infiltrate identity infrastructure is consistent with North Korea’s historical targeting priorities. Notably, the system time zone on Kim’s host machine was set to UTC+9 (Pyongyang Standard Time), reinforcing the theory that the actor maintains direct ties to the DPRK’s internal environment, even if operating remotely.&lt;/p&gt;
    &lt;p&gt;However, this actor’s digital footprint extends well into Chinese infrastructure. Browser and download logs reveal frequent interaction with platforms like gitee[.]com, baidu[.]com, and zhihu[.]com, highly popular within the PRC but unusual for DPRK operators who typically minimize exposure to foreign services. Moreover, session logs include simplified Chinese content and PRC browsing behaviors, suggesting that the actor may be physically operating within China or through Chinese-language systems. This aligns with longstanding intelligence on North Korean cyber operators stationed in Chinese border cities such as Shenyang and Dandong, where DPRK nationals often conduct cyber operations with tacit approval or logistical consent from Chinese authorities. These locations provide higher-speed internet, relaxed oversight, and convenient geopolitical proximity.&lt;/p&gt;
    &lt;p&gt;The targeting of Taiwanese infrastructure further complicates attribution. Kimsuky has not historically prioritized Taiwan, yet in this case, the actor demonstrated direct reconnaissance of Taiwanese government and developer networks. While this overlaps with Chinese APT priorities, recent evidence from the “Kim” dump, including analysis of phishing kits and credential theft workflows, suggests this activity was likely performed by a DPRK actor exploring broader regional interests, possibly in alignment with Chinese strategic goals. Researchers have noted that Kimsuky operators have recently asked questions in phishing lures related to potential Chinese-Taiwanese conflicts, implying interest beyond the Korean peninsula.&lt;/p&gt;
    &lt;p&gt;Some tooling overlaps with PRC-linked APTs, particularly GitHub-based stagers and proxy-resolving modules, but these are not uncommon in the open-source malware ecosystem and may reflect opportunistic reuse rather than deliberate mimicry.&lt;/p&gt;
    &lt;head rend="h2"&gt;IMINT Analysis: Visual Tradecraft and Cultural Camouflage&lt;/head&gt;
    &lt;p&gt;A review of image artifacts linked to the “Kim” actor reveals a deliberate and calculated use of Chinese social and technological visual content as part of their operational persona. These images, extracted from browser history and uploads attributed to the actor, demonstrate both strategic alignment with DPRK priorities and active cultural camouflage within the PRC digital ecosystem.&lt;/p&gt;
    &lt;p&gt;The visual set includes promotional graphics for Honor smartphones, SoC chipset evolution charts, Weibo posts featuring vehicle registration certificates, meme-based sarcasm, and lifestyle imagery typical of Chinese internet users. Notably, the content is exclusively rendered in simplified Chinese, reinforcing prior assessments that the operator either resides within mainland China or maintains a working digital identity embedded in Chinese platforms. Devices and services referenced, such as Xiaomi phones, Zhihu, Weibo, and Baidu, suggest intimate familiarity with PRC user environments.&lt;/p&gt;
    &lt;p&gt;Operationally, this behavior achieves two goals. First, it enables the actor to blend in seamlessly with native PRC user activity, which complicates attribution and helps bypass platform moderation or behavioral anomaly detection. Second, the content itself may serve as bait or credibility scaffolding (e.g. A framework to give the illusion of trust to allow for easier compromise ) in phishing and social engineering campaigns, especially those targeting developers or technical users on Chinese-language platforms.&lt;/p&gt;
    &lt;p&gt;Some images, such as the detailed chipset timelines and VPN or device certification posts, suggest a continued interest in supply chain reconnaissance and endpoint profiling—both tradecraft hallmarks of Kimsuky and similar APT units. Simultaneously, meme humor, sarcastic overlays, and visual metaphors (e.g., the “Kaiju’s tail is showing” idiom) indicate the actor’s fluency in PRC netizen culture and possible mockery of operational security breaches—whether their own or others’.&lt;/p&gt;
    &lt;p&gt;Taken together, this IMINT corpus supports the broader attribution model: a DPRK-origin operator embedded, physically or virtually, within the PRC, leveraging local infrastructure and social platforms to facilitate long-term campaigns against South Korea, Taiwan, and other regional targets while maintaining cultural and technical deniability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Attribution Scenarios:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Option A: DPRK Operator Embedded in PRC&lt;list rend="ul"&gt;&lt;item&gt;Use of Korean language, OCR targeting of Korean documents, and focus on GPKI systems strongly suggest North Korean origin.&lt;/item&gt;&lt;item&gt;Use of PRC infrastructure (e.g., Baidu, Gitee) and simplified Chinese content implies the operator is physically located in China or benefits from access to Chinese internet infrastructure.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Use of Korean language, OCR targeting of Korean documents, and focus on GPKI systems strongly suggest North Korean origin.&lt;/item&gt;
      &lt;item&gt;Option B: PRC Operator Emulating DPRK&lt;list rend="ul"&gt;&lt;item&gt;Taiwan-focused reconnaissance aligns with PRC cyber priorities.&lt;/item&gt;&lt;item&gt;Use of open-source tooling and phishing methods shared with PRC APTs could indicate tactical emulation.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Taiwan-focused reconnaissance aligns with PRC cyber priorities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The preponderance of evidence supports the hypothesis that “Kim” is a North Korean cyber operator embedded in China or collaborating with PRC infrastructure providers. This operational model allows the DPRK to amplify its reach, mask attribution, and adopt regional targeting strategies beyond South Korea, particularly toward Taiwan. As this hybrid model matures, it reflects the strategic adaptation of DPRK-aligned threat actors who exploit the permissive digital environment of Chinese networks to evade detection and expand their operational playbook.&lt;/p&gt;
    &lt;head rend="h2"&gt;Targeting Profiles&lt;/head&gt;
    &lt;p&gt;The “Kim” leak provides one of the clearest windows to date into the role-specific targeting preferences of the operator, revealing a deliberate focus on system administrators, credential issuers, and backend developers, particularly in South Korea and Taiwan.&lt;/p&gt;
    &lt;p&gt;In South Korea, the operator’s interest centers around PKI administrators and infrastructure engineers. The recovered OCR commands were used to extract technical details from PDF documents outlining Korea’s digital signature protocols, such as identity verification, certificate validation, and encrypted communications, components that form the backbone of Korea’s secure authentication systems. The goal appears to be not only credential theft but full understanding and potential replication of government-trusted PKI procedures. This level of targeting suggests a strategic intent to penetrate deeply trusted systems, potentially for use in later spoofing or identity masquerading operations.&lt;/p&gt;
    &lt;p&gt;In Taiwan, the operator shifted focus to developer infrastructure and cloud access portals. Specific domains accessed, like caa.org[.]tw/.git/, indicate attempts to enumerate internal repositories, most likely to discover hardcoded secrets, authentication tokens, or deployment keys. This is a classic supply chain targeting method, aiming to access downstream systems via compromised developer credentials or misconfigured services.&lt;/p&gt;
    &lt;p&gt;Additional activity pointed to interaction with cloud service login panels such as tw.systexcloud[.]com and mlogin.mdfapps[.]com. These suggest an attempt to breach centralized authentication systems or identity providers, granting the actor broader access into enterprise or government networks with a single credential set.&lt;/p&gt;
    &lt;p&gt;Taken together, these targeting profiles reflect a clear emphasis on identity providers, backend engineers, and those with access to system-level secrets. This reinforces the broader theme of the dump: persistent, credential-first intrusion strategies, augmented by reconnaissance of authentication standards, key management policies, and endpoint development infrastructure.&lt;/p&gt;
    &lt;p&gt;South Korean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PKI admins, infrastructure engineers&lt;/item&gt;
      &lt;item&gt;OCR focus on Korean identity standards&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taiwanese:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Developer endpoints and internal .git/ repos&lt;/item&gt;
      &lt;item&gt;Access to cloud panels and login gateways&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Final Assessment&lt;/head&gt;
    &lt;p&gt;The “Kim” leak represents one of the most comprehensive and technically intimate disclosures ever associated with Kimsuky (APT43) or its adjacent operators. It not only reaffirms known tactics, credential theft, phishing, and PKI compromise, but exposes the inner workings of the operator’s environment, tradecraft, and operational intent in ways rarely observed outside of active forensic investigations.&lt;/p&gt;
    &lt;p&gt;At the core of the leak is a technically competent actor, well-versed in low-level shellcode development, Linux-based persistence mechanisms, and certificate infrastructure abuse. Their use of NASM, API hashing, and rootkit deployment points to custom malware authorship. Furthermore, the presence of parsed government-issued Korean PDFs, combined with OCR automation, shows not just opportunistic data collection but a concerted effort to model, mimic, or break state-level identity systems, particularly South Korea’s GPKI.&lt;/p&gt;
    &lt;p&gt;The operator’s cultural and linguistic fluency in Korean, and their targeting of administrative and privileged systems across South Korean institutions, support a high-confidence attribution to a DPRK-native threat actor. However, the extensive use of Chinese platforms like gitee[.]com, Baidu, and Zhihu, and Chinese infrastructure for both malware hosting and browsing activity reveals a geographical pivot or collaboration: a hybrid APT footprint rooted in DPRK tradecraft but operating from or with Chinese support.&lt;/p&gt;
    &lt;p&gt;Most notably, this leak uncovers a geographical expansion of operational interest; the actor is no longer solely focused on the Korean peninsula. The targeting of Taiwanese developer portals, government research IPs, and .git/ repositories shows a broadened agenda that likely maps to both espionage and supply chain infiltration priorities. This places Taiwan, like South Korea, at the forefront of North Korean cyber interest, whether for intelligence gathering, credential hijacking, or as staging points for more complex campaigns.&lt;/p&gt;
    &lt;p&gt;The threat uncovered here is not merely malware or phishing; it is an infrastructure-centric, credential-first APT campaign that blends highly manual operations (e.g., hand-compiled shellcode, direct OCR of sensitive PDFs) with modern deception tactics such as AiTM phishing and TLS proxy abuse.&lt;/p&gt;
    &lt;p&gt;Organizations in Taiwan and South Korea, particularly those managing identity, certificate, and cloud access infrastructure, should consider themselves under persistent, credential-focused surveillance. Defensive strategies must prioritize detection of behavioral anomalies (e.g., use of OCR tools, GPKI access attempts), outbound communications with spoofed Korean domains, and the appearance of low-level toolchains like NASM or proxyres-based scanning utilities within developer or admin environments.&lt;/p&gt;
    &lt;p&gt;In short: the “Kim” actor embodies the evolution of nation-state cyber threats—a fusion of old-school persistence, credential abuse, and modern multi-jurisdictional staging. The threat is long-term, embedded, and adaptive.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part III: Threat Intelligence Report&lt;/head&gt;
    &lt;head rend="h2"&gt;TLP WHITE:&lt;/head&gt;
    &lt;head rend="h3"&gt;Targeting Summary&lt;/head&gt;
    &lt;p&gt;The analysis of the “Kim” operator dump reveals a highly focused credential-theft and infrastructure-access campaign targeting high-value assets in both South Korea and Taiwan. Victims were selected based on their proximity to trusted authentication systems, administrative control panels, and development environments.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Category&lt;/cell&gt;
        &lt;cell&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Regions&lt;/cell&gt;
        &lt;cell&gt;South Korea, Taiwan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Targets&lt;/cell&gt;
        &lt;cell&gt;Government, Telecom, Enterprise IT&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Accounts&lt;/cell&gt;
        &lt;cell&gt;svradmin, oracle, app_adm01, unwadm, shkim88, jaejung91&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Domains&lt;/cell&gt;
        &lt;cell&gt;tw.systexcloud[.]com, nid-security[.]com, spo.go[.]kr, caa.org[.]tw/.git/&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Indicators of Compromise (IOCs)&lt;/head&gt;
    &lt;head rend="h4"&gt;Domains&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Phishing: nid-security[.]com, html-load[.]com, wuzak[.]com, koala-app[.]com, webcloud-notice[.]com&lt;/item&gt;
      &lt;item&gt;Spoofed portals: dcc.mil[.]kr, spo.go[.]kr, mofa.go[.]kr&lt;/item&gt;
      &lt;item&gt;Pastebin raw links: Used for payload staging and malware delivery&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;IP Addresses&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Targets (Taiwan): &lt;list rend="ul"&gt;&lt;item&gt;163.29.3[.]119 National Center for High-performance Computing&lt;/item&gt;&lt;item&gt;118.163.30[.]45 Taiwanese government subnet&lt;/item&gt;&lt;item&gt;59.125.159[.]81 Chunghwa Telecom&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Brute Forcing / Infrastructure Origins: &lt;list rend="ul"&gt;&lt;item&gt;23.95.213[.]210 VPS provider with malicious history&lt;/item&gt;&lt;item&gt;218.92.0[.]210 China Unicom&lt;/item&gt;&lt;item&gt;122.114.233[.]77 Henan Mobile, PRC&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Internal Host IPs (Operator Environment)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;192.168.130[.]117&lt;/item&gt;
      &lt;item&gt;192.168.150[.]117&lt;/item&gt;
      &lt;item&gt;192.168.0[.]39&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Operator Environment: Internal Host IP Narrative&lt;/head&gt;
    &lt;p&gt;The presence of internal IP addresses such as 192.168.130[.]117, 192.168.150[.]117, and 192.168.0[.]39 within the dump offers valuable insight into the attacker’s local infrastructure, an often-overlooked element in threat intelligence analysis. These addresses fall within private, non-routable RFC1918 address space, commonly assigned by consumer off-the-shelf (COTS) routers and small office/home office (SOHO) network gear.&lt;/p&gt;
    &lt;p&gt;The use of the 192.168.0[.]0/16 subnet, particularly 192.168.0.x and 192.168.150.x, strongly suggests that the actor was operating from a residential or low-profile environment, not a formal nation-state facility or hardened infrastructure. This supports existing assessments that North Korean operators, particularly those affiliated with Kimsuky, often work remotely from locations in third countries such as China or Southeast Asia, where they can maintain inconspicuous, low-cost setups while accessing global infrastructure.&lt;/p&gt;
    &lt;p&gt;Moreover, the distinction between multiple internal subnets (130.x, 150.x, and 0.x) may indicate segmentation of test environments or multiple virtual machines running within a single NATed network. This aligns with the forensic evidence of iterative development and testing workflows seen in the .bash_history files, where malware stagers, rootkits, and API obfuscation utilities were compiled, cleaned, and rerun repeatedly.&lt;/p&gt;
    &lt;p&gt;Together, these IPs reveal an operator likely working from a clandestine, residential base of operations, with modest hardware and commercial-grade routers. This operational setup is consistent with known DPRK remote IT workers and cyber operators who avoid attribution by blending into civilian infrastructure. It also suggests the attacker may be physically located outside of North Korea, possibly embedded in a friendly or complicit environment, strengthening the case for China-based activity by DPRK nationals.&lt;/p&gt;
    &lt;head rend="h3"&gt;MITRE ATT&amp;amp;CK Mapping&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Phase&lt;/cell&gt;
        &lt;cell&gt;Technique(s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Initial Access&lt;/cell&gt;
        &lt;cell&gt;T1566.002 , Adversary-in-the-Middle (AiTM) Phishing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Execution&lt;/cell&gt;
        &lt;cell&gt;T1059.005 , Native API ShellcodeT1059.003 , Bash/Shell Scripts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Credential Access&lt;/cell&gt;
        &lt;cell&gt;T1555 , Credential Store DumpingT1557.003 , Session Hijacking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Persistence&lt;/cell&gt;
        &lt;cell&gt;T1176 , Rootkit (via khook syscall manipulation)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Defense Evasion&lt;/cell&gt;
        &lt;cell&gt;T1562.001 , Disable Security ToolsT1552 , Unsecured Credential Files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Discovery&lt;/cell&gt;
        &lt;cell&gt;T1592 , Technical Information DiscoveryT1590 , Network Information&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Exfiltration&lt;/cell&gt;
        &lt;cell&gt;T1041 , Exfiltration over C2 ChannelT1567.002 , Exfil via Cloud Services&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Tooling and Capabilities&lt;/head&gt;
    &lt;p&gt;The actor’s toolkit spans multiple disciplines, blending malware development, system reconnaissance, phishing, and proxy evasion:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NASM-based shellcode loaders: Compiled manually for Windows execution.&lt;/item&gt;
      &lt;item&gt;Win32 API hashing: Obfuscated imports via hashstring.py to evade detection.&lt;/item&gt;
      &lt;item&gt;GitHub/Gitee abuse: Tooling hosted or cloned from public developer platforms.&lt;/item&gt;
      &lt;item&gt;OCR exploitation: Used ocrmypdf to parse Korean PDF specs related to digital certificates and VPN appliances.&lt;/item&gt;
      &lt;item&gt;Rootkit deployment: Hidden persistence paths including /usr/lib64/tracker-fs and /proc/acpi/pcicard.&lt;/item&gt;
      &lt;item&gt;Proxy config extraction: Investigated PAC URLs using proxyres-based recon.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Attribution Confidence Assessment&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Attribution Candidate&lt;/cell&gt;
        &lt;cell&gt;Confidence Level&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;DPRK-aligned (Kimsuky)&lt;/cell&gt;
        &lt;cell&gt;High, Native Korean targeting, GPKI focus, OCR behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;China-blended infrastructure&lt;/cell&gt;
        &lt;cell&gt;Moderate, PRC hosting, Gitee usage, Taiwan focus&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Solely PRC Actor&lt;/cell&gt;
        &lt;cell&gt;Low-to-Moderate, Tooling overlap but weak linguistic match&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Assessment: The actor appears to be a DPRK-based APT operator working from within or in partnership with Chinese infrastructure, representing a hybrid attribution model.&lt;/p&gt;
    &lt;head rend="h3"&gt;Defensive Recommendations&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Area&lt;/cell&gt;
        &lt;cell&gt;Recommendation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;PKI Security&lt;/cell&gt;
        &lt;cell&gt;Monitor usage of .key, .sig, .crt artifacts; enforce HSM or 2FA for key use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Phishing Defense&lt;/cell&gt;
        &lt;cell&gt;Block domains identified in IoCs; validate TLS fingerprints and referrer headers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Endpoint Hardening&lt;/cell&gt;
        &lt;cell&gt;Detect use of nasm, make, and OCR tools; monitor /usr/lib*/tracker-* paths&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Network Telemetry&lt;/cell&gt;
        &lt;cell&gt;Alert on .git/ directory access from external IPs; monitor outbound to Pastebin/GitHub&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Taiwan Focus&lt;/cell&gt;
        &lt;cell&gt;Establish watchlists for .tw domains targeted by PRC-originating IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Admin Accounts&lt;/cell&gt;
        &lt;cell&gt;Review usage logs for svradmin, oracle, app_adm01, and ensure rotation policies&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h1"&gt;APPENDIX A&lt;/head&gt;
    &lt;head rend="h2"&gt;Overlap or Confusion with Chinese Threat Actors&lt;/head&gt;
    &lt;p&gt;There is notable evidence of operational blur between Kimsuky and Chinese APTs in the context of Taiwan. The 2025 “Kim” data breach revealed an attacker targeting Taiwan whose tools and phishing kits matched Kimsuky’s, yet whose personal indicators (language, browsing habits) suggested a Chinese national. Researchers concluded this actor was likely a Chinese hacker either mimicking Kimsuky tactics or collaborating with them.. In fact, the leaked files on DDoS Secrets hint that Kimsuky has “openly cooperated with other Chinese APTs and shared their tools and techniques”. This overlap can cause attribution confusion – a Taiwan-focused operation might initially be blamed on China but could involve Kimsuky elements, or vice versa. So far, consensus is that North Korean and Chinese cyber operations remain separate, but cases like “Kim” show how a DPRK-aligned actor can operate against Taiwan using TTPs common to Chinese groups, muddying the waters of attribution.&lt;/p&gt;
    &lt;head rend="h2"&gt;File List from dump:&lt;/head&gt;
    &lt;head rend="h2"&gt;Master Evidence Inventory:&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;File Name&lt;/cell&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;Content Summary&lt;/cell&gt;
        &lt;cell&gt;Category&lt;/cell&gt;
        &lt;cell&gt;Relevance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;.bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;Operator shell history commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Shows rootkit compilation, file ops, network tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;user-bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;User-level shell commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Development and test activity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;root-bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;Root-level shell commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Privilege-level activity, implant deployment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;auth.log.2&lt;/cell&gt;
        &lt;cell&gt;EN/KR&lt;/cell&gt;
        &lt;cell&gt;Authentication logs (PAM/SSH)&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Credential changes marked 변경완료, brute force IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;20190315.log&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;System log file&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Auth and system access events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;chrome-timeline.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Browser activity timeline&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Visited domains extraction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;chromehistory.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Browser history export&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;URLs visited&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;history.sqlite&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty DB file&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No useful data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Media History&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty SQLite DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No playback activity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;History&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty Brave/Chromium DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No visited URLs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Web Data&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Autofill/search DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Search engines used (Google, DuckDuckGo, Qwant, Startpage, Ecosia)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Visited Links&lt;/cell&gt;
        &lt;cell&gt;Binary&lt;/cell&gt;
        &lt;cell&gt;LevelDB/binary structure&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Could not extract URLs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Cookies&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;SQLite DB with cookies&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Google cookies found&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;request_log.txt.20250220&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Captured phishing session&lt;/cell&gt;
        &lt;cell&gt;Phishing&lt;/cell&gt;
        &lt;cell&gt;Spoofed spo.go.kr, base64 credential logging&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;技术说明书 – 22.docx&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese rootkit stealth manual&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Kernel hiding, binary embedding&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1.ko 图文编译 .doc&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese compilation guide&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Rootkit build process&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1. build ko .txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Build notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Implant compilation instructions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;0. 使用.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Usage notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Implant usage and commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;re 正向工具修改建议 1.0.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Modification notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Reverse tool modification suggestions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1111.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Rootkit/tool snippet&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Part of implant notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;client&lt;/cell&gt;
        &lt;cell&gt;Binary&lt;/cell&gt;
        &lt;cell&gt;Rootkit client binary&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Controller for implant communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SSA_AO_AD_WT_002_웹보안 프로토콜설계서_Ver1.0_.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;GPKI protocol design doc&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;Korean web PKI standards&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;행자부 웹보안API 인수인계.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;GPKI API deployment manual&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;Deployment and cert API internals&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HIRA-IR-T02_의약품처방조제_ComLibrary_통신전문.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;Medical ComLibrary XML spec&lt;/cell&gt;
        &lt;cell&gt;Healthcare&lt;/cell&gt;
        &lt;cell&gt;Prescription system communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;(별지2)행정전자서명_기술요건_141125.pdf&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;PKI requirements PDF&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;OCR target&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SecuwaySSL U_카달로그.pdf&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;VPN catalog&lt;/cell&gt;
        &lt;cell&gt;PKI/VPN&lt;/cell&gt;
        &lt;cell&gt;OCR target&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;phrack-apt-down-the-north-korea-files.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Phrack article&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Background on Kimsuky dump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Muddled Libra Threat Assessment.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Threat intel report&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Comparative threat actor study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Leaked North Korean Linux Stealth Rootkit Analysis.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Rootkit analysis&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Detailed implant study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Inside the Kimsuky Leak.docx (various)&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Threat report drafts&lt;/cell&gt;
        &lt;cell&gt;Report&lt;/cell&gt;
        &lt;cell&gt;Working versions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;account (2).txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;DB export (DBsafer, TrustedOrange)&lt;/cell&gt;
        &lt;cell&gt;Infra&lt;/cell&gt;
        &lt;cell&gt;Accounts and DB changes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;result.txt&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;Cert-related parsed data&lt;/cell&gt;
        &lt;cell&gt;Infra&lt;/cell&gt;
        &lt;cell&gt;Included GPKI .key/.sig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;english_wikipedia.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Wikipedia dump&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Unrelated baseline&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;bookmarks-2021-01-04.jsonlz4&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Firefox bookmarks (compressed)&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Needs decompression&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Screenshot translations&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese text (rootkit marketing blurb)&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Kernel hiding tool description&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dti.domaintools.com/inside-the-kimsuky-leak-how-the-kim-dump-exposed-north-koreas-credential-theft-playbook/"/></entry><entry><id>https://news.ycombinator.com/item?id=45152086</id><title>Show HN: Greppers – fast CLI cheat sheet with instant copy and shareable search</title><updated>2025-09-06T21:07:49.200065+00:00</updated><content>&lt;doc fingerprint="a1eadbd093f5fba9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop Googling the same command twice.&lt;/head&gt;
    &lt;p&gt;A tiny, blazing‑fast directory of CLI commands with copy‑ready examples. Offline friendly. No BS.&lt;/p&gt;
    &lt;p&gt;Try:&lt;/p&gt;
    &lt;head rend="h2"&gt;Built for speed and memory.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instant search: Runs entirely in your browser.&lt;/item&gt;
      &lt;item&gt;Copy‑to‑clipboard: One click, no ceremony.&lt;/item&gt;
      &lt;item&gt;Opinionated examples: Real‑world flags and patterns.&lt;/item&gt;
      &lt;item&gt;Keyboard first: / focuses search, ↑↓ navigate, ⏎ copies.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.greppers.com/"/></entry><entry><id>https://news.ycombinator.com/item?id=45152369</id><title>Europe enters the exascale supercomputing league with Jupiter</title><updated>2025-09-06T21:07:48.585073+00:00</updated><link href="https://ec.europa.eu/commission/presscorner/detail/en/ip_25_2029"/></entry><entry><id>https://news.ycombinator.com/item?id=45152403</id><title>How Often Do Health Insurers Say No to Patients? No One Knows</title><updated>2025-09-06T21:07:48.169911+00:00</updated><content>&lt;doc fingerprint="ee9a0a917a53c507"&gt;
  &lt;main&gt;
    &lt;p&gt;It’s one of the most crucial questions people have when deciding which health plan to choose: If my doctor orders a test or treatment, will my insurer refuse to pay for it?&lt;/p&gt;
    &lt;p&gt;After all, an insurance company that routinely rejects recommended care could damage both your health and your finances. The question becomes ever more pressing as many working Americans see their premiums rise as their benefits shrink.&lt;/p&gt;
    &lt;p&gt;Yet, how often insurance companies say no is a closely held secret. There’s nowhere that a consumer or an employer can go to look up all insurers’ denial rates — let alone whether a particular company is likely to decline to pay for procedures or drugs that its plans appear to cover.&lt;/p&gt;
    &lt;p&gt;The lack of transparency is especially galling because state and federal regulators have the power to fix it, but haven’t.&lt;/p&gt;
    &lt;p&gt;ProPublica, in collaboration with The Capitol Forum, has been examining the hidden world of insurance denials. A previous story detailed how one of the nation’s largest insurers flagged expensive claims for special scrutiny; a second story showed how a different top insurer used a computer program to bulk-deny claims for some common procedures with little or no review.&lt;/p&gt;
    &lt;p&gt;The findings revealed how little consumers know about the way their claims are reviewed — and denied — by the insurers they pay to cover their medical costs.&lt;/p&gt;
    &lt;p&gt;When ProPublica set out to find information on insurers’ denial rates, we hit a confounding series of roadblocks.&lt;/p&gt;
    &lt;p&gt;In 2010, federal regulators were granted expansive authority through the Affordable Care Act to require that insurers provide information on their denials. This data could have meant a sea change in transparency for consumers. But more than a decade later, the federal government has collected only a fraction of what it’s entitled to. And what information it has released, experts say, is so crude, inconsistent and confusing that it’s essentially meaningless.&lt;/p&gt;
    &lt;p&gt;The national group for state insurance commissioners gathers a more detailed, reliable trove of information. Yet, even though commissioners’ primary duty is to protect consumers, they withhold nearly all of these details from the public. ProPublica requested the data from every state’s insurance department, but none provided it.&lt;/p&gt;
    &lt;p&gt;Two states collect their own information on denials and make it public, but their data covers only a tiny subset of health plans serving a small number of people.&lt;/p&gt;
    &lt;p&gt;The minuscule amount of details available about denials robs consumers of a vital tool for comparing health plans.&lt;/p&gt;
    &lt;p&gt;“This is life and death for people: If your insurance won’t cover the care you need, you could die,” said Karen Pollitz, a senior fellow at KFF (formerly known as the Kaiser Family Foundation) who has written repeatedly about the issue. “It’s all knowable. It’s known to the insurers, but it is not known to us.”&lt;/p&gt;
    &lt;p&gt;The main trade groups for health insurance companies, AHIP (formerly known as America’s Health Insurance Plans) and the Blue Cross Blue Shield Association, say the industry supports transparency and complies with government disclosure requirements. Yet the groups have often argued against expanding this reporting, saying the burdens it would impose on insurance companies would outweigh the benefits for consumers.&lt;/p&gt;
    &lt;p&gt;“Denial rates are not directly comparable from one health plan to another and could lead consumers to make inaccurate conclusions on the robustness of the health plan,” Kelly Parsons, director of media relations for the Blue Cross Blue Shield Association, said in an email.&lt;/p&gt;
    &lt;p&gt;The trade groups stress that a substantial majority of patient claims are approved and that there can be good reasons — including errors and incomplete information from doctors — for some to be denied.&lt;/p&gt;
    &lt;p&gt;“More abstract data about percentages of claims that are approved or denied have no context and are not a reliable indicator of quality — it doesn’t address why a claim was or was not approved, what happened after the claim was not approved the first time, or how a patient or their doctor can help ensure a claim will be approved,” AHIP spokesperson Kristine Grow said in a written response to questions from ProPublica. “Americans deserve information and data that has relevance to their own personal health and circumstances.”&lt;/p&gt;
    &lt;p&gt;The limited government data available suggests that, overall, insurers deny between 10% and 20% of the claims they receive. Aggregate numbers, however, shed no light on how denial rates may vary from plan to plan or across types of medical services.&lt;/p&gt;
    &lt;p&gt;Some advocates say insurers have a good reason to dodge transparency. Refusing payment for medical care and drugs has become a staple of their business model, in part because they know customers appeal less than 1% of denials, said Wendell Potter, who oversaw Cigna’s communications team for more than a decade before leaving the industry in 2008 to become a consumer advocate.&lt;/p&gt;
    &lt;p&gt;“That’s money left on the table that the insurers keep,” he said.&lt;/p&gt;
    &lt;p&gt;At least one insurer disputes this. Potter’s former employer, Cigna, said in an email that his “unsubstantiated opinions” don’t reflect the company’s business model. In a separate written statement, Cigna said it passes on the money it saves “by lowering the cost of health care services and reducing wasteful spending” to the employers who hire it to administer their plans or insure their workers.&lt;/p&gt;
    &lt;p&gt;The few morsels insurers have served up on denials stand in stark contrast to the avalanche of information they’ve divulged in recent years on other fronts, often in response to government mandates. Starting last year, for example, insurers began disclosing the prices they’ve negotiated to pay medical providers for most services.&lt;/p&gt;
    &lt;p&gt;Experts say it’ll take similar mandates to make insurers cough up information on denials, in part because they fear plans with low denial rates would be a magnet for people who are already ailing.&lt;/p&gt;
    &lt;p&gt;“Health plans would never do that voluntarily, would give you what their claim denial rates are, because they don’t want to attract sicker people,” said Mila Kofman, who leads the District of Columbia’s Affordable Care Act exchange and previously served as Maine’s superintendent of insurance.&lt;/p&gt;
    &lt;p&gt;About 85% of people with insurance who responded to a recent KFF survey said they want regulators to compel insurers to disclose how often they deny claims. Pollitz, who co-authored a report on the survey, is a cancer survivor who vividly recalls her own experiences with insurance denials.&lt;/p&gt;
    &lt;p&gt;“Sometimes it would just make me cry when insurance would deny a claim,” she said. “It was like, ‘I can’t deal with this now, I’m throwing up, I just can’t deal with this.’”&lt;/p&gt;
    &lt;p&gt;She should have been able to learn how her plan handled claims for cancer treatment compared with other insurers, she said.&lt;/p&gt;
    &lt;p&gt;“There could be much more accountability.”&lt;/p&gt;
    &lt;p&gt;In September 2009, amid a roiling national debate over health care, the California Nurses Association made a startling announcement: Three of the state’s six largest health insurers had each denied 30% or more of the claims submitted to them in the first half of the year.&lt;/p&gt;
    &lt;p&gt;California insurers instantly said the figures were misleading, inflated by claims submitted in error or for patients ineligible for coverage.&lt;/p&gt;
    &lt;p&gt;But beyond the unexpectedly high numbers, the real surprise was that the nurses association was able to figure out the plans’ denial rates at all, by using information researchers found on the California Department of Managed Health Care’s website.&lt;/p&gt;
    &lt;p&gt;At the time, no other state or federal regulatory agency was collecting or publishing details about how often private insurers denied claims, a 2009 report by the Center for American Progress found.&lt;/p&gt;
    &lt;p&gt;The Affordable Care Act, passed the following year, was a game changer when it came to policing insurers and pushing them to be more transparent.&lt;/p&gt;
    &lt;p&gt;The law took aim at insurers’ practice of excluding people with preexisting conditions, the most flagrant type of denial, and required companies offering plans on the marketplaces created under the law to disclose their prices and detail their benefits.&lt;/p&gt;
    &lt;p&gt;A less-noticed section of the law demanded transparency from a much broader group of insurers about how many claims they turned down, and it put the Department of Health and Human Services in charge of making this information public. The disclosure requirements applied not only to health plans sold on the new marketplaces but also to the employer plans that cover most Americans.&lt;/p&gt;
    &lt;p&gt;The law’s proponents in the Obama administration said they envisioned a flow of accurate, timely information that would empower consumers and help regulators spot problematic insurers or practices.&lt;/p&gt;
    &lt;p&gt;That’s not what happened.&lt;/p&gt;
    &lt;p&gt;The federal government didn’t start publishing data until 2017 and thus far has only demanded numbers for plans on the federal marketplace known as Healthcare.gov. About 12 million people get coverage from such plans — less than 10% of those with private insurance. Federal regulators say they eventually intend to compel health plans outside the Obamacare exchanges to release details about denials, but so far have made no move to do so.&lt;/p&gt;
    &lt;p&gt;Within the limited universe of Healthcare.gov, KFF’s analyses show that insurers, on average, deny almost 1 in 5 claims and that each year some reject more than 1 in 3.&lt;/p&gt;
    &lt;p&gt;But there are red flags that suggest insurers may not be reporting their figures consistently. Companies’ denial rates vary more than would be expected, ranging from as low as 2% to as high as almost 50%. Plans’ denial rates often fluctuate dramatically from year to year. A gold-level plan from Oscar Insurance Company of Florida rejected 66% of payment requests in 2020, then turned down just 7% in 2021. That insurer’s parent company, Oscar Health, was co-founded by Joshua Kushner, the younger brother of former President Donald Trump’s son-in-law Jared Kushner.&lt;/p&gt;
    &lt;p&gt;An Oscar Health spokesperson said in an email that the 2020 results weren’t a fair reflection of the company’s business “for a variety of reasons,” but wouldn’t say why. “We closely monitor our overall denial rates and they have remained comfortably below 20% over the last few years, including the 2020-2021 time period,” the spokesperson wrote.&lt;/p&gt;
    &lt;p&gt;Experts say they can’t tell if insurers with higher denial rates are counting differently or are genuinely more likely to leave customers without care or stuck with big bills.&lt;/p&gt;
    &lt;p&gt;“It’s not standardized, it’s not audited, it’s not really meaningful,” Peter Lee, the founding executive director of California’s state marketplace, said of the federal government’s information. Data, he added, “should be actionable. This is not by any means right now.”&lt;/p&gt;
    &lt;p&gt;Officials at the Centers for Medicare &amp;amp; Medicaid Services, which collects the denial numbers for the federal government, say they’re doing more to validate them and improve their quality. It’s notable, though, that the agency doesn’t use this data to scrutinize or take action against outliers.&lt;/p&gt;
    &lt;p&gt;“They’re not using it for anything,” Pollitz said.&lt;/p&gt;
    &lt;p&gt;Pollitz has co-authored four reports that call out the data’s shortcomings. An upshot of all of them: Much of what consumers would most want to know is missing.&lt;/p&gt;
    &lt;p&gt;The federal government provides numbers on insurers’ denials of claims for services from what the industry calls “in-network” medical providers, those who have contracts with the insurer. But it doesn’t include claims for care outside those networks. Patients often shoulder more costs for out-of-network services, ramping up the import of these denials.&lt;/p&gt;
    &lt;p&gt;In recent years, doctors and patients have complained bitterly that insurers are requiring them to get approval in advance for an increasing array of services, causing delays and, in some instances, harm. The government, however, hasn’t compelled insurers to reveal how many requests for prior authorization they get or what percent they deny.&lt;/p&gt;
    &lt;p&gt;These and other specifics — particularly about which procedures and treatments insurers reject most — would be necessary to turn the government’s data into a viable tool to help consumers choose health plans, said Eric Ellsworth, the director of health data strategy at Consumers' Checkbook, which designs such tools.&lt;/p&gt;
    &lt;p&gt;A spokesperson for CMS said that, starting in plan year 2024, the agency will require insurers offering federal marketplace plans to submit a few more numbers, including on out-of-network claims, but there’s no timeline yet for much of what advocates say is necessary.&lt;/p&gt;
    &lt;p&gt;Another effort, launched by a different set of federal regulators, illustrates the resistance that government officials encounter when they consider demanding more.&lt;/p&gt;
    &lt;p&gt;The U.S. Department of Labor regulates upwards of 2 million health plans, including many in which employers pay directly for workers’ health care coverage rather than buying it from insurance companies. Roughly two-thirds of American workers with insurance depend on such plans, according to KFF.&lt;/p&gt;
    &lt;p&gt;In July 2016, an arm of the Labor Department proposed rules requiring these plans to reveal a laundry list of never-before-disclosed information, including how many claims they turned down.&lt;/p&gt;
    &lt;p&gt;In addition, the agency said it was considering whether to demand the dollar amount of what the denied care cost, as well as a breakdown of the reasons why plans turned down claims or denied behavioral health services.&lt;/p&gt;
    &lt;p&gt;The disclosures were necessary to “remedy the current failure to collect data about a large sector of the health plan market,” as well as to satisfy mandates in the Affordable Care Act and provide critical information for agency oversight, a Labor Department factsheet said.&lt;/p&gt;
    &lt;p&gt;Trade groups for employers, including retailers and the construction industry, immediately pushed back.&lt;/p&gt;
    &lt;p&gt;The U.S. Chamber of Commerce said complying with the proposal would take an amount of work not justified by “the limited gains in transparency and enforcement ability.” The powerful business group made it sound like having to make the disclosures could spark insurance Armageddon: Employers might cut back benefits or “eliminate health and welfare benefits altogether.”&lt;/p&gt;
    &lt;p&gt;Trade groups for health insurance companies, which often act as administrators for employers that pay directly for workers’ health care, joined with business groups to blast the proposal. The Blue Cross Blue Shield Association called the mandated disclosures “burdensome and expensive.” AHIP questioned whether the Labor Department had the legal authority to collect the data and urged the agency to withdraw the idea “in its entirety.”&lt;/p&gt;
    &lt;p&gt;The proposal also drew opposition from another, less expected quarter: unions. Under some collective bargaining agreements, unions co-sponsor members’ health plans and would have been on the hook for the new reporting requirements, too. The AFL-CIO argued the requirements created a higher standard of disclosure for plans overseen by the Labor Department. To be fair and avoid confusion, the group said, the Labor Department should put its rules on ice until federal health regulators adopted equivalent ones for plans this proposal didn’t cover.&lt;/p&gt;
    &lt;p&gt;That left the transparency push without political champions on the left or the right, former Assistant Secretary of Labor Phyllis Borzi, who ran the part of the agency that tried to compel more disclosure, said in a recent interview.&lt;/p&gt;
    &lt;p&gt;“When you’re up against a united front from the industry, the business community and labor, it’s really hard to make a difference,” she said.&lt;/p&gt;
    &lt;p&gt;By the time the Labor Department stopped accepting feedback, Donald Trump had been elected president.&lt;/p&gt;
    &lt;p&gt;One trade association for large employers pointed out that the Affordable Care Act, which partly drove the new rules, was “a law that the incoming Administration and the incoming leadership of the 115th Congress have vowed to repeal, delay, dismantle, and otherwise not enforce.”&lt;/p&gt;
    &lt;p&gt;The law managed to survive the Trump administration, but the Labor Department’s transparency push didn’t. The agency withdrew its proposal in September 2019.&lt;/p&gt;
    &lt;p&gt;A Labor Department spokesperson said the Biden administration has no immediate plan to revive it.&lt;/p&gt;
    &lt;p&gt;Ultimately, it’s the National Association of Insurance Commissioners, a group for the top elected or appointed state insurance regulators, that has assembled the most robust details about insurance denials.&lt;/p&gt;
    &lt;p&gt;The association’s data encompasses more plans than the federal information, is more consistent and captures more specifics, including numbers of out-of-network denials, information about prior authorizations and denial rates for pharmacy claims. All states except New York and North Dakota participate.&lt;/p&gt;
    &lt;p&gt;Yet, consumers get almost no access. The commissioners’ association only publishes national aggregate statistics, keeping the rest of its cache secret.&lt;/p&gt;
    &lt;p&gt;When ProPublica requested the detailed data from each state’s insurance department, none would hand it over. More than 30 states said insurers had submitted the information under the authority commissioners are granted to examine insurers’ conduct. And under their states’ codes, they said, examination materials must be kept confidential.&lt;/p&gt;
    &lt;p&gt;The commissioners association said state insurance regulators use the information to compare companies, flag outliers and track trends.&lt;/p&gt;
    &lt;p&gt;Birny Birnbaum, a longtime insurance watchdog who serves on the group’s panel of consumer representatives, said the association’s approach reflects how state insurance regulators have been captured by the insurance industry’s demands for secrecy.&lt;/p&gt;
    &lt;p&gt;“Many seem to view their roles as protectors of industry information, as opposed to enforcers of public information laws,” Birnbaum said in an email.&lt;/p&gt;
    &lt;p&gt;Connecticut and Vermont compile their own figures and make them publicly accessible. Connecticut began reporting information on denials first, adding these numbers to its annual insurer report card in 2011.&lt;/p&gt;
    &lt;p&gt;Vermont demands more details, requiring insurers that cover more than 2,000 Vermonters to publicly release prior authorization and prescription drug information that is similar to what the state insurance commissioners collect. Perhaps most usefully, insurers have to separate claims denied because of administrative problems — many of which will be resubmitted and paid — from denials that have “member impact.” These involve services rejected on medical grounds or because they are contractually excluded.&lt;/p&gt;
    &lt;p&gt;Mike Fisher, Vermont’s state health care advocate, said there’s little indication consumers or employers are using the state’s information, but he still thinks the prospect of public scrutiny may have affected insurers’ practices. The most recent data shows Vermont plans had denial rates between 7.7% and 10.26%, considerably lower than the average for plans on Healthcare.gov.&lt;/p&gt;
    &lt;p&gt;“I suspect that’s not a coincidence,” Fisher said. “Shining a light on things helps.”&lt;/p&gt;
    &lt;p&gt;Despite persistent complaints from insurers that Vermont’s requirements are time-consuming and expensive, no insurers have left the state over it. “Certainly not,” said Sebastian Arduengo, who oversees the reporting for the Vermont Department of Financial Regulation.&lt;/p&gt;
    &lt;p&gt;In California, once considered the most transparent state, the Department of Managed Health Care in 2011 stopped requiring insurance carriers to specify how many claims they rejected.&lt;/p&gt;
    &lt;p&gt;A department spokesperson said in an email that the agency follows the requirements in state law, and the law doesn’t require health plans to disclose denials.&lt;/p&gt;
    &lt;p&gt;The state posts reports that flag some plans for failing to pay claims fairly and on time. Consumers can use those to calculate bare-bones denial rates for some insurers, but for others, you’d have to file a public records request to get the details needed to do the math.&lt;/p&gt;
    &lt;p&gt;Despite the struggles of the last 15 years, Pollitz hasn’t given up hope that one day there will be enough public information to rank insurers by their denial rates and compare how reliably they provide different services, from behavioral health to emergency care.&lt;/p&gt;
    &lt;p&gt;“There’s a name and shame function that is possible here,” she said. “It holds some real potential for getting plans to clean up their acts.”&lt;/p&gt;
    &lt;p&gt;Kirsten Berg contributed research. David Armstrong and Patrick Rucker contributed reporting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.propublica.org/article/how-often-do-health-insurers-deny-patients-claims"/></entry><entry><id>https://news.ycombinator.com/item?id=45152569</id><title>Utah's hottest new power source is 15,000 feet below the ground</title><updated>2025-09-06T21:07:47.943756+00:00</updated><content/><link href="https://www.gatesnotes.com/utahs-hottest-new-power-source-is-below-the-ground"/></entry></feed>