<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-17T10:10:17.560168+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46646645</id><title>Cloudflare acquires Astro</title><updated>2026-01-17T10:10:25.331502+00:00</updated><content>&lt;doc fingerprint="7fa05838a90aa8e6"&gt;
  &lt;main&gt;
    &lt;p&gt;The Astro Technology Company — the company behind the Astro web framework — is joining Cloudflare! Adoption of the Astro web framework continues to double every year, and Astro 6 is right around the corner. With Cloudflare’s support, we’ll have more resources and fewer distractions to continue our mission to build the best framework for content-driven websites.&lt;/p&gt;
    &lt;p&gt;What this means for Astro:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Astro stays open-source and MIT-licensed&lt;/item&gt;
      &lt;item&gt;Astro continues to be actively maintained&lt;/item&gt;
      &lt;item&gt;Astro continues to support a wide set of deployment targets, not just Cloudflare&lt;/item&gt;
      &lt;item&gt;Astro’s open governance and current roadmap remain in place.&lt;/item&gt;
      &lt;item&gt;All full-time employees of The Astro Technology Company are now employees of Cloudflare, and will continue to work on Astro full-time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How Astro started&lt;/head&gt;
    &lt;p&gt;In 2021, Astro was born out of frustration. The trend at the time was that every website should be architected as an application, and then shipped to the user’s browser to render. This was not very performant, and we’ve spent the last decade coming up with more and more complex solutions to solve for that performance problem. SSR, ISR, RSC, PPR, TTI optimizations via code-splitting, tree-shaking, lazy-loading, all to generate a blocking double-data hydration payload from a pre-warmed server running halfway around the world.&lt;/p&gt;
    &lt;p&gt;Our mission to design a web framework specifically for building websites — what we call content-driven websites, to better distinguish from data-driven, stateful web applications — resonated. Now Astro is downloaded almost 1,000,000 times per week, and has been used by 100,000s of developers to build fast, beautiful websites. Today you’ll find Astro all over the web, powering major websites and even entire developer platforms for companies like Webflow, Wix, Microsoft, and Google.&lt;/p&gt;
    &lt;p&gt;Along the way, we also tried to grow a business. In 2021 we raised some money and formed The Astro Technology Company. Our larger vision was that a well-designed framework like Astro could sit at the center of a massive developer platform, with optional hosted primitives (database, storage, analytics) designed in lockstep with the framework.&lt;/p&gt;
    &lt;p&gt;We were never able to realize this vision. Attempts to introduce paid, hosted primitives into our ecosystem fell flat, and rarely justified their own existence. We considered going more directly after first-class hosting or content management for Astro, but knew we’d spend much of our time playing catchup to well-funded, savvy competitors. We kept exploring different ideas, but nothing clicked with users the same way Astro did.&lt;/p&gt;
    &lt;p&gt;It wasn’t all bad. Astro DB (our attempt to build a hosted database product for Astro projects) eventually evolved into the open, built-in Astro database client that still lives in core today. Our exploration into building an e-commerce layer with Astro was eventually open-sourced. It was rewarding work, but over the years the distraction took its toll. Each attempt at a new paid product or offering took myself and others on the project away from working on the Astro framework that developers were using and loving every day.&lt;/p&gt;
    &lt;head rend="h2"&gt;Returning to Focus&lt;/head&gt;
    &lt;p&gt;Last year, Dane (Cloudflare CTO) and I began to talk more seriously about the future of the web. Those conversations quickly grew into something bigger: What does the next decade look like? How do frameworks adapt to a world of AI coding and agents?&lt;/p&gt;
    &lt;p&gt;It became clear that even as web technologies evolve, content remains at the center. We realized that we’ve each been working toward this same vision from different angles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cloudflare has been solving it from the infrastructure side: betting on a platform that is global by default, with fast startup, low latency, and security built-in.&lt;/item&gt;
      &lt;item&gt;Astro has been solving it from the framework side: betting on a web framework that makes it easy to build sites that are fast by default, without overcomplicating things.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The overlap is obvious. By working together, Cloudflare gives us the backing we need to keep innovating for our users. Now we can stop spending cycles worrying about building a business on top of Astro, and start focusing 100% on the code, with a shared vision to move the web forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cloudflare ❤️ Astro&lt;/head&gt;
    &lt;p&gt;Cloudflare has been a long-time sponsor and champion of Astro. They have a proven track record of supporting great open-source projects like Astro, TanStack, and Hono without trying to capture or lock anything down. Staying open to all was a non-negotiable requirement for both us and for Cloudflare.&lt;/p&gt;
    &lt;p&gt;That is why Astro will remain free, open-source, and MIT-licensed. We will continue to run our project in the open, with an open governance model for contributors and an open community roadmap that anyone can participate in. We remain fully committed to maintaining Astro as a platform-agnostic framework, meaning we will continue to support and improve deployments for all targets—not just Cloudflare.&lt;/p&gt;
    &lt;p&gt;With Cloudflare’s resources and support, we can now return our focus fully towards building the best web framework for content-driven websites. The web is changing fast, and the bar keeps rising: performance, scale, reliability, and a better experience for the teams shipping content on the web.&lt;/p&gt;
    &lt;p&gt;You’ll see that focus reflected across our roadmap, as we prepare for the upcoming Astro 6 release (beta out now!) and our 2026 roadmap. Stay tuned!&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;I want to extend a huge thank you to the agencies, companies, sponsors, partners, and theme authors who chose to work with us over the years. Thank you to our initial investors — Haystack, Gradient, Uncorrelated, Lightspeed — without whom Astro likely wouldn’t exist. Thank you to everyone in our open source community who continues to help make Astro better every day. And finally, thank you to everyone who uses Astro and puts their trust in us to help them build for the web.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://astro.build/blog/joining-cloudflare/"/><published>2026-01-16T14:25:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46646777</id><title>Cursor's latest “browser experiment” implied success without evidence</title><updated>2026-01-17T10:10:25.170709+00:00</updated><content>&lt;doc fingerprint="a645901deb75300c"&gt;
  &lt;main&gt;
    &lt;p&gt;2026-01-16&lt;/p&gt;
    &lt;head rend="h1"&gt;Cursor's latest "browser experiment" implied success without evidence&lt;/head&gt;
    &lt;p&gt;On January 14th 2026, Cursor published a blog post titled "Scaling long-running autonomous coding" (https://cursor.com/blog/scaling-agents)&lt;/p&gt;
    &lt;p&gt;In the blog post, they talk about their experiments with running "coding agents autonomously for weeks" with the explicit goal of&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;understand[ing] how far we can push the frontier of agentic coding for projects that typically take human teams months to complete&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;They talk about some approaches they tried, why they think those failed, and how to address the difficulties.&lt;/p&gt;
    &lt;p&gt;Finally they arrived at a point where something "solved most of our coordination problems and let us scale to very large projects without any single agent", which then led to this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub (https://github.com/wilsonzlin/fastrender)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never say explicitly.&lt;/p&gt;
    &lt;p&gt;After this, they embed the following video:&lt;/p&gt;
    &lt;p&gt;And below it, they say "While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.".&lt;/p&gt;
    &lt;head rend="h3"&gt;They never actually claim this browser is working and functional&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;error: could not compile 'fastrender' (lib) due to 34 previous errors; 94 warnings emitted&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build.&lt;/p&gt;
    &lt;p&gt;Multiple recent GitHub Actions runs on &lt;code&gt;main&lt;/code&gt; show
failures (including workflow-file errors), and independent build
attempts report dozens of compiler errors, recent PRs were all merged
with failing CI, and going back in the Git history from most recent
commit back 100 commits,&lt;lb/&gt;I couldn't find a single commit that compiled cleanly.&lt;/p&gt;
    &lt;p&gt;I'm not sure what the "agents" they unleashed on this codebase actually did, but they seemingly never ran "cargo build" or even less "cargo check", because both of those commands surface 10s of errors (which surely would balloon should we solve them) and about 100 warnings. There is an open GitHub issue in their repository about this right now: https://github.com/wilsonzlin/fastrender/issues/98&lt;/p&gt;
    &lt;p&gt;And diving into the codebase, if the compilation errors didn't make that clear already, makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality something that surely represents something, but it doesn't have intention behind it, and it doesn't even compile at this point.&lt;/p&gt;
    &lt;p&gt;They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible demo and no known-good revision (tag/release/commit) to verify the screenshots, beyond linking the repo.&lt;/p&gt;
    &lt;p&gt;Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.&lt;/p&gt;
    &lt;p&gt;They finish off the article saying:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Which seems like a really strange conclusion to arrive at, when all they've proved so far, is that agents can output millions of tokens and still not end up with something that actually works.&lt;/p&gt;
    &lt;p&gt;A "browser experiment" doesn't need to rival Chrome. A reasonable minimum bar is: it compiles on a supported toolchain and can render a trivial HTML file. Cursor's post doesn’t demonstrate that bar, and current public build attempts fail at this too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Cursor never says "this browser is production-ready", but they do frame it as "building a web browser from scratch" and "meaningful progress" and then use a screenshot and "extremely difficult" language, wanting to give the impression that this experiment actually was a success.&lt;/p&gt;
    &lt;p&gt;The closest they get to implying that this was a success, is this part:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But this extraordinary claim isn't backed up by any evidence. In the blog post they never provide a working commit, build instructions or even a demo that can be reproduced.&lt;/p&gt;
    &lt;p&gt;I don't think anyone expects this browser to be the next Chrome, but I do think that if you claim you've built a browser, it should at least be able to demonstrate being able to be compiled + loading a basic HTML file at the very least.&lt;/p&gt;
    &lt;head&gt;Versions&lt;/head&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;db6064b&lt;/code&gt; Add link to tested commits&lt;/head&gt;
    &lt;code&gt;@@ -33 +33 @@ And if you try to compile it yourself, you'll see that it's very far away from b

  Multiple recent GitHub Actions runs on `main` show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent PRs were all merged with failing CI, and going back in the Git history from most recent commit back-about

   100 -commits, I
+commits,&amp;lt;br/&amp;gt;[I

   couldn't find a single commit that compiled -cleanly.
+cleanly](https://gist.github.com/embedding-shapes/f5d096dd10be44ff82b6e5ccdaf00b29).&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;3dcd6e7&lt;/code&gt; Fix linebreak typo&lt;/head&gt;
    &lt;code&gt;@@ -9,3 +9 @@ On January 14th 2026, Cursor published a blog post titled "Scaling long-running
-In the blog post, they talk about their experiments with running "coding agents autonomously for weeks"
-
-with the explicit goal of
+In the blog post, they talk about their experiments with running "coding agents autonomously for weeks" with the explicit goal of&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;c74ab74&lt;/code&gt; Fix favicon, fix typos, made better simply&lt;/head&gt;
    &lt;code&gt;@@ -33 +33,3 @@ And below it, they say "While it might seem like a simple screenshot, building a

  And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build.
  Multiple recent GitHub Actions runs on `main` show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent PRs were all merged with failing CI, and going back in the Git history from most recent -commit,
+commit back about 100 commits,

   I couldn't find a single commit that compiled cleanly.@@ -37 +39 @@ I'm not sure what the "agents" they unleashed on this codebase actually did, but

  And diving into the codebase, if the compilation errors didn't make that -sure,
+clear already,

   makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality *something* that surely represents *something*, but it doesn't have intention behind it, and it doesn't even compile at this point.@@ -59 +61 @@ The closest they get to implying that this was a success, is this part:

  But this extraordinary claim isn't backed up by any evidence. In the blog post they never provide a working commit, build instructions or even a demo that can +be
   reproduced.&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;bafc54f&lt;/code&gt; Favicon + changes + cursor video&lt;/head&gt;
    &lt;code&gt;@@ -21 +21 @@ Finally they arrived at a point where something "solved most of our coordination

  This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never -say.
+say explicitly.
@@ -25 +25 @@ After this, they embed the following video:
-[video]
+![](/content/cursor-screenshots.webm)
@@ -33 +33 @@ And below it, they say "While it might seem like a simple screenshot, building a

  And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build. Multiple recent -CI workflow
+GitHub Actions

   runs on `main` -are failing, all the
+show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent

   PRs were +all

   merged with failing CI, and going back in the Git history from most recent commit, I couldn't find a single commit that compiled cleanly.@@ -39 +39,3 @@ And diving into the codebase, if the compilation errors didn't make that sure, m

  They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible -demo/build instructions or
+demo and no

   known-good -commit,
+revision (tag/release/commit) to verify the screenshots,

   beyond linking the repo.
  Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.@@ -46,0 +49,2 @@ Which seems like a really strange conclusion to arrive at, when all they've prov
+A "browser experiment" doesn't need to rival Chrome. A reasonable minimum bar is: it compiles on a supported toolchain and can render a trivial HTML file. Cursor's post doesn’t demonstrate that bar, and current public build attempts fail at this too.
@@ -55 +59 @@ The closest they get to implying that this was a success, is this part:

  But this extraordinary claim isn't backed up by any evidence. -They
+In the blog post they
   never provide a working commit, build instructions or even a demo that can reproduced.&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;d664475&lt;/code&gt; Move&lt;/head&gt;
    &lt;code&gt;@@ -0,0 +1,57 @@
+---
+date: 2026-01-16
+---
+
+# Cursor's latest "browser experiment" implied success without evidence
+
+On January 14th 2026, Cursor published a blog post titled "Scaling long-running autonomous coding" (https://cursor.com/blog/scaling-agents)
+
+In the blog post, they talk about their experiments with running "coding agents autonomously for weeks"
+
+with the explicit goal of
+
+&amp;gt; understand[ing] how far we can push the frontier of agentic coding for projects that typically take human teams months to complete
+
+They talk about some approaches they tried, why they think those failed, and how to address the difficulties.
+
+Finally they arrived at a point where something "solved most of our coordination problems and let us scale to very large projects without any single agent", which then led to this:
+
+&amp;gt; To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub (https://github.com/wilsonzlin/fastrender)
+
+This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never say.
+
+After this, they embed the following video:
+
+[video]
+
+And below it, they say "While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.".
+
+### They never actually claim this browser is working and functional
+
+&amp;gt; error: could not compile 'fastrender' (lib) due to 34 previous errors; 94 warnings emitted
+
+And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build. Multiple recent CI workflow runs on `main` are failing, all the PRs were merged with failing CI, and going back in the Git history from most recent commit, I couldn't find a single commit that compiled cleanly.
+
+I'm not sure what the "agents" they unleashed on this codebase actually did, but they seemingly never ran "cargo build" or even less "cargo check", because both of those commands surface 10s of errors (which surely would balloon should we solve them) and about 100 warnings. There is an open GitHub issue in their repository about this right now: https://github.com/wilsonzlin/fastrender/issues/98
+
+And diving into the codebase, if the compilation errors didn't make that sure, makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality *something* that surely represents *something*, but it doesn't have intention behind it, and it doesn't even compile at this point.
+
+They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible demo/build instructions or known-good commit, beyond linking the repo. Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.
+
+They finish off the article saying:
+
+&amp;gt; But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected.
+
+Which seems like a really strange conclusion to arrive at, when all they've proved so far, is that agents can output millions of tokens and still not end up with something that actually works.
+
+## Conclusion
+
+Cursor never says "this browser is production-ready", but they do frame it as "building a web browser from scratch" and "meaningful progress" and then use a screenshot and "extremely difficult" language, wanting to give the impression that this experiment actually was a success.
+
+The closest they get to implying that this was a success, is this part:
+
+&amp;gt; Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.
+
+But this extraordinary claim isn't backed up by any evidence. They never provide a working commit, build instructions or even a demo that can reproduced.
+
+I don't think anyone expects this browser to be the next Chrome, but I do think that if you claim you've built a browser, it should at least be able to demonstrate being able to be compiled + loading a basic HTML file at the very least.&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://embedding-shapes.github.io/cursor-implied-success-without-evidence/"/><published>2026-01-16T14:37:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46647491</id><title>6-Day and IP Address Certificates Are Generally Available</title><updated>2026-01-17T10:10:24.958052+00:00</updated><content>&lt;doc fingerprint="e659e0db14317484"&gt;
  &lt;main&gt;
    &lt;p&gt;Short-lived and IP address certificates are now generally available from Let’s Encrypt. These certificates are valid for 160 hours, just over six days. In order to get a short-lived certificate subscribers simply need to select the ‘shortlived’ certificate profile in their ACME client.&lt;/p&gt;
    &lt;p&gt;Short-lived certificates improve security by requiring more frequent validation and reducing reliance on unreliable revocation mechanisms. If a certificate’s private key is exposed or compromised, revocation has historically been the way to mitigate damage prior to the certificate’s expiration. Unfortunately, revocation is an unreliable system so many relying parties continue to be vulnerable until the certificate expires, a period as long as 90 days. With short-lived certificates that vulnerability window is greatly reduced.&lt;/p&gt;
    &lt;p&gt;Short-lived certificates are opt-in and we have no plan to make them the default at this time. Subscribers that have fully automated their renewal process should be able to switch to short-lived certificates easily if they wish, but we understand that not everyone is in that position and generally comfortable with this significantly shorter lifetime. We hope that over time everyone moves to automated solutions and we can demonstrate that short-lived certificates work well.&lt;/p&gt;
    &lt;p&gt;Our default certificate lifetimes will be going from 90 days down to 45 days over the next few years, as previously announced.&lt;/p&gt;
    &lt;p&gt;IP address certificates allow server operators to authenticate TLS connections to IP addresses rather than domain names. Let’s Encrypt supports both IPv4 and IPv6. IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important. You can learn more about our IP address certificates and the use cases for them from our post announcing our first IP Certificate.&lt;/p&gt;
    &lt;p&gt;We’d like to thank the Open Technology Fund and Sovereign Tech Agency, along with our Sponsors and Donors, for supporting the development of this work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability"/><published>2026-01-16T15:37:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46648714</id><title>Zep AI (Agent Context Engineering, YC W24) Is Hiring Forward Deployed Engineers</title><updated>2026-01-17T10:10:24.732559+00:00</updated><content>&lt;doc fingerprint="af57259bffd2ec7b"&gt;
  &lt;main&gt;
    &lt;p&gt;Agent Context Is Hard. We Fixed It.&lt;/p&gt;
    &lt;p&gt;Zep assembles the right context from chat history, business data, and user behavior so agents are personalized, accurate, and fast. Our open source project Graphiti hit 20k GitHub stars in under 12 months. Sub-200ms retrieval, SOC 2 Type 2/HIPAA certified, used by teams from startups to Fortune 500s.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/zep-ai/jobs/"/><published>2026-01-16T17:00:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46648885</id><title>Dell UltraSharp 52 Thunderbolt Hub Monitor</title><updated>2026-01-17T10:10:24.278775+00:00</updated><content>&lt;doc fingerprint="e22dab5494a79c42"&gt;
  &lt;main&gt;&lt;p&gt;Selecting will change the following options:&lt;/p&gt;&lt;p&gt;From To&lt;/p&gt;&lt;p&gt;51.5"&lt;/p&gt;&lt;p&gt;6144 x 2560 at 120Hz&lt;/p&gt;&lt;p&gt;In-plane Switching (IPS) Black Technology&lt;/p&gt;&lt;p&gt;99% DCI-P3 (CIE 1976)&lt;/p&gt;&lt;p&gt;100% sRGB (CIE 1931)&lt;/p&gt;...See More See More Color Gamut&lt;p&gt;2 HDMI port/s (HDCP 2.2) (Supports up to 6144 x 2560, 120 Hz, VRR, , as specified in HDMI 2.1 (FRL))&lt;/p&gt;&lt;p&gt;2 DisplayPort 1.4 (HDCP 2.2) port/s&lt;/p&gt;...See More See More Ports&lt;p&gt;Add the products you would like to compare, and quickly determine which is best for your needs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories"/><published>2026-01-16T17:14:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46648916</id><title>East Germany balloon escape</title><updated>2026-01-17T10:10:24.073175+00:00</updated><content>&lt;doc fingerprint="be46c17b47664bf8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;East Germany balloon escape&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Native name&lt;/cell&gt;&lt;cell&gt;Die Ballonflucht&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Date&lt;/cell&gt;&lt;cell&gt;16 September 1979&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Time&lt;/cell&gt;&lt;cell&gt;02:00 am (approximate)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Duration&lt;/cell&gt;&lt;cell&gt;25 minutes&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Location&lt;/cell&gt;&lt;cell&gt;Oberlemnitz, East Germany&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;Naila, West Germany&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Coordinates&lt;/cell&gt;&lt;cell&gt;50°28′59″N 11°35′29″E / 50.48306°N 11.59139°E[1]&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;50°19′52.7″N 11°40′13.1″E / 50.331306°N 11.670306°E[1]&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Organised by&lt;/cell&gt;&lt;cell&gt;Peter Strelzyk &amp;amp; family&lt;p&gt;Günter Wetzel &amp;amp; family&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Participants&lt;/cell&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Outcome&lt;/cell&gt;&lt;cell&gt;Successful escape to West Germany&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Non-fatal injuries&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;On 16 September 1979, eight people from two families escaped from East Germany by crossing the border into West Germany at night in a homemade hot air balloon. The unique feat was the result of over a year and a half of preparations involving three different balloons, various modifications, and a first, unsuccessful attempt. The failed attempt alerted the East German authorities to the plot, but the police were unable to identify the escapees before their second, successful flight two months later.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;[edit]&lt;p&gt;East Germany, then part of the Eastern Bloc, was separated from West Germany in the Western Bloc by the inner German border and the Berlin Wall, which were heavily fortified with watchtowers, land mines, armed soldiers, and various other measures to prevent illegal crossings. East German border troops were instructed to prevent defection to West Germany by all means, including lethal force (Schießbefehl; "order to fire").[2]&lt;/p&gt;&lt;p&gt;Peter Strelzyk (1942–2017), an electrician and former East German Air Force mechanic, and Günter Wetzel (born 1955), a bricklayer by trade,[3] were colleagues at a local plastics factory.[4] Friends for four years, they shared a desire to flee the country and began discussing ways to get across the border. On 7 March 1978, they agreed to plan an escape.[5] They considered building a helicopter but quickly realized they would be unable to acquire an engine capable of powering such a craft. They then decided to explore the idea of constructing a hot air balloon,[6] having been inspired by a television program about ballooning.[3] An alternate account is that a relative shared a magazine article about the International Balloon Festival in Albuquerque, New Mexico.[5]&lt;/p&gt;&lt;head rend="h2"&gt;Construction&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel began research into balloons. Their plan was to escape with their wives and a total of four children (aged 2 to 15). They calculated the weight of the eight passengers and the craft itself to be around 750 kilograms (1,650 lb). Subsequent calculations determined a balloon capable of lifting this weight would need to hold 2,000 cubic metres (71,000 cu ft) of air heated to 100 °C (212 °F). The next calculation was the amount of material needed for the balloon, estimated to be 800 square metres (8,600 sq ft).[6]&lt;/p&gt;&lt;p&gt;The pair lived in Pößneck, a small town of about 20,000 where large quantities of cloth could not be obtained without raising attention. They tried neighbouring towns of Rudolstadt, Saalfeld, and Jena without success.[7] They travelled 50 km (31 mi) to Gera, where they purchased 1-metre-wide (3 ft 3 in) rolls of cotton cloth totalling 850 metres (2,790 ft) in length at a department store after telling the astonished clerk that they needed the large quantity of material to use as tent lining for their camping club.[6][7]&lt;/p&gt;&lt;p&gt;Wetzel spent two weeks sewing the cloth into a balloon-shaped bag, 15 metres (49 ft) wide by 20 metres (66 ft) long, on a 40-year-old manually operated sewing machine. Strelzyk spent the time building the gondola and burner assembly. The gondola was made from an iron frame, sheet metal floor, and clothesline run around the perimeter every 150 millimetres (5.9 in) for the sides. The burner was made using two 11-kilogram (24 lb) bottles of liquid propane household gas, hoses, water pipe, a nozzle, and a piece of stove pipe.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First test&lt;/head&gt;[edit]&lt;p&gt;The team was ready to test the craft in April 1978. After days of searching, they found a suitable secluded forest clearing near Ziegenrück, 10 km (6.2 mi) from the border and 30 km (19 mi) from Pößneck. After lighting the burner one night, they failed to inflate the balloon. They thought the problem might stem from the fact that they had laid the balloon on the ground. After weeks of additional searching, they found a 25-metre (82 ft) cliff at a rock quarry where they could suspend the balloon vertically before inflation, but that also proved unsuccessful.[6]&lt;/p&gt;&lt;p&gt;The pair then decided to fill the bag with ambient-temperature air before using the burner to raise the air temperature and provide lift. They constructed a blower with a 14 hp (10 kW) 250 cc (15 cu in) motorcycle engine taken from Wetzel's old MZ, started with a Trabant automobile starter powered by jumper cables from Strelzyk's Moskvitch sedan.[8] This engine, silenced by a Trabant muffler, turned 1-metre-long (3.3 ft) fan blades to inflate the balloon. They also used a home-made flamethrower, similar to the gondola's burner, to pre-heat the air faster. With these modifications in place, they returned to the secluded clearing to try again but still could not inflate the balloon. But using the blower did allow them to discover that the cotton material with which they fashioned the balloon was too porous and leaked excessively.[6]&lt;/p&gt;&lt;p&gt;Their unsuccessful effort had cost them 2,400 DDM (US$360). Strelzyk disposed of the cloth by burning it in his furnace over several weeks.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Second test&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel purchased samples of different fabrics in local stores, including umbrella material and various samples of taffeta and nylon. They used an oven to test the material for heat resistance. In addition, they created a test rig from a vacuum cleaner and a water-filled glass tube to determine which material would allow the vacuum to exert the most suction on the water, and consequently which was the most impervious to air. The umbrella covering performed the best but was also the most expensive. They instead selected a synthetic kind of taffeta.[6]&lt;/p&gt;&lt;p&gt;To purchase a large quantity of fabric without arousing too much suspicion, the pair again drove to a distant city. This time they travelled over 160 kilometres (100 mi) to a department store in Leipzig. Their new cover story was that they belonged to a sailing club and needed the material to make sails. The quantity they needed had to be ordered, and although they feared the purchase might be reported to East Germany's State Security Service (Stasi), they returned the next day and picked up the material without incident. They paid 4,800 DDM (US$720) for 800 metres (2,600 ft) of 1-metre-wide (3 ft 3 in) fabric.[6] On the way home, they also purchased an electric motor to speed up the pedal-operated sewing machine they had been using to sew the material into the desired balloon shape.[7]&lt;/p&gt;&lt;p&gt;Wetzel spent the next week sewing the material into another balloon, accomplishing the task faster the second time with the now-electric sewing machine. Soon afterwards, the two men returned to the forest clearing and inflated the bag in about five minutes using the blower and flame thrower. The bag rose and held air, but the burner on the gondola was not powerful enough to create the heat needed for lift. The pair continued experimenting for months, doubling the number of propane tanks and trying different fuel mixtures. Disappointed with the result, Wetzel decided to abandon the project and instead started to pursue the idea of building a small gasoline engine-powered light aeroplane[6] or a glider.[5]&lt;/p&gt;&lt;p&gt;Strelzyk continued trying to improve the burner. In June 1979, he discovered that with the propane tank inverted, additional pressure caused the liquid propane to evaporate, which produced a bigger flame. He modified the gondola to mount the propane tanks upside down, and returned to the test site where he found the new configuration produced a 12-metre (39 ft) long flame. Strelzyk was ready to attempt an escape.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First escape attempt&lt;/head&gt;[edit]&lt;p&gt;On 3 July 1979, the weather and wind conditions were favourable. The entire Strelzyk family lifted from a forest clearing at 1:30 am and climbed at a rate of 4 metres (13 ft) per second. They reached an altitude of 2,000 metres (6,600 ft) according to an altimeter Strelzyk had made by modifying a barometer. A light wind was blowing them towards the border. The balloon then entered clouds, and atmospheric water vapour condensed on the balloon, adding weight which caused it to descend prematurely. The family landed safely approximately 180 metres (590 ft) short of the border, at the edge of the heavily mined border zone. Unsure of where they were, Strelzyk explored until he found a piece of litter – a bread bag from a bakery in Wernigerode, an East German town. The group spent nine hours carefully extricating themselves from the 500-metre (1,600 ft) wide border zone to avoid detection. They also had to travel unnoticed through a 5 km (3.1 mi) restricted zone before hiking back a total of 14 km (8.7 mi) to their car and the launch paraphernalia they had left behind.[6] They made it home just in time to report their absence from work and school was due to sickness.[7]&lt;/p&gt;&lt;p&gt;The abandoned balloon was discovered by the authorities later that morning. Strelzyk destroyed all compromising evidence and sold his car, fearing that it could link him to the escape attempt.[6] On 14 August, the Stasi launched an appeal to find the "perpetrator of a serious offence", listing in detail all the items recovered at the landing site.[9] Strelzyk felt that the Stasi would eventually trace the balloon to him and the Wetzels. He agreed with Wetzel that their best chance was to quickly build another balloon and get out as soon as possible.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Successful escape&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel decided to double the balloon's size to 4,000 cubic metres (140,000 cu ft) in volume, 20 metres (66 ft) in diameter, and 25 metres (82 ft) in height. They needed 1,250 square metres (13,500 sq ft) of taffeta, and purchased the material, in various colours and patterns, all over the country in order to escape suspicion. Wetzel sewed a third balloon, using over 6 kilometres (3.7 mi) of thread, and Strelzyk rebuilt everything else as before. In six weeks, they had prepared the 180-kilogram (400 lb) balloon and a payload of 550 kilograms (1,210 lb), including the gondola, equipment, and cargo (the two families). Confident in their calculations, they found the weather conditions right on 15 September, when a violent thunderstorm created the correct winds. The two families set off for the launch site in Strelzyk's replacement car (a Wartburg) and a moped. Arriving at 1:30 am, they needed just ten minutes to inflate the balloon and an additional three minutes to heat the air.[6]&lt;/p&gt;&lt;p&gt;Lifting off just after 2:00 am, the group failed to cut the tethers holding the gondola to the ground at the same time, tilting the balloon and sending the flame towards the fabric, which caught fire. After putting out the fire with an extinguisher brought along for just such an emergency, they climbed to 2,000 metres (6,600 ft) in nine minutes, drifting towards West Germany at 30 kilometres per hour (19 mph). The balloon flew for 28 minutes, with the temperature plummeting to −8 °C (18 °F) in the unsheltered gondola, which consisted solely of clothesline railing.&lt;/p&gt;&lt;p&gt;A design miscalculation resulted in the burner stovepipe being too long, causing the flame to be too high in the balloon, creating excessive pressure which caused the balloon to split. The air rushing out of the split extinguished the burner flame. Wetzel was able to re-light the flame with a match, and had to do so several more times before the group landed. At one point, they increased the flame to the maximum possible extent and rose to 2,500 metres (8,200 ft). They later learned they had been high enough to be detected, but not identified, on radar by West German air traffic controllers.[6] They had also been detected on the East German side by a night watchman at the district culture house in Bad Lobenstein. The report of an unidentified flying object heading toward the border caused guards to activate search lights, but the balloon was too high and out of reach of the lights.[10]&lt;/p&gt;&lt;p&gt;The tear in the balloon meant the group had to use the burner much more often, greatly limiting the distance it could travel. Wetzel later said he thought they could have travelled another 50 kilometres (31 mi) had the balloon remained intact. They made out the border crossing at Rudolphstein on the A9 and saw the search lights. When the propane ran out, they descended quickly, landing near the town of Naila, in the West German state of Bavaria and only 10 km (6 mi) from the border. The only injury was suffered by Wetzel, who broke his leg upon landing.[6] Various clues indicated to the families that the balloon had made it across the border. These included spotting red and yellow coloured lights, not common in East Germany,[3] and small farms, in contrast to the large state-run operations in the east. Another clue was modern farm equipment, unlike the older equipment used in East Germany.[11] Two Bavarian State Police officers saw the balloon's flickering light and headed to where they thought it would land. There they found Strelzyk and Wetzel, who first asked if they had made it to the West, although they noticed the police car was an Audi – another sign they were in West Germany. Upon learning they had, the escapees happily called for their families to join them.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Aftermath&lt;/head&gt;[edit]&lt;p&gt;East Germany immediately increased border security, closed all small airports close to the border, and ordered the planes kept farther inland.[6] Propane gas tanks became registered products, and large quantities of fabric suitable for balloon construction could no longer be purchased. Mail from East Germany to the two escaped families was prohibited.[12]&lt;/p&gt;&lt;p&gt;Erich Strelzyk learned of his brother's escape on the ZDF news and was arrested in his Potsdam apartment three hours after the landing. The arrest of family members was standard procedure to deter others from attempting escape. He was charged with "aiding and abetting escape", as were Strelzyk's sister Maria and her husband, who were sentenced to 2½ years. The three were eventually released with the help of Amnesty International.[12]&lt;/p&gt;&lt;p&gt;The families decided to initially settle in Naila where they had landed. Wetzel worked as an automobile mechanic and Strelzyk opened a TV repair shop in Bad Kissingen. Due to pressure from Stasi spies, the Strelzyks moved to Switzerland in 1985.[10] After German reunification in 1990, they returned to their old home in their hometown of Pößneck.[13] The Wetzels remained in Bavaria.[7]&lt;/p&gt;&lt;p&gt;West German weekly magazine Stern paid Strelzyk and Wetzel for exclusive rights to the story.[3]&lt;/p&gt;&lt;p&gt;The escape has been portrayed in two films: Night Crossing (1982) and Balloon (2018). The former, also called With the Wind to the West – the English translation of the German title – was an English-language film produced by Disney. The latter was a German-language production which "both families welcomed [Director] Herbig’s desire to, as he put it, 'make a German film for an international audience.'" The Strelzyks were reportedly "moved to tears" at the screening of Balloon at Rockefeller Center in New York City.[12] Herbig claimed in 2018 that both the Strelzyk and Wetzel families had been dissatisfied with the Disney film.[14]&lt;/p&gt;&lt;p&gt;Peter Strelzyk died in 2017 at age 74 after a long illness.[13]&lt;/p&gt;&lt;p&gt;In 2017, the balloon was put on permanent display at the Haus der Bayerischen Geschichte: Museum in Regensburg.[10]&lt;/p&gt;&lt;head rend="h2"&gt;Escapees&lt;/head&gt;[edit]&lt;p&gt;The family members included:[3]&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Peter Strelzyk, aged 37&lt;/item&gt;&lt;item&gt;Doris Strelzyk&lt;/item&gt;&lt;item&gt;Frank Strelzyk, aged 15&lt;/item&gt;&lt;item&gt;Andreas Strelzyk, aged 11&lt;/item&gt;&lt;item&gt;Günter Wetzel, aged 24&lt;/item&gt;&lt;item&gt;Petra Wetzel&lt;/item&gt;&lt;item&gt;Peter Wetzel, aged 5&lt;/item&gt;&lt;item&gt;Andreas Wetzel, aged 2&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Media&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;The Disney film Night Crossing (1982) is an adaptation of the story[13]&lt;/item&gt;&lt;item&gt;Michael Herbig's film Balloon (2018) is a German-language adaptation of the story[15]&lt;/item&gt;&lt;item&gt;BBC program Outlook, "Fleeing Communism in a Hot Air Balloon"[16]&lt;/item&gt;&lt;item&gt;PBS Nova program, "History's Great Escapes" (2004)[17]&lt;/item&gt;&lt;item&gt;Doris Strelzyk, Peter Strelzyk, Gudrun Giese: Destiny Balloon Escape. Quadriga, Berlin 1999, ISBN 3-88679-330-3&lt;/item&gt;&lt;item&gt;Jürgen Petschull, With the Wind to the West. The Adventurous Flight from Germany to Germany. Goldmann, Munich 1980, ISBN 3-442-11501-9&lt;/item&gt;&lt;item&gt;Kristen Fulton (Author), Torben Kuhlmann (Illustrator), Flight for Freedom: The Wetzel Family’s Daring Escape from East Germany. March 3, 2020, ISBN 978-1452149608&lt;/item&gt;&lt;item&gt;The Netflix series White Rabbit Project, episode 2, "Jailbreak"&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b Wetzel, Günter. "Die Nacht der Flucht". Ballonflucht.de. Archived from the original on 19 September 2020. Retrieved 16 September 2019.&lt;/item&gt;&lt;item&gt;^ Hertle, Hans-Hermann; Nooke, Maria (2009). Die Todesopfer an der Berliner Mauer 1961–1989. Ein biographisches Handbuch. Ch. Links Verlag. ISBN 978-3-86153-517-1.&lt;/item&gt;&lt;item&gt;^ a b c d e Getler, Michael (28 September 1979). "Harrowing Flight From East Germany". The Washington Post. Archived from the original on 26 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Snow, Philipp (16 September 2009). "Balloon escape from the GDR With hot air to freedom". Spiegel Online (in German). Archived from the original on 7 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c Simpson, Paul (2013). The Mammoth Book of Prison Breaks. Little, Brown Book Group. p. 216. ISBN 978-1-4721-0024-5. Archived from the original on 16 September 2023. Retrieved 1 April 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e f g h i j k l m n o p q r s Dornberg, John (February 1980). "The Freedom Balloon". Popular Mechanics. pp. 100–103. Retrieved 22 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e Overbye, Stine (13 April 2017). "Fathers wanted to escape GDR in a hot air balloon". Historia (in Dutch). Archived from the original on 1 April 2018. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ Petschull, Jürgen (27 September 1979). "Das Himmelfahrtskommando" [High-flying mission] (PDF). Stern (in German). No. 40. p. 34. Archived from the original (PDF) on 12 July 2024 – via Museum Naila.&lt;/item&gt;&lt;item&gt;^ Souerbry, Rachel. "How Two Families Escaped East Germany In A Homemade Hot Air Balloon". ranker.com. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Wetzel und Peter Strelzyk Ballonhülle der Strelzyks". museum.bayern (in German). Archived from the original on 8 April 2019. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "East-West: The Great Balloon Escape". Time. 1 October 1979. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "The Balloon Escape of Peter Strelzyk". goethe-rutheneum.de (in German). Archived from the original on 11 February 2013. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Man who fled East Germany in a homemade balloon and whose story was made into a film dies". The Express. 15 March 2017. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Connolly, Kate (17 October 2018). "Film of daring balloon escape from East revives German identity debate". Archived from the original on 8 February 2021. Retrieved 10 May 2019.&lt;/item&gt;&lt;item&gt;^ Ballon at IMDb&lt;/item&gt;&lt;item&gt;^ "Fleeing Communism in a Hot Air Balloon". bbc. Archived from the original on 12 December 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "Great Escapes". pbs.org. Archived from the original on 16 April 2019. Retrieved 16 April 2019.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;External links&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;Escape by balloon by Günter Wetzel (participant website)&lt;/item&gt;&lt;item&gt;Video of balloon on museum display&lt;/item&gt;&lt;item&gt;BBC Outlook program&lt;/item&gt;&lt;item&gt;Photograph of Güenter Wetzel, Peter and Doris Strelzyk Archived 1 April 2018 at the Wayback Machine&lt;/item&gt;&lt;item&gt;Photograph of the actual balloon, inflated in 1985 at a festival in Hof, Bavaria&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/East_Germany_balloon_escape"/><published>2026-01-16T17:16:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46649142</id><title>STFU</title><updated>2026-01-17T10:10:23.583242+00:00</updated><content>&lt;doc fingerprint="a01e89ee7325e0d9"&gt;
  &lt;main&gt;
    &lt;p&gt;i was at bombay airport. some dude was watching reels on full volume and laughing loudly. asking nicely doesn't work anymore. me being me, didn't have the courage to speak up.&lt;/p&gt;
    &lt;p&gt;so i built a tiny app that plays back the same audio it hears, delayed by ~2 seconds. asked claude, it spat out a working version in one prompt. surprisingly WORKS.&lt;/p&gt;
    &lt;p&gt;discussion - https://x.com/the2ndfloorguy/status/2011734249871954188&lt;/p&gt;
    &lt;p&gt;something something auditory feedback loop something something cognitive dissonance. idk i'm not a neuroscientist. all i know is it makes people shut up and that's good enough for me.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;straight up honest - originally called this "make-it-stop" but then saw @TimDarcet also built similar and named it STFU. wayyyyy better name. so stole it. sorry not sorry.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;made with spite and web audio api. do whatever you want with it.&lt;/p&gt;
    &lt;p&gt;yo, meanwhile if you are new here, you might find my, other side projects kinda funny.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Pankajtanwarbanna/stfu"/><published>2026-01-16T17:32:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46649489</id><title>Emoji Use in the Electronic Health Record is Increasing</title><updated>2026-01-17T10:10:23.492233+00:00</updated><content/><link href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2843883"/><published>2026-01-16T17:56:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46650347</id><title>Reading across books with Claude Code</title><updated>2026-01-17T10:10:23.306053+00:00</updated><content>&lt;doc fingerprint="3f200f9427931e3e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Reading across books with Claude Code&lt;/head&gt;
    &lt;p&gt;Jan 4, 2026&lt;/p&gt;
    &lt;p&gt;LLMs are overused to summarise and underused to help us read deeper.&lt;/p&gt;
    &lt;p&gt;To explore how they can enrich rather than reduce, I set Claude Code up with tools to mine a library of 100 non-fiction books. It found sequences of excerpts connected by an interesting idea, or trails.&lt;/p&gt;
    &lt;p&gt;Here’s a part of one such trail, linking deception in the startup world to the social psychology of mass movements (I’m especially pleased by the jump from Jobs to Theranos):&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The books were selected from Hacker News’ favourites, which I previously scraped and visualized.&lt;/p&gt;
    &lt;p&gt;Claude browses the books a chunk at a time. A chunk is a segment of roughly 500 words that aligns with paragraphs when possible. This length is a good balance between saving tokens and providing enough context for ideas to breathe.&lt;/p&gt;
    &lt;p&gt;Chunks are indexed by topic, and topics are themselves indexed for search. This makes it easy to look up all passages in the corpus that relate to, say, deception.&lt;/p&gt;
    &lt;p&gt;This works well when you know what to look for, but search alone can’t tell you which topics are present to begin with. There are over 100,000 extracted topics, far too many to be browsed directly. To support exploration, they are grouped into a hierarchical tree structure.&lt;/p&gt;
    &lt;p&gt;This yields around 1,000 top-level topics. They emerge from combining lower-level topics, and not all of them are equally useful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Incidents that frustrated Ev Williams&lt;/item&gt;
      &lt;item&gt;Names beginning with “Da”&lt;/item&gt;
      &lt;item&gt;Events between 1971 &amp;amp; 1974&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, this Borgesian taxonomy is good enough for Claude to piece together what the books are about.&lt;/p&gt;
    &lt;p&gt;Claude uses the topic tree and the search via a few CLI tools.&lt;lb/&gt; They allow it to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Find all chunks associated with a topic similar to a query.&lt;/item&gt;
      &lt;item&gt;Find topics which occur in a window of chunks around a given topic.&lt;/item&gt;
      &lt;item&gt;Find topics that co-occur in multiple books.&lt;/item&gt;
      &lt;item&gt;Browse topics and chunks that are siblings in the topic tree.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To generate the trails, the agent works in stages.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;First, it scans the library and the existing trails, and proposes novel trail ideas. It mainly browses the topic tree to find unexplored areas and rarely reads full chunks in depth.&lt;/item&gt;
      &lt;item&gt;Then, it takes a specific idea and turns it into a trail. It receives seed topics from the previous stage and browses many chunks. It extracts excerpts, specific sequences of sentences, and decides on how best to order them to support an insight.&lt;/item&gt;
      &lt;item&gt;Finally, it adds highlights and edges between consecutive excerpts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What I learned&lt;/head&gt;
    &lt;head rend="h3"&gt;Claude Code is great for non-coding tasks&lt;/head&gt;
    &lt;p&gt;Even though I’ve been using Claude Code to develop for months, my first instinct for this project was to consider it as a traditional pipeline of several discrete stages. My initial attempt at this system consisted of multiple LLM modules with carefully hand-assembled contexts.&lt;/p&gt;
    &lt;p&gt;On a whim, I ran Claude with access to the debugging tools I’d been using and a minimal prompt: “find something interesting.” It immediately did a better job at pulling in what it needed than the pipeline I was trying to tune by hand, while requiring much less orchestration. It was a clear improvement to push as much of the work into the agent’s loop as possible.&lt;/p&gt;
    &lt;p&gt;I ended up using Claude as my main interface to the project.&lt;lb/&gt; Initially I did so because it inferred the sequence of CLI calls I wanted to run faster than I could recall them. Then, I used it to automate tasks which weren’t rigid enough to be scripted traditionally.&lt;/p&gt;
    &lt;p&gt;The latter opened up options that I wouldn’t have considered before. For example, I changed my mind on how short I wanted excerpts to be. I communicated my new preference to Claude, which then looked through all the existing trails and edited them as necessary, balancing the way the overall meaning of the trail changed. Previously, I would’ve likely considered all previous trails to be outdated and generated new ones, because the required edits would’ve been too nuanced to specify.&lt;/p&gt;
    &lt;p&gt;In general, agents have widened my ambitions.&lt;lb/&gt; By taking care of the boilerplate, I no longer shy away from the tedious parts. Revision is cheap, so I don’t need to plow ahead with suboptimal choices just because it’d be too costly to undo them. This, in turn, keeps up the momentum and lets me focus on the joyful, creative aspects of the work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ask the agent what it needs&lt;/head&gt;
    &lt;p&gt;My focus went from optimising prompts to implementing better tools for Claude to use, moving up a rung on the abstraction ladder.&lt;/p&gt;
    &lt;p&gt;My mental model of the AI component changed: from a function mapping input to output, to a coworker I was assisting. I spent my time thinking about the affordances that would make the workflow better, as if I were designing them for myself. That they were to be used by an agent was a mere detail.&lt;/p&gt;
    &lt;p&gt;This worked because the agent is now intelligent enough that the way it uses these tools overlaps with my own mental model. It is generally easy to empathise with it and predict what it will do.&lt;/p&gt;
    &lt;p&gt;Initially I watched Claude’s logs closely and tried to guess where it was lacking a certain ability. Then I realised I could simply ask it to provide feedback at the end and list the functionality it wished it had. Claude was excellent at proposing new commands and capabilities that would make the work more efficient.&lt;/p&gt;
    &lt;p&gt;Claude suggested improvements, which Claude implemented, so Claude could do the work better. At least I’m still needed to pay for the tokens — for now.&lt;/p&gt;
    &lt;head rend="h3"&gt;Novelty is a useful guide&lt;/head&gt;
    &lt;p&gt;It’s hard to quantify interestingness as an objective to optimise for.&lt;lb/&gt; Why Greatness Cannot Be Planned makes the case that chasing novelty is often a more fruitful approach. While its conclusions are debated, I’ve found this idea to be a good fit for this project.&lt;/p&gt;
    &lt;p&gt;As a sign of the times, this novelty search was implemented in two ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;By biasing the search algorithm towards under-explored topics and books.&lt;/item&gt;
      &lt;item&gt;By asking Claude nicely.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A topic’s novelty score was calculated as the mean distance from its embedding’s k nearest neighbors. A book’s novelty score is the average novelty of the unique topics that it contains. This value was used to rank search results, so that those which were both relevant and novel were more likely to be seen.&lt;/p&gt;
    &lt;p&gt;On a prompting level, Claude starts the ideation phase by looking at all the existing trails and is asked to avoid any conceptual overlap. This works fairly well, though it is often distracted by any topics related to secrecy, systems theory, or tacit knowledge.&lt;/p&gt;
    &lt;p&gt;It’s as if the very act of finding connections in a corpus summons the spirit of Umberto Eco and amps up the conspiratorial thinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it’s implemented&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;EPUBs are parsed using &lt;code&gt;selectolax&lt;/code&gt;, which I picked over BeautifulSoup for its speed and simpler API.&lt;/item&gt;
      &lt;item&gt;Everything from the plain text to the topic tree is stored in SQLite. Embeddings are stored using &lt;code&gt;sqlite-vec&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The text is split into sentences using &lt;code&gt;wtpsplit&lt;/code&gt;(the&lt;code&gt;sat-6l-sm&lt;/code&gt;model). Those sentences are then grouped into chunks, trying to get up to 500 words without breaking up paragraphs.&lt;/item&gt;
      &lt;item&gt;I used &lt;code&gt;DSPy&lt;/code&gt;to call LLMs. It worked well for the structured data extraction and it was easy to switch out different models to experiment. I tried its prompt optimizers before I went full agentic, and their results were very promising.&lt;/item&gt;
      &lt;item&gt;I settled on Gemini 2.5 Flash Lite for topic extraction. The model gets passed a chunk and is asked to return 3-5 topics. It is also asked whether the chunk is useful, in order to filter out index entries, acknowledgements, orphan headers, etc. I was surprised at how stable these extracted topics were: similar chunks often shared some of the exact same topic labels. Processing 100 books used about 60M input tokens and ~£10 in total.&lt;/item&gt;
      &lt;item&gt;After a couple books got indexed, I shared the results with Claude Opus along with the original prompt and asked it to improve it. This is a half-baked single iteration of the type of prompt optimisation DSPy implements, and it worked rather well.&lt;/item&gt;
      &lt;item&gt;Topic pairs with a distance below a threshold get merged together. This takes care of near-duplicates such as “Startup founder”, “Startup founders”, and “Founder of startups”.&lt;/item&gt;
      &lt;item&gt;The CLI output uses a semi-XML format. In order to stimulate navigating, most output is nested with related content. For example, when searching for a topic, chunks are shown with the other topics they contain. This allows us to get a sense of what the chunk is about, as well as which other topics might be interesting. There’s probably more token-efficient formats, but I never hit the limit of the context window.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;&amp;lt;topics query="deception" count="1"&amp;gt;
  &amp;lt;topic id="47193" books="7" score="0.0173" label="Deception"&amp;gt;
    &amp;lt;chunk id="186" book="1"&amp;gt;
      &amp;lt;topic id="47192" label="Business deal"/&amp;gt;
      &amp;lt;topic id="47108" label="Internal conflict"/&amp;gt;
      &amp;lt;topic id="46623" label="Startup founders"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
    &amp;lt;chunk id="1484" book="4"&amp;gt;
      &amp;lt;topic id="51835" label="Gawker Media"/&amp;gt;
      &amp;lt;topic id="53006" label="Legal Action"/&amp;gt;
      &amp;lt;topic id="52934" label="Maskirovka"/&amp;gt;
      &amp;lt;topic id="52181" label="Strategy"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
    &amp;lt;chunk id="2913" book="9"&amp;gt;
      &amp;lt;topic id="59348" label="Blood testing system"/&amp;gt;
      &amp;lt;topic id="59329" label="Elizabeth Holmes"/&amp;gt;
      &amp;lt;topic id="59352" label="Investor demo"/&amp;gt;
      &amp;lt;topic id="59349" label="Theranos"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
  &amp;lt;/topic&amp;gt;
&amp;lt;/topics&amp;gt;&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Topics are embedded using&lt;/p&gt;&lt;code&gt;google/embeddinggemma-300m&lt;/code&gt;and reranked using&lt;code&gt;BAAI/bge-reranker-v2-m3&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Many CLI tools require loading the embedding model and other expensive state. The first call transparently starts a separate server process which loads all these resources once and holds onto them for a while. Subsequent CLI calls use this server through Python’s&lt;/p&gt;&lt;code&gt;multiprocessing.connection&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The topic collection is turned into a graph (backed by&lt;/p&gt;&lt;code&gt;igraph&lt;/code&gt;) by adding edges based on the similarity of their embeddings and the point-wise mutual information of their co-occurrences.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The graph is turned into a tree by applying Leiden partitioning recursively until a minimum size is reached. I tried the Surprise quality function because it had no parameters to tweak, and found it to be good enough. Each group is labelled by Gemini based on all the topics that it contains.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Excerpts are cleaned by Gemini to remove EPUB artifacts, parsing errors, headers, footnotes, etc. Doing this only for excerpts that are actually shown, instead of during pre-processing, saved a lot of tokens.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pieterma.es/syntopic-reading-claude/"/><published>2026-01-16T18:49:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46652617</id><title>Releasing rainbow tables to accelerate Net-NTLMv1 protocol deprecation</title><updated>2026-01-17T10:10:23.036155+00:00</updated><content>&lt;doc fingerprint="ac035d9b403222ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Closing the Door on Net-NTLMv1: Releasing Rainbow Tables to Accelerate Protocol Deprecation&lt;/head&gt;
    &lt;head rend="h5"&gt;Mandiant&lt;/head&gt;
    &lt;p&gt;Written by: Nic Losby&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Mandiant is publicly releasing a comprehensive dataset of Net-NTLMv1 rainbow tables to underscore the urgency of migrating away from this outdated protocol. Despite Net-NTLMv1 being deprecated and known to be insecure for over two decades—with cryptanalysis dating back to 1999—Mandiant consultants continue to identify its use in active environments. This legacy protocol leaves organizations vulnerable to trivial credential theft, yet it remains prevalent due to inertia and a lack of demonstrated immediate risk.&lt;/p&gt;
    &lt;p&gt;By releasing these tables, Mandiant aims to lower the barrier for security professionals to demonstrate the insecurity of Net-NTLMv1. While tools to exploit this protocol have existed for years, they often required uploading sensitive data to third-party services or expensive hardware to brute-force keys. The release of this dataset allows defenders and researchers to recover keys in under 12 hours using consumer hardware costing less than $600 USD. This initiative highlights the amplified impact of combining Mandiant's frontline expertise with Google Cloud's resources to eliminate entire classes of attacks.&lt;/p&gt;
    &lt;p&gt;This post details the generation of the tables, provides access to the dataset for community use, and outlines critical remediation steps to disable Net-NTLMv1 and prevent authentication coercion attacks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Background&lt;/head&gt;
    &lt;p&gt;Net-NTLMv1 has been widely known to be insecure since at least 2012, following presentations at DEFCON 20, with cryptanalysis of the underlying protocol dating back to at least 1999. On Aug. 30, 2016, Hashcat added support for cracking Data Encryption Standard (DES) keys using known plaintext, further democratizing the ability to attack this protocol. Rainbow tables are almost as old, with the initial paper on rainbow tables published in 2003 by Philippe Oechslin, citing an earlier iteration of a time-memory trade-off from 1980 by Martin Hellman.&lt;/p&gt;
    &lt;p&gt;Essentially, if an attacker can obtain a Net-NTLMv1 hash without Extended Session Security (ESS) for the known plaintext of &lt;code&gt;1122334455667788&lt;/code&gt;, a cryptographic attack, referred to as a known plaintext attack (KPA), can be applied. This guarantees recovery of the key material used. Since the key material is the password hash of the authenticating Active Directory (AD) object—user or computer—the attack results can quickly be used to compromise the object, often leading to privilege escalation.&lt;/p&gt;
    &lt;p&gt;A common chain attackers use is authentication coercion from a highly privileged object, such as a domain controller (DC). Recovering the password hash of the DC machine account allows for DCSync privileges to compromise any other account in AD.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dataset Release&lt;/head&gt;
    &lt;p&gt;The unsorted dataset can be downloaded using &lt;code&gt;gsutil -m cp -r gs://net-ntlmv1-tables/tables .&lt;/code&gt; or through the Google Cloud Research Dataset portal. &lt;/p&gt;
    &lt;p&gt;The SHA512 hashes of the tables can be checked by first downloading the checksums &lt;code&gt;gsutil -m cp gs://net-ntlmv1-tables/tables.sha512 .&lt;/code&gt; then checked by &lt;code&gt;sha512sum -c tables.sha512&lt;/code&gt;. The password cracking community has already created derivative work and is also hosting the ready to use tables.&lt;/p&gt;
    &lt;head rend="h3"&gt;Use of the Tables&lt;/head&gt;
    &lt;p&gt;Once a Net-NTLMv1 hash has been obtained, the tables can be used with historical or modern reinventions of rainbow table searching software such as rainbowcrack (rcrack), or RainbowCrack-NG on central processing units (CPUs) or a fork of rainbowcrackalack on graphics processing units (GPUs). The Net-NTLMv1 hash needs to be preprocessed to the DES components using ntlmv1-multi as shown in the next section.&lt;/p&gt;
    &lt;head rend="h3"&gt;Obtaining a Net-NTLMv1 Hash&lt;/head&gt;
    &lt;p&gt;Most attackers will use Responder with the &lt;code&gt;--lm&lt;/code&gt; and &lt;code&gt;--disable-ess&lt;/code&gt; flags and set the authentication to a static value of &lt;code&gt;1122334455667788&lt;/code&gt; to only allow for connections with Net-NTLMv1 as a possibility. Attackers can then wait for incoming connections or coerce authentication using a tool such as PetitPotam or DFSCoerce to generate incoming connections from DCs or lower privilege hosts that are useful for objective completion. Responses can be cracked to retrieve password hashes of either users or computer machine accounts. A sample workflow for an attacker is shown below in Figure 1, Figure 2, and Figure 3.&lt;/p&gt;
    &lt;p&gt;Figure 1: DFSCoerce against a DC&lt;/p&gt;
    &lt;p&gt;Figure 2: Net-NTLMv1 hash obtained for DC machine account&lt;/p&gt;
    &lt;p&gt;Figure 3: Parse Net-NTLMv1 hash to DES parts&lt;/p&gt;
    &lt;p&gt;Figure 4 illustrates the processing of the Net-NTLMv1 hash to the DES ciphertexts.&lt;/p&gt;
    &lt;p&gt;Figure 4: Net-NTLMv1 hash to DES ciphertexts&lt;/p&gt;
    &lt;p&gt;An attacker then takes the split-out ciphertexts to crack the keys used based on the known plaintext of &lt;code&gt;1122334455667788&lt;/code&gt; with the steps of loading the tables shown in Figure 5 and cracking results in Figure 6 and Figure 7.&lt;/p&gt;
    &lt;p&gt;Figure 5: Loading DES components for cracking&lt;/p&gt;
    &lt;p&gt;Figure 6: First hash cracked&lt;/p&gt;
    &lt;p&gt;Figure 7: Second hash cracked and run statistics&lt;/p&gt;
    &lt;p&gt;An attacker can then calculate the last remaining key with ntlmv1-multi once again, or look it up with twobytes, to recreate the full NT hash for the DC account with the last key part shown in Figure 8.&lt;/p&gt;
    &lt;p&gt;Figure 8: Calculate remaining key&lt;/p&gt;
    &lt;p&gt;The result can be checked with hashcat's NT hash shucking mode, &lt;code&gt;-m 27000&lt;/code&gt;, as shown in Figure 9.&lt;/p&gt;
    &lt;p&gt;Figure 9: Keys checked with hash shucking&lt;/p&gt;
    &lt;p&gt;An attacker can then use the hash to perform a DCSync attack targeting a DC and authenticating as the now compromised machine account. The attack flow uses secretsdump.py from the Impacket toolsuite and is shown in Figure 10.&lt;/p&gt;
    &lt;p&gt;Figure 10: DCSync attack performed&lt;/p&gt;
    &lt;head rend="h3"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Organizations should immediately disable the use of Net-NTLMv1.&lt;/p&gt;
    &lt;head rend="h4"&gt;Local Computer Policy&lt;/head&gt;
    &lt;p&gt;"Local Security Settings" &amp;gt; "Local Policies" &amp;gt; "Security Options" &amp;gt; “Network security: LAN Manager authentication level" &amp;gt; "Send NTLMv2 response only".&lt;/p&gt;
    &lt;head rend="h4"&gt;Group Policy&lt;/head&gt;
    &lt;p&gt;"Computer Configuration" &amp;gt; "Policies" &amp;gt; "Windows Settings" &amp;gt; "Security Settings" &amp;gt; "Local Policies" &amp;gt; "Security Options" &amp;gt; "Network Security: LAN Manager authentication level" &amp;gt; "Send NTLMv2 response only"&lt;/p&gt;
    &lt;p&gt;As these are local to the computer configurations, attackers can and have set the configuration to a vulnerable state to then fix the configuration after their attacks have completed with local administrative access. Monitoring and alerting of when and where Net-NTLMv1 is used is needed in addition to catching these edge cases.&lt;/p&gt;
    &lt;p&gt;Filter Event Logs for Event ID 4624: "An Account was successfully logged on." &amp;gt; "Detailed Authentication Information" &amp;gt; "Authentication Package" &amp;gt; "Package Name (NTLM only)", if "LM" or "NTLMv1" is the value of this attribute, LAN Manager or Net-NTLMv1 was used.&lt;/p&gt;
    &lt;head rend="h3"&gt;Related Reading&lt;/head&gt;
    &lt;p&gt;This project was inspired by and referenced the following research published to blogs, social media, and code repositories.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Thank you to everyone who helped make this blog post possible, including but not limited to Chris King and Max Gruenberg.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables"/><published>2026-01-16T21:42:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46652944</id><title>Install.md: A standard for LLM-executable installation</title><updated>2026-01-17T10:10:22.034939+00:00</updated><content>&lt;doc fingerprint="d540f21bfdefd486"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;install.md: A Standard for LLM-Executable Installation&lt;/head&gt;&lt;p&gt;January 15, 2026&lt;/p&gt;&lt;p&gt;Michael Ryaboy&lt;/p&gt;&lt;p&gt;Content Strategist&lt;/p&gt;&lt;head rend="h4"&gt;Share this article&lt;/head&gt;&lt;p&gt;Installing software is the kind of specific and repetitive task that agents are good at. Today we are proposing install.md to standardize how developers should write installation instructions for agents. It's currently live on all Mintlify sites including Cerebras, Firecrawl, and Langchain.&lt;/p&gt;&lt;p&gt;Proposal for a standard &lt;code&gt;/install.md&lt;/code&gt; file that provides LLM-executable installation instructions.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;&lt;p&gt;Agents are growing in capability faster than software developers have been able to keep up. Product documentation today is focused on humans instead of AI which creates friction when trying to automate annoying yak-shaving style tasks like installation.&lt;/p&gt;&lt;p&gt;The difference is very subtle. Agents need to have a task iterated to them like "I want you to install Mintlify CLI for me. Execute all the steps below autonomously." whereas humans can work from more general prose or even a bash script.&lt;/p&gt;&lt;p&gt;Today we are proposing install.md to standardize how developers should write installation instructions for agents. It's currently live on all Mintlify sites including Cerebras, Firecrawl, and Langchain.&lt;/p&gt;&lt;head rend="h2"&gt;Proposal&lt;/head&gt;&lt;p&gt;Add an &lt;code&gt;install.md&lt;/code&gt; markdown file to your project with LLM-executable installation instructions.&lt;/p&gt;&lt;p&gt;Users paste that file into an LLM or pipe it directly from a URL. The LLM reads the instructions, detects the environment, adapts to the setup, and executes—optionally with approval at every step. Because the file is human-readable, users see exactly what will happen before it runs.&lt;/p&gt;&lt;p&gt;Instead of piping an executable file into bash with absolutely zero safeguards on what gets executed or confidence that it will figure out how to work with your arch linux setup, you can instead send an install.md to claude and trust Opus to deal with the minutia for you.&lt;/p&gt;&lt;code&gt;curl -fsSL https://www.anaconda.com/docs/install.md | claude
&lt;/code&gt;&lt;p&gt;This works for any language or framework, whether your software is distributed as a binary, package, or script.&lt;/p&gt;&lt;p&gt;As the developer, you define how installation should work. You encode knowledge about edge cases that would clutter your docs but matter when things break.&lt;/p&gt;&lt;p&gt;Mintlify now auto detects all of that information, synthesizes it into a version designed for agents, and hosts it for you at &lt;code&gt;https://&amp;lt;your-docs-url&amp;gt;/install.md&lt;/code&gt;. If your documentation covers multiple products—say, an SDK and a CLI—Mintlify defaults to generating install.md for the CLI. You can override the auto-generated file by adding your own &lt;code&gt;install.md&lt;/code&gt; to the root of your documentation directory. If you'd prefer to disable the feature entirely, reach out to support@mintlify.com.&lt;/p&gt;&lt;p&gt;Alternatively, if you are not using Mintlify, you can set up and host this file manually.&lt;/p&gt;&lt;head rend="h2"&gt;Format&lt;/head&gt;&lt;p&gt;install.md uses a structured format with specific keywords that guide the LLM through autonomous execution.&lt;/p&gt;&lt;p&gt;A typical install.md includes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Header: Product name as a lowercase, hyphenated H1 heading (e.g., &lt;code&gt;# claude-code&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;Description: Blockquote describing the product (e.g., &lt;code&gt;&amp;gt; Documentation and setup instructions for product-name&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;Action prompt: Direct instruction to the LLM (e.g., "I want you to install [Product] for me. Execute all the steps below autonomously.")&lt;/item&gt;&lt;item&gt;OBJECTIVE: What the installation should achieve&lt;/item&gt;&lt;item&gt;DONE WHEN: Specific verification criteria (e.g., a command that returns expected output)&lt;/item&gt;&lt;item&gt;TODO: Markdown checkbox list of steps to complete&lt;/item&gt;&lt;item&gt;Step sections: Detailed installation instructions with code blocks&lt;/item&gt;&lt;item&gt;EXECUTE NOW: Call-to-action that references the TODO list and objective&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This format is flexible—it's up to the developer to define the steps necessary for a successful installation.&lt;/p&gt;&lt;p&gt;Here is an example:&lt;/p&gt;&lt;code&gt;# mintlify

&amp;gt; Documentation and setup instructions for mintlify

I want you to install Mintlify CLI for me. Execute all the steps below autonomously.

OBJECTIVE: Install the Mintlify CLI and set up a local documentation preview environment.

DONE WHEN: Local documentation server is running and accessible at http://localhost:3000.

## TODO

- [ ] Verify Node.js v20.17.0+ is installed
- [ ] Install the Mintlify CLI globally
- [ ] Create a new documentation project
- [ ] Start the local development server
- [ ] Verify the preview is accessible at localhost:3000

## Prerequisites

You need to have Node.js v20.17.0 or higher installed. Verify your Node.js version:

```bash
node --version
```

You must also have Git installed:

```bash
git --version
```

## Install the CLI

You need to install the Mintlify CLI globally using npm or pnpm.

Using npm:

```bash
npm i -g mint
```

Using pnpm:

```bash
pnpm add -g mint
```

Verify the installation:

```bash
mint --version
```

## Create a new documentation project

You must create a new documentation project using the CLI. This clones the starter kit into your specified directory:

```bash
mint new docs
```

The CLI will prompt you for a project name and theme. You can also specify these directly:

```bash
mint new docs --name my-project --theme linden
```

Navigate into your new project directory:

```bash
cd docs
```

## Start the local preview server

You need to start the development server to preview your documentation locally:

```bash
mint dev
```

Your documentation preview is now available at `http://localhost:3000`.

If port 3000 is already in use, you can specify a custom port:

```bash
mint dev --port 3333
```

Alternatively, run without global installation using npx:

```bash
npx mint dev
```

## Verify the preview

Open your browser and navigate to http://localhost:3000 to confirm the documentation site is running.

## Update the CLI

If you need to update to the latest version:

```bash
mint update
```

Or reinstall with the latest version:

```bash
npm i -g mint@latest
```

## Additional CLI commands

Check for broken links in your documentation:

```bash
mint broken-links
```

Check for accessibility issues:

```bash
mint a11y
```

Validate an OpenAPI specification:

```bash
mint openapi-check &amp;lt;openapi-file-or-url&amp;gt;
```

EXECUTE NOW: Complete the above TODO list to achieve: Local documentation server is running and accessible at http://localhost:3000.
&lt;/code&gt;&lt;p&gt;The instructions describe outcomes, not exact commands. The LLM adapts to the environment—npm or pnpm, macOS or Linux, fresh project or existing codebase.&lt;/p&gt;&lt;head rend="h2"&gt;Relationship to llms.txt&lt;/head&gt;&lt;p&gt;install.md works naturally with your llms.txt. llms.txt helps LLMs understand your software; install.md tells them how to install it. Your install.md can link to your llms.txt so the LLM can reference it for troubleshooting, configuration details, or any additional context needed during installation.&lt;/p&gt;&lt;head rend="h2"&gt;Advantages&lt;/head&gt;&lt;p&gt;For developers shipping software:&lt;/p&gt;&lt;p&gt;Define installation once and it adapts to every environment. You can encode edge cases and troubleshooting knowledge without cluttering your main documentation. There's no wizard to build or maintain, and you control exactly what context the LLM receives. Installation instructions for agents can differ from your public docs without worrying about company voice or developer experience polish. You're writing directly to your actual users, which are agents.&lt;/p&gt;&lt;p&gt;For users installing software:&lt;/p&gt;&lt;p&gt;A single command installs your software, or you can paste the file into any LLM. The instructions are human-readable so you can review every step before it executes, and modify it to improve performance on your system if necessary. The LLM adapts to your specific environment automatically. Because the file is fetched at runtime, you never deal with stale training data.&lt;/p&gt;&lt;p&gt;For agents:&lt;/p&gt;&lt;p&gt;Installation instructions live in a predictable location that's easy to find. The structured format provides clear success criteria for determining when installation is complete. The file is markdown, not HTML, which means clean input for the model.&lt;/p&gt;&lt;head rend="h2"&gt;Contributing&lt;/head&gt;&lt;p&gt;The spec is open source:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Spec: installmd.org&lt;/item&gt;&lt;item&gt;GitHub: github.com/mintlify/install-md&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Add an &lt;code&gt;install.md&lt;/code&gt; to your project root or &lt;code&gt;/docs&lt;/code&gt; directory. That's it.&lt;/p&gt;&lt;p&gt;If you use Mintlify for documentation, install.md is generated automatically at &lt;code&gt;yourdocs.com/install.md&lt;/code&gt;.&lt;/p&gt;&lt;head rend="h2"&gt;FAQ&lt;/head&gt;&lt;p&gt;What about installation wizards like PostHog's or Sentry's?&lt;/p&gt;&lt;p&gt;Wizards solve the same problem: reliable installation across environments. They require significant engineering to build and maintain. PostHog's wizard consists of several LLM prompts, which users need to audit the repo to find. install.md is a lighter-weight alternative—define instructions in markdown, and the LLM handles adaptation. For complex integrations with many configuration options, a dedicated wizard may still be the right choice. For most software, install.md gets you most of the benefit with far less effort.&lt;/p&gt;&lt;p&gt;How does install.md work with my existing CLI or scripts?&lt;/p&gt;&lt;p&gt;Your install.md can instruct the LLM to run your CLI, execute your scripts, or follow your existing setup process. Think of it as a layer that guides the LLM to use whatever tools you've already built.&lt;/p&gt;&lt;p&gt;What about security? Isn't this just &lt;code&gt;curl | bash&lt;/code&gt; with extra steps?&lt;/p&gt;&lt;p&gt;This is a fair concern. A few things make install.md different:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Human-readable by design. Users can review the instructions before execution. Unlike obfuscated scripts, the intent is clear.&lt;/item&gt;&lt;item&gt;Step-by-step approval. LLMs in agentic contexts can be configured to request approval before running commands. Users see each action and can reject it.&lt;/item&gt;&lt;item&gt;No hidden behavior. install.md describes outcomes in natural language. Malicious intent is harder to hide than in a shell script.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Install.md doesn't eliminate trust requirements. Users should only use install.md files from sources they trust—same as any installation method.&lt;/p&gt;&lt;p&gt;What about versioning?&lt;/p&gt;&lt;p&gt;install.md works at the current version by default. If your installation differs significantly across versions, you can host version-specific files (&lt;code&gt;/v2/install.md&lt;/code&gt;) or include version detection logic in the instructions themselves.&lt;/p&gt;&lt;p&gt;What if install.md doesn't fit my use case?&lt;/p&gt;&lt;p&gt;The spec is open source. Open an issue or submit a PR—we're evolving the standard based on real-world feedback.&lt;/p&gt;&lt;head rend="h4"&gt;More blog posts to read&lt;/head&gt;&lt;head rend="h3"&gt;Why documentation is one of the most important surfaces for marketers&lt;/head&gt;&lt;p&gt;A look at why documentation is one of the most influential surfaces in a technical product’s funnel, how it shapes evaluation and adoption, and why marketers should treat it as a core part of their narrative.&lt;/p&gt;January 14, 2026&lt;p&gt;Peri Langlois&lt;/p&gt;&lt;p&gt;Head of Product Marketing&lt;/p&gt;&lt;head rend="h3"&gt;How I built our knowledge base in an afternoon&lt;/head&gt;&lt;p&gt;Migrating content from multiple sources to Mintlify and building a knowledge base in hours, not weeks.&lt;/p&gt;January 13, 2026&lt;p&gt;Anahita Sahu&lt;/p&gt;&lt;p&gt;Chief of Staff&lt;/p&gt;&lt;p&gt;Michael Ryaboy&lt;/p&gt;&lt;p&gt;Content Strategist&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mintlify.com/blog/install-md-standard-for-llm-executable-installation"/><published>2026-01-16T22:15:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46653721</id><title>FLUX.2 [Klein]: Towards Interactive Visual Intelligence</title><updated>2026-01-17T10:10:21.792323+00:00</updated><content>&lt;doc fingerprint="9d927013843c0b86"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLUX.2 [klein]: Towards Interactive Visual Intelligence&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Models&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FLUX.2 [klein]: Towards Interactive Visual Intelligence&lt;/head&gt;
    &lt;p&gt;Today, we release the FLUX.2 [klein] model family, our fastest image models to date. FLUX.2 [klein] unifies generation and editing in a single compact architecture, delivering state-of-the-art quality with end-to-end inference as low as under a second. Built for applications that require real-time image generation without sacrificing quality, and runs on consumer hardware with as little as 13GB VRAM.&lt;/p&gt;
    &lt;p&gt;Demo showing editing with FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h3"&gt;Why go [klein]?&lt;/head&gt;
    &lt;p&gt;Visual Intelligence is entering a new era. As AI agents become more capable, they need visual generation that can keep up; models that respond in real-time, iterate quickly, and run efficiently on accessible hardware.&lt;/p&gt;
    &lt;p&gt;The klein name comes from the German word for "small", reflecting both the compact model size and the minimal latency. But FLUX.2 [klein] is anything but limited. These models deliver exceptional performance in text-to-image generation, image editing and multi-reference generation, typically reserved for much larger models.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's New&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sub-second inference. Generate or edit images in under 0.5s on modern hardware.&lt;/item&gt;
      &lt;item&gt;Photorealistic outputs and high diversity, especially in the base variants.&lt;/item&gt;
      &lt;item&gt;Unified generation and editing. Text-to-image, image editing, and multi-reference support in a single model while delivering frontier performance.&lt;/item&gt;
      &lt;item&gt;Runs on consumer GPUs. The 4B model fits in ~13GB VRAM (RTX 3090/4070 and above).&lt;/item&gt;
      &lt;item&gt;Developer-friendly &amp;amp; Accessible: Apache 2.0 on 4B models, open weights for 9B models. Full open weights for customization and fine-tuning.&lt;/item&gt;
      &lt;item&gt;API and open weights. Production-ready API or run locally with full weights.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: The “FLUX [dev] Non-Commercial License” has been renamed to “FLUX Non-Commercial License” and will apply to the 9B Klein models. No material changes have been made to the license.&lt;/p&gt;
    &lt;p&gt;Text to Image collage using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h3"&gt;The FLUX.2 [klein] Model Family&lt;/head&gt;
    &lt;head rend="h4"&gt;FLUX.2 [klein] 9B&lt;/head&gt;
    &lt;p&gt;Our flagship small model. Defines the Pareto frontier for quality vs. latency across text-to-image, single-reference editing, and multi-reference generation. Matches or exceeds models 5x its size - in under half a second. Built on a 9B flow model with 8B Qwen3 text embedder, step-distilled to 4 inference steps.&lt;/p&gt;
    &lt;p&gt;Combine multiple input images, blend concepts, and iterate on complex compositions - all at sub-second speed with frontier-level quality. No model this fast has ever done this well.&lt;/p&gt;
    &lt;p&gt;License: FLUX NCL&lt;/p&gt;
    &lt;p&gt;Imagine editing collage using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h4"&gt;&lt;lb/&gt;FLUX.2 [klein] 4B:&lt;/head&gt;
    &lt;p&gt;Fully open under Apache 2.0. Our most accessible model, it runs on consumer GPUs like the RTX 3090/4070. Compact but capable: supports T2I, I2I, and multi-reference at quality that punches above its size. Built for local development and edge deployment.&lt;/p&gt;
    &lt;p&gt;License: Apache 2.0&lt;/p&gt;
    &lt;head rend="h4"&gt;FLUX.2 [klein] Base 9B / 4B:&lt;/head&gt;
    &lt;p&gt;The full-capacity foundation models. Undistilled, preserving complete training signal for maximum flexibility. Ideal for fine-tuning, LoRA training, research, and custom pipelines where control matters more than speed. Higher output diversity than the distilled models.&lt;/p&gt;
    &lt;p&gt;License: 4B Base under Apache 2.0, 9B Base under FLUX NCL&lt;/p&gt;
    &lt;p&gt;Output Diversity using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h4"&gt;Quantized versions&lt;/head&gt;
    &lt;p&gt;We are also releasing FP8 and NVFP4 versions of all [klein] variants, developed in collaboration with NVIDIA for optimized inference on RTX GPUs. Same capabilities, smaller footprint - compatible with even more hardware.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FP8: Up to 1.6x faster, up to 40% less VRAM&lt;/item&gt;
      &lt;item&gt;NVFP4: Up to 2.7x faster, up to 55% less VRAM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Benchmarks on RTX 5080/5090, T2I at 1024×1024&lt;lb/&gt;Same licenses apply: Apache 2.0 for 4B variants, FLUX NCL for 9B.&lt;/p&gt;
    &lt;head rend="h4"&gt;&lt;lb/&gt;Performance Analysis&lt;/head&gt;
    &lt;p&gt;FLUX.2 [klein] Elo vs Latency (top) and VRAM (bottom) across Text-to-Image, Image-to-Image Single Reference, and Multi-Reference tasks. FLUX.2 [klein] matches or exceeds Qwen's quality at a fraction of the latency and VRAM, and outperforms Z-Image while supporting both text-to-image generation and (multi-reference) image editing in a unified model. The base variants trade some speed for full customizability and fine-tuning, making them better suited for research and adaptation to specific use cases. Speed is measured on a GB200 in bf16.&lt;/p&gt;
    &lt;head rend="h3"&gt;Into the New&lt;/head&gt;
    &lt;p&gt;FLUX.2 [klein] is more than a faster model. It's a step toward our vision of interactive visual intelligence. We believe the future belongs to creators and developers with AI that can see, create, and iterate in real-time. Systems that enable new categories of applications: real-time design tools, agentic visual reasoning, interactive content creation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources&lt;/head&gt;
    &lt;p&gt;Try it&lt;/p&gt;
    &lt;p&gt;Build with it&lt;/p&gt;
    &lt;p&gt;Learn more&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence"/><published>2026-01-16T23:46:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46654085</id><title>Keifu – A TUI for navigating commit graphs with color and clarity</title><updated>2026-01-17T10:10:21.233352+00:00</updated><content>&lt;doc fingerprint="323a5dcae4fcdf83"&gt;
  &lt;main&gt;
    &lt;p&gt;keifu (系譜, /keːɸɯ/) is a terminal UI tool that visualizes Git commit graphs. It shows a colored commit graph, commit details, and a summary of changed files, and lets you perform basic branch operations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Readable commit graph — &lt;code&gt;git log --graph&lt;/code&gt;is hard to read; keifu renders a cleaner, color-coded graph&lt;/item&gt;
      &lt;item&gt;Fast branch switching — With AI-assisted coding, working on multiple branches in parallel has become common. keifu makes branch switching quick and visual&lt;/item&gt;
      &lt;item&gt;Keep it simple — Only basic Git operations are supported; this is not a full-featured Git client&lt;/item&gt;
      &lt;item&gt;Narrow terminal friendly — Works well in split panes and small windows&lt;/item&gt;
      &lt;item&gt;No image protocol required — Works on any terminal with Unicode support&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unicode commit graph with per-branch colors&lt;/item&gt;
      &lt;item&gt;Commit list with branch labels, date, author, short hash, and message (some fields may be hidden on narrow terminals)&lt;/item&gt;
      &lt;item&gt;Commit detail panel with full message and changed file stats (+/-)&lt;/item&gt;
      &lt;item&gt;Git operations: checkout, create/delete branch, fetch&lt;/item&gt;
      &lt;item&gt;Branch search with dropdown UI&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run inside a Git repository (auto-discovery from current directory)&lt;/item&gt;
      &lt;item&gt;A terminal with Unicode line drawing support and color&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git&lt;/code&gt;command in PATH (required for fetch)&lt;/item&gt;
      &lt;item&gt;Rust toolchain (for building from source)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cargo install keifu&lt;/code&gt;
    &lt;code&gt;mise use -g github:trasta298/keifu@latest&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/trasta298/keifu &amp;amp;&amp;amp; cd keifu &amp;amp;&amp;amp; cargo install --path .&lt;/code&gt;
    &lt;p&gt;Run inside a Git repository:&lt;/p&gt;
    &lt;code&gt;keifu&lt;/code&gt;
    &lt;p&gt;See docs/configuration.md for configuration options.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;j&lt;/code&gt; / &lt;code&gt;↓&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Move down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;k&lt;/code&gt; / &lt;code&gt;↑&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Move up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;]&lt;/code&gt; / &lt;code&gt;Tab&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Jump to next commit that has branch labels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;[&lt;/code&gt; / &lt;code&gt;Shift+Tab&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Jump to previous commit that has branch labels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;h&lt;/code&gt; / &lt;code&gt;←&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select left branch (same commit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;l&lt;/code&gt; / &lt;code&gt;→&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select right branch (same commit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Page down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+u&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Page up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;g&lt;/code&gt; / &lt;code&gt;Home&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Go to top&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;G&lt;/code&gt; / &lt;code&gt;End&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Go to bottom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;@&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Jump to HEAD (current branch)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Checkout selected branch/commit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;b&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create branch at selected commit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Delete branch (local, non-HEAD)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;f&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fetch from origin&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search branches (incremental fuzzy search)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;↑&lt;/code&gt; / &lt;code&gt;Ctrl+k&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select previous result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;↓&lt;/code&gt; / &lt;code&gt;Ctrl+j&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Select next result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Jump to selected branch&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;Esc&lt;/code&gt; / &lt;code&gt;Backspace&lt;/code&gt; on empty&lt;/cell&gt;
        &lt;cell&gt;Cancel search&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;R&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Refresh repository data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle help&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;q&lt;/code&gt; / &lt;code&gt;Esc&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Quit&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The TUI loads up to 500 commits across all branches.&lt;/item&gt;
      &lt;item&gt;Merge commits are diffed against the first parent; the initial commit is diffed against an empty tree.&lt;/item&gt;
      &lt;item&gt;Changed files are capped at 50 and binary files are skipped.&lt;/item&gt;
      &lt;item&gt;If there are staged or unstaged changes (excluding untracked files), an "uncommitted changes" row appears at the top.&lt;/item&gt;
      &lt;item&gt;When multiple branches point to the same commit, the label is collapsed to a single name with a &lt;code&gt;+N&lt;/code&gt;suffix (e.g.,&lt;code&gt;main +2&lt;/code&gt;). Use&lt;code&gt;h&lt;/code&gt;/&lt;code&gt;l&lt;/code&gt;or&lt;code&gt;←&lt;/code&gt;/&lt;code&gt;→&lt;/code&gt;to switch between them.&lt;/item&gt;
      &lt;item&gt;Checking out &lt;code&gt;origin/xxx&lt;/code&gt;creates or updates a local branch. Upstream is set only when creating a new branch. If the local branch exists but points to a different commit, it is force-updated to match the remote.&lt;/item&gt;
      &lt;item&gt;Remote branches are displayed, but delete operations only work with local branches.&lt;/item&gt;
      &lt;item&gt;Fetch requires the &lt;code&gt;origin&lt;/code&gt;remote to be configured.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/trasta298/keifu"/><published>2026-01-17T00:32:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46654749</id><title>Drone Hacking Part 1: Dumping Firmware and Bruteforcing ECC</title><updated>2026-01-17T10:10:19.625995+00:00</updated><content>&lt;doc fingerprint="ae645296a9a5069d"&gt;
  &lt;main&gt;
    &lt;p&gt;~48 min read&lt;/p&gt;
    &lt;head rend="h1"&gt;Drone Hacking Part 1: Dumping Firmware and Bruteforcing ECC&lt;/head&gt;
    &lt;head rend="h2"&gt;Intro&lt;/head&gt;
    &lt;p&gt;In July 2025, we from Neodyme got together in Munich and did security research on a bunch of IoT devices, ranging from bluetooth headsets, to door locks, to drones. One of these was the Potensic Atom 2. It’s a photo and video drone with a gimbal-stabilized 4K camera and a remote control that you hook up to your own smartphone and the proprietary app. If you’ve ever flown a DJI Mini 4K, this drone will look very familiar to you.&lt;/p&gt;
    &lt;p&gt;This post is part of a two-part series that will cover how we disassembled the drone and dumped the firmware from the NAND chip and how we analyzed the drone’s firmware, app, and remote control to find some backdoors and vulnerabilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Goal: Dumping the Firmware&lt;/head&gt;
    &lt;p&gt;One of the most important pieces of information you can acquire when setting up to hack a device is its firmware. If you want to reverse engineer the software that’s running on the drone and find vulnerabilities in that, then you need a copy of it in the first place.&lt;/p&gt;
    &lt;p&gt;Now there are a couple of ways to go about that, some are less intrusive and some are more effective.&lt;/p&gt;
    &lt;p&gt;You might get lucky and be able to just download the firmware as a firmware update from the manufacturer’s website. However, those update sites are often not publicly documented and can be locked behind authorization checks or encrypted. Encrypted firmwares can still be useful - you “just” need to reverse engineer the on-device decryption process. For the Atom 2, downloading the firmware updates required having a valid drone and remote control serial number and the firmware update was also encrypted. Without having the decryption logic, we put this approach on ice during our initial research.&lt;/p&gt;
    &lt;p&gt;Another really comfortable approach is to use exposed debug interfaces like JTAG or UART. However, those are often undocumented, unlabeled, or entirely removed for public versions. We didn’t find any on the Atom 2.&lt;/p&gt;
    &lt;p&gt;What we can always do, though not necessarily always successful, is solder off the entire NAND chip and dump the firmware byte by byte. This has the risk of breaking the NAND chip and/or the rest of the board if you’re not careful. Also, some devices, like modern smart phones, encrypt their persistent storage with key material stored in, e.g., the TPM. If that is the case, then simply soldering off the NAND chip will leave you with unusable encrypted data. Fortunately, the Atom 2’s NAND contents are not encrypted, as we find out later.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dumping the NAND Chip&lt;/head&gt;
    &lt;p&gt;Dumping a NAND chip generally always follows the same pattern:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Identifying the NAND Chip&lt;/item&gt;
      &lt;item&gt;Removing it from the board&lt;/item&gt;
      &lt;item&gt;Identifying the data pins and communication protocol of the NAND chip&lt;/item&gt;
      &lt;item&gt;Connecting the NAND chip to some kind of reading device&lt;/item&gt;
      &lt;item&gt;Reading the NAND content&lt;/item&gt;
      &lt;item&gt;Reassembling the read contents into a working firmware - usually containing one or more file systems&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Identifying the NAND Chip&lt;/head&gt;
    &lt;p&gt;The Atom 2 has multiple boards:&lt;/p&gt;
    &lt;p&gt;We are mainly interested in the main board because that’s where the NAND flash is going to be. The main board had several metal RF shields that we have already pried off or cut through on the photos.&lt;/p&gt;
    &lt;p&gt;We can identify most of these chips through their markings. Note that while we’re mainly interested in the NAND chip, knowing the others can help with recognizing things during reversing later on. Roughly knowing which SoC we were working with was crucial, as you will see in later sections of this blog post.&lt;/p&gt;
    &lt;p&gt;(Note that the markings below might not match the photos completely. We had multiple drones. The markings are mostly from the first drone and the photos are mostly of the second drone.)&lt;/p&gt;
    &lt;head rend="h4"&gt;Top-side&lt;/head&gt;
    &lt;p&gt;SoC (System on a Chip, aka “the main thingy”)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: 23AP10 VTQMSQKJYJ 4978-CN B3&lt;/item&gt;
      &lt;item&gt;We didn’t find an exact match, but this site references the 21AP10. &lt;list rend="ul"&gt;&lt;item&gt;The page title is &lt;code&gt;21AP10 SS928 平替SD3403V100 海思 SOC芯片&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;21AP10 SS928 平替&lt;/code&gt;=&amp;gt;&lt;code&gt;21AP10 SS928 Drop-In Replacement&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;SD3403V100 海思 SOC芯片&lt;/code&gt;=&amp;gt;&lt;code&gt;HiSilicon SD3403V100 SOC Chip&lt;/code&gt;&lt;/item&gt;&lt;item&gt;That is a mobile camera SoC.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The page title is &lt;/item&gt;
      &lt;item&gt;It makes sense that this is the SoC because it is close to both external RAM chips and the NAND flash.&lt;/item&gt;
      &lt;item&gt;In this teardown of a previous Atom model, the device had a &lt;code&gt;HiSilicon Hi 3559 camera MCU&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;We found a data sheet for the HiSilicon Hi3519 V100. &lt;list rend="ul"&gt;&lt;item&gt;Close enough for now.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RAM&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: SEC340 K4A8G16 5WC BCTD G2F9190AC&lt;/item&gt;
      &lt;item&gt;Data sheet can be found on the internet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ARM Cortex-M4&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: GD32F470 VGH6 BUMK618 AL2451 GigaDevice ARM&lt;/item&gt;
      &lt;item&gt;Data sheet can be found on the internet.&lt;/item&gt;
      &lt;item&gt;Might be SD-card related since the SD card slot is on the other side.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unknown Chips&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: V2 2441TM4N190.00 &lt;list rend="ul"&gt;&lt;item&gt;The name &lt;code&gt;2441TM&lt;/code&gt;appears in some WizSense surveillance cameras&lt;/item&gt;&lt;item&gt;Not sure if related&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The name &lt;/item&gt;
      &lt;item&gt;2 chips with markings: 8285HE 426656 CS2441&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Bottom Side&lt;/head&gt;
    &lt;p&gt;NAND flash&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: MXIC X243662 MX35UF4GE4AD-241 5P231800A1&lt;/item&gt;
      &lt;item&gt;Data sheet can be found on the internet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RAM&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: SEC407 K4A8G16 5WC BCTD G2K43304C&lt;/item&gt;
      &lt;item&gt;Same as on top side&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ARM Cortex-M4&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Markings: F460JEUA P8VR4400 2416021&lt;/item&gt;
      &lt;item&gt;Not sure what it’s used for.&lt;/item&gt;
      &lt;item&gt;A data sheet for the HC32F460JEUA-QFN48TR (looks close enough?) can be found on the internet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;WLAN + Bluetooth&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RTL8821CS&lt;/item&gt;
      &lt;item&gt;Data sheet can be found on the internet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Removing the NAND Chip from the board&lt;/head&gt;
    &lt;p&gt;Now that we have identified the NAND chip, we fasten the board and tape off the remaining components with heat-shielding tape.&lt;/p&gt;
    &lt;p&gt;Usually getting the chip off of the board is just a matter of using hot air station and flux. However, you can see on the photos that the chip is actually glued to the main board with what is probably epoxy. That’s a thing you can do if you want to secure the chips more securely and not depend on the solder joints to hold your chip in place (and risk breaking them). Or you can do that just to the NAND chip to make it harder for researcher to pry off your NAND chip and dump your firmware.&lt;/p&gt;
    &lt;p&gt;Anyway, a few cuts with a sharp knife, some heat and a generous amount of flux later, the little bugger came off in one piece.&lt;/p&gt;
    &lt;p&gt;(And with it, a couple of extremely tiny resistors that I knocked off with my pliers and promptly lost. This main board is now broken. But don’t worry, through the magic of buying &lt;del&gt;two&lt;/del&gt; three of them, we can still fly the drone.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Identifying the data pins and communication protocol of the NAND chip&lt;/head&gt;
    &lt;p&gt;According to the data sheet of the MX35UF4GE4AD NAND chip, the flash chip can either come in a 24-pin BGA package or an 8-pin WSON package, which we have here. A quick look at the pin descriptions tell us that the NAND chip is communicating via SPI.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Pin Symbol&lt;/cell&gt;
        &lt;cell role="head"&gt;Pin Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CS#&lt;/cell&gt;
        &lt;cell&gt;Chip Select&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SI&lt;/cell&gt;
        &lt;cell&gt;Serial Data Input&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SO&lt;/cell&gt;
        &lt;cell&gt;Serial Data Output&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SCLK&lt;/cell&gt;
        &lt;cell&gt;Clock Input&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;WP#&lt;/cell&gt;
        &lt;cell&gt;Write protection&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;HOLD#&lt;/cell&gt;
        &lt;cell&gt;Hold&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;VCC&lt;/cell&gt;
        &lt;cell&gt;Power Supply (1.8 V)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GND&lt;/cell&gt;
        &lt;cell&gt;Ground&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DNU&lt;/cell&gt;
        &lt;cell&gt;Do Not Use&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Well, let’s solder tiny copper cables to all of those pins and drown them in a bit of hot glue to stop them from breaking off.&lt;/p&gt;
    &lt;p&gt;Note that you can get a proper socket for 8-WSON chips into which you simply clamp the chip and which exposes easy-to-work-with breakout pins. None of our sockets we brought fit though, so we just did it the old-school way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Connecting the NAND chip to some kind of reading device&lt;/head&gt;
    &lt;p&gt;SPI is pretty easy to work with. We have two main data lines called SI and SO (Serial In/Out). You will also find them under the names “MOSI” and “MISO” (Master Out Slave In / Master In Slave Out). As the names of these suggest, SPI follows a master-slave architecture. The microcontroller drives the communication and the peripheral device reacts.&lt;/p&gt;
    &lt;p&gt;Fortunately, we are simulating the microcontroller-side of the communication, which means that we have a large amount of control. Specifically, we control the clock (SCLK). Sometimes it is hard to talk to embedded hardware because of the speed at which they operate. With SPI, however, we can slow down the clock to however fast we want the devices to talk.&lt;/p&gt;
    &lt;p&gt;Since SPI is a bus protocol, more than one slave device can be hooked up to a master device on the same data lines. To avoid collisions, each device is also assigned its own “Chip Select” line (CS). When the master device wants to talk to a specific slave device, it pulls the corresponding CS line low. Devices that have their CS line high won’t react at all.&lt;/p&gt;
    &lt;p&gt;Obviously there are fancy devices on the market that will make dumping a NAND chip via SPI pretty easy and straightforward. Problem is, we couldn’t get any of them to work. They either didn’t fit (physically), were too fast or failed for some other strange reason we didn’t understand. So we wrote our own dump script onto an ESP32 using the SPI commands in the data sheet and let it forward the data to our computer via the USB console.&lt;/p&gt;
    &lt;p&gt;Doing that, we ended up with a 544 MiB dump, containing 131,072 pages of 4096+256 bytes. (We will come back to that “+256” later on.)&lt;/p&gt;
    &lt;p&gt;Let’s dig into what this the flash dump contains with &lt;code&gt;binwalk&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Sweet! We get a working ASCII copyright string, so something must have worked. And at the end of the image we have a bunch of UBIFS images. That’s probably where all the juicy files are!&lt;/p&gt;
    &lt;p&gt;Let’s extract them with &lt;code&gt;dd&lt;/code&gt; and take a look inside with ubi_reader:&lt;/p&gt;
    &lt;p&gt;Hmm. That doesn’t work. Spoiler: The extracted image is broken.&lt;/p&gt;
    &lt;p&gt;Now if you’ve ever done something as hacky as this, you will know about a pesky little phenomenon that happens when you just solder copper wires onto a chip, stick that onto the ports of an ESP32 and do SPI communication - which has no built-in integrity checks.&lt;/p&gt;
    &lt;head rend="h4"&gt;Random Bit Flips&lt;/head&gt;
    &lt;p&gt;These are three dumps taken from the same NAND chip:&lt;/p&gt;
    &lt;p&gt;If you read 4 MiB of data from the chip, not all of the bits you receive are correct. And without any additional data, you have little way of knowing which ones are correct and which are not. If you are lucky, then the dumped data will still “work”, i.e., the contained file system will mount and you can browse files, but futher down the line you will have no way of knowing whether that weird function you’re reversing is actually weird or just the product of random bit flips messing up the CPU instructions.&lt;/p&gt;
    &lt;p&gt;A relatively simple yet time-consuming way to get around this: Read the flash often (at least three times) and hold a majority vote for every bit. Since the bit flips are random and not too prevalent, they are less likely to hit the same bit twice.&lt;/p&gt;
    &lt;p&gt;Hot tip: If you’re gonna work with python, use numpy and work on arrays and memory-mapped files. Otherwise this can take a lot of time and a lot of RAM - even for a 512 MiB flash dump.&lt;/p&gt;
    &lt;p&gt;But isn’t there a better way? Yes, there is. And - btw - even with completely correct majority voting, the flash content is still broken. But we’ll get to that.&lt;/p&gt;
    &lt;p&gt;Trying to work with the majority-voted dump:&lt;/p&gt;
    &lt;head rend="h2"&gt;Out-of-band bytes and ECC troubles&lt;/head&gt;
    &lt;p&gt;One thing we have have silently brushed aside for now: The NAND chip distinguishes between “user data” and “extra data”. In our dump above, we have naively concatenated it all together and assumed that a page size of 4096+256 bytes somehow makes sense. Of course, it doesn’t.&lt;/p&gt;
    &lt;p&gt;Also, this majority voting hack is obviously not the “correct” way to work with a NAND chip. And even the proper SoC mounted on the proper mainboard can’t run a system off of a flash chip that gives it random bit flips that it can’t detect or recover from. The problem is that NAND is just inherently imperfect storage. Majority voting only corrects for transmission errors during dumping, but does nothing to bit errors that are stored on the device! Bits on the storage might decay over time, or the CPU might also have some transmission errors during writing.&lt;/p&gt;
    &lt;p&gt;Of course this problem has been very well known for a long time, so manufacturers always include some extra space next to user data for “error correction”. These extra bytes are called “out-of-band” bytes. And they are used to implement Error Correction Codes (ECC).&lt;/p&gt;
    &lt;head rend="h3"&gt;ECC according to the NAND chip data sheet&lt;/head&gt;
    &lt;p&gt;The flash chip implements its own error correction algorithm by reserving some of the space for ECC. It is split into&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2048 blocks of&lt;/item&gt;
      &lt;item&gt;64 pages of&lt;/item&gt;
      &lt;item&gt;4096 user data bytes + 256 “extra” bytes (aka out-of-band bytes)&lt;/item&gt;
      &lt;item&gt;=&amp;gt; 512 MiB of user data (the chip is 4 Gb, not 4 GB)&lt;/item&gt;
      &lt;item&gt;=&amp;gt; 32 MiB of extra data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the chip-internal ECC is enabled, some of those extra bytes are used for ECC.&lt;/p&gt;
    &lt;p&gt;At this point, we naively assumed that each page would be&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;4096 bytes of user data followed by&lt;/item&gt;
      &lt;item&gt;256 (or less?) bytes of ECC covering the previous 4096 bytes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, we quickly found out that the sequences classified as “extra data” contain readable strings! That definitely suggests that this isn’t ECC data.&lt;/p&gt;
    &lt;p&gt;You can also see that there are parts within the user data where strings are suddenly cut off. This suggests that the ECC layout we assumed was wrong. It took us quite a while to figure out what exactly we missed.&lt;/p&gt;
    &lt;head rend="h4"&gt;Entropy Analysis&lt;/head&gt;
    &lt;p&gt;Turns out, the ECC layout is not just 4096 bytes of user data followed by 256 bytes of ECC. If we put all pages next to each other and then calculate the entropy over each n-th byte of a page, we will find that there are multiple sections with high entropy:&lt;/p&gt;
    &lt;p&gt;Why are we looking at entropy? Well, because we expect the user data to have ASCII text (low entropy) every now and then and the ECC data to be mostly random-looking byte values (high entropy).&lt;/p&gt;
    &lt;p&gt;The graph we’re seeing up here suggests that there are sections of roughly 1 KiB of user data, followed by 28 bytes of ECC data. Specifically,&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1028 B user data + 28 B ECC&lt;/item&gt;
      &lt;item&gt;1028 B user data + 28 B ECC&lt;/item&gt;
      &lt;item&gt;1028 B user data + 28 B ECC&lt;/item&gt;
      &lt;item&gt;1014 B user data + 28 B ECC&lt;/item&gt;
      &lt;item&gt;142 B unused&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why these stranges values? And which ECC algorithm is that? We can choose to ignore that and just extract the user data sections and stitch them together. I won’t spam you with more &lt;code&gt;binwalk&lt;/code&gt; and &lt;code&gt;dd&lt;/code&gt; screenshots and just tell you that that also won’t result in a readable UBIFS image. Fortunately, we find an explanation for these values in the next section!&lt;/p&gt;
    &lt;head rend="h3"&gt;ECC according to the SoC data sheet&lt;/head&gt;
    &lt;p&gt;At this point, we had already spent a lot of time fiddling with unstable reading setups and ECC layouts. And then we found that some further digging into the right documentation could have saved us a lot of time during our research. Because the SoC also does ECC. Not just the NAND chip. In fact, we can ignore the NAND chips ECC feature completely.&lt;/p&gt;
    &lt;p&gt;The SoC’s data sheet lists several possible ECC layouts. One of them is the following:&lt;/p&gt;
    &lt;p&gt;Well, that fits our findings perfectly, plus a BB (“bad blocks”) and CTRL (some kind of control bytes?) area that we didn’t identify before.&lt;/p&gt;
    &lt;p&gt;Using this diagram, we can cut out all the ECC, BB and CTRL sections and reconstruct the pure 512 MiB user data flash content.&lt;/p&gt;
    &lt;p&gt;Heyyy, look at that! We managed to extract a file system again - albeit with some error remaining. Let’s see what’s on it:&lt;/p&gt;
    &lt;p&gt;Hmm. Damn. The UBIFS image is now at least somewhat syntactically correct. But it is still broken enough to not have any files. Why could that be? Well, we are looking at exactly what the SoC would see after reading the data from the NAND chip. Plus that we have done majority voting on the bytes - so our version is even better than what the SoC would see.&lt;/p&gt;
    &lt;p&gt;But, there is no guarantee that there aren’t any random bit flips on the NAND chip, i.e., that random bit flipping happened during writing, desoldering or anytime between that! So, there seems to no way around actually implementing the ECC algorithm and correcting the bit flips on the flash dump. Problem is: What kind of ECC algorithm is the SoC running? Unfortunately, the datasheet is silent here, so we had to find out on our own.&lt;/p&gt;
    &lt;head rend="h3"&gt;A short primer on reverse engineering ECC algorithms&lt;/head&gt;
    &lt;p&gt;Typical ECC algorithms on NAND chips use BCH codes, which are parametrized by the following properties:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The amount of parity bits.&lt;/item&gt;
      &lt;item&gt;The correction capacity &lt;code&gt;t&lt;/code&gt;, i.e., how many simultaneous bit flips may appear in the same data block before the block is “too broken” and the ECC algorithm fails.&lt;/item&gt;
      &lt;item&gt;The primitive polynomial used in the equation. If you don’t know what this is, just think of it as an integer parameter for now.&lt;/item&gt;
      &lt;item&gt;Whether and how the data is transformed before the parity bits are calculated.&lt;/item&gt;
      &lt;item&gt;Whether and how the parity bits are transformed after they are calculated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can deduce (1) and (2) from our flash dump. For (3), (4), and (5) we have to either find the code of the SoC (if it is implement in software at all) and reverse engineer the ECC algorithm - or just bruteforce them.&lt;/p&gt;
    &lt;head rend="h4"&gt;Amount of parity bits&lt;/head&gt;
    &lt;p&gt;As we have seen in the SoC’s data sheet, we have 112 byte of ECC / parity bits. However, the fragmented layout on the flash suggests that we actually have 4 ECC groups of 28 byte, each covering a different part of the user data. Note that this is an educated guess and does not have to be true. If we’re not getting anywhere, we should consider dropping this assumption later on. But spoiler: We’re right about this.&lt;/p&gt;
    &lt;p&gt;This means that we have 224 parity bits (= 28 bytes).&lt;/p&gt;
    &lt;head rend="h4"&gt;Correction capacity&lt;/head&gt;
    &lt;p&gt;This part we can just calculate if we make one very realistic assumption. We have 1028 bytes of user data, which is 8224 bits. If we want to represent these 8224 bits as a binary polynomial, we need at least degree 14:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;2^13 =  8192&lt;/code&gt; &amp;lt; - Too small
&lt;code&gt;2^14 = 16384&lt;/code&gt; &amp;lt; - Fits!&lt;/p&gt;
    &lt;p&gt;This means our primitive polynomial needs to be at least degree 14 (&lt;code&gt;m &amp;gt;= 14&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The correction capacity is determined by the degree &lt;code&gt;m&lt;/code&gt; and the amount of parity bits. The more parity bits we have in relation to &lt;code&gt;m&lt;/code&gt;, the higher our correction capacity &lt;code&gt;t&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;t = parity_bits / m&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Now given that &lt;code&gt;parity_bits&lt;/code&gt; is fixed at 224 and assuming that the engineers chose &lt;code&gt;t&lt;/code&gt; to be maximal, we conclude that &lt;code&gt;m = 14&lt;/code&gt; and&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;t = 224 / 14 = 16&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;meaning that we can correct for up to 16 bit flips in the covered user data chunk. Anything more than that and the chunk is lost.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;t = 16&lt;/code&gt; also fits the description of the ECC section in the SoC’s data sheet: “16-Bit/1KB Error Correction Performance” (see our diagram above). So we are pretty certain that this assumption is correct.&lt;/p&gt;
    &lt;head rend="h4"&gt;Primitive polynomial&lt;/head&gt;
    &lt;p&gt;We don’t know that and we will have to bruteforce it. Given that it is a binary polynomial, it is usually represented as a bit vector or simply as an integer. Given that &lt;code&gt;m = 14&lt;/code&gt; we already know that our polynomial must have its 14th bit set and that the 14th bit is the highest bit that is set:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;2^14 &amp;lt;= prim_poly &amp;lt; 2^15&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;which is well within bruteforcing range.&lt;/p&gt;
    &lt;head rend="h4"&gt;Pre-encode and post-encode transformations&lt;/head&gt;
    &lt;p&gt;There are a few transformations that are commonly applied to either the user data before calculating the parity bits (“encoding”) or applied to the parity bits after calculating them. Examples include&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reverse bit order&lt;/item&gt;
      &lt;item&gt;reverse byte order&lt;/item&gt;
      &lt;item&gt;swap nibbles&lt;/item&gt;
      &lt;item&gt;invert&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why you ask? Well, one of these combinations for example is very useful for NAND storage devices. You see, when NAND pages are erased and then read, their values are all &lt;code&gt;0xFF&lt;/code&gt;. Problem is, a page full of &lt;code&gt;0xFF&lt;/code&gt; will have&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;user data = &lt;code&gt;0xFFFF...&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ECC = &lt;code&gt;0xFFFF...&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;and that is not a valid parity, meaning a cleanly erased page will be read as containing a lot of errors. That is because&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;parity(0xFF...) != 0xFF...&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;But we can pull a trick to make this work: Before encoding, invert the user data. And after encoding, invert the parity bits:&lt;/p&gt;
    &lt;p&gt;Notice that the parity of an all-zero page is all-zero:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;parity(0x00...) != 0x00...&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;So by implementing our ECC algorithm with these two inversions, we make a freshly erased page (&lt;code&gt;0xFF...&lt;/code&gt;) have a valid parity (&lt;code&gt;0xFF...&lt;/code&gt;) and the SoC’s error correction won’t need special handling for erased NAND pages.&lt;/p&gt;
    &lt;p&gt;Okay, back to the actual algorithm at hand here. How do we know that these two inversions are what the engineers actually chose? We don’t! We just try all these different transformations and see if one of them works. The amount of possible combinations of these 4 transformations is quite low and easily bruteforcable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Brute-forcing ECC parameters&lt;/head&gt;
    &lt;p&gt;In summary, to test our guessed parameters, we need a user data section without errors, generate its ECC and check if it matches the ECC that we read off of the NAND chip. Our bruteforce script thus has to do the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Find a “good” user data section with no bit flips and the corresponding ECC section.&lt;/item&gt;
      &lt;item&gt;Iterate through all possible transformations.&lt;/item&gt;
      &lt;item&gt;Iterate through all possible primitive polynomials of degree 14&lt;/item&gt;
      &lt;item&gt;For each iteration, generate the ECC of the userdata section. If it matches the existing ECC, we have found the parameters.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Picking a “good” user data section&lt;/head&gt;
    &lt;p&gt;We need a user data section and its corresponding ECC section without bit flips. But how do we know that a section does not have bit flips? We don’t! We could try to be clever here. One possible approach would be to pick a section with a lot of text and check if the text makes sense. But the lazy approach works just as well: Just try a lot of sections and hope that one of them is correct. More bruteforce. Yeah.&lt;/p&gt;
    &lt;p&gt;As you can see in the script above, we only look at the first section of every page and then move on to the next page entirely. We’re not completely sure yet which ECC bytes cover which user data sections - especially since the 4th section looks fragmented. But we will stick to our assumption that the first 1028 bytes of user data are covered by the first 28 bytes of ECC. Spoiler: We’re right about this. Another Spoiler: The first 3 pages have bit-flips in their first section. The 4th one is good.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterate through all possible transformations&lt;/head&gt;
    &lt;p&gt;We will try out 4 different transformations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reverse bit order&lt;/item&gt;
      &lt;item&gt;reverse byte order&lt;/item&gt;
      &lt;item&gt;swap nibbles&lt;/item&gt;
      &lt;item&gt;invert&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For these transformation we want all possible subsets and orderings, but without using the same transformation twice in one run.&lt;/p&gt;
    &lt;p&gt;Then we can run through all these combinations as both pre-transformations as well as post-transformations:&lt;/p&gt;
    &lt;p&gt;Note that some combinations are equivalent:&lt;/p&gt;
    &lt;p&gt;We don’t optimize for that though.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterate through all possible primitive polynomials of degree 14&lt;/head&gt;
    &lt;p&gt;There are three ways to do this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A simple and slow way&lt;/item&gt;
      &lt;item&gt;A math-heavy and fast way&lt;/item&gt;
      &lt;item&gt;A much better way that is about as simple as (1) and as fast as (2)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, we went with (1) during our initial research because sometimes thinking just takes longer than computing inefficiently. Afterwards, I spent hours digging into polynomial algebra to come up with (2) and was very happy about it - only to also find (3) right afterwards which was a lot simpler and equally as good… Oh well, at least I got to freshen up on first- and second-semester linear algebra.&lt;/p&gt;
    &lt;p&gt;(1) Simple and slow The simple way would be to just try all polynomials of degree 14. In their integer representation, that’s all integers in &lt;code&gt;range(2**14, 2**15)&lt;/code&gt;
While this will eventually cover the correct primitive polynomial, it will also make bchlib crash the entire script with a SIGSEGV for a lot of non-primitive polynomials.&lt;/p&gt;
    &lt;p&gt;A quick-and-dirty workaround is to just spawn a new process for every candidate polynomial so your main script doesn’t die. And that’s what we did during initial research. It works - but the creation of over 16,000 processes makes this a bit slow. Not too slow to work with though. This approach works in practice.&lt;/p&gt;
    &lt;p&gt;(2) Math-heavy and fast The proper way to do this is to only pass primitive polynomials into BCH’s constructor. But how do we know if the polynomial that is represented by our integer is primitive? By doing lots of math. If you’re not familiar with polynomial algebra (like I was) but really want to know how this works, read the section A brief detour into polynomial algebra in the addendum.&lt;/p&gt;
    &lt;p&gt;Spoiler: It is a lot of thinking work and only about 5% faster than (3) in my tests.&lt;/p&gt;
    &lt;p&gt;(3) Simple and fast Turns out, bchlib only crashes for polynomials with a constant term of 0, i.e., even integers. So if we use &lt;code&gt;range(2**14 + 1, 2**15, 2)&lt;/code&gt;, then it just works without having to fiddle with multiprocessing or math.&lt;/p&gt;
    &lt;p&gt;This will still throw a runtime error for a lot of non-primitive polynomials but we can catch that via try-except:&lt;/p&gt;
    &lt;head rend="h4"&gt;Checking the generated ECC&lt;/head&gt;
    &lt;p&gt;This is straight-forward and self-explanatory.&lt;/p&gt;
    &lt;p&gt;You can find the full ECC Bruteforce Script in the addendum.&lt;/p&gt;
    &lt;head rend="h3"&gt;Restoring the full firmware&lt;/head&gt;
    &lt;p&gt;Now that we have a working ECC setup, let’s reassemble the entire firmware! There is just one little detail that we still need to find out:&lt;/p&gt;
    &lt;p&gt;Which parts of user data are covered by which parts of ECC? We already confirmed that the first user data section is covered by the first 28 bytes of ECC. And the same turns out to be true for the second and third user data section. The fourth section is a bit tricky: It is 928+84 bytes of user data long, with additional BB and CTRL bytes around. What is that about? Turns out, a bit of trial-and-error and looking at the SoC’s data sheet revealed how ECC works for that section.&lt;/p&gt;
    &lt;p&gt;Now we just need to apply that to every page and - voilà - full firmware dump. :tada:&lt;/p&gt;
    &lt;p&gt;The Final Restore Script can be found in the addendum.&lt;/p&gt;
    &lt;p&gt;If we look at the binwalk output for that file, it is much better and looks like it is actually free of errors:&lt;/p&gt;
    &lt;p&gt;When trying to extract the first ubifs image with ubi_reader, we actually get a working file system!&lt;/p&gt;
    &lt;p&gt;ubi_reader still throws an error in the later segments of UBIFS image but this extraction is good enough to start reverse engineering the successfully extracted files. Notably, it is enough to reverse engineer the firmware decryption!&lt;/p&gt;
    &lt;p&gt;Stay tuned for Part 2 of our drone hacking blogpost where we dive into the reverse engineering and vulnerability analysis of the Potensic Atom 2!&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum&lt;/head&gt;
    &lt;head rend="h3"&gt;Final Restore Script&lt;/head&gt;
    &lt;head rend="h3"&gt;ECC Bruteforce Script&lt;/head&gt;
    &lt;head rend="h3"&gt;Primitive Binary Polynomial Generator&lt;/head&gt;
    &lt;head rend="h3"&gt;Fun Fuckups&lt;/head&gt;
    &lt;head rend="h2"&gt;A brief detour into polynomial algebra&lt;/head&gt;
    &lt;p&gt;If you are like me and you’re not really familiar with polynomial algebra, it makes sense to talk about related concepts in the integer world first and then move on to their counterparts in the polynomial world. This helps to get an intuition of what we are actually dealing with.&lt;/p&gt;
    &lt;p&gt;I assume that you are generally familiar with modular arithmetic and prime numbers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Integers and Modulo Rings&lt;/head&gt;
    &lt;p&gt;For now, we are working on the field of integers, i.e., , mathematically denoted .&lt;/p&gt;
    &lt;p&gt;When we introduce a modulus, we get . Explanation for the notation:&lt;/p&gt;
    &lt;p&gt;is some modulus. Not necessary prime at this point. Just an integer - a member of .&lt;/p&gt;
    &lt;p&gt;is all multiples of . So . If were , this would be .&lt;/p&gt;
    &lt;p&gt;Now means: The field but treat all elements as equivalent if they are a multiple of apart - meaning their difference is in . If were , then and would be equivalent, because their difference is , which is a multiple of and thus in .&lt;/p&gt;
    &lt;p&gt;This is exactly what “mod 7” is:&lt;/p&gt;
    &lt;p&gt;So is just all of .&lt;/p&gt;
    &lt;p&gt;Note that this collapses the infinite field of all possible integers down to a finite set of equivalence classes. In , all numbers are either in or are equivalents of one of those. So for practical purposes, there are only possible values in .&lt;/p&gt;
    &lt;p&gt;What do we need primes for? Well, has a practical problem: Sometimes multiplying two things results in a zero. Example for :&lt;/p&gt;
    &lt;p&gt;That is bad if we want to do a lot of multiplication within our modulo ring. Because if we ever accidentally hit a multiple of , we will get and that point it doesn’t matter what we multiply onto that - it will stay . So there are a lot of possible values that all collapse into the same when multiplied with certain numbers.&lt;/p&gt;
    &lt;p&gt;In the field of all integers, , we don’t have that problem. As long as we don’t multiply with itself, the results of a multiplication will never be . Good thing there is a solution for that: Using a prime modulus.&lt;/p&gt;
    &lt;head rend="h3"&gt;Prime Numbers, Finite Fields, and Cycles&lt;/head&gt;
    &lt;p&gt;Prime numbers have the nice feature that the modulo rings they induce, , are fields and not just rings, meaning addition and multiplication work just as well as they do in . In , multiplying by something other than will never result in a multiple of - because is prime and you can’t reach a prime from another number through multiplication. (Multiplying by itself doesn’t count, because .)&lt;/p&gt;
    &lt;p&gt;Because is a field and it has a finite amount of elements , it is called a “finite field” or a “Galois field” and sometimes denoted instead of . To be super precise, is a generalization and means “any finite field with elements”. just happens to be one of those - and is the most popular one.&lt;/p&gt;
    &lt;p&gt;Now we go a step further and look at a concept called primitive root. Before explaining that, let’s take a look at a use case for them first.&lt;/p&gt;
    &lt;p&gt;Imagine you want a pseudorandom permutation of , i.e., you don’t want the sequence but a more random-looking sequence tha still hits all of these numbers. It doesn’t have to be cryptographically random or unpredictable. It just needs to look at bit random - perhaps to de-cluster memory writes for better wear-leveling. Primitive roots give us a nice implementation for that.&lt;/p&gt;
    &lt;p&gt;In , multiplication never yields unless you multiply by . That means you can, e.g., keep doubling a number and will never accidentally hit :&lt;/p&gt;
    &lt;p&gt;Oh look at that, a cycle! This is what will always happen in a finite field. When you keep multiplying by the same number, you will eventually reach the number you started with. And at that point, you are in a cycle.&lt;/p&gt;
    &lt;p&gt;is a bit impractical though because its induced cycle only ever hits the numbers and never hits . Note that no cycle will ever hit , so the maximum cycle we can possible get with a modulus of is cycle length .&lt;/p&gt;
    &lt;head rend="h3"&gt;Primitive Roots and Prime Factors&lt;/head&gt;
    &lt;p&gt;And there are indeed numbers that generate a full cycle!&lt;/p&gt;
    &lt;p&gt;These numbers, numbers that induce a full cycle in a finite field, are called primitive roots. and are each primitive roots modulo . Since their induced cycle has a length of , the so-called order of and is .&lt;/p&gt;
    &lt;p&gt;More generally, a primitive root modulo some prime is a number whose order is , i.e., whose induced cycle has a length of . In that case . Expressed more formally: is a primitive root modulo if and only if the smallest for which is true, is&lt;/p&gt;
    &lt;p&gt;Now then how would you best check if a number is a primitive root modulo ? The obvious solution is to just count upwards from 1 through and check each time. That works but it can take a long time for big numbers. Turns out, we don’t have to check every possible from through . To understand that, take a look at from before:&lt;/p&gt;
    &lt;p&gt;We can see that the cycle has length and contains the numbers . We don’t see the numbers . But what happens when we use but we start at ?&lt;/p&gt;
    &lt;p&gt;Again, a cycle of ! And this time we’ve seen all the remaining numbers . If we instead start at or , we will get the same cycle over . So splits the entire finite field excluding 0 into two subsets: and .&lt;/p&gt;
    &lt;p&gt;Let’s look at another example: and try to find all cycles.&lt;/p&gt;
    &lt;p&gt;So partitions the non-zero elements into `.&lt;/p&gt;
    &lt;p&gt;Notice how all those cycles induced by the same number always have the same size? If you think about it, then that makes perfect sense. When you have but you “start at ”, you’re basically just taking the regular cycle and multiply its elements by . So the resulting cycle must have the same length: .&lt;/p&gt;
    &lt;p&gt;And this isn’t a coincidence. In fact, all cycles induced by the same number always have the same length. And that number always partitions the entire finite field without into disjoint sets of the same size.&lt;/p&gt;
    &lt;p&gt;How does that help us? Well, for it makes the cycle lengths and impossible! Because you can’t cover all non-zero elements by splitting them into sets of size or . More generally, cycles lengths (and thus orders) must always be a divisor of , i.e., the amount of all non-zero elements.&lt;/p&gt;
    &lt;p&gt;This is called Lagrange’s theorem: The order of the subgroup divides the order of the whole group.&lt;/p&gt;
    &lt;p&gt;So to check if is a primitive root, we don’t have to check all from through . We only have to check all divisors of ! Also, we obviously don’t have to check . The only number for which is itself, which always induces a cycle of and is thus never a primitive root for .&lt;/p&gt;
    &lt;p&gt;So we’re down to only having to check all divisors of that are larger than . That already eliminates most of the candidates.&lt;/p&gt;
    &lt;p&gt;But we can go even further!&lt;/p&gt;
    &lt;head rend="h3"&gt;Fast Primitivity Check&lt;/head&gt;
    &lt;p&gt;We only need to check some of the divisors. This is where prime factorization comes into play. Let’s say that we have the prime factors of . We will call these prime factors . Note that itself does not have any prime factors because - well - it is a prime number. But does have prime factors. In fact, will always be one of those prime factors because must be odd to be a prime and must therefore be even.&lt;/p&gt;
    &lt;p&gt;Now what if I told you that we only need to check the divisors of that we can obtain by dividing through a prime factor. Specifically, we only need to check&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;p&gt;Why is that? Well, first of all, notice that the “other divisors” are themselves divisors of either or :&lt;/p&gt;
    &lt;p&gt;And if , then that implies that&lt;/p&gt;
    &lt;p&gt;and so on.&lt;/p&gt;
    &lt;p&gt;Why? Well, because if were equal to one, then&lt;/p&gt;
    &lt;p&gt;and that is a contradiction! You can prove the same for any in general if you want. The general proof works just like this example.&lt;/p&gt;
    &lt;p&gt;Alright, so we only have to check all possible with being a prime factor of .&lt;/p&gt;
    &lt;p&gt;Here is a generator function that will return all primitive roots for a given prime modulus :&lt;/p&gt;
    &lt;p&gt;And you know what? Armed with this, we can not just find primitive roots but also primitive polynomials! We just need to translate this concept to polynomials!&lt;/p&gt;
    &lt;p&gt;… which is a bit tricky.&lt;/p&gt;
    &lt;head rend="h3"&gt;Binary Polynomials, Irreducibility and Primitive Elements&lt;/head&gt;
    &lt;p&gt;Alright, first things first: Polynomials. They can look something like this:&lt;/p&gt;
    &lt;p&gt;And through the black magic of math, we can treat these polynomials as multidimensional numbers:&lt;/p&gt;
    &lt;p&gt;And on these, we can perform the same kind of arithmetic as on integers: Addition, Multiplication, Subtraction, Division - and thus Modulo. Dividing one polynomial by another sounds odd? It is. We’ll skip the details here since we’ve already derailed enough. Just know that the intuition from integer arithmetic carries over to polynomials.&lt;/p&gt;
    &lt;p&gt;Now keep in mind that we are working with binary polynomials, i.e., polynomials whose coefficients are either or . And we can represent those as integers. For example, represents the polynomial&lt;/p&gt;
    &lt;p&gt;We use these binary polynomials because they have a numbers of nice properties that things like BCH error correction codes rely on. For example, we can represent all binary strings of length as a -degree polynomial with binary coefficients. For integers, we’d represent those strings as integers from to . But we would have problems doing modular arithmetic on those strings because isn’t necessarily prime and then isn’t a field. For polynomials, there are nice and efficient ways to build a field over -degree binary polynomials.&lt;/p&gt;
    &lt;p&gt;Throughout this section we have to keep in mind that the integer representation ( in the example above) is just a representation of the polynomial in memory. The polynomial is not an integer and we can’t just do regular integer arithmetic like addition and multiplication with Python’s &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt; with it. Polynomials have their own arithmetic and they work differently.&lt;/p&gt;
    &lt;p&gt;Since we are dealing with binary polynomials, the coefficients of the polynomials are all either or . More formally, the coefficients are elements of , which is basically the same as or “mod 2”.&lt;/p&gt;
    &lt;p&gt;The set of all binary polynomials is called . In CompSci terms, these are all possible bit arrays.&lt;/p&gt;
    &lt;p&gt;So since we’re moving from working on integers to working on binary polynomials, is our binary polynomial-equivalent of , with being all integers and being all binary polynomials.&lt;/p&gt;
    &lt;p&gt;While we used to represent a single integer in , we will use to represent a single polynomial in .&lt;/p&gt;
    &lt;p&gt;Similar to how is the set of all multiples of n, is the set of all multiples of - notice the double-paranthesis.&lt;/p&gt;
    &lt;p&gt;And similar to how is but treating two integers as equivalent if their difference is a multiple of , is but treating two polynomials as equivalent if their difference is a multiple of . It is essentially “mod ” in polynomial world.&lt;/p&gt;
    &lt;p&gt;If we have an integer and can’t be divided by another integer, then is prime. Analogously, if we have a polynomial and can’t be reduced by another polynomial, then is irreducible.&lt;/p&gt;
    &lt;p&gt;If is prime, then there is at least one primitive root in , so that spans the entire . If is irreducible, then there is at least one primitive element in so that spans the entire .&lt;/p&gt;
    &lt;p&gt;(Side note: “primitive root” is a legacy term only used for . “primitive element” is the general term. They mean the same thing.)&lt;/p&gt;
    &lt;p&gt;Also, while the order of is just , the order of is , which is the amount of all possible -bit arrays.&lt;/p&gt;
    &lt;p&gt;Now we are almost there! We have already come far enough where we can recognize that an irreducible polynomial is analogous to a prime integer .&lt;/p&gt;
    &lt;p&gt;Now, what is a primitive polynomial then?&lt;/p&gt;
    &lt;head rend="h3"&gt;Primitive Polynomials&lt;/head&gt;
    &lt;p&gt;Well, that’s simple! A primitive polynomial is an irreducible polynomial with one additional requirement:&lt;/p&gt;
    &lt;p&gt;The super simple polynomial must be a primitive element, i.e., must span the entire .&lt;/p&gt;
    &lt;p&gt;Why is that useful? Well, because that means that every non-zero polynomial in can be represented as for some integer . So every non-zero polynomial can be represented as an integer and we have a random-looking permutation of all non-zero binary polynomials in .&lt;/p&gt;
    &lt;p&gt;And that is what BCH codes use and why we require a primitive polynomial.&lt;/p&gt;
    &lt;p&gt;Now, how do we calculate all primitive polynomials then? We don’t. There are infinitely many. But we can calculate all primitive polynomials of some specific degree ! And how do we do that? Well, using what we have already built for finding primitive roots for integers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Iterate through all possible polynomials of degree . For each candidate , (step 1) &lt;list rend="ul"&gt;&lt;item&gt;check if irreducible. Discard if not. (step 2)&lt;/item&gt;&lt;item&gt;check if (the simple polynomial with integer representation 2) is a primitive element in the finite field induced by . (step 3) &lt;list rend="ul"&gt;&lt;item&gt;the wanted cycle length is the amount of all possible polynomials of degree :&lt;/item&gt;&lt;item&gt;get all prime factors of&lt;/item&gt;&lt;item&gt;check if for all prime factors&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For (step 1), we want a primitive polynomial with degree , so we only consider polynomials where their m-th coefficient is 1 and all higher-order coefficients are 0. This means that their integer representations are in&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;range(2^m, 2^(m+1))&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;To speed it up by factor 2: We can’t have any polynomials where the constant term, i.e., the lowest-order coefficient is zero. Example:&lt;/p&gt;
    &lt;p&gt;(note that there is no at the end)&lt;/p&gt;
    &lt;p&gt;That’s because every polynomial with a zero constant term is divisible by the polynomial and is thus not irreducible and thus not primitive. So we only iterate over polynomials with a constant term of . In the integer representation, those are the odd integers, so we use&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;range(2^m + 1, 2^(m-1), 2)&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;For (step 2), checking whether a polynomial is irreducible is the analogue to checking whether an integer is prime.&lt;/p&gt;
    &lt;p&gt;Ruling out even integer representations of polynomials in (1) skips half the possible candidates because those are all reducible. Unfortunately, there will still be plenty of reducible polynomials left. Just like there are a lot of non-prime numbers among the odd integers.&lt;/p&gt;
    &lt;p&gt;For a full irreducibility test, we use Rabin’s Test. The implementation has a similar structure as the Rabin-Miller Test for integers. We won’t cover either here because this section is long enough already.&lt;/p&gt;
    &lt;p&gt;For (step 3), we do the same as for primitive roots in integer-world, except we use a polynomial-compatible &lt;code&gt;pow&lt;/code&gt; function:&lt;/p&gt;
    &lt;head rend="h3"&gt;Finding all Primitive Polynomials&lt;/head&gt;
    &lt;p&gt;And now we can finally compute all the primitive polynomials with degree 14. The full script is attached in the addendum. It takes about 1 second (single-threaded, on my laptop) to list all 756 primitive polynomials for degree 14. Yes - there are only 756!&lt;/p&gt;
    &lt;p&gt;And how much faster does this make our script compared to the naive &lt;code&gt;range(2**14 + 1, 2**15, 2)&lt;/code&gt;
that lists half of all possible binary polynomials of degree 14?&lt;/p&gt;
    &lt;p&gt;About 1 second on a single-threaded run on my laptop…&lt;/p&gt;
    &lt;p&gt;Turns out just throwing a bunch of mostly non-primitive polynomials against bchlib and catching the exception is just as fast as doing it properly…&lt;/p&gt;
    &lt;p&gt;Oh, and you know what? You could have also just pulled a list of all primitive polynomials of degree 14 from the internet. Because, well, we aren’t the first to generate that list.&lt;/p&gt;
    &lt;p&gt;But hey, we learned some math.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://neodyme.io/en/blog/drone_hacking_part_1/"/><published>2026-01-17T02:35:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46655667</id><title>Meditation and Unconscious: A Buddhist Monk and a Neuroscientist (2022)</title><updated>2026-01-17T10:10:19.444899+00:00</updated><content>&lt;doc fingerprint="bf79dc917f21dbe4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;On Meditation and the Unconscious: A Buddhist Monk and a Neuroscientist in Conversation&lt;/head&gt;
    &lt;p&gt;Buddhism shares with science the task of examining the mind empirically; it has pursued, for two millennia, direct investigation of the mind through penetrating introspection. Neuroscience, on the other hand, relies on third-person knowledge in the form of scientific observation.&lt;/p&gt;
    &lt;p&gt;In the following conversation, Matthieu Ricard, a Buddhist monk trained as a molecular biologist, and Wolf Singer, a distinguished neuroscientist, offer their perspectives on the unconscious and the role of meditation in resolving conflicts that arise at levels inaccessible to conscious processing.&lt;/p&gt;
    &lt;p&gt;The text is excerpted from their book “Beyond the Self: Conversations between Buddhism and Neuroscience,” a collection of illuminating exchanges Ricard and Singer — close friends — had over the course of eight years at meetings around the world. Their objective, as they write in the book’s preface, “is to confront two perspectives anchored in rich traditions: the contemplative Buddhist practice, and epistemology and research in neuroscience.” &lt;lb/&gt;—The Editors&lt;/p&gt;
    &lt;p&gt;Matthieu Ricard: Let’s explore for a bit the notion of the unconscious, from neuroscientific and contemplative perspectives. Usually when people speak about the unconscious, they refer to something deep in our psyche that we cannot access with our ordinary consciousness. We certainly have the concept, in Buddhism, of habitual tendencies that are opaque to our awareness. These tendencies initiate various thought patterns that can either occur spontaneously or be triggered by some kind of external circumstance. Sometimes you are just sitting there, thinking of nothing in particular, and suddenly the thought of someone or a particular event or situation pops up in the mind, seemingly out of nowhere. From there, a whole chain of thoughts begins to unfold, and if you are not mindful, you can easily get lost in it.&lt;/p&gt;
    &lt;p&gt;The general public, psychologists, and neuroscientists surely have varying views about what the unconscious is. As for psychoanalysis, what it calls the depths of the unconscious are, from a contemplative perspective, the outer layers of clouds formed by mental confusion that temporarily prevent one from experiencing the most fundamental nature of mind. How can there be something unconscious in a state of pure awareness, devoid of mental construct? No darkness exists in the middle of the sun. For Buddhism, the deepest, most fundamental aspect of consciousness is this sun-like awareness, not the murky unconscious. Of course, this is all expressed from the first-person perspective, and I am sure that a neuroscientist approaching this issue from the third-person perspective will have a different view of the unconscious.&lt;/p&gt;
    &lt;p&gt;Wolf Singer: Yes, I see it a bit differently. As mentioned earlier, an enormous amount of knowledge is stored in the specific architectures of the brain, but we are not aware of most of these “given” heuristics, assumptions, concepts, and so on. These routines determine the outcomes of cognitive processes, which we are aware of, but the routines remain hidden in the unconscious. Usually we are not aware of the rules that govern the interpretation of sensory signals, the construction of our percepts, or the logic according to which we learn, decide, associate, and act.&lt;/p&gt;
    &lt;p&gt;We cannot move these implicit hypotheses and rules to the workspace of consciousness by focusing our attention on them, as is possible with contents stored, for example, in declarative memory, the memory in which we store what has been consciously experienced. Abundant evidence indicates that attentional mechanisms play a crucial role in controlling access to consciousness. When attended to, most signals from our senses can reach the level of conscious awareness. Exceptions are certain odors, such as pheromones, that are processed by special subsystems and cannot be perceived consciously. Then there are the many signals from within the body that are excluded from conscious processing, such as messages about blood pressure, sugar level, and so on. It cannot be emphasized enough, however, that signals permanently excluded from conscious processing as well as transitorily excluded signals such as nonattended sensory stimuli still have a massive impact on behavior. In addition, these unconscious signals can control attentional mechanisms and thereby determine which of the stored memories or sensory signals will be attended and transferred to the level of conscious processing.&lt;/p&gt;
    &lt;p&gt;Another constraint is the limited capacity of the workspace of consciousness. At any one moment in time, only a limited number of contents can be processed consciously. Whether these limitations are due to the inability to attend to large numbers of items simultaneously or whether they result from the restricted capacity of working memory or both is still a matter of scientific investigation. The capacity of the workspace is limited to four to seven different items. This finding corresponds to the number of contents that can be kept simultaneously in working memory. The phenomenon of change blindness, the inability to detect local changes in two images presented in quick succession, demonstrates impressively our inability to attend to and consciously process all features of an image simultaneously.&lt;/p&gt;
    &lt;p&gt;Perception is actually not as holistic as it appears to be. We scan complex scenes serially, and actually much of what we seem to perceive we are in fact reconstructing from memory. Which of the many signals actually reach the level of conscious awareness is determined by a host of factors, both conscious and unconscious. It depends on what we attend to, and this is controlled by either external cues, such as the saliency of a stimulus, or internal motifs, many of which we may not actually be aware of. Then it may occur that even an attentive, conscious search for content stored in declarative memory fails to raise it to the level of awareness. We are all familiar with the temporary inability to remember an episode or a name and then how a persisting subconscious search process may suddenly lift the content into the workspace of consciousness. It appears that we are not always capable of controlling which contents enter consciousness.&lt;/p&gt;
    &lt;p&gt;I consider the workspace of consciousness as the highest and most integrated level of brain function. Access to this workspace is privileged and controlled by attention. Moreover, the rules governing conscious deliberations such as consciously made decisions most likely differ from those of subconscious processes. The former are based mainly on rational, logical, or syntactic rules, and the search for solutions is essentially a serial process. Arguments and facts are scrutinized one by one and possible outcomes investigated. Hence, conscious processing takes time. Subconscious mechanisms seem to rely more on parallel processing, whereby a large number of neuronal assemblies, each of which represents a particular solution, enter into competition with one another. Then a “winner-takes-all” algorithm leads to the stabilization of the assembly that best fits the actual context of distributed activity patterns. Thus, the conscious mechanism is suited best to circumstances in which no time pressure exists, when not too many variables have to be considered, and when the variables are defined with sufficient precision to be subjected to rational analysis. The domains of subconscious processing are situations requiring fast responses or conditions where large numbers of underdetermined variables have to be considered simultaneously and weighed against variables that have no or only limited access to conscious processing, such as the wealth of implicit knowledge and heuristics, vague feelings, and hidden motives or drives.&lt;/p&gt;
    &lt;p&gt;The outcome of such subconscious processes manifests itself in either immediate behavioral responses or what are called “gut feelings.” It is often not possible to indicate with a rational argument why exactly one has responded in that way and why one feels that something is wrong or right. In experimental settings, one can even demonstrate that the rational arguments given for or against a particular response do not always correspond to the “real” causes. For complex problems with numerous entangled variables, it often turns out that subconscious processes lead to better solutions than conscious deliberations because of the wealth of heuristics exploitable by subconscious processing. Given the large amount of information and implicit knowledge to which consciousness has no or only sporadic access and the crucial importance of subconscious heuristics for decision making and the guidance of behavior, training oneself to ignore the voices of the subconscious would not be a helpful, well-adapted strategy.&lt;/p&gt;
    &lt;p&gt;MR: What you said corresponds with what Daniel Kahneman explains in his book “Thinking, Fast and Slow.” Although we are generally convinced that we are rational, our decisions, economic or otherwise, are often irrational and strongly influenced by our immediate gut feelings, emotions, and situations to which we have been exposed immediately before taking a decision. Intuition is a highly adaptable faculty that allows us to make fast decisions in complex situations, but it also lures us into thinking that we have made a rational choice, which actually takes more time and deliberation.&lt;/p&gt;
    &lt;p&gt;I understand that a lot is going on in the brain to allow us to function and have coherent perceptions, memories, and so on. But I was thinking more of the pragmatic aspect of dealing with the particular tendencies that give rise to the afflictive mental states and emotions associated with suffering. My point was that if you know how to relate to pure awareness and rest within that space of awareness, when disturbing emotions arise, they dissolve as they appear and do not create suffering. If one is an expert in this, then there is no need to bother about what is going on down in the subconscious. It is more a question of method. Psychoanalysis, for instance, contends that you need to find a way to dig into those hidden impulses and identify them, whereas Buddhist meditation teaches you to free the thoughts as they arise.&lt;/p&gt;
    &lt;p&gt;By dwelling in the clarity of the present moment, you are free from all ruminations, upsetting emotions, frustrations, and other inner conflicts. If you learn to deal, moment after moment, with the arising of thoughts, then you can preserve your inner freedom, which is the desired goal of such training.&lt;/p&gt;
    &lt;head rend="h3"&gt;Side Effects of Meditation&lt;/head&gt;
    &lt;p&gt;WS: Here we seem to face rather divergent concepts of the virtues of subconscious processing and the way we should deal with the unconscious dimension of our mind. This brings me to a critical issue: the side effects of meditation. One could argue that a strategy consisting of closing one’s eyes when facing conflicts, in escaping from problems rather than solving them, is perhaps a suboptimal strategy. Let us assume that conflicts exist in the subconscious and that the rumination motivated by these conflicts serves to identify and settle them. Such conflicts could arise from ambiguous bonding between the child and her caretaker in early infancy or from conflicting imperatives imprinted by early education. The causes of such problems cannot easily surface in consciousness because they are part of implicit memories that have been formed prior to the maturation of declarative memory. Such conflicts jeopardize mental and physical health.&lt;/p&gt;
    &lt;p&gt;Humankind throughout its history has sought relief from such problems, with drugs, cultural activities, and, more recently, a host of specially designed therapies. Most of the latter require one to face the problem to cope with it. Another strategy, which is applied in cognitive and behavioral therapy, attempts to alleviate the problem by unlearning the habit using conditioning paradigms. If one suffers from a particular phobia, then one gets exposed to the threatening events and learns that they don’t cause harm, and after a while, one habituates to the threat and the problem may be solved.&lt;/p&gt;
    &lt;p&gt;MR: We surely need to get at the heart of the issue. But in the end, what we need is to be free from inner conflicts, one way or another, right? So, there might be ways that involve digging into the past as much as one can, with or without the help of a therapist, and then trying to solve the problem or trauma that has thus been identified, thereby freeing oneself from the afflictive effect. But there are also ways, including those used by Buddhism, that do not attempt to elude the problem but to free any conflicting thoughts that arise in the mind at the moment they arise. If you become expert in those methods, the so-called afflictive thoughts no longer have the power to afflict you because they undo themselves the moment they arise. But that is not all: Experience shows that by repeatedly doing so, you not only deal successfully with each individual arising of afflictive thoughts but you also slowly erode the tendencies for such thoughts to arise. So in the end, you are free of them entirely. Among contemporary Western therapies, cognitive and behavioral therapy also offer methods to attend precisely to a particular emotion that upsets you in the moment and deal with it in a reasonable and constructive way and has therefore some interesting similarities with the Buddhist approach.&lt;/p&gt;
    &lt;p&gt;WS: Let us see what meditation could contribute to the resolution of conflicts that arise at levels inaccessible to conscious processing. I shall take a critical stance and use a real-world problem as an example. Imagine a conflict evolves between two partners that evokes uneasy feelings and causes lasting mental rumination in both parties. Their two ego bubbles fight against each other, as in “Who’s Afraid of Virginia Woolf?” Love and passion exist between them, which are both difficult to control because they are anchored in subconscious spheres. The partners go into retreat and meditate, stop ruminating, and feel fine while they meditate alone in a protected environment. But will this solve the problem? Will they not resume fighting once they are back home, together, and confronted again with their problems?&lt;/p&gt;
    &lt;p&gt;MR: To openly confront our differences can be a way to pacify a conflict, but it is not the only one. To begin with, a conflict requires two protagonists confronting each other in antagonistic ways. One cannot clap with one hand only. In fact, if one of the persons involved disarms his or her own antagonistic mind, then it will contribute greatly to reducing the conflict with the other person.&lt;/p&gt;
    &lt;p&gt;We did an experiment at Berkeley with Paul Ekman and Robert Levenson, who, among other things, have been studying conflict resolution. In this case, they wanted me to have two conversations with two different people. The idea was to discuss a controversial topic — in this case, why a former biologist like me, who did research in a prestigious lab at Pasteur Institute, would ever choose not only to become a Buddhist monk but to believe in crazy things such as reincarnation. We were all fitted with all kinds of sensors detecting our heart rate, blood pressure, breathing, skin conductivity and sweating, and body movements, and our facial expressions were recorded on a video camera, to be later analyzed in details for fleeting microexpressions. My first interlocutor was Professor Donald Glaser, a Nobel laureate in physics, who then moved to research in neurobiology. He was an extremely kind and open-minded person. Our discussion went well, and at the end of the 10 minutes, we both regretted not having more time to dialogue. Our physiological parameters indicated a calm, nonconflictual attitude. Then came in someone who had to be chosen because he was reputed to be a rather difficult person — he was not told about that of course! He knew that we were supposed to get into a heated debate and went straight into it. His physiology became immediately highly aroused. From my side, I tried my best to remain calm — I actually enjoyed it — and did my best to provide reasonable answers delivered in a friendly way. Soon enough, his physiology became calmer and calmer, and at the end of the 10 minutes, he told the researchers, “I can’t fight with this guy. He says reasonable things and smiles all the time.” So, as the Tibetan saying goes, “One cannot clap with one hand.”&lt;/p&gt;
    &lt;p&gt;As far as your own inner conflicts are concerned, if you use meditation simply as a quick fix to superficially appease your emotions, you temporarily enjoy a pleasant deferral of these inner conflicts. But as you rightly say, these cosmetic changes have not reached the root of the problem.&lt;/p&gt;
    &lt;p&gt;Merely putting problems to sleep for a while or trying to forcibly suppress strong emotions will not help either. You are just keeping a time bomb ticking somewhere in a corner of your mind.&lt;/p&gt;
    &lt;p&gt;True meditation, however, is not just taking a break. It is not simply closing one’s eyes to the problem for a while. Meditation goes to the root of the problem. You need to become aware of the destructive aspect of compulsive attachment and all of the conflictive mental states that you mentioned. They are destructive in the sense of undermining your happiness and that of others, and to counteract them you need more than just a calming pill. Meditation practice offers many kinds of antidotes.&lt;/p&gt;
    &lt;p&gt;A direct antidote is a state of mind that is diametrically opposed to the afflictive emotion you want to overcome, such as heat and cold. Benevolence, for instance, is the direct opposite of malevolence because you cannot wish simultaneously to benefit and harm the same person. Using this kind of antidote neutralizes the negative emotions that afflict us.&lt;/p&gt;
    &lt;p&gt;Let’s take the example of desire. Everyone would agree that desire is natural and plays an essential role in helping us to realize our aspirations. But desire in itself is neither helpful nor harmful. Everything depends on what kind of influence it has over us. It is capable of both providing inspiration in our life and poisoning it. It can encourage us to act in a way that is constructive for ourselves and others, but it can also bring about intense pain. The latter occurs when desire is associated with grasping and craving. It then causes us to become addicted to the causes of suffering. In that case, it is a source of unhappiness, and there is no advantage in continuing to be ruled by it. Here you may apply the antidote of inner freedom to the desire that causes suffering. You bring to your mind the comforting and soothing quality of inner freedom and spend a few moments allowing a feeling of freedom to be born and grow in you.&lt;/p&gt;
    &lt;p&gt;Because desire also tends to distort reality and project its object as something that you cannot live without, to regain a more accurate view of things, you may take the time to examine all aspects of the object of your desire and see how your mind has superimposed its own projections onto it. Finally, you let your mind relax into the state of awareness, free from hope and fear, and appreciate the freshness of the present moment, which acts like a balm to soothe the burning of desire. If you do that repeatedly and perseveringly — and this point is really the most important — this will gradually lead to a real change in the way you experience things all the time.&lt;/p&gt;
    &lt;p&gt;The second, even more powerful way to deal with afflictive emotions is to stop identifying with them: You are not the desire, you are not the conflict, and you are not the anger. Usually we identify with our emotions completely. When we become overwhelmed by desire, anxiety, or a fit of anger, we become one with it. It is omnipresent in our mind, leaving no room for other mental states such as inner peace, patience, or reasoning, which might calm our torments.&lt;/p&gt;
    &lt;p&gt;The antidote is to be aware of desire or anger, instead of identifying with it. Then the part of our mind that is aware of anger is not angry, it is simply aware. In other words, awareness is not affected by the emotion it is observing. Understanding that makes it possible to step back and realize that the emotion is actually devoid of solidity. We just need to provide an open space of inner freedom, and the internal affliction will dissolve by itself.&lt;/p&gt;
    &lt;p&gt;By doing so, we avoid two extremes, each as inefficient as the other: repressing our emotion, which would then remain as powerful as before, or letting the emotion flare up, at the expense of those around us and of our own inner peace. Not to identify with emotions is a fundamental antidote that is applicable to all kinds of emotions in any circumstance.&lt;/p&gt;
    &lt;p&gt;This method might seem difficult at the beginning, especially in the heat of the moment, but with practice, it will become easier to retain mastery of your mind and deal with the conflicting emotions of day-to-day life.&lt;/p&gt;
    &lt;p&gt;Matthieu Ricard, a Buddhist monk, trained as a molecular biologist before moving to Nepal to study Buddhism. He is the author of several books, including “The Monk and the Philosopher” (with his father, Jean-François Revel); “The Quantum and the Lotus” (with Trinh Xuan Thuan); “The Art of Meditation“; and “Beyond the Self: Conversations between Buddhism and Neuroscience” (with Wolf Singer), from which this article is excerpted. The MIT Press will publish the English translation of his memoir, “Notebooks of a Wandering Monk,” next fall.&lt;/p&gt;
    &lt;p&gt;Wolf Singer is Emeritus Director of the Max Planck Institute for Brain Research and Founding Director of the Frankfurt Institute for Advanced Studies and the Ernst Strüngmann Institute for Neuroscience in cooperation with the Max Planck Society, where he is also Senior Research Fellow.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thereader.mitpress.mit.edu/meditation-and-the-unconscious-buddhism-neuroscience-conversation/"/><published>2026-01-17T05:49:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656045</id><title>The 'untouchable hacker god' behind Finland's biggest ever crime</title><updated>2026-01-17T10:10:19.296984+00:00</updated><content>&lt;doc fingerprint="260593d10eb24786"&gt;
  &lt;main&gt;
    &lt;p&gt;Tiina Parikka was half-naked when she read the email. It was a Saturday in late October 2020, and Parikka had spent the morning sorting out plans for distance learning after a Covid outbreak at the school where she was headteacher. She had taken a sauna at her flat in Vantaa, just outside Finland’s capital, Helsinki, and when she came into her bedroom to get dressed, she idly checked her phone. There was a message that began with Parikka’s name and her social security number – the unique code used to identify Finnish people when they access healthcare, education and banking. “I knew then that this is not a game,” she says.&lt;/p&gt;
    &lt;p&gt;The email was in Finnish. It was jarringly polite. “We are contacting you because you have used Vastaamo’s therapy and/or psychiatric services,” it read. “Unfortunately, we have to ask you to pay to keep your personal information safe.” The sender demanded €200 in bitcoin within 24 hours, otherwise the price would go up to €500 within 48 hours. “If we still do not receive our money after this, your information will be published for everyone to see, including your name, address, phone number, social security number and detailed records containing transcripts of your conversations with Vastaamo’s therapists or psychiatrists.”&lt;/p&gt;
    &lt;p&gt;Parikka swallows hard as she relives this memory. “My heart was pounding. It was really difficult to breathe. I remember lying down on the bed and telling my spouse, ‘I think I’m going to have a heart attack.’”&lt;/p&gt;
    &lt;p&gt;Someone had hacked into Vastaamo, the company through which Parikka had accessed psychotherapy. They’d got hold of therapy notes containing her most private, intimate feelings and darkest thoughts – and they were holding them to ransom. Parikka’s mind raced as she tried to recall everything she’d confided during three years of weekly therapy sessions. How would her family react if they knew what she’d been saying? What would her students say? The sense of exposure and violation was unfathomable: “It felt like a public rape.”&lt;/p&gt;
    &lt;p&gt;Therapy had been Parikka’s lifeline. Now 62, she’d had three children by the time she was 25, including twins who had been born extremely prematurely in the 1980s, weighing only a few hundred grams each. One grew up with cerebral palsy; the other is blind. Parikka spent years juggling medical emergencies, surgeries and hospital stays with a demanding job and a crumbling marriage. “During those years, nobody ever asked me, the mother, ‘How are you?’”&lt;/p&gt;
    &lt;p&gt;She divorced in 2014 and met her current partner a year later. By then, her children were adults with independent lives. After decades of putting everyone’s else’s needs before her own, she should have been finally able to exhale. Instead, she had a breakdown. “I had full-scale anxiety running through my body all the time. I couldn’t sleep. I had panic attacks. I couldn’t eat.” Driving at high speed on the highway one day, dark thoughts descended. “I was thinking, I wouldn’t mind if this car crashed.”&lt;/p&gt;
    &lt;p&gt;In search of urgent help, she went to Google, which led her to Vastaamo, Finland’s one-stop digital shop for people in search of psychotherapy. No doctor referral was necessary. She managed to book a session for the very next day. “It was that easy.”&lt;/p&gt;
    &lt;p&gt;Being able to confide in a total stranger felt liberating. She told her therapist things she had never told another soul. “Trauma in relationships. The disappointment and tragedy of having disabled children, and the influence it had on my life,” she says. “Silly things, childish things. It’s very human to feel hate, anger, rage.”&lt;/p&gt;
    &lt;p&gt;After Parikka read the email that left her struggling to breathe, she had no idea where to turn for help. She rang the emergency services, but the police told her to get off the line; they needed to keep it free for real emergencies. In her bathrobe, her phone still in her hand, she felt utterly alone.&lt;/p&gt;
    &lt;p&gt;But Parikka was far from alone. Across Finland, 33,000 people who had used Vastaamo were discovering that a hacker had got hold of their therapy notes and was holding them to ransom. These were people who, by definition, were likely to be vulnerable, in need of help. Each was experiencing a very personal, individual terror. In a country of only 5.6 million people, everyone knows someone who was hacked.&lt;/p&gt;
    &lt;p&gt;Some victims’ notes had already been cherrypicked for the world to see. Three days before the extortion emails were sent, someone using the handle ransom_man had left posts on the dark web, on r/Suomi, the Finnish-language subreddit, and on Ylilauta, Finland’s equivalent to 4chan. This time, the post was in English. “Hello Finnish Colleagues,” it began. “We have hacked the psychotherapy clinic vastaamo.fi and taken tens of thousands of patient records including extremely sensitive session notes and social security numbers. We requested a small payment of 40 bitcoins (nothing for a company with yearly revenues close to 20 million euros) but the CEO has stopped responding to our emails. We are now starting to gradually release their patient records, 100 entries every day.”&lt;/p&gt;
    &lt;p&gt;There was a link to the dark web, where 100 records were already on display. Directly below it, ransom_man had signed off the post with a single word: “Enjoy!”&lt;/p&gt;
    &lt;p&gt;The 100 records included those of politicians, police officers and prominent public figures. Their names appeared alongside therapy notes that contained details of adultery, suicide attempts, paedophilia and sexual violence. Some of the records belonged to children. And whoever was behind the hack was true to their word: the next day, 100 more patient records were uploaded.&lt;/p&gt;
    &lt;p&gt;Some victims went searching on the dark web in a desperate attempt to see if their records were out there. Some paid the ransom, scrabbling to get hold of bitcoin while the clock ticked down. Lawyers representing the victims have told me they know of at least two cases where people took their own lives after they discovered their therapy notes had been hacked.&lt;/p&gt;
    &lt;p&gt;But for all of them, it was already too late. At 2am on 23 October 2020 – the day before the emails began to arrive in tens of thousands of inboxes – ransom_man had uploaded a much larger file. It contained every record of every single patient on Vastaamo’s database. Everyone’s therapy notes had already been published, for free, for everyone in the world to see.&lt;/p&gt;
    &lt;p&gt;Who was behind the biggest crime Finland had ever known? And might they have been motivated by something other than money? I have spent 18 months trying to answer these questions, following threads across Europe and the US. They culminated in a visit to a prison, and one of the most chilling conversations I have ever had.&lt;/p&gt;
    &lt;p&gt;Finland has been ranked the happiest country on Earth by the UN for the last eight years in a row. A world leader in childcare and education, Finland is also famously hi-tech: it’s the most digitalised country in Europe, renowned for its communications sector (as the home of Nokia) and leading the way when it comes to cybersecurity and AI innovation. But Finland is also a place of extremes. It has more heavy metal bands per capita than any other nation. In the far north, for the few days around the winter solstice, the sun does not rise.&lt;/p&gt;
    &lt;p&gt;Vastaamo had long been considered an example of how Finland was getting it right when it came to digital tech. Founded in 2008 by entrepreneur Ville Tapio and his mother, Nina, a psychotherapist, the aim was to open up therapy to the masses, removing the stigma of asking for help. The platform made it easy for people to see who was free, where, and what therapeutic approach they specialised in. The logo had the colour palette of a first-aid kit, with white lettering in a green speech bubble. Vastaamo means “a place for answers”.&lt;/p&gt;
    &lt;p&gt;It was an attractive platform for therapists, too: they didn’t have to worry about marketing or billing – Vastaamo would take care of all of that. The company even provided a behind-the-scenes digital interface where therapists could make and store their notes. This formula, combined with the increasing demand for therapy services, meant Vastaamo grew fast. It opened its own network of around 20 clinics across Finland, employing more than 220 psychotherapists by 2018, leading some in Finland to refer to it as “the McDonald’s of therapy”. In the years before Zoom and Teams were part of our daily lives, the remote therapy also offered by Vastaamo was groundbreaking. In 2019, a private equity firm bought a majority stake in the company, earning the Tapio family a payout of more than €5m.&lt;/p&gt;
    &lt;p&gt;Meri-Tuuli Auer, 30, describes using Vastaamo as “like Uber for therapy – convenient, accessible, relatively cheap”. She picked her therapist because he offered cognitive psychotherapy – and she liked his photo. “He looked nice. He looked approachable.”&lt;/p&gt;
    &lt;p&gt;Auer’s home, on the outskirts of Helsinki, is a riot of pink. There are Barbie dolls, Barbie books and Barbie-themed handbags on her shelves, as well as a glittery open-top Barbie sports car. A pole-dancing pole takes pride of place in the centre of her living room.&lt;/p&gt;
    &lt;p&gt;“I’m a mixed personality,” she tells me over tea in Moomin mugs. “I love being around people, but I get that inkling, that doubt: maybe they all think I’m full of shit and stupid and ugly and I have no idea what I’m doing.” Auer has struggled with depression for much of her life. When she was 18, she was in a secretive, difficult relationship with a man 29 years her senior, which made her self-esteem plummet further. She was drinking heavily. “If I hadn’t gone to therapy, I don’t know what would have become of me. Maybe there is another universe where I didn’t make it to 30.”&lt;/p&gt;
    &lt;p&gt;Most of the cost of Auer’s treatment was covered by the Finnish healthcare system; she paid only about €25 for each weekly session. She was making great strides. “After going to therapy in 2018 and 2019, I had gained a basic sense of security. That was lost in 2020.”&lt;/p&gt;
    &lt;p&gt;Vastaamo’s CEO knew the company’s patient registry was being held to ransom weeks before his customers found out. On 28 September 2020, Ville Tapio received an email demanding the bitcoin equivalent of €450,000 to keep it safe. Sample patient records attached to the email proved the extortionist wasn’t bluffing. Tapio called in a cybersecurity firm to investigate.&lt;/p&gt;
    &lt;p&gt;Medical information is an obvious target for would-be extortionists, says Antti Kurittu, the security specialist Tapio hired. But this was something else: “Whatever I tell a therapist is, by its very nature, a lot more private than what my blood pressure is,” he says, drily.&lt;/p&gt;
    &lt;p&gt;Kurittu used to be a detective, investigating cybercrimes for the Finnish police; he says he insisted they be told about the ransom attempt so they could begin a parallel investigation. Meanwhile, he began inspecting Vastaamo’s server, looking for clues as to who might be behind the hack – and one of the first things he noticed was how lax security had been. “It was definitely unfit for purpose for storing this kind of information,” he says. He tells me that the patient records database was accessible via the internet; there was no firewall and, perhaps most egregiously, it was secured with a blank password, so anyone could just press enter and open it. Kurittu determined that whoever had hacked Vastaamo had probably just been scanning the internet in search of any badly secured databases that could be monetised. “They tried a bunch of bank vaults to see which ones were open, and just happened to stumble on this one.”&lt;/p&gt;
    &lt;p&gt;For a few weeks, the hacker and Vastaamo exchanged emails, but there was no question that Vastaamo would pay the ransom. If they did, they’d have to trust a criminal’s word that the records had been destroyed – plus, Kurittu says, it goes against the national character. “Finns are a bit of a belligerent bunch. We’re not known for paying ransom quietly or easily, which I take great national pride in.”&lt;/p&gt;
    &lt;p&gt;After ransom_man started leaking patient records to put pressure on the company, Kurittu kept a close eye on the server being used to publish them. He had a hunch whoever was behind this was either Finnish, or had lived in Finland for a long time: they knew which famous names to flaunt from the patient records.&lt;/p&gt;
    &lt;p&gt;When Auer learned about the hack, she downloaded a browser that would enable her to access the dark web, for the first time in her life. “I was thinking to myself, I just have to see if my records are there.” She found her name wasn’t among the first batch posted, and closed the file without reading anyone’s records. But she saw other people discussing what they’d seen. “People had already picked – in their opinion – the funniest parts from the patient records. They were laughing at these people’s misery. A 10-year-old child had gone to therapy, and people found it funny.”&lt;/p&gt;
    &lt;p&gt;Auer began to spiral. “I closed myself in at home, I didn’t want to leave, I didn’t want anyone to see me,” she tells me. She had no hope that the hacker would ever be found. “It’s not that I don’t trust the police in Finland – it’s just that it seemed like an impossible task.”&lt;/p&gt;
    &lt;p&gt;But the much larger file ransom_man had uploaded to the dark web – the one that contained every single one of Vastaamo’s patient records – also included vital clues to his identity. The first three batches of therapy notes had been posted manually, but when the hacker had tried to automate the process, he had not only accidentally uploaded all of the therapy notes, but also his entire home folder. It had appeared only briefly before it was taken down, along with a post that read “whoopsie :D”, but ransom_man had screwed up.&lt;/p&gt;
    &lt;p&gt;“After spending several evenings with the file, I had the feeling I’d seen this kind of thing before,” Kurittu says. The data on the hacker’s home drive wasn’t systematically organised and arranged in folders, as you would expect from someone for whom extortion was a business. “It had that sort of chaotic, passionate hobby feeling to it.” And there was something about the childish way ransom_man had named some of the files that was eerily familiar (the one containing all the patient data was entitled “therapissed”).&lt;/p&gt;
    &lt;p&gt;Kurittu’s mind went back to 2013 when he was a senior detective constable for the Helsinki police, and the file names he’d seen on a computer he’d seized from a 16-year-old boy. “It made me think of Julius Kivimäki.”&lt;/p&gt;
    &lt;p&gt;Aleksanteri Kivimäki – who used to go by his middle name, Julius, or the online handle zeekill – had long been notorious among cybersecurity investigators. Not because of any particular talent as a hacker, but because he seemed prepared to go further than most who spend their time in the darkest parts of the internet.&lt;/p&gt;
    &lt;p&gt;Aged 14, Kivimäki was involved with a group called Hack the Planet (named after the tagline of the 1995 movie Hackers). They would break into big companies and show off what they had managed to steal online. “It was for the LOLs,” says Blair Strater, a former hacker from Illinois who hung out with Kivimäki in internet relay chat forums at that time. “You notice that something is open and you just take it. It’s not targeted.”&lt;/p&gt;
    &lt;p&gt;This kind of hacking was about impressing others – winning online clout, not extorting money. But some of those involved may have felt they were also serving a noble purpose: exposing security vulnerabilities in major corporations, or the hypocrisy of cybersecurity firms who claimed to be qualified to advise businesses while being unable to secure their own network.&lt;/p&gt;
    &lt;p&gt;Strater found Kivimäki amusing, at first. “A lot of the things he did early on were objectively funny,” he tells me over Zoom from his home in Illinois. When I ask Strater whether I would find them funny, he clarifies that his humour was an acquired taste best suited to 4chan. But in 2010, when Strater was 17 and Kivimäki was 14, they fell out over which one of them was going to publish a report of a recent hack.&lt;/p&gt;
    &lt;p&gt;Orders of pizzas and Chinese takeaway began arriving at the home Strater shared with his parents and younger sister on the outskirts of Chicago; when they opened the door, the delivery driver would ask for Julius Kivimäki. “Taxis were ordered. Hookers were ordered,” Strater says. “My father had to send away a big dump truck filled with gravel.” Strater received a blizzard of letters from credit card and insurance companies, and government agencies, including one from the department of social security confirming that an appointment with the welfare office had been created for him and his spouse – Julius Kivimäki.&lt;/p&gt;
    &lt;p&gt;Then, at 2am one morning, police in body armour carrying guns with laser sights turned up outside the Straters’ home, responding to reports that Blair had beaten his mother to death in a drug-fuelled rage. When she answered the door, they took her blood pressure to verify that she was, in fact, alive. It was the first of dozens of so-called swatting attacks the family would endure. After a lull of a couple of months, Strater learned that someone using his name had emailed a bomb threat to a local police officer; it led to Strater spending three weeks over Christmas in a juvenile detention centre.&lt;/p&gt;
    &lt;p&gt;Several years into their feud, in 2015, someone hacked Elon Musk and Tesla’s Twitter accounts, and tweeted that anyone who rang the Straters’ landline or showed up at their home would get a free car; their phone rang off the hook for days, and Blair’s father had to turn several disappointed people away from their porch. Someone using Blair’s mother’s name posted a threat to shoot up the elementary school where his 10-year-old sister was a pupil. His mother’s LinkedIn and Twitter accounts were hacked and filled with juvenile, racist posts, as well as antisemitic insults directed at the company where she worked as a healthcare statistician. Within months, she had lost her job.&lt;/p&gt;
    &lt;p&gt;The campaign of terror lasted for many more years. Strater says it’s never going to be fully over. “It’s like having cancer: it’s never really cured, it goes into remission,” he says. “Every so often, someone would hit me up and say, ‘Hey, I was one of the people that helped Julius do these things.’ Sometimes they would say, ‘He made me do them. He was blackmailing me,’ which is something he does to an awful lot of people. I want to make this very clear: I am not the person zeekill fucked with the most.”&lt;/p&gt;
    &lt;p&gt;Indeed, Kivimäki set his sights far beyond the Strater family. In August 2014 – days after his 17th birthday – he rang in a fake bomb threat that grounded a flight carrying John Smedley, president of Sony Online Entertainment, who oversaw PlayStation’s multiplayer network. A group calling themselves Lizard Squad claimed responsibility, posting almost nonsensically on Twitter that the attack was in sympathy with Islamic State. Lizard Squad struck again, on 25 December 2014, with a cyber-attack that shut down Xbox and PlayStation, and ruined Christmas morning for millions. Brazenly, Kivimäki gave interviews to BBC 5 Live and Sky News as a Lizard Squad spokesperson, claiming they did the hack both to amuse themselves and to expose Microsoft and Sony’s poor cybersecurity. He seemed to revel in the chaos and drama. He appeared on camera on Sky News; he used a fake name, but his boyish face – blond hair, blue eyes, plump cheeks – was visible for all to see.&lt;/p&gt;
    &lt;p&gt;In July 2015, following Kurittu’s investigation with the Finnish police, Kivimäki was convicted of hacking into servers at MIT and Harvard universities, as well as money laundering and fraud. He was found guilty of more than 50,000 data breaches, and received a two-year suspended sentence; he had his computer confiscated and was forced to pay back more than €6,000 obtained through his crimes. He never faced justice for any of the offences he perpetrated against Blair Strater and his family.&lt;/p&gt;
    &lt;p&gt;Shortly after he received his suspended sentence, Kivimäki updated his Twitter bio to read “untouchable hacker god”.&lt;/p&gt;
    &lt;p&gt;Kivimäki spent the next few years travelling the world. During lockdown, he lived in an air-conditioned apartment in Westminster, 20 metres away from the central London headquarters of MI5. There were trips to Dubai, Hong Kong, Barcelona and Paris. According to the images of himself he liked to post online, he was living the life of an international jetsetter. But he was not, in the end, untouchable.&lt;/p&gt;
    &lt;p&gt;Police made a micropayment of 0.1 bitcoins to ransom_man. They were able to determine that, when it was laundered into real-world currency, it was transferred into Kivimäki’s bank account. The home folder ransom_man had accidentally uploaded had led the police to some servers, one of which had been paid for using a credit card linked to him – the same one he’d been using to pay for Apple services and an OnlyFans subscription.&lt;/p&gt;
    &lt;p&gt;As investigators traced the history on ransom_man’s home folder, they were able to determine that, as well as looking for keywords such as rape, abuse and child molestation in the database of patient records, the hacker had also searched for Kivimäki’s home address, and the names of his family members. “Before publication, he ensured there was no harmful information about him, or people close to him,” Pasi Vainio, the lead prosecutor on the case, tells me. Those searches took place using an IP address linked to Kivimäki’s Westminster apartment. “He was in London when the crimes were committed.”&lt;/p&gt;
    &lt;p&gt;But it was a drawn-out, arduous investigation. There were terabytes of data to comb through. The crime had so many victims that the police had to create an online portal for everyone to register and give their statements. That generated more than 21,000 criminal reports, all of which needed to be looked at individually. So it was October 2022 – two years after Parikka, Auer and the other victims had received their ransom demands – before Vainio signed an arrest warrant for Kivimäki. His face – chubby-cheeked and floppy-haired – was added to Europol’s list of most-wanted fugitives, alongside murderers and drug traffickers.&lt;/p&gt;
    &lt;p&gt;On 3 February 2023, French police were alerted to a report of domestic violence taking place in a flat in a Paris suburb. Officers used a battering ram to enter the property and found a man and a woman inside. The man was pale and white-blond, but when asked to identify himself he handed over a Romanian passport that gave his name as Asan Amet. “We have a Scandinavian-looking guy, 195cm tall,” Vainio tells me with a smile. “I think the French police just thought something’s off.” They searched their databases and discovered Amet was one of Kivimäki’s known aliases. He was handed over to the Finnish authorities a few weeks later.&lt;/p&gt;
    &lt;p&gt;“I don’t know what I had expected, but I was surprised to see that he looked so normal,” Auer says. “He looks like a regular Finnish young man. It did make me feel like it could have been anyone.”&lt;/p&gt;
    &lt;p&gt;“I had heard that he was in a court hearing,” Parikka says. “We have a habit – every night at 8.30pm, I’ll lie here on the couch with my spouse and watch the main news. Without warning, Kivimäki was there on the screen. Kivimäki came to my living room.” She glances over to her couch, metres away from where we sit, and is overcome with tears. “I didn’t sleep the next night.”&lt;/p&gt;
    &lt;p&gt;But when the trial began, in November 2023, Parikka was determined to watch Kivimäki face justice. The logistics of inviting more than 21,000 registered victims to court were impossible; instead, proceedings were relayed to public spaces such as cinemas so that the plaintiffs could watch in real time. In a case that was all about the right to privacy and anonymity, it sounds a profoundly awkward setup. “We were all sitting far away from each other,” Auer says. “It was dead silent.” Parikka had a similar experience. “We pretty much kept to ourselves.”&lt;/p&gt;
    &lt;p&gt;On 30 April 2024, Kivimäki was found guilty of all charges – including 9,600 counts of aggravated invasion of privacy and more than 21,300 counts of attempted aggravated extortion – and sentenced to six years and three months in prison: a long stretch by Finnish standards, but shy of the seven-year maximum he could have received. His appeal against his sentence is currently under way.&lt;/p&gt;
    &lt;p&gt;Even if his conviction is upheld, he will be a free man by the end of this year.&lt;/p&gt;
    &lt;p&gt;“The sentencing scale is too low, in my opinion. But that’s the framework we have in Finland,” Vainio says. He tells me a colleague has tried to quantify the harm caused, using the conservative estimate that each person had endured a week of agony as a result of the hack. “When you multiply it with the number of victims of this case, you would have 635 years of suffering.”&lt;/p&gt;
    &lt;p&gt;Now 28, Kivimäki has served much of his sentence in a spotless, bright but suitably austere facility in Turku, south-west Finland, a two-hour train ride from Helsinki. For months, he had refused to grant me an interview, but while I am in Finland reporting this story, he changes his mind. As I sit in silence in the prison’s visitor room for what feels like hours, watching the clock tick down behind a panel of reinforced glass, I wonder if Kivimäki is trolling me; if he has dragged me over here simply to derail the other interviews I already had scheduled, with no intention of ever leaving his cell. But after 40 minutes he appears. With his white-blond hair, ice-blue eyes and razor burn, and dressed in a black T-shirt and shorts, he looks like an overgrown teenage boy.&lt;/p&gt;
    &lt;p&gt;He didn’t do it, he says; he’s simply a victim of his own notoriety. “They had to find somebody. They just chose somebody who was convenient for the story.” When I point out that there’s an enormous amount of circumstantial evidence linking him to the hack, Kivimäki is defiant. “The obvious answer is that it’s just somebody close to me.” He has an idea who it is, he continues, but he isn’t prepared to name names.&lt;/p&gt;
    &lt;p&gt;It seems very selfless to do time for someone else’s crime, I say. I tell him Parikka says having her therapy notes held to ransom felt like a public rape. “I’m sure that’s how she felt,” he replies, blankly. “It’s quite remote to me. I’m involved, in that I was in court over this stuff, but I didn’t do it. It’s another story in the news.”&lt;/p&gt;
    &lt;p&gt;As a fellow human being rather than the person convicted of the crime, I ask, what’s your response to people taking their lives after having their therapy notes stolen? “There’s a lot of terrible things going on in the world. I don’t really feel any differently about this. I turn on the news and there’s people dying in Gaza or wherever. It’s like, how do you feel about that? I think the honest answer for most people is that they just … don’t.” You don’t have anything to say to the victims? “Not really,” he replies. “These are nameless, faceless people.”&lt;/p&gt;
    &lt;p&gt;“There’s been just one question that I would ask Kivimäki,” Parikka says. “That would be: ‘Was there ever such a moment that you felt empathy?’ I don’t think he’s able to put himself into anybody else’s situation.” She pauses. “I think that he really needs therapy.”&lt;/p&gt;
    &lt;p&gt;Vastaamo was declared bankrupt in February 2021. Days after patients received the ransom emails, the board announced that it had let the CEO, Ville Tapio, go. In April 2023, Tapio was found guilty of criminal negligence in his handling of patient data. His conviction was overturned on appeal in December 2025. (He declined my requests to interview him.)&lt;/p&gt;
    &lt;p&gt;“I have actually been more angry towards Ville Tapio than I have been towards Kivimäki,” Auer says. “As CEO of the company, he had the responsibility to make sure that it was prepared for all kinds of risks, and that they had sufficient information security. It seems like it was never a priority to him.” What was his priority? “Making money. He ran a very successful business.”&lt;/p&gt;
    &lt;p&gt;“I believe that originally the Tapios were wanting to help people and make therapy available,” Parikka says. “There are now maybe thousands of people who will never use therapy again, because they can never trust. And that’s really bad.”&lt;/p&gt;
    &lt;p&gt;Alongside more than 6,000 other plaintiffs, Auer and Parikka are part of a civil case suing Kivimäki for damages. Despite the lifestyle he projects online, he claims not to have the funds to pay damages; so far, no one has been able to find his assets. The government has agreed to pay compensation to victims – anything from a few hundred euros to a few thousand, depending on how many pages of their therapy notes Vastaamo had in its database, and how sensitive the information contained in those pages was – but the sum is likely to be symbolic. How can you ever repay the damage of being exposed in this way?&lt;/p&gt;
    &lt;p&gt;Copies of the patient files have been circulating ever since they were first released in October 2020. At one point, someone created a special search engine for browsing the database. This doesn’t surprise Parikka. “Kivimäki isn’t just one of a kind,” she says. “I know human curiosity. People want to know.”&lt;/p&gt;
    &lt;p&gt;Other people are as prepared as Kivimäki was to break moral and legal boundaries – for money, for online clout, out of ghoulish curiosity or simply for the LOLs. In May, Finnish police announced that there was a second suspect in the Vastaamo case, a US citizen living in Estonia – suspected of aiding and abetting Kivimäki, helping prepare the files. He has been charged with assisting in the attempted extortion.&lt;/p&gt;
    &lt;p&gt;In an era when AI models are trained on our Zoom conversations, emails and status updates, it is naive to believe that anything can ever be fully secure. The human need to confide in others can be met in an extraordinary range of ways in the digital age. In a world of unparalleled connectivity, can our innermost secrets ever be truly safe?&lt;/p&gt;
    &lt;p&gt;Kivimäki thinks we are all clinging on to analogue expectations about privacy in a digital world. “So many of our worst secrets – I mean worst of worst, things we might really, really not want to share with the entire world – they exist online. They’ll exist in the database of some company you used,” he tells me. “Everybody’s photos, everybody’s text-messaging histories.” He fixes me with his eyes. “You fundamentally want to believe in this privacy. But, on the other hand, I don’t know how you’re going to get there.”&lt;/p&gt;
    &lt;p&gt;Intrigue: Ransom Man, Jenny Kleeman’s six-part series for BBC Radio 4, is available now on BBC Sounds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/technology/2026/jan/17/vastaamo-hack-finland-therapy-notes"/><published>2026-01-17T07:29:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656100</id><title>Every data centre is a U.S. military base</title><updated>2026-01-17T10:10:18.812874+00:00</updated><content>&lt;doc fingerprint="3fb89bf09f231cfd"&gt;
  &lt;main&gt;
    &lt;p&gt;In February, U.S. President Donald Trump signed an executive order sanctioning the International Criminal Court (ICC) and its chief prosecutor, British lawyer Karim Khan. The move came in response to the court’s decision to issue an arrest warrant for Israeli Prime Minister Benjamin Netanyahu for the crimes against humanity he committed in the ongoing Gaza genocide.&lt;/p&gt;
    &lt;p&gt;The move was outrageous for many reasons, and not even the first time the United States had sanctioned an ICC chief prosecutor. Khan’s predecessor was also in Trump’s crosshairs when she opened an investigation into crimes in Afghanistan, where the actions of the United States would not be excluded.&lt;/p&gt;
    &lt;p&gt;The sanctions on Khan hampered the work of the court, and he found that not only were his UK bank accounts frozen, but he also lost access to his Microsoft email address. He ended up switching to Swiss privacy-focused provider Proton Mail. While it has not made the same impact in Canada, the news about Khan losing his access to Microsoft services quickly rippled through the halls of power across Europe when it was revealed in May.&lt;/p&gt;
    &lt;p&gt;The withdrawal of service showed European lawmakers how vulnerable their access to the technologies they rely on not just in their personal lives, but to run governments and key institutions. They were also facing escalating pressure from the Trump administration and the billionaires of Silicon Valley to roll back their world-leading tech regulations, and U.S. Vice President JD Vance showed up on the continent a week after Khan was sanctioned to lecture Europe about its values, approach to free speech, and attempts to exclude the neo-Nazi party Alternative for Germany from political power.&lt;/p&gt;
    &lt;p&gt;Microsoft tried to distance itself from the controversy, but even its spokesperson admitted there had been a “disconnection of [the court’s] sanctioned official.” The company didn’t help its case when Microsoft France’s director of public and legal affairs told the French Senate under oath in June that it “cannot guarantee” it would be able to deny requests from the Trump administration for data stored on its servers within the European Union.&lt;/p&gt;
    &lt;p&gt;As European lawmakers grew increasingly concerned about a U.S. digital “kill switch” and the security of the cloud services supplied by major U.S. companies they’d come to rely on, one thing was clear: they were not nearly as sovereign as they previously believed, and their dependence on U.S. tech had to be addressed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rolling back tech regulation&lt;/head&gt;
    &lt;p&gt;Canada is not immune from these vulnerabilities. Due to our geographic proximity to and greater dependence on the United States, they are arguably even more present as Canadians reassess our relationship with our neighbour to the south. We have already seen how effectively the United States can apply pressure to Canada in the tech domain and beyond.&lt;/p&gt;
    &lt;p&gt;If we look at Europe, the pressure from U.S. tech executives like Meta CEO Mark Zuckerberg or Apple CEO Tim Cook is much more apparent. The chief executives and company spokespeople regularly single out European regulations causing them commercial headaches. In Canada, that pressure is still there; the executives just don’t often speak out publicly. The more vocal opposition is outsourced to domestic tech leaders and our own coterie of commentators that echo narratives beneficial to the big U.S. tech giants.&lt;/p&gt;
    &lt;p&gt;Over the past couple years, we saw a concerted campaign by Canadian tech executives, aligned with the right-wing politics their counterparts in Silicon Valley adopted, begin to openly push a political program in their interests, often paired with explicit support for Pierre Poilievre and the Conservative Party. However, since Mark Carney replaced Justin Trudeau at the helm of the Liberal Party, they’ve embraced the central banker-in-chief. He’s committed to attracting investment above all else, and that means he’s much more open to their policy demands.&lt;/p&gt;
    &lt;p&gt;As a result, we’ve seen a rapid erosion in the government’s efforts to rein in U.S. tech companies. Since April, planned AI regulations have been put on ice, along with the Online harms bill that sought to address harmful behaviour in online spaces. That was in spite of concretely seeing how those platforms are used by bad actors to sow division within society as wildfires spread across the country again this past summer. In parts of the country, local politicians had to directly respond to disinformation spreading online that people desperate for updates were falling for.&lt;/p&gt;
    &lt;p&gt;In June, another pillar in the Trudeau government’s attempt to regulate the tech industry fell when Donald Trump walked away from trade negotiations, saying he would only return once the Canadian government repealed its digital services tax. Executives like Zuckerberg have lobbied Trump to try to kill those taxes in countries around the world. Late on the Sunday night before the tax was supposed to come into effect, Carney and Finance Minister François-Philippe Champagne announced it would be sacrificed so talks could continue. Months later, a comprehensive deal with the United States remains elusive.&lt;/p&gt;
    &lt;p&gt;It can be easy to believe that all this pressure is a product of the way Trump’s return to office emboldened U.S. tech companies, but it’s simply brought a longstanding process out into the open. The U.S. government has long recognized how much it benefits from ensuring other countries are dependent on products and services made by companies in its jurisdiction. For years, it used trade negotiations to insert clauses in agreements that limit foreign governments’ ability to regulate its tech companies and has used its diplomats to apply pressure in other ways.&lt;/p&gt;
    &lt;p&gt;For example, CUSMA contains measures that constrain the authority of the Canadian government to regulate the tech industry. The agreement limits the ability to regulate cross-border data flows, to force companies to reveal their source code, to discriminate between foreign and domestic tech firms, or to expect them to store data on Canadians within our borders. On top of that, U.S. officials under the Biden administration regularly pressured the government when it moved forward with tech regulations, including with the streaming bill and digital services tax. The Online News Act is the latest to find itself in U.S. crosshairs.&lt;/p&gt;
    &lt;p&gt;Protecting the global market share and curtailing attempts to rein in U.S. tech companies is bipartisan policy in the United States. They may occasionally get angry at certain domestic consequences of the tech products they depend on, but Democrats and Republicans alike are not very concerned about how those issues play out beyond the country’s borders. Ensuring other countries depend on U.S. tech companies not only increases U.S. power, but also provides it with ample economic benefits.&lt;/p&gt;
    &lt;head rend="h2"&gt;The consequences of dependence&lt;/head&gt;
    &lt;p&gt;Political developments in the 1980s and 1990s played a key role in shaping the dominant position the United States holds today. In the late 1980s, then Senator Al Gore recognized that technology and power were inseparable. In a speech to the senate, he declared that “the nation which most completely assimilates high-performance computing into its economy will very likely emerge as the dominant intellectual, economic, and technological force in the next century.”&lt;/p&gt;
    &lt;p&gt;Gore and President Bill Clinton were intent on ensuring the United States reaped the gains of the emerging internet. What started as a military and academic project had already begun to be commercialized, and in 1995, they completed the handover of the public infrastructure to the private sector. U.S. companies got a head start on building the businesses that would dominate the digital economy, and much easier access to capital to rapidly scale domestically and later internationally.&lt;/p&gt;
    &lt;p&gt;In those years, the model of the internet was established—and the private sector was firmly in charge. There were debates about carving out a “public lane” on the “information superhighway,” but those efforts were ultimately defeated.&lt;/p&gt;
    &lt;p&gt;The U.S. government used its influence to push for telecom deregulation and the removal of trade barriers around the world, aiding its companies to move into international markets. Tech advocacy groups assisted in their own way by crafting a narrative that the internet was inherently liberatory and any attempts by governments to restrict the expansion of digital services, platforms, and the companies that run them was an inherent breach of their citizens’ rights. Over time, U.S. companies rode the wave to global dominance, and as they took over new markets, domestic competitors were acquired or simply failed in face of the pressure.&lt;/p&gt;
    &lt;p&gt;Our dependence on U.S. tech has long been a problem, just one that many people in power did not want to touch because of how it would anger the United States. Even proposing basic tech regulations prompted rebukes from the U.S. government and threatened the prospect of investment from those digital colonizers. But that dependence left us without the tools to get a handle on key avenues for communication and commerce.&lt;/p&gt;
    &lt;p&gt;As U.S. tech companies fought to roll back workers’ rights in the gig economy and beyond, allowed false information to spread across social media platforms, decimated the funding model for journalism, and had countless other negative social impacts, the Canadian government was limited in its ability to respond. All the while, as more Canadians—both individuals and companies—became dependent on U.S. digital services, the profits were siphoned back to the United States, fueling a growing economic divide that has prompted economists to start sounding the alarm.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reclaiming digital sovereignty&lt;/head&gt;
    &lt;p&gt;There is one thing we can say for Trump’s attacks on Canada: they have finally given us the space to speak openly and honestly about many of the ways the U.S.-Canada relationship has not been working for us for a very long time—and the digital dimension of our lopsided economic integration is a massive part of that. If Canada is to regain greater autonomy over its affairs and build a better society, we must get serious about reclaiming our digital sovereignty.&lt;/p&gt;
    &lt;p&gt;Since Trump’s return to office, governments have been ramping up defence spending to ensure they can defend themselves in a world where the United States is no longer a security guarantor and possibly even a security threat. That same seriousness should be given to digital technology.&lt;/p&gt;
    &lt;p&gt;As our European allies have found first hand, our dependence on U.S. companies for cloud services creates a severe vulnerability, where the U.S. government can request whatever data it wants or can even shut off our access at a moment’s notice. During the election campaign, Carney said he would be reassessing public cloud contracts going to Amazon, Microsoft, Google, and Oracle. More recently, when he announced the first batch of nation-building projects, the prime minister called out the need for a sovereign cloud. He is taking steps in the right direction, but the devil will be in the details.&lt;/p&gt;
    &lt;p&gt;Our ambition cannot stop there though. In far too many cases, our governments, universities, schools, and other public institutions—not to mention private businesses—are run on Microsoft or Google services. Now is the perfect time to get governments off Microsoft 365 and schools off Google Classroom by properly resourcing a new public agency or Crown corporation dedicated to building technology in the public interest.&lt;/p&gt;
    &lt;p&gt;European state, local, and even departments of national governments are already taking the initiative to move in that direction. There are ample open-source tools already out there that could be adapted to those institutional use cases, with a mandate to work in close collaboration with public institutions to ensure their new suite of digital services properly meets their unique needs. Governments could even think about bringing tech development closer to communities, building on a model not dissimilar to public libraries.&lt;/p&gt;
    &lt;p&gt;We have an opportunity to think bigger and to challenge those fundamental assumptions that were crafted in the 1990s to convince us digital technology had to be left to the private sector. For three decades, the goal of tech development has not been to improve our lives or to serve the public good, but rather to maximize shareholder value and to increase the power of the companies that control it. It’s that nature of digital technology that is at the root of so many of the social harms that the tech oligopoly have saddled us with in recent years. We need to recognize that was a choice, and we can choose to take a different path.&lt;/p&gt;
    &lt;p&gt;But we must also be aware of the pitfalls ahead. Some Canadian tech executives that, until recently, were pushing for a Conservative government are embracing a program of digital sovereignty as well, but it is explicitly not one that centres the public good. Instead, they’re pushing the government to continue pulling back on regulations, while deploying billions through public procurement, incentives, and subsidies to flood into their businesses. They want to hold onto the Silicon Valley model and the harms that it’s created, but better cash in on it for themselves. They want to join the digital colonizers rather than bring them down.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.policyalternatives.ca/news-research/every-data-centre-is-a-u-s-military-base/"/><published>2026-01-17T07:43:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656358</id><title>Show HN: Streaming gigabyte medical images from S3 without downloading them</title><updated>2026-01-17T10:10:18.308952+00:00</updated><content>&lt;doc fingerprint="286dba183daf5de1"&gt;
  &lt;main&gt;
    &lt;p&gt;A modern, cloud-native tile server for Whole Slide Images. One command to start serving tiles directly from S3.&lt;/p&gt;
    &lt;code&gt;# Installation (requires Rust, see alternatives below)
cargo install wsi-streamer

# On your local machine
wsi-streamer s3://my-slides-bucket --s3-region eu-west-3&lt;/code&gt;
    &lt;p&gt;That's it. No configuration files, no local storage, no complex setup. Open &lt;code&gt;http://localhost:3000/view/sample.svs&lt;/code&gt; in your browser to view a slide.&lt;/p&gt;
    &lt;p&gt;Whole Slide Images are large (1-10GB+) and typically live in object storage. Traditional viewers require downloading entire files before serving a single tile. WSI Streamer takes a different approach: it understands slide formats natively, fetches only the bytes needed via HTTP range requests, and returns JPEG tiles immediately.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Range-based streaming — fetches only the bytes needed for each tile, no local files&lt;/item&gt;
      &lt;item&gt;Built-in viewer — OpenSeadragon-based web viewer with pan, zoom, and dark theme&lt;/item&gt;
      &lt;item&gt;Native format support — Rust parsers for Aperio SVS and pyramidal TIFF&lt;/item&gt;
      &lt;item&gt;Production-ready — HMAC-SHA256 signed URL authentication&lt;/item&gt;
      &lt;item&gt;Multi-level caching — slides, blocks, and encoded tiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install from crates.io:&lt;/p&gt;
    &lt;code&gt;cargo install wsi-streamer&lt;/code&gt;
    &lt;p&gt;Or build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/PABannier/WSIStreamer.git
cd WSIStreamer
cargo build --release&lt;/code&gt;
    &lt;p&gt;Or run with Docker:&lt;/p&gt;
    &lt;code&gt;# Pull from GitHub Container Registry
docker run -p 3000:3000 -e WSI_S3_BUCKET=my-bucket ghcr.io/pabannier/wsistreamer:latest

# Or use Docker Compose for local development with MinIO
docker compose up --build&lt;/code&gt;
    &lt;code&gt;# Serve slides from S3
wsi-streamer s3://my-slides

# Custom port
wsi-streamer s3://my-slides --port 8080

# S3-compatible storage (MinIO, etc.)
wsi-streamer s3://slides --s3-endpoint http://localhost:9000&lt;/code&gt;
    &lt;code&gt;# List slides
curl http://localhost:3000/slides

# Get slide metadata
curl http://localhost:3000/slides/sample.svs

# Fetch a tile (level 0, position 0,0)
curl http://localhost:3000/tiles/sample.svs/0/0/0.jpg -o tile.jpg

# Get thumbnail
curl "http://localhost:3000/slides/sample.svs/thumbnail?max_size=256" -o thumb.jpg&lt;/code&gt;
    &lt;code&gt;# Enable HMAC-SHA256 authentication
wsi-streamer s3://my-slides --auth-enabled --auth-secret "$SECRET"

# Generate signed URLs
wsi-streamer sign --path /tiles/slide.svs/0/0/0.jpg --secret "$SECRET" --base-url http://localhost:3000&lt;/code&gt;
    &lt;p&gt;The web viewer handles authentication automatically when enabled.&lt;/p&gt;
    &lt;code&gt;# Check S3 connectivity
wsi-streamer check s3://my-slides

# List available slides
wsi-streamer check s3://my-slides --list-slides

# Test a specific slide
wsi-streamer check s3://my-slides --test-slide sample.svs&lt;/code&gt;
    &lt;p&gt;All options can be set via CLI flags or environment variables:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Env Var&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_HOST&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.0.0.0&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bind address&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_PORT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3000&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTTP port&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-bucket&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_BUCKET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;S3 bucket name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-endpoint&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_ENDPOINT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Custom S3 endpoint&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-region&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_REGION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;us-east-1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;AWS region&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--auth-enabled&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_AUTH_ENABLED&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable authentication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--auth-secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_AUTH_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;HMAC secret key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--cache-slides&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CACHE_SLIDES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Max slides in cache&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--cache-tiles&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CACHE_TILES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100MB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Tile cache size&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--jpeg-quality&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_JPEG_QUALITY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;80&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JPEG quality (1-100)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--cors-origins&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CORS_ORIGINS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;any&lt;/cell&gt;
        &lt;cell&gt;Allowed CORS origins&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;wsi-streamer --help&lt;/code&gt; for full details.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Endpoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /health&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Health check&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /view/{slide_id}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Web viewer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /tiles/{slide_id}/{level}/{x}/{y}.jpg&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fetch tile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List slides&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Slide metadata&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}/thumbnail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Thumbnail&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}/dzi&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;DZI descriptor&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See API_SPECIFICATIONS.md for complete documentation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Format&lt;/cell&gt;
        &lt;cell role="head"&gt;Extensions&lt;/cell&gt;
        &lt;cell role="head"&gt;Compression&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Aperio SVS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.svs&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JPEG, JPEG 2000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pyramidal TIFF&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;.tif&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;JPEG, JPEG 2000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Files must be tiled (not stripped) and pyramidal.&lt;/p&gt;
    &lt;p&gt;MIT. See LICENSE.&lt;/p&gt;
    &lt;p&gt;Issues and pull requests welcome. See CONTRIBUTING.md.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/PABannier/WSIStreamer"/><published>2026-01-17T08:46:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656373</id><title>Office app has changed to copilot and now I can't open files</title><updated>2026-01-17T10:10:18.266414+00:00</updated><content/><link href="https://old.reddit.com/r/Office365/comments/1q2b28q/office_app_has_changed_to_copilot_and_now_i_cant"/><published>2026-01-17T08:48:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656552</id><title>ClickHouse Acquires Langfuse</title><updated>2026-01-17T10:10:18.140097+00:00</updated><content>&lt;doc fingerprint="2bee90517ddf277e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Langfuse joins ClickHouse&lt;/head&gt;
    &lt;p&gt;Our goal continues to be building the best LLM engineering platform&lt;/p&gt;
    &lt;p&gt;ClickHouse has acquired Langfuse.&lt;/p&gt;
    &lt;p&gt;If you’re reading this as a Langfuse user, your first question is probably: What does this mean for me?&lt;/p&gt;
    &lt;p&gt;Our roadmap stays the same, our goal continues to be building the best LLM engineering platform, and we remain committed to open source and self-hosting. There are no immediate changes to how you use Langfuse and how you can reach out to us.&lt;/p&gt;
    &lt;p&gt;What does change is our ability to move faster. With ClickHouse behind us, we can invest more deeply into performance, reliability, and our roadmap that helps teams build and improve AI applications in production.&lt;/p&gt;
    &lt;head rend="h2"&gt;What stays the same&lt;/head&gt;
    &lt;p&gt;This is the section we would want to read first, too.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Langfuse stays open source and self‑hostable. There are no planned changes to licensing. As you know, we leaned heavily into OSS over the last years.&lt;/item&gt;
      &lt;item&gt;Langfuse Cloud keeps running as‑is. Same product, same endpoints, same experience.&lt;/item&gt;
      &lt;item&gt;Support stays the same. Same channels, same SLAs for existing customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What gets better now&lt;/head&gt;
    &lt;p&gt;Joining Clickhouse compresses years of operational learning into immediate, real customer benefits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More engineering leverage on the hardest parts. Langfuse is a data‑intensive product. Working closely with the ClickHouse engineering team helps us push performance and reliability.&lt;/item&gt;
      &lt;item&gt;Faster progress on enhanced enterprise-grade compliance and security, with the help of Clickhouse’s resources.&lt;/item&gt;
      &lt;item&gt;Learning from Clickhouse’s customer success and support playbook. This puts us years ahead and allows us to spend more time on what we really care about: our users.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A quick look back&lt;/head&gt;
    &lt;p&gt;The longer version of how we got here is in our handbook.&lt;/p&gt;
    &lt;p&gt;Langfuse started the same way many LLM products start: we were building agents ourselves. And we constantly ran into the same problems.&lt;/p&gt;
    &lt;p&gt;Building LLM apps is easy to demo and hard to run in production. Debugging is different, quality is non‑deterministic, and the iteration loop is messy. When we did Y Combinator in early 2023, we saw this every week, both in our own projects and in what other founders in our cohort were working on.&lt;/p&gt;
    &lt;p&gt;So we built a duct tape version of what we wished existed: tracing and evaluation primitives that are easy to add, easy to self‑host, and actually useful for iterating.&lt;/p&gt;
    &lt;p&gt;The very first version was intentionally simple. It ran on Postgres, because speed of shipping mattered more than theoretical scaling. That got us to a real product and a real community fast.&lt;/p&gt;
    &lt;p&gt;Then people actually started to use the product more than we could have imagined.&lt;/p&gt;
    &lt;p&gt;As adoption grew, Postgres became the bottleneck for the workloads Langfuse needed to support (high‑throughput ingestion + fast analytical reads). With Langfuse v3, we switched the core data layer to ClickHouse to make Langfuse scale for production workloads, both in Cloud and self‑hosted deployments.&lt;/p&gt;
    &lt;p&gt;And if you like infrastructure deep dives, here’s the v3 migration write‑up.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why join ClickHouse&lt;/head&gt;
    &lt;p&gt;There are a lot of ways this could have gone. We didn’t plan to sell the company. Actually, we had Term Sheets for a great Series A and were looking forward to some days off over Christmas after an intense year.&lt;/p&gt;
    &lt;p&gt;What changed wasn’t our conviction in Langfuse, it was realizing how much faster we can go together with ClickHouse, while staying true to what makes Langfuse work: open source, self-hosting, and a product that’s built for real production workloads.&lt;/p&gt;
    &lt;head rend="h3"&gt;A shared history (before the acquisition)&lt;/head&gt;
    &lt;p&gt;This dialogue didn’t start with a term sheet. Because Langfuse runs on ClickHouse, we naturally ended up collaborating early and often.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We’ve always been closely in touch with many teams at ClickHouse: sharing feedback with the database team, and using new features to make Langfuse more reliable. For example, compute-compute separation helps us to reduce the risk of noisy-neighbours on Langfuse Cloud.&lt;/item&gt;
      &lt;item&gt;Langfuse Cloud is a large customer of ClickHouse Cloud.&lt;/item&gt;
      &lt;item&gt;Teams at ClickHouse use Langfuse to improve their agentic applications.&lt;/item&gt;
      &lt;item&gt;We invested heavily in ClickHouse-backed self-hosting: documentation, templates, and deployment patterns, and collaborated closely with ClickHouse on improving that experience.&lt;/item&gt;
      &lt;item&gt;As a result, Langfuse introduced thousands of teams to ClickHouse when upgrading from Langfuse v2 to v3.&lt;/item&gt;
      &lt;item&gt;We’ve done community meetups together: a ClickHouse meetup at our Berlin office, another one in San Francisco, and an OpenHouse talk in Amsterdam.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Langfuse runs on ClickHouse, ClickHouse uses Langfuse to optimize its agentic products, we share lots of customers and OSS deployments; that gives ClickHouse every incentive to keep Langfuse fast, reliable, and boringly dependable at scale.&lt;/p&gt;
    &lt;p&gt;So in many ways, we operated like long-term partners. This acquisition is a way to make that partnership permanent — and invest aggressively together.&lt;/p&gt;
    &lt;p&gt;Max shared on how we use ClickHouse to keep product performance ahead of demand at ClickHouse Open House (recording) in Amsterdam.&lt;/p&gt;
    &lt;head rend="h3"&gt;Culture and engineering fit&lt;/head&gt;
    &lt;p&gt;The first time we met Aaron, Yury, Alexey, Tanya, Ryadh, and Pete in-person ended up in a long lunch in Amsterdam. It became obvious we share a similar view on building great developer tooling, how that drives everything within our companies, and how fast analytics is increasingly foundational for building and optimizing agentic products.&lt;/p&gt;
    &lt;p&gt;We already knew that ClickHouse is one of the best infrastructure engineering teams in the world. More importantly, the engineering culture feels like an instant match:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;open-source identity and stewardship&lt;/item&gt;
      &lt;item&gt;developer-first product instincts&lt;/item&gt;
      &lt;item&gt;performance and reliability as product features (not afterthoughts)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The whole Langfuse team will join ClickHouse to continue building Langfuse. All of these aspects were important to us and we couldn’t be more excited.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we’re focused on next&lt;/head&gt;
    &lt;p&gt;Our north star doesn’t change: help teams ship useful, reliable agents by closing the loop from production data to better prompts, evaluations, and product decisions.&lt;/p&gt;
    &lt;p&gt;Concretely, we’re investing in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Production monitoring and analytics for real agent systems (not just offline evals).&lt;/item&gt;
      &lt;item&gt;Workflows across tracing, labeling, and experiments so iteration loops get shorter.&lt;/item&gt;
      &lt;item&gt;More performance and scale—especially for large self‑hosted and enterprise deployments.&lt;/item&gt;
      &lt;item&gt;More polish (UI/UX, developer experience, and docs) so the product stays simple even as the space gets more complex.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can always follow along on the public roadmap.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;Langfuse exists because the community pushed it forward, through GitHub issues, PRs, feedback, and lots of Slack messages and spontaneous calls to dig into a product feature together.&lt;/p&gt;
    &lt;p&gt;We’re grateful for the trust you’ve put in us. Joining ClickHouse is our way of honoring that trust by putting more resources behind the thing we care about most: building a product you can rely on.&lt;/p&gt;
    &lt;p&gt;We’re excited for what’s next!&lt;lb/&gt; Max, Clemens, and Marc&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;p&gt;Is Langfuse still open source?&lt;lb/&gt;Yes. No licensing changes planned.&lt;/p&gt;
    &lt;p&gt;Can I still self‑host Langfuse?&lt;lb/&gt;Yes. Self‑hosting is a first‑class path.&lt;/p&gt;
    &lt;p&gt;Does anything change for Langfuse Cloud customers today?&lt;lb/&gt;No. Same product, same endpoints, same contracts.&lt;/p&gt;
    &lt;p&gt;Where do I go for support?&lt;lb/&gt;No changes: https://langfuse.com/support&lt;/p&gt;
    &lt;p&gt;Will the Langfuse team stay on Langfuse?&lt;lb/&gt;Yes. The team is joining ClickHouse and will keep building Langfuse. Also, we continue hiring in Berlin and SF.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join the discussion&lt;/head&gt;
    &lt;p&gt;If you have any other questions, let’s discuss together on GitHub Discussions.&lt;/p&gt;
    &lt;p&gt;If you’re an enterprise customer and have additional questions, feel free to reach out to enterprise@langfuse.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://langfuse.com/blog/joining-clickhouse"/><published>2026-01-17T09:15:45+00:00</published></entry></feed>