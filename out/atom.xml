<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-25T00:53:10.628758+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46367377</id><title>Confessions to a Data Lake</title><updated>2025-12-25T00:53:23.098873+00:00</updated><content>&lt;doc fingerprint="26c3c9593ae49cda"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Confessions to a data lake&lt;/head&gt;
    &lt;p&gt;Iâve been building Confer: end-to-end encryption for AI chats. With Confer, your conversations are encrypted so that nobody else can see them. Confer canât read them, train on them, or hand them over â because only you have access to them.&lt;/p&gt;
    &lt;p&gt;The core idea is that your conversations with an AI assistant should be as private as your conversations with a person. Not because youâre doing something wrong, but because privacy is what lets you think freely.&lt;/p&gt;
    &lt;p&gt;I founded Signal with a simple premise: when you send someone a message, only that person should be able to read it. Not the company transmitting it, not the government, not anyone else on the internet. It took years, but eventually this idea became mainstream enough that even Facebook adopted end-to-end encryption.&lt;/p&gt;
    &lt;p&gt;These days I spend a lot of time âtalking toâ LLMs. They are amazing. A big part of what makes them so powerful is the conversational interface â so once again I find myself sending messages on the internet; but these messages are very different than before.&lt;/p&gt;
    &lt;head rend="h2"&gt;The medium is the message&lt;/head&gt;
    &lt;p&gt;Marshall McLuhan argued that the form of a medium matters more than its content. Televisionâs format - passive, visual, interrupt-driven - shaped society more than any particular broadcast. The printing press changed how we think, not just what we read.&lt;/p&gt;
    &lt;p&gt;You could say that LLMs are the first technology where the medium actively invites confession.&lt;/p&gt;
    &lt;p&gt;Search trained us to be transactional: keywords in, links out. When you type something into a search box, it has the âfeelingâ of broadcasting something to a company rather than communicating in an intimate space.&lt;/p&gt;
    &lt;p&gt;The conversational format is different. When youâre chatting with an âassistant,â your brain pattern-matches to millennia of treating dialogue as intimate. You elaborate. You think out loud. You share context. Thatâs a big part of what makes it so much more useful than search â you can iterate, elaborate, change your mind, ask follow-up questions.&lt;/p&gt;
    &lt;p&gt;One way to think about Signalâs initial premise is that the visual interfaces of our tools should faithfully represent the way the underlying technology works: if a chat interface shows a private conversation between two people, it should actually be a private conversation between two people, rather than a âgroup chatâ with unknown parties underneath the interface.&lt;/p&gt;
    &lt;p&gt;Today, AI assistants are failing this test harder than anything ever before. We are using LLMs for the kind of unfiltered thinking that we might do in a private journal â except this journal is an API endpoint. An API endpoint to a data lake specifically designed for extracting meaning and context. We are shown a conversational interface with an assistant, but if it were an honest representation, it would be a group chat with all the OpenAI executives and employees, their business partners / service providers, the hackers who will compromise that plaintext data, the future advertisers who will almost certainly emerge, and the lawyers and governments who will subpoena access.&lt;/p&gt;
    &lt;p&gt;None of this is entirely new, exactly. We went through the same cycle with email. In the early days, people treated email like private correspondence. Then we learned that our emails live forever on corporate servers, that theyâre subject to discovery in lawsuits, that theyâre available to law enforcement, that theyâre scanned for advertising. Slowly, culturally, we adjusted our expectations. We learned not to put certain things in email.&lt;/p&gt;
    &lt;head rend="h2"&gt;Advertising is coming&lt;/head&gt;
    &lt;p&gt;What is new is that email and social media are interfaces where we mostly post completed thoughts. AI assistants are a medium that invites us to post our uncompleted thoughts.&lt;/p&gt;
    &lt;p&gt;When you work through a problem with an AI assistant, youâre not just revealing information - youâre revealing how you think. Your reasoning patterns. Your uncertainties. The things youâre curious about but donât know. The gaps in your knowledge. The shape of your mental model.&lt;/p&gt;
    &lt;p&gt;When advertising comes to AI assistants, they will slowly become oriented around convincing us of something (to buy something, to join something, to identify with something), but they will be armed with total knowledge of your context, your concerns, your hesitations. It will be as if a third party pays your therapist to convince you of something.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making the interface match the way the technology works&lt;/head&gt;
    &lt;p&gt;Confer is designed to be a service where you can explore ideas without your own thoughts potentially conspiring against you someday; a service that breaks the feedback loop of your thoughts becoming targeted ads becoming thoughts; a service where you can learn about the world â without data brokers and future training runs learning about you instead.&lt;/p&gt;
    &lt;p&gt;Itâs still an early project, but Iâve been testing it with friends for a few weeks. Keep an eye on this blog for more technical posts to follow. Try it out and let me know what you think!&lt;/p&gt;
    &lt;p&gt;Don't have Confer? Give it a try!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://confer.to/blog/2025/12/confessions-to-a-data-lake/"/><published>2025-12-23T17:51:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46368827</id><title>Pantograph: Building a preschool for robots</title><updated>2025-12-25T00:53:23.010504+00:00</updated><content>&lt;doc fingerprint="6511291f21e6acab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Pantograph: Building a Preschool for Robots&lt;/head&gt;
    &lt;p&gt;In order to solve robotics' data problem, we're building a preschool for robots.&lt;/p&gt;
    &lt;p&gt;The areas of deep learning that have seen the fastest progress in the past decade are those where data is abundant: language models and image generators can train on the entire internet; game-playing models like AlphaGo can generate data by playing against themselves. These datasets don't exist for robotics, so we need to create them from scratch.&lt;/p&gt;
    &lt;p&gt;At Pantograph, we're creating systems that are capable of unsupervised data gathering in the real world. Our models build representations of the world as they go, gradually learning about the world around them and about how they can influence it. Like language models, they are trained on enough diverse data to be able to generalize to new, unseen tasks. Like AlphaGo, our models learn from experience, continuously improving as they interact with the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exploration in the Real World&lt;/head&gt;
    &lt;p&gt;What would the ideal real-world robotics dataset look like? Scale is important, as is diversity. The internet has an abundance of videos, so the most important real-world data to collect is about things that are difficult to infer from video. We need data about the properties of materials: texture, viscosity, density, what it feels like to bend something, to rub something against something else.&lt;/p&gt;
    &lt;p&gt;This first phase of data collection will look something like a robot preschool: thousands of small, inexpensive robots, touching everything they can get their hands on, tossing things around, finding the exact balancing point of two wooden blocks, bending, rubbing, scraping, building up a model of the world around them. This data will be the foundation upon which we will train increasingly capable models.&lt;/p&gt;
    &lt;p&gt;The robots will not only learn about the world around them, but also about themselves. The resulting models will be native to the robot's hardware, better able to exploit its capabilities and idiosyncrasies than any human operator.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware Demo&lt;/head&gt;
    &lt;p&gt;Today, we're releasing an early preview of our hardware. It's designed from the ground up for what we think of as the robot preschool — this first phase of data collection, exploration, and long-horizon tasks.&lt;/p&gt;
    &lt;p&gt;Data scale matters, so minimizing cost matters. This makes our robot's small size an asset: it's cheaper to build, easier to scale, and faster to replace. Being small and low to the ground also makes it safer to be around as it learns - failures are less damaging, and human supervisors can easily pick it up and move it around. This is true for toddlers just as much as robots: being little makes being uncoordinated a lot less dangerous.&lt;/p&gt;
    &lt;p&gt;Real-world exploration also presents a specific hardware challenge: durability. Early models won't be especially coordinated: they'll bump into things, hit the ground, each other, themselves. The hardware has to survive that. We decided to design our hardware in-house because every detail matters when building a system that's robust and reliable at scale. Our team started with component-level testing — at this point, we've amassed over 10,000 hours of in-house stress and endurance data validating our most critical parts.&lt;/p&gt;
    &lt;p&gt;Our robot is small, strong, and exceptionally durable. It has treads instead of wheels, which make it more stable, terrain-capable, and motor efficient. It's an "origami" robot wherever possible: we lean heavily on 2D profile-based manufacturing — die cutting, laser cutting and bent sheet metal construction so that the design is materially efficient and easy to manufacture at scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;Strength&lt;/head&gt;
    &lt;p&gt;Despite its size, our robot is quite strong. Fully extended, its arms each have a continuous payload of about 1kg, and it's capable of moving much heavier objects, as shown in the clips below.&lt;/p&gt;
    &lt;p&gt;Two robots together can move a couch, a person, and an IKEA bookshelf (~130kg):&lt;/p&gt;
    &lt;head rend="h2"&gt;Dexterity&lt;/head&gt;
    &lt;p&gt;Fine manipulation is the most difficult robotic capability, and we've designed our grippers to be simple while still capable of complex manipulation tasks. The following clips show our grippers connecting zip ties, inserting a USB cable into a port, and building a structure out of wooden blocks:&lt;/p&gt;
    &lt;head rend="h2"&gt;Tool Use&lt;/head&gt;
    &lt;p&gt;The world around us was mostly designed for humans, and it's important that a general-purpose robot be able to interact with tools designed for human hands. The compliance of our robot's grippers makes it better able to manipulate such tools. The following clips show our robot using scissors to cut a piece of paper, an electric screw driver to insert a fastener, and a label maker to print a message:&lt;/p&gt;
    &lt;head rend="h2"&gt;Teleoperation Setup&lt;/head&gt;
    &lt;p&gt;The demos above were collected via a simple teleoperation setup, pictured below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting This Right Matters&lt;/head&gt;
    &lt;p&gt;A pantograph is a mechanical linkage that scales and replicates motion: trace a shape with one end, and the other reproduces it larger or smaller. We named our company Pantograph because we believe robotics should do the same for human agency: amplify what people can do, extend our reach, and multiply our capacity to shape the world around us.&lt;/p&gt;
    &lt;p&gt;Generally intelligent robots will reshape how work gets done and what people are capable of building. This technology touches the foundations of how society is organized: labor, economics, what it means to make something. That weight is something we feel.&lt;/p&gt;
    &lt;p&gt;We want robotics to amplify what it is possible for humans to do. We're targeting low hardware costs not just because it lets us train at scale, but because we want to expand who gets to build and what becomes possible to build. More labs, more workshops, more ambitious projects that today are impractical. This is a future that should be widely shared.&lt;/p&gt;
    &lt;p&gt;We structured Pantograph as a Public Benefit Corporation because we take seriously both the promise and the responsibility of what we're building. The PBC structure encodes that commitment into how we're governed, ensuring that as we scale, we remain accountable to something beyond short-term returns.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's Next&lt;/head&gt;
    &lt;p&gt;We're in the process of massively scaling up data collection with our hardware. We own the entire stack, from hardware and firmware to our training infrastructure and learning algorithms. In all of these areas, there is much work to do.&lt;/p&gt;
    &lt;p&gt;On the hardware side, we're scaling to thousands of robots over the coming months. We'll be iterating on our designs for reliability, manufacturability, and capability, and keeping the robots running continuously. We're deepening our relationships with suppliers who can scale with us. Beyond this generation, we're interested in building hardware that meets a wider range of needs and exploring new form factors.&lt;/p&gt;
    &lt;p&gt;On the research side, there are many unanswered questions: what's the right task distribution? What's the right way to incorporate pretraining? How can we steer the resulting models? These algorithms have never been scaled up before, and there is a lot of room for new ideas.&lt;/p&gt;
    &lt;p&gt;If the prospect of designing hardware and algorithms that can learn continuously in the real world sounds exciting to you, we're hiring!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pantograph.com/blog/building-a-preschool-for-robots.html"/><published>2025-12-23T19:59:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46373644</id><title>The e-scooter isn't new – London was zooming around on Autopeds a century ago</title><updated>2025-12-25T00:53:22.291770+00:00</updated><content>&lt;doc fingerprint="f24298f1f9a8250f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The e-scooter isn’t new – London was zooming around on Autopeds a century ago&lt;/head&gt;
    &lt;p&gt;The e-scooters that clutter up pavements may seem like a new thing, but a hundred years ago, there were already people zooming around London on powered scooters.&lt;/p&gt;
    &lt;p&gt;These were the Autoped, an American import that was once popular enough to regularly appear in the newspapers before vanishing seemingly without a trace.&lt;/p&gt;
    &lt;p&gt;Invented in the USA in 1915, they first appeared in London in 1917, despite a ban on imports during WWI, and really took off when the import ban was lifted in 1919.&lt;/p&gt;
    &lt;p&gt;By today’s standards, they look like a bargain, selling for just £36, although that’s actually about £1,600 in today’s money, so they were really aimed at the wealthy buyers.&lt;/p&gt;
    &lt;p&gt;Gamage’s, the people’s emporium, described them as being made for everybody who feels the necessity of making the most of time, of conserving health and energy, and keeping travelling expenses down to the minimum.&lt;/p&gt;
    &lt;p&gt;It was said to be able to reach speeds of 10mph, and unlike modern versions, the Autoped was powered by petrol.&lt;/p&gt;
    &lt;p&gt;(There was apparently an electric version by Eveready, but it might have been only in the USA)&lt;/p&gt;
    &lt;p&gt;For comfort over rough roads, they were fitted with 15-inch-diameter pneumatic tyres. The Lady magazine suggested the Autoped would make for a more suitable alternative to the motorbike.&lt;/p&gt;
    &lt;p&gt;They even played a key role in a silent movie, At Sword’s Point, about an annoying man who refuses to say no when rebuffed by a lady and, when trying to escape the relatives, steals an Autoped but collides with his pursuer, also on an Autoped. An “explosion followed, and they both disappeared”.&lt;/p&gt;
    &lt;p&gt;Wait, what?&lt;/p&gt;
    &lt;p&gt;His Majesty’s government wasn’t going to be left behind either, and there was a report in the Pall Mall Gazette of a “distinguished looking autopedist, gracefully erect” sweeping down Whitehall delivering parcels to 10 Downing Street.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;American Miss Shirley Kellogg brings new motor scooter invention to England. &lt;/p&gt;
    &lt;p&gt;However, by 1922, the adverts aren’t by Gammages, but by owners selling them off cheaply in the classified ads. Several noted that the owners were switching to a car instead.&lt;/p&gt;
    &lt;p&gt;It seems that the British weather might have killed off the Autoped.&lt;/p&gt;
    &lt;p&gt;But finally, to that famous image of a lady on an Autoped – it’s of Lady Florence Priscilla Norman, a noted suffragist and was given the Autoped by her husband, the Liberal MP, Henry Norman.&lt;/p&gt;
    &lt;p&gt;Just think, had the Autoped lingered on for a few more years and become more affordable as manufacturing increased, how different the streets of our cities could have been.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ianvisits.co.uk/articles/the-e-scooter-isnt-new-london-was-zooming-around-on-autopeds-a-century-ago-86263/"/><published>2025-12-24T08:32:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46374856</id><title>Avoid Mini-Frameworks</title><updated>2025-12-25T00:53:22.121694+00:00</updated><content>&lt;doc fingerprint="3f8a9131171b9adb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Avoid Mini-frameworks&lt;/head&gt;
    &lt;p&gt;I work in Google Ads infrastructure in the past four years. Over time, I've seen one pattern came along again and again, causing endless pain for developers, that is, creating mini-frameworks.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is mini-framework?&lt;/head&gt;
    &lt;p&gt;First, I'd like to give readers a sense of what I mean by "mini-frameworks". Imagine a company that has 1000 engineers, and they share the same tech stack. Over time, a team finds the shared tech stack unsatisfactory, either because they have to write boilerplate code over and over, or the performance is not good enough, or whatever. So they decided to create their own framework on top of the shared stack. You know it's a framework and not just a library, when you hear engineers present the work using concepts they invented, as a way to actualize their mental model. Framework like this is what I called "mini-framework", with some common characteristics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Created by a small number of team(s) to solve their pain points&lt;/item&gt;
      &lt;item&gt;Wraps around the company/org-shared tech stack or framework&lt;/item&gt;
      &lt;item&gt;Introduce new concepts that doesn't exist in the original stack&lt;/item&gt;
      &lt;item&gt;Creators claim that the framework "magically" solves many problems, and push more people to use it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you work for a big company, most likely you've seen or even done this. But why is it bad? Being a victim myself, I can share my story.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Story&lt;/head&gt;
    &lt;p&gt;Over the years, my team has been using a Google-internal framework to write distributed programs, and are gradually migrating our org's codebase onto it. This framework is well-designed and maintained by a dedicated team. We're generally happy with it, though it has some itchy points (not pain points). Being a strong and ambitious engineer, my manager proposed that we add an abstraction layer on top of it, with the aim to lower the barrier for org adoption, and solve those itchy points on the way. I was skeptical and tried convincing my manager not to do it, but failed. Eventually, several engineers spent quarters to add this abstraction layer, and now the fun begins.&lt;/p&gt;
    &lt;p&gt;First, one author tried to adopt it in our existing codebase. People thought it would be easy, but it took like a year. Why? Because during the migration, they found that the abstraction cannot handle certain use cases, so they have to spend time patching it to make it work. In the meantime, other people like me were writing new code using the original framework, this again added new requirements and workload for migration. Eventually, after spending way more time than initially planned, the migration completed, and my manager decided that newly-written code should use our own framework.&lt;/p&gt;
    &lt;p&gt;You think this is the end? Of course not!&lt;/p&gt;
    &lt;p&gt;Since I started writing code with the new framework, there wasn't a single time that I didn't want to curse and quit the job. The framework is so hard to use, it introduced so many concepts with the intent to hide complexity, but ended up bringing more. Since I'm not the person who writes it, I'm not familiar with all tricks and hacks. As a result, what used to cost me a day to finish can now take two weeks, plus I have to constantly ask the author how to do certain things, and even booked pair-programming sessions. As I heard, other team members were having the same complaints. As for the original goal of driving adoption, ofc it didn't help (if not slower). What's funny is that, this layer is supposed to make people outside of our team write code more easily, but now even our own team are suffering from it.&lt;/p&gt;
    &lt;p&gt;Looking back, part of the problem was caused by bad design and implementation, but the fundamental problem lies in creating the mini-framework in the first place. I've observed other mini-frameworks, they all sort of have the same problem, just some worse than the others. So I've come up with a few thoughts to explain why mini-frameworks are bad.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why mini-frameworks are bad?&lt;/head&gt;
    &lt;p&gt;First, mini-frameworks lacks feature completeness and compatibility. People often think that they can magically "hide the unnecessary complexity", but in reality they can't. Even if the mini-framework can deal with 80% use cases well, they often lack the flexibility and features from the original framework to satisfy the rest 20%. DSL (Domain Specific Language) shares the same problem, and that's why people hate it so much.&lt;/p&gt;
    &lt;p&gt;Second, mini-frameworks violates the ETC (Easier To Change) principle. I first learned the concept from the legendary book The Pragmatic Programmer, and it still astonishes me that many programmers (even experienced ones) are not aware of it. Put simply, it suggests to write code in a way that allows future modifications be made easily. Creating mini-frameworks violates this principle in two ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The mini-framework only models the current use cases to solve certain problems. When requirements change in the future, it often cannot keep up with it.&lt;/item&gt;
      &lt;item&gt;Creating mini-framework often requires poking into the implementation details of the original framework, and those details were abstracted away for good reason: they can change at any time. The more implementation details that are relied upon, the harder for the maintaining team to evolve the original framework.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Third, mini-frameworks is a realization of the creator's mental model, but it's not everyone's mental model. People who tend to create mini-framework are often more opinionated, which is a good thing by itself. But when you create things for others to use, too opinionated can be a bad thing. I would even say that sometimes (not always), creating a mini framework directly reflects the author's ego, and they chose a framework because a tiny library don't recognize the "significance of the work".&lt;/p&gt;
    &lt;p&gt;Fourth, mini-frameworks tend to cause tech stack fragmentation. I generated an image to show what I mean: part of the system is migrated, others are not. As new layers kept being added, over time it gets worse. Not sure if other companies are like this, but at Google, I've never actually seen a code migration fully complete, which is kinda hilarious.&lt;/p&gt;
    &lt;p&gt;Last but also the most concerning: lack of maintenance. Unlike shared infrastructure owned by dedicated teams, mini-frameworks were often owned by those 1 or 2 people who created it. Once they left the team or company, it becomes really hard to find successors — sure other team members may know roughly how things work, but certainly not as deep as the authors. Also, people lack the motivation to maintain existing stuff, because you don't get paid more or promoted doing this. Therefore, mini frameworks often die with the departure of the original authors, unless it has gained major adoption before that, which happens less likely than not.&lt;/p&gt;
    &lt;head rend="h2"&gt;So, What Should You Do Instead?&lt;/head&gt;
    &lt;p&gt;At this point, it's important to clarify what I'm against and what I'm not. I'm certainly not against adding abstractions——because abstractions are essentially, the program itself, we can't live without it. I'm against adding abstractions in a wrong way, and in the form that's not needed.&lt;/p&gt;
    &lt;p&gt;Let me bring this up once again since it's really important: The real and only difference between a library and a framework, is whether it introduces new concepts. The line can be blurry sometimes, but more often you can tell easily. For example, a library can include a set of subclasses or utility functions around the original framework, as they don't introduce new concepts. But if you see a README that starts with a "Glossary" section, you know it's 99.99% chance a framework (people may still refer to them as "libraries", but you get the idea).&lt;/p&gt;
    &lt;p&gt;My point is, we should be really really careful introducing new concepts. If you can, avoid it. The cognitive load brought by a bunch of buzz words is heavier than people realized, and especially, what the framework author can realize. Words are the mirror of someone's thought, same with code. The authors create concepts because it is how they model the problem inside their brain, it is how they think. That's why they claim the concepts are "natural and straightforward", while others are struggling to understand.&lt;/p&gt;
    &lt;p&gt;So rule No.1, avoid creating mini-frameworks, create libraries instead. But in the cases where you do find it necessary to create a framework, my suggestions are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Link concepts to concrete business requirements, not something in your head.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start fresh. Don't build a wrapper around the existing framework, build your own from scratch. Yes this would make it a major decision that requires more discussions and resources, but it avoids many of the aforementioned issues. After all, you have good business justification to do this, right.. Right?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;Take it seriously. Having seen many disasters caused by mini-frameworks, I can't help thinking if it's because people didn't take it seriously enough. My feeling is that, since people don't really understand the distinction between a library and a framework, both the initiator and reviewers of the decision tend to underthink it: "Oh it's just another abstraction, we do that all the time". As my story shows, it's really not. Creating and adopting a framework, whether mini or not, is always a serious decision, thus should be treated that way. By realizing the seriousness of this matter, I hope we can avoid making rashy decisions to create mini-frameworks that should not exist in the first place.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://laike9m.com/blog/avoid-mini-frameworks,171/"/><published>2025-12-24T12:04:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46375174</id><title>I'm returning my Framework 16</title><updated>2025-12-25T00:53:21.934089+00:00</updated><content>&lt;doc fingerprint="56a45c37c90b9dd7"&gt;
  &lt;main&gt;
    &lt;p&gt; My current laptop is an aging X1 Carbon generation 7, purchased some time in mid 2019. A few months ago a few keys of the keyboard stopped working, specifically the 5, 6, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; and Delete keys. Sometimes I can get it working again by
mashing one of them for a while, but it's not consistent. Given my past
experiences with X1 Carbon laptops breaking outside of warranty and the
frustration that comes with replacing their components, I decided it was time to
look for a replacement.&lt;/p&gt;
    &lt;p&gt;Unfortunately, buying a new X1 Carbon wasn't going to be an option: when it comes to displays you now basically have two choices: a subpar not-quite-2K IPS display, or a 2.5K (ish) OLED display. Since I use my laptop for programming and often use it in low light conditions such as a living room with dimmed lights in the evening, OLED just doesn't make sense. Knowing my luck I'd also run into OLED burn-in the moment the warranty expires. There are also some other issues with the X1 line in general, such as poor CPU cooling and the absolute nightmare that is opening them up to replace parts or clean them properly.&lt;/p&gt;
    &lt;p&gt;I looked at some other brands but it appears that in 2025 there's just aren't many good options for Linux users. I narrowed it down to two options:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Buy a refurbished M1 or M2 Macbook and run Asahi Linux&lt;/item&gt;
      &lt;item&gt;Buy a Framework&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I eliminated the use of Asahi Linux because of the following reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The battery life doesn't appear to be all that better than conventional laptops when running Linux. This isn't entirely surprising because of a lot of the battery improvements on macOS are the result of the software and hardware integration, not just the hardware&lt;/item&gt;
      &lt;item&gt;There seem to be issues with suspend not working as well (at least based on various comments I came across), and hardware support in general is a bit dodgy&lt;/item&gt;
      &lt;item&gt;If something needs replacing I basically have an expensive paperweight, because everything is soldered together, assuming you could even find spare parts in the first place&lt;/item&gt;
      &lt;item&gt;I'm not sure Asahi as a project will still be around in 5 years, but my laptop will be&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In contrast, Framework laptops has many supposed benefits: they're upgradable, repairable, actively work on Linux and even FreeBSD support (or at least sponsor developers working on this), allow you to customize the keyboard using QMK/VIAL. In fact, on paper it sounds like the perfect developer laptop. In reality, I'm not so sure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Table of contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration&lt;/item&gt;
      &lt;item&gt;Building the laptop&lt;/item&gt;
      &lt;item&gt;Operating system&lt;/item&gt;
      &lt;item&gt;Weight&lt;/item&gt;
      &lt;item&gt;Design&lt;/item&gt;
      &lt;item&gt;Display&lt;/item&gt;
      &lt;item&gt;Power LED&lt;/item&gt;
      &lt;item&gt;GPU&lt;/item&gt;
      &lt;item&gt;CPU&lt;/item&gt;
      &lt;item&gt;Battery&lt;/item&gt;
      &lt;item&gt;WiFi and Bluetooth&lt;/item&gt;
      &lt;item&gt;Keyboard&lt;/item&gt;
      &lt;item&gt;Trackpad&lt;/item&gt;
      &lt;item&gt;Speakers&lt;/item&gt;
      &lt;item&gt;Modular ports&lt;/item&gt;
      &lt;item&gt;Conclusion&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Configuration&lt;/head&gt;
    &lt;p&gt;Framework has three models of laptops: a 12 inch, 13.5 inch and 16 inch laptop. My X1 Carbon is a 14 inch laptop but I've always felt like I wanted something just slightly larger. I ended up buying the Framework 16 for two reason:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I read various reports of the Framework 13 having issues with poor battery life, fan noise, heating, etc&lt;/item&gt;
      &lt;item&gt;While 16 inch is a fair bit larger than 14 inch, I was hoping it would be manageable size wise&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The base configuration is as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework 16 DIY edition&lt;/item&gt;
      &lt;item&gt;CPU: Ryzen AI 7 350&lt;/item&gt;
      &lt;item&gt;RAM: 2x8 GiB DDR5-5600&lt;/item&gt;
      &lt;item&gt;SSD: WD Black SN7100, 500 GiB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also bought an additional Intel AX210 WiFi card in case the default Mediatek card would cause any trouble, as I don't trust brands other than Intel when it comes to WiFi.&lt;/p&gt;
    &lt;p&gt;Shipping took about a week or so, with the laptop making quite the journey from Taiwan to the Philippines to China, then to Japan and then back to China, then to Istanbul, then to France and at last to The Netherlands. I'm not sure what happened here, maybe the pilot got drunk or perhaps Fedex' tracking is just broken.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building the laptop&lt;/head&gt;
    &lt;p&gt;I bought the DIY edition which requires some manual assembly, though not nearly as much as I feared. All I had to do was install the SSD, RAM, and the keyboard spacers. The spacers, touchpad and keyboard use magnetic connectors so installing and removing them is trivial. To access the SSD and RAM slots you need to unscrew a plate that sits between these slots and the keyboard, but this only takes a few minutes using the provided screwdriver.&lt;/p&gt;
    &lt;p&gt;I didn't measure how long it took me to install it the first time, but opening it up and putting it back together a second time only took perhaps 5-10 minutes at most. For comparison, to replace most parts of the X1 Carbon you essentially have to take the whole thing apart and unscrew countless screws many of which are hard to find. Unsurprisingly, I've lost some of these screws over the years and dreaded opening it up the few times I had to.&lt;/p&gt;
    &lt;p&gt;This is an area where Framework excels compared to all other brands: it's just so easy to swap the parts out that it puts other brands to shame when it comes to hardware maintainability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Operating system&lt;/head&gt;
    &lt;p&gt;For the operating system I initially gave FreeBSD 15 a quick try. I knew it wasn't going to be the final OS due to it still having issues with the Framework hardware (e.g. suspend doesn't work properly), but I figured it was worth a try just to see what would happen. The installation went fine and WiFi worked fine, though that was because I swapped the Mediatek card with the Intel AX210 as the Mediatek card doesn't work at all on FreeBSD. Upon loading the AMD drivers I encountered a kernel crash, likely due to the same issue as discussed in this drm-kmod issue. A laptop without working GPU drivers isn't going to work, so at this point I decided to give up on FreeBSD (again) and install Fedora 43 instead.&lt;/p&gt;
    &lt;p&gt;Fedora 43 worked just fine as expected, and everything worked, so let's take a look at the hardware.&lt;/p&gt;
    &lt;head rend="h2"&gt;Weight&lt;/head&gt;
    &lt;p&gt;The Framework 16 weights about 2.2 kg according to my kitchen scale. For comparison, my X1 Carbon weights 1.3 kg. That may not seem like a big difference, but the extra kilogram makes carrying around the Framework 16 more difficult. In particular, I don't feel comfortable carrying it with just one hand while this isn't a problem with the X1.&lt;/p&gt;
    &lt;p&gt;The Framework is best described as a bit of a chonker and I certainly don't see myself carrying it around a lot. This also gives it a bit of an identity crisis: laptops should be portable, otherwise why not just get a desktop. And yet the Framework 16 is neither portable nor remotely as powerful as a desktop, so who exactly is the target audience?&lt;/p&gt;
    &lt;head rend="h2"&gt;Design&lt;/head&gt;
    &lt;p&gt;The design of the laptop is a bit polarizing. I like the combination of black and silver, but I hate how janky it all looks and feels due to the removable spacers. Note the lines separating the touchpad from the spacers on the left and right of it:&lt;/p&gt;
    &lt;p&gt;Not only does it look weird, you can also feel the gap and edges when resting your palm on them. The silver spacers and touchpad are also raised slightly relative to the black keyboard area, and the edges are quite sharp. If you have arm hairs you may consider shaving them off or risk getting them stuck. I also suspect gunk will build up in these edges over time.&lt;/p&gt;
    &lt;p&gt;The spacers aren't held solid in place either, meaning you can move them around and they have a bit of flex to them:&lt;/p&gt;
    &lt;p&gt;You may need to turn up your volume to hear the noise the spacers make. Also, apologies for the vertical video!&lt;/p&gt;
    &lt;p&gt;There's also a practical problem: due to the flex of the spacers if you try to hold the laptop on its sides it will actually "wobble" a bit. Combined with the weight I suspect that unless you hold on to this laptop for dear life, you will at some point drop it.&lt;/p&gt;
    &lt;p&gt;These issues could be considered a minor issue in isolation but remember, this model costs two thousand Euros (I'll bring this up a few more times). For a premium price I expect a premium design and build quality, and this isn't it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Display&lt;/head&gt;
    &lt;p&gt;The display isn't terrible, but it's not great either. Like most laptop displays that aren't Macbooks there's a bit of flex to the display, though this shouldn't be much of an issue. The colors of the display are overly saturated, with reds in particular looking more intense than they should. Here's a silly example of what a particular shade of red looks like on my X1 Carbon:&lt;/p&gt;
    &lt;p&gt;And here's the same color on the Framework 16:&lt;/p&gt;
    &lt;p&gt;Note that both displays were using the same brightness and the same color temperature/night light setting. For comparison, here's what those colors should look like when using a properly calibrated (at the hardware level at least) Eizo CS2740 that I use for my desktop:&lt;/p&gt;
    &lt;p&gt;I'm aware the quality of the photos isn't great, but if you compare the Framework version to the others you'll notice the colors are more saturated compared to what they should look like.&lt;/p&gt;
    &lt;p&gt;The white/grey uniformity also leaves a lot to be desired, though this is true for all modern IPS displays that aren't manufactured by Eizo:&lt;/p&gt;
    &lt;p&gt;I find non-uniform displays distracting as it can create a sort of tunnel vision effect/feeling. While the X1 Carbon also suffers from this problem, it feels less pronounced than in case of the Framework. Of course the Eizo display doesn't suffer from this problem at all (hence I bought it), but then it again it costs a ridiculous €1700.&lt;/p&gt;
    &lt;p&gt;Which brings us to the brightness. This display is bright, even at the lowest setting. I found various forum posts that mention the Framework 13 suffers from a similar issue but that you can at least now lower the brightness further on recent versions of Linux, but this isn't supported for the Framework 16. Here's what that looks like in practice:&lt;/p&gt;
    &lt;p&gt;The Framework 16 is on the left and the X1 Carbon on the right, both set to the lowest brightness setting that is still usable.&lt;/p&gt;
    &lt;p&gt;The Framework 16 being so much brighter means that using it in a darker room (e.g. a living room at night with the lights dimmed) makes you feel like a deer looking into the headlights of a car that's about to run you over. In other words, not fun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Power LED&lt;/head&gt;
    &lt;p&gt;On the topic of brightness, the power button in the top right corner of the keyboard has an LED that can't be turned off in the BIOS. Instead, you can set it to a few different settings including "Ultra low", but it doesn't make much of a difference as even at the lowest setting it's still too bright. This wouldn't be so bad if it wasn't sitting in the bottom right corner of your eye when you look at the display.&lt;/p&gt;
    &lt;p&gt;I ended up using this systemd service to turn the LED off upon booting, but something as simple as this should just be a BIOS option. Not being able to turn the LED off is apparently a feature.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPU&lt;/head&gt;
    &lt;p&gt;I didn't do any GPU intensive testing such as video decoding. One annoying issue is that the display has a tendency to flicker. On top of that, there's a "nice" feature where the GPU reduces the display brightness based on the contents on the screen to conserve battery. The problem is that it takes a good two seconds or so to adjust, making it obvious and jarring to look at. It's especially noticeable when switching to the workspace overview in Gnome and back, due to a large section of this overview being a dark color.&lt;/p&gt;
    &lt;p&gt;This feature is disabled by adding &lt;code&gt;amdgpu.abmlevel=0&lt;/code&gt; to &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt;
in &lt;code&gt;/etc/default/grubg&lt;/code&gt;, followed by running &lt;code&gt;sudo grub2-mkconfig -o
/boot/grub2/grub.cfg&lt;/code&gt; and a reboot. This also seems to reduce the amount of
flickering, though it still happened a few times after applying this setting.&lt;/p&gt;
    &lt;p&gt;Some additional details on the ambient dimming anti-feature are in this forum post.&lt;/p&gt;
    &lt;p&gt;I can see the value of this feature but only if the GPU waits longer before adjusting the brightness and increases the transition time so it's less obvious. In it's current form it's just a nuisance.&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU&lt;/head&gt;
    &lt;p&gt;The CPU is fine, though I didn't extensively test its performance. It's certainly better than the mediocre Intel CPU of my X1 Carbon. One thing I noticed is that the CPU makes a sort of coil whine/crackling BZZZZZZ noise when under load. This isn't unique to Framework (e.g. my X1 also does this), the more open design (e.g. there's a big fan grill/mesh at the top of the keyboard) makes this more noticeable.&lt;/p&gt;
    &lt;p&gt;I can't speak about the fan noise because I never heard them. This could either mean they are quiet enough or that I didn't stress the CPU enough.&lt;/p&gt;
    &lt;head rend="h2"&gt;Battery&lt;/head&gt;
    &lt;p&gt;I didn't do any proper testing of battery usage, but it seems to be on par with other Linux capable laptops based on my usage thus far. This means you'll likely be looking at 6-8 hours of battery per charge for average programming usage. It seems this is the case for basically any reasonable Linux-capable laptop these days, unfortunately.&lt;/p&gt;
    &lt;p&gt;I did notice that it drains quite a bit when suspended: when I put it to sleep the first night the battery was at 47%. When I opened the laptop again some 8 hours later the battery was at 42%. This means you're looking at about 5% of battery per average night, which isn't great. Hibernate could be an alternative but support for it on Fedora is a bit dodgy and requires some manual work I'm not interested in, so I didn't test this.&lt;/p&gt;
    &lt;head rend="h2"&gt;WiFi and Bluetooth&lt;/head&gt;
    &lt;p&gt;Both the Intel and Mediatek cards work without issue. Both achieve the same speeds on my 1 Gbps connection over a 5Ghz network (with a channel width of 80mhz): about 800-900 Mbps for uploads and somewhere between 600 and 700 Mbps for downloads. While not being able to achieve the full 1 Gbps speed over WiFi is expected, I was a bit surprised to see that uploads are in fact faster than downloads.&lt;/p&gt;
    &lt;p&gt;I tested various other devices with similar WiFi hardware and they all upload and download at about the same speeds, and all operate at slightly lower speeds (500-600 Mbps, depending on your luck).&lt;/p&gt;
    &lt;p&gt;I don't think it's the network itself either: the access points are TP-Link EAP660 HDs that can handle speeds well beyond 1 Gbps. As far as I know the configuration is also sound (including the use of specific channels to reduce interference to a minimum).&lt;/p&gt;
    &lt;p&gt;Still, 600-700 Mbps over WiFi is more than I'll probably ever need so I didn't dive into this further.&lt;/p&gt;
    &lt;p&gt;I didn't specifically test Bluetooth but it did detect a few devices, so I'll assume this will work just fine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Keyboard&lt;/head&gt;
    &lt;p&gt;Some reviews I read mentioned that the keyboard has a bit of flex to it, but I didn't notice this. The keycaps are a little mushy, which isn't too bad but not great either. The difference in key size and spacing compared to the X1 did mean I pressed the wrong key at times, but I suspect this is just a matter of adjusting.&lt;/p&gt;
    &lt;p&gt;The keyboard runs QMK, albeit a rather outdated version of QMK released in 2022. I experimented with porting the code to a newer version so I could take advantage of some features that I use in my split keyboard, but couldn't get it to work. The official way to configure the keyboard is by using this VIAL web application. This application requires WebHID support which isn't implemented by Firefox, requiring me to install and use Chromium just to configure the keyboard. This isn't enough though, as on Linux you'll need to install some additional udev rules to get things working. The official rules provided by QMK didn't work, instead I used the rules from this forum reply.&lt;/p&gt;
    &lt;p&gt;Once set up I was able to configure the keyboard such as by changing the layout from QWERTY to Colemak-DH. VIAL is pretty basic though and the interface is rather clunky, so I'm not a fan of this approach. I hope that at some point Framework will upstream their keyboard logic into the official QMK repository to make this process easier.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trackpad&lt;/head&gt;
    &lt;p&gt;The trackpad is decent, though I noticed it's overly sensitive when it comes to scrolling. For example, on various occasions I lifted my fingers off the trackpad without any swiping motion and somehow still managed to trigger a scrolling motion. The trackpad of the X1 Carbon doesn't have this problem and subsequently is easier and more pleasant to use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Speakers&lt;/head&gt;
    &lt;p&gt;They're terribly. Or more precisely, they're terrible when the volume is less than 50% or so. What appears to be happening is that adjusting the volume below 50% doesn't result in it being louder but instead changes how it sounds (for a lack of a better description). At lower volumes it sounds like sound playing over a phone in speaker mode, with a sort of tin can/metallic sound to it. Once you hit 50% or so it starts to sound more like an OK set of speakers but it also becomes noticeable louder. There's a setting in the BIOS that you can set to "Linux" mode to supposedly improve the quality but it was already set to this value.&lt;/p&gt;
    &lt;p&gt;While most laptop speakers aren't great (even the Dolby Atmos speakers of the X1 Carbon are mediocre), for a laptop that costs two thousand Euros the sound is disappointing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular ports&lt;/head&gt;
    &lt;p&gt;An interesting feature of the Framework is that you can swap out the various ports. You want 6 USB-C ports? You can do that! What about 3 headphone jacks? Also possible! Replacing them is quite easy, though for some reason my headphone jack adapter required some additional force to be removed.&lt;/p&gt;
    &lt;p&gt;Like the keyboard area the design is a bit janky though, with visible lines/space between the adapters and the case, though this at least is something you won't notice unless you're explicitly looking for it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Which brings me to the conclusion: is it worth buying this laptop, considering most configurations will cost you around two thousand Euros? To be honest, no, not at all. For a premium price I expect a premium laptop, but the Framework 16 feels more like a €1200-€1500 laptop at best and certainly doesn't deliver a premium experience. I understand Framework is a young company still trying to figure out a lot of things, but two thousand Euros for this kind of laptop is just absurd.&lt;/p&gt;
    &lt;p&gt;For this reason I've submitted a request to return the laptop. What I'll be replacing my X1 Carbon with instead I'm not entirely sure of. One option is the Framework 13 given that it solves at least some issues I have with the Framework 16 (e.g. it's bulkiness and inability to lower the brightness further), but it also seems to share many of the other issues such as poor speaker quality and (at least from hat I could find) worse heat regulation, and a (possibly) worse battery.&lt;/p&gt;
    &lt;p&gt;I've looked at various other brands such as System76 and the many other Clevo resellers, but they all seem to suffer similar issues such as poor battery life, poor performance, difficult to maintain hardware wise, or some combination thereof.&lt;/p&gt;
    &lt;p&gt;I guess for now the X1 Carbon will have to hold out a little longer, provided I don't throw it out of the window the next time I can't get the various dodgy keyboard keys to work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yorickpeterse.com/articles/im-returning-my-framework-16/"/><published>2025-12-24T12:55:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46375384</id><title>When Compilers Surprise You</title><updated>2025-12-25T00:53:21.628193+00:00</updated><content>&lt;doc fingerprint="26e3f81475bb3a59"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by me, proof-read by an LLM. &lt;lb/&gt;Details at end.&lt;/p&gt;
    &lt;p&gt;Every now and then a compiler will surprise me with a really smart trick. When I first saw this optimisation I could hardly believe it. I was looking at loop optimisation, and wrote something like this simple function that sums all the numbers up to a given value:&lt;/p&gt;
    &lt;p&gt;So far so decent: GCC has done some preliminary checks, then fallen into a loop that efficiently sums numbers using &lt;code&gt;lea&lt;/code&gt; (we’ve seen this before). But taking a closer look at the loop we see something unusual:&lt;/p&gt;
    &lt;code&gt;.L3:
  lea edx, [rdx+1+rax*2]        ; result = result + 1 + x*2
  add eax, 2                    ; x += 2
  cmp edi, eax                  ; x != value
  jne .L3                       ; keep looping
&lt;/code&gt;
    &lt;p&gt;The compiler has cleverly realised it can do two numbers1 at a time using the fact it can see we’re going to add &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;x + 1&lt;/code&gt;, which is the same as adding &lt;code&gt;x*2 + 1&lt;/code&gt;. Very cunning, I think you’ll agree!&lt;/p&gt;
    &lt;p&gt;If you turn the optimiser up to &lt;code&gt;-O3&lt;/code&gt; you’ll see the compiler works even harder to vectorise the loop using parallel adds. All very clever.&lt;/p&gt;
    &lt;p&gt;This is all for GCC. Let’s see what clang does with our code:&lt;/p&gt;
    &lt;p&gt;This is where I nearly fell off my chair: there is no loop! Clang checks for positive &lt;code&gt;value&lt;/code&gt;, and if so it does:&lt;/p&gt;
    &lt;code&gt;  lea eax, [rdi - 1]        ; eax = value - 1
  lea ecx, [rdi - 2]        ; ecx = value - 2
  imul rcx, rax             ; rcx = (value - 1) * (value - 2)
  shr rcx                   ; rcx &amp;gt;&amp;gt;= 1
  lea eax, [rdi + rcx]      ; eax = value + rcx
  dec eax                   ; --eax
  ret
&lt;/code&gt;
    &lt;p&gt;It was not at all obvious to me what on earth was going on here. By backing out the maths a little, this is equivalent to:&lt;/p&gt;
    &lt;code&gt;v + ((v - 1)(v - 2) / 2) - 1;
&lt;/code&gt;
    &lt;p&gt;Expanding the parentheses:&lt;/p&gt;
    &lt;code&gt;v + (vÂ² - 2v - v + 2) / 2 - 1
&lt;/code&gt;
    &lt;p&gt;Rearranging a bit:&lt;/p&gt;
    &lt;code&gt;(vÂ² - 3v + 2) / 2 + (v - 1)
&lt;/code&gt;
    &lt;p&gt;Multiplying the &lt;code&gt;(v - 1)&lt;/code&gt; by 2 / 2:&lt;/p&gt;
    &lt;code&gt;(vÂ² - 3v + 2) / 2 + (2v - 2)/2
&lt;/code&gt;
    &lt;p&gt;Combining those and cancelling:&lt;/p&gt;
    &lt;code&gt;(vÂ² - v) / 2
&lt;/code&gt;
    &lt;p&gt;Simplifying and factoring gives us &lt;code&gt;v(v - 1) / 2&lt;/code&gt; which is the closed-form solution to the “sum of integers”! Truly amazing2 - we’ve gone from an O(n) algorithm as written, to an O(1) one!&lt;/p&gt;
    &lt;p&gt;I love that despite working with compilers for more than twenty years, they can still surprise and delight me. The years of experience and work that have been poured into making compilers great is truly humbling, and inspiring.&lt;/p&gt;
    &lt;p&gt;We’re nearly at the end of this series - there’s so much more to say but that will have to wait for another time. Tomorrow will be a little different: see you then!&lt;/p&gt;
    &lt;p&gt;See the video that accompanies this post.&lt;/p&gt;
    &lt;p&gt;This post is day 24 of Advent of Compiler Optimisations 2025, a 25-day series exploring how compilers transform our code.&lt;/p&gt;
    &lt;p&gt;This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.&lt;/p&gt;
    &lt;p&gt;Support Compiler Explorer on Patreon or GitHub, or by buying CE products in the Compiler Explorer Shop.&lt;/p&gt;
    &lt;p&gt;Some of the initial code checks for odd/even and accounts accordingly. ↩&lt;/p&gt;
    &lt;p&gt;Why does the compiler emit this exact sequence and not a slightly more straightforward sequence? I think it’s partly avoiding overflow in cases where it might otherwise overflow and just a side effect of the way clang tracks and infers induction variables. I really don’t know for sure, though. ↩&lt;/p&gt;
    &lt;p&gt;Matt Godbolt is a C++ developer living in Chicago. He works for Hudson River Trading on super fun but secret things. He is one half of the Two's Complement podcast. Follow him on Mastodon or Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xania.org/202512/24-cunning-clang"/><published>2025-12-24T13:27:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46376652</id><title>My 2026 Open Social Web Predictions</title><updated>2025-12-25T00:53:21.363380+00:00</updated><content>&lt;doc fingerprint="b8beabfa6dac4a7a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;My 2026 Open Social Web Predictions&lt;/head&gt;
    &lt;p&gt;I just finished reviewing my 2025 predictions (how do you think I did grading myself?) www.timothychambers.net/2024/12/2…&lt;/p&gt;
    &lt;p&gt;Now it’s time to make some bets for 2026. I do this not to prove how great my prognostication muscles are, but to shine a spotlight on trends I think are vital, spur discussions, and give some attention to projects that have earned it. As always, I try to make these as quantifiable, verifiable and crisp as I can. Here goes:&lt;/p&gt;
    &lt;p&gt;🌱 MILD&lt;/p&gt;
    &lt;p&gt;Safe bets — would be surprising if these DON’T happen.&lt;/p&gt;
    &lt;p&gt;▶️ Bluesky will cross 60 million registered users in 2026. Growth will slow from 2024’s explosive pace but remain steady, driven by continued X dissatisfaction and improved features.&lt;/p&gt;
    &lt;p&gt;▶️ The ActivityPub Fediverse (excluding Threads) will cross 15 million registered users, monthly active users (excluding will plateau around 2-3 million. Another good year in terms of stable base, but no big waves of new users. Both Bluesky and Fediverse growth won’t come from big waves of migration this year.&lt;/p&gt;
    &lt;p&gt;▶️ Any smaller waves from X/Twitter or from a newly bought TikTok will benefit Meta (Threads/IG), BlueSky, and Fediverse in that order. I see nothing that would change that prediction that was true last year, too.&lt;/p&gt;
    &lt;p&gt;▶️ Threads will pass 500 million monthly active users and remain the largest ActivityPub-adjacent platform by a wide margin. But see the next prediction:&lt;/p&gt;
    &lt;p&gt;▶️ Threads federation will remain partial, and opt-in through all of 2026. Full two-way federation will NOT ship in 2026 but may move from about 90 percent there, to 95 percent done, inching forward but not finalized and prioritized as a feature. As Manton wrote, that’s better than fully closed, and better than them stripping it out. (which they might do but I’m predicting not) My bet: the status quo continues. www.manton.org/2025/12/1…&lt;/p&gt;
    &lt;p&gt;▶️ Ghost’s ActivityPub integration will bring 75,000+ new federated accounts to the Fediverse and Ghost will finish 2026 in the top 10 Fediverse server software by MAU.&lt;/p&gt;
    &lt;p&gt;▶️ WordPress-based federated accounts will cross 50,000 as measured by FediDB. Currently at approximately 26,000 accounts across 12,700 servers, the WordPress-to-Fediverse pipeline becomes a meaningful growth contributor.&lt;/p&gt;
    &lt;p&gt;🔥 MEDIUM-SPICEY Plausible bets — could go either way, but evidence points toward yes.&lt;/p&gt;
    &lt;p&gt;▶️ BridgyFed will shift to “opt-out” for Bluesky users bridging to ActivityPub — and the discourse will be far less contentious than the 2024 debates predicted. Cross-protocol interoperability quietly normalizes.&lt;/p&gt;
    &lt;p&gt;▶️ At least one fully independent ATProto stack — PDS, Relay, and AppView operating without dependency on Bluesky PBC infrastructure — will achieve viability in 2026, meaning it has paying customers or sustainable funding. This will be the year ATProto proves (or fails to prove) it can exist beyond Bluesky-the-company.&lt;/p&gt;
    &lt;p&gt;▶️ Mastodon gGmbH will hit key sustainability milestones in 2026. Their hosting revenue model will exceed internal targets, the new organizational structure will unlock additional grant funding (beyond NGI/NLnet), and the pace of Mastodon development will noticeably accelerate — shipping more significant features in 2026 than in the previous two years combined.&lt;/p&gt;
    &lt;p&gt;▶️ Bluesky PBC will raise another round of funding in 2026 and announce more details on a proposed business model. Following their $15M Series A (October 2024), the company will close a larger round to extend runway. The announced business model will NOT be advertising-based. I’d expect subscriptions, marketplace fees, or enterprise services.&lt;/p&gt;
    &lt;p&gt;▶️ The first “ATProto-native” social app that is NOT microblogging will cross 100,000 users. Whether it’s Frontpage (link aggregation), Leaflet (long-form), Smoke Signal, or something new — the ATmosphere diversifies beyond Bluesky-the-app.&lt;/p&gt;
    &lt;p&gt;▶️ Flipboard’s Surf app will launch its 1.0 version in 2026 and cross 1 million downloads across iOS and Android by year end, with 100,000+ monthly active users. It will become the most-downloaded dedicated Open Social Web client, surpassing Mastodon’s official app and Graysky.&lt;/p&gt;
    &lt;p&gt;▶️ Fedify will power the federation layer for at least one mid-sized social platform (500K+ users) that adds ActivityPub support in 2026. The “build vs. buy” calculation for federation shifts decisively toward “just use Fedify.”&lt;/p&gt;
    &lt;p&gt;▶️ Fediscovery will ship in a stable Mastodon release in 2026, moving from behind feature flags to production-ready. The specifications for pluggable discovery providers — covering account search, follow recommendations, and trends — will reach 1.0 status, and at least one public Fediscovery-compatible provider will launch for general use. Small instance operators will finally have a real option to improve discovery without running their own infrastructure.&lt;/p&gt;
    &lt;p&gt;▶️ The new “ActivityRank” algorithm in Loops will prove that ethical recommendations and decentralization can coexist. Dan Supernault’s approach — where each instance trains its own algorithm while surfacing content across the ActivityPub network — will be recognized as a breakthrough in solving the fediverse’s discoverability problem. By the end of 2026, the pattern will be studied or adopted by at least two other ActivityPub platforms.&lt;/p&gt;
    &lt;p&gt;▶️ ATProto will advance from Internet Drafts to an official IETF Working Group in 2026. Following the September 2025 submission of initial specifications, Bluesky will secure enough support and independent implementers to form a dedicated Working Group — moving from “proposal being discussed” to “standard being formally developed.”&lt;/p&gt;
    &lt;p&gt;🌶️ SPICY Hot takes - a bit more risky - but I’m calling my shot.&lt;/p&gt;
    &lt;p&gt;▶️ A well-known digital-native media publication (10M+ monthly visitors) will federate via ActivityPub in 2026 and publicly share positive results. Whether through Ghost, WordPress, or custom implementation, this outlet will report that federated followers drove meaningful engagement — making the business case for federation legible to other publishers for the first time. By year end, at least two additional publications will announce federation plans, citing this pioneer as proof of concept.&lt;/p&gt;
    &lt;p&gt;▶️ At least one major news organization (top 50 US by traffic) will announce it is leaving X/Twitter entirely and making Bluesky or the Fediverse its primary social distribution channel. The “institutional exodus” begins.&lt;/p&gt;
    &lt;p&gt;▶️ At least one major national government or major city will launch an official presence on BOTH Bluesky AND the ActivityPub Fediverse in 2026 — and it will be a European government. Expect surprising additional early adopters after this from Latin America, Asia-Pacific, or Africa to follow that lead and make moves that year to do the same. This is the year the move to “digital sovereignty" from US tech will benefit the open social web. Eurosky will inch along with some promise.&lt;/p&gt;
    &lt;p&gt;▶️ Nostr ↔ ATProto ↔ ActivityPub three-way bridging becomes functional via BridgyFed or another service by end of 2026. The “protocol wars” narrative collapses into “just pick your client.”&lt;/p&gt;
    &lt;p&gt;▶️ AltStore will be live with Federation features in at least 5 countries by end of 2026 (currently EU + Japan, with Brazil, Australia, UK announced). AltStore is an independent iOS app marketplace created by Riley Testut and Shane Gill — the first major alternative to Apple’s App Store, made possible by the EU’s Digital Markets Act. The federated app marketplace model will prove viable outside Europe, challenging Apple’s App Store dominance in multiple regulatory regimes simultaneously. Their ActivityPub integration — where app updates flow to Mastodon, Threads, and Bluesky — will become the most compelling non-social-media use case for decentrlized social features, proving definitively that such protocols extends beyond microblogging.&lt;/p&gt;
    &lt;p&gt;▶️ Loops will become the third most-used Fediverse software by MAU by end of 2026, trailing only Mastodon and Pixelfed. The short-form video platform will cross 100,000 monthly active users, with Loops-originated content generating significant federated engagement from non-Loops clients — proving that ActivityPub can power video-centric social experiences.&lt;/p&gt;
    &lt;p&gt;▶️ PieFed will emerge as the most feature-rich Threadiverse platform by end of 2026, surpassing Lemmy and Mbin in moderation tools, user experience, and federation capabilities. The platform will cross 10,000 monthly active users and its rapid development pace — shipping major features weekly — will make it the default recommendation for anyone starting a new Reddit-style community in the fediverse.&lt;/p&gt;
    &lt;p&gt;▶️ More laws akin to Utah’s Digital Choice Act will pass or advance - sparking first steps towards interoperability to mainstream US discourse. The Utah law takes effect July 1, 2026, and several other states will pass similar ones, requiring social media platforms to enable data portability and interoperability. At least one major platform will announce ActivityPub or AT Protocol support to comply. The “Digital Choice” framing will prove more politically viable than “antitrust” for breaking Big Tech’s lock-in.&lt;/p&gt;
    &lt;p&gt;What did I miss? What did I get wrong? Let me know — and I’ll see you in December 2026 to grade these.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.timothychambers.net/2025/12/23/my-open-social-web-predictions.html"/><published>2025-12-24T15:59:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46377070</id><title>Show HN: A local-first, reversible PII scrubber for AI workflows</title><updated>2025-12-25T00:53:21.191302+00:00</updated><content>&lt;doc fingerprint="4fd9715371229a4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A local-first, reversible PII scrubber for AI workflows using ONNX and Regex&lt;/head&gt;
    &lt;head rend="h2"&gt;The Privacy-Translation Paradox&lt;/head&gt;
    &lt;p&gt;Every engineering team eventually faces the same dilemma: You need to translate user content (support tickets, documents, chat logs) using high-quality engines like DeepL or LLMs like GPT-4, but you strictly cannot send Personally Identifiable Information (PII) to third-party APIs (yes, I’m European).&lt;/p&gt;
    &lt;p&gt;The solution is seemingly simple: Redact the data. The problem? Redaction destroys translation quality.&lt;/p&gt;
    &lt;p&gt;If you scrub “John bought a generic gift for Mary” into “PERSON bought a generic gift for PERSON,” the translation engine loses the context needed for grammatical gender agreement, case endings, and prepositions in target languages like French or German. Furthermore, most open-source PII scrubbers are “one-way” — they clean data for analytics, not for a round-trip translation workflow.&lt;/p&gt;
    &lt;p&gt;At ELAN Languages, I built a solution for this. Today, we are open-sourcing Bridge Anonymization: a TypeScript library for reversible, context-aware PII masking designed specifically for translation pipelines.&lt;/p&gt;
    &lt;head rend="h2"&gt;How &lt;code&gt;bridge-anonymization &lt;/code&gt;Works&lt;/head&gt;
    &lt;p&gt;Unlike general-purpose scrubbers, Bridge is designed around a lifecycle:&lt;/p&gt;
    &lt;code&gt;Detect -&amp;gt; Mask -&amp;gt; Translate -&amp;gt; Rehydrate&lt;/code&gt;
    &lt;p&gt;It (Mask &amp;amp; Rehydrate, not Translate) runs entirely on-device (Node.js or Bun) using a hybrid engine of RegEx and quantized ONNX models.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Hybrid Detection Strategy&lt;/head&gt;
    &lt;p&gt;A single detection method isn’t enough. Regex is fast but limited; NER (Named Entity Recognition) is smart but heavy. &lt;code&gt;bridge-anonymization&lt;/code&gt; uses both:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Structured PII (Regex): We use strict patterns for things that follow rules — IBANs (with Mod-97 checksum validation), Credit Cards (Luhn algorithm), and Emails.&lt;/item&gt;
      &lt;item&gt;Soft PII (NER): For Names, Organizations, and Locations, we wrap a powerful NER model via ONNX Runtime.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This allows developers to choose their trade-off. You can run &lt;code&gt;anonymizeRegexOnly()&lt;/code&gt; for sub-millisecond performance on streams, or the full &lt;code&gt;anonymize()&lt;/code&gt; pipeline for high-precision document scrubbing.&lt;/p&gt;
    &lt;code&gt;import { createAnonymizer } from '@elanlanguages/bridge-anonymization';&lt;lb/&gt;&lt;lb/&gt;// Auto-downloads the ~280MB quantized model on first run&lt;lb/&gt;const anonymizer = createAnonymizer({&lt;lb/&gt;  ner: { mode: 'quantized' }&lt;lb/&gt;});&lt;lb/&gt;&lt;lb/&gt;await anonymizer.initialize();&lt;/code&gt;
    &lt;head rend="h3"&gt;2. The Semantic Masking Challenge&lt;/head&gt;
    &lt;p&gt;While preventing leaks is solved, preserving context remains the frontier.&lt;/p&gt;
    &lt;p&gt;In our current roadmap, we are tackling Semantic Masking. The goal is to enrich our PII tags with metadata (Gender, Location Scope) so the machine translation engine can generate grammatically correct output.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Problem&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gender Agreement: Replacing “Mary” with generic XML leads to “Il a vu &lt;code&gt;&amp;lt;PII type=”PERSON” /&amp;gt;&lt;/code&gt;” (masculine default) instead of “Elle a vu…” (feminine).&lt;/item&gt;
      &lt;item&gt;Prepositions: Replacing “Berlin” vs. “Germany” with generic &lt;code&gt;&amp;lt;PII type="LOCATION"/&amp;gt;&lt;/code&gt;confuses engines that need to know if the location is a city, country, landmark or other place.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Our V1 Approach: Lookup Tables&lt;/head&gt;
    &lt;p&gt;For our first iteration, we are implementing a ‘lightweight’ semantic enricher that runs post-NER detection.&lt;/p&gt;
    &lt;code&gt;// Before&lt;lb/&gt;&amp;lt;PII type="PERSON" id="1"/&amp;gt;&lt;lb/&gt;&lt;lb/&gt;// After (Enriched)&lt;lb/&gt;&amp;lt;PII type="PERSON" gender="female" id="1"/&amp;gt;&lt;/code&gt;
    &lt;head rend="h3"&gt;The Implementation:&lt;/head&gt;
    &lt;p&gt;Data Sources: We aggregate open data from &lt;code&gt;gender-guesser&lt;/code&gt; (approx. 40k Western names) and &lt;code&gt;GeoNames&lt;/code&gt; (cities &amp;gt;15k population).&lt;/p&gt;
    &lt;p&gt;Persons: We check the first name against our database. If ambiguous (e.g., “Andrea” is male in Italian but female in German), we can use the &lt;code&gt;locale&lt;/code&gt; hint provided to the anonymizer to disambiguate.&lt;/p&gt;
    &lt;p&gt;Locations: We classify entities into &lt;code&gt;city&lt;/code&gt;, &lt;code&gt;country&lt;/code&gt;, or &lt;code&gt;region&lt;/code&gt; based on the GeoNames export.&lt;/p&gt;
    &lt;p&gt;But there is a trade-off: We explicitly chose lookup tables over ML for Version 1 to keep the library as lightweight as possible. While a model would handle edge cases better, carrying a static JSON/TXT files is significantly cheaper than loading another 100MB ONNX model just for gender inference. This covers ~90% of common Western names and major cities with near-zero runtime overhead.&lt;/p&gt;
    &lt;p&gt;In the future, we’ll put additional research into custom ML solutions to cover a broader (and context-aware) enrichment strategies.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Fuzzy Rehydration&lt;/head&gt;
    &lt;p&gt;When you send a string like &lt;code&gt;Hello &amp;lt;PII id="1"/&amp;gt;&lt;/code&gt; to a generic LLM or MT engine, the output often comes back "mangled." The engine might change the quotes to smart quotes, add spaces inside the tags, or reorder attributes.&lt;/p&gt;
    &lt;p&gt;If your library relies on strict string replacement, your pipeline breaks.&lt;/p&gt;
    &lt;p&gt;We implemented a Fuzzy Tag Matcher that is resilient to these hallucinations. It detects variations in spacing, quoting, and attribute order to ensure we can always map the token back to the original value.&lt;/p&gt;
    &lt;code&gt;// The mapping table is encrypted using AES-256-GCM&lt;lb/&gt;const { anonymizedText, piiMap } = await anonymizer.anonymize("Call John at +49...");&lt;lb/&gt;&lt;lb/&gt;// Translate via any external API...&lt;lb/&gt;const translated = await externalTranslate(anonymizedText);&lt;lb/&gt;// Even if the API returns: "Rufen Sie &amp;lt; PII id = «1» type='PERSON' &amp;gt; an..."&lt;lb/&gt;&lt;lb/&gt;// Rehydrate seamlessly&lt;lb/&gt;const final = rehydrate(translated, piiMap); &lt;lb/&gt;// Result: "Rufen Sie John an..."&lt;/code&gt;
    &lt;head rend="h3"&gt;4. Security First&lt;/head&gt;
    &lt;p&gt;Because the “PII Map” (the link between &lt;code&gt;ID:1&lt;/code&gt; and &lt;code&gt;John Smith&lt;/code&gt;) effectively is the PII, we treat it as sensitive material.&lt;/p&gt;
    &lt;p&gt;The library includes a crypto module that forces AES-256-GCM encryption for the mapping table. The raw PII never leaves the local memory space, and the state object that persists between the masking and rehydration steps is encrypted at rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance &amp;amp; Architecture&lt;/head&gt;
    &lt;p&gt;We built this for Node.js environments for easy use in web-based applications (electron, tauri) and where Python isn’t always an option.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Runtime: We abstract the ONNX runtime to support both &lt;code&gt;onnxruntime-node&lt;/code&gt;and&lt;code&gt;onnxruntime-web&lt;/code&gt;(for Bun/Edge support).&lt;/item&gt;
      &lt;item&gt;Quantization: By default, we pull a quantized (INT8) version of the XLM-RoBERTa model (~280MB) which provides 95%+ of the accuracy of the full model at 1/4 the size (custom models are supported, too).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Try it out&lt;/head&gt;
    &lt;p&gt;The project is MIT licensed and available on npm.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub: github.com/elanlanguages/bridge-anonymization&lt;/item&gt;
      &lt;item&gt;NPM: &lt;code&gt;npm install @elanlanguages/bridge-anonymization&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’d love feedback on the NER implementation and edge cases in the rehydration logic!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medium.com/@tj.ruesch/a-local-first-reversible-pii-scrubber-for-ai-workflows-using-onnx-and-regex-e9850a7531fc"/><published>2025-12-24T16:44:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46377597</id><title>Show HN: Vibium – Browser automation for AI and humans, by Selenium's creator</title><updated>2025-12-25T00:53:19.074713+00:00</updated><content>&lt;doc fingerprint="8d362e50e91db4ee"&gt;
  &lt;main&gt;
    &lt;p&gt;Browser automation without the drama.&lt;/p&gt;
    &lt;p&gt;Vibium is browser automation infrastructure built for AI agents. A single binary handles browser lifecycle, WebDriver BiDi protocol, and exposes an MCP server — so Claude Code (or any MCP client) can drive a browser with zero setup. Works great for AI agents, test automation, and anything else that needs a browser.&lt;/p&gt;
    &lt;p&gt;New here? Getting Started Tutorial — zero to hello world in 5 minutes.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Interface&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Clicker&lt;/cell&gt;
        &lt;cell&gt;Browser automation, BiDi proxy, MCP server&lt;/cell&gt;
        &lt;cell&gt;CLI / stdio / WebSocket :9515&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;JS Client&lt;/cell&gt;
        &lt;cell&gt;Developer-facing API&lt;/cell&gt;
        &lt;cell&gt;npm package&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────┐
│                         LLM / Agent                         │
│          (Claude Code, Codex, Gemini, Local Models)         │
└─────────────────────────────────────────────────────────────┘
                      ▲
                      │ MCP Protocol (stdio)
                      ▼
           ┌─────────────────────┐         
           │   Vibium Clicker    │
           │                     │
           │  ┌───────────────┐  │
           │  │  MCP Server   │  │
           │  └───────▲───────┘  │         ┌──────────────────┐
           │          │          │         │                  │
           │  ┌───────▼───────┐  │WebSocket│                  │
           │  │  BiDi Proxy   │  │◄───────►│  Chrome Browser  │
           │  └───────────────┘  │  BiDi   │                  │
           │                     │         │                  │
           └─────────────────────┘         └──────────────────┘
                      ▲
                      │ WebSocket BiDi :9515
                      ▼
┌─────────────────────────────────────────────────────────────┐
│                        JS/TS Client                         │
│                     npm install vibium                      │
│                                                             │
│    ┌─────────────────┐               ┌─────────────────┐    │
│    │ Async API       │               │    Sync API     │    │
│    │ await vibe.go() │               │    vibe.go()    │    │
│    │                 │               │                 │    │
│    └─────────────────┘               └─────────────────┘    │
└─────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;A single Go binary (~10MB) that does everything:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browser Management: Detects/launches Chrome with BiDi enabled&lt;/item&gt;
      &lt;item&gt;BiDi Proxy: WebSocket server that routes commands to browser&lt;/item&gt;
      &lt;item&gt;MCP Server: stdio interface for LLM agents&lt;/item&gt;
      &lt;item&gt;Auto-Wait: Polls for elements before interacting&lt;/item&gt;
      &lt;item&gt;Screenshots: Viewport capture as PNG&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Design goal: The binary is invisible. JS developers just &lt;code&gt;npm install vibium&lt;/code&gt; and it works.&lt;/p&gt;
    &lt;code&gt;// Option 1: require (REPL-friendly)
const { browserSync } = require('vibium')

// Option 2: dynamic import (REPL with --experimental-repl-await)
const { browser } = await import('vibium')

// Option 3: static import (in .mjs or .ts files)
import { browser, browserSync } from 'vibium'&lt;/code&gt;
    &lt;p&gt;Sync API:&lt;/p&gt;
    &lt;code&gt;const fs = require('fs')
const { browserSync } = require('vibium')

const vibe = browserSync.launch()
vibe.go('https://example.com')

const png = vibe.screenshot()
fs.writeFileSync('screenshot.png', png)

const link = vibe.find('a')
link.click()
vibe.quit()&lt;/code&gt;
    &lt;p&gt;Async API:&lt;/p&gt;
    &lt;code&gt;const fs = await import('fs/promises')
const { browser } = await import('vibium')

const vibe = await browser.launch()
await vibe.go('https://example.com')

const png = await vibe.screenshot()
await fs.writeFile('screenshot.png', png)

const link = await vibe.find('a')
await link.click()
await vibe.quit()&lt;/code&gt;
    &lt;p&gt;One command to add browser control to Claude Code:&lt;/p&gt;
    &lt;code&gt;claude mcp add vibium -- npx -y vibium&lt;/code&gt;
    &lt;p&gt;That's it. No manual steps needed. Chrome downloads automatically during setup.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_launch&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start browser (visible by default)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_navigate&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_find&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find element by CSS selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_click&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Click an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_type&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Type text into an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_screenshot&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Capture viewport (base64 or save to file with &lt;code&gt;--screenshot-dir&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_quit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Close browser&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;npm install vibium&lt;/code&gt;
    &lt;p&gt;This automatically:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Installs the Clicker binary for your platform&lt;/item&gt;
      &lt;item&gt;Downloads Chrome for Testing + chromedriver to platform cache: &lt;list rend="ul"&gt;&lt;item&gt;Linux: &lt;code&gt;~/.cache/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;macOS: &lt;code&gt;~/Library/Caches/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Windows: &lt;code&gt;%LOCALAPPDATA%\vibium\&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Linux: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No manual browser setup required.&lt;/p&gt;
    &lt;p&gt;Skip browser download (if you manage browsers separately):&lt;/p&gt;
    &lt;code&gt;VIBIUM_SKIP_BROWSER_DOWNLOAD=1 npm install vibium&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Architecture&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;x64 (Intel)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;arm64 (Apple Silicon)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As a library:&lt;/p&gt;
    &lt;code&gt;import { browser } from "vibium";

const vibe = await browser.launch();
await vibe.go("https://example.com");
const el = await vibe.find("a");
await el.click();
await vibe.quit();&lt;/code&gt;
    &lt;p&gt;With Claude Code:&lt;/p&gt;
    &lt;p&gt;Once installed via &lt;code&gt;claude mcp add&lt;/code&gt;, just ask Claude to browse:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Go to example.com and click the first link"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See CONTRIBUTING.md for development setup and guidelines.&lt;/p&gt;
    &lt;p&gt;V1 focuses on the core loop: browser control via MCP and JS client.&lt;/p&gt;
    &lt;p&gt;See V2-ROADMAP.md for planned features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python and Java clients&lt;/item&gt;
      &lt;item&gt;Cortex (memory/navigation layer)&lt;/item&gt;
      &lt;item&gt;Retina (recording extension)&lt;/item&gt;
      &lt;item&gt;Video recording&lt;/item&gt;
      &lt;item&gt;AI-powered locators&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-12-22: Day 12 - Published to npm&lt;/item&gt;
      &lt;item&gt;2025-12-21: Day 11 - Polish &amp;amp; Error Handling&lt;/item&gt;
      &lt;item&gt;2025-12-20: Day 10 - MCP Server&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 9 - Actionability&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 8 - Elements &amp;amp; Sync API&lt;/item&gt;
      &lt;item&gt;2025-12-17: Halfway There&lt;/item&gt;
      &lt;item&gt;2025-12-16: Week 1 Progress&lt;/item&gt;
      &lt;item&gt;2025-12-11: V1 Announcement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache 2.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/VibiumDev/vibium"/><published>2025-12-24T17:49:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46377862</id><title>Fabrice Bellard: Biography (2009) [pdf]</title><updated>2025-12-25T00:53:18.872020+00:00</updated><content/><link href="https://www.ipaidia.gr/wp-content/uploads/2020/12/117-2020-fabrice-bellard.pdf"/><published>2025-12-24T18:17:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46378554</id><title>Show HN: Minimalist editor that lives in browser, stores everything in the URL</title><updated>2025-12-25T00:53:16.359518+00:00</updated><content>&lt;doc fingerprint="2a34105e063698ad"&gt;
  &lt;main&gt;
    &lt;p&gt;A minimalist text editor that lives entirely in your browser and stores everything in the URL hash.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;📝 It's a textarea! Actually not.&lt;/item&gt;
      &lt;item&gt;🗜️ Compression magic - Your text gets compressed with deflate because we're fancy like that&lt;/item&gt;
      &lt;item&gt;🔗 URL storage - Share your notes by copying a 500-character URL. Your friends will love it!&lt;/item&gt;
      &lt;item&gt;🌓 Dark mode - Respects your poor eyes and your color scheme preference&lt;/item&gt;
      &lt;item&gt;💾 Auto-save - Debounced to 500ms because we're not savages&lt;/item&gt;
      &lt;item&gt;📱 Mobile friendly - Type your manifesto on the go&lt;/item&gt;
      &lt;item&gt;🎯 No backend - Zero servers were harmed in the making of this app&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open textarea.my&lt;/item&gt;
      &lt;item&gt;Type stuff&lt;/item&gt;
      &lt;item&gt;Marvel at the URL getting longer&lt;/item&gt;
      &lt;item&gt;Try to share it&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
      &lt;item&gt;Profit&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start your document with &lt;code&gt;# Title&lt;/code&gt;to set a custom page title&lt;/item&gt;
      &lt;item&gt;Your data lives in localStorage AND the URL. Double the fun!&lt;/item&gt;
      &lt;item&gt;Feeling fancy? Add a &lt;code&gt;style&lt;/code&gt;attribute to the&lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt;tag via DevTools. It'll be saved in the URL too!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with ❤️ and JavaScript&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/antonmedv/textarea"/><published>2025-12-24T19:42:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379076</id><title>Spaced repetition for efficient learning (2019)</title><updated>2025-12-25T00:53:15.188403+00:00</updated><content>&lt;doc fingerprint="bc59919e28231ffb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Spaced Repetition for Efficient Learning&lt;/head&gt;
    &lt;p&gt;Efficient memorization using the spacing effect: literature review of widespread applicability, tips on use &amp;amp; what it’s good for.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Spaced repetition is a centuries-old psychological technique for efficient memorization &amp;amp; practice of skills where instead of attempting to memorize by ‘cramming’, memorization can be done far more efficiently by instead spacing out each review, with increasing durations as one learns the item, with the scheduling done by software. Because of the greater efficiency of its slow but steady approach, spaced repetition can scale to memorizing hundreds of thousands of items (while crammed items are almost immediately forgotten) and is especially useful for foreign languages &amp;amp; medical studies.&lt;/p&gt;
      &lt;p&gt;I review what this technique is useful for, some of the large research literature on it and the testing effect (up to ~2013, primarily), the available software tools and use patterns, and miscellaneous ideas &amp;amp; observations on it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;One of the most fruitful areas of computing is making up for human frailties. They do arithmetic perfectly because we can’t1. They remember terabytes because we’d forget. They make the best calendars, because they always check what there is to do today. Even if we do not remember exactly, merely remembering a reference can be just as good, like the point of reading a manual or textbook all the way through: it is not to remember everything that is in it for later but to later remember that something is in it (and skimming them, you learn the right words to search for when you actually need to know more about a particular topic).&lt;/p&gt;
    &lt;p&gt;We use any number of such neuroprosthetics2, but there are always more to be discovered. They’re worth looking for because they are so valuable: a shovel is much more effective than your hand, but a power shovel is orders of magnitude better than both - even if it requires training and expertise to use.&lt;/p&gt;
    &lt;head rend="h1"&gt;Spacing Effect&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;You can get a good deal from rehearsal,&lt;/p&gt;&lt;lb/&gt;If it just has the proper dispersal.&lt;lb/&gt;You would just be an ass,&lt;lb/&gt;To do it en masse,&lt;lb/&gt;Your remembering would turn out much worsal.&lt;p&gt;Ulrich Neisser3&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;My current favorite prosthesis is the class of software that exploits the spacing effect, a centuries-old observation in cognitive psychology, to achieve results in studying or memorization much better than conventional student techniques; it is, alas, obscure4.&lt;/p&gt;
    &lt;p&gt;The spacing effect essentially says that if you have a question (“What is the fifth letter in this random sequence you learned?”), and you can only study it, say, 5 times, then your memory of the answer (‘e’) will be strongest if you spread your 5 tries out over a long period of time - days, weeks, and months. One of the worst things you can do is blow your 5 tries within a day or two. You can think of the ‘forgetting curve’ as being like a chart of a radioactive half-life: each review bumps your memory up in strength 50% of the chart, say, but review doesn’t do much in the early days because the memory simply hasn’t decayed much! (Why does the spacing effect work, on a biological level? There are clear neurochemical differences between massed and spaced in animal models with spacing (&amp;gt;1 hour) enhancing long-term potentiation but not massed5, but the why and wherefore - that’s an open question; see the concept of memory traces or the sleep studies.) A graphical representation of the forgetting curve:&lt;/p&gt;
    &lt;p&gt;Even better, it’s known that active recall is a far superior method of learning than simply passively being exposed to information.6 Spacing also scales to huge quantities of information; gambler/financier Edward O. Thorp harnessed “spaced learning” when he was a physics grad student “in order to be able to work longer and harder”7, and Roger Craig set multiple records on the quiz show Jeopardy! 2010–201114ya in part thanks to using Anki to memorize chunks of a collection of &amp;gt;200,000 past questions8; a later Jeopardy winner, Arthur Chu, also used spaced repetition9. Med school students (who have become a major demographic for SRS due to the extremely large amounts of factual material they are expected to memorize during medical school) usually have thousands of cards, especially if using pre-made decks (more feasible for medicine due to fairly standardized curriculums &amp;amp; general lack of time to make custom cards). Foreign-language learners can easily reach 10-30,000 cards; one Anki user reports a deck of &amp;gt;765k automatically-generated cards filled with Japanese audio samples from many sources (“Youtube videos, video games, TV shows, etc”).&lt;/p&gt;
    &lt;p&gt;A graphic might help; imagine here one can afford to review a given piece of information a few times (one is a busy person). By looking at the odds we can remember the item, we can see that cramming wins in the short term, but unexercised memories decay so fast that after not too long spacing is much superior:&lt;/p&gt;
    &lt;p&gt;It’s more dramatic if we look at a video visualizing decay of a corpus of memory with random review vs most-recent review vs spaced review.&lt;/p&gt;
    &lt;head rend="h2"&gt;If You’re so Good, Why Aren’t You Rich&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Most people find the concept of programming obvious, but the doing impossible.10&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Of course, the latter strategy (cramming) is precisely what students do. They cram the night before the test, and a month later can’t remember anything. So why do people do it? (I’m not innocent myself.) Why is spaced repetition so dreadfully unpopular, even among the people who try it once?11&lt;/p&gt;
    &lt;p&gt;Because it does work. Sort of. Cramming is a trade-off: you trade a strong memory now for weak memory later. (Very weak12.) And tests are usually of all the new material, with occasional old questions, so this strategy pays off! That’s the damnable thing about it - its memory longevity &amp;amp; quality are, in sum, less than that of spaced repetition, but cramming delivers its goods now13. So cramming is a rational, if short-sighted, response, and even SRS software recognize its utility &amp;amp; support it to some degree14. (But as one might expect, if the testing is continuous and incremental, then the learning tends to also be long-lived15; I do not know if this is because that kind of testing is a disguised accidental spaced repetition system, or the students/subjects simply studying/acting differently in response to small-stakes exams.) In addition to this short-term advantage, there’s an ignorance of the advantages of spacing and a subjective illusion that the gains persist1617 (cf. 201218, 2014, et al 2013, et al 2019); from 2009’s study of GRE vocab (emphasis added):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Across experiments, spacing was more effective than massing for 90% of the participants, yet after the first study session, 72% of the participants believed that massing had been more effective than spacing….When they do consider spacing, they often exhibit the illusion that massed study is more effective than spaced study, even when the reverse is true (Dunlosky &amp;amp; Nelson, 1994; Kornell &amp;amp; Bjork, 200817yaa; 2001; Zechmeister &amp;amp; Shaughnessy, 1980).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As one would expect if the testing and spacing effects are real things, students who naturally test themselves and study well in advance of exams tend to have higher GPAs.19 If we interpret questions as tests, we are not surprised to see that 1-on-1 tutoring works dramatically better than regular teaching and that tutored students answer orders of magnitude more questions20.&lt;/p&gt;
    &lt;p&gt;This short-term perspective is not a good thing in the long term, of course. Knowledge builds on knowledge; one is not learning independent bits of trivia. Richard Hamming recalls in “You and Your Research” that “You observe that most great scientists have tremendous drive….Knowledge and productivity are like compound interest.”&lt;/p&gt;
    &lt;p&gt;Knowledge needs to accumulate, and flashcards with spaced repetition can aid in just that accumulation, fostering steady review even as the number of cards and intellectual prerequisites mounts into the thousands.&lt;/p&gt;
    &lt;p&gt;This long term focus may explain why explicit spaced repetition is an uncommon studying technique: the pay-off is distant &amp;amp; counterintuitive, the cost of self-control near &amp;amp; vivid. (See hyperbolic discounting.) It doesn’t help that it’s pretty difficult to figure out when one should review - the optimal point is when you’re just about to forget about it, but that’s the kicker: if you’re just about to forget about it, how are you supposed to remember to review it? You only remember to review what you remember, and what you already remember isn’t what you need to review!21&lt;/p&gt;
    &lt;p&gt;The paradox is resolved by letting a computer handle all the calculations. We can thank Hermann Ebbinghaus for investigating in such tedious detail than we can, in fact, program a computer to calculate both the forgetting curve and optimal set of reviews22. This is the insight behind spaced repetition software: ask the same question over and over, but over increasing spans of time. You start with asking it once every few days, and soon the human remembers it reasonably well. Then you expand intervals out to weeks, then months, and then years. Once the memory is formed and dispatched to long-term memory, it needs but occasional exercise to remain hale and hearty23 - I remember well the large dinosaurs made of cardboard for my 4th or 5th birthday, or the tunnel made out of boxes, even though I recollect them once or twice a year at most.&lt;/p&gt;
    &lt;head rend="h2"&gt;Literature Review&lt;/head&gt;
    &lt;p&gt;But don’t take my word for it - Nullius in verba! We can look at the science. Of course, if you do take my word for it, you probably just want to read about how to use it and all the nifty things you can do, so I suggest you skip all the way down to that section. Everyone else, we start at the beginning:&lt;/p&gt;
    &lt;head rend="h3"&gt;Background: Testing Works!&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;“If you read a piece of text through twenty times, you will not learn it by heart so easily as if you read it ten times while attempting to recite from time to time and consulting the text when your memory fails.” –The New Organon, Francis Bacon&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The testing effect is the established psychological observation that the mere act of testing someone’s memory will strengthen the memory (regardless of whether there is feedback). Since spaced repetition is just testing on particular days, we ought to establish that testing works better than regular review or study, and that it works outside of memorizing random dates in history. To cover a few papers:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Allen, G.A., Mahler, W.A., &amp;amp; Estes, W.K. (196956ya). “Effects of recall tests on long-term retention of paired associates”. Journal of Verbal Learning and Verbal Behavior, 8, 463-470&lt;/p&gt;
        &lt;p&gt;1 test results in memories as strong a day later as studying 5 times; intervals improve retention compared to massed presentation.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Karpicke &amp;amp; Roediger (200322ya). “The Critical Importance of Retrieval for Learning”&lt;/p&gt;
        &lt;p&gt;In learning Swahili vocabulary, students were given varying routines of testing or studying or testing and studying; this resulted in similar scores during the learning phase. Students were asked to predict what percentage they’d remember (average: 50% over all groups). One week later, the students who tested remembered ~80% of the vocabulary versus ~35% for non-testing students. Some students were tested or studied more than others; diminishing returns set in quickly once the memory had formed the first day. Students reported rarely testing themselves and not testing already learned items.&lt;/p&gt;
        &lt;p&gt;Lesson: again, testing improves memory compared to studying. Also, no student knows this.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Roediger &amp;amp; Karpicke (200619yaa). “Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention”&lt;/p&gt;
        &lt;p&gt;Students were tested (with no feedback) on reading comprehension of a passage over 5 minutes, 2 days, and 1 week. Studying beat testing over 5 minutes, but nowhere else; students believed studying superior to testing over all intervals. At 1 week, testing scores were ~60% versus ~40%.&lt;/p&gt;
        &lt;p&gt;Lesson: testing improves memory compared to studying. Everyone (teachers &amp;amp; students) ‘knows’ the opposite.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Karpicke &amp;amp; Roediger (200619yaa). “Expanding retrieval promotes short-term retention, but equal interval retrieval enhances long-term retention”&lt;/p&gt;
        &lt;p&gt;General scientific prose comprehension; from 2006b: “After 2 days, initial testing produced better retention than restudying (68% versus 54%), and an advantage of testing over restudying was also observed after 1 week (56% versus 42%).”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Roediger &amp;amp; Karpicke (200619yab). “The Power of Testing Memory: Basic Research and Implications for Educational Practice”&lt;/p&gt;
        &lt;p&gt;Literature review; 7 studies before 194184ya demonstrating testing improves retention, and 6 afterwards. See also the reviews “Spacing Learning Events Over Time: What the Research Says” &amp;amp; “Using spacing to enhance diverse forms of learning: Review of recent research and implications for instruction”, et al 2012.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2008, “Examining the Testing Effect with Open- and Closed-Book Tests”&lt;/p&gt;
        &lt;p&gt;As with #2, the purer forms of testing (in this case, open-book versus closed-book testing) did better over the long run, and students were deluded about what worked best.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bangert- et al 1991. “Effects of frequent classroom testing”&lt;/p&gt;
        &lt;p&gt;Meta-analysis of 35 studies (1929–60198936ya) varying tests during school semesters. 29 found benefits; 5 found negatives; 1 null result. Meta-study found large benefits to testing even once, then diminishing returns.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2006, “Impact of self-assessment questions and learning styles in Web-based learning: a randomized, controlled, crossover trial”; final scores were higher when the doctors (residents) learned with questions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2009, “The Effect of Online Chapter Quizzes on Exam Performance in an Undergraduate Social Psychology Course” (“This study examined the effectiveness of compulsory, mastery-based, weekly reading quizzes as a means of improving exam and course performance. Completion of reading quizzes was related to both better exam and course performance.”); see also et al 2012.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2013, “Effect of Repeated Testing on the Development of Secondary Language Proficiency”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2013, “Taking the Testing Effect Beyond the College Freshman: Benefits for Lifelong Learning”; verifies testing effect in older adults has similar effect size as younger&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2013, “Test-enhanced learning”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2021, “Testing (Quizzing) Boosts Classroom Learning: A Systematic And Meta–Analytic Review”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(One might be tempted to object that testing works for some learning styles, perhaps verbal styles. This is an unsupported assertion inasmuch as the experimental literature on learning styles is poor and the existing evidence mixed that there are such things as learning styles.24)&lt;/p&gt;
    &lt;head rend="h4"&gt;Subjects&lt;/head&gt;
    &lt;p&gt;The above studies often used pairs of words or words themselves. How well does the testing effect generalize?&lt;/p&gt;
    &lt;p&gt;Materials which benefited from testing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;foreign vocabulary (eg. 2003, et al 2009, et al 200725, de la 2012)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;GRE materials (like vocab, 2009); prose passages on general scientific topics (Karpicke &amp;amp; Roediger, 200619yaa; Pashler et al, 200322ya)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;trivia (1991)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;elementary &amp;amp; middle school lessons with subjects such as biographical material and science (1917; 193926 and 201227, respectively)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2008: short-answer tests superior on textbook passages&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;history textbooks; retention better with initial short-answer test rather than multiple choice (1982)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1975 also found better retention compared to multiple-choice or recognition problems&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Duchastel &amp;amp; Nungester, 1981: 6 months after testing, testing beat studying in retention of a history passage&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1981: free recall decisively beat short-answer &amp;amp; multiple choice for reading comprehension of a history passage&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1989: free recall self-test beat recognition or Cloze deletions; subject matter was the labels for parts of flowers&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2007: prose passages; initial short answer testing produced superior results 3 days later on both multiple choice and short answer tests&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2002: tests in 2 psychology courses, introductory &amp;amp; memory/learning; “80% versus 74% for the introductory psychology course and 89% versus 80% for the learning and memory course”28&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This covers a pretty broad range of what one might call ‘declarative’ knowledge. Extending testing to other fields is more difficult and may reduce to ‘write many frequent analyses, not large ones’ or ‘do lots of small exercises’, whatever those might mean in those fields:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A third issue, which relates to the second, is whether our proposal of testing is really appropriate for courses with complex subject matters, such as the philosophy of Spinoza, Shakespeare’s comedies, or creative writing. Certainly, we agree that most forms of objective testing would be difficult in these sorts of courses, but we do believe the general philosophy of testing (broadly speaking) would hold-students should be continually engaged and challenged by the subject matter, and there should not be merely a midterm and final exam (even if they are essay exams). Students in a course on Spinoza might be assigned specific readings and thought-provoking essay questions to complete every week. This would be a transfer-appropriate form of weekly ‘testing’ (albeit with take-home exams). Continuous testing requires students to continuously engage themselves in a course; they cannot coast until near a midterm exam and a final exam and begin studying only then.29&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h4"&gt;Downsides&lt;/head&gt;
    &lt;p&gt;Testing does have some known flaws:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;interference in recall - ability to remember tested items drives out ability to remember similar untested items&lt;/p&gt;
        &lt;p&gt;Most/all studies were in laboratory settings and found relatively small effects:&lt;/p&gt;
        &lt;p&gt;In sum, although various types of recall interference are quite real (and quite interesting) phenomena, we do not believe that they compromise the notion of test-enhanced learning. At worst, interference of this sort might dampen positive testing effects somewhat. However, the positive effects of testing are often so large that in most circumstances they will overwhelm the relatively modest interference effects.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;multiple choice tests can accidentally lead to ‘negative suggestion effects’ where having previously seen a falsehood as an item on the test makes one more likely to believe it.&lt;/p&gt;
        &lt;p&gt;This is mitigated or eliminated when there’s quick feedback about the right answer (see 2008 “Feedback enhances the positive effects and reduces the negative effects of multiple-choice testing”). Solution: don’t use multiple choice; inferior in testing ability to free recall or short answers, anyway.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Neither problem seems major.&lt;/p&gt;
    &lt;head rend="h3"&gt;Distributed&lt;/head&gt;
    &lt;p&gt;A lot depends on when you do all your testing. Above we saw some benefits to testing a lot the moment you learn something, but the same number of tests could be spread out over time, to give us the spacing effect or spaced repetition. There are hundreds of studies involving the spacing effect:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2006 is a review of 184 articles with 317 experiments; other reviews include:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1928, “Factors influencing the relative economy of massed and distributed practice in learning”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1989, “Spacing effects and their implications for theory and practice”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2010, “Spacing and testing effects: A deeply critical, lengthy, and at times discursive review of the literature”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1999, “A meta-analytic review of the distribution of practice effect: Now you see it, now you don’t”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Almost unanimously they find spacing out tests is superior to massed testing when the final test/measurement is conducted days or years later30, although the mechanism isn’t clear31. Besides all the previously mentioned studies, we can throw in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Peterson, L. R., Wampler, R., Kirkpatrick, M., &amp;amp; Saltzman, D. (196362ya). “Effect of spacing presentations on retention of a paired associate over short intervals”. Journal of Experimental Psychology, 66(2), 206-209&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Glenberg, A. M. (197748ya). “Influences of retrieval processes on the spacing effect in free recall”. Journal of Experimental Psychology: Human Learning and Memory, 3(3), 282-294&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 1989, “Age-related differences in the impact of spacing, lag and retention interval”. Psychology and Aging, 4, 3-9&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The research literature focuses extensively on the question of what kind of spacing is best and what this implies about memory: a spacing that has static fixed intervals or a spacing which expands? This is important for understanding memory and building models of it, and would be helpful for integrating spaced repetition into classrooms (for example, 2013’s 10 minutes studying / 10 minutes break schedule, repeating the same material 3 times, designed to trigger LTM formation on that block of material?) But for practical purposes, this is uninteresting; to sum it up, there are many studies pointing each way, and whatever difference in efficiency exists, is minimal. Most existing software follows SuperMemo in using an expanding spacing algorithm, so it’s not worth worrying about; as Mnemosyne developer Peter Bienstman says, it’s not clear the more complex algorithms really help32, and the Anki developers were concerned about the complexity, difficulty of reimplementing SM’s proprietary algorithms, lack of substantial gains, &amp;amp; larger errors SM3+ risks attempting to be more optimal. So too here.&lt;/p&gt;
    &lt;p&gt;For those interested, 3 of the studies that found fixed spacings better than expanding:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Carpenter, S. K., &amp;amp; DeLosh, E. L. (200520ya). “Application of the testing and spacing effects to name learning”. Applied Cognitive Psychology, 19, 619-63633&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Logan, J. M. (200421ya). Spaced and expanded retrieval effects in younger and older adults. Unpublished doctoral dissertation, Washington University, St. Louis, MO&lt;/p&gt;
        &lt;p&gt;This thesis is interesting inasmuch as Logan found that young adults did considerably worse with an expanding spacing after a day.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Karpicke &amp;amp; Roediger, 200619yaa&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The fixed vs expanding issue aside, a list of additional generic studies finding benefits to spaced vs massed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2006 (large review used elsewhere in this page)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2006a&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2006. “The effects of over-learning and distributed practice on the retention of mathematics knowledge”. Applied Cognitive Psychology, 20: 1209–1224 (see also 2007, et al 2005)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2005. “Distributed and Massed Practice: From Laboratory to Classroom”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Keppel, Geoffrey. “A Reconsideration of the Extinction-Recovery Theory”. Journal of Verbal Learning &amp;amp; Verbal Behavior. 6(4) 196758ya, 476-486&lt;/p&gt;
        &lt;p&gt;A week later, the massed reviewers went from 5.9 correct → 2.1; the spaced reviewers went from 5.5 → 5.0. (Note the usual observation: massed was initially better, and later much worse, less than half as good.)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Four days after the 2 high school groups memorized 16 French words, the spaced group remembered 15 and the massed 11.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1985, “The effect of expanded versus massed practice on the retention of multiplication facts and spelling lists”34&lt;/p&gt;
        &lt;p&gt;A test immediately following the training showed superior performance for the distributed group (70% correct) compared to the massed group (53% correct). These results seem to show that the spacing effect applies to school-age children and to at least some types of materials that are typically taught in school.35&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1999, “A meta-analytic review of the distribution of practice effect: Now you see it, now you don’t”:&lt;/p&gt;
        &lt;p&gt;According to Donovan &amp;amp; Radosevich’s meta-analysis of spacing studies, the effect size for the spacing effect is d = 0.42. This means that the average person getting distributed training remembers better than about 67% of the people getting massed training. This effect size is nothing to sneeze at-in education research, effect sizes as low as d = 0.25 are considered “practically significant”, while effect sizes above d = 1 are rare.36&lt;/p&gt;
        &lt;p&gt;In one meta-analysis by 1999, for instance, the size of the spacing effect declined sharply as conceptual difficulty of the task increased from low (eg. rotary pursuit) to average (eg. word list recall) to high (eg. puzzle). By this finding, the benefits of spaced practise may be muted for many mathematics tasks.37&lt;/p&gt;
        &lt;p&gt;The Donovan meta-analysis notes that the effect size is smaller in studies with better methodology, but still important.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bahrick, Harry P; Phelphs, Elizabeth. “Retention of Spanish vocabulary over 8 years”. Journal of Experimental Psychology: Learning, Memory, &amp;amp; Cognition. Vol 13(2) April 198738ya, 344-349; the extremely long delay after the initial training period makes this particularly interesting:&lt;/p&gt;
        &lt;p&gt;Harry Bahrick and Elizabeth Phelps (198738ya) examined the retention of 50 Spanish vocabulary words after an eight-year delay. Subjects were divided into three groups. Each practiced for seven or eight sessions, separated by a few minutes, a day, or 30 days. In each session, subjects practiced until they could produce the list perfectly one time….Eight years later, people in the no-delay group could recall 6% of the words, people in the one-day delay group could remember 8%, and those in the 30-day group averaged 15%. Everyone also took a multiple choice test, and again, the spacing effect was observed. The no-delay group scored 71%, the one-day group scored 80%, and the 30-day group scored 83%.&lt;/p&gt;
        &lt;p&gt;…Bahrick and his colleagues varied both the spacing of practice and the amount of practice. Practice sessions were spaced 14, 28, or 56 days apart, and totaled 13 or 26 sessions. They tested subjects’ memory one, two, three, and five years after training. Once again, it took a bit longer to reach the criterion within each session when practice sessions were spaced farther apart, but again, this small investment paid dividends years later. It didn’t matter whether testing occurred at one, two, three, or five years after practice-the 56-day group always remembered the most, the 28-day group was next, and the 14-day group remembered the least. Further, the effect was quite large. If words were practiced every 14 days, you needed twice as much practice to reach the same level of performance as when words were practiced every 56 days!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2003; “Is Temporal Spacing of Tests Helpful Even When It Inflates Error Rates?”&lt;/p&gt;
        &lt;p&gt;Long intervals between tests necessarily means you will often err; errors were thought to intrinsically reduce learning. While the extra errors do damage accuracy in the short-run, the long intervals are powerful enough that they still win.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;works in ill subpopulations:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;works on short-term review conducted with Alzheimer’s patients; spacing used on the scale of seconds and minutes, with modest success in teaching object locations or daily tasks to do38:&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;
                &lt;p&gt;Camp, C. J. (198936ya). “Facilitation of new learning in Alzheimer’s disease”. In G. C. Gilmore, P. J. Whitehouse, &amp;amp; M. L. Wykle (Eds.), Memory, aging, and dementia (pp. 212-225)&lt;/p&gt;
              &lt;/item&gt;
              &lt;item&gt;
                &lt;p&gt;Camp, C. J., &amp;amp; McKitrick, L. A. (199233ya). “Memory interventions in Alzheimer’s-type dementia populations: Methodological and theoretical issues”. In R. L. West &amp;amp; J. D. Sinnott (Eds.), Everyday memory and aging: Current research and methodology (pp. 152-172) -&lt;/p&gt;
              &lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;works with traumatic brain injury; et al 2009, “Application of the spacing effect to improve learning and memory for functional tasks in traumatic brain injury: a pilot study”&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;and multiple sclerosis; et al 2009, “A functional application of the spacing effect to improve learning and memory in persons with multiple sclerosis”&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;math39:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;multiplication (1985)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;permuting a sequence (2006)on&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;calculating the volume of polyhedrons (2007)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;statistics (1984)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;pre-calculus (199740 but there’s a related null ‘calculus I’ result as well) and algebra (2002, 2013; possible null, 2013)&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;medicine (2009, et al 2012; 2009, a 2 year followup to et al 2007 and Kerfoot has a number of other relevant studies; et al 2013) and surgery ( et al 2006, “Teaching Surgical Skills: What Kind of Practice Makes Perfect? A Randomized, Controlled Trial”, distributed practice of microvascular suturing; et al 2014)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;introductory psychology (2006, “Encouraging Distributed Study: A Classroom Experiment on the Spacing Effect”41. Teaching of Psychology, 33, 249-252)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;8th-grade American history (Carpenter, Pashler, and 2009)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;learning to read with phonics ( et al 2005)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;music (2009)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;biology (middle school; 2013)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;statistics (introductory; et al 2015)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;memorizing website passwords (2014, et al 2014, 2017)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;possibly not Australian constitutional law ( et al 2015)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Generality of Spacing Effect&lt;/head&gt;
    &lt;p&gt;We have already seen that spaced repetition is effective on a variety of academic fields and mediums. Beyond that, spacing effects can be found in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;various “domains (eg. learning perceptual motor tasks or learning lists of words)”42 such as spatial43&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“across species (eg. rats, pigeons, and humans [or flies or bumblebees, and sea slugs, et al 1972 &amp;amp; et al 2002])”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“across age groups [infancy44, childhood45, adulthood46, the elderly47] and individuals with different memory impairments”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“and across retention intervals of seconds48 [to days49] to months” (we have already seen studies using years)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The domains are limited, however. et al 2006:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[1995, reviewing 120 articles] concluded that longer ISIs facilitate learning of verbal information (eg. spelling50) and motor skills (eg. mirror tracing); in each case, over 80% of studies showed a distributed practice benefit. In contrast, only one third of intellectual skill (eg. math computation) studies showed a benefit from distributed practice, and half showed no effect from distributed practice.&lt;/p&gt;
      &lt;p&gt;…[1999] The largest effect sizes were seen in low rigor studies with low complexity tasks (eg. rotary pursuit, typing, and peg reversal), and retention interval failed to influence effect size. The only interaction Donovan and Radosevich examined was the interaction of ISI and task domain. It is important to note that task domain moderated the distributed practice effect; depending on task domain and lag, an increase in ISI either increased or decreased effect size. Overall, Donovan and Radosevich found that increasingly distributed practice resulted in larger effect sizes for verbal tasks like free recall, foreign language, and verbal discrimination, but these tasks also showed an inverse-U function, such that very long lags produced smaller effect sizes. In contrast, increased lags produced smaller effect sizes for skill tasks like typing, gymnastics, and music performance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Skills like gymnastics and music performance raise an important point about the testing effect and spaced repetition: they are for the maintenance of memories or skills, they do not increase it beyond what was already learned. If one is a gifted amateur when one starts reviewing, one remains a gifted amateur. Ericsson covers what is necessary to improve and attain new expertise: deliberate practice51. From “The Role of Deliberate Practice”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The view that merely engaging in a sufficient amount of practice—regardless of the structure of that practice—leads to maximal performance, has a long and contested history. In their classic studies of Morse Code operators, Bryan and Harter (1897, 1899) identified plateaus in skill acquisition, when for long periods subjects seemed unable to attain further improvements. However, with extended efforts, subjects could restructure their skill to overcome plateaus…Even very experienced Morse Code operators could be encouraged to dramatically increase their performance through deliberate efforts when further improvements were required…More generally, Thorndike (1921104ya) observed that adults perform at a level far from their maximal level even for tasks they frequently carry out. For instance, adults tend to write more slowly and illegibly than they are capable of doing…The most cited condition [for optimal learning and improvement of performance] concerns the subjects’ motivation to attend to the task and exert effort to improve their performance…The subjects should receive immediate informative feedback and knowledge of results of their performance…In the absence of adequate feedback, efficient learning is impossible and improvement only minimal even for highly motivated subjects. Hence mere repetition of an activity will not automatically lead to improvement in, especially, accuracy of performance…In contrast to play, deliberate practice is a highly structured activity, the explicit goal of which is to improve performance. Specific tasks are invented to overcome weaknesses, and performance is carefully monitored to provide cues for ways to improve it further. We claim that deliberate practice requires effort and is not inherently enjoyable.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h5"&gt;Motor Skills&lt;/head&gt;
    &lt;p&gt;It should be noted that reviews conflict on how much spaced repetition applies to motor skills; 1988 find benefits, while 1987 and earlier do not. The difference may be that simple motor tasks benefit from spacing as suggested by 1979 (benefits to a randomized/spaced schedule), while complex ones where the subject is already operating at his limits do not benefit, suggested by 2002. 2009 mentions some divergent studies:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The contextual interference hypothesis (Shea and 1979, 1966 [“Facilitation and interference” in Acquisition of skill]) predicted the blocked condition would exhibit superior performance immediately following practice (acquisition) but the random condition would perform better at delayed retention testing. This hypothesis is generally consistent in laboratory motor learning studies (eg. 1983, 2004), but less consistent in applied studies of sports skills (with a mix of positive &amp;amp; negative eg. 1997, et al 1994, 2013) and fine-motor skills ( et al 2005, Ste- et al 2004).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Some of the positive spaced repetition studies (from 2012):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Perhaps even prior to the empirical work on cognitive learning and the spacing effect, the benefits of spaced study had been apparent in an array of motor learning tasks, including maze learning (1912), typewriting (1915), archery (1915), and javelin throwing (1916; see 1928, for a larger review of the motor learning tasks which reap benefits from spacing; see also 1996, for a more recent review of motor learning tasks). Thus, as in the cognitive literature, the study of practice distribution in the motor domain is long established (see reviews by 1987; 2005), and most interest has centered around the impact of varying the separation of learning trials of motor skills in learning and retention of practiced skills. 1988 conducted a review and meta-analysis of studies on distribution of practice, and they concluded that massing of practice tends to depress both immediate performance and learning, where learning is evaluated at some removed time from the practice period. Their main finding was, as in the cognitive literature, that learning was relatively stronger after spaced than after massed practice (although see 1988; 1988; et al 1988 for criticisms of the review)…Probably the most widely cited example is 1978’s study concerning how optimally to teach postal workers to type. They had learners practice once a day or twice a day, and for session lengths of either 1 or 2 h at a time. The main findings were that learners took the fewest cumulative hours of practice to achieve a performance criterion in their typing when they were in the most distributed practice condition. This finding provides clear evidence for the benefits of spacing practice for enhancing learning. However, as has been pointed out (; 2005), there is also trade-off to be considered in that the total elapsed time (number of days) between the beginning of practice and reaching criterion was substantially longer for the most spaced condition….The same basic results have been repeatedly demonstrated in the decades since (see reviews by 1990; 2004), and with a wide variety of motor tasks including different badminton serves (1986), rifle shooting (Boyce &amp;amp; Del 1990), a pre-established skill, baseball batting ( et al 1994), learning different logic gate configurations ( et al 1989; 1990), for new users of automated teller machines (2000), and for solving mathematical problems as might appear in a class homework (2007; Le 2008; 2010).&lt;/p&gt;
      &lt;p&gt;Culler, E. A. (1912113ya). “The effect of distribution of practice upon learning”. Journal of Philosophical Psychology, 9, 580-583&lt;/p&gt;
      &lt;p&gt;Pyle, W. H. (1915110ya). “Concentrated versus distributed practice”&lt;/p&gt;
      &lt;p&gt;Murphy, H. H. (1916109ya). “Distributions of practice periods in learning”. Journal of Educational Psychology, 7, 150-162&lt;/p&gt;
      &lt;p&gt;Adams, J. A. (198738ya). “Historical review and appraisal of research on the learning, retention, and transfer of human motor skills”&lt;/p&gt;
      &lt;p&gt;Schmidt, R. A., &amp;amp; Lee, T. D. (200520ya). Motor control and learning: A behavioral emphasis (4th ed.). Urbana-Champaign: Human Kinetics&lt;/p&gt;
      &lt;p&gt;Lee, T. D., &amp;amp; Genovese, E. D. (198837ya). “Distribution of practice in motor skill acquisition: Learning and performance effects reconsidered”. Research Quarterly for Exercise and Sport, 59, 277-287&lt;/p&gt;
      &lt;p&gt;Ammons, R. B. (198837ya). “Distribution of practice in motor skill acquisition: A few questions and comments”. Research Quarterly for Exercise and Sport, 59, 288-290&lt;/p&gt;
      &lt;p&gt;Christina, R. W., &amp;amp; Shea, J. B. (198837ya). “The limitations of generalization based on restricted information”. Research Quarterly for Exercise and Sport, 59, 291-297&lt;/p&gt;
      &lt;p&gt;Newell, K. M., Antoniou, A., &amp;amp; Carlton, L. G. (198837ya). “Massed and distributed practice effects: Phenomena in search of a theory?” Research Quarterly for Exercise and Sport, 59, 308-313&lt;/p&gt;
      &lt;p&gt;Lee, T. D., &amp;amp; Wishart, L. R. (200520ya). “Motor learning conundrums (and possible solutions)”&lt;/p&gt;
      &lt;p&gt;Lee, T. D., &amp;amp; Simon, D. A. (200421ya). “Contextual interference”&lt;/p&gt;
      &lt;p&gt;Goode, S., &amp;amp; Magill, R. A. (198639ya). “Contextual interference effects in learning three badminton serves”. Research Quarterly for Exercise and Sport, 57, 308-314&lt;/p&gt;
      &lt;p&gt;Boyce,, &amp;amp; Del Rey, P. (199035ya). “Designing applied research in a naturalistic setting using a contextual interference paradigm”. Journal of Human Movement Studies, 18, 189-200&lt;/p&gt;
      &lt;p&gt;et al 1994, “Contextual interference effects with skilled baseball players”&lt;/p&gt;
      &lt;p&gt;Carlson, R. A., &amp;amp; Yaure, R. G. (199035ya). “Practice schedules and the use of component skills in problem solving”&lt;/p&gt;
      &lt;p&gt;Carlson, R. A., Sullivan, M. A., &amp;amp; Schneider, W. (198936ya). “Practice and working memory effects in building procedural skill”&lt;/p&gt;
      &lt;p&gt;Jamieson,, &amp;amp; Rogers, W. A. (200025ya). “Age-related effects of blocked and random practice schedules on learning a new technology”&lt;/p&gt;
      &lt;p&gt;Le Blanc, K. &amp;amp; Simon, D. A. (200817ya). “Mixed practice enhances retention and JOL accuracy for mathematical skills”. Poster presented at the 200817ya annual meeting of the Psychonomic Society, Chicago, IL&lt;/p&gt;
      &lt;p&gt;et al 2016, “Motor Skills Are Strengthened through Reconsolidation”&lt;/p&gt;
      &lt;p&gt;et al 1993, “The Effects of Variable Practice on the Performance of a Basketball Skill”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In this vein, it’s interesting to note that interleaving may be helpful for tasks with a mental component as well: et al 2003, et al 2011, and according to et al 2013 the rates at which Xbox Halo: Reach video game players advance in skill matches nicely predictions from distribution: players who play 4–8 matches a week advance more in skill per match, than players who play more (distributed); but advance slower per week than players who play many more matches / massed. (See also 2016.)&lt;/p&gt;
    &lt;head rend="h5"&gt;Abstraction&lt;/head&gt;
    &lt;p&gt;Another potential objection is to argue52 that spaced repetition inherently hinders any kind of abstract learning and thought because related materials are not being shown together - allowing for comparison and inference - but days or months apart. Ernst A. Rothkopf: “Spacing is the friend of recall, but the enemy of induction” (2008, p. 585). This is plausible based on some of the early studies53 but the 4 recent studies I know of directly examining the issue both found spaced repetition helped abstraction as well as general recall:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;2008a, “Learning concepts and categories: Is spacing the ‘enemy of induction’?” Psychological Science, 19, 585-592&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vlach, H. A., Sandhofer, C. M., &amp;amp; Kornell, N. (200817ya). “The spacing effect in children’s memory and category induction”. Cognition, 109, 163-167&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kornell, N., Castel, A. D., Eich, T. S., &amp;amp; Bjork, R. A. (201015ya). “Spacing as the friend of both memory and induction in younger and older adults”. Psychology and Aging, 25, 498-503&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2012, “Distributing Learning Over Time: The Spacing Effect in Children’s Acquisition and Generalization of Science Concepts”, Child Development&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2012, “The spacing effect in inductive learning”; includes:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;replication of 2008&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;et al 2011&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;unknown paper currently in peer review&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2013, “Effects of Spaced versus Massed Training in Function Learning”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2014: 1, 2; et al 2019: “A randomized controlled trial of interleaved mathematics practice”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2014, “Equal spacing and expanding schedules in children’s categorization and generalization”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gluckman et al, “Spacing Simultaneously Promotes Multiple Forms of Learning in Children’s Science Curriculum”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Review Summary&lt;/head&gt;
    &lt;p&gt;To bring it all together with the gist:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;testing is effective and comes with minimal negative factors&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;expanding spacing is roughly as good as or better than (wide) fixed intervals, but expanding is more convenient and the default&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;testing (and hence spacing) is best on intellectual, highly factual, verbal domains, but may still work in many low-level domains&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the research favors questions which force the user to use their memory as much as possible; in descending order of preference:&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;free recall&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;short answers&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;multiple-choice&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Cloze deletion&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;recognition&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the research literature is comprehensive and most questions have been answered - somewhere.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the most common mistakes with spaced repetition are&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;formulating poor questions and answers&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;assuming it will help you learn, as opposed to maintain and preserve what one already learned54. (It’s hard to learn from cards, but if you have learned something, it’s much easier to then devise a set of flashcards that will test your weak points.)&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Using It&lt;/head&gt;
    &lt;p&gt;One doesn’t need to use SuperMemo, of course; there are plenty of free alternatives. I like Mnemosyne (homepage) myself - Free, packaged for Ubuntu Linux, easy to use, free mobile client, long track record of development and reliability (I’ve used it since ~2008). But the SRS Anki is also popular, and has advantages in being more feature-rich and a larger &amp;amp; more active community (and possibly better support for East Asian language material and a better but proprietary mobile client).&lt;/p&gt;
    &lt;p&gt;OK, but what does one do with it? It’s a surprisingly difficult question, actually. It’s akin to “the tyranny of the blank page” (or blank wiki); now that I have all this power - a mechanical golem that will never forget and never let me forget whatever I chose to - what do I choose to remember?&lt;/p&gt;
    &lt;head rend="h3"&gt;How Much To Add&lt;/head&gt;
    &lt;p&gt;The most difficult task, beyond that of just persisting until the benefits become clear, is deciding what’s valuable enough to add in. In a 3 year period, one can expect to spend “30–40 seconds” on any given item. The long run theoretical predictions are a little hairier. Given a single item, the formula for daily time spent on it is Time = 1⁄500 × nthYear−1.5 + 1⧸30,000. During our 20th year, we would spend t = 1⁄500 × 20−1.5 + 1⧸3,000, or &lt;code&gt;3.557e-4&lt;/code&gt; minutes a day. This is the average daily time, so to recover the annual time spent, we simply multiply by 365. Suppose we were interested in how much time a flashcard would cost us over 20 years. The average daily time changes every year (the graph looks like an exponential decay, remember), so we have to run the formula for each year and sum them all; in Haskell:&lt;/p&gt;
    &lt;code&gt;sum $ map (\year -&amp;gt; ((1/500 * year ** (-(1.5))) + 1/30000) * 365.25) [1..20]
# 1.8291&lt;/code&gt;
    &lt;p&gt;Which evaluates to 1.8 minutes. (This may seem too small, but one doesn’t spend much time in the first year and the time drops off quickly55.) Anki user muflax’s statistics put his per-card time at 71s, for example. But maybe Piotr Woźniak was being optimistic or we’re bad at writing flashcards, so we’ll double it to 5 minutes. That’s our key rule of thumb that lets us decide what to learn and what to forget: if, over your lifetime, you will spend more than 5 minutes looking something up or will lose more than 5 minutes as a result of not knowing something, then it’s worthwhile to memorize it with spaced repetition. 5 minutes is the line that divides trivia from useful data.56 (There might seem to be thousands of flashcards that meet the 5 minute rule. That’s fine. Spaced repetition can accommodate dozens of thousands of cards. See the next section.)&lt;/p&gt;
    &lt;p&gt;To a lesser extent, one might wonder when one is in a hurry, should one learn something with spaced repetition and with massed? How far away should the tests or deadlines be before abandoning spaced repetition? It’s hard to compare since one would need a specific regimens to compare for the crossover point, but for massed repetition, the average time after memorization at which one has a 50% chance of remembering the memorized item seems to be 3-5 days.57 Since there would be 2 or 3 repetitions in that period, presumably one would do better than 50% in recalling an item. 5 minutes and 5 days seems like a memorable enough rule of thumb: ‘don’t use spaced repetition if you need it sooner than 5 days or it’s worth less than 5 minutes’.&lt;/p&gt;
    &lt;head rend="h4"&gt;Overload&lt;/head&gt;
    &lt;p&gt;Spaced repetition is not infinite. Wozniak estimates a maximum number of ~300,000 items can be learned.&lt;/p&gt;
    &lt;p&gt;One common experience of new users to spaced repetition is to add too much stuff—trivialities and things they don’t really care about. But they soon learn the curse of Borges’s Funes the Memorious. If they don’t actually want to learn the material they put in, they will soon stop doing the daily reviews - which will cause reviews to pile up, which will be further discouraging, and so they stop. At least with physical fitness there isn’t a precisely dismaying number indicating how far behind you are! But if you have too little at the beginning, you’ll have few repetitions per day, and you’ll see little benefit from the technique itself - it looks like boring flash card review.&lt;/p&gt;
    &lt;head rend="h3"&gt;What to Add&lt;/head&gt;
    &lt;p&gt;I find one of the best uses for Mnemosyne is, besides the classic use of memorizing academic material such as geography or the periodic table or foreign vocabulary or Bible/Koran verses or the avalanche of medical school facts, to add in words from A Word A Day58 and Wiktionary, memorable quotes I see59, personal information such as birthdays (or license plates, a problem for me before), and so on. Quotidian uses, but all valuable to me. With a diversity of flashcards, I find my daily review interesting. I get all sorts of questions - now I’m trying to see whether a Haskell fragment is syntactically correct, now I’m pronouncing Korean hangul and listening to the answer, now I’m trying to find the Ukraine on a map, now I’m enjoying some A.E. Housman poetry, followed by a few quotes from LessWrong quote threads, and so on. Other people use it for many other things; one application that impresses me for its simple utility is memorizing names &amp;amp; faces of students although learning musical notes is also not bad.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Workload&lt;/head&gt;
    &lt;p&gt;On average, when I’m studying a new topic, I’ll add 3–20 questions a day. Combined with my particular memory, I usually review about 90 or 100 items a day (out of the total &amp;gt;18,300). This takes under 20 minutes, which is not too bad. (I expect the time is expanded a bit by the fact that early on, my formatting guidelines were still being developed, and I hadn’t the full panoply of categories I do now - so every so often I must stop and edit categories.)&lt;/p&gt;
    &lt;p&gt;If I haven’t been studying something recently, the exponential decaying of reviews slowly drops the daily review. For example, in March 201114ya, I wasn’t studying many things, so for 2011-03-24–2011-03-2614ya, my scheduled daily reviews are 73, 83, and 74; after that, it will 201213ya, the daily reviews are in the 40s or sometimes 50s for similar reasons, but the gradual shrinkage will continue.&lt;/p&gt;
    &lt;p&gt;We can see this vividly, and we can even see a sort of analogue of the original forgetting curve, if we ask Mnemosyne 2.0 to graph the number of cards to review per day for the next year up to February 201312ya (assuming no additions or missed reviews etc.):&lt;/p&gt;
    &lt;p&gt;If Mnemosyne weren’t using spaced repetition, it would be hard to keep up with 18,300+ flashcards. But because it is using spaced repetition, keeping up is easy.&lt;/p&gt;
    &lt;p&gt;Nor is 18.3k extraordinary. Many users have decks in the 6–7k range, Mnemosyne developer Peter Bienstman has &amp;gt;8.5k &amp;amp; Patrick Kenny &amp;gt;27k, Hugh Chen has a 73k+ deck, and in &lt;code&gt;irc://irc.libera.chat#anki&lt;/code&gt;, they tell me of one user who triggered bugs with his &amp;gt;200k deck. 200,000 may be a bit much, but for regular humans, some amount smaller seems possible—it’s interesting to compare SRS decks to the feat of memorizing Paradise Lost or to the Muslim title of ‘hafiz’, one who has memorized the ~80,000 words of the Koran, or the stricter ‘hafid’, one who had memorized the Koran and 100,000 hadiths as well. Other forms of memory are still more powerful.60 (I suspect that spaced repetition is involved in one of the few well-documented cases of “hyperthymesia”, Jill Price: reading Wired, she has ordinary fallible powers of memorization for surprise demands with no observed anatomical differences and is restricted to “her own personal history and certain categories like television and airplane crashes”; further, she is a packrat with obsessive-compulsive traits who keeps &amp;gt;50,000 pages of detailed diaries—perhaps due to a childhood trauma—associates daily events nigh-involuntarily with past events. Marcus says the other instances of hyperthymesia resemble Price.)&lt;/p&gt;
    &lt;head rend="h3"&gt;When to Review&lt;/head&gt;
    &lt;p&gt;When should one review? In the morning? In the evening? Any old time? The studies demonstrating the spacing effect do not control or vary the time of day, so in one sense, the answer is: it doesn’t matter - if it did matter, there would be considerable variance in how effective the effect is based on when a particular study had its subjects do their reviews.&lt;/p&gt;
    &lt;p&gt;So one reviews at whatever time is convenient. Convenience makes one more likely to stick with it, and sticking with it overpowers any temporary improvement.&lt;/p&gt;
    &lt;p&gt;If one is not satisfied with that answer, then on general considerations, one ought to review before bedtime &amp;amp; sleep. Memory consolidation seems to be related, and sleep is known to powerfully influence what memories enter long-term memory, strengthening memories of material learned close to bedtime and increasing creativity; interrupting sleep without affecting total sleep time or quality still damages memory formation in mice61. So reviewing before bedtime would be best. (Other mental exercises show improvement when trained before bedtime; for example, dual n-back.) One possible mechanism is that it may be that the expectancy of future reviews/tests is enough to encourage memory consolidation during sleep; so if one reviews and goes to bed, presumably the expectancy is stronger than if one reviewed at breakfast and had an eventful day and forgot entirely about the reviewed flashcards. (See also the correlation between time of studying &amp;amp; GPA in 2012.) Neural growth may be related; from 2010:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Recent advances in our understanding of the neurobiology underlying normal human memory formation have revealed that learning is not an event, but rather a process that unfolds over time.16,17,18,[2003 Fundamental Neuroscience],20 Thus, it is not surprising that learning strategies that repeat materials over time enhance their retention.20,21,22,23,24,25,26&lt;/p&gt;
      &lt;p&gt;…Thousands of new cells are generated in this region every day, although many of these cells die within weeks of their creation.31 The survival of dentate gyrus neurons has been shown to be enhanced in animals when they are placed into learning situations.16-20 Animals that learn well retain more dentate gyrus neurons than do animals that do not learn well. Furthermore, 2 weeks after testing, animals trained in discrete spaced intervals over a period of time, rather than in a single presentation or a ‘massed trial’ of the same information, remember better.16-20 The precise mechanism that links neuronal survival with learning has not yet been identified. One theory is that the hippocampal neurons that preferentially survive are the ones that are somehow activated during the learning process.16-2062 The distribution of learning over a period of time may be more effective in encouraging neuronal survival by allowing more time for changes in gene expression and protein synthesis that extend the life of neurons that are engaged in the learning process.&lt;/p&gt;
      &lt;p&gt;…Transferring memory from the encoding stage, which occurs during alert wakefulness, into consolidation must thus occur at a time when interference from ongoing new memory formation is reduced.17,18 One such time for this transfer is during sleep, especially during non-rapid eye movement sleep, when the hippocampus can communicate with other brain areas without interference from new experiences.32,33,34 Maybe that is why some decisions are better made after a good night’s rest and also why pulling an all-nighter, studying with sleep deprivation, may allow you to pass an exam an hour later but not remember the material a day later.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h4"&gt;Prospects: Extended Flashcards&lt;/head&gt;
    &lt;p&gt;Let’s step back for a moment. What are all our flashcards, small and large, doing for us? Why do I have a pair of flashcards for the word ‘anent’ among many others? I can just look it up.&lt;/p&gt;
    &lt;p&gt;But look ups take time compared to already knowing something. (Let’s ignore the previously discussed 5 minute rule.) If we think about this abstractly in a computer science context, we might recognize it as an old concept in algorithms &amp;amp; optimization discussions—the space-time tradeoff. We trade off lookup time against limited skull space.&lt;/p&gt;
    &lt;p&gt;Consider the sort of factual data already given as examples - we might one day need to know the average annual rainfall in Honolulu or Austin, but it would require too much space to memorize such data for all capitals. There are millions of English words, but in practice any more than 100,000 is excessive. More surprising is a sort of procedural knowledge. An extreme form of space-time tradeoffs in computers is when a computation is replaced by pre-calculated constants. We could take a math function and calculate its output for each possible input. Usually such a lookup table of input to output is really large. Think about how many entries would be in such a table for all possible integer multiplications between 1 and 1 billion. But sometimes the table is really small (like binary Boolean functions) or small (like trigonometric tables) or large but still useful (rainbow tables usually start in the gigabytes and easily reach terabytes).&lt;/p&gt;
    &lt;p&gt;Given an infinitely large lookup table, we could replace completely the skill of, say, addition or multiplication by the lookup table. No computation. The space-time tradeoff taken to the extreme of the space side of the continuum. (We could go the other way and define multiplication or addition as the slow computation which doesn’t know any specifics like the multiplication table - as if every time you wanted to add 2+2 you had to count on 4 fingers.)&lt;/p&gt;
    &lt;p&gt;So suppose we were children who wanted to learn multiplication. SRS and Mnemosyne can’t help because multiplication is not a specific factoid? The space-time tradeoff shows us that we can de-proceduralize multiplication and turn it partly into factoids. It wouldn’t be hard for us to write a quick script or macro to generate, say, 500 random cards which ask us to multiply AB by XY, and import them to Mnemosyne.63&lt;/p&gt;
    &lt;p&gt;After all, which is your mind going to do - get good at multiplying 2 numbers (generate on-demand), or memorize 500 different multiplication problems (memoize)? From my experience with multiple subtle variants on a card, the mind gives up after just a few and falls back on a problem-solving approach - which is exactly what one wants to exercise, in this case. Congratulations; you have done the impossible.&lt;/p&gt;
    &lt;p&gt;From a software engineering point of view, we might want to modify or improve the cards, and 500 snippets of text would be a tad hard to update. So coolest would be a ‘dynamic card’. Add a markup type like &lt;code&gt;&amp;lt;eval src=""&amp;gt;&lt;/code&gt; , and then Mnemosyne feeds the &lt;code&gt;src&lt;/code&gt; argument straight into the Python interpreter, which returns a tuple of the question text and the answer text. The question text is displayed to the user as usual, the user thinks, requests the answer, and grades himself. In Anki, Javascript is supported directly by the application in HTML &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags (currently inline only but Anki could presumably import libraries by default), for example for kinds of syntax highlighting, so any kind of dynamic card could be written that one wants.&lt;/p&gt;
    &lt;p&gt;So for multiplication, the dynamic card would get 2 random integers, print a question like &lt;code&gt;x * y = ?&lt;/code&gt; and then print the result as the answer. Every so often you would get a new multiplication question, and as you get better at multiplication, you see it less often - exactly as you should. Still in a math vein, you could generate variants on formulas or programs where one version is the correct one and the others are subtly wrong; I do this by hand with my programming flashcards (especially if I make an error doing exercises, that signals a finer point to make several flashcards on), but it can be done automatically. kpreid describes one tool of his:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I have written a program (in the form of a web page) which does a specialized form of this [generating ‘damaged formulas’]. It has a set of generators of formulas and damaged formulas, and presents you with a list containing several formulas of the same type (eg. ∫ 2x dx = x^2 + C) but with one damaged (eg. ∫ 2x dx = 2x^2 + C).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This approach generalizes to anything you can generate random problems of or have large databases of examples of. Khan Academy apparently does something like this in associating large numbers of (algorithmicly-generated?) problems with each of its little modules and tracking retention of the skill in order to decide when to do further review of that module. For example, maybe you are studying Go and are interested in learning life-and-death positions. Those are things that can be generated by computer Go programs, or fetched from places like GoProblems.com. For even more examples, Go is rotationally invariant - the best move remains the same regardless of which way the board is oriented and since there is no canonical direction for the board (like in chess) a good player ought to be able to play the same no matter how the board looks - so each specific example can be mirrored in 3 other ways. Or one could test one’s ability to ‘read’ a board by writing a dynamic card which takes each example board/problem and adds some random pieces as long as some go-playing program like GNU Go says the best move hasn’t changed because of the added noise.&lt;/p&gt;
    &lt;p&gt;One could learn an awful lot of things this way. Programming languages could be learned this way - someone learning Haskell could take all the functions listed in the Prelude or his Haskell textbook, and ask QuickCheck to generate random arguments for the functions and ask the GHC interpreter &lt;code&gt;ghci&lt;/code&gt; what the function and its arguments evaluate to. Games other than go, like chess, may work (a live example being Chess Tempo &amp;amp; Listudy, and see the experience of Dan Schmidt; or Super Smash Brothers). A fair bit of mathematics. If the dynamic card has Internet access, it can pull down fresh questions from an RSS feed or just a website; this functionality could be quite useful in a foreign language learning context with every day bringing a fresh sentence to translate or another exercise.&lt;/p&gt;
    &lt;p&gt;With some NLP software, one could write dynamic flashcards which test all sorts of things: if one confuses verbs, the program could take a template like “$PRONOUN $VERB $PARTICLE $OBJECT % {right: caresse, wrong: caresses}” which yields flashcards like “Je caresses le chat” or “Tu caresse le chat” and one would have to decide whether it was the correct conjugation. (The dynamicism here would help prevent memorizing specific sentences rather than the underlying conjugation.) In full generality, this would probably be difficult, but simpler approaches like templates may work well enough. Jack Kinsella:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I wish there were dynamic SRS decks for language learning (or other disciplines). Such decks would count the number of times you have reviewed an instance of an underlying grammatical rule or an instance of a particular piece of vocabulary, for example its singular/plural/third person conjugation/dative form. These sophisticated decks would present users with fresh example sentences on every review, thereby preventing users from remembering specific answers and compelling them to learn the process of applying the grammatical rule afresh. Moreover, these decks would keep users entertained through novelty and would present users with tacit learning opportunities through rotating vocabulary used in non-essential parts of the example sentence. Such a system, with multiple-level review rotation, would not only prevent against overfit learning, but also increase the total amount of knowledge learned per minute, an efficiency I’d gladly invest in.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Even though these things seem like ‘skills’ and not ‘data’!&lt;/p&gt;
    &lt;head rend="h1"&gt;Popularity&lt;/head&gt;
    &lt;p&gt;As of 2011-05-02:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Metric&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Mnemosyne&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;iSRS&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;Homepage Alexa&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;ML/forum members&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;Ubuntu installs&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;Debian installs&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;Arch votes&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;iPhone ratings&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Unreleased65&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;
          &lt;p&gt;Android ratings&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Android installs&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;SuperMemo doesn’t fall under the same ratings, but it has sold in the hundreds of thousands over its 2 decades:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Biedalak is CEO of SuperMemo World, which sells and licenses Wozniak’s invention. Today, SuperMemo World employs just 25 people. The venture capital never came through, and the company never moved to California. About 50,000 copies of SuperMemo were sold in 200619ya, most for less than $48.99$302006. Many more are thought to have been pirated.66&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It seems safe to estimate the combined market-share of Anki, Mnemosyne, iSRS and other SRS apps at somewhere under 50,000 users (making due allowance for users who install multiple times, those who install and abandon it, etc.). Relatively few users seem to have migrated from SuperMemo to those newer programs, so it seems fair to simply add that 50k to the other 50k and conclude that the worldwide population is somewhere around (but probably under) 100,000.&lt;/p&gt;
    &lt;head rend="h1"&gt;Where Was I Going With This?&lt;/head&gt;
    &lt;p&gt;Nowhere, really. Mnemosyne/SR software in general are just one of my favorite tools: it’s based on a famous effect67 discovered by science, and it exploits it elegantly68 and usefully. It’s a testament to the Enlightenment ideal of improving humanity through reason and overcoming our human flaws; the idea of SR is seductive in its mathematical rigor69. In this age where so often the ideal of ‘self-improvement’ and progress are decried, and gloom are espoused by even the common people, it’s really nice to just have a small example like this in one’s daily life, an example not yet so prosaic and boring as the lightbulb.&lt;/p&gt;
    &lt;head rend="h1"&gt;See Also&lt;/head&gt;
    &lt;p&gt;In the course of using Mnemosyne, I’ve written a number of scripts to generate repetitively varying cards.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;mnemo.hs&lt;/code&gt;will take any newline-delimited chunk of text, like a poem, and generates every possible Cloze deletion; that is, an ABC poem will become 3 questions: _BC/ABC, A_C/ABC, AB_/ABC&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mnemo2.hs&lt;/code&gt;works as above, but is more limited and is intended for long chunks of text where&lt;code&gt;mnemo.hs&lt;/code&gt;would cause a combinatorial explosion of generated questions; it generates a subset: for ABCD, one gets __CD/ABCD, A__D/ABCD, and AB__/ABCD (it removes 2 lines, and iterates through the list).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mnemo3.hs&lt;/code&gt;is intended for date or name-based questions. It’ll take input like “Barack Obama is %47%.” and spit out some questions based on this: “Barack Obama is _7./47”, “Barack Obama is 4_./47” etc.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mnemo4.hs&lt;/code&gt;is intended for long lists of items. If one wants to memorize the list of US Presidents, the natural questions for flashcards goes something like “Who was the 3rd president?/Thomas Jefferson”, “Thomas Jefferson was the _rd president./3”, “Who was president after John Adams?/Thomas Jefferson”, “Who was president before James Madison?/Thomas Jefferson”.&lt;p&gt;You note there’s repetition if you do this for each president - one asks the ordinal position of the item both ways (item -&amp;gt; position, position -&amp;gt; item), what precedes it, and what succeeds it.&lt;/p&gt;&lt;code&gt;mnemo4.hs&lt;/code&gt;automates this, given a list. In order to be general, the wording is a bit odd, but it’s better than writing it all out by hand! (Example output is in the comments to the source code).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The reader might well be curious by this point what my Mnemosyne database looks like. I use Mnemosyne quite a bit, and as of 2020-02-02, I have 16,149 (active) cards in my deck. Said curious reader may find my cards &amp;amp; media at &lt;code&gt;gwern.cards&lt;/code&gt; (52M; Mnemosyne 2.x format).&lt;/p&gt;
    &lt;p&gt;The Mnemosyne project has been collecting user-submitted spaced repetition statistical data for years. The full dataset as of 2014-01-27 is available for download by anyone who wishes to analyze it.&lt;/p&gt;
    &lt;head rend="h1"&gt;External Links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Michael Nielsen: “Augmenting Long-term Memory”; “Quantum computing for the very curious”; “How can we develop transformative tools for thought?”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“A Year of Spaced Repetition Software in the Classroom”; two years; seven year followup; cf. “Easy Application of Spaced Practice in the Classroom”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AJATT table of contents -(applying SRS to learning Japanese)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Math:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;“Using spaced repetition systems to see through a piece of mathematics”, Michael Nielsen&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;“Teaching linear algebra” (with spaced repetition), by Ben Tilly; Manual flashcards for his 2nd grader&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Programming:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;“Janki Method: Using spaced repetition systems to learn and retain technical knowledge” (Reddit discussion); SRS problems &amp;amp; solutions&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;“Memorizing a programming language using spaced repetition software” (Derek Sivers; HN)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;“Chasing 10X: Leveraging A Poor Memory In Engineering”; “Everything I Know: Strategies, Tips, and Tricks for Anki”&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;“Remembering R—Using Spaced Repetition to finally write code fluently”&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“QS Primer: Spaced Repetition and Learning” -(talks on applications of spaced repetition)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Value compared to curriculums:&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;Point: “Why Forgetting Can Be Good”, by Scott H. Young&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Counterpoint: “Spaced repetition in natural and artificial learning”, by Ryan Muller&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
        &lt;p&gt;My own observation is that an optimally constructed curriculum could effectively implement spaced repetition, but even if it did (most don’t), unless it is computerized it will not adapt to the user.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bash scripts for generating vocabulary flashcards (processing multiple online dictionaries, good for having multiple examples; images; and audio)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;vocabulary selection:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Diff revision: diff-based revision of text notes, using spaced repetition”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“A vote against spaced repetition”; “How Flashcards Fail: Confessions of a Tired Memory Guy”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Learning Ancient Egyptian in an Hour Per Week with Beeminder”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Using Anki with Babies / Toddlers”: 1, 2, 2, 4&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;followup at age 5 (cf. mutualism)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;“SuperMemo does not work for kids”, Piotr Wozniak&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SeRiouS: “Spaced Repetition Technology for Legal Education”, “SeRiouS: an LPTI-supported Project to Improve Students’ Learning and Bar Performance”, Gabe Teninbaum (video presentation)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“The role of digital flashcards in legal education: theory and potential”, et al 2014&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Making Summer Count: How Summer Programs Can Boost Children’s Learning”, et al 2011 (RAND MG1120)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Factors that Influence Skill Decay And Retention: a Quantitative Review and Analysis”, et al 1998&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“On The Forgetting Of College Academics: At ‘Ebbinghaus speed’?”, et al 2017&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Total recall: the people who never forget; An extremely rare condition may transform our understanding of memory” (obsessive recording &amp;amp; reviewing demonstrates you can recall much of your life if you live nothing worth recalling); “The Mystery of S., the Man with an Impossible Memory: The neuropsychologist Alexander Luria’s case study of Solomon Shereshevsky helped spark a myth about a man who could not forget. But the truth is more complicated”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Anki Essentials, Vermeer&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“No. 126: Four Years of Spaced Repetition” (Gene Dan, actuarial studies)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“One Year Anki Update” (biology grad school)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“How To Remember Anything Forever-ish”: an interactive comic (Nicky Case)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“The Overfitted Brain: Dreams evolved to assist generalization”, 2020&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Relearn Faster and Retain Longer: Along With Practice, Sleep Makes Perfect”, et al 2016&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Replication and Analysis of Ebbinghaus’ Forgetting Curve”, 2015&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Learning from Errors”, 2017&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Flashcard Sources&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;“One does not learn computing by using a hand calculator, but one can forget arithmetic.” —1982↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Listing other neuroprosthetics is hard. It’s an interesting idea, but as proponents of externalism like Andy Clark have found, it’s easier to feel that externalism is meaningful than to nail down a clear definition which separates a neuroprosthetic or part of one’s mind from a random tool you like or find useful. Consider whether a pencil and paper a neuroprosthetic: clearly it is not for a child learning to write, who must carefully compose the words in his mind and put them down one after another, but it is not so clear for an adult who has been writing all his life and can doodle or write down thoughts without thinking about them and may even be surprised at what they happened to write.&lt;/p&gt;
        &lt;p&gt;I like this definition: “a neuroprosthetic is anything whose results you use without further thought”. So in the classic example, when Otto needs to go somewhere, he never thinks “I am an amnesiac who stores locations in my notepad, and I must look up the location” - he just looks up the location. A good heuristic would be anything whose destruction leaves one feeling lost, slow, stupid, or ignorant.&lt;/p&gt;
        &lt;p&gt;By this standard, I can think of only a few tools I use without noticeable thought:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;keybindings such as window manager shortcuts, in particular shortcuts for Google searches; on occasion, XMonad’s Prompt gets inscrutably wedged, locking it. When this happens, I have to restart X because I Google everything and the keybinding is so engrained that not using it is unbearable. It would be like trying to write with your weak hand.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Google Calendar and PredictionBook: it is incredible how many followups or reminders or regularly happening tasks I can put into Google Calendar or PB. I have outsourced many habits or thoughts to them, and I no longer think of it as anything special. If either were gone, I would feel frightened - what events were passing, what beliefs falsified, what opportunities opening up (or closing!) that I had suddenly become ignorant of?&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Evernote, for a similar reason; many of my memories have ceased to be things like “octopuses see too fast to watch TV and so only HDTV or UHDTV works for them; I read this in Orion Magazine” and become things like “octopus TV Evernote”, and if I want to know what it was about octopuses &amp;amp; TV, well, I’ll have to look it up in Evernote. Mnemosyne plays a similar role for me, but there the memories are much clearer on their own because of the spaced repetition.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;my website Gwern.net; I’ve had to say many times that I don’t know what I think about something, but whatever that is, it’s on my website. (A more extreme form of the Evernote/Mnemosyne neuroprosthetic.) A commenter once wrote that reading Gwern.net felt like he was crawling around in my head. He was more right than he realized.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;as quoted in “Retrieval practice and the maintenance of knowledge”, 1988↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From “Close the Book. Recall. Write It Down: That old study method still works, researchers say. So why don’t professors preach it?”; The Chronicle of Higher Education&lt;/p&gt;&lt;p&gt;Two psychology journals have recently published papers showing that this strategy works, the latest findings from a decades-old body of research. When students study on their own, “active recall” - recitation, for instance, or flashcards and other self-quizzing - is the most effective way to inscribe something in long-term memory. Yet many college instructors are only dimly familiar with that research…&lt;/p&gt;&lt;p&gt;From “The Spacing Effect: A Case Study in the Failure to Apply the Results of Psychological Research” (1988), whose title alone summarizes the situation (see also 2007, Making Minds: What’s Wrong with Education - and What Should We Do About It?):&lt;/p&gt;&lt;p&gt;Second, it [the spacing effect] is remarkably robust. In many cases, two spaced presentations are about twice as effective as two massed presentations (eg. Hintzman, 197451ya; Melton, 1970), and the difference between them increases as the frequency of repetition increases (Underwood, 197055ya)…&lt;/p&gt;&lt;p&gt;The spacing effect was known as early as 1885140ya when Ebbinghaus published the results of his seminal work on memory. With himself as the subject, Ebbinghaus found that for a single 12-syllable series, 68 immediately successive repetitions had the effect of making possible an errorless recital after seven additional repetitions on the following day. However, the same effect was achieved by only 38 distributed repetitions spread over 3 days. On the basis of this and other related findings, Ebbinghaus concluded that ‘with any considerable number of repetitions a suitable distribution of them over a space of time is decidedly more advantageous than the massing of them at a single time’ (Ebbinghaus, 1885140ya/1913112ya. p. 89)&lt;/p&gt;&lt;p&gt;2012:&lt;/p&gt;&lt;p&gt;Furthermore, even after acknowledging the benefits of spacing, changing teaching practices proved to be enormously difficult. et al 2010 wrote: “Anecdotally, high school teachers and college professors seem to teach in a linear fashion without repetition and give three or four noncumulative exams.” (p. 130). Focusing on the math domain, where one might expect a very easy-to-review-and-to-space strategy, Rohrer (200916ya) points out that mathematics textbooks usually present topics in a non-spaced, non-mixed fashion. Even much earlier, Vash (198936ya) had written: “Education policy setters know perfectly well that [spaced practice] works better [than massed practice]. They don’t care. It isn’t tidy. It doesn’t let teachers teach a unit and dust off their hands quickly with a nice sense of ‘Well, that’s done.’” (p. 1547478ya).&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Rohrer, D. (200916ya). “The effects of spacing and mixing practice problems”. Journal for Research in Mathematics Education, 40, 4-17&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Vash, C. L. (198936ya). “The spacing effect: A case study in the failure to apply the results of psychological research”. American Psychologist, 44, 1547478ya (a comment on Dempster’s article?)&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;From Psychology: An Introduction:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;In one practical demonstration of the spacing effect, Bahrick, Bahrick, Bahrick, &amp;amp; Bahrick (199332ya) showed that retention of foreign language vocabulary was greatly enhanced if practice sessions were spaced far apart. For example, “Thirteen retraining sessions spaced at 56 days yielded retention comparable to 26 sessions spaced at 14 days.” In other words, subjects could use half as many study sessions, if the study sessions were spread over a time period four times as long.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;“Synaptic evidence for the efficacy of spaced learning”, et al 2012 (“Take your time: Neurobiology sheds light on the superiority of spaced versus massed learning”):&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The superiority of spaced versus massed training is a fundamental feature of learning. Here, we describe unanticipated timing rules for the production of long-term potentiation (LTP) in adult rat hippocampal slices that can account for one temporal segment of the spaced trials phenomenon. Successive bouts of naturalistic theta burst stimulation of field CA1 afferents markedly enhanced previously saturated LTP if spaced apart by 1 h or longer, but were without effect when shorter intervals were used. Analyses of F-actin-enriched spines to identify potentiated synapses indicated that the added LTP obtained with delayed theta trains involved recruitment of synapses that were “missed” by the first stimulation bout. Single spine glutamate-uncaging experiments confirmed that less than half of the spines in adult hippocampus are primed to undergo plasticity under baseline conditions, suggesting that intrinsic variability among individual synapses imposes a repetitive presentation requirement for maximizing the percentage of potentiated connections. We propose that a combination of local diffusion from initially modified spines coupled with much later membrane insertion events dictate that the repetitions be widely spaced. Thus, the synaptic mechanisms described here provide a neurobiological explanation for one component of a poorly understood, ubiquitous aspect of learning.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;There are many studies to the effect that active recall is best. Here’s one recent study, “Retrieval Practice Produces More Learning than Elaborative Studying with Concept Mapping”, 2011 (covered in Science Daily and the NYT):&lt;/p&gt;&lt;p&gt;Educators rely heavily on learning activities that encourage elaborative studying, while activities that require students to practice retrieving and reconstructing knowledge are used less frequently. Here, we show that practicing retrieval produces greater gains in meaningful learning than elaborative studying with concept mapping. The advantage of retrieval practice generalized across texts identical to those commonly found in science education. The advantage of retrieval practice was observed with test questions that assessed comprehension and required students to make inferences. The advantage of retrieval practice occurred even when the criterial test involved creating concept maps. Our findings support the theory that retrieval practice enhances learning by retrieval-specific mechanisms rather than by elaborative study processes. Retrieval practice is an effective tool to promote conceptual learning about science.&lt;/p&gt;&lt;p&gt;From “Forget What You Know About Good Study Habits”. New York Times;&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Cognitive scientists do not deny that honest-to-goodness cramming can lead to a better grade on a given exam. But hurriedly jam-packing a brain is akin to speed-packing a cheap suitcase, as most students quickly learn - it holds its new load for a while, then most everything falls out….When the neural suitcase is packed carefully and gradually, it holds its contents for far, far longer. An hour of study tonight, an hour on the weekend, another session a week from now: such so-called spacing improves later recall, without requiring students to put in more overall study effort or pay more attention, dozens of studies have found.&lt;/p&gt;&lt;p&gt;“The idea is that forgetting is the friend of learning”, said Dr. Kornell. “When you forget something, it allows you to relearn, and do so effectively, the next time you see it.”&lt;/p&gt;&lt;p&gt;That’s one reason cognitive scientists see testing itself - or practice tests and quizzes - as a powerful tool of learning, rather than merely assessment. The process of retrieving an idea is not like pulling a book from a shelf; it seems to fundamentally alter the way the information is subsequently stored, making it far more accessible in the future.&lt;/p&gt;&lt;p&gt;In one of his own experiments, Dr. Roediger and Jeffrey Karpicke, who is now at Purdue University, had college students study science passages from a reading comprehension test, in short study periods. When students studied the same material twice, in back-to-back sessions, they did very well on a test given immediately afterward, then began to forget the material. But if they studied the passage just once and did a practice test in the second session, they did very well on one test two days later, and another given a week later.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The Mathematics of Gambling, 1984, §2 “The Wheels”, Chapter 4, pg43–44:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;It was the spring of 195570ya. I was finishing my second year of graduate physics at U.C.L.A…I changed my field of study from physics to mathematics…I attended classes and studied 50–60 hours a week, generally including Saturdays and Sundays. I had read about the psychology of learning in order to be able to work longer and harder. I found that “spaced learning” worked well: study for an hour, then take a break of at least ten minutes (shower, meal, tea, errands, etc.). One Sunday afternoon about 3 p.m., I came to the co-op dining room for a tea break…My head was bubbling with physics equations, and several of my good friends were sitting around chatting.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From Final Jeopardy: Man Versus Machine and the Quest to Know Everything, by Stephen Baker, pg214:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The program he put together tested him on categories, gauged his strengths (sciences, NFL football) and weaknesses (fashion, Broadway shows), and then directed him toward the preparation most likely to pay off in his own match. To patch these holes in his knowledge, Craig used a free online tool called Anki, which provides electronic flash cards for hundreds of fields of study, from Japanese vocabulary to European monarchs. The program, in Craig’s words, is based on psychological research on ‘the forgetting curve’. It helps people find holes in their knowledge and determines how often they need those areas to be reviewed to keep them in mind. In going over world capitals, for example, the system learns quickly that a user like Craig knows London, Paris, and Rome, so it might spend more time reinforcing the capital of, say, Kazakhstan. (And what would be the Kazakh capital? ‘Astana’, Craig said in a flash. ‘It used to be Almaty, but they moved it.’)&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;“Our Interview With Jeopardy! Champion Arthur Chu”:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;[Chu:] …Jeopardy! is aimed at the sort of average TV viewer, so they’re not going to ask things that are pointlessly obscure…So I used a program called Anki which uses a method called “spaced repetition.” It keeps track of where you’re doing well or poorly, and pushes you to study the flashcards you don’t know as well, until you develop an even knowledge base about a particular subject, and I just made flashcards for those specific things. I memorized all the world capitals, it wasn’t that hard once I had the flashcards and was using them every day. I memorized the US State Nicknames (they’re on Wikipedia), memorized the basic important facts about the 44 US Presidents. I really focused on those. But there’s a lot more stuff to know. I went on Jeopardy! knowing that there was stuff I didn’t know. For instance, everyone laughs about sports - but I also knew that [sports clues] were the least likely to come up in Double Jeopardy and Final Jeopardy and be very important. So I decided I shouldn’t sweat it too much, I should just recognize that I didn’t know them and let that go, as long as I can get the high value clues. So that was how I prepared.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Alan J. Perlis, “Epigrams in Programming” (198243ya)↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Web developer Persol writes in August 2012:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;I actually wrote a site that did this [spaced repetition] a few months ago. I had about 4000 users who had actually gone through a complete session…As guessed, the problem is that I couldn’t get people to start forming it as a habit. There is no immediate payback. Less than 20 people out of 4000 did more than one session…Additionally, there are at least 18 competitors. Here’s the list I made at the time. Very few seem to be successful. I shut the site down about a month ago. There are numerous free competitors which don’t have any great annoyances. I wouldn’t suggest starting another of these sites unless you figured out an effective way to “gamify” it.&lt;/p&gt;&lt;p&gt;…~4000 people finished a session. Many more ‘tried’ than 4000…I just couldn’t determine which users were bots that registered randomly vs users that didn’t finish the first session.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Tried: lots (but unknown)&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Finished 1 session: ~4000&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Finished &amp;gt;1 session: ~20 [0.5%]&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;“Play it Again: The Master Psychopharmacology Program as an Example of Interval Learning in Bite-Sized Portions”, et al 2010:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Since Ebbinghaus’ time, a voluminous amount of research has confirmed this simple but important fact: the retention of new information degrades rapidly unless it is reviewed in some manner. A modern example of this loss of knowledge without repetition is a study of cardiopulmonary resuscitation (CPR) skills that demonstrated rapid decay in the year following training. By 3 years post-training only 2.4% were able to perform CPR successfully.6 Another recent study of physicians taking a tutorial they rated as very good or excellent showed mean knowledge scores increasing from 50% before the tutorial to 76% immediately afterward.7 However, score gains were only half as great 3-8 days later and incredibly, there was no [statistically-]significant knowledge retention measurable at all at 55 days.7 Similar results have been reported by us in follow-up studies of knowledge retention from continuing medical education programs.1 [Stahl SM, Davis RL. Best Practices for Medical Educators. Carlsbad, CA: NEI Press; 200916ya]&lt;/p&gt;&lt;p&gt;…This may be due to the fact that lectures with assigned reading are the easiest for teachers. Also, medical learning is rarely measured immediately after a lecture or after reading new material for the first time and then measured again a few days or weeks later, so that the low retention rates of this approach may not be widely appreciated.1,4 No wonder formal medical education conferences without enabling or practice-reinforcing strategies appear to have relatively little impact on practice and healthcare outcomes.8,9,10&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One study looking at cramming is the 199332ya “Cramming: A barrier to student success, a way to beat the system or an effective learning strategy?”, et al 1993, abstract:&lt;/p&gt;
        &lt;p&gt;Tested the hypothesis that cramming is an ineffective study strategy by examining the weekly study diaries of 166 undergraduates. All subjects also completed an end-of-semester questionnaire measuring study habits. subjects were classified in the following study patterns: ideal, confident, zealous, or crammer. Contrary to the hypothesis, results suggest that cramming is an effective approach, most widespread in courses using take-home essay examinations and major research papers. Crammers’ grades were as good as or better than those of subjects using other strategies; the longer subjects were in college, the more likely it was that they crammed. Crammers studied more hours than most students and were as interested in their courses as other students.&lt;/p&gt;
        &lt;p&gt;Note that there is no measure of long-term retention, suggesting that people who only care about grades are rationally choosing to cram.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Anki has its Cram Mode and Mnemosyne 2.0 has a cramming plugin. When a SRS doesn’t have explicit support, it’s always possible to ‘game’ the algorithm by setting one’s scores artificially low, so the SR algorithm thinks you are stupid and need to do a lot of repetitions.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;“Examining the examiners: Why are we so bad at assessing students?”, 2002:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Conway, 1992 looked at long term memory for the information presented on a psychology course. They found that some types of information, especially that relating to research methods, were remembered better than others. But in a follow up analysis, they found that the type of assessment used had an effect on memory. In essence, material assessed by continuous assessment was more likely to be remembered than information assessed by exams.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;2010:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;For example, simple restudying allows the learner to reexperience all of the material but actually produces poor long-term retention.25,26,35 Why do students keep studying the original materials? Certainly if this is their only choice, then restudying is a necessary tactic. Another answer may be that repeated studying falsely inflates students’ confidence in their ability to remember in the future because they sense that they understand it now, and they and their instructors may be unaware of the many studies that show poor retention on delayed testing after this form of repetition.25,26,35&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From et al 2010:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Contrary to the massing-aids-induction hypothesis, final test performance was consistently and considerably superior in the spaced condition. A large majority of participants, however, judged massing to be more effective than spacing, despite making the judgment after taking the test.&lt;/p&gt;&lt;p&gt;…Metacognitive judgments-that is, judgments about one’s own memory and cognition-are often based on feelings of fluency(eg. see Benjamin, Bjork, &amp;amp; Schwartz, 1998; Rhodes &amp;amp; Castel, 2008). Because massing naturally leads to feelings of fluency and increases short-term task performance during learning, learners frequently rate spacing as less effective than massing, even when their performance shows the opposite pattern (1978; Kornell &amp;amp; Bjork, 200817ya; Simon &amp;amp; Bjork, 200124ya; Zechmeister &amp;amp; Shaughnessy, 198045ya). Averaged across Kornell and Bjork’s (200817ya) experiments, for example, more than 80% of participants rated massing as equally or more effective than spacing, whereas only 15% of participants actually performed better in the massed condition than in the spaced condition.&lt;/p&gt;&lt;p&gt;…Such an illusion was apparent in the induction condition. Contrary to previous research, however, participants gave higher ratings for spacing than massing during repetition learning (see, eg. Simon &amp;amp; Bjork, 200124ya; Zechmeister &amp;amp; Shaughnessy, 198045ya). This outcome may have occurred because of a process of a habituation: Six presentations and a total of 30 s spent studying a single painting may have come to seem inefficient and pointless. Thus, there appears to be a turning point in metacognitive ratings based on fluency: As fluency increases, metacognitive ratings increase up to a point, but as fluency continues to increase and encoding or retrieval becomes too easy, metacognitive ratings may begin to decrease.&lt;/p&gt;&lt;p&gt;…In advance of their research, 2008 were convinced that such inductive learning would benefit from massing, yet their results showed the opposite. Undaunted, we remained convinced that spacing would be more beneficial for repetition learning than for inductive learning- especially for older adults, given their overall declines in episodic memory. The current results disconfirmed our expectations once again. If our intuitions are erroneous, despite our years spent proving and praising the spacing effect-including roughly 40 years’ worth contributed by Robert A. Bjork-those of the average student are surely mistaken as well (as the inaccuracy of the participants’ metacognitive ratings suggests). We have, perhaps, fallen victim to the illusion that making learning easy makes learning effective, rather than recognizing that spacing is a desirable difficulty (1994) that enhances inductive learning as well as repetition learning well into old age.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From 2012:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Thus, while spacing may boost learning, it may be thought to be relatively inefficient in terms of study time. As we discuss later, this feeling of inefficiency may be one of the reasons that spacing is not the more popular strategy. Interestingly, in that same study (1978; and see also 1985 and 1954 [Experimental Psychology]), there was evidence of such a thing as laboring in vain. That is, exceeding a certain number of hours of practice a day (more than approximately 2h) led to no increases in learning, as might be expected. Related to the deficient-processing theory mentioned above, these results are crucial in understanding intuitively how the spacing effect works: We simply get burnt out. These data are also analogous to the cognitive literature on overlearning, which shows that while continuous study over long periods of time might seem beneficial (and even feel good) in the short-term, the benefits disappear soon afterwards ( et al 2005; 2006)…In the above-described 1978’s study, for example, after postal workers practiced typing in either massed or spaced study sessions, they had to indicate how satisfied they were with the training. Results showed that while spacing led to the best learning, it was the least liked. Similarly, 2001 found that people preferred the massing strategy on a motor learning task.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Baddeley, A. D., &amp;amp; Longman, D. J. A. (197847ya). “The influence of length and frequency of training session on the rate of learning to type”. Ergonomics, 21, 627-635&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Pirolli, P., &amp;amp; Anderson, J. R. (198540ya). “The role of practice in fact retrieval”&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;“Study strategies of college students: Are self-testing and scheduling related to achievement?”, 2012:&lt;/p&gt;&lt;p&gt;Previous studies, such as those by Kornell and Bjork (Psychonomic Bulletin &amp;amp; Review, 14:219-224, 200718ya) and Karpicke, Butler, and Roediger (Memory, 17:471-479, 200916ya), have surveyed college students’ use of various study strategies, including self-testing and rereading. These studies have documented that some students do use self-testing (but largely for monitoring memory) and rereading, but the researchers did not assess whether individual differences in strategy use were related to student achievement. Thus, we surveyed 324 undergraduates about their study habits as well as their college grade point average (GPA). Importantly, the survey included questions about self-testing, scheduling one’s study, and a checklist of strategies commonly used by students or recommended by cognitive research. Use of self-testing and rereading were both positively associated with GPA. Scheduling of study time was also an important factor: Low performers were more likely to engage in late-night studying than were high performers; massing (versus spacing) of study was associated with the use of fewer study strategies overall; and all students-but especially low performers-were driven by impending deadlines. Thus, self-testing, rereading, and scheduling of study play important roles in real-world student achievement.&lt;/p&gt;&lt;p&gt;(See also et al 2013.) Note the self-testing correlation excludes flashcards, a result that both the authors and me found surprising. The sleep connection is interesting, given the hypothesized link between stronger memory formation &amp;amp; studying before a good night’s sleep - you can hardly get a good night’s sleep if you are cramming late into the night (correlated with lower grades) but you can if you do so at a reasonable time in the evening (in time to get a solid night).&lt;/p&gt;&lt;p&gt;See also Susser &amp;amp; 2012:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Laboratory studies have demonstrated the long-term memory benefits of studying material in multiple distributed sessions as opposed to one massed session, given an identical amount of overall study time (ie. the spacing effect). The current study goes beyond the laboratory to investigate whether undergraduates know about the advantage of spaced study, to what extent they use it in their own studying, and what factors might influence its utilization. Results from a web-based survey indicated that participants (n = 285) were aware of the benefits of spaced study and would use a higher level of spacing under ideal compared to realistic circumstances. However, self-reported use of spacing was intermediate, similar to massing and several other study strategies, and ranked well below commonly used strategies such as rereading notes. Several factors were endorsed as important in the decision to distribute study time, including the perceived difficulty of an upcoming exam, the amount of material to learn, how heavily an exam is weighed in the course grade, and the value of the material. Further, level of metacognitive self-regulation and use of elaboration strategies were associated with higher rates of spaced study.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Analytic Culture in the US Intelligence Community: An Ethnographic Study, 2005, pg89:&lt;/p&gt;
        &lt;p&gt;To investigate the intensity of instructional interactions, Art Graesser and Natalie 1994 compared questioning and answering in classrooms with those in tutorial settings.5 They found that classroom groups of students ask about three questions an hour and that any single student in a classroom asks about 0.11 questions per hour. In contrast, they found that students in individual tutorial sessions asked 20-30 questions an hour and were required to answer 117-146 questions per hour. Reviews of the intensity of interaction that occurs in technology-based instruction have found even more active student response levels. [J. D. Fletcher, Technology, the Columbus Effect, and the Third Revolution in Learning.]&lt;/p&gt;
        &lt;p&gt;Although 1994 also found that sheer number of questions was not necessarily important, suggesting diminishing marginal returns or perhaps bad question asking.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“SuperMemo is based on the insight that there is an ideal moment to practice what you’ve learned. Practice too soon and you waste your time. Practice too late and you’ve forgotten the material and have to relearn it. The right time to practice is just at the moment you’re about to forget. Unfortunately, this moment is different for every person and each bit of information. Imagine a pile of thousands of flash cards. Somewhere in this pile are the ones you should be practicing right now. Which are they?” Gary Wolf, “Want to Remember Everything You’ll Ever Learn? Surrender to This Algorithm”, Wired Magazine↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Make no mistake about it: Computers process numbers - not symbols. We measure our understanding (and control) by the extent to which we can arithmetize an activity.” Perlis, ibid.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;this exponential expansion is how a SR program can handle continual input of cards: if cards were scheduled at fixed intervals, like every other day, review would soon become quite impossible - I have &amp;gt;18000 items in Mnemosyne, but I don’t have time to review 9000 questions a day!↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;See the 200817ya meta-analysis, “Learning Styles: Concepts and Evidence” (APS press release); from the abstract:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;…in order to demonstrate that optimal learning requires that students receive instruction tailored to their putative learning style, the experiment must reveal a specific type of interaction between learning style and instructional method: Students with one learning style achieve the best educational outcome when given an instructional method that differs from the instructional method producing the best outcome for students with a different learning style. In other words, the instructional method that proves most effective for students with one learning style is not the most effective method for students with a different learning style.&lt;/p&gt;&lt;p&gt;Our review of the literature disclosed ample evidence that children and adults will, if asked, express preferences about how they prefer information to be presented to them. There is also plentiful evidence arguing that people differ in the degree to which they have some fairly specific aptitudes for different kinds of thinking and for processing different types of information. However, we found virtually no evidence for the interaction pattern mentioned above, which was judged to be a precondition for validating the educational applications of learning styles. Although the literature on learning styles is enormous, very few studies have even used an experimental methodology capable of testing the validity of learning styles applied to education. Moreover, of those that did use an appropriate method, several found results that flatly contradict the popular meshing hypothesis.&lt;/p&gt;&lt;p&gt;We conclude therefore, that at present, there is no adequate evidence base to justify incorporating learning-styles assessments into general educational practice. Thus, limited education resources would better be devoted to adopting other educational practices that have a strong evidence base, of which there are an increasing number. However, given the lack of methodologically sound studies of learning styles, it would be an error to conclude that all possible versions of learning styles have been tested and found wanting; many have simply not been tested at all.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fritz, C. O., Morris, P. E., Acton, M., Etkind, R., &amp;amp; Voelkel, A. R (200718ya). “Comparing and combining expanding retrieval practice and the keyword mnemonic for foreign vocabulary learning”. Applied Cognitive Psychology, 21, 499-526.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From et al 2007, describing 1939, “Studies in retention”:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Spitzer (193986ya) incorporated a form of expanded retrieval in a study designed to assess the ability of sixth graders to learn science facts. Impressively, Spitzer tested over 3600 students in Iowa-the entire sixth-grade population of 91 elementary schools at the time. The students read two articles, one on peanuts and the other on bamboo, and were given a 25-item multiple choice test to assess their knowledge (such as ‘To which family of plants does bamboo belong?’). Spitzer tested a total of nine groups, manipulating both the timing of the test (administered immediately or after various delays) and the number of identical tests students received (one to three). Spitzer did not incorporate massed or equal interval retrieval conditions, but he had at least two groups that were tested on an expanding schedule of retrieval, in which the intervals between tests were separated by the passage of time (in days) rather than by intervening to-be-learned information. For example, in one of the groups, the first test was given immediately, the second test was given seven days after the first test, and the third test was given 63 days after the second test. Thus, in essence, this group was tested on a 0-7-63 day expanding retrieval schedule. Spitzer compared performance of the expanded retrieval group to a group given a single test 63 days after reading the original article. On the first (immediate) test, the expanded retrieval group correctly answered 53% of the questions. After 63 days and two previous tests, their score was still an impressive 43%. The single test group correctly answered only 25% of the original items after 63 days, giving the expanded retrieval group an 18% retention advantage. This is quite impressive, given that this large benefit remained after a 63-day retention interval. Similar beneficial effects were found in a group tested on a 0-1-21 day expanded retrieval schedule compared to a group given a single test after 21 days. Of course, this study does not decouple the effects of testing from spacing or expansion, but the results do clearly indicate considerable learning and retention using the expanded repeated testing procedure. Spitzer concluded that ‘…examinations are learning devices and should not be considered only as tools for measuring achievement of pupils’ (p. 656, italics added)&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;quote/&gt;↩︎&lt;p&gt;The spacing effect describes the robust finding that long-term learning is promoted when learning events are spaced out in time, rather than presented in immediate succession. Studies of the spacing effect have focused on memory processes rather than for other types of learning, such as the acquisition and generalization of new concepts. In this study, early elementary school children (5-7 year-olds; N = 36) were presented with science lessons on one of three schedules: massed, clumped, and spaced. The results revealed that spacing lessons out in time resulted in higher generalization performance for both simple and complex concepts. Spaced learning schedules promote several types of learning, strengthening the implications of the spacing effect for educational practices and curriculum.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See also 2006, who compared spacing &amp;amp; massed in an introductory psychology course as well.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2006b again.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;et al 2007 review:&lt;/p&gt;&lt;p&gt;No feedback or correction was given to subjects if they made errors or omitted answers. 1978 found that the expanding-interval schedule produced better recall than equal-interval testing on a final test at the end of the session, and equal-interval testing, in turn, produced better recall than did initial massed testing. Thus, despite the fact that massed testing produced nearly errorless performance during the acquisition phase, the other two schedules produced better retention on the final test given at the end of the session. However, the difference favoring the expanding retrieval schedule over the equal-interval schedule was fairly small at around 10%. In research following up Landauer and Bjork’s (197847ya) original experiments, practically all studies have found that spaced schedules of retrieval (whether equal-interval or expanding schedules) produce better retention on a final test given later than do massed retrieval tests given immediately after presentation (eg. Cull, 200025ya; Cull, Shaughnessy, &amp;amp; Zechmeister, 199629ya), although exceptions do exist. For example, in Experiments 3 and 4 of et al 1996, massed testing produced performance as good as equal-interval testing on a 5-5-5 schedule, but most other experiments have found that any spaced schedule of testing (either equal-interval or expanding) is better than a massed schedule for performance on a delayed test. However, whether expanding schedules are better than equal-interval schedules for long-term retention-the other part of Landauer and Bjork’s interesting findings-remains an open question. Balota, Duchek, and Logan (in press) have provided a thorough consideration of the relevant evidence and have shown that it is mixed at best, and that most researchers have found no difference between the two schedules of testing. That is, performance on a final test at the end of a session often shows no difference in performance between equal-interval and expanding retrieval schedules.&lt;/p&gt;&lt;p&gt;Cull, for those curious (Cull, W. L. (200025ya). “Untangling the benefits of multiple study opportunities and repeated testing for cued recall”. Applied Cognitive Psychology, 14, 215-235):&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Cull (200025ya) compared expanded retrieval to equal interval spaced retrieval in a series of four experiments designed to mimic typical teaching or study strategies encountered by students. He examined the role of testing versus simply restudying the material, feedback, and various retention intervals on final test performance. Paired associates (an uncommon word paired with a common word, such as bairn-print) were presented in a manner similar to the flashcard techniques students often use to learn vocabulary words. The intervals between retrieval attempts of to-be-learned information ranged from minutes in some experiments to days in others. Interestingly, across four experiments, Cull did not find any evidence of an advantage of an expanded condition over a uniform spaced condition (ie. no [substantial] expanded retrieval effect), although both conditions consistently produced large advantages over massed presentations. He concluded that distributed testing of any kind, expanded or equal interval, can be an effective learning aid for teachers to provide for their students.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The et al 2007 review offers a synthesis of current theories on how massed and spaced differ, based on memory encoding:&lt;/p&gt;&lt;p&gt;According to encoding variability theory, performance on a memory test is dependent upon the overlap between the contextual information available at the time of test and the contextual information available during encoding. During massed study, there is relatively little time for contextual elements to fluctuate between presentations and so this condition produces the highest performance in an immediate memory test, when the test context strongly overlaps with the same contextual information encoded during both of the massed presentations. In contrast, when there is spacing between the items, there is time for fluctuation to take place between the presentations during study, and hence there is an increased likelihood of having multiple unique contexts encoded. Because a delayed test will also allow fluctuation of context, it is better to have multiple unique contexts encoded, as in the spaced presentation format, as opposed to a single encoded context, as in the massed presentation format.&lt;/p&gt;&lt;p&gt;et al 2010 did 3 experiments on reading comprehension:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;On a test 1 week later, recall was enhanced by the expanding schedule, but only when the task between successive retrievals was highly interfering with memory for the passage. These results suggest that the extent to which learners benefit from expanding retrieval practice depends on the degree to which the to-be-learned information is vulnerable to forgetting.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From Mnemosyne’s Principles page:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The Mnemosyne algorithm is very similar to SM2 used in one of the early versions of SuperMemo. There are some modifications that deal with early and late repetitions, and also to add a small, healthy dose of randomness to the intervals. Supermemo now uses SM11. However, we are a bit skeptical that the huge complexity of the newer SM algorithms provides for a statistically relevant benefit. But, that is one of the facts we hope to find out with our data collection. We will only make modifications to our algorithms based on common sense or if the data tells us that there is a statistically relevant reason to do so.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;et al 2007:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Carpenter and DeLosh (200520ya, Exp. 2) have recently investigated face-name learning under massed, expanded (1-3-5), and equal interval (3-3-3) conditions. This study also involved study and study and test procedures during the acquisition phase. Carpenter and DeLosh found a large effect of spacing, but no evidence of a benefit of expanded over equal interval practice. In fact, Carpenter and DeLosh reported a reliable benefit of the equal interval condition over the expanded retrieval condition.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;et al 2007 again:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;1985 tested the effectiveness of expanded retrieval in a third-grade classroom setting. In separate conditions, students were given new multiplication problems or spelling words to learn. The problem or word was presented audiovisually once and then tested on either a massed retrieval schedule of 0-0-0-0 or an expanding schedule of 0-1-2-4, in which the intervals involved being tested on old items or learning new items. After each test trial for a given item, the item was re-presented in its entirety so students received feedback on what they were learning. Performance during the learning phase was at 100% for both spelling words and multiplication facts. On an immediate final retention test, Rea and Modigliani found a performance advantage for all items-math and spelling- practiced on an expanding schedule compared to the massed retrieval schedule. They suggested, as have others, that spacing combined with the high success rate inherent in the expanded retrieval schedule produced better retention than massed retrieval practice. However, as in Spitzer’s study, Rea and Modigliani did not test an appropriate equal interval spacing condition. Hence, their finding that expanded retrieval is superior to massed retrieval in third graders could simply reflect the superiority of spaced versus massed rehearsal-in other words, the spacing effect.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;et al 2007; &amp;gt;1 is rare in psychology, see “One Hundred Years of Social Psychology Quantitatively Described”, et al 2003↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2006↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;et al 2007:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;…long-term retention of information has been demonstrated over several days in some cases (eg. Camp et al, 199629ya). For example, in the latter study, Camp et al employed an expanding retrieval strategy to train 23 individuals with mild to moderate AD to refer to a daily calendar as a cue to remember to perform various personal activities (eg. take medication). Following a baseline phase to determine whether subjects would spontaneously use the calendar, spaced retrieval training was implemented by repeatedly asking the subject the question, ‘How are you going to remember what to do each day?’ at expanding time intervals. The results indicated that 20/23 subjects did learn the strategy (ie. to look at the calendar) and retained it over a 1-week period.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;2006 warns us, though, about many of the other math studies:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;In one meta-analysis by 1999, for instance, the size of the spacing effect declined sharply as conceptual difficulty of the task increased from low (eg. rotary pursuit) to average (eg. word list recall) to high (eg. puzzle). By this finding, the benefits of spaced practise may be muted for many mathematics tasks.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;What is especially nice about this study was that not only did it use high-quality (intelligent &amp;amp; motivated) college students (United States Air Force Academy), the conditions were relatively controlled - both groups had the same homework (so equal testing effect), but like 2006/2007, the distribution was what varied:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The course topics, textbook, handouts, reading assignments, and graded assignments (with the exception of quiz, homework, and participation points) were identical for the treatment and control groups. The listing of homework assignments in the syllabus differed between groups. The control group was assigned daily homework related to the topic(s) presented that day in class. Peterson (197154ya) calls this the vertical model for assigning mathematics homework. The treatment group was assigned homework in accordance with a distributed organizational pattern that combines practice on current topics and reinforcement of previously covered topics. Under the distributed model, approximately 40% of the problems on a given topic were assigned the day the topic was first introduced, with an additional 20% assigned on the next lesson and the remaining 40% of problems on the topic assigned on subsequent lessons (Hirsch et al, 198342ya). In Hirsch’s research and in this study, after the initial homework assignment, problem(s) representing a given topic resurfaced on the 2nd, 4th, 7th, 12th, and 21st lesson. Consequently, treatment group homework for lesson one consisted of only one topic; homework for lessons two and three consisted of two topics; and homework for lesson four through six consisted of three topics. This pattern continued as new topics were added and was applied to all non-exam, non-laboratory lessons. As shown by Tables 1 and 2, the same homework problems were assigned to both groups with only the pattern of assignment differing. Because of the nature of the distributed practice model, homework for the treatment group contained fewer problems (relative to the control group) early in the semester with the number of problems increasing as the semester progressed. Later in the semester, homework for the treatment group contained more problems (relative to the control group)….The USAFA routinely collects study time data. After each exam, a large sample of cadets (at least 60% of the course population) anonymously reported the amount of time (in minutes) spent studying for the exam. Time spent studying was approximately equal for both groups (see Table 5). Descriptive data revels that, for both the treatment and control group, study time for the third exam was at least 16% greater than study time for any other exam. Study time for the final exam was at least 68% greater than study time for any of the hourly exams (see Table 5)&lt;/p&gt;&lt;p&gt;…The treatment produced an effect size (f 2) of 0.013 on the first exam, 0.029 on the second exam, 0.035 on the fourth exam, and 0.040 on the final course percentage grade. Although the effect sizes appear to be small, the treatment group outscored the control group in every case. A mean difference of 5.13 percentage points on the first, second, and fourth exam translates to an advantage of about a third of a letter grade for students in the treatment group. In addition, higher minimum scores earned by the treatment group may indicate that the distributed practice treatment served to eliminate the extremely low scores (refer to Table 3)….Oddly, the distributed practice treatment did not produce a [statistically-]significant effect on final exam scores. One possible cause for the disparity was the USAFA policy exempting the top performers from the final exam. Of the 16 exempted students, 11 were from the treatment group with only 5 from the control group.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;2006 abstract:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Two introductory psychology classes (N = 145) participated in a counterbalanced classroom experiment that demonstrated the spacing effect and, by analogy, the benefits of distributed study. After hearing words presented twice in either a massed or distributed manner, participants recalled the words and scored their recall protocols, reliably remembering more distributed than massed words. Posttest scores on a multiple-choice quiz covering points illustrated by the experiment averaged about twice the comparable pretest scores, indicating the effectiveness of the exercise in conveying content. Students’ subjective ratings suggested that the experiment helped convince them of the benefits of distributed study.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See et al 2006↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Commins, S., Cunningham, L., Harvey, D., and Walsh, D. (200322ya). “Massed but not spaced training impairs spatial memory”. Behavioural Brain Research 139, 215-223↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Galluccio &amp;amp; Rovee-2006, “Nonuniform effects of reinstatement within the time window”. Learning and Motivation, 37, 1-17.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;See the previous sections for many using children; one previously uncited is 1993, “The spacing effect in preschool children’s free recall of pictures and words”; but et al 2009 adds some interesting qualifiers to spaced repetition in the young:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;Preschoolers, elementary school children, and college students exhibited a spacing effect in the free recall of pictures when learning was intentional. When learning was incidental and a shallow processing task requiring little semantic processing was used during list presentation, young adults still exhibited a spacing effect, but children consistently failed to do so. Children, however, did manifest a spacing effect in incidental learning when an elaborate semantic processing task was used.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Another previously uncited study: Glenberg, A. M. (197946ya), “Component-levels theory of the effects of spacing of repetitions on recall and recognition”. Memory &amp;amp; Cognition, 7, 95-112.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See et al 2010; et al 2012 shows the spacing benefits but reduced in magnitude in its 56-74 year old subjects, similar to et al 2012 and 2013↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mammarella, N., Russo, R., &amp;amp; Avons, S. E. (200223ya). ”Spacing effects in cued-memory tasks for unfamiliar faces and nonwords”. Memory &amp;amp; Cognition, 30, 1238–1251↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Childers, J. B., &amp;amp; Tomasello, M. (200223ya). ”Two-year-olds learn novel nouns, verbs, and conventional actions from massed or distributed exposures”. Developmental Psychology, 38, 967-978↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;eg. et al 1968↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The famous ‘10,000 hours of practice’ figure may not be as true or important as Ericsson and publicizers like Malcolm Gladwell imply, given the high variance of expertise against time, and results from sports showing smaller time investments (see also Hambrick’s corpus cutting ‘deliberate practice’ down to size), and Ericsson absurdly deny the powerful role of genetics and the necessary condition of having talent but the insight of ‘deliberate practice’ helping talented people probably is real. One may be able to get away with 3,000 hours rather than 10,000, but one isn’t going to do that with mindless repetition or no repetitions.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gentner, D., Loewenstein, J., &amp;amp; Thompson, L. (200322ya). “Learning and transfer: A general role for analogical encoding”. Journal of Educational Psychology, 95, 393-40↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;From et al 2010:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The benefits of spacing seem to diminish or disappear when to-be-learned items are not repeated exactly (Appleton-Knapp, Bjork, &amp;amp; Wickens, 2005)…a number of studies have shown that massing, rather than spacing, promotes inductive learning. These studies have generally employed relatively simple perceptual stimuli that facilitate experimental control (Gagné, 1950; Goldstone, 1996; Kurtz &amp;amp; Hovland, 1956; [Whitman J. R., &amp;amp; Garner, W. R. (196362ya). “Concept learning as a function of the form of internal structure”. Journal of Verbal Learning &amp;amp; Verbal Behavior, 2, 195-202]).&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;High error rates - indicating one didn’t actually learn the card contents in the first place - seem to be connected to failures of the spacing effect; there’s some evidence that people naturally choose to mass study when they don’t yet know the material.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The 20 years look like this (note the scientific notation):&lt;/p&gt;&lt;code&gt;[0.742675, 0.27044575182838654, 0.15275979054767388, 0.10348750000000001, 7.751290630254386e-2, 6.187922936397532e-2, 5.161829250474865e-2, 4.445884397854832e-2, 3.923055555555555e-2, 3.5275438307530015e-2, 3.219809429218694e-2, 2.9748098818459235e-2, 2.7759942051635768e-2, 2.6120309801216147e-2, 2.474928593068675e-2, 2.35890625e-2, 2.2596898475825956e-2, 2.1740583401051353e-2, 2.0995431241707652e-2, 2.0342238287817983e-2]&lt;/code&gt;↩︎&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;modulo things where knowing it is useful even if you don’t need it often - it can be a brick in a pyramid of knowledge; cf. page 3 of Wolf:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The problem of forgetting might not torment us so much if we could only convince ourselves that remembering isn’t important. Perhaps the things we learn - words, dates, formulas, historical and biographical details - don’t really matter. Facts can be looked up. That’s what the Internet is for. When it comes to learning, what really matters is how things fit together. We master the stories, the schemas, the frameworks, the paradigms; we rehearse the lingo; we swim in the episteme.&lt;/p&gt;&lt;p&gt;The disadvantage of this comforting notion is that it’s false. “The people who criticize memorization - how happy would they be to spell out every letter of every word they read?” asks Robert Bjork, chair of UCLA’s psychology department and one of the most eminent memory researchers. After all, Bjork notes, children learn to read whole words through intense practice, and every time we enter a new field we become children again. “You can’t escape memorization,” he says. “There is an initial process of learning the names of things. That’s a stage we all go through. It’s all the more important to go through it rapidly.” The human brain is a marvel of associative processing, but in order to make associations, data must be loaded into memory.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See Stephen R. Schmidt’s webpage “Theories of Forgetting”, which cites ‘Woodworth &amp;amp; Schlosbeg (196164ya)’ when presenting a log graph of various studies’ forgetting curves.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;which neatly addresses the issue of such mailing lists being useless (‘who learns a word after just one exposure?’).↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mnemosyne in this case constitutes both a way to learn the quotes so I can use them, and a waste book; just the other day I had 3 or 4 apposite quotes for an essay because I had entered them into Mnemosyne months or years ago.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It’s well known that any speaker of a language understands many more words than they will ever use or be able to explicitly generate, that their “reading vocabulary” exceeds their “writing vocabulary”; less well-known is that on many problems, one can guess at well above random rates even while feeling unsure &amp;amp; ignorant, necessitating psychologists to employ forced-choice paradigms to reveal such “dark knowledge”. Even less known is the capacity of recognition memory or “implicit memory” (cf. McCollough effect); this memory can apply to things like recognizing images or text or music, typing, puzzle solving, etc. Andrew Drucker, in “Multiplying 10-digit numbers using Flickr: The power of recognition memory”, employs visual memory to calculate 9,883,603,368 × 4,288,997,768 = 42,390,752,785,149,282,624; he cites as precedent 1973:&lt;/p&gt;
        &lt;p&gt;In one of the most widely-cited studies on recognition memory, Standing showed participants an epic 10,000 photographs over the course of 5 days, with 5 seconds’ exposure per image. He then tested their familiarity, essentially as described above. The participants showed an 83% success rate, suggesting that they had become familiar with about 6,600 images during their ordeal. Other volunteers, trained on a smaller collection of 1,000 images selected for vividness, had a 94% success rate.&lt;/p&gt;
        &lt;p&gt;One sometimes sees people argue that something is insecure or unguessable or free from possible placebo effect because it involves too many objects to explicitly memorize, but as these examples make clear, recognition memory can happen quickly and store surprisingly large amounts of information. This could be used for authentication (see for example et al 2012; HN discussion) or message since recognition memory could be exploited as a sort of secure communication system. Two parties can share a set of 20,000 photographs (10,000 pairs); to send a message, have a messenger spend 5 days on 10,000 picked ones; and then to receive it, ask him to recognize which photograph he saw in each of the 10,000 pairs. The subject not only does not know what the binary message is or what means, he can’t even produce it since he cannot remember the photographs!&lt;/p&gt;
        &lt;p&gt;At an 80% accuracy rate, we can even calculate how many bits of information can be entrusted to the messenger using Shannon’s theorem; a calculation gives 5.8 kilobits as the upper limit: if p = 0.2 (based on the 80% success rate), then 10000 / (1 − (p × log2 p + (1 − p) × (log2 (1 − p)))) = 5,807.44. (This message can, of course, be encrypted.)&lt;/p&gt;
        &lt;p&gt;So we see that Frank Herbert was right after all: the securest way to send a message is through a “distrans” messenger! (The downside is that the implicit recognition memory decays; see 1986 for adjusted estimates.)&lt;/p&gt;
        &lt;p&gt;This system is even more interesting because the learning happens unconsciously, without volition, so the subject does not need to cooperate nor even know about it (they could be exposed to key images without realizing it, such as through ‘advertising’). Further, recognition of an image also happens unconsciously, and can be observed by EEG ERPs &amp;amp; fMRI (and probably other neural correlates or modalities like eyetracking or skin galvanic response). Thus, messages can be stored &amp;amp; retrieved both unconsciously &amp;amp; involuntarily in brains!↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;In this vein, I am reminded of what a former polyphasic sleeper told me:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;I’ve been polyphasic for about a year. (Not anymore; kills my memory.)…Anki reps, mostly. I found that I could do proper review sessions for about 2–3 days and would hit an impenetrable wall. I couldn’t learn a single new card and had total brain fog until I got 3 hours more sleep. That, however, would reset my adaptation. The whole effect is a bit less pronounced on Everyman, but not much. It is however easier to add sleep when you already have a core. I didn’t notice any other major mental impairment after the initial sleep deprivation.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For a more recent review, see et al 2013.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Presumably one would immediately give them all some high grade like 5 to avoid suddenly having a daily load of 500 cards for a while.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smaller is better.↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“For Mnemosyne 2.x, Ullrich is working on an official Mnemosyne iPhone client which will have very easy syncing.”↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;See Page 4, 2008:&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;The spacing effect was one of the proudest lab-derived discoveries, and it was interesting precisely because it was not obvious, even to professional teachers. The same year that Neisser revolted, Robert Bjork, working with Thomas Landauer of Bell Labs, published the results of two experiments involving nearly 700 undergraduate students. Landauer and Bjork were looking for the optimal moment to rehearse something so that it would later be remembered. Their results were impressive: The best time to study something is at the moment you are about to forget it. And yet - as Neisser might have predicted - that insight was useless in the real world.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;When I first read of SuperMemo, I had already taken a class in cognitive psychology and was reasonably familiar with Ebbinghaus’s forgetting curve - so my reaction to its methodology was Huxley’s: “How extremely stupid not to have thought of that!”↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;See page 7, 2008&lt;/p&gt;&lt;quote/&gt;↩︎&lt;p&gt;And yet now, as I grin broadly and wave to the gawkers, it occurs to me that the cold rationality of his approach may be only a surface feature and that, when linked to genuine rewards, even the chilliest of systems can have a certain visceral appeal. By projecting the achievement of extreme memory back along the forgetting curve, by provably linking the distant future - when we will know so much - to the few minutes we devote to studying today, Wozniak has found a way to condition his temperament along with his memory. He is making the future noticeable. He is trying not just to learn many things but to warm the process of learning itself with a draft of utopian ecstasy.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gwern.net/spaced-repetition"/><published>2025-12-24T20:48:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379173</id><title>Keystone (YC S25) is hiring engineer #1 to automate coding</title><updated>2025-12-25T00:53:14.316431+00:00</updated><content>&lt;doc fingerprint="a3b096f07e6fa468"&gt;
  &lt;main&gt;
    &lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;
    &lt;p&gt;About Keystone&lt;/p&gt;
    &lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
    &lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
    &lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
    &lt;p&gt;About the Role&lt;/p&gt;
    &lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
    &lt;p&gt;Example projects:&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you:&lt;/p&gt;
    &lt;p&gt;Stack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
    &lt;p&gt;Comp &amp;amp; benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
    &lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer"/><published>2025-12-24T21:01:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379183</id><title>Nvidia buying AI chip startup Groq for about $20B in cash</title><updated>2025-12-25T00:53:14.044560+00:00</updated><content>&lt;doc fingerprint="22d081694f3ed1b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Nvidia has agreed to buy assets from Groq, a designer of high-performance artificial intelligence accelerator chips, for $20 billion in cash, according to Alex Davis, CEO of Disruptive, which led the startup's latest financing round in September.&lt;/p&gt;
    &lt;p&gt;Davis, whose firm has invested more than half a billion dollars in Groq since the company was founded in 2016, said the deal came together quickly. Groq raised $750 million at a valuation of about $6.9 billion three months ago. Investors in the round included Blackrock and Neuberger Berman, as well as Samsung, Cisco, Altimeter and 1789 Capital, where Donald Trump Jr. is a partner.&lt;/p&gt;
    &lt;p&gt;Groq said in a blog post on Wednesday that it's "entered into a non-exclusive licensing agreement with Nvidia for Groq's inference technology," without disclosing a price. With the deal, Groq founder and CEO Jonathan Ross along with Sunny Madra, the company's president, and other senior leaders "will join Nvidia to help advance and scale the licensed technology," the post said.&lt;/p&gt;
    &lt;p&gt;Groq added that it will continue as an "independent company," led by finance chief Simon Edwards as CEO.&lt;/p&gt;
    &lt;p&gt;Colette Kress, Nvidia's CFO, declined comment on the transaction.&lt;/p&gt;
    &lt;p&gt;Davis told CNBC that Nvidia is getting all of Groq's assets, though its nascent Groq cloud business is not part of the transaction. Groq said "GroqCloud will continue to operate without interruption."&lt;/p&gt;
    &lt;p&gt;The deal represents by far Nvidia's largest purchase ever. The chipmaker's biggest acquisition to date came in 2019, when it bought Israeli chip designer Mellanox for close to $7 billion. At the end of October, Nvidia had $60.6 billion in cash and short-term investments, up from $13.3 billion in early 2023.&lt;/p&gt;
    &lt;p&gt;In an email to employees that was obtained by CNBC, Nvidia CEO Jensen Huang said the agreement will expand Nvidia's capabilities.&lt;/p&gt;
    &lt;p&gt;"We plan to integrate Groq's low-latency processors into the NVIDIA AI factory architecture, extending the platform to serve an even broader range of AI inference and real-time workloads," Huang wrote.&lt;/p&gt;
    &lt;p&gt;Huang added that, "While we are adding talented employees to our ranks and licensing Groq's IP, we are not acquiring Groq as a company."&lt;/p&gt;
    &lt;p&gt;Nvidia orchestrated a similar but smaller deal in September, when it shelled out over $900 million to hire Enfabrica CEO Rochan Sankar and other employees at the AI hardware startup, and to license the company's technology, CNBC reported at the time.&lt;/p&gt;
    &lt;p&gt;Other tech giants, including Meta, Google and Microsoft, have spent heavily over the last couple years to hire top AI talent through various types of licensing deals.&lt;/p&gt;
    &lt;p&gt;Nvidia has ramped up its investments in chip startups and the broader ecosystem as its cash pile has mounted. The company has backed AI and energy infrastructure company Crusoe, AI model developer Cohere, and boosted its investment in CoreWeave as the AI-centric cloud provider was getting ready to go public this year.&lt;/p&gt;
    &lt;p&gt;In September, Nvidia said it intended to invest up to $100 billion in OpenAI, with the startup committed to deploying at least 10 gigawatts of Nvidia products. The companies have yet to announce a formal deal. That same month, Nvidia said it would invest $5 billion in Intel as part of a partnership.&lt;/p&gt;
    &lt;p&gt;Groq has been targeting revenue of $500 million this year amid booming demand for AI accelerator chips used in speeding up the process for large language models to complete inference-related tasks. The company was not pursuing a sale when it was approached by Nvidia, Davis said.&lt;/p&gt;
    &lt;p&gt;Groq was founded in 2016 by a group of former engineers, including Ross. He was one of the creators of Google's tensor processing unit, or TPU, the search giant's custom chip that's being used by some companies as an alternative to Nvidia's graphics processing units.&lt;/p&gt;
    &lt;p&gt;In its initial filing with the SEC, announcing a $10.3 million fundraising in late 2016, Groq listed as principals Ross and Douglas Wightman, an entrepreneur and former engineer at the Google X "moonshot factory." Wightman left Groq in 2019, according to his LinkedIn profile.&lt;/p&gt;
    &lt;p&gt;Groq isn't the only chip startup that's gained traction during the AI boom.&lt;/p&gt;
    &lt;p&gt;AI chipmaker Cerebras Systems had planned to go public this year but withdrew its IPO filing in October after announcing that it raised over $1 billion in a fundraising round.&lt;/p&gt;
    &lt;p&gt;In a filing with the SEC, Cerebras said it does not intend to conduct a proposed offering "at this time," but didn't provide a reason. A spokesperson told CNBC at the time that the company still hopes to go public as soon as possible.&lt;/p&gt;
    &lt;p&gt;Cerebras filed for an IPO in late 2024, as it was ramping up to take on Nvidia in an effort to create processors for running generative AI models.&lt;/p&gt;
    &lt;p&gt;— CNBC's Jordan Novet contributed to this report.&lt;/p&gt;
    &lt;p&gt;WATCH: How the massive power draw of generative AI is overtaxing our grid&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/12/24/nvidia-buying-ai-chip-startup-groq-for-about-20-billion-biggest-deal.html"/><published>2025-12-24T21:02:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379677</id><title>How I Left YouTube</title><updated>2025-12-25T00:53:13.834227+00:00</updated><content>&lt;doc fingerprint="2cf5125326c467cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I Left YouTube&lt;/head&gt;
    &lt;p&gt;I remember sitting down in a meeting room hearing the results of my third try at promo cycle trying to get from an L4 to an L5. I helped launch/lead features on YouTube, I led teams, I designed and implemented systems that were still in use to that day by many people, people all across the org knew me and said I was indispensable to the company and were surprised that I wasn't already at an L5/6 level. The results of that meeting? The same from the previous promotion decisions; “it’s unfortunately a no. You don’t have enough impact.”&lt;/p&gt;
    &lt;p&gt;That Tuesday afternoon realization kicked off a grueling, educational, and emotionally taxing journey: leaving a "dream job" to find out what I was actually worth in the open market.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Mathematics of Leveling&lt;/head&gt;
    &lt;p&gt;In the software engineering world, we exist on a ladder. We call this ”Leveling”.&lt;/p&gt;
    &lt;p&gt;For those outside the tech industry, imagine the military. You have Lieutenants, Captains, Majors, and Generals. In tech, these are usually denoted as L3 (Entry/Junior), L4 (Mid), L5 (Senior), and L6 (Staff). L1/2 are saved for contractors or interns. After these denominations, one usually switches to a director or someone on the Leadership team. Your level dictates your salary, your stock grants, and most importantly, the scope of problems you are allowed to solve.&lt;/p&gt;
    &lt;p&gt;I found myself in a situation common to many engineers at large organizations. I was operating at a “Senior” or “Staff" level (architecting systems and roadmaps rather than just writing the code and tracking bugs), but my official title and compensation were stuck at just above junior level.&lt;/p&gt;
    &lt;p&gt;I faced a choice: continue to do way more work to prove myself for the lottery that is the promo cycle or leave to find a company that would recognize my output immediately. I chose the latter. And I decided to attempt a "double level" jump during my interviews (L4 to L6). I didn't just want a lateral move; I wanted the title that matched the work I was already doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Double Life of the Employed Candidate&lt;/head&gt;
    &lt;p&gt;Hunting for a job is a full-time occupation. Doing so while maintaining high performance at a demanding job like YouTube is a recipe for cognitive fracture.&lt;/p&gt;
    &lt;p&gt;The strain comes from context switching. From 9:00 AM to 5:00 PM, I had to care deeply about our quarterly goals and production stability. Then, from 6:00 PM to midnight, I had to care about inverting binary trees and system architecture design.&lt;/p&gt;
    &lt;p&gt;I recall taking "calls" in my car, taking vacation days to practice and do interviews, tethering my laptop to my phone's hotspot to solve coding challenges while squatting in a coffee shop down the street from the office. This duality is exhausting. It forces you to lie by omission to people you respect. You can't tell your team, "I can't take that ticket because I need to study dynamic programming." You just have to work faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;Navigating the NDA Minefield&lt;/head&gt;
    &lt;p&gt;One of the most complex hurdles in this cycle was proving I was capable of that "double level" jump without breaking Non-Disclosure Agreements (NDAs).&lt;/p&gt;
    &lt;p&gt;When you work at a place like YouTube, the scale of the problems you solve is the primary selling point. However, the specifics of how you solved them are often trade secrets.&lt;/p&gt;
    &lt;p&gt;Here is the strategy I developed: Abstract the mechanism, not the metric.&lt;/p&gt;
    &lt;p&gt;I couldn't tell interviewers exactly how a specific proprietary algorithm worked. Instead, I focused on the agnostic engineering principles.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don't say: "I tweaked the YouTube watch-time algorithm using X variable."&lt;/item&gt;
      &lt;item&gt;Do say: "I optimized a high-throughput distributed system to prioritize user retention metrics, reducing latency by 150ms through a custom caching layer."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It shows you understand the systems (which is transferable knowledge) rather than just the product (which stays at the old company). If you are ever in this position, focus on the scale of the data and the architectural patterns you used (like Microservices or Event-Driven Architecture) rather than the feature itself. In the end, it also helped me connect with external technologies and lingo better!&lt;/p&gt;
    &lt;head rend="h3"&gt;The Elephant in the Room...&lt;/head&gt;
    &lt;p&gt;Most interviewers asked me the question that people assume is the hardest to answer... "describe why you are not already an L5/6". And honestly, this was the easiest part. People understood the problems with promos at Google/YouTube, but also this situation. The problem of "doing more work and not getting compensated" is pretty well-known.&lt;/p&gt;
    &lt;p&gt;What was unique was how long it took me to decide to leave. And I had to highlight the incredibly talented team I worked with and the amazing managers that taught me so much. There is so much value in knowing and feeling that the people around you care about you and want to build amazing things with you.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Thirteen-Interview Marathon&lt;/head&gt;
    &lt;p&gt;The most alarming trend I analyzed during this cycle is the inflation of the interview loop.&lt;/p&gt;
    &lt;p&gt;At one prominent tech company, I underwent 13 separate interviews for a single role. This included initial screens, coding rounds, system design rounds, behavioral checks, and meetings with cross-functional partners.&lt;/p&gt;
    &lt;p&gt;From a critical perspective, this signals organizational dysfunction. If a company requires 13 people to sign off on a hire, it suggests they operate on a consensus-based model that stifles autonomy. It implies a fear of making mistakes that outweighs the desire for talent.&lt;/p&gt;
    &lt;p&gt;When I analyze the data from my own process, the companies with 5 to 8 rounds had the clearest internal culture. They knew what they wanted. The company with 13 rounds was fishing for a reason to say "no” (which some ultimately told me).&lt;/p&gt;
    &lt;head rend="h3"&gt;The Final Conversation&lt;/head&gt;
    &lt;p&gt;We often hear that "people leave managers, not jobs." But sometimes, people leave jobs despite loving their managers.&lt;/p&gt;
    &lt;p&gt;My final conversation with my manager was heart-wrenching. I had prepared a script, anticipating a counter-offer or a guilt trip. Instead, I was met with soft and understanding empathy.&lt;/p&gt;
    &lt;p&gt;I explained that my growth curve had flattened. I wasn't leaving because the team failed me; I was leaving because I had outgrown the pot I was planted in. Staying would have required me to stagnate to fit the available space. I needed to leave to see what I was capable of. And he listened to every word.&lt;/p&gt;
    &lt;p&gt;I walked out of the meeting feeling incredibly bittersweet, with tears ready to fall. He knew my talent, he knew how hard I worked, and he still was incredibly supportive while I said I was leaving.&lt;/p&gt;
    &lt;p&gt;This is a hard lesson for both employees and leaders: Retention has a ceiling. Sometimes, the best thing a manager can do for that high-performer is to wish them luck as they walk out the door. It wasn't his fault I wasn't promoted to the level I wanted—he was fighting the same bureaucratic machine I was.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Takeaway&lt;/head&gt;
    &lt;p&gt;Leaving a recognizable brand like Google/YouTube is frightening. You lose the immediate validation that comes with the name on your resume. But careers are long, and comfort is the enemy of progress.&lt;/p&gt;
    &lt;p&gt;If you feel like you are solving problems two levels above your pay grade, and the only reward you get is more work, it is time to test the market. The interview fatigue is real, and the conversations are hard, but the clarity you gain on your own value is worth the struggle.&lt;/p&gt;
    &lt;p&gt;I’m curious about your experiences with career stagnation. Have you ever felt like you were "acting" at a higher level than your title? How did you handle the conversation with your leadership?&lt;/p&gt;
    &lt;p&gt;Please share your stories in the comments below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links and Resources&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Software Engineering Levels: levels.fyi (Excellent resource for comparing titles and compensation across big tech).&lt;/item&gt;
      &lt;item&gt;Github: Career Ladder (detailed guide on how Github views levels; and I personally like their view)&lt;/item&gt;
      &lt;item&gt;System Design Interview Guide: System Design Primer on GitHub&lt;/item&gt;
      &lt;item&gt;Navigating NDAs: Harvard Business Review: Non-Disclosure Agreements&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zhach.news/how-i-left-youtube/"/><published>2025-12-24T21:54:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46380075</id><title>Phoenix: A modern X server written from scratch in Zig</title><updated>2025-12-25T00:53:13.266949+00:00</updated><content>&lt;doc fingerprint="d47bdcdf6826ad85"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Phoenix&lt;/head&gt;
    &lt;p&gt;Phoenix is a new X server, written from scratch in Zig (not a fork of Xorg server). This X server is designed to be a modern alternative to the Xorg server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Current state&lt;/head&gt;
    &lt;p&gt;Phoenix is not ready to be used yet. At the moment it can render simple applications that do GLX, EGL or Vulkan graphics (fully hardware accelerated) nested in an existing X server. Running Phoenix nested will be the only supported mode until Phoenix has progressed more and can run real-world applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Simplicity&lt;/head&gt;
    &lt;p&gt;Be a simpler X server than the Xorg server by only supporting a subset of the X11 protocol, the features that are needed by relatively modern applications (applications written in the last ~20 years).&lt;lb/&gt; Only relatively modern hardware (made in the last ~15 years) which support linux drm and mesa gbm will be supported, and no server driver interface like the Xorg server. Just like how Wayland compositors work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Security&lt;/head&gt;
    &lt;p&gt;Be safer than the Xorg server by parsing protocol messages automatically. As it's written in Zig, it also automatically catches illegal behaviors (such as index out of array bounds) when building with the &lt;code&gt;ReleaseSafe&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;Applications will be isolated from each other by default and can only interact with other applications either through a GUI prompt asking for permission, such as with screen recorders, where it will only be allowed to record the window specified or by explicitly giving the application permission before launched (such as a window manager or external compositor). This will not break existing clients as clients wont receive errors when they try to access more than they need, they will instead receive dummy data.&lt;lb/&gt; Applications that rely on global hotkeys should work, as long as a modifier key is pressed (keys such as ctrl, shift, alt and super). If an application needs global hotkeys without pressing a modifier key then it needs to be given permissions to do so (perhaps by adding a command to run a program with more X11 permissions).&lt;lb/&gt; There will be an option to disable this to make the X server behave like the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improvements for modern technology&lt;/head&gt;
    &lt;p&gt;Support modern hardware better than the Xorg server, such as proper support for multiple monitors (different refresh rates, VRR - not a single framebuffer for the whole collection of displays) and technology like HDR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improved graphics handling&lt;/head&gt;
    &lt;p&gt;No tearing by default and a built-in compositor. The compositor will get disabled if the user runs an external compositor (client application), such as picom or if the client runs a fullscreen application and disabled vsync in the application. The goal is to also have lower vsync/compositor latency than the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;New standards&lt;/head&gt;
    &lt;p&gt;New standards will be developed and documented, such as per-monitor DPI as randr properties. Applications can use this property to scale their content to the specified DPI for the monitor they are on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extending the X11 protocol&lt;/head&gt;
    &lt;p&gt;If there is a need for new features (such as HDR) then the X11 protocol will be extended.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wayland compatibility&lt;/head&gt;
    &lt;p&gt;Some applications might only run on Wayland in the future. Such applications should be supported by either Phoenix supporting Wayland natively or by running an external application that works as a bridge between Wayland and X11 (such as 12to11).&lt;/p&gt;
    &lt;head rend="h3"&gt;Nested display server&lt;/head&gt;
    &lt;p&gt;Being able to run Phoenix nested under X11 or Wayland with hardware acceleration. This is not only useful for debugging Phoenix but also for developers who want to test their window manager or compositor without restarting the display server they are running.&lt;lb/&gt; Being able to run Phoenix under Wayland as an alternative Xwayland server would be a good option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Replacing the Xorg server&lt;/head&gt;
    &lt;p&gt;The Xorg server will always support more features of the X11 protocol and wider range of hardware (especially older ones).&lt;/p&gt;
    &lt;head rend="h3"&gt;Multiple screens&lt;/head&gt;
    &lt;p&gt;Multiple displays (monitors) are going to be supported but not X11 screens.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exclusive access&lt;/head&gt;
    &lt;p&gt;GrabServer has no effect in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Endian-swapped client/server&lt;/head&gt;
    &lt;p&gt;This can be reconsidered if there is a reason.&lt;/p&gt;
    &lt;head rend="h3"&gt;Indirect (remote) GLX.&lt;/head&gt;
    &lt;p&gt;This is very complex as there are a lot of functions that would need to be implemented. These days remote streaming options are more efficient. Alternatively a proxy for glx could be implemented that does remote rendering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Differences between the X11 protocol and Phoenix&lt;/head&gt;
    &lt;head rend="h3"&gt;Core protocol&lt;/head&gt;
    &lt;p&gt;Several parts of the X11 protocol (core) are mandatory to be implemented by an X server, such as font related operations. However these are not going to be implemented in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Strings&lt;/head&gt;
    &lt;p&gt;Strings are in ISO Latin-1 encoding in the X11 protocol unless specified otherwise, however in Phoenix all strings are UTF-8 unless the protocol states that it's not an ISO Latin-1 string.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing&lt;/head&gt;
    &lt;p&gt;Run:&lt;/p&gt;
    &lt;code&gt;zig build -Doptimize=ReleaseSafe
sudo zig build install -p /usr/local -Doptimize=ReleaseSafe
&lt;/code&gt;
    &lt;head rend="h2"&gt;Uninstalling&lt;/head&gt;
    &lt;p&gt;Zig does currently not support the uninstall command so you have to remove files manually:&lt;/p&gt;
    &lt;code&gt;sudo rm /usr/local/bin/phoenix
&lt;/code&gt;
    &lt;head rend="h2"&gt;Building (for development)&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build&lt;/code&gt;, which builds Phoenix in debug mode. The compiled binary will be available at &lt;code&gt;./zig-out/bin/phoenix&lt;/code&gt;. You can alternatively build and run with one command: &lt;code&gt;zig build run&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generate x11 protocol documentation&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build -Dgenerate-docs=true&lt;/code&gt;. This will generate &lt;code&gt;.txt&lt;/code&gt; files in &lt;code&gt;./zig-out/protocol/&lt;/code&gt;. This generates x11 protocol documentation in the style of the official protocol documentation. The documentation is automatically generated from the protocol struct code.
Note that the generated documentation feature is a work-in-progress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zig 0.14.1&lt;/item&gt;
      &lt;item&gt;x11 (&lt;code&gt;xcb&lt;/code&gt;) - for nested mode under X11, when building Phoenix with&lt;code&gt;-Dbackends=x11&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;wayland (&lt;code&gt;wayland-client&lt;/code&gt;,&lt;code&gt;wayland-egl&lt;/code&gt;) - for nested mode under Wayland, when building Phoenix with&lt;code&gt;-Dbackends=wayland&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;drm (&lt;code&gt;libdrm&lt;/code&gt;,&lt;code&gt;gbm&lt;/code&gt;) - for running Phoenix as a standalone X11 server, when building Phoenix with&lt;code&gt;-Dbackends=drm&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;OpenGL (&lt;code&gt;libglvnd&lt;/code&gt;which provides both&lt;code&gt;gl&lt;/code&gt;and&lt;code&gt;egl&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://git.dec05eba.com/phoenix/about/"/><published>2025-12-24T22:43:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46380168</id><title>Tell HN: Merry Christmas</title><updated>2025-12-25T00:53:12.794871+00:00</updated><content>&lt;doc fingerprint="3d2d13d459cf20bd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Different cultures celebrate Christmas at different days and time zones are a thing. But it's Christmas here, so:&lt;/p&gt;
      &lt;p&gt;Merry Christmas to everyone. I hope you get some rest and can spend time with people who are dear to you and get to focus on what's important rather than getting lost in stressing about everything having to be perfect.&lt;/p&gt;
      &lt;p&gt;Also much love to everyone who cannot spend their Christmas with dear people.&lt;/p&gt;
      &lt;p&gt;To make sure this post meets the relevancy criteria, here is a Wikipedia article about some Christmas (more precisely advent) tradition which I personally really like: https://en.wikipedia.org/wiki/Christmas_market&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46380168"/><published>2025-12-24T22:56:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46380399</id><title>Asterisk AI Voice Agent</title><updated>2025-12-25T00:53:12.315889+00:00</updated><content>&lt;doc fingerprint="2c0ef1107fb2aeaa"&gt;
  &lt;main&gt;
    &lt;p&gt;The most powerful, flexible open-source AI voice agent for Asterisk/FreePBX. Featuring a modular pipeline architecture that lets you mix and match STT, LLM, and TTS providers, plus 5 production-ready golden baselines validated for enterprise deployment.&lt;/p&gt;
    &lt;p&gt;Quick Start • Features • Demo • Documentation • Community&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Quick Start&lt;/item&gt;
      &lt;item&gt;🎉 What's New&lt;/item&gt;
      &lt;item&gt;🌟 Why Asterisk AI Voice Agent?&lt;/item&gt;
      &lt;item&gt;✨ Features&lt;/item&gt;
      &lt;item&gt;🎥 Demo&lt;/item&gt;
      &lt;item&gt;🛠️ AI-Powered Actions&lt;/item&gt;
      &lt;item&gt;🩺 Agent CLI Tools&lt;/item&gt;
      &lt;item&gt;⚙️ Configuration&lt;/item&gt;
      &lt;item&gt;🏗️ Project Architecture&lt;/item&gt;
      &lt;item&gt;📊 Requirements&lt;/item&gt;
      &lt;item&gt;🗺️ Documentation&lt;/item&gt;
      &lt;item&gt;🤝 Contributing&lt;/item&gt;
      &lt;item&gt;💬 Community&lt;/item&gt;
      &lt;item&gt;📝 License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get the Admin UI running in 2 minutes.&lt;/p&gt;
    &lt;p&gt;For a complete first successful call walkthrough (dialplan + transport selection + verification), see:&lt;/p&gt;
    &lt;code&gt;# Clone repository
git clone https://github.com/hkjarral/Asterisk-AI-Voice-Agent.git
cd Asterisk-AI-Voice-Agent

# Run preflight with auto-fix (creates .env, generates JWT_SECRET)
sudo ./preflight.sh --apply-fixes&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Important: Preflight creates your&lt;/p&gt;&lt;code&gt;.env&lt;/code&gt;file and generates a secure&lt;code&gt;JWT_SECRET&lt;/code&gt;. Always run this first!&lt;/quote&gt;
    &lt;code&gt;# Start the Admin UI container
docker compose up -d --build admin-ui&lt;/code&gt;
    &lt;p&gt;Open in your browser:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local: &lt;code&gt;http://localhost:3003&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Remote server: &lt;code&gt;http://&amp;lt;server-ip&amp;gt;:3003&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Default Login: &lt;code&gt;admin&lt;/code&gt; / &lt;code&gt;admin&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Follow the Setup Wizard to configure your providers and make a test call.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Security: The Admin UI is accessible on the network. Change the default password immediately and restrict port 3003 via firewall, VPN, or reverse proxy for production use.&lt;/quote&gt;
    &lt;code&gt;# Start ai-engine (required for health checks)
docker compose up -d --build ai-engine

# Check ai-engine health
curl http://localhost:15000/health
# Expected: {"status":"healthy"}

# View logs for any errors
docker compose logs ai-engine | tail -20&lt;/code&gt;
    &lt;p&gt;The wizard will generate the necessary dialplan configuration for your Asterisk server.&lt;/p&gt;
    &lt;p&gt;Transport selection is configuration-dependent (not strictly “pipelines vs full agents”). Use the validated matrix in:&lt;/p&gt;
    &lt;p&gt;For users who prefer the command line or need headless setup.&lt;/p&gt;
    &lt;code&gt;./install.sh
agent quickstart&lt;/code&gt;
    &lt;code&gt;# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start services
docker compose up -d&lt;/code&gt;
    &lt;p&gt;Add this to your FreePBX (&lt;code&gt;extensions_custom.conf&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;[from-ai-agent]
exten =&amp;gt; s,1,NoOp(Asterisk AI Voice Agent v4.5.3)
 same =&amp;gt; n,Stasis(asterisk-ai-voice-agent)
 same =&amp;gt; n,Hangup()
&lt;/code&gt;
    &lt;p&gt;Health check:&lt;/p&gt;
    &lt;code&gt;agent doctor&lt;/code&gt;
    &lt;p&gt;View logs:&lt;/p&gt;
    &lt;code&gt;docker compose logs -f ai-engine&lt;/code&gt;
    &lt;head&gt;Latest Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full Call Logging: Every call saved with conversation history, timing, and outcome&lt;/item&gt;
      &lt;item&gt;Per-Call Debugging: Review transcripts, tool executions, and errors from Admin UI&lt;/item&gt;
      &lt;item&gt;Search &amp;amp; Filter: Find calls by caller, provider, context, or date range&lt;/item&gt;
      &lt;item&gt;Export: Download call data as CSV or JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Immediate Interruption: Agent audio stops instantly when caller speaks&lt;/item&gt;
      &lt;item&gt;Provider-Owned Turn-Taking: Full agents (Google, Deepgram, OpenAI, ElevenLabs) handle VAD natively&lt;/item&gt;
      &lt;item&gt;Platform Flush: Local playback clears immediately on interruption signal&lt;/item&gt;
      &lt;item&gt;Transport Parity: Works with both ExternalMedia RTP and AudioSocket&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Faster Whisper: High-accuracy STT backend with GPU acceleration&lt;/item&gt;
      &lt;item&gt;MeloTTS: New neural TTS option for local pipelines&lt;/item&gt;
      &lt;item&gt;Model Hot-Swap: Switch models via Dashboard without container restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Tools Framework: Connect AI agents to external services via Model Context Protocol&lt;/item&gt;
      &lt;item&gt;Admin UI Config: Configure MCP servers from the web interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Remote Endpoint Pinning: Lock RTP streams to prevent audio hijacking&lt;/item&gt;
      &lt;item&gt;Allowlist Support: Restrict allowed remote hosts for ExternalMedia&lt;/item&gt;
      &lt;item&gt;Cross-Talk Prevention: SSRC-based routing ensures call isolation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;local_hybrid&lt;/code&gt;Default: Privacy-focused pipeline is now the out-of-box default&lt;/item&gt;
      &lt;item&gt;Pipeline-Aware Readiness: Health probes correctly reflect pipeline component status&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Previous Versions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🌍 Pre-flight Script: System compatibility checker with auto-fix mode.&lt;/item&gt;
      &lt;item&gt;🔧 Admin UI Fixes: Models page, providers page, dashboard improvements.&lt;/item&gt;
      &lt;item&gt;🛠️ Developer Experience: Code splitting, ESLint + Prettier.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🎤 New STT Backends: Kroko ASR, Sherpa-ONNX.&lt;/item&gt;
      &lt;item&gt;🔊 Kokoro TTS: High-quality neural TTS.&lt;/item&gt;
      &lt;item&gt;🔄 Model Management: Dynamic backend switching from Dashboard.&lt;/item&gt;
      &lt;item&gt;📚 Documentation: LOCAL_ONLY_SETUP.md guide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🖥️ Admin UI v1.0: Modern web interface (http://localhost:3003).&lt;/item&gt;
      &lt;item&gt;🎙️ ElevenLabs Conversational AI: Premium voice quality provider.&lt;/item&gt;
      &lt;item&gt;🎵 Background Music: Ambient music during AI calls.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔧 Complete Tool Support: Works across ALL pipeline types.&lt;/item&gt;
      &lt;item&gt;📚 Documentation Overhaul: Reorganized structure.&lt;/item&gt;
      &lt;item&gt;💬 Discord Community: Official server integration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🤖 Google Live API: Gemini 2.0 Flash integration.&lt;/item&gt;
      &lt;item&gt;🚀 Interactive Setup: &lt;code&gt;agent quickstart&lt;/code&gt;wizard.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔧 Tool Calling System: Transfer calls, send emails.&lt;/item&gt;
      &lt;item&gt;🩺 Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Benefit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Asterisk-Native&lt;/cell&gt;
        &lt;cell&gt;Works directly with your existing Asterisk/FreePBX - no external telephony providers required.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Truly Open Source&lt;/cell&gt;
        &lt;cell&gt;MIT licensed with complete transparency and control.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Modular Architecture&lt;/cell&gt;
        &lt;cell&gt;Choose cloud, local, or hybrid - mix providers as needed.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Production-Ready&lt;/cell&gt;
        &lt;cell&gt;Battle-tested baselines with Call History-first debugging.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cost-Effective&lt;/cell&gt;
        &lt;cell&gt;Local Hybrid costs ~$0.001-0.003/minute (LLM only).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Privacy-First&lt;/cell&gt;
        &lt;cell&gt;Keep audio local while using cloud intelligence.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;OpenAI Realtime (Recommended for Quick Start)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Modern cloud AI with natural conversations (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-openai.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Enterprise deployments, quick setup.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deepgram Voice Agent (Enterprise Cloud)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Advanced Think stage for complex reasoning (&amp;lt;3s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-deepgram.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Deepgram ecosystem, advanced features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Google Live API (Multimodal AI)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Gemini Live (Flash) with multimodal capabilities (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-google-live.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Google ecosystem, advanced AI features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ElevenLabs Agent (Premium Voice Quality)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;ElevenLabs Conversational AI with premium voices (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-elevenlabs.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Voice quality priority, natural conversations.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local Hybrid (Privacy-Focused)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Local STT/TTS + Cloud LLM (OpenAI). Audio stays on-premises.&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-local-hybrid.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Audio privacy, cost control, compliance.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run your own local LLM using Ollama - perfect for privacy-focused deployments:&lt;/p&gt;
    &lt;code&gt;# In ai-agent.yaml
active_pipeline: local_ollama&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No API key required - fully self-hosted on your network&lt;/item&gt;
      &lt;item&gt;Tool calling support with compatible models (Llama 3.2, Mistral, Qwen)&lt;/item&gt;
      &lt;item&gt;Local Vosk STT + Your Ollama LLM + Local Piper TTS&lt;/item&gt;
      &lt;item&gt;Complete privacy - all processing stays on-premises&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mac Mini, gaming PC, or server with Ollama installed&lt;/item&gt;
      &lt;item&gt;8GB+ RAM (16GB+ recommended for larger models)&lt;/item&gt;
      &lt;item&gt;See docs/OLLAMA_SETUP.md for setup guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommended Models:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Tool Calling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;llama3.2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;mistral&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;qwen2.5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4.7GB&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tool Calling System: AI-powered actions (transfers, emails) work with any provider.&lt;/item&gt;
      &lt;item&gt;Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;,&lt;code&gt;init&lt;/code&gt;commands.&lt;/item&gt;
      &lt;item&gt;Modular Pipeline System: Independent STT, LLM, and TTS provider selection.&lt;/item&gt;
      &lt;item&gt;Dual Transport Support: AudioSocket and ExternalMedia RTP (see Transport Compatibility matrix).&lt;/item&gt;
      &lt;item&gt;High-Performance Architecture: Separate &lt;code&gt;ai-engine&lt;/code&gt;and&lt;code&gt;local-ai-server&lt;/code&gt;containers.&lt;/item&gt;
      &lt;item&gt;Observability: Built-in Call History for per-call debugging + optional &lt;code&gt;/metrics&lt;/code&gt;scraping.&lt;/item&gt;
      &lt;item&gt;State Management: SessionStore for centralized, typed call state.&lt;/item&gt;
      &lt;item&gt;Barge-In Support: Interrupt handling with configurable gating.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Modern web interface for configuration and system management.&lt;/p&gt;
    &lt;p&gt;Quick Start:&lt;/p&gt;
    &lt;code&gt;docker compose up -d admin-ui
# Access at: http://localhost:3003
# Login: admin / admin (change immediately!)&lt;/code&gt;
    &lt;p&gt;Key Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Setup Wizard: Visual provider configuration.&lt;/item&gt;
      &lt;item&gt;Dashboard: Real-time system metrics and container status.&lt;/item&gt;
      &lt;item&gt;Live Logs: WebSocket-based log streaming.&lt;/item&gt;
      &lt;item&gt;YAML Editor: Monaco-based editor with validation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Experience our production-ready configurations with a single phone call:&lt;/p&gt;
    &lt;p&gt;Dial: (925) 736-6718&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Press 5 → Google Live API (Multimodal AI with Gemini 2.0)&lt;/item&gt;
      &lt;item&gt;Press 6 → Deepgram Voice Agent (Enterprise cloud with Think stage)&lt;/item&gt;
      &lt;item&gt;Press 7 → OpenAI Realtime API (Modern cloud AI, most natural)&lt;/item&gt;
      &lt;item&gt;Press 8 → Local Hybrid Pipeline (Privacy-focused, audio stays local)&lt;/item&gt;
      &lt;item&gt;Press 9 → ElevenLabs Agent (Santa voice with background music)&lt;/item&gt;
      &lt;item&gt;Press 10 → Fully Local Pipeline (100% on-premises, CPU-based)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your AI agent can perform real-world telephony actions through tool calling.&lt;/p&gt;
    &lt;code&gt;Caller: "Transfer me to the sales team"
Agent: "I'll connect you to our sales team right away."
[Transfer to sales queue with queue music]
&lt;/code&gt;
    &lt;p&gt;Supported Destinations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extensions: Direct SIP/PJSIP endpoint transfers.&lt;/item&gt;
      &lt;item&gt;Queues: ACD queue transfers with position announcements.&lt;/item&gt;
      &lt;item&gt;Ring Groups: Multiple agents ring simultaneously.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cancel Transfer: "Actually, cancel that" (during ring).&lt;/item&gt;
      &lt;item&gt;Hangup Call: Ends call gracefully with farewell.&lt;/item&gt;
      &lt;item&gt;Voicemail: Routes to voicemail box.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic Call Summaries: Admins receive full transcripts and metadata.&lt;/item&gt;
      &lt;item&gt;Caller-Requested Transcripts: "Email me a transcript of this call."&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Transfer to extensions, queues, or ring groups&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cancel_transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Cancel in-progress transfer (during ring)&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hangup_call&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;End call gracefully with farewell message&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;leave_voicemail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Route caller to voicemail extension&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;send_email_summary&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-send call summaries to admins&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;request_transcript&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Caller-initiated email transcripts&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Production-ready CLI for operations and setup.&lt;/p&gt;
    &lt;p&gt;Installation:&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/hkjarral/Asterisk-AI-Voice-Agent/main/scripts/install-cli.sh | bash&lt;/code&gt;
    &lt;p&gt;Commands:&lt;/p&gt;
    &lt;code&gt;agent quickstart          # Interactive setup wizard
agent dialplan            # Generate dialplan snippets
agent config validate     # Validate configuration
agent doctor --fix        # System health check
agent troubleshoot        # Analyze specific call
agent demo                # Demo features&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;config/ai-agent.yaml&lt;/code&gt;- Golden baseline configs.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;.env&lt;/code&gt;- Secrets and API keys (git-ignored).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;OPENAI_API_KEY=sk-your-key-here
DEEPGRAM_API_KEY=your-key-here
ASTERISK_ARI_USERNAME=asterisk
ASTERISK_ARI_PASSWORD=your-password&lt;/code&gt;
    &lt;p&gt;The engine exposes Prometheus-format metrics at &lt;code&gt;http://&amp;lt;engine-host&amp;gt;:15000/metrics&lt;/code&gt;.
Per-call debugging is handled via Admin UI → Call History.&lt;/p&gt;
    &lt;p&gt;Two-container architecture for performance and scalability:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;ai-engine&lt;/code&gt;(Lightweight orchestrator): Connects to Asterisk via ARI, manages call lifecycle.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;local-ai-server&lt;/code&gt;(Optional): Runs local STT/LLM/TTS models (Vosk, Sherpa, Kroko, Piper, Kokoro, llama.cpp).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;graph LR
    A[Asterisk Server] &amp;lt;--&amp;gt;|ARI, RTP| B[ai-engine]
    B &amp;lt;--&amp;gt;|API| C[AI Provider]
    B &amp;lt;--&amp;gt;|WS| D[local-ai-server]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Requirement&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Architecture&lt;/cell&gt;
        &lt;cell&gt;x86_64 (AMD64) only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OS&lt;/cell&gt;
        &lt;cell&gt;Linux with systemd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Supported Distros&lt;/cell&gt;
        &lt;cell&gt;Ubuntu 20.04+, Debian 11+, RHEL/Rocky/Alma 8+, Fedora 38+, Sangoma Linux&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: ARM64 (Apple Silicon, Raspberry Pi) is not currently supported. See Supported Platforms for the full compatibility matrix.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;RAM&lt;/cell&gt;
        &lt;cell role="head"&gt;Disk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cloud (OpenAI/Deepgram)&lt;/cell&gt;
        &lt;cell&gt;2+ cores&lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;1GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Local Hybrid&lt;/cell&gt;
        &lt;cell&gt;4+ cores&lt;/cell&gt;
        &lt;cell&gt;8GB+&lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Docker + Docker Compose v2&lt;/item&gt;
      &lt;item&gt;Asterisk 18+ with ARI enabled&lt;/item&gt;
      &lt;item&gt;FreePBX (recommended) or vanilla Asterisk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;preflight.sh&lt;/code&gt; script handles initial setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seeds &lt;code&gt;.env&lt;/code&gt;from&lt;code&gt;.env.example&lt;/code&gt;with your settings&lt;/item&gt;
      &lt;item&gt;Prompts for Asterisk config directory location&lt;/item&gt;
      &lt;item&gt;Sets &lt;code&gt;ASTERISK_UID&lt;/code&gt;/&lt;code&gt;ASTERISK_GID&lt;/code&gt;to match host permissions (fixes media access issues)&lt;/item&gt;
      &lt;item&gt;Re-running preflight often resolves permission problems&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration Reference&lt;/item&gt;
      &lt;item&gt;Transport Compatibility&lt;/item&gt;
      &lt;item&gt;Tuning Recipes&lt;/item&gt;
      &lt;item&gt;Supported Platforms&lt;/item&gt;
      &lt;item&gt;Local Profiles&lt;/item&gt;
      &lt;item&gt;Monitoring Guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome! Please see our Contributing Guide.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord Server - Support and discussions&lt;/item&gt;
      &lt;item&gt;GitHub Issues - Bug reports&lt;/item&gt;
      &lt;item&gt;GitHub Discussions - General chat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;If you find this project useful, please give it a ⭐️ on GitHub!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/hkjarral/Asterisk-AI-Voice-Agent"/><published>2025-12-24T23:25:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46380475</id><title>Microsoft please get your tab to autocomplete shit together</title><updated>2025-12-25T00:53:12.043906+00:00</updated><content>&lt;doc fingerprint="5b1dc935701a48f1"&gt;
  &lt;main&gt;
    &lt;p&gt;November 26, 2025 • Programming&lt;/p&gt;
    &lt;p&gt;What do you think is gonna happen after I press tab when looking at this screenshot?&lt;/p&gt;
    &lt;p&gt;That’s right, its gonna do nothing and suggest something else that it wasn’t any of the 2 initial suggestions&lt;/p&gt;
    &lt;p&gt;Whoever team or person is on charge of the behavior of vscode autocomplete behavior at Microsoft (or at least the C# Dev Kit plugin) please do your job and fix this, thank you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ivanca.github.io/programming/2025/11/26/microsoft-pls-get-your-tab-to-autocomplete-shit-together/"/><published>2025-12-24T23:33:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46380758</id><title>Who Watches the Waymos? I do [video]</title><updated>2025-12-25T00:53:11.047456+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=oYU2hAbx_Fc"/><published>2025-12-25T00:10:12+00:00</published></entry></feed>