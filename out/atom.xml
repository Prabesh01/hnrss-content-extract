<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-15T18:45:59.851983+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45590900</id><title>Ireland is making basic income for artists program permanent</title><updated>2025-10-15T18:46:07.215802+00:00</updated><content>&lt;doc fingerprint="7fea01d9548b374e"&gt;
  &lt;main&gt;
    &lt;p&gt;Several years after launching a trial, Ireland is set to make its basic income for artists program permanent starting in 2026.&lt;/p&gt;
    &lt;p&gt;Under the program, selected artists receive a weekly payment of approximately $375, or about $1,500 per month. There are 2,000 spots available, with applications set to open in September 2026; eligibility criteria have not yet been announced. The government may expand the program to additional applicants in the future, should more funding become available, according to Irish broadcaster RTÉ.&lt;/p&gt;
    &lt;p&gt; The current program, which began in 2022 and is set to end in February after a six-month extension agreed to earlier this year, was launched to support the arts sector following the pandemic. Many artists suffered disproportionate income losses during that time due to the cancelation of live performances and events.&lt;lb/&gt;For the pilot, applicants could apply under visual arts, theater, literature, music, dance, opera, film, circuses, and architecture. They were required to submit two pieces of evidence proving that they were professional cultural workers, such as proof of income from art sales, membership in a professional body, or reviews. At the time, the New York Times reported that more than 9,000 people applied, with 8,200 deemed eligible and 2,000 randomly selected to receive payments. Another 1,000 eligible applicants were placed in a control group to be monitored but not receive funds. &lt;/p&gt;
    &lt;p&gt;The announcement follows the release of an external report by UK-based consultants Alma Economics, which found that the pilot cost €72 million to date but generated nearly €80 million in total benefits to the Irish economy. The report also found that recipients’ arts-related income increased by more than €500 per month on average, income from non-arts work decreased by around €280, and reliance on other social programs declined, with participants receiving €100 less per month on average.&lt;/p&gt;
    &lt;p&gt;“The economic return on this investment in Ireland’s artists and creative arts workers is having an immediate positive impact on the sector and the economy overall,” Patrick O’Donovan, minister for culture, communications, and sport, said in a statement.&lt;/p&gt;
    &lt;p&gt;The report further estimated that a permanent, “scaled-up” program would likely result in artists producing 22 percent more work, while lowering the average cost of art to consumers by 9 to 25 percent.&lt;/p&gt;
    &lt;p&gt; In October, the government released the results of a public survey on the scheme, which found that 97 percent of respondents support the program. However, 47 percent of the 17,000 respondents said artists should be selected based on economic need, while 37.5 percent favored selection by merit. Only 14 percent preferred random selection.&lt;lb/&gt;Ireland’s BIA program is a form of universal basic income, a policy that grants all citizens a recurring payment regardless of socioeconomic status or other factors. Such programs have grown increasingly mainstream—if not widely implemented—in recent years, as fears rise over the effects of artificial intelligence and other technology-driven job losses. Many UBI advocates have cited Ireland’s program as evidence that the model works. &lt;/p&gt;
    &lt;p&gt;“As the pilot shows, basic income works and people need a UBI now to face and deal with the many social, economic, and ecological crises of our world. The Network will continue to help demonstrate basic income within communities and show how it is a sustainable policy,” the UBI Lab Network said in a statement calling for a nationwide program.&lt;/p&gt;
    &lt;p&gt;“We need no further pilots. People need a UBI now to face and deal with the many social, economic, and ecological crises of our world,” Reinhard Huss, organizer of UBI Lab Leeds, told Business Insider in June.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.artnews.com/art-news/news/ireland-basic-income-artists-program-permanent-1234756981/"/><published>2025-10-15T11:40:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590949</id><title>Show HN: Halloy – Modern IRC client</title><updated>2025-10-15T18:46:06.868043+00:00</updated><content>&lt;doc fingerprint="3f7a5c1966185a9a"&gt;
  &lt;main&gt;
    &lt;p&gt;Halloy is an open-source IRC client written in Rust, with the Iced GUI library. It aims to provide a simple and fast client for Mac, Windows, and Linux platforms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation for latest release: https://halloy.chat.&lt;/item&gt;
      &lt;item&gt;Documentation for main branch (when building from source): https://unstable.halloy.chat.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Join #halloy on libera.chat if you have questions or looking for help.&lt;/p&gt;
    &lt;p&gt;Halloy is also available from Flathub and Snap Store.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IRCv3.2 capabilities&lt;/item&gt;
      &lt;item&gt;SASL support&lt;/item&gt;
      &lt;item&gt;DCC Send&lt;/item&gt;
      &lt;item&gt;Keyboard shortcuts&lt;/item&gt;
      &lt;item&gt;Auto-completion for nicknames, commands, and channels&lt;/item&gt;
      &lt;item&gt;Notifications support&lt;/item&gt;
      &lt;item&gt;Multiple channels at the same time across servers&lt;/item&gt;
      &lt;item&gt;Command bar for for quick actions&lt;/item&gt;
      &lt;item&gt;Custom themes&lt;/item&gt;
      &lt;item&gt;Portable mode&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Halloy is released under the GPL-3.0 License. For more details, see the LICENSE file.&lt;/p&gt;
    &lt;p&gt;For any questions, suggestions, or issues, please open an issue on the GitHub repository.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/squidowl/halloy"/><published>2025-10-15T11:45:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591082</id><title>Helpcare AI (YC F24) Is Hiring</title><updated>2025-10-15T18:46:06.502336+00:00</updated><content>&lt;doc fingerprint="439da654fe15b36e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Ideal Candidate:&lt;/p&gt;
      &lt;p&gt;- Worked at an early-stage startup (pre-seed, seed, series A)&lt;/p&gt;
      &lt;p&gt;- 7yrs of full-stack experience. (python, react preferred, open to other)&lt;/p&gt;
      &lt;p&gt;- Some experience with LLM / Agentic Applications.&lt;/p&gt;
      &lt;p&gt;- Some experience with Data Ingestion.&lt;/p&gt;
      &lt;p&gt;- Bonus 2x / yr.&lt;/p&gt;
      &lt;p&gt;- $120,000+ / yr. with generous equity.&lt;/p&gt;
      &lt;p&gt;Tech Stack:&lt;/p&gt;
      &lt;p&gt;Python, React, Fast API, Supabase&lt;/p&gt;
      &lt;p&gt;Who we are:&lt;/p&gt;
      &lt;p&gt;- Mission to improve the world's capacity for care&lt;/p&gt;
      &lt;p&gt;- Respectful, intelligent, positive team&lt;/p&gt;
      &lt;p&gt;- A-players that are excited to build the best&lt;/p&gt;
      &lt;p&gt;- Well funded, YC- Company with incredible customer demand&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45591082"/><published>2025-10-15T12:00:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591149</id><title>Garbage collection for Rust: The finalizer frontier</title><updated>2025-10-15T18:46:05.598625+00:00</updated><content>&lt;doc fingerprint="b6a84895ac650758"&gt;
  &lt;main&gt;&lt;p&gt;Also available as: DOI, PDF (arxiv).&lt;/p&gt;&lt;p&gt;See also: Experiment (DOI).&lt;/p&gt;&lt;p&gt;Abstract Rust is a non-Garbage Collected (GCed) language, but the lack of GC makes expressing data-structures that require shared ownership awkward, inefficient, or both. In this paper we explore a new design for, and implementation of, GC in Rust, called Alloy. Unlike previous approaches to GC in Rust, Alloy allows existing Rust destructors to be automatically used as GC finalizers: this makes Alloy integrate better with existing Rust code than previous solutions but introduces surprising soundness and performance problems. Alloy provides novel solutions for the core problems: finalizer safety analysis rejects unsound destructors from automatically being reused as finalizers; finalizer elision optimises away unnecessary finalizers; and premature finalizer prevention ensures that finalizers are only run when it is provably safe to do so.&lt;/p&gt;&lt;p&gt; Amongst the ways one can classify programming languages are whether they are Garbage Collected (GCed) or not: GCed languages enable implicit memory management; non-GCed languages require explicit memory management (e.g &lt;code&gt;C&lt;/code&gt;'s &lt;code&gt;malloc&lt;/code&gt; / &lt;code&gt;free&lt;/code&gt; functions). Rust's use of affine types [25, p. 5] and
ownership does not fit within this classification: it is not GCed but it has implicit scope-based
memory management. Most portions of Rust programs are as succinct as a GCed equivalent, but
ownership is too inflexible to express shared ownership for data-structures that require multiple
owners (e.g. doubly linked lists). Workarounds such as reference counting impose an extra
burden on the programmer, make mistakes more likely, and often come with a performance
penalty.
&lt;/p&gt;&lt;p&gt; In an attempt to avoid such problems, there are now a number of GCs for Rust (e.g. [2, 11, 14, 32, 33]). Most introduce a user-visible type &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; which takes a value v of type &lt;code&gt;T&lt;/code&gt; and moves v to the 'GC
heap'. The &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; value itself is a wrapper around a pointer to v on the GC heap. &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; can be
cloned (i.e. duplicated) and dereferenced to a value of type &lt;code&gt;&amp;amp;T&lt;/code&gt; (i.e. a type-safe pointer) at
will by the user. When no &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; wrappers pointing to v can be found, indirectly or directly,
from the program's roots (e.g. variables on the stack), then the GC heap memory for v can be
reclaimed.
&lt;/p&gt;&lt;p&gt; It has proven hard to find a satisfying design and implementation for a GC for Rust, as perhaps suggested by the number of attempts to do so. We identify two fundamental challenges for GC for Rust: how to give &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; an idiomatic and complete API; and how to make finalizers
(i.e. the code that is run just before a value is collected by the GC) safe, performant, and
ergonomic.
&lt;/p&gt;&lt;p&gt;In this paper we introduce Alloy, a new GC for Rust: an example of its use is shown in Listing 1. Alloy uses conservative garbage collection (i.e. treating each reachable machine word as a potential pointer), which naturally solves the API challenge. However, the finalization challenge is much more involved: the causes of this challenge, and our solutions to it, occupy the bulk of this paper.&lt;/p&gt;&lt;p&gt; Normal Rust code uses destructors (i.e. code which is run just before a value is reclaimed by Rust's implicit memory management) extensively. Although finalizers and destructors may seem to be synonyms, existing GCs for Rust cannot reuse destructors as finalizers: the latter must be manually implemented for each type that needs it. Unfortunately, even this is trickier than it appears: it is not possible to implement a finalizer for &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; if &lt;code&gt;T&lt;/code&gt; is an external library; some parts of destructors are
automatically created by the Rust compiler, but hand-written finalizers must duplicate those parts
manually; and users can accidentally cause a type's finalizer to be run more than once. In short,
finalization in existing GCs for Rust is unpalatable.
&lt;/p&gt;&lt;p&gt;GCs for Rust are not alone in requiring manually written finalizers. In a close cousin to our work, a GC proposal for C++, the reuse of destructors as finalizers was ruled out due to seemingly insoluble problems [8, p. 32], which we divide into four categories: (1) some safe destructors are not safe finalizers; (2) finalizers can be run prematurely; (3) running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks; (4) and finalizers are prohibitively slower than destructors. All are, at least to some degree, classical GC problems; all are exacerbated in some way by Rust; and none, with the partial exception of #2, has existing solutions.&lt;/p&gt;&lt;p&gt;We show that it is possible to reuse most Rust destructors as finalizers in a satisfying way. We introduce novel solutions to the long-standing problems this implies by making use of some of Rust's unusual static guarantees. We thus gain a better GC for Rust and solutions to open GC problems. Our solutions, in order, are: (1) finalizer safety analysis extends Rust's static analyses to reject programs whose destructors are not provably safe to be used as finalizers; (2) premature finalizer prevention automatically inserts fences to prevent the GC from being 'tricked' into collecting values before they are dead; (3) we run finalizers on a separate thread; and (4) and finalizer elision statically optimises away finalizers if the underlying destructor duplicates the GC's work.&lt;/p&gt;&lt;p&gt;Alloy as an implementation is necessarily tied to Rust, though most of the novel techniques in this paper rely on general properties of affine types and ownership. While we do not wish to claim generality without evidence, it seems likely that many of the techniques in this paper will generalise to other ownership-based languages, as and when such emerge.&lt;/p&gt;&lt;p&gt;Although Alloy is not production ready, its performance is already reasonable: when we control for the (admittedly somewhat slow) conservative GC (BDWGC) Alloy currently uses, the performance of Alloy varies from 0.74Ã to, in the worst case, 1.17Ã that of reference counting. Alloy is also sufficiently polished (e.g. good quality error messages) in other ways for it to: show a plausible path forwards for those who may wish to follow it; and to allow others to evaluate whether GC for Rust is a good idea or not.&lt;/p&gt;&lt;p&gt;This paper is divided into four main parts: GC and Rust background (Section 2); Alloy's basic design (Section 3); destructor and finalizer challenges and solutions (Sections 4 to 7); and evaluation (Section 8). The first three parts have the challenge that our work straddles two areas that can seem mutually exclusive: GC and Rust. We have tried to provide sufficient material for readers expert in one of these areas to gain adequate familiarity with the other, without boring either, but we encourage readers to skip material they are already comfortable with.&lt;/p&gt;&lt;p&gt;2.1 The Challenges of Shared Ownership in Rust&lt;/p&gt;&lt;p&gt; Rust uses affine types and ownership to statically guarantee that: a value has a single owner (e.g. a variable); an owner can move (i.e. permanently transfer the ownership of) a value to another owner; and when a value's owner goes out of scope, the value's destructor is run and its backing memory reclaimed. An owner can pass references to a value to other code, subject to the following static restrictions: there can be multiple immutable references ('&lt;code&gt;&amp;amp;&lt;/code&gt;') to a value or a single
mutable reference ('&lt;code&gt;&amp;amp;mut&lt;/code&gt;'); and references cannot outlast the owner. These rules allow many
Rust programs to be as succinct as their equivalents in GCed languages. This suggests that
the search for a good GC for Rust may be intellectually stimulating but of little practical
value.
&lt;/p&gt;&lt;p&gt;However, there are many programs which need to express data structures which do not fit into the restrictions of affine types and ownership. These are often described as 'cyclic data-structures', but in this paper we use the more abstract term 'shared ownership', which includes, but is not limited to, cyclic data-structures.&lt;/p&gt;&lt;p&gt; A common way of expressing shared ownership is to use the reference counting type &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; from
Rust's standard library. For many data-structures, this is a reasonable solution, but some forms of shared
ownership require juggling strong and weak counts. This complicates programs (see Listing 2) and can
cause problems when values live for shorter or longer than intended.
&lt;/p&gt;&lt;p&gt;A different solution is to store values in a vector and use integer indices into that vector. Such indices are morally closer to machine pointers than normal Rust references: the indices can become stale, dangle, or may never have been valid in the first place. The programmer must also manually deal with issues such as detecting unused values, compaction, and so on. In other words, the programmer ends up writing a partial GC themselves. A variant of this idea are arenas, which gradually accumulate multiple values but free all of them in one go: values can no longer be reclaimed too early, though arenas tend to unnecessarily increase the lifetime of values.&lt;/p&gt;&lt;p&gt; A type-based approach is &lt;code&gt;GhostCell&lt;/code&gt; [35], which uses branding to statically ensure that at any given
point only one part of a program can access a shared ownership data-structure. This necessarily excludes
common use cases where multiple owners (e.g. in different threads) need to simultaneously access
disjoint parts of a data-structure.
&lt;/p&gt;&lt;p&gt; Although it is easily overlooked, some workarounds (e.g. &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;) rely on using unsafe Rust
(i.e. parts of the language, often involving pointers, that are not fully statically checked by the
compiler). Pragmatically, we assume that widely used code, even if technically unsafe, has
been pored over sufficiently that it is trustworthy in practise. However, 'new' solutions that a
programmer implements using unsafe Rust are unlikely to immediately reach the same level of
trustworthiness.
&lt;/p&gt;&lt;p&gt;While we do not believe that every Rust program would be improved by GC, the variety of workarounds already present in Rust code, and the difficultly of creating new ones, suggests that there is a subset that would benefit from GC.&lt;/p&gt;GC is a venerable field and has accumulated terminology that can seem unfamiliar or unintuitive. We mostly use the same terminology as Jones et al [19], the major parts of which we define here.&lt;p&gt;A program which uses GC is split between the mutator (the user's program) and the collector (the GC itself). At any given point in time, a thread is either running as a mutator or a collector. In our context, all threads run as a collector at least sometimes (for reasons that will become apparent later, some threads always run as a collector). Tracing and reclamation is performed during a collection phase. Our collections always stop-the-world, where all threads running mutator code are paused while collection occurs.&lt;/p&gt;&lt;p&gt;A tracing GC is one that scans memory looking for reachable values from a program's roots: values, including cycles of values, that are not reachable from the roots can then be reclaimed. In contrast, a pure reference counting GC does not scan memory, and thus cannot free values that form a cycle. Increasingly, GC implementations make use of multiple techniques (see [3]) but, for simplicity's sake, we assume that implementations wholly use one technique or another except otherwise stated. For brevity, we use 'GC' as a short-hand for 'tracing GC'; when we deal with other kinds of GC (e.g. reference counting), we explicitly name them.&lt;/p&gt;&lt;p&gt; We refer to memory which is allocated via &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; as being on the GC heap. We use the term 'GC value'
to refer both to the pointer wrapped in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; and the underlying value on the GC heap, even though
multiple pointers / wrappers can refer to a single value on the GC heap, unless doing so would lead to
ambiguity.
&lt;/p&gt;&lt;p&gt; We use 'Alloy' to refer to the combination of: our extension to the Rust language; our modifications to the &lt;code&gt;rustc&lt;/code&gt; compiler; and our integration of the Boehm-Demers-Weiser GC (BDWGC) into the runtime of
programs compiled with our modified &lt;code&gt;rustc&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;In this section we outline Alloy's basic design and implementation choices â the rest of the paper then goes into detail on the more advanced aspects.&lt;/p&gt;&lt;p&gt;Alloy provides a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; type that exposes an API modelled on the &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; type from Rust's
standard library, because &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;: is conceptually similar to &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;; widely used in Rust code, and
its API familiar; and that API reflects long-term experience about what Rust programmers
need.
&lt;/p&gt;&lt;p&gt; When a user calls &lt;code&gt;Gc::new(v)&lt;/code&gt;, the value &lt;code&gt;v&lt;/code&gt; is moved to the GC heap: the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; value returned
to the user is a simple wrapper around a pointer to &lt;code&gt;v&lt;/code&gt;'s new address. The same underlying
GCed value may thus have multiple, partly or wholly overlapping, references active at any
point. To avoid undermining Rust's ownership system, dereferencing a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; produces an
immutable (i.e. '&lt;code&gt;&amp;amp;&lt;/code&gt;') reference to the underlying value. If the user wishes to mutate the underlying
value, they must use other Rust types that enable interior mutability (e.g. &lt;code&gt;RefCell&amp;lt;T&amp;gt;&lt;/code&gt; or
&lt;code&gt;Mutex&amp;lt;T&amp;gt;&lt;/code&gt;).
&lt;/p&gt;&lt;p&gt; One feature that Alloy explicitly supports is the ability in Rust to cast references to raw pointers and back again. This can occur in two main ways. &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; can be dereferenced to &lt;code&gt;&amp;amp;T&lt;/code&gt; which can
then, as with any other reference, be converted to *const T (i.e. a C-esque pointer to T).
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; also supports the common Rust functions (&lt;code&gt;into_raw&lt;/code&gt; and &lt;code&gt;from_raw&lt;/code&gt;) which wrap the
value-to-pointer conversion in a slightly higher-level API. The ability to convert references to raw
pointers is used in many places (e.g. Rust's standard C Foreign Function Interface (FFI)).
We believe that a viable GC for Rust must allow the same conversions, but doing so has a
profound impact because Rust allows raw pointers to be converted to the integer type &lt;code&gt;usize&lt;/code&gt; and
back1.
&lt;/p&gt;&lt;p&gt;Having acknowledged that pointers can be 'disguised' as integers, it is then inevitable that Alloy must be a conservative GC: if a machine word's integer value, when considered as a pointer, falls within a GCed block of memory, then that block itself is considered reachable (and is transitively scanned). Since a conservative GC cannot know if a word is really a pointer, or is a random sequence of bits that happens to be the same as a valid pointer, this over-approximates the live set (i.e. the blocks that the GC will not reclaim). Typically the false detection rate is very low (see e.g. a Java study which measures it at under 0.01% of the live set [28]).&lt;/p&gt;&lt;p&gt;Conservative GC occupies a grey zone in programming language semantics: in most languages, and most compiler's internal semantics, conservative GC is, formally speaking, unsound; and furthermore some languages (including Rust) allow arbitrary 'bit fiddling' on pointers, temporarily obscuring the address they are referring to. Despite this, conservative GC is widely used, including in the two most widespread web browsers: Chrome uses it in its Blink rendering engine [1] and Safari uses it in its JavaScript VM JavaScriptCore [26]. Even in 2025, we lack good alternatives to conservative GC: there is no cross-platform API for precise GC; and while some compilers such as LLVM provide some support for GC features [23], we have found them incomplete and buggy. Despite the potential soundness worries, conservative GC thus remains a widely used technique.&lt;/p&gt;&lt;p&gt; Conservative GC enables Alloy to make a useful ergonomic improvement over most other GCs for Rust whose &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is only cloneable. Such types can be duplicated, but doing so requires
executing arbitrary user code. To make the possible run-time cost of this clear, Rust has no
direct syntax for cloning: users must explicitly call &lt;code&gt;Rc::clone(&amp;amp;v)&lt;/code&gt; to duplicate a value &lt;code&gt;v&lt;/code&gt;. In
contrast, since Alloy's &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is just a wrapper around a pointer it is not just cloneable but
also copyable: duplication only requires copying bytes (i.e. no arbitrary user code need be
executed). Copying is implied by assignment (i.e. &lt;code&gt;w = v&lt;/code&gt;), reducing the need for explicit
cloning2.
This is not just a syntactic convenience but also reflects an underlying semantic difference: duplicating a
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; in Alloy is is a cheaper and simpler operation than most other GCs for Rust which which tend to
rely, at least in part, on reference counting.
&lt;/p&gt;&lt;p&gt; There is one notable limitation of &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s API relative to &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;. The latter, by definition, knows how
many references there are to the underlying data, allowing the value stored inside it to be mutably
borrowed at run-time if there is only a single reference to it (via &lt;code&gt;get_mut&lt;/code&gt; and &lt;code&gt;make_mut&lt;/code&gt;). In contrast,
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; cannot know how many references there are to the underlying data. As we shall see in Section 8,
some Rust programs are built around the performance advantages of this API (e.g. turning 'copy on
write' into just 'write' in some important cases).
&lt;/p&gt;&lt;p&gt;The most visible aspect of Alloy is its fork, and extension of, the standard Rust compiler &lt;code&gt;rustc&lt;/code&gt;. We
forked &lt;code&gt;rustc&lt;/code&gt; 1.79.0, adding or changing approximately 5,500 Lines of Code (LoC) in the core compiler,
and adding approximately 2,250 LoC of tests.
&lt;/p&gt;&lt;p&gt; Alloy uses BDWGC [9] as the underlying conservative GC, because it is the most widely ported conservative GC we know of. We use BDWGC's &lt;code&gt;GC_set_finalize_on_demand(1)&lt;/code&gt; API, which causes
finalizers to be run on their own thread.
&lt;/p&gt;&lt;p&gt; We had to make some minor changes to BDWGC to suit our situation. First, we disabled BDWGC's parallel collector because it worsens Alloy's performance. It is unclear to us why this happens: we observe significant lock contention within BDWGC during GC collections, but have not correlated this with a cause. Second, BDWGC cannot scan pointers stored in thread locals because these are platform dependent. Fortunately, &lt;code&gt;rustc&lt;/code&gt; uses LLVM's thread local storage
implementation, which stores such pointers in the &lt;code&gt;PT_TLS&lt;/code&gt; segment of the ELF binary: we modified
BDWGC to scan this ELF segment during each collection. Third, BDWGC dynamically intercepts
thread creation calls so that it can can scan their stacks, but (for bootstrapping reasons) is
unable to do so in our context: we explicitly changed Alloy to register new threads with
BDWGC.
&lt;/p&gt;&lt;p&gt;In many GCed languages, 'destructor' and 'finalizer' are used as synonyms, as both terms refer to code run when a value's lifetime has ended. In existing GCs for Rust, these two terms refer to completely different hierarchies of code (i.e. destructors and finalizers are fundamentally different). In Alloy, in contrast, a reasonable first approximation is that finalizers are a strict subset of destructors. In this section we pick apart these differences, before describing the challenges of using destructors as finalizers.&lt;/p&gt;&lt;p&gt;When a value in Rust is dropped (i.e. at the point its owner goes out of lexical scope) its destructor is automatically run. Rust's destructors enable a style of programming that originated in C++ called RAII (Resource Acquisition Is Initialization) [30, Section 14.4]: when a value is dropped, the underlying resources it possesses (e.g. file handles or heap memory) are released. Destructors are used frequently in Rust code (to give a rough idea: approximately 15% of source-level types in our benchmark suite have destructors).&lt;/p&gt;&lt;p&gt; Rust destructors are formed of two parts, run in the following order: a user-defined drop method; and automatically inserted drop glue. Drop methods are optional and users can provide one for a type by implementing the &lt;code&gt;Drop&lt;/code&gt; trait's &lt;code&gt;drop&lt;/code&gt; method. Drop glue recursively calls destructors of contained types
(e.g. fields in a struct). Although it is common usage to conflate 'destructor' in Rust with drop methods,
drop glue is an integral part of a Rust destructor: we therefore use 'destructor' as the umbrella term for
both drop methods and drop glue.
&lt;/p&gt;&lt;p&gt; When considering finalizers for a GC for Rust, there are several layers of design choices. We will shortly see that finalizers cause a number of challenges (Section 4.1) and one choice would be to forbid finalizers entirely. However, this would mean that one could not sensibly embed types that have destructors in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. While Rust does not always call destructors, the situations where this occurs are
best considered 'exceptional': not calling destructors from &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; would completely undermine
reasonable programmer expectations. Because of this, Alloy, and indeed virtually all GCs for Rust,
support finalizers in some form.
&lt;/p&gt;&lt;p&gt; However, existing GCs force distinct notions of destructors and finalizers onto the programmer. Where the former have the &lt;code&gt;Drop&lt;/code&gt; trait, the latter typically have a &lt;code&gt;Finalize&lt;/code&gt; trait. If a user type needs to be
finalized then the user must provide an implementation of the &lt;code&gt;Finalize&lt;/code&gt; trait. However, doing so
introduces a number of problems: (1) external libraries are unlikely to provide finalizers, so they must be
manually implemented by each consumer; (2) Rust's orphan rule [27, Section 6.12] prevents one
implementing traits for types defined in external libraries (i.e. unless a library's types were designed to
support &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;, those types cannot be directly GCed); (3) one cannot automatically replicate drop glue
for finalizers; and (4) one cannot replicate &lt;code&gt;rustc&lt;/code&gt;'s refusal to allow calls to the equivalent of
&lt;code&gt;Drop::drop&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;Programmers can work around problems #1 and #2 in various ways. For example, they can wrap external library types in newtypes (zero-cost wrappers) and implement finalizers on those instead [20, Section 19.3]. Doing so is tedious but not conceptually difficult.&lt;/p&gt;&lt;p&gt; Problem #3 has partial solutions: for example, [14] uses the &lt;code&gt;Trace&lt;/code&gt; macro to generate finalizer glue (the
finalizer equivalent of drop glue) for struct fields. This runs into an unsolvable variant of problem #2:
types in external libraries will not implement this trait and cannot be recursively scanned for finalizer
glue.
&lt;/p&gt;&lt;p&gt; Problem #4 is impossible to solve in Rust as-is. One cannot define a function that can never be called â what use would such a function have? A possible partial solution might seem to be for the &lt;code&gt;finalize&lt;/code&gt;
method take ownership of the value, but &lt;code&gt;Drop::drop&lt;/code&gt; does not do so because that would not allow drop
glue to be run afterwards.
&lt;/p&gt;&lt;p&gt;4.1 General Challenges When Using Destructors as Finalizers&lt;/p&gt;&lt;p&gt;We have stated as our aim that Alloy should use destructors as finalizers. Above we explained some Rust-specific challenges â but there are several non-Rust-specific challenges too! Fundamentally, finalizers and destructors have different, and sometimes incompatible, properties. The best guide to these differences, and the resulting problems, is Boehm [6], supplemented by later work on support for GC in the C++ specification [8]3.&lt;/p&gt;&lt;p&gt;An obvious difference between destructors and finalizers is when both are run. While C++ and Rust define precisely when a destructor will be run4, finalizers run at an unspecified point in time. This typically happens at some point after the equivalent destructor would run, though a program may exit before any given finalizer is run5. There are, however, two situations which invert this. First, if a thread exits due to an error, and the program is either not compiled with unwinding, or the thread has crossed a non-unwinding ABI boundary, then destructors might not be run at all, where a GC will naturally run the equivalent finalizers: we do not dwell on this, as both behaviours are reasonable in their different contexts. Second, and more surprisingly, it is possible for finalizers in non-error situations to run prematurely, that is before the equivalent destructor [6, section 3.4].&lt;/p&gt;&lt;p&gt;A less obvious difference relates to where destructors and finalizers are run. Destructors run in the same thread as the last owner of a value. However, running finalizers in the same thread as the last owner of the value can lead to race conditions [24] and deadlocks [6, section 3.3] if a finalizer tries to access a resource that the mutator expects to have exclusive access too. When such problems affect destructors in normal Rust code, it is the clear result of programmer error, since they should have taken into account the predictable execution point of destructors. However, since finalizers do not have a predictable execution point, there is no way to safely access shared resources if they are run on the same thread. The only way to avoid this is to run finalizers on a non-mutator thread â but not all Rust types / destructors are safe to run on another thread.&lt;/p&gt;&lt;p&gt;There are several additional differences such as: finalizers can reference other GCed values that are partly, or wholly, 'finalized' and may have had their backing memory reused; and finalizers can resurrect values by copying the reference passed to the finalizer and storing it somewhere.&lt;/p&gt;&lt;p&gt;Over time, finalizers have thus come to be viewed with increasing suspicion. Java, for example, has deprecated, and intends eventually removing, per-type finalizers: instead it has introduced deliberately less flexible per-object 'cleaners', whose API prevents problems such as object resurrection and per-class finalization [13].&lt;/p&gt;&lt;p&gt;4.2 The Challenge of Finalizers for Alloy&lt;/p&gt;&lt;p&gt;At this point we hope to have convinced the reader that: a viable GC for Rust needs to be able to use existing destructors as finalizers whenever possible; but that finalizers, even in existing GCs, cause various problems.&lt;/p&gt;&lt;p&gt;It is our belief that some problems with finalizers are fundamental. For example, finalizers inevitably introduce latency between the last use of a value and its finalization.&lt;/p&gt;&lt;p&gt; Some problems with finalizers are best considered the accidental artefacts of older designs. Java's cleaners, for example, can be thought of as a more restrictive version of finalizers that allow most common use-cases but forbid by design many dangerous use cases. For example, per-class/struct finalization can easily be replaced by per-object/value finalization; and object resurrection can be prevented if object access requires a level of indirection. Alloy benefits from our better shared understanding of such problems and the potential solutions: it trivially addresses per-object/value finalization (&lt;code&gt;Gc::new_unfinalizable&lt;/code&gt; function turns finalization off
for specific values) and, as we shall see later, via only slightly more involved means, object
resurrection.
&lt;/p&gt;&lt;p&gt;However, that leaves many problems that are potentially in the middle: they are not obviously fundamental, but there are not obvious fixes for them either. In our context, where we wish to use destructors as finalizers, four problems have hitherto been thought insoluble [8, p. 32]: (1) finalizers are prohibitively slower than destructors; (2) finalizers can run prematurely; (3) running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks; (4) some safe destructors are not safe finalizers.&lt;/p&gt;&lt;p&gt;Fortunately for us, Rust's unusual static guarantees, suitably expanded by Alloy, allow us to address each problem in novel, satisfying, ways. In the following section, we tackle these problems in the order above, noting that we tackle problems #1 and #2 separately, and #3 and #4 together.&lt;/p&gt;&lt;p&gt;As we shall see in Section 8, there is a correlation between the number of finalizers that are run and overhead from GC (with a worst case, albeit a definite outlier, in our experiment of 3.35Ã slowdown). In this section we show how to reduce the number of finalizers that are run, which helps reduce this overhead.&lt;/p&gt;&lt;p&gt;A variety of factors contribute to the finalizer performance overhead, including: a queue of finalizers must be maintained, whereas destructors can be run immediately; finalizers run some time after the last access of a value, making cache misses more likely; and finalizers can cause values (including values they own) to live for longer (e.g. leading to increased memory usage and marking overhead). Most of these factors are inherent to any GC and our experience of using and working on BDWGCâ a mature, widely used GC â does not suggest that it is missing optimisations which would overcome all of this overhead.&lt;/p&gt;&lt;p&gt; Instead, whenever possible, Alloy elides finalizers so that they do not need to be run at all. We are able to do this because: (1) BDWGC is responsible for all allocations and will, if necessary GC allocations even if they are not directly wrapped in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;; and (2) many Rust destructors only free memory which
BDWGC would, albeit with some latency, do anyway.
&lt;/p&gt;&lt;p&gt; Consider the standard Rust type &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; which heap allocates space for a value; when a &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; value
is dropped, the heap allocation will be freed. We can then make two observations. First, &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;'s drop
method solely consists of a &lt;code&gt;deallocate&lt;/code&gt; call. Second, while we informally say that &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; allocates on
the 'heap' and &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; allocates on the 'GC heap', all allocations in Alloy are made through BDWGC and
stored in the same heap.
&lt;/p&gt;&lt;p&gt; When used as a finalizer, &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method is thus unneeded, as the underlying memory will be
freed by BDWGC anyway. This means that there is no need to run a finalizer for a type such as
&lt;code&gt;Gc&amp;lt;Box&amp;lt;u8&amp;gt;&amp;gt;&lt;/code&gt; at all, and the finalizer can be statically elided. However, we cannot elide a
finalizer for a type such as &lt;code&gt;Gc&amp;lt;Box&amp;lt;Rc&amp;lt;u8&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; because &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method must be run for the
reference count to be decremented. As this shows, we must consider the complete destructor, and
not just the top-level drop method, when deciding whether a corresponding finalizer can be
elided.
&lt;/p&gt;&lt;p&gt;5.1 Implementing Finalizer Elision&lt;/p&gt;&lt;p&gt;Finalizer elision statically determines which type's destructors do not require corresponding finalizers and elides them. It does so conservatively, and deals correctly with drop glue.&lt;/p&gt;&lt;p&gt; As shown in Algorithm 1, any type which implements the &lt;code&gt;Drop&lt;/code&gt; trait requires finalization unless it also
implements the new &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; marker trait (i.e. a trait without methods). This
trait can be used by a programmer to signify that a type's drop method need not be called if the type is
placed inside a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. The 'Drop' part of the trait name is deliberate (i.e. it is not a simplification of
'destructor') as it allows the programmer to reason about a type locally (i.e. without considering drop
glue or concrete type paramaters). If the type has a transitively reachable field whose type implements
the &lt;code&gt;Drop&lt;/code&gt; trait but not the &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; trait, then then the top-level type still
requires finalization.
&lt;/p&gt;&lt;p&gt; Even though neither normal Rust destructors or Alloy finalizers are guaranteed to run, a program whose destructors or finalizers never run would probably not be usable (leaking resources such as memory, deadlocking, and so on). We therefore make &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; an unsafe trait,
because implementing it inappropriately is likely to lead to undesired â though not incorrect! â
behaviour at run-time.
&lt;/p&gt;&lt;p&gt; Alloy modifies the standard Rust library to implement &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; on the following types:
&lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;Vec&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;RawVec&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;VecDeque&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;LinkedList&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;BTreeMap&amp;lt;K, V&amp;gt;&lt;/code&gt;, &lt;code&gt;BTreeSet&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;HashMap&amp;lt;K, V&amp;gt;&lt;/code&gt;, &lt;code&gt;HashSet&amp;lt;T&amp;gt;&lt;/code&gt;,
&lt;code&gt;RawTable&amp;lt;K, V&amp;gt;&lt;/code&gt;6,
and &lt;code&gt;BinaryHeap&amp;lt;T&amp;gt;&lt;/code&gt;. Fortunately, not only are these types' drop methods compatible with
&lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt;, but they are extensively used in real Rust code: they enable significant
numbers of finalizers to be elided.
&lt;/p&gt;&lt;p&gt; Listing 3 shows the new const compiler intrinsic &lt;code&gt;needs_finalizer&lt;/code&gt; we added to implement
Algorithm 1. The intrinsic is evaluated at compile-time: its result can be inlined into &lt;code&gt;Gc::new&lt;/code&gt;, allowing
the associated conditional to be removed too. In other words â compiler optimisations allowing â the
'does this specific type require a finalizer?' check has no run-time overhead.
&lt;/p&gt;&lt;p&gt;Most of us assume that finalizers are always run later than the equivalent destructor would have run, but they can sometimes run before [6, section 3.4], undermining soundness. Such premature finalization is also possible in Alloy as described thus far (see Listing 4). In this section we show how to prevent premature finalization.&lt;/p&gt;&lt;p&gt;There are two aspects to premature finalization. First, language specifications often do not define, or do not precisely define, when the earliest point that a value can be finalized is. While this means that, formally, there is no 'premature' finalization, it seems unlikely that language designers anticipated some of the resulting implementation surprises (see e.g. this example in Java [29]). Second, compiler optimisations â at least in LLVM â are 'GC unaware', so optimisations such as scalar replacement can change the point in a program when GCed values appear to be finalizable.&lt;/p&gt;&lt;p&gt; In our context, it is natural to define premature finalization as a (dynamic) finalizer for a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; value
running before the (static) &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; owner has gone out of scope. Similar to the high-level proposal mooted
in [7, Solution 1], we must ensure that the dynamic lifetime of a reference derived from a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; matches
or exceeds the lifetime of the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; itself.
&lt;/p&gt;&lt;p&gt; Our solution relies on adjusting &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method to keep alive a GCed value for at least the static
lifetime of the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; itself. In other words, we ensure that the conservative GC will always see a pointer
to a GCed value while the corresponding &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is in-scope.
&lt;/p&gt;&lt;p&gt; However, there is a major problem to overcome: copyable types such as &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; are forbidden from
having destructors. The fundamental challenge we have to solve is that each copied value will have a
destructor called on it, which has the potential for any shared underlying value to be destructed more
than once. Alloy explicitly allows &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; â but no other copyable type â to have a destructor, but to
ensure it doesn't cause surprises in the face of arbitrary numbers of copies, the destructor must be
idempotent. Our task is made easier because &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; naturally has no drop glue from Rust's perspective:
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; consists of a field with a pointer type, and such types are opaque from a destruction
perspective.
&lt;/p&gt;&lt;p&gt; We therefore only need to make sure that &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method is idempotent. Fortunately, this is
sufficient for our purposes: we want the drop method to inhibit finalization but that does not
require run-time side effects. To achieve this, we use a fence. These come in various flavours.
What we need is a fence that prevents both: the compiler from reordering computations
around a particular syntactic point; and the CPU from reordering computations around a
particular address. We copy the platform specific code from the BDWGC &lt;code&gt;GC_reachable_here&lt;/code&gt;
macro7
into &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method, which achieves the effect we require.
&lt;/p&gt;&lt;p&gt;6.1 Optimising Premature Finalizer Prevention&lt;/p&gt;&lt;p&gt;The drop method we add to &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; fully prevents premature finalization. It also naturally solves a
performance problem with the suggested solution for C++ in [7, Solution 1], which requires keeping
alive all pointers, no matter their type, for their full scope. By definition, our solution only
keeps alive &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; values: the compiler is free to optimise values of other types as it so wishes.
However, on an artificial microbenchmark we observed a noticeable overhead from our fence
insertion.
&lt;/p&gt;&lt;p&gt; We thus implemented a simple optimisation: we only insert fences for a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; if it has a finalizer.
Intuitively, it seems that we should not generate drop methods in such cases, but this is difficult to do
directly inside &lt;code&gt;rustc&lt;/code&gt;. Instead, we suppress calls to the drop methods of such types: the two approaches
are functionally equivalent, though ours does put an extra burden on dead-code elimination in the
compiler tool-chain.
&lt;/p&gt;&lt;p&gt; Alloy adds a new pass &lt;code&gt;RemoveElidableDrops&lt;/code&gt; to &lt;code&gt;rustc&lt;/code&gt;'s Mid-Level Intermediate Representation
(MIR) processing. MIR is best thought of as the main IR inside &lt;code&gt;rustc&lt;/code&gt;: it contains the complete set of
functions in the program, where each function consists of a sequence of basic blocks. Simplifying
somewhat, function and drop method calls are represented as different kinds of terminators on basic
blocks. Terminators reference both a callee and a successor basic block.
&lt;/p&gt;&lt;p&gt; The &lt;code&gt;remove_elidable_drops&lt;/code&gt; pass iterates over a program's MIR, identifies drop method
terminators which reference elidable finalizers, and turns them into 'goto' terminators to the
successor basic basic block. Algorithm 4 in the Appendix presents a more formal version of this
algorithm.
&lt;/p&gt;&lt;p&gt;In this section we address two high-level problems: running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks; and some safe destructors are not safe finalizers. Addressing the former problem is conceptually simple â finalizers must be run on a separate thread â but we must ensure that doing so is sound. We therefore consider this a specific instance of the latter problem, treating both equally in this section.&lt;/p&gt;&lt;p&gt;We therefore introduce Finalizer Safety Analysis (FSA), which prevents unsafe (in the sense of 'not safe Rust') destructors being used as finalizers. As a first approximation, FSA guarantees that finalizers are memory safe, cycle safe (i.e. do not access already finalized objects), and thread safe. We present the three main components of FSA individually before bringing them together.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; can store, directly or indirectly, normal Rust references (i.e. &lt;code&gt;&amp;amp;&lt;/code&gt; and &lt;code&gt;&amp;amp;mut&lt;/code&gt;), at which point it is
subject to Rust's normal borrow checker rules and cannot outlive the reference. However, finalizers
implicitly extend the lifetime of a GCed value, including any stored references: accessing a reference in a
finalizer could undermine Rust's borrow checking rules.
&lt;/p&gt;&lt;p&gt; A simple way of avoiding this problem is to forbid &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; from storing, directly or indirectly,
references. This might seem to be no great loss: storing references in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; largely nullifies the
'GCness' of &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. However, we found the result hard to use, as it can make simple tasks such as
gradually migrating existing code to use &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; painful.
&lt;/p&gt;&lt;p&gt; A moderate, but in our experience insufficient, relaxation is to recognise that only types that need a finalizer can possibly have problems with references, and to forbid such types from storing references in &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. For example, if there is no drop method for &lt;code&gt;struct S{x: &amp;amp;u8}&lt;/code&gt;
then its destructor is safe to use as a finalizer, since its non-drop aspects will not use the &lt;code&gt;&amp;amp;u8&lt;/code&gt;
reference.
&lt;/p&gt;&lt;p&gt; The eventual rule we alighted upon for FSA is that a destructor for a type &lt;code&gt;T&lt;/code&gt; can be used as a
finalizer provided the destructor's drop methods do not obtain references derived from &lt;code&gt;T&lt;/code&gt;'s
fields (including fields reachable from its attributes). Using Rust's terminology, we forbid
projections (which include a struct's fields, indexes into a vector, and so on) in destructors from
generating references. Any non-projection references that are used in a destructor are by
definition safe to use, as they either exist only for the duration of the drop method (references to
variables on the stack) or will exist for the remainder of the program (references to global
variables).
&lt;/p&gt;&lt;p&gt;This rule over-approximates the safe set of destructors. For example, a drop method that creates a new value and tries to obtain a reference to a field in it (i.e. a projection) cannot be a destructor under FSA, even though the reference cannot outlast the drop method. We found that attempting to relax our rule further to deal with such cases rapidly complicates exposition and implementation.&lt;/p&gt;&lt;p&gt;One of the main motivations for GCs is that they solve problems with cyclic data structures. However, finalizers can be unsound if they access state shared within members of a cycle. Listing 5 shows an example of undefined behaviour when two GCed values create a cycle and both their finalizers reference the other GCed value. Whichever order the finalizers are run in, at least one of the finalizers will see the other GCed value as partly or wholly 'finalized'.&lt;/p&gt;&lt;p&gt;Most languages and systems we are aware of assume that users either don't run into this problem (finalization cycles are considered rare in GCed languages [19, p. 229]) or know how to deal with it when they do (e.g. refactoring the types into parts that do and don't require finalization [6, p. 11]). There is no fully automatic solution to this problem. Some GCs offer weak references, which allow users to detect when finalization cycles have been broken, though they still have to deal with the consequences manually.&lt;/p&gt;&lt;p&gt; We wanted to provide users with static guarantees that their destructors will not behave unexpectedly when used as finalizers in a cycle. A first attempt at enforcing such a property might seem to be that a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; cannot have, directly or indirectly, fields of type &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. This would indeed
prevent the mistakes we want to catch but also disallow shared ownership! We therefore
check only that a type's destructor does not, directly or indirectly, access a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. This allows
GCed types to express shared ownership so long as their destructor(s) do not access other GC
types.
&lt;/p&gt;&lt;p&gt; To make this check easier to implement, we introduce an auto trait [27, Section. 11], a kind of marker trait that the compiler propagates automatically. An auto trait &lt;code&gt;A&lt;/code&gt; will be automatically implemented for a
type &lt;code&gt;T&lt;/code&gt; unless one of the following is true: there is an explicit negative implementation of &lt;code&gt;A&lt;/code&gt; for &lt;code&gt;T&lt;/code&gt;; or &lt;code&gt;T&lt;/code&gt;
contains a field that is not itself &lt;code&gt;A&lt;/code&gt;. Informally, we say that a negative implementation of an auto-trait
pollutes containing types.
&lt;/p&gt;&lt;p&gt; Our new auto trait is called &lt;code&gt;FinalizerSafe&lt;/code&gt;, and we provide a single negative implementation
&lt;code&gt;impl&amp;lt;T&amp;gt; !FinalizerSafe for Gc&amp;lt;T&amp;gt;&lt;/code&gt;. This naturally handles transitively reachable code, allowing FSA
itself to only check that a destructor's direct field accesses are &lt;code&gt;FinalizerSafe&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;7.3 Destructors Need to be Runnable on a Finalizer Thread&lt;/p&gt;&lt;p&gt;Running finalizers on the same thread as a mutator can cause problems when the finalizer accesses state shared with the mutator (see Section 4.1 for a general description and Listing 6 for a concrete example). The most general solution to this problem is to run finalizers on a separate finalizer thread that never runs mutator code.&lt;/p&gt;&lt;p&gt; We must therefore ensure that it is safe to run a type's destructor on the finalizer thread. A conservative definition is that &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is safe to use if &lt;code&gt;T&lt;/code&gt; implements both of Rust's existing &lt;code&gt;Send&lt;/code&gt; (denoting
a type that can be permanently moved from one thread to another) and &lt;code&gt;Sync&lt;/code&gt; (denoting a type that can be
safely accessed simultaneously by multiple threads) auto traits. However, requiring that finalization be
restricted to types that implement both &lt;code&gt;Send&lt;/code&gt; and &lt;code&gt;Sync&lt;/code&gt; can be frustrating, particularly because more
types implement &lt;code&gt;Send&lt;/code&gt; than &lt;code&gt;Sync&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; It may seem sufficient for &lt;code&gt;T&lt;/code&gt; to implement &lt;code&gt;Send&lt;/code&gt; alone so that the value can be safely sent to the finalizer
thread. However, this would not prevent a finalizer indirectly accessing state shared with a
non-GCed value via a mechanism such as &lt;code&gt;Arc&lt;/code&gt;, causing the very problems we are trying to
avoid.
&lt;/p&gt;&lt;p&gt; FSA thus ignores whether a type implements &lt;code&gt;Send&lt;/code&gt; or &lt;code&gt;Sync&lt;/code&gt; (or not) and instead examines the
destructor directly. To pass FSA: the destructor must not access thread locals; and any types the
destructor accesses via projections must implement both &lt;code&gt;Send&lt;/code&gt; and &lt;code&gt;Sync&lt;/code&gt;. Intuitively, this allows a
non-&lt;code&gt;Send&lt;/code&gt;-or-&lt;code&gt;Sync&lt;/code&gt; type &lt;code&gt;T&lt;/code&gt; to have a safe finalizer provided that &lt;code&gt;T&lt;/code&gt;'s destructor only access the &lt;code&gt;Send&lt;/code&gt; and
&lt;code&gt;Sync&lt;/code&gt; 'subset' of &lt;code&gt;T&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; This rule shows clearly that FSA is a form of abstract interpretation rather than a mere extension of the type system8. After careful examination we believe this is compatible with Rust's semantics (and &lt;code&gt;rustc&lt;/code&gt; and LLVM's
implementations) at the time of writing, but it is worth knowing that this rule would be unsafe in other
languages and implementations (for example our assumption would be unsafe in Java due to
synchronisation removal [31]). We leave it as an open question to others as to whether Rust should
deliberately permit or forbid such checks in its semantics.
&lt;/p&gt;&lt;p&gt;The implementation of the finalization thread is fairly simple. For example, we do not need to explicitly synchronise memory between the mutator and finalization threads because BDWGC's stop-the-world collection phase already synchronises all memory between threads.&lt;/p&gt;&lt;p&gt; FSA integrates the seemingly separate components presented above into one. It iterates over every function in a Rust program analysing destructors of types that are used in &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. Algorithm 2 shows the
essence of FSA (for example eliding details of caching which Alloy uses to speed up compile
times).
&lt;/p&gt;&lt;p&gt; Because FSA is a form of abstract interpretation, we need to determine when to run FSA on a program. In essence, whenever a previously unchecked type &lt;code&gt;T&lt;/code&gt; is used to create a new &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;, FSA is run. As well as
the &lt;code&gt;Gc::new&lt;/code&gt; constructor, &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; instances can be created with conversion traits such as &lt;code&gt;From&lt;/code&gt;. We
annotated each such entry point with a new &lt;code&gt;rustc&lt;/code&gt;-only attribute &lt;code&gt;rustc_fsa_entry_point&lt;/code&gt;: calls to
functions with this attribute lead to FSA checks.
&lt;/p&gt;&lt;p&gt; A naive implementation of FSA would be a notable cost, so Alloy uses several optimisations. As alluded to above, FSA caches the results of various checks to avoid pointlessly repeating work. We also extend &lt;code&gt;FinalizerSafe&lt;/code&gt; with negative implementations for &lt;code&gt;&amp;amp;T&lt;/code&gt;, and &lt;code&gt;&amp;amp;mut T&lt;/code&gt;. If a type &lt;code&gt;T&lt;/code&gt; implements all of
&lt;code&gt;FinalizerSafe&lt;/code&gt;, &lt;code&gt;Send&lt;/code&gt;, and &lt;code&gt;Sync&lt;/code&gt;, we know that there can be no unsafe projections used in a destructor,
and can bypass most FSA checks entirely (though we still need to check for thread local accesses).
Across our benchmark suite, FSA increases compilation time in release mode by a modest
0.8â1.6%.
&lt;/p&gt;&lt;p&gt; Algorithm 2 also captures Alloy's approach to error messages. Rather than just inform a user that 'your drop method has not passed FSA', Alloy pinpoints which field or line in a drop method caused FSA to fail: &lt;code&gt;EmitReferenceError&lt;/code&gt; informs the user when a reference in a type is used in a way that violates
FSA (see Section 7.1); and &lt;code&gt;EmitFinalizerUnsafeError&lt;/code&gt; when a drop method contains code which is
unsafe (e.g. references a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; type, an opaque function, etc.). Listing 7 shows an example of the errors
reported by Alloy: note that it pinpoints the line within a drop method that caused an FSA
error.
&lt;/p&gt;&lt;p&gt;7.4.1 Awkward Kinds of Functions&lt;/p&gt;&lt;p&gt;FSA can encounter two kinds of 'awkward' functions.&lt;/p&gt;&lt;p&gt; First, some functions (e.g. due to use of trait objects, or FFIs) do not have a body available when FSA runs: using such a function necessarily causes an FSA check to fail. One common class of functions which causes this are Rust intrinsics (e.g. &lt;code&gt;min_align_of&lt;/code&gt; etc.): we audited the most frequently used of
these and annotated those which are FSA-safe with a new &lt;code&gt;rustc_fsa_safe_fn&lt;/code&gt; attribute. Other functions
whose bodies are unknown cause FSA to fail.
&lt;/p&gt;&lt;p&gt; Second, in most cases, FSA runs on Rust functions whose generic types have been replaced with concrete types (in Rust terminology, functions have been 'monomorphised'). Sometimes, however, FSA encounters functions (e.g. intrinsics or functions with certain annotations) whose generic types have not yet been replaced. FSA can still run on such functions, but will reject them unless all generic types imply the &lt;code&gt;FinalizerSafe&lt;/code&gt;, &lt;code&gt;Send&lt;/code&gt;, and &lt;code&gt;Sync&lt;/code&gt; traits. Note that calling a method on a generically typed value will
lead to FSA finding a method without a body: as in the first case above, this will cause FSA to
fail.
&lt;/p&gt;&lt;p&gt; The common theme to both is that we wish FSA to be sound, at which point we forego completeness. This can cause users frustration when FSA raises an error on code they know is FSA safe. As is common in Rust, we therefore provide an unsafe escape hatch which allows users to silence FSA errors when they can prove to their satisfaction that doing so does undermine correctness. We experimented with a per-type approach, but found that unduly restrictive: we therefore provide a per-value escape hatch with the &lt;code&gt;unsafe FinalizerUnchecked&amp;lt;T&amp;gt;&lt;/code&gt; type. Values wrapped in this type are
considered safe to use at all points in FSA. Our aim is that users should rarely need to resort to this
escape hatch, but, as is not uncommon in Rust, there are valid idioms of use where we found it
necessary.
&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Version&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;cell role="head"&gt;#benchmarks&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;Debian CLBG Rust#2&lt;/cell&gt;&lt;cell&gt;Heap allocation microbenchmark&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;Debian CLBG Rust#1&lt;/cell&gt;&lt;cell&gt;Regular expression matching&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;v0.15.0-dev&lt;/cell&gt;&lt;cell&gt;Terminal emulator&lt;/cell&gt;&lt;cell&gt;10&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;v9.0.0&lt;/cell&gt;&lt;cell&gt;Unix find replacement&lt;/cell&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;v0.13.4&lt;/cell&gt;&lt;cell&gt;Lexer / parser library&lt;/cell&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;v14.1.1&lt;/cell&gt;&lt;cell&gt;Fast grep replacement&lt;/cell&gt;&lt;cell&gt;13&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;git #35b780&lt;/cell&gt;&lt;cell&gt;SOM AST VM&lt;/cell&gt;&lt;cell&gt;26&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;git #35b780&lt;/cell&gt;&lt;cell&gt;SOM bytecode VM&lt;/cell&gt;&lt;cell&gt;26&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;, etc.). Binary Trees and Regex-Redux are classic
stand-alone GC benchmarks; the other 'benchmarks' represent benchmark suites (e.g. Ripgrep contains 13
benchmarks). The middle portion of the table shows a variety of 'normal' Rust programs; the bottom portion
of the program shows three implementations of the SOM programming language.&lt;p&gt;In this section we explain our methodology and our experimental results.&lt;/p&gt;&lt;p&gt;There is no existing benchmark suite for GCs for Rust. Even if such a suite did exist, it may not have been suitable for our purposes because in experiment EGCvs we want to compare programs using existing shared ownership approaches. We searched through roughly the 100 most popular Rust libraries on &lt;code&gt;crates.io&lt;/code&gt; (the de facto standard Rust package system) looking for suitable candidates. In
practise this meant we looked for crates using reference counting. In the interests of brevity,
for the rest of this section we use '&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;' to cover both &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; and its thread-safe cousin
&lt;code&gt;Arc&amp;lt;T&amp;gt;&lt;/code&gt;.
&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell role="head"&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell role="head"&gt;Weak&amp;lt;T&amp;gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;107&lt;/cell&gt;&lt;cell&gt;9,450&lt;/cell&gt;&lt;cell&gt;1,970&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;cell&gt;421&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;299&lt;/cell&gt;&lt;cell&gt;1,825&lt;/cell&gt;&lt;cell&gt;23&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;108&lt;/cell&gt;&lt;cell&gt;109&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;104&lt;/cell&gt;&lt;cell&gt;249&lt;/cell&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;206&lt;/cell&gt;&lt;cell&gt;35&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;464&lt;/cell&gt;&lt;cell&gt;39&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;, we also show
how many weak references are left in: this is a proxy both for partial porting, and also how the extent weak
references. This is a proxy for the extent of changes that cyclic data-structures impose upon source code.&lt;p&gt;Table 1 shows the resulting suite: note that, except for Binary Trees and Regex-Redux, the 'benchmarks' are themselves benchmark suites. Collectively, our suite contains â depending on whether you count the SOM implementations' (identical) benchmark suites collectively or separately â 62 or 88 benchmarks. Table 2 shows how often relevant types are used after porting. Table 3 shows the distribution of heap data at run-time. This shows that our suite contains benchmarks with a variety of memory patterns.&lt;/p&gt;&lt;p&gt; Binary Trees is allocation intensive and sufficiently simple that it can be easily and meaningfully ported to additional shared ownership strategies: Rust-GC, a user library for GC for Rust [14]; and &lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt;, a non-GC memory arena [10]. Alacritty, fd, and Ripgrep are well known Rust programs, all
of which have their own benchmark suites. grmtools is a parsing library which uses &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; extensively
in error recovery: we benchmarked it using 28KLoC of real Java source code, which we mutated with
syntax errors.
&lt;/p&gt;&lt;p&gt; SOM is a small, but complete, language in the Smalltalk mould, which has a wide variety of implementations. Our suite includes two of these: som-rs-ast (which represents programs as ASTs); and som-rs-bc (which represents programs as bytecode). Both are existing ports of a Java SOM VM into Rust and use &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;. We use the same SOM &lt;code&gt;core-lib&lt;/code&gt; benchmarks for both, derived from git commit
#afd5a6.
&lt;/p&gt;&lt;p&gt; We were not able to port all parts of all programs. In particular, some programs make extensive use of the &lt;code&gt;make_mut&lt;/code&gt; and &lt;code&gt;get_mut&lt;/code&gt; functions in &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;, which allow a programmer to mutate their contents if, at
run-time, they only have a single owner. There is not, and cannot be, equivalent functionality with a
copyable &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; type. In some cases we were able to successfully use alternative mechanisms. In others
we judged the usages to either be rare at run-time (i.e. not worth porting), or too difficult to port (i.e. too
much of the program is built around the resulting assumptions). In a small number of cases we
ended up introducing bugs. Alacritty's UTF-8 support is an example, resulting in deadlocks.
Whenever we encountered a bug in our porting, we reverted back to &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; for that portion of the
port.
&lt;/p&gt;&lt;table&gt;&lt;row span="5"&gt;&lt;cell role="head"&gt;Allocated (#)&lt;/cell&gt;&lt;cell role="head"&gt;GC owned (%)&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Box&amp;lt;T&amp;gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;125&lt;/cell&gt;&lt;cell&gt;8,770&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;2.70&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;3,222,201&lt;/cell&gt;&lt;cell&gt;3,222,190&lt;/cell&gt;&lt;cell&gt;100.00&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;17,821&lt;/cell&gt;&lt;cell&gt;306,902&lt;/cell&gt;&lt;cell&gt;61&lt;/cell&gt;&lt;cell&gt;1.23&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;2,283&lt;/cell&gt;&lt;cell&gt;19,859,431&lt;/cell&gt;&lt;cell&gt;4,038,605&lt;/cell&gt;&lt;cell&gt;44.19&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;45&lt;/cell&gt;&lt;cell&gt;3,132&lt;/cell&gt;&lt;cell&gt;78&lt;/cell&gt;&lt;cell&gt;15.39&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;12,786&lt;/cell&gt;&lt;cell&gt;521,366&lt;/cell&gt;&lt;cell&gt;26,069&lt;/cell&gt;&lt;cell&gt;17.97&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;15&lt;/cell&gt;&lt;cell&gt;8,586,976&lt;/cell&gt;&lt;cell&gt;1,533,728&lt;/cell&gt;&lt;cell&gt;76.95&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;15&lt;/cell&gt;&lt;cell&gt;2,397,931&lt;/cell&gt;&lt;cell&gt;1,530,325&lt;/cell&gt;&lt;cell&gt;99.71&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; values. For example, a program consisting of a single &lt;code&gt;Gc&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; would have a
'GC Owned' value of 100% because the &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; is owned by the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. As we shall see later, there can be a
number of knock-on effects when a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; owns other such values.&lt;p&gt;8.1.2 What We Couldn't Include in the Benchmark Suite&lt;/p&gt;&lt;p&gt;We tried porting 10 other programs that are not included in our benchmark suite. To avoid readers wondering if we have 'cherry-picked' our eventual benchmark suite, we briefly report why those other programs have been excluded. All excluded benchmarks are shown in Table 4 in the Appendix.&lt;/p&gt;&lt;p&gt;Several programs (e.g. numbat, mini-moka, and salsa), once ported, turned out to be uninteresting from a GC benchmarking perspective. Irrespective of the number of source locations that reference memory allocation types, the benchmarks we could run from them allocated sufficiently little memory that there are no worthwhile differences between different allocation strategies. Put another way: these programs are in a sense 'the same' from our evaluation perspective.&lt;/p&gt;&lt;p&gt; Two programs (bevy and rust-analyzer) did not run correctly after porting. Both extensively use the &lt;code&gt;make_mut&lt;/code&gt; or &lt;code&gt;get_mut&lt;/code&gt; functions in &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; and reverting those changes made the benchmarks
uninteresting.
&lt;/p&gt;&lt;p&gt; We also ported RustPython, but were unable to adjust it to faithfully implement Python-level destructors. In essence, in RustPython's default configuration, its representation of objects is not compatible with FSA. This means that we can not run Python &lt;code&gt;__del__&lt;/code&gt; methods in the
finalizer thread. Although technically this is still compatible with Python's semantics, we
felt this would be a misleading comparison, as our port of RustPython would be doing less
work.
&lt;/p&gt;&lt;p&gt;Our experiment can be seen as a comparison of Alloy against 'normal' Rust. Fortunately, Alloy is a strict superset of 'normal' Rust: only if users explicitly opt into GC does Alloy really become a 'GC for Rust'. This allows us to use the same compiler, standard library, and so on, removing several potential confounding factor in our results. We compile two binaries: one without logging features compiled and one with. We only use the latter when reporting collector related metrics.&lt;/p&gt;&lt;p&gt; A challenge in our experiment is that different allocation strategies can use different underlying allocators. In particular, Alloy has to use BDWGC, but, for example, &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; can use a modern allocator
such as jemalloc. Much has changed in the performance of allocators since BDWGC's 1980s roots: in
&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;-only benchmarks, we observe an inherent overhead from BDWGC of 2â26% relative to jemalloc
(see Table 6 in the Appendix), which is a significant, and variable, confounding factor. Fortunately,
BDWGC can be used as a 'traditional' allocator that allocates and frees on demand (i.e. no
conservative GC occurs): in the main experiment, we thus use BDWGC as the allocator for all
benchmarks.
&lt;/p&gt;&lt;p&gt;We want to understand the memory usage of different allocation strategies over the lifetime of a benchmark. However, there is no single metric which captures 'memory usage', nor even an agreed set of metrics [5]. We use two metrics to capture different facets: (1) heap footprint, the amount of live heap memory recorded by by Heaptrack [34] at every allocation and deallocation; and (2) Resident Set Size (RSS), the total physical memory in RAM used by the process (including memory-mapped files, stack, and code/text segments), sampled at 10Hz. The overhead of recording heap footprint is much greater than RSS, but it provides a more detailed view of memory usage.&lt;/p&gt;&lt;p&gt;Another pair of confounding factors are the initial and maximum sizes of the GC heap: too-small values can lead to frequent resizing and/or 'thrashing'; large values to unrealistically few collections. What 'small' and 'large' are varies by benchmark, and 'careful' (or thoughtless) choices can significantly distort one's view of performance. BDWGC uses an adaptive strategy by default, growing the heap size as it detects that it would benefit from doing so. To give some sense of whether a different strategy and/or heap size would make a difference, we ran our benchmarks with three different fixed heap sizes. Doing so either has little effect or speeds benchmarks up; when it does so, the impact is generally under 10% and is at most 28% (the detailed results are presented in Table 9 in the Appendix). Broadly speaking, this suggests that BDWGC's default heap sizing approach, at least in our context, is not significantly distorting our view of performance.&lt;/p&gt;&lt;p&gt; We ran each benchmark in our suite 30 times. We report wall-clock times as returned by the standard Unix &lt;code&gt;time&lt;/code&gt; utility. The SOM benchmarks are run using its conventional rebench
tool; we adjusted rebench to use &lt;code&gt;time&lt;/code&gt; for consistency with our other benchmarks. We ran
all benchmarks on an AMD EPYC 7773X 64-Core 3.5GHz CPU with 128GiB RAM, running
Debian 12 ('bookworm'). We turned off turbo boost and hyper-threading, as both can colour
results.
&lt;/p&gt;&lt;p&gt;Except where otherwise stated, we report means and 99% confidence intervals for all metrics. We use the arithmetic mean for individual benchmarks and the geometric mean for benchmark suites.&lt;/p&gt;&lt;p&gt;When plotting time-series (i.e. sampled) memory metrics, we face the challenge that different configurations of the same benchmark can execute at different speeds. We thus resample each benchmark's data to 1000 evenly spaced points using linear interpolation. We chose 1000 samples because it is considerably above the visual resolution of our plots. After normalization, we calculate the arithmetic mean of the memory footprint measurement at each grid point (and not the raw underlying data) across all runs of the same benchmark. We record 99% confidence intervals at each point and show the result as shaded regions around the mean.&lt;/p&gt;&lt;p&gt;The main results for EGCvs can be seen in Fig. 1. Though there is variation, Alloy has an overhead on wall-clock time of 5% on our benchmark suite. The effect on memory is more variable though, unsurprisingly, Alloy typically has a larger average heap footprint (i.e. allocated memory lives for longer). This metric needs to treated with slight caution: benchmarks which allocate relatively small amounts of memory (see Table 3) can make the relative effect of average heap footprint seem much worse than it is in absolute terms.&lt;/p&gt;&lt;p&gt; Binary Trees is sufficiently simple that we also used it to compare against &lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt; and Rust-GC.
The time-series data in Fig. 2 is particularly illuminating (for completeness, Table 5 in the Appendix has
the raw timings). Alloy is around 3.5Ã slower than &lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt;. The time-series data for the latter shows it
going through distinct phases: a (relatively long) allocation phase, a (relatively moderate) 'work' phase,
and a (relatively short) deallocation phase. Put another way: these clear phases make Binary Trees a
perfect match for an arena. In the other approaches, the 'work' phase occupies a much greater proportion
of their execution, because it also incorporates allocator work. Alloy is around 1.3Ã faster than &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;,
but both have similar memory profiles. Alloy is around 3Ã faster than Rust-GC and has an
average heap footprint around 4Ã smaller, reflecting Alloy's advantage in not being a user-land
library that relies in part on &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;. Although we caution against over-interpreting a single
benchmark, this does give us at least some idea of the performance ceiling and floor for different
approaches.
&lt;/p&gt;&lt;p&gt; The time-series data in Fig. 2 helps explain other factors. For example, it shows that som-rs-bc leaks memory on the JSON Small benchmark (we suspect it also leaks in some other benchmarks, though rarely as visibly). This is because &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; keeps alive values in cycles; Alloy does not leak memory on
som-rs-bc, as it naturally deals correctly with cycles.
&lt;/p&gt;&lt;p&gt; We can see from the time-series data that Ripgrep has a complex heap footprint pattern. This may suggest a memory leak, but in fact it is a consequence of the inevitable delay in freeing memory in a GC. In general, GC notices that memory is unused later than reference counting, but this is exacerbated further by finalizers. Surprisingly, finalizers can lengthen or shorten an allocation's lifetime. GCed values with finalizers tend to have longer lifetimes, because they have to wait in the finalizer queue. However, when a finalizer calls &lt;code&gt;free&lt;/code&gt; on
indirectly owned values, those are immediately marked as not live, rather than having to
wait until the next collection to be discovered as such. This, albeit indirectly, explains the
seemingly random peaks and troughs in memory usage one can observe in Ripgrep's time-series
data.
&lt;/p&gt;&lt;p&gt; The results of EElision are shown in Fig. 3. In general, there is a fairly clear correlation: the more finalizers are removed, and the greater the proportion of the overall heap the memory owned by &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is,
the better the metrics become. However, there are several caveats. First, when all finalizers are removed,
BDWGC does not start a finalizer thread or invoke locking related to it, unduly flattering the time-based
metrics. Second, the quantity of finalizers is only a partial proxy for cost: some finalizers free
up large graphs of indirectly owned values, which can take some time to run. Third, some
benchmarks change the work they do: grmtools speeds up so much that its error recovery
algorithm has time to do more work, so while finalizer hugely benefits its GC pause time,
its wall-clock time changes much less. Finally, since finalizers can cause indirectly owned
allocations to be freed earlier than the GC itself does naturally, removing them can cause
indirectly owned values to live for longer: Ripgrep's average heap footprint highlights this
issue.
&lt;/p&gt;&lt;p&gt;The results for EPremOpt are shown in Fig. 4. We created three configurations of Alloy. None has no fences, and thus is unsound, but allows us to approximate (allowing for possible vagaries from running unsound code!) the best possible outcome. Naive inserts all possible fences. Optimised inserts only necessary fences. Once confidence intervals are taken into account, there are no statistically significant results for this experiment. Although it is possible that benchmarking 'noise' is hiding a meaningful result, our data suggests that any such differences are likely to be minimal. To make up for this disappointment, the fact that there is no difference between any of these suggests that, on non-artificial benchmarks, premature finalizer prevention is not a noticeable cost.&lt;/p&gt;&lt;p&gt; Any performance judgements we make are necessarily contingent on our methodology the benchmark suite we chose, including the proportion of benchmarks that we ported, and the way we process and present data. For example, we did not port external libraries to use &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; so many benchmarks use a
variety of allocation strategies. Even had we ported everything, we would not be able to say, for example,
that finalizer elision will always improve performance by exactly the factor we see in our experiment:
there undoubtedly exist reasonable, non-pathological, programs which will see performance changes
outside the ranges that our results suggest.
&lt;/p&gt;&lt;p&gt;Using BDWGC as the allocator for all benchmarks has the advantage of removing 'pure' allocator performance as a confounding factor, but does mean that some of the performance characteristics of benchmarks will be changed (e.g due to the portion of time we spend in the allocator; or BDWGC's adaptive heap sizing strategy). A generic, modern conservative GC, using the insights of recent non-GC allocators, would almost certainly give different â though we suspect not profoundly different â results. To the best of our knowledge there is currently no production-quality modern, generic conservative, GC we could use instead, though we are aware of at least one attempt to create such an alternative: it will be interesting to rerun our experiments if and when that arrives.&lt;/p&gt;&lt;p&gt;The RSS memory metric we collect is at Linux's whim: if it does not update as frequently as we expect, we will see artificially 'smoothed' data that may miss out peaks and troughs. Similar, our interpolation of time-series data onto a normalised grid can also smooth data. We manually checked a large quantity of data to ensure this was not a significant effect; by running benchmarks 30 times means it is also less more likely that peaks and troughs are caught at least sometimes.&lt;/p&gt;&lt;p&gt;In this paper we hope to have given sufficient background on GC and the use of destructors and finalizers in general. In this section we mostly survey the major parts of the GC for Rust landscape more widely. Our survey is inevitably incomplete, in part because this is a rapidly evolving field (a number of changes have occurred since the most recent equivalent survey we are aware of [16]). We also cover some relevant non-Rust GC work not mentioned elsewhere.&lt;/p&gt;&lt;p&gt; Early versions of Rust had 'managed pointers' (using the &lt;code&gt;@T&lt;/code&gt; syntax) which were intended to
represent GC types [16]. The core implementation used reference counting though there
were several, sometimes short-lived, cycle detectors [17]. Managed pointer support was
removed9 
around a year before the first stable release of Rust. This was not the end of the story for
'GC as a core part of Rust', with core Rust developers exploring the problem space in more
detail [15, 21, 22]. Over time these efforts dwindled, and those interested in GC for Rust largely
moved from anticipating &lt;code&gt;rustc&lt;/code&gt; support to expecting to have to do everything in user-level
libraries.
&lt;/p&gt;&lt;p&gt; One of the earliest user-level GC for Rust libraries is Bacon-Rajan-CC [12]. This provides a type &lt;code&gt;Cc&amp;lt;T&amp;gt;&lt;/code&gt;
which is similar in intention to Alloy's &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. The mechanism by which objects are collected is rather
different: they have a naive reference count, which causes objects outside a cycle to have deterministic
destruction; and users can manually invoke a cycle detector, which uses trial deletion in the style of Bacon and
Rajan [4]10 
to identify objects in unused cycles. Cycle detection requires users manually implementing a &lt;code&gt;Trace&lt;/code&gt; trait
which traverses a type's fields. Destructors are used as finalizers: to avoid the problems with Rust
references we solved in Section 7.1, Bacon-Rajan-CC imposes a &lt;code&gt;T:'static&lt;/code&gt; lifetime bound on the type
parameter passed to &lt;code&gt;Cc&amp;lt;T&amp;gt;&lt;/code&gt;. Simplifying slightly, this means that any references in such a type must be
valid for the remaining lifetime of the program, a severe restriction. Unlike our approach to the access of
already-finalized values (Section 7.2), it can only detect such accesses at runtime, leading to a (safe) Rust
&lt;code&gt;panic&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; Probably the best known GC for Rust is Rust-GC [14] (partly covered in Section 4). Rust-GC's &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;
provides a similar API to Alloy, with the notable exception that its &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is not, and cannot be, copyable,
thus always requiring calls to &lt;code&gt;Gc::clone&lt;/code&gt;. Although, like Alloy, Rust-GC allows &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; values to be
converted into pointers, its lack of conservative GC means that users must ensure that a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; wrapper
is kept alive for the entire lifetime of pointers derived from it. Similarly to Bacon-Rajan-CC,
GCed values are reference counted, with occasional tracing sweeps to identify cycles, though
Rust-GC performs cycle detection automatically (i.e. it doesn't require manual calls to a
function such as &lt;code&gt;collect_cycles&lt;/code&gt;). Drop methods are not used as finalizers: if a finalizer is
required, a manual implementation of the &lt;code&gt;Finalize&lt;/code&gt; trait must be provided; finalizer glue can be
largely, though not fully (see Section 4), automatically created by the provided &lt;code&gt;Trace&lt;/code&gt; macro.
Rust-GC detects accesses to already-finalized values dynamically at run-time, panicking
if they occur. Unlike Bacon-Rajan-CC, these accesses are detected by recording what the
collector's state is in: if the collector is in a 'sweep' phase, any access of a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; leads to a
panic. We have not yet verified whether cross-thread collection / sweeping can evade this
check.
&lt;/p&gt;&lt;p&gt; An example of moving beyond reference counting in a GC for Rust is Shifgrethor [2]. It requires &lt;code&gt;Gc&lt;/code&gt;
values to be created by a &lt;code&gt;Root&amp;lt;'root&amp;gt;&lt;/code&gt;: the resulting &lt;code&gt;Gc&amp;lt;'root, T&amp;gt;&lt;/code&gt; is then tied to the lifetime of the
&lt;code&gt;Root&amp;lt;'root&amp;gt;&lt;/code&gt;. This allows roots to be precisely identified, but requires explicitly having access to a
&lt;code&gt;Root&amp;lt;'root&amp;gt;&lt;/code&gt; whenever a &lt;code&gt;Gc&amp;lt;'root, T&amp;gt;&lt;/code&gt; is used. As with Rust-GC, Shifgrethor requires users to
manually implement a &lt;code&gt;Finalize&lt;/code&gt; trait, though Shifgrethor's is more restrictive: not only can other
GCed values not be accessed (implicitly solving the same problem as Section 7.2) but any other
type without the same &lt;code&gt;'root&lt;/code&gt; lifetime as the GCed value is forbidden. This means that many
seemingly safe finalizers require implementing the unsafe &lt;code&gt;UnsafeFinalize&lt;/code&gt; trait. We view
Shifgrethor as proof that accurately tracking GC roots in normal Rust without reference
counting is possible, though it cannot deal with references being converted into pointers and
&lt;code&gt;usize&lt;/code&gt;s.
&lt;/p&gt;&lt;p&gt; A different means of tackling the root-finding problem is GcArena [32], which uses branding in a similar way to &lt;code&gt;GhostCell&lt;/code&gt;s (see Section 2). In essence, users provide a special 'root' type which is the
only place where roots can be stored. Mutating the heap can only be done in the context
of functions that are passed a branded reference to the GCed heap. Once such a function
has completed, GcArena is in full control of the GC heap, and knows that only the root
type needs to be scanned for roots. This leads to a precise guarantee about GC reference
lifetimes. However, if code executes in an arena for too long, the system can find itself starved of
resources, with no way of recovering, even if much of the arena is no longer used. GcArena
was originally part of the Piccolo VM (which was itself previously called Luster), a Lua VM
written in Rust. Such VMs have a frequently executed main loop which is a natural point for a
program to relinquish references to the GCed heap, but this is not true of many other GCed
programs.
&lt;/p&gt;&lt;p&gt; One attempt to improve upon Rust-GC is Bronze [11], though it shows how challenging it can be to meaningfully improve GC for Rust: both of its main advances have subsequently been disabled because they are not just unsound but actively lead to crashes. First, Bronze tried to solve the root-finding problem by using LLVM's &lt;code&gt;gc.root&lt;/code&gt;
intrinsic at function entries to generate stack-maps (a run-time mechanism for accurately tracking active
pointers). This rules out the false positives that are inevitable in conservative GC. However, Bronze
could not track nested references: if a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; was used as a field in a struct, it was not tracked
by the GC. Second, Bronze tried to give GC in Rust similar semantics to non-ownership
languages such as Java. It did this by allowing shared mutation, undermining Rust's borrow
checker.
&lt;/p&gt;&lt;p&gt;Chrome's rendering engine Blink uses the conservative GC Oilpan. It has the interesting property that it has two classes of finalizers. 'Full finalizers' are similar to finalizers in Alloy, running on a finalizer thread at an indeterminate future point, but with the difference that they can only reference parts of a GCed value. To mitigate this, 'pre-finalizers' are run by the collector on the same thread as mutator as soon as an object as recognised as unused, and can access all of a GCed value. Pre-finalizers are necessary, but not encouraged, because they implicitly pause the stop-the-world phase of the collector. This reflects the fact that latency is a fundamental concern for a rendering engine: Alloy currently makes no pretences to being low latency.&lt;/p&gt;&lt;p&gt;We introduced a novel design for GC in Rust that solves a number of outstanding challenges in GC for Rust, as well as â by taking advantage of Rust's unusual static guarantees â some classical GC finalizer problems. By making integration with existing Rust code easier than previous GCs for Rust, we hope to have shown a pragmatic route for partial or wholesale migration of Rust code that would benefit from GC.&lt;/p&gt;&lt;p&gt; Challenges and future opportunities remain. For example, Alloy is an 'all or nothing' cost: if you want to use &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; in a single location, you must pay the costs of the GC runtime and so
on. Alloy's absolute speed is, we believe, limited by BDWGC: it is probable that using a
semi-precise GC and/or a faster conservative GC could change our view of the absolute performance
speed
&lt;/p&gt;&lt;p&gt; In summary, we do not claim that Alloy is the ultimate design for GC in Rust â reasonable people may, for example, disagree on whether the costs of conservative GC are worth the gains â but it does show what can be achieved if one is willing to alter the language's design and &lt;code&gt;rustc&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;The accompanying artefact [18] contains: the source code necessary to run this paper's experiment (including generating figures etc.) from scratch; and data from a run of the experiment that we used in this paper.&lt;/p&gt;&lt;p&gt;This work was funded by an EPSRC PhD studentship and the Shopify / Royal Academy of Engineering Research Chair in Language Engineering. We thank Steve Klabnik and Andy Wingo for comments.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Benchmark&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;cell role="head"&gt;Reason for exclusion&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;bevy&lt;/cell&gt;&lt;cell&gt;ECS game engine in Rust&lt;/cell&gt;&lt;cell&gt;Unable to port successfully (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;dyon&lt;/cell&gt;&lt;cell&gt;Scripting language in Rust&lt;/cell&gt;&lt;cell&gt;Unable to port successfully (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;jiff&lt;/cell&gt;&lt;cell&gt;A datetime library for Rust&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;mini-moka&lt;/cell&gt;&lt;cell&gt;Concurrent in-memory cache library&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;numbat&lt;/cell&gt;&lt;cell&gt;Math search engine&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;rkyv&lt;/cell&gt;&lt;cell&gt;Zero-copy deserialization framework&lt;/cell&gt;&lt;cell&gt;Insufficient &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; coverage in benchmarks&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;RustPython&lt;/cell&gt;&lt;cell&gt;Python interpreter written in Rust&lt;/cell&gt;&lt;cell&gt;Difficulty retro-fitting &lt;code&gt;__del__&lt;/code&gt; semantics (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;rust-analyzer&lt;/cell&gt;&lt;cell&gt;Language server for Rust&lt;/cell&gt;&lt;cell&gt;Unable to port successfully (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;salsa&lt;/cell&gt;&lt;cell&gt;Incremental recomputation library&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;WLambda&lt;/cell&gt;&lt;cell&gt;Scripting language written in Rust&lt;/cell&gt;&lt;cell&gt;Insufficient &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; coverage in benchmarks&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="5"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; (Rust-GC)&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;0.41 [0.39, 0.45]&lt;/cell&gt;&lt;cell&gt;0.40 [0.38, 0.44]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;0.11 [0.11, 0.11]&lt;/cell&gt;&lt;cell&gt;0.15 [0.14, 0.15]&lt;/cell&gt;&lt;cell&gt;0.33 [0.32, 0.33]&lt;/cell&gt;&lt;cell&gt;0.03 [0.03, 0.04]&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;0.33 [0.29, 0.38]&lt;/cell&gt;&lt;cell&gt;0.31 [0.26, 0.37]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;3.06 [3.00, 3.14]&lt;/cell&gt;&lt;cell&gt;3.24 [3.17, 3.31]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;0.47 [0.47, 0.47]&lt;/cell&gt;&lt;cell&gt;0.45 [0.45, 0.46]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;1.61 [1.55, 1.69]&lt;/cell&gt;&lt;cell&gt;1.52 [1.45, 1.59]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;0.92 [0.88, 0.95]&lt;/cell&gt;&lt;cell&gt;0.79 [0.76, 0.82]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;0.28 [0.27, 0.29]&lt;/cell&gt;&lt;cell&gt;0.29 [0.28, 0.30]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;cell role="head"&gt;Ratio&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;jemalloc&lt;/cell&gt;&lt;cell&gt;BDWGC&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;0.36 [0.33, 0.40]&lt;/cell&gt;&lt;cell&gt;0.40 [0.38, 0.44]&lt;/cell&gt;&lt;cell&gt;1.11&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;0.12 [0.12, 0.12]&lt;/cell&gt;&lt;cell&gt;0.15 [0.14, 0.15]&lt;/cell&gt;&lt;cell&gt;1.26&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;0.30 [0.25, 0.36]&lt;/cell&gt;&lt;cell&gt;0.31 [0.26, 0.37]&lt;/cell&gt;&lt;cell&gt;1.02&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;3.09 [3.01, 3.17]&lt;/cell&gt;&lt;cell&gt;3.24 [3.17, 3.31]&lt;/cell&gt;&lt;cell&gt;1.05&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;0.45 [0.44, 0.45]&lt;/cell&gt;&lt;cell&gt;0.45 [0.45, 0.46]&lt;/cell&gt;&lt;cell&gt;1.01&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;1.46 [1.40, 1.53]&lt;/cell&gt;&lt;cell&gt;1.52 [1.45, 1.59]&lt;/cell&gt;&lt;cell&gt;1.04&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;0.77 [0.74, 0.80]&lt;/cell&gt;&lt;cell&gt;0.79 [0.76, 0.82]&lt;/cell&gt;&lt;cell&gt;1.02&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;0.28 [0.27, 0.29]&lt;/cell&gt;&lt;cell&gt;0.29 [0.28, 0.30]&lt;/cell&gt;&lt;cell&gt;1.02&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;-only code (i.e., no GC). The ratio column shows BDWGC time divided by jemalloc time.&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;jemalloc&lt;/cell&gt;&lt;cell&gt;BDWGC&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;User time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;jemalloc&lt;/cell&gt;&lt;cell&gt;BDWGC&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Heap Size (MiB)&lt;/cell&gt;&lt;cell role="head"&gt;Relative wall-clock time&lt;/cell&gt;&lt;cell role="head"&gt;Benchmarks failed&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;16&lt;/cell&gt;&lt;cell&gt;0.96 [0.91, 0.99]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.98 [0.95, 1.02]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.94 [0.89, 0.98]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;cell&gt;0.88 [0.82, 1.02]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;cell&gt;0.90 [0.80, 1.01]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;16&lt;/cell&gt;&lt;cell&gt;0.87 [0.82, 0.94]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;16&lt;/cell&gt;&lt;cell&gt;0.94 [0.90, 0.99]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.94 [0.88, 0.98]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.94 [0.89, 1.00]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;1024&lt;/cell&gt;&lt;cell&gt;1.01 [1.00, 1.02]&lt;/cell&gt;&lt;cell&gt;2/4 (Eclipse, Jenkins)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;2048&lt;/cell&gt;&lt;cell&gt;1.00 [1.00, 1.01]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;4096&lt;/cell&gt;&lt;cell&gt;1.01 [1.00, 1.02]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;256&lt;/cell&gt;&lt;cell&gt;0.94 [0.92, 0.95]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;512&lt;/cell&gt;&lt;cell&gt;0.93 [0.90, 0.94]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;1024&lt;/cell&gt;&lt;cell&gt;0.96 [0.92, 1.07]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.96 [0.95, 0.96]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.95 [0.94, 0.95]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;128&lt;/cell&gt;&lt;cell&gt;0.94 [0.93, 0.95]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.72 [0.71, 0.74]&lt;/cell&gt;&lt;cell&gt;2/4 (Fannkuch, TreeSort)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;96&lt;/cell&gt;&lt;cell&gt;0.74 [0.73, 0.75]&lt;/cell&gt;&lt;cell&gt;2/4 (Fannkuch, TreeSort)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;128&lt;/cell&gt;&lt;cell&gt;0.75 [0.74, 0.76]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.79 [0.78, 0.80]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.79 [0.77, 0.80]&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;128&lt;/cell&gt;&lt;cell&gt;0.84 [0.83, 0.86]&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Fin. elided (%)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Table 10. Percentage of finalizers Alloy was able to elide for each benchmark.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Before elision&lt;/cell&gt;&lt;cell&gt;After elision&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;User time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Before elision&lt;/cell&gt;&lt;cell&gt;After elision&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Avg. heap footprint (MiB)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Before elision&lt;/cell&gt;&lt;cell&gt;After elision&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;size_t&lt;/code&gt; and &lt;code&gt;uintptr_t&lt;/code&gt; types respectively. Rust now has a provenance lint to nudge users in this general direction, but the &lt;code&gt;as&lt;/code&gt; keyword still allows arbitrary conversions.
    &lt;code&gt;y = Gc::clone(&amp;amp;v)&lt;/code&gt; is available, since every copyable type is also cloneable.
    &lt;code&gt;RawTable&lt;/code&gt; is contained in the separate &lt;code&gt;hashbrown&lt;/code&gt; crate which is then included in Rust's standard library. We previously maintained a fork of this, but synchronising it is painful. For now, at least, we have hacked explicit knowledge of &lt;code&gt;RawTable&lt;/code&gt; into the &lt;code&gt;needs_finalize&lt;/code&gt; function.
    &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/"/><published>2025-10-15T12:08:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591222</id><title>Show HN: Scriber Pro – Offline AI transcription for macOS</title><updated>2025-10-15T18:46:05.477799+00:00</updated><content>&lt;doc fingerprint="68fec097b143b4f5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Scriber Pro&lt;/head&gt;
    &lt;p&gt;Offline AI transcription for macOS&lt;/p&gt;
    &lt;p&gt; • 4.5hr video → 3.5min. Faster than Rev, Otter, or any online service.&lt;lb/&gt; • More accurate on long context. No 2-hour upload limits.&lt;lb/&gt; • 100% offline. Your data never leaves your Mac. &lt;/p&gt;
    &lt;p&gt;All HN promo codes claimed! Thanks for the response. Download on Mac App Store&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Scriber Pro?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stupid fast: 4.5hr video → 3.5min. Seriously.&lt;/item&gt;
      &lt;item&gt;Any format: MP3, WAV, MP4, MOV, M4A, FLAC—drop it in, it works.&lt;/item&gt;
      &lt;item&gt;Perfect timecodes: 5min or 5hr file, timecodes stay accurate. No drift, no chunking errors.&lt;/item&gt;
      &lt;item&gt;Works offline: On a plane. In a coffee shop. No internet, no problem.&lt;/item&gt;
      &lt;item&gt;Your data stays yours: Everything processes on your Mac. No cloud uploads, no surveillance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Export Anywhere&lt;/head&gt;
    &lt;p&gt; Timecode formats: SRT, VTT, JSON (with precise timestamps)&lt;lb/&gt; Documents: PDF, DOCX, TXT, Markdown&lt;lb/&gt; Data: CSV, JSON&lt;lb/&gt; One transcription, eight formats. Perfect timecodes whether it's 3min or 3hr. &lt;/p&gt;
    &lt;p&gt;Contact: [email protected] | Main Site&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scriberpro.cc/hn/"/><published>2025-10-15T12:16:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591707</id><title>I almost got hacked by a 'job interview'</title><updated>2025-10-15T18:46:05.299494+00:00</updated><content>&lt;doc fingerprint="39dbf13f092261dc"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple unleashes M5, the next big leap in AI performance for Apple silicon&lt;/head&gt;
    &lt;p&gt; M5 delivers over 4x the peak GPU compute performance for AI compared to M4, featuring a next-generation GPU with a Neural Accelerator in each core, a more powerful CPU, a faster Neural Engine, and higher unified memory bandwidth &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today announced M5, delivering the next big leap in AI performance and advances to nearly every aspect of the chip. Built using third-generation 3-nanometer technology, M5 introduces a next-generation 10-core GPU architecture with a Neural Accelerator in each core, enabling GPU-based AI workloads to run dramatically faster, with over 4x the peak GPU compute performance compared to M4.1 The GPU also offers enhanced graphics capabilities and third-generation ray tracing that combined deliver a graphics performance that is up to 45 percent higher than M4.1 M5 features the world’s fastest performance core, with up to a 10-core CPU made up of six efficiency cores and up to four performance cores.2 Together, they deliver up to 15 percent faster multithreaded performance over M4.1 M5 also features an improved 16-core Neural Engine, a powerful media engine, and a nearly 30 percent increase in unified memory bandwidth to 153GB/s.1 M5 brings its industry-leading power-efficient performance to the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro, allowing each device to excel in its own way. All are available for pre-order today. &lt;/p&gt;
    &lt;p&gt;“M5 ushers in the next big leap in AI performance for Apple silicon,” said Johny Srouji, Apple’s senior vice president of Hardware Technologies. “With the introduction of Neural Accelerators in the GPU, M5 delivers a huge boost to AI workloads. Combined with a big increase in graphics performance, the world’s fastest CPU core, a faster Neural Engine, and even higher unified memory bandwidth, M5 brings far more performance and capabilities to MacBook Pro, iPad Pro, and Apple Vision Pro.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Next-Generation GPU Architecture Optimized for AI and Graphics&lt;/head&gt;
    &lt;p&gt;With the next-generation GPU architecture in M5, every compute block of the chip is optimized for AI. The 10-core GPU features a dedicated Neural Accelerator in each core, delivering over 4x peak GPU compute compared to M4, and over 6x peak GPU compute for AI performance compared to M1.1 And now with M5, the new 14-inch MacBook Pro and iPad Pro benefit from dramatically accelerated processing for AI-driven workflows, such as running diffusion models in apps like Draw Things, or running large language models locally using platforms like webAI. &lt;/p&gt;
    &lt;p&gt;The next-generation GPU and enhanced shader cores in M5 also deliver increased graphics performance, achieving up to 30 percent faster performance compared to M4 and up to 2.5x faster performance than M1.1 M5 also includes Apple’s third-generation ray-tracing engine, providing up to a 45 percent graphics uplift in apps using ray tracing.1 Combined with rearchitected second-generation dynamic caching, the GPU provides smoother gameplay, more realistic visuals in 3D applications, and faster rendering times for complex graphics projects and other visually intensive applications. With M5, Apple Vision Pro renders 10 percent more pixels with the micro-OLED displays, and refresh rates increase up to 120Hz, resulting in crisper details, more fluid display performance, and reduced motion blur. &lt;/p&gt;
    &lt;p&gt;The GPU architecture is engineered for seamless integration with Apple’s software frameworks. Applications using built-in Apple frameworks and APIs — like Core ML, Metal Performance Shaders, and Metal 4 — can automatically see immediate increases in performance. Developers can also build solutions for their apps by directly programming the Neural Accelerators using Tensor APIs in Metal 4. &lt;/p&gt;
    &lt;head rend="h2"&gt;A Faster Neural Engine to Power Intelligent Features&lt;/head&gt;
    &lt;p&gt;The faster 16-core Neural Engine delivers powerful AI performance with incredible energy efficiency, complementing the Neural Accelerators in the CPU and GPU to make M5 fully optimized for AI workloads. For example, AI-powered features on Apple Vision Pro — like the ability to transform 2D photos into spatial scenes in the Photos app, or generating a Persona — operate with greater speed and efficiency. &lt;/p&gt;
    &lt;p&gt;The Neural Engine in M5 also enhances performance for Apple Intelligence.3 On-device AI tools like Image Playground get faster, and the overall performance of Apple Intelligence models are enhanced by the faster Neural Engine and unified memory in M5.4 Also, developers using Apple’s Foundation Models framework will get faster performance. &lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced Memory to Do Even More with AI&lt;/head&gt;
    &lt;p&gt;M5 offers unified memory bandwidth of 153GB/s, providing a nearly 30 percent increase over M4 and more than 2x over M1. The unified memory architecture enables the entire chip to access a large single pool of memory, which allows MacBook Pro, iPad Pro, and Apple Vision Pro to run larger AI models completely on device. It fuels the faster CPU, GPU, and Neural Engine as well, offering higher multithreaded performance in apps, faster graphics performance in creative apps and games, and faster AI performance running models on the Neural Accelerators in the GPU or the Neural Engine. And with 32GB of memory capacity, M5 also helps users to seamlessly run demanding creative suites like Adobe Photoshop and Final Cut Pro simultaneously, while uploading large files to the cloud in the background. &lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Silicon and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The power-efficient performance of M5 helps the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro meet Apple’s high standards for energy efficiency, and reduces the total amount of energy consumed over the product’s lifetime. &lt;/p&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using preproduction 14-inch MacBook Pro systems with Apple M5, 10-core CPU, and 10-core GPU; production 14-inch MacBook Pro systems with Apple M4, 10-core CPU, and 10-core GPU; and production 13-inch MacBook Pro systems with Apple M1, 8-core CPU, and 8-core GPU. Performance measured using select industry‑standard benchmarks. Performance tests are conducted using specific computer systems and reflect the approximate performance of MacBook Pro.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using shipping competitive systems and select industry-standard benchmarks.&lt;/item&gt;
      &lt;item&gt;Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
      &lt;item&gt;Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.daviddodda.com/how-i-almost-got-hacked-by-a-job-interview"/><published>2025-10-15T12:56:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591799</id><title>Apple M5 chip</title><updated>2025-10-15T18:46:05.177534+00:00</updated><content>&lt;doc fingerprint="39dbf13f092261dc"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple unleashes M5, the next big leap in AI performance for Apple silicon&lt;/head&gt;
    &lt;p&gt; M5 delivers over 4x the peak GPU compute performance for AI compared to M4, featuring a next-generation GPU with a Neural Accelerator in each core, a more powerful CPU, a faster Neural Engine, and higher unified memory bandwidth &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today announced M5, delivering the next big leap in AI performance and advances to nearly every aspect of the chip. Built using third-generation 3-nanometer technology, M5 introduces a next-generation 10-core GPU architecture with a Neural Accelerator in each core, enabling GPU-based AI workloads to run dramatically faster, with over 4x the peak GPU compute performance compared to M4.1 The GPU also offers enhanced graphics capabilities and third-generation ray tracing that combined deliver a graphics performance that is up to 45 percent higher than M4.1 M5 features the world’s fastest performance core, with up to a 10-core CPU made up of six efficiency cores and up to four performance cores.2 Together, they deliver up to 15 percent faster multithreaded performance over M4.1 M5 also features an improved 16-core Neural Engine, a powerful media engine, and a nearly 30 percent increase in unified memory bandwidth to 153GB/s.1 M5 brings its industry-leading power-efficient performance to the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro, allowing each device to excel in its own way. All are available for pre-order today. &lt;/p&gt;
    &lt;p&gt;“M5 ushers in the next big leap in AI performance for Apple silicon,” said Johny Srouji, Apple’s senior vice president of Hardware Technologies. “With the introduction of Neural Accelerators in the GPU, M5 delivers a huge boost to AI workloads. Combined with a big increase in graphics performance, the world’s fastest CPU core, a faster Neural Engine, and even higher unified memory bandwidth, M5 brings far more performance and capabilities to MacBook Pro, iPad Pro, and Apple Vision Pro.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Next-Generation GPU Architecture Optimized for AI and Graphics&lt;/head&gt;
    &lt;p&gt;With the next-generation GPU architecture in M5, every compute block of the chip is optimized for AI. The 10-core GPU features a dedicated Neural Accelerator in each core, delivering over 4x peak GPU compute compared to M4, and over 6x peak GPU compute for AI performance compared to M1.1 And now with M5, the new 14-inch MacBook Pro and iPad Pro benefit from dramatically accelerated processing for AI-driven workflows, such as running diffusion models in apps like Draw Things, or running large language models locally using platforms like webAI. &lt;/p&gt;
    &lt;p&gt;The next-generation GPU and enhanced shader cores in M5 also deliver increased graphics performance, achieving up to 30 percent faster performance compared to M4 and up to 2.5x faster performance than M1.1 M5 also includes Apple’s third-generation ray-tracing engine, providing up to a 45 percent graphics uplift in apps using ray tracing.1 Combined with rearchitected second-generation dynamic caching, the GPU provides smoother gameplay, more realistic visuals in 3D applications, and faster rendering times for complex graphics projects and other visually intensive applications. With M5, Apple Vision Pro renders 10 percent more pixels with the micro-OLED displays, and refresh rates increase up to 120Hz, resulting in crisper details, more fluid display performance, and reduced motion blur. &lt;/p&gt;
    &lt;p&gt;The GPU architecture is engineered for seamless integration with Apple’s software frameworks. Applications using built-in Apple frameworks and APIs — like Core ML, Metal Performance Shaders, and Metal 4 — can automatically see immediate increases in performance. Developers can also build solutions for their apps by directly programming the Neural Accelerators using Tensor APIs in Metal 4. &lt;/p&gt;
    &lt;head rend="h2"&gt;A Faster Neural Engine to Power Intelligent Features&lt;/head&gt;
    &lt;p&gt;The faster 16-core Neural Engine delivers powerful AI performance with incredible energy efficiency, complementing the Neural Accelerators in the CPU and GPU to make M5 fully optimized for AI workloads. For example, AI-powered features on Apple Vision Pro — like the ability to transform 2D photos into spatial scenes in the Photos app, or generating a Persona — operate with greater speed and efficiency. &lt;/p&gt;
    &lt;p&gt;The Neural Engine in M5 also enhances performance for Apple Intelligence.3 On-device AI tools like Image Playground get faster, and the overall performance of Apple Intelligence models are enhanced by the faster Neural Engine and unified memory in M5.4 Also, developers using Apple’s Foundation Models framework will get faster performance. &lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced Memory to Do Even More with AI&lt;/head&gt;
    &lt;p&gt;M5 offers unified memory bandwidth of 153GB/s, providing a nearly 30 percent increase over M4 and more than 2x over M1. The unified memory architecture enables the entire chip to access a large single pool of memory, which allows MacBook Pro, iPad Pro, and Apple Vision Pro to run larger AI models completely on device. It fuels the faster CPU, GPU, and Neural Engine as well, offering higher multithreaded performance in apps, faster graphics performance in creative apps and games, and faster AI performance running models on the Neural Accelerators in the GPU or the Neural Engine. And with 32GB of memory capacity, M5 also helps users to seamlessly run demanding creative suites like Adobe Photoshop and Final Cut Pro simultaneously, while uploading large files to the cloud in the background. &lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Silicon and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The power-efficient performance of M5 helps the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro meet Apple’s high standards for energy efficiency, and reduces the total amount of energy consumed over the product’s lifetime. &lt;/p&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using preproduction 14-inch MacBook Pro systems with Apple M5, 10-core CPU, and 10-core GPU; production 14-inch MacBook Pro systems with Apple M4, 10-core CPU, and 10-core GPU; and production 13-inch MacBook Pro systems with Apple M1, 8-core CPU, and 8-core GPU. Performance measured using select industry‑standard benchmarks. Performance tests are conducted using specific computer systems and reflect the approximate performance of MacBook Pro.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using shipping competitive systems and select industry-standard benchmarks.&lt;/item&gt;
      &lt;item&gt;Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
      &lt;item&gt;Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/"/><published>2025-10-15T13:02:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591801</id><title>Apple Vision Pro upgraded with M5 chip</title><updated>2025-10-15T18:46:05.009205+00:00</updated><content>&lt;doc fingerprint="b7cdbb1d7322b0d5"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple Vision Pro upgraded with the powerful M5 chip and comfortable Dual Knit Band&lt;/head&gt;
    &lt;p&gt; The latest version improves performance, display rendering, battery life, and comfort, while offering innovative features with visionOS 26 and all-new spatial apps and Apple Immersive content &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today introduced Apple Vision Pro with the powerful M5 chip that delivers a leap forward in performance, improved display rendering, faster AI-powered workflows, and extended battery life. The upgraded Vision Pro also comes with the soft, cushioned Dual Knit Band to help users achieve an even more comfortable fit, and visionOS 26, which unlocks innovative spatial experiences, including widgets, new Personas, an interactive Jupiter Environment, and new Apple Intelligence features with support for additional languages.1 There are over 1 million apps and thousands of games on the App Store, hundreds of 3D movies on the Apple TV app, and all-new series and films in Apple Immersive with a selection of live NBA games coming soon. Vision Pro with M5 and the Dual Knit Band is now available to pre-order on apple.com. Customers can book a demo at Apple Store locations today and it will be available nationwide beginning Wednesday, October 22. &lt;/p&gt;
    &lt;p&gt;“With the breakthrough performance of M5, the latest Apple Vision Pro delivers faster performance, sharper details throughout the system, and even more battery life, setting a new standard for what’s possible in spatial computing,” said Bob Borchers, Apple’s vice president of Worldwide Product Marketing. “Paired with the comfortable Dual Knit Band, innovative features in visionOS 26, and all-new Apple Immersive experiences spanning adventure, documentary, music, and sports, spatial computing is even more capable, entertaining, and magical with the new Vision Pro.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Leap Forward in Performance with M5&lt;/head&gt;
    &lt;p&gt;M5 provides an even faster, smoother, and more responsive experience for Apple Vision Pro users, while introducing new opportunities for developers to create more advanced spatial and immersive experiences. Built using third-generation 3-nanometer technology, M5 on Vision Pro features an advanced 10-core CPU that delivers higher multithreaded performance, resulting in faster experiences throughout the system, including faster load times for apps and widgets and more responsive web browsing. The next-generation 10-core GPU architecture brings support for hardware-accelerated ray tracing and mesh shading, enabling developers to add remarkable detail to lighting, shadows, and reflections in games like Control. &lt;/p&gt;
    &lt;p&gt;With M5, Apple Vision Pro renders 10 percent more pixels on the custom micro-OLED displays compared to the previous generation, resulting in a sharper image with crisper text and more detailed visuals. Vision Pro can also increase the refresh rate up to 120Hz for reduced motion blur when users look at their physical surroundings, and an even smoother experience when using Mac Virtual Display. Vision Pro with M5 works alongside the purpose-built R1 chip, which processes input from 12 cameras, five sensors, and six microphones, and streams new images to the displays within 12 milliseconds to create a real-time view of the world. The high-performance battery now supports up to two and a half hours of general use, and up to three hours of video playback, all on a single charge.2 And it’s easy to use Vision Pro for longer periods at home, at an office, or while commuting by connecting the battery to power. &lt;/p&gt;
    &lt;p&gt;The 16-core Neural Engine makes AI-powered features run up to 50 percent faster for system experiences — like capturing a Persona or transforming photos into spatial scenes — and up to 2x faster for third-party apps compared to the previous generation.3 With M5, developers such as JigSpace are pioneering new use cases for enterprises that combine spatial computing with on-device AI. Using Apple’s Foundation Models framework, the new JigSpace app for Vision Pro taps into the on-device model at the core of Apple Intelligence to make complex information easier to understand. Users can parse through complex datasets with natural language and learn about sophisticated objects, like wind turbines, using interactive 3D models. &lt;/p&gt;
    &lt;head rend="h2"&gt;The New Dual Knit Band Offers a More Comfortable Fit&lt;/head&gt;
    &lt;p&gt;The Dual Knit Band delivers an even more comfortable fit for users. It features upper and lower straps that are 3D-knitted as a single piece to create a unique dual-rib structure that provides cushioning, breathability, and stretch. The lower strap features flexible fabric ribs embedded with tungsten inserts that provide a counterweight for additional comfort, balance, and stability. And the intuitive dual-function Fit Dial allows users to make fine-tuned adjustments to achieve their ideal fit. The new Dual Knit Band comes in small, medium, and large sizes; is available to purchase separately; and is compatible with the previous-generation Apple Vision Pro. Customers can easily find the size that is right for them using the Apple Store app for iPhone. &lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful Spatial Experiences with visionOS 26&lt;/head&gt;
    &lt;p&gt;visionOS 26 brings a set of powerful spatial experiences to Apple Vision Pro. Widgets seamlessly integrate into a user’s space and reappear every time they put Vision Pro on, making it easy to check the time or weather, play music or podcasts, decorate their space with photos, or access ChatGPT. Striking enhancements to Persona make communicating in apps like FaceTime feel even more natural and familiar. Spatial scenes, which use generative AI to add lifelike depth to photos, make memories come to life. Users can play back 180-degree, 360-degree, and wide field-of-view video from popular action cameras, so they can enjoy their footage the way it was meant to be seen, and creators can publish videos in these formats to apps like Safari and Vimeo. With iPadOS 26.1, available later this fall, the Apple Vision Pro app comes to iPad, offering users another great way to discover new content, queue apps and games to download, find tips, and quickly access information about their Vision Pro. &lt;/p&gt;
    &lt;head rend="h2"&gt;New Apps, Content, and Games to Explore&lt;/head&gt;
    &lt;p&gt;There are over 1 million apps available for Apple Vision Pro, including more than 3,000 apps built for visionOS. Users can design their dream home with HomeByMe and Lowe’s Style Studio, outfit their closet with Balenciaga, and browse stunning artwork with Christie’s Select and Art Authority Museum. They can explore extraordinary locations around the world with Epic Earth and Explore POV, transform their physical space into a planetarium with Space Vision, or travel back in time with D-Day: The Camera Soldier. &lt;/p&gt;
    &lt;p&gt;Apple Vision Pro remains the ultimate entertainment device. With the new Vision Pro, users can experience concerts like never before with Amplium; tune into their favorite teams with apps from major sports leagues; or enjoy a personal theater with apps from popular streaming services on a screen that appears up to 100 feet wide. Apple Immersive continues to redefine what is possible in storytelling, and Vision Pro users can enjoy new series and films on the Apple TV app. Later this season, users in the Lakers’ broadcast territory will be able to watch select live games in Apple Immersive, and new titles from the Audi F1 Project, the BBC, HYBE, and Red Bull will launch in Apple Immersive in the coming months.4 The Apple TV app is also home to one of the largest digital collections of 3D movies available, featuring recent blockbusters like Superman, Jurassic World Rebirth, How to Train Your Dragon, and Wicked. &lt;/p&gt;
    &lt;p&gt;Gaming on Apple Vision Pro is next level with its ultra-high-resolution displays, advanced Spatial Audio system, low latency, and responsive controls across a variety of input methods, including popular game controllers like Sony DualSense, which now supports multidevice pairing. &lt;/p&gt;
    &lt;p&gt;Players will be able to enjoy iPad games like Where Winds Meet, POOLS, and Sniper Elite 4, fun spatial games like Porta Nubi and Glassbreakers: Champions of Moss, and the latest titles on consoles and PCs with apps like Portal and Steam Link. And with support for the PlayStation VR2 Sense controller, players get a new class of immersive games with high-performance motion tracking in six degrees of freedom, finger touch detection, and vibration support. Elu Legend, Pickle Pro, Ping Pong Club, and Spatial Rifts are some of the first games available with support for the PlayStation VR2 controller. &lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced Capabilities for Pro Users and Enterprises&lt;/head&gt;
    &lt;p&gt;With Apple Vision Pro, users can supercharge their workflows and discover new ways to realize their creative visions. Artists can design new works using apps like Crayon and Da Vinci Eye. Photographers can edit images with color accuracy from any location and in any lighting condition using Pixelmator on MacBook Pro with Mac Virtual Display. Filmmakers can scout locations from anywhere by viewing spatial media — including panoramas and spatial videos shot on iPhone — on a large wraparound display. And pro users can assemble and rehearse their presentations while in a seat-for-seat replica of the Steve Jobs Theater at Apple Park using Keynote. With Logitech Muse — a digital pencil built for Vision Pro — users can create and collaborate with a new level of precision. Apps like Crayon, doppl by Interaptix, Sketch Pro, and Spatial Analogue are adding support for Muse over the coming weeks. &lt;/p&gt;
    &lt;p&gt;Businesses around the world are harnessing the power of spatial computing on Apple Vision Pro every day to invent new solutions and streamline operations across design, education, healthcare, sales, and more. CAE, the multinational technology company that specializes in simulation and instruction solutions, uses Vision Pro to help pilots complete training activities outside of specialized centers, featuring true-to-life flight deck environments and scenarios. At Porsche, drivers can visualize and personalize new vehicles in select showrooms before taking delivery. And by seamlessly blending digital content with the physical world, Visage Imaging provides high-quality, three-dimensional medical imaging, helping hospitals like UC San Diego Health improve patient care. &lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Vision Pro and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. Apple Vision Pro is made with 100 percent recycled aluminum in the frame and battery enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled cobalt in the battery. Vision Pro is designed to last and meets Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled. &lt;/p&gt;
    &lt;p&gt;Pricing and Availability &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro with the M5 chip and Dual Knit Band starts at $3,499 (U.S.), and is available in 256GB, 512GB, and 1TB storage capacities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers can pre-order Apple Vision Pro with the M5 chip and Dual Knit Band today in Australia, Canada, France, Germany, Hong Kong, Japan, the UAE, the UK, and the U.S. It will be available for pre-order in China mainland and Singapore on Friday, October 17.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro with the M5 chip and Dual Knit Band will be available in Apple Store locations in Australia, Canada, China mainland, Hong Kong, France, Germany, Japan, Singapore, the UAE, the UK, and the U.S. on Wednesday, October 22. It will be available in South Korea and Taiwan later.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers can book a demo of Apple Vision Pro online. Demos are hosted at all Apple Store locations where Vision Pro is available. Demos of the latest Vision Pro will feature the new Dual Knit Band, and customers can ask to see new features, apps, and experiences, including the Spatial Gallery app, Apple Intelligence features like Genmoji and Writing Tools, and extended previews of several Apple Immersive experiences, including the new sports documentary Tour De Force from CANAL+ and MotoGP in select markets.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro comes with the new Dual Knit Band, a Light Seal, two Light Seal Cushions, an Apple Vision Pro Cover for the front of the device, Polishing Cloth, Battery, USB-C Charge Cable, and the 40W Dynamic Power Adapter with 60W Max.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dual Knit Band is available to purchase separately for $99 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro Travel Case is available for $199 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For users who require vision correction, ZEISS Optical Inserts — Readers will be available for $99 (U.S.), and ZEISS Optical Inserts — Prescription will be available for $149 (U.S.).5&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Logitech Muse is now available to pre-order for $129.95 (U.S.) from logitech.com and the Apple Store online in countries and regions where Apple Vision Pro is available. It will be available alongside Apple Vision Pro with M5 and the Dual Knit Band on Wednesday, October 22.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PlayStation VR2 Sense controller and Controller Charging Station will be available for $249.95 (U.S.) from the Apple Store online in the U.S. beginning Tuesday, November 11.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover Apple Vision Pro, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit apple.com/applecare.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Image Playground is available in English (Australia, Canada, India, Singapore, UK, U.S.), French (Canada, France), German, Italian, Japanese, and Spanish (Mexico, Spain) when Apple Intelligence is enabled. Feature availability varies by region.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in August and September 2025 using preproduction Apple Vision Pro (M5) units and software. Testing consisted of full battery discharge while performing each of the following tasks: video playback, internet browsing, spatial video capture, and FaceTime. Video playback tested in conjunction with an Environment, using 2D movie content purchased from the Apple TV app. Internet browsing tested using 20 popular websites. FaceTime tested between two Apple Vision Pro units with Personas enabled. Tested with Wi‑Fi associated to a network. Battery life depends on device settings, usage, network, environmental conditions, and many other factors. Battery tests are conducted using specific Apple Vision Pro units; actual results may vary.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using preproduction Apple Vision Pro (M5) and production Apple Vision Pro (M2) units. Up to 2x faster performance results were achieved when tested with prerelease Draw Things v1.20250820.0 on Apple Vision Pro (M5), v1.20250903.0 on Apple Vision Pro (M2), and a 768x768 text-to-image generation with step-distilled Qwen Image model at 6-bit quantization in two steps. When tested with Photos app by creating spatial scenes from photos, performance results were up to 1.5x faster. Performance tests are conducted using specific Apple Vision Pro units and reflect the approximate performance of Apple Vision Pro.&lt;/item&gt;
      &lt;item&gt;Additional information about titles from the Audi F1 Project, the BBC, HYBE, and Red Bull will be provided by these creators closer to their availability.&lt;/item&gt;
      &lt;item&gt;A valid prescription is required. Not all prescriptions are supported. Vision correction accessories are sold separately. ZEISS Optical Inserts — Prescription are only available to purchase online.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/"/><published>2025-10-15T13:03:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591865</id><title>Mac Source Ports – Run old games on new Macs</title><updated>2025-10-15T18:46:04.458086+00:00</updated><content>&lt;doc fingerprint="27614135739545fa"&gt;
  &lt;main&gt;
    &lt;p&gt;Mac Source Ports features native app builds of source ports of your favorite games for both Apple Silicon and Intel Macs, signed and notarized whenever possible.&lt;/p&gt;
    &lt;p&gt;Developer: Stainless Games&lt;lb/&gt;Release Date: June 13, 1997&lt;/p&gt;
    &lt;p&gt;An example of controversy for controversy's sake, Carmageddon basically took what people wanted to do in other racing games - crash into other cars and run over pedestrians - and turned it into the primary gameplay loop. They took the macabre joke about getting points for hitting people in your car and made it a gameplay mechanic. The game was successful both from a critical and commercial perspective, as well as its goal as a controversy magnet.&lt;lb/&gt;The dethrace project is a source port where in lieu of source code they're reverse engineering it, and according to their Twitter account they're approximately 70% of the way there. The game is very playable but may crash in some places, so I'm introducing a new tag: Early Access. This probably could use a better name but I'm using it to convey the notion that the project doesn't consider itself completely finished (though there are reports of people making it through the entire game), but it's still pretty awesome so I figured if nothing else it's worth putting up a quick build.&lt;/p&gt;
    &lt;p&gt;Developer: Pumpkin Studios&lt;lb/&gt;Release Date: April 10, 1999&lt;lb/&gt;Source Code Release Date: December 6, 2004&lt;/p&gt;
    &lt;p&gt;Warzone 2100 is a post-apocalyptic real-time strategy game from 1999 whose source was released in 2004 and whose content was released as freeware in 2008.&lt;lb/&gt;Although my aim is to host signed and notarized game bundles on Mac Source Ports, the Warzone 2100 Project has done incredible work on this port and has logistical reasons for not being notarized yet. While they work through that process, I decided it was worth making an exception to the site's policy so that Apple Silicon gamers looking for a full, free and polished RTS would be able to find it.&lt;lb/&gt;Because the app bundle is not notarized, on first run you may run into issues. The shortest answer is to right-click on the app bundle (wz2100.app) and select Open. The long answer is here.&lt;/p&gt;
    &lt;p&gt;Developer: Grey Matter Interactive&lt;lb/&gt;Release Date: November 19, 2001&lt;lb/&gt;Source Code Release Date: August 12, 2010&lt;/p&gt;
    &lt;p&gt;Return to Castle Wolfenstein is a fantastic single player game with lots of little touches you might have missed the first time around and that you don't see much anymore. Still abolutely worth firing up just to blast some Nazis. This source port also includes the multiplayer as a separate app, which still works on the servers running to this day.&lt;/p&gt;
    &lt;p&gt;Developer: id Software&lt;lb/&gt;Release Date: December 9, 1997&lt;lb/&gt;Source Code Release Date: December 22, 2001&lt;/p&gt;
    &lt;p&gt;Quake II is a first-person shooter, the second in the Quake series. Yamagi Quake2 is the most mature and advanced port actively being maintained.&lt;/p&gt;
    &lt;p&gt;Developer: New World Computing&lt;lb/&gt;Release Date: October 1, 1996&lt;/p&gt;
    &lt;p&gt;Heroes of Might and Magic II is a 4X turn-based strategy game. Ranked once by PC Gamer as the sixth-best game of all time it features resource building, new factions, skills, and a single-player campaign.&lt;/p&gt;
    &lt;p&gt;Developer: Chris Sawyer&lt;lb/&gt;Release Date: October 15, 2002&lt;/p&gt;
    &lt;p&gt;Another game from the mind of Chris Sawyer, RollerCoaster Tycoon 2 shares the same pixel art style and hardcore interface as his other games.&lt;/p&gt;
    &lt;p&gt;Developer: Epic MegaGames&lt;lb/&gt;Release Date: May 7, 1998&lt;/p&gt;
    &lt;p&gt;Although never as big as Mario or Sonic, Jazz Jackrabbit did well enough with a hungry PC gaming crowd to merit a second game in the series. It's your standard shareware sequel story: more levels, more twists, better technology. If you liked the original you'll like this one.&lt;lb/&gt;It also has a very confusing release strategy. The original game was shareware, when you bought it you got the full Jazz Jackrabbit 2 game. Later, it was re-released with an additional episode under the title Jazz Jackrabbit 2: The Secret Files. Then came a release called Jazz Jackrabbit 2: The Christmas Chronicles, which adds Christmas-themed levels. So when you get the game on GOG you might spot two entries, neither of which look like they're the base game, but both should work in Jazz² Resurrection.&lt;/p&gt;
    &lt;p&gt;Developer: Thalion Software&lt;lb/&gt;Release Date: April 11, 1993&lt;lb/&gt;Source Code Release Date: May 7, 2023&lt;/p&gt;
    &lt;p&gt;The Commodore Amiga was one of those computers where it jumped ahead of the competition by several miles, but then stayed there for a long time and got surpassed by the competition. I think this is why there's such a distinctive look to the games the platform and why it was so accessible to smaller game designers, the types we'd call "indie" today.&lt;lb/&gt;Ambermoon is an RPG for the Amiga that really looks like an Amiga game. It was the second part of an unfinished trilogy. Although the original game's source has been released, the source port we're pointing to is Ambermoon.net which like it sounds is a recreation of the original game in C#/.NET (the original game was Amiga-specific Assembly language and isn't a great candidate for portability).&lt;lb/&gt;In addition to being able to download it below from the developer's GitHub page, the game is also available on itch.io as a "Name your own price" download in case you want to support or tip the developer.&lt;/p&gt;
    &lt;p&gt;Developer: Bungie&lt;lb/&gt;Release Date: December 21, 1994&lt;lb/&gt;Source Code Release Date: January 2000&lt;/p&gt;
    &lt;p&gt;The year is 1994. The world can't get enough of DOOM. Everyone that is except for you because you own an Apple Macintosh and DOOM is a PC game. You comfort yourself with your superior port of Wolfenstein 3-D but it's just not the same.&lt;lb/&gt;Bungie Software Products Corporation to the rescue! Marathon was released as the Mac's answer to DOOM, and a game which was its opposite, as it was not on the PC. Bungie would go on to make a trilogy of games in the Marathon universe before starting work on the Mac-exclusive Halo&lt;lb/&gt;Of course what really happened is Microsoft bought Bungie and Halo became an Xbox exclusive. Halo and Marathon may not share a universe, but Bungie put Marathon references in all of their Halo titles, including embedding the Marathon logo in the original Halo box art.&lt;lb/&gt;Bungie released all three Marathon titles as freeware in 2005 so the downloads from the Aleph One project include the entire game. No need to dig out your old discs here.&lt;/p&gt;
    &lt;p&gt;Developer: Bungie&lt;lb/&gt;Release Date: November 24, 1995&lt;lb/&gt;Source Code Release Date: January 2000&lt;/p&gt;
    &lt;p&gt;Marathon 2, released a year after the original, was also released for Windows 95. The game featured engine improvements and a plot that took place 17 years after the original. The graphics for this release have been upgraded from the release on XBLA.&lt;lb/&gt;Bungie released all three Marathon titles as freeware in 2005 so the downloads from the Aleph One project include the entire game. No need to dig out your old discs here.&lt;/p&gt;
    &lt;p&gt;Developer: Tom Kidd / Mac Source Ports&lt;lb/&gt;Release Date: February 23, 2022&lt;/p&gt;
    &lt;p&gt;Extractor is an app from Mac Source Ports that extracts files from GOG Windows-based installers. Think of it as a GUI version of innoextract.&lt;lb/&gt;Right now, Extractor does exactly two things: lists the files in an installer, and extracts the files from an installer. We hope to expand it in the future but for now it's a simple application.&lt;/p&gt;
    &lt;p&gt;Developer: Hard Light Productions&lt;lb/&gt;Release Date: February 11, 2024&lt;/p&gt;
    &lt;p&gt;Knossos.NET is a utility that aids in downloading and configuring the FreeSpace 2 Open Source Project, aids in configuring the content from a GOG installer or other location, and can even help with mod management and multiplayer support. Check it out if you want to play FreeSpace 2 with as little hassle as possible.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.macsourceports.com/"/><published>2025-10-15T13:07:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591902</id><title>M5 MacBook Pro</title><updated>2025-10-15T18:46:04.122346+00:00</updated><content>&lt;doc fingerprint="bdcaf12d1526c1d3"&gt;
  &lt;main&gt;&lt;p&gt;M5 brings next-generation speed and powerful on-device AI to college students, business users, and aspiring creators.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Available in 14”&lt;/item&gt;&lt;item&gt;Up to 6x faster &lt;lb/&gt;than M16&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Sizes. The 14-inch model is available with the M5, M4 Pro, or M4 Max chip. The 16‑inch model is available with the M4 Pro or M4 Max chip.&lt;/p&gt;&lt;p&gt;Colors. Available in two stunning finishes. MacBook Pro shown in Space Black.&lt;/p&gt;&lt;p&gt;Display. The brilliant Liquid Retina XDR display delivers up to 1,600 nits peak HDR brightness and a 1,000,000:1 contrast ratio for stunning visuals with true blacks and bright highlights.&lt;/p&gt;&lt;p&gt;Connectivity. Every MacBook Pro comes with three Thunderbolt 4 or 5 ports, an HDMI port, a MagSafe 3 port, an SDXC card slot, and a headphone jack. Connect high-speed peripherals and drive multiple external displays.11&lt;/p&gt;&lt;p&gt;Camera. The 12MP Center Stage camera keeps you in frame as you move around. And Desk View lets you share your workspace.&lt;/p&gt;&lt;p&gt;Mics and speakers. With a studio-quality three-mic array and a six-speaker sound system that supports Spatial Audio and Dolby Atmos, MacBook Pro brings incredible audio to any space.&lt;/p&gt;&lt;p&gt;Durability. Made with 100 percent recycled aluminum in the enclosure, MacBook Pro is exceptionally well built and designed to last.&lt;/p&gt;&lt;p&gt;Happily ever faster.&lt;/p&gt;&lt;p&gt;The M5 chip joins M4 Pro and M4 Max to create the most advanced series of chips ever built for a pro laptop. Each chip delivers phenomenal single- and multithreaded CPU performance and faster unified memory — giving you the kind of speed you’ve never thought possible. And with powerful Neural Accelerators in the M5 chip, you can fly through AI tasks at mind-bending speeds.&lt;/p&gt;&lt;p&gt;Up to 6x faster AI performance than M16&lt;/p&gt;&lt;p&gt;A powerful Neural Accelerator is built into each GPU core of the M5 chip, which dramatically speeds up AI tasks like image generation from diffusion models and large language model (LLM) prompt processing. The 16-core Neural Engine drives Apple Intelligence features, making on-device AI powerful and energy efficient.&lt;/p&gt;&lt;p&gt;Run graphics-intensive workflows with responsiveness that keeps up with your imagination. M5 features a GPU with enhanced shader cores and a third-generation ray tracing engine, so gaming feels more immersive and realistic. And Dynamic Caching optimizes on-chip memory to significantly increase GPU utilization — driving huge performance boosts for pro apps and games.&lt;/p&gt;&lt;p&gt;M5 brings next-generation speed and powerful on-device AI to college students, business users, and aspiring creators.&lt;/p&gt;&lt;p&gt;M4 Pro delivers even more power for scientists, engineers, software developers, and creative pros tackling intensive projects.&lt;/p&gt;&lt;p&gt;Our most advanced chip ever built for a pro laptop. M4 Max is perfect for 3D VFX artists, AI developers, and film composers.&lt;/p&gt;&lt;p&gt;The 14‑inch MacBook Pro with M5 brings serious speed and advanced on-device AI to the personal, professional, and creative work you do every day. Effortlessly multitask across apps like Asana and Keynote. Breeze through memory-intensive projects such as editing high-resolution photos and videos. M5 also powers AI features that boost your productivity — whether you want to summarize pages of lecture notes or create AI assistants that automate daily workflows for your business.&lt;/p&gt;&lt;p&gt;Faster time to first token performance6&lt;/p&gt;&lt;p&gt;Faster AI video enhancing performance in Topaz Video14&lt;/p&gt;&lt;p&gt;Faster render performance with ray tracing in Blender15&lt;/p&gt;&lt;p&gt;Faster AI speech enhancement in Adobe Premiere Pro16&lt;/p&gt;&lt;p&gt;Faster gaming performance in Cyberpunk 2077: Ultimate17&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode18&lt;/p&gt;&lt;p&gt;For those who need more power, M4 Pro speeds up everything from database design and data modeling to DNA sequencing. Whether you choose the 14- or 16‑inch model, MacBook Pro with M4 Pro handles demanding workflows with ease and delivers graphics performance that makes 3D rendering and animation faster.&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift19&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI20&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW21&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within22&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB23&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode24&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop25&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift26&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI27&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW28&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within29&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB30&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode31&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop32&lt;/p&gt;&lt;p&gt;Available on the 14- and 16‑inch MacBook Pro, the M4 Max chip is designed for the most extreme workflows. Interact with large language models with hundreds of billions of parameters. Rip through intensive creative workloads, like detailed visual effects, 3D animation, film scoring, and 8K video editing. M4 Max redefines what a laptop can do.&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift33&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI34&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW35&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within36&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB37&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode38&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop39&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift40&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI41&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW42&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within43&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB44&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode45&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop46&lt;/p&gt;&lt;p&gt;Built for AI. From the silicon up.&lt;/p&gt;&lt;p&gt;Apple silicon, and every major subsystem that powers it, is designed for AI — creating a platform that comprehensively unites hardware, software, and ecosystem. So you can run demanding on-device AI workloads with incredible power efficiency. Always knowing that security and privacy are designed in, not just bolted on.&lt;/p&gt;&lt;p&gt;Mac is optimized to handle the world’s most advanced AI apps. Run image generation apps like DiffusionBee, LLM apps like Msty AI and LM Studio, and video enhancement apps like Topaz Video.&lt;/p&gt;&lt;p&gt;Transform vocals with AI plug-ins like MicDrop for Logic Pro. And make complex image modifications in seconds with Generative Fill in Adobe Photoshop.&lt;/p&gt;&lt;p&gt;Apple Intelligence helps you write, express yourself, and get things done effortlessly. Turn a quick note into a polished announcement. Remove distractions from photos with Clean Up. Create unique images with new ChatGPT styles in Image Playground. And use intelligent actions in the Shortcuts app to create automations — like comparing an audio transcription to typed notes and extracting information from a PDF. Apple Intelligence is AI — for you and I.47&lt;/p&gt;&lt;p&gt;Apple Intelligence is designed to protect your privacy at every step. It’s integrated into the core of your Mac through on-device processing. So it’s aware of your personal information without collecting your personal information. And with groundbreaking Private Cloud Compute, Apple Intelligence can draw on larger server-based models, running on Apple silicon, to handle more complex requests for you while protecting your privacy.&lt;/p&gt;&lt;p&gt;All-day battery life. &lt;lb/&gt;Think outside the outlet. &lt;/p&gt;&lt;p&gt;MacBook Pro has the longest battery life ever in a Mac — up to 24 hours — and supports fast charge, allowing it to charge up to 50 percent in just 30 minutes.48 All models provide the same performance whether they’re plugged in or not, so you can spend more time thinking about an outlet for your passion, not your laptop.&lt;/p&gt;&lt;p&gt;macOS Tahoe introduces Liquid Glass, a refined yet familiar look. With new ways to boost your productivity, work seamlessly with iPhone, and get even more from Apple Intelligence, it’s the most beautiful and powerful version of macOS yet.&lt;/p&gt;Learn more about macOS Tahoe&lt;p&gt;Even better together.&lt;/p&gt;&lt;p&gt;Mac and iPhone are incredible on their own. But when you use them together, they work wonders. Thanks to Continuity, you can move seamlessly across devices to share files and photos, hand off tasks, and even control your iPhone from your Mac.&lt;/p&gt;&lt;p&gt;Mail, Uber Eats&lt;/p&gt;&lt;p&gt;Uber Eats&lt;/p&gt;&lt;p&gt;Notes, Microsoft PowerPoint&lt;/p&gt;&lt;p&gt;Phone app&lt;/p&gt;&lt;p&gt;Your ambitions. There’s an app for that.&lt;/p&gt;&lt;p&gt;Tens of thousands of apps are optimized for Apple silicon — from your go-to productivity apps to your favorite games and hardest-working pro apps. With MacBook Pro, they all soar.&lt;/p&gt;&lt;p&gt;Adobe Lightroom&lt;/p&gt;&lt;p&gt;Xcode&lt;/p&gt;&lt;p&gt;MATLAB&lt;/p&gt;&lt;p&gt;Keynote&lt;/p&gt;&lt;p&gt;Adobe InDesign&lt;/p&gt;&lt;p&gt;Blender&lt;/p&gt;&lt;p&gt;Logic Pro&lt;/p&gt;&lt;p&gt;DaVinci Resolve Studio&lt;/p&gt;&lt;p&gt;Cyberpunk 2077: Ultimate&lt;/p&gt;&lt;p&gt;Let there be delight.&lt;/p&gt;&lt;p&gt;Up to 1,600 nits peak HDR brightness&lt;/p&gt;&lt;p&gt;1,000 nits sustained HDR brightness&lt;/p&gt;&lt;p&gt;1,000,000:1 contrast ratio&lt;/p&gt;&lt;p&gt;Down to 1 nit brightness in dark environments&lt;/p&gt;&lt;p&gt;Up to 1,000 nits SDR brightness outdoors&lt;/p&gt;&lt;p&gt;1,000,000,000 colors&lt;/p&gt;&lt;p&gt;Go from the sunniest terrace to the darkest studio with more ease than ever. The eye-popping Liquid Retina XDR display offers up to 1,600 nits peak HDR brightness. And it provides up to 1,000 nits of brightness for SDR content in bright light so you can see what’s on your screen more clearly outside. In low-light situations, it dims to 1 nit so you can work comfortably in darker spaces.&lt;/p&gt;&lt;p&gt;The ultimate show and tell.&lt;/p&gt;&lt;p&gt;The 12MP Center Stage camera helps you look sharp in any light. Together with the advanced mics and speakers, it lets you take charge of the meeting from afar.&lt;/p&gt;&lt;p&gt;No compromises.&lt;/p&gt;&lt;p&gt;Security starts with Apple silicon and extends to the macOS architecture. This deep integration of hardware and software along with automatic software updates helps keep MacBook Pro stable and protected for the long term. The security architecture also powers features such as Touch ID, Find My, and advanced defenses that protect against viruses and malware.&lt;/p&gt;&lt;p&gt;Unlock your Mac, sign in to apps, and make secure payments with your fingertip. The Secure Enclave keeps your fingerprint data safe.&lt;/p&gt;&lt;p&gt;Locate your misplaced MacBook Pro and remotely lock or erase it if needed.&lt;/p&gt;&lt;p&gt;Encrypt and protect your files and data without having to think about it.&lt;/p&gt;&lt;p&gt;Don’t know which model you have?&lt;/p&gt;&lt;p&gt;Click the Apple logo in the upper left of your screen and choose About This Mac.&lt;/p&gt;&lt;p&gt;Here’s what you get with the new 14‑inch MacBook Pro with M5.&lt;/p&gt;&lt;p&gt;Fly through demanding AI tasks up to 86x faster.1&lt;/p&gt;&lt;p&gt;A stunning Liquid Retina XDR display.&lt;/p&gt;&lt;p&gt;Built for&lt;lb/&gt;Apple Intelligence.&lt;/p&gt;&lt;p&gt;Here’s what you get with the 16‑inch MacBook Pro with M4 Max.&lt;/p&gt;&lt;p&gt;Fly through demanding tasks up to 7.8x faster.4&lt;/p&gt;&lt;p&gt;A stunning Liquid Retina XDR display.&lt;/p&gt;&lt;p&gt;Built for&lt;lb/&gt;Apple Intelligence.&lt;/p&gt;&lt;p&gt;Here’s what you get with the new 14‑inch MacBook Pro with M5.&lt;/p&gt;&lt;p&gt;Fly through demanding AI tasks up to 6x faster.6&lt;/p&gt;&lt;p&gt;More ports and faster charging.&lt;/p&gt;&lt;p&gt;More detailed graphics and gaming with hardware-accelerated ray tracing.&lt;/p&gt;&lt;p&gt;A stunning Liquid Retina XDR display.&lt;/p&gt;&lt;p&gt;Here’s what you get with the 16‑inch MacBook Pro with M4 Max.&lt;/p&gt;&lt;p&gt;Fly through demanding tasks up to 3.5x faster.7&lt;/p&gt;&lt;p&gt;More detailed graphics and gaming with hardware-accelerated ray tracing.&lt;/p&gt;&lt;p&gt;A faster Neural Engine to get more done with AI-powered features.&lt;/p&gt;&lt;p&gt;A display with more consistent brightness in any light.&lt;/p&gt;&lt;p&gt;Get credit toward a new MacBook Pro when you trade in an eligible device.8&lt;/p&gt;See what your device is worth&lt;p&gt;Pay over time, interest‑free.&lt;/p&gt;&lt;p&gt;When you choose to check out at Apple with Apple Card Monthly Installments.◊&lt;/p&gt;&lt;p&gt;Pay for your new Mac over time, interest-free with Apple Card.◊ Simply choose to check out at Apple with Apple Card Monthly Installments as your payment option when you make your purchase. And enjoy 3% Daily Cash back, all up front. Terms apply.&lt;/p&gt;Learn more, Apple Card Monthly Installments&lt;p&gt;Save with Apple Trade In.&lt;/p&gt;&lt;p&gt;Get credit toward your next Mac when you trade in an eligible device.8&lt;/p&gt;&lt;p&gt;Just add a trade-in when you choose a new product. Once your eligible device has been received and verified, we’ll credit the value to your payment method. Or choose to check out with Apple Card Monthly Installments and we’ll apply the credit instantly. Terms apply.&lt;/p&gt;Learn more, Apple Trade In&lt;p&gt;Save with education pricing.&lt;/p&gt;&lt;p&gt;Students and educators can save exclusively through the Apple Store.**&lt;/p&gt;&lt;p&gt;Students and educators can save on MacBook Pro with education pricing.&lt;/p&gt;Learn more, Education Pricing&lt;p&gt;Join an online Personal Setup session.&lt;/p&gt;&lt;p&gt;Talk one on one with a Specialist to set up your Mac and discover new features.&lt;/p&gt;&lt;p&gt;When you buy your new Mac directly from Apple, you’ll get access to Personal Setup. In these online sessions, a Specialist can guide you through setup and data transfer or focus on features that help you make the most of your Mac. Best of all, you can join whenever works for you, from wherever you are.&lt;/p&gt;Learn more, Personal Setup&lt;p&gt;Customize your Mac.&lt;/p&gt;&lt;p&gt;Choose your chip, memory, storage, even color.&lt;/p&gt;&lt;p&gt;Build the Mac that’s best for you. When you buy online at Apple, you can customize your Mac just the way you want. Whether you need an extra-powerful chip, more memory, or additional storage, you can tailor any new Mac to suit your needs.&lt;/p&gt;Shop Mac&lt;p&gt;Get flexible delivery and easy pickup.&lt;/p&gt;&lt;p&gt;Choose two‑hour delivery from an Apple Store, free delivery, or easy pickup options.&lt;/p&gt;&lt;p&gt;Get your new Apple products quickly and easily with two‑hour delivery from an Apple Store, free next‑day delivery, or convenient Apple pickup options.&lt;/p&gt;Learn more, delivery and pickup options&lt;p&gt;Shop live with a Specialist.&lt;/p&gt;&lt;p&gt;Let us guide you live over video and answer all of your questions.&lt;/p&gt;&lt;p&gt;We can help you choose the product you need while guiding you through the online Apple Store. You won’t appear on camera. Available 7 a.m.–7 p.m. PT.&lt;/p&gt;Shop together with a Specialist&lt;p&gt;Explore a shopping experience designed around you.&lt;/p&gt;&lt;p&gt;Use the Apple Store app to get a more personal way to shop.&lt;/p&gt;&lt;p&gt;Get personalized product recommendations, compare models, access Your Saves, and track your orders. Opt in today to get updates on new products, promotions, flexible payment options, and store events.&lt;/p&gt;&lt;p&gt;Scan the QR code to get started.&lt;/p&gt;&lt;p&gt;Strikingly thin and fast so you can work, play, or create anywhere.&lt;/p&gt;&lt;p&gt;The most advanced Mac laptops for demanding workflows.&lt;/p&gt;&lt;p&gt;Our approach.&lt;/p&gt;&lt;p&gt;Using recycled materials, like 100% recycled aluminum in the enclosure, reduces the need to mine new material, which avoids the carbon emissions and environmental impacts of mining.&lt;/p&gt;Learn more in our 14-inch MacBook Pro M5 Product Environmental Report (PDF) Learn more in our 14-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF) Learn more in our 16-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF)&lt;p&gt;How you can help.&lt;/p&gt;&lt;p&gt;You can protect the earth’s precious resources by trading in, passing down, or recycling devices and accessories you no longer use. You can bring them into any Apple Store for free, secure recycling. We also offer other ways to recycle, including mail-in options.&lt;/p&gt;Learn how to trade in or recycle devices&lt;p&gt;Our approach.&lt;/p&gt;&lt;p&gt;Using electricity from renewable sources like wind and solar across our global supply chain — instead of fossil fuels — significantly reduces carbon emissions from manufacturing Apple products.&lt;/p&gt;Learn more in our 14-inch MacBook Pro M5 Product Environmental Report (PDF) Learn more in our 14-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF) Learn more in our 16-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF)&lt;p&gt;How you can help.&lt;/p&gt;&lt;p&gt;You can extend the lifespan of your batteries and Apple products by using Optimized Battery Charging. It works by learning your charging habits and delaying the final charge — from 80% to 100% — until you are likely to need it.&lt;/p&gt;Learn more about Optimized Battery Charging&lt;p&gt;Our approach.&lt;/p&gt;&lt;p&gt;MacBook Pro comes in paper packaging that is 100% fiber-based, as part of our commitment to remove plastic from the packaging of all Apple products.&lt;/p&gt;Learn more in our 14-inch MacBook Pro M5 Product Environmental Report (PDF) Learn more in our 14-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF) Learn more in our 16-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF)&lt;p&gt;How you can help.&lt;/p&gt;&lt;p&gt;New Apple products come in paper packaging that’s 100% fiber-based. In most places, you can put the entire box into your household recycling bin. You can also bring Apple packaging to any Apple Store and we’ll recycle it for free.&lt;/p&gt;Learn more about recycling&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/macbook-pro/"/><published>2025-10-15T13:10:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591905</id><title>iPad Pro with M5 chip</title><updated>2025-10-15T18:46:03.759636+00:00</updated><content>&lt;doc fingerprint="bddbbebdc82a4ddc"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple introduces the powerful new iPad Pro with the M5 chip&lt;/head&gt;
    &lt;p&gt; The new iPad Pro features the next generation of Apple silicon, with a big leap in AI performance, faster storage, and the game-changing capabilities of iPadOS 26 &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today introduced the new iPad Pro featuring the incredibly powerful M5 chip. M5 unlocks the most advanced iPad experience ever, packing an incredible amount of power and AI performance into the ultraportable design of iPad Pro. Featuring a next-generation GPU with a Neural Accelerator in each core, M5 delivers a big boost in performance for iPad Pro users, whether they’re working on cutting-edge projects or tapping into AI for productivity. The new iPad Pro delivers up to 3.5x the AI performance than iPad Pro with M41 and up to 5.6x faster than iPad Pro with M1.2 N1, the new Apple-designed wireless networking chip, enables the latest generation of wireless technologies with support for Wi-Fi 7 on iPad Pro. The C1X modem comes to cellular models of iPad Pro, delivering up to 50 percent faster cellular data performance than its predecessor with even greater efficiency, allowing users to do more on the go. Available in space black and silver, iPad Pro comes in 11-inch and 13-inch sizes, and features the Ultra Retina XDR display for an unparalleled viewing experience. The game-changing features of iPadOS 26 supercharge iPad Pro and help users handle demanding creative and professional tasks with ease. With staggering performance gains and breakthrough improvements over M1 models, there has never been a better time to upgrade. The new iPad Pro is available to pre-order starting today, and will be available in stores beginning Wednesday, October 22. &lt;/p&gt;
    &lt;p&gt;“Powered by the next generation of Apple silicon, the new iPad Pro delivers our most advanced and versatile iPad experience yet,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “iPad Pro with M5 unlocks endless possibilities for creativity and productivity — with a huge leap in AI performance and a big boost in graphics, superfast wireless connectivity, and game-changing iPadOS 26 features, it pushes the boundaries of what iPad can do yet again.” &lt;/p&gt;
    &lt;head rend="h2"&gt;M5: The Next Big Leap in AI for iPad&lt;/head&gt;
    &lt;p&gt;Apple silicon continues to set iPad apart with industry-leading performance, advanced technologies, power efficiency, and AI capabilities. With the M5 chip powering iPad Pro, AI on iPad takes its next big leap, with a more advanced GPU and CPU, and a faster Neural Engine. The 10-core GPU introduces a new architecture with a Neural Accelerator in each core, resulting in a massive boost in GPU performance for AI workloads. M5 delivers AI performance that’s up to 3.5x faster compared to M4,1 and up to 5.6x faster than iPad Pro with M1.2 The new iPad Pro is designed for AI and accelerates a wide variety of workloads, such as on-device diffusion-based image generation in apps like Draw Things, and AI video masking in apps like DaVinci Resolve. And the faster 16-core Neural Engine delivers the most energy-efficient performance for on-device AI, perfect for apps that use the Foundation Models framework and for Apple Intelligence features like creating in Image Playground.3 &lt;/p&gt;
    &lt;head rend="h2"&gt;Next-Level Performance with M5&lt;/head&gt;
    &lt;p&gt;The M5 chip brings next-level performance, with a significant boost to graphics performance and a faster CPU. Incorporating a third-generation ray-tracing engine enabling more realistic lighting, reflections, and shadows — M5 is ideal for visually intensive applications and gaming — iPad Pro has up to 1.5x faster 3D rendering with ray tracing than the previous-generation iPad Pro,1 and up to a whopping 6.7x faster rendering performance than iPad Pro with M1.2 M5 has up to a 10-core CPU, with four performance cores and six efficiency cores, and is the world’s fastest CPU core. The faster CPU is perfect for a range of users, including graphic designers working with complex vector graphics in apps like Adobe Illustrator, architects who routinely multitask across apps like SketchUp and Morpholio Trace, and business users who need to quickly launch and access large files across multiple apps. &lt;/p&gt;
    &lt;p&gt;iPad Pro with M5 delivers: &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 6.7x faster 3D rendering with ray tracing in Octane X when compared to iPad Pro with M1,2 and up to 1.5x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 6x faster video transcode performance in Final Cut Pro for iPad when compared to iPad Pro with M1,2 and up to 1.2x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 4x faster AI image generation performance in Draw Things for iPad when compared to iPad Pro with M1,2 and up to 2x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 3.7x faster AI video upscaling performance in DaVinci Resolve for iPad when compared to iPad Pro with M1,2 and up to 2.3x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Faster Memory Bandwidth and Storage for More Seamless Multitasking&lt;/head&gt;
    &lt;p&gt;iPad Pro brings new enhancements to accelerate overall speed and responsiveness, including an increase in unified memory bandwidth, faster storage read and write speeds, more starting unified memory, and fast charge support. With over 150GB/s of unified memory bandwidth — a nearly 30 percent increase compared to the previous generation — the new iPad Pro helps users multitask across more apps, process AI models faster, play demanding games, and more. The new iPad Pro offers up to 2x faster storage read and write speeds, and the 256GB and 512GB models start with 12GB of unified memory — 50 percent more than before, bringing even more value. And with the new windowing system in iPadOS 26, iPad Pro users will experience more seamless multitasking, enhancing even the most complex workflows. Additionally, iPad Pro supports fast charge — enabling up to a 50 percent charge in around 30 minutes4 with an optional high-wattage USB-C power adapter like Apple’s new 40W Dynamic Power Adapter with 60W Max.5 &lt;/p&gt;
    &lt;head rend="h2"&gt;The C1X and N1 Chips Come to iPad&lt;/head&gt;
    &lt;p&gt;Cellular models of iPad Pro feature C1X, a cellular modem designed by Apple that brings users up to 50 percent faster cellular data performance, and for active cellular users, up to 30 percent less power usage than iPad Pro with M4. Cellular models of iPad Pro allow users to enjoy GPS and location capabilities, so they can navigate with even more confidence. Users can also enjoy 5G cellular support, so they can stay connected for work or leisure all around the world. And with eSIM, users can quickly and securely add a new plan, connect and transfer existing cellular plans digitally, and stay in touch with family and friends regardless of Wi-Fi availability — perfect for users working on the go, like frequent business travelers or architects out in the field. &lt;/p&gt;
    &lt;p&gt;The new iPad Pro also features N1, a new Apple-designed wireless networking chip that enables Wi-Fi 7, Bluetooth 6, and Thread. N1 brings better performance when connected to 5GHz networks, and improves the overall performance and reliability of features like Personal Hotspot and AirDrop. &lt;/p&gt;
    &lt;head rend="h2"&gt;An Unrivaled Design and Display&lt;/head&gt;
    &lt;p&gt;iPad Pro offers users the ultimate level of portability in a stunningly thin and light design. Available in space black and silver, the 11-inch model is just 5.3 mm thin, and the 13-inch model is even thinner at a striking 5.1 mm. The Ultra Retina XDR display — the world’s most advanced display — features groundbreaking tandem OLED technology that delivers extreme brightness, incredibly precise contrast, and technologies like ProMotion and True Tone. iPad Pro supports 1000 nits of full-screen brightness for SDR and HDR content, and 1600 nits peak brightness for HDR. And for users who work with high-end, color-managed workflows or in challenging lighting conditions, iPad Pro offers a nano-texture display glass option for reduced glare that is precisely etched at a nanometer scale, maintaining image quality and contrast while scattering ambient light. &lt;/p&gt;
    &lt;p&gt;The new iPad Pro adds the ability to drive external displays at up to 120Hz — ideal for creative workflows like video editing as well as gaming. And for users with a 120Hz external display, iPad Pro also brings new support for Adaptive Sync, which provides the lowest possible latency in external display performance, resulting in smoother motion and fewer perceived glitches, useful for low-latency use cases like gaming. &lt;/p&gt;
    &lt;head rend="h2"&gt;iPadOS 26 Supercharges the iPad Experience&lt;/head&gt;
    &lt;p&gt;iPadOS 26 introduces a new design and powerful features that help users handle demanding creative and professional tasks with ease, and push the capabilities and versatility of iPad even further. &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The beautiful new design is crafted with Liquid Glass, a translucent new material that reflects and refracts its surroundings, while reacting to users’ input and dynamically transforming to bring greater focus to the content they care about most.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An entirely new, powerful, and intuitive windowing system helps users control, organize, and switch between apps, all while maintaining the simplicity of iPad. And with a new menu bar, users can access the commands available in an app with a simple swipe down from the top of the display, or by moving their cursor to the top.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;iPadOS 26 introduces new ways to manage, access, and organize files with a supercharged Files app featuring an updated List view and new folder customization options. With folders in the Dock, users can conveniently access downloads, documents, and more from anywhere. Additionally, users can set a default app for opening specific files or file types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Preview app comes to iPad, giving users a dedicated app to view and edit PDFs, with powerful features like Apple Pencil Markup and AutoFill built in.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Taking advantage of Apple silicon, iPadOS 26 unlocks new capabilities for creative pros with Background Tasks, more control over their audio input, and the ability to capture high-quality recordings with local capture.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Intelligence delivers helpful and relevant intelligence that is deeply integrated across operating systems, while taking an extraordinary step forward for privacy in AI.6 New features across iPadOS 26 include Live Translation in Phone, FaceTime, and Messages;7 new intelligent actions in Shortcuts; the ability to identify and automatically categorize relevant actions in Reminders; and more.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Advanced Accessories for iPad Pro&lt;/head&gt;
    &lt;p&gt;Accessories extend the versatility of iPad Pro, opening up even more possibilities for creativity and productivity. Apple Pencil Pro and Apple Pencil (USB-C) offer users two incredible options for illustrating, note-taking, annotating, and more. The thin and light Magic Keyboard for iPad Pro provides the most advanced experience with a floating design, function row, and gorgeous aluminum palm rest. iPad Pro is also compatible with the Smart Folio for iPad Pro, which attaches magnetically and supports multiple viewing angles. &lt;/p&gt;
    &lt;head rend="h2"&gt;iPad Pro and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The new iPad Pro is made with 30 percent recycled content by weight, including 100 percent recycled aluminum in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled cobalt in the battery. It is manufactured with 55 percent renewable electricity, like wind and solar, across the supply chain. iPad Pro is also designed to last and offers industry-leading software support while meeting Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled. &lt;/p&gt;
    &lt;p&gt;Pricing and Availability &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers can pre-order iPad Pro with M5 starting today on apple.com/store, and in the Apple Store app in 31 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, starting Wednesday, October 22.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 11-inch and 13-inch iPad Pro with M5 will be available in silver and space black finishes in 256GB, 512GB, 1TB, and 2TB configurations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 11-inch iPad Pro starts at $999 (U.S.) for the Wi-Fi model, and $1,199 (U.S.) for the Wi-Fi + Cellular model. The 13-inch iPad Pro starts at $1,299 (U.S.) for the Wi-Fi model, and $1,499 (U.S.) for the Wi-Fi + Cellular model. Additional technical specifications, including nano-texture glass options, are available at apple.com/store.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;With education savings, the 11-inch iPad Pro starts at $899 (U.S.), and the 13-inch iPad Pro starts at $1,199 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Pencil Pro and Apple Pencil (USB-C) are compatible with the new iPad Pro. Apple Pencil Pro is available for $129 (U.S.), and $119 (U.S.) with education savings. Apple Pencil (USB-C) is available for $79 (U.S.), and $69 (U.S.) with education savings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Magic Keyboard for iPad Pro is available in black and white finishes. The 11-inch Magic Keyboard is available for $299 (U.S.), and the new 13-inch Magic Keyboard is available for $349 (U.S.). With education savings, the 11-inch Magic Keyboard is available for $279 (U.S.), and the 13-inch Magic Keyboard is available for $329 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Magic Keyboard for iPad Air with M3 is now available in black, and is compatible with the 11-inch and 13-inch iPad Air. The 11-inch Magic Keyboard is available for $269 (U.S.), and the 13-inch Magic Keyboard is available for $319 (U.S.). With education savings, the 11-inch Magic Keyboard is available for $249 (U.S.), and the 13-inch Magic Keyboard is available for $299 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Apple-designed 40W Dynamic Power Adapter with 60W Max is available for $39 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new iPad, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit apple.com/applecare.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple offers great ways to save on the latest iPad. Customers can trade in their current iPad and get credit toward a new one by visiting the Apple Store online, the Apple Store app, or an Apple Store location. To see what their device is worth, and for terms and conditions, customers can visit apple.com/shop/trade-in.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers in the U.S. who shop at Apple using Apple Card can pay monthly at 0 percent APR when they choose to check out with Apple Card Monthly Installments, and they’ll get 3 percent Daily Cash back — all up front. More information — including details on eligibility, exclusions, and Apple Card terms — is available at apple.com/apple-card/monthly-installments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Images in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Results are compared to iPad Pro 13-inch (M4) units with 10-core CPU and 16GB of unified memory.&lt;/item&gt;
      &lt;item&gt;Results are compared to iPad Pro 12.9-inch (5th generation) units with 8-core CPU and 16GB of unified memory.&lt;/item&gt;
      &lt;item&gt;Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.&lt;/item&gt;
      &lt;item&gt;Testing was conducted by Apple in August and September 2025. See apple.com/ipad-pro for more information.&lt;/item&gt;
      &lt;item&gt;The 40W Dynamic Power Adapter with 60W Max is available in Canada, China mainland, Japan, Mexico, Taiwan, the Philippines, and the U.S.&lt;/item&gt;
      &lt;item&gt;Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
      &lt;item&gt;Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified). Live Translation in Phone and FaceTime is available for one-on-one calls in English (UK, U.S.), French (France), German (Germany), Portuguese (Brazil), and Spanish (Spain) when Apple Intelligence is enabled, on a compatible iPhone, iPad, or Mac. Later this year, Live Translation in Phone and FaceTime will add language support for Chinese (Mandarin, simplified), Chinese (Mandarin, traditional), Italian, Japanese, and Korean. Some features may not be available in all regions or languages.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/"/><published>2025-10-15T13:10:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45592271</id><title>F5 says hackers stole undisclosed BIG-IP flaws, source code</title><updated>2025-10-15T18:46:03.380279+00:00</updated><content>&lt;doc fingerprint="a44e181ad817d7ce"&gt;
  &lt;main&gt;
    &lt;p&gt;U.S. cybersecurity company F5 disclosed that nation-state hackers breached its systems and stole undisclosed BIG-IP security vulnerabilities and source code.&lt;/p&gt;
    &lt;p&gt;The company states that it first became aware of the breach on August 9, 2025, with its investigations revealing that the attackers had gained long-term access to its system, including the company's BIG-IP product development environment and engineering knowledge management platform.&lt;/p&gt;
    &lt;p&gt;F5 is a Fortune 500 tech giant specializing in cybersecurity, cloud management, and application delivery networking (ADN) applications. The company has 23,000 customers in 170 countries, and 48 of the Fortune 50 entities use its products.&lt;/p&gt;
    &lt;p&gt;BIG-IP is the firm's flagship product used for application delivery and traffic management by many large enterprises worldwide.&lt;/p&gt;
    &lt;head rend="h3"&gt;No supply-chain risk&lt;/head&gt;
    &lt;p&gt;It’s unclear how long the hackers maintained access, but the company confirmed that they stole source code, vulnerability data, and some configuration and implementation details for a limited number of customers.&lt;/p&gt;
    &lt;p&gt;"Through this access, certain files were exfiltrated, some of which contained certain portions of the Company's BIG-IP source code and information about undisclosed vulnerabilities that it was working on in BIG-IP," the company states.&lt;/p&gt;
    &lt;p&gt;Despite this critical exposure of undisclosed flaws, F5 says there's no evidence that the attackers leveraged the information in actual attacks, such as exploiting the undisclosed flaw against systems. The company also states that it has not seen evidence that the private information has been disclosed.&lt;/p&gt;
    &lt;p&gt;F5 claims that the threat actors' access to the BIG-IP environment did not compromise its software supply chain or result in any suspicious code modifications.&lt;/p&gt;
    &lt;p&gt;This includes its platforms that contain customer data, such as its CRM, financial, support case management, or iHealth systems. Furthermore, other products and platforms managed by the company are not compromised, including NGINX, F5 Distributed Cloud Services, or Silverline systems' source code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Response to the breach&lt;/head&gt;
    &lt;p&gt;After discovering the intrusion, F5 took remediation action by tightening access to its systems, and improving its overall threat monitoring, detection, and response capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rotated credentials and strengthened access controls across our systems.&lt;/item&gt;
      &lt;item&gt;Deployed improved inventory and patch management automation, as well as additional tooling to better monitor, detect, and respond to threats.&lt;/item&gt;
      &lt;item&gt;Implemented enhancements to our network security architecture.&lt;/item&gt;
      &lt;item&gt;Hardened our product development environment, including strengthening security controls and monitoring of all software development platforms.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additionally, the company also focuses on the security of its products through source code reviews and security assessements with support from NCC Group and IOActive.&lt;/p&gt;
    &lt;p&gt;NCC Group's assessment covered security reviews of critical software components in BIG-IP and portions of the development pipeline in an effort that involved 76 consultants.&lt;/p&gt;
    &lt;p&gt;IOActive's expertise was called in after the security breach and the engagement is still in progress. The results so far show no evidence of the threat actor introducing vulnerablities in critical F5 software source code or the software development build pipeline.&lt;/p&gt;
    &lt;head rend="h3"&gt;Customers should take action&lt;/head&gt;
    &lt;p&gt;F5 is still reviewing which customers had their configuration or implementation details stolen and will contact them with guidance.&lt;/p&gt;
    &lt;p&gt;To help customers secure their F5 environments against risks stemming from the breach, the company released updates for BIG-IP, F5OS, BIG-IP Next for Kubernetes, BIG-IQ, and APM clients.&lt;/p&gt;
    &lt;p&gt;Despite any evidence "of undisclosed critical or remote code execution vulnerabilities," the company urges customers to prioritize installing the new BIG-IP software updates.&lt;/p&gt;
    &lt;p&gt;Furthermore, F5 support makes available a threat hunting guide for customers to improve detection and monitoring in their environment.&lt;/p&gt;
    &lt;p&gt;New best practices for hardening F5 systems now include automated checks to the F5 iHealth Diagnostic Tool, which can now flag security risks, vulnerabilities, prioritize actions, and provide remediation guidance.&lt;/p&gt;
    &lt;p&gt;Another recommendation is to enable BIG-IP event streaming to SIEM and configure the systems to log to a remote syslog server and monitor for login attempts.&lt;/p&gt;
    &lt;p&gt;"Our global support team is available to assist. You can open a MyF5 support case or contact F5 support directly for help updating your BIG-IP software, implementing any of these steps, or to address any questions you may have" - F5&lt;/p&gt;
    &lt;p&gt;The company added that it has validated the safety of BIG-IP releases through multiple independent reviews by leading cybersecurity firms, including CrowdStrike and Mandiant.&lt;/p&gt;
    &lt;p&gt;Additional guidance for F5 customers comes from UK's National Cyber Security Centre (NCSC) and the U.S. Cybersecurity and Infrastructure Security Agency (CISA).&lt;/p&gt;
    &lt;p&gt;Both agencies recommmend identifying all F5 products (hardware, software, and virtualized) and making sure that no management interface is exposed on the public web. If an exposed interface is discovered, companies should make compromise assessment.&lt;/p&gt;
    &lt;p&gt;F5 notes that it delayed the public disclosure of the incident at the U.S. government's request, presumably to allow enough time to secure critical systems.&lt;/p&gt;
    &lt;p&gt;"On September 12, 2025, the U.S. Department of Justice determined that a delay in public disclosure was warranted pursuant to Item 1.05(c) of Form 8-K. F5 is now filing this report in a timely manner," explains F5.&lt;/p&gt;
    &lt;p&gt;F5 states that the incident has no material impact on its operations. All services remain available and are considered safe, based on the latest available evidence.&lt;/p&gt;
    &lt;p&gt;BleepingComputer has contacted F5 to request more details about the incident, and we will update this post when we receive a response.&lt;/p&gt;
    &lt;p&gt;This is a developing story.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Security Validation Event of the Year: The Picus BAS Summit&lt;/head&gt;
    &lt;p&gt;Join the Breach and Attack Simulation Summit and experience the future of security validation. Hear from top experts and see how AI-powered BAS is transforming breach and attack simulation.&lt;/p&gt;
    &lt;p&gt;Don't miss the event that will shape the future of your security strategy&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bleepingcomputer.com/news/security/f5-says-hackers-stole-undisclosed-big-ip-flaws-source-code/"/><published>2025-10-15T13:33:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45592401</id><title>Pwning the Nix ecosystem</title><updated>2025-10-15T18:46:03.227507+00:00</updated><content>&lt;doc fingerprint="4f2c49954c2797ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Pwning the Entire Nix Ecosystem&lt;/head&gt;
    &lt;p&gt;last year at nixcon, me and my friend lexi gave a lightning talk about how we found a vulnerability in nixpkgs that would have allowed us to pwn pretty much the entire nix ecosystem and inject malicious code into nixpkgs. it only took us about a day from starting our search to reporting it and getting it fixed. since i unfortunately was too sick to attend this years nixcon, i thought it might be a good time to write up what we found and how we did it.&lt;/p&gt;
    &lt;head rend="h2"&gt;github actions: the easy target #&lt;/head&gt;
    &lt;p&gt;github actions is a ci/cd system by github that can do pretty much anything in a repo. it’s an easy target for attackers because if you have access to a workflow, you can just commit code without authorization and then you have a supply chain attack. plus, it’s all written in yaml 🇳🇴, which was NEVER meant to be executed !!&lt;/p&gt;
    &lt;code&gt;name: learn-github-actions
on: [push]
jobs:
  check-bats-version:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm install -g bats
      - run: bats -v
&lt;/code&gt;
    &lt;p&gt;this is a simple example of a github action. nothing fancy, just running some commands when code is pushed.&lt;/p&gt;
    &lt;head rend="h2"&gt;the dangerous pull_request_target #&lt;/head&gt;
    &lt;p&gt;actions run when a trigger activates them. there are a bunch of different triggers like pushes, commits, or pull requests. but there’s a special one called &lt;code&gt;pull_request_target&lt;/code&gt; that has a few critical differences from regular &lt;code&gt;pull_request&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;crucially, unlike &lt;code&gt;pull_request&lt;/code&gt;, &lt;code&gt;pull_request_target&lt;/code&gt; has read/write and secret access by default, even on pull requests from forks. this isn’t vulnerable by itself, but things go south when you start trusting user input from those PRs.&lt;/p&gt;
    &lt;p&gt;github even warns about this in their docs:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Warning: For workflows that are triggered by the&lt;/p&gt;&lt;code&gt;pull_request_target&lt;/code&gt;event, the&lt;code&gt;GITHUB_TOKEN&lt;/code&gt;is granted read/write repository permission unless the&lt;code&gt;permissions&lt;/code&gt;key is specified and the workflow can access secrets, even when it is triggered from a fork.&lt;/quote&gt;
    &lt;p&gt;so we started looking for workflows in nixpkgs that use &lt;code&gt;pull_request_target&lt;/code&gt; and found 14 files. some of them were secure, like this labeler example:&lt;/p&gt;
    &lt;code&gt;name: "Label PR"
on:
  pull_request_target:
jobs:
  labels:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/labeler@8558fd74291d67161a8a
        with:
          repo-token: $
&lt;/code&gt;
    &lt;p&gt;this is safe because it just passes the token to a trusted action. but then we found some more interesting ones…&lt;/p&gt;
    &lt;head rend="h2"&gt;the editorconfig vulnerability #&lt;/head&gt;
    &lt;p&gt;the first vulnerable workflow we found was for checking editorconfig rules. here’s a simplified version of what it was doing:&lt;/p&gt;
    &lt;code&gt;steps:
  - name: Get list of changed files from PR
    run: gh api [...] | jq [ ... ] &amp;gt; "$HOME/changed_files"
  - uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871
    with:
      ref: refs/pull/$/merge
  - name: Checking EditorConfig
    run: cat "$HOME/changed_files" | xargs -r editorconfig-checker
&lt;/code&gt;
    &lt;p&gt;the workflow would:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;get a list of files changed in the PR&lt;/item&gt;
      &lt;item&gt;checkout the PR code&lt;/item&gt;
      &lt;item&gt;run editorconfig-checker on those files&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;the problem? it was using &lt;code&gt;xargs&lt;/code&gt; to pass the filenames to editorconfig-checker. if you’ve read the man page for xargs, you’ll see this warning:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It is not possible for xargs to be used securely&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;basically, we could create a file with a name that’s actually a command line argument. for example, if we added a file called &lt;code&gt;--help&lt;/code&gt; to our PR, when the workflow ran &lt;code&gt;cat "$HOME/changed_files" | xargs -r editorconfig-checker&lt;/code&gt;, the filename would be passed as an argument to editorconfig-checker, causing it to print its help message instead of checking files.&lt;/p&gt;
    &lt;p&gt;this is a classic command injection vulnerability. we didn’t take it further to try to execute arbitrary code since editorconfig-checker is written in go and we’d need to audit it more deeply, but it’s most likely possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;the code owners vulnerability: local file inclusion #&lt;/head&gt;
    &lt;p&gt;the second vulnerable workflow we found was even more serious. it was checking the CODEOWNERS file in PRs:&lt;/p&gt;
    &lt;code&gt;steps:
  - uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf
    with:
      ref: refs/pull/$/merge
      path: pr
  - run: nix-build base/ci -A codeownersValidator
  - run: result/bin/codeowners-validator
    env:
      OWNERS_FILE: pr/ci/OWNERS
&lt;/code&gt;
    &lt;p&gt;the workflow would:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;checkout the PR code&lt;/item&gt;
      &lt;item&gt;build the codeowners validator&lt;/item&gt;
      &lt;item&gt;run the validator on the OWNERS file from the PR&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;the validator would echo the contents of the OWNERS file if there was an error. this meant we could put whatever we wanted in that file and it would get printed in the logs.&lt;/p&gt;
    &lt;p&gt;but it gets worse. since the workflow was checking out our PR code, we could replace the OWNERS file with a symbolic link to ANY file on the runner. like, say, the github actions credentials file:&lt;/p&gt;
    &lt;code&gt;$ rm OWNERS
$ ln -s /home/runner/runners/2.320.0/.credentials OWNERS
&lt;/code&gt;
    &lt;p&gt;when the validator ran, it would try to read our symlinked file and helpfully print out an error message containing the first line:&lt;/p&gt;
    &lt;p&gt;and just like that, we had a github actions token with read/write access to nixpkgs. this would let us push directly to nixpkgs, bypassing all the normal review processes.&lt;/p&gt;
    &lt;head rend="h2"&gt;the fix #&lt;/head&gt;
    &lt;p&gt;after we found these vulnerabilities, we reported them to the nixpkgs maintainers, in this case infinisil, who immediately took action:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;they disabled the vulnerable workflows in the repos action settings&lt;/item&gt;
      &lt;item&gt;they fixed the vulnerabilities by properly separating untrusted data from privileged operations&lt;/item&gt;
      &lt;item&gt;they renamed the fixed workflows after the security fixes, this is because of another pitfall with &lt;code&gt;pull_request_target&lt;/code&gt;allowing you to target any branch the action is on, even if it’s 5 or 10 years old as long as it hasn’t been disabled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;the key lessons from this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;avoid mixing untrusted data and secrets, or be very careful with them&lt;/item&gt;
      &lt;item&gt;only allow the permissions you really need&lt;/item&gt;
      &lt;item&gt;read the docs about permissions very carefully&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;if you think your org has vulnerable github actions, you can use the panic button too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;go to your org at https://github.com/[org]&lt;/item&gt;
      &lt;item&gt;go to the “Settings” tab&lt;/item&gt;
      &lt;item&gt;go to “Actions” → “General” section&lt;/item&gt;
      &lt;item&gt;under “Policies”, switch “All repositories” to “Disable”&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;conclusion #&lt;/head&gt;
    &lt;p&gt;it only took us about a day to find, report, and help fix a vulnerability that could have compromised the entire nix ecosystem. this shows how important it is to be careful with github actions, especially when dealing with &lt;code&gt;pull_request_target&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;big thanks to intrigus and everyone at KITCTF (intrigus gave a talk about exactly these issues that taught us how this works), and thanks to infinisil for fixing this on the same day we reported it.&lt;/p&gt;
    &lt;p&gt;if you want to learn more, check out these resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://kitctf.de/talks/2023-10-26-insecure-github-actions/insecure-github-actions.pdf&lt;/item&gt;
      &lt;item&gt;https://securitylab.github.com/resources/github-actions-preventing-pwn-requests/&lt;/item&gt;
      &lt;item&gt;https://github.com/NixOS/nixpkgs/pull/351446&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;also, if you’re curious, you can watch our original lightning talk from nixcon&lt;/p&gt;
    &lt;p&gt;anyway that’s all. stay safe with your github actions. meow :3&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ptrpa.ws/nixpkgs-actions-abuse"/><published>2025-10-15T13:41:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45592585</id><title>A kernel stack use-after-free: Exploiting Nvidia's GPU Linux drivers</title><updated>2025-10-15T18:46:02.457135+00:00</updated><content>&lt;doc fingerprint="fe119d1b2c221259"&gt;
  &lt;main&gt;
    &lt;p&gt;Author Robin Bastide&lt;/p&gt;
    &lt;p&gt;Category Exploitation&lt;/p&gt;
    &lt;p&gt;Tags exploitation, vulnerability, NVIDIA, GPU, CVE-2025-23280, CVE-2025-23330, 2025&lt;/p&gt;
    &lt;p&gt;This article details two bugs discovered in the NVIDIA Linux Open GPU Kernel Modules and demonstrates how they can be exploited. The bugs can be triggered by an attacker controlling a local unprivileged process. Their security implications were confirmed via a proof of concept that achieves kernel read and write primitives.&lt;/p&gt;
    &lt;head rend="h1"&gt;The NVIDIA Open source driver&lt;/head&gt;
    &lt;p&gt;Back in 2022, NVIDIA started distributing the Linux Open GPU Kernel Modules. Since 2024, using these modules is officially "the right move" for both consumer and server hardware. The driver provides multiple kernel modules, the bugs being found in &lt;code&gt;nvidia.ko&lt;/code&gt; and &lt;code&gt;nvidia-uvm.ko&lt;/code&gt;. They expose ioctls on device files, most of them being accessible to unprivileged users. These ioctls are meant to be used by NVIDIA's proprietary userland binaries and libraries. However, using the header files provided in the kernel modules repository as a basis, it's possible to make direct ioctl calls.&lt;/p&gt;
    &lt;p&gt;While manually probing the attack surface related to memory allocation and management we found two vulnerabilities. They were reported to NVIDIA and the vendor issued fixes in their NVIDIA GPU Display Drivers update of October 2025&lt;/p&gt;
    &lt;head rend="h1"&gt;Bug #1: Kernel null-pointer dereference in &lt;code&gt;nvidia-uvm&lt;/code&gt; module (CVE-2025-23300)&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;UVM_MAP_EXTERNAL_ALLOCATION&lt;/code&gt; ioctl of the &lt;code&gt;nvidia-uvm&lt;/code&gt; module allows mapping memory allocated from the main &lt;code&gt;nvidia&lt;/code&gt; module into the Unified Virtual Memory framework. This includes memory allocations of type &lt;code&gt;NV01_MEMORY_DEVICELESS&lt;/code&gt; which are not associated with any device and therefore have the &lt;code&gt;pGpu&lt;/code&gt; field of their corresponding &lt;code&gt;MEMORY_DESCRIPTOR&lt;/code&gt; structure set to null. The ioctl call leads to an unchecked use of this field, resulting in a kernel null-pointer dereference. An example stack trace is provided below:&lt;/p&gt;
    &lt;code&gt;// linux 6.11.0-24 + nvidia 570.86.15 from Ubuntu Noble

osIovaMap+0x11e/0x630 [nvidia]
iovaspaceAcquireMapping_IMPL+0x232/0x470 [nvidia]
memdescMapIommu+0x90/0x300 [nvidia]
dupMemory+0x2d9/0x830 [nvidia]
nvUvmInterfaceDupMemory+0x44/0xe0 [nvidia]
uvm_map_external_allocation_on_gpu+0x298/0x500 [nvidia_uvm]
uvm_api_map_external_allocation+0x5dd/0x860 [nvidia_uvm]
uvm_ioctl+0x1aad/0x1e70 [nvidia_uvm]
uvm_unlocked_ioctl_entry.part.0+0x7b/0xf0 [nvidia_uvm]
uvm_unlocked_ioctl_entry+0x6a/0x90 [nvidia_uvm]
__x64_sys_ioctl+0xa3/0xf0
x64_sys_call+0x11ad/0x25f0
do_syscall_64+0x7e/0x170
&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;ð ï¸â NVIDIA Fix&lt;/p&gt;&lt;p&gt;A new check was added to the function&lt;/p&gt;&lt;code&gt;dupMemory&lt;/code&gt;so that operations that require valid GPU contexts are skipped for deviceless memory.&lt;/quote&gt;
    &lt;head rend="h1"&gt;Bug #2: Kernel use-after-free in &lt;code&gt;threadStateInit()&lt;/code&gt; and &lt;code&gt;threadStateFree()&lt;/code&gt; in &lt;code&gt;nvidia&lt;/code&gt; module (CVE-2025-23280)&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;threadStateInit()&lt;/code&gt; and &lt;code&gt;threadStateFree()&lt;/code&gt; functions are used in multiple locations of the &lt;code&gt;open-gpu-kernel-modules&lt;/code&gt; codebase. They are always used as a pair to encapsulate specific operations, as seen in the following example:&lt;/p&gt;
    &lt;code&gt;// src/nvidia/src/kernel/rmapi/mapping.c (line 433)

NV_STATUS
rmapiMapWithSecInfoTls
(
    RM_API            *pRmApi,
    NvHandle           hClient,
    NvHandle           hDevice,
    NvHandle           hMemCtx,
    NvHandle           hMemory,
    NvU64              offset,
    NvU64              length,
    NvU32              flags,
    NvU64             *pDmaOffset,
    API_SECURITY_INFO *pSecInfo
)
{
    THREAD_STATE_NODE threadState;
    NV_STATUS         status;

    threadStateInit(&amp;amp;threadState, THREAD_STATE_FLAGS_NONE);

    status = rmapiMapWithSecInfo(pRmApi, hClient, hDevice, hMemCtx, hMemory, offset,
                                 length, flags, pDmaOffset, pSecInfo);

    threadStateFree(&amp;amp;threadState, THREAD_STATE_FLAGS_NONE);

    return status;
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;threadState&lt;/code&gt; structure will be inserted into a global red-black tree (&lt;code&gt;threadStateDatabase.dbRoot&lt;/code&gt;) during &lt;code&gt;threadStateInit()&lt;/code&gt; and removed during &lt;code&gt;threadStateFree()&lt;/code&gt;. The fact that this structure is always stack-allocated is dangerous if a kernel oops occurs between the two function calls. The oops will lead to the kernel stack for this task being freed on modern Linux kernels, which use virtual stacks allocated through &lt;code&gt;vmalloc&lt;/code&gt;. As a result, an invalid pointer to the now freed stack would remain in the global tree structure. This is exactly what happens when bug #1 is triggered: &lt;code&gt;threadStateInit()&lt;/code&gt; is called during &lt;code&gt;dupMemory()&lt;/code&gt; (in &lt;code&gt;src/nvidia/src/kernel/rmapi/nv_gpu_ops.c&lt;/code&gt;) and the null-pointer dereference happens before the call to &lt;code&gt;threadStateFree()&lt;/code&gt;. The following stack trace shows the use-after-free being triggered by a call to &lt;code&gt;open&lt;/code&gt; on &lt;code&gt;/dev/nvidia0&lt;/code&gt; after the oops caused by bug #1:&lt;/p&gt;
    &lt;code&gt;// linux 6.11.0-24 + nvidia 570.86.15 from Ubuntu Noble

_mapInsertBase+0x3c/0x320 [nvidia]
threadStateInit+0xd5/0x1b0 [nvidia]
rm_is_device_sequestered+0x28/0x60 [nvidia]
nv_open_device+0x2ef/0x9e0 [nvidia]
nvidia_open+0x22a/0x4b0 [nvidia]
chrdev_open+0xd2/0x250
do_dentry_open+0x218/0x4c0
vfs_open+0x30/0x100
do_open+0x2ba/0x440
path_openat+0x132/0x2c0
do_filp_open+0xc0/0x170
do_sys_openat2+0xb3/0xe0
__x64_sys_openat+0x55/0xa0
x64_sys_call+0x230a/0x25f0
do_syscall_64+0x7e/0x170
&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;ð ï¸â NVIDIA Fix&lt;/p&gt;&lt;p&gt;The heap based&lt;/p&gt;&lt;code&gt;threadStateAlloc&lt;/code&gt;function was added as a "new UAF-safe API". However, it seems it is currently used as a replacement for the stack based&lt;code&gt;threadStateInit&lt;/code&gt;only in the&lt;code&gt;dupMemory&lt;/code&gt;function. This has not been tested, but, other functions still using&lt;code&gt;threadStateInit&lt;/code&gt;may continue to be vulnerable to a UAF in the case of a oops.&lt;/quote&gt;
    &lt;head rend="h1"&gt;Exploitation&lt;/head&gt;
    &lt;p&gt;Proof of concept exploitation was carried out in the following environment:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ThinkPad P14s Gen 3 (Intel) with NVIDIA T550 Laptop GPU&lt;/item&gt;
      &lt;item&gt;Ubuntu Noble with the following packages:&lt;list rend="ul"&gt;&lt;item&gt;linux-image-6.11.0-24-generic (6.11.0-24.24~24.04.1 amd64)&lt;/item&gt;&lt;item&gt;nvidia-driver-570-server-open (570.86.15-0ubuntu0.24.04.4 amd64)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since bug #1 is only used to trigger bug #2, we will focus on the latter. This bug is quite unusual since the UAF address is part of a kernel stack, and as such it belongs to a &lt;code&gt;vmalloc&lt;/code&gt; area. Most resources available on UAF exploitation are related to &lt;code&gt;kmalloc&lt;/code&gt; as it's used way more broadly for kernel allocations. The only reference for exploitation related to &lt;code&gt;vmalloc&lt;/code&gt; seems to be "An iOS hacker tries Android" from Brandon Azad. However, things changed since then, for example the introduction of &lt;code&gt;random_kstack_offset&lt;/code&gt;. This feature introduces a randomly generated stack offset at each syscall entry, effectively cancelling its mostly deterministic layout. By randomising the position of key stack values, it makes exploitation more difficult.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vmalloc&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;vmalloc&lt;/code&gt; is a kernel function for allocating virtually contiguous memory with a page granularity. It's notably used for allocating kernel stacks, as well as other large kernel allocations. On a running system, the allocations can be inspected using &lt;code&gt;/proc/vmallocinfo&lt;/code&gt;. This section will discuss the behavior of the allocator, focusing on address space management, without addressing how backing pages are selected. Here is a very simplified representation of an area managed by &lt;code&gt;vmalloc&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;When a new allocation is made, it's placed in the first free area that can accommodate its size. Here is an example for a small allocation that takes the first empty slot:&lt;/p&gt;
    &lt;p&gt;Here is an example for a bigger allocation that didn't fit in the first available slot and so is being allocated further away:&lt;/p&gt;
    &lt;p&gt;When allocations are released, they are not immediately freed but instead marked as unpurged. While they are not used by the kernel anymore, they still live in the &lt;code&gt;vmalloc&lt;/code&gt; area and the address cannot be reused directly. Here is an example if we free three of the allocations:&lt;/p&gt;
    &lt;p&gt;To be effectively freed, the unpurged allocations must be purged. This is done when the number of pages contained in the unpurged allocations crosses the value returned by &lt;code&gt;lazy_max_pages&lt;/code&gt;, which can easily be computed from userland and is defined as follows:&lt;/p&gt;
    &lt;code&gt;// linux/mm/vmalloc.c

static unsigned long lazy_max_pages(void)
{
    unsigned int log;

    log = fls(num_online_cpus());

    return log * (32UL * 1024 * 1024 / PAGE_SIZE);
}
&lt;/code&gt;
    &lt;p&gt;After the purge, all released areas are typically ready to be used again for allocations:&lt;/p&gt;
    &lt;p&gt;However, due to recent optimisations, the kernel will now add freed allocations back into size-based pools. While they are in these pools, they will be reused in priority for allocations of the same size and the corresponding areas cannot be used for allocations of other sizes. This is a bit annoying in the context of the exploitation of a UAF, but the pools have a "decay" feature where ~25% of their contents will be released during a purge. By triggering a lot of purges instead of one, we can completely empty out the pools and get a similar result to the old behavior.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shaping primitives&lt;/head&gt;
    &lt;p&gt;To act on the &lt;code&gt;vmalloc&lt;/code&gt; area from an unprivileged process we will use the three following primitives.&lt;/p&gt;
    &lt;head rend="h3"&gt;Forking&lt;/head&gt;
    &lt;p&gt;As previously mentioned, kernel stacks are allocated in the &lt;code&gt;vmalloc&lt;/code&gt; area. As each userland process has its own dedicated kernel thread stack, forking will lead to a new 0x5000 bytes allocation. This corresponds to four pages for the stack itself and one guard page. Freed kernel stacks are cached to be possibly reused later without the need for new allocations. However, when a stack is released, the operation is usually delayed meaning that if we write very aggressive code like this:&lt;/p&gt;
    &lt;code&gt;while (1) {
    if (fork() == 0) {
        exit(0);
    }
}
&lt;/code&gt;
    &lt;p&gt;It will lead to the stack cache not being used properly, triggering numerous allocations and deallocations, ultimately leading to a lot of unpurged areas.&lt;/p&gt;
    &lt;head rend="h3"&gt;Video4linux2 buffers&lt;/head&gt;
    &lt;p&gt;The v4l2 (video4linux2) framework is used for interacting with video devices from userland. It has nothing to do with the NVIDIA driver but it can provide some powerful &lt;code&gt;vmalloc&lt;/code&gt; capabilities. Indeed, it has a &lt;code&gt;vmalloc&lt;/code&gt; backend for allocating buffers shared with the user (&lt;code&gt;drivers/media/common/videobuf2/videobuf2-vmalloc.c&lt;/code&gt;). The use of this backend is not systematic but seems to be common for internal and external USB-based webcams. The target system being a laptop, it's of course fit with one such device. However, some systems may restrict the use of video devices to the &lt;code&gt;video&lt;/code&gt; group.&lt;/p&gt;
    &lt;p&gt;By opening a video device using the &lt;code&gt;vmalloc&lt;/code&gt; backend we get access to the following capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allocate between 1 and 16 buffers at once&lt;/item&gt;
      &lt;item&gt;Control the size by asking for different resolutions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mmap&lt;/code&gt;the buffers in userland while they are also mapped in kernel&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Only one set of buffers can be allocated per video device. However, the &lt;code&gt;mmap&lt;/code&gt; capability is extremely powerful and the fact that we can allocate large buffers is also very useful to generate a lot of unpurged pages to trigger purges.&lt;/p&gt;
    &lt;head rend="h3"&gt;Side effect purge&lt;/head&gt;
    &lt;p&gt;We know that we can trigger purges by allocating and freeing a large number of buffers using either forking or v4l2 buffers. Still, it's not possible to know precisely when the purge will happen. However, exceeding &lt;code&gt;lazy_max_pages&lt;/code&gt; unpurged pages is in fact not the only way to cause a purge. And, by sheer chance, the allocation of a deviceless memory inside the NVIDIA driver (i.e. the type of memory used to trigger bug #1) will cause &lt;code&gt;nv_alloc_contig_pages()&lt;/code&gt; to be called with the &lt;code&gt;NV_MEMORY_UNCACHED&lt;/code&gt; flag. This will cause an attribute change using the &lt;code&gt;change_page_attr_set_clr()&lt;/code&gt; kernel function which will explicitly call &lt;code&gt;vm_unmap_aliases()&lt;/code&gt; leading to a purge. This is extremely useful for improving reliability by starting from a known clean state.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reclaiming the UAF&lt;/head&gt;
    &lt;p&gt;The first step in the exploitation is to gain control of the UAF. The goal is to trigger it, provoke a large number of purges so that the affected kernel stack is actually freed and finally allocate a v4l2 buffer that overlaps the UAF address. By memory mapping (via &lt;code&gt;mmap&lt;/code&gt;) this buffer, we can get full control over the UAF area. First, we begin by allocating deviceless memory in the NVIDIA driver until there is no unpurged area left and the pools are empty. Then, we can use the forking primitive to fill all the holes in the &lt;code&gt;vmalloc&lt;/code&gt; area. This will ensure a clean state where future allocations will be made one right after the other even if they are of different sizes. When forking, we will make most of the processes terminate immediately. However, some of them will be kept alive at regular intervals, to create gaps that are smaller than the v4l2 buffers we will allocate later. This way, even after the unpurged stacks are freed (red allocations in the next figure), any v4l2 buffer allocated will end up in the clean area, while smaller allocations on the system that could disrupt the exploitation will end up in these holes. We will refer to the kept alive stacks as guards.&lt;/p&gt;
    &lt;p&gt;Once we reach the clean state, we do the final setup by:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Forking and keeping alive a "beacon" process (used later)&lt;/item&gt;
      &lt;item&gt;Allocating and freeing a medium-sized v4l2 buffer&lt;/item&gt;
      &lt;item&gt;Forking a new process and triggering bug #1 with it&lt;/item&gt;
      &lt;item&gt;Allocating and freeing a medium-sized v4l2 buffer again&lt;/item&gt;
      &lt;item&gt;Allocating and keeping alive a final guard process&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These steps are very time sensitive as any other allocation on the system may get in between, most probably leading to a failure of the exploitation.&lt;/p&gt;
    &lt;p&gt;After that, it's possible to monitor the oops happening by waiting for the triggering process to get killed. Once it happened, the driver will be in a reduced state. Indeed, the kernel thread that hit the bug was killed while holding locks, so, most new calls to the drivers will just hang indefinitely. This means we can't use the side effect purge method and instead have to use large v4l2 buffers. These large allocations will not interfere with the area of the UAF as they will be allocated further away because of the guard stacks.&lt;/p&gt;
    &lt;p&gt;Once we allocated and freed enough of these large allocations so that the pools are empty, we can just allocate a set of two medium-sized v4l2 buffers. These buffers will be backed by only one &lt;code&gt;vmalloc&lt;/code&gt; allocation and so they will be one after the other. If everything went right, they should end up being allocated just after the beacon process because of guards. The second buffer will contain the UAF. The reason we used two buffers is because Buffer0 will be used later in the exploitation for data storage.&lt;/p&gt;
    &lt;head rend="h2"&gt;The tree data structure&lt;/head&gt;
    &lt;p&gt;The UAF we now control somewhere in Buffer1 is the node of a binary Red/Black tree. It serves as the underlying data storage for a map container, the global &lt;code&gt;threadStateDatabase.dbRoot&lt;/code&gt;. This map is used to store structures of type &lt;code&gt;THREAD_STATE_NODE&lt;/code&gt; in the time frame between &lt;code&gt;threadStateInit()&lt;/code&gt; and &lt;code&gt;threadStateFree()&lt;/code&gt;. The implementation is intrusive so every &lt;code&gt;THREAD_STATE_NODE&lt;/code&gt; structure contains a &lt;code&gt;struct MapNode&lt;/code&gt; defined as follows:&lt;/p&gt;
    &lt;code&gt;// src/nvidia/inc/libraries/containers/map.h

struct MapNode {
    NvU64       key;
    MapNode    *pParent;
    MapNode    *pLeft;
    MapNode    *pRight;
    NvBool      bIsRed;
};
&lt;/code&gt;
    &lt;p&gt;This data structure will be our primary focus. The &lt;code&gt;THREAD_STATE_NODE&lt;/code&gt; structure also contains interesting fields such as function pointers. However, the &lt;code&gt;threadStateInit()&lt;/code&gt; and &lt;code&gt;threadStateFree()&lt;/code&gt; functions only perform operations on the structure found in their own stack, so that it' not possible to trick them into calling these function pointers on a node coming from the tree.&lt;/p&gt;
    &lt;head rend="h2"&gt;Revealing kernel memory addresses&lt;/head&gt;
    &lt;p&gt;Even if the driver is in a reduced state, one operation still working is opening a GPU device (e.g. &lt;code&gt;/dev/nvidia0&lt;/code&gt;). Fortunately, this triggers a call to &lt;code&gt;rm_is_device_sequestered()&lt;/code&gt; which uses the &lt;code&gt;threadStateInit()&lt;/code&gt; and &lt;code&gt;threadStateFree()&lt;/code&gt; combo. This means a new node will be inserted and removed from the tree each time we open the device file. As the nodes have a very short life span, we can expect the UAF node to be the only one in the tree. As such, the UAF node will be the root and we can expand the tree by creating our own node linked to it. Before doing that, we need to solve two problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Where is the UAF node located in Buffer1 to be able to modify it&lt;/item&gt;
      &lt;item&gt;What is the address of Buffer0 so we can create our own nodes inside it and link them together&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Because of &lt;code&gt;random_kstack_offset&lt;/code&gt;, we can't predict the offset of the UAF node in the stack and so its offset in Buffer1. Fortunately, a zeroed out &lt;code&gt;struct MapNode&lt;/code&gt; is a valid node (a black node with no children). Therefore, if the whole Buffer1 is zeroed out, insertions in the tree can happen without any issue. Because the key will also be 0, new nodes will be inserted as the right child of the UAF node. So, when calling &lt;code&gt;open&lt;/code&gt; on the GPU device, &lt;code&gt;node.pRight&lt;/code&gt; will very briefly be filled with a pointer to a child. To find the offset of the node in Buffer1, a possibility is to call &lt;code&gt;open&lt;/code&gt; repeatedly from another process and scan Buffer1 until we find a non-zero value.&lt;/p&gt;
    &lt;p&gt;Furthermore, because &lt;code&gt;node.pRight&lt;/code&gt; will point to the &lt;code&gt;struct MapNode&lt;/code&gt; stored in the stack of the process calling &lt;code&gt;open&lt;/code&gt;, it's effectively leaking an address inside its kernel stack. We set up a beacon process for this reason, ensuring its stack is positioned just before Buffer0.&lt;/p&gt;
    &lt;p&gt;Once the beacon stack address is leaked, we can guess an address that should be part of Buffer0. If we set &lt;code&gt;node.pRight&lt;/code&gt; of the UAF node to this guessed address, new nodes will be inserted as the right child of the guessed node. By calling &lt;code&gt;open&lt;/code&gt; repeatedly again and scanning Buffer0 for a nonzero value, we can find the offset of the guessed node. By subtracting the found offset to the guess address we ultimately find the exact kernel address of Buffer0.&lt;/p&gt;
    &lt;p&gt;The guess address technique may seem superfluous, but it's essential as we cannot ascertain the exact beacon stack base address from the leak. This ambiguity is due to the &lt;code&gt;random_kstack_offset&lt;/code&gt; feature and the possibility that a kernel stack allocation can begin at any page boundary.&lt;/p&gt;
    &lt;head rend="h2"&gt;A first write primitive&lt;/head&gt;
    &lt;p&gt;Now that we have everything needed to create arbitrary trees, we need to find arrangements that could lead to interesting primitives during either insertion or deletion of a node. These operations always comprise the actual addition or removal of the node in the tree followed by a fixup phase (&lt;code&gt;_mapInsertFixup()&lt;/code&gt; or &lt;code&gt;_mapDeleteFixup()&lt;/code&gt;). These fixup functions will usually recolor and perform rotations in the tree. They are interesting as they loop up through it allowing us to have at least a bit of control on the execution. The goal is then to trick them into reading or writing at an arbitrary address. To do so we can use part of the rotation code:&lt;/p&gt;
    &lt;code&gt;static void _mapRotateRight
(
    MapNode **pPRoot,
    MapNode *x
)
{
    // rotate node x to right
    MapNode *y = x-&amp;gt;pLeft;
    // establish x-&amp;gt;pLeft link
    x-&amp;gt;pLeft = y-&amp;gt;pRight;

    if (y-&amp;gt;pRight)
        y-&amp;gt;pRight-&amp;gt;pParent = x; // &amp;lt;= Here is the only use of y-&amp;gt;pRight

    // establish y-&amp;gt;pParent link
    y-&amp;gt;pParent = x-&amp;gt;pParent;

    if (x-&amp;gt;pParent)
    {
        if (x == x-&amp;gt;pParent-&amp;gt;pRight)
            x-&amp;gt;pParent-&amp;gt;pRight = y;
        else
            x-&amp;gt;pParent-&amp;gt;pLeft = y;
    }

    else
        (*pPRoot) = y;

    // link x and y
    y-&amp;gt;pRight = x;
    x-&amp;gt;pParent = y;
}
&lt;/code&gt;
    &lt;p&gt;There is a mirror version of this code (&lt;code&gt;_mapRotateLeft&lt;/code&gt;) that could also be used, but we will focus on the right one. When executed this function will set &lt;code&gt;pParent&lt;/code&gt; in the node pointed to by &lt;code&gt;y-&amp;gt;pRight&lt;/code&gt; if it's not null without ever using it again. Visually the rotation looks like this:&lt;/p&gt;
    &lt;p&gt;If we set &lt;code&gt;y-&amp;gt;pRight&lt;/code&gt; to an arbitrary address, we can obtain a constrained arbitrary write primitive because a pointer to &lt;code&gt;x&lt;/code&gt; will be written to &lt;code&gt;y-&amp;gt;pRight + offsetof(MapNode, pParent)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Assuming &lt;code&gt;x&lt;/code&gt; is one of our nodes in Buffer0, we can consider that we are writing a pointer to a controlled address. The right rotation can be attained from &lt;code&gt;_mapInsertFixup()&lt;/code&gt; without the value of &lt;code&gt;y-&amp;gt;pRight&lt;/code&gt; being used by building the right tree structure. There might be better primitives available directly from the tree but this one have the advantage of being straightforward and reliable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Selecting a target&lt;/head&gt;
    &lt;p&gt;Next step is to find what exactly to overwrite. Without relying on other bugs, we are only aware of a few addresses allocated by &lt;code&gt;vmalloc&lt;/code&gt;. One solution would be to shape the &lt;code&gt;vmalloc&lt;/code&gt; area so that an interesting allocation is found close to our beacon and buffers in order to guess its address. That should be doable, but after searching for a bit, I didn't find any interesting structure. As a matter of fact, &lt;code&gt;vmalloc&lt;/code&gt; is not used that much in the kernel and mostly for big buffers because of its page granularity. Also, there are in fact multiple separated &lt;code&gt;vmalloc&lt;/code&gt; areas, limiting the possibilities.&lt;/p&gt;
    &lt;p&gt;Instead, targeting kernel stacks seemed easier as we already know we can leak their addresses. We used this capability before to guess the address of Buffer0. However, we can also leak the address of other interesting values in the stack during the execution of &lt;code&gt;open&lt;/code&gt; (the syscall that triggers the insertion in the tree). Indeed, offsets in the stack should be constant for a given kernel and driver binaries, we can just calculate beforehand the distance between the node and a specific value we want to target in the stack. The use of &lt;code&gt;kstack_random_offset&lt;/code&gt; changes nothing, as the offset is added before the syscall is executed.&lt;/p&gt;
    &lt;p&gt;However, in order to use this method combined with the write primitive, the target address needs to be computed in the very small time frame between the insertion of the node and the rotation of the tree that will trigger the write. This is due to the address changing every syscall because of &lt;code&gt;kstack_random_offset&lt;/code&gt;. By default, there is not enough time for the userland process to modify the mapped memory in time. However, we can artificially increase the time taken by the tree iteration before the rotation is executed. The &lt;code&gt;_mapInsertFixup()&lt;/code&gt; function has a recolor-only path which will perform the following:&lt;/p&gt;
    &lt;p&gt;For our purposes, recoloring has no side effects and can be used to waste time, by building a tree using the pattern found in the previous figure. We can then build a three-staged tree:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Setup: Welcomes the new node insertion and make the iteration jump into an alternate part of the tree (i.e. that is not under the root) using a flawed &lt;code&gt;pParent&lt;/code&gt;pointer&lt;/item&gt;
      &lt;item&gt;Dummy: Combination of an arbitrary number of recolor patterns used to waste time (256 patterns were used for the proof of concept)&lt;/item&gt;
      &lt;item&gt;Write: Perform a write using a rotation, the address will be computed and filled in dynamically by userland&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The node is made to be inserted as a left child using very large keys to facilitate the jump into the dummy phase. This tree allows to reliably write a pointer to controlled data over any chosen value in the kernel thread stack during the handling of the &lt;code&gt;open&lt;/code&gt; syscall. The written data will effectively be a pointer to the node labeled &lt;code&gt;END&lt;/code&gt;. After the rotation, we are free to write any data at this address.&lt;/p&gt;
    &lt;head rend="h2"&gt;Escalating with stack corruption&lt;/head&gt;
    &lt;p&gt;Now, we just need to find a good candidate pointer to overwrite. A very interesting one is the &lt;code&gt;file&lt;/code&gt; pointer in &lt;code&gt;path_openat()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;// fs/namei.c

static struct file *path_openat(struct nameidata *nd,
            const struct open_flags *op, unsigned flags)
{
    struct file *file;
    int error;

    file = alloc_empty_file(op-&amp;gt;open_flag, current_cred()); // struct file allocation
    if (IS_ERR(file))
        return file;

    if (unlikely(file-&amp;gt;f_flags &amp;amp; __O_TMPFILE)) {
        error = do_tmpfile(nd, flags, op, file);
    } else if (unlikely(file-&amp;gt;f_flags &amp;amp; O_PATH)) {
        error = do_o_path(nd, flags, file);
    } else {
        const char *s = path_init(nd, flags);
        while (!(error = link_path_walk(s, nd)) &amp;amp;&amp;amp;
               (s = open_last_lookups(nd, file, op)) != NULL)
            ;
        if (!error)
            error = do_open(nd, file, op); // function that will lead to the write
        terminate_walk(nd);
    }
    if (likely(!error)) {
        if (likely(file-&amp;gt;f_mode &amp;amp; FMODE_OPENED))
            return file;
        WARN_ON(1);
        error = -EINVAL;
    }
    fput_close(file);
    if (error == -EOPENSTALE) {
        if (flags &amp;amp; LOOKUP_RCU)
            error = -ECHILD;
        else
            error = -ESTALE;
    }
    return ERR_PTR(error);
}
&lt;/code&gt;
    &lt;p&gt;When looking at the compiled binary for the target version, we can see that the &lt;code&gt;file&lt;/code&gt; pointer is stored in &lt;code&gt;r12&lt;/code&gt;. The &lt;code&gt;do_open()&lt;/code&gt; function spills &lt;code&gt;r12&lt;/code&gt; on the stack and at the same time will lead to the call that triggers our write. Meaning that we can ultimately overwrite the &lt;code&gt;file&lt;/code&gt; pointer to make it point into our memory mapped Buffer0 by precomputing the offset between &lt;code&gt;struct MapNode&lt;/code&gt; and the spilled &lt;code&gt;r12&lt;/code&gt; register in the stack. This modified file pointer will be returned by &lt;code&gt;path_openat()&lt;/code&gt; and associated with a file descriptor in the calling process by &lt;code&gt;fd_install()&lt;/code&gt; in &lt;code&gt;do_sys_openat2()&lt;/code&gt;. There are a few checks and dereferences that may cause issues, but by creating a fake &lt;code&gt;struct file&lt;/code&gt; with somewhat sensible values it's possible to overcome them easily.&lt;/p&gt;
    &lt;p&gt;It's to be noted that the &lt;code&gt;file&lt;/code&gt; structure is defined with the &lt;code&gt;__randomize_layout&lt;/code&gt; macro. This will lead to the fields being out of order and that we have to find the offsets for the specific target kernel. Fortunately, in our case, these can be easily extracted from the Ubuntu debug packages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Leaking KASLR&lt;/head&gt;
    &lt;p&gt;The control over a &lt;code&gt;struct file&lt;/code&gt; is extremely powerful. This structure notably contains several function pointers due to the Virtual File System layer. However, our last barrier to a full exploitation is KASLR (Kernel Address Space Layout Randomization). To break it, we can leverage some syscalls that check the type of a file by comparing the &lt;code&gt;f_op&lt;/code&gt; pointer to the expected &lt;code&gt;struct file_operations&lt;/code&gt;. For example, &lt;code&gt;recvfrom&lt;/code&gt; uses &lt;code&gt;sock_from_file()&lt;/code&gt; to get access to private data specific to sockets and checks the file type using the &lt;code&gt;f_op&lt;/code&gt; pointer:&lt;/p&gt;
    &lt;code&gt;// linux/net/socket.c

struct socket *sock_from_file(struct file *file)
{
    if (likely(file-&amp;gt;f_op == &amp;amp;socket_file_ops))
        return file-&amp;gt;private_data;  /* set in sock_alloc_file */

    return NULL;
}
&lt;/code&gt;
    &lt;p&gt;If the pointers don't match and &lt;code&gt;sock_from_file()&lt;/code&gt; returns null, &lt;code&gt;recvfrom&lt;/code&gt; will simply return &lt;code&gt;-ENOTSOCK&lt;/code&gt;. So, we can call this syscall repeatedly on the file descriptor linked with our controlled &lt;code&gt;struct file&lt;/code&gt;, starting with &lt;code&gt;f_op&lt;/code&gt; set to the static address of &lt;code&gt;socket_file_ops&lt;/code&gt; and then incrementing it to test all the possible slided values. KASLR is leaked when the syscall returns something other than &lt;code&gt;-ENOTSOCK&lt;/code&gt;. This is a somewhat fast process due to KASLR entropy only being 9 bits.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping up&lt;/head&gt;
    &lt;p&gt;After that, we can just create our own file operations table. I decided to use the &lt;code&gt;llseek&lt;/code&gt; handler to perform arbitrary functions calls in the kernel. It's defined as follows:&lt;/p&gt;
    &lt;code&gt;loff_t (*llseek) (struct file * file, loff_t offset, int whence);
&lt;/code&gt;
    &lt;p&gt;It's interesting because the syscall handler does not perform any check on the file before calling the handler. Also, we have control and access to all the parameters and the return value directly from userland. The limitations are as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The &lt;code&gt;whence&lt;/code&gt;parameter should be less than five&lt;/item&gt;
      &lt;item&gt;The first parameter is a pointer to our controlled &lt;code&gt;struct file&lt;/code&gt;meaning we must input or output arbitrary data from the start of the structure. That's not a problem on the target version because all the fields in the start are unused, but it could be if we are very unlucky with the randomized order of the fields.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By setting the handler to point to selected kernel functions and then calling the &lt;code&gt;llseek&lt;/code&gt; syscall, we can build a basic set of primitives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kernel symbolication with &lt;code&gt;unsigned long kallsyms_lookup_name(const char *name)&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Kernel arbitrary read with &lt;code&gt;void *memcpy(void *dest, const void *src, size_t count)&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Kernel arbitrary write with &lt;code&gt;int debugfs_u64_get(void *data, u64 *val)&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For testing them, we can escalate the privileges of our userland process. We just need to symbolicate &lt;code&gt;init_task&lt;/code&gt; and iterate the tasks until we find the one corresponding to our process. Then, we can overwrite the creds to become root and open a shell. Below is the full proof of concept running in real time:&lt;/p&gt;
    &lt;head rend="h1"&gt;Closing Remarks&lt;/head&gt;
    &lt;p&gt;To conclude, a couple of key points to consider. First, the exploit is sensitive to system activity, particularly forking and calls to the NVIDIA driver during specific time frames. This poses a challenge on systems under constant heavy load where the exploitation will most likely fail.&lt;/p&gt;
    &lt;p&gt;Second, as previously mentioned the kernel oops triggered by bug #1 causes multiple locks to be held, rendering most of the NVIDIA driver unusable. It should be possible to manually unlock the driver using the kernel read and write primitives, but this has not been tested.&lt;/p&gt;
    &lt;p&gt;The complete proof-of-concept exploit described in this blog post is available here&lt;/p&gt;
    &lt;head rend="h2"&gt;Disclosure timeline&lt;/head&gt;
    &lt;p&gt;Below we include a timeline of all the relevant events during the coordinated vulnerability disclosure process with the intent of providing transparency to the whole process and our actions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-06-18 Quarkslab reported the vulnerabilities to NVIDIA PSIRT.&lt;/item&gt;
      &lt;item&gt;2025-06-18 NVIDIA acknowledged the report and asked if we planned to disclose the bugs.&lt;/item&gt;
      &lt;item&gt;2025-06-25 Quarkslab replied that we planned to publish a blog post or conference talk but there was no specific plan and it would be determined along the coordination process.&lt;/item&gt;
      &lt;item&gt;2025-06-26 NVIDIA acknowledged last email and promised to keep us updated as the process evolves.&lt;/item&gt;
      &lt;item&gt;2025-07-14 NVIDIA indicated it couldnt reproduce the bugs.&lt;/item&gt;
      &lt;item&gt;2025-07-21 Quarkslab sent a reply to NVIDIA noting that the report had specific comments about triggering the bugs and exploitability.&lt;/item&gt;
      &lt;item&gt;2025-07-22 NVIDIA acknowledged the last communication and said it was passed to the dev team.&lt;/item&gt;
      &lt;item&gt;2025-07-24 Quarkslab sent further details about how to reproduce the bugs and asked what runtime environment was NVIDIA using to try to repro them.&lt;/item&gt;
      &lt;item&gt;2025-07-28 Quarkslab re-sent the prior email with a minimized PoC.&lt;/item&gt;
      &lt;item&gt;2025-08-08 NVIDIA provided information about their runtime environment, the internal case numbers, and said they will implement the fixes by mid-january 2026, and asked if Quarkslab could delay disclosure until then.&lt;/item&gt;
      &lt;item&gt;2025-08-11 NVIDIA reiterated the request to postpone disclosure until mid-January 2026.&lt;/item&gt;
      &lt;item&gt;2025-08-12 Quarkslab replied that the bugs were first reported in June 18th and mid-January was well past the standard 90 day normally agreed for coordinated disclosure and that we did not see a rationale for postponing publication by, at a minimum, 3 months. Therefore Quarkslab continued with the publication deadline set to September 23rd 2025 and offered to extend the deadline an additional 30 days provided NVIDIA gave us some insights about the full scope of affected products and if the fixes are to be released as a stand alone security fix, as opposed to rolled into a version bump that includes other code changes.&lt;/item&gt;
      &lt;item&gt;2025-08-12 NVIDIA acknowledged our email and said it will communicate the deadline to the product team.&lt;/item&gt;
      &lt;item&gt;2025-08-14 NVIDIA provided an update and requested the 30-day extension offered. Indicated the fix for the null pointer dereferrence bug, which would make the UAF not reachable, was under review. The team was determining whether the fix would be a standalone update or included in a regular version update release. NVIDIA said it would be happy to share the final disclosure security bulletin language before releasing it to partners and the public.&lt;/item&gt;
      &lt;item&gt;2025-08-18 NVIDIA requested confirmation of the 30 day extension to the disclosure deadline.&lt;/item&gt;
      &lt;item&gt;2025-08-18 Quarkslab agreed to extend the disclosure deadline to October 23rd 2025.&lt;/item&gt;
      &lt;item&gt;2025-10-09 NVIDIA published Security Bulletin: NVIDIA GPU Display Drivers - October 2025 crediting CVE-2025-2330 to Quarkslab.&lt;/item&gt;
      &lt;item&gt;2025-10-09 Quarkslab asked NVIDIA when they planned to fix the UAF bug or if it was the fix for CVE-2025-23280 in the October update, which was not credited to anyone.&lt;/item&gt;
      &lt;item&gt;2025-10-09 NVIDIA apologized for not having notified Quarkslab of the security bulletin release and said it would correct the attribution of CVE-2025-23280, which was indeed the Kernel UAF bug.&lt;/item&gt;
      &lt;item&gt;2025-10-14 This blog post is published.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.quarkslab.com/./nvidia_gpu_kernel_vmalloc_exploit.html"/><published>2025-10-15T13:52:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45593213</id><title>Reverse engineering a 27MHz RC toy communication using RTL SDR</title><updated>2025-10-15T18:46:02.360212+00:00</updated><content>&lt;doc fingerprint="6418241e49e88683"&gt;
  &lt;main&gt;
    &lt;p&gt;My kids have this RC fire engine that works in the 27MHz band. I got curious how the communication is, with objective to control the toy from laptop. I had an RTL SDR in my toolbox. I have used it with gnuradio software for a couple of analog reception tasks. Not for anything serious so far. So I started simple and kept building on top.&lt;/p&gt;
    &lt;p&gt;Following is the final block diagram I arrived at. Seems complex right?. I will walk you through the steps involved in reverse engineering the communication.&lt;/p&gt;
    &lt;p&gt;Though the toy says it uses 27MHz, the exact frequency can be anywhere in the 26-28MHz range. Identifying the exact frequency and visualizing the signal in a waterfall diagram is the first step. Created a gnuradio project and added RTL-SDR Source block and QT GUI Sink block connected to its output to do this. Also added a QT GUI Range block to vary the RF frequency. Executed the flow graph. After playing a bit with the slider at bottom of the output window, I could visualize the RF signal as shown below. Note the strong red indicates the time when i was pressing the key on remote control.&lt;/p&gt;
    &lt;p&gt;Now that we understood the frequency to be 27.1MHz, we need to find out the modulation scheme. Modulation can be on Amplitude, the frequency or the phase, or a combination. To figure if there is any amplitude modulation, we need to look at the RF time domain with a large observation window. So I added a time domain visualisation by configuring the QT GUI sink block. During execution, increased the FFT size (observation window) from default 1024 to 16384&lt;/p&gt;
    &lt;p&gt;It appears like it is some form of Amplitude Shift Keying (ASK). (It can be a combination of Amplitude and phase modulation also. But we build on this assumption, and see whether we can differentiate all the RC keys with just the ASK). Next step is to demodulate the ASK signal with the help of an AM Demod block. From my experience with analog reception, I added an AGC2 and Decimating FIR Filter blocks to improve the signal to noise ratio. The demodulator output was then visualised using a QT GUI Sink. Also the output was taken to an Audio Sink to hear the message, after passing through a Low Pass Filter to reduce the sample rate to 32kHz required for the Audio Sink.&lt;/p&gt;
    &lt;p&gt;The time domain output of the QT GUI Sink is shown above while pressing one of the keys. Shows repeating Ones and Zeros last for 0.5 ms each. I changed the FFT size parameter on bottom to get idea about the larger frame structure.&lt;/p&gt;
    &lt;p&gt;At observation window of 32768, a repeating sequence of low frequency (111011101110) pattern followed by high frequency (10101010…) pattern is evident. The envelope change is an artefact of the AGC, so just ignore that. Tried a different switch on the remote.&lt;/p&gt;
    &lt;p&gt;Here we have a shorter high frequency (1010…) pattern. So the switches are encoded using the length of high frequency region. Now we need to estimate the length of each of the frames. For this we need to downsample it such that each sample represents 1 bit. A Symbol Sync block is required for this downsampling. Then with a Threshold block the amplitudes were converted to the [0,1] range. To count the bits after the preamble pattern (111011101110) I tried using many built in blocks like “Correlate Access Code – Tag” block etc. But did not work as per expectation. So I added a Python Block and decided to write the python code to count it, and renamed it to Custom Decode Block. The code used to count the frame length is shown below&lt;/p&gt;
    &lt;p&gt;The code was arrived at after a few trials and errors. It just correlates the 110110110 pattern with the datastream to identify the frame starts, and calculate the distance between the frame starts. Now it prints the frame length to the console. And also shows that as height of spike in an output visualization.&lt;/p&gt;
    &lt;p&gt;Almost done. But one more problem. Some keys especially those that had the long sequence of 1010.. were not showing up. I had to solve one more issue that is rooted on the gnu radio implementation to get all the frame length. The reason is the buffers passed to the code were very small and insufficient to hold a full frame in case of the long frames. So I had to add this Stream to Vector and Vector to Stream block pairs to aggregate multiple block and make a bigger block before passing to my Python block.&lt;/p&gt;
    &lt;p&gt;After all this exercise, I arrive at the following table. First 2 columns are experimentally obtained and other two are calculated.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Key Combination&lt;/cell&gt;
        &lt;cell&gt;Frame Length (bits)&lt;/cell&gt;
        &lt;cell&gt;Data Length (Frame Length – 12) (bits)&lt;/cell&gt;
        &lt;cell&gt;Data Length/12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;132&lt;/cell&gt;
        &lt;cell&gt;120&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;V&lt;/cell&gt;
        &lt;cell&gt;120&lt;/cell&gt;
        &lt;cell&gt;108&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;&amp;lt;&lt;/cell&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;&amp;gt;&lt;/cell&gt;
        &lt;cell&gt;84&lt;/cell&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;^,&amp;lt;&lt;/cell&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;60&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;^, &amp;gt;&lt;/cell&gt;
        &lt;cell&gt;96&lt;/cell&gt;
        &lt;cell&gt;84&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;V, &amp;lt;&lt;/cell&gt;
        &lt;cell&gt;60&lt;/cell&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;V, &amp;gt;&lt;/cell&gt;
        &lt;cell&gt;108&lt;/cell&gt;
        &lt;cell&gt;96&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;A video tutorial on the above is available at https://www.youtube.com/watch?v=4koACEEZMiQ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nitrojacob.wordpress.com/2025/09/03/reverse-engineering-a-27mhz-rc-toy-communication-using-rtl-sdr/"/><published>2025-10-15T14:31:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45593390</id><title>Recreating the Canon Cat document interface</title><updated>2025-10-15T18:46:01.884534+00:00</updated><content>&lt;doc fingerprint="a7ccd91428230980"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Recreating the Canon Cat document interface&lt;/head&gt;
    &lt;p&gt;March 26&lt;/p&gt;
    &lt;p&gt;My work is supported by members. If you find my work valuable and have the means, consider supporting it with a membership or sponsorship! This members-only article has been made publicly available. You can see more of my work at alexanderobenauer.com.&lt;/p&gt;
    &lt;p&gt;The last chapter of Bootstrapping Computing is all about user environments. One of the more unique user environments mentioned is found on the Canon Cat, an obscure machine that didn’t last long on the market, but took some specific philosophies to an extreme, presenting fascinating implications for how users might interact with their personal computers.&lt;/p&gt;
    &lt;p&gt;The Cat’s user environment was one long text stream. There are some caveats to this next statement, but basically: that’s it!&lt;/p&gt;
    &lt;p&gt;There was no mouse, only a keyboard. In fact, the Cat did away with WIMP entirely — there were no windows, no icons, no menus, and no pointer. There was no file hierarchy and no need to name things. None of your text was automatically timestamped.&lt;/p&gt;
    &lt;p&gt;It was just you, a keyboard, and one long text stream with everything you’ve done in it.&lt;/p&gt;
    &lt;p&gt;For navigation, the Cat featured leap keys: two rose-colored keys below the spacebar. You could press and hold one while typing a sequence of characters to “teleport” to the nearest instance of that pattern. The left leap key would take you back, the right leap key would take you forward.&lt;/p&gt;
    &lt;p&gt;User conventions emerged to support life within this system. Users would implement their own navigational systems using special characters, tags, “@keywords”, and consistent date and timestamp formats that would work well with the leap keys.&lt;/p&gt;
    &lt;p&gt;That’s what caught my eye first: your environment effectively becomes a system of your own design, over time. With a small set of commands and a simple data model, many of the features in users’ systems were actually personal conventions that made good use of the of the available actions. It’s an interesting form of personal software: your conventions compound and evolve to make the system into what you want and need it to be.&lt;/p&gt;
    &lt;head rend="h2"&gt;Jasper&lt;/head&gt;
    &lt;p&gt;Since the system people used was in part of their own design, built over time, it isn’t a system that you’d understand just from reading about how it worked, or watching a demo, or reimplementing it, or even using a reimplementation for a few minutes. It’s a system you can only really understand when you use it seriously for a long time, such that you feel the push and pull to impose certain conventions that make the available actions help you around your growing body of work.&lt;/p&gt;
    &lt;p&gt;This is what made me curious to live in such an environment: to experience the ways in which this system’s philosophy and implementation play out in the lives of its users.&lt;/p&gt;
    &lt;p&gt;I’ve implemented a basic version of the Canon Cat interface in a little web app called Jasper.Jasper was the original name for the cat in Tom and Jerry. By the time the character would recur, he became Thomas Jasper Cat Sr. (long for Tom Cat). I’ve attempted to start living in this system “full-time”, or as much as possible, for my notes, tasks, thinking, and document composition (so if you’re reading this, that would explain typos: I have no spellcheck in here at the moment). I’m still new to the environment, but in this update, I’ll share some early observations.&lt;/p&gt;
    &lt;p&gt;Here’s a demo video and some screenshots (essay continues below):&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;I’ll first touch on some implementation details before I discuss observations from use.&lt;/p&gt;
    &lt;p&gt;Leap was a central feature on the Canon Cat, and I’ve mirrored its finer details in Jasper. You can leap in either direction, and you can leap again — repeatedly pressing the left or right leap keys after a leap to continue jumping to the previous or next instance of your pattern. When you type a lowercase pattern, it matches case insensitively; if you type a pattern using any capital letters, it matches case sensitively (this was a smart choice in the design of the original system, and I enjoyed having it in Jasper). Also like the original, it has circular search. I do new work at the bottom, so when starting at the top, I can leap backward to “@todo” to get to my most recent todo list. And it has what the Cat’s materials called “cursor rebound” — if you type a pattern that isn’t found anywhere in the environment, the cursor returns to its starting position (the Cat’s how-to guide recommended adding a few “x”s to your pattern if you wanted to intentionally return to your starting position).&lt;/p&gt;
    &lt;p&gt;The hard part is that the Canon Cat had bespoke hardware with dedicated keys for its actions. The leap keys were positioned below the spacebar, so your thumbs could hold them while typing your pattern. Lacking that, I opted to use the option keys to each side of my spacebar. Initially, I tried implementing the leap keys as a hold-and-press quasimode, as in the original. I prefer this approach, because this quasimode is “embodied” — my posture is slightly different while in this mode (like using press-to-talk on video calls). But ultimately, using the option keys this way presented too many problems. These keys are not ergonomically positioned like the Cat’s leap keys; leaping to “@todo” was a bit uncomfortable. But the primary stumbling block with this approach is that the option key has too many meanings in systems today, and so caused all kinds of non-trivial problems, starting with the fact that characters pressed are not the characters typed while the option key is held down. I managed to work around many of these issues to get a basic implementation going, but ultimately found the many edge cases too frustrating to make the less-than-ergonomic option worth it. So in Jasper, leap mode begins when you press and release an option key, and leaving the mode requires pressing escape, return, or any arrow key.&lt;/p&gt;
    &lt;p&gt;Canon Cat was also a WYSIWYG interface: what you print is exactly what you see on screen. The ruler at the bottom of the Cat’s interface is set in characters, with 80 on each line. I figured I wouldn’t print much from Jasper, but this arrangement has an interesting effect: everything you type is found in the same place horizontally every time you read it or scan for it. To preserve this aspect, Jasper’s editor has a fixed width, with 64 characters on each line (similar to what the Cat had once you took into account the character spaces used for margins).&lt;/p&gt;
    &lt;p&gt;I added highlighting to leap’s pattern matches in Jasper, as I found using leap taking longer than it needed to when I couldn’t tell where my cursor had moved to. (Canon Cat’s cursor carried more visual weight than today’s blinking bar, but I prefer the latter, and have found highlighting all matches, with the active one given the most color, to be beneficial.)&lt;/p&gt;
    &lt;p&gt;When I’m at my desktop, I use a full-size keyboard with a number pad. It has several function and other keys that I mapped into more of the specific actions of the Cat. When I wrote the second version of Jasper, I left behind most of the other keys in favor of their existing modern equivalents, since there’s no difference in behavior.&lt;/p&gt;
    &lt;head rend="h2"&gt;Merits&lt;/head&gt;
    &lt;p&gt;There are a number of things about this system that I find appealing, often uniquely so among the broader landscape of user environments.&lt;/p&gt;
    &lt;p&gt;As I mentioned in the introduction, I appreciate that this system has a simple data model, leaning on user conventions to take things further. The user will gradually design their own system over time, and evolve it as time goes on. It feels more like a box of tools than a curated experience, something surprisingly rare in the productivity software landscape.&lt;/p&gt;
    &lt;p&gt;On the Canon Cat, users could insert document separators, which were special characters displayed as thick horizontal lines or gaps. They were used to denote the end of one document and the beginning of another. The document separator was a character you’d type from the keyboard, just like an “a”, a space, or any other, so leaping from one document to the next doesn’t require another command or set of keys: you can leap to the next document separator using its special character in a standard leap. You effectively end up with a keyboard shortcut of Leap + Document Separator to navigate to the beginning or end of your current document. But this isn’t a special case; it’s just like leaping to any other character. And you could do the same with newlines or spaces to jump to the beginning or end of paragraphs or words.In my implementation, the benefits are not quite as potent as in the original Cat, since I don’t have a dedicated document separator key and character, or press-and-hold leap keys. Instead, the ` character is used for document separators, which can be used in Jasper’s leap mode to jump to the beginning or end of documents. This is a delightfully efficient paradigm; it reminds me of the MOVE command on the Xerox Star that could be learned once and used for many different purposes, such as, depending on the chosen destination, to put a file in a folder, to print a document, or to send an email — none of these required additional commands. It’s as though the system was designed by asking, “How could we include lots of keyboard shortcuts that we never have to explain, that the user will discover all on their own?” They are a byproduct of the system’s fundamental operation. And as such, users can create their own keyboard shortcuts with how they structure and type text in their environments.&lt;/p&gt;
    &lt;p&gt;Finally, this will be a hard point to make, but I’ll try:&lt;/p&gt;
    &lt;p&gt;Something unexpected that I really like about this system is that it’s always “correct”. If I record something somewhere else (such as on a piece of paper) and move it into my system a day later, I can still put it in the correct day, if that’s how I have things grouped. In a similar system using my phone’s Notes app, the timestamps are automatic and unchangeable, so there’s a slightly different relationship I have with the timestamps and ordering of notes in this app. Apps with this automatic behavior are ever so slightly not my timestamps, and I relate to them accordingly. These timestamps and orderings gesture toward how I think of my notes, but there are lots of little wrinkles. I remember the more important wrinkles, carrying around these asterisks in my head, but there are lots of less memorable ones that give me the impression that these are the app’s timestamps; the computer’s timestamps — not my own. This might sound like a trivial detail, but I think it sows the seeds of distrust and frustration with our digital systems. It’s little things like this that quietly indicate, if only to our subconscious, that this isn’t our system, it’s their system, we just happen to be putting our data in it. That’s not a great feeling! In contrast, the Cat feels more like my system, since I implement my system within it. My document — my whole environment — is exactly as I write it.&lt;/p&gt;
    &lt;p&gt;I was surprised to find that the leap keys mapped into my brain almost immediately. Pretty quickly after starting to use the system, I noticed my mind thinking in terms of its affordances. In a long note in the Notes app on my phone, I found myself mentally reaching for the “leap back” key to go to a particular spot in the note that was off-screen. Lacking that, I wondered if Notes on the iPhone has the similar “find” to search in the document (I had to look this up — it turns out Notes actually has it, buried in a menu with a long list of other features). It would be interesting to explore a custom keyboard for the iPhone that has leap back and leap forward keys (though the quasimode of holding the key down while typing would not work well on this device size). I am increasingly frustrated in other apps — code editors, text editors, even when reading articles in a web browser — because I can’t use leap in them; my mind reaching for it the way an absent mind accidentally thinks to pinch-to-zoom some small text on a physical piece of paper.&lt;/p&gt;
    &lt;p&gt;Early on, I was using my mouse too often as a habit. Without it, I’d be forced to find a couple of other syntaxes in my document that help me navigate with the leap keys. So I added a way to disable the mouse, which I kept on as much as possible. By the time I built the second (and current) version of Jasper, I’d kicked the habit, so it doesn’t feature a way to disable the mouse.&lt;/p&gt;
    &lt;p&gt;Ultimately, I think the value I get from the Cat interface in Jasper is not close to what they advertised it for. Ads called it “the world’s first Work Processor”, a wordplay on word processor.A Canon Cat brochure But it clicked for me in a different way.&lt;/p&gt;
    &lt;p&gt;For years, I’ve worked from a single, long document in Obsidian that I call my “Starters”. I usually append to the top (rather than the bottom, as I do in Jasper), but it works in a similar way.&lt;/p&gt;
    &lt;p&gt;Almost everything composed that I think, or see, or want to read later lands in Starters. Like things group together, but as I scroll down, I’m going backward in time seeing lots of little observations, insights, and questions. I don’t have to name or categorize anything. So it lets the ideas unfold freely into whatever they want and need to be.&lt;/p&gt;
    &lt;p&gt;As I scroll back, I see lots of closely related things that I wouldn’t have otherwise realized were related. As my mind is thinking in some particular way, everything from a 7-10 day period all seems shaped in some similar way. It also helps me to see intersections among truly unrelated things, which leads to interesting insights, useful metaphors for writing, and so forth. Starters has also been the closest glimpse I’ve gotten at a system that prevents writers block. (The other is a small list of websites; each reliably gets me thinking and writing.)&lt;/p&gt;
    &lt;p&gt;I like that it works in a particular way to support the kind of free associative thinking that the brain is so good at. I’ve found this to be true of Jasper too. I’ve taken to keeping my Jasper stream always on the left side of my screen when I’m working in other applications (or the left screen at my desk), to record notes during meetings, quickly jot errant thoughts, record interesting links, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extending these ideas&lt;/head&gt;
    &lt;p&gt;Let’s talk about the ways a system like this could extend in the future, and things I found myself wishing the system had, for better or for worse.&lt;/p&gt;
    &lt;p&gt;The Cat had a handful of other features that I’ve largely ignored here. One was performing calculations on math written in your text, when you highlighted that text and hit the CALC key. This is essentially a DSL you can use within your otherwise freeform text that is given certain powers by the system. Could you encode some of your other conventions with user programs that can do things for you with little syntaxes in your document? Archy, a successor to Canon Cat, had an implementation of a similar idea.In Archy, commands could be installed as user programs. They didn’t present separate, bounded apps, but worked on the entire system and could be combined with one another. You could, for example, install an email package that came with a SEND MAIL command, which you could invoke after selecting the text you want to send, then specifying who you want to send it to.&lt;/p&gt;
    &lt;p&gt;It would be quite handy to have autocomplete in the document, and in the leap field, whenever typing something like @ or #, to autofill an often-used name or a person or project. That said, I can usually remember how I’ve chosen to write someone’s name. Macros would also be handy, and autocompleting a date / timestamp in a particular, consistent format would have kept me from a few errors in my convention’s syntax.&lt;/p&gt;
    &lt;p&gt;I also find myself wanting Markdown support. What’s interesting about Markdown in this case is that, like the user conventions that emerged among Canon Cat users, one can target the character sequences used in specific places while leaping (for example, to leap to multiple equal or pound signs to navigate through the headers in a document).&lt;/p&gt;
    &lt;p&gt;It’s interesting to consider how you might use this system with an LLM. LLMs work well with big blocks of text, and that’s what this environment is made up of. It’d be easy enough to send along specific lines, so an LLM could “scan” up or down a document, or use leap on its own to, for example, find the notes from the last few meetings I had with a particular person to generate a summary before our next chat.&lt;/p&gt;
    &lt;p&gt;Maybe predictably, early on I found myself wanting more than one text stream. I fought that inclination to discover what’s in store down the pure Canon Cat path. I also found myself wanting the ability to collapse sections (for finished todo lists, discarded drafts, etc.), though I could see these being a slippery slope, as I may feel the pull to do some deeper organization of my text, the abnegation of which is one of the most fascinating principles of this system. Over time, and once I implemented document separators, this inclination sort of melted away.&lt;/p&gt;
    &lt;p&gt;Having adapted my thinking to suit the mono-stream, one thing that would be nice to have is the ability to filter down to just the documents in your stream with a certain tag or other pattern. This would let me filter down to a certain month or year, topic, project, or notes regarding or with a certain person.&lt;/p&gt;
    &lt;p&gt;I would also appreciate having colors: when scanning through, color-coding different kinds of “entries” would help me find things I’m looking for more quickly. I think in terms of “types” — some entries are meeting notes, some are ruminations, some are composed documents to publish, and so forth. Being able to make types visually distinct while scanning through would help offload lots of “finding” work to my subconscious (as is the case in OLLOS).&lt;/p&gt;
    &lt;p&gt;And finally, in order to continue living in it “full-time”, I’d like to have Jasper sync with other devices. This would be excellent territory for a CRDT like Automerge.&lt;/p&gt;
    &lt;head rend="h2"&gt;Immediacy of a typewriter&lt;/head&gt;
    &lt;p&gt;This system reminds me of the Freewrite (a device that creates a focused space for writing text).The Freewrite takes this further: you can only write at the end of the text; you can’t edit or insert elsewhere. You can try out their online version at https://sprinter.getfreewrite.com. This aspect brings some nice qualities with it. I can “just think”, without being burdened by organizing files into specific folders, or naming things before I’ve even written them. From the Canon Cat’s How-to Guide: “When our designers created the Cat they threw out all the junk that makes computers clunky and held onto the personality and immediacy of a typewriter.”&lt;/p&gt;
    &lt;p&gt;It’s interesting to attempt recreating such a system; there are lots of specific interaction details that I’ve had to look into, which one wouldn’t consider unless reimplementing such a system. Canonical answers haven’t always been easy to find, however!&lt;/p&gt;
    &lt;p&gt;If you want to try it out yourself, it’s available for members here. It will save your text in your browser’s local storage (it does not send your text to any server).&lt;/p&gt;
    &lt;p&gt;Thanks to Paul Rony for introducing me to the Canon Cat and Archy, and for discussions about them and Jasper. Many of the assets associated with the Canon Cat can be found at canoncat.net, published by Vitorio Miliano. Photographs of the Canon Cat are from user snuci on deskthority.net.&lt;/p&gt;
    &lt;p&gt;My work is supported by members. If you find my work valuable and have the means, consider supporting it with a membership or sponsorship! This members-only article has been made publicly available. You can see more of my work at alexanderobenauer.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lab.alexanderobenauer.com/updates/the-jasper-report"/><published>2025-10-15T14:42:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45593665</id><title>David Byrne Radio</title><updated>2025-10-15T18:46:01.467297+00:00</updated><content>&lt;doc fingerprint="bd1957b3e9959ebe"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;David Byrne Presents: The Funky Broadway&lt;/head&gt;
      &lt;p&gt;by David Byrne&lt;/p&gt;
      &lt;p&gt;When I moved to New York, I worked for a while as an usher in a movie theater on East 34th Street. Once in a while, I had the job of taking the tickets, receipts, or sometimes the reels of film in big cans to the chain headquarters further uptown. Broadway! This street was famous, I thought to myself, it’s in songs and movies, and now I’m walking on it!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.davidbyrne.com/radio#filter=all&amp;sortby=date:desc"/><published>2025-10-15T15:00:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45595403</id><title>Claude Haiku 4.5</title><updated>2025-10-15T18:46:01.156199+00:00</updated><content>&lt;doc fingerprint="172b3fff2916ca6c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Claude Haiku 4.5&lt;/head&gt;
    &lt;p&gt;Claude Haiku 4.5, our latest small model, is available today to all users.&lt;/p&gt;
    &lt;p&gt;What was recently at the frontier is now cheaper and faster. Five months ago, Claude Sonnet 4 was a state-of-the-art model. Today, Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed.&lt;/p&gt;
    &lt;p&gt;Claude Haiku 4.5 even surpasses Claude Sonnet 4 at certain tasks, like using computers. These advances make applications like Claude for Chrome faster and more useful than ever before.&lt;/p&gt;
    &lt;p&gt;Users who rely on AI for real-time, low-latency tasks like chat assistants, customer service agents, or pair programming will appreciate Haiku 4.5’s combination of high intelligence and remarkable speed. And users of Claude Code will find that Haiku 4.5 makes the coding experience—from multiple-agent projects to rapid prototyping—markedly more responsive.&lt;/p&gt;
    &lt;p&gt;Claude Sonnet 4.5, released two weeks ago, remains our frontier model and the best coding model in the world. Claude Haiku 4.5 gives users a new option for when they want near-frontier performance with much greater cost-efficiency. It also opens up new ways of using our models together. For example, Sonnet 4.5 can break down a complex problem into multi-step plans, then orchestrate a team of multiple Haiku 4.5s to complete subtasks in parallel.&lt;/p&gt;
    &lt;p&gt;Claude Haiku 4.5 is available everywhere today. If you’re a developer, simply use claude-haiku-4-5 via the Claude API. Pricing is now $1/$5 per million input and output tokens.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt;Benchmarks&lt;/head&gt;
    &lt;quote&gt;Claude Haiku 4.5 hit a sweet spot we didn't think was possible: near-frontier coding quality with blazing speed and cost efficiency. In Augment's agentic coding evaluation, it achieves 90% of Sonnet 4.5's performance, matching much larger models. We're excited to offer it to our users.&lt;/quote&gt;
    &lt;quote&gt;Claude Haiku 4.5 is a leap forward for agentic coding, particularly for sub-agent orchestration and computer use tasks. The responsiveness makes AI-assisted development in Warp feel instantaneous.&lt;/quote&gt;
    &lt;quote&gt;Historically models have sacrificed speed and cost for quality. Claude Haiku 4.5 is blurring the lines on this trade off: it's a fast frontier model that keeps costs efficient and signals where this class of models is headed.&lt;/quote&gt;
    &lt;quote&gt;Claude Haiku 4.5 delivers intelligence without sacrificing speed, enabling us to build AI applications that utilize both deep reasoning and real-time responsiveness.&lt;/quote&gt;
    &lt;quote&gt;Claude Haiku 4.5 is remarkably capable—just six months ago, this level of performance would have been state-of-the-art on our internal benchmarks. Now it runs up to 4-5 times faster than Sonnet 4.5 at a fraction of the cost, unlocking an entirely new set of use cases.&lt;/quote&gt;
    &lt;quote&gt;Speed is the new frontier for AI agents operating in feedback loops. Haiku 4.5 proves you can have both intelligence and rapid output. It handles complex workflows reliably, self-corrects in real-time, and maintains momentum without latency overhead. For most development tasks, it's the ideal performance balance.&lt;/quote&gt;
    &lt;quote&gt;Claude Haiku 4.5 outperformed our current models on instruction-following for slide text generation, achieving 65% accuracy versus 44% from our premium tier model—that's a game-changer for our unit economics.&lt;/quote&gt;
    &lt;quote&gt;Our early testing shows that Claude Haiku 4.5 brings efficient code generation to GitHub Copilot with comparable quality to Sonnet 4 but at faster speed. Already we're seeing it as an excellent choice for Copilot users who value speed and responsiveness in their AI-powered development workflows.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Safety evaluations&lt;/head&gt;
    &lt;p&gt;We ran a detailed series of safety and alignment evaluations on Claude Haiku 4.5. The model showed low rates of concerning behaviors, and was substantially more aligned than its predecessor, Claude Haiku 3.5. In our automated alignment assessment, Claude Haiku 4.5 also showed a statistically significantly lower overall rate of misaligned behaviors than both Claude Sonnet 4.5 and Claude Opus 4.1—making Claude Haiku 4.5, by this metric, our safest model yet.&lt;/p&gt;
    &lt;p&gt;Our safety testing also showed that Claude Haiku 4.5 poses only limited risks in terms of the production of chemical, biological, radiological, and nuclear (CBRN) weapons. For that reason, we’ve released it under the AI Safety Level 2 (ASL-2) standard—compared to the more restrictive ASL-3 for Sonnet 4.5 and Opus 4.1. You can read the full reasoning behind the model’s ASL-2 classification, as well as details on all our other safety tests, in the Claude Haiku 4.5 system card.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further information&lt;/head&gt;
    &lt;p&gt;Claude Haiku 4.5 is available now on Claude Code and our apps. Its efficiency means you can accomplish more within your usage limits while maintaining premium model performance.&lt;/p&gt;
    &lt;p&gt;Developers can use Claude Haiku 4.5 on our API, Amazon Bedrock, and Google Cloud’s Vertex AI, where it serves as a drop-in replacement for both Haiku 3.5 and Sonnet 4 at our most economical price point.&lt;/p&gt;
    &lt;p&gt;For complete technical details and evaluation results, see our system card, model page, and documentation.&lt;/p&gt;
    &lt;head rend="h4"&gt;Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools—bash and file editing via string replacements. We report 73.3%, which was averaged over 50 trials, no test-time compute, 128K thinking budget, and default sampling parameters (temperature, top_p) on the full 500-problem SWE-bench Verified dataset.&lt;list rend="ul"&gt;&lt;item&gt;The score reported uses a minor prompt addition: "You should use tools as much as possible, ideally more than 100 times. You should also implement your own tests first before attempting the problem."&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Terminal-Bench: All scores reported use the default agent framework (Terminus 2), with XML parser, averaging 11 runs (6 without thinking (40.21% score), 5 with 32K thinking budget (41.75% score)) with n-attempts=1.&lt;/item&gt;
      &lt;item&gt;τ2-bench: Scores were achieved averaging over 10 runs using extended thinking (128k thinking budget) and default sampling parameters (temperature, top_p) with tool use and a prompt addendum to the Airline and Telecom Agent Policy instructing Claude to better target its known failure modes when using the vanilla prompt. A prompt addendum was also added to the Telecom User prompt to avoid failure modes from the user ending the interaction incorrectly.&lt;/item&gt;
      &lt;item&gt;AIME: Haiku 4.5 score reported as the average over 10 independent runs that each calculate pass@1 over 16 trials with default sampling parameters (temperature, top_p) and 128K thinking budget.&lt;/item&gt;
      &lt;item&gt;OSWorld: All scores reported use the official OSWorld-Verified framework with 100 max steps, averaged across 4 runs with 128K total thinking budget and 2K thinking budget per-step configured.&lt;/item&gt;
      &lt;item&gt;MMMLU: All scores reported are the average of 10 runs over 14 non-English languages with a 128K thinking budget.&lt;/item&gt;
      &lt;item&gt;All other scores were averaged over 10 runs with default sampling parameters (temperature, top_p) and 128K thinking budget.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All OpenAI scores reported from their GPT-5 post, GPT-5 for developers post, GPT-5 system card (SWE-bench Verified reported using n=500), and Terminal Bench leaderboard (using Terminus 2). All Gemini scores reported from their model web page, and Terminal Bench leaderboard (using Terminus 1).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/news/claude-haiku-4-5"/><published>2025-10-15T16:55:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45596168</id><title>Claude Haiku 4.5 System Card [pdf]</title><updated>2025-10-15T18:46:01.012066+00:00</updated><content/><link href="https://assets.anthropic.com/m/99128ddd009bdcb/original/Claude-Haiku-4-5-System-Card.pdf"/><published>2025-10-15T17:52:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45596359</id><title>Clone-Wars: 100 open-source clones of popular sites</title><updated>2025-10-15T18:46:00.102176+00:00</updated><content>&lt;doc fingerprint="89043409dff25bcb"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;100+ open-source clones and alternatives of popular sites like Airbnb, Amazon, Instagram, Netflix, TikTok, Spotify, WhatsApp, YouTube, etc. List contains source code, tutorials, demo links, tech stack, and GitHub stars count. Great for learning purpose!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Made by Gourav Goyal&lt;/p&gt;
    &lt;head rend="h2"&gt;See full tables with better view 👉 gourav.io/clone-wars&lt;/head&gt;
    &lt;p&gt;I need your help to maintain this list up to date 🙏. See contribution Guide.&lt;/p&gt;
    &lt;p&gt;I'm also looking for a maintainer to merge PRs of new clones.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Full-stack clones with link to free tutorials.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Two kinds of projects on this list:&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;Clones: look quite similar (UI-wise) but aren't fully-functional, mostly made for learning purposes.&lt;/item&gt;
          &lt;item&gt;Alternatives: fully-functional open-source alternatives of popular software. Seeing GitHub stars will give you a rough idea about which one is which.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Read the story behind this project: My simple GitHub project went viral 🚀&lt;/p&gt;
    &lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Clone of&lt;/cell&gt;
        &lt;cell role="head"&gt;Demo&lt;/cell&gt;
        &lt;cell role="head"&gt;Tutorial / Course Site&lt;/cell&gt;
        &lt;cell role="head"&gt;Repo&lt;/cell&gt;
        &lt;cell role="head"&gt;Tech Stack&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Airbnb&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;GitHub backend, frontend&lt;/cell&gt;
        &lt;cell&gt;Sanity SDK, Next.js, React Hooks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;freeCodeCamp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native, Firebase Firestore, Firebase storage, Redux, Expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Moodle&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;freeCodeCamp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Django Rest Framework&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Apollo GraphQL, DataStax Astra, Netlify&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Todoist&lt;/cell&gt;
        &lt;cell&gt;todoist-preview.png&lt;/cell&gt;
        &lt;cell&gt;freeCodeCamp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase, React, SCSS, BEM naming methodology&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;freeCodeCamp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vue.js, Quasar Framework, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;freeCodeCamp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Android Studio, Firebase, Genymotion&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Discord&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;Youtube (Traversy Media)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Django&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;Youtube (JavaScript Mastery)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React JS, Rapid API, Material UI 5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;freeCodeCamp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Yii2 PHP Framework&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Android Studio, Kotlin, XML, YouTube API&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;(scroll right on table to see all 5 columns)&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Clone/Alt of&lt;/cell&gt;
        &lt;cell role="head"&gt;Demo&lt;/cell&gt;
        &lt;cell role="head"&gt;Repo&lt;/cell&gt;
        &lt;cell role="head"&gt;Tech stack&lt;/cell&gt;
        &lt;cell role="head"&gt;Repo Stars&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1Password / LastPass&lt;/cell&gt;
        &lt;cell&gt;bitwarden.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;C#, Xamarin&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;gh.artemchep.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Dart, Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;2048-three.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;demo.matsz.dev&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, TypeScript, Redux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;guaracy.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Beads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;oddrationale.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Dart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Airbnb&lt;/cell&gt;
        &lt;cell&gt;abod-bnb.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Airbnb&lt;/cell&gt;
        &lt;cell&gt;realbnb.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript, React, NextJS, Prisma, GraphQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Airbnb&lt;/cell&gt;
        &lt;cell&gt;airbnb-clone-black-seven.vercel.app/&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next, Tailwind, SEO, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Airtable&lt;/cell&gt;
        &lt;cell&gt;rowy.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase, Firestore, Google Cloud Platform, Cloud Functions, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Airtable&lt;/cell&gt;
        &lt;cell&gt;baserow&lt;/cell&gt;
        &lt;cell&gt;GitLab&lt;/cell&gt;
        &lt;cell&gt;Django, nuxt.js, PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Algolia&lt;/cell&gt;
        &lt;cell&gt;meilisearch.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Rust&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;amazonna.netlify.app &lt;p&gt;youtube&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Amazon Prime Video&lt;/cell&gt;
        &lt;cell&gt;prime-clone-e1de6.firebaseapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Apple Music&lt;/cell&gt;
        &lt;cell&gt;appo-music.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Ruby on Rails, PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ArcoMage&lt;/cell&gt;
        &lt;cell&gt;arcomage.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript, React, Redux, RxJS, Sass, WebRTC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Auth0&lt;/cell&gt;
        &lt;cell&gt;ory.sh&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Bit.ly&lt;/cell&gt;
        &lt;cell&gt;polrproject.org&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP, MySQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Bit.ly&lt;/cell&gt;
        &lt;cell&gt;shlink.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP, Mezzio, Doctrine, Symfony&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Bit.ly&lt;/cell&gt;
        &lt;cell&gt;zws.im&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript,&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Bit.ly&lt;/cell&gt;
        &lt;cell&gt;kutt.it&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript,&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Bit.ly&lt;/cell&gt;
        &lt;cell&gt;shortl.it&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript, NodeJS, EJS, JQuery&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;BrickGame&lt;/cell&gt;
        &lt;cell&gt;Retro-Brick-Game&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Battleship Game&lt;/cell&gt;
        &lt;cell&gt;battleboats.ito.wtf&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript, React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Calendly&lt;/cell&gt;
        &lt;cell&gt;calendso.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next.js, Typescript, React, Tailwind, Prisma&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Clubhouse&lt;/cell&gt;
        &lt;cell&gt;jam.systems&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, WebRTC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Clubhouse&lt;/cell&gt;
        &lt;cell&gt;dogehouse.tv&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Postgress, Elixir&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Codecademy&lt;/cell&gt;
        &lt;cell&gt;codecademyclone.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;DEV.to&lt;/cell&gt;
        &lt;cell&gt;devfrom.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Discord&lt;/cell&gt;
        &lt;cell&gt;ericellb.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Node, Express, Socket-IO, MySQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Discord&lt;/cell&gt;
        &lt;cell&gt;valkyrieapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, NestJS, TypeScript, Socket-IO, PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Discord&lt;/cell&gt;
        &lt;cell&gt;dev.fosscord.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript, Express, WebRTC, Websockets, TypeORM, SQLite&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Disney+&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native, expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Disney+ Hotstar&lt;/cell&gt;
        &lt;cell&gt;determined-bardeen-6a04b8.netlify&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ReactJS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Doodle&lt;/cell&gt;
        &lt;cell&gt;sm2030.user.srcf.net&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Dribbble&lt;/cell&gt;
        &lt;cell&gt;driwwwle.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MERN, react&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Dribbble&lt;/cell&gt;
        &lt;cell&gt;v.redd.it&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MongoDB, ExpressJS, React,&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Dropbox&lt;/cell&gt;
        &lt;cell&gt;try.nextcloud.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP, JS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Dropbox&lt;/cell&gt;
        &lt;cell&gt;Live.filegator.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP, JS, Vuejs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Evernote&lt;/cell&gt;
        &lt;cell&gt;joplinapp.org&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JavaScript, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Express JS&lt;/cell&gt;
        &lt;cell&gt;robiul.dev&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node js&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;odinclone.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MERN&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;react, graphql, mongodb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;clonedbook.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next.js, MUI, Firebase, Faker.js&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Firebase&lt;/cell&gt;
        &lt;cell&gt;appwrite.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Firebase&lt;/cell&gt;
        &lt;cell&gt;supabase.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Elixir,React,PostgreSQL,Python&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Firebase&lt;/cell&gt;
        &lt;cell&gt;nhost.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PostgreSQL, GraphQL, TypeScript, Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Gmail&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;searchify.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;NextJS, TailwindCSS, Google Search API&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Analytics&lt;/cell&gt;
        &lt;cell&gt;plausible.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Elixir, PostgreSQL, Tailwind&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Analytics&lt;/cell&gt;
        &lt;cell&gt;matomo.org&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP, HTML, MySQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Analytics&lt;/cell&gt;
        &lt;cell&gt;ackee.electerious.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Analytics&lt;/cell&gt;
        &lt;cell&gt;learnsql.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Rails, OpenResty, TimescaleDB, postgresql, tailwindcss&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Drive&lt;/cell&gt;
        &lt;cell&gt;mydrive-3.herokuapp &lt;p&gt;mydrive-storage.com&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Node.js, mongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Keep&lt;/cell&gt;
        &lt;cell&gt;github.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, GraphQL, Golang, SQlite&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Keep&lt;/cell&gt;
        &lt;cell&gt;vue-keep-sepia.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vue, TypeScript, Firestore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Keep&lt;/cell&gt;
        &lt;cell&gt;google-keeps-clone.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Django, JS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Forms&lt;/cell&gt;
        &lt;cell&gt;google-forms-clone.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Django, JS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Forms&lt;/cell&gt;
        &lt;cell&gt;https://handform-c62a3.web.app/&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Photos&lt;/cell&gt;
        &lt;cell&gt;photos-clone.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Photos&lt;/cell&gt;
        &lt;cell&gt;photoprism.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Go,TensorFlow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Google Translate&lt;/cell&gt;
        &lt;cell&gt;libretranslate.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Python, Flask&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Hashnode&lt;/cell&gt;
        &lt;cell&gt;hashnode-clone-sass.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;HTML, SASS, JavaScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Headspace&lt;/cell&gt;
        &lt;cell&gt;meditofoundation.org&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Hacker News&lt;/cell&gt;
        &lt;cell&gt;hackernews-redesign.netlify&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Hacker News&lt;/cell&gt;
        &lt;cell&gt;news.python&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Python, Django&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Hacker News&lt;/cell&gt;
        &lt;cell&gt;rm-hackernews.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Reactjs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Hacker News&lt;/cell&gt;
        &lt;cell&gt;hackernews-jaywhen.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next.js&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HotJar&lt;/cell&gt;
        &lt;cell&gt;Formbricks&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JavaScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Hulu&lt;/cell&gt;
        &lt;cell&gt;fake-hulu-eosin.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next.js, Sass, Firebase, tmdb-api&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;IMDB&lt;/cell&gt;
        &lt;cell&gt;movie4fun.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, ReactQuery, tmdb-api&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;maxgram.zabarka.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MongoDB, Express, Reactjs, Node&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;instaclone.net &lt;p&gt;github.com (gif)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Reactjs, Express, Nodejs, Mongodb, Socketio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;github.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Jetpack Compose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;instagram-clone-dbe40.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Intercom&lt;/cell&gt;
        &lt;cell&gt;papercups.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Elixir, Phoenix&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Intercom&lt;/cell&gt;
        &lt;cell&gt;chatwoot.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JAMStack, Vue&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;iOS Homescreen&lt;/cell&gt;
        &lt;cell&gt;ios-homescreen.now.sh&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Next.js, Emotion&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Jira&lt;/cell&gt;
        &lt;cell&gt;jira.sebastianfdz.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next.js, React-Query Radix UI, Clerk Auth, Zod, TailwindCSS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Jira&lt;/cell&gt;
        &lt;cell&gt;jira.ivorreic.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Express(Typescript), JWT, TypeORM, PostgreSQL, React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Jira&lt;/cell&gt;
        &lt;cell&gt;jira.trungk18&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Angular, Akita, TailwindCSS, ng-zorro&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;LaunchDarkly&lt;/cell&gt;
        &lt;cell&gt;getunleash.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Java, Node.js, Go, Python, Ruby, .Net, JavaScript, React, Android, iOS,&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;LaunchDarkly&lt;/cell&gt;
        &lt;cell&gt;flagsmith.com&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Python, Django, React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Linear.app&lt;/cell&gt;
        &lt;cell&gt;youtube.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, TailwindCSS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;MacOS Calculator&lt;/cell&gt;
        &lt;cell&gt;chamoda.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;MacOS Finder Clone&lt;/cell&gt;
        &lt;cell&gt;finder-clone.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Sass&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Medium / Wordpress / Substack&lt;/cell&gt;
        &lt;cell&gt;ghost.org&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JAMStack, Ember, Node, MySQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Medium&lt;/cell&gt;
        &lt;cell&gt;next-realworld.now.sh&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Next.js&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Messenger&lt;/cell&gt;
        &lt;cell&gt;tippindev.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP/Laravel, MySQL, Websockets&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;MS Paint&lt;/cell&gt;
        &lt;cell&gt;jspaint.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node.js&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix [Fakeflix]&lt;/cell&gt;
        &lt;cell&gt;fakeflix.th3wall.codes&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;netflix-clone-react-typescript.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React(v18), RTK(ReduxToolKit), Typescript, TMDB API, MUI, Video.js, Framer Motion, Slick Carousel, Docker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;azazel5.github.io &lt;p&gt;github.com (gif)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;netflix-clone-dd230.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;spaceflix.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Ruby, React, Redux, PostgreSQL, AWS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;expo-netflix.calebnance.now.sh&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native, expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;roseflix-rosebilag.vercel&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, TypeScript, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;nfx.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, TypeScript, SCSS Modules&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Netflix&lt;/cell&gt;
        &lt;cell&gt;Wep-App ,android&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Capacitor, Pwa&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Nike&lt;/cell&gt;
        &lt;cell&gt;gif&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Express, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Notion&lt;/cell&gt;
        &lt;cell&gt;focalboard.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node, React, Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Okta&lt;/cell&gt;
        &lt;cell&gt;[topaz.sh](https://www.topaz.sh projects/)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Okta&lt;/cell&gt;
        &lt;cell&gt;ory.sh&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Obsidian&lt;/cell&gt;
        &lt;cell&gt;zettlr.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Electron, Vue, Markdown&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Omegle&lt;/cell&gt;
        &lt;cell&gt;start-a-conversation.firebaseapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase, Twilio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Orkut&lt;/cell&gt;
        &lt;cell&gt;orkutnostalgia.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;ReactJS, GraphQL, Apollo, PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;PayTM&lt;/cell&gt;
        &lt;cell&gt;github.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;trusting-euler-8aafb8.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GraphQL, ReactJS, NodeJS, Mysql&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Postman&lt;/cell&gt;
        &lt;cell&gt;firecamp.dev&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Electron, ReactJS, NodeJS, Typescript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Postman&lt;/cell&gt;
        &lt;cell&gt;insomnia.rest&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Electron&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Postman&lt;/cell&gt;
        &lt;cell&gt;hoppscotch.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JAMStack, Vue, NuxtJS, firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Privnote&lt;/cell&gt;
        &lt;cell&gt;secret.roushik.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Django, Postgres, jQuery&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;troddit.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;NextJS, React, TailwindCSS, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;redditsyncr.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;asperitas.now.sh&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node.js, React, NoSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Lemmy&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ActivityPub, Rust, Postgres, Docker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;kbin&lt;/cell&gt;
        &lt;cell&gt;Codeberg&lt;/cell&gt;
        &lt;cell&gt;ActivityPub, PHP, Postgres, Docker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Sublinks&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ActivityPub, Java, TypeScript, MariaDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;PieFed&lt;/cell&gt;
        &lt;cell&gt;Codeberg&lt;/cell&gt;
        &lt;cell&gt;ActivityPub, Python, Postgres, Redis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Retool&lt;/cell&gt;
        &lt;cell&gt;budibase.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node.js, Svelte&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Retool&lt;/cell&gt;
        &lt;cell&gt;ILLA Cloud&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Typescript, Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Telegram&lt;/cell&gt;
        &lt;cell&gt;tinode.co&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Go, React, Java, Swift, MySQL, MongoDB, RethinkDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;TikTok + Reddit&lt;/cell&gt;
        &lt;cell&gt;reddit-tiktok.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Twitch&lt;/cell&gt;
        &lt;cell&gt;twitchclone.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Next.JS, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Slack&lt;/cell&gt;
        &lt;cell&gt;mattermost.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Go&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Slack&lt;/cell&gt;
        &lt;cell&gt;rocket.chat&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JAMStack, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Slack&lt;/cell&gt;
        &lt;cell&gt;zulip.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Python, JS, TS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Slack&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native, Expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Slido&lt;/cell&gt;
        &lt;cell&gt;askent.berlinchan.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Material-UI, Apollo GraphQL, Hasura, TypeORM, TypeGraphQL, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Sliders Game&lt;/cell&gt;
        &lt;cell&gt;Play the game&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vanilla JavaScript, CSS, MongoDb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Snapchat&lt;/cell&gt;
        &lt;cell&gt;towhidkashem.github.io &lt;p&gt;youtube&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, TypeScript, Cypress, Jest, Enzyme&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;spotify.trungk18&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Angular 11, Nx, ngrx, TailwindCSS and ng-zorro&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;github.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify Web Player&lt;/cell&gt;
        &lt;cell&gt;spotify-clone-oguz3.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;screenshot&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Electron, React, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;drive.google.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;tune42-spotify.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;expo-spotify.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native, Expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;30sekify.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Electron&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify&lt;/cell&gt;
        &lt;cell&gt;30sekify.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Electron&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Spotify + Soundcloud + YouTube&lt;/cell&gt;
        &lt;cell&gt;kord.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Express, PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Stack Overflow&lt;/cell&gt;
        &lt;cell&gt;live.scoold&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Java, jQuery, Para&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Stack Overflow&lt;/cell&gt;
        &lt;cell&gt;clone-of-stackoverflow.vercel&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ReactJs, NextJs, Express, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Stack Overflow&lt;/cell&gt;
        &lt;cell&gt;drive.google.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MySQL, Express, React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Stack Overflow&lt;/cell&gt;
        &lt;cell&gt;stackunderflow.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MongoDB, Express, React, NodeJS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Temp-Mail&lt;/cell&gt;
        &lt;cell&gt;simplelogin.io &lt;p&gt;youtube&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Python, Docker, Vue&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Tetris Game&lt;/cell&gt;
        &lt;cell&gt;hinsxd-tetris.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Tetris Game&lt;/cell&gt;
        &lt;cell&gt;tetris20.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Tetris Game React&lt;/cell&gt;
        &lt;cell&gt;chvin.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Web Audio Api&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;TikTok&lt;/cell&gt;
        &lt;cell&gt;github.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Native, Firebase, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;TikTok&lt;/cell&gt;
        &lt;cell&gt;youtube.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;TikTok&lt;/cell&gt;
        &lt;cell&gt;youtube.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Flutter, Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;TikTok + Reddit&lt;/cell&gt;
        &lt;cell&gt;enrybalassiano.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;TinyURL&lt;/cell&gt;
        &lt;cell&gt;nexturl.vercel.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Next.js TypeScript React Mongodb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Todoist&lt;/cell&gt;
        &lt;cell&gt;todoishh.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React Firebase&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Travian&lt;/cell&gt;
        &lt;cell&gt;cosmodream.ga&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vanilla JS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;wekan.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Meteor&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;taiga.io&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Django, AngularJS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;kanboard.org&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;trellis-app.herokuapp &lt;p&gt;github.com (gif)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Node, Express, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;codesource.io (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Angular 10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;tiquetapp.herokuapp.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Python, Flask, PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;tberghuis.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;rupmalya-trello-clone.herokuapp &lt;p&gt;youtube.com&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Express, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;project-manager1.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Node, Express, Socket.io, MongoDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Trello&lt;/cell&gt;
        &lt;cell&gt;trello-project-manager.netlify&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Node.js, Firebase, Serverless, AWS Lambda&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mastodon&lt;/cell&gt;
        &lt;cell&gt;echoloop.buzz&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Node.js, Next.Js, Express.Js, TypeScript, TailwindCSS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mastodon&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ActivityPub, Ruby, Go, Postgres, Redis, Docker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;https://tweeetr.netlify.app/ &lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React,Express js, NodeJS,Graphql,Apollo client,apollo-server,styled-components&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;twitter-geek.netlify.app &lt;p&gt;github.com (screenshot)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;React, Redux, NodeJS, MYSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;twitterclone2.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;HTML, CSS, JQuery&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;tclone.netlify.app &lt;p&gt;github.com (gif)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;MERN&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;twitterapp-clone.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;React, express, mongo, aws, socket.io&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;twitter-cln.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vue, Express, Mongo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;twitter-web-clone-react.vercel&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Typeform&lt;/cell&gt;
        &lt;cell&gt;Formbricks&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JavaScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Typeform / Google Form&lt;/cell&gt;
        &lt;cell&gt;ohmyform.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Typeform&lt;/cell&gt;
        &lt;cell&gt;supereasyforms.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JavaScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Uber&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React native, expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Uber&lt;/cell&gt;
        &lt;cell&gt;youtube.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Uber Eats&lt;/cell&gt;
        &lt;cell&gt;enatega.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JavaScript, React, React Native, Material UI, GraphQL, Expo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Ubuntu&lt;/cell&gt;
        &lt;cell&gt;vivek9patel.github.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Tailwind CSS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Udemy&lt;/cell&gt;
        &lt;cell&gt;wedemy.up.railway.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vue 3, TypeScript, Java, Spring, MySQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Udemy&lt;/cell&gt;
        &lt;cell&gt;wedemy.up.railway.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Vue 3, TypeScript, ElementUI, Java, Springboot, MySQL, Redis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Unsplash&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Unsplash&lt;/cell&gt;
        &lt;cell&gt;github.com (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Unsplash&lt;/cell&gt;
        &lt;cell&gt;mani-unsplash-clone.netlify&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Material-UI&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Vimeo&lt;/cell&gt;
        &lt;cell&gt;bimeo.herokuapp&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Ruby. PostgreSQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;VK&lt;/cell&gt;
        &lt;cell&gt;openvk.su&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;PHP, HTML, CSS, JQuery, MySQL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;codesource.io (screenshot)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;medium.com (article)&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Angular, Express, PostgreSQL, GraphQL, TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;youtube &lt;p&gt;clone-massenger.herokuapp&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;MERN&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;tinode.co&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Go, React, Java, Swift, MySQL, MongoDB, RethinkDB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;WhatsApp (Web)&lt;/cell&gt;
        &lt;cell&gt;whatsapp-clone-web.netlify.app&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;React, React Context API, Express, JavaScript, Socket.IO&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Windows 11&lt;/cell&gt;
        &lt;cell&gt;win11.blueedge.me&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Firebase, TailwindCSS, Internationalization&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Wix&lt;/cell&gt;
        &lt;cell&gt;grapesjs.com&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;JavaScript, Webpack&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Workflowy&lt;/cell&gt;
        &lt;cell&gt;deepnotes.in&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ReactJS, DraftJS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;yt-clone-7.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;ReactJs,Redux,Firebase,YouTube API&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube&lt;/cell&gt;
        &lt;cell&gt;utubeclone.netlify.app &lt;p&gt;youtube&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;GitHub &lt;p&gt;GitHub&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Express, Sequelize&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube Music&lt;/cell&gt;
        &lt;cell&gt;octave-music.web.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;React, Redux, Firebase, Material-UI&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube Music&lt;/cell&gt;
        &lt;cell&gt;beatbump.ml&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Svelte&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;YouTube Music&lt;/cell&gt;
        &lt;cell&gt;music.creasource.app&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Angular&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Zapier&lt;/cell&gt;
        &lt;cell&gt;n8n.io&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;TypeScript, Vue, Docker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Zapier&lt;/cell&gt;
        &lt;cell&gt;vimeo.com (gif)&lt;/cell&gt;
        &lt;cell&gt;GitHub&lt;/cell&gt;
        &lt;cell&gt;Ruby&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Some link is broken or clone is not good enough? report it&lt;/p&gt;
    &lt;p&gt;I need your help to maintain this list up to date 🙏.&lt;/p&gt;
    &lt;p&gt;If there's some issue with a clone (URL not working, repo not found, clone not good enough, etc.), then feel free to remove or update it with working link. Just edit readme.md and submit a PR. I'll review and merge it.&lt;/p&gt;
    &lt;p&gt;Before submitting a clone make sure:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It should be a clone/alternative of some popular software or app.&lt;/item&gt;
      &lt;item&gt;Project must have at least minimal functionality, please do not submit any 'UI only' clone.&lt;/item&gt;
      &lt;item&gt;Also, no more Trello, 2048 clones unless your tech-stack is different.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Add clone to 1st table if you can also provide tutorial link else add it to 2nd table. Maintain alphabetical order while adding.&lt;/p&gt;
    &lt;p&gt;Edit readme.md (you may use online md editor like markdown.site for better table visualization) and submit the PR! Make sure there are no merge conflicts.&lt;/p&gt;
    &lt;p&gt;Any other feedback to improve this project is also welcome :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/GorvGoyl/Clone-Wars"/><published>2025-10-15T18:06:41+00:00</published></entry></feed>