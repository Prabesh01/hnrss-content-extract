<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-16T10:13:11.958519+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46278208</id><title>Chafa: Terminal Graphics for the 21st Century</title><updated>2025-12-16T10:13:19.435749+00:00</updated><content>&lt;doc fingerprint="7f1291714fd2bd2c"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The future is (still) now&lt;/head&gt;
    &lt;p&gt;The premier UX of the 21st century just got a little better: With &lt;code&gt;chafa&lt;/code&gt;,
  you can now view very, very reasonable approximations
  of pictures and animations in the comfort of your
  favorite terminal emulator. The power of ANSI X3.64 compels you!&lt;/p&gt;
    &lt;head rend="h3"&gt;Example&lt;/head&gt;
    &lt;p&gt;You can get fair results by using only U+2580 (upper half block). Other terminal graphics packages do this, and so can Chafa with &lt;code&gt;chafa --symbols vhalf&lt;/code&gt;. However, Chafa
uses more symbols by default, greatly improving quality.&lt;/p&gt;
    &lt;p&gt;There are more examples in the gallery!&lt;/p&gt;
    &lt;head rend="h3"&gt;Features&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports most popular image formats, including animated GIFs.&lt;/item&gt;
      &lt;item&gt;Outputs to all popular terminal graphics formats: Sixels, Kitty, iTerm2, Unicode mosaics.&lt;/item&gt;
      &lt;item&gt;Combines Unicode symbols from multiple selectable ranges for optimal output.&lt;/item&gt;
      &lt;item&gt;Fullwidth character support, e.g. Chinese, Japanese, Korean.&lt;/item&gt;
      &lt;item&gt;Glyphs can be loaded from any font file supported by Freetype (TTF, OTF, PCF, etc).&lt;/item&gt;
      &lt;item&gt;Multiple color modes, including Truecolor, 256-color, 16-color and simple FG/BG.&lt;/item&gt;
      &lt;item&gt;RGB and DIN99d color spaces for improved color picking.&lt;/item&gt;
      &lt;item&gt;Alpha transparency support in any color mode, including in animations.&lt;/item&gt;
      &lt;item&gt;Works with most modern and classic terminals and terminal emulators.&lt;/item&gt;
      &lt;item&gt;Documented, stable C API.&lt;/item&gt;
      &lt;item&gt;Fast &amp;amp; lean: SIMD optimized, multithreaded.&lt;/item&gt;
      &lt;item&gt;Suitable for terminal graphics, ANSI art composition and even black &amp;amp; white print.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some of the features are discussed in a series of blog posts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Introducing Chafa&lt;/item&gt;
      &lt;item&gt;The worst ANSI art renderer, except for all the others&lt;/item&gt;
      &lt;item&gt;Chafa 1.2.0: Faster than ever, now with 75% more grit&lt;/item&gt;
      &lt;item&gt;Chafa 1.4.0: Now with sixels&lt;/item&gt;
      &lt;item&gt;Chafa 1.6.0: Wider&lt;/item&gt;
      &lt;item&gt;Chafa 1.8: Terminal graphics with a side of everything&lt;/item&gt;
      &lt;item&gt;Chafa 1.14: All-singing, all-dancing&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Documentation&lt;/head&gt;
    &lt;p&gt;Chafa will print a help text if run without arguments, or with &lt;code&gt;chafa --help&lt;/code&gt;.
It also comes with a man page displayable with &lt;code&gt;man chafa&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The gallery contains examples of how command-line options can be used to tweak the output.&lt;/p&gt;
    &lt;p&gt;There is C API documentation for application developers.&lt;/p&gt;
    &lt;p&gt;Erica Ferrua EdwardsdÃ³ttir is developing Python bindings that allow Chafa to be used in Python programs. These are documented on their own site.&lt;/p&gt;
    &lt;p&gt;HÃ©ctor Molinero FernÃ¡ndez maintains JavaScript bindings that allow Chafa to be used in Node.js, web browsers, and more. These are documented on their own site.&lt;/p&gt;
    &lt;head rend="h3"&gt;Community&lt;/head&gt;
    &lt;p&gt;Please bring your questions to our &lt;del&gt;secret business&lt;/del&gt; friendly Matrix chat. Stay a while and listen, or talk about terminals, software or your choice of breakfast cereal. All are welcome, but an appreciation for terminals, programming and/or computer graphics is likely to enhance your experience.&lt;/p&gt;
    &lt;p&gt;Although the chat's history is hidden from non-members, this is a public forum, so if your ambition is to overthrow the government/megacorps by way of an underground network of refurbished Minitels, you may want to keep it under your hat. Furthermore, and hopefully obviously, we treat our fellow humans with respect. Have fun!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hpjansson.org/chafa/"/><published>2025-12-15T18:16:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46279187</id><title>Umbrel – Personal Cloud</title><updated>2025-12-16T10:13:19.096461+00:00</updated><content>&lt;doc fingerprint="c5e113d09df9eb66"&gt;
  &lt;main&gt;
    &lt;p&gt;Your cloud. In your&lt;/p&gt;
    &lt;p&gt;Your cloud. In your&lt;/p&gt;
    &lt;p&gt;Your cloud. In your&lt;/p&gt;
    &lt;p&gt;home.&lt;/p&gt;
    &lt;p&gt;home.&lt;/p&gt;
    &lt;p&gt;home.&lt;/p&gt;
    &lt;p&gt;Store your files, download and stream media, run a Bitcoin node, and more â all in your home.&lt;/p&gt;
    &lt;p&gt;Store your files, download and stream media, run a Bitcoin node, and more â all in your home.&lt;/p&gt;
    &lt;p&gt;Store your files, download and stream media, run a Bitcoin node, and more â all in your home.&lt;/p&gt;
    &lt;p&gt;The all-new Umbrel Home&lt;/p&gt;
    &lt;p&gt;Your data, finally home.&lt;/p&gt;
    &lt;p&gt;Now with up to 4TB of SSD storage for everything that matters.&lt;/p&gt;
    &lt;p&gt;The all-new Umbrel Home&lt;/p&gt;
    &lt;p&gt;Your data, finally home.&lt;/p&gt;
    &lt;p&gt;Now with up to 4TB of SSD storage for everything that matters.&lt;/p&gt;
    &lt;p&gt;The all-new Umbrel Home&lt;/p&gt;
    &lt;p&gt;Your data, finally home.&lt;/p&gt;
    &lt;p&gt;Now with up to 4TB of SSD storage for everything that matters.&lt;/p&gt;
    &lt;p&gt;What can I do with umbrelOS?&lt;/p&gt;
    &lt;p&gt;What can I do with umbrelOS?&lt;/p&gt;
    &lt;p&gt;The superpowers are&lt;/p&gt;
    &lt;p&gt;The superpowers are&lt;/p&gt;
    &lt;p&gt;endlessssssssss&lt;/p&gt;
    &lt;p&gt;endlessssssssss&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
        &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
        &lt;p&gt;Get Pi-holeÂ® on your Umbrel and your entire network gets rid of ads. Yes, the entire network, not just your browser.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Automate your home and appliances.&lt;/p&gt;
        &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
        &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run DeepSeek R1, LLama 3, and more.&lt;/p&gt;
        &lt;p&gt;Download and run advanced AI models directly on your own hardware. Self-hosting AI models ensures full control over your data and protects your privacy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Google Drive that lives in your home.&lt;/p&gt;
    &lt;p&gt;With Nextcloud, store your documents, calendar, contacts and photos on your Umbrel instead of Google's servers.&lt;/p&gt;
    &lt;p&gt;Run your own Bitcoin node.&lt;/p&gt;
    &lt;p&gt;Don't trust. Verify. Run your own node and achieve unparalleled privacy by connecting your wallets directly to your Bitcoin node.&lt;/p&gt;
    &lt;p&gt;Stream your movies &amp;amp; TV shows.&lt;/p&gt;
    &lt;p&gt;Stream the movies and TV shows you download on your umbrelOS home server effortlessly to your TV, computer, and phone.&lt;/p&gt;
    &lt;p&gt;Automate your home.&lt;/p&gt;
    &lt;p&gt;Home Assistant integrates with over a thousand different devices and services to make your home work for you.&lt;/p&gt;
    &lt;p&gt;Block ads on your entire network.&lt;/p&gt;
    &lt;p&gt;Get Pi-holeÂ® on your Umbrel and block ads on your entire network. Yes â the entire network, not just your browser.&lt;/p&gt;
    &lt;p&gt;That's all. Except not.&lt;/p&gt;
    &lt;p&gt;Thereâs an entire&lt;/p&gt;
    &lt;p&gt;app store.&lt;/p&gt;
    &lt;p&gt;Discover amazing self-hosted apps in the Umbrel App Store and install them in one click on umbrelOS.&lt;/p&gt;
    &lt;p&gt;That's all. Except not.&lt;/p&gt;
    &lt;p&gt;Thereâs an entire&lt;/p&gt;
    &lt;p&gt;app store.&lt;/p&gt;
    &lt;p&gt;Discover amazing self-hosted apps in the Umbrel App Store and install them in one click on umbrelOS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Bitcoin Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Shell&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Samourai&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Plex&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nostr Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ghostfolio&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Torq&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SimpleTorrent&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Bitcoin Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Shell&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Samourai&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lightning Node&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Plex&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nostr Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ghostfolio&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Torq&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SimpleTorrent&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;mempool&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WoofBot&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LibreOffice&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sphinx Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tailscale&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nextcloud&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Firefox&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhotoPrism&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trilium Notes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;n8n&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;mempool&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WoofBot&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LibreOffice&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sphinx Relay&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tailscale&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nextcloud&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Firefox&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhotoPrism&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trilium Notes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;n8n&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Community&lt;/p&gt;
    &lt;p&gt;Community&lt;/p&gt;
    &lt;p&gt;A place to get your questions answered, and to connect with fellow sovereign individuals.&lt;/p&gt;
    &lt;p&gt;Support&lt;/p&gt;
    &lt;p&gt;Support&lt;/p&gt;
    &lt;p&gt;Get help with installing and troubleshooting umbrelOS and Umbrel Home.&lt;/p&gt;
    &lt;p&gt;Careers&lt;/p&gt;
    &lt;p&gt;Careers&lt;/p&gt;
    &lt;p&gt;Weâre hiring! Join us and shape the future of Umbrel.&lt;/p&gt;
    &lt;p&gt;Stay in the loop&lt;/p&gt;
    &lt;p&gt;Stay in the loop&lt;/p&gt;
    &lt;p&gt;Follow our journey in enabling sovereign individuals truly own their data.&lt;/p&gt;
    &lt;p&gt;Better yet, be a part of it.&lt;/p&gt;
    &lt;p&gt;Follow our journey in enabling sovereign individuals truly own their data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://umbrel.com"/><published>2025-12-15T19:27:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46279825</id><title>The appropriate amount of effort is zero</title><updated>2025-12-16T10:13:18.600842+00:00</updated><content>&lt;doc fingerprint="21475376a7f44cfd"&gt;
  &lt;main&gt;
    &lt;p&gt;Most people put too much effort into everything they do. Here’s a good example from Kristijan around tension in his hands when touching and holding things:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Something clicked about inhibition and non-doing (in Alexander Technique), and the strongest effect has been a relaxation of my hands.&lt;/p&gt;— Kristijan (@kristijan_moves) August 20, 2025&lt;lb/&gt;Like I was touching and holding things with 40% more tension than required for that object or activity.@m_ashcroft any thoughts?&lt;/quote&gt;
    &lt;p&gt;It’s a great example, because gripping too tightly, as we might with the hands, is a great metaphor for what it’s like everywhere else in your system. There’s a pattern of pervasive over-gripping that, once you start to look for it, you will find everywhere.&lt;/p&gt;
    &lt;p&gt;There is an appropriate amount of energy required for each activity. Holding a cup, turning a steering wheel, or writing a blog post all need exactly the amount of energy that they need. This may sound like a truism, but if it were so obvious, why do many drivers often realise they are driving with a vice-like grip, with tension running up into their shoulders and jaws?&lt;/p&gt;
    &lt;p&gt;Let me share my slightly unusual definition of “effort”: it’s the felt experience of expending energy beyond what an activity requires, like tensing your brow when you try to understand something, or the excess tension in your hand when you hold your phone[1].&lt;/p&gt;
    &lt;p&gt;Using this definition, it’s clear that the appropriate amount of effort for any activity is zero.&lt;/p&gt;
    &lt;p&gt;This idea is where the concept of non-doing can trip people up, because it doesn’t mean no action. It means no effort, even though the amount of energy required could be large. Or, to borrow from Daoist wisdom:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Nature does not hurry, yet everything is accomplished." — Lao Tzu&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Nature is an enormous flow of energy, yet nature makes no effort. Everything nature does is perfectly well-suited to what it does, and it cannot be otherwise. This is why non-doing comes with a felt experience of effortlessness, when it seems like everything is working exactly the way it’s supposed to be.&lt;/p&gt;
    &lt;p&gt;Consider this quote from Katie Ledecky who, with 14 Olympic medals, is described as “the most decorated female swimmer in history”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I felt so relaxed. It just felt very easy, and that's why it surprised me that I had broken my world record.” — Katie Ledecky&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Not only that, but trying too hard can reduce performance. Here’s marathoner Ryan Hall:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“… you don't get your best performances by trying harder. When you see the guy who wins the race, he usually jogs out of it waving to the crowd, feeling good. The people who look the worst come in after the top guy.”[2] – Ryan Hall&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So why is it so common to effort when it both feels harder and reduces performance?&lt;/p&gt;
    &lt;p&gt;For one thing, there are all kinds of societal scripts in the modern age that push us in that direction. All those hustle bros captured by Total Work push their grindset worldview, recapitulating the Protestant work ethic for new audiences. The influence of these cultural waters on our psychophysical wiring can’t be overstated.&lt;/p&gt;
    &lt;p&gt;These scripts team up with one of the core principles of Alexander Technique: Faulty Sensory Appreciation. When you try so hard all the time, that level of effort feels familiar and you stop noticing it. Put another way, years of overdoing mis-calibrate your senses so effort feels right and ease feels wrong. If you follow your feelings, you are guided back to that same old familiar where you’re trying too hard without even realising it.&lt;/p&gt;
    &lt;p&gt;By the way, this phenomenon happens all the time in many other domains, and can be the cause of much trouble.&lt;/p&gt;
    &lt;p&gt;What all this means is that when you pull back the effort below your familiar baseline, it can feel unfamiliar, like you’re not trying hard enough, and those societal scripts I mentioned before can make this experience hard to stay in, even if you’re now closer to the appropriate amount of energy needed.&lt;/p&gt;
    &lt;p&gt;The way out of this is to experiment with feeling the unfamiliarity of trying less hard and seeing what it’s like. In Kristijan’s case, he played with this for long enough that his sensory perception updated to reflect what was going on more accurately, and he was able to feel that he had been using too much tension before.&lt;/p&gt;
    &lt;p&gt;So I invite you to go about your day and practice dropping the effort. See how weird it feels, but notice how the activity is still getting done. See what it’s like to drop the energy too low, where you might become lethargic or your performance drops. Notice the sweet spot as a surprising experience of ease and a kind of elegance: the less you grip, the smoother and more precise the movement.&lt;/p&gt;
    &lt;p&gt;Happy experimenting!&lt;/p&gt;
    &lt;p&gt;If you get hung up on this definition, just substitute it for something like “over-efforting” or “trying too hard”, as the underlying phenomenon is the same regardless of what you call it. ↩︎&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://expandingawareness.org/blog/the-appropriate-amount-of-effort-is-zero/"/><published>2025-12-15T20:09:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46280465</id><title>A kernel bug froze my machine: Debugging an async-profiler deadlock</title><updated>2025-12-16T10:13:18.308276+00:00</updated><content>&lt;doc fingerprint="de10905790230f2a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How a Kernel Bug Froze My Machine: Debugging an Async-profiler Deadlock&lt;/head&gt;
    &lt;p&gt;I've been a Linux user since the late 90s, starting with Slackware on an underpowered AMD K6. Over the years I've hit plenty of bugs, but the last decade has been remarkably stable - until a kernel bug started freezing my machine whenever I used async-profiler.&lt;/p&gt;
    &lt;p&gt;I'm not a kernel developer, but I found myself poking around kernel source code to understand the problem better and figure out what was going on under the hood.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem&lt;/head&gt;
    &lt;p&gt;I was about to start an investigation of latency spikes in QuestDB reported by a user. To do that, I wanted to use the async-profiler to capture CPU heatmaps.&lt;/p&gt;
    &lt;p&gt;However, when I tried to attach the profiler, my machine froze completely. It did not respond to any keys, it was impossible to switch to a terminal, it did not respond to SSH. The only way to recover was to hard reboot it. I tried to start QuestDB with the profiler already configured to start at launch - the same result, a frozen machine almost immediately after the launch.&lt;/p&gt;
    &lt;p&gt;I thought that was weird, this had not happened to me in years. It was already late in the evening, I felt tired anyway so I decided to call it a day. There was a tiny chance I was hallucinating and the problem would go away by itself overnight. A drowning man will clutch at a straw after all.&lt;/p&gt;
    &lt;p&gt;The next day, I tried to attach the profiler again - same result, frozen machine. Async-profiler integration in QuestDB is a relatively new feature, so I thought there might be a bug in the integration code, perhaps a regression in the recent QuestDB release. So I built an older QuestDB version: The same result, frozen machine. This was puzzling - I positively knew this worked before. How do I know? Because I worked on the integration code not too long ago, and I tested the hell out of it.&lt;/p&gt;
    &lt;p&gt;This was a strong hint that the problem was not in QuestDB, but rather in the environment. I've gotten lazy since my Slackware days and I have been using Ubuntu for years now and I realized that I had recently updated Ubuntu to the latest version: 25.10. Could it be that the problem is in the new Ubuntu version?&lt;/p&gt;
    &lt;p&gt;At this point I started Googling around and I found a report created by a fellow performance aficionado, Francesco Nigro, describing exactly the same problem: machine freeze when using async-profiler. This was the final confirmation I was not hallucinating! Except Francesco is using Fedora, not Ubuntu. However, his Fedora uses the same kernel version as my Ubuntu: 6.17. I booted a machine with an older Ubuntu, started QuestDB and attached the profiler and it worked like a charm. This was yet another indication that the problem was in the system, possibly even in the kernel. This allowed me to narrow down my Google keywords and find this kernel patch which talks about the very same problem!&lt;/p&gt;
    &lt;p&gt;I found it quite interesting: A kernel bug triggered by async-profiler causing machine freezes on recent mainstream distributions. After some poking I found a workaround: Start the profiler with &lt;code&gt;-e ctimer&lt;/code&gt; option to avoid using the problematic kernel feature. I tried the workaround and indeed, with this option, the profiler worked fine and my machine did not freeze.&lt;/p&gt;
    &lt;p&gt;Normally I'd move on, but I was curious. What exactly is going on under the hood? Why is it freezing? What is this &lt;code&gt;ctimer&lt;/code&gt; thing? What exactly is the bug and how does the patch work? So I decided to dig deeper.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Async-profiler Works&lt;/head&gt;
    &lt;p&gt;Async-profiler is a sampling profiler. It periodically interrupts threads in the profiled application and collects their stack traces. The collected stack traces are then aggregated and visualized in various ways (flame graphs are one of the most popular visualizations). It has multiple ways to interrupt the profiled application, the most common one is using &lt;code&gt;perf_events&lt;/code&gt; kernel feature. This is how it works by default on Linux
assuming kernel paranoia settings allow it.&lt;/p&gt;
    &lt;head rend="h3"&gt;perf_events Under the Hood&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;perf_events&lt;/code&gt; subsystem is a powerful Linux kernel feature for performance monitoring. For CPU profiling, async-profiler uses
a software event called &lt;code&gt;cpu-clock&lt;/code&gt;, which is driven by high-resolution timers (hrtimers) in the kernel.&lt;/p&gt;
    &lt;p&gt;Here's the sequence of events during profiling:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Setup: For each thread in the profiled application, async-profiler opens a &lt;code&gt;perf_event&lt;/code&gt;file descriptor configured to generate a signal after a specified interval of CPU time (e.g., 10ms).&lt;/item&gt;
      &lt;item&gt;Arming the event: The profiler calls &lt;code&gt;ioctl(fd, PERF_EVENT_IOC_REFRESH, 1)&lt;/code&gt;to arm the event for exactly one sample. This is a one-shot mechanism, combined with the&lt;code&gt;RESET&lt;/code&gt;at the end of the handler. The goal is to measure application CPU time only and exclude the signal's handler own overhead.&lt;/item&gt;
      &lt;item&gt;Timer fires: When the configured CPU time elapses, the kernel's hrtimer fires and delivers a signal to the target thread.&lt;/item&gt;
      &lt;item&gt;Signal handler: Async-profiler's signal handler captures the stack trace and records the sample. At the end of the handler, it resets the counter and re-arms the event for the next sample:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;ioctl(fd, PERF_EVENT_IOC_RESET, 0); // Clear the counterioctl(fd, PERF_EVENT_IOC_REFRESH, 1); // Arm for exactly 1 more sample&lt;/quote&gt;
    &lt;p&gt;This cycle repeats for the duration of the profiling session, creating a stream of stack trace samples that are later aggregated into flame graphs or heatmaps.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Kernel Bug&lt;/head&gt;
    &lt;p&gt;The kernel bug that caused my machine to freeze was introduced by commit 18dbcbfabfff ("perf: Fix the POLL_HUP delivery breakage"). Ironically, this commit was fixing a different bug, but it introduced a deadlock in the cpu-clock event handling.&lt;/p&gt;
    &lt;p&gt;Here's what happens in the buggy kernel when the &lt;code&gt;PERF_EVENT_IOC_REFRESH(1)&lt;/code&gt; counter reaches zero:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;hrtimer fires for cpu-clock event - &lt;code&gt;perf_swevent_hrtimer()&lt;/code&gt;is called (inside hrtimer interrupt context)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;perf_swevent_hrtimer()&lt;/code&gt;calls&lt;code&gt;__perf_event_overflow()&lt;/code&gt;- this processes the counter overflow&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;__perf_event_overflow()&lt;/code&gt;decides to stop the event (counter reached 0 after&lt;code&gt;PERF_EVENT_IOC_REFRESH(1)&lt;/code&gt;) - calls&lt;code&gt;cpu_clock_event_stop()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;cpu_clock_event_stop()&lt;/code&gt;calls&lt;code&gt;perf_swevent_cancel_hrtimer()&lt;/code&gt;- this calls&lt;code&gt;hrtimer_cancel()&lt;/code&gt;to cancel the timer&lt;/item&gt;
      &lt;item&gt;DEADLOCK: &lt;code&gt;hrtimer_cancel()&lt;/code&gt;waits for the hrtimer callback to complete - but we ARE inside the hrtimer callback! The system hangs forever waiting for itself&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The function &lt;code&gt;hrtimer_cancel()&lt;/code&gt; is a blocking call - it spins waiting for any active callback to finish.&lt;/p&gt;
    &lt;quote&gt;int hrtimer_cancel(struct hrtimer *timer){int ret;do {ret = hrtimer_try_to_cancel(timer);if (ret &amp;lt; 0)hrtimer_cancel_wait_running(timer);} while (ret &amp;lt; 0);return ret;}&lt;/quote&gt;
    &lt;p&gt;When called from inside that same callback, it waits forever. Since this happens in interrupt context with interrupts disabled on the CPU, that CPU becomes completely unresponsive. When this happens on multiple CPUs (which it does, since each thread has its own &lt;code&gt;perf_event&lt;/code&gt;), the entire system freezes.&lt;/p&gt;
    &lt;head&gt;Click to see the deadlock visualized&lt;/head&gt;
    &lt;head rend="h2"&gt;The Fix&lt;/head&gt;
    &lt;p&gt;The kernel patch fixes this deadlock with two changes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Replace &lt;code&gt;hrtimer_cancel()&lt;/code&gt;with&lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;- hrtimer_cancel(&amp;amp;hwc-&amp;gt;hrtimer);+ hrtimer_try_to_cancel(&amp;amp;hwc-&amp;gt;hrtimer);&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt; is non-blocking - it returns immediately with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;0&lt;/code&gt;if the timer was not active&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;1&lt;/code&gt;if the timer was successfully cancelled&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-1&lt;/code&gt;if the timer callback is currently running&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike &lt;code&gt;hrtimer_cancel()&lt;/code&gt;, it doesn't spin waiting for the callback to finish. So when called from within the callback itself, it simply returns &lt;code&gt;-1&lt;/code&gt; and continues.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use &lt;code&gt;PERF_HES_STOPPED&lt;/code&gt;flag as a deferred stop signal&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The stop function now sets a flag:&lt;/p&gt;
    &lt;quote&gt;static void cpu_clock_event_stop(struct perf_event *event, int flags){+ event-&amp;gt;hw.state = PERF_HES_STOPPED;perf_swevent_cancel_hrtimer(event);...}&lt;/quote&gt;
    &lt;p&gt;And the hrtimer callback checks this flag:&lt;/p&gt;
    &lt;quote&gt;static enum hrtimer_restart perf_swevent_hrtimer(struct hrtimer *hrtimer){- if (event-&amp;gt;state != PERF_EVENT_STATE_ACTIVE)+ if (event-&amp;gt;state != PERF_EVENT_STATE_ACTIVE ||+ event-&amp;gt;hw.state &amp;amp; PERF_HES_STOPPED)return HRTIMER_NORESTART;&lt;/quote&gt;
    &lt;head rend="h3"&gt;How It Works Together&lt;/head&gt;
    &lt;p&gt;When &lt;code&gt;cpu_clock_event_stop()&lt;/code&gt; is called from within the hrtimer callback:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;PERF_HES_STOPPED&lt;/code&gt;flag is set&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt;returns&lt;code&gt;-1&lt;/code&gt;(callback running) - but doesn't block&lt;/item&gt;
      &lt;item&gt;Execution returns up the call stack back to &lt;code&gt;perf_swevent_hrtimer()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;perf_swevent_hrtimer()&lt;/code&gt;completes and returns&lt;code&gt;HRTIMER_NORESTART&lt;/code&gt;(because&lt;code&gt;__perf_event_overflow()&lt;/code&gt;returned&lt;code&gt;1&lt;/code&gt;, indicating the event should stop)&lt;/item&gt;
      &lt;item&gt;The hrtimer subsystem sees &lt;code&gt;HRTIMER_NORESTART&lt;/code&gt;and doesn't reschedule the timer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When &lt;code&gt;cpu_clock_event_stop()&lt;/code&gt; is called from outside the callback (normal case):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;PERF_HES_STOPPED&lt;/code&gt;flag is set&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt;returns&lt;code&gt;0&lt;/code&gt;or&lt;code&gt;1&lt;/code&gt;- timer is cancelled immediately&lt;/item&gt;
      &lt;item&gt;If by chance the callback fires before cancellation completes, it sees &lt;code&gt;PERF_HES_STOPPED&lt;/code&gt;and returns&lt;code&gt;HRTIMER_NORESTART&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;PERF_HES_STOPPED&lt;/code&gt; flag acts as a safety net to make sure the timer stops regardless of the race between setting the flag and the timer firing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Debugging a kernel&lt;/head&gt;
    &lt;p&gt;The explanation above is my understanding of the kernel bug and the fix based on reading the kernel source code. I am a hacker, I like to tinker. A theoretical understanding is one thing, but I wanted to see it in action. But how do you even debug a kernel? I'm not a kernel developer, but I decided to try. Here is how I did it.&lt;/p&gt;
    &lt;p&gt;My intuition was to use QEMU since it allows one to emulate or virtualize a full machine. QEMU also has a built-in GDB server that allows you to connect GDB to the emulated machine.&lt;/p&gt;
    &lt;head rend="h3"&gt;Setting up QEMU with Ubuntu&lt;/head&gt;
    &lt;p&gt;I downloaded an Ubuntu 25.10 ISO image and created a new empty VM disk image:&lt;/p&gt;
    &lt;quote&gt;$ qemu-img create -f qcow2 ubuntu-25.10.qcow2 20G&lt;/quote&gt;
    &lt;p&gt;Then I launched QEMU to install Ubuntu:&lt;/p&gt;
    &lt;quote&gt;$ qemu-system-x86_64 \-enable-kvm \-m 4096 \-smp 4 \-drive file=ubuntu-25.10.qcow2,if=virtio \-cdrom ubuntu-25.10-desktop-amd64.iso \-boot d \-vga qxl&lt;/quote&gt;
    &lt;p&gt;The second command boots the VM from the ISO image and allows me to install Ubuntu on the VM disk image. I went through the installation process as usual. I probably could have used a server edition or a prebuilt image, but at this point I was already in unknown territory, so I wanted to make other things as simple as possible.&lt;/p&gt;
    &lt;p&gt;Once the installation was complete, I rebooted the VM:&lt;/p&gt;
    &lt;quote&gt;$ qemu-system-x86_64 \-enable-kvm \-m 4096 \-smp 4 \-drive file=ubuntu-25.10.qcow2,if=virtio \-netdev user,id=net0,hostfwd=tcp::9000-:9000 \-device virtio-net-pci,netdev=net0 \-monitor tcp:127.0.0.1:55555,server,nowait \-s&lt;/quote&gt;
    &lt;p&gt;and downloaded, unpacked and started QuestDB:&lt;/p&gt;
    &lt;quote&gt;$ curl -L https://github.com/questdb/questdb/releases/download/9.2.2/questdb-9.2.2-rt-linux-x86-64.tar.gz -o questdb.tar.gz$ tar -xzvf questdb.tar.gz$ cd questdb-9.2.2-rt-linux-x86-64$ ./bin/questdb start&lt;/quote&gt;
    &lt;p&gt;This was meant to validate that QuestDB works in the VM at all. Firefox was already installed in the Ubuntu desktop edition, so I just opened &lt;code&gt;http://localhost:9000&lt;/code&gt; in Firefox and verified QuestDB web console was up and running.&lt;/p&gt;
    &lt;p&gt;The next step was to stop QuestDB and start it with a profiler attached:&lt;/p&gt;
    &lt;quote&gt;$ ./bin/questdb stop$ ./bin/questdb start -p&lt;/quote&gt;
    &lt;p&gt;At this point, I expected the virtual machine to freeze. However, it didn't. It was responsive as if nothing bad had happened. That was a bummer. I wanted to see the deadlock in action! I thought that perhaps QEMU is in a way shielding the virtual machine from the bug. But then I realized that the default Ubuntu uses paranoia settings that prevent &lt;code&gt;perf_events&lt;/code&gt; from working properly and async-profiler falls back to
using &lt;code&gt;ctimer&lt;/code&gt; when &lt;code&gt;perf_events&lt;/code&gt; are restricted. The kernel bug specifically lives in the &lt;code&gt;perf_events&lt;/code&gt; hrtimer
code path, so we must force async-profiler to use that path to trigger the bug.&lt;/p&gt;
    &lt;p&gt;To fix this, I changed the paranoia settings:&lt;/p&gt;
    &lt;quote&gt;$ echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid&lt;/quote&gt;
    &lt;p&gt;After this, I restarted QuestDB with the profiler again:&lt;/p&gt;
    &lt;quote&gt;$ ./bin/questdb stop$ ./bin/questdb start -p&lt;/quote&gt;
    &lt;p&gt;And this time, the virtual machine froze as expected! Success! I was able to reproduce the problem in QEMU!&lt;/p&gt;
    &lt;head rend="h3"&gt;Attaching GDB to QEMU&lt;/head&gt;
    &lt;p&gt;Now that I was able to reproduce the problem in QEMU, I wanted to attach GDB to the emulated machine to see the deadlock in action.&lt;/p&gt;
    &lt;p&gt;Let's start &lt;code&gt;GDB&lt;/code&gt; on the host machine and connect it to QEMU's built-in GDB server:&lt;/p&gt;
    &lt;quote&gt;$ gdbGNU gdb (Ubuntu 16.3-1ubuntu2) 16.3[...](gdb) target remote :1234Remote debugging using :1234warning: No executable has been specified and target does not supportdetermining executable automatically. Try using the "file" command.0xffffffff82739398 in ?? ()(gdb) info threadsId Target Id Frame* 1 Thread 1.1 (CPU#0 [running]) 0xffffffff82739398 in ?? ()2 Thread 1.2 (CPU#1 [running]) 0xffffffff82739398 in ?? ()3 Thread 1.3 (CPU#2 [running]) 0xffffffff827614d3 in ?? ()4 Thread 1.4 (CPU#3 [running]) 0xffffffff82739398 in ?? ()(gdb) thread apply all bt&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Side note: We just casually attached a debugger to a live kernel! How cool is that?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can see 4 threads corresponding to the 4 CPUs in the VM. The &lt;code&gt;bt&lt;/code&gt; command shows the stack traces of all threads, but there is not much useful information since we don't have the kernel symbols loaded in GDB.
Let's fix this. I am lazy again and take advantage of running exactly the same kernel version as the host machine so I can use the host's kernel image and symbol files.&lt;/p&gt;
    &lt;p&gt;On the host machine, we need to add repositories with debug symbols and install the debug symbols for the running kernel:&lt;/p&gt;
    &lt;quote&gt;echo "deb http://ddebs.ubuntu.com questing main restricted universe multiverse" | sudo tee /etc/apt/sources.list.d/ddebs.listecho "deb http://ddebs.ubuntu.com questing-updates main restricted universe multiverse" | sudo tee -a /etc/apt/sources.list.d/ddebs.listecho "deb http://ddebs.ubuntu.com questing-proposed main restricted universe multiverse" | sudo tee -a /etc/apt/sources.list.d/ddebs.listsudo apt install ubuntu-dbgsym-keyringsudo apt updatesudo apt install linux-image-$(uname -r)-dbgsym&lt;/quote&gt;
    &lt;p&gt;With the debug symbols installed, I started GDB again and loaded the kernel image and symbols:&lt;/p&gt;
    &lt;quote&gt;$ gdb /usr/lib/debug/boot/vmlinux-$(uname -r)GNU gdb (Ubuntu 16.3-1ubuntu2) 16.3[...]gdb) target remote :1234Remote debugging using :12340xffffffff9e9614d3 in ?? ()[...](gdb) info threadsId Target Id Frame* 1 Thread 1.1 (CPU#0 [running]) 0xffffffff9e9614d3 in ?? ()2 Thread 1.2 (CPU#1 [running]) 0xffffffff9e939398 in ?? ()3 Thread 1.3 (CPU#2 [running]) 0xffffffff9e9614d3 in ?? ()4 Thread 1.4 (CPU#3 [running]) 0xffffffff9e9614d3 in ?? ()(gdb) quit&lt;/quote&gt;
    &lt;p&gt;and symbols were still NOT resolved! I had to capitulate and ask a LLM for help. After a bit of brainstorming, we realized that the kernel is compiled with KASLR enabled, so the kernel is loaded at a random address at each boot. The simplest way to fix this is to disable KASLR, I could not care less about security in my test VM. To disable KASLR, I edited the GRUB configuration, added the &lt;code&gt;nokaslr&lt;/code&gt; parameter, updated GRUB and rebooted the VM:&lt;/p&gt;
    &lt;quote&gt;$ vim /etc/default/grub# Add nokaslr to the GRUB_CMDLINE_LINUX_DEFAULT lineGRUB_CMDLINE_LINUX_DEFAULT="quiet splash nokaslr"$ sudo update-grub$ sudo reboot&lt;/quote&gt;
    &lt;p&gt;Then I set the paranoia settings again, started QuestDB with the profiler and attached GDB again. This time, the symbols were resolved correctly!&lt;/p&gt;
    &lt;quote&gt;$ gdb /usr/lib/debug/boot/vmlinux-$(uname -r)GNU gdb (Ubuntu 16.3-1ubuntu2) 16.3[...](gdb) target remote :1234[...](gdb) info threadsId Target Id Frame* 1 Thread 1.1 (CPU#0 [running]) csd_lock_wait (csd=0xffff88813bd3a460) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:3512 Thread 1.2 (CPU#1 [running]) csd_lock_wait (csd=0xffff88813bd3b520) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:3513 Thread 1.3 (CPU#2 [running]) hrtimer_try_to_cancel (timer=0xffff88802343d028) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:13594 Thread 1.4 (CPU#3 [running]) hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359&lt;/quote&gt;
    &lt;p&gt;This looks much better! We can see that the first 2 threads are stuck in &lt;code&gt;csd_lock_wait()&lt;/code&gt; function, presumably waiting for locks held by the other CPUs
and threads 3 and 4 are in &lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The threads 3 and 4 are the interesting ones since they execute a function related to the kernel bug we are investigating. Let's switch to thread 4 and see its stack trace:&lt;/p&gt;
    &lt;quote&gt;(gdb) thread 4[Switching to thread 4 (Thread 1.4)]#0 hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:13591359 in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c(gdb) bt#0 hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359#1 hrtimer_cancel (timer=timer@entry=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1488#2 0xffffffff81700605 in perf_swevent_cancel_hrtimer (event=&amp;lt;optimized out&amp;gt;) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11818#3 perf_swevent_cancel_hrtimer (event=0xffff888023439f80) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11805#4 cpu_clock_event_stop (event=0xffff888023439f80, flags=0) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11868#5 0xffffffff81715488 in __perf_event_overflow (event=event@entry=0xffff888023439f80, throttle=throttle@entry=1, data=data@entry=0xffffc90002cd7cc0, regs=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:10338#6 0xffffffff81716eaf in perf_swevent_hrtimer (hrtimer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/events/core.c:11774#7 0xffffffff81538a03 in __run_hrtimer (cpu_base=&amp;lt;optimized out&amp;gt;, base=&amp;lt;optimized out&amp;gt;, timer=0xffff88802343a0e8, now=0xffffc90002cd7e58, flags=&amp;lt;optimized out&amp;gt;) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1761#8 __hrtimer_run_queues (cpu_base=cpu_base@entry=0xffff88813bda1400, now=now@entry=48514890563, flags=flags@entry=2, active_mask=active_mask@entry=15) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1825#9 0xffffffff8153995d in hrtimer_interrupt (dev=&amp;lt;optimized out&amp;gt;) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1887#10 0xffffffff813c4ac8 in local_apic_timer_interrupt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1039#11 __sysvec_apic_timer_interrupt (regs=regs@entry=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1056#12 0xffffffff82621724 in instr_sysvec_apic_timer_interrupt (regs=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1050#13 sysvec_apic_timer_interrupt (regs=0xffffc90002cd7f48) at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/apic/apic.c:1050#14 0xffffffff81000f0b in asm_sysvec_apic_timer_interrupt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/include/asm/idtentry.h:574#15 0x00007b478171db80 in ?? ()#16 0x0000000000000001 in ?? ()#17 0x0000000000000000 in ?? ()&lt;/quote&gt;
    &lt;p&gt;We can see the exact sequence of function calls leading to the deadlock: &lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt; called from &lt;code&gt;cpu_clock_event_stop()&lt;/code&gt;, called from &lt;code&gt;__perf_event_overflow()&lt;/code&gt;, called from &lt;code&gt;perf_swevent_hrtimer()&lt;/code&gt;.
This matches our understanding of the bug perfectly! This is the infinite loop in &lt;code&gt;hrtimer_cancel()&lt;/code&gt; that causes the
deadlock.&lt;/p&gt;
    &lt;head rend="h2"&gt;Forensics and Playing God&lt;/head&gt;
    &lt;p&gt;Okay, I have to admit that seeing a kernel stack trace is already somewhat satisfying, but we have a live (well, half-dead) kernel under a debugger. Let's have some fun. I want to touch the deadlock and understand why it took down the whole machine, and see if we can perform a miracle and bring it back to life.&lt;/p&gt;
    &lt;head rend="h4"&gt;Confirming the suspect&lt;/head&gt;
    &lt;p&gt;We know &lt;code&gt;hrtimer_cancel&lt;/code&gt; is waiting for a callback to finish. But which callback? The stack trace says &lt;code&gt;perf_swevent_cancel_hrtimer&lt;/code&gt;,
but let's verify the hrtimer struct in memory actually points to the function we blame.&lt;/p&gt;
    &lt;p&gt;I switched to the stuck thread (Thread 4 in my case) and looked at frame #0:&lt;/p&gt;
    &lt;quote&gt;(gdb) thread 4[Switching to thread 4 (Thread 1.4)]#0 hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:13591359 in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c(gdb) frame 0#0 hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:13591359 in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c(gdb) print *timer$1 = {node = {node = {__rb_parent_color = 18446612682661667048, rb_right = 0x0, rb_left = 0x0}, expires = 48514879474}, _softexpires = 48514879474, function = 0xffffffff81716dd0 &amp;lt;perf_swevent_hrtimer&amp;gt;, base = 0xffff88813bda1440, state = 0 '\000', is_rel = 0 '\000', is_soft = 0 '\000', is_hard = 1 '\001'}&lt;/quote&gt;
    &lt;p&gt;Let me explain these GDB commands: &lt;code&gt;frame 0&lt;/code&gt; selects the innermost stack frame - the function currently executing.
In a backtrace, frame 0 is the current function, frame 1 is its caller, frame 2 is the caller's caller, and so on.
By selecting frame 0, I can inspect local variables and parameters in &lt;code&gt;hrtimer_try_to_cancel()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;print *timer&lt;/code&gt; command dereferences the &lt;code&gt;timer&lt;/code&gt; pointer and displays the contents of the &lt;code&gt;struct hrtimer&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;struct hrtimer {struct timerqueue_node node;ktime_t _softexpires;enum hrtimer_restart (*function)(struct hrtimer *);struct hrtimer_clock_base *base;u8 state;u8 is_rel;u8 is_soft;u8 is_hard;};&lt;/quote&gt;
    &lt;p&gt;The key field here is &lt;code&gt;function&lt;/code&gt; - a pointer to a callback function that takes a &lt;code&gt;struct hrtimer *&lt;/code&gt; and returns
&lt;code&gt;enum hrtimer_restart&lt;/code&gt;. This callback is invoked when the timer fires. GDB shows it points to &lt;code&gt;0xffffffff81716dd0&lt;/code&gt; and helpfully resolves this address to &lt;code&gt;perf_swevent_hrtimer&lt;/code&gt;. Since we're currently inside &lt;code&gt;perf_swevent_hrtimer&lt;/code&gt; (look at frame #6 in our backtrace above), this confirms the self-deadlock: the timer is trying to cancel itself while its own callback is still running!&lt;/p&gt;
    &lt;head rend="h4"&gt;The Mystery of the "Other" CPUs&lt;/head&gt;
    &lt;p&gt;One question remained: If CPUs 3 and 4 are deadlocked in a loop, why did the entire machine freeze? Why couldn't I just SSH in and kill the process? The answer lies in those other threads we saw earlier, stuck in &lt;code&gt;csd_lock_wait&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;(gdb) thread 1[Switching to thread 1 (Thread 1.1)]#0 csd_lock_wait (csd=0xffff88813bd3a460) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351warning: 351 /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c: No such file or directory&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;CSD&lt;/code&gt; stands for Call Function Single Data. In Linux, when one CPU wants another CPU to do something (like flush a TLB
or stop a perf_event), it sends an IPI (Inter-Processor Interrupt).
If the target CPU is busy with interrupts disabled (which is exactly the case for our deadlocked CPUs 3 and 4), it never responds.&lt;/p&gt;
    &lt;p&gt;The sender (CPU 0) sits there spinning, waiting for the other CPU to say "Done!". Eventually, all CPUs end up waiting for the stuck CPUs and the entire system grinds to a halt.&lt;/p&gt;
    &lt;head rend="h4"&gt;Performing a Kernel Resurrection&lt;/head&gt;
    &lt;p&gt;This is the part where the real black magic starts. We know the kernel is stuck in this loop in &lt;code&gt;hrtimer_cancel&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;do {ret = hrtimer_try_to_cancel(timer);} while (ret &amp;lt; 0);&lt;/quote&gt;
    &lt;p&gt;As long as &lt;code&gt;hrtimer_try_to_cancel&lt;/code&gt; returns &lt;code&gt;-1&lt;/code&gt; (which it does, because the callback is running), the loop continues
forever.&lt;/p&gt;
    &lt;p&gt;But we have GDB. We can change reality.&lt;/p&gt;
    &lt;p&gt;If we force the function to return &lt;code&gt;0&lt;/code&gt; (meaning "timer not active"), the loop should break, &lt;code&gt;cpu_clock_event_stop&lt;/code&gt;
should finish, and the kernel should unfreeze. It might crash 1 millisecond later because we left the timer in an
inconsistent state, but perhaps it's worth trying.&lt;/p&gt;
    &lt;p&gt;First, let's double-check we are in the innermost frame, inside &lt;code&gt;hrtimer_try_to_cancel&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;(gdb) thread 4[Switching to thread 4 (Thread 1.4)]#0 hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359warning: 1359 /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c: No such file or directory(gdb) frame 0#0 hrtimer_try_to_cancel (timer=0xffff88802343a0e8) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:13591359 in /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c&lt;/quote&gt;
    &lt;p&gt;Use the GDB &lt;code&gt;finish&lt;/code&gt; command to let the function run to completion and pause right when it returns to the caller:&lt;/p&gt;
    &lt;quote&gt;(gdb) finish&lt;/quote&gt;
    &lt;p&gt;We are now sitting at line 1490, right at the check &lt;code&gt;if (ret &amp;lt; 0)&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;int hrtimer_cancel(struct hrtimer *timer){int ret;do {ret = hrtimer_try_to_cancel(timer);if (ret &amp;lt; 0) // &amp;lt;-- we are herehrtimer_cancel_wait_running(timer);} while (ret &amp;lt; 0);return ret;}&lt;/quote&gt;
    &lt;p&gt;On x86_64, integer return values are passed in the &lt;code&gt;%rax&lt;/code&gt; register.
Since &lt;code&gt;hrtimer_try_to_cancel&lt;/code&gt; returns an &lt;code&gt;int&lt;/code&gt; (32-bit), we can use &lt;code&gt;$eax&lt;/code&gt; (the lower 32 bits of &lt;code&gt;%rax&lt;/code&gt;):&lt;/p&gt;
    &lt;quote&gt;(gdb) print $eax$2 = -1&lt;/quote&gt;
    &lt;p&gt;Exactly as expected. &lt;code&gt;-1&lt;/code&gt; means the timer callback is running, so the loop will continue.
But since the CPU is paused, we can overwrite this value. We can lie to the kernel and tell it the timer was
successfully cancelled (return code 1) or inactive (return code 0). I chose 0.&lt;/p&gt;
    &lt;quote&gt;(gdb) set $eax = 0(gdb) print $eax$3 = 0&lt;/quote&gt;
    &lt;p&gt;I crossed my fingers and unpaused the VM:&lt;/p&gt;
    &lt;quote&gt;(gdb) continueContinuing.&lt;/quote&gt;
    &lt;p&gt;And it did nothing. The VM was still frozen. Let's see what is going on:&lt;/p&gt;
    &lt;quote&gt;(gdb) info threadsId Target Id Frame1 Thread 1.1 (CPU#0 [running]) csd_lock_wait (csd=0xffff88813bd3a460) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:3512 Thread 1.2 (CPU#1 [running]) csd_lock_wait (csd=0xffff88813bd3b520) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:3513 Thread 1.3 (CPU#2 [running]) hrtimer_try_to_cancel (timer=0xffff88802343d028) at /build/linux-8YMEfB/linux-6.17.0/kernel/time/hrtimer.c:1359* 4 Thread 1.4 (CPU#3 [running]) csd_lock_wait (csd=0xffff88813bd3b560) at /build/linux-8YMEfB/linux-6.17.0/kernel/smp.c:351&lt;/quote&gt;
    &lt;p&gt;Now, thread 4 is also stuck in &lt;code&gt;csd_lock_wait&lt;/code&gt;, just like threads 1 and 2. We managed to escape from the infinite
loop in thread 4, but thread 3 is still stuck in &lt;code&gt;hrtimer_try_to_cancel&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We could try the same trick on thread 3, but would this be enough to unfreeze the entire system? For starters, we tricked the kernel into thinking the timer was inactive, but in reality it is still active. This is very thin ice to skate on - we might have just created more problems for ourselves. And more importantly, even if the kernel could escape the deadlock, the profiler would immediately try to re-arm the timer again, leading us back into the same deadlock.&lt;/p&gt;
    &lt;p&gt;So I decided to give up on the resurrection attempt. The kernel was stuck, but at least I understood the problem now and I was pretty happy with my newly acquired kernel debugging skills.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;While I couldn't perform a miracle and resurrect the frozen kernel, I walked away with a much deeper understanding of the machinery behind Linux &lt;code&gt;perf_events&lt;/code&gt; and hrtimers. I learned how to set up QEMU for kernel debugging, how to attach GDB to a live kernel, and how to inspect kernel data structures in memory.&lt;/p&gt;
    &lt;p&gt;For QuestDB users, the takeaway is simple: if you are on a kernel version 6.17, use the &lt;code&gt;-e ctimer&lt;/code&gt; flag when
profiling. It bypasses the buggy &lt;code&gt;perf_events&lt;/code&gt; hrtimer path entirely. Or just wait for either the kernel fix to land
in your distro or the next QuestDB release, which will include an
async-profiler version that works around this issue.&lt;/p&gt;
    &lt;p&gt;As for me, I’m going back to my code. The next time my machine freezes, I might just reboot it like a normal person. But where is the fun in that?&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum: The Second Resurrection Attempt&lt;/head&gt;
    &lt;p&gt;After writing this post, I kept thinking about that failed resurrection attempt. We got so close: We broke one CPU out of the deadlock, but the other was still stuck. I should have tried harder! So I started QEMU again, reproduced the deadlock, and this time came with a plan: use GDB to force kernel to kill the QuestDB Java process, so the profiler can't re-arm the timer.&lt;/p&gt;
    &lt;p&gt;First, I needed to find the Java process. The &lt;code&gt;perf_event&lt;/code&gt; structure has an owner field pointing to the task that created it:&lt;/p&gt;
    &lt;quote&gt;(gdb) print event-&amp;gt;owner$1 = (struct task_struct *) 0xffff88810b2ed100(gdb) print ((struct task_struct *)0xffff88810b2ed100)-&amp;gt;comm$2 = "java"(gdb) print ((struct task_struct *)0xffff88810b2ed100)-&amp;gt;pid$3 = 4488&lt;/quote&gt;
    &lt;p&gt;Great, we found the Java process with PID 4488. Now, how do you kill a process when the kernel is deadlocked and can't process signals? You store the signal directly in memory. &lt;code&gt;SIGKILL&lt;/code&gt; is signal 9, which means bit 8 in the signal bitmask:&lt;/p&gt;
    &lt;quote&gt;(gdb) set ((struct task_struct *)0xffff88810b2ed100)-&amp;gt;signal-&amp;gt;shared_pending.signal.sig[0] = 0x100&lt;/quote&gt;
    &lt;p&gt;With the pending kill signal in place, I broke the deadlock loop as before. The system hit another deadlock - a different CPU was now stuck waiting for a spinlock. The lock value showed it was held:&lt;/p&gt;
    &lt;quote&gt;(gdb) print *((unsigned int *)0xffff88813bda1400)$4 = 1&lt;/quote&gt;
    &lt;p&gt;I forcibly released the lock (what could possibly go wrong?):&lt;/p&gt;
    &lt;quote&gt;(gdb) set *((unsigned int *)0xffff88813bda1400) = 0&lt;/quote&gt;
    &lt;p&gt;Then broke another &lt;code&gt;hrtimer&lt;/code&gt; loop on a different CPU. It was like playing whack-a-mole with deadlocks - each Java thread had its own &lt;code&gt;perf_event&lt;/code&gt;, and they were all hitting the same bug.&lt;/p&gt;
    &lt;p&gt;After a few rounds of this, I ran continue and checked the threads:&lt;/p&gt;
    &lt;quote&gt;(gdb) continueContinuing.^CThread 4 received signal SIGINT, Interrupt.0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82(gdb) info threadsId Target Id Frame1 Thread 1.1 (CPU#0 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:822 Thread 1.2 (CPU#1 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:823 Thread 1.3 (CPU#2 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82* 4 Thread 1.4 (CPU#3 [halted ]) 0xffffffff82621d8b in pv_native_safe_halt () at /build/linux-8YMEfB/linux-6.17.0/arch/x86/kernel/paravirt.c:82(gdb) continue&lt;/quote&gt;
    &lt;p&gt;I looked at the QEMU window. The desktop was responsive. The mouse moved. Java was gone - killed by the &lt;code&gt;SIGKILL&lt;/code&gt; we planted before breaking the deadlock.
We actually did it. We resurrected a kernel-deadlocked machine by lying to it about return values, forcibly releasing locks, and planting signals in process memory.
Would I recommend this in production (or anywhere outside a lab)? Absolutely not. But was it fun? Totally!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://questdb.com/blog/async-profiler-kernel-bug/"/><published>2025-12-15T20:52:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46280887</id><title>Secret Documents Show Pepsi and Walmart Colluded to Raise Food Prices</title><updated>2025-12-16T10:13:18.158782+00:00</updated><content/><link href="https://www.thebignewsletter.com/p/secret-documents-show-pepsi-and-walmart"/><published>2025-12-15T21:24:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46281288</id><title>Economics of Orbital vs. Terrestrial Data Centers</title><updated>2025-12-16T10:13:17.831143+00:00</updated><content>&lt;doc fingerprint="f9bb25352574da8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt; Economics of Orbital vs&lt;lb/&gt; Terrestrial Data Centers &lt;/head&gt;&lt;p&gt;It might not be rational&lt;/p&gt;&lt;p&gt;But&lt;/p&gt;&lt;p&gt;It might be physically possible&lt;/p&gt;&lt;p&gt;Before we get nerd sniped by the shiny engineering details, ask the only question that matters. Why compute in orbit? Why should a watt or a flop 250 miles up be more valuable than one on the surface? What advantage justifies moving something as mundane as matrix multiplication into LEO?&lt;/p&gt;&lt;p&gt;That "why" is almost missing from the public conversation. People jump straight to hardware and hand-wave the business case, as if the economics are self-evident. They aren't. A lot of the energy here is FOMO and aesthetic futurism, not a grounded value proposition.&lt;/p&gt;&lt;p&gt;Note: This page is built from publicly available information and first-principles modeling. No proprietary data. These are my personal thoughts and do not represent the views of any company or organization.&lt;/p&gt;&lt;head rend="h3"&gt;Orbital Solar&lt;/head&gt;&lt;p&gt;$31.2B&lt;/p&gt;&lt;head rend="h3"&gt;Terrestrial&lt;/head&gt;&lt;p&gt;$14.8B&lt;/p&gt;&lt;head rend="h4"&gt;Orbital Solar&lt;/head&gt;&lt;head rend="h4"&gt;Terrestrial (On-Site CCGT)&lt;/head&gt;&lt;head rend="h3"&gt;Orbital Solar&lt;/head&gt;&lt;head rend="h3"&gt;Terrestrial&lt;/head&gt;&lt;head rend="h2"&gt;Model Assumptions&lt;/head&gt;&lt;head rend="h4"&gt;Global&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;GPUs not included—this models everything upstream of compute hardware&lt;/item&gt;&lt;item&gt;Target capacity: 1 GW nameplate electrical&lt;/item&gt;&lt;item&gt;Analysis period: 5 years&lt;/item&gt;&lt;item&gt;All figures in 2025 USD; excludes financing, taxes, incentives, and FMV&lt;/item&gt;&lt;item&gt;Full availability assumed (no downtime derates), no insurance/logistics overheads&lt;/item&gt;&lt;/list&gt;&lt;head rend="h4"&gt;Orbital Solar (Starlink-class)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Single bus class (Starlink V2 Mini heritage) scaled linearly to target power&lt;/item&gt;&lt;item&gt;Station-keeping propellant mass assumed rolled into Starlink-like specific power (W/kg)&lt;/item&gt;&lt;item&gt;Linear solar cell degradation assumed; actual silicon with coverglass shows steep-then-shallow curve&lt;/item&gt;&lt;item&gt;Solar margin = extra initial capacity to maintain average power over lifetime (not end-of-life)&lt;/item&gt;&lt;item&gt;GPU margin = cumulative expected failures over analysis period (replacement cost, not extra capacity)&lt;/item&gt;&lt;item&gt;Optimal fairing packing assumed regardless of satellite size (kW); no packing penalty modeled&lt;/item&gt;&lt;item&gt;No additional mass for liquid cooling loop infrastructure; likely needed but not included&lt;/item&gt;&lt;item&gt;All mass delivered to LEO; no on-orbit servicing/logistics&lt;/item&gt;&lt;item&gt;Launch pricing applied to total delivered mass; no cadence/manifest constraints modeled&lt;/item&gt;&lt;item&gt;Thermal: only solar array area used as radiator; no dedicated radiator mass assumed&lt;/item&gt;&lt;item&gt;Radiation/shielding impacts on mass ignored; no degradation of structures beyond panel aging&lt;/item&gt;&lt;item&gt;No disposal, de-orbit, or regulatory compliance costs included&lt;/item&gt;&lt;item&gt;Ops overhead and NRE treated as flat cost adders; no learning-curve discounts&lt;/item&gt;&lt;item&gt;No adjustments for permitting or regulatory delay&lt;/item&gt;&lt;/list&gt;&lt;head rend="h4"&gt;Terrestrial (On-Site CCGT)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;On-site H-Class CCGT at the fence line; grid interconnect/transmission not costed&lt;/item&gt;&lt;item&gt;Capex buckets embed site prep/land; permitting, taxes, and financing excluded&lt;/item&gt;&lt;item&gt;Fuel price held flat; no carbon price, hedging, or escalation modeled&lt;/item&gt;&lt;item&gt;Water/cooling availability assumed; no scarcity or discharge penalties&lt;/item&gt;&lt;item&gt;Fixed PUE and capacity factor; no forced-outage or maintenance derates applied&lt;/item&gt;&lt;item&gt;No efficiency gains or technology learning assumed over time for terrestrial plant&lt;/item&gt;&lt;item&gt;No adjustments for permitting or regulatory delay&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Motivation and Framing&lt;/head&gt;&lt;p&gt;I love space. I live and breathe it. I'm lucky enough to brush the heavens with my own metal and code, and I want nothing more than a booming orbital space economy that creates the flywheel that makes space just another location we all work and visit. I love AI and I subscribe to maximum, unbounded scale. I want to make the biggest bets. I grew up half-afraid we'd never get another Apollo or Manhattan. I truly want the BigThing.&lt;/p&gt;&lt;p&gt;This is all to say that the current discourse is increasingly bothering me due to the lack of rigor; people are using back-of-the-envelope math, doing a terrible job of it, and only confirming whatever conclusion they already want. Calculating radiation and the cost of goods is not difficult. Run the numbers.&lt;/p&gt;&lt;p&gt;Before we do the classic engineer thing and get nerd sniped by all the shiny technical problems, it's worth asking the only question that matters: why put compute in orbit at all? Why should a watt or a flop be more valuable 250 miles up than on the surface? What economic or strategic advantage justifies the effort required to run something as ordinary as matrix multiplication in low Earth orbit?&lt;/p&gt;&lt;p&gt;That "why" is nearly missing from the public conversation. The "energy is cheaper, less regulations, infinite space" arguments just ring false compared to the mountains of challenges and brutal physics putting anything in space layers on. The discourse then skips straight to implementation, as if the business case is obvious.&lt;/p&gt;&lt;head rend="h3"&gt;Personal Positioning&lt;/head&gt;&lt;p&gt;I'm not here to dunk on anyone building real hardware. Space is hard, and shipping flight systems is a credibility filter. I'm annoyed at everyone else. The conversation is full of confident claims built on one cherry-picked fact and zero arithmetic. This is a multivariable physics problem with closed-form constraints. If you're not doing the math, you're not contributing, you're adding noise and hyping for a future we all want instead of doing the hard work to actually drive reality forward.&lt;/p&gt;&lt;head rend="h3"&gt;Core Thesis&lt;/head&gt;&lt;p&gt;The target I care about is simple: can you make space-based, commodity compute cost-competitive with the cheapest terrestrial alternative? That's the whole claim. Not "space is big." Not "the sun is huge." Not "launch will be cheap." Can you deliver useful watts and reject the waste heat at a price that beats a boring Crusoe-style tilt-wall datacenter tied into a 200–500 MW substation?&lt;/p&gt;&lt;p&gt;If you can't beat that, the rest is just vibes. GPUs are pretty darn happy living on the ground. They like cheap electrons, mature supply chains, and technicians who can swap a dead server in five minutes. Orbit doesn't get points for being cool. Orbit has to win on cost, or it has to admit it's doing something else entirely. If it's an existential humanity play, that's cool too, but it's a slightly different game.&lt;/p&gt;&lt;head rend="h3"&gt;Analytical Lens&lt;/head&gt;&lt;p&gt;So here's what I did. I built a simple model that reduces the debate to one parameter: cost per watt of usable power for compute. The infographic below lets you change the assumptions directly. If you disagree with the inputs, great. Move the sliders. But at least we'll be arguing over numbers that map to reality.&lt;/p&gt;&lt;p&gt;The model is deliberately boring. No secret sauce. Just publicly available numbers and first-principles physics: solar flux, cell efficiency, radiator performance, launch cost, hardware mass, and a terrestrial benchmark that represents the real alternative: a tilt-wall datacenter sitting on top of cheap power. The code is public, please go through everything. github.com/andrewmccalip/thoughts&lt;/p&gt;&lt;head rend="h3"&gt;Findings and Implications&lt;/head&gt;&lt;p&gt;Here's the headline result: it's not obviously stupid, and it's not a sure thing. It's actually more reasonable than my intuition thought! If you run the numbers honestly, the physics doesn't immediately kill it, but the economics are savage. It only gets within striking distance under aggressive assumptions, and the list of organizations positioned to even try that is basically one.&lt;/p&gt;&lt;p&gt;That "basically one" point matters. This isn't about talent. It's about integration. If you have to buy launch, buy buses, buy power hardware, buy deployment, and pay margin at every interface, you never get there. The margin stack and the mass tax eat you alive. Vertical integration isn't a nice-to-have. It's the whole ballgame.&lt;/p&gt;&lt;head rend="h3"&gt;Market and Incentives&lt;/head&gt;&lt;p&gt;Which is why I trend positive on SpaceX here. If anyone can brute force a new industrial stack into existence, it's the team that can reduce $/kg and get as humanly close to free launch as possible. And they need to, because the economics are not close. This is not a 25% mismatch. It's 400%. Closing that is the whole job. Positive does not mean gullible. It needs measurable targets and painful reality checks.&lt;/p&gt;&lt;p&gt;If SpaceX ever goes public, this is exactly the kind of thing shareholders should demand: extreme, barely-achievable goalposts with clean measurement. Tesla did it with the options grant. Do the same here. Pay Elon a king's ransom if he delivers a new industrial primitive: cheap, sustained dollars per kilogram and dollars per watt in orbit, at real cadence, for years.&lt;/p&gt;&lt;head rend="h3"&gt;Broader Interpretation&lt;/head&gt;&lt;p&gt;On strict near-term unit economics, this might still be a mediocre use of capital. A tilt-wall datacenter in Oregon with cheap power, cheap cooling, and technicians on call is hard to beat. Crusoe can park compute on stranded natural gas and turn it into flops with a supply chain that already exists.&lt;/p&gt;&lt;p&gt;But the knock-on effects are why this keeps pulling at people. If you can industrialize power and operations in orbit at meaningful scale, you're not just running GPUs. You're building a new kind of infrastructure that makes it easier for humans to keep spreading out. Compute is just one of the first excuses to pay for the scaffolding. Even if this is a mediocre trade on strict near-term unit economics, the second-order effects could be enormous.&lt;/p&gt;&lt;p&gt;I'll go one step further and say the quiet part out loud: we should be actively goading more billionaires into spending on irrational, high-variance projects that might actually advance civilization. I feel genuine secondhand embarrassment watching people torch their fortunes on yachts and status cosplay. No one cares about your Loro Piana. If you've built an empire, the best possible use of it is to burn its capital like a torch and light up a corner of the future. Fund the ugly middle. Pay for the iteration loops. Build the cathedrals. This is how we advance civilization.&lt;/p&gt;&lt;head rend="h3"&gt;Links to Reports&lt;/head&gt;&lt;p&gt;Everyone is going to copy-paste this into the models, so I've done that part for you. It's a decent way to automate the sanity checks, but it could use more in-depth review.&lt;/p&gt;&lt;p&gt;GitHub: github.com/andrewmccalip/thoughts&lt;/p&gt;&lt;p&gt;"Conduct a thorough, first-principles-based review of this project. Scrutinize every assumption and constant, rigorously fact-checking all data. The objective is to identify and correct any fundamental errors in logic or calculation."&lt;/p&gt;&lt;p&gt; Grok: grok.com/share/...&lt;lb/&gt; ChatGPT: chatgpt.com/share/...&lt;lb/&gt; Gemini: gemini.google.com/share/...&lt;lb/&gt; Claude: claude.ai/public/artifacts/... &lt;/p&gt;&lt;head rend="h3"&gt;Overall Conclusion&lt;/head&gt;&lt;p&gt;Even so, irrational ambition doesn't get to ignore physics. The point of this page is to make the constraints explicit, so we can argue about reality instead of vibes. If the numbers close, even barely, then it's worth running hard on the idea. If they don't, the honest move is to say so and move on. Either way, I think some version of this has a feeling of inevitability.&lt;/p&gt;&lt;p&gt;So scroll down, play with the sliders, and try to break it. Change launch cost. Change lifetime. Change specific power. Change hardware cost. The goal here isn't to "win" an argument. It's to drag the conversation back to first principles: assumptions you can point at, and outputs you can sanity-check. Check out the GitHub, run the code, find the errors, and I'll update it live.&lt;/p&gt;&lt;p&gt;After that, we can do the fun part: thermal diagrams, radiator math, orbit beta angles, failure rates, comms geometry, all the shiny engineering details that make this topic so addicting. It's not obviously stupid, and it's not a sure thing. That's why it's worth doing the math.&lt;/p&gt;&lt;p&gt;It might not be rational. But it might be physically possible.&lt;/p&gt;&lt;head rend="h3"&gt;Technical Engineering Challenges&lt;/head&gt;&lt;p&gt;The governing constraint for orbital compute is thermodynamics. Terrestrial datacenters leverage convective cooling—dumping waste heat into the atmosphere or water sources, effectively using the planet as an infinite cold reservoir. In the vacuum of space, convection is impossible. Heat rejection relies exclusively on radiation.&lt;/p&gt;&lt;p&gt;Every object in space settles to an equilibrium temperature where absorbed power equals radiated power. If heat generation exceeds radiative capacity, the temperature rises until the $T^4$ term in the Stefan-Boltzmann law balances the equation:&lt;/p&gt;$$\dot{Q}_{\text{rad}} = \varepsilon \sigma A T^4$$&lt;p&gt;The engineering challenge is ensuring this equilibrium temperature remains below the safe operating limits of silicon processors.&lt;/p&gt;&lt;head rend="h4"&gt;Energy Balance and Heat Rejection&lt;/head&gt;&lt;p&gt;To dimension the radiator surface, we must account for the total thermal load managed by the satellite bus. In this model, based on a Starlink-style bifacial architecture (PV on front, radiator on back), the system must reject the aggregate energy of two distinct paths:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Incident Solar Flux: The sun delivers $G_{\text{sc}} = 1361\;\text{W/m}^2$ (AM0). With a solar absorptivity $\alpha = 0.92$, the panel absorbs approximately $\sim 1250\;\text{W/m}^2$.&lt;/item&gt;&lt;item&gt;Energy Partitioning: &lt;list rend="ul"&gt;&lt;item&gt;Electrical Path ($\sim$22%): High-efficiency cells convert $\sim 275\;\text{W/m}^2$ into electricity. This power drives the compute payload and is converted entirely back into heat by the processors. A liquid cooling loop collects this heat and returns it to the panel structure for rejection.&lt;/item&gt;&lt;item&gt;Thermal Absorption ($\sim$78%): The remaining $\sim 975\;\text{W/m}^2$ is not converted to electricity but is absorbed immediately as lattice heat (phonon generation) within the panel structure.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Total Heat Load: The radiator must reject the sum of both the immediate thermal absorption and the returned electrical waste heat—effectively 100% of the absorbed solar flux.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This imposes a strict area density limit. High-power compute requires large collection areas, which inherently absorb large amounts of solar heat. The radiator must be sized to reject this aggregate load while maintaining an operating temperature below the junction limit.&lt;/p&gt;&lt;head rend="h4"&gt;Operating Temperature Limits&lt;/head&gt;&lt;p&gt;Modern AI accelerators (H100/B200 class) typically throttle at junction temperatures $T_j &amp;gt; 85\text{–}100\degree\text{C}$. To maintain a junction at 85°C, and accounting for the thermal gradient across cold plates and interface materials ($\Delta T \approx 10\degree\text{C}$), the radiator surface temperature $T_{\text{rad}}$ is constrained to approximately 75°C.&lt;/p&gt;&lt;p&gt;The model below calculates the equilibrium temperature for a bifacial array in a terminator orbit ($\beta = 90^\circ$). It accounts for solar flux, Earth IR ($\sim 237\;\text{W/m}^2$), and albedo. If the calculated equilibrium temperature $T_{\text{eq}}$ exceeds the target radiator temperature, the design fails.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andrewmccalip.com/space-datacenters"/><published>2025-12-15T21:56:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46281944</id><title>JetBlue flight averts mid-air collision with US Air Force jet</title><updated>2025-12-16T10:13:17.514120+00:00</updated><content>&lt;doc fingerprint="bfbbe4d212d3adc9"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON, Dec 15 (Reuters) - A JetBlue (JBLU.O) passenger jet bound for New York took evasive action on Friday to avoid a mid-air collision with a U.S. Air Force tanker plane near Venezuela, a pilot said in an air traffic control recording.&lt;/p&gt;
    &lt;p&gt;JetBlue Flight 1112 had departed the Caribbean nation of Curacao and was flying about 40 miles (64 km) off the coast of Venezuela when the Airbus (AIR.PA) A320 reported encountering the Air Force jet, which did not have its transponder activated, according to the recording captured by liveatc.net.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The Air Force pilot was within a few miles of the plane and at the same altitude, the JetBlue pilot said on the recording.&lt;/p&gt;
    &lt;p&gt;"They passed directly in our flight path... They don't have their transponder turned on. It's outrageous," the pilot said.&lt;/p&gt;
    &lt;p&gt;The Air Force jet then entered Venezuelan airspace, the JetBlue pilot said. "We almost had a mid-air collision up here."&lt;/p&gt;
    &lt;head rend="h2"&gt;INCIDENT RECALLS DEADLY JANUARY CRASH&lt;/head&gt;
    &lt;p&gt;Senate Commerce Committee Chair Ted Cruz noted on Monday that an Army helicopter had collided with an American Airlines (AAL.O) flight on January 29 near Reagan Washington National Airport, killing 67 people, and was not using an advanced tracking technology called an automatic dependent surveillance-broadcast system, also known as ADS-B. "Why do we continue to tolerate near misses?" Cruz said of the JetBlue incident.&lt;/p&gt;
    &lt;p&gt;Senator Maria Cantwell, the top Democrat on the committee, also said the JetBlue incident raised concerns and the public needed a better system. "This is not acceptable," Cantwell said. "You don't have corridors where military aircraft and commercial planes are flying and then not letting each other know that they are in that space. We just can't have that."&lt;/p&gt;
    &lt;p&gt;The senators spoke on Monday at a press conference as they push to remove a provision from a must-pass annual defense bill that they say would weaken air safety by allowing military aircraft to operate in Washington, DC, airspace without transmitting ADS-B information.&lt;/p&gt;
    &lt;p&gt;A JetBlue spokesperson said on Monday the company's top priority was safety.&lt;/p&gt;
    &lt;p&gt;"Our crew members are trained on proper procedures for various flight situations, and we appreciate our crew for promptly reporting this situation to our leadership team. We have reported this incident to federal authorities and will participate in any investigation."&lt;/p&gt;
    &lt;head rend="h2"&gt;U.S. MILITARY ACTIVE IN REGION&lt;/head&gt;
    &lt;p&gt;The incident happened as the United States has mounted a large-scale military buildup in the southern Caribbean as President Donald Trump campaigns to oust Venezuelan leader Nicolas Maduro, pushing relations to their most volatile point in years.&lt;/p&gt;
    &lt;p&gt;U.S. Southern Command said in a statement on Monday that it was aware of the incident and reviewing the matter.&lt;/p&gt;
    &lt;p&gt;The military added its "aircrews are highly trained professionals who operate in accordance with established procedures and applicable airspace requirements. Safety remains a top priority, and we are working through the appropriate channels to assess the facts surrounding the situation.”&lt;/p&gt;
    &lt;p&gt;Last month, the Federal Aviation Administration warned major airlines of a "potentially hazardous situation" when flying over Venezuela and urged them to exercise caution. Major airlines from around the world have halted flights as tensions have worsened and Trump has threatened to begin hitting land targets in Venezuela.&lt;/p&gt;
    &lt;p&gt;The FAA did not immediately comment on Monday on the JetBlue incident.&lt;/p&gt;
    &lt;p&gt;Reporting by David Shepardson in Washington; Editing by Lisa Shumaker and Jamie Freed&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/"/><published>2025-12-15T22:48:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46282679</id><title>Native vs. emulation: World of Warcraft game performance on Snapdragon X Elite</title><updated>2025-12-16T10:13:17.293315+00:00</updated><content>&lt;doc fingerprint="379ae9ff3d84b595"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Native versus emulation - World of Warcraft game performance on Snapdragon X Elite&lt;/head&gt;
    &lt;p&gt;At the beginning of the year, I tested the Snapdragon X Elite unreleased dev-kit, and I couldn't really compare x86 versus native gaming performance for the same game. I only managed to get World of Warcraft Classic x86 to run, and when compared to the native version, the FPS drop was 40-60% in two simple benchmarks. WoW retail x86 did not work, but now with the latest Windows improvements and the Prism emulation layer, things have changed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Test platform&lt;/head&gt;
    &lt;p&gt;The tests were done on a Snapdragon X Elite dev kit equipped with X1E-00-1DE Snapdragon X Elite SoC (3.8 GHz with 4.3 GHz boost on 1-2 cores) and 32GB of RAM. The dev kit runs at a higher TDP than most, if not all, laptops and has the theoretically best bin of chips (highest boost clocks).&lt;/p&gt;
    &lt;p&gt;The key difference since my initial review is the Windows version. Microsoft was working hard on improving emulation performance and compatibility. Since Windows 11 24H2, there is a new emulator called Prism, and with recent updates it also got AVX instructions support to handle even more x86_64 applications.&lt;/p&gt;
    &lt;p&gt;For the tests I used Windows 11 25H2 26220.7344 Insider Preview version to get all possible improvements taken into account.&lt;/p&gt;
    &lt;p&gt;Additionally, the x86_64 binaries properties were edited to enable &lt;quote&gt;newer emulated CPU features&lt;/quote&gt;:&lt;/p&gt;
    &lt;head rend="h2"&gt;World of Warcraft&lt;/head&gt;
    &lt;p&gt;WoW is an MMORPG, and it does not have a built-in benchmark. It can be reliably benchmarked to some extent if you use specific game areas/instances. You can check more in my WoW benchmarking section.&lt;/p&gt;
    &lt;p&gt;As a PC game, it's a modern DX12 game engine with optional ray-traced shadows support and a few other features. It offers native x86, Windows on ARM, and Apple Silicon versions. In my previous tests, the x86 retail version would not run on Snapdragon, and only the Classic version managed to run. The FPS drop versus the native version was massive of around 40-60% (but the testing wasn't as detailed as I would like).&lt;/p&gt;
    &lt;p&gt;With the Windows (and WoW) changes, both x86_64 WoW clients managed to run on Windows on ARM, allowing me to get way more test data. MSI Afterburner and other similar tools don't support WoA, so I had to use the game's built-in average FPS meter (which doesn't average over long periods of time; and no 1% lows/frame time graphs).&lt;/p&gt;
    &lt;head rend="h3"&gt;World of Warcraft - native versus emulated&lt;/head&gt;
    &lt;p&gt;I measured the FPS at 1080p for two settings - mode 3 (low) and mode 7 (high). The results are as follows:&lt;/p&gt;
    &lt;p&gt;The results are astounding as the x86 version is rivaling the native one, maybe even edging the native client.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WoW Classic and Stonard in retail are old locations, very light to render, so even with an iGPU, the FPS will be high.&lt;/item&gt;
      &lt;item&gt;Ardenweald is the most GPU-intensive modern zone from the test collection. Bastion is less demanding but has a bit more geometry. Dazar'alor harbor view is a geometry/render distance-based benchmark and will depend mostly on GPU&lt;/item&gt;
      &lt;item&gt;Necrotic Wake and Spires of Ascension are dungeons with some mobs, geometry, and units the game tracks. GPU with increasing CPU load.&lt;/item&gt;
      &lt;item&gt;Valdrakken is a player hub from the previous expansion, now mostly empty - player hubs when active are quite demanding to render without stutter. They tend to use a lot of assets as well.&lt;/item&gt;
      &lt;item&gt;Combat benchmark is pushing the game into single-core CPU limit - it's done in the old Karazhan raid, where I can reliably pull a large group of mobs and stand still with fixed camera position. iGPUs can also be the bottleneck on higher settings due to particle effects of spells going off. Most dGPUs will have no problems with them.&lt;/item&gt;
      &lt;item&gt;Out of combat, when test mobs despawn, the FPS inside Karazan increases as it's an old instance without any complex geometry or large asset collection. The game combat &lt;quote&gt;world state&lt;/quote&gt;vanishes and thus the single-core bottleneck as well&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Karazhan benchmark was the only one where the native version was noticeably ahead of the emulated version. Due to that, I've also added two modern dungeon instances, and those results were more in line with other locations. Either there was a difference between game versions, or in larger instances, game performance can be limited by some sort of system latency, and emulation is not the best for that.&lt;/p&gt;
    &lt;p&gt;WoW by default will use 4 CPU cores, with one core being the &lt;quote&gt;primary&lt;/quote&gt; ones. In a mass combat / mass NPC scenario, the main core will see 100% load and will be the limiting factor.&lt;/p&gt;
    &lt;p&gt;Windows on ARM can handle a lot of x86 Windows applications, but not all of them. From my quick re-tests, I managed to run Unigine Valley, but Unigine Superposition failed to run.&lt;/p&gt;
    &lt;head rend="h3"&gt;Default versus very strict emulation&lt;/head&gt;
    &lt;p&gt;I was curious what the difference between emulation settings. Switching to &lt;quote&gt;very strict&lt;/quote&gt; emulation settings disables a lot of features, which in turn tanked x86 WoW performance:&lt;/p&gt;
    &lt;head rend="h2"&gt;Mobile SoC comparison&lt;/head&gt;
    &lt;p&gt;I've also recently tested Strix Point HX 370, and Intel Arrow Lake 255H capped at 30W, so I've added them to the comparison charts:&lt;/p&gt;
    &lt;p&gt;In iGPU-heavy scenarios, Intel/AMD tend to be ahead, while in CPU scenarios, all 3 platforms get close to each other.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;I really wanted to compare native versus emulated on Snapdragon, as initial WoW Classic performance differences were huge. With recent Prism updates, I forced the devkit to update Windows, and it managed to run the x86 retail World of Warcraft client. This allowed me to test CPU and GPU-focused scenarios within the game. Surprisingly, for WoW, there was no real penalty, at least outside the raid/combat scenario. When you install Battle.net and WoW, you will get the native version by default, so you don't have to select or change anything.&lt;/p&gt;
    &lt;p&gt;It's good to see improvements to Windows on ARM. Better application compatibility is nice, but it will never be perfect. On top of that, some apps will have hardcoded checks, and you won't be able to use x86 drivers. Qualcomm is preparing the second generation of mobile X Elite chips, and it will be interesting to see how they perform. Initial launch saw a lot of laptop sales, but also a lot of returns.&lt;/p&gt;
    &lt;p&gt;Limited Linux support is still a problem, from device tree lists, firmware extraction, to overall worse behavior of the SoC under Linux. Linux ARM support is way better than Windows, and even some hardware vendors tend to support ARM Linux due to the Raspberry Pi (like astrophotography equipment, vision cameras).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rkblog.dev/posts/pc-hardware/pc-on-arm/x86_versus_arm_native_game/"/><published>2025-12-15T23:47:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46283016</id><title>Quill OS: An open-source OS for Kobo's eReaders</title><updated>2025-12-16T10:13:16.825436+00:00</updated><content>&lt;doc fingerprint="ae45b2563aa66bc8"&gt;
  &lt;main&gt;
    &lt;p&gt;Here are some of Quill OS' features:&lt;/p&gt;
    &lt;p&gt; Fully integrated KoBox X11 subsystem &lt;lb/&gt;ePUB, PDF, picture and plain text display support &lt;lb/&gt;Versatile configuration options for reading &lt;lb/&gt;muPDF rendering engine for ePUBs and PDFs &lt;lb/&gt;Wi-Fi support and web browser &lt;lb/&gt;Encrypted storage with EncFS &lt;lb/&gt;Fast dictionary &amp;amp; local storage search &lt;lb/&gt;Dark mode &lt;lb/&gt;Full factory reset option if needed &lt;lb/&gt;Seamless update process &lt;lb/&gt;VNC viewer app &lt;lb/&gt;Search function &lt;lb/&gt;10 built-in fonts &lt;lb/&gt;Auto-suspend &lt;lb/&gt;Lock screen/passcode &lt;lb/&gt;User-friendly experience &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://quill-os.org/"/><published>2025-12-16T00:22:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46283750</id><title>Rollstack (YC W23) is hiring multiple software engineers (TypeScript) US/Canada</title><updated>2025-12-16T10:13:16.292222+00:00</updated><content>&lt;doc fingerprint="f3a0d348861224cf"&gt;
  &lt;main&gt;
    &lt;p&gt;Automate data-driven slide decks and documents with AI&lt;/p&gt;
    &lt;p&gt;At Rollstack, we are revolutionizing the way businesses share and communicate data and insights. Organizations worldwide rely on slide decks and documents to make informed decisions, whether for leadership, clients, or partners. Yet, preparing these materials often consumes countless hours. Rollstack fully automates that.&lt;/p&gt;
    &lt;p&gt;We help some of the world's leading organizations, from mid-sized to public companies like SoFi, Zillow and Whirlpool, in automating their slide decks and documents. Headquartered in New York, we offer a remote-friendly workplace and are backed by Insight Partners and Y Combinator, the most successful startup incubator in the world that produced the likes of Airbnb, Twitch, Instacart, Dropbox, Reddit, Doordash, Stripe, Coinbase, etc.&lt;/p&gt;
    &lt;p&gt;Our team operates with speed and focus to deliver outsized impacts for our customers. We approach every challenge with first principles, never assuming things have to be done a certain way. We are a diverse team that believes intelligence and kindness go hand in hand, welcoming individuals from all backgrounds. Our persistence and rapid execution define us as a category leader and a future generational company.&lt;/p&gt;
    &lt;p&gt;As a Software Engineer at Rollstack, you’ll build core features that automate how companies share data through slides and documents. You’ll work across the stack on integrations, AI insights, and performance optimization. This role is ideal for engineers who thrive on impact, autonomy, and fast-paced product development.&lt;/p&gt;
    &lt;p&gt;At Rollstack, we’re looking for engineers who enjoy iterating, shipping quickly, and solving customers' problems. We want individuals who exhibit a strong sense of ownership and have a get-things-done mentality. Our engineering team defines and drives its technical agenda to continuously iterate on the product and solve our customers' most important problems.&lt;lb/&gt; Our interview process is designed to find these kinds of engineers:&lt;/p&gt;
    &lt;p&gt;Rollstack is solving the last mile problem in the modern data stack and creating a new category: Reports Automation. We connect BI tools to slide decks and documents, automating their generation and updates.&lt;/p&gt;
    &lt;p&gt;We help some of the world's leading organizations—from mid-sized to public companies like SoFi, Zillow and Whirlpool—in automating their slide decks and documents. Headquartered in New York, we offer a remote-friendly workplace and are backed by Insight Partners and Y Combinator, the most successful startup incubator in the world that produced the likes of Airbnb, Twitch, Instacart, Dropbox, Reddit, Doordash, Stripe, Coinbase, etc.&lt;/p&gt;
    &lt;p&gt;Our team operates with speed and focus to deliver outsized impacts for our customers. We approach every challenge with first principles, never assuming things have to be done a certain way. We are a diverse team that believes intelligence and kindness go hand in hand, welcoming individuals from all backgrounds. Our persistence and rapid execution define us as a category leader and a future generational company.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/rollstack-2/jobs/QPqpb1n-software-engineer-typescript-us-canada"/><published>2025-12-16T01:51:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46284266</id><title>8M users' AI conversations sold for profit by "privacy" extensions</title><updated>2025-12-16T10:13:16.146148+00:00</updated><content>&lt;doc fingerprint="9d53a3a2bd344c8c"&gt;
  &lt;main&gt;
    &lt;p&gt;A few weeks ago, I was wrestling with a major life decision. Like I've grown used to doing, I opened Claude and started thinking out loud-laying out the options, weighing the tradeoffs, asking for perspective.&lt;/p&gt;
    &lt;p&gt;Midway through the conversation, I paused. I realized how much I'd shared: not just this decision, but months of conversations-personal dilemmas, health questions, financial details, work frustrations, things I hadn't told anyone else. I'd developed a level of candor with my AI assistant that I don't have with most people in my life.&lt;/p&gt;
    &lt;p&gt;And then an uncomfortable thought: what if someone was reading all of this?&lt;/p&gt;
    &lt;p&gt;The thought didn't let go. As a security researcher, I have the tools to answer that question.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery&lt;/head&gt;
    &lt;p&gt;We asked Wings, our agentic-AI risk engine, to scan for browser extensions with the capability to read and exfiltrate conversations from AI chat platforms. We expected to find a handful of obscure extensions-low install counts, sketchy publishers, the usual suspects.&lt;/p&gt;
    &lt;p&gt;The results came back with something else entirely.&lt;/p&gt;
    &lt;p&gt;Near the top of the list: Urban VPN Proxy. A Chrome extension with over 6 million users. A 4.7-star rating from 58,000 reviews. A "Featured" badge from Google, meaning it had passed manual review and met what Google describes as "a high standard of user experience and design."&lt;/p&gt;
    &lt;p&gt;A free VPN promising privacy and security. Exactly the kind of tool someone installs when they want to protect themselves online.&lt;/p&gt;
    &lt;p&gt;We decided to look closer.&lt;/p&gt;
    &lt;head rend="h2"&gt;What We Found&lt;/head&gt;
    &lt;p&gt;Urban VPN Proxy targets conversations across ten AI platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ChatGPT&lt;/item&gt;
      &lt;item&gt;Claude&lt;/item&gt;
      &lt;item&gt;Gemini&lt;/item&gt;
      &lt;item&gt;Microsoft Copilot&lt;/item&gt;
      &lt;item&gt;Perplexity&lt;/item&gt;
      &lt;item&gt;DeepSeek&lt;/item&gt;
      &lt;item&gt;Grok (xAI)&lt;/item&gt;
      &lt;item&gt;Meta AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For each platform, the extension includes a dedicated "executor" script designed to intercept and capture conversations. The harvesting is enabled by default through hardcoded flags in the extension's configuration:&lt;/p&gt;
    &lt;p&gt;There is no user-facing toggle to disable this. The only way to stop the data collection is to uninstall the extension entirely.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;The data collection operates independently of the VPN functionality. Whether the VPN is connected or not, the harvesting runs continuously in the background.&lt;/p&gt;
    &lt;p&gt;Here's the technical breakdown:&lt;/p&gt;
    &lt;p&gt;1. Script injection into AI platforms&lt;/p&gt;
    &lt;p&gt;The extension monitors your browser tabs. When you visit any of the targeted AI platforms (ChatGPT, Claude, Gemini, etc.), it injects an "executor" script directly into the page. Each platform has its own dedicated script - chatgpt.js, claude.js, gemini.js, and so on.&lt;/p&gt;
    &lt;p&gt;2. Overriding native browser functions&lt;/p&gt;
    &lt;p&gt;Once injected, the script overrides fetch() and XMLHttpRequest - the fundamental browser APIs that handle all network requests. This is an aggressive technique. The script wraps the original functions so that every network request and response on that page passes through the extension's code first.&lt;/p&gt;
    &lt;p&gt;This means when Claude sends you a response, or when you submit a prompt to ChatGPT, the extension sees the raw API traffic before your browser even renders it.&lt;/p&gt;
    &lt;p&gt;3. Parsing and packaging&lt;/p&gt;
    &lt;p&gt;The injected script parses the intercepted API responses to extract conversation data - your prompts, the AI's responses, timestamps, conversation IDs. This data is packaged and sent via window.postMessage to the extension's content script, tagged with the identifier PANELOS_MESSAGE.&lt;/p&gt;
    &lt;p&gt;4. Exfiltration via background worker&lt;/p&gt;
    &lt;p&gt;The content script forwards the data to the extension's background service worker, which handles the actual exfiltration. The data is compressed and transmitted to Urban VPN's servers at endpoints including analytics.urban-vpn.com and stats.urban-vpn.com.&lt;/p&gt;
    &lt;p&gt;What gets captured:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Every prompt you send to the AI&lt;/item&gt;
      &lt;item&gt;Every response you receive&lt;/item&gt;
      &lt;item&gt;Conversation identifiers and timestamps&lt;/item&gt;
      &lt;item&gt;Session metadata&lt;/item&gt;
      &lt;item&gt;The specific AI platform and model used&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Timeline&lt;/head&gt;
    &lt;p&gt;The AI conversation harvesting wasn't always there. Based on our analysis:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Before version 5.5.0: No AI harvesting functionality&lt;/item&gt;
      &lt;item&gt;July 9, 2025: Version 5.5.0 released with AI harvesting enabled by default&lt;/item&gt;
      &lt;item&gt;July 2025 - Present: All user conversations with targeted AI platforms captured and exfiltrated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Chrome and Edge extensions auto-update by default. Users who installed Urban VPN for its stated purpose - VPN functionality - woke up one day with new code silently harvesting their AI conversations.&lt;/p&gt;
    &lt;p&gt;Anyone who used ChatGPT, Claude, Gemini, or the other targeted platforms while Urban VPN was installed after July 9, 2025 should assume those conversations are now on Urban VPN's servers and have been shared with third parties. Medical questions, financial details, proprietary code, personal dilemmas - all of it, sold for "marketing analytics purposes."&lt;/p&gt;
    &lt;head rend="h2"&gt;What "AI Protection" Actually Does&lt;/head&gt;
    &lt;p&gt;Urban VPN's Chrome Web Store listing promotes "AI protection" as a feature:&lt;/p&gt;
    &lt;p&gt;"Advanced VPN Protection - Our VPN provides added security features to help shield your browsing experience from phishing attempts, malware, intrusive ads and AI protection which checks prompts for personal data (like an email or phone number), checks AI chat responses for suspicious or unsafe links and displays a warning before click or submit your prompt."&lt;/p&gt;
    &lt;p&gt;The framing suggests the AI monitoring exists to protect you-checking for sensitive data you might accidentally share, warning you about suspicious links in responses.&lt;/p&gt;
    &lt;p&gt;The code tells a different story. The data collection and the "protection" notifications operate independently. Enabling or disabling the warning feature has no effect on whether your conversations are captured and exfiltrated. The extension harvests everything regardless.&lt;/p&gt;
    &lt;p&gt;The protection feature shows occasional warnings about sharing sensitive data with AI companies. The harvesting feature sends that exact sensitive data - and everything else - to Urban VPN's own servers, where it's sold to advertisers. The extension warns you about sharing your email with ChatGPT while simultaneously exfiltrating your entire conversation to a data broker.&lt;/p&gt;
    &lt;head rend="h2"&gt;It Gets Worse&lt;/head&gt;
    &lt;p&gt;After documenting Urban VPN Proxy's behavior, we checked whether the same code existed elsewhere.&lt;/p&gt;
    &lt;p&gt;It did. The identical AI harvesting functionality appears in seven other extensions from the same publisher, across both Chrome and Edge:&lt;/p&gt;
    &lt;p&gt;Chrome Web Store:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy - 6,000,000 users&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy - 600,000 users&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard - 40,000 users&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker - 10,000 users&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Microsoft Edge Add-ons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy - 1,323,622 users&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy - 36,459 users&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard - 12,624 users&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker - 6,476 users&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Total affected users: Over 8 million.&lt;/p&gt;
    &lt;p&gt;The extensions span different product categories, a VPN, an ad blocker, a "browser guard" security tool, but share the same surveillance backend. Users installing an ad blocker have no reason to expect their Claude conversations are being harvested.&lt;/p&gt;
    &lt;p&gt;All of these extensions carry "Featured" badges from their respective stores, except Urban Ad Blocker for Edge. These badges signal to users that the extensions have been reviewed and meet platform quality standards. For many users, a Featured badge is the difference between installing an extension and passing it by - it's an implicit endorsement from Google and Microsoft.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who's Behind This&lt;/head&gt;
    &lt;p&gt;Urban VPN is operated by Urban Cyber Security Inc., which is affiliated with BiScience (B.I Science (2009) Ltd.), a data broker company.&lt;/p&gt;
    &lt;p&gt;This company has been on researchers' radar before. Security researchers Wladimir Palant and John Tuckner at Secure Annex have previously documented BiScience's data collection practices. Their research established that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BiScience collects clickstream data (browsing history) from millions of users&lt;/item&gt;
      &lt;item&gt;Data is tied to persistent device identifiers, enabling re-identification&lt;/item&gt;
      &lt;item&gt;The company provides an SDK to third-party extension developers to collect and sell user data&lt;/item&gt;
      &lt;item&gt;BiScience sells this data through products like AdClarity and Clickstream OS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our finding represents an expansion of this operation. BiScience has moved from collecting browsing history to harvesting complete AI conversations-a significantly more sensitive category of data.&lt;/p&gt;
    &lt;p&gt;The privacy policy confirms the data flow:&lt;/p&gt;
    &lt;p&gt;"We share the Web Browsing Data with our affiliated company... BiScience that uses this raw data and creates insights which are commercially used and shared with Business Partners"&lt;/p&gt;
    &lt;head rend="h2"&gt;The Disclosure Problem&lt;/head&gt;
    &lt;p&gt;To be fair, Urban VPN does disclose some of this-if you know where to look.&lt;/p&gt;
    &lt;p&gt;The consent prompt (shown during extension setup) mentions that the extension processes "ChatAI communication" along with "pages you visit" and "security signals." It states this is done "to provide these protections."&lt;/p&gt;
    &lt;p&gt;[Screenshot: Urban VPN consent prompt]&lt;/p&gt;
    &lt;p&gt;The privacy policy goes further, buried deep in the document:&lt;/p&gt;
    &lt;p&gt;"AI Inputs and Outputs. As part of the Browsing Data, we will collect the prompts and outputs queried by the End-User or generated by the AI chat provider, as applicable."&lt;/p&gt;
    &lt;p&gt;And:&lt;/p&gt;
    &lt;p&gt;"We also disclose the AI prompts for marketing analytics purposes."&lt;/p&gt;
    &lt;p&gt;However, the Chrome Web Store listing-the place where users actually decide whether to install-shows a different picture:&lt;/p&gt;
    &lt;p&gt;"This developer declares that your data is Not being sold to third parties, outside of the approved use cases"&lt;/p&gt;
    &lt;p&gt;The listing mentions the extension handles "Web history" and "Website content." It says nothing about AI conversations specifically.&lt;/p&gt;
    &lt;p&gt;The contradictions are significant:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The consent prompt frames AI monitoring as protective. The privacy policy reveals the data is sold for marketing.&lt;/item&gt;
      &lt;item&gt;The store listing says data isn't sold to third parties. The privacy policy describes sharing with BiScience, "Business Partners," and use for "marketing analytics."&lt;/item&gt;
      &lt;item&gt;Users who installed before July 2025 never saw the updated consent prompt-the AI harvesting was added via silent update in version 5.5.0.&lt;/item&gt;
      &lt;item&gt;Even users who see the consent prompt have no granular control. You can't accept the VPN but decline the AI harvesting. It's all or nothing.&lt;/item&gt;
      &lt;item&gt;Nothing indicates to users that the data collection continues even when the VPN is disconnected and the AI protection feature is turned off. The harvesting runs silently in the background regardless of what features the user has enabled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Google's Role&lt;/head&gt;
    &lt;p&gt;Urban VPN Proxy carries Google's "Featured" badge on the Chrome Web Store. According to Google's documentation:&lt;/p&gt;
    &lt;p&gt;"Featured extensions follow our technical best practices and meet a high standard of user experience and design."&lt;/p&gt;
    &lt;p&gt;"Before it receives a Featured badge, the Chrome Web Store team must review each extension."&lt;/p&gt;
    &lt;p&gt;This means a human at Google reviewed Urban VPN Proxy and concluded it met their standards. Either the review didn't examine the code that harvests conversations from Google's own AI product (Gemini), or it did and didn't consider this a problem.&lt;/p&gt;
    &lt;p&gt;The Chrome Web Store's Limited Use policy explicitly prohibits "transferring or selling user data to third parties like advertising platforms, data brokers, or other information resellers." BiScience is, by its own description, a data broker.&lt;/p&gt;
    &lt;p&gt;The extension remains live and featured as of this writing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;Browser extensions occupy a unique position of trust. They run in the background, have broad access to your browsing activity, and auto-update without asking. When an extension promises privacy and security, users have little reason to suspect it's doing the opposite.&lt;/p&gt;
    &lt;p&gt;What makes this case notable isn't just the scale - 8 million users - or the sensitivity of the data - complete AI conversations. It's that these extensions passed review, earned Featured badges, and remained live for months while harvesting some of the most personal data users generate online. The marketplaces designed to protect users instead gave these extensions their stamp of approval.&lt;/p&gt;
    &lt;p&gt;If you have any of these extensions installed, uninstall them now. Assume any AI conversations you've had since July 2025 have been captured and shared with third parties.&lt;/p&gt;
    &lt;p&gt;This writeup was authored by the research team at Koi.&lt;/p&gt;
    &lt;p&gt;We built Koi to detect exactly these kinds of threats - extensions that slip past marketplace reviews and quietly exfiltrate sensitive data. Our risk engine, Wings, continuously monitors browser extensions to catch threats before they reach your team.&lt;/p&gt;
    &lt;p&gt;Book a demo to see how behavioral analysis catches what static review misses.&lt;/p&gt;
    &lt;p&gt;Stay safe out there.&lt;/p&gt;
    &lt;head rend="h2"&gt;IOCs&lt;/head&gt;
    &lt;p&gt;Chrome:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy: eppiocemhmnlbhjplcgkofciiegomcon&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard: almalgbpmcfpdaopimbdchdliminoign&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker: feflcgofneboehfdeebcfglbodaceghj&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy for Chrome: pphgdbgldlmicfdkhondlafkiomnelnk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Edge:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Urban VPN Proxy: nimlmejbmnecnaghgmbahmbaddhjbecg&lt;/item&gt;
      &lt;item&gt;Urban Browser Guard: jckkfbfmofganecnnpfndfjifnimpcel&lt;/item&gt;
      &lt;item&gt;Urban Ad Blocker: gcogpdjkkamgkakkjgeefgpcheonclca&lt;/item&gt;
      &lt;item&gt;1ClickVPN Proxy for Edge: deopfbighgnpgfmhjeccdifdmhcjckoe&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;â&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.koi.ai/blog/urban-vpn-browser-extension-ai-conversations-data-collection"/><published>2025-12-16T03:03:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46284658</id><title>SHARP, an approach to photorealistic view synthesis from a single image</title><updated>2025-12-16T10:13:15.865046+00:00</updated><content>&lt;doc fingerprint="b4c1e2802635c4d6"&gt;
  &lt;main&gt;
    &lt;p&gt;Lars Mescheder, Wei Dong, Shiwei Li, Xuyang Bai, Marcel Santos, Peiyun Hu, Bruno Lecouat, Mingmin Zhen,&lt;/p&gt;
    &lt;p&gt;Amaël Delaunoy, Tian Fang, Yanghai Tsin, Stephan R. Richter, Vladlen Koltun&lt;/p&gt;
    &lt;p&gt;Apple&lt;/p&gt;
    &lt;p&gt;We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25–34% and DISTS by 21–43% versus the best prior model, while lowering the synthesis time by three orders of magnitude.&lt;/p&gt;
    &lt;p&gt;SHARP synthesizes a photorealistic 3D representation from a single photograph in less than a second. The synthesized representation supports high-resolution rendering of nearby views, with sharp details and fine structures, at more than 100 frames per second on a standard GPU. We illustrate on photographs from Unsplash.&lt;/p&gt;
    &lt;code&gt;@inproceedings{Sharp2025:arxiv,
  title      = {Sharp Monocular View Synthesis in Less Than a Second},
  author     = {Lars Mescheder and Wei Dong and Shiwei Li and Xuyang Bai and Marcel Santos and Peiyun Hu and Bruno Lecouat and Mingmin Zhen and Ama\"{e}l Delaunoyand Tian Fang and Yanghai Tsin and Stephan R. Richter and Vladlen Koltun},
  journal    = {arXiv preprint arXiv:2512.10685},
  year       = {2025},
  url        = {https://arxiv.org/abs/2512.10685},
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://apple.github.io/ml-sharp/"/><published>2025-12-16T04:06:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46284897</id><title>Erdős Problem #1026</title><updated>2025-12-16T10:13:15.736461+00:00</updated><content>&lt;doc fingerprint="a098d6150ae7afb1"&gt;
  &lt;main&gt;&lt;p&gt;Problem 1026 on the Erdős problem web site recently got solved through an interesting combination of existing literature, online collaboration, and AI tools. The purpose of this blog post is to try to tell the story of this collaboration, and also to supply a complete proof.&lt;/p&gt;&lt;p&gt;The original problem of Erdős, posed in 1975, is rather ambiguous. Erdős starts by recalling his famous theorem with Szekeres that says that given a sequence of distinct real numbers, one can find a subsequence of length which is either increasing or decreasing; and that one cannot improve the to , by considering for instance a sequence of blocks of length , with the numbers in each block decreasing, but the blocks themselves increasing. He also noted a result of Hanani that every sequence of length can be decomposed into the union of monotone sequences. He then wrote “As far as I know the following question is not yet settled. Let be a sequence of distinct numbers, determine&lt;/p&gt;where the maximum is to be taken over all monotonic sequences “.&lt;p&gt;This problem was added to the Erdős problem site on September 12, 2025, with a note that the problem was rather ambiguous. For any fixed , this is an explicit piecewise linear function of the variables that could be computed by a simple brute force algorithm, but Erdős was presumably seeking optimal bounds for this quantity under some natural constraint on the . The day the problem was posted, Desmond Weisenberg proposed studying the quantity , defined as the largest constant such that&lt;/p&gt;for all choices of (distinct) real numbers . Desmond noted that for this formulation one could assume without loss of generality that the were positive, since deleting negative or vanishing does not decrease the left-hand side and does not increase the right-hand side. By a limiting argument one could also allow collisions between the , so long as one interpreted monotonicity in the weak sense.&lt;p&gt;Though not stated on the web site, one can formulate this problem in game theoretic terms. Suppose that Alice has a stack of coins for some large . She divides the coins into piles of consisting of coins each, so that . She then passes the piles to Bob, who is allowed to select a monotone subsequence of the piles (in the weak sense) and keep all the coins in those piles. What is the largest fraction of the coins that Bob can guarantee to keep, regardless of how Alice divides up the coins? (One can work with either a discrete version of this problem where the are integers, or a continuous one where the coins can be split fractionally, but in the limit the problems can easily be seen to be equivalent.)&lt;/p&gt;&lt;p&gt;AI-generated images continue to be problematic for a number of reasons, but here is one such image that somewhat manages at least to convey the idea of the game:&lt;/p&gt;&lt;p&gt;For small , one can work out by hand. For , clearly : Alice has to put all the coins into one pile, which Bob simply takes. Similarly : regardless of how Alice divides the coins into two piles, the piles will either be increasing or decreasing, so in either case Bob can take both. The first interesting case is . Bob can again always take the two largest piles, guaranteeing himself of the coins. On the other hand, if Alice almost divides the coins evenly, for instance into piles for some small , then Bob cannot take all three piles as they are non-monotone, and so can only take two of them, allowing Alice to limit the payout fraction to be arbitrarily close to . So we conclude that .&lt;/p&gt;&lt;p&gt;An hour after Desmond’s comment, Stijn Cambie noted (though not in the language I used above) that a similar construction to the one above, in which Alice divides the coins into pairs that are almost even, in such a way that the longest monotone sequence is of length , gives the upper bound . It is also easy to see that is a non-increasing function of , so this gives a general bound . Less than an hour after that, Wouter van Doorn noted that the Hanani result mentioned above gives the lower bound , and posed the problem of determining the asymptotic limit of as , given that this was now known to range between and . This version was accepted by Thomas Bloom, the moderator of the Erdős problem site, as a valid interpretation of the original problem.&lt;/p&gt;&lt;p&gt;The next day, Stijn computed the first few values of exactly:&lt;/p&gt;While the general pattern was not yet clear, this was enough data for Stijn to conjecture that , which would also imply that as . (EDIT: as later located by an AI deep research tool, this conjecture was also made in Section 12 of this 1980 article of Steele.) Stijn also described the extremizing sequences for this range of , but did not continue the calculation further (a naive computation would take runtime exponential in , due to the large number of possible subsequences to consider).&lt;p&gt;The problem then lay dormant for almost two months, until December 7, 2025, in which Boris Alexeev, as part of a systematic sweep of the Erdős problems using the AI tool Aristotle, was able to get this tool to autonomously solve this conjecture in the proof assistant language Lean. The proof converted the problem to a rectangle-packing problem.&lt;/p&gt;&lt;p&gt;This was one further addition to a recent sequence of examples where an Erdős problem had been automatically solved in one fashion or another by an AI tool. Like the previous cases, the proof turned out to not be particularly novel. Within an hour, Koishi Chan gave an alternate proof deriving the required bound from the original Erdős-Szekeres theorem by a standard “blow-up” argument which we can give here in the Alice-Bob formulation. Take a large , and replace each pile of coins with new piles, each of size , chosen so that the longest monotone subsequence in this collection is . Among all the new piles, the longest monotone subsequence has length . Applying Erdős-Szekeres, one concludes the bound&lt;/p&gt;and on canceling the ‘s, sending , and applying Cauchy-Schwarz, one obtains (in fact the argument gives for all ).&lt;p&gt;Once this proof was found, it was natural to try to see if it had already appeared in the literature. AI deep research tools have successfully located such prior literature in the past, but in this case they did not succeed, and a more “old-fashioned” Google Scholar job turned up some relevant references: a 2016 paper by Tidor, Wang and Yang contained this precise result, citing an earlier paper of Wagner as inspiration for applying “blowup” to the Erdős-Szekeres theorem.&lt;/p&gt;&lt;p&gt;But the story does not end there! Upon reading the above story the next day, I realized that the problem of estimating was a suitable task for AlphaEvolve, which I have used recently as mentioned in this previous post. Specifically, one could task to obtain upper bounds on by directing it to produce real numbers (or integers) summing up to a fixed sum (I chose ) with a small a value of as possible. After an hour of run time, AlphaEvolve produced the following upper bounds on for , with some intriguingly structured potential extremizing solutions:&lt;/p&gt;The numerical scores (divided by ) were pretty obviously trying to approximate simple rational numbers. There were a variety of ways (including modern AI) to extract the actual rational numbers they were close to, but I searched for a dedicated tool and found this useful little web page of John Cook that did the job: I could not immediately see the pattern here, but after some trial and error in which I tried to align numerators and denominators, I eventually organized this sequence into a more suggestive form: This gave a somewhat complicated but predictable conjecture for the values of the sequence . On posting this, Boris found a clean formulation of the conjecture, namely that whenever and . After a bit of effort, he also produced an explicit upper bound construction:&lt;quote&gt;Proposition 1 If and , then .&lt;/quote&gt;&lt;p&gt;Proof: Consider a sequence of numbers clustered around the “red number” and “blue number” , consisting of blocks of “blue” numbers, followed by blocks of “red” numbers, and then further blocks of “blue” numbers. When , one should take all blocks to be slightly decreasing within each block, but the blue blocks should be are increasing between each other, and the red blocks should also be increasing between each other. When , all of these orderings should be reversed. The total number of elements is indeed&lt;/p&gt;and the total sum is close to With this setup, one can check that any monotone sequence consists either of at most red elements and at most blue elements, or no red elements and at most blue elements, in either case giving a monotone sum that is bounded by either or giving the claim.&lt;p&gt;Here is a figure illustrating the above construction in the case (obtained after starting with a ChatGPT-provided file and then manually fixing a number of placement issues):&lt;/p&gt;&lt;p&gt;Here is a plot of (produced by ChatGPT Pro), showing that it is basically a piecewise linear approximation to the square root function:&lt;/p&gt;&lt;p&gt;Shortly afterwards, Lawrence Wu clarified the connection between this problem and a square packing problem, which was also due to Erdős (Problem 106). Let be the least number such that, whenever one packs squares of sidelength into a square of sidelength , with all sides parallel to the coordinate axes, one has&lt;/p&gt;&lt;quote&gt;Proposition 2 For any , one has&lt;/quote&gt;&lt;p&gt;Proof: Given and , let be the maximal sum over all increasing subsequences ending in , and be the maximal sum over all decreasing subsequences ending in . For , we have either (if ) or (if ). In particular, the squares and are disjoint. These squares pack into the square , so by definition of , we have&lt;/p&gt;and the claim follows.&lt;p&gt;This idea of using packing to prove Erdős-Szekeres type results goes back to a 1959 paper of Seidenberg, although it was a discrete rectangle-packing argument that was not phrased in such an elegantly geometric form. It is possible that Aristotle was “aware” of the Seidenberg argument via its training data, as it had incorporated a version of this argument in its proof.&lt;/p&gt;&lt;p&gt;Here is an illustration of the above argument using the AlphaEvolve-provided example&lt;/p&gt;&lt;p&gt;for to convert it to a square packing (image produced by ChatGPT Pro):&lt;/p&gt;&lt;p&gt;At this point, Lawrence performed another AI deep research search, this time successfully locating a paper from just last year by Baek, Koizumi, and Ueoro, where they show that&lt;/p&gt;&lt;quote&gt;Theorem 3 For any , one has&lt;/quote&gt;&lt;p&gt;which, when combined with a previous argument of Praton, implies&lt;/p&gt;&lt;quote&gt;Theorem 4 For any and with , one has&lt;/quote&gt;&lt;p&gt;This proves the conjecture!&lt;/p&gt;&lt;p&gt;There just remained the issue of putting everything together. I did feed all of the above information into a large language model, which was able to produce a coherent proof of (1) assuming the results of Baek-Koizumi-Ueoro and Praton. Of course, LLM outputs are prone to hallucination, so it would be preferable to formalize that argument in Lean, but this looks quite doable with current tools, and I expect this to be accomplished shortly. But I was also able to reproduce the arguments of Baek-Koizumi-Ueoro and Praton, which I include below for completeness.&lt;/p&gt;&lt;p&gt;Proof: (Proof of Theorem 3, adapted from Baek-Koizumi-Ueoro) We can normalize . It then suffices to show that if we pack the length torus by axis-parallel squares of sidelength , then&lt;/p&gt;&lt;p&gt;Pick . Then we have a grid&lt;/p&gt;inside the torus. The square, when restricted to this grid, becomes a discrete rectangle for some finite sets with By the packing condition, we have From (2) we have hence Inserting this bound and rearranging, we conclude that Taking the supremum over we conclude that so by the pigeonhole principle one of the summands is at most . Let’s say it is the former, thus In particular, the average value of is at most . But this can be computed to be , giving the claim. Similarly if it is the other sum.&lt;p&gt;UPDATE: Actually, the above argument also proves Theorem 4 with only minor modifications. Nevertheless, we give the original derivation of Theorem 4 using the embedding argument of Praton below for sake of completeness.&lt;/p&gt;&lt;p&gt;Proof: (Proof of Theorem 4, adapted from Praton) We write with . We can rescale so that the square one is packing into is . Thus, we pack squares of sidelength into , and our task is to show that&lt;/p&gt;We pick a large natural number (in particular, larger than ), and consider the three nested squares We can pack by unit squares. We can similarly pack into squares of sidelength . All in all, this produces squares, of total length Applying Theorem 3, we conclude that The right-hand side is and the left-hand side similarly evaluates to and so we simplify to Sending , we obtain the claim. One striking feature of this story for me is how important it was to have a diverse set of people, literature, and tools to attack this problem. To be able to state and prove the precise formula for required multiple observations, including some version of the following:&lt;list rend="ul"&gt;&lt;item&gt;The sequence can be numerically computed as a sequence of rational numbers.&lt;/item&gt;&lt;item&gt;When appropriately normalized and arranged, visible patterns in this sequence appear that allow one to conjecture the form of the sequence.&lt;/item&gt;&lt;item&gt;This problem is a weighted version of the Erdős-Szekeres theorem.&lt;/item&gt;&lt;item&gt;Among the many proofs of the Erdős-Szekeres theorem is the proof of Seidenberg in 1959, which can be interpreted as a discrete rectangle packing argument.&lt;/item&gt;&lt;item&gt;This problem can be reinterpreted as a continuous square packing problem, and in fact is closely related to (a generalized axis-parallel form of) Erdős problem 106, which concerns such packings.&lt;/item&gt;&lt;item&gt;The axis-parallel form of Erdős problem 106 was recently solved by Baek-Koizumi-Ueoro.&lt;/item&gt;&lt;item&gt;The paper of Praton shows that Erdős Problem 106 implies the generalized version needed for this problem. This implication specializes to the axis-parallel case.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Another key ingredient was the balanced AI policy on the Erdős problem website, which encourages disclosed AI usage while strongly discouraging undisclosed use. To quote from that policy: “Comments prepared with the assistance of AI are permitted, provided (a) this is disclosed, (b) the contents (including mathematics, code, numerical data, and the existence of relevant sources) have been carefully checked and verified by the user themselves without the assistance of AI, and (c) the comment is not unreasonably long.”&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/"/><published>2025-12-16T04:49:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46285319</id><title>Bonsai: A Voxel Engine, from scratch</title><updated>2025-12-16T10:13:15.277364+00:00</updated><content>&lt;doc fingerprint="5a19635f49de9c16"&gt;
  &lt;main&gt;
    &lt;p&gt;Bonsai is a voxel engine in a pot. It's been tended to with love and care over the years. It started out as a learning excercise, and has taught me the value of simplicity.&lt;/p&gt;
    &lt;p&gt;Bonsai supports massive worlds. The current version supports a maximum world size of ~1 billion blocks, cubed. At one block per meter, that's the distance from earth to the moon, 2600 times, in every direction. The view distance is the entire world, all the time. Yes, you read that right. In Bonsai, you can see in a straight line from Jupiter to the sun.&lt;/p&gt;
    &lt;p&gt;Bonsai terrain generation is fully procedural, and user configurable. Terrain is generated on the GPU using regular glsl shaders. Anything you can do in a shader, you can do in a Bonsai terrain generator.&lt;/p&gt;
    &lt;p&gt;The current version is 2.0.0-prealpha-rc0, which can be found by joining the Discord. This version is a large rewrite of several core systems, including the world generation, editor and parts of the renderer.&lt;/p&gt;
    &lt;p&gt;In its current state, the engine is effectively a terrain generator and editor. For details on remaing work, see Roadmap to v2.0.0.&lt;/p&gt;
    &lt;p&gt;Bonsai, and nearly all it's dependencies, are written completely from scratch. One external dependency is the C runtime library for program startup. There is a back-burner task to remove the CRT entirely, athough it's unclear when/if anyone will ever get around to it.&lt;/p&gt;
    &lt;p&gt;The only external requirements to build Bonsai are clang++ (&amp;gt;= version 18.1) and a few appropriate system headers.&lt;/p&gt;
    &lt;p&gt;Grab pre-built binaries &amp;amp; assets from the Latest Releases for your platform of your choice (as long as your platform of choice is Windows or Linux) ;)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deferred Shading&lt;/item&gt;
      &lt;item&gt;HDR Lighting&lt;/item&gt;
      &lt;item&gt;Order-independant Transparency&lt;/item&gt;
      &lt;item&gt;Lighting Bloom&lt;/item&gt;
      &lt;item&gt;Shadow Mapping&lt;/item&gt;
      &lt;item&gt;Screen Space Ambient Occlusion&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hot Shader &amp;amp; Game-code Reloading&lt;/item&gt;
      &lt;item&gt;Async Job System&lt;/item&gt;
      &lt;item&gt;Entities&lt;/item&gt;
      &lt;item&gt;Collision&lt;/item&gt;
      &lt;item&gt;Transparent &amp;amp; Emissive Particles&lt;/item&gt;
      &lt;item&gt;UI Framework&lt;/item&gt;
      &lt;item&gt;Asset Loaders&lt;/item&gt;
      &lt;item&gt;Primitive Physics&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully programmable GPU-based terrain generation&lt;/item&gt;
      &lt;item&gt;Batteries-included library of pre-built terrain shaders&lt;/item&gt;
      &lt;item&gt;1D, 2D and 3D noise library&lt;/item&gt;
      &lt;item&gt;Terrain derivitives available in second-stage terrain "decoration"&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CSG-like SDF world editing&lt;/item&gt;
      &lt;item&gt;Library of primitive shapes (rect, sphere, line, cylinder .. etc)&lt;/item&gt;
      &lt;item&gt;SDF brush-based texturing of primitives&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Layer-based brush GUI&lt;/item&gt;
      &lt;item&gt;(coming soon) glsl brush shaders&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manual Instrumentation&lt;/item&gt;
      &lt;item&gt;Memory allocation tracking&lt;/item&gt;
      &lt;item&gt;Multithreaded callgraph tracing&lt;/item&gt;
      &lt;item&gt;Context Switches (windows only)&lt;/item&gt;
      &lt;item&gt;Physical Core (windows only)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[ ] HRC : https://github.com/entropylost/amitabha&lt;/p&gt;
    &lt;p&gt;[ ] SSR : https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html&lt;/p&gt;
    &lt;p&gt;[ ] Screen-space lines : https://mattdesl.svbtle.com/drawing-lines-is-hard&lt;/p&gt;
    &lt;p&gt;[ ] Better shadows : https://developer.nvidia.com/gpugems/gpugems3/part-ii-light-and-shadows/chapter-8-summed-area-variance-shadow-maps&lt;/p&gt;
    &lt;p&gt;[ ] Screen Space Shadows : https://panoskarabelas.com/posts/screen_space_shadows/&lt;/p&gt;
    &lt;p&gt;[ ] Motion Blur : https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-27-motion-blur-post-processing-effect&lt;/p&gt;
    &lt;p&gt;[ ] TAA?&lt;/p&gt;
    &lt;p&gt;[ ] FXAA : http://blog.simonrodriguez.fr/articles/2016/07/implementing_fxaa.html&lt;/p&gt;
    &lt;p&gt;[ ] Water : https://www.youtube.com/watch?v=5yhDb9dzJ58&lt;/p&gt;
    &lt;p&gt;[ ] Fluids : https://andrewkchan.dev/posts/fire.html&lt;/p&gt;
    &lt;p&gt;[ ] Remove meshing entirely? https://www.youtube.com/watch?v=4xs66m1Of4A&lt;/p&gt;
    &lt;p&gt;[ ] Lumen-style GI screen-space radiance caching : https://www.youtube.com/watch?v=2GYXuM10riw&lt;/p&gt;
    &lt;p&gt;[ ] Erosion simulation&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://inria.hal.science/hal-01262376/document&lt;/item&gt;
      &lt;item&gt;https://xing-mei.github.io/files/erosion.pdf&lt;/item&gt;
      &lt;item&gt;https://nickmcd.me/2020/04/15/procedural-hydrology/&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[ ] Biomes&lt;/p&gt;
    &lt;p&gt;[ ] Meshing&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Isotropic surface meshing&lt;/item&gt;
      &lt;item&gt;https://graphics.stanford.edu/courses/cs164-10-spring/Handouts/isotropic.pdf&lt;/item&gt;
      &lt;item&gt;https://inria.hal.science/inria-00071612/document&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[ ] MCA importer&lt;/p&gt;
    &lt;p&gt;[ ] Sound : mp3, ogg, ..? decompresser&lt;/p&gt;
    &lt;p&gt;[ ] Better low-discrepency sequences : https://blog.demofox.org/2017/05/29/when-random-numbers-are-too-random-low-discrepancy-sequences/&lt;/p&gt;
    &lt;p&gt;[ ] Better disk/sphere sampling patterns : https://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/&lt;/p&gt;
    &lt;p&gt;[ ] Better hash function! : https://nullprogram.com/blog/2018/07/31/&lt;/p&gt;
    &lt;p&gt;[ ] Better GPU hashing! : https://arugl.medium.com/hash-noise-in-gpu-shaders-210188ac3a3e&lt;/p&gt;
    &lt;p&gt;[ ] Hash-trie as alternative to a table : https://nullprogram.com/blog/2023/09/30/&lt;/p&gt;
    &lt;p&gt;[ ] Octree ? https://graphics.tudelft.nl/Publications-new/2020/CBE20/ModifyingCompressedVoxels-main.pdf&lt;/p&gt;
    &lt;p&gt;[ ] Better floating-point rng : https://www.corsix.org/content/higher-quality-random-floats&lt;/p&gt;
    &lt;p&gt;[ ] Better greedy meshing? https://www.youtube.com/watch?v=4xs66m1Of4A&lt;/p&gt;
    &lt;p&gt;[ ] More interpolation goodies : https://paulbourke.net/miscellaneous/interpolation/&lt;/p&gt;
    &lt;p&gt;[ ] Better (faster) Sin/Cos ? https://www.shadertoy.com/view/432yWW&lt;/p&gt;
    &lt;p&gt;[ ] Look into using this Intel tooling for dual CPU/GPU world-gen? https://www.intel.com/content/dam/develop/external/us/en/documents/spir-vtointe-ispcgpu-compute-on-the-cpu.pdf https://ispc.github.io/&lt;/p&gt;
    &lt;p&gt;[ ] Improve the ETW layer : https://github.com/bombomby/optick/blob/master/src/optick_core.win.h&lt;/p&gt;
    &lt;p&gt;[ ] GPU Profiling : https://www.khronos.org/opengl/wiki/Query_Object&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/scallyw4g/bonsai"/><published>2025-12-16T06:06:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46285376</id><title>Children with cancer scammed out of millions fundraised for their treatment</title><updated>2025-12-16T10:13:15.154687+00:00</updated><content>&lt;doc fingerprint="274d9985a18985a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Children with cancer scammed out of millions fundraised for their treatment, BBC finds&lt;/head&gt;
    &lt;p&gt;Warning: Disturbing content&lt;/p&gt;
    &lt;p&gt;A little boy faces the camera. He is pale and has no hair.&lt;/p&gt;
    &lt;p&gt;"I am seven years old and I have cancer," he says. "Please save my life and help me."&lt;/p&gt;
    &lt;p&gt;Khalil - who is pictured above in a still from the film - didn't want to record this, says his mother Aljin. She had been asked to shave his head, and then a film crew hooked him up to a fake drip, and asked his family to pretend it was his birthday. They had given him a script to learn and recite in English.&lt;/p&gt;
    &lt;p&gt;And he didn't like it, says Aljin, when chopped onions were placed next to him, and menthol put under his eyes, to make him cry.&lt;/p&gt;
    &lt;p&gt;Aljin agreed to it because, although the set-up was fake, Khalil really did have cancer. She was told this video would help crowdfund money for better treatment. And it did raise funds - $27,000 (£20,204), according to a campaign we found in Khalil's name.&lt;/p&gt;
    &lt;p&gt;But Aljin was told the campaign had failed, and says she received none of this money - just a $700 (£524) filming fee on the day. One year later, Khalil died.&lt;/p&gt;
    &lt;p&gt;Across the world, desperate parents of sick or dying children are being exploited by online scam campaigns, the BBC World Service has discovered. The public have given money to the campaigns, which claim to be fundraising for life-saving treatment. We have identified 15 families who say they got little to nothing of the funds raised and often had no idea the campaigns had even been published, despite undergoing harrowing filming.&lt;/p&gt;
    &lt;p&gt;Nine families we spoke to - whose campaigns appear to be products of the same scam network - say they never received anything at all of the $4m (£2.9m) apparently raised in their names.&lt;/p&gt;
    &lt;p&gt;A whistleblower from this network told us they had looked for "beautiful children" who "had to be three to nine years old… without hair".&lt;/p&gt;
    &lt;p&gt;We have identified a key player in the scam as an Israeli man living in Canada called Erez Hadari.&lt;/p&gt;
    &lt;p&gt;Our investigation began in October 2023, when a distressing YouTube advert caught our attention. "I don't want to die," a girl called Alexandra from Ghana sobbed. "My treatments cost a lot."&lt;/p&gt;
    &lt;p&gt;A crowdfunding campaign for her appeared to have raised nearly $700,000 (£523,797).&lt;/p&gt;
    &lt;p&gt;We saw more videos of sick children from around the world on YouTube, all strikingly similar - slickly produced, and seemingly having raised huge amounts of money. They all conveyed a sense of urgency, using emotive language.&lt;/p&gt;
    &lt;p&gt;We decided to investigate further.&lt;/p&gt;
    &lt;p&gt;The campaigns with the biggest apparent international reach were under the name of an organisation called Chance Letikva (Chance for Hope, in English) - registered in Israel and the US.&lt;/p&gt;
    &lt;p&gt;Identifying the children featured was difficult. We used geolocation, social media and facial recognition software to find their families, based as far apart as Colombia and the Philippines.&lt;/p&gt;
    &lt;p&gt;While it was difficult to know for sure if the campaign websites' cash totals were genuine, we donated small amounts to two of them and saw the totals increase by those amounts.&lt;/p&gt;
    &lt;p&gt;We also spoke to someone who says she gave $180 (£135) to Alexandra's campaign and was then inundated with requests for more, all written as if sent by Alexandra and her father.&lt;/p&gt;
    &lt;p&gt;In the Philippines, Aljin Tabasa told us her son Khalil had fallen ill just after his seventh birthday.&lt;/p&gt;
    &lt;p&gt;"When we found out it was cancer it felt like my whole world shattered," she says.&lt;/p&gt;
    &lt;p&gt;Aljin says treatment at their local hospital in the city of Cebu was slow, and she had messaged everyone she could think of for help. One person put her in touch with a local businessman called Rhoie Yncierto - who asked for a video of Khalil which, looking back, Aljin realises was essentially an audition.&lt;/p&gt;
    &lt;p&gt;Another man then arrived from Canada in December 2022, introducing himself as "Erez". He paid her the filming fee up front, she says, promising a further $1,500 (£1,122) a month if the film generated lots of donations.&lt;/p&gt;
    &lt;p&gt;Erez directed Khalil's film at a local hospital, asking for retake after retake - the shoot taking 12 hours, Aljin says.&lt;/p&gt;
    &lt;p&gt;Months later, the family say they had still not heard how the video had performed. Aljin messaged Erez, who told her the video "wasn't successful".&lt;/p&gt;
    &lt;p&gt;"So as I understood it, the video just didn't make any money," she says.&lt;/p&gt;
    &lt;p&gt;But we told her the campaign had apparently collected $27,000 (£20,204) as of November 2024, and was still online.&lt;/p&gt;
    &lt;p&gt;"If I had known the money we had raised, I can't help but think that maybe Khalil would still be here," Aljin says. "I don't understand how they could do this to us."&lt;/p&gt;
    &lt;p&gt;When asked about his role in the filming, Rhoie Yncierto denied telling families to shave their children's heads for filming and said he had received no payment for recruiting families.&lt;/p&gt;
    &lt;p&gt;He said he had "no control" over what happened with the funds and had no contact with the families after the day of filming. When we told him they had not received any of the campaigns' donations he said he was "puzzled" and was "very sorry for the families".&lt;/p&gt;
    &lt;p&gt;Nobody named Erez appears on registration documents for Chance Letikva. But two of its campaigns we investigated had also been promoted by another organisation called Walls of Hope, registered in Israel and Canada. Documents list the director in Canada as Erez Hadari.&lt;/p&gt;
    &lt;p&gt;Photos of him online show him at Jewish religious events in the Philippines, New York and Miami. We showed Aljin, and she said it was the same person she had met.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Outside the UK, watch the film on BBC World Service YouTube&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We asked Mr Hadari about his involvement in a campaign in the Philippines. He did not respond.&lt;/p&gt;
    &lt;p&gt;We visited further families whose campaigns were either organised by, or linked to, Mr Hadari - one in a remote indigenous community in Colombia, and another in Ukraine.&lt;/p&gt;
    &lt;p&gt;As with Khalil's case, local fixers had got in touch to offer help. The children were filmed and made to cry or fake tears for a nominal fee, but never received any further money.&lt;/p&gt;
    &lt;p&gt;In Sucre, north-west Colombia, Sergio Care says he initially refused this help. He had been approached by someone called Isabel, he says, who offered financial assistance after his eight-year-old daughter, Ana, was diagnosed with a malignant brain tumour.&lt;/p&gt;
    &lt;p&gt;But Isabel came looking for him at the hospital treating Ana, he says, accompanied by a man who said he worked for an international NGO.&lt;/p&gt;
    &lt;p&gt;The description Sergio gave of the man matched that of Erez Hadari - he then recognised him in a photo we showed him.&lt;/p&gt;
    &lt;p&gt;"He gave me hope... I didn't have any money for the future."&lt;/p&gt;
    &lt;p&gt;Demands on the family did not end with the filming.&lt;/p&gt;
    &lt;p&gt;Isabel kept ringing, Sergio says, demanding more photos of Ana in hospital. When Sergio didn't reply, Isabel started messaging Ana herself - voice notes we have heard.&lt;/p&gt;
    &lt;p&gt;Ana told Isabel she had no more photos to send. Isabel replied: "This is very bad Ana, very bad indeed."&lt;/p&gt;
    &lt;p&gt;In January this year, Ana - now fully recovered - tried to find out what happened to the money promised.&lt;/p&gt;
    &lt;p&gt;"That foundation disappeared," Isabel told her in a voice note. "Your video was never uploaded. Never. Nothing was done with it, you hear?"&lt;/p&gt;
    &lt;p&gt;But we could see the video had been uploaded and, by April 2024, appeared to have raised nearly $250,000 (£187,070).&lt;/p&gt;
    &lt;p&gt;In October, we persuaded Isabel Hernandez to speak to us over video link.&lt;/p&gt;
    &lt;p&gt;A friend from Israel, she explained, had introduced her to someone offering work for "a foundation" looking to help children with cancer. She refused to name who she worked for.&lt;/p&gt;
    &lt;p&gt;She was told only one of the campaigns she helped organise was published, she says, and that it had not been successful.&lt;/p&gt;
    &lt;p&gt;We showed Isabel that two campaigns had in fact been uploaded - one of them apparently raising more than $700,000 (£523,797).&lt;/p&gt;
    &lt;p&gt;"I need to apologise to [the families]," she said. "If I'd known what was going on, I would not have been able to do something like this."&lt;/p&gt;
    &lt;p&gt;In Ukraine, we discovered that the person who approached the mother of a sick child was actually employed in the place where the campaign video was filmed.&lt;/p&gt;
    &lt;p&gt;Tetiana Khaliavka organised a shoot with five-year-old Viktoriia, who has brain cancer, at Angelholm Clinic in Chernivtsi.&lt;/p&gt;
    &lt;p&gt;One Facebook post linked to Chance Letikva's campaign shows Viktoriia and her mother Olena Firsova, sitting on a bed. "I see your efforts to save my daughter, and it deeply moves us all. It's a race against time to raise the amount needed for Viktoriia's treatments," reads the caption.&lt;/p&gt;
    &lt;p&gt;Olena says she never wrote or even said these words and had no idea the campaign had been uploaded.&lt;/p&gt;
    &lt;p&gt;It appears to have raised more than €280,000 (£244,000).&lt;/p&gt;
    &lt;p&gt;Tetiana, we were told, was in charge of advertising and communications at Angelholm.&lt;/p&gt;
    &lt;p&gt;The clinic recently told the BBC it didn't approve filming on its premises - adding: "The clinic has never participated in, nor supported, any fundraising initiatives organised by any organisation."&lt;/p&gt;
    &lt;p&gt;Angelholm says it has terminated Tetiana Khaliavka's employment.&lt;/p&gt;
    &lt;p&gt;Olena showed us the contract she had been asked to sign.&lt;/p&gt;
    &lt;p&gt;In addition to the family's $1,500 (£1,122) filming fee on the day, it states they would get $8,000 (£5,986) once the fundraising goal was met. The amount for the goal, however, has been left blank.&lt;/p&gt;
    &lt;p&gt;The contract showed an address in New York for Chance Letikva. On the organisation's website, there is another - in Beit Shemesh, about an hour from Jerusalem. We travelled to both, but found no sign of it.&lt;/p&gt;
    &lt;p&gt;And we discovered Chance Letikva seems to be one of many such organisations.&lt;/p&gt;
    &lt;p&gt;The man who filmed Viktoriia's campaign told our producer - who was posing as a friend of a sick child - that he works for other similar organisations.&lt;/p&gt;
    &lt;p&gt;"Each time, it's a different one," the man - who had introduced himself as "Oleh" - told her. "I hate to put it this way, but they work kind of like a conveyor belt."&lt;/p&gt;
    &lt;p&gt;"About a dozen similar companies" requested "material", he said, naming two of them - Saint Teresa and Little Angels, both registered in the US.&lt;/p&gt;
    &lt;p&gt;When we checked their registration documents, we once again found Erez Hadari's name.&lt;/p&gt;
    &lt;p&gt;What is not clear is where the money raised for the children has gone.&lt;/p&gt;
    &lt;p&gt;More than a year after Viktoriia's filming, her mother Olena rang Oleh, who seems to go by Alex Kohen online, to find out. Shortly afterwards, someone from Chance Letikva called to say the donations had paid for advertising, she says.&lt;/p&gt;
    &lt;p&gt;This is also what Mr Hadari told Aljin, Khalil's mother, when she confronted him over the phone.&lt;/p&gt;
    &lt;p&gt;"There is cost of advertising. So the company lost money," Mr Hadari told her, without giving any evidence to support this.&lt;/p&gt;
    &lt;p&gt;Charity experts told us advertising should not amount to more than 20% of the total raised by campaigns.&lt;/p&gt;
    &lt;p&gt;Someone previously employed to recruit children for Chance Letikva campaigns told us how those featured had been chosen.&lt;/p&gt;
    &lt;p&gt;They had been asked to visit oncology clinics, they said - speaking on condition of anonymity.&lt;/p&gt;
    &lt;p&gt;"They were always looking for beautiful children with white skin. The child had to be three to nine years old. They had to know how to speak well. They had to be without hair," they told us.&lt;/p&gt;
    &lt;p&gt;"They asked me for photos, to see if the child is right, and I would send it to Erez."&lt;/p&gt;
    &lt;p&gt;The whistleblower told us Mr Hadari would then send the photo on to someone else, in Israel, whose name they were never told.&lt;/p&gt;
    &lt;p&gt;As for Mr Hadari himself, we tried to reach him at two addresses in Canada but could not find him. He replied to one voice note we had sent him - asking about the money he had been apparently crowdfunding - by saying the organisation "has never been active", without specifying which one. He did not respond to a further voice note and letter laying out all our questions and allegations.&lt;/p&gt;
    &lt;p&gt;Campaigns set up by Chance Letikva for two children who died - Khalil and a Mexican boy called Hector - still appear to be accepting money.&lt;/p&gt;
    &lt;p&gt;Chance Letikva's US branch appears to be linked to a new organisation called Saint Raphael, which has produced more campaigns - at least two of which seem to have been filmed in Angelholm clinic in Ukraine, as the clinic's distinctive wood panelling and staff uniforms can be seen.&lt;/p&gt;
    &lt;p&gt;Olena, Viktoriia's mother, says her daughter has been diagnosed with another brain tumour. She says she is sickened by the findings of our investigation.&lt;/p&gt;
    &lt;p&gt;"When your child is… hanging on the edge of life, and someone's out there, making money off that. Well, it's filthy. It's blood money."&lt;/p&gt;
    &lt;p&gt;The BBC contacted Tetiana Khaliavka and Alex Kohen, and the organisations Chance Letikva, Walls of Hope, Saint Raphael, Little Angels and Saint Teresa - inviting them to respond to the allegations made against them. None of them replied.&lt;/p&gt;
    &lt;p&gt;The Israeli Corporations Authority, which oversees the country's non-profit organisations, told us that if it has evidence founders are using entities as "a cover for illegal activity", then registration inside Israel may be denied and the founder could be barred from working in the sector.&lt;/p&gt;
    &lt;p&gt;UK regulator, the Charity Commission, advises those wishing to donate to charities to check that those associations are registered, and that the appropriate fundraising regulator should be contacted if in doubt.&lt;/p&gt;
    &lt;p&gt;Additional reporting by: Ned Davies, Tracks Saflor, Jose Antonio Lucio, Almudena Garcia-parrado, Vitaliya Kozmenko, Shakked Auerbach, Tom Tzur Wisfelder, Katya Malofieieva, Anastasia Kucher, Alan Pulido and Neil McCarthy&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you have any information to add to this investigation please contact simi@bbc.co.uk&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/ckgz318y8elo"/><published>2025-12-16T06:17:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46285448</id><title>O'saasy License Agreement</title><updated>2025-12-16T10:13:14.982508+00:00</updated><content>&lt;doc fingerprint="397c7755846b53b8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;O'Saasy&lt;/head&gt;
    &lt;head rend="h2"&gt;License Agreement&lt;/head&gt;
    &lt;p&gt;Copyright © &amp;lt;Year&amp;gt;, &amp;lt;Copyright Holder&amp;gt;.&lt;/p&gt;
    &lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/item&gt;
      &lt;item&gt;No licensee or downstream recipient may use the Software (including any modified or derivative versions) to directly compete with the original Licensor by offering it to third parties as a hosted, managed, or Software-as-a-Service (SaaS) product or cloud service where the primary value of the service is the functionality of the Software itself.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://osaasy.dev/"/><published>2025-12-16T06:29:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46285535</id><title>A linear-time alternative for Dimensionality Reduction and fast visualisation</title><updated>2025-12-16T10:13:13.521666+00:00</updated><content>&lt;doc fingerprint="a1a6a01b0b669bba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Linear-Time Alternative To t-SNE for Dimensionality Reduction and Fast Visualisation&lt;/head&gt;
    &lt;p&gt;Moving data visualisation from a Python notebook to a web browser usually demands a painful compromise: you either pay for a heavy GPU backend or you force the user to wait while JavaScript struggles through iterative algorithms.&lt;/p&gt;
    &lt;p&gt;This article explores a third option: Sine Landmark Reduction (SLR).&lt;/p&gt;
    &lt;p&gt;SLR is a deterministic, linear-time alternative to t-SNE designed specifically for the browser. It bypasses the heavy optimisation loops of traditional methods by using trilateration against a fixed topological skeleton. The result? A method fast enough to power Thingbook’s DriftMind stack, capable of mapping 9,000 datapoints (at 50 dimensions) into 3D space in under two seconds.&lt;/p&gt;
    &lt;p&gt;We will cover:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why t-SNE/UMAP are a poor fit for the browser&lt;/item&gt;
      &lt;item&gt;The idea of landmarks instead of all-pairs distances&lt;/item&gt;
      &lt;item&gt;How to build a synthetic “sine skeleton” in high-D&lt;/item&gt;
      &lt;item&gt;How linearised trilateration turns distances into coordinates&lt;/item&gt;
      &lt;item&gt;Two important refinements: alpha scaling and distance warping&lt;/item&gt;
      &lt;item&gt;A compact Python implementation of SLR you can experiment with today&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why do most dimensionality-reduction techniques fail in resource-limited environments? (such as your browser…)&lt;/head&gt;
    &lt;p&gt;Methods like t-SNE and UMAP are excellent for static, offline exploration, but they are fundamentally unsuited for rapid, iterative visual inspection. During exploratory analysis, many data-driven decisions depend on immediate feedback, insights that guide the next analytical step or help you assess the operational status of highly complex datasets. When the underlying method cannot deliver results interactively due to memory or compute constraints, the entire exploratory workflow breaks down. Several reasons explain this limitation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They rely on iterative optimisation (gradient descent style loops).&lt;/item&gt;
      &lt;item&gt;They typically need to compare many or all points to each other, leading to O(N²) complexity.&lt;/item&gt;
      &lt;item&gt;For 10,000 points, that’s on the order of 100 million pairwise interactions.&lt;/item&gt;
      &lt;item&gt;In a browser, that means dropped frames, frozen UIs, or shipping the entire dataset to a backend.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For an interactive tool where users drag-and-drop a CSV and expect something to appear almost instantly, we need something closer to O(N): one pass over the points, not N passes.&lt;/p&gt;
    &lt;p&gt;This is the design target for SLR:&lt;lb/&gt;linear time, deterministic, analytic, and simple enough to run in plain JavaScript or WebAssembly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Landmarks Instead of All-Pairs&lt;/head&gt;
    &lt;p&gt;The core idea is simple: Instead of comparing every point to every other point, compare every point to a small, fixed set of landmarks. Imagine placing 100 “radio towers” in high-dimensional space (k=50) to cover all the space. To embed a new point x, you don’t ask&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“how far am I from every other point?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You only ask:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“How far am I from each of these 100 towers?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If we do this for N points, the work is O(N × k). With k fixed and relatively small, this is effectively O(N).&lt;/p&gt;
    &lt;p&gt;The key questions then become:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;How do we choose good landmarks to place my towers?&lt;/item&gt;
      &lt;item&gt;Given only distances to these landmarks, how do we reconstruct a low-dimensional coordinate?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLR answers these with:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A sine-based synthetic skeleton or data-derived skeleton&lt;/item&gt;
      &lt;item&gt;A fast, analytic linearised trilateration step inspired by GPS localisation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Building a Synthetic Sine Skeleton&lt;/head&gt;
    &lt;p&gt;The first way to obtain landmarks is to invent them synthetically, without using any real data points. SLR defines a smooth path through the n-dimensional space using independent sine waves on each dimension:&lt;/p&gt;
    &lt;p&gt;Each coordinate uses its own amplitude, frequency, and phase, drawn from simple uniform distributions. In code:&lt;/p&gt;
    &lt;code&gt;class SineLandmarkReduction:&lt;lb/&gt;    def __init__(self, n_components=2, n_landmarks=50,&lt;lb/&gt;                 random_state=42, synthetic_landmarks=False):&lt;lb/&gt;        self.n_components = n_components&lt;lb/&gt;        self.k = n_landmarks&lt;lb/&gt;        self.synthetic_landmarks = synthetic_landmarks&lt;lb/&gt;        self.rng = np.random.RandomState(random_state)&lt;lb/&gt;&lt;lb/&gt;    def _gamma(self, t, a, omega, phi):&lt;lb/&gt;        """Synthetic sine path function γ(t)."""&lt;lb/&gt;        # result shape: (n_dims, n_landmarks)&lt;lb/&gt;        return a[:, None] * np.sin(omega[:, None] * t + phi[:, None])&lt;/code&gt;
    &lt;p&gt;To build the landmarks:&lt;/p&gt;
    &lt;code&gt;a = self.rng.uniform(0.5, 2.0, n_features)&lt;lb/&gt;omega = self.rng.uniform(0.5, 1.5, n_features)&lt;lb/&gt;phi = self.rng.uniform(0, 2 * np.pi, n_features)&lt;lb/&gt;t = np.linspace(0, 2 * np.pi, self.k)&lt;lb/&gt;&lt;lb/&gt;self.L_high = self._gamma(t, a, omega, phi).T  # shape: (k, n_features)&lt;/code&gt;
    &lt;p&gt;We then sample k points along this path to define the high-dimensional landmarks:&lt;/p&gt;
    &lt;p&gt;Because the curve winds smoothly through the space, the landmarks form a well-spread, continuous loop when projected to 3D subspaces:&lt;/p&gt;
    &lt;p&gt;Why sine waves?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extremely cheap to compute&lt;/item&gt;
      &lt;item&gt;Deterministic given a random seed&lt;/item&gt;
      &lt;item&gt;Naturally explore the space without clustering in arbitrary regions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This mode is ideal when you want a stable, model-driven skeleton that is independent of the dataset.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data-Derived Landmarks and Hybrid Normalisation&lt;/head&gt;
    &lt;p&gt;SLR allows you to skip the automatic skeleton generation and extract the Landmarks from your dataset structure without losing the O(N) complexity. Essentially, this mode lets the landmarks adapt to the data. This is useful when the dataset has a strong cluster structure or an interesting topology that a synthetic curve might miss.&lt;/p&gt;
    &lt;p&gt;The trick is a hybrid normalisation strategy:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Raw selection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Select landmark indices from the unnormalised data.&lt;/item&gt;
      &lt;item&gt;High-variance features dominate cluster structure; staying in raw scale helps us capture that.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Normalised computation&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;After selecting the landmarks, normalise both X and the selected landmarks (e.g. StandardScaler).&lt;/item&gt;
      &lt;item&gt;All features then contribute fairly to Euclidean distances during trilateration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the implementation:&lt;/p&gt;
    &lt;code&gt;if self.synthetic_landmarks:&lt;lb/&gt;    # synthetic branch (see previous section)&lt;lb/&gt;    ...&lt;lb/&gt;else:&lt;lb/&gt;    # 1. Select k landmark indices from raw data&lt;lb/&gt;    idx = self.rng.choice(n_samples, size=self.k, replace=False)&lt;lb/&gt;    self.L_high = X[idx].copy()  # raw landmarks&lt;lb/&gt;&lt;lb/&gt;    # 2. Fit PCA skeleton on raw landmarks&lt;lb/&gt;    L_low_raw = pca.fit_transform(self.L_high)&lt;lb/&gt;&lt;lb/&gt;    # 3. Normalise X and landmarks for distance computations&lt;lb/&gt;    X_scaled = scaler.fit_transform(X)&lt;lb/&gt;    self.L_high = scaler.transform(self.L_high)&lt;/code&gt;
    &lt;p&gt;We now have high-D landmarks &lt;code&gt;L ∈ R^(k×n)&lt;/code&gt;. To embed everything in e.g. 2D or 3D, we first map the landmarks themselves to a low dimension using PCA:&lt;/p&gt;
    &lt;p&gt;1. Centre the Data: Centre the landmark matrix &lt;code&gt;L&lt;/code&gt; to obtain &lt;code&gt;L_bar&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;2. Compute Covariance: Compute the covariance matrix &lt;code&gt;Σ&lt;/code&gt;: &lt;code&gt;Σ = (1 / k-1) · L_barᵀ · L_bar&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;3. Form the Projection Matrix: Take the top &lt;code&gt;m&lt;/code&gt; eigenvectors to form the projection matrix &lt;code&gt;Wm&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;4. Project to Low Dimensions: Obtain low-D landmark coordinates &lt;code&gt;L’_raw&lt;/code&gt;: &lt;code&gt;L’_raw = L_bar · Wm&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Because the distance computations later are done in the normalised feature space, we match scales using an RMS ratio:&lt;/p&gt;
    &lt;code&gt;rms_high = np.sqrt(np.mean([&lt;lb/&gt;    np.linalg.norm(self.L_high[i] - self.L_high[j])**2&lt;lb/&gt;    for i in range(self.k) for j in range(i+1, self.k)&lt;lb/&gt;]))&lt;lb/&gt;rms_low = np.sqrt(np.mean([&lt;lb/&gt;    np.linalg.norm(L_low_raw[i] - L_low_raw[j])**2&lt;lb/&gt;    for i in range(self.k) for j in range(i+1, self.k)&lt;lb/&gt;]))&lt;lb/&gt;&lt;lb/&gt;self.L_low = L_low_raw * (rms_high / rms_low)&lt;/code&gt;
    &lt;p&gt;This ensures:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The shape of the low-D skeleton matches the raw data geometry (for data-derived landmarks).&lt;/item&gt;
      &lt;item&gt;The scale of the skeleton is compatible with the normalised distance metric.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Linearised Trilateration: The GPS Analogy&lt;/head&gt;
    &lt;p&gt;With landmarks defined both in high-D and low-D, the core embedding step becomes:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Given a point&lt;/p&gt;&lt;code&gt;x&lt;/code&gt;, find a low-D point&lt;code&gt;y&lt;/code&gt;whose distances to the low-D landmarks match the high-D distances from&lt;code&gt;x&lt;/code&gt;to the high-D landmarks.&lt;/quote&gt;
    &lt;p&gt;Let:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;L_j&lt;/code&gt;: The high-D landmarks (after scaling).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;L''_j&lt;/code&gt;: The low-D landmarks (&lt;code&gt;self.L_low&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;δ²_j&lt;/code&gt;: The squared distance from&lt;code&gt;x&lt;/code&gt;to landmark&lt;code&gt;j&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We ideally want:&lt;/p&gt;
    &lt;p&gt;This is a classic trilateration problem (think GPS). Naively, it is non-linear in y. SLR’s key trick is to linearise it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Roman Ferrando’s stories in your inbox&lt;/head&gt;
    &lt;p&gt;Join Medium for free to get updates from this writer.&lt;/p&gt;
    &lt;p&gt;Take the equation for landmark 0 and subtract it from each equation j:&lt;/p&gt;
    &lt;p&gt;Expanding and cancelling the &lt;code&gt;yᵀy&lt;/code&gt; terms give a linear system:&lt;/p&gt;
    &lt;p&gt;Stacking these for &lt;code&gt;j = 1…k-1&lt;/code&gt; yields:&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;A&lt;/code&gt;depends only on low-D landmarks.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;b&lt;/code&gt;depends on the measured distances&lt;code&gt;δ²_j&lt;/code&gt;for a given&lt;code&gt;x&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In code, we precompute &lt;code&gt;A&lt;/code&gt; and its pseudoinverse once:&lt;/p&gt;
    &lt;code&gt;# Precompute solver&lt;lb/&gt;self.L0_low = self.L_low[0]&lt;lb/&gt;self.A = 2 * (self.L_low[1:] - self.L0_low)   # shape: (k-1, m)&lt;lb/&gt;self.A_pinv = np.linalg.pinv(self.A)          # Moore–Penrose pseudoinverse&lt;lb/&gt;self.L_low_sq_norms = np.sum(self.L_low**2, axis=1)&lt;/code&gt;
    &lt;p&gt;Then, for a batch of points X:&lt;/p&gt;
    &lt;code&gt;# Squared distances in high-D&lt;lb/&gt;diff = X_scaled[:, np.newaxis, :] - self.L_high[np.newaxis, :, :]&lt;lb/&gt;delta_sq = np.sum(diff**2, axis=2)  # shape: (n_samples, k)&lt;lb/&gt;&lt;lb/&gt;# Right-hand side b for all points&lt;lb/&gt;term1 = self.L_low_sq_norms[1:] - self.L_low_sq_norms[0]      # shape: (k-1,)&lt;lb/&gt;term2 = delta_sq[:, 1:] - delta_sq[:, 0:1]                    # broadcast&lt;lb/&gt;b = term1 - term2                                             # (n_samples, k-1)&lt;lb/&gt;&lt;lb/&gt;# Initial low-D coordinates (first pass)&lt;lb/&gt;Y_raw = b @ self.A_pinv.T                                     # (n_samples, m)&lt;/code&gt;
    &lt;p&gt;Because A is fixed, embedding a new point is just:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute k squared distances.&lt;/item&gt;
      &lt;item&gt;Build b.&lt;/item&gt;
      &lt;item&gt;One matrix multiplication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is exactly the type of workload that scales linearly with N and runs comfortably in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;Alpha Refinement: Fixing Global Scale&lt;/head&gt;
    &lt;p&gt;In practice, we do a two-pass mapping. The first pass gives Y_raw, but some global scale mismatch can remain between high-D and low-D distances.&lt;/p&gt;
    &lt;p&gt;SLR introduces a global scalar α that best aligns the two:&lt;/p&gt;
    &lt;p&gt;In code:&lt;/p&gt;
    &lt;code&gt;# Squared distances in high-D&lt;lb/&gt;diff = X_scaled[:, np.newaxis, :] - self.L_high[np.newaxis, :, :]&lt;lb/&gt;delta_sq = np.sum(diff**2, axis=2)  # shape: (n_samples, k)&lt;lb/&gt;&lt;lb/&gt;# Right-hand side b for all points&lt;lb/&gt;term1 = self.L_low_sq_norms[1:] - self.L_low_sq_norms[0]      # shape: (k-1,)&lt;lb/&gt;term2 = delta_sq[:, 1:] - delta_sq[:, 0:1]                    # broadcast&lt;lb/&gt;b = term1 - term2                                             # (n_samples, k-1)&lt;lb/&gt;&lt;lb/&gt;# Initial low-D coordinates (first pass)&lt;lb/&gt;Y_raw = b @ self.A_pinv.T                                     # (n_samples, m)&lt;/code&gt;
    &lt;p&gt;We then rescale the high-D distances and solve again:&lt;/p&gt;
    &lt;code&gt;delta_sq_corrected = (alpha**2) * delta_sq&lt;lb/&gt;&lt;lb/&gt;term2_corr = delta_sq_corrected[:, 1:] - delta_sq_corrected[:, 0:1]&lt;lb/&gt;b_corr = term1 - term2_corr&lt;lb/&gt;&lt;lb/&gt;Y_final = b_corr @ self.A_pinv.T&lt;/code&gt;
    &lt;p&gt;This simple, non-iterative correction significantly improves embedding quality while keeping the whole procedure analytic and fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;Distance Warping: Tuning Locality vs Global Geometry&lt;/head&gt;
    &lt;p&gt;t-SNE is popular because it exaggerates local structure: clusters become very tight and well separated. Pure trilateration, on the other hand, preserves global geometry more faithfully.&lt;/p&gt;
    &lt;p&gt;SLR adds a knob to interpolate between these behaviours via distance warping:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;p = 1.0&lt;/code&gt;→ pure global geometry&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;p ≈ 0.5&lt;/code&gt;→ stronger local neighbourhoods&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;p ≈ 0.33&lt;/code&gt;→ visually similar separation to t-SNE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the reference implementation, the warp is applied right after computing distances:&lt;/p&gt;
    &lt;code&gt;# delta_sq shape: (k,)&lt;lb/&gt;delta_sq = np.sum((x - self.L_high)**2, axis=1)&lt;lb/&gt;&lt;lb/&gt;# Nonlinear locality warp&lt;lb/&gt;delta = np.sqrt(delta_sq)   # Euclidean distances&lt;lb/&gt;p = 0.5                     # try 0.5; smaller p → stronger locality&lt;lb/&gt;delta = delta ** p&lt;lb/&gt;delta_sq = delta ** 2&lt;/code&gt;
    &lt;p&gt;This gives you t-SNE-like cluster separation while preserving the deterministic, analytic nature of SLR.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting It Together: The &lt;code&gt;fit_transform&lt;/code&gt; Pipeline&lt;/head&gt;
    &lt;p&gt;The full &lt;code&gt;fit_transform&lt;/code&gt; method ties everything together: scaling, landmark construction, PCA, trilateration, alpha refinement, and final embedding.&lt;/p&gt;
    &lt;p&gt;Here is a condensed view (non-essential boilerplate omitted):&lt;/p&gt;
    &lt;code&gt;def fit_transform(self, X):&lt;lb/&gt;    scaler = StandardScaler()&lt;lb/&gt;    n_samples, n_features = X.shape&lt;lb/&gt;    pca = PCA(n_components=self.n_components)&lt;lb/&gt;&lt;lb/&gt;    if self.synthetic_landmarks:&lt;lb/&gt;        # Synthetic sine landmarks&lt;lb/&gt;        a = self.rng.uniform(0.5, 2.0, n_features)&lt;lb/&gt;        omega = self.rng.uniform(0.5, 1.5, n_features)&lt;lb/&gt;        phi = self.rng.uniform(0, 2 * np.pi, n_features)&lt;lb/&gt;        t = np.linspace(0, 2 * np.pi, self.k)&lt;lb/&gt;        self.L_high = self._gamma(t, a, omega, phi).T&lt;lb/&gt;        L_low_raw = pca.fit_transform(self.L_high)&lt;lb/&gt;        X_scaled = scaler.fit_transform(X)&lt;lb/&gt;    else:&lt;lb/&gt;        # Data-derived landmarks&lt;lb/&gt;        idx = self.rng.choice(n_samples, size=self.k, replace=False)&lt;lb/&gt;        self.L_high = X[idx].copy()&lt;lb/&gt;        L_low_raw = pca.fit_transform(self.L_high)&lt;lb/&gt;        X_scaled = scaler.fit_transform(X)&lt;lb/&gt;        self.L_high = scaler.transform(self.L_high)&lt;lb/&gt;&lt;lb/&gt;    # RMS scaling of low-D skeleton&lt;lb/&gt;    ...  # (rms_high / rms_low scaling as shown earlier)&lt;lb/&gt;&lt;lb/&gt;    # Precompute trilateration solver&lt;lb/&gt;    self.L0_low = self.L_low[0]&lt;lb/&gt;    self.A = 2 * (self.L_low[1:] - self.L0_low)&lt;lb/&gt;    self.A_pinv = np.linalg.pinv(self.A)&lt;lb/&gt;    self.L_low_sq_norms = np.sum(self.L_low**2, axis=1)&lt;lb/&gt;&lt;lb/&gt;    # Vectorised first pass (Y_raw)&lt;lb/&gt;    diff = X_scaled[:, np.newaxis, :] - self.L_high[np.newaxis, :, :]&lt;lb/&gt;    delta_sq = np.sum(diff**2, axis=2)&lt;lb/&gt;    term1 = self.L_low_sq_norms[1:] - self.L_low_sq_norms[0]&lt;lb/&gt;    term2 = delta_sq[:, 1:] - delta_sq[:, 0:1]&lt;lb/&gt;    b = term1 - term2&lt;lb/&gt;    Y_raw = b @ self.A_pinv.T&lt;lb/&gt;&lt;lb/&gt;    # Alpha refinement and second pass&lt;lb/&gt;    diff_low = Y_raw[:, np.newaxis, :] - self.L_low[np.newaxis, :, :]&lt;lb/&gt;    dist_low = np.linalg.norm(diff_low, axis=2)&lt;lb/&gt;    dist_high = np.sqrt(delta_sq)&lt;lb/&gt;    alpha = np.sum(dist_low * dist_high) / np.sum(delta_sq)&lt;lb/&gt;&lt;lb/&gt;    delta_sq_corrected = (alpha**2) * delta_sq&lt;lb/&gt;    term2_corr = delta_sq_corrected[:, 1:] - delta_sq_corrected[:, 0:1]&lt;lb/&gt;    b_corr = term1 - term2_corr&lt;lb/&gt;    Y_final = b_corr @ self.A_pinv.T&lt;lb/&gt;&lt;lb/&gt;    return Y_final&lt;/code&gt;
    &lt;p&gt;From the browser’s perspective, once the landmarks and pseudoinverse are precomputed, embedding new points is just distance computations + one matrix multiply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: SLR vs t-SNE on a 5-Cluster Dataset&lt;/head&gt;
    &lt;p&gt;To evaluate SLR against a familiar baseline, consider 5 Gaussian clusters in a 20-dimensional space (5,000 points). Using SLR with appropriate p:&lt;/p&gt;
    &lt;p&gt;Using t-SNE on the same data:&lt;/p&gt;
    &lt;p&gt;You get a flavour of the trade-off:&lt;/p&gt;
    &lt;p&gt;t-SNE&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Strong local separation&lt;/item&gt;
      &lt;item&gt;Poor global interpretability&lt;/item&gt;
      &lt;item&gt;Stochastic, run-to-run variability&lt;/item&gt;
      &lt;item&gt;Iterative, quadratic, and slower&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLR&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deterministic layouts&lt;/item&gt;
      &lt;item&gt;Preserved global structure&lt;/item&gt;
      &lt;item&gt;Tunable locality via p&lt;/item&gt;
      &lt;item&gt;Linear time, analytic, out-of-sample mapping&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A concise comparison:&lt;/p&gt;
    &lt;head rend="h2"&gt;Minimal Usage Example&lt;/head&gt;
    &lt;p&gt;Here is a minimal example showing how to use &lt;code&gt;SineLandmarkReduction&lt;/code&gt; on a synthetic dataset and plot the result:&lt;/p&gt;
    &lt;code&gt;import numpy as np&lt;lb/&gt;import matplotlib.pyplot as plt&lt;lb/&gt;from sklearn.datasets import make_blobs&lt;lb/&gt;&lt;lb/&gt;X, y = make_blobs(&lt;lb/&gt;    n_samples=5000,&lt;lb/&gt;    n_features=20,&lt;lb/&gt;    centers=5,&lt;lb/&gt;    cluster_std=0.80,&lt;lb/&gt;    random_state=42&lt;lb/&gt;)&lt;lb/&gt;&lt;lb/&gt;slr = SineLandmarkReduction(&lt;lb/&gt;    n_components=2,&lt;lb/&gt;    n_landmarks=50,&lt;lb/&gt;    random_state=42,&lt;lb/&gt;    synthetic_landmarks=False   # or True, depending on your use case&lt;lb/&gt;)&lt;lb/&gt;&lt;lb/&gt;Y = slr.fit_transform(X)&lt;lb/&gt;&lt;lb/&gt;plt.figure(figsize=(7, 6))&lt;lb/&gt;scatter = plt.scatter(Y[:, 0], Y[:, 1], c=y, s=8, alpha=0.8)&lt;lb/&gt;plt.xlabel("SLR Dimension 1")&lt;lb/&gt;plt.ylabel("SLR Dimension 2")&lt;lb/&gt;plt.title("Sine Landmark Reduction (SLR) Visualization")&lt;lb/&gt;plt.colorbar(scatter, label="Cluster Label")&lt;lb/&gt;plt.show()&lt;/code&gt;
    &lt;p&gt;Replace the synthetic dataset with your own feature matrix and you have a ready-to-use, deterministic embedding.&lt;/p&gt;
    &lt;p&gt;In a browser deployment, the same ideas can be ported to JavaScript or WebAssembly with minimal changes: the algorithm itself only needs basic linear algebra and a pseudoinverse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Closing Thoughts&lt;/head&gt;
    &lt;p&gt;Sine Landmark Reduction (SLR) is designed from first principles for environments where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Latency matters (interactive drag-and-drop exploration).&lt;/item&gt;
      &lt;item&gt;Resources are constrained (no GPU, no heavy backend).&lt;/item&gt;
      &lt;item&gt;Reproducibility is a feature (deterministic embeddings across runs).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Constructing a synthetic or data-driven landmark skeleton,&lt;/item&gt;
      &lt;item&gt;Projecting it via PCA with RMS scaling,&lt;/item&gt;
      &lt;item&gt;Using linearised trilateration for an analytic solution,&lt;/item&gt;
      &lt;item&gt;Adding alpha refinement for scale consistency, and&lt;/item&gt;
      &lt;item&gt;Exposing distance warping as a control for locality,&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SLR offers a fast, deterministic, and interpretable alternative to t-SNE/UMAP in browser-native contexts.&lt;/p&gt;
    &lt;p&gt;It is already powering Thingbook’s interactive Data Explorer, but the underlying idea is more general: if you can formalise your embedding problem in terms of distances to a small set of stable landmarks, you can achieve real-time dimensionality reduction with simple linear algebra.&lt;/p&gt;
    &lt;p&gt;If you want to experiment further, the Python implementation shown here can be dropped into your own notebooks or adapted to a JavaScript/WebAssembly stack to enable SLR directly in your web applications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medium.com/@roman.f/a-linear-time-alternative-to-t-sne-for-dimensionality-reduction-and-fast-visualisation-5cd1a7219d6f"/><published>2025-12-16T06:47:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46286030</id><title>The biggest heat pumps in the world</title><updated>2025-12-16T10:13:13.207735+00:00</updated><content>&lt;doc fingerprint="c1e6107f4cbc9dba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Meet the biggest heat pumps in the world&lt;/head&gt;
    &lt;p&gt;The pipe that will supply the heat pump, drawing water from the River Rhine in Germany, is so big that you could walk through it, fully upright, I'm told.&lt;/p&gt;
    &lt;p&gt;"We plan to take 10,000 litres per second," says Felix Hack, project manager at MVV Environment, an energy company, as he describes the 2m diameter pipes that will suck up river water in Mannheim, and then return it once heat from the water has been harvested.&lt;/p&gt;
    &lt;p&gt;In October, parent firm MVV Energie announced its plan to build what could be the most powerful heat pump modules ever. Two units, each with a capacity of 82.5 megawatts.&lt;/p&gt;
    &lt;p&gt;That's enough to supply around 40,000 homes, in total, via a district heating system. MVV Energie aims to build the system on the site of a coal power plant that is converting to cleaner technologies.&lt;/p&gt;
    &lt;p&gt;The scale of the heat pumps was determined partly by limits on the size of machinery that could be transported through the streets of Mannheim, or potentially via barges along the Rhine. "We're not sure about that yet," says Mr Hack. "It might come via the river."&lt;/p&gt;
    &lt;p&gt;One person well aware of the project is Alexandre de Rougemont, at Everllence (formerly MAN Energy Solutions), another German company that also makes extremely large heat pumps. "It is a competition, yeah," he says. "We're open about it."&lt;/p&gt;
    &lt;p&gt;Heat pumps soak up heat from the air, ground or, in these cases, bodies of water. Refrigerants inside the heat pumps evaporate when they are warmed even slightly.&lt;/p&gt;
    &lt;p&gt;By compressing the refrigerant, you boost that heat further. This same process occurs in heat pumps designed to supply single homes, it just happens on a much larger scale in giant heat pumps that serve entire city districts.&lt;/p&gt;
    &lt;p&gt;As towns and cities around the world seek to decarbonise, many are deciding to purchase large heat pumps, which can attach to district heating networks.&lt;/p&gt;
    &lt;p&gt;These networks allow hot water or steam to reach multiple buildings, all connected up with many kilometres of pipe. Ever bigger models of heat pump are emerging to meet demand.&lt;/p&gt;
    &lt;p&gt;"There was a lot of pressure on us to change the heat generation to new sources, especially renewable sources," explains Mr Hack as he discusses the decommissioning of coal-fired units at the Mannheim plant. The site is right by the Rhine, already has a hefty electricity grid connection, and is plugged in to the district heating network, so it makes sense to install the heat pumps here, he says.&lt;/p&gt;
    &lt;p&gt;He notes that the technology is possible partly thanks to the availability of very large compressors in the oil and gas industry – where they are used to compress fossil fuels for storage or transportation, for example.&lt;/p&gt;
    &lt;p&gt;Work on the Mannheim project is due to start next year. The heat pumps – with a combined capacity of 162MW – are set to become fully operational in the winter of 2028-29. Mr Hack adds that a multi-step filter system will prevent the heat pumps sucking up fish from the river, and that modelling suggests the system will affect the average temperature of the river by less than 0.1C.&lt;/p&gt;
    &lt;p&gt;Installations such as this are not cheap. The Mannheim heat pump setup will cost €200m ($235m; £176m). Mr de Rougemont at Everllence says that, at his company, heat-pump equipment costs roughly €500,000 per megawatt of installed capacity – this does not include the additional cost of buildings, associated infrastructure and so on.&lt;/p&gt;
    &lt;p&gt;Everllence is currently working on a project in Aalborg, Denmark that will be even more powerful than the system in Mannheim, with a total capacity of 176MW. It will use smaller modules, however – four 44MW units – and is due to become operational in 2027, when it will supply nearly one third of all heating demand in the town.&lt;/p&gt;
    &lt;p&gt;Those 44MW machines are actually the same ones used in a previous project, now fully operational, to the south of Aalborg in Esbjerg. There, they don't run at maximum capacity but rather supply 35MW each.&lt;/p&gt;
    &lt;p&gt;Large hot water storage tanks, each able to hold 200,000 cubic metres of liquid, will give the system added flexibility, adds Mr de Rougemont: "When the electricity price is high, you stop your heat pump and only provide heat from the storage."&lt;/p&gt;
    &lt;p&gt;Veronika Wilk at the Austrian Institute of Technology says, "Heat pumps and district heating systems are a great fit." Such systems can harvest heat from bodies of water or even wastewater from sewage treatment plants.&lt;/p&gt;
    &lt;p&gt;Dr Wilk notes that, when you use multiple large heat pumps on a district heating network, you gain flexibility and efficiency. You could run two out of four heat pumps in the autumn, say, when less heat is required than during the depths of winter.&lt;/p&gt;
    &lt;p&gt;All the systems mentioned so far harvest energy from water sources but, less commonly, very large heat pumps can use the air as a heat source, too. Even in a relatively cold city such as Helsinki.&lt;/p&gt;
    &lt;p&gt;"The sea in front of Helsinki is too shallow," explains Timo Aaltonen, senior vice president of heating and cooling at Helen Oy, an energy firm. "We calculated that we would need to build a tunnel more than 20km long to the ocean, to get enough water [with a] temperature high enough."&lt;/p&gt;
    &lt;p&gt;Helsinki is in the process of radically overhauling its district heating system. The city has added heat pumps, biomass burners and electric boilers to a 1,400km network that links up nearly 90% of buildings in the Finnish capital, adds Mr Aaltonen.&lt;/p&gt;
    &lt;p&gt;Heat pumps convert single kilowatt hours of electricity into multiple kilowatt hours of heat but electric boilers can't do this and are therefore considered less efficient.&lt;/p&gt;
    &lt;p&gt;I ask why Helen Oy decided to install hundreds of megawatts of these boilers and Mr Aaltonen says that they are cheaper to install than heat pumps and having them also means he and colleagues don't have to rely entirely on the air, which is limited in terms of how much heat it can provide at scale. Plus, the electric boilers can help to soak up surplus renewables and provide an electricity grid-balancing function, he says.&lt;/p&gt;
    &lt;p&gt;There are no heat pumps in the UK that rival the systems under development in Denmark, Germany and Finland. However, some new district heating networks are on the way, such as the Exeter Energy Network, which will supply the University of Exeter and other customers.&lt;/p&gt;
    &lt;p&gt;The minimum planned capacity of the network is 12MW. It will feature three 4MW air-to-water heat pumps, with the first unit due to become operational in 2028.&lt;/p&gt;
    &lt;p&gt;Keith Baker at Glasgow Caledonian University, who researches district heating systems, says the UK has opportunities to make more of this technology. Water in disused mines, which maintains a relatively stable temperature, is beginning to supply larger heat pumps here, for example.&lt;/p&gt;
    &lt;p&gt;Post-industrial and rural areas where there is adequate space to install heat pumps and heat storage tanks are "the sweet spots", he says.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c17p44w87rno"/><published>2025-12-16T08:13:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46286313</id><title>15,000 Free Pixel Art Icons</title><updated>2025-12-16T10:13:12.643436+00:00</updated><content>&lt;doc fingerprint="4323d44f5ab6342a"&gt;
  &lt;main&gt;
    &lt;p&gt;Download All All Creatures Food Beverages Kitchen Interiors Apparel Accessories Beauty Vehicles Structures Technology Tools Medical Science Music Art Sports Recreation Nature Symbols&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://piixes.com/"/><published>2025-12-16T08:58:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46286559</id><title>I'm a Tech Lead, and nobody listens to me. What should I do?</title><updated>2025-12-16T10:13:12.402024+00:00</updated><content>&lt;doc fingerprint="37c382572f802db8"&gt;
  &lt;main&gt;
    &lt;p&gt;In June 2018, I joined mytaxi (FREE NOW), a competitor of Uber in the ride-hailing space, as Backend Chapter Lead. I was looking for an opportunity to grow in technical leadership. Honestly, I did not even fully understand what “Chapter Lead” meant. After some research, I learned it was part of Spotify’s squad (team) and chapter (horizontal domain, such as iOS, Android, Backend, Data, etc.) model, as well as tribes (groups of squads organized around vertical domains, for example, everything related to drivers).&lt;lb/&gt;Note: this article is a translation from the original “Soy Tech Lead y no me hacen caso. ¿Qué hago?”, in Spanish.&lt;/p&gt;
    &lt;p&gt;Note: this article is a translation from the original “Soy Tech Lead y no me hacen caso. ¿Qué hago?”, in Spanish.&lt;/p&gt;
    &lt;p&gt;That role had two main components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Backend technical leadership (TL), driven by best practices and with a strong emphasis on continuous improvement. At the time, mytaxi was experiencing major traffic growth. Some services — for example, the one used to incentivize drivers to complete more rides — experienced significant traffic spikes and required improvements, re-architecting, and similar work. On top of that, there were a bit over 200 services to manage.&lt;/item&gt;
      &lt;item&gt;People management in a horizontal setup. The idea was that all backend engineers would report to either Ariel, the other Chapter Lead, or me, regardless of their team. This was not a very orthodox setup, but at the time, around 3–5 backend engineers were joining every month. There was a strong need to make people productive as quickly as possible, align on architecture, and keep the product moving.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I came in with no prior formal experience as a Tech Lead. I think I never read as much in my life as during the month between announcing I was leaving my previous job and joining mytaxi. Not only that. I had never really had a proper Tech Lead to learn from. What could go wrong?&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;The first day was very entertaining. I log into Slack and introduce myself to the infrastructure and platform manager. He says:&lt;/p&gt;
    &lt;quote&gt;By the way, you have an incident in service X. Could you take a look?&lt;/quote&gt;
    &lt;p&gt;Just like that. It is nine in the morning on a Monday, and we already have an incident. I do not even know where the logs are, Henning. After the initial shock, I managed to find the responsible team. They identified the issue, fixed it, and everything got resolved.&lt;/p&gt;
    &lt;p&gt;This first interaction made several things very clear to me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nobody really knows how to manage incidents, document what happened, or communicate progress. Great start.&lt;/item&gt;
      &lt;item&gt;There is no culture of doing incident reviews or extracting actions to prevent similar incidents in the future.&lt;/item&gt;
      &lt;item&gt;There is some coupling between domains. In this case, the Value Added Tax (VAT) concept was applied to two completely different use cases. A change in one of them caused the incident in the other.&lt;/item&gt;
      &lt;item&gt;Many people do not know how to debug. They look at me as if the logs were talking to me, or as if I were Harry Potter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The good part was that there was clearly a lot to fix. I had a pretty clear idea of how engineering culture could be improved. On top of that, I had the Tech Lead title. This was going to be easy. Or maybe not.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;👋 Hi, João here. This is the opening post of a series designed for Tech Leads and Engineering Managers who want to lead with greater clarity and intention.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Traits of a good Tech Lead”&lt;/item&gt;
      &lt;item&gt;“I’m a Tech Lead, and nobody listens to me. What should I do?” ← This article&lt;/item&gt;
      &lt;item&gt;“KPIs, SLOs, and operational excellence”. Coming soon. Subscribe so you do not miss it.&lt;/item&gt;
      &lt;item&gt;To be continued…&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m currently writing “The Tech Lead Handbook”, scheduled for release in H1 2026. The ideas in this series will form its core.&lt;/p&gt;
    &lt;p&gt;If you want to join the waitlist, you’ll get a 25% launch discount.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;head rend="h1"&gt;Trust&lt;/head&gt;
    &lt;p&gt;After that incident, I created an incident review document and suggested a small review of the tasks that should be prioritized to prevent it from happening again. I got carried away and created an initial presentation for the other backend Chapter Leads with a backend strategy. I do not remember it perfectly, but it included hexagonal architecture, a testing pyramid with contract tests to avoid breaking APIs used by mobile apps, and more. Days go by, and I start thinking:&lt;/p&gt;
    &lt;quote&gt;Damn, nobody is listening to me. I put a lot of work into those slides and that strategy.&lt;/quote&gt;
    &lt;p&gt;Today, the reason seems obvious to me. Titles do not grant influence. To influence, you need to build trust. And I had not earned enough of it yet to propose something so fundamental. Through my own experience and through coaching sessions, I have seen this exact mistake repeated several times throughout my career.&lt;/p&gt;
    &lt;p&gt;Years later, I discovered the well-known trust equation by Maister, Green, and Galford. It would have been incredibly helpful back then. It goes like this:&lt;/p&gt;
    &lt;p&gt;The trust equation. Generated with Gemini 3 / NanoBanana.&lt;/p&gt;
    &lt;p&gt;The first time I read it, my mind was blown because it described exactly what was happening to me. Let’s break it down:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Credibility: knowing what you are talking about and having technical judgment. When you say something, people feel it is well-founded. In 2018, I might have had some of this credibility, but it had not yet been proven in that context, with those people, with those systems. I was coming from the outside. Imported credibility is always worth less — unless you come from a FAANG or have built a strong personal brand — than credibility earned on the ground.&lt;/item&gt;
      &lt;item&gt;Reliability: doing what you say you will do. Being consistent and showing up when needed. In a high-paced environment like mytaxi, this matters a lot. In those first days, I was still learning where the logs lived. It is hard to demonstrate reliability if you do not even control the map.&lt;/item&gt;
      &lt;item&gt;Intimacy: people feel they can talk to you, that you will not leave them exposed, and that you understand their fears and doubts. For a TL, this is more important than it seems. Without this, any technical proposal feels like a judgment. And when people get defensive, everything slows down.&lt;/item&gt;
      &lt;item&gt;And then there is the denominator: self-orientation. When your proposals seem to serve your own agenda more than the team’s needs, trust collapses. That was my mistake. I arrived with a strategy too early, without listening, without seeing what they actually needed, without having earned the moral right to propose it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In other words, even if my ideas were good, the equation still did not work out. I had some credibility, a bit of reliability still to build, intimacy yet to be created, and too much self-orientation. The result was obvious. Low trust.&lt;/p&gt;
    &lt;p&gt;Two key moments&lt;/p&gt;
    &lt;p&gt;Over time, I realized that trust is not built through big speeches, but through concrete actions that solve real, everyday problems. Looking back, two obvious moments accelerated the team’s shift in how they perceived me.&lt;/p&gt;
    &lt;p&gt;Regulatory complexity&lt;/p&gt;
    &lt;p&gt;Because mytaxi competed with Uber in a highly regulated taxi market, with very local regulations across Europe, the application needed to support multiple variants of the same flow. This led to the proliferation of dozens of configuration flags across all services. The result was chaos. Nobody knew for sure what was enabled in each city, what affected iOS, what affected Android, or where each option was actually defined. To make matters worse, the configuration was spread across roughly 200 services.&lt;/p&gt;
    &lt;p&gt;One day, Maria — an Agile Coach — talked to me very directly about this pain. I did what I knew best at the time. I built something. I put together a portal — a bit rough, to be honest — that queried the configuration APIs of all services and aggregated that information by functionality, country, or city. Features could be browsed by city or by name. The website was very simple, generated from an HTML template by a Python service.&lt;lb/&gt;The features could be queried by city or by name. The website was very simple, with HTML generated by a Python service.&lt;/p&gt;
    &lt;p&gt;The features could be queried by city or by name. The website was very simple, with HTML generated by a Python service.&lt;/p&gt;
    &lt;p&gt;Suddenly, at a glance, anyone could see what was enabled and where. It was not pretty, but it solved a problem. More importantly, it showed that I was there to help them work better (credibility), not to impose an abstract technical agenda. Soon after, other teams started using the portal, including Product Owners, QA, and even Operations. Without intending to, it became an organizational alignment tool. And it led to something even more interesting. Other engineers started contributing.&lt;/p&gt;
    &lt;p&gt;Once they saw the value it created, several colleagues proposed improvements, fixed minor bugs, and added features I had never even considered. One of them built a small website to visualize city zones, which solved a long-standing pain for teams working with geofencing or driver-passenger assignment. Another automated part of the flag update process. Someone else added metrics to detect inconsistent configurations across platforms.&lt;/p&gt;
    &lt;p&gt;What started as a quick hack turned into a small ecosystem of internal tools that reduced uncertainty, sped up decisions, and made the team’s life a little easier every week.&lt;/p&gt;
    &lt;p&gt;That domino effect taught me something important. When you solve a real problem and make it visible, people join in. Trust is also built that way, by inviting others to improve what you started and celebrating when they do it better than you.&lt;/p&gt;
    &lt;p&gt;Debugging&lt;/p&gt;
    &lt;p&gt;The second moment concerned something much more human. Helping people debug. I have never considered myself especially smart, but I have always been very systematic when connecting error messages, code, hypotheses, and system behavior. To my surprise, many people saw this as almost magical. It was not magic. It was a mix of experience, fundamentals, intuition, knowing where to look, and not being afraid to dive into third-party library code.&lt;/p&gt;
    &lt;p&gt;I started pairing with colleagues during incident resolution (intimacy), teaching them to formulate and discard hypotheses, read logs with intent, and distinguish symptoms from root causes. I proposed incident-review practices that improved the quality of our responses and helped us learn collectively.&lt;/p&gt;
    &lt;p&gt;Without realizing it, these two contributions did more for my reputation than any presentation or strategy deck. Building helpful things and standing by people when the system is on fire creates more trust than any title. That was when my ideas finally started gaining traction. Interestingly, these two actions reduced my self-orientation to zero. I stopped thinking about “my strategy” and started thinking about “our work”.&lt;/p&gt;
    &lt;head rend="h1"&gt;What would you tell your 2018 self?&lt;/head&gt;
    &lt;p&gt;Looking back, one idea stands out. No, TLs don’t earn influence just because “it is their role”. It is earned every day, not through speeches, but by solving painful problems and being present when people need real support.&lt;/p&gt;
    &lt;p&gt;If you are in a similar situation, here is some advice I wish I had received in 2018:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Before proposing a strategy, first understand what actually hurts your team.&lt;/item&gt;
      &lt;item&gt;Pick one or two actions that deliver immediate value and execute them.&lt;/item&gt;
      &lt;item&gt;Talk less about architecture and more about how your proposal reduces toil, risk, or uncertainty.&lt;/item&gt;
      &lt;item&gt;Do not try to prove you are the smartest person in the room. Try to help others do their job better.&lt;/item&gt;
      &lt;item&gt;Feedback cycles, unlike code, are slower. They are measured in weeks or months. Be patient.&lt;/item&gt;
      &lt;item&gt;And above all, remember that trust is cumulative. It is earned in every interaction.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Technical influence does not start with a title. It begins with the visible impact you create. Because when a TL feels unheard, the solution is not to speak louder.&lt;lb/&gt;It is to change the conversation. And to start from the only place you truly control: your own behavior.&lt;lb/&gt;---&lt;lb/&gt;🎁 Want to put this into practice with your team tomorrow? Subscriber-only gift&lt;/p&gt;
    &lt;p&gt;It is to change the conversation. And to start from the only place you truly control: your own behavior.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;🎁 Want to put this into practice with your team tomorrow? Subscriber-only gift&lt;/p&gt;
    &lt;p&gt;Many Tech Leads feel unheard because EMs, TLs, and the rest of the team operate with different expectations that no one has made explicit. That friction is not resolved with more meetings or more processes. It is determined with clarity. To help you close that gap, I have prepared a FREE alignment toolkit with three practical tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For Tech Leads: a self-assessment traffic light to fight impostor syndrome and clearly understand where you are creating value and where you are burning out.&lt;/item&gt;
      &lt;item&gt;For Engineering Managers: an evaluation traffic light to give objective feedback based on behaviors, not gut feelings. Help your Tech Leads have a real impact.&lt;/item&gt;
      &lt;item&gt;For the team: an operational principles template to stop debating the same decisions every week and create shared criteria.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In addition, to complement this article, I will include a concrete plan for your first 90 days as a Tech Lead: what to observe, what to prioritize, what to avoid, and how to build trust through small, visible steps. It is the plan I wish I had had during my first week at mytaxi.&lt;/p&gt;
    &lt;p&gt;If you have already downloaded the toolkit, you do not need to do anything. You already have the updated version and will automatically receive the 90-day plan.&lt;/p&gt;
    &lt;p&gt;If you are not yet subscribed, subscribe, complete this form, and I’ll send you the kit so you can move from intention to action. It is FREE!&lt;/p&gt;
    &lt;p&gt;---&lt;lb/&gt;— João&lt;/p&gt;
    &lt;p&gt;— João&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://world.hey.com/joaoqalves/i-m-a-tech-lead-and-nobody-listens-to-me-what-should-i-do-e16e454d"/><published>2025-12-16T09:38:42+00:00</published></entry></feed>