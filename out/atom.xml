<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-22T02:24:53.748117+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45312323</id><title>Node 20 will be deprecated on GitHub Actions runners</title><updated>2025-09-22T02:25:02.505380+00:00</updated><content>&lt;doc fingerprint="7ea3c1fd4f20fea4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Deprecation of Node 20 on GitHub Actions runners&lt;/head&gt;
    &lt;p&gt;Node20 will reach end-of-life (EOL) in April of 2026. As a result we have started the deprecation process of Node20 for GitHub Actions. We plan to migrate all actions to run on Node24 in the fall of 2025.&lt;/p&gt;
    &lt;p&gt;The newest GitHub runner (v2.328.0) now supports both Node20 and Node24 and uses Node20 as the default version. If you’d like to test Node24 ahead of time, set &lt;code&gt;FORCE_JAVASCRIPT_ACTIONS_TO_NODE24=true&lt;/code&gt; as an &lt;code&gt;env&lt;/code&gt; in your workflow or as an environment variable on your runner machine to force the use of Node24.&lt;/p&gt;
    &lt;p&gt;Beginning on March 4th, 2026, runners will begin using Node24 by default. To opt out of this and continue using Node20 after this date, set &lt;code&gt;ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION=true&lt;/code&gt; as an &lt;code&gt;env&lt;/code&gt; in your workflow or as an environment variable on your runner machine. This will only work until we upgrade the runner and remove Node20 later in the summer of 2026.&lt;/p&gt;
    &lt;head rend="h3"&gt;Removal of operating system support with Node24&lt;/head&gt;
    &lt;p&gt;Node24 is incompatible with macOS 13.4 and lower versions.&lt;/p&gt;
    &lt;p&gt;Node 24 does not have official support for ARM32, so self-hosted runners on ARM32 will no longer be supported after Node 20 deprecation.&lt;/p&gt;
    &lt;p&gt;To find out more about the OS versions we support and self-hosted runner architectures, please read our documentation.&lt;/p&gt;
    &lt;head rend="h3"&gt;What you need to do&lt;/head&gt;
    &lt;p&gt;For Actions maintainers: Update your actions to run on Node24 instead of Node20 (Actions configuration settings)&lt;lb/&gt; For Actions users: Update your workflows with latest versions of the actions that run on Node24 (Using versions for Actions)&lt;/p&gt;
    &lt;p&gt;Join the discussion within GitHub Community.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.blog/changelog/2025-09-19-deprecation-of-node-20-on-github-actions-runners/"/><published>2025-09-20T11:19:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45322135</id><title>Why your outdoorsy friend suddenly has a gummy bear power bank</title><updated>2025-09-22T02:25:02.319827+00:00</updated><content>&lt;doc fingerprint="6e4c575fa806d42a"&gt;
  &lt;main&gt;
    &lt;p&gt;Like many backpackers, I’m a sicko. I have weighed all my gear in order to maintain a spreadsheet for pack weight on every trip I’m on. I’ve spent more money than I care to think about in order to drop pounds, or even ounces. This is why I’m the proud new owner of a power bank that looks like a toy.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why your outdoorsy friend suddenly has a gummy bear power bank&lt;/head&gt;
    &lt;p&gt;It’s… ultralight?&lt;/p&gt;
    &lt;p&gt;It’s… ultralight?&lt;/p&gt;
    &lt;p&gt;It’s the Haribo-licensed gummy bear power bank. It’s the lightest-ever 20,000mAH power bank, it’s got a gummy-bear themed built-in USB-C cord, and it’s taking over the ultralight backpacking world. The specs say it weighs 9.9 ounces — and in a world where ounces count, that’s a big deal.&lt;/p&gt;
    &lt;p&gt;Ultralight culture seems a little nuts to the uninitiated. Probably most people do not measure every piece of equipment they carry for weekend backpacking trips. But when you are hiking more than 10 miles a day, especially if you are walking up mountains, you start looking for stuff to get rid of — because even being two pounds lighter is a tremendous relief. The “ideal” baseweight for ultralighters is below 10 pounds, though below 20 is considered respectable. If you’re hiking more than 100 miles, every ounce counts.&lt;/p&gt;
    &lt;p&gt;The ultralight movement is why a lot of backpackers wear trail runners instead of hiking boots, and why a lot of tents now incorporate hiking poles so users don’t have to carry separate poles for freestanding tents. Since 1991, when Ray Jardin published The PCT Hikers Handbook, lots of new companies specializing in the lightest possible equipment have sprung up — as have online communities like r/ultralight. In these communities, there’s a ritual called the “shakedown,” where users post their packs and other people tell them how to cut weight.&lt;/p&gt;
    &lt;p&gt;So of course this community was first to the exciting new world of gummy bear charging.&lt;/p&gt;
    &lt;p&gt;The previous preferred 20k powerbank was a Nitecore build. It’s a serious-looking black box built out of carbon fiber; it costs about $100 and tips the scale at 10.3 ounces. My goofy toy power bank costs $23; it weighed slightly more than the promised specs at 9.95 ounces. It has pass-through charging, just like the Nitecore and allows for fast charging, too. This is like discovering a Volkswagen Beetle can out-haul a Tesla Cybertruck.&lt;/p&gt;
    &lt;p&gt;And when I say it’s sweeping the backpacking world, I don’t just mean online. I got a text from my Appalachian-trail hiking buddy just last week — he’d weighed his new Haribo bank against his old Anker bank, and the Haribo won. He included photos and everything.&lt;/p&gt;
    &lt;p&gt;In writing this post, I was trying to figure out why this exists at all. That was how I discovered there’s a whole Haribo line — a mouse, a wall charger, earbuds, charging cables, and a wireless powerbank. It appears to be a brand collab that was crowdfunded in Japan.&lt;/p&gt;
    &lt;p&gt;Unfortunately the power bank won’t charge through the built-in gummy bear cable, so you’ll have to carry a USB-C cable to get juice on a resupply stop. But still, from the people who brought you “bread bags on your feet to stay dry when it’s raining,” there’s a new ridiculous outdoor device winning hearts and minds. I haven’t done capacity testing yet, but if it does what the specs promise, the most hard-core battery pack an ultralighter can buy is decorated with gummy bears.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/tech/781387/backpacking-ultralight-haribo-power-bank"/><published>2025-09-21T12:31:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45322819</id><title>I forced myself to spend a week in Instagram instead of Xcode</title><updated>2025-09-22T02:25:02.150665+00:00</updated><content>&lt;doc fingerprint="3bcc78561ea6cefc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I forced myself to spend a week in Instagram instead of Xcode&lt;/head&gt;
    &lt;head rend="h3"&gt;This is what happens when you ban yourself from coding&lt;/head&gt;
    &lt;head rend="h4"&gt;Let’s set the stage:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The Lagree Buddy app has enough quality features that this is an actual, useful thing that I feel comfortable promoting &amp;amp; charging money for.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are more features I want to build, but they’re bigger features and are still weeks from releasing (because I need to QA them in the real world).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Since the hard paywall and overhauled onboarding (discussed here), there has been a noticeable increase in purchases (woohoo! see chart below)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Given the information above, I figured I should try an experiment.&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;What if I spent every business hour on marketing/distribution instead of coding and building more features?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That felt so uncomfortable to even say out loud because it meant spending a week on social media and talking to people about the app. But it also meant not hiding inside the code.&lt;/p&gt;
    &lt;p&gt;So here’s a detailed (but slightly stream of consciousness) recap of how that week went.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 1 || Monday, August 25th&lt;/head&gt;
    &lt;p&gt;If any influencers out there want to give me some tips on how to IG correctly, please do. But my current thought process is to craft a story arc for one day. And then to break that arc into 4-6 posts, to be posted every 3 hours or so.&lt;/p&gt;
    &lt;p&gt;I do this because I don’t want it to feel salesy or spammy. So I at least inject some sort of narrative. So today’s story arc was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Working on new feature at home, but oh no! it’s broken!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thought I fixed it and took it to class, but oh no! still broken!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I found out why it was broken, explained it, and took it into another class …&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FIXED.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FIXED 2.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FIXED 3.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also spent the day reaching out to new studios &amp;amp; trainers I saw wearing Apple Watches. Sent out 10 today and got 2 responses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 2 || Tuesday, August 26th&lt;/head&gt;
    &lt;p&gt;I bought a Microformer last week, so let’s use the thing for some content!&lt;/p&gt;
    &lt;p&gt;I signed up for Lagreeing at Home, found an instructor with an Apple Watch, snapped a lot of photos, and got busy creating and scheduling another story arc.&lt;/p&gt;
    &lt;p&gt;I almost immediately got a response from Lagreeing at Home about collabing, and I’d have to say… that’s a pretty big win. Lagreeing at Home was born out of the pandemic and has been an incredible presence in the Lagree community, so hearing some affirmation from them is a fantastic feeling.&lt;/p&gt;
    &lt;p&gt;I wanted to do more cold DM’s to studios and trainers today, too, but sometimes the Apple Gods say “try again tomorrow” (wheel of death! see below).&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 3 || Wednesday, August 27th&lt;/head&gt;
    &lt;p&gt;It’s only been two days, but I’ve been struggling with the actual creation of content itself. Struggling might be the wrong word… underestimate? I underestimated the amount of work it takes!&lt;/p&gt;
    &lt;p&gt;I planned everything out on Monday. But then you have to obviously create the stuff, and all of that takes so long! So today, today is going to be an FAQ series. But the question is how to create it creatively so it’s not just social media slop.&lt;/p&gt;
    &lt;p&gt;And after playing with a basic Q&amp;amp;A and not liking how it looked (aka ugly and sales-y) ... I went hunting on Reddit and found this incredible tool (Postfully) to create fake text messages and came up with this for my Q&amp;amp;A instead:&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 4 || Thursday, August 28th&lt;/head&gt;
    &lt;p&gt;I signed up for THE Sebastian Lagree’s class on Sunday. Three reasons why:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;I want to show him the app in person&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I’m running out of content and I need some photos of a new studio 😅&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I’m getting sick of social media and wanted to do something in real life loll&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I needed a break from creating content, so I cheated and repurposed my IG stories into TikTok videos. But I didn’t want to give up on my mission, so I fell back on cold messaging studios and trainers.&lt;/p&gt;
    &lt;p&gt;Getting any response is a nice feeling, but this message back from new studio Hold Fitness was incredible! She saw my original post on Reddit from 6 months ago!&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 5 || Friday, August 29th&lt;/head&gt;
    &lt;p&gt;I am absolutely ITCHING to get back to the code!!&lt;/p&gt;
    &lt;p&gt;But I am trying to stick to my mission for the week and am racking my brain on what content to come up without sounding repetitive or spammy. Thank goodness I went to class yesterday and took a bunch of b-roll footage because an idea quickly formed that felt different enough from everything before it this week.&lt;/p&gt;
    &lt;p&gt;This might have been the hardest day to stick to this challenge. Because everything inside of me was screaming:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“CAN WE FOR THE LOVE OF GOD GET OFF OF SOCIAL MEDIA AND DO SOMETHING PRODUCTIVE LIKE BUILD MORE FEATURES.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But the thing that I had to constantly remind myself of is that this is productive.&lt;/p&gt;
    &lt;p&gt;Build it and they will come is a fallacy.&lt;/p&gt;
    &lt;p&gt;You have to tell people about the damn thing. It just doesn’t feel productive because you’re over here churning and burning things that feel like they have a shelf-life of 24 hours (if even that). And sending out cold DM’s and hoping for 1 or 2 responses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 6 || Saturday, August 30th&lt;/head&gt;
    &lt;p&gt;Day of rest. &lt;lb/&gt;Sorry, not sorry.&lt;lb/&gt;But I did not code, so the challenge is still intact.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 7 || Sunday August 31th&lt;/head&gt;
    &lt;p&gt;Sebastian Lagree day!!&lt;/p&gt;
    &lt;p&gt;I drove to Brentwood to take a class from SEBASTIAN LAGREE himself. I was pretty nervous because I wasn’t sure if he was going to think my app was stupid or if it was weird, but he honestly couldn’t have been nicer.&lt;/p&gt;
    &lt;p&gt;He’s also an insanely good instructor, which seems obvious, but when you only see someone on IG as an “influencer”, you’re not entirely sure what to expect.&lt;/p&gt;
    &lt;p&gt;But his class was f-ing legit. But be warned, it may or may not be 60 minutes long 😂. Most classes I’ve taken are 45 minutes, but if you like to get there early (like I do), he will start the class early and end the class late and have you BURNING. My max HR hit 172, and I was sore for a week.&lt;/p&gt;
    &lt;p&gt;It was excellent.&lt;/p&gt;
    &lt;p&gt;I also had an entire plan of going home and editing/posting the content from this day, but like I said, I was sore for a week. So, the immediate aftermath of this class was me just lying down on the couch. No content was edited, posted, or thought about for the rest of the day loll.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Footnote: Because I’m always looking at people’s wrists for Apple Watches in class now, I couldn’t help but notice the lady next to me. Most people wear a fitness tracker in class or nothing at all. But this lady next to me was rocking this:&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;End of Week Results &amp;amp; Takeaways&lt;/head&gt;
    &lt;p&gt;Cold DMs actually work (sometimes). I sent maybe 30-40 messages total and got 4-5 meaningful responses. That's not amazing, but it's infinitely better than the zero responses you get when you never reach out at all.&lt;/p&gt;
    &lt;p&gt;Marketing opens doors that code never could. Sebastian seeing my app in person matters more than any feature I could have shipped that week. You can't build your way into someone's awareness - you have to actually show up.&lt;/p&gt;
    &lt;p&gt;You can't analytics your way to relationships. The numbers didn't move (see chart below), but the connections did. Having Lagreeing at Home and Sebastian Lagree be aware of the app and the person behind the app should pay dividends in the future.&lt;/p&gt;
    &lt;p&gt;Content creation is way harder than I thought. As an engineer, I assumed making an Instagram story would take 10 minutes. Turns out creating something that doesn't look like garbage takes a couple of hours. And doing it daily? Forget about it. I planned a whole week of content on Monday and ended up creating everything day-of because I completely underestimated the work involved.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.pixelpusher.club/p/i-forced-myself-to-spend-a-week-in"/><published>2025-09-21T14:00:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323027</id><title>Unified Line and Paragraph Detection by Graph Convolutional Networks (2022)</title><updated>2025-09-22T02:25:02.037927+00:00</updated><content>&lt;doc fingerprint="3d9db40ad4d580ca"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Cryptography and Security&lt;/head&gt;&lt;p&gt; [Submitted on 7 Mar 2025 (v1), last revised 8 Sep 2025 (this version, v15)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:The Beginner's Textbook for Fully Homomorphic Encryption&lt;/head&gt;View PDF&lt;quote&gt;Abstract:Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables computations to be performed directly on encrypted data, as if the data were in plaintext. After all computations are performed on the encrypted data, it can be decrypted to reveal the result. The decrypted value matches the result that would have been obtained if the same computations were applied to the plaintext data.&lt;lb/&gt;FHE supports basic operations such as addition and multiplication on encrypted numbers. Using these fundamental operations, more complex computations can be constructed, including subtraction, division, logic gates (e.g., AND, OR, XOR, NAND, MUX), and even advanced mathematical functions such as ReLU, sigmoid, and trigonometric functions (e.g., sin, cos). These functions can be implemented either as exact formulas or as approximations, depending on the trade-off between computational efficiency and accuracy.&lt;lb/&gt;FHE enables privacy-preserving machine learning by allowing a server to process the client's data in its encrypted form through an ML model. With FHE, the server learns neither the plaintext version of the input features nor the inference results. Only the client, using their secret key, can decrypt and access the results at the end of the service protocol. FHE can also be applied to confidential blockchain services, ensuring that sensitive data in smart contracts remains encrypted and confidential while maintaining the transparency and integrity of the execution process. Other applications of FHE include secure outsourcing of data analytics, encrypted database queries, privacy-preserving searches, efficient multi-party computation for digital signatures, and more.&lt;lb/&gt;As this book is an open project (this https URL), we welcome FHE experts to join us as collaborators to help expand the draft.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Ronny Ko [view email]&lt;p&gt;[v1] Fri, 7 Mar 2025 04:29:11 UTC (33 KB)&lt;/p&gt;&lt;p&gt;[v2] Thu, 13 Mar 2025 15:18:50 UTC (5,237 KB)&lt;/p&gt;&lt;p&gt;[v3] Fri, 14 Mar 2025 03:22:13 UTC (5,239 KB)&lt;/p&gt;&lt;p&gt;[v4] Sun, 13 Apr 2025 13:14:01 UTC (5,258 KB)&lt;/p&gt;&lt;p&gt;[v5] Sat, 26 Apr 2025 18:20:16 UTC (5,275 KB)&lt;/p&gt;&lt;p&gt;[v6] Sun, 4 May 2025 15:31:10 UTC (5,302 KB)&lt;/p&gt;&lt;p&gt;[v7] Mon, 12 May 2025 17:20:32 UTC (5,099 KB)&lt;/p&gt;&lt;p&gt;[v8] Tue, 20 May 2025 16:04:22 UTC (5,062 KB)&lt;/p&gt;&lt;p&gt;[v9] Mon, 26 May 2025 03:42:34 UTC (5,062 KB)&lt;/p&gt;&lt;p&gt;[v10] Sun, 1 Jun 2025 08:45:01 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v11] Sun, 8 Jun 2025 04:45:52 UTC (4,571 KB)&lt;/p&gt;&lt;p&gt;[v12] Mon, 30 Jun 2025 13:04:04 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v13] Mon, 7 Jul 2025 09:54:47 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v14] Wed, 13 Aug 2025 04:21:08 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v15] Mon, 8 Sep 2025 05:39:49 UTC (4,570 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2503.05136"/><published>2025-09-21T14:26:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323207</id><title>DXGI debugging: Microsoft put me on a list</title><updated>2025-09-22T02:25:01.516660+00:00</updated><content>&lt;doc fingerprint="260f8913c3239dc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DXGI debugging: Microsoft put me on a list&lt;/head&gt;
    &lt;p&gt;Why does Space Station 14 crash with ANGLE on ARM64? 6 hours later…&lt;/p&gt;
    &lt;p&gt;So. I’ve been continuing work on getting ARM64 builds out for Space Station 14. The thing I was working on yesterday were launcher builds, specifically a single download that supports both ARM64 and x64. I’d already gotten the game client itself running natively on ARM64, and it worked perfectly fine in my dev environment. I wrote all the new launcher code, am pretty sure I got it right. Zip it up, test it on ARM64, aaand…&lt;/p&gt;
    &lt;p&gt;The game client crashes on Windows ARM64. Both in my VM and on Julian’s real Snapdragon X laptop.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: logs&lt;/head&gt;
    &lt;p&gt;The client logs are empty. They suspiciously cut out right after SDL is initialized.&lt;/p&gt;
    &lt;p&gt;Of course it isn’t that easy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: pulling WinDbg out of the shed&lt;/head&gt;
    &lt;p&gt;Given that there’s no logs, this has to be a native crash. That means it’s WinDbg time.&lt;/p&gt;
    &lt;p&gt;So at first I decided to start &lt;code&gt;Space Station 14 Launcher.exe&lt;/code&gt; directly through WinDbg. This is annoying because I have to go into child processes (with &lt;code&gt;.childdbg 1&lt;/code&gt;) twice, and for some reason there’s a lot of waiting, but it does work…&lt;/p&gt;
    &lt;p&gt;The game crashes in &lt;code&gt;USER32!GetDC&lt;/code&gt; on an illegal instruction, somewhere after SDL does something. I barely glanced at the disassembly but it made no sense to me, so I just assumed there’s some UB happening and didn’t think much of it. After all, why would the implementation of &lt;code&gt;GetDC()&lt;/code&gt; have broken assembly?&lt;/p&gt;
    &lt;code&gt;(3148.35e4): Illegal instruction - code c000001d (first chance)
(3148.35e4): Unknown exception - code c000041d (!!! second chance !!!)
*** WARNING: Unable to verify checksum for C:\Users\Luna\Downloads\SS14.Launcher_Windows\bin_arm64\loader\SDL3.DLL
USER32!GetDC+0x8:
00007ff9`f7be9548 ee8e1db0 ???
&lt;/code&gt;
    &lt;p&gt;WinDbg was also unable to pull stack frames from C# code. It did, thankfully, clearly communicate why this was. Yep, it’s our friend &lt;code&gt;mscordaccore&lt;/code&gt; again!&lt;/p&gt;
    &lt;code&gt;CLRDLL: Consider using ".cordll -lp &amp;lt;path&amp;gt;" command to specify .NET runtime directory.
CLRDLL: Consider using ".cordll -lp &amp;lt;path&amp;gt;" command to specify .NET runtime directory.
&lt;/code&gt;
    &lt;p&gt;However, my attempts to actually follow said instructions were completely fruitless, giving this error:&lt;/p&gt;
    &lt;code&gt;0:027:ARM64EC&amp;gt; .cordll -lp C:\Users\Luna\Downloads\SS14.Launcher_Windows\dotnet_arm64\shared\Microsoft.NETCore.App\9.0.9
CLRDLL: Consider using ".cordll -lp &amp;lt;path&amp;gt;" command to specify .NET runtime directory.
CLR DLL status: ERROR: Unable to load DLL C:\Users\Luna\Downloads\SS14.Launcher_Windows\dotnet_arm64\shared\Microsoft.NETCore.App\9.0.9\mscordaccore_AMD64_arm64_9.0.925.41916.dll, Win32 error 0n87
&lt;/code&gt;
    &lt;p&gt;Why is it trying to run an &lt;code&gt;AMD64&lt;/code&gt; binary? Wait is WinDbg not natively compiled for ARM64? Sigh. Let’s just do it without C# debugging, I can probably manage based off the SDL stack trace. So I pull &lt;code&gt;SDL3.pdb&lt;/code&gt; from our server, drop it next to &lt;code&gt;SDL3.dll&lt;/code&gt;, and then use the UI to reload the symbols. And that gets us a bit further, we now have proper function names for SDL3!&lt;/p&gt;
    &lt;p&gt;So I double click one of the entries in the UI’s stack trace view. And the entire debugger breaks. Stack trace view goes empty. Every action I try to make causes more of these errors to be printed:&lt;/p&gt;
    &lt;code&gt;Machine is not a possible execution machine
Unable to get current machine context, HRESULT 0x8000FFFF
Machine is not a possible execution machine
Unable to get current machine context, HRESULT 0x8000FFFF
Machine is not a possible execution machine
Unable to get current machine context, HRESULT 0x8000FFFF
Machine is not a possible execution machine
Machine is not a possible execution machine
&lt;/code&gt;
    &lt;p&gt;Now even WinDbg is broken??&lt;/p&gt;
    &lt;p&gt;Googling these errors gave nothing useful. One of them gave not a single result. After just pondering the error for a moment, I thought “wait, why is the command prompt still saying &lt;code&gt;ARM64EC&amp;gt;&lt;/code&gt;? ARM64EC is for emulation, but the active debugger processes (&lt;code&gt;SS14.Launcher.exe&lt;/code&gt; and &lt;code&gt;SS14.Loader.exe&lt;/code&gt;) are both native ARM64.&lt;/p&gt;
    &lt;p&gt;Turns out that it’s because I started &lt;code&gt;Space Station 14 Launcher.exe&lt;/code&gt; directly. You see, that executable is x64 native, and its only job is to set up the .NET environment and launch the actual ARM64 executable. Something about starting the debugging session with that program causes WinDbg to get extremely confused when later looking at the child processes it spawns.&lt;/p&gt;
    &lt;p&gt;From this point on I just started launching &lt;code&gt;SS14.Launcher.exe&lt;/code&gt; directly1. This means I wasn’t setting up the same &lt;code&gt;DOTNET_ROOT&lt;/code&gt; (because WinDbg can’t set environment variables when launching things… yes really), but this didn’t really matter. This fixed both the “Machine is not a possible execution machine” errors and the issues with showing C# stack traces. I guess WinDbg is compiled for ARM64 after all, and it just decided to run an x64 debug host when you start debugging an x64 application. Fair enough I guess?&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: what’s SDL doing?&lt;/head&gt;
    &lt;p&gt;After figuring out all of the above, we could really get started. I also opted to swap out &lt;code&gt;SDL3.dll&lt;/code&gt; with a locally-built copy, so that the debugger could locate source files2. What SDL is doing is pretty straight forward: the first time the window is shown, it clears the background with GDI commands:&lt;/p&gt;
    &lt;p&gt;I mean… this is like, fine, right? I mean I don’t know much about this code, but why would this crash on ARM but not x64??? The window is valid. &lt;code&gt;GetDC()&lt;/code&gt; is an extremely fundamental Win32 function call. If there was something broken with it, my OS would not be usable. What the fuck is going on?&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;if (ShouldClearWindowOnEraseBackground(data))&lt;/code&gt; allows it to be disabled via a hint, which can be specified by environment variable. This fixes the crash… until you open a second OS window, then SDL3 calls &lt;code&gt;GetDC()&lt;/code&gt; once again and that crashes. Not a solution.&lt;/p&gt;
    &lt;p&gt;So I checked the actual &lt;code&gt;USER32!GetDC&lt;/code&gt; again, and this time I actually paid attention to the disassembly code instead of glossing over it. What the fuck? &lt;code&gt;pacibsp&lt;/code&gt; is missing at the start. It’s loading an address for a jump that only jumps to the next instruction, which is invalid. In some runs, said instruction was instead a broken &lt;code&gt;x26&lt;/code&gt;-relative &lt;code&gt;str&lt;/code&gt; instruction that AV’d because the register was all zeroes.&lt;/p&gt;
    &lt;p&gt;At this point let’s introduce the villain. You might have noticed it in the call stack: &lt;code&gt;DXGI!My_GetDC&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For those who aren’t well-versed in DirectX stuff: DXGI is a fundamental part of DirectX ever since DirectX 10 (Vista). For those who have never modded a game before: a detour is a hack that injects instructions into other functions at runtime, to do evil shit. Why the hell is Microsoft using this in DXGI?&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: DXGI despair&lt;/head&gt;
    &lt;p&gt;Through the debugging adventure, I ended up putting a breakpoint on every call to &lt;code&gt;USER32!GetDC&lt;/code&gt;. The first few calls are fine, but then the last one, the one that crashes, is not.&lt;/p&gt;
    &lt;p&gt;At this point I got really desperate. “Asking in low-level programming Discords”-level desperate. I ended up asking for help in the DirectX Discord (yes, there’s an official DirectX Discord, and there’s many MS employees in there).&lt;/p&gt;
    &lt;p&gt;I would like to thank Jesse Natalia from the DirectX Discord for responding swiftly to my messages in there.&lt;/p&gt;
    &lt;p&gt;After some back and forth there, I wanted to catch DXGI in the act. Maybe that would tell me something, I don’t know. So with a simple &lt;code&gt;ba w4 USER32!GetDC&lt;/code&gt;, I put a hardware breakpoint for whenever something would write to &lt;code&gt;USER32!GetDC&lt;/code&gt;. I did have to awkwardly “run the program for just a little bit” because &lt;code&gt;USER32.dll&lt;/code&gt; isn’t loaded immediately at program startup.3&lt;/p&gt;
    &lt;p&gt;While writing this blog post I realized there is an intelligent way to do this. It’s called &lt;code&gt;sxe ld USER32.dll&lt;/code&gt;. I’ve literally written about it in this blog before. Oops.&lt;/p&gt;
    &lt;p&gt;Now this is very interesting. The bottom of the stack trace is quite expected: SDL creates a window, uses ANGLE’s EGL implementation for this, that does a bunch of stuff, and eventually creates a DXGI swapchain. But then what is &lt;code&gt;UpgradeSwapEffect&lt;/code&gt;? And why is it installing a detour?&lt;/p&gt;
    &lt;p&gt;Ah, I already know what this is.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optimizing windowed games: flip model&lt;/head&gt;
    &lt;p&gt;Right. So. DirectX.&lt;/p&gt;
    &lt;p&gt;When you create a DirectX swapchain, you specify an “effect”, which falls into two categories: “bitblt” and “flip”. To make a long story short: bitblt is the “original” one, while flip is the much more modern one added in Windows 84. It’s more efficient and performant, and all software should be using it. Furthermore, on modern versions of Windows and with a GPU supporting “Multiplane Overlays”, flip model actually enables windowed games to be displayed with zero additional latency over “exclusive” fullscreen mode.&lt;/p&gt;
    &lt;p&gt;Of course, many games never get updated, or they’re stuck on an ancient version. And many of these games don’t care. So in Windows 11, Microsoft added “Optimizations for windowed games”, which forcibly enables flip model on games that are still using bitblt. Why does DXGI need to install detours for this? Probably some compatibility shit with the bitblt model. I don’t have any deep knowledge of how Win32 GDI stuff works, but it’s not hard for me to imagine there’s some interplay here they need to take care of. I can also confirm that disabling the feature in Windows’ settings menu fixes the crash!&lt;/p&gt;
    &lt;p&gt;If you’re wondering why SS14 isn’t using flip model: it’s because we can’t. We’re not creating the swapchain directly, ANGLE is. And ANGLE is continuing to use &lt;code&gt;SWAP_EFFECT_SEQUENTIAL&lt;/code&gt;. I actually once experimented with SS14 managing the swapchain, but this ran into some ANGLE limitations and I never got around to ironing out all the edge cases and crashes. I’d rather just spend the brain power on ditching OpenGL, rather than trying to continue working with this broken API.5.&lt;/p&gt;
    &lt;p&gt;So here we are. The entire debugging story so far, you’re like, “surely Microsoft didn’t break DXGI on ARM64, huh???” But now it’s becoming plausible. There’s barely any native ARM64 Windows games, and surely none that are using bitblt swapchains. And guess what, you don’t even need &lt;code&gt;GetDC()&lt;/code&gt; for modern DirectX games. SDL does it because it’s heavily designed for OpenGL. Most games run in x64 emulation, and that presumably works fine. Everything adds up to it being possible this just genuinely fell under the radar at Microsoft.&lt;/p&gt;
    &lt;p&gt;This should be pretty easy to verify in a minimal example. I cloned an old DirectX SDK sample, updated it to be compiled for ARM64, added some &lt;code&gt;GetDC()&lt;/code&gt; calls, aaand… nope, no crash. Then I spent quite a while trying various stuff: comparing the swapchain creation code with that of ANGLE, changing various parameters, verifying whether the detour was being installed (it wasn’t). But eventually, I did find it.&lt;/p&gt;
    &lt;p&gt;It’s the filename.&lt;/p&gt;
    &lt;p&gt;Of course it’s the goddamn filename.&lt;/p&gt;
    &lt;head rend="h2"&gt;I’m on a list&lt;/head&gt;
    &lt;p&gt;It only happens when the program is called &lt;code&gt;SS14.Loader.exe&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The final piece of the puzzle. It didn’t happen in a dev environment because then the exe isn’t named &lt;code&gt;SS14.Loader.exe&lt;/code&gt;. Microsoft only enables “Optimizations for windowed games” on a specific list of games. And guess what, none of those select games are on ARM64, at least until I was unfortunate enough to port mine. How did we get on the list? Who knows.&lt;/p&gt;
    &lt;p&gt;Microsoft put me on a list, that ships with every Windows install. And this list actually broke my game. Achievement unlocked!&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum: why ANGLE, and about OpenGL on Windows ARM64&lt;/head&gt;
    &lt;p&gt;Traditionally, OpenGL on Windows has been implemented by the 3 IHVs (Nvidia, AMD, Intel). If they didn’t explicitly go out of their way to add it to their drivers, you’d have no OpenGL beyond 1.0. Those new Snapdragon X devices, however, use Microsoft’s new-ish “OpenGL on D3D12” driver. It’s actually part of Mesa!&lt;/p&gt;
    &lt;p&gt;The problem with Space Station 14 is that said driver is broken for us, causing severe graphical artifacts and flickering. I had been aware of this for years, because the same driver is used for the GPU acceleration of WSL2, but I never bothered to report it 😬. So for the purpose of porting SS14 to ARM64 Windows, I decided to just immediately force on ANGLE on Qualcomm devices, and call it a day.&lt;/p&gt;
    &lt;p&gt;What I didn’t know until yesterday is that the OpenGL on D3D12 driver does not ship with Qualcomm’s drivers! It’s on the Microsoft store! I can even install it in my VM and get it to emulate OpenGL on top of DirectX’s software renderer (WARP), just like I had been doing with ANGLE. I’ve finally bothered to report the graphical issues, so hopefully it gets fixed eventually. If it does get fixed, Microsoft Store distribution means it shouldn’t take too long to trickle down to users, and then we can stop enforcing ANGLE on Qualcomm devices.&lt;/p&gt;
    &lt;p&gt;For Space Station 14, I will say that this means I’ll be postponing official Windows ARM64 support for now. At least until either bug (OpenGL on D3D12 or ARM64 DXGI detours) are fixed. Or when I finally rewrite the renderer to drop OpenGL, that’s also an option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum: clarifications&lt;/head&gt;
    &lt;p&gt;(This bit added a few hours after publishing)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Why not just rename the &lt;code&gt;.exe&lt;/code&gt;on ARM”: what I didn’t mention is that Steamworks does not support ARM64 Linux or Windows, at the moment. That means ARM64 builds will not be on Steam regardless, and I didn’t feel like going through even more the effort to add a workaround, just to improve performance for that 0.001% of people playing the game on a Snapdragon X device while also downloading from our website. And God forbid Microsoft updates the list later based on a bulk import of some random filenames and catches the new name too. The game already works when emulated, so I’m leaving it there until Windows is fixed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Debugging&lt;/p&gt;&lt;code&gt;SS14.Loader.exe&lt;/code&gt;directly would be a pain in the ass because it needs like a dozen arguments and environment variables configured by the launcher. I’d rather not. ↩︎&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I assume there’s a way to configure WinDbg to load these if the paths don’t line up properly… but I wouldn’t know how. Lol. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This is because, being a .NET app, most native libraries are dynamically loaded at runtime. Only libraries that are direct dependencies of the&lt;/p&gt;&lt;code&gt;.exe&lt;/code&gt;are available in the “initial debugger break” period before the program really starts. ↩︎&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you were one of those people that held onto Windows 7 for as long as possible, this is the kind of shit you were missing out on. Seriously, 8.1 was fine. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fuck EGL especially. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://slugcat.systems/post/25-09-21-dxgi-debugging-microsoft-put-me-on-a-list/"/><published>2025-09-21T14:45:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323793</id><title>Oxford loses top 3 university ranking in the UK</title><updated>2025-09-22T02:24:59.915241+00:00</updated><content>&lt;doc fingerprint="c0fc00182795c8d8"&gt;
  &lt;main&gt;
    &lt;p&gt;The University of Oxford has fallen out of the top three universities in the UK for the first time, according to The Times and The Sunday Times Good University Guide for 2026.&lt;/p&gt;
    &lt;p&gt;Both Oxford and Cambridge universities have been supplanted by Durham University, which now holds the third-place spot among the top universities in the UK.&lt;/p&gt;
    &lt;p&gt;Oxford and Cambridge are tied for fourth in the 2026 rankings, after falling due to their relatively poor performance in the latest National Student Survey.&lt;/p&gt;
    &lt;p&gt;Durham University was named The Times’s University of the Year, although the number-one ranked university in the UK remained the London School of Economics and Political Science (LSE) for the second year in a row.&lt;/p&gt;
    &lt;p&gt;Second place was held by the University of St Andrews, again for the second consecutive year.&lt;/p&gt;
    &lt;p&gt;While the University of St Andrews ranked very highly in student experience and teaching quality, it lost out to the LSE in graduate prospects and research quality.&lt;/p&gt;
    &lt;p&gt;Durham University improved by 30 places year-on-year in its students’ evaluation of teaching quality, which was the main driver in securing its third place in the overall university league table.&lt;/p&gt;
    &lt;p&gt;“Durham is an outstanding place to study. We ensure that every student can grow and thrive here,” said Durham University Vice-Chancellor Professor Karen O’Brien.&lt;/p&gt;
    &lt;p&gt;“Our loyal, engaged alumni are testament to the impressive career prospects that await our graduates.”&lt;/p&gt;
    &lt;p&gt;The table below shows the top 20 universities in the United Kingdom, according to The Times University Rankings 2026.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;London School of Economics and Political Science&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;University of St Andrews&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Durham University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4/5&lt;/cell&gt;
        &lt;cell&gt;University of Cambridge&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4/5&lt;/cell&gt;
        &lt;cell&gt;University of Oxford&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Imperial College London&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;University of Bath&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;University of Warwick&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;University College London&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;University of Bristol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;University of Strathclyde&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;Loughborough University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;University of Sheffield&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;University of Exeter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;Lancaster University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;University of Birmingham&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;University of Southampton&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;University of Liverpool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;King’s College London&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;University of York&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hotminute.co.uk/2025/09/19/oxford-loses-top-3-university-ranking-for-the-first-time/"/><published>2025-09-21T15:51:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323856</id><title>LaLiga's Anti-Piracy Crackdown Triggers Widespread Internet Disruptions in Spain</title><updated>2025-09-22T02:24:59.694178+00:00</updated><content/><link href="https://reclaimthenet.org/laligas-anti-piracy-crackdown-triggers-widespread-internet-disruptions"/><published>2025-09-21T15:57:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323875</id><title>Show HN: Freeing GPUs stuck by runaway jobs</title><updated>2025-09-22T02:24:59.158769+00:00</updated><content>&lt;doc fingerprint="e409f88b6c106fd9"&gt;
  &lt;main&gt;
    &lt;p&gt;A CLI tool for managing GPUs across NVIDIA, AMD, Intel, and Apple Silicon systems. Monitor, control, and secure your GPU infrastructure with ease.&lt;/p&gt;
    &lt;p&gt;Join our Discord community for discussions, support, and updates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monitor GPUs: Real-time usage, memory, temperature, and processes&lt;/item&gt;
      &lt;item&gt;Kill Processes: Gracefully terminate stuck GPU processes&lt;/item&gt;
      &lt;item&gt;Security: Detect crypto miners and suspicious activity&lt;/item&gt;
      &lt;item&gt;Guard Mode: Policy enforcement to prevent resource abuse&lt;/item&gt;
      &lt;item&gt;Dashboard: Web interface for cluster monitoring&lt;/item&gt;
      &lt;item&gt;Remote: Manage GPUs across multiple servers&lt;/item&gt;
      &lt;item&gt;Multi-Vendor: Works with NVIDIA, AMD, Intel, and Apple Silicon&lt;/item&gt;
      &lt;item&gt;AI Integration: MCP server for AI assistant integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For faster development builds:&lt;/p&gt;
    &lt;code&gt;# Fast release build (recommended for development)
cargo build --profile release-fast

# Standard release build (optimized for production)
cargo build --release

# Maximum optimization (slowest, best performance)
cargo build --profile release-max&lt;/code&gt;
    &lt;p&gt;Build times on typical hardware:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debug build: ~3 seconds&lt;/item&gt;
      &lt;item&gt;Release-fast: ~28 seconds&lt;/item&gt;
      &lt;item&gt;Release: ~28 seconds (improved from 76 seconds)&lt;/item&gt;
      &lt;item&gt;Release-max: ~60+ seconds (maximum optimization)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Linux (Ubuntu/Debian):&lt;/p&gt;
    &lt;code&gt;sudo apt install build-essential libssl-dev pkg-config&lt;/code&gt;
    &lt;p&gt;Linux (Fedora/RHEL/CentOS):&lt;/p&gt;
    &lt;code&gt;sudo dnf install gcc gcc-c++ pkg-config openssl-devel
# or for older systems:
# sudo yum install gcc gcc-c++ pkg-config openssl-devel&lt;/code&gt;
    &lt;p&gt;macOS:&lt;/p&gt;
    &lt;code&gt;# Install Xcode command line tools
xcode-select --install
# OpenSSL is included with macOS&lt;/code&gt;
    &lt;p&gt;Windows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Visual Studio Build Tools&lt;/item&gt;
      &lt;item&gt;OpenSSL is handled automatically by vcpkg&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NVIDIA: NVIDIA drivers installed&lt;/item&gt;
      &lt;item&gt;AMD: ROCm drivers installed&lt;/item&gt;
      &lt;item&gt;Intel: intel-gpu-tools package installed&lt;/item&gt;
      &lt;item&gt;Apple Silicon: macOS with Apple Silicon (M1/M2/M3/M4)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OS: Linux, macOS, or Windows&lt;/item&gt;
      &lt;item&gt;Rust: 1.70+ (for building from source)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Build from source (first build may take 2-3 minutes)
git clone https://github.com/kagehq/gpu-kill.git
cd gpu-kill
cargo build --release

# Or install via Cargo
cargo install gpukill

# List your GPUs
gpukill --list

# Watch GPU usage in real-time
gpukill --list --watch&lt;/code&gt;
    &lt;code&gt;# Kill a stuck process
gpukill --kill --pid 12345 --force

# Reset a crashed GPU
gpukill --reset --gpu 0 --force

# Start the web dashboard (backend only)
gpukill --server --server-port 8080&lt;/code&gt;
    &lt;p&gt;Start the web interface for cluster monitoring:&lt;/p&gt;
    &lt;code&gt;# 1. Start the backend API server
gpukill --server --server-port 8080

# 2. Start the dashboard UI (in a new terminal)
cd dashboard
npm install  # First time only
npm run dev

# 3. Access the dashboard
open http://localhost:3000&lt;/code&gt;
    &lt;p&gt;Note: You need both the backend server (port 8080) and frontend UI (port 3000) running for the dashboard to work.&lt;/p&gt;
    &lt;p&gt;The dashboard provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time monitoring of all GPUs&lt;/item&gt;
      &lt;item&gt;Security detection with threat analysis&lt;/item&gt;
      &lt;item&gt;Policy management for resource control&lt;/item&gt;
      &lt;item&gt;Cluster overview with Magic Moment insights&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GPU Kill includes a MCP server that enables AI assistants to interact with GPU management functionality:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Resources: Read GPU status, processes, audit data, policies, and security scans&lt;/item&gt;
      &lt;item&gt;Tools: Kill processes, reset GPUs, scan for threats, create policies&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Start the MCP server
cargo run --release -p gpukill-mcp

# Server runs on http://localhost:3001/mcp&lt;/code&gt;
    &lt;p&gt;Ask your AI to use the tools.&lt;/p&gt;
    &lt;code&gt;What GPUs do I have and what's their current usage?
&lt;/code&gt;
    &lt;code&gt;Kill the Python process that's stuck on GPU 0
&lt;/code&gt;
    &lt;code&gt;Kill all training processes that are using too much GPU memory
&lt;/code&gt;
    &lt;code&gt;Show me GPU usage and kill any stuck processes
&lt;/code&gt;
    &lt;code&gt;Scan for crypto miners and suspicious activity
&lt;/code&gt;
    &lt;code&gt;Create a policy to limit user memory usage to 8GB
&lt;/code&gt;
    &lt;code&gt;Reset GPU 1 because it's not responding
&lt;/code&gt;
    &lt;code&gt;What processes are currently using my GPUs?
&lt;/code&gt;
    &lt;p&gt;See mcp/README.md for detailed MCP server documentation.&lt;/p&gt;
    &lt;code&gt;# Scan for crypto miners and suspicious activity
gpukill --audit --rogue

# Configure detection rules
gpukill --audit --rogue-config&lt;/code&gt;
    &lt;code&gt;# Enable Guard Mode
gpukill --guard --guard-enable

# Test policies safely
gpukill --guard --guard-test-policies&lt;/code&gt;
    &lt;p&gt;For detailed security and policy documentation, see DETAILED.md.&lt;/p&gt;
    &lt;p&gt;Manage GPUs across multiple servers via SSH:&lt;/p&gt;
    &lt;code&gt;# List GPUs on remote server
gpukill --remote staging-server --list

# Kill process on remote server
gpukill --remote prod-gpu-01 --kill --pid 1234

# Reset GPU on remote server
gpukill --remote gpu-cluster --reset --gpu 0&lt;/code&gt;
    &lt;p&gt;OpenSSL not found:&lt;/p&gt;
    &lt;code&gt;# Ubuntu/Debian
sudo apt install build-essential libssl-dev pkg-config

# Fedora/RHEL/CentOS
sudo dnf install gcc gcc-c++ pkg-config openssl-devel&lt;/code&gt;
    &lt;p&gt;Other common build issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ensure you have the latest Rust toolchain: &lt;code&gt;rustup update&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Clean and rebuild: &lt;code&gt;cargo clean &amp;amp;&amp;amp; cargo build --release&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check system dependencies are installed (see Requirements section)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;gpukill --help                    # Show all options
gpukill --version                 # Show version&lt;/code&gt;
    &lt;p&gt;GPU Kill uses a CI/CD pipeline with automatic GPU testing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Conditional GPU testing - Runs automatically when GPU hardware is available&lt;/item&gt;
      &lt;item&gt;✅ Multi-vendor GPU testing on real hardware (NVIDIA, AMD, Intel, Apple Silicon)&lt;/item&gt;
      &lt;item&gt;✅ Hot Aisle integration - Optional on-demand GPU instance provisioning for comprehensive testing&lt;/item&gt;
      &lt;item&gt;✅ Cross-platform compatibility testing&lt;/item&gt;
      &lt;item&gt;✅ Performance benchmarking and profiling&lt;/item&gt;
      &lt;item&gt;✅ Security auditing and compliance checks&lt;/item&gt;
      &lt;item&gt;✅ Stress testing for reliability validation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;On GitHub hosted runners: GPU tests skip gracefully (no GPU hardware)&lt;/item&gt;
      &lt;item&gt;On self-hosted runners: GPU tests run automatically when GPU hardware is detected&lt;/item&gt;
      &lt;item&gt;On cloud instances: GPU tests run automatically when GPU hardware is available&lt;/item&gt;
      &lt;item&gt;On developer machines: GPU tests run automatically when GPU hardware is detected&lt;/item&gt;
      &lt;item&gt;Via Hot Aisle: On-demand GPU instance provisioning for comprehensive testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Option 1: Test Locally (Already Working)&lt;/p&gt;
    &lt;code&gt;cargo test --test gpu_hardware_tests  # Runs on your GPU hardware&lt;/code&gt;
    &lt;p&gt;Option 2: Set Up Cloud GPU (5 minutes)&lt;/p&gt;
    &lt;code&gt;# On any cloud GPU instance:
curl -sSL https://raw.githubusercontent.com/kagehq/gpu-kill/main/scripts/setup-gpu-runner.sh | bash&lt;/code&gt;
    &lt;p&gt;Option 3: Self-Hosted Runner See CI_CD.md for detailed information about our testing infrastructure and how to set up self-hosted runners with GPU hardware.&lt;/p&gt;
    &lt;p&gt;Option 4: Hot Aisle Integration (Optional)&lt;/p&gt;
    &lt;code&gt;# Build with Hot Aisle feature
cargo build --release --features hotaisle

# Integration tests run automatically (no API key required)
# For actual GPU testing:
# 1. Set up HOTAISLE_API_KEY in GitHub Secrets
# 2. Manually trigger "Hot Aisle GPU Testing" workflow
# 3. Tests run on real GPU hardware with automatic cleanup&lt;/code&gt;
    &lt;p&gt;Option 5: Cloud GPU Setup See docs/CLOUD_GPU_SETUP.md for AWS, GCP, and Azure GPU instance setup.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DETAILED.md - Complete documentation, API reference, and advanced features&lt;/item&gt;
      &lt;item&gt;Dashboard README - Web interface documentation&lt;/item&gt;
      &lt;item&gt;CI_CD.md - CI/CD pipeline and testing infrastructure&lt;/item&gt;
      &lt;item&gt;docs/HOTAISLE_INTEGRATION.md - Hot Aisle integration guide&lt;/item&gt;
      &lt;item&gt;docs/CLOUD_GPU_SETUP.md - Cloud GPU setup guide (AWS, GCP, Azure)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the FSL-1.1-MIT License. See the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/kagehq/gpu-kill"/><published>2025-09-21T16:00:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324343</id><title>Timesketch: Collaborative forensic timeline analysis</title><updated>2025-09-22T02:24:58.683693+00:00</updated><content>&lt;doc fingerprint="f7201de7e5f62665"&gt;
  &lt;main&gt;
    &lt;p&gt;Timesketch is an open-source tool for collaborative forensic timeline analysis. Using sketches you and your collaborators can easily organize your timelines and analyze them all at the same time. Add meaning to your raw data with rich annotations, comments, tags and stars.&lt;/p&gt;
    &lt;p&gt;This is not an official Google product (experimental or otherwise), it is just code that happens to be owned by Google.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/google/timesketch"/><published>2025-09-21T16:43:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324349</id><title>Sj.h: A tiny little JSON parsing library in ~150 lines of C99</title><updated>2025-09-22T02:24:58.256636+00:00</updated><content>&lt;doc fingerprint="afd877d9ee5a4e03"&gt;
  &lt;main&gt;
    &lt;p&gt;A tiny little JSON parsing library&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;~150 lines of C99&lt;/item&gt;
      &lt;item&gt;Zero-allocations with minimal state&lt;/item&gt;
      &lt;item&gt;Error messages with &lt;code&gt;line:column:&lt;/code&gt;location&lt;/item&gt;
      &lt;item&gt;No number parsing: &lt;code&gt;strtod&lt;/code&gt;,&lt;code&gt;atoi&lt;/code&gt;? Handle them how you want&lt;/item&gt;
      &lt;item&gt;No string parsing: bring your own unicode surrogate pair handling (or don't)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A small program to load a rectangle from a JSON string into a &lt;code&gt;Rect&lt;/code&gt; struct:&lt;/p&gt;
    &lt;code&gt;char *json_text = "{ \"x\": 10, \"y\": 20, \"w\": 30, \"h\": 40 }";

typedef struct { int x, y, w, h; } Rect;

bool eq(sj_Value val, char *s) {
    size_t len = val.end - val.start;
    return strlen(s) == len &amp;amp;&amp;amp; !memcmp(s, val.start, len);
}

int main(void) {
    Rect rect = {0};

    sj_Reader r = sj_reader(json_text, strlen(json_text));
    sj_Value obj = sj_read(&amp;amp;r);

    sj_Value key, val;
    while (sj_iter_object(&amp;amp;r, obj, &amp;amp;key, &amp;amp;val)) {
        if (eq(key, "x")) { rect.x = atoi(val.start); }
        if (eq(key, "y")) { rect.y = atoi(val.start); }
        if (eq(key, "w")) { rect.w = atoi(val.start); }
        if (eq(key, "h")) { rect.h = atoi(val.start); }
    }

    printf("rect: { %d, %d, %d, %d }\n", rect.x, rect.y, rect.w, rect.h);
    return 0;
}&lt;/code&gt;
    &lt;p&gt;See the demo folder for further usage examples.&lt;/p&gt;
    &lt;p&gt;This is free and unencumbered software released into the public domain. See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rxi/sj.h"/><published>2025-09-21T16:43:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45325410</id><title>Bringing Observability to Claude Code: OpenTelemetry in Action</title><updated>2025-09-22T02:24:57.972386+00:00</updated><content>&lt;doc fingerprint="37095ff26f17da6a"&gt;
  &lt;main&gt;
    &lt;p&gt;AI coding assistants like Claude Code are becoming core parts of modern development workflows. But as with any powerful tool, the question quickly arises: how do we measure and monitor its usage? Without proper visibility, it’s hard to understand adoption, performance, and the real value Claude brings to engineering teams. For leaders and platform engineers, that lack of observability can mean flying blind when it comes to understanding ROI, productivity gains, or system reliability.&lt;/p&gt;
    &lt;p&gt;That’s where observability comes in. By leveraging OpenTelemetry and SigNoz, we built an observability pipeline that makes Claude Code usage measurable and actionable. From request volumes to latency metrics, everything flows into SigNoz dashboards, giving us clarity on how Claude is shaping developer workflows and helping us spot issues before they snowball.&lt;/p&gt;
    &lt;p&gt;In this post, we’ll walk through how we connected Claude Code’s monitoring hooks with OpenTelemetry and exported everything into SigNoz. The result: a streamlined, data-driven way to shine a light on how developers actually interact with Claude Code and to help teams make smarter, evidence-backed decisions about scaling AI-assisted coding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Monitor Claude Code?&lt;/head&gt;
    &lt;p&gt;Claude Code is powerful, but like any tool that slips seamlessly into a developer’s workflow, it can quickly turn into a black box. You know people are using it, but how much, how effectively, and at what cost? Without telemetry, you’re left guessing whether Claude is driving real impact or just lurking quietly in the background.&lt;/p&gt;
    &lt;p&gt;That’s why monitoring matters. With the right observability pipeline, Claude Code stops being an invisible assistant and starts showing its true footprint in your engineering ecosystem. By tracking key logs and metrics in SigNoz dashboards, we can answer questions that directly tie usage to value:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Total token usage &amp;amp; cost → How much are we spending, and where are those tokens going?&lt;/item&gt;
      &lt;item&gt;Sessions, conversations &amp;amp; requests per user → Who’s using Claude regularly, and what does “active usage” really look like?&lt;/item&gt;
      &lt;item&gt;Quota visibility → How close are we to hitting limits (like the 5-hour quota), and do we need to adjust capacity?&lt;/item&gt;
      &lt;item&gt;Performance trends → From command duration over time to request success rate, are developers getting fast, reliable responses?&lt;/item&gt;
      &lt;item&gt;Behavior insights → Which terminals are people using (VS Code, Apple Terminal, etc.), how are decisions distributed (accept vs. reject), and what tool types are most popular?&lt;/item&gt;
      &lt;item&gt;Model distribution → Which Claude variants (Sonnet, Opus, etc.) are driving the most activity?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Together, this info transforms Claude Code from “just another AI tool” into something measurable, transparent, and optimizable. Monitoring gives you the clarity to not only justify adoption but also to fine-tune how Claude fits into developer workflows.&lt;/p&gt;
    &lt;p&gt;And that’s where the observability stack comes in. OpenTelemetry and SigNoz give us the tools to capture this data, export them cleanly, and turn raw usage into actionable insights. Let’s take a closer look at how they fit into the picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;OpenTelemetry and SigNoz: The Observability Power Duo&lt;/head&gt;
    &lt;p&gt;What is OpenTelemetry?&lt;/p&gt;
    &lt;p&gt;OpenTelemetry (OTel) is an open-source observability framework that makes it easy to collect telemetry data—traces, metrics, and logs—from across your stack. It’s a CNCF project, widely adopted, and built with flexibility in mind. The key advantage? You instrument once, and your telemetry can flow to any backend you choose. No vendor lock-in and no tangled integrations.&lt;/p&gt;
    &lt;p&gt;For Claude Code, this means we can capture usage and performance signals at a very granular level. Every request, every session, every token consumed can be traced and exported via OpenTelemetry. Instead of Claude Code being a black box, you now have standardized hooks to surface: how long requests take, how often they succeed, and which models or terminals are driving activity.&lt;/p&gt;
    &lt;p&gt;What is SigNoz?&lt;/p&gt;
    &lt;p&gt;SigNoz is an all-in-one observability platform that pairs perfectly with OpenTelemetry. Think of it as the dashboard and analysis layer. The place where all your Claude Code telemetry comes to life. With SigNoz, you can visualize logs and metrics in real time, slice usage data by user or model, and set alerts when things go wrong.&lt;/p&gt;
    &lt;p&gt;In our case, that means building dashboards that track:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Token usage &amp;amp; costs over time&lt;/item&gt;
      &lt;item&gt;Requests per user and per terminal type&lt;/item&gt;
      &lt;item&gt;Command durations and success rates&lt;/item&gt;
      &lt;item&gt;Model distributions (e.g., Sonnet vs Opus)&lt;/item&gt;
      &lt;item&gt;User decisions (accept vs reject)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By combining OpenTelemetry’s standardized data collection with SigNoz’s rich visualization and alerting, you get a complete observability stack for Claude Code. The result is not just raw logs and metrics. It’s a full picture of Claude Code in action, right where you need it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Monitoring Claude Code&lt;/head&gt;
    &lt;p&gt;Check out detailed instructions on how to set up OpenTelemetry instrumentation for your Claude Code usage over here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Option 1 (VSCode)&lt;/head&gt;
    &lt;p&gt;Step 1: Launch VSCode with telemetry enabled&lt;/p&gt;
    &lt;code&gt;CLAUDE_CODE_ENABLE_TELEMETRY=1 \
OTEL_METRICS_EXPORTER=otlp \
OTEL_LOGS_EXPORTER=otlp \
OTEL_EXPORTER_OTLP_PROTOCOL=grpc \
OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.&amp;lt;region&amp;gt;.signoz.cloud:443" \
OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=&amp;lt;your-ingestion-key&amp;gt;" \
OTEL_METRIC_EXPORT_INTERVAL=10000 \
OTEL_LOGS_EXPORT_INTERVAL=5000 \
code .
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set the &lt;code&gt;&amp;lt;region&amp;gt;&lt;/code&gt;to match your SigNoz Cloud region&lt;/item&gt;
      &lt;item&gt;Replace &lt;code&gt;&amp;lt;your-ingestion-key&amp;gt;&lt;/code&gt;with your SigNoz ingestion key&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This will open VSCode with the required environment variables already configured. From here, any Claude Code activity will automatically generate telemetry and export logs to your SigNoz Cloud instance.&lt;/p&gt;
    &lt;p&gt;For convenience, you can also clone our bash script, update it with your SigNoz endpoint and ingestion key, and run it directly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Option 2 (Terminal)&lt;/head&gt;
    &lt;p&gt;Step 1: Launch Claude Code with telemetry enabled&lt;/p&gt;
    &lt;code&gt;CLAUDE_CODE_ENABLE_TELEMETRY=1 \
OTEL_METRICS_EXPORTER=otlp \
OTEL_LOGS_EXPORTER=otlp \
OTEL_EXPORTER_OTLP_PROTOCOL=grpc \
OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.&amp;lt;region&amp;gt;.signoz.cloud:443" \
OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=&amp;lt;your-ingestion-key&amp;gt;" \
OTEL_METRIC_EXPORT_INTERVAL=10000 \
OTEL_LOGS_EXPORT_INTERVAL=5000 \
claude
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set the &lt;code&gt;&amp;lt;region&amp;gt;&lt;/code&gt;to match your SigNoz Cloud region&lt;/item&gt;
      &lt;item&gt;Replace &lt;code&gt;&amp;lt;your-ingestion-key&amp;gt;&lt;/code&gt;with your SigNoz ingestion key&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This will launch Claude Code with telemetry enabled. Any Claude Code activity in the terminal session will automatically generate and export logs and metrics to your SigNoz Cloud instance.&lt;/p&gt;
    &lt;p&gt;For convenience, you can also clone our bash script, update it with your SigNoz endpoint and ingestion key, and run it directly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Administrator Configuration&lt;/head&gt;
    &lt;p&gt;Administrators can configure OpenTelemetry settings for all users through the managed settings file. This allows for centralized control of telemetry settings across an organization. See the settings precedence for more information about how settings are applied.&lt;/p&gt;
    &lt;p&gt;The managed settings file is located at:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS: &lt;code&gt;/Library/Application Support/ClaudeCode/managed-settings.json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Linux and WSL: &lt;code&gt;/etc/claude-code/managed-settings.json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Windows: &lt;code&gt;C:\ProgramData\ClaudeCode\managed-settings.json&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example managed settings configuration:&lt;/p&gt;
    &lt;code&gt;{
  "env": {
    "CLAUDE_CODE_ENABLE_TELEMETRY": "1",
    "OTEL_METRICS_EXPORTER": "otlp",
    "OTEL_LOGS_EXPORTER": "otlp",
    "OTEL_EXPORTER_OTLP_PROTOCOL": "grpc",
    "OTEL_EXPORTER_OTLP_ENDPOINT": "http://collector.company.com:4317",
    "OTEL_EXPORTER_OTLP_HEADERS": "Authorization=Bearer company-token"
  }
}
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Managed settings can be distributed via MDM (Mobile Device Management) or other device management solutions. Environment variables defined in the managed settings file have high precedence and cannot be overridden by users.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Example Configurations&lt;/head&gt;
    &lt;code&gt;# Console debugging (1-second intervals)
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=console
export OTEL_METRIC_EXPORT_INTERVAL=1000

# OTLP/gRPC
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_PROTOCOL=grpc
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Prometheus
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=prometheus

# Multiple exporters
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=console,otlp
export OTEL_EXPORTER_OTLP_PROTOCOL=http/json

# Different endpoints/backends for metrics and logs
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=otlp
export OTEL_LOGS_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_METRICS_PROTOCOL=http/protobuf
export OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=http://metrics.company.com:4318
export OTEL_EXPORTER_OTLP_LOGS_PROTOCOL=grpc
export OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=http://logs.company.com:4317

# Metrics only (no events/logs)
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_PROTOCOL=grpc
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Events/logs only (no metrics)
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_LOGS_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_PROTOCOL=grpc
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
&lt;/code&gt;
    &lt;p&gt;Your Claude Code activity should now automatically emit logs and metrics.&lt;/p&gt;
    &lt;p&gt;Finally, you should be able to view logs in Signoz Cloud under the logs tab:&lt;/p&gt;
    &lt;p&gt;When you click on any of these logs in SigNoz, you'll see a detailed view of the log, including attributes:&lt;/p&gt;
    &lt;p&gt;You should be able to see Claude Code related metrics in Signoz Cloud under the metrics tab:&lt;/p&gt;
    &lt;p&gt;When you click on any of these metrics in SigNoz, you'll see a detailed view of the metric, including attributes:&lt;/p&gt;
    &lt;head rend="h2"&gt;Making Sense of Your Telemetry Data&lt;/head&gt;
    &lt;p&gt;Metrics&lt;/p&gt;
    &lt;p&gt;Once you’ve wired Claude Code into OpenTelemetry and SigNoz, you’ll start to see a rich stream of metrics flowing in. But raw numbers don’t mean much until you know what they represent. Let’s break down the key metrics Claude Code exports and why they matter for teams looking to understand usage and impact.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;claude_code.session.count&lt;/code&gt;→ How many CLI sessions are being started? This tells you how frequently developers are reaching for Claude in their day-to-day workflow.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.lines_of_code.count&lt;/code&gt;→ Tracks the number of lines of code modified. A simple way to measure how much “hands-on” coding Claude is influencing.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.pull_request.count&lt;/code&gt;→ Keeps count of pull requests created. Helpful for seeing if Claude is actually contributing to shipped code rather than just local tinkering.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.commit.count&lt;/code&gt;→ Monitors the number of Git commits tied to Claude-assisted sessions. Great for measuring real integration into development cycles.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.cost.usage&lt;/code&gt;→ Shows the cost of each session in USD. This is key for keeping budgets in check and spotting whether usage is spiking unexpectedly.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.token.usage&lt;/code&gt;→ Tracks the number of tokens consumed. Useful for understanding scale, model efficiency, and forecasting spend.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.code_edit_tool.decision&lt;/code&gt;→ Captures developer decisions when Claude suggests edits (accept vs. reject). Over time, this paints a picture of trust and adoption.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;claude_code.active_time.total&lt;/code&gt;→ The total active time (in seconds) a session runs. Think of this as a measure of “engagement depth”—longer active times often signal serious coding assistance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With these metrics visualized in SigNoz, you move from raw telemetry to stories about usage: how often developers lean on Claude, how much code it influences, and whether it’s paying off in commits, pull requests, and team efficiency.&lt;/p&gt;
    &lt;p&gt;Logs&lt;/p&gt;
    &lt;p&gt;Metrics give you the what and how much, but logs tell the story behind the numbers. Claude Code exports a variety of rich logs through OpenTelemetry that let you dig into the details of how developers interact with the assistant in real time. Here’s a breakdown of the key event types and what they mean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;User Prompt Event (&lt;/p&gt;&lt;code&gt;claude_code.user_prompt&lt;/code&gt;)&lt;p&gt;Logged whenever a developer submits a prompt. Attributes include timestamp, prompt length, and (optionally) the prompt itself if you’ve enabled&lt;/p&gt;&lt;code&gt;OTEL_LOG_USER_PROMPTS=1&lt;/code&gt;. This is your front-row seat into what kinds of requests developers are making and how frequently.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Tool Result Event (&lt;/p&gt;&lt;code&gt;claude_code.tool_result&lt;/code&gt;)&lt;p&gt;Captures the outcome of a tool execution. You’ll see the tool name, whether it succeeded or failed, execution time, errors (if any), and the developer’s decision (accept or reject). With this, you can measure not just tool usage but also trust and reliability.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;API Request Event (&lt;/p&gt;&lt;code&gt;claude_code.api_request&lt;/code&gt;)&lt;p&gt;Fired on every API call to Claude. Attributes include model name, cost, duration, token counts (input/output/cache), and more. This is where you connect usage directly to cost efficiency and performance.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;API Error Event (&lt;/p&gt;&lt;code&gt;claude_code.api_error&lt;/code&gt;)&lt;p&gt;Logged when an API request fails. You’ll see error messages, HTTP status codes, duration, and retry attempts. These events are critical for debugging reliability issues and spotting patterns like repeated failures on specific models or endpoints.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Tool Decision Event (&lt;/p&gt;&lt;code&gt;claude_code.tool_decision&lt;/code&gt;)&lt;p&gt;Records when a tool permission decision is made—whether developers accept or reject a suggested action, and the source of that decision (config, user override, abort, etc.). Over time, this shows how much developers trust Claude’s automated suggestions versus stepping in manually.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By streaming these events into SigNoz, you don’t just know that “Claude Code was used X times.” You can see the full lifecycle of interactions from a prompt being entered, to tools executing, to API calls completing (or failing), all the way to whether a developer accepted the outcome. It’s observability not just at the system level, but at the human + AI collaboration level.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Data to Dashboards: Bringing Claude Code Logs &amp;amp; Metrics to Life&lt;/head&gt;
    &lt;p&gt;Once you've got Claude Code's telemetry flowing into SigNoz, you can build dashboards to monitor critical metrics like total token usage, request patterns, and performance bottlenecks. You can check out our Claude Code dashboard template here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Total Token Usage (Input &amp;amp; Output)&lt;/head&gt;
    &lt;p&gt;Tokens are the currency of AI coding assistants. By splitting input tokens (developer prompts) and output tokens (Claude’s responses), this panel shows exactly how much work Claude is doing. Over time, you can see whether usage is ramping up, stable, or dropping off—and keep an eye on efficiency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sessions and Conversations&lt;/head&gt;
    &lt;p&gt;This panel tracks how many CLI sessions and conversations are happening. Sessions show how often developers are turning to Claude, while conversations capture depth of interaction. Together, they reveal adoption and engagement.&lt;/p&gt;
    &lt;head rend="h3"&gt;Total Cost (USD)&lt;/head&gt;
    &lt;p&gt;Claude Code usage comes with a cost. This panel translates token consumption into actual dollars spent. It’s a quick way to validate ROI, spot runaway usage early, and ensure your AI assistant remains a cost-effective part of the toolchain.&lt;/p&gt;
    &lt;head rend="h3"&gt;Command Duration (P95)&lt;/head&gt;
    &lt;p&gt;How long do Claude-assisted commands actually take? This chart tracks the 95th percentile duration, helping you catch slowdowns, spikes, or performance regressions. Developers want Claude to be fast—this view keeps latency in check.&lt;/p&gt;
    &lt;head rend="h3"&gt;Token Usage Over Time&lt;/head&gt;
    &lt;p&gt;Instead of looking at total tokens in a snapshot, this time series shows usage trends. Are developers spiking usage during sprints? Is there a steady upward adoption curve? This view is perfect for spotting both growth and anomalies.&lt;/p&gt;
    &lt;head rend="h3"&gt;Success Rate of Requests&lt;/head&gt;
    &lt;p&gt;Not every request to Claude is successful. This panel highlights how often requests succeed vs. fail, helping you spot reliability issues—whether from the model, connectivity, or developer inputs. A healthy success rate means smooth workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Terminal Type&lt;/head&gt;
    &lt;p&gt;Claude Code is flexible, but developers use it differently depending on environment. This pie chart shows where developers are working—VS Code, Apple Terminal, or elsewhere. Great for understanding adoption across dev setups.&lt;/p&gt;
    &lt;head rend="h3"&gt;Requests per User&lt;/head&gt;
    &lt;p&gt;Usage isn’t always evenly distributed. This table breaks down requests by user, making it clear who’s leaning on Claude heavily and who’s barely touching it. Perfect for identifying champions, training needs, or power users.&lt;/p&gt;
    &lt;head rend="h3"&gt;Model Distribution&lt;/head&gt;
    &lt;p&gt;Claude ships with multiple models, and not all usage is equal. This panel shows which models developers are actually calling. It’s a handy way to track preferences and see if newer models are gaining traction.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tool Types&lt;/head&gt;
    &lt;p&gt;Claude can call on different tools—like &lt;code&gt;Read&lt;/code&gt;, &lt;code&gt;Edit&lt;/code&gt;, &lt;code&gt;LS&lt;/code&gt;, &lt;code&gt;TodoWrite&lt;/code&gt;, &lt;code&gt;Bash&lt;/code&gt;, and more. This breakdown shows which tools are most frequently used, shining a light on the kinds of coding tasks developers are trusting Claude with.&lt;/p&gt;
    &lt;head rend="h3"&gt;User Decisions&lt;/head&gt;
    &lt;p&gt;AI suggestions only matter if developers use them. This panel tracks accept vs. reject decisions, showing how much developers trust Claude’s output. High acceptance is a sign of quality; high rejection is a signal to dig deeper.&lt;/p&gt;
    &lt;head rend="h3"&gt;Quota Usage (5-Hour Rolling Window)&lt;/head&gt;
    &lt;p&gt;Claude Code subscriptions often come with rolling quotas that reset every 5 hours. This panel tracks how much of that rolling limit has been used based on your specific subscription plan, giving you an early warning system before developers hit hard caps. Instead of being caught off guard by usage rejections, teams can proactively manage consumption and adjust workflows as they approach the threshold.&lt;/p&gt;
    &lt;p&gt;Taken together, these panels create more than just a pretty dashboard. They form a control center for Claude Code observability. You can see usage patterns unfold in real time, tie costs back to activity, and build trust in Claude’s role as part of the development workflow. Whether you’re keeping budgets in check, tracking adoption, or optimizing performance, dashboards give you the clarity to manage AI-assisted coding at scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping It Up&lt;/head&gt;
    &lt;p&gt;As AI coding assistants like Claude Code become part of daily developer workflows, observability isn’t optional—it’s essential. By combining Claude Code’s built-in monitoring hooks with OpenTelemetry and SigNoz, you can transform raw telemetry into a living, breathing picture of usage, performance, and cost.&lt;/p&gt;
    &lt;p&gt;From tracking tokens and costs, to understanding which tools and models developers actually rely on, to surfacing adoption trends and decision patterns, observability gives you the power to manage Claude Code with the same rigor you bring to any other critical piece of infrastructure. Dashboards then tie it all together, turning streams of data into a real-time pulse of how Claude Code powers development.&lt;/p&gt;
    &lt;p&gt;The result? Teams gain the confidence to scale Claude Code usage responsibly, optimize for performance and spend, and most importantly, make evidence-backed decisions about how AI fits into their engineering culture. With visibility comes clarity and with clarity, Claude Code becomes not just an assistant, but a measurable driver of developer productivity.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://signoz.io/blog/claude-code-monitoring-with-opentelemetry/"/><published>2025-09-21T18:37:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45326388</id><title>Apple Silicon GPU Support in Mojo</title><updated>2025-09-22T02:24:57.499561+00:00</updated><content>&lt;doc fingerprint="bd9e781543241bcc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;The latest nightly releases of Mojo (and our next stable release) include initial support for a new accelerator architecture: Apple Silicon GPUs!&lt;/p&gt;
      &lt;p&gt;We know that one of the biggest barriers to programming GPUs is access to hardware. It’s our hope that by making it possible to use Mojo to develop for a GPU present in every modern Mac, we can further democratize developing GPU-accelerated algorithms and AI models. This should also enable new paths of local-to-cloud development for AI models and more.&lt;/p&gt;
      &lt;p&gt;To get started, you need to have an Apple Silicon Mac (we support all M1 - M4 series chips) running macOS 15 or newer, with Xcode 16 or newer installed. The version of the Metal Shading Language we use (3.2, AIR bitcode version 2.7.0) needs the macOS 15 SDK, and you’ll get an error about incompatible bitcode versions if you run on an older macOS or use an older version of Xcode that doesn’t have the macOS 15 SDK.&lt;/p&gt;
      &lt;p&gt;You can clone our &lt;code&gt;modular&lt;/code&gt; repository and try out one of our GPU function examples in the &lt;code&gt;examples/mojo/gpu-functions&lt;/code&gt; directory. All but the &lt;code&gt;reduction.mojo&lt;/code&gt; example should work on Apple Silicon GPUs today in the latest nightlies. Additionally, puzzles 1-15 of the Mojo GPU puzzles should now work on Apple Silicon GPUs with the latest nightly. We haven’t yet updated the Pixi environment for the GPU puzzles to add Apple Silicon support, so for now you may need to run the Mojo code manually from another environment.&lt;/p&gt;
      &lt;head rend="h1"&gt;Current capabilities&lt;/head&gt;
      &lt;p&gt;This is just the beginning of our support for Apple Silicon GPUs, and many pieces of functionality still need to be built out. Known features that don’t work today include:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Intrinsics for many hardware capabilities &lt;list rend="ul"&gt;&lt;item&gt;Not all Mojo GPU examples work, such as &lt;code&gt;reduction.mojo&lt;/code&gt; and the more complex matrix multiplication examples&lt;/item&gt;&lt;item&gt;GPU puzzles 16 and above need more advanced hardware features&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Basic MAX graphs&lt;/item&gt;
        &lt;item&gt;MAX custom ops&lt;/item&gt;
        &lt;item&gt;PyTorch interoperability&lt;/item&gt;
        &lt;item&gt;Running AI models&lt;/item&gt;
        &lt;item&gt;Serving AI models&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;I’ll emphasize that even simple MAX graphs, and by extension AI models, don’t yet run on Apple Silicon GPUs. In our Python APIs, &lt;code&gt;accelerator_count()&lt;/code&gt; will still return 0 until we have basic MAX graph support enabled. Hopefully, that won’t be long.&lt;/p&gt;
      &lt;head rend="h1"&gt;Next steps&lt;/head&gt;
      &lt;p&gt;We’ve identified many of the technical blockers to progressively enable the above. The current list of what we plan to work on includes:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Handle &lt;code&gt;MAX_THREADS_PER_BLOCK_METADATA&lt;/code&gt; and similar aliases&lt;/item&gt;
        &lt;item&gt;Support &lt;code&gt;GridDim&lt;/code&gt;, &lt;code&gt;lane_id&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Enable &lt;code&gt;async_copy_*&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Convert arguments of an array type to a pointer type&lt;/item&gt;
        &lt;item&gt;Support &lt;code&gt;bfloat16&lt;/code&gt; on ARM devices&lt;/item&gt;
        &lt;item&gt;Support &lt;code&gt;SubBuffer&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Enable atomic operations&lt;/item&gt;
        &lt;item&gt;Complete implementation of &lt;code&gt;MetalDeviceContext::synchronize&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Enable captured arguments&lt;/item&gt;
        &lt;item&gt;Support &lt;code&gt;print&lt;/code&gt; and &lt;code&gt;debug_assert&lt;/code&gt;&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;I apologize for some of the cryptic error messages you may get when hitting a piece of missing functionality, or encountering a system configuration we aren’t yet compatible with. We hope to improve the messaging over time, and to provide better guides for debugging failures.&lt;/p&gt;
      &lt;head rend="h1"&gt;How this works&lt;/head&gt;
      &lt;p&gt;To learn more about how Mojo code is compiled to target Apple Silicon GPUs, check out Amir Nassereldine’s detailed technical presentation from our recent Modular Community Meeting. He did amazing work in establishing the fundamentals during his summer internship, and we are now building on that to advance Mojo on this new architecture.&lt;/p&gt;
      &lt;p&gt;In brief, a multi-step process is used to compile and run Mojo code on an Apple Silicon GPU. First, we compile Mojo GPU functions to Apple Intermediate Representation (AIR) bitcode. This is done through lowering to LLVM IR, and then specifically converting to Metal-compatible AIR.&lt;/p&gt;
      &lt;p&gt;Mojo handles interactions with an accelerator through the &lt;code&gt;DeviceContext&lt;/code&gt; type. In the case of Apple Silicon GPUs, we’ve specialized this into a&lt;code&gt;MetalDeviceContext&lt;/code&gt; that handles the next stages in compilation and execution.&lt;/p&gt;
      &lt;p&gt;The &lt;code&gt;MetalDeviceContext&lt;/code&gt; uses the Metal-cpp API to compile the AIR representation into a &lt;code&gt;.metallib&lt;/code&gt; for execution on device. Once the &lt;code&gt;.metallib&lt;/code&gt; is ready, the &lt;code&gt;MetalDeviceContext&lt;/code&gt; manages a Metal &lt;code&gt;CommandQueue&lt;/code&gt;, and buffers operations for moving data, running a GPU function, and more. All of this happens behind-the-scenes and a Mojo developer doesn’t need to worry about any of it.&lt;/p&gt;
      &lt;p&gt;Code that you’ve written to run on an NVIDIA or AMD GPUs should mostly just work on an Apple Silicon GPU, assuming no device-specific features were being used. Obviously, different patterns will be required to get the most performance out of each GPU, and we’re excited to explore this new optimization space on Apple Silicon GPUs with you.&lt;/p&gt;
      &lt;head rend="h1"&gt;Just the beginning&lt;/head&gt;
      &lt;p&gt;While we’d love help in bringing up Apple Silicon GPU support, some of the infrastructure for introducing support for new AIR intrinsics and compiling them to a &lt;code&gt;.metallib&lt;/code&gt; currently requires Modular developers for implementation. We’ll get more of the basics in place before work moves primarily to the open-source standard library and kernels, at which point community members will be able to do a lot more to advance compatibility. Contributions are always welcome, but we don’t want you to hit missing non-public components and get frustrated by being unable to move forward.&lt;/p&gt;
      &lt;p&gt;We’ll share much more documentation and content on how to work with and optimize for this new hardware family, but we’re extremely excited about even these first few steps onto Apple Silicon GPUs. I’ll to try to keep this post up to date as we expand functionality.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://forum.modular.com/t/apple-silicon-gpu-support-in-mojo/2295"/><published>2025-09-21T20:35:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45326690</id><title>Procedural Island Generation (VI)</title><updated>2025-09-22T02:24:57.310398+00:00</updated><content>&lt;doc fingerprint="9968ebcc5b77ecfe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Procedural Island Generation (VI)&lt;/head&gt;
    &lt;p&gt;This is the final installment of our procedural island generation series. After building the mesh foundation (Part I), painting elevation hints (Part II), adding mountain detail (Part III), simulating hydrology (Part IV), and colouring the terrain with our biome ramp (Part V), it is time to package the result. CartoKit finishes by baking the terrain into a compact mesh, visualising it through an egui viewer, and exporting artefacts for other tools.&lt;/p&gt;
    &lt;p&gt;The journey from mathematical representation to visual output ends with three components:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;Terrain::from_terrain&lt;/code&gt;– a baked mesh carrying elevation, moisture, biome, and river metadata.&lt;/item&gt;
      &lt;item&gt;The debug renderer &amp;amp; viewer – CPU rasterisers that turn the data into diagnostic images.&lt;/item&gt;
      &lt;item&gt;Export helpers – GLB export, PNG captures, and GIF generation built on the same primitives.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s look at each piece.&lt;/p&gt;
    &lt;head rend="h2"&gt;Baked Terrain Output&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;Terrain::from_terrain&lt;/code&gt; (&lt;code&gt;src/terrain.rs:368&lt;/code&gt;) distils the incremental &lt;code&gt;TerrainBuilder&lt;/code&gt; state into a reusable asset. The bake step:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Keeps only faces whose centroids lie inside the unit square, trimming the guard ring used during generation.&lt;/item&gt;
      &lt;item&gt;Copies vertex elevation and moisture into mesh attributes so downstream tools can query them directly.&lt;/item&gt;
      &lt;item&gt;Tags every face with average elevation, a &lt;code&gt;TerrainType&lt;/code&gt;(land vs. ocean), and the coarse&lt;code&gt;BiomeType&lt;/code&gt;classification introduced in Part V.&lt;/item&gt;
      &lt;item&gt;Marks edges as regular, coastline, or river and stores river-flow magnitudes when a &lt;code&gt;RiverSystem&lt;/code&gt;is present.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The baked mesh is still a &lt;code&gt;TopoMesh&lt;/code&gt;, meaning we retain the halfedge connectivity that made the earlier stages convenient. When you call &lt;code&gt;Terrain::from_terrain(&amp;amp;builder)&lt;/code&gt;, you get a self-contained structure that is ready for export or further processing without touching the heavy generation code again.&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU Debug Renderer&lt;/head&gt;
    &lt;p&gt;All of CartoKit’s imagery is rendered on the CPU. The &lt;code&gt;cartokit::debug&lt;/code&gt; module contains a suite of rasterisers—triangle fill, watertight line drawing, paint-map sampling, rainfall heatmaps—that output directly into &lt;code&gt;image::RgbaImage&lt;/code&gt; buffers. The viewer’s &lt;code&gt;DisplayRenderer&lt;/code&gt; (&lt;code&gt;examples/viewer/display_modes.rs&lt;/code&gt;) wires those helpers together:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mesh modes (&lt;code&gt;SeedPoints&lt;/code&gt;,&lt;code&gt;Delaunay&lt;/code&gt;,&lt;code&gt;Voronoi&lt;/code&gt;,&lt;code&gt;Quads&lt;/code&gt;,&lt;code&gt;FinalTriangulation&lt;/code&gt;) call&lt;code&gt;draw_topokit_mesh&lt;/code&gt;with optional vertex overlays.&lt;/item&gt;
      &lt;item&gt;Scalar fields (&lt;code&gt;TriangleElevation&lt;/code&gt;,&lt;code&gt;DistanceField&lt;/code&gt;,&lt;code&gt;Rainfall&lt;/code&gt;,&lt;code&gt;Humidity&lt;/code&gt;,&lt;code&gt;RiverFlow&lt;/code&gt;,&lt;code&gt;Biome&lt;/code&gt;) delegate to&lt;code&gt;draw_triangles_opt&lt;/code&gt;/&lt;code&gt;draw_regions_opt&lt;/code&gt;with palette swaps.&lt;/item&gt;
      &lt;item&gt;Noise visualisations reuse the same pipeline, just swapping in different &lt;code&gt;TriangleProperty&lt;/code&gt;variants.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Because everything renders to software images, the viewer behaves the same on every platform, and the exported screenshots and GIFs are bit-for-bit identical to what you see on screen.&lt;/p&gt;
    &lt;head rend="h2"&gt;Interactive Viewer&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;cartokit_viewer&lt;/code&gt; example wraps those images in an egui/eframe interface:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The right-hand parameter panel exposes seeds, Bridson separation, rainfall, and river controls, regenerating the terrain whenever you tweak them.&lt;/item&gt;
      &lt;item&gt;The “Paint Terrain” mode lets you brush elevation hints onto the 128×128 paint map; the next regeneration integrates those hints into the terrain.&lt;/item&gt;
      &lt;item&gt;Display modes cover the full pipeline: seed classification, mesh structure, mountain distance fields, rainfall, humidity, river diagnostics, biome colours, and the final shaded map.&lt;/item&gt;
      &lt;item&gt;Animation tools (&lt;code&gt;examples/viewer/animation.rs&lt;/code&gt;) let you scrub parameters over time and queue frame exports.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each frame, the viewer renders the active mode into an &lt;code&gt;RgbaImage&lt;/code&gt;, uploads it as an egui texture, and then recycles the same image for exports. There is no separate rendering path—what you export is exactly what you preview.&lt;/p&gt;
    &lt;head rend="h2"&gt;Export Helpers&lt;/head&gt;
    &lt;p&gt;Three helpers in &lt;code&gt;examples/viewer/export.rs&lt;/code&gt; turn the baked data into files:&lt;/p&gt;
    &lt;code&gt;// 1. Bake + GLB export via MeshKit
display::export_mesh(&amp;amp;terrain_builder, seed);

// 2. One PNG per display mode
display::export_all_images(seed, &amp;amp;modes, |mode| renderer.render(mode));

// 3. Thumbnail tiles for quick comparisons
display::export_all_images_tile(seed, &amp;amp;modes, |mode| renderer.render(mode));
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;export_mesh&lt;/code&gt;clones the baked&lt;code&gt;Terrain&lt;/code&gt;, rescales coordinates for GLTF’s Y‑up convention, and calls&lt;code&gt;meshkit::io::save_mesh&lt;/code&gt;to produce a&lt;code&gt;.glb&lt;/code&gt;file that loads cleanly in Blender or other viewers.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;export_all_images&lt;/code&gt;walks every display mode and drops the rendered PNGs into&lt;code&gt;exports/images_seed_&amp;lt;seed&amp;gt;/&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;export_all_images_tile&lt;/code&gt;cuts out the top-left 1/8×1/8 tile from each image—handy for diffing or documentation thumbnails.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For animated parameter studies, &lt;code&gt;examples/viewer/gif_export.rs&lt;/code&gt; converts a list of pre-rendered frames into a looping GIF, with options for downsampling, FPS, and output directory naming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance Snapshot&lt;/head&gt;
    &lt;p&gt;Generation times were covered in the earlier posts (≈80 ms for the default 27 K-site map on a modern desktop). The finishing steps add little overhead:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Stage&lt;/cell&gt;
        &lt;cell role="head"&gt;Time (2048×2048 render)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;Terrain::from_terrain&lt;/code&gt; bake&lt;/cell&gt;
        &lt;cell&gt;~6 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CPU render – biome view&lt;/cell&gt;
        &lt;cell&gt;~8 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GLB export (&lt;code&gt;meshkit::io::save_mesh&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;~15 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;PNG capture per display mode&lt;/cell&gt;
        &lt;cell&gt;5–10 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GIF encoding (20 frames @ 1024²)&lt;/cell&gt;
        &lt;cell&gt;~9 ms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Numbers vary with map resolution and active mode (mesh overlays with AA lines take longer than simple heatmaps), but everything remains comfortably interactive.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future Directions&lt;/head&gt;
    &lt;p&gt;With a solid foundation in place, the obvious extensions are clear:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPU shading – real-time lighting, water reflections, and atmospheric effects on top of the baked mesh.&lt;/item&gt;
      &lt;item&gt;Mesh decimation – level-of-detail generation or streaming tiles for massive worlds.&lt;/item&gt;
      &lt;item&gt;Additional exporters – heightmaps, splatmaps, or direct integrations for Unity/Unreal/Godot.&lt;/item&gt;
      &lt;item&gt;Dynamic overlays – weather, vegetation instancing, or settlement placement driven by the existing attributes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These items all build on the baked &lt;code&gt;Terrain&lt;/code&gt; structure and export scaffolding we now have.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Through six posts we moved from random seeds to a fully packaged island:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Poisson disk sampling and dual meshes establish the geometric scaffold.&lt;/item&gt;
      &lt;item&gt;A paint map and layered noise sculpt elevation.&lt;/item&gt;
      &lt;item&gt;Hydrology adds rivers and erosion cues.&lt;/item&gt;
      &lt;item&gt;A simple elevation/moisture colormap paints believable biomes.&lt;/item&gt;
      &lt;item&gt;The baked &lt;code&gt;Terrain&lt;/code&gt;, debug renderer, and export helpers ship the result.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The complete system generates a richly annotated island in under a tenth of a second and provides everything you need to inspect, tweak, and export it. The modular architecture welcomes experimentation—swap out any component and the rest of the pipeline keeps working.&lt;/p&gt;
    &lt;p&gt;Thanks for following along. I hope CartoKit inspires your own explorations into procedural worlds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Valuable Resources&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MeshKit – Halfedge library used throughout the project&lt;/item&gt;
      &lt;item&gt;EGUI – Immediate-mode GUI powering the viewer&lt;/item&gt;
      &lt;item&gt;glTF 2.0 – Asset format we export to&lt;/item&gt;
      &lt;item&gt;Red Blob Games: Polygonal Map Generation – Foundational reading for the dual-mesh approach&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://brashandplucky.com/2025/09/28/procedural-island-generation-vi.html"/><published>2025-09-21T21:11:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45326740</id><title>Lightweight, highly accurate line and paragraph detection</title><updated>2025-09-22T02:24:57.037201+00:00</updated><content>&lt;doc fingerprint="2c9c2528d5d592af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 17 Mar 2022]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Unified Line and Paragraph Detection by Graph Convolutional Networks&lt;/head&gt;View PDF&lt;quote&gt;Abstract:We formulate the task of detecting lines and paragraphs in a document into a unified two-level clustering problem. Given a set of text detection boxes that roughly correspond to words, a text line is a cluster of boxes and a paragraph is a cluster of lines. These clusters form a two-level tree that represents a major part of the layout of a document. We use a graph convolutional network to predict the relations between text detection boxes and then build both levels of clusters from these predictions. Experimentally, we demonstrate that the unified approach can be highly efficient while still achieving state-of-the-art quality for detecting paragraphs in public benchmarks and real-world images.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2203.09638"/><published>2025-09-21T21:18:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45326754</id><title>Show HN: Tips to stay safe from NPM supply chain attacks</title><updated>2025-09-22T02:24:56.328072+00:00</updated><content>&lt;doc fingerprint="1c111a5d8ce32b00"&gt;
  &lt;main&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;The NPM ecosystem is no stranger to compromises12, supply-chain attacks3, malware45, spam6, phishing7, incidents8 or even trolls9. In this repository, I have consolidated a list of information you might find useful in securing yourself against these incidents.&lt;/p&gt;
    &lt;p&gt;Feel free to submit a Pull Request, or reach out to me on Twitter!&lt;/p&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;This repository covers &lt;code&gt;npm&lt;/code&gt;, &lt;code&gt;bun&lt;/code&gt;, &lt;code&gt;deno&lt;/code&gt;, &lt;code&gt;pnpm&lt;/code&gt;, &lt;code&gt;yarn&lt;/code&gt; and more.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;On&lt;/p&gt;&lt;code&gt;npm&lt;/code&gt;, by default, a new dependency will be installed with the Caret&lt;code&gt;^&lt;/code&gt;operator. This operator installs the most recent&lt;code&gt;minor&lt;/code&gt;or&lt;code&gt;patch&lt;/code&gt;releases. E.g.,&lt;code&gt;^1.2.3&lt;/code&gt;will install&lt;code&gt;1.2.3&lt;/code&gt;,&lt;code&gt;1.2.4&lt;/code&gt;,&lt;code&gt;1.3.0&lt;/code&gt;,&lt;code&gt;1.6.2&lt;/code&gt;, etc. See https://docs.npmjs.com/about-semantic-versioning and try out the npm SemVer Calculator (https://semver.npmjs.com). To avoid installing freshly compromised packages, it is often advised to pin exact versions (e.g.,&lt;code&gt;"my-package": "1.2.3"&lt;/code&gt;).&lt;/quote&gt;
    &lt;p&gt;Here's how to use the save exact flag to pin exact version in various package managers:&lt;/p&gt;
    &lt;code&gt;npm install --save-exact react

pnpm add --save-exact react

yarn add --save-exact react

bun add --exact react

deno add npm:react@19.1.1&lt;/code&gt;
    &lt;p&gt;We can also update this setting in configuration files (e.g., &lt;code&gt;.npmrc&lt;/code&gt;), with either &lt;code&gt;save-exact&lt;/code&gt; or &lt;code&gt;save-prefix&lt;/code&gt; alike key and value pairs:&lt;/p&gt;
    &lt;code&gt;npm config set save-exact=true

pnpm config set save-exact true

yarn config set defaultSemverRangePrefix ""&lt;/code&gt;
    &lt;p&gt;For &lt;code&gt;bun&lt;/code&gt;, the config file is &lt;code&gt;bunfig.toml&lt;/code&gt; and corresponding config is:&lt;/p&gt;
    &lt;code&gt;[install]
exact = true&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;However, our direct dependencies also have their own dependencies (transitive dependencies). Even if we pin our direct dependencies, their transitive dependencies might still use broad version range operators (like&lt;/p&gt;&lt;code&gt;^&lt;/code&gt;or&lt;code&gt;~&lt;/code&gt;). The solution is to override the transitive dependencies: https://docs.npmjs.com/cli/v11/configuring-npm/package-json#overrides&lt;/quote&gt;
    &lt;p&gt;In &lt;code&gt;package.json&lt;/code&gt;, if we have the following &lt;code&gt;overrides&lt;/code&gt; field:&lt;/p&gt;
    &lt;code&gt;{
  "dependencies": {
    "library-a": "^3.0.0"
  },
  "overrides": {
    "lodash": "4.17.21"
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Let's assume that &lt;code&gt;library-a&lt;/code&gt;'s&lt;code&gt;package.json&lt;/code&gt;has a dependency on&lt;code&gt;"lodash": "^4.17.0"&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Without the &lt;code&gt;overrides&lt;/code&gt;section,&lt;code&gt;npm&lt;/code&gt;might install&lt;code&gt;lodash@4.17.22&lt;/code&gt;(or any of the latest&lt;code&gt;4.x.x&lt;/code&gt;versions) as a transitive dependency of&lt;code&gt;library-a&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;However, by adding &lt;code&gt;"overrides": { "lodash": "4.17.21" }&lt;/code&gt;, we are telling&lt;code&gt;npm&lt;/code&gt;that anywhere&lt;code&gt;lodash&lt;/code&gt;appears in the dependency tree, it must be resolved to exactly version&lt;code&gt;4.17.21&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For &lt;code&gt;pnpm&lt;/code&gt;, we can also define the &lt;code&gt;overrides&lt;/code&gt; field in the &lt;code&gt;pnpm-workspace.yaml&lt;/code&gt; file: https://pnpm.io/settings#overrides&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;yarn&lt;/code&gt;, the &lt;code&gt;resolutions&lt;/code&gt; field is introduced before the &lt;code&gt;overrides&lt;/code&gt; field, and it also offers a similar functionality: https://yarnpkg.com/configuration/manifest#resolutions&lt;/p&gt;
    &lt;code&gt;{
  "resolutions": {
    "lodash": "4.17.21"
  }
}&lt;/code&gt;
    &lt;code&gt;# yarn also provide a cli to set the resolution: https://yarnpkg.com/cli/set/resolution
yarn set resolution &amp;lt;descriptor&amp;gt; &amp;lt;resolution&amp;gt;&lt;/code&gt;
    &lt;p&gt;For &lt;code&gt;bun&lt;/code&gt;, it supports either the &lt;code&gt;overrides&lt;/code&gt; field or the &lt;code&gt;resolutions&lt;/code&gt; field: https://bun.com/docs/install/overrides&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;deno&lt;/code&gt;, see denoland/deno#28664 for more details.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Ensure to commit package managers lockfiles to&lt;/p&gt;&lt;code&gt;git&lt;/code&gt;and share between different environments. Different lockfiles are:&lt;code&gt;package-lock.json&lt;/code&gt;for&lt;code&gt;npm&lt;/code&gt;,&lt;code&gt;pnpm-lock.yaml&lt;/code&gt;for&lt;code&gt;pnpm&lt;/code&gt;,&lt;code&gt;bun.lock&lt;/code&gt;for&lt;code&gt;bun&lt;/code&gt;,&lt;code&gt;yarn.lock&lt;/code&gt;for&lt;code&gt;yarn&lt;/code&gt;and&lt;code&gt;deno.lock&lt;/code&gt;for&lt;code&gt;deno&lt;/code&gt;.&lt;p&gt;In automated environments such as continuous integration and deployments, we should install the exact dependencies as defined in the lockfile.&lt;/p&gt;&lt;/quote&gt;
    &lt;code&gt;npm ci

bun install --frozen-lockfile

yarn install --frozen-lockfile

deno install --frozen&lt;/code&gt;
    &lt;p&gt;For &lt;code&gt;deno&lt;/code&gt;, we can also set the following in a &lt;code&gt;deno.json&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;{
  "lock": {
    "frozen": true
  }
}&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Lifecycle scripts are special scripts that happen in addition to the&lt;/p&gt;&lt;code&gt;pre&amp;lt;event&amp;gt;&lt;/code&gt;,&lt;code&gt;post&amp;lt;event&amp;gt;&lt;/code&gt;, and&lt;code&gt;&amp;lt;event&amp;gt;&lt;/code&gt;scripts. For instance,&lt;code&gt;preinstall&lt;/code&gt;is run before&lt;code&gt;install&lt;/code&gt;is run and&lt;code&gt;postinstall&lt;/code&gt;is run after&lt;code&gt;install&lt;/code&gt;is run. See how npm handles the "scripts" field: https://docs.npmjs.com/cli/v11/using-npm/scripts#life-cycle-scripts&lt;p&gt;Lifecycle scripts are a common strategy from malicious actors. For example, the "Shai-Hulud" worms3 edit the&lt;/p&gt;&lt;code&gt;package.json&lt;/code&gt;file to add a&lt;code&gt;postinstall&lt;/code&gt;script that would then steal credentials.&lt;/quote&gt;
    &lt;code&gt;npm config set ignore-scripts true --global

yarn config set enableScripts false&lt;/code&gt;
    &lt;p&gt;For &lt;code&gt;bun&lt;/code&gt;, &lt;code&gt;deno&lt;/code&gt; and &lt;code&gt;pnpm&lt;/code&gt;, they are disabled by default.&lt;/p&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;We can combine many of the flags above. For example, the following &lt;code&gt;npm&lt;/code&gt; command would install only production dependencies as defined in the lockfile and ignore lifecycle scripts:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;npm ci --omit=dev --ignore-scripts&lt;/code&gt;
    &lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;We can set a delay to avoid installing newly published packages. This applies to all dependencies, including transitive ones. For example,&lt;/p&gt;&lt;code&gt;pnpm v10.16&lt;/code&gt;introduced the&lt;code&gt;minimumReleaseAge&lt;/code&gt;option: https://pnpm.io/settings#minimumreleaseage, which defines the minimum number of minutes that must pass after a version is published before pnpm will install it. If&lt;code&gt;minimumReleaseAge&lt;/code&gt;is set to&lt;code&gt;1440&lt;/code&gt;, then pnpm will not install a version that was published less than 24 hours ago.&lt;/quote&gt;
    &lt;code&gt;pnpm config set minimumReleaseAge &amp;lt;minutes&amp;gt;

# only install packages published at least 1 day ago
npm install --before="$(date -v -1d)"

yarn config set npmMinimalAgeGate &amp;lt;minutes&amp;gt;&lt;/code&gt;
    &lt;p&gt;For &lt;code&gt;pnpm&lt;/code&gt;, there's also a &lt;code&gt;minimumReleaseAgeExclude&lt;/code&gt; option to exclude certain packages from the minimum release age.&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;npm&lt;/code&gt;, there is a proposal to add &lt;code&gt;minimumReleaseAge&lt;/code&gt; option and &lt;code&gt;minimumReleaseAgeExclude&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;yarn&lt;/code&gt;, config options &lt;code&gt;npmMinimalAgeGate&lt;/code&gt; and &lt;code&gt;npmPreapprovedPackages&lt;/code&gt; are implemented since &lt;code&gt;v4.10.0&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;bun&lt;/code&gt;, it is discussed here: oven-sh/bun#22679&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;deno&lt;/code&gt;, an draft proposal is here: denoland/deno#30752&lt;/p&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;Renovate CLI (https://github.com/renovatebot/renovate) also includes a &lt;code&gt;minimumReleaseAge&lt;/code&gt; config option.&lt;/p&gt;
    &lt;p&gt;Step Security (https://www.stepsecurity.io) introduced a NPM Package Cooldown Check feature to fail any PR that adds a recently published package.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;In the latest LTS version of&lt;/p&gt;&lt;code&gt;nodejs&lt;/code&gt;, we can use the Permission model to control what system resources a process has access to or what actions the process can take with those resources. However, this does not provide security guarantees in the presence of malicious code. Malicious code can still bypass the permission model and execute arbitrary code without the restrictions imposed by the permission model.&lt;/quote&gt;
    &lt;p&gt;Read about the Node.js permission model: https://nodejs.org/docs/latest/api/permissions.html&lt;/p&gt;
    &lt;code&gt;# by default, granted full access
node index.js

# restrict access to all available permissions
node --permission index.js

# enable specific permissions
node --permission --allow-fs-read=* --allow-fs-write=* index.js

# use permission model with `npx`
npx --node-options="--permission" &amp;lt;package-name&amp;gt;&lt;/code&gt;
    &lt;p&gt;Deno enables permissions by default. See https://docs.deno.com/runtime/fundamentals/security/&lt;/p&gt;
    &lt;code&gt;# by default, restrict access
deno run script.ts

# enable specific permission
deno run --allow-read script.ts&lt;/code&gt;
    &lt;p&gt;For Bun, the permission model is currently discussed here and here.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Because&lt;/p&gt;&lt;code&gt;npm&lt;/code&gt;has a low barrier for publishing packages, the ecosystem quickly grew to be the biggest package registry with over 5 million packages to date10. But not all packages are created equal. There are small utility packages8 that are downloaded as dependencies when we could write them ourselves and raise the question of "have we forgotten how to code?11"&lt;/quote&gt;
    &lt;p&gt;Between &lt;code&gt;nodejs&lt;/code&gt;, &lt;code&gt;bun&lt;/code&gt; and &lt;code&gt;deno&lt;/code&gt;, developers can use many of their modern features instead of relying on third-party libraries. The native modules may not provide the same level of functionality, but they should be considered whenever possible. Here are few examples:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;NPM libraries&lt;/cell&gt;
        &lt;cell role="head"&gt;Built-in modules&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;axios&lt;/code&gt;, &lt;code&gt;node-fetch&lt;/code&gt;, &lt;code&gt;got&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;native&lt;code&gt;fetch&lt;/code&gt; API&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;jest&lt;/code&gt;, &lt;code&gt;mocha&lt;/code&gt;, &lt;code&gt;ava&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;node:test&lt;/code&gt;,&lt;code&gt;node:assert&lt;/code&gt;, &lt;code&gt;bun test&lt;/code&gt; and &lt;code&gt;deno test&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;nodemon&lt;/code&gt;, &lt;code&gt;chokidar&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;node --watch&lt;/code&gt;, &lt;code&gt;bun --watch&lt;/code&gt; and &lt;code&gt;deno --watch&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;dotenv&lt;/code&gt;, &lt;code&gt;dotenv-expand&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;node --env-file&lt;/code&gt;, &lt;code&gt;bun --env-file&lt;/code&gt; and &lt;code&gt;deno --env-file&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;typescript&lt;/code&gt;, &lt;code&gt;ts-node&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;node --experimental-strip-types&lt;/code&gt;12, native to &lt;code&gt;deno&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;esbuild&lt;/code&gt;, &lt;code&gt;rollup&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;bun build&lt;/code&gt; and &lt;code&gt;deno bundle&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;prettier&lt;/code&gt;, &lt;code&gt;eslint&lt;/code&gt;, etc&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;deno lint&lt;/code&gt; and &lt;code&gt;deno fmt&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here are some resources that you might find useful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://obsidian.md/blog/less-is-safer&lt;/item&gt;
      &lt;item&gt;https://kashw1n.com/blog/nodejs-2025&lt;/item&gt;
      &lt;item&gt;https://lyra.horse/blog/2025/08/you-dont-need-js&lt;/item&gt;
      &lt;item&gt;https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use&lt;/item&gt;
      &lt;item&gt;https://github.com/you-dont-need/You-Dont-Need-Momentjs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;https://docs.npmjs.com/about-two-factor-authentication&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Two factor authentication (2FA) adds an extra layer of authentication to your&lt;/p&gt;&lt;code&gt;npm&lt;/code&gt;account. 2FA is not required by default, but it is a good practice to enable it.&lt;/quote&gt;
    &lt;code&gt;# ensure that 2FA is enabled for auth and writes (this is the default)
npm profile enable-2fa auth-and-writes&lt;/code&gt;
    &lt;p&gt;https://docs.npmjs.com/about-access-tokens#about-granular-access-tokens&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;An access token is a common way to authenticate to&lt;/p&gt;&lt;code&gt;npm&lt;/code&gt;when using the API or the&lt;code&gt;npm&lt;/code&gt;CLI.&lt;/quote&gt;
    &lt;code&gt;npm token create # for a read and publish token
npm token create --read-only # for a read-only token
npm token create --cidr=[list] # for a CIDR-restricted read and publish token
npm token create --read-only --cidr=[list] # for a CIDR-restricted read-only token&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restrict token to specific packages, scopes, and organizations&lt;/item&gt;
      &lt;item&gt;Set a token expiration date&lt;/item&gt;
      &lt;item&gt;Limit token access based on IP address ranges (CIDR notation)&lt;/item&gt;
      &lt;item&gt;Select between read-only or read and write access&lt;/item&gt;
      &lt;item&gt;Don't use the same token for multiple purposes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;https://docs.npmjs.com/generating-provenance-statements&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The provenance attestation is established by publicly providing a link to a package's source code and build instructions from the build environment. This allows developers to verify where and how your package was built before they download it.&lt;/p&gt;&lt;p&gt;The publish attestations are generated by the registry when a package is published by an authorized user. When an npm package is published with provenance, it is signed by Sigstore public good servers and logged in a public transparency ledger, where users can view this information.&lt;/p&gt;&lt;p&gt;For example, here's what a provenance statement look like on the&lt;/p&gt;&lt;code&gt;vue&lt;/code&gt;package page: https://www.npmjs.com/package/vue#provenance&lt;/quote&gt;
    &lt;p&gt;To establish provenance, use a supported CI/CD provider (e.g., GitHub Actions) and publish with the correct flag:&lt;/p&gt;
    &lt;code&gt;npm publish --provenance&lt;/code&gt;
    &lt;p&gt;To publish without evoking the &lt;code&gt;npm publish&lt;/code&gt; command, we can do one of the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;NPM_CONFIG_PROVENANCE&lt;/code&gt;to&lt;code&gt;true&lt;/code&gt;in CI/CD environment&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;provenance=true&lt;/code&gt;to&lt;code&gt;.npmrc&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;publishConfig&lt;/code&gt;block to&lt;code&gt;package.json&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;"publishConfig": {
  "provenance": true
}&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Limiting the files in an npm package helps prevent malware by reducing the attack surface, and it avoids accidental leaking of sensitive data&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;files&lt;/code&gt; field in &lt;code&gt;package.json&lt;/code&gt; is used to specify the files that should be included in the published package. Certain files are always included, see: https://docs.npmjs.com/cli/v11/configuring-npm/package-json#files for more details.&lt;/p&gt;
    &lt;code&gt;{
  "name": "my-package",
  "version": "1.0.0",
  "main": "dist/index.js",
  "files": ["dist", "LICENSE", "README.md"]
}&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;.npmignore&lt;/code&gt; file can also be used to exclude files from the published package.&lt;/p&gt;
    &lt;p&gt;It will not override the &lt;code&gt;"files"&lt;/code&gt; field, but in subdirectories it will.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;.npmignore&lt;/code&gt; file works just like a &lt;code&gt;.gitignore&lt;/code&gt;. If there is a &lt;code&gt;.gitignore&lt;/code&gt; file, and &lt;code&gt;.npmignore&lt;/code&gt; is missing, &lt;code&gt;.gitignore&lt;/code&gt;'s contents will be used instead.&lt;/p&gt;
    &lt;p&gt;We can run &lt;code&gt;npx pack --dry-run&lt;/code&gt; to see the contents that will be included in the published version of the package.&lt;/p&gt;
    &lt;code&gt;&amp;gt; npx pack --dry-run
npm notice Tarball Contents
npm notice 1.1kB LICENSE
npm notice 1.9kB README.md
npm notice 108B index.js
npm notice 700B package.json
npm notice Tarball Details&lt;/code&gt;
    &lt;p&gt;Also, run &lt;code&gt;npm publish --dry-run&lt;/code&gt; to see what would be happen when we run the publish command.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Private package registries are a great way for organizations to manage their own dependencies, and can acts as a proxy to the public&lt;/p&gt;&lt;code&gt;npm&lt;/code&gt;registry. Organizations can enforce security policies and vet packages before they are used in a project.&lt;/quote&gt;
    &lt;p&gt;Here are some private registries that you might find useful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Packages https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-npm-registry&lt;/item&gt;
      &lt;item&gt;Verdaccio https://github.com/verdaccio/verdaccio&lt;/item&gt;
      &lt;item&gt;Vlt https://www.vlt.sh/&lt;/item&gt;
      &lt;item&gt;JFrog Artifactory https://jfrog.com/integrations/npm-registry&lt;/item&gt;
      &lt;item&gt;Sonatype: https://help.sonatype.com/en/npm-registry.html&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Many package managers provide audit functionality to scan your project's dependencies for known security vulnerabilities, show a report and recommend the best way to fix them.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;npm audit # audit dependencies
npm audit fix # automatically install any compatible updates
npm audit signatures # verify the signatures of the dependencies

pnpm audit
pnpm audit --fix

bun audit

yarn npm audit
yarn npm audit --recursive # audit transitive dependencies&lt;/code&gt;
    &lt;p&gt;GitHub offers several services that can help protect against &lt;code&gt;npm&lt;/code&gt; malwares, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dependabot: This tool automatically scans your project's dependencies, including &lt;code&gt;npm&lt;/code&gt;packages, for known vulnerabilities.&lt;/item&gt;
      &lt;item&gt;Software Bill of Materials (SBOMs): GitHub allows you to export an SBOM for your repository directly from its dependency graph. An SBOM provides a comprehensive list of all your project's dependencies, including transitive ones (dependencies of your dependencies).&lt;/item&gt;
      &lt;item&gt;Code Scanning: Code scanning can also help identify potential vulnerabilities or suspicious patterns that might arise from integrating compromised &lt;code&gt;npm&lt;/code&gt;packages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Warning&lt;/p&gt;
    &lt;p&gt;If you spot vulnerabilities or issues in NPM or Github, please report them using the following links:&lt;/p&gt;
    &lt;p&gt;Socket.dev is a security platform designed to protect JavaScript projects by scanning and securing dependencies from malicious and vulnerable code. It offers various tools such as GitHub App, "Safe NPM" CLI tool, Web Extension, and VSCode Extension. Watch their talk on AI powered malware hunting at scale, Jan 2025 for more details.&lt;/p&gt;
    &lt;p&gt;Snyk offers a suite of tools to fix vulnerabilities in open source dependencies, including a CLI to run vulnerability scans on local machine, IDE integrations to embed into development environment, and API to integrate with Snyk programmatically. For example, you can test public npm packages before use or create automatic PRs for known vulnerabilities.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Maintainer burnout is a significant problem in the open-source community. Many popular&lt;/p&gt;&lt;code&gt;npm&lt;/code&gt;packages are maintained by volunteers who work in their spare time, often without any compensation. Over time, this can lead to exhaustion and a lack of motivation, making them more susceptible to social engineering where a malicious actor pretends to be a helpful contributor and eventually injects malicious code.&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;In 2018, the&lt;/p&gt;&lt;code&gt;event-stream&lt;/code&gt;package was compromised due to the maintainer giving access to a malicious actor13. Another example outside the JavaScript ecosystem is the XZ Utils incident14 in 2024 where a malicious actor worked for over three years to attain a position of trust.&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;OSS donations also help create a more sustainable model for open-source development. Foundations can help support the business, marketing, legal, technical assistance and direct support behind hundreds of open source projects that so many rely upon15.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In the JavaScript ecosystem, the OpenJS Foundation (https://openjsf.org) was founded in 2019 from a merger of JS Foundation and Node.js Foundation. But here are few platforms where you can also directly donate to OSS maintainers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Sponsors https://github.com/sponsors&lt;/item&gt;
      &lt;item&gt;Open Collective https://opencollective.com&lt;/item&gt;
      &lt;item&gt;Thanks.dev https://thanks.dev&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;https://www.aikido.dev/blog/npm-debug-and-chalk-packages-compromised ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://socket.dev/blog/ongoing-supply-chain-attack-targets-crowdstrike-npm-packages ↩ ↩2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://www.reversinglabs.com/blog/malicious-npm-patch-delivers-reverse-shell ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://socket.dev/blog/north-korean-apt-lazarus-targets-developers-with-malicious-npm-package ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://github.com/duckdb/duckdb-node/security/advisories/GHSA-w62p-hx95-gf2c ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://openssf.org/blog/2024/04/15/open-source-security-openssf-and-openjs-foundations-issue-alert-for-social-engineering-takeovers-of-open-source-projects/ ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/bodadotsh/npm-security-best-practices"/><published>2025-09-21T21:19:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327059</id><title>My new Git utility `what-changed-twice` needs a new name</title><updated>2025-09-22T02:24:56.022250+00:00</updated><content>&lt;doc fingerprint="7612e86254321f17"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Archive:&lt;/p&gt;
          &lt;p&gt;Subtopics:&lt;/p&gt;
          &lt;p&gt;Comments disabled&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Sun, 21 Sep 2025&lt;/p&gt;
          &lt;p&gt; My new git utility `what-changed-twice` needs a new name &lt;/p&gt;
          &lt;p&gt;As I have explained in the past, my typical workflow is to go along commiting stuff that might or might not make sense, then clean it all up at the end, doing multiple passes with &lt;/p&gt;
          &lt;p&gt;What is Fred for? I have a couple of uses for it so far.&lt;/p&gt;
          &lt;p&gt;Often as I work I'll produce a chain of commits that looks like this:&lt;/p&gt;
          &lt;p&gt;It often happens that I will modify a file on Monday, modify it some more on Tuesday, correct a spelling error on Wednesday. I might have made 7 sets of changes to the main file, of which 4 are related, 2 others are related to each other but not to the other 4, and the last one is unrelated to any of the rest. When a file has changed more than once, I need to see what changed and then group the changes into related sets.&lt;/p&gt;
          &lt;p&gt;The &lt;/p&gt;
          &lt;p&gt;Some files changed only once, and I don't need to think about those at this stage. Later I can go back and split up those commits if it seems to make the history clearer.&lt;/p&gt;
          &lt;p&gt;Fred takes the output of &lt;/p&gt;
          &lt;p&gt;It finds which files were modified in which commits, and it prints a report about any file that was modified in more than one commit:&lt;/p&gt;
          &lt;p&gt;The report is in two parts. At the top, the path of each file that changed more than once in the log, and the (highly-abbreviated) commit IDs of the commits in which it changed. For example, &lt;/p&gt;
          &lt;p&gt;Now I can look to see what else changed in those three commits:&lt;/p&gt;
          &lt;p&gt;then look at the changes to &lt;/p&gt;
          &lt;p&gt;and then decide if there are any changes I might like to squash together.&lt;/p&gt;
          &lt;p&gt;Many other files changed on the branch, but I only have to concern myself with four.&lt;/p&gt;
          &lt;p&gt;There's bonus information too. If a commit is not mentioned in the report, then it only changed files that didn't change in any other commit. That means that in a rebase, I can move that commit literally anywhere else in the sequence without creating a conflict. Only the commits in the report can cause conflicts if they are reordered.&lt;/p&gt;
          &lt;p&gt;I write most things in Python these days, but this one seemed to cry out for Perl. Here's the code.&lt;/p&gt;
          &lt;p&gt;Hmm, maybe I'll call it &lt;/p&gt;
          &lt;p&gt;[Other articles in category /prog/git] permanent link&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.plover.com/2025/09/21/#what-changed-twice"/><published>2025-09-21T21:59:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327199</id><title>How can I influence others without manipulating them?</title><updated>2025-09-22T02:24:55.594416+00:00</updated><content>&lt;doc fingerprint="b482039d8bacd597"&gt;
  &lt;main&gt;
    &lt;p&gt;We influence others every day, whether we intend to or not. Sometimes it is through the way we argue, sometimes through the way we listen, and sometimes simply through the story we tell about what matters. Influence is not the property of the few who hold authority. It is the currency of all relationships.&lt;/p&gt;
    &lt;p&gt;The word persuasion often carries with it the scent of manipulation, as though one person is moving another toward something they do not really want. But there is another way to hold it. Influence can be understood as an invitation. It is the art of meeting people where they are, of entering their world with respect, and of opening a door that they might choose to walk through with us.&lt;/p&gt;
    &lt;p&gt;This article invites you to consider five doors of influence: Rationalising, Asserting, Negotiating, Inspiring, and Bridging. Each opens a different path into relationship and commitment. Each has its gifts. Each, when overused, can become a wall instead of a door.&lt;/p&gt;
    &lt;p&gt;The practice is not to master all five overnight, but to grow our awareness and our range. Persuasion is not a personality trait. It is a skill. It asks us to listen, to notice, and to choose consciously how we invite others.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our own doorway: The blind spot of preference&lt;/head&gt;
    &lt;p&gt;Most of us have a default style of persuasion. Perhaps you lean on facts. Perhaps you rely on conviction. Perhaps you search for compromise, tell stories, or call on the voices of others. None of these is wrong. Each is a doorway.&lt;/p&gt;
    &lt;p&gt;Yet our default does more than shape how we speak. It shapes how we see. If I lean on data, I may hear someone’s story as weak rather than inspiring. If I favour conviction, I may interpret hesitation as lack of commitment, when it might be an opening for negotiation. If I thrive on inspiration, I may dismiss detail-oriented questions as nit-picking rather than as a real need for clarity. If I am most comfortable with bridging, I may feel uneasy with those who are direct and independent.&lt;/p&gt;
    &lt;p&gt;Our own doorway becomes a filter. It colours what we pay attention to, what we dismiss, and how we react. The danger is that we mistake difference for resistance. We think they are being difficult, when in fact they are simply standing at another door.&lt;/p&gt;
    &lt;p&gt;Becoming aware of our preference allows us to pause. Instead of defending our own style, we can ask: What is the invitation they are offering me through their language and behaviour? Which door are they holding open that I have overlooked because I was guarding my own?&lt;/p&gt;
    &lt;p&gt;Influence begins with this act of humility. The willingness to see that the door we most trust may not be the one others are waiting at.&lt;/p&gt;
    &lt;p&gt;Once we recognise our blind spot, we are ready to notice the variety of doors available to us. Influence is not one way, it is five ways. Each has its own language, its own gifts, and its own risks. Rationalising, Asserting, Negotiating, Inspiring, and Bridging are not personality types but choices. At any moment, we can choose to knock on a different door, depending on where others are standing and what the moment requires.&lt;/p&gt;
    &lt;p&gt;What follows is a closer look at each door. how to recognise it, how to walk through it well, and how to avoid turning it into a wall.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rationalising: The door of logic&lt;/head&gt;
    &lt;p&gt;Rationalising is the style that seeks to persuade through facts, evidence, and analysis. It appeals to those who are comforted by structure and clarity. When someone asks for data, compares benchmarks, or worries about risk and performance, they are standing at the rational door.&lt;/p&gt;
    &lt;p&gt;This style has its strengths. It reassures the finance director who needs a business case. It appeals to the engineer who wants proof that the system will not fail. It builds trust with the analyst who measures quality by what can be verified.&lt;/p&gt;
    &lt;p&gt;To enter this door well, we come prepared. We gather our facts. We organise our thinking into a clear flow: problem, options, evidence, recommendation. We know the return on investment, the efficiency gains, the quality improvements. We anticipate objections and hold evidence ready to meet them. We present data not as a weapon but as a gift of clarity.&lt;/p&gt;
    &lt;p&gt;Yet logic alone is not enough. Overused, it can become cold and detached. The person across from us may long for empathy, but we bury them in numbers. They may seek relationship, but we offer them a chart. Rationalising can easily turn into proving a point rather than creating understanding.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reflection questions&lt;/head&gt;
    &lt;p&gt;• Which metrics or outcomes matter most to this person, and have I framed my case in those terms, for example ROI, risk, quality or efficiency?&lt;/p&gt;
    &lt;p&gt;• What is my one-page flow: problem, options, evidence, recommendation?&lt;/p&gt;
    &lt;p&gt;• Which objections are most likely, and what independent sources will I cite to address them?&lt;/p&gt;
    &lt;p&gt;• Where will a chart or comparison clarify, and where could visuals overwhelm?&lt;/p&gt;
    &lt;p&gt;• What level of evidence would be enough for this decision, and how will I check for overload signals in the moment?&lt;/p&gt;
    &lt;p&gt;• Where might I be using facts to prove a point rather than to build shared understanding?&lt;/p&gt;
    &lt;p&gt;• If they are not data-driven, which second door will I pivot to after I test for fit?&lt;/p&gt;
    &lt;p&gt;• What jargon should I remove to keep the message precise and clear?&lt;/p&gt;
    &lt;head rend="h2"&gt;Asserting: The door of conviction&lt;/head&gt;
    &lt;p&gt;Asserting persuades through confidence, authority, and clarity. It is the voice that speaks directly and without hesitation. It is the person who values decisiveness, who prefers a straight line over a winding explanation, who respects those who stand their ground.&lt;/p&gt;
    &lt;p&gt;You recognise this style when someone expresses strong opinions with little hesitation, when they challenge ideas and expect you to do the same, when they respond best to conviction rather than ambiguity. For them, clarity is a form of respect.&lt;/p&gt;
    &lt;p&gt;To enter this door well, we speak with confidence. We choose firm language, declarative statements, uncluttered by qualifiers. We are direct and concise. We know our boundaries, and we state them. We are ready with anchor points: two or three firm reasons why our proposal matters.&lt;/p&gt;
    &lt;p&gt;The temptation, though, is to confuse assertiveness with aggression. Overused, asserting becomes domineering. It silences others. It leaves no room for dialogue. It builds resistance where it meant to build respect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reflection questions&lt;/head&gt;
    &lt;p&gt;• What exactly am I asking for in one clear sentence?&lt;/p&gt;
    &lt;p&gt;• What is non-negotiable, and what is flexible?&lt;/p&gt;
    &lt;p&gt;• What two or three anchor reasons will I use to support my position?&lt;/p&gt;
    &lt;p&gt;• How will I signal credibility without drifting into name-dropping or status plays?&lt;/p&gt;
    &lt;p&gt;• What does matching their energy look like while staying respectful and calm?&lt;/p&gt;
    &lt;p&gt;• Where will I deliberately pause to listen so I do not over-talk the room?&lt;/p&gt;
    &lt;p&gt;• What early signals tell me I am tipping into pressure, and how will I de-escalate?&lt;/p&gt;
    &lt;p&gt;• If directness stalls the dialogue, what is my next door to try?&lt;/p&gt;
    &lt;head rend="h2"&gt;Negotiating: The door of balance&lt;/head&gt;
    &lt;p&gt;Negotiating persuades by finding common ground. It seeks the middle path, the workable solution, the compromise that honours both sides. It is rooted in the belief that influence is not about victory but about mutual benefit.&lt;/p&gt;
    &lt;p&gt;You notice this style in those who raise concerns gently, who suggest meeting halfway, who speak in terms of “what if” and “could we.” They are pragmatic. They value win–win outcomes. They prefer flexibility over confrontation.&lt;/p&gt;
    &lt;p&gt;To enter this door well, we listen closely to uncover the real concern beneath the stated one. We protect what matters most to us while staying open to trade-offs. We come with options. We ask open-ended questions. We remain collaborative, treating the conversation as joint problem-solving.&lt;/p&gt;
    &lt;p&gt;But compromise has its dangers. Overused, negotiation turns into unnecessary concession. We may be seen as weak or uncertain. Others may begin every conversation expecting us to bend. We may give away value before fully exploring our own position.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reflection questions&lt;/head&gt;
    &lt;p&gt;• What is the real concern beneath what is being said, and how will I surface it with open questions?&lt;/p&gt;
    &lt;p&gt;• Which larger goals or principles am I protecting, and what are my red lines?&lt;/p&gt;
    &lt;p&gt;• What tradables or creative options can I offer that create value without giving away too much?&lt;/p&gt;
    &lt;p&gt;• What do I expect in return for each concession?&lt;/p&gt;
    &lt;p&gt;• How will I hold a respectful, collaborative tone so we stay in joint problem solving?&lt;/p&gt;
    &lt;p&gt;• At what point would compromise become drift, and how will I name that threshold?&lt;/p&gt;
    &lt;p&gt;• If others expect automatic concessions from me, how will I reset expectations early?&lt;/p&gt;
    &lt;p&gt;• What alternative door will I use if bargaining signals are not present?&lt;/p&gt;
    &lt;head rend="h2"&gt;Inspiring: The door of vision&lt;/head&gt;
    &lt;p&gt;Inspiring persuades through story, metaphor, and imagination. It calls people to something larger than themselves. It shifts the focus from what is practical to what is possible.&lt;/p&gt;
    &lt;p&gt;You know you are with an inspiring type when they disengage from technical talk but light up at mention of purpose or possibility. They ask about impact and legacy. They respond to stories and metaphors. They look for meaning, not just measurement.&lt;/p&gt;
    &lt;p&gt;To enter this door well, we tell relevant stories. We use vivid language and imagery. We connect ideas to values and aspirations. We speak with authenticity and passion. We invite others to imagine: What if you could? What would it feel like if…?&lt;/p&gt;
    &lt;p&gt;Yet inspiration without grounding can lose its way. Overused, it becomes idealistic, disconnected from reality, heavy with promise and light on delivery. Listeners may nod politely but ask for numbers that never come. Trust fades when vision is not matched by action.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reflection questions&lt;/head&gt;
    &lt;p&gt;• What specific story from their world will make this possibility feel real and credible?&lt;/p&gt;
    &lt;p&gt;• What image or analogy will help them visualise success?&lt;/p&gt;
    &lt;p&gt;• Which values or purpose of theirs does this idea serve, for example impact, legacy, innovation or customer experience?&lt;/p&gt;
    &lt;p&gt;• What is the smallest concrete next step that grounds the vision?&lt;/p&gt;
    &lt;p&gt;• Where will I invite imagination with a genuine what if question, then check for practical concerns?&lt;/p&gt;
    &lt;p&gt;• What numbers or proof points should I have ready if they ask for them?&lt;/p&gt;
    &lt;p&gt;• How will I keep my tone authentic so enthusiasm does not outpace deliverables?&lt;/p&gt;
    &lt;p&gt;• If inspiration lands politely but without commitment, which door will I move to next?&lt;/p&gt;
    &lt;head rend="h2"&gt;Bridging: The door of relationship&lt;/head&gt;
    &lt;p&gt;Bridging persuades through connection and social proof. It is the style that builds trust by involving others, by leaning on shared experience, by showing that someone else has walked this path before.&lt;/p&gt;
    &lt;p&gt;You recognise it when someone asks, “Who else is doing this?” or seems hesitant until they hear a peer’s endorsement. They value rapport and trust more than unknown data. They commit when they see others they respect committing.&lt;/p&gt;
    &lt;p&gt;To enter this door well, we bring in mutual contacts. We offer testimonials and case studies. We emphasise shared goals. We give before we ask, offering help, making introductions, extending reciprocity. We are warm and attentive, because this style rests on human connection.&lt;/p&gt;
    &lt;p&gt;But here too lies a danger. Overused, bridging makes us dependent on others. We may delay decisions, waiting for third-party validation. We may undermine our own authority, deferring to outside voices instead of speaking for ourselves.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reflection questions&lt;/head&gt;
    &lt;p&gt;• Who do they already trust that I can appropriately involve, and how will I make that connection?&lt;/p&gt;
    &lt;p&gt;• Which case study or testimonial best mirrors their context?&lt;/p&gt;
    &lt;p&gt;• How will I frame our shared goals so alignment is explicit?&lt;/p&gt;
    &lt;p&gt;• What value can I offer first, for example a helpful introduction or insight, before asking for commitment?&lt;/p&gt;
    &lt;p&gt;• How will I keep momentum without waiting for every third party to weigh in?&lt;/p&gt;
    &lt;p&gt;• Where do I need to speak in my own voice so I do not over-rely on others’ validation?&lt;/p&gt;
    &lt;p&gt;• What is my plan to sustain the relationship beyond this single decision?&lt;/p&gt;
    &lt;p&gt;• If bridging slows progress, which door should I try to regain decisiveness?&lt;/p&gt;
    &lt;head rend="h2"&gt;Living the paradox of influence&lt;/head&gt;
    &lt;p&gt;Each of these five doors, Rationalising, Asserting, Negotiating, Inspiring, and Bridging, offers a path into relationship. Each works best when it honours the person we hope to influence rather than serving only our own habits.&lt;/p&gt;
    &lt;p&gt;The paradox is that any of them, when overused, becomes a wall. Logic turns cold. Conviction turns harsh. Compromise turns weak. Vision turns empty. Relationship turns dependent. What begins as invitation can end as imposition.&lt;/p&gt;
    &lt;p&gt;The practice is not to abandon our natural style but to notice when it no longer serves. To ask: Which doorway is this person already standing at? What language are they using? What energises them? What shuts them down?&lt;/p&gt;
    &lt;p&gt;Influence then becomes less about pressing harder on the door we know, and more about walking around to the door they are holding open.&lt;/p&gt;
    &lt;p&gt;Persuasion is not about clever tactics or manipulation. It is about presence. It is about listening for what matters to others and choosing consciously how we invite them.&lt;/p&gt;
    &lt;p&gt;The question that remains for each of us is simple: Which door will you choose to knock on in your next conversation?&lt;/p&gt;
    &lt;p&gt;Do you have any tips or advice? What has worked for you? Do you have any recommended resources to explore? Thanks for reading!&lt;/p&gt;
    &lt;head rend="h2"&gt;Influenced by&lt;/head&gt;
    &lt;p&gt;The five doors of influence: Rationalising, Asserting, Negotiating, Inspiring, and Bridging, are my synthesis, but several bodies of work have shaped them:&lt;/p&gt;
    &lt;p&gt;• Gary Yukl’s research on leadership influence tactics, which identified patterns such as rational persuasion, pressure, exchange, inspirational appeals, and coalition tactics.&lt;/p&gt;
    &lt;p&gt;• Robert Cialdini’s principles of persuasion, especially authority, social proof, reciprocity, and consistency, which continue to show how people respond to influence in practice.&lt;/p&gt;
    &lt;p&gt;• Negotiation practice and theory, from both organisational behaviour research and classic works on principled negotiation, which highlight the importance of mutual benefit and trade-offs.&lt;/p&gt;
    &lt;p&gt;• Leadership and change literature, including Peter Block’s writings on community and invitation, which shape the idea of influence as a relational act rather than a manipulative one.&lt;/p&gt;
    &lt;p&gt;• My own work with leadership teams, where repeated practice has confirmed that leaders tend to default to one or two styles, often without realising the limits this creates in how they see and respond to others.&lt;/p&gt;
    &lt;p&gt;These streams converge in the five doors. They are not meant as a new theory, but as a practical frame that leaders can hold in the moment, to choose how they wish to invite others.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andiroberts.com/leadership-questions/how-to-influence-others-without-manipulating"/><published>2025-09-21T22:20:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327318</id><title>Zig got a new ELF linker and it's fast</title><updated>2025-09-22T02:24:54.978229+00:00</updated><content>&lt;doc fingerprint="d41cc1ab4580173c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Elf2: create a new linker from scratch #25299&lt;/head&gt;
    &lt;p&gt; Merged &lt;/p&gt;
    &lt;p&gt; +4,141 −536 &lt;/p&gt;
    &lt;p&gt; Add this suggestion to a batch that can be applied as a single commit. This suggestion is invalid because no changes were made to the code. Suggestions cannot be applied while the pull request is closed. Suggestions cannot be applied while viewing a subset of changes. Only one suggestion per line can be applied in a batch. Add this suggestion to a batch that can be applied as a single commit. Applying suggestions on deleted lines is not supported. You must change the existing code in this line in order to create a valid suggestion. Outdated suggestions cannot be applied. This suggestion has been applied or marked resolved. Suggestions cannot be applied from pending reviews. Suggestions cannot be applied on multi-line comments. Suggestions cannot be applied while the pull request is queued to merge. Suggestion cannot be applied right now. Please check back later. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ziglang/zig/pull/25299"/><published>2025-09-21T22:40:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327399</id><title>EU to block Big Tech from new financial data sharing system</title><updated>2025-09-22T02:24:54.275219+00:00</updated><content>&lt;doc fingerprint="8e3b0d555aaacbe9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;&lt;quote&gt;EU to block Big Tech from new financial data sharing system&lt;/quote&gt;&lt;/head&gt;&lt;head rend="h2"&gt;Save 40% on Standard Digital&lt;/head&gt;was $540 now $319 for your first year&lt;p&gt;Save now on essential digital access to quality FT journalism on any device. Saving based on monthly annualised price.&lt;/p&gt;&lt;head rend="h2"&gt;Explore more offers.&lt;/head&gt;&lt;head rend="h3"&gt;Trial&lt;/head&gt;&lt;p&gt;Then $75 per month. Complete digital access to quality FT journalism on any device. Cancel or change your plan anytime during your trial.&lt;/p&gt;&lt;head rend="h3"&gt;Premium Digital&lt;/head&gt;&lt;p&gt;Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.&lt;/p&gt;&lt;p&gt;FT newspaper delivered Monday-Saturday, plus FT Digital Edition delivered to your device Monday-Saturday.&lt;/p&gt;&lt;p&gt;Check whether you already have access via your university or organisation.&lt;/p&gt;&lt;p&gt;Terms &amp;amp; Conditions apply&lt;/p&gt;&lt;head rend="h2"&gt;Explore our full range of subscriptions.&lt;/head&gt;&lt;head rend="h3"&gt;For individuals&lt;/head&gt;&lt;p&gt;Discover all the plans currently available in your country&lt;/p&gt;&lt;head rend="h3"&gt;For multiple readers&lt;/head&gt;&lt;p&gt;Digital access for organisations. Includes exclusive features and content.&lt;/p&gt;&lt;head rend="h2"&gt;Why the FT?&lt;/head&gt;&lt;p&gt;See why over a million readers pay to read the Financial Times.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ft.com/content/6596876f-c831-482c-878c-78c1499ef543"/><published>2025-09-21T22:54:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327531</id><title>Be Careful with Go Struct Embedding</title><updated>2025-09-22T02:24:54.082022+00:00</updated><content>&lt;doc fingerprint="4670afddffbd929b"&gt;
  &lt;main&gt;
    &lt;p&gt;Go has a feature called struct embedding that allows you to compose types. It looks something like this:&lt;/p&gt;
    &lt;code&gt;type Position struct {
	X int
	Y int
}

type Colour struct {
	R byte
	G byte
	B byte
}

type Rectangle struct {
	Position
	Colour
	
	Width  int
	Height int
}

r := Rectangle{/* ... */}

// This works:
fmt.Printf("%d,%d\n", r.Position.X, r.Position.Y)

// but so does this:
fmt.Printf("%d,%d\n", r.X, r.Y)
&lt;/code&gt;
    &lt;p&gt;But what do you think this code does?&lt;/p&gt;
    &lt;code&gt;type FooService struct {
	URL string
}

type BarConnectionOptions struct {
	URL string
}

type BarService struct {
	BarConnectionOptions
}

type Options struct {
	FooService
	BarService
}

opts := Options{
	FooService: FooService{URL: "abc.com"},
	BarService: BarService{
		BarConnectionOptions: BarConnectionOptions{
			URL: "xyz.com",
		},
	},
}

fmt.Println(opts.URL)
&lt;/code&gt;
    &lt;p&gt;I would expect this to fail to compile as &lt;code&gt;URL&lt;/code&gt; is ambiguous. It actually prints &lt;code&gt;abc.com&lt;/code&gt;, presumably as it is the least nested version of that field. This happened at the day job, although it was caught in a test. Be careful when embedding structs!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mattjhall.co.uk/posts/be-careful-with-go-struct-embedding.html"/><published>2025-09-21T23:16:08+00:00</published></entry></feed>