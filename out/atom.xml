<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-25T16:49:05.177584+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46019898</id><title>Three Years from GPT-3 to Gemini 3</title><updated>2025-11-25T16:49:13.983017+00:00</updated><content>&lt;doc fingerprint="3d53915f1bb40691"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Three Years from GPT-3 to Gemini 3&lt;/head&gt;
    &lt;head rend="h3"&gt;From chatbots to agents&lt;/head&gt;
    &lt;p&gt;I‚Äôve been testing Google‚Äôs new Gemini 3 model. It is very good. But rather than give you benchmark numbers, I‚Äôm going to show you how far AI has come in three years by asking the AI to demonstrate it.&lt;/p&gt;
    &lt;p&gt;It has been slightly less than three years since the release of ChatGPT. A few days before that launch, I wrote my first post on this Substack about OpenAI‚Äôs earlier GPT-3 model. Then ChatGPT came out, and I wrote immediately afterwards that ‚ÄúI am usually pretty hesitant to make technology predictions, but I think that this is going to change our world much sooner than we expect, and much more drastically. Rather than automating jobs that are repetitive &amp;amp; dangerous, there is now the prospect that the first jobs that are disrupted by AI will be more analytic; creative; and involve more writing and communication.‚Äù&lt;/p&gt;
    &lt;p&gt;I think I got that one right.&lt;/p&gt;
    &lt;p&gt;I could explain the difference between the original ChatGPT and the new AI model from Google, Gemini 3, that launched today. But I don‚Äôt have to. Instead, I gave the screenshot above to Gemini 3 with a single prompt:&lt;/p&gt;
    &lt;p&gt;Me: ‚Äúshow how far AI has come since this post by doing stuff.‚Äù&lt;/p&gt;
    &lt;p&gt;Gemini: ‚ÄúI can definitely show you the difference. The tweet you shared is from November 2022‚Äîright on the cusp of the modern AI boom. Back then, the ‚Äúwow factor‚Äù was that an AI could write a coherent paragraph or a simple poem about a silly concept like a ‚Äúcandy-powered FTL drive escaping otters.‚Äù&lt;/p&gt;
    &lt;p&gt;To demonstrate how far we‚Äôve come, I‚Äôm not just going to write text about it. I have built you a fully interactive, playable Candy-Powered FTL Starship Simulator.&lt;/p&gt;
    &lt;p&gt;In 2022, AI could describe the engine. In 2025, AI can code the engine, design the interface, and let you pilot the ship yourself.‚Äù&lt;/p&gt;
    &lt;p&gt;And, indeed, it built me a tiny game where I had to use the power of candy to escape otters, featuring small poems and an ongoing set of amusing updates. If you‚Äôre reading this blog, you probably knew AI could do that. What‚Äôs more interesting is what else Gemini 3 can do when you stop thinking of it as a chatbot and start thinking of it as something else entirely&lt;/p&gt;
    &lt;head rend="h1"&gt;Coding tools that aren‚Äôt just coding tools&lt;/head&gt;
    &lt;p&gt;Along with Gemini 3, Google has launched Antigravity. For programmers, Antigravity should be familiar territory, it is similar to Claude Code and OpenAI Codex, specialized tools that can be given access to your computer and which can autonomously write computer programs with guidance. If you aren‚Äôt a programmer, you may dismiss Antigravity and similar tools. I think that is a mistake because the ability to code isn‚Äôt just about programming, it‚Äôs about being able to do anything that happens on a computer. And that changes what these tools actually are.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is very good at coding, and this matters to you even if you don‚Äôt think of what you do as programming. A fundamental perspective powering AI development is that everything you do on a computer is, ultimately, code, and if AI can work with code it can do anything someone with a computer can: build you dashboards, work with websites, create PowerPoint, read your files, and so on. This makes agents that can code general purpose tools. Antigravity embraces this idea, with the concept of an Inbox, a place where I can send AI agents off on assignments and where they can ping me when they need permission or help.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt communicate with these agents in code, I communicate with them in English and they use code to do the work. Because Gemini 3 is good at planning, it is capable of figuring out what to do, and also when to ask my approval. For example, I gave Antigravity access to a directory on my computer containing all of my posts for this newsletter.1 I then asked Gemini 3,0: ‚ÄúI would like an attractive list of predictions I have made about AI in a single site, also do a web search to see which I was right and wrong about.‚Äù It then read through all the files, executing code, until it gave me a plan which I could edit or approve. The screenshot below is the first time the AI asked me anything about the project, and its understanding of what I wanted was impressive. I made a couple of small changes and let the AI work.&lt;/p&gt;
    &lt;p&gt;It then did web research, created a site, took over my browser to confirm the site worked, and presented me the results. Just as I would have with a human, I went through the results and made a few suggestions for improvement. It then packaged up the results so I could deploy them here.&lt;/p&gt;
    &lt;p&gt;It was not that Gemini 3.0 was capable of doing everything correctly without human intervention ‚Äî agents aren‚Äôt there yet. There were no hallucinations I spotted, but there were things I corrected, though those errors were more about individual judgement calls or human-like misunderstandings of my intentions than traditional AI problems. Importantly, I felt that I was in control of the choices AI was making because the AI checked in and its work was visible. It felt much more like managing a teammate than prompting an AI through a chat interface.&lt;/p&gt;
    &lt;head rend="h1"&gt;PhD Level Intelligence?&lt;/head&gt;
    &lt;p&gt;But Antigravity isn‚Äôt the only way Gemini 3 surprised me. The other was in how it handled work that required genuine judgment. As I have mentioned many times on this site, benchmarking AI progress is a mess. Gemini 3 takes a definitive benchmark lead on most stats, (although it may still not be able to beat the $200 GPT-5 Pro Model, but I suspect that might change when Gemini 3‚Äôs inevitable Deep Think version comes out). But you will hear one phrase repeated a lot in the AI world - that a model has ‚ÄúPhD level intelligence.‚Äù&lt;/p&gt;
    &lt;p&gt;I decided to put that to the test. I gave Gemini 3 access to a directory of old files I had used for research into crowdfunding a decade ago. It was a mishmash of files labelled things like ‚Äúproject_final_seriously_this_time_done.xls‚Äù and data in out-of-date statistical formats. I told the AI to ‚Äúfigure out the data and the structure and the initial cleaning from the STATA files and get it ready to do a new analysis to find new things.‚Äù And it did, recovering corrupted data and figuring out the complexities of the environment.&lt;/p&gt;
    &lt;p&gt;Then I gave it a typical assignment that you would expect from a second year PhD student, doing minor original research. With no further hints I wrote: ‚Äúgreat, now i want you to write an original paper using this data. do deep research on the field, make the paper not just about crowdfunding but about an important theoretical topic of interest in either entrepreneurship or business strategy. conduct a sophisticated analysis, write it up as if for a journal.‚Äù I gave it no suggestions beyond that and yet the AI considered the data, generated original hypotheses, tested them statistically, and gave me formatted output in the form of a document. The most fascinating part was that I did not give it any hints about what to research, it walked the tricky tightrope of figuring out what might be an interesting topic and how to execute it with the data it had - one of the hardest things to teach. After a couple of vague commands (‚Äúbuild it out more, make it better‚Äù) I got a 14 page paper.&lt;/p&gt;
    &lt;p&gt;Aside from this, I was impressed that the AI came up with its own measure, a way of measuring how unique a crowdfunding idea was by using natural language processing tools to compare its description mathematically to other descriptions. It wrote the code, executed it and checked the results.&lt;/p&gt;
    &lt;p&gt;So is this a PhD-level intelligence? In some ways, yes, if you define a PhD level intelligence as doing the work of a competent grad student at a research university. But it also had some of the weaknesses of a grad student. The idea was good, as were many elements of the execution, but there were also problems: some of its statistical methods needed more work, some of its approaches were not optimal, some of its theorizing went too far given the evidence, and so on. Again, we have moved past hallucinations and errors to more subtle, and often human-like, concerns. Interestingly, when I gave it suggestions with a lot of leeway, the way I would a student: (‚Äúmake sure that you cover the crowdfunding research more to establish methodology, etc.‚Äù) it improved tremendously, so maybe more guidance would be all that Gemini needed. We are not there yet, but ‚ÄúPhD intelligence‚Äù no longer seems that far away.&lt;/p&gt;
    &lt;head rend="h1"&gt;Gemini 3&lt;/head&gt;
    &lt;p&gt;Gemini 3 is a very good thinking and doing partner that is available to billions of people around the world. It is also a sign of many things: the fact that we have not yet seen a significant slowdown in AI‚Äôs continued development, the rise of agentic models, the need to figure out better ways to manage smart AIs, and more. It shows how far AI has come.&lt;/p&gt;
    &lt;p&gt;Three years ago, we were impressed that a machine could write a poem about otters. Less than 1,000 days later, I am debating statistical methodology with an agent that built its own research environment. The era of the chatbot is turning into the era of the digital coworker. To be very clear, Gemini 3 isn‚Äôt perfect, and it still needs a manager who can guide and check it. But it suggests that ‚Äúhuman in the loop‚Äù is evolving from ‚Äúhuman who fixes AI mistakes‚Äù to ‚Äúhuman who directs AI work.‚Äù And that may be the biggest change since the release of ChatGPT.&lt;/p&gt;
    &lt;p&gt;Obligatory warning: Giving an AI agent access to your computer can be risky if you don‚Äôt know what you are doing. They can move or delete files without asking you and can potentially present a security risk as well by exposing your documents to others. I suspect many of these problems will be addressed as these tools are adapted to non-coders, but, for now, be very careful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.oneusefulthing.org/p/three-years-from-gpt-3-to-gemini"/><published>2025-11-23T01:25:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46030799</id><title>What OpenAI did when ChatGPT users lost touch with reality</title><updated>2025-11-25T16:49:13.855616+00:00</updated><content/><link href="https://www.nytimes.com/2025/11/23/technology/openai-chatgpt-users-risks.html"/><published>2025-11-24T05:58:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46031220</id><title>Build a Compiler in Five Projects</title><updated>2025-11-25T16:49:13.667419+00:00</updated><content>&lt;doc fingerprint="4d007891504bb690"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Build a Compiler in Five Projects&lt;/head&gt;
    &lt;p&gt;Class website here: https://kmicinski.com/cis531-f25&lt;/p&gt;
    &lt;p&gt;Are you interested in building a compiler? Learning how functional languages are implemented? Gaining a bit of practical experience with x86-64 assembly language? If so, I invite you to try your hand at the projects in my class, CIS531. CIS531 is a masters-level class on compiler design which assumes that (a) you know how to program, (b) you‚Äôve had some exposure to C (know about stack allocation, malloc, etc.), and (c) have seen some assembly code. My class projects are in the Racket programming language, but if you don‚Äôt know Racket, it is quite easy to learn: I have a set of YouTube video lectures that teach Racket quickly! If you‚Äôve never heard of Racket before, or you‚Äôre skeptical of functional programming, indulge me for a bit: there‚Äôs no hardcore FP theory or math in this course, and Racket is genuinely the best language to use for this specific setup.&lt;/p&gt;
    &lt;p&gt;My class follows Prof. Jeremy Siek‚Äôs excellent book, ‚ÄúEssentials of Compilation.‚Äù While I highly recommend buying the book and supporting Prof. Siek, I will also note that there are free online preliminary editions floating around; in my class, I followed the free version and suggested that students buy the book if doing so fit their goals. However, along with the book, I also have a set of class slides along with sporadic course videos, both available on the class website.&lt;/p&gt;
    &lt;p&gt;This class builds up to a compiler with the following features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Variables and assignment via &lt;code&gt;let&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Integer arithmetic via &lt;code&gt;+&lt;/code&gt;and&lt;code&gt;-&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Reading inputs / printing output&lt;/item&gt;
      &lt;item&gt;Booleans, conjunctions/disjunctions (and/or)&lt;/item&gt;
      &lt;item&gt;Branching via &lt;code&gt;if&lt;/code&gt;, integer comparisons (&amp;lt;, etc.)&lt;/item&gt;
      &lt;item&gt;Heap-allocated vectors&lt;/item&gt;
      &lt;item&gt;Assignment / mutation (&lt;code&gt;set!&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;While loops&lt;/item&gt;
      &lt;item&gt;Fixed-arity functions and function application&lt;/item&gt;
      &lt;item&gt;Lambdas (closures at runtime)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The unique combination of features lets us tour an interesting cross-section of programming languages, exploring both imperative programming with loops and mutation but also functional programming with lists and recursion.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Projects&lt;/head&gt;
    &lt;p&gt;To be specific, I challenge you to complete five projects, each including a comprehensive test suite that will seriously stress the correctness of your implementation. p1 is a warmup project (you should skip if you already know Racket), but p2-5 build a compiler for a set of increasingly-complex languages to x86-64. The languages nest inside of each other, with p2 giving us straight-line arithmetic, p3 giving us decision trees, p4 giving us loops and mutation, and p5 giving us functions, recursion, and lambdas.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;p1 ‚Äì Stack interpreter. This is a warmup project, if you know Racket and have some PL background, feel free to skip.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;p2 ‚Äì Straight-line arithmetic / variables ‚Üí x86-64 assembly language&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;p3 ‚Äì Booleans and branching (if, and, or) ‚Üí x86-64 assembly language&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;p4 ‚Äì Vectors, heap allocation, set!, and loops ‚Üí x86-64 assembly language&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;p5 ‚Äì Functions, lambdas, and closure conversion ‚Üí x86-64 assembly language&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The projects are designed with one key principle in mind: get us to the most expressive/fun language possible, as fast as possible. In doing this, we sacrifice a lot that might be typically covered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Our languages aren‚Äôt type/memory safe, we assume the programmer is correct&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No register allocation (possible to add, not too hard)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No garbage collection of any kind: we just use malloc. We could trivially support the Boehm GC (I have done that in the past), but it was another static library to link in and I really wanted to make this self contained.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We support a very limited set of builtins (but it is trivial to add more)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So even after project 5, getting to a ‚Äúreal‚Äù compiler would take a bit of effort. The most important (in my opinion) are (a) memory safety (the language needs to be safe, period) via dynamic type tagging and (b) slightly more builtins, and (c) register allocation. That would get us to a respectable compiler. After that, we could add more language features, or optimize the ones we have, e.g., by using abstract interpretation.&lt;/p&gt;
    &lt;head rend="h3"&gt;An Example Program&lt;/head&gt;
    &lt;p&gt;Our language will include functions, loops, branching, assignment, and even heap-allocated vectors. As an example of the power, here‚Äôs a Sudoku solver written in the language&lt;/p&gt;
    &lt;code&gt;(program
 ;; =========================
 ;; List primitives
 ;; Empty list is (void)
 ;; =========================
 (define (is_nil x) (eq? x (void)))

 ;; cons cell as 2-element vector: [0] = head, [1] = tail
 (define (cons h t)
   (let ([c (make-vector 2)])
     (let ([_ (vector-set! c 0 h)])
       (let ([_ (vector-set! c 1 t)])
         c))))

 (define (head c) (vector-ref c 0))
 (define (tail c) (vector-ref c 1))

 ;; =========================
 ;; Cell representation
 ;; cell = (row col val) as nested cons
 ;; =========================
 (define (make_cell r c v)
   (cons r (cons c (cons v (void)))))

 (define (cell_row cell)
   (head cell))

 (define (cell_col cell)
   (head (tail cell)))

 (define (cell_val cell)
   (head (tail (tail cell))))

 ;; =========================
 ;; Block indexing (0,1,2) for rows/cols
 ;; =========================
 (define (block_index3 x)
   (if (&amp;lt; x 3)
       0
       (if (&amp;lt; x 6)
           1
           2)))

 (define (same_block? r1 c1 r2 c2)
   (if (eq? (block_index3 r1) (block_index3 r2))
       (eq? (block_index3 c1) (block_index3 c2))
       #f))

 ;; =========================
 ;; Lookup current value at (row, col) in board
 ;; board is a list of cells
 ;; Return 0 if not assigned
 ;; =========================
 (define (lookup board row col)
   (if (is_nil board)
       0
       (let ([cell (head board)])
         (let ([r (cell_row cell)])
           (let ([c (cell_col cell)])
             (if (and (eq? r row) (eq? c col))
                 (cell_val cell)
                 (lookup (tail board) row col)))))))

 ;; =========================
 ;; Conflict check:
 ;; #t if some cell in board has:
 ;;   - same value, and
 ;;   - same row OR same col OR same 3x3 block
 ;; =========================
 (define (conflicts? board row col val)
   (if (is_nil board)
       #f
       (let ([cell (head board)])
         (let ([r (cell_row cell)])
           (let ([c (cell_col cell)])
             (let ([v (cell_val cell)])
               (if (and (eq? v val)
                        (or (eq? r row)
                            (or (eq? c col)
                                (same_block? r c row col))))
                   #t
                   (conflicts? (tail board) row col val))))))))

 ;; =========================
 ;; Recursive backtracking solver over (row, col)
 ;; board: list of assignments
 ;; rows, cols = 0..8
 ;; =========================
 (define (solve_cell row col board)
   (if (eq? row 9)
       ;; All rows done: solved
       board
       (if (eq? col 9)
           ;; End of row: go to next row
           (solve_cell (+ row 1) 0 board)
           ;; Otherwise, try this cell
           (let ([existing (lookup board row col)])
             (if (eq? existing 0)
                 ;; Empty cell: try values 1..9
                 (let ([candidate 1])
                   (let ([solution (void)])
                     (begin
                       (while (and (&amp;lt; candidate 10)
                                   (eq? solution (void)))
                              (begin
				(if (conflicts? board row col candidate)
                                    ;; conflict, skip
                                    (set! solution solution)
                                    ;; no conflict, extend board and recurse
                                    (let ([s (solve_cell row
                                                         (+ col 1)
                                                         (cons (make_cell row col candidate)
                                                               board))])
                                      (if (eq? s (void))
                                          (set! solution solution)
                                          (set! solution s))))
				(set! candidate (+ candidate 1))))
                       solution)))
                 ;; Pre-filled cell: just move on
                 (solve_cell row (+ col 1) board))))))

 ;; =========================
 ;; Read initial board from input:
 ;; 81 integers, row-major, 0 = empty, 1..9 = given
 ;; Returns list of cells
 ;; =========================
 (define (read_board)
   (let ([board (void)])
     (let ([i 0])
       (begin
         (while (&amp;lt; i 9)
		(begin
                  (let ([j 0])
                    (while (&amp;lt; j 9)
			   (begin
			     (let ([v (read)])
                               (if (eq? v 0)
				   (set! board board)
				   (set! board (cons (make_cell i j v) board))))
			     (set! j (+ j 1)))))
                  (set! i (+ i 1))))
         board))))

 ;; =========================
 ;; Entry: read board, solve from (0,0), return solution
 ;; Solution is a list of (row col val) cells
 ;; =========================
 (let* ([board (read_board)]
        [solution (solve_cell 0 0 board)])
   (lookup solution 8 8)))
&lt;/code&gt;
    &lt;head rend="h3"&gt;The Full Language&lt;/head&gt;
    &lt;p&gt;The final language you‚Äôll implement will be this one. In comments, I‚Äôve also highlighted the sublanguages: for example, project 2 includes only numbers, input (read), binary plus, unary minus, variable references and let binding. It grows to all of &lt;code&gt;R5&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;(define (R5-exp? e)
  (match e
    ;; Project 2
    [(? fixnum?) #t]
    ['(read) #t]
    [`(+ ,(? R5-exp? e0) ,(? R5-exp? e1)) #t]
    [`(- ,(? R5-exp? e)) #t]
    [(? symbol?) #t]
    [`(let ([,(? symbol? x) ,(? R5-exp? e)]) ,(? R5-exp? eb)) #t]
	;; Project 3
    [#t #t]
    [#f #t]
    ['(void) #t]
    [`(- ,(? R5-exp? e0) ,(? R5-exp? e1)) #t]
    [`(and ,(? R5-exp? e0) ,(? R5-exp? e1)) #t]
    [`(or  ,(? R5-exp? e0) ,(? R5-exp? e1)) #t]
    [`(not ,(? R5-exp? e1)) #t]
    [`(,(? cmp? c) ,(? R5-exp? e0) ,(? R5-exp? e1)) #t]
    [`(if ,(? R5-exp? e-g) ,(? R5-exp? e-t) ,(? R5-exp? e-f)) #t]
    ;; Project 4
    [`(let* ([,(? symbol? xs) ,(? R5-exp? es)] ...) ,(? R5-exp? eb)) #t]
    [`(begin ,(? R5-exp?) ... ,(? R5-exp? ret)) #t]
    [`(while ,(? R5-exp? e-g) ,(? R5-exp? es) ...) #t]
    [`(make-vector ,(? R5-exp? len)) #t]
    [`(vector-ref ,(? R5-exp? v) ,(? fixnum? i)) #t]
    [`(vector-set! ,(? R5-exp? v) ,(? fixnum? i) ,(? R5-exp? e-v)) #t]
    [`(set! ,(? symbol? x) ,(? R5-exp? e)) #t]
    ;; Project 5
    [`(,(? R5-exp? e-f) ,(? R5-exp? a-args) ...) #t]
    [`(lambda (,(? symbol? xs) ...) ,(? R5-exp? e-body)) #t]
	[_ #f]))

(define (R5-defn? defn)
  (match defn
    ;; Project 5 adds multiple function definitions
    [`(define (,(? symbol? f) ,(? symbol? formals) ...)  ,(? R5-exp? e-b)) #t]
    [_ #f]))

(define (R5? p)
  (match p
    [`(program ,(? R5-defn? defns) ... ,(? R5-exp?)) #t]
    [_ #f]))
&lt;/code&gt;
    &lt;head rend="h3"&gt;The Compiler‚Äôs Structure&lt;/head&gt;
    &lt;p&gt;To get you booted up fast as possible, every single project is designed the same way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;compile.rkt&lt;/code&gt;‚Äì Your pass implementations. You will edit functions provided here. -&amp;gt; This is the only file you will edit! The rest are read-only&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;irs.rkt&lt;/code&gt;‚Äì IR definitions and predicates like&lt;code&gt;anf-program?&lt;/code&gt;,&lt;code&gt;c1-program?&lt;/code&gt;, etc. (see also typed/shrunk variants)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;interpreters.rkt&lt;/code&gt;‚Äì Reference interpreters for several IRs (used by tests and for your own debugging).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;system.rkt&lt;/code&gt;‚Äì System/ABI configuration, pass names, runtime filenames, output paths, etc.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;main.rkt&lt;/code&gt;‚Äì Driver that runs all passes, can build a binary, and can launch a debug server.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;test.rkt&lt;/code&gt;‚Äì Test harness. Runs isolation tests or end-to-end native tests depending on&lt;code&gt;-m&lt;/code&gt;mode.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;runtime.c&lt;/code&gt;‚Äì Minimal runtime (&lt;code&gt;read_int64&lt;/code&gt;,&lt;code&gt;print_int64&lt;/code&gt;, etc.).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;test-programs/&lt;/code&gt;‚Äì Example programs (&lt;code&gt;.scm&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;input-files/&lt;/code&gt;‚Äì Input streams for programs (lines of integers).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;goldens/&lt;/code&gt;‚Äì Instructor goldens (IR snapshots, interpreter outputs, and stdout baselines).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You write your code in &lt;code&gt;compile.rkt&lt;/code&gt;, which consists of a set of
passes. Each pass transforms an input language into an output
language, and these intermediate languages (IRs) are codified via
predicates in &lt;code&gt;irs.rkt&lt;/code&gt;. To define the meaning of each IR, we give an
interpreter for each in &lt;code&gt;interpreters.rkt&lt;/code&gt;. For the compiler to be
correct, it needs to be the case that‚Äìfor all input streams‚Äìthe
compiler produces the same output stream across all intermediate
IRs. There is some system-specific stuff in &lt;code&gt;system.rkt&lt;/code&gt;, which takes
care of things like Linux vs. Mac ABI issues, specifying register
names, etc. The &lt;code&gt;main.rkt&lt;/code&gt; file acts as a main compiler entrypoint,
and it carefully runs each pass of the compiler, checking predicates
before/after each pass and interpreting each IR, checking to ensure
consistency. This is a huge win for debugging, in my opinion: you
always want to localize errors to the proximate pass which causes
misinterpretation, and &lt;code&gt;main.rkt&lt;/code&gt; seriously aids debugging in my
experience. There is also more comprehensive test infrastructure in
&lt;code&gt;test.rkt&lt;/code&gt;; this test script is invoked by the Python-based test
scripts in &lt;code&gt;test/&lt;/code&gt;. These tests check the behavior of the compiler on
the programs in the &lt;code&gt;test-programs/&lt;/code&gt; directory, using the files from
&lt;code&gt;input-files&lt;/code&gt; as inputs and comparing to the outputs in &lt;code&gt;goldens/&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Is This Course Unique and Cool?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;You build a real compiler, all the way to actual x86-64 assembly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Each IR has a corresponding interpreter, which is easy to find/read and written in a familiar style, giving semantic clarity and testable correctness.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The project is language scalable, meaning that you can use it as a base for building your own language. Of course, this is thanks to Dr. Siek‚Äôs great ‚Äúincremental‚Äù design.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is fully testable across multiple passes, which helps anticipate the thing we all fear most about writing a compiler: seeing a problem that is the ramification of far-away code from higher up in the compilation pipeline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is written in a simple, pure recursive style. Just plain old pattern matching and recursion here, no need for any complex abstractions.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;How Do I Get Started?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Familiarize yourself with the course webpage: https://kmicinski.com/cis531-f25&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you don‚Äôt know Racket, start with project 1: https://kmicinski.com/cis531-f25/projects/1&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Otherwise, start with project 2: https://kmicinski.com/cis531-f25/projects/2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;When you finish each project, move on to the next!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;When you‚Äôre done, start building your own language. Consider adding type (checking/inference), classes, more builtins, pattern matching, continuations, exceptions, algebraic effects. The options are myriad, but once you‚Äôve finished projects 2-5, you‚Äôve built a whole compiler for a surprisingly expressive language.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Thank you to the National Science Foundation and Others&lt;/head&gt;
    &lt;p&gt;If you like this work and live in the United States, please feel commensurately less bad about paying your taxes. I made the whole class free, at least as free as I could given practical constraints. This class work on compilation is partially supported by our NSF PPoSS large, which has already produced many cool major results. In subsequent explorations, I am hoping that I can use this class compiler as a baseline for highly-scalable engines that reason about programs. Given the simple, self-contained nature‚Äìand the presence of per-pass interpreters and consistency testing‚ÄìI see this as an awesome potential baseline for cool extensions.&lt;/p&gt;
    &lt;p&gt;My course is of course heavily inspired by Prof. Siek‚Äôs book and course, along with inspiration from Thomas Gilray at Washington State. Eight years ago, Tom and I took a spontaneous trip to see the eclipse halfway across the country (skipping out on the ICSE ‚Äò17 deadline basically); we discussed compiler design over a steamed seafood buffet in Myrtle Beach after napping in a cheap motel, having been awake for over 24 hours and feeling the eclipse had made it worth it. We sketched out his whole compiler on that roadtrip, and ever since that night eating steamed crabs, I wanted to build my own course compiler. Now that I have, I am not sure it compares to waking up for just four hours of twilight, only to consume copious amounts of butter and shellfish as the brisk ocean air wisps over your face, the closures and continuations softly washing rhythmically through the conversation as you walk along the beach back to your $50 motel room.&lt;/p&gt;
    &lt;p&gt;In closing, thanks for checking this out, this compiler was a ton of fun to build. Even as someone who has some amount of expertise in compiler design, building it and getting it 100% right (I hope!) was such a rewarding experience. My real sincere hope is that it offers students (and you!) a fun journey. If you end up doing anything this, please get in touch: kkmicins@syr.edu. I‚Äôd love to see what you come up with. Best wishes,&lt;/p&gt;
    &lt;p&gt;Kristopher Micinski ‚Äì Syracuse, November, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kmicinski.com/functional-programming/2025/11/23/build-a-language/"/><published>2025-11-24T07:14:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46036878</id><title>Implications of AI to schools</title><updated>2025-11-25T16:49:13.373780+00:00</updated><content>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info ¬© 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/karpathy/status/1993010584175141038"/><published>2025-11-24T17:51:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46036895</id><title>Cool-retro-term: terminal emulator which mimics look and feel of CRTs</title><updated>2025-11-25T16:49:12.779274+00:00</updated><content>&lt;doc fingerprint="afec61b99b81218b"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;&amp;gt; Default Amber&lt;/cell&gt;
        &lt;cell role="head"&gt;C:\ IBM DOS&lt;/cell&gt;
        &lt;cell role="head"&gt;$ Default Green&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;cool-retro-term is a terminal emulator which mimics the look and feel of the old cathode tube screens. It has been designed to be eye-candy, customizable, and reasonably lightweight.&lt;/p&gt;
    &lt;p&gt;It uses the QML port of qtermwidget (Konsole): https://github.com/Swordfish90/qmltermwidget.&lt;/p&gt;
    &lt;p&gt;This terminal emulator works under Linux and macOS and requires Qt5. It's suggested that you stick to the latest LTS version.&lt;/p&gt;
    &lt;p&gt;Settings such as colors, fonts, and effects can be accessed via context menu.&lt;/p&gt;
    &lt;p&gt;If you want to get a hold of the latest version, just go to the Releases page and grab the latest AppImage (Linux) or dmg (macOS).&lt;/p&gt;
    &lt;p&gt;Alternatively, most distributions such as Ubuntu, Fedora or Arch already package cool-retro-term in their official repositories.&lt;/p&gt;
    &lt;p&gt;Check out the wiki and follow the instructions on how to build it on Linux and macOS.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Swordfish90/cool-retro-term"/><published>2025-11-24T17:52:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46036908</id><title>Show HN: I built an interactive HN Simulator</title><updated>2025-11-25T16:49:12.527201+00:00</updated><content>&lt;doc fingerprint="777ff7b7fede5c03"&gt;
  &lt;main&gt;
    &lt;p&gt;More&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ysimulator.run/news"/><published>2025-11-24T17:52:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46037626</id><title>Pebble Watch software is now open source</title><updated>2025-11-25T16:49:12.109272+00:00</updated><content>&lt;doc fingerprint="dc4f4b1117d7c1f1"&gt;
  &lt;main&gt;
    &lt;p&gt;Pebble Watch Software Is Now 100% Open Source + Tick Talk #4 - PT2 Demos!&lt;/p&gt;
    &lt;p&gt;[2025-11-24]&lt;/p&gt;
    &lt;p&gt;Another big Pebble update today! TLDR:&lt;/p&gt;
    &lt;p&gt;Yesterday, Pebble watch software was ~95% open source. Today, it‚Äôs 100% open source. You can download, compile and run all the software you need to use your Pebble. We just published the source code for the new Pebble mobile app!&lt;/p&gt;
    &lt;p&gt;Pebble Appstore now has a publicly available backup and supports multiple feeds, providing long term reliability through decentralization. We‚Äôve launched our own feed and Developer Dashboard.&lt;/p&gt;
    &lt;p&gt;Pebble Time 2 schedule update (aiming to begin shipping in January, with most arriving on wrists in March/April)&lt;/p&gt;
    &lt;p&gt;Over the last year, and especially in the last week, I've chatted with tons of people in the Pebble community. One of the main questions people have is ‚Äòhow do I know that my new Pebble watch will continue to work long into the future?‚Äô. It‚Äôs an extremely valid question and concern - one that I share as a fellow Pebble wearer. I called this out specifically in my blog post announcing the relaunch in January 2025. How is this time round going to be different from last time?&lt;/p&gt;
    &lt;p&gt;There are two pieces to making Pebble sustainable long term - hardware and software.&lt;/p&gt;
    &lt;p&gt;Hardware&lt;/p&gt;
    &lt;p&gt;Nothing lasts forever, especially an inexpensive gadget like a Pebble. We want to be able to keep manufacturing these watches long into the future - mostly because I will always want one on my wrist! The company I set up to relaunch Pebble, Core Devices, is self funded, built without investors, and extremely lean. As long as we stay profitable (ie we don‚Äôt lose money), we will continue to manufacture new watches.&lt;/p&gt;
    &lt;p&gt;We‚Äôre also making sure that our new watches are more repairable than old Pebble watches. The back cover of Pebble Time 2 is screwed in. You can remove the back cover and replace the battery.&lt;/p&gt;
    &lt;p&gt;We‚Äôve also published electrical and mechanical design files for Pebble 2 Duo. Yes, you can download the schematic (includes KiCad project files) right now on Github! This should give you a nice jumpstart to designing your own PebbleOS-compatible device.&lt;/p&gt;
    &lt;p&gt;Software&lt;/p&gt;
    &lt;p&gt;Last time round, barely any of the Pebble software was open source. This made it very hard for the Pebble community to make improvements to their watches after the company behind Pebble shut down. Things are different now! This whole relaunch came about primarily because Google open sourced PebbleOS (thank you!). Yesterday, the software that powers Pebble watches was around 95% open source. As of today, it‚Äôs now 100%. This means that if Core Devices were to disappear into a black hole, you have all the source code you need to build, run and improve the software behind your Pebble.&lt;/p&gt;
    &lt;p&gt;I confess that I misunderstood why 95% was much less sustainable than 100% until recently. I discuss this in more detail in my latest Tick Talk episode (check it out). Long story short - I‚Äôm an Android user and was happy to sideload the old Pebble APK on my phone, but iPhone and other Android users have basically been stuck without an easily available Pebble mobile companion app for years.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how we‚Äôre making sure the 3 main Pebble software components are open source and guaranteed to work long into the future:&lt;/p&gt;
    &lt;p&gt;PebbleOS - software that runs on your watch itself. This has been 100% open source since January and we‚Äôve committed to open sourcing all the improvements we‚Äôve made ‚Üí github.com/coredevices/PebbleOS. You can download the source code, compile PebbleOS and easily install it over Bluetooth on your new Pebble. Textbook definition of open source!&lt;/p&gt;
    &lt;p&gt;Pebble mobile companion app - the app that for your iPhone or Android. Without the app, your Pebble is basically a paperweight. When the Pebble Tech Corp died, the lack of an open source mobile app made it difficult for anyone to continue to use their watches. We had to build an entirely new app (get it here). Today, our app is now 100% open source on Github- ensuring that what happened before cannot happen again. Want to learn more about how we built the new app cross platform using Kotlin Multiplatform? Watch Steve‚Äôs presentation at Droidcon.&lt;/p&gt;
    &lt;p&gt;Developer tools and Pebble Appstore - this software enables people to build and share their watchapps and watchfaces.&lt;/p&gt;
    &lt;p&gt;In the case of dev tools, just being open source is not enough. They needed to be updated to work on modern computers. Before we made improvements, the state of the art of Pebble app development was using an Ubuntu virtualbox VM with Python2! Over the summer, our incredibly productive intern upgraded all the SDK and dev tools and created a new way to develop Pebble apps in the browser. You should check them out!&lt;/p&gt;
    &lt;p&gt;Then there‚Äôs the Pebble Appstore. This is a collection of nearly 15,000 watchfaces and watchapps that you - the Pebble community - developed between 2012 and July 2018. When Fitbit pulled the plug on the original Pebble Appstore, the Rebble Foundation downloaded a copy of all the apps and faces, and set up a new web service to let users of the old Pebble app continue to download and use watchfaces. This was an incredible effort, one that I have used thousands of times and am a happy paying subscriber. But it‚Äôs still centralized - if their server disappears, there is no freely available backup.&lt;/p&gt;
    &lt;p&gt;To compensate for that, today we‚Äôre launching two new things:&lt;/p&gt;
    &lt;p&gt;The Pebble mobile app will soon (later this week) be able to subscribe to multiple appstore ‚Äòfeeds‚Äô. This is similar to open source package managers like pip, AUR, APT, etc. Anyone can create a Pebble-compatible appstore feed and users will be able to browse apps from that feed in the Pebble mobile app.&lt;/p&gt;
    &lt;p&gt;We‚Äôve created our own Pebble Appstore feed (appstore-api.repebble.com) and new Developer Dashboard. Our feed (fyi powered by 100% new software) is configured to back up an archive of all apps and faces to Archive.org (backup will gradually complete over the next week). Today, our feed only has a subset of all Pebble watchfaces and apps (thank you aveao for creating Pebble Archive!). Developers - you can upload your existing or new apps right now! We hope that this sets a standard for openness and we encourage all feeds to publish a freely and publicly available archive.&lt;/p&gt;
    &lt;p&gt;Important to note - developers will still be able to charge money for their apps and faces, using Kiezel pay or other services. This change does not preclude them from doing that, in fact it makes it even easier - I could see some developers creating a paid-only feed. As I recently wrote, we're also working on other ways for Pebble developers to earn money by publishing fun, beautiful and creative Pebble apps.&lt;/p&gt;
    &lt;p&gt;Another important note - some binary blobs and other non-free software components are used today in PebbleOS and the Pebble mobile app (ex: the heart rate sensor on PT2 , Memfault library, and others). Optional non-free web services, like Wispr-flow API speech recognizer, are also used. These non-free software components are not required - you can compile and run Pebble watch software without them. This will always be the case. More non-free software components may appear in our software in the future. The core Pebble watch software stack (everything you need to use your Pebble watch) will always be open source.&lt;/p&gt;
    &lt;p&gt;Pre-production Pebble Time 2. These watches are not final quality! We are still tweaking and tuning everything.&lt;/p&gt;
    &lt;p&gt;PT2 Schedule Update&lt;/p&gt;
    &lt;p&gt;We‚Äôre currently in the middle of Pebble Time 2 design verification test (DVT) phase. After we finish that, we go into production verification test (PVT) and then mass production (MP). So far, things are proceeding according to the schedule update I shared last month but that is extraordinarily subject to change. We still have a lot of testing (especially waterproof and environmental) to go. If we find problems (which is likely) we will push the schedule back to make improvements to the product.&lt;/p&gt;
    &lt;p&gt;The one major complicating factor is the timing of Chinese New Year (CNY). It‚Äôs early next year - factories will shut down for 3 weeks starting around the end of January. After restarting, things always take a week or two to get back to full speed.&lt;/p&gt;
    &lt;p&gt;We are trying our best to get into mass production and ship out at most several thousand Pebble Time 2s before CNY. It‚Äôs going to be very tight ü§û. More likely is that production will begin after CNY, then we need to transfer the watches to our fulfillment center, and ship them out. Realistically, at this time we‚Äôre forecasting that the majority of people will receive their PT2 in March and April. Please keep in mind that things may still change.&lt;/p&gt;
    &lt;p&gt;Picking a PT2 colour&lt;/p&gt;
    &lt;p&gt;There will be 4 colour options for PT2 - black/black, black/red, silver/blue, silver/(white most likely). Let me be crystal very clear - no one has picked a colour yet üòÉ. In a few weeks, I will send out an email asking everyone who pre-ordered a Pebble Time 2 to select which colour they would like to receive. Please do not email us asking when this email will be sent out. No one has been invited yet to do this. I will post here after all emails have gone out.&lt;/p&gt;
    &lt;p&gt;On a related note, I am extremely happy that we built and shipped Pebble 2 Duo. Not only is it an awesome watch, it was also a phenomenal way for us to exercise our production muscles and ease back into the systematic flow of building and shipping smartwatches.&lt;/p&gt;
    &lt;p&gt;A video is worth a million words - so I encourage you to watch me demo Pebble Time 2 watches I just received this week. Keep in mind these watches are PRE-PRODUCTION which means they parts have imperfect qualities! Subject to change!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ericmigi.com/blog/pebble-watch-software-is-now-100percent-open-source"/><published>2025-11-24T18:52:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46038047</id><title>Claude Advanced Tool Use</title><updated>2025-11-25T16:49:11.863808+00:00</updated><content>&lt;doc fingerprint="b34d76d332b7ca8a"&gt;
  &lt;main&gt;
    &lt;p&gt;The future of AI agents is one where models work seamlessly across hundreds or thousands of tools. An IDE assistant that integrates git operations, file manipulation, package managers, testing frameworks, and deployment pipelines. An operations coordinator that connects Slack, GitHub, Google Drive, Jira, company databases, and dozens of MCP servers simultaneously.&lt;/p&gt;
    &lt;p&gt;To build effective agents, they need to work with unlimited tool libraries without stuffing every definition into context upfront. Our blog article on using code execution with MCP discussed how tool results and definitions can sometimes consume 50,000+ tokens before an agent reads a request. Agents should discover and load tools on-demand, keeping only what's relevant for the current task.&lt;/p&gt;
    &lt;p&gt;Agents also need the ability to call tools from code. When using natural language tool calling, each invocation requires a full inference pass, and intermediate results pile up in context whether they're useful or not. Code is a natural fit for orchestration logic, such as loops, conditionals, and data transformations. Agents need the flexibility to choose between code execution and inference based on the task at hand.&lt;/p&gt;
    &lt;p&gt;Agents also need to learn correct tool usage from examples, not just schema definitions. JSON schemas define what's structurally valid, but can't express usage patterns: when to include optional parameters, which combinations make sense, or what conventions your API expects.&lt;/p&gt;
    &lt;p&gt;Today, we're releasing three features that make this possible:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tool Search Tool, which allows Claude to use search tools to access thousands of tools without consuming its context window&lt;/item&gt;
      &lt;item&gt;Programmatic Tool Calling, which allows Claude to invoke tools in a code execution environment reducing the impact on the model‚Äôs context window&lt;/item&gt;
      &lt;item&gt;Tool Use Examples, which provides a universal standard for demonstrating how to effectively use a given tool&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In internal testing, we‚Äôve found these features have helped us build things that wouldn‚Äôt have been possible with conventional tool use patterns. For example, Claude for Excel uses Programmatic Tool Calling to read and modify spreadsheets with thousands of rows without overloading the model‚Äôs context window.&lt;/p&gt;
    &lt;p&gt;Based on our experience, we believe these features open up new possibilities for what you can build with Claude.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tool Search Tool&lt;/head&gt;
    &lt;head rend="h3"&gt;The challenge&lt;/head&gt;
    &lt;p&gt;MCP tool definitions provide important context, but as more servers connect, those tokens can add up. Consider a five-server setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub: 35 tools (~26K tokens)&lt;/item&gt;
      &lt;item&gt;Slack: 11 tools (~21K tokens)&lt;/item&gt;
      &lt;item&gt;Sentry: 5 tools (~3K tokens)&lt;/item&gt;
      &lt;item&gt;Grafana: 5 tools (~3K tokens)&lt;/item&gt;
      &lt;item&gt;Splunk: 2 tools (~2K tokens)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's 58 tools consuming approximately 55K tokens before the conversation even starts. Add more servers like Jira (which alone uses ~17K tokens) and you're quickly approaching 100K+ token overhead. At Anthropic, we've seen tool definitions consume 134K tokens before optimization.&lt;/p&gt;
    &lt;p&gt;But token cost isn't the only issue. The most common failures are wrong tool selection and incorrect parameters, especially when tools have similar names like &lt;code&gt;notification-send-user&lt;/code&gt; vs. &lt;code&gt;notification-send-channel&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Our solution&lt;/head&gt;
    &lt;p&gt;Instead of loading all tool definitions upfront, the Tool Search Tool discovers tools on-demand. Claude only sees the tools it actually needs for the current task.&lt;/p&gt;
    &lt;p&gt;Traditional approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All tool definitions loaded upfront (~72K tokens for 50+ MCP tools)&lt;/item&gt;
      &lt;item&gt;Conversation history and system prompt compete for remaining space&lt;/item&gt;
      &lt;item&gt;Total context consumption: ~77K tokens before any work begins&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the Tool Search Tool:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only the Tool Search Tool loaded upfront (~500 tokens)&lt;/item&gt;
      &lt;item&gt;Tools discovered on-demand as needed (3-5 relevant tools, ~3K tokens)&lt;/item&gt;
      &lt;item&gt;Total context consumption: ~8.7K tokens, preserving 95% of context window&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This represents an 85% reduction in token usage while maintaining access to your full tool library. Internal testing showed significant accuracy improvements on MCP evaluations when working with large tool libraries. Opus 4 improved from 49% to 74%, and Opus 4.5 improved from 79.5% to 88.1% with Tool Search Tool enabled.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Tool Search Tool works&lt;/head&gt;
    &lt;p&gt;The Tool Search Tool lets Claude dynamically discover tools instead of loading all definitions upfront. You provide all your tool definitions to the API, but mark tools with &lt;code&gt;defer_loading: true&lt;/code&gt; to make them discoverable on-demand. Deferred tools aren't loaded into Claude's context initially. Claude only sees the Tool Search Tool itself plus any tools with &lt;code&gt;defer_loading: false&lt;/code&gt; (your most critical, frequently-used tools).&lt;/p&gt;
    &lt;p&gt;When Claude needs specific capabilities, it searches for relevant tools. The Tool Search Tool returns references to matching tools, which get expanded into full definitions in Claude's context.&lt;/p&gt;
    &lt;p&gt;For example, if Claude needs to interact with GitHub, it searches for "github," and only &lt;code&gt;github.createPullRequest&lt;/code&gt; and &lt;code&gt;github.listIssues&lt;/code&gt; get loaded‚Äînot your other 50+ tools from Slack, Jira, and Google Drive.&lt;/p&gt;
    &lt;p&gt;This way, Claude has access to your full tool library while only paying the token cost for tools it actually needs.&lt;/p&gt;
    &lt;p&gt;Prompt caching note: Tool Search Tool doesn't break prompt caching because deferred tools are excluded from the initial prompt entirely. They're only added to context after Claude searches for them, so your system prompt and core tool definitions remain cacheable.&lt;/p&gt;
    &lt;p&gt;Implementation:&lt;/p&gt;
    &lt;code&gt;{
  "tools": [
    // Include a tool search tool (regex, BM25, or custom)
    {"type": "tool_search_tool_regex_20251119", "name": "tool_search_tool_regex"},

    // Mark tools for on-demand discovery
    {
      "name": "github.createPullRequest",
      "description": "Create a pull request",
      "input_schema": {...},
      "defer_loading": true
    }
    // ... hundreds more deferred tools with defer_loading: true
  ]
}
&lt;/code&gt;
    &lt;p&gt;For MCP servers, you can defer loading entire servers while keeping specific high-use tools loaded:&lt;/p&gt;
    &lt;code&gt;{
  "type": "mcp_toolset",
  "mcp_server_name": "google-drive",
  "default_config": {"defer_loading": true}, # defer loading the entire server
  "configs": {
    "search_files": {
"defer_loading": false
    }  // Keep most used tool loaded
  }
}&lt;/code&gt;
    &lt;p&gt;The Claude Developer Platform provides regex-based and BM25-based search tools out of the box, but you can also implement custom search tools using embeddings or other strategies.&lt;/p&gt;
    &lt;head rend="h3"&gt;When to use the Tool Search Tool&lt;/head&gt;
    &lt;p&gt;Like any architectural decision, enabling the Tool Search Tool involves trade-offs. The feature adds a search step before tool invocation, so it delivers the best ROI when the context savings and accuracy improvements outweigh additional latency.&lt;/p&gt;
    &lt;p&gt;Use it when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tool definitions consuming &amp;gt;10K tokens&lt;/item&gt;
      &lt;item&gt;Experiencing tool selection accuracy issues&lt;/item&gt;
      &lt;item&gt;Building MCP-powered systems with multiple servers&lt;/item&gt;
      &lt;item&gt;10+ tools available&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Less beneficial when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Small tool library (&amp;lt;10 tools)&lt;/item&gt;
      &lt;item&gt;All tools used frequently in every session&lt;/item&gt;
      &lt;item&gt;Tool definitions are compact&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Programmatic Tool Calling&lt;/head&gt;
    &lt;head rend="h3"&gt;The challenge&lt;/head&gt;
    &lt;p&gt;Traditional tool calling creates two fundamental problems as workflows become more complex:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Context pollution from intermediate results: When Claude analyzes a 10MB log file for error patterns, the entire file enters its context window, even though Claude only needs a summary of error frequencies. When fetching customer data across multiple tables, every record accumulates in context regardless of relevance. These intermediate results consume massive token budgets and can push important information out of the context window entirely.&lt;/item&gt;
      &lt;item&gt;Inference overhead and manual synthesis: Each tool call requires a full model inference pass. After receiving results, Claude must "eyeball" the data to extract relevant information, reason about how pieces fit together, and decide what to do next‚Äîall through natural language processing. A five tool workflow means five inference passes plus Claude parsing each result, comparing values, and synthesizing conclusions. This is both slow and error-prone.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Our solution&lt;/head&gt;
    &lt;p&gt;Programmatic Tool Calling enables Claude to orchestrate tools through code rather than through individual API round-trips. Instead of Claude requesting tools one at a time with each result being returned to its context, Claude writes code that calls multiple tools, processes their outputs, and controls what information actually enters its context window.&lt;/p&gt;
    &lt;p&gt;Claude excels at writing code and by letting it express orchestration logic in Python rather than through natural language tool invocations, you get more reliable, precise control flow. Loops, conditionals, data transformations, and error handling are all explicit in code rather than implicit in Claude's reasoning.&lt;/p&gt;
    &lt;head rend="h4"&gt;Example: Budget compliance check&lt;/head&gt;
    &lt;p&gt;Consider a common business task: "Which team members exceeded their Q3 travel budget?"&lt;/p&gt;
    &lt;p&gt;You have three tools available:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;get_team_members(department)&lt;/code&gt;- Returns team member list with IDs and levels&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_expenses(user_id, quarter)&lt;/code&gt;- Returns expense line items for a user&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_budget_by_level(level)&lt;/code&gt;- Returns budget limits for an employee level&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Traditional approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fetch team members ‚Üí 20 people&lt;/item&gt;
      &lt;item&gt;For each person, fetch their Q3 expenses ‚Üí 20 tool calls, each returning 50-100 line items (flights, hotels, meals, receipts)&lt;/item&gt;
      &lt;item&gt;Fetch budget limits by employee level&lt;/item&gt;
      &lt;item&gt;All of this enters Claude's context: 2,000+ expense line items (50 KB+)&lt;/item&gt;
      &lt;item&gt;Claude manually sums each person's expenses, looks up their budget, compares expenses against budget limits&lt;/item&gt;
      &lt;item&gt;More round-trips to the model, significant context consumption&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With Programmatic Tool Calling:&lt;/p&gt;
    &lt;p&gt;Instead of each tool result returning to Claude, Claude writes a Python script that orchestrates the entire workflow. The script runs in the Code Execution tool (a sandboxed environment), pausing when it needs results from your tools. When you return tool results via the API, they're processed by the script rather than consumed by the model. The script continues executing, and Claude only sees the final output.&lt;/p&gt;
    &lt;p&gt;Here's what Claude's orchestration code looks like for the budget compliance task:&lt;/p&gt;
    &lt;code&gt;team = await get_team_members("engineering")

# Fetch budgets for each unique level
levels = list(set(m["level"] for m in team))
budget_results = await asyncio.gather(*[
    get_budget_by_level(level) for level in levels
])

# Create a lookup dictionary: {"junior": budget1, "senior": budget2, ...}
budgets = {level: budget for level, budget in zip(levels, budget_results)}

# Fetch all expenses in parallel
expenses = await asyncio.gather(*[
    get_expenses(m["id"], "Q3") for m in team
])

# Find employees who exceeded their travel budget
exceeded = []
for member, exp in zip(team, expenses):
    budget = budgets[member["level"]]
    total = sum(e["amount"] for e in exp)
    if total &amp;gt; budget["travel_limit"]:
        exceeded.append({
            "name": member["name"],
            "spent": total,
            "limit": budget["travel_limit"]
        })

print(json.dumps(exceeded))&lt;/code&gt;
    &lt;p&gt;Claude's context receives only the final result: the two to three people who exceeded their budget. The 2,000+ line items, the intermediate sums, and the budget lookups do not affect Claude‚Äôs context, reducing consumption from 200KB of raw expense data to just 1KB of results.&lt;/p&gt;
    &lt;p&gt;The efficiency gains are substantial:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Token savings: By keeping intermediate results out of Claude's context, PTC dramatically reduces token consumption. Average usage dropped from 43,588 to 27,297 tokens, a 37% reduction on complex research tasks.&lt;/item&gt;
      &lt;item&gt;Reduced latency: Each API round-trip requires model inference (hundreds of milliseconds to seconds). When Claude orchestrates 20+ tool calls in a single code block, you eliminate 19+ inference passes. The API handles tool execution without returning to the model each time.&lt;/item&gt;
      &lt;item&gt;Improved accuracy: By writing explicit orchestration logic, Claude makes fewer errors than when juggling multiple tool results in natural language. Internal knowledge retrieval improved from 25.6% to 28.5%; GIA benchmarks from 46.5% to 51.2%.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Production workflows involve messy data, conditional logic, and operations that need to scale. Programmatic Tool Calling lets Claude handle that complexity programmatically while keeping its focus on actionable results rather than raw data processing.&lt;/p&gt;
    &lt;head rend="h3"&gt;How Programmatic Tool Calling works&lt;/head&gt;
    &lt;head rend="h4"&gt;1. Mark tools as callable from code&lt;/head&gt;
    &lt;p&gt;Add code_execution to tools, and set allowed_callers to opt-in tools for programmatic execution:&lt;/p&gt;
    &lt;code&gt;{
  "tools": [
    {
      "type": "code_execution_20250825",
      "name": "code_execution"
    },
    {
      "name": "get_team_members",
      "description": "Get all members of a department...",
      "input_schema": {...},
      "allowed_callers": ["code_execution_20250825"] # opt-in to programmatic tool calling
    },
    {
      "name": "get_expenses",
 	...
    },
    {
      "name": "get_budget_by_level",
	...
    }
  ]
}&lt;/code&gt;
    &lt;p&gt;The API converts these tool definitions into Python functions that Claude can call.&lt;/p&gt;
    &lt;head rend="h4"&gt;2. Claude writes orchestration code&lt;/head&gt;
    &lt;p&gt;Instead of requesting tools one at a time, Claude generates Python code:&lt;/p&gt;
    &lt;code&gt;{
  "type": "server_tool_use",
  "id": "srvtoolu_abc",
  "name": "code_execution",
  "input": {
    "code": "team = get_team_members('engineering')\n..." # the code example above
  }
}&lt;/code&gt;
    &lt;head rend="h4"&gt;3. Tools execute without hitting Claude's context&lt;/head&gt;
    &lt;p&gt;When the code calls get_expenses(), you receive a tool request with a caller field:&lt;/p&gt;
    &lt;code&gt;{
  "type": "tool_use",
  "id": "toolu_xyz",
  "name": "get_expenses",
  "input": {"user_id": "emp_123", "quarter": "Q3"},
  "caller": {
    "type": "code_execution_20250825",
    "tool_id": "srvtoolu_abc"
  }
}&lt;/code&gt;
    &lt;p&gt;You provide the result, which is processed in the Code Execution environment rather than Claude's context. This request-response cycle repeats for each tool call in the code.&lt;/p&gt;
    &lt;head rend="h4"&gt;4. Only final output enters context&lt;/head&gt;
    &lt;p&gt;When the code finishes running, only the results of the code are returned to Claude:&lt;/p&gt;
    &lt;code&gt;{
  "type": "code_execution_tool_result",
  "tool_use_id": "srvtoolu_abc",
  "content": {
    "stdout": "[{\"name\": \"Alice\", \"spent\": 12500, \"limit\": 10000}...]"
  }
}&lt;/code&gt;
    &lt;p&gt;This is all Claude sees, not the 2000+ expense line items processed along the way.&lt;/p&gt;
    &lt;head rend="h3"&gt;When to use Programmatic Tool Calling&lt;/head&gt;
    &lt;p&gt;Programmatic Tool Calling adds a code execution step to your workflow. This extra overhead pays off when the token savings, latency improvements, and accuracy gains are substantial.&lt;/p&gt;
    &lt;p&gt;Most beneficial when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Processing large datasets where you only need aggregates or summaries&lt;/item&gt;
      &lt;item&gt;Running multi-step workflows with three or more dependent tool calls&lt;/item&gt;
      &lt;item&gt;Filtering, sorting, or transforming tool results before Claude sees them&lt;/item&gt;
      &lt;item&gt;Handling tasks where intermediate data shouldn't influence Claude's reasoning&lt;/item&gt;
      &lt;item&gt;Running parallel operations across many items (checking 50 endpoints, for example)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Less beneficial when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Making simple single-tool invocations&lt;/item&gt;
      &lt;item&gt;Working on tasks where Claude should see and reason about all intermediate results&lt;/item&gt;
      &lt;item&gt;Running quick lookups with small responses&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Tool Use Examples&lt;/head&gt;
    &lt;head rend="h3"&gt;The challenge&lt;/head&gt;
    &lt;p&gt;JSON Schema excels at defining structure‚Äìtypes, required fields, allowed enums‚Äìbut it can't express usage patterns: when to include optional parameters, which combinations make sense, or what conventions your API expects.&lt;/p&gt;
    &lt;p&gt;Consider a support ticket API:&lt;/p&gt;
    &lt;code&gt;{
  "name": "create_ticket",
  "input_schema": {
    "properties": {
      "title": {"type": "string"},
      "priority": {"enum": ["low", "medium", "high", "critical"]},
      "labels": {"type": "array", "items": {"type": "string"}},
      "reporter": {
        "type": "object",
        "properties": {
          "id": {"type": "string"},
          "name": {"type": "string"},
          "contact": {
            "type": "object",
            "properties": {
              "email": {"type": "string"},
              "phone": {"type": "string"}
            }
          }
        }
      },
      "due_date": {"type": "string"},
      "escalation": {
        "type": "object",
        "properties": {
          "level": {"type": "integer"},
          "notify_manager": {"type": "boolean"},
          "sla_hours": {"type": "integer"}
        }
      }
    },
    "required": ["title"]
  }
}&lt;/code&gt;
    &lt;p&gt;The schema defines what's valid, but leaves critical questions unanswered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Format ambiguity: Should &lt;code&gt;due_date&lt;/code&gt;use "2024-11-06", "Nov 6, 2024", or "2024-11-06T00:00:00Z"?&lt;/item&gt;
      &lt;item&gt;ID conventions: Is &lt;code&gt;reporter.id&lt;/code&gt;a UUID, "USR-12345", or just "12345"?&lt;/item&gt;
      &lt;item&gt;Nested structure usage: When should Claude populate &lt;code&gt;reporter.contact&lt;/code&gt;?&lt;/item&gt;
      &lt;item&gt;Parameter correlations: How do &lt;code&gt;escalation.level&lt;/code&gt;and&lt;code&gt;escalation.sla_hours&lt;/code&gt;relate to priority?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These ambiguities can lead to malformed tool calls and inconsistent parameter usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Our solution&lt;/head&gt;
    &lt;p&gt;Tool Use Examples let you provide sample tool calls directly in your tool definitions. Instead of relying on schema alone, you show Claude concrete usage patterns:&lt;/p&gt;
    &lt;code&gt;{
    "name": "create_ticket",
    "input_schema": { /* same schema as above */ },
    "input_examples": [
      {
        "title": "Login page returns 500 error",
        "priority": "critical",
        "labels": ["bug", "authentication", "production"],
        "reporter": {
          "id": "USR-12345",
          "name": "Jane Smith",
          "contact": {
            "email": "jane@acme.com",
            "phone": "+1-555-0123"
          }
        },
        "due_date": "2024-11-06",
        "escalation": {
          "level": 2,
          "notify_manager": true,
          "sla_hours": 4
        }
      },
      {
        "title": "Add dark mode support",
        "labels": ["feature-request", "ui"],
        "reporter": {
          "id": "USR-67890",
          "name": "Alex Chen"
        }
      },
      {
        "title": "Update API documentation"
      }
    ]
  }&lt;/code&gt;
    &lt;p&gt;From these three examples, Claude learns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Format conventions: Dates use YYYY-MM-DD, user IDs follow USR-XXXXX, labels use kebab-case&lt;/item&gt;
      &lt;item&gt;Nested structure patterns: How to construct the reporter object with its nested contact object&lt;/item&gt;
      &lt;item&gt;Optional parameter correlations: Critical bugs have full contact info + escalation with tight SLAs; feature requests have reporter but no contact/escalation; internal tasks have title only&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In our own internal testing, tool use examples improved accuracy from 72% to 90% on complex parameter handling.&lt;/p&gt;
    &lt;head rend="h3"&gt;When to use Tool Use Examples&lt;/head&gt;
    &lt;p&gt;Tool Use Examples add tokens to your tool definitions, so they‚Äôre most valuable when accuracy improvements outweigh the additional cost.&lt;/p&gt;
    &lt;p&gt;Most beneficial when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complex nested structures where valid JSON doesn't imply correct usage&lt;/item&gt;
      &lt;item&gt;Tools with many optional parameters and inclusion patterns matter&lt;/item&gt;
      &lt;item&gt;APIs with domain-specific conventions not captured in schemas&lt;/item&gt;
      &lt;item&gt;Similar tools where examples clarify which one to use (e.g., &lt;code&gt;create_ticket&lt;/code&gt;vs&lt;code&gt;create_incident&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Less beneficial when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple single-parameter tools with obvious usage&lt;/item&gt;
      &lt;item&gt;Standard formats like URLs or emails that Claude already understands&lt;/item&gt;
      &lt;item&gt;Validation concerns better handled by JSON Schema constraints&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Best practices&lt;/head&gt;
    &lt;p&gt;Building agents that take real-world actions means handling scale, complexity, and precision simultaneously. These three features work together to solve different bottlenecks in tool use workflows. Here's how to combine them effectively.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer features strategically&lt;/head&gt;
    &lt;p&gt;Not every agent needs to use all three features for a given task. Start with your biggest bottleneck:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Context bloat from tool definitions ‚Üí Tool Search Tool&lt;/item&gt;
      &lt;item&gt;Large intermediate results polluting context ‚Üí Programmatic Tool Calling&lt;/item&gt;
      &lt;item&gt;Parameter errors and malformed calls ‚Üí Tool Use Examples&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This focused approach lets you address the specific constraint limiting your agent's performance, rather than adding complexity upfront.&lt;/p&gt;
    &lt;p&gt;Then layer additional features as needed. They're complementary: Tool Search Tool ensures the right tools are found, Programmatic Tool Calling ensures efficient execution, and Tool Use Examples ensure correct invocation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Set up Tool Search Tool for better discovery&lt;/head&gt;
    &lt;p&gt;Tool search matches against names and descriptions, so clear, descriptive definitions improve discovery accuracy.&lt;/p&gt;
    &lt;code&gt;// Good
{
    "name": "search_customer_orders",
    "description": "Search for customer orders by date range, status, or total amount. Returns order details including items, shipping, and payment info."
}

// Bad
{
    "name": "query_db_orders",
    "description": "Execute order query"
}&lt;/code&gt;
    &lt;p&gt;Add system prompt guidance so Claude knows what's available:&lt;/p&gt;
    &lt;code&gt;You have access to tools for Slack messaging, Google Drive file management, 
Jira ticket tracking, and GitHub repository operations. Use the tool search 
to find specific capabilities.&lt;/code&gt;
    &lt;p&gt;Keep your three to five most-used tools always loaded, defer the rest. This balances immediate access for common operations with on-demand discovery for everything else.&lt;/p&gt;
    &lt;head rend="h3"&gt;Set up Programmatic Tool Calling for correct execution&lt;/head&gt;
    &lt;p&gt;Since Claude writes code to parse tool outputs, document return formats clearly. This helps Claude write correct parsing logic:&lt;/p&gt;
    &lt;code&gt;{
    "name": "get_orders",
    "description": "Retrieve orders for a customer.
Returns:
    List of order objects, each containing:
    - id (str): Order identifier
    - total (float): Order total in USD
    - status (str): One of 'pending', 'shipped', 'delivered'
    - items (list): Array of {sku, quantity, price}
    - created_at (str): ISO 8601 timestamp"
}&lt;/code&gt;
    &lt;p&gt;See below for opt-in tools that benefit from programmatic orchestration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tools that can run in parallel (independent operations)&lt;/item&gt;
      &lt;item&gt;Operations safe to retry (idempotent)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Set up Tool Use Examples for parameter accuracy&lt;/head&gt;
    &lt;p&gt;Craft examples for behavioral clarity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use realistic data (real city names, plausible prices, not "string" or "value")&lt;/item&gt;
      &lt;item&gt;Show variety with minimal, partial, and full specification patterns&lt;/item&gt;
      &lt;item&gt;Keep it concise: 1-5 examples per tool&lt;/item&gt;
      &lt;item&gt;Focus on ambiguity (only add examples where correct usage isn't obvious from schema)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;These features are available in beta. To enable them, add the beta header and include the tools you need:&lt;/p&gt;
    &lt;code&gt;client.beta.messages.create(
    betas=["advanced-tool-use-2025-11-20"],
    model="claude-sonnet-4-5-20250929",
    max_tokens=4096,
    tools=[
        {"type": "tool_search_tool_regex_20251119", "name": "tool_search_tool_regex"},
        {"type": "code_execution_20250825", "name": "code_execution"},
        # Your tools with defer_loading, allowed_callers, and input_examples
    ]
)&lt;/code&gt;
    &lt;p&gt;For detailed API documentation and SDK examples, see our:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation and cookbook for Tool Search Tool&lt;/item&gt;
      &lt;item&gt;Documentation and cookbook for Programmatic Tool Calling&lt;/item&gt;
      &lt;item&gt;Documentation for Tool Use Examples&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These features move tool use from simple function calling toward intelligent orchestration. As agents tackle more complex workflows spanning dozens of tools and large datasets, dynamic discovery, efficient execution, and reliable invocation become foundational.&lt;/p&gt;
    &lt;p&gt;We're excited to see what you build.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Written by Bin Wu, with contributions from Adam Jones, Artur Renault, Henry Tay, Jake Noble, Nathan McCandlish, Noah Picard, Sam Jiang, and the Claude Developer Platform team. This work builds on foundational research by Chris Gorgolewski, Daniel Jiang, Jeremy Fox and Mike Lambert. We also drew inspiration from across the AI ecosystem, including Joel Pobar's LLMVM, Cloudflare's Code Mode and Code Execution as MCP. Special thanks to Andy Schumeister, Hamish Kerr, Keir Bradwell, Matt Bleifer and Molly Vorwerck for their support.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/engineering/advanced-tool-use"/><published>2025-11-24T19:21:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46038099</id><title>Unpowered SSDs slowly lose data</title><updated>2025-11-25T16:49:11.469086+00:00</updated><content>&lt;doc fingerprint="3653bc3789b28fb8"&gt;
  &lt;main&gt;
    &lt;p&gt;SSDs have all but replaced hard drives when it comes to primary storage. They're orders of magnitude faster, more convenient, and consume less power than mechanical hard drives. That said, if you're also using SSDs for cold storage, expecting the drives lying in your drawer to work perfectly after years, you might want to rethink your strategy. Your reliable SSD could suffer from corrupted or lost data if left unpowered for extended periods. This is why many users don't consider SSDs a reliable long-term storage medium, and prefer using hard drives, magnetic tape, or M-Disc instead.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your SSD data isn't as permanent as you think&lt;/head&gt;
    &lt;head rend="h3"&gt;Non-volatile with an asterisk&lt;/head&gt;
    &lt;p&gt;Unlike hard drives that magnetize spinning discs to store data, SSDs modify the electrical charge in NAND flash cells to represent 0 and 1. NAND flash retains data in underlying transistors even when power is removed, similar to other forms of non-volatile memory. However, the duration for which your SSD can retain data without power is the key here. Even the cheapest SSDs, say those with QLC NAND, can safely store data for about a year of being completely unpowered. More expensive TLC NAND can retain data for up to 3 years, while MLC and SLC NAND are good for 5 years and 10 years of unpowered storage, respectively.&lt;/p&gt;
    &lt;p&gt;The problem is that most consumer SSDs use only TLC or QLC NAND, so users who leave their SSDs unpowered for over a year are risking the integrity of their data. The reliability of QLC NAND has improved over the years, so you should probably consider 2‚Äì3 years of unpowered usage as the guardrails. Without power, the voltage stored in the NAND cells can be lost, either resulting in missing data or completely useless drives.&lt;/p&gt;
    &lt;p&gt;This data retention deficiency of consumer SSDs makes them an unreliable medium for long-term data storage, especially for creative professionals and researchers. HDDs can suffer from bit rot, too, due to wear and tear, but they're still more resistant to power loss. If you haven't checked your archives in a while, I'd recommend doing so at the earliest.&lt;/p&gt;
    &lt;head rend="h2"&gt;But, most people don't need to worry about it&lt;/head&gt;
    &lt;head rend="h3"&gt;Archival storage isn't that common&lt;/head&gt;
    &lt;p&gt;The scenario I described above isn't relevant to people outside enterprise, enthusiast, and solopreneur usage. The need to store tons of data for years on drives that aren't plugged in isn't a concern for most people, who use one or two SSDs on their PC that might be left without power for only a few months, at the maximum. You've probably lost data on your SSD due to a rare power surge or a faulty drive rather than voltage loss. Some factors, like temperature and the quality of the underlying NAND flash, can accelerate this voltage loss.&lt;/p&gt;
    &lt;p&gt;SSDs aren't eternal, even if you keep them powered on forever. The limited write cycles of NAND flash will eventually bring an SSD to the end of its lifecycle, but the majority of users will probably replace the drive before that ever happens. So, you don't need to worry about writing too much data to your SSD or leaving your PC turned off for days, weeks, or even months. Just don't trust an unpowered SSD that's gathering dust in the house for years, which brings me to my next point.&lt;/p&gt;
    &lt;head rend="h2"&gt;You should always have a backup anyway&lt;/head&gt;
    &lt;head rend="h3"&gt;Prevention is better than cure&lt;/head&gt;
    &lt;p&gt;Backing up your data is the simplest strategy to counteract the limitations of storage media. Having multiple copies of your data on different types of storage ensures that any unexpected incidents protect your data from vanishing forever. This is exactly what the 3-2-1 backup rule talks about: 3 copies of data on at least 2 different storage media, with 1 copy stored off-site. For most people, this condition can easily be fulfilled by using their primary computer, a NAS, and cloud storage. Redundancy is the underlying principle that safeguards your data.&lt;/p&gt;
    &lt;p&gt;Whether it's the limited lifespan of your SSD, the potential for harmful exigencies like power failure, or the limits of data retention on flash storage, your backup will ensure your peace of mind. Yes, SSDs aren't the best choice for cold storage, but even if you're using hard drives, having a single copy of your data is asking for trouble. Every user will come face-to-face with drive failure sooner or later, so investing in a robust backup system isn't really optional if you care about your data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Store it and forget it doesn't work for SSDs&lt;/head&gt;
    &lt;p&gt;As long as you're using consumer SSDs for primary storage on your PC, it's all well and good. You'll most likely replace your drive long before exhausting its P/E cycles. For long-term storage, however, relying on SSDs is risky, since they can lose data if left without power for years. This data loss can occur anytime from 1 to 3 years of keeping your SSDs unpowered, so using alternate storage media and investing in a backup system should be your priorities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.xda-developers.com/your-unpowered-ssd-is-slowly-losing-your-data/"/><published>2025-11-24T19:25:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46042655</id><title>Windows GUI ‚Äì Good, Bad and Pretty Ugly (2023)</title><updated>2025-11-25T16:49:10.067411+00:00</updated><content>&lt;doc fingerprint="149ee97fbfa67cd6"&gt;
  &lt;main&gt;
    &lt;p&gt;Windows launched way back in 1985, when I was still using a Commodore 64 and PCs were all of four years old‚Äìbarely out of diapers. The GUI or Graphical User Interface, has changed a lot over the years and I thought it might be fun/horrifying to rank every major version of the Windows GUI, from Windows 1.0 in 1985, to Windows 11 as of 2023.&lt;/p&gt;
    &lt;p&gt;I‚Äôm rating not based on how the system looked at the time (you can do only do so much with CGA/EGA graphics, after all), but how they look now. Is this fair? Probably not, but as always, I make the rules!&lt;/p&gt;
    &lt;p&gt;The rating system is based on a scale of 1 to 10 Clippys, with 10 being best.&lt;/p&gt;
    &lt;quote&gt;NOTE: I am skipping over all versions of Windows NT because it follows the look of other versions mentioned below.&lt;/quote&gt;
    &lt;p&gt;Overall Rankings:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Windows 11&lt;/item&gt;
      &lt;item&gt;Windows 2000&lt;/item&gt;
      &lt;item&gt;Windows 95/98/Vista/7&lt;/item&gt;
      &lt;item&gt;Windows 10&lt;/item&gt;
      &lt;item&gt;Windows 3.0/3.1/XP&lt;/item&gt;
      &lt;item&gt;Windows 8.1&lt;/item&gt;
      &lt;item&gt;Windows 8&lt;/item&gt;
      &lt;item&gt;Windows 2.0&lt;/item&gt;
      &lt;item&gt;Windows 1.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Windows 1.0 (1985)&lt;lb/&gt;Rating: 1 Clippy&lt;/p&gt;
    &lt;p&gt;In 1985, Windows ran on top of DOS, had drop-down menus, fixed windows, and CGA graphics. In a way, the extremely limited colour palette actually made it more colourful. Perhaps too colourful. This is pretty ugly all around. If you are a fan of this, you probably wear plaid bow ties unironically.&lt;/p&gt;
    &lt;p&gt;Windows 2.0 (1987)&lt;lb/&gt;Rating: 2.5 Clippys&lt;/p&gt;
    &lt;p&gt;This is where Windows goes from hideously ugly to just unattractive. The menu bars and arrows have been refined a little, and now you get resizable windows. It‚Äôs like a colour Macintosh, but hit with an ugly stick. And still needs to run on top of DOS.&lt;/p&gt;
    &lt;p&gt;Windows 3.0 (1990)&lt;lb/&gt;Rating: 6 Clippys&lt;/p&gt;
    &lt;p&gt;Microsoft makes a big leap with Windows 3, the first version to offer a coherent GUI, with pseudo 3D elements for buttons and scroll bars. Support for VGA graphics also means the cartoony look has gone away, making it look that more professional. It still needs DOS and has that weird File Manager/Program Manager split. Oh, and Minesweeper.&lt;/p&gt;
    &lt;p&gt;Windows 3.1 (1992)&lt;lb/&gt;Rating 6 Clippys&lt;/p&gt;
    &lt;p&gt;Windows hits the big time. This is the version where it was clear Windows was the future and DOS was the past. Windows 3.1 actually doesn‚Äôt look much different than 3.0, though, so it rates the same.&lt;/p&gt;
    &lt;p&gt;Windows 95 (1995)&lt;lb/&gt;Rating: 7.5 Clippys&lt;/p&gt;
    &lt;p&gt;With Windows 95, Microsoft managed to produce a version of its OS that scared Apple so much they ended up bringing Steve Jobs back, along with his own operating system, NeXTSTEP. Windows 95 introduced the taskbar, the Start button (it‚Äôs even labelled Start, how quaint!), a proper desktop and a continued refinement with the 3D bevelled look. The GUI is also simplified in some ways, with the title bar widgets all getting moved to the top-right corner. Icons are more detailed and colours are overall more subdued.&lt;/p&gt;
    &lt;p&gt;While it looks dated to our 2023 eyes, this GUI remains just as clear and functional today as it was 28 (!) years ago.&lt;/p&gt;
    &lt;p&gt;Windows 98 (1998)&lt;lb/&gt;Rating: 7.5 Clippys&lt;/p&gt;
    &lt;p&gt;Windows 98 basically looks the same as Windows 95, but Microsoft did add a stylin‚Äô gradient effect to title bars. It‚Äôs not enough to change its rating over 95, though. Sorry, MS!&lt;/p&gt;
    &lt;p&gt;Note: I am skipping Windows Millennium Edition (Me) because while it had changes under the hood, visually it is pretty much Windows 98 Third Edition.&lt;/p&gt;
    &lt;p&gt;Windows 2000 (2000)&lt;lb/&gt;Rating: 8 Clippys&lt;/p&gt;
    &lt;p&gt;I admit bias here. First, this is essentially a version of Windows NT, which I said I wouldn‚Äôt be rating. Second, it really just brings the 95/98 look to the NT version of Windows. But this was the first version of Windows that tried to bridge the gap between consumer and business versions‚Äìand it mostly worked (if you could get it at a discount, like I did at the time). I give it a slight edge because they changed some of the icons, improving them, in my view. It also had a generally more sophisticated veneer‚Äìthe last version of Windows to really use this approach for many years.&lt;/p&gt;
    &lt;p&gt;Windows XP (2001)&lt;lb/&gt;Rating: 6 Clippys&lt;/p&gt;
    &lt;p&gt;Our first regression! Windows XP gave us a pretty wallpaper (probably the most famous OS wallpaper ever) and there‚Äôs something I find pleasing about the look of its buttons and most of its icons. The bevelled look, combined with much brighter colours, though, gives the OS a decidedly less serious look. I‚Äôm not sure what Microsoft was going for, but I don‚Äôt think ‚Äúcartoony‚Äù is what they had in mind. Not a total disaster or anything, but kind of goofy-looking in hindsight.&lt;/p&gt;
    &lt;p&gt;Windows Vista (2006)&lt;lb/&gt;Rating: 7.5 Clippys&lt;/p&gt;
    &lt;p&gt;With Vista, Microsoft sought to strip away the bright, simple colours of XP in favour of a glossy 3D sheen. For the most part, I think it works, though transparency does get a bit out of hand at times. I like how the Start button now looks more like a button. Icons are cleaner and more detailed. This is Microsoft saying Windows is all grown up now. Too bad about all the driver issues and steep system requirements.&lt;/p&gt;
    &lt;p&gt;Windows 7 (2009)&lt;lb/&gt;Rating: 7.5 Clippys &lt;/p&gt;
    &lt;p&gt;As you can see, Windows 7 is pretty much Vista, but with the transparency toned down. This is welcome, but it‚Äôs not enough to change its rating over Vista.&lt;/p&gt;
    &lt;p&gt;Windows 8 (2012)&lt;lb/&gt;Rating: 5 Clippys&lt;/p&gt;
    &lt;p&gt;And here we have a major step back. Microsoft somehow thought that in 2012 everyone would be using tablets with swipe gestures, and designed Windows 8‚Äôs GUI around this. They also elected to do away with finely-detailed icons in favour of simple, single-colour tiles and widgets. But the tiles could be one of many colours (and sizes), so you ended up with a crazy quilt look (see the screenshot below for a representative example). They got rid of the Start menu and the Start button. This is ugly. If you like Windows 8‚Äôs look, you are a bad person. You are the one Steve Jobs was talking about when he said Microsoft had no taste.&lt;/p&gt;
    &lt;p&gt;Windows 8.1 (2013)&lt;lb/&gt;Rating: 5.5 Clippys&lt;/p&gt;
    &lt;p&gt;Windows 8.1 made some changes, such as adding back the Start button and including the option to boot to the desktop, but the GUI was mostly the same, and just as ugly.&lt;/p&gt;
    &lt;p&gt;Windows 10 (2015)&lt;lb/&gt;Rating: 6.5 Clippys&lt;/p&gt;
    &lt;p&gt;Windows 10‚Äôs main mission was to undo Windows 8. It brought back the Start menu, it made the desktop the central part of the UI again, and it tamed some of the tile experience, though the flat look still persisted. This frankenOS approach means it feels like a cross between Windows 7 and 8. It‚Äôs not bad, but it‚Äôs also clearly the result of yanking the Windows GUI off in a new and unplanned direction.&lt;/p&gt;
    &lt;p&gt;Windows 11 (2021)&lt;lb/&gt;Rating: 8 Clippys&lt;/p&gt;
    &lt;p&gt;There are things to critique about Windows 11‚Äìits security requirements, the all but mandatory MS account, a push toward oversimplification of the Start menu. But in terms of GUI, this is probably the most refined the OS has been since 2000. It also restores a cohesion to the look of the OS that had been missing since Windows 7 in 2009. Sure, it‚Äôs clearly aping macOS in some ways, like the rounded corners on windows, but everything looks very clean. I actually would give this version the nod, aesthetically, over the current version of macOS (Monterey as I write this)‚Äìthough not by a lot. The biggest knocks are its lack of customization (in some regards), removal of features (the taskbar can no longer be moved to other edges of the screen) and Microsoft‚Äôs annoying habit of adding more intrusive bloatware, pop-ups and other distractions. Looks-wise, though, it‚Äôs pretty nice!&lt;/p&gt;
    &lt;p&gt;Overall, the versions I feel Microsoft got right (and iterated on) were:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows 3.0&lt;/item&gt;
      &lt;item&gt;Windows 95&lt;/item&gt;
      &lt;item&gt;Windows Vista&lt;/item&gt;
      &lt;item&gt;Windows 11&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The ones that struck out were:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows XP&lt;/item&gt;
      &lt;item&gt;Windows 8&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The early versions (1.0 and 2.0) were hamstrung by the technology at the time, while Windows 10 had to pick up the pieces from Windows 8.&lt;/p&gt;
    &lt;p&gt;Rumours say Microsoft is working on Windows 12. If so, I wouldn‚Äôt expect it to depart visually from Windows 11, but you never know.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://creolened.com/windows-gui-good-bad-and-pretty-ugly-ranked/"/><published>2025-11-25T05:33:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46042928</id><title>Human brains are preconfigured with instructions for understanding the world</title><updated>2025-11-25T16:49:09.672385+00:00</updated><content>&lt;doc fingerprint="230b53ace9f3ddab"&gt;
  &lt;main&gt;
    &lt;p&gt;Health&lt;/p&gt;
    &lt;head rend="h1"&gt;Evidence suggests early developing human brains are preconfigured with instructions for understanding the world&lt;/head&gt;
    &lt;p&gt;Assistant Professor of Biomolecular Engineering Tal Sharf‚Äôs lab used organoids to make fundamental discoveries about human brain development.&lt;/p&gt;
    &lt;head rend="h2"&gt;Press Contact&lt;/head&gt;
    &lt;head rend="h2"&gt;Key takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New findings suggest the brain has preconfigured, structured activity patterns even before sensory experiences occur.&lt;/item&gt;
      &lt;item&gt;UC Santa Cruz researchers used brain organoids to study the brain‚Äôs earliest electrical activity.&lt;/item&gt;
      &lt;item&gt;Understanding early brain patterns could have important implications for diagnosing and treating developmental brain disorders.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Humans have long wondered when and how we begin to form thoughts. Are we born with a pre-configured brain, or do thought patterns only begin to emerge in response to our sensory experiences of the world around us? Now, science is getting closer to answering the questions philosophers have pondered for centuries.&lt;/p&gt;
    &lt;p&gt;Researchers at the University of California, Santa Cruz, are using tiny models of human brain tissue, called organoids, to study the earliest moments of electrical activity in the brain. A new study in Nature Neuroscience finds that the earliest firings of the brain occur in structured patterns without any external experiences, suggesting that the human brain is preconfigured with instructions about how to navigate and interact with the world.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese cells are clearly interacting with each other and forming circuits that self-assemble before we can experience anything from the outside world,‚Äù said Tal Sharf, assistant professor of biomolecular engineering at the Baskin School of Engineering and the study‚Äôs senior author. ‚ÄúThere‚Äôs an operating system that exists, that emerges in a primordial state. In my laboratory, we grow brain organoids to peer into this primordial version of the brain‚Äôs operating system and study how the brain builds itself before it‚Äôs shaped by sensory experience.‚Äù&lt;/p&gt;
    &lt;p&gt;In improving our fundamental understanding of human brain development, these findings can help researchers better understand neurodevelopmental disorders, and pinpoint the impact of toxins like pesticides and microplastics in the developing brain.&lt;/p&gt;
    &lt;head rend="h4"&gt;Studying the developing brain&lt;/head&gt;
    &lt;p&gt;The brain, similar to a computer, runs on electrical signals‚Äîthe firing of neurons. When these signals begin to fire, and how the human brain develops, are challenging topics for scientists to study, as the early developing human brain is protected within the womb.&lt;/p&gt;
    &lt;p&gt;Organoids, which are 3D models of tissue grown from human stem cells in the lab, provide a unique window into brain development. The Braingeneers group at UC Santa Cruz, in collaboration with researchers at UC San Francisco and UC Santa Barbara, are pioneering methods to grow these models and take measurements from them to gain insights into brain development and disorders.&lt;/p&gt;
    &lt;p&gt;Organoids are particularly useful for understanding if the brain develops in response to sensory input‚Äîas they exist in the lab setting and not the body‚Äîand can be grown ethically in large quantities. In this study, researchers prompted stem cells to form brain tissue, and then measured their electrical activity using specialized microchips, similar to those that run a computer. Sharf‚Äôs background in both applied physics, computation, and neurobiology form his expertise in modelling the circuitry of the early brain.&lt;/p&gt;
    &lt;p&gt;‚ÄúAn organoid system that‚Äôs intrinsically decoupled from any sensory input or communication with organs gives you a window into what‚Äôs happening with this self-assembly process,‚Äù Sharf said. ‚ÄúThat self-assembly process is really hard to do with traditional 2D cell culture‚Äîyou can‚Äôt get the cell diversity and the architecture. The cells need to be in intimate contact with each other. We‚Äôre trying to control the initial conditions, so we can let biology do its wonderful thing.‚Äù&lt;/p&gt;
    &lt;p&gt;The Sharf lab is developing novel neural interfaces, leveraging expertise in physics, materials science, and electrical engineering. On the right, Koushik Devarajan, an electrical and computer engineering Ph.D. student in the Sharf lab.&lt;/p&gt;
    &lt;head rend="h4"&gt;Pattern production&lt;/head&gt;
    &lt;p&gt;The researchers observed the electrical activity of the brain tissue as they self-assembled from stem cells into a tissue that can translate the senses and produce language and conscious thought. They found that within the first few months of development, long before the human brain is capable of receiving and processing complex external sensory information such as vision and hearing, its cells spontaneously began to emit electrical signals characteristic of the patterns that underlie translation of the senses.&lt;/p&gt;
    &lt;p&gt;Through decades of neuroscience research, the community has discovered that neurons fire in patterns that aren‚Äôt just random. Instead, the brain has a ‚Äúdefault mode‚Äù ‚Äî a basic underlying structure for firing neurons which then becomes more specific as the brain processes unique signals like a smell or taste. This background mode outlines the possible range of sensory responses the body and brain can produce.&lt;/p&gt;
    &lt;p&gt;In their observations of single neuron spikes in the self-assembling organoid models, Sharf and colleagues found that these earliest observable patterns have striking similarity with the brain‚Äôs default mode. Even without having received any sensory input, they are firing off a complex repertoire of time-based patterns, or sequences, which have the potential to be refined for specific senses, hinting at a genetically encoded blueprint inherent to the neural architecture of the living brain.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese intrinsically self-organized systems could serve as a basis for constructing a representation of the world around us,‚Äù Sharf said. ‚ÄúThe fact that we can see them in these early stages suggests that evolution has figured out a way that the central nervous system can construct a map that would allow us to navigate and interact with the world.‚Äù&lt;/p&gt;
    &lt;p&gt;Knowing that these organoids produce the basic structure of the living brain opens up a range of possibilities for better understanding human neurodevelopment, disease, and the effects of toxins in the brain.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe‚Äôre showing that there is a basis for capturing complex dynamics that likely could be signatures of pathological onsets that we could study in human tissue,‚Äù Sharf said. ‚ÄúThat would allow us to develop therapies, working with clinicians at the preclinical level to potentially develop compounds, drug therapies, and gene editing tools that could be cheaper, more efficient, higher throughput.‚Äù&lt;/p&gt;
    &lt;p&gt;This study included researchers at UC Santa Barbara, Washington University in St. Louis, Johns Hopkins University, the University Medical Center Hamburg-Eppendorf, and ETH Zurich.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ucsc.edu/2025/11/sharf-preconfigured-brain/"/><published>2025-11-25T06:31:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46042946</id><title>Most Stable Raspberry Pi? Better NTP with Thermal Management</title><updated>2025-11-25T16:49:09.248920+00:00</updated><content>&lt;doc fingerprint="b57aba02285e8efe"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôve written before about building microsecond-accurate NTP servers with Raspberry Pi and GPS PPS, and more recently about revisiting the setup in 2025. Both posts focused on the hardware setup and basic configuration to achieve sub-microsecond time synchronization using GPS Pulse Per Second (PPS) signals.&lt;/p&gt;
    &lt;p&gt;But there was a problem. Despite having a stable PPS reference, my NTP server‚Äôs frequency drift was exhibiting significant variation over time. After months (years) of monitoring the system with Grafana dashboards, I noticed something interesting: the frequency oscillations seemed to correlate with CPU temperature changes. The frequency would drift as the CPU heated up during the day and cooled down at night, even though the PPS reference remained rock-solid.&lt;/p&gt;
    &lt;p&gt;Like clockwork (no pun intended), I somehow get sucked back into trying to improve my setup every 6-8 weeks. This post is the latest on that never-ending quest.&lt;/p&gt;
    &lt;p&gt;This post details how I achieved an 81% reduction in frequency variability and 77% reduction in frequency standard deviation through a combination of CPU core pinning and thermal stabilization. Welcome to Austin‚Äôs Nerdy Things, where we solve problems that 99.999% of people (and 99% of datacenters) don‚Äôt have.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Problem: Thermal-Induced Timing Jitter&lt;/head&gt;
    &lt;p&gt;Modern CPUs, including those in Raspberry Pis, use dynamic frequency scaling to save power and manage heat. When the CPU is idle, it runs at a lower frequency (and voltage). When load increases, it scales up. This is great for power efficiency, but terrible for precision timekeeping.&lt;/p&gt;
    &lt;p&gt;Why? Because timekeeping (with NTP/chronyd/others) relies on a stable system clock to discipline itself against reference sources. If the CPU frequency is constantly changing, the system clock‚Äôs tick rate varies, introducing jitter into the timing measurements. Even though my PPS signal was providing a mostly perfect 1-pulse-per-second reference, the CPU‚Äôs frequency bouncing around made it harder for chronyd to maintain a stable lock.&lt;/p&gt;
    &lt;p&gt;But here‚Äôs the key insight: the system clock is ultimately derived from a crystal oscillator, and crystal oscillator frequency is temperature-dependent. The oscillator sits on the board near the CPU, and as the CPU heats up and cools down throughout the day, so does the crystal. Even a few degrees of temperature change can shift the oscillator‚Äôs frequency by parts per million ‚Äì exactly what I was seeing in my frequency drift graphs. The CPU frequency scaling was one factor, but the underlying problem was that temperature changes were affecting the crystal oscillator itself. By stabilizing the CPU temperature, I could stabilize the thermal environment for the crystal oscillator, keeping its frequency consistent.&lt;/p&gt;
    &lt;p&gt;Looking at my Grafana dashboard, I could see the frequency offset wandering over a range of about 1 PPM (parts per million) as the Pi warmed up and cooled down throughout the day. The RMS offset was averaging around 86 nanoseconds, which isn‚Äôt terrible (it‚Äôs actually really, really, really good), but I knew it could be better.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery&lt;/head&gt;
    &lt;p&gt;After staring at graphs for longer than I‚Äôd like to admit, I had an idea: what if I could keep the CPU at a constant temperature? If the temperature (and therefore the frequency) stayed stable, maybe the timing would stabilize too.&lt;/p&gt;
    &lt;p&gt;The solution came in two parts:&lt;/p&gt;
    &lt;p&gt;1. CPU core isolation ‚Äì Dedicate CPU 0 exclusively to timing-critical tasks (chronyd and PPS interrupts) 2. Thermal stabilization ‚Äì Keep the other CPUs busy to maintain a constant temperature, preventing frequency scaling&lt;/p&gt;
    &lt;p&gt;Here‚Äôs what happened when I turned on the thermal stabilization system on November 17, 2025 at 09:10 AM:&lt;/p&gt;
    &lt;p&gt;Same ish graph but with CPU temp also plotted:&lt;/p&gt;
    &lt;p&gt;That vertical red line marks on the first plot when I activated the ‚Äútime burner‚Äù process. Notice how the frequency oscillations immediately dampen and settle into a much tighter band? Let‚Äôs dive into how this works.&lt;/p&gt;
    &lt;p&gt;EDIT: 2025-11-25 I didn‚Äôt expect to wake up and see this at #2 on Hacker News ‚Äì https://news.ycombinator.com/item?id=46042946&lt;/p&gt;
    &lt;head rend="h2"&gt;The Solution Part 1: CPU Core Pinning and Real-Time Priority&lt;/head&gt;
    &lt;p&gt;The first step is isolating timing-critical operations onto a dedicated CPU core. On a Raspberry Pi (4-core ARM), this means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CPU 0: Reserved for chronyd and PPS interrupts&lt;/item&gt;
      &lt;item&gt;CPUs 1-3: Everything else, including our thermal load&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I had AI (probably Claude Sonnet 4 ish, maybe 4.5) create a boot optimization script that runs at system startup:&lt;/p&gt;
    &lt;code&gt;#!/bin/bash
# PPS NTP Server Performance Optimization Script
# Sets CPU affinity, priorities, and performance governor at boot

set -e

echo "Setting up PPS NTP server performance optimizations..."

# Wait for system to be ready
sleep 5

# Set CPU governor to performance mode
echo "Setting CPU governor to performance..."
cpupower frequency-set -g performance

# Pin PPS interrupt to CPU0 (may fail if already pinned, that's OK)
echo "Configuring PPS interrupt affinity..."
echo 1 &amp;gt; /proc/irq/200/smp_affinity 2&amp;gt;/dev/null || echo "PPS IRQ already configured"

# Wait for chronyd to start
echo "Waiting for chronyd to start..."
timeout=30
while [ $timeout -gt 0 ]; do
    chronyd_pid=$(pgrep chronyd 2&amp;gt;/dev/null || echo "")
    if [ -n "$chronyd_pid" ]; then
        echo "Found chronyd PID: $chronyd_pid"
        break
    fi
    sleep 1
    ((timeout--))
done

if [ -z "$chronyd_pid" ]; then
    echo "Warning: chronyd not found after 30 seconds"
else
    # Set chronyd to real-time priority and pin to CPU 0
    echo "Setting chronyd to real-time priority and pinning to CPU 0..."
    chrt -f -p 50 $chronyd_pid
    taskset -cp 0 $chronyd_pid
fi

# Boost ksoftirqd/0 priority
echo "Boosting ksoftirqd/0 priority..."
ksoftirqd_pid=$(ps aux | grep '\[ksoftirqd/0\]' | grep -v grep | awk '{print $2}')
if [ -n "$ksoftirqd_pid" ]; then
    renice -n -10 $ksoftirqd_pid
    echo "ksoftirqd/0 priority boosted (PID: $ksoftirqd_pid)"
else
    echo "Warning: ksoftirqd/0 not found"
fi

echo "PPS NTP optimization complete!"

# Log current status
echo "=== Current Status ==="
echo "CPU Governor: $(cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor)"
echo "PPS IRQ Affinity: $(cat /proc/irq/200/effective_affinity_list 2&amp;gt;/dev/null || echo 'not readable')"
if [ -n "$chronyd_pid" ]; then
    echo "chronyd Priority: $(chrt -p $chronyd_pid)"
fi
echo "======================"&lt;/code&gt;
    &lt;p&gt;What this does:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Performance Governor: Forces all CPUs to run at maximum frequency, disabling frequency scaling&lt;/item&gt;
      &lt;item&gt;PPS IRQ Pinning: Ensures PPS interrupt (IRQ 200) is handled exclusively by CPU 0&lt;/item&gt;
      &lt;item&gt;Chronyd Real-Time Priority: Sets chronyd to SCHED_FIFO priority 50, giving it preferential CPU scheduling&lt;/item&gt;
      &lt;item&gt;Chronyd CPU Affinity: Pins chronyd to CPU 0 using &lt;code&gt;taskset&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ksoftirqd Priority Boost: Improves priority of the kernel softirq handler on CPU 0&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This script can be added to &lt;code&gt;/etc/rc.local&lt;/code&gt; or as a systemd service to run at boot.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Solution Part 2: PID-Controlled Thermal Stabilization&lt;/head&gt;
    &lt;p&gt;Setting the performance governor helps, but on a Raspberry Pi, even at max frequency, the CPU temperature will still vary based on ambient conditions and load. Temperature changes affect the CPU‚Äôs actual operating frequency due to thermal characteristics of the silicon.&lt;/p&gt;
    &lt;p&gt;The solution? Keep the CPU at a constant temperature using a PID-controlled thermal load. I call it the ‚Äútime burner‚Äù (inspired by CPU burn-in tools, but with precise temperature control).&lt;/p&gt;
    &lt;p&gt;As a reminder of what we‚Äôre really doing here: we‚Äôre maintaining a stable thermal environment for the crystal oscillator. The RPi 3B‚Äôs 19.2 MHz oscillator is physically located near the CPU on the Raspberry Pi board, so by actively controlling CPU temperature, we‚Äôre indirectly controlling the oscillator‚Äôs temperature. Since the oscillator‚Äôs frequency is temperature-dependent (this is basic physics of quartz crystals), keeping it at a constant temperature means keeping its frequency stable ‚Äì which is exactly what we need for precise timekeeping.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how it works:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read CPU temperature from &lt;code&gt;/sys/class/thermal/thermal_zone0/temp&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;PID controller calculates how much CPU time to burn to maintain target temperature (I chose 54¬∞C)&lt;/item&gt;
      &lt;item&gt;Three worker processes run on CPUs 1, 2, and 3 (avoiding CPU 0)&lt;/item&gt;
      &lt;item&gt;Each worker alternates between busy-loop (MD5 hashing) and sleeping based on PID output&lt;/item&gt;
      &lt;item&gt;Temperature stabilizes at the setpoint, preventing thermal drift&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here‚Äôs the core implementation (simplified for readability):&lt;/p&gt;
    &lt;code&gt;#!/usr/bin/env python3
import time
import argparse
import multiprocessing
import hashlib
import os
from collections import deque

class PIDController:
    """Simple PID controller with output clamping and anti-windup."""
    def __init__(self, Kp, Ki, Kd, setpoint, output_limits=(0, 1), sample_time=1.0):
        self.Kp = Kp
        self.Ki = Ki
        self.Kd = Kd
        self.setpoint = setpoint
        self.output_limits = output_limits
        self.sample_time = sample_time
        self._last_time = time.time()
        self._last_error = 0.0
        self._integral = 0.0
        self._last_output = 0.0

    def update(self, measurement):
        """Compute new output of PID based on measurement."""
        now = time.time()
        dt = now - self._last_time

        if dt &amp;lt; self.sample_time:
            return self._last_output

        error = self.setpoint - measurement

        # Proportional
        P = self.Kp * error

        # Integral with anti-windup
        self._integral += error * dt
        I = self.Ki * self._integral

        # Derivative
        derivative = (error - self._last_error) / dt if dt &amp;gt; 0 else 0.0
        D = self.Kd * derivative

        # Combine and clamp
        output = P + I + D
        low, high = self.output_limits
        output = max(low, min(high, output))

        self._last_output = output
        self._last_error = error
        self._last_time = now

        return output

def read_cpu_temperature(path='/sys/class/thermal/thermal_zone0/temp'):
    """Return CPU temperature in Celsius."""
    with open(path, 'r') as f:
        temp_str = f.read().strip()
    return float(temp_str) / 1000.0

def burn_cpu(duration):
    """Busy-loop hashing for 'duration' seconds."""
    end_time = time.time() + duration
    m = hashlib.md5()
    while time.time() &amp;lt; end_time:
        m.update(b"burning-cpu")

def worker_loop(worker_id, cmd_queue, done_queue):
    """
    Worker process:
    - Pins itself to CPUs 1, 2, or 3 (avoiding CPU 0)
    - Burns CPU based on commands from main process
    """
    available_cpus = [1, 2, 3]
    cpu_to_use = available_cpus[worker_id % len(available_cpus)]
    os.sched_setaffinity(0, {cpu_to_use})
    print(f"Worker {worker_id} pinned to CPU {cpu_to_use}")

    while True:
        cmd = cmd_queue.get()
        if cmd is None:
            break

        burn_time, sleep_time = cmd
        burn_cpu(burn_time)
        time.sleep(sleep_time)
        done_queue.put(worker_id)

# Main control loop (simplified)
def main():
    target_temp = 54.0  # degrees Celsius
    control_window = 0.20  # 200ms cycle time

    pid = PIDController(Kp=0.05, Ki=0.02, Kd=0.0,
                        setpoint=target_temp,
                        sample_time=0.18)

    # Start 3 worker processes
    workers = []
    cmd_queues = []
    done_queue = multiprocessing.Queue()

    for i in range(3):
        q = multiprocessing.Queue()
        p = multiprocessing.Process(target=worker_loop, args=(i, q, done_queue))
        p.start()
        workers.append(p)
        cmd_queues.append(q)

    try:
        while True:
            # Measure temperature
            current_temp = read_cpu_temperature()

            # PID control: output is fraction of time to burn (0.0 to 1.0)
            output = pid.update(current_temp)

            # Convert to burn/sleep times
            burn_time = output * control_window
            sleep_time = control_window - burn_time

            # Send command to all workers
            for q in cmd_queues:
                q.put((burn_time, sleep_time))

            # Wait for workers to complete
            for _ in range(3):
                done_queue.get()

            print(f"Temp={current_temp:.2f}C, Output={output:.2f}, "
                  f"Burn={burn_time:.2f}s")

    except KeyboardInterrupt:
        for q in cmd_queues:
            q.put(None)
        for p in workers:
            p.join()

if __name__ == '__main__':
    main()&lt;/code&gt;
    &lt;p&gt;The full implementation includes a temperature filtering system to smooth out sensor noise and command-line arguments for tuning the PID parameters.&lt;/p&gt;
    &lt;p&gt;PID Tuning Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kp=0.05: Proportional gain ‚Äì responds to current error&lt;/item&gt;
      &lt;item&gt;Ki=0.02: Integral gain ‚Äì eliminates steady-state error&lt;/item&gt;
      &lt;item&gt;Kd=0.0: Derivative gain ‚Äì set to zero because temperature changes slowly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The target temperature of 54¬∞C was chosen empirically ‚Äì high enough to keep the CPU from idling down, but low enough to avoid thermal throttling (which starts around 80¬∞C on Raspberry Pi).&lt;/p&gt;
    &lt;head rend="h2"&gt;The Results: Numbers Don‚Äôt Lie&lt;/head&gt;
    &lt;p&gt;The improvement was immediately visible. Here are the statistics comparing performance before and after the optimization:&lt;/p&gt;
    &lt;p&gt;A note on ambient conditions: The Raspberry Pi lives in a project enclosure in our master bedroom (chosen for its decent GPS reception and ADS-B coverage for a new aircraft AR overlay app idea I‚Äôm working on also running on this Pi). While the time burner maintains the CPU die temperature at 54¬∞C, the enclosure is still subject to ambient temperature swings. Room temperature cycles from a low of 66¬∞F (18.9¬∞C) at 5:15 AM to a peak of 72¬∞F (22.2¬∞C) at 11:30 AM ‚Äì a 6¬∞F daily swing from our heating schedule. The fact that we see such dramatic frequency stability improvements despite this ambient variation speaks to how effective the thermal control is. The CPU‚Äôs active heating overwhelms the environmental changes, maintaining consistent silicon temperature where it matters most.&lt;/p&gt;
    &lt;head rend="h3"&gt;Frequency Stability&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Before&lt;/cell&gt;
        &lt;cell role="head"&gt;After&lt;/cell&gt;
        &lt;cell role="head"&gt;Improvement&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mean RMS Offset&lt;/cell&gt;
        &lt;cell&gt;85.44 ns&lt;/cell&gt;
        &lt;cell&gt;43.54 ns&lt;/cell&gt;
        &lt;cell&gt;49.0% reduction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Median RMS Offset&lt;/cell&gt;
        &lt;cell&gt;80.13 ns&lt;/cell&gt;
        &lt;cell&gt;37.93 ns&lt;/cell&gt;
        &lt;cell&gt;52.7% reduction&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The RMS offset is chronyd‚Äôs estimate of the timing uncertainty. Cutting this nearly in half means the system is maintaining significantly better time accuracy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Setup Instructions&lt;/head&gt;
    &lt;p&gt;Want to replicate this? Here‚Äôs the step-by-step process:&lt;/p&gt;
    &lt;head rend="h3"&gt;Prerequisites&lt;/head&gt;
    &lt;p&gt;You need a working GPS PPS NTP server setup. If you don‚Äôt have one yet, follow my 2025 NTP guide first.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 0: Install Required Tools&lt;/head&gt;
    &lt;code&gt;sudo apt-get update
sudo apt-get install linux-cpupower python3 util-linux&lt;/code&gt;
    &lt;head rend="h3"&gt;Step 1: Create the Boot Optimization Script&lt;/head&gt;
    &lt;p&gt;Save the optimization script from earlier as &lt;code&gt;/usr/local/bin/pps-optimize.sh&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;sudo nano /usr/local/bin/pps-optimize.sh
# Paste the script content
sudo chmod +x /usr/local/bin/pps-optimize.sh&lt;/code&gt;
    &lt;head rend="h3"&gt;Step 2: Create Systemd Service for Boot Script&lt;/head&gt;
    &lt;p&gt;Create &lt;code&gt;/etc/systemd/system/pps-optimize.service&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;[Unit]
Description=PPS NTP Performance Optimization
After=chronyd.service
Requires=chronyd.service

[Service]
Type=oneshot
ExecStart=/usr/local/bin/pps-optimize.sh
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target&lt;/code&gt;
    &lt;p&gt;Enable it:&lt;/p&gt;
    &lt;code&gt;sudo systemctl enable pps-optimize.service&lt;/code&gt;
    &lt;head rend="h3"&gt;Step 3: Install the Time Burner Script&lt;/head&gt;
    &lt;p&gt;Save the time burner Python script as &lt;code&gt;/usr/local/bin/time_burner.py&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;sudo nano /usr/local/bin/time_burner.py
# Paste the full time burner script
sudo chmod +x /usr/local/bin/time_burner.py&lt;/code&gt;
    &lt;head rend="h3"&gt;Step 4: Create Systemd Service for Time Burner&lt;/head&gt;
    &lt;p&gt;Create &lt;code&gt;/etc/systemd/system/time-burner.service&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;[Unit]
Description=CPU Thermal Stabilization for NTP
After=network.target

[Service]
Type=simple
User=root
ExecStart=/usr/bin/python3 /usr/local/bin/time_burner.py -t 54.0 -n 3
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target&lt;/code&gt;
    &lt;p&gt;Enable and start it:&lt;/p&gt;
    &lt;code&gt;sudo systemctl enable time-burner.service
sudo systemctl start time-burner.service&lt;/code&gt;
    &lt;head rend="h3"&gt;Step 5: Verify the Setup&lt;/head&gt;
    &lt;p&gt;Check that everything is running:&lt;/p&gt;
    &lt;code&gt;# Verify CPU governor
cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
# Should output: performance

# Check chronyd CPU affinity and priority
ps -eo pid,comm,psr,ni,rtprio | grep chronyd
# Should show psr=0 (CPU 0) and rtprio=50

# Check time burner processes
ps aux | grep time_burner
# Should show 4 processes (1 main + 3 workers)

# Monitor NTP performance
chronyc tracking&lt;/code&gt;
    &lt;p&gt;Example output from &lt;code&gt;chronyc tracking&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;Reference ID    : 50505300 (PPS)
Stratum         : 1
Ref time (UTC)  : Sun Nov 24 16:45:23 2025
System time     : 0.000000038 seconds fast of NTP time
Last offset     : -0.000000012 seconds
RMS offset      : 0.000000035 seconds
Frequency       : 1.685 ppm slow
Residual freq   : -0.001 ppm
Skew            : 0.002 ppm
Root delay      : 0.000000001 seconds
Root dispersion : 0.000010521 seconds
Update interval : 16.0 seconds
Leap status     : Normal&lt;/code&gt;
    &lt;p&gt;Notice the RMS offset of 35 nanoseconds ‚Äì this is the kind of accuracy you can achieve with thermal stabilization.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 6: Monitor Over Time&lt;/head&gt;
    &lt;p&gt;(Topic for a future post)&lt;/p&gt;
    &lt;p&gt;Set up Grafana dashboards to monitor:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency offset (PPM)&lt;/item&gt;
      &lt;item&gt;RMS offset (nanoseconds)&lt;/item&gt;
      &lt;item&gt;CPU temperature&lt;/item&gt;
      &lt;item&gt;System time offset&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You‚Äôll see the frequency stabilize within a few hours as the PID controller locks onto the target temperature.&lt;/p&gt;
    &lt;head rend="h2"&gt;Monitoring and Troubleshooting&lt;/head&gt;
    &lt;head rend="h3"&gt;Real-Time Monitoring&lt;/head&gt;
    &lt;p&gt;Watch chronyd tracking in real-time:&lt;/p&gt;
    &lt;code&gt;watch -n 1 "chronyc tracking"&lt;/code&gt;
    &lt;p&gt;Check time burner status:&lt;/p&gt;
    &lt;code&gt;sudo systemctl status time-burner.service&lt;/code&gt;
    &lt;p&gt;View time burner output:&lt;/p&gt;
    &lt;code&gt;sudo journalctl -u time-burner.service -f&lt;/code&gt;
    &lt;head rend="h3"&gt;Common Issues&lt;/head&gt;
    &lt;p&gt;Temperature overshoots or oscillates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Adjust PID gains ‚Äì reduce Kp if oscillating, increase Ki if steady-state error&lt;/item&gt;
      &lt;item&gt;Try different target temperatures (50-60¬∞C range)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;High CPU usage (obviously):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is intentional ‚Äì the time burner uses ~90% of 3 cores&lt;/item&gt;
      &lt;item&gt;Not suitable for Pis running other workloads&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Chronyd not pinned to CPU 0:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check that the optimization script runs after chronyd starts&lt;/item&gt;
      &lt;item&gt;Adjust the timing in the systemd service dependencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Trade-offs and Considerations&lt;/head&gt;
    &lt;p&gt;Let‚Äôs be honest about the downsides:&lt;/p&gt;
    &lt;head rend="h3"&gt;Power Consumption&lt;/head&gt;
    &lt;p&gt;The time burner keeps 3 cores at ~30% average utilization. My Pi now draws about 3-4W continuously (vs 1-2W idle). Over a year, that‚Äôs an extra 15-25 kWh, or about $2-3 in electricity (depending on your rates).&lt;/p&gt;
    &lt;head rend="h3"&gt;Heat&lt;/head&gt;
    &lt;p&gt;Running at 54¬∞C means the Pi is warm to the touch. This is well within safe operating temperature (thermal throttling doesn‚Äôt start until 80¬∞C), but you might want to ensure adequate ventilation. I added a small heatsink just to be safe.&lt;/p&gt;
    &lt;head rend="h3"&gt;CPU Resources&lt;/head&gt;
    &lt;p&gt;You‚Äôre dedicating 3 of 4 cores to burning cycles. This is fine for a dedicated NTP server, but not suitable if you‚Äôre running other services on the same Pi. That said, I am also running the feeder to my new ADS-B aircraft visualization app on it. My readsb instance regularly gets to 1200 msg/s with 200+ aircraft.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is It Worth It?&lt;/head&gt;
    &lt;p&gt;For 99.999% of use cases: absolutely not.&lt;/p&gt;
    &lt;p&gt;Most applications don‚Äôt need better than millisecond accuracy, let alone the 35-nanosecond RMS offset I‚Äôm achieving. Even for distributed systems, microsecond-level accuracy is typically overkill.&lt;/p&gt;
    &lt;p&gt;When this might make sense:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Precision timing applications (scientific instrumentation, radio astronomy)&lt;/item&gt;
      &lt;item&gt;Distributed systems research requiring tight clock synchronization&lt;/item&gt;
      &lt;item&gt;Network testing where timing precision affects results&lt;/item&gt;
      &lt;item&gt;Because you can (the best reason for any homelab project)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For me, this falls squarely in the ‚Äúbecause you can‚Äù category. I had the monitoring infrastructure in place, noticed the thermal correlation, and couldn‚Äôt resist solving the problem. Plus, I learned a lot about PID control, CPU thermal characteristics, and Linux real-time scheduling.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future Improvements&lt;/head&gt;
    &lt;p&gt;Some ideas I‚Äôm considering:&lt;/p&gt;
    &lt;head rend="h3"&gt;Adaptive PID Tuning&lt;/head&gt;
    &lt;p&gt;The current PID gains are hand-tuned for a specific ambient temperature range. The fairly low P value is to avoid spikes when some load on the Pi kicks up the temp. The I is a balance to keep long term ‚Äúburn‚Äù relatively consistent. Implementing an auto-tuning algorithm (like Ziegler-Nichols) or adaptive PID could handle seasonal temperature variations better.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hardware Thermal Control&lt;/head&gt;
    &lt;p&gt;Instead of software thermal control, I could add an actively cooled heatsink with PWM fan control. This might achieve similar temperature stability while using less power overall.&lt;/p&gt;
    &lt;head rend="h3"&gt;Oven-Controlled Crystal Oscillator (OCXO)&lt;/head&gt;
    &lt;p&gt;For the ultimate in frequency stability, replacing the Pi‚Äôs crystal with a temperature-controlled OCXO would eliminate thermal drift at the source. This is how professional timing equipment works. I do have a BH3SAP GPSDO sitting next to me (subject to a future post)‚Ä¶ Then again, I‚Äôm the person who just wrote 4000 words about optimizing a $50 time server, so who am I kidding?&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;Through a combination of CPU core isolation and PID-controlled thermal stabilization, I achieved:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;81% reduction in frequency variability&lt;/item&gt;
      &lt;item&gt;77% reduction in frequency standard deviation&lt;/item&gt;
      &lt;item&gt;74% reduction in frequency range&lt;/item&gt;
      &lt;item&gt;49% reduction in RMS offset&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The system now maintains 38-nanosecond median RMS offset from the GPS PPS reference, with frequency drift that‚Äôs barely detectable in the noise. The CPU runs at a constant 54¬∞C, and in steady state, the frequency offset stays within a tight ¬±0.14 PPM band (compared to ¬±0.52 PPM before optimization).&lt;/p&gt;
    &lt;p&gt;Was this necessary? No. Did I learn a bunch about thermal management, PID control, and Linux real-time scheduling? Yes. Would I do it again? Absolutely.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resource&lt;/head&gt;
    &lt;p&gt;I did come across a ‚Äúburn‚Äù script that was the basis for this thermal management. I can‚Äôt find it at the moment, but when I do I‚Äôll link it here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Related Posts&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsecond-Accurate NTP with a Raspberry Pi and PPS GPS (2021)&lt;/item&gt;
      &lt;item&gt;Revisiting Microsecond-Accurate NTP for Raspberry Pi in 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Further Reading&lt;/head&gt;
    &lt;p&gt;Have questions or suggestions? Drop a comment below. I‚Äôm particularly interested to hear if anyone has tried alternative thermal management approaches or has experience with OCXO modules for Raspberry Pi timing applications.&lt;/p&gt;
    &lt;p&gt;Thanks for reading, and happy timekeeping!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://austinsnerdythings.com/2025/11/24/worlds-most-stable-raspberry-pi-81-better-ntp-with-thermal-management/"/><published>2025-11-25T06:35:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045039</id><title>Making Crash Bandicoot (2011)</title><updated>2025-11-25T16:49:08.859732+00:00</updated><content>&lt;doc fingerprint="5fc2b1ecb077262e"&gt;
  &lt;main&gt;
    &lt;p&gt;As one of the co-creators of Crash Bandicoot, I have been (slowly) writing a long series of posts on the making of everyone‚Äôs favorite orange marsupial. You can find them all below, so enjoy.&lt;/p&gt;
    &lt;p&gt;If you are on mobile and cannot see the grid of posts, click here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://all-things-andy-gavin.com/video-games/making-crash/"/><published>2025-11-25T12:05:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045085</id><title>Trillions Spent and Big Software Projects Are Still Failing</title><updated>2025-11-25T16:49:07.819189+00:00</updated><content>&lt;doc fingerprint="f94c525c6b670fdc"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;How IT Managers Fail Software Projects&lt;/head&gt;&lt;p&gt;AI won‚Äôt solve IT‚Äôs management problems&lt;/p&gt;&lt;p&gt;‚ÄúWhy worry about something that isn‚Äôt going to happen?‚Äù&lt;/p&gt;&lt;p&gt;KGB Chairman Charkov‚Äôs question to inorganic chemist Valery Legasov in HBO‚Äôs ‚ÄúChernobyl‚Äù miniseries makes a good epitaph for the hundreds of software development, modernization, and operational failures I have covered for IEEE Spectrum since my first contribution, to its September 2005 special issue on learning‚Äîor rather, not learning‚Äîfrom software failures. I noted then, and it‚Äôs still true two decades later: Software failures are universally unbiased. They happen in every country, to large companies and small. They happen in commercial, nonprofit, and governmental organizations, regardless of status or reputation.&lt;/p&gt;&lt;p&gt;Global IT spending has more than tripled in constant 2025 dollars since 2005, from US $1.7 trillion to $5.6 trillion, and continues to rise. Despite additional spending, software success rates have not markedly improved in the past two decades. The result is that the business and societal costs of failure continue to grow as software proliferates, permeating and interconnecting every aspect of our lives.&lt;/p&gt;&lt;p&gt;For those hoping AI software tools and coding copilots will quickly make large-scale IT software projects successful, forget about it. For the foreseeable future, there are hard limits on what AI can bring to the table in controlling and managing the myriad intersections and trade-offs among systems engineering, project, financial, and business management, and especially the organizational politics involved in any large-scale software project. Few IT projects are displays of rational decision-making from which AI can or should learn. As software practitioners know, IT projects suffer from enough management hallucinations and delusions without AI adding to them.&lt;/p&gt;&lt;p&gt;As I noted 20 years ago, the drivers of software failure frequently are failures of human imagination, unrealistic or unarticulated project goals, the inability to handle the project‚Äôs complexity, or unmanaged risks, to name a few that today still regularly cause IT failures. Numerous others go back decades, such as those identified by Stephen Andriole, the chair of business technology at Villanova University‚Äôs School of Business, in the diagram below first published in Forbes in 2021. Uncovering a software system failure that has gone off the rails in a unique, previously undocumented manner would be surprising because the overwhelming majority of software-related failures involve avoidable, known failure-inducing factors documented in hundreds of after-action reports, academic studies, and technical and management books for decades. Failure d√©j√† vu dominates the literature.&lt;/p&gt;&lt;p&gt;The question is, why haven‚Äôt we applied what we have repeatedly been forced to learn?&lt;/p&gt;&lt;head rend="h2"&gt;The Phoenix That Never Rose&lt;/head&gt;&lt;p&gt;Many of the IT developments and operational failures I have analyzed over the last 20 years have each had their own Chernobyl-like meltdowns, spreading reputational radiation everywhere and contaminating the lives of those affected for years. Each typically has a story that strains belief. A prime example is the Canadian government‚Äôs CA $310 million Phoenix payroll system, which went live in April 2016 and soon after went supercritical.&lt;/p&gt;&lt;p&gt;Phoenix project executives believed they could deliver a modernized payment system, customizing PeopleSoft‚Äôs off-the-shelf payroll package to follow 80,000 pay rules spanning 105 collective agreements with federal public-service unions. It also was attempting to implement 34 human-resource system interfaces across 101 government agencies and departments required for sharing employee data. Further, the government‚Äôs developer team thought they could accomplish this for less than 60 percent of the vendor‚Äôs proposed budget. They‚Äôd save by removing or deferring critical payroll functions, reducing system and integration testing, decreasing the number of contractors and government staff working on the project, and forgoing vital pilot testing, along with a host of other overly optimistic proposals.&lt;/p&gt;&lt;head rend="h3"&gt;The Worst IT Failure&lt;/head&gt;&lt;p&gt;Jordan Pettitt/PA Images/Getty Images&lt;/p&gt;&lt;p&gt;The Phoenix payroll failure pales in comparison to the worst operational IT system failure to date: the U.K. Post Office‚Äôs electronic point-of-sale (EPOS) Horizon system, provided by Fujitsu. Rolled out in 1999, Horizon was riddled with internal software errors that were deliberately hidden, leading to the Post Office unfairly accusing 3,500 local post branch managers of false accounting, fraud, and theft. Approximately 900 of these managers were convicted, with 236 incarcerated between 1999 and 2015. By then, the general public and the branch managers themselves finally joined Computer Weekly‚Äôs reporters (who had doggedly reported on Horizon‚Äôs problems since 2008) in the knowledge that there was something seriously wrong with Horizon‚Äôs software. It then took another decade of court cases, an independent public statutory inquiry, and an ITV miniseries ‚ÄúMr. Bates vs. The Post Office‚Äù to unravel how the scandal came to be.&lt;/p&gt;&lt;p&gt;Like Phoenix, Horizon was plagued with problems that involved technical, management, organizational, legal, and ethical failures. For example, the core electronic point-of-sale system software was built on communication and data-transfer middleware that was itself buggy. In addition, Horizon‚Äôs functionality ran wild under unrelenting, ill-disciplined scope creep. There were ineffective or missing development and project management processes, inadequate testing, and a lack of skilled professional, technical, and managerial personnel.&lt;/p&gt;&lt;p&gt;The Post Office‚Äôs senior leadership repeatedly stated that the Horizon software was fully reliable, becoming hostile toward postmasters who questioned it, which only added to the toxic environment. As a result, leadership invoked every legal means at its disposal and crafted a world-class cover-up, including the active suppression of exculpatory information, so that the Post Office could aggressively prosecute postmasters and attempt to crush any dissent questioning Horizon‚Äôs integrity.&lt;/p&gt;Shockingly, those wrongly accused still have to continue to fight to be paid just compensation for their ruined lives. Nearly 350 of the accused died, at least 13 of whom are believed to be by suicide, before receiving any payments for the injustices experienced. Unfortunately, as attempts to replace Horizon in 2016 and 2021 failed, the Post Office continues to use it, at least for now. The government wants to spend ¬£410 million on a new system, but it‚Äôs a safe bet that implementing it will cost much, much more. The Post Office accepted bids for a new point-of-sale software system in summer 2025, with a decision expected by 1 July 2026.&lt;p&gt;Phoenix‚Äôs payroll meltdown was preordained. As a result, over the past nine years, around 70 percent of the 430,000 current and former Canadian federal government employees paid through Phoenix have endured paycheck errors. Even as recently as fiscal year 2023‚Äì2024, a third of all employees experienced paycheck mistakes. The ongoing financial stress and anxieties for thousands of employees and their families have been immeasurable. Not only are recurring paycheck troubles sapping worker morale, but in at least one documented case, a coroner blamed an employee‚Äôs suicide on the unbearable financial and emotional strain she suffered.&lt;/p&gt;&lt;p&gt;By the end of March 2025, when the Canadian government had promised that the backlog of Phoenix errors would finally be cleared, over 349,000 were still unresolved, with 53 percent pending for more than a year. In June, the Canadian government once again committed to significantly reducing the backlog, this time by June 2026. Given previous promises, skepticism is warranted.&lt;/p&gt;&lt;head rend="h3"&gt;Minnesota Licensing and Registration System&lt;/head&gt;Anthony Souffle/Star Tribune/AP&lt;p&gt;2019&lt;/p&gt;&lt;p&gt;The planned $41 million Minnesota Licensing and Registration System (MNLARS) effort is rolled out in 2016 and then is canceled in 2019 after a total cost of $100 million. It is deemed too hard to fix.&lt;/p&gt;&lt;p&gt;The financial costs to Canadian taxpayers related to Phoenix‚Äôs troubles have so far climbed to over CA $5.1 billion (US $3.6 billion). It will take years to calculate the final cost of the fiasco. The government spent at least CA $100 million (US $71 million) before deciding on a Phoenix replacement, which the government acknowledges will cost several hundred million dollars more and take years to implement. The late Canadian Auditor General Michael Ferguson‚Äôs audit reports for the Phoenix fiasco described the effort as an ‚Äúincomprehensible failure of project management and oversight.‚Äù&lt;/p&gt;&lt;p&gt;While it may be a project management and oversight disaster, an inconceivable failure Phoenix certainly is not. The IT community has striven mightily for decades to make the incomprehensible routine.&lt;/p&gt;&lt;head rend="h2"&gt;Opportunity Costs of Software Failure Keep Piling Up&lt;/head&gt;&lt;p&gt;South of the Canadian border, the United States has also seen the overall cost of IT-related development and operational failures since 2005 rise to the multi-trillion-dollar range, potentially topping $10 trillion. A report from the Consortium for Information &amp;amp; Software Quality (CISQ) estimated the annual cost of operational software failures in the United States in 2022 alone was $1.81 trillion, with another $260 billion spent on software-development failures. It is larger than the total U.S. defense budget for that year, $778 billion.&lt;/p&gt;&lt;p&gt;The question is, why haven‚Äôt we applied what we have repeatedly been forced to learn?&lt;/p&gt;&lt;p&gt;What percentage of software projects fail, and what failure means, has been an ongoing debate within the IT community stretching back decades. Without diving into the debate, it‚Äôs clear that software development remains one of the riskiest technological endeavors to undertake. Indeed, according to Bent Flyvbjerg, professor emeritus at the University of Oxford‚Äôs Sa—ód Business School, comprehensive data shows that not only are IT projects risky, they are the riskiest from a cost perspective.&lt;/p&gt;&lt;head rend="h3"&gt;Australia Modernising Business Registers Program&lt;/head&gt;&lt;p&gt;iStock&lt;/p&gt;&lt;p&gt;2022&lt;/p&gt;&lt;p&gt;Australia‚Äôs planned AU $480.5 million program to modernize it business register systems is canceled. After AU $530 million is spent, a review finds that the projected cost has risen to AU $2.8 billion, and the project would take five more years to complete.&lt;/p&gt;&lt;p&gt;The CISQ report estimates that organizations in the United States spend more than $520 billion annually supporting legacy software systems, with 70 to 75 percent of organizational IT budgets devoted to legacy maintenance. A 2024 report by services company NTT DATA found that 80 percent of organizations concede that ‚Äúinadequate or outdated technology is holding back organizational progress and innovation efforts.‚Äù Furthermore, the report says that virtually all C-level executives believe legacy infrastructure thwarts their ability to respond to the market. Even so, given that the cost of replacing legacy systems is typically many multiples of the cost of supporting them, business executives hesitate to replace them until it is no longer operationally feasible or cost-effective. The other reason is a well-founded fear that replacing them will turn into a debacle like Phoenix or others.&lt;/p&gt;&lt;p&gt;Nevertheless, there have been ongoing attempts to improve software development and sustainment processes. For example, we have seen increasing adoption of iterative and incremental strategies to develop and sustain software systems through Agile approaches, DevOps methods, and other related practices.&lt;/p&gt;&lt;head rend="h3"&gt;Louisiana Office of Motor Vehicles&lt;/head&gt;&lt;p&gt;Gerald Herbert/AP&lt;/p&gt;&lt;p&gt;2025&lt;/p&gt;&lt;p&gt;Louisiana‚Äôs governor orders a state of emergency over repeated failures of the 50-year-old Office of Motor Vehicles mainframe computer system. The state promises expedited acquisition of a new IT system, which might be available by early 2028.&lt;/p&gt;&lt;p&gt;The goal is to deliver usable, dependable, and affordable software to end users in the shortest feasible time. DevOps strives to accomplish this continuously throughout the entire software life cycle. While Agile and DevOps have proved successful for many organizations, they also have their share of controversy and pushback. Provocative reports claim Agile projects have a failure rate of up to 65 percent, while others claim up to 90 percent of DevOps initiatives fail to meet organizational expectations.&lt;/p&gt;&lt;p&gt;It is best to be wary of these claims while also acknowledging that successfully implementing Agile or DevOps methods takes consistent leadership, organizational discipline, patience, investment in training, and culture change. However, the same requirements have always been true when introducing any new software platform. Given the historic lack of organizational resolve to instill proven practices, it is not surprising that novel approaches for developing and sustaining ever more complex software systems, no matter how effective they may be, will also frequently fall short.&lt;/p&gt;&lt;head rend="h2"&gt;Persisting in Foolish Errors&lt;/head&gt;&lt;p&gt;The frustrating and perpetual question is why basic IT project-management and governance mistakes during software development and operations continue to occur so often, given the near-total societal reliance on reliable software and an extensively documented history of failures to learn from? Next to electrical infrastructure, with which IT is increasingly merging into a mutually codependent relationship, the failure of our computing systems is an existential threat to modern society.&lt;/p&gt;&lt;p&gt;Frustratingly, the IT community stubbornly fails to learn from prior failures. IT project managers routinely claim that their project is somehow different or unique and, thus, lessons from previous failures are irrelevant. That is the excuse of the arrogant, though usually not the ignorant. In Phoenix‚Äôs case, for example, it was the government‚Äôs second payroll-system replacement attempt, the first effort ending in failure in 1995. Phoenix project managers ignored the well-documented reasons for the first failure because they claimed its lessons were not applicable, which did nothing to keep the managers from repeating them. As it‚Äôs been said, we learn more from failure than from success, but repeated failures are damn expensive.&lt;/p&gt;&lt;head rend="h3"&gt;Jaguar Land Rover&lt;/head&gt;&lt;p&gt;Alamy&lt;/p&gt;&lt;p&gt;2025&lt;/p&gt;&lt;p&gt;A cyberattack forced Jaguar Land Rover, Britain‚Äôs largest automaker, to shut down its global operations for over a month. An initial FAIR-MAM assessment, a cybersecurity-cost-model, estimates the loss for Jaguar Land Rover to be between $1.2 billion and $1.9 billion (¬£911 million and ¬£1.4 billion), which has affected its 33,000 employees and some 200,000 employees of its suppliers.&lt;/p&gt;&lt;p&gt;Not all software development failures are bad; some failures are even desired. When pushing the limits of developing new types of software products, technologies, or practices, as is happening with AI-related efforts, potential failure is an accepted possibility. With failure, experience increases, new insights are gained, fixes are made, constraints are better understood, and technological innovation and progress continue. However, most IT failures today are not related to pushing the innovative frontiers of the computing art, but the edges of the mundane. They do not represent Austrian economist Joseph Schumpeter‚Äôs ‚Äúgales of creative destruction.‚Äù They‚Äôre more like gales of financial destruction. Just how many more enterprise resource planning (ERP) project failures are needed before success becomes routine? Such failures should be called IT blunders, as learning anything new from them is dubious at best.&lt;/p&gt;&lt;p&gt;Was Phoenix a failure or a blunder? I argue strongly for the latter, but at the very least, Phoenix serves as a master class in IT project mismanagement. The question is whether the Canadian government learned from this experience any more than it did from 1995‚Äôs payroll-project fiasco? The government maintains it will learn, which might be true, given the Phoenix failure‚Äôs high political profile. But will Phoenix‚Äôs lessons extend to the thousands of outdated Canadian government IT systems needing replacement or modernization? Hopefully, but hope is not a methodology, and purposeful action will be necessary.&lt;/p&gt;&lt;p&gt;The IT community has striven mightily for decades to make the incomprehensible routine.&lt;/p&gt;&lt;p&gt;Repeatedly making the same mistakes and expecting a different result is not learning. It is a farcical absurdity. Paraphrasing Henry Petroski in his book To Engineer Is Human: The Role of Failure in Successful Design (Vintage, 1992), we may have learned how to calculate the software failure due to risk, but we have not learned how to calculate to eliminate the failure of the mind. There are a plethora of examples of projects like Phoenix that failed in part due to bumbling management, yet it is extremely difficult to find software projects managed professionally that still failed. Finding examples of what could be termed ‚ÄúIT heroic failures‚Äù is like Diogenes seeking one honest man.&lt;/p&gt;&lt;p&gt;The consequences of not learning from blunders will be much greater and more insidious as society grapples with the growing effects of artificial intelligence, or more accurately, ‚Äúintelligent‚Äù algorithms embedded into software systems. Hints of what might happen if past lessons go unheeded are found in the spectacular early automated decision-making failure of Michigan‚Äôs MiDAS unemployment and Australia‚Äôs Centrelink ‚ÄúRobodebt‚Äù welfare systems. Both used questionable algorithms to identify deceptive payment claims without human oversight. State officials used MiDAS to accuse tens of thousands of Michiganders of unemployment fraud, while Centrelink officials falsely accused hundreds of thousands of Australians of being welfare cheats. Untold numbers of lives will never be the same because of what occurred. Government officials in Michigan and Australia placed far too much trust in those algorithms. They had to be dragged, kicking and screaming, to acknowledge that something was amiss, even after it was clearly demonstrated that the software was untrustworthy. Even then, officials tried to downplay the errors‚Äô impact on people, then fought against paying compensation to those adversely affected by the errors. While such behavior is legally termed ‚Äúmaladministration,‚Äù administrative evil is closer to reality.&lt;/p&gt;&lt;head rend="h3"&gt;Lidl Enterprise Resource Planning (ERP)&lt;/head&gt;&lt;p&gt;Nicolas Guyonnet/Hans Lucas/AFP/Getty Images&lt;/p&gt;&lt;p&gt;2017&lt;/p&gt;&lt;p&gt;The international supermarket chain Lidl decides to revert to its homegrown legacy merchandise-management system after three years of trying to make SAP‚Äôs ‚Ç¨500 million enterprise resource planning (ERP) system work properly.&lt;/p&gt;&lt;p&gt;If this behavior happens in government organizations, does anyone think profit-driven companies whose AI-driven systems go wrong are going to act any better? As AI becomes embedded in ever more IT systems‚Äîespecially governmental systems and the growing digital public infrastructure, which we as individuals have no choice but to use‚Äîthe opaqueness of how these systems make decisions will make it harder to challenge them. The European Union has given individuals a legal ‚Äúright to explanation‚Äù when a purely algorithmic decision goes against them. It‚Äôs time for transparency and accountability regarding all automated systems to become a fundamental, global human right.&lt;/p&gt;&lt;p&gt;What will it take to reduce IT blunders? Not much has worked with any consistency over the past 20 years. The financial incentives for building flawed software, the IT industry‚Äôs addiction to failure porn, and the lack of accountability for foolish management decisions are deeply entrenched in the IT community. Some argue it is time for software liability laws, while others contend that it is time for IT professionals to be licensed like all other professionals. Neither is likely to happen anytime soon.&lt;/p&gt;&lt;head rend="h3"&gt;Boeing 737 Max&lt;/head&gt;David Ryder/ Getty Images&lt;p&gt;2018&lt;/p&gt;&lt;p&gt;Boeing adds poorly designed and described Maneuvering Characteristics Augmentation System (MCAS) to new 737 Max model creating safety problems leading to two fatal airline crashes killing 346 passengers and crew and grounding of fleet for some 20 months. Total cost to Boeing estimates at $14b in direct costs and $60b in indirect costs.&lt;/p&gt;&lt;p&gt;So, we are left with only a professional and personal obligation to reemphasize the obvious: Ask what you do know, what you should know, and how big the gap is between them before embarking on creating an IT system. If no one else has ever successfully built your system with the schedule, budget, and functionality you asked for, please explain why your organization thinks it can. Software is inherently fragile; building complex, secure, and resilient software systems is difficult, detailed, and time-consuming. Small errors have outsize effects, each with an almost infinite number of ways they can manifest, from causing a minor functional error to a system outage to allowing a cybersecurity threat to penetrate the system. The more complex and interconnected the system, the more opportunities for errors and their exploitation. A nice start would be for senior management who control the purse strings to finally treat software and systems development, operations, and sustainment efforts with the respect they deserve. This not only means providing the personnel, financial resources, and leadership support and commitment, but also the professional and personal accountability they demand.&lt;/p&gt;&lt;head rend="h3"&gt;F-35 Joint Strike Fighter&lt;/head&gt;&lt;p&gt;Staff Sgt .Zachary Rufus/ U.S. Air Force&lt;/p&gt;&lt;p&gt;2025&lt;/p&gt;&lt;p&gt;Software and hardware issues with the F-35 Block 4 upgrade continue unabated. The Block 4 upgrade program which started in 2018, and is intended to increase the lethality of the JSF aircraft has slipped to 2031 at earliest from 2026, with cost rising from $10.5 b to a minimum of $16.5b. It will take years more to rollout the capability to the F-35 fleet.&lt;/p&gt;&lt;p&gt;It is well known that honesty, skepticism, and ethics are essential to achieving project success, yet they are often absent. Only senior management can demand they exist. For instance, honesty begins with the forthright accounting of the myriad of risks involved in any IT endeavor, not their rationalization. It is a common ‚Äúsecret‚Äù that it is far easier to get funding to fix a troubled software development effort than to ask for what is required up front to address the risks involved. Vendor puffery may also be legal, but that means the IT customer needs a healthy skepticism of the typically too-good-to-be-true promises vendors make. Once the contract is signed, it is too late. Furthermore, computing‚Äôs malleability, complexity, speed, low cost, and ability to reproduce and store information combine to create ethical situations that require deep reflection about computing‚Äôs consequences on individuals and society. Alas, ethical considerations have routinely lagged when technological progress and profits are to be made. This practice must change, especially as AI is routinely injected into automated systems.&lt;/p&gt;&lt;p&gt;In the AI community, there has been a movement toward the idea of human-centered AI, meaning AI systems that prioritize human needs, values, and well-being. This means trying to anticipate where and when AI can go wrong, move to eliminate these situations, and build in ways to mitigate the effects if they do happen. This concept requires application to every IT system‚Äôs effort, not just AI.&lt;/p&gt;&lt;p&gt;Given the historic lack of organizational resolve to instill proven practices...novel approaches for developing and sustaining ever more complex software systems...will also frequently fall short.&lt;/p&gt;&lt;p&gt;Finally, project cost-benefit justifications of software developments rarely consider the financial and emotional distress placed on end users of IT systems when something goes wrong. These include the long-term failure after-effects. If these costs had to be taken fully into account, such as in the cases of Phoenix, MiDAS, and Centrelink, perhaps there could be more realism in what is required managerially, financially, technologically, and experientially to create a successful software system. It may be a forlorn request, but surely it is time the IT community stops repeatedly making the same ridiculous mistakes it has made since at least 1968, when the term ‚Äúsoftware crisis‚Äù was coined. Make new ones, damn it. As Roman orator Cicero said in Philippic 12, ‚ÄúAnyone can make a mistake, but only an idiot persists in his error.‚Äù&lt;/p&gt;&lt;p&gt;Special thanks to Steve Andriole, Hal Berghel, Matt Eisler, John L. King, Roger Van Scoy, and Lee Vinsel for their invaluable critiques and insights.&lt;/p&gt;&lt;p&gt;This article appears in the December 2025 print issue as ‚ÄúThe Trillion-Dollar Cost of IT‚Äôs Willful Ignorance.‚Äù&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Lessons From a Decade of IT Failures ‚Ä∫&lt;/item&gt;&lt;item&gt;We Need Better IT Project Failure Post-Mortems ‚Ä∫&lt;/item&gt;&lt;item&gt;Why Software Fails ‚Ä∫&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spectrum.ieee.org/it-management-software-failures"/><published>2025-11-25T12:14:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045661</id><title>Brain has five 'eras' with adult mode not starting until early 30s</title><updated>2025-11-25T16:49:07.695197+00:00</updated><content>&lt;doc fingerprint="2723832778b3ddf0"&gt;
  &lt;main&gt;
    &lt;p&gt;Scientists have identified five major ‚Äúepochs‚Äù of human brain development in one of the most comprehensive studies to date of how neural wiring changes from infancy to old age.&lt;/p&gt;
    &lt;p&gt;The study, based on the brain scans of nearly 4,000 people aged under one to 90, mapped neural connections and how they evolve during our lives. This revealed five broad phases, split up by four pivotal ‚Äúturning points‚Äù in which brain organisation moves on to a different trajectory, at around the ages of nine, 32, 66 and 83 years.&lt;/p&gt;
    &lt;p&gt;‚ÄúLooking back, many of us feel our lives have been characterised by different phases. It turns out that brains also go through these eras,‚Äù said Prof Duncan Astle, a researcher in neuroinformatics at Cambridge University and senior author of the study.&lt;/p&gt;
    &lt;p&gt;‚ÄúUnderstanding that the brain‚Äôs structural journey is not a question of steady progression, but rather one of a few major turning points, will help us identify when and how its wiring is vulnerable to disruption.‚Äù&lt;/p&gt;
    &lt;p&gt;The childhood period of development was found to occur between birth until the age of nine, when it transitions to the adolescent phase ‚Äì an era that lasts up to the age of 32, on average.&lt;/p&gt;
    &lt;p&gt;In a person‚Äôs early 30s the brain‚Äôs neural wiring shifts into adult mode ‚Äì the longest era, lasting more than three decades. A third turning point around the age of 66 marks the start of an ‚Äúearly ageing‚Äù phase of brain architecture. Finally, the ‚Äúlate ageing‚Äù brain takes shape at around 83 years old.&lt;/p&gt;
    &lt;p&gt;The scientists quantified brain organisation using 12 different measures, including the efficiency of the wiring, how compartmentalised it is and whether the brain relies heavily on central hubs or has a more diffuse connectivity network.&lt;/p&gt;
    &lt;p&gt;From infancy through childhood, our brains are defined by ‚Äúnetwork consolidation‚Äù, as the wealth of synapses ‚Äì the connectors between neurons ‚Äì in a baby‚Äôs brain are whittled down, with the more active ones surviving. During this period, the study found, the efficiency of the brain‚Äôs wiring decreases.&lt;/p&gt;
    &lt;p&gt;Meanwhile, grey and white matter grow rapidly in volume, so that cortical thickness ‚Äì the distance between outer grey matter and inner white matter ‚Äì reaches a peak, and cortical folding, the characteristic ridges on the outer brain, stabilises.&lt;/p&gt;
    &lt;p&gt;In the second ‚Äúepoch‚Äù of the brain, the adolescence era, white matter continues to grow in volume, so organisation of the brain‚Äôs communications networks is increasingly refined. This era is defined by steadily increasing efficiency of connections across the whole brain, which is related to enhanced cognitive performance. The epochs were defined by the brain remaining on a constant trend of development over a sustained period, rather than staying in a fixed state throughout.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe‚Äôre definitely not saying that people in their late 20s are going to be acting like teenagers, or even that their brain looks like that of a teenager,‚Äù said Alexa Mousley, who led the research. ‚ÄúIt‚Äôs really the pattern of change.‚Äù&lt;/p&gt;
    &lt;p&gt;She added that the findings could give insights into risk factors for mental health disorders, which most frequently emerge during the adolescent period.&lt;/p&gt;
    &lt;p&gt;At around the age of 32 the strongest overall shift in trajectory is seen. Life events such as parenthood may play a role in some of the changes seen, although the research did not explicitly test this. ‚ÄúWe know that women who give birth, their brain changes afterwards,‚Äù said Mousley. ‚ÄúIt‚Äôs reasonable to assume that there could be a relationship between these milestones and what‚Äôs happening in the brain.‚Äù&lt;/p&gt;
    &lt;p&gt;From 32 years, the brain architecture appears to stabilise compared with previous phases, corresponding with a ‚Äúplateau in intelligence and personality‚Äù based on other studies. Brain regions also become more compartmentalised.&lt;/p&gt;
    &lt;p&gt;The final two turning points were defined by decreases in brain connectivity, which were believed to be related to ageing and degeneration of white matter in the brain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/science/2025/nov/25/brain-human-cognitive-development-life-stages-cambridge-study"/><published>2025-11-25T13:38:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045972</id><title>Apt Rust requirement raises questions</title><updated>2025-11-25T16:49:07.058137+00:00</updated><content>&lt;doc fingerprint="a746d937ce0756d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;APT Rust requirement raises questions&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;quote&gt;
      &lt;head&gt;Welcome to LWN.net&lt;/head&gt;
      &lt;p&gt;The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider subscribing to LWN. Thank you for visiting LWN.net!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It is rarely newsworthy when a project or package picks up a new dependency. However, changes in a core tool like Debian's Advanced Package Tool (APT) can have far-reaching effects. For example, Julian Andres Klode's declaration that APT would require Rust in May 2026 means that a few of Debian's unofficial ports must either acquire a working Rust toolchain or depend on an old version of APT. This has raised several questions within the project, particularly about the ability of a single maintainer to make changes that have widespread impact.&lt;/p&gt;
    &lt;p&gt;On October 31, Klode sent an announcement to the debian-devel mailing list that he intended to introduce Rust dependencies and code into APT as soon as May 2026:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This extends at first to the Rust compiler and standard library, and the Sequoia ecosystem.&lt;/p&gt;
      &lt;p&gt;In particular, our code to parse .deb, .ar, .tar, and the HTTP signature verification code would strongly benefit from memory safe languages and a stronger approach to unit testing.&lt;/p&gt;
      &lt;p&gt;If you maintain a port without a working Rust toolchain, please ensure it has one within the next 6 months, or sunset the port.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Klode added this was necessary so that the project as a whole could move forward, rely on modern technologies, "&lt;quote&gt;and not be held back by trying to shoehorn modern software on retro computing devices&lt;/quote&gt;". Some Debian developers have welcomed the news. Paul Tagliamonte acknowledged that it would impact unofficial Debian ports but called the push toward Rust "&lt;quote&gt;welcome news&lt;/quote&gt;".&lt;/p&gt;
    &lt;p&gt;However, John Paul Adrian Glaubitz complained that Klode's wording was unpleasant and that the approach was confrontational. In another message, he explained that he was not against adoption of Rust; he had worked on enabling Rust on many of the Debian architectures and helped to fix architecture-specific bugs in the Rust toolchain as well as LLVM upstream. However, the message strongly suggested there was no room for a change in plan: Klode had ended his message with "&lt;quote&gt;thank you for understanding&lt;/quote&gt;", which invited no further discussion. Glaubitz was one of a few Debian developers who expressed discomfort with Klode's communication style in the message.&lt;/p&gt;
    &lt;p&gt;Klode noted, briefly, that Rust was already a hard requirement for all Debian release architectures and ports, except for Alpha (alpha), Motorola 680x0 (m68k), PA-RISC (hppa), and SuperH (sh4), because of APT's use of the Sequoia-PGP project's sqv tool to verify OpenPGP signatures. APT falls back to using the GNU Privacy Guard signature-verification tool, gpgv, on ports that do not have a Rust compiler. By depending directly on Rust, though, APT itself would not be available on ports without a Rust compiler. LWN recently covered the state of Linux architecture support, and the status of Rust support for each one.&lt;/p&gt;
    &lt;p&gt;None of the ports listed by Klode are among those officially supported by Debian today, or targeted for support in Debian 14 ("forky"). The sh4 port has never been officially supported, and none of the other ports have been supported since Debian 6.0. The actual impact on the ports lacking Rust is also less dramatic than it sounded at first. Glaubitz assured Antoni Boucher that "&lt;quote&gt;the ultimatum that Julian set doesn't really exist&lt;/quote&gt;", but phrasing it that way "&lt;quote&gt;gets more attention in the news&lt;/quote&gt;". Boucher is the maintainer of rust_codegen_gcc, a GCC ahead-of-time code generator for Rust. Nothing, Glaubitz said, stops ports from using a non-Rust version of APT until Boucher and others manage to bootstrap Rust for those ports.&lt;/p&gt;
    &lt;head rend="h4"&gt;Security theater?&lt;/head&gt;
    &lt;p&gt;David Kalnischkies, who is also a major contributor to APT, suggested that if the goal is to reduce bugs, it would be better to remove the code that is used to parse the .deb, .ar, and .tar formats that Klode mentioned from APT entirely. It is only needed for two tools, apt-ftparchive and apt-extracttemplates, he said, and the only "&lt;quote&gt;serious usage&lt;/quote&gt;" of apt-ftparchive was by Klode's employer, Canonical, for its Launchpad software-collaboration platform. If those were taken out of the main APT code base, then it would not matter whether they were written in Rust, Python, or another language, since the tools are not directly necessary for any given port.&lt;/p&gt;
    &lt;p&gt;Kalnischkies also questioned the claim that Rust was necessary to achieve the stronger approach to unit testing that Klode mentioned:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You can certainly do unit tests in C++, we do. The main problem is that someone has to write those tests. Like docs.&lt;/p&gt;
      &lt;p&gt;Your new solver e.g. has none (apart from our preexisting integration tests). You don't seriously claim that is because of C++ ? If you don't like GoogleTest, which is what we currently have, I could suggest doctest (as I did in previous installments). Plenty other frameworks exist with similar or different styles.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Klode has not responded to those comments yet, which is a bit unfortunate given the fact that introducing hard dependencies on Rust has an impact beyond his own work on APT. It may well be that he has good answers to the questions, but it can also give the impression that Klode is simply embracing a trend toward Rust. He is involved in the Ubuntu work to migrate from GNU Coreutils to the Rust-based uutils. The reasons given for that work, again, are around modernization and better security‚Äîbut security is not automatically guaranteed simply by switching to Rust, and there are a number of other considerations.&lt;/p&gt;
    &lt;p&gt;For example, Adrian Bunk pointed out that there are a number of Debian teams, as well as tooling, that will be impacted by writing some of APT in Rust. The release notes for Debian 13 ("trixie") mention that Debian's infrastructure "&lt;quote&gt;currently has problems with rebuilding packages of types that systematically use static linking&lt;/quote&gt;", such as those with code written in Go and Rust. Thus, "&lt;quote&gt;these packages will be covered by limited security support until the infrastructure is improved to deal with them maintainably&lt;/quote&gt;". Limited security support means that updates to Rust libraries are likely to only be released when Debian publishes a point release, which happens about every two months. The security team has specifically stated that sqv is fully supported, but there are still outstanding problems.&lt;/p&gt;
    &lt;p&gt;Due to the static-linking issue, any time one of sqv's dependencies, currently more than 40 Rust crates, have to be rebuilt due to a security issue, sqv (at least potentially) also needs to be rebuilt. There are also difficulties in tracking CVEs for all of its dependencies, and understanding when a security vulnerability in a Rust crate may require updating a Rust program that depends on it.&lt;/p&gt;
    &lt;p&gt;Fabian Gr√ºnbichler, a maintainer of Debian's Rust toolchain, listed several outstanding problems Debian has with dealing with Rust packages. One of the largest is the need for a consistent Debian policy for declaring statically linked libraries. In 2022, Guillem Jover added a control field for Debian packages called Static-Built-Using (SBU), which would list the source packages used to build a binary package. This would indicate when a binary package needs to be rebuilt due to an update in another source package. For example, sqv depends on more than 40 Rust crates that are packaged for Debian. Without declaring the SBUs, it may not be clear if sqv needs to be updated when one of its dependencies is updated. Debian has been working on a policy requirement for SBU since April 2024, but it is not yet finished or adopted.&lt;/p&gt;
    &lt;p&gt;The discussion sparked by Gr√ºnbichler makes clear that most of Debian's Rust-related problems are in the process of being solved. However, there's no evidence that Klode explored the problems before declaring that APT would depend on Rust, or even asked "is this a reasonable time frame to introduce this dependency?"&lt;/p&gt;
    &lt;head rend="h4"&gt;Where tradition meets tomorrow&lt;/head&gt;
    &lt;p&gt;Debian's tagline, or at least one of its taglines, is "the universal operating system", meaning that the project aims to run on a wide variety of hardware (old and new) and be usable on the desktop, server, IoT devices, and more. The "Why Debian" page lists a number of reasons users and developers should choose the distribution: multiple hardware architectures, long-term support, and its democratic governance structure are just a few of the arguments it puts forward in favor of Debian. It also notes that "&lt;quote&gt;Debian cannot be controlled by a single company&lt;/quote&gt;". A single developer employed by a company to work on Debian tools pushing a change that seems beneficial to that company, without discussion or debate, that impacts multiple hardware architectures and that requires other volunteers to do unplanned work or meet an artificial deadline seems to go against many of the project's stated values.&lt;/p&gt;
    &lt;p&gt;Debian, of course, does have checks and balances that could be employed if other Debian developers feel it necessary. Someone could, for example, appeal to Debian's Technical Committee, or sponsor a general resolution to override a developer if they cannot be persuaded by discussion alone. That happened recently when the committee required systemd maintainers to provide the /var/lock directory "&lt;quote&gt;until a satisfactory migration of impacted software has occurred and Policy updated accordingly&lt;/quote&gt;".&lt;/p&gt;
    &lt;p&gt;However, it also seems fair to point out that Debian can move slowly, even glacially, at times. APT added support for the DEB822 format for its source information lists in 2015. Despite APT supporting that format for years, Klode faced resistance in 2021, when he pushed for Debian to move to the new format ahead of the Debian 12 ("bookworm") release in 2021, but was unsuccessful. It is now the default for trixie with the move to APT 3.0, though APT will continue to support the old format for years to come.&lt;/p&gt;
    &lt;p&gt;The fact is, regardless of what Klode does with APT, more and more free software is being written (or rewritten) in Rust. Making it easier to support that software when it is packaged for Debian is to everyone's benefit. Perhaps the project needs some developers who will be aggressive about pushing the project to move more quickly in improving its support for Rust. However, what is really needed is more developers lending a hand to do the work that is needed to support Rust in Debian and elsewhere, such as gccrs. It does not seem in keeping with Debian's community focus for a single developer to simply declare dependencies that other volunteers will have to scramble to support.&lt;/p&gt;
    &lt;p&gt; Posted Nov 24, 2025 16:42 UTC (Mon) by atai (subscriber, #10977) [Link] (4 responses) Posted Nov 24, 2025 16:53 UTC (Mon) by epa (subscriber, #39769) [Link] (1 responses) Posted Nov 24, 2025 17:14 UTC (Mon) by ojeda (subscriber, #143370) [Link] `rustc_codegen_clr` has such a mode, and there was also another start on a new C backend for `rustc`. Neither is "production ready", but it is a nice approach, and in fact it is not uncommon for languages to design their compilers that way. Posted Nov 24, 2025 16:53 UTC (Mon) by jmm (subscriber, #34596) [Link] Posted Nov 24, 2025 16:56 UTC (Mon) by farnz (subscriber, #17727) [Link] The other route is to contribute to things like gccrs or rust_codegen_gcc, so that Rust is available on these ports, too. This has the slight advantage that, once you have Rust support, any other packages in Debian that need Rust become buildable for that port. Posted Nov 24, 2025 17:02 UTC (Mon) by ballombe (subscriber, #9523) [Link] (88 responses) I am very reticent to lose that by moving to rust, especially since there is no strictly technical reasons, Rebuilding packages to update their dependencies is not sustainable for Debian. Posted Nov 24, 2025 17:26 UTC (Mon) by DemiMarie (subscriber, #164188) [Link] (76 responses) Even in C++, you already need to do this to pull in fixes made to a template, because templates are located in the header file. Most other natively-compiled languages also require such rebuilding. When it comes to new languages, Swift and maybe Hare are the only exceptions I know of. None of these languages are being developed or funded by distros. They are all developed and funded by companies that can and do rebuild their programs from source and link statically without any issues. Distros are complaining that there is a problem without doing a substantial fraction of upstream maintenance on Cargo, rustc, GHC, Go, or any of the other toolchains. If distros want ecosystems to be more friendly to them, they need to put in the (large) amount of work to make that happen. It‚Äôs not impossible, but it is very difficult, and it has ecosystem-wide implications. Until they do, they get to use whatever the people who do do this work choose to make. Posted Nov 24, 2025 17:31 UTC (Mon) by fishface60 (subscriber, #88700) [Link] Hopefully the likes of Canonical, Red Hat or possibly Valve will step up to fund this, since it doesn't seem realistic to expect volunteer distributions like Debian to do the work. Posted Nov 24, 2025 17:49 UTC (Mon) by bluca (subscriber, #118303) [Link] (67 responses) Then the future is shite Posted Nov 24, 2025 18:07 UTC (Mon) by Wol (subscriber, #4433) [Link] (20 responses) &amp;gt; Then the future is shite Or you go back to what I was doing over 40 years ago, when a library was just that ... Yes you'll need some thought about how to update it into the modern world, but you static link and your library is a bunch of .o's that get copied in. Yes you need to rebuild your applications, but the compile load is so much lower. And if you really want to sort-of-merge your compiler and linker, okay you won't be able to mix-n-match compilers in all likelihood, but instead of .o's you compile the library to intermediate compiler representation, optimise whatever hell you can out of it, and then dump that into a .lib file that the compiler can pull into the application. Okay, you lose the ability to just drop in a new fixed library, that fixes all your apps in one hit, but how well does that really work in practice? Cheers, Posted Nov 24, 2025 20:12 UTC (Mon) by ballombe (subscriber, #9523) [Link] (13 responses) It work pretty well. For example each time a new CVE is fixed in libtiff, the libtiff library is upgraded and there is no need to rebuild every software that directly or indirectly process TIFF files. Making very costly to apply a security fix does not increase security. Posted Nov 25, 2025 8:54 UTC (Tue) by taladar (subscriber, #68407) [Link] (8 responses) Posted Nov 25, 2025 9:45 UTC (Tue) by leromarinvit (subscriber, #56850) [Link] (6 responses) If they don't, just setting APT to auto-install security updates, without somehow restarting individual services or the whole system afterwards, is clearly not enough to at least keep a system free of known (and fixed) vulnerabilities. Posted Nov 25, 2025 10:03 UTC (Tue) by taladar (subscriber, #68407) [Link] Posted Nov 25, 2025 10:05 UTC (Tue) by epa (subscriber, #39769) [Link] (4 responses) In principle a program could be re-linked against the new shared library code while it stays running, but that requires an even stronger ABI stability guarantee than most libraries provide. Posted Nov 25, 2025 11:26 UTC (Tue) by SLi (subscriber, #53131) [Link] (3 responses) Posted Nov 25, 2025 14:02 UTC (Tue) by farnz (subscriber, #17727) [Link] (2 responses) The point is that it's not that big a reduction in effort - and it's a reduction in effort in the automated part, to boot. Posted Nov 25, 2025 14:59 UTC (Tue) by intelfx (subscriber, #130118) [Link] (1 responses) Nobody is making the claim for shared libraries to somehow obviate the need to *restart the applications*. You invented this claim out of thin air. Shared libraries obviate the need to *update the binaries*, no more, no less. Posted Nov 25, 2025 15:12 UTC (Tue) by farnz (subscriber, #17727) [Link] The only thing they do is mean that you don't have to replace the executables - but replacing binaries (libraries or executables) is the bit of the update process that's simple to automate. Posted Nov 25, 2025 16:02 UTC (Tue) by draco (subscriber, #1792) [Link] You keep saying distros don't handle this case, but they do. Posted Nov 25, 2025 12:17 UTC (Tue) by NAR (subscriber, #1313) [Link] (3 responses) Posted Nov 25, 2025 14:06 UTC (Tue) by farnz (subscriber, #17727) [Link] (2 responses) Imagine a new version of libtiff which introduces a security-relevant bug into the decompressor for TIFF compression scheme 32809 (ThunderScan 4-bit RLE). Upstream's statically linked builds of the program are not vulnerable, because they don't enable the bits of libtiff needed to handle files from ancient Macs, but because your distro includes a utility that's supposed to analyse an ancient Mac disk image and convert all the data to modern formats that you can work with, your distro build of libtiff has this support enabled. Hey presto, an application that was not vulnerable in the upstream configuration (and may not be vulnerable on other distros that don't support reading TIFF files from ancient Macs) is now vulnerable, because you're running a configuration of the code that's necessary for a different application. Worst case, you've opened up a network-accessible vulnerability in an application that was unaware that you could build libtiff this way, in order to give more functionality to an application that's carefully sandboxed in case the files are corrupt and trigger a bug. Posted Nov 25, 2025 15:10 UTC (Tue) by paulj (subscriber, #341) [Link] (1 responses) Which scenario is the more common? Which has the better track record at quickly updating to fix bugs? The random statically linked upstream-packaged apps or the Linux distros? I'd say the distros. But let's say Linux distros are just average. Say we have 100 upstream-packaged statically-linked apps, and 100 apps using the distro shared library... ~50 of the upstream apps will update before the distro, and ~50 after - with a long tail. So - even if distros are not very good at shipping security updates, the statically linked approach will still leave you with a number of vulnerable apps for a long time to come. Posted Nov 25, 2025 15:18 UTC (Tue) by farnz (subscriber, #17727) [Link] Note that the distro is quite capable of using the dependency information it already has (BuildRequires and the like) to rebuild statically linked binaries - dynamically linked versus statically linked is more about how much automated work has to be done to get you a fixed version in place, rather than about which is "more secure". And I don't believe anyone has done the study to determine which is actually more secure in practice - static linked executables, with unused parts of libraries turned off, or dynamically linked executables sharing a library with more used components. Once you allow for things like time to determine that an update is needed, it's quite a complex space to think about, and (like so much in computing), we're more going on "what feels right" than on hard data. Posted Nov 24, 2025 20:25 UTC (Mon) by ebee_matteo (subscriber, #165284) [Link] (5 responses) &amp;gt; &amp;gt; Then the future is shite &amp;gt; Or you go back to what I was doing over 40 years ago, when a library was just that ... You can also go back at the beginning of UNIX and use IPC across small binaries to perform tasks. Many people here still like their pipes on the shell. I see it a good pattern in keeping programs small and then using IPC to make them communicate, via pipes / sockets and gRPC / varlink / DBus / anything. That for me would be a better future... Posted Nov 24, 2025 20:37 UTC (Mon) by willy (subscriber, #9762) [Link] (4 responses) At this point I hope you realize you've merely restated the problem, not solved it. Posted Nov 24, 2025 21:29 UTC (Mon) by DemiMarie (subscriber, #164188) [Link] (3 responses) Server software is often shipped as containers nowadays, and containers don‚Äôt benefit much from dynamic linking. In fact, static linking is often considered a benefit in the server world due to ease of deployment. Embedded systems do benefit from dynamic linking, and Android uses dynamic linking for its Rust crates. However, updates for embedded devices are usually complete images, so ABI stability is of very little value. The only advantage would be allowing binary dependencies to use Rust APIs. The systems that benefit greatly from ABI stability are ‚Äútraditional‚Äù distros with mutable root filesystems. However, none of them have been willing to fund the needed improvements. Furthermore, many of these distros are run by volunteers. Like fishface60, I hope that Canonical, SUSE, Red Hat, or Valve steps up and funds a solution. Posted Nov 24, 2025 23:17 UTC (Mon) by bluca (subscriber, #118303) [Link] Except of course that's not really true, as proven by companies like Redhat spending tons of dev time to implement very, very complex solutions to post-facto deduplicate said containers, because that whole docker mess doesn't really scale beyond a handful of instances. Storage, memory and loading time costs are through the roof because of the intense duplication. Posted Nov 25, 2025 8:58 UTC (Tue) by taladar (subscriber, #68407) [Link] (1 responses) Posted Nov 25, 2025 13:35 UTC (Tue) by khim (subscriber, #9252) [Link] The funding is not there because there are no actor who may benefit from that work and have some money to spare. Google and Microsoft don't have an incentive to fund anything like that because they are not providing Rust ABIs (at least not yet) and distros are not in position to develop anything and don't even feel it's their responsibility to develop anything. Story about ‚Äúawful inlining‚Äù is entirely moot point: you have the same thing with Posted Nov 24, 2025 18:42 UTC (Mon) by keithp (subscriber, #5140) [Link] (27 responses) So, you either get responsible language design with actual type checking across interfaces, or you get shared libraries. I haven't seen any plan for getting both. It kinda sucks, but given that I have to make a choice, I know which I'm willing to accept. At this point, I'd assume any time a package using Rust anywhere should trigger a rebuild of any reverse dependencies, at least until policy tells us how to avoid that. Posted Nov 24, 2025 18:57 UTC (Mon) by ballombe (subscriber, #9523) [Link] (9 responses) Posted Nov 24, 2025 21:05 UTC (Mon) by DemiMarie (subscriber, #164188) [Link] Posted Nov 24, 2025 21:27 UTC (Mon) by mb (subscriber, #50428) [Link] Posted Nov 25, 2025 12:02 UTC (Tue) by farnz (subscriber, #17727) [Link] (6 responses) Polymorphism is absolutely fine as long as you are aware that this means that the polymorphic parts of your library live in the caller's binary, not in your binary. Same with defined constants in a header, struct layout etc. The thing that you need is something that tells you when you've modified something that will be in the caller's binary, not your binary, so that you can undo that breakage. Ideally, you'd also have a way to "shim" your new library, so that old binaries can still link against the new library, and go via the shim that fixes things up so that they continue to work without a rebuild. But this is a really hard tool to develop; there's a lot hiding in those two sentences. Even just doing the "modified something that will cause breakage" for static linking is hard; and dynamic linking ups the difficulty a notch. Posted Nov 25, 2025 13:38 UTC (Tue) by khim (subscriber, #9252) [Link] (5 responses) This would only work if your library provides ABI without things like Posted Nov 25, 2025 13:56 UTC (Tue) by farnz (subscriber, #17727) [Link] (4 responses) Second, I didn't say that you can't have polymorphism; I said that you have to be aware that your polymorphic components live outside your binary. You can have, for example, pub fn foo&amp;lt;P: AsRef&amp;lt;Path&amp;gt;&amp;gt;(path: P) -&amp;gt; u32 { foo_impl(path.as_ref() }, as long as you are happy that foo is inlined into the caller's binary, while fn foo_impl(path: &amp;amp;Path) -&amp;gt; u32 is in your binary. The important part is that you're aware of what's in your dynamic library, and what's outside it, and that you have a way to cope with the subset of your code that's in the caller not changing when your dynamic library changes. That might be shims and symbol versions like glibc, or not changing things once they've been exposed in a way that breaks the ABI. Posted Nov 25, 2025 14:32 UTC (Tue) by khim (subscriber, #9252) [Link] (3 responses) Yes. But not with Rust as it exists today. Even Well‚Ä¶ compiler upgrade [potentially] break ABI which means you would have to specify precisely which version of the compiler defines it‚Ä¶ and never upgrade. RenderScript tried that and died as a result, Apple ended up in the exact same potion, etc. You couldn't build a stable platform on a quicksand. Posted Nov 25, 2025 15:09 UTC (Tue) by farnz (subscriber, #17727) [Link] (2 responses) Indeed, you might well end up with a v1, v2, v3 etc stable ABI, where v1 is what we thought was good enough next year, v2 is a decade later with all the small improvements that we've accumulated since v1 was marked stable, with downstream users deciding when it's worth moving to a new version of the ABI and breaking older binaries - or even provide a stable ABI v1 shim that uses the stable ABI v5 code to implement things, and does whatever is needed to get compatibility (copies of data structures etc). But that's something the compiler team has to commit to. None of this works if the compiler team won't stabilize the ABI (replacing the compiler version dependency with a stable ABI version dependency). Posted Nov 25, 2025 15:18 UTC (Tue) by khim (subscriber, #9252) [Link] (1 responses) Then what's the point of limiting the whole thing to statically known types? Polymorphic ABIs work with the compiler buy-in just fine: there are Swift, C#, Java, Ada‚Ä¶ it's not a rocket science, it's well-tested tech. Know for decades, not years. Posted Nov 25, 2025 15:33 UTC (Tue) by farnz (subscriber, #17727) [Link] Mine is that the provider of a library with a stable ABI needs to be aware of what they're actually offering - what parts have to be kept stable (including because they're embedded in user code - e.g. user code knows this is a thin pointer, ergo you can't change it to a fat pointer, or user code knows this data structure is 108 bytes in size, so that can't change), and what parts are safe to change (e.g. user code calls into your library at this point, so you can change the implementation). Note that you might want to allow some of your library code to be inlined for performance - e.g. Vec::len is something you'd want inlined, you might want to inline most of Vec::push, only calling out-of-line code if the Vec needs to grow, for two examples. And when you do that, you need to know that part of your stable ABI is ensuring that the inlined parts still work as designed, even if the parts that you've kept in your shared binary are changing. Posted Nov 24, 2025 21:16 UTC (Mon) by zyga (subscriber, #81533) [Link] (8 responses) Apple paid for that support in Swift so that apps for their platforms can benefit from base OS library updates without having to be rebuilt. Rust and Go didn't have the money or desire to implement that, respectively. I recommend reading what Swift can do today, on Linux. You can load a library with a type. Load another with a container and efficiently instantiate container specialized with that type, all with dynamic libararies and stable ABIs. It is compiler voodoo but it is not impossible. I kind of think we are all doomed in the long run (e.g. imagine all of GTK and Qt are written in rust and require a complete world rebuild for every tiny update). IMO that is not scalable and the trend to move to Rust or another langue like that, will bounce at some point. Either someone steps in and does the heavy lifting to solve this problem, or distributions will just grind down to a halt. Posted Nov 24, 2025 21:50 UTC (Mon) by zyga (subscriber, #81533) [Link] (2 responses) Posted Nov 25, 2025 12:17 UTC (Tue) by paulj (subscriber, #341) [Link] (1 responses) Posted Nov 25, 2025 13:40 UTC (Tue) by khim (subscriber, #9252) [Link] Posted Nov 24, 2025 23:15 UTC (Mon) by DemiMarie (subscriber, #164188) [Link] (2 responses) Posted Nov 25, 2025 2:11 UTC (Tue) by khim (subscriber, #9252) [Link] (1 responses) That can be solved by declaring that thing an ‚Äústd-only‚Äù feature. There's nothing impossible there, but it's a lot of work‚Äîmeans it's unlikely to happen without serious funding‚Ä¶ who can provide it? Posted Nov 25, 2025 6:52 UTC (Tue) by josh (subscriber, #17465) [Link] We're working on it, though. Posted Nov 25, 2025 9:01 UTC (Tue) by taladar (subscriber, #68407) [Link] (1 responses) Posted Nov 25, 2025 10:25 UTC (Tue) by intelfx (subscriber, #130118) [Link] It would have been smaller in source code, but not in binary, for obvious reasons: it might not need to reimplement an ecosystem of dependencies, but the object code generated from those dependencies would still have to exist somewhere. Unless, of course, it was a hypothetical *shared* Rust library, linking to *shared* Rust libraries of those dependencies. Right. Posted Nov 25, 2025 14:23 UTC (Tue) by gspr (subscriber, #91542) [Link] (7 responses) For example, take the directed graph of dependencies between Rust packages in Debian. Pick any package that is not a library (i.e. not a librust-foo-dev package). This package surely uses, in its dependencies, either monomorphized versions of functions and types, or dynamic dispatch. Note down all the monomorphized versions, and add them to a list for each dependency. Traverse the graph in topological order, and build these monomorphization lists for all dependencies. Then build all library packages as shared objects with all of those monomorphic instances explicitly stamped out (I understand there's no compiler support for this at the moment, but it shouldn't be too hard to fake it by generating stubs?). Will this not allow dynamic linking and bug-fixing in shared objects *within* Debian at least? For a given compiler version, of course. Non-Debian software that uses the libraries are no better off than before (unless they happen to need the same monomorphizations), but they're also no worse off. I'm sure I'm overlooking something here, but I'd love to learn :) Posted Nov 25, 2025 14:39 UTC (Tue) by farnz (subscriber, #17727) [Link] (6 responses) You end up with the same problem as the rebuild problem, since you cannot determine ahead of time that no bug fixes will involve a new monomorphization. You will probably reduce the number of total rebuilds you need, but if you're unlucky, you won't. Posted Nov 25, 2025 14:43 UTC (Tue) by gspr (subscriber, #91542) [Link] (5 responses) Is that likely? Or, is it any more more likely than, say, a bugfix in a classical C library needing to break the ABI? Posted Nov 25, 2025 14:46 UTC (Tue) by farnz (subscriber, #17727) [Link] (4 responses) Posted Nov 25, 2025 14:51 UTC (Tue) by gspr (subscriber, #91542) [Link] (3 responses) Definitely. But a similar change in a classical C library would be to return a new error value. That wouldn't technically break the ABI, but it would sure require depending packages to acquire knowledge of the new error value. That would take *more* than just recompiling. I guess what I'm saying is that this approach doesn't always work, but it's not much worse than the situation for classical C libraries. Posted Nov 25, 2025 14:59 UTC (Tue) by farnz (subscriber, #17727) [Link] (2 responses) For example, if I truncate the error value to 8 bits to make it fit an existing struct, because all known error values are under 255, and you introduce error value 256, I've got a problem in C. This gets worse in Rust, because enums aren't just a value, they can carry data, too, so the enum may get larger as a result of the change, and upstream won't care that the old enum compiled by Debian was 72 bytes, and the new one is 80 bytes - especially if compiled with a newer compiler, they're both 64 bytes. Posted Nov 25, 2025 15:34 UTC (Tue) by gspr (subscriber, #91542) [Link] (1 responses) Posted Nov 25, 2025 15:42 UTC (Tue) by farnz (subscriber, #17727) [Link] Remember that the state we're in with C is in part because the language requires programmers to get it right, or risk UB, and as a result, C programmers doing security fixes tend to be thinking about all the ways they can accidentally break someone; Rust programmers tend not to be doing that, because the result of breaking someone is a compiler error, not UB. That cultural difference matters, and is part of why the aim on the Rust side is to have a state where swapping in an incompatible dynamic library is a dynamic linker failure, not UB as it is in C. Posted Nov 24, 2025 19:03 UTC (Mon) by carlosrodfern (subscriber, #166486) [Link] (7 responses) Posted Nov 24, 2025 22:25 UTC (Mon) by Cyberax (‚ú≠ supporter ‚ú≠, #52523) [Link] (3 responses) Android uses this for the OTA system updates. Posted Nov 24, 2025 23:39 UTC (Mon) by carlosrodfern (subscriber, #166486) [Link] (1 responses) The fact that statically linked programs are a good solution in containers doesn't mean that it can be extrapolated to an Linux distro. A slightly change in the nature of a problem, or in the size of the problem, can justifies a very different solution. It is a typical mistake that people make as they get excited about one technology or approach and want to apply it to all the things that like like a nail. Statically linked programs written in golang or Rust for containers make a lot of sense since the pros are weighty and the cons are not that significant in the context of that use case, but it is not a good approach for all the programs in Linux distros. Posted Nov 25, 2025 0:49 UTC (Tue) by Cyberax (‚ú≠ supporter ‚ú≠, #52523) [Link] But it's not really a problem, is it? Binary diffs for patch update can negate the advantages of shared libraries. &amp;gt; The fact that statically linked programs are a good solution in containers doesn't mean that it can be extrapolated to an Linux distro. But maybe it can? I actually tried a fully static distro a while ago ( https://github.com/oasislinux/oasis ), and it objectively felt _better_ than regular Debian. I'm not at all convinced that shared libraries are worth all the hassle. Posted Nov 25, 2025 7:54 UTC (Tue) by joib (subscriber, #8541) [Link] So the tech to do this efficiently already exists in open source, it just needs to be integrated more deeply into distro package distribution tooling. Posted Nov 25, 2025 6:39 UTC (Tue) by mb (subscriber, #50428) [Link] (2 responses) negligible &amp;gt;program load time Probably faster with statically linked binaries. &amp;gt;configurability What? Posted Nov 25, 2025 11:11 UTC (Tue) by euclidian (subscriber, #145308) [Link] Theoretically for basic cases when the binary gets recompiled with the same static library you get the de-duplication from dynamic libraries plus inlining and versioning working (just loosing the de-duplication). I doubt it would ever work well enough for production use (first load of a program) and i got side tracked dealing with edge cases but it might be something I should poke again. Posted Nov 25, 2025 11:22 UTC (Tue) by LtWorf (subscriber, #124958) [Link] Posted Nov 24, 2025 19:27 UTC (Mon) by Cyberax (‚ú≠ supporter ‚ú≠, #52523) [Link] (9 responses) Posted Nov 24, 2025 23:14 UTC (Mon) by bluca (subscriber, #118303) [Link] (8 responses) Posted Nov 25, 2025 0:51 UTC (Tue) by Cyberax (‚ú≠ supporter ‚ú≠, #52523) [Link] (7 responses) It's so much better to precompile everything into "Component A", so that it need not care if anything on disk changes. Posted Nov 25, 2025 6:48 UTC (Tue) by koflerdavid (subscriber, #176408) [Link] (3 responses) Atomic distributions handle this by creating a new file system image in the background, and the user boots into the updated system. Posted Nov 25, 2025 9:06 UTC (Tue) by taladar (subscriber, #68407) [Link] (2 responses) Posted Nov 25, 2025 14:37 UTC (Tue) by NightMonkey (subscriber, #23051) [Link] For example, I use this to upgrade religiously: emerge -uDNv --with-bdeps y system world --keep-going --jobs --load-average 8 Posted Nov 25, 2025 15:26 UTC (Tue) by ballombe (subscriber, #9523) [Link] Posted Nov 25, 2025 6:53 UTC (Tue) by josh (subscriber, #17465) [Link] (2 responses) Whether you're dealing with a replacement of component A, or a replacement of library B, either way, you *always* write to a temporary file and rename over the original, so that the old inode still exists as the source of the mmap'd code, and then restart A. Writing over the original will cause segfaults. Posted Nov 25, 2025 9:08 UTC (Tue) by taladar (subscriber, #68407) [Link] (1 responses) Posted Nov 25, 2025 12:03 UTC (Tue) by draco (subscriber, #1792) [Link] Posted Nov 24, 2025 19:22 UTC (Mon) by ibukanov (subscriber, #3942) [Link] (4 responses) Posted Nov 24, 2025 20:20 UTC (Mon) by ojeda (subscriber, #143370) [Link] There is no standard C++ ABI, though vendors try to help to some degree. As for unsafe calls, that is the same as in C++, i.e. every call is unsafe. By the way, in Rust you can easily specify nowadays that an external function is safe, e.g. Posted Nov 24, 2025 20:20 UTC (Mon) by ebee_matteo (subscriber, #165284) [Link] (2 responses) Except when it hasn't. ARMv5 ABI changed after GCC 7 (we all love our -Wno-psabi). C++11 also broke ABI in several ways. See GCC 5 and the libstdc++ versioning fiasco. `_GLIBCXX_USE_CXX11_ABI` for the win. GCC 11 broke ABI with GCC 10 due to std::span. jmp_buf has different ABI for s390 after glibc 2.19. I can cite more. Yes, C++ has slightly better ABI guarantees than Rust, but mostly just because its usage is widespread enough, across so many decades, that it came to be that way /de facto/ after people spent years fighting with ABI problems. And as other people have pointed out, you still have the issue of macros and templates to solve when you use the C++ headers. C is the closest we have to a stable ABI, assuming the same macros are defined at the time of inclusion. And you can write Rust programs exporting C mangled functions, and that works just fine also to produce shared libs. But that's the best you can do as of today. I guess at some point the pressure will be enough for Rust to standardize something resembling an ABI, but the widespread use of monomorphization makes it extremely tricky to do. C++ already had enough of problems with the infamous "extern template" feature of C++98, and now with C++ modules. Which, years after standardization, mostly still do not work. Posted Nov 24, 2025 22:48 UTC (Mon) by randomguy3 (subscriber, #71063) [Link] (1 responses) Posted Nov 24, 2025 23:06 UTC (Mon) by ballombe (subscriber, #9523) [Link] Posted Nov 25, 2025 11:20 UTC (Tue) by nim-nim (subscriber, #34454) [Link] (1 responses) Why should they ? The same developer-friendly argument was made for Java software, the same refusal to invest in a mechanism to share components and stabilise ABIs was advanced by Java developers, the same hostility to distribution best practices was trumpeted right and left. Fast forward twenty years the technical debt come due and no one can leave the Java boat fast enough. Turns out, refactoring vast piles of vendored, forked and obsolescent code, with no clear lines of demarcation because no one enforced ABI separation for a long time, is completely unappealing. You can ignore problems a long time they come back with a vengeance. Posted Nov 25, 2025 13:46 UTC (Tue) by khim (subscriber, #9252) [Link] You live in some imaginary universe. On our universe Java is number three language, behind JavaScript and Python, but ahead of PHP, it's used by the most popular OS and no one thinks about abandoning it‚Ä¶ sure, people like to grumble about Java problems‚Ä¶ they use Java, nonetheless. Isn't that what you are doing here? Posted Nov 24, 2025 17:50 UTC (Mon) by farnz (subscriber, #17727) [Link] There's also work coming from the other direction, of providing a way to deliberately indicate that you intend something to be ABI, and widening the number of things that have a stable ABI, which will hopefully meet the efforts to determine what a stable ABI definition "should" look like in the middle. Unfortunately, all this takes time, motivation, and a lot of work; without more people helping, I could see it taking some time to get there. Posted Nov 24, 2025 18:48 UTC (Mon) by hunger (subscriber, #36242) [Link] (6 responses) Does it? Yes, it works most of the time, but that is by luck and not by design. The headers used to build some binary contain lots of code that gets backed into the binary (e.g. all templates). If any of those get changed by the next version of the library, then you can spent fun times debugging crashes as suddenly the code baked into the binary from the old version fails to use some symbol backed into the new library. There is a reason why most distros rebuild binaries when the dependencies change. Yes, rust could do the same. Rust has a different culture so it won't. Posted Nov 25, 2025 2:22 UTC (Tue) by Elv13 (subscriber, #106198) [Link] (3 responses) I am not familiar with the tooling Rust has to track ABI breakages, but I assume it could be handled using tooling rather than try to maintain a stable shared library ABI across versions. Posted Nov 25, 2025 2:46 UTC (Tue) by khim (subscriber, #9252) [Link] (2 responses) Not really. One example: let's convert your Easy: it doesn't exist. cargo_semver_checks is very through, but it only tracks source compatibility. Never binary. Stable ABI doesn't exist, period. There was some interest in development of such ABI, but effort have stalled. Posted Nov 25, 2025 9:12 UTC (Tue) by taladar (subscriber, #68407) [Link] (1 responses) It mostly works in C and C++ since those seem to have much lower standards for what they consider 'working'. Posted Nov 25, 2025 13:49 UTC (Tue) by khim (subscriber, #9252) [Link] With Swift approach (roughly: make Sure, it would be a bit work to provide stable ABI and most crates wouldn't bother, but if someone want to create a ‚ÄúRust platform‚Äù (similarly to how iOS and macOS are ‚ÄúSwift platforms‚Äù) then it's perfectly doable if costly. Posted Nov 25, 2025 11:37 UTC (Tue) by SLi (subscriber, #53131) [Link] (1 responses) The claim that this is not sustainable for Debian also seems strange, given that a lot of distros do manage to do it (including non-commercial ones like NixOS). Posted Nov 25, 2025 15:02 UTC (Tue) by intelfx (subscriber, #130118) [Link] &amp;gt; given that a lot of distros do manage to do it (including non-commercial ones like NixOS). NixOS is only managing to do it because commercial sponsors dump relatively huge money into operation of their CI and binary cache. Same also goes for other "non-commercial" distros ‚Äî if you look closer, you'll find they all have commercial sponsors subsidizing the infrastructure. Posted Nov 25, 2025 0:34 UTC (Tue) by pabs (subscriber, #43278) [Link] (2 responses) https://doc.rust-lang.org/reference/linkage.html The problem though is the culture of the Rust ecosystem; much of it prefers static linking, dislikes distros and probably would reject patches to introduce dylibs for each package. Posted Nov 25, 2025 4:14 UTC (Tue) by xnox (subscriber, #63320) [Link] (1 responses) It doesn't provide stable abi - one can use them to share code across multiple related binaries, think private .so It also is unsafe and removes type checking - which defeats the point of rust to begin with. Posted Nov 25, 2025 10:55 UTC (Tue) by joib (subscriber, #8541) [Link] &lt;head&gt;portable APT?&lt;/head&gt;&lt;head&gt;portable APT?&lt;/head&gt;&lt;head&gt;portable APT?&lt;/head&gt;&lt;head&gt;portable APT?&lt;/head&gt;&lt;lb/&gt; The ports w/o a Rust toolchain could still use cupt, which is written in C++. &lt;head/&gt; The question, as always, would be who's going to do the forking and keep up with upstream? &lt;head&gt;portable APT?&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;lb/&gt; C++ support shared libraries and rust could in principle support them too. In fact rust shared libraries could fix most of the problems with C shared libraries by having well-defined ABI and API definitions in the library itself. &lt;head/&gt; Rebuilding packages when their dependencies change is the future. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;lb/&gt; Wol&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; The claim being made for shared libraries is that I can just update the library, and all the applications are immediately patched, which reduces admin effort as compared to static linking, where I have to update the binaries and then restart the applications. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; They don't even do that - you have to update the binaries that are supplied by the shared library, and the in-memory copies of the binaries, too. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; And there's a particularly nasty subset of that, induced by the increased scope of feature unification. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; Oh yes - both ways round are possible. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; The problem is real. The funding to solve it is missing. &lt;head&gt;ABI stability funding&lt;/head&gt;&lt;head&gt;ABI stability funding&lt;/head&gt;&lt;head&gt;ABI stability funding&lt;/head&gt;&lt;head&gt;ABI stability funding&lt;/head&gt;&lt;code&gt;dyn Trait&lt;/code&gt; already, what this would would do, in terms of the language is to bring &lt;code&gt;dyn Trait&lt;/code&gt; to parity with &lt;code&gt;impl Trait&lt;/code&gt;, if you want inlining then simply don't use &lt;code&gt;dyn Trait&lt;/code&gt; and you are done.&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;lb/&gt; This is not required to replace C code.&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;lb/&gt; You can basically do almost all the things you can do in C. Including dynamic linking.&lt;head/&gt; The problem is more than just parametric polymorphism; it's things like defined constants, semantic meaning of functions and more. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; &amp;gt; Polymorphism is absolutely fine as long as you are aware that this means that the polymorphic parts of your library live in the caller's binary, not in your binary. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;code&gt;Option&lt;/code&gt; or &lt;code&gt;Result&lt;/code&gt;‚Ä¶ and ABI that doesn't use these is as almost far from idiomatic Rust as &lt;code&gt;"C"&lt;/code&gt;&lt;head/&gt; Why? Option and Result can be fully monomorphized in your API, in which case there's no polymorphic parts (even though pub struct Foo&amp;lt;T&amp;gt;(Option&amp;lt;T&amp;gt;) is polymorphic, pub struct Foo(Result&amp;lt;u32, MyError&amp;gt;) is not). &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; &amp;gt; Option and Result can be fully monomorphized in your API &lt;head&gt;Shared libraries&lt;/head&gt;&lt;code&gt;struct Foo&amp;lt;T&amp;gt;(Option&amp;lt;T&amp;gt;)&lt;/code&gt; is polymorphic, &lt;code&gt;pub struct Foo(Result&amp;lt;u32, MyError&amp;amp;ht;)&lt;/code&gt; is not).

&lt;code&gt;pub struct Foo(Result&amp;lt;u32, MyError&amp;gt;)&lt;/code&gt; is polymorphic because it depends on a compiler version. Compile is free to change the representation of &lt;code&gt;pub struct Foo(Result&amp;lt;u32, MyError&amp;gt;)&lt;/code&gt; at any time, in fact nightly have a flag to do that and stable does it from time, to time, too.&lt;head/&gt; Sure, you'd need the compiler to not break things that are marked as ABI - and you'd have to accept that the stable ABI is not necessarily as efficient as the unstable ABI. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; &amp;gt; But that's something the compiler team has to commit to. None of this works if the compiler team won't stabilize the ABI (replacing the compiler version dependency with a stable ABI version dependency). &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; I don't know why you'd limit it to statically known types - that's not my proposal at all. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; You can have both (just not at the same time). That's what Swift does. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Swift vs Rust ABI&lt;/head&gt;&lt;head&gt;Swift vs Rust ABI&lt;/head&gt;&lt;head&gt;Swift vs Rust ABI&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; The problem comes with updates. If you update (say) ripgrep to fix a bug, and it uses a new monomorphization, that new monomorphization can rely on a new monomorphization inside a library package, and so on. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; If you're doing the change downstream, then yes it is quite likely - something as "trivial" to upstream as "add a new variant to an error enum" is a new monomorphization, with the resulting need to recompile everything that knows the layout of that enum. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; Returning a new error value that was previously impossible is an ABI break, in both C and Rust, unless it's clearly documented beforehand that other errors are possible. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; It's slightly worse, because years of habit mean that C programmers are used to thinking about whether a change will break distro ABIs; Rust programmers aren't, and because Rust makes it easier to express things that are hard to express in C (sum types, for example), they're more likely to make changes to fix a bug that make the situation worse. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;code&gt;unsafe extern "C" {
    safe fn f();
}&lt;/code&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;lb/&gt; In fact, I am not aware of a standardised ABI for C++ at all.&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; &amp;gt; Fast forward twenty years the technical debt come due and no one can leave the Java boat fast enough. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; In the short term, there's experiments like stabby and abi_stable looking at what it means to provide a well-defined ABI for a shared library written in Rust and intended to be consumed by other Rust programs. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head/&gt; &amp;gt; I assume it could be handled using tooling rather than try to maintain a stable shared library ABI across versions. &lt;head&gt;Shared libraries&lt;/head&gt;&lt;code&gt;enum SecurityMode {LEGACY, SECURE, DISABLED};&lt;/code&gt; to Rust and add &lt;code&gt;Option&amp;lt;‚Ä¶&amp;amp;rt;&lt;/code&gt; wrapping. And now look on how different versions of Rust thread that. Nice, isn't it? The same effect that you just described‚Äîbut without any source changes, just with different compiler. And no, release notes wouldn't save you, either, there are nothing in them about this change.&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;code&gt;dyn Trait&lt;/code&gt; as capable as &lt;code&gt;impl Trait&lt;/code&gt; at the cost of implementation speed) there would be no material difference between ABI stability checks and API stability checks.&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;head&gt;Shared libraries&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/SubscriberLink/1046841/5bbf1fc049a18947/"/><published>2025-11-25T14:18:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045987</id><title>Launch HN: Onyx (YC W24) ‚Äì The open-source chat UI</title><updated>2025-11-25T16:49:06.723581+00:00</updated><content>&lt;doc fingerprint="374119d99fbe8bf8"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, Chris and Yuhong here from Onyx (&lt;/p&gt;https://github.com/onyx-dot-app/onyx&lt;p&gt;). We‚Äôre building an open-source chat that works with any LLM (proprietary + open weight) &lt;/p&gt;and&lt;p&gt; gives these LLMs the tools they need to be useful (RAG, web search, MCP, deep research, memory, etc.).&lt;/p&gt;&lt;p&gt;Demo: https://youtu.be/2g4BxTZ9ztg&lt;/p&gt;&lt;p&gt;Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company's data, lacked customization, and frankly didn't work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.&lt;/p&gt;&lt;p&gt;As the project grew, we started seeing an interesting trend‚Äîeven though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We‚Äôd hear, ‚Äúthe connectors, indexing, and search are great, but I‚Äôm going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them‚Äù.&lt;/p&gt;&lt;p&gt;Many users would add RAG, agents, and custom tools later, but much of the usage stayed ‚Äòbasic chat‚Äô. We thought: ‚Äúwhy would people co-opt an enterprise search when other AI chat solutions exist?‚Äù&lt;/p&gt;&lt;p&gt;As we continued talking to users, we realized two key points:&lt;/p&gt;&lt;p&gt;(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI&lt;/p&gt;&lt;p&gt;(2) providing this well is much harder than you might think and the bar is incredibly high&lt;/p&gt;&lt;p&gt;Consumer products like ChatGPT and Claude already provide a great experience‚Äîand chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from ‚Äúthis works‚Äù to ‚Äúthis feels magical‚Äù is not easy, and nothing else in the space has managed to do it.&lt;/p&gt;&lt;p&gt;So ~3 months ago we pivoted to Onyx, the open-source chat UI with:&lt;/p&gt;&lt;p&gt;- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who‚Äôs using AI tools for the first time.&lt;/p&gt;&lt;p&gt;- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.&lt;/p&gt;&lt;p&gt;- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.&lt;/p&gt;&lt;p&gt;Through building features like deep research and code interpreter that work across model providers, we've learned a ton of non-obvious things about engineering LLMs that have been key to making Onyx work. I'd like to share two that were particularly interesting (happy to discuss more in the comments).&lt;/p&gt;&lt;p&gt;First, context management is one of the most difficult and important things to get right. We‚Äôve found that LLMs really struggle to remember both system prompts and previous user messages in long conversations. Even simple instructions like ‚Äúignore sources of type X‚Äù in the system prompt are very often ignored. This is exacerbated by multiple tool calls, which can often feed in huge amounts of context. We solved this problem with a ‚ÄúReminder‚Äù prompt‚Äîa short 1-3 sentence blurb injected at the end of the user message that describes the non-negotiables that the LLM must abide by. Empirically, LLMs attend most to the very end of the context window, so this placement gives the highest likelihood of adherence.&lt;/p&gt;&lt;p&gt;Second, we‚Äôve needed to build an understanding of the ‚Äúnatural tendencies‚Äù of certain models when using tools, and build around them. For example, the GPT family of models are fine-tuned to use a python code interpreter that operates in a Jupyter notebook. Even if told explicitly, it refuses to add `print()` around the last line, since, in Jupyter, this last line is automatically written to stdout. Other models don‚Äôt have this strong preference, so we‚Äôve had to design our model-agnostic code interpreter to also automatically `print()` the last bare line.&lt;/p&gt;&lt;p&gt;So far, we‚Äôve had a Fortune 100 team fork Onyx and provide 10k+ employees access to every model within a single interface, and create thousands of use-case specific Assistants for every department, each using the best model for the job. We‚Äôve seen teams operating in sensitive industries completely airgap Onyx w/ locally hosted LLMs to provide a copilot that wouldn‚Äôt have been possible otherwise.&lt;/p&gt;&lt;p&gt;If you‚Äôd like to try Onyx out, follow https://docs.onyx.app/deployment/getting_started/quickstart to get set up locally w/ Docker in &amp;lt;15 minutes. For our Cloud: https://www.onyx.app/. If there‚Äôs anything you'd like to see to make it a no-brainer to replace your ChatGPT Enterprise/Claude Enterprise subscription, we‚Äôd love to hear it!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46045987"/><published>2025-11-25T14:20:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46046916</id><title>FLUX.2: Frontier Visual Intelligence</title><updated>2025-11-25T16:49:06.427909+00:00</updated><content>&lt;doc fingerprint="4d170e309478ce0e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLUX.2: Frontier Visual Intelligence&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;News&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;FLUX.2 is designed for real-world creative workflows, not just demos or party tricks. It generates high-quality images while maintaining character and style consistency across multiple reference images, following structured prompts, reading and writing complex text, adhering to brand guidelines, and reliably handling lighting, layouts, and logos. FLUX.2 can edit images at up to 4 megapixels while preserving detail and coherence.&lt;/p&gt;
    &lt;head rend="h2"&gt;Black Forest Labs: Open Core&lt;/head&gt;
    &lt;p&gt;We believe visual intelligence should be shaped by researchers, creatives, and developers everywhere, not just a few. That‚Äôs why we pair frontier capability with open research and open innovation, releasing powerful, inspectable, and composable open-weight models for the community, alongside robust, production-ready endpoints for teams that need scale, reliability, and customization.&lt;/p&gt;
    &lt;p&gt;When we launched Black Forest Labs in 2024, we set out to make open innovation sustainable, building on our experience developing some of the world‚Äôs most popular open models. We‚Äôve combined open models like FLUX.1 [dev]‚Äîthe most popular open image model globally‚Äîwith professional-grade models like FLUX.1 Kontext [pro], which powers teams from Adobe to Meta and beyond. Our open core approach drives experimentation, invites scrutiny, lowers costs, and ensures that we can keep sharing open technology from the Black Forest and the Bay into the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;From FLUX.1 to FLUX.2&lt;/head&gt;
    &lt;p&gt;Precision, efficiency, control, extreme realism - where FLUX.1 showed the potential of media models as powerful creative tools, FLUX.2 shows how frontier capability can transform production workflows. By radically changing the economics of generation, FLUX.2 will become an indispensable part of our creative infrastructure.&lt;/p&gt;
    &lt;p&gt;Output Versatility: FLUX.2 is capable of generating highly detailed, photoreal images along with infographics with complex typography, all at resolutions up to 4MP&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs New&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-Reference Support: Reference up to 10 images simultaneously with the best character / product / style consistency available today.&lt;/item&gt;
      &lt;item&gt;Image Detail &amp;amp; Photorealism: Greater detail, sharper textures, and more stable lighting suitable for product shots, visualization, and photography-like use cases.&lt;/item&gt;
      &lt;item&gt;Text Rendering: Complex typography, infographics, memes and UI mockups with legible fine text now work reliably in production.&lt;/item&gt;
      &lt;item&gt;Enhanced Prompt Following: Improved adherence to complex, structured instructions, including multi-part prompts and compositional constraints.&lt;/item&gt;
      &lt;item&gt;World Knowledge: Significantly more grounded in real-world knowledge, lighting, and spatial logic, resulting in more coherent scenes with expected behavior.&lt;/item&gt;
      &lt;item&gt;Higher Resolution &amp;amp; Flexible Input/Output Ratios: Image editing on resolutions up to 4MP.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All variants of FLUX.2 offer image editing from text and multiple references in one model.&lt;/p&gt;
    &lt;head rend="h2"&gt;Available Now&lt;/head&gt;
    &lt;p&gt;The FLUX.2 family covers a spectrum of model products, from fully managed, production-ready APIs to open-weight checkpoints developers can run themselves. The overview graph below shows how FLUX.2 [pro], FLUX.2 [flex], FLUX.2 [dev], and FLUX.2 [klein] balance performance, and control&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FLUX.2 [pro]: State-of-the-art image quality that rivals the best closed models, matching other models for prompt adherence and visual fidelity while generating images faster and at lower cost. No compromise between speed and quality. ‚Üí Available now at BFL Playground, the BFL API and via our launch partners.&lt;/item&gt;
      &lt;item&gt;FLUX.2 [flex]: Take control over model parameters such as the number of steps and the guidance scale, giving developers full control over quality, prompt adherence and speed. This model excels at rendering text and fine details. ‚Üí Available now at bfl.ai/play , the BFL API and via our launch partners.&lt;/item&gt;
      &lt;item&gt;FLUX.2 [dev]: 32B open-weight model, derived from the FLUX.2 base model. The most powerful open-weight image generation and editing model available today, combining text-to-image synthesis and image editing with multiple input images in a single checkpoint. FLUX.2 [dev] weights are available on Hugging Face and can be used via API endpoints on FAL, Replicate, Runware, Verda, TogetherAI, Cloudflare, DeepInfra. Run FLUX.2 [dev] on GeForce RTX GPUs for local experimentation with an optimized fp8 reference implementation of FLUX.2 [dev], created in collaboration with NVIDIA and ComfyUI. For a commercial license, visit our website.&lt;/item&gt;
      &lt;item&gt;FLUX.2 [klein] (coming soon): Open-source, Apache 2.0 model, size-distilled from the FLUX.2 base model. More powerful &amp;amp; developer-friendly than comparable models of the same size trained from scratch, with many of the same capabilities as its teacher model. Join the beta&lt;/item&gt;
      &lt;item&gt;FLUX.2 - VAE: A new variational autoencoder for latent representations that provide an optimized trade-off between learnability, quality and compression rate. This model provides the foundation for all FLUX.2 flow backbones, and an in-depth report describing its technical properties is available here. The FLUX.2 - VAE is available on HF under an Apache 2.0 license.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Generating designs with variable steps: FLUX.2 [flex] provides a ‚Äústeps‚Äù parameter, trading off typography accuracy and latency. From left to right: 6 steps, 20 steps, 50 steps.&lt;/p&gt;
    &lt;p&gt;Controlling image detail with variable steps: FLUX.2 [flex] provides a ‚Äústeps‚Äù parameter, trading off image detail and latency. From left to right: 6 steps, 20 steps, 50 steps.&lt;/p&gt;
    &lt;p&gt;The FLUX.2 model family delivers state-of-the-art image generation quality at extremely competitive prices, offering the best value across performance tiers.&lt;/p&gt;
    &lt;p&gt;For open-weights image models, FLUX.2 [dev] sets a new standard, achieving leading performance across text-to-image generation, single-reference editing, and multi-reference editing, consistently outperforming all open-weights alternatives by a significant margin.&lt;/p&gt;
    &lt;p&gt;Whether open or closed, we are committed to the responsible development of these models and services before, during, and after every release.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;FLUX.2 builds on a latent flow matching architecture, and combines image generation and editing in a single architecture. The model couples the Mistral-3 24B parameter vision-language model with a rectified flow transformer. The VLM brings real world knowledge and contextual understanding, while the transformer captures spatial relationships, material properties, and compositional logic that earlier architectures could not render.&lt;/p&gt;
    &lt;p&gt;FLUX.2 now provides multi-reference support, with the ability to combine up to 10 images into a novel output, an output resolution of up to 4MP, substantially better prompt adherence and world knowledge, and significantly improved typography. We re-trained the model‚Äôs latent space from scratch to achieve better learnability and higher image quality at the same time, a step towards solving the ‚ÄúLearnability-Quality-Compression‚Äù trilemma. Technical details can be found in the FLUX.2 VAE blog post.&lt;/p&gt;
    &lt;head rend="h2"&gt;More Resources:&lt;/head&gt;
    &lt;head rend="h2"&gt;Into the New&lt;/head&gt;
    &lt;p&gt;We're building foundational infrastructure for visual intelligence, technology that transforms how the world is seen and understood. FLUX.2 is a step closer to multimodal models that unify perception, generation, memory, and reasoning, in an open and transparent way.&lt;/p&gt;
    &lt;p&gt;Join us on this journey. We're hiring in Freiburg (HQ) and San Francisco. View open roles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bfl.ai/blog/flux-2"/><published>2025-11-25T15:47:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46047229</id><title>Roblox is a problem ‚Äì but it's a symptom of something worse</title><updated>2025-11-25T16:49:06.012786+00:00</updated><content>&lt;doc fingerprint="2502935f3822c5c9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Roblox is a problem ‚Äî but it‚Äôs a symptom of something worse&lt;/head&gt;
    &lt;p&gt;What is the role of tech journalism in a world where CEOs no longer feel shame?&lt;/p&gt;
    &lt;p&gt;I.&lt;/p&gt;
    &lt;p&gt;On Friday, the Hard Fork team published our interview with Roblox CEO David Baszucki. In the days since, it has become the most-discussed interview we've done in three years on the show. Listeners who wrote in to us said they were shocked to hear the leader of a platform with 151.5 million monthly users, most of them minors, express frustration and annoyance at being asked about the company's history of failures related to child safety. Journalists described the interview as "bizarre," "unhinged," and a "car crash."&lt;/p&gt;
    &lt;p&gt;And a case can be made that it was all of those things ‚Äî even if Baszucki, in the studio afterwards and later on X, insisted to us that he had had a good time. In the moment, though, Baszucki's dismissive attitude toward discussing child safety struck me as something worse: familiar.&lt;/p&gt;
    &lt;p&gt;Baszucki, after all, is not the first CEO to have insisted to me that a platform's problems are smaller than I am making them out to be. Nor is he the first to blame the platform's enormous scale, or to try to change the subject. (He is the first tech CEO to suggest to me that maybe there should be prediction markets in video games for children, but that's another story.)&lt;/p&gt;
    &lt;p&gt;What people found noteworthy about our interview, I think, was the fresh evidence that our most successful tech CEOs really do think and talk this way. Given a chance to display empathy for the victims of crimes his platform enabled, or to convey regret about historical safety lapses, or even just to gesture at some sense of responsibility for the hundreds of millions of children who in various ways are depending on him, the CEO throws up his hands and asks: how long are you guys going to be going on about all this stuff?&lt;/p&gt;
    &lt;p&gt;Roblox is different from other social products in that it explicitly courts users as young as 5. (You are supposed to be at least 13 to use Instagram, TikTok, and other major platforms.) That has always put significant pressure on the company to develop serious safety features. The company says it spends hundreds of millions of dollars a year on safety, and that 10 percent of its employees work on trust and safety issues. And trust and safety workers I know tell me that they respect Roblox's safety teams.&lt;/p&gt;
    &lt;p&gt;At the same time, this is a platform launched in 2006 where, for most of its history, adults could freely approach and message any minor unless their parents had dug into the app settings. Roblox did not verify users' ages, letting any child identify as 13 or older to bypass content restrictions. Filters intended to prevent inappropriate chat or the exchange of personal information were easily bypassed by slightly changing the spelling of words. Parental controls could be circumvented simply by a child creating a new account and declaring that they were at least 13.&lt;/p&gt;
    &lt;p&gt;Last year the company introduced new restrictions on chat. And this year, the company said it would deploy its own age estimation technology to determine users' ages and restrict the content available to them accordingly. This rollout was the main reason we had sought to interview Baszucki in the first place ‚Äî something we had communicated to his team.&lt;/p&gt;
    &lt;p&gt;Which only made it stranger when Baszucki expressed surprise at our line of inquiry and threw his PR team under the bus. ("If our PR people said, ‚ÄúLet‚Äôs talk about age-gating for an hour,' I‚Äôm up for it, but I love your pod. I thought I came here to talk about everything,'" he said.)&lt;/p&gt;
    &lt;p&gt;Since 2018, at least two dozen people in the United States have been arrested and accused of abducting or abusing victims they met on Roblox, according to a 2024 investigation by Bloomberg. Attorneys general in Texas, Kentucky, and Louisiana have filed lawsuits against Roblox alleging that the platform facilitates child exploitation and grooming. More than 35 families have filed lawsuits against the company over child predation.&lt;/p&gt;
    &lt;p&gt;As recently as this month, a reporter for the Guardian created an account presenting herself as a child and found that in Roblox she could wander user-created strip clubs, casinos, and horror games. In one "hangout" game, in which she identified as a 13-year-old, another avatar sexually assaulted her by thrusting his hips into her avatar's face as she begged him to leave her alone.&lt;/p&gt;
    &lt;p&gt;It's true that any platform that lets strangers communicate will lead to real-world harm. I believe that millions of children use Roblox daily without incident. And we would not want to shut down the entire internet to prevent a single bad thing from ever happening.&lt;/p&gt;
    &lt;p&gt;But there is much a leader can do with the knowledge that his platform will inevitably lead to harm, should he wish.&lt;/p&gt;
    &lt;p&gt;Understanding how attractive Roblox would be to predators, the company long ago could have blocked unrestricted contact between adults and minors. It could have adopted age verification before a wave of state legislation signaled that it would soon become mandatory anyway. It could have made it harder for children under 13 to create new accounts, and require them to get parental consent in a way it could verify.&lt;/p&gt;
    &lt;p&gt;But doing so would require Roblox to focus on outcomes for children, at the likely expense of growth. And so here we are.&lt;/p&gt;
    &lt;p&gt;II.&lt;/p&gt;
    &lt;p&gt;Galling? Yes. But like I said: it's also familiar.&lt;/p&gt;
    &lt;p&gt;Over and over again, we have seen leaders in Baszucki's position choose growth over guardrails. Safety features come out years after the need for them is identified, if at all. Internal critics are sidelined, laid off, or managed out. And when journalists ask, politely but insistently, why so many of their users are suffering, executives laugh and tell us that we're the crazy ones.&lt;/p&gt;
    &lt;p&gt;Look at OpenAI, where the company is reckoning with the fact that making its models less sycophantic has been worse for user engagement ‚Äî and is building new features to turn the engagement dial back up.&lt;/p&gt;
    &lt;p&gt;Look at TikTok, which has answered concerns that short-form video is worsening academic performance for children with new "digital well-being features" that include an affirmation journal, a "background sound generator aimed at improving the mental health of its users," and "new badges to reward people who use the platform within limits, especially teens." Answering concerns that teens are using the app too much with more reasons to use the app.&lt;/p&gt;
    &lt;p&gt;Or look at Meta, where new court filings from over the weekend allege ... a truly staggering number of things. To name a few: the company "stalled internal efforts to prevent child predators from contacting minors for years due to growth concerns," according to Jeff Horwitz in Reuters; "recognized that optimizing its products to increase teen engagement resulted in serving them more harmful content, but did so anyway"; and gave users 17 attempts to traffic people for sex before banning their accounts. (Meta denies the allegations, which are drawn from internal documents that have not been made public; Meta has also objected to unsealing the documents.)&lt;/p&gt;
    &lt;p&gt;Lawsuits will always contain the most salacious allegations lawyers can find, of course. But what struck me about these latest filings is not the lawyers' predictably self-serving framing but rather the quotes from Meta's own employees.&lt;/p&gt;
    &lt;p&gt;When the company declined to publish internal research from 2019 which showed that no longer looking at Facebook and Instagram improved users' mental health, one employee said: "If the results are bad and we don‚Äôt publish and they leak ... is it going to look like tobacco companies doing research and knowing cigs were bad and then keeping that info to themselves?‚Äù&lt;/p&gt;
    &lt;p&gt;When Meta researchers found that by 2018, approximately 40 percent of children ages 9 to 12 were daily Instagram users ‚Äî despite the fact that you are supposed to be 13 to join ‚Äî some employees bristled at what they perceived as tacit encouragement from executives to accelerate growth efforts among children.&lt;/p&gt;
    &lt;p&gt;"Oh good, we‚Äôre going after &amp;lt;13 year olds now?‚Äù one wrote, as cited in Time's account of the brief. ‚ÄúZuck has been talking about that for a while...targeting 11 year olds feels like tobacco companies a couple decades ago (and today). Like we‚Äôre seriously saying ‚Äòwe have to hook them young‚Äô here.‚Äù&lt;/p&gt;
    &lt;p&gt;When Meta studied the potential of its products to be addictive in 2018, it found that 55 percent of 20,000 surveyed users showed at least some signs of "problematic use." When it published that research the following year, though, it redefined "problematic use" to include only the most severe cases ‚Äî 3.1 percent of users.&lt;/p&gt;
    &lt;p&gt;‚ÄúBecause our product exploits weaknesses in the human psychology to promote product engagement and time spent,‚Äù a user experience researcher wrote, the company should ‚Äúalert people to the effect that the product has on their brain.‚Äù&lt;/p&gt;
    &lt;p&gt;You will not be surprised to learn that the company did not alert people to the issue.&lt;/p&gt;
    &lt;p&gt;III.&lt;/p&gt;
    &lt;p&gt;As usual, the rank-and-file employees are doing their job. Over and over again, though, their boss' boss tells them to stop.&lt;/p&gt;
    &lt;p&gt;The thing is, platforms' strategy of delay, deny and deflect mostly works.&lt;/p&gt;
    &lt;p&gt;Americans have short attention spans ‚Äî and lots to worry about. The tech backlash that kicked off in 2017 inspired platforms to make meaningful and effective investments in content moderation, cybersecurity, platform integrity, and other teams that worked to protect their user bases. Imperfect as these efforts were, they bolstered my sense that tech platforms were susceptible to pressure from the public, from lawmakers and from journalists. They acted slowly, and incompletely, but at least they acted.&lt;/p&gt;
    &lt;p&gt;Fast forward to today and the bargain no longer holds. Platforms do whatever the president of the United States tells them to do, and very little else. Shame, that once-great regulator of social norms and executive behavior, has all but disappeared from public life. In its place is denial, defiance, and the noxious vice signaling of the investor class.&lt;/p&gt;
    &lt;p&gt;I'm still reckoning with what it means to do journalism in a world where the truth can barely hold anyone's attention ‚Äî much less hold a platform accountable, in any real sense of that word. I'm rethinking how to cover tech policy at a time when it is being made by whim. I'm noticing the degree to which platforms wish to be judged only by their stated intentions, and almost never on the outcomes of anyone who uses them.&lt;/p&gt;
    &lt;p&gt;In the meantime the platforms hurtle onward, pitching ever-more fantastical visions of the future while seeming barely interested in stewarding the present.&lt;/p&gt;
    &lt;p&gt;For the moment, I'm grateful that a car-crash interview drew attention to one CEO's exasperation with being asked about that. But the real problem isn't that David Baszucki talks this way. It's that so many of his peers do, too.&lt;/p&gt;
    &lt;p&gt;Sponsored&lt;/p&gt;
    &lt;head rend="h3"&gt;Unknown number calling? It‚Äôs not random‚Ä¶&lt;/head&gt;
    &lt;p&gt;The BBC caught scam call center workers on hidden cameras as they laughed at the people they were tricking.&lt;/p&gt;
    &lt;p&gt;One worker bragged about making $250k from victims. The disturbing truth?&lt;lb/&gt;Scammers don‚Äôt pick phone numbers at random. They buy your data from brokers.&lt;/p&gt;
    &lt;p&gt;Once your data is out there, it‚Äôs not just calls. It‚Äôs phishing, impersonation, and identity theft.&lt;/p&gt;
    &lt;p&gt;That‚Äôs why we recommend Incogni: They delete your info from the web, monitor and follow up automatically, and continue to erase data as new risks appear.&lt;/p&gt;
    &lt;p&gt;Black Friday deal: Try Incogni here and get 55% off your subscription with code PLATFORMER&lt;/p&gt;
    &lt;head rend="h2"&gt;Following&lt;/head&gt;
    &lt;head rend="h3"&gt;Trump backs down on AI preemption&lt;/head&gt;
    &lt;p&gt;What happened: Facing criticism from both parties, the Trump administration backed down from issuing an executive order that would have effectively placed a moratorium on state AI regulations, Reuters reported.&lt;/p&gt;
    &lt;p&gt;The order would have fought state regulations by withholding federal funding and establishing an ‚ÄúAI Litigation Task Force‚Äù to ‚Äúchallenge State AI laws.‚Äù&lt;/p&gt;
    &lt;p&gt;Why we‚Äôre following: Last week we covered the draft executive order and how Trump‚Äôs attempts to squash state AI regulation have drawn bipartisan backlash ‚Äî and made Republicans increasingly more sympathetic to the views of AI safety advocates.&lt;/p&gt;
    &lt;p&gt;It's always hard to guess when Trump's instinct to do as he pleases will be thwarted by political opposition. In this case, though, the revived moratorium had little support outside the David Sacks wing of the party. And so ‚Äî for now, anyway ‚Äî it fell apart.&lt;/p&gt;
    &lt;p&gt;What people are saying: State lawmakers are fighting the moratorium proposal Trump made to Congress. Today, a letter signed by 280 state lawmakers urged Congress to ‚Äúreject any provision that overrides state and local AI legislation.‚Äù&lt;/p&gt;
    &lt;p&gt;A moratorium would threaten existing laws that ‚Äústrengthen consumer transparency, guide responsible government procurement, protect patients, and support artists and creators,‚Äù the letter said.&lt;/p&gt;
    &lt;p&gt;On the other side of the debate, the tech-funded industry PAC Leading the Future announced a $10 million campaign to push Congress to pass national AI regulations that would supersede state law.&lt;/p&gt;
    &lt;p&gt;‚ÄîElla Markianos&lt;/p&gt;
    &lt;head rend="h3"&gt;X‚Äôs "About This Account" meltdown&lt;/head&gt;
    &lt;p&gt;What happened: On Friday, X debuted its About This Account feature globally in a rollout that descended into chaos over the feature‚Äôs accidental uncovering of foreign actors behind popular right-wing accounts that actively share news on US politics.&lt;/p&gt;
    &lt;p&gt;X users can now see the date an account joined the platform, how many times it has changed its username, and most importantly, the country or region it‚Äôs based in. The move, according to X head of product Nikita Bier, ‚Äúis an important first step to securing the integrity of the global town square.‚Äù&lt;/p&gt;
    &lt;p&gt;But the feature has had an unintended consequence: it revealed that big pro-Trump accounts like @MAGANationX, a right-wing user with nearly 400,000 followers that regularly shares news about US politics, aren't actually based in the US. MAGANationX, for example, is based in Eastern Europe, according to X.&lt;/p&gt;
    &lt;p&gt;Other popular right-wing accounts ‚Äî that use names from the Trump family ‚Äî like @IvankaNews_ (1 million followers before it was suspended), @BarronTNews (nearly 600,000 followers), and @TrumpKaiNews (more than 11,000 followers), appear to be based in Nigeria, Eastern Europe, and Macedonia respectively.&lt;/p&gt;
    &lt;p&gt;The data could be skewed by travel, VPNs, or old IP addresses, and some have complained their location is inaccurate. Bier said the rollout has ‚Äúa few rough edges‚Äù that will be resolved by Tuesday.&lt;/p&gt;
    &lt;p&gt;Why we‚Äôre following: One of Elon Musk‚Äôs promises during the takeover of Twitter was to purge the platform of inauthentic accounts. But several studies have shown that suspected inauthentic activity has remained at about the same levels. X has long struggled with troll farms spreading misinformation, boosted by its tendency to monetarily reward engagement.&lt;/p&gt;
    &lt;p&gt;There's also an irony in the fact that revealing the origins of ragebait-posting political accounts like these was once the subject of groundbreaking research by the Stanford Internet Observatory and other academic researchers. But the effort outraged Republicans, which then sued them over their contacts with the government about information operations like these and largely succeeded in stopping the work.&lt;/p&gt;
    &lt;p&gt;What people are saying: Accusations of foreign actors spreading fake news flew on both sides of the aisle. When the feature appeared to be pulled for a short period of time, Republican Gov. Ron DeSantis of Florida said ‚ÄúX needs to reinstate county-of-origin ‚Äî it helps expose the grift.‚Äù&lt;/p&gt;
    &lt;p&gt;In a post that garnered 3.2 million views, @greg16676935420 attached a screenshot of @AmericanGuyX‚Äôs profile, which shows the account‚Äôs based in India: ‚ÄúBREAKING: American guy is not actually an American guy.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhen an American billionaire offers money to people from relatively poor countries for riling up and radicalising Americans, it's not surprising that they'll take up the offer,‚Äù @ChrisO_wiki wrote in a post that garnered nearly 700,000 views.&lt;/p&gt;
    &lt;p&gt;In perhaps the most devastating consequence of the feature, @veespo_444s said they ‚Äúspent 2 years acting mysterious over what country I live in just for Elon to fuck it all up with a single update‚Äù in a post that has 4.3 million views and 90,000 likes.&lt;/p&gt;
    &lt;p&gt;‚ÄîLindsey Choo&lt;/p&gt;
    &lt;head rend="h3"&gt;Side Quests&lt;/head&gt;
    &lt;p&gt;How President Trump amplifies right-wing trolls and AI memes. The crypto crash has taken about $1 billion out of the Trump family fortune.&lt;/p&gt;
    &lt;p&gt;Gamers are using Fortnite and GTA to prepare for ICE raids. How Democrats are building their online strategy to catch up with Republicans.&lt;/p&gt;
    &lt;p&gt;In the last month, Elon Musk has posted more about politics than about his companies on X.&lt;/p&gt;
    &lt;p&gt;Hundreds of English-language websites link to articles from a pro-Kremlin disinformation network and are being used to "groom" AI chatbots into spreading Russian propaganda, a study found.&lt;/p&gt;
    &lt;p&gt;Sam Altman and Jony Ive said they‚Äôre now prototyping their hardware device, but it remains two years away. An in-depth look at OpenAI's mental health crisis after GPT-4o details how the company changed ChatGPT after reports of harmful interactions. OpenAI safety research leader Andrea Vallone, who led ChatGPT‚Äôs responses to mental health crises, is reportedly leaving. A review of ChatGPT‚Äôs new personal shopping agent.&lt;/p&gt;
    &lt;p&gt;Anthropic unveiled Claude Opus 4.5, which it said is the best model for software engineering. Other highlights from the launch: it outscored human engineering candidates on a take-home exam, is cheaper than Opus 4.1, can keep a chat going indefinitely via ongoing summarization of past chats, and is harder to trick with prompt injection.&lt;/p&gt;
    &lt;p&gt;In other research, AI models can unintentionally develop misaligned behaviors after learning to cheat, Anthropic said. (This won an approving tweet from Ilya Sutskever, who hadn't posted about AI on X in more than a year.)&lt;/p&gt;
    &lt;p&gt;Why Meta‚Äôs $27 billion data center and its debt won‚Äôt be on its balance sheet. Meta is venturing into electricity trading to speed up its power plant construction. Facebook Groups now has a nickname feature for anonymous posting.&lt;/p&gt;
    &lt;p&gt;A judge is set to decide on remedies for Google‚Äôs adtech monopoly next year. Italy closed its probe into Google over unfair practices that used personal data. Google stock closed at a record high last week after the successful launch of Gemini 3. AI Mode now has ads.&lt;/p&gt;
    &lt;p&gt;Something for the AI skeptics: Google must double its serving capacity every six months to meet current demand for AI services, Google Cloud VP Amin Vahdat said.&lt;/p&gt;
    &lt;p&gt;AI demand has strained the memory chip supply chain, chipmakers said.&lt;/p&gt;
    &lt;p&gt;Amazon has more than 900 data centers ‚Äî more than previously known ‚Äî in more than 50 countries. Its Autonomous Threat Analysis system uses specialized AI agents for debugging. AWS said it would invest $50 billion in AI capabilities for federal agencies.&lt;/p&gt;
    &lt;p&gt;Twitch was added to Australia's list of platforms banned for under-16s. Pinterest was spared.&lt;/p&gt;
    &lt;p&gt;Grindr said it ended talks on a $3.5 billion take-private deal, citing uncertainty over financing.&lt;/p&gt;
    &lt;p&gt;Interviews with AI quality raters who are telling their friends and family not to use the tech. How AI is threatening the fundamental method of online survey research by evading bot detection techniques. Insurers are looking to limit their liability on claims related to AI. Another look at how America‚Äôs economy is now deeply tied to AI stocks and their performance.&lt;/p&gt;
    &lt;p&gt;Scientists built an AI model that can flag human genetic mutations likely to cause disease.&lt;/p&gt;
    &lt;head rend="h3"&gt;Those good posts&lt;/head&gt;
    &lt;p&gt;For more good posts every day, follow Casey‚Äôs Instagram stories.&lt;/p&gt;
    &lt;p&gt;(Link)&lt;/p&gt;
    &lt;p&gt;(Link)&lt;/p&gt;
    &lt;p&gt;(Link)&lt;/p&gt;
    &lt;head rend="h3"&gt;Talk to us&lt;/head&gt;
    &lt;p&gt;Send us tips, comments, questions, and your questions for the tech CEOs: casey@platformer.news. Read our ethics policy here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.platformer.news/roblox-ceo-interview-backlash-analysis/"/><published>2025-11-25T16:12:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46047350</id><title>Orion 1.0 ‚Äì Browse Beyond</title><updated>2025-11-25T16:49:05.826015+00:00</updated><content>&lt;doc fingerprint="bf500252492497aa"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Orion 1.0 √¢¬¥√Ø¬∏ Browse Beyond&lt;/head&gt;
    &lt;p&gt;After six years of relentless development, Orion for MacOS 1.0 is here.&lt;/p&gt;
    &lt;p&gt;What started as a vision initiated by our founder, Vladimir Prelovac, has now come to fruition on Mac, iPhone, and iPad. Today, Orion for macOS officially leaves its beta phase behind and joins our iOS and iPadOS apps as a fully√¢fledged, production√¢ready browser.&lt;/p&gt;
    &lt;p&gt;While doing so, it expands Kagi ecosystem of privacy-respecting, user-centric products (that we have begun fondly naming ‚ÄúKagiverse‚Äù) to now include: Search, Assistant, Browser, Translate, News with more to come.&lt;/p&gt;
    &lt;p&gt;We built Orion for people who feel that modern browsing has drifted too far from serving the user. This is our invitation to browse beyond √¢¬¥√Ø¬∏ the status quo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why a new browser?&lt;/head&gt;
    &lt;p&gt;The obvious question is: why the heck do we need a new browser? The world already has Chrome, Safari, Firefox, Edge, and a growing list of ‚ÄúAI browsers.‚Äù Why add yet another?&lt;/p&gt;
    &lt;p&gt;Because something fundamental has been lost.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Zero telemetry, privacy√¢first access to the internet: a basic human right.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Your browser is the most intimate tool you have on your computer. It sees everything you read, everything you search, everything you type. Do you want that relationship funded by advertisers, or by you?&lt;/p&gt;
    &lt;p&gt;With ad√¢funded browsers and AI overlays, your activity is a gold mine. Every click becomes a way to track, every page another opportunity to profile you a little more deeply. We believe there needs to be a different path: a browser that answers only to its user.&lt;/p&gt;
    &lt;p&gt;Orion is our attempt at that browser. No trade-offs between features and privacy. It‚Äôs fast, customizable, and uncompromising on both fronts.&lt;/p&gt;
    &lt;head rend="h2"&gt;A bold technical choice: WebKit, not another Chromium clone&lt;/head&gt;
    &lt;p&gt;In a world dominated by Chromium, choosing a rendering engine is an act of resistance.&lt;/p&gt;
    &lt;p&gt;From day one, we made the deliberate choice to build Orion on WebKit, the open√¢source engine at the heart of Safari and the broader Apple ecosystem. It gives us:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A high√¢performance engine that is deeply optimized for macOS and iOS.&lt;/item&gt;
      &lt;item&gt;An alternative to the growing Chromium monoculture.&lt;/item&gt;
      &lt;item&gt;A foundation that is not controlled by an advertising giant.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Orion may feel familiar if you‚Äôre used to Safari √¢ respecting your muscle memory and the aesthetics of macOS and iOS √¢ but it is an entirely different beast under the hood. We combined native WebKit speed with a completely new approach to extensions, privacy, and customization.&lt;/p&gt;
    &lt;head rend="h2"&gt;Speed by nature, privacy by default&lt;/head&gt;
    &lt;p&gt;Most people switch browsers for one reason: speed.&lt;/p&gt;
    &lt;p&gt;Orion is designed to be fast by nature, not just in benchmarks, but in how it feels every day:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A lean, native codebase without ad√¢tech bloat.&lt;/item&gt;
      &lt;item&gt;Optimized startup, tab switching, and page rendering.&lt;/item&gt;
      &lt;item&gt;A UI that gets out of your way and gives you more screen real estate for content.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Alongside speed, we treat privacy as a first√¢class feature:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zero Telemetry: We don‚Äôt collect usage data. No analytics, no identifiers, no tracking.&lt;/item&gt;
      &lt;item&gt;No ad or tracking technology baked in: Orion is not funded by ads, so there is no incentive to follow you around the web.&lt;/item&gt;
      &lt;item&gt;Built√¢in protections: Strong content blocking and privacy defaults from the first launch.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Speed. Extensions. Privacy. Pick all three.&lt;/head&gt;
    &lt;head rend="h2"&gt;Thoughtful AI, security first&lt;/head&gt;
    &lt;p&gt;We are excited about what AI can do for search, browsing, and productivity. Kagi, the company behind Orion, has been experimenting with AI√¢powered tools for years while staying true to our AI integration philosophy.&lt;/p&gt;
    &lt;p&gt;But we are also watching a worrying trend: AI agents are being rushed directly into the browser core, with deep access to everything you do online √¢ and sometimes even to your local machine.&lt;/p&gt;
    &lt;p&gt;Security researchers have already documented serious issues in early AI browsers and ‚Äúagentic‚Äù browser features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hidden or undocumented APIs that allowed embedded AI components to execute arbitrary local commands on users√¢ devices.&lt;/item&gt;
      &lt;item&gt;Prompt√¢injection attacks that trick AI agents into ignoring safety rules, visiting malicious sites, or leaking sensitive information beyond what traditional browser sandboxes were designed to protect.&lt;/item&gt;
      &lt;item&gt;Broader concerns that some implementations are effectively ‚Äúlighting everything on fire‚Äù by expanding the browser√¢s attack surface and data flows in ways users don√¢t fully understand.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our stance is simple:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We are not against AI, and we are conscious of its limitations. We already integrate with AI√¢powered services wherever it makes functional sense and will continue to expand those capabilities.&lt;/item&gt;
      &lt;item&gt;We are against rushing insecure, always√¢on agents into the browser core. Your browser should be a secure gateway, not an unvetted co√¢pilot wired into everything you do.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So today:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Orion ships with no built√¢in AI code in its core.&lt;/item&gt;
      &lt;item&gt;We focus on providing a clean, predictable environment, especially for enterprises and privacy√¢conscious professionals.&lt;/item&gt;
      &lt;item&gt;Orion is designed to connect seamlessly to the AI tools you choose √¢ soon including Kagi‚Äôs intelligent features √¢ while keeping a clear separation between your browser and any external AI agents.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As AI matures and security models improve, we‚Äôll continue to evaluate thoughtful, user√¢controlled ways to bring AI into your workflow without compromising safety, privacy or user choice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simple for everyone, limitless for experts&lt;/head&gt;
    &lt;p&gt;We designed Orion to bridge the gap between simplicity and power. Out of the box, it‚Äôs a clean, intuitive browser for anyone. Under the hood, it‚Äôs a deep toolbox for people who live in their browser all day.&lt;/p&gt;
    &lt;p&gt;Some of the unique features you‚Äôll find in Orion 1.0:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Focus Mode: Instantly transform any website into a distraction√¢free web app. Perfect for documentation, writing, or web apps you run all day.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Link Preview: Peek at content from any app √¢ email, notes, chat √¢ without fully committing to opening a tab, keeping your workspace tidy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mini Toolbar, Overflow Menu, and Page Tweak: Fine√¢tune each page‚Äôs appearance and controls, so the web adapts to you, not the other way around.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Profiles as Apps: Isolate your work, personal, and hobby browsing into completely separate profiles, each with its own extensions, cookies, and settings.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For power users, we‚Äôve added granular options throughout the browser. These are there when you want them, and out of your way when you don‚Äôt.&lt;/p&gt;
    &lt;p&gt;Orion 1.0 also reflects six years of feedback from early adopters. Many invisible improvements √¢ tab stability, memory behavior, complex web app compatibility √¢ are a direct result of people pushing Orion hard in their daily workflows and telling us what broke.&lt;/p&gt;
    &lt;head rend="h2"&gt;Browse Beyond √¢¬¥√Ø¬∏: our new signature&lt;/head&gt;
    &lt;p&gt;With this release, we are introducing our new signature: Browse Beyond √¢¬¥√Ø¬∏.&lt;/p&gt;
    &lt;p&gt;We originally started with the browser name ‚ÄòKagi.‚Äô On February 3, 2020, Vlad suggested a shortlist for rebranding: Comet, Core, Blaze, and Orion. We chose Orion not just for the name itself, but because it perfectly captured our drive for exploration and curiosity. It was a natural fit that set the stage for everything that followed.&lt;/p&gt;
    &lt;p&gt;You‚Äôll see this reflected in our refreshed visual identity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A star (√¢¬¥√Ø¬∏) motif throughout our communication.&lt;/item&gt;
      &lt;item&gt;A refined logo that now uses the same typeface as Kagi, creating a clear visual bond between our browser and our search engine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Orion is part of the broader Kagi ecosystem, united by a simple idea: the internet should be built for people, not advertisers or any other third parties.&lt;/p&gt;
    &lt;head rend="h2"&gt;Small team, sustainable model&lt;/head&gt;
    &lt;p&gt;Orion is built by a team of just six developers.&lt;/p&gt;
    &lt;p&gt;To put that in perspective:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;That‚Äôs roughly 10% of the size of the ‚Äúsmall‚Äù browser teams at larger companies.&lt;/item&gt;
      &lt;item&gt;And a rounding error compared to the teams behind Chrome or Edge.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yet, the impact is real: over 1 million downloads to date, and a dedicated community of 2480 paid subscribers who make this independence possible.&lt;/p&gt;
    &lt;p&gt;For the first two years, development was carried out by a single developer. Today, we are a tight knit group operating close to our users. We listen, debate, and implement fixes proposed directly by our community on OrionFeedback.org.&lt;/p&gt;
    &lt;p&gt;This is our only source of decision making, rather than any usage analytics or patterns, because remember, Orion is zero-telemetry!&lt;/p&gt;
    &lt;p&gt;This small team approach lets us move quickly, stay focused, and avoid the bloat or hype that often comes with scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free, yet self√¢funded&lt;/head&gt;
    &lt;p&gt;Orion is free for everyone.&lt;/p&gt;
    &lt;p&gt;Every user also receives 200 free Kagi searches, with no account or sign√¢up required. It‚Äôs our way of introducing you to fast, ad√¢free, privacy√¢respecting search from day one.&lt;/p&gt;
    &lt;p&gt;But we are also 100% self√¢funded. We don‚Äôt sell your data and we don‚Äôt take money from advertisers, which means we rely directly on our users to sustain the project.&lt;/p&gt;
    &lt;p&gt;There are three ways to contribute to Orion‚Äôs future:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tip Jar (from the app): A simple way to say ‚Äúthank you‚Äù without any commitment.&lt;/item&gt;
      &lt;item&gt;Supporter Subscription: $5/month or $50/year.&lt;/item&gt;
      &lt;item&gt;Lifetime Access: A one√¢time payment of $150 for life.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supporters (via subscription or lifetime purchase) unlock a set of Orion+ perks available today, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Floating windows: Keep a video or window on top of other apps.&lt;/item&gt;
      &lt;item&gt;Customization: Programmable buttons and custom application icons.&lt;/item&gt;
      &lt;item&gt;Early access to new, supporter√¢exclusive features we‚Äôre already building for next year.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By supporting Orion, you‚Äôre not just funding a browser √¢ you are co√¢funding a better web with humans at the center.&lt;/p&gt;
    &lt;head rend="h2"&gt;Orion everywhere you are&lt;/head&gt;
    &lt;p&gt;Orion 1.0 is just the beginning. Our goal is simple: Browse Beyond, everywhere.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Orion for macOS&lt;/p&gt;&lt;lb/&gt;Our flagship browser, six years in the making. Built natively for Mac, with performance and detail that only come from living on the platform for a long time. Download it now.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Orion for iOS and iPadOS&lt;/p&gt;&lt;lb/&gt;Trusted daily by users who want features no other mobile browser offers. Native iOS performance with capabilities that redefine what√¢s possible on mobile. Download it now.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Orion for Linux (Alpha)&lt;/p&gt;&lt;lb/&gt;Currently in alpha for users who value choice and independence. Native Linux performance, with the same privacy√¢first approach as on macOS.&lt;lb/&gt;Sign up for our newsletter to follow development and join the early testing wave.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Orion for Windows (in development)&lt;/p&gt;&lt;lb/&gt;We have officially started development on Orion for Windows, with a target release scheduled for late 2026. Our goal is full parity with Orion 1.0 for macOS, including synchronized profiles and Orion+ benefits across platforms. Sign up for our newsletter to follow development and join the early testing wave.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Synchronization will work seamlessly across devices, so your browsing experience follows you, not the other way around.&lt;/p&gt;
    &lt;head rend="h2"&gt;What people say&lt;/head&gt;
    &lt;p&gt;From early testers to privacy advocates and power users, Orion has grown through the voices of its community.&lt;/p&gt;
    &lt;p&gt;We‚Äôll continue to surface community stories and feedback as Orion evolves. If you share your experience publicly, there‚Äôs a good chance we‚Äôll see it.&lt;/p&gt;
    &lt;head rend="h2"&gt;The road ahead&lt;/head&gt;
    &lt;p&gt;Hitting v1.0 is a big milestone, but we‚Äôre just getting started.&lt;/p&gt;
    &lt;p&gt;Over the next year, our roadmap is densely packed with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deeper customization options for power users.&lt;/item&gt;
      &lt;item&gt;Further improvements to stability and complex web app performance.&lt;/item&gt;
      &lt;item&gt;New Orion+ features that push what a browser can do while keeping it simple for everyone else.&lt;/item&gt;
      &lt;item&gt;Tighter integrations with Kagi‚Äôs intelligent tools √¢ always under your control, never forced into your workflow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We‚Äôre also working on expanding and improving our website to better showcase everything Orion can do, including better documentation and onboarding for teams that want to standardize on Orion.&lt;/p&gt;
    &lt;p&gt;Meanwhile, follow our X account where we√¢ll be dropping little freebies on the regular (and don‚Äôt worry, we‚Äôll be posting these elsewhere on socials as well!)&lt;/p&gt;
    &lt;p&gt;Thank you for choosing to Browse Beyond with us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.kagi.com/orion"/><published>2025-11-25T16:21:24+00:00</published></entry></feed>