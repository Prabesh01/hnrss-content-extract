<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-19T23:10:05.673781+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45978423</id><title>Thunderbird adds native Microsoft Exchange email support</title><updated>2025-11-19T23:10:12.472729+00:00</updated><content>&lt;doc fingerprint="ae591a91108cb8dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Thunderbird Adds Native Microsoft Exchange Email Support&lt;/head&gt;
    &lt;p&gt;If your organization uses Microsoft Exchange-based email, you‚Äôll be happy to hear that Thunderbird‚Äôs latest monthly Release version 145, now officially supports native access via the Exchange Web Services (EWS) protocol. With EWS now built directly into Thunderbird, a third-party add-on is no longer required for email functionality. Calendar and address book support for Exchange accounts remain on the roadmap, but email integration is here and ready to use!&lt;/p&gt;
    &lt;head rend="h2"&gt;What changes for Thunderbird users&lt;/head&gt;
    &lt;p&gt;Until now, Thunderbird users in Exchange hosted environments often relied on IMAP/POP protocols or third-party extensions. With full native Exchange support for email, Thunderbird now works more seamlessly in Exchange environments, including full folder listings, message synchronization, folder management both locally and on the server, attachment handling, and more. This simplifies life for users who depend on Exchange for email but prefer Thunderbird as their client.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to get started&lt;/head&gt;
    &lt;p&gt;For many people switching from Outlook to Thunderbird, the most common setup involves Microsoft-hosted Exchange accounts such as Microsoft 365 or Office 365. Thunderbird now uses Microsoft‚Äôs standard sign-in process (OAuth2) and automatically detects your account settings, so you can start using your email right away without any extra setup.&lt;/p&gt;
    &lt;p&gt;If this applies to you, setup is straightforward:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create a new account in Thunderbird 145 or newer.&lt;/item&gt;
      &lt;item&gt;In the new Account Hub, select Exchange (or Exchange Web Services in legacy setup).&lt;/item&gt;
      &lt;item&gt;Let Thunderbird handle the rest!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important note: If you see something different, or need more details or advice, please see our support page and wiki page. Also, some authentication configurations are not supported yet and you may need to wait for a further update that expands compatibility, please refer to the table below for more details.&lt;/p&gt;
    &lt;head rend="h2"&gt;What functionality is supported now and what‚Äôs coming soon&lt;/head&gt;
    &lt;p&gt;As mentioned earlier, EWS support in version 145 currently enables email functionality only. Calendar and address book integration are in active development and will be added in future releases. The chart below provides an at-a-glance view of what‚Äôs supported today.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Feature area&lt;/cell&gt;
        &lt;cell&gt;Supported now&lt;/cell&gt;
        &lt;cell&gt;Not yet supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Email ‚Äì account setup &amp;amp; folder access&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Creating accounts via auto-config with EWS, server-side folder manipulation&lt;/cell&gt;
        &lt;cell&gt;‚Äì&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Email ‚Äì message operations&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Viewing messages, sending, replying/forwarding, moving/copying/deleting&lt;/cell&gt;
        &lt;cell&gt;‚Äì&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Email ‚Äì attachments&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Attachments can be saved and displayed with detach/delete support.&lt;/cell&gt;
        &lt;cell&gt;‚Äì&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Search &amp;amp; filtering&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Search subject and body, quick filtering&lt;/cell&gt;
        &lt;cell&gt;‚ùå Filter actions requiring full body content are not yet supported.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Accounts hosted on Microsoft 365&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Domains using the standard Microsoft OAuth2 endpoint&lt;/cell&gt;
        &lt;cell&gt;‚ùå Domains requiring custom OAuth2 application and tenant IDs will be supported in the future.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Accounts hosted on-premise&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Password-based Basic authentication&lt;/cell&gt;
        &lt;cell&gt;‚ùå Password-based NTLM authentication and OAuth2 for on-premise servers are on the roadmap.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Calendar support&lt;/cell&gt;
        &lt;cell&gt;‚Äì&lt;/cell&gt;
        &lt;cell&gt;‚ùå Not yet implemented ‚Äì calendar syncing is on the roadmap.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Address book / contacts support&lt;/cell&gt;
        &lt;cell&gt;‚Äì&lt;/cell&gt;
        &lt;cell&gt;‚ùå Not yet implemented ‚Äì address book support is on the roadmap.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Microsoft Graph support&lt;/cell&gt;
        &lt;cell&gt;‚Äì&lt;/cell&gt;
        &lt;cell&gt;‚ùå Not yet implemented ‚Äì Microsoft Graph integration will be added in the future.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Exchange Web Services and Microsoft Graph&lt;/head&gt;
    &lt;p&gt;While many people and organizations still rely on Exchange Web Services (EWS), Microsoft has begun gradually phasing it out in favor of a newer, more modern interface called Microsoft Graph. Microsoft has stated that EWS will continue to be supported for the foreseeable future, but over time, Microsoft Graph will become the primary way to connect to Microsoft 365 services.&lt;/p&gt;
    &lt;p&gt;Because EWS remains widely used today, we wanted to ensure full support for it first to ensure compatibility for existing users. At the same time, we‚Äôre actively working to add support for Microsoft Graph, so Thunderbird will be ready as Microsoft transitions to its new standard.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking ahead&lt;/head&gt;
    &lt;p&gt;While Exchange email is available now, calendar and address book integration is on the way, bringing Thunderbird closer to being a complete solution for Exchange users. For many people, having reliable email access is the most important step, but if you depend on calendar and contact synchronization, we‚Äôre working hard to bring this to Thunderbird in the near future, making Thunderbird a strong alternative to Outlook.&lt;/p&gt;
    &lt;p&gt;Keep an eye on future releases for additional support and integrations, but in the meantime, enjoy a smoother Exchange email experience within your favorite email client!&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;If you want to know more about Exchange support in Thunderbird, please refer to the dedicated page on support.mozilla.org. Organization admins can also find out more on the Mozilla wiki page. To follow ongoing and future work in this area, please refer to the relevant meta-bug on Bugzilla.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.thunderbird.net/2025/11/thunderbird-adds-native-microsoft-exchange-email-support/"/><published>2025-11-19T11:45:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45979190</id><title>Larry Summers resigns from OpenAI board</title><updated>2025-11-19T23:10:12.350243+00:00</updated><content>&lt;doc fingerprint="ee31da039104d639"&gt;
  &lt;main&gt;
    &lt;p&gt;Former Treasury Secretary Larry Summers said Wednesday that he will resign from the board of OpenAI after the release of emails between him and the notorious sex offender Jeffrey Epstein.&lt;/p&gt;
    &lt;p&gt;Summers had announced Monday that he would be stepping back from all public commitments, but it was not immediately clear whether that included his position at the artificial intelligence startup.&lt;/p&gt;
    &lt;p&gt;"I am grateful for the opportunity to have served, excited about the potential of the company, and look forward to following their progress," Summers said in a statement to CNBC.&lt;/p&gt;
    &lt;p&gt;OpenAI's board told CNBC it respects Summers' decision to resign.&lt;/p&gt;
    &lt;p&gt;"We appreciate his many contributions and the perspective he brought to the Board," the OpenAI board of directors said in a statement.&lt;/p&gt;
    &lt;p&gt;Details of Summers' correspondence with Epstein were made public last week after the House Oversight and Government Reform Committee released more than 20,000 documents it obtained pursuant to a subpoena from Epstein's estate. Summers has faced intense scrutiny following the release of those files.&lt;/p&gt;
    &lt;p&gt;Summers joined OpenAI's board in 2023 during a turbulent period for the startup. OpenAI CEO Sam Altman was briefly ousted from the company, though he returned to the chief executive role days later.&lt;/p&gt;
    &lt;p&gt;In the wake of "The Blip," as some OpenAI employees call it, Summers was appointed to the board alongside Bret Taylor, former co-CEO of Salesforce, and Quora CEO Adam D'Angelo, who was the only member of OpenAI's previous board who still held a seat.&lt;/p&gt;
    &lt;p&gt;Axios was first to report about Summers' resignation from the board.&lt;/p&gt;
    &lt;p&gt;President Donald Trump on Friday asked the Department of Justice to investigate the relationship between Epstein and Summers, as well as Epstein's ties to former President Bill Clinton, JPMorgan Chase and billionaire tech investor Reid Hoffman. Trump has been facing renewed pressure over his own past friendship with Epstein.&lt;/p&gt;
    &lt;p&gt;Summers is a former president of Harvard University, and Democratic Sen. Elizabeth Warren of Massachusetts told CNN on Monday that the university should sever ties with him. He announced his intention to step back from his public commitments later that day, but said he will continue to fulfill his teaching obligations at Harvard.&lt;/p&gt;
    &lt;p&gt;"I am deeply ashamed of my actions and recognize the pain they have caused. I take full responsibility for my misguided decision to continue communicating with Mr. Epstein," Summers said in a statement to CNBC on Monday.&lt;/p&gt;
    &lt;p&gt;Congress on Tuesday agreed to pass a bipartisan bill ordering the Department of Justice to release all of its files on Epstein, clearing the path for Trump to sign it into law.&lt;/p&gt;
    &lt;p&gt;WATCH: House overwhelmingly votes to release more Epstein investigation files, sends bill to Senate&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/11/19/larry-summers-epstein-openai.html"/><published>2025-11-19T13:16:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45980117</id><title>Europe is scaling back GDPR and relaxing AI laws</title><updated>2025-11-19T23:10:12.255485+00:00</updated><content>&lt;doc fingerprint="ff1cf01c3abf8d9c"&gt;
  &lt;main&gt;
    &lt;p&gt;After years of staring down the world‚Äôs biggest tech companies and setting the bar for tough regulation worldwide, Europe has blinked. Under intense pressure from industry and the US government, Brussels is stripping protections from its flagship General Data Protection Regulation (GDPR) ‚Äî including simplifying its infamous cookie permission pop-ups ‚Äî and relaxing or delaying landmark AI rules in an effort to cut red tape and revive sluggish economic growth.&lt;/p&gt;
    &lt;head rend="h1"&gt;Europe is scaling back its landmark privacy and AI laws&lt;/head&gt;
    &lt;p&gt;The EU folds under Big Tech‚Äôs pressure.&lt;/p&gt;
    &lt;p&gt;The EU folds under Big Tech‚Äôs pressure.&lt;/p&gt;
    &lt;p&gt;The changes, proposed by the European Commission, the bloc‚Äôs executive branch, changes core elements of the GDPR, making it easier for companies to share anonymized and pseudonymized personal datasets. They would allow AI companies to legally use personal data to train AI models, so long as that training complies with other GDPR requirements.&lt;/p&gt;
    &lt;p&gt;The proposal also waters down a key part of Europe‚Äôs sweeping artificial intelligence rules, the AI Act, which came into force in 2024 but had many elements that would only come into effect later. The change extends the grace period for rules governing high-risk AI systems that pose ‚Äúserious risks‚Äù to health, safety, or fundamental rights, which were due to come into effect next summer. The rules will now only apply once it‚Äôs confirmed that ‚Äúthe needed standards and support tools are available‚Äù to AI companies.&lt;/p&gt;
    &lt;p&gt;One change that‚Äôs likely to please almost everyone is a reduction in Europe‚Äôs ubiquitous cookie banners and pop-ups. Under the new proposal, some ‚Äúnon-risk‚Äù cookies won‚Äôt trigger pop-ups at all, and users would be able to control others from central browser controls that apply to websites broadly.&lt;/p&gt;
    &lt;p&gt;Other amendments in the new Digital Omnibus include simplified AI documentation requirements for smaller companies, a unified interface for companies to report cybersecurity incidents, and centralizing oversight of AI into the bloc‚Äôs AI Office.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis is being done in the European way.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWe have all the ingredients in the EU to succeed. But our companies, especially our start-ups and small businesses, are often held back by layers of rigid rules,‚Äù said Henna Virkkunen, executive vice-president for tech sovereignty at the European Commission. ‚ÄúBy cutting red tape, simplifying EU laws, opening access to data and introducing a common European Business Wallet we are giving space for innovation to happen and to be marketed in Europe. This is being done in the European way: by making sure that fundamental rights of users remain fully protected.‚Äù&lt;/p&gt;
    &lt;p&gt;The proposal now heads to the European Parliament and the EU‚Äôs 27 member states ‚Äî where it will need a qualified majority ‚Äî for approval, a process that could drag on for months and potentially introduce significant changes.&lt;/p&gt;
    &lt;p&gt;The proposed overhaul won‚Äôt land quietly in Brussels, and if the development of the GDPR and AI Act are anything to go by, a political and lobbying firestorm is on its way. The GDPR is a cornerstone of Europe‚Äôs tech strategy and as close to sacred as a policy can be. Leaked drafts have already provoked outrage among civil rights groups and politicians, who have accused the Commission of weakening fundamental safeguards and bowing to pressure from Big Tech.&lt;/p&gt;
    &lt;p&gt;The decision follows months of intense pressure from Big Tech and Donald Trump ‚Äî as well as high-profile internal figures like ex-Italian prime minister and former head of the European Central Bank Mario Draghi ‚Äî urging the bloc to weaken burdensome tech regulation. The Commission has sought to frame the changes as simplifying the EU‚Äôs tech laws, not weakening them ‚Äì a way of soothing growing fears in Brussels that its tough rules are hampering its ability to compete globally. With very few exceptions, Europe doesn‚Äôt have any credible competitors in the global AI race, which is dominated by US and Chinese companies like DeepSeek, Google, and OpenAI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/823750/european-union-ai-act-gdpr-changes"/><published>2025-11-19T14:41:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45980760</id><title>Launch HN: Mosaic (YC W25) ‚Äì Agentic Video Editing</title><updated>2025-11-19T23:10:12.028538+00:00</updated><link href="https://mosaic.so"/><published>2025-11-19T15:28:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45982073</id><title>Meta Segment Anything Model 3</title><updated>2025-11-19T23:10:11.742865+00:00</updated><content/><link href="https://ai.meta.com/sam3/"/><published>2025-11-19T17:14:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45982162</id><title>Static Web Hosting on the Intel N150: FreeBSD, SmartOS, NetBSD, OpenBSD and Linu</title><updated>2025-11-19T23:10:11.114154+00:00</updated><content>&lt;doc fingerprint="362d517fea0ed7c2"&gt;
  &lt;main&gt;
    &lt;p&gt;I often get very specific infrastructure requests from clients. Most of the time it is some form of hosting. My job is usually to suggest and implement the setup that fits their goals, skills and long term plans.&lt;/p&gt;
    &lt;p&gt;If there are competent technicians on the other side, and they are willing to learn or already comfortable with Unix style systems, my first choices are usually one of the BSDs or an illumos distribution. If they need a control panel, or they already have a lot of experience with a particular stack that will clearly help them, I will happily use Linux and it usually delivers solid, reliable results.&lt;/p&gt;
    &lt;p&gt;Every now and then someone asks the question I like the least:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√¢But how does it perform compared to X or Y?√¢&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I have never been a big fan of benchmarks. At best they capture a very specific workload on a very specific setup. They are almost never a perfect reflection of what will happen in the real world.&lt;/p&gt;
    &lt;p&gt;For example, I discovered that idle bhyve VMs seem to use fewer resources when the host is illumos than when the host is FreeBSD. It looks strange at first sight, but the illumos people are clearly working very hard on this, and the result is a very capable and efficient platform.&lt;/p&gt;
    &lt;p&gt;Despite my skepticism, from time to time I enjoy running some comparative tests. I already did it with Proxmox KVM versus FreeBSD bhyve, and I also compared Jails, Zones, bhyve and KVM on the same Intel N150 box. That led to the FreeBSD vs SmartOS article where I focused on CPU and memory performance on this small mini PC.&lt;/p&gt;
    &lt;p&gt;This time I wanted to do something simpler, but also closer to what I see every day: static web hosting.&lt;/p&gt;
    &lt;p&gt;Instead of synthetic CPU or I/O tests, I wanted to measure how different operating systems behave when they serve a small static site with nginx, both over HTTP and HTTPS.&lt;/p&gt;
    &lt;p&gt;This is not meant to be a super rigorous benchmark. I used the default nginx packages, almost default configuration, and did not tune any OS specific kernel settings. In my experience, careful tuning of kernel and network parameters can easily move numbers by several tens of percentage points. The problem is that very few people actually spend time chasing such optimizations. Much more often, once a limit is reached, someone yells √¢we need mooooar powaaaar√¢ while the real fix would be to tune the existing stack a bit.&lt;/p&gt;
    &lt;p&gt;So the question I want to answer here is more modest and more practical:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;With default nginx and a small static site, how much does the choice of host OS really matter on this Intel N150 mini PC?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spoiler: less than people think, at least for plain HTTP. Things get more interesting once TLS enters the picture.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Disclaimer&lt;/p&gt;&lt;lb/&gt;These benchmarks are a snapshot of my specific hardware, network and configuration. They are useful to compare relative behavior on this setup. They are not a universal ranking of operating systems. Different CPUs, NICs, crypto extensions, kernel versions or nginx builds can completely change the picture.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Test setup&lt;/head&gt;
    &lt;p&gt;The hardware is the same Intel N150 mini PC I used in my previous tests: a small, low power box that still has enough cores to be interesting for lab and small production workloads.&lt;/p&gt;
    &lt;p&gt;On it, I installed several operating systems and environments, always on the bare metal, not nested inside each other. On each OS I installed nginx from the official packages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Software under test&lt;/head&gt;
    &lt;p&gt;On the host:&lt;/p&gt;
    &lt;p&gt;SmartOS, with:&lt;lb/&gt; - a Debian 12 LX zone&lt;lb/&gt; - an Alpine Linux 3.22 LX zone&lt;lb/&gt; - a native SmartOS zone &lt;/p&gt;
    &lt;p&gt;FreeBSD 14.3-RELEASE:&lt;lb/&gt; - nginx running inside a native jail &lt;/p&gt;
    &lt;p&gt;OpenBSD 7.8:&lt;lb/&gt; - nginx on the host &lt;/p&gt;
    &lt;p&gt;NetBSD 10.1:&lt;lb/&gt; - nginx on the host &lt;/p&gt;
    &lt;p&gt;Debian 13.2:&lt;lb/&gt; - nginx on the host &lt;/p&gt;
    &lt;p&gt;Alpine Linux 3.22:&lt;lb/&gt; - nginx on the host &lt;/p&gt;
    &lt;p&gt;I also tried to include DragonFlyBSD, but the NIC in this box is not supported. Using a different NIC just for one OS would have made the comparison meaningless, so I excluded it.&lt;/p&gt;
    &lt;head rend="h3"&gt;nginx configuration&lt;/head&gt;
    &lt;p&gt;In all environments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;nginx was installed from the system packages&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;worker_processes&lt;/code&gt;was set to&lt;code&gt;auto&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;the web root contained the same static content&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The important part is that I used exactly the same &lt;code&gt;nginx.conf&lt;/code&gt; file for all operating systems and all combinations in this article. I copied the same configuration file verbatim to every host, jail and zone. The only changes were the IP address and file paths where needed, for example for the TLS certificate and key. &lt;/p&gt;
    &lt;p&gt;The static content was a default build of the example site generated by BSSG, my Bash static site generator. The web root was the same logical structure on every OS and container type.&lt;/p&gt;
    &lt;p&gt;There is no OS specific tuning in the configuration and no kernel level tweaks. This is very close to a √¢package install plus minimal config√¢ situation.&lt;/p&gt;
    &lt;head rend="h3"&gt;TLS configuration&lt;/head&gt;
    &lt;p&gt;For HTTPS I used a very simple configuration, identical on every host.&lt;/p&gt;
    &lt;p&gt;Self signed certificate created with:&lt;/p&gt;
    &lt;code&gt;openssl req -x509 -newkey rsa:4096 -nodes -keyout server.key -out server.crt -days 365 -subj "/CN=localhost"  
&lt;/code&gt;
    &lt;p&gt;Example nginx &lt;code&gt;server&lt;/code&gt; block for HTTPS (simplified): &lt;/p&gt;
    &lt;code&gt;server {  
listen 443 ssl http2;  
listen [::]:443 ssl http2;  

server_name _;  

ssl_certificate /etc/nginx/ssl/server.crt;  
ssl_certificate_key /etc/nginx/ssl/server.key;  

root /var/www/html;  
index index.html index.htm;  

location / {  
try_files $uri $uri/ =404;  
}  
}  
&lt;/code&gt;
    &lt;p&gt;The HTTP virtual host is also the same everywhere, with the root pointing to the BSSG example site.&lt;/p&gt;
    &lt;head rend="h3"&gt;Load generator&lt;/head&gt;
    &lt;p&gt;The tests were run from my workstation on the same LAN:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;client host: a mini PC machine connected at 2.5 Gbit/s&lt;/item&gt;
      &lt;item&gt;switch: 2.5 Gbit/s&lt;/item&gt;
      &lt;item&gt;test tool: &lt;code&gt;wrk&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For each target host I ran:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;wrk -t4 -c50 -d10s http://IP&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;wrk -t4 -c10 -d10s http://IP&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;wrk -t4 -c50 -d10s https://IP&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;wrk -t4 -c10 -d10s https://IP&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each scenario was executed multiple times to reduce noise; the numbers below are medians (or very close to them) from the runs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The contenders&lt;/head&gt;
    &lt;p&gt;To keep things readable, I will refer to each setup as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SmartOS Debian LX √¢ SmartOS host, Debian 12 LX zone&lt;/item&gt;
      &lt;item&gt;SmartOS Alpine LX √¢ SmartOS host, Alpine 3.22 LX zone&lt;/item&gt;
      &lt;item&gt;SmartOS Native √¢ SmartOS host, native zone&lt;/item&gt;
      &lt;item&gt;FreeBSD Jail √¢ FreeBSD 14.3-RELEASE, nginx in a jail&lt;/item&gt;
      &lt;item&gt;OpenBSD Host √¢ OpenBSD 7.8, nginx on the host&lt;/item&gt;
      &lt;item&gt;NetBSD Host √¢ NetBSD 10.1, nginx on the host&lt;/item&gt;
      &lt;item&gt;Debian Host √¢ Debian 13.2, nginx on the host&lt;/item&gt;
      &lt;item&gt;Alpine Host √¢ Alpine 3.22, nginx on the host&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Everything uses the same nginx configuration file and the same static site.&lt;/p&gt;
    &lt;head rend="h2"&gt;Static HTTP results&lt;/head&gt;
    &lt;p&gt;Let us start with plain HTTP, since this removes TLS from the picture and focuses on the kernel, network stack and nginx itself.&lt;/p&gt;
    &lt;head rend="h3"&gt;HTTP, 4 threads, 50 concurrent connections&lt;/head&gt;
    &lt;p&gt;Approximate median &lt;code&gt;wrk&lt;/code&gt; results: &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Environment&lt;/cell&gt;
        &lt;cell role="head"&gt;HTTP 50 connections&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SmartOS Debian LX&lt;/cell&gt;
        &lt;cell&gt;~46.2 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SmartOS Alpine LX&lt;/cell&gt;
        &lt;cell&gt;~49.2 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SmartOS Native&lt;/cell&gt;
        &lt;cell&gt;~63.7 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;FreeBSD Jail&lt;/cell&gt;
        &lt;cell&gt;~63.9 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OpenBSD Host&lt;/cell&gt;
        &lt;cell&gt;~64.1 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NetBSD Host&lt;/cell&gt;
        &lt;cell&gt;~64.0 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Debian Host&lt;/cell&gt;
        &lt;cell&gt;~63.8 k&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Alpine Host&lt;/cell&gt;
        &lt;cell&gt;~63.9 k&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Two things stand out:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;All the native or jail/container setups on the hosts that are not LX zones cluster around 63 to 64k requests per second.&lt;/item&gt;
      &lt;item&gt;The two SmartOS LX zones sit slightly lower, in the 46 to 49k range, which is still very respectable for this hardware.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In other words, as long as you are on the host or in something very close to it (FreeBSD jail, SmartOS native zone, NetBSD, OpenBSD, Linux on bare metal), static HTTP on nginx will happily max out around 64k requests per second with this small Intel N150 CPU.&lt;/p&gt;
    &lt;p&gt;The Debian and Alpine LX zones on SmartOS are a bit slower, but not dramatically so. They still deliver close to 50k requests per second and, in a real world scenario, you would probably saturate the network or the client long before hitting those numbers.&lt;/p&gt;
    &lt;head rend="h3"&gt;HTTP, 4 threads, 10 concurrent connections&lt;/head&gt;
    &lt;p&gt;With fewer concurrent connections, absolute throughput drops, but the relative picture is similar:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SmartOS Native around 44k&lt;/item&gt;
      &lt;item&gt;NetBSD and Alpine Host around 34 to 35k&lt;/item&gt;
      &lt;item&gt;FreeBSD, Debian, OpenBSD around 31 to 33k&lt;/item&gt;
      &lt;item&gt;The SmartOS LX zones sit slightly below, around 35 to 37k req/s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The important conclusion is simple:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For plain HTTP static hosting, once nginx is installed and correctly configured, the choice between these operating systems makes very little difference on this hardware. Zones and jails add negligible overhead, LX zones add a small one.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you are only serving static content over HTTP, your choice of OS should be driven by other factors: ecosystem, tooling, update strategy, your own expertise and preference.&lt;/p&gt;
    &lt;head rend="h2"&gt;Static HTTPS results&lt;/head&gt;
    &lt;p&gt;TLS is where things start to diverge more clearly and where CPU utilization becomes interesting.&lt;/p&gt;
    &lt;head rend="h3"&gt;HTTPS, 4 threads, 50 concurrent connections&lt;/head&gt;
    &lt;p&gt;Approximate medians:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Environment&lt;/cell&gt;
        &lt;cell role="head"&gt;HTTPS 50 connections&lt;/cell&gt;
        &lt;cell role="head"&gt;CPU notes at 50 HTTPS connections&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SmartOS Debian LX&lt;/cell&gt;
        &lt;cell&gt;~51.4 k&lt;/cell&gt;
        &lt;cell&gt;CPU saturated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SmartOS Alpine LX&lt;/cell&gt;
        &lt;cell&gt;~40.4 k&lt;/cell&gt;
        &lt;cell&gt;CPU saturated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SmartOS Native&lt;/cell&gt;
        &lt;cell&gt;~52.8 k&lt;/cell&gt;
        &lt;cell&gt;CPU saturated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FreeBSD Jail&lt;/cell&gt;
        &lt;cell&gt;~62.9 k&lt;/cell&gt;
        &lt;cell&gt;around 60% CPU idle&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OpenBSD Host&lt;/cell&gt;
        &lt;cell&gt;~39.7 k&lt;/cell&gt;
        &lt;cell&gt;CPU saturated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;NetBSD Host&lt;/cell&gt;
        &lt;cell&gt;~40.4 k&lt;/cell&gt;
        &lt;cell&gt;CPU at 100%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Debian Host&lt;/cell&gt;
        &lt;cell&gt;~62.8 k&lt;/cell&gt;
        &lt;cell&gt;about 20% CPU idle&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Alpine Host&lt;/cell&gt;
        &lt;cell&gt;~62.4 k&lt;/cell&gt;
        &lt;cell&gt;small idle headroom, around 7% idle&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These numbers tell a more nuanced story.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;FreeBSD, Debian and Alpine on bare metal form a √¢fast TLS√¢ group.&lt;/p&gt;&lt;lb/&gt;All three sit around 62 to 63k requests per second with 50 concurrent HTTPS connections.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;FreeBSD does this while using significantly less CPU.&lt;/p&gt;&lt;lb/&gt;During the HTTPS tests with 50 connections, the FreeBSD host still had around 60% CPU idle. It is the platform that handled TLS load most comfortably in terms of CPU headroom.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Debian and Alpine are close in throughput, but push the CPU harder.&lt;/p&gt;&lt;lb/&gt;Debian still had some idle time left, Alpine even less. In practice, all three are excellent here, but FreeBSD gives you more room before you hit the wall.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;SmartOS, NetBSD and OpenBSD form a √¢good but heavier√¢ TLS group.&lt;/p&gt;&lt;lb/&gt;Their HTTPS throughput is in the 40 to 52k req/s range and they reach full CPU usage at 50 concurrent connections. OpenBSD and NetBSD stabilize around 39 to 40k req/s. SmartOS native and the Debian LX zone manage slightly better (around 51 to 53k) but still with the CPU pegged.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;HTTPS, 4 threads, 10 concurrent connections&lt;/head&gt;
    &lt;p&gt;With lower concurrency:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FreeBSD, Debian and Alpine still sit in roughly the 29 to 31k req/s range&lt;/item&gt;
      &lt;item&gt;SmartOS Native and LX zones are in the mid to high 30k range&lt;/item&gt;
      &lt;item&gt;NetBSD and OpenBSD sit around 26 to 27k req/s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The relative pattern is the same: for this TLS workload, FreeBSD and modern Linux distributions on bare metal appear to make better use of the cryptographic capabilities of the CPU, delivering higher throughput or more headroom or both.&lt;/p&gt;
    &lt;head rend="h2"&gt;What TLS seems to highlight&lt;/head&gt;
    &lt;p&gt;The HTTPS tests point to something that is not about nginx itself, but about the TLS stack and how well it can exploit the hardware.&lt;/p&gt;
    &lt;p&gt;On this Intel N150, my feeling is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FreeBSD, with the userland and crypto stack I am running, is very efficient at TLS here. It delivers the highest throughput while keeping plenty of CPU in reserve.&lt;/item&gt;
      &lt;item&gt;Debian and Alpine, with their recent kernels and libraries, are also strong performers, close to FreeBSD in throughput, but with less idle CPU.&lt;/item&gt;
      &lt;item&gt;NetBSD, OpenBSD and SmartOS (native and LX) are still perfectly capable of serving a lot of HTTPS traffic, but they have to work harder to keep up and they hit 100% CPU much earlier.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This matches what I see in day to day operations: TLS performance is often less about √¢nginx vs something else√¢ and more about the combination of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the TLS library version and configuration&lt;/item&gt;
      &lt;item&gt;how well the OS uses the CPU crypto instructions&lt;/item&gt;
      &lt;item&gt;kernel level details in the network and crypto paths&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I suspect the differences here are mostly due to how each system combines its TLS stack (OpenSSL, LibreSSL and friends), its kernel and its hardware acceleration support. It would take a deeper dive into profiling and configuration knobs to attribute the gaps precisely.&lt;/p&gt;
    &lt;p&gt;In any case, on this specific mini PC, if I had to pick a platform to handle a large amount of HTTPS static traffic, FreeBSD, Debian and Alpine would be my first candidates, in that order.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zones, jails and containers: overhead in practice&lt;/head&gt;
    &lt;p&gt;Another interesting part of the story is the overhead introduced by different isolation technologies.&lt;/p&gt;
    &lt;p&gt;From these tests and the previous virtualization article on the same N150 machine, the picture is consistent:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;FreeBSD jails behave almost like bare metal.&lt;/p&gt;&lt;lb/&gt;For both HTTP and HTTPS, running nginx in a jail on FreeBSD 14.3-RELEASE produces numbers practically identical to native hosts on other OSes. CPU utilization is excellent, especially under TLS.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;SmartOS native zones are also very close to the metal.&lt;/p&gt;&lt;lb/&gt;Static HTTP performance reaches the same 64k req/s region and HTTPS is only slightly behind the √¢fast TLS√¢ group, although with higher CPU usage.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;SmartOS LX zones introduce a noticeable but modest overhead.&lt;/p&gt;&lt;lb/&gt;Both Debian and Alpine LX zones on SmartOS perform slightly worse than the native zone or FreeBSD jails. For static HTTP they are still very fast. For HTTPS the Debian LX zone remains competitive but costs more CPU, while the Alpine LX zone is slower.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a surprise. LX zones translate Linux system calls on top of the illumos kernel and there is a cost for that. The important point is that the cost is not catastrophic. On a bigger CPU you would probably not notice it unless you are really pushing the limits.&lt;/p&gt;
    &lt;head rend="h2"&gt;What this means for real workloads&lt;/head&gt;
    &lt;p&gt;It is easy to get lost in tables and percentages, so let us go back to the initial question.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A client wants static hosting.&lt;/p&gt;&lt;lb/&gt;Does the choice between FreeBSD, SmartOS, NetBSD or Linux matter in terms of performance?&lt;/quote&gt;
    &lt;p&gt;For plain HTTP on this hardware, with nginx and the same configuration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Not really.&lt;lb/&gt;All the native hosts and FreeBSD jails deliver roughly the same maximum throughput, in the 63 to 64k req/s range. SmartOS LX zones are slightly slower but still strong.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For HTTPS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yes, it starts to matter a bit more.&lt;/item&gt;
      &lt;item&gt;FreeBSD stands out for how relaxed the CPU is under high TLS load.&lt;/item&gt;
      &lt;item&gt;Debian and Alpine are very close in throughput, with more CPU used but still with some headroom.&lt;/item&gt;
      &lt;item&gt;SmartOS, NetBSD and OpenBSD can still push a lot of HTTPS traffic, but they reach 100% CPU earlier and stabilize at lower request rates.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Does this mean you should always choose FreeBSD or Debian or Alpine for static HTTPS hosting?&lt;/p&gt;
    &lt;p&gt;Not necessarily.&lt;/p&gt;
    &lt;p&gt;In real deployments, the bottleneck is rarely the TLS performance of a single node serving a small static site. Network throughput, storage, logging, reverse proxies, CDNs and application layers all play a role.&lt;/p&gt;
    &lt;p&gt;However, knowing that FreeBSD and current Linux distributions can squeeze more out of a small CPU under TLS is useful when you are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;sizing hardware for small VPS nodes that must serve many HTTPS requests&lt;/item&gt;
      &lt;item&gt;planning to consolidate multiple services on a low power box&lt;/item&gt;
      &lt;item&gt;deciding whether you can afford to keep some CPU aside for other tasks (cache, background jobs, monitoring, and so on)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As always, the right answer depends on the complete picture: your skills, your tooling, your backups, your monitoring, the rest of your stack, and your tolerance for troubleshooting when things go sideways.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;From these small tests, my main takeaways are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Static HTTP is basically solved on all these platforms.&lt;/p&gt;&lt;lb/&gt;On a modest Intel N150, every system tested can push around 64k static HTTP requests per second with nginx set to almost default settings. For many use cases, that is already more than enough.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;TLS performance is where the OS and crypto stack start to matter.&lt;/p&gt;&lt;lb/&gt;FreeBSD, Debian and Alpine squeeze more HTTPS requests out of the N150, and FreeBSD in particular does it with a surprising amount of idle CPU left. NetBSD, OpenBSD and SmartOS need more CPU to reach similar speeds and stabilize at lower throughput once the CPU is saturated.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Jails and native zones are essentially free, LX zones cost a bit more.&lt;/p&gt;&lt;lb/&gt;FreeBSD jails and SmartOS native zones show very little overhead for this workload. SmartOS LX zones are still perfectly usable, but if you are chasing every last request per second you will see the cost of the translation layer.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Benchmarks are only part of the story.&lt;/p&gt;&lt;lb/&gt;If your team knows OpenBSD inside out and has tooling, scripts and workflows built around it, you might happily accept using more CPU on TLS in exchange for security features, simplicity and familiarity. The same goes for NetBSD or SmartOS in environments where their specific strengths shine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I will not choose an operating system for a client just because a benchmark looks nicer. These numbers are one of the many inputs I consider. What matters most is always the combination of reliability, security, maintainability and the human beings who will have to operate the&lt;lb/&gt; system at three in the morning when something goes wrong. &lt;/p&gt;
    &lt;p&gt;Still, it is nice to know that if you put a tiny Intel N150 in front of a static site and you pick FreeBSD or a modern Linux distribution for HTTPS, you are giving that little CPU a fair chance to shine.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://it-notes.dragas.net/2025/11/19/static-web-hosting-intel-n150-freebsd-smartos-netbsd-openbsd-linux/"/><published>2025-11-19T17:22:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45982526</id><title>Show HN: DNS Benchmark Tool ‚Äì Compare and monitor resolvers</title><updated>2025-11-19T23:10:10.303562+00:00</updated><content>&lt;doc fingerprint="2b0bb65311a27490"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Part of BuildTools - Network Performance Suite&lt;/head&gt;
    &lt;p&gt;Fast, comprehensive DNS performance testing with DNSSEC validation, DoH/DoT support, and enterprise features&lt;/p&gt;
    &lt;code&gt;pip install dns-benchmark-tool
dns-benchmark benchmark --use-defaults&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;üéâ 1,400+ downloads this week! Thank you to our growing community.&lt;/p&gt;&lt;lb/&gt;üì¢ Want multi-region testing? Join the waitlist ‚Üí&lt;/quote&gt;
    &lt;p&gt;Real Time Tracking&lt;/p&gt;
    &lt;p&gt;We‚Äôve added three powerful CLI commands to make DNS benchmarking even more versatile:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;üöÄ top ‚Äî quick ranking of resolvers by speed and reliability&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;üìä compare ‚Äî side‚Äëby‚Äëside benchmarking with detailed statistics and export options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;üîÑ monitoring ‚Äî continuous performance tracking with alerts and logging&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Quick resolver ranking
dns-benchmark top

# Compare resolvers side-by-side
dns-benchmark compare Cloudflare Google Quad9 --show-details

# Run monitoring for 1 hour with alerts
dns-benchmark monitoring --use-defaults --interval 30 --duration 3600 \
  --alert-latency 150 --alert-failure-rate 5 --output monitor.log&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DNS Benchmark Tool &lt;list rend="ul"&gt;&lt;item&gt;Part of BuildTools - Network Performance Suite&lt;/item&gt;&lt;item&gt;üéâ Today‚Äôs Release Highlights&lt;/item&gt;&lt;item&gt;Table of Contents&lt;/item&gt;&lt;item&gt;üéØ Why This Tool?&lt;/item&gt;&lt;item&gt;Quick start&lt;/item&gt;&lt;item&gt;‚ú® Key Features&lt;/item&gt;&lt;item&gt;üîß Advanced Capabilities&lt;/item&gt;&lt;item&gt;üíº Use Cases&lt;/item&gt;&lt;item&gt;üì¶ Installation &amp;amp; Setup&lt;/item&gt;&lt;item&gt;üìñ Usage Examples&lt;/item&gt;&lt;item&gt;üîß Utilities&lt;/item&gt;&lt;item&gt;Complete usage guide&lt;/item&gt;&lt;item&gt;üîç README Adjustments for Final Patch&lt;/item&gt;&lt;item&gt;‚ö° CLI Commands&lt;/item&gt;&lt;item&gt;üìä Analysis Enhancements&lt;/item&gt;&lt;item&gt;‚ö° Best Practices&lt;/item&gt;&lt;item&gt;Feedback &amp;amp; Community Input&lt;/item&gt;&lt;item&gt;‚öôÔ∏è Configuration Files&lt;/item&gt;&lt;item&gt;Output formats&lt;/item&gt;&lt;item&gt;Performance optimization&lt;/item&gt;&lt;item&gt;Troubleshooting&lt;/item&gt;&lt;item&gt;Automation &amp;amp; CI&lt;/item&gt;&lt;item&gt;Screenshots&lt;/item&gt;&lt;item&gt;Getting help&lt;/item&gt;&lt;item&gt;Release workflow&lt;/item&gt;&lt;item&gt;üåê Hosted Version (Coming Soon)&lt;/item&gt;&lt;item&gt;üõ£Ô∏è Roadmap&lt;/item&gt;&lt;item&gt;ü§ù Contributing&lt;/item&gt;&lt;item&gt;‚ùì FAQ&lt;/item&gt;&lt;item&gt;üîó Links &amp;amp; Support&lt;/item&gt;&lt;item&gt;License&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;DNS resolution is often the hidden bottleneck in network performance. A slow resolver can add hundreds of milliseconds to every request.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚è±Ô∏è Hidden Bottleneck: DNS can add 300ms+ to every request&lt;/item&gt;
      &lt;item&gt;ü§∑ Unknown Performance: Most developers never test their DNS&lt;/item&gt;
      &lt;item&gt;üåç Location Matters: "Fastest" resolver depends on where YOU are&lt;/item&gt;
      &lt;item&gt;üîí Security Varies: DNSSEC, DoH, DoT support differs wildly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;dns-benchmark-tool helps you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üîç Find the fastest DNS resolver for YOUR location&lt;/item&gt;
      &lt;item&gt;üìä Get real data - P95, P99, jitter, consistency scores&lt;/item&gt;
      &lt;item&gt;üõ°Ô∏è Validate security - DNSSEC verification built-in&lt;/item&gt;
      &lt;item&gt;üöÄ Test at scale - 100+ concurrent queries in seconds&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Developers optimizing API performance&lt;/item&gt;
      &lt;item&gt;‚úÖ DevOps/SRE validating resolver SLAs&lt;/item&gt;
      &lt;item&gt;‚úÖ Self-hosters comparing Pi-hole/Unbound vs public DNS&lt;/item&gt;
      &lt;item&gt;‚úÖ Network admins running compliance checks&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install dns-benchmark-tool&lt;/code&gt;
    &lt;code&gt;# Test default resolvers against popular domains
dns-benchmark benchmark --use-defaults&lt;/code&gt;
    &lt;p&gt;Results are automatically saved to &lt;code&gt;./benchmark_results/&lt;/code&gt; with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Summary CSV with statistics&lt;/item&gt;
      &lt;item&gt;Detailed raw data&lt;/item&gt;
      &lt;item&gt;Optional PDF/Excel reports&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's it! You just benchmarked 5 DNS resolvers against 10 domains.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Async queries - Test 100+ resolvers simultaneously&lt;/item&gt;
      &lt;item&gt;Multi-iteration - Run benchmarks multiple times for accuracy&lt;/item&gt;
      &lt;item&gt;Statistical analysis - Mean, median, P95, P99, jitter, consistency&lt;/item&gt;
      &lt;item&gt;Cache control - Test with/without DNS caching&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DNSSEC validation - Verify cryptographic trust chains&lt;/item&gt;
      &lt;item&gt;DNS-over-HTTPS (DoH) - Encrypted DNS benchmarking&lt;/item&gt;
      &lt;item&gt;DNS-over-TLS (DoT) - Secure transport testing&lt;/item&gt;
      &lt;item&gt;DNS-over-QUIC (DoQ) - Experimental QUIC support&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple formats - CSV, Excel, PDF, JSON&lt;/item&gt;
      &lt;item&gt;Visual reports - Charts and graphs&lt;/item&gt;
      &lt;item&gt;Domain statistics - Per-domain performance analysis&lt;/item&gt;
      &lt;item&gt;Error breakdown - Identify problematic resolvers&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;TSIG authentication - Secure enterprise queries&lt;/item&gt;
      &lt;item&gt;Zone transfers - AXFR/IXFR validation&lt;/item&gt;
      &lt;item&gt;Dynamic updates - Test DNS write operations&lt;/item&gt;
      &lt;item&gt;Compliance reports - Audit-ready documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux, macOS, Windows - Works everywhere&lt;/item&gt;
      &lt;item&gt;CI/CD friendly - JSON output, exit codes&lt;/item&gt;
      &lt;item&gt;IDNA support - Internationalized domain names&lt;/item&gt;
      &lt;item&gt;Auto-detection - Windows WMI DNS discovery&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;g-emoji&gt;‚ö†Ô∏è&lt;/g-emoji&gt;These flags are documented for visibility but not yet implemented.&lt;lb/&gt;They represent upcoming advanced features.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--doh&lt;/code&gt;‚Üí DNS-over-HTTPS benchmarking (coming soon)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--dot&lt;/code&gt;‚Üí DNS-over-TLS benchmarking (coming soon)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--doq&lt;/code&gt;‚Üí DNS-over-QUIC benchmarking (coming soon)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--dnssec-validate&lt;/code&gt;‚Üí DNSSEC trust chain validation (coming soon)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--zone-transfer&lt;/code&gt;‚Üí AXFR/IXFR zone transfer testing (coming soon)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--tsig&lt;/code&gt;‚Üí TSIG-authenticated queries (coming soon)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--idna&lt;/code&gt;‚Üí Internationalized domain name support (coming soon)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;üöÄ Performance &amp;amp; Concurrency Features&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Async I/O with dnspython - Test 100+ resolvers simultaneously&lt;/item&gt;
      &lt;item&gt;Trio framework support - High-concurrency async operations&lt;/item&gt;
      &lt;item&gt;Configurable concurrency - Control max concurrent queries&lt;/item&gt;
      &lt;item&gt;Retry logic - Exponential backoff for failed queries&lt;/item&gt;
      &lt;item&gt;Cache simulation - Test with/without DNS caching&lt;/item&gt;
      &lt;item&gt;Multi-iteration benchmarks - Run tests multiple times for accuracy&lt;/item&gt;
      &lt;item&gt;Warmup phase - Pre-warm DNS caches before testing&lt;/item&gt;
      &lt;item&gt;Statistical analysis - Mean, median, P95, P99, jitter, consistency scores&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;dns-benchmark benchmark \
  --max-concurrent 200 \
  --iterations 5 \
  --timeout 3.0 \
  --warmup&lt;/code&gt;
    &lt;head&gt;üîí Security &amp;amp; Privacy Features&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DNSSEC validation - Verify cryptographic trust chains&lt;/item&gt;
      &lt;item&gt;DNS-over-HTTPS (DoH) - Encrypted DNS benchmarking via HTTPS&lt;/item&gt;
      &lt;item&gt;DNS-over-TLS (DoT) - Secure transport layer testing&lt;/item&gt;
      &lt;item&gt;DNS-over-QUIC (DoQ) - Experimental QUIC protocol support&lt;/item&gt;
      &lt;item&gt;TSIG authentication - Transaction signatures for enterprise DNS&lt;/item&gt;
      &lt;item&gt;EDNS0 support - Extended DNS features and larger payloads&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Test DoH resolvers
dns-benchmark benchmark \
  --doh \
  --resolvers doh-providers.json \
  --dnssec-validate&lt;/code&gt;
    &lt;head&gt;üè¢ Enterprise &amp;amp; Migration Features&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zone transfers (AXFR/IXFR) - Full and incremental zone transfer validation&lt;/item&gt;
      &lt;item&gt;Dynamic DNS updates - Test DNS write operations and updates&lt;/item&gt;
      &lt;item&gt;EDNS0 support - Extended DNS options, client subnet, larger payloads&lt;/item&gt;
      &lt;item&gt;Windows WMI integration - Auto-detect active system DNS settings&lt;/item&gt;
      &lt;item&gt;Compliance reporting - Generate audit-ready PDF/Excel reports&lt;/item&gt;
      &lt;item&gt;SLA validation - Track uptime and performance thresholds&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Validate DNS migration
dns-benchmark benchmark \
  --resolvers old-provider.json,new-provider.json \
  --zone-transfer \ # coming soon
  --output migration-report/ \
  --formats pdf,excel&lt;/code&gt;
    &lt;head&gt;üìä Analysis &amp;amp; Reporting Features&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Per-domain statistics - Analyze performance by domain&lt;/item&gt;
      &lt;item&gt;Per-record-type stats - Compare A, AAAA, MX, TXT, etc.&lt;/item&gt;
      &lt;item&gt;Error breakdown - Categorize and count error types&lt;/item&gt;
      &lt;item&gt;Comparison matrices - Side-by-side resolver comparisons&lt;/item&gt;
      &lt;item&gt;Trend analysis - Performance over time (with multiple runs)&lt;/item&gt;
      &lt;item&gt;Best-by-criteria - Find best resolver by latency/reliability/consistency&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Detailed analysis
dns-benchmark benchmark \
  --use-defaults \
  --domain-stats \
  --record-type-stats \
  --error-breakdown \
  --formats csv,excel,pdf&lt;/code&gt;
    &lt;head&gt;üåê Internationalization &amp;amp; Compatibility&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IDNA support - Internationalized domain names (IDN)&lt;/item&gt;
      &lt;item&gt;Multiple record types - A, AAAA, MX, TXT, CNAME, NS, SOA, PTR, SRV, CAA&lt;/item&gt;
      &lt;item&gt;Cross-platform - Linux, macOS, Windows (native support)&lt;/item&gt;
      &lt;item&gt;CI/CD integration - JSON output, proper exit codes, quiet mode&lt;/item&gt;
      &lt;item&gt;Custom resolvers - Load from JSON, test your own DNS servers&lt;/item&gt;
      &lt;item&gt;Custom domains - Test against your specific domain list&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Test internationalized domains
dns-benchmark benchmark \
  --domains international-domains.txt \
  --record-types A,AAAA,MX \
  --resolvers custom-resolvers.json&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;üí° Most users only need basic features. These advanced capabilities are available when you need them.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;# Find fastest DNS for your API endpoints
dns-benchmark benchmark \
  --domains api.myapp.com,cdn.myapp.com \
  --record-types A,AAAA \
  --resolvers production.json \
  --iterations 10&lt;/code&gt;
    &lt;p&gt;Result: Reduce API latency by 100-300ms&lt;/p&gt;
    &lt;code&gt;# Test new DNS provider before switching
dns-benchmark benchmark \
  --resolvers current-dns.json,new-dns.json \
  --use-defaults \
  --dnssec-validate \ # coming soon
  --output migration-report/ \
  --formats pdf,excel&lt;/code&gt;
    &lt;p&gt;Result: Verify performance and security before migration&lt;/p&gt;
    &lt;code&gt;# Compare Pi-hole against public resolvers (coming soon)
dns-benchmark compare \
  --resolvers pihole.local,1.1.1.1,8.8.8.8,9.9.9.9 \
  --domains common-sites.txt \
  --rounds 10&lt;/code&gt;
    &lt;p&gt;Result: Data-driven proof your self-hosted DNS is faster (or not!)&lt;/p&gt;
    &lt;code&gt;# Add to crontab for monthly reports
0 0 1 * * dns-benchmark benchmark \
  --use-defaults \
  --output /var/reports/dns/ \
  --formats pdf,csv \
  --domain-stats \
  --error-breakdown&lt;/code&gt;
    &lt;p&gt;Result: Automated compliance and SLA reporting&lt;/p&gt;
    &lt;code&gt;# Benchmark privacy-focused DoH/DoT resolvers
dns-benchmark benchmark \
  --doh \ # coming soon
  --resolvers privacy-resolvers.json \
  --domains sensitive-sites.txt \
  --dnssec-validate&lt;/code&gt;
    &lt;p&gt;Result: Find fastest encrypted DNS without sacrificing privacy&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.9+&lt;/item&gt;
      &lt;item&gt;pip package manager&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install dns-benchmark-tool&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/frankovo/dns-benchmark-tool.git
cd dns-benchmark-tool
pip install -e .&lt;/code&gt;
    &lt;code&gt;dns-benchmark --version
dns-benchmark --help&lt;/code&gt;
    &lt;code&gt;# Test with defaults (recommended for first time)
dns-benchmark benchmark --use-defaults&lt;/code&gt;
    &lt;code&gt;# Basic test with progress bars
dns-benchmark benchmark --use-defaults

# Basic test without progress bars
dns-benchmark benchmark --use-defaults --quiet

# Test with custom resolvers and domains
dns-benchmark benchmark --resolvers data/resolvers.json --domains data/domains.txt

# Quick test with only CSV output
dns-benchmark benchmark --use-defaults --formats csv&lt;/code&gt;
    &lt;code&gt;# Export a machine-readable bundle
dns-benchmark benchmark --use-defaults --json --output ./results

# Test specific record types
dns-benchmark benchmark --use-defaults --record-types A,AAAA,MX

# Custom output location and formats
dns-benchmark benchmark \
  --use-defaults \
  --output ./my-results \
  --formats csv,excel,pdf,json

# Include detailed statistics
dns-benchmark benchmark \
  --use-defaults \
  --record-type-stats \
  --error-breakdown

# High concurrency with retries
dns-benchmark benchmark \
  --use-defaults \
  --max-concurrent 200 \
  --timeout 3.0 \
  --retries 3

# Website migration planning
dns-benchmark benchmark \
  --resolvers data/global_resolvers.json \
  --domains data/migration_domains.txt \
  --formats excel,pdf \
  --output ./migration_analysis

# DNS provider selection
dns-benchmark benchmark \
  --resolvers data/provider_candidates.json \
  --domains data/business_domains.txt \
  --formats csv,excel \
  --output ./provider_selection

# Network troubleshooting
dns-benchmark benchmark \
  --resolvers "192.168.1.1,1.1.1.1,8.8.8.8" \
  --domains "problematic-domain.com,working-domain.com" \
  --timeout 10 \
  --retries 3 \
  --formats csv \
  --output ./troubleshooting

# Security assessment
dns-benchmark benchmark \
  --resolvers data/security_resolvers.json \
  --domains data/security_test_domains.txt \
  --formats pdf \
  --output ./security_assessment

# Performance monitoring
dns-benchmark benchmark \
  --use-defaults \
  --formats csv \
  --quiet \
  --output /var/log/dns_benchmark/$(date +%Y%m%d_%H%M%S)

# New top commands
# Run a basic benchmark (default: rank by latency)
dns-benchmark top
# ‚Üí Tests all resolvers with sample domains, ranks by latency

# Limit the number of resolvers shown
dns-benchmark top --limit 5
# ‚Üí Shows only the top 5 resolvers

# Rank by success rate
dns-benchmark top --metric success
# ‚Üí Ranks resolvers by highest success rate

# Rank by reliability (combined score: success rate + latency)
dns-benchmark top --metric reliability
# ‚Üí Uses weighted score to rank resolvers

# Filter resolvers by category
dns-benchmark top --category privacy
dns-benchmark top --category family
dns-benchmark top --category security
# ‚Üí Tests only resolvers in the specified category

# Use a custom domain list
dns-benchmark top --domains domains.txt
# ‚Üí Loads domains from a text file instead of built-in sample list

# Specify DNS record types
dns-benchmark top --record-types A,AAAA,MX
# ‚Üí Queries multiple record types (comma-separated)

# Adjust timeout and concurrency
dns-benchmark top --timeout 3.0 --max-concurrent 50
# ‚Üí Sets query timeout to 3 seconds and limits concurrency to 50

# Export results to JSON
dns-benchmark top --output results.json
# ‚Üí Saves results in JSON format

# Export results to CSV
dns-benchmark top --output results.csv
# ‚Üí Saves results in CSV format

# Export results to TXT
dns-benchmark top --output results.txt
# ‚Üí Saves results in plain text format

# Quiet mode (no progress bar, CI/CD friendly)
dns-benchmark top --quiet
# ‚Üí Suppresses progress output

# Example combined usage
dns-benchmark top --limit 10 --metric reliability --category privacy --output top_resolvers.csv
# ‚Üí Benchmarks privacy resolvers, ranks by reliability, shows top 10, exports to CSV

# New compare commaands
# Comparison of resolvers by name
dns-benchmark compare Cloudflare Google Quad9
# ^ Compares Cloudflare, Google, and Quad9 resolvers using default domains and record type A

# Basic compare resolvers by IP address
dns-benchmark compare 1.1.1.1 8.8.8.8 9.9.9.9
# ^ Directly specify resolver IPs instead of names

# Increase iterations for more stable results
dns-benchmark compare "Cloudflare" "Google" --iterations 5
# ^ Runs 5 rounds of queries per resolver/domain/record type

# Use a custom domain list from file
dns-benchmark compare Cloudflare Google -d ./data/domains.txt
# ^ Loads domains from domains.txt instead of sample domains

# Query multiple record types
dns-benchmark compare Cloudflare Google -t A,AAAA,MX
# ^ Tests A, AAAA, and MX records for each domain

# Adjust timeout and concurrency
dns-benchmark compare Cloudflare Google --timeout 3.0 --max-concurrent 200
# ^ Sets query timeout to 3 seconds and allows 200 concurrent queries

# Export results to JSON
dns-benchmark compare Cloudflare Google -o results.json
# ^ Saves comparison summary to results.json

# Export results to CSV
dns-benchmark compare Cloudflare Google -o results.csv
# ^ Saves comparison summary to results.csv (via CSVExporter)

# Suppress progress output
dns-benchmark compare Cloudflare Google --quiet
# ^ Runs silently, only prints final results

# Show detailed per-domain breakdown
dns-benchmark compare Cloudflare Google --show-details
# ^ Prints average latency and success counts per domain for each resolver

# New monitoring commands
# Start monitoring with default resolvers and sample domains
dns-benchmark monitoring --use-defaults
# ^ Runs indefinitely, checking every 60s, using built-in resolvers and 5 sample domains

# Monitor with a custom resolver list from JSON
dns-benchmark monitoring -r resolvers.json --use-defaults
# ^ Loads resolvers from resolvers.json, domains from defaults

# Monitor with a custom domain list
dns-benchmark monitoring -d domains.txt --use-defaults
# ^ Uses default resolvers, but domains are loaded from domains.txt

# Change monitoring interval to 30 seconds
dns-benchmark monitoring --use-defaults --interval 30
# ^ Runs checks every 30 seconds instead of 60

# Run monitoring for a fixed duration (e.g., 1 hour = 3600 seconds)
dns-benchmark monitoring --use-defaults --duration 3600
# ^ Stops automatically after 1 hour

# Set stricter alert thresholds
dns-benchmark monitoring --use-defaults --alert-latency 150 --alert-failure-rate 5
# ^ Alerts if latency &amp;gt;150ms or failure rate &amp;gt;5%

# Save monitoring results to a log file
dns-benchmark monitoring --use-defaults --output monitor.log
# ^ Appends results and alerts to monitor.log

# Combine options: custom resolvers, domains, interval, duration, and logging
dns-benchmark monitoring -r resolvers.json -d domains.txt -i 45 --duration 1800 -o monitor.log
# ^ Monitors resolvers from resolvers.json against domains.txt every 45s, for 30 minutes, logging to monitor.log

# Run monitoring for 1 hour with alerts
dns-benchmark monitoring --use-defaults --interval 30 --duration 3600 \
  --alert-latency 150 --alert-failure-rate 5 --output monitor.log
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;Avg Latency: N/A&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;# Provide feedback
dns-benchmark feedback&lt;/code&gt;
    &lt;code&gt;# Show default resolvers and domains
dns-benchmark list-defaults

# Browse all available resolvers
dns-benchmark list-resolvers

# Browse with detailed information
dns-benchmark list-resolvers --details

# Filter by category
dns-benchmark list-resolvers --category security
dns-benchmark list-resolvers --category privacy
dns-benchmark list-resolvers --category family

# Export resolvers to different formats
dns-benchmark list-resolvers --format csv
dns-benchmark list-resolvers --format json&lt;/code&gt;
    &lt;code&gt;# List all test domains
dns-benchmark list-domains

# Show domains by category
dns-benchmark list-domains --category tech
dns-benchmark list-domains --category ecommerce
dns-benchmark list-domains --category social

# Limit results
dns-benchmark list-domains --count 10
dns-benchmark list-domains --category news --count 5

# Export domain list
dns-benchmark list-domains --format csv
dns-benchmark list-domains --format json&lt;/code&gt;
    &lt;code&gt;# View all available categories
dns-benchmark list-categories&lt;/code&gt;
    &lt;code&gt;# Generate sample configuration
dns-benchmark generate-config --output sample_config.yaml

# Category-specific configurations
dns-benchmark generate-config --category security --output security_test.yaml
dns-benchmark generate-config --category family --output family_protection.yaml
dns-benchmark generate-config --category performance --output performance_test.yaml

# Custom configuration for specific use case
dns-benchmark generate-config --category privacy --output privacy_audit.yaml&lt;/code&gt;
    &lt;code&gt;# Basic test with progress bars
dns-benchmark benchmark --use-defaults

# Quick test with only CSV output
dns-benchmark benchmark --use-defaults --formats csv --quiet

# Test specific record types
dns-benchmark benchmark --use-defaults --record-types A,AAAA,MX&lt;/code&gt;
    &lt;p&gt;Add-on analytics flags:&lt;/p&gt;
    &lt;code&gt;# Include domain and record-type analytics and error breakdown
dns-benchmark benchmark --use-defaults \
  --domain-stats --record-type-stats --error-breakdown&lt;/code&gt;
    &lt;p&gt;JSON export:&lt;/p&gt;
    &lt;code&gt;# Export a machine-readable bundle
dns-benchmark benchmark --use-defaults --json --output ./results&lt;/code&gt;
    &lt;code&gt;# Compare internal vs external DNS
dns-benchmark benchmark \
  --resolvers "192.168.1.1,1.1.1.1,8.8.8.8,9.9.9.9" \
  --domains "internal.company.com,google.com,github.com,api.service.com" \
  --formats excel,pdf \
  --timeout 3 \
  --max-concurrent 50 \
  --output ./network_audit

# Test DNS failover scenarios
dns-benchmark benchmark \
  --resolvers data/primary_resolvers.json \
  --domains data/business_critical_domains.txt \
  --record-types A,AAAA \
  --retries 3 \
  --formats csv,excel \
  --output ./failover_test&lt;/code&gt;
    &lt;code&gt;# Comprehensive ISP resolver comparison
dns-benchmark benchmark \
  --resolvers data/isp_resolvers.json \
  --domains data/popular_domains.txt \
  --timeout 5 \
  --max-concurrent 100 \
  --formats csv,excel,pdf \
  --output ./isp_performance_analysis

# Regional performance testing
dns-benchmark benchmark \
  --resolvers data/regional_resolvers.json \
  --domains data/regional_domains.txt \
  --formats excel \
  --quiet \
  --output ./regional_analysis&lt;/code&gt;
    &lt;code&gt;# Test application dependencies
dns-benchmark benchmark \
  --resolvers "1.1.1.1,8.8.8.8" \
  --domains "api.github.com,registry.npmjs.org,pypi.org,docker.io,aws.amazon.com" \
  --formats csv \
  --quiet \
  --output ./app_dependencies

# CI/CD integration test
dns-benchmark benchmark \
  --resolvers data/ci_resolvers.json \
  --domains data/ci_domains.txt \
  --timeout 2 \
  --formats csv \
  --quiet&lt;/code&gt;
    &lt;code&gt;# Security-focused resolver testing
dns-benchmark benchmark \
  --resolvers data/security_resolvers.json \
  --domains data/malware_test_domains.txt \
  --formats csv,pdf \
  --output ./security_audit

# Privacy-focused testing
dns-benchmark benchmark \
  --resolvers data/privacy_resolvers.json \
  --domains data/tracking_domains.txt \
  --formats excel \
  --output ./privacy_analysis&lt;/code&gt;
    &lt;code&gt;# Corporate network assessment
dns-benchmark benchmark \
  --resolvers data/enterprise_resolvers.json \
  --domains data/corporate_domains.txt \
  --record-types A,AAAA,MX,TXT,SRV \
  --timeout 10 \
  --max-concurrent 25 \
  --retries 2 \
  --formats csv,excel,pdf \
  --output ./enterprise_dns_audit

# Multi-location testing
dns-benchmark benchmark \
  --resolvers data/global_resolvers.json \
  --domains data/international_domains.txt \
  --formats excel \
  --output ./global_performance&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;--iterations, -i&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run the full benchmark loop N times&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;dns-benchmark benchmark --use-defaults -i 3&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;--use-cache&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Allow cached results to be reused across iterations&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;dns-benchmark benchmark --use-defaults -i 3 --use-cache&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;--warmup&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run a full warmup (all resolvers √ó domains √ó record types)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;dns-benchmark benchmark --use-defaults --warmup&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;--warmup-fast&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run a lightweight warmup (one probe per resolver)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;dns-benchmark benchmark --use-defaults --warmup-fast&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--include-charts&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Embed charts and graphs in PDF/Excel reports for visual performance analysis&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;dns-benchmark benchmark --use-defaults --formats pdf,excel --include-charts&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The DNS Benchmark Tool now includes three specialized commands for different workflows:&lt;/p&gt;
    &lt;p&gt;Quickly rank resolvers by speed and reliability.&lt;/p&gt;
    &lt;code&gt;# Rank resolvers quickly
dns-benchmark top

# Use custom domain list
dns-benchmark top -d domains.txt

# Export results to JSON
dns-benchmark top -o results.json&lt;/code&gt;
    &lt;p&gt;Benchmark resolvers side‚Äëby‚Äëside with detailed statistics.&lt;/p&gt;
    &lt;code&gt;# Compare Cloudflare, Google, and Quad9
dns-benchmark compare Cloudflare Google Quad9

# Compare by IP addresses
dns-benchmark compare 1.1.1.1 8.8.8.8 9.9.9.9

# Show detailed per-domain breakdown
dns-benchmark compare Cloudflare Google --show-details

# Export results to CSV
dns-benchmark compare Cloudflare Google -o results.csv&lt;/code&gt;
    &lt;p&gt;Continuously monitor resolver performance with alerts.&lt;/p&gt;
    &lt;code&gt;# Monitor default resolvers continuously (every 60s)
dns-benchmark monitoring --use-defaults

# Monitor with custom resolvers and domains
dns-benchmark monitoring -r resolvers.json -d domains.txt

# Run monitoring for 1 hour with alerts
dns-benchmark monitoring --use-defaults --interval 30 --duration 3600 \
  --alert-latency 150 --alert-failure-rate 5 --output monitor.log&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Typical Use Case&lt;/cell&gt;
        &lt;cell role="head"&gt;Key Options&lt;/cell&gt;
        &lt;cell role="head"&gt;Output&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;top&lt;/cell&gt;
        &lt;cell&gt;Quick ranking of resolvers by speed and reliability&lt;/cell&gt;
        &lt;cell&gt;Fast check to see which resolver is best right now&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--domains&lt;/code&gt;, &lt;code&gt;--record-types&lt;/code&gt;, &lt;code&gt;--output&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Sorted list of resolvers with latency &amp;amp; success rate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;compare&lt;/cell&gt;
        &lt;cell&gt;Side‚Äëby‚Äëside comparison of specific resolvers&lt;/cell&gt;
        &lt;cell&gt;Detailed benchmarking across chosen resolvers/domains&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--domains&lt;/code&gt;, &lt;code&gt;--record-types&lt;/code&gt;, &lt;code&gt;--iterations&lt;/code&gt;, &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--show-details&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Table of resolvers with latency, success rate, per‚Äëdomain breakdown&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;monitoring&lt;/cell&gt;
        &lt;cell&gt;Continuous monitoring with alerts&lt;/cell&gt;
        &lt;cell&gt;Real‚Äëtime tracking of resolver performance over time&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--interval&lt;/code&gt;, &lt;code&gt;--duration&lt;/code&gt;, &lt;code&gt;--alert-latency&lt;/code&gt;, &lt;code&gt;--alert-failure-rate&lt;/code&gt;, &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--use-defaults&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Live status indicators, alerts, optional log file&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Iteration count: displayed when more than one iteration is run.&lt;/item&gt;
      &lt;item&gt;Cache hits: shows how many queries were served from cache (when &lt;code&gt;--use-cache&lt;/code&gt;is enabled).&lt;/item&gt;
      &lt;item&gt;Failure tracking: resolvers with repeated errors are counted and can be inspected with &lt;code&gt;get_failed_resolvers()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Cache statistics: available via &lt;code&gt;get_cache_stats()&lt;/code&gt;, showing number of cached entries and whether cache is enabled.&lt;/item&gt;
      &lt;item&gt;Warmup results: warmup queries are marked with &lt;code&gt;iteration=0&lt;/code&gt;in raw data, making them easy to filter out in analysis.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example summary output:&lt;/p&gt;
    &lt;code&gt;=== BENCHMARK SUMMARY ===
Total queries: 150
Successful: 140 (93.33%)
Average latency: 212.45 ms
Median latency: 198.12 ms
Fastest resolver: Cloudflare
Slowest resolver: Quad9
Iterations: 3
Cache hits: 40 (26.7%)&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Mode&lt;/cell&gt;
        &lt;cell role="head"&gt;Recommended Flags&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Quick Run&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;--iterations 1 --timeout 1 --retries 0 --warmup-fast&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fast feedback, minimal retries, lightweight warmup. Good for quick checks.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Thorough Run&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;--iterations 3 --use-cache --warmup --timeout 5 --retries 2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Multiple passes, cache enabled, full warmup. Best for detailed benchmarking.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Debug Mode&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;--iterations 1 --timeout 10 --retries 0 --quiet&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Long timeout, no retries, minimal output. Useful for diagnosing resolver issues.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Balanced Run&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;--iterations 2 --use-cache --warmup-fast --timeout 2 --retries 1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;A middle ground: moderate speed, some retries, cache enabled, quick warmup.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We value your input! Help us improve dns-benchmark by sharing your experience and DNS challenges.&lt;/p&gt;
    &lt;p&gt;Open the feedback form directly from CLI:&lt;/p&gt;
    &lt;code&gt;dns-benchmark feedback&lt;/code&gt;
    &lt;p&gt;This command:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Opens the feedback survey in your default browser&lt;/item&gt;
      &lt;item&gt;Takes ~2 minutes to complete&lt;/item&gt;
      &lt;item&gt;Directly shapes our roadmap and priorities&lt;/item&gt;
      &lt;item&gt;Automatically marks feedback as given (won't prompt again)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Survey link: https://forms.gle/BJBiyBFvRJHskyR57&lt;/p&gt;
    &lt;p&gt;To avoid being intrusive, dns-benchmark uses intelligent prompting:&lt;/p&gt;
    &lt;p&gt;When prompts appear:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;After your 5th, 15th, and 30th benchmark run&lt;/item&gt;
      &lt;item&gt;With a 24-hour cooldown between prompts&lt;/item&gt;
      &lt;item&gt;Only if you haven't already given feedback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Auto-dismiss conditions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You've already submitted feedback&lt;/item&gt;
      &lt;item&gt;You've dismissed the prompt 3 times&lt;/item&gt;
      &lt;item&gt;You've opted out via environment variable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example prompt:&lt;/p&gt;
    &lt;code&gt;‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üì¢ Quick feedback request
Help shape dns-benchmark! Share your biggest DNS challenge.
‚Üí https://forms.gle/BJBiyBFvRJHskyR57 (2 min survey)
‚Üí Or run: dns-benchmark feedback
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Show this again? (y/n) [y]:
&lt;/code&gt;
    &lt;p&gt;What we store locally: dns-benchmark stores feedback prompt state in &lt;code&gt;~/.dns-benchmark/feedback.json&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Contents:&lt;/p&gt;
    &lt;code&gt;{
  "total_runs": 15,
  "feedback_given": false,
  "dismissed_count": 0,
  "last_shown": 1699876543,
  "version": "1.0"
}&lt;/code&gt;
    &lt;p&gt;Privacy notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ All data stored locally on your machine&lt;/item&gt;
      &lt;item&gt;‚úÖ No telemetry or tracking&lt;/item&gt;
      &lt;item&gt;‚úÖ No automatic data transmission&lt;/item&gt;
      &lt;item&gt;‚úÖ File is only read/written during benchmark runs&lt;/item&gt;
      &lt;item&gt;‚úÖ Safe to delete at any time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What we collect (only when you submit feedback):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Whatever you choose to share in the survey&lt;/item&gt;
      &lt;item&gt;We never collect usage data automatically&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Method 1: Dismiss the prompt When prompted, type &lt;code&gt;n&lt;/code&gt; to dismiss:&lt;/p&gt;
    &lt;code&gt;Show this again? (y/n) [y]: n
‚úì Got it! We won't ask again. Thanks for using dns-benchmark!
&lt;/code&gt;
    &lt;p&gt;After 3 dismissals, prompts stop permanently.&lt;/p&gt;
    &lt;p&gt;Method 2: Environment variable (complete disable)&lt;/p&gt;
    &lt;code&gt;# Bash/Zsh
export DNS_BENCHMARK_NO_FEEDBACK=1

# Windows PowerShell
$env:DNS_BENCHMARK_NO_FEEDBACK="1"

# Permanently (add to ~/.bashrc or ~/.zshrc)
echo 'export DNS_BENCHMARK_NO_FEEDBACK=1' &amp;gt;&amp;gt; ~/.bashrc&lt;/code&gt;
    &lt;p&gt;Method 3: Delete state file&lt;/p&gt;
    &lt;code&gt;rm ~/.dns-benchmark/feedback.json&lt;/code&gt;
    &lt;p&gt;Method 4: CI/CD environments Feedback prompts are automatically disabled when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;CI=true&lt;/code&gt;environment variable is set (standard in GitHub Actions, GitLab CI, etc.)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--quiet&lt;/code&gt;flag is used&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Reset for testing (developers):&lt;/p&gt;
    &lt;code&gt;dns-benchmark reset-feedback  # Hidden command&lt;/code&gt;
    &lt;code&gt;{
  "resolvers": [
    {
      "name": "Cloudflare",
      "ip": "1.1.1.1",
      "ipv6": "2606:4700:4700::1111"
    },
    {
      "name": "Google DNS",
      "ip": "8.8.8.8",
      "ipv6": "2001:4860:4860::8888"
    }
  ]
}&lt;/code&gt;
    &lt;code&gt;# Popular websites
google.com
github.com
stackoverflow.com

# Corporate domains
microsoft.com
apple.com
amazon.com

# CDN and cloud
cloudflare.com
aws.amazon.com&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raw data: individual query results with timestamps and metadata&lt;/item&gt;
      &lt;item&gt;Summary statistics: aggregated metrics per resolver&lt;/item&gt;
      &lt;item&gt;Domain statistics: per-domain metrics (when --domain-stats)&lt;/item&gt;
      &lt;item&gt;Record type statistics: per-record-type metrics (when --record-type-stats)&lt;/item&gt;
      &lt;item&gt;Error breakdown: counts by error type (when --error-breakdown)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raw data sheet: all query results with formatting&lt;/item&gt;
      &lt;item&gt;Resolver summary: comprehensive statistics with conditional formatting&lt;/item&gt;
      &lt;item&gt;Domain stats: per-domain performance (optional)&lt;/item&gt;
      &lt;item&gt;Record type stats: per-record-type performance (optional)&lt;/item&gt;
      &lt;item&gt;Error breakdown: aggregated error counts (optional)&lt;/item&gt;
      &lt;item&gt;Performance analysis: charts and comparative analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Executive summary: key findings and recommendations&lt;/item&gt;
      &lt;item&gt;Performance charts: latency comparison; optional success rate chart&lt;/item&gt;
      &lt;item&gt;Resolver rankings: ordered by average latency&lt;/item&gt;
      &lt;item&gt;Detailed analysis: technical deep‚Äëdive with percentiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Machine‚Äëreadable bundle including: &lt;list rend="ul"&gt;&lt;item&gt;Overall statistics&lt;/item&gt;&lt;item&gt;Resolver statistics&lt;/item&gt;&lt;item&gt;Raw query results&lt;/item&gt;&lt;item&gt;Domain statistics&lt;/item&gt;&lt;item&gt;Record type statistics&lt;/item&gt;&lt;item&gt;Error breakdown&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;dns-benchmark generate-config \
  --category privacy \
  --output my-config.yaml&lt;/code&gt;
    &lt;code&gt;# Large-scale testing (1000+ queries)
dns-benchmark benchmark \
  --resolvers data/many_resolvers.json \
  --domains data/many_domains.txt \
  --max-concurrent 50 \
  --timeout 3 \
  --quiet \
  --formats csv

# Unstable networks
dns-benchmark benchmark \
  --resolvers data/backup_resolvers.json \
  --domains data/critical_domains.txt \
  --timeout 10 \
  --retries 3 \
  --max-concurrent 10

# Quick diagnostics
dns-benchmark benchmark \
  --resolvers "1.1.1.1,8.8.8.8" \
  --domains "google.com,cloudflare.com" \
  --formats csv \
  --quiet \
  --timeout 2&lt;/code&gt;
    &lt;code&gt;# Command not found
pip install -e .
python -m dns_benchmark.cli --help

# PDF generation fails (Ubuntu/Debian)
sudo apt-get install libcairo2 libpango-1.0-0 libpangocairo-1.0-0 \
  libgdk-pixbuf2.0-0 libffi-dev shared-mime-info
# Or skip PDF
dns-benchmark benchmark --use-defaults --formats csv,excel

# Network timeouts
dns-benchmark benchmark --use-defaults --timeout 10 --retries 3
dns-benchmark benchmark --use-defaults --max-concurrent 25&lt;/code&gt;
    &lt;code&gt;# Verbose run
python -m dns_benchmark.cli benchmark --use-defaults --formats csv

# Minimal configuration
dns-benchmark benchmark --resolvers "1.1.1.1" --domains "google.com" --formats csv&lt;/code&gt;
    &lt;code&gt;# Daily monitoring
0 2 * * * /usr/local/bin/dns-benchmark benchmark --use-defaults --formats csv --quiet --output /var/log/dns_benchmark/daily_$(date +\%Y\%m\%d)

# Time-based variability (every 6 hours)
0 */6 * * * /usr/local/bin/dns-benchmark benchmark --use-defaults --formats csv --quiet --output /var/log/dns_benchmark/$(date +\%Y\%m\%d_\%H)&lt;/code&gt;
    &lt;code&gt;- name: DNS Performance Test
  run: |
    pip install dnspython pandas click tqdm colorama
    dns-benchmark benchmark \
      --resolvers "1.1.1.1,8.8.8.8" \
      --domains "api.service.com,database.service.com" \
      --formats csv \
      --quiet&lt;/code&gt;
    &lt;p&gt;Place images in &lt;code&gt;docs/screenshots/&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;docs/screenshots/cli_run.png&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;docs/screenshots/excel_report.png&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;docs/screenshots/pdf_summary.png&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;docs/screenshots/pdf_charts.png&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;docs/screenshots/excel_charts.png&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;docs/screenshots/real_time_monitoring.png&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;dns-benchmark --help
dns-benchmark benchmark --help
dns-benchmark list-resolvers --help
dns-benchmark list-domains --help
dns-benchmark list-categories --help
dns-benchmark generate-config --help&lt;/code&gt;
    &lt;p&gt;Common scenarios:&lt;/p&gt;
    &lt;code&gt;# I'm new ‚Äî where to start?
dns-benchmark list-defaults
dns-benchmark benchmark --use-defaults

# Test specific resolvers
dns-benchmark list-resolvers --category security
dns-benchmark benchmark --resolvers data/security_resolvers.json --use-defaults

# Generate a management report
dns-benchmark benchmark --use-defaults --formats excel,pdf \
  --domain-stats --record-type-stats --error-breakdown --json \
  --output ./management_report&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Prerequisites&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;GPG key configured: run &lt;code&gt;make gpg-check&lt;/code&gt;to verify.&lt;/item&gt;
          &lt;item&gt;Branch protection: main requires signed commits and passing CI.&lt;/item&gt;
          &lt;item&gt;CI publish: triggered on signed tags matching vX.Y.Z.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;GPG key configured: run &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Prepare release (signed)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Patch/minor/major bump:&lt;/p&gt;
            &lt;code&gt;make release-patch # or: make release-minor / make release-major&lt;/code&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;Updates versions.&lt;/item&gt;
              &lt;item&gt;Creates or reuses &lt;code&gt;release/X.Y.Z&lt;/code&gt;.&lt;/item&gt;
              &lt;item&gt;Makes a signed commit and pushes the branch.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Open PR: from&lt;/p&gt;&lt;code&gt;release/X.Y.Z&lt;/code&gt;into&lt;code&gt;main&lt;/code&gt;, then merge once CI passes.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tag and publish&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Create signed tag and push:&lt;/p&gt;
            &lt;quote&gt;make release-tag VERSION=X.Y.Z&lt;/quote&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;Tags main with &lt;code&gt;vX.Y.Z&lt;/code&gt;(signed).&lt;/item&gt;
              &lt;item&gt;CI publishes to PyPI.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;Tags main with &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manual alternative&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Create branch and commit signed:&lt;/p&gt;
            &lt;quote&gt;git checkout -b release/manually-update-version-based-on-release-pattern git add . git commit -S -m "Release release/$NEXT_VERSION" git push origin release/$NEXT_VERSION&lt;/quote&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Open PR and merge into main.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Then tag:&lt;/p&gt;
            &lt;code&gt;make release-tag VERSION=$NEXT_VERSION&lt;/code&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Notes&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Signed commits: &lt;code&gt;git commit -S ...&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Signed tags: &lt;code&gt;git tag -s vX.Y.Z -m "Release vX.Y.Z"&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Version sources: &lt;code&gt;pyproject.toml&lt;/code&gt;and&lt;code&gt;src/dns_benchmark/__init__.py&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Signed commits: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;CLI stays free forever. The hosted version adds features impossible to achieve locally:&lt;/p&gt;
    &lt;p&gt;Test from US-East, US-West, EU, Asia simultaneously. See how your DNS performs for users worldwide.&lt;/p&gt;
    &lt;p&gt;Monitor DNS performance over time. Identify trends, degradation, and optimize continuously.&lt;/p&gt;
    &lt;p&gt;Get notified via Email, Slack, PagerDuty when DNS performance degrades or SLA thresholds are breached.&lt;/p&gt;
    &lt;p&gt;Share results, dashboards, and reports across your team. Role-based access control.&lt;/p&gt;
    &lt;p&gt;Automated monthly reports proving DNS provider meets SLA guarantees. Audit-ready documentation.&lt;/p&gt;
    &lt;p&gt;Integrate DNS monitoring into your existing observability stack. Prometheus, Datadog, Grafana.&lt;/p&gt;
    &lt;p&gt;Join the Waitlist ‚Üí | Early access gets 50% off for 3 months&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Benchmark DNS resolvers across domains and record types&lt;/item&gt;
      &lt;item&gt;Export to CSV, Excel, PDF, JSON&lt;/item&gt;
      &lt;item&gt;Statistical analysis (P95, P99, jitter, consistency)&lt;/item&gt;
      &lt;item&gt;Automation support (CI/CD, cron)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;CLI stays free forever. Hosted adds:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üåç Multi-region testing (US, EU, Asia, custom)&lt;/item&gt;
      &lt;item&gt;üìä Historical tracking with charts and trends&lt;/item&gt;
      &lt;item&gt;üö® Alerts (Email, Slack, PagerDuty, webhooks)&lt;/item&gt;
      &lt;item&gt;üë• Team collaboration and sharing&lt;/item&gt;
      &lt;item&gt;üìà SLA compliance reporting&lt;/item&gt;
      &lt;item&gt;üîå API access and integrations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Join Waitlist for early access&lt;/p&gt;
    &lt;p&gt;Part of BuildTools - Network Performance Suite:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üîç HTTP/HTTPS Benchmark - Test API endpoints and CDNs&lt;/item&gt;
      &lt;item&gt;üîí SSL Certificate Monitor - Never miss renewals&lt;/item&gt;
      &lt;item&gt;üì° Uptime Monitor - 24/7 availability tracking&lt;/item&gt;
      &lt;item&gt;üåê API Health Dashboard - Complete network observability&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Help shape our roadmap:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üìù 2-minute feedback survey&lt;/item&gt;
      &lt;item&gt;üí¨ GitHub Discussions&lt;/item&gt;
      &lt;item&gt;‚≠ê Star us if this helps you!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We love contributions! Here's how you can help:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üêõ Report bugs - Open an issue&lt;/item&gt;
      &lt;item&gt;üí° Suggest features - Start a discussion&lt;/item&gt;
      &lt;item&gt;üìù Improve docs - README, examples, tutorials&lt;/item&gt;
      &lt;item&gt;üîß Submit PRs - Bug fixes, features, tests&lt;/item&gt;
      &lt;item&gt;‚≠ê Star the repo - Help others discover the tool&lt;/item&gt;
      &lt;item&gt;üì¢ Spread the word - Tweet, blog, share&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project includes a &lt;code&gt;Makefile&lt;/code&gt; to simplify installation, testing, and code quality checks.&lt;/p&gt;
    &lt;code&gt;.PHONY: install install-dev uninstall mypy black isort flake8 cov test clean cli-test

# üîß Install package (runtime only)
install:
  pip install .

# üîß Install package with dev extras (pytest, mypy, flake8, black, isort, etc.)
install-dev:
  pip install .[dev]

# üîß Uninstall package
uninstall:
  pip uninstall -y dns-benchmark-tool \
  dnspython pandas aiohttp click pyfiglet colorama Jinja2 weasyprint openpyxl pyyaml tqdm matplotlib \
  mypy black flake8 autopep8 pytest coverage isort

mypy:
  mypy .

isort:
  isort .

black:
  black .

flake8:
  flake8 src tests --ignore=E126,E501,E712,F405,F403,E266,W503 --max-line-length=88 --extend-ignore=E203

cov:
  coverage erase
  coverage run --source=src -m pytest -vv -s
  coverage html

test: mypy black isort flake8 cov

clean:
  rm -rf __pycache__ .pytest_cache htmlcov .coverage coverage.xml \
  build dist *.egg-info .eggs benchmark_results
cli-test:
  # Run only the CLI smoke tests marked with @pytest.mark.cli
  pytest -vv -s -m cli tests/test_cli_commands.py&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Install runtime only&lt;/p&gt;
        &lt;quote&gt;make install&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install with dev dependencies&lt;/p&gt;
        &lt;quote&gt;make install-dev&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run type checks, linting, formatting, and tests&lt;/p&gt;
        &lt;code&gt;make test&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run CLI smoke tests only&lt;/p&gt;
        &lt;quote&gt;make cli-test&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Clean build/test artifacts&lt;/p&gt;
        &lt;quote&gt;make clean&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow PEP 8 style guide&lt;/item&gt;
      &lt;item&gt;Add tests for new features&lt;/item&gt;
      &lt;item&gt;Update documentation&lt;/item&gt;
      &lt;item&gt;Keep PRs focused and atomic&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Why is my ISP's DNS not fastest?&lt;/head&gt;
    &lt;p&gt;Local ISP DNS often has caching advantages but may lack:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Global anycast network (slower for distant domains)&lt;/item&gt;
      &lt;item&gt;DNSSEC validation&lt;/item&gt;
      &lt;item&gt;Privacy features (DoH/DoT)&lt;/item&gt;
      &lt;item&gt;Reliability guarantees&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Test both and decide based on YOUR priorities!&lt;/p&gt;
    &lt;head&gt;How often should I benchmark DNS?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One-time: When choosing DNS provider&lt;/item&gt;
      &lt;item&gt;Monthly: For network health checks&lt;/item&gt;
      &lt;item&gt;Before migration: When switching providers&lt;/item&gt;
      &lt;item&gt;After issues: To troubleshoot performance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Can I test my own DNS server?&lt;/head&gt;
    &lt;p&gt;Yes! Just add it to a custom resolvers JSON file:&lt;/p&gt;
    &lt;code&gt;{
  "resolvers": [
    {"name": "My DNS", "ip": "192.168.1.1"}
  ]
}&lt;/code&gt;
    &lt;head&gt;What's the difference between CLI and hosted version?&lt;/head&gt;
    &lt;p&gt;CLI (Free Forever):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run tests from YOUR location&lt;/item&gt;
      &lt;item&gt;Save results locally&lt;/item&gt;
      &lt;item&gt;Manual execution&lt;/item&gt;
      &lt;item&gt;Open source&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hosted (Coming Soon):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test from MULTIPLE regions&lt;/item&gt;
      &lt;item&gt;Historical tracking&lt;/item&gt;
      &lt;item&gt;Automated scheduling&lt;/item&gt;
      &lt;item&gt;Alerts and integrations&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Is this tool safe to use in production?&lt;/head&gt;
    &lt;p&gt;Yes! The tool only performs DNS lookups (read operations). It does NOT:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modify DNS records&lt;/item&gt;
      &lt;item&gt;Perform attacks&lt;/item&gt;
      &lt;item&gt;Send data to external servers (unless you enable hosted features)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All tests are standard DNS queries that any resolver handles daily.&lt;/p&gt;
    &lt;head&gt;Why do results vary between runs?&lt;/head&gt;
    &lt;p&gt;DNS performance varies due to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Network conditions&lt;/item&gt;
      &lt;item&gt;DNS caching (resolver and intermediate)&lt;/item&gt;
      &lt;item&gt;Server load&lt;/item&gt;
      &lt;item&gt;Geographic routing changes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run multiple iterations (&lt;code&gt;--iterations 5&lt;/code&gt;) for more consistent results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Website: buildtools.net&lt;/item&gt;
      &lt;item&gt;PyPI: dns-benchmark-tool&lt;/item&gt;
      &lt;item&gt;GitHub: frankovo/dns-benchmark-tool&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Feedback: 2-minute survey&lt;/item&gt;
      &lt;item&gt;Discussions: GitHub Discussions&lt;/item&gt;
      &lt;item&gt;Issues: Bug Reports&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Downloads: 1,400+ (this week)&lt;/item&gt;
      &lt;item&gt;Active Users: 600+&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the MIT License ‚Äî see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Built with ‚ù§Ô∏è by @frankovo&lt;/p&gt;
    &lt;p&gt;Part of BuildTools - Network Performance Suite&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/frankovo/dns-benchmark-tool"/><published>2025-11-19T17:52:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45982649</id><title>Building more with GPT-5.1-Codex-Max</title><updated>2025-11-19T23:10:10.089824+00:00</updated><content>&lt;doc fingerprint="af48c13f1c3bd48c"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôre introducing GPT‚Äë5.1-Codex-Max, our new frontier agentic coding model, available in Codex today. GPT‚Äë5.1-Codex-Max is built on an update to our foundational reasoning model, which is trained on agentic tasks across software engineering, math, research, and more. GPT‚Äë5.1-Codex-Max is faster, more intelligent, and more token-efficient at every stage of the development cycle‚Äìand a new step towards becoming a reliable coding partner.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max is built for long-running, detailed work. It‚Äôs our first model natively trained to operate across multiple context windows through a process called compaction, coherently working over millions of tokens in a single task. This unlocks project-scale refactors, deep debugging sessions, and multi-hour agent loops.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max is available in Codex today for use in the CLI, IDE extension, cloud, and code review, and API access is coming soon.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max was trained on real-world software engineering tasks, like PR creation, code review, frontend coding, and Q&amp;amp;A and outperforms our previous models on many frontier coding evaluations. The model‚Äôs gains on benchmarks also come with improvements to real-world usage: GPT‚Äë5.1-Codex-Max is the first model we have trained to operate in Windows environments, and the model‚Äôs training now includes tasks designed to make it a better collaborator in the Codex CLI.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max shows significant improvements in token efficiency due to more effective reasoning. On SWE-bench Verified, GPT‚Äë5.1-Codex-Max with ‚Äòmedium‚Äô reasoning effort achieves better performance than GPT‚Äë5.1-Codex with the same reasoning effort, while using 30% fewer thinking tokens. For non-latency-sensitive tasks, we‚Äôre also introducing a new Extra High (‚Äòxhigh‚Äô) reasoning effort, which thinks for an even longer period of time for a better answer. We still recommend medium as the daily driver for most tasks.&lt;/p&gt;
    &lt;p&gt;We expect the token efficiency improvements to translate to real-world savings for developers.&lt;/p&gt;
    &lt;p&gt;For example, GPT‚Äë5.1-Codex-Max is able to produce high quality frontend designs with similar functionality and aesthetics, but at much lower cost than GPT‚Äë5.1-Codex.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;Prompt:&lt;/code&gt;
      &lt;code&gt; Generate a single self-contained browser app that renders an interactive CartPole RL sandbox with canvas graphics, a tiny policy-gradient controller, metrics, and an SVG network visualizer.&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;Features&lt;/code&gt;
    &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;Must be able to actually train a policy to make model better at cart pole&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Visualizer for the activations/weights when the model is training or at inference&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Steps in the episode, rewards this episode&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Last survival time and best survival time in steps&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;Save to index.html&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Compaction enables GPT‚Äë5.1-Codex-Max to complete tasks that would have previously failed due to context-window limits, such as complex refactors and long-running agent loops by pruning its history while preserving the most important context over long horizons. In Codex applications, GPT‚Äë5.1-Codex-Max automatically compacts its session when it approaches its context window limit, giving it a fresh context window. It repeats this process until the task is completed.&lt;/p&gt;
    &lt;p&gt;The ability to sustain coherent work over long horizons is a foundational capability on the path toward more general, reliable AI systems. GPT‚Äë5.1-Codex-Max can work independently for hours at a time. In our internal evaluations, we‚Äôve observed GPT‚Äë5.1-Codex-Max work on tasks for more than 24 hours. It will persistently iterate on its implementation, fix test failures, and ultimately deliver a successful result.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max performs significantly better on evaluations that require sustained, long-horizon reasoning. Because it can coherently work across multiple context windows using compaction, the model delivers improved results on challenges in areas like long-horizon coding and cybersecurity. We analyzed the results of this model‚Äôs performance on first- and third-party evaluations in the GPT‚Äë5.1-Codex-Max system card.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max does not reach High capability on Cybersecurity under our Preparedness Framework but it is the most capable cybersecurity model we‚Äôve deployed to date and agentic cybersecurity capabilities are rapidly evolving. As a result, we are taking steps to prepare for High capability on Cybersecurity and are enhancing our safeguards in the cyber domain and working to ensure that defenders can benefit from these improved capabilities through programs like Aardvark.&lt;/p&gt;
    &lt;p&gt;When we launched GPT‚Äë5-Codex, we implemented dedicated cybersecurity-specific monitoring to detect and disrupt malicious activity. While we have not observed a meaningful increase in scaled abuse, we are preparing additional mitigations for advanced capabilities. Our teams have already disrupted cyber operations attempting to misuse our models, and suspicious activity is routed for review through our policy monitoring systems.&lt;/p&gt;
    &lt;p&gt;Codex is designed to run in a secure sandbox by default: file writes are limited to its workspace, and network access is disabled unless a developer turns it on. We recommend keeping Codex in this restricted-access mode, since enabling internet or web search can introduce prompt-injection risks from untrusted content.&lt;/p&gt;
    &lt;p&gt;As Codex becomes more capable of long-running tasks, it is increasingly important for developers to review the agent‚Äôs work before making changes or deploying to production. To assist with this, Codex produces terminal logs and cites its tool calls and test results. While its code reviews reduce the risk of deploying model or human produced bugs to production, Codex should be treated as an additional reviewer and not a replacement for human reviews.&lt;/p&gt;
    &lt;p&gt;Cybersecurity capabilities can be used for both defense and offense, so we take an iterative deployment approach: learning from real-world use, updating safeguards, and preserving important defensive tools such as automated vulnerability scanning and remediation assistance.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max is available in Codex with ChatGPT Plus, Pro, Business, Edu, and Enterprise plans. For details on how usage limits work for your plan, please see our docs(opens in a new window).&lt;/p&gt;
    &lt;p&gt;For developers using Codex CLI via API key, we plan to make GPT‚Äë5.1-Codex-Max available in the API soon.&lt;/p&gt;
    &lt;p&gt;Starting today, GPT‚Äë5.1-Codex-Max will replace GPT‚Äë5.1-Codex as the default model in Codex surfaces. Unlike GPT‚Äë5.1, which is a general-purpose model, we recommend using GPT‚Äë5.1-Codex-Max and the Codex family of models only for agentic coding tasks in Codex or Codex-like environments.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.1-Codex-Max shows how far models have come in sustaining long-horizon coding tasks, managing complex workflows, and producing high-quality implementations with far fewer tokens. We‚Äôve seen the model combined with steady upgrades to our CLI, IDE extension, cloud integration, and code review tooling result in supercharged engineering productivity: internally, 95% of OpenAI engineers use Codex weekly, and these engineers ship roughly 70% more pull requests since adopting Codex. As we push the frontier of what agents are able to do, we‚Äôre excited to see what you'll build with them.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‚Äë5.1-Codex (high)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‚Äë5.1-Codex-Max (xhigh)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;SWE-bench Verified (n=500)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;73.7%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;77.9%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;SWE-Lancer IC SWE&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;66.3%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;79.9%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Terminal-Bench 2.0&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;52.8%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;58.1%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/gpt-5-1-codex-max/"/><published>2025-11-19T18:01:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45984072</id><title>Pozsar's Bretton Woods III: The Framework</title><updated>2025-11-19T23:10:09.958036+00:00</updated><content>&lt;doc fingerprint="738b89f505a75594"&gt;
  &lt;main&gt;
    &lt;p&gt;In March 2022, as Western nations imposed unprecedented sanctions following Russia‚Äôs invasion of Ukraine, Zoltan Pozsar published a series of dispatches that would become some of the most discussed pieces in financial markets that year. The core thesis was stark: we were witnessing the birth of ‚ÄúBretton Woods III,‚Äù a fundamental shift in how the global monetary system operates. Nearly three years later, with more data on de-dollarization trends, commodity market dynamics, and structural changes in global trade, it‚Äôs worth revisiting this framework.&lt;/p&gt;
    &lt;p&gt;I first heard of Pozsar at Credit Suisse during the 2019 repo market disruptions and the March 2020 funding crisis, when his framework explained market dynamics in a way I have never seen it before. Before joining Credit Suisse as a short-term rate strategist, Pozsar spent years at the Federal Reserve (where he created the map of the shadow banking system, which prompted the G20 to initiate regulatory measures in this area) and the U.S. Treasury. His work focuses on what he calls the ‚Äúplumbing‚Äù of financial markets, the often-overlooked mechanisms through which money actually flows through the system. His intellectual approach draws heavily from Perry Mehrling‚Äôs ‚Äúmoney view,‚Äù which treats money as having four distinct prices rather than being a simple unit of account.&lt;/p&gt;
    &lt;p&gt;Pozsar‚Äôs Bretton Woods III framework rests on a straightforward distinction. ‚ÄúInside money‚Äù refers to claims on institutions: Treasury securities, bank deposits, central bank reserves. ‚ÄúOutside money‚Äù refers to commodities like gold, oil, wheat, metals that have intrinsic value independent of any institution‚Äôs promise.&lt;/p&gt;
    &lt;p&gt;Bretton Woods I (1944-1971) was backed by gold, outside money. The U.S. dollar was convertible to gold at a fixed rate, and other currencies were pegged to the dollar. When this system collapsed in 1971, Bretton Woods II emerged: a system where dollars were backed by U.S. Treasury securities, inside money. Countries accumulated dollar reserves, primarily in the form of Treasuries, to support their currencies and facilitate international trade.&lt;/p&gt;
    &lt;p&gt;Pozsar‚Äôs argument: the moment Western nations froze Russian foreign exchange reserves, the assumed risk-free nature of these dollar holdings changed fundamentally. What had been viewed as having negligible credit risk suddenly carried confiscation risk. For any country potentially facing future sanctions, the calculus of holding large dollar reserve positions shifted. Hence Bretton Woods III: a system where countries increasingly prefer holding reserves in the form of commodities and gold, outside money that cannot be frozen by another government‚Äôs decision.&lt;/p&gt;
    &lt;p&gt;To understand Pozsar‚Äôs analysis, we need to understand his analytical framework. Perry Mehrling teaches that money has four prices: (1) Par: The one-for-one exchangeability of different types of money. Your bank deposit should convert to cash at par. Money market fund shares should trade at $1. When par breaks, as it did in 2008 when money market funds ‚Äúbroke the buck,‚Äù the payments system itself is threatened. (2) Interest: The price of future money versus money today. This is the domain of overnight rates, term funding rates, and the various ‚Äúbases‚Äù (spreads) between different funding markets. When covered interest parity breaks down and cross-currency basis swaps widen, it signals stress in the ability to transform one currency into another over time. (3) Exchange rate: The price of foreign money. How many yen or euros does a dollar buy? Fixed exchange rate regimes can collapse when countries lack sufficient reserves, as happened across Southeast Asia in 1997. (4) Price level: The price of commodities in terms of money. How much does oil, wheat, or copper cost? This determines not just headline inflation but feeds through into the price of virtually everything in the economy.&lt;/p&gt;
    &lt;p&gt;Central banks have powerful tools for managing the first three prices. They can provide liquidity to preserve par, influence interest rates through policy, and intervene in foreign exchange markets. But the fourth price, the price level, particularly when driven by commodity supply shocks, is far harder to control. As Pozsar puts it: ‚ÄúYou can print money, but not oil to heat or wheat to eat.‚Äù&lt;/p&gt;
    &lt;p&gt;Pozsar‚Äôs contribution was to extend Mehrling‚Äôs framework into what he calls the ‚Äúreal domain,‚Äù the physical infrastructure underlying commodity flows. For each of the three non-commodity prices of money, there‚Äôs a parallel in commodity markets: (1) Foreign exchange ‚Üî Foreign cargo: Just as you exchange currencies, you exchange dollars for foreign-sourced commodities. (2) Interest (time value of money) ‚Üî Shipping: Just as lending has a time dimension, moving commodities from port A to port B takes time and requires financing. (3) Par (stability) ‚Üî Protection: Just as central banks protect the convertibility of different money forms, military and diplomatic power protects commodity shipping routes.&lt;/p&gt;
    &lt;p&gt;This mapping reveals something important: commodity markets have their own ‚Äúplumbing‚Äù that works parallel to financial plumbing. And when this real infrastructure gets disrupted, it creates stresses that purely monetary policy cannot resolve.&lt;/p&gt;
    &lt;p&gt;One of the most concrete examples in Pozsar‚Äôs March 2022 dispatches illustrates this intersection between finance and physical reality. Consider what happens when Russian oil exports to Europe are disrupted and must be rerouted to Asia. Previously, Russian oil traveled roughly 1-2 weeks from Baltic ports to European refineries on Aframax carriers (ships carrying about 600,000 barrels). The financing required was relatively short-term, a week or two. Post-sanctions, the same oil must travel to Asian buyers. But the Baltic ports can‚Äôt accommodate Very Large Crude Carriers (VLCCs), which carry 2 million barrels. So the oil must first be loaded onto Aframax vessels, sailed to a transfer point, transferred ship-to-ship to VLCCs, then shipped to Asia, a journey of roughly four months.&lt;/p&gt;
    &lt;p&gt;The same volume of oil, moved the same distance globally, now requires: (a) More ships (Aframax vessels for initial transport plus VLCCs for long-haul). (b) More time (4 months instead of 1-2 weeks). (c) More financing (commodity traders must borrow for much longer terms). (d) More capital tied up by banks (longer-duration loans against volatile commodities).&lt;/p&gt;
    &lt;p&gt;Pozsar estimated this rerouting alone would encumber approximately 80 VLCCs, roughly 10% of global VLCC capacity, in permanent use. The financial implication: banks‚Äô liquidity coverage ratios (LCRs) increase because they‚Äôre extending more term credit to finance these longer shipping durations. When commodity trading requires more financing for longer durations, it competes with other demands for bank balance sheet. If this happens simultaneously with quantitative tightening (QT), when the central bank is draining reserves from the system, funding stresses become more likely. As Pozsar noted: ‚ÄúIn 2019, o/n repo rates popped because banks got to LCR and they stopped lending reserves. In 2022, term credit to commodity traders may dry up because QT will soon begin in an environment where banks‚Äô LCR needs are going up, not down.‚Äù&lt;/p&gt;
    &lt;p&gt;One aspect of the framework that deserves more attention relates to dollar funding for non-U.S. banks. According to recent Dallas Fed research, banks headquartered outside the United States hold approximately $16 trillion in U.S. dollar assets, comparable in magnitude to the $22 trillion held by U.S.-based institutions. The critical difference: U.S. banks have access to the Federal Reserve‚Äôs emergency liquidity facilities during periods of stress. Foreign banks do not have a U.S. dollar lender of last resort. During the COVID-19 crisis, the Fed expanded dollar swap lines to foreign central banks precisely to address this vulnerability, about $450 billion, roughly one-sixth of the Fed‚Äôs balance sheet expansion in early 2020. The structural dependency on dollar funding creates ongoing vulnerabilities. When dollars become scarce globally, whether due to Fed policy tightening, shifts in risk sentiment, or disruptions in commodity financing, foreign banks face balance sheet pressures that can amplify stress. The covered interest parity violations that Pozsar frequently discusses reflect these frictions: direct dollar borrowing and synthetic dollar borrowing through FX swaps theoretically should cost the same, but in practice, significant basis spreads persist.&lt;/p&gt;
    &lt;p&gt;Continue reading Pozsar‚Äôs Bretton Woods III: Three Years Later [2/2]&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://philippdubach.com/2025/10/25/pozsars-bretton-woods-iii-the-framework-1/2/"/><published>2025-11-19T19:39:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45984143</id><title>The Death of Arduino?</title><updated>2025-11-19T23:10:09.429548+00:00</updated><content>&lt;doc fingerprint="34c1a75a173c319e"&gt;
  &lt;main&gt;
    &lt;p&gt;Qualcomm-owned Arduino quietly pushed a sweeping rewrite of its Terms of Service and Privacy Policy, and the changes mark a clear break from the open-hardware ethos that built the platform. The new documents introduce an irrevocable, perpetual license over anything users upload, broad surveillance-style monitoring of AI features, a clause preventing users from identifying potential patent infringement, years-long retention of usernames even after account deletion, and the integration of all user data (including minors) into Qualcomm‚Äôs global data ecosystem. Military weird things and more. Several sections effectively reshape Arduino from an open community platform into a tightly controlled corporate service with deep data extraction built in. The most striking addition: users are now explicitly forbidden from reverse-engineering or even attempting to understand how the platform works unless Arduino gives permission. That‚Äôs a profound shift for a brand long embraced by educators, makers, researchers, and open-source advocates. With the cloud having a rough day and many systems offline, yesterday... Anyone invested in transparency, community governance, or data rights should read these documents closely. Links: https://lnkd.in/efKSip3e https://lnkd.in/eKDWCZT4 Somewhere an old Uno is whispering ‚Äúthis is not my beautiful life"... Forbes did a couple press-release style "features" with incorrect information that Qualcomm or Arduino supplied, obviously Qualcomm has severe issues with fraud, acquisitions, et. this was 3 DAYS AGO - Former Qualcomm executive sentenced to prison for $180M fraud scheme. @Bill Curtis &amp;amp; Steve McDowell please consider a revisit... Nakul Duggal seems to be the one that will end up taking the fall for this, the CEO of Qualcomm is not in the press release for the sale (and the press release seems like it was made by ChatGPT when you put it through those AI detectors?).. ANY WAY - Naukul and the Ardunio better get a ride in the over 10 Gulfstreams, which are a puzzle to investors, why so many? And why get a G800 now that's over $75m ...? That's how much Arduino has in funding... US's Qualcomm adds G800 to corporate jet fleet... https://lnkd.in/ddiCikpf LIKE, SHARE, AND SUBSCRIBE FOR MORE DIY ELECTRONICS AND OPEN SOURCE NEWS @ Adafruit Industries Qualcomm Arduino Cristiano R. Amon Massimo Banzi Fabio Violante Pietro D. Marcello Majonchi Federico Musto (ÈæçÁçµ‰∫∫) &amp;lt;-- #opensource #privacy #techpolicy #hardware #iot #surveillance #qualcomm #arduino #makers #infosec #datarights #termsandconditions #cloudcomputing&lt;/p&gt;
    &lt;p&gt;This is going to be a huge blow to academic robotics research&lt;/p&gt;
    &lt;p&gt;It was great knowing you Arduino, RIP. Hello, RP2040 and ESP32, hope we have a great future ahead!&lt;/p&gt;
    &lt;p&gt;"I'm shocked," said nobody. And so the pancake flips, the pendulum oscillates, and hub-and-spoke businesses will change to matrix management, and vice versa. With adversity, and lemons, comes the opportunity to make some tasty lemonade. Gaps will be filled, and I can think of no stronger and more agile (domestic!) player than Adafruit to fill them. Stir that pot, LadyAda, we are (all) counting on you.&lt;/p&gt;
    &lt;p&gt;Sounds like an opportunity just opened for a new open source company.&lt;/p&gt;
    &lt;p&gt;This project is on its last legs. Any real alternative?&lt;/p&gt;
    &lt;p&gt;Congratulations Qualcomm that was a really stupid move. The Arduino-sphere has too much independant inertia for some corporate raider to change the free and open environment. The quickest way for a company to make themselves irreverent and to drive business away is to go proprietary. Arduino was an open source project (software and hardware). If you don't like Qualcomm's limits, screw them. Take you solution open source again. Write your own. Make you own OS/platform/uploader. There must be hundreds (or thousands) of work-a-like clone-ish boards and firmwares. They can't stop you from doing your own open projects using non-Qualcomm platforms/solutions.&lt;/p&gt;
    &lt;p&gt;Do the leadership teams at Arduino and Qualcomm perhaps need to read this book? https://www.amazon.com/Enshittification-Everything-Suddenly-Worse-About/dp/0374619328/&lt;/p&gt;
    &lt;p&gt;QCOMM does not understand anything about the Maker space. They are a greedy corporation that doesn't give a crap about the community that Arduino has built over the past 10+ years. VSC coupled with PlatformIO and other hardware platforms will most likely become the De-facto standard for the Maker space.&lt;/p&gt;
    &lt;p&gt;Remember what they tried to do to Ardupilot..&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.linkedin.com/posts/adafruit_opensource-privacy-techpolicy-activity-7396903362237054976-r14H"/><published>2025-11-19T19:44:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45984333</id><title>The Subversive Hyperlink</title><updated>2025-11-19T23:10:09.364227+00:00</updated><content>&lt;doc fingerprint="e7a6d59a30fdc8c3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Subversive Hyperlink&lt;/head&gt;
    &lt;p&gt;The web has a superpower: permission-less link sharing.&lt;/p&gt;
    &lt;p&gt;I send you a link and as long as you have an agent, i.e. a browser (or a mere HTTP client), you can access the content at that link.&lt;/p&gt;
    &lt;p&gt;This ability to create and disseminate links is almost radical against the backdrop of today‚Äôs platforms.&lt;/p&gt;
    &lt;p&gt;To some, the hyperlink is dangerous and must be controlled:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They want to control what you can link to (see: app stores &amp;amp; external purchase links).&lt;/item&gt;
      &lt;item&gt;They want to control how many links you can make (see: the link-in-bio phenomenon).&lt;/item&gt;
      &lt;item&gt;They want to monetize your links (see: search engines) and give you no credit (see: AI).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And yet, we keep on linking:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To whatever we want (üëã Apple)&lt;/item&gt;
      &lt;item&gt;However many times we want (üëã Meta)&lt;/item&gt;
      &lt;item&gt;And with no expectation of return (üëã Google/Open AI)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why? Because it‚Äôs a web. Interconnectedness is the whole point.&lt;/p&gt;
    &lt;p&gt;Links form the whole. Without links, there is no whole. No links means no web, only silos. Isolation. The absence of connection.&lt;/p&gt;
    &lt;p&gt;Subvert the status quo. Own a website. Make and share links.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.jim-nielsen.com/2024/the-subversive-hyperlink/"/><published>2025-11-19T19:59:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45984353</id><title>Cognitive and mental health correlates of short-form video use</title><updated>2025-11-19T23:10:08.755590+00:00</updated><content>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://psycnet.apa.org/fulltext/2026-89350-001.html"/><published>2025-11-19T20:01:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45984623</id><title>Racing karts on a Rust GPU kernel driver</title><updated>2025-11-19T23:10:08.139681+00:00</updated><content>&lt;doc fingerprint="a7d9bad17987858e"&gt;
  &lt;main&gt;
    &lt;p&gt;Daniel Almeida &lt;lb/&gt;November 19, 2025&lt;/p&gt;
    &lt;p&gt;Reading time:&lt;/p&gt;
    &lt;p&gt;A few months ago, we introduced Tyr, a Rust driver for Arm Mali GPUs that continues to see active development upstream and downstream. As the upstream code awaits broader ecosystem readiness, we have focused on a downstream prototype that will serve as a baseline for community benchmarking and help guide our upstreaming efforts.&lt;/p&gt;
    &lt;p&gt;Today, we are excited to share that the Tyr prototype has progressed from basic GPU job execution to running GNOME, Weston, and full-screen 3D games like SuperTuxKart, demonstrating a functional, high-performance Rust driver that matches C-driver performance and paves the way for eventual upstream integration!&lt;/p&gt;
    &lt;p&gt;I previously discussed the relationship between user-mode drivers (UMDs) and kernel-mode drivers (KMDs) in one of my posts about how GPUs work. Here's a quick recap to help get you up to speed:&lt;/p&gt;
    &lt;quote&gt;One thing to be understood from the previous section is that the majority of the complexity tends to reside at the UMD level. This component is in charge of translating the higher-level API commands into lower-level commands that the GPU can understand. Nevertheless the KMD is responsible for providing key operations such that its user-mode driver is actually implementable, and it must do so in a way that fairly shares the underlying GPU hardware among multiple tasks in the system.&lt;/quote&gt;
    &lt;p&gt;While the UMD will take care of translating from APIs like Vulkan or OpenGL into GPU-specific commands, the KMD must bring the GPU hardware to a state where it can accept requests before it can share the device fairly among the UMDs in the system. This covers power management, parsing and loading the firmware, as well as giving the UMD a way to allocate GPU memory while ensuring isolation between different GPU contexts for security.&lt;/p&gt;
    &lt;p&gt;This was our initial focus for quite a few months while working on Tyr, and testing was mainly done through the IGT framework. These tests would mainly consist of performing simple &lt;code&gt;ioctls()&lt;/code&gt; against the driver and subsequently checking whether the results made sense.&lt;/p&gt;
    &lt;p&gt;By the way, those willing to further understand the relationship between UMDs and KMDs on Linux should watch a talk given at Kernel Recipes by my colleague Boris Brezillon on the topic!&lt;/p&gt;
    &lt;p&gt;Once the GPU is ready to accept requests and userspace can allocate GPU memory as needed, the UMD can place all the resources required by a given workload in GPU buffers. These can be further referenced by the command buffers containing the instructions to be executed, as we explain in the excerpt below:&lt;/p&gt;
    &lt;quote&gt;With the data describing the model and the machine code describing the shaders, the UMD must ask the KMD to place this in GPU memory prior to execution. It must also tell the GPU that it wants to carry out a draw call and set any state needed to make this happen, which it does by means of building VkCommandBuffers, which are structures containing instructions to be carried out by the GPU in order to make the workload happen. It also needs to set up a way to be notified when the workload is done and then allocate the memory to place the results in.&lt;/quote&gt;
    &lt;p&gt;In this sense, the KMD is the last link between the UMD and the GPU hardware, providing the necessary APIs for job submission and synchronization. It ensures that all the drawing operations built at the userspace level can actually reach the GPU for execution. It is the KMD's responsibility to ensure that jobs only get scheduled once its dependencies have finished executing. It also has to notify (in other words, signal to) the UMD when jobs are done, or the UMD won't really know when the results are valid.&lt;/p&gt;
    &lt;p&gt;Additionally, before Tyr can execute a complex workload consisting of a vast amount of simultaneous jobs, it must be able to execute a simple one correctly, or debugging will be an unfruitful nightmare. For this matter, we devised the simplest job we could think of: one that merely places a single integer in a given memory location using a MOV instruction on the GPU. Our IGT test then blocks until the KMD signals that the work was carried out.&lt;/p&gt;
    &lt;p&gt;Reading that memory location and ensuring that its contents match the constant we were expecting shows that the test was executed successfully. In other words, it shows that we were able to place the instructions in one of the GPU's ring buffers and have the hardware iterator pick it up and execute correctly, paving the way for more complex tests that can actually try to draw something.&lt;/p&gt;
    &lt;p&gt;The test source code for this dummy job is here.&lt;/p&gt;
    &lt;p&gt;With job submission and signalling working, it was time to attempt to render a scene. We chose &lt;code&gt;kmscube&lt;/code&gt;, which draws a single rotating cube on the screen, as the next milestone.&lt;/p&gt;
    &lt;p&gt;It was a good candidate owing to its simple geometry and the fact that it is completely self-contained. In other words, no compositor is needed and rendering takes place in a buffer that's directly handed to the display (KMS) driver.&lt;/p&gt;
    &lt;p&gt;Getting &lt;code&gt;kmscube&lt;/code&gt; to run would also prove that we were really enforcing the job dependencies that were set by the UMD or we would get visual glitches. To do so, we relied on a slightly updated version of the Rust abstractions for the DRM scheduler posted by Asahi Lina a few years ago. The result was a rotating cube that was rendered at the display's refresh rate.&lt;/p&gt;
    &lt;p&gt;Using offscreen rendering lets us go even faster, jumping from 30 or 60fps to more than 500 frames per second, matching the performance of the C driver. That's a lot of frames being drawn!&lt;/p&gt;
    &lt;p&gt;The natural progression would be to launch &lt;code&gt;Weston&lt;/code&gt; or &lt;code&gt;GNOME&lt;/code&gt;. As there is quite a lot going on when a DE like GNOME is running; we were almost expecting it not to work at first, so it came as a huge surprise when GNOME's login page was rendered.&lt;/p&gt;
    &lt;p&gt;In fact, you can log in to GNOME, open Firefox, and...watch a YouTube video:&lt;/p&gt;
    &lt;p&gt;Running &lt;code&gt;vkcube&lt;/code&gt; under &lt;code&gt;weston&lt;/code&gt; also just works!&lt;/p&gt;
    &lt;p&gt;The last 3D milestone is running a game or another 3D-intensive application. Not only would that put the GPU through a demanding workload, but it would also allow us to gauge the KMD's performance more accurately. Again, the game is rendered correctly and is completely playable, without any noticeable hiccups or other performance issues, so long as it is run on full screen. Unfortunately, windowed mode still has some glitches: it is a prototype, after all.&lt;/p&gt;
    &lt;p&gt;It's important to clarify what this means and how this plays into the long-term vision for the project.&lt;/p&gt;
    &lt;p&gt;In fact, it's easier to start by what we are not claiming with this post: Tyr is not ready to be used as a daily-driver, and it will still take time to replicate this upstream, although it is now clear that we will surely get there. And as a mere prototype, it has a lot of shortcuts that we would not have in an upstream version, even though it can run on top of an unmodified (i.e., upstream) version of Mesa.&lt;/p&gt;
    &lt;p&gt;That said, this prototype can serve as an experimental driver and as a testbed for all the Rust abstraction work taking place upstream. It will let us experiment with different design decisions and gather data on what truly contributes to the project's objective. It is a testament that Rust GPU KMDs can work, and not only that, but they can perform on par with their C counterparts.&lt;/p&gt;
    &lt;p&gt;Needless to say, we cannot make any assumptions about stability on an experimental driver, it might very well lock up and lose your work after some time, so be aware.&lt;/p&gt;
    &lt;p&gt;Finally, this was tested on a Rock 5B board, which is fitted with a Rockchip RK3588 system-on-chip and it will probably not work for any other device at the moment. Those with this hardware at hand should feel free to test our branch and provide feedback. The source code can be found here. Make sure to enable &lt;code&gt;CONFIG_TYR_DRM_DEPS&lt;/code&gt; and &lt;code&gt;CONFIG_DRM_TYR&lt;/code&gt;. Feel free to contribute to Tyr by checking out our issue board!&lt;/p&gt;
    &lt;p&gt;Below is a video showcasing the Tyr prototype in action. Enjoy!&lt;/p&gt;
    &lt;p&gt;19/11/2025&lt;/p&gt;
    &lt;p&gt;The Tyr prototype has now progressed from basic GPU job execution to running GNOME, Weston, and full-screen 3D games like SuperTuxKart,‚Ä¶&lt;/p&gt;
    &lt;p&gt;05/11/2025&lt;/p&gt;
    &lt;p&gt;As a trusted partner of industry leaders like CLAAS, Ag Leader, and CCI, we are delighted to exhibit for the first time at one of the world‚Äôs‚Ä¶&lt;/p&gt;
    &lt;p&gt;16/10/2025&lt;/p&gt;
    &lt;p&gt;Collabora and MediaTek are advancing upstream Linux support for the latest Genio IoT boards and Chromebook Plus laptops, enabling full hardware‚Ä¶&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.collabora.com/news-and-blog/news-and-events/racing-karts-on-a-rust-gpu-kernel-driver.html"/><published>2025-11-19T20:23:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45984659</id><title>Loose wire leads to blackout, contact with Francis Scott Key bridge</title><updated>2025-11-19T23:10:07.996114+00:00</updated><content>&lt;doc fingerprint="ee0fa5758446d526"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Blackouts led to loss of steering and propulsion on 984-foot-long vessel&lt;/p&gt;
      &lt;p&gt;WASHINGTON (Nov. 18, 2025) -- The NTSB said Tuesday that a single loose wire on the 984-foot-long containership Dali caused an electrical blackout that led to the giant vessel veering and contacting the nearby Francis Scott Key Bridge in Baltimore, which then collapsed, killing six highway workers. &lt;/p&gt;
      &lt;p&gt;At Tuesday‚Äôs public meeting at NTSB headquarters, investigators said the loose wire in the ship‚Äôs electrical system caused a breaker to unexpectedly open -- beginning a sequence of events that led to two vessel blackouts and a loss of both propulsion and steering near the 2.37-mile-long Key Bridge on March 26, 2024. Investigators found that wire-label banding prevented the wire from being fully inserted into a terminal block spring-clamp gate, causing an inadequate connection. &lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;Illustration showing how placement of wire-label banding affects the way wires are seated in their terminal blocks. (Source: NTSB) &lt;/p&gt;
      &lt;p&gt;After the initial blackout, the Dali‚Äôs heading began swinging to starboard toward Pier 17 of the Key Bridge. Investigators found that the pilots and the bridge team attempted to change the vessel‚Äôs trajectory, but the loss of propulsion so close to the bridge rendered their actions ineffective. A substantial portion of the bridge subsequently collapsed into the river, and portions of the pier, deck and truss spans collapsed onto the vessel‚Äôs bow and forwardmost container bays. &lt;/p&gt;
      &lt;p&gt;A seven-person road maintenance crew and one inspector were on the bridge when the vessel struck. Six of the highway workers died. The NTSB found that the quick actions of the Dali pilots, shoreside dispatchers and the Maryland Transportation Authority to stop bridge traffic prevented greater loss of life. &lt;/p&gt;
      &lt;p&gt;‚ÄùOur investigators routinely accomplish the impossible, and this investigation is no different,‚Äô said NTSB Chairwoman Jennifer Homendy. ‚ÄúThe Dali, at almost 1,000 feet, is as long as the Eiffel Tower is high, with miles of wiring and thousands of electrical connections. Finding this single wire was like hunting for a loose rivet on the Eiffel Tower. &lt;/p&gt;
      &lt;p&gt;‚ÄúBut like all of the accidents we investigate,this was preventable,‚Äù Homendy said. ‚ÄúImplementing NTSB recommendations in this investigation will prevent similar tragedies in the future.‚Äù &lt;/p&gt;
      &lt;p&gt;Contributing to the collapse of the Key Bridge and the loss of life was the lack of countermeasures to reduce the bridge‚Äôs vulnerability to collapse due to impact by ocean-going vessels, which have only grown larger since the Key Bridge‚Äôs opening in 1977. When the Japan-flagged containership Blue Nagoya contacted the Key Bridge after losing propulsion in 1980, the 390-foot-long vessel caused only minor damage. The Dali, however, is 10 times the size of the Blue Nagoya. &lt;/p&gt;
      &lt;p&gt;The comparative sizes of the Blue Nagoya and the Dali relative to the Key Bridge. (Source: NTSB) &lt;/p&gt;
      &lt;p&gt;As part of the investigation, the NTSB in March released an initial report on the vulnerability of bridges nationwide to large vessel strikes. The report found that the Maryland Transportation Authority‚Äîand many other owners of bridges spanning navigable waterways used by ocean-going vessels‚Äîwere likely unaware of the potential risk that a vessel collision could pose to their structures. This was despite longstanding guidance from the American Association of State Highway and Transportation Officials recommending that bridge owners perform these assessments. &lt;/p&gt;
      &lt;p&gt;The NTSB sent letters to 30 bridge owners identified in the report, urging them to evaluate their bridges and, if needed, develop plans to reduce risks. All recipients have since responded, and the status of each recommendation is available on the NTSB‚Äôs website. &lt;/p&gt;
      &lt;p&gt; As a result of the investigation, the NTSB issued new safety recommendations to the US Coast Guard; US Federal Highway Administration; the American Association of State Highway and Transportation Officials; the Nippon Kaiji Kyokai (ClassNK); the American National Standards Institute; the American National Standards Institute Accredited Standards Committee on Safety in Construction and Demolitions Operations A10; HD Hyundai Heavy Industries; Synergy Marine Pte. Ltd; and WAGO Corporation, the electrical component manufacturer; and multiple bridge owners across the nation. &lt;/p&gt;
      &lt;p&gt;A synopsis of actions taken Tuesday, including the probable cause, findings and recommendations, can be found on ntsb.gov. The complete investigation report will be released in the coming weeks. &lt;/p&gt;
    &lt;/div&gt;
    &lt;p&gt;To report an incident/accident or if you are a public safety agency, please call 1-844-373-9922 or 202-314-6290 to speak to a Watch Officer at the NTSB Response Operations Center (ROC) in Washington, DC (24/7).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ntsb.gov:443/news/press-releases/Pages/NR20251118.aspx"/><published>2025-11-19T20:26:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45985036</id><title>Researchers discover security vulnerability in WhatsApp</title><updated>2025-11-19T23:10:07.187829+00:00</updated><content>&lt;doc fingerprint="ff0d111b292581c1"&gt;
  &lt;main&gt;
    &lt;p&gt;IT-Security Researchers from the University of Vienna and SBA Research identified and responsibly disclosed a large-scale privacy weakness in WhatsApp's contact discovery mechanism that allowed the enumeration of 3.5 billion accounts. In collaboration with the researchers, Meta has since addressed and mitigated the issue. The study underscores the importance of continuous, independent security research on widely used communication platforms and highlights the risks associated with the centralization of instant messaging services. The preprint of the study has now been published, and the results will be presented in 2026 at the Network and Distributed System Security (NDSS) Symposium.&lt;/p&gt;
    &lt;p&gt;WhatsApp's contact discovery mechanism can use a user's address book to find other WhatsApp users by their phone number. Using the same underlying mechanism, the researchers demonstrated that it was possible to query more than 100 million phone numbers per hour through WhatsApp's infrastructure, confirming more than 3.5 billion active accounts across 245 countries. "Normally, a system shouldn't respond to such a high number of requests in such a short time ‚Äî particularly when originating from a single source," explains lead author Gabriel Gegenhuber from the University of Vienna. "This behavior exposed the underlying flaw, which allowed us to issue an effectively unlimited requests to the server and, in doing so, map user data worldwide."&lt;/p&gt;
    &lt;p&gt;The accessible data items used in the study are the same that are public for anyone who knows a user's phone number and consist of: phone number, public keys, timestamps, and, if set to public, about text and profile picture. From these data points, the researchers were able to extract additional information, which allowed them to infer a user's operating system, account age, as well as the number of linked companion devices. The study shows that even this limited amount of data per user can reveal important information, both on macroscopic and individual levels.&lt;/p&gt;
    &lt;head rend="h2"&gt;The study also revealed a range of broader insights:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Millions of active WhatsApp accounts were identified in countries where the platform was officially banned, including China, Iran, and Myanmar.&lt;/item&gt;
      &lt;item&gt;Population-level insights into platform usage, such as the global distribution of Android (81%) versus iOS (19%) devices, regional differences in privacy behavior (e.g., use of public profile pictures or "about" tagline), and variations in user growth across countries.&lt;/item&gt;
      &lt;item&gt;A small number of cases showed re-use of cryptographic keys across different devices or phone numbers, pointing to potential weaknesses in non-official WhatsApp clients or fraudulent use.&lt;/item&gt;
      &lt;item&gt;Nearly half of all phone numbers that appeared in the 2021 Facebook data leak of 500 million phone numbers (caused by a scraping incident in 2018) were still active on WhatsApp. This highlights the enduring risks for leaked numbers (e.g., being targeted in scam calls) associated with such exposures.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The study did not involve access to message content, and no personal data was published or shared. All retrieved data was deleted by the researchers prior to publication. Message content on WhatsApp is ‚Äúend-to-end encrypted‚Äù and was not affected at any time. ‚ÄúThis end-to-end encryption protects the content of messages, but not necessarily the associated metadata,‚Äù explains last author Aljosha Judmayer from the University of Vienna. ‚ÄúOur work shows that privacy risks can also arise when such metadata is collected and analysed on a large scale.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúThese findings remind us that even mature, widely trusted systems can contain design or implementation flaws that have real-world consequences," says lead author Gabriel Gegenhuber from the University of Vienna: "They show that security and privacy are not one-time achievements, but must be continuously re-evaluated as technology evolves."&lt;/p&gt;
    &lt;p&gt;"Building on our previous findings on delivery receipts and key management, we are contributing to a long-term understanding of how messaging systems evolve and where new risks arise," adds co-author Maximilian G√ºnther from the University of Vienna.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe are grateful to the University of Vienna researchers for their responsible partnership and diligence under our Bug Bounty program. This collaboration successfully identified a novel enumeration technique that surpassed our intended limits, allowing the researchers to scrape basic publicly available information. We had already been working on industry-leading anti-scraping systems, and this study was instrumental in stress-testing and confirming the immediate efficacy of these new defenses. Importantly, the researchers have securely deleted the data collected as part of the study, and we have found no evidence of malicious actors abusing this vector. As a reminder, user messages remained private and secure thanks to WhatsApp‚Äôs default end-to-end encryption, and no non-public data was accessible to the researchers‚Äù, says Nitin Gupta, Vice President of Engineering at WhatsApp.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ethical Handling and Disclosure&lt;/head&gt;
    &lt;p&gt;The research was conducted with strict ethical guidelines and in accordance with responsible disclosure principles. The findings were promptly reported to Meta, the operator of WhatsApp, which has since implemented countermeasures (e.g., rate-limiting, stricter profile information visibility) to close the identified vulnerability. The authors argue that transparency, academic scrutiny, and independent testing are essential to maintaining trust in global communication services. They emphasize that proactive collaboration between researchers and industry can significantly improve user privacy and prevent abuse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Research Context&lt;/head&gt;
    &lt;p&gt;This publication represents the third study by researchers from the University of Vienna and SBA Research examining the security and privacy of prevalent instant messengers such as WhatsApp and Signal. The team investigates how design and implementation choices in end-to-end encrypted messaging services can unintentionally expose user information or weaken privacy guarantees.&lt;/p&gt;
    &lt;p&gt;Earlier this year, the researchers published "Careless Whisper: Exploiting Silent Delivery Receipts to Monitor Users on Mobile Instant Messengers" (distinguished with the Best Paper Award at RAID 2025), which demonstrated how silent pings and their delivery receipts could be abused to infer user activity patterns and online behavior on WhatsApp and similar messaging platforms. Later that same year, "Prekey Pogo: Investigating Security and Privacy Issues in WhatsApp's Handshake Mechanism" (presented at USENIX WOOT 2025) analyzed the cryptographic foundations of WhatsApp's prekey distribution mechanism, revealing implementation weaknesses of the Signal-based protocol.&lt;/p&gt;
    &lt;p&gt;"By building on our earlier findings about delivery receipts and key management, we're contributing to a long-term understanding of how messaging systems evolve, and where new risks emerge." said Maximilian G√ºnther (University of Vienna).&lt;/p&gt;
    &lt;p&gt;The current study, "Hey there! You are using WhatsApp: Enumerating Three Billion Accounts for Security and Privacy", extends this line of research to the global scope, showing how contact discovery mechanisms can unintentionally allow large-scale user enumeration at an unprecedented magnitude. It will appear in the proceedings of the NDSS Symposium 2026, one of the leading international conferences on computer and network security.&lt;/p&gt;
    &lt;p&gt;Publication: Gabriel K. Gegenhuber, Philipp √â. Frenzel, Maximilian G√ºnther, Johanna Ullrich und Aljosha Judmayer: Hey there! You are using WhatsApp: Enumerating Three Billion Accounts for Security and Privacy. In: Network and Distributed System Security Symposium (NDSS), 2026. Preprint available here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.univie.ac.at/en/news/detail/forscherinnen-entdecken-grosse-sicherheitsluecke-in-whatsapp"/><published>2025-11-19T20:55:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45985196</id><title>How Slide Rules Work</title><updated>2025-11-19T23:10:06.910057+00:00</updated><content>&lt;doc fingerprint="f199d34c2ecd3f9c"&gt;
  &lt;main&gt;
    &lt;p&gt;[TOC]&lt;/p&gt;
    &lt;p&gt;The survival of our species owes much to our brain, specifically, its ability to observe, analyse, and plan. Planting crops and storing grains for the winter were some of the earliest uses of these abilities. Measuring and calculating are foundational elements of observation, analysis, and planning. Computation, upon which our modern society depends, is but an extension of those ancient measurement and calculation techniques.&lt;/p&gt;
    &lt;p&gt;Calculations operate on operands obtained through measurements. Counting was the oldest form of measurement. In prehistory, humans counted by scratching marks on bones. Next to evolve was a ruler etched with markings. Thereafter, humans were marking, measuring, calculating, tracking, and predicting the movements of the Sun and the Moon using stone pillars, astronomically aligned burial mounds, and sun dials.&lt;/p&gt;
    &lt;p&gt;By around 3000 BC, Sumerians invented the sexagesimal (base-$60$) number system, and they were using the abacus by 2700 BC. The abacus was one of the earliest devices that mechanised calculations, and it is still in extensive use, throughout the world. A cuneiform clay tablet from 1800 BC shows that Babylonians already knew how to survey land boundaries with the aid of Pythagorean triples. Egyptians improved upon these techniques to survey property boundaries on the Nile flood planes and to erect the pyramids. By 220 BC, Persian astronomers were using the astrolabe to calculate the latitude, to measure the height of objects, and to triangulate positions. Greeks constructed truly advanced mechanical instruments that predicted solar and lunar eclipses. The sophistication and refinement exhibited by the Antikythera mechanism from around 200 BC continues to amaze modern engineers.&lt;/p&gt;
    &lt;p&gt;Ancient astronomy measured, tracked, and predicted the movements of heavenly objects. But when celestial navigation came to be used extensively in global trade across the oceans, we began charting the night sky in earnest, and thus was born modern astronomy. Astronomical calculations involved manually manipulating numbers. Those calculations were tedious and error prone.&lt;/p&gt;
    &lt;p&gt;In 1614, a brilliant Scottish mathematician John Napier discovered logarithms. Perhaps it would be more appropriate to say Napier invented logarithms, for his discovery was motivated by his desire to simplify multiplication and division. Arithmetically, multiplication can be expressed as repeated additions, and division as repeated subtractions. Logarithmically, multiplication of two numbers can be reduced to addition of their logarithms, and division to subtraction thereof. Hence, multiplication and division of very large numbers can be reduced to straightforward addition and subtraction, with the aid of prepared logarithm and inverse logarithm tables.&lt;/p&gt;
    &lt;p&gt;In 1620, Edmund Gunter, an English astronomer, used Napier‚Äôs logarithms to fashion a calculating device that came to be known as Gunter‚Äôs scale. The markings on this device were not linear like a simple ruler, but logarithmic. To multiply two numbers, the length representing the multiplicand is first marked out on the logarithmic scale using a divider and, from thence, the length representing the multiplier is similarly marked out, thereby obtaining the product, which is the sum of the two logarithmic lengths. Gunter‚Äôs scale mechanised the tedious task of looking up numbers on logarithm tables. This device was the forerunner of the slide rule.&lt;/p&gt;
    &lt;p&gt;The first practical slide rule was invented by William Oughtred, an English mathematician, in 1622. Oughtred used two bits of wood graduated with Gunter‚Äôs scale to perform multiplication and addition. Then, in 1630, Oughtred fashioned a brass circular slide rule with two integrated pointers. This device was a significant improvement over Gunter‚Äôs scale, in terms of practicality and usability. The photograph below shows a brass circular slide rule that is a contemporaneous clone of Oughtred‚Äôs.&lt;/p&gt;
    &lt;p&gt;The earliest adopters of the slide rule were the 17th century astronomers, who used it to perform arithmetic and trigonometric operations, quickly. But it was the 19th century engineers, the spearheads of the Industrial Revolution, who propelled the slide rule technology forward. For nearly four centuries after its invention, the slide rule remained the preeminent calculating device. Buildings, bridges, machines, and even computer system components, were designed by slide rule. Apollo astronauts carried the Pickett N600-ES pocket slide rule, onboard, for navigation and propulsion calculations. The General Dynamics F-16, a modern, air-superiority fighter, was designed by slide rule. Well into the late 1970s, school children all over the world, including me, were taught to use the slide rule and the logarithm book, along with penmanship and grammar.&lt;/p&gt;
    &lt;p&gt;The largest and most enthusiastic group of slide rule users, naturally, were engineers. But slide rules were used in all areas of human endeavour that required calculation: business, construction, manufacturing, medicine, photography, and more. Obviously, bankers and accountants relied on the slide rule to perform sundry arithmetic gymnastics. Construction sites and factory floors, too, used specialised versions of slide rules for mixing concrete, computing volumes, etc. Surveyors used the stadia slide rule made specifically for them. Doctors use special, medical slide rules for calculating all manner of things: body mass index, pregnancy terms, medicine dosage, and the like. Photographers used photometric slide rules for calculating film development times. Army officers used artillery slide rules to compute firing solutions in the field. Pilots used aviation slide rules for navigation and fuel-burn calculations. The list was long. This humble device elevated the 18th century astronomy, powered the 19th century Industrial Revolution, and seeded the 20th century Technological Revolution. Indeed, the slide rule perfectly expressed the engineering design philosophy: capability through simplicity.&lt;/p&gt;
    &lt;p&gt;But then, in 1972, HP released its first programmable scientific calculator, the inimitable HP-35. The HP-35 rang loud the death knell of the slide rule. Although electronic pocket calculators were unaffordable in the early 1970s, they became ubiquitous within a decade thanks to Moore‚Äôs law and Dennard‚Äôs law, and quickly displaced the slide rule. By the early 1980s, only a few people in the world were using the slide rule. I was one.&lt;/p&gt;
    &lt;p&gt;It was around this time that I arrived at the university‚Äîin Burma. In those days, electronic pocket calculators were beyond the reach of most Burmese college students. To ensure fairness, my engineering college insisted that all students used the government-issued slide rule, which was readily accessible to everyone. Many classrooms in my college had large, wall-mounted demonstration slide rules to teach first-year students how properly to use the slide rule like an engineer‚Äîthat is, to eradicate the bad habits learned in high school. As engineering students, we carried the slide rule upon our person, daily.&lt;/p&gt;
    &lt;p&gt;I subsequently emigrated to the US. Arrival in the US ended my association with the slide rule because, by the 1980s, American engineers were already using HP RPN pocket calculators and MATLAB technical computing software on the IBM PC. I soon became an HP calculator devotee. As such, I never got to use the slide rule extensively in a professional setting. But I hung on to my student slide rules: the government-issued Aristo 0968 Studio, a straight rule, and the handed-down Faber-Castell 8/10, a circular rule. To this day, I remain partial to the intimate, tactile nature of the slide rule, especially the demands it places upon the user‚Äôs mind. Over the next four decades, I collected many slide rules, dribs and drabs. The models in my collection are the ones I admired as an engineering student in Burma, but were, then, beyond reach.&lt;/p&gt;
    &lt;p&gt;In its heyday, everyone used the slide rule in every facet of life. As children, we saw it being used everywhere, so we were acquainted with it, even if we did not know how to use it. We were taught to use the slide rule‚Äôs basic facilities in middle school. Our options were the abacus, the log books, or the slide rule. The choice was abundantly clear: we enthusiastically took up the slide rule‚Äîa rite of passage, as it were. Now, though, even the brightest engineering students in the world have never heard of a slide rule, let alone know how it works.&lt;/p&gt;
    &lt;p&gt;My main goal in writing this article is to preserve the knowledge about, and the memory of, this ingenious computing device: how it works and how it was used. The focus here is on the basic principles of operation and how the slide rule was used in engineering. This is a ‚Äúhow it works‚Äù explanation, and not a ‚Äúhow to use‚Äù manual. Those who are interested in the most efficient use of a slide rule may read the manuals listed in the resources section at the end of this article. Beyond history and reminiscence, I hope to highlight the wide-ranging utility of some of the most basic mathematical functions that are familiar to middle schoolers.&lt;/p&gt;
    &lt;p&gt;It is mighty difficult to discuss the slide rule without having the device in hand. For the presentations below, I chose the Keuffel &amp;amp; Esser (K&amp;amp;E) 4081-3 Log Log Duplex Decitrig, a well-made wood rule. It was one of the most popular engineering slide rules for decades, especially in the US. As such, many engineering professors published good introductory books for it, and these books are now available online in PDF format.&lt;/p&gt;
    &lt;p&gt;The term ‚Äúlog-log‚Äù refers to the $LL$ scale, which is used to compute exponentiation, as will be explained, later. The term ‚Äúduplex‚Äù refers to the fact that both sides of the frame are engraved with scales, a K&amp;amp;E invention. The label ‚ÄúDecitrig‚Äù was K&amp;amp;E‚Äôs trade name for its slide rules that used decimal degrees for trigonometric computations, instead of minutes and seconds. Engineers prefer using the more convenient decimal notation.&lt;/p&gt;
    &lt;p&gt;Another common model was the Post 1460 Versalog. Although less popular than the K&amp;amp;E 4081-3, the Post 1460 is cheaper and, in my opinion, is a better slide rule. It is made of bamboo, a more stable material than wood.&lt;/p&gt;
    &lt;p&gt;Go on eBay and buy a good, inexpensive slide rule, either the K&amp;amp;E 4081-3 or the Post 1460; you will need a slide rule to follow the discussions below. Alternatively, you could use a slide rule simulator. The feature of this simulator that is especially useful to novices is the cursor‚Äôs ability instantaneously to show the exact scale values under the hairline.&lt;/p&gt;
    &lt;p&gt;And I recommend that, after you have read this article, you study one or more of the books listed in the resources section at the end.&lt;/p&gt;
    &lt;p&gt;A slide rule comprises three components: the body, the slide, and the cursor, as shown below. The body, about 25 cm in length, consists of two pieces of wood, the upper and the lower frames, bound together with metal brackets at the ends. The slide is a thin strip of wood that glides left and right between the upper and the lower frames. The cursor consists of two small plates of glass held by metal brackets and these brackets are anchored to the upper and the lower lintels. The cursor straddles the body and glides across its length. Hence, the three components of a slide rule move independently of, and with respect to, one another.&lt;/p&gt;
    &lt;p&gt;A duplex slide rule, like the K&amp;amp;E 4081-3 shown below, both sides of the frame have scales, and so do both sides of the slide. These scales are set and read using the hairline inscribed on the cursor glass. The cursor cannot slip off the body, because it is blocked by the metal brackets at the ends of the body.&lt;/p&gt;
    &lt;p&gt;A simplex slide rule, like the Nestler 23 R shown below, the cursor can slip off the body. The body is a single piece of wood with a trough in the middle separating the upper and the lower frames. Only the frontside of the frame has scales, but the slide has scales on both sides.&lt;/p&gt;
    &lt;p&gt;The slide rule is always operated using both hands, fingers of one hand pushing and those of the other gently opposing. The lower lintel of the cursor glides along the bottom of the lower frame. There is a tension spring between the upper lintel of the cursor and the top of the upper frame. This tension spring braces the lower lintel of the cursor flush against the bottom of the lower frame. To make fine adjustments of the cursor, one uses the thumbs of both hands against the lower lintel of the cursor. It is important to avoid touching the upper lintel, since it does not sit flush against the frame, due to the tension spring. When using the backside of a duplex straight rule, the lower lintel of the cursor has now flipped to the topside, so it had to be fine adjusted using the forefingers. Fine adjustments of the slide are made with the thumb or the forefinger of one hand opposing its counterpart of the other hand. To use the backside scales on a duplex straight rule, the device is flipped bottom-to-top.&lt;/p&gt;
    &lt;p&gt;Simplex slide rules have use instructions and a few scientific constants on the back, but duplex slide rules come with plastic inserts that bear such information. But no engineer I knew actually used this on-device information. Procedures for operating an engineering slide rule are complex; we had to study the user‚Äôs manual thoroughly and receive hands-on instructions for several weeks before we became proficient enough to be left alone with a slide rule without causing mayhem in the laboratory. And every branch of engineering has its own set of published handbooks in which many formulae and constants can readily be found.&lt;/p&gt;
    &lt;p&gt;properties of logarithms‚ÄîThe base-$10$ common logarithm function $log(x)$ and its inverse, the power-of-10 function $10^x$, give life to the slide rule. The two main properties of logarithms upon which the slide rule relies are these:&lt;/p&gt;
    &lt;p&gt;That is, to compute $a √ó b$, we first compute the sum of $log(a)$ and $log(b)$, then compute the $log^{-1}$ of the sum. Likewise, $a √∑ b$ is computed as the $log^{-1}$ of the difference between $log(a)$ and $log(b)$.&lt;/p&gt;
    &lt;p&gt;logarithmic scale‚ÄîThe slide rule mechanises these calculations by using two identical logarithmic scales, commonly labelled $C$ (on the slide) and $D$ (on the frame). Gunter‚Äôs logarithmic scale is derived from a ruler-like linear scale in the following manner. We begin with a 25-cm-long blank strip of wood and mark it up with $10$ equally spaced segments labelled $0, 1, 2, 3, ‚Ä¶, 10$, similar to an ordinary ruler, but labelling the ending $10$ as $1$, instead. This first piece of wood has now become the source linear scale. We then line up the second 25-cm long blank strip of wood with the first one, and mark up that second piece of wood with $9$ unequally spaced segments labelled $1, 2, 3, ‚Ä¶, 1$, starting with $1$ and, again, ending with $1$. The division marks of the second piece of wood is placed non-linearly in accordance with their $log$ values and by reference to the linear scale:&lt;/p&gt;
    &lt;p&gt;The second scale thus obtained is the non-linear, logarithmic scale. In the figure below, the upper one is the source linear scale and the lower one is the derived logarithmic scale.&lt;/p&gt;
    &lt;p&gt;On the slide rule, the source linear scale is labelled $L$, and it is called the ‚Äúlogarithm scale‚Äù. The derived logarithmic scale is labelled $D$.&lt;/p&gt;
    &lt;p&gt;I would like to direct your attention to this potentially confusing terminology. The term ‚Äúlogarithm scale‚Äù refers to the linear $L$ scale used for computing the common logarithm function $log(x)$. And the term ‚Äúlogarithmic scale‚Äù refers to the non-linear $C$ and $D$ scales used for computing the arithmetic operations $√ó$ and $√∑$. This knotty terminology is unavoidable, given the logarithmic nature of the slide rule.&lt;/p&gt;
    &lt;p&gt;The logarithmic scale and the logarithm scale are related by a bijective function $log$:&lt;/p&gt;
    &lt;p&gt;In the plot below, the black curve is $log$ and the red is $log^{-1}$.&lt;/p&gt;
    &lt;p&gt;The special name for $log^{-1}$ is power-of-$10$ function $10^x$. The $D$ and the $L$ scales form a transform pair that converts between the logarithmic scale and the arithmetic scale. It turns out that the $log$ function transforms the arithmetic scale‚Äôs $√ó$ and $√∑$ operators into the logarithmic scale‚Äôs $+$ and $-$ operators, and the $log^{-1}$ function performs the inverse transformation.&lt;/p&gt;
    &lt;p&gt;Plotting the $log$ function on a logarithmic scale produces a sequence of evenly spaced values. Hence, the $L$ scale appears linear, when laid out on the slide rule. Note also that the mere act of reading $x$ on the logarithmic scale implicitly computes $log(x)$; there is no need explicitly to compute $log^{-1}(x)$. Gunter‚Äôs logarithmic scale was the groundbreaking idea that made the slide rule work so effectively, efficiently, effortlessly.&lt;/p&gt;
    &lt;p&gt;The logarithmic scale has many other uses in STEM beyond the slide rule: the Richter scale used to measure seismic events; the $dB$ decibel scale used to measure sound pressure levels; the spectrogram used to visualise frequency domain signals are just a few examples. These uses exploit the logarithms‚Äô ability to compress a very large range, while preserving relevant details.&lt;/p&gt;
    &lt;p&gt;computations using logarithmic scales‚ÄîTo compute $2 √ó 3$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;The above multiplication procedure computes $2 √ó 3 = 6$, like this:&lt;/p&gt;
    &lt;p&gt;To put it another way, adding $2$ units of length and $3$ units of length yields $2 + 3 = 5$ units of length on the arithmetic scale of an ordinary rule. But on the logarithmic scale of the slide rule, adding $2$ units of length and $3$ units of length yields $2 √ó 3 = 6$ units of length.&lt;/p&gt;
    &lt;p&gt;To compute $2 √∑ 3$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Multiplication and division operations start and end with the cursor hairline on the $D$ scale. Skilled users frequently skipped the initial cursor setting when multiplying and the final cursor setting when dividing, opting instead to use the either end of the $C$ scale as the substitute hairline.&lt;/p&gt;
    &lt;p&gt;In slide rule parlance, accuracy refers to how consistently the device operates‚Äîthat is, how well it was manufactured and how finely it was calibrated. And precision means how many significant figures the user can reliably read off the scale.&lt;/p&gt;
    &lt;p&gt;Professional-grade slide rules are made exceedingly well, so they are very accurate. Yet, they all allow the user to calibrate the device. Even a well-made slide rule, like the K&amp;amp;E 4081-3 can go out of alignment if mistreated, say by exposing it to sun, solvent, or shock (mechanical or thermal). Misaligned slide rule can be recalibrated using the procedure described in the maintenance section, later in this article. And prolonged exposure to moisture and heat can deform a wood rule, like the K&amp;amp;E 4081-3, thereby damaging it, permanently. The accuracy of a warped wood rule can no longer be restored by recalibrating. So, be kind to your slide rule.&lt;/p&gt;
    &lt;p&gt;To analyse the precision of the slide rule, we must examine the resolution of the logarithmic scale, first. The $C$ and $D$ scales are logarithmic, so they are nonlinear. The scales start on the left at $log(1) = 0$, which is marked as $1$, and end on the right at $log(10) = 1$, which is also marked as $1$. Indeed, these scales wrap around by multiples of $10$ and, hence, the $1$ mark at both ends.&lt;/p&gt;
    &lt;p&gt;As can be seen in the figure below, the distance between two adjacent major divisions on the scale shrinks logarithmically from left to right:&lt;/p&gt;
    &lt;p&gt;The figure above also shows the three distinct regions on the $D$ scale that have different resolutions:&lt;/p&gt;
    &lt;p&gt;At the left end of the $D$ scale, $1.11$, $1.12$, etc., can be read directly from the scale. With practice, one could visually subdivide each minor division into $10$ sub-subdivisions and discern $1.111$ from $1.112$, reliably, precisely. In the photograph below, the cursor hairline is placed on $1.115$.&lt;/p&gt;
    &lt;p&gt;In the middle of the $D$ scale, $3.12$, $3.14$, etc., can be read directly from the scale. Indeed, $3.14$ is marked as $\pi$ on $C$ and $D$ scales of all slide rules. With a nominal eyesight, each minor division could be subdivided visually and easily read $3.13$, which is halfway between the $3.12$ and the $3.14$ graduations. The photograph below shows the hairline on $3.13$.&lt;/p&gt;
    &lt;p&gt;On the right end of $D$ scale, $9.8$, $8.85$, $9.9$, $9.95$, etc., can be read directly from the scale. With due care, each minor division could be subdivided into two sub-subdivisions and read without undue strain $9.975$, which is halfway between the $9.95$ and the $1$ graduations. See the photograph below. But for those of us with poor eyesights, it is rather difficult to discern $9.98$ from $9.99$.&lt;/p&gt;
    &lt;p&gt;Under optimal conditions‚Äîcalibrated slide rule, nominal eyesight, good lighting, and alert mind‚Äîthe slide rule can attain four significant figures of precision on the lower end of the $D$ scale and three significant figures on the higher end of the scale.&lt;/p&gt;
    &lt;p&gt;It is important to note that the logarithmic scale cycles, repeatedly. Hence, the scale reading of $314$ can be valued as $‚Ä¶$, $0.0314$, $0.314$, $3.14$, $31.4$, $314.0$, $3140.0$, $‚Ä¶$ and so forth, depending on the context. The decimal point must be located using mental arithmetic. For example, $\pi/8 \approx 3/8 \approx 0.4$, so the result must necessarily be $0.3927$, not $0.03927$, $3.927,$ nor anything else. So, mental arithmetic locates the decimal point thereby getting us within the zone of accuracy, and scale reading yields the constituent digits thus getting us the precision we desire.&lt;/p&gt;
    &lt;p&gt;Ordinarily, the slide rule was used to evaluate complicated expressions involving many chained calculations when they needed to be performed quickly, but when precision was not a paramount concern. When precision is important, however, logarithm tables were used. These tables were laboriously hand-computed to several significant figures. If the desired value fell between two entries in the table, the user is obliged to interpolate the result, manually. While actuaries may have demanded the high precision afforded by the logarithm table, engineers willingly accepted three or four significant figures offered by the slide rule, because the slide rule was accurate enough for engineering use and it was the fastest means then available to perform calculations. In due course, the slide rule became inextricably linked to engineers, like the stethoscope to doctors.&lt;/p&gt;
    &lt;p&gt;It might be shocking to a modern reader to learn that slide rule wielding engineers accepted low-precision results, considering how precise today‚Äôs engineering is, owing to the use of computer-aided design (CAD) and other automation tools. But these high-tech tools came into common use in engineering, only in the 1990s. Before that, we had to perform analysis by hand using calculators, and prior to that with slide rules. In fact, engineering analysis was a tedious affair. For instance, to design a simple truss bridge‚Äîthe kind prevalent in the 19th century‚Äîthe structural engineer must compute the tension and compression forces present in each beam, taking into account the dimensions of the beams, the strengths of various materials, expected dynamic loads, projected maximum winds, and many other factors. The analysis of force vectors involves many arithmetic and trigonometric calculations, even for the simplest of structures. The sheer number calculations made it uneconomical to insist upon the higher precisions offered by the logarithm tables. As such, engineers settled for lower precision, and in compensation incorporated ample safety margins. This was one of the reasons why older structures are heftier, stronger, and longer-lasting, compared to their modern counterparts.&lt;/p&gt;
    &lt;p&gt;Slide rules came in straight, circular, and cylindrical varieties. Cylindrical rules consist of two concentric cylinders that slide and rotate relative to each other. The key innovation of cylindrical rules was the helical scale that wraps round the cylinder. This coiled scale stretches to an impressive length, despite the relatively small size of the cylinder. Of course, a longer scale yields a greater precision. The cylinder can be rotated to bring the back-facing numbers round to the front.&lt;/p&gt;
    &lt;p&gt;Circular rules were the first practical slide rules. Their main advantages are compactness and stoutness. A typical model is constructed like a pocket watch and operated like one too, using crowns. The glass-faced, sealed construction protects the device against dust. Some circular models sport a spiral scale, thereby extracting good precision from a compact real estate. But the circular scales oblige the user to rotate the device frequently for proper reading. Expert users of circular rules were good at reading the scales upside-down. On some very small models, the graduation marks get very tight near the centre. In other words, circular rules can be rather fiddly.&lt;/p&gt;
    &lt;p&gt;Of all the varieties, straight rules are the easiest and the most convenient to use, because they are relatively small and light, and because the whole scale is visible at once. However, their scale lengths are bounded by the length of the body. So, straight rules are less precise by comparison.&lt;/p&gt;
    &lt;p&gt;Most engineers preferred straight rules, because these devices allowed the user to see the whole scales, and they were fast, accurate, and portable enough for routine use. Hence, this article focuses on straight rules. But a few engineers did use circular models, either because these devices were more precise or because they were more compact. In general, engineers did not use cylindrical ones; these devices were too unwieldy and they had only basic arithmetic scales. But accountants, financiers, actuaries, and others who required greater precision swore by cylindrical rules.&lt;/p&gt;
    &lt;p&gt;The commonest kind of slide rule was the 25 cm desk model, called the straight rule. The cursor is made of clear plastic or glass, etched with a hairline. The frame and the slide are made of wood, bamboo, aluminium, or plastic. The name ‚Äúslide rule‚Äù derives from the slippy-slidy bits and the ruler-like scales. Straight rules come in four types: Mannheim, Rietz, Darmstadt, and log-log duplex.&lt;/p&gt;
    &lt;p&gt;The less expensive Mannheim and Rietz models were used in high school, and the more sophisticated Darmstadt and log-log duplex models were used in college. There were longer straight rules used by those who required more precision. And there were shorter, pocket-sized straight rules, like the Pickett N600-ES carried by the Apollo astronauts. Although not very precise, pocket slide rules were good enough for quick, back-of-the-napkin calculations in the field. Engineers, however, were partial to the 25 cm desk straight rule. As such, the majority of the slide rules manufactured over the past two centuries were of this design.&lt;/p&gt;
    &lt;p&gt;Mannheim type‚ÄîThe most basic straight rule is the Mannheim type, the progenitor of the modern slide rule. Surely, applying the adjective ‚Äúmodern‚Äù to a device that had been deemed outmoded for over 40 years is doing gentle violence to the English language. But given that the slide rule is now over 400 years old, a 150-year-old Mannheim model is comparatively ‚Äúmodern‚Äù.&lt;/p&gt;
    &lt;p&gt;A Mannheim slide rule has $C$ and $D$ scales for arithmetic operations ($√ó$ and $√∑$), $L$ scale for common logarithm ($log$), $A$ and $B$ scales for square and square root ($x^2$ and $\sqrt{x}$), $K$ scale for cubic and cube root ($x^3$ and $\sqrt[3]{x}$), and $S$ and $T$ scales for trigonometric functions ($sin$ and $tan$).&lt;/p&gt;
    &lt;p&gt;The following is the Post 1447 simplex slide rule, manufactured by the Japanese company Hemmi in the late 1950s. As is the tradition for Japanese slide rules, this one is made of bamboo, which is a better material than wood, because bamboo is more resistant to warping and it slides more smoothly. The term ‚Äúsimplex‚Äù refers to the slide rules with scales on only one side of the frame.&lt;/p&gt;
    &lt;p&gt;Unlike its simplex frame, the slide of the Mannheim rule has engraved on its backside the $S$, $L$, and $T$ scales, which are read through the cutouts at each end. Given that the Post 1447 is a modern Mannheim rule, it has clear-plastic windows over the cutouts, and engraved on these windows are fixed red hairlines for reading the scales. These hairlines are alined with the $1$ mark on the frontside $D$ scale.&lt;/p&gt;
    &lt;p&gt;Classic Mannheim simplex slide rules do not have windows over the cutouts. Instead, their cutouts are cleverly placed in an offset: the right-hand cutout is aligned with the two upper scales on the backside of the slide (the $S$ and the $L$ scales) and the left-hand cutout is aligned with the two lower scales (the $L$ and the $T$ scales). It does get unwieldy when trying to read the left-edge of the $S$ scale, but this design compromise significantly reduces the need to flip the slide round to the front. If the predominant calculations are trigonometric, however, it is more convenient to just flip the slide and to use the front of the slide rule.&lt;/p&gt;
    &lt;p&gt;The original Mannheim slide rule was invented in 1859 by Am√©d√©e Mannheim, a French artillery officer, for quickly computing firing solutions in the field. It had only $C$, $D$, $A$, and $B$ scales, so it was capable of computing only $√ó$, $√∑$, $x^2$, and $\sqrt{x}$. This suited its intended purpose. It was the forefather of the modern straight rule.&lt;/p&gt;
    &lt;p&gt;Rietz type‚ÄîA slight improvement upon the French Mannheim type was the German Rietz type, designed in 1902 for Dennert &amp;amp; Pape (D&amp;amp;P, subsequently Aristo) by Max Rietz, an engineer. It added the $ST$ scale for small angles in the range $[0.573¬∞, $ $5.73¬∞] = [0.01, 0.1]\ rad$. In this angular range, $sin(\theta) \approx tan(\theta)$, so the combined $sin$-$tan$ scale suffices. The following is the Nestler 23 R Rietz, a German make known to be favoured by boffins, including Albert Einstein. The 23 R dates to 1907, but the example below is from the 1930s. The frontside has $K$ and $A$ scales on the upper frame; $B$, $CI$ , and $C$ scales on the slide; and $D$ and $L$ scales on the lower frame. The $CI$ scale is the reverse $C$ scale that runs from right to left.&lt;/p&gt;
    &lt;p&gt;The backside of the Nestler 23 R have traditional, Mannheim-style offset cutouts at each end and black index marks engraved onto the wood frame. The backside of the slide holds the $S$, $ST$, and $T$ scales. The $S$ and $ST$ scales are read in the right-hand cutout, and the $ST$ and the $T$ scales are read in the left-hand cutout.&lt;/p&gt;
    &lt;p&gt;Some slide rules, like this older Nestler 23 R below, came with magnifying cursor glass to allow a more precise scale reading. But I find the distorted view at the edges of the magnifier rather vexing. This model looks to be from the 1920s.&lt;/p&gt;
    &lt;p&gt;Darmstadt type‚ÄîAnother German innovation was the Darmstadt type, designed in 1924 by Alwin Walther, a professor at the Technical University of Darmstadt, for D&amp;amp;P (Aristo). Darmstadt rule was the workhorse preferred by the early 20th century engineers. It added three $LL_n$ scales ($LL_1$, $LL_2$, and $LL_3$) which are used to compute general exponentiation of the form $x^{y/z} = \sqrt[z]{x^y}$, when $x &amp;gt; 1$. When $z = 1$, the general expression reduces to $x^y$. When $y = 1$, the general expression reduces to $x^{1/z} = \sqrt[z]{x}$. Newer, more advanced models sport the fourth $LL_0$ scale. The following is the Aristo 967 U Darmstadt from the mid 1970s.&lt;/p&gt;
    &lt;p&gt;The backside of the Aristo 967 U‚Äôs slide has the $L$ and the three $LL_n$ scales. Being that it is a late model Darmstadt simplex rule with a clear plastic back, the entire lengths of these scales are visible at once‚Äîa definite improvement to usability compared to the tradition wood rules with cutouts. These scales are read against the fixed red hairline at each end.&lt;/p&gt;
    &lt;p&gt;log-log duplex type‚ÄîModern engineering slide rules generally are of the log-log duplex type. The duplex scale layout was invented by William Cox in 1895 for K&amp;amp;E. The models used by engineering students have three black $LL_n$ scales ($LL_1$, $LL_2$, and $LL_3$ running from left to right) for cases where $x &amp;gt; 1$ and three red $LL_{0n}$ scales ($LL_{01}$, $LL_{02}$, and $LL_{03}$ running from right to left) for cases where $x &amp;lt; 1$. More advanced models used by professional engineers have four black-red pairs of $LL$ scales.&lt;/p&gt;
    &lt;p&gt;The Faber-Castell (FC) 2/83 N Novo Duplex slide rule, shown below, is a late model, advanced engineering rule from the mid 1970s. It was designed and manufactured at the close of the slide rule era. It was especially popular outside the US. It is a rather long and wide slide rule. And it was arguably one of the most aesthetically pleasing slide rules ever made.&lt;/p&gt;
    &lt;p&gt;Aside from sporting four black-red pairs of $LL$ scales on the backside, the FC 2/83 N has $T_1, T_2$ expanded $tan$ scales and $W_1, W_2$ specialised scale pairs for computing $\sqrt{x}$ with greater precision.&lt;/p&gt;
    &lt;p&gt;Circular slide rules can be categorised into three types: simplex, pocket watch, and duplex. Circular rules were popular with businessmen, and the most popular models were of the stylish, pocket watch type.&lt;/p&gt;
    &lt;p&gt;simplex type‚ÄîThe diameter of the FC 8/10 circular rule is only 12 cm, but in terms of capability, it is equivalent to a 25-cm Rietz straight rule. The FC 8/10 is an atypical circular rule: most circular rules use spiral scales, but the FC 8/10 uses traditional Rietz scales in wrapped, circular form. The example shown below was made in the mid 1970s.&lt;/p&gt;
    &lt;p&gt;Since the FC 8/10 is a simplex circular rule, its backside holds no scales; instead it bears use instructions and a few scientific constants.&lt;/p&gt;
    &lt;p&gt;pocket watch type‚ÄîA more typical design for circular slide rules is the pocket watch variety, like the Fowler‚Äôs Universal Calculator shown below. William Fowler of Manchester, England, began manufacturing calculating devices in 1898. This particular model probably dates to the 1950s. Fowler slide rules were made to exacting standards, like a stylish, expensive pocket watch, and are operated like a watch, too, using the two crowns.&lt;/p&gt;
    &lt;p&gt;The backside of the Fowler‚Äôs Universal Calculator is covered in black leather. This device is small enough to fit in the palm and the edges of the metal case are rounded, so it is quite comfortable to hold.&lt;/p&gt;
    &lt;p&gt;duplex type‚ÄîIt is no secret that most engineers disliked the circular slide rule; many were downright derisive. Seymour Cray, the designer of the CRAY super computer, my favourite electrical engineer and my fellow circular slide rule fancier, once quipped, ‚ÄúIf you had a circular [slide rule], you had some social problems in college.‚Äù But the Dempster RotaRule Model AA was the circular rule that even the most ardent straight rule enthusiast found tempting. It is a duplex circular rule. And it is exceedingly well made. Its plastic is as good as the European plastics, far superior to the plastics used by American manufacturers like K&amp;amp;E. It is the brainchild of John Dempster, an American mechanical engineer. The Dempster RotaRule Model AA shown below is probably from the late 1940s. Unconventionally, the trigonometric scales are on the frontside.&lt;/p&gt;
    &lt;p&gt;The backside of the Dempster RotaRule holds the four $LL_n$ scales among others.&lt;/p&gt;
    &lt;p&gt;All cylindrical rules emphasise precision, so they all have very long scales. Some cylindrical rules use the helical-scale design, while others use the stacked straight-scale design. Cylindrical rules come in two types: pocket type and desk type. The business community favoured the greater precision these devices afforded. As such, most cylindrical rules were very large; they were made for the banker‚Äôs ornate mahogany desk.&lt;/p&gt;
    &lt;p&gt;pocket type‚ÄîThe Otis King Model L, shown below, is a contradiction: it is a compact cylindrical rule that, when collapsed, is well shy of an open palm. Portability wise, this cylindrical rule could compete with larger pocket watch type circular rules. But because the Model L employs helical scales, its precision is far superior to that of common straight rules and pocket watch circular rules. This particular Model L is likely from the 1950s.&lt;/p&gt;
    &lt;p&gt;desk type‚ÄîA giant among large cylindrical rules was the K&amp;amp;E 1740, designed in 1881 by Edwin Thacher, an American engineer working for K&amp;amp;E. I have never seen this device in person, so I do not know the finer points of how it was used. But the general operating principles are similar to that of the Otis King Model K: the outer cylinder is mounted to the wooden base but it can spin in place. The inner cylinder shifts and spins independently of the outer cylinder. The inner cylinder‚Äôs scale is read through the slits in the outer cylinder‚Äôs scale. Thus, the outer cylinder is analogous to the straight rule‚Äôs frame, and the inner cylinder is analogous to the straight rule‚Äôs slide. There is, however, no cursor on this device; it is unnecessary, since the large, legible scales can be lined up against each other by eye. The first Thacher model dates to 1881. The one shown in the photograph blow, a museum piece, is probably a late model from the 1950s, by the look of it.&lt;/p&gt;
    &lt;p&gt;Ordinary engineering slide rules provide arithmetic, logarithm, exponential, and trigonometric functions. Some advanced models provide hyperbolic functions. More models provide speciality-specific functions: electronic, electrical, mechanical, chemical, civil, and so forth. Here, I shall ignore such speciality-specific rules.&lt;/p&gt;
    &lt;p&gt;The impetus for the slide rule‚Äôs invention was to expedite $√ó$ and $√∑$. These arithmetic operations were performed using the $C$ and the $D$ scales. Over time, slide rule designers had created numerous scales that augment the $C$ and $D$ scales: reciprocal $CI$ and $DI$; folded $CF$ and $DF$; and folded reciprocal $CIF$ and $DIF$.&lt;/p&gt;
    &lt;p&gt;In 1775, Thomas Everard, an English excise officer, inverted Gunter‚Äôs logarithmic scale, thus paving the way for the reciprocal $CI$ and $DI$ scales that run from right to left. Using $D$ and $C$, $a √∑ b$ is computed as $a_D - b_C$. But using $D$ and $CI$, this expression is computed as $a_D + b_{CI}$:&lt;/p&gt;
    &lt;p&gt;The $CF$, $DF$, $CIF$, and $DIF$ scales are called ‚Äúfolded‚Äù, because they fold the $C$, $D$, $CI$, and $DI$ scales, respectively, at $\pi$, thereby shifting the $1$ mark to the middle of the scale. The following photograph shows these auxiliary scales on the slide.&lt;/p&gt;
    &lt;p&gt;These auxiliary scales often reduce slide and cursor movement distances considerably, thereby speeding up computations. But I shall not present the detailed procedures on using these auxiliary scales, because they are procedural optimisations not essential to understanding slide rule fundamentals. Interested readers may refer to the user‚Äôs manuals, which are listed in the resource section at the end of the article.&lt;/p&gt;
    &lt;p&gt;The logarithm $L$ scale is the irony of the slide rule. The $log$ function is nonlinear. But because the slide rule is based upon this very same nonlinearity, the $L$ scale appears linear when inscribed on the slide rule.&lt;/p&gt;
    &lt;p&gt;To compute $log(2)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;squaring on slide rule‚ÄîA typical engineering slide rule provides the $A$ scale on the frame and the $B$ scale on the slide for computing $x^2$, the $K$ scale on the frame for computing $x^3$, and the $LL_n$ scales and their reciprocals $LL_{0n}$ scales on the frame for computing $x^y$. The procedures for computing powers and roots always involve the $D$ scale on the frame.&lt;/p&gt;
    &lt;p&gt;To compute $3^2$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;The $A$-$D$ scale pair computes $x^2$, because $A$ is a double-cycle logarithmic scale and $D$ is a single-cycle logarithmic scale. In the reverse direction, the $D$-$A$ scale pair computes $\sqrt{x}$.&lt;/p&gt;
    &lt;p&gt;To compute $\sqrt{9}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;But placing the hairline on $9$ in the second cycle of the $A$ scale would compute $\sqrt{90} = 9.49$.&lt;/p&gt;
    &lt;p&gt;cubing on slide rule‚ÄîIt is a little known fact that Isaac Newton invented the cubic $K$ scale in 1675 by solving the cubic equation. The $K$-$D$ scale pair computes $x^3$ because $K$ is a triple-cycle logarithmic scale. And the reverse $D$-$K$ scale pair computes $\sqrt[3]{x}$.&lt;/p&gt;
    &lt;p&gt;To compute $3^3$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;When computing $\sqrt[3]{x}$, the digits to the left of the decimal are grouped by threes, and if the left-most group has one digit (say $1,000$) then place the argument in $K$ scale‚Äôs first cycle; if two digits (say $22,000$) then in the second cycle; and if three digits (say $333,000$) then in the third cycle.&lt;/p&gt;
    &lt;p&gt;To compute $\sqrt[3]{64000}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Placing the hairline on $6.4$ in the first cycle of the $K$ scale would compute $\sqrt[3]{6.4} = 1.857$, and placing the hairline on $640$ in the third cycle of the $K$ scale would compute $\sqrt[3]{640} = 8.62$.&lt;/p&gt;
    &lt;p&gt;logarithmic exponentiation‚ÄîGeneral exponentiation of the form $x^{y/z}$ can be reduced to arithmetic operations by applying the $log$ function:&lt;/p&gt;
    &lt;p&gt;Then, $√ó$ and $√∑$ can be further reduced to $+$ and $-$ by applying the $log$ function once more:&lt;/p&gt;
    &lt;p&gt;It turns out that the slide rule performs this trick using the base-$e$ natural logarithm $ln$ as the inner logarithm and the base-$10$ common logarithm $log$ as the outer logarithm. That is, the function composition is actually $log \circ ln$, not $log \circ log$. The $ln$ is used instead of the $log$ for the inner logarithm, in order to compress the range of the $LL_n$ scale, thereby improving reading precision. Hence, computing $x^{y/z}$ on the slide rule is equivalent to performing the following logarithmic operations:&lt;/p&gt;
    &lt;p&gt;So, computing $2^4$ and $\sqrt[4]{16}$ on the slide rule proceed as follows:&lt;/p&gt;
    &lt;p&gt;We now see that the ‚Äúlog-log‚Äù nomenclature of engineering slide rules is a not-so-subtle nod to the function composition $\color{blue}{log} \circ \color{green}{ln}$ that appears in the expressions computing $x^{y/z}$.&lt;/p&gt;
    &lt;p&gt;On the slide rule, the $LL$ scales compute general exponentiation $x^{y/z}$. It is, therefore, reasonable to ask, ‚ÄúIf the $LL$ scale pairs can compute arbitrary powers and roots, why waste precious real estate with the redundant $A$, $B$, and $K$ scales?‚Äù The answer is convenience. Engineering calculations make frequent use of squares (for Pythagoreans and areas) and cubes (for volumes), and these scales provide quick calculations of those operations. Although the $LL$ scales possess greater flexibility and precision, their procedures are commensurately more intricate and error prone.&lt;/p&gt;
    &lt;p&gt;Recall that reading the result on the $D$ scale implicitly performs $log^{-1}$. Likewise, reading the result on the $LL_n$ scale implicitly performs $ln^{-1}$.&lt;/p&gt;
    &lt;p&gt;natural logarithm scale‚ÄîThe black $LL_n$ scale is closely related to the base-$e$ ($e = 2.718$) natural logarithm $ln$. The $LL_n$ and the $D$ scales are related by a bijective function $ln$:&lt;/p&gt;
    &lt;p&gt;In the plot below, the black curve is $ln$ and the red is $ln^{-1}$.&lt;/p&gt;
    &lt;p&gt;The special name for $ln^{-1}$ is exponential function $e^x$. The $LL_n$ and the $D$ scales form a transform pair that converts between the base-$e$ natural logarithm scale and the base-$10$ common logarithm scale.&lt;/p&gt;
    &lt;p&gt;Unlike the $D$ scale, the black $LL_n$ scale is not cyclic; it is one long scale. On the K&amp;amp;E 4081-3, the black $LL_n$ scale is divided into these three ranges:&lt;/p&gt;
    &lt;p&gt;These ranges of the $LL_n$ scales clearly show the rate of exponential growth. The function composition $log \circ ln$ used to derive the $LL_n$ scales, so that the $LL_3$ scale lines up perfectly with the $D$ scale: $log(ln(e)) = 0$ and $log(ln(22000)) = 1$. The lower $LL_n$ scales are similarly derived in accordance with their respective ranges.&lt;/p&gt;
    &lt;p&gt;Had we used the $log \circ log$ function composition to construct the $LL_n$ scales, the range of the $LL_3$ scale would be $[10^1, 10^{10}]$, instead. Shrinking this galactic scale down to a 25-cm length would make the scale resolution unusably coarse. The function $e^x$ is famous for its fast growth rate, but $10^x$ beats it, hands down.&lt;/p&gt;
    &lt;p&gt;The red $\color{red}{LL_{0n}}$ scales are reciprocals of the black $LL_n$ scales. As such, these scales run from right to left. On the K&amp;amp;E 4081-3, the red $\color{red}{LL_{0n}}$ scale is divided into these ranges:&lt;/p&gt;
    &lt;p&gt;Because the $LL$ scales are intimately linked to $ln$, and by extension to $e^x$, many slide rules label the $LL_n$ scales as $e^x$ and the $\color{red}{LL_{0n}}$ scales as $e^{-x}$. Note the terminology: the term ‚Äúexponentiation‚Äù refers to the expression $x^y$, and the term ‚Äúexponential‚Äù refers to the function $e^x$.&lt;/p&gt;
    &lt;p&gt;To compute $ln(2)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;To compute $ln(3)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Computing $e^x$, however, is not the primary purpose of the $LL$ scale pairs; Peter Roget, an English physician and the creator of the Roget Thesaurus, designed this scale to compute arbitrary powers and roots in the form of $x^{y/z}$. The black $LL_n$ scales are for computing powers and roots of $x &amp;gt; 1$, and the red $\color{red}{LL_{0n}}$ for $x &amp;lt; 1$.&lt;/p&gt;
    &lt;p&gt;As we have seen earlier, multiplication and division start and end on the fixed $D$ scale and requires the use of the sliding the $C$ scale. Likewise, exponentiation starts and ends on the fixed $LL$ scales and requires the use of the sliding $C$ scale. At a glance, computing $x^y$ seems as straightforward as computing $x √ó y$. But in truth, the $LL$ scales are beguiling; using them correctly requires care, and using them quickly requires practice. A typical first-year engineering student takes several weeks of regular use to become proficient with the $LL$ scales.&lt;/p&gt;
    &lt;p&gt;The procedures for computing $x^y$ using the $LL$ scales are complex enough that they warrant being split into two cases: when $x &amp;gt; 1$ and when $x &amp;lt; 1$.&lt;/p&gt;
    &lt;p&gt;exponentiation for the $x &amp;gt; 1$ case‚ÄîIf $x &amp;gt; 1$, we use the $LL_n$ scales and the $C$ scale to compute $x^y$ as follows:&lt;/p&gt;
    &lt;p&gt;To compute $1.03^{2.4}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Sometimes, we get into a bit of a quandary. Say, we wish to compute $1.03^{9.2}$. We line up the $C$ scale‚Äôs left-hand $1$ with the $LL_1$ scale‚Äôs $1.03$. But now, the $C$ scale‚Äôs $9.2$ has fallen off the right edge of the slide rule. What this indicates is that we have exceeded the upper limit of the $LL_1$ scale from whence we began, and have ventured onto the $LL_2$ scale. That means we must read the result on the $LL_2$ scale. In order to avoid going off the edge, we instead use the folded $CF$ scale.&lt;/p&gt;
    &lt;p&gt;To compute $1.03^{9.2}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;If the exponent is negative, we read the result on the $\color{red}{LL_{0n}}$ scale. Because $x^{-y} = 1/x^y$ and $LL_n = 1/\color{red}{LL_{0n}}$, computing $x^y$ on the $LL_n$ scale but reading the result on the $\color{red}{LL_{0n}}$ scale yields $x^{-y}$.&lt;/p&gt;
    &lt;p&gt;To compute $2.22^{-1.11}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Had we read the result on the $LL_2$ scale, we would have computed $2.22^{1.11} = 2.434$. But by reading the result on the $\color{red}{LL_{02}}$ scale, we compute the reciprocal $1/2.434 = 0.413$, as desired. The $LL$ scales are the most powerful scales on an engineering straight rule. But with that power comes numerous traps for the unweary. Interested readers may read the user‚Äôs manuals listed in the resources section at the end of the article.&lt;/p&gt;
    &lt;p&gt;When computing $2.22^{-1.11}$ above, we used the $CI$ scale, instead of the $C$ scale, as usual. This is because the base $2.22$ is far to the right edge of the slide rule, had we used the $C$ scale, the slide would be hanging almost entirely off the right edge. Using the $CI$ scale in this case reduces the slide movement distance, considerably.&lt;/p&gt;
    &lt;p&gt;exponentiation for the $x &amp;lt; 1$ case‚ÄîIf $x &amp;lt; 1$, we use the $\color{red}{LL_{0n}}$ scales and the $C$ scale to compute $x^y$. The procedures for the $\color{red}{LL_{0n}}$ scales are analogously categorised into four ranges of the exponent, the details of which I shall forego.&lt;/p&gt;
    &lt;p&gt;To compute $0.222^{1.11}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Trigonometric functions are related to each other by these identities:&lt;/p&gt;
    &lt;p&gt;In the plot below, the blue curve is $sin$, the green is $cos$, and the red is $tan$.&lt;/p&gt;
    &lt;p&gt;black $S$ scale‚ÄîThe $S$ scale on the slide rule is graduated in degrees from $5.73¬∞$ to $90¬∞$. When $\theta ‚àà [5.73¬∞, 90¬∞]$ on the $S$ scale, $sin(\theta) ‚àà [0.1, 1.0]$ on the $C$ scale. The $S$ and the $C$ scales are related by a bijective function $sin$:&lt;/p&gt;
    &lt;p&gt;In the plot below, the black curve is $sin$ and the blue is $sin^{-1}$. Note that the inverse function (here $sin^{-1}$) is a reflection in the $y = x$ line of the original function (here $sin$). In the figure below, the $x$-axis represents the angle $\theta$ in radians.&lt;/p&gt;
    &lt;p&gt;To compute $sin(30¬∞)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;To compute $\theta$ in the expression $sin(\theta) = 0.866$, we do the opposite: set the argument $0.866$ on the $C$ scale and read the result $60¬∞$ on the $S$ scale. This computes $\theta = sin^{-1}(0.866) = 60¬∞$.&lt;/p&gt;
    &lt;p&gt;red $\color{red}{S}$ scale‚ÄîThe $S$ scale is graduated from left to right, in black, for $sin$ between the angles $5.73¬∞$ and $90¬∞$. But since $cos(\theta) = sin(90¬∞ - \theta)$, the $cos$ scale is readily combined into the $S$ scale, but in the reverse direction and marked in red. Hence, $cos(\theta)$ is computed using the same procedure, but in reference to the red $\color{red}{S}$ scale.&lt;/p&gt;
    &lt;p&gt;In the plot below, the red curve is $cos$ and the blue is $cos^{-1}$.&lt;/p&gt;
    &lt;p&gt;black $T$ scale‚ÄîThe $T$ scale is graduated in degrees from $5.73¬∞$ to $45¬∞$. When $\theta ‚àà [5.73¬∞, 45¬∞]$ on the $T$ scale, $tan(\theta) ‚àà [0.1, 1.0]$ on the $C$ scale. The $T$ and the $C$ scales are related by a bijective function $tan$:&lt;/p&gt;
    &lt;p&gt;In the plot below, the black curve is $tan$ and the blue is $tan^{-1}$.&lt;/p&gt;
    &lt;p&gt;red $\color{red}{T}$ scale‚ÄîThe $T$ scale, too, has red markings, running right to left, for $\theta ‚àà [45¬∞, 84.29¬∞]$. The red $\color{red}{T}$ scale is used for $tan(\theta) ‚àà [1 \rightarrow 10]$ and for $cot(\theta) ‚àà [1.0 \leftarrow 0.1]$. The red $\color{red}{T}$ scale is used in conjunction with the reciprocal $CI$ scale.&lt;/p&gt;
    &lt;p&gt;To compute $tan(83¬∞)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Since $cot(\theta) = tan(90¬∞ - \theta) = 1/tan(\theta)$, we may compute $cot(\theta)$ using the black $T$ scale or the red $\color{red}{T}$ scale, as per the procedure described above. So, to compute $cot(83¬∞)$, we use the same procedure as $tan(83¬∞)$ on the red $\color{red}{T}$ scale, but read the result $cot(83¬∞) = 1/tan(83¬∞) = 0.1228$ on the $C$ scale, instead of the $CI$ scale. Alternatively, we may compute $tan(90¬∞ - 83¬∞)$ on the black $T$ scale, and read the result $cot(83¬∞) = tan(7¬∞) = 0.1228$ also on the $C$ scale.&lt;/p&gt;
    &lt;p&gt;In the plot below, the red curve is $cot$ and the green is $cot^{-1}$.&lt;/p&gt;
    &lt;p&gt;$ST$ or $SRT$ scale‚ÄîThe $ST$ scale is used to compute $sin$ and $tan$ for small angles in the range $[0.573¬∞, 5.73¬∞] = [0.01, 0.1]\ rad$, because $sin(\theta) \approx tan(\theta)$ for small angles. For such small angles, we may exploit another approximation: $sin(\theta) \approx tan(\theta) \approx \theta\ rad$, where the angle $\theta$ is measured in radians. For this reason, some manufacturers, like K&amp;amp;E, label the $ST$ scale as $SRT$ for $sin$-$rad$-$tan$.&lt;/p&gt;
    &lt;p&gt;In the plot below, the blue curve is $sin$ and the red is $tan$. These two curves are indistinguishable when $\theta ‚àà [0.0, 0.1]\ rad$.&lt;/p&gt;
    &lt;p&gt;It is possible to chain trigonometric and arithmetic calculations on the slide rule. This is one of the reasons why calculating with the slide rule is so much faster than using tables. Those who are interested in these details should read the user‚Äôs manuals listed in the resources section at the end of the article.&lt;/p&gt;
    &lt;p&gt;calibrating‚ÄîWhen an adjustable slide rule, like the K&amp;amp;E 4081-3, goes askew (but not warped), its accuracy can be restore by recalibrating. The frame of this duplex slide rule consists of the fixed lower portion and the adjustable upper portion. The two faces of the cursor are independently adjustable, as well. We calibrate this slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Frustrating though it can be to recalibrate a skewed slide rule, that is the easy bit. Reading the scales with adequate precision, however, is trickier, especially for those of us with poor eyesights.&lt;/p&gt;
    &lt;p&gt;cleaning‚ÄîI can say nothing about maintaining and cleaning vintage Thacher-style large cylindrical rules, since I have never even seen one in person. But straight rules, circular rules, and Otis King-style cylindrical rules should be cleaned by gently wiping down with clean, moist (but not dripping wet) microfibre cloth or paper towel, then dry off the moisture, immediately. Although plastic and aluminium rules can withstand water, wood and bamboo rules cannot. Note that the black handle (the cursor) on the Otis King is actually a black-painted brass cylinder. Aggressive rubbing can scrub off the black paint. And be forewarned: never use chemical solvents.&lt;/p&gt;
    &lt;p&gt;With use, the slide can get sticky, over time. This is caused by the grime‚Äîan amalgam of dust and skin oil‚Äîthat collect in the crevices between the slide and the frame. This grime can be cleaned with a moist microfibre cloth or paper towel. Do not apply lemon oil, grease, powder, graphite, or any other foreign substance to the slide rule, and especially never to the slide-frame contact areas. Not only does the slide rule not require lubricants, these foreign substances could mar, or perhaps even damage, the device.&lt;/p&gt;
    &lt;p&gt;Dust also tends to gather under the cursor glass. The easiest way to remove the dust is to blow it out using a compressed air canister. To remove stubborn stains under the glass, however, the cursor may need to be disassembled and cleaned.&lt;/p&gt;
    &lt;p&gt;If you are reading this article, odds are that you do not own a slide rule. It is my hope that you would acquire one, say from eBay, and learn to use it. Your first slide rule should not be a rare, collector‚Äôs item; it should be something like the K&amp;amp;E 4081-3 Log Log Duplex Decitrig or the Post 1460 Versalog‚Äîa cheap, but good, model. If you do end up buying one, yours will most likely be grimy and discoloured, for having been kept in a dusty storage bin for decades. Do not despair; most old slide rules can be renewed to a good extent. The grime and discolouration can be removed by gently‚ÄîI mean gently‚Äîrubbing with the soft, foamy side of a moist (but not dripping wet) kitchen sponge loaded with a spot of dish soap. If you do decide to attack a stain with the rough side of the sponge, use care and judgement, or you will scrub off the scale markings. Use extra care, when scrubbing painted slide rules, like the Pickett aluminium rules. And if yours is a wood slide rule, minimise its contact with water. Immediately dry off the slide rule after cleaning. Do not apply heat as a drying aid. And I strongly suggest that you clean in stages, removing the grime layer by layer.&lt;/p&gt;
    &lt;p&gt;This section is about collecting slide rules: what to look for, how to purchase, how to avoid pitfalls, etc. I collect slide rules; this should surprise no one reading this article. But I am an atypical collector. I buy but I do not sell. I do not engage in bidding wars on eBay. Most of the slide rules I collect are those that I coveted as a young engineering student in the early 1980s. A few are cheap curiosities. More importantly, I buy slide rules that are not ‚Äúcollector-grade‚Äù. That is, my slide rules have high accuracy, but they do not necessarily have high resale value: most are not rarities; some have former owners‚Äô names engraved upon them; many do not come with cases, manuals, wrappings, boxes, and other accoutrement of collecting. Moreover, whereas most collectors favour top-of-the-line, sophisticated, powerful slide rules, I am partial to the humble Darmstadt rule, for this type offers the best balance in terms of density, simplicity, and utility. And as much as I like the Darmstadt rules, I dislike having to use the pocket rules, mainly due to my poor eyesight. Nevertheless, pocket rules are perfectly serviceable; Apollo astronauts staked their lives on it, after all.&lt;/p&gt;
    &lt;p&gt;My main goal in collecting slide rules is to play, not to display. Although these simple instruments no longer hold practical value today, they were once instrumental in creating immense value for humanity. I acknowledge that fact by collecting them. And by using them, I am able to appreciate more deeply the ingenuity of my forebears, the 19th century engineers who propelled forward humanity and slide rule design. To perpetuate this appreciation, I taught my son how to use slide rules, starting when he was a third-grader. I am motivated by knowledge and nostalgia, not by possessory pride or pecuniary purpose. So, when perusing my collection described herein, take my biases into account: a collection is a reflection of the collector.&lt;/p&gt;
    &lt;p&gt;Here is a little perspective. In the 1950s, an ordinary engineering slide rule, like the K&amp;amp;E 4081-3, was priced around 20 USD, now. In today‚Äôs money, that slide rule would cost about 230 USD. By way of comparison, the HP Prime calculator‚Äîthe ultimate weapon of an engineer‚Äîwith reverse Polish notation (RPN), computer algebra system (CAS), BASIC programming language, 3D plotting, colour touchscreen, and a whole lot more, costs about 100 USD, new, in 2021. A refurbished Dell laptop with Intel Core i5 CPU and 4 GB of RAM costs about 130 USD. Are you all astonishment?&lt;/p&gt;
    &lt;p&gt;I purchased all my slide rules on eBay, except these: the Aristo 0968, which was the required equipment at my engineering school in early 1980s Burma, and I purchased it from the government store; the FC 8/10, which was owned by my engineer aunt, who gifted it to me when I entered engineering school; the FC 67/64 R and the FC 2/83 N, which I purchased new from the Faber-Castell online store a couple of decades ago, when the company still had new old-stock (NOS) slide rules; and the Concise Model 300, which I purchased new from Concise online store several years ago. Concise still makes slide rules today, by the way.&lt;/p&gt;
    &lt;p&gt;Below, I arranged my collection by slide rule variety (straight, circular, and cylindrical); within each variety by brandname; and under each brandname by capability (Mannheim, Rietz, Darmstadt, log-log duplex, and vector). I took the photographs with a tripod-mounted camera from a fixed position, so as to show the relative sizes of the slide rules. A typical straight rule is approximately 30 cm in overall length, so it should be easy to ascertain the absolute sizes of the devices from these photographs.&lt;/p&gt;
    &lt;p&gt;Do note that sellers (brands) are not manufacturers, in some cases. For example, Frederick Post (est. 1890), a well-known American company, sold under the Post brand topping bamboo slide rules designed and manufactured by Hemmi of Japan. Hemmi (est. 1895) also sold their superb bamboo slide rules under their own brand. And Keuffel &amp;amp; Esser (est. 1867), the leading American designer and manufacturer of high-quality slide rules, began life as an importer of German slide rules. Also of note was that German manufacturers, Faber-Castell (est. 1761), Aristo (est. 1862), and Nestler (est. 1878), were in West Germany (FRD) during the Cold War, but Reiss (est. 1882) was in East Germany (DDR). And Kontrolpribor (est. 1917), a Russian manufacturer, is more properly labelled a factory in the former Soviet Union.&lt;/p&gt;
    &lt;p&gt;Before we proceed, here are some admonishments for those who are buying slide rules for using, not merely for possessing:&lt;/p&gt;
    &lt;p&gt;My slide rule collection spans several models from each of the following major manufacturers.&lt;/p&gt;
    &lt;p&gt;Aristo (DE)‚ÄîAristo was the slide rule brandname of the German company Dennert &amp;amp; Pape (D&amp;amp;P), founded in 1872. They make top quality rules with understated good looks. D&amp;amp;P were a thought leader in the early part of 20th century. They invented the Rietz scale in 1902 and the Darmstadt scale in 1924. And in 1936, they abandoned wood and began making all-plastic slide rules under the Aristo brand. Plastic is more stable than wood and, hence, a better slide rule material. This high-quality plastic became their signature material. The brandname Aristo eventually became the company name. I have a particular affinity for Aristo because of my first slide rule, the Aristo 0968.&lt;/p&gt;
    &lt;p&gt;Blundell-Harling (UK)‚ÄîBlundell-Harling are an English stationary manufacturer that make technical drawing supplies, today. Back in the day, their BRL slide rules were highly regarded. During the nearly four-century reign of the slide rule, almost every industrialised nation had at least one slide rule manufacturer. But the English slide rules‚Äîstraight, circular, cylindrical, the lot‚Äîwere generally superior in terms of craftsmanship and materials. It makes sense in a way; the English invented the slide rule, after all.&lt;/p&gt;
    &lt;p&gt;Breitling (CH)‚ÄîBreitling are a famed Swiss watchmaker. They were founded in 1884. They have long been associated with aviation. Their Navitimer line is the first wristwatch with integrated chronograph and slide rule, introduced in 1952 for use by pilots. Instrument flying in those days required pilots to use the cockpit flight instruments together with an accurate chronometer (for flight time, arrival time, etc.), a chronograph (for timed turns, holding patterns, ground speed, etc.), and a slide rule (for navigation, fuel burn calculations, etc.). The Navitimer fulfilled all three needs, because it was a chronometer-grade wristwatch, a chronograph, and a slide rule, all in one. Although flying today had become automated, traditional-minded pilots continue to admire the Navitimer for its history, quality, and utility.&lt;/p&gt;
    &lt;p&gt;Concise (JP)‚ÄîConcise are a Japanese maker of drawing and measuring tools. They made good, but low-cost, plastic, circular slide rules. Today in the 21st century, they are the only company still making slide rules.&lt;/p&gt;
    &lt;p&gt;Dempster (US)‚ÄîDempster were a boutique American manufacturer of top quality circular slide rules. They were founded by John Dempster, a Berkeley graduate mechanical engineer, who began manufacturing the Dempster RotaRule in 1928, in the basement of his home in Berkeley, California. The company made only one type of slide rule, and it is the most advanced, and the most desirable, circular slide rules.&lt;/p&gt;
    &lt;p&gt;Faber-Castell (DE)‚ÄîFounded in 1761, Faber-Castell (FC) began life as an office supply company. Today, they remain one of the oldest, and largest, stationary companies. They are now famous for their quality pens and pencils. But for about 100 years, until 1975, FC were a worldwide leader in slide rule making.&lt;/p&gt;
    &lt;p&gt;Fowler (UK)‚ÄîFowler were an English maker of pocket watch slide rules, which they called ‚Äúcalculators‚Äù. They were founded in 1853, and they held numerous British patents on pocket watch slide rules. Fowler rules were of superlative quality, constructed like expensive pocket watches. And these devices came in high-quality, wooden cases that resembled jewellery boxes.&lt;/p&gt;
    &lt;p&gt;Gilson (US)‚ÄîGilson, established in the 1930s, were an American maker of cheap, but powerful, aluminium circular rules with spiral scales. They made many models, both large (almost 22 cm diameter) and small (about 12 cm diameter), but all were of the same, three-cursor design. In some ways, Gilson circular rules expressed the traditional, American engineering philosophy: big, brash, gaudy, tough, powerful, and usable, but cheap.&lt;/p&gt;
    &lt;p&gt;Graphoplex (FR)‚ÄîGraphoplex were a French maker of splendid-looking slide rules, but with a horrid-looking logo. In terms of quality, French slide rules are on par with German ones. Graphoplex‚Äôs sector-dial watch face style scales are quite pleasing to the eye. Although this visual design was common in the late 19th century, it disappeared during the early 20th century. Some early German wood rules used this visual design, but later wood rules abandoned it. Graphoplex, though, carried this visual design to their modern plastic rules, giving these devices a rather unique classic look.&lt;/p&gt;
    &lt;p&gt;Hemmi (JP)‚ÄîEstablished in 1895, Hemmi designed and manufactured top-quality, innovative slide rules. They made accurate, elegant instruments using quality materials. Their signature material was bamboo. Bamboo is perhaps the best material with which to make slide rules. It is tough, stable, and naturally slippery. I adore Hemmi rules. Today, they make high-tech electronic devices. Yet, they continue to use the name Hemmi Slide Rule Co., Ltd., proudly displaying their illustrious heritage.&lt;/p&gt;
    &lt;p&gt;Keuffel &amp;amp; Esser (US)‚ÄîKeuffel &amp;amp; Esser (K&amp;amp;E) were the most successful manufacturer of quality slide rules in America. They were founded in 1867 by a pair of German immigrants. Initially, they only imported German slide rules. But soon, they began designing and making their own slide rules. K&amp;amp;E were quite innovative. The duplex design was one of theirs, invented for them by William Cox in 1895. Their signature material was mahogany. Mahogany is a good material for slide rule, but it is neither as robust nor as stable as bamboo. K&amp;amp;E also made several plastic rules, but their plastic is of a much lower grade, compared to the European plastics.&lt;/p&gt;
    &lt;p&gt;Kontrolpribor (RU)‚ÄîKontrolpribor was a Soviet factory that made pocket watch slide rules. Like other Soviet products, Kontrolpribor devices feel cheap, but sturdy. Today, Kontrolpribor make high-tech scientific instruments.&lt;/p&gt;
    &lt;p&gt;Loga (CH)‚ÄîLoga were a Swiss maker of superb technical instruments, including circular and cylindrical slide rules. They were founded in the early 20th century. Until about the late 19th century, Switzerland was the home of cheap, high-quality craftsmen. French, German, and English watchmakers relied extensively on the highly skilled Swiss labour force to hand-make their high-end watches. That was how the modern Swiss watch industry was born. So, it is no surprise that 20th century Swiss slide rules exhibit similar craftsmanship.&lt;/p&gt;
    &lt;p&gt;Logarex (CZ)‚ÄîLogarex was a factory in Czechoslovakia, when the country was part of the old Eastern Bloc. Like most everything manufactured in the Eastern Bloc countries during the Soviet Era, Logarex slide rules feel cheap, but usable.&lt;/p&gt;
    &lt;p&gt;Nestler (DE)‚ÄîNestler were a German maker of high-quality slide rules. They were established in 1878. Their mahogany rules were the stuff of legend. Even their very old wood rules from the early 20th century have a modern, minimalist look-and-feel to them. Of all the German brands, Nestler is my favourite.&lt;/p&gt;
    &lt;p&gt;Otis King (UK)‚ÄîOtis King was an English electrical engineer. His company made high-quality pocket cylindrical rules, starting around 1922. They made only two types‚Äîthe Model K and the Model L‚Äîboth of which are described, below. And despite being designed by an electrical engineer, these rules are not suitable for daily use in engineering, given their limited capabilities. The focus of these rules is on portability and precision, the two characteristics treasured by businessmen.&lt;/p&gt;
    &lt;p&gt;Pickett &amp;amp; Eckel (US)‚ÄîPickett, established in 1943, were a newcomer to the American slide rule market. Their signature material was aluminium. And most of their rules wore their trade-dress, the Pickett Eye-Saver Yellow. To be honest, I detest the cold, sharp edges of the aluminium and the gaudy eye-slayer yellow. But loads of American engineers fancied Pickett rules. Not withstanding my opinion, this slide rule is a solid performer. Aluminium is thermally much more stable than wood. And it is well-neigh indestructible. Nevertheless, Pickett aluminium rules feel cheap to me‚Äîmy apologies to NASA who, for their Apollo missions, chose the Pickett N600-ES, a pared-down, pocket version of the popular Pickett N3-ES.&lt;/p&gt;
    &lt;p&gt;Frederick Post (US)‚ÄîFrederick Post were an American importer of top-quality Hemmi bamboo rules. These bamboo rules were sold under the Post brand in America. Frederick Post morphed into Teledyne Post in 1970, and continued making drafting supplies until they were dissolved in 1992.&lt;/p&gt;
    &lt;p&gt;Reiss (DE)‚ÄîReiss were a German slide rule maker, established in 1882. During the Cold War, it diminished to a Soviet-style factory in East Germany. But unlike their fellow Eastern Bloc countrymen, the East Germans staunchly clung on to their German culture that held craftsmanship in high regard. As such, Reiss rules are good quality instruments, comparable to Western European brands.&lt;/p&gt;
    &lt;p&gt;Aristo 967 U Darmstadt‚ÄîThe Aristo 967 U is a late-model, advanced Darmstadt slide rule. Unlike the older Darmstadt rules, the backside of Aristo 967 U is clear plastic, which allows the user to see the entire backside of the slide which, in keeping with the Darmstadt tradition, holds the $L$ scale and the three $LL_n$ scales. And in accordance with that tradition, this slide rule is of a simplex design. As such, the cursor does not reach the backside; the backside scales are read against the fixed red hairlines at each end. Typical of all Aristo slide rules, the frame, the slide, and the cursor are made of a very high-grade plastic, allowing all these bits to glide smoothly.&lt;/p&gt;
    &lt;p&gt;Many late-model, plastic Darmstadt rules, like the Aristo 967 U, have thin lips protruding from the frame, often marked with 25-cm and 10-in ruler scales. Unfortunately, the corners of these lips are rather fragile. These corners chipped off, if the slide rule was dropped. Pay attention to this type of damage, when purchasing a plastic Darmstadt.&lt;/p&gt;
    &lt;p&gt;Frankly, I fail to see the value of inscribing ruler scales on a slide rule. All engineers use the triangular rule for measuring and drafting. This ruler is always on our desks. And on the very first day in engineering school, we were taught never to use the slide rule‚Äîa precision instrument‚Äîlike a common ruler. So, putting ruler scales on a slide rule is simply wasting precious real estate.&lt;/p&gt;
    &lt;p&gt;Aristo 0968 Studio‚ÄîThe Aristo 0968 is an ordinary log-log duplex engineering straight rule, like the K&amp;amp;E 4081-3. But this slide rule is about half a centimetre wider than the slender K&amp;amp;E 4081-3. This extra space affords a couple of extra scales and a more logical scale layout. The Aristo 0968 has the Pythagorean $P$ scale for computing $1 - x^2$ and two $tan$ scales $T_1\ [5.5¬∞, 45¬∞]$ and $T_2\ [45¬∞, 84.5¬∞]$, which the K&amp;amp;E 4081-3 does not have. And all three pairs of $LL$ scales are placed on the backside, making it a much more convenient rule to use for exponentiation‚Äîa good trait for an engineering rule. Indeed, usability is the hallmark of European and Asian slide rules; this is the area in which American slide rules falter.&lt;/p&gt;
    &lt;p&gt;This Aristo 0968 was my first slide rule, purchased from the government store in Burma, circa 1982, upon my arrival at the engineering college, then the only one of its kind in the country.&lt;/p&gt;
    &lt;p&gt;Aristo 0969 StudioLog‚ÄîThe Arist 0969 is a top-of-the-line engineering duplex slide rule, with four pairs of $LL$ scales, $P$ scale, extended trigonometric scales, etc. In terms of capabilities, it is identical to its more famous competitor, the FC 2/83 N. But being half centimetre or so wider, the Aristo 0969 is a monster of a slide rule. This extra real estate allows a bit of extra spacing between the scales, arguably making them easier to read.&lt;/p&gt;
    &lt;p&gt;I think the excessive girth of the Aristo 0969 makes it awkward to flip. It is not one of my favourites.&lt;/p&gt;
    &lt;p&gt;BRL D.26 Darmstadt‚ÄîThe BRL D.26 is a late model Darmstadt. In terms of capabilities, the BRL D.26 is comparable to its contemporary, the Aristo 0967 U. But this English rule‚Äôs build quality is obviously superior to that of its German competitor. The backside of the BRL D.26 sports the traditional cutout for reading the three $LL_n$ scales.&lt;/p&gt;
    &lt;p&gt;I like the BRL D.26, not only for its Darmstadt design, but also because of its superior quality and its quiet elegance.&lt;/p&gt;
    &lt;p&gt;FC 1/54 Darmstadt‚ÄîI rather like the sensible scale layout of the FC 1/54. The back of the slide has the usual three $LL_n$ scales, which are read through the cutouts covered with hairline-inscribed clear plastic. Being of a classic German simplex design, this rule is narrow, but quite thick, compared to modern duplex rules. This thickness gives enough space to the top and bottom edges of the frame for additional scales. The top edge has the 27-cm ruler scale and the $L$ scale, and the bottom edge has the $S$ and the $T$ trigonometric scales.&lt;/p&gt;
    &lt;p&gt;As I stated earlier, I adore Darmstadt rules. The FC 1/54 is one of my favourite Darmstadt rules. But it is not my absolute favourite Darmstadt rule. Which rule is my absolute favourite? Read on.&lt;/p&gt;
    &lt;p&gt;FC 67/64 R Pocket Darmstadt mit Addiator‚ÄîThe FC 67/64 R is a Darmstadt pocket straight rule of about 15 cm in length. Being a Darmstadt rule, the backside of the slide has the usual three $LL_n$ scales. But instead of the traditional cutouts, the backside of the slide rule is occupied by a metal Addiator. As such, the only way to use the $LL_n$ scales is to flip the slide round to the front.&lt;/p&gt;
    &lt;p&gt;The Addiator is a clever little contraption capable of performing addition and subtraction. The device must be reset before each operation by pulling out the bar at the top. The Addiator on the backside of this slide rule is capable of dealing with six significant figures. The operand is entered by dragging with the provided stylus a slot next to the desired digit in the appropriate column. When adding, both augend and addend are set in the upper register. When subtracting, the minuend is set in the upper register and the subtrahend in the lower register. The way the Addiator handles the carry is particularly clever. The mechanisms of this device work on similar principles as the mechanical calculator. But the Addiator is only 1 mm thick and fits neatly behind a pocket slide rule. Given that this is an article about slide rules, however, I shall say no more about this fascinating instrument. The curious may view YouTube videos on the subject.&lt;/p&gt;
    &lt;p&gt;The Addiator does make the backside of the FC 67/64 R‚Äôs slide inaccessible. But considering the computation power afforded by the Addiator, this may well be a worthwhile compromise in some applications. I purchased this FC 67/64 R, new, straight from the Faber-Castell online store, many years ago.&lt;/p&gt;
    &lt;p&gt;FC 1/98 Elektro‚ÄîThe FC 1/98 is an advanced Darmstadt rule designed for electrical power engineers (as opposed to electronic engineers). It is of the classic German simplex design‚Äînarrow and thick. As such, it has specialised scales, like the $kW$ scale for computing power $P$, the $Dynamo$-$Motor$ scale for computing percent power efficiency ($Œ∑ = P_{out} / P_{in}$) of generators and motors, and the $Volt$ scale for computing voltage drop along copper wires. Note that the term ‚Äúdynamo‚Äù was an older name for generator, and motor is the dual of generator. The $Dynamo$-$Motor$ scale and the $Volt$ scale are engraved in the trough of the frame, under the slide. That is a creative use of the limited space. The frame holds the $LL_2$ and $LL_3$, but no $LL_1$. The bottom edge of the frame holds the $K$ scale. The backside of the slide holds the $S$, $L$, and $T$ Mannheim scales, which are read through the traditional, offset cutouts without clear plastic covers. So, the FC 1/98 is a rather unique rule that combines Mannheim, Darmstadt, and electrical engineering scales.&lt;/p&gt;
    &lt;p&gt;The FC 1/98 is, for sure, a speciality slide rule for electrical engineers. But it is general enough to qualify as a Darmstadt-ish engineering rule. And its space-efficient scale layout deserves recognition. As such, I chose to include it in this article. But I did leave out other speciality engineering rules in my collection‚Äîtransmission line Smith chart, electronic engineering rule, mechanical engineering rule, chemical engineering rule, E-6B navigation rule, etc.‚Äîbecause they are too far afield from the primary purpose of this article.&lt;/p&gt;
    &lt;p&gt;FC 2/83 N Novo-Duplex‚ÄîThe FC 2/83 N is famous both for its evident usability as well as for its elegant beauty. Yes, contrary to the prevailing view, we engineers do appreciate aesthetics. The FC 2/83 N uses pale green backgrounds for $C$ and $CF$ on the frontside and $C$ and $D$ on the backside. It uses pale blue backgrounds for $A$ and $B$ on the frontside. In my opinion‚Äîand this view sprang from my experience with human factors in user interface design‚ÄîFC 2/83 N‚Äôs colour-coded scale backgrounds are a better design choice than the Aristo 0969‚Äôs spread-out scales. And the FC 2/83 N has on the backside the $W_1$-$W^{‚Äò}_1$ and $W_2$-$W^{‚Äò}_2$ extended square root scales, which the Aristo 0969 lacks. That is impressive, considering the Aristo 0969 is a good half-centimetre wider than the FC 2/83 N. Also, as can be seen in the photograph below, the FC 2/83 N‚Äôs slide has black grooves at its tips. These striations make it easier to pull out the slide from its stowed position. Little things like this make big differences in usability and convenience, especially when operating under time pressure‚Äîlike in an examination.&lt;/p&gt;
    &lt;p&gt;I would like to draw attention to the fact that the 1970s were, how shall I say it tactfully, ‚Äúunique‚Äù in terms of design taste. All right, they were loud, they were excessive. In that era of paisleys and bell-bottoms, German slide rule design‚Äîtypified by the Aristo 0969, the FC 2/83 N, and the Nestler 0292‚Äîmanaged to remain tastefully restrained. I purchased this FC 2/83 N, new, straight from the Faber-Castell online store, many years ago.&lt;/p&gt;
    &lt;p&gt;Graphoplex 643 Pocket Electric Log Log‚ÄîThe Graphoplex 643 is an advanced pocket rule. Of all my pocket rules‚Äîwhich I have but a few, due to my poor eyesight‚ÄîI find this one the easiest to read. This pocket rule is a miniature version of the Graphoplex 640. See the full description in the Graphoplex 640 subsection, below.&lt;/p&gt;
    &lt;p&gt;Graphoplex 640 Electric Log Log‚ÄîThe Graphoplex 640 is another topping Darmstadt rule, like the BRL D.26. But breaking from the Darmstadt tradition, the Graphoplex 640 places the three $LL_n$ scales on the frontside, on the lower frame. And the backside of the slide holds the trigonometric scales and the $C$ scale, which are read through a single cutout on the right side of the rule. The cutout has a clear plastic cover with a hairline, which makes it easy to read all four scales on the backside of the slide. But having only one cutout makes it cumbersome to read the left-hand portions of these scales. The Graphoplex 640 places the three $LL_n$ scales together with the $D$ and $C$ scales. This arrangement significantly improves usability by reducing the need frequently to flip the slide rule when computing exponentiations.&lt;/p&gt;
    &lt;p&gt;The Graphoplex 643 and the Graphoplex 640 were marketed as speciality electrical engineering slide rules. But they are fairly conventional Darmstadt rules. I like these rules very much. Yet, they are not my absolute favourite Darmstadt rules. Read on, to find out which one is my absolute favourite Darmstadt engineering slide rule.&lt;/p&gt;
    &lt;p&gt;Hemmi 135 Pocket Advanced Darmstadt‚ÄîThe Hemmi 135 pocket rule is a marvel: it is a miniature version of the Hemmi 130W, an advanced Darmstadt rule, except for a minor difference with the $LL_n$ scales on the backside of the slide. Whereas the Hemmi 130W has four $LL_n$ scales, the Hemmi 135 has only three, given its diminutive size. See the full description in the Hemmi 130W subsection, below.&lt;/p&gt;
    &lt;p&gt;Hemmi 130W Advanced Darmstadt‚ÄîThe Hemmi 130W is my absolute favourite Darmstadt rule. There, I said it. I would very much like to have owned this rule, when I was a young engineering student those many years ago. As with all Hemmi slide rules, this rule is made of bamboo, my favourite slide rule material. The $S$, $T$, and $P$ scales, along with the usual ones, are on the frontside. Traditional Darmstadt rules have only $LL_1$, $LL_2$, and $LL_3$ on the backside of the slide. But the Hemmi 130W‚Äôs slide has four $LL_n$ scales: $LL_0$, $LL_1$, $LL_2$, and $LL_3$. This makes this slide rule one of the most powerful Darmstadt simplex rules. The $L$ and the $LL_n$ scales are read through large cutouts at each end. The plastic cover of each cutout is inscribed with a fixed red hairline for reading the scales.&lt;/p&gt;
    &lt;p&gt;I adore Darmstadt rules. I said so, often. And of all the Darmstadt rules I own, I love the Hemmi 130W the most. Yet, I think Hemmi missed an opportunity with the way they used the real estate of the top and bottom edges of the frame. Typical of Hemmi simplex rules, this one is fairly thick. The top edge of the frame holds a vapid 27-cm ruler and the bottom edge holds an odd zero-centred 26-cm ruler with 13-cm linear scales crawling out to each end. Hemmi should, instead, have inscribed more useful scales, like the $ST$ scale or the split $T_1$-$T_2$ scales, on the frame edges.&lt;/p&gt;
    &lt;p&gt;Hemmi 153 Electrical Engineer‚ÄîThe Hemmi 153 is a log-log vector duplex rule cherished by electrical power engineers. In terms of capabilities, this slide rule is comparable to the more famous K&amp;amp;E 4083-3 described below in the K&amp;amp;E section. But the Hemmi 153 computes the hyperbolic functions in a rather unique and ingenious way, using the Gudermannian function, introduced in 1833 by Christoph Gudermann, a German mathematician:&lt;/p&gt;
    &lt;p&gt;The function $gd$, thus, relates trigonometric functions with hyperbolic functions as follows:&lt;/p&gt;
    &lt;p&gt;The backside of the Hemmi 153 has the $\theta$ angle scale in the range $[0¬∞, 90¬∞]$, the $P$ scale for computing $sin$, and the $Q$ scale for computing $cos$. The frontside has the $T$ scale for computing $tan$ and the $G_\theta$ scale for computing $gd(x)$. Using the $G_\theta$ scale and the $P$, $Q$, and $T$ scales of the Hemmi 153, we can compute all the hyperbolic functions. The $G_\theta$ scale, thus, expands the power of this slide rule by using the real estate for just one extra scale. I am of the opinion that the Hemmi 153 is one of those rare inventions that attained the design ideal of pragmatic minimalism.&lt;/p&gt;
    &lt;p&gt;To compute $sin(30¬∞)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;To compute $cos(60¬∞)$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;Note the asymmetry between the $sin$ and $cos$ procedures, above. This is a consequence of the $P$ and $Q$ scales‚Äô dual-use design: they are used to compute Pythagorean, but they also double as the $sin$ and $cos$ scales. It is, therefore, faster to compute $cos(60¬∞)$ as $sin(90¬∞ - 60¬∞)$.&lt;/p&gt;
    &lt;p&gt;Now, the cleverer bit: computing hyperbolic functions without various hyperbolic scales. To compute $sinh(0.5)$ using the identity $tan(gd(x)) = sinh(x)$ mentioned above, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;To compute $tanh(0.5)$ using the identity $sin(gd(x)) = tanh(x)$ mentioned above, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;When using the $T$ scale on the Hemmi 153 where the angle $\theta$ scale goes all the way up to $90¬∞$, it is important to recall that $tan(90¬∞) = ‚àû$.&lt;/p&gt;
    &lt;p&gt;The Hemmi 153 is marketed as a speciality electrical engineering slide rule. But it would be a crime not to include it in this article, due to its innovative $G_\theta$ scale-based hyperbolic function computations.&lt;/p&gt;
    &lt;p&gt;Hemmi 255D Expert Electrical Engineer‚ÄîAs the name suggests the Hemmi 255D is a newer, more advanced electrical engineering log-log vector duplex rule, compared to the older Hemmi 153. But whereas the Hemmi 153 uses the ingenious, but unconventional, $G_\theta$ scale to compute the hyperbolic functions via the trigonometric functions, the Hemmi 255D employs the more direct way to compute hyperbolic functions via the conventional $Sh$ and $Th$ scales. In terms of capabilities, the Hemmi 255D is comparable to other log-log vector duplex rules, like the Pickett N4-ES.&lt;/p&gt;
    &lt;p&gt;The Hemmi 255D is definitely a speciality electrical engineering rule. But it is also a general engineering vector slide rule, in the same category as the famous K&amp;amp;E 4083-3. So, I chose to include it in this article.&lt;/p&gt;
    &lt;p&gt;K&amp;amp;E 4181-1 Pocket Log Log Duplex Decitrig‚ÄîThe K&amp;amp;E 4181-1 is a miniature version of the K&amp;amp;E 4081-3. But whereas the K&amp;amp;E 4081-3 is made of wood, the K&amp;amp;E 4181-1 is made of plastic. And unlike the European plastics, the plastic of this slide rule feels cheap. See the full description in the K&amp;amp;E 4081-3 subsection, below.&lt;/p&gt;
    &lt;p&gt;K&amp;amp;E 4081-3 Log Log Duplex Decitrig‚ÄîThe K&amp;amp;E 4081-3 is the quintessential engineering slide rule. Its design is old and basic, but its implementation good and enduring. In a way, the K&amp;amp;E 4081-3 is the Ford Model T of engineering slide rules. It does have a few usability quirks, such as the $LL_1$ and $LL_{01}$ being relegated to the backside. But such compromises are inevitable, given the compactness of this slide rule.&lt;/p&gt;
    &lt;p&gt;This slide rule was the most popular slide rule in America. Although it is a very good slide rule, the wood core is easily damaged, when mistreated. And because they were inexpensive, many owners abused them. As such, many K&amp;amp;E 4081-3 slide rules being sold on eBay are warped, and hence are useless. Good ones do pop up every so often; so, be patient. The same admonishment applies to all wood rules, especially the very old ones made in the early 20th century or before.&lt;/p&gt;
    &lt;p&gt;K&amp;amp;E 68-1100 Deci-Lon 10‚ÄîThe K&amp;amp;E 68-1100 is one of the last, and most refined, engineering slide rules from K&amp;amp;E, designed to compete with late model German slide rules: Aristo 0969, FC 2/83 N, and Nester 0292. And like other newer K&amp;amp;E rules, the K&amp;amp;E 68-1100 is made of plastic that is on the cheap side, compared to the European plastics.&lt;/p&gt;
    &lt;p&gt;The odd feature of this slide rule is the asymmetric design: the lower frame is very narrow, the slide is quite wide, and the upper frame is unusually wide. The wide upper frame allows all four $LL_{0n}$ scales to fit on the frontside and on the backside all four $LL_n$ scales. This scale layout is much more convenient to use. But to those of us who are used to the common, symmetric design, the lopsided frame feels awkward in the hands. Many collectors admire this advanced engineering rule, but I am no fan of it.&lt;/p&gt;
    &lt;p&gt;K&amp;amp;E 4083-3 Log Log Duplex Vector‚ÄîHyperbolic functions are complex domain analogues of real domain trigonometric functions. Whereas trigonometric functions are defined using the unit circle, hyperbolic functions are defined using the hyperbola. Hyperbolic functions are popular with mechanical and civil engineers, who use it to compute the catenary of chains (or, heavy-duty power transmission lines)‚Äîthe sag that results when hanging a chain of a certain length from two equal-height posts.&lt;/p&gt;
    &lt;p&gt;The length and sag of a chain hung from two posts of equal height is expressed thus:&lt;/p&gt;
    &lt;p&gt;Here, $l$ is the length of the chain, $s$ is the sag, $w$ is the weight per unit length, $H$ is the tension at the lowest point, and $2b$ is the distance between the two posts. By the way, the world-famous Gateway Arch in St. Louis, Missouri, is a catenary arch, an inverted catenary curve.&lt;/p&gt;
    &lt;p&gt;Electrical power engineers use hyperbolic functions to compute impedances (and hence, voltages and currents, by Ohm‚Äôs law) on long-distant power transmission lines that stretch several hundred kilometres. Electrical engineers model the impedance of a long transmission line using the $\pi$ model, which represents the long cable as a series connection of short, individual segments, like a long chain made of small, individual links.&lt;/p&gt;
    &lt;p&gt;The K&amp;amp;E 4083-3 vector rule was one of the earliest advanced engineering slide rules with hyperbolic sine $Sh$ and hyperbolic tangent $Th$ scales. Electrical power engineering deals with electric motors, transmission lines, etc., and much of the work in this discipline involves vector calculus. The ‚Äúvector‚Äù designation of the K&amp;amp;E 4083-3 probably traces its origin to electrical power engineers‚Äô obsession with vector calculus and hyperbolic slide rules.&lt;/p&gt;
    &lt;p&gt;Catenary of chain and impedance of power line can be computed using the $C$, $D$, $CI$, $DI$, and other arithmetic scales in combination with $Sh$ and $Th$ hyperbolic scales, like those on the backside of the K&amp;amp;E 4083-3 vector rule.&lt;/p&gt;
    &lt;p&gt;However, since hyperbolic functions are related to exponential functions, an ordinary log-log duplex slide rule, like the K&amp;amp;E 4081-3, can compute hyperbolic functions using the following identities and the $LL$ scales, albeit rather tediously:&lt;/p&gt;
    &lt;p&gt;In the plot below, the blue curve is $sinh$, the green is $cosh$, and the red is $tanh$.&lt;/p&gt;
    &lt;p&gt;Logarex 27403-X Darmstadt‚ÄîThe Logarex 27403-X is a late model, simplex Darmstadt, with traditional Darmstadt scales on the frontside and three $LL_n$ scales on the backside of the slide. But whereas a traditional Darmstadt rule has a closed backside and cutouts at each end for reading the $LL_n$ scales, the backside of the Logarex 27403-X is open like a duplex rule and there are no cutouts with red indices. The black indices at each end of the frame permit reading only the $LL_1$ and $LL_3$ scales. But there is no way to read the $LL_2$ scale in the middle of the slide. The only way to use the $LL_n$ scales effectively is to flip the slide round to the front.&lt;/p&gt;
    &lt;p&gt;Flipping the backside of the slide round to the front is a common practice when using older Mannheim and Darmstadt rules. But it amounts to a design blunder on a modern duplex rule like the Logarex 27403-X. Of course, one could use a straight edge of a ruler or a piece of paper as a makeshift index for reading the $LL_2$ scale in the middle of the slide. The overall quality of the Logarex 27403-X is quite horrid: its plastic is about as good as a cheap soap dish.&lt;/p&gt;
    &lt;p&gt;Nestler 23 R/3 Rietz‚ÄîThe Nestler 23 R was favoured by very illustrious scientists and engineers, including Albert Einstein, Wernher von Braun, and Sergei Korolev. It is a conventional Rietz rule with a traditional Rietz scale layout. Perhaps it was this simplicity that attracted these greatest scientific minds of the 20th century.&lt;/p&gt;
    &lt;p&gt;Despite the fact that the Nestler 23 R is well loved, there is something subversively quirky about this slide rule. Being of the classic German simplex design, this slide rule is thick enough to have space on the top and bottom edges of the frame for additional scales. The Nestler 23 R has a 27-cm ruler scale on the top edge of the frame and the bottom edge of the frame is either blank or has a $1:25$ scale. The $1:25$ scale is 27.2 cm in length, and is divided linearly into 4-cm divisions. The name for this scale hints at $4 √ó 25 = 100$ cm, or 1 m. I do not think ruler scales belong on a slide rule; a slide rule is a fine instrument, not a common ruler.&lt;/p&gt;
    &lt;p&gt;Nestler 0210 Darmstadt‚ÄîThis slide rule is powerful in a minimalistic sort of way. The backside of the slide has the three $LL_n$ scales typical of Darmstadt rules, which are read through clear-plastic-covered cutouts. And given its classic German simplex proportions, the thick edges sport more scales. The top edge of the frame holds the 27-cm ruler scale and the $L$ scale. The bottom edge of the frame holds the $S$ and $T$ scales. This design is practical, logical, and compact. Of all the Nestler slide rules I own, the Nestler 0210 is my favourite.&lt;/p&gt;
    &lt;p&gt;Nestler 0292 Multimath-Duplex‚ÄîI like the appearance of Nestler slide rules for their understated elegance. Being a late model advanced log-log duplex engineering rule, the Nestler 0292 possesses the same computing capabilities as the top-of-the-line models from other manufacturers: Aristo 0969, FC 2/83 N, K&amp;amp;E 68-1100, Pickett N3-ES, et al. In my view, the Nester 0292 beats them all in both usability and beauty. No offence intended to those who admire the FC 2/83 N‚Äôs looks; indeed, I like that slide rule very well, only not as much as I like the Nestler 0292. Whereas the FC 2/83 N advertises its power, the Nestler 0292 expresses its power quietly. It is appreciably slimmer than the FC 2/83 N, so it feels more comfortable in the hand, especially for those of us who grew up on smaller rules, like the Aristo 0968. And it employs only one background colour, the pale green background, which covers both sides of the slide. I am of the opinion that the Nestler 0292 is an embodiment of the philosophy of engineering: elegant simplicity, effortless efficiency, quiet power.&lt;/p&gt;
    &lt;p&gt;Pickett N3-ES Power Log Exponential‚ÄîThe Pickett N3-ES is a late model log-log duplex engineering slide rule. Being constructed of aluminium, it is stabler and tougher than wood rules. Like its competitors, it has eight $LL$ scales. Pickett cleverly stacked the $LL_n$ and $LL_{0n}$ scales on the same line‚Äî$LL_0$-$LL_{00}$ stack, $LL_1$-$LL_{01}$ stack, and so on‚Äîthus yielding a logical, compact scale layout. But some may argue that stacked scales are more difficult to read. To each his own.&lt;/p&gt;
    &lt;p&gt;I quite like this stacked $LL$ scales layout. But I cannot countenance the economy feel and the impertinent colour of this slide rule. And it is significantly wider and weightier, compared to the late model German log-log duplex rules. In sum, the Pickett N3-ES is cheap and bulky, but stout and reliable.&lt;/p&gt;
    &lt;p&gt;Pickett N4-ES Vector Log Log Dual-Based Speed Rule‚ÄîThe Pickett N4-ES is the vectorised version of the Pickett N3-ES. As such, the Pickett N4-ES adds the hyperbolic $Sh$ and $Th$ scales. It is peculiar, though, that this slide rule labels its $LL$ scales from $LL_1$-$LL_{01}$ to $LL_4$-$LL_{04}$, instead of employing the more conventional scheme, which goes from $LL_0$-$LL_{00}$ to $LL_3$-$LL_{03}$. I dislike this slide rule, too.&lt;/p&gt;
    &lt;p&gt;Post 1447 Mannheim‚ÄîThe Post 1447 was an honest slide rule fit for innocent high schoolers of the day. It is of the traditional Mannheim simplex design. It has the usual $A$, $B$, $CI$, $C$, $D$, and $K$ scales on the frontside. The $S$, $L$, and $T$ scales are on the backside of the slide, which are read through the clear-plastic-covered cutouts on the backside of the frame.&lt;/p&gt;
    &lt;p&gt;Back in the day, fortunate middle schoolers and high schoolers learned to use the slide rule on a superb Mannheim rule, like the Post 1447. The cursed, though, had to settle for something vapid, like the Sterling Acumath 400.&lt;/p&gt;
    &lt;p&gt;Post 1461 Pocket Versalog II‚ÄîThe Post 1461 is a miniature version of the Post 1460. See the full description in the Post 1460 subsection, below.&lt;/p&gt;
    &lt;p&gt;Post 1460 Versalog II‚ÄîThe Post 1460 is a direct competitor, albeit a more refined one, to the K&amp;amp;E 4081-3 log-log duplex engineering slide rule. But in my view, the Post 1460 is superior, in terms of appearance, feel, durability, and usability. And it has four black-red pairs of $LL$ scales and the $R_1$-$R_2$ extended $\sqrt{x}$ scales. The Versalog II has a green $cos$ scale, but the original Versalog has a dark blue $cos$ scale.&lt;/p&gt;
    &lt;p&gt;My only objection to the design of the Post 1460 is its rather sharp edges. The rounded edges of the K&amp;amp;E 4081-3 feel more comfortable.&lt;/p&gt;
    &lt;p&gt;Reiss Darmstadt‚ÄîThis slide rule is a traditional Darmstadt rule, but it is made of aluminium. In terms of quality, this slide rule is as good as any European model, and is much better made than the Pickett aluminium rules. But it is quite solid; it weights almost as much as the Pickett N3-ES, despite being much slimmer. Because it is rather slim, the Reiss Darmstadt rule is more comfortable to handle. Still, I dislike its cold, sharp construction.&lt;/p&gt;
    &lt;p&gt;Reiss 3214 Darmstadt Record‚ÄîThe Reiss 3214 is a late model advanced Darmstadt rule. It feels as solid and smooth as other late model European rules. Its duplex design breaks with the Darmstadt tradition. But in keeping with the Darmstadt tradition, the backside of its slide has three $LL_n$ scales, and the frame is not adjustable. The Reiss 3214 is a decent plastic slide rule.&lt;/p&gt;
    &lt;p&gt;Breitling Montbrillant Datora‚ÄîThe Breitling Montbrillant Datora is a member of the Navitimer family of pilot‚Äôs watches. The $C$ scale is engraved on the rotating bezel and the $D$ scale is fixed to the watch face. The watch face also has indices for kph to mph conversion and nautical mile to statute mile conversion. As per the Navitimer tradition, this watch incorporates the chronograph function. And it adds the 24-hour sub-dial, and a complete calendar with day, date, and month indicators. The label ‚ÄúDatora‚Äù refers to this complete-calendar feature. And the label ‚ÄúMontbrillant‚Äù was a historical designation Breitling applied to some of their watch dials during the early 1920s.&lt;/p&gt;
    &lt;p&gt;Concise Model 300‚ÄîThe Concise 300 is a low-cost, compact, duplex circular rule. It uses pared-down Darmstadt scales, providing only $LL_2$ and $LL_3$. But it provides two $tan$ scales, $T_1$ and $T_2$. In terms of computing power, this slide rule is as capable as the FC 1/98 except, of course, it does not have the electrical engineering scales. The Concise 300 is held with the $1$ index mark pointing up, and is flipped left-to-right. For its price, this is a decent slide rule. But it does not stack up well against other Japanese-made slide rules, in terms of workmanship.&lt;/p&gt;
    &lt;p&gt;I purchased this Concise Model 300, new, straight from the Concise online store, many years ago. The quality of this new slide rule seems lower than the older ones I have seen, back in the day.&lt;/p&gt;
    &lt;p&gt;Dempster RotaRule Model AA‚ÄîThe Dempster RotaRule was designed and manufactured by John Dempster, a mechanical engineer, for use in engineering. Only about 2,500 units were made between 1928 and 1950, so it is a rare item. A clean, unmarred example like this one is even rarer. The Dempster RotaRule is undoubtedly the most desirable log-log duplex engineering circular rule. The phrase ‚Äúengineering circular rule‚Äù is an oxymoron, given that circular slide rules were a favourite of businessmen and most engineers disliked circular rules. But the Dempster RotaRule is a different kind of circular rule. It has all everything that engineers need: the trigonometric scales, the four $LL_n$ scales, and the Pythagorean $\sqrt{x^2 + y^2}$ scale. At about 13 cm in diameter, this slide rule is about the same size as the simplex FC 8/10. But unlike the FC 8/10‚Äôs sedate, single-cycle Rietz scales, the Dempster RotaRule has a 254-cm, quadruple-cycle $LL_n$ scale. And it even has a surveyor‚Äôs $Stadia$ scale and a financier‚Äôs $Monthly\ Interest$ scale, making it suitable for both technical and business uses. Because the outer portion of the disc (analogue of straight rule‚Äôs frame) is fixed and the inner portion (analogue of straight rule‚Äôs slide) rotates, the Dempster RotaRule needs only one cursor. And this cursor is well made to the point of being over engineered: it has a sturdy frame equipped with a friction lock, and the central hub has hole to plant a small, brass-framed magnifier that comes with the device. Somewhat unusually, the Dempster RotaRule places the trigonometric scales on the frontside. This slide rule is held with the $1$ index mark pointing down, and is flipped left-to-right. The all-important $LL_n$ scale is on the backside.&lt;/p&gt;
    &lt;p&gt;The Dempster RotaRule inspired the Boykin RotaRule Model 510, which is a proper engineering slide rule, with three $LL_n$ scales and three $LL_{0n}$ scales, comparable in capabilities to a top-of-the-line, log-log duplex engineering straight rule, like the K&amp;amp;E 4081-3, only much smaller and with far greater precision. Incidentally, Bernard Boykin, the designer of the fabulous Boykin circular slide rule, was my fellow engineer and a fellow Marylander, to boot. Alas, I do not own a Boykin circular rule.&lt;/p&gt;
    &lt;p&gt;FC 8/10‚ÄîThe FC 8/10 is a simplex circular rule with Rietz-equivalent scales. It uses aesthetically pleasing pale yellow and pale green backgrounds for some of the scales. I consider this slide rule one of the prettiest of all engineering tools. I liked the FC 8/10, not only for its beauty, but also because it was well made, accurate, inexpensive, unique, and compact. All the scales are engraved onto the exposed plastic face. The outer portion of the face is fixed to the body, and the rotatable inner portion of the face is operated using both thumbs, pushing against each other. And the cursor with the hairline rotates across the face over the scales.&lt;/p&gt;
    &lt;p&gt;As an engineering student in the early 1980s Burma, I used this FC 8/10; it was a hand-me-down from my engineer aunt. It was my favourite slide rule, and I used it daily for ordinary tasks. But when I needed the $LL$ scales, say for laboratory work and examinations, I used my other slide rule, the Aristo 0968 log-log duplex straight rule. In general, hopping among different slide rules is considered detrimental, since it robs one the opportunity to develop an intimate relation with a single device. But the FC 8/10 is a unique circular rule: it is just a straight rule in a circular guise. Despite being circular in shape, it operates on the same principles as the Rietz straight rule: the outer portion of the FC 8/10 is analogous to the frame of the straight rule, and the inner portion is analogous to the slide of the straight rule. And the circular shape of the device physically and visually highlights the wrap-around nature of the logarithmic scales. So, my flip-flopping between the FC 8/10 and the 0968 did not impact me, negatively.&lt;/p&gt;
    &lt;p&gt;Fowler‚Äôs Universal Calculator‚ÄîAt only about 8.5 cm in diameter, the Fowler‚Äôs Universal Calculator is perfectly sized for the hand. Etched into the glass cover is the fixed red hairline, aligned to the crown at 12 o‚Äôclock. Turning this crown clockwise rotates the face anticlockwise, and turning it anticlockwise rotates the face clockwise. This behaviour may feel weird at first, but it becomes natural with use. All the scales are etched onto this one-piece, rotating face. Turning the crown at 2 o‚Äôclock clockwise rotates the clear plastic cursor bearing the black hairline clockwise, and turning it anticlockwise rotates the cursor anticlockwise. The second crown behaves more naturally. It is odd, however, that this slide rule has no $x^2$ $A$ and $B$ scales, yet it has a very long, triple-cycle $\sqrt[3]{x}$ scale. Let us chalk it up to ‚Äúbusiness logic‚Äù.&lt;/p&gt;
    &lt;p&gt;Gilson Binary‚ÄîThe Gilson Binary is a cheaply-made, large, thin, aluminium disc of approximately 22 cm in diameter. Given its immense size, it is capable of very high precision calculations. And its two-arm cursor mechanism is quite clever. The frontside has $C$, $CI$, $A$, $K$, $L$, $LL_0$, $LL_1$, $LL_2$, $LL_3$, fraction multiplication and division scale, and millimetre to fractional-inch conversion scale pair. Engineers round the world have always deemed fractions to be annoyances, like a piece of food stuck between the teeth. But to American engineers of yore, fractions were their bread-and-butter. So, the Gilson Binary was a favourite tool of many an American engineer, decades ago. Thankfully, fractions are no longer a thing in American engineering today, although they still dominate factory floors, as do the Imperial measurement system. Depressing.&lt;/p&gt;
    &lt;p&gt;The Gilson Binary‚Äôs $C$ scale is over 60 cm in length. The range of the entire clockwise, quadruple-cycle $LL_n$ scale is an impressive $[1.0015, 10^6]$. So, chasing the mammoth $LL$ scale round the large face is a daunting task. To ease the pain, the tan-colour face is punctuated with bright yellow scale background rings: the $LL_0$ scale has tan background, the $LL_1$ scale has yellow background, and so on. That helps‚Äîsomewhat.&lt;/p&gt;
    &lt;p&gt;The ingenious part of the Gilson Binary is its two-armed cursor mechanism. The front face of this slide rule has two clear plastic cursors, one longer than the other. When the long cursor is moved, the short cursor also moves in lock step. But the short cursor can be moved independently of the long cursor. Suffice it to say the Gilson Binary‚Äôs design is unique. Without the aid of a manual, even experienced straight rule users would be hard pressed to figure out how properly to use it. But once its quirks have been discovered, it is just as simple to use as a straight rule. Note, also, that the Gilson Binary‚Äôs two-cursor configuration requires only one logarithmic scale $C$. Hence, there is no need to allocate space for the $D$ scale.&lt;/p&gt;
    &lt;p&gt;Ordinarily, computations begin with setting the long cursor hairline on the $1$ on the $C$ scale, and end with reading under the short cursor hairline on the appropriate scale. The short cursor is analogous to the slide of a straight rule.&lt;/p&gt;
    &lt;p&gt;To compute $2 √ó 3$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;To compute $1.03^{2.4}$, we manipulate the slide rule as follows:&lt;/p&gt;
    &lt;p&gt;The Gilson Binary is held with the $1$ index mark pointing up, and is flipped left-to-right. As I said above, it is a rather unusual slide rule. The unusual design elements continue on the back face. The backside cursor is a one-arm variety. For instance, unlike a typical slide rule, the Gilson Binary has two opposing $Degree$ scales, one running clockwise and the other anticlockwise. These degree scales are split into three cycles, each spanning $30¬∞$. Stacked atop the degree scales are the clockwise, triple-cycle $T$ scales. The $Degree$-$T$ scale pair is interlaced with the clockwise, triple-cycle $S$ scales. And note that since the $Degree$ scale‚Äôs range is $[0¬∞, 90¬∞]$, one must use care to avoid reading a nonsensical value like $tan(90¬∞) = ‚àû$.&lt;/p&gt;
    &lt;p&gt;American slide rule manufacturers, like most American engineers of that era, had a hostile attitude toward users in general and toward usability in particular, mistakenly believing that smart, trained people‚Äîlike engineers‚Äîshould be able to cope with complexity. This attitude is prominently on display in the design of the Gilson Binary. This slide rule would be far more pleasant to use, had the subtle background colours‚Äîgreen, blue, and yellow, like those found on the FC 8/10‚Äîbeen used, instead of the hypnotic yellow rings. Yes, it is unfair to compare the 1930s Gilson with the 1970s Faber-Castell. But it is eminently fair to compare the American Gilson to its German contemporaries, like the FC 1/54 and the Nestler 23 R. There, too, the Gilson design falls woefully short, in terms of aesthetics and usability.&lt;/p&gt;
    &lt;p&gt;One more thing. There is a usability quirk common to all circular rules: to bring the upside-down scales into correct, upright orientation, the body of the circular rule must be spun round. This is easy enough for smaller circular rules, like the Dempster RotaRule, the FC 8/10, or the Fowler‚Äôs Universal Calculator; one simply spins the holding hand‚Äîwithout shifting the grip‚Äîthereby retaining the anchor point on the scale. But for a big circular rule, like the Gilson Binary, it is often necessary to use both hands to spin the rule, thus necessitating shifting of the grip and losing the anchor point on the scale. The long, spiral scales of the Gilson Binary exacerbate this problem. This is where usability-improving features, such as the German rules‚Äô coloured scale backgrounds, could have made the Gilson Binary (and its many imitators) far more user friendly.&lt;/p&gt;
    &lt;p&gt;Kontrolpribor Model KL-1‚ÄîThe Kontrolpribor KL-1 is a pocket watch type duplex circular rule. It is about the size of a wristwatch. The front and back faces are covered with cheap plastic. Because the plastic covers are domed, they are prone to scratching. The black-dotted crown at 12 o‚Äôclock rotates the face and the red-dotted one at 2 o‚Äôclock rotates the needle. The frontside has 15-cm long $C$ and $A$ scales. The backside has circular $C$ and $S$ scales and a spiral $T$ scale. This slide rule is comparable in computing power to a pocket Mannheim straight rule. The Kontrolpribor KL-1 is held with the black-dotted crown pointing up, and is flipped left-to-right. The backside has the $C$ scale, the circular $S\ [5.5¬∞, 90¬∞]$ scale, and the spiral $T\ [1¬∞, 45¬∞]$ scale. This scale layout is quite unique.&lt;/p&gt;
    &lt;p&gt;Compared to the Fowler‚Äôs Universal Calculator, this slide rule is but a cheap toy. Yet, it is much more powerful than the Breitling Navitimer, a very expensive toy.&lt;/p&gt;
    &lt;p&gt;Loga 30 Tt‚ÄîThe enviable Swiss craftsmanship is evident in the Loga 30 Tt: accurate, sturdy, elegant. Being a Darmstadt-equivalent model, it is one of the more powerful circular rules. Like other high-end circular rules, the outer portion of the front face is fixed to the frame and the inner portion rotates. The frontside cursor bisects the front face that holds a double-cycle, stacked $\sqrt{x}$ scale and the usual Darmstadt scales. The $\sqrt{x}$ scale is the inverse of the $x^2$ scales ordinarily labelled $A$ and $B$. On this slide rule, though, the $C$ and $D$ scales are confusingly labelled $A$ and $B$. Another quirk of the Loga 30 Tt is that it is intended to be flipped by holding it between the right thumb and forefinger at 3 o‚Äôclock. If it were flipped left-to-right, the $1$ index mark would point to the right instead of straight up. The entire back face is fixed to the frame, and holds the $S$, $T$, $ST$, and the three $LL_n$ scales. The end of the backside cursor protrudes beyond the disc. The clever bit is that the back cursor is attached to the inner rotating portion of the front face, and the cursor‚Äôs protruding end serves as the handle that rotates the inner front face. A small, rotatable, black disc is mounted to the backside hub. This disc is meant to be used as the handle, when computing with the frontside scales. In terms of capability and quality, the Loga 30 Tt is on par with high-end Darmstadt straight rules, like BRL D.26, FC 1/54, and Nestler 0210. I rather fancy the Loga 30 Tt.&lt;/p&gt;
    &lt;p&gt;Pickett 101-C Dial Rule‚ÄîThe Pickett 101-C is a low-end circular rule. The body is a cheap, thin aluminium disc, not unlike the Gilson Binary. Being a rather small disc, there is space for only two $LL_n$ scales. The ranges are notable, though: $LL_1 ‚àà [1.15, 4.0]$ and $LL_2 ‚àà [4, 10^6]$. And like other low-end, American circular rules of that era, this slide rule has a fraction scale. Indeed, the Pickett 101-C is essentially a miniature version of the Gilson Binary, except for the much shorter $LL_n$ scale. This slide rule is held with the $1$ index mark pointing up, and is flipped bottom-to-top, like a straight rule.&lt;/p&gt;
    &lt;p&gt;Pickett 111-ES‚ÄîUnlike other Pickett rules, which are made in America, the Pickett 111-ES is made in Japan. And although it has an aluminium core, the metal edges are rounded off and the faces are covered in high-quality Japanese plastic. It is a pleasant rule to use, despite its eye-gouging yellow. The Pickett 111-ES is held with the $1$ index mark pointing down, and flipped left-to-right. This slide rule is a log-log duplex advanced engineering circular rule with eight $LL$ scales, a rarity among circular rules. In fact, it is more capable than the venerable Dempster RotaRule‚Äîa sacrilegious! This slide rule employs Pickett‚Äôs stacked layout for the $LL$ scales. But whereas the Pickett N3-ES stacks $LL_n$ and $LL_{0n}$ on the same line, the Pickett 111-ES stacks the adjacent $LL$ scales: the $LL_0$-$LL_1$ stack and the $LL_2$-$LL_3$ stack are on the frontside, and the $LL_{00}$-$LL_{01}$ stack and the $LL_{02}$-$LL_{03}$ stack are on the backside. The backside also holds a double-cycle $S$ scale, a triple-cycle $T$ scale, and a single-cycle $ST$ scale.&lt;/p&gt;
    &lt;p&gt;The capabilities of the Pickett 111-ES compare well against top-of-the-line engineering straight rules, like Aristo 0969, FC 2/83 N, Nestler 0292, K&amp;amp;E 68-1100, Pickett N3-ES, and others. And similar in design to other high-end circular rules, like the Dempster RotaRule, the outer portion is fixed, the inner portion rotates, and the duplex cursor is firm but glides smoothly. I am no fan of Pickett slide rules, but I really like the Pickett 111-ES.&lt;/p&gt;
    &lt;p&gt;Otis King Model K‚ÄîOtis King cylindrical slide rules use helical scales. The Model K is unusual in that it uses a double-cycle $C$ scale, thus, can perform chained calculations without the need to reset the cursor, as is necessary with the Model L, described below, which has a normal, single-cycle $C$ scale. But the Model K is limited, capability wise: it could compute only $√ó$ and $√∑$.&lt;/p&gt;
    &lt;p&gt;To use the Model K, one holds the chrome handle in one hand and, with the free hand, pulls out the top, thereby exposing the helical logarithmic scales. The black cylinder in the middle, which is operated with the free hand, is the equivalent of the straight rule‚Äôs cursor. It is engraved with two white index marks which are aligned to each other. These indices are equivalent of a straight rule‚Äôs cursor hairline. The upper cylinder, which holds the $C$ scale can shift up and down along the longitudinal axis, and it can also spin about that axis independently of the fixed $D$ scale on the lower cylinder. The back-facing numbers on the $D$ scale can be brought into view by spinning the chrome handle. And the black cylinder can shift and spin independently of both the upper and the lower scales. So, the Model K‚Äôs fixed lower cylinder is equivalent to the frame of the straight rule and the movable upper cylinder is equivalent to the slide of the straight rule.&lt;/p&gt;
    &lt;p&gt;Otis King Model L‚ÄîThe Model L is identical in construction and operation to the Model K. These two slide rules have a $D$ scale that is almost the same length. But the Model L‚Äôs upper cylinder is occupied by the single-cycle $C$ scale and the $L$ scale. The Model L could compute $√ó$, $√∑$, $log$, and $log^{-1}$.&lt;/p&gt;
    &lt;p&gt;I have endeavoured to give a thorough enough explanation in this article on how the slide rule works, how it was used, and how it came to be. But this article will not make the reader an expert user of an advanced engineering slide rule; that is the domain of the user‚Äôs manuals. I have also emphasised the necessity of engaging the mind, when using a slide rule. And I have demonstrated the extent to which some very simple mathematical functions, like $log$, $ln$, $sin$, $tan$, etc., were put to use to solve substantial problems in engineering.&lt;/p&gt;
    &lt;p&gt;Ingenuity is the ability to make useful things inexpensively on a massive scale by composing simple, but innovative, ideas in reliable, repeatable ways. And that is what engineering is. The slide rule, both as a tool for engineering and as a product of engineering, epitomised this philosophy in its day. The slide rule was born when necessity and ingenuity coincided at a crucial point in history, and it accelerated the technological development of humanity. Over its almost four-century reign, it enabled us to cross the oceans, it empowered us to span the continents, it took us to the Moon. The slide rules deserves remembrance, respect, reverence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://amenzwa.github.io/stem/ComputingHistory/HowSlideRulesWork/"/><published>2025-11-19T21:07:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45985506</id><title>Screw it, I'm installing Linux</title><updated>2025-11-19T23:10:06.722106+00:00</updated><content>&lt;doc fingerprint="1e1b385fdf96b4dc"&gt;
  &lt;main&gt;
    &lt;p&gt;This time I‚Äôm really going to do it. I am going to put Linux on my gaming PC. Calling it now. 2026 is the year of Linux on the desktop. Or at least on mine.&lt;/p&gt;
    &lt;head rend="h1"&gt;Screw it, I‚Äôm installing Linux&lt;/head&gt;
    &lt;p&gt;I don‚Äôt like where Windows is going. Gaming on Linux has never been more approachable. Time to give it a shot.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt like where Windows is going. Gaming on Linux has never been more approachable. Time to give it a shot.&lt;/p&gt;
    &lt;p&gt;Linux has been a perfectly viable desktop OS for ages. But gaming on Linux is now viable, too. Valve‚Äôs hard work getting Windows games to run well on the Linux-based Steam Deck has lifted all boats. Gaming handhelds that ship with Windows run better and have higher frame rates on Bazzite, a Fedora-based distro, than they do with Windows. And after reading about the upcoming Steam Machine and Antonio‚Äôs experience running Bazzite on the Framework Desktop, I want to try it.&lt;/p&gt;
    &lt;p&gt;To be clear, my desktop works fine on Windows 11. But the general ratio of cool new features to egregious bullshit is low. I do not want to talk to my computer. I do not want to use OneDrive. I‚Äôm sure as hell not going to use Recall. I am tired of Windows trying to get me to use Edge, Edge trying to get me to use Bing, and everything trying to get me to use Copilot. I paid for an Office 365 subscription so I could edit Excel files. Then Office 365 turned into Copilot 365, and I tried to use it to open a Word document and it didn‚Äôt know how.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Microsoft is ending support for Windows 10, including security updates, forcing people to buy new hardware or live with the risks. It‚Äôs disabling workarounds that let you set up Windows 11 with a local account or with older hardware. It‚Äôs turning Xboxes into PCs and PCs into upsells for its other businesses. Just this week, the company announced that it‚Äôs putting AI agents in the taskbar to turn Windows into a ‚Äúcanvas for AI.‚Äù I do not think Windows is going to be a better operating system in a year, so it feels like a good time to try Linux again.&lt;/p&gt;
    &lt;p&gt;I‚Äôm not normally one to change frogs midstream, but the water sure is getting hot.&lt;/p&gt;
    &lt;p&gt;That‚Äôs not to say I know what I‚Äôm doing. I‚Äôve used Macs for a decade for work, and I dabbled in Ubuntu 20-something years ago, but otherwise I‚Äôve been a Windows guy since 3.1. At first, that‚Äôs because it‚Äôs what we had at home, later because that‚Äôs where the games were, and finally out of force of habit (and because that‚Äôs where the games were). I brought a desktop to college instead of a laptop (so I could play games), and I‚Äôve been building my own PCs for 18 years. I started my journalism career at Maximum PC magazine, testing gaming PC components.&lt;/p&gt;
    &lt;p&gt;I try to stay familiar with all the major operating systems because of my job, so in addition to my work MacBook I also have a Chromebook, a ThinkPad, and a collection of older hardware I refuse to get rid of. I can work pretty well in Windows, in macOS, or in ChromeOS.&lt;/p&gt;
    &lt;p&gt;My experiences with Linux over the past decade, on the other hand, have largely been as a series of extremely optional Tasks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Trying to set up Homebridge on a Raspberry Pi. It sort of worked but was stymied by my home network setup, and I eventually replaced it with Home Assistant.&lt;/item&gt;
      &lt;item&gt;Setting up a Beepy, a kind of a bootleg Linux handheld with a tiny monochrome screen and a BlackBerry keyboard. This took longer than I wanted, but it worked in the end, and I learned that using a command-line interface with a BlackBerry keyboard on a tiny monochrome screen is my version of hell.&lt;/item&gt;
      &lt;item&gt;Running a Linux VM on my Chromebook so I could use Obsidian, my preferred note-taking app, which doesn‚Äôt have a web interface. This was a pleasant experience and I have no complaints.&lt;/item&gt;
      &lt;item&gt;[deep breath] Setting up three different virtual machines using the Windows Subsystem for Linux so I could build keyboard firmware: one for QMK, one for ZMK, and I think the third was because the first QMK one stopped working. All of these were on my old desktop, on which the entire Linux subsystem somehow broke beyond repair.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of those projects, except the Chromebook one, took longer than expected, and cut into my vanishingly rare discretionary time. That‚Äôs also the time I use for gaming, reading, staring into the void, and half-starting organizational projects, so you can see how precious it is to me.&lt;/p&gt;
    &lt;p&gt;The prospect of instead using that time trying to get my computer back to a baseline level of functionality ‚Äî that is, as useful as it was before I tried installing Linux ‚Äî is tempting, but it‚Äôs also why I haven‚Äôt done it yet.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a good time to try gaming on Linux. Antonio and Sean have been having fun with Bazzite, a Linux distro that mimics SteamOS; my friend and former colleague Will Smith is cohosting a PCWorld podcast called Dual Boot Diaries with this exact premise.&lt;/p&gt;
    &lt;p&gt;And what better device to try it on than my personal desktop with an AMD Ryzen 7 9800X3D processor and Nvidia GeForce RTX 4070 Super graphics card? I just rebuilt this thing. The Windows install is only like six months old. It‚Äôs working about as well as Windows does.&lt;/p&gt;
    &lt;p&gt;So really, why wouldn‚Äôt I blow that up and start over?&lt;/p&gt;
    &lt;p&gt;Based on listening to two and a half episodes of Dual Boot Diaries and a brief text conversation with Will, I‚Äôm going to install CachyOS, an Arch-based distro optimized for gaming on modern hardware, with support for cutting-edge CPUs and GPUs and an allegedly easy setup.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt expect things to go smoothly. I don‚Äôt really know what I‚Äôm doing, and Linux is still a very small percentage of the PC gaming world. As of the most recent Steam Hardware &amp;amp; Software Survey ‚Äî the best proxy we have for PC gaming hardware info as a whole ‚Äî just over 3 percent of Steam users are running Linux. Of those, 27 percent are using SteamOS (and therefore a Steam Deck), 10 percent are using Arch, 6 percent are using CachyOS, 4 percent are using Bazzite, and the rest are split over a bunch of distros.&lt;/p&gt;
    &lt;p&gt;So if anything goes wrong in my install, it‚Äôll be a lot of forum-hopping and Discord searching to figure it all out. But I‚Äôve cleverly arranged it so the stakes are only medium: I have other machines to work on while my desktop is inevitably borked (and to run programs like Adobe Creative Suite), and if I end up spending hours of my discretionary time learning Linux instead of gaming, well, that‚Äôs not the worst outcome.&lt;/p&gt;
    &lt;p&gt;Maybe it‚Äôll all go smoothly and I‚Äôll report back in a few weeks, another prophet of the revolution. Maybe it‚Äôll go terribly and I‚Äôll come crawling back. Only one way to find out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/tech/823337/switching-linux-gaming-desktop-cachyos"/><published>2025-11-19T21:30:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45985867</id><title>It's your fault my laptop knows where I am</title><updated>2025-11-19T23:10:06.567582+00:00</updated><content>&lt;doc fingerprint="b5288b17995722c8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;#Attendance&lt;/head&gt;
    &lt;p&gt;I‚Äôm in Introduction to Algorithms (577) this semester at UW, and I‚Äôve been enjoying hearing Renault explaining how to prove program correctness, DP, network flow, and the circumstances under which Dijkstra invented his shortest-path algorithm.&lt;/p&gt;
    &lt;p&gt;However‚Ä¶ algos is a somewhat unique class for me, given that it‚Äôs the first course I‚Äôve taken that mandates being present during lectures by taking attendance. It accomplishes this through a platform called TopHat, who many students will recognize through its use of displaying participation questions.&lt;/p&gt;
    &lt;p&gt;TopHat asks you to provide it a four-length numerical code (that‚Äôll be provided to you by your lecturer) in order to verify that you‚Äôre actually in the location where the attendance is being taken. You type that code into the student TopHat page, and, bam, you‚Äôre marked present.&lt;/p&gt;
    &lt;p&gt;However, I suppose they caught on to the unpatchable strategy of Having Friends, who, given that they are in the same class section as you, can be sent messages begging for the code from the comfort of your bed.&lt;/p&gt;
    &lt;p&gt;So, for the paranoid lecturer, TopHat allows ‚Äúsecure attendance‚Äù, a feature which, according to them, determines your location as ‚Äú‚Ä¶determined by [your] device geolocation or by both geolocation and proximity (to the classroom and other students).‚Äù&lt;/p&gt;
    &lt;p&gt;The first time I heard about this system, I wondered how much leeway this ‚Äúgeolocation‚Äù would afford you. There exist a plethora of traditional ‚ÄúIP geolocation‚Äù services, which use your IP address and ASN ‚Äî both semi-unique identifiers sent to the webpage upon load ‚Äî to try and identify your location. This provides‚Ä¶ varied results depending on where you‚Äôre located. When in Madison and NYC, popular IP geolocation services have been able to pin me within a mile or so of my actual location. In any suburban area, the error jumps to city-level.1 Surely TopHat wouldn‚Äôt be relying on such an inaccurate measure of detecting location when determining attendance ‚Äî students living in Chadbourne Hall taking lectures in Mosse Humanities (approx. 250ft apart) would be able to skirt the attendance requirement. That could be catastrophic!&lt;/p&gt;
    &lt;head rend="h2"&gt;#The Geolocation API&lt;/head&gt;
    &lt;p&gt;Alas, it is not IP geolocation being used by TopHat. As aforementioned, IP geolocation is a pretty implicit flow ‚Äî webpages are able to see your IP when you connect to them. However, when trying to determine your location, TopHat pops up a big scary dialogue past the line of death!&lt;/p&gt;
    &lt;p&gt;Clearly this is asking something else entirely ‚Äî something that‚Äôs presumably so precise as to require my explicit consent.&lt;/p&gt;
    &lt;p&gt;I‚Äôll spare you the suspense. This is the Geolocation API, a feature of all modern browsers that allows the retrieval of your location to a much more precise degree (hence the permission pop-up). As of writing this post, IP geolocation is enough to place me somewhere in the Lakeshore neighborhood of Madison (1-2 miles long), but Chrome‚Äôs Geolocation API is enough to pin me to the exact building ‚Äî Morgridge Hall ‚Äî I‚Äôm sitting in. That‚Äôs orders of magnitude more accurate.&lt;/p&gt;
    &lt;p&gt;When I first experienced my laptop doing this, my first thought was ‚ÄúHow?‚Äù There‚Äôs nothing special that my laptop has access to that would somehow allow my browser to have a more specific location‚Ä¶ right? My laptop doesn‚Äôt have a GPS receiver in it2 that would allow location identification in the same way that phones can (and it isn‚Äôt just piggybacking off of my phone‚Äôs GPS, since this same location API is available on Windows devices).&lt;/p&gt;
    &lt;head rend="h3"&gt;#It‚Äôs all of our faults&lt;/head&gt;
    &lt;p&gt;When you press ‚Äúallow‚Äù on the popup, your browser uses an accuracy heuristic to determine which method fetches the most accurate location. While this could be GPS (if on a cellular-enabled device) or the aforementioned IP geolocation, it will most likely have the highest success with the Wi-Fi Positioning System, a strategy that uses the wireless access points around you to identify your location.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how it works. After allowing your browser permission to access your location, a website has access to the &lt;code&gt;getCurrentPosition()&lt;/code&gt; function. When calling it, your browser kindly asks your operating system for a list of the surrounding Wi-Fi access points ‚Äî more specifically, their signal strength, SSIDs, and BSSIDs.&lt;/p&gt;
    &lt;p&gt;If those last two are foreign to you, the ‚ÄúSSID‚Äù of a network is just the friendly name ‚Äî for example, &lt;code&gt;UWNet&lt;/code&gt; or &lt;code&gt;eduroam&lt;/code&gt;. The BSSID is the MAC address of the access point, which is unique per each device. Having a unique identifier per access point is immensely important, as you can imagine just how many APs are named the same thing. Take a look at the map of APs around campus named &lt;code&gt;UWNet&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Okay, so, great. We now know exactly which Wi-Fi network you‚Äôre connected to. But how does this translate to your location on a map? And how do we even know where these networks are in the real world?&lt;/p&gt;
    &lt;head rend="h3"&gt;#Wardriving&lt;/head&gt;
    &lt;p&gt;The notion of associating Wi-Fi networks with their physical locations has been prevalent since the early 2000s. As far as I can tell, Skyhook Wireless were the first to do it on a commercially-available scale, using a technique known as wardriving. This entails getting in a vehicle and driving around while capturing the information of as many Wi-Fi networks as possible. Since the devices doing the network scanning also have a reliable knowledge of their position (through GPS), all you have to do is associate the location of where you saw the network with its signal strength. Some RSSI trilateration later, and you have a roughly accurate map of Wi-Fi networks you‚Äôve seen and their corresponding physical locations.&lt;/p&gt;
    &lt;p&gt;The useful thing is that, once in possession of all of this data, you can perform the process in reverse ‚Äî on a user‚Äôs device, send a list of the Wi-Fi networks you can see (and their corresponding RSSI), and receive an approximate guess on where that places your device in the world. For a while, that‚Äôs what everyone‚Äôs devices (including Apple ones, until iOS 3.2) did, relying on either Skyhook‚Äôs or Google‚Äôs privately collected list. The latter, interestingly enough, used their Street View vehicles (the ones taking images of roads) to capture the Wi-Fi information for a while.&lt;/p&gt;
    &lt;p&gt;However, at some point, companies realized the potential benefit of sourcing this information from the users of their devices. After all, they‚Äôre already frequently checking their GPS location and phoning home to cell towers, so why not send some anonymized Wi-Fi location data along with it?&lt;/p&gt;
    &lt;p&gt;So, that‚Äôs what Apple, Google, and Microsoft devices began doing. The location services of their products, by default, started aggregating the SSIDs and BSSIDs of Wi-Fi hotspots they could see (and their locations) and logging them for others‚Äô devices to use for more accurate location services. And‚Ä¶ that‚Äôs more or less the same thing that modern devices use today. When Chrome tells me that a website would like to use my location, and I allow it, the list of the surrounding hotspots will be sent to Google ‚Äî which, because tens of thousands of people with GPS-enabled devices have also pinged the networks, allows my computer to obtain an extremely accurate estimation on where I am. So, thank you, everybody‚Ä¶?&lt;/p&gt;
    &lt;head rend="h2"&gt;#Controversy&lt;/head&gt;
    &lt;p&gt;If you were feeling a little nervous about the idea of your phone aggregating and sharing the location and information of every Wi-Fi network you‚Äôve ever interacted with in your entire life, don‚Äôt worry, you‚Äôre not alone! There have been plenty of historical incidents with abuses of the technology.&lt;/p&gt;
    &lt;p&gt;Starting with a tough one: remember how earlier (in wardriving) I mentioned that Google historically used their Street View cars to obtain network information for their location services? It turns out that they were sniffing much more than just the headers of the packets ‚Äî they were aggregating the raw 802.11 Wi-Fi data frames, which includes the non-encrypted payload of HTTP packets. I assume that very little of the internet was using HTTPS in 2010, so the reported 600 gigabytes worth of data they obtained definitely contained some things that users would probably rather them not see.&lt;/p&gt;
    &lt;p&gt;A larger and more pertinent concern tends to crop up with regards to the possibility of tracing someone‚Äôs location ‚Äî which is valid, given its sensitivity. This has been a worry since WPS‚Äô inception, but one older example I found was Elie Bursztein et al.‚Äôs talk and accompanying blog post ‚ÄúUsing the microsoft geolocalization api to retrace where a windows laptop has been‚Äù. At the time, there was a bug where Windows would save a persistent record of every MAC address that you connected to, making it possible to retrace someone‚Äôs steps (thus, tracking their location as it changed) using one of numerous location APIs live at the time.&lt;/p&gt;
    &lt;p&gt;These vulnerabilities are even seen in contemporary times ‚Äî Erik Rye and Dave Levin of the University of Maryland wrote ‚ÄúSurveilling the Masses with Wi-Fi-Based Positioning Systems‚Äù in 2024, detailing a flaw in Apple‚Äôs location services that allowed them to exfiltrate the positions of nearly two billion BSSIDs by cleverly filtering the MAC address space they were searching. Their paper‚Äôs great, and it touches on some real dangers possible from the information in the hands of an adversary, such as stalking individuals by continuously locating their router BSSID, or monitoring population density during wartime by observing the movement of groups of devices (and satellite internet constellations like Starlink).&lt;/p&gt;
    &lt;p&gt;Over time, the location service providers have improved the security of the APIs they develop. This is supremely important given the risks we‚Äôve discussed, especially given that nearly every device created by these companies are, by default3, sending this information to their manufacturers. Nearly every company that participates in WPS allows you to opt your BSSID out ‚Äî either by changing the name of your SSID or by specifying the MAC address in a form somewhere:&lt;/p&gt;
    &lt;p&gt;Apple‚Äôs instructional opt out page (appending &lt;code&gt;_nomap&lt;/code&gt;) to the SSID.&lt;/p&gt;
    &lt;p&gt;Google‚Äôs page, which offers the same advice.&lt;/p&gt;
    &lt;p&gt;Microsoft‚Äôs form, requiring a BSSID submission to opt out.&lt;/p&gt;
    &lt;head rend="h2"&gt;#Conclusion&lt;/head&gt;
    &lt;p&gt;If I didn‚Äôt mention it yet, this technology does have a name. It‚Äôs called the Wi-Fi positioning system (WPS). There‚Äôs still a vibrant community of Wi-Fi positioning enthusiasts out there ‚Äî https://wigle.net/ is a crowd-sourced database from recreational wardrivers who have contributed nearly two billion networks over the last 25 years. You can zoom in on your town and see the Wi-Fi density near you, and you can even check if your own network has been tagged by someone else!&lt;/p&gt;
    &lt;p&gt;I‚Äôd also be remiss if I didn‚Äôt mention https://beacondb.net/, a self described ‚Äúpublic domain wireless geolocation database‚Äù, which, while I haven‚Äôt had time to play with, sounds like a very promising open version of the trackers so commonly used nowadays. While it doesn‚Äôt have as dense of a database as any of the other providers, I actually think it‚Äôs neat to have a lack of homogeneity among the smaller providers ‚Äî it shows the data is truly different!&lt;/p&gt;
    &lt;p&gt;It‚Äôs been really fun diving down this rabbit hole to learn how our devices gain access to our location. It‚Äôs one of the more niche things that I‚Äôve taken for granted when using my devices, and it certainly didn‚Äôt occur to me that, while in lecture, the only reason I could be marked present was because thousands of other students had (without their knowledge) pinged servers all over the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;#Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;This conclusion ‚Äî ‚Äúerror rates scale based on living settlement density‚Äù is my personal conjecture. It is surprisingly frustrating just exactly how little information there is online about how these services attempt to pin your location from just your IP address. Wikipedia has an article about IP geolocation, but it‚Äôs vague when discussing the actual implementation details‚Ä¶ ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Small digression: did you know that, until May 2000, GPS satellites (which are owned and operated by the United States Space Force) provided the general public a signal with intentional error built into it? This was called Selective Availability, and it augmented the position of GPS readings by about 50 meters (162 feet) horizontally. It was shut off for a number of reasons ‚Äî one of which being that Differential GPS allows you to circumvent the distortion trivially by comparing the error of the signal against the location of a reference station with a known position. ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It‚Äôs associated with ‚ÄúLocation Services‚Äù on most devices, meaning that you cannot opt out of your phone reporting the locations of surrounding Wi-Fi devices without turning off your phone‚Äôs ability to obtain its location entirely. ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.amoses.dev/blog/wifi-location/"/><published>2025-11-19T21:58:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45985890</id><title>The patent office is about to make bad patents untouchable</title><updated>2025-11-19T23:10:06.308869+00:00</updated><content>&lt;doc fingerprint="ee1cd31b9b1d06bf"&gt;
  &lt;main&gt;
    &lt;p&gt;The U.S. Patent and Trademark Office (USPTO) has proposed new rules that would effectively end the public‚Äôs ability to challenge improperly granted patents at their source‚Äîthe Patent Office itself. If these rules take effect, they will hand patent trolls exactly what they‚Äôve been chasing for years: a way to keep bad patents alive and out of reach. People targeted with troll lawsuits will be left with almost no realistic or affordable way to defend themselves.&lt;/p&gt;
    &lt;p&gt;We need EFF supporters to file public comments opposing these rules right away. The deadline for public comments is December 2. The USPTO is moving quickly, and staying silent will only help those who profit from abusive patents.&lt;/p&gt;
    &lt;p&gt;Tell USPTO: The public has a right to challenge bad patents&lt;/p&gt;
    &lt;p&gt;We‚Äôre asking supporters who care about a fair patent system to file comments using the federal government‚Äôs public comment system. Your comments don‚Äôt need to be long, or use legal or technical vocabulary. The important thing is that everyday users and creators of technology have the chance to speak up, and be counted.&lt;/p&gt;
    &lt;p&gt;Below is a short, simple comment you can copy and paste. Your comment will carry more weight if you add a personal sentence or two of your own. Please note that comments should be submitted under your real name and will become part of the public record.&lt;/p&gt;
    &lt;p&gt;Sample comment:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I oppose the USPTO‚Äôs proposed rule changes for inter partes review (IPR), Docket No. PTO-P-2025-0025. The IPR process must remain open and fair. Patent challenges should be decided on their merits, not shut out because of legal activity elsewhere. These rules would make it nearly impossible for the public to challenge bad patents, and that will harm innovation and everyday technology users.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Why This Rule Change Matters&lt;/head&gt;
    &lt;p&gt;Inter partes review, (IPR), isn‚Äôt perfect. It hasn‚Äôt eliminated patent trolling, and it‚Äôs not available in every case. But it is one of the few practical ways for ordinary developers, small companies, nonprofits, and creators to challenge a bad patent without spending millions of dollars in federal court. That‚Äôs why patent trolls hate it‚Äîand why the USPTO‚Äôs new rules are so dangerous.&lt;/p&gt;
    &lt;p&gt;IPR isn‚Äôt easy or cheap, but compared to years of litigation, it‚Äôs a lifeline. When the system works, it removes bogus patents from the table for everyone, not just the target of a single lawsuit.&lt;/p&gt;
    &lt;p&gt;IPR petitions are decided by the Patent Trial and Appeal Board (PTAB), a panel of specialized administrative judges inside the USPTO. Congress designed IPR to provide a fresh, expert look at whether a patent should have been granted in the first place‚Äîespecially when strong prior art surfaces. Unlike full federal trials, PTAB review is faster, more technical, and actually accessible to small companies, developers, and public-interest groups.&lt;/p&gt;
    &lt;p&gt;Here are three real examples of how IPR protected the public:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The ‚ÄúPodcasting Patent‚Äù (Personal Audio)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Personal Audio claimed it had ‚Äúinvented‚Äù podcasting and demanded royalties from audio creators using its so-called podcasting patent. EFF crowdsourced prior art, filed an IPR, and ultimately knocked out the patent‚Äîbenefiting the entire podcasting world.&lt;/p&gt;
    &lt;p&gt;Under the new rules, this kind of public-interest challenge could easily be blocked based on procedural grounds like timing, before the PTAB even examines the patent.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SportBrain‚Äôs ‚Äúupload your fitness data‚Äù patent&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SportBrain sued more than 80 companies over a patent that claimed to cover basic gathering of user data and sending it over a network. A panel of PTAB judges canceled every claim.&lt;/p&gt;
    &lt;p&gt;Under the new rules, this patent could have survived long enough to force dozens more companies to pay up.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Shipping &amp;amp; Transit: a troll that sued hundreds of businesses&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more than a decade, Shipping &amp;amp; Transit sued companies over extremely broad ‚Äúdelivery notifications‚Äùpatents. After repeated losses at PTAB and in court (including fee awards), the company finally collapsed.&lt;/p&gt;
    &lt;p&gt;Under the new rules, a troll like this could keep its patents alive and continue carpet-bombing small businesses with lawsuits.&lt;/p&gt;
    &lt;p&gt;IPR hasn‚Äôt ended patent trolling. But when a troll waves a bogus patent at hundreds or thousands of people, IPR is one of the only tools that can actually fix the underlying problem: the patent itself. It dismantles abusive patent monopolies that never should have existed, saving entire industries from predatory litigation. That‚Äôs exactly why patent trolls and their allies have fought so hard to shut it down. They‚Äôve failed to dismantle IPR in court or in Congress‚Äîand now they‚Äôre counting on the USPTO‚Äôs own leadership to do it for them.&lt;/p&gt;
    &lt;head rend="h3"&gt;What the USPTO Plans To Do&lt;/head&gt;
    &lt;p&gt;First, they want you to give up your defenses in court. Under this proposal, a defendant can‚Äôt file an IPR unless they promise to never challenge the patent‚Äôs validity in court.&lt;/p&gt;
    &lt;p&gt;For someone actually being sued or threatened with patent infringement, that‚Äôs simply not a realistic promise to make. The choice would be: use IPR and lose your defenses‚Äîor keep your defenses and lose IPR.&lt;/p&gt;
    &lt;p&gt;Second, the rules allow patents to become ‚Äúunchallengeable‚Äù after one prior fight. That‚Äôs right. If a patent survives any earlier validity fight, anywhere, these rules would block everyone else from bringing an IPR, even years later and even if new prior art surfaces. One early decision‚Äîeven one that‚Äôs poorly argued, or didn‚Äôt have all the evidence‚Äîwould block the door on the entire public.&lt;/p&gt;
    &lt;p&gt;Third, the rules will block IPR entirely if a district court case is projected to move faster than PTAB.&lt;/p&gt;
    &lt;p&gt;So if a troll sues you with one of the outrageous patents we‚Äôve seen over the years, like patents on watching an ad, showing picture menus, or clocking in to work, the USPTO won‚Äôt even look at it. It‚Äôll be back to the bad old days, where you have exactly one way to beat the troll (who chose the court to sue in)‚Äîspend millions on experts and lawyers, then take your chances in front of a federal jury.&lt;/p&gt;
    &lt;p&gt;The USPTO claims this is fine because defendants can still challenge patents in district court. That‚Äôs misleading. A real district-court validity fight costs millions of dollars and takes years. For most people and small companies, that‚Äôs no opportunity at all. &lt;/p&gt;
    &lt;head rend="h3"&gt;Only Congress Can Rewrite IPR&lt;/head&gt;
    &lt;p&gt;IPR was created by Congress in 2013 after extensive debate. It was meant to give the public a fast, affordable way to correct the Patent Office‚Äôs own mistakes. Only Congress‚Äînot agency rulemaking‚Äîcan rewrite that system.&lt;/p&gt;
    &lt;p&gt;The USPTO shouldn‚Äôt be allowed to quietly undermine IPR with procedural traps that block legitimate challenges.&lt;/p&gt;
    &lt;p&gt;Bad patents still slip through every year. The Patent Office issues hundreds of thousands of new patents annually. IPR is one of the only tools the public has to push back.&lt;/p&gt;
    &lt;p&gt;These new rules rely on the absurd presumption that it‚Äôs the defendants‚Äîthe people and companies threatened by questionable patents‚Äîwho are abusing the system with multiple IPR petitions, and that they should be limited to one bite at the apple.&lt;/p&gt;
    &lt;p&gt;That‚Äôs utterly upside-down. It‚Äôs patent trolls like Shipping &amp;amp; Transit and Personal Audio that have sued, or threatened, entire communities of developers and small businesses.&lt;/p&gt;
    &lt;p&gt;When people have evidence that an overbroad patent was improperly granted, that evidence should be heard. That‚Äôs what Congress intended. These rules twist that intent beyond recognition.&lt;/p&gt;
    &lt;p&gt;In 2023, more than a thousand EFF supporters spoke out and stopped an earlier version of this proposal‚Äîyour comments made the difference then, and they can again.&lt;/p&gt;
    &lt;p&gt;Our principle is simple: the public has a right to challenge bad patents. These rules would take that right away. That‚Äôs why it‚Äôs vital to speak up now.&lt;/p&gt;
    &lt;p&gt;Sample comment:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I oppose the USPTO‚Äôs proposed rule changes for inter partes review (IPR), Docket No. PTO-P-2025-0025. The IPR process must remain open and fair. Patent challenges should be decided on their merits, not shut out because of legal activity elsewhere. These rules would make it nearly impossible for the public to challenge bad patents, and that will harm innovation and everyday technology users.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.eff.org/deeplinks/2025/11/patent-office-about-make-bad-patents-untouchable"/><published>2025-11-19T22:00:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45985978</id><title>Tailscale Down</title><updated>2025-11-19T23:10:05.985884+00:00</updated><content>&lt;doc fingerprint="96dbe3bae5972fde"&gt;
  &lt;main&gt;
    &lt;p&gt;Monitoring&lt;/p&gt;
    &lt;p&gt;Tailscale coordination servers are functioning properly now. We are currently monitoring to keep ensuring the servers stay healthy.&lt;/p&gt;
    &lt;p&gt;Identified&lt;/p&gt;
    &lt;p&gt;We have identified the issue and are working on a fix.&lt;/p&gt;
    &lt;p&gt;Investigating&lt;/p&gt;
    &lt;p&gt;We are investigating a problem causing coordination server errors and slowdown for some users, including access to login.tailscale.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://status.tailscale.com/incidents/01KAF1H8V7EGFKVG5KGZBB2RJC"/><published>2025-11-19T22:08:06+00:00</published></entry></feed>