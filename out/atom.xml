<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-16T20:38:07.731486+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45602428</id><title>Elixir 1.19</title><updated>2025-10-16T20:38:14.346826+00:00</updated><content>&lt;doc fingerprint="3a60ba942a313394"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Elixir v1.19 released: enhanced type checking, broader type inference, and up to 4x faster compilation for large projects&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 brings further improvements to the type system and compilation times, allowing us to find more bugs, faster.&lt;/p&gt;
    &lt;head rend="h2"&gt;Type system improvements&lt;/head&gt;
    &lt;p&gt;This release improves the type system around two key areas: type inference and type checking of anonymous functions and protocols. These enhancements seem simple on the surface but required us to go beyond existing literature by extending current theory and developing new techniques. We will outline the technical details in future articles. For now, let‚Äôs look at what‚Äôs new.&lt;/p&gt;
    &lt;head rend="h3"&gt;Type inference of all constructs&lt;/head&gt;
    &lt;p&gt;Type inference (or reconstruction) is the ability of a type system to automatically deduce, either partially or fully, the type of an expression at compile time. Type inference may occur at different levels. For example, many programming languages can automatically infer the types of variables, also known ‚Äúlocal type inference‚Äù, but not all can infer type signatures of functions.&lt;/p&gt;
    &lt;p&gt;Originally, our plan with Elixir‚Äôs upcoming type system was to support type inference of patterns, guards, and return types. Therefore, if you wrote this simple function:&lt;/p&gt;
    &lt;code&gt;def even?(x) when is_integer(x) do
  rem(x, 2) == 0
end
&lt;/code&gt;
    &lt;p&gt;Elixir would correctly infer the type to be &lt;code&gt;integer() -&amp;gt; boolean()&lt;/code&gt;. However, if you wrote this function:&lt;/p&gt;
    &lt;code&gt;def even?(x) do
  rem(x, 2) == 0
end
&lt;/code&gt;
    &lt;p&gt;The type would be &lt;code&gt;dynamic() -&amp;gt; boolean()&lt;/code&gt;, since there are no guards, even though the functions behave virtually the same, as the &lt;code&gt;rem&lt;/code&gt; operator expects both arguments to be integer (they just raise different exceptions for non-integer values).&lt;/p&gt;
    &lt;p&gt;Inferring type signatures comes with a series of trade-offs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Speed - type inference algorithms are often more computationally intensive than type checking algorithms.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Expressiveness - in any given type system, the constructs that support inference are always a subset of those that can be type-checked. Therefore, if a programming language is restricted to only fully reconstructed types, it is less expressive than a solely type checked counterpart.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Incremental compilation - type inference complicates incremental compilation. If module A depends on module B, which depends on module C, a change to C may require the type signature in B to be reconstructed, which may then require A to be recomputed (and so on). This dependency chain may require large projects to explicitly add type signatures for stability and compilation efficiency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cascading errors - when a user accidentally makes type errors or the code has conflicting assumptions, type inference may lead to less clear error messages as the type system tries to reconcile diverging type assumptions across code paths.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the other hand, type inference offers the benefit of enabling type checking for functions and codebases without requiring the user to add type annotations. To balance these trade-offs, we are exploring ‚Äúmodule type inference‚Äù: our goal is to infer type signatures considering invocations of functions in the same module and of functions from other applications (such as Elixir itself and your dependencies). Once module types are inferred, your whole project is type checked considering all declared and inferred types.&lt;/p&gt;
    &lt;p&gt;We have successfully implemented these features as part of Elixir v1.19, by performing inference of all constructs (except guards), taking into account the signatures from calls to functions within the same module and in Elixir‚Äôs standard library. This means the second function above, without the guard, will also infer the type &lt;code&gt;integer() -&amp;gt; boolean()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In future releases, we plan to perform type inference of guards (originally planned for v1.19) and also consider the type signatures of your dependencies during inference. Overall, these changes allow us to assess the impact of the trade-offs above as the type system evolves, which suits well our current goals of incrementally using types to find bugs in existing codebases, without changing them.&lt;/p&gt;
    &lt;p&gt;Keep in mind this only applies to type inference. Once we introduce type signatures and you explicitly annotate your functions, type inference and the trade-offs above no longer play a role. Any function with an explicit type signature will be typed checked against the user-provided annotations, as in other statically typed languages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Type checking of protocol dispatch and implementations&lt;/head&gt;
    &lt;p&gt;This release adds type checking when dispatching and implementing protocols.&lt;/p&gt;
    &lt;p&gt;For example, string interpolation in Elixir uses the &lt;code&gt;String.Chars&lt;/code&gt; protocol. If you pass a value that does not implement said protocol, Elixir will now emit a warning accordingly.&lt;/p&gt;
    &lt;p&gt;Here is an example passing a range, which cannot be converted into a string, to an interpolation:&lt;/p&gt;
    &lt;code&gt;defmodule Example do
  def my_code(first..last//step = range) do
    "hello #{range}"
  end
end
&lt;/code&gt;
    &lt;p&gt;the above emits the following warnings:&lt;/p&gt;
    &lt;code&gt;warning: incompatible value given to string interpolation:

    data

it has type:

    %Range{first: term(), last: term(), step: term()}

but expected a type that implements the String.Chars protocol, it must be one of:

    dynamic(
      %Date{} or %DateTime{} or %NaiveDateTime{} or %Time{} or %URI{} or %Version{} or
        %Version.Requirement{}
    ) or atom() or binary() or float() or integer() or list(term())
&lt;/code&gt;
    &lt;p&gt;Warnings are also emitted if you pass a data type that does not implement the &lt;code&gt;Enumerable&lt;/code&gt; protocol as a generator to for-comprehensions:&lt;/p&gt;
    &lt;code&gt;defmodule Example do
  def my_code(%Date{} = date) do
    for(x &amp;lt;- date, do: x)
  end
end
&lt;/code&gt;
    &lt;p&gt;will emit:&lt;/p&gt;
    &lt;code&gt;warning: incompatible value given to for-comprehension:

    x &amp;lt;- date

it has type:

    %Date{year: term(), month: term(), day: term(), calendar: term()}

but expected a type that implements the Enumerable protocol, it must be one of:

    dynamic(
      %Date.Range{} or %File.Stream{} or %GenEvent.Stream{} or %HashDict{} or %HashSet{} or
        %IO.Stream{} or %MapSet{} or %Range{} or %Stream{}
    ) or fun() or list(term()) or non_struct_map()
&lt;/code&gt;
    &lt;head rend="h3"&gt;Type checking and inference of anonymous functions&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 can now type infer and type check anonymous functions. Here is a trivial example:&lt;/p&gt;
    &lt;code&gt;defmodule Example do
  def run do
    fun = fn %{} -&amp;gt; :map end
    fun.("hello")
  end
end
&lt;/code&gt;
    &lt;p&gt;The example above has an obvious typing violation, as the anonymous function expects a map but a string is given. With Elixir v1.19, the following warning is now printed:&lt;/p&gt;
    &lt;code&gt;    warning: incompatible types given on function application:

        fun.("hello")

    given types:

        binary()

    but function has type:

        (dynamic(map()) -&amp;gt; :map)

    typing violation found at:
    ‚îÇ
  6 ‚îÇ     fun.("hello")
    ‚îÇ        ~
    ‚îÇ
    ‚îî‚îÄ mod.exs:6:8: Example.run/0
&lt;/code&gt;
    &lt;p&gt;Function captures, such as &lt;code&gt;&amp;amp;String.to_integer/1&lt;/code&gt;, will also propagate the type as of Elixir v1.19, arising more opportunity for Elixir‚Äôs type system to catch bugs in our programs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;The type system was made possible thanks to a partnership between CNRS and Remote. The development work is currently sponsored by Fresha, Starfish*, and Dashbit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Faster compile times in large projects&lt;/head&gt;
    &lt;p&gt;This release includes two compiler improvements that can lead up to 4x faster builds in large codebases.&lt;/p&gt;
    &lt;p&gt;While Elixir has always compiled the given files in project or a dependency in parallel, the compiler would sometimes be unable to use all of the machine resources efficiently. This release addresses two common limitations, delivering performance improvements that scale with codebase size and available CPU cores.&lt;/p&gt;
    &lt;head rend="h3"&gt;Code loading bottlenecks&lt;/head&gt;
    &lt;p&gt;Prior to this release, Elixir would load modules as soon as they were defined. However, because the Erlang part of code loading happens within a single process (the code server), this would make it a bottleneck, reducing parallelization, especially on large projects.&lt;/p&gt;
    &lt;p&gt;This release makes it so modules are loaded lazily. This reduces the pressure on the code server and the amount of work during compilation, with reports of more than two times faster compilation for large projects. The benefits depend on the codebase size and the number of CPU cores available.&lt;/p&gt;
    &lt;p&gt;Implementation wise, the parallel compiler already acts as a mechanism to resolve modules during compilation, so we built on that. By making sure the compiler controls both module compilation and module loading, it can also better guarantee deterministic builds.&lt;/p&gt;
    &lt;p&gt;There are two potential regressions with this approach. The first one happens if you spawn processes during compilation which invoke other modules defined within the same project. For example:&lt;/p&gt;
    &lt;code&gt;defmodule MyLib.SomeModule do
  list = [...]

  Task.async_stream(list, fn item -&amp;gt;
    MyLib.SomeOtherModule.do_something(item)
  end)
end
&lt;/code&gt;
    &lt;p&gt;Because the spawned process is not visible to the compiler, it won‚Äôt be able to load &lt;code&gt;MyLib.SomeOtherModule&lt;/code&gt;. You have two options, either use &lt;code&gt;Kernel.ParallelCompiler.pmap/2&lt;/code&gt; or explicitly call &lt;code&gt;Code.ensure_compiled!(MyLib.SomeOtherModule)&lt;/code&gt; before spawning the process that uses said module.&lt;/p&gt;
    &lt;p&gt;The second one is related to &lt;code&gt;@on_load&lt;/code&gt; callbacks (typically used for NIFs) that invoke other modules defined within the same project. For example:&lt;/p&gt;
    &lt;code&gt;defmodule MyLib.SomeModule do
  @on_load :init

  def init do
    MyLib.AnotherModule.do_something()
  end

  def something_else do
    ...
  end
end

MyLib.SomeModule.something_else()
&lt;/code&gt;
    &lt;p&gt;The reason this fails is because &lt;code&gt;@on_load&lt;/code&gt; callbacks are invoked within the code server and therefore they have limited ability to load additional modules. It is generally advisable to limit invocation of external modules during &lt;code&gt;@on_load&lt;/code&gt; callbacks but, in case it is strictly necessary, you can set &lt;code&gt;@compile {:autoload, true}&lt;/code&gt; in the invoked module to address this issue in a forward and backwards compatible manner.&lt;/p&gt;
    &lt;p&gt;Both snippets above could actually lead to non-deterministic compilation failures in the past, and as a result of these changes, compiling these cases are now deterministic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Parallel compilation of dependencies&lt;/head&gt;
    &lt;p&gt;This release introduces a variable called &lt;code&gt;MIX_OS_DEPS_COMPILE_PARTITION_COUNT&lt;/code&gt;, which instructs &lt;code&gt;mix deps.compile&lt;/code&gt; to compile dependencies in parallel.&lt;/p&gt;
    &lt;p&gt;While fetching dependencies and compiling individual Elixir dependencies already happened in parallel, as outlined in the previous section, there were pathological cases where performance gains would be left on the table, such as when compiling dependencies with native code or dependencies where one or two large files would take most of the compilation time.&lt;/p&gt;
    &lt;p&gt;By setting &lt;code&gt;MIX_OS_DEPS_COMPILE_PARTITION_COUNT&lt;/code&gt; to a number greater than 1, Mix will now compile multiple dependencies at the same time, using separate OS processes. Empirical testing shows that setting it to half of the number of cores on your machine is enough to maximize resource usage. The exact speed up will depend on the number of dependencies and the number of machine cores and some users reported up to 4x faster compilation times when using our release candidates. If you plan to enable it on CI or build servers, keep in mind it will most likely have a direct impact on memory usage too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Erlang/OTP 28 support&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 officially supports Erlang/OTP 28.1+ and later. In order to support the new Erlang/OTP 28 representation for regular expressions, structs can now control how they are escaped into abstract syntax trees by defining a &lt;code&gt;__escape__/1&lt;/code&gt; callback.&lt;/p&gt;
    &lt;p&gt;On the other hand, the new representation for regular expressions in Erlang/OTP 28+ implies they can no longer be used as default values for struct fields. Therefore, this is not allowed:&lt;/p&gt;
    &lt;code&gt;defmodule Foo do
  defstruct regex: ~r/foo/
end
&lt;/code&gt;
    &lt;p&gt;You can, however, still use regexes when initializing the structs themselves:&lt;/p&gt;
    &lt;code&gt;defmodule Foo do
  defstruct [:regex]

  def new do
    %Foo{regex: ~r/foo/}
  end
end
&lt;/code&gt;
    &lt;head rend="h2"&gt;OpenChain certification&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 is also our first release following OpenChain compliance, as previously announced. In a nutshell:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Elixir releases now include a Source SBoM in CycloneDX 1.6 or later and SPDX 2.3 or later formats.&lt;/item&gt;
      &lt;item&gt;Each release is attested along with the Source SBoM.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These additions offer greater transparency into the components and licenses of each release, supporting more rigorous supply chain requirements.&lt;/p&gt;
    &lt;p&gt;This work was performed by Jonatan M√§nnchen and sponsored by the Erlang Ecosystem Foundation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;There are many other goodies in this release, such as improved option parsing, better debuggability and performance in ExUnit, the addition of &lt;code&gt;mix help Mod&lt;/code&gt;, &lt;code&gt;mix help Mod.fun&lt;/code&gt;, &lt;code&gt;mix help Mod.fun/arity&lt;/code&gt;, and &lt;code&gt;mix help app:package&lt;/code&gt; to make documentation accessible via shell for humans and agents, and much more. See the CHANGELOG for the complete release notes.&lt;/p&gt;
    &lt;p&gt;Happy coding!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://elixir-lang.org/blog/2025/10/16/elixir-v1-19-0-released/"/><published>2025-10-16T07:31:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604308</id><title>Jiga (YC W21) Is Hiring Full Stacks</title><updated>2025-10-16T20:38:13.986019+00:00</updated><content>&lt;doc fingerprint="335ec57ff13aea3c"&gt;
  &lt;main&gt;
    &lt;p&gt;Jiga transforms the traditional way manufacturers do business.&lt;/p&gt;
    &lt;p&gt;We're building a digital platform that streamlines the complex, inefficient process of procuring manufactured parts directly from suppliers, making it automated, collaborative, and data-driven.&lt;/p&gt;
    &lt;p&gt;Now that I‚Äôve got your attention with some AI cringe, read the job posting carefully before applying.&lt;/p&gt;
    &lt;p&gt;About Jiga:&lt;/p&gt;
    &lt;p&gt;We are on a mission to help engineers build physical products faster. Imagine the &lt;code&gt;npm install&lt;/code&gt; for mechanical engineers.&lt;/p&gt;
    &lt;p&gt;How we work:&lt;/p&gt;
    &lt;p&gt;Remote: We are a fully remote company with team members from over 5 countries.&lt;/p&gt;
    &lt;p&gt;Culture: We never count hours and measure team members by performance and communication only. We hate micro-management and we 100% trust team members to perform tasks and to be honest with each other.&lt;/p&gt;
    &lt;p&gt;We play online games weekly together, encourage people to ask the hard questions, and we fly everyone once per year for our annual offsite in a beautiful place in the nature.&lt;/p&gt;
    &lt;p&gt;Meetings: We have a no-BS-meeting policy. We will have one weekly with the whole company and another one with the dev team. That's it.&lt;/p&gt;
    &lt;p&gt;Engineering Values:&lt;/p&gt;
    &lt;p&gt;Funding: Fully funded with significant, growing revenue. We are transparent about our runway.&lt;/p&gt;
    &lt;p&gt;You should apply if&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;p&gt;Benefits&lt;/p&gt;
    &lt;p&gt;No, we don‚Äôt have Friday happy hours or a fridge packed with 10 different flavors of ice cream in our office. In fact, we don‚Äôt have an office.&lt;/p&gt;
    &lt;p&gt;We do offer:&lt;/p&gt;
    &lt;p&gt;How to apply&lt;/p&gt;
    &lt;p&gt;Please send a short blurb about yourself and your favorite ice cream flavor (mine is cookies)&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;fulltimeRemoteFull stack3+ years&lt;/p&gt;
    &lt;p&gt;fulltimeUS / Remote (US)Full stack$13+ years&lt;/p&gt;
    &lt;p&gt;fulltimeIL / Remote (IL)3+ years&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.workatastartup.com/jobs/44310"/><published>2025-10-16T12:00:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604451</id><title>A stateful browser agent using self-healing DOM maps</title><updated>2025-10-16T20:38:13.702860+00:00</updated><link href="https://100x.bot/a/a-stateful-browser-agent-using-self-healing-dom-maps"/><published>2025-10-16T12:21:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604673</id><title>Hyperflask ‚Äì Full stack Flask and Htmx framework</title><updated>2025-10-16T20:38:13.475628+00:00</updated><content>&lt;doc fingerprint="fa8a766ea56e588d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Backend-driven interactive apps&lt;/head&gt;
    &lt;p&gt;Hyperflask is built on top of Flask, a popular Python web framework. It is easy to use and master. Backend-driven apps ensure straighforward state management and limit a lot of footguns from frontend-heavy apps. Combined with HTMX and a component system, creating interactive apps is easier than ever.&lt;/p&gt;
    &lt;head rend="h2"&gt;A powerful component system&lt;/head&gt;
    &lt;p&gt;Hyperflask introduces component-driven architecture to Flask apps. Seamlessly create frontend (web components, react, etc...) and backend components and use them in your jinja templates. Use HTMX to create server-backed interactive components.&lt;/p&gt;
    &lt;head rend="h2"&gt;File-based routing&lt;/head&gt;
    &lt;p&gt;Hyperflask extends Flask with many powerful features, notably file-based routing using a new file format that combines python code and a jinja template (inspired by Astro pages).&lt;/p&gt;
    &lt;head rend="h2"&gt;Build beautiful UIs&lt;/head&gt;
    &lt;p&gt;Hyperflask includes beautiful components provided by daisyUI and icons by Bootstrap Icons. Use Tailwind to customize styling. Create beautiful UIs in minutes without any CSS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Batteries included&lt;/head&gt;
    &lt;p&gt; Send emails using MJML, run background jobs, send push events using SSE, translations, authentication, content streaming, optimized images, ... &lt;lb/&gt;Everything you need to build a product ! &lt;/p&gt;
    &lt;head rend="h2"&gt;Content driven when needed&lt;/head&gt;
    &lt;p&gt;Hyperflask can be used to generate static web sites. It can also run in an hybrid mode where the server is accessed only for dynamic requests.&lt;/p&gt;
    &lt;head rend="h2"&gt;No messing around with your environment&lt;/head&gt;
    &lt;p&gt;Dev and prod environment are standardized on containers. With a tight integration with VS Code, everything is easy to setup and run. Easily deploy to VPS and various cloud services.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ensuring a thriving ecosystem&lt;/head&gt;
    &lt;p&gt;The Hyperflask framework itself is a small code base. It combines many Flask extensions in a seamless manner. All extensions and related projects are developed independently of the framework under the Hyperflask organization. Feel free to pick and choose the part you prefer from Hyperflask and use them in your own projects.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hyperflask.dev/"/><published>2025-10-16T12:46:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604700</id><title>Show HN: Inkeep (YC W23) ‚Äì Agent builder that works both visually and in code</title><updated>2025-10-16T20:38:12.934617+00:00</updated><content>&lt;doc fingerprint="85708f8bb901b03a"&gt;
  &lt;main&gt;
    &lt;p&gt;With Inkeep, you can build and ship AI Agents with a No-Code Visual Builder or TypeScript SDK. Agents can be edited in code or no-code with full 2-way sync, so technical and non-technical teams can create and manage their Agents in a single platform. To get started, see the docs.&lt;/p&gt;
    &lt;p&gt;A no-code drag-and-drop canvas designed to allow any team to create and manage teams of Agents visually.&lt;/p&gt;
    &lt;p&gt;A code-first approach for building and managing multi-agent systems. Engineering teams to build with the tools and developer experience they expect.&lt;/p&gt;
    &lt;code&gt;import { agent, subAgent } from "@inkeep/agents-sdk";

const helloAgent = subAgent({
  id: "hello-agent",
  name: "Hello Agent",
  description: "Says hello",
  prompt: 'Only reply with the word "hello", but you may do it in different variations like h3110, h3110w0rld, h3110w0rld! etc...',
});

export const basicAgent = agent({
  id: "basic-agent",
  name: "Basic Agent",
  description: "A basic agent",
  defaultSubAgent: helloAgent,
  subAgents: () =&amp;gt; [helloAgent],
});&lt;/code&gt;
    &lt;p&gt;The Visual Builder and TypeScript SDK are fully interoperable: your technical and non-technical teams can edit and manage Agents in either format and switch or collaborate with others at any time.&lt;/p&gt;
    &lt;p&gt;Inkeep Agents can operate as real-time AI Chat Assistants, for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a customer experience agent for customer support, technical docs, or in-app product copilot&lt;/item&gt;
      &lt;item&gt;an internal copilot to assist your support, sales, marketing, ops, and other teams&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Agents can also be used for AI workflow automation like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Creating and updating knowledge bases, documentation, and blogs&lt;/item&gt;
      &lt;item&gt;Updating CRMs, triaging helpdesk tickets, and streamlining repetitive tasks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Inkeep Open Source includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Visual Builder &amp;amp; TypeScript SDK with 2-way sync&lt;/item&gt;
      &lt;item&gt;Multi-agent architecture to support teams of agents&lt;/item&gt;
      &lt;item&gt;MCP Tools with credentials management&lt;/item&gt;
      &lt;item&gt;A UI component library for dynamic chat experiences&lt;/item&gt;
      &lt;item&gt;Triggering Agents via MCP, A2A, &amp;amp; Vercel SDK APIs&lt;/item&gt;
      &lt;item&gt;Observability via a Traces UI &amp;amp; OpenTelemetry&lt;/item&gt;
      &lt;item&gt;Easy deployment to Vercel and using Docker&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a full overview, see the Concepts guide.&lt;/p&gt;
    &lt;p&gt;The Inkeep Agent Platform is composed of several key services and libraries that work together:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;agents-manage-api: An API that handles configuration of Agents, Sub Agents, MCP Servers, Credentials, and Projects with a REST API.&lt;/item&gt;
      &lt;item&gt;agents-manage-ui: Visual Builder web interface for creating and managing Agents. Writes to the &lt;code&gt;agents-manage-api&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;agents-sdk: TypeScript SDK (&lt;code&gt;@inkeep/agents-sdk&lt;/code&gt;) for declaratively defining Agents and custom tools in code. Writes to&lt;code&gt;agents-manage-api&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;agents-cli: Includes various handy utilities, including &lt;code&gt;inkeep push&lt;/code&gt;and&lt;code&gt;inkeep pull&lt;/code&gt;which sync your TypeScript SDK code with the Visual Builder.&lt;/item&gt;
      &lt;item&gt;agents-run-api: The Runtime API that exposes Agents as APIs and executes Agent conversations. Keeps conversation state and emits OTEL traces.&lt;/item&gt;
      &lt;item&gt;agents-ui: A UI component library of chat interfaces for embedding rich, dynamic Agent conversational experiences in web apps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Underneath the hood, the framework uses the Vercel AI SDK for interfacing with LLM providers. The &lt;code&gt;agents-sdk&lt;/code&gt;/ &lt;code&gt;agents-manage-api&lt;/code&gt; share many concepts with Vercel's &lt;code&gt;ai&lt;/code&gt; SDK, and &lt;code&gt;agents-run-api&lt;/code&gt; outputs a data stream compatible with Vercel's &lt;code&gt;useChat&lt;/code&gt; and AI Elements primitives for custom UIs.&lt;/p&gt;
    &lt;p&gt;The Inkeep Agent Framework is licensed under the Elastic License 2.0 (ELv2) subject to Inkeep's Supplemental Terms (SUPPLEMENTAL_TERMS.md). This is a fair-code, source-available license that allows broad usage while protecting against certain competitive uses.&lt;/p&gt;
    &lt;p&gt;Inkeep is designed to be extensible and open: you can use the LLM provider of your choice, use Agents via standard protocols, and easily deploy and self-host Agents in your own infra.&lt;/p&gt;
    &lt;p&gt;If you'd like to contribute, follow our contribution guide.&lt;/p&gt;
    &lt;p&gt;Follow us to stay up to date, get help, and share feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/inkeep/agents"/><published>2025-10-16T12:50:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604779</id><title>Electricity can heal wounds three times as fast (2023)</title><updated>2025-10-16T20:38:11.984232+00:00</updated><content>&lt;doc fingerprint="fedd408029bd4e42"&gt;
  &lt;main&gt;
    &lt;p&gt;Chronic wounds are a major health problem for diabetic patients and the elderly ‚Äì in extreme cases they can even lead to amputation. Using electric stimulation, researchers in a project at Chalmers University of Technology, Sweden, and the University of Freiburg, Germany, have developed a method that speeds up the healing process, making wounds heal three times faster.&lt;/p&gt;
    &lt;p&gt;There is an old Swedish saying that one should never neglect a small wound or a friend in need. For most people, a small wound does not lead to any serious complications, but many common diagnoses make wound healing far more difficult. People with diabetes, spinal injuries or poor blood circulation have impaired wound healing ability. This means a greater risk of infection and chronic wounds ‚Äì which in the long run can lead to such serious consequences as amputation.&lt;/p&gt;
    &lt;p&gt;Now a group of researchers at Chalmers and the University of Freiburg have developed a method using electric stimulation to speed up the healing process.&lt;/p&gt;
    &lt;p&gt;‚ÄúChronic wounds are a huge societal problem that we don‚Äôt hear a lot about. Our discovery of a method that may heal wounds up to three times faster can be a game changer for diabetic and elderly people, among others, who often suffer greatly from wounds that won‚Äôt heal,‚Äù says Maria Asplund, Professor of Bioelectronics at Chalmers University of Technology and head of research on the project.&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;lb/&gt;Electric guidance of cells for faster healing&lt;/head&gt;
    &lt;p&gt;The researchers worked from an old hypothesis that electric stimulation of damaged skin can be used to heal wounds. The idea is that skin cells are electrotactic, which means that they directionally ‚Äòmigrate‚Äô in electric fields. This means that if an electric field is placed in a petri dish with skin cells, the cells stop moving randomly and start moving in the same direction. The researchers investigated how this principle can be used to electrically guide the cells in order to make wounds heal faster. Using a tiny engineered chip, the researchers were able to compare wound healing in artificial skin, stimulating one wound with electricity and letting one heal without electricity. The differences were striking.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe were able to show that the old hypothesis about electric stimulation can be used to make wounds heal significantly faster. In order to study exactly how this works for wounds, we developed a kind of biochip on which we cultured skin cells, which we then made tiny wounds in. Then we stimulated one wound with an electric field, which clearly led to it healing three times as fast as the wound that healed without electric stimulation,‚Äù Asplund says.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hope for diabetes patients&lt;/head&gt;
    &lt;p&gt;In the study, the researchers also focused on wound healing in connection with diabetes, a growing health problem worldwide. One in 11 adults today has some form of diabetes according to the World Health Organization (WHO) and the International Diabetes Federation.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe‚Äôve looked at diabetes models of wounds and investigated whether our method could be effective even in those cases. We saw that when we mimic diabetes in the cells, the wounds on the chip heal very slowly. However, with electric stimulation we can increase the speed of healing so that the diabetes-affected cells almost correspond to healthy skin cells,‚Äù Asplund says.&lt;/p&gt;
    &lt;head rend="h3"&gt;Individualised treatment the next step&lt;/head&gt;
    &lt;p&gt;The Chalmers researchers recently received a large grant which will allow them to continue their research in the field, and in the long run enable the development of wound healing products for consumers on the market. Similar products have come out before, but more basic research is required to develop effective products that generate enough electric field strength and stimulate in the right way for each individual. This is where Asplund and her colleagues come into the picture:&lt;/p&gt;
    &lt;p&gt;‚ÄúWe are now looking at how different skin cells interact during stimulation, to take a step closer to a realistic wound. We want to develop a concept to be able to ‚Äòscan‚Äô wounds and adapt the stimulation based on the individual wound. We are convinced that this is the key to effectively helping individuals with slow-healing wounds in the future,‚Äù Asplund says.&lt;/p&gt;
    &lt;head rend="h3"&gt;More about the study:&lt;/head&gt;
    &lt;p&gt;‚Ä¢ ‚ÄúBioelectronic microfluidic wound healing: a platform for investigating direct current stimulation of injured cell collectives‚Äù was published in the journal Lab on a Chip. The article was written by Sebastian Shaner, Anna Savelyeva, Anja Kvartuh, Nicole Jedrusik, Lukas Matter, Jos√© Leal and Maria Asplund. The researchers work at the University of Freiburg in Germany and Chalmers University of Technology. &lt;lb/&gt;‚Ä¢ In their study, the researchers showed that wound healing on artificial skin stimulated with electric current was three times faster than on the skin that healed naturally. The electric field was low, about 200 mV/mm, and did not have a negative impact on the cells. &lt;lb/&gt;‚Ä¢ The method the researchers developed is based on a microfluidic biochip on which artificial skin can be grown, stimulated with an electric current and studied in an effective and controlled manner. The concept allows researchers to conduct multiple experiments in parallel on the same chip. &lt;lb/&gt;‚Ä¢ The research project began in 2018 and is funded by the European Research Council (ERC). The project was recently granted new funding so the research can get to market and benefit patients.&lt;/p&gt;
    &lt;head rend="h3"&gt;For more information, please contact:&lt;/head&gt;
    &lt;p&gt;Maria Asplund, Professor of Bioelectronics, Department of Microtechnology and Nanoscience at Chalmers University of Technology, Sweden&lt;lb/&gt;maria.asplund@chalmers.se, +46 31 772 41 14&lt;/p&gt;
    &lt;p&gt;Sebastian Shaner, PhD Candidate, Department of Microsystems Engineering at the University of Freiburg, Germany&lt;lb/&gt;sebastian.shaner@blbt.uni-freiburg.de&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Professor, Electronics Material and Systems, Microtechnology and Nanoscience&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.chalmers.se/en/current/news/mc2-how-electricity-can-heal-wounds-three-times-as-fast/"/><published>2025-10-16T12:59:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45605153</id><title>Lace: A New Kind of Cellular Automata Where Links Matter</title><updated>2025-10-16T20:38:11.621207+00:00</updated><content>&lt;doc fingerprint="ea85981ebb574771"&gt;
  &lt;main&gt;
    &lt;p&gt;This article is about a new kind of simple computational rule (‚ÄúLACE rules‚Äù running on LACE, the Link Automata Computing Engine platform) which, when applied locally on a grid of cells, demonstrates fascinating emergent ‚Äúartificial life‚Äù behavior. &lt;lb/&gt;For readers familiar with the Game of Life (GOL), this is a next-level class of cellular automata that utilizes neighborhood topology ‚Äî the state of the grid is a function of both cell states and their connectivity (links).&lt;lb/&gt;To quickly get a sense of what LACE does ‚Äì scroll down in this post to the video Gallery section and take a look at (a) the Game of Life, with links, and then as a comparison, check out (b) the ‚ÄúAmazing Dragons‚Äù LACE rule, and the many other ‚ÄúRealm of LACE‚Äù (ROL) rules that fully utilize topology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preamble&lt;/head&gt;
    &lt;p&gt;I have been thinking about cellular automata ever since I read a fascinating and important book, Three Scientists and Their Gods, during the summer of my sophomore year of college. This book changed my life. &lt;lb/&gt;After reading this book ferociously on the drive home from Oberlin college to Boston, for summer vacation, I became obsessed with the idea of digital physics ‚Äì and particularly with the work of Ed Fredkin, (and later Stephen Wolfram as well). &lt;/p&gt;
    &lt;p&gt;And so I decided I had to find a way to get into Ed Fredkin‚Äôs lab at MIT. This became my mission in life&lt;/p&gt;
    &lt;p&gt;Finally, after many attempts, I did managed to finagle a summer internship in his lab at MIT, thanks to the kindness of Professors Norman Margolus and Tommaso Toffolli, two of the great minds in the field. They had authored an MIT Press book that I had found and read countless times, Cellular Automata Machines, which at the time was the bible in the field.&lt;/p&gt;
    &lt;p&gt;In their lab they had built a specialized supercomputer, CAM-6, for digital physics simulations. I spent every minute of that summer in their lab on CAM-6, exploring the computational universe. &lt;lb/&gt;For years after that internship, I filled dozens of journals with detailed ideas and theories about digital physics. I wrote code, I tested ideas, I learned and explored. But nothing really came close to the richness and complexity of the vision I had experienced, or our actual natural world. &lt;lb/&gt;These digital models were lacking something, but I wasn‚Äôt sure what. &lt;lb/&gt;Then, years later, it became more clear. &lt;lb/&gt;The topology of spacetime is not merely a fixed set of locations and states, it‚Äôs a graph. The links between things are important. (Note: As Stephen Wolfram would later point out to me, this idea harkens back to the dialectical debate between the views of Newton and Leibniz).&lt;/p&gt;
    &lt;p&gt;I needed a new kind of model, one where the shape of space could evolve, one where the shape of space could affect matter, and where matter could affect the shape of space, because after all, according to Einstein, they are really the same thing.&lt;/p&gt;
    &lt;p&gt;And from this insight I then undertook decades of exploration into the idea of a new kind of cellular automata ‚Äî one in which the cells had links to each other, which could also figure into their states. Both the cell states and link states could interact, forming complex topologies and geometries. &lt;lb/&gt;Decades went by, along with many experiments that did not bear fruit. &lt;lb/&gt;But last year, I actually built something that demonstrates this new class of CA rather nicely. &lt;lb/&gt;Now I‚Äôm finally getting around to posting it‚Ä¶&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing LACE: The Link Automata Computing Engine&lt;/head&gt;
    &lt;p&gt;LACE is a new experimental platform written in python, for exploring a class of cellular automata in which both the states of cells and their connections (links) to each other are subject to the rules.&lt;lb/&gt;In LACE, the state of a cell is a function of both its neighbors AND the links it has to them, and link states in turn are a function of the cells they connect.&lt;lb/&gt;LACE rules can use topological properties of cells and neighborhoods, such as number of connections, neighbor degree, and other metrics.&lt;/p&gt;
    &lt;p&gt;This enables rules in which virtual neighborhood topology (the links) affects neighborhood states ‚Äî rules in which topology can both evolve and shape the behavior of the system, and in which the behavior of the system can shape topology.&lt;lb/&gt;The added topological dimension enables rules that can have more interesting behavior than traditional ‚Äúcells-only‚Äù CA rules, opening up a fascinating new computational vista (within Wolfram‚Äôs, Ruliad) of new kinds of rules that generate new species of stable patterns ‚Äì oscillators ‚Äì gliders, puffers, and more.&lt;/p&gt;
    &lt;p&gt;LACE rules range from link-aware variants of Conway‚Äôs famous Game of Life, but where edges have varying degrees of influence, to completely new kinds of ‚ÄúRealm of LACE‚Äù rules that use topological metrics in their computations. In theory, these rules could even be utilized to simulate neural networks.&lt;/p&gt;
    &lt;p&gt;What is fascinating about these new link-aware ‚ÄúRealm of LACE rules‚Äù is that they exhibit amazing new forms of stability and periodic structure. They produce new kinds of periodic gliders, oscillators, puffers, and other kinds of phenomena. Some of them even have behaviors that resemble forms of ‚Äúartificial life.‚Äù&lt;lb/&gt;For more details on how these rules work, get the repo and open various rules in the rule editor, where all their parameters are explained. There are many new classes of rules to experiment with.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Code&lt;/head&gt;
    &lt;p&gt;You can read more about LACE here.&lt;/p&gt;
    &lt;p&gt;You can get the LACE python code repo here.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Gallery&lt;/head&gt;
    &lt;p&gt;(NOTE ‚Äì click on the videos and use the settings icon to set quality to 1080p for best visuals)&lt;/p&gt;
    &lt;p&gt;First, let‚Äôs take a look at Conway‚Äôs Game of Life, but with links visible. This demonstration simply shows the links and their states, but in this example, the links do not affect the states of cells. This shows that LACE can run traditional 2D cellular automata rules, with the links visible, but without the links changing rule behavior.&lt;lb/&gt;In more sophisticated LACE rules (scroll down), we will actually modify the behavior of the Life rule based on the links&lt;/p&gt;
    &lt;p&gt;And here are some Life gliders, doing their thing, with links visible‚Ä¶&lt;/p&gt;
    &lt;p&gt;And here is a stable pattern in Life‚Ä¶ with links‚Ä¶.&lt;/p&gt;
    &lt;p&gt;Now, here is a version of Life, where edges influence rule behavior‚Ä¶&lt;/p&gt;
    &lt;p&gt;Here‚Äôs a variant of Life where edges play even more of a role. &lt;lb/&gt;In LACE we can adjust the influence that links have on rule behavior ‚Äì from none (links are merely decorative), to strong influence (links condition cell states).&lt;/p&gt;
    &lt;p&gt;Above, we looked at some traditional Life rule cellular automata. These examples illustrated varying levels of link-awareness in rules. But they are still not showing the full capabilities of the LACE platform.&lt;lb/&gt;Next, we turn to more advanced LACE rules that fully utilize the capabilities of the system‚Ä¶&lt;/p&gt;
    &lt;head rend="h2"&gt;The Realm of LACE: LACE Rules&lt;/head&gt;
    &lt;p&gt;Now, take a look at the ‚ÄúAmazing Dragons‚Äù rule in the Realm of LACE (ROL), one of the more interesting rules in this universe.&lt;/p&gt;
    &lt;p&gt;This is not a life rule ‚Äì it‚Äôs a LACE rule ‚Äì a fully topological rule.&lt;/p&gt;
    &lt;p&gt;Here links and neighborhood topology play a major role in the behavior of cell states and cell states modify the states of links as well.&lt;lb/&gt;(Here‚Äôs a little more detail on how rules work ‚Äì see this and this and a longer explanation here)&lt;/p&gt;
    &lt;p&gt;‚Ä¶and look what happens!&lt;/p&gt;
    &lt;p&gt;LACE also supports an optional high-performance, GPU-accelerated mode using Taichi, for large-scale simulations‚Ä¶&lt;/p&gt;
    &lt;p&gt;And here‚Äôs another interesting LACE rule‚Ä¶&lt;/p&gt;
    &lt;p&gt;and check this out‚Ä¶&lt;/p&gt;
    &lt;p&gt;and this one‚Ä¶.&lt;/p&gt;
    &lt;p&gt;And now a gallery of many other interesting LACE rules‚Ä¶&lt;/p&gt;
    &lt;p&gt;This has been a preview of the Realm of LACE ‚Ä¶ an incredible new class of cellular automata rules, where links matter and topology evolves.&lt;lb/&gt;Learn more by playing with the repo, and please share your discoveries üôÇ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.novaspivack.com/science/introducing-lace-a-new-kind-of-cellular-automata"/><published>2025-10-16T13:33:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45605291</id><title>Why I Chose Elixir Phoenix over Rails, Laravel, and Next.js</title><updated>2025-10-16T20:38:11.476141+00:00</updated><content>&lt;doc fingerprint="b7d4d06b17b5be94"&gt;
  &lt;main&gt;
    &lt;p&gt;October 16, 2025 ¬∑ by Akarsh&lt;/p&gt;
    &lt;p&gt;First things first, why do we code? To solve problems in the most optimal way possible.&lt;/p&gt;
    &lt;p&gt;For me, the number one factor is speed: both application speed and development speed. That‚Äôs exactly what led me to Phoenix LiveView.&lt;/p&gt;
    &lt;p&gt;If I had chosen React or Next.js with Laravel, or even Inertia.js with Laravel, I would have had to maintain both sides of the stack, frontend and backend. As a solo developer, I didn‚Äôt have the time to manage state in two different places. I needed a solid monolithic solution that could handle everything together.&lt;/p&gt;
    &lt;p&gt;So I looked into Laravel Livewire and Rails Hotwire. Both are great tools that simplify frontend work without depending too much on JavaScript. I even thought about going full JavaScript with Next.js, but I‚Äôve never been a big fan of using JS on the backend.&lt;/p&gt;
    &lt;p&gt;Rails Hotwire really caught my attention, especially because of how fast you can build an MVP with Rails. But I still needed background jobs, real-time updates, and two-way communication that just works. Those things are possible in Rails and Laravel, but they take a bit more effort to set up.&lt;/p&gt;
    &lt;p&gt;Then I came across Elixir and its framework Phoenix. It had all the elegance of Ruby on Rails, but with far better performance. It came with built-in background jobs through Oban, a familiar and clean syntax, and something truly special called LiveView.&lt;/p&gt;
    &lt;p&gt;LiveView feels like the perfect balance between traditional server-rendered apps and frontend-heavy frameworks. It‚Äôs way ahead of both Rails Hotwire and Laravel Livewire. LiveView communicates through WebSockets, which means real-time two-way updates without sending new requests every time something changes. You can still use Alpine.js or any JavaScript library you want through hooks when needed.&lt;/p&gt;
    &lt;p&gt;Phoenix also comes with Oban jobs built in. You can declare background jobs easily, and when something fails, it automatically restarts without breaking the app. That‚Äôs the beauty of Elixir. It‚Äôs a compiled language built on top of Erlang, which powers highly concurrent systems like WhatsApp and Discord.&lt;/p&gt;
    &lt;p&gt;I‚Äôm not saying Phoenix is better than Laravel, Rails, or Next.js. All of these are excellent frameworks, and I‚Äôve personally used them to build applications. Phoenix just turned out to be the best fit for my specific use case. This is my project - Hyperzoned.com&lt;/p&gt;
    &lt;p&gt;I don‚Äôt know who needs to hear this, but try exploring beyond what you already know. You might find a better and more efficient way to solve your next problem. After all, never stop learning.&lt;/p&gt;
    &lt;p&gt;Thanks for reading! You can find me on X or Hyperzoned.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://akarshc.com/post/phoenix-for-my-project.html"/><published>2025-10-16T13:48:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45605501</id><title>DoorDash and Waymo launch autonomous delivery service in Phoenix</title><updated>2025-10-16T20:38:11.138704+00:00</updated><content>&lt;doc fingerprint="f98ba259b3b2bde5"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, DoorDash announced a new partnership with Waymo to launch an autonomous delivery service in Metro Phoenix and introduce a limited-time $10 Waymo promotion for DashPass members in Los Angeles, San Francisco, and Phoenix.&lt;/p&gt;
    &lt;p&gt;From now through the end of the year, DashPass members in these three cities can receive $10 off one Waymo ride per month.* A new promotion code will be issued at the start of each month through December 31, 2025.&lt;/p&gt;
    &lt;p&gt;Testing of the new autonomous delivery service in Metro Phoenix is now underway, with plans to launch broader commercial operations later this year. DoorDash consumers in the area may be matched with a fully autonomous Waymo vehicle for deliveries from participating merchants using DoorDash‚Äôs Autonomous Delivery Platform, the system that helps orchestrate different types of delivery methods together at scale, whether that‚Äôs Dashers, robots, drones, or Waymo. The service will begin with deliveries from DashMart, DoorDash‚Äôs owned and operated convenience, grocery, and retail store that also powers DashMart Fulfillment Services, with plans to expand over time.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúDashPass is designed to give consumers consistent value, convenience, and access to the best of their communities, and our partnership with Waymo builds on that promise,‚Äù said David Richter, Vice President of Business and Corporate Development at DoorDash. ‚ÄúTogether, we‚Äôre giving members access to, and savings on, a new and delightful experience, while advancing our vision for a multi-modal autonomous future of local commerce.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWe are excited to make everyday errands easier with the Waymo Driver, offering the added peace of mind that comes with our safe and reliable technology. Through our partnership with DoorDash, we leverage our proven delivery experience to provide customers with a seamless, contact-free way to get items they need, whether it‚Äôs groceries or a quick bite,‚Äù said Nicole Gavel, Head of Business Development and Strategic Partnerships at Waymo.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;DashPass offers exclusive deals, member-only benefits, and $0 delivery fees and reduced service fees on eligible orders from thousands of restaurants, grocery stores, and retailers. On average, DashPass members save $5 per eligible order and have collectively saved more than $10 billion globally since the program launched in 2018.&lt;/p&gt;
    &lt;p&gt;*On weekday rides booked between 2 a.m. and 2 p.m. Terms apply.&lt;/p&gt;
    &lt;p&gt;Forward-Looking Statements&lt;lb/&gt;This communication contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. Forward-looking statements generally relate to future events, and such statements in this communication include, but are not limited to, expectations regarding the opportunity and expected benefits of the partnership between DoorDash and Waymo. Expectations and beliefs regarding these matters may not materialize, and actual results in future periods are subject to risks and uncertainties that could cause actual results to differ materially from those projected. For information on potential risks and uncertainties that could cause actual results to differ from any results predicted, please see DoorDash‚Äôs most recent Annual Report on Form 10-K and subsequent Quarterly Reports on Form 10-Q, each filed with the Securities and Exchange Commission.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://about.doordash.com/en-us/news/waymo"/><published>2025-10-16T14:04:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45606070</id><title>Improving the Trustworthiness of JavaScript on the Web</title><updated>2025-10-16T20:38:10.434221+00:00</updated><content>&lt;doc fingerprint="9e39b013996d6ecb"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;The web is the most powerful application platform in existence. As long as you have the right API, you can safely run anything you want in a browser.&lt;/p&gt;
      &lt;p&gt;Well√¢¬¶ anything but cryptography.&lt;/p&gt;
      &lt;p&gt;It is as true today as it was in 2011 that Javascript cryptography is Considered Harmful. The main problem is code distribution. Consider an end-to-end-encrypted messaging web application. The application generates cryptographic keys in the client√¢s browser that lets users view and send end-to-end encrypted messages to each other. If the application is compromised, what would stop the malicious actor from simply modifying their Javascript to exfiltrate messages?&lt;/p&gt;
      &lt;p&gt;It is interesting to note that smartphone apps don√¢t have this issue. This is because app stores do a lot of heavy lifting to provide security for the app ecosystem. Specifically, they provide integrity, ensuring that apps being delivered are not tampered with, consistency, ensuring all users get the same app, and transparency, ensuring that the record of versions of an app is truthful and publicly visible.&lt;/p&gt;
      &lt;p&gt;It would be nice if we could get these properties for our end-to-end encrypted web application, and the web as a whole, without requiring a single central authority like an app store. Further, such a system would benefit all in-browser uses of cryptography, not just end-to-end-encrypted apps. For example, many web-based confidential LLMs, cryptocurrency wallets, and voting systems use in-browser Javascript cryptography for the last step of their verification chains.&lt;/p&gt;
      &lt;p&gt;In this post, we will provide an early look at such a system, called Web Application Integrity, Consistency, and Transparency (WAICT) that we have helped author. WAICT is a W3C-backed effort among browser vendors, cloud providers, and encrypted communication developers to bring stronger security guarantees to the entire web. We will discuss the problem we need to solve, and build up to a solution resembling the current transparency specification draft. We hope to build even wider consensus on the solution design in the near future.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Defining the Web Application&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;In order to talk about security guarantees of a web application, it is first necessary to define precisely what the application is. A smartphone application is essentially just a zip file. But a website is made up of interlinked assets, including HTML, Javascript, WASM, and CSS, that can each be locally or externally hosted. Further, if any asset changes, it could drastically change the functioning of the application. A coherent definition of an application thus requires the application to commit to precisely the assets it loads. This is done using integrity features, which we describe now.&lt;/p&gt;
      &lt;p&gt;An important building block for defining a single coherent application is subresource integrity (SRI). SRI is a feature built into most browsers that permits a website to specify the cryptographic hash of external resources, e.g.,&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;&amp;lt;script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.13.7/underscore-min.js" integrity="sha512-dvWGkLATSdw5qWb2qozZBRKJ80Omy2YN/aF3wTUVC5+D1eqbA+TjWpPpoj8vorK5xGLMa2ZqIeWCpDZP/+pQGQ=="&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This causes the browser to fetch &lt;code&gt;underscore.js&lt;/code&gt; from &lt;code&gt;cdnjs.cloudflare.com&lt;/code&gt; and verify that its SHA-512 hash matches the given hash in the tag. If they match, the script is loaded. If not, an error is thrown and nothing is executed.&lt;/p&gt;
      &lt;p&gt;If every external script, stylesheet, etc. on a page comes with an SRI integrity attribute, then the whole page is defined by just its HTML. This is close to what we want, but a web application can consist of many pages, and there is no way for a page to enforce the hash of the pages it links to.&lt;/p&gt;
      &lt;p&gt;We would like to have a way of enforcing integrity on an entire site, i.e., every asset under a domain. For this, WAICT defines an integrity manifest, a configuration file that websites can provide to clients. One important item in the manifest is the asset hashes dictionary, mapping a hash belonging to an asset that the browser might load from that domain, to the path of that asset. Assets that may occur at any path, e.g., an error page, map to the empty string:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;"hashes": {
"81db308d0df59b74d4a9bd25c546f25ec0fdb15a8d6d530c07a89344ae8eeb02": "/assets/js/main.js",
"fbd1d07879e672fd4557a2fa1bb2e435d88eac072f8903020a18672d5eddfb7c": "/index.html",
"5e737a67c38189a01f73040b06b4a0393b7ea71c86cf73744914bbb0cf0062eb": "/vendored/main.css",
"684ad58287ff2d085927cb1544c7d685ace897b6b25d33e46d2ec46a355b1f0e": "",
"f802517f1b2406e308599ca6f4c02d2ae28bb53ff2a5dbcddb538391cb6ad56a": ""
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The other main component of the manifest is the integrity policy, which tells the browser which data types are being enforced and how strictly. For example, the policy in the manifest below will:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Reject any script before running it, if it√¢s missing an SRI tag and doesn√¢t appear in the hashes&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Reject any WASM possibly after running it, if it√¢s missing an SRI tag and doesn√¢t appear in hashes&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;quote&gt;
        &lt;code&gt;"integrity-policy": "blocked-destinations=(script), checked-destinations=(wasm)"&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Put together, these make up the integrity manifest:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;"manifest": {
  "version": 1,
  "integrity-policy": ...,
  "hashes": ...,
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Thus, when both SRI and integrity manifests are used, the entire site and its interpretation by the browser is uniquely determined by the hash of the integrity manifest. This is exactly what we wanted. We have distilled the problem of endowing authenticity, consistent distribution, etc. to a web application to one of endowing the same properties to a single hash.&lt;/p&gt;
      &lt;p&gt;Recall, a transparent web application is one whose code is stored in a publicly accessible, append-only log. This is helpful in two ways: 1) if a user is served malicious code and they learn about it, there is a public record of the code they ran, and so they can prove it to external parties, and 2) if a user is served malicious code and they don√¢t learn about it, there is still a chance that an external auditor may comb through the historical web application code and find the malicious code anyway. Of course, transparency does not help detect malicious code or even prevent its distribution, but it at least makes it publicly auditable.&lt;/p&gt;
      &lt;p&gt;Now that we have a single hash that commits to an entire website√¢s contents, we can talk about ensuring that that hash ends up in a public log. We have several important requirements here:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Do not break existing sites. This one is a given. Whatever system gets deployed, it should not interfere with the correct functioning of existing websites. Participation in transparency should be strictly opt-in.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;No added round trips. Transparency should not cause extra network round trips between the client and the server. Otherwise there will be a network latency penalty for users who want transparency.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;User privacy. A user should not have to identify themselves to any party more than they already do. That means no connections to new third parties, and no sending identifying information to the website.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;User statelessness. A user should not have to store site-specific data. We do not want solutions that rely on storing or gossipping per-site cryptographic information.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Non-centralization. There should not be a single point of failure in the system√¢if any single party experiences downtime, the system should still be able to make progress. Similarly, there should be no single point of trust√¢if a user distrusts any single party, the user should still receive all the security benefits of the system.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Ease of opt-in. The barrier of entry for transparency should be as low as possible. A site operator should be able to start logging their site cheaply and without being an expert.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Ease of opt-out. It should be easy for a website to stop participating in transparency. Further, to avoid accidental lock-in like the defunct HPKP spec, it should be possible for this to happen even if all cryptographic material is lost, e.g., in the seizure or selling of a domain.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Opt-out is transparent. As described before, because transparency is optional, it is possible for an attacker to disable the site√¢s transparency, serve malicious content, then enable transparency again. We must make sure this kind of attack is detectable, i.e., the act of disabling transparency must itself be logged somewhere.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Monitorability. A website operator should be able to efficiently monitor the transparency information being published about their website. In particular, they should not have to run a high-network-load, always-on program just to notify them if their site has been hijacked.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;With these requirements in place, we can move on to construction. We introduce a data structure that will be essential to the design.&lt;/p&gt;
      &lt;p&gt;Almost everything in transparency is an append-only log, i.e., a data structure that acts like a list and has the ability to produce an inclusion proof, i.e., a proof that an element occurs at a particular index in the list; and a consistency proof, i.e., a proof that a list is an extension of a previous version of the list. A consistency proof between two lists demonstrates that no elements were modified or deleted, only added.&lt;/p&gt;
      &lt;p&gt;The simplest possible append-only log is a hash chain, a list-like data structure wherein each subsequent element is hashed into the running chain hash. The final chain hash is a succinct representation of the entire list.&lt;/p&gt;
      &lt;p&gt;A hash chain. The green nodes represent the chain hash, i.e., the hash of the element below it, concatenated with the previous chain hash. &lt;/p&gt;
      &lt;p&gt;The proof structures are quite simple. To prove inclusion of the element at index i, the prover provides the chain hash before &lt;code&gt;i&lt;/code&gt;, and all the elements after &lt;code&gt;i&lt;/code&gt;:&lt;/p&gt;
      &lt;p&gt;Proof of inclusion for the second element in the hash chain. The verifier knows only the final chain hash. It checks equality of the final computed chain hash with the known final chain hash. The light green nodes represent hashes that the verifier computes. &lt;/p&gt;
      &lt;p&gt;Similarly, to prove consistency between the chains of size i and j, the prover provides the elements between i and j:&lt;/p&gt;
      &lt;p&gt;Proof of consistency of the chain of size one and chain of size three. The verifier has the chain hashes from the starting and ending chains. It checks equality of the final computed chain hash with the known ending chain hash. The light green nodes represent hashes that the verifier computes. &lt;/p&gt;
      &lt;p&gt;We can use hash chains to build a transparency scheme for websites.&lt;/p&gt;
      &lt;p&gt;As a first step, let√¢s give every site its own log, instantiated as a hash chain (we will discuss how these all come together into one big log later). The items of the log are just the manifest of the site at a particular point in time:&lt;/p&gt;
      &lt;p&gt;A site√¢s hash chain-based log, containing three historical manifests. &lt;/p&gt;
      &lt;p&gt;In reality, the log does not store the manifest itself, but the manifest hash. Sites designate an asset host that knows how to map hashes to the data they reference. This is a content-addressable storage backend, and can be implemented using strongly cached static hosting solutions.&lt;/p&gt;
      &lt;p&gt;A log on its own is not very trustworthy. Whoever runs the log can add and remove elements at will and then recompute the hash chain. To maintain the append-only-ness of the chain, we designate a trusted third party, called a witness. Given a hash chain consistency proof and a new chain hash, a witness:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Verifies the consistency proof with respect to its old stored chain hash, and the new provided chain hash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;If successful, signs the new chain hash along with a signature timestamp.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Now, when a user navigates to a website with transparency enabled, the sequence of events is:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;The site serves its manifest, an inclusion proof showing that the manifest appears in the log, and all the signatures from all the witnesses who have validated the log chain hash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The browser verifies the signatures from whichever witnesses it trusts.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The browser verifies the inclusion proof. The manifest must be the newest entry in the chain (we discuss how to serve old manifests later).&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The browser proceeds with the usual manifest and SRI integrity checks.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;At this point, the user knows that the given manifest has been recorded in a log whose chain hash has been saved by a trustworthy witness, so they can be reasonably sure that the manifest won√¢t be removed from history. Further, assuming the asset host functions correctly, the user knows that a copy of all the received code is readily available.&lt;/p&gt;
      &lt;p&gt;The need to signal transparency. The above algorithm works, but we have a problem: if an attacker takes control of a site, they can simply stop serving transparency information and thus implicitly disable transparency without detection. So we need an explicit mechanism that keeps track of every website that has enrolled into transparency.&lt;/p&gt;
      &lt;p&gt;To store all the sites enrolled into transparency, we want a global data structure that maps a site domain to the site log√¢s chain hash. One efficient way of representing this is a prefix tree (a.k.a., a trie). Every leaf in the tree corresponds to a site√¢s domain, and its value is the chain hash of that site√¢s log, the current log size, and the site√¢s asset host URL. For a site to prove validity of its transparency data, it will have to present an inclusion proof for its leaf. Fortunately, these proofs are efficient for prefix trees.&lt;/p&gt;
      &lt;p&gt;A prefix tree with four elements. Each leaf√¢s path corresponds to a domain. Each leaf√¢s value is the chain hash of its site√¢s log. &lt;/p&gt;
      &lt;p&gt;To add itself to the tree, a site proves possession of its domain to the transparency service, i.e., the party that operates the prefix tree, and provides an asset host URL. To update the entry, the site sends the new entry to the transparency service, which will compute the new chain hash. And to unenroll from transparency, the site just requests to have its entry removed from the tree (an adversary can do this too; we discuss how to detect this below).&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h4"&gt;Proving to Witnesses and Browsers&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Now witnesses only need to look at the prefix tree instead of individual site logs, and thus they must verify whole-tree updates. The most important thing to ensure is that every site√¢s log is append-only. So whenever the tree is updated, it must produce a √¢proof√¢ containing every new/deleted/modified entry, as well as a consistency proof for each entry showing that the site log corresponding to that entry has been properly appended to. Once the witness has verified this prefix tree update proof, it signs the root.&lt;/p&gt;
      &lt;p&gt;The sequence of updating a site√¢s assets and serving the site with transparency enabled.&lt;/p&gt;
      &lt;p&gt;The client-side verification procedure is as in the previous section, with two modifications:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;The client now verifies two inclusion proofs: one for the integrity policy√¢s membership in the site log, and one for the site log√¢s membership in a prefix tree.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The client verifies the signature over the prefix tree root, since the witness no longer signs individual chain hashes. As before, the acceptable public keys are whichever witnesses the client trusts.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Signaling transparency. Now that there is a single source of truth, namely the prefix tree, a client can know a site is enrolled in transparency by simply fetching the site√¢s entry in the tree. This alone would work, but it violates our requirement of √¢no added round trips,√¢ so we instead require that client browsers will ship with the list of sites included in the prefix tree. We call this the transparency preload list.√Ç &lt;/p&gt;
      &lt;p&gt;If a site appears in the preload list, the browser will expect it to provide an inclusion proof in the prefix tree, or else a proof of non-inclusion in a newer version of the prefix tree, thereby showing they√¢ve unenrolled. The site must provide one of these proofs until the last preload list it appears in has expired. Finally, even though the preload list is derived from the prefix tree, there is nothing enforcing this relationship. Thus, the preload list should also be published transparently.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h4"&gt;Filling in Missing Properties&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Remember we still have the requirements of monitorability, opt-out being transparent, and no single point of failure/trust. We fill in those details now.&lt;/p&gt;
      &lt;p&gt;Adding monitorability. So far, in order for a site operator to ensure their site was not hijacked, they would have to constantly query every transparency service for its domain and verify that it hasn√¢t been tampered with. This is certainly better than the 500k events per hour that CT monitors have to ingest, but it still requires the monitor to be constantly polling the prefix tree, and it imposes a constant load for the transparency service.&lt;/p&gt;
      &lt;p&gt;We add a field to the prefix tree leaf structure: the leaf now stores a √¢created√¢ timestamp, containing the time the leaf was created. Witnesses ensure that the √¢created√¢ field remains the same over all leaf updates (and it is deleted when the leaf is deleted). To monitor, a site operator need only keep the last observed √¢created√¢ and √¢log size√¢ fields of its leaf. If it fetches the latest leaf and sees both unchanged, it knows that no changes occurred since the last check.&lt;/p&gt;
      &lt;p&gt;Adding transparency of opt-out. We must also do the same thing as above for leaf deletions. When a leaf is deleted, a monitor should be able to learn when the deletion occurred within some reasonable time frame. Thus, rather than outright removing a leaf, the transparency service responds to unenrollment requests by replacing the leaf with a tombstone value, containing just a √¢created√¢ timestamp. As before, witnesses ensure that this field remains unchanged until the leaf is permanently deleted (after some visibility period) or re-enrolled.&lt;/p&gt;
      &lt;p&gt;Permitting multiple transparency services. Since we require that there be no single point of failure or trust, we imagine an ecosystem where there are a handful of non-colluding, reasonably trustworthy transparency service providers, each with their own prefix tree. Like Certificate Transparency (CT), this set should not be too large. It must be small enough that reasonable levels of trust can be established, and so that independent auditors can reasonably handle the load of verifying all of them.&lt;/p&gt;
      &lt;p&gt;Ok that√¢s the end of the most technical part of this post. We√¢re now going to talk about how to tweak this system to provide all kinds of additional nice properties.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;(Not) Achieving Consistency&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Transparency would be useless if, every time a site updates, it serves 100,000 new versions of itself. Any auditor would have to go through every single version of the code in order to ensure no user was targeted with malware. This is bad even if the velocity of versions is lower. If a site publishes just one new version per week, but every version from the past ten years is still servable, then users can still be served extremely old, potentially vulnerable versions of the site, without anyone knowing. Thus, in order to make transparency valuable, we need consistency, the property that every browser sees the same version of the site at a given time.&lt;/p&gt;
      &lt;p&gt;We will not achieve the strongest version of consistency, but it turns out that weaker notions are sufficient for us. If, unlike the above scenario, a site had 8 valid versions of itself at a given time, then that would be pretty manageable for an auditor. So even though it√¢s true that users don√¢t all see the same version of the site, they will all still benefit from transparency, as desired.&lt;/p&gt;
      &lt;p&gt;We describe two types of inconsistency and how we mitigate them.&lt;/p&gt;
      &lt;p&gt;Tree inconsistency occurs when transparency services√¢ prefix trees disagree on the chain hash of a site, thus disagreeing on the history of the site. One way to fully eliminate this is to establish a consensus mechanism for prefix trees. A simple one is majority voting: if there are five transparency services, a site must present three tree inclusion proofs to a user, showing the chain hash is present in three trees. This, of course, triples the tree inclusion proof size, and lowers the fault tolerance of the entire system (if three log operators go down, then no transparent site can publish any updates).&lt;/p&gt;
      &lt;p&gt;Instead of consensus, we opt to simply limit the amount of inconsistency by limiting the number of transparency services. In 2025, Chrome trusts eight Certificate Transparency logs. A similar number of transparency services would be fine for our system. Plus, it is still possible to detect and prove the existence of inconsistencies between trees, since roots are signed by witnesses. So if it becomes the norm to use the same version on all trees, then social pressure can be applied when sites violate this.&lt;/p&gt;
      &lt;p&gt;Temporal inconsistency occurs when a user gets a newer or older version of the site (both still unexpired), depending on some external factors such as geographic location or cookie values. In the extreme, as stated above, if a signed prefix root is valid for ten years, then a site can serve a user any version of the site from the last ten years.&lt;/p&gt;
      &lt;p&gt;As with tree inconsistency, this can be resolved using consensus mechanisms. If, for example, the latest manifest were published on a blockchain, then a user could fetch the latest blockchain head and ensure they got the latest version of the site. However, this incurs an extra network round trip for the client, and requires sites to wait for their hash to get published on-chain before they can update. More importantly, building this kind of consensus mechanism into our specification would drastically increase its complexity. We√¢re aiming for v1.0 here.&lt;/p&gt;
      &lt;p&gt;We mitigate temporal inconsistency by requiring reasonably short validity periods for witness signatures. Making prefix root signatures valid for, e.g., one week would drastically limit the number of simultaneously servable versions. The cost is that site operators must now query the transparency service at least once a week for the new signed root and inclusion proof, even if nothing in the site changed. The sites cannot skip this, and the transparency service must be able to handle this load. This parameter must be tuned carefully.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Beyond Integrity, Consistency, and Transparency&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Providing integrity, consistency, and transparency is already a huge endeavor, but there are some additional app store-like security features that can be integrated into this system without too much work.&lt;/p&gt;
      &lt;p&gt;One problem that WAICT doesn√¢t solve is that of provenance: where did the code the user is running come from, precisely? In settings where audits of code happen frequently, this is not so important, because some third party will be reading the code regardless. But for smaller self-hosted deployments of open-source software, this may not be viable. For example, if Alice hosts her own version of Cryptpad for her friend Bob, how can Bob be sure the code matches the real code in Cryptpad√¢s Github repo?&lt;/p&gt;
      &lt;p&gt;WEBCAT. The folks at the Freedom of Press Foundation (FPF) have built a solution to this, called WEBCAT. This protocol allows site owners to announce the identities of the developers that have signed the site√¢s integrity manifest, i.e., have signed all the code and other assets that the site is serving to the user. Users with the WEBCAT plugin can then see the developer√¢s Sigstore signatures, and trust the code based on that.&lt;/p&gt;
      &lt;p&gt;We√¢ve made WAICT extensible enough to fit WEBCAT inside and benefit from the transparency components. Concretely, we permit manifests to hold additional metadata, which we call extensions. In this case, the extension holds a list of developers√¢ Sigstore identities. To be useful, browsers must expose an API for browser plugins to access these extension values. With this API, independent parties can build plugins for whatever feature they wish to layer on top of WAICT.&lt;/p&gt;
      &lt;p&gt;So far we have not built anything that can prevent attacks in the moment. An attacker who breaks into a website can still delete any code-signing extensions, or just unenroll the site from transparency entirely, and continue with their attack as normal. The unenrollment will be logged, but the malicious code will not be, and by the time anyone sees the unenrollment, it may be too late.&lt;/p&gt;
      &lt;p&gt;To prevent spontaneous unenrollment, we can enforce unenrollment cooldown client-side. Suppose the cooldown period is 24 hours. Then the rule is: if a site appears on the preload list, then the client will require that either 1) the site have transparency enabled, or 2) the site have a tombstone entry that is at least 24 hours old. Thus, an attacker will be forced to either serve a transparency-enabled version of the site, or serve a broken site for 24 hours.&lt;/p&gt;
      &lt;p&gt;Similarly, to prevent spontaneous extension modifications, we can enforce extension cooldown on the client. We will take code signing as an example, saying that any change in developer identities requires a 24 hour waiting period to be accepted. First, we require that extension &lt;code&gt;dev-ids&lt;/code&gt; has a preload list of its own, letting the client know which sites have opted into code signing (if a preload list doesn√¢t exist then any site can delete the extension at any time). The client rule is as follows: if the site appears in the preload list, then both 1) &lt;code&gt;dev-ids&lt;/code&gt; must exist as an extension in the manifest, and 2) &lt;code&gt;dev-ids-inclusion&lt;/code&gt; must contain an inclusion proof showing that the current value of dev-ids was in a prefix tree that is at least 24 hours old. With this rule, a client will reject values of &lt;code&gt;dev-ids&lt;/code&gt; that are newer than a day. If a site wants to delete &lt;code&gt;dev-ids&lt;/code&gt;, they must 1) request that it be removed from the preload list, and 2) in the meantime, replace the dev-ids value with the empty string and update &lt;code&gt;dev-ids-inclusion&lt;/code&gt; to reflect the new value.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Deployment Considerations&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;There are a lot of distinct roles in this ecosystem. Let√¢s sketch out the trust and resource requirements for each role.&lt;/p&gt;
      &lt;p&gt;Transparency service. These parties store metadata for every transparency-enabled site on the web. If there are 100 million domains, and each entry is 256B each (a few hashes, plus a URL), this comes out to 26GB for a single tree, not including the intermediate hashes. To prevent size blowup, there would probably have to be a pruning rule that unenrolls sites after a long inactivity period. Transparency services should have largely uncorrelated downtime, since, if all services go down, no transparency-enabled site can make any updates. Thus, transparency services must have a moderate amount of storage, be relatively highly available, and have downtime periods uncorrelated with each other.&lt;/p&gt;
      &lt;p&gt;Transparency services require some trust, but their behavior is narrowly constrained by witnesses. Theoretically, a service can replace any leaf√¢s chain hash with its own, and the witness will validate it (as long as the consistency proof is valid). But such changes are detectable by anyone that monitors that leaf.&lt;/p&gt;
      &lt;p&gt;Witness. These parties verify prefix tree updates and sign the resulting roots. Their storage costs are similar to that of a transparency service, since they must keep a full copy of a prefix tree for every transparency service they witness. Also like the transparency services, they must have high uptime. Witnesses must also be trusted to keep their signing key secret for a long period of time, at least long enough to permit browser trust stores to be updated when a new key is created.&lt;/p&gt;
      &lt;p&gt;Asset host. These parties carry little trust. They cannot serve bad data, since any query response is hashed and compared to a known hash. The only malicious behavior an asset host can do is refuse to respond to queries. Asset hosts can also do this by accident due to downtime.&lt;/p&gt;
      &lt;p&gt;Client. This is the most trust-sensitive part. The client is the software that performs all the transparency and integrity checks. This is, of course, the web browser itself. We must trust this.&lt;/p&gt;
      &lt;p&gt;We at Cloudflare would like to contribute what we can to this ecosystem. It should be possible to run both a transparency service and a witness. Of course, our witness should not monitor our own transparency service. Rather, we can witness other organizations√¢ transparency services, and our transparency service can be witnessed by other organizations.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Supporting Alternate Ecosystems&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;WAICT should be compatible with non-standard ecosystems, ones where the large players do not really exist, or at least not in the way they usually do. We are working with the FPF on defining transparency for alternate ecosystems with different network and trust environments. The primary example we have is that of the Tor ecosystem.&lt;/p&gt;
      &lt;p&gt;A paranoid Tor user may not trust existing transparency services or witnesses, and there might not be any other trusted party with the resources to self-host these functionalities. For this use case, it may be reasonable to put the prefix tree on a blockchain somewhere. This makes the usual domain validation impossible (there√¢s no validator server to speak of), but this is fine for onion services. Since an onion address is just a public key, a signature is sufficient to prove ownership of the domain.&lt;/p&gt;
      &lt;p&gt;One consequence of a consensus-backed prefix tree is that witnesses are now unnecessary, and there is only need for the single, canonical, transparency service. This mostly solves the problems of tree inconsistency at the expense of latency of updates.&lt;/p&gt;
      &lt;p&gt;We are still very early in the standardization process. One of the more immediate next steps is to get subresource integrity working for more data types, particularly WASM and images. After that, we can begin standardizing the integrity manifest format. And then after that we can start standardizing all the other features. We intend to work on this specification hand-in-hand with browsers and the IETF, and we hope to have some exciting betas soon.&lt;/p&gt;
      &lt;p&gt;In the meantime, you can follow along with our transparency specification draft, check out the open problems, and share your ideas. Pull requests and issues are always welcome!&lt;/p&gt;
      &lt;p&gt;Many thanks to Dennis Jackson from Mozilla for the lengthy back-and-forth meetings on design, to Giulio B and Cory Myers from FPF for their immensely helpful influence and feedback, and to Richard Hansen for great feedback.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/improving-the-trustworthiness-of-javascript-on-the-web/"/><published>2025-10-16T14:50:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45606698</id><title>Codex Is Live in Zed</title><updated>2025-10-16T20:38:10.238114+00:00</updated><content>&lt;doc fingerprint="b44ddc5f080cb81d"&gt;
  &lt;main&gt;
    &lt;p&gt;When we introduced the Agent Client Protocol (ACP) in collaboration with Google's Gemini CLI team, we did not anticipate how much pent-up demand there was for a protocol like this!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First we saw a wave of requests for Anthropic's Claude Code&lt;/item&gt;
      &lt;item&gt;Then we saw a bunch of other clients and agents adopting ACP, most recently JetBrains&lt;/item&gt;
      &lt;item&gt;Now we've seen a fresh wave of requests for OpenAI's Codex:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As of today, Zed supports Codex out-the-box via ACP. You can select it from the New Thread menu, just like Claude Code or Gemini CLI:&lt;/p&gt;
    &lt;p&gt;Like our other ACP integrations, Codex via ACP is strictly about improving UI and keeping you in flow in your IDE of choice; the billing and legal/terms arrangement is directly between you and OpenAI. Zed does not charge for use of external agents like Codex, nor do prompts and code sent via Codex-ACP to OpenAI touch Zed's servers! We've also separately open-sourced the codex-acp adapter so you can use it outside of Zed as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning from Different Agents&lt;/head&gt;
    &lt;p&gt;Every model behaves a bit differently than the others, and the same is true of agents. For example, some agents support switching models in the middle of a conversation, whereas others require sticking with the same model throughout. Some support viewing and resuming past conversations, whereas others have no concept of conversation persistence. ACP is designed to be flexible enough to work with a variety of agent capabilities, but the experience of using them still varies based on the agent's implementation details.&lt;/p&gt;
    &lt;p&gt;A detail that came up when we were building the Codex ACP adapter was that the Codex agent runs terminal commands in its own process, and then streams output bytes from that terminal process to the client. In the past, we've had this reversed: the agent would send the client a request to run a terminal command (e.g. &lt;code&gt;mkdir examples&lt;/code&gt;) and then the client would manage
the actual running of that command.&lt;/p&gt;
    &lt;p&gt;Naturally, we want to keep the look and feel consistent no matter which agent you're using, but this design difference between Codex and other agents makes certain details unavoidably different. For example, for other agents we can spawn terminals in pseudoterminal (PTY) mode. This means you can actually interact with the terminal right in the Agent Panel if the agent launches an interactive process, and it also means things like colorful terminal output tend to be enabled by default.&lt;/p&gt;
    &lt;p&gt;On the other hand, being in PTY mode means that an agent can get stuck. A classic example of this is when an agent tries to run &lt;code&gt;git rebase --continue&lt;/code&gt; and the terminal pops up the configured editor, then waits for the programmer to make any
edits (if desired) to the commit message. This can be nice for a human, but for an agent that's waiting for the command to
finish, it creates a deadlock. The process won't proceed without interaction, and the agent won't interact until the process
completes! Having terminals work in non-PTY mode might result in fewer colors and less interactivity, but it also results in
fewer cases of agents getting stuck.&lt;/p&gt;
    &lt;p&gt;Now that we've integrated agents that both enable and disable PTY mode, we can compare how the experience feels in both cases, and use that to inform our recommendations for future ACP integrations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Which ACP Integration is Next?&lt;/head&gt;
    &lt;p&gt;In addition to Codex, we have already added support to Zed for Claude Code, Gemini CLI, and other agents, all via ACP. Since ACP is not specific to Zed, we've also seen it be adopted by editors like Neovim, Emacs, and now the JetBrains family of IDEs.&lt;/p&gt;
    &lt;p&gt;Now that the protocol has picked up enough adoption on its own, we're happy to shift our focus to working with the community on the future of the protocol‚Äîas opposed to building ACP adapters ourselves like we did with Codex and Claude Code. We're excited to see what amazing ACP integrations the community cooks up!&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking for a better editor?&lt;/head&gt;
    &lt;p&gt;You can try Zed today on macOS, Windows, or Linux. Download now!&lt;/p&gt;
    &lt;head rend="h3"&gt;We are hiring!&lt;/head&gt;
    &lt;p&gt;If you're passionate about the topics we cover on our blog, please consider joining our team to help us ship the future of software development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zed.dev/blog/codex-is-live-in-zed"/><published>2025-10-16T15:36:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45607117</id><title>Claude Skills</title><updated>2025-10-16T20:38:09.919514+00:00</updated><content>&lt;doc fingerprint="9e4c2e7f2f779869"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Claude Skills&lt;/head&gt;
    &lt;p&gt;Claude can now use Skills to improve how it performs specific tasks. Skills are folders that include instructions, scripts, and resources that Claude can load when needed.&lt;/p&gt;
    &lt;p&gt;Claude will only access a skill when it's relevant to the task at hand. When used, skills make Claude better at specialized tasks like working with Excel or following your organization's brand guidelines.&lt;/p&gt;
    &lt;p&gt;You've already seen Skills at work in Claude apps, where Claude uses them to create files like spreadsheets and presentations. Now, you can build your own skills and use them across Claude apps, Claude Code, and our API.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Skills work&lt;/head&gt;
    &lt;p&gt;While working on tasks, Claude scans available skills to find relevant matches. When one matches, it loads only the minimal information and files needed‚Äîkeeping Claude fast while accessing specialized expertise.&lt;/p&gt;
    &lt;p&gt;Skills are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Composable: Skills stack together. Claude automatically identifies which skills are needed and coordinates their use.&lt;/item&gt;
      &lt;item&gt;Portable: Skills use the same format everywhere. Build once, use across Claude apps, Claude Code, and API.&lt;/item&gt;
      &lt;item&gt;Efficient: Only loads what's needed, when it's needed.&lt;/item&gt;
      &lt;item&gt;Powerful: Skills can include executable code for tasks where traditional programming is more reliable than token generation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Think of Skills as custom onboarding materials that let you package expertise, making Claude a specialist on what matters most to you. For a technical deep-dive on the Agent Skills design pattern, architecture, and development best practices, read our engineering blog.&lt;/p&gt;
    &lt;head rend="h2"&gt;Skills work with every Claude product&lt;/head&gt;
    &lt;head rend="h3"&gt;Claude apps&lt;/head&gt;
    &lt;p&gt;Skills are available to Pro, Max, Team and Enterprise users. We provide skills for common tasks like document creation, examples you can customize, and the ability to create your own custom skills.&lt;/p&gt;
    &lt;p&gt;Claude automatically invokes relevant skills based on your task‚Äîno manual selection needed. You'll even see skills in Claude's chain of thought as it works.&lt;lb/&gt;Creating skills is simple. The "skill-creator" skill provides interactive guidance: Claude asks about your workflow, generates the folder structure, formats the SKILL.md file, and bundles the resources you need. No manual file editing required. &lt;/p&gt;
    &lt;p&gt;Enable Skills in Settings. For Team and Enterprise users, admins must first enable Skills organization-wide.&lt;/p&gt;
    &lt;head rend="h3"&gt;Claude Developer Platform (API)&lt;/head&gt;
    &lt;p&gt;Agent Skills, which we often refer to simply as Skills, can now be added to Messages API requests and the new &lt;code&gt;/v1/skills&lt;/code&gt; endpoint gives developers programmatic control over custom skill versioning and management. Skills require the Code Execution Tool beta, which provides the secure environment they need to run.&lt;/p&gt;
    &lt;p&gt;Use Anthropic-created skills to have Claude read and generate professional Excel spreadsheets with formulas, PowerPoint presentations, Word documents, and fillable PDFs. Developers can create custom Skills to extend Claude's capabilities for their specific use cases.&lt;/p&gt;
    &lt;p&gt;Developers can also easily create, view, and upgrade skill versions through the Claude Console.&lt;/p&gt;
    &lt;p&gt;Explore the documentation or Anthropic Academy to learn more.&lt;/p&gt;
    &lt;quote&gt;Skills teaches Claude how to work with Box content. Users can transform stored files into PowerPoint presentations, Excel spreadsheets, and Word documents that follow their organization's standards‚Äîsaving hours of effort.&lt;/quote&gt;
    &lt;quote&gt;With Skills, Claude works seamlessly with Notion - taking users from questions to action faster. Less prompt wrangling on complex tasks, more predictable results.&lt;/quote&gt;
    &lt;quote&gt;Canva plans to leverage Skills to customize agents and expand what they can do. This unlocks new ways to bring Canva deeper into agentic workflows‚Äîhelping teams capture their unique context and create stunning, high-quality designs effortlessly.&lt;/quote&gt;
    &lt;quote&gt;Skills streamline our management accounting and finance workflows. Claude processes multiple spreadsheets, catches critical anomalies, and generates reports using our procedures. What once took a day, we can now accomplish in an hour.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Claude Code&lt;/head&gt;
    &lt;p&gt;Skills extend Claude Code with your team's expertise and workflows. Install skills via plugins from the anthropics/skills marketplace. Claude loads them automatically when relevant. Share skills through version control with your team. You can also manually install skills by adding them to &lt;code&gt;~/.claude/skills&lt;/code&gt;. The Claude Agent SDK provides the same Agent Skills support for building custom agents. &lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude apps: User Guide &amp;amp; Help Center&lt;/item&gt;
      &lt;item&gt;API developers: Documentation&lt;/item&gt;
      &lt;item&gt;Claude Code: Documentation&lt;/item&gt;
      &lt;item&gt;Example Skills to customize: GitHub repository&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;We're working toward simplified skill creation workflows and enterprise-wide deployment capabilities, making it easier for organizations to distribute skills across teams.&lt;/p&gt;
    &lt;p&gt;Keep in mind, this feature gives Claude access to execute code. While powerful, it means being mindful about which skills you use‚Äîstick to trusted sources to keep your data safe. Learn more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/news/skills"/><published>2025-10-16T16:05:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45607758</id><title>Gemini 3.0 spotted in the wild through A/B testing</title><updated>2025-10-16T20:38:09.849250+00:00</updated><content>&lt;doc fingerprint="ef53a5961b3a9e93"&gt;
  &lt;main&gt;
    &lt;p&gt;So I kept reading rumors that Gemini 3.0 is accessible through Google AI Studio through A/B testing and the SVGs folks were posting (of Xbox controllers in particular) made me think that they might be right.&lt;/p&gt;
    &lt;p&gt;Gemini 3.0 is one of the most anticipated releases in AI at the moment because of the expected advances in coding performance.&lt;/p&gt;
    &lt;p&gt;Evaluating models is a difficult task, but surprisingly the SVG generation task seems to be a very efficient proxy for gauging model quality as @simonw has shown us using his ‚Äúpelican riding a bicycle‚Äù test.&lt;/p&gt;
    &lt;p&gt;Lo and behold, after trying a couple of times I got the A/B screen and got an SVG image of an Xbox 360 controller that looked VERY impressive compared to the rest of the frontier.&lt;/p&gt;
    &lt;p&gt;The exact prompt I used:&lt;/p&gt;
    &lt;code&gt;Create an SVG image of an Xbox 360 controller. Output it in a Markdown multi-line code block.
Like this:
```svg
...
```
&lt;/code&gt;
    &lt;p&gt;For what it‚Äôs worth the model ID for ‚ÄúGemini 3.0‚Äù was &lt;code&gt;ecpt50a2y6mpgkcn&lt;/code&gt; which doesn‚Äôt really help understand which version of the model it is. Perhaps since I user selected Gemini 2.5 Pro it is actually Gemini 3.0 Pro that it is pitted against, as comparing Gemini 3.0 Flash to Gemini 2.5 Pro in an A/B test makes less sense to me. Also, it had about 24s higher TTFT and output length was about 40% longer (this includes reasoning tokens AFAICT), but that doesn‚Äôt say much other than it‚Äôs likely not a ‚ÄúGPT-5 Pro‚Äù type answer that uses significant test time compute.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;p&gt;‚ÄúGemini 3.0‚Äù A/B result versus the Gemini 2.5 Pro model:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ricklamers.io/posts/gemini-3-spotted-in-the-wild/"/><published>2025-10-16T16:54:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45607822</id><title>SWE-Grep and SWE-Grep-Mini: RL for Fast Multi-Turn Context Retrieval</title><updated>2025-10-16T20:38:09.649163+00:00</updated><content>&lt;doc fingerprint="655e27db2dfa194a"&gt;
  &lt;main&gt;&lt;p&gt;TL;DR: We trained SWE-grep and SWE-grep-mini, fast agentic models specialized in highly parallel context retrieval. They match the retrieval capabilities of frontier coding models, while taking an order of magnitude less time. Available now in Windsurf‚Äôs new Fast Context subagent, and our new SWE-grep demo playground!&lt;/p&gt;&lt;p&gt;Modern coding agents face a fundamental tradeoff between speed and intelligence. Frontier models can solve complex tasks, but it can take minutes of searching before they edit a single file, breaking your flow. In Windsurf and Devin, we observed that our agent trajectories were often spending &amp;gt;60% of their first turn just retrieving context.&lt;/p&gt;&lt;p&gt;Context retrieval has been historically done in 2 ways:&lt;/p&gt;&lt;p&gt;This speed-intelligence tradeoff seemed inescapable until: We trained SWE-grep and SWE-grep-mini: models which match the retrieval capabilities of frontier coding models, while taking an order of magnitude less time. These models now power Fast Context, a subagent that helps you stay in flow.&lt;/p&gt;&lt;p&gt;We will be rolling Fast Context out progressively to Windsurf users, starting from the latest release. There is no required UI or command to try it - just use Windsurf Cascade as per normal. When you make a query that requires code search, Fast Context will trigger (you can also force it to trigger by submitting the query with &lt;code&gt;Cmd+Enter&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;Check out how Fast Context reduces the time it takes to understand large codebases:&lt;/p&gt;&lt;p&gt;You can try Fast Context yourself in our new playground: https://playground.cognition.ai/.&lt;/p&gt;&lt;p&gt;Since we are offering direct comparisons between our agent and alternative agents, we should mention what is going on here and our attempts to make it a fair comparison. We host all 3 agents - a Fast Context Agent stripped out of Windsurf, stock Claude Code, and stock Cursor CLI - in their own Modal containers and pipe the inputs/outputs through stdin/stdout. This is meant to reflect the experience of using each agent locally. This is not meant to be an extremely rigorous benchmark, just a demo experience we cooked up on the side to answer the obvious question of ‚Äúhow does Fast Context compare to what I‚Äôm used to outside of Windsurf?‚Äù You should run these tests in your own environment (with Fast Context in Windsurf) for best fidelity to your actual experience.&lt;/p&gt;&lt;p&gt;There are a few reasons why we think that context retrieval is a uniquely suited task for a custom subagent:&lt;/p&gt;&lt;code&gt;SWE-grep&lt;/code&gt; fast?&lt;p&gt;A few things were key to unlocking this level of intelligence at blazing-fast speeds:&lt;/p&gt;&lt;p&gt;Most coding agents take so long to fetch context because they only issue one (or a few) tool calls at a time. Each turn of tool calls incurs an additional prefill, an extra network roundtrip, and decoding overhead: to explore codebases as efficiently as possible, search subagents should be doing many tool calls in parallel.&lt;/p&gt;&lt;p&gt;While many models technically support parallel tool calls, it‚Äôs difficult to get them to use them effectively. Models are getting better than this‚ÄîSonnet in particular has improved greatly from 3.6 to 4.5‚Äîbut we felt that models didn‚Äôt exploit them optimally. Here is a rough sketch of the model design space that we targeted for &lt;code&gt;SWE-grep&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;Increasing parallelism also lets us use fewer tool calls. Across our ablations, we discovered that, by increasing the amount of parallelism from 4 to 8 searches per turn, we could reduce the number of turns spent searching from 6 to 4 while retaining the same performance.&lt;/p&gt;&lt;p&gt;We thus trained the &lt;code&gt;SWE-grep&lt;/code&gt; models to natively issue up to 8 parallel tool calls per turn in a maximum of 4 turns (3 turns of exploration and 1 turn for the answer). The SWE-grep models are given a restricted set of tool calls (&lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;read&lt;/code&gt;, &lt;code&gt;glob&lt;/code&gt;, ...) to ensure cross-platform compatibility (we have loads of Windows users!) and guarantee safety.&lt;/p&gt;&lt;p&gt;We train &lt;code&gt;SWE-grep&lt;/code&gt; directly with multi-turn reinforcement learning. Then we distill &lt;code&gt;SWE-grep&lt;/code&gt; into &lt;code&gt;SWE-grep-mini&lt;/code&gt; and perform additional reinforcement learning to boost the model‚Äôs performance on the task. Our reward function is an average of weighted F1 scores over file retrieval and line retrieval tasks, with respect to our ground truth dataset. This objective was sufficient for &lt;code&gt;SWE-grep&lt;/code&gt; to naturally learn to make more tool calls to its advantage over the course of training, without us explicitly incentivizing this behavior:&lt;/p&gt;&lt;p&gt;We‚Äôll explain some details about our training algorithm, a modified version of the policy gradient, and some tweaks that helped us keep training stable.&lt;/p&gt;&lt;p&gt;Given an LLM policy and outcome reward R, the policy gradient is given by&lt;/p&gt;&lt;p&gt;where the sum is over the tokens in a single trajectory. If we are able to sample from the training policy, we can use a simple Monte Carlo estimate for the gradient, which is unbiased when the data is on-policy. However, standard training and inference libraries have different numerics, which effectively turns the sampled data into off-policy data. This is amplified when using low-precision rollouts, a common optimization in RL frameworks. The solution is to apply importance sampling. Recent works have proposed using per-token importance sampling ratios. Per-token ratios, though, do not fully remove the bias. Indeed, at step t we have an action-choice mismatch, a state-distribution mismatch, and a reward-signal mismatch. A per-token ratio corrects only the action-choice mismatch. To derive an unbiased estimate, we apply per-sequence importance sampling&lt;/p&gt;&lt;p&gt;We expand at the token-level, subtract a leave-one-out baseline to reduce the variance, and rescale by a constant factor (absorbed in the learning rate), obtaining a surrogate loss (for a given prompt) that gives the correct gradient estimation (the notation []_‚àá denotes a stop gradient):&lt;/p&gt;&lt;p&gt;where we sample g completions from the same prompt for the Monte Carlo estimate, A‚±º = R‚±º - mean(R‚ÇÅ, ... ,R‚Çâ) and T_max is the maximum number of sampled tokens allowed during training (like Dr. GRPO).&lt;/p&gt;&lt;p&gt;A large number of parallel tool calls over multiple turns introduces a lot of tokens from the environment in the trajectories. These tokens are not generated by the model, leading to instabilities, especially when training small models. We found the following techniques to be helpful in stabilizing these runs:&lt;/p&gt;&lt;p&gt;To train SWE-grep and evaluate models on the context retrieval task, we used an internal dataset consisting of real-world repositories, user queries, and a labeled ground truth of relevant files and line ranges, drawn from our hardest bug reports and internal tests. We call this the Cognition CodeSearch Eval.&lt;/p&gt;&lt;p&gt;When evaluating models for context retrieval, we care about two metrics:&lt;/p&gt;&lt;p&gt;We use a weighted F1 score, where precision is prioritized over recall, precisely because we found that context pollution matters. We found that polluting the context of the main agent was more detrimental than leaving some context out, as the agent is typically only a few searches away to recover any remaining context. To evaluate models, we allow each model 4 turns of up to 8 parallel tool calls (searches, reads, etc.), and benchmark them on the above metrics.&lt;/p&gt;&lt;p&gt;Our results on our evaluation set demonstrate that SWE-grep and SWE-grep-mini are an order of magnitude faster than frontier models, while matching or outperforming them at context retrieval.&lt;/p&gt;&lt;p&gt;We also evaluated how well the SWE-grep models work when used as a subagent in larger agent pipelines.&lt;/p&gt;&lt;p&gt;Coding tasks. To evaluate how well it works in Windsurf‚Äôs Cascade agent, we use an randomly selected subset of difficult SWE-Bench Verified tasks. When using the Fast Context subagent, the agent (using Sonnet 4.5 as the main model) accomplishes the same number of tasks in significantly lower end-to-end time.&lt;/p&gt;&lt;p&gt;*on internal runners&lt;/p&gt;&lt;p&gt;**search file steps include greps, file reads, glob searches, etc.&lt;/p&gt;&lt;p&gt;Codebase Q&amp;amp;A. We show the end-to-end latency on some example queries over open-source repositories. As with our playground setup, we benchmark the Fast Context agent‚Äîas it would be used in Windsurf‚Äîagainst Claude Code and Cursor CLI by measuring end-to-end latency.&lt;/p&gt;&lt;p&gt;The Fast Context subagent in Windsurf is our first stepping stone on our roadmap for Fast Agents. The &lt;code&gt;SWE-grep&lt;/code&gt; models will be deployed in DeepWiki, Devin, Windsurf Tab and future products as we validate and tune for those use cases - future directions we want to explore include much more variable turn length, even higher intelligence, and tools speed optimizations.&lt;/p&gt;&lt;p&gt;End-to-end latency is a moderately non-consensus dimension of research for agent labs. In a world where coding agents grab headlines for having 2-30 hours of autonomy, the marketing incentive is to make agents slower, not faster. But we think the pendulum will swing the other way soon ‚Äî simply because we have the unfair advantage of seeing actual user behavior across sync and async code agents at massive scale.&lt;/p&gt;&lt;p&gt;The goal of Windsurf is to keep you in flow, which Mihaly Csikszentmihalyi defines as ‚Äúa state of complete absorption in an activity‚Äù. Roughly, we estimate that your P(breaking flow) geometrically increases 10% every second that passes while you wait for agent response, with the exact threshold varying based on perceived complexity of the request. The arbitrary ‚Äúflow window‚Äù we hold ourselves to is 5 seconds.&lt;/p&gt;&lt;p&gt;Our ultimate goal at the combined Cognition+Windsurf is to maximize your software engineering productivity, and we are simultaneously researching both the directions of pushing the frontier of coding agent autonomy -AND- making them faster given a ‚Äúgood enough‚Äù bar. The best mental model we‚Äôve found is the one we‚Äôve arrived at below - avoid the Semi-Async Valley of Death at all costs!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cognition.ai/blog/swe-grep"/><published>2025-10-16T16:59:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45608285</id><title>Mysterious Intrigue Around an x86 "Corporate Entity Other Than Intel/AMD"</title><updated>2025-10-16T20:38:09.380826+00:00</updated><content>&lt;doc fingerprint="7a5835c61a25b0f6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mysterious Intrigue Around An x86 "Corporate Entity Other Than Intel/AMD"&lt;/head&gt;
    &lt;p&gt; Posted to the Linux kernel mailing list and GNU Binutils mailing list today is an intriguing message from a longtime x86/x86_64 expert around a "a corporate entity other than Intel/AMD" using some x86 opcodes not used by AMD or Intel processors. &lt;lb/&gt;Longtime x86 expert Christian Ludloff posted a cryptic message to the LKML and Binutils mailing lists. An anonymous Phoronix reader in turn relayed the interesting occurrence to me. Christian Ludloff has worked for Google, AMD, TI, and others over the years as an x86 architecture expert as well as being known for his sandpile.org x86 CPU information site.&lt;lb/&gt;The subject for the mailing list posts by Christian Ludloff was x86 opcode/CPUID/MSR allocations and simply said:&lt;lb/&gt;These x86 opcodes and CPUs and MSR ranges now "in active use by a corporate entity other than Intel/AMD" makes this rather intriguing... And that it's a "corporate" entity rather than noting a research organization, hobbyist project, etc. And how said corporate entity has the legal ability to even work on a new x86-based implementation is interesting. For Christian Ludloff to be involved does give it additional weight.&lt;lb/&gt;As pointed out in the Phoronix Forums, it could be Zhaoxin. But as they have contributed GCC patches, Glibc patches, Linux kernel patches, etc, over the years it's not clear why they would go unnamed or have to relay the message via Ludloff rather than their prior direct mailing list posts.&lt;lb/&gt;For now that's all I know but rather interesting seeing this message from Ludloff today on the public mailing lists.&lt;/p&gt;
    &lt;p&gt;Longtime x86 expert Christian Ludloff posted a cryptic message to the LKML and Binutils mailing lists. An anonymous Phoronix reader in turn relayed the interesting occurrence to me. Christian Ludloff has worked for Google, AMD, TI, and others over the years as an x86 architecture expert as well as being known for his sandpile.org x86 CPU information site.&lt;/p&gt;
    &lt;p&gt;The subject for the mailing list posts by Christian Ludloff was x86 opcode/CPUID/MSR allocations and simply said:&lt;/p&gt;
    &lt;quote&gt;"If x86 opcode/CPUID/MSR allocations are not of your concern, then you can stop reading.&lt;lb/&gt;-------------------- 8&amp;lt; -------------------&lt;lb/&gt;I was asked to relay this to binutils/LKML.&lt;lb/&gt;As of 2025, the following are in active use by a corporate entity other than Intel/AMD.&lt;lb/&gt;Any collisions with them should be avoided.&lt;lb/&gt;- opcode 0Eh in PM64 - x86 PUSH CS that got removed by x86-64 in 2002; not used since&lt;lb/&gt;- opcode 0Fh,36h and opcode 0Fh,3Eh - there is a historic collision with Cyrix RDSHR, but that is not considered to be an issue&lt;lb/&gt;- opcode 0Fh,3Ah,E0h...EFh in classic, VEX, EVEX, Map3, and Map7 encodings, without a prefix, or CS/SS/DS/ES/FS/GS, LOCK, REPE/REPNE, or ASIZE/OSIZE/REX (but not REX2!) prefixes - a historic collision with K10M VCVTFXPNTPD2DQ (at MVEX opcode E6h prefix F2) exists but is not considered an issue&lt;lb/&gt;- opcode 0Fh,1Eh,/0 - a "hinting NOP" group&lt;lb/&gt;- CPUID range E000_xxxxh - unspecified leaf return values at this particular time&lt;lb/&gt;- MSR range E000_xxxxh - unspecified values after RESET - unchanged values after INIT&lt;lb/&gt;I have documented them at www.sandpile.org.&lt;lb/&gt;-------------------- 8&amp;lt; -------------------&lt;lb/&gt;--&lt;lb/&gt;C."&lt;/quote&gt;
    &lt;p&gt;These x86 opcodes and CPUs and MSR ranges now "in active use by a corporate entity other than Intel/AMD" makes this rather intriguing... And that it's a "corporate" entity rather than noting a research organization, hobbyist project, etc. And how said corporate entity has the legal ability to even work on a new x86-based implementation is interesting. For Christian Ludloff to be involved does give it additional weight.&lt;/p&gt;
    &lt;p&gt;As pointed out in the Phoronix Forums, it could be Zhaoxin. But as they have contributed GCC patches, Glibc patches, Linux kernel patches, etc, over the years it's not clear why they would go unnamed or have to relay the message via Ludloff rather than their prior direct mailing list posts.&lt;/p&gt;
    &lt;p&gt;For now that's all I know but rather interesting seeing this message from Ludloff today on the public mailing lists.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.phoronix.com/news/x86-Opcodes-Not-AMD-Or-Intel"/><published>2025-10-16T17:36:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45608456</id><title>Talent</title><updated>2025-10-16T20:38:09.129727+00:00</updated><content>&lt;doc fingerprint="7e1591173be606bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;On Talent&lt;/head&gt;
    &lt;p&gt;Quantity has a quality of its very own. Some writers are good - and they write all the time. The holy trinity of newsletter writers (Matt Levine, Byrne Hobart and Patrick McKenzie) write up to 700k words a year - so 2,000 words a day. I think Matt Levine‚Äôs schedule looks a little bit like waking up and doing 4000 words early in the morning about three times a week, then hitting send on his newsletter. Marc Rubinstein (another pretty prolific writer!) recently shared this Bloomberg profile of Jason Goldberg - ‚Äúa Barclays analyst who has been writing a daily briefing note for 20 years‚Äù. It‚Äôs not just newsletter writers - for instance, Philip Kerr managed to write 42 books in 29 years by just working obsessively, writing on birthdays and Christmas. Paul Erd√∂s had an even more insane work schedule:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;‚ÄúErd√∂s first did mathematics at the age of three, but for the last twenty-five years of his life, since the death of his mother, he put in nineteen-hour days, keeping himself fortified with 10 to 20 milligrams of Benzedrine or Ritalin, strong espresso, and caffeine tablets. "A mathematician," Erd√∂s was fond of saying, "is a machine for turning coffee into theorems." When friends urged him to slow down, he always had the same response: "There'll be plenty of time to rest in the grave."&lt;/p&gt;&lt;p&gt;Erd√∂s would let nothing stand in the way of mathematical progress. When the name of a colleague in California came up at breakfast in New Jersey, Erd√∂s remembered a mathematical result he wanted to share with him. He headed toward the phone and started to dial. His host interrupted him, pointing out that it was 5:00 A.M. on the West Coast. "Good," Erd√∂s said, "that means he'll be home."&lt;/p&gt;&lt;lb/&gt;‚Ä¶&lt;lb/&gt;Like all of Erd√∂s's friends, Graham was concerned about his drug-taking. In 1979, Graham bet Erd√∂s $500 that he couldn't stop taking amphetamines for a month. Erd√∂s accepted the challenge, and went cold turkey for thirty days. After Graham paid up--and wrote the $500 off as a business expense--Erd√∂s said, "You've showed me I'm not an addict. But I didn't get any work done. I'd get up in the morning and stare at a blank piece of paper. I'd have no ideas, just like an ordinary person. You've set mathematics back a month." He promptly resumed taking pills, and mathematics was the better for it.&lt;/quote&gt;
    &lt;p&gt; Looking at these guys, one feels a bit inadequate. How do they do it? Why aren‚Äôt you doing it? What did you get done this week?&lt;lb/&gt; One answer to this question is Scott Alexander‚Äôs essay is The Parable of the Talents. In the essay, he‚Äôs basically trying to square a circle: to reconcile the ideas that 1. natural talent exists and 2. everyone is morally equivalent. Alexander puts a lot of effort into proving point 1, and I think he does a great job. Here are the relevant sections. I agree with all of this, which is why I‚Äôm not trying to put it into my own words. But I‚Äôm particularly interested in his point that talent is a real thing, and some people are just better at things than others. He takes this really seriously. &lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;‚ÄúConsider for a moment Srinivasa Ramanujan, one of the greatest mathematicians of all time. He grew up in poverty in a one-room house in small-town India. He taught himself mathematics by borrowing books from local college students and working through the problems on his own until he reached the end of the solveable ones and had nowhere else to go but inventing ways to solve the unsolveable ones.&lt;/p&gt;&lt;p&gt;There are a lot of poor people in the United States today whose life circumstances prevented their parents from reading books to them as a child, prevented them from getting into the best schools, prevented them from attending college, et cetera. And pretty much all of those people still got more educational opportunities than Ramanujan did.&lt;/p&gt;&lt;p&gt;And from there we can go in one of two directions. First, we can say that a lot of intelligence is innate, that Ramanujan was a genius, and that we mortals cannot be expected to replicate his accomplishments.&lt;/p&gt;&lt;p&gt;Or second, we can say those poor people are just not trying hard enough.&lt;/p&gt;&lt;p&gt;‚Ä¶&lt;/p&gt;&lt;lb/&gt;In high school English, I got A++s in all my classes, Principal‚Äôs Gold Medals, 100%s on tests, first prize in various state-wide essay contests, etc. In Math, I just barely by the skin of my teeth scraped together a pass in Calculus with a C-.&lt;p&gt;Every time I won some kind of prize in English my parents would praise me and say I was good and should feel good. My teachers would hold me up as an example and say other kids should try to be more like me. Meanwhile, when I would bring home a report card with a C- in math, my parents would have concerned faces and tell me they were disappointed and I wasn‚Äôt living up to my potential and I needed to work harder et cetera.&lt;/p&gt;&lt;p&gt;And I don‚Äôt know which part bothered me more.&lt;/p&gt;&lt;p&gt;Every time I was held up as an example in English class, I wanted to crawl under a rock and die. I didn‚Äôt do it! I didn‚Äôt study at all, half the time I did the homework in the car on the way to school, those essays for the statewide competition were thrown together on a lark without a trace of real effort. To praise me for any of it seemed and still seems utterly unjust.&lt;/p&gt;&lt;p&gt;On the other hand, to this day I believe I deserve a fricking statue for getting a C- in Calculus I. It should be in the center of the schoolyard, and have a plaque saying something like ‚ÄúScott Alexander, who by making a herculean effort managed to pass Calculus I, even though they kept throwing random things after the little curly S sign and pretending it made sense.‚Äù&lt;/p&gt;&lt;p&gt;And without some notion of innate ability, I don‚Äôt know what to do with this experience. I don‚Äôt want to have to accept the blame for being a lazy person who just didn‚Äôt try hard enough in Math. But I really don‚Äôt want to have to accept the credit for being a virtuous and studious English student who worked harder than his peers.&lt;/p&gt;&lt;lb/&gt;‚Ä¶&lt;p&gt;When I was 6 and my brother was 4, our mom decided that as an Overachieving Jewish Mother she was contractually obligated to make both of us learn to play piano. She enrolled me in a Yamaha introductory piano class, and my younger brother in a Yamaha ‚Äòcute little kids bang on the keyboard‚Äô class.&lt;/p&gt;&lt;p&gt;A little while later, I noticed that my brother was now with me in my Introductory Piano class.&lt;/p&gt;&lt;p&gt;A little while later, I noticed that my brother was now by far the best student in my Introductory Piano Class, even though he had just started and was two or three years younger than anyone else there.&lt;/p&gt;&lt;p&gt;A little while later, Yamaha USA flew him to Japan to show him off before the Yamaha corporate honchos there.&lt;/p&gt;&lt;p&gt;Well, one thing led to another, and my brother won several international piano competitions, got a professorship in music at age 25, and now routinely gets news articles written about him calling him ‚Äúamong the top musicians of his generation‚Äù.&lt;/p&gt;&lt;p&gt;Meanwhile, I was always a mediocre student at Yamaha. When the time came to try an instrument in elementary school, I went with the violin to see if maybe I‚Äôd find it more to my tastes than the piano. I was quickly sorted into the remedial class because I couldn‚Äôt figure out how to make my instrument stop sounding like a wounded cat. After a year or so of this, I decided to switch to fulfilling my music requirement through a choir, and everyone who‚Äôd had to listen to me breathed a sigh of relief.&lt;/p&gt;&lt;p&gt;Every so often I wonder if somewhere deep inside me there is the potential to be ‚Äúamong the top musicians of my generation.‚Äù I try to recollect whether my brother practiced harder than I did. My memories are hazy, but I don‚Äôt think he practiced much harder until well after his career as a child prodigy had taken off.&lt;/p&gt;&lt;p&gt;‚Ä¶&lt;/p&gt;&lt;p&gt;I dunno. But I don‚Äôt think of myself as working hard at any of the things I am good at, in the sense of ‚Äúexerting vast willpower to force myself kicking and screaming to do them‚Äù. It‚Äôs possible I do work hard, and that an outside observer would accuse me of eliding how hard I work, but it‚Äôs not a conscious elision and I don‚Äôt feel that way from the inside.&lt;/p&gt;&lt;p&gt;‚Ä¶&lt;/p&gt;&lt;p&gt;But I still feel like there‚Äôs something going on here where the solution to me being bad at math and piano isn‚Äôt just ‚Äúsweat blood and push through your brain‚Äôs aversion to these subjects until you make it stick‚Äù. When I read biographies of Ramanujan and other famous mathematicians, there‚Äôs no sense that they ever had to do that with math. When I talk to my brother, I never get a sense that he had to do that with piano. And if I am good enough at writing to qualify to have an opinion on being good at things, then I don‚Äôt feel like I ever went through that process myself.&lt;/p&gt;&lt;lb/&gt;So this too is part of my deal with myself. I‚Äôll try to do my best at things, but if there‚Äôs something I really hate, something where I have to go uphill every step of the way, then it‚Äôs okay to admit mediocrity. I won‚Äôt beat myself up for not forcing myself kicking and screaming to practice piano. And in return I won‚Äôt become too cocky about practicing writing a lot.‚Äù&lt;/quote&gt;
    &lt;p&gt;Here‚Äôs a related piece - his Apologia pro vita sua.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúI have had a really busy few months. I think it will be letting up soon, but I‚Äôm not sure. And I‚Äôve told a lot of people who needed things from me, for one reason or another, ‚ÄúI‚Äôm sorry, I‚Äôm too busy to take care of this right now.‚Äù&lt;/p&gt;
      &lt;p&gt;And I worry that some of those people read my blog and think ‚ÄúWait, if you have enough time to write blog posts nearly every day, some of which are up to six thousand words long, why don‚Äôt you have enough time to do a couple of hours work for me?‚Äù&lt;/p&gt;
      &lt;p&gt;And the answer is ‚Äì you fancy doctors with your mathematics and subtraction might say that I could just take a couple of hours away from blogging and use those free hours to write that one thing or analyze that one study or whatever, but you‚Äôre not going to fool me.&lt;/p&gt;
      &lt;p&gt;Just as drugs mysteriously find their own non-fungible money, enjoyable activities mysteriously find their own non-fungible time. If I had to explain it, I‚Äôd say the resource bottleneck isn‚Äôt time but energy/willpower, and that these look similar because working hard saps energy/willpower and relaxing for a while restores it, so when I have less time I also have less energy/willpower. But some things don‚Äôt require energy/willpower and so are essentially free. Writing this is my addiction, so it‚Äôs free. Doesn‚Äôt mean anything else is.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Erd√∂s‚Äôs genius, then, was that his 19 hour workdays were ‚Äúessentially free‚Äù. He didn‚Äôt sweat blood and push though his brain‚Äôs aversion to doing maths - it must have come pretty naturally to him. So it‚Äôs really important to do things that come naturally to you.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs Jim Donovan talking about his SLA with clients while working as an investment banker:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWhen I started at Goldman Sachs ‚Ä¶ I would say to clients, you can leave me a voicemail, any time, unless I‚Äôm dead or asleep, I check it every ten seconds‚Ä¶ And I don‚Äôt sleep very long either.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I suspect that for Donovan, this didn‚Äôt feel like sweating blood - it was just how he was wired. Some people (not me!) are slow repliers, some people hate always being available, and those people are going to be terrible investment bankers and Jim Donovan is going to take their clients. Because for him, this stuff came naturally. He‚Äôs a 99.999th percentile voicemail replier. He was born to do it - and what‚Äôs awesome is that he found a way to turn his natural talent into loads of money.&lt;/p&gt;
    &lt;p&gt;I know professional writers that hear about Matt Levine and Scott Alexander‚Äôs work routine, and shake their heads. They produce a book every few years; they need to waste a few hours to get in the mindset to do anything. The can‚Äôt just jot down a paragraph here and there in their breaks. And yet even though they can‚Äôt hold themselves to that standard, they‚Äôre still professional writers. I mean, look how Hunter S. Thompson lived (yes, I know it‚Äôs not real):&lt;/p&gt;
    &lt;p&gt;My writing process doesn‚Äôt look much like Levine‚Äôs. I don‚Äôt have his consistency. The general pattern is that I spend weeks or months stewing on something, and then take a few hours and write it all down in one go, with minimal editing. That‚Äôs in contrast to a friend who told me recently that he spent two years writing 52 essays - one every two weeks, with metronomic consistency.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs an example from my finals. I had a coursework essay due at 12pm, and the night before, I went for dinner with my two best friends. At about 5am I had maybe the introduction written - and I felt my life flashing before my eyes. Was this going to be the moment I failed my finals? But because I‚Äôd spent six months thinking about the question on and off, over the next few hours I managed to write 2,000 words on the subject of ‚ÄúOnly God, not Man, makes an heir‚Äù: to what extent did Henry II‚Äôs legal reforms strengthen God‚Äôs hand?‚Äù, and got a 78 for my troubles - my best mark across all my papers.&lt;/p&gt;
    &lt;p&gt;Honestly, that was super fun - it wasn‚Äôt a sustainable or consistent way to get work done, but I enjoyed the pressure, I enjoyed the challenge, and I definitely enjoyed the 78. Writing seems to come to me in these spurts, which implies that I‚Äôm going to struggle to work with the consistency that Matt Levine achieves; ergo, I should not become a professional newsletter writer.&lt;/p&gt;
    &lt;p&gt; If you read enough finance books you start to pick up anecdotes about what makes a good trader. Lots of my friends are traders - there‚Äôs an archetype of ‚ÄúBritish Indian, studied economics at Cambridge, grew up in northwest London‚Äù that seems particularly successful - and so I‚Äôve had feedback on these ideas. These guys say that they see themselves in these quotes.&lt;lb/&gt; One useful trait is an extreme ability for self-control and rational thinking under pressure:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Bill [Gross] was to a large extent a trend follower, but he had a unique ability to know when it was time to lean against that trend and take a contrary position. There were numerous occasions where everyone else was scared shitless, and Bill put on his seat belt."&lt;/p&gt;&lt;p&gt;Pimco partner Ben Trosky, quoted in The Bond King&lt;/p&gt;&lt;lb/&gt;"When the financial stakes were high, though, [Steve] Cohen demonstrated an almost inhuman ability to stay calm and make rational trading decisions.&lt;lb/&gt;‚Ä¶&lt;lb/&gt;It was practically a genetic anomaly, this ability to behave like a reptile when he was trading, as opposed to a human being prone to fear and self-doubt. When he interviewed new hires he tried to test for this quality as best he could."&lt;p&gt;Sheelah Kolhatkar, Black Edge&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;Another is being inscrutable. For example, people talked about John Meriwether from LTCM like this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúJohn has a steel-trap mind. You have no clue what he's thinking.‚Äù&lt;/p&gt;
      &lt;p&gt;William McIntosh (who hired Meriwether into Salomon Brothers), quoted in When Genius Failed&lt;/p&gt;
      &lt;p&gt;‚ÄúHe wore the same blank half-tense expression when he won as he did when he lost. He had, I think, a profound ability to control the two emotions that commonly destroy traders - fear and greed - and it made him as noble as a man who pursues his own interest so fiercely can be."&lt;/p&gt;
      &lt;p&gt;Michael Lewis, writing about Meriwether‚Äôs time at Salomon in Liar‚Äôs Poker&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Mostly, though, the key is to be an obsessive:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúMy interview with the company - that is, with [Thomas] Peterffy - was memorable. It took place it his apartment in Greenwich, where his butler (his butler!) served us drinks. I made an offhand joke about programming, and he chided me for not having respect for the practice. He told me: 'To be successful in this business, you have to think about it all the time. Lots of people in this business are very smart, but not everyone can think about it all the time.' These words - you have to think about it all the time - made a deep impression on me. Peterffy's phrase has pretty much become my motto - at least, it's one of them. At the time, I was struck by how simple and obvious it was. In fact, it was exactly what I did when I was faced with a complex programming challenge.‚Äù&lt;/p&gt;
      &lt;p&gt;Igor Tulchinsky, talking about how he came to work at Timber Hill (a Connecticut prop trading firm) in The Unrules&lt;/p&gt;
      &lt;p&gt;"Intentionally isolated, he said, 'a quiet oasis of serenity.'&lt;/p&gt;
      &lt;p&gt;Serene for him, maybe, but his personality mangled whatever peace the rest of them could have enjoyed. The place was suffused with Gross's clinical insecurity that someone might catch up, that someone might threaten Pimco's dominance.&lt;/p&gt;
      &lt;p&gt;No moment wasted, no dollar left unsqueezed. This was the dominant culture, trickled down from the trade floor: Gross's 'Pimbots' ground their teeth in their sleep and woke up screaming: their marriages and livers disintegrated. It was precisely that they were so intensely obsessive, going beyond what everyone else did, that made them so great, they had to convince themselves...&lt;/p&gt;
      &lt;p&gt;Failure to deliver wasn't tolerated. Pimco would sniff out anyone's weakness."&lt;/p&gt;
      &lt;p&gt;Mary Childs discussing Bill Gross‚Äôs decision to locate Pimco in Newport Beach, in The Bond King&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; And finally, a quote that hits the nail on the head - even though it doesn‚Äôt come from a trader:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"A man has to live and sleep with his business if he wants to make a go of it. You have to take it home with you at night, so you can lie there in the darkness and figure out what you can do to improve it. In fact, you have to become sort of a 'nut' about it, so that you become so enthused that you will bore your friends talking about it. You have to be a one-man crusade."&lt;/p&gt;
      &lt;p&gt;George Mecherle‚Äôs answer to the question, ‚Äúwhat is the secret of your success?‚Äù, in The Farmer from Merna&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Nassim Taleb once said, "unless you're a trader, don't trade. Unless you're a baker, don't bake. Unless you're a dynamite maker, don't make dynamite." I think unless you can see yourself in at least some of those quotes, you probably shouldn‚Äôt be a trader.&lt;/p&gt;
    &lt;p&gt;I once spent a huge amount of effort on something in which I had zero natural talent.&lt;/p&gt;
    &lt;p&gt;I started playing rugby at seven years old. I was always pretty useless, but I always tried really hard. I remember deciding age 12 that I wanted to be better, so one day, at my (boarding) prep school, I woke up early, got a tackle bag, and started doing tackle practice - on my own, at 7am. A teacher walked by, and said ‚Äòwhat are you doing?‚Äô Slightly sheepishly, I packed up the bag and went back inside. I didn‚Äôt get picked to go on the rugby tour, and never played for the U13 A team. When I went to secondary school, I was, again, rubbish - I think at one point I played for the U14 D team. And then, in October 2014, Bath, my favourite rugby union team, signed Sam Burgess: the Yorkshire-born Australian rugby league star. I watched his documentary on YouTube, and it changed my life. The Russell Crowe narration at the start made a huge impression on me:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúNow I have this theory about a certain kind of player. Like a Ron Coote, a Steve Menzies, a Gorden Tallis. I call it the Sparkly-Eyed Man. He‚Äôs a man who can be as vicious as he needs to be over the course of eighty minutes to get a result for his team. And the moment that final whistle is blown he‚Äôs a completely different person. He‚Äôs able to laugh easily, he‚Äôs good with kids, respectful to women, and he appreciates life. Which is why he‚Äôs the Sparkly-Eyed Man. He has that thing built within him to never quit, and if you‚Äôre going to do something, you do it to the absolute utmost of your ability. Those sparkly-eyed men, they carve their names deep in Rugby League.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sam Burgess won the 2014 NRL Grand Final with South Sydney, just before he left for Bath. He broke his cheekbone in the opening tackle of the game, was man of the match, and won the Bunnies their first premiership in 43 years.&lt;/p&gt;
    &lt;p&gt;This blew my mind. I wanted to be that guy. As a teenager, I absorbed all the sports motivational videos on YouTube. I watched this one, I watched this one, and this one above all. This stuff is burned into the back of my skull. I watched these things over and over again. I tried to figure out how to set them as an alarm.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;‚ÄúWhen you immerse yourself in your craft, you not studying to get a grade, you‚Äôre not playing to score points, you immerse yourself in it, so you become it, you gon‚Äô go to another level.&lt;/p&gt;&lt;lb/&gt;The most important thing is this: to be able to sacrifice yourself at any moment, to sacrifice what you are, for what you will become. Listen to me. Pain is temporary. It may last for a minute, or an hour, or a day, or even a year, but eventually it will subside. And something else will take its place. You ain‚Äôt gon‚Äô die. At the end of pain is success! You‚Äôre not gon‚Äô die because you‚Äôre feeling a little pain! I dare you to take a little pain. I dare you.&lt;lb/&gt;Your life is in your hand. You are the captain of your ship. You could have, you could be, you could do whatever you want to do, remember boy, if it was easy, everybody would do it. It‚Äôs what they eat, it‚Äôs what they sleep, it‚Äôs what they drink, it possesses them.‚Äù&lt;/quote&gt;
    &lt;p&gt; So I decided I was going to play for the school first XV. I had about two and a half years to get ready. Let‚Äôs be honest, there wasn‚Äôt that much pain involved in that process - not like the pain Ray Lewis, who‚Äôs quoted in the speech above, had growing up. But this was the most difficult a quest I could find. A lot of people told me I couldn‚Äôt do it - my tutor, the U16A coach, told me I‚Äôd never play for the first XV.&lt;lb/&gt; I ate so much food I vomited. I drank a gallon of milk a day. I did squats until my nose bled. Here‚Äôs me, age 16, pulling 180 at Villain Strength in Mill Hill; and age 17, squatting 140x5 in my South Sydney jersey.&lt;/p&gt;
    &lt;p&gt;And ultimately, it worked. I played a few games for the XV. I proved the doubters wrong. I achieved my goal. And I was still actually pretty useless at rugby.&lt;/p&gt;
    &lt;p&gt; I knew what it felt like to be effortlessly good at something, because I had that academically; when it came to maths tests, spelling bees, quizzes - I just had it. ‚ÄúDo you know how easy this is for me? Do you have any fucking idea how easy this is? This is a fucking joke! And I'm sorry you can't do this, I really am because I wouldn't have to fucking sit here and watch you fumble around and fuck it up.‚Äù In the classroom, I was Will Hunting; on the rugby pitch, I fumbled around and fucked it up. &lt;lb/&gt; It didn‚Äôt matter that I‚Äôd spent three years getting bigger and stronger and fitter and faster - I still wasn‚Äôt anywhere near the level of the players with actual talent. They could see the game, they knew how to be in the right place at the right time, they could throw the final pass - and I had spent enough time trying to be like that that I knew I never could. I spent 8 years at school with a guy who‚Äôs probably going to be an Olympic hurdler this year; he had talent. And so it didn‚Äôt matter how many Tri-Nations games I watched or how many pushups I did, because I‚Äôd never get it like they did. I had worked as hard as I could, and it wasn‚Äôt ever going to be good enough.&lt;lb/&gt; That was my Scott Alexander sweating blood experience. I learned what it felt like to stick with something. But my learning from that experience was that next time I should make sure I sweated blood working on a strength. Do more of what comes naturally.&lt;/p&gt;
    &lt;p&gt; I‚Äôve spent the last few years trying to figure out what that is. I studied linear algebra, I read Marsilius of Padua, I wrote essays, I wrote SQL, I managed ad campaigns, I travelled the world selling software, I hired and fired a team, I tried to respond to messages in 10 seconds, I networked my way into industries and learned what makes them tick, and I raised some venture capital. Some of that felt natural; some of it didn‚Äôt. I‚Äôm still looking for what comes next. &lt;lb/&gt; I was in LA last week, on a mission to meet great people. The best person I met was the World‚Äôs Strongest Man, Martins Licis, at his gym in El Segundo. It was a complete accident; I didn‚Äôt know he was there, and I didn‚Äôt expect to work out that day. But the reason I was able to walk in and learn strongman from the best in the world was all those hours spent under a bar, squatting until my nose bled. &lt;lb/&gt; So I guess it‚Äôs ok to bake bread even if you‚Äôre not a baker - we‚Äôre all allowed hobbies. Just don‚Äôt make it your full-time job. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.felixstocker.com/blog/talent"/><published>2025-10-16T17:47:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45608795</id><title>test-ipv6.com will stay online</title><updated>2025-10-16T20:38:08.793768+00:00</updated><content>&lt;doc fingerprint="6e39dbdd18ab35e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Update: test-ipv6.com will stay online!&lt;/head&gt;
    &lt;p&gt;After announcing its retirement, many generous people and organizations offered help - thank you! The project is now transitioning to an RIR (Regional Internet Registry), which will continue running the site in the public interest. I'll share updates as things progress.&lt;/p&gt;
    &lt;head&gt;Click to see the previous message&lt;/head&gt;
    &lt;head rend="h2"&gt;Previous message&lt;/head&gt;
    &lt;p&gt;TL;DR: I will retire test-ipv6.com in December 2025.&lt;/p&gt;
    &lt;p&gt;I have provided test-ipv6.com to the public since 2010. I've sunk significant resources - engineering, support, equipment, and hosting fees - into what is a revenue-free product.&lt;/p&gt;
    &lt;p&gt;Without going into details: I feel now is the time for me to refocus my resources within the family.&lt;lb/&gt; I hope people will understand, and respect this decision.&lt;/p&gt;
    &lt;p&gt;I am shutting the site down, with a target of "during winter break" (December) 2025.&lt;/p&gt;
    &lt;p&gt;Mirror operators: Should you wish to keep your mirrors up, they will stop getting updates in December.&lt;/p&gt;
    &lt;p&gt;Service providers: If you have runbooks for your support team based on this site, or based on RIPE-631, you'll need to update those.&lt;/p&gt;
    &lt;p&gt;FAQ:&lt;/p&gt;
    &lt;p&gt;Q: Will I (jfesler) transfer the source?&lt;/p&gt;
    &lt;p&gt;A: These portions are already public.&lt;/p&gt;
    &lt;p&gt;These are already public.&lt;lb/&gt; http://github.com/falling-sky/source&lt;lb/&gt; https://github.com/falling-sky/fsbuilder - used to build what's in source&lt;lb/&gt; https://github.com/falling-sky/mod_ip - the /ip/ handler for Apache&lt;lb/&gt; https://github.com/falling-sky/mtu1280d - the synthetic MTU180 netfilter daemon.&lt;/p&gt;
    &lt;p&gt;The remaining parts, such as geolocation and service provider lookups, I am contractually unable to release. Please do not ask.&lt;/p&gt;
    &lt;p&gt;Q: What about monitoring and validation?&lt;/p&gt;
    &lt;p&gt;Delan Azabani has shared with me https://codeberg.org/shuppy/fallen-sky, which includes a standalone validator.&lt;/p&gt;
    &lt;p&gt;Q: Will I (jfesler) transfer the domain?&lt;/p&gt;
    &lt;p&gt;A: I'd consider a reputable RIR or NIC organization serving the public interest taking things over.&lt;/p&gt;
    &lt;p&gt;Q: Should mirrors be retired?&lt;/p&gt;
    &lt;p&gt;A: I would suggest it. Once the primary site is retired, I will stop monitoring the functionality of your mirror, and stop providing geolocation and service provider lookups.&lt;/p&gt;
    &lt;p&gt;Q: I have more questions or comments!&lt;/p&gt;
    &lt;p&gt;A: If we ever meet for coffee or beer, ask me then.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://status.test-ipv6.com"/><published>2025-10-16T18:13:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45608887</id><title>A conspiracy to kill IE6 (2019)</title><updated>2025-10-16T20:38:08.562788+00:00</updated><content>&lt;doc fingerprint="37659024b9a457cb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Conspiracy To Kill IE6&lt;/head&gt;
    &lt;p&gt;The bittersweet consequence of YouTube‚Äôs incredible growth is that so many stories will be lost underneath all of the layers of new paint. This is why I wanted to tell the story of how, ten years ago, a small team of web developers conspired to kill IE6 from inside YouTube and got away with it.&lt;/p&gt;
    &lt;p&gt;I do not recall the exact triggering event that led to our web development team laying out plans to kill IE6 over lunch in the YouTube cafeteria. Perhaps it was the time I pushed out a CSS stylesheet that included an attribute selector on a semi-supported HTML element. Any reasonable web developer would expect this to be ignored by browsers not up to the task. This was not the case with older flavors of IE. Under very specific conditions, an attribute selector on an unsupported HTML element in IE would create an internal recursion that would at best, cause the browser to crash and at worst, trigger a blue screen of death. Or perhaps it was the hundredth time one of our software engineers had innocently pushed out an &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag with an empty src attribute. Nobody joining the team could be expected to know that in early versions of IE, the browser would load the root path ‚Äú/‚Äù for empty src attributes. The &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag would suddenly behave like an &lt;code&gt;&amp;lt;iframe&amp;gt;&lt;/code&gt;, loading our homepage and all of its dependent resources in what could become an exponentially expanding recursive loop. Whenever an empty image tag found its way on to the homepage, it was all-hands-on-deck emergency to locate and replace the offending code before we melted our servers into paperweights.&lt;/p&gt;
    &lt;p&gt;Regardless of whatever the event at that time was, it had been brutal and it had been IE6 related. IE6 had been the bane of our web development team‚Äôs existence. At least one to two weeks every major sprint cycle had to be dedicated to fixing new UI that was breaking in IE6. Despite this pain, we were told we had to continue supporting IE6 because our users might be unable to upgrade or might be working at companies that were locked in. IE6 users represented around 18% of our user base at that point. We understood that we could not just drop support for it. However, sitting in that cafeteria, having only slept about a few hours each in the previous days, our compassion for these users had completely eroded away. We began collectively fantasizing about how we could exact our revenge on IE6. One idea rose to the surface that quickly captured everyone‚Äôs attention. Instead of outright dropping IE6 support, what if we just threatened to? How would users react? Would they revolt against YouTube? Would they mail death threats to our team like had happened in the past? Or would they suddenly become loud advocates of modern browsers? We openly daydreamed about cubicle workers around the world suddenly inventing creative ‚Äúbusiness‚Äù reasons for needing upgraded browsers. Grandparents would hold their technically savvy grand-kids hostage, demanding they fix their ‚ÄúYouTubes‚Äù. What had begun as a team therapy session started to materialize into an actual plan, a plan we quickly realized we were uniquely positioned to execute on.&lt;/p&gt;
    &lt;p&gt;The plan was very simple. We would put a small banner above the video player that would only show up for IE6 users. It would read ‚ÄúWe will be phasing out support for your browser soon. Please upgrade to one of these more modern browsers.‚Äù Next to the text would be links to the current versions of the major browsers, including Chrome, Firefox, IE8 and eventually, Opera. The text was intentionally vague and the timeline left completely undefined. We hoped that it was threatening enough to motivate end users to upgrade without forcing us to commit to any actual deprecation plan. Users would have the ability to close out this warning if they wanted to ignore it or deal with it later. The code was designed to be as subtle as possible so that it would not catch the attention of anyone monitoring our checkins. Nobody except the web development team used IE6 with any real regularity, so we knew it was unlikely anyone would notice our banner appear in the staging environment. We even delayed having the text translated for international users so that a translator asking for additional context could not inadvertently surface what we were doing. Next, we just needed a way to slip the code into production without anyone catching on.&lt;/p&gt;
    &lt;p&gt;It turned out that a handful of us had entered YouTube at an interesting time‚Ä¶ several months after YouTube had been acquired by Google but before Google had begun deeply integrating YouTube into their larger organization. The early YouTube engineers were rightfully territorial and initially hesitant to adapt to Google‚Äôs infrastructure and norms. With their penchants for gray-hat hacking, fast cars, and hard whiskey and an uncommon number of piercings, tattoos, and minor arrest records, many had been rejected during previous Google interviews. Ending up at YouTube instead, they found themselves breaking their backs to stay ahead of exponentially growing traffic while having to constantly defend against critics explaining how Google Video would imminently kill them. By the time they were acquired into Google, many of these engineers had come to view their outcast identity as a critical component of their eventual success.&lt;/p&gt;
    &lt;p&gt;To cement their authority over the YouTube codebase during the integration into Google, the early engineers created a specialized permission set called ‚ÄúOldTuber‚Äù. OldTuber granted you the ability to completely bypass the new Google-oriented code enforcement policies, enabling anyone holding it to commit code directly to the YouTube codebase, with only the most glancing of code reviews from anyone. No need for code readability. No need for exhaustive tests. No need for maintaining code coverage. If you broke the site by improperly wielding OldTuber status, it was on your head and you would lose the privilege immediately, if not your job. So you just had to be a good citizen and never break the site. Our boss, an early YouTube engineer himself, had gone out of his way to ingratiate the web development team with the rest of the early YouTube engineers. Through his efforts, a couple of us eventually found ourselves in possession of OldTuber status, despite never having been a part of the original team. It was like we were just walking down the street when someone mistook us for valets and handed us the keys to their Ferrari. For better or for worse, we were not exactly the types to just hand the keys back and walk away. We saw an opportunity in front of us to permanently cripple IE6 that we might never get again. If this went at all wrong, a number of us would surely be fired. Our most renegade web developer, an otherwise soft-spoken Croatian guy, insisted on checking in the code under his name, as a badge of personal honor, and the rest of us leveraged our OldTuber status to approve the code review. The code merged into production and our banner went live a few days later.&lt;/p&gt;
    &lt;p&gt;The first person to come by our desks was the PR team lead. He was a smart, dapper man who was always bubbling with energy and enthusiasm. Except this time. This time he was uncharacteristically prickly. He had come in on an otherwise normal day to find email from every major tech news publication asking why the second largest website on the planet was threatening to cut off access to nearly a fifth of its user base. Fortunately for us, the publications had already settled on a narrative that this was a major benefit to the Internet. By their call, YouTube was leading the charge towards making the web a faster, safer experience for all of its users. The entire PR team had Macs running Chrome and could not even see what we had done, let alone issue comments to the press on any of it. They were caught completely unaware. We eagerly told them everything about what we had launched and helped them craft the necessary talking points to expand on the narrative already established by the media. Satisfied that he could get back in front of the story, the PR team lead turned and warned us to never do anything like this without telling him first. He did not want to let great public relations opportunities like this slip by ever again.&lt;/p&gt;
    &lt;p&gt;Next came the lawyers. Two senior lawyers sprinted over to our desks in a state of buttoned-down panic. They immediately demanded that we remove the banner. We explained how we would need the SREs to do an emergency push and that it would take at least a few hours to do. Frustrated, one of the lawyers asked ‚ÄúWhy did you have to put Chrome first?‚Äù Confused, I explained that we did not give any priority to Chrome. Our boss, in on the conspiracy with us, had thoughtfully recommended that we randomize the order of the browsers listed and then cookie the random seed for each visitor so that the UI would not jump around between pages, which we had done. As luck would have it, these two lawyers still used IE6 to access certain legacy systems and had both ended up with random seeds that placed Chrome in the first position. Their fear was that by showing preferential treatment to Chrome, we might prick the ears of European regulators already on the lookout for any anti-competitive behavior. While the lawyers conceded that nothing we had done would have likely risen to that level of offense, it had happened on their watch and they did not appreciate that. I repeatedly cleared the cookies in my copy of IE6 and showed the browsers reshuffling with each refresh. Content with the demonstration, the lawyers quickly retreated back to their desks without any further concerns.&lt;/p&gt;
    &lt;p&gt;I expected the next people to be the engineering managers and that they would be the angriest given how clearly we had abused our OldTuber status. Suspiciously, nobody came by that day. The next day, a handful of engineers stopped by to congratulate us on the launch of the banner after reading articles around the Internet, but that was it. I asked my boss if he was getting any blowback and he shrugged, indicating that nobody had pulled him aside yet. It seemed that for the moment we were in the clear. Surprised and unable to make sense of this, I probed one of the managers about what he thought about the banner launching. He responded ‚ÄúOh, I just figured you guys copied the banner that Google Docs had put up.‚Äù I was confused. How could Google Docs have beaten us to the punch on this? I opened up Google Docs in IE6 and sure enough, a banner very much like ours was showing at the top. It implored their users to upgrade to avoid breaking features in terms similarly vague to ours.&lt;/p&gt;
    &lt;p&gt;I had met a few engineers on the Google Docs team while working on some shared Javascript libraries. I reached out to one and asked how they had arrived at the decision to launch their own banner. He explained to me that they had been wanting to deprecate IE6 support for a long time but their managers would not let them for the same reasons we had always heard. One of their engineers testing in IE6 had noticed the YouTube banner pretty shortly after it went live and immediately took it to their manager as evidence as to why they should do the same. Shortly thereafter, the Google Docs engineers whipped up their own IE6 banner and pushed it into production, presumably under the mistaken assumption that we had done our diligence and had received all of the necessary approvals. The first time many Googlers heard chatter about IE6 banners was from email threads where other teams had begun asking if they could deprecate IE6 like Google Docs had. Luck would have it that this had included many of our managers. Amazingly, we had somehow bypassed detection as the originators of the IE6 banner inside of Google.&lt;/p&gt;
    &lt;p&gt;Eventually the YouTube engineering management did ask themselves how the decision to deprecate IE6 was ultimately made, given it happened so quickly and seemed conspicuously premature for a media site of our scale and with such a wide user base. Once they realized what had happened, they cornered our boss for details, grappled with the consequences of our actions and begrudgingly arrived at the conclusion that the ends had justified the means. Between YouTube, Google Docs, and several other Google properties posting IE6 banners, Google had given permission to every other site on the web to add their own. IE6 banners suddenly started appearing everywhere. Within one month, our YouTube IE6 user base was cut in half and over 10% of global IE6 traffic had dropped off while all other browsers increased in corresponding amounts. The results were better than our web development team had ever intended.&lt;/p&gt;
    &lt;p&gt;We somehow got away with our plan to kill IE6 without facing any meaningful corrective action. Few people even knew we were involved at all and those that did, did not want to bring attention to it or risk encouraging similar behavior. At a beer garden in San Francisco, our boss, winking his hardest, made us swear to never do anything like this again. We agreed, toasted IE6 falling into single digit percentages, and never snuck anything into production again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.chriszacharias.com/a-conspiracy-to-kill-ie6"/><published>2025-10-16T18:22:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45609922</id><title>Benjie's Humanoid Olympic Games</title><updated>2025-10-16T20:38:08.481745+00:00</updated><content/><link href="https://generalrobots.substack.com/p/benjies-humanoid-olympic-games"/><published>2025-10-16T19:51:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45609942</id><title>Show HN: We priced basic needs in work hours (global ranking and CSVs)</title><updated>2025-10-16T20:38:08.234348+00:00</updated><content>&lt;doc fingerprint="52ee1cd11ab096e9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Work Hours to Afford Essentials: Best and Worst Countries&lt;/head&gt;
    &lt;p&gt; Published on | Prices Last Reviewed for Freshness: October 2025&lt;lb/&gt; Written by Alec Pow - Economic &amp;amp; Pricing Investigator | Content Reviewed by CFA Alexander Popinker&lt;/p&gt;
    &lt;p&gt;Educational content; not financial advice. Prices are estimates; confirm current rates, fees, taxes, and terms with providers or official sources.&lt;/p&gt;
    &lt;p&gt;Which Countries make you work the least (and the most) to cover basic needs? And where does the U.S. stand?&lt;/p&gt;
    &lt;p&gt;Plain-English promise: We priced the same monthly starter basket everywhere, rent for a modest apartment, utilities (electricity + gas), basic groceries, getting around, and everyday essentials, then ranked countries by how many hours a typical worker must work to pay for it. We highlight where you need the least and the most hours‚Äîand exactly where the U.S. sits in between. Lower hours = better.&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR ‚Äî winners on top&lt;/head&gt;
    &lt;head class="pricer-jump-summary" aria-controls="pricer-jump-track" aria-expanded="false"&gt;Jump to sections&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Winners (fewest hours): Bolivia ~80 h, Nicaragua ~81 h, Romania ~84 h, Turkey ~90 h, Zambia ~106 h ‚Äî roughly 10‚Äì13 workdays a month to cover the basics.&lt;/item&gt;
      &lt;item&gt;Strugglers (most hours, press window 80‚Äì220): Antigua &amp;amp; Barbuda ~219 h, Portugal ~219 h, Ghana ~211 h, Finland ~205 h, Sweden ~203 h ‚Äî 25‚Äì27 workdays.&lt;/item&gt;
      &lt;item&gt;United States: 140.0 h/month (~17.5 workdays). Better than ~74% of countries in our publishable set, but only #11 of 42 globally. In the OECD-only table, the U.S. is #5 of 38 (only Turkey, Lithuania, Poland, Slovenia need fewer hours).&lt;/item&gt;
      &lt;item&gt;Extremes (OECD, out-of-window): Mexico 323.2 h (highest), Israel 288.8 h; also Japan 259.6, Greece 258.7, Ireland 243.9, New Zealand 235.3, Slovakia 232.0, Estonia 221.0 ‚Äî see ‚ÄúExtremes‚Äù below &amp;amp; OECD CSV.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;What WTEI measures (and what those hours actually mean)&lt;/head&gt;
    &lt;p&gt;We hold the basket constant to keep the comparison fair. Then two forces decide your place in the ranking:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prices in your country for each component of the basket (via the World Bank‚Äôs ICP 2021 price parities).&lt;/item&gt;
      &lt;item&gt;Your country‚Äôs typical take-home hourly pay (OECD net pay where available; otherwise a clearly flagged ILOSTAT gross proxy).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;WTEI is simply basket cost √∑ hourly pay ‚Üí hours per month. It‚Äôs the most intuitive unit we could think of: how much of your month disappears just to stand still.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Interpretation guide: ‚â§130 h/mo feels livable. &amp;gt;150 h/mo starts to bite. ~200+ h/mo means most of your work month goes to rent, lights, groceries, and getting around.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;The U.S. Data, Explained&lt;/head&gt;
    &lt;p&gt;140.0 hours/month (‚âà 17.5 workdays). That puts the U.S. better than ~74% of countries in our publishable set, but #11 of 42 globally‚Äînot a podium finish. Why does the U.S. not look terrible even with high rents? Because WTEI is time, and time is shaped by the denominator. Net hourly pay in the U.S. is high. When pay is strong, it offsets part of a pricey basket. That‚Äôs why countries with cheaper prices can still rank worse if typical take-home pay is too low. Two more anchors make the U.S. position easy to grasp:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Neighbor check: the U.S. sits between Slovenia (~134.8 h) and Austria (~141.1 h), close peers in the table.&lt;/item&gt;
      &lt;item&gt;OECD check: compared with the OECD median (~192.9 h), the U.S. advantage is equivalent to +$10.94/hour more pay or a ‚Äì27.4% cheaper basket (holding the other lever fixed). That‚Äôs the size of the gap you‚Äôd need to erase to be ‚Äúaverage‚Äù among rich countries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And a fair nuance: our default hourly pay uses a flat 2,080 h/yr. Many European economies work fewer hours per year; switching to actual hours lifts their hourly pay and lowers their WTEI (we find roughly a ~16% drop in a sensitivity). That change nudges the U.S. down a few places in the OECD slice. We can publish both versions for transparency.&lt;/p&gt;
    &lt;head rend="h2"&gt;Winners: What‚Äôs Going Right&lt;/head&gt;
    &lt;p&gt;Bolivia (~80 h) and Nicaragua (~81 h) are the purest illustration of how WTEI works. Their baskets are cheap in time terms because the big, non-negotiable costs‚Äîrent and utilities‚Äîare low compared with the U.S., and typical pay isn‚Äôt so low that it erases those gains. In practice, that means roughly ten workdays fund the basics each month‚Äîleaving more calendar for everything else.&lt;/p&gt;
    &lt;p&gt;Romania (~84 h) is the EU eye-opener. It marries EU-level infrastructure with lower housing and utilities price levels than Western Europe. Pay has climbed enough in recent years that, when you divide that same basket by take-home hourly pay, you land in the global top tier. This is what ‚Äútime-to-afford‚Äù picks up that price charts miss.&lt;/p&gt;
    &lt;p&gt;Turkey (~90 h) and Zambia (~106 h) show two different paths to a similar outcome. In one case, component prices are low relative to income; in the other, the mix of prices (especially housing/utilities) is favorable enough that a typical paycheck stretches far in time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Strugglers: what‚Äôs getting in the way&lt;/head&gt;
    &lt;p&gt;Antigua &amp;amp; Barbuda (~219 h) is Island Economics 101: food and transport carry import and distance premiums; wages don‚Äôt fully keep pace. Stack those costs onto even a modest rent and you pass 200 hours (most of the month) just to buy the basics.&lt;/p&gt;
    &lt;p&gt;Portugal (~219 h) defies the ‚Äúcheap rent fixes everything‚Äù myth. Even if rent isn‚Äôt off the charts, food and transport relative to take-home pay can push a country into the time-heavy zone. That‚Äôs the denominator at work: when net hourly pay is on the lower side for the OECD, you need more time to fund the same basket.&lt;/p&gt;
    &lt;p&gt;Ghana (~211 h) brings the point home from the other direction. If food and transport sit near U.S. price parity, but pay is low, hours explode‚Äîeven when rent itself looks cheap. In WTEI terms, it‚Äôs the combination that matters.&lt;/p&gt;
    &lt;p&gt;Finland (~205 h) and Sweden (~203 h) remind us: rich ‚â† automatic winner. When everyday prices outpace net take-home pay, you can land above 200 hours even in high-income settings. (Again, using actual annual hours would improve part of Europe‚Äôs standing; we‚Äôll show that variant in the repo.)&lt;/p&gt;
    &lt;p&gt;(For out-of-window cases that would distort the scale, see Extremes below.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Extremes that would blow up the chart (out of the 80‚Äì220h press window)&lt;/head&gt;
    &lt;p&gt;To keep the hero visual readable, we cap the display at 80‚Äì220 hours/month. Several OECD countries sit above that window. They‚Äôre real, they‚Äôre in our OECD CSV, and they‚Äôre listed here so reporters and readers can see the full picture.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Country&lt;/cell&gt;
        &lt;cell role="head"&gt;Hours / month&lt;/cell&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Note&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mexico&lt;/cell&gt;
        &lt;cell&gt;323.2 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Israel&lt;/cell&gt;
        &lt;cell&gt;288.8 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
        &lt;cell&gt;259.6 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Greece&lt;/cell&gt;
        &lt;cell&gt;258.7 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Ireland&lt;/cell&gt;
        &lt;cell&gt;243.9 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;New Zealand&lt;/cell&gt;
        &lt;cell&gt;235.3 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Slovakia&lt;/cell&gt;
        &lt;cell&gt;232.0 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Estonia&lt;/cell&gt;
        &lt;cell&gt;221.0 h&lt;/cell&gt;
        &lt;cell&gt;OECD net&lt;/cell&gt;
        &lt;cell&gt;Out of press window&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Biggest out-of-window number: Mexico (323.2 h). Next: Israel (288.8 h).&lt;/p&gt;
    &lt;head rend="h4"&gt;Why these hours are so high (quick read)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mexico (~323 h). WTEI rises when typical net hourly pay is modest relative to the essentials basket. Mexico‚Äôs OECD-net series yields a high time cost even before any housing or transport frictions you feel on the ground. We list it here rather than squeeze the main chart‚Äôs scale.&lt;/item&gt;
      &lt;item&gt;Israel (~289 h). High take-home pay coexists with high housing/services price levels. In time terms, the price side wins‚Äîpushing the WTEI outside our readability window.&lt;/item&gt;
      &lt;item&gt;Japan, Greece, Ireland, New Zealand, Slovakia, Estonia. Each mixes different drivers, but the mechanics are the same: if typical net hourly pay is not strong enough versus the price level of rent/food/transport, WTEI climbs. Our fix is transparency: show them here and in the OECD CSV, keep the hero legible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Popular countries with incomplete/non-comparable pay data (directional only)&lt;/head&gt;
    &lt;p&gt;These economies draw a lot of attention, but we don‚Äôt yet have a publishable, comparable typical net hourly pay + actual hours series. We place them directionally using price levels and official wage signals. They do not affect the headline rank. Where our Extended (gross-basis) file has a number, we show it in parentheses as non-comparable context.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;China ‚Äî likely middle. (No Extended figure yet in our file.)&lt;/item&gt;
      &lt;item&gt;India ‚Äî likely upper. Extended gross-basis: ~349.5 h (directional; not comparable to Gold).&lt;/item&gt;
      &lt;item&gt;Russian Federation ‚Äî likely middle. (No Extended figure yet in our file.)&lt;/item&gt;
      &lt;item&gt;Qatar ‚Äî middle, wide dispersion by worker type. (No Extended figure yet.)&lt;/item&gt;
      &lt;item&gt;United Arab Emirates ‚Äî middle, wide dispersion by worker type. (No Extended figure yet.)&lt;/item&gt;
      &lt;item&gt;Singapore ‚Äî middle-to-better. Extended gross-basis: ~1,357.8 h (directional; not comparable to Gold; housing-heavy).&lt;/item&gt;
      &lt;item&gt;Hong Kong SAR ‚Äî middle-to-better. (No Extended figure yet.)&lt;/item&gt;
      &lt;item&gt;Taiwan ‚Äî middle-to-better. (No Extended figure yet.)&lt;/item&gt;
      &lt;item&gt;Saudi Arabia ‚Äî middle-to-better, segmented market. (No Extended figure yet.)&lt;/item&gt;
      &lt;item&gt;Ukraine ‚Äî middle-high on pre-war baselines. Extended gross-basis: ~4,281.0 h (non-comparable; reflects extremely low hourly pay series in file).&lt;/item&gt;
      &lt;item&gt;North Korea ‚Äî not placed (no ICP coverage; no comparable wage/price framework).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Reminder. ‚ÄúDirectional‚Äù means we steer by price levels and wage signals but hold these economies out of the Gold rank until we can publish a consistent typical net hourly and actual hours worked series. Numbers shown from Extended are gross-basis and not comparable to Gold.&lt;/p&gt;
    &lt;head rend="h2"&gt;How many days you win, or lose, each month&lt;/head&gt;
    &lt;p&gt;Hours are really days of your life (divide by 8). So compared with the global median (~166.3 h):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bolivia (~80 h) buys back roughly 11 weekdays every month.&lt;/item&gt;
      &lt;item&gt;United States (140.0 h) buys back about 3‚Öì weekdays each month.&lt;/item&gt;
      &lt;item&gt;Portugal (~219 h) loses roughly 6¬Ω weekdays each month.&lt;/item&gt;
      &lt;item&gt;Ghana (~211 h) loses roughly 5¬Ω weekdays each month.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;That‚Äôs the real currency WTEI tracks: time you don‚Äôt get back.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;‚ÄúWhat would it take‚Äù to move up&lt;/head&gt;
    &lt;p&gt;Pick a target and show the lever.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To crack the global Top-10 (‚âà 134.8 h): the U.S. (140.0 h) needs roughly a +3.9% pay increase or a ‚Äì3.7% basket cut. That‚Äôs your ‚Äúdistance to elite.‚Äù&lt;/item&gt;
      &lt;item&gt;To return to the median (~166.3 h): Portugal (~219 h) needs about a +31.7% pay lift or a ‚Äì24.1% basket reduction; Ghana (~211 h) needs roughly +26.9% pay or ‚Äì21.2% prices. These are large shifts‚Äîexplaining why everyday life there feels time-tight.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use this to talk policy with precision: is your country‚Äôs problem expensive essentials (attack rent, transport, food logistics), take-home pay (tax thresholds, credits), or both?&lt;/p&gt;
    &lt;head rend="h2"&gt;Continent math&lt;/head&gt;
    &lt;p&gt;North America (incl. Central America &amp;amp; Caribbean). A split screen: Nicaragua (~81 h) is a global winner; the United States (140 h) sits in the ‚Äúbetter‚Äù tier; Canada (~175 h) needs more time; Antigua &amp;amp; Barbuda (~219 h) shows the island penalty; Mexico (~323 h, OECD-only) is an outlier on the hard side.&lt;/p&gt;
    &lt;p&gt;South America. Bolivia (~80 h) is a world-beater; Chile (~200+ h) lands time-heavy, illustrating how transport and food can dominate when wages lag.&lt;/p&gt;
    &lt;p&gt;Europe. It‚Äôs a range: Romania (~84 h) near the top of the world; Slovenia (~135 h) better than the U.S.; Portugal (~219 h), Finland (~205 h), Sweden (~203 h) on the tough side. Switching to actual national hours makes many EU countries look better; we‚Äôll publish that sensitivity.&lt;/p&gt;
    &lt;p&gt;Africa. Not one story. Zambia (~106 h) is genuinely time-light‚Äîbeats plenty of rich economies. Ghana (~211 h) shows how food/transport near U.S. parity plus low pay can eat the month even when rent is cheap. Asia &amp;amp; Oceania. Turkey (~90 h) is among the quickest-to-afford in the OECD-adjacent set; Malaysia sits middle-low; South Korea is middle; Australia (~200 h) and New Zealand are often rent-led, pushing hours up.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remote-worker (nomad) lens&lt;/head&gt;
    &lt;p&gt;Hold the denominator fixed at U.S. net hourly pay and ask: where is the basket cheapest? That yields a very different map‚Äîone that‚Äôs useful for remote workers and teams deciding where time goes furthest.&lt;/p&gt;
    &lt;p&gt;Note: This isn‚Äôt about visas or culture; it‚Äôs a time calculation for the essentials only.&lt;/p&gt;
    &lt;head rend="h2"&gt;What eats your time&lt;/head&gt;
    &lt;p&gt;Every country‚Äôs hours decompose into five pieces of the basket. Two fingerprints dominate:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rent-led: common in richer economies; housing is the time sink. When supply or zoning constrains modest units, WTEI rises even if wages are high.&lt;/item&gt;
      &lt;item&gt;Food/transport-led: common in lower-income settings; groceries and getting around dominate. Logistics, imports, and fuel can overwhelm gains from cheap rent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is why national conversations that fixate on a single villain (‚Äúit‚Äôs all rent‚Äù or ‚Äúit‚Äôs all wages‚Äù) miss the point. WTEI shows where the bottleneck actually is.&lt;/p&gt;
    &lt;head rend="h2"&gt;Method &amp;amp; caveats (one minute, no jargon)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Basket: fixed starter basket (rent, utilities, food, transport, other) for comparability.&lt;/item&gt;
      &lt;item&gt;Prices: ICP 2021 price parities by component translate the U.S. basket into each country‚Äôs prices. See also the ICP data hub for PLIs and PPPs: ICP data.&lt;/item&gt;
      &lt;item&gt;Pay: typical hourly ‚Äî OECD net (gold) where available; ILOSTAT gross proxy elsewhere (clearly flagged).&lt;/item&gt;
      &lt;item&gt;Unit: hours per month (WTEI). Press window: we visualize 80‚Äì220 h for clean charts; the full extended table is downloadable.&lt;/item&gt;
      &lt;item&gt;Hero visuals use an 80‚Äì220 h press window for legibility; OECD countries outside this range are shown in the Extremes box and in the OECD download.&lt;/item&gt;
      &lt;item&gt;Transparency: Where a component PLI (e.g., rent or utilities) was missing, we filled from the appropriate ICP aggregate and flagged it in the data so nothing is hidden.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Data &amp;amp; downloads&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Global (winners first): wtei_publishable_ascending.csv&lt;/item&gt;
      &lt;item&gt;OECD (net-pay, full range): wtei_oecd_2025.csv&lt;/item&gt;
      &lt;item&gt;Extended (gross-basis): wtei_extended_2025.csv&lt;/item&gt;
      &lt;item&gt;Nomad Top-15 ¬∑ Nomad Bottom-15&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Related research (method, not the article)&lt;/head&gt;
    &lt;p&gt;The Monthly Survival Hours (MSH) paper underpins the component approach behind WTEI. It‚Äôs a separate, methods-first contribution‚ÄîAn Addition if you discuss methodology: Pow, A., &amp;amp; Stonden, L. (2025). Affordability in Hours‚Ä¶ SocArXiv. DOI 10.31235/osf.io/ztbx2&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Every 8 hours here is one day of your life. Live in a winner and you buy back long weekends every month. Live in a struggler and the weekdays vanish into rent, lights, food, and the bus. That‚Äôs what the Work-to-Essentials Index measures: how much of your life the basics cost.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.thepricer.org/hours-to-afford-essentials-best-and-worst-countries/"/><published>2025-10-16T19:53:10+00:00</published></entry></feed>