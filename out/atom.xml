<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-11T17:39:14.507361+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45885242</id><title>Why effort scales superlinearly with the perceived quality of creative work</title><updated>2025-11-11T17:39:24.233329+00:00</updated><content>&lt;doc fingerprint="a9409d1a3d28c10f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Effort Scales Superlinearly with the Perceived Quality of Creative Work&lt;/head&gt;
    &lt;p&gt;Abstract claim: The act of creation is fractal exploration–exploitation under optimal feedback control. When resolution increases the portion of parameter space that doesn't make the artifact worse (acceptance volume) collapses. Verification latency and rate–distortion combine into a precision tax that scales superlinearly with perceived quality.&lt;/p&gt;
    &lt;p&gt;When I make something good, I often spend most of my time making thousands of high-precision edits on an artifact that I thought should have been finished hours ago. Previously, I called this 'last-mile edits', but that was the wrong mental image.&lt;/p&gt;
    &lt;p&gt;"Last mile" implies executing a known plan with diminishing returns but "last mile" at one level just becomes "early exploration" at higher resolution at the next level. Instead of treating exploration (idea) and exploitation (execution) as temporally separated phases, they nest recursively. That nested search is where the effort goes.&lt;/p&gt;
    &lt;p&gt;Once you commit to D minor, this scene, that argument structure you've constrained the search space and now you search again within it.&lt;/p&gt;
    &lt;p&gt;Take some of my quicker five-minute, gestural sketches below. You'd think they break this nested search dynamic but with a closer look it becomes clear that I just front-loaded my taxes by caching motor heuristics.&lt;/p&gt;
    &lt;p&gt;Domains and modalities differ in how wide and forgiving their basins are and how quickly you can verify the edit (feedback latency). Music timing has a narrow basin at the micro-level (±20 ms can kill a groove) but can be more forgiving higher up: key and pitch changes can be interchangeable without loss of quality, not often though. Prose has a wide basin (many phrasings work). Abstract, contemporary art has extremely wide basin, so much so that nobody with any self-respect even bothers anymore. Renaissance paintings have more constraints and less distortion tolerance.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Modality&lt;/cell&gt;
        &lt;cell role="head"&gt;Basin&lt;/cell&gt;
        &lt;cell role="head"&gt;Verifier&lt;/cell&gt;
        &lt;cell role="head"&gt;Speed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Text (prose)&lt;/cell&gt;
        &lt;cell&gt;Wide&lt;/cell&gt;
        &lt;cell&gt;Human read&lt;/cell&gt;
        &lt;cell&gt;Minutes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Code&lt;/cell&gt;
        &lt;cell&gt;Wide (design) / Narrow (syntax)&lt;/cell&gt;
        &lt;cell&gt;Compiler/tests&lt;/cell&gt;
        &lt;cell&gt;ms-seconds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Music timing&lt;/cell&gt;
        &lt;cell&gt;Narrow&lt;/cell&gt;
        &lt;cell&gt;Ear–body&lt;/cell&gt;
        &lt;cell&gt;~20-40ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Line drawing&lt;/cell&gt;
        &lt;cell&gt;Narrow&lt;/cell&gt;
        &lt;cell&gt;Eye–hand&lt;/cell&gt;
        &lt;cell&gt;~100ms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Let's take the following optimization landscape and assume it's for the process of writing a song. To make it simpler, let's constrain like this: We've written the lyrics and picked a BPM of 80.&lt;/p&gt;
    &lt;p&gt;The wider, more forgiving hill corresponds to choosing C major on the macro level, but there might be a higher, sharper peak in E minor that's trickier—i.e., it demands more precision edits.&lt;/p&gt;
    &lt;p&gt;Wide basins let coarse proposals land. This is where almost all generative AI outputs live and the oxygen is still plenty. Near a sharp peak, the acceptance volumea a We call it acceptance volume, but in the 3D example above, it’d be the area of a tiny slice of the hill. shrinks rapidly and you can’t reliably see micro-improvements without averaging more evidence or trials. The controller (often the hand) makes many tiny corrections after some latency. Rinse and repeat until the piece sits on a hard-to-vary peak.&lt;/p&gt;
    &lt;p&gt;That's why effort seems like it scales superlinearly as perceived quality rises. Judging the intermediate artifact takes more time and most edits (the search) make it worse. Geometrically bad edits become more likely and land you lower in the landscape.&lt;/p&gt;
    &lt;p&gt;Craft, then, is the slog of closing ever-less-perceivable gaps.&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQs&lt;/head&gt;
    &lt;p&gt;Don't bands sometimes record a banger song in an hour together?&lt;/p&gt;
    &lt;p&gt;The tower-climbing happened during practice (*muscle memory*), not recording. Jazz is closer to real-time exploration and mistakes are more accepted and expected.&lt;/p&gt;
    &lt;p&gt;Drawing takes forever because you're exploring AND refining simultaneously.&lt;/p&gt;
    &lt;p&gt;We don't "rehearse" a specific drawing, we solve a novel problem in real-time. There's no cached motor sequence to execute.&lt;/p&gt;
    &lt;code&gt;@misc{strasser2025,
  author = {Strasser, Markus},
  title = {Why Effort Scales Superlinearly with the Perceived Quality of Creative Work},
  year = {2025},
  url = {https://markusstrasser.org/},
  note = {Accessed: 2025-11-11}
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://markusstrasser.org/creative-work-landscapes.html"/><published>2025-11-11T08:29:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45885813</id><title>iPhone Pocket</title><updated>2025-11-11T17:39:24.123848+00:00</updated><content>&lt;doc fingerprint="f96cfbcd532723c4"&gt;
  &lt;main&gt;
    &lt;p&gt; UPDATE November 11, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Introducing iPhone Pocket: a beautiful way to wear and carry iPhone&lt;/head&gt;
    &lt;p&gt; Born out of a collaboration between ISSEY MIYAKE and Apple, iPhone Pocket features a singular 3D-knitted construction designed to fit any iPhone &lt;/p&gt;
    &lt;p&gt;ISSEY MIYAKE and Apple today unveiled iPhone Pocket. Inspired by the concept of “a piece of cloth,” its singular 3D-knitted construction is designed to fit any iPhone as well as all pocketable items. Beginning Friday, November 14, it will be available at select Apple Store locations and on apple.com in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S. &lt;/p&gt;
    &lt;p&gt;iPhone Pocket features a ribbed open structure with the qualities of the original pleats by ISSEY MIYAKE. Born from the idea of creating an additional pocket, its understated design fully encloses iPhone, expanding to fit more of a user’s everyday items. When stretched, the open textile subtly reveals its contents and allows users to peek at their iPhone display. iPhone Pocket can be worn in a variety of ways — handheld, tied onto bags, or worn directly on the body. Featuring a playful color palette, the short strap design is available in eight colors, and the long strap design in three colors. &lt;/p&gt;
    &lt;p&gt;“The design of iPhone Pocket speaks to the bond between iPhone and its user, while keeping in mind that an Apple product is designed to be universal in aesthetic and versatile in use,” shared Yoshiyuki Miyamae, design director of MIYAKE DESIGN STUDIO. “iPhone Pocket explores the concept of ‘the joy of wearing iPhone in your own way.’ The simplicity of its design echoes what we practice at ISSEY MIYAKE — the idea of leaving things less defined to allow for possibilities and personal interpretation.” &lt;/p&gt;
    &lt;p&gt;“Apple and ISSEY MIYAKE share a design approach that celebrates craftsmanship, simplicity, and delight,” said Molly Anderson, Apple’s vice president of Industrial Design. “This clever extra pocket exemplifies those ideas and is a natural accompaniment to our products. The color palette of iPhone Pocket was intentionally designed to mix and match with all our iPhone models and colors — allowing users to create their own personalized combination. Its recognizable silhouette offers a beautiful new way to carry your iPhone, AirPods, and favorite everyday items.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Piece of Cloth&lt;/head&gt;
    &lt;p&gt;Crafted in Japan, iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE. The design drew inspiration from the concept of “a piece of cloth” and reinterpreted the everyday utility of the brand’s iconic pleated clothing. The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout. &lt;/p&gt;
    &lt;head rend="h2"&gt;Availability&lt;/head&gt;
    &lt;p&gt;iPhone Pocket is a limited-edition release. The short strap design is available in lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black; the long strap design is available in sapphire, cinnamon, and black. iPhone Pocket in the short strap design retails at $149.95 (U.S.), and the long strap design at $229.95 (U.S.). &lt;/p&gt;
    &lt;p&gt;Customers can purchase iPhone Pocket beginning Friday, November 14, at select Apple Store locations and apple.com in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S. Just in time for the holidays, Apple Specialists in stores and online can help customers mix and match different lengths and colors with their iPhone, style iPhone Pocket, and purchase their new favorite accessory. &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Canton Road, Hong Kong&lt;/item&gt;
      &lt;item&gt;Apple Ginza, Tokyo&lt;/item&gt;
      &lt;item&gt;Apple Jing’an, Shanghai&lt;/item&gt;
      &lt;item&gt;Apple Marché Saint-Germain, Paris&lt;/item&gt;
      &lt;item&gt;Apple Myeongdong, Seoul&lt;/item&gt;
      &lt;item&gt;Apple Orchard Road, Singapore&lt;/item&gt;
      &lt;item&gt;Apple Piazza Liberty, Milan&lt;/item&gt;
      &lt;item&gt;Apple Regent Street, London&lt;/item&gt;
      &lt;item&gt;Apple SoHo, New York City&lt;/item&gt;
      &lt;item&gt;Apple Xinyi A13, Taipei&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Images in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/"/><published>2025-11-11T10:17:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45886002</id><title>Welcome, the entire land - "Hello, world!" in hieroglyphics</title><updated>2025-11-11T17:39:23.359050+00:00</updated><content>&lt;doc fingerprint="3d29b85d08cb83d9"&gt;
  &lt;main&gt;
    &lt;p&gt;Earlier this year I was attending the dConstruct web conference in Brighton, UK. These sorts of conferences bring together plenty of like-minded people and friends I only get to see a few times a year. After the conference a few of us stuck around a few days to relax, recuperate and chat.&lt;/p&gt;
    &lt;p&gt;Brighton is also the home to one of Britain’s many follies. In 01803, the Prince Regent decided to build a reconstruction of an Indian style riding school and stable near the sea front. This later became the Royal Pavilion. In the proper tradition of British follies, what comes next would fit right in!&lt;/p&gt;
    &lt;p&gt;The day after dConstruct, Mike, Remy, Josh and I all sat in the park next to the Brighton Dome and ate our ice cream. When Mike astutely pointed out the Egyptian exhibit that was on at the museum. We all thought it was interesting, then he came-up with a zinger of a comment. He said, “They did a pretty good job translating”. The title of the exhibit was “The Egyptians”. I thought to myself, that it was a pretty good name for the exhibition. He then went on to tell us that the hieroglyphs on the sign read “The Egyptian People” and the museum adequately captured this in their translation. I think we all sat there a minute to take in what just happened. Someone amongst us could read 05000+ year old text! Then first thing that came to my mind was how we could harness this power in some useful way.&lt;/p&gt;
    &lt;p&gt;Now, my suggestion was not the best, nor most practical, but somehow this folly was the one that we ran with.&lt;/p&gt;
    &lt;p&gt;If you were to draw a Venn diagram and one circle was the people who could read Egyptian hieroglyphs and another circle computer programmers, the overlap would be pretty slim. So the usefulness of my idea was both NOT useful and NOT very funny except to the tiny group of people in that overlap.&lt;/p&gt;
    &lt;p&gt;I wanted a t-shirt that said, “Hello World” in hieroglyphics!&lt;/p&gt;
    &lt;p&gt;Now, the history of the Hello World Program goes back a ways! Anyone who has ever taken an introductory computer programming course has written a Hello World Program. It’s the first thing you learn how to do, get the computer to echo back to the screen the text “Hello World” just to demonstrate that things are working and you have control of the machine.&lt;/p&gt;
    &lt;p&gt;I was quickly informed that Ancient Egyptian didn’t have a glyph for the letter ‘L’ because it didn’t exist in their language, atleast not till later when it was added by the British. Now I’m not one to let a missing letter of the alphabet stop me, so we enlisted the some help.&lt;/p&gt;
    &lt;p&gt;Mike was kind enough to email some old colleagues from school and friends who stayed true to the path of Egyptology and now work in various museums around the UK. Now, it must have been a strange request to get an email asking someone to translated HELLO WORLD into hieroglyphics, I mean, it’s not everyday someone asks you these sorts of questions. But like any proper geek, Egyptian, weather, computer, climbing, photography, or other, they are more than happy to help out anyone who has taken an interest in their subject matter. So after a few back and forths we dug a bit deeper into the translation issues.&lt;/p&gt;
    &lt;p&gt;I was willing to bend the actual HELLO WORLD text infavour of an equivalent saying, such as GREETINGS EARTH. With all their technological achievements, Egyptians were only just short of creating the computer, and when they did, they would have needed something to output to prove it worked. GREETINGS FROM RA, THE SUN RISES, or something as prolific.&lt;/p&gt;
    &lt;p&gt;The result that we got back from translation was “Welcome, the entire land”. Now, it is mind boggling to think that it’s been 05000+ years since the first hieroglyphs and it is highly unlikely that this has EVER been written before. “Welcome, the entire land” is a greeting from a long extinct ideology, language and culture. “Welcome, the entire land” is a warm greeting.&lt;/p&gt;
    &lt;p&gt;The following was translated from the glyphs to English. The glyphs themselves would be pictorially translated as the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Flowering reed with legs.&lt;/item&gt;
      &lt;item&gt;Flowering reed.&lt;/item&gt;
      &lt;item&gt;Double score.&lt;/item&gt;
      &lt;item&gt;Legs to signify movement.&lt;/item&gt;
      &lt;item&gt;Pestle.&lt;/item&gt;
      &lt;item&gt;Flowering reed.&lt;/item&gt;
      &lt;item&gt;Flat alluvial land with grains of sand.&lt;/item&gt;
      &lt;item&gt;Mouth.&lt;/item&gt;
      &lt;item&gt;Bundle of flax stems showing the bolls.&lt;/item&gt;
      &lt;item&gt;Mouth.&lt;/item&gt;
      &lt;item&gt;Road bordered by shrubs.&lt;/item&gt;
      &lt;item&gt;Horned viper.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This forms the hieroglyphic which is read from left to right, top to bottom. You can tell because of the way the first glyph is facing. It creates a very flexible system that can be used to make beautifully stylized writing.&lt;/p&gt;
    &lt;p&gt;From the basic design I began to stylize it to make it more interesting, less academic and more artsy.&lt;/p&gt;
    &lt;p&gt;I was so proud of this folly that I got my wish and printed it onto a t-shirt. I can now wear it knowing a tiny fraction of the population can translate it, and those who can probably won’t get the joke (and vice versa).&lt;/p&gt;
    &lt;p&gt;For anyone else who thinks it is an interesting folly, you are more than welcome to take the translation and design and apply it to anything you wish. A coffee mug, hat, your own shirt, anything. The designs are public domain, I think the Egyptians would have wanted it that way, after 03000+ years of having disappeared, the term of copyright would have expired several times over by now anyway.&lt;/p&gt;
    &lt;p&gt;Downloadable files&lt;/p&gt;
    &lt;p&gt;Special Thanks to Mike Stenhouse for contacting translators and the Egypt Exploration Society for conducting translations. I think everyone involved enjoyed this strange project as much as I.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://optional.is/required/2009/12/03/welcome-the-entire-land/"/><published>2025-11-11T10:52:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45886131</id><title>OpenAI may not use lyrics without license, German court rules</title><updated>2025-11-11T17:39:22.429229+00:00</updated><content>&lt;doc fingerprint="ed438551963b67be"&gt;
  &lt;main&gt;
    &lt;p&gt;MUNICH, Nov 11 (Reuters) - OpenAI's chatbot ChatGPT violated German copyright laws by reproducing lyrics from songs by best-selling musician Herbert Groenemeyer and others, a court ruled on Tuesday, in a closely watched case against the U.S. firm over its use of lyrics to train its language models.&lt;/p&gt;
    &lt;p&gt;The regional court in Munich found that the company trained its AI on protected content from nine German songs, including Groenemeyer's hits "Maenner" and "Bochum".&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The case was brought by German music rights society GEMA, whose members include composers, lyricists and publishers, in another sign of artists around the world fighting back against data scraping by AI.&lt;/p&gt;
    &lt;p&gt;Presiding judge Elke Schwager ordered OpenAI to pay damages for the use of copyrighted material, without disclosing a figure.&lt;/p&gt;
    &lt;p&gt;GEMA legal advisor Kai Welp said GEMA hoped discussions could now take place with OpenAI on how copyright holders can be remunerated.&lt;/p&gt;
    &lt;head rend="h2"&gt;COPYRIGHT INFRINGED&lt;/head&gt;
    &lt;p&gt;OpenAI had argued that its language models did not store or copy specific training data but, rather, reflected what they had learned based on the entire training data set.&lt;/p&gt;
    &lt;p&gt;Since the output would only be generated as a result of user inputs known as prompts, it was not the defendants, but the respective user who would be liable for it, OpenAI had argued.&lt;/p&gt;
    &lt;p&gt;However, the court found that both the memorisation in the language models and the reproduction of the song lyrics in the chatbot's outputs constitute infringements of copyright exploitation rights, according to a statement on the ruling.&lt;/p&gt;
    &lt;head rend="h2"&gt;POTENTIAL PRECEDENT&lt;/head&gt;
    &lt;p&gt;The outcome of the case could set a precedent in Europe for how AI companies use copyrighted materials.&lt;/p&gt;
    &lt;p&gt;"The internet is not a self-service store, and human creative achievements are not free templates," said GEMA CEO Tobias Holzmueller. "Today, we have set a precedent that protects and clarifies the rights of authors: even operators of AI tools such as ChatGPT must comply with copyright law."&lt;/p&gt;
    &lt;p&gt;The decision can be appealed.&lt;/p&gt;
    &lt;p&gt;"We disagree with the ruling and are considering next steps," a spokesperson for OpenAI said. "The decision is for a limited set of lyrics and does not impact the millions of people, businesses and developers in Germany that use our technology every day."&lt;/p&gt;
    &lt;p&gt;Earlier this year, leading Bollywood music labels asked a New Delhi court to join a copyright lawsuit against OpenAI over alleged unauthorised use of sound recordings to train AI models, underscoring global concerns about AI and music rights.&lt;/p&gt;
    &lt;p&gt;Reporting by Joern Poltz, Writing by Friederike Heine; Editing by Madeline Chambers and Susan Fenton&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/"/><published>2025-11-11T11:20:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45886191</id><title>DARPA and Texas Bet $1.4B on Unique Foundry -3D heterogeneous integration</title><updated>2025-11-11T17:39:22.256937+00:00</updated><content>&lt;doc fingerprint="5130c2c4c2378f7f"&gt;
  &lt;main&gt;
    &lt;p&gt;A 1980s-era semiconductor fab in Austin, Texas, is getting a makeover. The Texas Institute for Electronics (TIE), as it’s called now, is tooling up to become the only advanced packaging plant in the world that is dedicated to 3D heterogeneous integration (3DHI)—the stacking of chips made of multiple materials, both silicon and non-silicon.&lt;/p&gt;
    &lt;p&gt;The fab is the infrastructure behind DARPA’s Next-Generation Microelectronics Manufacturing (NGMM) program. “NGMM is focused on a revolution in microelectronics through 3D heterogeneous integration,” said Michael Holmes, managing director of the program.&lt;/p&gt;
    &lt;p&gt;Stacking two or more silicon chips inside the same package makes them act as if they are all one integrated circuit. It already powers some of the most advanced processors in the world. But DARPA predicts silicon-on-silicon stacking will result in no more than a 30-fold boost in performance over what’s possible with 2D integration. By contrast, doing it with a mix of materials—gallium nitride, silicon carbide, and other semiconductors—could deliver a 100-fold boost, Holmes told engineers and other interested parties at the program’s unofficial coming out party, the NGMM Summit, late last month.&lt;/p&gt;
    &lt;p&gt;The new fab will make sure these unusual stacked chips are prototyped and manufactured in the United States. Startups, and there were many at the launch event, are looking for a place to prototype and begin manufacturing ideas that are too weird for anywhere else—and hopefully bypassing the lab-to-fab valley of death that claims many hardware startups.&lt;/p&gt;
    &lt;p&gt;The state of Texas is contributing $552 million to stand up the fab and its programs, with DARPA contributing the remaining $840 million. After NGMM’s five-year mission is complete, the fab is expected to be a self-sustaining business. “We are, frankly, a startup,” said TIE CEO Dwayne LaBrake. “We have more runway than a typical startup, but we have to stand on our own.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Starting up a 3DHI Fab&lt;/head&gt;
    &lt;p&gt;Getting to that point will take a lot of work, but the TIE foundry is off to a quick start. On a tour of the facility, IEEE Spectrum saw multiple chip manufacturing and testing tools in various states of installation and met several engineers and technicians who had started within the past three months. TIE expects all the fab’s tools to be in place in the first quarter of 2026.&lt;/p&gt;
    &lt;p&gt;Just as important as the tools themselves is the ability of foundry customers to use them in a predictable manufacturing process. That’s something that is particularly difficult to develop, TIE officials explained. At the most basic level, non-silicon wafers are often not the same size as one another, and they have different mechanical properties, meaning they expand and contract with temperature at different rates. Yet much of the fab’s work will be linking these chips together with micrometer precision.&lt;/p&gt;
    &lt;p&gt;The first phase of getting that done is the development of what are called a process design kit and an assembly design kit. The former provides the rules that constrain semiconductor design at the fab. The latter, the assembly design kit, is the real heart of things, because it gives the rules for the 3D assembly and other advanced packaging.&lt;/p&gt;
    &lt;p&gt;Next, TIE will refine those by way of three 3DHI projects, which NGMM is calling exemplars. These are a phased-array radar, an infrared imager called a focal plane array, and a compact power converter. Piloting those through production “gives us an initial road map…an on-ramp into tremendous innovation across a broader application space,” said Holmes.&lt;/p&gt;
    &lt;p&gt;These three very different products are emblematic of how the fab will have to operate once it’s up and running. Executives described it as a “high-mix, low-volume” foundry, meaning it’s going to have to be good at doing many different things, but it’s not going to make a lot of any one thing.&lt;/p&gt;
    &lt;p&gt;This is the opposite of most silicon foundries. A high-volume silicon foundry gets to run lots of similar test wafers through its process to work out the bugs. But TIE can’t do that, so instead it’s relying on AI—developed by Austin startup Sandbox Semiconductor—to help predict the outcome of tweaks to its processes.&lt;/p&gt;
    &lt;p&gt;Along the way, NGMM will provide a number of research opportunities. “What we have with NGMM is a very rare opportunity,” said Ted Moise, a professor at UT Dallas and an IEEE Fellow. With NGMM, universities are planning to work on new thermal conductivity films, microfluidic cooling technology, understanding failure mechanisms in complex packages, and more.&lt;/p&gt;
    &lt;p&gt;“NGMM is a weird program for DARPA,” admitted Whitney Mason, director of the agency’s Microsystems Technology Office. “It’s not our habit to stand up facilities that do manufacturing.”&lt;/p&gt;
    &lt;p&gt;But “Keep Austin Weird” is the city’s unofficial motto, so maybe NGMM and TIE will prove a perfect fit.&lt;/p&gt;
    &lt;p&gt;Samuel K. Moore is the senior editor at IEEE Spectrum in charge of semiconductors coverage. An IEEE member, he has a bachelor's degree in biomedical engineering from Brown University and a master's degree in journalism from New York University.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spectrum.ieee.org/3d-heterogeneous-integration"/><published>2025-11-11T11:33:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45886194</id><title>Advent of Code on the Z-Machine</title><updated>2025-11-11T17:39:21.686282+00:00</updated><content>&lt;doc fingerprint="36e8cb932e150bdb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Advent of Code on the Z-machine&lt;/head&gt;
    &lt;p&gt;Fantasy consoles like the Pico-8 are a great idea. A fantasy console provides a standardised and portable environment in which developers can explore ideas within creative constraints. The Z-machine, developed by Infocom in 1979, is the earliest fantasy console I know, although this is probably the first time it’s been called that.&lt;/p&gt;
    &lt;p&gt;Infocom faced the problem of porting their text adventures to the multitude of platforms that existed at the time. Since they came out of the academic environment at mit, they applied a brand-spanking new solution to the problem: they built a virtual machine, the Z-machine, and made a compiler that produced bytecode for it. This meant that once they had made a new game, the new game could instantly be played on all platforms which had the Z-machine1 With a caveat. The Z-machine exists in multiple versions. For a long time, version 3 was the default for new games, and it was widely supported. Some games exceeded the capabilities of version 3 and were made for higher versions – they weren’t quite as portable, so the designer had to show that they could do good enough things with the more capable machines that the tradeoff would be worth it., and if they ported the Z-machine to a new platform, users of that platform could instantly play all games developed for the Z-machine. Today, when Flash, Java, ecmaScript and others have showed us how successful this approach is, we take it for granted, but at the time that was just not how you did things.&lt;/p&gt;
    &lt;head rend="h1"&gt;The z-machine is still alive&lt;/head&gt;
    &lt;p&gt;The observant reader has noticed that I use the present tense when mentioning the Z-machine. That’s because it still exists, and it’s still used. Granted, many text adventures today are written for the more capable Glulx virtual machine – a spiritual successor to the Z-machine – but then again, many text adventures are also written for the Z-machine.&lt;/p&gt;
    &lt;p&gt;Let’s say we want to learn to program the Z-machine. How do we get started?&lt;/p&gt;
    &lt;p&gt;We could emit bytecode directly. That would probably be a cool learning experience. It would also be kind of annoying, so we’ll ignore that alternative.&lt;/p&gt;
    &lt;p&gt;The next step up on the abstraction staircase is zil, that weird, low-level Lisp-looking thing that’s not at all Lisp.&lt;/p&gt;
    &lt;quote&gt;&amp;lt;ROUTINE WABE-F ("OPTIONAL" (CONTEXT &amp;lt;&amp;gt;)) &amp;lt;COND (&amp;lt;EQUAL? .CONTEXT ,M-LOOK&amp;gt; &amp;lt;TELL "This grassy " D ,CLEARING " is only twenty " "feet across, and perfectly circular. Paths " "wander off in many " D ,INTDIR "s through " "the surrounding " D ,THICKET ,PERIOD&amp;gt; &amp;lt;RTRUE&amp;gt;) (&amp;lt;AND &amp;lt;EQUAL? .CONTEXT ,M-EXIT&amp;gt; &amp;lt;MISSED-MEEP?&amp;gt;&amp;gt; &amp;lt;CRLF&amp;gt; &amp;lt;RTRUE&amp;gt;) (T &amp;lt;RFALSE&amp;gt;)&amp;gt;&amp;gt;&lt;/quote&gt;
    &lt;p&gt;There is a modern compiler for zil, which can be used to build the source code from the original games, or indeed write new games. It’s tempting! But in the end, there are two reasons I opted not to write zil:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First off, it is really low level. From what I understand, not even the people at Infocom wrote raw zil. Instead, they used Lisp macros that generated zil.2 They probably also had a zil interpreter in Lisp, meaning they could tweak parsing, move items, change location properties, etc. with the game running. It must have been a very productive way to iterate.&lt;/item&gt;
      &lt;item&gt;Although there are plenty of examples of zil code (all of the Infocom games, for one thing!) there’s relatively little documentation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Inform 6 is another language that compiles to Z-machine bytecode. From a birds eye view, it similar to zil because they are both similar to Z-machine bytecode. Inform 6 was created before the zil source code for the Infocom classics was released; Inform was designed by reverse-engineering the original Z-machines. The Inform 6 compiler comes as a set of stand-alone C source files that are built with the command&lt;/p&gt;
    &lt;quote&gt;$ cc -O2 -o inform *.c&lt;/quote&gt;
    &lt;p&gt; So refreshing. Once we have that compiler, we can give it a source file of Inform 6 code and it produces bytecode for the Z-machine. Here’s &lt;code&gt;hello.inf&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;[Main; print "hello, world!^"; ];&lt;/quote&gt;
    &lt;p&gt; This looks strange, but it’s not very. Subroutines are declared with square brackets. The entrypoint of an Inform 6 program is called &lt;code&gt;Main&lt;/code&gt;. Names are not
case-sensitive, but subroutines conventionally use Pascal_Case. Carets in
strings become newlines.
&lt;/p&gt;
    &lt;p&gt;We compile this to Z-machine bytecode with&lt;/p&gt;
    &lt;quote&gt;$ inform hello.inf&lt;/quote&gt;
    &lt;p&gt; and then we have a file called &lt;code&gt;hello.z5&lt;/code&gt; which is bytecode that runs on the
Z-machine, version 5. The compiler defaults to version 5 because it is most
popular today, but when Infocom developed games, they defaulted to the less
capable version 3, because it had lower system requirements. We can ask the
Inform 6 compiler for version 3 bytecode as long as our code is compatible with it.
&lt;/p&gt;
    &lt;quote&gt;$ inform -v3 hello.inf&lt;/quote&gt;
    &lt;p&gt; Now we get a &lt;code&gt;hello.z3&lt;/code&gt; file with bytecode which should run on any Z-machine. I
happen to have &lt;code&gt;bocfel&lt;/code&gt; lying around.
&lt;/p&gt;
    &lt;quote&gt;$ bocfel hello.z3 Bocfel 2.1.2 Using the Cheap Glk Implementation, library version 1.0.6. hello, world! $&lt;/quote&gt;
    &lt;p&gt;Great! Now what’s that way everyone goes about learning a new language? Riiight, Advent of Code. Before committing to doing it in Inform 6 this year, maybe we should try the first couple of days of the previous year as a warm-up exercise. Let’s see, here’s day one. Okay, some numbers, a little sorting, shouldn’t be too hard.&lt;/p&gt;
    &lt;head rend="h1"&gt;A machine for olden times has olden integers&lt;/head&gt;
    &lt;p&gt;Except … look at the full puzzle input. The first number is something like 76309. Now guess the bit depth of integers in the Z-machine. Yup, it uses 16-bit integers, the highest of which is 65535. We cannot even represent the puzzle input natively on the Z-machine. Smarter people would close the tab and move on to other things, but I wrote the 160 lines of Inform 6 to do the required long integer maths using arrays of four bytes for storage.&lt;/p&gt;
    &lt;p&gt; It contains functions such as this one, which adds &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt;, storing
the result in &lt;code&gt;sum&lt;/code&gt;.3 Why not update one of the addends in place? That would
have been a valid design decision. Maybe that’s the way these things usually are
done. The current method signature is just the first thing that came to mind.
&lt;/p&gt;
    &lt;code&gt;[long_plus left right sum _i _carry _temp;
    for (_i = 3 : _i &amp;gt;= 0 : _i--) {
        _temp = left-&amp;gt;_i + right-&amp;gt;_i + _carry;
        sum-&amp;gt;_i = _temp &amp;amp; $ff;
        @log_shift _temp (-8) -&amp;gt; _carry;
    }
];
&lt;/code&gt;
    &lt;p&gt;There are a few things to note in this code:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inform 6 only has one type of local variable: subroutine parameter. But all parameters are optional as far as the compiler cares, so to get local variables we declare the local variables we need as parameters and then the caller doesn’t supply values for them. Conventionally, these parameters are prefixed with an underscore.&lt;/item&gt;
      &lt;item&gt;You didn’t read the &lt;code&gt;for&lt;/code&gt;loop wrong. It actually uses colons to separate the parts of the loop head. Odd.&lt;/item&gt;
      &lt;item&gt;The byte-wise addition is greatly simplified by having 16-bit integers in the Z-machine, since we just store the output of each half-adder in &lt;code&gt;_temp&lt;/code&gt;and it holds both result and carry.&lt;/item&gt;
      &lt;item&gt;The right arrow mostly indicates byte array indexing, such as in &lt;code&gt;left-&amp;gt;_i&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;When Inform 6 doesn’t have a high-level keyword, it is possible to embed Z-machine instructions directly in the Inform 6 source code, by prefixing the opcode with &lt;code&gt;@&lt;/code&gt;. This embedded assembly syntax uses the right arrow to indicate the destination of operations.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;_carry&lt;/code&gt;variable isn’t explicitly initialised before it is read for the first time. Is it valid Inform 6 to not do that? I don’t know. I’m just an amateur who was handed a hammer with no instruction on how to use it. It seems that&lt;code&gt;bocfel&lt;/code&gt;reliably fills my non-initialised local variables with zeroes, but I don’t know if that’s a guarantee. There are surely many other such errors that you wouldn’t find in professional code.4 I have been informed that Inform 6 guarantees parameters are initialised to zero unless they are given a value by the caller. But my point still stands! I could be missing other things.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most of the other methods are fairly natural, if we have implemented long integer maths before. We will want to assign regular integers into long integers:&lt;/p&gt;
    &lt;quote&gt;[long_set source target _temp; bzero(target, 4); target-&amp;gt;3 = source &amp;amp; $ff; @log_shift source (-8) -&amp;gt; _temp; target-&amp;gt;2 = _temp &amp;amp; $ff; ];&lt;/quote&gt;
    &lt;p&gt;We need methods to store and fetch these long integers from arrays:&lt;/p&gt;
    &lt;quote&gt;[long_arrfetch source target offset _i; for (_i = 0 : _i &amp;lt; 4 : _i++) target-&amp;gt;_i = source-&amp;gt;(4*offset+_i) &amp;amp; $ff; ]; [long_arrstore source target offset _i; for (_i = 0 : _i &amp;lt; 4 : _i++) target-&amp;gt;(4*offset+_i) = source-&amp;gt;_i &amp;amp; $ff; ];&lt;/quote&gt;
    &lt;p&gt; We can use &lt;code&gt;arrstore&lt;/code&gt; to copy from one long integer to another.
&lt;/p&gt;
    &lt;quote&gt;[long_copy source target; long_arrfetch(source, target, 0); ];&lt;/quote&gt;
    &lt;p&gt;We can read a series of bytes into a long integer:&lt;/p&gt;
    &lt;quote&gt;[long_read buffer offset target _i _j _temp; long_set(0, target); ! Walking the length of the buffer. for (_i = offset : _i &amp;lt; buffer-&amp;gt;0 : _i++) { ! If we have a digit... if (buffer-&amp;gt;_i &amp;gt;= 48 &amp;amp;&amp;amp; buffer-&amp;gt;_i &amp;lt;= 57) { ! Take its numeric value. _temp = buffer-&amp;gt;_i - 48; ! Add it as the new least significant ! decimal digit of the long integer. for (_j = 3 : _j &amp;gt;= 0 : _j--) { _temp = _temp + target-&amp;gt;_j * 10; target-&amp;gt;_j = _temp &amp;amp; $ff; @log_shift _temp (-8) -&amp;gt; _temp; } } else { ! Return the position of the first non-digit. return _i; } } ];&lt;/quote&gt;
    &lt;p&gt;We can also convert a long integer into a series of digits:&lt;/p&gt;
    &lt;quote&gt;[long_print value _i _count _temp; ! We're destructively extracting digits from the ! value, so better create a local copy of it ! before proceeding. long_copy(value, _qx); while (true) { _temp = 0; ! Divide out the least significant digit. for (_i = 0 : _i &amp;lt; 4 : _i++) { @log_shift _temp 8 -&amp;gt; _temp; _temp = _temp + _qx-&amp;gt;_i; _qx-&amp;gt;_i = _temp / 10; _temp = _temp % 10; } ! Convert it to a character and store. _fbuf-&amp;gt;_count = 48 + _temp; ! We should never see more than 10 digits. if (++_count &amp;gt; 10) break; ! When we have divided out all digits, we ! exit. (We always run one iteration to ! make sure we print 0 when it is 0.) if (long_iszero(_qx)) break; } ! We'll get the digits least significant first ! so we print the buffer backwards. (Although ! I'd argue we made a mistake when we copied ! the order Arabs write their numbers and ! transplanted it into a left-to-right language. ! Clearly, the Arabs meant their numbers to be ! least significant digit first in the direction ! the language is written.) for (_i = _count - 1 : _i &amp;gt;= 0 : _i--) { print (char) _fbuf-&amp;gt;_i; } ];&lt;/quote&gt;
    &lt;p&gt; In this code we see our first print directive, &lt;code&gt;(char)&lt;/code&gt;. Normally the &lt;code&gt;print&lt;/code&gt;
instruction would print the numeric value of the character, but we can instruct
it to interpret the next value as a character by giving it such a directive.
Although it looks like a type cast, it is not. It is part of the &lt;code&gt;print&lt;/code&gt;
statement syntax of Inform 6.
&lt;/p&gt;
    &lt;p&gt; Although almost all long integer methods that need temporary storage use the two registers &lt;code&gt;_rx&lt;/code&gt; and &lt;code&gt;_tx&lt;/code&gt;, the print method specifically uses &lt;code&gt;_qx&lt;/code&gt; and it is
the only method that uses that register. It makes debugging a lot simpler to be
able to call print inside another subroutine without having the printing method
clobber the temporary storage of the other subroutine! Pro tip.
&lt;/p&gt;
    &lt;p&gt;We need a size comparison too.&lt;/p&gt;
    &lt;quote&gt;[long_lessthan left right _i; for (_i = 0 : _i &amp;lt; 4 : _i++) { if (left-&amp;gt;_i &amp;lt; right-&amp;gt;_i) return true; if (left-&amp;gt;_i &amp;gt; right-&amp;gt;_i) return false; } ! If it gets here, they are equal, which means ! left is not less than right. return false; ];&lt;/quote&gt;
    &lt;p&gt;I’m not sure why I show you all this. It’s all fairly standard long integer maths implementation, and nothing relevant to the Z-machine at all. I hope you didn’t fall asleep. Sorry.&lt;/p&gt;
    &lt;p&gt;One thing that turned out much simpler than I thought it would be was the subroutine to sort arrays of these things. Granted, it’s only simple because of the other subroutines supporting it, but still!&lt;/p&gt;
    &lt;quote&gt;[long_sort arr n _i _j; for (_i = 1 : _i &amp;lt; n : _i++) { long_arrfetch(arr, _rx, _i); for (_j = _i-1 : _j &amp;gt;= -1 : _j--) { long_arrfetch(arr, _tx, _j); if (_j &amp;gt;= 0 &amp;amp;&amp;amp; long_lessthan(_rx, _tx)) { long_arrstore(_tx, arr, _j+1); } else { long_arrstore(_rx, arr, _j+1); break; } } } ];&lt;/quote&gt;
    &lt;p&gt; Here, &lt;code&gt;_rx&lt;/code&gt; and &lt;code&gt;_tx&lt;/code&gt; are global temporary registers for use within this module.
The Z-machine is designed to not do any dynamic allocation outside of parameters
on the stack, so any arrays (e.g. to hold long integers) need to be allocated
statically.5 There are Inform games that rely on dynamic allocation and they
twist the Z-machine in awkward ways to achieve that, from what I understand.
Andrew Plotkin’s Lists and Lists comes to mind.
&lt;/p&gt;
    &lt;head rend="h1"&gt;Solving the first day’s problems&lt;/head&gt;
    &lt;p&gt; With that little nightmare of implementing long integer maths out of the way, we can start to figure out the Z-machine again. There seems to be a few ways to read input from the user, but the main one is the instruction with opcode &lt;code&gt;@aread&lt;/code&gt; in version 5.6 The corresponding opcode in version 3 is &lt;code&gt;@sread&lt;/code&gt;,
but I never got it to work after a quick test. I’m sure I could with more
tinkering, but that would be a distraction.
&lt;/p&gt;
    &lt;p&gt;Here’s a method that uses it to read a line of user input into a buffer.&lt;/p&gt;
    &lt;quote&gt;! Read a line into buf, returning the index of the ! first read character. [read_line buf l _discard; ! Zero out the buffer while keeping the initial ! element which indicates buffer size. l = buf-&amp;gt;0; bzero(buf, l); buf-&amp;gt;0 = l; @aread buf -&amp;gt; _discard; return 2; ];&lt;/quote&gt;
    &lt;p&gt; The &lt;code&gt;@aread&lt;/code&gt; instruction stores the number of read characters in the second
location of the array, and returns the final character of the input. We’ll
ignore both of those, because we’ll read the input until the first nul
character to figure out where it ends.
&lt;/p&gt;
    &lt;p&gt;We will also have a function that skips past non-digits in a character buffer to advance to the next number in the input.&lt;/p&gt;
    &lt;quote&gt;[skip_nodig buf offset; while (offset &amp;lt; buf-&amp;gt;0 &amp;amp;&amp;amp; (buf-&amp;gt;offset &amp;lt; 48 || buf-&amp;gt;offset &amp;gt; 57)) offset++; return offset; ];&lt;/quote&gt;
    &lt;p&gt;That’s most of the preparation. Using this code, we can solve the first half of the first day of Advent of Code 2024. Note that we do not use the Inform 6 standard library at all. The compiler only sees the code we have written and the Z-machine only executes instructions compiled from our code. Why this matters will be explained later.&lt;/p&gt;
    &lt;quote&gt;Include "util.h"; Include "long.h"; Constant MAX_INPUT = 20; Constant MAX_LINES = 1000; ! Read buffer, used to accept user input. Array rbuf-&amp;gt;(MAX_INPUT); ! Temporary storage locations for long integers. Array ax-&amp;gt;4; Array bx-&amp;gt;4; Array cx-&amp;gt;4; Array dx-&amp;gt;4; ! We will need four bytes for each number in the two ! columns of full input. Array as -&amp;gt;(MAX_LINES*4); Array bs -&amp;gt;(MAX_LINES*4); [Main _next _n _i; ! Set the buffer size in the buffer. rbuf-&amp;gt;0 = MAX_INPUT-1; while (_n &amp;lt; MAX_LINES) { ! Try to read another line of input. _next = read_line(rbuf); if (rbuf-&amp;gt;_next == 0) break; ! Extract the two numbers from the input. _next = long_read(rbuf, _next, ax); _next = skip_nodig(rbuf, _next); _next = long_read(rbuf, _next, bx); ! Push the numbers into their arrays. long_arrstore(ax, as, _n); long_arrstore(bx, bs, _n); _n++; } ! Sort each array. long_sort(as, _n); long_sort(bs, _n); ! Accumulate distances into dx. long_set(0, dx); ! Compute the distances between parallel values. for (_i = 0 : _i &amp;lt; _n : _i++) { long_arrfetch(as, ax, _i); long_arrfetch(bs, bx, _i); long_minus(ax, bx, cx); long_plus(dx, cx, dx); } print "Cumulative distances: "; long_print(dx); print "^"; ];&lt;/quote&gt;
    &lt;p&gt; For the full input, this takes four seconds to run in &lt;code&gt;bocfel&lt;/code&gt; on my machine,
but it produces the correct answer! To solve the second half of the day, we can
tack on another loop at the end.
&lt;/p&gt;
    &lt;quote&gt;long_set(0, dx); ! Step through both arrays somewhat cleverly to ! find matches more cheaply than in square time. ! Well, it would have been more cheaply than ! square time if we didn't choose a square time ! algorithm for sorting both inputs... for (_i = 0, _j = 0 : _i &amp;lt; _n : _i++) { long_arrfetch(as, ax, _i); long_arrfetch(bs, bx, _j); ! If a is greater than b, then we need to ! advance j until they match. while (_j &amp;lt; _n &amp;amp;&amp;amp; long_lessthan(bx, ax)) { _j++; long_arrfetch(bs, bx, _j); } _firstmatch = _j; ! If a is equal to b, it contributes and we ! advance j. while (_j &amp;lt; _n &amp;amp;&amp;amp; ~~long_lessthan(ax, bx)) { long_plus(dx, ax, dx); _j++; long_arrfetch(bs, bx, _j); } ! Now a is less than b, so we need to advance i. ! But first we rewind b so that other equal ! elements of a have a chance of counting their ! contributions too! _j = _firstmatch; } print "Similarity score: "; long_print(dx); print "^";&lt;/quote&gt;
    &lt;head rend="h1"&gt;Using objects to solve the second day&lt;/head&gt;
    &lt;p&gt; So far, we have only seen procedural code, but Inform 6 is also somewhat object-oriented7 Sometimes the Z-machine is described as one of the first widely-installed object-oriented systems, but there is very little support for object-orientation in the Z-machine itself. Also zil does not support what we would today recognise as object-oriented code. It has things called objects, but they are closer to C &lt;code&gt;struct&lt;/code&gt;s., with the idea being that messages being passed
between objects is a useful way to simulate interactions in the world. It still
won’t allocate objects dynamically, so for the most part it is used with
singleton objects.8 It is possible to create objects during run-time, but
then they come from a statically allocated fixed-size pool.
&lt;/p&gt;
    &lt;p&gt;Inform 6 supports dual object hierarchies: it encodes is-a relationships through inheritance, and has-a relationships through an object tree indicating containment. We can use the first half of the second day’s puzzle to illustrate both.&lt;/p&gt;
    &lt;p&gt;To model the second day’s problem, we begin by defining an attribute indicating that a report is safe. An attribute is a boolean flag (in fact, they are called flags in zil) that all objects start out not having, but it can be set on any of them.&lt;/p&gt;
    &lt;quote&gt;Attribute valid;&lt;/quote&gt;
    &lt;p&gt;Then we create a class for the generic report approver.&lt;/p&gt;
    &lt;quote&gt;Class Report_Approver with ! Store the previous value for range calculations. _prev nothing, ! Method that decides whether to accept a new value. _accept, ! Default reject method that accepts the first value, ! rejects any changes that are too large, and otherwise ! defers to the accept method. _reject [next; if (self._prev == nothing) return false; if (abs(next - self._prev) &amp;gt; 3) return true; return ~~self._accept(next); ], ! When appending a number, if it is rejected, remove ! the valid attribute from this approver. append [next; if (self._reject(next)) give self ~valid; self._prev = next; ], ! To reset an approver, remove the previous value ! and default back to a valid report again. reset [; self._prev = nothing; give self valid; ], has valid;&lt;/quote&gt;
    &lt;p&gt; Here we can see some new features. Properties are like attributes except instead of booleans, they store values. Importantly, they can store anonymous subroutines, which are declared like normal subroutines except without a name, and inside them we have access to the implicit variable &lt;code&gt;self&lt;/code&gt;. The keyword
&lt;code&gt;give&lt;/code&gt; sets and unsets flags on objects (sorry, I mean “assigns attributes to”
objects, and “removes attributes from” objects).
&lt;/p&gt;
    &lt;p&gt;As before, properties/methods that are not meant to be public are conventionally named with a leading underscore.&lt;/p&gt;
    &lt;p&gt; Next we define an aggregate approver that judges the validity of a report by consulting multiple sub-approvers. It will accept a report as long as any of the sub-approvers accept it. We inherit from the &lt;code&gt;Report_Approver&lt;/code&gt; class to do it,
and we override both public methods &lt;code&gt;append&lt;/code&gt; and &lt;code&gt;reset&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;Report_Approver multi_approver with append [next _sub _anyvalid; ! Append to all sub-approvers. objectloop (_sub in self) { _sub.append(next); ! As long as any of them are valid... if (_sub has valid) _anyvalid = true; } ! ...then the aggregate is also valid. if (~~_anyvalid) give self ~valid; ], reset [_sub; ! Reset all sub-approvers objectloop (_sub in self) _sub.reset(); ! Then perform the same reset as ! the parent class. self.Report_Approver::reset(); ];&lt;/quote&gt;
    &lt;p&gt; The &lt;code&gt;reset&lt;/code&gt; method on this object calls the &lt;code&gt;reset&lt;/code&gt; method of its superclass.
There are a few ways this can be done9 In some instances we can define
properties as additive and the full inheritance chain is consulted
automatically. but this seemed easiest here.
&lt;/p&gt;
    &lt;p&gt; We also see the &lt;code&gt;objectloop&lt;/code&gt; Inform 6 keyword, which starts a special kind of
loop that iterates through the direct descendants of an object in the object
tree.10 We could iterate through the children using object relationship
methods like &lt;code&gt;parent&lt;/code&gt;, &lt;code&gt;child&lt;/code&gt;, and &lt;code&gt;sibling&lt;/code&gt;, but the &lt;code&gt;objectloop&lt;/code&gt; is more
convenient and easier to read. As a reminder, the object tree is not the same
thing as the inheritance tree; the object tree is about which objects contain
each other (has-a, rather than is-a).
&lt;/p&gt;
    &lt;p&gt; So far, we have not seen which objects are contained by the &lt;code&gt;multi_approver&lt;/code&gt;,
but that happens next!
&lt;/p&gt;
    &lt;quote&gt;Report_Approver -&amp;gt; decremental_reports with _accept [next; return next - self._prev &amp;lt; 0; ]; Report_Approver -&amp;gt; incremental_reports with _accept [next; return next - self._prev &amp;gt; 0; ];&lt;/quote&gt;
    &lt;p&gt; This is another way the right arrow is used in Inform 6. When we define objects with a right arrow, they are automatically inserted as children into the object defined just before. This means both &lt;code&gt;decremental_reports&lt;/code&gt; and
&lt;code&gt;incremental_reports&lt;/code&gt; become children of &lt;code&gt;multi_approver&lt;/code&gt;.11 There are also
functions to move objects around in the object tree, if they need to move during
runtime, for example.
&lt;/p&gt;
    &lt;p&gt; Finally, we use this by reading in numbers and pushing them into the aggregate approver, counting the number of approved plans in the local variable &lt;code&gt;_i&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;while (_n &amp;lt; 1000) { ! Try to read another line of input. ! Stop if there is no more input. _next = read_line(rbuf); if (rbuf-&amp;gt;_next == 0) break; while (rbuf-&amp;gt;_next &amp;gt; 0) { ! Extract a number from the input. _next = long_read(rbuf, _next, ax); _next = skip_nodig(rbuf, _next); ! Truncate long integer into short integer ! and send it to the aggregate approver. multi_approver.append(long_trunc(ax)); } ! If the reports are still safe now, ! increment count and then reset. if (multi_approver has valid) _i++; multi_approver.reset(); }&lt;/quote&gt;
    &lt;p&gt;The puzzle input for this day fits comfortably in the Z-machine short integers, but since we already had a method for parsing numbers that happens to produce a long integer, we might as well use it and then truncate it to a short integer.&lt;/p&gt;
    &lt;p&gt;The next half of that day’s puzzle sounds like it would need expensive backtracking unless done cleverly, and I’m all out of clever for this article, so I’ll stop here. At this point, I feel fairly done with Inform 6 for Advent of Code problems. I’ve toyed with the system and gotten a much better understanding of it. I’m reminded of why I don’t do more low-level programming: it’s a fun challenge, to be sure, but when I write code I do it mainly for the result, not for the challenge. If I want a mental challenge, I’d much rather play the game of go or something.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why learn Inform 6&lt;/head&gt;
    &lt;p&gt;Now why, if I don’t like low-level programming, would I do this in the first place? Great question!&lt;/p&gt;
    &lt;p&gt;A little while ago I learned Inform 7, which I’m not entirely happy with. I like the rule-based approach, but I strongly dislike the syntax. I started looking into Inform 6 as an alternative. While Inform 7 comes as one, relatively opaque package, Inform 6 is split into two parts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Inform 6 language, which compiles down to Z-machine bytecode and looks relatively sensible, as we have seen in this article; and&lt;/item&gt;
      &lt;item&gt;The Inform 6 standard library, which acts as text adventure engine framework, providing basic interactions and world model.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This means we can learn the Inform 6 language in isolation, separate from its standard library!&lt;/p&gt;
    &lt;p&gt;If there’s anything I’ve learned about learning new systems, it’s that it’s useful to pull them apart and see exactly where the boundaries between their parts go. Exactly where does the Z-machine stop, and Inform 6 take over? Exactly where does Inform 6 stop, and the standard library take over? Incredibly useful to be able to answer those questions, but it’s hard if we try to learn the entire system as one unit. This article, then, was pulling the Inform 6 language apart from its standard library, and learning the where the boundaries go.&lt;/p&gt;
    &lt;p&gt;Something else that’s cool about this separation is that instead of including the standard library, we can include any other library to provide our basic interactions and world model. I, for example, have been eyeing PunyInform, which is compatible with version 3 of the Z-machine. That seems like a useful creative constraint. Version 3 only supports a maximum of 255 objects. If I can’t make a good game with 255 objects, it is not going to help to give myself more objects to hang myself with.&lt;/p&gt;
    &lt;p&gt;Wouldn’t this mean low-level programming? Not quite. With the addition of a standard library (either the one that used to ship with Inform 6, or an alternative like PunyInform), the Inform 6 language becomes much higher level – at least when trying to make text adventures.&lt;/p&gt;
    &lt;p&gt;Well, we’ll see. There’s a PunyInform competition starting soon and ending in November. If I can produce a game in time for that, I’ll let you know. If you hear nothing, I didn’t.&lt;/p&gt;
    &lt;head rend="h1"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Many thanks to the members of the IntFiction forums for pointing out errors in a draft of this article.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://entropicthoughts.com/advent-of-code-on-z-machine"/><published>2025-11-11T11:34:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45886479</id><title>Widespread distribution of bacteria containing PETases across global oceans</title><updated>2025-11-11T17:39:21.510596+00:00</updated><content/><link href="https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false"/><published>2025-11-11T12:22:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887007</id><title>Show HN: Venturu – Zillow for the market of local businesses</title><updated>2025-11-11T17:39:21.259439+00:00</updated><content>&lt;doc fingerprint="3adb92596774f7a2"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Buy a business with confidence&lt;/head&gt;&lt;p&gt;Verified listings. Expert brokers. Your next opportunity awaits.&lt;/p&gt;&lt;p&gt;3,850+ Businesses&lt;/p&gt;&lt;p&gt;1,350+ Expert Brokers&lt;/p&gt;&lt;p&gt;50 States&lt;/p&gt;&lt;head rend="h2"&gt;Featured Listings&lt;/head&gt;&lt;head rend="h2"&gt;How Venturu works&lt;/head&gt;&lt;p&gt;1&lt;/p&gt;&lt;head rend="h3"&gt;Explore Listings&lt;/head&gt;&lt;p&gt;Search our map for verified businesses for sale and use filters to easily narrow your search by industry, price, or location.&lt;/p&gt;&lt;p&gt;2&lt;/p&gt;&lt;head rend="h3"&gt;Inquire Easily&lt;/head&gt;&lt;p&gt;Send purchase inquiries on interesting listings with just a click to easily start the conversation about buying the business.&lt;/p&gt;&lt;p&gt;3&lt;/p&gt;&lt;head rend="h3"&gt;Evaluate Opportunities&lt;/head&gt;&lt;p&gt;Look closely at business details and information, using free tools like our valuation estimate, to help you decide with confidence.&lt;/p&gt;&lt;p&gt;4&lt;/p&gt;&lt;head rend="h3"&gt;Seal the Deal&lt;/head&gt;&lt;p&gt;Smoothly handle talks and paperwork using helpful tools, plus get optional expert help from brokers, to confidently complete your business purchase.&lt;/p&gt;&lt;head rend="h2"&gt;Why Use Venturu?&lt;/head&gt;&lt;head rend="h3"&gt;Browse with Confidence&lt;/head&gt;&lt;p&gt;Feel sure exploring verified business listings on our simple platform with an easy map search to find your ideal small business opportunity.&lt;/p&gt;&lt;head rend="h3"&gt;Make Informed Decisions&lt;/head&gt;&lt;p&gt;Make smarter choices by reviewing clear business details and using free tools, like our instant valuation estimate, for helpful insights.&lt;/p&gt;&lt;head rend="h3"&gt;Expert Support&lt;/head&gt;&lt;p&gt;Get expert help buying a business by easily connecting with trusted local business brokers listed in our helpful and free broker directory.&lt;/p&gt;&lt;head rend="h2"&gt;Need Expert Help Buying a Business?&lt;/head&gt;&lt;head rend="h4"&gt;Connect with Trusted Brokers&lt;/head&gt;&lt;p&gt;Buying a business is easier with help. Search our free directory to find experienced local business brokers in your area or industry. View profiles, check reviews, and contact them directly for guidance on your purchase.&lt;/p&gt;Find a Business Broker&lt;head rend="h2"&gt;What Our Buyers Are Saying&lt;/head&gt;&lt;p&gt;Emily S.&lt;/p&gt;&lt;p&gt;Restaurant Owner&lt;/p&gt;&lt;p&gt;Venturu made finding relevant businesses so simple. The verified listings and easy search saved me weeks of effort. Found and purchased my dream business quickly!&lt;/p&gt;&lt;p&gt; Purchased for $475,000&lt;/p&gt;&lt;p&gt;Mark T.&lt;/p&gt;&lt;p&gt;Small Business Investor&lt;/p&gt;&lt;p&gt;With Venturu's detailed info and connection to a great local broker, I felt confident buying my business. Highly recommend for anyone looking for an established SMB.&lt;/p&gt;&lt;p&gt; Purchased for $620,000&lt;/p&gt;&lt;p&gt;Laura B.&lt;/p&gt;&lt;p&gt;Entrepreneur&lt;/p&gt;&lt;p&gt;As a first-time buyer, the platform was easy to use, and finding an experienced broker through their directory was a huge help. Venturu gave me the confidence I needed.&lt;/p&gt;&lt;p&gt; Purchased for $810,000&lt;/p&gt;&lt;head rend="h2"&gt;Frequently Asked Questions&lt;/head&gt;&lt;p&gt;How do I search for businesses for sale?&lt;/p&gt;&lt;p&gt;Is Venturu free to use for searching businesses?&lt;/p&gt;&lt;p&gt;How accurate is the free valuation estimate I see on listings?&lt;/p&gt;&lt;p&gt;How do I find a business broker to help me buy?&lt;/p&gt;&lt;p&gt;How do you make sure the business listings are real?&lt;/p&gt;&lt;p&gt;How do I inquire about a business I like?&lt;/p&gt;&lt;p&gt;I want to sell my business, where do I go?&lt;/p&gt;&lt;p&gt;I'm a business broker, where do I go?&lt;/p&gt;&lt;head rend="h2"&gt;About Venturu&lt;/head&gt;&lt;head rend="h3"&gt;Building a better way for business sales&lt;/head&gt;&lt;p&gt;We started Venturu because we believe buying or selling a local business should be simpler and more trustworthy. We're building the go-to marketplace that connects sellers, buyers, and expert brokers, providing free core tools to ensure a smoother, more successful experience for everyone involved.&lt;/p&gt;&lt;p&gt;Founder&lt;/p&gt;&lt;p&gt;Founder&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.venturu.com"/><published>2025-11-11T13:24:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887105</id><title>The Perplexing Appeal of the Telepathy Tapes</title><updated>2025-11-11T17:39:20.693315+00:00</updated><content>&lt;doc fingerprint="edcc911708208ffd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Ky Dickens, the director of The Telepathy Tapes, repeatedly describes her findings — namely, that non-verbal autistic people can read minds — as “paradigm-shifting.” This is not a cherry-picked hyperbole: at the official Telepathy Tapes website, t-shirts bearing the phrase “paradigm shifted” are on sale for $40 USD (plus shipping &amp;amp; handling).&lt;/p&gt;
        &lt;p&gt;The series is a roughly 500-minute explanation, spread across 10 episodes, of a silent revolution taking place among autistic individuals. One by one, the program presents the charged testimonies of families crushed by bleak diagnoses deemed “severe” or “profound,” peppered with recollections of callous doctors who suggest letting go of hope for the future. Defiant parents and teachers refuse this fate, and against all odds, manage to help the nonspeakers in their lives find some means of communicating.&lt;/p&gt;
        &lt;p&gt;It’s easy enough to understand the appeal of such accounts, in which extraordinary individuals triumph over seemingly insurmountable adversity. But The Telepathy Tapes aims to do more than share feel-good stories. It seeks to lend credence to a truly radical claim that nonspeakers — not just the few featured on the show, but all nonspeakers — have tapped into something the rest of us have allowed to atrophy, a part of the mind capable of accessing a universal collective consciousness.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Farfetched as it may sound to the uninitiated, it’s a notion that’s garnered enduring appeal among a widespread audience. For a brief period at the start of 2025, the series eclipsed podcast juggernaut Joe Rogan on Spotify’s top podcast charts. In February, Rogan invited Dickens onto his show to speak at length for an audience of millions. By July, Spotify’s editorial team named The Telepathy Tapes one of the “best breakout series of 2025.” &lt;/p&gt;
        &lt;p&gt;Beyond the less-than-reliable realm of The Joe Rogan Experience, the possibility of psychic thought transmission has captivated individuals not usually prone to magical thinking. Dickens’ truth-seeking odyssey stems from informal, unreviewed research conducted by Dr. Diane Hennacy Powell, a Johns Hopkins-educated neuropsychiatrist and former Harvard Medical School faculty member. Despite the unsubstantiated nature of her findings — Powell has never submitted her telepathy work to peer review — frequently cited and highly respected professor of psychology Dr. Scott Barry Kaufman sat Powell down for an interview, in which he expressed earnest interest in conducting further experimentation on the subject of telepathy. In the same exchange, Kaufman also revealed that prominent autism researcher Simon Baron-Cohen had expressed a similar interest in working alongside Powell.&lt;/p&gt;
        &lt;p&gt;The message has found still more purchase outside of the sciences. Influencer and entrepreneur Packy McCormick praised the series to a readership of over 250,000 people. “[We are] moving past the stranglehold of the dogmatic rational materialist paradigm…and towards something both ancient and cutting-edge,”he wrote in a glowing review of the series. Author and investor Scott Britton, following a conversation on Telepathy with Ky Dickens, boldly claimed that “we will reach a tipping point in collective belief during this lifetime that will open up the aperture for much greater human capacity.”&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Most recently, NewsNation — a scrappy, centrist cable network that deems itself “America’s source for fact-based, unbiased news” — featured an hour-long promotional interview with Ky Dickens and cognitive neuroscientist parapsychologist Dr. Julia Mossbridge. There’s also a feature-length documentary currently underway, said to premiere sometime in the spring of 2026. &lt;/p&gt;
        &lt;p&gt;But amidst all the chatter about paradigm shifts, the voice I’ve found myself reflecting on most is my grandmother’s.&lt;/p&gt;
        &lt;p&gt;In life, she was a devout Catholic, with the same steadfast faith that guided Acadian ancestors. For her last three decades on Earth, night after night, she punctually prayed that God would grant her one simple request. Though the act of prayer itself was a private matter, she candidly spoke of what she asked for one hundred thousand times over: that my eldest brother, Chris, would speak to her.&lt;/p&gt;
        &lt;p&gt;When initially presented with the possibility that my brother might be telepathic, I thought immediately of her kitchen table in the soft morning light, where my family would sit, and my grandmother would tell us that her prayers had been answered overnight in the form of a dream. While she pieced together the conversation she supposedly shared with my brother, Chris would sit silently beside me, stabbing at the stack of brown sugar flapjacks in front of him or fiddling with the loose knob of a pot lid. &lt;/p&gt;
        &lt;p&gt;If anyone else had doubts about the recollections she shared with such conviction, they were suppressed. Who were any of us to claim to better understand the nature of dreams, or to challenge a belief that brought her such unbridled delight?&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Since discovering The Telepathy Tapes, I’ve frequently found myself revisiting this composite memory. In many ways, my brother resembles the non-speakers featured on the podcast. Despite being a few years shy of his 40th birthday, Chris would likely neglect many of his most basic needs if not for the gentle, constant patient prodding of my mother and father. He expresses himself through gestures, a few simple signs, and an occasional monosyllabic utterance, but he never truly talks. It has been this way since before I was born, and I’ve fully accepted that it will likely always be this way. &lt;/p&gt;
        &lt;p&gt;Though the nuances of a highly variant neurodevelopmental condition like autism are difficult for a child’s brain to comprehend, I managed to discern two laws concerning Chris early on. Firstly, there is an enormous divergence in the way Chris and I understand the world, and this results in a struggle for him to accomplish things that come naturally to most, including communication. This is the basis of the second law: There will always be depths to my brother that I cannot know. &lt;/p&gt;
        &lt;p&gt;Acceptance of these statutes have guided me through the most challenging parts of our strange and wordless relationship. They have explained his howls that occasionally rip through the chatter of restaurant dining rooms, his fixation with the flow of running water, his tendency not to react at all when I talk to him. When he flips through the pages of books, I am not sure if he is reading or up to something else entirely. The countless uncertainties become far easier to embrace and appreciate with the laws in place. &lt;/p&gt;
        &lt;p&gt;But recently, I’ve been forced to question the laws that have long guided me. Something about The Telepathy Tapes — and, by extension, the suggestion that my brother and grandmother did find some impossible way to speak — rings true to a surprising number of people. It’s enough to make me wonder, if only for a moment, whether I somehow missed a sign of recognition all those years ago at the kitchen table, in the twinkle of my brother’s eye, or deep within the hint of a smile.&lt;/p&gt;
        &lt;p&gt;My fleeting moments of self-doubt are always quieted by the stark juxtaposition between the idealistic claims presented by The Telepathy Tapes and my own lived experience, never mind the lack of compelling scientific evidence. Autism is a magnet for pseudoscientific theory, and I’ve formed skeptical calluses in response. &lt;/p&gt;
        &lt;p&gt;All the same, I’ve found myself vexed by the tight grip these psychic notions have, particularly on otherwise skeptical individuals and organizations. When something strikes so close to your heart, you have no choice but to dig for answers — not just about the nature of telepathy, but of the cultural movement that wants to believe it’s real.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The strongest pieces of evidence for autistic telepathy are the anecdotal accounts shared by the caregivers, case workers, and educators who work firsthand with nonspeakers. Their stories are captivating, all the more because they are perfectly suited for audio. Naturally, The Telepathy Tapes leans heavily on these testimonies. From the opening of the first episode onwards, Dickens implores her audience to not only listen, but to believe the words spoken by oft-ignored parents and teachers. &lt;/p&gt;
        &lt;p&gt;Unshakable faith is an absolute necessity moving forward with the series, because the fantastic claims that follow defy rational explanation. &lt;/p&gt;
        &lt;p&gt;Dickens and her crew travel the United States to both meet nonspeakers who have found means of communicating and — crucially — conduct tests to verify their supposed abilities. To do this, nonspeakers are presented with stencil-like boards bearing numbers and letters, which they use to meticulously spell out messages. This in itself is remarkable, but The Telepathy Tapes takes things a step further. Dickens proceeds to ask nonspeakers to identify numbers drawn from a deck of UNO cards, or write words generated at random on an out-of-sight iPad. The podcast’s carefully curated sound bites suggest that the nonspeakers respond with astounding accuracy. Ever-present caregivers, always privy to the correct answers, enthusiastically encourage their sons, daughters, and students. Dickens posits that this astounding precision is attributable to the crystal-clear line of telepathic communication nonspeakers share with those they’re closest to. &lt;/p&gt;
        &lt;p&gt;After establishing the infallibility of the nonspeaker’s mind-reading abilities, Dickens teases that telepathic communication merely represents “the tip of the iceberg” of autistic superpowers. By episode three, tales are told of non-speakers from across the world gathering on an astral plane called “the Hill” to chat. In episode seven, a little girl named Emelia exhibits an ability to read ancient Egyptian hieroglyphs. When asked how she learned to decipher the symbols, Emelia matter-of-factly spells, one letter at a time, that God taught her. Some nonspeakers are said to be able to predict the future. Others can confer with the dead.&lt;/p&gt;
        &lt;p&gt;Disparate findings from a variety of “scientists” are strung together in an attempt to make further sense of some (but not all) of the extraordinary assertions. Electrical engineer turned parapsychologist Dr. Dean Radin describes the methodology of Ganzfeld experiments, an ESP assessment conducted for the sake of those seeking “proof-oriented research”. Cambridge-educated Dr. Rupert Sheldrake recounts a series of past experiments on potential telepathic bonds shared between humans and dogs. At one point, the notion of quantum entanglement is introduced as a possible explanation for telepathic communication. It’s disjointed, and The Telepathy Tapes knows it. However, definitive scientific proof isn’t really the point. Dickens posits that the majority of phenomena featured on the show lack a concrete explanation because our perception of reality itself is deeply flawed. We, as a species, cling too closely to materialism, the concept that our world is built upon energy and matter alone. Ultimately, the argument for autistic telepathy relies on faith. Specifically, faith in a single assumption: that every thought communicated through nonspeakers is accurate.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Early in the series, Dickens insists that telepathy is a pure form of communication, because the autistic nonspeakers themselves are pure of heart. Throughout, The Telepathy Tapes works hard to establish that all statements fit into a binary of truth and lie. And, as Dickens explains in episode seven, there’s a universal unwillingness to lie among nonspeakers. Why would they tell anything but the truth, given the intense effort it takes for them to produce sentences at all? “We can’t all be lying,” one exasperated mother partway through episode eight sighs.&lt;/p&gt;
        &lt;p&gt;And she’s right. They can’t all be lying. Decades worth of documentation suggests that the messages coming from nonspeakers are something else entirely. In fact, the communication methods employed by the nonspeakers of The Telepathy Tapes are incompatible with intentionality at all.&lt;/p&gt;
        &lt;p&gt;For individuals with speech difficulties, there exists a range of reliable augmentative and alternative communication techniques. In some cases, nonspeakers are able to use AAC techniques that are familiar and straightforward, such as sign language or a simple pencil and paper. Others with profound, comorbid intellectual or physical disabilities require supplemental aids or devices, like tactile and digital picture boards or text-to-speech apps. Such aids take individual impediments into account and allow users to independently convey messages using whatever the skills they have. &lt;/p&gt;
        &lt;p&gt;That said, aided AAC can sometimes feel hollow and unsatisfying. Particularly if you are working with a nonspeaker who may not know how to read or write, messages can be practical but limited. Throughout the years, my brother has sporadically used the Picture Exchange Communication System, or PECS®, which consists of picking out and placing simple laminated picture cards sequentially on a velcro-laced sentence strip. If the mood suits him, he responds to concrete requests, such as what he’d like to eat for dinner, with vague, terse responses such as “CHICKEN” or “SHRIMP”. Rarely are there hints regarding how he’d prefer those dishes be prepared, or what he’d like on the side, or whether he’d like to stay at home or go out to eat. They’re the sort of answers that leave you craving further detail.&lt;/p&gt;
        &lt;p&gt;The communication techniques featured on The Telepathy Tapes participants are something else entirely. They go by several different names: Supported Typing, Typing to Communicate, Rapid Prompting Method (RPM), and Spelling to Communicate (S2C). Dickens uses the catch-all term “Spelling” to refer to them from episode two onwards. &lt;/p&gt;
        &lt;p&gt;Spelling techniques, in theory, offer a degree of communicative freedom, and the deep, insightful, detailed correspondences reflect that. It’s wildly appealing to those who have spent lifetimes making educated guesses regarding the needs and wants of their loved ones.&lt;/p&gt;
        &lt;p&gt;However, the Spelling utilized by the nonspeakers on The Telepathy Tapes is collaborative in a way that spelling, in the traditional sense, is not. Spelling is very much dependent on neurotypical communication partners, who prop up unfixed letter boards, assist in interpreting messages, and occasionally, correct perceived mistakes in messages. They act as guides, and are often (understandably) deeply biased and deeply invested in the success of the nonspeaker. In the case of The Telepathy Tapes, they are the very people claiming to share telepathic connections. &lt;/p&gt;
        &lt;p&gt;Modern Spelling methods are uniformly rooted in a contentious technique called Facilitated Communication (FC). It’s a term most people aren’t familiar with, because the practice fell out of favor before it had a chance to sincerely take off. Dickens herself readily admits that Spelling is a spiritual successor to FC, which she nonchalantly suggests was unfairly dismissed by the ableist masses. Conveniently left out of The Telepathy Tapes story are the uncomfortable controversy that led to the denouncement of FC, and the grueling trials that caused many to lose faith in it entirely.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;When Australian educator and disability advocate Rosemary Crossley first developed Facilitated Communication, her initial reports were nothing short of miraculous.&lt;/p&gt;
        &lt;p&gt;As a hospital assistant in the mid-1970s, Crossley met Anne McDonald, a nonverbal teenager diagnosed with cerebral palsy and severe intellectual disability. Since age 3, Anne had been institutionalized at the St. Nicholas Hospital in Melbourne. The facility was understaffed, its conditions horrendous, and Anne spent much of her time writhing on the floors. Nonetheless, Crossley thought she sensed something special in Anne, a hidden potential that belied all of her previous diagnoses. &lt;/p&gt;
        &lt;p&gt;To realize this, Crossley developed a means of communication centered around pointing out word and letter blocks. However, due to her profound motor and coordination issues, Anne struggled to point. At some point, Crossley thought to support her client’s unsteady arm. Immediately, Anne’s messages became much clearer.&lt;/p&gt;
        &lt;p&gt;Anne lacked any formal education, yet within the span of about three weeks, she was spelling in complete sentences. As time passed, she expressed familiarity with topics ranging from advanced mathematics to international nuclear policy. Crossley speculated she’d picked all this up through overheard conversations and the TV. Eventually, Anne spoke out about the abuses she faced in the institution that housed her, and expressed her desire to escape the substandard living conditions. At one point, she even accused a St Nicholas’ pediatrician of attempting to smother her with a pillow. A subsequent investigation ultimately dismissed these claims, but Crossley did manage to convince a court of Anne’s competency. Anne won her freedom, then went on to earn a humanities degree and pen a memoir, co-written by Crossley.&lt;/p&gt;
        &lt;p&gt;Beautiful, poetic, and — above all — hopeful, the story spread across the country. All along, the only thing Anne needed was for someone to reach out and, quite literally, lend a helping hand. Her newfound words convinced many to reconsider decades' worth of human rights violations occurring in state-run asylums and psychiatric hospitals.&lt;/p&gt;
        &lt;p&gt;Australia’s scientific community was skeptical. However, their misgivings were largely kept private, fearing that to cast doubt on Crossley’s methodology would unintentionally jeopardize the promising strides toward civil liberty the story inspired. It wasn’t until 1987 that the country’s top communications specialists banded together to publish a statement of concern. Specifically, they cited a significant risk that the thoughts and biases of facilitators might muddle the messages of nonspeakers.&lt;/p&gt;
        &lt;p&gt;Even so, Crossley shared her breakthrough technique with other nonspeaking clients. Soon, FC was applied as a blanket treatment for nonspeakers facing a variety of physical and cognitive diagnoses, particularly autistic children. &lt;/p&gt;
        &lt;p&gt;Eventually, word of facilitated communication reached Doug Biklen, a Syracuse University professor researching intellectual disability.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Astounded by the extraordinary outcomes Crossley’s method yielded, Biklen traveled to Australia to record a series of qualitative observations detailing her technique, which were published by the Harvard Educational Review in 1990. Biklen presented a theory that autistic difficulties in communication stemmed from “praxis rather than cognition”. Put simply, he believed autism might be a problem of physical expression rather than cognitive understanding.&lt;/p&gt;
        &lt;p&gt;Word of FC’s efficacy spread through North America with fervor. Biklen touted it as a universally applicable communication aid guaranteed to bring out the locked-away thoughts of nonspeakers. Diane Sawyer described FC as “an awakening.” The New York Times, in a 1991 article, mused that the technique “could upset a half-century of thought” concerning autism treatment. In 1992, Biklen founded the Facilitated Communication Institute at Syracuse University. Students, parents, and clinicians, eager to serve as a conduit for the voiceless, clamored to be trained as facilitators. Story after story emerged of children with limited vocabularies expressing literacy and intellect far surpassing previous expectations.&lt;/p&gt;
        &lt;p&gt;Then a disturbing trend emerged. &lt;/p&gt;
        &lt;p&gt;Letter by letter, a rapidly growing number of newly communicative FC users described graphic accounts of sadistic sexual and physical abuse. Almost always, these accusations pegged loved ones and caretakers as victimizers.&lt;/p&gt;
        &lt;p&gt;Compared to the general population, rates of abuse run markedly higher among those facing intellectual disabilities. It’s also true that a significant number of perpetrators are primary caretakers or disability service providers. Even so, the rate of new allegations was staggering, considering the relatively small number of people practicing FC. By the end of 1994, at least 60 such cases were reported across the United States — which, seasoned AAC professionals were quick to note, far outpaced rates of abuse reported by nonspeakers communicating through independent means.&lt;/p&gt;
        &lt;p&gt;Trusted teachers faced termination and permanently tarnished career prospects. Devoted parents were caught entirely off guard by brutal rape allegations. Some cases culminated in criminal charges. Accused parties faced harsh consequences, including decades of jail time and staggering legal fees. &lt;lb/&gt;In one exceptionally extreme case covered in a 1993 FC-centered Frontline report, 16-year-old Betsy Wheaton accused everyone in her family – father, mother, brother, even grandparents – of sexual abuse. As a precaution, Betsy was thrust into the foster care system. While separated from her family, Betsy lost ten pounds, suffered two black eyes, and developed a severe ear infection that went undetected for weeks before rupturing.&lt;/p&gt;
        &lt;p&gt;Betsy’s physical deterioration signaled to investigators something very wrong was afoot. Despite enduring excruciating physical pain, Betsy never used FC to express her discomfort. The local attorney covering her case then began to question whether Betsy was as capable of communication as she seemed.&lt;/p&gt;
        &lt;p&gt;The court had a moral dilemma to untangle. If Betsy’s communications were accurate, sending her home would be unconscionable. If they weren’t, keeping her in the foster system would be unjust. All parties agreed to consult with an expert in communication. Betsy was brought to Boston Children’s Hospital, where Dr. Howard Shane conducted a series of tests to determine Betsy’s true communicative prowess. Frontline described them as follows:&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;“Shane had devised a double-blind test…to objectively determine who was authoring the messages, Betsy or the facilitator who transcribed the allegations. He showed both a series of pictures and asked them to type what they saw. When both Betsy and her facilitator saw a picture of a key, the letters K-E-Y were typed. But Shane wanted to discover what would happen if each saw a different picture. When Betsy saw a cup, she didn't type "cup," she instead typed "hat" — what the facilitator saw. So too when she was shown a boat but spelled “sandwich,” or was shown a dog but spelled “sneakers.” &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The findings were bittersweet. Betsy’s family was cleared of wrongdoing, but the determination brought with it broader, disturbing insinuations regarding FC. The results of Dr. Shane’s testing suggested that, whether intentionally or not, facilitators were influencing facilitated messages. They cast doubt on the driving philosophy of FC: the idea that “good” minds are locked behind faulty, apraxic, inherently uncooperative bodies. &lt;/p&gt;
        &lt;p&gt;The unsettling discovery kicked off a series of similar controlled studies testing for evidence of independent authorship through FC, conducted between 1992 and 2014. The results they yielded were unequivocal: across thousands of hours of experiments conducted on more than three hundred and sixty participants, just six showed evidence of independent communication through FC. In simple message-passing and double-blind tests, study participants almost uniformly failed. Conversely, whenever facilitators knew the right answers, participants consistently provided accurate responses.&lt;/p&gt;
        &lt;p&gt;Most taken aback by these results were the facilitators themselves. Despite having good intentions, facilitators were unwittingly falling victim to the ideomotor effect; automatic muscular movements, tainted by unconscious thought.&lt;/p&gt;
        &lt;p&gt;This phenomenon was first identified in the mid-19th century, at the height of the Spiritualism movement. Nearly two hundred years before the recording of The Telepathy Tapes, scientists were puzzled by lost souls channeled through planchette-wielding mediums. Rigorous testing led inquiring minds to conclude that simple suggestions can oftentimes influence minuscule, involuntary motions.&lt;/p&gt;
        &lt;p&gt;Part of caring for a nonspeaker is to be vigilant and attentive. Family members and care workers cooperate in the interest of loved ones, but also often maintain a healthy degree of suspicion in one another. After all, abuse is most likely to happen in the home or classroom, and nonspeakers cannot easily advocate for themselves. It’s entirely possible that small grains of unconscious mistrust, fed by nightmarish hypotheticals, were the catalyst that sparked the slew of graphic allegations. Through the ideomotor phenomenon, FC contorted legitimate devotion and love into something monstrous..&lt;/p&gt;
        &lt;p&gt;Still, some families and educators weren’t ready to give up on FC. Accepting the nature of the ideomotor phenomenon is easy enough when it’s used to rationalize the realm of Ouija boards, hypnotists, and carnival bits. But FC felt real. It was the answer to a million desperate prayers. No parent wants their child’s declarations of love compared to a show pony trick. No teacher wants their valiant efforts likened to the mechanics of a children’s game. Scientific findings become secondary when you’ve seemingly seen a miracle happen before your eyes. The idea of letting go was unbearable.&lt;/p&gt;
        &lt;p&gt;So instead of fading into obscurity, FC quietly continued. The pain of past tragedies dulled, and advocates, unconvinced of the risks, perpetuated the practice.&lt;/p&gt;
        &lt;p&gt;In their eyes, little harm could come from trying.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;30 years have passed. Surface-level changes have obscured FC just enough to hide its ugly past. But for those intimately familiar with the practice, it’s all too obvious that little has effectively changed. &lt;/p&gt;
        &lt;p&gt;A cosmetic rebrand has partially allowed FC to avoid further scrutiny. As early as 2014, John Hussman – a hedge fund manager turned FC philanthropist – emphasized a need to phase out the term “facilitated communication.” While speaking at an FC conference held in Syracuse, he called for advocates of the technique to “come up with some other name to fly under the radar and maintain credibility.” Spelling — again, Dickens’ preferred term — has since taken its place.&lt;/p&gt;
        &lt;p&gt;Spelling skirts FC comparisons due to a single fundamental difference. To avoid accusations of outside influence, communication partners are discouraged from touching nonspeakers during sessions. Instead, communication partners are instructed to suspend a letter board in front of nonspeakers. It’s argued that the lack of physical contact makes it impossible for facilitators to influence messages.&lt;/p&gt;
        &lt;p&gt;In practice, however, touch often plays a role in the Spelling process. The very first example of telepathy in an autistic nonspeaker, introduced 15 minutes into the very first episode of The Telepathy Tapes, featured a 12-year-old named Mia whose mother held her head as she pointed to her letter board. “I'm one of these people that thinks whatever the individual needs to help them communicate, it's okay,” Ky Dickens later divulged in her interview with Joe Rogan. “If you need a little touch so you know where your arm is, or sometimes it helps you go faster if there's a little push, I think, go for it.”&lt;/p&gt;
        &lt;p&gt;Even in ideal scenarios where there is no physical contact between nonspeakers and communication partners, the danger of message interference still exists. Facilitators still maintain control of the letter board they hold. Even the steadiest hands are wont to drift, no doubt driven by conscious or subconscious desire for there to be some profound meaning in the words-in-progress. The slightest inadvertent slip is all it takes to move a board just enough to change the meaning of a message entirely.&lt;/p&gt;
        &lt;p&gt;This tendency is perhaps best illustrated in a 2024 documentary simply titled SPELLERS THE MOVIE. Around the four-minute mark, a nonspeaker named Aiden selects GQREKA, which is interpreted as GREA, before the facilitator shifts the board to better position the letter T in the path of Aiden’s pointer. The same subtle mid-word movements can be seen around the 11-minute mark, when Jamie points to characters on a laminated alphabet held out by his father, and again at the 21-minute mark, when Cade spells with a facilitator after a day spent at the beach.&lt;/p&gt;
        &lt;p&gt;It’s difficult to rule out influence, even in scenarios where communication partners aren’t touching letter boards at all. The involuntary blinks and twitches of a communication partner several feet away might not register to an unfamiliar onlooker, but provide a wealth of information to a nonspeaker with an intimate bond and a lifetime of experience interpreting body language. &lt;/p&gt;
        &lt;p&gt;These blatant perils are still largely unknown. Stories glorifying FC and Spelling sporadically attract mainstream recognition. As recently as October 2025, the New York Times published a letter to the editor which is very likely a facilitated message claiming that profound autism does not exist. Doug Biklen has co-produced at least two feature-length documentaries on the subject, one of which, Autism is a World, received an Academy Award nomination in 2005.&lt;/p&gt;
        &lt;p&gt;Communication “success” stories have found a niche in short-form, feel-good formats that don’t bother to dig deep into difficult details. Now and then, you’ll find inspirational speech journeys featured as a human-interest puff piece for a local news station. And sometimes, there’s reason to believe that the subjects have in fact found a voice. But little effort is made to distinguish the differences between the child who independently expresses themself through an image-based AAC iPad app and the child who relies on facilitator intervention heavily susceptible to bias. Messy histories, efficacy rates, and complicated ethical considerations are elided in favor of a five-minute snippet of hope.&lt;/p&gt;
        &lt;p&gt;As cable television has atrophied, these incomplete narratives have migrated to the feral internet, to platforms like YouTube and TikTok, where they’ve found larger audiences than ever. There, they are entirely unbound by any semblance of journalistic integrity. Under tags like #s2c and #rapidpromptingmethod and #autismodyssey are posts akin to diary entries, chronicling efforts to reach nonspeakers.&lt;/p&gt;
        &lt;p&gt;It’s hard to be angry with such content creators, or the vast majority of people who turn to Spelling as a means of support. Few are dishonest or seeking clout. Instead, most feel that documenting their experience is a means of giving back to the community. Without trudging through the damning findings, the reports that explain the mechanical risks, a speller in action is an incredibly convincing sight — the sort of wonder you’d be crazy not to evangelize. In all likelihood, some Spelling advocates aren’t aware that there’s any reason to be cautious at all. &lt;/p&gt;
        &lt;p&gt;And they never learn, because skeptics generally don’t care to push back. They face the same dilemma that Australian speech pathologists faced in the 80s, when FC was first unleashed. At best, poking at the truth risks dismantling the dreams of people who have endured struggles unimaginable to most, who have done nothing wrong, without so much as a promising alternative. At worst, doubting capability can be misconstrued by bad actors and defensive caregivers as an attack on the very humanity of a nonspeaker. &lt;/p&gt;
        &lt;p&gt;And in the collective, comfortable silence, nothing has changed.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The Telepathy Tapes claims to be a paradigm shift. In actuality, claims of an autism and telepathy link have festered for decades. In 1960, child psychologist Dr. Mira Rothenberg, in her book Children with Emerald Eyes, described the “penetrating unconscious communication” shared between autistic individuals and their mothers as telepathic. Archived Usenet forums dating as far back as 1992 speak of links drawn between FC and paranormal phenomena. “Telepathy is another mode of expression bonded in intimacy…while many of our loved ones with autism may be blessed with the gift of telepathy, they may not yet fully comprehend it. A gentle and loving caregiver will need to explain it,” author William Stillman wrote in a 2006 publication titled Autism and the God Connection.&lt;/p&gt;
        &lt;p&gt;Stillman’s words touch on a long-established trope of caretaker as savior, of “something more” being reached through the arduous efforts of someone who believes hard enough. It’s the overarching theme that colors FC since the first dialogues between Rosemary Crossley and Anne McDonald. &lt;/p&gt;
        &lt;p&gt;Should you choose to pay $9.99 and gain lifetime access to footage depicting uncontrolled tests conducted by The Telepathy Tapes crew, you’ll witness the same red flags indicating ideomotor interference that have long troubled psychologists. Supportive hands, unstable letter boards, and anticipatory mothers an arm’s reach away link together The Telepathy Tapes “evidence”, and serve as visual confirmation of the complete lack of care concerning potential facilitator bias. &lt;/p&gt;
        &lt;p&gt;It’s all part of an endless cycle of fallacy, sustained by inaction. Even so, Dickens is not entirely off when she presents a tectonic shift in reality. Or rather, a wholehearted rejection of it. &lt;/p&gt;
        &lt;p&gt;For months, I was puzzled as to why a great number of listeners wholly ignorant of the autistic experience were so enamoured by The Telepathy Tapes. Those seeking to navigate relationships with nonspeakers do not have the luxury of ignoring reports that might offer some sliver of insight into their loved ones, but everyone else has a sea of content to sift.&lt;/p&gt;
        &lt;p&gt;With the October 2025 premiere of the second season, though, I feel I’m finally starting to understand. Moving forward, the series has expressed a desire to explore the wider nature of consciousness and explore topics outside of the autistic community. No longer is the focus on the voiceless. As much as it might try to convince audiences otherwise, The Telepathy Tapes was never about disability advocacy or propelling the stories of marginalized caretakers. It’s always been a larger call to rebel, and to disregard everything you think you know in favor of a defiant unknown. &lt;/p&gt;
        &lt;p&gt;This is the selling point that caught the attention of Joe Rogan and sent the podcast soaring to popularity. It’s a message that speaks to a wide range of people newly discontented with consensus reality: the psychonaut whose epistemics have been permanently disrupted by ego-death, the post-rationalist convinced that “magic” is just the term we use for phenomenology we don’t understand, the meditators who’ve touched something transcendent and abandoned skepticism in favor of a more open and permissive worldview. The notion of telepathy is beguiling to wildly successful innovators who grew up on sci-fi and refuse to be limited by outdated standards and reasoning in their efforts to push forward. Last year, Elon Musk proclaimed that the first Neuralink brain implant would quite literally be marketed as “Telepathy”, and this past spring, the company filed an application with the US Patent and Trademark Office for exclusive ownership of the term. Meanwhile, Dr. Julia Mossbridge, who is collaborated Dickens in the second season of The Telepathy Tapes, has toyed with the development of AI agents capable of unconditional love. Telepathy is irresistible to those who view themselves as boundary pushers who spend their days trying to defy what’s possible.&lt;/p&gt;
        &lt;p&gt;Non-speakers and the ones closest to them simply serve as the emotionally-charged lynchpin that holds the anti-establishment romance together. &lt;/p&gt;
        &lt;p&gt;It’s impossible to say whether or not The Telepathy Tapes would have resonated with audiences ten years ago, before COVID, when truth felt a little less fragile. Perhaps the siren call to suspend disbelief is one we’ll always be drawn to. After all, if the content of The Telepathy Tapes proves anything, it’s that we’re fated to repeat ourselves, no matter how detrimental the end results may be. We are — have always been — desperate to believe that we are something more than meets the eye.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;All the while, promises to “Make America Healthy Again” imply that we are all somehow profoundly sick; frequently, it’s been implied that autism is one of the primary culprits holding us back from greatness. With autism rates rising to 1 in 31, anxiety is at a fever pitch. It hardly matters whether the uptick is due to some environmental epidemic or complex genetics or a change in diagnostic criteria, just that we find a way to reverse course. &lt;/p&gt;
        &lt;p&gt;When RFK Jr. and Dr. Oz talk of “cures”, I recoil, because my brother’s autism is so deeply ingrained in his identity that imagining him otherwise is impossible. The notion of somehow erasing autism is one both deeply unrealistic and not particularly comforting to those who live within and alongside it each passing day. &lt;/p&gt;
        &lt;p&gt;The Telepathy Tapes offers something slightly more attainable than a mythical cure. It presents a reality where nonspeakers, beneath their perceived deficits, are the same as, if not superior to, everyone else. &lt;/p&gt;
        &lt;p&gt;The first thing Ky Dickens claims, at the opening of her podcast, is that the loved ones of nonspeakers are being ignored. As one of those loved ones, this is what I’d like the world to hear: my brother’s greatness is not conditional on being just like everyone else. He is representative of everything fearmongers catastrophize. There are things that he will always struggle with, and parts of him I’ll never know. And that’s okay. None of that matters. He is fascinating and wonderful, challenges and all. &lt;/p&gt;
        &lt;p&gt;My greatest desire is that he somehow finds a way to say everything he might want to say, not for my sake, but his own. I think this was all my grandmother wanted, too, when she spoke of conversing in dreams. To hear him state in eloquent, unambiguous terms that he thinks about me as much as I think of him, that he’s always cared for me in his own quiet way, would be phenomenal. &lt;/p&gt;
        &lt;p&gt;Even so, my love for him — not my idea of some trapped, imaginary, internal him, but the wordless him that physically inhabits this world — trumps that pining. There is no need to demonstrate “something more” than I can see and hear. He is inherently worthy of respect and dignity, not something to be feared. I want the world to know that my brother is human, no more, no less. And should he ever find a way to share the things I long to hear, I want there to be no questions of where they’re coming from.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://asteriskmag.com/issues/12-books/paradigm-shifted-the-perplexing-appeal-of-the-telepathy-tapes"/><published>2025-11-11T13:34:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887536</id><title>Show HN: Tusk Drift – Open-source tool for automating API tests</title><updated>2025-11-11T17:39:19.485146+00:00</updated><content>&lt;doc fingerprint="3122664bacfeec83"&gt;
  &lt;main&gt;
    &lt;p&gt;The Node.js Tusk Drift SDK enables fast and deterministic API testing by capturing and replaying API calls made to/from your service. Automatically record real-world API calls, then replay them as tests using the Tusk CLI to find regressions. During replay, all outbound requests are intercepted with recorded data to ensure consistent behavior without side-effects.&lt;/p&gt;
    &lt;p&gt;For comprehensive guides and API reference, visit our full documentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Initialization Guide - Set up the SDK in your Node.js application&lt;/item&gt;
      &lt;item&gt;Environment Variables - Environment variables reference&lt;/item&gt;
      &lt;item&gt;Quick Start Guide - Record and replay your first trace&lt;/item&gt;
      &lt;item&gt;Troubleshooting Guide - Common issues and solutions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tusk Drift currently supports the following packages and versions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;HTTP/HTTPS: All versions (Node.js built-in)&lt;/item&gt;
      &lt;item&gt;GRPC: &lt;code&gt;@grpc/grpc-js@1.x&lt;/code&gt;(Outbound requests only)&lt;/item&gt;
      &lt;item&gt;PG: &lt;code&gt;pg@8.x&lt;/code&gt;,&lt;code&gt;pg-pool@2.x-3.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Firestore: &lt;code&gt;@google-cloud/firestore@7.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Postgres: &lt;code&gt;postgres@3.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;MySQL: &lt;code&gt;mysql2@3.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;IORedis: &lt;code&gt;ioredis@4.x-5.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Upstash Redis: &lt;code&gt;@upstash/redis@1.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;GraphQL: &lt;code&gt;graphql@15.x-16.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Prisma: &lt;code&gt;prisma@5.x-6.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;JSON Web Tokens: &lt;code&gt;jsonwebtoken@5.x-9.x&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;JWKS RSA: &lt;code&gt;jwks-rsa@1.x-3.x&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you're using packages or versions not listed above, please create an issue with the package + version you'd like an instrumentation for.&lt;/p&gt;
    &lt;p&gt;First, install and configure the Tusk Drift CLI by following our CLI installation guide. The CLI helps set up your Tusk configuration file and replays tests.&lt;/p&gt;
    &lt;p&gt;The wizard will eventually direct you back here when it's time to set up the SDK.&lt;/p&gt;
    &lt;p&gt;After completing the CLI wizard, install the SDK:&lt;/p&gt;
    &lt;code&gt;npm install @use-tusk/drift-node-sdk&lt;/code&gt;
    &lt;p&gt;Refer to our initialization guide to set up the SDK for your service.&lt;/p&gt;
    &lt;p&gt;Follow along our quick start guide to record and replay your first test!&lt;/p&gt;
    &lt;p&gt;Having issues?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Read our troubleshooting doc&lt;/item&gt;
      &lt;item&gt;Create an issue or reach us at support@usetusk.ai.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Join our open source community on Slack.&lt;/p&gt;
    &lt;p&gt;We appreciate feedback and contributions. See CONTRIBUTING.md.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Use-Tusk/drift-node-sdk"/><published>2025-11-11T14:18:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887709</id><title>Show HN: Gametje – A casual online gaming platform</title><updated>2025-11-11T17:39:19.171233+00:00</updated><content>&lt;doc fingerprint="9097803aa597369"&gt;
  &lt;main&gt;
    &lt;p&gt;Gametje requires javascript to function properly. GAMETJE ...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gametje.com"/><published>2025-11-11T14:36:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887857</id><title>Drawing Text Isn't Simple: Benchmarking Console vs. Graphical Rendering</title><updated>2025-11-11T17:39:18.394023+00:00</updated><content>&lt;doc fingerprint="266a99377fb93586"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Drawing Text on Screen - What Could Be Simpler?&lt;/head&gt;
    &lt;p&gt;So, this all started because I decided to learn Go. Polyglots say the best way to learn one is by doing something fun with it. Some watch movies, some read, some play with flashcards, others just jump into deep water and start talking with zero vocabulary.&lt;/p&gt;
    &lt;p&gt;I figured that logic should work for programming languages too - so I picked a fun target project: writing a text-based file manager. Think old-school Norton Commander or Dos Navigator. My personal favorite is still FAR Manager - it's insanely productive, still actively developed, and honestly the main reason I haven't switched to Linux or macOS yet.&lt;/p&gt;
    &lt;p&gt;Anyway, FAR Manager's code is in a language I don't speak, and writing plugins wouldn't get me where I want, so... I decided to just rewrite the whole thing. Easy, right? I know it's ridiculous, but that's fine - I like big impossible projects. Aim for the Moon, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Plan&lt;/head&gt;
    &lt;p&gt;I won't spoil the full idea (still might build it), but I disclose these two main modules:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Input handling (keyboard, mouse)&lt;/item&gt;
      &lt;item&gt;Output handling (drawing text on screen)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's skip the boring input stuff - it works, after wrestling with all the quirks of Windows' console mode. Long story short: the “modern” VT (Virtual Terminal) mode that Windows adopted from Linux is slower output and dumber input than the old API. It doesn't even tell you when Shift is pressed, only when you actually type an uppercase letter with it. Add in a few more edge cases like Ctrl+Alt+Shift chaos, and you get the idea. I found workarounds, though, so keyboard input is mostly done.&lt;/p&gt;
    &lt;p&gt;Now, the fun part.&lt;/p&gt;
    &lt;head rend="h2"&gt;Output: Drawing Text&lt;/head&gt;
    &lt;p&gt;How hard can it be to draw letters on a screen, right?&lt;/p&gt;
    &lt;p&gt;There are several ways to do it in the Windows console:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Old way: &lt;code&gt;WriteConsoleOutputW&lt;/code&gt;- directly dump characters and color data to the screen.&lt;/item&gt;
      &lt;item&gt; New way: &lt;code&gt;WriteConsoleW&lt;/code&gt;- embed color codes in the text (the VT way), richer (e.g. bold, italic, underline)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The new one is half as fast. On a modern mid-range PC, that's just sad.&lt;/p&gt;
    &lt;p&gt;So I looked for better options - maybe GPU acceleration? Some people pointed me to GPU-powered terminals with buttery-smooth rendering. Sounded good, so I dug deeper.&lt;/p&gt;
    &lt;p&gt;After days of poking Go, forums, and LLMs, it became clear that Go is not made for things like this. So I switched to something battle-tested: C#. (And if anyone tells you "every language can do anything", please slap them with a large trout. I mean, sure - but at what cost?)&lt;/p&gt;
    &lt;p&gt;C# means .NET, which can power full-blown 3D games, so drawing text should be child's play! I tried three rendering paths:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;GDI - the classic Windows graphics interface. Works even "without" a GPU, so obviously not fast.&lt;/item&gt;
      &lt;item&gt;DirectX - the big guns, made for real-time 3D games.&lt;/item&gt;
      &lt;item&gt;Vulkan - similar to DirectX but cross-platform.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I built a simple benchmark using all three plus the two console methods. The screen was 240x63 characters (Full HD with a 8x16 font). Test conditions were intentionally rough - every character with random colors - just to stress the system.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results (random colors everywhere)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Renderer&lt;/cell&gt;
        &lt;cell role="head"&gt;240x63&lt;/cell&gt;
        &lt;cell role="head"&gt;80x25&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleOutputW&lt;/cell&gt;
        &lt;cell&gt;20.3&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleW&lt;/cell&gt;
        &lt;cell&gt;12.9&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GDI&lt;/cell&gt;
        &lt;cell&gt;22.2&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vulkan&lt;/cell&gt;
        &lt;cell&gt;23.5&lt;/cell&gt;
        &lt;cell&gt;175.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DirectX&lt;/cell&gt;
        &lt;cell&gt;17.6&lt;/cell&gt;
        &lt;cell&gt;130.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All of them sucked, basically. Even with optimizations. But I measured the "optimistic" ways as well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results (realistic: white on black)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Renderer&lt;/cell&gt;
        &lt;cell role="head"&gt;240x63&lt;/cell&gt;
        &lt;cell role="head"&gt;80x25&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleOutputW&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleW&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GDI&lt;/cell&gt;
        &lt;cell&gt;62.4&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vulkan&lt;/cell&gt;
        &lt;cell&gt;114.4&lt;/cell&gt;
        &lt;cell&gt;733.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DirectX&lt;/cell&gt;
        &lt;cell&gt;140.2&lt;/cell&gt;
        &lt;cell&gt;944.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Now we're talking. GPU rendering finally pays off - DirectX crushed it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Different Angle&lt;/head&gt;
    &lt;p&gt;Turns out the real bottleneck isn't the rendering API - it's Windows' font drawing (which is sadly CPU-bound). So I tried something unconventional: draw each character once, cache it as a texture, and then just copy those textures around. Copying pixels is much faster than redrawing fonts every frame.&lt;/p&gt;
    &lt;p&gt;That alone gave a massive speed bump in stress test (random colors):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Resolution&lt;/cell&gt;
        &lt;cell role="head"&gt;DirectX + Texture&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;240x63&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80x25&lt;/cell&gt;
        &lt;cell&gt;450.1&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Nice jump - but there's a catch.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Catch&lt;/head&gt;
    &lt;p&gt;Texturing looks great on paper, but you lose flexibility. You can't really optimize texture copies much more. On the other hand, writing text directly can be heavily optimized - for example, drawing an entire line at once when color and style match. That gives 5-7x speedups in practice.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Resolution&lt;/cell&gt;
        &lt;cell role="head"&gt;DX + text&lt;/cell&gt;
        &lt;cell role="head"&gt;DX + texture&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;240x63&lt;/cell&gt;
        &lt;cell&gt;17.6&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
        &lt;cell&gt;+377% (stress test)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;80x25&lt;/cell&gt;
        &lt;cell&gt;130.5&lt;/cell&gt;
        &lt;cell&gt;450.1&lt;/cell&gt;
        &lt;cell&gt;+345% (stress test)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;240x63&lt;/cell&gt;
        &lt;cell&gt;140.2&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
        &lt;cell&gt;-47% (normal use)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80x25&lt;/cell&gt;
        &lt;cell&gt;944.5&lt;/cell&gt;
        &lt;cell&gt;450.1&lt;/cell&gt;
        &lt;cell&gt;-47% (normal use)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So - caching helps in extreme cases, but slows things down in normal ones.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The sweet spot is DirectX + direct text drawing. It's fast enough, flexible, and still keeps the door open for fancier options like Vulkan if I ever go cross-platform.&lt;/p&gt;
    &lt;p&gt;Moral of the story: Drawing text on screen isn't simple, most of the internet forums got the bottleneck wrong, only a selected few know what's really happening under the hood.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cv.co.hu/csabi/drawing-text-performance-graphical-vs-console.html"/><published>2025-11-11T14:49:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887958</id><title>Blender 5.1</title><updated>2025-11-11T17:39:17.723289+00:00</updated><content>&lt;doc fingerprint="63c8653952c5b5da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Blender 5.1 Release Notes¶&lt;/head&gt;
    &lt;p&gt;Blender 5.1 is currently in Alpha until February 4, 2026. See schedule.&lt;/p&gt;
    &lt;p&gt;Under development in &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Animation &amp;amp; Rigging&lt;/item&gt;
      &lt;item&gt;Assets&lt;/item&gt;
      &lt;item&gt;Compositor&lt;/item&gt;
      &lt;item&gt;Core&lt;/item&gt;
      &lt;item&gt;Cycles&lt;/item&gt;
      &lt;item&gt;EEVEE &amp;amp; Viewport&lt;/item&gt;
      &lt;item&gt;Geometry Nodes&lt;/item&gt;
      &lt;item&gt;Grease Pencil&lt;/item&gt;
      &lt;item&gt;Modeling &amp;amp; UV&lt;/item&gt;
      &lt;item&gt;Motion Tracking&lt;/item&gt;
      &lt;item&gt;Physics&lt;/item&gt;
      &lt;item&gt;Pipeline &amp;amp; I/O&lt;/item&gt;
      &lt;item&gt;Python API&lt;/item&gt;
      &lt;item&gt;Rendering&lt;/item&gt;
      &lt;item&gt;Sculpt, Paint, Texture&lt;/item&gt;
      &lt;item&gt;User Interface&lt;/item&gt;
      &lt;item&gt;Video Sequencer&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://developer.blender.org/docs/release_notes/5.1/"/><published>2025-11-11T14:58:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45888143</id><title>Grebedoc – static site hosting for Git forges</title><updated>2025-11-11T17:39:17.262887+00:00</updated><content>&lt;doc fingerprint="b09023494ec63381"&gt;
  &lt;main&gt;&lt;p&gt;In short: a service that publishes the &lt;code&gt;pages&lt;/code&gt; branch in your Git repository as a website on your domain; think GitHub Pages if it was open source and community operated.&lt;/p&gt;&lt;p&gt;More specifically, it is a public deployment of git-pages and Caddy configured to work especially with Codeberg but also with other Git forges. It is operated by Catherine 'whitequark' and teammates, and currently deployed using Rage4 anycast infrastructure routing to VPSes in six regions (Europe, North America East, North America West, South America, East Asia, Australia), with site contents stored on Tigris and backed up to Wasabi.&lt;/p&gt;&lt;p&gt;This service is provided as a public utility, especially for those migrating from GitHub to community operated forges, and we plan to operate it indefinitely. It is monitored and has a status page.&lt;/p&gt;&lt;p&gt;The size of a website is currently limited to 768 MiB. We are aiming to eventually raise this to 10 GiB.&lt;/p&gt;&lt;p&gt;Currently, we set COOP/COEP headers on all &lt;code&gt;text/html&lt;/code&gt; files by default. This is about to change, so please monitor the linked issue for updates if you make use of &lt;code&gt;SharedArrayBuffer&lt;/code&gt; in your code.&lt;/p&gt;&lt;p&gt;git-pages is a self-service static site server for the general public. It is efficient, reliable, scales horizontally to any number of nodes, and deployable in under 5 minutes. It is designed to work with an S3-compatible object store such as MinIO, and integrates with Caddy for TLS termination and on-demand certificate provisioning. It accepts webhook events from Forgejo, Gitea, Gogs, and GitHub. See the git-pages README for more details.&lt;/p&gt;&lt;p&gt;Unlike the pull-based architecture of the similar codeberg.page service, this service is push-based: the forge must notify the pages server whenever there is a content update. This makes it much more efficient, but requires the forge to be configured for publishing (via CI or a webhook).&lt;/p&gt;&lt;p&gt;Publishing a site using git-pages is done using a &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; request to the same URL where the contents will appear. The server is compatible with many popular publishing workflows and has multiple flexible authorization methods.&lt;/p&gt;&lt;p&gt;Select repository &amp;gt; Settings &amp;gt; Webhooks &amp;gt; Add webhook &amp;gt; Forgejo, then configure only the following:&lt;/p&gt;&lt;code&gt;pages&lt;/code&gt; or &lt;code&gt;{username}.grebedoc.dev&lt;/code&gt;): &lt;code&gt;http://{username}.grebedoc.dev/&lt;/code&gt;&lt;code&gt;{repository}&lt;/code&gt;): &lt;code&gt;http://{username}.grebedoc.dev/{repository}/&lt;/code&gt;&lt;code&gt;pages&lt;/code&gt;&lt;p&gt;Leave everything else at the default values and select Add webhook. Next update to the &lt;code&gt;pages&lt;/code&gt; branch will cause its contents to become available at the target URL.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the webhook for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;Method A: To prove that you control the domain, update the configuration of your domain to add a &lt;code&gt;TXT&lt;/code&gt; record at the &lt;code&gt;_git-pages-repository&lt;/code&gt; subdomain with the full git clone URL (something like &lt;code&gt;https://forge.tld/user/repo.git&lt;/code&gt;) as its value.&lt;/p&gt;&lt;p&gt;Method B: To prove that you control the domain, generate a strong password (32 or more random alphanumeric characters) and compute a challenge as: &lt;code&gt;SHA256("{domain} {password}")&lt;/code&gt;. This can be done by running &lt;code&gt;echo -n "{domain} {password}" | sha256sum&lt;/code&gt; in the terminal, or with the following JavaScript-based form:&lt;/p&gt;&lt;p&gt;Update the configuration of your domain to add a &lt;code&gt;TXT&lt;/code&gt; record at the &lt;code&gt;_git-pages-challenge&lt;/code&gt; subdomain with the challenge as its value.&lt;/p&gt;&lt;p&gt;Important! Keep the password secret. Anyone who knows it can replace the contents of your static site with anything they want.&lt;/p&gt;&lt;p&gt;After using Method A or Method B, configure your domain to have &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;AAAA&lt;/code&gt; records pointing to the same server as &lt;code&gt;grebedoc.dev&lt;/code&gt;. In most cases this can be done using an &lt;code&gt;ALIAS&lt;/code&gt; record, but if this functionality isn't available it will need to be done by hand.

&lt;/p&gt;&lt;p&gt;Select repository &amp;gt; Settings &amp;gt; Webhooks &amp;gt; Add webhook &amp;gt; Forgejo, then configure only the following:&lt;/p&gt;&lt;code&gt;http://{domain}/&lt;/code&gt; or &lt;code&gt;http://{domain}/{subdir}/&lt;/code&gt; (only one level of directories can be used)&lt;code&gt;pages&lt;/code&gt;&lt;code&gt;Pages {password}&lt;/code&gt; (Method B only)&lt;p&gt;Leave everything else at the default values and select Add webhook. The next time the &lt;code&gt;pages&lt;/code&gt; branch is pushed, its contents will be published at the target URL.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the webhook for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;This configuration method is not limited to Codeberg; it works with any Forgejo, Gitea, Gogs, or GitHub based forge. If the forge does not make it possible to supply an &lt;code&gt;Authorization:&lt;/code&gt; header, use &lt;code&gt;http://Pages:{password}@{domain}/&lt;/code&gt; as the target URL instead.&lt;/p&gt;&lt;p&gt;Follow the DNS configuration steps for Method A or Method B as described above. Next, configure your forge or Git repository to issue a &lt;code&gt;PUT&lt;/code&gt; HTTP request after a branch has been updated with this Curl command (or its equivalent):&lt;/p&gt;&lt;p&gt;For Method A: &lt;code&gt;curl http://{domain}/ -X PUT --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For Method B: &lt;code&gt;curl http://{domain}/ -X PUT -H "Authorization: Pages {password}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;The optional &lt;code&gt;-H "X-Pages-Branch: {branch}"&lt;/code&gt; argument may be used to publish from a branch other than &lt;code&gt;pages&lt;/code&gt;. This functionality requires the &lt;code&gt;PUT&lt;/code&gt; method to be used, and is not available with webhooks.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;Follow the DNS configuration steps for Method B (only) as described above. Next, make a ZIP or tar archive of your site and upload it with this Curl command (or its equivalent):&lt;/p&gt;&lt;p&gt;For a ZIP archive: &lt;code&gt;curl http://{domain}/ -X PUT -H "Authorization: Pages {password}" -H "Content-Type: application/zip" --data-binary @{archive}&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For a tar archive: &lt;code&gt;curl http://{domain}/ -X PUT -H "Authorization: Pages {password}" -H "Content-Type: application/x-tar" --data-binary @{archive}&lt;/code&gt;&lt;/p&gt;&lt;p&gt;It is also possible to upload a &lt;code&gt;.tar.gz&lt;/code&gt; (&lt;code&gt;Content-Type: application/x-tar+gzip&lt;/code&gt;) or a &lt;code&gt;.tar.zst&lt;/code&gt; (&lt;code&gt;Content-Type: application/x-tar+zstd&lt;/code&gt;) archive. Using Zstandard level 0 to 3 is recommended, especially for large sites: it is a very efficient compression algorithm that will likely reduce the total energy used to publish the site.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;Follow the DNS configuration steps for Method A or Method B as described above. Before altering the &lt;code&gt;ALIAS&lt;/code&gt; or &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;AAAA&lt;/code&gt; records, use the following Curl command (or its equivalent) to publish your site at the new server:&lt;/p&gt;&lt;p&gt;For Method A: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For Method B: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" -H "Authorization: Pages {password}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Verify the deployment by requesting the index page: &lt;code&gt;curl https://grebedoc.dev/ -H "Host: {domain}"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Now, alter the &lt;code&gt;ALIAS&lt;/code&gt; or &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;AAAA&lt;/code&gt; records for your domain.&lt;/p&gt;&lt;p&gt;Add a file named &lt;code&gt;_redirects&lt;/code&gt; at the root of your repository or archive. See the Codeberg documentation for a reference of the syntax. Note that the &lt;code&gt;_redirects&lt;/code&gt; file will not be accessible from your site after publishing; it will only alter how your site works.&lt;/p&gt;&lt;p&gt;It is possible to enter malformed rules in the &lt;code&gt;_redirects&lt;/code&gt; file. Such problems will not prevent your site from being published, but the malformed rules are ignored. Any problems are reported in the response to the &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; request used to publish your site (your forge will display them on the webhook configuration page); they are also available at the special &lt;code&gt;https://{host}/.git-pages/manifest.json&lt;/code&gt; or &lt;code&gt;https://{host}/{site}/.git-pages/manifest.json&lt;/code&gt; URL, which describes how git-pages understands the layout of your site.&lt;/p&gt;&lt;p&gt;Add a file named &lt;code&gt;_headers&lt;/code&gt; at the root of your repository or archive. See the Netlify documentation for a reference of the syntax; note that &lt;code&gt;*&lt;/code&gt; is currently allowed only by itself and as the last path segment, unlike on Netlify. Note also that the &lt;code&gt;_headers&lt;/code&gt; file will not be accessible from your site after publishing; it will only alter how your site works.&lt;/p&gt;&lt;p&gt;Only custom headers that are a part of the following allowlist may be used:&lt;/p&gt;&lt;code&gt;X-Clacks-Overhead&lt;/code&gt;&lt;code&gt;Reporting-Endpoints&lt;/code&gt;&lt;code&gt;Cross-Origin-Embedder-Policy&lt;/code&gt;&lt;code&gt;Cross-Origin-Opener-Policy&lt;/code&gt;&lt;code&gt;Cross-Origin-Resource-Policy&lt;/code&gt;&lt;code&gt;Content-Security-Policy&lt;/code&gt;&lt;code&gt;Content-Security-Policy-Report-Only&lt;/code&gt;&lt;code&gt;Integrity-Policy&lt;/code&gt;&lt;code&gt;Integrity-Policy-Report-Only&lt;/code&gt;&lt;code&gt;Permissions-Policy&lt;/code&gt;&lt;code&gt;Referrer-Policy&lt;/code&gt;&lt;code&gt;X-Frame-Options&lt;/code&gt;&lt;code&gt;Content-Disposition&lt;/code&gt;&lt;code&gt;Sourcemap&lt;/code&gt;&lt;p&gt;The capitalization of the headers is unimportant. The values of these headers are not restricted. Specifying a header multiple times per rule is allowed and causes every instance to appear in the HTTP response.&lt;/p&gt;&lt;p&gt;It is possible to enter malformed rules in the &lt;code&gt;_headers&lt;/code&gt; file. Such problems will not prevent your site from being published, but the malformed rules are ignored. Any problems are reported in the response to the &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; request used to publish your site (your forge will display them on the webhook configuration page); they are also available at the special &lt;code&gt;https://{host}/.git-pages/manifest.json&lt;/code&gt; or &lt;code&gt;https://{host}/{site}/.git-pages/manifest.json&lt;/code&gt; URL, which describes how git-pages understands the layout of your site.&lt;/p&gt;&lt;p&gt;There are two ways to unpublish a site.&lt;/p&gt;&lt;p&gt;Publishing a completely empty commit makes all of its contents unreachable and erases the routing information. Once complete, the pages server behaves as if the site was never published.&lt;/p&gt;&lt;p&gt;Git command: &lt;code&gt;git checkout --orphan empty-pages &amp;amp;&amp;amp; git commit --allow-empty -m "unpublish" &amp;amp;&amp;amp; git push origin empty-pages:pages&lt;/code&gt;&lt;/p&gt;&lt;p&gt;If Method B is used for authorization, a &lt;code&gt;DELETE&lt;/code&gt; request unpublishes a site.&lt;/p&gt;&lt;p&gt;Curl command: &lt;code&gt;curl https://{domain}/ -X DELETE -H "Authorization: Pages {password}"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Important! The git-pages server deduplicates files globally to reduce operational cost. Consequently, some of your files will linger in the backend store even after you unpublish your site. These files are completely inaccessible from the web, and will be purged by the next garbage collection cycle. (Garbage collection is a work in progress.)&lt;/p&gt;&lt;p&gt;To comply with the terms of service of the TLS certificate authorities (such as Let's Encrypt and ZeroSSL), this service only acquires certificates for domains it has a published site for, regardless of the DNS settings or HTTP headers. This means that the site cannot be published using its own &lt;code&gt;https://&lt;/code&gt; URL yet. Instead, use the following Curl command (or its equivalent) to publish your site for the first time:&lt;/p&gt;&lt;p&gt;For Method A: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For Method B: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" -H "Authorization: Pages {password}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Take a look at the live dashboard (requires you to have working IPv6, which saves me 2 €/month).&lt;/p&gt;&lt;p&gt;It is a great crested grebe! Original photo © Bengt Nyman, CC BY-SA 4.0.&lt;/p&gt;&lt;p&gt;The architecture of grebedoc.dev is the inverse of the architecture of codeberg.page; "Grebedoc" is "Codeberg" backwards.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://grebedoc.dev"/><published>2025-11-11T15:11:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45888697</id><title>Canada loses its measles-free status, with US on track to follow</title><updated>2025-11-11T17:39:16.948785+00:00</updated><content>&lt;doc fingerprint="6ea8a01db6a5a6ea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Canada loses its measles-free status, with US on track to follow&lt;/head&gt;
    &lt;p&gt;Canada has lost its measles elimination status, said the Pan American Health Organization (Paho) on Monday, after failing to curb an outbreak of the virus for 12 consecutive months.&lt;/p&gt;
    &lt;p&gt;Because Canada is no longer deemed measles-free, the Americas region as a whole has lost its elimination status, although individually the other countries are still considered to have stamped out the disease.&lt;/p&gt;
    &lt;p&gt;The US, however, risks losing its status as well if it does not stop an ongoing outbreak by January. Related cases have now been reported in Utah, Arizona and South Carolina.&lt;/p&gt;
    &lt;p&gt;Canada's outbreak began last October, with health officials attributing it to fewer people being vaccinated against measles.&lt;/p&gt;
    &lt;p&gt;At a news conference on Monday, Paho officials appealed to Canadian governments and the public to ramp up vaccinations, noting that 95% of the population needs to be immunised to stop the spread of measles.&lt;/p&gt;
    &lt;p&gt;"This loss represents a setback, but it is also reversible," said Dr Jarbas Barbosa, the health organisation's director.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How Canada became the centre of a measles outbreak in North America&lt;/item&gt;
      &lt;item&gt;More than 150 children quarantined as US measles cases hit 33-year high&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Public Health Agency of Canada said in its own statement that it is collaborating with Paho and regional health authorities to improve vaccine rates and strengthen data sharing.&lt;/p&gt;
    &lt;p&gt;Prior to Monday, Canada had been declared measles-free for three decades. It can regain its elimination status if it can curb spread of the measles strain associated with the current outbreak for at least 12 months.&lt;/p&gt;
    &lt;p&gt;The country has reported more than 5,000 measles cases in 2025, with most of them in the provinces of Ontario and Alberta. That is three times the 1,681 cases reported in the US, despite Canada's much smaller population.&lt;/p&gt;
    &lt;p&gt;The bulk of the outbreak has been in "under-vaccinated communities", Canadian health officials have said.&lt;/p&gt;
    &lt;p&gt;Vaccination rates in Alberta, one of the provinces hit hard by the outbreak, are lower than the 95% threshold, according to provincial data.&lt;/p&gt;
    &lt;p&gt;One region, the South Zone, located south of the province's largest city Calgary, reported only 68% of children under the age of two were immunised against measles as of 2024.&lt;/p&gt;
    &lt;p&gt;The MMR vaccine is the most effective way to fight off the dangerous virus, which can lead to pneumonia, brain swelling and death. The jabs are 97% effective and also immunise against mumps and rubella.&lt;/p&gt;
    &lt;p&gt;Canadian immunologist Dawn Bowdish told the BBC that there are many reasons behind the low vaccination rates, including lack of access to general practitioners, the absence of a national vaccination registry that Canadians could use to check their immunisation status, and the spread of misinformation.&lt;/p&gt;
    &lt;p&gt;She also noted a lack of public health outreach to communities that have been hesitant or distrustful of vaccines.&lt;/p&gt;
    &lt;p&gt;"It highlights how many of our systems broke down to get us to this point," said Prof Bowdish of McMaster University in Hamilton, Ontario.&lt;/p&gt;
    &lt;p&gt;"I hope that it will be a wake-up call to policymakers, and that it will be enough of a national embarrassment that we remedy some of those systemic issues," she added&lt;/p&gt;
    &lt;p&gt;The Americas is the first and only region in the world to have been declared measles-free, starting in 2016. That status was then briefly lifted after outbreaks in Venezuela and Brazil. The two countries regained elimination status in 2024, in part through coordinated vaccine efforts where millions were immunised.&lt;/p&gt;
    &lt;p&gt;But measles has since spread again, now in North America.&lt;/p&gt;
    &lt;p&gt;Along with Canada and the United States, Mexico has also seen a surge in cases and now ranks among the top 10 countries with the largest outbreaks, according to the US Centers for Disease Control and Prevention.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/cy7e2lv4r8xo"/><published>2025-11-11T15:50:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45888891</id><title>Firefox Expands Fingerprint Protections</title><updated>2025-11-11T17:39:16.606243+00:00</updated><content>&lt;doc fingerprint="9f3493f63975af6e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Firefox expands fingerprint protections: advancing towards a more private web&lt;/head&gt;
    &lt;p&gt;With Firefox 145, we’re rolling out major privacy upgrades that take on browser fingerprinting — a pervasive and hidden tracking technique that lets websites identify you even when cookies are blocked or you’re in private browsing. These protections build on Mozilla’s long-term goal of building a healthier, transparent and privacy-preserving web ecosystem.&lt;/p&gt;
    &lt;p&gt;Fingerprinting builds a secret digital ID of you by collecting subtle details of your setup — ranging from your time zone to your operating system settings — that together create a “fingerprint” identifiable across websites and across browser sessions. Having a unique fingerprint means fingerprinters can continuously identify you invisibly, allowing bad actors to track you without your knowledge or consent. Online fingerprinting is able to track you for months, even when you use any browser’s private browsing mode.&lt;/p&gt;
    &lt;p&gt;Protecting people’s privacy has always been core to Firefox. Since 2020, Firefox’s built-in Enhanced Tracking Protection (ETP) has blocked known trackers and other invasive practices, while features like Total Cookie Protection and now expanded fingerprinting defenses demonstrate a broader goal: prioritizing your online freedom through innovative privacy-by-design. Since 2021, Firefox has been incrementally enhancing anti-fingerprinting protections targeting the most common pieces of information collected for suspected fingerprinting uses.&lt;/p&gt;
    &lt;p&gt;Today, we are excited to announce the completion of the second phase of defenses against fingerprinters that linger across all your browsing but aren’t in the known tracker lists. With these fingerprinting protections, the amount of Firefox users trackable by fingerprinters is reduced by half.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we built stronger defenses&lt;/head&gt;
    &lt;p&gt;Drawing from a global analysis of how real people’s browsers can be fingerprinted, Mozilla has developed new, unique and powerful defenses against real-world fingerprinting techniques. Firefox is the first browser with this level of insight into fingerprinting and the most effective deployed defenses to reduce it. Like Total Cookie Protection, one of our most innovative privacy features, these new defenses are debuting in Private Browsing Mode and ETP Strict mode initially, while we work to enable them by default.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Firefox protects you&lt;/head&gt;
    &lt;p&gt;These fingerprinting protections work on multiple layers, building on Firefox’s already robust privacy features. For example, Firefox has long blocked known tracking and fingerprinting scripts as part of its Enhanced Tracking Protection.&lt;/p&gt;
    &lt;p&gt;Beyond blocking trackers, Firefox also limits the information it makes available to websites — a privacy-by-design approach — that preemptively shrinks your fingerprint. Browsers provide a way for websites to ask for information that enables legitimate website features, e.g. your graphics hardware information, which allows sites to optimize games for your computer. But trackers can also ask for that information, for no other reason than to help build a fingerprint of your browser and track you across the web.&lt;/p&gt;
    &lt;p&gt;Since 2021, Firefox has been incrementally advancing fingerprinting protections, covering the most pervasive fingerprinting techniques. These include things like how your graphics card draws images, which fonts your computer has, and even tiny differences in how it performs math. The first phase plugged the biggest and most-common leaks of fingerprinting information.&lt;/p&gt;
    &lt;p&gt;Recent Firefox releases have tackled the next-largest leaks of user information used by online fingerprinters. This ranges from strengthening the font protections to preventing websites from getting to know your hardware details like the number of cores your processor has, the number of simultaneous fingers your touchscreen supports, and the dimensions of your dock or taskbar. The full list of detailed protections is available in our documentation.&lt;/p&gt;
    &lt;p&gt;Our research shows these improvements cut the percentage of users seen as unique by almost half.&lt;/p&gt;
    &lt;p&gt;Firefox’s new protections are a balance of disrupting fingerprinters while maintaining web usability. More aggressive fingerprinting blocking might sound better, but is guaranteed to break legitimate website features. For instance, calendar, scheduling, and conferencing tools legitimately need your real time zone. Firefox’s approach is to target the most leaky fingerprinting vectors (the tricks and scripts used by trackers) while preserving functionality many sites need to work normally. The end result is a set of layered defenses that significantly reduce tracking without downgrading your browsing experience. More details are available about both the specific behaviors and how to recognize a problem on a site and disable protections for that site alone, so you always stay in control. The goal: strong privacy protections that don’t get in your way.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s next for your privacy&lt;/head&gt;
    &lt;p&gt;If you open a Private Browsing window or use ETP Strict mode, Firefox is already working behind the scenes to make you harder to track. The latest phase of Firefox’s fingerprinting protections marks an important milestone in our mission to deliver: smart privacy protections that work automatically — no further extensions or configurations needed. As we head into the future, Firefox remains committed to fighting for your privacy, so you get to enjoy the web on your terms. Upgrade to the latest Firefox and take back control of your privacy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/"/><published>2025-11-11T16:04:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45889602</id><title>iPod Socks</title><updated>2025-11-11T17:39:16.514335+00:00</updated><content>&lt;doc fingerprint="6d44f58fb134518d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;iPod Socks&lt;/head&gt;&lt;p&gt;iPod Socks were a set of multi-colored cotton knit socks introduced by Apple Inc. in November 2004 for protection of iPods from damage during travel.[1]&lt;/p&gt;&lt;head rend="h2"&gt;History&lt;/head&gt;[edit]&lt;p&gt;The socks were jokingly presented by Apple CEO Steve Jobs as a "revolutionary new product" at a special music event held on October 26, 2004.[2][3] They were available in a package of six different colors, including green, purple, grey, blue, orange and pink, for US$29.[4]&lt;/p&gt;&lt;p&gt;Apple stopped selling the product sometime in September 2012.[5] The set soon became a collector's item, with aftermarket prices rising as high as US$90 by 2014.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Reception&lt;/head&gt;[edit]&lt;p&gt;Jeremy Horwitz of iLounge gave a rating of B− for the socks, indicating a "Limited Recommendation". Horwitz noted the product's two-toned design and ability to hold an iPod of any size, but criticized the socks for inhibiting access to the screen and controls and high price.[7] In 2021, Chaim Gartenberg of The Verge described the product as a "bizarre piece of Apple's history" comparable to the Polishing Cloth, noting that the socks remained relatively popular during its availability from 2004 to 2012 due to their "relatively universal size" and bright colors.[8]&lt;/p&gt;&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ Revisiting the forgotten history of obscure Apple accessories by Michael Steeber, 9to5Mac. March 19, 2018.&lt;/item&gt;&lt;item&gt;^ Dybwab, Barb (November 11, 2004). "Breaking news: iPod socks available for pre-order!!". Engadget. Retrieved November 9, 2021.&lt;/item&gt;&lt;item&gt;^ Jobs, Steve (October 26, 2004). Apple Special Music Event 2004 (Speech). California Theatre (San Jose).&lt;/item&gt;&lt;item&gt;^ Cohen, Peter (November 10, 2004). "iPod Socks coming in Dec". Macworld. Archived from the original on November 20, 2004. Retrieved November 9, 2021.&lt;/item&gt;&lt;item&gt;^ Apple removes iPod Socks from online store, AppleInsider. September 26, 2012.&lt;/item&gt;&lt;item&gt;^ Remember These iPod Accessories? by Lulu Chang, Bustle. October 30, 2014.&lt;/item&gt;&lt;item&gt;^ Horwitz, Jeremy (November 30, 2004). "Review: Apple iPod Socks". iLounge. Archived from the original on March 15, 2008. Retrieved November 9, 2021.&lt;/item&gt;&lt;item&gt;^ Gartenberg, Chaim (October 26, 2021). "AirPod Beanies bring back the infamous iPod Sock for a new generation". The Verge. Retrieved November 9, 2021.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;This article incorporates material derived from the "iPod Socks" article on the Apple wiki at Fandom (formerly Wikia) and is licensed under the Creative Commons Attribution-Share Alike 3.0 License (November 9, 2021).&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;External links&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;Apple iPod Socks[dead link] at Apple (archived 2007-10-21, 2004-11-12[dead link])&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/IPod_Socks"/><published>2025-11-11T16:52:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45889783</id><title>Weave (YC W25) is hiring a founding ML engineer</title><updated>2025-11-11T17:39:15.743007+00:00</updated><content>&lt;doc fingerprint="951e4c15f89423cc"&gt;
  &lt;main&gt;
    &lt;p&gt;AI to understand engineering work&lt;/p&gt;
    &lt;p&gt;At Weave, we’re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.&lt;/p&gt;
    &lt;p&gt;We are a well-funded startup, backed by top investors, growing rapidly.&lt;/p&gt;
    &lt;p&gt;You'll be working directly with me (Andrew), the CTO. Before I was CTO of Weave I was the founding engineer at Causal, and I want to give you all the support and growth opportunities in this role that I got when I went through it.&lt;/p&gt;
    &lt;p&gt;You’ll also be working directly with Adam, the CEO. Adam runs sales at Weave, and before that worked as a sales executive at a few different high growth startups.&lt;/p&gt;
    &lt;p&gt;You are a good fit for Weave if you are a formidable engineer. This means you stop at nothing to accomplish your goal. We don't care much about your current skills or even what you've done before; we care that you will be able to do anything you set your mind to.&lt;/p&gt;
    &lt;p&gt;You must also be pragmatic. Weave is a startup so something is always on fire. You need to know when to let little fires burn and when to break out the extinguisher.&lt;/p&gt;
    &lt;p&gt;You must have experience with shipping ML systems to production, end to end. From selecting an appropriate data set, to feature engineering, to model design, to deployment &amp;amp; iteration.&lt;/p&gt;
    &lt;p&gt;You must be a very good engineer who's committed to becoming a great engineer. The slope is more important than the Y-intercept.&lt;/p&gt;
    &lt;p&gt;You must be empathetic. We're building products for other people, so you need to be able to understand how other people think and why.&lt;/p&gt;
    &lt;p&gt;You must care about helping other software engineering teams be great. If that's not an exciting mission for you, it will be hard to stay motivated through the inevitable highs and lows.&lt;/p&gt;
    &lt;p&gt;You must be an excellent communicator. You'll be working on a product that's communicating with millions of engineers and leaders, so you need to be clear.&lt;/p&gt;
    &lt;p&gt;Finally you must be gritty. You should be accustomed to picking the hard option and pushing through it.&lt;/p&gt;
    &lt;p&gt;(Please feel free to apply even if some or all of these don't apply to you!)&lt;/p&gt;
    &lt;p&gt;Our tech stack is React + TypeScript on the frontend, Go on the backend, and Python for ML. Experience with any of those three languages is a bonus.&lt;/p&gt;
    &lt;p&gt;If you've already done lots of thinking about engineering productivity and how to improve it, that's great and we want to hear about it!&lt;/p&gt;
    &lt;p&gt;As Weave’s founding ML engineer, your job is to build ML systems to understand and improve the work that software engineers do. You’ll be building our processes and standards as you go to make building every incremental feature and subsequent model easier. Your goal will be to delight customers with intelligence that makes their job 10x easier.&lt;/p&gt;
    &lt;p&gt;At Weave, we’re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.&lt;/p&gt;
    &lt;p&gt;We are a well-funded startup, backed by top investors and growing rapidly.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/weave-3/jobs/ZPyeXzM-founding-ml-engineer"/><published>2025-11-11T17:00:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45889793</id><title>Show HN: Cactoide – Federated RSVP Platform</title><updated>2025-11-11T17:39:15.310726+00:00</updated><content>&lt;doc fingerprint="efaf8ee999fbbf20"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cactoide(ea)* ðµ&lt;/head&gt;
    &lt;head rend="h2"&gt;The Ultimate RSVP Platform&lt;/head&gt;
    &lt;p&gt;A federated mobile-first event RSVP platform that lets you create events, share unique URLs, and collect RSVPs without any registration required. With built-in federation, discover and share events across a decentralized network of instances.&lt;/p&gt;
    &lt;p&gt;Cactoide is open source and easily self-hostable. View the source code, contribute, or host your own instance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Cactoide(ae)?ðµ*&lt;/head&gt;
    &lt;p&gt;Like the cactus, great events bloom under any condition when managed with care. Cactoide(ae) helps you streamline RSVPs, simplify coordination, and keep every detail efficientâso your gatherings are resilient, vibrant, and unforgettable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover Public Events&lt;/head&gt;
    &lt;p&gt;See what others are planning and get inspired&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Cactoide?&lt;/head&gt;
    &lt;head rend="h3"&gt;Instant Event Creation&lt;/head&gt;
    &lt;p&gt;Create events in seconds with our streamlined form. No accounts, no waiting, just pure efficiency.&lt;/p&gt;
    &lt;head rend="h3"&gt;One-Click Sharing&lt;/head&gt;
    &lt;p&gt;Each event gets a unique, memorable URL. Share instantly via any platform or messaging app.&lt;/p&gt;
    &lt;head rend="h3"&gt;All-in-One Clarity&lt;/head&gt;
    &lt;p&gt;No more scrolling through endless chats and reactions. See everyone's availability and responses neatly in one place.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Hassle, No Sign-Ups&lt;/head&gt;
    &lt;p&gt;Skip registrations and endless forms. Unlike other event platforms, you create and share instantly â no accounts, no barriers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Smart Limits&lt;/head&gt;
    &lt;p&gt;Choose between unlimited RSVPs or set a limited capacity. Perfect for any event size.&lt;/p&gt;
    &lt;head rend="h3"&gt;Effortless Simplicity&lt;/head&gt;
    &lt;p&gt;Designed to be instantly clear and easy. No learning curve â just open, create, and go.&lt;/p&gt;
    &lt;head rend="h3"&gt;Invite Links&lt;/head&gt;
    &lt;p&gt;Create invite-only events with special links. Only people with the specific invite link can RSVP, giving you full control over who can attend.&lt;/p&gt;
    &lt;head rend="h3"&gt;Federation&lt;/head&gt;
    &lt;p&gt;Connect with other Cactoide instances to discover events across the network. Share your public events and create a decentralized event discovery network.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Create Event&lt;/head&gt;
    &lt;p&gt;Fill out a simple form with event details. Choose between limited or unlimited capacity.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Get Unique URL&lt;/head&gt;
    &lt;p&gt;Receive a random, memorable URL for your event. Perfect for sharing anywhere.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Collect RSVPs&lt;/head&gt;
    &lt;p&gt;People visit your link and join with just their name. No accounts needed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ready to Create Your First Event?&lt;/head&gt;
    &lt;p&gt;Join thousands of event organizers who trust Cactoide&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cactoide.org/"/><published>2025-11-11T17:01:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45889891</id><title>Cache-Friendly, Low-Memory Lanczos Algorithm in Rust</title><updated>2025-11-11T17:39:14.810020+00:00</updated><content>&lt;doc fingerprint="91155a0e0fae71f1"&gt;
  &lt;main&gt;
    &lt;p&gt;The standard Lanczos method for computing matrix functions has a brutal memory requirement: storing an basis matrix that grows with every iteration. For a -variable problem needing iterations, that’s roughly 4 GB just for the basis.&lt;/p&gt;
    &lt;p&gt;In this post, we will explore one of the most straightforward solutions to this problem: a two-pass variant of the Lanczos algorithm that only requires memory at the cost of doubling the number of matrix-vector products. The surprising part is that when implemented carefully, the two-pass version isn’t just memory-efficient—it can be faster for certain problems. We will dig into why.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All code is available on GitHub: two-pass-lanczos&lt;/item&gt;
      &lt;item&gt;The full technical report with proofs and additional experiments: report.pdf&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;head&gt;Open Table of Contents&lt;/head&gt;
    &lt;head rend="h1"&gt;Computing Matrix Functions&lt;/head&gt;
    &lt;p&gt;Let’s consider the problem of computing the action of matrix functions on a vector:&lt;/p&gt;
    &lt;p&gt;where is a large sparse Hermitian matrix and is a matrix function defined on the spectrum of . This is a problem that appears pretty often in scientific computing: solving linear systems corresponds to , exponential integrators for PDEs use , and many other problems require functions like or .&lt;/p&gt;
    &lt;p&gt;Indeed, there are a lot problems with computing directly. First of all, even if is sparse, is generally dense. Storing it explicitly is out of the question for large problems. Even if we could store it, computing it directly would require algorithms like the Schur-Parlett method that scale as , which is impractical for large .&lt;/p&gt;
    &lt;p&gt;However we know that given any matrix function defined on the spectrum of , we can express as a polynomial in of degree at most (the size of the matrix) such that (this is a consequence of the Cayley-Hamilton theorem). This polynomial interpolates and its derivatives in the Hermitian sense at the eigenvalues of .&lt;/p&gt;
    &lt;p&gt;This gives us a good and a bad news: the good news is that, well, we can express as a polynomial in . The bad news is that the degree of this polynomial can be as high as , which is huge for large problems. The idea is then to find a low-degree polynomial approximation to that is good enough for our purposes. If we can find a polynomial of degree such that , then we can approximate the solution as:&lt;/p&gt;
    &lt;p&gt;This polynomial only involves vectors within a specific subspace.&lt;/p&gt;
    &lt;head rend="h2"&gt;Krylov Projection&lt;/head&gt;
    &lt;p&gt;We can notice that only depends on vectors in the Krylov subspace of order&lt;/p&gt;
    &lt;p&gt;This is fortunate: we can compute an approximate solution by staying within this space, which only requires repeated matrix-vector products with . For large sparse matrices, that’s the only operation we can do efficiently anyway.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We don’t need to construct explicitly. We compute iteratively: .&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But there’s a problem: the raw vectors form a terrible basis. They quickly become nearly parallel, making any computation numerically unstable. We need an orthonormal basis.&lt;/p&gt;
    &lt;head rend="h3"&gt;Building an Orthonormal Basis&lt;/head&gt;
    &lt;p&gt;The standard method is the Arnoldi process, which is Gram-Schmidt applied to Krylov subspaces. We start by normalizing . Then, iteratively:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute a new candidate:&lt;/item&gt;
      &lt;item&gt;Orthogonalize against all existing basis vectors:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Normalize:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The coefficients become entries of a projected matrix. After iterations, we have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;: an orthonormal basis for&lt;/item&gt;
      &lt;item&gt;: an upper Hessenberg matrix representing the projection of onto this subspace&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can express this relationship with the Arnoldi decomposition:&lt;/p&gt;
    &lt;head rend="h3"&gt;Solving in the Reduced Space&lt;/head&gt;
    &lt;p&gt;Now we approximate our original problem by solving it in the small -dimensional space. Using the Full Orthogonal Method (FOM), we enforce that the residual is orthogonal to the Krylov subspace. This gives:&lt;/p&gt;
    &lt;p&gt;where is computed as:&lt;/p&gt;
    &lt;p&gt;The heavy lifting is now on computing , a small matrix. Since , we can afford direct methods like Schur-Parlett ().&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For (linear systems), this reduces to solving with LU decomposition.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h1"&gt;The Lanczos Algorithm&lt;/head&gt;
    &lt;p&gt;When is Hermitian (or symmetric in the real case), the general Arnoldi process simplifies dramatically. We can prove that must also be Hermitian. A matrix that is both upper Hessenberg and Hermitian must be real, symmetric, and tridiagonal. This is a huge simplification.&lt;/p&gt;
    &lt;p&gt;In the literature, this projected matrix is denoted to highlight its tridiagonal structure:&lt;/p&gt;
    &lt;p&gt;where are the diagonal elements and are the off-diagonals (subdiagonals from the orthogonalization).&lt;/p&gt;
    &lt;head rend="h2"&gt;Three-Term Recurrence&lt;/head&gt;
    &lt;p&gt;This tridiagonal structure leads to a beautiful simplification. To build the next basis vector , we don’t need the entire history of vectors. We only need the two previous ones. Since is Hermitian, this guarantees that any new vector is automatically orthogonal to all earlier vectors (beyond the previous two). So we can skip the full orthogonalization and use a simple three-term recurrence:&lt;/p&gt;
    &lt;p&gt;Rearranging gives us an algorithm to compute directly:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute the candidate:&lt;/item&gt;
      &lt;item&gt;Extract the diagonal coefficient:&lt;/item&gt;
      &lt;item&gt;Orthogonalize against the two previous vectors:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Normalize: and&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is known as the Lanczos algorithm. It’s more efficient than Arnoldi because each iteration only orthogonalizes against two previous vectors instead of all prior ones.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reconstructing the Solution&lt;/head&gt;
    &lt;p&gt;After iterations, we end up with the tridiagonal matrix and all basis vectors . We can then reconstruct the approximate solution as:&lt;/p&gt;
    &lt;p&gt;where is solved from the small tridiagonal matrix.&lt;/p&gt;
    &lt;p&gt;There is a timing problem however: we cannot compute the coefficients until all iterations are complete. The full matrix is only available at the end, so we must store every basis vector along the way, leading to a memory cost of .&lt;/p&gt;
    &lt;p&gt;So we’re left with a choice: whether we store all the basis vectors and solve the problem in passes, or find a way to avoid storing them. There is a middle ground.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There are also techniques to compress the basis vectors, have a look here&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h1"&gt;Two-Pass Algorithm&lt;/head&gt;
    &lt;p&gt;Here’s where we break the timing deadlock. The insight that we don’t actually need to store the basis vectors if we can afford to compute them twice&lt;/p&gt;
    &lt;p&gt;Think about what we have after the first pass. We’ve computed all the and coefficients that compose the entire tridiagonal matrix . These numbers are small compared to the full basis. What if we kept only these scalars, discarded all the vectors, and then replayed the Lanczos recurrence a second time? We’d regenerate the same basis, and this time we’d use it to build the solution.&lt;/p&gt;
    &lt;p&gt;This comes at a cost. We run Lanczos twice, so we pay for matrix-vector products instead of . But we only ever store a constant number of vectors in memory, no basis matrix. The memory complexity drops to .&lt;/p&gt;
    &lt;p&gt;It sounds like a bad trade at first. But as we’ll see later, the cache behavior of this two-pass approach can actually make it as fast (or even faster) on real hardware if well optimized.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Pass: Compute the Projected Problem&lt;/head&gt;
    &lt;p&gt;We initialize and set , .Then we run the standard Lanczos recurrence:&lt;/p&gt;
    &lt;p&gt;At each step, we record and . But we do not store . Instead, we discard it immediately after computing . In this way we only keep in memory at most just three vectors at any time (, , and the working vector ).&lt;/p&gt;
    &lt;p&gt;After iterations, we have the full set . These scalars define the tridiagonal matrix . We can now solve:&lt;/p&gt;
    &lt;p&gt;This is the solution in the reduced space. Now that we have the coefficients we need to build .&lt;/p&gt;
    &lt;head rend="h2"&gt;Second Pass: Reconstruct and Accumulate&lt;/head&gt;
    &lt;p&gt;With in memory, we replay the Lanczos recurrence exactly as before. We start with the same initialization (, , ) and apply the same sequence of operations, using the stored scalars and to reconstruct each basis vector on demand. We can write some rust-like pseudocode for this second pass to get a feel for it:&lt;/p&gt;
    &lt;code&gt;let mut x_k = vec![0.0; n];
let mut v_prev = vec![0.0; n];
let mut v_curr = b.clone() / b_norm;

for j in 1..=k {
    let w = A @ v_curr;  // Matrix-vector product

    // We don't recompute alpha/beta; we already have them from pass 1
    let alpha_j = alphas[j - 1];
    let beta_prev = j &amp;gt; 1 ? betas[j - 2] : 0.0;

    // Accumulate the solution
    x_k += y_k[j - 1] * v_curr;

    // Regenerate the next basis vector for the *next* iteration
    let v_next = (w - alpha_j * v_curr - beta_prev * v_prev) / betas[j - 1];

    // Slide the window forward
    v_prev = v_curr;
    v_curr = v_next;
}&lt;/code&gt;
    &lt;p&gt;This loop regenerates each on demand and immediately uses it to update the solution. Once we’ve accumulated into , we discard the vector. We never store the full basis.&lt;/p&gt;
    &lt;head rend="h3"&gt;A Subtle Numerical Point&lt;/head&gt;
    &lt;p&gt;There is one detail worth noting: floating-point arithmetic is deterministic. When we replay the Lanczos recurrence in the second pass with the exact same inputs and the exact same order of operations, we get bitwise-identical vectors. The regenerated in pass 2 are identical to the ones computed in pass 1.&lt;/p&gt;
    &lt;p&gt;However, the order in which we accumulate the solution differs. In a standard Lanczos, is built as a single matrix-vector product: (a &lt;code&gt;gemv&lt;/code&gt; call in BLAS). In the two-pass method, it’s built as a loop of scaled vector additions (a series of &lt;code&gt;axpy&lt;/code&gt; calls). These operations accumulate rounding error differently, so the final solution differs slightly, typically by machine epsilon. This rarely matters in practice, and convergence is unaffected.&lt;/p&gt;
    &lt;head rend="h1"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;Building this in Rust forces us to think concretely about where data lives and how it flows through the cache hierarchy. We need to control memory layout, decide when allocations happen, and choose abstractions that cost us nothing at runtime.&lt;/p&gt;
    &lt;p&gt;For linear algebra, we reach for &lt;code&gt;faer&lt;/code&gt;. Three design choices in this library matter for what we’re building:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stack allocation via &lt;code&gt;MemStack&lt;/code&gt;: Pre-allocated scratch space that lives for the entire computation. The hot path becomes allocation-free.&lt;/item&gt;
      &lt;item&gt;Matrix-free operators: The &lt;code&gt;LinOp&lt;/code&gt;trait defines an operator by its action (&lt;code&gt;apply&lt;/code&gt;) without materializing a matrix. For large sparse problems, this is the only viable approach.&lt;/item&gt;
      &lt;item&gt;SIMD-friendly loops: The &lt;code&gt;zip!&lt;/code&gt;macro generates code that compiles to packed instructions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Recurrence Step&lt;/head&gt;
    &lt;p&gt;Our starting point is the Lanczos three-term recurrence that we derived earlier:&lt;/p&gt;
    &lt;p&gt;We can translate this into a recurrence step function. The signature looks like this:&lt;/p&gt;
    &lt;code&gt;fn lanczos_recurrence_step&amp;lt;T: ComplexField, O: LinOp&amp;lt;T&amp;gt;&amp;gt;(
    operator: &amp;amp;O,
    mut w: MatMut&amp;lt;'_, T&amp;gt;,
    v_curr: MatRef&amp;lt;'_, T&amp;gt;,
    v_prev: MatRef&amp;lt;'_, T&amp;gt;,
    beta_prev: T::Real,
    stack: &amp;amp;mut MemStack,
) -&amp;gt; (T::Real, Option&amp;lt;T::Real&amp;gt;)&lt;/code&gt;
    &lt;p&gt;The function is generic over the field type &lt;code&gt;T&lt;/code&gt; (&lt;code&gt;f64&lt;/code&gt;, &lt;code&gt;c64&lt;/code&gt;, etc.) and the operator type &lt;code&gt;O&lt;/code&gt;. It operates on matrix views (&lt;code&gt;MatMut&lt;/code&gt; and &lt;code&gt;MatRef&lt;/code&gt;) to avoid unnecessary data copies. The return type gives us the diagonal element  and, if no breakdown occurs, the off-diagonal .&lt;/p&gt;
    &lt;p&gt;Now we can implement the body by following the math. The first step is the most expensive:&lt;/p&gt;
    &lt;code&gt;// 1. Apply operator: w = A * v_curr
operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);&lt;/code&gt;
    &lt;p&gt;The matrix-vector product dominates the computational cost. Everything else is secondary.&lt;/p&gt;
    &lt;p&gt;Next, we orthogonalize against . This is where we benefit from &lt;code&gt;faer&lt;/code&gt;’s design. The &lt;code&gt;zip!&lt;/code&gt; macro fuses this operation into a single loop that the compiler vectorizes into SIMD instructions.&lt;/p&gt;
    &lt;code&gt;// 2. Orthogonalize against v_{j-1}: w -= β_{j-1} * v_{j-1}
let beta_prev_scaled = T::from_real_impl(&amp;amp;beta_prev);
zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
    *w_i = sub(w_i, &amp;amp;mul(&amp;amp;beta_prev_scaled, v_prev_i));
});&lt;/code&gt;
    &lt;p&gt;With &lt;code&gt;w&lt;/code&gt; partially orthogonalized, we can compute the diagonal coefficient via an inner product. Since  is Hermitian,  is guaranteed real.&lt;/p&gt;
    &lt;code&gt;// 3. Compute α_j = v_j^H * w
let alpha = T::real_part_impl(&amp;amp;(v_curr.adjoint() * w.rb())[(0, 0)]);&lt;/code&gt;
    &lt;p&gt;We complete the orthogonalization against with another &lt;code&gt;zip!&lt;/code&gt; loop.&lt;/p&gt;
    &lt;code&gt;// 4. Orthogonalize against v_j: w -= α_j * v_j
let alpha_scaled = T::from_real_impl(&amp;amp;alpha);
zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
    *w_i = sub(w_i, &amp;amp;mul(&amp;amp;alpha_scaled, v_curr_i));
});&lt;/code&gt;
    &lt;p&gt;Now &lt;code&gt;w&lt;/code&gt; holds the unnormalized next basis vector. We compute its norm to get . If this norm is numerically zero, the Krylov subspace is invariant, the iteration has reached its natural stopping point. This is called breakdown.&lt;/p&gt;
    &lt;code&gt;// 5. Compute β_j = ||w||_2 and check for breakdown
let beta = w.rb().norm_l2();
let tolerance = breakdown_tolerance::&amp;lt;T::Real&amp;gt;();

if beta &amp;lt;= tolerance {
    (alpha, None)
} else {
    (alpha, Some(beta))
}&lt;/code&gt;
    &lt;p&gt;The function returns &lt;code&gt;None&lt;/code&gt; for  when breakdown occurs, signaling to the caller that no further iterations should proceed.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Iterator for State Management&lt;/head&gt;
    &lt;p&gt;The recurrence step is a pure function, but calling it in a loop is both inefficient and awkward. We’d need to manually pass vectors in and out of each iteration. More critically, we’d create copies when we should be reusing memory.&lt;/p&gt;
    &lt;p&gt;The iterator pattern solves this. We create a struct that encapsulates the state:&lt;/p&gt;
    &lt;code&gt;struct LanczosIteration&amp;lt;'a, T: ComplexField, O: LinOp&amp;lt;T&amp;gt;&amp;gt; {
    operator: &amp;amp;'a O,
    v_prev: Mat&amp;lt;T&amp;gt;,       // v_{j-1}
    v_curr: Mat&amp;lt;T&amp;gt;,       // v_j
    work: Mat&amp;lt;T&amp;gt;,         // Workspace for the next vector
    beta_prev: T::Real,   // β_{j-1}
    // ... iteration counters
}&lt;/code&gt;
    &lt;p&gt;The main design choice here is that vectors are owned (&lt;code&gt;Mat&amp;lt;T&amp;gt;&lt;/code&gt;), not borrowed. This enables an optimization in the &lt;code&gt;next_step&lt;/code&gt; method. After computing the next vector and normalizing it into &lt;code&gt;work&lt;/code&gt;, we cycle the state without allocating or copying:&lt;/p&gt;
    &lt;code&gt;// Inside next_step, after normalization...
core::mem::swap(&amp;amp;mut self.v_prev, &amp;amp;mut self.v_curr);
core::mem::swap(&amp;amp;mut self.v_curr, &amp;amp;mut self.work);&lt;/code&gt;
    &lt;p&gt;On x86-64, swapping two &lt;code&gt;Mat&amp;lt;T&amp;gt;&lt;/code&gt; structures (fat pointers) compiles to three &lt;code&gt;mov&lt;/code&gt; instructions. The pointers change, but no vector data moves. After the swap, &lt;code&gt;v_prev&lt;/code&gt; points to what &lt;code&gt;v_curr&lt;/code&gt; held, &lt;code&gt;v_curr&lt;/code&gt; points to &lt;code&gt;work&lt;/code&gt;’s allocation, and &lt;code&gt;work&lt;/code&gt; points to the old &lt;code&gt;v_prev&lt;/code&gt; data. In the next iteration, &lt;code&gt;work&lt;/code&gt; gets reused.&lt;/p&gt;
    &lt;p&gt;We keep exactly three n-dimensional vectors live in memory. The same allocations cycle through the computation, staying hot in L1 cache. This is the core reason the two-pass method can be faster than expected, the working set never leaves cache.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Pass: Computing the Decomposition&lt;/head&gt;
    &lt;p&gt;The first pass runs the Lanczos iteration and collects the coefficients . Basis vectors are discarded after each step.&lt;/p&gt;
    &lt;code&gt;pub fn lanczos_pass_one&amp;lt;T: ComplexField&amp;gt;(
    operator: &amp;amp;impl LinOp&amp;lt;T&amp;gt;,
    b: MatRef&amp;lt;'_, T&amp;gt;,
    k: usize,
    stack: &amp;amp;mut MemStack,
) -&amp;gt; Result&amp;lt;LanczosDecomposition&amp;lt;T::Real&amp;gt;, LanczosError&amp;gt; {
    // ...
}&lt;/code&gt;
    &lt;p&gt;We allocate vectors for the coefficients with a capacity hint to avoid reallocations:&lt;/p&gt;
    &lt;code&gt;let mut alphas = Vec::with_capacity(k);
let mut betas = Vec::with_capacity(k - 1);&lt;/code&gt;
    &lt;p&gt;Then we construct the iterator. This allocates the three work vectors once. After this point, the hot path is allocation-free:&lt;/p&gt;
    &lt;code&gt;let mut lanczos_iter = LanczosIteration::new(operator, b, k, b_norm)?;

for i in 0..k {
    if let Some(step) = lanczos_iter.next_step(stack) {
        alphas.push(step.alpha);
        steps_taken += 1;

        let tolerance = breakdown_tolerance::&amp;lt;T::Real&amp;gt;();
        if step.beta &amp;lt;= tolerance {
            break;
        }

        if i &amp;lt; k - 1 {
            betas.push(step.beta);
        }
    } else {
        break;
    }
}&lt;/code&gt;
    &lt;p&gt;The check for breakdown stops the iteration when the residual becomes numerically zero. This means we’ve found an invariant subspace and there’s no value in continuing.&lt;/p&gt;
    &lt;p&gt;At the end, we collect the scalars into a &lt;code&gt;LanczosDecomposition&lt;/code&gt; struct. The memory footprint throughout this pass is constant: three n-dimensional vectors plus two small arrays that grow to at most  elements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Second Pass: Reconstructing the Solution&lt;/head&gt;
    &lt;p&gt;Now we face a different problem. We have the coefficients from the first pass and the coefficient vector from solving the projected problem. We need to reconstruct the solution:&lt;/p&gt;
    &lt;p&gt;without storing the full basis matrix .&lt;/p&gt;
    &lt;p&gt;The recurrence step in this pass is structurally similar to the first pass, but with a key difference: we no longer compute inner products or norms. We already know the coefficients, so the step becomes pure reconstruction.&lt;/p&gt;
    &lt;code&gt;fn lanczos_reconstruction_step&amp;lt;T: ComplexField, O: LinOp&amp;lt;T&amp;gt;&amp;gt;(
    operator: &amp;amp;O,
    mut w: MatMut&amp;lt;'_, T&amp;gt;,
    v_curr: MatRef&amp;lt;'_, T&amp;gt;,
    v_prev: MatRef&amp;lt;'_, T&amp;gt;,
    alpha_j: T::Real,
    beta_prev: T::Real,
    stack: &amp;amp;mut MemStack,
) {
    // Apply operator
    operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);

    // Orthogonalize using stored α_j and β_{j-1}
    let beta_prev_scaled = T::from_real_impl(&amp;amp;beta_prev);
    zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
        *w_i = sub(w_i, &amp;amp;mul(&amp;amp;beta_prev_scaled, v_prev_i));
    });

    let alpha_scaled = T::from_real_impl(&amp;amp;alpha_j);
    zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
        *w_i = sub(w_i, &amp;amp;mul(&amp;amp;alpha_scaled, v_curr_i));
    });
}&lt;/code&gt;
    &lt;p&gt;This is cheaper than the first-pass recurrence. We’ve eliminated the inner products that computed and the norm calculation for . What remains is pure orthogonalization and the operator application.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;lanczos_pass_two&lt;/code&gt; implements this reconstruction. We initialize the three work vectors and the solution accumulator:&lt;/p&gt;
    &lt;code&gt;pub fn lanczos_pass_two&amp;lt;T: ComplexField&amp;gt;(
    operator: &amp;amp;impl LinOp&amp;lt;T&amp;gt;,
    b: MatRef&amp;lt;'_, T&amp;gt;,
    decomposition: &amp;amp;LanczosDecomposition&amp;lt;T::Real&amp;gt;,
    y_k: MatRef&amp;lt;'_, T&amp;gt;,
    stack: &amp;amp;mut MemStack,
) -&amp;gt; Result&amp;lt;Mat&amp;lt;T&amp;gt;, LanczosError&amp;gt; {
    let mut v_prev = Mat::&amp;lt;T&amp;gt;::zeros(b.nrows(), 1);
    let inv_norm = T::from_real_impl(&amp;amp;T::Real::recip_impl(&amp;amp;decomposition.b_norm));
    let mut v_curr = b * Scale(inv_norm);  // v_1

    let mut work = Mat::&amp;lt;T&amp;gt;::zeros(b.nrows(), 1);

    // Initialize solution with first component
    let mut x_k = &amp;amp;v_curr * Scale(T::copy_impl(&amp;amp;y_k[(0, 0)]));&lt;/code&gt;
    &lt;p&gt;We build the solution incrementally by starting with the first basis vector scaled by its coefficient. The main loop then regenerates each subsequent vector: we regenerate each subsequent basis vector, normalize it using the stored , and immediately accumulate its contribution:&lt;/p&gt;
    &lt;code&gt;for j in 0..decomposition.steps_taken - 1 {
    let alpha_j = T::Real::copy_impl(&amp;amp;decomposition.alphas[j]);
    let beta_j = T::Real::copy_impl(&amp;amp;decomposition.betas[j]);
    let beta_prev = if j == 0 {
        T::Real::zero_impl()
    } else {
        T::Real::copy_impl(&amp;amp;decomposition.betas[j - 1])
    };

    // 1. Regenerate the unnormalized next vector
    lanczos_reconstruction_step(
        operator,
        work.as_mut(),
        v_curr.as_ref(),
        v_prev.as_ref(),
        alpha_j,
        beta_prev,
        stack,
    );

    // 2. Normalize using stored β_j
    let inv_beta = T::from_real_impl(&amp;amp;T::Real::recip_impl(&amp;amp;beta_j));
    zip!(work.as_mut()).for_each(|unzip!(w_i)| {
        *w_i = mul(w_i, &amp;amp;inv_beta);
    });

    // 3. Accumulate: x_k += y_{j+1} * v_{j+1}
    let coeff = T::copy_impl(&amp;amp;y_k[(j + 1, 0)]);
    zip!(x_k.as_mut(), work.as_ref()).for_each(|unzip!(x_i, v_i)| {
        *x_i = add(x_i, &amp;amp;mul(&amp;amp;coeff, v_i));
    });

    // 4. Cycle vectors for the next iteration
    core::mem::swap(&amp;amp;mut v_prev, &amp;amp;mut v_curr);
    core::mem::swap(&amp;amp;mut v_curr, &amp;amp;mut work);
}&lt;/code&gt;
    &lt;p&gt;The accumulation &lt;code&gt;x_k += y_{j+1} * v_{j+1}&lt;/code&gt; is implemented as a fused multiply-add in the &lt;code&gt;zip!&lt;/code&gt; loop. On hardware with FMA support, this becomes a single instruction per element, not three separate operations.&lt;/p&gt;
    &lt;p&gt;Note that we accumulate the solution incrementally. After each iteration, &lt;code&gt;x_k&lt;/code&gt; contains a partial result. We cycle through the same three vectors (&lt;code&gt;v_prev&lt;/code&gt;, &lt;code&gt;v_curr&lt;/code&gt;, &lt;code&gt;work&lt;/code&gt;), keeping the working set small and resident in L1 cache.&lt;/p&gt;
    &lt;p&gt;Compare this to the standard method’s final reconstruction step: . This is a dense matrix-vector product where is . When and are both large, this matrix no longer fits in cache. The CPU must stream it from main memory, paying the cost of memory latency. Each element requires a load, multiply, and accumulate, but the load operations dominate—the CPU stalls waiting for data.&lt;/p&gt;
    &lt;p&gt;In our two-pass reconstruction, the operator &lt;code&gt;$\mathbf{A}$&lt;/code&gt; is applied  times, but against vectors that stay in cache. The memory bandwidth is spent on reading the sparse structure of  and the vector elements, not on scanning a dense  matrix.&lt;/p&gt;
    &lt;p&gt;This is the reason the two-pass method can be faster on real hardware despite performing twice as many matrix-vector products. The cache behavior of the reconstruction phase overwhelms the savings of storing the basis.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Public API&lt;/head&gt;
    &lt;p&gt;We can wrap the two passes into a single entry point:&lt;/p&gt;
    &lt;code&gt;pub fn lanczos_two_pass&amp;lt;T, O, F&amp;gt;(
    operator: &amp;amp;O,
    b: MatRef&amp;lt;'_, T&amp;gt;,
    k: usize,
    stack: &amp;amp;mut MemStack,
    mut f_tk_solver: F,
) -&amp;gt; Result&amp;lt;Mat&amp;lt;T&amp;gt;, LanczosError&amp;gt;
where
    T: ComplexField,
    O: LinOp&amp;lt;T&amp;gt;,
    F: FnMut(&amp;amp;[T::Real], &amp;amp;[T::Real]) -&amp;gt; Result&amp;lt;Mat&amp;lt;T&amp;gt;, anyhow::Error&amp;gt;,
{
    // First pass: compute T_k coefficients
    let decomposition = lanczos_pass_one(operator, b, k, stack)?;

    if decomposition.steps_taken == 0 {
        return Ok(Mat::zeros(b.nrows(), 1));
    }

    // Solve projected problem: y_k' = f(T_k) * e_1
    let y_k_prime = f_tk_solver(&amp;amp;decomposition.alphas, &amp;amp;decomposition.betas)?;

    // Scale by ||b||
    let y_k = &amp;amp;y_k_prime * Scale(T::from_real_impl(&amp;amp;decomposition.b_norm));

    // Second pass: reconstruct solution
    lanczos_pass_two(operator, b, &amp;amp;decomposition, y_k.as_ref(), stack)
}&lt;/code&gt;
    &lt;p&gt;The design separates concerns. The &lt;code&gt;f_tk_solver&lt;/code&gt; closure is where we inject the specific matrix function. We compute the Lanczos decomposition, then pass the coefficients to the user-provided solver, which computes  for whatever function  is needed. This decoupling means we handle linear solves, matrix exponentials, or any other function without modifying the core algorithm.&lt;/p&gt;
    &lt;p&gt;The caller provides &lt;code&gt;f_tk_solver&lt;/code&gt; as a closure. It receives the raw  arrays and must return the coefficient vector . We then scale it by  and pass everything to the second pass.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example: Solving a Linear System&lt;/head&gt;
    &lt;p&gt;To see this in practice, consider solving . We compute , which means the &lt;code&gt;f_tk_solver&lt;/code&gt; must solve the small tridiagonal system .&lt;/p&gt;
    &lt;p&gt;Since is tridiagonal, we can exploit its structure. A sparse LU factorization solves it in time instead of the cost of a dense method.&lt;/p&gt;
    &lt;code&gt;let f_tk_solver = |alphas: &amp;amp;[f64], betas: &amp;amp;[f64]| -&amp;gt; Result&amp;lt;Mat&amp;lt;f64&amp;gt;, anyhow::Error&amp;gt; {
    let steps = alphas.len();
    if steps == 0 {
        return Ok(Mat::zeros(0, 1));
    }

    // 1. Assemble T_k from coefficients using triplet format
    let mut triplets = Vec::with_capacity(3 * steps - 2);
    for (i, &amp;amp;alpha) in alphas.iter().enumerate() {
        triplets.push(Triplet { row: i, col: i, val: alpha });
    }
    for (i, &amp;amp;beta) in betas.iter().enumerate() {
        triplets.push(Triplet { row: i, col: i + 1, val: beta });
        triplets.push(Triplet { row: i + 1, col: i, val: beta });
    }
    let t_k_sparse = SparseColMat::try_new_from_triplets(steps, steps, &amp;amp;triplets)?;

    // 2. Construct e_1
    let mut e1 = Mat::zeros(steps, 1);
    e1.as_mut()[(0, 0)] = 1.0;

    // 3. Solve T_k * y' = e_1 via sparse LU
    Ok(t_k_sparse.as_ref().sp_lu()?.solve(e1.as_ref()))
};&lt;/code&gt;
    &lt;p&gt;The closure takes the coefficient arrays, constructs the sparse tridiagonal matrix, and solves the system. The triplet format lets us build the matrix efficiently without knowing its structure in advance. The sparse LU solver leverages the tridiagonal structure to avoid dense factorization.&lt;/p&gt;
    &lt;head rend="h1"&gt;Some interesting results&lt;/head&gt;
    &lt;p&gt;Now that we have a working implementation we can run some tests. The core idea of what we have done is simple: trade flops for better memory access. But does this trade actually pay off on real hardware? To find out, we need a reliable way to benchmark it.&lt;/p&gt;
    &lt;p&gt;For the data, we know that the performance of any Krylov method is tied to the operator’s spectral properties. We need a way to generate a family of test problems where we can precisely control the size, sparsity, and numerical difficulty. A great way to do this is with Karush-Kuhn-Tucker (KKT) systems, which are sparse, symmetric, and have a specific block structure.&lt;/p&gt;
    &lt;p&gt;This structure gives us two critical knobs to turn. First, with the netgen utility, we can control the matrix, which lets us dial in the problem dimension, . Second, we build the diagonal block D with random entries from a range . This parameter, , gives us direct control over the numerical difficulty of the problem.&lt;/p&gt;
    &lt;p&gt;For a symmetric matrix like , the 2-norm condition number, , is the ratio of its largest to its smallest eigenvalue: . Since is diagonal, its eigenvalues are simply its diagonal entries. We are drawing these entries from a uniform distribution , so we have and . This means we get direct control, as .The spectral properties of this block heavily influence the spectrum of the entire matrix . A large condition number in leads to a more ill-conditioned system for . The convergence rate of Krylov methods like Lanczos is fundamentally governed by the distribution of the operator’s eigenvalues. An ill-conditioned matrix, with a wide spread of eigenvalues, will require more iterations, , to reach the desired accuracy. By simply adjusting the parameter, we can generate everything from well-conditioned problems that converge quickly to ill-conditioned ones that force us to run a large number of iterations. This is exactly what we need to rigorously test our implementation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory and Computation Trade-off&lt;/head&gt;
    &lt;p&gt;We measure the algorithm against two hypotheses on a large sparse problem with , varying the number of iterations .&lt;/p&gt;
    &lt;p&gt;Hypothesis 1 (Memory): The one-pass method stores the full basis with complexity . We expect its memory to grow linearly with . The two-pass method operates with memory, so it should have a flat profile.&lt;/p&gt;
    &lt;p&gt;Hypothesis 2 (Runtime): The two-pass method performs matrix-vector products instead of . If all else were equal, we’d expect it to run twice as slow.&lt;/p&gt;
    &lt;head rend="h3"&gt;Memory Usage&lt;/head&gt;
    &lt;p&gt;The memory data confirms Hypothesis 1 exactly. The one-pass method’s footprint scales as a straight line—each additional iteration adds one vector to the basis. The two-pass method remains flat. No allocation growth happens after initialization.&lt;/p&gt;
    &lt;head rend="h3"&gt;Runtime: Where Theory Breaks&lt;/head&gt;
    &lt;p&gt;The runtime data contradicts Hypothesis 2. The two-pass method is slower, but never by a factor of two. For small , the gap is minimal. As grows, the two-pass runtime diverges slowly from the one-pass method, not by doubling, but by a much smaller margin.&lt;/p&gt;
    &lt;p&gt;This difference comes from memory access patterns. Both methods perform matrix-vector products, but they differ in how they reconstruct the solution.&lt;/p&gt;
    &lt;p&gt;The one-pass method computes in a single dense matrix-vector product. When and are large, the basis matrix exceeds all cache levels. The CPU cannot keep the data resident; instead, it streams from main memory. This is a memory-bandwidth-bound operation. The processor stalls, waiting for each load to complete. Instruction-level parallelism collapses.&lt;/p&gt;
    &lt;p&gt;The two-pass method reconstructs the solution incrementally. At each iteration, it operates on exactly three n-dimensional vectors: , , and . This working set fits in L1 cache. The processor performs matrix-vector products (each one reading the sparse operator, then applying it to a cached vector), but the solution accumulation happens entirely within cache. The additional matrix-vector products are cheaper than the memory latency of the standard method.&lt;/p&gt;
    &lt;p&gt;The cost of re-computing basis vectors is less than the latency cost of scanning an dense matrix from main memory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Medium-Scale Behavior&lt;/head&gt;
    &lt;p&gt;At we can observe an equilibrium. The two methods have nearly identical runtime. The standard method’s matrix is smaller; it fits partially in cache. The cache-miss penalty here becomes manageable. The two-pass method still has the advantage of cache-local accumulation, but the difference is marginal.&lt;/p&gt;
    &lt;head rend="h3"&gt;What About Dense Matrices?&lt;/head&gt;
    &lt;p&gt;To be sure of our hypothesis, we can test it directly using a dense matrix of size . For dense problems, the matrix-vector product is , it dominates all other costs. Memory latency will become negligible relative to the compute work and the cache efficiency advantage should disappear.&lt;/p&gt;
    &lt;p&gt;We can see that the two-pass method runs almost exactly twice as slow as the one-pass method. The slope ratio is exactly 2:1. In a compute-bound regime, the extra matrix-vector products cannot be hidden by cache effects. Here, the theoretical trade-off holds perfectly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scalability&lt;/head&gt;
    &lt;p&gt;Now, let’s fix the iteration count at and vary from to to measure scalability. Based on what we have seen before, we would expect the two-pass memory to scale linearly with but with a small constant factor (three vectors, plus scalars). The one-pass method should also scale linearly, but with a -dependent slope.&lt;/p&gt;
    &lt;p&gt;Here we have to use a logarithmic y-axis to show both curves; the two-pass line is so flat relative to the one-pass line that it’s otherwise invisible.&lt;/p&gt;
    &lt;p&gt;Runtime scales linearly with for both methods, as expected. Below , the two methods have similar performance. This is the regime where both basis and working set fit in cache, or where the problem is small enough that memory latency is not the bottleneck.&lt;/p&gt;
    &lt;p&gt;As increases beyond , the matrix-vector product time dominates. The sparse structure of ensures that each matvec requires multiple memory accesses per element. For the one-pass method, the final reconstruction of begins to cost more as the matrix grows. For the two-pass method, performing matrix-vector products means the matvec cost accumulates more rapidly. The divergence is gradual, not sharp, because the advantage of cache locality in accumulation persists—but it cannot overcome the fundamental cost of doubling the number of expensive operations.&lt;/p&gt;
    &lt;p&gt;Well, that’s it. If you want to have a better look at the code or use it, it’s all open source:&lt;/p&gt;
    &lt;p&gt;This was more of an exploration than a production-ready library, so expect rough edges. But I hope it gives an interesting perspective on how algorithm engineering and low-level implementation details can alter what seems like a straightforward trade-off on a blackboard.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/"/><published>2025-11-11T17:08:00+00:00</published></entry></feed>