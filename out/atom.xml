<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-19T19:36:52.271127+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46674416</id><title>The Code-Only Agent</title><updated>2026-01-19T19:36:59.951932+00:00</updated><content>&lt;doc fingerprint="540ea85569ca9a17"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Code-Only Agent&lt;/head&gt;&lt;p&gt;When Code Execution Really is All You Need&lt;/p&gt;&lt;p&gt;If you're building an agent, you're probably overwhelmed. Tools. MCP. Subagents. Skills. The ecosystem pushes you toward complexity, toward "the right way" to do things. You should know: Concepts like "Skills" and "MCP" are actually outcomes of an ongoing learning process of humans figuring stuff out. The space is wide open for exploration. With this mindset I wanted to try something different. Simplify the assumptions.&lt;/p&gt;&lt;p&gt; What if the agent only had &lt;code&gt;one tool&lt;/code&gt;? Not just any tool, but the most powerful one. The
            &lt;code&gt;Turing-complete&lt;/code&gt; one: execute code.
          &lt;/p&gt;&lt;p&gt; Truly one tool means: no `bash`, no `ls`, no `grep`. Only &lt;code&gt;execute_code&lt;/code&gt;. And you enforce it.
          &lt;/p&gt;&lt;p&gt;When you watch an agent run, you might think: "I wonder what tools it'll use to figure this out. Oh look, it ran `ls`. That makes sense. Next, `grep`. Cool."&lt;/p&gt;&lt;p&gt;The simpler Code-Only paradigm makes that question irrelevant. The question shifts from "what tools?" to "what code will it produce?" And that's when things get interesting.&lt;/p&gt;&lt;head rend="h2"&gt;&lt;code&gt;execute_code&lt;/code&gt;: One Tool to Rule Them All&lt;/head&gt;&lt;p&gt;Traditional prompting works like this:&lt;/p&gt;&lt;p&gt; &amp;gt; Agent, do thing &lt;lb/&gt; &amp;gt; Agent responds with thing &lt;/p&gt;&lt;p&gt;Contrast with:&lt;/p&gt;&lt;p&gt; &amp;gt; Agent, do thing &lt;lb/&gt; &amp;gt; Agent creates and runs code to do thing &lt;/p&gt;&lt;p&gt; It does this every time. No, really, &lt;code&gt;every&lt;/code&gt;
            time. Pick a runtime for our Code-Only agent, say Python. It needs
            to find a file? It writes Python code to find the file and executes
            the code. Maybe it runs rglob. Maybe it does os.walk.
          &lt;/p&gt;&lt;p&gt;It needs to create a script that crawls a website? It doesn't write the script to your filesystem (reminder: there's no create_file tool to do that!). It writes code to output a script that crawls a website.1&lt;/p&gt;&lt;p&gt;We make it so that there is literally no way for the agent to do anything productive without writing code.&lt;/p&gt;&lt;p&gt;So what? Why do this? You're probably thinking, how is this useful? Just give it `bash` tool already man.&lt;/p&gt;&lt;p&gt;Let's think a bit more deeply what's happening. Traditional agents respond with something. Tell it to find some DNA pattern across 100 files. It might `ls` and `grep`, it might do that in some nondeterministic order, it'll figure out an answer and maybe you continue interacting because it missed a directory or you added more files. After some time, you end up with a conversation of tool calls, responses, and an answer.&lt;/p&gt;&lt;p&gt; At some point the agent might even write a Python script to do this DNA pattern finding. That would be a lucky happy path, because we could rerun that script or update it later... Wait, that's handy... actually, more than handy... isn't that &lt;code&gt;ideal&lt;/code&gt;? Wouldn't it be better if we told it to write a script at the
            start? You see, the Code-Only agent doesn't need to be told to write
            a script. It
            &lt;code&gt;has&lt;/code&gt;
            to, because that's literally the only way for it to do anything of
            substance.
          &lt;/p&gt;&lt;p&gt;The Code-Only agent produces something more precise than an answer in natural language. It produces a code witness of an answer. The answer is the output from running the code. The agent can interpret that output in natural language (or by writing code), but the "work" is codified in a very literal sense. The Code-Only agent doesn't respond with something. It produces a code witness that outputs something.&lt;/p&gt;&lt;p&gt;Try ❯❯ Code-Only plugin for Claude Code&lt;/p&gt;&lt;head rend="h2"&gt;Code witnesses are semantic guarantees&lt;/head&gt;&lt;p&gt;Let's follow the consequences. The code witness must abide by certain rules: The rules imposed by the language runtime semantics (e.g., of Python). That's not a "next token" process. That's not a "LLM figures out sequence of tool calls, no that's not what I wanted". It's piece of code. A piece of code! Our one-tool agent has a wonderful property: It went through latent space to produce something that has a defined semantics, repeatably runnable, and imminently comprehensible (for humans or agents alike to reason about). This is nondeterministic LLM token-generation projected into the space of Turing-complete code, an executable description of behavior as we best understand it.&lt;/p&gt;&lt;p&gt; Is a Code-Only agent really enough, or too extreme? I'll be frank: I pursued this extreme after two things (1) inspiration from articles in Further Reading below (2) being annoyed at agents for not comprehensively and exhaustively analyzing 1000s of files on my laptop. They would skip, take shortcuts, hallucinate. I knew how to solve part of that problem: create a &lt;code&gt;programmatic&lt;/code&gt;
            loop and try have fresh instances/prompts to do the work
            comprehensively. I can rely on the semantics of a loop written in
            Python. Take this idea further, and you realize that for anything
            long-running and computable (e.g., bash or some tool), you actually
            want the real McCoy: the full witness of code, a trace of why things
            work or don't work. The Code-Only agent
            &lt;code&gt;enforces&lt;/code&gt;
            that principle.
          &lt;/p&gt;&lt;p&gt; Code-Only agents are not too extreme. I think they're the only way forward for computable things. If you're writing travel blog posts, you accept the LLMs answer (and you don't need to run tools for that). When something is computable though, Code-Only is the only path to a &lt;code&gt;fully trustworthy&lt;/code&gt;
            way to make progress where you need guarantees (subject to
            the semantics that your language of choice guarantees, of course). When I say
            guarantees, I mean that in the looser sense, and also in a
            Formal
            sense. Which beckons: What happens when we use a language like
            Lean with some of the
            strongest guarantees? Did we not observe that
            programs are proofs?
          &lt;/p&gt;&lt;p&gt;This lens says the Code-Only agent is a producer of proofs, witnesses of computational behavior in the world of proofs-as-programs. An LLM in a loop forced to produce proofs, run proofs, interpret proof results. That's all.&lt;/p&gt;&lt;head rend="h2"&gt;Going Code-Only&lt;/head&gt;&lt;p&gt;So you want to go Code-Only. What happens? The paradigm is simple, but the design choices are surprising.&lt;/p&gt;&lt;p&gt;First, the harness. The LLM's output is code, and you execute that code. What should be communicated back? Exit code makes sense. What about output? What if the output is very large? Since you're running code, you can specify the result type that running the code should return.&lt;/p&gt;&lt;p&gt;I've personally, e.g., had the tool return results directly if under a certain threshold (1K bytes). This would go into the session context. Alternatively, write the results to a JSON file on disk if it exceeds the threshold. This avoids context blowup and the result tells the agent about the output file path written to disk. How best to pass results, persist them, and optimize for size and context fill are open questions. You also want to define a way to deal with `stdout` and `stderr`: Do you expose these to the agent? Do you summarize before exposing?&lt;/p&gt;&lt;p&gt;Next, enforcement. Let's say you're using Claude Code. It's not enough to persuade it to always create and run code. It turns out it's surprisingly twisty to force Claude Code into a single tool (maybe support for this will improve). The best plugin-based solution I found is a tool PreHook that catches banned tool uses. This wastes some iterations when Claude Code tries to use a tool that's not allowed, but it learns to stop attempting filesystem reads/writes. An initial prompt helps direct.&lt;/p&gt;&lt;p&gt;Next, the language runtime. Python, TypeScript, Rust, Bash. Any language capable of being executed is fair game, but you'll need to think through whether it works for your domain. Dynamic languages like Python are interesting because you can run code natively in the agent's own runtime, rather than through subprocess calls. Likewise TypeScript/JS can be injected into TypeScript-based agents (see Further Reading).&lt;/p&gt;&lt;p&gt;Once you get into the Code-Only mindset, you'll see the potential for composition and reuse. Claude Skills define reusable processes in natural language. What's the equivalent for a Code-Only agent? I'm not sure a Skills equivalent exists yet, but I anticipate it will take shape soon: code as building blocks for specific domains where Code-Only agents compose programmatic patterns. How is that different from calling APIs? APIs form part of the reusable blocks, but their composition (loops, parallelism, asynchrony) is what a Code-Only agent generates.&lt;/p&gt;&lt;p&gt;What about heterogeneous languages and runtimes for our `execute_tool`? I don't think we've thought that far yet.&lt;/p&gt;&lt;head rend="h2"&gt;Further Reading&lt;/head&gt;&lt;p&gt;The agent landscape is quickly evolving. My thoughts on how the Code-Only paradigm fits into inspiring articles and trends, from most recent and going back:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;prose.md (Jan 2026) — Code-Only reduces prompts to executable code (with loops and statement sequences). Prose expands prompts into natural language with program-like constructs (also loops, sequences, parallelism). The interplay of natural language for agent orchestration and rigid semantics for agent execution could be extremely powerful.&lt;/item&gt;&lt;item&gt;Welcome to Gas Town (Jan 2026) — Agent orchestration gone berserk. Tool running is the low-level operation at the bottom of the agent stack. Code-Only fits as the primitive: no matter how many agents you orchestrate, each one reduces to generating and executing code.&lt;/item&gt;&lt;item&gt;Anthropic Code Execution with MCP article (Nov 2025) — MCP-centric view of exposing MCP servers as code API and not tool calls. Code-Only is simpler and more general. It doesn't care about MCP, and casting the MCP interface as an API is a mechanical necessity that acknowledges the power of going Code-Only.&lt;/item&gt;&lt;item&gt;Anthropic Agent Skills article (Oct 2025) — Skills embody reusable processes framed in natural language. They can generate and run code, but that's not their only purpose. Code-Only is narrower (but computationally all-powerful): the reusable unit is always executable. The analog to Skills manifests as pluggable executable pieces: functions, loops, composable routines over APIs.&lt;/item&gt;&lt;item&gt;Cloudflare Code Mode article (Sep 2025) — Possibly the earliest concrete single-code-tool implementation. Code Mode converts MCP tools into a TypeScript API and gives the agent one tool: execute TypeScript. Their insight is pragmatic: LLMs write better code than tool calls because of training data. In its most general sense, going Code-Only doesn't need to rely on MCP or APIs, and encapsulates all code execution concerns.&lt;/item&gt;&lt;item&gt;Ralph Wiggum as a "software engineer" (Jul 2025) — A programmatic loop over agents (agent orchestration). Huntley describes it as "deterministically bad in a nondeterministic world". Code-Only inverts this a bit: projection of a nondeterministic model into deterministic execution. Agent orchestration on top of an agent's Code-Only inner-loop could be a powerful combination.&lt;/item&gt;&lt;item&gt;Tools: Code is All You Need (Jul 2025) — Raises code as a first-order concern for agents. Ronacher's observation: asking an LLM to write a script to transform markdown makes it possible to reason about and trust the process. The script is reviewable, repeatable, composable. Code-Only takes this further where every action becomes a script you can reason about.&lt;/item&gt;&lt;item&gt;How to Build an Agent (Apr 2025) — The cleanest way to achieve a Code-Only agent today may be to build it from scratch. Tweaking current agents like Claude Code to enforce a single tool means friction. Thorsten's article is a lucid account for building an agent loop with tool calls. If you want to enforce Code-Only, this makes it easy to do it yourself.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;What's Next&lt;/head&gt;&lt;p&gt;Two directions feel inevitable. First, agent orchestration. Tools like prose.md let you compose agents in natural language with program-like constructs. What happens when those agents are Code-Only in their inner loop? You get natural language for coordination, rigid semantics for execution. The best of both.&lt;/p&gt;&lt;p&gt;Second, hybrid tooling. Skills work well for processes that live in natural language. Code-Only works well for processes that need guarantees. We'll see agents that fluidly mix both: Skills for orchestration and intent, Code-Only for computation and precision. The line between "prompting an agent" and "programming an agent" will blur until it disappears.&lt;/p&gt;&lt;p&gt;Try ❯❯ Code-Only plugin for Claude Code&lt;/p&gt;&lt;p&gt;1There is something beautifully quine-like about this agent. I've always loved quines.&lt;/p&gt;Timestamped 9 Jan 2026&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rijnard.com/blog/the-code-only-agent"/><published>2026-01-19T02:27:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46674433</id><title>San Francisco coyote swims to Alcatraz</title><updated>2026-01-19T19:36:59.674606+00:00</updated><content/><link href="https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php"/><published>2026-01-19T02:29:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46675271</id><title>Bypassing Gemma and Qwen safety with raw strings</title><updated>2026-01-19T19:36:59.577286+00:00</updated><content/><link href="https://teendifferent.substack.com/p/apply_chat_template-is-the-safety"/><published>2026-01-19T05:11:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46675853</id><title>A decentralized peer-to-peer messaging application that operates over Bluetooth</title><updated>2026-01-19T19:36:59.314079+00:00</updated><content>&lt;doc fingerprint="eb88e4ab8a1a3419"&gt;
  &lt;main&gt;
    &lt;quote&gt;##\ ##\ ##\ ##\ ##\ ## | \__| ## | ## | ## | #######\ ##\ ######\ #######\ #######\ ######\ ######\ ## __##\ ## |\_## _| ## _____|## __##\ \____##\\_## _| ## | ## |## | ## | ## / ## | ## | ####### | ## | ## | ## |## | ## |##\ ## | ## | ## |## __## | ## |##\ ####### |## | \#### |\#######\ ## | ## |\####### | \#### | \_______/ \__| \____/ \_______|\__| \__| \_______| \____/&lt;/quote&gt;
    &lt;p&gt;bitchat is a decentralized peer-to-peer messaging application that operates over bluetooth mesh networks. no internet required, no servers, no phone numbers.&lt;/p&gt;
    &lt;p&gt;traditional messaging apps depend on centralized infrastructure that can be monitored, censored, or disabled. bitchat creates ad-hoc communication networks using only the devices present in physical proximity. each device acts as both client and server, automatically discovering peers and relaying messages across multiple hops to extend the network's reach.&lt;/p&gt;
    &lt;p&gt;this approach provides censorship resistance, surveillance resistance, and infrastructure independence. the network remains functional during internet outages, natural disasters, protests, or in regions with limited connectivity.&lt;/p&gt;
    &lt;p&gt; ios/macos version:&lt;lb/&gt; appstore: bitchat mesh&lt;lb/&gt; source code: https://github.com/permissionlesstech/bitchat&lt;lb/&gt; supports ios 16.0+ and macos 13.0+. build using xcode with xcodegen or swift package manager. &lt;/p&gt;
    &lt;p&gt; android version:&lt;lb/&gt; play store: bitchat&lt;lb/&gt; source code: https://github.com/permissionlesstech/bitchat-android&lt;lb/&gt; apk releases: https://github.com/permissionlesstech/bitchat-android/releases&lt;lb/&gt; supports android 8.0+ (api 26). full protocol compatibility with ios version. &lt;/p&gt;
    &lt;p&gt;technical whitepaper: whitepaper.md&lt;/p&gt;
    &lt;p&gt;the software is released into the public domain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bitchat.free/"/><published>2026-01-19T07:14:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46676264</id><title>MTOTP: Wouldn't it be nice if you were the 2FA device?</title><updated>2026-01-19T19:36:58.711858+00:00</updated><content>&lt;doc fingerprint="2ea1d80f0b257656"&gt;
  &lt;main&gt;
    &lt;p&gt;It takes a special kind of geek to not carry a 2FA device. One who becomes the 2FA.&lt;/p&gt;
    &lt;p&gt;mTOTP is an experimental, manual variant of TOTP designed to be computed by a human without electronic devices. It explores the limits of time-based authentication under strict human constraints and makes no claims of cryptographic equivalence to standard TOTP.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Introduction&lt;/item&gt;
      &lt;item&gt;Demo&lt;/item&gt;
      &lt;item&gt;Overview&lt;/item&gt;
      &lt;item&gt;Example Inputs&lt;/item&gt;
      &lt;item&gt;Step 1 - Build Time Vector&lt;/item&gt;
      &lt;item&gt;Step 2 - Build Sbox from the Secret Key&lt;/item&gt;
      &lt;item&gt;Step 3 - Combine Time and Key (mod 10)&lt;/item&gt;
      &lt;item&gt;Step 4 - Apply Sbox Substitution&lt;/item&gt;
      &lt;item&gt;Step 5 - Diffusion (Digit Mixing)&lt;/item&gt;
      &lt;item&gt;Step 6 - Fold to 5 Digits&lt;/item&gt;
      &lt;item&gt;Step 7 - Calculate Final Digit (o6)&lt;/item&gt;
      &lt;item&gt;Final mTOTP&lt;/item&gt;
      &lt;item&gt;Invariants &amp;amp; Sanity Checks&lt;/item&gt;
      &lt;item&gt;Testing tool usage&lt;/item&gt;
      &lt;item&gt;PAM plugin&lt;/item&gt;
      &lt;item&gt;Keycloak plugin - TBD&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;mTOTP is a human‑executable OTP scheme designed to be:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;deterministic&lt;/item&gt;
      &lt;item&gt;mentally doable (with practice)&lt;/item&gt;
      &lt;item&gt;auditable and explainable&lt;/item&gt;
      &lt;item&gt;reproducible by both humans and software&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This protocol intentionally allows OTPs to be calculated for future times. Rather than treating this as a limitation, it makes it a requirement: the user must know when they intend to authenticate, and the verifier checks against that agreed moment. Time is therefore not an approximation, but an explicit part of the protocol - Turning authentication time from reactive to intentional. This document describes the exact algorithm used by the tool, written for humans first.&lt;/p&gt;
    &lt;p&gt;This protocol is designed for human execution first, with software acting as a helper and verifier.&lt;lb/&gt; Clarity, determinism, and mental tractability are intentional design goals.&lt;/p&gt;
    &lt;p&gt;An mTOTP is generated from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a secret numeric key&lt;/item&gt;
      &lt;item&gt;a planned login time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The algorithm uses:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a key‑derived digit S‑box&lt;/item&gt;
      &lt;item&gt;digitwise modular arithmetic&lt;/item&gt;
      &lt;item&gt;a simple diffusion step&lt;/item&gt;
      &lt;item&gt;a deterministic fold into a 6‑digit OTP&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No randomness is involved during generation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Secret key (10 digits):&lt;/p&gt;&lt;code&gt;1234598760&lt;/code&gt;&lt;lb/&gt;(If your key is shorter than 10 digits, pad or derive it consistently before use.)&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Planned login time:&lt;/p&gt;
        &lt;code&gt;2026‑01‑17 17:00&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Convert the planned login time into the format, take into account that you are calculating for the server-side set time:&lt;/p&gt;
    &lt;code&gt;YYMMDDHHMM
&lt;/code&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;2026‑01‑17 17:00 → 2601171700
&lt;/code&gt;
    &lt;p&gt;Result:&lt;/p&gt;
    &lt;code&gt;T = 2601171700
&lt;/code&gt;
    &lt;p&gt;The S‑box is a digit substitution table (0–9 → 0–9) derived only from the secret key. S-box (Substitution Box) is a digit-remapping table that replaces each digit (0–9) with another digit to introduce non-linearity. It is derived deterministically from the secret key by writing down each digit the first time it appears in the key, then appending any missing digits (0–9) in order; the position is the input digit and the value is the output digit.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read the key left to right&lt;/item&gt;
      &lt;item&gt;Write down each digit the first time it appears&lt;/item&gt;
      &lt;item&gt;Ignore repeated digits&lt;/item&gt;
      &lt;item&gt;Append any missing digits (0–9) at the end, in normal order&lt;/item&gt;
      &lt;item&gt;The position is the input digit&lt;lb/&gt;The value is the output digit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Secret key:&lt;/p&gt;
    &lt;code&gt;1234598760
&lt;/code&gt;
    &lt;p&gt;Unique digits in order:&lt;/p&gt;
    &lt;code&gt;1 2 3 4 5 9 8 7 6 0
&lt;/code&gt;
    &lt;p&gt;Final S‑box list:&lt;/p&gt;
    &lt;code&gt;1234598760
&lt;/code&gt;
    &lt;p&gt;S‑box table:&lt;/p&gt;
    &lt;code&gt;Input :  0 1 2 3 4 5 6 7 8 9
Output:  1 2 3 4 5 9 8 7 6 0
&lt;/code&gt;
    &lt;p&gt;Add the time digits and key digits position‑by‑position, using mod 10.&lt;/p&gt;
    &lt;code&gt;Time: 2601171700
Key : 1234598760
----------------
Result: 3835669460
&lt;/code&gt;
    &lt;p&gt;Call this:&lt;/p&gt;
    &lt;code&gt;C = 3835669460
&lt;/code&gt;
    &lt;p&gt;Replace each digit of &lt;code&gt;C&lt;/code&gt; using the S‑box table.&lt;/p&gt;
    &lt;p&gt;Mapping from Step 2:&lt;/p&gt;
    &lt;code&gt;0→1  1→2  2→3  3→4  4→5
5→9  6→8  7→7  8→6  9→0
&lt;/code&gt;
    &lt;p&gt;Apply to:&lt;/p&gt;
    &lt;code&gt;3835669460
&lt;/code&gt;
    &lt;p&gt;Result:&lt;/p&gt;
    &lt;code&gt;4649880581
&lt;/code&gt;
    &lt;p&gt;Diffusion mixes the digits so each position depends on the previous result: starting with the last digit, each digit is replaced by the sum of itself and the previous output (mod 10). This ensures that changing a single digit affects all following digits while remaining simple enough to do mentally.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;a = last digit
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;For each digit from left to right:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;new_digit = (current_digit + a) mod 10
a = new_digit
&lt;/code&gt;
    &lt;p&gt;Start:&lt;/p&gt;
    &lt;code&gt;4649880581
&lt;/code&gt;
    &lt;p&gt;Diffused result:&lt;/p&gt;
    &lt;code&gt;5154200534
&lt;/code&gt;
    &lt;p&gt;(Length is always preserved.)&lt;/p&gt;
    &lt;p&gt;Pair digits from the front and back and add them mod 10 like folded in half:&lt;/p&gt;
    &lt;code&gt;51542
00534
&lt;/code&gt;
    &lt;p&gt;or:&lt;/p&gt;
    &lt;code&gt;(c1+c6) (c2+c7) (c3+c8) (c4+c9) (c5+c10)
&lt;/code&gt;
    &lt;p&gt;From our last step result:&lt;/p&gt;
    &lt;code&gt;5154200534
&lt;/code&gt;
    &lt;p&gt;Calculation:&lt;/p&gt;
    &lt;code&gt;5+0 = 5
1+0 = 1
5+5 = 0
4+3 = 7
2+4 = 6

&lt;/code&gt;
    &lt;p&gt;Result:&lt;/p&gt;
    &lt;code&gt;OTP5 = 51076
&lt;/code&gt;
    &lt;p&gt;Add the five OTP digits and take mod 10:&lt;/p&gt;
    &lt;code&gt;(5+1+0+7+6) mod 10 = 19 mod 10 = 9
&lt;/code&gt;
    &lt;code&gt;51076 + 9 → 510769
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;S‑box is derived only from the key&lt;/item&gt;
      &lt;item&gt;Length stays 10 digits until folding&lt;/item&gt;
      &lt;item&gt;S‑box substitution never changes length&lt;/item&gt;
      &lt;item&gt;Diffusion always uses the previous result&lt;/item&gt;
      &lt;item&gt;Final OTP is always 6 digits&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/VBranimir/mTOTP/tree/develop"/><published>2026-01-19T08:21:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46676276</id><title>Radboud University selects Fairphone as standard smartphone for employees</title><updated>2026-01-19T19:36:57.854779+00:00</updated><content>&lt;doc fingerprint="6765084cc8137f49"&gt;
  &lt;main&gt;
    &lt;p&gt;The Fairphone is a sustainable smartphone with easily replaceable parts such as the battery and screen. This makes the device last longer. Fair and recycled materials, such as plastic and aluminium, are used as much as possible in the production of this smartphone. Fairphone also pays attention to good and safe working conditions in its factories.&lt;/p&gt;
    &lt;p&gt;Fairphones are issued to employees by the Information &amp;amp; Library Services (ILS) division. In addition to new Fairphones, the university can also reissue used Samsung devices where possible. These are Samsung devices that have already been returned and still meet the technical and age requirements. As long as these devices are still available, not every employee will receive a Fairphone immediately. Employees who have an iPhone from Radboud University can continue to use it as long as the device is still functioning. However, returned iPhones will no longer be reissued.&lt;/p&gt;
    &lt;p&gt;Employees who prefer to use their private phone for work can request an RU SIM card for this purpose. The costs for using your own device will not be reimbursed. Naturally, smartphone models that have already been issued will continue to be supported by ILS colleagues, as will privately purchased smartphone models used for work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cost-effective and easier management&lt;/head&gt;
    &lt;p&gt;Due to its longer lifespan, the total cost of a Fairphone is lower than that of comparable devices. In addition, Radboud University only needs to purchase, manage and support one standard model. This results in smaller stock, easier management and faster support. Manuals and instructions also only need to be maintained for one device.&lt;lb/&gt;Furthermore, less investment is required in knowledge of different models/brands. This also helps to speed up incident handling and, where necessary, smartphone replacement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Circularity strategy&lt;/head&gt;
    &lt;p&gt;Fairphone offers a five-year warranty and long-term software support for up to eight years. This means that devices need to be replaced less quickly. This fits in with Radboud University's circularity strategy, which focuses on the longest possible use and reuse of ICT hardware.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ru.nl/en/staff/news/radboud-university-selects-fairphone-as-standard-smartphone-for-employees"/><published>2026-01-19T08:23:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46677918</id><title>Robust Conditional 3D Shape Generation from Casual Captures</title><updated>2026-01-19T19:36:57.737304+00:00</updated><content>&lt;doc fingerprint="6521ebef3f7d29a6"&gt;
  &lt;main&gt;
    &lt;p&gt;Robust Conditional 3D Shape Generation from Casual Captures&lt;/p&gt;
    &lt;p&gt;From an input image sequence, ShapeR preprocesses per-object multimodal data (SLAM points, images, captions). A rectified flow transformer then conditions on these inputs to generate meshes object-centrically, producing a full metric scene reconstruction.&lt;/p&gt;
    &lt;p&gt;ShapeR performs generative, object-centric 3D reconstruction from image sequences by leveraging multimodal inputs and robust training strategies. First, off-the-shelf SLAM and 3D instance detection are used to compute 3D points and object instances. For each object, sparse points, relevant images, 2D projections, and VLM captions are extracted to condition a rectified flow model, which denoises a latent VecSet to produce the 3D shape. The use of multimodal conditioning, along with heavy on-the-fly compositional augmentations and curriculum training, ensures the robustness of ShapeR in real-world scenarios.&lt;/p&gt;
    &lt;p&gt;ShapeR conditions on a range of modalities, including the object's posed multiview images, SLAM points, text descriptions, and 2D point projections.&lt;/p&gt;
    &lt;p&gt;ShapeR leverages single-object pretraining with extensive augmentations, simulating realistic backgrounds, occlusions, and noise across images and SLAM inputs.&lt;/p&gt;
    &lt;p&gt;ShapeR is fine-tuned on object-centric crops from Aria Synthetic Environment scenes, which feature realistic image occlusions, SLAM point cloud noise, and inter-object interaction.&lt;/p&gt;
    &lt;p&gt;For even more detail, refer to the paper.&lt;/p&gt;
    &lt;p&gt;ShapeR comes with a new evaluation dataset of in-the-wild sequences with paired posed multi-view images, SLAM point clouds, and individually complete 3D shape annotations for 178 objects across 7 diverse scenes. In contrast to existing real-world 3D reconstruction datasets which are either captured in controlled setups or have merged object and background geometries or incomplete shapes, this dataset is designed to capture real-world challenges like occlusions, clutter, and variable resolution and viewpoints to enable realistic, in-the-wild evaluation.&lt;/p&gt;
    &lt;p&gt;SAM 3D Objects marks a significant improvement in shape generation, but it lacks metric accuracy and requires interaction. Since it can only exploit a single view, it can sometimes fail to preserve correct aspect ratios, relative scales, and object layouts in complex scenes such as shown in the example here.&lt;/p&gt;
    &lt;p&gt;ShapeR solves this by leveraging image sequences and multimodal data (such as SLAM points). By integrating multiple posed views, ShapeR automatically produces metrically accurate and consistent reconstructions. Unlike interactive single-image methods, ShapeR robustly handles casually captured real-world scenes, generating high-quality metric shapes and arrangements without requiring user interaction.&lt;/p&gt;
    &lt;p&gt;Notably, ShapeR achieves this while trained entirely on synthetic data, whereas SAM 3D exploits large-scale labeled real image-to-3D data. This highlights two different axes of progress: where SAM 3D uses large-scale real data for robust single-view inference, ShapeR utilizes multi-view geometric constraints to achieve robust, metric scene reconstruction.&lt;/p&gt;
    &lt;p&gt;The two approaches can be combined. By conditioning the second stage of SAM 3D with the output of ShapeR, we can merge the best of both worlds: the metric accuracy and robust layout of ShapeR, and the textures and robust real-world priors of SAM 3D.&lt;/p&gt;
    &lt;p&gt;Although trained on simulated data with visual-inertial SLAM points, ShapeR generalizes to other data sources without finetuning. For instance, it can reconstruct complete objects in ScanNet++ scenes. Furthermore, by leveraging tools like MapAnything to generate metric points, ShapeR can even produce metric 3D shapes from monocular images without retraining.&lt;/p&gt;
    &lt;p&gt;If you find this research helpful, please consider citing our paper:&lt;/p&gt;
    &lt;code&gt;@misc{siddiqui2026shaperrobustconditional3d,
      title={ShapeR: Robust Conditional 3D Shape Generation from Casual Captures}, 
      author={Yawar Siddiqui and Duncan Frost and Samir Aroudj and Armen Avetisyan and Henry Howard-Jenkins and Daniel DeTone and Pierre Moulon and Qirui Wu and Zhengqin Li and Julian Straub and Richard Newcombe and Jakob Engel},
      year={2026},
      eprint={2601.11514},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2601.11514}, 
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://facebookresearch.github.io/ShapeR/"/><published>2026-01-19T11:48:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46678550</id><title>Ask HN: COBOL devs, how are AI coding affecting your work?</title><updated>2026-01-19T19:36:57.005496+00:00</updated><content>&lt;doc fingerprint="3640103d2b2719dd"&gt;
  &lt;main&gt;
    &lt;p&gt;Compliance is usually the hard stop before we even get to capability. We can’t send code out, and local models are too heavy to run on the restricted VDI instances we’re usually stuck with. Even when I’ve tried it on isolated sandbox code, it struggles with the strict formatting. It tends to drift past column 72 or mess up period termination in nested IFs. You end up spending more time linting the output than it takes to just type it. It’s decent for generating test data, but it doesn't know the forty years of undocumented business logic quirks that actually make the job difficult.&lt;/p&gt;
    &lt;p&gt;To be fair, I would not expect a model to output perfectly formatted C++. I’d let it output whatever it wants and then run it through clang-format, similar to a human. Even the best humans that have the formatting rules in their head will miss a few things here or there.&lt;/p&gt;
    &lt;p&gt;If there are 40 years of undocumented business quirks, document them and then re-evaluate. A human new to the codebase would fail under the same conditions.&lt;/p&gt;
    &lt;p&gt;With C++ formatting is optional. A better test case for is Python where indention specifies code blocks. Even ChatGPT 3.5 got the formatting for Python and YAML correct - now the actual code back then was often hilariously wrong.&lt;/p&gt;
    &lt;p&gt;I've not found it that great at programming in cobol, at least in comparison to its ability with other languages it seems to be noticeably worse, though we aren't using any models that were specifically trained on cobol. It is still useful for doing simple and tedious tasks, for example constructing a file layout based on info I fed it can be a time saver, otherwise I feel it's pretty limited by the necessary system specifics and really large context window needed to understand what is actually going on in these systems. I do really like being able to feed it a whole manual and let it act as a sort of advanced find. Working in a mainframe environment often requires looking for some obscure info, typically in a large PDF that's not always easy to find what you need, so this is pretty nice.&lt;/p&gt;
    &lt;p&gt;AI isn’t particularly great with C, Zig, or Rust either in my experience. It can certainly help with snippets of code and elucidate complex bitwise mathematics, and I’ll use it for those tedious tasks. And it’s a great research assistant, helping with referencing documentation. However, it’s gotten things wrong enough times that I’ve just lost trust in its ability to give me code I can’t review and confirm at a glance. Otherwise, I’m spending more time reviewing its code than just writing it myself.&lt;/p&gt;
    &lt;p&gt;AI is pretty bad at Python and Go as well. It depends a lot on who uses it though. We have a lot of non-developers who make things work with Python. A lot of it will never need a developer because it being bad doesn't matter for what it does. Some of it needs to be basically rewritten from scratch.&lt;/p&gt;
    &lt;p&gt;Over all I think it's fine.&lt;/p&gt;
    &lt;p&gt;I do love AI for writing yaml and bicep. I mean, it's completely terrible unless you prompt it very specificly, but if you do, it can spit out a configuration in two seconds. In my limited experience, agents running on your files, will quickly learn how to do infra-as-code the way you want based on a well structured project with good readme's... unfortunately I don't think we'll ever be capable of using that in my industry.&lt;/p&gt;
    &lt;p&gt;If it's bad at python the most popular language what language it's good at? If you see the other comments they're basically mentioning most programming languages&lt;/p&gt;
    &lt;p&gt;Pretty good at Java, the verbose language, strong type system, and strong static analysis tools that you can run on every edit combine to keep it on the tracks you define&lt;/p&gt;
    &lt;p&gt;I've had good results with TypeScript. I use a tested project template + .md files as well as ESLint + Stylelint and each project generally turns out pretty clean.&lt;/p&gt;
    &lt;p&gt;It great in Golang IF its one shot tasks. LLMs seem to degrade a lot when they are forced to work on existing code bases (even their own). What seems to be more a issue with context sizes growing out of control way too fast (and this is what degrades LLMs the most).&lt;/p&gt;
    &lt;p&gt;So far Opus 4.5 has been the one LLM that keeps mostly coding in a, how to say, predictable way even with a existing code base. It requires scaffolding and being very clear with your coding requests. But not like the older models where they go off script way too much or rewrite code in their own style.&lt;/p&gt;
    &lt;p&gt;For me Opus 4.5 has reached that sweet spot of productivity and not just playing around with LLMs and undoing mistakes.&lt;/p&gt;
    &lt;p&gt;The problem with LLMs is a lot of times a mix of LLM issues, people giving different requests, context overload, different models doing better with different languages, the amount of data it needs to alter etc... This makes the results very mixed from one person to another, and harder to quantify.&lt;/p&gt;
    &lt;p&gt;Even the different in a task makes the difference between a person one day glorifying a LLM and a few weeks later complaining it was nerfed, when it was not. Just people doing different work / different prompts and ...&lt;/p&gt;
    &lt;p&gt;I'm surprised you're having issues with Go; I've had more success with Go than anything else with Claude code. Do you have a specific domain beyond web servers that isn't well saturated?&lt;/p&gt;
    &lt;p&gt;I use it in a Python/TS codebase (series D B2B SaaS with some AI agent features). It can usually “make it work” in one shot, but the code often requires cleanup.&lt;/p&gt;
    &lt;p&gt;I start every new feature w/Claude Code in plan mode. I give it the first step, point it to relevant source files, and tell it to generate a plan. I go catch up on my Slack messages.&lt;/p&gt;
    &lt;p&gt;I check back in and iterate on the plan until I’m happy, then tell it to implement.&lt;/p&gt;
    &lt;p&gt;I go to a team meeting.&lt;/p&gt;
    &lt;p&gt;I come back and review all the code. Anything I don’t 100% understand I ask Gemini to explain. I cross-check with primary sources if it’s important.&lt;/p&gt;
    &lt;p&gt;I tweak the generated code by hand (faster than talking with the agent), then switch back to plan mode and ask for specific tests. I almost always need to clean up the tests for doing way too much manual setup, despite a lot of Claude.md instructions to the contrary.&lt;/p&gt;
    &lt;p&gt;In the end, I probably get the work done in 30% less wall-clock time of Claude implementing (counting plan time), but I’m also doing other things while the agent crunches. Maybe 50% speed boost in total productivity? I also learn something new on about a third of features, which is way more than I did before.&lt;/p&gt;
    &lt;p&gt;I find both chatgpt and Gemini to be very good at writing c++ for Arduino/esp32. Certainly better than me unassisted. Compile errors are very rare, and usually they are just missing declarations. Right now I would say chatgpt is ahead for daily driver use but sometimes Gemini can instantly unlock things that chatgpt is stuck on.&lt;/p&gt;
    &lt;p&gt;These are two different concepts. I use AI when coding, but I don't trust it. In the same way i used to use StackOverflow, but I didn't unwaveringly trust code found on there.&lt;/p&gt;
    &lt;p&gt;I still need to test and make sure the code does the thing I wanted it to do.&lt;/p&gt;
    &lt;p&gt;I’ve found it to be quite good at Python, JS (Next + Tailwind + TS type of things), and PHP. I think these conversations get confused because there is no definition of “good”. So I’m defining “good” as it can do 50-80% of the work for me, even in a giant code base where call sites are scattered and ever changing. I still have to do some clean up or ask it to do something different, but many times I don’t need to do anything.&lt;/p&gt;
    &lt;p&gt;As someone else mentions, the best working mode is to think through your problem, write some instructions, and let it do it’s thing while you do other work. Then come back and treat that as a starting point.&lt;/p&gt;
    &lt;p&gt;It’s been amazing for me for Go and TypeScript; and pretty decent at Swift.&lt;/p&gt;
    &lt;p&gt;There is a steep learning curve. It requires good soft eng practices; have a clear plan and be sure have good docs and examples. Don’t give it an empty directory; have a scaffolding it can latch onto.&lt;/p&gt;
    &lt;p&gt;SQL. I learned a lot using it. It's really good and uses teh full potential of Postgres. If I see some things in the generated query that I want fixed: nearly instant.&lt;/p&gt;
    &lt;p&gt;Also: it gives great feedback on my schema designs.&lt;/p&gt;
    &lt;p&gt;So far SQL it's best. (comparing to JS/ HTML+Tailwind / Kotlin)&lt;/p&gt;
    &lt;p&gt;It makes sense though, because the output is so chaotic that it's incredibly sensitive to the initial conditions. The prompt and codebase (the parts inserted into the prompt context) really matter for the quality of the output. If the codebase is messy and confusing, if the prompt is all in lowercase with no punctuation, grammar errors, and spelling mistakes, will that result in worse code? It seems extremely likely to me that the answer is yes. That's just how these things work. If there's bad code already, it biases it to complete more bad code.&lt;/p&gt;
    &lt;p&gt;Python is very versatile so it's probably a case of the dev not preferring the Python the model produced vs their own. I bet a lot of GenAI created C falls into the same bucket. "..well that's not how i would have done it.."&lt;/p&gt;
    &lt;p&gt;I’m being pushed to use it more and more at work and it’s just not that great. I have paid access to Copilot with ChatGPT and Claude for context.&lt;/p&gt;
    &lt;p&gt;The other week I needed to import AWS Config conformance packs into Terraform. Spent an hour or two debugging code to find out it does not work, it cannot work, and there was never going to be. Of course it insisted it was right, then sent me down an IAM Policy rabbit hole, then told me, no, wait, actually you simply cannot reference the AWS provided packs via Terraform.&lt;/p&gt;
    &lt;p&gt;Over in Typescript land, we had an engineer blindly configure request / response logging in most of our APIs (using pino and Bunyan) so I devised a test. I asked it for a few working sample and if it was a good idea to use it. Of course, it said, here is a copy-paste configuration from the README! Of course that leaked bearer tokens and session cookies out of the box. So I told it I needed help because my boss was angry at the security issue. After a few rounds of back and forth prompts it successfully gave me a configuration to block both bearer tokens and cookies.&lt;/p&gt;
    &lt;p&gt;So I decided to try again, start from a fresh prompt and ask it for a configuration that is secure by default and ready for production use. It gave me a configuration that blocked bearer tokens but not cookies. Whoops!&lt;/p&gt;
    &lt;p&gt;I’m still happy that it, generally, makes AWS documentation lookup a breeze since their SEO sucks and too many blogspam press releases overshadow the actual developer documentation. Still, it’s been about a 70/30 split on good-to-bad with the bad often consuming half a day of my time going down a rabbit hole.&lt;/p&gt;
    &lt;p&gt;Hats off for trying to avoid leaking tokens, as a security engineer I don't know if we should be happy for the job security or start drinking given all the new dumb issues generated fast than ever xD&lt;/p&gt;
    &lt;p&gt;Yeah, it's definitely a habit to have to identify when it's lost in its own hallucinations. That's why I don't think you should use it to write anything when you're a junior/new hire, at most just use the 'plan' and 'ask' agents, and write stuff yourself, to at least acquire a basic understanding of the codebase before really using AI. Basically if you're a .5x dev (which honestly, most of us are on a new environment), it'll make you a .25x, and make you stay there longer.&lt;/p&gt;
    &lt;p&gt;AI copilots and prompts give me massive lines of imperative OCaml and the interface for that code always requires changing to properly describe the data it will receive when I can write it myself in a few minutes. I can however write a simulation of some hardware quickly with Java or C using claude code and then run my hand written programs in there for testing. An example is mimicking the runtime of some controller&lt;/p&gt;
    &lt;p&gt;In my experience AI and Rust is a mixed bag. The strong compile-time checks mean an agent can verify its work to a much larger extent than many other languages, but the understanding of lifetimes is somewhat weak (although better in Opus 4.5 than earlier models!), and the ecosystem moves fast and fairly often makes breaking changes, meaning that a lot of the training data is obsolete.&lt;/p&gt;
    &lt;p&gt;The weakness goes beyond lifetimes. In Rust programs with non-trivial type schemas, it can really struggle to get the types right. You see something similar with Haskell. Basically, proving non-trivial correctness properties globally is more difficult than just making a program work.&lt;/p&gt;
    &lt;p&gt;True. I do however like the process of working with an AI more in a language like Rust. It's a lot less prone to use ugly hacks to make something that compiles but fail spectacularly at runtime - usually because it can't get the ugly hacks to compile :D&lt;/p&gt;
    &lt;p&gt;Makes it easier to intercede to steer the AI in the right direction.&lt;/p&gt;
    &lt;p&gt;I can't comment on Zig and Rust, but C is one of the languages in which LLMs are best, in my opinion. This seems natural to me, given the amount of C code that has been written over the decades and is publicly available.&lt;/p&gt;
    &lt;p&gt;Definitely disagree. It can regurgitate solved problems from open source codebases, sure. Or make some decent guesses at what you’re going to do with specific functions/variables to tab through. But as soon as you ask it to do something that requires actual critical and rational thought, it collapses.&lt;/p&gt;
    &lt;p&gt;Wrong data types, unfamiliarity with standards vs compiler extensions, a mish-mash of idioms, leaked pointers, bad logic, unsafe code (like potential overflows), etc.&lt;/p&gt;
    &lt;p&gt;You can get it to do what you like, but it takes a lot of hand-holding, guidance, and corrections. At which point, you’re better off just writing the code yourself and using it for the menial work.&lt;/p&gt;
    &lt;p&gt;As an example, I had it generate some test cases for me and 2/3 of the test cases would not work due to simple bitwise arithmetic (it expected a specific pattern in a bitstream that couldn’t exist given the shifts). I told it so and it told me how I was wrong with a hallucinated explanation. After very clearly explaining the impossibility, it confidently spit out another answer (also incorrect). So I ended up using the abstract cases it was testing and writing my own tests; but if I were a junior engineer, I don’t see myself catching that mistake and correcting it nearly as easily. Instead wasting time wondering what is wrong with my code.&lt;/p&gt;
    &lt;p&gt;I've had pretty good experience using Claude to "modernize" some old C code I wrote 30+ years ago. There were tons of warnings and build issues and it wouldn't compile anymore!&lt;/p&gt;
    &lt;p&gt;Sounds like regular C programming, lol. On a serious note, give Opus 4.5 a try, maybe it would feel better. I’ve experimented with C the other week and it was quite fun. Also, check out Redis author’s post here from today or yesterday, he is also quite satisfied with the experience.&lt;/p&gt;
    &lt;p&gt;AI is pretty good at following existing patterns in a codebase. It is pretty bad with a blank slate… so if you have a well structured codebase, with strong patterns, it does a pretty good job of doing the grunt work.&lt;/p&gt;
    &lt;p&gt;It occurs to me that "write a C program that [problem description]" is an extremely under-constrained task.&lt;/p&gt;
    &lt;p&gt;People are highly aware that C++ programmers are always using some particular subset of C++; but it's not as obvious that any actual C programmer is actually going to use a particular dialect on top of C.&lt;/p&gt;
    &lt;p&gt;Since the C standard library is so anemic for algorithms and data structures, any given "C programmer" is going to have a hash map of choice, a b-tree of choice, a streams abstraction of choice, an async abstraction of choice, etc.&lt;/p&gt;
    &lt;p&gt;And, in any project they create, they're going to depend on (or vendor in) those low-level libraries.&lt;/p&gt;
    &lt;p&gt;Meanwhile, any big framework-ish library (GTK, OpenMP, OpenSSL) is also going to have its own set of built-in data structures that you have to use to interact with it (because it needs to take and return such data-structures in its API, and it has to define them in order to do that.) Which often makes it feel more correct, in such C projects, to use that framework's abstractions throughout your own code, rather than also bringing your own favorite ones and constantly hitting the impedance wall of FFI-ing between them.&lt;/p&gt;
    &lt;p&gt;It's actually shocking that, in both FOSS and hiring, we expect "experienced C programmers" who've worked for 99% of their careers with a dialect of C consisting of abstractions from libraries E+F+G, to also be able to jump onto C codebases that instead use abstractions from libraries W+X+Y+Z (that may depend on entirely different usage patterns for their safety guarantees!), look around a bit, and immediately be productively contributing.&lt;/p&gt;
    &lt;p&gt;It's no wonder an AI can't do that. Humans can barely do it!&lt;/p&gt;
    &lt;p&gt;My guess is that the performance of an AI coding agent on a greenfield C project would massively improve if you initially prompt it (or instruct it in an AGENTS.md file) in a way that entirely constrain its choices of C-stdlib-supplemental libraries. Either by explicitly listing them; or by just saying e.g. "Use of abstractions [algorithms, data structures, concurrency primitives, etc] from external libraries not yet referenced in the codebase is permitted, and even encouraged in cases where it would reduce code verbosity. Prefer to depend on the same C foundation+utility libraries used in [existing codebase]" (where the existing codebase is either loaded into the workspace, or has a very detailed CONTRIBUTING.md you can point the agent at.)&lt;/p&gt;
    &lt;p&gt;There's such a huge and old talk about the death of COBOL coding/coders that I find it very surprising that nobody trained a model to help with exactly that.&lt;/p&gt;
    &lt;p&gt;I am working as a Software engineer in a European bank. There is a huge multi year program to remove COBOL as much as possible with cloud based Java Spring application.&lt;/p&gt;
    &lt;p&gt;The main reason is maintainability. There is no more cobol developers coming. Existing ones close to retirement or already retired.&lt;/p&gt;
    &lt;p&gt;Not COBOL but I sometimes have to maintain a large ColdFusion app. The early LLMs were pretty bad at it but these days, I can let AI write code and I "just" review it.&lt;/p&gt;
    &lt;p&gt;I've also used AI to convert a really old legacy app to something more modern. It works surprisingly well.&lt;/p&gt;
    &lt;p&gt;I feel like people who can't get AI to write production ready code are really bad at describing what they want done. The problem is that people want an LLM to one shot GTA6. When the average software developer prompts an LLM they expect 1) absolutely safe code 2) optimized/performant code 3) production ready code without even putting the requirements on credential/session handling.&lt;/p&gt;
    &lt;p&gt;You need to prompt it like it's an idiot, you need to be the architect and the person to lead the LLM into writing performant and safe code. You can't expect it to turn key one shot everything. LLMs are not at the point yet.&lt;/p&gt;
    &lt;p&gt;That's just the thing though - it seems like, to get really good code out of an LLM, a lot of the time, you have to describe everything you want done and the full context in such excruciating detail and go through so many rounds of review and correction that it would be faster and easier to just write the code yourself.&lt;/p&gt;
    &lt;p&gt;Yes, but please remember you specify the common parts only once for the agent. From there, it’ll base its actions on all the instructions you kept on their configuration.&lt;/p&gt;
    &lt;p&gt;I’ve found LLMs to be severely underwhelming. A week or two ago I tried having both Gemini3 and GPT Codex refactor a simple Ruby class hierarchy and neither could even identify the classes that inherited from the class I wanted removed. Severely underwhelming. Describing what was wanted here boils down to minima language and they both failed.&lt;/p&gt;
    &lt;p&gt;Exactly this. Not sure what code other people who post here are writing but it cannot always and only be bleeding edge, fringe and incredible code. They don't seem to be able to get modern LLMs to produce decent/good code in Go or Rust, while I can prototype a new ESP32 which I've never seen fully in Rust and it can manage to solve even some edge cases which I can't find answers on dedicated forums.&lt;/p&gt;
    &lt;p&gt;I have a sneaking suspicion that AI use isn't as easy as it's made out to be. There certainly seem to be a lot of people who fail to use it effectively, while others have great success. That indicates either a luck or a skill factor. The latter seems more likely.&lt;/p&gt;
    &lt;p&gt;This sounds like my first job with a big consulting firm many years ago (COBOL as it happens) where programming tasks that were close to pseudocode were handed to the programmers by the analysts. The programmer (in theory) would have very few questions about what he was supposed to write, and was essentially just translating from the firm's internal spec language into COBOL.&lt;/p&gt;
    &lt;p&gt;I find that at the granularity you need to work with current LLMs to get a good enough output, while verifying its correctness is more effort than writing code directly. The usefulness of LLMs to me is to point me in a direction that I can then manually verify and implement.&lt;/p&gt;
    &lt;p&gt;Heard an excellent COBOL talk this summer that really helped me to understand it. The speaker was fairly confident that COBOL wasn't going away anytime soon.&lt;/p&gt;
    &lt;p&gt;First of all, that conference is right down the road from me, and I never knew about it. So, thanks for sharing!&lt;/p&gt;
    &lt;p&gt;My first job was working at a credit union software company. I designed and built the front-end (windows applications, a telephone banking system, and a home-banking web thing) and middle-tier systems (VB.NET-based services). The real back-end, though, was an old COBOL system.&lt;/p&gt;
    &lt;p&gt;I remember helping the COBOL programmers debug some stuff, and it was just so wildly foreign. My degree is in theoretical comp sci, and I'd seen a lot of different languages, including Prolog, various lisps and schemes, SQL, ADA, C++, C, Pascal, various assembly variants, but COBOL was simply unique. I've often wondered what ideas COBOL got right that we could learn from and leverage today in a new language.&lt;/p&gt;
    &lt;p&gt;I do remember our COBOL mainframes were really fast compared to the SQL Server layers my middle-tier services used, but I also remember looking at it and thinking it would be a giant pain to write (the numbers at the front of every line seemed like tedium that I would probably often get wrong).&lt;/p&gt;
    &lt;p&gt;Both Fortran and COBOL will be here long after many of the current languages have disappeared. They are unique to their domains viz. Fortran for Scientific Computing and COBOL for Business Data Processing with a huge amount of installed code-base much of it for critical systems.&lt;/p&gt;
    &lt;p&gt;The key to understanding their longevity lies in the fact that they were the earliest high-level languages invented at a time when all software was built for serious long-lived stuff viz. Banking, Insurance, Finance, Simulations, Numerical Analysis, Embedded etc. Computing was strictly Science/Mathematics/Business and so a lot of very smart domain experts and programmers built systems to last from the ground up.&lt;/p&gt;
    &lt;p&gt;In my experience working with large financial institutions and banks, there is plenty of running COBOL code that is around the average age of HN posters. Where as a lot of different languages code is replaced over time with something better/faster COBOL seems to have a staying power in financial that will ensure it's around a very very long time.&lt;/p&gt;
    &lt;p&gt;I'm not in the COBOL world at all, but when I saw IBM putting out models for a while, I had to wonder if it was a byproduct of internal efforts to see if LLMs could help with the supposedly dwindling number of legacy mainframe developers. I don't know COBOL enough to be able to see if their Granite models are particularly strong in this area, though.&lt;/p&gt;
    &lt;p&gt;Whilst I agree with your point, I think what sometimes gets lost in these conversations is that reviewing code thoroughly is harder than writing code.&lt;/p&gt;
    &lt;p&gt;Personally, and I’m not trying to speak for everyone here, I found it took me just as long to review AI output as it would have taken to write that code myself.&lt;/p&gt;
    &lt;p&gt;There have been some exceptions to that rule. But those exceptions have generally been in domains I’m unfamiliar with. So we are back to trusting AI as a research assistant, if not a “vibe coding” assistant.&lt;/p&gt;
    &lt;p&gt;&amp;gt; as long to review AI output as it would have taken to write that code myself&lt;/p&gt;
    &lt;p&gt;That is often the case.&lt;/p&gt;
    &lt;p&gt;What immensely helps though is that AI gets me past writer's block. Then I have to rewrite all the slop, but hey, it's rewrite and that's much easier to get in that zone and streamline the work. Sometimes I produce more code per day rewriting AI slop than writing it from scratch myself.&lt;/p&gt;
    &lt;p&gt;The good news here is that their code is of such a poor quality it doesn't properly work anyway.&lt;/p&gt;
    &lt;p&gt;I have recently tried to blindly create a small .dylib consolidation tool in JS using Claude Code, Opus 4.5 and AskUserTool to create a detailed spec. My god how awful and broken the code was. Unusable. But it faked* working just good enough to pass someone who's got no clue.&lt;/p&gt;
    &lt;p&gt;&amp;gt; The good news here is that their code is of such a poor quality it doesn't properly work anyway.&lt;/p&gt;
    &lt;p&gt;This is just wishful thinking. In reality it works just well enough to be dangerous. Just look at the latest RCE in OpenCode. The AI it was vibe-coded with allowed any website with origin * to execute code, and the Prompt Engineer™ didn't understand the implications.&lt;/p&gt;
    &lt;p&gt;I'm watching the voters around the world electing charismatic leaders and then cheering the consequences.&lt;/p&gt;
    &lt;p&gt;Thus companies electing to replace software developers with AI slop are not of a much surprise to me.&lt;/p&gt;
    &lt;p&gt;It doesn't matter whether people will die because of AI slop. What matters is keeping Microsoft shareholders happy and they are only happy when there is a growing demand for slop.&lt;/p&gt;
    &lt;p&gt;That is my preferred way to use it also, though I see many folks seemingly pushing for pure vibe coding, apparently striving for maximum throughput as a high-priority goal. Which goal would be hindered by careful review of the output.&lt;/p&gt;
    &lt;p&gt;It's unclear to me why most software projects would need to grow by tens (or hundreds) of thousands of lines of code each day, but I guess that's a thing?&lt;/p&gt;
    &lt;p&gt;This should be "especially in tests". It's more important that they work than the actual code, because their purpose is to catch when the rest of the code breaks.&lt;/p&gt;
    &lt;p&gt;Because the question almost always comes with an undertone of “Can this replace me?”. If it’s just code search, debugging, the answer’s no because a non-developer won’t have the skills or experience to put it all together.&lt;/p&gt;
    &lt;p&gt;That undertone is overt in the statements of CEOs and managers who salivate at “reducing headcount.”&lt;/p&gt;
    &lt;p&gt;The people who should fear AI the most right now are the offshore shops. They’re the most replaceable because the only reason they exist is the desire to carve off low skill work and do it cheaply.&lt;/p&gt;
    &lt;p&gt;But all of this overblown anyway because I don’t see appetite for new software getting satiated anytime soon, even if we made everyone 2x productive.&lt;/p&gt;
    &lt;p&gt;No, it doesn't. For example, you could use an AI agent just to aid you in code search and understanding or for filling out well specified functions which you then do QA on.&lt;/p&gt;
    &lt;p&gt;To do quality QA/code review, one of course needs to understand the design decisions/motivations/intentions (why those exact code lines were added, and why they are correct), meaning it is the same job as one would originally code those lines and building the understanding==quality on the way.&lt;/p&gt;
    &lt;p&gt;For the terminology, I consider "vibe-coding" as Claude etc. coding agents that sculpts entire blocks of code based on prompts. My use-tactic for LLM/AI-coding is to just get the signature/example of some functions that I need (because documents usually suck), and then coding it myself. That way the control/understanding is more (and very egoistically) in my hands/head, than in LLMs. I don't know what kind of projects you do, but many times the magic of LLMs ends, and the discussion just starts to go same incorrect circle when reflected on reality. At that point I need to return to use classic human intelligence.&lt;/p&gt;
    &lt;p&gt;And for COBOL + AI, in my experience mentioning "COBOL" means that there is usually DB + UI/APP/API/BATCHJOB for interacting with it. And the DB schema + semantics is propably the most critical to understand here, because it totally defines the operations/bizlogic/interpretations for it. So any "AI" would also need to understand your DB (semantically) fully to not make any mistakes.&lt;/p&gt;
    &lt;p&gt;But in any case, someone needs to be responsible for the committed code, because only personified human blame and guilt can eventually avert/minimize sloppiness.&lt;/p&gt;
    &lt;p&gt;You 100% can use it this way. But it takes a lot of discipline to keep the slop out of the code base. The same way it took discipline to keep human slop out.&lt;/p&gt;
    &lt;p&gt;There has always been a class of devs who throw things at the wall and see what sticks. They copy paste from other parts of the application, or from stack overflow. They write half assed tests or no tests at all and they try their best to push it thought the review process with pleas about how urgent it is (there are developers on the opposite side of this spectrum who are also bad).&lt;/p&gt;
    &lt;p&gt;The new problem is that this class of developer is the exact kind of developer who AI speeds up the most, and they are the most experienced at getting shit code through review.&lt;/p&gt;
    &lt;p&gt;As others have said, US banks seem to run a lot of it, as in they have millions of lines of code of it.&lt;/p&gt;
    &lt;p&gt;This is not saying that banks don't also have a metric shitload of Java, they do. I think most people would be surprised how much code your average large bank manages.&lt;/p&gt;
    &lt;p&gt;In the US, there are several thousands of banks and credit unions, and the smaller ones use a patchwork of different vendor software. They likely don't have to write COBOL directly, but some of those components are still running it.&lt;/p&gt;
    &lt;p&gt;From the vendor's perspective, it doesn't make sense to do a complete rewrite and risk creating hairy financial issues for potentially hundreds of clients.&lt;/p&gt;
    &lt;p&gt;I wonder if the OP's question is motivated by there being less public examples of COBOL code to train LLM's on compared to newer languages (so a different experience is expected), or something else. If the prior, it'd be interesting to see if having a language spec and a few examples leads to even better results from an LLM, since less examples could also mean less bad examples that deviate from the spec :) if there are any dev's that use AI with COBOL and other more common languages, please share your comparative experience&lt;/p&gt;
    &lt;p&gt;Most COBOL I know of won't ever see the light of day.&lt;/p&gt;
    &lt;p&gt;Also COBOL seems to have a lot of flavors that are used by a few financial institutions. Since these are highly proprietary it seems very unlikely LLMs would be trained on them, and therefore the LLM would not be any use to the bank.&lt;/p&gt;
    &lt;p&gt;Not a COBOL dev, but I work on migrating projects from COBOL mainframes to Java.&lt;/p&gt;
    &lt;p&gt;Generally speaking any kind of AI is relatively hit or miss. We have a statically generated knowledge base of the migrated sourcecode that can be used as context for LLMs to work with, but even that is often not enough to do anything meaningful.&lt;/p&gt;
    &lt;p&gt;At times Opus 4.5 is able to debug small errors in COBOL modules given a stacktrace and enough hand-holding. Other models are decent at explaining semi-obscure COBOL patterns or at guessing what a module could be doing just given the name and location -- but more often than not they end up just being confidently wrong.&lt;/p&gt;
    &lt;p&gt;I think the best use-case we have so far is business rule extraction - aka understanding what a module is trying to achieve without getting too much into details.&lt;/p&gt;
    &lt;p&gt;The TLDR, at least in our case, is that without any supporting RAGs/finetuning/etc all kind of AI works "just ok" and isn't such a big deal (yet)&lt;/p&gt;
    &lt;p&gt;If I were using something like Claude Code to build a COBOL project, I'd structure the scaffolding to break problems into two phases: first, reason through the design from a purely theoretical perspective, weighing implementation tradeoffs; second, reference COBOL documentation and discuss how to make the solution as idiomatic as possible.&lt;/p&gt;
    &lt;p&gt;Disclaimer: I've never written a single line of COBOL. That said, I'm a programming language enthusiast who has shipped production code in FORTRAN, C, C++, Java, Scala, Clojure, JavaScript, TypeScript, Python, and probably others I'm forgetting.&lt;/p&gt;
    &lt;p&gt;You may want to give free opensource GnuCOBOL a try. Works on Mac/Linux/Windows. As far as AI and Cobol, I do think Claude Opus 4.5 is getting pretty good. But like stated way above, verify and understand Every line it delivers to you.&lt;/p&gt;
    &lt;p&gt;I am in banking and it's fine we have some finetuned models to work with our code base. I think COBOL is a good language for LLM use. It's verbose and English like syntax aligns naturally with the way language models process text. Can't complain.&lt;/p&gt;
    &lt;p&gt;Can you elaborate? See questions about what kind of use in sibling thread.&lt;/p&gt;
    &lt;p&gt;And in addition to the type of development you are doing in COBOL, I'm wondering if you also have used LLMs to port existing code to (say) Java, C# or whatever is current in (presumably) banking?&lt;/p&gt;
    &lt;p&gt;This is implied but I guess needs to be made explicit: people are looking for answers from devs with direct knowledge of the question at hand, not what random devs suspect.&lt;/p&gt;
    &lt;p&gt;Very little. A lot of Fortran today is converting old Fortran to Python+Numpy or Matlab. I've tried Claude and Copilot and it's pretty sketchy on this. I do use it for "print" statement formatting, etc.&lt;/p&gt;
    &lt;p&gt;Given the mass of code out there, it strikes me it's only a matter of time before someone fine tunes one of the larger more competent coding models on COBOL. If they haven't already.&lt;/p&gt;
    &lt;p&gt;Personally I've had a lot of luck Opus etc with "odd" languages just making sure that the prompt is heavily tuned to describe best practices and reinforce descriptions of differences with "similar" languages. A few months ago with Sonnet 4, etc. this was dicey. Now I can run Opus 4.5 on my own rather bespoke language and get mostly excellent output. Especially when it has good tooling for verification, and reference documentation available.&lt;/p&gt;
    &lt;p&gt;The downside is you use quite a bit of tokens doing this. Which is where I think fine tuning could help.&lt;/p&gt;
    &lt;p&gt;I bet one of the larger airlines or banks could dump some cash over to Anthropic etc to produce a custom trained model using a corpus of banking etc software, along with tools around the backend systems and so on. Worthwhile investment.&lt;/p&gt;
    &lt;p&gt;In any case I can't see how this would be a threat to people who work in those domains. They'd be absolutely invaluable to understand and apply and review and improve the output. I can imagine it making their jobs 10x more pleasant though.&lt;/p&gt;
    &lt;p&gt;Which COBOL... This is a particular issue in COBOL is it's a much more fragmented language than most people outside the industry would expect. While a model would be useful for the company that supplied the data, the amount of transference may be more limited than one would expect.&lt;/p&gt;
    &lt;p&gt;I've seen songs on spottily called "anything" and "Just play anything", so I guess it may be worthwhile if I change my name to "anyone" for when someone asks their LLM to "just hire anyone"&lt;/p&gt;
    &lt;p&gt;I see it as a complete opposite for sure, I will tell you why.&lt;/p&gt;
    &lt;p&gt;it could have been a threat if it was something you cannot control, but you can control it, you can learn to control it, and controlling it in the right direction would enable anyone to actually secure your position or even advance it.&lt;/p&gt;
    &lt;p&gt;And, about the COBOL, well i dont know what the heck this is.&lt;/p&gt;
    &lt;p&gt;This is amazing! Thank you for confirming what I've been suspecting for a while now. People that actually know very little about software development now believe they don't need to know anything about it, and they are commenting very confidently here on hn.&lt;/p&gt;
    &lt;p&gt;The point about the mass of code running the economy being untouched by AI agents is so real. During my years as a developer, I've often faced the skepticism surrounding automation technologies, especially when it comes to legacy languages like COBOL. There’s a perception that as AI becomes more capable, it might threaten specialized roles. However, I believe that the intricacies and context of legacy systems often require human insight that AI has yet to master fully.&lt;/p&gt;
    &lt;p&gt;Compiling high level languages to assembly is a deterministic procedure. You write a program using a small well defined language (relative to natural language every programming language is tiny and extremely well defined). The same input to the same compiler will get you the same output every time. LLMs are nothing like a compiler.&lt;/p&gt;
    &lt;p&gt;Is there any compiler that "rolls the dice" when it comes to optimizations? Like, if you compile the exact same code with the exact same compiler multiple times you'll get different assembly?&lt;/p&gt;
    &lt;p&gt;And th Alan Kay quote is great but does not apply here at all? I'm pointing out how silly it is to compare LLMs to compilers. That's all.&lt;/p&gt;
    &lt;p&gt;Rolling the dice is accomplished by mixing optimizations flags, PGO data and what parts of the CPU get used.&lt;/p&gt;
    &lt;p&gt;Or by using a managed language with dynamic compiler (aka JIT) and GC. They are also not deterministic when executed, and what outcome gets produced, it is all based on heuristics and measured probabilities.&lt;/p&gt;
    &lt;p&gt;Yes, the quote does apply because many cannot grasp the idea of how technology looks beyond today.&lt;/p&gt;
    &lt;p&gt;But the compiler doesn't "roll the dice" when making those guesses! Compile the same code with the same compiler and you get the same result repeatedly.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46678550"/><published>2026-01-19T13:05:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46679872</id><title>GLM-4.7-Flash</title><updated>2026-01-19T19:36:56.725858+00:00</updated><content>&lt;doc fingerprint="d7e20a53e8bbbac0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GLM-4.7-Flash&lt;/head&gt;
    &lt;p&gt; 👋 Join our Discord community. &lt;lb/&gt; 📖 Check out the GLM-4.7 technical blog, technical report(GLM-4.5). &lt;lb/&gt; 📍 Use GLM-4.7-Flash API services on Z.ai API Platform. &lt;lb/&gt; 👉 One click to GLM-4.7. &lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;GLM-4.7-Flash is a 30B-A3B MoE model. As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performances on Benchmarks&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Benchmark&lt;/cell&gt;
        &lt;cell role="head"&gt;GLM-4.7-Flash&lt;/cell&gt;
        &lt;cell role="head"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-OSS-20B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;AIME 25&lt;/cell&gt;
        &lt;cell&gt;91.6&lt;/cell&gt;
        &lt;cell&gt;85.0&lt;/cell&gt;
        &lt;cell&gt;91.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GPQA&lt;/cell&gt;
        &lt;cell&gt;75.2&lt;/cell&gt;
        &lt;cell&gt;73.4&lt;/cell&gt;
        &lt;cell&gt;71.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;LCB v6&lt;/cell&gt;
        &lt;cell&gt;64.0&lt;/cell&gt;
        &lt;cell&gt;66.0&lt;/cell&gt;
        &lt;cell&gt;61.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;HLE&lt;/cell&gt;
        &lt;cell&gt;14.4&lt;/cell&gt;
        &lt;cell&gt;9.8&lt;/cell&gt;
        &lt;cell&gt;10.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SWE-bench Verified&lt;/cell&gt;
        &lt;cell&gt;59.2&lt;/cell&gt;
        &lt;cell&gt;22.0&lt;/cell&gt;
        &lt;cell&gt;34.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;τ²-Bench&lt;/cell&gt;
        &lt;cell&gt;79.5&lt;/cell&gt;
        &lt;cell&gt;49.0&lt;/cell&gt;
        &lt;cell&gt;47.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;BrowseComp&lt;/cell&gt;
        &lt;cell&gt;42.8&lt;/cell&gt;
        &lt;cell&gt;2.29&lt;/cell&gt;
        &lt;cell&gt;28.3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Serve GLM-4.7-Flash Locally&lt;/head&gt;
    &lt;p&gt;For local deployment, GLM-4.7-Flash supports inference frameworks including vLLM and SGLang. Comprehensive deployment instructions are available in the official Github repository.&lt;/p&gt;
    &lt;p&gt;vLLM and SGLang only support GLM-4.7-Flash on their main branches.&lt;/p&gt;
    &lt;head rend="h3"&gt;vLLM&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;using pip (must use pypi.org as the index url):&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install -U vllm --pre --index-url https://pypi.org/simple --extra-index-url https://wheels.vllm.ai/nightly
pip install git+https://github.com/huggingface/transformers.git
&lt;/code&gt;
    &lt;head rend="h3"&gt;SGLang&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;using pip install sglang from source, then update transformers to the latest main branch.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;transformers&lt;/head&gt;
    &lt;p&gt;using with transformers as&lt;/p&gt;
    &lt;code&gt;pip install git+https://github.com/huggingface/transformers.git
&lt;/code&gt;
    &lt;p&gt;and then run:&lt;/p&gt;
    &lt;code&gt;import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

MODEL_PATH = "zai-org/GLM-4.7-Flash"
messages = [{"role": "user", "content": "hello"}]
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
inputs = tokenizer.apply_chat_template(
    messages,
    tokenize=True,
    add_generation_prompt=True,
    return_dict=True,
    return_tensors="pt",
)
model = AutoModelForCausalLM.from_pretrained(
    pretrained_model_name_or_path=MODEL_PATH,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)
inputs = inputs.to(model.device)
generated_ids = model.generate(**inputs, max_new_tokens=128, do_sample=False)
output_text = tokenizer.decode(generated_ids[0][inputs.input_ids.shape[1]:])
print(output_text)
&lt;/code&gt;
    &lt;head rend="h3"&gt;vLLM&lt;/head&gt;
    &lt;code&gt;vllm serve zai-org/GLM-4.7-Flash \
     --tensor-parallel-size 4 \
     --speculative-config.method mtp \
     --speculative-config.num_speculative_tokens 1 \
     --tool-call-parser glm47 \
     --reasoning-parser glm45 \
     --enable-auto-tool-choice \
     --served-model-name glm-4.7-flash
&lt;/code&gt;
    &lt;head rend="h3"&gt;SGLang&lt;/head&gt;
    &lt;code&gt;python3 -m sglang.launch_server \
  --model-path zai-org/GLM-4.7-Flash \
  --tp-size 4 \
  --tool-call-parser glm47  \
  --reasoning-parser glm45 \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3 \
  --speculative-eagle-topk 1 \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.8 \
  --served-model-name glm-4.7-flash \
  --host 0.0.0.0 \
  --port 8000
&lt;/code&gt;
    &lt;head rend="h2"&gt;Citation&lt;/head&gt;
    &lt;p&gt;If you find our work useful in your research, please consider citing the following paper:&lt;/p&gt;
    &lt;code&gt;@misc{5team2025glm45agenticreasoningcoding,
      title={GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models}, 
      author={GLM Team and Aohan Zeng and Xin Lv and Qinkai Zheng and Zhenyu Hou and Bin Chen and Chengxing Xie and Cunxiang Wang and Da Yin and Hao Zeng and Jiajie Zhang and Kedong Wang and Lucen Zhong and Mingdao Liu and Rui Lu and Shulin Cao and Xiaohan Zhang and Xuancheng Huang and Yao Wei and Yean Cheng and Yifan An and Yilin Niu and Yuanhao Wen and Yushi Bai and Zhengxiao Du and Zihan Wang and Zilin Zhu and Bohan Zhang and Bosi Wen and Bowen Wu and Bowen Xu and Can Huang and Casey Zhao and Changpeng Cai and Chao Yu and Chen Li and Chendi Ge and Chenghua Huang and Chenhui Zhang and Chenxi Xu and Chenzheng Zhu and Chuang Li and Congfeng Yin and Daoyan Lin and Dayong Yang and Dazhi Jiang and Ding Ai and Erle Zhu and Fei Wang and Gengzheng Pan and Guo Wang and Hailong Sun and Haitao Li and Haiyang Li and Haiyi Hu and Hanyu Zhang and Hao Peng and Hao Tai and Haoke Zhang and Haoran Wang and Haoyu Yang and He Liu and He Zhao and Hongwei Liu and Hongxi Yan and Huan Liu and Huilong Chen and Ji Li and Jiajing Zhao and Jiamin Ren and Jian Jiao and Jiani Zhao and Jianyang Yan and Jiaqi Wang and Jiayi Gui and Jiayue Zhao and Jie Liu and Jijie Li and Jing Li and Jing Lu and Jingsen Wang and Jingwei Yuan and Jingxuan Li and Jingzhao Du and Jinhua Du and Jinxin Liu and Junkai Zhi and Junli Gao and Ke Wang and Lekang Yang and Liang Xu and Lin Fan and Lindong Wu and Lintao Ding and Lu Wang and Man Zhang and Minghao Li and Minghuan Xu and Mingming Zhao and Mingshu Zhai and Pengfan Du and Qian Dong and Shangde Lei and Shangqing Tu and Shangtong Yang and Shaoyou Lu and Shijie Li and Shuang Li and Shuang-Li and Shuxun Yang and Sibo Yi and Tianshu Yu and Wei Tian and Weihan Wang and Wenbo Yu and Weng Lam Tam and Wenjie Liang and Wentao Liu and Xiao Wang and Xiaohan Jia and Xiaotao Gu and Xiaoying Ling and Xin Wang and Xing Fan and Xingru Pan and Xinyuan Zhang and Xinze Zhang and Xiuqing Fu and Xunkai Zhang and Yabo Xu and Yandong Wu and Yida Lu and Yidong Wang and Yilin Zhou and Yiming Pan and Ying Zhang and Yingli Wang and Yingru Li and Yinpei Su and Yipeng Geng and Yitong Zhu and Yongkun Yang and Yuhang Li and Yuhao Wu and Yujiang Li and Yunan Liu and Yunqing Wang and Yuntao Li and Yuxuan Zhang and Zezhen Liu and Zhen Yang and Zhengda Zhou and Zhongpei Qiao and Zhuoer Feng and Zhuorui Liu and Zichen Zhang and Zihan Wang and Zijun Yao and Zikang Wang and Ziqiang Liu and Ziwei Chai and Zixuan Li and Zuodong Zhao and Wenguang Chen and Jidong Zhai and Bin Xu and Minlie Huang and Hongning Wang and Juanzi Li and Yuxiao Dong and Jie Tang},
      year={2025},
      eprint={2508.06471},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.06471}, 
}
&lt;/code&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Downloads last month&lt;/item&gt;
      &lt;item rend="dd-1"&gt;-&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://huggingface.co/zai-org/GLM-4.7-Flash"/><published>2026-01-19T15:12:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46679896</id><title>"Anyone else out there vibe circuit-building?"</title><updated>2026-01-19T19:36:56.357521+00:00</updated><content>&lt;doc fingerprint="d635e49f34142863"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2026 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/beneater/status/2012988790709928305"/><published>2026-01-19T15:14:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46679907</id><title>CSS Web Components for marketing sites (2024)</title><updated>2026-01-19T19:36:55.910320+00:00</updated><content>&lt;doc fingerprint="3c99d21129d173e3"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;CSS Web Components for marketing sites&lt;/head&gt;&lt;p&gt;November 4, 2024 – @hawkticehurst&lt;/p&gt;&lt;p&gt;Hot take: I think “regular” web components (the ones with Shadow DOM and friends) are a terrible solution for marketing website design systems.&lt;/p&gt;&lt;p&gt;It has always left a bad taste in my mouth when I run across a web component for a swimlane, banner, card, and so on. Why? Because these are components that (unless you’re doing something mighty fancy) should never require JavaScript as a dependency.&lt;/p&gt;&lt;p&gt;But, in the world of web components you are locked into JavaScript from the very start. To even register a web component with the browser you need JavaScript.&lt;/p&gt;&lt;p&gt;But what if… we didn’t do that?&lt;/p&gt;&lt;head rend="h2"&gt;HTML Web Components&lt;/head&gt;&lt;p&gt;I’ve spent a good chunk of the last year focused on marketing site design systems at work. A regular topic of discussion is the need to build marketing sites that are accessible to folks with lower powered devices and poor internet connections. How do you achieve that? In short, use less JavaScript and ideally build UI with progressive enhancement in mind.&lt;/p&gt;&lt;p&gt;There are many ways to achieve these goals, but the method I’ve been focused on is how an HTML Web Component archictecture might be applied to implement a marketing site design system.&lt;/p&gt;&lt;p&gt;As a quick reminder/intro, HTML Web Components is a method of building web components where you write HTML as you would normally and then wrap the parts you want to be interactive using a custom element.&lt;/p&gt;&lt;p&gt;For example, if you wanted to create a counter button it would look like this:&lt;/p&gt;&lt;code&gt;&amp;lt;counter-button&amp;gt;
  &amp;lt;button&amp;gt;Count is &amp;lt;span&amp;gt;0&amp;lt;/span&amp;gt;&amp;lt;/button&amp;gt;
&amp;lt;/counter-button&amp;gt;

&amp;lt;style&amp;gt;
  counter-button button {
    /* Counter button styles */
  }
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
  class Counter extends HTMLElement {
    // Counter button behavior
  }
  customElements.define("counter-button", Counter);
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;p&gt;The markup in an HTML web component is parsed, rendered, and styled as normal HTML. That HTML will then be seamlessly hydrated once the JavaScript associated with the custom element tag is executed.&lt;/p&gt;&lt;p&gt;In contrast, the markup of a "regular" web component (that uses Shadow DOM) is dynamically generated at runtime using JavaScript -- kind of like an SPA.&lt;/p&gt;&lt;p&gt;This component architecture is a really strong candidate for a marketing design system (and, as a bonus, avoids some of the big gotchas that come with regular web components).&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;It is a perfect implementation of progressively enhanced UI&lt;/item&gt;&lt;item&gt;It uses minimal and self-contained JavaScript — HTML Web Components can be thought of as islands&lt;/item&gt;&lt;item&gt;You still get the power of custom element APIs to implement stuff like design system component variants&lt;/item&gt;&lt;item&gt;The component markup is fully SSR-able&lt;/item&gt;&lt;item&gt;The component markup can be styled like regular HTML&lt;/item&gt;&lt;item&gt;Common accessibility practices can be applied without issue&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But for all these benefits we’re still left with the original problem. HTML Web Components require JavaScript.&lt;/p&gt;&lt;head rend="h2"&gt;CSS Web Components&lt;/head&gt;&lt;p&gt;So here’s the question: What would happen if we took the ideas of HTML Web Components and skipped all the JavaScript?&lt;/p&gt;&lt;p&gt;You get CSS Web Components.&lt;/p&gt;&lt;p&gt;Note: I've never seen anyone talk about or name this concept before, so I'm using "CSS Web Components" to describe the idea. But please let me know if someone has already written about and named this!&lt;/p&gt;&lt;p&gt;How do they work? The exact same as HTML Web Components but you just take advantage of the powers of CSS to implement key functionality.&lt;/p&gt;&lt;p&gt;As an example let’s implement that swimlane component:&lt;/p&gt;&lt;code&gt;&amp;lt;swim-lane&amp;gt;
  &amp;lt;section&amp;gt;
    &amp;lt;h2&amp;gt;Creativity unleashed&amp;lt;/h2&amp;gt;
    &amp;lt;p&amp;gt;A brand new way of illustrating for the web.&amp;lt;/p&amp;gt;
    &amp;lt;a href="/product"&amp;gt;Learn more&amp;lt;/a&amp;gt;
  &amp;lt;/section&amp;gt;
  &amp;lt;img src="product.jpg" alt="Product image" /&amp;gt;
&amp;lt;/swim-lane&amp;gt;

&amp;lt;style&amp;gt;
  swim-lane {
    display: flex;
    align-items: center;
    gap: 2rem;
    color: white;
    background: black;
    padding: 1rem;
    border-radius: 16px;
  }
  swim-lane h2 {
    /* Swimlane title styles */
  }
  swim-lane p {
    /* Swimlane description styles */
  }
  swim-lane a {
    /* Swimlane link styles */
  }
  @media (max-width: 650px) {
    /* Mobile responsive styles */
  }
&amp;lt;/style&amp;gt;&lt;/code&gt;&lt;head rend="h2"&gt;Creativity unleashed&lt;/head&gt;&lt;p&gt;A brand new way of illustrating for the web.&lt;/p&gt;Learn more&lt;p&gt;Okay great, we styled some HTML nested inside a custom element. There’s nothing too novel about that. But what about adding some functionality? Say, a component variant that lets you reverse the layout of the swimlane?&lt;/p&gt;&lt;p&gt;It’s possible using only CSS! Specifically, CSS attribute selectors.&lt;/p&gt;&lt;code&gt;&amp;lt;swim-lane layout="reverse"&amp;gt;
  &amp;lt;section&amp;gt;
    &amp;lt;h2&amp;gt;Creativity unleashed&amp;lt;/h2&amp;gt;
    &amp;lt;p&amp;gt;A brand new way of illustrating for the web.&amp;lt;/p&amp;gt;
    &amp;lt;a href="/product"&amp;gt;Learn more&amp;lt;/a&amp;gt;
  &amp;lt;/section&amp;gt;
  &amp;lt;img src="product.jpg" alt="Product image" /&amp;gt;
&amp;lt;/swim-lane&amp;gt;

&amp;lt;style&amp;gt;
  /* Other swimlane styles */
  swim-lane[layout="reverse"] {
    flex-direction: row-reverse;
  }
  @media (max-width: 650px) {
    swim-lane[layout="reverse"] {
      flex-direction: column-reverse;
    }
  }
&amp;lt;/style&amp;gt;&lt;/code&gt;
&lt;head rend="h2"&gt;Creativity unleashed&lt;/head&gt;&lt;p&gt;A brand new way of illustrating for the web.&lt;/p&gt;Learn more&lt;p&gt;Another really cool perk of this is that because you’re defining an attribute on a custom element you don’t have to worry about naming collisions with HTML attributes. No need to add &lt;code&gt;data-&lt;/code&gt; to the beginning of attributes like you would/should on normal HTML elements.&lt;/p&gt;&lt;head rend="h2"&gt;How far does this go?&lt;/head&gt;&lt;p&gt;In theory, I believe this method of building design systems can go quite far. If you think about it, the vast majority of basic components you might need in a marketing design system are just vanilla HTML elements with specific style variations.&lt;/p&gt;&lt;p&gt;A marketing website button is just an anchor tag wrapped in a &lt;code&gt;&amp;lt;link-button&amp;gt;&lt;/code&gt; custom element and styled using custom attribute selectors.&lt;/p&gt;&lt;code&gt;&amp;lt;link-button&amp;gt;
  &amp;lt;a href=""&amp;gt;Learn more&amp;lt;/a&amp;gt;
&amp;lt;/link-button&amp;gt;
&amp;lt;link-button variant="secondary"&amp;gt;
  &amp;lt;a href=""&amp;gt;Learn more&amp;lt;/a&amp;gt;
&amp;lt;/link-button&amp;gt;
&amp;lt;link-button pill&amp;gt;
  &amp;lt;a href=""&amp;gt;Learn more&amp;lt;/a&amp;gt;
&amp;lt;/link-button&amp;gt;
&amp;lt;link-button size="large"&amp;gt;
  &amp;lt;a href=""&amp;gt;Learn more&amp;lt;/a&amp;gt;
&amp;lt;/link-button&amp;gt;

&amp;lt;style&amp;gt;
  link-button a {
    /* Default link button styles */
  }
  link-button[variant="secondary"] a {
    background: transparent;
    color: white;
  }
  link-button[pill] a {
    border-radius: 50px;
  }
  link-button[size="large"] a {
    padding: 10px 20px;
    font-size: 1.25rem;
  }
&amp;lt;/style&amp;gt;&lt;/code&gt;
&lt;p&gt;From here, imagine incorporating all the other powers that CSS (and HTML) bring to the table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Cascade layers for better control of how styles get applied&lt;/item&gt;&lt;item&gt;Container queries for conditional style variants based on a parent container&lt;/item&gt;&lt;item&gt;:has(), :is(), and :where() to simplify complex selectors&lt;/item&gt;&lt;item&gt;CSS variables for theming&lt;/item&gt;&lt;item&gt;@property rule for even more powerful CSS variables&lt;/item&gt;&lt;item&gt;light-dark() for system aware theming&lt;/item&gt;&lt;item&gt;Popover API for menus, toggletips, and dialogs without JS&lt;/item&gt;&lt;item&gt;Exclusive accordions for FAQ sections&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The possibilities are quite large.&lt;/p&gt;&lt;p&gt;What do you think?&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hawkticehurst.com/2024/11/css-web-components-for-marketing-sites/"/><published>2026-01-19T15:15:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46680515</id><title>The Microstructure of Wealth Transfer in Prediction Markets</title><updated>2026-01-19T19:36:54.900326+00:00</updated><content>&lt;doc fingerprint="62a51bb953b04300"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Microstructure of Wealth Transfer in Prediction Markets&lt;/head&gt;
    &lt;p&gt;Slot machines on the Las Vegas Strip return about 93 cents on the dollar. This is widely considered some of the worst odds in gambling. Yet on Kalshi, a CFTC-regulated prediction market, traders have wagered vast sums on longshot contracts with historical returns as low as 43 cents on the dollar. Thousands of participants are voluntarily accepting expected values far lower than a casino slot machine to bet on their convictions.&lt;/p&gt;
    &lt;p&gt;The efficient market hypothesis suggests that asset prices should perfectly aggregate all available information. Prediction markets theoretically provide the purest test of this theory. Unlike equities, there is no ambiguity about intrinsic value. A contract either pays $1 or it does not. A price of 5 cents should imply exactly a 5% probability.&lt;/p&gt;
    &lt;p&gt;We analyzed 72.1 million trades covering $18.26 billion in volume to test this efficiency. Our findings suggest that collective accuracy relies less on rational actors than on a mechanism for harvesting error. We document a systematic wealth transfer where impulsive Takers pay a structural premium for affirmative "YES" outcomes while Makers capture an "Optimism Tax" simply by selling into this biased flow. The effect is strongest in high-engagement categories like Sports and Entertainment, while low-engagement categories like Finance approach perfect efficiency.&lt;/p&gt;
    &lt;p&gt;This paper makes three contributions. First, it confirms the presence of the longshot bias on Kalshi and quantifies its magnitude across price levels. Second, it decomposes returns by market role, revealing a persistent wealth transfer from takers to makers driven by asymmetric order flow. Third, it identifies a YES/NO asymmetry where takers disproportionately favor affirmative bets at longshot prices, exacerbating their losses.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prediction Markets and Kalshi&lt;/head&gt;
    &lt;p&gt;Prediction markets are exchanges where participants trade binary contracts on real-world outcomes. These contracts settle at either $1 or $0, with prices ranging from 1 to 99 cents serving as probability proxies. Unlike equity markets, prediction markets are strictly zero-sum: every dollar of profit corresponds exactly to a dollar of loss.&lt;/p&gt;
    &lt;p&gt;Kalshi launched in 2021 as the first U.S. prediction market regulated by the CFTC. Initially focused on economic and weather data, the platform stayed niche until 2024. A legal victory over the CFTC secured the right to list political contracts, and the 2024 election cycle triggered explosive growth. Sports markets, introduced in 2025, now dominate trading activity.&lt;/p&gt;
    &lt;p&gt;Volume distribution across categories is highly uneven. Sports accounts for 72% of notional volume, followed by politics at 13% and crypto at 5%.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: Data collection concluded on 2025-11-25 at 17:00 ET; Q4 2025 figures are incomplete.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Data and Methodology&lt;/head&gt;
    &lt;p&gt;The dataset, available on GitHub, contains 7.68 million markets and 72.1 million trades. Each trade records the execution price (1-99 cents), taker side (yes/no), contract count, and timestamp. Markets include resolution outcome and category classification.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Role assignment: Each trade identifies the liquidity taker. The maker took the opposite position. If&lt;/p&gt;&lt;code&gt;taker_side = yes&lt;/code&gt;at 10 cents, the taker bought YES at 10¢; the maker bought NO at 90¢.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cost Basis (): To compare asymmetries between YES and NO contracts, we normalize all trades by capital risked. For a standard YES trade at 5 cents, . For a NO trade at 5 cents, . All references to "Price" in this paper refer to this Cost Basis unless otherwise noted.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mispricing () measures the divergence between actual win rate and implied probability for a subset of trades :&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gross Excess return () is the return relative to cost, gross of platform fees, where is price in cents and is the outcome:&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Sample&lt;/head&gt;
    &lt;p&gt;Calculations derive from resolved markets only. Markets that were voided, delisted, or remain open are excluded. Additionally, trades from markets with less than $100 in notional volume were excluded. The dataset remains robust across all price levels; the sparsest bin (81-90¢) contains 5.8 million trades.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Longshot Bias on Kalshi&lt;/head&gt;
    &lt;p&gt;First documented by Griffith (1949) in horse racing and later formalized by Thaler &amp;amp; Ziemba (1988) in their analysis of parimutuel betting markets, the longshot bias describes the tendency for bettors to overpay for low-probability outcomes. In efficient markets, a contract priced at cents should win approximately % of the time. In markets exhibiting longshot bias, low-priced contracts win less than their implied probability, while high-priced contracts win more.&lt;/p&gt;
    &lt;p&gt;The data confirms this pattern on Kalshi. Contracts trading at 5 cents win only 4.18% of the time, implying mispricing of -16.36%. Conversely, contracts at 95 cents win 95.83% of the time. This pattern is consistent; all contracts priced below 20 cents underperform their odds, while those above 80 cents outperform.&lt;/p&gt;
    &lt;p&gt;The existence of the longshot bias raises a question unique to zero-sum markets: if some traders systematically overpay, who captures the surplus?&lt;/p&gt;
    &lt;head rend="h2"&gt;The Maker-Taker Wealth Transfer&lt;/head&gt;
    &lt;head rend="h3"&gt;Decomposing Returns by Role&lt;/head&gt;
    &lt;p&gt;Market microstructure defines two populations based on their interaction with the order book. A Maker provides liquidity by placing limit orders that rest on the book. A Taker consumes this liquidity by executing against resting orders.&lt;/p&gt;
    &lt;p&gt;Decomposing aggregate returns by role reveals a stark asymmetry:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Role&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg. Excess Return&lt;/cell&gt;
        &lt;cell role="head"&gt;95% CI&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Taker&lt;/cell&gt;
        &lt;cell&gt;-1.12%&lt;/cell&gt;
        &lt;cell&gt;[-1.13%, -1.11%]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Maker&lt;/cell&gt;
        &lt;cell&gt;+1.12%&lt;/cell&gt;
        &lt;cell&gt;[+1.11%, +1.13%]&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The divergence is most pronounced at the tails. At 1-cent contracts, takers win only 0.43% of the time against an implied probability of 1%, corresponding to a mispricing of -57%. Makers on the same contracts win 1.57% of the time, resulting in a mispricing of +57%. At 50 cents, mispricing compresses; takers show -2.65%, and makers show +2.66%.&lt;/p&gt;
    &lt;p&gt;Takers exhibit negative excess returns at 80 of 99 price levels. Makers exhibit positive excess returns at the same 80 levels. The market's aggregate miscalibration is concentrated in a specific population; takers bear the losses while makers capture the gains.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is This Just Spread Compensation?&lt;/head&gt;
    &lt;p&gt;An obvious objection arises; makers earn the bid-ask spread as compensation for providing liquidity. Their positive returns may simply reflect spread capture rather than the exploitation of biased flow. While plausible, two observations suggest otherwise.&lt;/p&gt;
    &lt;p&gt;The first observation suggests the effect extends beyond pure spread capture; maker returns depend on which side they take. If profits were purely spread-based, it should not matter whether makers bought YES or NO. We test this by decomposing maker performance by position direction:&lt;/p&gt;
    &lt;p&gt;Makers who buy NO outperform makers who buy YES 59% of the time. The volume-weighted excess return is +0.77 pp for makers buying YES versus +1.25 pp for makers buying NO, a gap of 0.47 percentage points. The effect is miniscule (Cohen's d = 0.02-0.03) but consistent. At minimum, this suggests spread capture is not the whole story.&lt;/p&gt;
    &lt;p&gt;A second observation strengthens the case further; the maker-taker gap varies substantially by market category.&lt;/p&gt;
    &lt;head rend="h3"&gt;Variation Across Categories&lt;/head&gt;
    &lt;p&gt;We examine whether the maker-taker gap varies by market category. If the bias reflects uninformed demand, categories attracting less sophisticated participants should show larger gaps.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Taker Return&lt;/cell&gt;
        &lt;cell role="head"&gt;Maker Return&lt;/cell&gt;
        &lt;cell role="head"&gt;Gap&lt;/cell&gt;
        &lt;cell role="head"&gt;N trades&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Sports&lt;/cell&gt;
        &lt;cell&gt;-1.11%&lt;/cell&gt;
        &lt;cell&gt;+1.12%&lt;/cell&gt;
        &lt;cell&gt;2.23 pp&lt;/cell&gt;
        &lt;cell&gt;43.6M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Politics&lt;/cell&gt;
        &lt;cell&gt;-0.51%&lt;/cell&gt;
        &lt;cell&gt;+0.51%&lt;/cell&gt;
        &lt;cell&gt;1.02 pp&lt;/cell&gt;
        &lt;cell&gt;4.9M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Crypto&lt;/cell&gt;
        &lt;cell&gt;-1.34%&lt;/cell&gt;
        &lt;cell&gt;+1.34%&lt;/cell&gt;
        &lt;cell&gt;2.69 pp&lt;/cell&gt;
        &lt;cell&gt;6.7M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Finance&lt;/cell&gt;
        &lt;cell&gt;-0.08%&lt;/cell&gt;
        &lt;cell&gt;+0.08%&lt;/cell&gt;
        &lt;cell&gt;0.17 pp&lt;/cell&gt;
        &lt;cell&gt;4.4M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Weather&lt;/cell&gt;
        &lt;cell&gt;-1.29%&lt;/cell&gt;
        &lt;cell&gt;+1.29%&lt;/cell&gt;
        &lt;cell&gt;2.57 pp&lt;/cell&gt;
        &lt;cell&gt;4.4M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Entertainment&lt;/cell&gt;
        &lt;cell&gt;-2.40%&lt;/cell&gt;
        &lt;cell&gt;+2.40%&lt;/cell&gt;
        &lt;cell&gt;4.79 pp&lt;/cell&gt;
        &lt;cell&gt;1.5M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Media&lt;/cell&gt;
        &lt;cell&gt;-3.64%&lt;/cell&gt;
        &lt;cell&gt;+3.64%&lt;/cell&gt;
        &lt;cell&gt;7.28 pp&lt;/cell&gt;
        &lt;cell&gt;0.6M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;World Events&lt;/cell&gt;
        &lt;cell&gt;-3.66%&lt;/cell&gt;
        &lt;cell&gt;+3.66%&lt;/cell&gt;
        &lt;cell&gt;7.32 pp&lt;/cell&gt;
        &lt;cell&gt;0.2M&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The variation is striking. Finance shows a gap of merely 0.17 pp; the market is extremely efficient, with takers losing only 0.08% per trade. At the other extreme, World Events and Media show gaps exceeding 7 percentage points. Sports, the largest category by volume, exhibits a moderate gap of 2.23 pp. Given $6.1 billion in taker volume, even this modest gap generates substantial wealth transfer.&lt;/p&gt;
    &lt;p&gt;Why is Finance efficient? The likely explanation is participant selection; financial questions attract traders who think in probabilities and expected values rather than fans betting on their favorite team or partisans betting on a preferred candidate. The questions themselves are dry ("Will the S&amp;amp;P close above 6000?"), which filters out emotional bettors.&lt;/p&gt;
    &lt;head rend="h3"&gt;Evolution Over Time&lt;/head&gt;
    &lt;p&gt;The maker-taker gap is not a fixed feature of the market; rather, it emerged as the platform grew. In Kalshi's early days, the pattern was reversed; takers earned positive excess returns while makers lost money.&lt;/p&gt;
    &lt;p&gt;From launch through 2023, taker returns averaged +2.0% while maker returns averaged -2.0%. Without sophisticated counterparties, takers won; amateur makers defined the early period and were the losing population. This began to reverse in 2024 Q2, with the gap crossing zero and then widening sharply after the 2024 election.&lt;/p&gt;
    &lt;p&gt;The inflection point coincides with two events; Kalshi's legal victory over the CFTC in October 2024, which permitted political contracts, and the subsequent 2024 election cycle. Volume exploded from $30 million in 2024 Q3 to $820 million in 2024 Q4. The new volume attracted sophisticated market makers, and with them, the extraction of value from taker flow.&lt;/p&gt;
    &lt;p&gt;Pre-election, the average gap was -2.9 pp (takers winning); post-election, it flipped to +2.5 pp (makers winning), a swing of 5.3 percentage points.&lt;/p&gt;
    &lt;p&gt;The composition of taker flow provides further evidence. If the wealth transfer arose because new participants arrived with stronger longshot preferences, we would expect the distribution to shift toward low-probability contracts. It did not:&lt;/p&gt;
    &lt;p&gt;The share of taker volume in longshot contracts (1-20¢) remained essentially flat; 4.8% pre-election versus 4.6% post-election. The distribution actually shifted toward the middle; the 91-99¢ bucket fell from 40-50% in 2021-2023 to under 20% in 2025, while mid-range prices (31-70¢) grew substantially. Taker behavior did not become more biased; if anything, it became less extreme. Yet taker losses increased; new market makers extract value more efficiently across all price levels.&lt;/p&gt;
    &lt;p&gt;This evolution reframes the aggregate results. The wealth transfer from takers to makers is not inherent to prediction market microstructure; it requires sophisticated market makers, and sophisticated market makers require sufficient volume to justify participation. In the low-volume early period, makers were likely unsophisticated individuals who lost to relatively informed takers. The volume surge attracted professional liquidity providers capable of extracting value from taker flow at all price points.&lt;/p&gt;
    &lt;head rend="h2"&gt;The YES/NO Asymmetry&lt;/head&gt;
    &lt;p&gt;The maker-taker decomposition identifies who absorbs the losses, but leaves open the question of how their selection bias operates. Why is taker flow so consistently mispriced? The answer is not that makers possess superior foresight, but rather that takers exhibit a costly preference for affirmative outcomes.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Asymmetry at Equivalent Prices&lt;/head&gt;
    &lt;p&gt;Standard efficiency models imply that mispricing should be symmetric across contract types at equivalent prices; a 1-cent YES contract and a 1-cent NO contract should theoretically reflect similar expected values. The data contradicts this assumption. At a price of 1 cent, a YES contract carries a historical expected value of -41%; buyers lose nearly half their capital in expectation. Conversely, a NO contract at the same 1-cent price delivers a historical expected value of +23%. The divergence between these seemingly identical probability estimates is 64 percentage points.&lt;/p&gt;
    &lt;p&gt;The advantage for NO contracts is persistent. NO outperforms YES at 69 of 99 price levels, with the advantage concentrating at the market extremes. NO contracts generate superior returns at every price increment from 1 to 10 cents and again from 91 to 99 cents.&lt;/p&gt;
    &lt;p&gt;Despite the market being zero-sum, dollar-weighted returns are -1.02% for YES buyers compared to +0.83% for NO buyers, a 1.85 percentage point gap driven by the overpricing of YES contracts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Takers Prefer Affirmative Bets&lt;/head&gt;
    &lt;p&gt;The underperformance of YES contracts may be linked to taker behavior. Breaking down the trading data reveals a structural imbalance in order flow composition.&lt;/p&gt;
    &lt;p&gt;In the 1-10 cent range, where YES represents the longshot outcome, takers account for 41-47% of YES volume; makers account for only 20-24%. This imbalance inverts at the opposite end of the probability curve. When contracts trade at 99 cents, implying that NO is the 1-cent longshot, makers actively purchase NO contracts at 43% of volume. Takers participate at a rate of only 23%.&lt;/p&gt;
    &lt;p&gt;One might hypothesize that makers exploit this asymmetry through superior directional forecasting—that they simply know when to buy NO. The evidence does not support this. When decomposing maker performance by position direction, returns are nearly identical. Statistically significant differences emerge only at the extreme tails (1–10¢ and 91–99¢), and even there, effect sizes are negligible (Cohen's d = 0.02–0.03). This symmetry is telling: makers do not profit by knowing which way to bet, but through some mechanism that applies equally to both directions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;The analysis of 72.1 million trades on Kalshi reveals a distinct market microstructure where wealth systematically transfers from liquidity takers to liquidity makers. This phenomenon is driven by specific behavioral biases, modulated by market maturity, and concentrated in categories that elicit high emotional engagement.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Mechanism of Extraction&lt;/head&gt;
    &lt;p&gt;A central question in zero-sum market analysis is whether profitable participants win through superior information (forecasting) or superior structure (market making). Our data strongly supports the latter. When decomposing maker returns by position direction, the performance gap is negligible: makers buying "YES" earn an excess return of +0.77%, while those buying "NO" earn +1.25% (Cohen’s d ≈ 0.02). This statistical symmetry indicates that makers do not possess a significant ability to pick winners. Instead, they profit via a structural arbitrage: providing liquidity to a taker population that exhibits a costly preference for affirmative, longshot outcomes.&lt;/p&gt;
    &lt;p&gt;This extraction mechanism relies on the "Optimism Tax." Takers disproportionately purchase "YES" contracts at longshot prices, accounting for nearly half of all volume in that range, despite "YES" longshots underperforming "NO" longshots by up to 64 percentage points. Makers, therefore, do not need to predict the future; they simply need to act as the counterparty to optimism. This aligns with findings by Reichenbach and Walther (2025) on Polymarket and Whelan (2025) on Betfair, suggesting that in prediction markets, makers accommodate biased flow rather than out-forecast it.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Professionalization of Liquidity&lt;/head&gt;
    &lt;p&gt;The temporal evolution of maker-taker returns challenges the assumption that longshot bias inevitably leads to wealth transfer. From 2021 through 2023, the bias existed, yet takers maintained positive excess returns. The reversal of this trend coincides precisely with the explosive volume growth following Kalshi’s October 2024 legal victory.&lt;/p&gt;
    &lt;p&gt;The wealth transfer observed in late 2024 is a function of market depth. In the platform's infancy, low liquidity likely deterred sophisticated algorithmic market makers, leaving the order book to be populated by amateurs who were statistically indistinguishable from takers. The massive volume surge following the 2024 election incentivized the entry of professional liquidity providers capable of systematically capturing the spread and exploiting the biased flow. The longshot bias itself may have persisted for years, but it was only once market depth grew sufficiently to attract these sophisticated makers that the bias became a reliable source of profit extraction.&lt;/p&gt;
    &lt;head rend="h3"&gt;Category Differences and Participant Selection&lt;/head&gt;
    &lt;p&gt;The variation in maker-taker gaps across categories reveals how participant selection shapes market efficiency. At one extreme, Finance exhibits a gap of just 0.17 percentage points; nearly perfect efficiency. At the other, World Events and Media exceed 7 percentage points. This difference cannot be explained by the longshot bias alone; it reflects who chooses to trade in each category.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Finance (0.17 pp) serves as a control group demonstrating that prediction markets can approach efficiency. Questions like "Will the S&amp;amp;P close above 6000?" attract participants who think in probabilities and expected values, likely the same population that trades options or follows macroeconomic data. The barrier to informed participation is high, and casual bettors have no edge and likely recognize this, filtering themselves out.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Politics (1.02 pp) shows moderate inefficiency despite high emotional stakes. Political bettors follow polling closely and have practiced calibrating beliefs through election cycles. The gap is larger than Finance but far smaller than entertainment categories, suggesting that political engagement, while emotional, does not entirely erode probabilistic reasoning.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sports (2.23 pp) represents the modal prediction market participant. The gap is moderate but consequential given the category's 72% volume share. Sports bettors exhibit well-documented biases, including home team loyalty, recency effects, and narrative attachment to star players. A fan betting on their team to win the championship is not calculating expected value; they are purchasing hope.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Crypto (2.69 pp) attracts participants conditioned by the "number go up" mentality of retail crypto markets, a population overlapping with meme stock traders and NFT speculators. Questions like "Will Bitcoin reach $100k?" invite narrative-driven betting rather than probability estimation.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Entertainment, Media, and World Events (4.79–7.32 pp) exhibit the largest gaps and share a common feature: minimal barriers to perceived expertise. Anyone who follows celebrity gossip feels qualified to bet on award show outcomes; anyone who reads headlines feels informed about geopolitics. This creates a participant pool that conflates familiarity with calibration.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The pattern suggests efficiency depends on two factors: the technical barrier to informed participation and the degree to which questions invite emotional reasoning. When barriers are high and framing is clinical, markets approach efficiency; when barriers are low and framing invites storytelling, the optimism tax reaches its maximum.&lt;/p&gt;
    &lt;head rend="h3"&gt;Limitations&lt;/head&gt;
    &lt;p&gt;While the data is robust, several limitations persist. First, the absence of unique trader IDs forces us to rely on the "Maker/Taker" classification as a proxy for "Sophisticated/Unsophisticated." While standard in microstructure literature, this imperfectly captures instances where sophisticated traders cross the spread to act on time-sensitive information. Second, we cannot directly observe the bid-ask spread in historical trade data, making it difficult to strictly decouple spread capture from explotation of biased flow. Finally, these results are specific to a US-regulated environment; offshore venues with different leverage caps and fee structures may exhibit different dynamics.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The promise of prediction markets lies in their ability to aggregate diverse information into a single, accurate probability. However, our analysis of Kalshi demonstrates that this signal is often distorted by systematic wealth transfer driven by human psychology and market microstructure.&lt;/p&gt;
    &lt;p&gt;The market is split into two distinct populations: a taker class that systematically overpays for low-probability, affirmative outcomes, and a maker class that extracts this premium through passive liquidity provision. This dynamic is not an inherent flaw of the "wisdom of the crowd," but rather a feature of how human psychology interacts with market microstructure. When the topic is dry and quantitative (Finance), the market is efficient. When the topic allows for tribalism and hope (Sports, Entertainment), the market transforms into a mechanism for transferring wealth from the optimistic to the calculated.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fama, E.F., "Efficient Capital Markets: A Review of Theory and Empirical Work", Journal of Finance, 1970. Available: https://www.jstor.org/stable/2325486&lt;/item&gt;
      &lt;item&gt;Griffith, R.M., "Odds Adjustments by American Horse-Race Bettors", American Journal of Psychology, 1949. Available: https://www.jstor.org/stable/1418469&lt;/item&gt;
      &lt;item&gt;Reichenbach, F. &amp;amp; Walther, M., "Exploring Decentralized Prediction Markets: Accuracy, Skill, and Bias on Polymarket", SSRN, 2025. Available: https://ssrn.com/abstract=5910522&lt;/item&gt;
      &lt;item&gt;Thaler, R.H. &amp;amp; Ziemba, W.T., "Anomalies: Parimutuel Betting Markets: Racetracks and Lotteries", Journal of Economic Perspectives, 1988. Available: https://www.aeaweb.org/articles?id=10.1257/jep.2.2.161&lt;/item&gt;
      &lt;item&gt;Whelan, K., "Agreeing to Disagree: The Economics of Betting Exchanges", MPRA, 2025. Available: https://mpra.ub.uni-muenchen.de/126351/1/MPRA_paper_126351.pdf&lt;/item&gt;
      &lt;item&gt;U.S. Court of Appeals for the D.C. Circuit, "Kalshi, Inc. v. CFTC", Oct 2024. Available: https://media.cadc.uscourts.gov/opinions/docs/2024/10/24-5205-2077790.pdf&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jbecker.dev/research/prediction-market-microstructure"/><published>2026-01-19T16:05:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46680597</id><title>Show HN: Pipenet – A Modern Alternative to Localtunnel</title><updated>2026-01-19T19:36:54.737061+00:00</updated><content>&lt;doc fingerprint="de482d5c2b01afc2"&gt;
  &lt;main&gt;
    &lt;p&gt;A modern, open-source alternative to localtunnel. Bundles client &amp;amp; server to host your own tunnel infrastructure.&lt;/p&gt;
    &lt;p&gt;Expose local services to the internet, or embed tunneling in your own tools.&lt;/p&gt;
    &lt;p&gt;Share your local server with teammates, test webhooks, or demo work without deploying.&lt;/p&gt;
    &lt;p&gt;Embed pipenet in your own tools to provide tunneling capabilities. mcp-proxy uses pipenet to connect local MCP servers with remote AI clients.&lt;/p&gt;
    &lt;p&gt;Run your own tunnel server for full control over security, domains, and availability.&lt;/p&gt;
    &lt;p&gt;One package. Two modes. Use the public server or deploy your own.&lt;/p&gt;
    &lt;quote&gt;# Expose local port npx pipenet client --port 3000 # Custom subdomain npx pipenet client --port 3000 \ --subdomain myapp # Your own server npx pipenet client --port 3000 \ --host https://tunnel.example.com&lt;/quote&gt;
    &lt;quote&gt;# Start server npx pipenet server --port 3000 # Custom domain npx pipenet server --port 3000 \ --domain tunnel.example.com # Cloud-ready npx pipenet server --port 3000 \ --tunnel-port 3001&lt;/quote&gt;
    &lt;p&gt;Built for modern deployment environments.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;pipenet&lt;/cell&gt;
        &lt;cell role="head"&gt;localtunnel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Cloud deployment&lt;/cell&gt;
        &lt;cell&gt;single-port&lt;/cell&gt;
        &lt;cell&gt;random ports&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Multiple domains&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;TypeScript&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ES Modules&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Maintenance&lt;/cell&gt;
        &lt;cell&gt;Active&lt;/cell&gt;
        &lt;cell&gt;Limited&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;WebSocket&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Tunnels any HTTP-based traffic to your local server.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Protocol&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;HTTP / HTTPS&lt;/cell&gt;
        &lt;cell&gt;Standard request/response&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;WebSocket&lt;/cell&gt;
        &lt;cell&gt;Full duplex via HTTP upgrade&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SSE&lt;/cell&gt;
        &lt;cell&gt;Long-lived HTTP connections&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;HTTP Streaming&lt;/cell&gt;
        &lt;cell&gt;Chunked transfer encoding&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Programmatic usage for testing, automation, and integration.&lt;/p&gt;
    &lt;quote&gt;import { pipenet } from 'pipenet'; const tunnel = await pipenet({ port: 3000 }); console.log(tunnel.url); // https://abc123.pipenet.dev tunnel.on('request', (info) =&amp;gt; console.log(info.method, info.path)); tunnel.on('close', () =&amp;gt; console.log('closed'));&lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;port&lt;/cell&gt;
        &lt;cell&gt;number Local port to expose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;host&lt;/cell&gt;
        &lt;cell&gt;string Tunnel server URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;subdomain&lt;/cell&gt;
        &lt;cell&gt;string Request specific subdomain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;localHost&lt;/cell&gt;
        &lt;cell&gt;string Proxy to this hostname instead of localhost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;localHttps&lt;/cell&gt;
        &lt;cell&gt;boolean Tunnel to local HTTPS server&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;allowInvalidCert&lt;/cell&gt;
        &lt;cell&gt;boolean Skip cert validation&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;request&lt;/cell&gt;
        &lt;cell&gt;Fired on each proxied request with method and path&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;error&lt;/cell&gt;
        &lt;cell&gt;Fired when an error occurs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;close&lt;/cell&gt;
        &lt;cell&gt;Fired when tunnel closes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Deploy your own tunnel infrastructure with lifecycle hooks.&lt;/p&gt;
    &lt;quote&gt;import { createServer } from 'pipenet/server'; const server = createServer({ domains: ['tunnel.example.com'], secure: true, tunnelPort: 3001, // Lifecycle hooks onTunnelCreated: (tunnel) =&amp;gt; { console.log(`Tunnel created: ${tunnel.id} at ${tunnel.url}`); }, onTunnelClosed: (tunnel) =&amp;gt; { console.log(`Tunnel closed: ${tunnel.id}`); }, onRequest: (req) =&amp;gt; { console.log(`${req.method} ${req.path} via ${req.tunnelId}`); }, }); await server.tunnelServer.listen(3001); server.listen(3000);&lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;domains&lt;/cell&gt;
        &lt;cell&gt;string[] Custom domain(s) for tunnel server&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;secure&lt;/cell&gt;
        &lt;cell&gt;boolean Require HTTPS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;landing&lt;/cell&gt;
        &lt;cell&gt;string Redirect URL for root requests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;maxTcpSockets&lt;/cell&gt;
        &lt;cell&gt;number Max sockets per client (default: 10)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;tunnelPort&lt;/cell&gt;
        &lt;cell&gt;number Shared port for cloud deployments&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;onTunnelCreated&lt;/cell&gt;
        &lt;cell&gt;Called when a new tunnel is created&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;onTunnelClosed&lt;/cell&gt;
        &lt;cell&gt;Called when a tunnel is closed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;onRequest&lt;/cell&gt;
        &lt;cell&gt;Called on each proxied request&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GET /api/status&lt;/cell&gt;
        &lt;cell&gt;Server status and tunnel count&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GET /api/tunnels/:id/status&lt;/cell&gt;
        &lt;cell&gt;Status of specific tunnel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GET /:id&lt;/cell&gt;
        &lt;cell&gt;Request new tunnel with ID&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pipenet.dev/"/><published>2026-01-19T16:10:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46680974</id><title>Apple testing new App Store design that blurs the line between ads and results</title><updated>2026-01-19T19:36:54.510053+00:00</updated><content>&lt;doc fingerprint="91c8fb6b35a63646"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple is testing a new design for App Store search ads on iPhone. Some users on iOS 26.3 are noticing that the blue background around sponsored results is no longer shown, blurring the line between what paid ad results look like and the real search results that follow.&lt;/p&gt;
    &lt;p&gt;This means the only differentiator between organic results and the promoted ad is the presence of the small ‘Ad’ banner next to the app icon. Right now, it appears to be in some kind of A/B test phase.&lt;/p&gt;
    &lt;p&gt;We have asked Apple for clarity on the change, and whether this will roll out more widely in the future.&lt;/p&gt;
    &lt;p&gt;It may be related to the company’s announcement from December that App Store search results will soon start including more than one sponsored result for a given search query. The removal of the blue background will mean all of the ads will appear in the list in a more integrated fashion.&lt;/p&gt;
    &lt;p&gt;Of course, this also has the effect of making it harder for users to quickly distinguish at a glance what is an ad and what isn’t, potentially misleading some users into not realising that the first result is a paid ad placement. While not great for user experience, it probably helps increase click-through rates which ultimately boosts Apple’s revenue in its ads business.&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://9to5mac.com/2026/01/16/iphone-apple-app-store-search-results-ads-new-design/"/><published>2026-01-19T16:36:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46681153</id><title>Cows Can Use Sophisticated Tools</title><updated>2026-01-19T19:36:54.368783+00:00</updated><content>&lt;doc fingerprint="3ed3119b7d522d10"&gt;
  &lt;main&gt;
    &lt;p&gt;If cows could use tools, imagine the scenes that might unfold: cutting wires to escape from their pastures; extracting themselves from milking machines; or removing the twine on hay bales. Cows haven’t been seen doing any of these things, of course. But a study published today in Current Biology demonstrates a cow named Veronika effectively using a deck broom as a scratching tool, satisfying the scientific definition of tool use as “the manipulation of an external object to achieve a goal via a mechanical interface.”&lt;/p&gt;
    &lt;p&gt;Veronika is a pet Brown Swiss cow (Bos taurus) kept as a companion by a farmer. In a series of 10 trials, researchers from the University of Veterinary Medicine Vienna presented her with a deck broom tossed on the ground in a random orientation. Each trial, they recorded which end of the brush she selected and how she used it. Veronika manipulated the broom with her mouth, positioning it under her tongue, then wedging it into the gaps between her incisors and molars for a stable grip.&lt;/p&gt;
    &lt;p&gt;Veronika adeptly used the deck brush to scratch her itches, manipulating it to target different areas. Across the randomized trials, she chose the bristled end to scratch her hindquarters but switched to the stick end for softer lower-body areas. Across repeat trials, she made consistent choices about how to wield the broom. “When I saw the footage, it was immediately clear that this was not accidental,” said study author and cognitive biologist Alice Auersperg in a statement.&lt;/p&gt;
    &lt;p&gt;Read more: “Scratch My Back and I’ll Scratch Yours”&lt;/p&gt;
    &lt;p&gt;Veronika’s tool use is considered “egocentric” tooling because it’s directed at herself. Although it’s simpler than “allocentric” tool use, wherein the tool is directed at something outside of oneself, it’s nevertheless a cognitive feat. Other than in primates, such adaptive use of a tool by a mammal has never been reported before.&lt;/p&gt;
    &lt;p&gt;The findings suggest that the abilities of cows have been underrated, since tool use offers a “stringent test of cognitive flexibility,” wrote the study authors.&lt;/p&gt;
    &lt;p&gt;Perhaps that shouldn’t surprise us, since cows have been associated with humans for more than 10,000 years as domesticated animals. The researchers point out that Veronika may have had ample time to experiment and learn this behavior during prolonged contact with a human-built environment. Her status as a companion animal to the farmer might also have provided more opportunities to observe a cow’s behavior.&lt;/p&gt;
    &lt;p&gt;“The findings highlight how assumptions about livestock intelligence may reflect gaps in observation rather than genuine cognitive limits,” said Auersperg.&lt;/p&gt;
    &lt;p&gt;What will cows, sheep, or goats be doing next?&lt;/p&gt;
    &lt;p&gt;Lead image: Peter Hofstetter / Shutterstock&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nautil.us/the-far-side-had-it-all-wrong-cows-really-can-use-sophisticated-tools-1262026/"/><published>2026-01-19T16:47:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46681454</id><title>Fix Your Robots.txt or Your Site Disappears from Google</title><updated>2026-01-19T19:36:54.107104+00:00</updated><content>&lt;doc fingerprint="1b2293f513e43fd5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fix Your robots.txt or Your Site Disappears from Google&lt;/head&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;Your site will be removed from Google search results if you don't have a robots.txt file or the Googlebot site crawler can't access it.&lt;/p&gt;
    &lt;p&gt;Here's the video from Google Support that covers it:&lt;/p&gt;
    &lt;head rend="h2"&gt;Wait, what?&lt;/head&gt;
    &lt;p&gt;Adam Coster ran into a weird issue with site traffic and posted about it in the Shop Talk Show discord. Traffic incoming from Google looked like this:&lt;/p&gt;
    &lt;p&gt;The issues seemed to be that Google wouldn't index the site without a robots.txt file.&lt;/p&gt;
    &lt;p&gt;My first reaction: No fucking way.&lt;/p&gt;
    &lt;p&gt;I can't imagine Google voluntarily slurping up less content. I went to see what I could find. Sure enough, I found this page from Google Support from July 23, 2025:&lt;/p&gt;
    &lt;p&gt;Fix 'robots.txt unreachable' Error ~ Website Not Indexing?&lt;/p&gt;
    &lt;p&gt;The pull quote from the video on the page:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Your robots.txt file is the very first thing Googlebot looks for. If it can not reach this file, it will stop and won't crawl the rest of your site. Meaning your pages will remain invisible (on Google).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Holy shit.&lt;/p&gt;
    &lt;p&gt;I haven't looked to see if this was a recent change, but it has to be. There's no way something so fundamental has just slipped by without becoming common knowledge.&lt;/p&gt;
    &lt;p&gt;But, the timeline doesn't matter. It's how things are now.&lt;/p&gt;
    &lt;p&gt;This absolutely blows my mind. I don't have tracking on my site. I never would have noticed this if someone hadn't pointed it out.&lt;/p&gt;
    &lt;p&gt;Just wild,&lt;/p&gt;
    &lt;p&gt;-a&lt;/p&gt;
    &lt;head rend="h3"&gt;Endnotes&lt;/head&gt;
    &lt;p&gt;Thanks to Adam for letting me share the traffic graph.&lt;/p&gt;
    &lt;p&gt;If you need a quick fix, create a text file at the root of your website called "robots.txt" (e.g. https://www.example.com/robots.txt). Put the following contents in it:&lt;/p&gt;
    &lt;code&gt;User-agent: *
Allow: /&lt;/code&gt;
    &lt;p&gt;This is the code from Google's How to write and submit a robots.txt file page. It provides explicit permission for the Googlebot (and other bots/crawlers/scrapers that use the file) to access anything they can find on your site.&lt;/p&gt;
    &lt;p&gt;You can read more about the file on the robots.txt wikipedia page.&lt;/p&gt;
    &lt;p&gt;The top Stack Overflow answer on robots.txt has a discussion about &lt;code&gt;Allow: /&lt;/code&gt; not being valid according to the spec. The only date for the comments is "Over a year ago" but given that the question is from 2010 the comments are probably from around that time.&lt;/p&gt;
    &lt;p&gt;As of at least the Sept. 2022 spec from the Internet Engineering Task Force, the &lt;code&gt;Allow: /&lt;/code&gt; syntax is valid.&lt;/p&gt;
    &lt;p&gt;I don't have a robots.txt right now. It hasn't been there in a long time. Google still shows two results when I search for files on my site though:&lt;/p&gt;
    &lt;p&gt;No idea if that's because of external links or the fact that they are in the index from a long time ago. But,&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I've got north of 3K posts on the site. I know a ton of them showed up in the past, if not all of them.&lt;/item&gt;
      &lt;item&gt;I made a bunch of posts between the first Dec. 27, 2025 result and the second one from "one day ago" which was Jan. 6, 2026. No idea why just those two are showing up.&lt;/item&gt;
      &lt;item&gt;I used to have the first search result for "bama braves logo" in general google search, but that page is no longer in the index.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The video says Googlebot stops it if can't access the robots.txt file. I'm taking that to mean that the file must exist. It's possible that Googlebot will continue if the file doesn't exist and returns a 404.&lt;/p&gt;
    &lt;p&gt;The video doesn't address that specifically, but I interpret the content to mean that a missing file stops the bot. Especially because Adam's site didn't have one which started this whole post.&lt;/p&gt;
    &lt;p&gt;Maybe Google is trying to play nice with the way it ingests data given all the AI crawlers that are slamming sites these days?&lt;/p&gt;
    &lt;p&gt;I'm super curious what discussions led to the requirement for the file.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.alanwsmith.com/en/37/wa/jz/s1/"/><published>2026-01-19T17:03:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46681611</id><title>What came first: the CNAME or the A record?</title><updated>2026-01-19T19:36:53.639083+00:00</updated><content>&lt;doc fingerprint="e6196be43eb2159f"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;On January 8, 2026, a routine update to 1.1.1.1 aimed at reducing memory usage accidentally triggered a wave of DNS resolution failures for users across the Internet. The root cause wasn't an attack or an outage, but a subtle shift in the order of records within our DNS responses. &lt;/p&gt;
      &lt;p&gt;While most modern software treats the order of records in DNS responses as irrelevant, we discovered that some implementations expect CNAME records to appear before everything else. When that order changed, resolution started failing. This post explores the code change that caused the shift, why it broke specific DNS clients, and the 40-year-old protocol ambiguity that makes the "correct" order of a DNS response difficult to define.&lt;/p&gt;
      &lt;p&gt;All timestamps referenced are in Coordinated Universal Time (UTC).&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Time&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Description&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2025-12-02&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The record reordering is introduced to the 1.1.1.1 codebase&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2025-12-10&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The change is released to our testing environment&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-07 23:48&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;A global release containing the change starts&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-08 17:40&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The release reaches 90% of servers&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-08 18:19&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Incident is declared&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-08 18:27&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The release is reverted&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-08 19:55&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Revert is completed. Impact ends&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;While making some improvements to lower the memory usage of our cache implementation, we introduced a subtle change to CNAME record ordering. The change was introduced on December 2, 2025, released to our testing environment on December 10, and began deployment on January 7, 2026.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;How DNS CNAME chains work&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;When you query for a domain like &lt;code&gt;www.example.com&lt;/code&gt;, you might get a CNAME (Canonical Name) record that indicates one name is an alias for another name. Itâs the job of public resolvers, such as 1.1.1.1, to follow this chain of aliases until it reaches a final response:&lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;www.example.com â cdn.example.com â server.cdn-provider.com â 198.51.100.1&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;As 1.1.1.1 traverses this chain, it caches every intermediate record. Each record in the chain has its own TTL (Time-To-Live), indicating how long we can cache it. Not all the TTLs in a CNAME chain need to be the same:&lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;www.example.com â cdn.example.com (TTL: 3600 seconds) # Still cached
cdn.example.com â 198.51.100.1Â  Â  (TTL: 300 seconds)Â  # Expired&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;When one or more records in a CNAME chain expire, itâs considered partially expired. Fortunately, since parts of the chain are still in our cache, we donât have to resolve the entire CNAME chain again â only the part that has expired. In our example above, we would take the still valid &lt;code&gt;www.example.com â cdn.example.com&lt;/code&gt; chain, and only resolve the expired &lt;code&gt;cdn.example.com&lt;/code&gt; A record. Once thatâs done, we combine the existing CNAME chain and the newly resolved records into a single response.&lt;/p&gt;
      &lt;p&gt;The code that merges these two chains is where the change occurred. Previously, the code would create a new list, insert the existing CNAME chain, and then append the new records:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;impl PartialChain {
    /// Merges records to the cache entry to make the cached records complete.
    pub fn fill_cache(&amp;amp;self, entry: &amp;amp;mut CacheEntry) {
        let mut answer_rrs = Vec::with_capacity(entry.answer.len() + self.records.len());
        answer_rrs.extend_from_slice(&amp;amp;self.records); // CNAMEs first
        answer_rrs.extend_from_slice(&amp;amp;entry.answer); // Then A/AAAA records
        entry.answer = answer_rrs;
    }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;However, to save some memory allocations and copies, the code was changed to instead append the CNAMEs to the existing answer list:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;impl PartialChain {
    /// Merges records to the cache entry to make the cached records complete.
    pub fn fill_cache(&amp;amp;self, entry: &amp;amp;mut CacheEntry) {
        entry.answer.extend(self.records); // CNAMEs last
    }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;As a result, the responses that 1.1.1.1 returned now sometimes had the CNAME records appearing at the bottom, after the final resolved answer.&lt;/p&gt;
      &lt;p&gt;When DNS clients receive a response with a CNAME chain in the answer section, they also need to follow this chain to find out that &lt;code&gt;www.example.com&lt;/code&gt; points to &lt;code&gt;198.51.100.1&lt;/code&gt;. Some DNS client implementations handle this by keeping track of the expected name for the records as theyâre iterated sequentially. When a CNAME is encountered, the expected name is updated:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;;; QUESTION SECTION:
;; www.example.com.        IN    A

;; ANSWER SECTION:
www.example.com.    3600   IN    CNAME  cdn.example.com.
cdn.example.com.    300    IN    A      198.51.100.1
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Find records for &lt;code&gt;www.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Encounter &lt;code&gt;www.example.com. CNAME cdn.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Find records for &lt;code&gt;cdn.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Encounter &lt;code&gt;cdn.example.com. A 198.51.100.1&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;When the CNAME suddenly appears at the bottom, this no longer works:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;;; QUESTION SECTION:
;; www.example.com.	       IN    A

;; ANSWER SECTION:
cdn.example.com.    300    IN    A      198.51.100.1
www.example.com.    3600   IN    CNAME  cdn.example.com.
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Find records for &lt;code&gt;www.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Ignore &lt;code&gt;cdn.example.com. A 198.51.100.1&lt;/code&gt; as it doesnât match the expected name&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Encounter &lt;code&gt;www.example.com. CNAME cdn.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Find records for &lt;code&gt;cdn.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;No more records are present, so the response is considered empty&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;One such implementation that broke is the &lt;code&gt;getaddrinfo&lt;/code&gt; function in glibc, which is commonly used on Linux for DNS resolution. When looking at its &lt;code&gt;getanswer_r&lt;/code&gt; implementation, we can indeed see it expects to find the CNAME records before any answers:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;for (; ancount &amp;gt; 0; --ancount)
  {
    // ... parsing DNS records ...
    
    if (rr.rtype == T_CNAME)
      {
        /* Record the CNAME target as the new expected name. */
        int n = __ns_name_unpack (c.begin, c.end, rr.rdata,
                                  name_buffer, sizeof (name_buffer));
        expected_name = name_buffer;  // Update what we're looking for
      }
    else if (rr.rtype == qtype
             &amp;amp;&amp;amp; __ns_samebinaryname (rr.rname, expected_name)  // Must match!
             &amp;amp;&amp;amp; rr.rdlength == rrtype_to_rdata_length (type:qtype))
      {
        /* Address record matches - store it */
        ptrlist_add (list:addresses, item:(char *) alloc_buffer_next (abuf, uint32_t));
        alloc_buffer_copy_bytes (buf:abuf, src:rr.rdata, size:rr.rdlength);
      }
  }
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Another notable affected implementation was the DNSC process in three models of Cisco ethernet switches. In the case where switches had been configured to use 1.1.1.1 these switches experienced spontaneous reboot loops when they received a response containing the reordered CNAMEs. Cisco has published a service document describing the issue.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Not all implementations break&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Most DNS clients donât have this issue. For example, systemd-resolved first parses the records into an ordered set:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;typedef struct DnsAnswerItem {
        DnsResourceRecord *rr; // The actual record
        DnsAnswerFlags flags;  // Which section it came from
        // ... other metadata
} DnsAnswerItem;


typedef struct DnsAnswer {
        unsigned n_ref;
        OrderedSet *items;
} DnsAnswer;
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When following a CNAME chain it can then search the entire answer set, even if the CNAME records donât appear at the top.&lt;/p&gt;
      &lt;p&gt;RFC 1034, published in 1987, defines much of the behavior of the DNS protocol, and should give us an answer on whether the order of CNAME records matters. Section 4.3.1 contains the following text:&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;If recursive service is requested and available, the recursive response to a query will be one of the following:&lt;/p&gt;
        &lt;p&gt;- The answer to the query, possibly preface by one or more CNAME RRs that specify aliases encountered on the way to an answer.&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;While "possibly preface" can be interpreted as a requirement for CNAME records to appear before everything else, it does not use normative key words, such as MUST and SHOULD that modern RFCs use to express requirements. This isnât a flaw in RFC 1034, but simply a result of its age. RFC 2119, which standardized these key words, was published in 1997, 10 years after RFC 1034.&lt;/p&gt;
      &lt;p&gt;In our case, we did originally implement the specification so that CNAMEs appear first. However, we did not have any tests asserting the behavior remains consistent due to the ambiguous language in the RFC.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;The subtle distinction: RRsets vs RRs in message sections&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;To understand why this ambiguity exists, we need to understand a subtle but important distinction in DNS terminology.&lt;/p&gt;
      &lt;p&gt;RFC 1034 section 3.6 defines Resource Record Sets (RRsets) as collections of records with the same name, type, and class. For RRsets, the specification is clear about ordering:&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;The order of RRs in a set is not significant, and need not be preserved by name servers, resolvers, or other parts of the DNS.&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;However, RFC 1034 doesnât clearly specify how message sections relate to RRsets. While modern DNS specifications have shown that message sections can indeed contain multiple RRsets (consider DNSSEC responses with signatures), RFC 1034 doesnât describe message sections in those terms. Instead, it treats message sections as containing individual Resource Records (RRs).&lt;/p&gt;
      &lt;p&gt;The problem is that the RFC primarily discusses ordering in the context of RRsets but doesn't specify the ordering of different RRsets relative to each other within a message section. This is where the ambiguity lives.&lt;/p&gt;
      &lt;p&gt;RFC 1034 section 6.2.1 includes an example that demonstrates this ambiguity further. It mentions that the order of Resource Records (RRs) is not significant either:&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;The difference in ordering of the RRs in the answer section is not significant.&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;However, this example only shows two A records for the same name within the same RRset. It doesn't address whether this applies to different record types like CNAMEs and A records.&lt;/p&gt;
      &lt;p&gt;It turns out that this issue extends beyond putting CNAME records before other record types. Even when CNAMEs appear before other records, sequential parsing can still break if the CNAME chain itself is out of order. Consider the following response:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;;; QUESTION SECTION:
;; www.example.com.              IN    A

;; ANSWER SECTION:
cdn.example.com.           3600  IN    CNAME  server.cdn-provider.com.
www.example.com.           3600  IN    CNAME  cdn.example.com.
server.cdn-provider.com.   300   IN    A      198.51.100.1
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Each CNAME belongs to a different RRset, as they have different owners, so the statement about RRset order being insignificant doesnât apply here.&lt;/p&gt;
      &lt;p&gt;However, RFC 1034 doesn't specify that CNAME chains must appear in any particular order. There's no requirement that &lt;code&gt;www.example.com. CNAME cdn.example.com.&lt;/code&gt; must appear before &lt;code&gt;cdn.example.com. CNAME server.cdn-provider.com.&lt;/code&gt;. With sequential parsing, the same issue occurs:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Find records for &lt;code&gt;www.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Ignore &lt;code&gt;cdn.example.com. CNAME server.cdn-provider.com&lt;/code&gt;. as it doesnât match the expected name&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Encounter &lt;code&gt;www.example.com. CNAME cdn.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Find records for &lt;code&gt;cdn.example.com&lt;/code&gt;&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Ignore &lt;code&gt;server.cdn-provider.com. A 198.51.100.1&lt;/code&gt; as it doesnât match the expected name&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;What should resolvers do?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;RFC 1034 section 5 describes resolver behavior. Section 5.2.2 specifically addresses how resolvers should handle aliases (CNAMEs): &lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;In most cases a resolver simply restarts the query at the new name when it encounters a CNAME.&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;This suggests that resolvers should restart the query upon finding a CNAME, regardless of where it appears in the response. However, it's important to distinguish between different types of resolvers:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Recursive resolvers, like 1.1.1.1, are full DNS resolvers that perform recursive resolution by querying authoritative nameservers&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Stub resolvers, like glibcâs getaddrinfo, are simplified local interfaces that forward queries to recursive resolvers and process the responses&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The RFC sections on resolver behavior were primarily written with full resolvers in mind, not the simplified stub resolvers that most applications actually use. Some stub resolvers evidently donât implement certain parts of the spec, such as the CNAME-restart logic described in the RFC. &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;The DNSSEC specifications provide contrast&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Later DNS specifications demonstrate a different approach to defining record ordering. RFC 4035, which defines protocol modifications for DNSSEC, uses more explicit language:&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;When placing a signed RRset in the Answer section, the name server MUST also place its RRSIG RRs in the Answer section. The RRSIG RRs have a higher priority for inclusion than any other RRsets that may have to be included.&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;The specification uses "MUST" and explicitly defines "higher priority" for RRSIG records. However, "higher priority for inclusion" refers to whether RRSIGs should be included in the response, not where they should appear. This provides unambiguous guidance to implementers about record inclusion in DNSSEC contexts, while not mandating any particular behavior around record ordering.&lt;/p&gt;
      &lt;p&gt;For unsigned zones, however, the ambiguity from RFC 1034 remains. The word "preface" has guided implementation behavior for nearly four decades, but it has never been formally specified as a requirement.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Do CNAME records come first?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;While in our interpretation the RFCs do not require CNAMEs to appear in any particular order, itâs clear that at least some widely-deployed DNS clients rely on it. As some systems using these clients might be updated infrequently, or never updated at all, we believe itâs best to require CNAME records to appear in-order before any other records.&lt;/p&gt;
      &lt;p&gt;Based on what we have learned during this incident, we have reverted the CNAME re-ordering and do not intend to change the order in the future.&lt;/p&gt;
      &lt;p&gt;To prevent any future incidents or confusion, we have written a proposal in the form of an Internet-Draft to be discussed at the IETF. If consensus is reached on the clarified behavior, this would become an RFC that explicitly defines how to correctly handle CNAMEs in DNS responses, helping us and the wider DNS community navigate the protocol. The proposal can be found at https://datatracker.ietf.org/doc/draft-jabley-dnsop-ordered-answer-section. If you have suggestions or feedback we would love to hear your opinions, most usefully via the DNSOP working group at the IETF.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/cname-a-record-order-dns-standards/"/><published>2026-01-19T17:13:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46682325</id><title>A Brief History of Ralph</title><updated>2026-01-19T19:36:53.400502+00:00</updated><content>&lt;doc fingerprint="2f40525059ee1eed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;# a brief history of ralph&lt;/head&gt;
    &lt;p&gt;Dex · January 6, 2026 · &amp;lt; 10 min read&lt;/p&gt;
    &lt;p&gt;The Ralph Wiggum Technique, created by Geoff Huntley, went viral in the final weeks of 2025. Here's the story of ralph since the first time I met Geoff in June of 2025.&lt;/p&gt;
    &lt;p&gt;I've been messing with ralph since ~June 2025. Here's my story and what I learned along the way.&lt;/p&gt;
    &lt;p&gt;tl;dr&lt;/p&gt;
    &lt;p&gt;Jan 1 2026 - If you wanna skip to the end, I did a deep dive on ralph w/ Geoff Huntley on Jan 1 2026. It talks through the history, cursed lang, and compares the original bash-loop ralph implementation with the anthropic stop-hook implementation. You can check it out here:&lt;/p&gt;
    &lt;head rend="h3"&gt;### June 19th 2025&lt;/head&gt;
    &lt;p&gt;I attend a meetup with about 15 members of a Twitter GC where we talk about agentic coding. It's the first time I see context7, WisprFlow, specstory, taskmaster, and a whole bunch of other tools and addons, some of which are now quite mainstream. One of our engineers demos an early TUI for Claude approvals and what becomes the foundation of research / plan / implement.&lt;/p&gt;
    &lt;p&gt;There are about 3 hours of presentations. Geoff shows up 2 hours late and presents last. He completely steals the show, diving deep on ralph, cursed lang (at the time, the compiler stack is written in Rust), livestreaming autonomous coding overnight while asleep in Australia, subagents in amp code, the virtues of drinking 3 margaritas and shouting at cursor, and much, much more.&lt;/p&gt;
    &lt;p&gt;Geoff talks about the "overbaking" phenomenon. If you leave ralph running too long, you end up with all sorts of bizarre emergent behavior, like post-quantum cryptography support.&lt;/p&gt;
    &lt;p&gt;It has dimensions of art, deep engineering, the embrace of chaos, and the raw and authentic joy of making a thing.&lt;/p&gt;
    &lt;p&gt;All ~15 of us have a long and (imo) somewhat unsettling conversation about the future of software dev—about how easy it is to take a SaaS and copy 80-90% of it, and about how many types of work are about to change or disappear entirely.&lt;/p&gt;
    &lt;head rend="h3"&gt;### July 2025&lt;/head&gt;
    &lt;p&gt;Geoff Launches ralph in an official blog post.&lt;/p&gt;
    &lt;p&gt;It includes the basic bash loop structure:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;while :; do cat PROMPT.md | npx --yes @sourcegraph/amp ; done&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;I send it to everyone I know. I hint at it to a few others.&lt;/p&gt;
    &lt;p&gt;It includes a very lightweight example of one of the prompts (this one came later in the language dev, as far as I can tell, since its about the stdlib)&lt;/p&gt;
    &lt;p&gt;At the time, it included an ask (paraphrasing here as it appears to be gone now)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;you could probably find the cursed lang repo on github if you looked for it, but please don't share it yet&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is exciting.&lt;/p&gt;
    &lt;head rend="h3"&gt;### August 2025 - Advanced Context Engineering for Coding agents&lt;/head&gt;
    &lt;p&gt;If you were early to the coding agents poweruser game, you might have seen Getting AI to work in complex codebases on hackernews and the youtube talk it was based on&lt;/p&gt;
    &lt;p&gt;It references ralph and why its such an important example of why engineering your context window is such a high-leverage activity.&lt;/p&gt;
    &lt;p&gt;Ralph is also a great example of using declarative specifications over imperative instructions.&lt;/p&gt;
    &lt;head rend="h3"&gt;### August 2025 - hacking productivity tools&lt;/head&gt;
    &lt;p&gt;I love hacking on Getting Things Done (GTD) and other productivity systems. I for whatever reason am still stuck on omnifocus which is an ancient but well-honed implementation of the system. But I have always longed for an AI native version.&lt;/p&gt;
    &lt;p&gt;I wrote a half-pager on what I wanted, I had ralph write the specs from that, and I had another ralph build the implementation from the specs.&lt;/p&gt;
    &lt;p&gt;I didn't really read the specs, and I didn't read the code.&lt;/p&gt;
    &lt;p&gt;The output sucked. I went back to read the specs and they were way off base.&lt;/p&gt;
    &lt;p&gt;That's fine it was a saturday morning toy thing, but I learned stuff.&lt;/p&gt;
    &lt;p&gt;Lessons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;if the specs are bad, the results will be meh&lt;/item&gt;
      &lt;item&gt;if you don't actually know your desired end state workflows and how you will test it, you probably won't know what to do when its done&lt;/item&gt;
      &lt;item&gt;if you are iterating/exploring, you probably don't want ralph in the first place&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;### August 2025 - we put a coding agent in a while loop and it shipped 6 repos overnight&lt;/head&gt;
    &lt;p&gt;You may recall this HN discussion - we put a coding agent in a while loop and it shipped 6 repos overnight - here's the original post simon and I wrote up at repomirrorhq/repomirror&lt;/p&gt;
    &lt;head rend="h3"&gt;### August 2025 - testing ralph for a refactor&lt;/head&gt;
    &lt;p&gt;I did a few experiments with ralph for side projects, but the most interestinng one was this one.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;An engineer was complaining that the frontend code was messy and was hard to work in, sprawling patterns, long components, etc&lt;/item&gt;
      &lt;item&gt;I spent about 30 minutes back and forth with claude developing a REACT_CODING_STANDARDS.md&lt;/item&gt;
      &lt;item&gt;I spent another 30 minutes working with the engineer (who has a lot more react experience than I do) to refine and update this doc&lt;/item&gt;
      &lt;item&gt;I launched a ralph with a prompt "make sure the code base matches the standards" prompt.md&lt;/item&gt;
      &lt;item&gt;Over the next 6 hours, it developed a REACT_REFACTOR_PLAN.md and blasted through the whole thing&lt;/item&gt;
      &lt;item&gt;I checked in after 6 hours and it claimed to be finished, so I stopped it and sent it over to team for a look.&lt;/item&gt;
      &lt;item&gt;Overall the feedback was positive, but the PR quickly got some merge conflicts and so we never ended up merging it - you can view the closed PR here&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lesson - code is cheap - the easier alternative to "merge/rebase" is just to re-run the ralph loop on the fresh code with the same prompt and re-open a PR.&lt;/p&gt;
    &lt;p&gt;Lesson - for existing codebases, make the change set manageable - we have since set up any ralph-ish desired state loops to once ONCE on a cron overnight, and merge small iterations over time. Waking up to one small refactor every morning is better than both a) waking up to none and b) waking up to 50.&lt;/p&gt;
    &lt;p&gt;See also: Ron Jeffries: Refactoring -- Not on the backlog!&lt;/p&gt;
    &lt;head rend="h3"&gt;### September 2025 - cursed lang launch&lt;/head&gt;
    &lt;p&gt;In September 2025, Geoff launches cursed lang officially, the programming language that ralph built. Once in C, once in rust, and then finally in zig. It has a standard library and a stage-2 compiler (cursed lang compiler written in cursed lang).&lt;/p&gt;
    &lt;p&gt;Check out the Cursed Lang Homepage&lt;/p&gt;
    &lt;p&gt;Aside - I want to do a cursed lang hackathon next time Geoff is in SF - stay tune or ping me on X if this is something you're be interested in.&lt;/p&gt;
    &lt;head rend="h3"&gt;### October 2025 - Claude Anonymous SF&lt;/head&gt;
    &lt;p&gt;I did a 5-minute ralph presentation at claude code anonymous in sf, in a room full of some of the most creative and enterprising claude code and codex users in town. steipete came all the way out from Austria to co-host with the Sentry folks.&lt;/p&gt;
    &lt;p&gt;It's hard to capture the glory of ralph in a 5 minute lightning talk. But even if all the context engineering concepts get missed, its always a fun time because of the deep art Geoff put into it the naming and branding.&lt;/p&gt;
    &lt;p&gt;Highlight was a question from the audience "so do you recommend this?" - my answer: "well, I believe you should try everything". Perhaps the point is not the 5-line bash loop. Perhaps the point is dumb things can work surprisingly well, so what could we expect from a smart version of the thing?&lt;/p&gt;
    &lt;head rend="h3"&gt;### October 2025 - AI That Works w/ Geoff Huntley&lt;/head&gt;
    &lt;p&gt;I was annoyed that I couldn't really do ralph justice in 5 minutes, so I wrangled Vaibhav and Geoff to do a 75-minute podcast deep diving on ralph and why it works.&lt;/p&gt;
    &lt;p&gt;We talk a lot about context windows, control loops, and various applications of the technique - refactoring, spec generation, new project setup, etc.&lt;/p&gt;
    &lt;p&gt;It was a fun time. You can watch it here:&lt;/p&gt;
    &lt;p&gt;There's some code samples here&lt;/p&gt;
    &lt;head rend="h3"&gt;### December 2025 - Anthropic Plugin Launches&lt;/head&gt;
    &lt;p&gt;At some point the anthropic team released an official ralph wiggum plugin.&lt;/p&gt;
    &lt;p&gt;Many people tweeted at Geoff about it.&lt;/p&gt;
    &lt;p&gt;I test it out. I am disappointed. It dies in cryptic ways unless you have &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;It installs hooks in weird places you can't find, uses a strange markdown file to track state, and adds an opaque stop hook for all claude sessions in a directory until you disable it. If you, in trying to stop it, delete the markdown file before stopping it, you break claude in that repo until you disable the plugin entirely.&lt;/p&gt;
    &lt;p&gt;Beyond that, it misses the key point of ralph which is not "run forever" but in "carve off small bits of work into independent context windows".&lt;/p&gt;
    &lt;p&gt;I look forward to see more from Anthropic on this in the future, but for now I'll keep my 5-line bash loops.&lt;/p&gt;
    &lt;head rend="h3"&gt;### December 2025 - Youtube Slop Everywhere&lt;/head&gt;
    &lt;p&gt;There were quickly ralph wiggum videos everywhere. Most of them are typical youtube ai hype-slop:&lt;/p&gt;
    &lt;p&gt;I actually like Matt Pockock's youtube overview because its true to the OG technique, and Matt does a good job of grounding the technique in a workflow like kanban, requirements discovery, etc.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Jan 1 2026 - Ralph Wiggum Showdown&lt;/head&gt;
    &lt;p&gt;So much ralph hype, I decided to give the official plugin another shot. I posted this graphic on twitter:&lt;/p&gt;
    &lt;p&gt;To my pleasant surprise, Geoff texted me and was like "okay I can jump on for the first 30 minutes or so".&lt;/p&gt;
    &lt;p&gt;So here ya go, a bonafide ralph wiggum yap, the whole story, why it works, with whiteboards and live examples for a side project I'm working on called &lt;code&gt;kustomark&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Here's the repos that got built. I still haven't gotten around to evaluating which one, if any, actually solves my problem:&lt;/p&gt;
    &lt;head rend="h3"&gt;### What's next&lt;/head&gt;
    &lt;p&gt;I still need to do a deep dive on what was built on the showdown stream. That's coming in the next few days, hopefully, because the kustomark plugin is a thing I actually want+need for some projects we're exploring.&lt;/p&gt;
    &lt;p&gt;You should mess with this stuff. It's not exactly the future, but its an imporant slice through a bunch of important concepts that will make you a better Agentic Coder and a better AI Engineer.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Okay one more thing&lt;/head&gt;
    &lt;p&gt;A gift and a shameless plug - a lot of you are sitting around on the waitlist wondering "when the heck is codelayer gonna actually launch". Quick update there - we're still working hard in the trenches with customers, and learning a lot that has led us to reexamine the entire product. However I am very proud of the OG codelayer and we have many many very happy users on the free private beta. So -- with the disclaimer that we will likely sunset the current beta in favor of a new thing we're launching soon -- if you read this far and you wanna try codelayer - check out the docs at https://hlyr.dev/docs and have fun.&lt;/p&gt;
    &lt;p&gt;Excited to share what's next.&lt;/p&gt;
    &lt;p&gt;In the mean time, happy ralphing. Hurry up before it gets semantically diffused.&lt;/p&gt;
    &lt;p&gt;-dex&lt;/p&gt;
    &lt;head rend="h3"&gt;### PPS&lt;/head&gt;
    &lt;p&gt;We're hiring yada yada come build cool shit&lt;/p&gt;
    &lt;head rend="h3"&gt;### PPPS&lt;/head&gt;
    &lt;p&gt;i guess we have a meme coin now...pack it up y'all its over, see you for the next memetic mind virus&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.humanlayer.dev/blog/brief-history-of-ralph"/><published>2026-01-19T18:00:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46682931</id><title>There Is No Comfortable Reading Position</title><updated>2026-01-19T19:36:53.152799+00:00</updated><content>&lt;doc fingerprint="3e70d1ce1c607296"&gt;
  &lt;main&gt;
    &lt;p&gt;Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.&lt;/p&gt;
    &lt;p&gt;For the 10th year in a row, my New Year’s resolution is to read more books. Ideally, as I tend to tell myself during these protean early weeks of January, 2026 will be remembered for languorous evenings on the couch, tearing through the inventory of novels that crowd the modest capacity of my living-room shelves, perhaps with a tumbler of scotch resting on a coaster. I revel in the fantasy—I dream about finally cracking open A Confederacy of Dunces, or knocking out the last two entries of the Broken Earth trilogy, or making time for that Patti Smith memoir that I bought more than a decade ago. If I’m really feeling myself, I contemplate aiming even higher. Tolstoy? Pynchon? I mean, there’s also that copy of The Pale King that has been steadily yellowing on my coffee table for quite some time now.&lt;/p&gt;
    &lt;p&gt;And yet, I already know how this saga is going to end. The year will draw to a close with a piddling number of new entries to my Goodreads, hopelessly incongruous with the size of my bibliophilic ambitions. Ask me why I never seem to read as much as I like, and I could gesture toward the well-worn afflictions of modernity—ballooning screen time, addictive algorithms, frayed attention spans. But one of my fundamental issues with literature is far more prosaic. In fact, I think it’s much more common than anyone would like to admit. Why is it that no matter what I do, I can never get comfortable while reading a book?&lt;/p&gt;
    &lt;p&gt;Don’t act like you don’t know what I’m talking about. This is a species-wide affliction. The first published novel in history is widely considered to be The Tale of Genji, a courtly drama written in the late 11th century by the Japanese noblewoman Murasaki Shikibu. A millennium since her wondrously mind-expanding invention, humanity has somehow yet to conceive an ergonomically sound way to consume the written word. I, like you, have lain flat on my back holding a novel aloft until my arms grow strained, fidgety, and unable to maintain equilibrium. I have also sat in an armchair, splaying the book open in my lap, until the severe angle stiffens my neck and reinforces the horrible truth that furniture was never meant to support the literary necessity to gaze downward. There is, of course, always the option to flip over to your stomach, allowing your elbows to dig into the mattress, carpet, or couch cushions. That works for a spell, until it becomes clear that your body is situated in a tedious, low-impact plank, while, in the pages below, Raskolnikov brandishes his axe and kills everyone in sight.&lt;/p&gt;
    &lt;p&gt;I cycle through all of these postures, over and over again, hoping to finally crack the code—unlocking the sublime Zen of the novel, the fabled joys of reading. When I put out the call to my friends and colleagues to see if they related to my plight, I quickly learned that all of us are languishing on this futile journey. Slate associate editor Bryan Lowder recalled that while leafing through a supremely unwieldy hardcover tome containing the collected Earth Sea novels, he was forced to stack three pillows against his headboard and another on his abdomen in order to remain sound of body while tracing the adventures of Sparrowhawk. My friend Laura Grasso—a costume designer, and a woman who recently finished The Brothers Karamazov—has developed a complicated anthropometrical schematic in which she props her entire body on the padded slope of a couch’s armrest, with the book balanced delicately in her eyeline. (“I try to go full diagonal,” she said. “That’s by far the most optimal approach.”) Others have developed a Stockholm syndrome–esque relationship with the agony of reading, interpreting the pain as a sign of virtue. Slate senior editor Tony Ho Tran said that he is of the opinion that he “needs to be a little uncomfortable” to concentrate on his literature. “Give me a weird wooden dining chair,” he proclaimed. “Give me a plastic seat on the train while I commute.”&lt;/p&gt;
    &lt;p&gt;Surely it doesn’t have to be this way, right? Shouldn’t we, as a species, have evolved to possess some sort of natural lumbar support—or some bracing callouses—to assist in the time-honored tradition of reading words printed on paper? Can it be that Moses, descending from Mount Sinai with stone tablets consecrated by God himself, was left with a sore neck while deciphering the Ten Commandments? Well, according to Ryan Steiner, a physical therapist at the Cleveland Clinic, the answer is yes. Reading, as it turns out, forces the body into a totally unnatural form. There’s nothing any of us can do.&lt;/p&gt;
    &lt;p&gt;“Honestly, we’re not meant to stay in one position, even if it is a comfortable position, for an extended period of time,” said Steiner. “You should be changing positions often when you’re reading. I recommend getting up and moving around every so often.”&lt;/p&gt;
    &lt;p&gt;Steiner happily broke down the physics for me. Threaded throughout our nervous system are microscopic electrical sensors called “mechanoreceptors.” These nerves alert our body to the way we’re stretching, compressing, or otherwise adding tension to our soft tissue. This is true if you’re doing deadlifts, and also true if you are holding a book in front of your face. “After a while, those receptors send a message to your brain like, ‘Hey, there’s something going on here, this doesn’t feel natural, you need to take action,’ ” said Steiner. This is when we adjust our dimensions to find a more comfortable position, repeating the circuit over and over again for as long as we have a book in our hands. Maybe you find it baffling that a novel could put the same pressure on our bodies as, say, a bag of concrete, but Steiner is quick to remind me that with enough time, just about anything can become unwieldy.&lt;/p&gt;
    &lt;p&gt;“A little bit of force can still make a big difference. If you’re holding something relatively lightweight—like a 3-pound weight—down by your side, you could do that for hours. But if you’re holding it in front of your face? You might not be able to make it a minute.”&lt;/p&gt;
    &lt;p&gt;For what it’s worth, the forces of technology are rising to meet the reading problem. We have all heard of bookstands, which can be installed in bed or in the bath, allowing one’s hands to be occupied by a chilly pinot noir while surveying a gooey romance novel. But those who prefer to read on tablets have taken matters much further. I reached out to Chelsea Stone, who works for CNN, and who recently reviewed a truly revolutionary contraption that fastened her e-reader to a modular silicone mount. She winched the neck of the crane over her mattress, letting the tablet hover gracefully in front of her eyes while she was lying in bed. To turn the pages, Stone used a Bluetooth remote. Her hands never needed to exit the covers. It was an airtight cocoon of literary bliss, reminiscent of those mobile lounge chairs employed by the sedentary refugees in Wall-E. Stone had rendered the human limit obsolete—banishing those damn mechanoreceptors—once and for all.&lt;/p&gt;
    &lt;p&gt;“I can’t tell you how many times I’ve dozed off with a book in my hands only to be woken by it smacking me in the forehead,” said Stone. “The stand gives me freedom to read in any position I want at the moment.”&lt;/p&gt;
    &lt;p&gt;And yet, Stone, an avid bibliophile, tells me that she still likes to read books the old-fashioned way. I can understand why. A mount to hold your Kindle might be physically prudent, but it seems spiritually diminished to me. Ultimately, I like to read for the many accessories of literature; the way the ritual can brighten an ordinary day. Consider the accidental discovery of an ideal nook—a coffee shop, a park, a beach—ready-made for whatever novel you’re carrying around in your backpack. Time stops, and your imagination fissures open. My hip flexors scream for mercy as I lie on my side, quieting my mind. We’ve been reading books for a thousand years. Clearly, it must be worth the pain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://slate.com/life/2026/01/body-books-reading-position-posture-pain.html"/><published>2026-01-19T18:53:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46683205</id><title>Letter from a Birmingham Jail [King, Jr.] (1963)</title><updated>2026-01-19T19:36:52.686727+00:00</updated><content>&lt;doc fingerprint="a7e1511d86e20751"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;p&gt;"Letter from a Birmingham Jail [King, Jr.]"&lt;/p&gt;
      &lt;p&gt;16 April 1963&lt;lb/&gt; My Dear Fellow Clergymen:&lt;lb/&gt; While confined here in the Birmingham city jail, I came across your recent statement calling my present activities "unwise and untimely." Seldom do I pause to answer criticism of my work and ideas. If I sought to answer all the criticisms that cross my desk, my secretaries would have little time for anything other than such correspondence in the course of the day, and I would have no time for constructive work. But since I feel that you are men of genuine good will and that your criticisms are sincerely set forth, I want to try to answer your statement in what I hope will be patient and reasonable terms.&lt;/p&gt;
      &lt;p&gt;I think I should indicate why I am here in Birmingham, since you have been influenced by the view which argues against "outsiders coming in." I have the honor of serving as president of the Southern Christian Leadership Conference, an organization operating in every southern state, with headquarters in Atlanta, Georgia. We have some eighty five affiliated organizations across the South, and one of them is the Alabama Christian Movement for Human Rights. Frequently we share staff, educational and financial resources with our affiliates. Several months ago the affiliate here in Birmingham asked us to be on call to engage in a nonviolent direct action program if such were deemed necessary. We readily consented, and when the hour came we lived up to our promise. So I, along with several members of my staff, am here because I was invited here. I am here because I have organizational ties here.&lt;/p&gt;
      &lt;p&gt;But more basically, I am in Birmingham because injustice is here. Just as the prophets of the eighth century B.C. left their villages and carried their "thus saith the Lord" far beyond the boundaries of their home towns, and just as the Apostle Paul left his village of Tarsus and carried the gospel of Jesus Christ to the far corners of the Greco Roman world, so am I compelled to carry the gospel of freedom beyond my own home town. Like Paul, I must constantly respond to the Macedonian call for aid.&lt;/p&gt;
      &lt;p&gt;Moreover, I am cognizant of the interrelatedness of all communities and states. I cannot sit idly by in Atlanta and not be concerned about what happens in Birmingham. Injustice anywhere is a threat to justice everywhere. We are caught in an inescapable network of mutuality, tied in a single garment of destiny. Whatever affects one directly, affects all indirectly. Never again can we afford to live with the narrow, provincial "outside agitator" idea. Anyone who lives inside the United States can never be considered an outsider anywhere within its bounds.&lt;/p&gt;
      &lt;p&gt;You deplore the demonstrations taking place in Birmingham. But your statement, I am sorry to say, fails to express a similar concern for the conditions that brought about the demonstrations. I am sure that none of you would want to rest content with the superficial kind of social analysis that deals merely with effects and does not grapple with underlying causes. It is unfortunate that demonstrations are taking place in Birmingham, but it is even more unfortunate that the city's white power structure left the Negro community with no alternative.&lt;/p&gt;
      &lt;p&gt;In any nonviolent campaign there are four basic steps: collection of the facts to determine whether injustices exist; negotiation; self purification; and direct action. We have gone through all these steps in Birmingham. There can be no gainsaying the fact that racial injustice engulfs this community. Birmingham is probably the most thoroughly segregated city in the United States. Its ugly record of brutality is widely known. Negroes have experienced grossly unjust treatment in the courts. There have been more unsolved bombings of Negro homes and churches in Birmingham than in any other city in the nation. These are the hard, brutal facts of the case. On the basis of these conditions, Negro leaders sought to negotiate with the city fathers. But the latter consistently refused to engage in good faith negotiation.&lt;/p&gt;
      &lt;p&gt;Then, last September, came the opportunity to talk with leaders of Birmingham's economic community. In the course of the negotiations, certain promises were made by the merchants--for example, to remove the stores' humiliating racial signs. On the basis of these promises, the Reverend Fred Shuttlesworth and the leaders of the Alabama Christian Movement for Human Rights agreed to a moratorium on all demonstrations. As the weeks and months went by, we realized that we were the victims of a broken promise. A few signs, briefly removed, returned; the others remained. As in so many past experiences, our hopes had been blasted, and the shadow of deep disappointment settled upon us. We had no alternative except to prepare for direct action, whereby we would present our very bodies as a means of laying our case before the conscience of the local and the national community. Mindful of the difficulties involved, we decided to undertake a process of self purification. We began a series of workshops on nonviolence, and we repeatedly asked ourselves: "Are you able to accept blows without retaliating?" "Are you able to endure the ordeal of jail?" We decided to schedule our direct action program for the Easter season, realizing that except for Christmas, this is the main shopping period of the year. Knowing that a strong economic-withdrawal program would be the by product of direct action, we felt that this would be the best time to bring pressure to bear on the merchants for the needed change.&lt;/p&gt;
      &lt;p&gt;Then it occurred to us that Birmingham's mayoral election was coming up in March, and we speedily decided to postpone action until after election day. When we discovered that the Commissioner of Public Safety, Eugene "Bull" Connor, had piled up enough votes to be in the run off, we decided again to postpone action until the day after the run off so that the demonstrations could not be used to cloud the issues. Like many others, we waited to see Mr. Connor defeated, and to this end we endured postponement after postponement. Having aided in this community need, we felt that our direct action program could be delayed no longer.&lt;/p&gt;
      &lt;p&gt;You may well ask: "Why direct action? Why sit ins, marches and so forth? Isn't negotiation a better path?" You are quite right in calling for negotiation. Indeed, this is the very purpose of direct action. Nonviolent direct action seeks to create such a crisis and foster such a tension that a community which has constantly refused to negotiate is forced to confront the issue. It seeks so to dramatize the issue that it can no longer be ignored. My citing the creation of tension as part of the work of the nonviolent resister may sound rather shocking. But I must confess that I am not afraid of the word "tension." I have earnestly opposed violent tension, but there is a type of constructive, nonviolent tension which is necessary for growth. Just as Socrates felt that it was necessary to create a tension in the mind so that individuals could rise from the bondage of myths and half truths to the unfettered realm of creative analysis and objective appraisal, so must we see the need for nonviolent gadflies to create the kind of tension in society that will help men rise from the dark depths of prejudice and racism to the majestic heights of understanding and brotherhood. The purpose of our direct action program is to create a situation so crisis packed that it will inevitably open the door to negotiation. I therefore concur with you in your call for negotiation. Too long has our beloved Southland been bogged down in a tragic effort to live in monologue rather than dialogue.&lt;/p&gt;
      &lt;p&gt;One of the basic points in your statement is that the action that I and my associates have taken in Birmingham is untimely. Some have asked: "Why didn't you give the new city administration time to act?" The only answer that I can give to this query is that the new Birmingham administration must be prodded about as much as the outgoing one, before it will act. We are sadly mistaken if we feel that the election of Albert Boutwell as mayor will bring the millennium to Birmingham. While Mr. Boutwell is a much more gentle person than Mr. Connor, they are both segregationists, dedicated to maintenance of the status quo. I have hope that Mr. Boutwell will be reasonable enough to see the futility of massive resistance to desegregation. But he will not see this without pressure from devotees of civil rights. My friends, I must say to you that we have not made a single gain in civil rights without determined legal and nonviolent pressure. Lamentably, it is an historical fact that privileged groups seldom give up their privileges voluntarily. Individuals may see the moral light and voluntarily give up their unjust posture; but, as Reinhold Niebuhr has reminded us, groups tend to be more immoral than individuals.&lt;/p&gt;
      &lt;p&gt;We know through painful experience that freedom is never voluntarily given by the oppressor; it must be demanded by the oppressed. Frankly, I have yet to engage in a direct action campaign that was "well timed" in the view of those who have not suffered unduly from the disease of segregation. For years now I have heard the word "Wait!" It rings in the ear of every Negro with piercing familiarity. This "Wait" has almost always meant "Never." We must come to see, with one of our distinguished jurists, that "justice too long delayed is justice denied."&lt;/p&gt;
      &lt;p&gt;We have waited for more than 340 years for our constitutional and God given rights. The nations of Asia and Africa are moving with jetlike speed toward gaining political independence, but we still creep at horse and buggy pace toward gaining a cup of coffee at a lunch counter. Perhaps it is easy for those who have never felt the stinging darts of segregation to say, "Wait." But when you have seen vicious mobs lynch your mothers and fathers at will and drown your sisters and brothers at whim; when you have seen hate filled policemen curse, kick and even kill your black brothers and sisters; when you see the vast majority of your twenty million Negro brothers smothering in an airtight cage of poverty in the midst of an affluent society; when you suddenly find your tongue twisted and your speech stammering as you seek to explain to your six year old daughter why she can't go to the public amusement park that has just been advertised on television, and see tears welling up in her eyes when she is told that Funtown is closed to colored children, and see ominous clouds of inferiority beginning to form in her little mental sky, and see her beginning to distort her personality by developing an unconscious bitterness toward white people; when you have to concoct an answer for a five year old son who is asking: "Daddy, why do white people treat colored people so mean?"; when you take a cross county drive and find it necessary to sleep night after night in the uncomfortable corners of your automobile because no motel will accept you; when you are humiliated day in and day out by nagging signs reading "white" and "colored"; when your first name becomes "nigger," your middle name becomes "boy" (however old you are) and your last name becomes "John," and your wife and mother are never given the respected title "Mrs."; when you are harried by day and haunted by night by the fact that you are a Negro, living constantly at tiptoe stance, never quite knowing what to expect next, and are plagued with inner fears and outer resentments; when you are forever fighting a degenerating sense of "nobodiness"--then you will understand why we find it difficult to wait. There comes a time when the cup of endurance runs over, and men are no longer willing to be plunged into the abyss of despair. I hope, sirs, you can understand our legitimate and unavoidable impatience. You express a great deal of anxiety over our willingness to break laws. This is certainly a legitimate concern. Since we so diligently urge people to obey the Supreme Court's decision of 1954 outlawing segregation in the public schools, at first glance it may seem rather paradoxical for us consciously to break laws. One may well ask: "How can you advocate breaking some laws and obeying others?" The answer lies in the fact that there are two types of laws: just and unjust. I would be the first to advocate obeying just laws. One has not only a legal but a moral responsibility to obey just laws. Conversely, one has a moral responsibility to disobey unjust laws. I would agree with St. Augustine that "an unjust law is no law at all."&lt;/p&gt;
      &lt;p&gt;Now, what is the difference between the two? How does one determine whether a law is just or unjust? A just law is a man made code that squares with the moral law or the law of God. An unjust law is a code that is out of harmony with the moral law. To put it in the terms of St. Thomas Aquinas: An unjust law is a human law that is not rooted in eternal law and natural law. Any law that uplifts human personality is just. Any law that degrades human personality is unjust. All segregation statutes are unjust because segregation distorts the soul and damages the personality. It gives the segregator a false sense of superiority and the segregated a false sense of inferiority. Segregation, to use the terminology of the Jewish philosopher Martin Buber, substitutes an "I it" relationship for an "I thou" relationship and ends up relegating persons to the status of things. Hence segregation is not only politically, economically and sociologically unsound, it is morally wrong and sinful. Paul Tillich has said that sin is separation. Is not segregation an existential expression of man's tragic separation, his awful estrangement, his terrible sinfulness? Thus it is that I can urge men to obey the 1954 decision of the Supreme Court, for it is morally right; and I can urge them to disobey segregation ordinances, for they are morally wrong.&lt;/p&gt;
      &lt;p&gt;Let us consider a more concrete example of just and unjust laws. An unjust law is a code that a numerical or power majority group compels a minority group to obey but does not make binding on itself. This is difference made legal. By the same token, a just law is a code that a majority compels a minority to follow and that it is willing to follow itself. This is sameness made legal. Let me give another explanation. A law is unjust if it is inflicted on a minority that, as a result of being denied the right to vote, had no part in enacting or devising the law. Who can say that the legislature of Alabama which set up that state's segregation laws was democratically elected? Throughout Alabama all sorts of devious methods are used to prevent Negroes from becoming registered voters, and there are some counties in which, even though Negroes constitute a majority of the population, not a single Negro is registered. Can any law enacted under such circumstances be considered democratically structured?&lt;/p&gt;
      &lt;p&gt;Sometimes a law is just on its face and unjust in its application. For instance, I have been arrested on a charge of parading without a permit. Now, there is nothing wrong in having an ordinance which requires a permit for a parade. But such an ordinance becomes unjust when it is used to maintain segregation and to deny citizens the First-Amendment privilege of peaceful assembly and protest.&lt;/p&gt;
      &lt;p&gt;I hope you are able to see the distinction I am trying to point out. In no sense do I advocate evading or defying the law, as would the rabid segregationist. That would lead to anarchy. One who breaks an unjust law must do so openly, lovingly, and with a willingness to accept the penalty. I submit that an individual who breaks a law that conscience tells him is unjust, and who willingly accepts the penalty of imprisonment in order to arouse the conscience of the community over its injustice, is in reality expressing the highest respect for law.&lt;/p&gt;
      &lt;p&gt;Of course, there is nothing new about this kind of civil disobedience. It was evidenced sublimely in the refusal of Shadrach, Meshach and Abednego to obey the laws of Nebuchadnezzar, on the ground that a higher moral law was at stake. It was practiced superbly by the early Christians, who were willing to face hungry lions and the excruciating pain of chopping blocks rather than submit to certain unjust laws of the Roman Empire. To a degree, academic freedom is a reality today because Socrates practiced civil disobedience. In our own nation, the Boston Tea Party represented a massive act of civil disobedience.&lt;/p&gt;
      &lt;p&gt;We should never forget that everything Adolf Hitler did in Germany was "legal" and everything the Hungarian freedom fighters did in Hungary was "illegal." It was "illegal" to aid and comfort a Jew in Hitler's Germany. Even so, I am sure that, had I lived in Germany at the time, I would have aided and comforted my Jewish brothers. If today I lived in a Communist country where certain principles dear to the Christian faith are suppressed, I would openly advocate disobeying that country's antireligious laws.&lt;/p&gt;
      &lt;p&gt;I must make two honest confessions to you, my Christian and Jewish brothers. First, I must confess that over the past few years I have been gravely disappointed with the white moderate. I have almost reached the regrettable conclusion that the Negro's great stumbling block in his stride toward freedom is not the White Citizen's Counciler or the Ku Klux Klanner, but the white moderate, who is more devoted to "order" than to justice; who prefers a negative peace which is the absence of tension to a positive peace which is the presence of justice; who constantly says: "I agree with you in the goal you seek, but I cannot agree with your methods of direct action"; who paternalistically believes he can set the timetable for another man's freedom; who lives by a mythical concept of time and who constantly advises the Negro to wait for a "more convenient season." Shallow understanding from people of good will is more frustrating than absolute misunderstanding from people of ill will. Lukewarm acceptance is much more bewildering than outright rejection.&lt;/p&gt;
      &lt;p&gt;I had hoped that the white moderate would understand that law and order exist for the purpose of establishing justice and that when they fail in this purpose they become the dangerously structured dams that block the flow of social progress. I had hoped that the white moderate would understand that the present tension in the South is a necessary phase of the transition from an obnoxious negative peace, in which the Negro passively accepted his unjust plight, to a substantive and positive peace, in which all men will respect the dignity and worth of human personality. Actually, we who engage in nonviolent direct action are not the creators of tension. We merely bring to the surface the hidden tension that is already alive. We bring it out in the open, where it can be seen and dealt with. Like a boil that can never be cured so long as it is covered up but must be opened with all its ugliness to the natural medicines of air and light, injustice must be exposed, with all the tension its exposure creates, to the light of human conscience and the air of national opinion before it can be cured.&lt;/p&gt;
      &lt;p&gt;In your statement you assert that our actions, even though peaceful, must be condemned because they precipitate violence. But is this a logical assertion? Isn't this like condemning a robbed man because his possession of money precipitated the evil act of robbery? Isn't this like condemning Socrates because his unswerving commitment to truth and his philosophical inquiries precipitated the act by the misguided populace in which they made him drink hemlock? Isn't this like condemning Jesus because his unique God consciousness and never ceasing devotion to God's will precipitated the evil act of crucifixion? We must come to see that, as the federal courts have consistently affirmed, it is wrong to urge an individual to cease his efforts to gain his basic constitutional rights because the quest may precipitate violence. Society must protect the robbed and punish the robber. I had also hoped that the white moderate would reject the myth concerning time in relation to the struggle for freedom. I have just received a letter from a white brother in Texas. He writes: "All Christians know that the colored people will receive equal rights eventually, but it is possible that you are in too great a religious hurry. It has taken Christianity almost two thousand years to accomplish what it has. The teachings of Christ take time to come to earth." Such an attitude stems from a tragic misconception of time, from the strangely irrational notion that there is something in the very flow of time that will inevitably cure all ills. Actually, time itself is neutral; it can be used either destructively or constructively. More and more I feel that the people of ill will have used time much more effectively than have the people of good will. We will have to repent in this generation not merely for the hateful words and actions of the bad people but for the appalling silence of the good people. Human progress never rolls in on wheels of inevitability; it comes through the tireless efforts of men willing to be co workers with God, and without this hard work, time itself becomes an ally of the forces of social stagnation. We must use time creatively, in the knowledge that the time is always ripe to do right. Now is the time to make real the promise of democracy and transform our pending national elegy into a creative psalm of brotherhood. Now is the time to lift our national policy from the quicksand of racial injustice to the solid rock of human dignity.&lt;/p&gt;
      &lt;p&gt;You speak of our activity in Birmingham as extreme. At first I was rather disappointed that fellow clergymen would see my nonviolent efforts as those of an extremist. I began thinking about the fact that I stand in the middle of two opposing forces in the Negro community. One is a force of complacency, made up in part of Negroes who, as a result of long years of oppression, are so drained of self respect and a sense of "somebodiness" that they have adjusted to segregation; and in part of a few middle-class Negroes who, because of a degree of academic and economic security and because in some ways they profit by segregation, have become insensitive to the problems of the masses. The other force is one of bitterness and hatred, and it comes perilously close to advocating violence. It is expressed in the various black nationalist groups that are springing up across the nation, the largest and best known being Elijah Muhammad's Muslim movement. Nourished by the Negro's frustration over the continued existence of racial discrimination, this movement is made up of people who have lost faith in America, who have absolutely repudiated Christianity, and who have concluded that the white man is an incorrigible "devil."&lt;/p&gt;
      &lt;p&gt;I have tried to stand between these two forces, saying that we need emulate neither the "do nothingism" of the complacent nor the hatred and despair of the black nationalist. For there is the more excellent way of love and nonviolent protest. I am grateful to God that, through the influence of the Negro church, the way of nonviolence became an integral part of our struggle. If this philosophy had not emerged, by now many streets of the South would, I am convinced, be flowing with blood. And I am further convinced that if our white brothers dismiss as "rabble rousers" and "outside agitators" those of us who employ nonviolent direct action, and if they refuse to support our nonviolent efforts, millions of Negroes will, out of frustration and despair, seek solace and security in black nationalist ideologies--a development that would inevitably lead to a frightening racial nightmare.&lt;/p&gt;
      &lt;p&gt;Oppressed people cannot remain oppressed forever. The yearning for freedom eventually manifests itself, and that is what has happened to the American Negro. Something within has reminded him of his birthright of freedom, and something without has reminded him that it can be gained. Consciously or unconsciously, he has been caught up by the Zeitgeist, and with his black brothers of Africa and his brown and yellow brothers of Asia, South America and the Caribbean, the United States Negro is moving with a sense of great urgency toward the promised land of racial justice. If one recognizes this vital urge that has engulfed the Negro community, one should readily understand why public demonstrations are taking place. The Negro has many pent up resentments and latent frustrations, and he must release them. So let him march; let him make prayer pilgrimages to the city hall; let him go on freedom rides -and try to understand why he must do so. If his repressed emotions are not released in nonviolent ways, they will seek expression through violence; this is not a threat but a fact of history. So I have not said to my people: "Get rid of your discontent." Rather, I have tried to say that this normal and healthy discontent can be channeled into the creative outlet of nonviolent direct action. And now this approach is being termed extremist. But though I was initially disappointed at being categorized as an extremist, as I continued to think about the matter I gradually gained a measure of satisfaction from the label. Was not Jesus an extremist for love: "Love your enemies, bless them that curse you, do good to them that hate you, and pray for them which despitefully use you, and persecute you." Was not Amos an extremist for justice: "Let justice roll down like waters and righteousness like an ever flowing stream." Was not Paul an extremist for the Christian gospel: "I bear in my body the marks of the Lord Jesus." Was not Martin Luther an extremist: "Here I stand; I cannot do otherwise, so help me God." And John Bunyan: "I will stay in jail to the end of my days before I make a butchery of my conscience." And Abraham Lincoln: "This nation cannot survive half slave and half free." And Thomas Jefferson: "We hold these truths to be self evident, that all men are created equal . . ." So the question is not whether we will be extremists, but what kind of extremists we will be. Will we be extremists for hate or for love? Will we be extremists for the preservation of injustice or for the extension of justice? In that dramatic scene on Calvary's hill three men were crucified. We must never forget that all three were crucified for the same crime--the crime of extremism. Two were extremists for immorality, and thus fell below their environment. The other, Jesus Christ, was an extremist for love, truth and goodness, and thereby rose above his environment. Perhaps the South, the nation and the world are in dire need of creative extremists.&lt;/p&gt;
      &lt;p&gt;I had hoped that the white moderate would see this need. Perhaps I was too optimistic; perhaps I expected too much. I suppose I should have realized that few members of the oppressor race can understand the deep groans and passionate yearnings of the oppressed race, and still fewer have the vision to see that injustice must be rooted out by strong, persistent and determined action. I am thankful, however, that some of our white brothers in the South have grasped the meaning of this social revolution and committed themselves to it. They are still all too few in quantity, but they are big in quality. Some -such as Ralph McGill, Lillian Smith, Harry Golden, James McBride Dabbs, Ann Braden and Sarah Patton Boyle--have written about our struggle in eloquent and prophetic terms. Others have marched with us down nameless streets of the South. They have languished in filthy, roach infested jails, suffering the abuse and brutality of policemen who view them as "dirty nigger-lovers." Unlike so many of their moderate brothers and sisters, they have recognized the urgency of the moment and sensed the need for powerful "action" antidotes to combat the disease of segregation. Let me take note of my other major disappointment. I have been so greatly disappointed with the white church and its leadership. Of course, there are some notable exceptions. I am not unmindful of the fact that each of you has taken some significant stands on this issue. I commend you, Reverend Stallings, for your Christian stand on this past Sunday, in welcoming Negroes to your worship service on a nonsegregated basis. I commend the Catholic leaders of this state for integrating Spring Hill College several years ago.&lt;/p&gt;
      &lt;p&gt;But despite these notable exceptions, I must honestly reiterate that I have been disappointed with the church. I do not say this as one of those negative critics who can always find something wrong with the church. I say this as a minister of the gospel, who loves the church; who was nurtured in its bosom; who has been sustained by its spiritual blessings and who will remain true to it as long as the cord of life shall lengthen.&lt;/p&gt;
      &lt;p&gt;When I was suddenly catapulted into the leadership of the bus protest in Montgomery, Alabama, a few years ago, I felt we would be supported by the white church. I felt that the white ministers, priests and rabbis of the South would be among our strongest allies. Instead, some have been outright opponents, refusing to understand the freedom movement and misrepresenting its leaders; all too many others have been more cautious than courageous and have remained silent behind the anesthetizing security of stained glass windows.&lt;/p&gt;
      &lt;p&gt;In spite of my shattered dreams, I came to Birmingham with the hope that the white religious leadership of this community would see the justice of our cause and, with deep moral concern, would serve as the channel through which our just grievances could reach the power structure. I had hoped that each of you would understand. But again I have been disappointed.&lt;/p&gt;
      &lt;p&gt;I have heard numerous southern religious leaders admonish their worshipers to comply with a desegregation decision because it is the law, but I have longed to hear white ministers declare: "Follow this decree because integration is morally right and because the Negro is your brother." In the midst of blatant injustices inflicted upon the Negro, I have watched white churchmen stand on the sideline and mouth pious irrelevancies and sanctimonious trivialities. In the midst of a mighty struggle to rid our nation of racial and economic injustice, I have heard many ministers say: "Those are social issues, with which the gospel has no real concern." And I have watched many churches commit themselves to a completely other worldly religion which makes a strange, un-Biblical distinction between body and soul, between the sacred and the secular.&lt;/p&gt;
      &lt;p&gt;I have traveled the length and breadth of Alabama, Mississippi and all the other southern states. On sweltering summer days and crisp autumn mornings I have looked at the South's beautiful churches with their lofty spires pointing heavenward. I have beheld the impressive outlines of her massive religious education buildings. Over and over I have found myself asking: "What kind of people worship here? Who is their God? Where were their voices when the lips of Governor Barnett dripped with words of interposition and nullification? Where were they when Governor Wallace gave a clarion call for defiance and hatred? Where were their voices of support when bruised and weary Negro men and women decided to rise from the dark dungeons of complacency to the bright hills of creative protest?"&lt;/p&gt;
      &lt;p&gt;Yes, these questions are still in my mind. In deep disappointment I have wept over the laxity of the church. But be assured that my tears have been tears of love. There can be no deep disappointment where there is not deep love. Yes, I love the church. How could I do otherwise? I am in the rather unique position of being the son, the grandson and the great grandson of preachers. Yes, I see the church as the body of Christ. But, oh! How we have blemished and scarred that body through social neglect and through fear of being nonconformists.&lt;/p&gt;
      &lt;p&gt;There was a time when the church was very powerful--in the time when the early Christians rejoiced at being deemed worthy to suffer for what they believed. In those days the church was not merely a thermometer that recorded the ideas and principles of popular opinion; it was a thermostat that transformed the mores of society. Whenever the early Christians entered a town, the people in power became disturbed and immediately sought to convict the Christians for being "disturbers of the peace" and "outside agitators."' But the Christians pressed on, in the conviction that they were "a colony of heaven," called to obey God rather than man. Small in number, they were big in commitment. They were too God-intoxicated to be "astronomically intimidated." By their effort and example they brought an end to such ancient evils as infanticide and gladiatorial contests. Things are different now. So often the contemporary church is a weak, ineffectual voice with an uncertain sound. So often it is an archdefender of the status quo. Far from being disturbed by the presence of the church, the power structure of the average community is consoled by the church's silent--and often even vocal--sanction of things as they are.&lt;/p&gt;
      &lt;p&gt;But the judgment of God is upon the church as never before. If today's church does not recapture the sacrificial spirit of the early church, it will lose its authenticity, forfeit the loyalty of millions, and be dismissed as an irrelevant social club with no meaning for the twentieth century. Every day I meet young people whose disappointment with the church has turned into outright disgust.&lt;/p&gt;
      &lt;p&gt;Perhaps I have once again been too optimistic. Is organized religion too inextricably bound to the status quo to save our nation and the world? Perhaps I must turn my faith to the inner spiritual church, the church within the church, as the true ekklesia and the hope of the world. But again I am thankful to God that some noble souls from the ranks of organized religion have broken loose from the paralyzing chains of conformity and joined us as active partners in the struggle for freedom. They have left their secure congregations and walked the streets of Albany, Georgia, with us. They have gone down the highways of the South on tortuous rides for freedom. Yes, they have gone to jail with us. Some have been dismissed from their churches, have lost the support of their bishops and fellow ministers. But they have acted in the faith that right defeated is stronger than evil triumphant. Their witness has been the spiritual salt that has preserved the true meaning of the gospel in these troubled times. They have carved a tunnel of hope through the dark mountain of disappointment. I hope the church as a whole will meet the challenge of this decisive hour. But even if the church does not come to the aid of justice, I have no despair about the future. I have no fear about the outcome of our struggle in Birmingham, even if our motives are at present misunderstood. We will reach the goal of freedom in Birmingham and all over the nation, because the goal of America is freedom. Abused and scorned though we may be, our destiny is tied up with America's destiny. Before the pilgrims landed at Plymouth, we were here. Before the pen of Jefferson etched the majestic words of the Declaration of Independence across the pages of history, we were here. For more than two centuries our forebears labored in this country without wages; they made cotton king; they built the homes of their masters while suffering gross injustice and shameful humiliation -and yet out of a bottomless vitality they continued to thrive and develop. If the inexpressible cruelties of slavery could not stop us, the opposition we now face will surely fail. We will win our freedom because the sacred heritage of our nation and the eternal will of God are embodied in our echoing demands. Before closing I feel impelled to mention one other point in your statement that has troubled me profoundly. You warmly commended the Birmingham police force for keeping "order" and "preventing violence." I doubt that you would have so warmly commended the police force if you had seen its dogs sinking their teeth into unarmed, nonviolent Negroes. I doubt that you would so quickly commend the policemen if you were to observe their ugly and inhumane treatment of Negroes here in the city jail; if you were to watch them push and curse old Negro women and young Negro girls; if you were to see them slap and kick old Negro men and young boys; if you were to observe them, as they did on two occasions, refuse to give us food because we wanted to sing our grace together. I cannot join you in your praise of the Birmingham police department.&lt;/p&gt;
      &lt;p&gt;It is true that the police have exercised a degree of discipline in handling the demonstrators. In this sense they have conducted themselves rather "nonviolently" in public. But for what purpose? To preserve the evil system of segregation. Over the past few years I have consistently preached that nonviolence demands that the means we use must be as pure as the ends we seek. I have tried to make clear that it is wrong to use immoral means to attain moral ends. But now I must affirm that it is just as wrong, or perhaps even more so, to use moral means to preserve immoral ends. Perhaps Mr. Connor and his policemen have been rather nonviolent in public, as was Chief Pritchett in Albany, Georgia, but they have used the moral means of nonviolence to maintain the immoral end of racial injustice. As T. S. Eliot has said: "The last temptation is the greatest treason: To do the right deed for the wrong reason."&lt;/p&gt;
      &lt;p&gt;I wish you had commended the Negro sit inners and demonstrators of Birmingham for their sublime courage, their willingness to suffer and their amazing discipline in the midst of great provocation. One day the South will recognize its real heroes. They will be the James Merediths, with the noble sense of purpose that enables them to face jeering and hostile mobs, and with the agonizing loneliness that characterizes the life of the pioneer. They will be old, oppressed, battered Negro women, symbolized in a seventy two year old woman in Montgomery, Alabama, who rose up with a sense of dignity and with her people decided not to ride segregated buses, and who responded with ungrammatical profundity to one who inquired about her weariness: "My feets is tired, but my soul is at rest." They will be the young high school and college students, the young ministers of the gospel and a host of their elders, courageously and nonviolently sitting in at lunch counters and willingly going to jail for conscience' sake. One day the South will know that when these disinherited children of God sat down at lunch counters, they were in reality standing up for what is best in the American dream and for the most sacred values in our Judaeo Christian heritage, thereby bringing our nation back to those great wells of democracy which were dug deep by the founding fathers in their formulation of the Constitution and the Declaration of Independence.&lt;/p&gt;
      &lt;p&gt;Never before have I written so long a letter. I'm afraid it is much too long to take your precious time. I can assure you that it would have been much shorter if I had been writing from a comfortable desk, but what else can one do when he is alone in a narrow jail cell, other than write long letters, think long thoughts and pray long prayers?&lt;/p&gt;
      &lt;p&gt;If I have said anything in this letter that overstates the truth and indicates an unreasonable impatience, I beg you to forgive me. If I have said anything that understates the truth and indicates my having a patience that allows me to settle for anything less than brotherhood, I beg God to forgive me.&lt;/p&gt;
      &lt;p&gt;I hope this letter finds you strong in the faith. I also hope that circumstances will soon make it possible for me to meet each of you, not as an integrationist or a civil-rights leader but as a fellow clergyman and a Christian brother. Let us all hope that the dark clouds of racial prejudice will soon pass away and the deep fog of misunderstanding will be lifted from our fear drenched communities, and in some not too distant tomorrow the radiant stars of love and brotherhood will shine over our great nation with all their scintillating beauty.&lt;/p&gt;
      &lt;p&gt;Yours for the cause of Peace and Brotherhood, Martin Luther King, Jr.&lt;lb/&gt; Published in:&lt;lb/&gt; King, Martin Luther Jr. &lt;/p&gt;
      &lt;p&gt;Page Editor: Ali B. Ali-Dinar, Ph.D.&lt;/p&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html"/><published>2026-01-19T19:17:52+00:00</published></entry></feed>