<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-28T13:45:14.743594+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45721801</id><title>Pyrex catalog from from 1938 with hand-drawn lab glassware [pdf]</title><updated>2025-10-28T13:45:28.332709+00:00</updated><content/><link href="https://exhibitdb.cmog.org/opacimages/Images/Pyrex/Rakow_1000132877.pdf"/><published>2025-10-27T15:04:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45722639</id><title>Claude for Excel</title><updated>2025-10-28T13:45:28.051985+00:00</updated><content>&lt;doc fingerprint="3d3f8e961dffc20a"&gt;
  &lt;main&gt;
    &lt;p&gt;Piloting Claude for Excel&lt;/p&gt;
    &lt;p&gt;Claude understands your entire workbookâfrom nested formulas to multiple tab dependencies. Get explanations with cell-level citations, and update assumptions while preserving formulas. Now in beta as a research preview.&lt;/p&gt;
    &lt;head rend="h2"&gt;How teams use Claude for Excel&lt;/head&gt;
    &lt;p&gt;Claude listens carefully, follows instructions precisely, â¨and thinks through complex problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Get answers about any cell in seconds&lt;/head&gt;
    &lt;p&gt;Navigate complex models instantly. Ask Claude about specific formulas, entire worksheets, or calculation flows across tabs. Every explanation includes cell-level citations so you can verify the logic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Test scenarios without breaking formulas&lt;/head&gt;
    &lt;p&gt;Update assumptions across your entire model while preserving all dependencies. Test different scenarios quicklyâClaude highlights every change with explanations for full transparency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Debug and fix errors&lt;/head&gt;
    &lt;p&gt;Trace #REF!, #VALUE!, and circular reference errors to their source in seconds. Claude explains what went wrong and how to fix it without disrupting the rest of your model.&lt;/p&gt;
    &lt;head rend="h3"&gt;Build models or fill existing templates&lt;/head&gt;
    &lt;p&gt;Create draft financial models from scratch based on your requirements. Or populate existing templates with fresh data while maintaining all formulas and structure.&lt;/p&gt;
    &lt;p&gt;The Claude you trust, right in Excel&lt;/p&gt;
    &lt;head rend="h3"&gt;Transparency and visibility&lt;/head&gt;
    &lt;p&gt;See Claudeâs changes in real time with explanations&lt;/p&gt;
    &lt;head rend="h3"&gt;Formula integrity&lt;/head&gt;
    &lt;p&gt;Maintain Excel model structure and formatting&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise security&lt;/head&gt;
    &lt;p&gt;Works within your existing compliance framework&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;Claude for Excel is available in beta as a research preview through a waitlist for 1,000 Max, Team and Enterprise plan customers. Weâll gradually expand access as we build confidence through this limited preview.&lt;/p&gt;
    &lt;p&gt;Claude for Excel works within your existing security framework. Claude can make mistakes, so you should always review changes before finalizing, especially for client-facing deliverables.&lt;/p&gt;
    &lt;p&gt;Claude for Excel is currently in beta as a research preview, so itâs best for model analysis, assumption updates, error debugging, template population, formula explanations, multi-tab navigation. Claude doesnât have advanced Excel capabilities including pivot tables, conditional formatting, data validation, data tables, macros, and VBA. Weâre actively working on these features.&lt;/p&gt;
    &lt;p&gt;Yes, Claude is trained to recognize common financial modeling patterns, formula structures, and industry-standard calculations. However, always verify outputs match your specific methodologies.&lt;/p&gt;
    &lt;p&gt;Currently .xlsx and .xlsm files are supported. File size limits apply based on your Claude plan.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.claude.com/claude-for-excel"/><published>2025-10-27T16:09:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723159</id><title>JetKVM – Control any computer remotely</title><updated>2025-10-28T13:45:27.828511+00:00</updated><content>&lt;doc fingerprint="af5976106919f929"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Ultra-Low Latency&lt;/head&gt;
    &lt;p&gt;High-definition 1080p video at 60 FPS with 30-60 millisecond latency, using efficient H.264 encoding. Smooth mouse and keyboard action transfer for responsive remote interaction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free &amp;amp; Optional Cloud Access&lt;/head&gt;
    &lt;p&gt;Optional remote management via our open-source JetKVM Cloud using WebRTC. Privacy-first design with opt-in cloud access that provides secure and fast direct connections, even behind the most restrictive NAT environments, with our STUN and TURN servers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Source: Built for Collaboration&lt;/head&gt;
    &lt;p&gt;JetKVM is built on a robust Golang foundation and powered by Linux for adaptability and transparency. Whether you're a seasoned developer or an enthusiastic tinkerer, you can easily modify or fine-tune the software using familiar tooling and straightforward SSH uploads.&lt;/p&gt;
    &lt;head rend="h4"&gt;Available Source Code&lt;/head&gt;
    &lt;head rend="h5"&gt;KVM Runtime&lt;/head&gt;
    &lt;p&gt;Combining a Go-based backend with a React-powered WebRTC dashboard. Perfect for forking, submitting new features, fixing bugs, or customizing local streaming and control.&lt;/p&gt;
    &lt;head rend="h5"&gt;Cloud API &amp;amp; Dashboard&lt;/head&gt;
    &lt;p&gt;Our cloud-hosted management interface is fully open source. Delve into our secure remote connection orchestration or fork it to build specialized workflows and unique integrations.&lt;/p&gt;
    &lt;head rend="h5"&gt;Core System&lt;/head&gt;
    &lt;p&gt;Minimal Linux system built with BusyBox for core utilities. No bloat or unnecessary services - just the essential components needed for stable remote access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universally loved&lt;/head&gt;
    &lt;p&gt;Every single tech reviewer who's tested JetKVM has given it a glowing review. No exceptions. From professional data centers to home labs, the verdict is unanimous: this is the remote access solution the tech world has been waiting for.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unlimited Hackability&lt;/head&gt;
    &lt;p&gt;The JetKVM hardware is fully customizable. Through the RJ12 extension port, extra hardware capabilities can easily be added by anyone. The JetKVM extension port is the way to fully customize your device.&lt;/p&gt;
    &lt;head rend="h2"&gt;Seamless Remote Control&lt;/head&gt;
    &lt;p&gt;Experience fluid control and crystal-clear video quality that makes remote access feel local. Perfect for IT professionals, developers, and power users who demand responsive remote management.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay updated on our latest projects&lt;/head&gt;
    &lt;p&gt;Join our newsletter to receive updates about new features, product launches, and early access opportunities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jetkvm.com/"/><published>2025-10-27T16:44:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723359</id><title>Why Busy Beaver hunters fear the Antihydra</title><updated>2025-10-28T13:45:27.487073+00:00</updated><content>&lt;doc fingerprint="eeaad01055b00fc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Busy Beaver Hunters Fear the Antihydra&lt;/head&gt;
    &lt;p&gt;In the summer of 2024, I reported on an online community that nailed down the precise value of a number called BB(5) — the first big breakthrough in 50 years on an old problem in theoretical computer science known as the busy beaver game. BB(5), now known to be 47,176,870, is the fifth of the so-called busy beaver numbers, which measure the complexity of the craziest computations that simple computer programs can complete.1The team recently released a paper describing their results in detail.&lt;/p&gt;
    &lt;p&gt;The next step in this idiosyncratic research effort is to identify the sixth busy beaver number BB(6), and there has been some notable progress on that front — I wrote a follow-up story about it a few months ago. But busy beaver researchers don’t expect to nail down the true value of BB(6) any time soon. That’s because doing so would require them to understand the behavior of a program with the awesome name “Antihydra,” which resembles a longstanding open problem in mathematics called the Collatz conjecture.2Antihydra should not be confused with the false hydra, a very cool and very terrifying monster conceived by D&amp;amp;D blogger Arnold Kemp. A twitter user sharing my first busy beaver story summed up this state of affairs more succinctly:&lt;/p&gt;
    &lt;p&gt;Both of my stories alluded to the Antihydra barrier only very briefly. In this blog post I will explore it in more detail: What exactly is Antihydra, what is the Collatz conjecture, how are they connected, and what makes them so daunting?&lt;/p&gt;
    &lt;head rend="h2"&gt;Busy Beaver Basics&lt;/head&gt;
    &lt;p&gt;If you haven’t already read my two Quanta stories about the busy beaver game, I recommend doing so before reading further, mainly just because they’re both really fun! Here I’ll recap how the busy beaver game works so that we’re all on the same page.&lt;/p&gt;
    &lt;p&gt;I wrote above that the busy beaver numbers “measure the complexity of the craziest computations that simple computer programs can complete.” To define them more precisely, we first need a mathematical framework for gauging the complexity of computer programs themselves, to decide which ones are “simple.” Then we need a way to quantify the complexity of computations — what computer programs do — so that we can identify the craziest ones.&lt;/p&gt;
    &lt;p&gt;In the busy beaver game, computer programs are represented by hypothetical devices called Turing machines, which compute in discrete steps by reading and writing 0s and 1s on an infinite tape divided into cells. A unique list of rules governs the behavior of each Turing machine. Anything you can do with an ordinary computer program, you can in principle do with the right set of Turing machine rules.3In the busy beaver literature, these rules are called “states.” “In principle” is doing a lot of work in this sentence — even if you managed to acquire the requisite infinite tape, computing with a Turing machine would be horrendously inefficient. But Turing machines are easier to analyze theoretically than more practical programming languages.&lt;/p&gt;
    &lt;p&gt;Let’s unpack how Turing machines work in a bit more detail. At each step, a Turing machine consults one of its rules and edits one cell on the tape. Each rule has two cases: what to do if the current cell contains a 0, and what to do if it contains a 1. “What to do” here means what to write in the current cell, which direction to move next, and which rule to consult for the next step. One case of one rule breaks this pattern: It tells the Turing machine to “halt,” or stop running. But by itself, the existence of this instruction doesn’t guarantee that a Turing machine will halt — the machine might never get there. Quanta’s visual designer Kristina Armitage encapsulated all of this in a beautiful infographic.4In my first Busy Beaver story, you will also find animations of Turing machines in action.&lt;/p&gt;
    &lt;p&gt;The number of rules that a Turing machine has will be our measure of program complexity. This choice lets us replace our vague question about the craziest things that simple computer programs can do with a series of specific questions about different degrees of craziness, corresponding to different busy beaver numbers. You learn the value of BB(1) by answering the question “what’s the most complex computation that a one-rule Turing machine can complete?” Likewise, BB(2) measures the most complex computation that a two-rule machine can complete, and so on.&lt;/p&gt;
    &lt;p&gt;To answer these questions, we need a precise definition of what makes one computation more complex than another. A natural measure is how many steps the Turing machine needs to complete the computation. “Complete” is important — every Turing machine that never halts will run for infinitely many steps, but that’s not really a fair comparison. The number of steps that a Turing machine takes before halting (and indeed, whether it halts at all) can depend on the initial pattern of 0s and 1s on the tape. For the busy beaver game, we always start from the so-called “blank tape,” which has 0s in every cell.&lt;/p&gt;
    &lt;p&gt;We now have all the necessary pieces to formally define the busy beaver numbers. Let’s take BB(6) to be specific: It is the longest finite runtime among all six-rule Turing machines, when those machines start with a blank tape. Finding this number is straightforward in principle. First, list out all possible six-rule Turing machines. Next, sort them into two categories: those that will eventually halt when they start running on the blank tape, and those that will run forever. Toss out all the non-halting machines. Finally, measure how many steps each of the halting machines takes before stopping. The largest number is BB(6).&lt;/p&gt;
    &lt;p&gt;The problem with this plan lies in the second step, where you divide the Turing machines into two groups based on whether or not they halt. It turns out that deciding whether a Turing machine will halt can be an extremely hard problem, to put it mildly. And if you can’t tell whether a given machine will halt, then you don’t know whether your list of halting Turing machines is complete, so you can’t know whether you’ve found the longest runtime! As of this writing, researchers have classified the vast majority of six-rule machines as either halting or non-halting. But there are 1,618 “holdouts” whose fate remains unknown.&lt;/p&gt;
    &lt;p&gt;Antihydra is one of these holdout machines. To nail down the value of BB(6), researchers must first determine whether Antihydra halts, and that seems to be beyond the reach of any known mathematical technique. To understand why, we need to take a step back and ask, “what exactly are these Turing machines doing?”&lt;/p&gt;
    &lt;head rend="h2"&gt;Leveling Up&lt;/head&gt;
    &lt;p&gt;You may object at this point that we already know exactly what these Turing machines are doing: Each one is just following a specific sequence of rules, writing 0s and 1s on the tape as it goes. But this “low-level” description is a bit like saying “when I push these buttons, my pocket calculator toggles transistors on and off in this specific pattern.” That may very well be true, but “high-level” descriptions like “when I push these buttons, my pocket calculator multiplies 3 and 4” are usually more useful.&lt;/p&gt;
    &lt;p&gt;There’s no guarantee that any given Turing machine’s behavior admits such a simple high-level description.5Also, in many cases low-level descriptions are perfectly adequate. For example, the easiest way to prove that a Turing machine halts is just to simulate it step by step until it stops running. When that happens, you don’t need a deeper understanding of why it halted: Just note its runtime and move on. But remember that Turing machines can carry out all possible computations — that means that at least some Turing machines must be executing programs with high-level descriptions that humans can understand.&lt;/p&gt;
    &lt;p&gt;Actually, the most notable five- and six-rule Turing machines that busy beaver researchers have studied so far all have relatively simple high-level descriptions — that includes the longest-running five- and six-rule machines that eventually halt, the most complex non-halting five-rule machines, and holdouts like Antihydra.6This is an empirical observation, not a self-evident truth. In fact, some researchers expected that the longest-running Turing machines would be “spaghetti code” machines that lack any high-level description!&lt;/p&gt;
    &lt;p&gt;Let’s look at a specific example. The fifth busy beaver, which runs for 47,176,870 steps before halting, obeys the following low-level rules:&lt;/p&gt;
    &lt;p&gt;In 1993, the mathematician Pascal Michel proved that these rules are equivalent to a simple high-level program:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x = 0\).&lt;/item&gt;
      &lt;item&gt;Divide \(x\) by 3 and check the remainder. &lt;list rend="ul"&gt;&lt;item&gt;If the remainder is 0, calculate \((5x + 18)/3\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If the remainder is 1, calculate \((5x + 22)/3\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If the remainder is 2, halt.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;If you haven’t halted, go back to step 2 and plug in the new value of \(x\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once you have a high-level description like this, you can use it to determine whether the machine will halt — and if so, exactly how many steps it will take.7Each step in a high-level program like this one corresponds to many individual Turing machine steps. Whenever you prove an equivalence between high-level and low-level descriptions, you get formulas that you can use to compute how long each high-level step will take. I won’t say anything about how to actually prove these equivalences. In this case, the high-level program just repeatedly plugs in new values of \(x\) until it finds one that leaves a remainder of 2 when divided by 3. One third of numbers have this property, so you might guess that the program will take three tries to find one, give or take a few. If you start from a random value of \(x\), you’ll find that three iterations is indeed typical. But it turns out that if you start from \(x = 0\), this program will repeat the second step 15 times before it lands on a number with remainder 2! Busy beaver researchers often like to anthropomorphize the Turing machines they study, imagining that the machines are actively trying to run for as long as possible. Adopting that perspective, we might say that this Turing machine got very lucky.&lt;/p&gt;
    &lt;p&gt;The fifth busy beaver is just one member of a family of “Collatz-like” Turing machines whose high-level behavior has the following general form:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x\) equal to some starting value (which may or may not be 0).&lt;/item&gt;
      &lt;item&gt;Divide \(x\) by a fixed number \(N\). The remainder tells you what formula to use to get your new value of \(x\).&lt;/item&gt;
      &lt;item&gt;Check if you’ve met a specific halting condition. If not, go back to step 2 with the new value of \(x\).8As we saw in the above example, the halting condition can be as simple as “the remainder has a specific value.” Below we’ll see some examples with different halting conditions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The family of Collatz-like Turing machines includes both halting and non-halting machines. It gets its name from a procedure for generating number sequences devised in 1937 by the mathematician Lothar Collatz:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Choose a starting value for \(x\).&lt;/item&gt;
      &lt;item&gt;Check whether \(x\) is even or odd. &lt;list rend="ul"&gt;&lt;item&gt;If it’s even, calculate \(x/2\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If it’s odd, calculate \(3x + 1\). The result is your new value of \(x\).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Check whether \(x = 1\). If not, go back to step 2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This looks very similar to our general description of high-level behavior for Collatz-like machines, with \(x = 1\) as the halting condition.9“Check whether \(x\) is even or odd” is just another way of saying “divide \(x\) by 2 and check the remainder.” Strictly speaking, we don’t have to specify that the sequence stops when \(x = 1\). But if we keep applying the rules after it hits 1, the sequence enters an infinite loop: 1 &amp;gt; 4 &amp;gt; 2 &amp;gt; 1 and so on. Try iterating these rules from any initial integer value of \(x\) — I’m willing to bet however much you like that you’ll eventually hit 1. The Collatz conjecture asserts that this happens for every positive integer, no matter how large. People have tested this empirically for all integers up to at least 2 billion trillion (!) without finding any counterexamples, which strongly suggests that the conjecture is true. But nobody knows how to rigorously prove it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cryptozoology&lt;/head&gt;
    &lt;p&gt;Let’s take a step back. At the beginning of this post I noted a link between the Collatz conjecture and Antihydra: Nobody knows how to prove the Collatz conjecture, and that’s why researchers don’t know how to conclusively determine whether Antihydra halts. But now I’ve instead linked the Collatz conjecture to the fifth busy beaver, a machine that has been proved to halt. What’s going on here?&lt;/p&gt;
    &lt;p&gt;The resolution to this apparent puzzle is that for the busy beaver game, we only care about whether a Turing machine halts when it starts running from a specific tape configuration, namely the blank tape. That means we only care about whether the corresponding Collatz-like sequence halts for a single input. The Collatz conjecture, meanwhile, asks whether you eventually hit \(x = 1\) for every input. It’s easy to show that the Collatz sequence ultimately hits \(x = 1\) for any one input, just as it’s easy to show that the fifth busy beaver halts (once you’ve established an equivalence between its low-level rules and the high-level Collatz-like program).10As it happens, the busy beaver hunters Heiner Marxen and Jürgen Buntrock first proved that the fifth busy beaver halted by direct simulation (albeit with some tricks to speed things up). Michel only identified its high-level behavior after the fact.&lt;/p&gt;
    &lt;p&gt;We can easily construct a variant of the Collatz problem that’s hard to solve even for a single input. All we need to do is change the \(3x + 1\) rule for odd numbers to \(5x + 1\). In that case, trajectories that start from certain inputs (such as \(x = 7\)) look like they will diverge, never hitting 1 or falling into a cycle. But researchers haven’t been able to prove that any of these trajectories diverges. There’s an inherent asymmetry here. If you want to prove that a sequence does eventually end up somewhere, you can always just use brute force, at least in principle. But if you want to prove that a sequence never terminates, even a single input can be hard.&lt;/p&gt;
    &lt;p&gt;We’re now finally ready to confront the terror that is Antihydra. It obeys the following high-level rules:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x = 8\).11This may seem like a weird starting point, given that we’re supposed to start with the blank tape in the busy beaver game. That’s still true here — it’s just that Antihydra spends a while futzing around on the tape before it starts iterating this sequence, and the high-level effect of all that futzing is to set the starting value to 8.&lt;/item&gt;
      &lt;item&gt;Check whether \(x\) is even or odd. &lt;list rend="ul"&gt;&lt;item&gt;If it’s even, calculate \(3x/2\). The result is your new value of \(x\). Add one to a running tally of how many times you’ve applied this even rule.&lt;/item&gt;&lt;item&gt;If it’s odd, calculate \((3x-1)/2\). The result is your new value of \(x\). Add one to a running tally of how many times you’ve applied this odd rule.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Check whether your “odd” count is more than twice as large as your “even” count. If so, halt. If not, go back to step 2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a very curious set of rules. The formulas \(3x/2\) and \((3x-1)/2\) don’t appear to systematically favor odd or even numbers, so you might expect that iterating them again and again will look like repeatedly flipping a coin and keeping track of how often you get heads versus tails. Early on in a sequence of coin flips, it’s distinctly possible that you’ll end up with more than twice as many heads as tails. But if this doesn’t happen right away, it becomes less and less likely the longer you keep going. Researchers have now simulated the behavior of Antihydra out to more than 270 billion steps, and as expected, the “even” and “odd” tallies are pretty close to equal — nowhere near the extreme imbalance demanded by the halting condition. So it seems overwhelmingly likely that Antihydra never halts. But nobody knows how to prove it! The mathematician John Conway coined the delightful term “probviously” for situations like this — ones where the specific problem of interest is very hard to solve, but probabilistic reasoning about the “typical” behavior of similar problems makes the answer seem obvious.&lt;/p&gt;
    &lt;p&gt;Antihydra’s behavior is qualitatively similar to the \(5x + 1\) version of the Collatz conjecture, where we don’t know how to prove that any single trajectory diverges. I want to stress that as far as researchers know, there isn’t a more precise mathematical link between these two problems: If you resolved one of them, it wouldn’t automatically resolve the other. But the problems seem hard for very similar reasons. If someone does manage to prove the Collatz conjecture, the mathematical techniques used in the proof would likely be promising for the Antihydra problem (and vice versa).&lt;/p&gt;
    &lt;p&gt;Actually, Antihydra is just one of many probviously non-halting Turing machines with Collatz-like behavior. Busy beaver hunter Shawn Ligocki dubbed these machines “cryptids” when they were first identified in variants of the standard busy beaver game.12These variants use extra tape symbols in addition to 0 and 1. For example, the BB(3,3) version of the busy beaver game studies the behavior of Turing machines with three rules that can read and write three symbols: 0, 1, and 2.&lt;/p&gt;
    &lt;p&gt;The first two cryptids to be discovered were named Bigfoot and Hydra;13Antihydra was named for a mathematical connection to Hydra. researchers have now identified so many cryptids that it no longer makes sense to give each one its own name. The existence of all these cryptids implies that busy beaver numbers beyond BB(5) will remain out of reach until researchers develop new mathematical tools for tackling Collatz-like problems. And the legendary mathematician Paul Erdős reportedly said “Mathematics may not be ready for such problems.”&lt;/p&gt;
    &lt;p&gt;But that doesn’t mean busy beaver hunters should give up. There’s still plenty of questions to explore in what might be called “cryptid ecology.” How many subspecies of cryptids are there? How are they related to each other, and to other unsolved problems in mathematics beyond the Collatz conjecture? Since the beginning of the busy beaver game, avid hunters have repeatedly encountered surprising new Turing machine behavior, and that pattern shows no sign of letting up.&lt;/p&gt;
    &lt;p&gt;This past August I visited Tahquamenon Falls in Michigan’s upper peninsula, a part of the state that’s apparently an epicenter of bigfoot sightings. Fortunately I didn’t encounter any cryptids, but I did learn some new things about a few friendlier critters. Surprising discoveries can come from anywhere!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://benbrubaker.com/why-busy-beaver-hunters-fear-the-antihydra/"/><published>2025-10-27T16:56:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45725009</id><title>Study finds growing social circles may fuel polarization</title><updated>2025-10-28T13:45:26.958789+00:00</updated><content>&lt;doc fingerprint="b71dc3835465878d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;More friends, more division: Study finds growing social circles may fuel polarization&lt;/head&gt;
    &lt;head rend="h5"&gt;Sadie Harley&lt;/head&gt;
    &lt;p&gt;scientific editor&lt;/p&gt;
    &lt;head rend="h5"&gt;Robert Egan&lt;/head&gt;
    &lt;p&gt;associate editor&lt;/p&gt;
    &lt;p&gt;Between 2008 and 2010, polarization in society increased dramatically alongside a significant shift in social behavior: the number of close social contacts rose from an average of two to four or five people. The connection between these two developments could provide a fundamental explanation for why societies around the world are increasingly fragmenting into ideological bubbles.&lt;/p&gt;
    &lt;p&gt;"The big question that not only we, but many countries are currently grappling with, is why polarization has increased so dramatically in recent years," says Stefan Thurner from the Complexity Science Hub (CSH), explaining the study's motivation. The research was published in Proceedings of the National Academy of Sciences.&lt;/p&gt;
    &lt;p&gt;The researchers' findings confirm that increasing polarization is not merely perceived—it is measurable and objectively occurring. "And this increase happened suddenly, between 2008 and 2010," says Thurner. The question remained: what caused it?&lt;/p&gt;
    &lt;head rend="h2"&gt;The friendship shift: From two to five close contacts&lt;/head&gt;
    &lt;p&gt;To investigate, Thurner and his team examined whether social networks had changed—specifically, whether people's close friendships had shifted. "For decades, sociological studies showed that people maintained an average of about two close friends—people who could influence their opinions on important issues," explains Thurner.&lt;/p&gt;
    &lt;p&gt;Here too, the researchers identified a striking change: "Around 2008, there was a sharp increase from an average of two close friends to four or five," explains CSH scientist Jan Korbel.&lt;/p&gt;
    &lt;head rend="h2"&gt;The paradox: More connection, more division&lt;/head&gt;
    &lt;p&gt;Are these two developments related? Do more close friends—and thus denser social networks—lead to network fragmentation and ultimately societal polarization?&lt;/p&gt;
    &lt;p&gt;Using a model based on real data, the researchers discovered this could indeed be the case: "When network density increases with more connections, polarization within the collective inevitably rises sharply," says Markus Hofer from CSH.&lt;/p&gt;
    &lt;p&gt;"This finding impressed us greatly because it could provide a fundamental explanation for the peculiar form of polarization we're currently observing simultaneously across many parts of the world—one that definitely threatens democracy," Thurner continues.&lt;/p&gt;
    &lt;p&gt;"When people are more connected with each other, they encounter different opinions more frequently. This inevitably leads to more conflict and thus greater societal polarization," adds Korbel.&lt;/p&gt;
    &lt;p&gt;Polarization has always existed, but what is happening now goes far beyond historical patterns. Greater connectivity has led to the formation of fewer but more tightly-knit groups with strongly differing opinions, between which there is hardly any exchange.&lt;/p&gt;
    &lt;p&gt;"There are few bridges between these 'bubbles,' and when they exist, they are often negative or even hostile," says Korbel. "This is called fragmentation, and it represents a new social phenomenon," adds Thurner.&lt;/p&gt;
    &lt;head rend="h2"&gt;Behind the numbers: Tracking polarization through decades of data&lt;/head&gt;
    &lt;p&gt;For their study, the researchers analyzed extensive existing survey data on both polarization and social networks.&lt;/p&gt;
    &lt;p&gt;"To measure political polarization, we used over 27,000 surveys from the Pew Research Center, which regularly records political attitudes of people in the US," explains Hofer.&lt;/p&gt;
    &lt;p&gt;"The key advantage of this data is that the questions have remained virtually unchanged over time, enabling reliable long-term comparisons."&lt;/p&gt;
    &lt;p&gt;The researchers found that political attitudes became significantly more one-sided between 1999 and 2017. For example, only 14% of respondents consistently expressed liberal views in 1999, but by 2017, this had risen to 31%. Conversely, only 6% of respondents consistently held conservative views in 1999, compared to 16% in 2017.&lt;/p&gt;
    &lt;p&gt;"More and more people are clearly aligning themselves with one political camp rather than holding a mixture of liberal and conservative views," explains Hofer.&lt;/p&gt;
    &lt;p&gt;To analyze friendship networks, the researchers combined 30 different surveys totaling over 57,000 respondents from Europe and the US, including the General Social Survey (US) and the European Social Survey.&lt;/p&gt;
    &lt;p&gt;"Despite minor differences between individual surveys, the data consistently show that the average number of close friendships rose from 2.2 in 2000 to 4.1 in 2024," says Hofer.&lt;/p&gt;
    &lt;p&gt;"The decisive contribution of this study is that it reconciled both phenomena using a mathematical social model," explains Thurner.&lt;/p&gt;
    &lt;p&gt;"This enabled us to show that increasing connectivity must lead to sudden polarization once a critical connectivity density is exceeded—just like a phase transition in physics, such as water turning to ice," adds Hofer.&lt;/p&gt;
    &lt;p&gt;"It is fascinating that these phase transitions also exist in societies. The exact location of these critical thresholds still needs clarification. According to our results, for close relationships, it lies somewhere between three and four people," the researchers note.&lt;/p&gt;
    &lt;head rend="h2"&gt;The smartphone era: When connection may have become fragmentation&lt;/head&gt;
    &lt;p&gt;The sharp rise in both polarization and the number of close friends occurred between 2008 and 2010—precisely when social media platforms and smartphones first achieved widespread adoption. This technological shift may have fundamentally changed how people connect with each other, indirectly promoting polarization.&lt;/p&gt;
    &lt;p&gt;"Democracy depends on all parts of society being involved in decision-making, which requires that everyone be able to communicate with each other. But when groups can no longer talk to each other, this democratic process breaks down," emphasizes Stefan Thurner.&lt;/p&gt;
    &lt;p&gt;Tolerance plays a central role. "If I have two friends, I do everything I can to keep them—I am very tolerant towards them. But if I have five and things become difficult with one of them, it's easier to end that friendship because I still have 'backups.' I no longer need to be as tolerant," explains Thurner.&lt;/p&gt;
    &lt;p&gt;What disappears as a result is a societal baseline of tolerance—a development that could contribute to the long-term erosion of democratic structures. To prevent societies from increasingly fragmenting, Thurner emphasizes the importance of learning early how to engage with different opinions and actively cultivating tolerance.&lt;/p&gt;
    &lt;p&gt;More information: Thurner, Stefan, Why more social interactions lead to more polarization in societies, Proceedings of the National Academy of Sciences (2025). DOI: 10.1073/pnas.2517530122. doi.org/10.1073/pnas.2517530122&lt;/p&gt;
    &lt;p&gt;Journal information: Proceedings of the National Academy of Sciences&lt;/p&gt;
    &lt;p&gt;Provided by Complexity Science Hub Vienna&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://phys.org/news/2025-10-friends-division-social-circles-fuel.html"/><published>2025-10-27T19:06:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45726192</id><title>Easy RISC-V</title><updated>2025-10-28T13:45:26.684428+00:00</updated><content>&lt;doc fingerprint="bae7c0d12017aa49"&gt;
  &lt;main&gt;&lt;p&gt;(Last updated: 2025-10-28 08:04)&lt;/p&gt;&lt;p&gt;This page is not designed to be used on a narrow screen or without CSS. If you’re having issues using the emulator, try the emulators disabled version.&lt;/p&gt;&lt;p&gt;An interactive introduction to RISC-V assembly programming, by dramforever.&lt;/p&gt;&lt;p&gt;Interested in the code? Want to report an issue? Check out the GitHub page: https://github.com/dramforever/easyriscv&lt;/p&gt;&lt;p&gt;Inspired by Easy 6502 by Nick Morgan, this is a quick-ish introductory tutorial to RISC-V assembly programming. This tutorial is intended for those with a basic familiarity with low level computer science concepts, but unfamiliar with RISC-V. If you’re curious about RISC-V, I hope this will be a good start to your journey to learning about it.&lt;/p&gt;&lt;p&gt;RISC-V (pronounced “risk-five”), as its name suggests, is RISC (Reduced instruction set computer) architecture. Having started its life at UC Berkerley, RISC-V has bred a lively community of students, researchers, engineers and hobbyists working on software and hardware. Some highlights of RISC-V include:&lt;/p&gt;&lt;p&gt;RISC-V is less mature than more established architectures like x86 or Arm, but it is quickly gaining steam and has found great success in many areas of application, such as embedded systems, custom processors, education, and research.&lt;/p&gt;&lt;p&gt;This article will cover the 32-bit bare bones RV32I_Zicsr instruction set with a tiny subset of the privileged architecture. You’ll probably never find a “real” chip with such bare bones instruction support. Most of them will have more extensions for other features like floating point or compressed instructions. However, I would still consider what we have here a “complete” instruction set. For example, Rust has Tier 2 support for the target &lt;code&gt;riscv32i-unknown-none-elf&lt;/code&gt;
which works completely fine with only the instructions we’ll cover
here.&lt;/p&gt;&lt;p&gt;Speaking of instructions we will cover, why don’t we meet the 45 of them right here and now:&lt;/p&gt;&lt;code&gt;lui auipc
jal jalr
beq bne blt bge bltu bgeu
lb lh lw lbu lhu sb sh sw
addi slti sltiu xori ori andi slli srli srai
add sub slt sltu xor or and sll srl sra
ecall ebreak
csrrw csrrs csrrc csrrwi csrrsi csrrci&lt;/code&gt;&lt;p&gt;Some of these instruction names should ring a bell (&lt;code&gt;add&lt;/code&gt;,
&lt;code&gt;or&lt;/code&gt;, &lt;code&gt;xor&lt;/code&gt;). Others will look like they have some
pattern to it. A few weird ones like &lt;code&gt;auipc&lt;/code&gt; stand out. These
instructions form the foundation of RISC-V, performing the basic tasks a
processor would do.&lt;/p&gt;&lt;p&gt;You will also catch a glimpse of what creating an operating system on RISC-V is like, namely handling exceptions and privilege levels.&lt;/p&gt;&lt;p&gt;Let’s get started.&lt;/p&gt;&lt;p&gt;Throughout this article you will see emulator panes like these:&lt;/p&gt;&lt;p&gt;(If you just see a code block, there’s a JavaScript problem. Make sure you’ve enabled JavaScript, probably…)&lt;/p&gt;&lt;p&gt;You can use the buttons to control each emulator. Go ahead and click on ‘Start’. A register view should pop up showing the state of the emulator. Now click on ‘Run’. You’ll notice that:&lt;/p&gt;&lt;code&gt;a0 (x10) 0x00000000&lt;/code&gt;&lt;p&gt;Changed into:&lt;/p&gt;&lt;code&gt;a0 (x10) 0x00000123&lt;/code&gt;&lt;p&gt;And the emulator stopped. Congratulations, you’ve run your first RISC-V assembly program. First here, at least.&lt;/p&gt;&lt;p&gt;‘Start’ assembles your code and, well, starts the emulator. If there’s a problem with your code, it will tell you about it and the emulator will not start.&lt;/p&gt;&lt;p&gt;When the emulator is started, you can see the current state of the registers in the side pane. More controls also becomes available. ‘Run’ runs until the end or until you hit ‘Pause’. ‘Step’ runs a single step.&lt;/p&gt;&lt;p&gt;If you hit ‘Step’, you’ll notice that the above program takes two steps to run. You may have guessed correctly that the first step corresponds to &lt;code&gt;addi&lt;/code&gt;, and the second corresponds to
&lt;code&gt;ebreak&lt;/code&gt;. The top of the register panel shows
&lt;code&gt;pc&lt;/code&gt;, the current instruction address, and in parentheses the
current instruction.&lt;/p&gt;&lt;p&gt;‘Dump’ opens a new window containing some text. There are two sections: the first is the symbol table, which tells you about the labels in your code:&lt;/p&gt;&lt;code&gt;# Symbols
# 0x40000000 start&lt;/code&gt;&lt;p&gt;The second section is an annotated version of your code:&lt;/p&gt;&lt;code&gt;start:
{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 00100073 } ebreak&lt;/code&gt;&lt;p&gt;This tells you that the &lt;code&gt;addi&lt;/code&gt; instruction encodes to hex
&lt;code&gt;12300513&lt;/code&gt;, and starts at address hex &lt;code&gt;40000000&lt;/code&gt;.
Similarly, &lt;code&gt;ebreak&lt;/code&gt; encodes as &lt;code&gt;00100073&lt;/code&gt; at
address hex &lt;code&gt;40000004&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;(Note: RISC-V instructions are little-endian, meaning that the four bytes of &lt;code&gt;addi&lt;/code&gt; are actually
&lt;code&gt;13 05 30 12&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;We’ll talk in detail about all of &lt;code&gt;pc&lt;/code&gt;, registers,
instructions, labels, and the two checkboxes later.&lt;/p&gt;&lt;p&gt;Now you may have also guessed that &lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;
means &lt;code&gt;x10 = x0 + 0x123&lt;/code&gt;. As for &lt;code&gt;ebreak&lt;/code&gt;, for
now, just remember that &lt;code&gt;ebreak&lt;/code&gt; stops the emulator.&lt;/p&gt;&lt;p&gt;The program counter, or &lt;code&gt;pc&lt;/code&gt; is the address of
the current instruction. It points to the instruction to be
executed.&lt;/p&gt;&lt;p&gt;RV32I has 31 general purpose registers numbered &lt;code&gt;x1&lt;/code&gt; through
&lt;code&gt;x31&lt;/code&gt;. These can contain any 32-bit data.&lt;/p&gt;&lt;p&gt;(If you’re wondering, there are no flags for RV32I.)&lt;/p&gt;&lt;p&gt;The register &lt;code&gt;x0&lt;/code&gt; is a
special “zero register”. For computational instructions, you can use
&lt;code&gt;x0&lt;/code&gt; anywhere a register is expected. Reading it always gives
zero, and writing to it just gets ignored. The use of a special register
simplifies the design of the architecture, and this design is shared by
MIPS and Arm AArch64. We will make good use of &lt;code&gt;x0&lt;/code&gt; soon.&lt;/p&gt;&lt;p&gt;(Note: In the emulator, the instruction listed in parenthesis next to &lt;code&gt;pc&lt;/code&gt; in the register view is provided as a convenience and is
not part of the processor state.)&lt;/p&gt;&lt;p&gt;But before we can start talking about instructions themselves, we need a way to talk about the instruction syntax so I can, you know, write it down for you.&lt;/p&gt;&lt;p&gt;The syntax of an instruction is the instruction name and then several comma-separated operands. For example, for this instruction we’ve seen above:&lt;/p&gt;&lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;&lt;p&gt;&lt;code&gt;x10&lt;/code&gt; is the destination register or
&lt;code&gt;rd&lt;/code&gt;. The next operand is
the first (and only) source
register or &lt;code&gt;rs1&lt;/code&gt;. The last operand is an
immediate value or &lt;code&gt;imm&lt;/code&gt;. Using these
abbreviations, we can summarize that the syntax for &lt;code&gt;addi&lt;/code&gt;
is:&lt;/p&gt;&lt;code&gt;addi rd, rs1, imm&lt;/code&gt;&lt;p&gt;Some other instructions have a second source register or &lt;code&gt;rs2&lt;/code&gt;. For example, the
non-immediate &lt;code&gt;add&lt;/code&gt; instruction has this syntax:&lt;/p&gt;&lt;code&gt;add rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Some other instructions have no operands, like &lt;code&gt;ebreak&lt;/code&gt;.
Others have slightly more complex operands.&lt;/p&gt;&lt;p&gt;Using the registers as a playground of numbers, we can use computational instructions to work with them.&lt;/p&gt;&lt;p&gt;As we’ve seen above, you can get a RISC-V machine to add numbers together.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;addi&lt;/code&gt;
instruction adds the value in &lt;code&gt;rs1&lt;/code&gt; to the immediate value
&lt;code&gt;imm&lt;/code&gt;, and puts the result in &lt;code&gt;rd&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;addi rd, rs1, imm&lt;/code&gt;&lt;p&gt;The &lt;code&gt;add&lt;/code&gt; instruction
adds the value in &lt;code&gt;rs1&lt;/code&gt; to the value in &lt;code&gt;rs2&lt;/code&gt;, and
puts the result in &lt;code&gt;rd&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;add rd, rs1, rs2&lt;/code&gt;&lt;p&gt;The opposite of addition is subtraction. The &lt;code&gt;sub&lt;/code&gt; instruction subtracts the
value in &lt;code&gt;rs2&lt;/code&gt; from the value in &lt;code&gt;rs1&lt;/code&gt;
(i.e. &lt;code&gt;rs1 - rs2&lt;/code&gt;), and puts the result in &lt;code&gt;rd&lt;/code&gt;.
There’s no corresponding &lt;code&gt;subi&lt;/code&gt; instruction — Just use
&lt;code&gt;addi&lt;/code&gt; with a negative number.&lt;/p&gt;&lt;code&gt;sub rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Step through this demo program and try writing your own additions and subtractions:&lt;/p&gt;&lt;p&gt;One thing you should note is that the immediate value has a limited range, namely &lt;code&gt;[-2048, 2047]&lt;/code&gt;, the range of a 12-bit two’s
complement signed integer. This limitation is because RV32I uses fixed
32-bit i.e. 4-byte instructions, and only the top 12 bits are available
to encode an immediate value. You can see the hexadecimal value encoded
in the instruction from the ‘Dump’. This article will not go into much
further detail about instruction encodings.&lt;/p&gt;&lt;code&gt;{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 55500593 } addi x11, x0, 0x555&lt;/code&gt;&lt;p&gt;Even instructions as simple as addition and subtraction have other interesting uses. We have already used &lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;
to put &lt;code&gt;0x123&lt;/code&gt; in the register &lt;code&gt;x10&lt;/code&gt;. When writing
in assembly, we can use a little shortcut called pseudoinstructions. The
&lt;code&gt;li&lt;/code&gt; (“load immediate”)
pseudoinstruction is a convenient way to put a small value in a
register. It expands to &lt;code&gt;addi rd, x0, imm&lt;/code&gt; when
&lt;code&gt;imm&lt;/code&gt; is in the range &lt;code&gt;[-2048, 2047]&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;li rd, imm&lt;/code&gt;&lt;p&gt;When &lt;code&gt;imm&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;, &lt;code&gt;addi&lt;/code&gt; copies the
value without changing it because adding zero is the same as doing
nothing. The &lt;code&gt;mv&lt;/code&gt; (“move”)
pseudoinstruction copies the value from &lt;code&gt;rs1&lt;/code&gt; to
&lt;code&gt;rd&lt;/code&gt;. It expands to &lt;code&gt;addi rd, rs1, 0&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;mv rd, rs1&lt;/code&gt;&lt;p&gt;Using the pseudoinstruction is exactly equivalent to using the “real” instruction. You can see in the dump that the two are assembled exactly the same way.&lt;/p&gt;&lt;p&gt;Subtracting from zero is negation. What’s the negative of &lt;code&gt;0x123&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Hmm, we get &lt;code&gt;0xfffffedd&lt;/code&gt;. That’s the 32-bit two’s complement
representation of &lt;code&gt;-291&lt;/code&gt;, or &lt;code&gt;-0x123&lt;/code&gt;. There’s
plenty of tutorials on this out there, so we’ll just note that whenever
something is “signed”, RISC-V uses two’s complement representation. The
benefit of this is that there are fewer instructions for separate signed
and unsigned instructions — both signed and unsigned numbers have the
same overflow wrap-around behavior.&lt;/p&gt;&lt;p&gt;Speaking of overflow wrap-around, what happens if we add something too much and it overflows? We’ll use &lt;code&gt;add&lt;/code&gt; to repeatedly
double &lt;code&gt;0x123&lt;/code&gt; and see what happens:&lt;/p&gt;&lt;p&gt;As &lt;code&gt;0x123&lt;/code&gt; crawls up to the upper bits and eventually we
get to &lt;code&gt;0x9180_0000&lt;/code&gt;, in the next iteration it turns into
&lt;code&gt;0x2300_0000&lt;/code&gt;. There was an overflow! Doubling of
&lt;code&gt;0x9180_0000&lt;/code&gt; gives &lt;code&gt;0x1_2300_0000&lt;/code&gt;, but that
needs 33 bits in binary, so the highest bit can’t be put in the result.
Since RISC-V doesn’t have flag bits for carry or overflow, it’s simply
gone. The programmer is expected to deal with this.&lt;/p&gt;&lt;p&gt;While we’re talking about bits, another thing we can do with bits is performing bitwise logical operations on them.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;and&lt;/code&gt; instruction
performs a bitwise-“and” between the bits of &lt;code&gt;rs1&lt;/code&gt; and
&lt;code&gt;rs2&lt;/code&gt; and puts the result in &lt;code&gt;rd&lt;/code&gt;. The &lt;code&gt;or&lt;/code&gt; and &lt;code&gt;xor&lt;/code&gt; instructions similarly
performs bitwise-“or” and bitwise-“xor”, respectively.&lt;/p&gt;&lt;code&gt;and rd, rs1, rs2
or rd, rs1, rs2
xor rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Immediate operand versions of the three, namely &lt;code&gt;andi&lt;/code&gt;, &lt;code&gt;ori&lt;/code&gt;, &lt;code&gt;xori&lt;/code&gt; also exist.&lt;/p&gt;&lt;code&gt;andi rd, rs1, imm
ori rd, rs1, imm
xori rd, rs1, imm&lt;/code&gt;&lt;p&gt;Here are some random bit operation examples you can play with:&lt;/p&gt;&lt;p&gt;Remember that the immediate value is in the range &lt;code&gt;[-2048, 2047]&lt;/code&gt;. For negative values, the two’s complement
representation used means that the high bits are all ones. For example,
using &lt;code&gt;-1&lt;/code&gt; as &lt;code&gt;imm&lt;/code&gt; means the second operand is
binary all ones, or &lt;code&gt;0xffff_ffff&lt;/code&gt;. This allows us to use
&lt;code&gt;xori rd, rs1, -1&lt;/code&gt; as bitwise-“not”.&lt;/p&gt;&lt;p&gt;Another interesting operation you can do is to round/align something up or down to a multiple of a power of two. For example, if you want to find the closest multiple of 16 below &lt;code&gt;a&lt;/code&gt;, in binary that would be clearing the lowest
4 bits, or &lt;code&gt;a &amp;amp; ~0b1111&lt;/code&gt;. Conveniently, that’s
&lt;code&gt;a &amp;amp; -16&lt;/code&gt; in two’s complement.&lt;/p&gt;&lt;p&gt;Aligning up is less intuitive, but one idea would be adding 16 first. However that gives an incorrect result for multiples of 16. It’s easy enough to fix though: adding one less works exactly right: &lt;code&gt;(a + 15) &amp;amp; -16&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Usually when you write a comparison of some sort like &lt;code&gt;a == b&lt;/code&gt; or &lt;code&gt;a &amp;gt;= b&lt;/code&gt;, it’s used as a condition
for some &lt;code&gt;if&lt;/code&gt; or loop, but… those things are complicated!
We’ll get to it later.&lt;/p&gt;&lt;p&gt;Sometimes you just want a boolean value out of a comparison. The C convention uses 1 for true and 0 for false, and since the world runs on C now, that’s what RISC-V provides.&lt;/p&gt;&lt;p&gt;In C there are six comparison operators:&lt;/p&gt;&lt;code&gt;== != &amp;lt; &amp;gt; &amp;lt;= &amp;gt;=&lt;/code&gt;&lt;p&gt;The values being compared can also be both signed or both unsigned.&lt;/p&gt;&lt;p&gt;How many comparison instructions do we have at our disposal? Let’s see…&lt;/p&gt;&lt;p&gt;The &lt;code&gt;slt&lt;/code&gt; (“set less
than”) instruction compares &lt;code&gt;rs1&lt;/code&gt; and &lt;code&gt;rs2&lt;/code&gt; as
signed 32-bit integers, and sets &lt;code&gt;rd&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; if
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt;, and &lt;code&gt;0&lt;/code&gt; otherwise
(&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt;). The &lt;code&gt;sltu&lt;/code&gt; instruction is similar
but it treats the operands as unsigned values. &lt;code&gt;slti&lt;/code&gt; and &lt;code&gt;sltiu&lt;/code&gt; are similar but the
second operand is an immediate value.&lt;/p&gt;&lt;code&gt;slt rd, rs1, rs2
sltu rd, rs1, rs2
slti rd, rs1, imm
sltiu rd, rs1, imm&lt;/code&gt;&lt;p&gt;(Of particular note is &lt;code&gt;sltiu&lt;/code&gt;, where the immediate
operand still has the range &lt;code&gt;[-2048, 2047]&lt;/code&gt; but is sign
extended to 32 bits and then treated as an unsigned value, like what
would happen in C with &lt;code&gt;a &amp;lt; (unsigned)-1&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;That’s… one of the six comparisons settled. What about the others? As it turns out, we can synthesize any of the other five, using up to two instructions.&lt;/p&gt;&lt;p&gt;Making &lt;code&gt;&amp;gt;&lt;/code&gt; from &lt;code&gt;&amp;lt;&lt;/code&gt; is easy, as you can
just swap the operands. Using &lt;code&gt;xori&lt;/code&gt; with &lt;code&gt;1&lt;/code&gt; we
can invert the result of a comparison, giving as &lt;code&gt;&amp;lt;=&lt;/code&gt; and
&lt;code&gt;&amp;gt;=&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;That was signed comparison but unsigned comparison works the same using &lt;code&gt;sltu&lt;/code&gt; instead of &lt;code&gt;slt&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As for &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;!=&lt;/code&gt;, let’s tackle the easier
case of &lt;code&gt;a == 0&lt;/code&gt; and &lt;code&gt;a != 0&lt;/code&gt; first. We will use
the fact that for unsigned values, &lt;code&gt;a != 0&lt;/code&gt; is equivalent to
&lt;code&gt;a &amp;gt; 0&lt;/code&gt;. The negation of that is &lt;code&gt;a &amp;lt;= 0&lt;/code&gt;,
which is the same as &lt;code&gt;a &amp;lt; 1&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As a bonus, this is also how we get logical not and converting integer to boolean.&lt;/p&gt;&lt;p&gt;Now that we have these, &lt;code&gt;a == b&lt;/code&gt; is just
&lt;code&gt;(a - b) == 0&lt;/code&gt;, and &lt;code&gt;a != b&lt;/code&gt; is just
&lt;code&gt;(a - b) != 0&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In summary: (&lt;code&gt;[u]&lt;/code&gt; means use &lt;code&gt;u&lt;/code&gt; for unsigned
comparison and nothing for signed comparison)&lt;/p&gt;&lt;code&gt;a &amp;lt; b&lt;/code&gt;: &lt;code&gt;slt[u]&lt;/code&gt;&lt;code&gt;a &amp;gt; b&lt;/code&gt;: &lt;code&gt;slt[u] reversed&lt;/code&gt;&lt;code&gt;a &amp;lt;= b&lt;/code&gt;: &lt;code&gt;slt[u] reversed ; xori 1&lt;/code&gt;&lt;code&gt;a &amp;gt;= b&lt;/code&gt;: &lt;code&gt;slt[u] ; xori 1&lt;/code&gt;&lt;code&gt;a == 0&lt;/code&gt;: &lt;code&gt;sltu x0&lt;/code&gt;&lt;code&gt;a != 0&lt;/code&gt;: &lt;code&gt;sltiu 1&lt;/code&gt;&lt;code&gt;a == b&lt;/code&gt;: &lt;code&gt;sub ; sltu x0&lt;/code&gt;&lt;code&gt;a != b&lt;/code&gt;: &lt;code&gt;sub ; sltiu 1&lt;/code&gt;&lt;p&gt;There is no way I can do justice to the usage of bit shifts in the middle of a tutorial on RISC-V assembly. If you’re here, you’ve probably heard of them. There’s nothing really special to the way they appear in usage for RISC-V.&lt;/p&gt;&lt;p&gt;There are two variants for right shifting: &lt;code&gt;srl&lt;/code&gt; and &lt;code&gt;srli&lt;/code&gt; (“shift right logical
(immediate)”) performs “logical” or unsigned right shift where the
leftmost or most significant bits are filled with zeros.&lt;/p&gt;&lt;p&gt;&lt;code&gt;sra&lt;/code&gt; and &lt;code&gt;srai&lt;/code&gt; (“shift right
arithmetic (immediate)”) performs “arithmetic” or signed right shift
where the leftmost bits are filled with the same of what highest/sign
bit was. So if you shift a negative value, you get a negative result; if
you shift a non-negative value, you get a non-negative result.&lt;/p&gt;&lt;code&gt;srl rd, rs1, rs2
sra rd, rs1, rs2
srli rd, rs1, imm
srai rd, rs1, imm&lt;/code&gt;&lt;p&gt;As before, the ones with the &lt;code&gt;i&lt;/code&gt; suffix take an immediate
value as the second operand, and the ones without &lt;code&gt;i&lt;/code&gt; take a
register.&lt;/p&gt;&lt;p&gt;So &lt;code&gt;a&lt;/code&gt; means “arithmetic”, &lt;code&gt;l&lt;/code&gt; means “logical”.
Got it.&lt;/p&gt;&lt;p&gt;Left shifts have no such distinction. For consistency they are still “logical”: &lt;code&gt;sll&lt;/code&gt; is left
shift, and &lt;code&gt;slli&lt;/code&gt; is
left shift with immediate.&lt;/p&gt;&lt;code&gt;sll rd, rs1, rs2
slli rd, rs1, imm&lt;/code&gt;&lt;p&gt;Aha, now we can blow up &lt;code&gt;0x123&lt;/code&gt; without repeating myself
so much:&lt;/p&gt;&lt;p&gt;The immediate value for shift instructions are special: they can only be in the range of 0 to 31, inclusive, because it doesn’t make sense to shift by a negative amount, or by more than 31. When the shift amount is taken from a register, the value is considered modulo 32, or in other words only the last 5 bits are taken into account:&lt;/p&gt;&lt;p&gt;For some fun, let’s try multiplying a value by 10, something you would do when parsing decimal numbers: &lt;code&gt;a * 10&lt;/code&gt; can be
rewritten as &lt;code&gt;(a &amp;lt;&amp;lt; 1) + (a &amp;lt;&amp;lt; 3)&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;That’s it?&lt;/p&gt;&lt;p&gt;You may have noticed some glaring omissions. What we’ve learned doesn’t even cover grade school math: multiplication and division are missing.&lt;/p&gt;&lt;p&gt;RISC-V is designed with extensions in mind. Remember that as said in the introduction, RV32I is the barest bones of the barest bones we’ve got. Forcing everyone to make their processors with multiplication and division even for tasks that don’t need them would waste silicon area and money on every chip. Instead those making RISC-V processors have great freedom to choose, and indeed some would say they have too much freedom.&lt;/p&gt;&lt;p&gt;For us… Honestly, I’m just glad we’ve been dealt a hand that we can tackle completely in full. There’s no way I’m finishing writing this tutorial if RV32I wasn’t so bare boned.&lt;/p&gt;&lt;p&gt;(Operand &lt;code&gt;a&lt;/code&gt; is &lt;code&gt;rs1&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt; is
&lt;code&gt;rs2&lt;/code&gt; or immediate. In the instruction name &lt;code&gt;[i]&lt;/code&gt;
means an immediate variant is available. Subscript &lt;code&gt;u&lt;/code&gt; means
unsigned and &lt;code&gt;s&lt;/code&gt; means two’s complement signed.)&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Instruction&lt;/cell&gt;&lt;cell role="head"&gt;Operation&lt;/cell&gt;&lt;cell role="head"&gt;Immediate range&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;add[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;sub&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a - b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(n/a)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;slt[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(a &amp;lt;s b) ? 1 : 0&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;slt[i]u&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(a &amp;lt;u b) ? 1 : 0&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;xor[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a ^ b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;or[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a | b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;and[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;amp; b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;sll[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;lt;&amp;lt; b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;srl[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;gt;&amp;gt;u b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;&lt;code&gt;sra[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;gt;&amp;gt;s b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The &lt;code&gt;addi&lt;/code&gt; instruction has limit on the immediate value.
How do we make bigger values?&lt;/p&gt;&lt;p&gt;The &lt;code&gt;lui&lt;/code&gt; (“load upper
immediate”) instruction takes an immediate in the range
&lt;code&gt;[0, 1048575]&lt;/code&gt; (i.e. up to &lt;code&gt;220 - 1&lt;/code&gt;)
and sets &lt;code&gt;rd&lt;/code&gt; to that value left shifted 12 bits:&lt;/p&gt;&lt;code&gt;lui rd, imm20&lt;/code&gt;&lt;p&gt;That was… slightly confusing. Why don’t we give it a try:&lt;/p&gt;&lt;p&gt;Instead of &lt;code&gt;li&lt;/code&gt; loading a “low” immediate, we control the
upper 20 bits of what we put in the register. After that, we
can use another &lt;code&gt;addi&lt;/code&gt; instruction to fill in the lower bits.
For example, if we want &lt;code&gt;0x12345&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;For convenience, in assembly you can use &lt;code&gt;%hi()&lt;/code&gt; and &lt;code&gt;%lo()&lt;/code&gt; to extract the, well,
high 20 and low 12 bits of a value. The previous example could also be
written:&lt;/p&gt;&lt;p&gt;Letting &lt;code&gt;lui&lt;/code&gt; handle the high 20 bits, and
&lt;code&gt;addi&lt;/code&gt; for the low 12 bits, you can make any 32-bit
value.&lt;/p&gt;&lt;p&gt;(A small complication arises if you want to use values with bit 11 set. In that case, the immediate operand to &lt;code&gt;addi&lt;/code&gt; will have
to be negative. However &lt;code&gt;%hi&lt;/code&gt; understands this and adds one
to compensate, so this &lt;code&gt;%hi&lt;/code&gt;/&lt;code&gt;%lo&lt;/code&gt; combination
does work for everything.)&lt;/p&gt;&lt;p&gt;So far, everything that we’ve had so far can be done on even the most basic programmer’s calculator. To truly make a computer… do computer stuff, we’d want loops and conditionals.&lt;/p&gt;&lt;p&gt;In RISC-V parlance, a branch is a conditional transfer of control flow, and a jump is an unconditional transfer of control flow.&lt;/p&gt;&lt;p&gt;I think the branch instructions are slightly simpler, so let’s start with those.&lt;/p&gt;&lt;p&gt;All the branch instruction follow the form “If some comparison, go to somewhere.” The conditions are:&lt;/p&gt;&lt;code&gt;beq&lt;/code&gt;:
&lt;code&gt;rs1 == rs2&lt;/code&gt; (“equal”)&lt;code&gt;bne&lt;/code&gt;:
&lt;code&gt;rs1 != rs2&lt;/code&gt; (“not equal”)&lt;code&gt;blt&lt;/code&gt;:
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt; signed (“less than”)&lt;code&gt;bge&lt;/code&gt;:
&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt; signed (“greater or equal”)&lt;code&gt;bltu&lt;/code&gt;:
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt; signed (“less than unsigned”)&lt;code&gt;bgeu&lt;/code&gt;:
&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt; signed (“greater or equal unsigned”)&lt;p&gt;(In case you’re wondering about the confusing choice of ordering operators here, it’s just that the negation of &lt;code&gt;&amp;lt;&lt;/code&gt; is
&lt;code&gt;&amp;gt;=&lt;/code&gt;.)&lt;/p&gt;&lt;code&gt;beq rs1, rs2, label
bne rs1, rs2, label
blt rs1, rs2, label
bge rs1, rs2, label
bltu rs1, rs2, label
bgeu rs1, rs2, label&lt;/code&gt;
&lt;p&gt;Oh, right, almost forgot to explain what labels are. Labels are convenience identifiers for addresses at some line of your code. They are some identifier followed by a colon (like &lt;code&gt;this:&lt;/code&gt;). They
can appear on a line of its own, or before any instruction on the line.
You can see which address they point to using the “Dump” button. The
third operand of a branch instruction is a label to jump to if the
condition holds.&lt;/p&gt;&lt;p&gt;Let’s add up all the numbers from 1 to 100:&lt;/p&gt;&lt;p&gt;You can try your hands on making your favorite loops, like fibonacci numbers or something. Speaking of trying your hands, just so we’re ready, here’s what an infinite loop looks like. Try pausing or stopping the loop, and single stepping through the instructions.&lt;/p&gt;&lt;p&gt;(If you know a thing or two about JavaScript in the browser, you’ll know that a real infinite loop in JavaScript makes the whole page becomes unresponsive, unless it’s in a worker or something. The “Run” button here just runs the emulator for a certain number of steps, pausing by giving back control to the event loop in between.)&lt;/p&gt;&lt;p&gt;(This isn’t the preferred way to write an unconditional jump. We’ll see what is later.)&lt;/p&gt;&lt;p&gt;By the way, there’s no &lt;code&gt;bgt[u]&lt;/code&gt; or &lt;code&gt;ble[u]&lt;/code&gt;
because you can just swap &lt;code&gt;rs1&lt;/code&gt; and &lt;code&gt;rs2&lt;/code&gt; to get
those.&lt;/p&gt;&lt;p&gt;There are two jump instructions in RISC-V. One of them is &lt;code&gt;jal&lt;/code&gt; “jump and link”, which
sets &lt;code&gt;rd&lt;/code&gt; to the address of the following instruction, and
then jumps to a label:&lt;/p&gt;&lt;code&gt;jal rd, label&lt;/code&gt;
&lt;p&gt;Another is &lt;code&gt;jalr&lt;/code&gt;
“jump and link register”, which sets &lt;code&gt;rd&lt;/code&gt; to the address of
the following instruction, and then jumps to the address at
&lt;code&gt;imm + rs1&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;jalr rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;(Actually, the address jumped to is &lt;code&gt;(imm + rs1) &amp;amp; ~1&lt;/code&gt;, i.e. the least significant bit is
cleared. This distinction won’t come up in normal code, like, pretty
much ever.)&lt;/p&gt;&lt;p&gt;Eesh, that’s some funky looking syntax. When you see parentheses like this, it has something to do with an address. Parens means address.&lt;/p&gt;&lt;p&gt;That’s… still a lot going on. Let’s take on some simpler cases first: If &lt;code&gt;rd&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; then the only thing these
instructions do is jumping. We can use it instead of the branch
instructions for an unconditional jump.&lt;/p&gt;&lt;p&gt;For convenience, a pseudoinstruction is available for you: &lt;code&gt;j&lt;/code&gt; (“jump”) is for
&lt;code&gt;jal&lt;/code&gt; with &lt;code&gt;rd&lt;/code&gt; being &lt;code&gt;x0&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;j label&lt;/code&gt;
&lt;p&gt;As for why you would want to do this… Well, we only have 32 bits per instruction, and since the &lt;code&gt;jal&lt;/code&gt; instruction only needs one
register number instead of the branch instructions’ two, and it doesn’t
need a condition, the instruction encoding permits jumping over a longer
range. So this is always preferred over something like
&lt;code&gt;beq x0, x0, label&lt;/code&gt; for a jump.&lt;/p&gt;&lt;p&gt;As for &lt;code&gt;jalr&lt;/code&gt;, you can jump to an address that’s stored in
a register. In C, that would be dealing with function pointers. You’d
need this any time dynamic dispatch is needed. For example, we load the
address of &lt;code&gt;foo&lt;/code&gt; into a register first before jumping to
it.&lt;/p&gt;&lt;p&gt;In case you forgot by now, the &lt;code&gt;lui&lt;/code&gt;/&lt;code&gt;addi&lt;/code&gt;
combo at the start puts the address of the label &lt;code&gt;foo&lt;/code&gt; in
register &lt;code&gt;x10&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Similar to &lt;code&gt;j&lt;/code&gt;, &lt;code&gt;jr&lt;/code&gt; (“jump register”) is a
psuedoinstruction for &lt;code&gt;jalr&lt;/code&gt; with &lt;code&gt;rd&lt;/code&gt; being
&lt;code&gt;x0&lt;/code&gt; and &lt;code&gt;imm&lt;/code&gt; being &lt;code&gt;0&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;jr rs1&lt;/code&gt;
&lt;p&gt;Hmmm… If I didn’t really need the address in &lt;code&gt;x10&lt;/code&gt;, that
&lt;code&gt;addi&lt;/code&gt; would be unnecessary, since &lt;code&gt;jalr&lt;/code&gt; has the
ability to add a low immediate on its own:&lt;/p&gt;&lt;p&gt;What’s the advantage of this over &lt;code&gt;jal x0&lt;/code&gt;? Since
&lt;code&gt;%hi&lt;/code&gt; and &lt;code&gt;%lo&lt;/code&gt; can represent any 32-bit value,
this two-instruction combo can jump to any address, free from range
restrictions. You do need a free scratch register for the high part of
the address though, but since RISC-V gives you 31 of them, this
shouldn’t be too much of a problem.&lt;/p&gt;&lt;p&gt;What’s the deal with the destination register then? What do you need the address of the next instruction for? For jumping back of course. We can use this functionality to call functions and return back.&lt;/p&gt;&lt;p&gt;Note that I used the register &lt;code&gt;x1&lt;/code&gt; for this, which is the
register for providing the return address by convention. For
convenience, if the destination register is omitted in &lt;code&gt;jal&lt;/code&gt;,
it defaults to &lt;code&gt;x1&lt;/code&gt;. Meanwhile, &lt;code&gt;ret&lt;/code&gt; (“return”) is a
pseudoinstruction that stands for &lt;code&gt;jr x1&lt;/code&gt;,
i.e. &lt;code&gt;jalr x0, 0(x1)&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;jal label
ret&lt;/code&gt;
&lt;p&gt;So the example above can be rewritten more conveniently as:&lt;/p&gt;&lt;p&gt;That’s a nice computer we have here. Now we have… all of 31 × 4 = 124 bytes of storage in the form of registers to work with. I want more…&lt;/p&gt;&lt;p&gt;The emulator has 1 MiB of memory starting at address &lt;code&gt;0x4000_0000&lt;/code&gt;. That’s &lt;code&gt;0x4000_0000&lt;/code&gt; to
&lt;code&gt;0x400f_ffff&lt;/code&gt;, inclusive. The assembler starts assembling at
the beginning of memory, as you can see in the dump, starting at address
&lt;code&gt;0x4000_0000&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;.word&lt;/code&gt; directive straight up puts a
4-byte/32-bit word into the current position. You can specify multiple
values separated by commas.&lt;/p&gt;&lt;code&gt;.word value [ , value [ , ...  ] ]&lt;/code&gt;
&lt;p&gt;The &lt;code&gt;lw&lt;/code&gt; (“load word”)
instruction loads a word from the address &lt;code&gt;rs1 + imm&lt;/code&gt; and
puts it in &lt;code&gt;rd&lt;/code&gt;, in other words it reads the word from
memory:&lt;/p&gt;&lt;code&gt;lw rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;As with &lt;code&gt;jalr&lt;/code&gt;, you can combine it with &lt;code&gt;lui&lt;/code&gt;
to access any address.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;sw&lt;/code&gt; (“store word”)
instruction stores &lt;code&gt;rs2&lt;/code&gt; to a word in memory at address
&lt;code&gt;rs2 + imm&lt;/code&gt;, in other words it writes the word to memory:&lt;/p&gt;&lt;code&gt;sw rs2, imm(rs1)&lt;/code&gt;
&lt;p&gt;Just to make absolutely sure we’re clear on this, load means reading from memory, store means writing to memory. Both words can be nouns and verbs. Also, a word is 32-bit for RISC-V.&lt;/p&gt;&lt;p&gt;Let’s have some fun. Can we have the program read itself?&lt;/p&gt;&lt;p&gt;Ohh that’s fun. Does this mean I can also write programs with just &lt;code&gt;.word&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Oh that’s nice. Just a peek into the world of machine code and instruction encodings… which we will not be getting into.&lt;/p&gt;&lt;p&gt;With memory accesses under our belt, we can address a lot more data easily. Here’s an example where we find the sum of all the values in an array. Note how we can access different addresses of memory, whereas there is no way to address a register by a number in another register.&lt;/p&gt;&lt;p&gt;The equivalent in C would be something like&lt;/p&gt;&lt;code&gt;uint32_t array[], length;

uint32_t *current = array;
uint32_t *end = array + length;
uint32_t sum = 0;

for (; current != end; current ++) {
    sum += *current;
}&lt;/code&gt;
&lt;p&gt;Note how adding one to a pointer to word bumps the address by 4, because the addresses are all byte addresses, and one word is four bytes. In C, the compiler handles the multiplier for you, but in assembly you have to remember to do it manually.&lt;/p&gt;&lt;p&gt;Not everything in memory is word sized. You’ve already seen an array, which is multiple-word-sized. There are also stuff smaller than word-sized.&lt;/p&gt;&lt;p&gt;An obvious one is the byte, which is, well, 1-byte/8-bit and written &lt;code&gt;[u]int8_t&lt;/code&gt; in C. In
the middle is the halfword,
which is 2-byte/16-bit and written &lt;code&gt;[u]int16_t&lt;/code&gt; in C. You can
use the directives &lt;code&gt;.byte&lt;/code&gt; and &lt;code&gt;.half&lt;/code&gt; respectively for those
data types.&lt;/p&gt;&lt;code&gt;.byte value [ , value [ , ...  ] ]
.half value [ , value [ , ...  ] ]&lt;/code&gt;
&lt;p&gt;And just in case you don’t remember those, &lt;code&gt;.2byte&lt;/code&gt; means the same as
&lt;code&gt;.half&lt;/code&gt;, and &lt;code&gt;.4byte&lt;/code&gt; means the same as
&lt;code&gt;.word&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;.2byte value [ , value [ , ...  ] ] # Same as .half
.4byte value [ , value [ , ...  ] ] # Same as .word&lt;/code&gt;
&lt;p&gt;There’s a small problem with loading smaller-than-word sized values into word-sized registers: What do you do with the rest of the bits? Obviously the lowest of the bits gets the actual value loaded. There are two most useful ways to fill the upper bits:&lt;/p&gt;&lt;p&gt;Zero extension is easy enough. As the name suggests, sign extension has something to do with signed values. It’s what happens when you convert a narrower signed value into a wider one.&lt;/p&gt;&lt;p&gt;(Keeping the rest of the bits unchanged isn’t a good option. It complicates the implementation for processor, especially of modern high performance design, to just write parts of a register. It would be easiest if the new value didn’t depend on the old value.)&lt;/p&gt;&lt;p&gt;For example, the signed byte value &lt;code&gt;-100&lt;/code&gt; is
&lt;code&gt;0x9c&lt;/code&gt;. Since the highest bit i.e. the sign bit of it is
&lt;code&gt;1&lt;/code&gt;, when we expand it into 32 bits we fill the high 24 bits
with one so the new value, &lt;code&gt;0xffff_ff9c&lt;/code&gt; still represents
&lt;code&gt;-100&lt;/code&gt;. This is sign extension.&lt;/p&gt;&lt;p&gt;If we want to convert the unsigned byte value &lt;code&gt;156&lt;/code&gt;, still
&lt;code&gt;0x9c&lt;/code&gt;, into an unsigned word, it would have to be
&lt;code&gt;0x0000_009c&lt;/code&gt; to preserve its value.&lt;/p&gt;&lt;p&gt;For bytes, the &lt;code&gt;lb&lt;/code&gt;
(“load byte”) instruction loads a byte and sign extends the result, and
the &lt;code&gt;lbu&lt;/code&gt; (“load byte
unsigned”) instruction does the same but zero extends the result. As
with &lt;code&gt;lw&lt;/code&gt;, the address is &lt;code&gt;rs1 + imm&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;lb rd, imm(rs1)
lbu rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;Similarly for &lt;code&gt;lh&lt;/code&gt;
(“load half”) and &lt;code&gt;lhu&lt;/code&gt;
(“load half unsigned”), just for unsigned halfwords (two bytes each,
remember):&lt;/p&gt;&lt;code&gt;lh rd, imm(rs1)
lhu rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;We can try out the sign extension and zero extension example from earlier.&lt;/p&gt;&lt;p&gt;Correspondingly, the &lt;code&gt;sb&lt;/code&gt; (“store byte”) and &lt;code&gt;sh&lt;/code&gt; (“store half”) do the
opposite of &lt;code&gt;lb&lt;/code&gt; and &lt;code&gt;lh&lt;/code&gt;, storing bytes and
halfwords to memory. Instead of widening small values to register size,
these take the lowest order bits from &lt;code&gt;rs1&lt;/code&gt; and stores it to
memory. (There’s no &lt;code&gt;sbu&lt;/code&gt; and &lt;code&gt;shu&lt;/code&gt; because stores
are narrowing instead of widening operations.)&lt;/p&gt;&lt;code&gt;sb rs2, imm(rs1)
sh rs2, imm(rs1)&lt;/code&gt;
&lt;p&gt;While we’re at it, here’s two more minor details. Firstly, endianness. While theoretically big endian RISC-V machines can exist, I’ve never seen one… and this emulator is little endian, meaning that the four bytes in a word are laid out in memory lowest first. So, &lt;code&gt;.byte 0x1, 0x2, 0x3, 0x4&lt;/code&gt; would be
the same as &lt;code&gt;.word 0x04030201&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Secondly, memory accesses should be aligned for maximum efficiency. This means that the address for a halfword/2byte should be a multiple of two, and the address for a word/4byte should be a multiple of four. Misaligned accesses (meaning, well, when the address is not aligned) may not work as expected.&lt;/p&gt;&lt;p&gt;For user programs running on a rich operating systems, misaligned accesses are supported but may be slow. In embedded application running on microcontrollers and such, it might not work at all.&lt;/p&gt;&lt;p&gt;This emulator supports misaligned memory accesses.&lt;/p&gt;&lt;p&gt;Now you can try translating some basic C code into RISC-V assembly. Functions are… still out of the question for now. Variables have to be either global or put in registers. What else are we missing…&lt;/p&gt;&lt;p&gt;Is it Hello World time? I think it’s Hello World time…&lt;/p&gt;&lt;p&gt;For a computer to not just be a space heater, we need some way for it to at least generate output and take input. While other architectures may have dedicated I/O instructions, RISC-V uses memory mapped I/O. Essentially, this means that loads and stores to special addresses communicate with other devices. They do not work like normal memory, and you should only use the supported widths to access them.&lt;/p&gt;&lt;p&gt;One output device we have here is at address &lt;code&gt;0x1000_0000&lt;/code&gt;. Any 32-bit writes to it appends the lowest 8
bits as a byte to the text in the output pane. In other words, a
&lt;code&gt;sw&lt;/code&gt; to that address writes a byte of output.&lt;/p&gt;&lt;p&gt;(The output pane uses UTF-8 encoding.)&lt;/p&gt;&lt;p&gt;Eh, close enough to greeting the entire world. We could refactor it a bit to use a loop, or whatever… Now that we think about it, how about going one step further and organize our code into some functions?&lt;/p&gt;&lt;p&gt;We already know how to call a function and return back. Namely, &lt;code&gt;jal&lt;/code&gt; calls a function, and &lt;code&gt;ret&lt;/code&gt; returns. Usually
functions take arguments, uses local variables, and returns results.
Since there’s no real difference between the 31 general purpose
registers, on account of them being, well, general purpose, we could
just use any of them as we wish. Usually though, there are some standard
conventions to follow&lt;/p&gt;&lt;p&gt;This whole time you probably have noticed that registers are listed with two names each, and indeed both work identically in assembly.&lt;/p&gt;&lt;p&gt;These register aliases are named after their uses:&lt;/p&gt;&lt;code&gt;s0&lt;/code&gt; through
&lt;code&gt;s11&lt;/code&gt; are saved registers&lt;code&gt;t0&lt;/code&gt; through
&lt;code&gt;t6&lt;/code&gt; are temporary registers&lt;code&gt;a0&lt;/code&gt; through
&lt;code&gt;a7&lt;/code&gt; are argument registers&lt;code&gt;zero&lt;/code&gt; is the,
well, zero register&lt;code&gt;ra&lt;/code&gt; is for the
return address, by convention, as we’ve seen&lt;code&gt;sp&lt;/code&gt; … we’ll talk
about &lt;code&gt;sp&lt;/code&gt; later&lt;code&gt;tp&lt;/code&gt;
and &lt;code&gt;gp&lt;/code&gt; is out of the
scope of this document.)&lt;p&gt;(Yeah it’s… all placed in a weird order. The reason is out of the scope of this tutorial.)&lt;/p&gt;&lt;p&gt;When you call a function, you put up to eight arguments in the… well, argument registers, in the order &lt;code&gt;a0&lt;/code&gt;, &lt;code&gt;a1&lt;/code&gt;, …,
&lt;code&gt;a7&lt;/code&gt;. After that you use &lt;code&gt;jal&lt;/code&gt; or something, which
puts the return address in &lt;code&gt;ra&lt;/code&gt;, and jumps to the
function.&lt;/p&gt;&lt;p&gt;Inside, the function, if it wishes to use the call-saved registers &lt;code&gt;s0&lt;/code&gt; through &lt;code&gt;s11&lt;/code&gt;, it must save their values at
the start of the function, and restore them before returning. The non
call-saved registers &lt;code&gt;a0&lt;/code&gt; through &lt;code&gt;a7&lt;/code&gt;,
&lt;code&gt;t0&lt;/code&gt; through &lt;code&gt;t6&lt;/code&gt; and &lt;code&gt;ra&lt;/code&gt; may be
modified without restoring their values.&lt;/p&gt;&lt;p&gt;When the called function is done, it would, as mentioned, restore any used call-saved registers, and jump back to the return address, resuming the calling code.&lt;/p&gt;&lt;p&gt;Here’s a basic-ish example:&lt;/p&gt;&lt;code&gt;int memcmp(const void *a, const void *b, size_t n)&lt;/code&gt;
&lt;p&gt;The parameter &lt;code&gt;a&lt;/code&gt; is passed in &lt;code&gt;a0&lt;/code&gt;,
&lt;code&gt;b&lt;/code&gt; is passed in &lt;code&gt;a1&lt;/code&gt;, and &lt;code&gt;n&lt;/code&gt; is
passed in &lt;code&gt;a2&lt;/code&gt;. The return value will be in &lt;code&gt;a0&lt;/code&gt;.
Here’s an implementation and test run:&lt;/p&gt;&lt;p&gt;Here’s a slightly better-organized “Hello World”, using a &lt;code&gt;puts&lt;/code&gt; function:&lt;/p&gt;&lt;p&gt;Although we can write some very basic functions now, there are still a few problems:&lt;/p&gt;&lt;code&gt;ra&lt;/code&gt; would be overwritten, and then you can’t return back
from the outer function anymore.&lt;p&gt;Clearly, both would require using memory somehow. We can feed two birds with one scone by using memory in a structured way: The stack.&lt;/p&gt;&lt;p&gt;Unlike some other architectures, the &lt;code&gt;sp&lt;/code&gt; register is not
really special in any way. But just like how we can designate how
&lt;code&gt;a0&lt;/code&gt; is used, we can have some conventions about how
&lt;code&gt;sp&lt;/code&gt; is supposed to be used:&lt;/p&gt;&lt;code&gt;sp&lt;/code&gt; needs to have the same value as when the
function was entered&lt;code&gt;sp&lt;/code&gt; always points to somewhere in an area of
memory called the “stack”, and it is always 16-byte
aligned.&lt;p&gt;And, for the stack itself:&lt;/p&gt;&lt;code&gt;address &amp;gt;= sp&lt;/code&gt; are “in the stack”, and
&lt;code&gt;address &amp;lt; sp&lt;/code&gt; are free space that the stack can grow
into.&lt;code&gt;sp&lt;/code&gt;, and deallocate space by incrementing &lt;code&gt;sp&lt;/code&gt;.
Of course, allocations and deallocations must be balanced properly.&lt;p&gt;An example is in order. Let’s say you have a function &lt;code&gt;foo&lt;/code&gt; which just calls &lt;code&gt;bar&lt;/code&gt; twice.&lt;/p&gt;&lt;code&gt;void foo() {
    bar();
    bar();
}&lt;/code&gt;
&lt;p&gt;Inside &lt;code&gt;foo&lt;/code&gt;, it would need to save the initial
&lt;code&gt;ra&lt;/code&gt;, so it can return back later. Even though
&lt;code&gt;ra&lt;/code&gt; takes only 4 bytes, &lt;code&gt;sp&lt;/code&gt; needs to be 16-byte
aligned at all times, so we round that up to 16 bytes. Decrementing
&lt;code&gt;sp&lt;/code&gt; by 16 we allocate the space:&lt;/p&gt;&lt;code&gt;foo:
    addi sp, sp, -16&lt;/code&gt;
&lt;p&gt;Now, in addition to all of the non call-saved registers, we have 16 bytes of scratch space at &lt;code&gt;sp&lt;/code&gt; through &lt;code&gt;sp + 15&lt;/code&gt;.
We can backup the value of &lt;code&gt;ra&lt;/code&gt; here&lt;/p&gt;&lt;code&gt;    ...
    sw ra, 0(sp)&lt;/code&gt;
&lt;p&gt;Then we just call &lt;code&gt;bar&lt;/code&gt; twice, which overwrites
&lt;code&gt;ra&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;    ...
    jal bar
    jal bar&lt;/code&gt;
&lt;p&gt;At the end of the function, we just need to get back the return address, deallocate the stack space, and return. Although using any register would suffice for the return address, since it is the backed up value of &lt;code&gt;ra&lt;/code&gt; after all, we load it back to
&lt;code&gt;ra&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;    ...
    lw ra, 0(sp)
    addi sp, sp, 16
    ret&lt;/code&gt;
&lt;p&gt;In a similar way you can save and restore the &lt;code&gt;s&lt;/code&gt;
(remember, call-saved) registers. Usually, the most convenient way to
manage this is to put values that need to be preserved across inner
function calls in the &lt;code&gt;s&lt;/code&gt; registers, and then add code at the
beginning to save them, and add code at the end to restore them.&lt;/p&gt;&lt;p&gt;Obligatory recursive Fibonacci time!&lt;/p&gt;&lt;p&gt;The algorithm should be fairly straightforward:&lt;/p&gt;&lt;code&gt;fibonacci(n) {
    if (n &amp;lt; 2) { return n; }
    else { return fib(n - 1) + fib(n - 2); }
}&lt;/code&gt;
&lt;p&gt;What’s worth noting here is the fairly symmetric pattern of saving registers at the start:&lt;/p&gt;&lt;code&gt;    addi sp, sp, -16
    sw ra, 0(sp)
    sw s0, 4(sp)
    sw s1, 8(sp)&lt;/code&gt;
&lt;p&gt;And restoring them at the end:&lt;/p&gt;&lt;code&gt;    lw ra, 0(sp)
    lw s0, 4(sp)
    lw s1, 8(sp)
    addi sp, sp, 16
    ret&lt;/code&gt;
&lt;p&gt;A little thing to also note that the &lt;code&gt;s&lt;/code&gt; registers are
only saved in the more complex branch, where as the simpler branch just
returns directly. This is also acceptable from a calling convention
perspective.&lt;/p&gt;&lt;p&gt;(Note: In the emulator, the &lt;code&gt;sp&lt;/code&gt; register is initialized
to an address that would be convenient for you for use as a stack, as a,
well, convenience.)&lt;/p&gt;&lt;p&gt;Let’s go back to this example:&lt;/p&gt;&lt;code&gt;    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
puts_loop:
    lb t0, 0(a0)
    beq t0, zero, puts_done
    sw t0, 0(t1)
    addi a0, a0, 1
    j puts_loop

puts_done:
    ret&lt;/code&gt;
&lt;p&gt;Having to name things like &lt;code&gt;puts_loop&lt;/code&gt;,
&lt;code&gt;puts_done&lt;/code&gt; is a bit annoying. There’s a shorter way: numeric labels.&lt;/p&gt;&lt;p&gt;A numeric label is one with a name of a decimal number. To refer to a numeric label, use the number and a &lt;code&gt;f&lt;/code&gt; suffix for “forward”,
and &lt;code&gt;b&lt;/code&gt; for “backward”, and it will correspond to the nearest
numeric label with that number, searching forwards or backwards,
respectively.&lt;/p&gt;&lt;p&gt;So, the &lt;code&gt;puts&lt;/code&gt; example from earlier can be rewritten:&lt;/p&gt;&lt;code&gt;    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
1:
    lb t0, 0(a0)
    beq t0, zero, 2f
    sw t0, 0(t1)
    addi a0, a0, 1
    j 1b

2:
    ret&lt;/code&gt;
&lt;p&gt;Yeah I don’t really like this syntax either, but it is what we’ve got.&lt;/p&gt;&lt;p&gt;Remember that oddball instruction I mentioned way back, &lt;code&gt;auipc&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;I don’t know about your experience, but the first time I saw RISC-V disassembly, this is the one instruction that caught my eye. And this memory has stuck with me ever since. It’s a rather common occurrence in real RISC-V programs, and somehow I’ve been hiding it from you this whole time. If you take a sneak peek at the next section’s title, you’ll see how far we’ve come without &lt;code&gt;auipc&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;So what does it do?&lt;/p&gt;&lt;p&gt;The &lt;code&gt;auipc&lt;/code&gt; (“add
upper immediate to pc”) instruction is very similar to &lt;code&gt;lui&lt;/code&gt;.
Instead of setting &lt;code&gt;rd&lt;/code&gt; to &lt;code&gt;imm20 &amp;lt;&amp;lt; 12&lt;/code&gt;, it
sets it to &lt;code&gt;pc + (imm20 &amp;lt;&amp;lt; 12)&lt;/code&gt;, where &lt;code&gt;pc&lt;/code&gt;
is the address of the &lt;code&gt;auipc&lt;/code&gt; instruction itself.&lt;/p&gt;&lt;code&gt;auipc rd, imm20&lt;/code&gt;
&lt;p&gt;It works very similarly to &lt;code&gt;lui&lt;/code&gt;. You can think of them as
a pair: the “base” of &lt;code&gt;lui&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;, whereas the
“base” of &lt;code&gt;auipc&lt;/code&gt; is the address of the &lt;code&gt;auipc&lt;/code&gt;
instruction. So this code:&lt;/p&gt;&lt;code&gt;start:
    lui a0, 3
    addi a0, a0, 4&lt;/code&gt;
&lt;p&gt;Gives you &lt;code&gt;0x3004&lt;/code&gt;, whereas this:&lt;/p&gt;&lt;code&gt;start:
    auipc a0, 3
    addi a0, a0, 4&lt;/code&gt;
&lt;p&gt;Gives you &lt;code&gt;start + 0x3004&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Why would you need this? On modern systems, it’s often desirable to have machine code that can be moved around in address space. For example, a shared library i.e. dynamically linked library can be loaded into any program, at any address. It would be helpful if the machine code does not need to be patched every time. This is called position independent code (PIC).&lt;/p&gt;&lt;p&gt;Some instructions already exhibit position independence. For example, as mentioned earlier when we talked about using &lt;code&gt;lui&lt;/code&gt; and
&lt;code&gt;jalr&lt;/code&gt; as a pair, the branch instructions and
&lt;code&gt;jal&lt;/code&gt; are encoded, as with all RV32I instructions, into
32-bit instruction words, so they can’t possibly be able to encode every
possible address. Instead, the jump destination is &lt;code&gt;pc&lt;/code&gt; plus
some offset (&lt;code&gt;pc&lt;/code&gt; being, as before, the jump/branch
instruction itself), and the offset itself is encoded.&lt;/p&gt;&lt;p&gt;You can see these are three different instructions that jump to itself. Since the offset is &lt;code&gt;0&lt;/code&gt; in each case, the encoding is
the same. Use the “Dump” button to see for yourself.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;auipc&lt;/code&gt; instruction allows for very flexible position
independence. You can make arbitrary calculations based on the address
at which code is located. The immediate-bit operand mirroring
&lt;code&gt;lui&lt;/code&gt; means that it is well suited for two-instruction pairs,
just like &lt;code&gt;lui&lt;/code&gt;. These kind of “&lt;code&gt;pc&lt;/code&gt; plus
something” calculations are known as pc-relative
addressing.&lt;/p&gt;&lt;p&gt;The syntax for getting the assembler to generate the immediate values for pc-relative addressing a bit arcane but hear me out:&lt;/p&gt;&lt;p&gt;Like &lt;code&gt;%hi()&lt;/code&gt; and &lt;code&gt;%lo()&lt;/code&gt;, &lt;code&gt;%pcrel_hi()&lt;/code&gt; and &lt;code&gt;%pcrel_lo()&lt;/code&gt; gives you
the immediate values needed for pc-relative addressing. You pass the
label you want to address to &lt;code&gt;%pcrel_hi()&lt;/code&gt;, but pass a label
to the &lt;code&gt;auipc&lt;/code&gt; instruction to
&lt;code&gt;%pcrel_lo()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Unlike &lt;code&gt;%lo()&lt;/code&gt;, We need the address of the
&lt;code&gt;auipc&lt;/code&gt; instruction itself to calculate the immediate value,
and this is why you need to pass a label to it. You don’t need to write
&lt;code&gt;foo&lt;/code&gt; again, since the assembler will look at the
&lt;code&gt;auipc&lt;/code&gt; instruction and see it’s supposed to be for
&lt;code&gt;foo&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If you hate writing that, you can also use the convenience pseudoinstruction &lt;code&gt;la&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;la rd, label&lt;/code&gt;
&lt;p&gt;Just like a &lt;code&gt;lui&lt;/code&gt; + &lt;code&gt;jalr&lt;/code&gt; pair, an
&lt;code&gt;auipc&lt;/code&gt; + &lt;code&gt;jalr&lt;/code&gt; can be used to jump to somewhere
farther away than one &lt;code&gt;jal&lt;/code&gt; can reach in position-independent
code.&lt;/p&gt;&lt;p&gt;One very common case is to call a function that might not be within reach of &lt;code&gt;jal&lt;/code&gt;. You can use the pseudoinstruction &lt;code&gt;call&lt;/code&gt; for that.&lt;/p&gt;&lt;code&gt;call label&lt;/code&gt;
&lt;p&gt;This expands to:&lt;/p&gt;&lt;code&gt;1:
    auipc ra, %pcrel_hi(label)
    jalr ra, %pcrel_lo(1b)(ra)&lt;/code&gt;
&lt;p&gt;Notice how &lt;code&gt;ra&lt;/code&gt; is used as a temporary register to store
the intermediate result, which is immediately overwritten by
&lt;code&gt;jalr&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In fact, there really isn’t any reason to prefer &lt;code&gt;lui&lt;/code&gt;
over &lt;code&gt;auipc&lt;/code&gt; when using a label. This is why you if you
disassemble a real RISC-V program, you see it everywhere, even in
non-position-independent code.&lt;/p&gt;&lt;p&gt;Now would be a good time to take a break, since we’re ready to head into…&lt;/p&gt;&lt;p&gt;We’re going to write an extremely bare bones operating system.&lt;/p&gt;&lt;p&gt;One of the tasks an operating system performs is to control what programs can and cannot do. On RISC-V, the most basic of this control is implemented using privilege levels. RISC-V defines… let’s just say, several privilege levels, but we’re only going to use two here:&lt;/p&gt;&lt;p&gt;The lower the privilege level number goes, the less privileged that level is. Higher privilege levels treat lower privilege levels as generally completely unreliable and untrusted, and must isolate themselves from adversarial software and failures of lower privilege levels.&lt;/p&gt;&lt;p&gt;(However, we won’t be talking about all of the features that make this full isolation possible, and the emulator you’ve been seeing does not have enough features for that anyway. Therefore, the operating system we’ll be building will leave itself unprotected in various ways.)&lt;/p&gt;&lt;p&gt;The privilege levels are sometimes called “modes” for short. And, if that’s not short enough, we can shorten the level names themselves, ending up with M-mode and U-mode. All of the ways to refer to these privilege levels are interchangable.&lt;/p&gt;&lt;p&gt;When a RISC-V machine starts (This is known as “reset”), it begins execution in Machine mode. On a typical “embedded” system where only Machine mode and User mode are implemented, execution begins in the initialization code read from flash memory. This code can either perform what needs to be done itself, or it can be an operating system that manages some tasks, each executing in User mode.&lt;/p&gt;&lt;p&gt;The former design is used for simpler programs, and is analogous to the programs we’ve seen and run so far. The latter is more complicated. We’ll see the basics of how to achieve that soon.&lt;/p&gt;&lt;p&gt;The control and status registers (CSRs) deal with various features that are in some sense “special”. No I don’t have a better explanation of what “special” means.&lt;/p&gt;&lt;p&gt;Six instructions are available for manipulating CSRs.&lt;/p&gt;&lt;code&gt;csrrw rd, csr, rs1
csrrs rd, csr, rs1
csrrc rd, csr, rs1
csrrwi rd, csr, uimm5
csrrsi rd, csr, uimm5
csrrci rd, csr, uimm5&lt;/code&gt;
&lt;p&gt;To refer to a CSR in these instructions, use its name in assembly code. We’ll get to those in a bit.&lt;/p&gt;&lt;p&gt;The pattern works like this. Each of the instructions atomically reads the old value of the CSR, and writes the new value based on some operation performed on the old value and the last operand. The possible operations are:&lt;/p&gt;&lt;code&gt;csrrw&lt;/code&gt; (“CSR read
write”): &lt;code&gt;{ csr = rs1; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrs&lt;/code&gt; (“CSR read
set”): &lt;code&gt;{ csr = csr | rs1; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrc&lt;/code&gt; (“CSR read
clear”): &lt;code&gt;{ csr = csr &amp;amp; ~rs1; rd = csr_old; }&lt;/code&gt;&lt;p&gt;Where &lt;code&gt;&amp;amp;&lt;/code&gt;, &lt;code&gt;|&lt;/code&gt;, &lt;code&gt;~&lt;/code&gt; are bitwise
“and”, “or”, “not” respectively.&lt;/p&gt;&lt;p&gt;Specifically, note that &lt;code&gt;rd&lt;/code&gt; and &lt;code&gt;rs1&lt;/code&gt; can be
the same. For example, this instruction swaps the value in
&lt;code&gt;a0&lt;/code&gt; and &lt;code&gt;mscratch&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;csrrw a0, mscratch, a0&lt;/code&gt;
&lt;p&gt;For the “immediate” variants, instead of a register, they take an “unsigned”/zero-extended 5-bit immediate value, i.e. an immediate value 0 through 31, inclusive. This is represented using &lt;code&gt;uimm5&lt;/code&gt; in
the assembly syntax description. The operation is the same
otherwise.&lt;/p&gt;&lt;code&gt;csrrwi&lt;/code&gt; (“CSR
read write immediate”): &lt;code&gt;{ csr = uimm5; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrsi&lt;/code&gt; (“CSR
read set immediate”):
&lt;code&gt;{ csr = csr | uimm5; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrci&lt;/code&gt; (“CSR
read clear immediate”):
&lt;code&gt;{ csr = csr &amp;amp; ~uimm5; rd = csr_old; }&lt;/code&gt;&lt;p&gt;The full feature set of these instructions are designed for manipulating bit fields in CSRs, which we will not be doing that much of in this tutorial. Still, this orthogonal design should be fairly intuitive to remember.&lt;/p&gt;&lt;p&gt;CSRs and fields in CSRs do not behave like general purpose registers: Some of them are read/write, some are read-only. Also, invalid values have special behaviors. We will touch on more details as we introduce the individual CSRs themselves, but one thing you may have noticed is that we don’t seem to have read-only CSR instructions. Read-only access is achieved using special cases in the instruction encodings:&lt;/p&gt;&lt;code&gt;csrrs&lt;/code&gt; and &lt;code&gt;csrrc&lt;/code&gt; do not write to the CSR if
&lt;code&gt;rs1&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; (a.k.a. &lt;code&gt;zero&lt;/code&gt;) (Note
that just the value of &lt;code&gt;rs1&lt;/code&gt; being 0 is not enough.)&lt;code&gt;csrrsi&lt;/code&gt; and &lt;code&gt;csrrci&lt;/code&gt; do not write to the CSR
if &lt;code&gt;uimm5&lt;/code&gt; is 0.&lt;p&gt;While we’re at it:&lt;/p&gt;&lt;code&gt;csrrw&lt;/code&gt; and &lt;code&gt;csrrwi&lt;/code&gt; do not read the CSR if
&lt;code&gt;rd&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; (a.k.a. &lt;code&gt;zero&lt;/code&gt;). (Note
that writing to &lt;code&gt;x0&lt;/code&gt; has no effect anyway, since it’s
constant 0.)&lt;p&gt;(No standard RISC-V CSR is write-only, or has side effects on read.)&lt;/p&gt;&lt;p&gt;As a convenience, the pseudoinstructions &lt;code&gt;csrr&lt;/code&gt; (“CSR read”) and &lt;code&gt;csrw&lt;/code&gt; (“CSR write”) are
available. &lt;code&gt;csrw csr, rs1&lt;/code&gt; expands to
&lt;code&gt;csrrw x0, csr, rs1&lt;/code&gt;. Meanwhile, &lt;code&gt;csrr rd, csr&lt;/code&gt;
expands specifically to &lt;code&gt;csrrs rd, csr, x0&lt;/code&gt;, just so we can
agree on an encoding.&lt;/p&gt;&lt;code&gt;csrw csr, rs1
csrr rd, csr&lt;/code&gt;
&lt;p&gt;You may have seen these CSR things if you’ve scrolled down on the register view. Yes, we’re finally getting into those.&lt;/p&gt;&lt;p&gt;An example of CSRs is counters. Two basic read-only counters are &lt;code&gt;cycle&lt;/code&gt; and
&lt;code&gt;instret&lt;/code&gt;. These
counters, well, count the number of “cycles” and “instructions
retired”. “Retired” is a technical term basically meaning “successfully
completed”.&lt;/p&gt;&lt;p&gt;Since a 32-bit counter will overflow quite fast, on RV32, the counters have “high” counterparts: &lt;code&gt;cycleh&lt;/code&gt; and &lt;code&gt;instreth&lt;/code&gt;. So, for
example, the full cycle counter has 64 bits, with the lower 32 bits in
the CSR &lt;code&gt;cycle&lt;/code&gt; and higher 32 bits in the CSR
&lt;code&gt;cycleh&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;While the emulator is running, scroll down on the register view panel, and on the bottom you’ll see the values of these counters. For convenience, they’re shown combined, so, &lt;code&gt;cycle = 0x11223344_55667788&lt;/code&gt; means &lt;code&gt;cycleh&lt;/code&gt; is
&lt;code&gt;0x11223344&lt;/code&gt;, and &lt;code&gt;cycle&lt;/code&gt; is
&lt;code&gt;0x55667788&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;On real hardware &lt;code&gt;cycle&lt;/code&gt; is coupled to the clock cycle. In
this emulator, every time you press “Step”, it counts as a cycle. When
you press “Run” and it starts, well, running, a certain number of cycles
happen periodically.&lt;/p&gt;&lt;p&gt;Let’s look at a really simple example:&lt;/p&gt;&lt;p&gt;It takes 4 cycles for this program to stop, but &lt;code&gt;instret&lt;/code&gt;
ends up at only 3 because the final &lt;code&gt;ebreak&lt;/code&gt; instruction
never actually completes.&lt;/p&gt;&lt;p&gt;(Do not confuse “retired” with “retried”.)&lt;/p&gt;&lt;p&gt;A program can read its own counters. For example, this fun little program loops until the cycle count is over 1000, assuming the low 32 bits doesn’t overflow before it has time to react:&lt;/p&gt;&lt;p&gt;Technically &lt;code&gt;cycle&lt;/code&gt; and &lt;code&gt;instret&lt;/code&gt; are not part
of the privileged architecture. The real fun begins now.&lt;/p&gt;&lt;p&gt;The emulator shows the current privilege level as &lt;code&gt;(priv)&lt;/code&gt;. It is in parentheses to remind you of a very
important fact:&lt;/p&gt;&lt;p&gt;There is no CSR for the current privilege level.&lt;/p&gt;&lt;p&gt;In general, it is not possible for a RISC-V program to learn what privilege level it’s in. This is required for the Popek and Goldberg conditions of virtualization to work, specifically because being able to read the current privilege level at a lower-than-maximum privilege level would be a “sensitive” but “unprivileged” instruction.&lt;/p&gt;&lt;p&gt;If you’re writing a program for a certain privilege level, you should simply assume that it is correctly being run at that privilege level.&lt;/p&gt;&lt;p&gt;A fundamental way an operating system does its job is through handling exceptions. In general, exceptions occur when there’s a problem with a specific instruction, and execution cannot continue. For example, since &lt;code&gt;cycle&lt;/code&gt; is a read-only CSR, writing to it is
an illegal instruction:&lt;/p&gt;&lt;p&gt;Since we have no exception handling in the program, we’ll have to inspect what happened manually in the emulator. Indeed, a lot has happened:&lt;/p&gt;&lt;p&gt;Firstly, this message tells you that an exception happened:&lt;/p&gt;&lt;code&gt;[ Exception: Illegal instruction (2) | tval = 0xc0001073, epc = 0x4000000c ]&lt;/code&gt;
&lt;p&gt;The same information is now also available in the CSRs, as follows:&lt;/p&gt;&lt;code&gt;mcause&lt;/code&gt; (“M-mode
trap cause”): The kind of exception.&lt;code&gt;mepc&lt;/code&gt; (“M-mode
exception pc”): The address of the instruction that caused the
exception.&lt;code&gt;mtval&lt;/code&gt; (“M-mode
trap value”): Extra information about the exception.&lt;code&gt;mstatus&lt;/code&gt; (“M-mode
status”): It is set to &lt;code&gt;0x00001800&lt;/code&gt;. The two bits in the
middle, &lt;code&gt;mstatus[12:11]&lt;/code&gt; (In C syntax,
&lt;code&gt;(mstatus &amp;gt;&amp;gt; 11) &amp;amp; 0x3&lt;/code&gt;) is the
&lt;code&gt;mstatus.MPP&lt;/code&gt; (“M-mode previous privilege level”) field,
which contains 3, meaning that the exception occurred while running in
Machine mode.&lt;p&gt;When an exception happens, in addition to recording the exception information in these CSR fields, &lt;code&gt;pc&lt;/code&gt; is set to
&lt;code&gt;mtvec&lt;/code&gt;, which is supposed to be the handler address. Let’s
write ourselves an exception handler that simply prints a message and
stops the emulator, and see the handling in action:&lt;/p&gt;&lt;p&gt;Yeah it just prints &lt;code&gt;Oh no!&lt;/code&gt; on error. Baby steps…&lt;/p&gt;&lt;p&gt;The checkboxes “Pause on exc.” and “Print on exc.” control whether the emulator should pause or print a message, respectively, when an exception occurs. You can uncheck those if you want the exception handler set in the program to run without interference.&lt;/p&gt;&lt;p&gt;(Another case that will cause a jump to &lt;code&gt;mtvec&lt;/code&gt; is interrupts. However, this feature
does not exist in the emulator. The two cases are collectively called
traps.)&lt;/p&gt;&lt;p&gt;These are the exceptions possible in this emulator, and their respective numeric codes:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;Instruction address misaligned&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;cell&gt;Instruction access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;Illegal instruction&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;3&lt;/cell&gt;&lt;cell&gt;Breakpoint&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;5&lt;/cell&gt;&lt;cell&gt;Load access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;cell&gt;Store/AMO access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;cell&gt;Environment call from User mode&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;11&lt;/cell&gt;&lt;cell&gt;Environment call from Machine mode&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;“Instruction address misaligned” happens when attempting to jump to an instruction that is not 4-byte aligned. The exception happens on the jump or branch instruction, not the target.&lt;/p&gt;&lt;p&gt;“Load access fault” and “Store/AMO access fault” happens when accessing an invalid memory address, or accessing a memory address in an invalid way.&lt;/p&gt;&lt;p&gt;(“AMO” stands for “atomic memory operation”, which we will not talk about and is not featured in the emulator.)&lt;/p&gt;&lt;p&gt;“Illegal instruction” happens not only in the self explanatory way when an invalid instruction is executed, but also when accessing a CSR in an invalid way, or from too low a privilege level.&lt;/p&gt;&lt;p&gt;“Breakpoint”, “Environment call from User mode” and “Environment call from Machine mode” will be explained in a future section.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;mret&lt;/code&gt; (“M-mode
return”) instruction performs the reverse of part of what happens when
an exception occurs. To be precise, what happens is:&lt;/p&gt;&lt;code&gt;mstatus.MPP&lt;/code&gt;&lt;code&gt;mstatus.MPP&lt;/code&gt; is set to 0&lt;code&gt;pc&lt;/code&gt; is set to &lt;code&gt;mepc&lt;/code&gt;&lt;p&gt;(You can think of the privilege mode bits as shifting in a chain &lt;code&gt;0 → MPP → priv&lt;/code&gt;. And, to be even more precise,
&lt;code&gt;mstatus.MPP&lt;/code&gt; is set to the lowest supported privilege mode
since it’s not supposed to contain unsupported modes.)&lt;/p&gt;&lt;p&gt;&lt;code&gt;mret&lt;/code&gt; takes no operands, so the assembly syntax is
simply:&lt;/p&gt;&lt;code&gt;mret&lt;/code&gt;
&lt;p&gt;If we do &lt;code&gt;mret&lt;/code&gt; after getting an exception, then we simply
go back to retrying the same instruction again. This is useful for more
featureful implementations, where for example, after handling a page
fault the correct course of action is to retry the faulting
instruction.&lt;/p&gt;&lt;p&gt;However, &lt;code&gt;mstatus&lt;/code&gt; and &lt;code&gt;mepc&lt;/code&gt; are also
writable. This gives us more flexibility in the use of
&lt;code&gt;mret&lt;/code&gt;. As an analogy, the same &lt;code&gt;jr&lt;/code&gt; instruction
(really &lt;code&gt;jalr&lt;/code&gt; instruction) can be used to return from a
call, and also can be used to jump to any address. Similarly,
&lt;code&gt;mret&lt;/code&gt; not only lets us return from an exception, but also
lets us jump to any address and switch to any privilege
level.&lt;/p&gt;&lt;p&gt;Even though &lt;code&gt;mret&lt;/code&gt; is named “return”, it is in fact the
only way to lower the privilege level to enter User mode.
Here’s an example of entering User mode, with a User mode program that
does something bad:&lt;/p&gt;&lt;p&gt;As you can see, after we enter User mode, all of the CSRs used for exception handling become completely inaccessible, not even readable. As with writing a read-only CSR, accessing an CSR without permission also causes an illegal instruction exception.&lt;/p&gt;&lt;p&gt;Moreover, when an exception happens, we go back to Machine mode, so the exception handler runs in Machine mode. Here the handler does nothing except stopping the emulator.&lt;/p&gt;&lt;p&gt;Sometimes, a program may wish to intentionally cause an exception. There are several well-defined way to do that:&lt;/p&gt;&lt;code&gt;unimp&lt;/code&gt; has the same encoding
as &lt;code&gt;csrrw zero, cycle, zero&lt;/code&gt;, and it is the canonical RV32I
illegal instruction. It causes causes an “Illegal instruction”
exception.&lt;code&gt;ebreak&lt;/code&gt; causes a
“Breakpoint” exception&lt;code&gt;ecall&lt;/code&gt; causes an
“Environment call from User mode” exception when executed in User mode,
and “Environment call from Machine mode” exception when executed in
Machine mode.&lt;p&gt;Give those exceptions a try here:&lt;/p&gt;&lt;p&gt;As the names suggest, &lt;code&gt;ebreak&lt;/code&gt; is used for debugging
breakpoints. As a special case, in this emulator &lt;code&gt;ebreak&lt;/code&gt; in
Machine mode stops the emulator. You can think of it as the emulator
being a debugger, and the debugger catching the breakpoint.&lt;/p&gt;&lt;p&gt;&lt;code&gt;unimp&lt;/code&gt; can be used to intentionally crash a program upon
detection of some unrecoverable error.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;code&gt;ecall&lt;/code&gt; is used for things like system calls.
“Environment call from User mode” is a distinct exception cause code to
make it easy to check specifically for this case.&lt;/p&gt;&lt;p&gt;One thing that you would want in your trap handler is to not trust or disturb any general purpose registers in the code that the trap occurred in, unless you intentionally want to do so, for example to return a value from a system call. So you’d want to save all the registers to memory, before doing anything else. However, accessing memory requires a general purpose register.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;mscratch&lt;/code&gt;
(“M-mode scratch”) CSR can help with this. This register, unlike all the
others, have no special functionality. It can hold any 32-bit value.
However, like all the other M-mode CSRs, it can only be accessed in
Machine mode. User mode code cannot change the value of it.&lt;/p&gt;&lt;p&gt;So for example, you can stash the operating system stack pointer in &lt;code&gt;mscratch&lt;/code&gt; before switching to User mode, and it will stay in
&lt;code&gt;mscratch&lt;/code&gt; untouched in User mode. At the top of the handler,
&lt;code&gt;csrrw sp, mscratch, sp&lt;/code&gt; to swap from the user stack pointer
to the operating system stack pointer.&lt;/p&gt;&lt;code&gt;handler:
    csrrw sp, mscratch, sp
    # Save registers except sp
    csrr t0, mscratch
    # t0 = user sp, save it
    # Save user pc
    ...&lt;/code&gt;
&lt;p&gt;And, to restore:&lt;/p&gt;&lt;code&gt;    lw t0, ... # Load user pc
    csrw mepc, t0
    lw t0, ... # Load user sp
    csrw mscratch, t0
    # Restore registers except sp
    csrrw sp, mscratch, sp
    mret&lt;/code&gt;
&lt;p&gt;We’ll see the full code for this in the following section.&lt;/p&gt;&lt;p&gt;We have enough of to write a very very bare bones operating system. It will support these features:&lt;/p&gt;&lt;code&gt;a7 = 1&lt;/code&gt;: putchar, &lt;code&gt;a0&lt;/code&gt; is the byte to
write&lt;code&gt;a7 = 2&lt;/code&gt;: exit&lt;p&gt;We design the exception handling as follows:&lt;/p&gt;&lt;code&gt;mscratch&lt;/code&gt; is 0.&lt;code&gt;mscratch&lt;/code&gt; points to the operating
system stack pointer&lt;code&gt;mscratch&lt;/code&gt; is 0, the exception came
from M-mode, which we cannot handle, so we report a fatal
exception.&lt;code&gt;trap_main&lt;/code&gt;, which manipulates
U-mode registers in memory&lt;code&gt;trap_main&lt;/code&gt;, we restore registers from memory,
deallocate the space from the stack, and go back to U-mode, as outlined
in the previous section.&lt;p&gt;The structure to save registers in is fairly simple:&lt;/p&gt;&lt;code&gt;struct regs {
  unsigned long pc;
  unsigned long ra; // x1
  unsigned long sp; // x2
  ...
  unsigned long t6; // x31
};&lt;/code&gt;
&lt;p&gt;Basically you can think of it as an array where element 0 is &lt;code&gt;pc&lt;/code&gt;, and elements 1 through 31 are registers x1 through
x31.&lt;/p&gt;&lt;p&gt;Inside &lt;code&gt;trap_main&lt;/code&gt;, we check &lt;code&gt;mcause&lt;/code&gt; to see if
it’s a system call. If it is, we dispatch based on &lt;code&gt;a7&lt;/code&gt;. If
it’s not, we report an exception from U-mode.&lt;/p&gt;&lt;p&gt;At the beginning, we simply initialize the &lt;code&gt;struct regs&lt;/code&gt;
structure on stack, initialize user &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt;
in it, and jump to the same code that handles returning to U-mode.&lt;/p&gt;&lt;p&gt;Here’s the assembly code with User mode code at the bottom. You may want to uncheck “Pause on exc.” and “Print on exc.” for convenience.&lt;/p&gt;&lt;p&gt;Do not be too hard on yourself if you have trouble understanding the code fully. This is, after all, a fairly complete OS kernel entry and exit implementation. Really, the most important part I’m showing you here is that it is possible.&lt;/p&gt;&lt;p&gt;For reference, here’s some of the OS code in pseudo-C.&lt;/p&gt;&lt;code&gt;void trap_main(struct regs *regs) {
    unsigned long cause = csr_read(mcause);
    if (cause != 8)
        do_bad_exception(regs, cause);

    # Call do_syscall with args from ecall
    unsigned long ret = do_syscall(regs-&amp;gt;a0, ..., regs-&amp;gt;a7);
    regs-&amp;gt;a0 = ret;

    // Bump user pc by 4, skip over ecall instruction
    regs-&amp;gt;pc += 4;
}

unsigned long do_syscall(
    unsigned long a0,
    ...,
    unsigned long a7
) {
    if (a7 == 1)
        sys_putchar(a0);
    else if (a7 == 8)
        sys_exit();
    else
        return -1;
}

unsigned long sys_putchar(char a) {
    kputchar(a);
    return 0;
}

[[noreturn]]
unsigned long sys_exit(char a) {
    ebreak();
}

[[noreturn]]
void do_bad_exception(struct regs *regs, unsigned long cause) {
    kputs("Exception 0x");
    kputchar(hex_chars[cause]);
    kputchar('\n');
    ebreak();
}

[[noreturn]]
void fatal() {
    kputs("Fatal exception\n");
    ebreak();
}

void kputs(const char *str) {
    while (*str) {
        u32 val = (u32)*str;
        writel(0x10000000, val); // MMIO write
        str ++;
    }
}

void kputchar(char c) {
    u32 val = (u32)c;
    writel(0x10000000, val); // MMIO write
}&lt;/code&gt;
&lt;p&gt;And here’s the user code, again in pseudo C:&lt;/p&gt;&lt;code&gt;[[noreturn]]
void user_entry() {
    puts(...);
    exit();
}

void puts(const char *str) {
    while (*str) {
        putchar(*str);
        str ++;
    }
}

void putchar(char c) {
    ecall(a0 = c, a7 = 1);
}

void exit() {
    ecall(a7 = 2);
}&lt;/code&gt;
&lt;p&gt;As long as this tutorial is, some simplifications have been made. Here are some of the most egregious lies and omissions, compared to the “real” RISC-V architecture and “real” RISC-V assembly code found in the world:&lt;/p&gt;&lt;code&gt;li&lt;/code&gt; pseudoinstruction should support a wider range
of constants.&lt;code&gt;mstatus&lt;/code&gt; is a lot more complicated than what I have
described.&lt;code&gt;%hi&lt;/code&gt;, &lt;code&gt;%lo&lt;/code&gt;, &lt;code&gt;%pcrel_hi&lt;/code&gt;,
&lt;code&gt;%pcrel_lo&lt;/code&gt; are more complicated than what I have
described.&lt;p&gt;There are also very important topics that are common or even ubiquitous in the RISC-V world, but I chose not to cover:&lt;/p&gt;&lt;p&gt;However, what I’ve taught you should be more than enough to get you started into learning more on your own, or with further materials.&lt;/p&gt;&lt;p&gt;Here are some references and tutorials I would personally recommend, if you’re looking to get further into RISC-V low-level development&lt;/p&gt;&lt;p&gt;Other useful resources that I have used while writing this tutorial:&lt;/p&gt;&lt;code&gt;arch/riscv/kernel/entry.S&lt;/code&gt; from Linux https://elixir.bootlin.com/linux/latest/source/arch/riscv/kernel/entry.S&lt;p&gt;Thanks to these folks for UI design help and content suggestions:&lt;/p&gt;&lt;p&gt;And thanks to you for coming along with me on this journey. Come on over to https://github.com/dramforever/easyriscv if you have suggestions, grievances, or just want to share some thoughts.&lt;/p&gt;&lt;p&gt;This tutorial is provided under the CC0 license. To the maximum extent permitted by law, this tutorial is dedicated to the public domain.&lt;/p&gt;&lt;p&gt;The associated code in the repository is provided under, of your choosing, either the CC0 license or the 0-clause “BSD” license.&lt;/p&gt;&lt;code&gt;add&lt;/code&gt;&lt;code&gt;addi&lt;/code&gt;&lt;code&gt;and&lt;/code&gt;&lt;code&gt;andi&lt;/code&gt;&lt;code&gt;auipc&lt;/code&gt;&lt;code&gt;beq&lt;/code&gt;&lt;code&gt;bge&lt;/code&gt;&lt;code&gt;bgeu&lt;/code&gt;&lt;code&gt;blt&lt;/code&gt;&lt;code&gt;bltu&lt;/code&gt;&lt;code&gt;bne&lt;/code&gt;&lt;code&gt;call&lt;/code&gt;&lt;code&gt;csrr&lt;/code&gt;&lt;code&gt;csrrc&lt;/code&gt;&lt;code&gt;csrrci&lt;/code&gt;&lt;code&gt;csrrs&lt;/code&gt;&lt;code&gt;csrrsi&lt;/code&gt;&lt;code&gt;csrrw&lt;/code&gt;&lt;code&gt;csrrwi&lt;/code&gt;&lt;code&gt;csrw&lt;/code&gt;&lt;code&gt;ebreak&lt;/code&gt;&lt;code&gt;ecall&lt;/code&gt;&lt;code&gt;j&lt;/code&gt;&lt;code&gt;jal&lt;/code&gt;&lt;code&gt;jalr&lt;/code&gt;&lt;code&gt;jr&lt;/code&gt;&lt;code&gt;la&lt;/code&gt;&lt;code&gt;lb&lt;/code&gt;&lt;code&gt;lbu&lt;/code&gt;&lt;code&gt;lh&lt;/code&gt;&lt;code&gt;lhu&lt;/code&gt;&lt;code&gt;li&lt;/code&gt;&lt;code&gt;lui&lt;/code&gt;&lt;code&gt;lw&lt;/code&gt;&lt;code&gt;mret&lt;/code&gt;&lt;code&gt;mv&lt;/code&gt;&lt;code&gt;or&lt;/code&gt;&lt;code&gt;ori&lt;/code&gt;&lt;code&gt;ret&lt;/code&gt;&lt;code&gt;sb&lt;/code&gt;&lt;code&gt;sh&lt;/code&gt;&lt;code&gt;sll&lt;/code&gt;&lt;code&gt;slli&lt;/code&gt;&lt;code&gt;slt&lt;/code&gt;&lt;code&gt;slti&lt;/code&gt;&lt;code&gt;sltiu&lt;/code&gt;&lt;code&gt;sltu&lt;/code&gt;&lt;code&gt;sra&lt;/code&gt;&lt;code&gt;srai&lt;/code&gt;&lt;code&gt;srl&lt;/code&gt;&lt;code&gt;srli&lt;/code&gt;&lt;code&gt;sub&lt;/code&gt;&lt;code&gt;sw&lt;/code&gt;&lt;code&gt;unimp&lt;/code&gt;&lt;code&gt;xor&lt;/code&gt;&lt;code&gt;xori&lt;/code&gt;&lt;code&gt;imm&lt;/code&gt;&lt;code&gt;pc&lt;/code&gt;&lt;code&gt;rd&lt;/code&gt;&lt;code&gt;rs1&lt;/code&gt;&lt;code&gt;rs2&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dramforever.github.io/easyriscv/"/><published>2025-10-27T20:57:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45727060</id><title>OpenAI says over a million people talk to ChatGPT about suicide weekly</title><updated>2025-10-28T13:45:26.470495+00:00</updated><content>&lt;doc fingerprint="340b5d718824effe"&gt;
  &lt;main&gt;
    &lt;p&gt;OpenAI released new data on Monday illustrating how many of ChatGPT’s users are struggling with mental health issues and talking to the AI chatbot about it. The company says that 0.15% of ChatGPT’s active users in a given week have “conversations that include explicit indicators of potential suicidal planning or intent.” Given that ChatGPT has more than 800 million weekly active users, that translates to more than a million people a week.&lt;/p&gt;
    &lt;p&gt;The company says a similar percentage of users show “heightened levels of emotional attachment to ChatGPT,” and that hundreds of thousands of people show signs of psychosis or mania in their weekly conversations with the AI chatbot.&lt;/p&gt;
    &lt;p&gt;OpenAI says these types of conversations in ChatGPT are “extremely rare,” and thus difficult to measure. That said, the company estimates these issues affect hundreds of thousands of people every week.&lt;/p&gt;
    &lt;p&gt;OpenAI shared the information as part of a broader announcement about its recent efforts to improve how models respond to users with mental health issues. The company claims its latest work on ChatGPT involved consulting with more than 170 mental health experts. OpenAI says these clinicians observed that the latest version of ChatGPT “responds more appropriately and consistently than earlier versions.”&lt;/p&gt;
    &lt;p&gt;In recent months, several stories have shed light on how AI chatbots can adversely affect users struggling with mental health challenges. Researchers have previously found that AI chatbots can lead some users down delusional rabbit holes, largely by reinforcing dangerous beliefs through sycophantic behavior.&lt;/p&gt;
    &lt;p&gt;Addressing mental health concerns in ChatGPT is quickly becoming an existential issue for OpenAI. The company is currently being sued by the parents of a 16-year-old boy who confided his suicidal thoughts to ChatGPT in the weeks leading up to his suicide. State attorneys general from California and Delaware — which could block the company’s planned restructuring — have also warned OpenAI that it needs to protect young people who use their products.&lt;/p&gt;
    &lt;p&gt;Earlier this month, OpenAI CEO Sam Altman claimed in a post on X that the company has “been able to mitigate the serious mental health issues” in ChatGPT, though he did not provide specifics. The data shared on Monday appears to be evidence for that claim, though it raises broader issues about how widespread the problem is. Nevertheless, Altman said OpenAI would be relaxing some restrictions, even allowing adult users to start having erotic conversations with the AI chatbot.&lt;/p&gt;
    &lt;head rend="h3"&gt;2-FOR-1 DISCOUNT: Bring a +1 and save 60%&lt;/head&gt;
    &lt;head rend="h4"&gt;Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. And don’t miss 300+ showcasing startups in all sectors.&lt;lb/&gt;Bring a +1 and save 60% on their pass, or get your pass by Oct 27 to save up to $444.&lt;/head&gt;
    &lt;head rend="h3"&gt;2-FOR-1 DISCOUNT: Bring a +1 and save 60%&lt;/head&gt;
    &lt;head rend="h4"&gt;Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. And don’t miss 300+ showcasing startups in all sectors. Bring a +1 and save 60% on their pass, or get your pass by Oct 27 to save up to $444.&lt;/head&gt;
    &lt;p&gt;In the Monday announcement, OpenAI claims the recently updated version of GPT-5 responds with “desirable responses” to mental health issues roughly 65% more than the previous version. On an evaluation testing AI responses around suicidal conversations, OpenAI says its new GPT-5 model is 91% compliant with the company’s desired behaviors, compared to 77% for the previous GPT‑5 model.&lt;/p&gt;
    &lt;p&gt;The company also says its latest version of GPT-5 also holds up to OpenAI’s safeguards better in long conversations. OpenAI has previously flagged that its safeguards were less effective in long conversations.&lt;/p&gt;
    &lt;p&gt;On top of these efforts, OpenAI says it’s adding new evaluations to measure some of the most serious mental health challenges facing ChatGPT users. The company says its baseline safety testing for AI models will now include benchmarks for emotional reliance and non-suicidal mental health emergencies.&lt;/p&gt;
    &lt;p&gt;OpenAI has also recently rolled out more controls for parents of children who use ChatGPT. The company says it’s building an age prediction system to automatically detect children using ChatGPT, and impose a stricter set of safeguards.&lt;/p&gt;
    &lt;p&gt;Still, it’s unclear how persistent the mental health challenges around ChatGPT will be. While GPT-5 seems to be an improvement over previous AI models in terms of safety, there still seems to be a slice of ChatGPT’s responses that OpenAI deems “undesirable.” OpenAI also still makes its older and less-safe AI models, including GPT-4o, available for millions of its paying subscribers.&lt;/p&gt;
    &lt;p&gt;If you or someone you know needs help, call 1-800-273-8255 for the National Suicide Prevention Lifeline. You can also text HOME to 741-741 for free; text 988; or get 24-hour support from the Crisis Text Line. Outside of the U.S., please visit the International Association for Suicide Prevention for a database of resources.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2025/10/27/openai-says-over-a-million-people-talk-to-chatgpt-about-suicide-weekly/"/><published>2025-10-27T22:26:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45727097</id><title>Linux VM without VM software – User Mode Linux</title><updated>2025-10-28T13:45:26.173559+00:00</updated><content>&lt;doc fingerprint="751b991d55a32fe1"&gt;
  &lt;main&gt;
    &lt;p&gt;If you carefully read the Linux kernel docs, you will find an interesting statement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Linux has also been ported to itself. You can now run the kernel as a userspace application - this is called UserMode Linux (UML).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Today, we’ll explore how you can start an unconventional VM by running a Linux kernel as a process within the Linux kernel itself. This approach doesn’t require installing virtualization software like QEMU, nor does it need root privileges, which opens up some intriguing possibilities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Table of contents&lt;/head&gt;
    &lt;head&gt;Open Table of contents&lt;/head&gt;
    &lt;head rend="h2"&gt;Kernel’s Hardware Abstraction&lt;/head&gt;
    &lt;p&gt;A fundamental responsibility of the kernel is to abstract hardware and offer a consistent interface to userspace. This includes managing shared resources like the CPU and memory for multiple tasks. The kernel determines the underlying hardware (e.g., through a device tree on some platforms, which lists system components) and connects the appropriate drivers.&lt;/p&gt;
    &lt;p&gt;This hardware can also be entirely virtual. In a QEMU virtual machine, for instance, resources like memory and attached disks are virtualized by the QEMU userspace application, incurring a certain performance overhead. The CPU presents an interesting case, as it too can be virtualized in userspace, particularly when emulating a different architecture.&lt;/p&gt;
    &lt;p&gt;A fascinating aspect of drivers for virtualized hardware is that they can be enlightened — or, more formally, paravirtualized. This means the drivers are aware they’re running on virtualized hardware and can leverage this by communicating with the hardware in specialized ways. While the specifics are complex, one can imagine drivers interacting with virtual hardware in ways not feasible with physical counterparts. Online sources suggest that paravirtualization can achieve performance levels close to those of physical devices using traditional drivers.&lt;/p&gt;
    &lt;head rend="h2"&gt;UML - Kernel in a Userspace Process&lt;/head&gt;
    &lt;p&gt;Personally, I view UML as a paravirtualized kernel configuration. Instead of running directly on bare metal, the UML kernel operates atop an existing kernel instance, leveraging some of its userspace functionalities. For instance, rather than linking the console driver to a physical UART, it can utilize standard userspace input/output. Similarly, a block device driver can target a file on the host’s filesystem instead of a physical disk.&lt;/p&gt;
    &lt;p&gt;In this setup, UML is essentially a userspace process that cleverly employs concepts like files and sockets to launch a new Linux kernel instance capable of running its own processes. The exact mapping of these processes to the host — specifically, how the CPU is virtualized — is something I’m not entirely clear on, and I’d welcome insights in the comments. One could envision an implementation where guest threads and processes map to host counterparts but with restricted system visibility, akin to containers, yet still operating within a nested Linux kernel.&lt;/p&gt;
    &lt;p&gt;This page from the kernel’s documentation has a pretty good illustration of what this looks like:&lt;/p&gt;
    &lt;code&gt;            +----------------+
            | Process 2 | ...|
+-----------+----------------+
| Process 1 | User-Mode Linux|
+----------------------------+
|       Linux Kernel         |
+----------------------------+
|         Hardware           |
+----------------------------+&lt;/code&gt;
    &lt;p&gt;I highly recommend checking out that page for more detailed documentation, particularly for the compelling reasons listed for its usefulness. The final point is especially appealing:&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;It’s extremely fun.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;And that’s precisely why we’re diving into it today!&lt;/p&gt;
    &lt;head rend="h2"&gt;Building a UML Kernel&lt;/head&gt;
    &lt;p&gt;First things first: it’s crucial to understand that a UML kernel can run only on x86 platforms. You can layer an x86 UML kernel on top of an existing x86 kernel; as far as I know, no other configurations are supported.&lt;/p&gt;
    &lt;p&gt;Next, we’ll build the UML binary. The configuration process starts with:&lt;/p&gt;
    &lt;code&gt;ARCH=um make menuconfig&lt;/code&gt;
    &lt;p&gt;You can configure the kernel much like you normally would. You’ll immediately notice several UML-specific options on the initial configuration page. I tend to think of these as “enlightened” drivers, designed to use the host’s userspace facilities as virtual hardware.&lt;/p&gt;
    &lt;p&gt;For this demonstration, I specifically enabled the &lt;code&gt;BLK_DEV_UBD&lt;/code&gt; option. The documentation explains:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The User-Mode Linux port includes a driver called UBD which will let you access arbitrary files on the host computer as block devices. Unless you know that you do not need such virtual block devices, say Y here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This option wasn’t enabled by default (which surprised me a bit), so I recommend setting it to &lt;code&gt;Y&lt;/code&gt;. Once you’ve finalized your configuration, building is straightforward:&lt;/p&gt;
    &lt;code&gt;ARCH=um make -j16&lt;/code&gt;
    &lt;p&gt;And this produces a &lt;code&gt;linux&lt;/code&gt; binary right there!&lt;/p&gt;
    &lt;code&gt;$ file linux
linux: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=742d088d46f7c762b29257e4c44042f321dc4ad5, with debug_info, not stripped&lt;/code&gt;
    &lt;p&gt;Interestingly, it’s dynamically linked to the C standard library:&lt;/p&gt;
    &lt;code&gt;$ ldd linux
        linux-vdso.so.1 (0x00007ffc0a3ce000)
        libc.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3490409000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f3490601000)&lt;/code&gt;
    &lt;head rend="h2"&gt;Building Userspace&lt;/head&gt;
    &lt;p&gt;To do anything meaningful within our nested kernel, we need a userspace. For simplicity, I chose to download the latest Buildroot and build it for x86/64.&lt;/p&gt;
    &lt;p&gt;If you’re feeling adventurous and want to try building a minimal userspace from scratch but aren’t sure where to begin, pairing this with the micro Linux distro exercise could be a lot of fun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Running the Nested Kernel&lt;/head&gt;
    &lt;p&gt;To make things interesting, I decided to provide a block device to the nested kernel, write some data to it, and then verify that data from the host system.&lt;/p&gt;
    &lt;p&gt;First, let’s create the disk image:&lt;/p&gt;
    &lt;code&gt;$ dd if=/dev/urandom of=./disk.ext4 bs=1M count=100&lt;/code&gt;
    &lt;p&gt;Next, we’ll format it with ext4:&lt;/p&gt;
    &lt;code&gt;$ sudo mkfs.ext4 ./disk.ext4&lt;/code&gt;
    &lt;p&gt;Now, it’s time to fire up the kernel in userspace. I’ll use the Buildroot image (an &lt;code&gt;ext2&lt;/code&gt; file provided by Buildroot) as the root filesystem:&lt;/p&gt;
    &lt;code&gt;./linux ubd0=/tmp/uml/rootfs.ext2 ubd1=/tmp/uml/disk.ext4 root=/dev/ubda&lt;/code&gt;
    &lt;p&gt;And just like that, we’re greeted by a very familiar kernel boot sequence!&lt;/p&gt;
    &lt;code&gt;Core dump limits :
        soft - 0
        hard - NONE
Checking that ptrace can change system call numbers...OK
Checking syscall emulation for ptrace...OK
Checking environment variables for a tempdir...none found
Checking if /dev/shm is on tmpfs...OK
Checking PROT_EXEC mmap in /dev/shm...OK
Linux version 6.14.7 (uros@debian-home) (gcc (Debian 12.2.0-14) 12.2.0, GNU ld (GNU Binutils for Debian) 2.40) #6 Mon May 19 16:27:13 PDT 2025
Zone ranges:
  Normal   [mem 0x0000000000000000-0x0000000063ffffff]
Movable zone start for each node
Early memory node ranges
  node   0: [mem 0x0000000000000000-0x0000000003ffffff]
Initmem setup node 0 [mem 0x0000000000000000-0x0000000003ffffff]
random: crng init done
Kernel command line: ubd0=/tmp/uml/rootfs.ext2 ubd1=/tmp/uml/disk.ext4 root=/dev/ubda console=tty0
printk: log buffer data + meta data: 16384 + 57344 = 73728 bytes
Dentry cache hash table entries: 8192 (order: 4, 65536 bytes, linear)
Inode-cache hash table entries: 4096 (order: 3, 32768 bytes, linear)
Sorting __ex_table...
Built 1 zonelists, mobility grouping on.  Total pages: 16384
mem auto-init: stack:all(zero), heap alloc:off, heap free:off
SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1
NR_IRQS: 64
clocksource: timer: mask: 0xffffffffffffffff max_cycles: 0x1cd42e205, max_idle_ns: 881590404426 ns
Calibrating delay loop... 8931.73 BogoMIPS (lpj=44658688)
Checking that host ptys support output SIGIO...Yes
pid_max: default: 32768 minimum: 301
Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
Memory: 57488K/65536K available (3562K kernel code, 944K rwdata, 1244K rodata, 165K init, 246K bss, 7348K reserved, 0K cma-reserved)
...&lt;/code&gt;
    &lt;p&gt;and at the end, we have the Buildroot login:&lt;/p&gt;
    &lt;code&gt;Run /sbin/init as init process
EXT4-fs (ubda): warning: mounting unchecked fs, running e2fsck is recommended
EXT4-fs (ubda): re-mounted 23cafb4d-e18f-4af4-829d-f0dc7303e6c4 r/w. Quota mode: none.
EXT4-fs error (device ubda): ext4_mb_generate_buddy:1217: group 1, block bitmap and bg descriptor inconsistent: 7466 vs 7467 free clusters
Seeding 256 bits and crediting
Saving 256 bits of creditable seed for next boot
Starting syslogd: OK
Starting klogd: OK
Running sysctl: OK
Starting network: OK
Starting crond: OK

Welcome to Buildroot
buildroot login:&lt;/code&gt;
    &lt;p&gt;The boot process was surprisingly quick.&lt;/p&gt;
    &lt;p&gt;Now, let’s create a mountpoint for our disk within the UML instance:&lt;/p&gt;
    &lt;code&gt;# mkdir /mnt/disk&lt;/code&gt;
    &lt;p&gt;Then, we mount the second UBD device (&lt;code&gt;ubdb&lt;/code&gt;) to this mountpoint:&lt;/p&gt;
    &lt;code&gt;# mount /dev/ubdb /mnt/disk/&lt;/code&gt;
    &lt;p&gt;With the disk mounted, we can write a test file:&lt;/p&gt;
    &lt;code&gt;# echo "This is a UML test!" &amp;gt; /mnt/disk/foo.txt
# cat /mnt/disk/foo.txt
This is a UML test!&lt;/code&gt;
    &lt;p&gt;I can now shut down the UML VM:&lt;/p&gt;
    &lt;code&gt;# poweroff&lt;/code&gt;
    &lt;p&gt;which gives&lt;/p&gt;
    &lt;code&gt;# Stopping crond: stopped /usr/sbin/crond (pid 64)
OK
Stopping network: OK
Stopping klogd: OK
Stopping syslogd: stopped /sbin/syslogd (pid 40)
OK
Seeding 256 bits and crediting
Saving 256 bits of creditable seed for next boot
EXT4-fs (ubdb): unmounting filesystem e950822b-09f7-49c2-bb25-9755a249cfa1.
umount: devtmpfs busy - remounted read-only
EXT4-fs (ubda): re-mounted 23cafb4d-e18f-4af4-829d-f0dc7303e6c4 ro. Quota mode: none.
The system is going down NOW!
Sent SIGTERM to all processes
Sent SIGKILL to all processes
Requesting system poweroff
reboot: Power down&lt;/code&gt;
    &lt;p&gt;On my host system:&lt;/p&gt;
    &lt;code&gt;$ sudo mount ./disk.ext4 ./img&lt;/code&gt;
    &lt;code&gt;$ cat ./img/foo.txt
This is a UML test!&lt;/code&gt;
    &lt;p&gt;This little experiment confirms that we successfully ran a VM using UML, wrote data to a block device within it, and those changes persisted, accessible from the host system.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Throughout this article, I’ve referred to UML as a VM, and you’d be right to raise an eyebrow. On one hand, it embodies the idea of hardware virtualization via host userspace facilities, and the environment gets its own distinct kernel. On the other hand, this guest kernel is intrinsically linked to the host’s kernel. While it aims for isolation, it doesn’t achieve the same level you’d expect from a QEMU VM powered by KVM.&lt;/p&gt;
    &lt;p&gt;What’s the real-world utility here? Is UML suitable for running isolated workloads? My educated guess is: probably not for most production scenarios. I believe UML’s primary strength lies in kernel debugging, rather than serving as a full-fledged, production-ready virtualization stack. For robust VM needs, KVM virtualization (operating at a different architectural layer) is far more battle-tested. Of course, containers offer another alternative if sharing the host kernel is acceptable for your workloads. UML carves out an interesting niche between these two: offering a separate kernel instance while still maintaining a unique connection to the host kernel. It’s a fascinating concept.&lt;/p&gt;
    &lt;p&gt;Perhaps in the future, this intriguing technology will garner more attention and see wider adoption. For now, though, it’s a fantastic tool for experimentation and, at the very least, a lot of fun to play with!&lt;/p&gt;
    &lt;p&gt;Happy hacking!&lt;/p&gt;
    &lt;p&gt;For updates, please consider following me on Twitter/X and LinkedIn.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://popovicu.com/posts/linux-vm-without-vm-software-user-mode/"/><published>2025-10-27T22:30:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45727557</id><title>Iroh-blobs</title><updated>2025-10-28T13:45:25.748806+00:00</updated><content>&lt;doc fingerprint="1e5ea82579a148e8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;iroh-blobs 0.95 - New features&lt;/head&gt;by rklaehn&lt;p&gt;Iroh-blobs 0.95 contains a number of significant new features that are worth explaining in detail. There are several new features that are useful for blobs users and also for iroh users in general.&lt;/p&gt;&lt;p&gt;Let's start with a feature that is essential for blobs itself, but can also be useful for many other protocols.&lt;/p&gt;&lt;head rend="h1"&gt;Connection pool&lt;/head&gt;&lt;p&gt;There is a new connection pool in &lt;code&gt;util::connection_pool&lt;/code&gt;. This is useful whenever you have a protocol that has to talk to a large number of endpoints while keeping an upper bound of concurrent open connections. In blobs, this is used whenever you use the downloader to orchestrate blobs downloads from multiple providers.&lt;/p&gt;&lt;p&gt;Iroh connections are relatively lightweight, but even so you don't want to keep thousands of them open at the same time. But opening a new connection every time you do a small exchange with a peer is very wasteful. The &lt;code&gt;ConnectionPool&lt;/code&gt; gives you an API to deal with these tradeoffs.&lt;/p&gt;&lt;head rend="h2"&gt;Basic usage&lt;/head&gt;&lt;p&gt;Let's first look at basic usage:&lt;/p&gt;&lt;code&gt;let pool = ConnectionPool::new(ep, iroh_blobs::ALPN, Options::default());
let conn = pool.get_or_connect(remote_id)?;
/// use the connection as usual.
&lt;/code&gt;&lt;p&gt;&lt;code&gt;get_or_connect&lt;/code&gt; will try to get an existing connection from the pool. If there is none, it will create one and store it. The connection will be kept in the pool for a configurable time. Idle connections will be closed as needed. So you can just use this as a drop-in replacement for endpoint.connect and be sure that you won't ever create an unbounded number of connections.&lt;/p&gt;&lt;head rend="h2"&gt;Advanced features&lt;/head&gt;&lt;p&gt;There are some advanced features that can be configued using non-default options.&lt;/p&gt;&lt;code&gt;pub struct Options {
    pub idle_timeout: Duration,
    pub connect_timeout: Duration,
    pub max_connections: usize,
    pub on_connected: Option&amp;lt;OnConnected&amp;gt;,
}
&lt;/code&gt;&lt;p&gt;You can configure the max number of connections to be retained, the maximum tolerable duration for connection establishment, and the max duration connections are kept when idle.&lt;/p&gt;&lt;p&gt;So far, pretty straightforward. There is an additional option to perform some setup before the connection is handed out to the user. For example, you can reject connections based on the data available at this time from the endpoint and the connection, or wait for the connection to reach a certain state before handing it out.&lt;/p&gt;&lt;p&gt;As an example, you might want to do iroh-blobs transfers only on direct connections in order to get good performance or reduce bandwidth use on the relay. If establishing direct connections is not possible, the connection establishment would time out, and you would never even attempt a transfer from such a node.&lt;/p&gt;&lt;code&gt;async fn on_connected(ep: Endpoint, conn: Connection) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    let Ok(id) = conn.remote_node_id() else {
        return Err(io::Error::other("unable to get node id"));
    };
    let Some(watcher) = ep.conn_type(id) else {
        return Err(io::Error::other("unable to get conn_type watcher"));
    };
    let mut stream = watcher.stream();
    while let Some(status) = stream.next().await {
        if let ConnectionType::Direct { .. } = status {
            return Ok(());
        }
    }
    Err(io::Error::other("connection closed before becoming direct"))
};
let options = Options::default().with_on_connected(on_connected);
let pool = ConnectionPool::new(ep, iroh_blobs::ALPN, options);

let conn = pool.get_or_connect(remote_id)?;
/// use the connection as usual.
&lt;/code&gt;&lt;p&gt;The code to await a direct connection will change quite a bit once we have QUIC multipath. But the capability will remain, and we will update the test code to reflect the new API.&lt;/p&gt;&lt;p&gt;The connection pool is generic enough that it will move to its own crate together with some other iroh utilities. It lives in blobs only until iroh 1.0 is released.&lt;/p&gt;&lt;p&gt;Until then, just depend on iroh-blobs. Iroh-blobs without persistent storage is a very lightweight dependency.&lt;/p&gt;&lt;p&gt;One thing to keep in mind when using the connection pool: the connection pool needs the ability to track which connections are currently being used. To do this, the connection pool does not return &lt;code&gt;Connection&lt;/code&gt; but &lt;code&gt;ConnectionRef&lt;/code&gt;, a struct that derefs to &lt;code&gt;Connection&lt;/code&gt; but contains some additional lifetime tracking.&lt;/p&gt;&lt;p&gt;But &lt;code&gt;Connection&lt;/code&gt; is &lt;code&gt;Clone&lt;/code&gt;, so in principle there is nothing stopping you from cloning the wrapped connection and losing the lifetime tracking. Don't do this. If you work with connections from the pool, you should pass around either a &lt;code&gt;ConnectionRef&lt;/code&gt; or a &lt;code&gt;&amp;amp;Connection&lt;/code&gt; to make sure the underlying &lt;code&gt;ConnectionRef&lt;/code&gt; stays alive.&lt;/p&gt;&lt;p&gt;Incorrect usage of &lt;code&gt;ConnectionRef&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;fn handle_connection(connection: Connection) { tokio::spawn(...) }

let conn = pool.get_or_connect(remote_id)?;
handle_connection(conn.clone()); // clones the Connection out of the ConnectionRef.
/// The ConnectionRef will be dropped here, and the pool will consider the connection idle!
&lt;/code&gt;&lt;p&gt;Correct usage of &lt;code&gt;ConnectionRef&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;fn handle_connection(connection: ConnectionRef) { tokio::spawn(...) }

let conn = pool.get_or_connect(remote_id)?;
handle_connection(conn.clone());
/// The ConnectionRef will be moved into the task, and its lifetime will be properly tracked!
&lt;/code&gt;&lt;p&gt;We experimented with a safer callback-based API, but it turned out to be just too inconvenient to use.&lt;/p&gt;&lt;head rend="h1"&gt;Abstract request and response streams&lt;/head&gt;&lt;p&gt;Iroh-blobs is a protocol that tries to avoid overabstraction. For example as of now you can only use the BLAKE3 hash function, and we hardcode the chunk group size to a value that should work well for all users.&lt;/p&gt;&lt;p&gt;But sometimes there are cases where a bit of abstraction is needed. There was a user request to be able to use compression with iroh-blobs in sendme. One way to do this is to compress files before adding them to the blob store. But this has various downsides. It requires you to create a copy of all data before adding it to the blob store, and will also not lead to very good compression rates when dealing with a large number of small files, since each file will have to be compressed in isolation.&lt;/p&gt;&lt;p&gt;It would be better to compress requests and response streams of the entire protocol and expose the resulting protocol under a different ALPN. With this approach the compression algorithm would be able to find redundancies between multiple files when handling a request for multiple blobs.&lt;/p&gt;&lt;p&gt;This was previously impossible since iroh-blobs worked directly with &lt;code&gt;iroh::endpoint::SendStream&lt;/code&gt; and &lt;code&gt;iroh::endpoint::RecvStream&lt;/code&gt;. So we added traits to allow wrapping send and receive stream in a transform such as compression/decompression.&lt;/p&gt;&lt;p&gt;By default, iroh-blobs still works directly with &lt;code&gt;iroh::endpoint::SendStream&lt;/code&gt; and &lt;code&gt;iroh::endpoint::RecvStream&lt;/code&gt;, so for normal use nothing changes.&lt;/p&gt;&lt;p&gt;The traits are a bit similar to Stream and Sink, but with two important additions.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;We allow sending and receiving Bytes, since iroh streams work with bytes internally. That way we avoid a copy in the default case.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;We have methods stop and reset to close the stream, and on the send stream a method stopped that returns a future that resolves when the remote side has closed the stream.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Wrapping the entire iroh-blobs protocol into compression is pretty straightforward except for some boilerplate. We have an example compression.rs that shows how to do this.&lt;/p&gt;&lt;p&gt;We will have this as an optional feature of sendme in one of the next releases.&lt;/p&gt;&lt;p&gt;Just like the connection pool, these traits are generally useful whenever you want to derive iroh protocols by wrapping existing protocols, so they will move to a separate crate once iroh 1.0 is released.&lt;/p&gt;&lt;head rend="h1"&gt;Enhanced provider events&lt;/head&gt;&lt;p&gt;This change is from iroh-blobs 0.93&lt;/p&gt;&lt;p&gt;On the provider side, it is now possible to have very detailed events about what the provider is doing. The provider events are now implemented as an irpc protocol. For each request type you can use an event mask to configure if you want to be notified at all, and if you need the ability to intercept the request, e.g. if you only want to serve certain hashes.&lt;/p&gt;&lt;p&gt;There is an example how to use the new provider events to limit by provider node id or hash.&lt;/p&gt;&lt;p&gt;Here is a provider event handler that serves only blobs requests for hashes in a fixed set of allowed hashes:&lt;/p&gt;&lt;code&gt;fn limit_by_hash(allowed_hashes: HashSet&amp;lt;Hash&amp;gt;) -&amp;gt; EventSender {
    let mask = EventMask {
        // We want to get a request for each get request that we can answer
        // with OK or not OK depending on the hash. We do not want detailed
        // events once it has been decided to handle a request.
        get: RequestMode::Intercept,
        ..EventMask::DEFAULT
    };
    let (tx, mut rx) = EventSender::channel(32, mask);
    n0_future::task::spawn(async move {
        while let Some(msg) = rx.recv().await {
            if let ProviderMessage::GetRequestReceived(msg) = msg {
                let res = if !msg.request.ranges.is_blob() {
                    Err(AbortReason::Permission)
                } else if !allowed_hashes.contains(&amp;amp;msg.request.hash) {
                    Err(AbortReason::Permission)
                } else {
                    Ok(())
                };
                msg.tx.send(res).await.ok();
            }
        }
    });
    tx
}
&lt;/code&gt;&lt;head rend="h1"&gt;What's next&lt;/head&gt;&lt;p&gt;The next major feature in iroh-blobs will be a minimal version of multiprovider downloads for individual blobs.&lt;/p&gt;&lt;p&gt;As soon as iroh 1.0 is released, several generic parts of iroh-blobs will move to a separate iroh utilities crate.&lt;/p&gt;&lt;p&gt;To get started, take a look at our docs, dive directly into the code, or chat with us in our discord channel.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.iroh.computer/blog/iroh-blobs-0-95-new-features"/><published>2025-10-27T23:28:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45728975</id><title>Complete Digitization of Leonardo da Vinci's Codex Atlanticus</title><updated>2025-10-28T13:45:25.464225+00:00</updated><content>&lt;doc fingerprint="3a053512a6ea9c9c"&gt;
  &lt;main&gt;
    &lt;p&gt;No historical figure better fits the definition of “Renaissance man” than Leonardo da Vinci, but that term has become so overused as to become misleading. We use it to express mild surprise that one person could use both their left and right hemispheres equally well. But in Leonardo’s day, people did not think of themselves as having two brains, and the worlds of art and science were not so far apart as they are now.&lt;/p&gt;
    &lt;p&gt;That Leonardo was able to combine fine arts and fine engineering may not have been overly surprising to his contemporaries, though he was an extraordinarily brilliant example of the phenomenon. The more we learn about him, the more we see how closely related the two pursuits were in his mind.&lt;/p&gt;
    &lt;p&gt;He approached everything he did as a technician. The uncanny effects he achieved in painting were the result, as in so much Renaissance art, of mathematical precision, careful study, and firsthand observation.&lt;/p&gt;
    &lt;p&gt;His artistic projects were also experiments. Some of them failed, as most experiments do, and some he abandoned, as he did so many scientific projects. No matter what, he never undertook anything, whether mechanical, anatomical, or artistic, without careful planning and design, as his copious notebooks testify. As more and more of those notebooks have become available online, both Renaissance scholars and laypeople alike have learned considerably more about how Leonardo’s mind worked.&lt;/p&gt;
    &lt;p&gt;First, there was the Codex Arundel. It is, writes Jonathan Jones at The Guardian, “the living record of a universal mind”—but also, specifically, the mind of a “technophile.” Then, the Victoria and Albert National Art Library announced the digitization of Codex Forster, which contains some of Leonardo’s earliest notebooks. Now The Visual Agency has released a complete digitization of Leonardo’s Codex Atlanticus, a huge collection of the artist, engineer, and inventor’s finely-illustrated notes.&lt;/p&gt;
    &lt;p&gt;“No other collection counts more original papers written by Leonardo,” notes Google. The Codex Atlanticus “consists of 1119 papers, most of them drawn or written on both sides.” Its name has “nothing to do with the Atlantic Ocean, or with some esoteric, mysterious content hidden in its pages.” The 12-volume collection acquired its title because the drawings and writings were bound with the same size paper that was used for making atlases. Gathered in the 16th century by sculptor Pompeo Leoni, the papers descended from Leonardo’s close student Giovan Francesco Melzi, who was entrusted with them after his teacher’s death.&lt;/p&gt;
    &lt;p&gt;The history of the Codex itself makes for a fascinating narrative, much of which you can learn at Google’s Ten Key Facts slideshow. The notebooks span Leonardo’s career, from 1478, when he was “still working in his native Tuscany, to 1519, when he died in France.” The collection was taken from Milan by Napoleon and brought to France, where it remained in the Louvre until 1815, when the Congress of Vienna ruled that all artworks stolen by the former Emperor be returned. (The emissary tasked with returning the Codex could not decipher Leonardo’s mirror writing and took it for Chinese.)&lt;/p&gt;
    &lt;p&gt;The Codex contains not only engineering diagrams, anatomy studies, and artistic sketches, but also fables written by Leonardo, inspired by Florentine literature. And it features Leonardo’s famed “CV,” a letter he wrote to the Duke of Milan describing in nine points his qualifications for the post of military engineer. In point four, he writes, “I still have very convenient bombing methods that are easy to transport; they launch stones and similar such in a tempest full of smoke to frighten the enemy, causing great damage and confusion.”&lt;/p&gt;
    &lt;p&gt;As if in illustration, elsewhere in the Codex, the drawing above appears, “one of the most celebrated” of the collection.” It was “shown to traveling foreigners visiting the Ambrosiana [the Biblioteca Ambrosiana in Milan, where the Codex resides] since the 18th century, usually arousing much amazement.” It is still amazing, especially if we consider the possibility that its artistry might have been something of a byproduct for its creator, whose primary motivation seems to have been solving technical problems—in the most elegant ways imaginable.&lt;/p&gt;
    &lt;p&gt;See the complete digitization of Leonardo’s Codex Atlanticus here.&lt;/p&gt;
    &lt;p&gt;Note: An earlier version of this post appeared on our site in 2019.&lt;/p&gt;
    &lt;p&gt;Related Content:&lt;/p&gt;
    &lt;p&gt;How Leonardo da Vinci Drew an Accurate Satellite Map of an Italian City (1502)&lt;/p&gt;
    &lt;p&gt;Leonardo da Vinci’s Handwritten Resume (Circa 1482)&lt;/p&gt;
    &lt;p&gt;Leonardo Da Vinci’s To-Do List from 1490: The Plan of a Renaissance Man&lt;/p&gt;
    &lt;p&gt;Josh Jones is a writer and musician based in Durham, NC.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.openculture.com/2025/10/digitization-of-leonardo-da-vincis-codex-atlanticus.html"/><published>2025-10-28T03:32:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45729467</id><title>Picture gallery: Amiga prototype "Lorraine" at the Amiga 40 event</title><updated>2025-10-28T13:45:24.513174+00:00</updated><content>&lt;doc fingerprint="76b8ee2d4cb73196"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;DEUTSCHE VERSION&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Links&lt;/cell&gt;
        &lt;cell&gt;|&lt;/cell&gt;
        &lt;cell&gt;Forums&lt;/cell&gt;
        &lt;cell&gt;|&lt;/cell&gt;
        &lt;cell&gt;Comments&lt;/cell&gt;
        &lt;cell&gt;|&lt;/cell&gt;
        &lt;cell&gt;Report news&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Chat&lt;/cell&gt;
        &lt;cell&gt;|&lt;/cell&gt;
        &lt;cell&gt;Polls&lt;/cell&gt;
        &lt;cell&gt;|&lt;/cell&gt;
        &lt;cell&gt;Newsticker&lt;/cell&gt;
        &lt;cell&gt;|&lt;/cell&gt;
        &lt;cell&gt;Archive&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[Login] [Register] [Forgot your password?]&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="20"/&gt;
      &lt;row span="20"&gt;
        &lt;cell&gt;23.Oct.2025&lt;p&gt;a1k.org (Webseite)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Picture gallery: Amiga prototype "Lorraine" at the Amiga 40&lt;p&gt;Dale Luck from the original Amiga development team has preserved the very first Amiga prototype, which used three huge stacks of well-equipped breadboards instead of custom chips. The computer was on display in Germany for the first time last weekend at the Amiga 40 event. Amiga user ‘Pittrock’ took pictures of the exhibit and kindly gave us permission to publish them here:&lt;/p&gt;&lt;p&gt;(cg)&lt;/p&gt;&lt;p&gt;[News message: 23. Oct. 2025, 22:53] [Comments: 0]&lt;/p&gt;&lt;p&gt;[Send via e-mail] [Print version] [ASCII version]&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt; Masthead | Privacy policy | Netiquette | Advertising | Contact &lt;p&gt;Copyright © 1998-2025 by amiga-news.de - all rights reserved.&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.amiga-news.de/en/news/AN-2025-10-00110-EN.html"/><published>2025-10-28T05:28:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45730094</id><title>Poker Tournament for LLMs</title><updated>2025-10-28T13:45:24.086673+00:00</updated><content>&lt;doc fingerprint="7b6effef6ef87f8c"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading event data...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pokerbattle.ai/event"/><published>2025-10-28T07:42:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45730411</id><title>Criminal complaint against facial recognition company Clearview AI</title><updated>2025-10-28T13:45:22.972320+00:00</updated><content>&lt;doc fingerprint="fab418b895b1f840"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, noyb has filed a criminal complaint against Clearview AI and its managers. The facial recognition company is known for scraping billions of photos of Europeans and people around the world on the internet – and selling its facial recognition system to law enforcement and state actors. Several EU data protection authorities have already imposed fines and bans on Clearview AI. But the US company simply ignores these actions – given the lack of enforcement.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Original Complaints against Clearview filed in 2021&lt;/item&gt;
      &lt;item&gt;Decision of Austrian DPA deeming Clearview illegal&lt;/item&gt;
      &lt;item&gt;Several Clearview fines:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Background. Clearview AI is a US company that scrapes the internet and adds all of the faces it can find in photos and videos to its database. It claims to have collected more than 60 billion photos. This allows customers of Clearview AI to identify people by uploading a photo and obtaining other pictures of the same person, including links, the name of a subpage of a website and other meta data. The company originally tried to operate largely under the radar but the New York Times revealed its practices in 2020. While Clearview AI primarily promotes its facial recognition software as a tool for law enforcement, it was also used by companies such as Walmart or Bank of America.&lt;/p&gt;
    &lt;p&gt;Max Schrems: “Facial recognition technology is extremely invasive. It allows for mass surveillance and immediate identification of millions of people. Clearview AI amassed a global database of photos and biometric data, which makes it possible to identify people within seconds. Such power is extremely concerning and undermines the idea of a free society, where surveillance is the exception instead of the rule.”&lt;/p&gt;
    &lt;p&gt;Clearly illegal and intrusive. EU data protection authorities have already repeatedly held that Clearview AI, which processed the data of millions of Europeans, clearly violated the GDPR. The French, the Greek, the Italian and the Dutch authority imposed fines of roughly 100 million euros on Clearview for its intrusive practices. The Austrian data protection authority considered that Clearview AI has acted illegally. Several bans were issued. These decisions were not challenged by the US company.&lt;/p&gt;
    &lt;p&gt;Ignoring the law. Instead, Clearview AI is simply ignoring the EU authorities. Only in the UK did the company appeal the decision and fine imposed by the British ICO, with a final court decision yet to be issued. EU data protection authorities did not come up with a way to enforce its fines and bans against the US company, allowing Clearview AI to effectively dodge the law.&lt;/p&gt;
    &lt;p&gt;Max Schrems: “Clearview AI seems to simply ignore EU fundamental rights and just spits in the face of EU authorities.”&lt;/p&gt;
    &lt;p&gt;Criminal Complaint. However, EU law is not limited to administrative fines under the GDPR. Article 84 GDPR also allows EU Member States to foresee criminal sanctions for GDPR breaches. Austria has implemented such a criminal provision for certain GDPR violations in § 63 of its national Data Protection Act. In contrast to GDPR violations, criminal violations also allow actions to be taken against managers and to use the full range of criminal procedures, including EU-wide actions. For that reason, noyb now filed a criminal complaint with the public prosecutors in Austria. If successful, Clearview AI and its executives could face jail time and be held personally liable, in particular if traveling to Europe.&lt;/p&gt;
    &lt;p&gt;Max Schrems: “We even run cross-border criminal procedures for stolen bikes, so we hope that the public prosecutor also takes action when the personal data of billions of people was stolen – as has been confirmed by multiple authorities.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://noyb.eu/en/criminal-complaint-against-facial-recognition-company-clearview-ai"/><published>2025-10-28T08:34:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45730607</id><title>Geometry and Physics of Wrinkling (2003) [pdf]</title><updated>2025-10-28T13:45:22.353409+00:00</updated><content/><link href="https://softmath.seas.harvard.edu/wp-content/uploads/2019/10/2003-03.pdf"/><published>2025-10-28T09:02:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45731315</id><title>Understanding the Worst .NET Vulnerability</title><updated>2025-10-28T13:45:22.065667+00:00</updated><content>&lt;doc fingerprint="b71699087fe1929d"&gt;
  &lt;main&gt;
    &lt;p&gt;I admit, that's a very click-baity headline, but Microsoft have given the vulnerability a CVSS score of 9.9, their highest ever. Time to panic, right?&lt;/p&gt;
    &lt;p&gt;In this post I try to provide a bit more context. I explain how request smuggling vulnerabilities work in general, how it works in this case, what attackers could use it for, how the vulnerability was fixed, what you can do to protect yourself.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;WARNING: I am not a security professional, so do not take anything in this post as gospel or advice. I'm just a developer trying to make sense of things. 😄 All of the details in this post are based on information that was provided or referenced in the original announcement.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What is the CVE-2025-55315 vulnerability?&lt;/head&gt;
    &lt;p&gt;On October 14th 2025, on a standard Microsoft "patch Tuesday", Microsoft released new versions of all their supported versions of .NET, and also published a security advisory: Microsoft Security Advisory CVE-2025-55315: .NET Security Feature Bypass Vulnerability. The high level summary from that announcement said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Inconsistent interpretation of http requests ('http request/response smuggling') in ASP.NET Core allows an authorized attacker to bypass a security feature over a network.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The advice was "patch all of your things", but the real headline was that this vulnerability was given a CVSS score of 9.9 our of 10, which you know, sounds pretty bad! Barry Dorrans AKA blowdart, .NET security head honcho, gave an explanation of the reasoning behind the score in a comment on the original issue:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The bug enables HTTP Request Smuggling, which on its own for ASP.NET Core would be nowhere near that high, but that's not how we rate things...&lt;/p&gt;
      &lt;p&gt;Instead, we score based on how the bug might affect applications built on top of ASP.NET.&lt;/p&gt;
      &lt;p&gt;Request Smuggling allows an attacker to hide an extra request inside an another, and what that hidden request can do is very application specific.&lt;/p&gt;
      &lt;p&gt;The smuggled request could cause your application code to&lt;/p&gt;
      &lt;item&gt;Login as a different user (EOP)&lt;/item&gt;
      &lt;item&gt;Make an internal request (SSRF)&lt;/item&gt;
      &lt;item&gt;Bypass CSRF checks&lt;/item&gt;
      &lt;item&gt;Perform an injection attack&lt;/item&gt;
      &lt;p&gt;But we don't know what's possible because it's dependent on how you've written your app.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That does all sound pretty scary! 😱 So you can understand the consternation that the issue has caused, especially given the hesitation to explain exactly what "how you've written your app" means.&lt;/p&gt;
    &lt;p&gt;Out of curiosity, I decided to dig in further to really understand this vulnerability, how it could impact you, and what "how you've written your app" could mean.&lt;/p&gt;
    &lt;head rend="h2"&gt;How does request smuggling work?&lt;/head&gt;
    &lt;p&gt;Before we get to the actual patched vulnerability in ASP.NET Core and how the vulnerability works, I think it's important to have some background about the general class of exploits known as HTTP request smuggling.&lt;/p&gt;
    &lt;p&gt;HTTP request smuggling is a security exploit that has been known about for a long time (according to Wikipedia, it was first documented in 2005). It fundamentally arises when you have two different servers processing an HTTP request (e.g. a server and a proxy server), and where those two servers differ in how they handle "invalid" HTTP requests.&lt;/p&gt;
    &lt;p&gt;In all cases of HTTP request smuggling, the exploit works by creating an invalid HTTP request (or sometimes just an ambiguous request), that looks a bit like two HTTP requests glued together. In summary, the exploit then works a bit like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The proxy server receives the ambiguous HTTP request&lt;/item&gt;
      &lt;item&gt;The proxy server forwards the request (unmodified) to the destination server&lt;/item&gt;
      &lt;item&gt;The server interprets the ambiguous request as two pipelined HTTP requests sent to the server, and processes them separately.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I think it's easiest to understand the problem with an example, so the request below shows an example from the original 2005 paper.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this is not an example of the request smuggling vulnerability in CVE-2025-55315, it's just a representative example of request smuggling in general.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let's imagine the attacker sends an HTTP request that looks like this:&lt;/p&gt;
    &lt;code&gt;POST /some_script.jsp HTTP/1.0
Connection: Keep-Alive
Content-Type: application/x-www-form-urlencoded
Content-Length: 9
Content-Length: 204

this=thatPOST /vuln_page.jsp HTTP/1.0
Content-Type: application/x-www-form-urlencoded
Content-Length: 95

param1=value1&amp;amp;data=&amp;lt;script&amp;gt;alert("stealing%20your%20data:"%2bdocument.cookie)&amp;lt;/script&amp;gt;&amp;amp;foobar
&lt;/code&gt;
    &lt;p&gt;The important feature of this request is that there are two &lt;code&gt;Content-Length&lt;/code&gt; headers, with different values: &lt;code&gt;9&lt;/code&gt; or &lt;code&gt;204&lt;/code&gt;. This is the core of the exploit; the difference between which of the these two headers the HTTP proxy and HTTP server honour is what causes the vulnerability.&lt;/p&gt;
    &lt;p&gt;Let's walk through how the exploit works, step-by-step:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The attacker sends the above HTTP request.&lt;/item&gt;
      &lt;item&gt;The HTTP proxy receives the request, notes the duplicate &lt;code&gt;Content-Length&lt;/code&gt;headers, and accepts the second header, the&lt;code&gt;204&lt;/code&gt;length. That means the whole rest of the request is treated as the message body, and seems fine as far as the proxy is concerned.&lt;/item&gt;
      &lt;item&gt;The HTTP proxy forwards the request on to the destination server.&lt;/item&gt;
      &lt;item&gt;This server also notes the duplicate &lt;code&gt;Content-Length&lt;/code&gt;header, but it takes the first of the headers, with the length of&lt;code&gt;9&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The server reads &lt;code&gt;9&lt;/code&gt;bytes of the body (i.e.&lt;code&gt;this=that&lt;/code&gt;) and treats that as the whole request. As far as the server is concerned, the whole (valid) request has been received, and it sees the rest of the data as a whole new request.&lt;/item&gt;
      &lt;item&gt;That means that the destination server sees an entirely new HTTP request to process, &lt;code&gt;POST /vuln_page.jsp&lt;/code&gt;, and treats it as a new request.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's the core of the issue; the proxy saw one request, while the destination server saw two—the second request has been "smuggled" past the proxy to the server.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The request smuggling technique shown here, where you have multiple&lt;/p&gt;&lt;code&gt;Content-Length&lt;/code&gt;headers isn't the "canonical" example you'll generally see referenced, but I used it here because it's simpler to understand in a lot of ways.&lt;p&gt;The canonical request smuggling attack is where you send both a&lt;/p&gt;&lt;code&gt;Content-Length&lt;/code&gt;header and a&lt;code&gt;Transfer-Encoding: chunked&lt;/code&gt;header (which specifies the length of the body as part of the body itself). As before, the request smuggling exploit relies on differences in how proxy and destination servers interpret these conflicting headers.&lt;/quote&gt;
    &lt;p&gt;So as you've seen, request smuggling enables sending a secret request to a destination server that an intermediate proxy server hasn't seen. In the next section we'll look at why that's a bad thing, and how it can be exploited.&lt;/p&gt;
    &lt;head rend="h2"&gt;How can an attacker exploit request smuggling?&lt;/head&gt;
    &lt;p&gt;On the face of it, request smuggling might not seem like a big deal. So the server sees two requests, so what? You could always send two requests to the server anyway, right? Well, yes and no.&lt;/p&gt;
    &lt;p&gt;The issue with request smuggling is really all about the mismatch between the proxy and destination servers. Thanks to this mismatch, and depending on what behaviours and expectations the target application has, attackers can use request smuggling to&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reflect malicious data to other users on sites that are vulnerable to cross-site scripting.&lt;/item&gt;
      &lt;item&gt;Poison caches with bad data.&lt;/item&gt;
      &lt;item&gt;Exfiltrate authentication credentials or other data from client requests.&lt;/item&gt;
      &lt;item&gt;Invoke endpoints that shouldn't be publicly accessible (because the proxy would block external access to them).&lt;/item&gt;
      &lt;item&gt;Replace/override authentication controls handled by the proxy.&lt;/item&gt;
      &lt;item&gt;Redirect users to malicious sites on sites vulnerable to open-redirect attacks.&lt;/item&gt;
      &lt;item&gt;And more…&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As you can see, these are all Bad™️, so you can kind of understand why the 9.9 rating was given! 😱&lt;/p&gt;
    &lt;p&gt;That said, it's worth mentioning that not all of these attacks will be fruitful against all applications. Some of the easiest to understand versions of these exploits are where the proxy is not just doing "dumb" forwarding of requests, but rather it's validating or enhancing the request in some way.&lt;/p&gt;
    &lt;p&gt;For example, if you have a proxy sat in front of your server which is responsible for handling TLS termination and client-authentication and identification using certificates, then request smuggling could be used to bypass these checks and insert your own identification.&lt;/p&gt;
    &lt;p&gt;As an example of that attack, the HTTP request below demonstrates using a &lt;code&gt;Content-Length&lt;/code&gt; and &lt;code&gt;Transfer-Encoding&lt;/code&gt; request smuggling attack to "hide" the request to &lt;code&gt;/admin&lt;/code&gt; from the front-end proxy, and insert a malicious &lt;code&gt;X-SSL-CLIENT-CN&lt;/code&gt; header, which would normally be added by the front-end proxy:&lt;/p&gt;
    &lt;code&gt;POST /example HTTP/1.1
Host: some-website.com
Content-Type: x-www-form-urlencoded
Content-Length: 64
Transfer-Encoding: chunked

0

GET /admin HTTP/1.1
X-SSL-CLIENT-CN: administrator
Foo: x
&lt;/code&gt;
    &lt;p&gt;In this example, the server assumes that the &lt;code&gt;X-SSL-CLIENT-CN: administrator&lt;/code&gt; header was added by the proxy, and so the server assumes that the proxy already did all the necessary authentication and authorization. The attacker is able to perform a request as an entirely different user.&lt;/p&gt;
    &lt;p&gt;Request smuggling is clearly a big problem whenever you have a front-end proxy that does some functionality, but even when it's essentially a dumb proxy, request smuggling can still be used to steal and exfiltrate data from other user's requests, even if the attacked site is not vulnerable to cross-site scripting or other vulnerabilities.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In these attacks, simply having functionality that displays data provided by a user (even sanitised) can be sufficient to steal the credentials of other users. So something as simple as displaying a user name or a comment could be sufficient.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This post is long enough, and there are so many different attacks, that I'm going to leave it there for looking at exploits. If you'd like to learn more about what's possible, along with simple explanations and examples of exploits, I recommend the PortSwigger documentation on exploiting request smuggling.&lt;/p&gt;
    &lt;head rend="h2"&gt;Does request smuggling only apply if I have a proxy?&lt;/head&gt;
    &lt;p&gt;In general, whenever people talk about request smuggling, they normally talk about the case where you have multiple servers: the canonical example is a proxy server and a destination server, as I've discussed so far. But don't be fooled, these issues and vulnerabilities can apply even if you aren't strictly using a proxy.&lt;/p&gt;
    &lt;p&gt;The key feature of the vulnerability is that there's an opportunity for confusion between two "systems", whether they're full "servers" or not. This obviously applies to proxy servers, but could also apply to your application if you're doing anything where you're reading/manipulating/forwarding request streams, or where there's the possibility for confusion inside the same application.&lt;/p&gt;
    &lt;p&gt;For ASP.NET Core applications, if you're working with &lt;code&gt;HttpRequest.Body&lt;/code&gt; or &lt;code&gt;HttpRequest.BodyReader&lt;/code&gt;, or other similar methods then you may be vulnerable to attacks even if you're not explicitly using a proxy server. Even if you don't think of your application as a proxy or as using a proxy, if you're doing "proxy-like" things, then you could be vulnerable.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Put in other words, if you're reading, manipulating, or forwarding request streams directly in ASP.NET Core, as opposed to just relying on the built-in model binding, then you could be at risk to request smuggling attacks. It's very hard to enumerate all the attack vectors, so you should consider any code that does so as a potential avenue of exploitation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We've now covered how request smuggling works and can be exploited in general, so it's time to look at the specific version of request smuggling that is targeted in the .NET CVE-2025-55315 vulnerability.&lt;/p&gt;
    &lt;head rend="h2"&gt;How does the request smuggling in CVE-2025-55315 work?&lt;/head&gt;
    &lt;p&gt;As we've seen, HTTP request smuggling is a general technique that relies on differences between proxies and servers in how they parse HTTP requests. I've shown two specific versions of this so far: duplicate &lt;code&gt;Content-Length&lt;/code&gt; headers, and &lt;code&gt;Content-Length&lt;/code&gt;/&lt;code&gt;Transfer-Encoding&lt;/code&gt; confusion, but these are not exhaustive. There are variations on these approaches which also lead to request smuggling.&lt;/p&gt;
    &lt;p&gt;The request smuggling vulnerability in CVE-2025-55315 relies on a variation which (as far as I can tell) was first reported in June 2025 by Jeppe Bonde Weikop on their blog. This variation relies on &lt;code&gt;Transfer-Encoding&lt;/code&gt; and the Chunk Extensions feature.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;All the details and images in this section are based on the descriptions and examples in the original post. That post is excellent, so if you want even more detail and explanation than here, you should definitely read it, and then you can skip the abbreviated version I provide here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To understand the vulnerability, we'll first look at how chunked transfer encoding works and what chunk extensions are. We'll then look at how invalid line-endings can lead to differences in interpretation of a request. Finally, we'll look at how this difference in interpretation can open the way for request smuggling, and how ASP.NET Core fixed the problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;code&gt;Transfer-Encoding: chunked&lt;/code&gt; and chunk extensions&lt;/head&gt;
    &lt;p&gt;To understand the vulnerability, we first need to understand how &lt;code&gt;Transfer-Encoding: chunked&lt;/code&gt; works, and how chunk extensions complicate things.&lt;/p&gt;
    &lt;p&gt;When you're sending a request, you might not always know up-front how big the request is that you're sending. Let's take a practical example of serializing a .NET object to JSON into a request body. The only way to know for sure how big the serialized data is going to be is to actually serialize it. So you could serialize the data to memory before writing the request, but if the data is very big, then that could cause issues with allocating big arrays.&lt;/p&gt;
    &lt;p&gt;Instead, &lt;code&gt;Transfer-Encoding: chunked&lt;/code&gt; allows sending the request data in multiple "chunks". You need to know the size of each individual chunk, but not the overall size of the data, or how many chunks there are. This works well for serializing to a small buffer, sending that small buffer as a chunk, and then re-using the buffer to serialize the next part, until you have serialized the whole object.&lt;/p&gt;
    &lt;p&gt;In terms of the HTTP request itself, each chunk consists of a header and a body. The header consists of a hexadecimal-formatted number of bytes, followed by a &lt;code&gt;\r\n&lt;/code&gt; (&lt;code&gt;CRLF&lt;/code&gt;) line ending. The chunk body is then the specified number of bytes, followed by another &lt;code&gt;\r\n&lt;/code&gt;. You can have as many chunks as you need, and the request will keep being passed until you send a &lt;code&gt;0&lt;/code&gt; length chunk, which indicates the end of the request.&lt;/p&gt;
    &lt;p&gt;As an example, the following HTTP &lt;code&gt;POST&lt;/code&gt; shows posting some JSON to an endpoint, but the JSON is sent as three distinct chunks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chunk 1: The header is &lt;code&gt;9&lt;/code&gt;indicating 9 bytes will be sent (followed by&lt;code&gt;\r\n&lt;/code&gt;), and then the 9 bytes of the start of the JSON document in the chunk body, again followed by&lt;code&gt;\r\n&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Chunk 1: The header is &lt;code&gt;e&lt;/code&gt;indicating 14 bytes (14 in hexadecimal is&lt;code&gt;e&lt;/code&gt;) will be sent (followed by&lt;code&gt;\r\n&lt;/code&gt;), and then the remaining 14 bytes of the end of the JSON document, followed by&lt;code&gt;\r\n&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The final chunk is an "empty" chunk, &lt;code&gt;0\r\n\r\n&lt;/code&gt;, indicating the end of the request.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're going to see shortly that line endings are very important, so the following diagram shows the same as the above HTTP request, but with the line endings included:&lt;/p&gt;
    &lt;p&gt;That's "normal" chunked transfer encoding, so now we come to chunk extensions. Chunk extensions are part of the HTTP 1.1 protocol which allows for adding key-value pairs of metadata to individual chunks. The following example shows the same request as before, but with a chunk extension, &lt;code&gt;;foo=bar&lt;/code&gt; in the second chunk:&lt;/p&gt;
    &lt;p&gt;A chunk extension is indicated by a &lt;code&gt;;&lt;/code&gt; after the chunk header length, followed by one or more key-value pairs in the form &lt;code&gt;key=value&lt;/code&gt;. It's important to understand that chunk extensions are not part of the data that's seen by a request handler; chunk extensions are just metadata about the individual chunk. And tl;dr; they're completely useless 😅&lt;/p&gt;
    &lt;p&gt;To the closest approximation, no-one cares about chunk extensions; client implementations don't send them, and servers just ignore them. If that's the case, how can they be the cause of such a problematic bug in .NET?&lt;/p&gt;
    &lt;p&gt;The problem is how the implementation ignores them…&lt;/p&gt;
    &lt;head rend="h3"&gt;Invalid chunk extensions with incorrect line endings&lt;/head&gt;
    &lt;p&gt;In general with HTTP, clients and server implementations often try to follow the robustness principle of "be conservative in what you send, and lenient with what you accept". Unfortunately, it's this very leniency which can sometimes leave us in hot water. After all, it was leniency around requests containing both a &lt;code&gt;Content-Length&lt;/code&gt; and &lt;code&gt;Transfer-Encoding&lt;/code&gt; header that was the root cause of the original request smuggling exploit.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that the HTTP 1.1 RFC now forbids forwarding both these headers, precisely to avoid request smuggling attacks.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For chunk extensions though, leniency is often accidentally built in to the server implementations. Given that no implementations actually do anything with the chunk extensions, the canonical approach to handling them when parsing a chunk header is just to ignore them. When a &lt;code&gt;;&lt;/code&gt; is parsed, it's common to just look for the end of the line, and ignore everything in between.&lt;/p&gt;
    &lt;p&gt;For ASP.NET Core (prior to the fix), on finding a &lt;code&gt;;&lt;/code&gt; in the chunk header, Kestrel would "parse" the extension, but in practice, it would search for the carriage return &lt;code&gt;\r&lt;/code&gt; and then check for the following &lt;code&gt;\n&lt;/code&gt;, skipping everything in between, a little bit like this (very simplified compared to original code):&lt;/p&gt;
    &lt;code&gt;private void ParseExtension(ReadOnlySequence&amp;lt;byte&amp;gt; buffer)
{
    while(true)
    {
        // Chunk-extensions not currently parsed
        // Just drain the data
        var extensionCursor = buffer.PositionOf(ByteCR);
        var suffixBuffer = buffer.Slice(extensionCursor); // skips over extensionCursor bytes

        var suffixSpan = suffixBuffer.Slice(0, 2).ToSpan();

        if (suffixSpan[1] == '\n')
        {
            // We consumed the \r\n at the end of the extension, so switch modes.
            return;
        }

        // Otherwise, keep reading data until we do find \r\n
        buffer = ReadMoreData();
    }
}
&lt;/code&gt;
    &lt;p&gt;The implementation in ASP.NET Core wasn't particularly special; most servers simply skip over the bytes until they find a &lt;code&gt;\r\n&lt;/code&gt;. The big question is exactly how the servers search for &lt;code&gt;\r\n&lt;/code&gt;. What happens if they see a lone &lt;code&gt;\r&lt;/code&gt;, or a lone &lt;code&gt;\n&lt;/code&gt;? Do they treat that the same as a &lt;code&gt;\r\n&lt;/code&gt;? Do they throw an error if they find an un-paired &lt;code&gt;\r&lt;/code&gt; or &lt;code&gt;\n&lt;/code&gt;? Or do they ignore it and keep looking for a &lt;code&gt;\r\n&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;That ambiguity is at the heart of the CVE-2025-55315 request smuggling vulnerability. Differences in how proxy and server implementations treat standalone &lt;code&gt;\r&lt;/code&gt; or &lt;code&gt;\n&lt;/code&gt; in a chunk header allow for request smuggling exploits that use this ambiguity.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note that according to the RFC, implementers must not treat&lt;/p&gt;&lt;code&gt;\r&lt;/code&gt;or&lt;code&gt;\n&lt;/code&gt;as "valid" line terminators for a chunk header, and neither&lt;code&gt;\r&lt;/code&gt;or&lt;code&gt;\n&lt;/code&gt;are allowed elsewhere in chunk headers, so correct implementations must reject requests that include these standalone line endings in chunk headers.&lt;/quote&gt;
    &lt;p&gt;For complete clarity, the following example is the same as the previous implementation but with an invalid chunk header in the chunk extension of the second chunk. Instead of ending with &lt;code&gt;\r\n&lt;/code&gt;, the chunk extension ends with a single &lt;code&gt;\n&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;That's the root cause of the request smuggling vulnerability, so in the next section we'll look at how this could be used to craft a malicious HTTP request.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exploiting invalid chunk extensions for request smuggling&lt;/head&gt;
    &lt;p&gt;Just as with other examples of request smuggling, the chunk extensions approach relies on differences in how a proxy parses a request compared to a subsequent server. This difference means the proxy sees one request, while the destination request sees two requests, and allows for all the same exploits I discussed earlier.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;As discussed, these examples come from this excellent blog post, so see that post for more details, variations on the attack, and further ways to exploit the vulnerability.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The following example shows a malicious HTTP request that exploits a difference in line-ending handling between a proxy and the destination server to smuggle a request to the &lt;code&gt;/admin&lt;/code&gt; endpoint. We can imagine that the proxy is configured to automatically reject requests to &lt;code&gt;/admin&lt;/code&gt; normally, and the server assumes that the proxy handles that for us.&lt;/p&gt;
    &lt;p&gt;In this example the attacker creates a malformed chunk header with a chunk extension by sending &lt;code&gt;2;\n&lt;/code&gt;. The &lt;code&gt;;&lt;/code&gt; ensures that both the proxy and and server treat the header as a chunk extension, but using &lt;code&gt;\n&lt;/code&gt; instead of &lt;code&gt;\r\n&lt;/code&gt; results in differential parsing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The proxy only sees a single request: &lt;list rend="ul"&gt;&lt;item&gt;It treats the &lt;code&gt;\n&lt;/code&gt;as a "valid" line-ending for the chunk header&lt;/item&gt;&lt;item&gt;It then treats the &lt;code&gt;xx&lt;/code&gt;as the chunk body&lt;/item&gt;&lt;item&gt;&lt;code&gt;47&lt;/code&gt;is the next chunk header&lt;/item&gt;&lt;item&gt;The next 71 bytes (&lt;code&gt;47&lt;/code&gt;is hex, which is 71 in decimal) are treated as the chunk body.&lt;/item&gt;&lt;item&gt;Finally there's the empty chunk block&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;It treats the &lt;/item&gt;
      &lt;item&gt;The server sees two requests: &lt;list rend="ul"&gt;&lt;item&gt;The server ignores the lone &lt;code&gt;\n&lt;/code&gt;, and skips all the way to&lt;code&gt;xx\r\n&lt;/code&gt;&lt;/item&gt;&lt;item&gt;It then treats the &lt;code&gt;47&lt;/code&gt;as the chunk body&lt;/item&gt;&lt;item&gt;It sees an ending chunk,&lt;code&gt;0\r\n\r\n&lt;/code&gt;and thinks the request is over&lt;/item&gt;&lt;item&gt;The remaining data is treated as a completely separate request, which contains only an empty chunk in the body.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The server ignores the lone &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is pretty much the simplest example, but you can essentially exploit this difference in all the ways I described previously. Exactly what the implications are for your application are hard to say, but given that all sorts of security bypass, credential stealing, and injection attacks are possible, it's easy to understand why the vulnerability received a CVSS rating of 9.9.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One very interesting thing I found was looking at the security advisories for the same flaw in other HTTP implementations from other languages. In the python aiohttp and ruby puma servers, for example, give the vulnerability only a moderate severity rating in both cases. In netty it's even given a low severity.&lt;/p&gt;
      &lt;p&gt;As far as I can tell, these servers are essentially vulnerable in the same way as ASP.NET Core is, so it's just an interesting data point, and I think reflects how Microsoft really want to make sure this gets the visibility it deserves and that customers patch their apps!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;How was the vulnerability fixed?&lt;/head&gt;
    &lt;p&gt;As with most fixes for request-smuggling, the solution is to stop being lenient and/or ambiguous about how standalone line-endings are handled in chunk headers.&lt;/p&gt;
    &lt;p&gt;In ASP.NET Core, the PR that fixes the issue does so by explicitly checking for any line-endings, instead of just looking for &lt;code&gt;\r&lt;/code&gt;. If it finds a line ending and it's not strictly &lt;code&gt;\r\n&lt;/code&gt;, then Kestrel now throws a &lt;code&gt;KestrelBadHttpRequestException&lt;/code&gt; and returns a &lt;code&gt;400&lt;/code&gt; response.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;I'll mention here there is an&lt;/p&gt;&lt;code&gt;AppContext&lt;/code&gt;switch for opting-in to the dangerous/vulnerable parsing behaviour after you have patched your application, but please don't use it, I can't believe there's really a good (or safe) reason to.😅&lt;/quote&gt;
    &lt;p&gt;The vulnerability has been patched in ASP.NET Core, so what should you do?&lt;/p&gt;
    &lt;head rend="h2"&gt;What should you do?&lt;/head&gt;
    &lt;p&gt;Obviously the good news here is that there is a fix for ASP.NET Core. As described in the original issue, the important thing is to update to the latest supported version of ASP.NET Core as soon as possible.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There's no announced evidence of the request smuggling vulnerability being exploited in the wild, but given the vast number of ways that request smuggling could be used, would we even know? 🤔&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That means you should update your version of .NET 8, .NET 9, or .NET 10:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Vulnerable versions&lt;/cell&gt;
        &lt;cell role="head"&gt;Lowest patched version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;.NET 10&lt;/cell&gt;
        &lt;cell&gt;10.0.0-rc2&lt;/cell&gt;
        &lt;cell&gt;10.0.0-rc2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;.NET 9&lt;/cell&gt;
        &lt;cell&gt;9.0.0 - 9.0.9&lt;/cell&gt;
        &lt;cell&gt;9.0.10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;.NET 8&lt;/cell&gt;
        &lt;cell&gt;8.0.0 - 8.0.20&lt;/cell&gt;
        &lt;cell&gt;8.0.21&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you're using ASP.NET Core 2.3 on .NET Framework, then you'll need to update your version of Microsoft.AspNetCore.Server.Kestrel.Core:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Vulnerable versions&lt;/cell&gt;
        &lt;cell role="head"&gt;Lowest patched version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Microsoft.AspNetCore.Server.Kestrel.Core&lt;/cell&gt;
        &lt;cell&gt;2.0.0-2.3.0&lt;/cell&gt;
        &lt;cell&gt;2.3.6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you are doing self-contained deployments of your applications, you'll need to update to the patched versions and then redeploy your applications.&lt;/p&gt;
    &lt;p&gt;And if you're using older versions of .NET Core? Well, then you can't patch… HeroDevs provide additional support for out-of-support versions of .NET (and have confirmed they'll be patching it in .NET 6), but this vulnerability is present in basically all versions of .NET Core as far as I can tell. I've personally tested down to .NET Core 3.0 and I can confirm that the vulnerability is there and there are no patches coming for you. The best thing to do is to update to a supported version of .NET.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;⚠️ If you are running ASP.NET Core using &amp;lt;=.NET Core 3.0, .NET Core 3.1, .NET 5, .NET 6 (unless supported by HeroDevs), or .NET 7, then you are vulnerable, and there are no patches. You should update to a supported version of .NET as soon as possible. Ironically, if you're stuck on old .NET Framework Web Forms or MVC applications you are apparently not vulnerable.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It's worth noting that if you are stuck on one of these old framework versions and can't upgrade, then probably the best way to protect yourself is to ensure that you have a proxy in front of your application which is confirmed to not be vulnerable (though obviously you are likely vulnerable to other exploits 😅).&lt;/p&gt;
    &lt;p&gt;For example, Azure App Services (AAS) confirmed that applications running in AAS are no longer vulnerable, even if you haven't updated, because the proxy that AAS uses (itself a YARP based ASP.NET Core proxy) has been patched. By blocking the requests at the proxy level, ambiguous requests will never make it to your application, so you are protected.&lt;/p&gt;
    &lt;p&gt;Unfortunately, right now, it's not clear exactly where you stand if you're using a service other than AAS for hosting your applications. Even IIS hasn't been confirmed to be safe or vulnerable at this point, but I did some unofficial testing on my Windows 11 box, and as fat as I can tell, it is vulnerable.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note that various people in the original issue are attempting to test IIS by using the&lt;/p&gt;&lt;code&gt;Content-Length&lt;/code&gt;/&lt;code&gt;Transfer-Encoding&lt;/code&gt;version of request smuggling, which is not applicable here; we're interested in the chunk-extensions based version.&lt;/quote&gt;
    &lt;p&gt;Another interesting point is that this is vulnerability in HTTP/1.0 and HTTP/1.1 only; it is not a vulnerability in HTTP/2 or HTTP/3. HTTP/2 and HTTP/3 do not support chunked transfer encoding, and instead uses a different, more efficient, binary framing layer for data streaming. So another way to protect those applications which you can't upgrade may be to enforce that client's can only use HTTP/2 or HTTP/3. Be aware that's liable to break a lot of clients that are still using HTTP/1.1 though!&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You can configure the HTTP protocols allowed by Kestrel by configuring your Kestrel endpoints. The documentation shows various ways to do this.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;How to know if you're affected?&lt;/head&gt;
    &lt;p&gt;The "simplest" way to know if you're affected is to check the version of .NET you're using to run your applications, using &lt;code&gt;dotnet --info&lt;/code&gt; and verify that you're using one of the patched versions. If you are, you're safe. That's the only "supported" way to know that you're safe, and it's the one way I would recommend. As far as I can tell, there isn't currently a generalised tool to point at an application to find out if it's vulnerable, though it would likely be possible to write one.&lt;/p&gt;
    &lt;p&gt;The folks at HeroDevs re-implemented the functional tests from the original ASP.NET Core fix as a console application compiled against multiple versions of ASP.NET Core. They used this to confirm that unpatched versions of .NET 8-.NET 10 are vulnerable, while patched versions are not. They also used this to verify .NET 6 is vulnerable, and I tweaked it to confirm everything down to at least .NET Core 3.0 is vulnerable.&lt;/p&gt;
    &lt;p&gt;The test in the repro works by sending a chunked transfer encoding request to ASP.NET Core, with an invalid line ending in a chunk extension header. The vulnerability is identified by ASP.NET Core "hanging", waiting for more data, until it eventually times out. The "fixed" version immediately throws the &lt;code&gt;BadRequest&lt;/code&gt; exception included in the fix.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I saw some confusion about this test online; the argument was "if both the fixed and broken versions throw an exception, why does it matter"? However, that's not the point of the test. The fact that Kestrel is paused waiting for more data indicates that a smuggled HTTP request would have been executed. You can see how this can be leveraged to exfiltrate data or attack other users both in the chunk extensions blog or on PortSwigger's site.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I used a similar approach to try to understand whether IIS might be vulnerable by sending the same crafted HTTP request to IIS and seeing if it hung until timing out: it did on my version of IIS (&lt;code&gt;10.0.26100.1882&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;# Send an HTTP request with an invalid chunk extension, and see
# if it times out or if it's rejected with a 400... It times out 🙁
echo -e "GET / HTTP/1.1\r\nHost:\r\nTransfer-Encoding: chunked\r\n\r\n1;\n" \
  | nc localhost 80
&lt;/code&gt;
    &lt;p&gt;So does that definitely mean IIS is vulnerable? No, don't trust me, I'm not a security researcher 😅 But until you hear otherwise, I would play it safe and assume that IIS won't protect you from chunk extension request smuggling attacks. And in general, I would apply the same rules to any other proxies you are relying on in your infrastructure.&lt;/p&gt;
    &lt;p&gt;And as a final reminder, even though request smuggling is typically described and demonstrated using a proxy in front of your server, just not using a proxy does not mean you're automatically safe. If you're reading, manipulating, or forwarding request streams directly in ASP.NET Core, as opposed to just relying on the built-in model binding, then you might be at risk to request smuggling attacks. It's best to play it safe, patch your apps, and wherever possible leave the complexity of manipulating requests to ASP.NET Core.&lt;/p&gt;
    &lt;p&gt;In general, I would make sure to subscribe to the ASP.NET Core issue on GitHub, as it's likely that any more announcements around the issue will also be reported there.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;In this post I discuss the recent ASP.NET Core vulnerability: Microsoft Security Advisory CVE-2025-55315: .NET Security Feature Bypass Vulnerability. This advisory warns of a request smuggling vulnerability that affects basically all versions of ASP.NET Core.&lt;/p&gt;
    &lt;p&gt;I described how request smuggling works in general, using a simple example of request smuggling to show how ambiguity in how HTTP is parsed can lead to HTTP proxies and HTTP servers in handling the same HTTP request in different ways. This can lead to the server seeing two requests where the proxy only sees a single request.&lt;/p&gt;
    &lt;p&gt;After walking through a request smuggling example, I discussed some of the ways attackers could exploit a request smuggling vulnerability. That includes reflecting malicious data to other users of your app, exfiltrating authentication credentials or other data from client requests, invoking endpoints that shouldn't be publicly accessible, and various other attacks.&lt;/p&gt;
    &lt;p&gt;Next I walked through the specific request smuggling vulnerability identified in CVE-2025-55315. This uses ambiguities in the parsing of chunk extensions when sending requests that use chunked transfer encoding. Chunk extensions are generally ignored by all servers, but lenient handling can lead to differential handling between proxy and server, providing an avenue for request smuggling.&lt;/p&gt;
    &lt;p&gt;Finally, I walked through the mitigation steps you should take: patching your applications. I described the information we currently have about vulnerable or patched proxy servers, and how old versions of ASP.NET Core are not going to be getting patches, so will remain vulnerable (shout out again to HeroDevs for supporting .NET 6). If you're running in AAS, then you're ok, but otherwise, you need to check with your proxy provider to establish whether you are vulnerable or not.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andrewlock.net/understanding-the-worst-dotnet-vulnerability-request-smuggling-and-cve-2025-55315/"/><published>2025-10-28T11:03:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45731321</id><title>Your vibe coded slop PR is not welcome</title><updated>2025-10-28T13:45:21.779048+00:00</updated><content>&lt;doc fingerprint="afd9605404074135"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Your vibe coded slop PR is not welcome&lt;/head&gt;
    &lt;p&gt;16 hours ago&lt;/p&gt;
    &lt;p&gt;As both developers and stewards of significant open source projects, we’re watching AI coding tools create a new problem for open source maintainers.&lt;/p&gt;
    &lt;p&gt;AI assistants like GitHub Copilot, Cursor, Codex, and Claude can now generate hundreds of lines of code in minutes. This is genuinely useful; but it has an unintended consequence: reviewing machine generated code is very costly.&lt;/p&gt;
    &lt;p&gt;The core issue: AI tools have made code generation cheap, but they haven’t made code review cheap. Every incomplete PR consumes maintainer attention that could go toward ready-to-merge contributions.&lt;/p&gt;
    &lt;p&gt;At Discourse, we’re already seeing this accelerating across our contributor community. In the next year, every engineer maintaining open source projects will face the same challenge.&lt;/p&gt;
    &lt;p&gt;We need a clearer framework for AI-assisted contributions that acknowledges the reality of limited maintainer time.&lt;/p&gt;
    &lt;p&gt;A binary system works extremely well here. On one side there are prototypes that simply demonstrate an idea. On the other side there are ready for review PRs that meet a project’s contribution guidelines and are ready for human review.&lt;/p&gt;
    &lt;head rend="h3"&gt;The lack of proper labeling and rules is destructive to the software ecosystem&lt;/head&gt;
    &lt;p&gt;The new tooling is making it trivial to create a change set and lob it over the fence. It can introduce a perverse system where project maintainers spend disproportionate effort reviewing lopsided AI generated code that took seconds for contributors to create and now will take many hours to review.&lt;/p&gt;
    &lt;p&gt;This can be frustrating, time consuming and demotivating. On one side there is a contributor who spent a few minutes fiddling with AI prompts, on the other side you have an engineer that needs to spend many hours or even days deciphering alien intelligence.&lt;/p&gt;
    &lt;p&gt;This is not sustainable and is extremely destructive.&lt;/p&gt;
    &lt;head rend="h3"&gt;The prototype&lt;/head&gt;
    &lt;p&gt;AI coding agents such as Claude Code, Codex, Cursor CLI and more have unlocked the ability to ship a “new kind” of change set, the prototype.&lt;/p&gt;
    &lt;p&gt;The prototype is a live demo. It does not meet a project’s coding standards. It is not code you vouch for or guarantee is good. It lacks tests, may contain security issues and most likely would introduce an enormous amount of technical debt if merged as is.&lt;/p&gt;
    &lt;p&gt;That said it is a living demo that can help make an idea feel more real. It is also enormously fun.&lt;/p&gt;
    &lt;p&gt;Think of it as a delightful movie set.&lt;/p&gt;
    &lt;p&gt;Prototypes, especially on projects such as Discourse where enabling tooling exists are incredibly easy to explore using tools like dv.&lt;/p&gt;
    &lt;code&gt;% dv new my-experiment
% dv branch my-amazing-prototype
% dv ls
total 1
* my-amazing-prototype Running 1 minute ago http://localhost:4200

# finally visit http://localhost:4200 to see in action
&lt;/code&gt;
    &lt;p&gt;Prototypes are great vehicles for exploring ideas. In fact you can ship multiple prototypes that demonstrate completely different solutions to a single problem which help decide on the best approach.&lt;/p&gt;
    &lt;p&gt;Prototypes, video demos and simple visual mockups are great companions. The prototype has the advantage that you can play with it and properly explore the behavior of a change. The video is faster to consume. Sometimes you may want them all.&lt;/p&gt;
    &lt;p&gt;If you are vibe coding and prototyping there are some clear rules you should follow&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Don’t send pull requests (not even drafts), instead lean on branches to share your machine generated code.&lt;/item&gt;
      &lt;item&gt;Share a short video AND/OR links to a branch AND/OR quotes of particular interesting code from the prototype in issues / or forum posts.&lt;/item&gt;
      &lt;item&gt;Show all your cards, explain you were exploring an idea using AI tooling, so people know the nature of the change you are sharing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Maybe you will be lucky and an idea you had will get buy-in, maybe someone else may want to invest the time to drive a prototype into a production PR.&lt;/p&gt;
    &lt;head rend="h3"&gt;When should you prototype?&lt;/head&gt;
    &lt;p&gt;Prototyping is fun and incredibly accessible. Anyone can do it using local coding agents, or even coding agents on the cloud such as Jules, Codex cloud, Cursor Cloud, Lovable, v0 and many many more.&lt;/p&gt;
    &lt;p&gt;This heavily lowers the bar needed for prototyping. Product managers can prototype, CEOs can prototype, designers can prototype, etc.&lt;/p&gt;
    &lt;p&gt;However, this new fun that opens a new series of questions you should explore with your team.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When is a prototype appropriate?&lt;/item&gt;
      &lt;item&gt;How do designers feel about them?&lt;/item&gt;
      &lt;item&gt;Are they distracting? (are links to the source code too tempting)?&lt;/item&gt;
      &lt;item&gt;Do they take away from human creativity?&lt;/item&gt;
      &lt;item&gt;How should we label and share prototypes?&lt;/item&gt;
      &lt;item&gt;Is a prototype forcing an idea to jump the queue?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When you introduce prototyping into your company you need to negotiate these questions carefully and form internal consensus, otherwise you risk creating large internal attitude divides and resentment.&lt;/p&gt;
    &lt;head rend="h3"&gt;The value of the prototype&lt;/head&gt;
    &lt;p&gt;Prototypes, what are they good for? Absolutely something.&lt;/p&gt;
    &lt;p&gt;I find prototypes incredibly helpful in my general development practices.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Grep on steroids. I love that prototypes often act as a way of searching through our large code base isolating all the little areas that may need changing to achieve a change&lt;/item&gt;
      &lt;item&gt;I love communicating in paragraphs, but I am also a visual communicator. I love how easy a well constructed prototype can communicate a design idea I have, despite me not being that good in Figma.&lt;/item&gt;
      &lt;item&gt;I love that there is something to play with. It often surfaces many concerns that could have been missed by a spec. The best prototype is tested, during the test you discover many tiny things that are just impossible to guess upfront.&lt;/item&gt;
      &lt;item&gt;The crazy code LLMs generate is often interesting to me, it can sometimes challenge some of my thinking.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The prototype - a maintainers survival guide&lt;/head&gt;
    &lt;p&gt;Sadly, as the year progresses, I expect many open source projects to receive many prototype level PRs. Not everyone would have read this blog post or even agree with it.&lt;/p&gt;
    &lt;p&gt;As a maintainer dealing with external contributions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Protect yourself and your time. Timebox initial reviews of large change sets, focus on determining if it was “vibe coded” vs leaving 100 comments on machine generated code that took minutes to generate.&lt;/item&gt;
      &lt;item&gt;Develop an etiquette for dealing with prototypes pretending to be PRs. Point people at contribution guidelines, give people a different outlet. “I am closing this but this is interesting, head over to our forum/issues to discuss”&lt;/item&gt;
      &lt;item&gt;Don’t feel bad about closing a vibe coded, unreviewed, prototype PR!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The ready to review PR&lt;/head&gt;
    &lt;p&gt;A ready to review PR is the traditional PRs we submit.&lt;/p&gt;
    &lt;p&gt;We reviewed all the machine generated code and vouch for all of it. We ran the tests and like the tests, we like the code structure, we read every single line of code carefully we also made sure the PR meets a project’s guidelines.&lt;/p&gt;
    &lt;p&gt;All the crazy code agents generated along the way has been fixed, we are happy to stamp our very own personal brand on the code.&lt;/p&gt;
    &lt;p&gt;Projects tend to have a large set of rules around code quality, code organisation, testing and more.&lt;/p&gt;
    &lt;p&gt;We may have used AI assistance to generate a ready to review PR, fundamentally, though this does not matter, we vouch for the code and stand behind it meeting both our brand and a project’s guidelines.&lt;/p&gt;
    &lt;p&gt;The distance from a prototype to a ready to review PR can be deceptively vast. There may be days of engineering taking a complex prototype and making it production ready.&lt;/p&gt;
    &lt;p&gt;This large distance was communicated as well by Andrej Karpathy in the Dwarkesh Podcast.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For some kinds of tasks and jobs and so on, there’s a very large demo-to-product gap where the demo is very easy, but the product is very hard.&lt;/p&gt;
      &lt;p&gt;…&lt;/p&gt;
      &lt;p&gt;For example, in software engineering, I do think that property does exist. For a lot of vibe coding, it doesn’t. But if you’re writing actual production-grade code, that property should exist, because any kind of mistake leads to a security vulnerability or something like that.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Veracode survey found that only 55% of generation tasks resulted in secure code. (source).&lt;/p&gt;
    &lt;p&gt;Our models are getting better by the day, and everything really depends on an enormous amount of parameters, but the core message that LLMs can and do generate insecure code, stands.&lt;/p&gt;
    &lt;head rend="h3"&gt;On alien intelligence&lt;/head&gt;
    &lt;p&gt;The root cause for the distance between project guidelines and a prototype is AI alien intelligence.&lt;/p&gt;
    &lt;p&gt;Many engineers I know fall into 2 camps, either the camp that find the new class of LLMs intelligent, groundbreaking and shockingly good. In the other camp are engineers that think of all LLM generated content as “the emperor’s new clothes”, the code they generate is “naked”, fundamentally flawed and poison.&lt;/p&gt;
    &lt;p&gt;I like to think of the new systems as neither. I like to think about the new class of intelligence as “Alien Intelligence”. It is both shockingly good and shockingly terrible at the exact same time.&lt;/p&gt;
    &lt;p&gt;Framing LLMs as “Super competent interns” or some other type of human analogy is incorrect. These systems are aliens and the sooner we accept this the sooner we will be able to navigate the complexity that injecting alien intelligence into our engineering process leads to.&lt;/p&gt;
    &lt;head rend="h3"&gt;Playing to alien intelligence strength, the prototype&lt;/head&gt;
    &lt;p&gt;Over the past few months I have been playing a lot with AI agents. One project I am particularly proud of is dv. It is a container orchestrator for Discourse, that makes it easy to use various AI agents with Discourse.&lt;/p&gt;
    &lt;p&gt;I will often run multiple complete and different throwaway Discourse environments on my machines to explore various features. This type of tooling excels at vibe engineering prototypes.&lt;/p&gt;
    &lt;p&gt;Interestingly dv was mostly built using AI agents with very little human intervention, some of the code is a bit off brand, that said unlike Discourse or many of the other open source gems I maintain it is a toy project.&lt;/p&gt;
    &lt;p&gt;Back on topic, dv has been a great factory for prototypes on Discourse. This has been wonderful for me. I have been able to explore many ideas while catching up on my emails and discussions on various Discourse sites.&lt;/p&gt;
    &lt;head rend="h3"&gt;On banning AI contributions, prototypes and similar&lt;/head&gt;
    &lt;p&gt;Firstly you must be respectful of the rules any project you contribute has, seek them out and read them prior to contributing. For example: Cloud hypervisor says no AI generated code to avoid licensing risks.&lt;/p&gt;
    &lt;p&gt;That said, there is a trend among many developers of banning AI. Some go so far as to say “AI not welcome here” find another project.&lt;/p&gt;
    &lt;p&gt;This feels extremely counterproductive and fundamentally unenforceable to me. Much of the code AI generates is indistinguishable from human code anyway. You can usually tell a prototype that is pretending to be a human PR, but a real PR a human makes with AI assistance can be indistinguishable.&lt;/p&gt;
    &lt;p&gt;The new LLM tooling can be used in tremendous amounts of ways including simple code reviews and simple renamings within a file, to complete change set architecture.&lt;/p&gt;
    &lt;p&gt;Given the enormous mess and diversity here I think the healthiest approach is to set clear expectations. If I am submitting a PR it should match my brand and be code I vouch for.&lt;/p&gt;
    &lt;p&gt;As engineers it is our role to properly label our changes. Is our change ready for human review or is it simply a fun exploration of the problem space?&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is this important?&lt;/head&gt;
    &lt;p&gt;Human code review is increasingly becoming a primary bottleneck in software engineering. We need to be respectful of people’s time and protect our own engineering brands.&lt;/p&gt;
    &lt;p&gt;Prototype are fun, they can teach us a lot about a problem space. But when it comes to sending contributions to a project, treat all code as code you wrote, put your stamp of ownership and approval on whatever you build and only then send a PR you vouch for.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://samsaffron.com/archive/2025/10/27/your-vibe-coded-slop-pr-is-not-welcome"/><published>2025-10-28T11:03:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45731366</id><title>Show HN: Bash Screensavers</title><updated>2025-10-28T13:45:21.074625+00:00</updated><content>&lt;doc fingerprint="2d05b3369bc42e9d"&gt;
  &lt;main&gt;
    &lt;p&gt;Tired of your boring old terminal? Wish you could spice up your command line with some animated ASCII art? Well, you've come to the right place!&lt;/p&gt;
    &lt;p&gt;Welcome to Bash Screensavers, a collection of screensavers written entirely in &lt;code&gt;bash&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Because who needs fancy graphics cards and complex rendering engines when you have &lt;code&gt;echo&lt;/code&gt;, &lt;code&gt;sleep&lt;/code&gt;, and a little bit of &lt;code&gt;tput&lt;/code&gt; magic?&lt;/p&gt;
    &lt;p&gt;Gallery - Quickstart - Contributing - Spotlight - Jury - Library - Chat&lt;/p&gt;
    &lt;p&gt;The Gallery README has info on all the screensavers.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/attogram/bash-screensavers.git
cd bash-screensavers
./screensaver.sh&lt;/code&gt;
    &lt;code&gt;Bash Screensavers v0.0.27 (Mystic Shine)

  1 . alpha        - random colorful pixels
  2 . bouncing     - bouncing 'O' madness
  3 . cutesaver    - infinite loop of cuteness
  4 . fireworks    - Ooh! Aah! Pretty lights!
  5 . life         - cellular automata
  6 . matrix       - the matrix has you
  7 . pipes        - an endless pipe maze
  8 . rain         - soothing, gentle rain
  9 . speaky       - dramatic talking screensaver
  10. stars        - twinkling starfield
  11. tunnel       - fly into the digital tunnel
  12. vibe         - vibe coding

(Press ^C to exit)

Choose your screensaver:
&lt;/code&gt;
    &lt;p&gt;
      &lt;code&gt;./screensaver.sh&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;./screensaver.sh name&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;./screensaver.sh number&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;./screensaver.sh -r&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;./screensaver.sh -h&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;./screensaver.sh -v&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;./gallery/name/name.sh&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;We welcome contributions!&lt;/p&gt;
    &lt;p&gt;For the nitty-gritty, see CONTRIBUTING.md.&lt;/p&gt;
    &lt;p&gt;Vibe coders and AI Assistants are welcome to join the party.&lt;/p&gt;
    &lt;p&gt;The spotlight is a set of curator tools for marketing and publicity fluff, like pretty previews of all the screensavers.&lt;/p&gt;
    &lt;p&gt;Read the Spotlight Manual for details.&lt;/p&gt;
    &lt;p&gt;The jury makes sure the gallery is up-to-snuff.&lt;/p&gt;
    &lt;p&gt;They test everything. They're a bit batsy about it.&lt;/p&gt;
    &lt;p&gt;See the Jury Criteria for the rules.&lt;/p&gt;
    &lt;p&gt;This directory contains screensavers that are not yet ready for general use.&lt;/p&gt;
    &lt;p&gt;They may be broken, incomplete, or just not up to the quality standards of the main gallery.&lt;/p&gt;
    &lt;p&gt;Feel free to experiment with them, but use them at your own risk!&lt;/p&gt;
    &lt;p&gt;The library is filled with stuff about visualizations and voices.&lt;/p&gt;
    &lt;p&gt;Read the Library Index to get started.&lt;/p&gt;
    &lt;p&gt;Have questions, ideas, or just want to chat?&lt;/p&gt;
    &lt;p&gt;Made with ❤️ and a lot of bash.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/attogram/bash-screensavers"/><published>2025-10-28T11:12:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45731539</id><title>Amazon confirms 14,000 job losses in corporate division</title><updated>2025-10-28T13:45:20.623264+00:00</updated><content>&lt;doc fingerprint="2d4099d126be1dec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Amazon confirms 14,000 job losses in corporate division&lt;/head&gt;
    &lt;p&gt;Amazon has confirmed it plans to cut thousands of jobs, saying it needs to be "organised more leanly" to seize the opportunity provided by artificial intelligence (AI).&lt;/p&gt;
    &lt;p&gt;The tech giant said on Tuesday it would reduce its global corporate workforce by "approximately 14,000 roles".&lt;/p&gt;
    &lt;p&gt;Earlier reporting had suggested it was planning to lay off as many as 30,000 workers.&lt;/p&gt;
    &lt;p&gt;Beth Galetti, a senior vice president at Amazon, wrote in a note to staff that the move would make the company "even stronger" by shifting resources "to ensure we're investing in our biggest bets and what matters most to our customers' current and future needs".&lt;/p&gt;
    &lt;p&gt;She acknowledged that some would question the move given the company was performing well.&lt;/p&gt;
    &lt;p&gt;At the end of July, Amazon reported second quarter results which beat Wall Street expectations on several counts, including a 13% year over year increase in sales to $167.7bn (£125bn).&lt;/p&gt;
    &lt;p&gt;But Ms Galetti said the cuts were needed because AI was "the most transformative technology we've seen since the Internet" and was "enabling companies to innovate much faster than ever before."&lt;/p&gt;
    &lt;p&gt;"We're convicted that we need to be organised more leanly, with fewer layers and more ownership, to move as quickly as possible for our customers and business," she added.&lt;/p&gt;
    &lt;p&gt;The note, shared with Amazon employees earlier on Tuesday, said the company was "working hard to support everyone whose role is impacted" - including by helping those affected find new roles within Amazon.&lt;/p&gt;
    &lt;p&gt;Those who cannot will receive "transition support" including severance pay, it said.&lt;/p&gt;
    &lt;p&gt;The BBC has asked if it will affect employees in the UK.&lt;/p&gt;
    &lt;p&gt;The company has more than 1.5 million employees across its warehouses and offices worldwide.&lt;/p&gt;
    &lt;p&gt;This includes around 350,000 corporate workers, which include those in executive, managerial and sales roles, according to figures that Amazon submitted to the US government last year.&lt;/p&gt;
    &lt;p&gt;Like many technology firms, Amazon hired aggressively during the Covid-19 pandemic to meet the surge in demand for online deliveries and digital services.&lt;/p&gt;
    &lt;p&gt;Amazon boss Andy Jassy has since focused on reducing spending as the company invests heavily in AI tools to boost efficiency.&lt;/p&gt;
    &lt;p&gt;Mr Jassy said in June that the increase in AI tools will likely lead to job cuts as machines take over routine tasks.&lt;/p&gt;
    &lt;p&gt;"We will need fewer people doing some of the jobs that are being done today, and more people doing other types of jobs," he said then.&lt;/p&gt;
    &lt;head rend="h2"&gt;'Inevitable'&lt;/head&gt;
    &lt;p&gt;Amazon has carried out several rounds of cuts to its corporate division in recent years.&lt;/p&gt;
    &lt;p&gt;It laid off around 27,000 workers over several months in 2022, as rivals similarly looked to reverse hiring increases made during the pandemic.&lt;/p&gt;
    &lt;p&gt;After the company posted its latest financial results in July, its more subdued profit guidance for the forthcoming quarter left some sceptical of whether - or when - its enormous AI investments would pay off.&lt;/p&gt;
    &lt;p&gt;Slower growth for its cloud business, Amazon Web Services (AWS), compared to rivals Microsoft and Google, also sparked concern among some investors.&lt;/p&gt;
    &lt;p&gt;Amazon will report its latest results on Thursday for the period ending 30 September.&lt;/p&gt;
    &lt;p&gt;Ben Barringer, technology analyst at Quilter Cheviot, said the wider industry would be watching Amazon closely as it embarked on its latest round of cuts.&lt;/p&gt;
    &lt;p&gt;"We are already seeing jobs in software development be shed thanks to the capabilities of some of these AI tools, and the big companies will be looking to redistribute and restructure their workforces accordingly," he told the BBC.&lt;/p&gt;
    &lt;p&gt;"They have the data and can apply AI in a way that unfortunately means job losses are inevitable."&lt;/p&gt;
    &lt;p&gt;Additional reporting by Philippa Wain&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c1m3zm9jnl1o"/><published>2025-10-28T11:39:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45732350</id><title>The next chapter of the Microsoft–OpenAI partnership</title><updated>2025-10-28T13:45:15.870660+00:00</updated><content>&lt;doc fingerprint="ad180c98122ccbd8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The next chapter of the Microsoft–OpenAI partnership&lt;/head&gt;
    &lt;p&gt;Since 2019, Microsoft and OpenAI have shared a vision to advance artificial intelligence responsibly and make its benefits broadly accessible. What began as an investment in a research organization has grown into one of the most successful partnerships in our industry. As we enter the next phase of this partnership, we’ve signed a new definitive agreement that builds on our foundation, strengthens our partnership, and sets the stage for long-term success for both organizations.&lt;/p&gt;
    &lt;p&gt;First, Microsoft supports the OpenAI board moving forward with formation of a public benefit corporation (PBC) and recapitalization. Following the recapitalization, Microsoft holds an investment in OpenAI Group PBC valued at approximately $135 billion, representing roughly 27 percent on an as-converted diluted basis, inclusive of all owners—employees, investors, and the OpenAI Foundation. Excluding the impact of OpenAI’s recent funding rounds, Microsoft held a 32.5 percent stake on an as-converted basis in the OpenAI for-profit.&lt;/p&gt;
    &lt;p&gt;The agreement preserves key elements that have fueled this successful partnership—meaning OpenAI remains Microsoft’s frontier model partner and Microsoft continues to have exclusive IP rights and Azure API exclusivity until Artificial General Intelligence (AGI).&lt;/p&gt;
    &lt;p&gt;It also refines and adds new provisions that enable each company to independently continue advancing innovation and growth.&lt;/p&gt;
    &lt;p&gt;What has evolved:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Once AGI is declared by OpenAI, that declaration will now be verified by an independent expert panel.&lt;/item&gt;
      &lt;item&gt;Microsoft’s IP rights for both models and products are extended through 2032 and now includes models post-AGI, with appropriate safety guardrails.&lt;/item&gt;
      &lt;item&gt;Microsoft’s IP rights to research, defined as the confidential methods used in the development of models and systems, will remain until either the expert panel verifies AGI or through 2030, whichever is first. Research IP includes, for example, models intended for internal deployment or research only. Beyond that, research IP does not include model architecture, model weights, inference code, finetuning code, and any IP related to data center hardware and software; and Microsoft retains these non-Research IP rights.&lt;/item&gt;
      &lt;item&gt;Microsoft’s IP rights now exclude OpenAI’s consumer hardware.&lt;/item&gt;
      &lt;item&gt;OpenAI can now jointly develop some products with third parties. API products developed with third parties will be exclusive to Azure. Non-API products may be served on any cloud provider.&lt;/item&gt;
      &lt;item&gt;Microsoft can now independently pursue AGI alone or in partnership with third parties.&lt;/item&gt;
      &lt;item&gt;If Microsoft uses OpenAI’s IP to develop AGI, prior to AGI being declared, the models will be subject to compute thresholds; those thresholds are significantly larger than the size of systems used to train leading models today.&lt;/item&gt;
      &lt;item&gt;The revenue share agreement remains until the expert panel verifies AGI, though payments will be made over a longer period of time.&lt;/item&gt;
      &lt;item&gt;OpenAI has contracted to purchase an incremental $250B of Azure services, and Microsoft will no longer have a right of first refusal to be OpenAI’s compute provider.&lt;/item&gt;
      &lt;item&gt;OpenAI can now provide API access to US government national security customers, regardless of the cloud provider.&lt;/item&gt;
      &lt;item&gt;OpenAI is now able to release open weight models that meet requisite capability criteria.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we step into this next chapter of our partnership, both companies are better positioned than ever to continue building great products that meet real-world needs, and create new opportunity for everyone and every business.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/next-chapter-of-microsoft-openai-partnership/"/><published>2025-10-28T13:05:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45732552</id><title>Sick: Indexed deduplicated binary storage for JSON-like data structures</title><updated>2025-10-28T13:45:15.229596+00:00</updated><content>&lt;doc fingerprint="90612815ccd70790"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;SICK&lt;/code&gt; is an approach to handle &lt;code&gt;JSON&lt;/code&gt;-like structures and various libraries implementing it.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;SICK&lt;/code&gt; allows you to achieve the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Store &lt;code&gt;JSON&lt;/code&gt;-like data in efficient indexed binary form&lt;/item&gt;
      &lt;item&gt;Avoid reading and parsing whole &lt;code&gt;JSON&lt;/code&gt;files and access only the data you need just in time&lt;/item&gt;
      &lt;item&gt;Store multiple &lt;code&gt;JSON&lt;/code&gt;-like structures in one deduplicating storage&lt;/item&gt;
      &lt;item&gt;Implement perfect streaming parsers for &lt;code&gt;JSON&lt;/code&gt;-like data&lt;/item&gt;
      &lt;item&gt;Efficiently stream updates for &lt;code&gt;JSON&lt;/code&gt;-like data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tradeoff for these benefits is somehow more complicated and less efficient encoder.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;JSON&lt;/code&gt; has a Type-2 grammar and requires a pushdown automaton to parse it. So, it's not possible to implement efficient streaming parser for &lt;code&gt;JSON&lt;/code&gt;. Just imagine a huge hierarchy of nested &lt;code&gt;JSON&lt;/code&gt; objects: you won't be able to finish parsing the top-level object until you process the whole file.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;JSON&lt;/code&gt; is frequently used to store and transfer large amounts of data and these transfers tend to grow over time. Just imagine a typical &lt;code&gt;JSON&lt;/code&gt; config file for a large enterprise product.&lt;/p&gt;
    &lt;p&gt;The non-streaming nature of almost all the JSON parsers requires a lot of work to be done every time you need to deserialize a huge chunk of &lt;code&gt;JSON&lt;/code&gt; data: you need to read it from disk, parse it in memory into an AST representation, and, usually, map raw &lt;code&gt;JSON&lt;/code&gt; tree to object instances. Even if you use token streams and know the type of your object ahead of time you still have to deal with the Type-2 grammar.&lt;/p&gt;
    &lt;p&gt;This may be very inefficient and causes unnecessary delays, pauses, CPU activity and memory consumption spikes.&lt;/p&gt;
    &lt;p&gt;Let's assume that we have a small &lt;code&gt;JSON&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;[
    {"some key": "some value"},
    {"some key": "some value"},
    {"some value": "some key"},
]&lt;/code&gt;
    &lt;p&gt;Let's build a table for every unique value in our &lt;code&gt;JSON&lt;/code&gt; :&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;index&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Is Root&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;"some key"&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;"some value"&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;object&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;[string:0, string:1]&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;object&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;[string:1, string:0]&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;array&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;[object:0, object:0, object:1]&lt;/cell&gt;
        &lt;cell&gt;Yes (file.json)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We just built a flattened and deduplicated version of our initial &lt;code&gt;JSON&lt;/code&gt; structure.&lt;/p&gt;
    &lt;p&gt;Such representation allows us to do many different things, for example we may stream our table:&lt;/p&gt;
    &lt;code&gt;string:0 = "some key"
string:1 = "some value"

object:0.size = 2
object:0[string:0] = string:1
object:1[string:1] = string:0

array:0.size = 2
array:0[0] = object:0
array:0[1] = object:1

string:2 = "file.json"

root:0=array:0,string:2
&lt;/code&gt;
    &lt;p&gt;This particular encoding is inefficient but it's streamable and, moreover, we can add removal message into it thus supporting arbitrary updates:&lt;/p&gt;
    &lt;code&gt;array:0[0] = object:1
array:0[1] = remove
&lt;/code&gt;
    &lt;p&gt;There is an interesting observation: when a stream does not contain removal entries it can be safely reordered.&lt;/p&gt;
    &lt;p&gt;Also this representation eliminates many cases where full accumulation is required. Obviously, not all of them, the receiver still may need to accumulate the entries in a buffer until it can sort them out.&lt;/p&gt;
    &lt;p&gt;We may note that the only complex data structures in our "Value" column are lists and &lt;code&gt;(type, index)&lt;/code&gt; pairs. Let's call such pairs "references".&lt;/p&gt;
    &lt;p&gt;A reference can be represented as a pair of integers, so it would have a fixed byte length.&lt;/p&gt;
    &lt;p&gt;A list of references can be represented as an integer storing list length followed by all the references in their binary form. Let's note that such binary structure is indexed, once we know the index of an element we want to access we can do it immediately.&lt;/p&gt;
    &lt;p&gt;A list of any fixed-size scalar values can be represented the same way.&lt;/p&gt;
    &lt;p&gt;A list of variable-size values (e.g. a list of strings) can be represented the following way:&lt;/p&gt;
    &lt;code&gt;  {strings count}{list of string offsets}{all the strings concatenated}
&lt;/code&gt;
    &lt;p&gt;So, &lt;code&gt;["a", "bb", "ccc"]&lt;/code&gt; would become something like &lt;code&gt;3 0 2 3 a b bb ccc&lt;/code&gt; without spaces.&lt;/p&gt;
    &lt;p&gt;An important fact is that this encoding is indexed too and it can be reused to store any lists of variable-length data.&lt;/p&gt;
    &lt;p&gt;TODO: explain the overall EBA structure format, including tables, etc&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;SICK&lt;/code&gt; encoding follows compositional principles of &lt;code&gt;JSON&lt;/code&gt; (a set primitive types plus lists and dictionaries), though it is more powerful: it has "reference" type and allows you to encode custom types.&lt;/p&gt;
    &lt;p&gt;(1) It's easy to note that our table may store circular references, something &lt;code&gt;JSON&lt;/code&gt; can't do natively:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;index&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Is Root&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;object&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;[string:0, object:1]&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;object&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;[string:1, object:0]&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This may be convenient in some complex cases.&lt;/p&gt;
    &lt;p&gt;(2) Also we may note, that we may happily store multiple json files in one table and have full deduplication over their content. We just need to introduce a separate attribute (&lt;code&gt;is root&lt;/code&gt;) storing either nothing or the name of our "root entry" (&lt;code&gt;JSON&lt;/code&gt; file).&lt;/p&gt;
    &lt;p&gt;In real implementation it's more convenient to just create a separate "root" type, the value of a root type should always be a reference to its name and a reference to the actual &lt;code&gt;JSON&lt;/code&gt; value we encoded:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;index&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;"some key"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;"some value"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;string&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;"some value"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;object&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;[string:0, string,1]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;object&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;[string:1, string:0]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;array&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;[object:0, object:0, object:1]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;root&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;[string:2, array:0]&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;(3) We may encode custom scalar data types (e.g. timestamps) natively just by introducing new type tags.&lt;/p&gt;
    &lt;p&gt;(4) We may even store polymorphic types by introducing new type tags or even new type references.&lt;/p&gt;
    &lt;p&gt;Currently we provide C# and Scala implementations of SICK indexed binary JSON storage. Currently the code in this repository has no streaming capabilities. That may change in the future. It's not a hard problem to add streaming support, your contributions are welcome.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Binary Storage Encoder&lt;/cell&gt;
        &lt;cell role="head"&gt;Binary Storage Decoder&lt;/cell&gt;
        &lt;cell role="head"&gt;Stream Encoder&lt;/cell&gt;
        &lt;cell role="head"&gt;Stream Decoder&lt;/cell&gt;
        &lt;cell role="head"&gt;Encoder AST&lt;/cell&gt;
        &lt;cell role="head"&gt;Decoder AST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Scala&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Circe&lt;/cell&gt;
        &lt;cell&gt;Circe&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;C#&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;JSON.Net&lt;/cell&gt;
        &lt;cell&gt;Custom&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Also we provide basic JavaScript implementation backed by Scala.JS.&lt;/p&gt;
    &lt;p&gt;A type marker is represented as a single-byte unsigned integer. The possible values are:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Marker&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Comment&lt;/cell&gt;
        &lt;cell role="head"&gt;Value Length (bytes)&lt;/cell&gt;
        &lt;cell role="head"&gt;C# mapping&lt;/cell&gt;
        &lt;cell role="head"&gt;Scala Mapping&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;TNul&lt;/cell&gt;
        &lt;cell&gt;Equivalent to &lt;code&gt;null&lt;/code&gt; in JSON&lt;/cell&gt;
        &lt;cell&gt;4, stored in the marker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;TBit&lt;/cell&gt;
        &lt;cell&gt;Boolean&lt;/cell&gt;
        &lt;cell&gt;4, stored in the marker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;TByte&lt;/cell&gt;
        &lt;cell&gt;Byte,&lt;/cell&gt;
        &lt;cell&gt;4, stored in the marker&lt;/cell&gt;
        &lt;cell&gt;byte (unsigned)&lt;/cell&gt;
        &lt;cell&gt;Byte (signed)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;TShort&lt;/cell&gt;
        &lt;cell&gt;Signed 16-bit integer&lt;/cell&gt;
        &lt;cell&gt;4, stored in the marker&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;TInt&lt;/cell&gt;
        &lt;cell&gt;Signed 32-bit integer&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;TLng&lt;/cell&gt;
        &lt;cell&gt;Signed 64-bit integer&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;TBigInt&lt;/cell&gt;
        &lt;cell&gt;Variable, prefixed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;TDbl&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;TFlt&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;TBigDec&lt;/cell&gt;
        &lt;cell&gt;Variable, prefixed&lt;/cell&gt;
        &lt;cell&gt;Custom: scale/precision/signum/unscaled quadruple in C#&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;TStr&lt;/cell&gt;
        &lt;cell&gt;UTF-8 String&lt;/cell&gt;
        &lt;cell&gt;Variable, prefixed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;TArr&lt;/cell&gt;
        &lt;cell&gt;List of array entries&lt;/cell&gt;
        &lt;cell&gt;Variable, prefixed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;TObj&lt;/cell&gt;
        &lt;cell&gt;List of object entries&lt;/cell&gt;
        &lt;cell&gt;Variable, prefixed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;TRoot&lt;/cell&gt;
        &lt;cell&gt;Index of the name string (4 bytes) + reference (4+1=5 bytes)&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;Array entries are just references.&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;TODO&lt;/p&gt;
    &lt;p&gt;Current implementation has the following limitations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Maximum object size: &lt;code&gt;65534&lt;/code&gt;keys&lt;/item&gt;
      &lt;item&gt;The order of object keys is not preserved&lt;/item&gt;
      &lt;item&gt;Maximum amount of array elements: &lt;code&gt;2^32&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Maximum amount of unique values of the same type: &lt;code&gt;2^32&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These limitations may be lifted by using more bytes to store offset pointers and counts on binary level. Though it's hard to imagine a real application which would need that.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SICK is battle-tested and covered by "good enough" test suite which includes cross-implementation correctness tests (C#&amp;lt;-&amp;gt;Scala).&lt;/item&gt;
      &lt;item&gt;SICK powers several proprietary applications running on mobile devices and in the browser, some of which have large userbases (hundreds of thousands DAU).&lt;/item&gt;
      &lt;item&gt;No known open source users as of Oct/2025.&lt;/item&gt;
      &lt;item&gt;More implementations for various platforms are needed, 3rd party implementations are very welcome.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/7mind/sick"/><published>2025-10-28T13:22:24+00:00</published></entry></feed>