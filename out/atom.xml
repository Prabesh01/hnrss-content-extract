<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-24T15:11:04.662054+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45686919</id><title>Date bug in Rust-based coreutils affects Ubuntu 25.10 automatic updates</title><updated>2025-10-24T15:11:12.850047+00:00</updated><content>&lt;doc fingerprint="6441185f9c2667f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Date bug affects Ubuntu 25.10 automatic updates&lt;/head&gt;
    &lt;p&gt;The Ubuntu Project has announced that a bug in the Rust-based uutils version of the date command shipped with Ubuntu 25.10 broke automatic updates:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Some Ubuntu 25.10 systems have been unable to automatically check for available software updates. Affected machines include cloud deployments, container images, Ubuntu Desktop and Ubuntu Server installs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The announcement includes remediation instructions for those affected by the bug. Systems with the rust-coreutils package version 0.2.2-0ubuntu2 or earlier have the bug, it is fixed in 0.2.2-0ubuntu2.1 or later. It does not impact manual updates using the apt command or other utilities.&lt;/p&gt;
    &lt;p&gt;Ubuntu embarked on a project to "oxidize" the distribution by switching to uutils and sudo-rs for the 25.10 release, and to see if the Rust-based utilities would be suitable for the long-term-release slated for next April. LWN covered that project in March.&lt;/p&gt;
    &lt;p&gt; Posted Oct 23, 2025 20:52 UTC (Thu) by dskoll (subscriber, #1630) [Link] (14 responses) ... will be called Grateful Guinea-Pig But seriously. Rewriting C utilities that have been battle-tested for decades in Rust might be a good idea in the long term, but anyone could have predicted short-term hiccups. Posted Oct 23, 2025 21:38 UTC (Thu) by geofft (subscriber, #59789) [Link] (8 responses) Posted Oct 23, 2025 22:21 UTC (Thu) by dskoll (subscriber, #1630) [Link] (7 responses) I don't have anything against Rust (nor against C), but I do think it's unfortunate that the Rust utilities are licensed under the MIT license rather than the GPL. But that's a whole other debate... Posted Oct 23, 2025 23:57 UTC (Thu) by dralley (subscriber, #143766) [Link] (3 responses) Posted Oct 24, 2025 8:46 UTC (Fri) by leromarinvit (subscriber, #56850) [Link] (2 responses) Posted Oct 24, 2025 12:13 UTC (Fri) by joib (subscriber, #8541) [Link] Posted Oct 24, 2025 13:25 UTC (Fri) by dralley (subscriber, #143766) [Link] Posted Oct 24, 2025 11:10 UTC (Fri) by ballombe (subscriber, #9523) [Link] (2 responses) Posted Oct 24, 2025 13:56 UTC (Fri) by ssokolow (guest, #94568) [Link] (1 responses) Posted Oct 24, 2025 15:02 UTC (Fri) by rahulsundaram (subscriber, #21946) [Link] I don't see anything in the KDE 4 announcement to indicate that it was a developer preview. Where is this coming from? Posted Oct 24, 2025 1:45 UTC (Fri) by welinder (guest, #4699) [Link] And it's humbling to see that a silly little bug deep in date can silently break unattended security updates! Posted Oct 24, 2025 6:30 UTC (Fri) by eru (subscriber, #2753) [Link] (3 responses) I fail to see why it would be a good idea even in the long term. These utilities are done, the specifications do not change, or change very little. The only valid reason might be a future situation, where support for the C language starts disappearing, which is totally a fantasy scenario. C is too entrenched for that to happen within the expected lifetime of our technical civilisation. Posted Oct 24, 2025 7:40 UTC (Fri) by taladar (subscriber, #68407) [Link] (2 responses) https://gitweb.git.savannah.gnu.org/gitweb/?p=coreutils.git showing the last 16 commits doesn't even go back a week of development history? These tools need maintenance and rewriting them in something with a saner build system than C has to offer after being around for 50 years certainly will make this easier. As for C not disappearing, it feels like we are already in an era where most young people below the age of 35-40 or so do not learn it any more so you might be surprised how quickly the pool of potential volunteer maintainers will deplete for boring, mature C projects. Posted Oct 24, 2025 8:48 UTC (Fri) by alx.manpages (subscriber, #145117) [Link] (1 responses) I'm 32, and I went to university with people 7 years younger than me, and C was still the main language we studied there. I've heard that some schools have reduced the amount of C courses, but it's still there. &amp;gt; so you might be surprised how quickly the pool of potential volunteer maintainers will deplete for boring, mature C projects. While the number of people knowing C enough might reduce, it might also increase the ratio of C programmers that know C very well. Self-selection can be a good thing. I don't expect the amount of C experts to diminish significantly. &amp;gt; These tools need maintenance and rewriting them in something with a saner build system than C has to offer after being around for 50 years certainly will make this easier. C has evolved quite a lot in these 50 years, and I'm not sure Rust is better than C. Most of the issues people complain about C are in reality issues with old C, or low quality compilers. Some issues remain in the latest GCC, but there's work on having an even better C in the following years. Incremental improvements are better than entirely jumping to a new language, and this issue with Rust's date(1) is an example of why we should keep improving the C version, which is almost bug-free, instead of writing bugs in a different language. &amp;lt;https://www.joelonsoftware.com/2000/04/06/things-you-shou...&amp;gt; Posted Oct 24, 2025 13:14 UTC (Fri) by LtWorf (subscriber, #124958) [Link] Posted Oct 23, 2025 21:12 UTC (Thu) by pixelbeat (guest, #7440) [Link] (11 responses) Then there are fundamental issues with SIGPIPE handling in all the uutils https://github.com/uutils/coreutils/issues/8919 Also there are questionable interface changes being added like 12 ways to get a sha3 https://github.com/uutils/coreutils/issues/8984 I wish them well, but this needs to be carefully managed. Posted Oct 23, 2025 23:26 UTC (Thu) by csigler (subscriber, #1224) [Link] I cannot possibly (imaginarily) upvote this comment enough. For those familiar with the 1976 movie "Network": "You have meddled with the primal forces of Unix, and _you_will_atone_!!!" Clemmitt Posted Oct 24, 2025 4:04 UTC (Fri) by Keith.S.Thompson (subscriber, #133709) [Link] (9 responses) I wonder whether that was a deliberate decision. ("true" and "false" are bash builtins, so the commands under /usr/bin probably aren't used very often.) Posted Oct 24, 2025 6:05 UTC (Fri) by mb (subscriber, #50428) [Link] (1 responses) Posted Oct 24, 2025 11:31 UTC (Fri) by makapuf (subscriber, #125557) [Link] /s Posted Oct 24, 2025 9:27 UTC (Fri) by jengelh (guest, #33263) [Link] (1 responses) uutils-md5sum was recently broken too[1], so it is only natural to make a sensitive program like /bin/true (only one very specific return value is allowed!) be based on a known-good implementation. [1] https://www.phoronix.com/news/Ubuntu-25.10-Coreutils-Make... Posted Oct 24, 2025 10:18 UTC (Fri) by collinfunk (guest, #169873) [Link] $ /bin/true; echo $? Posted Oct 24, 2025 11:09 UTC (Fri) by pixelbeat (guest, #7440) [Link] (2 responses) Posted Oct 24, 2025 13:41 UTC (Fri) by ebee_matteo (subscriber, #165284) [Link] (1 responses) &amp;gt; If you don't want to build the multicall binary and would prefer to build the utilities as individual binaries, that is also possible. This is a decision from the distribution to take, I would say. Posted Oct 24, 2025 13:55 UTC (Fri) by pixelbeat (guest, #7440) [Link] Note also that GNU coreutils can be built as a multi-call binary. Testing the performance of that here shows that the overhead is not rust specific, but rather the dynamic linker overhead loading the full set of libs linked by the multi-call binaries Posted Oct 24, 2025 13:31 UTC (Fri) by juliank (guest, #45896) [Link] (1 responses) Because we dispatch by argv[0] in the multi-call binary we then did not find the binary because the tool was invoked with the symlink name. We do have a hardlink farm now and can resolve based on hardlink where available but it's a bit messy because it requires /proc to be mounted. Posted Oct 24, 2025 14:58 UTC (Fri) by pixelbeat (guest, #7440) [Link] Posted Oct 23, 2025 21:35 UTC (Thu) by JMB (guest, #74439) [Link] And concerning servers ... in most cases even extreme security relevant problems At least the problem shows that it is not fuitile to have tested the new Rust code ... Posted Oct 23, 2025 22:00 UTC (Thu) by geofft (subscriber, #59789) [Link] (2 responses) Looks like this was originally reported in https://pad.lv/2127970 on October 16, exactly one week ago and also exactly one week after Ubuntu 25.10's release. The reporter originally mentioned the bug in the context of a homegrown backup script that was failing silently, and they got the fix into the proposed stable update repository yesterday, with an (understandable) argument about why it wasn't same-day levels of urgent. This morning, someone pointed out that it breaks unattended-upgrades. It seems to me that it was only at this point that it was tracked as a security issue, and the package is now available in both the (prod) stable updates repository and the more minimal security updates repository. The actual bug itself is simply that support for `date -r &amp;lt;file&amp;gt;` wasn't implemented. The issue https://github.com/uutils/coreutils/issues/8621 and the pull request implementing support https://github.com/uutils/coreutils/pull/8630 were both filed on the same day, September 12 of this year, and it was reviewed and merged into main two days later. This, understandably, postdates whichever release Ubuntu snapshotted. I think I am mostly surprised that the command silently accepted -r and did nothing, and indeed from the actual diff (https://github.com/uutils/coreutils/commit/88a7fa7adfa048...) it's pretty clear that the argument parser had support for it but it wasn't wired up to do anything. If the command had instead returned an argument parsing error, I think this would have been caught a lot quicker. It does seem a little bit odd that whoever implemented this in the argument parser didn't at least add an "if -r, throw 'todo'" case. But it's also interesting that this was not statically caught. The Rust compiler is pretty good at warning and complaining about unused variables. (To be fair, most C compilers and many other languages are too, though anecdotally these warnings seem less noisy in Rust and I've seen more codebases in Rust where this is a hard failure than C codebases using -Werror. Also, Rust has #[must_use], if you want to be thorough.) However, there wasn't actually an unused variable here; you can see that you get the value out of the parsed-arguments object by asking for the value of the flag. I wonder if it's worth thinking about an argument-parsing API in Rust that would raise an unused-variable warning at compile time if a parsed command-line flag or argument is never used in the code. It might also be possible to do this with the existing parser with a sufficiently clever linter. Either way, the lack of compile-time detection of this bug feels at odds with the philosophy of a Rust rewrite of coreutils, i.e., that there's merit in having tools do the checking instead of trusting and expecting people to write perfect code. I also think it would be very much worth it for Ubuntu and the uutils developers to manually do an audit for all arguments that are parsed in an argument parser but not actually implemented. If this pattern happened once, it likely isn't the only case. Posted Oct 24, 2025 7:49 UTC (Fri) by taladar (subscriber, #68407) [Link] (1 responses) Posted Oct 24, 2025 9:19 UTC (Fri) by cyperpunks (subscriber, #39406) [Link] &lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;lb/&gt; It is not an other debate. This bug is a direct consequence of this decision.&lt;lb/&gt; If they were willing to be a GNU GPL derivative of the original coreutils, they could port the C code to rust instead of rewriting it from first principle, which would avoid introduce fresh bugs.&lt;head/&gt; And yet I don't think that's how it would go for two reasons: &lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;list/&gt; I blame Canonical for precipitating a second "We told you KDE 4.0 was a developer preview, not an end-user release" situation. &lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;Don't fix what aint broke&lt;/head&gt;&lt;quote&gt; Rewriting C utilities that have been battle-tested for decades in Rust might be a good idea in the long term, &lt;/quote&gt;&lt;head&gt;Don't fix what aint broke&lt;/head&gt;&lt;head&gt;Don't fix what aint broke&lt;/head&gt;&lt;head&gt;Don't fix what aint broke&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is not doing well&lt;/head&gt;&lt;head&gt;uutils is not doing well&lt;/head&gt;&lt;lb/&gt; 0&lt;lb/&gt; $ /bin/true --help &amp;gt; /dev/full; echo $?&lt;lb/&gt; true: write error: No space left on device&lt;lb/&gt; 1&lt;head/&gt; Interesting, I hadn't realized /bin/true was still GNU. Perhaps this is a performance consideration, as all uutils have a larger startup overhead than their GNU equivalents, due mainly to the large multicall binary being used (due to rust binaries being significantly larger). For example: &lt;head&gt;uutils has more overhead&lt;/head&gt;&lt;quote&gt; $ time seq 10000 | xargs -n1 true real 0m8.634s user 0m3.178s sys 0m5.616s $ time seq 10000 | xargs -n1 uu_true real 0m22.137s user 0m6.542s sys 0m15.561s &lt;/quote&gt; It irks me to see mention of rust implementations being faster, when at a fundamental level like this they're slower and add significant overhead to every command run &lt;head&gt;uutils has more overhead&lt;/head&gt;&lt;head/&gt; Yes agreed, though it's a different decision with uutils as the separate binaries are significantly larger. &lt;head&gt;uutils has more overhead&lt;/head&gt;&lt;quote&gt; $ ./configure --enable-single-binary --quiet &amp;amp;&amp;amp; make -n $(nproc) $ time seq 10000 | xargs -n1 src/true real 0m21.595s user 0m7.437s sys 0m14.151s &lt;/quote&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head/&gt; Ah right. Note the default GNU coreutils setup avoids that issue by using a wrapper script rather than symlinks. That's the default behavior with ./configure --enable-single-binary in GNU coreutils. I.e. it would install a file with the following contents at /usr/bin/true &lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;quote&gt;#!/usr/bin/coreutils --coreutils-prog-shebang=true&lt;/quote&gt;&lt;head&gt;No problems for oldschool Linux users ...&lt;/head&gt;&lt;lb/&gt; For Smartphone Junkies that may be true (due to fear of missing out),&lt;lb/&gt; but for experts there is no need to get even security fixes in less than a week.&lt;lb/&gt; are not fixed due to other priorities anyway ... form frozen zone ... to ice age.&lt;lb/&gt; but still wondering if concerning all bugs Rust really have a positive benefit&lt;lb/&gt; for experienced coders ... seems more a hype than something which can be prooved.&lt;head&gt;uutils date bug timeline and root cause&lt;/head&gt;&lt;head&gt;uutils date bug timeline and root cause&lt;/head&gt;&lt;head&gt;uutils date bug timeline and root cause&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/Articles/1043103/"/><published>2025-10-23T20:49:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45687458</id><title>/dev/null is an ACID compliant database</title><updated>2025-10-24T15:11:12.499468+00:00</updated><content>&lt;doc fingerprint="8812dd1940f64a11"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Atomicity&lt;/head&gt;
    &lt;p&gt;Operations are "all or nothing."&lt;/p&gt;
    &lt;p&gt;Anything you write to &lt;code&gt;/dev/null&lt;/code&gt; disappears entirely. There's no partial write problem: it’s either written (and discarded) or not written at all. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Consistency&lt;/head&gt;
    &lt;p&gt;The system transitions from one valid state to another.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; always stays in a consistent state (empty). No matter what you write, the invariant "file contains nothing" always holds. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Isolation&lt;/head&gt;
    &lt;p&gt;Concurrent transactions don’t interfere with each other.&lt;/p&gt;
    &lt;p&gt;Multiple processes can write to &lt;code&gt;/dev/null&lt;/code&gt; at the same time, and their outputs never conflict, because nothing is ever stored. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Durability&lt;/head&gt;
    &lt;p&gt;Once a transaction is committed, it remains so, even after crashes.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; "durably" commits your data into nothingness. After a crash or reboot, it still contains exactly what it always has: nothing. ✅&lt;/p&gt;
    &lt;p&gt;There is only 1 small problem though, it only comes with 0b of free storage. For more space, you will have to contact entreprise sales, which is actually just me!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jyu.dev/blog/why-dev-null-is-an-acid-compliant-database/"/><published>2025-10-23T21:28:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45687796</id><title>How memory maps (mmap) deliver faster file access in Go</title><updated>2025-10-24T15:11:11.822570+00:00</updated><content>&lt;doc fingerprint="f2fbd59d36b2b0c8"&gt;
  &lt;main&gt;
    &lt;p&gt;One of the slowest things you can do in an application is making system calls. They're slow because you do have to enter the kernel, which is quite expensive. What should you do when you need to do a lot of disk I/O but you care about performance? One solution is to use memory maps.&lt;lb/&gt;Memory maps are a modern Unix mechanism where you can take a file and make it part of the virtual memory. In Unix context, modern means that it was introduced in the 1980s or later. You have a file, containing data, you mmap it and you'll get a pointer to where this resides. Now, instead of seeking and reading, you just read from this pointer, adjusting the offset to get to the right data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;To show what kind of performance you can get using memory maps, I've written a little Go library that allows you to read from a file using a memory map or a ReaderAt. ReaderAt will do a pread(), which is a seek/read combo, while mmap will just read from the memory map.&lt;/p&gt;
    &lt;p&gt;This almost feels like magic. Initially, when we launched Varnish Cache back in 2006, this was one of the features that made Varnish Cache very fast when delivering content. Varnish Cache would use memory maps to deliver content at blistering speeds.&lt;lb/&gt;Also, since you can operate with pointers into memory that is allocated by the memory map, you'll reduce memory pressure as well as raw latency.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Downside of Memory Maps&lt;/head&gt;
    &lt;p&gt;The downside of memory maps is that you really can't write to the memory map. The reason is due to the way virtual memory works. When you're writing to a part of virtual memory that isn't mapped into physical memory, the CPU will generate a page fault. On a modern computer, the CPU is responsible for tracking what virtual memory pages are mapped onto what physical memory. Since you're writing to a page that isn't mapped, the CPU needs help.&lt;lb/&gt;So, when the page fault occurs, the OS will 1) allocate a new memory page, 2) read the contents of the file at the correct offset, 3) write this to the new memory page. Then control is returned to the application. The application will now overwrite the virtual memory page with new data.&lt;lb/&gt;Can we stop and appreciate how extremely inefficient this is? I think it is fairly safe to say that writing through a memory map is never a good idea when considering performance. At least if there is any risk, the file isn't mapped up in physical memory.&lt;lb/&gt;Let me illustrate this with a few more benchmarks.&lt;/p&gt;
    &lt;p&gt;As you can see, whether or not the pages are in cache is crucial for performance. WriterAt, which uses the pwrite call, is a much more predictable bet.&lt;lb/&gt;Still, writing through memory maps, was what Varnish Cache did initially. It somehow got away with it, but mostly because the competition was pretty bad.&lt;lb/&gt;This is why Varnish Cache got the malloc backend and why Varnish Enterprise got the various Massive Storage Engines. The malloc backend resolved the problem by just allocating system memory through the malloc system call, and the Massive Storage Engine uses io_uring, which is so new that support for it is still somewhat limited.&lt;/p&gt;
    &lt;head rend="h2"&gt;Using Memory Maps to Solve Real-world Performance Problems&lt;/head&gt;
    &lt;p&gt;The last couple of weeks I've been working on an HTTP-backed filesystem. This is part of our AI Storage Acceleration solution, geared towards high performance computing environments. In this filesystem we needed a way to transfer folder data over HTTP. A folder is really just a listing of files, symbolic links and directories. The naive approach would be just to use JSON encoding, but JSON is notorious for being slow.&lt;lb/&gt;Our priority is performance. We made a benchmarking suite, comparing various databases with each other. CDB was overall the fastest. Looking at the numbers, we'd still see that CDB would spend something like 1200ns on a database lookup that was entirely in the page cache. This seems very slow to me. After all, everything should be in memory and spending 1200ns reading memory sounds at least 100x too slow. I started looking into the CDB implementation I was using. It was the above ReaderAt implementation. So, most of the time is likely spent waiting for the operating system.&lt;lb/&gt;Some hours later, I was able to replace the seek/read with a memory map. This resulted in a 25x improvement in performance. Again, it feels like magic. Unlike the original file stevedore in Varnish Cache, this performance improvement has no downside.&lt;lb/&gt;Benchmarks: https://github.com/perbu/mmaps-in-go &lt;lb/&gt;CDB64 files with memory maps: https://github.com/perbu/cdb &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://info.varnish-software.com/blog/how-memory-maps-mmap-deliver-25x-faster-file-access-in-go"/><published>2025-10-23T21:56:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45688236</id><title>Automating Algorithm Discovery: A Case Study in MoE Load Balancing</title><updated>2025-10-24T15:11:11.555237+00:00</updated><link href="https://adrs-ucb.notion.site/moe-load-balancing"/><published>2025-10-23T22:35:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45689241</id><title>Counter-Strike's player economy is in a multi-billion dollar freefall</title><updated>2025-10-24T15:11:11.233048+00:00</updated><content>&lt;doc fingerprint="b660f151878bcf98"&gt;
  &lt;main&gt;
    &lt;p&gt;Counter-Strike has long been known for two things: tight tactical FPS gameplay and a thriving player marketplace effectively valued at literal billions of dollars. Now, thanks to a recent update from Valve, the latter is in a downward spiral, having lost 25% of its value — or $1.75 billion — overnight.&lt;/p&gt;
    &lt;p&gt;First, some context. Counter-Strike is a free-to-play multiplayer shooter. As with most other F2P games, it generates revenue from selling cosmetics. They arrive in lootbox-like Cases, which are opened by Keys purchased with real-world currency. They can also be obtained through trading with other players and purchasing from Steam Community Market. Beyond Steam, unofficial third-party marketplaces for CS cosmetics have also popped up as channels for buying and selling items.&lt;/p&gt;
    &lt;p&gt;Because items are obtained at random through opening Cases, rarer items fetch the highest value on the open marketplaces. Items of lower-rarity tiers can also be traded in at volume for an item of a higher tier via trade up contracts. Previously, Knives and Gloves could not be obtained through trade up contracts, exponentially increasing their value as highly sought-after items. Prior to the most recent update, some Knives, like a Doppler Ruby Butterfly Knife, could fetch around $20,000 on third-party storefronts like CSFloat.&lt;/p&gt;
    &lt;p&gt;Following Valve's Oct. 22 update to Counter-Strike, the second-highest-tier, Covert (Red), can now be traded up and turned into Knives and Gloves. Essentially, this means that a previously extremely rare and highly sought-after cosmetic is going to be much more obtainable for those who increasingly want it, reducing the value of Knives and Gloves on the open marketplace.&lt;/p&gt;
    &lt;p&gt;And this is where the market descends into a freefall. Now, that Butterfly Knife mentioned above? It's going for around $12,000, as people are essentially dumping their stock, with 15 sold over the past 16 hours at the time of this writing.&lt;/p&gt;
    &lt;p&gt;Bloomberg reported the market for Counter-Strike cosmetic items dropped 25% overnight from Wednesday evening into Thursday morning. It's lost about $1.84 billion in value, according to Pricempire, which tracks and analyses the market for CS items. "This completely changes the supply of Counter-Strike’s most sought-after and expensive tier of items," Pricempire marketing manager Ethan MacDonald told Bloomberg.&lt;/p&gt;
    &lt;p&gt;As sellers attempt to recoup their investments, similar fire sales like the one happening at CSFloat are occurring at other sites. One such site, Skin Port, even put us in a waiting room to access it; traffic was overwhelming its servers.&lt;/p&gt;
    &lt;p&gt;Just like how NFT or cryptocurrency values can drastically shift, Counter-Strike item traders are seeing their stock rapidly change in value, and not for the best. While some items of lower-rarity tiers have gone up in value, and Reds might see a bump now that they can be traded up into Knives and Gloves, that can't make up for the sudden drop at the top of the cosmetics market.&lt;/p&gt;
    &lt;p&gt;We'll have to wait and see if the market levels out or if it continues to crash. Plenty of players and CS traders must be eagerly awaiting more news: As of this writing, Pricempire's servers had crashed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.polygon.com/counter-strike-cs-player-economy-multi-billion-dollar-freefall/"/><published>2025-10-24T00:24:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45690219</id><title>Fast-DLLM: Training-Free Acceleration of Diffusion LLM</title><updated>2025-10-24T15:11:11.040168+00:00</updated><content>&lt;doc fingerprint="6c9c362a57f5d2ca"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 28 May 2025 (v1), last revised 3 Jul 2025 (this version, v3)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Diffusion-based large language models (Diffusion LLMs) have shown promise for non-autoregressive text generation with parallel decoding capabilities. However, the practical inference speed of open-sourced Diffusion LLMs often lags behind autoregressive models due to the lack of Key-Value (KV) Cache and quality degradation when decoding multiple tokens simultaneously. To bridge this gap, we introduce a novel block-wise approximate KV Cache mechanism tailored for bidirectional diffusion models, enabling cache reuse with negligible performance drop. Additionally, we identify the root cause of generation quality degradation in parallel decoding as the disruption of token dependencies under the conditional independence assumption. To address this, we propose a confidence-aware parallel decoding strategy that selectively decodes tokens exceeding a confidence threshold, mitigating dependency violations and maintaining generation quality. Experimental results on LLaDA and Dream models across multiple LLM benchmarks demonstrate up to \textbf{27.6$\times$ throughput} improvement with minimal accuracy loss, closing the performance gap with autoregressive models and paving the way for practical deployment of Diffusion LLMs.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Chengyue Wu [view email]&lt;p&gt;[v1] Wed, 28 May 2025 17:39:15 UTC (272 KB)&lt;/p&gt;&lt;p&gt;[v2] Wed, 2 Jul 2025 05:11:54 UTC (502 KB)&lt;/p&gt;&lt;p&gt;[v3] Thu, 3 Jul 2025 04:51:05 UTC (541 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2505.22618"/><published>2025-10-24T02:50:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45690251</id><title>Roc Camera</title><updated>2025-10-24T15:11:10.676107+00:00</updated><content>&lt;doc fingerprint="d8c40a7031a4502f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Photos used to be magic&lt;/head&gt;
    &lt;head rend="h2"&gt;Photosusedtobemagic&lt;/head&gt;
    &lt;p&gt;There was a time when cameras captured magic. Photos told stories of a certain moment in time, a reflection of reality, a physical artifact of lives.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI has blurred the line&lt;/head&gt;
    &lt;head rend="h2"&gt;AIhasblurredtheline&lt;/head&gt;
    &lt;p&gt;Now, how we take, share, and create images has changed. Social media has made sharing images easy. Generative AI now creates any image we can imagine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lost sight of what is real&lt;/head&gt;
    &lt;head rend="h2"&gt;Lostsightofwhatisreal&lt;/head&gt;
    &lt;p&gt;We've started to lose sight of what is real. We've lost our ability to find our bearings in an endless sea of copies and AI-generated noise.&lt;/p&gt;
    &lt;head rend="h2"&gt;It's time for Roc Camera&lt;/head&gt;
    &lt;head rend="h2"&gt;It'stimeforRocCamera&lt;/head&gt;
    &lt;p&gt;By combining attested sensor data, zero-knowledge proofs, and a tamper-proof environment, we've built Roc Camera to capture verifiably real photos.&lt;/p&gt;
    &lt;head rend="h3"&gt;Camera Components:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;â¢ 4-inch IPS LCD Screen 720x720 with Capacitive Touch&lt;/item&gt;
      &lt;item&gt;â¢ 16MP Sony IMX519 CMOS with 122Â° FOV lens&lt;/item&gt;
      &lt;item&gt;â¢ Raspberry Pi 4 4GB RAM ARM Cortex-A72 1.5 Ghz&lt;/item&gt;
      &lt;item&gt;â¢ LiPo 4000mAh Battery&lt;/item&gt;
      &lt;item&gt;â¢ Uninterruptible Power Supply Board&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Capture&lt;/head&gt;
    &lt;p&gt;Capture a photo that only this Camera can uniquely take&lt;/p&gt;
    &lt;head rend="h3"&gt;Prove&lt;/head&gt;
    &lt;p&gt;Creates a Zero Knowledge (ZK) Proof of the camera sensor data and other metadatas&lt;/p&gt;
    &lt;head rend="h3"&gt;Verify&lt;/head&gt;
    &lt;p&gt;Verify that the photo is real by checking the ZK proof via the Roc Photo SDK&lt;/p&gt;
    &lt;head rend="h2"&gt;Capture verifiably real moments&lt;/head&gt;
    &lt;p&gt;Accepting orders now â (Batch 2)&lt;/p&gt;
    &lt;p&gt;Ships in 2~3 weeks&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://roc.camera/"/><published>2025-10-24T02:54:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45690679</id><title>JupyterGIS breaks through to the next level</title><updated>2025-10-24T15:11:09.786990+00:00</updated><content>&lt;doc fingerprint="1e3f8f51d82fedc0"&gt;
  &lt;main&gt;
    &lt;p&gt;Launched in June 2024, JupyterGIS was introduced as a collaborative, web-based GIS environment built on the JupyterLab framework. Its objective is to bring QGIS-inspired workflows into the browser, enabling real-time collaborative editing, seamless integration with notebooks, and support for core geospatial data formats.&lt;/p&gt;
    &lt;p&gt;When it was first announced earlier this year, JupyterGIS already delivered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time collaborative editing (Google Docs-style)&lt;/item&gt;
      &lt;item&gt;Visualisation of raster &amp;amp; vector data&lt;/item&gt;
      &lt;item&gt;Symbology editing and spatio-temporal animations&lt;/item&gt;
      &lt;item&gt;Programmatic map control via a Python API.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks to contributions from the community and support from partner organizations, JupyterGIS has advanced significantly and now offers an expanded range of features for analysis, visualization, and collaboration.&lt;/p&gt;
    &lt;p&gt;Enhanced vector tile capabilities&lt;/p&gt;
    &lt;p&gt;Support for vector tiles has been strengthened, including full compatibility with the pmtiles format.&lt;/p&gt;
    &lt;p&gt;Other key updates include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An identify tool that inspects vector tiles to display features and associated properties.&lt;/item&gt;
      &lt;item&gt;A symbology panel that applies graduated, categorized, and canonical symbology to vector tile layers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These improvements enhance the interpretability and styling of geospatial datasets directly in the browser.&lt;/p&gt;
    &lt;p&gt;A new processing toolbox&lt;/p&gt;
    &lt;p&gt;One of the most significant updates is a new browser-based processing toolbox powered by a WebAssembly (WASM) build of the Geospatial Data Abstraction Library (GDAL).&lt;/p&gt;
    &lt;p&gt;Available tools include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Buffer: computes a buffer around geometries of a vector dataset.&lt;/item&gt;
      &lt;item&gt;Convex Hull: calculates the convex hull for each feature of an input layer.&lt;/item&gt;
      &lt;item&gt;Dissolve: combines features of vector layers into new features&lt;/item&gt;
      &lt;item&gt;Bounding Boxes: calculates the bounding box for each feature in an input layer.&lt;/item&gt;
      &lt;item&gt;Centroid: creates a new layer with the centroids of the geometries of an input layer.&lt;/item&gt;
      &lt;item&gt;Concave Hull: computes the concave hull for each feature of an input point layer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This toolbox has been designed for extensibility, with a JSON schema that allows additional GDAL operations to be integrated in a straightforward manner.&lt;/p&gt;
    &lt;p&gt;Symbology enhancements&lt;/p&gt;
    &lt;p&gt;Visualization of geospatial data has become more flexible and expressive through several enhancements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Viridis is now the default colormap, providing perceptually uniform visualization.&lt;/item&gt;
      &lt;item&gt;Multiband symbology is now available for GeoTIFFs.&lt;/item&gt;
      &lt;item&gt;Canonical symbology defined in GeoJSON files can be applied automatically.&lt;/item&gt;
      &lt;item&gt;Colormaps can now be reversed, allowing greater flexibility for data interpretation and visualization.&lt;/item&gt;
      &lt;item&gt;In the case of point layers, color and marker size can be styled independently, and bound to different data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integration with SpatioTemporal Asset Catalogs (STAC)&lt;/p&gt;
    &lt;p&gt;A SpatioTemporal Asset Catalog (STAC) browser is now embedded into JupyterGIS, streamlining access to different data collections. Users can select specific platforms and sensors, choose data products and processing levels, and set temporal and spatial constraints.&lt;/p&gt;
    &lt;p&gt;It is now possible to search across multiple datasets simultaneously. Users can click on any result to add it directly as a layer to their JupyterGIS project. This creates a seamless workflow from data discovery to visualization, making it easier for researchers and analysts to find and integrate relevant satellite imagery and geospatial datasets into their Jupyter notebooks.&lt;/p&gt;
    &lt;p&gt;Currently, the STAC Browser only supports the Geodes STAC API but support for all STAC catalogs is under way.&lt;/p&gt;
    &lt;p&gt;Support for more data types&lt;/p&gt;
    &lt;p&gt;The range of supported geospatial data formats is now broadened with GeoParquet and PMTiles, enabling efficient columnar storage and fast analytical queries for GeoParquet, and highly compact, streaming-friendly vector tile delivery for PMTiles.&lt;/p&gt;
    &lt;p&gt;User experience and interface improvements&lt;/p&gt;
    &lt;p&gt;The interface has been refined for a smoother workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Integrated control panels (layer list, filters, layer properties, etc.), reducing back and forth between the JupyterLab side-panels and the JupyterGIS UI. It also improves the “single document” scenario, allowing it to interact with JupyterGIS controls when opening a GIS document from the classic Jupyter Notebook UI.&lt;/item&gt;
      &lt;item&gt;An improved toolbar design, with cleaner icons and better usability.&lt;/item&gt;
      &lt;item&gt;A new feature to center the map on your current location.&lt;/item&gt;
      &lt;item&gt;Map annotations now link to the map: clicking an annotation automatically re-centers and zooms to the location.&lt;/item&gt;
      &lt;item&gt;Full-screen mode support.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Legends for vector layers&lt;/p&gt;
    &lt;p&gt;JupyterGIS now automatically generates legends for vector layers, ensuring consistent interpretation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Legends are dynamically updated to reflect current symbology.&lt;/item&gt;
      &lt;item&gt;Customizations such as reversed colormaps are preserved.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;JupyterGIS tiler extension&lt;/p&gt;
    &lt;p&gt;An extension for JupyterGIS enables the creation of JupyterGIS layers from xarray variables in Jupyter kernels, with support for lazy evaluation, bridging geospatial workflows with powerful array-based computation.&lt;/p&gt;
    &lt;p&gt;The package, called JupyterGIS-tiler, is available in GitHub here and can be installed from PyPI with pip install jupytergis-tiler.&lt;/p&gt;
    &lt;p&gt;Looking ahead&lt;/p&gt;
    &lt;p&gt;Development will continue to expand JupyterGIS in several directions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extension of the GDAL-based processing toolbox.&lt;/item&gt;
      &lt;item&gt;Deeper integration with QGIS and a richer Python API for automation.&lt;/item&gt;
      &lt;item&gt;A Story Maps Editor and Viewer to enable interactive communication of geospatial information through text, imagery, and maps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the meantime, feel free to try JupyterGIS directly in your browser with JupyterLite, no installation required.&lt;/p&gt;
    &lt;p&gt;Opportunities for engagement also include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Checking out documentation for tutorials and the Python API.&lt;/item&gt;
      &lt;item&gt;Discussions via the GeoJupyter Zulip channel or the bi-weekly GeoJupyter hackathon.&lt;/item&gt;
      &lt;item&gt;Contributions to the development repository.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The JupyterGIS community continues to grow, and active participation from researchers, developers, and educators worldwide is encouraged.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eo4society.esa.int/2025/10/16/jupytergis-breaks-through-to-the-next-level/"/><published>2025-10-24T04:13:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45692585</id><title>Interstellar Mission to a Black Hole</title><updated>2025-10-24T15:11:09.585517+00:00</updated><content>&lt;doc fingerprint="b6467ad31861cbdb"&gt;
  &lt;main&gt;
    &lt;p&gt;We normally think of interstellar flight in terms of reaching a single target. The usual destination is one of the Alpha Centauri stars, and because we know of a terrestrial-mass planet there, Proxima Centauri emerges as the best candidate. I don’t recall Proxima ever being named as the destination Breakthrough Starshot officially had in mind, but there is such a distance between it (4.2 light years) and the next target, Barnard’s Star at some 5.96 light years, that it seems evident we will give the nod to Proxima. If, that is, we decide to go interstellar.&lt;/p&gt;
    &lt;p&gt;Let’s not forget, though, that if we build a beaming infrastructure either on Earth or in space that can accelerate a sail to a significant percentage of lightspeed, we can use it again and again. That means many possible targets. I like the idea of exploring other possibilities, which is why Cosimo Bambi’s ideas on black holes interest me. Associated with Fudan University in Shanghai as well as New Uzbekistan University in Tashkent, Bambi has been thinking about the proliferation of black holes in the galaxy, and the nearest one to us. I’ve been pondering his notions ever since reading about them last August.&lt;/p&gt;
    &lt;p&gt;Black holes are obviously hard to find as we scale down to solar mass objects, and right now the closest one to us is GAIA-BH1, some 1560 light years out. But reading Bambi’s most recent paper, I see that one estimate of the number of stellar mass black holes in our galaxy is 1.4 X 109. Bambi uses this number, but as we might expect, estimates vary widely, from 10 million to 1 billion. These numbers are extrapolated from the population of massive stars and to a very limited extent on clues from observational astronomy.&lt;/p&gt;
    &lt;p&gt;Image: The first image of Sagittarius A*, or Sgr A*, the supermassive black hole at the center of our galaxy. Given how hard it was to achieve this image, can we find ways to locate far smaller solar-mass black holes, and possibly send a mission to one? Credit: Event Horizon Telescope Collaboration.&lt;/p&gt;
    &lt;p&gt;Bambi calculates a population of 1 black hole and 10 white dwarfs for every 100 stars in the general population. If he’s anywhere close to right, a black hole might well exist within 20 to 25 light years, conceivably detected in future observations by its effects upon the orbital motion of a companion star, assuming we are so lucky as to find a black hole in a binary system. The aforementioned GAIA-BH1 is in such a system, orbiting a companion star.&lt;/p&gt;
    &lt;p&gt;Most black holes, though, are thought to be isolated. One black hole (OGLE-2011-BLG-0462) has been detected through microlensing, and perhaps LIGO A+, the upgrade to the two LIGO facilities in Hanford, Washington, and Livingston, Louisiana, can help us find more as we increase our skills at detecting gravitational waves. There are other options as well, as Bambi notes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Murchikova &amp;amp; Sahu (2025) proposed to use observational facilities like the Square Kilometer Array (SKA), the Atacama Large Millimiter/Submillimiter Array (ALMA), and James Webb Space Telescope (JWST). Isolated black holes moving through the interstellar medium can accrete from the interstellar medium itself and such an accretion process produces electromagnetic radiation. Murchikova &amp;amp; Sahu (2025) showed that current observational facilities can already detect the radiation from isolated black holes in the warm medium of the Local Interstellar Cloud within 50 pc of Earth, but their identification as accreting black holes is challenging and requires multi-telescope observations.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If we do find a black hole out there at, say, 10 light years, we now have a target for future beamed sailcraft that offers an entirely different mission concept. We’re now probing not simply an unknown planet, but an astrophysical object so bizarre that observing its effects on spacetime will be a primary task. Sending two nanocraft, one could observe the other as it approaches the black hole. A signal sent from one to the other will be affected by the spacetime metric – the ‘geometry’ of spacetime – which would give us information about the Kerr solution to the phenomenon. The latter assumes a rotating black hole, whereas other solutions, like that of Schwarzschild, describe a non-rotating black hole.&lt;/p&gt;
    &lt;p&gt;Also intriguing is Bambi’s notion of testing fundamental constants. Does atomic physics change in gravitational fields this strong? There have been some papers exploring possible variations in fundamental constants over time, but little by way of observation studying gravitational fields much stronger than white dwarf surfaces. Two nanocraft in the vicinity of a black hole may offer a way to emit photons whose energies can probe the nature of the fine structure constant. The latter sets the interactions between elementary charged particles.&lt;/p&gt;
    &lt;p&gt;For that matter, is a black hole inevitably possessed of an event horizon, or is it best described as an ‘horizonless compact object’ (Bambi’s term)?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the presence of an event horizon, the signal from nanocraft B should be more and more redshifted (formally without disappearing, as an observer should never see a test-particle crossing the event horizon in a finite time, but, in practice, at some point the signal leaves the sensitivity band of the receiver on nanocraft A). If the compact object is a Kerr black hole, we can make clear predictions on the temporal evolution of the signal emitted by nanocraft B. If the compact object is a fuzzball [a bound state without event horizon], the temporal evolution of the signal should be different and presumably stop instantly when nanocraft B is converted into fuzzball degrees of freedom.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There are so many things to learn about black holes that it is difficult to know where to begin, and I suspect that if many of our space probes have returned surprising results (think of the remarkable ‘heart’ on Pluto), a mission to a black hole would uncover mysteries and pose questions we have yet to ask. What an intriguing idea, and to my knowledge, no one else has made the point that if we ever reach the level of launching a mission to Proxima Centauri, we should be capable of engineering the same sort of flyby of a nearby black hole.&lt;/p&gt;
    &lt;p&gt;And on the matter of small black holes, be aware of a just released paper examining the role of dark matter in their formation. This one considers black holes on a much smaller scale, possibly making the chances of finding a nearby one that much greater. Let me quote the abstract (the italics are mine). The citation is below:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Exoplanets, with their large volumes and low temperatures, are ideal celestial detectors for probing dark matter (DM) interactions. DM particles can lose energy through scattering with the planetary interior and become gravitationally captured if their interaction with the visible sector is sufficiently strong. In the absence of annihilation, the captured DM thermalizes and accumulates at the planet’s center, eventually collapsing into black holes (BHs). Using gaseous exoplanets as an example, we demonstrate that BH formation can occur within an observable timescale for superheavy DM with masses greater than 106 GeV and nuclear scattering cross sections. The BHs may either accrete the planetary medium or evaporate via Hawking radiation, depending on the mass of the DM that formed them. We explore the possibility of periodic BH formation within the unconstrained DM parameter space and discuss potential detection methods, including observations of planetary-mass objects, pulsed high-energy cosmic rays, and variations in exoplanet temperatures. Our findings suggest that future extensive exoplanet observations could provide complementary opportunities to terrestrial and cosmological searches for superheavy DM.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The paper is Bambi, “An interstellar mission to test astrophysical black holes,” iScience Volume 28, Issue 8113142 (August 15, 2025). Full text. The paper on black holes and dark matter is Phoroutan-Mehr &amp;amp; Fetherolf, “Probing superheavy dark matter with exoplanets,” Physical Review D Vol. 112 (20 August 2025), 036012 (full text).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.centauri-dreams.org/2025/10/23/interstellar-mission-to-a-black-hole/"/><published>2025-10-24T09:17:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45692984</id><title>Twake Drive – An open-source alternative to Google Drive</title><updated>2025-10-24T15:11:09.031221+00:00</updated><content>&lt;doc fingerprint="cb16d4485c6376c3"&gt;
  &lt;main&gt;
    &lt;p&gt; The open-source alternative to Google Drive. &lt;lb/&gt; Learn more » &lt;lb/&gt; Telegram | Website | Issues | Roadmap &lt;/p&gt;
    &lt;p&gt;To get a local copy up and running, please follow these simple steps.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone the repo &lt;quote&gt;git clone https://github.com/linagora/twake-drive&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Run it with Docker &lt;code&gt;cd tdrive docker compose -f docker-compose.minimal.yml up&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Open http://localhost/ in a browser&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js (Version: &amp;gt;=18.x)&lt;/item&gt;
      &lt;item&gt;MongoDB&lt;/item&gt;
      &lt;item&gt;Yarn (recommended)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Launch MongoDB using&lt;/p&gt;
        &lt;quote&gt;docker run -p 27017:27017 -d mongo&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Launch frontend with&lt;/p&gt;
        &lt;quote&gt;cd tdrive/frontend/; yarn dev:start&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Launch backend with&lt;/p&gt;&lt;quote&gt;cd tdrive/backend/node/; SEARCH_DRIVER=mongodb DB_DRIVER=mongodb PUBSUB_TYPE=local \ DB_MONGO_URI=mongodb://localhost:27017 STORAGE_LOCAL_PATH=/[full-path-to-store-documents]/documents \ NODE_ENV=development yarn dev&lt;/quote&gt;&lt;p&gt;If you need more parameters, create/edit&lt;/p&gt;&lt;code&gt;tdrive/backend/node/config/development.json&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The app will be running on port 3000&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Twake Drive is licensed under Affero GPL v3&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/linagora/twake-drive"/><published>2025-10-24T10:16:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45693325</id><title>Mesh2Motion – Open-source web application to animate 3D models</title><updated>2025-10-24T15:11:08.858336+00:00</updated><content>&lt;doc fingerprint="a9753601cfb2d489"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;ð¥³ Human &amp;amp; Animal rigs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports importing GLB, GLTF, and FBX models&lt;/item&gt;
      &lt;item&gt;Human and animal skeleton options&lt;/item&gt;
      &lt;item&gt;Intuitive skeleton positioning&lt;/item&gt;
      &lt;item&gt;Undo/Redo system when you make mistakes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;âï¸ Export Animations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Export multiple animations at once&lt;/item&gt;
      &lt;item&gt;Uses widely-supported GLB format&lt;/item&gt;
      &lt;item&gt;Human animation library from Quaternius&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Video Walkthrough&lt;/head&gt;
    &lt;head rend="h2"&gt;FREE &amp;amp; Open-Source&lt;/head&gt;
    &lt;p&gt;Mesh2Motion is an open-source project. With the way 3d animations and modeling tools are progressing, there just needs to be some tool like this that is open-source that can evolve. The goal of this project is to provide a free and easy way to animate 3D models for web and game engines. Everything should be freely available for both personal and commercial projects. Check out the GitHub repository for all the code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;The best place for bug reports and feedback is on the GitHub page. If you don't have GitHub, you could also try my socials:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;github.com/scottpetrovic/mesh2motion-app&lt;/item&gt;
      &lt;item&gt;@scottpetrovic&lt;/item&gt;
      &lt;item&gt;@scottpetrovic.bsky.social&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mesh2motion.org/"/><published>2025-10-24T11:01:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45693591</id><title>ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference</title><updated>2025-10-24T15:11:08.639234+00:00</updated><content>&lt;doc fingerprint="8d9c1c23d1f186ae"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 28 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Transformer-based large models excel in natural language processing and computer vision, but face severe computational inefficiencies due to the self-attention's quadratic complexity with input tokens. Recently, researchers have proposed a series of methods based on block selection and compression to alleviate this problem, but they either have issues with semantic incompleteness or poor training-inference efficiency. To comprehensively address these challenges, we propose ChunkLLM, a lightweight and pluggable training framework. Specifically, we introduce two components: QK Adapter (Q-Adapter and K-Adapter) and Chunk Adapter. The former is attached to each Transformer layer, serving dual purposes of feature compression and chunk attention acquisition. The latter operates at the bottommost layer of the model, functioning to detect chunk boundaries by leveraging contextual semantic information. During the training phase, the parameters of the backbone remain frozen, with only the QK Adapter and Chunk Adapter undergoing training. Notably, we design an attention distillation method for training the QK Adapter, which enhances the recall rate of key chunks. During the inference phase, chunk selection is triggered exclusively when the current token is detected as a chunk boundary, thereby accelerating model inference. Experimental evaluations are conducted on a diverse set of long-text and short-text benchmark datasets spanning multiple tasks. ChunkLLM not only attains comparable performance on short-text benchmarks but also maintains 98.64% of the performance on long-context benchmarks while preserving a 48.58% key-value cache retention rate. Particularly, ChunkLLM attains a maximum speedup of 4.48x in comparison to the vanilla Transformer in the processing of 120K long texts.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.02361"/><published>2025-10-24T11:41:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45693599</id><title>Poker fraud used X-ray tables, high-tech glasses and NBA players</title><updated>2025-10-24T15:11:08.320799+00:00</updated><content>&lt;doc fingerprint="7cc1817ecd478309"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'Mind-boggling' poker fraud used X-ray tables, high-tech glasses and NBA players&lt;/head&gt;
    &lt;p&gt;Celebrities, professional sports stars and wealthy gamblers sat at a table hoping to win big in a game of Texas Hold 'Em.&lt;/p&gt;
    &lt;p&gt;But they didn't know it was nearly impossible. They were "fishes" allegedly being targeted by the mafia in an elaborate poker gambling scheme that included X-ray card tables, secret cameras, analysers in chip trays and sunglasses and contact lenses that could read their hand.&lt;/p&gt;
    &lt;p&gt;In what sounds like an Ocean's Eleven film plot, prosecutors say these "unwitting" victims were cheated out of at least $7m (£5.25m) in poker games - with one person losing at least $1.8m.&lt;/p&gt;
    &lt;p&gt;The scheme, which US prosecutors described as "reminiscent of a Hollywood movie", was dismantled in a sprawling federal investigation that led to more than 30 arrests, including members of La Cosa Nostra crime families, Portland Trail Blazers basketball coach Chauncey Billups and former National Basketball Association (NBA) player Damon Jones.&lt;/p&gt;
    &lt;p&gt;FBI director Kash Patel called it a "mind-boggling" fraud scheme that cheated victims in New York, Miami, Las Vegas and other US cities.&lt;/p&gt;
    &lt;p&gt;Arrests in the scheme were announced on Thursday along with those in an alleged basketball betting plot, in which professional NBA players are accused of faking injuries to influence betting odds.&lt;/p&gt;
    &lt;p&gt;The underground poker scheme started as early as 2019, prosecutors say, and was allegedly operated by the mafia - specifically by members of notorious crime families, including Bonnano, Gambino, Lucchese and Genovese. A cut of the profits, prosecutors say, helped fund their criminal enterprise.&lt;/p&gt;
    &lt;p&gt;Former professional athletes, described by prosecutors as "face cards", were enlisted to help in the scheme and entice victims into playing.&lt;/p&gt;
    &lt;p&gt;Lured in by the opportunity to play with a high-profile celebrity - such as Billups or Jones - a wealthy, "unwitting victim" would be recruited for illegal, underground poker games where tens of thousands of dollars were on the line, prosecutors allege.&lt;/p&gt;
    &lt;p&gt;Unbeknownst to the lured-in players - referred to in the scheme as a "fish" - everyone surrounding them was in on the elaborate scam - from the players to the dealers, even the technology used to shuffle the deck and count the chips, according to a lengthy federal indictment.&lt;/p&gt;
    &lt;p&gt;Sophisticated wireless technology was also used to deceive the players during the games, most commonly in Texas Hold 'Em.&lt;/p&gt;
    &lt;p&gt;The technology was everywhere - an X-ray table that read any face-down card, analysers inside chip trays, a rigged shuffling machine that read cards and predicted who would have the best hand, and pre-marked cards that allowed those wearing special sunglasses and contact lenses to read what was in everyone's hands.&lt;/p&gt;
    &lt;p&gt;Secretive cameras - built into tables and light fixtures - also helped convey information to those helping in the plot, authorities say.&lt;/p&gt;
    &lt;p&gt;Then there was also a sophisticated method of communicating and rigging the game, prosecutors allege.&lt;/p&gt;
    &lt;p&gt;Information from the game would be sent to an off-site conspirator - called an "operator" by prosecutors - who then would send information to another player sitting at the table who was in on the scheme - who prosecutors call a "quarterback" or "driver".&lt;/p&gt;
    &lt;p&gt;That person would then secretly signal to others, prosecutors allege, effectively stealing money and making it impossible for victims to win.&lt;/p&gt;
    &lt;p&gt;Texts from the US justice department's evidence suggest the "quarterback" would either touch the $1,000 poker chip, tap his chin, wrist or arm to signal which conspirator had the best hand.&lt;/p&gt;
    &lt;p&gt;If the victim had the best hand, the "quarterback" would touch his black chips.&lt;/p&gt;
    &lt;p&gt;The texts also appear to show that at times conspirators agreed to lose some hands in order to keep victims at the gambling table for longer.&lt;/p&gt;
    &lt;p&gt;Another series of texts suggests participants in the scheme avoided suspicion of cheating by swapping in players and losing money to co-conspirators.&lt;/p&gt;
    &lt;p&gt;Authorities estimate that each game would leave a victim out of tens or hundreds of thousands of dollars.&lt;/p&gt;
    &lt;p&gt;Prosecutors say the defendants allegedly laundered the funds from the scheme through cryptocurrency, cash exchanges and shell companies.&lt;/p&gt;
    &lt;p&gt;A cut of the profits went to those who helped in the plot, prosecutors say, and some allegedly went to fund the mafia's criminal enterprise.&lt;/p&gt;
    &lt;p&gt;"This alleged scheme wreaked havoc across the nation, exploiting the notoriety of some and the wallets of others to finance the Italian crime families," said FBI Assistant Director in Charge Christopher Raia.&lt;/p&gt;
    &lt;p&gt;Billups, who was accused of being a face card in the fixed card games, was arrested in Portland and was placed on leave by the NBA. The Portland Trail Blazers said in a statement that they were aware of the allegations involving their head coach and were "fully co-operating with the investigation".&lt;/p&gt;
    &lt;p&gt;Jones was arrested in relation to both the poker and NBA injuries scheme. He is charged with two counts each of wire fraud conspiracy and money laundering conspiracy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/cz6nd9wnzn6o"/><published>2025-10-24T11:42:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45693743</id><title>Padlet (YC W13) Is Hiring in San Francisco and Singapore</title><updated>2025-10-24T15:11:07.596525+00:00</updated><content>&lt;doc fingerprint="28684c070fcc5eec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;LET'S GET TO WORK&lt;/head&gt;
    &lt;p&gt;Your morning cup of coffee.&lt;lb/&gt;The song you'll play at your wedding.&lt;lb/&gt;Football, either one.&lt;lb/&gt;The camera that recorded your first steps.&lt;lb/&gt;Air conditioning in the living room, hot water in the bathroom.&lt;lb/&gt;Your every comfort, every joy, every memory.&lt;lb/&gt;You have them because of someone's work,&lt;lb/&gt;because of a world at work,&lt;lb/&gt;because of generations that worked before us.&lt;lb/&gt;Making.&lt;lb/&gt;Saving.&lt;lb/&gt;Breaking.&lt;lb/&gt;Moving.&lt;lb/&gt;Wrestling inboxes that never tap out.&lt;lb/&gt;Five minutes to finish a ziplocked ham sandwich.&lt;lb/&gt;Trying to find parking. Always trying to find parking.&lt;lb/&gt;Knots in the gut before the lights turn on.&lt;lb/&gt;Blisters on fingers where the pencil meets the skin.&lt;lb/&gt;Snowfall or heatwave.&lt;lb/&gt;Stardust to sunrise.&lt;lb/&gt;They showed up for us.&lt;lb/&gt;Let's show up for them.&lt;lb/&gt;Let's move.&lt;lb/&gt;Let's break.&lt;lb/&gt;Let's save.&lt;lb/&gt;Let's make.&lt;lb/&gt;Let's get to work.&lt;/p&gt;
    &lt;p&gt;The song you'll play at your wedding.&lt;/p&gt;
    &lt;p&gt;Football, either one.&lt;/p&gt;
    &lt;p&gt;The camera that recorded your first steps.&lt;/p&gt;
    &lt;p&gt;Air conditioning in the living room, hot water in the bathroom.&lt;/p&gt;
    &lt;p&gt;Your every comfort, every joy, every memory.&lt;/p&gt;
    &lt;p&gt;You have them because of someone's work,&lt;/p&gt;
    &lt;p&gt;because of a world at work,&lt;/p&gt;
    &lt;p&gt;because of generations that worked before us.&lt;/p&gt;
    &lt;p&gt;Making.&lt;/p&gt;
    &lt;p&gt;Saving.&lt;/p&gt;
    &lt;p&gt;Breaking.&lt;/p&gt;
    &lt;p&gt;Moving.&lt;/p&gt;
    &lt;p&gt;Wrestling inboxes that never tap out.&lt;/p&gt;
    &lt;p&gt;Five minutes to finish a ziplocked ham sandwich.&lt;/p&gt;
    &lt;p&gt;Trying to find parking. Always trying to find parking.&lt;/p&gt;
    &lt;p&gt;Knots in the gut before the lights turn on.&lt;/p&gt;
    &lt;p&gt;Blisters on fingers where the pencil meets the skin.&lt;/p&gt;
    &lt;p&gt;Snowfall or heatwave.&lt;/p&gt;
    &lt;p&gt;Stardust to sunrise.&lt;/p&gt;
    &lt;p&gt;They showed up for us.&lt;/p&gt;
    &lt;p&gt;Let's show up for them.&lt;/p&gt;
    &lt;p&gt;Let's move.&lt;/p&gt;
    &lt;p&gt;Let's break.&lt;/p&gt;
    &lt;p&gt;Let's save.&lt;/p&gt;
    &lt;p&gt;Let's make.&lt;/p&gt;
    &lt;p&gt;Let's get to work.&lt;/p&gt;
    &lt;p&gt;Nitesh&lt;/p&gt;
    &lt;p&gt;Founder and CEO&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://padlet.jobs"/><published>2025-10-24T12:01:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45693904</id><title>Show HN: A fast, privacy-first image converter that runs in browser</title><updated>2025-10-24T15:11:07.362072+00:00</updated><content>&lt;doc fingerprint="1d3445719171ada6"&gt;
  &lt;main&gt;
    &lt;p&gt;PNG -&amp;gt; JPG converter&lt;/p&gt;
    &lt;head rend="h1"&gt;Convert PNG to JPG in seconds&lt;/head&gt;
    &lt;p&gt;Upload a PNG image and instantly download a high-quality JPG. Everything stays in your browser — no uploads, no limits.&lt;/p&gt;
    &lt;p&gt;100% free image converter&lt;/p&gt;
    &lt;p&gt;Lightning-fast&lt;/p&gt;
    &lt;p&gt;Explore other image converters&lt;/p&gt;
    &lt;head rend="h2"&gt;How to convert PNG to JPG in your browser&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Upload your image&lt;/head&gt;
    &lt;p&gt;Drop or select a PNG file from your device. The file never leaves your browser.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. We convert it instantly&lt;/head&gt;
    &lt;p&gt;The converter renders your image as JPG locally, keeping quality and dimensions intact.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Download the JPG file&lt;/head&gt;
    &lt;p&gt;Save the converted JPG with one click or choose another format.&lt;/p&gt;
    &lt;head rend="h2"&gt;Image converter FAQ&lt;/head&gt;
    &lt;p&gt;Everything you need to know about switching image formats in your browser&lt;/p&gt;
    &lt;head class="flex cursor-pointer items-center justify-between px-6 py-4 text-left hover:bg-muted/50 transition-colors list-none"&gt;Is the image converter free to use?&lt;/head&gt;
    &lt;p&gt;Yes—every converter on imageconverter.dev is free, unlimited, and watermark-free. Convert as many files as you want without creating an account.&lt;/p&gt;
    &lt;head class="flex cursor-pointer items-center justify-between px-6 py-4 text-left hover:bg-muted/50 transition-colors list-none"&gt;Do my images ever upload to a server?&lt;/head&gt;
    &lt;p&gt;No. All conversions happen entirely in your browser using Web APIs. After the page loads you can even go offline and the converter will keep working.&lt;/p&gt;
    &lt;head class="flex cursor-pointer items-center justify-between px-6 py-4 text-left hover:bg-muted/50 transition-colors list-none"&gt;Will the converter reduce image quality?&lt;/head&gt;
    &lt;p&gt;We preserve the image resolution and apply gentle compression only when the target format requires it. Transparent backgrounds are automatically flattened to white when exporting to JPG.&lt;/p&gt;
    &lt;head class="flex cursor-pointer items-center justify-between px-6 py-4 text-left hover:bg-muted/50 transition-colors list-none"&gt;Can I convert multiple images at once?&lt;/head&gt;
    &lt;p&gt;Right now this tool handles one file at a time so you can review the output before downloading. Need bulk conversions? Try our bulk resize tool with format switching support.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://imageconverter.dev/"/><published>2025-10-24T12:21:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45693978</id><title>Typst 0.14</title><updated>2025-10-24T15:11:06.391205+00:00</updated><content>&lt;doc fingerprint="7e9e51106fe534cc"&gt;
  &lt;main&gt;
    &lt;p&gt;Typst 0.14 is out now. With accessibility by default, PDFs as images, character-level justification, and more, it has everything you need to move from draft to production.&lt;/p&gt;
    &lt;p&gt;Typst's origins lie in academia, but over the past year, we've seen it expand to so much more. It's increasingly being used in the industry: For manually written documents, partially automated reports, and in fully automated batch PDF generation pipelines. Across these use cases, it's being used in production for critical documents.&lt;/p&gt;
    &lt;p&gt;In August, we launched a new website to reflect Typst's expanding scope, and now, with Typst 0.14, we're shipping crucial features that make Typst even more widely applicable.&lt;/p&gt;
    &lt;p&gt;If you need to comply with accessibility-related regulations, Typst 0.14 has your back. Typst now generates accessible documents by default, with opt-in support for stricter checks. For those working with complex illustrations, PDFs are now supported as a native image format. In case you're typesetting a book, the new character-level justification will give your layout the final touch. And if you're building a website or blog, many improvements to Typst's HTML export are waiting for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;p&gt;In this blog post, we'll take a closer look at the highlights of this release:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Accessibility&lt;/item&gt;
      &lt;item&gt;PDF standards&lt;/item&gt;
      &lt;item&gt;PDFs as images&lt;/item&gt;
      &lt;item&gt;Character-level justification&lt;/item&gt;
      &lt;item&gt;Richer HTML export&lt;/item&gt;
      &lt;item&gt;Migrating to Typst 0.14&lt;/item&gt;
      &lt;item&gt;Community Call&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To get started with Typst 0.14…&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;…in the web app: Just open any of your projects! You'll get a prompt offering you to upgrade to the latest version.&lt;/item&gt;
      &lt;item&gt;…in the command line: Run &lt;code&gt;typst update&lt;/code&gt;in your terminal or, if you haven't installed Typst previously, download the latest version of the CLI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a comprehensive overview of all changes in the release, visit the changelog. If you're looking to upgrade your document to Typst 0.14, you can also skip ahead to the Migration section.&lt;/p&gt;
    &lt;head rend="h2"&gt;Accessibility&lt;/head&gt;
    &lt;p&gt;Not everyone reads PDF documents the same. Some people read on large screens or print; others use small phones or screen readers to have documents read aloud. To cater to all these uses, a file must contain tags that allow Assistive Technology (AT) like screen readers to learn about the reading order and semantic meaning of each piece of text. Tags allow AT users to learn which text is &lt;code&gt;*strongly emphasized*&lt;/code&gt;, enable navigation of the document by skipping between headings, and more.&lt;/p&gt;
    &lt;p&gt;Tagging requires no additional work from you: If you are using the built-in markup and elements, Typst will automatically select the right tags! Unlike many other tools, PDF files created with Typst 0.14 are tagged by default, raising the bar for accessibility.&lt;/p&gt;
    &lt;p&gt;But tags are not enough to make a file accessible: To reach everyone, you need to design for universal accessibility from the start. The new features in Typst 0.14 can help you with that. Consider diagrams created with shapes or packages like cetz—their visual meaning is invisible to assistive technology. The new &lt;code&gt;alt&lt;/code&gt; parameter on figures solves this:&lt;/p&gt;
    &lt;code&gt;#figure(
  stack(
    dir: ltr,
    spacing: 0.5em,
    rect[Tagged PDF],
    text(2em, sym.arrow.long),
    rect[Accessibility],
  ),
  alt: "Diagram with two rectangles. The first is labelled 'Tagged PDF'. An arrow points to the second, labelled 'Accessibility'",
  caption: [
    Tags enable PDF accessibility
  ],
)
&lt;/code&gt;
    &lt;p&gt;With this change, AT users hear the alternative description and can grasp the figure's purpose just like sighted users—no information is lost. We have put together a new Accessibility Guide that contains more tips on how to create accessible documents, including how to write good alternative descriptions, when to use the figure's vs. the image's &lt;code&gt;alt&lt;/code&gt; parameter, and more.&lt;/p&gt;
    &lt;p&gt;To make sure you got everything right, you can enable the new PDF/UA-1 export. PDF/UA is an international standard that helps to create universally accessible PDF files. When it is enabled, Typst will run additional checks against your document to find accessibility issues and optimize for accessibility rather than compatibility. It will find issues such as missing document titles, wrong heading hierarchies, and missing alternative descriptions.&lt;/p&gt;
    &lt;p&gt;PDF/UA-1 helps you comply with existing and upcoming international accessibility regulation like the European Accessibility Act (EAA) in the EU and the new Americans with Disabilities Act's (ADA) Title II guidance by the DOJ. The former applies to many businesses active in the European Union since 28 June 2025 while the deadline for the latter is set for April 24, 2026. If you are using Typst in your business for customer- or government-facing documents, you should adopt Typst 0.14 as soon as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;PDF standards&lt;/head&gt;
    &lt;p&gt;Alongside PDF/UA-1 support, we've also generally expanded Typst's support for PDF standards. Instead of just PDF 1.7, you can now choose between the PDF versions 1.4, 1.5, 1.6, 1.7, and 2.0. And for PDF/A, we've expanded support from just two specific substandards to all four parts with all their conformance levels. While Typst's defaults are perfectly fine for most use cases, choosing a standard can optimize your document specifically for your use case. Consult the expanded PDF documentation in the reference for guidance on which standards you should pick under which circumstances.&lt;/p&gt;
    &lt;head rend="h2"&gt;PDFs as images&lt;/head&gt;
    &lt;p&gt;Staying with the PDF theme, there are exciting news for authors that have a lot of complex illustrations. Typst now supports PDF as a native image format. What I personally find most exciting about it, is that PDF images are supported across all export targets, and for each export target in the most suitable format. In PDF export, PDFs are naturally directly embedded. Meanwhile, in HTML and SVG export, PDFs are converted to an embedded SVG on-the-fly. And, finally, in PNG export and the web app preview, PDFs are rasterized. All of this PDF processing functionality lives right in the Typst compiler, with no system dependencies. This is only possible thanks to the amazing work of community member @LaurenzV, who created a new PDF processing library called &lt;code&gt;hayro&lt;/code&gt; from scratch. The library is 100% written in the programming language Rust (which is also the language we use for the Typst compiler) and is thus highly portable.&lt;/p&gt;
    &lt;code&gt;#figure(
  image(
    "throwing-success.pdf",
    alt: "A diagram titled 'Throwing Success' that .."
  ),
  caption: [
    Effect of normalized thrust
    on X and Y position of
    thrown emojis
  ],
)
&lt;/code&gt;
    &lt;head rend="h2"&gt;Character-level justification&lt;/head&gt;
    &lt;p&gt;Producing a visually balanced paragraph was once a fine art, when professional typesetters still carefully set paragraphs with movable type. Nowadays, you could hope that optimal paragraph typesetting is a solved problem across all our software. But, alas, it is not!&lt;/p&gt;
    &lt;p&gt;There are different strategies we can employ to produce a well-justified paragraph. Of course, to justify the paragraph, we need to stretch each line to the width of the measure. There are different ways to do this: Most obviously, we can adjust the spacing between words. This is what most software does. But we can also adjust the spacing between characters. This is now implemented in Typst.&lt;/p&gt;
    &lt;p&gt;Other methods to do this (which we want to explore in the future) include stretching the width of characters (this is best done with variable fonts) or, for some scripts, inserting special textual elements. For example, in Arabic, there are Kashida, which allow spacing out glyphs in words by extending the connectors between individual glyphs.&lt;/p&gt;
    &lt;p&gt;But that's just part of the recipe. Arguably, the even more crucial part is how this interplays with which linebreaks we chose to insert. Naively, we can choose our break points based on how much text fits and then perform the stretching. But we can do much better by taking into account each line's potential for stretching with the various mechanisms discussed above! We can then choose the break points that minimize the amount of bad-looking stretching.&lt;/p&gt;
    &lt;p&gt;I was initially skeptical about supporting character-level justification because I've seen it done poorly in some books. But that's actually not the fault of character-level justification per se; it's just excessive use of it. Tastefully chosen maxima—together with an algorithm that minimizes displeasing typography—make it bring out the best in justification.&lt;/p&gt;
    &lt;p&gt;We hear a lot about microtypography when people compare Typst with LaTeX. And even though Typst uses the same fundamental algorithm as LaTeX does to optimize paragraphs, it's true that LaTeX has some extra tricks up its sleeve. Now we do too though, as character-level justification is a feature that LaTeX does not support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Richer HTML Export&lt;/head&gt;
    &lt;p&gt;In Typst 0.13, we shipped a first, highly experimental version of HTML export. This very minimal version already introduced the primitives for flexible HTML generation. With these primitives, the mapping of Typst elements to HTML can be expressed through show rules, just like the mapping to visual elements is performed in paged export.&lt;/p&gt;
    &lt;p&gt;What was lacking though were show rules for many built-in elements, including elements like footnotes, outlines, and citations. Typst 0.14 makes good progress in this regard. Most semantic elements (those from the Model category) are now properly mapped to semantic HTML. We've also improved handling of textual content in HTML export. The more visualization- and styling-focused parts of Typst's standard library remain largely unsupported, but we plan to add support for those (to the extent possible) in the future.&lt;/p&gt;
    &lt;p&gt;Below, you can see an example of a small, but non-trivial Typst document exported to HTML with Typst 0.14.&lt;/p&gt;
    &lt;code&gt;#set heading(numbering: "1.")

= Introduction &amp;lt;intro&amp;gt;
In @intro, let's cite @netwok.

#bibliography("works.bib")
&lt;/code&gt;
    &lt;quote&gt;&amp;lt;!-- html, head, and body omitted for brevity --&amp;gt; &amp;lt;h2 id="intro"&amp;gt;1. Introduction&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; In &amp;lt;a href="#intro"&amp;gt;Section 1&amp;lt;/a&amp;gt;, let’s cite &amp;lt;a id="loc-1" href="#loc-2" role="doc-biblioref"&amp;gt;[1]&amp;lt;/a&amp;gt;. &amp;lt;/p&amp;gt; &amp;lt;section role="doc-bibliography"&amp;gt; &amp;lt;h2&amp;gt;Bibliography&amp;lt;/h2&amp;gt; &amp;lt;ul style="list-style-type: none"&amp;gt; &amp;lt;li id="loc-2"&amp;gt; &amp;lt;span class="prefix"&amp;gt;&amp;lt;a href="#loc-1" role="doc-backlink"&amp;gt;[1]&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt; R. Astley and L. Morris, “At-scale impact of the Net Wok: A culinarically holistic investigation of distributed dumplings,” &amp;lt;em&amp;gt;Armenian Journal of Proceedings&amp;lt;/em&amp;gt;, vol. 61, pp. 192–219, 2020. &amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/section&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Another exciting addition to HTML export is the new typed HTML interface. Typst's &lt;code&gt;html&lt;/code&gt; module now includes functions for constructing HTML elements with strongly-typed attributes. This means you can now write&lt;/p&gt;
    &lt;code&gt;#html.video(
  autoplay: true,
  width: 1280,
  height: 720,
  src: "sunrise.mp4",
)
&lt;/code&gt;
    &lt;p&gt;instead of&lt;/p&gt;
    &lt;code&gt;#html.elem("video", attrs: (
  autoplay: "",
  width: "1280",
  height: "720",
  src: "sunrise.mp4",
))
&lt;/code&gt;
    &lt;p&gt;As you can see, attributes are mapped to idiomatic Typst-native types.&lt;/p&gt;
    &lt;p&gt;Last but not least, we're happy to announce that HTML export will soon come to the Typst web app. We're still polishing up the implementation, but plan to ship it in the coming weeks.&lt;/p&gt;
    &lt;p&gt;Please note that HTML export remains experimental. To enable it in the CLI, pass &lt;code&gt;--features html&lt;/code&gt; or set &lt;code&gt;TYPST_FEATURES=html&lt;/code&gt;. In the web app, support for HTML export will also need to be enabled on a per-project basis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Migrating to Typst 0.14&lt;/head&gt;
    &lt;p&gt;As far as breaking changes and deprecations go, this is a pretty calm release. Most documents should continue to work as before. There are a few minor breaking changes that make certain validations more strict. For instance, labels, link URLs, and font lists may not be empty anymore. To learn about all breaking changes, consult the changelog and search for "breaking change".&lt;/p&gt;
    &lt;p&gt;The release also contains a few deprecations. In particular, you'll need to replace any use of &lt;code&gt;pdf.embed&lt;/code&gt; with &lt;code&gt;pdf.attach&lt;/code&gt;. Moreover, two bibliography styles were renamed and the &lt;code&gt;--make-deps&lt;/code&gt; CLI flag was deprecated in favor of the new, more flexible &lt;code&gt;--deps&lt;/code&gt; flag with &lt;code&gt;--deps-format make&lt;/code&gt;. There are also a few deprecated symbols. The compiler will warn you about all use of deprecated functionality.&lt;/p&gt;
    &lt;head rend="h3"&gt;In the web app&lt;/head&gt;
    &lt;p&gt;With this release, we're also bringing a better version upgrade experience to the web app. Previously, projects would always use the latest compiler version unless explicitly pinned to a specific version in the settings side panel.&lt;/p&gt;
    &lt;p&gt;We are now phasing out the "Latest" option. Instead, the web app detects when a new version is available since you've last edited a project, and offers you to upgrade. The upgrade assistant includes an automatic compatibility check that compiles your document with both versions, makes a verdict, and lists new errors and warnings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Community Call&lt;/head&gt;
    &lt;p&gt;Typst 0.14 is the result of 8 months of hard work by us and the community. We hope you are as excited about it as we are!&lt;/p&gt;
    &lt;p&gt;Speaking of the community—We're hosting a community call on Discord on Friday, November 7th. Join us to share your experiences with the new version and to chat with the community!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://typst.app/blog/2025/typst-0.14/"/><published>2025-10-24T12:33:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45694111</id><title>Traffic Light Protocol</title><updated>2025-10-24T15:11:06.254087+00:00</updated><content>&lt;doc fingerprint="e6926b83d677835f"&gt;
  &lt;main&gt;
    &lt;p&gt;TLP version 2.0 is the current version of TLP standardized by FIRST. It is authoritative from August 2022 onwards&lt;/p&gt;
    &lt;p&gt;a. The Traffic Light Protocol (TLP) was created to facilitate greater sharing of potentially sensitive information and more effective collaboration. Information sharing happens from an information source, towards one or more recipients. TLP is a set of four labels used to indicate the sharing boundaries to be applied by the recipients. Only labels listed in this standard are considered valid by FIRST.&lt;/p&gt;
    &lt;p&gt;b. The four TLP labels are: TLP:RED, TLP:AMBER, TLP:GREEN, and TLP:CLEAR. In written form, they MUST not contain spaces and SHOULD be in capitals. TLP labels MUST remain in their original form, even when used in other languages: content can be translated, but the labels cannot.&lt;/p&gt;
    &lt;p&gt;c. TLP provides a simple and intuitive schema for indicating with whom potentially sensitive information can be shared. TLP is not a formal classification scheme. TLP was not designed to handle licensing terms, nor information handling or encryption rules. TLP labels and their definitions are not intended to have any effect on freedom of information or “sunshine” laws in any jurisdiction.&lt;/p&gt;
    &lt;p&gt;d. TLP is optimized for ease of adoption, human readability and person-to-person sharing; it may be used in automated information exchange systems, such as MISP or IEP.&lt;/p&gt;
    &lt;p&gt;e. TLP is distinct from the Chatham House Rule, but may be used in conjunction when appropriate. When a meeting is held under the Chatham House Rule, participants are free to use the information received, but neither the identity nor the affiliation of the speaker(s), nor that of any other participant, may be revealed.&lt;/p&gt;
    &lt;p&gt;f. The source is responsible for ensuring that recipients of TLP-labeled information understand and can follow TLP sharing guidance.&lt;/p&gt;
    &lt;p&gt;g. The source is at liberty to specify additional sharing restrictions. These must be adhered to by recipients.&lt;/p&gt;
    &lt;p&gt;h. If a recipient needs to share information more widely than indicated by the TLP label it came with, they must obtain explicit permission from the source.&lt;/p&gt;
    &lt;p&gt;a. How to use TLP in messaging (such as email and chat)&lt;lb/&gt; TLP-labeled messaging MUST indicate the TLP label of the information, as well as any additional restrictions, directly prior to the information itself. The TLP label SHOULD be in the subject line of email. Where needed, also make sure to designate the end of the text to which the TLP label applies.&lt;/p&gt;
    &lt;p&gt;b. How to use TLP in documents TLP-labeled documents MUST indicate the TLP label of the information, as well as any additional restrictions, in the header and footer of each page. The TLP label SHOULD be in 12-point type or greater for users with low vision. It is recommended to right-justify TLP labels.&lt;/p&gt;
    &lt;p&gt;c. How to use TLP in automated information exchanges TLP usage in automated information exchanges is not defined: this is left to the designers of such exchanges, but MUST be in accordance with this standard.&lt;/p&gt;
    &lt;p&gt;d. TLP color-coding in RGB, CMYK and Hex&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="17"&gt;
        &lt;cell&gt;RGB:&lt;p&gt;font&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;RGB:&lt;p&gt;background&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;CMYK:&lt;p&gt;font&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;CMYK:&lt;p&gt;background&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Hex:&lt;p&gt;font&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Hex:&lt;p&gt;background&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="17"&gt;
        &lt;cell&gt;R&lt;/cell&gt;
        &lt;cell&gt;G&lt;/cell&gt;
        &lt;cell&gt;B&lt;/cell&gt;
        &lt;cell&gt;R&lt;/cell&gt;
        &lt;cell&gt;G&lt;/cell&gt;
        &lt;cell&gt;B&lt;/cell&gt;
        &lt;cell&gt;C&lt;/cell&gt;
        &lt;cell&gt;M&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;K&lt;/cell&gt;
        &lt;cell&gt;C&lt;/cell&gt;
        &lt;cell&gt;M&lt;/cell&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;K&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="17"&gt;
        &lt;cell&gt;TLP:RED&lt;/cell&gt;
        &lt;cell&gt;255&lt;/cell&gt;
        &lt;cell&gt;43&lt;/cell&gt;
        &lt;cell&gt;43&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;#FF2B2B&lt;/cell&gt;
        &lt;cell&gt;#000000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="17"&gt;
        &lt;cell&gt;TLP:AMBER&lt;/cell&gt;
        &lt;cell&gt;255&lt;/cell&gt;
        &lt;cell&gt;192&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;25&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;#FFC000&lt;/cell&gt;
        &lt;cell&gt;#000000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="17"&gt;
        &lt;cell&gt;TLP:GREEN&lt;/cell&gt;
        &lt;cell&gt;51&lt;/cell&gt;
        &lt;cell&gt;255&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;79&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;#33FF00&lt;/cell&gt;
        &lt;cell&gt;#000000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;TLP:CLEAR&lt;/cell&gt;
        &lt;cell&gt;255&lt;/cell&gt;
        &lt;cell&gt;255&lt;/cell&gt;
        &lt;cell&gt;255&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;#FFFFFF&lt;/cell&gt;
        &lt;cell&gt;#000000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note on color-coding: when there is too little color contrast between text and background, those with low vision struggle to read text or cannot see it at all. TLP is designed to accommodate those with low vision. Sources SHOULD adhere to the TLP color-coding to ensure enough color contrast for such readers.&lt;/p&gt;
    &lt;p&gt;Community: Under TLP, a community is a group who share common goals, practices, and informal trust relationships. A community can be as broad as all cybersecurity practitioners in a country (or in a sector or region).&lt;/p&gt;
    &lt;p&gt;Organization: Under TLP, an organization is a group who share a common affiliation by formal membership and are bound by common policies set by the organization. An organization can be as broad as all members of an information sharing organization, but rarely broader.&lt;/p&gt;
    &lt;p&gt;Clients: Under TLP, clients are those people or entities that receive cybersecurity services from an organization. Clients are by default included in TLP:AMBER so that the recipients may share information further downstream in order for clients to take action to protect themselves. For teams with national responsibility this definition includes stakeholders and constituents.&lt;/p&gt;
    &lt;p&gt;a. TLP:RED = For the eyes and ears of individual recipients only, no further disclosure. Sources may use TLP:RED when information cannot be effectively acted upon without significant risk for the privacy, reputation, or operations of the organizations involved. Recipients may therefore not share TLP:RED information with anyone else. In the context of a meeting, for example, TLP:RED information is limited to those present at the meeting.&lt;/p&gt;
    &lt;p&gt;b. TLP:AMBER = Limited disclosure, recipients can only spread this on a need-to-know basis within their organization and its clients. Note that TLP:AMBER+STRICT restricts sharing to the organization only. Sources may use TLP:AMBER when information requires support to be effectively acted upon, yet carries risk to privacy, reputation, or operations if shared outside of the organizations involved. Recipients may share TLP:AMBER information with members of their own organization and its clients, but only on a need-to-know basis to protect their organization and its clients and prevent further harm. Note: if the source wants to restrict sharing to the organization only, they must specify TLP:AMBER+STRICT.&lt;/p&gt;
    &lt;p&gt;c. TLP:GREEN = Limited disclosure, recipients can spread this within their community. Sources may use TLP:GREEN when information is useful to increase awareness within their wider community. Recipients may share TLP:GREEN information with peers and partner organizations within their community, but not via publicly accessible channels. TLP:GREEN information may not be shared outside of the community. Note: when “community” is not defined, assume the cybersecurity/defense community.&lt;/p&gt;
    &lt;p&gt;d. TLP:CLEAR = Recipients can spread this to the world, there is no limit on disclosure. Sources may use TLP:CLEAR when information carries minimal or no foreseeable risk of misuse, in accordance with applicable rules and procedures for public release. Subject to standard copyright rules, TLP:CLEAR information may be shared without restriction.&lt;/p&gt;
    &lt;p&gt;Notes:&lt;lb/&gt; 1. This document uses MUST and SHOULD as defined by RFC-2119.&lt;lb/&gt; 2. Comments or suggestions on this document can be sent to tlp-sig@first.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.first.org/tlp/"/><published>2025-10-24T12:52:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45694122</id><title>A sharded DuckDB on 63 nodes runs 1T row aggregation challenge in 5 sec</title><updated>2025-10-24T15:11:05.903606+00:00</updated><link href="https://gizmodata.com/blog/gizmoedge-one-trillion-row-challenge"/><published>2025-10-24T12:54:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45694272</id><title>Show HN: I built an 8-bit CPU simulator in Python from scratch</title><updated>2025-10-24T15:11:05.342096+00:00</updated><content>&lt;doc fingerprint="8691b351f053d6d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Tiny8 is a lightweight toolkit that allows you to explore how computers work at their core through small-scale memory models, handcrafted assembly, and lightweight in-memory data structures. Designed for rapid experimentation, Tiny8 embraces minimalism with zero unnecessary dependencies, a clean design, and intuitive visualization tools that make learning, debugging, and tinkering enjoyable.&lt;/p&gt;
    &lt;p&gt;Why Tiny8?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lightweight: tiny install footprint and no heavy runtime dependencies.&lt;/item&gt;
      &lt;item&gt;Educational: clear primitives and examples that demonstrate CPU concepts, memory layout, and algorithms.&lt;/item&gt;
      &lt;item&gt;Fast feedback loop: assemble, run, and visualize within seconds to iterate on ideas.&lt;/item&gt;
      &lt;item&gt;Extensible: meant for experiments, teaching, demos, and small tools that benefit from a predictable, tiny VM.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Who should use it?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Students learning low-level programming, assembly, or computer architecture who want hands-on examples.&lt;/item&gt;
      &lt;item&gt;Educators building demos and interactive lessons that visualize how registers and memory change.&lt;/item&gt;
      &lt;item&gt;Hobbyists and hackers experimenting with toy CPUs, compact data layouts, or custom instruction ideas.&lt;/item&gt;
      &lt;item&gt;Developers who want a tiny, readable simulator to prototype algorithms that manipulate memory directly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get started&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow the Installation section below to install from PyPI or set up a development environment.&lt;/item&gt;
      &lt;item&gt;See the Examples section (like the bubble sort demo) to run real programs and watch the visualizer in action.&lt;/item&gt;
      &lt;item&gt;Dive into the API Reference for details on the CPU, assembler, and visualization helpers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tiny8 supports Python 3.11 and newer. It has no heavy external dependencies and is suitable for inclusion in virtual environments. Follow the steps below to prepare your environment and install from source or PyPI.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.11+&lt;/item&gt;
      &lt;item&gt;Git (for installing from the repository)&lt;/item&gt;
      &lt;item&gt;Recommended: create and use a virtual environment&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/sql-hkr/tiny8.git
cd tiny8
uv venv
source .venv/bin/activate
uv sync&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;uv is an extremely fast Python package and project manager, written in Rust. To install it, run:&lt;/p&gt;
    &lt;code&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh

# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"&lt;/code&gt;
    &lt;p&gt;This flow sets up a development virtual environment, installs development requirements, and prepares the project for local editing and testing.&lt;/p&gt;
    &lt;code&gt;uv add tiny8&lt;/code&gt;
    &lt;p&gt;This example demonstrates a simple bubble sort algorithm implemented in assembly language for the Tiny8 CPU. The program first fills a section of RAM with pseudo-random bytes, then sorts those bytes using the bubble sort algorithm. Finally, a Python script runs the assembly program and visualizes the sorting process.&lt;/p&gt;
    &lt;p&gt;bubblesort.asm:&lt;/p&gt;
    &lt;code&gt;; Bubble sort using RAM (addresses 100..131) - 32 elements
; Purpose: fill RAM[100..131] with pseudo-random bytes and sort them
; Registers (use R16..R31 for LDI immediates):
;   R16 - base address (start = 100)
;   R17 - index / loop counter for initialization
;   R18 - PRNG state (seed)
;   R19..R24 - temporary registers used in loops and swaps
;   R25 - PRNG multiplier (kept aside to avoid clobber in MUL)
;
; The code below is split into two phases:
; 1) init_loop: generate and store 32 pseudo-random bytes at RAM[100..131]
; 2) outer/inner loops: perform a simple bubble sort over those 32 bytes

    ; initialize pointers and PRNG
    ldi r16, 100    ; base address
    ldi r17, 0      ; index = 0
    ldi r18, 123    ; PRNG seed
    ldi r25, 75     ; PRNG multiplier (kept in r25 so mul doesn't clobber it)

init_loop:
    ; PRNG step: r2 := lowbyte(r2 * 75), then tweak
    mul r18, r25     ; r18 = low byte of (r18 * 75)
    inc r18           ; small increment to avoid repeating patterns
    ; store generated byte into memory at base + index
    st r16, r18       ; RAM[base] = r18
    inc r16           ; advance base pointer
    inc r17           ; increment index
    ldi r23, 32
    cp r17, r23
    brne init_loop

; Bubble sort for 32 elements (perform passes until i == 31)
    ldi r18, 0      ; i = 0 (outer loop counter)
outer_loop:
    ldi r19, 0      ; j = 0 (inner loop counter)
inner_loop:
    ; compute address of element A = base + j
    ldi r20, 100
    add r20, r19
    ld r21, r20      ; r21 = A
    ; compute address of element B = base + j + 1
    ldi r22, 100
    add r22, r19
    ldi r23, 1
    add r22, r23
    ld r24, r22      ; r24 = B
    ; compare A and B (we'll swap if A &amp;lt; B)
    cp r21, r24      ; sets carry if r21 &amp;lt; r24
    brcs no_swap
    ; swap A and B: store B into A's address, A into B's address
    st r20, r24
    st r22, r21
no_swap:
    inc r19
    ldi r23, 31
    cp r19, r23
    breq end_inner
    jmp inner_loop
end_inner:
    inc r18
    ldi r23, 31
    cp r18, r23
    breq done
    jmp outer_loop

done:
    jmp done&lt;/code&gt;
    &lt;p&gt;Python Code:&lt;/p&gt;
    &lt;code&gt;from tiny8 import CPU, Visualizer, assemble_file

prog, labels = assemble_file("examples/bubblesort.asm")
cpu = CPU()
cpu.load_program(prog, labels)
cpu.run(max_cycles=15000)

print([cpu.read_ram(i) for i in range(100, 132)])

viz = Visualizer(cpu)
base = 100
viz.animate_combined(
    interval=1,
    mem_addr_start=base,
    mem_addr_end=base + 31,
    plot_every=100,
    # filename="bubblesort.gif",
    # fps=60,
)&lt;/code&gt;
    &lt;p&gt;Example Output:&lt;/p&gt;
    &lt;code&gt;[247, 243, 239, 238, 227, 211, 210, 195, 190, 187, 186, 171, 167, 159, 155, 150, 142, 139, 135, 130, 127, 106, 102, 94, 54, 50, 34, 26, 23, 15, 10, 6]&lt;/code&gt;
    &lt;p&gt;Below is a concise, categorized summary of the Tiny8 instruction set (mnemonics are case-insensitive). This is a quick reference — for implementation details see &lt;code&gt;src/tiny8/cpu.py&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Data transfer&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;LDI Rd, K — load immediate into register&lt;/item&gt;
          &lt;item&gt;MOV Rd, Rr — copy register&lt;/item&gt;
          &lt;item&gt;LD Rd, Rr_addr — load from RAM at address in register&lt;/item&gt;
          &lt;item&gt;ST Rr_addr, Rr — store register into RAM at address in register&lt;/item&gt;
          &lt;item&gt;IN Rd, port — read byte from RAM/IO into register&lt;/item&gt;
          &lt;item&gt;OUT port, Rr — write register to RAM/IO&lt;/item&gt;
          &lt;item&gt;PUSH Rr / POP Rd — stack push/pop&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Arithmetic&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;ADD Rd, Rr — add registers&lt;/item&gt;
          &lt;item&gt;ADC Rd, Rr — add with carry&lt;/item&gt;
          &lt;item&gt;SUB Rd, Rr / SUBI Rd, K — subtraction&lt;/item&gt;
          &lt;item&gt;SBC Rd, Rr / SBCI Rd, K — subtract with carry/borrow&lt;/item&gt;
          &lt;item&gt;INC Rd / DEC Rd — increment / decrement&lt;/item&gt;
          &lt;item&gt;MUL Rd, Rr — 8x8 -&amp;gt; 16 multiply (low/high in Rd/Rd+1)&lt;/item&gt;
          &lt;item&gt;DIV Rd, Rr — unsigned divide (quotient-&amp;gt;Rd, remainder-&amp;gt;Rd+1)&lt;/item&gt;
          &lt;item&gt;NEG Rd — two's complement negate&lt;/item&gt;
          &lt;item&gt;CLR Rd / SER Rd — clear or set register to all ones&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Logical and bit ops&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;AND Rd, Rr / ANDI Rd, K — bitwise AND&lt;/item&gt;
          &lt;item&gt;OR Rd, Rr / ORI Rd, K — bitwise OR&lt;/item&gt;
          &lt;item&gt;EOR Rd, Rr / EORI Rd, K — exclusive OR&lt;/item&gt;
          &lt;item&gt;COM Rd — one's complement&lt;/item&gt;
          &lt;item&gt;SWAP Rd — swap nibbles&lt;/item&gt;
          &lt;item&gt;TST Rd — test for zero or minus&lt;/item&gt;
          &lt;item&gt;SBI/CBI / SBIS/SBIC / SBRS/SBRC — set/clear/test single bits and conditional skips&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shifts &amp;amp; rotates&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;LSL Rd / LSR Rd — logical shift left/right&lt;/item&gt;
          &lt;item&gt;ROL Rd / ROR Rd — rotate through carry&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Word (16-bit) ops&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;SBIW / ADIW — simplified word add/subtract helpers for register pairs&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Control flow&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;JMP label / RJMP offset — unconditional jump&lt;/item&gt;
          &lt;item&gt;CALL label / RCALL offset — call subroutine (push return address)&lt;/item&gt;
          &lt;item&gt;RET / RETI — return from subroutine / return from interrupt (sets I)&lt;/item&gt;
          &lt;item&gt;BRNE / BREQ / BRCS / BRCC — conditional branches based on flags&lt;/item&gt;
          &lt;item&gt;CP Rd, Rr / CPI Rd, K — compare (sets flags)&lt;/item&gt;
          &lt;item&gt;CPSE Rd, Rr — compare and skip if equal&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the assembler in &lt;code&gt;src/tiny8/assembler.py&lt;/code&gt; (or &lt;code&gt;parse_asm&lt;/code&gt;) to write programs — register operands are specified as R0..R31 and immediates accept decimal, $hex, 0x, or 0b binary notation.&lt;/p&gt;
    &lt;p&gt;The API section documents the public modules, classes, functions, and configuration options. See:&lt;/p&gt;
    &lt;p&gt;Tiny8 is licensed under the MIT License. See LICENSE for details.&lt;/p&gt;
    &lt;p&gt;Contributions, bug reports, and pull requests are welcome; please follow the repository's CONTRIBUTING guidelines.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/sql-hkr/tiny8"/><published>2025-10-24T13:13:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45694767</id><title>Asahi Linux Still Working on Apple M3 Support, M1n1 Bootloader Going Rust</title><updated>2025-10-24T15:11:04.965496+00:00</updated><content>&lt;doc fingerprint="8f41bb17d99430ec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Asahi Linux Still Working On Apple M3 Support, m1n1 Bootloader Going Rust&lt;/head&gt;
    &lt;p&gt; The Asahi Linux developers involved with working on Linux support for Apple Silicon M-Series devices have put out a new progress report on their development efforts. &lt;lb/&gt;Asahi Linux developers have kept working on new kernel patches and some being upstreamed for Linux 6.17 and 6.18 cycles, as previously covered on Phoronix. Notably with Linux 6.18 is the Device Trees for the Apple M2 Pro / Max / Ultra devices albeit more driver code is still working its way upstream.&lt;lb/&gt;Asahi Linux developers are also working on moving toward the Rust programming language with their important m1n1 bootloader for Apple Silicon. They feel going to Rust is important for such a critical piece of software for better maintainability, safety, and ensuring the correct logic.&lt;lb/&gt;Asahi Linux developers have also made progress on getting more games working on Apple Silicon devices. Wine is also now working outside of muvm and their graphics driver support continues maturing:&lt;lb/&gt;With the upstream Linux kernel work around Apple Silicon so far being focused on Apple M1 and M2, you may be wondering about M3 and M4 or the recently announced M5... They still are battling Apple M3 bring-up. Today's progress report comments:&lt;lb/&gt;See the progress report in full over on AsahiLinux.org.&lt;/p&gt;
    &lt;p&gt;Asahi Linux developers have kept working on new kernel patches and some being upstreamed for Linux 6.17 and 6.18 cycles, as previously covered on Phoronix. Notably with Linux 6.18 is the Device Trees for the Apple M2 Pro / Max / Ultra devices albeit more driver code is still working its way upstream.&lt;/p&gt;
    &lt;p&gt;Asahi Linux developers are also working on moving toward the Rust programming language with their important m1n1 bootloader for Apple Silicon. They feel going to Rust is important for such a critical piece of software for better maintainability, safety, and ensuring the correct logic.&lt;/p&gt;
    &lt;p&gt;Asahi Linux developers have also made progress on getting more games working on Apple Silicon devices. Wine is also now working outside of muvm and their graphics driver support continues maturing:&lt;/p&gt;
    &lt;p&gt;With the upstream Linux kernel work around Apple Silicon so far being focused on Apple M1 and M2, you may be wondering about M3 and M4 or the recently announced M5... They still are battling Apple M3 bring-up. Today's progress report comments:&lt;/p&gt;
    &lt;quote&gt;"It may be surprising to learn that very basic, low-level support for M3 has existed for quite some time now. m1n1 is capable of initialising the CPU cores, turning on some critical peripheral devices, and booting the Asahi kernel. However, the level of support right now begins and ends with being able to boot to a blinking cursor. Naturally, this level of support is not at all useful for anything but low-level reverse engineering, but we of course plan on rectifying this in due time..."&lt;/quote&gt;
    &lt;p&gt;See the progress report in full over on AsahiLinux.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.phoronix.com/news/Asahi-Linux-M3-m1n1-Update"/><published>2025-10-24T14:03:22+00:00</published></entry></feed>