<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-09T22:36:48.973742+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45863360</id><title>I Am Mark Zuckerberg</title><updated>2025-11-09T22:36:58.829064+00:00</updated><content>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://iammarkzuckerberg.com/"/><published>2025-11-09T06:13:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865049</id><title>Visualize FastAPI endpoints with FastAPI-Voyager</title><updated>2025-11-09T22:36:57.607646+00:00</updated><content>&lt;doc fingerprint="2d7d4c5aa849e7b4"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading… FastAPI Voyager {{ state.version }} scroll to zoom in/out double click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }} {{ tag.routes.length }} {{ route.name }} No routes {{ dumpJson }} Import core data JSON&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.newsyeah.fun/voyager/"/><published>2025-11-09T12:24:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865159</id><title>Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology</title><updated>2025-11-09T22:36:56.002354+00:00</updated><content>&lt;doc fingerprint="25357b3c1a218080"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt;How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery: A Digital Time Capsule from 1987&lt;/head&gt;
    &lt;p&gt;Picture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to &lt;code&gt;comp.sources.games&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;“conquest – middle earth multi-player game, Part01/05”&lt;/p&gt;
    &lt;p&gt;That’s how Ed Barlow announced it at the time, before quickly changed the name to Conquer.&lt;/p&gt;
    &lt;p&gt;This was Conquer – a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn’t just the gameplay, but how it was built and distributed in an era when “open source” wasn’t even a term yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 0: University Days.&lt;/head&gt;
    &lt;p&gt;It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy.&lt;/p&gt;
    &lt;p&gt;But by 2006, this piece of computing history was trapped in legal limbo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1: The Quest Begins (2006)&lt;/head&gt;
    &lt;p&gt;As a university student in Spain in the early ’90s, I’d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear – typical of the “post it and see what happens” era of early internet software distribution.&lt;/p&gt;
    &lt;p&gt;I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions.&lt;/p&gt;
    &lt;p&gt;Simple, right?&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 2: Digital Detective Work&lt;/head&gt;
    &lt;p&gt;Finding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums.&lt;/p&gt;
    &lt;p&gt;The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: “Yes i delegated it all to adam aeons ago. Im easy on it all…. copyleft didnt exist when i wrote it and it was all for fun so…”&lt;/p&gt;
    &lt;p&gt;But there was a catch – I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 3: The Long Wait (2006-2011)&lt;/head&gt;
    &lt;p&gt;I documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders.&lt;/p&gt;
    &lt;p&gt;Years passed. The project stalled.&lt;/p&gt;
    &lt;p&gt;Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:&lt;/p&gt;
    &lt;p&gt;“I heard news of the request to release the code. I grant permission to release the code under GPL.” – Adam Bryant&lt;/p&gt;
    &lt;p&gt;He had found one of my articles online and reached out on his own.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: The Plot Twist – Version 5 Emerges (2025)&lt;/head&gt;
    &lt;p&gt;Fast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 – a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn’t just an update; it was a complete reimagining of the game.&lt;/p&gt;
    &lt;p&gt;But V5 had a different legal history. In the ’90s, there had been commercial arrangements. Would Adam agree to GPL this version too?&lt;/p&gt;
    &lt;p&gt;His response: “I have no issues with applying a new GPL license to Version 5 as well.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 5: The Missing Piece – PostScript Magic&lt;/head&gt;
    &lt;p&gt;Just when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps – a crucial feature in the pre-GUI era when players needed physical printouts to strategize.&lt;/p&gt;
    &lt;p&gt;Tracking down MaF in 2025 led me to his company, where he’s now Director of Product Security. His response: “Oh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.”&lt;lb/&gt;Richard Caley: More Than Just a Legal Footnote&lt;/p&gt;
    &lt;p&gt;But not all searches end with an answer. Some end with silence.&lt;/p&gt;
    &lt;p&gt;My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.&lt;/p&gt;
    &lt;p&gt;Then I found him – not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org.&lt;/p&gt;
    &lt;p&gt;“Richard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.”&lt;/p&gt;
    &lt;p&gt;Reading those words felt different from finding a historical record. This wasn’t archival research – this was walking into someone’s house years after they’d gone and finding a note on the table.&lt;/p&gt;
    &lt;p&gt;The page continued:&lt;/p&gt;
    &lt;p&gt;“Over and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.”&lt;/p&gt;
    &lt;p&gt;The “Caleyisms” – The Man Behind the Code&lt;/p&gt;
    &lt;p&gt;And then I discovered his “Caleyisms” – a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:&lt;/p&gt;
    &lt;p&gt;What’s a shell suit?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Oil company executive.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How do you prepare for a pyroclastic flow hitting Edinburgh?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Hang 1000 battered Mars bars on strings and stand back?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;On his book addiction:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:&lt;/p&gt;
    &lt;p&gt;“Lack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn’t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.”&lt;/p&gt;
    &lt;p&gt;A Digital Office Preserved&lt;/p&gt;
    &lt;p&gt;Exploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his “About” section:&lt;/p&gt;
    &lt;p&gt;“Thankfully I don’t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I’m not.”&lt;/p&gt;
    &lt;p&gt;Here was a complete person – technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions.&lt;/p&gt;
    &lt;p&gt;The legal reality was harsh: Richard’s contributions to Conquer couldn’t be relicensed. The university couldn’t help contact heirs due to privacy laws.&lt;/p&gt;
    &lt;p&gt;His friends had preserved his memory with a simple ASCII tribute at the end of his page:&lt;/p&gt;
    &lt;quote&gt;^_^&lt;lb/&gt;(O O)&lt;lb/&gt;\_/@@\&lt;lb/&gt;\\~~/&lt;lb/&gt;~~&lt;lb/&gt;- RJC RIP&lt;/quote&gt;
    &lt;p&gt;In the Conquer project documentation, Richard Caley isn’t remembered as a “problem case” or “unlicensable code.” He’s honored as the vibrant person he was – the brilliant mind behind the “Caleyisms,” the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 6: Modern Renaissance – Enter GitHub, CICD and Modern Distributions&lt;/head&gt;
    &lt;p&gt;Here’s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.&lt;/p&gt;
    &lt;p&gt;For APK packages, I used Melange – a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi “undistro”. The irony? I discovered this tool when some friend started to work for the company that created it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 7: The Technical Journey: From USENET to Modern CI/CD&lt;/head&gt;
    &lt;p&gt;The transformation has been remarkable:&lt;/p&gt;
    &lt;p&gt;1987 Original:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Distributed as split USENET posts&lt;/item&gt;
      &lt;item&gt;Manual compilation with system-specific Makefiles&lt;/item&gt;
      &lt;item&gt;No version control or automated testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2025 Revival:&lt;/p&gt;
    &lt;code&gt;# Modern CI/CD with GitHub Actions
- name: Build APK package
  run: melange build conquer.yaml
- name: Build Debian package  
  run: dpkg-buildpackage -b
&lt;/code&gt;
    &lt;p&gt;Key Modern Additions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPLv3 relicensing&lt;/item&gt;
      &lt;item&gt;Make building system modernization&lt;/item&gt;
      &lt;item&gt;C Codebase partially updated to support modern ANSI C99 specification&lt;/item&gt;
      &lt;item&gt;Debian packaging&lt;/item&gt;
      &lt;item&gt;APK packaging with Melange&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can see the complete transformation in the repositories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Conquer v4 – The original classic&lt;/item&gt;
      &lt;item&gt;Conquer v5 – The advanced rewrite&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Original Conquer v4 code, by Ed Barlow and Adam Bryant&lt;/p&gt;
    &lt;p&gt;(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!)&lt;/p&gt;
    &lt;p&gt;Conquer Version 5 – The evolution of the classical Conquer, by Adam Bryant&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 8: The Human Element: Why This Matters&lt;/head&gt;
    &lt;p&gt;This isn’t just about preserving old games – it’s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that’s what you did – you shared cool things with the community.&lt;/p&gt;
    &lt;p&gt;Martin Forssen’s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator!&lt;/p&gt;
    &lt;p&gt;The 20-year relicensing effort demonstrates something crucial about open source: it’s not just about code, it’s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they’re weaving the threads that connect computing’s past to its future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons for Modern Developers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Document everything: Those casual USENET posts became crucial legal evidence decades later&lt;/item&gt;
      &lt;item&gt;License clearly: Ed’s comment that “copyleft didnt exist when i wrote it” highlights how licensing landscapes evolve&lt;/item&gt;
      &lt;item&gt;Community matters: Adam found my articles because the community was talking about preservation&lt;/item&gt;
      &lt;item&gt;Technical debt is temporal: What seems like legacy tech today might be tomorrow’s archaeological treasure&lt;/item&gt;
      &lt;item&gt;Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Continuing Story&lt;/head&gt;
    &lt;p&gt;Both Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades.&lt;/p&gt;
    &lt;p&gt;The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life.&lt;/p&gt;
    &lt;p&gt;Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history.&lt;/p&gt;
    &lt;p&gt;What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?&lt;/p&gt;
    &lt;p&gt;#FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell&lt;/p&gt;
    &lt;p&gt;Read this article in Spanish / Lee este artículo en español: &lt;lb/&gt;https://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/&lt;/p&gt;
    &lt;p&gt;This article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/"/><published>2025-11-09T12:44:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865189</id><title>Zensical – A modern static site generator built by the Material for MkDocs team</title><updated>2025-11-09T22:36:55.833081+00:00</updated><content>&lt;doc fingerprint="9beaf6129f9c8fc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zensical – A modern static site generator built by the Material for MkDocs team¶&lt;/head&gt;
    &lt;p&gt;We are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities.&lt;/p&gt;
    &lt;p&gt;Zensical is the result of thousands of hours of work – built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability.&lt;/p&gt;
    &lt;p&gt;To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read &lt;code&gt;mkdocs.yml&lt;/code&gt;, allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months.&lt;/p&gt;
    &lt;p&gt;Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to stay in the loop.&lt;/p&gt;
    &lt;p&gt;This is the second article in a four-part series:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Transforming Material for MkDocs&lt;/item&gt;
      &lt;item&gt;Zensical – A modern static site generator built by the creators of Material for MkDocs.&lt;/item&gt;
      &lt;item&gt;What happens to the features in Insiders coming November 11, 2025&lt;/item&gt;
      &lt;item&gt;A path forward for our community coming November 18, 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why Zensical?¶&lt;/head&gt;
    &lt;p&gt;Since its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture.&lt;/p&gt;
    &lt;p&gt;We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.&lt;/p&gt;
    &lt;p&gt;In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles.&lt;/p&gt;
    &lt;p&gt;With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:&lt;/p&gt;
    &lt;p&gt;Although we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes.&lt;/p&gt;
    &lt;p&gt;You can jump to the compatibility section to learn what is already supported.&lt;/p&gt;
    &lt;head rend="h2"&gt;What you can expect¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Solid foundation¶&lt;/head&gt;
    &lt;p&gt;Our goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software.&lt;/p&gt;
    &lt;p&gt;ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.&lt;/p&gt;
    &lt;p&gt;Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting – differential builds, caching, and data flow orchestration.&lt;/p&gt;
    &lt;p&gt;With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modern design¶&lt;/head&gt;
    &lt;p&gt;Zensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:&lt;/p&gt;
    &lt;p&gt;Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily.&lt;/p&gt;
    &lt;p&gt;You can also keep the Material for MkDocs look and feel with a single line of configuration.&lt;/p&gt;
    &lt;head rend="h3"&gt;Blazing-fast search¶&lt;/head&gt;
    &lt;p&gt;Client-side search isn't a compromise – for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service.&lt;/p&gt;
    &lt;p&gt;As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.&lt;/p&gt;
    &lt;p&gt;Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:&lt;/p&gt;
    &lt;p&gt;In early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to receive news about Disco.&lt;/p&gt;
    &lt;head rend="h3"&gt;Authoring experience¶&lt;/head&gt;
    &lt;p&gt;Slow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.&lt;/p&gt;
    &lt;p&gt;It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs.&lt;/p&gt;
    &lt;p&gt;While the initial build can sometimes be slower than with MkDocs, repeated builds – especially when serving the site – are already 4 to 5x faster, as only changed files need to be rebuilt.&lt;/p&gt;
    &lt;p&gt;We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.&lt;/p&gt;
    &lt;head rend="h3"&gt;Maximum compatibility¶&lt;/head&gt;
    &lt;p&gt;Compatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands &lt;code&gt;mkdocs.yml&lt;/code&gt; configuration files, so that you can build your projects with minimal changes.&lt;/p&gt;
    &lt;p&gt;This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content.&lt;/p&gt;
    &lt;p&gt;However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modules can inject, extend, and re-define functionality&lt;/item&gt;
      &lt;item&gt;Modules are deterministic through topological ordering&lt;/item&gt;
      &lt;item&gt;Modules foster reusability, with the possibility to remix them&lt;/item&gt;
      &lt;item&gt;Modules can cooperate through well-defined contracts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zensical Spark¶&lt;/head&gt;
    &lt;p&gt;Zensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;You can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development.&lt;/p&gt;
    &lt;p&gt;You should also consider joining the waiting list, since seats are limited.&lt;/p&gt;
    &lt;head rend="h2"&gt;We're growing our team¶&lt;/head&gt;
    &lt;p&gt;We're also excited to announce that we're growing our team:&lt;/p&gt;
    &lt;p&gt;Timothée Mazzucotelli, also known as @pawamoy, is joining Zensical!&lt;/p&gt;
    &lt;p&gt;At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goodbye, GitHub Sponsors¶&lt;/head&gt;
    &lt;p&gt;Thank you! To all of you who have supported us over the years through GitHub Sponsors – we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!&lt;/p&gt;
    &lt;p&gt;Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible – we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths.&lt;/p&gt;
    &lt;p&gt;Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach.&lt;/p&gt;
    &lt;p&gt;This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company – building a business and team that can meet the growing demands of professional users while staying true to our values.&lt;/p&gt;
    &lt;p&gt;We're doubling down on Open Source, developing software for everyone.&lt;/p&gt;
    &lt;p&gt;If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Ahead¶&lt;/head&gt;
    &lt;p&gt;Material for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us – and with you.&lt;/p&gt;
    &lt;p&gt;Material for MkDocs is now in maintenance mode&lt;/p&gt;
    &lt;p&gt;We want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.&lt;/p&gt;
    &lt;p&gt;If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where we'll be in 12 months¶&lt;/head&gt;
    &lt;p&gt;Over the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 – introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities.&lt;/p&gt;
    &lt;p&gt;Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity.&lt;/p&gt;
    &lt;p&gt;You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue – we're here to help.&lt;/p&gt;
    &lt;head rend="h3"&gt;Connect with us¶&lt;/head&gt;
    &lt;p&gt;If you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks.&lt;/p&gt;
    &lt;p&gt;We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to stay in the loop.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/"/><published>2025-11-09T12:50:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865289</id><title>Montana becomes first state to enshrine 'right to compute' into law</title><updated>2025-11-09T22:36:55.404789+00:00</updated><content>&lt;doc fingerprint="a971129b188e4438"&gt;
  &lt;main&gt;
    &lt;p&gt;Montana has made history as the first state in the U.S. to legally protect its citizens’ right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law.&lt;/p&gt;
    &lt;p&gt;The groundbreaking legislation affirms Montanans’ fundamental right to own and operate computational resources — including hardware, software, and AI tools — under the state’s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world.&lt;/p&gt;
    &lt;p&gt;“Montana is once again leading the way in defending individual liberty,” said Senator Daniel Zolnikov, the bill’s sponsor and a longtime advocate for digital privacy. “With the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.”&lt;/p&gt;
    &lt;p&gt;While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law.&lt;/p&gt;
    &lt;p&gt;The act also includes provisions for AI-controlled critical infrastructure, requiring both a “shutdown mechanism” to allow human control and annual safety reviews — a move aimed at balancing innovation with public safety concerns.&lt;/p&gt;
    &lt;p&gt;The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a “flag in the ground” for digital rights, adding: “Montana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.”&lt;/p&gt;
    &lt;p&gt;The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana’s approach leans toward empowering individual users rather than restricting access.&lt;/p&gt;
    &lt;p&gt;The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state’s Majority Floor Leader, praised Montana’s leadership: “This is the kind of bold move that sets the tone for the rest of the country.”&lt;/p&gt;
    &lt;p&gt;Nationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation — like speech and property — is a fundamental human right. “A computer is an extension of the human capacity to think,” the organization states.&lt;/p&gt;
    &lt;p&gt;The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana’s law as “a monumental step forward in ensuring individuals retain control of their own data and digital tools.”&lt;/p&gt;
    &lt;p&gt;As debates over AI governance and digital rights continue to evolve, Montana’s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/"/><published>2025-11-09T13:03:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865327</id><title>Using bubblewrap to add sandboxing to NetBSD</title><updated>2025-11-09T22:36:54.971395+00:00</updated><content>&lt;doc fingerprint="53c195e199d53b4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD&lt;/head&gt;
    &lt;p&gt;This report was written by Vasyl Lanko as part of Google Summer of Code 2025.&lt;/p&gt;
    &lt;head rend="h1"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;As of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible.&lt;/p&gt;
    &lt;p&gt;There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Goals&lt;/head&gt;
    &lt;p&gt;The goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application.&lt;/p&gt;
    &lt;p&gt;NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries.&lt;/p&gt;
    &lt;p&gt;A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Implementation&lt;/head&gt;
    &lt;p&gt;Linux has 8 namespace types, in this project we will focus on only 2 of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details&lt;/item&gt;
      &lt;item&gt;mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of "everything is a file", so we need a separate mount namespace to have different configuration files on the same location as the system.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic.&lt;/p&gt;
    &lt;p&gt;We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)&lt;/p&gt;
    &lt;p&gt;We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux.&lt;/p&gt;
    &lt;head rend="h2"&gt;UTS namespace&lt;/head&gt;
    &lt;p&gt;UTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the &lt;code&gt;utsname&lt;/code&gt;  can be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers.&lt;/p&gt;
    &lt;p&gt;The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the &lt;code&gt;utsname&lt;/code&gt; we need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.&lt;/p&gt;
    &lt;p&gt;This namespace specific information needs to be saved somewhere, and for that we use the credential's &lt;code&gt;private_data&lt;/code&gt; field, so we can use a &lt;code&gt;UTS_key&lt;/code&gt; to save and retrieve &lt;code&gt;UTS&lt;/code&gt; related information from the secmodel. The key specifies the type of information we want to retrieve from the &lt;code&gt;private_data&lt;/code&gt;, hence using a &lt;code&gt;UTS_key&lt;/code&gt; for the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different.&lt;/p&gt;
    &lt;p&gt;We had to modify kernel code that was directly accessing the &lt;code&gt;hostname&lt;/code&gt; and &lt;code&gt;domainname&lt;/code&gt; variables, to instead call &lt;code&gt;get_uts()&lt;/code&gt;, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly.&lt;/p&gt;
    &lt;head rend="h2"&gt;MNT namespace&lt;/head&gt;
    &lt;p&gt;The MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system.&lt;/p&gt;
    &lt;p&gt;The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them.&lt;/p&gt;
    &lt;p&gt;For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the &lt;code&gt;MNT_key&lt;/code&gt;. Similarly to the UTS namespace, we had to modify kernel code to not directly access the &lt;code&gt;mountlist&lt;/code&gt;, but instead go through a wrapper called &lt;code&gt;get_mountlist()&lt;/code&gt; which returns the correct mountlist for the namespace the calling process resides in.&lt;/p&gt;
    &lt;p&gt;Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Status&lt;/head&gt;
    &lt;p&gt;You can find all code written during this project in GitHub at maksymlanko/netbsd-src &lt;code&gt;gsoc-bubblewrap&lt;/code&gt; branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on &lt;code&gt;gsoc-bubblewrap&lt;/code&gt; branch and this was the last one for the &lt;code&gt;mnt_ns&lt;/code&gt; still WIP branch.&lt;/p&gt;
    &lt;p&gt;The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces.&lt;/p&gt;
    &lt;p&gt;The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Future Work&lt;/head&gt;
    &lt;p&gt;As previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.&lt;/p&gt;
    &lt;p&gt;I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to &lt;code&gt;root&lt;/code&gt; in the namespace, giving them &lt;code&gt;sudo&lt;/code&gt; permissions while still restricting system-wide actions like shutting down the machine.&lt;/p&gt;
    &lt;p&gt;A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace.&lt;/p&gt;
    &lt;head rend="h1"&gt;Challenges&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.&lt;/item&gt;
      &lt;item&gt;The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code.&lt;/item&gt;
      &lt;item&gt;Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux.&lt;/item&gt;
      &lt;item&gt;There was a much bigger research component than I anticipated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD.&lt;/p&gt;
    &lt;head rend="h1"&gt;Notes&lt;/head&gt;
    &lt;p&gt;The project is called "Using bubblewrap to add sandboxing to NetBSD" and was initially projected to emulate the &lt;code&gt;unshare&lt;/code&gt; system call into &lt;code&gt;compat_linux&lt;/code&gt;, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to &lt;code&gt;compat_linux&lt;/code&gt; afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the &lt;code&gt;bwrap&lt;/code&gt; linux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called "Using bubblewrap to add sandboxing to NetBSD" but nowadays it would be more accurate to call it "Sandboxing in NetBSD with Linux-like namespaces".&lt;/p&gt;
    &lt;head rend="h1"&gt;Thanks&lt;/head&gt;
    &lt;p&gt;I am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.&lt;/p&gt;
    &lt;p&gt;I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;bug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations.&lt;/item&gt;
      &lt;item&gt;Emmanuel Dreyfus from &lt;code&gt;tech-kern&lt;/code&gt;, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project.&lt;/item&gt;
      &lt;item&gt;Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing"/><published>2025-11-09T13:09:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865956</id><title>Startups are pushing the boundaries of reproductive genetics</title><updated>2025-11-09T22:36:54.718293+00:00</updated><content/><link href="https://www.wsj.com/tech/biotech/genetically-engineered-babies-tech-billionaires-6779efc8"/><published>2025-11-09T14:50:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866165</id><title>Samsung Family Hub for 2025 Update Elevates the Smart Home Ecosystem</title><updated>2025-11-09T22:36:54.148909+00:00</updated><content>&lt;doc fingerprint="255dce4306b7f5ed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Samsung Family Hub™ for 2025 Update Elevates the Smart Home Ecosystem&lt;/head&gt;
    &lt;p&gt;The software update includes a more unified user experience across connected devices, enhancements to AI Vision Inside™, expanded Knox Security and more&lt;/p&gt;
    &lt;p&gt;10/27/2025&lt;/p&gt;
    &lt;p&gt;Samsung’s Family Hub™ for 2025 software enhancements will start rolling out in October for owners of Family Hub™ refrigerators. The update includes a more intuitive user interface, improved AI Vision Inside™ capabilities, Voice ID capabilities with Bixby[1] and upgraded security with Knox Matrix[2].&lt;/p&gt;
    &lt;head rend="h5"&gt;Unified Experience Across Screens&lt;/head&gt;
    &lt;p&gt;The refreshed One UI design that was first seen on Samsung’s 2025 Bespoke AI appliances will be coming to 2024 Family Hub™ models. This advances Samsung’s vision to bring a unified, seamless experience across the screens of its ecosystem of smart TVs, mobile devices and home appliances. In addition to enabling intuitive navigation and region-specific settings, users will get convenient access to features like Family Care, Pet Care and Home Care[3].&lt;/p&gt;
    &lt;p&gt;Family Hub’s™ Cover screen themes are also being updated with new features, including the addition of a Daily Board theme, that offers a new way to see useful information at a glance.&lt;/p&gt;
    &lt;head rend="h5"&gt;Smarter Food Tracking with AI Vision Inside Refrigerators&lt;/head&gt;
    &lt;p&gt;Family Hub™ refrigerators[4] with AI Vision Inside technology will receive upgrades to enable recognition of frequently used packaged foods and even more fresh fruits and vegetables to help families reduce food waste and save money. AI Vision Inside will now recognize 37 fresh food items, including apples, cherries, cucumbers, mangoes, kiwis and more. In addition, AI Vision can now identify and suggest labeling up to 50 packaged food items that are frequently placed in the fridge.[5]&lt;/p&gt;
    &lt;head rend="h5"&gt;Personalized Intelligence for Every User&lt;/head&gt;
    &lt;p&gt;Meanwhile, Bixby gets new Voice ID[6] capabilities, allowing it to recognize who is speaking and switches to their Samsung account. This makes it easy for users to access their calendar[7] and view their photos[8] or find a misplaced phone, even when it’s on silent[9].&lt;/p&gt;
    &lt;p&gt;Voice ID also enhances accessibility by syncing the refrigerator’s display with the visual settings on a user’s Samsung Galaxy phone, such as color inversion or grayscale[10]. And for quicker access, users can now activate Bixby with a simple double tap on the screen.&lt;/p&gt;
    &lt;head rend="h5"&gt;New Widget Pilot for Cover Screen Themes&lt;/head&gt;
    &lt;p&gt;As part of the Family Hub™ software update, we are piloting a new widget for select Cover screens themes of Family Hub™ refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements.[11]&lt;/p&gt;
    &lt;p&gt;Family Hub™ owners will have the option to turn off Cover screen ads in the Advertisements tab of the Settings menu. Ads can also be dismissed on the Cover screen, meaning that specific ads will not appear again during the campaign period. Advertising will not appear when Cover screen displays Art or Album themes.&lt;/p&gt;
    &lt;head rend="h5"&gt;Advanced Security That Works Quietly in the Background&lt;/head&gt;
    &lt;p&gt;Samsung is also expanding the reach of Knox Matrix, its advanced security solution built on private blockchain technology, to more of its smart home lineup. The protection now extends beyond Family Hub™+ refrigerators to include compatible Wi-Fi–enabled[12] Samsung fridges, washers and dryers launched in 2024[13] — creating a safer, more connected home ecosystem.&lt;/p&gt;
    &lt;p&gt;With Knox Trust Chain, these appliances can now monitor each other’s security status, ensuring every connected device stays protected. The Bespoke AI Family Hub™+ will also receive enhanced security features, including encrypted Credential Sync, Passkey support and the new Knox Security Dashboard introduced on 2025 models, giving users an easy, real-time view of their connected devices’ security status.&lt;/p&gt;
    &lt;head rend="h5"&gt;How to Update Your Family Hub™&lt;/head&gt;
    &lt;p&gt;Once the update is available for your fridge, you will receive a notification on the fridge’s screen asking to opt in to the latest software update. Enhancements will become available as soon as you accept the terms and complete the update.&lt;/p&gt;
    &lt;p&gt;To learn more about Samsung’s innovative line of smart Family Hub™ refrigerators, visit Samsung.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.samsung.com/us/samsung-family-hub-2025-update-elevates-smart-home-ecosystem/"/><published>2025-11-09T15:18:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866224</id><title>The Manuscripts of Edsger W. Dijkstra</title><updated>2025-11-09T22:36:53.848390+00:00</updated><content>&lt;doc fingerprint="e615734b00f3a2b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Edsger Wybe Dijkstra was one of the most influential members of computing science’s founding generation. Among the domains in which his scientific contributions are fundamental are&lt;/p&gt;
    &lt;p&gt;algorithm design&lt;/p&gt;
    &lt;p&gt;programming languages&lt;/p&gt;
    &lt;p&gt;program design&lt;/p&gt;
    &lt;p&gt;operating systems&lt;/p&gt;
    &lt;p&gt;distributed processing&lt;/p&gt;
    &lt;p&gt;formal specification and verification&lt;/p&gt;
    &lt;p&gt;design of mathematical arguments&lt;/p&gt;
    &lt;p&gt;In addition, Dijkstra was intensely interested in teaching, and in the relationships between academic computing science and the software industry.&lt;/p&gt;
    &lt;p&gt;During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra’s contributions brought him many prizes and awards, including computing science’s highest honor, the ACM Turing Award.&lt;/p&gt;
    &lt;p&gt;The Manuscripts&lt;/p&gt;
    &lt;p&gt;Like most of us, Dijkstra always believed it a scientist’s duty to maintain a lively correspondence with his scientific colleagues. To a greater extent than most of us, he put that conviction into practice. For over four decades, he mailed copies of his consecutively numbered technical notes, trip reports, insightful observations, and pungent commentaries, known collectively as “EWDs”, to several dozen recipients in academia and industry. Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra’s writings, the informal circulation of many of the EWDs eventually reached into the thousands.&lt;/p&gt;
    &lt;p&gt;Although most of Dijkstra’s publications began life as EWD manuscripts, the great majority of his manuscripts remain unpublished. They have been inaccessible to many potential readers, and those who have received copies have been unable to cite them in their own work. To alleviate both of these problems, the department has collected over a thousand of the manuscripts in this permanent web site, in the form of PDF bitmap documents (to read them, you’ll need a copy of Acrobat Reader). We hope you will find it convenient, useful, inspiring, and enjoyable.&lt;/p&gt;
    &lt;p&gt;The original manuscripts, along with diaries, correspondence, photographs, and other papers, are housed at The Center for American History of The University of Texas at Austin.&lt;/p&gt;
    &lt;p&gt;Indexes&lt;/p&gt;
    &lt;p&gt;Each manuscript file is accessible through either of two indexes:&lt;/p&gt;
    &lt;p&gt;0. BibTeX index. Each entry includes all the available bibliographic data.&lt;/p&gt;
    &lt;p&gt;1. Ad-hoc indexes. These contain titles only, but are faster if you know what you’re looking for.&lt;/p&gt;
    &lt;p&gt;EWD-numbered documents(This index gives an approximate correspondence between manuscripts’ EWD numbers and the year in which they appeared.)&lt;/p&gt;
    &lt;p&gt;Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica)&lt;/p&gt;
    &lt;p&gt;You can find a table relating EWD numbers to publication years here.&lt;/p&gt;
    &lt;p&gt;Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers.&lt;/p&gt;
    &lt;p&gt;Transcripts and translations&lt;/p&gt;
    &lt;p&gt;A growing number of the PDF bitmap documents have been transcribed to make them searchable and accessible to visitors who are visually impaired.&lt;/p&gt;
    &lt;p&gt;A few of the manuscripts written in Dutch have been translated into English, and one —EWD1036— has been translated into Spanish. EWD28 has been translated from English into Russian.&lt;/p&gt;
    &lt;p&gt;For these transcriptions and translations we are grateful to over sixty contributors. Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations).&lt;/p&gt;
    &lt;p&gt;Proofreading Each transcription gets a cursory scan as it’s prepared for uploading, but since a web page can always be updated, I don’t strive for (unattainable) perfection before installing it. On the web, proofreading is a game that can be played by every reader; if you spot an error, please&lt;/p&gt;
    &lt;p&gt;Links between EWDs&lt;/p&gt;
    &lt;p&gt;A compilation of cross-references has been contributed by Diethard Michaelis. As its author notes, the collection is incomplete, and all readers are invited to add to it.&lt;/p&gt;
    &lt;p&gt;Dijkstra often returned to topics about which he had already written, when he had something new to say or even just a better way of saying it. When Dijkstra himself didn’t provide the backward references, we indicate the relationship by "see also" links in the index, leaving the judgment of the extent to which the earlier EWD is superseded by the later one to the reader. Any reader who notices such a relationship is invited to&lt;/p&gt;
    &lt;p&gt;Summaries&lt;/p&gt;
    &lt;p&gt;We have begun adding summaries of the EWDs. This innovation was suggested by Günter Rote, who contributed the first dozen summaries. Additional contributions of summaries—especially summaries in English of EWDs in Dutch—are most welcome.&lt;/p&gt;
    &lt;p&gt;Copyrights&lt;/p&gt;
    &lt;p&gt;Copyrights in most EWDs are held by his children, one of whom — — handles requests for permission to publish reproductions. The exceptions are documents that were published, and whose copyrights are held by their publishers; those documents are listed here, and each one is provided with a cover page identifying the copyright holder.&lt;/p&gt;
    &lt;p&gt;Because the original manuscripts are in possession of the Briscoe Center for American History at The University of Texas, the Center’s policies are also applicable.&lt;/p&gt;
    &lt;p&gt;Video and audio&lt;/p&gt;
    &lt;p&gt;In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews.&lt;/p&gt;
    &lt;p&gt;About Dijkstra and his work&lt;/p&gt;
    &lt;p&gt;An interview with Dijkstra (Spanish translation here) was conducted in 1985 by Rogier F. van Vlissingen, who has also written a personal reflection on “Dijkstra’s sense of what computer science and programming are and what they aren’t.”&lt;/p&gt;
    &lt;p&gt;Another interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute.&lt;/p&gt;
    &lt;p&gt;To mark the occasion of Dijkstra’s retirement in November 1999 from the Schlumberger Centennial Chair in Computer Sciences, which he had occupied since 1984, and to celebrate his forty-plus years of seminal contributions to computing science, the Department of Computer Sciences organized a symposium, In Pursuit of Simplicity, which took place on his birthday in May 2000. The symposium’s program (10 MB) contains an outline of Dijkstra’s career, as well as a collection of quotes culled from his writings, from his blackboard, and from what others have said about him. Banquet speeches by David Gries, Fred Schneider, Krzysztof Apt, W.M. Turski, and H. Richards were recorded on a video.&lt;/p&gt;
    &lt;p&gt;Dijkstra’s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department’s memorial celebration.&lt;/p&gt;
    &lt;p&gt;A remembrance of Dijkstra was posted in May 2008 by Maarten van Emden (thanks to Tristram Brelstaff for noting it).&lt;/p&gt;
    &lt;p&gt;In 2021 Krzysztof R. Apt and Tony Hoare edited a commemoration of Edsger Dijkstra written by more than twenty computer scientists who knew him as a colleague, teacher, and friend.&lt;/p&gt;
    &lt;p&gt;A blog devoted to Dijkstra’s works and thoughts has been created, and is being maintained, by the historian of computing Edgar G. Daylight. An article by Daylight, “Dijkstra’s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,” appeared in The Computer Journal, March 2011.&lt;/p&gt;
    &lt;p&gt;In his blog A Programmer’s Place, Maarten van Emden has an entry entitled “Another scoop by Dijkstra?”. The entry describes Dijkstra’s “remarkable insight [in “Notes on Structured Programming” (EWD 249)] that resolves the stand-off between the Sieve of Eratosthenes (efficient in terms of time, but not memory) and the method of Trial Division (efficient in terms of memory, but not time)” by applying the Assembly-line Principle.&lt;/p&gt;
    &lt;p&gt;The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra’s “foundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.”&lt;/p&gt;
    &lt;p&gt;The Dijkstra Memorial Lectures&lt;/p&gt;
    &lt;p&gt;A series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010.&lt;/p&gt;
    &lt;p&gt;About this site&lt;/p&gt;
    &lt;p&gt;Recent significant changes in the site are listed here; the most recent change was posted on 30 March 2021.&lt;/p&gt;
    &lt;p&gt;The folks who contributed most significantly to the site’s creation are acknowledged here.&lt;/p&gt;
    &lt;p&gt;Comments and suggestions about the site are always welcome; please email them to the&lt;/p&gt;
    &lt;p&gt;Related site&lt;/p&gt;
    &lt;p&gt;If you find this site interesting, you may also be interested in another site:&lt;/p&gt;
    &lt;p&gt;Discipline in Thought which is a website dedicated to disciplined thinking, calculational mathematics, and mathematical methodology. The members of this site are markedly influenced by the works of EWD, and the material shared through the website continues in the traditions set by EWD (among others).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cs.utexas.edu/~EWD/"/><published>2025-11-09T15:27:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866243</id><title>AI isn't replacing jobs. AI spending is</title><updated>2025-11-09T22:36:53.677405+00:00</updated><content/><link href="https://www.fastcompany.com/91435192/chatgpt-llm-openai-jobs-amazon"/><published>2025-11-09T15:30:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866572</id><title>The Principles of Diffusion Models</title><updated>2025-11-09T22:36:53.410758+00:00</updated><content>&lt;doc fingerprint="ac0cac09d8b5828a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 24 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:The Principles of Diffusion Models&lt;/head&gt;View PDF&lt;quote&gt;Abstract:This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions. The goal is to learn a reverse process that transforms noise back into data while recovering the same intermediates. We describe three complementary views. The variational view, inspired by variational autoencoders, sees diffusion as learning to remove noise step by step. The score-based view, rooted in energy-based modeling, learns the gradient of the evolving data distribution, indicating how to nudge samples toward more likely regions. The flow-based view, related to normalizing flows, treats generation as following a smooth path that moves samples from noise to data under a learned velocity field. These perspectives share a common backbone: a time-dependent velocity field whose flow transports a simple prior to the data. Sampling then amounts to solving a differential equation that evolves noise into data along a continuous trajectory. On this foundation, the monograph discusses guidance for controllable generation, efficient numerical solvers, and diffusion-motivated flow-map models that learn direct mappings between arbitrary times. It provides a conceptual and mathematically grounded understanding of diffusion models for readers with basic deep-learning knowledge.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.21890"/><published>2025-11-09T16:10:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866697</id><title>Marble Fountain</title><updated>2025-11-09T22:36:53.217310+00:00</updated><content>&lt;doc fingerprint="51808547f247bba"&gt;
  &lt;main&gt;
    &lt;p&gt;5 minutes&lt;/p&gt;
    &lt;head rend="h1"&gt;Marble Fountain&lt;/head&gt;
    &lt;p&gt;I really enjoy procedural generation, especially systems designed to work with hardware outputs. After starting work at Formlabs in September of 2023 and gaining access to much nicer printers than I was used to, I started wanting to tackle some large algorithmic structure projects. Complexity is free in 3d printing, the limit of design geometry is mostly how much time you’re willing to spend in CAD. I wanted to print the most complicated art piece I could think of. Marble Fountain is what I came up with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tracks&lt;/head&gt;
    &lt;p&gt;My initial system came together quickly. Randomly placing spaced out points, drawing a spline through them, and setting a constant slope just works. My first draft was just subtracting a tube from the solid support structure which worked but was super limited. I wanted to add more parts and so I started working on a path solver. I wanted to fit as much motion into the volume of the printer as possible. This turned out to be extremely challenging.&lt;/p&gt;
    &lt;p&gt;The solver starts by making a random series of line segments connecting the top and bottom of the lift. There are several different algorithms to generate this guess, as the initial conditional has a noticeable impact on the shape of the structure for lower path counts. It’s interesting to play with different variants of the starting conditions and see how they change during generation.&lt;/p&gt;
    &lt;p&gt;A series of functions update the positions over time to “pull” the points into a followable path. The points making up each path:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stay in the bounding box&lt;/item&gt;
      &lt;item&gt;Evenly space themselves out&lt;/item&gt;
      &lt;item&gt;Pull towards a fixed height to enforce a constant slope&lt;/item&gt;
      &lt;item&gt;Enforce min and max turning radius of the path&lt;/item&gt;
      &lt;item&gt;Repel away from other tracks&lt;/item&gt;
      &lt;item&gt;Repel away from distant sections of our own track&lt;/item&gt;
      &lt;item&gt;Smooth out changes in slope to prevent jumps&lt;/item&gt;
      &lt;item&gt;Prevent slope from ever increasing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Velocity is a much harder problem than I anticipated. The tracks break a lot of the obvious assumptions if you act like the marble is a point mass, as changing the bank of the track moves the axis of rotation and can burn off rotational inertia to friction. Long straight sections would build up too much speed and bearings fly off on the turns, but balls taking sharp turns at slow speed will lose too much momentum and stop. I settled on setting a minimum turn radius for the track and banking much more aggressively than is technically necessary for any given speed, so it constantly snakes back and forth to burn off speed.&lt;/p&gt;
    &lt;p&gt;One of the most elegant designs of the whole structure is how the lift acts like a ball screw. The the screw is constrained by the balls on all sides which allows it to run with no bearing at the top. This also leads to a failure mode where if the screw ever only has balls on one side it will immediately start wobbling badly enough that all the balls currently rolling will fall off the tracks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supports&lt;/head&gt;
    &lt;p&gt;The support generation was surprisingly simple. Iterating from the top down and treating the support pillars as a particle system is quite robust. I spent more time tweaking the geometry for aesthetics than I did for actual structure and collision issues, although I did heavily lean on the overhang tolerance of the printer.&lt;/p&gt;
    &lt;p&gt;Each support:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pulls towards other supports, weighted by distance and similarity in size&lt;/item&gt;
      &lt;item&gt;Repels away from other supports&lt;/item&gt;
      &lt;item&gt;Pulls to stay in the bounding box&lt;/item&gt;
      &lt;item&gt;Pulls towards a fixed radius from the center of the structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supports also have inertia, which is where the arcs in the structure of the support columns come from.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;The final models take around 5-20 minutes to export. There’s a ton I could do to optimize the models, but at this point the geometry is simply beyond the scope of OpenSCAD. If I was rewriting this I would probably use a different tool more optimized for this type of organic geometry, likely an SDF library. I have vague ambitions to do a big rewrite eventually but figured sharing janky code is better than none. I started this just planning for the janky splines as a weekend project but it has gotten thoroughly out of hand.&lt;/p&gt;
    &lt;p&gt;I have a ton of other ideas to play with if I do that big rewrite. There is no realistic velocity estimation at any point in the whole system right now, just a pile of heuristics. I was originally trying to not overcomplicate but building a proper acceleration model by measuring velocity with a camera would have almost definitely saved time overall. Trying to maintain a fixed slope makes collision prevention much harder but is required to keep speed within bounds. At this point I’m also just curious about the response curve, there’s a knee somewhere where the surfaces start to slip that I want to track down.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking back&lt;/head&gt;
    &lt;p&gt;This was the most work I have ever put into a hobby project. I started in February 2024 and worked on it on and off until September. I applied to show it in a gallery (shoutout to New Alliance Gallery in Somerville) with two months of warning, which wound up leading to a large crunch trying to make the system reliable enough to show in person in the weeks before the show. I was able to get it working consistently, although it did lose 2-3 balls an hour and could only run for a few hours without the motor overheating. I got pretty burned out and dropped the project, which is why I shelved it for a full year before sharing anything.&lt;/p&gt;
    &lt;p&gt;Finally, a huge thanks to my friend Alex who listened to me ramble about marbles for several months every day while walking home from work, gave a ton of helpful input, and lived with the dozens of ball bearings scattered across our apartment.&lt;/p&gt;
    &lt;p&gt;ProceduralGeneration Art 3D Printed Python&lt;/p&gt;
    &lt;p&gt;983 Words&lt;/p&gt;
    &lt;p&gt;2025-11-01 00:00 (Last updated: 2025-11-03 01:40)&lt;/p&gt;
    &lt;p&gt;789ee9a @ 2025-11-03&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://willmorrison.net/posts/marble-fountain/"/><published>2025-11-09T16:26:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866772</id><title>Bumble Berry Pi – A Cheap DIY Raspberry Pi Handheld Cyberdeck</title><updated>2025-11-09T22:36:52.733930+00:00</updated><content>&lt;doc fingerprint="d40f95070be1dc8"&gt;
  &lt;main&gt;
    &lt;p&gt;A cheap, easy-to-build Raspberry Pi Handheld Cyberdeck&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I wanted a Clockwork Pi uConsole, but didn’t want to wait 90 business days&lt;/item&gt;
      &lt;item&gt;I like the tactile feeling of a mini keyboard&lt;/item&gt;
      &lt;item&gt;I wanted something small enough to fit into a pants pocket, so I can easily take it anywhere, but with a large enough screen to do useful things like writing little programs, running scripts, etc&lt;/item&gt;
      &lt;item&gt;I wanted to build this quickly &amp;amp; cheaply, with as many off-the-shelf components as possible&lt;/item&gt;
      &lt;item&gt;I mostly boot to the terminal interface and use tmux to manage mutliple terminal windows, but I occasionally use the GUI&lt;/item&gt;
      &lt;item&gt;I wanted to use the Raspberry Pi's I already owned (i.e. an old 3b+), rather than having to buy a new compute module&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;4.3” Touch Screen Display&lt;/item&gt;
      &lt;item&gt;Nice sized QWERTY keypad&lt;/item&gt;
      &lt;item&gt;37 Watt-hour battery (all day battery life with Raspberry Pi 3b+)&lt;/item&gt;
      &lt;item&gt;Only 2 3D-Printed Parts&lt;/item&gt;
      &lt;item&gt;Minimal assembly required&lt;/item&gt;
      &lt;item&gt;All parts available on Amazon&lt;/item&gt;
      &lt;item&gt;Cost: ~$60 worth of Amazon parts, not including the raspberry pi&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Part&lt;/cell&gt;
        &lt;cell role="head"&gt;QTY&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Buy Link&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Raspberry Pi&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$50&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;Pick your favorite. I picked a 3b+ for low cost and low power usage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4.3” Touch Screen Display&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$38&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mini Bluetooth keyboard&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$23&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;37 Watt-Hr USB Power Bank&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$19&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;Comes with short USB-C cable&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;USB-C to Micro-USB U-Shaped Adapter&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$10&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;USB-C Right Angle Adapter&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$9&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M3x10mm Countersunk Head Bolt&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M2.5x8mm Socket Head Bolt&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M3 Threaded Inserts&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2" Kapton Tape&lt;/cell&gt;
        &lt;cell&gt;1 ft&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;You could use another type of double-sided tape&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;bumble-berry-pi-enclosure-A-v3.STL&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Download from this repo an print on a 3D printer using PLA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;bumble-berry-pi-enclosure-B-v3.STL&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Download from this repo an print on a 3D printer using PLA&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Small phillips screw driver&lt;/item&gt;
      &lt;item&gt;M2.5mm hex driver&lt;/item&gt;
      &lt;item&gt;Soldering iron&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please note: Assembly instructions are a work in progress. Please let me know if you'd like additional instructions/videos, etc and I will do my best to provide them.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;3D print the two enclosure parts in PLA&lt;/item&gt;
      &lt;item&gt;Insert the 6 threaded inserts using a soldering iron (I always love this part)&lt;/item&gt;
      &lt;item&gt;Attach the raspberry pi to the screen using 4 phillips screws&lt;/item&gt;
      &lt;item&gt;Plug the ribbon cable into the rapsberry pi &amp;amp; display&lt;/item&gt;
      &lt;item&gt;Attach the screen to the front eclosure using 4 M2.5x6mm socket head bolts&lt;/item&gt;
      &lt;item&gt;Place the front enclosure face down on a table and insert the keyboard&lt;/item&gt;
      &lt;item&gt;Add a piece of double-sided kapton tape to the back of the keyboard&lt;/item&gt;
      &lt;item&gt;Place the USB power bank in the front enclosure&lt;/item&gt;
      &lt;item&gt;Add a piece of double-sided kapton tape to the back of the power bank&lt;/item&gt;
      &lt;item&gt;Route the USB cables &amp;amp; adapters as shown&lt;/item&gt;
      &lt;item&gt;Screw the enclosure back onto the enclosure front using 6 M3x10mm countersunk head bolts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I designed the 3D parts in Solidworks. Let me know if you're interested in the modifying the design and I can post the solidworks files.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/samcervantes/bumble-berry-pi"/><published>2025-11-09T16:34:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45867176</id><title>Ask HN: How do you get over the fear of sharing code?</title><updated>2025-11-09T22:36:52.341061+00:00</updated><content>&lt;doc fingerprint="4e6339913a219f53"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I'm a junior. Truth be told, I don't really care if professionals/adults see my code or pick it apart/mock it/fork it or whatever. All my repos are private just because I worry about other students being lazy and just ripping my hard work and claiming it as their own. That really pisses me off when I hear some horror stories like that.&lt;/p&gt;
      &lt;p&gt;Is this unfounded? Or do I have a right for some concern? It's obviously easier for viewers to just see public code repos and browse without ever requesting access so I know I'm losing some traffic (from my portfolio site)&lt;/p&gt;
      &lt;p&gt;I was thinking the alternative would be just linking my demo on my portfolio site as a proof of concept that yes I made it, yes it works, and if you're curious , here's a link to the code u can request independently of github.&lt;/p&gt;
      &lt;p&gt;Thank you in advance.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45867176"/><published>2025-11-09T17:17:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45867277</id><title>Python Software Foundation gets a donor surge after rejecting federal grant</title><updated>2025-11-09T22:36:51.886968+00:00</updated><content>&lt;doc fingerprint="3c0817bd488a0301"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PSF Gets a Donor Surge After Rejecting Anti-DEI Federal Grant&lt;/head&gt;
    &lt;p&gt;“The support from the Python community in response has been overwhelming,” Seth Larson told me last week. As the Python Software Foundation‘s (PSF) principal investigator for a $1.5 million grant National Science Foundation application, Larson had a front-row seat for the multiround, months-long vetting process — and to everything that happened next.&lt;/p&gt;
    &lt;p&gt;In short, the PSF turned the grant down after discovering new federal “terms and conditions” that would require them to end any programs promoting Diversity, Equity, and Inclusion (DEI) “during the term of this financial assistance award.” But a flood of new donations followed, and the PSF vowed to explore other funding options while remaining steadfast to their organizational values.&lt;/p&gt;
    &lt;p&gt;“It was so maddening to have to turn down work that would benefit everyone,” posted Loren Crary, PSF deputy executive director, on Reddit, “because they insisted on dictating what we do outside of the security project.”&lt;/p&gt;
    &lt;p&gt;Yet rejecting the grant created a surge in news coverage, thousands of upvotes on social media and an upswell of donations. Together, maybe that show of support forms a kind of collective answer — an example of how a community responds to a forceful outside attempt to challenge their culture.&lt;/p&gt;
    &lt;p&gt;By coming together.&lt;/p&gt;
    &lt;head rend="h2"&gt;Support From Guido — and Thousands of Others&lt;/head&gt;
    &lt;p&gt;“I was one of the board members who voted to reject this funding — a unanimous but tough decision,” wrote Simon Willison on his blog. “I’m proud to serve on a board that can make difficult decisions like this.”&lt;/p&gt;
    &lt;p&gt;And Python’s original creator, Guido van Rossum, even made his own post of support on X, formerly known as Twitter. “If you haven’t heard about this, kudos to the PSF for standing for its values (which are also my values).”&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you haven’t heard about this, kudos to the PSF for standing for its values (which are also my values).&lt;/p&gt;
      &lt;p&gt;— Guido van Rossum (@gvanrossum), Oct. 29, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The day of the announcement, the PSF received about 300 new donations, Crary said — but then they’d kept coming. On Tuesday (Oct. 28), one Reddit user even complained their first try at donating was met with a timeout error — and Crary responded that apparently, “Our donation page got a little overwhelmed.”&lt;/p&gt;
    &lt;p&gt;Crary — who had also been the co-principal investigator on the withdrawn application — also acknowledged the supportive responses on Python’s official discussion forum, writing “We’re very grateful for the community’s support, which has been pouring in and has honestly been a little overwhelming.”&lt;/p&gt;
    &lt;p&gt;Throughout that week, Crary responded to several people who announced they were making donations to the PSF as a show of support. “I can’t tell you how much it has meant to see the community stand up with us today, after sitting with these tough circumstances for a while,” she said.&lt;/p&gt;
    &lt;p&gt;On Friday, less than two weeks after the announcement, the organization had seen some inspiring numbers, Deb Nicholson, PSF executive director, told TNS. “We’ve raised over $157,000,” including 295 new Supporting Members paying an annual $99 membership fee. And that’s just the beginning. “We know some donors are pursuing an employer match, and some community members have started their own matching campaign, which will also bump those numbers up.”&lt;/p&gt;
    &lt;p&gt;“It doesn’t quite bridge the gap of $1.5 million, but it’s incredibly impactful for us, both financially and in terms of feeling this strong groundswell of support from the community.”&lt;/p&gt;
    &lt;p&gt;“We zero percent expected a flood of support,” Crary added later, “and it’s been a huge deal for us.”&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We love the values of open source and @ThePSF‘s commitment to their community. Please read and share their story.&lt;/p&gt;
      &lt;p&gt;— Google Open Source (@GoogleOSS), Oct. 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Soon, the move had drawn news coverage from around the web. The conversation continued across several social media platforms. Their announcement also received 1,400 upvotes in Reddit’s Python subreddit and another 355 comments. It made the front page of Hacker News, drawing another 726 upvotes (along with 754 comments).&lt;/p&gt;
    &lt;p&gt;The PSF’s LinkedIn post about the decision began with this “TLDR” summary: “The PSF has made the decision to put our community and our shared diversity, equity, and inclusion values ahead of seeking $1.5M in new revenue.”&lt;/p&gt;
    &lt;p&gt;“In the end, it wasn’t a hard decision,” they wrote, saying they put their value (and community) first.&lt;/p&gt;
    &lt;p&gt;Within days, over 2,000 people clicked supportive “Reactions” on LinkedIn — with 361 reposts and 88 comments.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Happens Next?&lt;/head&gt;
    &lt;p&gt;Larson had another message. “I’m proud of what our little team has been able to accomplish, even if it’s not the result we imagined when Loren and I started this project almost a year ago.&lt;/p&gt;
    &lt;p&gt;“Everything we’ve seen since we announced our decision has only confirmed my feelings that Python is an amazing community to be serving. I couldn’t be happier about that.”&lt;/p&gt;
    &lt;p&gt;But will the work still go forward for what that grant was meant to cover? With an annual budget of roughly $5 million, according to a recent blog post, the $1.5 million grant would’ve represented a 30% boost in funding (spread across over two years) — “easily the largest grant we’d ever received.”&lt;/p&gt;
    &lt;p&gt;As the group’s security developer-in-residence, Larson had hoped to use the grant to improve screening for attempted supply chain attacks on the official PyPI registry of Python packages. The PSF blog post says the plan was to build tools for automating package reviews “rather than the current process of reactive-only review.”&lt;/p&gt;
    &lt;p&gt;Larson told me last week that the grant they’d applied for “included funding for multiple contracted positions over the two-year work period.” Sadly, he told me, “The automated package reviewing pipeline as proposed in the grant has no timeline to be implemented given current circumstances.”&lt;/p&gt;
    &lt;p&gt;The larger open source community would’ve also benefited from the work, their blog post noted, since “the outputs of this work could be transferable for all open source software package registries, such as NPM and Crates.io, improving security across multiple open source ecosystems.”&lt;/p&gt;
    &lt;p&gt;But Larson told me that moving forward without the grant also leaves far less room for that “additional work required to create artifacts that are adaptable to more than one software ecosystem — like documentation showing design, operation, results and performance.”&lt;/p&gt;
    &lt;p&gt;And, “We’ll now have to balance the roadmap of work and maintenance on the Python Package Index (PyPI) and CPython with only existing security staffing. This leaves far less room for new large-scale projects.”&lt;/p&gt;
    &lt;head rend="h2"&gt;A Future With Funding?&lt;/head&gt;
    &lt;p&gt;Could that same security project still happen if new funding materializes? The PSF hasn’t entirely given up. “The PSF is always looking for new opportunities to fund work benefiting the Python community,” Nicholson told me in an email last week, adding pointedly that “we have received some helpful suggestions in response to our announcement that we will be pursuing.”&lt;/p&gt;
    &lt;p&gt;And even as things stand, the PSF sees itself as “always developing or implementing the latest technologies for protecting PyPI project maintainers and users from current threats,” and it plans to continue with that commitment. For example, it notes, PyPI today implements Trusted Publishing (a tightly scoped alternative to publisher-verifying API tokens), digital provenance attestations and the ongoing malware-blocking efforts of Project Quarantine.&lt;/p&gt;
    &lt;p&gt;The PSF also has ideas for increasing its other funding going forward. (“We’re looking at European grants, revenue sources that are tied to corporate usage, and increasing our individual giving program,” Nicholson told me.) “Ultimately, we do need some of these new revenue channels to pick up in order to continue serving our mission and the Python community the way we have been: Python and PyPI usage has grown steadily, especially since Python is essential to the recent explosion of the AI sector, while our funding has stayed essentially flat.”&lt;/p&gt;
    &lt;p&gt;But this latest show of community support is especially heartening, arriving in a time of inflation, tech-sector economic pressures and “lower sponsorship,” the PSF’s blog pointed out (along with the general uncertainty and conflict). Writing that the PSF “needs financial support now more than ever,” they’d urged readers to show their support by buying PSF memberships or making a donation, or by encouraging their company to become a sponsor.&lt;/p&gt;
    &lt;p&gt;“If you’re already a PSF member or regular donor, you have our deep appreciation,” they wrote, “and we urge you to share your story about why you support the PSF.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thenewstack.io/psf-gets-a-donor-surge-after-rejecting-anti-dei-federal-grant/"/><published>2025-11-09T17:28:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45867717</id><title>Drilling down on Uncle Sam's proposed TP-Link ban</title><updated>2025-11-09T22:36:51.275795+00:00</updated><content>&lt;doc fingerprint="b6ccb110c1301700"&gt;
  &lt;main&gt;
    &lt;p&gt;The U.S. government is reportedly preparing to ban the sale of wireless routers and other networking gear from TP-Link Systems, a tech company that currently enjoys an estimated 50% market share among home users and small businesses. Experts say while the proposed ban may have more to do with TP-Link’s ties to China than any specific technical threats, much of the rest of the industry serving this market also sources hardware from China and ships products that are insecure fresh out of the box.&lt;/p&gt;
    &lt;p&gt;The Washington Post recently reported that more than a half-dozen federal departments and agencies were backing a proposed ban on future sales of TP-Link devices in the United States. The story said U.S. Department of Commerce officials concluded TP-Link Systems products pose a risk because the U.S.-based company’s products handle sensitive American data and because the officials believe it remains subject to jurisdiction or influence by the Chinese government.&lt;/p&gt;
    &lt;p&gt;TP-Link Systems denies that, saying that it fully split from the Chinese TP-Link Technologies over the past three years, and that its critics have vastly overstated the company’s market share (TP-Link puts it at around 30 percent). TP-Link says it has headquarters in California, with a branch in Singapore, and that it manufactures in Vietnam. The company says it researches, designs, develops and manufactures everything except its chipsets in-house.&lt;/p&gt;
    &lt;p&gt;TP-Link Systems told The Post it has sole ownership of some engineering, design and manufacturing capabilities in China that were once part of China-based TP-Link Technologies, and that it operates them without Chinese government supervision.&lt;/p&gt;
    &lt;p&gt;“TP-Link vigorously disputes any allegation that its products present national security risks to the United States,” Ricca Silverio, a spokeswoman for TP-Link Systems, said in a statement. “TP-Link is a U.S. company committed to supplying high-quality and secure products to the U.S. market and beyond.”&lt;/p&gt;
    &lt;p&gt;Cost is a big reason TP-Link devices are so prevalent in the consumer and small business market: As this February 2025 story from Wired observed regarding the proposed ban, TP-Link has long had a reputation for flooding the market with devices that are considerably cheaper than comparable models from other vendors. That price point (and consistently excellent performance ratings) has made TP-Link a favorite among Internet service providers (ISPs) that provide routers to their customers.&lt;/p&gt;
    &lt;p&gt;In August 2024, the chairman and the ranking member of the House Select Committee on the Strategic Competition Between the United States and the Chinese Communist Party called for an investigation into TP-Link devices, which they said were found on U.S. military bases and for sale at exchanges that sell them to members of the military and their families.&lt;/p&gt;
    &lt;p&gt;“TP-Link’s unusual degree of vulnerabilities and required compliance with PRC law are in and of themselves disconcerting,” the House lawmakers warned in a letter (PDF) to the director of the Commerce Department. “When combined with the PRC government’s common use of SOHO [small office/home office] routers like TP-Link to perpetrate extensive cyberattacks in the United States, it becomes significantly alarming.”&lt;/p&gt;
    &lt;p&gt;The letter cited a May 2023 blog post by Check Point Research about a Chinese state-sponsored hacking group dubbed “Camaro Dragon” that used a malicious firmware implant for some TP-Link routers to carry out a sequence of targeted cyberattacks against European foreign affairs entities. Check Point said while it only found the malicious firmware on TP-Link devices, “the firmware-agnostic nature of the implanted components indicates that a wide range of devices and vendors may be at risk.”&lt;/p&gt;
    &lt;p&gt;In a report published in October 2024, Microsoft said it was tracking a network of compromised TP-Link small office and home office routers that has been abused by multiple distinct Chinese state-sponsored hacking groups since 2021. Microsoft found the hacker groups were leveraging the compromised TP-Link systems to conduct “password spraying” attacks against Microsoft accounts. Password spraying involves rapidly attempting to access a large number of accounts (usernames/email addresses) with a relatively small number of commonly used passwords.&lt;/p&gt;
    &lt;p&gt;TP-Link rightly points out that most of its competitors likewise source components from China. The company also correctly notes that advanced persistent threat (APT) groups from China and other nations have leveraged vulnerabilities in products from their competitors, such as Cisco and Netgear.&lt;/p&gt;
    &lt;p&gt;But that may be cold comfort for TP-Link customers who are now wondering if it’s smart to continue using these products, or whether it makes sense to buy more costly networking gear that might only be marginally less vulnerable to compromise.&lt;/p&gt;
    &lt;p&gt;Almost without exception, the hardware and software that ships with most consumer-grade routers includes a number of default settings that need to be changed before the devices can be safely connected to the Internet. For example, bring a new router online without changing the default username and password and chances are it will only take a few minutes before it is probed and possibly compromised by some type of Internet-of-Things botnet. Also, it is incredibly common for the firmware in a brand new router to be dangerously out of date by the time it is purchased and unboxed.&lt;/p&gt;
    &lt;p&gt;Until quite recently, the idea that router manufacturers should make it easier for their customers to use these products safely was something of anathema to this industry. Consumers were largely left to figure that out on their own, with predictably disastrous results.&lt;/p&gt;
    &lt;p&gt;But over the past few years, many manufacturers of popular consumer routers have begun forcing users to perform basic hygiene — such as changing the default password and updating the internal firmware — before the devices can be used as a router. For example, most brands of “mesh” wireless routers — like Amazon’s Eero, Netgear’s Orbi series, or Asus’s ZenWifi — require online registration that automates these critical steps going forward (or at least through their stated support lifecycle).&lt;/p&gt;
    &lt;p&gt;For better or worse, less expensive, traditional consumer routers like those from Belkin and Linksys also now automate this setup by heavily steering customers toward installing a mobile app to complete the installation (this often comes as a shock to people more accustomed to manually configuring a router). Still, these products tend to put the onus on users to check for and install available updates periodically. Also, they’re often powered by underwhelming or else bloated firmware, and a dearth of configurable options.&lt;/p&gt;
    &lt;p&gt;Of course, not everyone wants to fiddle with mobile apps or is comfortable with registering their router so that it can be managed or monitored remotely in the cloud. For those hands-on folks — and for power users seeking more advanced router features like VPNs, ad blockers and network monitoring — the best advice is to check if your router’s stock firmware can be replaced with open-source alternatives, such as OpenWrt or DD-WRT.&lt;/p&gt;
    &lt;p&gt;These open-source firmware options are compatible with a wide range of devices, and they generally offer more features and configurability. Open-source firmware can even help extend the life of routers years after the vendor stops supporting the underlying hardware, but it still requires users to manually check for and install any available updates.&lt;/p&gt;
    &lt;p&gt;Happily, TP-Link users spooked by the proposed ban may have an alternative to outright junking these devices, as many TP-Link routers also support open-source firmware options like OpenWRT. While this approach may not eliminate any potential hardware-specific security flaws, it could serve as an effective hedge against more common vendor-specific vulnerabilities, such as undocumented user accounts, hard-coded credentials, and weaknesses that allow attackers to bypass authentication.&lt;/p&gt;
    &lt;p&gt;Regardless of the brand, if your router is more than four or five years old it may be worth upgrading for performance reasons alone — particularly if your home or office is primarily accessing the Internet through WiFi.&lt;/p&gt;
    &lt;p&gt;NB: The Post’s story notes that a substantial portion of TP-Link routers and those of its competitors are purchased or leased through ISPs. In these cases, the devices are typically managed and updated remotely by your ISP, and equipped with custom profiles responsible for authenticating your device to the ISP’s network. If this describes your setup, please do not attempt to modify or replace these devices without first consulting with your Internet provider.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://krebsonsecurity.com/2025/11/drilling-down-on-uncle-sams-proposed-tp-link-ban/"/><published>2025-11-09T18:17:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45868259</id><title>The Sega Master System</title><updated>2025-11-09T22:36:51.098581+00:00</updated><content>&lt;doc fingerprint="a227b4314dc4092d"&gt;
  &lt;main&gt;
    &lt;p&gt;We traditionally divide consoles into “generations”—the earliest devices like the Magnavox Odyssey are the first generation, the Atari 2600 is second, the NES third, the SNES and Genesis fourth, the PlayStation fifth, and so on. These divisions turn out to be pretty slippery when you look at them more closely—generations don’t really match product lineage, raw power, or year of release all that closely at all. The closest we come to a real division is that consoles in the same generation competed against one another as peers.&lt;/p&gt;
    &lt;p&gt;Sega’s third generation may be the most blatant gap there. The SG-1000 came out on the very same day as the Famicom, and it is reckoned as a third-generation console. However, its actual hardware closely matches the ColecoVision, released less than a year before but which is firmly in the second generation. It doesn’t spread terribly far, either. Sega doesn’t make a major play for the international market until 1986, three years after the original SG-1000 release and one year after Nintendo started selling the Famicom internationally as the NES. The NES was a slightly modified Famicom—firmly 1983 tech, albeit very good 1983 tech that had been dominant in Japan for some time by this point. Sega’s offering—the “Master System”—was based on their “Mark III” console from 1985. Those extra two years were pretty busy ones in home computing—1985 in particular sees the release of the Amiga 1000 and the MSX2, both of which offered far more sophisticated graphics than their predecessors. (Indeed, the MSX 1 released the same year as the SG-1000 and had the same graphics chip!) The Master System manages a similar jump as the MSX 1-to-2 advance, or as the Atari 5200 did from the 2600 earlier in the decade.&lt;/p&gt;
    &lt;p&gt;Also, much like the 5200, the Master System is reckoned as being in the same generation as its own predecessor, though unlike the 5200 the Master System is far more famous and successful than the system it succeeded.&lt;/p&gt;
    &lt;p&gt;(If you’re looking at the Japanese name of “Mark III” and assuming that the SG-1000 is the Mark I, you may be wondering where the Mark II went. The only real candidate for this is an SG-1000 in different packaging that came out along the way. We’re not missing anything important.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Head to Head&lt;/head&gt;
    &lt;p&gt;The Master System was clearly designed to compete directly with the Famicom, but it is also clearly designed to be a broadly-compatible upgrade to the SG-1000. Looking at what the system offers really requires us to compare it both to its predecessor and to its primary competitor. These sorts of comparisons are often a fool’s errand—in this era of home computing particularly, the core capabilities of different machines is so different even in operating principles that the only thing you can do is gesture at how they approached it—but these three systems all have enough in common in their core design that we are on firmer ground. It helps that the Master System’s VDP is explicitly a mostly-compatible upgrade to the SG-1000’s, and that the NES’s PPU is also very clearly inspired by the original principles of that 1979-era chip.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CPU Memory. The SG-1000 matched the ColecoVision, with a single kilobyte of memory visible to the CPU. The Famicom doubled that to 2KB, and the Master System jumped it up to 8. In 1987, an expansion system for the Famicom was releaesd in Japan called the Famicom Disk System or FDS which loaded games off of floppy disks instead of cartridges, and it offered 32KB of additional RAM to actually load games into. This replaced the memory normally mapped to the cartridge ROM but could be used as working RAM by the games themselves.&lt;/item&gt;
      &lt;item&gt;Video Memory. The SG-1000 also matched the ColecoVision here, with a full 16KB of VRAM that enabled full use of all of its graphics modes. The SMS does not meaningfully expand it further; 16KB is enough for its enhanced graphics as well. The only addition on this side is that its palette information is stored in an independent “Color RAM” that only holds 32 bytes. The Famicom only offers 2KB of ordinary video RAM, with 32 bytes of palette RAM elsewhere in the VRAM space, and 256 bytes of “Object Attribute Memory” for sprite data also split out into its own 256-byte bank. 2KB of VRAM is impossibly small; the Famicom’s innovation here is that 8KB of the cartridge ROM is actually mapped directly into the VRAM’s address space as “character ROM” or “CHR-ROM.” Those 8KB are backed by fast RAM in some later cartridges, and the FDS also does this for its disk-based software, ultimately raising the total space available to a hair over 10KB.&lt;/item&gt;
      &lt;item&gt;ROM Capacity. The SG-1000 had a hard 32KB limit on the “Sega Cards” that held its games. The Master System expands the ROM space to 48KB and relies on a standardized bankswitching mechanism to allow cartridges to expand up to 512KB. The Famicom relied on more manufacturer-specific bespoke on-cartridge hardware for this capability, with Nintendo requiring standardization to a set of models of their design in the international markets. Famicom bankswitching was generally a bit more sophisticated because its 32KB of CPU ROM space and its 8KB of VROM space needed to be independently controlled. The FDS allowed disks to be swapped so the limit here was more the patience of the end user. By the end of the system’s lifecycle, the largest games for both the NES and Master System were about a megabyte in size.&lt;/item&gt;
      &lt;item&gt;Resolution. The SG-1000 and Master System both offer 256×192 displays, while the Famicom expands this to 256×240. In practice, the visible display for all three systems generally ends up more like 248×192 just because analog TVs didn’t render the whole signal visible.&lt;/item&gt;
      &lt;item&gt;Color Depth. SG-1000 graphics modes are 1 bit per pixel, though sometimes specified at a high granularity allowing use of all the system’s colors. Famicom graphics are 2 bits per pixel, generally offering three colors plus a transparency. The Master System uses 4, allowing 15 non-transparent colors for any given graphic element.&lt;/item&gt;
      &lt;item&gt;Palette. The SG-1000 offers 15 unique colors that may be selected by various graphical elements but which may not be meaningfully remapped or arranged in palettes. The Master System offers 64 colors that are essentially a 6-bit RGB system, much like EGA graphics on the PC. From this a developer may create two 16-color palettes, one usable only by backgrounds and the other usable by backgrounds or sprites. The Famicom also offers 64 colors, but only 62 that are unique and usable, and arranged in a more miscellaneous way. From this gamut the developer again selects 32 colors, arranged into four palettes each for the background and sprites.&lt;/item&gt;
      &lt;item&gt;Sprites. The SG-1000’s TMS9918A offers 32 8×8 or 16×16 monochrome sprites, 4 of which may be active on any given scanline. The NES and Master System both offer 64 sprites, up to 8 active per scanline, that may either all be 8×8 or 8×16. Both Sega systems have a status bit that reports if any two sprites have collided, though it does not tell you which ones; the Famicom has a very strange sprite collision detector that works only for the first sprite and only checks for collisions against the background. More on this later.&lt;/item&gt;
      &lt;item&gt;Backgrounds and Scrolling. The SG-1000’s TMS9918A graphics chip offers a great many graphics modes, which I have documented in detail before. None of these meaningfully permit scrolling without rewriting the entire name table. The Master System defines a 32×28 graphics display, and any point within it may be designated the upper-left corner. The VDP lets one turn off the leftmost column of graphics, which gives the room necessary to smoothly scroll the screen in any direction. The Famicom offers enough VRAM for two side-by-side background screens, and these are arranged by the cartridge logic to be either aligned horizontally or vertically. Due to the way backgrounds are encoded, it is significantly more difficult to completely hide scroll seams when scrolling diagonally on the NES. Even highly regarded late-era games like Super Mario Bros. 3 and Mega Man 3 have obvious glitches sometimes. All systems that support scrolling effectively support it by having the developer write X and Y scroll values to a pair of control registers.&lt;/item&gt;
      &lt;item&gt;VDP Register and VRAM Access. All of these systems access VRAM in similar ways. There is a “control port” to which the developer writes a two-byte address, and then a “data port” to which bytes are then written or read in sequence. The SG-1000 and Master System treat registers almost like a special kind of VRAM; registers are set by writing two command bytes to the VDP control port. Most of the Famicom’s registers, on the other hand, are directly mapped into the CPU’s address space starting at &lt;code&gt;$2000&lt;/code&gt;. The big exception is the 16-bit internal VRAM pointer, which is adjusted by writes to&lt;code&gt;$2005&lt;/code&gt;(when editing scrolling values) and&lt;code&gt;$2006&lt;/code&gt;(when doing more ordinary byte-oriented VRAM access).&lt;/item&gt;
      &lt;item&gt;Timing Restrictions. Both Sega systems maintain a fairly strict buffer between the developer and the VDP’s internal state. As a result, it is possible on both systems for command or data bytes to be “missed” by the VDP if they are overwritten before it can spare time to actually check its inputs. The Famicom exposes its internals much more directly to the developer, and all writes to any control register take effect, for all practical purposes, immediately. The timing restrictions on the Famicom instead are more macro-scale; the 16-bit internal VRAM pointer is used by the PPU for fetching the data required to draw the backgrounds, so attempting to access VRAM outside of VBLANK is likely to end up reading or writing the wrong locations.&lt;/item&gt;
      &lt;item&gt;Split Screens and Raster Effects. The SG-1000 offers no particular support for mid-frame configuration updates to allow for split-screen or other raster-level effects. The Famicom’s bizarre single-sprite collision detection is intended to trap exactly these cases; developers were expected to engineer a sprite-to-background collision at the appropriate split point and then edit control registers as needed at that point. As noted above, mid-screen PPU state is fragile enough that it was challenging to do much besides split-screen scrolling, but that was usually enough. Later cartridges included circuitry that could count scanlines and set interrupts to occur at specific points on the screen. The Master System backed similar hardware directly into its VDP, allowing for multiple regularly-spaced interrupts over the course of a screen. However, as part of its buffering of state away from the developer, vertical scrolling values could not actually be changed mid-frame. To account for this, it includes a special extra hardware mode that simply excludes the top two rows or right eight columns of the display from scrolling, prefiguring the “window layer” we’d later see in the Genesis and the Game Boy.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One of the themes that emerges from this is a difference in design philosophies—and one that I think extends at least out to the SNES and Genesis, too. Sega’s designs are more “down-to-earth”; programming it generally feels to me like “ask for this capability that was designed-in, and get it.” Nintendo’s systems, on the other hand, generally feel like they need to me to combine a number of independent mechanisms to get the result. (Compare the Master System’s hardwired split-screen to the Sprite 0-hit mechanism on the NES, for instance, or the wild profusion of effects on the SNES that boil down to “combine the HDMA subsystem with some other feature“.) As part of this, the Sega designs also retain a lot of the safeguards that Nintendo’s chips scrapped. Before this year I figured that the Genesis VDP let me write VRAM during active display thanks to the 16-bit era finally letting us get proper bus arbiters; that feature actually goes all the way back to 1979 and it was Nintendo’s PPUs that dropped the capability. In dropping it, and removing any barrier between the user-accessible VRAM pointer and the values used to drive the active display, Nintendo ended up accidentally permitting a wider array of raster-scrolling effects than they thought were possible originally. (We know they did not plan the effects used in Rockman 6 originally, because The Legend of Zelda does not exploit them and the display glitches a bit as a result. The Master System goes out of its way to make itself a more solid foundation—but a more solid foundation is also less flexible.&lt;/p&gt;
    &lt;p&gt;The Nintendo approach ends up looked on more kindly later on, I think—there’s room for the console’s power to grow with the expertise of its developer community—but I will freely admit that in the moment programming systems that use the Sega approach is more pleasant.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cartridge Structure&lt;/head&gt;
    &lt;p&gt;Cartridges had standard sizes from 8KB through 1MB, and there were 16 bytes of identifying information at the end of the first 32KB. (Cartridges shorter than 32KB just had it as their last 16 bytes.) This included a simple checksum, though I’ve gotten the impression that some models didn’t enforce it so some commercial software didn’t respect it either. Nevertheless, for my own work I created a simple “SMSFIX” utility that would expand simple assembled binaries to an appropriate size and document that appropriately.&lt;/p&gt;
    &lt;p&gt;Simple cartridges smaller than 32KB just loaded their entire contents into the first 32KB of RAM, mirroring themselves if necessary. Larger ones made use of a standard memory mapper and this only locked in the lowest 1KB of RAM. Somewhere in that code the developer was obliged to configure the memory-mapping registers, and Sega’s recommended approach for this was to lock down the lowest 32KB and then swap out the &lt;code&gt;$8000-$BFFF&lt;/code&gt; region with 16KB blocks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Writing a BIOS&lt;/head&gt;
    &lt;p&gt;The RAM, I/O port, and VDP design of the Master System were designed to be largely backwards-compatible with the SG-1000. This means that I should be able to reuse the earlier work I did creating a BIOS-like support library for the SG-1000 and adapt it pretty readily to the Master System as well.&lt;/p&gt;
    &lt;p&gt;As it turned out, attempting this worked so well that it made more sense to just block out the changes under some conditional-assembly defines like &lt;code&gt;ifdef SMS&lt;/code&gt; or &lt;code&gt;ifdef SG1000&lt;/code&gt; and only make the necessary alterations in those places:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The SMS has four additional I/O ports that we should define.&lt;/item&gt;
      &lt;item&gt;The stack pointer starts in a different place since we have more RAM.&lt;/item&gt;
      &lt;item&gt;Likewise, we have more memory to clear when we clear RAM during startup.&lt;/item&gt;
      &lt;item&gt;Color RAM must be cleared on its own on the Master System since it’s not just part of VRAM the way the SG-1000’s color tables were.&lt;/item&gt;
      &lt;item&gt;While the SG-1000’s VDP was highly configurable, and the SMS’s VDP has just as many knobs attached, there was an acknowledged canonical memory layout for the SMS that made good use of the entire 16KB of VRAM. We should initialize the VDP to that known-good configuration on startup.&lt;/item&gt;
      &lt;item&gt;There are two possible IRQ sources on the Master System; our built-in handler should be able to identify mid-frame interrupts, and both skip the frame-only operations on those and also forward them to an alternate handler.&lt;/item&gt;
      &lt;item&gt;We also should initialize the mapper circuitry, if any.&lt;/item&gt;
      &lt;item&gt;One thing I expected to need but didn’t turn out to need was a special call for writing values to color RAM. It turns out that the way I’d implemented the various VRAM-writing functions effectively mapped the 16KB of VRAM proper to &lt;code&gt;$0000-$3FFF&lt;/code&gt;and then the 32 bytes of CRAM to&lt;code&gt;$8000-$801F&lt;/code&gt;. I’ll take it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The official documentation for the Master System suggested an additional complication: when it described the VDP timing requirements it suggested that the Master System’s VDP needed to be written more slowly than the SG-1000’s. It purported to require a 16-cycle gap between writes during VBLANK and a 29-cycle gap during active display. My own calculations agreed with the 29-cycle number but only expected an 8-cycle gap needed during VBLANK. Enthusiasts at the SMS Power Forum actually did the timing experiments and discovered that the VBLANK number is closer to 3 cycles (impossible to violate on a Z80) and that the active-display value was more like 26 cycles. I’m going to stick with my SG-1000-level timing here, but we may be pretty confident that this will work out fine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Project Plans&lt;/head&gt;
    &lt;p&gt;The first thing I did was port over my sample Hello World program to make sure that my SMSFIX program and my adapted BIOS actually worked.&lt;/p&gt;
    &lt;p&gt;Moving forward, after learning about how much the Master System actually offered, I realized that I could actually recreate one of my first Sega Genesis projects over to the Master System with effectively no compromises. After that I think I’m going to want to create some more ambitious display, pushing right up to the level where we’d start really wanting the power of the Genesis to enhance it further.&lt;/p&gt;
    &lt;p&gt;After the rest of the systems I’ve poked at this year, the Master System really feels both very familiar, yet shockingly powerful given the expectations I brought in. This should be a fun time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bumbershootsoft.wordpress.com/2025/11/08/the-sega-master-system/"/><published>2025-11-09T19:15:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45868533</id><title>The Computer Church – Pennsylvania Computer and Technology Museum</title><updated>2025-11-09T22:36:50.385300+00:00</updated><content>&lt;doc fingerprint="e50519d110f5e775"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open by Appointment Fall 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;•O U R C O L L E C T I O N•&lt;/head&gt;
    &lt;head rend="h1"&gt;ANALOG COMPUTERS&lt;/head&gt;
    &lt;p&gt;Our collection of over 50 analog computers is the largest known collection in the world. It contains some of the rarest, most unique analog computers known to exist. &lt;lb/&gt; These computers were critical in post-WWII era and were used by the military to develop the most advanced aircraft and artillery of the times and by NASA for their earliest space programs.&lt;/p&gt;
    &lt;head rend="h1"&gt;ANALOG COMPUTERS&lt;/head&gt;
    &lt;p&gt;Analog computers of the 1940s and 1950s played a pivotal role in laying the foundational concepts and methodologies that would shape our modern digital computing landscape. &lt;lb/&gt;These machines introduced the fundamental idea that complex mathematical problems could be solved by machines, demonstrating that machines could solve problems that had, until then, only been solved by humans educated in mathematics!&lt;/p&gt;
    &lt;head rend="h1"&gt;ANALOG SUPERPOWERS&lt;/head&gt;
    &lt;p&gt;This highly regarded review of international governmental theft, published on Oct. 2024, features a cover-image of one of the oldest analog computers in our collection. &lt;lb/&gt;The author, Dr. Epstein, traveled to The Computer Church so she could get a perfect image of the technology that is the focus of the book...the gears at the heart of the controversy.&lt;/p&gt;
    &lt;head rend="h1"&gt;ANALOG SUPERPOWERS&lt;/head&gt;
    &lt;p&gt;But this particular computer is very special for an entirely different reason! &lt;lb/&gt;This "Rangekeeper Mark VII" that is pictured was the fire-control computer for the big guns on the USS St. Louis, a light cruiser that was in Pearl Harbor for routine maintenance on the morning of December 7, 1941. &lt;lb/&gt;The St. Louis earned the nickname the "Lucky Lou" when it became the first ship to make it out of Pearl Harbor during the attack.&lt;/p&gt;
    &lt;head rend="h1"&gt;• RESEARCH LIBRARY •&lt;/head&gt;
    &lt;head rend="h3"&gt;Homebrew Computer Club&lt;/head&gt;
    &lt;p&gt;This Newsletter stands as one of the most influential publications in the formation of Silicon Valley's technological culture and the personal computer revolution. Created and edited by its members, it initiated the idea of the personal computer and helped its members build early kit computers.&lt;/p&gt;
    &lt;head rend="h4"&gt;1975&lt;/head&gt;
    &lt;head rend="h3"&gt;Computer Notes&lt;/head&gt;
    &lt;p&gt;Computer Notes started as a company publication for MITS, but it became an important bridge between members of the emerging personal computer community. Among the key articles to appear was the 1976 publication of Bill Gates's famous "Open Letter to Hobbyists" which addressed intellectual property concerns in the new software industry.&lt;/p&gt;
    &lt;head rend="h4"&gt;1976&lt;/head&gt;
    &lt;head rend="h3"&gt;Hollerith Tabulating Machine&lt;/head&gt;
    &lt;p&gt;This is Hollerith personal copy of his article about the Tabulating Machine. &lt;lb/&gt; Unique, this is the only known copy. The handwritten note at the top of the cover likely refers to drawings of the Tabulating Machine that were sent to the Franklin Institute (Phila.) regarding an award they were presenting to Hollerith. &lt;/p&gt;
    &lt;head rend="h4"&gt;1889&lt;/head&gt;
    &lt;head rend="h3"&gt;Nieman Marcus Catalog&lt;/head&gt;
    &lt;p&gt;Each year the famed Nieman Marcus store offers a Christmas Catalog that contains an outrageously expensive gift for a man and a woman. in 1969 they featured an expensive "Kitchen Computer". Mostly a publicity stunt, the computer included a cutting board and was advertised as useful place for storing recipes!&lt;/p&gt;
    &lt;head rend="h4"&gt;1969&lt;/head&gt;
    &lt;head rend="h3"&gt;Moore School Lectures&lt;/head&gt;
    &lt;p&gt;From July 8th through August 31st 1946, the University of Pennsylvania's Moore School of Electrical Engineering hosted 28 invited students to the world's first course on digital computers. Over six weeks, leading engineers and scientists discussed the experiences of the ENIAC and EDVAC.&lt;/p&gt;
    &lt;head rend="h4"&gt;1947&lt;/head&gt;
    &lt;head rend="h3"&gt;Time Magazine&lt;/head&gt;
    &lt;p&gt;Vannevar Bush's multifaceted contributions to computer development established him as a foundational figure in both the analog and digital computing eras. He was TIME Magazine's 1944 Man of the Year. And just a year later, his visionary essay As We May Think inspired generations of computer scientists.&lt;/p&gt;
    &lt;head rend="h4"&gt;1944&lt;/head&gt;
    &lt;head rend="h3"&gt;Electronics Magazine&lt;/head&gt;
    &lt;p&gt;This issue featured General Sarnoff on the cover (Head of RCA and an early proponent of TV) but is best known for an article by Gordon Moore about the increasing speed/power of computers. While Moore's Law is certainly aging, it still is valued by many in the computer industry.&lt;/p&gt;
    &lt;head rend="h4"&gt;1965&lt;/head&gt;
    &lt;head rend="h3"&gt;Punch Card Tabulation&lt;/head&gt;
    &lt;p&gt;This book by Leon Truesdell traces the development of Hollerith's punch card system from 1890 to 1940. This book is considered the definitive institutional account of the evolution from hand-written era of data collection within the U.S. Census Bureau.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.thecomputerchurch.org/"/><published>2025-11-09T19:47:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45869146</id><title>Ask HN: What Are You Working On? (Nov 2025)</title><updated>2025-11-09T22:36:49.589521+00:00</updated><content>&lt;doc fingerprint="b758405369a5b6f8"&gt;
  &lt;main&gt;
    &lt;p&gt;Currently working on a take on Pokémon GO + Pokémon Snap but for birding. The goal is to explore your neighborhood, find birds, take good photos of them all. Next month, I'll be doing an event to find a rare bird, excited to see how it goes!&lt;/p&gt;
    &lt;p&gt;I'm resurrecting peer-to-peer Matrix (https://arewep2pyet.com) thanks to the Dutch government, who started funding it in October.&lt;/p&gt;
    &lt;p&gt;The main question is which P2P overlay network to use, if any: the prior incarnation used Pinecone (a variant of Yggdrasil), whereas this time we're pondering keeping it simpler and more scalable and using Matrix itself as the backbone to connect together smallish local P2P meshes - so by default you try to route via Matrix, but failing that you look on your LAN or BLE to see if you can talk directly to whoever you're addressing. Time will tell if this works :)&lt;/p&gt;
    &lt;p&gt;Discovered in-door bouldering / rock climbing and now go 3x a week, am absolutely loving it! Because of that, I haven't really worked on any side projects in a while. Perhaps I don't need to? My job advances me plenty in my field, but it is a bit of a bitter-sweet feeling in a sense, like maybe I should try to squeeze more out of my free time somehow.&lt;/p&gt;
    &lt;p&gt;I’ve been hesitant for fear of injury harming the ability to type, but might give it a go in the spring. Thanks for mentioning this I’m inspired to try it finally.&lt;/p&gt;
    &lt;p&gt;I’ve been climbing for 20 years and it’s the thing that prevents RSI for me and makes it possible to use a computer too much :). Certainly possible to injure fingers but would be a very rare climbing injury that would threaten coding.&lt;/p&gt;
    &lt;p&gt;I'm working on a web app that creates easy-to-understand stories and explainers for the sake of language learning. You can listen in your favourite podcast app, or directly on the website with illustrations.&lt;/p&gt;
    &lt;p&gt;Most of the testing so far is English/French/Japanese/Mandarin, but I'm eager to add more languages if anyone is fluent and willing to help me evaluate the text-to-speech.&lt;/p&gt;
    &lt;p&gt;Bread and butter stuff. Pulling together all of the assorted algorithms and data structures I implemented in C over the years out of necessity - lists, trees, stacks, queues, hash tables, memory pools, etc. - aligning the APIs, cleaning up and merging into a library. It's a background project but super fun. This and several parsers - JSON, some config file formats, and parsers for some GPS / GNSS receiver data protocols. FSMs also always feel like nice, clean fun. And prematurely optimising every bit.&lt;/p&gt;
    &lt;p&gt;It looks inside each file to see what it’s about, then moves it to the right folder with a single click. Everything happens on your Mac, so nothing leaves your computer. No clouds, no servers.&lt;/p&gt;
    &lt;p&gt;It already works with images, Office (Word, Excel, PowerPoint) PDFs, ePubs, text, Markdown, and many other file types (30+) in English. Next I’m adding multi-language support.&lt;/p&gt;
    &lt;p&gt;If you have messy folders anywhere on your Mac, Floxtop can help.&lt;/p&gt;
    &lt;p&gt;I finally started modding a total war game (Warhammer 3). I played the series since the very first title, Shogun and I always wanted to improve the control over units and add my custom AI to not micromanage everything, but assumed it would be too time consuming and distracting from my main work. And well, it likely would have been.&lt;/p&gt;
    &lt;p&gt;But thanks to LLMs, I finally decided to give it a go and got something basic working in a short time, hurrey for AI assisted coding!&lt;/p&gt;
    &lt;p&gt;Feels empowering to be honest. No idea if I will really implement the main ideas, that I have since a long time, but I know that I can now if I want to.&lt;/p&gt;
    &lt;p&gt;People use Puter for an incredibly wide range of things, including cloud storage, web hosting, coding, AI, and gaming. Right now, we're mostly focused on improving performance and making sure that it's as fast as a regular desktop environment!&lt;/p&gt;
    &lt;p&gt;It's an explorable database of films, TV shows, books and board games based around their historical setting: where and when the thing is set. It's been incredibly complex and interesting getting the (messy) data, making sense of it and trying to design a UI to explore it.&lt;/p&gt;
    &lt;p&gt;It's a honeypot system that uses AI to mess with attackers. When someone tries to hack your app, it detects them and serves up fake responses based on attack type.&lt;/p&gt;
    &lt;p&gt;The system learns from attackers behavior and creates convincing decoys to waste their time and frustrate their efforts. It's basically a trap that gets smarter the more attackers poke at it.&lt;/p&gt;
    &lt;p&gt;Finished: the 100%-vibe-coded "GPT-5 reviews all my PRs on max reasoning" GitHub app (which is shockingly effective, https://github.com/Smaug123/robocop - probably nothing new for people who already use some product like this, but I like owning my own infrastructure as far as possible, and GPT-5 and perhaps Gemini are the only models smart enough to do this so I can't take this any further).&lt;/p&gt;
    &lt;p&gt;Currently: back on "write an immediate-mode TUI framework that uses a vdom as its fundamental abstraction" (https://github.com/Smaug123/WoofWare.Zoomies), in the hope that this is the first UI framework that I don't absolutely loathe.&lt;/p&gt;
    &lt;p&gt;Next: using the TUI framework, write a debugger to inspect the internal state of my deterministic .NET runtime (https://github.com/Smaug123/WoofWare.PawPrint) and to step forward and backward in time.&lt;/p&gt;
    &lt;p&gt;Next: get the deterministic .NET runtime to a point where a property-based testing framework can identify the deadlock in some very simple buggy multithreaded code. (The framework is not yet able to run Hello World - did you know that's an incredibly complicated program in .NET? - but it can solve a few Advent of Code problems right now, can perform some limited exception handling, limited virtual method dispatch, limited casting between types. Even getting to Hello World might take a year if I'm unlucky.)&lt;/p&gt;
    &lt;p&gt;I'm working on a Yelp alternative called Vibehuntr -- just something different to browse venues using Google's API, with a social layer so I can see what my friends like. It's very rough around the edges right now and it might be completely different by next week. It's been a fun experiment in vibe coding on a full stack. https://vibehuntr.io&lt;/p&gt;
    &lt;p&gt;I just launched a 10-Bit Video Thumbnail Provider for Windows.&lt;/p&gt;
    &lt;p&gt;Windows does not natively support rendering thumbnails for 10-bit videos, which are commonly produced by cameras like the Sony A7IV.&lt;/p&gt;
    &lt;p&gt;When I started working on a short film the video clips were piling up on my hard drive. Opening them one by one to find what I was looking for was tedious.&lt;/p&gt;
    &lt;p&gt;I could not find a reputable solution to this problem, so I started a company and built one. I went through the process of EV Certification to have the installer and executable code signed.&lt;/p&gt;
    &lt;p&gt;I hope to be in the Microsoft Store soon.&lt;/p&gt;
    &lt;p&gt;I'm also building other utilities with similar purpose.&lt;/p&gt;
    &lt;p&gt;I wrote a pretty complicated set of GNU Makefiles for a simulation library at work, but was annoyed I had to work so hard to avoid collisions, so I'm working on a "more sanitary" build-your-own-build-system/build-system-kernel type deal.&lt;/p&gt;
    &lt;p&gt;I’m building a typed, array-oriented dataflow compiler that takes small declarative schemas and emits plain Ruby and JavaScript, with a C path. It has a mid-end with inlining, common subexpression elimination, constant folding, dead code elimination, loop fusion, and LICM.&lt;/p&gt;
    &lt;p&gt;A cpp code generator like esphome, to generate the firmware for midi devices in a simple yaml file, for raspberry Pico.&lt;/p&gt;
    &lt;p&gt;It would have been so much easy just to program the midi hub I wanted to program but wanted to make it generic.. now I can make the firmware for any configuration in seconds!&lt;/p&gt;
    &lt;p&gt;I'm building Your Next Store (YNS); it's a Shopify alternative built with React and Next.js.&lt;/p&gt;
    &lt;p&gt;We provide an opinionated boilerplate tailored for tools like Claude or Codex, so designers and developers can build storefronts faster and more easily. It enforces a clear structure to start from while keeping full control over design, animations, and the overall storefront experience. It’s built on top of Stripe, with our higher-level commerce abstractions, like "add to cart", "checkout", "pay", "browse products" etc; plus a Commerce CMS so merchants can manage everything smoothly once their store is live.&lt;/p&gt;
    &lt;p&gt;If youre planning to sell something online and want a modern solution, hit me up! :)&lt;/p&gt;
    &lt;p&gt;I'm working on a command-line tool for advanced full-text search of written documents. It works in a completely different way than grep, so it can do a lot of operations that grep fundamentally cannot like proximity searching.&lt;/p&gt;
    &lt;p&gt;I called it Wosp for word-oriented search and print. I released the first functional version a few days ago: https://github.com/atrettel/wosp&lt;/p&gt;
    &lt;p&gt;DIY grid-tied residential solar+inverter+battery. Trying to design the solar arrays' tilt mechanism now for lifting/lowering 5 panels at a time in winter (60-degree winter angle, 35-degree spring/summer/fall; ~24" difference). Thinking either two linear actuators, or a single hydraulic jack connected to multiple support beams. The weight isn't much, but I want a way to lift entire top edge at once to prevent twisting. Linear actuators are slightly more money and easier to build, but require power and weather-proofing. Jack is cheaper, but more complex to distribute force. Wondering if there's other options. (winch would require more robust/taller rear posts, seems more complex, might shade rear array)&lt;/p&gt;
    &lt;p&gt;Porting LevelDB[1] to Seastar[2], for internal metadata storage in Redpanda[3]. Before you ask why can’t something off the shelf be used, seastar has unique constraints around its runtime and its memory allocator that means we can’t reuse an existing library.&lt;/p&gt;
    &lt;p&gt;I've been working on two game development projects for the past couple of years.&lt;/p&gt;
    &lt;p&gt;One project is for building rhythm games in multiple game engines and multiple platforms. Currently, it works in Unity, Unreal, Godot, SDL (or any C++ game engine), and MonoGame (or any C# game engine), and runs on Windows, macOS, and Linux. I'm working on adding Love2d (or any Lua game engine) and Bevy (or any Rust game engine). I have a few local prototypes of it working in Unity and Godot, but nothing public yet. Still trying to figure out what kind of game I want to make with it.&lt;/p&gt;
    &lt;p&gt;The other is a general purpose game engine in C++ with SDL. It's far enough along that I'm building games in it, but it's more of an exploration into how games are made than a replacement for Unity or Godot. I suppose it could be eventually, but I'm trying to be realistic with what it can do. One thing I'm pretty happy with regarding this engine is that one of the demo repos will automatically build to WebGL and publish to itch.io when changes are pushed.&lt;/p&gt;
    &lt;p&gt;I’m building Sink It for Reddit (https://gosinkit.com), a browser extension to make Reddit usable on the web. It’s similar to RES with broader support for all the different Reddit UIs (there are 4).&lt;/p&gt;
    &lt;p&gt;It’s mostly free with only old Reddit features gated behind a one time $5 fee. The app has a few hundred thousand users on the Apple platforms but recently it was invited to join Mozilla’s Recommended Extensions program so I’m hoping to grow the non-Apple user base.&lt;/p&gt;
    &lt;p&gt;I have found that duplicated tabs can be useful e.g. for pages where footnotes are not hyperlinked in the text. When this happens I open a duplicate tab and scroll to the bottom of the page on it.&lt;/p&gt;
    &lt;p&gt;oh, for sure, that's why the extension shows which tabs are duplicated, and I can kill the duplicates individually, but also has a kill-all-duplicates button&lt;/p&gt;
    &lt;p&gt;I'm working on https://yap.town - an SRS based language learning app.&lt;/p&gt;
    &lt;p&gt;I would say it combines the best parts of Duolingo and Anki. Anki is great for memorizing words, but you don't see the words in the context of novel sentences. Duolingo is great for exposure to new sentences, but it's oriented around "lessons" and SRS is an afterthought. (Duolingo is also not designed for people serious about learning a language IMO, it's too easy and goes too slowly.)&lt;/p&gt;
    &lt;p&gt;Had to do quite a bit to get it to work well.&lt;/p&gt;
    &lt;p&gt;1. At first you would think that if you know all the words in a sentence, that should be enough to understand the sentence. But it doesn't work like that. For starters, words can have multiple meanings. The french word "bois" can mean "(you) drink" or "wood". You want to learn these separately. I trained an NLP model (a gemma3 finetune) that I use to understand the manner each word is used in each sentence: https://huggingface.co/collections/anchpop/lexide-nlp-models&lt;/p&gt;
    &lt;p&gt;2. Even then, what about a sentence like "you'd better not"? Even if you know the words "you" "had" "better" and "not", you still won't really get this. So I use the wiktionary "multiword terms" category for each language to get a huge list of terms like "'d better" , "you better believe it", etc, and teach these in addition to individual words. And then I only show sentences where you know all the individual words as well as all the terms.&lt;/p&gt;
    &lt;p&gt;A filmmaker community for those wanting to showcase their work. Right now everyone's got their own squarespace and the problem is that about 0 filmmakers also want to be web masters.&lt;/p&gt;
    &lt;p&gt;No projects at the moment. Just working on myself and improving some things in my life, job, cheaper place to rent, lose weight etc. Dreaming of starting a business, I just want to add a cool service to my local city but the economics is hard&lt;/p&gt;
    &lt;p&gt;Why? I love the old arcade and game boy games, and I want to recreate them to my liking. I also love mechanical systems and space rovers, and I want ro build worlds to explore and simulate these things&lt;/p&gt;
    &lt;p&gt;A kernel extension-less sshfs for macOS. I tried using FSKit and got halfway before I felt too constrained by the extension security model (must be app sandboxed, must be approved by the user in system settings). Now it’s just a standalone command line binary that doesn’t require any special permissions since it proxies NFS to SFTP. Everything “just works” and performance is reasonable&lt;/p&gt;
    &lt;p&gt;I’m working on Reflect [0], it’s a privacy-focused app for self-tracking and self-discovery. You can track metrics, run self-experiments, set goals, view correlations, visualize your data, etc.&lt;/p&gt;
    &lt;p&gt;Imo, you really should use a pure white background for the App Store screenshots instead of the current greyish background which looks kind of depressing.&lt;/p&gt;
    &lt;p&gt;On and off working on the Navigation API for Node, Bun, Deno, &amp;amp; as a browser polyfill.&lt;/p&gt;
    &lt;p&gt;Has 90% test coverage, makes use of web platform tests to verify compatibility, and is in use by some larger companies already with the Navigation API soon to become a baseline in evergreen browsers.&lt;/p&gt;
    &lt;p&gt;The Navigation API effectively is async state navigations. The likes of React has recently added Navigation API support to make use of the browser reload indicator.&lt;/p&gt;
    &lt;p&gt;I've been building a little toy computer and assembly language that's interpreted in python. Pretty close to the first release (and introductory blog post) and a lot of fun to build (and learn a bit more about real assembly as I go).&lt;/p&gt;
    &lt;p&gt;Working on adding Apple Intelligence to my macOS app built to analyze iOS app size metrics. I'm hoping to have a locally running assistant that can act like an iOS build engineer to provide optimization opportunities and more: https://apps.apple.com/us/app/dotipa/id6742254881.&lt;/p&gt;
    &lt;p&gt;Right now my app allows users to export build metadata as JSON which can be interpreted by LLMs for analysis, but I'd like to have this work on-device.&lt;/p&gt;
    &lt;p&gt;A FLAC encoder/decoder written in Guile scheme. I struggled to get the decoder working with most test files for a while until recently. It's more or less a fully functional decoder now. It's also 1:1 with the reference meta-flac command currently as well.&lt;/p&gt;
    &lt;p&gt;Create a script for a product demo or tutorial for your app using an extension. The script is used to generate your product content in multiple formats (narrated video, interactive demo, looping animation, and in-app guide). Whenever your product changes, just update the script and regenerate everything. No manual re-recording of video, syncing of audio, or any other post-production steps.&lt;/p&gt;
    &lt;p&gt;Building https://www.hessra.net/, an authorization system based on the Biscuit token format (decentralized, signed, and attenuable). The goal is to push beyond JWTs and Zanzibar-style policy engines by giving every machine-to-machine request its own embedded, verifiable authorization logic in a small capability token. These tokens can be delegated, restricted, and verified locally with no extra network calls required after getting the token.&lt;/p&gt;
    &lt;p&gt;Early use case is replacing API keys with identity tokens that expire, delegate, and prove possession and then can be used for easy step up to fine-grained authorization. There's some pretty interesting authorization stuff you can do, like having multiple parties sign off before a token is valid or requiring a series of micro-services sign a token for it to be valid.&lt;/p&gt;
    &lt;p&gt;I'm working on https://teeming.ai, trying to solve the information asymmetry problem in the job market.&lt;/p&gt;
    &lt;p&gt;The project has been a huge learning curve for me - I started out as a skeptic of how generative AI could solve real problems (rather than just create noise) but now think that, like the internet, it can create a new kind of abundance that will be harnessable in all sorts of interesting ways.&lt;/p&gt;
    &lt;p&gt;A Mac-based video manager that automatically transcribes, translates and summarises videos. I process information best through reading, so I built it to manage my growing collection of training course videos, webinars and meeting recordings. Currently working on adding RAG search to make it easier to query content.&lt;/p&gt;
    &lt;p&gt;Also building a CMS and static site generator that runs entirely client side in the browser. Pick themes, model content an publish to clean HTML. It also makes content available beyond just the browser, eg in a command line TUI.&lt;/p&gt;
    &lt;p&gt;Very cool. I make a consulting business out of packaging selenium scripts into windows apps for small businesses, do you have any desire to turn this into a saleable product?&lt;/p&gt;
    &lt;p&gt;Stagehand is our open source project, but the company behind it is called Browserbase - https://browserbase.com/ where we run headless browser infrastructure as a service. So no interest at this point, Browserbase drives the revenue that funds Stagehand!&lt;/p&gt;
    &lt;p&gt;An Intent is a self-contained document that describes a user request. It is composed of three main sections: WHY (the motivation), WHAT (the requirements, often in Gherkin language), and HOW (a detailed, step-by-step implementation plan defined with tasks). This approach ensures clarity and alignment before any code is written.&lt;/p&gt;
    &lt;p&gt;Building https://ottex.ai - a native MacOS app to solve repetitive micro tasks on a computer.&lt;/p&gt;
    &lt;p&gt;- Transcribe voice to text (especially useful when you need to explain something to Claude code )&lt;/p&gt;
    &lt;p&gt;- (soon) select text to instantly Check grammar / Improve writing / change tone of text&lt;/p&gt;
    &lt;p&gt;- (soon) select text to Translate between languages&lt;/p&gt;
    &lt;p&gt;I discovered that I have a few 10/20$ subscriptions (grammarly, raycast, wisperflow) that do embarrassingly simple stuff I can one shot with cheap SLM. So I decided to build a one app specialized in small repetitive tasks on computer.&lt;/p&gt;
    &lt;p&gt;I created this recently but have let it fallow in the last month. Planning to update it over the next few days / weeks. There are a crazy number of directions I could take it.&lt;/p&gt;
    &lt;p&gt;Working on https://gametje.com (a Jackbox games competitor). Been working on the Android TV app lately. Will probably start creating a new game next week with acronyms similar to the old game Acrophobia from the late 90s/early 2000s.&lt;/p&gt;
    &lt;p&gt;I posted in this monthly thread first time in May when I launched a daily logic puzzle, Clues by Sam. Since then it's grown significantly, and I couldn't be happier!&lt;/p&gt;
    &lt;p&gt;The game has a farily simple frontend, but there is a fairly complex constraint solving algorithm as part of the puzzle making process. What makes the puzzle quite unique is that you can't "guess". You can only make guesses that are provable by logic. The algorithm ensuring this has worked flawlessly for months now (though I've manually inserted some silly mistakes once or twice).&lt;/p&gt;
    &lt;p&gt;Today's puzzle is one of the hardest to date. The difficulty resets on Mondays, and then gets harder again towards Sunday.&lt;/p&gt;
    &lt;p&gt;I am working on methods to automate my VC firm. We have a small team and many different tasks to do. I’ve had success with using LLMs to help us automate various projects. But I appreciate any open source tools, techniques, readings, etc. if anyone knows any!&lt;/p&gt;
    &lt;p&gt;This is a pet project for myself. I love listening to online radio while at work, helps me focus. But I didn't really click with any of the current selection of web apps out there so decided to build one myself.&lt;/p&gt;
    &lt;p&gt;It uses the great API available at radio-browser.info for all the radio information.&lt;/p&gt;
    &lt;p&gt;Been using it as a way to learn how to market a website as well. Learning a lot.&lt;/p&gt;
    &lt;p&gt;A database populated with audio metadata (including a link back to YouTube or Spotify or whatever) that includes vector embeddings for the audio. That way I can grab clips of music I like from YouTube, generate vectors for them, then find similar things in the database.&lt;/p&gt;
    &lt;p&gt;It's off to a rocky start though, as I've initially populated it with YouTube-8M and AudioSet, neither of which are music-specific. The search results can be... Weird.&lt;/p&gt;
    &lt;p&gt;Unlike traditional accounting platforms we expose the ledger model directly which enables our customers to model complex transactions even when we do not have direct support for it.&lt;/p&gt;
    &lt;p&gt;Been working on this for a month, and it uses Elixir, Phoenix and InertiaJS with React.&lt;/p&gt;
    &lt;p&gt;I'm building one project a week for the next 25 weeks for my newsletter. First, I want interesting content for the newsletter. Second, I want to try to grow the newsletter to put out something fun and joyous. The world needs more good fun.&lt;/p&gt;
    &lt;p&gt;I'm working on Argon Chess, a deterministic chess variant with some degree of cheat resistance (hard to describe to chess engines like Fairy Stockfish) and tons of variety. A week ago, I added a way to play friends online a week ago (a Discord Activity) and a simple Play a Dumb AI feature on its website. You can also print the cards for free for offline play. https://argonchess.com/&lt;/p&gt;
    &lt;p&gt;I'm building a Firefox, Chrome, VSCode and OpenVSX security scanner and profiler, and working on building a private web store for Enterprises to switch to rather than using the default stores given all the ransomware and malware activity in that space. Will show HN very soon!&lt;/p&gt;
    &lt;p&gt;system to test and calibrate an analog traction control system. the system uses a frequency to voltage converter and a bunch of opamps to compare wheel speeds then determines wheel slip or slide and either reduces engine power or braking.&lt;/p&gt;
    &lt;p&gt;Test system uses ADCs, DACs and a DDS to produce a sine wave that simulates wheel speed.&lt;/p&gt;
    &lt;p&gt;A non-bloated HTML, CSS and pure Vanilla JS framework to create dashboards.&lt;/p&gt;
    &lt;p&gt;A cross-platform JSONL viewer where I am learning ImGUI. Haven’t found any other open source GUI framework that‘s small, provides out of the box components for tables, sorting&lt;/p&gt;
    &lt;p&gt;Helping my recent MBA grad sister make a simple python script to fit here resume to a JD using openAI's api. Shes applting to product and marketing roles in AI and this helps her understand the tech (and its limitations) better as well as apply to more jobs easier&lt;/p&gt;
    &lt;p&gt;Market is brutal though man. She hasnt gotten an offer after so much trying&lt;/p&gt;
    &lt;p&gt;Frontend framework in JavaScript that requires no build step, relies on DOM and SSR and can be used to build both SPA and hybrid apps without VDOM, js templates, hydration or putting HTML (or worse, css) inside JS code. It'll also have a very sophisticated declarative state manager which makes managing state and ui transitions a breeze. It's basically anti-React.&lt;/p&gt;
    &lt;p&gt;Working on https://ziva.sh/, an AI agent for game development. It uses MCP to integrate with Godot, a leading open source game engine.&lt;/p&gt;
    &lt;p&gt;It's coming together really nicely, targeting a beta release later this month. If anyone is interested in game development and wants to be a beta tester, lmk :)&lt;/p&gt;
    &lt;p&gt;Moved from nodered only to a hybrid of nodered and home assistant. Added some new sensors, nfc tags, modes and automations for multiple tenants / cost savings. Its been fun to automate some boring tasks.&lt;/p&gt;
    &lt;p&gt;Been nerd sniped recently so am working on a Rust version of markdownlint-cli2. I'm tired of having a node dependency in my projects and this seems like a constrained enough problem space that I'll actually get around to doing it.&lt;/p&gt;
    &lt;p&gt;Is anyone working on or knows a library for evaluating LLMs for application features and/or application features that use LLMs? I am wondering what people use or if anyone has their own solution.&lt;/p&gt;
    &lt;p&gt;For fun have been creating a mashup of old school DnD map generation using Commodore "10 Print Chr$(205.5+Rnd(1)); : Goto 10" style logic (in TS/Svelte/SVG):&lt;/p&gt;
    &lt;p&gt;Have been down a rabbit hole ensuring the stairs are realistic and that grid connects properly. Lots of fun and frustration with AI coding tools trying to solve that (they mostly don't/can't). Some fun detours learning a little Prolog to help out as well.&lt;/p&gt;
    &lt;p&gt;ELO translated to the NFL with margin-of-victory adjustments, a modest home-field term, and week-to-week recency weighting.&lt;/p&gt;
    &lt;p&gt;Post-hoc calibration with isotonic regression so 70% predictions land near 0.70 empirically.&lt;/p&gt;
    &lt;p&gt;Monte Carlo to roll games forward for distributions on weekly win odds and season outcomes, plus basic reliability/Brier/log-loss tracking.&lt;/p&gt;
    &lt;p&gt;# Where I’m taking it (ensemble ideas)&lt;/p&gt;
    &lt;p&gt;Blend a few complementary signals: (1) pure ELO strength; (2) schedule-adjusted EPA/Success Rate features; (3) injury/QB continuity and rest/travel effects; (4) a small “market prior” from closing lines; (5) weather/play style pace features.&lt;/p&gt;
    &lt;p&gt;Combine via a simple stacked model (regularized logistic, isotonic on top), or a Bayesian hierarchical model that lets team effects evolve with partial pooling.&lt;/p&gt;
    &lt;p&gt;Separate models for win prob vs. expected margin, then reconcile with a consistent link so the two don’t disagree.&lt;/p&gt;
    &lt;p&gt;Emphasis on calibration over leaderboard-chasing: reliability diagrams, ECE, PIT histograms, and backtests that penalize regime drift.&lt;/p&gt;
    &lt;p&gt;# Why I’m doing it&lt;/p&gt;
    &lt;p&gt;It’s a sandbox to teach myself Monte Carlo and ELO end-to-end—data ingest → feature plumbing → simulation → calibration → eval—on a domain with immediate feedback every week.&lt;/p&gt;
    &lt;p&gt;# How this connects to my day job (healthcare ops)&lt;/p&gt;
    &lt;p&gt;I work at BlueSprig, running ~150 ABA therapy clinics. I’m exploring whether ELO-like ideas can augment ops decisions:&lt;/p&gt;
    &lt;p&gt;“Strength” ratings for clinics, care teams, or scheduling templates based on outcome deltas and throughput (margin-of-victory ≈ effect size/efficiency).&lt;/p&gt;
    &lt;p&gt;Monte Carlo for expansion planning (new-site ramp curves), capacity/OT forecasting, and risk-adjusted outcome monitoring with calibration so probabilities mean something.&lt;/p&gt;
    &lt;p&gt;Guardrails for fairness and interpretability so ratings don’t become blunt scorecards.&lt;/p&gt;
    &lt;p&gt;# Help&lt;/p&gt;
    &lt;p&gt;If you’ve shipped calibrated ensembles in sports or have pointers on applying rating systems to multi-site healthcare operations, I’d love to trade notes or if you need someone to this and other kind of work for their dayjob email me at mgracepellon@gmail.com -- I would love to do this fulltime.&lt;/p&gt;
    &lt;p&gt;I’ve recently written ImapGoose, a daemon which keeps a remote IMAP mailbox in sync with a local tree of Maildir: https://whynothugo.nl/tags/imapgoose/&lt;/p&gt;
    &lt;p&gt;It relies on “modern” (2009) extensions to minimise traffic and avoids polling entirely (relying on the server to notify of new messages or changes as they happen).&lt;/p&gt;
    &lt;p&gt;It’s currently quite stable. The only known issue is that it can take a while to detect a timeout when the system is suspended and woken up again (there’s no portable API to detect suspend/resume).&lt;/p&gt;
    &lt;p&gt;Since then, I’ve been working on a simple TUI email client based on notmuch and maildir. So far it works really well for processing email, but lacks any capabilities for handling attachments, composing, sending (these are obviously on the roadmap).&lt;/p&gt;
    &lt;p&gt;Note that I am trying to narrow down a bug in my backend which sometimes causes it to crash. Since backend is built in Swift using SQLite as database, it's a but hard to nail down the issue.&lt;/p&gt;
    &lt;p&gt;I recently added FSRS (besides also having Anki integration). Now I'm working on replacing the need for reviewing flashcards by having reading activity automatically mark flashcards (current and future) as reviewed, so that you can get many of your reviews in just by reading native materials that interest you instead of sacrificing most of your study time to contextless flashcard grind.&lt;/p&gt;
    &lt;p&gt;I'm also working on a manga mode using a new manga OCR tech I have licensed out of academia that is ahead of state of the art alternatives.&lt;/p&gt;
    &lt;p&gt;This looks super cool. I love to see people working on language learning tech. I'm working on a language learning app too but it only really works well for indo-european languages. That said I would still love to collab or talk shop, my contact info is in my bio&lt;/p&gt;
    &lt;p&gt;And an iOS expense tracker focused for frequent travelers, and macOS photos viewer based on the filesystem instead of a monolithic opaque "library", 2 needs that I had since forever but could never get through Apple's atrocious developer documentation far enough to finish making them :')&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45869146"/><published>2025-11-09T21:02:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45869762</id><title>German Food Banks Feed 37,000 US Soldiers</title><updated>2025-11-09T22:36:49.500168+00:00</updated><content/><link href="https://hanschristensen.substack.com/p/german-food-banks-feed-37000-us-soldiers"/><published>2025-11-09T22:18:57+00:00</published></entry></feed>