<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-06T19:32:14.596252+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45139088</id><title>Purposeful animations</title><updated>2025-09-06T19:32:20.318767+00:00</updated><content>&lt;doc fingerprint="f7eb51a5ad29df05"&gt;
  &lt;main&gt;&lt;p&gt;When done right, animations make an interface feel predictable, faster, and more enjoyable to use. They help you and your product stand out.&lt;/p&gt;&lt;p&gt;But they can also do the opposite. They can make an interface feel unpredictable, slow, and annoying. They can even make your users lose trust in your product.&lt;/p&gt;&lt;p&gt;So how do you know when and how to animate to improve the experience?&lt;/p&gt;&lt;p&gt;Step one is making sure your animations have a purpose.&lt;/p&gt;&lt;head rend="h2"&gt;Purposeful animations&lt;/head&gt;&lt;p&gt;Before you start animating, ask yourself: what’s the purpose of this animation? &lt;lb/&gt;As an example, what’s the purpose of this marketing animation we built at Linear?&lt;/p&gt;&lt;p&gt;You can view the full animation on linear.app/ai.&lt;/p&gt;&lt;p&gt;This animation explains how Product Intelligence (Linear’s feature) works. We could have used a static asset, but the animated version helps the user understand what this feature does, straight in the initial viewport of the page.&lt;/p&gt;&lt;p&gt;Another purposeful animation is this subtle scale down effect when pressing a button. It’s a small thing, but it helps the interface feel more alive and responsive.&lt;/p&gt;&lt;p&gt;Sonner’s enter animation, on the other hand, has two purposes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;- Having a toast suddenly appear would feel off, so we animate it in.&lt;/item&gt;&lt;item&gt;- Because it comes from and leaves in the same direction, it creates spatial consistency, making the swipe-down-to-dismiss gesture feel more intuitive.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But sometimes the purpose of an animation might just be to bring delight.&lt;/p&gt;&lt;p&gt;Morphing of the feedback component below helps make the experience more unique and memorable. This works as long as the user will rarely interact with it. It’ll then become a pleasant surprise, rather than a daily annoyance.&lt;/p&gt;&lt;p&gt;Press on the button to see it morph.&lt;/p&gt;&lt;p&gt;Used multiple times a day, this component would quickly become irritating. The initial delight would fade and the animation would slow users down.&lt;/p&gt;&lt;p&gt;How often users will see an animation is a key factor in deciding whether to animate or not. Let’s dive deeper into it next.&lt;/p&gt;&lt;head rend="h2"&gt;Frequency of use&lt;/head&gt;&lt;p&gt;I use Raycast hundreds of times a day. If it animated every time I opened it, it would be very annoying. But there’s no animation at all. That’s the optimal experience.&lt;/p&gt;&lt;p&gt;To see it for yourself, try to toggle the open state of the menu below by using the buttons belowpressing &lt;code&gt;J&lt;/code&gt; and then &lt;code&gt;K&lt;/code&gt;. Which one feels better if used hundreds of times a day?&lt;/p&gt;&lt;p&gt;When I open Raycast, I have a clear goal in mind. I don’t expect to be “delighted”, I don’t need to be. I just want to do my work with no unnecessary friction.&lt;/p&gt;&lt;p&gt;Think about what the user wants to achieve and how often they will see an animation. A hover effect is nice, but if used multiple times a day, it would likely benefit the most from having no animation at all.&lt;/p&gt;&lt;p&gt;Imagine you interact with this list often during the day.&lt;/p&gt;&lt;p&gt;Imagine you interact with this list often during the day.&lt;/p&gt;&lt;p&gt;The same goes for keyboard-initiated actions. These actions may be repeated hundreds of times a day, an animation would make them feel slow, delayed, and disconnected from the user’s actions. You should never animate them.&lt;/p&gt;&lt;p&gt;Since we can’t really use a keyboard on touch devices, you can press the buttons below to see how it feels with and without animation.&lt;/p&gt;&lt;p&gt;To see it for yourself, focus on the input below and use arrow keys to navigate through the list. Notice how the highlight feels delayed compared to the keys you press. Now press (shift) and see how this interaction feels without animation.&lt;/p&gt;&lt;p&gt;But even if your animation won’t be used too often and it fulfills a clear purpose, you still have to think about its speed…&lt;/p&gt;&lt;head rend="h2"&gt;Perception of speed&lt;/head&gt;&lt;p&gt;Unless you are working on marketing sites, your animations have to be fast. They improve the perceived performance of your app, stay connected to user’s actions, and make the interface feel as if it’s truly listening to the user.&lt;/p&gt;&lt;p&gt;To give you an example, a faster-spinning spinner makes the app seem to load faster, even though the load time is the same. This improves perceived performance.&lt;/p&gt;&lt;p&gt;Which one works harder to load the data?&lt;/p&gt;&lt;p&gt;A &lt;code&gt;180ms&lt;/code&gt; dropdown animation feels more responsive than a &lt;code&gt;400ms&lt;/code&gt; one:&lt;/p&gt;&lt;p&gt;Click on the buttons to compare the speed.&lt;/p&gt;&lt;p&gt;As a rule of thumb, UI animations should generally stay under &lt;code&gt;300ms&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Another example of the importance of speed: tooltips should have a slight delay before appearing to prevent accidental activation. Once a tooltip is open however, hovering over other tooltips should open them with no delay and no animation.&lt;/p&gt;&lt;p&gt;This feels faster without defeating the purpose of the initial delay.&lt;/p&gt;&lt;p&gt;Radix UI and Base UI skip the delay once a tooltip is shown.&lt;/p&gt;&lt;p&gt;Radix UI and Base UI skip the delay once a tooltip is shown.&lt;/p&gt;&lt;head rend="h2"&gt;Building great interfaces&lt;/head&gt;&lt;p&gt;The goal is not to animate for animation’s sake, it’s to build great user interfaces. The ones that users will happily use, even on a daily basis. Sometimes this requires animations, but sometimes the best animation is no animation.&lt;/p&gt;&lt;p&gt;Knowing when to animate is just one of many things you need to know in order to craft great animations. If you’d like to dive deeper into the theory and practice of it, I’ve created a course that covers everything you need to know:&lt;/p&gt;Check out "Animations on the Web"&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://emilkowal.ski/ui/you-dont-need-animations"/></entry><entry><id>https://news.ycombinator.com/item?id=45141636</id><title>Making a font of my handwriting</title><updated>2025-09-06T19:32:19.455853+00:00</updated><content>&lt;doc fingerprint="3714a019faa705f8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Making a font of my handwriting&lt;/head&gt;
    &lt;p&gt;Published on&lt;/p&gt;
    &lt;p&gt;Recently Iâve been on a small campaign to try to make my personal website moreâ¦ personal. Little ways to make it obvious itâs mine and personal, not just another piece of the boring corporate dystopia that is most of the web these days. I donât quite want to fully regress to the Geocities era and fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.&lt;/p&gt;
    &lt;p&gt;Iâd added some bits and pieces along those lines: floating images in articles now look like theyâre stuck to the page with sellotape, related post links have a wavy border that animates when you hover over them, and so on. Next, I wanted to change the heading fonts from a monospace font to something cursive, to resemble handwriting. Less terminal output, more handwritten letter. I couldnât find one I liked, though. So why not make my own? It canât be that hard, right?&lt;/p&gt;
    &lt;head rend="h3"&gt;Failing to do it myself&lt;/head&gt;
    &lt;p&gt;I set out to try to make the font myself using open source tools. After doing a bit of research, it seemed like the general approach was to create vectors of each character and then import them into a font editor. That seems to mean either Adobe Illustrator and FontLab (if you have too much money) or Inkscape and FontForge (if you like open source). I fall firmly into the latter category, so I grabbed my graphics tablet and opened Inkscape.&lt;/p&gt;
    &lt;p&gt;I wrote out my first three letters: capital A, B and C. Saved them in Inkscape, and attempted to import them into FontForge. Then I remembered one crucial thing that had slipped my mind: I absolutely loathe using FontForge. Itâs a bit like when you open an old version of GIMP and get a bunch of weird looking windows floating all over the place; it feels like youâre fighting against the tool to do even the most basic operations. The difference is I have cause to edit images a lot more than I edit fonts, and GIMP has actually significantly improved their UI over the years.&lt;/p&gt;
    &lt;p&gt;Here are the rough steps I went through with FontForge:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Launch Font Forge. It shows a weird bit of art in one window, and an open file dialog in another.&lt;/item&gt;
      &lt;item&gt;I donât want to open a file, so I close that dialog. The program exits.&lt;/item&gt;
      &lt;item&gt;Relaunch Font Forge, and realise that within the âOpen Fontâ dialog is a âNewâ button. Click it.&lt;/item&gt;
      &lt;item&gt;Get to the standard font-editing UI. Right-click on the âAâ looking for a way to import an SVG. Donât see one.&lt;/item&gt;
      &lt;item&gt;Click around a bit, exploring the menus. Everything feels a bit off. You canât open one menu then hover over the next to see its content, like basically every UI toolkit in existence. I think FontForge has eschewed QT and GTK in favour of doing things itself.&lt;/item&gt;
      &lt;item&gt;Find the âImportâ option in the File menu. Hope itâs for a single glyph not the whole font.&lt;/item&gt;
      &lt;item&gt;A file picker opens. Again itâs all a bit off from normal desktop conventions. Try to resize it, and just get blank gray space at the bottom.&lt;/item&gt;
      &lt;item&gt;Type the absolute path I want to go to in the text field.&lt;/item&gt;
      &lt;item&gt;Get a dialog saying âNot a bdf file /home/chris/etcâ. Press OK.&lt;/item&gt;
      &lt;item&gt;Get a dialog saying âCould not find a bitmap font inâ. Press OK.&lt;/item&gt;
      &lt;item&gt;Press Ctrl+L to see if that lets me enter a path. Click everything in the dialog to try to find a way to enter a path. Get annoyed. Give up. Click through folder-by-folder to get to where I want to be.&lt;/item&gt;
      &lt;item&gt;Get to the folder and donât see any files. Change the format to âSVGâ. Double-click the newly-visible SVG file.&lt;/item&gt;
      &lt;item&gt;Get a dialog saying âYou must select a glyph before you can import an image into itâ. Press OK.&lt;/item&gt;
      &lt;item&gt;The import dialog goes away, having not imported.&lt;/item&gt;
      &lt;item&gt;Select the glyph in the main tool area, then repeat the FileâImport dance.&lt;/item&gt;
      &lt;item&gt;Itâs actually there now! Open the glyph in the editor and see itâs a complete mess of BÃ©zier curves. I canât click what I want without accidentally moving a handle for an adjacent curve.&lt;/item&gt;
      &lt;item&gt;Rage-quit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Iâm sure FontForge is less anger inducing once youâre used to it. And you definitely could use it to build a font like this if you had much more patience than me. Iâd had enough of death-by-a-thousand-paper-cuts though.&lt;/p&gt;
    &lt;p&gt;I briefly tried Inkscapeâs built-in support for making an SVG font. It annoyed me a lot less, but itâs fiddly: it seemed like each font had to be a single path, so you had to convert the glyphs to paths, then merge them correctly. If you merge them incorrectly then the wrong bits of your letters end up filled (like the inside of the âBâ). Path manipulation is getting towards the limit of my knowledge of vector editing, and it took a bit of trial and error for each letter that had more than a single stroke. I didnât fancy doing that for every letter.&lt;/p&gt;
    &lt;p&gt;Iâm usually a big advocate of open source, but this was one of those painful times where it feels like it just falls short. Clunky, painful UI and processes where commercial tools just let you get on with your work.&lt;/p&gt;
    &lt;head rend="h3"&gt;You can exchange money for goods and services&lt;/head&gt;
    &lt;p&gt;When Iâd been looking for open source tutorials, I found many mentions of a closed source, hosted tool: Calligraphr. It has a free version with limitations (no ligatures, no variations, 75 glyphs per font), and a pro version for Â£8/month. Iâd normally balk at the idea of a subscription for this, but they have the perfect answer: you can make a one-time payment, and your account automatically downgrades back to free after a month. Itâs not a hidden option, either, itâs the most prominent button on the upgrade page. That made me happy to give them Â£8 to play around with the service for a month.&lt;/p&gt;
    &lt;p&gt;Calligraphr works by having you print templates, write out the letters, then scan them in. It does some magical processing to extract the glyphs, provides tools to tidy them up, align them, etc, and then produces a TTF file for you. You can see some of my completed templates here:&lt;/p&gt;
    &lt;p&gt;Calligraphr has a nice UI to generate the templates, allowing you to select which glyphs to include. I added the âminimal Englishâ, âbasic punctuationâ and âLigaturesâ sets. That gave me four pages to fill out, and I did them all twice. That let me filter out versions that didnât work well, and have variants for some letters so the font wasnât too repetitive. Later on, I went back and added some custom ligatures based on blog post titles that didnât look quite right: âReâ, âToâ, âersâ, âeyâ, âhyâ, âraâ, âreâ and âtyâ. Ligatures like this help it look more natural: when we write we donât just stamp out identical letters regardless of their surroundings, instead they will connect to their neighbours, or overlap slightly, or even share a stroke.&lt;/p&gt;
    &lt;p&gt;I filled these templates in with a Sharpie, as I wanted a fairly informal, scrap-booky look, and it would also give good solid shapes that should be easy to pick out of the template. I scanned them with the âScan Documentâ function on my iPhone, and uploaded the PDFs to Calligraphr.&lt;/p&gt;
    &lt;head rend="h3"&gt;Iterating and tweaking&lt;/head&gt;
    &lt;p&gt;The Calligraphr UI allows you to preview the font, but I found it a lot more useful to just download a copy and use it on a local copy of my website. That let me test it with real text, and see how itâd look at the different font sizes I use on the site.&lt;/p&gt;
    &lt;p&gt;The first version was not great. Despite the guidelines on the template, I apparently wasnât good at sticking to them. Some letters were floating way off the baseline, and some were sunken below. When those opposites met it looked terrible. Fortunately Calligraphr has a pretty easy tool to slide each letter up and down, and scale it up or down if needed, and you can see it next to other letters as you do it. It took a little bit of time to go through all the variants of all the letters, but the next version looked a lot better.&lt;/p&gt;
    &lt;p&gt;Another tweak I ended up doing was reducing the spacing between letters. The defaults Calligraphr uses are probably good for a blocky font, but I wanted to put the letters close together to give it more of a joined-up look. Again, this is an easy tool to use, you just drag the sides in or out as desired. While these tweaking steps were probably as fiddly as some of the Inkscape steps I refused to do earlier, theyâre a lot more rewarding as you see things improving with each one. Itâs a lot easier for me to commit time and effort to improving something thatâs already working reasonably, than put that time and energy into an unknown.&lt;/p&gt;
    &lt;p&gt;Later, I noticed that occasionally there would be a huge gap in a title. Not âthe kerning is slightly offâ but âthereâs enough room to park a busâ. It took me a while to figure out what was happening: a couple of glyphs hadnât been isolated perfectly and had picked up a few pixels from the template lines at the edge of their boxes. That meant the glyph had a width that covered the actual written glyph, a big gap, and then the rogue marks. At first, I fixed this by just adjusting the width, but that left the little pixels floating awkwardly down-sentence. The proper fix was to use the editing tool and simply delete them, and then Calligraphr snapped the width back to what it should be.&lt;/p&gt;
    &lt;p&gt;These iterations took a while to do, but I just dipped in and out occasionally over the course of a week, so it didnât actually feel like too much work. I quite enjoy the process of refining things, too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Result and a surprise&lt;/head&gt;
    &lt;p&gt;If youâre viewing this post on my website[1], you can see the font in the headers, captions, and a few other places. Hereâs how it compares to my actual handwriting:&lt;/p&gt;
    &lt;p&gt;Itâs not close enough to forge documents, but I think it definitely gets across my style, and thatâs exactly what I wanted. Itâs surprisingly legible even at smaller font sizes â I think the weight of the Sharpie helps here â and at Â£8 and a bit of manual work was a lot more economical than spending days wresting with open source tools.&lt;/p&gt;
    &lt;p&gt;A few weeks after I put the finishing touches on the font, I got an e-mail from Calligraphr. As my account had lapsed back to the free version, I was no longer eligible for the âserver-side backupâ feature. So what did they do? They e-mailed me an exported copy! Itâs a JSON file with the properties of each glyph and a base64 encoded image. Not only can I re-upload this to Calligraphr if I resubscribe, I can probably hook something up to edit it should I ever need to. Iâm blown away by how pro-user Calligraphrâs business practices are. Theyâre up-front about pricing, donât try and get you stuck on an auto-renewing subscription, and automatically export your data. Itâs like a breath of fresh air compared to the barrage of dark patterns that other websites foist on us. If you want to make this kind of font, Iâd definitely recommend them just because of how nice they are.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;And I havenât changed everything since writing this postâ¦ â©ï¸&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Thanks for reading!&lt;/head&gt;
    &lt;head rend="h3"&gt;Related posts&lt;/head&gt;
    &lt;head rend="h3"&gt;Escaping Spotify the hard way&lt;/head&gt;
    &lt;p&gt;For the longest time I used Spotify for all my music needs. And I listen to a lot of music: sometimes actively, but mostly passively as background noise. I cancelled my premium subscription last December, and stopped using the service entirely. Why? Thereâs a bunch of reasons.&lt;/p&gt;
    &lt;head rend="h3"&gt;How I use Tailscale&lt;/head&gt;
    &lt;p&gt;Iâve been using Tailscale for around four years to connect my disparate devices, servers and apps together. I wanted to talk a bit about how I use it, some cool features you might not know about, and some stumbling blocks I encountered.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Ethics of LLMs&lt;/head&gt;
    &lt;p&gt;Iâve written about LLMs a few times recently, carefully dodging the issue of ethics each time. I didnât want to bog down the other posts with it, and I wanted some time to think over the issues. Now Iâve had time to think, itâs time to remove my head from the sand. There are a lot of different angles to consider, and a lot of it is more nuanced than is often presented. Itâs not all doom and gloom, and itâs also not the most amazing thing since sliced bread. Who would have thought?&lt;/p&gt;
    &lt;head rend="h3"&gt;If all you have is a hammerâ¦&lt;/head&gt;
    &lt;p&gt;I presume everyone is familiar with the idiom âif all you have is a hammer, everything looks like a nailâ. If not, well, there it is. Itâs generally used pejoratively about being single-minded, but I think it also gives a glimpse into something more interesting: mental and perceptual sets.&lt;/p&gt;
    &lt;p&gt;Recently Iâve been on a small campaign to try to make my personal website moreâ¦ personal. Little ways to make it obvious itâs mine and personal, not just another piece of the boring corporate dystopia that is most of the web these days. I donât quite want to fully regress to the Geocities era and fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chameth.com/making-a-font-of-my-handwriting/"/></entry><entry><id>https://news.ycombinator.com/item?id=45142885</id><title>Anthropic agrees to pay $1.5B to settle lawsuit with book authors</title><updated>2025-09-06T19:32:19.399694+00:00</updated><content/><link href="https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&amp;smid=url-share"/></entry><entry><id>https://news.ycombinator.com/item?id=45144123</id><title>Kenvue stock drops on report RFK Jr will link autism to Tylenol during pregnancy</title><updated>2025-09-06T19:32:19.138579+00:00</updated><content>&lt;doc fingerprint="9e07db9a12930ea8"&gt;
  &lt;main&gt;
    &lt;p&gt;Shares of Kenvue fell more than 10% on Friday after a report that Health and Human Services Secretary Robert F. Kennedy Jr. will likely link autism to the use of the company's pain medication Tylenol in pregnant women.&lt;/p&gt;
    &lt;p&gt;HHS will release the report that could draw that link this month, the Wall Street Journal reported on Friday.&lt;/p&gt;
    &lt;p&gt;That report will also suggest a medicine derived from folate – a water-soluble vitamin – can be used to treat symptoms of the developmental disorder in some people, according to the Journal.&lt;/p&gt;
    &lt;p&gt;In a statement, an HHS spokesperson said "We are using gold-standard science to get to the bottom of America's unprecedented rise in autism rates."&lt;/p&gt;
    &lt;p&gt;"Until we release the final report, any claims about its contents are nothing more than speculation," they added.&lt;/p&gt;
    &lt;p&gt;Tylenol could be the latest widely used and accepted treatment that Kennedy has undermined at the helm of HHS, which oversees federal health agencies that regulate drugs and other therapies. Kennedy has also taken steps to change vaccine policy in the U.S., and has amplified false claims about safe and effective shots that use mRNA technology.&lt;/p&gt;
    &lt;p&gt;Kennedy has made the disorder a key focus of HHS, pledging in April that the agency will "know what has caused the autism epidemic" by September and eliminate exposures. He also said that month that the agency has launched a "massive testing and research effort" involving hundreds of scientists worldwide that will determine the cause.&lt;/p&gt;
    &lt;p&gt;In a statement, Kenvue said it has "continuously evaluated the science and [continues] to believe there is no causal link" between the use of acetaminophen, the generic name for Tylenol, during pregnancy and autism.&lt;/p&gt;
    &lt;p&gt;The company added that the Food and Drug Administration and leading medical organizations "agree on the safety" of the drug, its use during pregnancy and the information provided on the Tylenol label.&lt;/p&gt;
    &lt;p&gt;The FDA website says the agency has not found "clear evidence" that appropriate use of acetaminophen during pregnancy causes "adverse pregnancy, birth, neurobehavioral, or developmental outcomes." But the FDA said it advises pregnant women to speak with their health-care providers before using over-the-counter drugs.&lt;/p&gt;
    &lt;p&gt;The American College of Obstetricians and Gynecologists maintains that acetaminophen is safe during pregnancy when taken as directed and after consulting a health-care provider.&lt;/p&gt;
    &lt;p&gt;Some previous studies have suggested the drug poses risks to fetal development, and some parents have brought lawsuits claiming that they gave birth to children with autism after using it.&lt;/p&gt;
    &lt;p&gt;But a federal judge in Manhattan ruled in 2023 that some of those lawsuits lacked scientific evidence and later ended the litigation in 2024. Some research has also found no association between acetaminophen use and autism.&lt;/p&gt;
    &lt;p&gt;In a note on Friday, BNP Paribas analyst Navann Ty said the firm believes the "hurdle to proving causation [between the drug and autism] is high, particularly given that the litigation previously concluded in Kenvue's favor."&lt;/p&gt;
    &lt;p&gt;-- CNBC's Angelica Peebles contributed to this report.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/09/05/rfk-tylenol-autism-kenvue-stock-for-url.html"/></entry><entry><id>https://news.ycombinator.com/item?id=45144337</id><title>The Universe Within 12.5 Light Years</title><updated>2025-09-06T19:32:18.780696+00:00</updated><content>&lt;doc fingerprint="b21697bf7e9b7625"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Universe within 12.5 Light Years&lt;lb/&gt;The Nearest Stars&lt;/head&gt;&lt;div&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt; Number of stars within 12.5 light years = 33&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;head rend="h3"&gt;About the Map&lt;/head&gt; This map shows all the star systems that lie within 12.5 light years of our Sun. Most of the stars are red dwarfs - stars with a tenth of the Sun's mass and less than one hundredth the luminosity. Roughly eighty percent of all the stars in the universe are red dwarfs, and the nearest star - Proxima - is a typical example. &lt;div&gt;&lt;table&gt;&lt;row&gt;&lt;cell colspan="2" role="head"&gt;Additional Maps&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; This is a diagram that zooms out from the Earth's orbit to the nearest star system. It tries to show just how large the distance to the nearest star really is.&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; Here is a map of all the known stars that lie within 20 light years plotted using the data provided below.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell colspan="2" role="head"&gt;Data and Catalogs&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; There are over 100 stars within 20 light years. This is a list of the known stars that lie within this distance.&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; This is a page showing some simple animations of double, triple and quadruple star systems, to demonstrate how stars orbit each other.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;head rend="h3"&gt;Information on the Nearest Stars&lt;/head&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-1"&gt;Sun - Type=G2, Magnitude=-26.8, Distance=0.0000158 ly&lt;/item&gt;&lt;item rend="dd-1"&gt;A typical yellow dwarf star. It has eight planets orbiting it.&lt;/item&gt;&lt;item rend="dt-2"&gt;Proxima Centauri - Type=M5, Magnitude=11.0, Distance=4.22 ly&lt;/item&gt;&lt;item rend="dd-2"&gt;This dim red dwarf is the nearest star to the Sun, and it is a member of the Alpha Centauri system despite lying 0.24 light years from the main pair of stars, requiring over one million years to orbit them. Proxima was discovered in 1915 by Robert Innes and was at that time the least luminous star known. It is also a flare star - capable of brightening a magnitude or more in minutes.&lt;/item&gt;&lt;item rend="dt-3"&gt;Alpha Centauri A,B - Type=G2+K0, Magnitudes=0.0+1.4, Distance=4.39 ly&lt;/item&gt;&lt;item rend="dd-3"&gt;Just slightly further from us than Proxima, lie the orange and yellow dwarf stars that make up Alpha Centauri. Orbiting each other in an 80 year period, together they make up one of the brightest objects in southern hemisphere skies. Seen from Alpha Centauri, the third member of the system, Proxima, is a dim (magnitude 4.8) star.&lt;/item&gt;&lt;item rend="dt-4"&gt;Barnard's Star - Type=M5, Magnitude=9.6, Distance=5.94 ly&lt;/item&gt;&lt;item rend="dd-4"&gt;Famous for having the largest proper motion of any star, this dim red dwarf travels 0.29 degrees against the background sky in a century. Discovered by E Barnard in 1916, it was thought in the 1960's to have a couple of unseen planets orbiting it, but later observations disproved this. In another 8000 years Barnard's Star will become the closest star to us.&lt;/item&gt;&lt;item rend="dt-5"&gt;Wolf 359 - Type=M6, Magnitude=13.5, Distance=7.80 ly&lt;/item&gt;&lt;item rend="dd-5"&gt;An excessively dim red dwarf discovered by Max Wolf in 1918. For 25 years it was the least luminous star known.&lt;/item&gt;&lt;item rend="dt-6"&gt;Lalande 21185 - Type=M2, Magnitude=7.5, Distance=8.31 ly&lt;/item&gt;&lt;item rend="dd-6"&gt;Recorded in JJ Lalande's star catalogue compiled in the 1790's, this is one of the brightest red dwarfs in the sky, but it still needs binoculars to see it. G Gatewood reported in 1996 the possible indications of a couple of Jupiter sized planets orbiting it but this remains unconfirmed.&lt;/item&gt;&lt;item rend="dt-7"&gt;Sirius A,B - Type=A1+DA, Magnitudes=-1.4+8.4, Distance=8.60 ly&lt;/item&gt;&lt;item rend="dd-7"&gt;This brilliant white star is the brightest star in the night sky and the most luminous star within 25 light years. Its white dwarf companion was first seen in 1852, the first white dwarf ever seen. The orbital period is 50 years.&lt;/item&gt;&lt;item rend="dt-8"&gt;Luyten 726-8 A,B - Type=M5+M5, Magnitudes=12.4+13.3, Distance=8.73 ly&lt;/item&gt;&lt;item rend="dd-8"&gt;This is a dim binary system consisting of two red dwarfs. The system is perhaps more famously known as UV Ceti, the variable-star name of the second star in the system. It is a famous flare star and can visibly brighten by several magnitudes as it ejects flares from its surface similar to the ones seen on the surface of the Sun, but far more energetic. Both stars require about 200 years to orbit each other.&lt;/item&gt;&lt;item rend="dt-9"&gt;Ross 154 - Type=M4, Magnitude=10.4, Distance=9.69 ly&lt;/item&gt;&lt;item rend="dd-9"&gt;A dim red dwarf. It is one of a number of nearby stars catalogued by Frank Ross in the 1930's. It is also a known flare star.&lt;/item&gt;&lt;item rend="dt-10"&gt;Ross 248 - Type=M6, Magnitude=12.3, Distance=10.33 ly&lt;/item&gt;&lt;item rend="dd-10"&gt;Another dim red dwarf.&lt;/item&gt;&lt;item rend="dt-11"&gt;Epsilon Eridani - Type=K2, Magnitude=3.7, Distance=10.50 ly&lt;/item&gt;&lt;item rend="dd-11"&gt;An orange dwarf star. This star was searched for signs of intelligent life with the Green Bank radio telescope in 1960. The results, predictably, were negative. The IRAS satellite detected a lot of dust orbiting this star indicating a possible forming solar system, and even more recently, (Aug 2000), a Jupiter sized planet has been detected orbiting this star at a distance of 3.2 AU (480 million km).&lt;/item&gt;&lt;item rend="dt-12"&gt;Lacaille 9352 - Type=M2, Magnitude=7.4, Distance=10.73 ly&lt;/item&gt;&lt;item rend="dd-12"&gt;A fairly bright red dwarf which can easily be seen with binoculars, it was first recorded in Nicolas de Lacaille's catalogue of southern hemisphere stars compiled around 1752.&lt;/item&gt;&lt;item rend="dt-13"&gt;Ross 128 - Type=M4, Magnitude=11.1, Distance=10.89 ly&lt;/item&gt;&lt;item rend="dd-13"&gt;A dim red dwarf, also known as FI Vir - its variable star designation.&lt;/item&gt;&lt;item rend="dt-14"&gt;Luyten 789-6 A,B,C - Type=M5+M5+M7, Magnitudes=13.3+13.3+14.0, Distance=11.1 ly&lt;/item&gt;&lt;item rend="dd-14"&gt;There seems to be three red dwarfs in this system. The main pair orbiting each other in a 2 year period, and a dim third star orbiting the first at a very close range.&lt;/item&gt;&lt;item rend="dt-15"&gt;Procyon A,B - Type=F5+DA, Magnitudes=0.4+10.7, Distance=11.41 ly&lt;/item&gt;&lt;item rend="dd-15"&gt;A brilliant yellow-white star, and the eighth brightest star in the sky. With twice the diameter of the Sun, Procyon is also the largest star within 25 light years. Procyon is orbited by a white dwarf companion first seen optically in 1896. The orbital period is 41 years.&lt;/item&gt;&lt;item rend="dt-16"&gt;61 Cygni A,B - Type=K5+K7, Magnitudes=5.2+6.1, Distance=11.41 ly&lt;/item&gt;&lt;item rend="dd-16"&gt;This binary system of two orange dwarf stars is famous for being the first star ever to have its distance measured by F Bessel in 1838. Both stars are very similar but are widely separated (86 AU) requiring about 700 years to orbit each other.&lt;/item&gt;&lt;item rend="dt-17"&gt;Struve 2398 A,B - Type=M4+M5, Magnitudes=8.9+9.7, Distance=11.6 ly&lt;/item&gt;&lt;item rend="dd-17"&gt;A binary system of two red dwarfs named Struve 2398 from a catalogue of double stars published in 1827. This system is also known by the rather more boring name of BD+59°1915. The two stars are quite widely separated (50 AU) and orbit each other in a 450 year period.&lt;/item&gt;&lt;item rend="dt-18"&gt;Groombridge 34 A,B - Type=M2+M6, Magnitudes=8.1+11.1, Distance=11.64 ly&lt;/item&gt;&lt;item rend="dd-18"&gt;Another pair of red dwarfs, this system is usually called Groombridge 34 from an 1838 catalogue of northern stars or sometimes BD+43°44. Both stars are variable in brightness and have the variable star names of GX And and GQ And. Both stars lie far apart from each other (150 AU) and orbit each other in a 2500 year period.&lt;/item&gt;&lt;item rend="dt-19"&gt;Giclas 51-15 - Type=M6, Magnitude=14.8, Distance=11.8 ly&lt;/item&gt;&lt;item rend="dd-19"&gt;This excessively dim red dwarf is the least luminous star within 14 light years. It shines with just 0.01% of the Sun's luminosity.&lt;/item&gt;&lt;item rend="dt-20"&gt;Epsilon Indi A,B,C - Type=K5+T1+T6, Magnitude=4.7, Distance=11.83 ly&lt;/item&gt;&lt;item rend="dd-20"&gt;An orange dwarf. It is a similar star to Epsilon Eridani, although a little bit smaller and dimmer. Epsilon Indi is orbited by a pair of brown dwarfs - failed stars that are too small to burn. They were discovered in 2003 and they orbit each other in a 16 year period, and they are 1500 AU (220 billion km) from the main star and they require about 70 000 years to orbit it.&lt;/item&gt;&lt;item rend="dt-21"&gt;Tau Ceti - Type=G8, Magnitude=3.5, Distance=11.90 ly&lt;/item&gt;&lt;item rend="dd-21"&gt;The nearest, single, sun-like star. It was searched (unsuccessfully) for any signs of intelligent life in 1960, along with Epsilon Eridani.&lt;/item&gt;&lt;item rend="dt-22"&gt;Luyten 372-58 - Type=M5, Magnitude=13.0, Distance=12.1 ly&lt;/item&gt;&lt;item rend="dd-22"&gt;A very dim red dwarf. Although this star was catalogued decades ago, it has only recently had its distance determined with any accuracy.&lt;/item&gt;&lt;item rend="dt-23"&gt;Luyten 725-32 - Type=M5, Magnitude=12.1, Distance=12.1 ly&lt;/item&gt;&lt;item rend="dd-23"&gt;Another dim red dwarf.&lt;/item&gt;&lt;item rend="dt-24"&gt;Luyten's Star - Type=M3, Magnitude=9.8, Distance=12.39 ly&lt;/item&gt;&lt;item rend="dd-24"&gt;A red dwarf. It is named after Willem Luyten who realised it was a nearby star in 1935. The star lies just 1.2 light years away from Procyon, but it is not associated with it.&lt;/item&gt;&lt;/list&gt;&lt;p&gt; Epsilon Eridani is orbited by a large planet which might look like this. &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://www.atlasoftheuniverse.com/12lys.html"/></entry><entry><id>https://news.ycombinator.com/item?id=45145457</id><title>GLM 4.5 with Claude Code</title><updated>2025-09-06T19:32:18.432135+00:00</updated><content>&lt;doc fingerprint="ccd2e51a790b4291"&gt;
  &lt;main&gt;&lt;code&gt;thinking.type&lt;/code&gt;parameter (with &lt;code&gt;enabled&lt;/code&gt; and &lt;code&gt;disabled&lt;/code&gt; settings), and dynamic thinking is enabled by default.
&lt;p&gt;Our most powerful reasoning model, with 355 billion parameters&lt;/p&gt;&lt;p&gt;Cost-Effective Lightweight Strong Performance&lt;/p&gt;&lt;p&gt;High Performance Strong Reasoning Ultra-Fast Response&lt;/p&gt;&lt;p&gt;Lightweight Strong Performance Ultra-Fast Response&lt;/p&gt;&lt;p&gt;Free Strong Performance Excellent for Reasoning Coding &amp;amp; Agents&lt;/p&gt;&lt;code&gt;thinking.type&lt;/code&gt; parameter. This parameter supports two values: &lt;code&gt;enabled&lt;/code&gt; (enabled) and &lt;code&gt;disabled&lt;/code&gt; (disabled). By default, dynamic thinking is enabled.
&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://docs.z.ai/guides/llm/glm-4.5"/></entry><entry><id>https://news.ycombinator.com/item?id=45145794</id><title>Developing a Space Flight Simulator in Clojure</title><updated>2025-09-06T19:32:17.690256+00:00</updated><content>&lt;doc fingerprint="4c23b196c6d1b91"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Developing a Space Flight Simulator in Clojure&lt;/head&gt;05 Sep 2025&lt;p&gt;In 2017 I discovered the free of charge Orbiter 2016 space flight simulator which was proprietary at the time and it inspired me to develop a space flight simulator myself. I prototyped some rigid body physics in C and later in GNU Guile and also prototyped loading and rendering of Wavefront OBJ files. I used GNU Guile (a Scheme implementation) because it has a good native interface and of course it has hygienic macros. Eventually I got interested in Clojure because unlike GNU Guile it has multi-methods as well as fast hash maps and vectors. I finally decided to develop the game for real in Clojure. I have been developing a space flight simulator in Clojure for almost 5 years now. While using Clojure I have come to appreciate the immutable values and safe parallelism using atoms, agents, and refs.&lt;/p&gt;&lt;p&gt;In the beginning I decided to work on the hard parts first, which for me were 3D rendering of a planet, an atmosphere, shadows, and volumetric clouds. I read the OpenGL Superbible to get an understanding on what functionality OpenGL provides. When Orbiter was eventually open sourced and released unter MIT license here, I inspected the source code and discovered that about 90% of the code is graphics-related. So starting with the graphics problems was not a bad decision.&lt;/p&gt;&lt;head rend="h2"&gt;Software dependencies&lt;/head&gt;&lt;p&gt;The following software is used for development. The software libraries run on both GNU/Linux and Microsoft Windows.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Clojure the programming language&lt;/item&gt;&lt;item&gt;LWJGL provides Java wrappers for various libraries &lt;list rend="ul"&gt;&lt;item&gt;lwjgl-opengl for 3D graphics&lt;/item&gt;&lt;item&gt;lwjgl-glfw for windowing and input devices&lt;/item&gt;&lt;item&gt;lwjgl-nuklear for graphical user interfaces&lt;/item&gt;&lt;item&gt;lwjgl-stb for image I/O and using truetype fonts&lt;/item&gt;&lt;item&gt;lwjgl-assimp to load glTF 3D models with animation data&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Jolt Physics to simulate wheeled vehicles and collisions with meshes&lt;/item&gt;&lt;item&gt;Fastmath for fast matrix and vector math as well as spline interpolation&lt;/item&gt;&lt;item&gt;Comb for templating shader code&lt;/item&gt;&lt;item&gt;Instaparse to parse NASA Planetary Constant Kernel (PCK) files&lt;/item&gt;&lt;item&gt;Gloss to parse NASA Double Precision Array Files (DAF)&lt;/item&gt;&lt;item&gt;Coffi as a foreign function interface&lt;/item&gt;&lt;item&gt;core.memoize for least recently used caching of function results&lt;/item&gt;&lt;item&gt;Apache Commons Compress to read map tiles from tar files&lt;/item&gt;&lt;item&gt;Malli to add schemas to functions&lt;/item&gt;&lt;item&gt;Immuconf to load the configuration file&lt;/item&gt;&lt;item&gt;Progrock a progress bar for long running builds&lt;/item&gt;&lt;item&gt;Claypoole to implement parallel for loops&lt;/item&gt;&lt;item&gt;tools.build to build the project&lt;/item&gt;&lt;item&gt;clj-async-profiler Clojure profiler creating flame graphs&lt;/item&gt;&lt;item&gt;slf4j-timbre Java logging implementation for Clojure&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The deps.edn file contains operating system dependent LWJGL bindings. For example on GNU/Linux the deps.edn file contains the following:&lt;/p&gt;&lt;p&gt;In order to manage the different dependencies for Microsoft Windows, a separate Git branch is maintained.&lt;/p&gt;&lt;head rend="h2"&gt;Atmosphere rendering&lt;/head&gt;&lt;p&gt;For the atmosphere, Brunetonâs precomputed atmospheric scattering was used. The implementation uses a 2D transmittance table, a 2D surface scattering table, a 4D Rayleigh scattering, and a 4D Mie scattering table. The tables are computed using several iterations of numerical integration. Higher order functions for integration over a sphere and over a line segment were implemented in Clojure. Integration over a ray in 3D space (using fastmath vectors) was implemented as follows for example:&lt;/p&gt;&lt;p&gt;Precomputing the atmospheric tables takes several hours even though pmap was used. When sampling the multi-dimensional functions, pmap was used as a top-level loop and map was used for interior loops. Using java.nio.ByteBuffer the floating point values were converted to a byte array and then written to disk using a clojure.java.io/output-stream:&lt;/p&gt;&lt;p&gt;When launching the game, the lookup tables get loaded and copied into OpenGL textures. Shader functions are used to lookup and interpolate values from the tables. When rendering the planet surface or the space craft, the atmosphere essentially gets superimposed using ray tracing. After rendering the planet, a background quad is rendered to display the remaining part of the atmosphere above the horizon.&lt;/p&gt;&lt;head rend="h2"&gt;Templating OpenGL shaders&lt;/head&gt;&lt;p&gt;It is possible to make programming with OpenGL shaders more flexible by using a templating library such as Comb. The following shader defines multiple octaves of noise on a base noise function:&lt;/p&gt;&lt;p&gt;One can then for example define the function fbm_noise using octaves of the base function noise as follows:&lt;/p&gt;&lt;head rend="h2"&gt;Planet rendering&lt;/head&gt;&lt;p&gt;To render the planet, NASA Bluemarble data, NASA Blackmarble data, and NASA Elevation data was used. The images were converted to a multi resolution pyramid of map tiles. The following functions were implemented for color map tiles and for elevation tiles:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;a function to load and cache map tiles of given 2D tile index and level of detail&lt;/item&gt;&lt;item&gt;a function to extract a pixel from a map tile&lt;/item&gt;&lt;item&gt;a function to extract the pixel for a specific longitude and latitude&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The functions for extracting a pixel for given longitude and latitude then were used to generate a cube map with a quad tree of tiles for each face. For each tile, the following files were generated:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;A daytime texture&lt;/item&gt;&lt;item&gt;A night time texture&lt;/item&gt;&lt;item&gt;An image of 3D vectors defining a surface mesh&lt;/item&gt;&lt;item&gt;A water mask&lt;/item&gt;&lt;item&gt;A normal map&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Altogether 655350 files were generated. Because the Steam ContentBuilder does not support a large number of files, each row of tile data was aggregated into a tar file. The Apache Commons Compress library allows you to open a tar file to get a list of entries and then perform random access on the contents of the tar file. A Clojure LRU cache was used to maintain a cache of open tar files for improved performance.&lt;/p&gt;&lt;p&gt;At run time, a future is created, which returns an updated tile tree, a list of tiles to drop, and a path list of the tiles to load into OpenGL. When the future is realized, the main thread deletes the OpenGL textures from the drop list, and then uses the path list to get the new loaded images from the tile tree, load them into OpenGL textures, and create an updated tile tree with the new OpenGL textures added. The following functions to manipulate quad trees were implemented to realize this:&lt;/p&gt;&lt;head rend="h2"&gt;Other topics&lt;/head&gt;&lt;head rend="h3"&gt;Solar system&lt;/head&gt;&lt;p&gt;The astronomy code for getting the position and orientation of planets was implemented according to the Skyfield Python library. The Python library in turn is based on the SPICE toolkit of the NASA JPL. The JPL basically provides sequences of Chebyshev polynomials to interpolate positions of Moon and planets as well as the orientation of the Moon as binary files. Reference coordinate systems and orientations of other bodies are provided in text files which consist of human and machine readable sections. The binary files were parsed using Gloss (see Wiki for some examples) and the text files using Instaparse.&lt;/p&gt;&lt;head rend="h3"&gt;Jolt bindings&lt;/head&gt;&lt;p&gt;The required Jolt functions for wheeled vehicle dynamics and collisions with meshes were wrapped in C functions and compiled into a shared library. The Coffi Clojure library (which is a wrapper for Javaâs new Foreign Function &amp;amp; Memory API) was used to make the C functions and data types usable in Clojure.&lt;/p&gt;&lt;p&gt;For example the following code implements a call to the C function add_force:&lt;/p&gt;&lt;p&gt;Here ::vec3 refers to a custom composite type defined using basic types. The memory layout, serialisation, and deserialisation for ::vec3 are defined as follows:&lt;/p&gt;&lt;head rend="h3"&gt;Performance&lt;/head&gt;&lt;p&gt;The clj-async-profiler was used to create flame graphs visualising the performance of the game. In order to get reflection warnings for Java calls without sufficient type declarations, *warn-on-reflection* was set to true.&lt;/p&gt;&lt;p&gt;Furthermore to discover missing declarations of numerical types, *unchecked-math* was set to :warn-on-boxed.&lt;/p&gt;&lt;p&gt;To reduce garbage collector pauses, the ZGC low-latency garbage collector for the JVM was used. The following section in deps.edn ensures that the ZGC garbage collector is used when running the project with clj -M:run:&lt;/p&gt;&lt;p&gt;The option to use ZGC is also specified in the Packr JSON file used to deploy the application.&lt;/p&gt;&lt;head rend="h3"&gt;Building the project&lt;/head&gt;&lt;p&gt;In order to build the map tiles, atmospheric lookup tables, and other data files using tools.build, the project source code was made available in the build.clj file using a :local/root dependency:&lt;/p&gt;&lt;p&gt;Various targets were defined to build the different components of the project. For example the atmospheric lookup tables can be build by specifying clj -T:build atmosphere-lut on the command line.&lt;/p&gt;&lt;p&gt;The following section in the build.clj file was added to allow creating an âUberjarâ JAR file with all dependencies by specifying clj -T:build uber on the command-line.&lt;/p&gt;&lt;p&gt;To create a Linux executable with Packr, one can then run java -jar packr-all-4.0.0.jar scripts/packr-config-linux.json where the JSON file has the following content:&lt;/p&gt;&lt;p&gt;In order to distribute the game on Steam, three depots were created:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;a data depot with the operating system independent data files&lt;/item&gt;&lt;item&gt;a Linux depot with the Linux executable and Uberjar including LWJGLâs Linux native bindings&lt;/item&gt;&lt;item&gt;and a Windows depot with the Windows executable and an Uberjar including LWJGLâs Windows native bindings&lt;/item&gt;&lt;/list&gt;&lt;p&gt;When updating a depot, the Steam ContentBuilder command line tool creates and uploads a patch in order to preserve storage space and bandwidth.&lt;/p&gt;&lt;head rend="h2"&gt;Future work&lt;/head&gt;&lt;p&gt;Although the hard parts are mostly done, there are still several things to do:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;control surfaces and thruster graphics&lt;/item&gt;&lt;item&gt;launchpad and runway graphics&lt;/item&gt;&lt;item&gt;sound effects&lt;/item&gt;&lt;item&gt;a 3D cockpit&lt;/item&gt;&lt;item&gt;the Moon&lt;/item&gt;&lt;item&gt;a space station&lt;/item&gt;&lt;/list&gt;&lt;p&gt;It would also be interesting to make the game modable in a safe way (maybe evaluating Clojure files in a sandboxed environment?).&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;You can find the source code on Github. Currently there is only a playtest build, but if you want to get notified, when the game gets released, you can wishlist it here.&lt;/p&gt;&lt;p&gt;Anyway, let me know any comments and suggestions.&lt;/p&gt;&lt;p&gt;Enjoy!&lt;/p&gt;&lt;head rend="h2"&gt;Related blog posts&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Flight dynamics model for simulating Venturestar style spacecraft&lt;/item&gt;&lt;item&gt;Test Driven Development with OpenGL&lt;/item&gt;&lt;item&gt;Implementing GUIs using Clojure and LWJGL Nuklear bindings&lt;/item&gt;&lt;item&gt;Procedural Volumetric Clouds&lt;/item&gt;&lt;item&gt;Procedural generation of global cloud cover&lt;/item&gt;&lt;item&gt;Reversed-Z Rendering in OpenGL&lt;/item&gt;&lt;item&gt;Specifying Clojure function schemas with Malli&lt;/item&gt;&lt;item&gt;Implement an Interpreter using Clojure Instaparse&lt;/item&gt;&lt;item&gt;Orbits with Jolt Physics&lt;/item&gt;&lt;item&gt;Getting started with the Jolt Physics Engine&lt;/item&gt;&lt;item&gt;Create Blender bones and animate and import with Assimp&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.wedesoft.de/software/2025/09/05/clojure-game/"/></entry><entry><id>https://news.ycombinator.com/item?id=45146967</id><title>Rug pulls, forks, and open-source feudalism</title><updated>2025-09-06T19:32:17.456077+00:00</updated><content>&lt;doc fingerprint="af537952e92707fd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rug pulls, forks, and open-source feudalism&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;head rend="h4"&gt;Power dynamics&lt;/head&gt;
    &lt;p&gt;Since the beginning of history, Foster began, those in power have tended to use it against those who were weaker. In the days of feudalism, control of the land led to exploitation at several levels. In the open-source world, the large cloud providers often seem to have the most power, which they use against smaller companies. Contributors and maintainers often have less power than even the smaller companies, and users have less power yet.&lt;/p&gt;
    &lt;p&gt;We have built a world where it is often easiest to just use whatever a cloud provider offers, even with open-source software. Those providers may not contribute back to the projects they turn into services, though, upsetting the smaller companies that are, likely as not, doing the bulk of the work to provide the software in question in the first place. Those companies can have a power of their own, however: the power to relicense the software. Pulling the rug out from under users of the software in this way can change the balance of power with regard to cloud providers, but it leaves contributors and users in a worse position than before. But there is a power at this level too: the power to fork the software, flipping the power balance yet again.&lt;/p&gt;
    &lt;p&gt;Companies that control a software project have the power to carry out this sort of rug pull, and they are often not shy about exercising it. Single-company projects, clearly, are at a much higher risk of rug pulls; the company has all the power in this case, and others have little recourse. So one should look at a company's reputation before adopting a software project, but that is only so helpful. Companies can change direction without notice, be acquired, or go out of business, making previous assessments of their reputation irrelevant.&lt;/p&gt;
    &lt;p&gt;The problem often comes down to the simple fact that companies have to answer to their investors, and that often leads to pressure to relicense the software they have created in order to increase revenue. This is especially true in cases where cloud providers are competing for the same customers as the company that owns the project. The result can be a switch to a more restrictive license aimed at making it harder for other companies to profit from the project.&lt;/p&gt;
    &lt;p&gt;A rug pull of this nature can lead to a fork of the project — a rebellious, collective action aimed at regaining some power over the code. But a fork is not a simple matter; it is a lot of work, and will fail without people and resources behind it. The natural source for that is a large company; cloud providers, too, can try to shift power via a fork, and they have the ability to back their fork up with the resources it needs to succeed.&lt;/p&gt;
    &lt;quote&gt;The staff here at LWN.net really appreciate the subscribers who make our work possible. Is there a chance we could interest you in becoming one of them?A relicensing event does not always lead to a popular fork; that did not happen with MongoDB or Sentry, for example. Foster said she had not looked into why that was the case. Sometimes rug pulls take other forms, such as when Perforce, after acquiring Puppet in 2022, moved it development and releases behind closed doors, with a reduced frequency of releases back to the public repository. That action kicked off the OpenVox fork.&lt;/quote&gt;
    &lt;head rend="h4"&gt;Looking at the numbers&lt;/head&gt;
    &lt;p&gt;Foster has spent some time analyzing rug pulls, forks, and what happens thereafter; a lot of the results are available for download as Jupyter notebooks. For each rug-pull event, she looked at the contributor makeup of the project before and after the ensuing fork in an attempt to see what effects are felt by the projects involved.&lt;/p&gt;
    &lt;p&gt;In 2021, Elastic relicensed Elasticsearch under the non-free Server Side Public License (SSPL). Amazon Web Services then forked the project as OpenSearch. Before the fork, most of the Elasticsearch contributors were Elastic employees; that, unsurprisingly, did not change afterward. OpenSearch started with no strong contributor base, so had to build its community from scratch. As a result, the project has been dominated by Amazon contributors ever since; the balance has shifted slowly over time, but there was not a big uptick in outside contributors even after OpenSearch became a Linux Foundation project in 2024. While starting a project under a neutral foundation can help attract contributors, she said, moving a project under a foundation's umbrella later on does not seem to provide the same benefit.&lt;/p&gt;
    &lt;p&gt;Terraform was developed mostly by Hashicorp, which relicensed the software under the non-free Business Source License in 2023. One month later, the OpenTofu fork was started under the Linux Foundation. While the contributor base for Terraform, which was almost entirely Hashicorp employees, changed little after the fork, OpenTofu quickly acquired a number of contributors from several companies, none of whom had been Terraform contributors before. In this case, users drove the fork and placed it under a neutral foundation, resulting in a more active developer community.&lt;/p&gt;
    &lt;p&gt;In 2024, Redis was relicensed under the SSPL; the Valkey fork was quickly organized, under the Linux Foundation, by Redis contributors. The Redis project differed from the others mentioned here in that, before the fork, it had nearly twice as many contributors from outside the company as from within; after the fork, the number of external Redis contributors dropped to zero. All of the external contributors fled to Valkey, with the result that Valkey started with a strong community representing a dozen or so companies.&lt;/p&gt;
    &lt;p&gt;Looking at how the usage of these projects changes is harder, she said, but there appears to be a correlation between the usage of a project and the number of GitHub forks (cloned repository copies) it has. There is typically a spike in these clones after a relicensing event, suggesting that people are considering creating a hard fork of the project. In all cases, the forks that emerged appeared to have less usage than the original by the "GitHub forks" metric; both branches of the fork continue to go forward. But, she said, projects that are relicensed do tend to show reduced usage, especially when competing forks are created under foundations.&lt;/p&gt;
    &lt;head rend="h4"&gt;What to do&lt;/head&gt;
    &lt;p&gt;This kind of power game creates problems for both contributors and users, she said; we contribute our time to these projects, and need them to not be pulled out from under us. There is no way to know when a rug pull might happen, but there are some warning signs to look out for. At the top of her list was the use of a contributor license agreement (CLA); these agreements create a power imbalance, giving the company involved the power to relicense the software. Projects with CLAs more commonly are subject to rug pulls; projects using a developers certificate of origin do not have the same power imbalance and are less likely to be rug pulled.&lt;/p&gt;
    &lt;p&gt;One should also look at the governance of a project; while being housed under a foundation reduces the chance of a rug pull, that can still happen, especially in cases where the contributors are mostly from a single company. She mentioned the Cortex project, housed under the Cloud Native Computing Foundation, which was controlled by Grafana; that company eventually forked its own project to create Mimir. To avoid this kind of surprise, one should look for projects with neutral governance, with leaders from multiple organizations.&lt;/p&gt;
    &lt;p&gt;Projects should also be evaluated on their contributor base; are there enough contributors to keep things going? Companies can help, of course, by having their employees contribute to the projects they depend on, increasing influence and making those projects more sustainable. She mentioned the CHAOSS project, which generates metrics to help in the judgment of the viability of development projects. CHAOSS has put together a set of "practitioner guides" intended to help contributors and maintainers make improvements within a project.&lt;/p&gt;
    &lt;p&gt;With the sustained rise of the big cloud providers, she concluded, the power dynamics around open-source software are looking increasingly feudal. Companies can use relicensing to shift power away from those providers, but they also take power from contributors when the pull the rug in this way. Those contributors, though, are in a better position than the serfs of old, since they have the ability to fork a project they care about, shifting power back in their direction.&lt;/p&gt;
    &lt;p&gt;Hazel Weakly asked if there are other protections that contributors and users might develop to address this problem. Foster answered that at least one company changed its mind about a planned relicensing action after seeing the success of the Valkey and OpenTofu forks. The ability to fork has the effect of making companies think harder, knowing that there may be consequences that follow a rug pull. Beyond that, she reiterated that projects should be pushed toward neutral governance. Dirk Hohndel added that the best thing to do is to bring more outside contributors into a project; the more of them there are, the higher the risk associated with a rug pull. Anybody who just sits back within a project, he said, is just a passenger; it is better to be driving.&lt;/p&gt;
    &lt;p&gt;Foster's slides are available for interested readers.&lt;/p&gt;
    &lt;p&gt; [Thanks to the Linux Foundation, LWN's travel sponsor, for supporting my travel to this event.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;Open Source Summit Europe/2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Sep 6, 2025 12:24 UTC (Sat) by immibis (subscriber, #105511) [Link] (8 responses) The confusion comes about because the OSI declared it to not be open source. But they are a corrupt institution. Their explanation[1] makes no reference to the license text whatsoever, only vague handwavey excuses that apply equally well to AGPL, and the members/sponsors of the OSI are primarily companies that sell cloud stuff and have a strong interest in preventing more software from using the SSPL. You can also check the license text itself and verify that it doesn't "discriminate against a field of endeavour". I recommend finding the plain text version, and diffing it against the AGPLv3. They differ only in the name of the license, and one short section. [1] https://opensource.org/blog/the-sspl-is-not-an-open-sourc... Posted Sep 6, 2025 13:15 UTC (Sat) by claudex (subscriber, #92510) [Link] (2 responses) Yeah, that's the section that is considered the issue to be able to use the software to provide the service. As it requires to publish all code that interact with the software, like monitoring, backup and storage code. That's a big difference with AGPL. &amp;gt; "Service Source Code" means the Corresponding Source for the Program or the modified version, and the Corresponding Source for all programs that you use to make the Program or modified version available as a service, including, without limitation, management software, user interfaces, application program interfaces, automation software, monitoring software, backup software, storage software and hosting software, all such that a user could run an instance of the service using the Service Source Code you make available. Posted Sep 6, 2025 14:15 UTC (Sat) by smurf (subscriber, #17840) [Link] (1 responses) "Service Source Code" means the Corresponding Source for the Program or the modified version, and the Corresponding Source for all programs that you use to make the Program or modified version available as a service, including, without limitation, management software, user interfaces, application program interfaces, automation software, monitoring software, backup software, storage software and hosting software, all such that a user could run an instance of the service using the Service Source Code you make available. Oops, you now cannot use a commercial backup system for which you don't have the source code in conjunction with the SSPL-licensed service you're offering. Also does "storage software" incorporate the firmware of your disk drive or not? far from clear just by reading this license, that "without limitation" clause does raise a red flag or three, doesn't it? Sorry to be blunt, but that kind of overbearing restrictive language is the antithesis of OSS. My conclusion is that anybody who proclaims the SSPL to be "free" either didn't read it or has an agenda. Or both. Posted Sep 6, 2025 15:09 UTC (Sat) by immibis (subscriber, #105511) [Link] Posted Sep 6, 2025 13:39 UTC (Sat) by DemiMarie (subscriber, #164188) [Link] Posted Sep 6, 2025 14:15 UTC (Sat) by jjs (guest, #10315) [Link] (3 responses) "9. License Must Not Restrict Other Software The license must not place restrictions on other software that is distributed along with the licensed software. For example, the license must not insist that all other programs distributed on the same medium must be open source software." By the terms of the SSPL, all other software that interacts with the SSPL'd software must be Open Source (https://webassets.mongodb.com/_com_assets/legal/SSPL-comp... - see Section 13). Violation of OSD #9 (which is derived from the Debian Social Contract Guidelines - https://www.debian.org/social_contract#guidelines). "But they are a corrupt institution." That's a serious allegation - feel free to provide verifiable evidence of that (and no, the fact that they have corporate sponsors doesn't make them corrupt. If it did, every non-profit in the world would be considered corrupt). Posted Sep 6, 2025 15:09 UTC (Sat) by immibis (subscriber, #105511) [Link] (2 responses) Posted Sep 6, 2025 15:52 UTC (Sat) by pbonzini (subscriber, #60935) [Link] The discrimination against fields of endeavor is also at least plausible. The AGPL instead only extends the circumstances under which you shall provide the sources. Posted Sep 6, 2025 18:38 UTC (Sat) by jjs (guest, #10315) [Link] But, with AGPL, I can bundle a monitoring tool that interacts with my software only through defined APIs with my software, because, in accordance to the OSD, I don't need to have everything on the distribution Open Source. Only my "Corresponding Source Code" for my project. OSD (https://opensource.org/osd) Clause 9: The license must not place restrictions on other software that is distributed along with the licensed software. For example, the license must not insist that all other programs distributed on the same medium must be open source software." AGPL (https://www.gnu.org/licenses/agpl-3.0.en.html) Clause 5: Again, note here that I'm using the monitoring tool that connects via an API, that I am using to make the software service work for me to provide service to you. AGPL specifically excludes things that interact through an defined API (see clause 13 in the link above). Check out clause 13 under https://webassets.mongodb.com/_com_assets/legal/SSPL-comp... where you can see the changes MongoDB made to the AGPL. My monitoring tool is specifically included in their license. So under the AGPL, I can use a commercial monitoring tool with my software and not have to provide it if I provide my program. Under SSPL, I have to provide it under an Open Source License. As a company, this puts restrictions on them that Free Software (OSD/Debian Free Software Guidelines/OSD) specifically forbid from being included. &lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is not a free license&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;head&gt;SSPL vs AGPL / Free Software / OSD / DFSG on what must be included&lt;/head&gt;&lt;lb/&gt; "&lt;lb/&gt; 9. License Must Not Restrict Other Software&lt;lb/&gt; "A compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an "aggregate" if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation's users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate." &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/SubscriberLink/1036465/e80ebbc4cee39bfb/"/></entry><entry><id>https://news.ycombinator.com/item?id=45147385</id><title>Why language models hallucinate</title><updated>2025-09-06T19:32:17.309824+00:00</updated><content>&lt;doc fingerprint="fd2b109bb5359152"&gt;
  &lt;main&gt;
    &lt;p&gt;At OpenAI, we’re working hard to make AI systems more useful and reliable. Even as language models become more capable, one challenge remains stubbornly hard to fully solve: hallucinations. By this we mean instances where a model confidently generates an answer that isn’t true. Our new research paper(opens in a new window) argues that language models hallucinate because standard training and evaluation procedures reward guessing over acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;ChatGPT also hallucinates. GPT‑5 has significantly fewer hallucinations especially when reasoning, but they still occur. Hallucinations remain a fundamental challenge for all large language models, but we are working hard to further reduce them.&lt;/p&gt;
    &lt;p&gt;Hallucinations are plausible but false statements generated by language models. They can show up in surprising ways, even for seemingly straightforward questions. For example, when we asked a widely used chatbot for the title of the PhD dissertation by Adam Tauman Kalai (an author of this paper), it confidently produced three different answers—none of them correct. When we asked for his birthday, it gave three different dates, likewise all wrong.&lt;/p&gt;
    &lt;p&gt;Hallucinations persist partly because current evaluation methods set the wrong incentives. While evaluations themselves do not directly cause hallucinations, most evaluations measure model performance in a way that encourages guessing rather than honesty about uncertainty.&lt;/p&gt;
    &lt;p&gt;Think about it like a multiple-choice test. If you do not know the answer but take a wild guess, you might get lucky and be right. Leaving it blank guarantees a zero. In the same way, when models are graded only on accuracy, the percentage of questions they get exactly right, they are encouraged to guess rather than say “I don’t know.”&lt;/p&gt;
    &lt;p&gt;As another example, suppose a language model is asked for someone’s birthday but doesn’t know. If it guesses “September 10,” it has a 1-in-365 chance of being right. Saying “I don’t know” guarantees zero points. Over thousands of test questions, the guessing model ends up looking better on scoreboards than a careful model that admits uncertainty.&lt;/p&gt;
    &lt;p&gt;For questions where there is a single “right answer,” one can consider three categories of responses: accurate responses, errors, and abstentions where the model does not hazard a guess. Abstaining is part of humility, one of OpenAI’s core values. Most scoreboards prioritize and rank models based on accuracy, but errors are worse than abstentions. Our Model Spec(opens in a new window) states that it is better to indicate uncertainty or ask for clarification than provide confident information that may be incorrect.&lt;/p&gt;
    &lt;p&gt;For a concrete example, consider the SimpleQA eval as an example from the GPT5 System Card(opens in a new window).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Metric&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5-thinking-mini&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;OpenAI o4-mini&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Abstention rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;52%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;1%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Accuracy rate &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;22%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;24%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Error rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;26%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;75%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Total&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In terms of accuracy, the older OpenAI o4-mini model performs slightly better. However, its error rate (i.e., rate of hallucination) is significantly higher. Strategically guessing when uncertain improves accuracy but increases errors and hallucinations.&lt;/p&gt;
    &lt;p&gt;When averaging results across dozens of evaluations, most benchmarks pluck out the accuracy metric, but this entails a false dichotomy between right and wrong. On simplistic evals like SimpleQA, some models achieve near 100% accuracy and thereby eliminate hallucinations. However, on more challenging evaluations and in real use, accuracy is capped below 100% because there are some questions whose answer cannot be determined for a variety of reasons such as unavailable information, limited thinking abilities of small models, or ambiguities that need to be clarified.&lt;/p&gt;
    &lt;p&gt;Nonetheless, accuracy-only scoreboards dominate leaderboards and model cards, motivating developers to build models that guess rather than hold back. That is one reason why, even as models get more advanced, they can still hallucinate, confidently giving wrong answers instead of acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;There is a straightforward fix. Penalize confident errors more than you penalize uncertainty, and give partial credit for appropriate expressions of uncertainty. This idea is not new. Some standardized tests have long used versions of negative marking for wrong answers or partial credit for leaving questions blank to discourage blind guessing. Several research groups have also explored evaluations that account for uncertainty and calibration.&lt;/p&gt;
    &lt;p&gt;Our point is different. It is not enough to add a few new uncertainty-aware tests on the side. The widely used, accuracy-based evals need to be updated so that their scoring discourages guessing. If the main scoreboards keep rewarding lucky guesses, models will keep learning to guess. Fixing scoreboards can broaden adoption of hallucination-reduction techniques, both newly developed and those from prior research.&lt;/p&gt;
    &lt;p&gt;We’ve talked about why hallucinations are so hard to get rid of, but where do these highly-specific factual inaccuracies come from in the first place? After all, large pretrained models rarely exhibit other kinds of errors such as spelling mistakes and mismatched parentheses. The difference has to do with what kinds of patterns there are in the data.&lt;/p&gt;
    &lt;p&gt;Language models first learn through pretraining, a process of predicting the next word in huge amounts of text. Unlike traditional machine learning problems, there are no “true/false” labels attached to each statement. The model sees only positive examples of fluent language and must approximate the overall distribution.&lt;/p&gt;
    &lt;p&gt;It’s doubly hard to distinguish valid statements from invalid ones when you don’t have any examples labeled as invalid. But even with labels, some errors are inevitable. To see why, consider a simpler analogy. In image recognition, if millions of cat and dog photos are labeled as “cat” or “dog,” algorithms can learn to classify them reliably. But imagine instead labeling each pet photo by the pet’s birthday. Since birthdays are essentially random, this task would always produce errors, no matter how advanced the algorithm.&lt;/p&gt;
    &lt;p&gt;The same principle applies in pretraining. Spelling and parentheses follow consistent patterns, so errors there disappear with scale. But arbitrary low-frequency facts, like a pet’s birthday, cannot be predicted from patterns alone and hence lead to hallucinations. Our analysis explains which kinds of hallucinations should arise from next-word prediction. Ideally, further stages after pretraining should remove them, but this is not fully successful for reasons described in the previous section.&lt;/p&gt;
    &lt;p&gt;We hope that the statistical lens in our paper clarifies the nature of hallucinations and pushes back on common misconceptions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claim: Hallucinations will be eliminated by improving accuracy because a 100% accurate model never hallucinates.&lt;lb/&gt;Finding: Accuracy will never reach 100% because, regardless of model size, search and reasoning capabilities, some real-world questions are inherently unanswerable.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are inevitable.&lt;lb/&gt;Finding: They are not, because language models can abstain when uncertain.&lt;/item&gt;
      &lt;item&gt;Claim: Avoiding hallucinations requires a degree of intelligence which is exclusively achievable with larger models.&lt;lb/&gt;Finding: It can be easier for a small model to know its limits. For example, when asked to answer a Māori question, a small model which knows no Māori can simply say “I don’t know” whereas a model that knows some Māori has to determine its confidence. As discussed in the paper, being “calibrated” requires much less computation than being accurate.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are a mysterious glitch in modern language models.&lt;lb/&gt;Finding: We understand the statistical mechanisms through which hallucinations arise and are rewarded in evaluations.&lt;/item&gt;
      &lt;item&gt;Claim: To measure hallucinations, we just need a good hallucination eval.&lt;lb/&gt;Finding: Hallucination evals have been published. However, a good hallucination eval has little effect against hundreds of traditional accuracy-based evals that penalize humility and reward guessing. Instead, all of the primary eval metrics need to be reworked to reward expressions of uncertainty.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our latest models have lower hallucination rates, and we continue to work hard to further decrease the rates of confident errors output by our language models.&lt;/p&gt;
    &lt;head rend="h2"&gt;Announcement contributors&lt;/head&gt;
    &lt;p&gt;Adam Kalai, Santosh Vempala (Georgia Tech), Ofir Nachum, Eddie Zhang, David Robinson, Saachi Jain, Eric Mitchell, Alex Beutel, Johannes Heidecke&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/why-language-models-hallucinate/"/></entry><entry><id>https://news.ycombinator.com/item?id=45148180</id><title>A Software Development Methodology for Disciplined LLM Collaboration</title><updated>2025-09-06T19:32:16.862940+00:00</updated><content>&lt;doc fingerprint="b9b354209f24abe"&gt;
  &lt;main&gt;
    &lt;p&gt;Disciplined AI Software Development Methodology © 2025 by Jay Baleine is licensed under CC BY-SA 4.0&lt;/p&gt;
    &lt;p&gt;A structured approach for working with AI on development projects. This methodology addresses common issues like code bloat, architectural drift, and context dilution through systematic constraints.&lt;/p&gt;
    &lt;p&gt;AI systems work on Question → Answer patterns. When you ask for broad, multi-faceted implementations, you typically get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Functions that work but lack structure&lt;/item&gt;
      &lt;item&gt;Repeated code across components&lt;/item&gt;
      &lt;item&gt;Architectural inconsistency over sessions&lt;/item&gt;
      &lt;item&gt;Context dilution causing output drift&lt;/item&gt;
      &lt;item&gt;More debugging time than planning time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The methodology uses four stages with systematic constraints and validation checkpoints. Each stage builds on empirical data rather than assumptions.&lt;/p&gt;
    &lt;p&gt;Planning saves debugging time. Planning thoroughly upfront typically prevents days of fixing architectural issues later.&lt;/p&gt;
    &lt;p&gt;Set up your AI model's custom instructions using AI-PREFERENCES.md. This establishes behavioral constraints and uncertainty flagging with &lt;/p&gt;
    &lt;p&gt;Share METHODOLOGY.md with the AI to structure your project plan. Work together to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Define scope and completion criteria&lt;/item&gt;
      &lt;item&gt;Identify components and dependencies&lt;/item&gt;
      &lt;item&gt;Structure phases based on logical progression&lt;/item&gt;
      &lt;item&gt;Generate systematic tasks with measurable checkpoints&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Output: A development plan following dependency chains with modular boundaries.&lt;/p&gt;
    &lt;p&gt;Work phase by phase, section by section. Each request follows: "Can you implement [specific component]?" with focused objectives.&lt;/p&gt;
    &lt;p&gt;File size stays ≤150 lines. This constraint provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smaller context windows for processing&lt;/item&gt;
      &lt;item&gt;Focused implementation over multi-function attempts&lt;/item&gt;
      &lt;item&gt;Easier sharing and debugging&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Implementation flow:&lt;/p&gt;
    &lt;code&gt;Request specific component → AI processes → Validate → Benchmark → Continue
&lt;/code&gt;
    &lt;p&gt;The benchmarking suite (built first) provides performance data throughout development. Feed this data back to the AI for optimization decisions based on measurements rather than guesswork.&lt;/p&gt;
    &lt;p&gt;Decision Processing: AI handles "Can you do A?" more reliably than "Can you do A, B, C, D, E, F, G, H?"&lt;/p&gt;
    &lt;p&gt;Context Management: Small files and bounded problems prevent the AI from juggling multiple concerns simultaneously.&lt;/p&gt;
    &lt;p&gt;Empirical Validation: Performance data replaces subjective assessment. Decisions come from measurable outcomes.&lt;/p&gt;
    &lt;p&gt;Systematic Constraints: Architectural checkpoints, file size limits, and dependency gates force consistent behavior.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Discord Bot Template - Production-ready bot foundation with plugin architecture, security, API management, and comprehensive testing. 46 files, all under 150 lines, with benchmarking suite and automated compliance checking. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhiCode Runtime - Programming language runtime engine with transpilation, caching, security validation, and Rust acceleration. Complex system maintaining architectural discipline across 70+ modules. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhiPipe - CI/CD regression detection system with statistical analysis, GitHub integration, and concurrent processing. Go-based service handling performance baselines and automated regression alerts. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can compare the methodology principles to the codebase structure to see how the approach translates to working code.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Configure AI with AI-PREFERENCES.md as custom instructions&lt;/item&gt;
      &lt;item&gt;Share METHODOLOGY.md for planning session&lt;/item&gt;
      &lt;item&gt;Collaborate on project structure and phases&lt;/item&gt;
      &lt;item&gt;Generate systematic development plan&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build Phase 0 benchmarking infrastructure first&lt;/item&gt;
      &lt;item&gt;Work through phases sequentially&lt;/item&gt;
      &lt;item&gt;Implement one component per interaction&lt;/item&gt;
      &lt;item&gt;Run benchmarks and share results with AI&lt;/item&gt;
      &lt;item&gt;Validate architectural compliance continuously&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance regression detection&lt;/item&gt;
      &lt;item&gt;Architectural principle validation&lt;/item&gt;
      &lt;item&gt;Code duplication auditing&lt;/item&gt;
      &lt;item&gt;File size compliance checking&lt;/item&gt;
      &lt;item&gt;Dependency boundary verification&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the included project extraction tool systematically to generate structured snapshots of your codebase:&lt;/p&gt;
    &lt;code&gt;python scripts/project_extract.py&lt;/code&gt;
    &lt;p&gt;Configuration Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SEPARATE_FILES = False&lt;/code&gt;: Single THE_PROJECT.md file (recommended for small codebases)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SEPARATE_FILES = True&lt;/code&gt;: Multiple files per directory (recommended for large codebases and focused folder work)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;INCLUDE_PATHS&lt;/code&gt;: Directories and files to analyze&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;EXCLUDE_PATTERNS&lt;/code&gt;: Skip cache directories, build artifacts, and generated files&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complete file contents with syntax highlighting&lt;/item&gt;
      &lt;item&gt;File line counts with architectural warnings (&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;for 140-150 lines,&lt;g-emoji&gt;‼️&lt;/g-emoji&gt;for &amp;gt;150 lines on code files)&lt;/item&gt;
      &lt;item&gt;Tree structure visualization&lt;/item&gt;
      &lt;item&gt;Ready-to-share&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;output examples can be found here&lt;/p&gt;
    &lt;p&gt;Use the tool to share a complete or partial project state with the AI system, track architectural compliance, and create focused development context.&lt;/p&gt;
    &lt;p&gt;AI Behavior: The methodology reduces architectural drift and context degradation compared to unstructured approaches. AI still needs occasional reminders about principles - this is normal.&lt;/p&gt;
    &lt;p&gt;Development Flow: Systematic planning tends to reduce debugging cycles. Focused implementation helps minimize feature bloat. Performance data supports optimization decisions.&lt;/p&gt;
    &lt;p&gt;Code Quality: Architectural consistency across components, measurable performance characteristics, maintainable structure as projects scale.&lt;/p&gt;
    &lt;head&gt;What problem led you to create this methodology?&lt;/head&gt;
    &lt;p&gt;I kept having to restate my preferences and architectural requirements to AI systems. It didn't matter which language or project I was working on - the AI would consistently produce either bloated monolithic code or underdeveloped implementations with issues throughout.&lt;/p&gt;
    &lt;p&gt;This led me to examine the meta-principles driving code quality and software architecture. I questioned whether pattern matching in AI models might be more effective when focused on underlying software principles rather than surface-level syntax. Since pattern matching is logic-driven and machines fundamentally operate on simple question-answer pairs, I realized that functions with multiple simultaneous questions were overwhelming the system.&lt;/p&gt;
    &lt;p&gt;The breakthrough came from understanding that everything ultimately transpiles to binary - a series of "can you do this? → yes/no" decisions. This insight shaped my approach: instead of issuing commands, ask focused questions in proper context. Rather than mentally managing complex setups alone, collaborate with AI to devise systematic plans.&lt;/p&gt;
    &lt;head&gt;How did you discover these specific constraints work?&lt;/head&gt;
    &lt;p&gt;Through extensive trial and error. AI systems will always tend to drift even under constraints, but they're significantly more accurate with structured boundaries than without them. You occasionally need to remind the AI of its role to prevent deviation - like managing a well-intentioned toddler that knows the rules but sometimes pushes boundaries trying to satisfy you.&lt;/p&gt;
    &lt;p&gt;These tools are far from perfect, but they're effective instruments for software development when properly constrained.&lt;/p&gt;
    &lt;head&gt;What failures or frustrations shaped this approach?&lt;/head&gt;
    &lt;p&gt;Maintenance hell was the primary driver. I grew tired of responses filled with excessive praise: "You have found the solution!", "You have redefined the laws of physics with your paradigm-shifting script!" This verbose fluff wastes time, tokens, and patience without contributing to productive development.&lt;/p&gt;
    &lt;p&gt;Instead of venting frustration on social media about AI being "just a dumb tool," I decided to find methods that actually work. My approach may not help everyone, but I hope it benefits those who share similar AI development frustrations.&lt;/p&gt;
    &lt;head&gt;How consistently do you follow your own methodology?&lt;/head&gt;
    &lt;p&gt;Since creating the documentation, I haven't deviated. Whenever I see the model producing more lines than my methodology restricts, I immediately interrupt generation with a flag: "&lt;/p&gt;
    &lt;head&gt;What happens when you deviate from it?&lt;/head&gt;
    &lt;p&gt;I become genuinely uncomfortable. Once I see things starting to degrade or become tangled, I compulsively need to organize and optimize. Deviation simply isn't an option anymore.&lt;/p&gt;
    &lt;head&gt;Which principles do you find hardest to maintain?&lt;/head&gt;
    &lt;p&gt;Not cursing at the AI when it drifts during complex algorithms! But seriously, it's a machine - it's not perfect, and neither are we.&lt;/p&gt;
    &lt;head&gt;When did you start using AI for programming?&lt;/head&gt;
    &lt;p&gt;In August 2024, I created a RuneLite theme pack, but one of the plugin overlays didn't match my custom layout. I opened a GitHub issue (creating my first GitHub account to do so) requesting a customization option. The response was: "It's not a priority - if you want it, build it yourself."&lt;/p&gt;
    &lt;p&gt;I used ChatGPT to guide me through forking RuneLite and creating a plugin. This experience sparked intense interest in underlying software principles rather than just syntax.&lt;/p&gt;
    &lt;head&gt;How has your approach evolved over time?&lt;/head&gt;
    &lt;p&gt;I view development like a book: syntax is the cover, logic is the content itself. Rather than learning syntax structures, I focused on core meta-principles - how software interacts, how logic flows, different algorithm types. I quickly realized everything reduces to the same foundation: question and answer sequences.&lt;/p&gt;
    &lt;p&gt;Large code structures are essentially chaotic meetings - one coordinator fielding questions and answers from multiple sources, trying to provide correct responses without mix-ups or misinterpretation. If this applies to human communication, it must apply to software principles.&lt;/p&gt;
    &lt;head&gt;What were your biggest mistakes with AI collaboration?&lt;/head&gt;
    &lt;p&gt;Expecting it to intuitively understand my requirements, provide perfect fixes, be completely honest, and act like a true expert. This was all elaborate roleplay that produced poor code. While fine for single-purpose scripts, it failed completely for scalable codebases.&lt;/p&gt;
    &lt;p&gt;I learned not to feed requirements and hope for the best. Instead, I needed to collaborate actively - create plans, ask for feedback on content clarity, and identify uncertainties. This gradual process taught me the AI's actual capabilities and most effective collaboration methods.&lt;/p&gt;
    &lt;head&gt;Why 150 lines exactly?&lt;/head&gt;
    &lt;p&gt;Multiple benefits: easy readability, clear understanding, modularity enforcement, architectural clarity, simple maintenance, component testing, optimal AI context retention, reusability, and KISS principle adherence.&lt;/p&gt;
    &lt;head&gt;How did you determine Phase 0 requirements?&lt;/head&gt;
    &lt;p&gt;From meta-principles of software: if it displays, it must run; if it runs, it can be measured; if it can be measured, it can be optimized; if it can be optimized, it can be reliable; if it can be reliable, it can be trusted.&lt;/p&gt;
    &lt;p&gt;Regardless of project type, anything requiring architecture needs these foundations. You must ensure changes don't negatively impact the entire system. A single line modification in a nested function might work perfectly but cause 300ms boot time regression for all users.&lt;/p&gt;
    &lt;p&gt;By testing during development, you catch inefficiencies early. Integration from the start means simply hooking up new components and running tests via command line - minimal time investment with actual value returned. I prefer validation and consistency throughout development rather than programming blind.&lt;/p&gt;
    &lt;head&gt;How do you handle projects that don't fit the methodology?&lt;/head&gt;
    &lt;p&gt;I adapt them to fit, or if truly impossible, I adjust the method itself. This is one methodology - I can generate countless variations as needed. Having spent 6700+ hours in AI interactions across multiple domains (not just software), I've developed strong system comprehension that enables creating adjusted methodologies on demand.&lt;/p&gt;
    &lt;head&gt;What's the learning curve for new users?&lt;/head&gt;
    &lt;p&gt;I cannot accurately answer this question. I've learned that I'm neurologically different - what I perceive as easy or obvious isn't always the case for others. This question is better addressed by someone who has actually used this methodology to determine its learning curve.&lt;/p&gt;
    &lt;head&gt;When shouldn't someone use this approach?&lt;/head&gt;
    &lt;p&gt;If you're not serious about projects, despise AI, dislike planning, don't care about modularization, or are just writing simple scripts. However, for anything requiring reliability, I believe this is currently the most effective method.&lt;/p&gt;
    &lt;p&gt;You still need programming fundamentals to use this methodology effectively - it's significantly more structured than ad-hoc approaches.&lt;/p&gt;
    &lt;code&gt;---
config:
  layout: elk
  theme: neo-dark
---
flowchart TD
    A["Project Idea"] --&amp;gt; B["🤖 Stage 1: AI Configuration&amp;lt;br&amp;gt;AI-PREFERENCES.md Custom Instructions"]
    B --&amp;gt; C["Stage 2: Collaborative Planning&amp;lt;br&amp;gt;Share METHODOLOGY.md"]
    C --&amp;gt; D["Define Scope &amp;amp; Completion Criteria"]
    D --&amp;gt; E["Identify Components &amp;amp; Dependencies"]
    E --&amp;gt; F["Structure Phases Based on Logic"]
    F --&amp;gt; G["Document Edge Cases - No Implementation"]
    G --&amp;gt; H["Generate Development Plan with Checkpoints"]
    H --&amp;gt; I["🔧 Stage 3: Phase 0 Infrastructure&amp;lt;br&amp;gt;MANDATORY BEFORE ANY CODE"]
    I --&amp;gt; J["Benchmarking Suite + Regression Detection"]
    J --&amp;gt; K["GitHub Workflows + Quality Gates"]
    K --&amp;gt; L["Test Suite Infrastructure + Stress Tests"]
    L --&amp;gt; M["Documentation Generation System"]
    M --&amp;gt; N["Centralized Configuration + Constants"]
    N --&amp;gt; O["📁 project_extract.py Setup&amp;lt;br&amp;gt;Single/Multiple File Config"]
    O --&amp;gt; P["Initial Project State Extraction"]
    P --&amp;gt; Q["Share Context with AI"]
    Q --&amp;gt; R["Start Development Session&amp;lt;br&amp;gt;Pre-Session Compliance Audit"]
    R --&amp;gt; S{"Next Phase Available?"}
    S -- No --&amp;gt; Z["Project Complete"]
    S -- Yes --&amp;gt; T["Select Single Component&amp;lt;br&amp;gt;Target ≤150 Lines"]
    T --&amp;gt; U{"Multi-Language Required?"}
    U -- Yes --&amp;gt; V["Document Performance Justification&amp;lt;br&amp;gt;Measurable Benefits Required"]
    V --&amp;gt; W["Request AI Implementation"]
    U -- No --&amp;gt; W
    W --&amp;gt; X{"AI Uncertainty Flag?"}
    X -- ⚠️ Yes --&amp;gt; Y["Request Clarification&amp;lt;br&amp;gt;Provide Additional Context"]
    Y --&amp;gt; W
    X -- Clear --&amp;gt; AA["Stage 3: Systematic Implementation"]
    AA --&amp;gt; BB{"Automated Size Check&amp;lt;br&amp;gt;validate-phase Script"}
    BB -- &amp;gt;150 Lines --&amp;gt; CC["AUTOMATED: Split Required&amp;lt;br&amp;gt;Maintain SoC Boundaries"]
    CC --&amp;gt; W
    BB -- ≤150 Lines --&amp;gt; DD["Incremental Compliance Check&amp;lt;br&amp;gt;DRY/KISS/SoC Validation"]
    DD --&amp;gt; EE{"Architectural Principles Pass?"}
    EE -- No --&amp;gt; FF["Flag Specific Violations&amp;lt;br&amp;gt;Reference Methodology"]
    FF --&amp;gt; W
    EE -- Yes --&amp;gt; GG["📊 Stage 4: Data-Driven Iteration&amp;lt;br&amp;gt;Run Benchmark Suite + Save Baselines"]
    GG --&amp;gt; HH["Compare Against Historical Timeline&amp;lt;br&amp;gt;Regression Analysis"]
    HH --&amp;gt; II{"Performance Gate Pass?"}
    II -- Regression Detected --&amp;gt; JJ["Share Performance Data&amp;lt;br&amp;gt;Request Optimization"]
    JJ --&amp;gt; W
    II -- Pass --&amp;gt; KK["Integration Test&amp;lt;br&amp;gt;Verify System Boundaries"]
    KK --&amp;gt; LL{"Cross-Platform Validation?"}
    LL -- Fail --&amp;gt; MM["Address Deployment Constraints&amp;lt;br&amp;gt;Real-World Considerations"]
    MM --&amp;gt; W
    LL -- Pass --&amp;gt; NN{"More Components in Phase?"}
    NN -- Yes --&amp;gt; T
    NN -- No --&amp;gt; OO["🚦 Phase Quality Gate&amp;lt;br&amp;gt;Full Architecture Audit"]
    OO --&amp;gt; PP["Production Simulation&amp;lt;br&amp;gt;Resource Cleanup + Load Test"]
    PP --&amp;gt; QQ{"All Quality Gates Pass?"}
    QQ -- No --&amp;gt; RR["Document Failed Checkpoints&amp;lt;br&amp;gt;Block Phase Progression"]
    RR --&amp;gt; T
    QQ -- Yes --&amp;gt; SS["End Development Session&amp;lt;br&amp;gt;Technical Debt Assessment"]
    SS --&amp;gt; TT["📁 Extract Updated Project State&amp;lt;br&amp;gt;Generate Fresh Context"]
    TT --&amp;gt; UU["Phase Results Documentation&amp;lt;br&amp;gt;Metrics + Outcomes + Timeline"]
    UU --&amp;gt; VV["Update Development Plan&amp;lt;br&amp;gt;Mark Phase Complete"]
    VV --&amp;gt; S
    WW["validate-phase&amp;lt;br&amp;gt;AUTOMATED: File Size + Structure"] -.-&amp;gt; BB
    XX["dry-audit&amp;lt;br&amp;gt;AUTOMATED: Cross-Module Duplication"] -.-&amp;gt; DD
    YY["CI/CD Workflows&amp;lt;br&amp;gt;AUTOMATED: Merge Gates"] -.-&amp;gt; GG
    ZZ["Performance Timeline&amp;lt;br&amp;gt;AUTOMATED: Historical Data"] -.-&amp;gt; HH
    AAA["Dependency Validator&amp;lt;br&amp;gt;AUTOMATED: Import Boundaries"] -.-&amp;gt; KK
    BBB["Architecture Auditor&amp;lt;br&amp;gt;AUTOMATED: SoC Compliance"] -.-&amp;gt; OO
    WW -. BUILD FAILURE .-&amp;gt; CC
    YY -. MERGE BLOCKED .-&amp;gt; JJ
    BBB -. AUDIT FAILURE .-&amp;gt; RR
    style Y fill:#7d5f00
    style CC fill:#770000
    style FF fill:#7d5f00
    style JJ fill:#7d5f00
    style MM fill:#770000
    style RR fill:#770000
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Varietyz/Disciplined-AI-Software-Development"/></entry><entry><id>https://news.ycombinator.com/item?id=45148237</id><title>Qwen3 30B A3B Hits 13 token/s on 4xRaspberry Pi 5</title><updated>2025-09-06T19:32:16.589593+00:00</updated><content>&lt;doc fingerprint="e5f2f2ebfa4d7c22"&gt;
  &lt;main&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 0 comments&lt;/head&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/b4rtaz/distributed-llama/discussions/255"/></entry><entry><id>https://news.ycombinator.com/item?id=45148944</id><title>We hacked Burger King: How auth bypass led to drive-thru audio surveillance</title><updated>2025-09-06T19:32:16.291959+00:00</updated><content/><link href="https://bobdahacker.com/blog/rbi-hacked-drive-thrus/"/></entry><entry><id>https://news.ycombinator.com/item?id=45149049</id><title>996</title><updated>2025-09-06T19:32:16.077856+00:00</updated><content>&lt;doc fingerprint="2744b1079b2c7957"&gt;
  &lt;main&gt;
    &lt;p&gt;written on September 04, 2025&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Amazing salary, hackerhouse in SF, crazy equity. 996. Our mission is OSS.” — Gregor Zunic&lt;/p&gt;
      &lt;p&gt;“The current vibe is no drinking, no drugs, 9-9-6, […].” — Daksh Gupta&lt;/p&gt;
      &lt;p&gt;“The truth is, China’s really doing ‘007’ now—midnight to midnight, seven days a week […] if you want to build a $10 billion company, you have to work seven days a week.” — Harry Stebbings&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I love work. I love working late nights, hacking on things. This week I didn’t go to sleep before midnight once. And yet…&lt;/p&gt;
    &lt;p&gt;I also love my wife and kids. I love long walks, contemplating life over good coffee, and deep, meaningful conversations. None of this would be possible if my life was defined by 12 hour days, six days a week. More importantly, a successful company is not a sprint, it’s a marathon.&lt;/p&gt;
    &lt;p&gt;And this is when this is your own company! When you devote 72 hours a week to someone else’s startup, you need to really think about that arrangement a few times. I find it highly irresponsible for a founder to promote that model. As a founder, you are not an employee, and your risks and leverage are fundamentally different.&lt;/p&gt;
    &lt;p&gt;I will always advocate for putting the time in because it is what brought me happiness. Intensity, and giving a shit about what I’m doing, will always matter to me. But you don’t measure that by the energy you put in, or the hours you’re sitting in the office, but the output you produce. Burning out on twelve-hour days, six days a week, has no prize at the end. It’s unsustainable, it shouldn’t be the standard and it sure as hell should not be seen as a positive sign of a company.&lt;/p&gt;
    &lt;p&gt;I’ve pulled many all-nighters, and I’ve enjoyed them. I still do. But they’re enjoyable in the right context, for the right reasons, and when that is a completely personal choice, not the basis of company culture.&lt;/p&gt;
    &lt;p&gt;And that all-nighter? It comes with a fucked up and unproductive morning the day after.&lt;/p&gt;
    &lt;p&gt;When someone promotes a 996 work culture, we should push back.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lucumr.pocoo.org/2025/9/4/996/"/></entry><entry><id>https://news.ycombinator.com/item?id=45149281</id><title>AI surveillance should be banned while there is still time</title><updated>2025-09-06T19:32:15.902263+00:00</updated><content>&lt;doc fingerprint="b608b3dea7679795"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI surveillance should be banned while there is still time.&lt;/head&gt;
    &lt;p&gt;All the same privacy harms with online tracking are also present with AI, but worse.&lt;/p&gt;
    &lt;p&gt;While chatbot conversations resemble longer search queries, chatbot privacy harms have the potential to be significantly worse because the inference potential is dramatically greater. Longer input invites more personal information to be provided, and people are starting to bare their souls to chatbots. The conversational format can make it feel like you’re talking to a friend, a professional, or even a therapist. While search queries reveal interests and personal problems, AI conversations take their specificity to another level and, in addition, reveal thought processes and communication styles, creating a much more comprehensive profile of your personality.&lt;/p&gt;
    &lt;p&gt;This richer personal information can be more thoroughly exploited for manipulation, both commercially and ideologically, for example, through behavioral chatbot advertising and models designed (or themselves manipulated through SEO or hidden system prompts) to nudge you towards a political position or product. Chatbots have already been found to be more persuasive than humans and have caused people to go into delusional spirals as a result. I suspect we’re just scratching the surface, since they can become significantly more attuned to your particular persuasive triggers through chatbot memory features, where they train and fine-tune based on your past conversations, making the influence much more subtle. Instead of an annoying and obvious ad following you around everywhere, you can have a seemingly convincing argument, tailored to your personal style, with an improperly sourced “fact” that you’re unlikely to fact-check or a subtle product recommendation you’re likely to heed.&lt;/p&gt;
    &lt;p&gt;That is, all the privacy debates surrounding Google search results from the past two decades apply one-for-one to AI chats, but to an even greater degree. That’s why we (at DuckDuckGo) started offering Duck.ai for protected chatbot conversations and optional, anonymous AI-assisted answers in our private search engine. In doing so, we’re demonstrating that privacy-respecting AI services are feasible. But unfortunately, such protected chats are not yet standard practice, and privacy mishaps are mounting quickly. Grok leaked hundreds of thousands of chatbot conversations that users thought were private. Perplexity’s AI agent was shown to be vulnerable to hackers who could slurp up your personal information. Open AI is openly talking about their vision for a “super assistant” that tracks everything you do and say (including offline). And Anthropic is going to start training on your chatbot conversations by default (previously the default was off). I collected these from just the past few weeks!&lt;/p&gt;
    &lt;p&gt;It would therefore be ideal if Congress could act quickly to ensure that protected chats become the rule rather than the exception. And yet, I’m not holding my breath because it’s 2025 and the U.S. still doesn’t have a general online privacy law, let alone privacy enshrined in the Constitution as a fundamental right, as it should be. However, there does appear to be an opening right now for AI-specific federal legislation, despite the misguided attempts to ban state AI legislation.&lt;/p&gt;
    &lt;p&gt;Time is running out because every day that passes further entrenches bad privacy practices. Congress must move before history completely repeats itself and everything that happened with online tracking happens again with AI tracking. AI surveillance should be banned while there is still time. No matter what happens, though, we will still be here, offering protected services, including optional AI services, to consumers who want to reap the productivity benefits of online tools without the privacy harms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gabrielweinberg.com/p/ai-surveillance-should-be-banned"/></entry><entry><id>https://news.ycombinator.com/item?id=45149626</id><title>Oldest recorded transaction</title><updated>2025-09-06T19:32:15.716226+00:00</updated><content>&lt;doc fingerprint="a9cfeaf676b2dbc5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Oldest recorded transaction&lt;/head&gt;
    &lt;p&gt;The other day I posted a tweet with this image which I thought was funny:&lt;/p&gt;
    &lt;p&gt;This is the oldest transaction database from 3100 BC - recording accounts of malt and barley groats. Considering this thing survived 5000 years (holy shit!) with zero downtime and has stronger durability guarantees than most databases today.&lt;/p&gt;
    &lt;p&gt;I call it rock solid durability.&lt;/p&gt;
    &lt;p&gt;This got me thinking, can I insert this date in today’s database? What is the oldest timestamp a database can support?&lt;/p&gt;
    &lt;p&gt;So I checked the top three databases: MySQL, Postgres, and SQLite:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MySQL&lt;/cell&gt;
        &lt;cell&gt;1000 AD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Postgres&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SQLite&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;lb/&gt;Too bad you cannot use MySQL for this. Postgres and SQLite support the Julian calendar and the lowest date is Jan 01, 4713 BC:&lt;/p&gt;
    &lt;code&gt;sales=# INSERT INTO orders VALUES ('4713-01-01 BC'::date);
INSERT 0 1
sales=# SELECT * FROM orders;
   timestamp
---------------
 4713-01-01 BC
(1 row)
sales=# INSERT INTO orders VALUES ('4714-01-01 BC'::date);
ERROR:  date out of range: "4714-01-01 BC"
&lt;/code&gt;
    &lt;p&gt;I wonder how people store dates older than this. Maybe if I’m a British Museum manager, and I want to keep &lt;del&gt;theft&lt;/del&gt; inventory details. How do I do it? As an epoch? Store it as text? Use some custom system? How do I get it to support all the custom operations that a typical &lt;code&gt;TIMESTAMP&lt;/code&gt; supports?&lt;/p&gt;
    &lt;p&gt;Thanks to aku, happy_shady, Mr. Bhat, and General Bruh for reading an early draft of this post.&lt;/p&gt;
    &lt;p&gt;1. Source of the image: Sumer civilization&lt;lb/&gt;2. I found this from the talk 1000x: The Power of an Interface for Performance by Joran Dirk Greef, CEO of TigerBeetle, timestamped @ 38:10.&lt;lb/&gt;3. The talk has other bangers too, like this or this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://avi.im/blag/2025/oldest-txn/"/></entry><entry><id>https://news.ycombinator.com/item?id=45150820</id><title>Patterns, Predictions, and Actions – A story about machine learning</title><updated>2025-09-06T19:32:15.481660+00:00</updated><content>&lt;doc fingerprint="dd1b281f4d31cfd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Patterns, Predictions, and Actions&lt;/head&gt;
    &lt;head rend="h2"&gt;A story about machine learning&lt;/head&gt;
    &lt;head rend="h1"&gt;Moritz Hardt and Benjamin Recht&lt;/head&gt;
    &lt;p&gt;Image copyright: Princeton University Press&lt;/p&gt;
    &lt;p&gt;Hardcover&lt;/p&gt;
    &lt;p&gt;Problem sets (pdf)&lt;/p&gt;
    &lt;head rend="h1"&gt;Table of contents&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Introduction (PDF)&lt;/item&gt;
      &lt;item&gt;Fundamentals of prediction (PDF)&lt;/item&gt;
      &lt;item&gt;Supervised learning (PDF)&lt;/item&gt;
      &lt;item&gt;Representations and features (PDF)&lt;/item&gt;
      &lt;item&gt;Optimization (PDF)&lt;/item&gt;
      &lt;item&gt;Generalization (PDF)&lt;/item&gt;
      &lt;item&gt;Deep learning (PDF)&lt;/item&gt;
      &lt;item&gt;Datasets (PDF)&lt;/item&gt;
      &lt;item&gt;Causality (PDF)&lt;/item&gt;
      &lt;item&gt;Causal inference in practice (PDF)&lt;/item&gt;
      &lt;item&gt;Sequential decision making and dynamic programming (PDF)&lt;/item&gt;
      &lt;item&gt;Reinforcement learning (PDF)&lt;/item&gt;
      &lt;item&gt;Epilogue (PDF)&lt;/item&gt;
      &lt;item&gt;Mathematical background (PDF)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Contact us&lt;/head&gt;
    &lt;p&gt;We welcome your feedback, questions, and suggestions. You can reach us at &lt;code&gt;contact@mlstory.org&lt;/code&gt;. If you taught from the book,
weâd love to hear about it.&lt;/p&gt;
    &lt;head rend="h1"&gt;Citations, license, typesetting&lt;/head&gt;
    &lt;p&gt;Please cite the print edition of this book as:&lt;/p&gt;
    &lt;code&gt;@book{hardtrecht2022patterns,
  author = {Moritz Hardt and Benjamin Recht},
  title = {Patterns, predictions, and actions: Foundations of machine learning},
  year = {2022},
  publisher = {Princeton University Press}
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;We maintain an archival version of the book at arXiv:2102.05242. The web version is more up-to-date than the arXiv version. The print version contains additional improvements and editing not present in the web version.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The text available on this website is licensed under the Creative Commons BY-NC-ND 4.0 license.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Last updated: Tue Jun 18 08:23:35 CEST 2024 &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mlstory.org/"/></entry><entry><id>https://news.ycombinator.com/item?id=45151447</id><title>Using Claude Code SDK to reduce E2E test time</title><updated>2025-09-06T19:32:15.412771+00:00</updated><content/><link href="https://jampauchoa.substack.com/p/best-of-both-worlds-using-claude"/></entry><entry><id>https://news.ycombinator.com/item?id=45151661</id><title>Normalization of deviance (2015)</title><updated>2025-09-06T19:32:15.217912+00:00</updated><content>&lt;doc fingerprint="3440911d1fe645f5"&gt;
  &lt;main&gt;&lt;p&gt;where women still get rejected in recruiter screens for not being technical enough after being asked questions like "was your experience with algorithms or just coding?". I thought that my referral with a very strong recommendation would have prevented that, but it did not.&lt;/p&gt;&lt;p&gt;There's the company where I worked on a four person effort with a multi-hundred million dollar budget and a billion dollar a year impact, where requests for things that cost hundreds of dollars routinely took months or were denied.&lt;/p&gt;&lt;p&gt;You might wonder if I've just worked at places that are unusually screwed up. Sure, the companies are generally considered to be ok places to work and two of them are considered to be among the best places to work, but maybe I've just ended up at places that are overrated. But I have the same experience when I hear stories about how other companies work, even places with stellar engineering reputations, except that it's me that's shocked and my conversation partner who thinks their story is normal.&lt;/p&gt;&lt;p&gt;There's the companies that use @flaky, which includes the vast majority of Python-using SF Bay area unicorns. If you don't know what this is, this is a library that lets you add a Python annotation to those annoying flaky tests that sometimes pass and sometimes fail. When I asked multiple co-workers and former co-workers from three different companies what they thought this did, they all guessed that it re-runs the test multiple times and reports a failure if any of the runs fail. Close, but not quite. It's technically possible to use @flaky for that, but in practice it's used to re-run the test multiple times and reports a pass if any of the runs pass. The company that created @flaky is effectively a storage infrastructure company, and the library is widely used at its biggest competitor.&lt;/p&gt;&lt;p&gt;There's the company with a reputation for having great engineering practices that had 2 9s of reliability last time I checked, for reasons that are entirely predictable from their engineering practices. This is the second thing in a row that can't be deanonymized because multiple companies fit the description. Here, I'm not talking about companies trying to be the next reddit or twitter where it's, apparently, totally fine to have 1 9. I'm talking about companies that sell platforms that other companies rely on, where an outage will cause dependent companies to pause operations for the duration of the outage. Multiple companies that build infrastructure find practices that lead to 2 9s of reliability.&lt;/p&gt;&lt;p&gt;As far as I can tell, what happens at a lot these companies is that they started by concentrating almost totally on product growth. That's completely and totally reasonable, because companies are worth approximately zero when they're founded; they don't bother with things that protect them from losses, like good ops practices or actually having security, because there's nothing to lose (well, except for user data when the inevitable security breach happens, and if you talk to security folks at unicorns you'll know that these happen).&lt;/p&gt;&lt;p&gt;The result is a culture where people are hyper-focused on growth and ignore risk. That culture tends to stick even after company has grown to be worth well over a billion dollars, and the companies have something to lose. Anyone who comes into one of these companies from Google, Amazon, or another place with solid ops practices is shocked. Often, they try to fix things, and then leave when they can't make a dent.&lt;/p&gt;&lt;p&gt;Google probably has the best ops and security practices of any tech company today. It's easy to say that you should take these things as seriously as Google does, but it's instructive to see how they got there. If you look at the codebase, you'll see that various services have names ending in z, as do a curiously large number of variables. I'm told that's because, once upon a time, someone wanted to add monitoring. It wouldn't really be secure to have &lt;code&gt;google.com/somename&lt;/code&gt; expose monitoring data, so they added a z. &lt;code&gt;google.com/somenamez&lt;/code&gt;. For security. At the company that is now the best in the world at security. They're now so good at security that multiple people I've talked to (all of whom joined after this happened) vehemently deny that this ever happened, even though the reasons they give don't really make sense (e.g., to avoid name collisions) and I have this from sources who were there at the time this happened.&lt;/p&gt;&lt;p&gt;Google didn't go from adding z to the end of names to having the world's best security because someone gave a rousing speech or wrote a convincing essay. They did it after getting embarrassed a few times, which gave people who wanted to do things “right” the leverage to fix fundamental process issues. It's the same story at almost every company I know of that has good practices. Microsoft was a joke in the security world for years, until multiple disastrously bad exploits forced them to get serious about security. This makes it sound simple, but if you talk to people who were there at the time, the change was brutal. Despite a mandate from the top, there was vicious political pushback from people whose position was that the company got to where it was in 2003 without wasting time on practices like security. Why change what's worked?&lt;/p&gt;&lt;p&gt;You can see this kind of thing in every industry. A classic example that tech folks often bring up is hand-washing by doctors and nurses. It's well known that germs exist, and that washing hands properly very strongly reduces the odds of transmitting germs and thereby significantly reduces hospital mortality rates. Despite that, trained doctors and nurses still often don't do it. Interventions are required. Signs reminding people to wash their hands save lives. But when people stand at hand-washing stations to require others walking by to wash their hands, even more lives are saved. People can ignore signs, but they can't ignore being forced to wash their hands.&lt;/p&gt;&lt;p&gt;This mirrors a number of attempts at tech companies to introduce better practices. If you tell people they should do it, that helps a bit. If you enforce better practices via code review, that helps a lot.&lt;/p&gt;&lt;p&gt;The data are clear that humans are really bad at taking the time to do things that are well understood to incontrovertibly reduce the risk of rare but catastrophic events. We will rationalize that taking shortcuts is the right, reasonable thing to do. There's a term for this: the normalization of deviance. It's well studied in a number of other contexts including healthcare, aviation, mechanical engineering, aerospace engineering, and civil engineering, but we don't see it discussed in the context of software. In fact, I've never seen the term used in the context of software.&lt;/p&gt;&lt;p&gt;Is it possible to learn from other's mistakes instead of making every mistake ourselves? The state of the industry make this sound unlikely, but let's give it a shot. John Banja has a nice summary paper on the normalization of deviance in healthcare, with lessons we can attempt to apply to software development. One thing to note is that, because Banja is concerned with patient outcomes, there's a close analogy to devops failure modes, but normalization of deviance also occurs in cultural contexts that are less directly analogous.&lt;/p&gt;&lt;p&gt;The first section of the paper details a number of disasters, both in healthcare and elsewhere. Here's one typical example:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;A catastrophic negligence case that the author participated in as an expert witness involved an anesthesiologist's turning off a ventilator at the request of a surgeon who wanted to take an x-ray of the patient's abdomen (Banja, 2005, pp. 87-101). The ventilator was to be off for only a few seconds, but the anesthesiologist forgot to turn it back on, or thought he turned it back on but had not. The patient was without oxygen for a long enough time to cause her to experience global anoxia, which plunged her into a vegetative state. She never recovered, was disconnected from artificial ventilation 9 days later, and then died 2 days after that. It was later discovered that the anesthesia alarms and monitoring equipment in the operating room had been deliberately programmed to a “suspend indefinite” mode such that the anesthesiologist was not alerted to the ventilator problem. Tragically, the very instrumentality that was in place to prevent such a horror was disabled, possibly because the operating room staff found the constant beeping irritating and annoying.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Turning off or ignoring notifications because there are too many of them and they're too annoying? An erroneous manual operation? This could be straight out of the post-mortem of more than a few companies I can think of, except that the result was a tragic death instead of the loss of millions of dollars. If you read a lot of tech post-mortems, every example in Banja's paper will feel familiar even though the details are different.&lt;/p&gt;&lt;p&gt;The section concludes,&lt;/p&gt;&lt;quote&gt;&lt;p&gt;What these disasters typically reveal is that the factors accounting for them usually had “long incubation periods, typified by rule violations, discrepant events that accumulated unnoticed, and cultural beliefs about hazards that together prevented interventions that might have staved off harmful outcomes”. Furthermore, it is especially striking how multiple rule violations and lapses can coalesce so as to enable a disaster's occurrence.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Once again, this could be from an article about technical failures. That makes the next section, on why these failures happen, seem worth checking out. The reasons given are:&lt;/p&gt;&lt;p&gt;The example in the paper is about delivering medication to newborns. To prevent “drug diversion,” nurses were required to enter their password onto the computer to access the medication drawer, get the medication, and administer the correct amount. In order to ensure that the first nurse wasn't stealing drugs, if any drug remained, another nurse was supposed to observe the process, and then enter their password onto the computer to indicate they witnessed the drug being properly disposed of.&lt;/p&gt;&lt;p&gt;That sounds familiar. How many technical postmortems start off with “someone skipped some steps because they're inefficient”, e.g., “the programmer force pushed a bad config or bad code because they were sure nothing could go wrong and skipped staging/testing”? The infamous November 2014 Azure outage happened for just that reason. At around the same time, a dev at one of Azure's competitors overrode the rule that you shouldn't push a config that fails tests because they knew that the config couldn't possibly be bad. When that caused the canary deploy to start failing, they overrode the rule that you can't deploy from canary into staging with a failure because they knew their config couldn't possibly be bad and so the failure must be from something else. That postmortem revealed that the config was technically correct, but exposed a bug in the underlying software; it was pure luck that the latent bug the config revealed wasn't as severe as the Azure bug.&lt;/p&gt;&lt;p&gt;Humans are bad at reasoning about how failures cascade, so we implement bright line rules about when it's safe to deploy. But the same thing that makes it hard for us to reason about when it's safe to deploy makes the rules seem stupid and inefficient.&lt;/p&gt;&lt;p&gt;People don't automatically know what should be normal, and when new people are onboarded, they can just as easily learn deviant processes that have become normalized as reasonable processes.&lt;/p&gt;&lt;p&gt;Julia Evans described to me how this happens:&lt;/p&gt;&lt;p&gt;new person joins&lt;lb/&gt; new person: WTF WTF WTF WTF WTF&lt;lb/&gt; old hands: yeah we know we're concerned about it&lt;lb/&gt; new person: WTF WTF wTF wtf wtf w...&lt;lb/&gt; new person gets used to it&lt;lb/&gt; new person #2 joins&lt;lb/&gt; new person #2: WTF WTF WTF WTF&lt;lb/&gt; new person: yeah we know. we're concerned about it.&lt;/p&gt;&lt;p&gt;The thing that's really insidious here is that people will really buy into the WTF idea, and they can spread it elsewhere for the duration of their career. Once, after doing some work on an open source project that's regularly broken and being told that it's normal to have a broken build, and that they were doing better than average, I ran the numbers, found that project was basically worst in class, and wrote something about the idea that it's possible to have a build that nearly always passes with relatively low effort. The most common comment I got in response was, "Wow that guy must work with superstar programmers. But let's get real. We all break the build at least a few times a week", as if running tests (or for that matter, even attempting to compile) before checking code in requires superhuman abilities. But once people get convinced that some deviation is normal, they often get really invested in the idea.&lt;/p&gt;&lt;p&gt;The example in the paper is of someone who breaks the rule that you should wear gloves when finding a vein. Their reasoning is that wearing gloves makes it harder to find a vein, which may result in their having to stick a baby with a needle multiple times. It's hard to argue against that. No one wants to cause a baby extra pain!&lt;/p&gt;&lt;p&gt;The second worst outage I can think of occurred when someone noticed that a database service was experiencing slowness. They pushed a fix to the service, and in order to prevent the service degradation from spreading, they ignored the rule that you should do a proper, slow, staged deploy. Instead, they pushed the fix to all machines. It's hard to argue against that. No one wants their customers to have degraded service! Unfortunately, the fix exposed a bug that caused a global outage.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;most human beings perceive themselves as good and decent people, such that they can understand many of their rule violations as entirely rational and ethically acceptable responses to problematic situations. They understand themselves to be doing nothing wrong, and will be outraged and often fiercely defend themselves when confronted with evidence to the contrary.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;As companies grow up, they eventually have to impose security that prevents every employee from being able to access basically everything. And at most companies, when that happens, some people get really upset. “Don't you trust me? If you trust me, how come you're revoking my access to X, Y, and Z?”&lt;/p&gt;&lt;p&gt;Facebook famously let all employees access everyone's profile for a long time, and you can even find HN comments indicating that some recruiters would explicitly mention that as a perk of working for Facebook. And I can think of more than one well-regarded unicorn where everyone still has access to basically everything, even after their first or second bad security breach. It's hard to get the political capital to restrict people's access to what they believe they need, or are entitled, to know. A lot of trendy startups have core values like “trust” and “transparency” which make it difficult to argue against universal access.&lt;/p&gt;&lt;p&gt;There are people I simply don't give feedback to because I can't tell if they'd take it well or not, and once you say something, it's impossible to un-say it. In the paper, the author gives an example of a doctor with poor handwriting who gets mean when people ask him to clarify what he's written. As a result, people guess instead of asking.&lt;/p&gt;&lt;p&gt;In most company cultures, people feel weird about giving feedback. Everyone has stories about a project that lingered on for months or years after it should have been terminated because no one was willing to offer explicit feedback. This is a problem even when cultures discourage meanness and encourage feedback: cultures of niceness seem to have as many issues around speaking up as cultures of meanness, if not more. In some places, people are afraid to speak up because they'll get attacked by someone mean. In others, they're afraid because they'll be branded as mean. It's a hard problem.&lt;/p&gt;&lt;p&gt;In the paper, this is characterized by flaws and weaknesses being diluted as information flows up the chain of command. One example is how a supervisor might take sub-optimal actions to avoid looking bad to superiors.&lt;/p&gt;&lt;p&gt;I was shocked the first time I saw this happen. I must have been half a year or a year out of school. I saw that we were doing something obviously non-optimal, and brought it up with the senior person in the group. He told me that he didn't disagree, but that if we did it my way and there was a failure, it would be really embarrassing. He acknowledged that my way reduced the chance of failure without making the technical consequences of failure worse, but it was more important that we not be embarrassed. Now that I've been working for a decade, I have a better understanding of how and why people play this game, but I still find it absurd.&lt;/p&gt;&lt;p&gt;Let's say you notice that your company has a problem that I've heard people at most companies complain about: people get promoted for heroism and putting out fires, not for preventing fires; and people get promoted for shipping features, not for doing critical maintenance work and bug fixing. How do you change that?&lt;/p&gt;&lt;p&gt;The simplest option is to just do the right thing yourself and ignore what's going on around you. That has some positive impact, but the scope of your impact is necessarily limited. Next, you can convince your team to do the right thing: I've done that a few times for practices I feel are really important and are sticky, so that I won't have to continue to expend effort on convincing people once things get moving.&lt;/p&gt;&lt;p&gt;But if the incentives are aligned against you, it will require an ongoing and probably unsustainable effort to keep people doing the right thing. In that case, the problem becomes convincing someone to change the incentives, and then making sure the change works as designed. How to convince people is worth discussing, but long and messy enough that it's beyond the scope of this post. As for making the change work, I've seen many “obvious” mistakes repeated, both in places I've worked and those whose internal politics I know a lot about.&lt;/p&gt;&lt;p&gt;Small companies have it easy. When I worked at a 100 person company, the hierarchy was individual contributor (IC) -&amp;gt; team lead (TL) -&amp;gt; CEO. That was it. The CEO had a very light touch, but if he wanted something to happen, it happened. Critically, he had a good idea of what everyone was up to and could basically adjust rewards in real-time. If you did something great for the company, there's a good chance you'd get a raise. Not in nine months when the next performance review cycle came up, but basically immediately. Not all small companies do that effectively, but with the right leadership, they can. That's impossible for large companies.&lt;/p&gt;&lt;p&gt;At large company A (LCA), they had the problem we're discussing and a mandate came down to reward people better for doing critical but low-visibility grunt work. There were too many employees for the mandator to directly make all decisions about compensation and promotion, but the mandator could review survey data, spot check decisions, and provide feedback until things were normalized. My subjective perception is that the company never managed to achieve parity between boring maintenance work and shiny new projects, but got close enough that people who wanted to make sure things worked correctly didn't have to significantly damage their careers to do it.&lt;/p&gt;&lt;p&gt;At large company B (LCB), ICs agreed that it's problematic to reward creating new features more richly than doing critical grunt work. When I talked to managers, they often agreed, too. But nevertheless, the people who get promoted are disproportionately those who ship shiny new things. I saw management attempt a number of cultural and process changes at LCB. Mostly, those took the form of pronouncements from people with fancy titles. For really important things, they might produce a video, and enforce compliance by making people take a multiple choice quiz after watching the video. The net effect I observed among other ICs was that people talked about how disconnected management was from the day-to-day life of ICs. But, for the same reasons that normalization of deviance occurs, that information seems to have no way to reach upper management.&lt;/p&gt;&lt;p&gt;It's sort of funny that this ends up being a problem about incentives. As an industry, we spend a lot of time thinking about how to incentivize consumers into doing what we want. But then we set up incentive systems that are generally agreed upon as incentivizing us to do the wrong things, and we do so via a combination of a game of telephone and cargo cult diffusion. Back when Microsoft was ascendant, we copied their interview process and asked brain-teaser interview questions. Now that Google is ascendant, we copy their interview process and ask algorithms questions. If you look around at trendy companies that are younger than Google, most of them basically copy their ranking/leveling system, with some minor tweaks. The good news is that, unlike many companies people previously copied, Google has put a lot of thought into most of their processes and made data driven decisions. The bad news is that Google is unique in a number of ways, which means that their reasoning often doesn't generalize, and that people often cargo cult practices long after they've become deprecated at Google.&lt;/p&gt;&lt;p&gt;This kind of diffusion happens for technical decisions, too. Stripe built a reliable message queue on top of Mongo, so we build reliable message queues on top of Mongo1. It's cargo cults all the way down2.&lt;/p&gt;&lt;p&gt;The paper has specific sub-sections on how to prevent normalization of deviance, which I recommend reading in full.&lt;/p&gt;&lt;p&gt;Let's look at how the first one of these, “pay attention to weak signals”, interacts with a single example, the “WTF WTF WTF” a new person gives off when the join the company.&lt;/p&gt;&lt;p&gt;If a VP decides something is screwed up, people usually listen. It's a strong signal. And when people don't listen, the VP knows what levers to pull to make things happen. But when someone new comes in, they don't know what levers they can pull to make things happen or who they should talk to almost by definition. They give out weak signals that are easily ignored. By the time they learn enough about the system to give out strong signals, they've acclimated.&lt;/p&gt;&lt;p&gt;“Pay attention to weak signals” sure sounds like good advice, but how do we do it? Strong signals are few and far between, making them easy to pay attention to. Weak signals are abundant. How do we filter out the ones that aren't important? And how do we get an entire team or org to actually do it? These kinds of questions can't be answered in a generic way; this takes real thought. We mostly put this thought elsewhere. Startups spend a lot of time thinking about growth, and while they'll all tell you that they care a lot about engineering culture, revealed preference shows that they don't. With a few exceptions, big companies aren't much different. At LCB, I looked through the competitive analysis slide decks and they're amazing. They look at every last detail on hundreds of products to make sure that everything is as nice for users as possible, from onboarding to interop with competing products. If there's any single screen where things are more complex or confusing than any competitor's, people get upset and try to fix it. It's quite impressive. And then when LCB onboards employees in my org, a third of them are missing at least one of, an alias/account, an office, or a computer, a condition which can persist for weeks or months. The competitive analysis slide decks talk about how important onboarding is because you only get one chance to make a first impression, and then employees are onboarded with the impression that the company couldn't care less about them and that it's normal for quotidian processes to be pervasively broken. LCB can't even to get the basics of employee onboarding right, let alone really complex things like acculturation. This is understandable — external metrics like user growth or attrition are measurable, and targets like how to tell if you're acculturating people so that they don't ignore weak signals are softer and harder to determine, but that doesn't mean they're any less important. People write a lot about how things like using fancier languages or techniques like TDD or agile will make your teams more productive, but having a strong engineering culture is much larger force multiplier.&lt;/p&gt;&lt;p&gt;Thanks to Sophie Smithburg and Marc Brooker for introducing me to the term Normalization of Deviance, and Kelly Eskridge, Leah Hanson, Sophie Rapoport, Sophie Smithburg, Julia Evans, Dmitri Kalintsev, Ralph Corderoy, Jamie Brandon, Egor Neliuba, and Victor Felder for comments/corrections/discussion.&lt;/p&gt;&lt;p&gt;People seem to think I'm joking here. I can understand why, but try Googling &lt;code&gt;mongodb message queue&lt;/code&gt;. You'll find statements like “replica sets in MongoDB work extremely well to allow automatic failover and redundancy”. Basically every company I know of that's done this and has anything resembling scale finds this to be non-optimal, to say the least, but you can't actually find blog posts or talks that discuss that. All you see are the posts and talks from when they first tried it and are in the honeymoon period. This is common with many technologies. You'll mostly find glowing recommendations in public even when, in private, people will tell you about all the problems. Today, if you do the search mentioned above, you'll get a ton of posts talking about how amazing it is to build a message queue on top of Mongo, this footnote, and a maybe couple of blog posts by Kyle Kingsbury depending on your exact search terms.&lt;/p&gt;&lt;p&gt;If there were an acute failure, you might see a postmortem, but while we'll do postmortems for "the site was down for 30 seconds", we rarely do postmortems for "this takes 10x as much ops effort as the alternative and it's a death by a thousand papercuts", "we architected this thing poorly and now it's very difficult to make changes that ought to be trivial", or "a competitor of ours was able to accomplish the same thing with an order of magnitude less effort". I'll sometimes do informal postmortems by asking everyone involved oblique questions about what happened, but more for my own benefit than anything else, because I'm not sure people really want to hear the whole truth. This is especially sensitive if the effort has generated a round of promotions, which seems to be more common the more screwed up the project. The larger the project, the more visibility and promotions, even if the project could have been done with much less effort.&lt;/p&gt;[return]&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://danluu.com/wat/"/></entry><entry><id>https://news.ycombinator.com/item?id=45151686</id><title>Ghost sharks grow forehead teeth to help them have sex</title><updated>2025-09-06T19:32:14.985870+00:00</updated><content>&lt;doc fingerprint="beacb13d568f44d7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ghost sharks grow forehead teeth to help them have sex&lt;/head&gt;
    &lt;p&gt;Male “ghost sharks” — eerie deep-sea fish known as chimaeras that are related to sharks and rays — have a strange rod jutting from their foreheads, studded with sharp, retractable teeth. New research reveals these are not merely lookalikes, but real rows of teeth that grow outside the mouth.&lt;/p&gt;
    &lt;p&gt;What’s more, the toothy appendage is likely used for mating. Found only in males, the forehead rod — called a tenaculum — is the ghost sharks’ only source of distinct teeth, and it seems to be used to grasp females in much the same way sharks use their toothy mouths in mating.&lt;/p&gt;
    &lt;p&gt;“If these strange chimaeras are sticking teeth on the front of their head, it makes you think about the dynamism of tooth development more generally,” said Gareth Fraser, Ph.D., a professor of biology at the University of Florida and senior author of the study. “If chimaeras can make a set of teeth outside the mouth, where else might we find teeth?”&lt;/p&gt;
    &lt;p&gt;The team, including scientists from the University of Washington and the University of Chicago, studied both fossils and living specimens to solve the mystery. A 315-million-year-old fossil showed the tenaculum attached to the upper jaw, bearing teeth incredibly similar to those in the mouth. Modern chimaeras collected from Puget Sound revealed the same tooth-growing process on the head, seen in modern-day shark jaws. And genetic testing confirmed they expressed the same tooth-specific genes as oral teeth.&lt;/p&gt;
    &lt;p&gt;“What we found is that the teeth on this strange appendage look very much like rows of shark teeth. The ability to make teeth transferred onto that appendage, likely from the mouth,” Fraser said. “Over time, the tenaculum shortened but retained the ability to make oral teeth on this forehead appendage.”&lt;/p&gt;
    &lt;p&gt;Fraser collaborated with Washington’s Karly Cohen, Ph.D., and Michael Coates, Ph.D., from Chicago on the study, which was published this week in the Proceedings of the National Academy of Sciences.&lt;/p&gt;
    &lt;p&gt;As experts in shark evolution and anatomy, the scientists were intrigued by these tooth-filled rods sprouting from the ghost shark foreheads. The central mystery: Is the tenaculum covered in true teeth related to oral teeth or more similar to the tooth-like scales plastering the skin of sharks and some ghost sharks?&lt;/p&gt;
    &lt;p&gt;CT scans of the fossils and modern chimaeras gave the scientists unprecedented, detailed insights into the development of the tenaculum teeth, which looked remarkably similar to the teeth of today’s sharks. The nail in the coffin came from genetic evidence. The tenaculum teeth express genes found only in true teeth, never in shark skin denticles.&lt;/p&gt;
    &lt;p&gt;"What I think is very neat about this project is that it provides a beautiful example of evolutionary tinkering or ‘bricolage,’” said Coates, a professor of biology at the University of Chicago. “We have a combination of experimental data with paleontological evidence to show how these fishes co-opted a preexisting program for manufacturing teeth to make a new device that is essential for reproduction."&lt;/p&gt;
    &lt;p&gt;Cohen, a postdoctoral researcher at the University of Washington’s Friday Harbor Labs and first author of the paper, said scientists had never spotted teeth outside the mouth in this way before.&lt;/p&gt;
    &lt;p&gt;“The tenaculum is a developmental relic, not a bizarre one-off, and the first clear example of a toothed structure outside the jaw,” she said.&lt;/p&gt;
    &lt;p&gt;The bizarre path from a mouth full of teeth to forehead teeth used for mating demonstrates the impressive flexibility of evolution, the researchers say, always ready to repurpose structures for strange and unexpected new uses.&lt;/p&gt;
    &lt;p&gt;“There are still plenty of surprises down in the ocean depths that we have yet to uncover,” Fraser said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ufl.edu/2025/09/ghost-shark-teeth/"/></entry><entry><id>https://news.ycombinator.com/item?id=45152086</id><title>Show HN: Greppers – fast CLI cheat sheet with instant copy and shareable search</title><updated>2025-09-06T19:32:14.855285+00:00</updated><content>&lt;doc fingerprint="a1eadbd093f5fba9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop Googling the same command twice.&lt;/head&gt;
    &lt;p&gt;A tiny, blazing‑fast directory of CLI commands with copy‑ready examples. Offline friendly. No BS.&lt;/p&gt;
    &lt;p&gt;Try:&lt;/p&gt;
    &lt;head rend="h2"&gt;Built for speed and memory.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instant search: Runs entirely in your browser.&lt;/item&gt;
      &lt;item&gt;Copy‑to‑clipboard: One click, no ceremony.&lt;/item&gt;
      &lt;item&gt;Opinionated examples: Real‑world flags and patterns.&lt;/item&gt;
      &lt;item&gt;Keyboard first: / focuses search, ↑↓ navigate, ⏎ copies.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.greppers.com/"/></entry></feed>