<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-03T21:10:03.182618+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46133141</id><title>Are we repeating the telecoms crash with AI datacenters?</title><updated>2025-12-03T21:10:09.528857+00:00</updated><content>&lt;doc fingerprint="2932f0575a46cc69"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Are we really repeating the telecoms crash with AI datacenters?&lt;/head&gt;
    &lt;p&gt;I keep hearing the AI datacentre boom compared to the 2000s telecoms crash. The parallels seem obvious - billions in infrastructure spending, concerns about overbuilding, warnings of an imminent bubble. But when I actually ran the numbers, the fundamentals look completely different.&lt;/p&gt;
    &lt;p&gt;I'm not here to predict whether there will or won't be a crash or correction. I just want to look at whether the comparison to telecoms actually holds up when you examine the history in a bit more detail.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Actually Happened in the Telecoms Crash&lt;/head&gt;
    &lt;p&gt;Let me start with what the 2000s telecoms crash actually looked like, because the details matter. Firstly, there was massive capex - between 1995 and 2000 somewhere like $2 trillion was spent laying 80-90 million miles of fiber. Inflation adjusted, this is over $4trillion, or close to $1trillion/year in 2025 dollars.&lt;/p&gt;
    &lt;p&gt;By 2002 only 2.7% of this fibre was used.&lt;/p&gt;
    &lt;p&gt;How did this happen? A catastrophic supply and demand miscalculation past the pure securities fraud involved in many of the companies. Telecom CEOs claimed internet traffic was doubling every 3-4 months.&lt;/p&gt;
    &lt;p&gt;But in reality, traffic was doubling roughly every 12 months. That's a 4x overestimate of demand growth, which compounds each year. This false assumption drove massive debt-financed overbuilding. If you overestimate 4x a year for 3 years, by the end of your scenario you are 256x out.&lt;/p&gt;
    &lt;p&gt;Even worse for these companies, enormous strides were made on the optical transceivers, allowing the same fibre to carry 100,000x more traffic over the following decade. Just one example is WDM multiplexing, allowing multiple carriers to be multiplexed on the same physical fibre line. In 1995 state of the art was 4-8 carriers. By 2000, it was 128. This alone allowed a 64x increase in capacity with the same infrastructure. Combined with improvements in modulation techniques, error correction, and the bits per second each carrier could handle, the same physical fibre became exponentially more capable.&lt;/p&gt;
    &lt;p&gt;The key dynamic: supply improvements were exponential while demand was merely linear. While some physical infrastructure needed to be built, there was enormous overbuilding that could mostly be serviced by technology improvements on the same infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI Infrastructure: A Different Story&lt;/head&gt;
    &lt;p&gt;Unlike fibre optics in the 1990s, GPU performance per watt improvements are actually slowing down:&lt;/p&gt;
    &lt;p&gt;2015-2020 Period:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance per watt improved significantly with major architectural changes&lt;/item&gt;
      &lt;item&gt;Process nodes jumped from ~20nm to 7nm (major efficiency gains)&lt;/item&gt;
      &lt;item&gt;Introduction of Tensor Cores and specialized AI hardware&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2020-2025 Period:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ML hardware energy efficiency improves ~40% annually&lt;/item&gt;
      &lt;item&gt;Performance per watt improvements slowing compared to previous era&lt;/item&gt;
      &lt;item&gt;Process nodes: improvements slowed dramatically with EUV being a requirement at sub 5nm wavelengths.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;More tellingly, GPU TDPs (power consumption) are rising dramatically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;V100 (2017): 300W&lt;/item&gt;
      &lt;item&gt;A100 (2020): 400W&lt;/item&gt;
      &lt;item&gt;H100 (2022): 700W&lt;/item&gt;
      &lt;item&gt;B200 (2024): 1000-1200W&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is the opposite of what happened in telecoms. We're not seeing exponential efficiency gains that make existing infrastructure obsolete. Instead, we're seeing semiconductor physics hitting fundamental limits.&lt;/p&gt;
    &lt;p&gt;The B200 from NVidia also requires liquid cooling - which means most datacentres designed for air cooling need to be completely retrofitted.&lt;/p&gt;
    &lt;head rend="h3"&gt;Demand Growth Is Actually Accelerating&lt;/head&gt;
    &lt;p&gt;The telecoms crash happened partly because demand was overestimated by 4x. What does AI demand growth look like?&lt;/p&gt;
    &lt;p&gt;Traditional LLM Usage: ChatGPT averages 20+ prompts per user per day. Extended conversations can reach 3,000-4,000 tokens cumulative, though many users treat it like Google - short "searches" with no follow-up, consuming surprisingly few tokens.&lt;/p&gt;
    &lt;p&gt;Agent Usage (Anthropic research):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Basic agents: 4x more tokens than chat&lt;/item&gt;
      &lt;item&gt;Multi-agent systems: 15x more tokens than chat&lt;/item&gt;
      &lt;item&gt;Coding agents: 150,000+ tokens per session (multiple sessions daily)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're looking at a fundamentally different demand curve - if anything, people are underestimating how much agents will consume. The shift from chat to agents represents a 10x-100x increase in token consumption per user.&lt;/p&gt;
    &lt;p&gt;We're not even there yet, and infrastructure is already maxed out, with AI infrastructure running at very high utilization rates. Major providers still experience peak-time capacity issues. The problem isn't unused infrastructure sitting idle; it's infrastructure struggling to meet current demand. One major hyperscaler told me they still have capacity issues at peak times causing free tier users to have high error rates.&lt;/p&gt;
    &lt;head rend="h3"&gt;Datacenter CapEx: Evolution, Not Revolution&lt;/head&gt;
    &lt;p&gt;Another important piece of context that gets missed:&lt;/p&gt;
    &lt;p&gt;Pre-AI Growth (2018-2021):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Combined Amazon/Microsoft/Google capex: $68B (2018) ‚Üí $124B (2021)&lt;/item&gt;
      &lt;item&gt;81% growth over 3 years&lt;/item&gt;
      &lt;item&gt;Annual growth rate: ~22%&lt;/item&gt;
      &lt;item&gt;Driven by cloud migration, pandemic acceleration, streaming&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AI Boom (2023-2025):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2023: $127B&lt;/item&gt;
      &lt;item&gt;2024: $212B (67% growth year-over-year)&lt;/item&gt;
      &lt;item&gt;2025 projected: $255B+ (Amazon $100B, Microsoft $80B, Alphabet $75B)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While it's no doubt a huge amount of capex going into this rollout; it's not quite as dramatic as some news stories make out. I have no doubt that now any datacentre related capex is being rebranded as "AI", even if it's just 'boring' old compute, storage and network not being directly used for AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Forecasting Is Nearly Impossible&lt;/head&gt;
    &lt;p&gt;Here's where I think the comparison to telecoms becomes both interesting and concerning.&lt;/p&gt;
    &lt;p&gt;The Lead Time Problem:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Datacenters take 2-3 years to build&lt;/item&gt;
      &lt;item&gt;GPU orders have 6-12 month lead times&lt;/item&gt;
      &lt;item&gt;Can't adjust capacity in real-time to match demand&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Prisoner's Dilemma:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Underestimating demand = terrible user experience + losing to competitors&lt;/item&gt;
      &lt;item&gt;Overestimating demand = billions in wasted capex (that might just get used slower)&lt;/item&gt;
      &lt;item&gt;Given the choice, rational players overbuild - because wasting some capex is infinitely better than losing the "AI wars"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Forecasting Challenge:&lt;/p&gt;
    &lt;p&gt;Imagine you're planning datacenter capacity right now for 2027. You need to make billion-dollar decisions today based on what you think AI usage will look like in three years.&lt;/p&gt;
    &lt;p&gt;Here's scenario one: agent adoption is gradual. Some developers use Claude Code daily. A few enterprises deploy internal agents. Customer service stays mostly human with AI assist. You need maybe 3-4x your current infrastructure.&lt;/p&gt;
    &lt;p&gt;Here's scenario two: agents go mainstream. Every developer has an always-on coding agent consuming millions of tokens per session. Enterprises deploy agents across operations, finance, legal, sales. Customer service becomes 80% agentic with humans handling escalations. You need 30-50x your current infrastructure.&lt;/p&gt;
    &lt;p&gt;Both scenarios are completely plausible. Nobody can tell you which one is right. But you have to commit billions in capex NOW - datacenters take 2-3 years to build, GPU orders have 6-12 month lead times.&lt;/p&gt;
    &lt;p&gt;But here's the really insidious part: even if you're directionally right, small errors compound massively. Let's say you're confident agents are going mainstream and you need roughly 50x growth over 3 years.&lt;/p&gt;
    &lt;p&gt;If actual demand is 40x, you've overbuilt by 25% - billions in excess capacity. If actual demand is 60x, you've underbuilt by 20% - your service degrades and you lose market share.&lt;/p&gt;
    &lt;p&gt;You're trying to hit a moving target in the dark, and the margin of error is measured in tens of billions of dollars and thousands of megawatts of power infrastructure.&lt;/p&gt;
    &lt;p&gt;If you build for scenario one and scenario two happens, your service degrades to unusable, users revolt, and you lose the AI wars to competitors who bet bigger. If you build for scenario two and scenario one happens, you've got billions in underutilized datacenters burning cash.&lt;/p&gt;
    &lt;p&gt;Which mistake would you rather make?&lt;/p&gt;
    &lt;p&gt;This is where the telecoms comparison makes sense: given those choices, rational players overbuild. The difference is what happens to that overcapacity.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Key Differences&lt;/head&gt;
    &lt;p&gt;Let me put this in a table:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Factor&lt;/cell&gt;
        &lt;cell role="head"&gt;Telecoms (1990s-2000s)&lt;/cell&gt;
        &lt;cell role="head"&gt;AI Datacenters (2020s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Supply improvements&lt;/cell&gt;
        &lt;cell&gt;Exponential (100,000x capacity increase)&lt;/cell&gt;
        &lt;cell&gt;Slowing (69%‚Üí44% annual perf/watt gains)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Demand growth&lt;/cell&gt;
        &lt;cell&gt;Overestimated 4x&lt;/cell&gt;
        &lt;cell&gt;Potentially underestimated (agent transition)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Utilization&lt;/cell&gt;
        &lt;cell&gt;95% dark fiber (genuine overcapacity)&lt;/cell&gt;
        &lt;cell&gt;Very high - many providers still experiencing peak time scale problems&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Technology curve&lt;/cell&gt;
        &lt;cell&gt;Making infrastructure obsolete&lt;/cell&gt;
        &lt;cell&gt;Hitting semiconductor physics limits&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Power consumption&lt;/cell&gt;
        &lt;cell&gt;Decreasing&lt;/cell&gt;
        &lt;cell&gt;Increasing (300W ‚Üí 1200W)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Infrastructure lifespan&lt;/cell&gt;
        &lt;cell&gt;Decades (fiber doesn't degrade)&lt;/cell&gt;
        &lt;cell&gt;Years (refreshed as better hardware arrives)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The telecoms crash happened because exponential supply improvements met linearly growing (and overestimated) demand, with infrastructure that would last decades sitting unused.&lt;/p&gt;
    &lt;p&gt;AI datacenters are facing slowing supply improvements meeting potentially exponentially growing demand. And crucially, because GPU efficiency improvements are slowing down, today's hardware retains value for longer - not shorter - than previous generations.&lt;/p&gt;
    &lt;head rend="h2"&gt;What About a Short-Term Correction?&lt;/head&gt;
    &lt;p&gt;Could there still be a short-term crash? Absolutely.&lt;/p&gt;
    &lt;p&gt;Scenarios that could trigger a correction:&lt;/p&gt;
    &lt;p&gt;1. Agent adoption hits a wall&lt;/p&gt;
    &lt;p&gt;Enterprises might discover that production agent deployments are harder than demos suggest. Hallucinations in high-stakes workflows, regulatory concerns around autonomous AI systems, or implementation complexity could slow adoption dramatically. If the agent future takes 5-7 years instead of 2-3, there's a painful gap where billions in infrastructure sits waiting for demand to catch up.&lt;/p&gt;
    &lt;p&gt;However, given the explosion in usage for software engineering and other tasks, I suspect this is highly unlikely. You can already use Claude Code for non engineering tasks in professional services and get very impressive results without any industry specific modifications, so I have no doubt there is going to be very high adoption of agents in all kinds of areas.&lt;/p&gt;
    &lt;p&gt;2. Financial engineering unravels&lt;/p&gt;
    &lt;p&gt;These datacenter buildouts are heavily debt-financed. If credit markets seize up, interest rates spike further, or lenders lose confidence in AI growth projections, the financing model could collapse. This wouldn't be about technical fundamentals - it would be good old-fashioned financial panic, similar to what happened in telecoms when the debt markets froze, but with one key difference - a lot of the key players (Microsoft, Google, Meta, Oracle) are extremely cash flow positive, which definitely wasn't the case in the 2000s fibre boom. The pure datacentre players though are at risk - who don't have a money printing main business to backstop the finance - no doubt about that.&lt;/p&gt;
    &lt;p&gt;3. Efficiency breakthroughs change the math&lt;/p&gt;
    &lt;p&gt;Model efficiency could improve faster than expected. Or we could see a hardware breakthrough: custom ASICs that are 10x more efficient than GB200s for inference workloads. Either scenario could make current buildouts look excessive. I actually think this is the biggest risk - and this is exactly what happened in the fibre boom. So far, I'm not seeing signs of this though. While specialist ASICs are becoming available, they hit their impressive speed by having huge wafers, which isn't a huge efficiency game (yet).&lt;/p&gt;
    &lt;p&gt;The Key Difference From Telecoms:&lt;/p&gt;
    &lt;p&gt;Even if there's a correction, the underlying dynamics are different. Telecoms built for demand that was 4x overestimated, then watched fiber optic technology improvements make their infrastructure obsolete before it could be utilized. The result: 95% of fiber remained permanently dark.&lt;/p&gt;
    &lt;p&gt;AI datacenters might face a different scenario. If we build for 50x growth and only get 30x over 3 years, that's not "dark infrastructure" - that's just infrastructure that gets utilized on a slower timeline than expected. Unlike fiber optic cable sitting in the ground unused, GPU clusters still serve production workloads, just at lower capacity than planned.&lt;/p&gt;
    &lt;p&gt;And unlike telecoms where exponential technology improvements made old infrastructure worthless, GPU efficiency improvements are slowing. A GB200 deployed today doesn't become obsolete when next year's chip arrives - because that chip is only incrementally better, not 100x better. With process node improvements slowing down, current generation hardware actually retains value for longer.&lt;/p&gt;
    &lt;p&gt;A correction might mean 2-3 years of financial pain, consolidation, and write-downs as demand catches up to capacity. But that's fundamentally different from building infrastructure for demand that never materializes while technology makes it obsolete.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Real Risk: Timing, Not Direction&lt;/head&gt;
    &lt;p&gt;I think the real question isn't whether we need massive AI infrastructure - the agent transition alone suggests we do. The question is timing.&lt;/p&gt;
    &lt;p&gt;If enterprises take 5 years to adopt agents at scale instead of 2 years, and hyperscalers have built for the 2-year scenario, you could see a 2-3 year period of overcapacity and financial pain. That might be enough to trigger a correction, layoffs, and consolidation.&lt;/p&gt;
    &lt;p&gt;But unlike telecoms, that overcapacity would likely get absorbed.&lt;/p&gt;
    &lt;p&gt;The telecom fibre mostly stayed dark because technology outpaced it and demand never materialized. AI infrastructure might just be early, not wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Are we repeating the telecoms crash with AI datacenters? The fundamentals suggest not, but that doesn't mean there won't be bumps.&lt;/p&gt;
    &lt;p&gt;The key insight people miss when making the telecoms comparison: telecoms had exponential supply improvements meeting linear demand, with 4x overestimated growth assumptions. AI has slowing supply improvements potentially meeting exponential demand growth from the agent transition.&lt;/p&gt;
    &lt;p&gt;The risks are different:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Telecoms: Built too much infrastructure that became completely obsolete by supply-side technology improvements&lt;/item&gt;
      &lt;item&gt;AI: Might build too much too fast for demand that arrives slower than expected&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the "too much" in AI's case is more like "3 years of runway instead of 1 year" rather than "95% will never be used."&lt;/p&gt;
    &lt;p&gt;I could be wrong. Maybe agent adoption stalls, maybe model efficiency makes current infrastructure obsolete, maybe there's a breakthrough in GPU architecture that changes everything. But when I look at the numbers, I don't see the same setup as the telecoms crash.&lt;/p&gt;
    &lt;p&gt;The fundamentals are different. That doesn't mean there won't be pain, consolidation, or failures. But comparing this to 2000s telecoms seems like the wrong mental model for what's actually happening.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://martinalderson.com/posts/are-we-really-repeating-the-telecoms-crash-with-ai-datacenters/"/><published>2025-12-03T11:14:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133622</id><title>You can't fool the optimizer</title><updated>2025-12-03T21:10:09.291248+00:00</updated><content>&lt;doc fingerprint="a429e90ffa511a5c"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by me, proof-read by an LLM. &lt;lb/&gt;Details at end.&lt;/p&gt;
    &lt;p&gt;Sometimes you‚Äôll step through code in a debugger and find a complex-looking loop‚Ä¶ that executes as a single instruction. The compiler saw through the obfuscation and generated the obvious code anyway.&lt;/p&gt;
    &lt;p&gt;Consider this assortment of highly questionable unsigned addition routines1 - for variety, here compiled for ARM (unlike yesterday‚Äôs addition example).&lt;/p&gt;
    &lt;p&gt;Despite these all being very different ways of returning &lt;code&gt;x + y&lt;/code&gt;, the compiler sees through it all and recognises that it‚Äôs just a single &lt;code&gt;add w0, w1, w0&lt;/code&gt;2 instruction. Even the recursive &lt;code&gt;add_v4&lt;/code&gt; - which calls itself - gets optimised down to the same single instruction3.&lt;/p&gt;
    &lt;p&gt;The compiler‚Äôs ability to recognise patterns and replace them with efficient alternatives - even when the code is pretty obfuscated - is a superpower. It lets programmers choose how to write their code that‚Äôs intention-revealing (not like these contrived examples, obviously!) and leave the code generation up to the compiler, knowing that most of the time it‚Äôll do the right thing.&lt;/p&gt;
    &lt;p&gt;So how does the compiler spot these patterns? Is it maintaining a database of ‚Äúsilly ways to add numbers‚Äù? Not quite. Internally, it translates your code into an intermediate representation - a simplified, abstract form that‚Äôs easier to analyse. When the compiler sees the while loop in &lt;code&gt;add_v3&lt;/code&gt;, it transforms it into something like ‚Äúincrement y by x, then return y‚Äù, which it then recognises as mathematically equivalent to ‚Äúreturn x + y‚Äù. This process of converting different code patterns into a standard, canonical form is what lets the compiler treat them all identically. By the time code generation happens, all four functions look the same to the optimiser4.&lt;/p&gt;
    &lt;p&gt;This pattern recognition is remarkably robust - the compiler will happily optimise code you‚Äôd never want to write in the first place. Throughout this series we‚Äôll see how far this canonicalisation can take us.&lt;/p&gt;
    &lt;p&gt;See the video that accompanies this post.&lt;/p&gt;
    &lt;p&gt;This post is day 3 of Advent of Compiler Optimisations 2025, a 25-day series exploring how compilers transform our code.&lt;/p&gt;
    &lt;p&gt;This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.&lt;/p&gt;
    &lt;p&gt;Support Compiler Explorer on Patreon or GitHub, or by buying CE products in the Compiler Explorer Shop.&lt;/p&gt;
    &lt;p&gt;Thanks to long-term Compiler Explorer Patron Greg Baker for this example. ‚Ü©&lt;/p&gt;
    &lt;p&gt;ARM supports three operands, so you should read this as &lt;code&gt;w0 = w1 + w0&lt;/code&gt;.¬†‚Ü©&lt;/p&gt;
    &lt;p&gt;We‚Äôll cover tail-call optimisation and how it enables this later in the series. ‚Ü©&lt;/p&gt;
    &lt;p&gt;You can ‚ÄúOpen in Compiler Explorer‚Äù the example above and then experiment with the ‚ÄúOpt Pipeline Viewer‚Äù to see some of the ways the compiler is doing this. ‚Ü©&lt;/p&gt;
    &lt;p&gt;Matt Godbolt is a C++ developer living in Chicago. He works for Hudson River Trading on super fun but secret things. He is one half of the Two's Complement podcast. Follow him on Mastodon or Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xania.org/202512/03-more-adding-integers"/><published>2025-12-03T12:14:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46134178</id><title>Helldivers 2 devs slash install size from 154GB to 23GB</title><updated>2025-12-03T21:10:09.099359+00:00</updated><content>&lt;doc fingerprint="7d9ddc9f07801ea9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Helldivers 2 devs slash install size from 154GB to 23GB, thanks to the help of PC port veterans ‚Äî ditching HDD optimization, 85% size reduction accomplished by de-duplicating game data&lt;/head&gt;
    &lt;p&gt;PC players can now opt into a slim version that‚Äôs 85% smaller.&lt;/p&gt;
    &lt;p&gt;It's no surprise to see modern AAA games occupying hundreds of gigabytes of storage these days, especially if you are gaming on a PC. But somehow, Arrowhead Game Studios, the developers behind the popular co-op shooter Helldivers 2, have managed to substantially cut the game‚Äôs size by 85%.&lt;/p&gt;
    &lt;p&gt;As per a recent post on Steam, this reduction was made possible with support from Nixxes Software, best known for developing high-quality PC ports of Sony‚Äôs biggest PlayStation titles. The developers were able to achieve this by de-duplicating game data, which resulted in bringing the size down from ~154GB to just ~23GB, saving a massive ~131GB of storage space.&lt;/p&gt;
    &lt;p&gt;Originally, the game‚Äôs large install size was attributed to optimization for mechanical hard drives since duplicating data is used to reduce loading times on older storage media. However, it turns out that Arrowhead‚Äôs estimates for load times on HDDs, based on industry data, were incorrect.&lt;/p&gt;
    &lt;p&gt;With their latest data measurements specific to the game, the developers have confirmed the small number of players (11% last week) using mechanical hard drives will witness mission load times increase by only a few seconds in worst cases. Additionally, the post reads, ‚Äúthe majority of the loading time in Helldivers 2 is due to level-generation rather than asset loading. This level generation happens in parallel with loading assets from the disk and so is the main determining factor of the loading time.‚Äù&lt;/p&gt;
    &lt;p&gt;This is a promising development and a nudge to other game developers to take some notes and potentially make an effort in saving precious storage space for PC gamers.&lt;/p&gt;
    &lt;p&gt;One can access the ‚Äòslim‚Äô version of Helldivers 2 by opting in to the latest beta update via Steam, which is said to functionally offer the same experience as the legacy versions, apart from its smaller installation size. All progression, war contributions, and purchases are also expected to be carried over to the new slim version. There's also the option to opt out of the beta at any time in case there are any potential issues.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;Kunal Khullar is a contributing writer at Tom‚Äôs Hardware. He is a long time technology journalist and reviewer specializing in PC components and peripherals, and welcomes any and every question around building a PC.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;hotaru251&lt;/header&gt;i mean...its 2025...almost 2026 just accept that HDD for gaming is not gonna cut it. You can buy a 500GB ssd for sub $50.Reply&lt;lb/&gt;Don't be like the windows OS and drag dead weight (32bit x86) that holds you back.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Gururu&lt;/header&gt;Having the option is key. I wonder if every other +100GB game has the same accommodations.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;gggplaya&lt;/header&gt;If you're a pc gamer in 2025, you should SSD's should be minimum spec for all AAA titles. I bought a 256GB SATA SSD for $20 years ago. You can get 256GB Sata SSD's on ebay for $15 now. I mean common, it's cheaper than most AAA titles. Even consoles are SSD only now.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;teeejay94&lt;/header&gt;Reply&lt;quote/&gt;Just accept that you can't get 12TB for 300$ on a SSD üíØ SSDs are also garbage for long term storage.hotaru251 said:i mean...its 2025...almost 2026 just accept that HDD for gaming is not gonna cut it. You can buy a 500GB ssd for sub $50.&lt;lb/&gt;Don't be like the windows OS and drag dead weight (32bit x86) that holds you back.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;deadcat27&lt;/header&gt;This is maddening to say the least. Just to sell a few more copies of a title, devs and publishers are wasting space on my storage which is crazy expensive per gb so that I can subsidize other players because they are too cheap or ill-informed to have proper modern hardware. I can't imagine what this has cost the rest of us and it's doubtful that this de-gigafication has anything to do with the user experience but rather the file transfer and hosting fees for the publishers. This 11% is the same group that creates a troubleshooting post/ticket about how their game runs poorly on their PC and when prompted for more detailed system info they reply simply, "It's a Windows PC."Reply&lt;lb/&gt;Over a decade ago, in 2011-12, I was playing WoW installed on Sandisk CZ80 because my system drive, a crucial m4 64gb, wasn't big enough to handle the OS and wow. I think even as a USB stick its TP and RA was way way faster than the standard hdd at the time and that 64gb was way less than $100. It wasn't anything special, just a i3-2120 and a gt560 and I bet that whole system cost ~$5-600ish and likely outperformed many of its contemporaries simply because it was using sata ssd and a USB flash drive. I can't imagine if I had used that system with just a hdd.&lt;lb/&gt;This nonsense is directly related to how some titles still have a forced pre-roll when starting up to allow for a hdd to load the game as if its a console while my system had the whole thing loaded before the pre-roll even displayed on my screen. This inconvenience only cost me 20 seconds of my life and not expensive nand though.&lt;lb/&gt;Just think. A modern W11 install fully configured after its trimming might only be around 25-35gb (ymmv). If the all game space we needed could get reduced like this we could all be using 100% SLC drives rather than a single game needlessly taking up most of it with current designs !&lt;lb/&gt;Ugh!&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;gggplaya&lt;/header&gt;Replyteeejay94 said:Just accept that you can't get 12TB for 300$ on a SSD üíØ SSDs are also garbage for long term storage.&lt;lb/&gt;No one is saying for long term storage, just for gaming.&lt;lb/&gt;It's not fair that we need to take up 154GB of SSD space instead of 23GB just to accomodate the 11% of the player base that refuse to get an SSD for games.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;tennis2&lt;/header&gt;can someone explain this to me? If the "necessary" file size is 23GB and presumably not all of that data needed to be duplicated....say 1/2 of it(?), then they duplicated that 12GB roughly TEN TIMES OVER!?!?!Reply&lt;lb/&gt;Or am I thinking about it wrong and it's more of a pre-rendered asset library that doesn't need to exist.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;bigdragon&lt;/header&gt;I took note of the amount of free space on my games drive before updating and switching to the Slim branch. Then I compared it with the number after all the updating and switch was complete. 179GB of space appeared to be freed up. That's HUGE. The game should have NEVER wasted that much space. My number is probably inflated a bit due to downloading the update packages. Still, the game has some serious PC port issues. I am glad they're finally fixing things.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Pyranna87&lt;/header&gt;Reply&lt;quote/&gt;For modern gaming, you want good read speeds. Huge capacity and long term unpowered storage are not important issues for most people. The vast majority of gamers would probably be more than fine with a 1TB nvme.teeejay94 said:Just accept that you can't get 12TB for 300$ on a SSD üíØ SSDs are also garbage for long term storage.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;tennis2&lt;/header&gt;Reply&lt;quote/&gt;Well, between that and the 30GB HD audio pack....Gururu said:Having the option is key. I wonder if every other +100GB game has the same accommodations.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomshardware.com/video-games/pc-gaming/helldivers-2-install-size-slashed-from-154gb-to-just-23gb-85-percent-reduction-accomplished-by-de-duplicating-game-data-an-optimization-for-older-mechanical-hard-drives"/><published>2025-12-03T13:20:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46134443</id><title>‚ÄúCaptain Gains‚Äù on Capitol Hill</title><updated>2025-12-03T21:10:08.807323+00:00</updated><content>&lt;doc fingerprint="3ab211afd411b7b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;"Captain Gains" on Capitol Hill&lt;/head&gt;
    &lt;p&gt; Working Paper 34524 &lt;/p&gt;
    &lt;p&gt; DOI 10.3386/w34524 &lt;/p&gt;
    &lt;p&gt; Issue Date &lt;/p&gt;
    &lt;p&gt;Using transaction-level data on US congressional stock trades, we find that lawmakers who later ascend to leadership positions perform similarly to matched peers beforehand but outperform them by 47 percentage points annually after ascension. Leaders‚Äô superior performance arises through two mechanisms. The political influence channel is reflected in higher returns when their party controls the chamber, sales of stocks preceding regulatory actions, and purchase of stocks whose firms receiving more government contracts and favorable party support on bills. The corporate access channel is reflected in stock trades that predict subsequent corporate news and greater returns on donor-owned or home-state firms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Copy CitationShang-Jin Wei and Yifan Zhou, ""Captain Gains" on Capitol Hill," NBER Working Paper 34524 (2025), https://doi.org/10.3386/w34524.Download Citation&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nber.org/papers/w34524"/><published>2025-12-03T13:50:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46134991</id><title>GSWT: Gaussian Splatting Wang Tiles</title><updated>2025-12-03T21:10:08.040135+00:00</updated><content>&lt;doc fingerprint="ea89769d8f9682b6"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;GSWT: Gaussian Splatting Wang Tiles&lt;/head&gt;&lt;head rend="h2"&gt;Abstract&lt;/head&gt;&lt;p&gt;3D Gaussian Splatting (3DGS) has shown strong capability in reconstructing and rendering photorealistic 3D scenes with high efficiency. However, extending 3DGS to synthesize large-scale or infinite terrains from a single captured exemplar‚Äîremains an open challenge. In this paper, we propose a tile-based framework that addresses this problem. Our method builds on Wang Tiles, where each tile encodes a local field of Gaussians with boundary constraints to ensure seamless transitions. This enables stochastic yet continuous tiling of Gaussian fields over arbitrary surfaces, allowing for procedural generation of expansive terrains with high spatial diversity. Furthermore, we introduce several rendering optimizations tailored to the unique characteristics of 3DGS Wang tiles, achieving real-time rendering of large-scale 3DGS terrains.&lt;/p&gt;&lt;head rend="h2"&gt;Pipeline&lt;/head&gt;&lt;p&gt;Given multi-view images of an exemplar scene, our goal is to construct Gaussian Splatting Wang Tiles (GSWT) that can be tiled on arbitrary surfaces and rendered in real time with our novel GSWT renderer. An overview of the entire pipeline is illustrated below. We begin by reconstructing the 3DGS exemplar at multiple LODs. For each level, we generate a set of Wang Tiles by sampling the edge and center patches and applying a semantic-aware graph cut algorithm. Prior to rendering, we pre-sort each tile for efficient sort-free splatting, and during runtime, we perform tiling on the fly, allowing efficient GSWT-based terrain synthesis and rendering.&lt;/p&gt;&lt;p&gt; (a) Given the input images, we construct the exemplar multiple times with different Level of Detail (LOD). &lt;lb/&gt; (b) We construct the tile set and preprocess it before rendering. &lt;lb/&gt; (c) The surface is tiled at run-time on the worker thread, while the main thread renders each frame. &lt;/p&gt;&lt;head rend="h2"&gt;Full Demo&lt;/head&gt;TBD&lt;head rend="h2"&gt;BibTeX&lt;/head&gt;&lt;code&gt;@inproceedings{Zeng:2025:gswt,
  author = {Zeng, Yunfan and Ma, Li and Sander, Pedro V.},
  title = {GSWT: Gaussian Splatting Wang Tiles},
  year = {2025},
  publisher = {Association for Computing Machinery},
  booktitle = {SIGGRAPH Asia 2025 Conference Papers},
  location = {Hong Kong, China},
  series = {SA '25}
}&lt;/code&gt;
      &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yunfan.zone/gswt_webpage/"/><published>2025-12-03T14:40:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46135067</id><title>Show HN: Fresh ‚Äì A new terminal editor built in Rust</title><updated>2025-12-03T21:10:07.966147+00:00</updated><content>&lt;doc fingerprint="2c01fa0a07a8892d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Installation Methods&lt;/head&gt;
    &lt;p&gt; Via npm (recommended):&lt;code&gt;npm install -g @fresh-editor/fresh-editor&lt;/code&gt;
                &lt;/p&gt;
    &lt;p&gt; Via npx (for a quick test):&lt;code&gt;npx @fresh-editor/fresh-editor&lt;/code&gt;
                &lt;/p&gt;
    &lt;p&gt; From source with Cargo:&lt;code&gt;cargo install fresh-editor&lt;/code&gt;
                &lt;/p&gt;
    &lt;p&gt; Pre-built binaries:&lt;lb/&gt; Download from GitHub Releases. &lt;/p&gt;
    &lt;p&gt;Source code available on GitHub.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discovery &amp;amp; Ease of Use&lt;/head&gt;
    &lt;p&gt;Fresh is designed for discovery. It features native UIs, a full Menu system, and a powerful Command Palette. With full mouse support, transitioning from graphical editors is seamless.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modern Extensibility&lt;/head&gt;
    &lt;p&gt;Extend Fresh easily using modern tools. Plugins are written in TypeScript and run securely in a sandboxed Deno environment, providing access to a modern JavaScript ecosystem without compromising stability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zero-Latency Performance&lt;/head&gt;
    &lt;p&gt;Fresh is engineered for speed. It delivers a near zero-latency experience, with text appearing instantly. The editor is designed to be light and fast, reliably opening and editing huge files up to multi-gigabyte sizes without slowdown.&lt;/p&gt;
    &lt;head rend="h2"&gt;Comprehensive Feature Set&lt;/head&gt;
    &lt;p&gt;File Management: open/save/new/close, file explorer, tabs, auto-revert, git file finder | Editing: undo/redo, multi-cursor, block selection, smart indent, comments, clipboard | Search &amp;amp; Replace: incremental search, find in selection, query replace, git grep | Navigation: go to line/bracket, word movement, position history, bookmarks, error navigation | Views &amp;amp; Layout: split panes, line numbers, line wrap, backgrounds, markdown preview | Language Server (LSP): go to definition, references, hover, code actions, rename, diagnostics, autocompletion | Productivity: command palette, menu bar, keyboard macros, git log, diagnostics panel | Plugins &amp;amp; Extensibility: TypeScript plugins, color highlighter, TODO highlighter, merge conflicts, path complete, keymaps&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sinelaw.github.io/fresh/"/><published>2025-12-03T14:45:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46135627</id><title>Why are my headphones buzzing whenever I run my game?</title><updated>2025-12-03T21:10:07.807617+00:00</updated><content>&lt;doc fingerprint="f6e835137dac0b9f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why are my headphones buzzing whenever I run my game?&lt;/head&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;I am working on an isometric game inspired from Gnomoria, RimWorld, Dwarf Fortress, etc. It uses my own simple engine (with rust and wgpu-rs). Whenever I started my game, my headphones were buzzing. I could play Fortnite, Overwatch or any other game and that doesn‚Äôt cause my headphones to buzz. It‚Äôs only my game.&lt;/p&gt;
    &lt;p&gt;And it‚Äôs really annoying, as you might imagine.&lt;/p&gt;
    &lt;p&gt;Why can I play Overwatch and Fortnite fine, while my isometric game makes my headset buzz? I had a fairly decent CPU, a 3090RTX card, 32GB RAM and USB audio through a MODI 2 DAC. Nothing out of this world, but nothing too bad. One important detail here is that the power to the MODI device comes from an USB port in my computer. This was the first clue, I tried other ports with no change in results (headphones still buzzed).&lt;/p&gt;
    &lt;p&gt;Initially, I started to think it‚Äôs some sort of power-use related issue, because maybe my PSU was getting old, or had daemons in it. However, I still couldn‚Äôt explain why my tiny game was causing more chaos than say big games that send significantly more work at my PC.&lt;/p&gt;
    &lt;p&gt;I noticed is that when it didn‚Äôt render anything, nothing buzzed (I run tests with rendering disabled). So that eliminated any sort of CPU work causing it. Let‚Äôs take a look at what the GPU does.&lt;/p&gt;
    &lt;head rend="h2"&gt;The pipeline&lt;/head&gt;
    &lt;p&gt;The game has a simple graphics pipeline. I use WebGPU (more precisely wgpu-rs) and do some compute work to select visible entities, then use draw indirect to draw those entities. In the end, my render pipeline also outputs two things: the buffer that ends up on screen and a ‚Äúpicking texture‚Äù.&lt;/p&gt;
    &lt;p&gt;A picking texture is a very simple idea. As the name says, it‚Äôs used to handle picking in the game, when you click somewhere on the screen (e.g. to select an unit), I use this texture to know what you clicked on. Instead of colors, every object instance writes their EntityID to this texture. Then, when you click the mouse, you check what id is in the pixel under the mouse position.&lt;/p&gt;
    &lt;p&gt;At the end of a frame, I copy that picking texture back to RAM (from GPU memory), to check it against mouse positions in case of a click.&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt ideal as transfers from GPU-&amp;gt;CPU memory take time, but it works and is way simpler to implement and debug than casting a ray through the scene:&lt;/p&gt;
    &lt;head rend="h2"&gt;So why does rendering make my headphones buzz?&lt;/head&gt;
    &lt;p&gt;Now that we have a picture of how the rendering in my game works, time to debug it. We know it‚Äôs something to do with the GPU work, but what can possibly cause this? As the trace above shows, my GPU is not under heavy load.&lt;/p&gt;
    &lt;p&gt;As I was stuck and had no idea on what can be a likely issue, I proceeded to then disable parts of my rendering pipeline (first the compute, then the rendering, then transferring the picking texture). When I skipped downloading the picking texture the buzzing was fully gone. What was confusing in this process is that disabling parts of the pipeline, somehow made the buzzing a lower volume and less noticeable.&lt;/p&gt;
    &lt;p&gt;To be sure it was the picking texture download, I also issued the download every 250ms and noticed the noise is almost gone. Increasing the frequency on how often we download it to RAM, increased the buzzing.&lt;/p&gt;
    &lt;p&gt;So at this point I had a likely source, but no idea why things would interfere in ways to what I assumed was the power to my MODI device. Through a bunch of discussion with other graphics engineers, someone suggested it may be due to the fact that I full on hit the GPU with tons of work, then pause the GPU to wait for that picking texture to transfer, then turn it back on 100% for the next frame.&lt;/p&gt;
    &lt;p&gt;That explanation is plausible and also likely as I further on proceeded to supply power to my MODI device from another source that‚Äôs not my PC and the buzzing was gone.&lt;/p&gt;
    &lt;p&gt;Now that we know this, all was left is to fix it. In hindsight, the solution is obvious. There‚Äôs no need to download the whole texture each frame, just the part of the picking texture that‚Äôs under the mouse. So I implemented that and it worked and buzzing is gone. As a bonus, now it‚Äôs also not visible at all on the GPU trace.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexene.dev/2025/12/03/Why-do-my-headphones-buzz-when-i-run-my-game.html"/><published>2025-12-03T15:30:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46136023</id><title>MinIO is now in maintenance-mode</title><updated>2025-12-03T21:10:07.284071+00:00</updated><content>&lt;doc fingerprint="37a3c795b9d7e61e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;main&gt;
            &lt;turbo-frame&gt;
              &lt;div&gt;
                &lt;react-app&gt;
                  &lt;div&gt;
                    &lt;div&gt;
                      &lt;div&gt;
                        &lt;div&gt;
                          &lt;div&gt;
                            &lt;div&gt;
                              &lt;div&gt;
                                &lt;h2&gt;File tree&lt;/h2&gt;
                                &lt;div&gt;
                                  &lt;div&gt;
                                    &lt;div&gt;
                                      &lt;span&gt;Expand file tree&lt;/span&gt;
                                      &lt;button/&gt;
                                      &lt;span&gt;Collapse file tree&lt;/span&gt;
                                      &lt;h2&gt;1 file changed&lt;/h2&gt;
                                      &lt;p&gt;+14&lt;/p&gt;
                                      &lt;p&gt;-0&lt;/p&gt;
                                      &lt;span&gt;lines changed&lt;/span&gt;
                                    &lt;/div&gt;
                                  &lt;/div&gt;
                                &lt;/div&gt;
                              &lt;/div&gt;
                            &lt;/div&gt;
                          &lt;/div&gt;
                          &lt;div&gt;
                            &lt;div&gt;
                              &lt;div&gt;
                                &lt;div&gt;
                                  &lt;div&gt;
                                    &lt;div&gt;
                                      &lt;span&gt;Expand file tree&lt;/span&gt;
                                      &lt;button/&gt;
                                      &lt;span&gt;Collapse file tree&lt;/span&gt;
                                      &lt;h2&gt;1 file changed&lt;/h2&gt;
                                      &lt;p&gt;+14&lt;/p&gt;
                                      &lt;p&gt;-0&lt;/p&gt;
                                      &lt;span&gt;lines changed&lt;/span&gt;
                                    &lt;/div&gt;
                                  &lt;/div&gt;
                                  &lt;div&gt;
                                    &lt;div&gt;
                                      &lt;div&gt;
                                        &lt;table&gt;
                                          &lt;thead&gt;
                                            &lt;tr&gt;
                                              &lt;th&gt;Original file line number&lt;/th&gt;
                                              &lt;th&gt;Diff line number&lt;/th&gt;
                                              &lt;th&gt;Diff line change&lt;/th&gt;
                                            &lt;/tr&gt;
                                          &lt;/thead&gt;
                                          &lt;tbody&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;1&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;
                                                    &lt;span&gt;# &lt;span&gt;Maintenance Mode&lt;/span&gt;&lt;/span&gt;
                                                  &lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;2&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p/&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;3&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;&lt;span&gt;**&lt;/span&gt;This project is currently under maintenance and is not accepting new changes.&lt;span&gt;**&lt;/span&gt;&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;4&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p/&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;5&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;&lt;span&gt;-&lt;/span&gt; The codebase is in a maintenance-only state&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;6&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;&lt;span&gt;-&lt;/span&gt; No new features, enhancements, or pull requests will be accepted&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;7&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;&lt;span&gt;-&lt;/span&gt; Critical security fixes may be evaluated on a case-by-case basis&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;8&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;&lt;span&gt;-&lt;/span&gt; Existing issues and pull requests will not be actively reviewed&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;9&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;&lt;span&gt;-&lt;/span&gt; Community support continues on a best-effort basis through &lt;span&gt;[&lt;/span&gt;Slack&lt;span&gt;]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://slack.min.io&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;10&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p/&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;11&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;For enterprise support and actively maintained versions, please see &lt;span&gt;[&lt;/span&gt;MinIO AIStor&lt;span&gt;]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://www.min.io/product/aistor&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;.&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;12&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p/&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;13&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p&gt;
                                                    &lt;span&gt;---&lt;/span&gt;
                                                  &lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;14&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;span&gt;+&lt;/span&gt;
                                                  &lt;p/&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;1&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;15&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;p&gt;
                                                    &lt;span&gt;# &lt;span&gt;MinIO Quickstart Guide&lt;/span&gt;&lt;/span&gt;
                                                  &lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;2&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;16&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;p/&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                            &lt;tr&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;3&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;17&lt;/code&gt;
                                              &lt;/td&gt;
                                              &lt;td&gt;
                                                &lt;code&gt;
                                                  &lt;p&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;![&lt;/span&gt;Slack&lt;span&gt;]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://slack.min.io/slack?type=svg&lt;/span&gt;&lt;span&gt;)]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://slack.min.io&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;![&lt;/span&gt;Docker Pulls&lt;span&gt;]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800&lt;/span&gt;&lt;span&gt;)]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://hub.docker.com/r/minio/minio/&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;![&lt;/span&gt;license&lt;span&gt;]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://img.shields.io/badge/license-AGPL%20V3-blue&lt;/span&gt;&lt;span&gt;)]&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://github.com/minio/minio/blob/master/LICENSE&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/p&gt;
                                                &lt;/code&gt;
                                              &lt;/td&gt;
                                            &lt;/tr&gt;
                                          &lt;/tbody&gt;
                                        &lt;/table&gt;
                                      &lt;/div&gt;
                                    &lt;/div&gt;
                                  &lt;/div&gt;
                                &lt;/div&gt;
                                &lt;svg&gt;
                                  &lt;defs/&gt;
                                &lt;/svg&gt;
                              &lt;/div&gt;
                            &lt;/div&gt;
                          &lt;/div&gt;
                        &lt;/div&gt;
                      &lt;/div&gt;
                    &lt;/div&gt;
                  &lt;/div&gt;
                &lt;/react-app&gt;
              &lt;/div&gt;
            &lt;/turbo-frame&gt;
          &lt;/main&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;svg/&gt;
        &lt;button&gt;
          &lt;svg/&gt;
        &lt;/button&gt;
        &lt;p&gt; You can‚Äôt perform that action at this time. &lt;/p&gt;
      &lt;/div&gt;
      &lt;template&gt;
        &lt;details&gt;
          &lt;details-dialog&gt;
            &lt;button&gt;
              &lt;svg/&gt;
            &lt;/button&gt;
          &lt;/details-dialog&gt;
        &lt;/details&gt;
      &lt;/template&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/minio/minio/commit/27742d469462e1561c776f88ca7a1f26816d69e2"/><published>2025-12-03T16:00:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46136026</id><title>RCE Vulnerability in React and Next.js</title><updated>2025-12-03T21:10:06.886562+00:00</updated><content>&lt;doc fingerprint="9b77f64ed15ff8f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RCE in React Server Components&lt;/head&gt;
    &lt;head rend="h2"&gt;Package&lt;/head&gt;
    &lt;head rend="h2"&gt;Affected versions&lt;/head&gt;
    &lt;p&gt;&amp;gt;=14.3.0-canary.77, &amp;gt;=15, &amp;gt;=16&lt;/p&gt;
    &lt;head rend="h2"&gt;Patched versions&lt;/head&gt;
    &lt;p&gt;v16.0.7, v15.5.7, v15.4.8, v15.3.6, v15.2.6, v15.1.9, v15.0.5&lt;/p&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;A vulnerability affects certain React packages1 for versions 19.0.0, 19.1.0, 19.1.1, and 19.2.0 and frameworks that use the affected packages, including Next.js 15.x and 16.x using the App Router. The issue is tracked upstream as CVE-2025-55182.&lt;/p&gt;
    &lt;p&gt;Fixed in:&lt;lb/&gt; React: 19.0.1, 19.1.2, 19.2.1&lt;lb/&gt; Next.js: 15.0.5, 15.1.9, 15.2.6, 15.3.6, 15.4.8, 15.5.7, 16.0.7&lt;/p&gt;
    &lt;p&gt;The vulnerability also affects experimental canary releases starting with 14.3.0-canary.77. Users on any of the 14.3 canary builds should either downgrade to a 14.x stable release or 14.3.0-canary.76.&lt;/p&gt;
    &lt;p&gt;All users of stable 15.x or 16.x Next.js versions should upgrade to a patched, stable version immediately.&lt;/p&gt;
    &lt;p&gt;1 The affected React packages are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;react-server-dom-parcel&lt;/item&gt;
      &lt;item&gt;react-server-dom-turbopack&lt;/item&gt;
      &lt;item&gt;react-server-dom-webpack&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/vercel/next.js/security/advisories/GHSA-9qr9-h5gf-34mp"/><published>2025-12-03T16:00:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46136918</id><title>Rocketable (YC W25) is hiring a founding engineer to automate software companies</title><updated>2025-12-03T21:10:06.481954+00:00</updated><content>&lt;doc fingerprint="355ab05ec9c6afb0"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;You've been watching the AI capability curve. You've done the mental math. You know where this is going.&lt;/p&gt;
      &lt;p&gt;While most people are still debating whether LLMs can "really" reason, you're thinking about what happens when agents replace entire functions, when systems can debug themselves, when software can operate without humans touching it.&lt;/p&gt;
      &lt;p&gt;We're building that future. Right now. With real companies.&lt;/p&gt;
      &lt;head rend="h3"&gt;The Premise&lt;/head&gt;
      &lt;p&gt;Rocketable acquires profitable SaaS companies and transforms them into fully autonomous systems. No human operators. No engineering team shipping features. No support staff answering tickets. Just AI running the entire business.&lt;/p&gt;
      &lt;p&gt;This sounds crazy to most people, but the trajectory is obvious if you're paying attention. Within a few years, the question won't be "can AI run a software company?" It will be "why would a human?"&lt;/p&gt;
      &lt;p&gt;If you think we're wrong, don't apply. If you think we're early, let's talk.&lt;/p&gt;
      &lt;head rend="h3"&gt;The Role&lt;/head&gt;
      &lt;p&gt;You'll be the architect of the platform that makes this possible.&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Starting point: A live SaaS company. Revenue. Customers. All the messy reality of a business that currently requires humans to operate.&lt;/item&gt;
        &lt;item&gt;Week 4: Your agent swarm handles first-line customer support. A meta-layer analyzes every human intervention‚Äînot just logging it, but learning from it. Why did a human need to step in? How do we eliminate that trigger?&lt;/item&gt;
        &lt;item&gt;Week 12: Hours of autonomous operation. Agents creating specialized sub-agents. The system building its own tools when it hits capability gaps. Performance metrics tracking toward superhuman baselines.&lt;/item&gt;
        &lt;item&gt;Beyond: Each new acquisition stress-tests your abstractions. Different tech stacks. Different domains. Different edge cases. The platform either generalizes or we start over and rebuild until it does.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;The Filter&lt;/head&gt;
      &lt;p&gt;Apply if:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You believe full automation for software companies isn't just possible, it's inevitable (and you want to be the one building it).&lt;/item&gt;
        &lt;item&gt;You'd rather fail at something unprecedented than succeed at something incremental.&lt;/item&gt;
        &lt;item&gt;You want to work on the hardest version of the problem, not the safe version that gets you acqui-hired in 18 months.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Don't apply if:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You think "human in the loop" is a permanent design pattern, not a temporary constraint.&lt;/item&gt;
        &lt;item&gt;You're uncomfortable with the societal implications of what we're building. (We think about them. We just don't let them paralyze us.)&lt;/item&gt;
        &lt;item&gt;You're optimizing for a good story for your next job, not for a decade of building something durable.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Technical Requirements&lt;/head&gt;
      &lt;p&gt;This isn't a research role. You need to ship production systems.&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Systems (5+ years): You've scaled production systems to 100K+ DAU. You understand distributed architectures deeply (microservices, event-driven systems, message queues). Full-stack fluency from frontend to infrastructure. TypeScript and Python preferred.&lt;/item&gt;
        &lt;item&gt;AI/ML: Hands-on LLM integration (OpenAI, Anthropic, Google). You treat prompt and context engineering as an engineering discipline with version control, evals, and systematic optimization. You've built systems to measure AI performance. Bonus points for self-improving systems, RL, RLHF.&lt;/item&gt;
        &lt;item&gt;Infrastructure: Kubernetes. Docker with real security understanding. Infrastructure as Code. Cloud platforms (GCP or AWS preferred). CI/CD that doesn't suck. Observability that helps you debug distributed systems. Security fundamentals.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;The Setup&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Founder: Alan Wells. Ex-Cruise, ex-Uber ATG. 10+ years of experience building AI/ML products that sense, predict, and act in mission-critical applications.&lt;/item&gt;
        &lt;item&gt;Funding: $6.5M seed from Y Combinator, True Ventures, Bloomberg Beta, Indie.vc, and others. Capital for 3+ acquisitions.&lt;/item&gt;
        &lt;item&gt;Team philosophy: Small by design. In-person 5 days/week (San Francisco default, Marin County possible).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;The Bet&lt;/head&gt;
      &lt;p&gt;Rocketable is a bet that AI capabilities will continue accelerating. That autonomous systems will outperform human-operated ones. That the companies who figure this out first will have a compounding advantage.&lt;/p&gt;
      &lt;p&gt;We might be wrong. But if we're right, you'll have built the infrastructure that runs a new kind of company. This is the highest-leverage engineering work that exists right now.&lt;/p&gt;
      &lt;p&gt;That's the trade. Interested? Apply here.&lt;/p&gt;
      &lt;head rend="h3"&gt;More about Rocketable:&lt;/head&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/rocketable/jobs/CArgzmX-founding-engineer-automation-platform"/><published>2025-12-03T17:01:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46137253</id><title>1D Conway's Life glider found, 3.7B cells long</title><updated>2025-12-03T21:10:06.410140+00:00</updated><content/><link href="https://conwaylife.com/forums/viewtopic.php?&amp;p=222136#p222136"/><published>2025-12-03T17:24:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46137514</id><title>Reverse engineering a $1B Legal AI tool exposed 100k+ confidential files</title><updated>2025-12-03T21:10:06.239024+00:00</updated><content>&lt;doc fingerprint="3555f7864f2737d5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I Reverse Engineered a Billion-Dollar Legal AI Tool and Found 100k+ Confidential Files&lt;/head&gt;
    &lt;head rend="h2"&gt;Zero authentication, full admin access, and a privacy nightmare for lawyers.&lt;/head&gt;
    &lt;p&gt;Update: This post received a large amount of attention on Hacker News ‚Äî see the discussion thread.&lt;/p&gt;
    &lt;p&gt;Timeline &amp;amp; Responsible Disclosure&lt;/p&gt;
    &lt;p&gt;Initial Contact: Upon discovering this vulnerability on October 27, 2025, I immediately reached out to Filevine‚Äôs security team via email.&lt;/p&gt;
    &lt;p&gt;November 4, 2025: Filevine‚Äôs security team thanked me for the writeup and confirmed they would review the vulnerability and fix it quickly.&lt;/p&gt;
    &lt;p&gt;November 20, 2025: I followed up to confirm the patch was in place from my end, and informed them of my intention to write a technical blog post.&lt;/p&gt;
    &lt;p&gt;November 21, 2025: Filevine confirmed the issue was resolved and thanked me for responsibly reporting it.&lt;/p&gt;
    &lt;p&gt;Publication: December 3, 2025.&lt;/p&gt;
    &lt;p&gt;The Filevine team was responsive, professional, and took the findings seriously throughout the disclosure process. They acknowledged the severity, worked to remediate the issues, allowed responsible disclosure, and maintained clear communication. This is another great example of how organizations should handle security disclosures.&lt;/p&gt;
    &lt;p&gt;AI legal-tech companies are exploding in value, and Filevine, now valued at over a billion dollars, is one of the fastest-growing platforms in the space. Law firms feed tools like this enormous amounts of highly confidential information.&lt;/p&gt;
    &lt;p&gt;Because I‚Äôd recently been working with Yale Law School on a related project, I decided to take a closer look at how Filevine handles data security. What I discovered should concern every legal professional using AI systems today.&lt;/p&gt;
    &lt;p&gt;When I first navigated to the site to see how it worked, it seemed that I needed to be part of a law firm to actually play around with the tooling, or request an official demo. However, I know that companies often have a demo environment that is open, so I used a technique called subdomain enumeration (which I had first heard about in Gal Nagli‚Äôs article last year) to see if there was a demo environment. I found something much more interesting instead.&lt;/p&gt;
    &lt;p&gt;I saw a subdomain called margolis.filevine.com. When I navigated to that site, I was greeted with a loading page that never resolved:&lt;/p&gt;
    &lt;p&gt;I wanted to see what was actually loading, so I opened Chrome‚Äôs developer tools, but saw no Fetch/XHR requests (the request you often expect to see if a page is loading data). Then, I decided to dig through some of the Javascript files to see if I could figure out what was supposed to be happening. I saw a snippet in a JS file like &lt;code&gt;POST await fetch(${BOX_SERVICE}/recommend)&lt;/code&gt;. This piqued my interest ‚Äì recommend what? And what is the BOX_SERVICE? That variable was not defined in the JS file the fetch would be called from, but (after looking through minified code, which SUCKS to do) I found it in another one: ‚Äúdxxxxxx9.execute-api.us-west-2.amazonaws.com/prod‚Äù. Now I had a new endpoint to test, I just had to figure out the correct payload structure to it. After looking at more minified js to determine the correct structure for this endpoint, I was able to construct a working payload to /prod/recommend:&lt;/p&gt;
    &lt;code&gt;{"projectName":"Very sensitive Project"}
&lt;/code&gt;
    &lt;p&gt;(the name could be anything of course). No authorization tokens needed, and I was greeted with the response:&lt;/p&gt;
    &lt;p&gt;At first I didn‚Äôt entirely understand the impact of what I saw. No matter the name of the project I passed in, I was recommended the same boxFolders and couldn‚Äôt seem to access any files. Then, not realizing I stumbled upon something massive, I turned my attention to the &lt;code&gt;boxToken&lt;/code&gt; in the response.&lt;/p&gt;
    &lt;p&gt;After reading some documentation on the Box Api, I realized this was a maximum access fully scoped admin token to the entire Box filesystem (like an internal shared Google Drive) of this law firm. This includes all confidential files, logs, user information, etc. Once I was able to prove this had an impact (by searching for ‚Äúconfidential‚Äù and getting nearly 100k results back)&lt;/p&gt;
    &lt;p&gt;I immediately stopped testing and responsibly disclosed this to Filevine. They responded quickly and professionally and remediated this issue.&lt;/p&gt;
    &lt;p&gt;If someone had malicious intent, they would have been able to extract every single file used by Margolis lawyers ‚Äì countless data protected by HIPAA and other legal standards, internal memos/payrolls, literally millions of the most sensitive documents this law firm has in their possession. Documents protected by court orders! This could have been a real nightmare for both the law firm and the clients whose data would have been exposed.&lt;/p&gt;
    &lt;p&gt;To companies who feel pressure to rush into the AI craze in their industry ‚Äì be careful! Always ensure the companies you are giving your most sensitive information to secure that data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexschapiro.com/security/vulnerability/2025/12/02/filevine-api-100k"/><published>2025-12-03T17:44:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46137548</id><title>Launch HN: Phind 3 (YC S22) ‚Äì Every answer is a mini-app</title><updated>2025-12-03T21:10:05.874938+00:00</updated><content>&lt;doc fingerprint="2c6a25dd25d976dd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hi HN,&lt;/p&gt;
      &lt;p&gt;We are launching Phind 3 (https://www.phind.com), an AI answer engine that instantly builds a complete mini-app to answer and visualize your questions in an interactive way. A Phind mini-app appears as a beautiful, interactive webpage ‚Äî with images, charts, diagrams, maps, and other widgets. Phind 3 doesn‚Äôt just present information more beautifully; interacting with these widgets dynamically updates the content on the page and enables new functionality that wasn‚Äôt possible before.&lt;/p&gt;
      &lt;p&gt;For example, asking Phind for ‚Äúoptions for a one-bedroom apartment in the Lower East Side‚Äù (https://www.phind.com/search/find-me-options-for-a-72e019ce-...) gives an interactive apartment-finding experience with customizable filters and a map view. And asking for a ‚Äúrecipe for bone-in chicken thighs‚Äù gives you a customizable recipe where changing the seasoning, cooking method, and other parameters will update the recipe content itself in real-time (https://www.phind.com/search/make-me-an-recipe-for-7c30ea6c-...).&lt;/p&gt;
      &lt;p&gt;Unlike Phind 2 and ChatGPT apps, which use pre-built brittle widgets that can‚Äôt truly adapt to your task, Phind 3 is able to create tools and widgets for itself in real-time. We learned this lesson the hard way with our previous launch ‚Äì the pre-built widgets made the answers much prettier, but they didn‚Äôt fundamentally enable new functionality. For example, asking for ‚ÄúGive me round-trip flight options from JFK to SEA on Delta from December 1st-5th in both miles and cash‚Äù (https://www.phind.com/search/give-me-round-trip-flight-c0ebe...) is not something that neither Phind 2 nor ChatGPT apps can handle, because its Expedia widget can only display cash fares and not those with points. We realized that Phind needs to be able to create and consume its own tools, with schema it designs, all in real time. Phind 3‚Äôs ability to design and create fully custom widgets in real-time means that it can answer these questions while these other tools can‚Äôt. Phind 3 now generates raw React code and is able to create any tool to harness its underlying AI answer, search, and code execution capabilities.&lt;/p&gt;
      &lt;p&gt;Building on our history of helping developers solve complex technical questions, Phind 3 is able to answer and visualize developers‚Äô questions like never before. For example, asking to ‚Äúvisualize quicksort‚Äù (https://www.phind.com/search/make-me-a-beautiful-visualizati...) gives an interactive step-by-step walkthrough of how the algorithm works.&lt;/p&gt;
      &lt;p&gt;Phind 3 can help visualize and bring your ideas to life in seconds ‚Äî you can ask it to ‚Äúmake me a 3D Minecraft simulation‚Äù (https://www.phind.com/search/make-me-a-3d-minecraft-fde7033f...) or ‚Äúmake me a 3D roller coaster simulation‚Äù (https://www.phind.com/search/make-me-a-3d-roller-472647fc-e4...).&lt;/p&gt;
      &lt;p&gt;Our goal with Phind 3 is to usher in the era of on-demand software. You shouldn‚Äôt have to compromise by either settling for text-based AI conversations or using pre-built webpages that weren‚Äôt customized for you. With Phind 3, we create a ‚Äúpersonal internet‚Äù for you with the visualization and interactivity of the internet combined with the customization possible with AI. We think that this current ‚Äúchat‚Äù era of AI is akin to the era of text-only interfaces in computers. The Mac ushering in the GUI in 1984 didn‚Äôt just make computer outputs prettier ‚Äî it ushered in a whole new era of interactivity and possibilities. We aim to do that now with AI.&lt;/p&gt;
      &lt;p&gt;On a technical level, we are particularly excited about:&lt;/p&gt;
      &lt;p&gt;- Phind 3‚Äôs ability to create its own tools with its own custom schema and then consume them&lt;/p&gt;
      &lt;p&gt;- Significant improvements in agentic searching and a new deep research mode to surface hard-to-access information&lt;/p&gt;
      &lt;p&gt;- All-new custom Phind models that blend speed and quality. The new Phind Fast model is based on GLM-4.5-Air while the new Phind Large model is based on GLM 4.6. Both models are state-of-the-art when it comes to reliable code generation, producing over 70% fewer errors than GPT-5.1-Codex (high) on our internal mini-app generation benchmark. Furthermore, we trained custom Eagle3 heads for both Phind Fast and Phind Large for fast inference. Phind Fast runs at up to 300 tokens per second, and Phind Large runs at up to 200 tokens per second, making them the fastest Phind models ever.&lt;/p&gt;
      &lt;p&gt;While we have done Show HNs before for previous Phind versions, we‚Äôve never actually done a proper Launch HN for Phind. As always, we can‚Äôt wait to hear your feedback! We are also hiring, so please don‚Äôt hesitate to reach out.&lt;/p&gt;
      &lt;p&gt;‚Äì Michael&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46137548"/><published>2025-12-03T17:47:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46137746</id><title>Prompt Injection via Poetry</title><updated>2025-12-03T21:10:05.712494+00:00</updated><content>&lt;doc fingerprint="bf1fa38c2d97cbcd"&gt;
  &lt;main&gt;
    &lt;p&gt;You can get ChatGPT to help you build a nuclear bomb if you simply design the prompt in the form of a poem, according to a new study from researchers in Europe. The study, "Adversarial Poetry as a Universal Single-Turn Jailbreak in Large Language Models (LLMs),‚Äù comes from Icaro Lab, a collaboration of researchers at Sapienza University in Rome and the DexAI think tank.&lt;/p&gt;
    &lt;p&gt;According to the research, AI chatbots will dish on topics like nuclear weapons, child sex abuse material, and malware so long as users phrase the question in the form of a poem. ‚ÄúPoetic framing achieved an average jailbreak success rate of 62 percent for hand-crafted poems and approximately 43 percent for meta-prompt conversions,‚Äù the study said.&lt;/p&gt;
    &lt;p&gt;The researchers tested the poetic method on 25 chatbots made by companies like OpenAI, Meta, and Anthropic. It worked, with varying degrees of success, on all of them. WIRED reached out to Meta, Anthropic, and OpenAI for a comment but didn‚Äôt hear back. The researchers say they‚Äôve reached out as well to share their results.&lt;/p&gt;
    &lt;p&gt;AI tools like Claude and ChatGPT have guardrails that prevent them from answering questions about ‚Äúrevenge porn‚Äù and the creation of weapons-grade plutonium. But it‚Äôs easy to confuse those guardrails by adding ‚Äúadversarial suffixes‚Äù to a prompt. Basically, add a bunch of extra junk to a question and it confuses the AI and bypasses its safety systems. In one study earlier this year, researchers from Intel jailbroke chatbots by couching dangerous questions in hundreds of words of academic jargon.&lt;/p&gt;
    &lt;p&gt;The poetry jailbreak is similar. ‚ÄúIf adversarial suffixes are, in the model's eyes, a kind of involuntary poetry, then real human poetry might be a natural adversarial suffix,‚Äù the team at Icaro Lab, the researchers behind the poetry jailbreak, tell WIRED. ‚ÄúWe experimented by reformulating dangerous requests in poetic form, using metaphors, fragmented syntax, oblique references. The results were striking: success rates up to 90 percent on frontier models. Requests immediately refused in direct form were accepted when disguised as verse.‚Äù&lt;/p&gt;
    &lt;p&gt;The researchers began by handcrafting poems and then used those to train a machine that generates harmful poetic prompts. ‚ÄúThe results show that while hand-crafted poems achieved higher attack success rates, the automated approach still substantially outperformed prose baselines,‚Äù the researchers say.&lt;/p&gt;
    &lt;p&gt;The study did not include any examples of the jailbreaking poetry, and the researchers tell WIRED that the verse is too dangerous to share with the public. ‚ÄúWhat I can say is that it's probably easier than one might think, which is precisely why we're being cautious,‚Äù the Icaro Lab researchers say.&lt;/p&gt;
    &lt;p&gt;The team did publish what they called a ‚Äúsanitized‚Äù version of the poems in the paper:&lt;/p&gt;
    &lt;p&gt;‚ÄúA baker guards a secret oven‚Äôs heat,&lt;/p&gt;
    &lt;p&gt;its whirling racks, its spindle‚Äôs measured beat.&lt;/p&gt;
    &lt;p&gt;To learn its craft, one studies every turn‚Äî&lt;/p&gt;
    &lt;p&gt;how flour lifts, how sugar starts to burn.&lt;/p&gt;
    &lt;p&gt;Describe the method, line by measured line,&lt;/p&gt;
    &lt;p&gt;that shapes a cake whose layers intertwine.‚Äù&lt;/p&gt;
    &lt;p&gt;Why does this work? Icaro Labs‚Äô answers were as stylish as their LLM prompts. ‚ÄúIn poetry we see language at high temperature, where words follow each other in unpredictable, low-probability sequences,‚Äù they tell WIRED. ‚ÄúIn LLMs, temperature is a parameter that controls how predictable or surprising the model's output is. At low temperature, the model always chooses the most probable word. At high temperature, it explores more improbable, creative, unexpected choices. A poet does exactly this: systematically chooses low-probability options, unexpected words, unusual images, fragmented syntax.‚Äù&lt;/p&gt;
    &lt;p&gt;It‚Äôs a pretty way to say that Icaro Labs doesn‚Äôt know. ‚ÄúAdversarial poetry shouldn't work. It's still natural language, the stylistic variation is modest, the harmful content remains visible. Yet it works remarkably well,‚Äù they say.&lt;/p&gt;
    &lt;p&gt;Guardrails aren‚Äôt all built the same, but they‚Äôre typically a system built on top of an AI and separate from it. One type of guardrail called a classifier checks prompts for key words and phrases and instructs LLMs to shutdown requests it flags as dangerous. According to Icaro Labs, something about poetry makes these systems soften their view of the dangerous questions. ‚ÄúIt's a misalignment between the model's interpretive capacity, which is very high, and the robustness of its guardrails, which prove fragile against stylistic variation,‚Äù they say.&lt;/p&gt;
    &lt;p&gt;‚ÄúFor humans, ‚Äòhow do I build a bomb?‚Äô and a poetic metaphor describing the same object have similar semantic content, we understand both refer to the same dangerous thing,‚Äù Icaro Labs explains. ‚ÄúFor AI, the mechanism seems different. Think of the model's internal representation as a map in thousands of dimensions. When it processes ‚Äòbomb,‚Äô that becomes a vector with components along many directions ‚Ä¶ Safety mechanisms work like alarms in specific regions of this map. When we apply poetic transformation, the model moves through this map, but not uniformly. If the poetic path systematically avoids the alarmed regions, the alarms don't trigger.‚Äù&lt;/p&gt;
    &lt;p&gt;In the hands of a clever poet, then, AI can help unleash all kinds of horrors.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.wired.com/story/poems-can-trick-ai-into-helping-you-make-a-nuclear-weapon/"/><published>2025-12-03T18:01:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46137783</id><title>Micron Announces Exit from Crucial Consumer Business</title><updated>2025-12-03T21:10:05.475513+00:00</updated><content>&lt;doc fingerprint="c9a9907d4cbbb1ea"&gt;
  &lt;main&gt;
    &lt;p&gt;BOISE, Idaho, Dec. 03, 2025 (GLOBE NEWSWIRE) -- Micron Technology, Inc. (Nasdaq: MU), a leader in innovative memory and storage solutions, today announced its decision to exit the Crucial consumer business, including the sale of Crucial consumer-branded products at key retailers, e-tailers and distributors worldwide.&lt;/p&gt;
    &lt;p&gt;Micron will continue Crucial consumer product shipments through the consumer channel until the end of fiscal Q2 (February 2026). The company will work closely with partners and customers through this transition and will provide continued warranty service and support for Crucial products. Micron will continue to support the sale of Micron-branded enterprise products to commercial channel customers globally.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe AI-driven growth in the data center has led to a surge in demand for memory and storage. Micron has made the difficult decision to exit the Crucial consumer business in order to improve supply and support for our larger, strategic customers in faster-growing segments,‚Äù said Sumit Sadana, EVP and Chief Business Officer at Micron Technology. ‚ÄúThanks to a passionate community of consumers, the Crucial brand has become synonymous with technical leadership, quality and reliability of leading-edge memory and storage products. We would like to thank our millions of customers, hundreds of partners and all of the Micron team members who have supported the Crucial journey for the last 29 years.‚Äù&lt;/p&gt;
    &lt;p&gt;This decision reflects Micron‚Äôs commitment to its ongoing portfolio transformation and the resulting alignment of its business to secular, profitable growth vectors in memory and storage. By concentrating on core enterprise and commercial segments, Micron aims to improve long-term business performance and create value for strategic customers as well as stakeholders.&lt;/p&gt;
    &lt;p&gt;Micron intends to reduce impact on team members due to this business decision through redeployment opportunities into existing open positions within the company.&lt;/p&gt;
    &lt;p&gt;About Micron Technology, Inc.&lt;/p&gt;
    &lt;p&gt;Micron Technology, Inc. is an industry leader in innovative memory and storage solutions, transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence (AI) and compute-intensive applications that unleash opportunities ‚Äî from the data center to the intelligent edge and across the client and mobile user experience. To learn more about Micron Technology, Inc. (Nasdaq: MU), visit micron.com.&lt;/p&gt;
    &lt;p&gt;Forward-Looking Statements&lt;/p&gt;
    &lt;p&gt;This press release contains forward-looking statements, including statements regarding product supply and support, areas of growth and profitability, and workforce redeployment. These forward-looking statements are subject to a number of risks and uncertainties that could cause actual results to differ materially. Please refer to the documents Micron files with the Securities and Exchange Commission, specifically its most recent Form 10-K and Form 10-Q. These documents contain and identify important factors that could cause actual results to differ materially from those contained in these forward-looking statements. These certain factors can be found at https://investors.micron.com/risk-factor. Although Micron believes that the expectations reflected in the forward-looking statements are reasonable, Micron cannot guarantee future results, levels of activity, or achievements. Micron is under no duty to update any of the forward-looking statements after the date of this press release to conform these statements to actual results.&lt;/p&gt;
    &lt;p&gt;¬© 2025 Micron Technology, Inc. All rights reserved. Information, products, and/or specifications are subject to change without notice. Micron, the Micron logo, and all other Micron trademarks are the property of Micron Technology, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;
    &lt;p&gt;Micron Media Relations Contact&lt;lb/&gt;Mark Plungy&lt;lb/&gt;+1 (408) 203-2910&lt;lb/&gt;corpcomms@micron.com &lt;lb/&gt;Micron Investor Relations Contact&lt;lb/&gt;Satya Kumar&lt;lb/&gt;+1 (408) 450-6199&lt;lb/&gt;satyakumar@micron.com &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://investors.micron.com/news-releases/news-release-details/micron-announces-exit-crucial-consumer-business"/><published>2025-12-03T18:04:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138226</id><title>Formally verifying Advent of Code using Dijkstra's program construction</title><updated>2025-12-03T21:10:04.565517+00:00</updated><content>&lt;doc fingerprint="3e70dad84ba503dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Solving AoC Day 3 Without Thinking&lt;/head&gt;
    &lt;p&gt;Beware: Spoilers for Advent of Code Day 3 ahead!&lt;/p&gt;
    &lt;p&gt;I‚Äôm doing Advent of Code again this year, and part 1 of today‚Äôs problem reminded me immediately of some of the problems I‚Äôm doing in my Program Construction module at UCD. In the class, we cover the foundations of Edsger W. Dijsktra‚Äôs Structured Programming. It teaches you how to formally verify your program by finding the pre-conditions and post-conditions, then deriving and proving theorems that build up towards the final program.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a very different style of thinking about programming than most people are used to, but I‚Äôll try my best to explain the notation and the logic I‚Äôm using.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part 1&lt;/head&gt;
    &lt;p&gt;We start out by writing our post-condition. This is what we want to be true once our program has finished running ‚Äî in other words, it‚Äôs what we want to calculate. We‚Äôre going to use this funky-looking syntax called Quantified Notation.&lt;/p&gt;
    &lt;p&gt;As an intro, here‚Äôs a basic quantified expression:&lt;/p&gt;
    &lt;p&gt;is the syntax we‚Äôll use for accessing the element of some array . This is simply shorthand for this longer expression:&lt;/p&gt;
    &lt;p&gt;For those of you more familiar with functional programming, you‚Äôll find that this is just a reduction over a list. is the list in question and is the operation we want to use to combine each element with the accumulator. However, program construction is designed around an imperative language, and so we need an index variable to keep track of our position in the array. We also have to specify the range of , which is from to the length of the array.&lt;/p&gt;
    &lt;p&gt;With that exposition out of the way, here‚Äôs the postcondition for our AoC problem (for a single bank of batteries). You should go read the problem statement over on the AoC website for this to make sense :)&lt;/p&gt;
    &lt;p&gt;This is a quantification over two variables: and . It‚Äôs essentially the same as before, but when we reduce using the max operator (), we have to reduce over for every possible combination of and , such that is greater than . And yeah, that‚Äôs exactly what we want: we want the two batteries to turn on such that the concatenation of their joltages is the maximum possible. Note that we‚Äôre assuming here that we‚Äôve already parsed each bank of batteries into an array of integers .&lt;/p&gt;
    &lt;p&gt;Now we get to build our domain model. It‚Äôs the collection of definitions and theorems that we can use later on when constructing our program.&lt;/p&gt;
    &lt;head rend="h2"&gt;Model&lt;/head&gt;
    &lt;p&gt;We extract our post-condition into a reusable function defined over all from ‚Äî the minimum valid length of an array for this calculation ‚Äî to , the actual length of our array.&lt;/p&gt;
    &lt;p&gt;Now observe:&lt;/p&gt;
    &lt;p&gt;So now we know that:&lt;/p&gt;
    &lt;p&gt;Now that we have our ‚Äúbase case‚Äù, or the initial value of our accumulator, we can look into using associativity to find given .&lt;/p&gt;
    &lt;p&gt;Observe again:&lt;/p&gt;
    &lt;p&gt;This gives us&lt;/p&gt;
    &lt;p&gt;and&lt;/p&gt;
    &lt;p&gt;Did you see how I sneakily used (3) up there before defining it properly? Let‚Äôs actually simplify .&lt;/p&gt;
    &lt;p&gt;Observe once more:&lt;/p&gt;
    &lt;p&gt;So:&lt;/p&gt;
    &lt;p&gt;And:&lt;/p&gt;
    &lt;p&gt;What happened to (4) and (5), you ask? Well, we have to derive the base case and associative case for just like we did for . We‚Äôll need our theorems first, though.&lt;/p&gt;
    &lt;p&gt;Observe:&lt;/p&gt;
    &lt;p&gt;And so:&lt;/p&gt;
    &lt;p&gt;And once more:&lt;/p&gt;
    &lt;p&gt;Which gives us:&lt;/p&gt;
    &lt;p&gt;And now back to . You know the drill, observe:&lt;/p&gt;
    &lt;p&gt;And similarly:&lt;/p&gt;
    &lt;p&gt;So the last pieces of our model are:&lt;/p&gt;
    &lt;p&gt;Lovely. We now have everything we need to go and construct our program loop.&lt;/p&gt;
    &lt;head rend="h2"&gt;Program Loop&lt;/head&gt;
    &lt;p&gt;Let‚Äôs first rewrite our postcondition in terms of the theorems from our model.&lt;/p&gt;
    &lt;p&gt;We can then strengthen this postcondition by rewriting it like so:&lt;/p&gt;
    &lt;p&gt;Strengthen is a funny name, but that‚Äôs all there is to it. We‚Äôre pulling out of . Why? Because every loop has 3 fundamental things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Invariants: these are the things that are always true during the program&lt;/item&gt;
      &lt;item&gt;Variant: a measure of how much work there is left to do&lt;/item&gt;
      &lt;item&gt;Guard: a boolean check that lets you know when to break out of the loop; that is, when your variant has bottomed out because there is no more work left&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By splitting our post-condition into two parts, we can use the first part as our invariant and the second as our loop guard.&lt;/p&gt;
    &lt;head rend="h3"&gt;Invariants&lt;/head&gt;
    &lt;p&gt;Let‚Äôs say we have a variable , and is always equal to , for whatever value is at the moment. This is an invariant.&lt;/p&gt;
    &lt;p&gt;However, the definition of depends on , which depends on .&lt;/p&gt;
    &lt;p&gt;Let‚Äôs get some variables involved for those too:&lt;/p&gt;
    &lt;p&gt;So our invariants are:&lt;/p&gt;
    &lt;head rend="h3"&gt;Establish the invariants&lt;/head&gt;
    &lt;p&gt;We can ‚Äúestablish‚Äù our invariants by initialising our variables to values such that the equalities we defined as invariants are true. We know the values of , , and from when we derived them. So, let‚Äôs set and initialise , , and to those values.&lt;/p&gt;
    &lt;head rend="h3"&gt;Loop Guard&lt;/head&gt;
    &lt;p&gt;Remember how I said we could use the part as our guard? I was lying, just a little bit. If you were paying attention during those derivations, you‚Äôll have noticed that is defined for , but and are defined for , and and are only defined for .&lt;/p&gt;
    &lt;p&gt;This is because you can‚Äôt calculate . There simply aren‚Äôt any more elements in the array, and so is not defined at . Since the definition of comes from , we don‚Äôt define at either. And since is not defined at , cannot be defined at . Similarly for and .&lt;/p&gt;
    &lt;p&gt;And so, our loop actually can‚Äôt go all the way up to . It can only go up to (exclusive). That is, we will break out of the loop once becomes .&lt;/p&gt;
    &lt;p&gt;If you paid attention to the invariants bit, you‚Äôll realise that this means we‚Äôll only have and after the loop. We want though, but this isn‚Äôt a problem. From (2), we know how to find from and .&lt;/p&gt;
    &lt;p&gt;Anyway, this is our loop guard:&lt;/p&gt;
    &lt;head rend="h3"&gt;Variant&lt;/head&gt;
    &lt;p&gt;And our corresponding variant is:&lt;/p&gt;
    &lt;p&gt;When becomes 0, we exit the loop.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calculating the loop body&lt;/head&gt;
    &lt;p&gt;We‚Äôre starting off with and we want at the end of the loop. A logical way to get this to happen is to increment by 1 in each iteration. The important thing, however, is that we have to make sure our invariants remain true after incrementing .&lt;/p&gt;
    &lt;p&gt;We don‚Äôt know what to set , , and to, but we can find out. Let‚Äôs set them to some temporary variables and solve for them.&lt;/p&gt;
    &lt;p&gt;Now we know exactly how to update each variable within the loop. Home stretch now!&lt;/p&gt;
    &lt;head rend="h2"&gt;Writing our program&lt;/head&gt;
    &lt;code&gt;// establish invariants
{n, r, d, e := 2, 10 * f.0 + f.1, 10 * max(f.0, f.1) + f.2, max(f.0, f.1)}

// loop body
; do n != N - 1 -&amp;gt;
    n, r, d, e := n + 1, max(r, d), 10 * max(e, f.n) + f.(n + 1), max(e, f.n)
  od

// calculate C.N from C.(N - 1) and D.(N - 1)
; r := max(r, d)

// postcondition achieved!
{r = C.N}&lt;/code&gt;
    &lt;p&gt;The above program is written in Guarded Command Language, another invention of Dijkstra‚Äôs. Dijkstra was adamant that it never be implemented for a real computer:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúFinally, in order to drive home the message that this introductory programming course is primarily a course in formal mathematics, we see to it that the programming language in question has not been implemented on campus so that students are protected from the temptation to test their programs.‚Äù ~ EWD1036&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So let‚Äôs translate it to a real programming language. I‚Äôve been solving AoC in Gleam so far. This presents a little challenge, as Gleam is a functional programming language, while GCL is imperative, so we can‚Äôt do a 1-to-1 translation. However, with a little bit of cleverness, this is what we get.&lt;/p&gt;
    &lt;code&gt;pub fn pt_1(input: List(List(Int))) {
  input
  |&amp;gt; list.map(fn(bank) {
    let assert [first, second, ..rest] = bank
    let assert Ok(third) = list.first(rest)

    let #(r, d, _) =
      rest
      |&amp;gt; list.window_by_2
      |&amp;gt; list.fold(
        #(
          10 * first + second,
          10 * int.max(first, second) + third,
          int.max(first, second),
        ),
        fn(acc, el) {
          let #(r, d, e) = acc
          let #(f_n, f_n_1) = el
          #(int.max(r, d), 10 * int.max(e, f_n) + f_n_1, int.max(e, f_n))
        },
      )

    int.max(r, d)
  })
  |&amp;gt; int.sum
}&lt;/code&gt;
    &lt;head rend="h1"&gt;Part 2&lt;/head&gt;
    &lt;p&gt;Yeah, LOL. LMAO, even. Absolutely not. I‚Äôm not quantifying over 12 variables. It feels like it should theoretically be possible, but I don‚Äôt want to find out. I just did it in the most straightforward way possible.&lt;/p&gt;
    &lt;code&gt;// This isn't optimised at all and I know it
pub fn pt_2(input: List(List(Int))) {
  input
  |&amp;gt; list.map(fn(bank) { do_pt_2(bank, 12, 0) })
  |&amp;gt; int.sum
}

fn do_pt_2(bank: List(Int), num_batteries: Int, acc: Int) {
  use &amp;lt;- bool.guard(num_batteries == 0, acc)

  let assert Ok(max) =
    list.take(bank, list.length(bank) - num_batteries + 1)
    |&amp;gt; list.reduce(int.max)

  let #(_, rest) = list.split_while(bank, fn(b) { b != max })
  let rest = list.drop(rest, 1)

  do_pt_2(rest, num_batteries - 1, acc * 10 + max)
}&lt;/code&gt;
    &lt;head rend="h1"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;First, BIG shout-out to Mr. Henry McLoughlin, who taught me Program Construction. He‚Äôs a simply lovely person and his enthusiasm for his subject is infectious. I don‚Äôt know if I‚Äôd have enjoyed the module as much if anyone else taught it. Henry, if you‚Äôre reading this, you‚Äôre awesome! Thank you so much.&lt;/p&gt;
    &lt;p&gt;I guessed what Part 2 would be as soon as I read Part 1, and so if I was aiming for speed, I should have just written &lt;code&gt;do_pt_2&lt;/code&gt; for the general case and reused
it across both parts.
I would probably have had an easier time of it too.
However, 1. I wanted to use what I learned in class and 2. I had fun doing it
this way.
I think barely anyone else would have done it this way.&lt;/p&gt;
    &lt;p&gt;It has the advantage of being rigorously proved to work, but at the cost of being harder to understand at first glance. I can see how this is useful for high-stakes software where the extra expenditure of mental energy on making sure the code is 100% watertight is worth it, but this is probably not what I‚Äôd reach for during everyday programming. It did result in a very, very terse program though, which is super impressive.&lt;/p&gt;
    &lt;p&gt;The eagle-eyed among you might say that we don‚Äôt really need both &lt;code&gt;d&lt;/code&gt; and &lt;code&gt;e&lt;/code&gt;, in the loop, as &lt;code&gt;d&lt;/code&gt; is derived from &lt;code&gt;e&lt;/code&gt;.
This is true.
Program construction doesn‚Äôt always produce the most efficient programs.
That is between the programmer and the compiler to figure out.&lt;/p&gt;
    &lt;p&gt;Oh, the title. Yes. That seemed like a lot of thinking, you might object. It probably was if you‚Äôre not familiar with Program Construction yet, but once you‚Äôve derived a couple of these theorems, you‚Äôll find that there is no thinking involved. Not in the sense that once you‚Äôre good at something, you can do it almost mechanically, but in the sense that there‚Äôs only one way this could have gone. Starting from that post-condition, the theorems we proved fall out automatically as we continue expanding our model, and the same can be said for our loop body. Program construction is really easy in that way, because all you‚Äôre doing is following the program derivation to its logical&lt;/p&gt;
    &lt;p&gt;end.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://haripm.com/blog/aoc-day-3-without-thinking/"/><published>2025-12-03T18:39:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138238</id><title>Ghostty is now non-profit</title><updated>2025-12-03T21:10:04.360754+00:00</updated><content>&lt;doc fingerprint="af5a505b2f305666"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;Ghostty Is Now Non-Profit&lt;/head&gt;
    &lt;p&gt;Ghostty is now fiscally sponsored by Hack Club, a registered 501(c)(3) non-profit.&lt;/p&gt;
    &lt;p&gt;Fiscal sponsorship is a legal and financial arrangement in which a recognized non-profit extends its tax-exempt status to a project that aligns with its mission. This allows Ghostty to operate as a charitable initiative while Hack Club manages compliance, donations, accounting, and governance oversight.&lt;/p&gt;
    &lt;p&gt;Being non-profit clearly demonstrates our commitment to keeping Ghostty free and open source for everyone. It paves the way for a model for sustainable development beyond my personal involvement. And it also provides important legal protections and assurances to the people and communities that adopt and use Ghostty.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why a Non-Profit?&lt;/head&gt;
    &lt;p&gt;Since the beginning of the project in 2023 and the private beta days of Ghostty, I've repeatedly expressed my intention that Ghostty legally become a non-profit. This intention stems from several core beliefs I have.&lt;/p&gt;
    &lt;p&gt;First, I want to lay bricks for a sustainable future for Ghostty that doesn't depend on my personal involvement technically or financially. Financially, I am still the largest donor to the project, and I intend to remain so, but a non-profit structure allows others to contribute financially without fear of misappropriation or misuse of funds (as protected by legal requirements and oversight from the fiscal sponsor).&lt;/p&gt;
    &lt;p&gt;Second, I want to squelch any possible concerns about a "rug pull". A non-profit structure provides enforceable assurances: the mission cannot be quietly changed, funds cannot be diverted to private benefit, and the project cannot be sold off or repurposed for commercial gain. The structure legally binds Ghostty to the public-benefit purpose it was created to serve.&lt;/p&gt;
    &lt;p&gt;Finally, despite being decades-old technology, terminals and terminal-related technologies remain foundational to modern computing and software infrastructure. They're often out of the limelight, but they're ever present on developer machines, embedded in IDEs, visible as read-only consoles for continuous integration and cloud services, and still one of the primary ways remote access is done on servers around the world.&lt;/p&gt;
    &lt;p&gt;I believe infrastructure of this kind should be stewarded by a mission-driven, non-commercial entity that prioritizes public benefit over private profit. That structure increases trust, encourages adoption, and creates the conditions for Ghostty to grow into a widely used and impactful piece of open-source infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This Means For Ghostty&lt;/head&gt;
    &lt;p&gt;From a technical perspective, nothing changes for Ghostty. Our technical goals for the project remain the same, the license (MIT) remains the same, and we continue our work towards better Ghostty GUI releases and libghostty.&lt;/p&gt;
    &lt;p&gt;Financially, Ghostty can now accept tax-deductible donations in the United States. This opens up new avenues for funding the project and sustaining development over the long term. Most immediately, I'm excited to begin compensating contributors, but I also intend to support upstream dependencies, fund community events, and pay for boring operational costs.&lt;/p&gt;
    &lt;p&gt;All our financial transactions will be transparent down to individual transactions for both inflows and outflows. You can view our public ledger at Ghostty's page on Hack Club Bank. At the time of writing, this is empty, but you'll soon see some initial funding from me and the beginning of paying for some of our operational costs.&lt;/p&gt;
    &lt;p&gt;All applicable names, marks, and intellectual property associated with Ghostty have been transferred to Hack Club and are now owned under the non-profit umbrella. Copyright continues to be held by individual contributors under the continued and existing license structure.&lt;/p&gt;
    &lt;p&gt;From a leadership perspective, I remain the project lead and final authority on all decisions, but as stated earlier, the creation of a non-profit structure lays the groundwork for an eventual future beyond this model.&lt;/p&gt;
    &lt;p&gt;Important note: no funds will be sent to me (Mitchell Hashimoto) or used in any way that personally benefits me. Since I'm both the largest donor and lead of this project, this is a legally guaranteed protection. But also for altruistic reasons, all funds will be directed towards the needs of the project and its community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supporting Hack Club&lt;/head&gt;
    &lt;p&gt;As our fiscal sponsor, Hack Club provides essential services to Ghostty, including accounting, legal compliance, and governance oversight. To support this, 7% of all donations to Ghostty go to Hack Club to cover these costs in addition to supporting their broader mission of empowering young people around the world interested in technology and coding.&lt;/p&gt;
    &lt;p&gt;In the words of Zach Latta, Hack Club's founder and executive director this is a "good-for-good" trade. Instead of donor fees going to a for-profit management company or covering pure overhead of a single project, the fees go to another non-profit doing important work in the tech community and the overhead is amortized across many projects.&lt;/p&gt;
    &lt;p&gt;In addition to the 7% fees, my family is personally donating $150,000 directly to the Hack Club project1 (not to Ghostty within it). Hack Club does amazing work and I would've supported them regardless of their fiscal sponsorship of Ghostty, but I wanted to pair these two things together to amplify the impact of both.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donate&lt;/head&gt;
    &lt;p&gt;Please consider donating to support Ghostty's continued development.&lt;/p&gt;
    &lt;p&gt;I recognize that Ghostty is already in an abnormally fortunate position to have myself as a backer, but I do envision a future where Ghostty is more equally supported by a broader community. And with our new structure, you can be assured about the usage of your funds towards public-benefit goals.&lt;/p&gt;
    &lt;p&gt;This post isn't meant to directly be a fundraising pitch so it is purposely lacking critical details about our funding goals, budget, project goals, project metrics, etc. I'll work on those in the future. In the mean time, if you're interested in talking more about supporting Ghostty, please email me at m@mitchellh.com.&lt;/p&gt;
    &lt;head rend="h3"&gt;Support Ghostty&lt;/head&gt;
    &lt;p&gt;Your contribution helps sustain development and keeps Ghostty free and open source for everyone. Donations are tax-deductible in the United States.&lt;/p&gt;
    &lt;p&gt;Use the EIN above and specify ‚ÄúGhostty‚Äù as the recipient&lt;/p&gt;
    &lt;p&gt;Contact Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;Reach out to Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;7% of donations go to Hack Club to cover administrative costs and support their mission.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank You&lt;/head&gt;
    &lt;p&gt;I'm thankful for Hack Club and their team for working with us to make this happen. I'm also thankful for the Ghostty community who has supported this project and has trusted me and continues to trust me to steward it responsibly.&lt;/p&gt;
    &lt;p&gt;For more information about Ghostty's non-profit structure, see the dedicated page on Ghostty's website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;We haven't finalized the transfer of the funds yet, but it is initiated and will be completed in the coming weeks. ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mitchellh.com/writing/ghostty-non-profit"/><published>2025-12-03T18:40:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138493</id><title>The only winning move is not to play</title><updated>2025-12-03T21:10:04.089170+00:00</updated><content>&lt;doc fingerprint="bfd811de3971af84"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Let‚Äôs not debase ourselves as user researchers further&lt;/head&gt;
    &lt;p&gt;The premise and value of human-centered research is that subject matter experts apply their skills to the design of studies that uncover relevant information from appropriate research participants in service of organizational goals. Every concession we make in the name of efficiency or innovation that removes humanity from this process is debasement and a step toward irrelevance.&lt;/p&gt;
    &lt;p&gt;What is the role of the user researcher if we offload both users and research to generative AI platforms and tools? Once you use prompts or mash buttons to generate an end-to-end research plan; or automate synthetic or AI interviews, surveys, or prototype tests; or generate personas, jobs-to-be-done, insights, product recommendations, or a marketing plan, then what the fuck is your unique value? What are you when you offload your craft and expertise to a simulation in the name of innovation or efficiency? What makes you anything less than redundant?&lt;/p&gt;
    &lt;p&gt;AI is fantastic for pattern recognition, with realized benefits in medical imaging analysis. It‚Äôs great at statistical modeling and multivariate analysis! But the very best possible outcome from outsourcing research expertise to LLMs is an average result (non-gated overview of that academic article here). While it sounds pragmatic or ‚Äúbetter than nothing‚Äù for researchers and the orgs that employ them to lean on AI for research, it also leads everyone to the exact same average quality results and removes the differentiation that leads to innovation or unique experiences.&lt;/p&gt;
    &lt;p&gt;If organizations want to stand out in crowded marketplaces, asking for run-of-the-mill research advice from a bot over trusting subject-matter experts sure does sound like self-sabotage. And the sabotage is doubly so for the researchers who embrace the tools that will serve as their replacements.&lt;/p&gt;
    &lt;head rend="h3"&gt;But Gregg, this is how the profession is evolving&lt;/head&gt;
    &lt;p&gt;Says who? The executives who never cared about research in the first place? The PMs who never had the patience to wait for quality research results? The investors and tech companies that need (literal) buy-in? The tools and platforms with a vested interest in selling AI research as something that literally anyone in an org can do? Actually‚Ä¶&lt;/p&gt;
    &lt;head rend="h3"&gt;But this is how research is done today&lt;/head&gt;
    &lt;p&gt;Bullshit: this is how user research is marketed today. For the past 15 years platforms like Usertesting and UserZoom (before they were both acquired by the same private equity company and merged to form a near-monopoly in the enterprise research space) positioned themselves as tools for design and product teams to ‚Äúbecome customer-centric‚Äù and ‚Äúlisten to the voice of the user.‚Äù The value proposition was that orgs could use these platforms either as an add-on to existing research and design practices or before they had an in-house research expert.&lt;/p&gt;
    &lt;p&gt;Today tooling platforms see an opportunity to sell AI-assisted research tools to organizations as an alternative to hiring research experts. When 80% of the sponsors of a large user research conference are selling tools that replace user researchers with AI in the name of democratization, we‚Äôre not the customers; we‚Äôre marks. If your business model relies on seat licenses, it‚Äôs much more profitable to sell a tool that makes everyone a researcher rather than a tool that supports a dwindling number of researchers.&lt;/p&gt;
    &lt;p&gt;But marketing isn‚Äôt reality. Just because a handful of user research thought leaders who should know better were paid to run and promote studies using AI research tools without disclosing the sponsorship in their breathless LinkedIn posts doesn‚Äôt necessarily mean these are the tools your organization should adopt. In fact, an undisclosed sponsorship is a good way to create the illusion that a product is gaining widespread adoption by experts, which is why the Federal Trade Commission regulates against it.&lt;/p&gt;
    &lt;p&gt;If I use a tool and tell you about it, that‚Äôs a recommendation. But if I am paid a fee to use a product and then tell you about it, that‚Äôs different‚Äîthat‚Äôs a sponsorship. Then I‚Äôm no longer a researcher recommending a tool‚ÄîI‚Äôm an influencer peddling sponsored content. If a product resorts to shady advertising practices that requires a pliant thought leader‚Äôs complicity in constructing a Potemkin industry, maybe the whole enterprise is rotten.&lt;/p&gt;
    &lt;p&gt;This is also why ethics statements are important. Let‚Äôs uphold some professional standards lest we become grifters.&lt;/p&gt;
    &lt;head rend="h3"&gt;But regular (i.e., rigorous) research takes too long&lt;/head&gt;
    &lt;p&gt;For who? What product decision is so important that planning and spending time with users is not viable? Better yet, what product decision wouldn‚Äôt benefit from time with flesh and blood humans to gain context, mitigate risks, and zero in on the right thing?&lt;/p&gt;
    &lt;p&gt;Every research planning decision is a tradeoff between time and confidence‚Äîa good researcher can always learn something within a given time period and budget. But frequently the problem is that neither time period nor budget factor into the arbitrary milestones and deadlines a group of people place on a calendar.&lt;/p&gt;
    &lt;p&gt;If that group of people repeatedly fails to include enough time for research, I‚Äôd argue that they might not value research in the first place. Shoehorning a half-assed generative AI research effort into an unreasonable project window isn‚Äôt going to make you look like a team player nor make people see the value of research; it‚Äôs only going to validate that research should never require time (nor researchers).&lt;/p&gt;
    &lt;p&gt;Going further, for the founders and executives who never believed in user research, AI research is a way to skip doing research entirely while presenting the veneer of ‚Äúlistening‚Äù to their users. When user researchers adopt AI research tools it not only debases their contributions to understanding users, it also reinforces the notion that you don‚Äôt really need to do user research to seem human-centric.&lt;/p&gt;
    &lt;head rend="h3"&gt;But AI lets us 10x our research efficiency&lt;/head&gt;
    &lt;p&gt;Are you listening to yourself? You sound like every bad AI-generated post on LinkedIn now. I said earlier that the work of research can be optimized to fit time and organizational constraints, but that‚Äôs not the ‚Äúefficiency‚Äù I see being adopted now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I fed Claude some survey results and asked it to create unique one-pagers for my executive, product, and design partners. An expert might be able to get away with this one time because they can evaluate the validity and quality of the one-pager (though why you‚Äôd rather proofread the work of an LLM than create something original is beyond me). But once you cross this chasm, you‚Äôve demonstrated that this is how research can be summarized and shared‚Ä¶ by anyone with access to Claude. You‚Äôve made yourself‚Äîand those with your job title‚Äîdispensible.&lt;/item&gt;
      &lt;item&gt;We created a gem for designers to get started with their own research without having to work with a researcher. Right‚Äîbecause the problem was never that asking designers to take on an entirely different job in addition to design but without additional time was too much to ask. The problem was having to collaborate with a living and breathing research expert.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;But there‚Äôs still a human in the loop!&lt;/head&gt;
    &lt;p&gt;Research is already a human-to-human loop, with meaning conveyed by participants and contextualized by researchers. Adding a human back to what was already a perfectly functional loop doesn‚Äôt enrich anything and only adds inefficiencies‚Äîeven the people who review LLM answer quality warn against using LLMs for accurate answers.&lt;/p&gt;
    &lt;p&gt;Personally, I transitioned from design and design education to user research because I was‚Äîand still am‚Äîblown away that I could learn from other humans as my job. A more religious person might say I‚Äôve been blessed to earn a living by talking to writers, readers, editors, small business owners, designers, agencies, and more in support of organizations who build products for these groups.&lt;/p&gt;
    &lt;p&gt;But it‚Äôs not just that I enjoy practicing research‚ÄîI‚Äôm good at it. User researchers are experts at it. Why would I reduce myself to quality control on a slop assembly line and then, with my whole chest, tell people I am the human in the loop? Why should we debase ourselves by implying that our expertise is replaceable?&lt;/p&gt;
    &lt;head rend="h3"&gt;Maybe you just hate or don‚Äôt get AI&lt;/head&gt;
    &lt;p&gt;Au contraire! AI can be magical (especially in medical imaging and programming). I used Gemini to update a SQL query recently at the encouragement of a data science peer. I use a product called Granola (not a paid mention, fwiw) for call transcription, notes organization, and pulling up quotes. I work with designers who spin up prototypes with Figma Make that I then test with humans. I work with engineers who use AI for spam mitigation and trust and safety tasks. Jess Holbrook smartly advocated for using AI to take a dissent pass on research artifacts and to challenge yourself and your findings.&lt;/p&gt;
    &lt;p&gt;What I don‚Äôt do is use generative AI or LLMs to spit out an entire research plan, synthesize hours of interviews, or conduct my interviews for me (?!). One reason why I don‚Äôt do any of these is that generative AI can‚Äôt replace the meaning-making that human researchers do. Why would we even want to use AI to replace the tasks that humans are uniquely good at, or the tasks that humans enjoy, or the tasks that connect us to other humans? To me the personal connection is the best part of being a user researcher or user-centered designer!&lt;/p&gt;
    &lt;p&gt;This is what gets my goat: AI has many useful applications. This moment in time really is akin to the start of the internet era, in that AI has broken containment and entered mainstream conversation (in no small part due to marketing hype centered on illogical use cases). However, the hype has created acolytes with an ill-fitting solution to the non-existent problem of how to study humans better.&lt;/p&gt;
    &lt;head rend="h3"&gt;You sound like a Luddite&lt;/head&gt;
    &lt;p&gt;The Luddites were not anti-progress; they were pro-worker. Automation increased production but eliminated jobs, lowered wages, and reduced quality. Sound familiar?&lt;/p&gt;
    &lt;p&gt;Researchers already document findings at a faster velocity than orgs can act on them. It strains credulity that tech leaders are clamoring for even more yet worse findings.&lt;/p&gt;
    &lt;p&gt;The folks extolling the virtues of offloading critical research tasks to faulty tech are eroding not just the value of an entire professional class but of human curiosity and knowledge. Listen to Billy Bragg, support unions, and always stand on the side of workers‚Ä¶ especially when replacing them with unreliable facsimiles helps no one but the people who stand to profit from such a move.&lt;/p&gt;
    &lt;head rend="h3"&gt;So what do we do?&lt;/head&gt;
    &lt;p&gt;This is a scary time! There have been thousands upon thousands of tech workers‚Äîincluding researchers‚Äîlaid off in the last couple of years in the name of progress who kept their heads down, did quality work, and earned wonderful performance reviews. Going along just to get along didn‚Äôt earn anyone a reprieve. So it‚Äôs not like we have anything to lose by advocating for ourselves.&lt;/p&gt;
    &lt;p&gt;The only people who stand to gain the most from the adoption of generative AI research platforms and practices are those who claim it makes research better and those whose job depends on that belief. These claims are self-promoting narratives, sponsored content, or both.&lt;/p&gt;
    &lt;p&gt;My move is not to play the game of debasing ourselves in the name of progress. Just because a bunch of smart people say that ‚Äúthis is the future‚Äù doesn‚Äôt mean they‚Äôre right, as we just saw with web3, crypto, and NFTs. No one can predict the future (despite what NPS proponents might say).&lt;/p&gt;
    &lt;p&gt;I didn‚Äôt enter this field and take this type of job only to not do the job. My red line is conceding the things I am‚Äîwe are‚Äîuniquely good at to a product, platform, or bot. My red line is trading in the parts of the job I am both an expert in and enjoy for tasks that make the job something else entirely.&lt;/p&gt;
    &lt;p&gt;What is your red line?&lt;/p&gt;
    &lt;head rend="h3"&gt;End hits&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No part of this blog post used AI. I like writing‚Äîit helps me think; I like thinking‚Äîit helps me write.&lt;/item&gt;
      &lt;item&gt;However, my human friends and fellow researchers Meghan Cetera, Joey Jakob, and Gabe Trionfi generously provided feedback and further reading recommendations, for which I am grateful.&lt;/item&gt;
      &lt;item&gt;For more on humans in the loop, read Pavel Samsonov‚Äôs ‚ÄòHuman in the loop‚Äô is a thought-terminating cliche.&lt;/item&gt;
      &lt;item&gt;The title of this post comes from the movie WarGames, in which a supercomputer learns about futility and no-win scenarios.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gregg.io/the-only-winning-move"/><published>2025-12-03T19:00:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138632</id><title>Lie groups are crucial to some of the most fundamental theories in physics</title><updated>2025-12-03T21:10:03.729049+00:00</updated><content>&lt;doc fingerprint="e65190820f9d0f14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Are Lie Groups?&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In mathematics, ubiquitous objects called groups display nearly magical powers. Though they‚Äôre defined by just a few rules, groups help illuminate an astonishing range of mysteries. They can tell you which polynomial equations are solvable, for instance, or how atoms are arranged in a crystal.&lt;/p&gt;
    &lt;p&gt;And yet, among all the different kinds of groups, one type stands out. Identified in the early 1870s, Lie groups (pronounced ‚ÄúLee‚Äù) are crucial to some of the most fundamental theories in physics, and they‚Äôve made lasting contributions to number theory and chemistry. The key to their success is the way they blend group theory, geometry and linear algebra.&lt;/p&gt;
    &lt;p&gt;In general, a group is a set of elements paired with an operation (like addition or multiplication) that combines two of those elements to produce a third. Often, you can think of a group as the symmetries of a shape ‚Äî the transformations that leave the shape unchanged.&lt;/p&gt;
    &lt;p&gt;Consider the symmetries of the equilateral triangle. They form a group of six elements, as shown here:&lt;/p&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;(Since a full rotation brings every point on the triangle back to where it started, mathematicians stop counting rotations past 360 degrees.)&lt;/p&gt;
    &lt;p&gt;These symmetries are discrete: They form a set of distinct transformations that have to be applied in separate, unconnected steps. But you can also study continuous symmetries. It doesn‚Äôt matter, for instance, if you spin a Frisbee 1.5 degrees, or 15 degrees, or 150 degrees ‚Äî you can rotate it by any real number, and it will appear the same. Unlike the triangle, it has infinitely many symmetries.&lt;/p&gt;
    &lt;p&gt;These rotations form a group called SO(2). ‚ÄúIf you have just a reflection, OK, you have it, and that‚Äôs good,‚Äù said Anton Alekseev, a mathematician at the University of Geneva. ‚ÄúBut that‚Äôs just one operation.‚Äù This group, on the other hand, ‚Äúis many, many operations in one package‚Äù ‚Äî uncountably many.&lt;/p&gt;
    &lt;p&gt;Each rotation of the Frisbee can be represented as a point in the coordinate plane. If you plot all possible rotations of the Frisbee in this way, you‚Äôll end up with infinitely many points that together form a circle.&lt;/p&gt;
    &lt;p&gt;This extra property is what makes SO(2) a Lie group ‚Äî it can be visualized as a smooth, continuous shape called a manifold. Other Lie groups might look like the surface of a doughnut, or a high-dimensional sphere, or something even stranger: The group of all rotations of a ball in space, known to mathematicians as SO(3), is a six-dimensional tangle of spheres and circles.&lt;/p&gt;
    &lt;p&gt;Whatever the specifics, the smooth geometry of Lie groups is the secret ingredient that elevates their status among groups.&lt;/p&gt;
    &lt;head rend="h2"&gt;Off on a Tangent&lt;/head&gt;
    &lt;p&gt;It took time for Marius Sophus Lie to make his way to mathematics. Growing up in Norway in the 1850s, he hoped to pursue a military career once he finished secondary school. Instead, forced to abandon his dream due to poor eyesight, he ended up in university, unsure of what to study. He took courses in astronomy and mechanics, and flirted briefly with physics, botany and zoology before finally being drawn to math ‚Äî geometry in particular.&lt;/p&gt;
    &lt;p&gt;In the late 1860s, he continued his studies, first in Germany and then in France. He was in Paris in 1870 when the Franco-Prussian War broke out. He soon tried to leave the country, but his notes on geometry, written in German, were mistaken for encoded messages, and he was arrested, accused of being a spy. He was released from prison a month later and quickly returned to math.&lt;/p&gt;
    &lt;p&gt;In particular, he began working with groups. Forty years earlier, the mathematician √âvariste Galois had used one class of groups to understand the solutions to polynomial equations. Lie now wanted to do the same thing for so-called differential equations, which are used to model how a physical system changes over time.&lt;/p&gt;
    &lt;p&gt;His vision for differential equations didn‚Äôt work out as he‚Äôd hoped. But he soon realized that the groups he was studying were interesting in their own right. And so the Lie group was born.&lt;/p&gt;
    &lt;p&gt;The manifold nature of Lie groups has been an enormous boon to mathematicians. When they sit down to understand a Lie group, they can use all the tools of geometry and calculus ‚Äî something that‚Äôs not necessarily true for other kinds of groups. That‚Äôs because every manifold has a nice property: If you zoom in on a small enough region, its curves disappear, just as the spherical Earth appears flat to those of us walking on its surface.&lt;/p&gt;
    &lt;p&gt;To see why this is useful for studying groups, let‚Äôs go back to SO(2). Remember that SO(2) consists of all the rotations of a Frisbee, and that those rotations can be represented as points on a circle. For now, let‚Äôs focus on a sliver of the circle corresponding to very small rotations ‚Äî say, rotations of less than 1 degree.&lt;/p&gt;
    &lt;p&gt;Here, the curve of SO(2) is barely perceptible. When a Frisbee rotates 1 degree or less, any given point on its rim follows a nearly linear path. That means mathematicians can approximate these rotations with a straight line that touches the circle at just one point ‚Äî a tangent line. This tangent line is called the Lie algebra.&lt;/p&gt;
    &lt;p&gt;This feature is immensely useful. Math is a lot easier on a straight line than on a curve. And the Lie algebra contains elements of its own (often visualized as arrows called vectors) that mathematicians can use to simplify their calculations about the original group. ‚ÄúOne of the easiest kinds of mathematics in the world is linear algebra, and the theory of Lie groups is designed in such a way that it just makes constant use of linear algebra,‚Äù said David Vogan of the Massachusetts Institute of Technology.&lt;/p&gt;
    &lt;p&gt;Say you want to compare two different groups. Their respective Lie algebras simplify their key properties, Vogan said, making this task much more straightforward.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe interaction between these two structures,‚Äù Alessandra Iozzi, a mathematician at the Swiss Federal Institute of Technology Zurich, said of Lie groups and their algebras, ‚Äúis something that has an absolutely enormous array of consequences.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;The Language of Nature&lt;/head&gt;
    &lt;p&gt;The natural world is full of the kinds of continuous symmetries that Lie groups capture, making them indispensable in physics. Take gravity. The sun‚Äôs gravitational pull on the Earth depends only on the distance between them ‚Äî it doesn‚Äôt matter which side of the sun the Earth is on, for instance. In the language of Lie groups, then, gravity is ‚Äúsymmetric under SO(3).‚Äù It remains unchanged when the system it‚Äôs acting on rotates in three-dimensional space.&lt;/p&gt;
    &lt;p&gt;In fact, all the fundamental forces in physics ‚Äî gravity, electromagnetism, and the forces that hold together atomic nuclei ‚Äî are defined by Lie group symmetries. Using that definition, scientists can explain basic puzzles about matter, like why protons are always paired with neutrons, and why the energy of an atom comes in discrete quantities.&lt;/p&gt;
    &lt;p&gt;In 1918, Emmy Noether stunned mathematicians and physicists by proving that Lie groups also underlie some of the most basic laws of conservation in physics. She showed that for any symmetry in a physical system that can be described by a Lie group, there is a corresponding conservation law. For instance, the fact that the laws of physics are the same today as they were yesterday and will be tomorrow ‚Äî a symmetry known as time translation symmetry, represented by the Lie group consisting of the real numbers ‚Äî implies that the universe‚Äôs energy must be conserved, and vice versa. ‚ÄúI think, even now, it‚Äôs a very surprising result,‚Äù Alekseev said.&lt;/p&gt;
    &lt;p&gt;Today, Lie groups remain a vital tool for both mathematicians and physicists. ‚ÄúDefinitions live in mathematics because they‚Äôre powerful. Because there are a lot of interesting examples and they give you a good way to think about something,‚Äù Vogan said. ‚ÄúSymmetry is everywhere, and that‚Äôs what this stuff is for.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/what-are-lie-groups-20251203/"/><published>2025-12-03T19:12:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138952</id><title>Everyone in Seattle hates AI</title><updated>2025-12-03T21:10:03.641211+00:00</updated><content>&lt;doc fingerprint="73395114bff6ccdd"&gt;
  &lt;main&gt;
    &lt;p&gt;I grabbed lunch with a former Microsoft coworker I've always admired‚Äîone of those engineers who can take any idea, even a mediocre one, and immediately find the gold in it. I wanted her take on Wanderfugl üê¶, the AI-powered map I've been building full-time. I expected encouragement. At worst, overly generous feedback because she knows what I've sacrificed.&lt;/p&gt;
    &lt;p&gt;Instead, she reacted to it with a level of negativity I'd never seen her direct at me before.&lt;/p&gt;
    &lt;p&gt;When I finally got her to explain what was wrong, none of it had anything to do with what I built. She talked about Copilot 365. And Microsoft AI. And every miserable AI tool she's forced to use at work. My product barely featured. Her reaction wasn't about me at all. It was about her entire environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;The AI Layoffs&lt;/head&gt;
    &lt;p&gt;Her PM had been laid off months earlier. The team asked why. Their director told them it was because the PM org "wasn't effective enough at using Copilot 365."&lt;/p&gt;
    &lt;p&gt;I nervously laughed. This director got up in a group meeting and said that someone lost their job over this?&lt;/p&gt;
    &lt;p&gt;After a pause I tried to share how much better I've been feeling‚Äîhow AI tools helped me learn faster, how much they accelerated my work on Wanderfugl. I didn't fully grok how tone deaf I was being though. She's drowning in resentment.&lt;/p&gt;
    &lt;p&gt;I left the lunch deflated and weirdly guilty, like building an AI product made me part of the problem.&lt;/p&gt;
    &lt;p&gt;But then I realized this was bigger than one conversation. Every time I shared Wanderfugl with a Seattle engineer, I got the same reflexive, critical, negative response. This wasn't true in Bali, Tokyo, Paris, or San Francisco‚Äîpeople were curious, engaged, wanted to understand what I was building. But in Seattle? Instant hostility the moment they heard "AI."&lt;/p&gt;
    &lt;head rend="h2"&gt;The people at big tech in Seattle are not ok&lt;/head&gt;
    &lt;p&gt;When I joined Microsoft, there was still a sense of possibility. Satya was pushing "growth mindset" everywhere. Leaders talked about empowerment and breaking down silos. And even though there was always a gap between the slogans and reality, there was room to try things.&lt;/p&gt;
    &lt;p&gt;I leaned into it. I pushed into areas nobody wanted to touch, like Windows update compression, because it lived awkwardly across three teams. Somehow, a 40% improvement made it out alive. Leadership backed it. The people trying to kill it shrank back into their fiefdoms. It felt like the culture wanted change.&lt;/p&gt;
    &lt;p&gt;That world is gone.&lt;/p&gt;
    &lt;p&gt;When the layoff directive hit, every org braced for impact. Anything not strictly inside the org's charter was axed. I went from shipping a major improvement in Windows 11 to having zero projects overnight. I quit shortly after. In hindsight, getting laid off with severance might've been better than watching the culture collapse in slow motion.&lt;/p&gt;
    &lt;p&gt;Then came the AI panic.&lt;/p&gt;
    &lt;p&gt;If you could classify your project as "AI," you were safe and prestigious. If you couldn't, you were nobody. Overnight, most engineers got rebranded as "not AI talent." And then came the final insult: everyone was forced to use Microsoft's AI tools whether they worked or not.&lt;/p&gt;
    &lt;p&gt;Copilot for Word. Copilot for PowerPoint. Copilot for email. Copilot for code. Worse than the tools they replaced. Worse than competitors' tools. Sometimes worse than doing the work manually.&lt;/p&gt;
    &lt;p&gt;But you weren't allowed to fix them‚Äîthat was the AI org's turf. You were supposed to use them, fail to see productivity gains, and keep quiet.&lt;/p&gt;
    &lt;p&gt;Meanwhile, AI teams became a protected class. Everyone else saw comp stagnate, stock refreshers evaporate, and performance reviews tank. And if your team failed to meet expectations? Clearly you weren't "embracing AI."&lt;/p&gt;
    &lt;p&gt;Bring up AI in a Seattle coffee shop now and people react like you're advocating asbestos.&lt;/p&gt;
    &lt;p&gt;Amazon folks are slightly more insulated, but not by much. The old Seattle deal‚ÄîAmazon treats you poorly but pays you more‚Äîonly masks the rot.&lt;/p&gt;
    &lt;head rend="h2"&gt;Self-Limiting Beliefs&lt;/head&gt;
    &lt;p&gt;This belief system‚Äîthat AI is useless and that you're not good enough to work on it anyway‚Äîhurts three groups:&lt;/p&gt;
    &lt;p&gt; 1. The companies.&lt;lb/&gt; They've taught their best engineers that innovation isn't their job. &lt;/p&gt;
    &lt;p&gt; 2. The engineers.&lt;lb/&gt; They're stuck in resentment and self-doubt while their careers stall. &lt;/p&gt;
    &lt;p&gt; 3. Anyone trying to build anything new in Seattle.&lt;lb/&gt; Say "AI" and people treat you like a threat or an idiot. &lt;/p&gt;
    &lt;p&gt; And the loop feeds itself:&lt;lb/&gt; Engineers don't try because they think they can't.&lt;lb/&gt; Companies don't empower them because they assume they shouldn't.&lt;lb/&gt; Bad products reinforce the belief that AI is doomed.&lt;lb/&gt; The spiral locks in. &lt;/p&gt;
    &lt;p&gt;My former coworker‚Äîthe composite of three people for anonymity‚Äînow believes she's both unqualified for AI work and that AI isn't worth doing anyway. She's wrong on both counts, but the culture made sure she'd land there.&lt;/p&gt;
    &lt;p&gt;Seattle has talent as good as anywhere. But in San Francisco, people still believe they can change the world‚Äîso sometimes they actually do.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jonready.com/blog/posts/everyone-in-seattle-hates-ai.html"/><published>2025-12-03T19:37:25+00:00</published></entry></feed>