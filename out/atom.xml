<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-06T20:40:12.434482+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45833811</id><title>Show HN: qqqa ‚Äì A fast, stateless LLM-powered assistant for your shell</title><updated>2025-11-06T20:40:20.083308+00:00</updated><content>&lt;doc fingerprint="41fc851218d5aa1"&gt;
  &lt;main&gt;
    &lt;p&gt;Fast, stateless LLM-powered assistant for your shell: qq answers; qa runs commands&lt;/p&gt;
    &lt;p&gt;qqqa is a two-in-one, stateless CLI tool that brings LLM assistance to the command line without ceremony.&lt;/p&gt;
    &lt;p&gt;The two binaries are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;qq&lt;/code&gt;- ask a single question, e.g. "qq how can I recursively list all files in this directory" (qq stands for "quick question")&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;qa&lt;/code&gt;- a single step agent that can optionally use tools to finish a task: read a file, write a file, or execute a command with confirmation (qa stands for "quick agent")&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By default the repo includes profiles for OpenAI and Groq.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;demo.mp4&lt;/head&gt;
    &lt;p&gt;qq means quick question. qa means quick agent. Both are easy to type rapidly on QWERTY keyboards with minimal finger movement. That makes interacting with LLMs faster and more natural during real work.&lt;/p&gt;
    &lt;p&gt;qqqa is deliberately stateless. There is no long running session and no hidden conversation memory stored by the tool. Every run is mostly independent and reproducible. For maintaining a lowkey continuity you can use &lt;code&gt;"include_history": true&lt;/code&gt; in the &lt;code&gt;config.json&lt;/code&gt; (or choose to use history during the &lt;code&gt;qq --init&lt;/code&gt; process).&lt;/p&gt;
    &lt;p&gt;Why stateless is great:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple and focused - Unix philosophy applied to LLM tools.&lt;/item&gt;
      &lt;item&gt;Shell friendly - compose with pipes and files instead of interactive chats.&lt;/item&gt;
      &lt;item&gt;Safe by default - qq is read-only and has access to no tools. qa is built with security in mind and requires confirmation before running tools.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tools may include transient context you choose to provide:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;qq&lt;/code&gt;can include the last few terminal commands as hints and piped stdin if present.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;qa&lt;/code&gt;can read files or run a specific command, but only once per invocation and with safety checks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For fast feedback loops, speed and cost matter. The included &lt;code&gt;groq&lt;/code&gt; profile targets Groq's OpenAI compatible API and the model &lt;code&gt;openai/gpt-oss-20b&lt;/code&gt;. We recommend Groq for really fast inference speed at roughly 1000 tokens per second and at a low price point compared to many alternatives. Set &lt;code&gt;GROQ_API_KEY&lt;/code&gt; and you are ready to go.&lt;/p&gt;
    &lt;p&gt;You can still use OpenAI or any other OpenAI compatible provider by adding a provider entry and a profile in &lt;code&gt;~/.qq/config.json&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI compatible API client with streaming and non streaming calls.&lt;/item&gt;
      &lt;item&gt;Stateless, single shot workflow that plays well with pipes and scripts.&lt;/item&gt;
      &lt;item&gt;Rich but simple formatting using XML like tags rendered to ANSI colors.&lt;/item&gt;
      &lt;item&gt;Config driven providers and profiles with per profile model overrides.&lt;/item&gt;
      &lt;item&gt;Safety rails for file access and command execution.&lt;/item&gt;
      &lt;item&gt;Old-school and SERIOUS? Optional no-emoji mode persisted via &lt;code&gt;--no-fun&lt;/code&gt;ü•∏&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the Homebrew tap:&lt;/p&gt;
    &lt;code&gt;brew tap iagooar/qqqa
brew install qqqa&lt;/code&gt;
    &lt;p&gt;Download a prebuilt archive from the GitHub Releases page, extract it, and place &lt;code&gt;qq&lt;/code&gt;/&lt;code&gt;qa&lt;/code&gt; somewhere on your &lt;code&gt;PATH&lt;/code&gt; (e.g., &lt;code&gt;/usr/local/bin&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;On first run qqqa creates &lt;code&gt;~/.qq/config.json&lt;/code&gt; with safe permissions. For a smooth first interaction, run the init flow:&lt;/p&gt;
    &lt;code&gt;# Interactive setup (choose provider and set key)
qq --init
# or
qa --init&lt;/code&gt;
    &lt;p&gt;If &lt;code&gt;~/.qq/config.json&lt;/code&gt; already exists, the init command keeps it untouched and explains how to rerun after moving or deleting the file.&lt;/p&gt;
    &lt;p&gt;The initializer lets you choose the default provider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Groq + &lt;code&gt;openai/gpt-oss-20b&lt;/code&gt;(faster, cheaper)&lt;/item&gt;
      &lt;item&gt;OpenAI + &lt;code&gt;gpt-5-mini&lt;/code&gt;(slower, a bit smarter)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It also offers to store an API key in the config (optional). If you prefer environment variables, leave it blank and set one of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;for Groq&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;for OpenAI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Defaults written to &lt;code&gt;~/.qq/config.json&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Providers &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;openai&lt;/code&gt;‚Üí base&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;, env&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;groq&lt;/code&gt;‚Üí base&lt;code&gt;https://api.groq.com/openai/v1&lt;/code&gt;, env&lt;code&gt;GROQ_API_KEY&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Profiles &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;openai&lt;/code&gt;‚Üí model&lt;code&gt;gpt-5-mini&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;groq&lt;/code&gt;‚Üí model&lt;code&gt;openai/gpt-oss-20b&lt;/code&gt;(default)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Optional per-profile &lt;code&gt;reasoning_effort&lt;/code&gt;for GPT-5 family models. If you leave it unset, qqqa sends&lt;code&gt;"reasoning_effort": "minimal"&lt;/code&gt;for any&lt;code&gt;gpt-5*&lt;/code&gt;model to keep responses fast. Set it to&lt;code&gt;"low"&lt;/code&gt;,&lt;code&gt;"medium"&lt;/code&gt;, or&lt;code&gt;"high"&lt;/code&gt;when you want deeper reasoning.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example override in &lt;code&gt;~/.qq/config.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;{
  "profiles": {
    "openai": {
      "model_provider": "openai",
      "model": "gpt-5-mini",
      "reasoning_effort": "medium"
    }
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optional flag: &lt;code&gt;no_emoji&lt;/code&gt;(unset by default). Set via&lt;code&gt;qq --no-fun&lt;/code&gt;or&lt;code&gt;qa --no-fun&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Terminal history is off by default. During &lt;code&gt;qq --init&lt;/code&gt; / &lt;code&gt;qa --init&lt;/code&gt; you can opt in to sending the last 10 &lt;code&gt;qq&lt;/code&gt;/&lt;code&gt;qa&lt;/code&gt; commands along with each request. You can still override per run with &lt;code&gt;--history&lt;/code&gt; (force on) or &lt;code&gt;-n/--no-history&lt;/code&gt; (force off). Only commands whose first token is &lt;code&gt;qq&lt;/code&gt; or &lt;code&gt;qa&lt;/code&gt; are ever shared.&lt;/p&gt;
    &lt;p&gt;You can still override at runtime:&lt;/p&gt;
    &lt;code&gt;# choose profile
qq -p groq "what is ripgrep"

# override model for a single call
qq -m openai/gpt-oss-20b "explain this awk one-liner"&lt;/code&gt;
    &lt;code&gt;# simplest
qq "convert mp4 to mp3"

# stream tokens with formatted output
qq -s "how do I kill a process by name on macOS"

# include piped context
git status | qq "summarize what I should do next"

# pipe extra context and keep CLI question
printf '%s\n' "This is a sample context. My code is 4242" | qq "What is my code"

# pipe the question itself
printf '%s\n' "Show me the full contents of this directory" | qq

# raw text (no ANSI formatting)
qq -r "explain sed vs awk"

# include terminal history for this run
qq --history "find large files in the last day"

# disable emojis in responses (persists)
qq --no-fun "summarize this"&lt;/code&gt;
    &lt;p&gt;Note: it is possible to run qq without quotes, which works most of the time the same way as with quotes.&lt;/p&gt;
    &lt;code&gt;# simplest
qq convert mp4 to mp3&lt;/code&gt;
    &lt;p&gt;You want to extract audio from a YouTube video but you do not remember the exact flags.&lt;/p&gt;
    &lt;p&gt;Ask with qq:&lt;/p&gt;
    &lt;code&gt;qq "how do I use ffmpeg to extract audio from a YouTube video into mp3"&lt;/code&gt;
    &lt;p&gt;A typical answer will suggest installing the tools and then using &lt;code&gt;yt-dlp&lt;/code&gt; to fetch audio and &lt;code&gt;ffmpeg&lt;/code&gt; to convert it:&lt;/p&gt;
    &lt;code&gt;# macOS
brew install yt-dlp ffmpeg

# Debian or Ubuntu
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y yt-dlp ffmpeg

# Download and extract audio to MP3 using ffmpeg under the hood
yt-dlp -x --audio-format mp3 "https://www.youtube.com/watch?v=VIDEO_ID"&lt;/code&gt;
    &lt;p&gt;Do it for me with qa:&lt;/p&gt;
    &lt;code&gt;qa "download audio as mp3 from https://www.youtube.com/watch?v=VIDEO_ID"&lt;/code&gt;
    &lt;p&gt;The agent will propose a safe command like &lt;code&gt;yt-dlp -x --audio-format mp3 URL&lt;/code&gt;, show it for confirmation, then run it. You can pass &lt;code&gt;-y&lt;/code&gt; to auto approve.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;qa&lt;/code&gt; can either answer in plain text or request one tool call in JSON. Supported tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;read_file&lt;/code&gt;with&lt;code&gt;{ "path": string }&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;write_file&lt;/code&gt;with&lt;code&gt;{ "path": string, "content": string }&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;execute_command&lt;/code&gt;with&lt;code&gt;{ "command": string, "cwd?": string }&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;# read a file the safe way
qa "read src/bin/qq.rs and tell me what main does"

# write a file
qa "create a README snippet at notes/intro.md with a short summary"

# run a command with confirmation
qa "list Rust files under src sorted by size"

# pipe the task itself
printf '%s\n' "Show me the full contents of this directory" | qa

# auto approve tool execution for non interactive scripts
qa -y "count lines across *.rs"

# include recent qq/qa commands just for this run
qa --history "trace which git commands I ran recently"

# disable emojis in responses (persists)
qa --no-fun "format and lint the repo"&lt;/code&gt;
    &lt;p&gt;When qa runs a command while stdout is a terminal, output now streams live; the structured &lt;code&gt;[tool:execute_command]&lt;/code&gt; summary still prints afterward for easy copying.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;execute_command&lt;/code&gt; prints the proposed command and asks for confirmation. It warns if the working directory is outside your home. Use &lt;code&gt;-y&lt;/code&gt; to auto approve in trusted workflows.&lt;/p&gt;
    &lt;p&gt;The runner enforces a default allowlist (think &lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;find&lt;/code&gt;, &lt;code&gt;rg&lt;/code&gt;, &lt;code&gt;awk&lt;/code&gt;, etc.) and rejects pipelines, redirection, and other high-risk constructs. When a command is blocked, &lt;code&gt;qa&lt;/code&gt; prompts you to add it to &lt;code&gt;command_allowlist&lt;/code&gt; inside &lt;code&gt;~/.qq/config.json&lt;/code&gt;; approving once persists the choice and updates future runs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;File tools require paths to be inside your home or the current directory. Reads are capped to 1 MiB, and traversal/symlink escapes are blocked.&lt;/item&gt;
      &lt;item&gt;Command execution uses a default allowlist (e.g. &lt;code&gt;ls&lt;/code&gt;,&lt;code&gt;grep&lt;/code&gt;,&lt;code&gt;rg&lt;/code&gt;,&lt;code&gt;find&lt;/code&gt;) plus your custom&lt;code&gt;command_allowlist&lt;/code&gt;entries. Destructive patterns (&lt;code&gt;rm -rf /&lt;/code&gt;,&lt;code&gt;sudo&lt;/code&gt;,&lt;code&gt;mkfs&lt;/code&gt;, etc.) are always blocked, and pipelines/redirection/newlines prompt for confirmation even with&lt;code&gt;--yes&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Commands run with a 120 s timeout and the agent performs at most one tool step‚Äîthere is no loop.&lt;/item&gt;
      &lt;item&gt;Config files are created with safe permissions. API keys come from environment variables unless you explicitly add a key to the config.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;for the Groq provider&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;for the OpenAI provider&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Project layout:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;src/bin/qq.rs&lt;/code&gt;and&lt;code&gt;src/bin/qa.rs&lt;/code&gt;entry points&lt;/item&gt;
      &lt;item&gt;Core modules in &lt;code&gt;src/&lt;/code&gt;:&lt;code&gt;ai.rs&lt;/code&gt;,&lt;code&gt;config.rs&lt;/code&gt;,&lt;code&gt;prompt.rs&lt;/code&gt;,&lt;code&gt;history.rs&lt;/code&gt;,&lt;code&gt;perms.rs&lt;/code&gt;,&lt;code&gt;formatting.rs&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Tools in &lt;code&gt;src/tools/&lt;/code&gt;:&lt;code&gt;read_file.rs&lt;/code&gt;,&lt;code&gt;write_file.rs&lt;/code&gt;,&lt;code&gt;execute_command.rs&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Integration tests in &lt;code&gt;tests/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See CONTRIBUTING.md for guidelines on reporting issues and opening pull requests, building from source, and the release process.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API error about missing key: run &lt;code&gt;qq --init&lt;/code&gt;to set things up, or export the relevant env var, e.g.&lt;code&gt;export GROQ_API_KEY=...&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;No output when streaming: try &lt;code&gt;-d&lt;/code&gt;to see debug logs.&lt;/item&gt;
      &lt;item&gt;Piped input not detected: ensure you are piping into &lt;code&gt;qq&lt;/code&gt;and not running it in a subshell that swallows stdin.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Licensed under MIT.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/matisojka/qqqa"/><published>2025-11-06T10:59:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45834254</id><title>Eating stinging nettles</title><updated>2025-11-06T20:40:19.786794+00:00</updated><content>&lt;doc fingerprint="3730f7cb74e1c58"&gt;
  &lt;main&gt;
    &lt;p&gt;Spring is here and the nettles are growing again so I decided it was time to make a meal out of them. Most people know that stinging nettles are pesky green plants that irritate the skin when you touch them. What you probably don‚Äôt know is that they‚Äôre a nutritious source of iron, calcium, potassium, and silica as well as vitamins A, B, C, and K1. Stinging nettles also have anti-inflammatory properties and can relieve arthritis and rheumatism. They can be turned into soups, curries, and risottos (some recipes here) and you can get them completely free from practically everywhere in Britain over the summer. You‚Äôve likely even got some in your garden.&lt;/p&gt;
    &lt;p&gt;When you collect them you need to wear gloves because they sting. The advantage of this is it allows you to make sure you‚Äôre collecting the right thing. If you‚Äôre unsure, just touch one and see whether it hurts which is exactly what I did. It hurt.&lt;/p&gt;
    &lt;p&gt;The even look a bit scary with their toothy-edged leaves.&lt;/p&gt;
    &lt;p&gt;Once you‚Äôve got them inside, boil them in water for a few minutes and this will stop them stinging.&lt;/p&gt;
    &lt;p&gt;We‚Äôre having stinging nettle risotto.&lt;/p&gt;
    &lt;p&gt;People think that when you become vegan you have to give up lots of food. It‚Äôs true that I stopped eating animals but the number of different species I eat has grown considerably. This is because meat-eaters tend to eat the same few species of animals over and over again ‚Äì pigs, cows, chickens. Whereas there are some 20,000 species of edible plants in the world. Meat also tends to fill you up. Indeed I‚Äôve been to dinner with people where all they have on their plate is a slab of meat and nothing else. Whereas as a vegan (with the exception of a shitty Spanish restaurant that served me a plate of artichokes and nothing else) I eat a huge variety of species. Meat-eaters can eat these too but they often don‚Äôt because meat is so filling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rachel.blog/2018/04/29/eating-stinging-nettles/"/><published>2025-11-06T11:57:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45834980</id><title>IKEA launches new smart home range with 21 Matter-compatible products</title><updated>2025-11-06T20:40:18.821478+00:00</updated><content>&lt;doc fingerprint="d5745a5ac3b9fbfb"&gt;
  &lt;main&gt;
    &lt;p&gt;Published 6 November 2025 ‚Ä¢ Inter IKEA newsroom&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA launches new smart home range with 21 Matter-compatible products&lt;/head&gt;
    &lt;p&gt;IKEA is launching 21 new smart home products focusing on lighting, sensors, and control ‚Äî all built to work with Matter, the universal smart home standard. The launch marks a significant step in making smart home technology easier to use, more affordable, and better adapted to real-life needs in the home.&lt;/p&gt;
    &lt;p&gt;With this launch, IKEA is rebuilding its smart home system and product range from the ground up. The new launch reflects years of development and testing in real homes, and a growing understanding of how people want smart products to work in their daily life.&lt;/p&gt;
    &lt;p&gt;The launch includes both new products and updates to existing categories ‚Äì now built to work with Matter. This means IKEA smart products can connect with a wider range of devices and platforms, making it easier for customers to build a smart home across different brands.&lt;/p&gt;
    &lt;p&gt;‚ÄúUntil now, smart home technology hasn‚Äôt been easy enough to use for most people ‚Äî or affordable enough for many to consider. This launch brings us closer to helping everyone feel ready and confident to get started,‚Äù says David Granath, Range Manager at IKEA of Sweden.&lt;/p&gt;
    &lt;p&gt;The updated range focuses on three key segments*, that provide the building blocks of a smart home that‚Äôs flexible, intuitive, and easy to expand over time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lighting ‚Äì The new smart bulb range from IKEA. Comes in a variety of shapes, sizes, lumen levels and styles, including colour and white spectrum options, and dimmable features.&lt;/item&gt;
      &lt;item&gt;Sensors ‚Äì motion, air quality, humidity and water leakage sensors designed to support wellbeing and prevent damage&lt;/item&gt;
      &lt;item&gt;Control ‚Äì Remotes that make it easy to control devices from a distance, and a smart plug that can turn any product into a smart product.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;*Full product list further down.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis launch is about making the smart home experience better and broader. We're upgrading our most-appreciated products while also adding new ones to solve even more everyday challenges. Our focus has been on keeping things simple from setup to daily use, so it‚Äôs easy for people to start, use and grow a smart home,‚Äù says Stjepan Begic, Product Developer at IKEA of Sweden.&lt;/p&gt;
    &lt;p&gt;All Matter-enabled products need a smart home hub to work ‚Äî like IKEA‚Äôs DIRIGERA hub, or one from another brand. As a certified Matter controller, DIRIGERA can also manage and control smart products from other manufacturers and brands. As a Matter Bridge, it ensures that existing IKEA non-Matter smart products will also be compatible with platforms using the Matter standard.&lt;/p&gt;
    &lt;p&gt;This launch is the first step in a broader update of the IKEA Home smart range. Looking ahead, IKEA will continue expanding into new product categories. The strategy is to launch products that are easier to use and more affordable than existing ones.&lt;/p&gt;
    &lt;p&gt;‚ÄúOur goal is still the same as when we started exploring the smart home in 2012: to make it easy to use, easy to understand, and within reach for the many. We start with understanding life at home, where we continuously watch, listen and learn what makes a difference in everyday life. We believe technology should serve a purpose, not exist for its own sake. With more than 900 million store visits each year, I think we‚Äôre in a good place to help more people discover the benefits of a smarter home,‚Äù says David Granath.&lt;/p&gt;
    &lt;p&gt;Sales start and local pricing may vary between markets. Please contact your local IKEA market for more information.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover the new Matter-compatible IKEA Home smart range:&lt;/head&gt;
    &lt;p&gt;The KAJPLATS smart bulb range includes eleven variations, offering a mix of shapes, sizes, lumen levels, and styles ‚Äî with options for both colour and white spectrum, as well as dimmable functionality. Compared to the previous TR√ÖDFRI range, each bulb has more functionality, including more colour options and broader light intensity spans.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E27/E26 ‚Äì standard globe shape, 60 mm diameter &lt;lb/&gt;Colour and white spectrum, 1 055 lm ‚Äì colour-changing&lt;lb/&gt;White spectrum, 470 lm ‚Äì dimmable&lt;lb/&gt;White spectrum, 1 055 lm ‚Äì dimmable&lt;lb/&gt;White spectrum, 1 521 lm ‚Äì dimmable&lt;/item&gt;
      &lt;item&gt;P45 E14* ‚Äì compact profile, 45 mm diameter&lt;lb/&gt;White spectrum, 470 lm ‚Äì dimmable&lt;lb/&gt;White spectrum, 806 lm ‚Äì dimmable&lt;lb/&gt;Colour and white spectrum, 806 lm ‚Äì colour-changing&lt;/item&gt;
      &lt;item&gt;GU10 ‚Äì directional spotlight &lt;lb/&gt;Colour and white spectrum, 470 lm - colour-changing&lt;lb/&gt;White spectrum, 575 lm ‚Äì dimmable&lt;/item&gt;
      &lt;item&gt;Clear-glass decorative bulbs ‚Äì white spectrum only (dimmable) &lt;lb/&gt;E14* ‚Äì 470 lm clear glass&lt;lb/&gt;E27 standard globe (60 mm diameter) ‚Äì 470 lm clear glass&lt;lb/&gt;E27 large globe (95 mm diameter) ‚Äì 810 lm clear glass&lt;lb/&gt;*E14 also available as E12 and E17 depending on local standardisations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Smart sensors: Five variations for motion, air quality, humidity and water leakage designed to support wellbeing and prevent damage.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MYGGSPRAY - Motion sensor for indoor and outdoor use that turns on lighting automatically in areas like entrances, staircases, garages, or anywhere you need hands-free light.&lt;/item&gt;
      &lt;item&gt;MYGGBETT ‚Äì Door/Window sensor. Detects when a door or window is opened or closed, and if connected to a smart system you can get notifications on your phone. Also works for spaces like walk-in closets, where it can trigger a light to turn on or off.&lt;/item&gt;
      &lt;item&gt;TIMMERFLOTTE ‚Äì Temperature and Humidity Sensor. Measures the indoor climate at home. Press the button to view temperature, followed by humidity ‚Äî one after the other.&lt;/item&gt;
      &lt;item&gt;ALPSTUGA ‚Äì Air quality sensor. Measures CO‚ÇÇ, particles (PM2.5), temperature, and humidity to show the air quality in your home. Built to work together with IKEA air purifiers for better indoor air. Can also display the time&lt;/item&gt;
      &lt;item&gt;KLIPPBOK ‚Äì Water leakage sensor. Detects leaks and alerts you with a sound ‚Äì and can also send a notification to your phone when connected to a hub. Small enough to place under sinks, appliances, or other risk areas.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Remote controls and plugs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BILRESA remote control with dual button ‚Äì A simple way to control smart products from afar. Use it to switch lights on or off, adjust brightness, change colour, or trigger a preset scene.&lt;/item&gt;
      &lt;item&gt;BILRESA remote control with scroll wheel ‚Äì Lets you adjust smart products with a simple turn. Use it to switch lights on or off, dim, change colour, or control a group or preset scene.&lt;/item&gt;
      &lt;item&gt;BILRESA Remote Control Kits (2x) ‚Äì Kits of three colourful versions of the remote controls, in green, red and beige. One kit with three scroll wheels, and the other is with remote control with dual buttons.&lt;/item&gt;
      &lt;item&gt;GRILLPLATS smart plug. This smart plug lets you control ordinary lamps or smaller appliances remotely ‚Äî turning them into smart products. It also tracks energy use and can be paired with a remote or motion sensor. Separate sales start&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ikea.com/global/en/newsroom/retail/the-new-smart-home-from-ikea-matter-compatible-251106/"/><published>2025-11-06T13:26:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45835083</id><title>I analyzed the lineups at the most popular nightclubs</title><updated>2025-11-06T20:40:18.630386+00:00</updated><content>&lt;doc fingerprint="3603417d793229b9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I analyzed the lineups at the world's most popular nightclubs&lt;/head&gt;
    &lt;p&gt;A few years back I did a bit of dance music related data visualization over at Lazily Evaluated. My favourite was an analysis of clubs and their lineups using Resident Advisor / RA data, I called it Clubster Analysis. I always wanted to dig into the technical aspects of gathering the data, analyzing it and building the charts and graphs to tell a story and give people insight. With this blog I now have the right venue for that kind of tech talk, so here goes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data gathering #&lt;/head&gt;
    &lt;p&gt;To visualize data, first you have to get some! For this purpose I wrote a little scraper in Python. I used Beautiful Soup to parse the html and grab the bits and pieces I was interested in.&lt;/p&gt;
    &lt;p&gt;My scraping of a few thousand pages didn‚Äôt cause considerable load on the RA servers. But in the age of overzealous AI scrapers it‚Äôs worth being polite, so I throttled according to their robots.txt. I also maintained a local cache of html files I had already downloaded, so that I wouldn‚Äôt have fetch the same data repeatedly (past lineups are unlikely to change after the fact) just because I discovered some bug or error in my parsing.&lt;/p&gt;
    &lt;p&gt;The order I scraped in was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Get the 20 most popular regions in RA (and then I dropped ‚ÄúStreamland‚Äù which was a pandemic era pseudo-region)&lt;/item&gt;
      &lt;item&gt;Fetch the most popular clubs and some related metadata for all of those regions.&lt;/item&gt;
      &lt;item&gt;For each club, get the lineups for every 2019 event of theirs (the last full year before the pandemic started).&lt;/item&gt;
      &lt;item&gt;Save the results to csv files&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Clean up, verification and Analysis #&lt;/head&gt;
    &lt;p&gt;I did some spot checks to verify that my parsing was working as I expected and added tests to make sure I handled edge cases and normalized artist names. There was a lot of variance in how dates were formatted, how artists were linked, etc.&lt;/p&gt;
    &lt;p&gt;After that I analyzed the data. I built one big table/dataframe in Pandas by joining all the info from the csv files. Then I calculated the similarities between each pair of clubs in the data set using the Jaccard index. Consider all the artists that have played at two given clubs, take the intersection (number of artists that have featured in lineups at both clubs) over the union (all the artists that have performed at one or the other). As an example if Club A had 100 artists booked and Club B had 100 artists, and they had 10 bookings in common, the Jaccard index would be 10/190 = ~5%. This gives you a good way to compare large and small clubs and balances large and small lineups (some of the clubs have multiple rooms with very long events, others have one dj playing in one room all night long once a week).&lt;/p&gt;
    &lt;p&gt;Based on the Jaccard index we can build a graph, using NetworkX from all the clubs. The edges between two nodes are weighted by the similarity of those clubs. On top of the graph we run community detection to create clusters (hence the clubster name). This gives us a rough idea of which clubs are most similar, that is to say, have similar tastes in their bookings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results #&lt;/head&gt;
    &lt;p&gt;For the year 2019, there were 131 clubs in the data set with 8.502 events. There were 9.405 unique artists making up 30.482 individual bookings. This means that the average artist in the dataset was booked 3.24 times at those clubs in that year and the average event had 3.5 artists on the line up.&lt;/p&gt;
    &lt;p&gt;As a whole, out of 8.515 possible pairs of clubs, 3.716 pairs had some overlap in their bookings and out of those the average overlap was 1%. This was lower than I thought, the bookings at European clubs felt more homogenous to me, but I suppose they book a lot of artists. It would be interesting to get more data, recent and historic, and see how this has evolved through time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Visualization #&lt;/head&gt;
    &lt;p&gt;This was my first time using D3 to draw charts. There was a bit of a learning curve, in earlier projects I had used higher level charting libraries which have simpler apis. But with D3 you get a lot of control over how your charts look and behave which I think I used to good effect in this instance.&lt;/p&gt;
    &lt;p&gt;My main goal was to visualize the clusters and to allow people to interact with the clubs. I coloured the clubs according to their clusters and sized them based on the number of followers they had on RA. I played around with the gravity and placement of the cluster, trying to find a balance that worked on different screen sizes as well as being a fair portrayal of the different communities.&lt;/p&gt;
    &lt;p&gt;I then did some scrollytelling to tell the story of the data, as I saw it, while the reader scrolls down the page. But I also added filters and interactivity for people to explore and see if they agree with my telling of the story or if they can find one of their own.&lt;/p&gt;
    &lt;p&gt;At the time I didn‚Äôt find any great React and D3 bridges, so it was a bit of a hassle getting the React components to play nice with the D3 graph, but in the end I was able to connect the two with &lt;code&gt;createRef&lt;/code&gt; to the D3 svg component.&lt;/p&gt;
    &lt;p&gt;Besides the clustering I looked into the ‚Äúresident factor‚Äù, how many times an artist was booked at a club repeatedly compared to all the one offs. This was lower than expected, most of these clubs were booking a constantly rotating assembly of talent, residents don‚Äôt play as big a part as I would have thought.&lt;/p&gt;
    &lt;p&gt;Transitioning between the different sections of these graphs was one of my favourite parts. Seeing the clusters morph into dots and candlestick charts (and back again) was oddly satisfying. Took a lot of tweaking, but I think it really tied together the scrollytelling experience.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think these transitions would have been possible with the higher level charting libraries I‚Äôd used previously. So the decision to go with D3 felt justified.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary #&lt;/head&gt;
    &lt;p&gt;This was a great pandemic project that combined web scraping, data analysis, and interactive visualization to explore the global dance music club scene. I learned me some D3 for the visualization, got better at doing cartesian graphing calculations in my head and learned about the underlying svg mechanics that power those graphs.&lt;/p&gt;
    &lt;p&gt;The results surprised me: despite my perceived homogeneity of European club bookings, only 1% average overlap between venues suggested more diverse landscape than I expected. The diminished role of residents compared to one-off bookings also challenged my assumptions about how these clubs operate. For the story telling maintaining the balance between a narrative and letting users explore and decide for themselves was a fun challenge. I think these sort of passion projects can give us deep insights into our world and culture.&lt;/p&gt;
    &lt;p&gt;The technical stack I worked with: Python, Pandas, NetworkX, D3, and React proved powerful despite some integration challenges. The complete project is available on GitHub and you can explore the live interactive visualization yourself.&lt;/p&gt;
    &lt;p&gt;I had a lot of fun building this and am proud of the result. If you‚Äôre working on cultural data analysis, need help with web scraping and visualization, or just want to discuss interesting datasets, feel free to reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/"/><published>2025-11-06T13:37:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45835123</id><title>Cloudflare Tells U.S. Govt That Foreign Site Blocking Efforts Are Trade Barriers</title><updated>2025-11-06T20:40:18.396623+00:00</updated><content>&lt;doc fingerprint="201a9b555f843940"&gt;
  &lt;main&gt;
    &lt;p&gt;Every year, the office of the United States Trade Representative (USTR) publishes the National Trade Estimate Report on Foreign Trade Barriers.&lt;/p&gt;
    &lt;p&gt;The report is compiled based on input from key industry players. This includes submissions from copyright industry groups that frequently highlight piracy challenges that in their view act as barriers to trade.&lt;/p&gt;
    &lt;p&gt;In previous years, for example, the MPA and others have called for more site-blocking efforts to counter the piracy threat. Interestingly, however, other American companies now inform the USTR that foreign site-blocking measures are becoming a significant trade barrier.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cloudflare Sees Piracy Blockades as Trade Barriers&lt;/head&gt;
    &lt;p&gt;To share its concerns, Cloudflare decided to participate in the annual trade barriers consultation for the first time this year. The company describes itself as a ‚Äúleading connectivity cloud company‚Äù running one of the world‚Äôs largest networks, providing security, performance, and reliability services.&lt;/p&gt;
    &lt;p&gt;According to Cloudflare, several foreign countries disproportionately impact U.S. technology providers, with many concerns relating to site-blocking measures that aim to deter online piracy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Spain&lt;/head&gt;
    &lt;p&gt;Cloudflare writes that Spanish courts allow rightsholders to request ‚Äúoverbroad court orders‚Äù that authorize IP address blocking. Since a single IP address can serve thousands of domains, disrupting pirates often means that many legitimate sites and services are blocked too, causing widespread collateral damage.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis practice results in the widespread and repeated disruption of tens of thousands of unrelated, legitimate websites, as well as the disruption of digital services, with no judicial opportunity for remedy,‚Äù Cloudflare writes.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese actions, designed to protect a narrow set of commercial interests, have caused significant collateral harm to businesses and users who are not the intended targets, without recourse or the possibility for affected parties to challenge the underlying order.‚Äù&lt;/p&gt;
    &lt;p&gt;The Spanish Government is aware of the problems, which Cloudflare says are at odds with international standards, but has chosen not to intervene in the issue. Therefore, it continues to present a significant trade barrier.&lt;/p&gt;
    &lt;head rend="h3"&gt;Italy&lt;/head&gt;
    &lt;p&gt;Cloudflare reports similar concerns in Italy, where the ‚ÄúPiracy Shield‚Äù site-blocking law has a direct effect on American companies. This blocking regulation requires network providers, including CDNs, to comply with blocking notices within 30 minutes.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe failure to include adequate safeguards against collateral damage has led to the inappropriate blocking of shared services of large cloud providers, which are disproportionately American businesses,‚Äù Cloudflare notes.&lt;/p&gt;
    &lt;p&gt;‚ÄúFor instance, the blocking of a Cloudflare IP address resulted in tens of thousands of non-targeted websites being blocked in February 2024. Furthermore, the blocking of the domain ‚Äúdrive.usercontent.google.com‚Äù in October denied Italian users access to Google Drive for over 12 hours.‚Äù&lt;/p&gt;
    &lt;p&gt;Efforts to expand Piracy Shield to public DNS resolvers and VPN services only make the problem worse, Cloudflare says, noting that some U.S. companies have already decided to leave the European country.&lt;/p&gt;
    &lt;p&gt;Automated piracy blocks are not the only reported trade barrier in Italy. Cloudflare also notes that the country allows rightsholders to ‚Äúabuse‚Äù the courts to disrupt U.S. businesses by granting ex parte blocking orders without giving the companies a chance to oppose them.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis coercive, penalty-based approach to removal of content, without adequate judicial review or due process protections, is a significant barrier to doing business in Italy,‚Äù Cloudflare writes.&lt;/p&gt;
    &lt;head rend="h3"&gt;France&lt;/head&gt;
    &lt;p&gt;In France, Cloudflare highlights Article L.333-10 of the Sports Code as a key problem. This has resulted in several pirate site blocking orders that go beyond regular Internet providers, requiring DNS resolvers and VPN services to take action as well.&lt;/p&gt;
    &lt;p&gt;Cloudflare notes that some services lack the technical capabilities to implement these orders and as a result, several U.S. companies have already left the country.&lt;/p&gt;
    &lt;p&gt;Recently, France passed a new anti-piracy bill that opens the door to automated IP-address blocking, similar to Italy‚Äôs Piracy Shield. This is a major concern for Cloudflare, which fears that this will only lead to more collateral damage.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt increases the risk of overblocking legitimate content or mistakenly targeting websites that operate lawfully, potentially disrupting cross-border digital services,‚Äù Cloudflare writes.&lt;/p&gt;
    &lt;head rend="h3"&gt;South Korea&lt;/head&gt;
    &lt;p&gt;South Korea has also created trade barriers due to its site-blocking measures, Cloudflare reports. A revision to the Network Act in 2023 now requires ‚ÄúCDNs to restrict access to illegal content‚Äù.&lt;/p&gt;
    &lt;p&gt;As a result, Cloudflare and other American companies are required to maintain detailed and regularly updated blocklists.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe South Korea Communication Commission (KCC) sends U.S. CDN providers a ‚Äòblock list‚Äô of over 1.5 million URLs (with 30,000 new additions monthly),‚Äù Cloudflare writes, noting that this places an ‚Äúunprecedented compliance burden‚Äù on companies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conflicting Demands at the U.S. Trade Office&lt;/head&gt;
    &lt;p&gt;Cloudflare urges the USTR to take these concerns into account for its upcoming National Trade Estimate Report. Ideally, it wants these trade barriers to be dismantled.&lt;/p&gt;
    &lt;p&gt;These calls run counter to requests from rightsholders, who urge the USTR to ensure that more foreign countries implement blocking measures. With potential site-blocking legislation being considered in U.S. Congress, that may impact local lobbying efforts as well.&lt;/p&gt;
    &lt;p&gt;If and how the USTR will address these concerns will become clearer early next year, when the 2026 National Trade Estimate Report is expected to be published.&lt;/p&gt;
    &lt;p&gt;‚Äî&lt;/p&gt;
    &lt;p&gt;A copy of Cloudflare‚Äôs submission for the USTR‚Äôs 2025 National Trade Estimate Report on Foreign Trade Barriers is available here (pdf)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://torrentfreak.com/cloudflare-tells-u-s-govt-that-foreign-site-blocking-efforts-are-digital-trade-barriers/"/><published>2025-11-06T13:41:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45835931</id><title>Auraphone: A simple app to collect people's info at events</title><updated>2025-11-06T20:40:18.269631+00:00</updated><content>&lt;doc fingerprint="f779845eca070a9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;auraphone: a simple app to collect people's info at events&lt;/head&gt;
    &lt;p&gt;Hi, I'm Andrew, and I'm building Auraphone, a simple app to collect people's info at events.&lt;/p&gt;
    &lt;p&gt;I've been a developer for many years and I thought I knew bluetooth well. I was an early employee of the scooter company Bird back in 2017 and wrote a lot of the ios and android bluetooth to "bird brain" logic. But I started a new bluetooth app that is a lot more complex. Imagine a room full of people at a big networking event. Every phone broadcasts a bluetooth service and every phone tries and connects, all at the same time! I'm building this app to bring networking events into the year 2026! We all have bluetooth phones with us, lets use them to solve this who is going to give who their phone number issue. Here is what it does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You set your name, photo, and what info you want to share. Maybe just your instagram username, maybe your email and linked in too, your choice what to broadcast.&lt;/item&gt;
      &lt;item&gt;Walk around your networking event and collect all this info from people you are in close range to.&lt;/item&gt;
      &lt;item&gt;Have a record of everyone you actually meet IRL at this event.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Here is a video demo:&lt;/head&gt;
    &lt;p&gt;Think of the term "peripheral" as server and "central" as client. Yes there are differences in bluetooth and there are reasons for those terms, but my life got much easier working on this app when I started just thinking client server. So in a room with just two phones, which one is which? It can't be a coin toss. If 50% of the time both phones act as the server and neither client, bad. Or if both phones act as clients, bad. So how do you break the tie? You start up your server AND you act as a client looking for servers to connect to. Just be careful not to connect to yourself!&lt;/p&gt;
    &lt;p&gt;With bluetooth your server advertises and when you connect it tells you what characteristics it has. Think of characteristics as "endpoints". They are not the same as an http endpoints at all but again my life got easier when I started thinking of them like this. Our app has two characteristics PROFILE_CHAR and PHOTO_CHAR and step one is a client hits PROFILE_CHAR endpoint and gets back json from the other phone with device_id, first_name, photo_hash, instagram and it doesn't have to be json. It could be Protocol Buffers and binary but again, I went with json and yes, easier life.&lt;/p&gt;
    &lt;p&gt;So with my 200 OK from PROFILE_CHAR endpoint I look at the photo_hash which is a 256 sha from the binary data of the image the user picked. If I have this file already cached, I'm good and I disconnect from this server. If not I hit the PHOTO_CHAR endpoint and get this image data and save as hash.jpg locally. And then I disconnect.&lt;/p&gt;
    &lt;p&gt;After I disconnect from a server I place that specific bluetooth server id on a cooldown list. I have other phones in the room I need to connect with! And all this time I'm also acting as a server myself. Well, sometimes. Sometimes when I'm busy being a client getting a photo I'll pause my server actions. And it depends on ios vs android. There is lots of complexity in the BLE (bluetooth low energy) stack. This loop of find a server, connect, get my info, disconnect, repeat is a great little loop. But there are limits and GATT errors and queue buffers that get full and MTU (max transmission unit) that can make it so two phones right next to each other take a while before they finally find each other.&lt;/p&gt;
    &lt;p&gt;So I made github.com/andrewarrow/auraphone-blue which is a BLE stack simulator all written in golang. If you look at the wire package you'll see a pretty complete BLE implementation using the file system and domain sockets to mock the bluetooth radio. The swift package and kotlin package should look very familiar to anyone who has worked on ios or android BLE.&lt;/p&gt;
    &lt;p&gt;My plan was to run many mock phones this way and test all the weird BLE differences between ios and android here. It did not work. The only thing this golang auraphone-blue repo did for me was really help me understand how bluetooth works. This BLE stack that I made in golang doesn't help me fix ios and android bugs, it only introduces its own subtle golang filesystem ble bugs!&lt;/p&gt;
    &lt;p&gt;In the end nothing fixed all the bugs better than just running two real ios phones and two real android phones and having them write to disk very thorough logs PLUS ble specific json files showing exactly what each operation was doing and what info it got back. I ended up writing logic to zip up the entire local directory of the phone with all these files and logs and doing an HTTP POST to my local mac just to get all the data off all 4 phones quickly after each run.&lt;/p&gt;
    &lt;p&gt;Now it's not like this app will keep running when you have your phone in your pocket. iOS has rules on bluetooth connections and it's basically only if your app is running and foreground. So the way I see auraphone working at an event, you walk around and mingle as normal but yeah every one has their phone out and running the app but ONLY this app. You are still present and in the conversation not just looking at other distractions from your phone.&lt;/p&gt;
    &lt;p&gt;But now effortlessly after your conversation is done and you move around the room, you have a record of who that person was! Also the list is sorted by last updated_at desc so whoever you are near will be at the top. Great for when you have met someone earlier that night but forget their name. Now you just look down at your auraphone app that's already out and running and say oh hey jessie!&lt;/p&gt;
    &lt;p&gt;The app is in the ios app store. For android we serve up the apk at auraphone.apk. We are testing it now at BLANKSPACES Culver City. Looking to try it now in a room full of people! Give me reports of did your phones see each other? Did the contact info sync? Did it solve a problem for you?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andrewarrow.dev/2025/11/simple-app-collect-peoples-info-at-events/"/><published>2025-11-06T14:54:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45836070</id><title>Kimi K2 Thinking, a SOTA open-source trillion-parameter reasoning model</title><updated>2025-11-06T20:40:18.202221+00:00</updated><link href="https://moonshotai.github.io/Kimi-K2/thinking.html"/><published>2025-11-06T15:06:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45836466</id><title>Supply chain attacks are exploiting our assumptions</title><updated>2025-11-06T20:40:17.882119+00:00</updated><content>&lt;doc fingerprint="ad40041988733720"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Supply chain attacks are exploiting our assumptions&lt;/head&gt;
    &lt;p&gt;Every time you run &lt;code&gt;cargo add&lt;/code&gt; or &lt;code&gt;pip install&lt;/code&gt;, you are taking a leap of faith. You trust that the code you are downloading contains what you expect, comes from who you expect, and does what you expect. These expectations are so fundamental to modern development that we rarely think about them. However, attackers are systematically exploiting each of these assumptions.&lt;/p&gt;
    &lt;p&gt;In 2024 alone, PyPI and npm removed thousands of malicious packages; multiple high-profile projects had malware injected directly into the build process; and the XZ Utils backdoor nearly made it into millions of Linux systems worldwide.&lt;/p&gt;
    &lt;p&gt;Dependency scanning only catches known vulnerabilities. It won‚Äôt catch when a typosquatted package steals your credentials, when a compromised maintainer publishes malware, or when attackers poison the build pipeline itself. These attacks succeed because they exploit the very trust that makes modern software development possible.&lt;/p&gt;
    &lt;p&gt;This post breaks down the trust assumptions that make the software supply chain vulnerable, analyzes recent attacks that exploit them, and highlights some of the cutting-edge defenses being built across ecosystems to turn implicit trust into explicit, verifiable guarantees.&lt;/p&gt;
    &lt;head rend="h2"&gt;Implicit trust&lt;/head&gt;
    &lt;p&gt;For many developers, the software supply chain begins and ends with the software bill of materials (SBOM) and dependency scanning, which together answer two fundamental questions: what code do you have, and does it contain known vulnerabilities? But understanding what you have is the bare minimum. As sophisticated attacks become more common, you also need to understand where your code comes from and how it gets to you.&lt;/p&gt;
    &lt;p&gt;You trust that you are installing the package you expect. You assume that running &lt;code&gt;cargo add rustdecimal&lt;/code&gt; is safe because &lt;code&gt;rustdecimal&lt;/code&gt; is a well-known and widely used library. Or wait, maybe it‚Äôs spelled &lt;code&gt;rust_decimal&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;You trust that packages are published by the package maintainers. When a popular package starts shipping with a precompiled binary to save build time, you may decide to trust the package author. However, many registries lack strong verification that publishers are who they claim to be.&lt;/p&gt;
    &lt;p&gt;You trust that packages are built from the package source code. You may work on a security-conscious team that audits code changes in the public repository before upgrading dependencies. But this is meaningless if the distributed package was built from code that does not appear in the repository.&lt;/p&gt;
    &lt;p&gt;You trust the maintainers themselves. Ultimately, installing third-party code means trusting package maintainers. It is not practical to audit every line of code you depend on. We assume that the maintainers of well-established and widely adopted packages will not suddenly decide to add malicious code.&lt;/p&gt;
    &lt;p&gt;These assumptions extend beyond traditional package managers. The same trust exists when you run a GitHub action, install a tool with Homebrew, or execute the convenient &lt;code&gt;curl ... | bash&lt;/code&gt; installation script. Understanding these implicit trust relationships is the first step in assessing and mitigating supply chain risk.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recent attacks&lt;/head&gt;
    &lt;p&gt;Attackers are exploiting trust assumptions across every layer of the supply chain. Recent incidents range from simple typosquatting to multiyear campaigns, demonstrating how attackers‚Äô tactics are evolving and growing more complex.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deceptive doubles&lt;/head&gt;
    &lt;p&gt;Typosquatting involves publishing a malicious package with a name similar to that of a legitimate package. Running &lt;code&gt;cargo add rustdecimal&lt;/code&gt; instead of &lt;code&gt;rust_decimal&lt;/code&gt; could install malware instead of the expected legitimate library. This exact attack occurred on crates.io in 2022. The malicious &lt;code&gt;rustdecimal&lt;/code&gt; mimicked the popular &lt;code&gt;rust_decimal&lt;/code&gt; package but contained a &lt;code&gt;Decimal::new&lt;/code&gt; function that executed a malicious binary when called.&lt;/p&gt;
    &lt;p&gt;The simplicity of the attack has made it easy for attackers to launch numerous large-scale campaigns, particularly against PyPI and npm. Since 2022, there have been multiple typosquatting campaigns targeting packages that account for a combined 1.2 billion weekly downloads. Thousands of malicious packages have been published to PyPI and npm alone. This type of attack happens so frequently that there are too many examples to list here. In 2023, researchers documented a campaign that registered 900 typosquats of 40 popular PyPI packages and discovered malware being staged on crates.io. The attacks have only intensified, with 500 malicious packages published in a single 2024 campaign.&lt;/p&gt;
    &lt;p&gt;Dependency confusion takes a different approach, exploiting package manager logic directly. Security researcher Alex Birsan demonstrated and named this type of attack in 2021. He discovered that many organizations use names for internal packages that are either leaked or guessable. By publishing packages with the same names as these internal packages to public registries, Birsan was able to trick package managers into downloading his version instead. Birsan‚Äôs proof of concept identified vulnerabilities across three programming languages and 35 organizations, including Shopify, Apple, Netflix, Uber, and Yelp.&lt;/p&gt;
    &lt;p&gt;In 2022, an attacker used this technique to include malicious code in the nightly releases of PyTorch for five days. An internal dependency named &lt;code&gt;torchtriton&lt;/code&gt; was hosted from PyTorch‚Äôs nightly package index. An attacker published a malicious package with the same name to PyPI, which took precedence. As a result, the nightly versions of PyTorch contained malware for five days before the malware was caught.&lt;/p&gt;
    &lt;p&gt;While these attacks occur at the point of installation, other attacks take a more direct approach by compromising the publishing process itself.&lt;/p&gt;
    &lt;head rend="h3"&gt;Stolen secrets&lt;/head&gt;
    &lt;p&gt;Compromised accounts are another frequent attack vector. Attackers acquire a leaked key, stolen token, or guessed password, and are able to directly publish malicious code on behalf of a trusted entity. A few recent incidents show the scale of this type of attack:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ctrl/tinycolor (September 2025): Self-propagating malware harvested npm API credentials and used the credentials to publish additional malicious packages. Over 40 packages were compromised, accounting for more than 2 million weekly downloads.&lt;/item&gt;
      &lt;item&gt;Nx (August 2025): A compromised token allowed attackers to publish malicious versions containing scripts leveraging already installed AI CLI tools (Claude, Gemini, Q) for reconnaissance, stealing cryptocurrency wallets, GitHub/npm tokens, and SSH keys from thousands of developers before exfiltrating data to public GitHub repositories.&lt;/item&gt;
      &lt;item&gt;rand-user-agent (May 2025): A malicious release containing malware was caught only after researchers noticed recent releases despite no changes to the source code in months.&lt;/item&gt;
      &lt;item&gt;rspack (December 2024): Stolen npm tokens enabled attackers to publish cryptocurrency miners in packages with 500,000 combined weekly downloads.&lt;/item&gt;
      &lt;item&gt;UAParser.js (October 2021): A compromised npm token was used to publish malicious releases containing a cryptocurrency miner. The library had millions of weekly downloads at the time of the attack.&lt;/item&gt;
      &lt;item&gt;PHP Git server (March 2021): Stolen credentials allowed attackers to inject a backdoor directly into PHP‚Äôs source code. Thankfully, the content of the changes was easily spotted and removed by the PHP team before any release.&lt;/item&gt;
      &lt;item&gt;Codecov (January 2021): Attackers found a deployment key in a public Docker image layer and used it to modify Codecov‚Äôs Bash Uploader tool, silently exfiltrating environment variables and API keys for months before discovery.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stolen secrets remain one of the most reliable supply chain attack vectors. But as organizations implement stronger authentication and better secret management, attackers are shifting from stealing keys to compromising the systems that use them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Poisoned pipelines&lt;/head&gt;
    &lt;p&gt;Instead of stealing credentials, some attackers have managed to distribute malware through legitimate channels by compromising the build and distribution systems themselves. Code reviews and other security checks are bypassed entirely by directly injecting malicious code into CI/CD pipelines.&lt;/p&gt;
    &lt;p&gt;The SolarWinds attack in 2020 is one of the well-known attacks in this category. Attackers compromised the build environment and inserted malicious code directly into the Orion software during compilation. The malicious version of Orion was then signed and distributed through SolarWinds‚Äô legitimate update channels. The attack affected thousands of organizations including multiple Fortune 500 companies and government agencies.&lt;/p&gt;
    &lt;p&gt;More recently, in late 2024, an attacker compromised the Ultralytics build pipeline to publish multiple malicious versions. The attacker used a template injection in the project‚Äôs GitHub Actions to gain access to the CI/CD pipeline and poisoned the GitHub Actions cache to include malicious code directly in the build. At the time of the attack, Ultralytics had more than one million weekly downloads.&lt;/p&gt;
    &lt;p&gt;In 2025, an attacker modified the &lt;code&gt;reviewdog/actions-setup&lt;/code&gt; GitHub action v1 tag to point to a malicious version containing code to dump secrets. This likely led to the compromise of another popular action, &lt;code&gt;tj-actions/changed-files&lt;/code&gt;, through its dependency on &lt;code&gt;tj-actions/eslint-changed-files&lt;/code&gt;, which in turn relied on the compromised &lt;code&gt;reviewdog&lt;/code&gt; action. This cascading compromise affected thousands of projects using the &lt;code&gt;changed-files&lt;/code&gt; action.&lt;/p&gt;
    &lt;p&gt;While poisoned pipeline attacks are relatively rare compared to typosquatting or credential theft, they represent an escalation in attacker sophistication. As stronger defenses are put in place, attackers are forced to move up the supply chain. The most determined attackers are willing to spend years preparing for a single attack.&lt;/p&gt;
    &lt;head rend="h3"&gt;Malicious maintainers&lt;/head&gt;
    &lt;p&gt;The XZ Utils backdoor, discovered in March 2024, nearly compromised millions of Linux systems worldwide. The attacker spent over two years making legitimate contributions to the project before gaining maintainer access. They then abused this trust to insert a sophisticated backdoor through a series of seemingly innocent commits that would have granted remote access to any system using the compromised version.&lt;/p&gt;
    &lt;p&gt;Ultimately, you must trust the maintainers of your dependencies. Secure build pipelines cannot protect against a trusted maintainer who decides to insert malicious code. With open-source maintainers increasingly overwhelmed, and with AI tools making it easier to generate convincing contributions at scale, this trust model is facing unprecedented challenges.&lt;/p&gt;
    &lt;head rend="h2"&gt;New defenses&lt;/head&gt;
    &lt;p&gt;As attacks grow more sophisticated, defenders are building tools to match. These new approaches are making trust assumptions explicit and verifiable rather than implicit and exploitable. Each addresses a different layer of the supply chain where attackers have found success.&lt;/p&gt;
    &lt;head rend="h3"&gt;TypoGard and Typomania&lt;/head&gt;
    &lt;p&gt;Most package managers now include some form of typosquatting protection, but they typically use traditional similarity checks like those measuring Levenshtein distance, which generate excessive false positives that need to be manually reviewed.&lt;/p&gt;
    &lt;p&gt;TypoGard fills this gap by using multiple context-aware metrics, like the following, to detect typosquatting packages with a low false positive rate and minimal overhead:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Repeated characters (e.g., &lt;code&gt;rustdeciimal&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Common typos based on keyboard layout&lt;/item&gt;
      &lt;item&gt;Swapped characters (e.g., &lt;code&gt;reqeusts&lt;/code&gt;instead of&lt;code&gt;requests&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Package popularity thresholds to focus on high-risk targets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This tool targets npm, but the concepts can be extended to other languages. The Rust Foundation published a Rust port, Typomania, that has been adopted by crates.io and has successfully caught multiple malicious packages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Zizmor&lt;/head&gt;
    &lt;p&gt;Zizmor is a static analysis tool for GitHub Actions. Actions have a large surface area, and writing complex workflows can be difficult and error-prone. There are many subtle ways workflows can introduce vulnerabilities.&lt;/p&gt;
    &lt;p&gt;For example, Ultralytics was compromised via template injection in one of its workflows.&lt;/p&gt;
    &lt;p&gt;Workflows triggered by &lt;code&gt;pull_request_target&lt;/code&gt; events run with write permission access to repository secrets. An attacker opened a pull request from a branch with a malicious name. When the workflow ran, the &lt;code&gt;github.head_ref&lt;/code&gt; variable expanded to the malicious branch name and executed as part of the run command with the workflow‚Äôs elevated privileges.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;reviewdog/actions-setup&lt;/code&gt; attack was also carried out in part by changing the action‚Äôs v1 tag to point to a malicious commit. Anyone using &lt;code&gt;reviewdog/actions-setup@v1&lt;/code&gt; in their workflows silently started getting a malicious version without making any changes to their own workflows.&lt;/p&gt;
    &lt;p&gt;Zizmor flags all of the above. It includes a dangerous-trigger rule to flag workflows triggered by &lt;code&gt;pull_request_target&lt;/code&gt;, a template-injection rule, and an unpinned-uses check that would have warned actions against using mutable references (like tags or branch names) when using &lt;code&gt;reviewdog/actions-setup@v1&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;PyPI Trusted Publishing and attestations&lt;/head&gt;
    &lt;p&gt;PyPI has taken significant steps to address several implicit trust assumptions through two complementary features: Trusted Publishing and attestations.&lt;/p&gt;
    &lt;p&gt;Trail of Bits worked with PyPI on Trusted Publishing1, which eliminates the need for long-lived API tokens. Instead of storing secrets that can be stolen, developers configure a trust relationship once: ‚Äúthis GitHub repository and workflow can publish this package.‚Äù When the workflow runs, GitHub sends a short-lived OIDC token to PyPI with claims about the repository and workflow. PyPI verifies this token was signed by GitHub‚Äôs key and responds with a short-lived PyPI token, which the workflow can use to publish the package. Using automatically generated, minimally scoped, short-lived tokens vastly reduces the risk of compromise.&lt;/p&gt;
    &lt;p&gt;Without long-lived and over-privileged API tokens, attackers must instead compromise the publishing GitHub workflow itself. While the Ultralytics attack demonstrated that CI/CD pipeline compromise is still a real threat, eliminating the need for users to manually manage credentials removes a source of user error and further reduces the attack surface.&lt;/p&gt;
    &lt;p&gt;Building on this foundation, Trail of Bits worked with PyPI again to introduce index-hosted digital attestations in late 2024 through PEP 740. Attestations cryptographically bind each published package to its build provenance using Sigstore. Packages using the PyPI publish GitHub action automatically include attestations, which act as a verifiable record of exactly where, when, and how the package was built.&lt;/p&gt;
    &lt;p&gt;Over 30,000 packages use Trusted Publishing, and ‚ÄúAre We PEP 740 Yet?‚Äù tracks attestation adoption among the most popular packages (86 of the top 360 at the time of writing). The final piece, automatic client side verification, remains a work in progress. Client tools like pip and uv do not yet verify attestations automatically. Until then, attestations provide transparency and auditability but not active protection during package installation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Homebrew build provenance&lt;/head&gt;
    &lt;p&gt;The implicit trust assumptions extend beyond programming languages and libraries. When you run &lt;code&gt;brew install&lt;/code&gt; to install a binary package (or, a bottle), you are trusting that the bottle you‚Äôre downloading was built by Homebrew‚Äôs official CI from the expected source code and that it was not uploaded by an attacker who found a way to compromise Homebrew‚Äôs bottle hosting or otherwise tamper with the bottle‚Äôs content.&lt;/p&gt;
    &lt;p&gt;Trail of Bits, in collaboration with Alpha-Omega and OpenSSF, helped to add build provenance to Homebrew using GitHub‚Äôs attestations. Every bottle built by Homebrew now comes with cryptographic proof linking it to the specific GitHub Actions workflow that created it. This makes it significantly harder for a compromised maintainer to silently replace bottles with malicious versions.&lt;/p&gt;
    &lt;p&gt;Each attestation includes the Git commit, the workflow that ran, and other build-time metadata. This transforms the trust assumption (‚ÄúI trust this bottle was built from the source I expect‚Äù) into a verifiable fact.&lt;/p&gt;
    &lt;p&gt;The implementation of attestations handled historical bottles through a ‚Äúbackfilling‚Äù process, creating attestations for packages built before the system was in place. As a result, all official Homebrew packages include attestations.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;brew verify&lt;/code&gt; command makes it straightforward to check provenance, though the feature is still in beta and verification isn‚Äôt automatic by default. There are plans to eventually extend this feature to third-party repositories, bringing the same security guarantees to the broader Homebrew ecosystem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Go Capslock&lt;/head&gt;
    &lt;p&gt;Capslock is a tool that statically identifies the capabilities of a Go program, including the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Filesystem operations (reading, writing, deleting files)&lt;/item&gt;
      &lt;item&gt;Network connections (outbound requests, listening on ports)&lt;/item&gt;
      &lt;item&gt;Process execution (spawning subprocesses)&lt;/item&gt;
      &lt;item&gt;Environment variable access&lt;/item&gt;
      &lt;item&gt;System call usage&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This approach represents a shift in supply chain security. Rather than focusing on who wrote the code or where it came from, capability analysis examines what the code can actually do. A JSON parsing library that unexpectedly gains network access raises immediate red flags, regardless of whether the change came from a compromised supply chain or directly from a maintainer.&lt;/p&gt;
    &lt;p&gt;In practice, static capability detection can be difficult. Language features like runtime reflection and unsafe operations make it impossible to statically detect capabilities entirely accurately. Despite the limitations, capability detection provides a critical safety net as part of a layered defense against supply chain attacks.&lt;/p&gt;
    &lt;p&gt;Capslock pioneered this approach for Go, and the concept is ripe for adoption across other languages. As supply chain attacks grow more sophisticated, capability analysis offers a promising path forward. Verify what code can do, not just where it comes from.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where we go from here&lt;/head&gt;
    &lt;p&gt;Supply chain attacks are not slowing down. If anything, they are becoming more automated, more complex, and more sophisticated in order to target broader audiences. Typosquatting campaigns are targeting packages with billions of downloads, publisher tokens and CI/CD pipelines are being compromised to poison software at the source, and patient attackers are spending years building reputation before striking.&lt;/p&gt;
    &lt;p&gt;The implicit trust that enabled software ecosystems to scale is being weaponized against us. Understanding your trust assumptions is the first step. Ask yourself these questions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Does my ecosystem block typosquatting packages?&lt;/item&gt;
      &lt;item&gt;How does it protect against compromised publisher tokens?&lt;/item&gt;
      &lt;item&gt;Can I verify build provenance?&lt;/item&gt;
      &lt;item&gt;Do I know what capabilities my dependencies have?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some ecosystems have started building defenses. Know what tools are available and start using them today. Use Trusted Publishing when publishing to PyPI or to crates.io. Check your GitHub Actions with Zizmor. Use It-Depends and Deptective to understand what software actually depends on. Verify attestations where feasible. Use Capslock to see the capabilities of Go packages, and more importantly, be aware when new capabilities are introduced.&lt;/p&gt;
    &lt;p&gt;But no ecosystem is completely covered. Push for better defaults where tools are lacking. Every verified attestation, every package caught typosquatting, and every flagged vulnerable GitHub action makes the entire industry more resilient. We cannot completely eliminate trust from supply chains, but we can strive to make that trust explicit, verifiable, and revocable.&lt;/p&gt;
    &lt;p&gt;If you need help understanding your supply chain trust assumptions, contact us.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The crates.io team released Trusted Publishing for Rust crates in July. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.trailofbits.com/2025/09/24/supply-chain-attacks-are-exploiting-our-assumptions/"/><published>2025-11-06T15:46:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45836826</id><title>FBI tries to unmask owner of archive.is</title><updated>2025-11-06T20:40:16.794069+00:00</updated><content>&lt;doc fingerprint="3f820317679167cd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Archive.today: FBI Demands Data from Provider Tucows&lt;/head&gt;
    &lt;p&gt;The mysterious website Archive.today is coming under the FBI's crosshairs. A court order is forcing the provider Tucows to hand over user data.&lt;/p&gt;
    &lt;p&gt;It is one of the most mysterious and, at the same time, best-known websites on the internet. Archive.today has built up a user base over a period of more than ten years who use the service to access previous snapshots of a web page. So basically like the Wayback Machine of the Internet Archive, only largely free of rules and presumably therefore also anonymous. To the chagrin of the media industry, the service is also often used to bypass paywalls. This is also possible because the service does not adhere to common rules and laws and offers no opt-out option.&lt;/p&gt;
    &lt;p&gt;And so far, the operators have gotten away with it. Although there have been minor problems in the history of the service occasionally, for example, a top-level domain operator denied them further use of one of the many archive domains. However, the operation of the project, which is allegedly financed by donations and own funds, was not seriously endangered.&lt;/p&gt;
    &lt;head rend="h3"&gt;Court Order in the USA&lt;/head&gt;
    &lt;p&gt;But now the operators of archive.today are apparently fearing bigger trouble. In recent months and years, they had become noticeably quieter. Until two years ago, for example, questions were regularly answered in the blog. In the official X account, which had been silent for over a year, a new post appeared at the end of October new post. ‚ÄúCanary,‚Äù it said there, along with a URL. The mentioned canary bird is likely an allusion to an old custom in mining. A canary brought along warned the miners when it keeled over dead about the threat of invisible gas.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;p&gt;The deadly danger that the site operators fear is apparently linked to the PDF linked in the X post linked PDF. It contains a court order that the US investigative authority FBI has obtained. It instructs the Canadian provider Tucows to hand over comprehensive data about the customer behind archive.today. It concerns address and connection data as well as payment information. If Tucows does not provide the data, penalties are threatened. Whether the court order is genuine and how the operators of the site obtained it could not be verified so far.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is the operator based in Russia?&lt;/head&gt;
    &lt;p&gt;Why the FBI is currently interested in archive.today, which is also accessible under the domains archive.is and archive.ph, is not evident from the court order. However, there are several obvious starting points for investigations: in addition to the obvious reason of copyright issues, the investigators could also be pursuing suspicions about unclear financing, the origin of the operators, or the technical approach.&lt;/p&gt;
    &lt;p&gt;In 2023, Finnish blogger Janni Patokallio compiled various clues and research results in a post in a post. According to this, Archive.today uses a botnet with changing IP addresses to circumvent anti-scraping measures. There are also indications that the operator(s) are based in Russia. Another private investigation from 2024 comes to a different conclusion. It names a software developer from New York as the alleged operator. According to this investigation, following the trail to Eastern Europe proved to be a red herring.&lt;/p&gt;
    &lt;p&gt;(mki)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html"/><published>2025-11-06T16:18:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45837067</id><title>Show HN: Dynamic code and feedback walkthroughs with your coding Agent in VSCode</title><updated>2025-11-06T20:40:16.461211+00:00</updated><content>&lt;doc fingerprint="ff0e141af947c6bf"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;üëáüèº Show &amp;gt; Tell üëâüèª&lt;/head&gt;
    &lt;p&gt;üëãüèΩ HN,&lt;/p&gt;
    &lt;p&gt;It‚Äôs always been a challenge for me to maintain a mental model of the product.&lt;/p&gt;
    &lt;p&gt;AI and agentic development is accelerating the problem of maintaining a systems model that allows us to make good design decisions. The more code we create, the more we need to review and learn.&lt;/p&gt;
    &lt;p&gt;The long poles in the software development lifecycle that have a lot of room for improvement are comprehension &amp;amp; alignment.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;How does it work now?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How should it work?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Where should we go next?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How do we get there?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I think it‚Äôs becoming abundantly clear that commoditizing coding is not commoditizing software development.&lt;/p&gt;
    &lt;p&gt;Stepping aside to speak to my own interests ‚Äî&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I don‚Äôt want to lose touch with how it works. I feel a lot of builders love solving the puzzles. When I say that, I‚Äôm not talking about writing code, I‚Äôm talking about shaping the solution, testing the solution, and improving it.&lt;/p&gt;
      &lt;p&gt;The loop of shaping the product is my joy.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In the end, we can all benefit with a hand making code more accessible ‚Äî whether it‚Äôs the code you forgot you wrote last week, your colleagues PR, an open source repo or the Agent who just built something while you got coffee.&lt;/p&gt;
    &lt;p&gt;My solution is called Intraview.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a VS Code extension (Yes, forks like Cursor too) that works with your existing Agent (Claude, GPT5-codex) via a local MCP to build visual tours. The tours can act as guided feedback sessions, as well, where you can review some work by an Agent or a PR with added context by the Agent on how things work. It‚Äôs secure-by-design, with the only external calls being some basic anonymous usage telemetry to Azure logging to help me understand what features to prioritize.&lt;/p&gt;
    &lt;p&gt;Nevertheless, it‚Äôs better to show than tell.&lt;/p&gt;
    &lt;p&gt;I created a walkthrough where I show how I pull down an Open Source repo (Plotly JS), install Intraview, create a code Tour to get me started with learning how to build a new visualization.&lt;/p&gt;
    &lt;p&gt;I also show how the tool helps with giving agents feedback.&lt;/p&gt;
    &lt;p&gt;It‚Äôs not a polished marketing video, there is no flashy hook, I assume you‚Äôve read this and I don‚Äôt lead with why. It‚Äôs pretty raw outside of some speed-ups to spare you from my bad decision to choose a Repo that‚Äôs 1.5GB.&lt;/p&gt;
    &lt;p&gt;The scene opens as all great stories with a Terminal and a GitHub page.&lt;/p&gt;
    &lt;p&gt;I‚Äôm grateful that you‚Äôve come this far to engage with this work and hope you‚Äôll take the next step to help me shape it.&lt;/p&gt;
    &lt;p&gt;Let me help you build and enjoy it a little more than you did yesterday.&lt;/p&gt;
    &lt;p&gt;Enjoy and, please, tell me what you think on HackerNews.&lt;/p&gt;
    &lt;p&gt;‚Äî Cy&lt;/p&gt;
    &lt;p&gt;If you‚Äôre interested in following my progress, find me on LinkedIn (I don‚Äôt use any other networks).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.intraview.ai/hn-demo"/><published>2025-11-06T16:35:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45837342</id><title>ICC ditches Microsoft 365 for openDesk</title><updated>2025-11-06T20:40:15.891835+00:00</updated><content>&lt;doc fingerprint="edbd58ff46c91d73"&gt;
  &lt;main&gt;
    &lt;p&gt;Het Internationaal Strafhof (International Criminal Court, ICC) ruilt Microsoft 365 in voor Open Desk, een Europees open source alternatief. Dat schrijft de Duitse krant Handelsblatt. De krant verwacht dat het ICC met de overstap mogelijk een trend start binnen de Europese publieke sector.&lt;/p&gt;
    &lt;head rend="h1"&gt;Internationaal Strafhof neemt afscheid van Microsoft 365&lt;/head&gt;
    &lt;p&gt;Het ICC stapt over naar Open Desk, een Europese opensource kantooromgeving&lt;/p&gt;
    &lt;p&gt;Microsoft bevestigt de breuk aan de nieuwssite Euractiv. ‚ÄòWij hechten waarde aan onze relatie met het ICC als klant en zijn ervan overtuigd dat niets ons vermogen in de weg staat om in de toekomst diensten aan het ICC te blijven leveren,‚Äô zegt een woordvoerder van Microsoft.&lt;/p&gt;
    &lt;head rend="h2"&gt;Digitale afhankelijkheid&lt;/head&gt;
    &lt;p&gt;Bij Europese overheden leven al langer zorgen over de digitale afhankelijkheid van Amerikaanse bedrijven. Die zorgen zijn sterk toegenomen sinds Donald Trump voor de tweede maal president van de Verenigde Staten werd.&lt;/p&gt;
    &lt;p&gt;Voor het ICC zijn de zorgen minder hypothetisch dan voor veel andere instituten: Trump heeft zijn ongenoegen met het Strafhof vaak laten blijken en liet sancties opstellen tegen de hoofdaanklager, Karim Khan. Persbureau AP meldde in mei 2025 dat Khan geen toegang meer had tot zijn Outlook e-mail. Microsoft bevestigde dat Khan was ‚Äòlosgekoppeld‚Äô van Microsoft-diensten, maar benadrukte tegelijkertijd dat het de dienstverlening aan de ICC-organisatie ‚Äògeen moment‚Äô heeft stopgezet.&lt;/p&gt;
    &lt;head rend="h2"&gt;EDIC&lt;/head&gt;
    &lt;p&gt;Hoe dan ook zit de angst er bij het ICC goed in. De organisatie gaat gebruikmaken van Open Desk, dat is ontwikkeld door het Zentrum Digitale Souver√§nit√§t (Zendis) in opdracht van het Duitse Federale ministerie van Binnenlandse Zaken. Zendis maakt onderdeel uit van het Digital Commons European Digital Infrastructure Consortium (DC-EDIC), het Europese consortium waarmee de EU strijdt voor meer digitale autonomie.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mijn bureau&lt;/head&gt;
    &lt;p&gt;Ook Nederlandse ambtenaren krijgen in de toekomst mogelijk te maken met de software van Open Desk. Onder de noemer Mijn Bureau experimenteert de Nederlandse overheid met een suite met verschillende Europese open source samenwerkingssoftware. Open Desk wordt binnen Mijn Bureau onder meer gebruikt voor e-mail. Mijn Bureau is een samenwerking van de Rijksoverheid, Gemeente Amsterdam en de VNG.&lt;/p&gt;
    &lt;p&gt;In een vandaag verschenen position paper pleit de VNG voor meer regie op technologie. Er wordt steeds meer toegewerkt naar verregaande samenwerking op het gebied van digitalisering. ln de Nederlandse Digitaliseringsstrategie (NDS) is het versterken van digitale weerbaarheid en autonomie √©√©n van de prioriteiten.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.binnenlandsbestuur.nl/digitaal/internationaal-strafhof-neemt-afscheid-van-microsoft-365"/><published>2025-11-06T16:57:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45837364</id><title>Senior BizOps at Artie (San Francisco)</title><updated>2025-11-06T20:40:15.354172+00:00</updated><content>&lt;doc fingerprint="e0b240d575995fac"&gt;
  &lt;main&gt;
    &lt;p&gt;Software that streams data from databases to warehouses in real-time&lt;/p&gt;
    &lt;p&gt;Artie is a fully-managed CDC streaming platform - we replicate production databases into warehouses in real time with zero maintenance. Teams use us for fraud/risk monitoring, live inventory, customer-facing analytics, and ML pipelines.&lt;/p&gt;
    &lt;p&gt;We‚Äôre trusted by 30+ customers including Substack, Alloy, and Wasserman - and just raised our Series A led by Standard Capital, building on our seed round backed by YC and General Catalyst.&lt;/p&gt;
    &lt;p&gt;We‚Äôre hiring a Senior Business Operations to help shape Artie‚Äôs next chapter of growth. This is one of the most high-leverage roles at the company - you‚Äôll sit at the intersection of product, GTM, and operations, and work directly with the founders on the questions that matter most.&lt;/p&gt;
    &lt;p&gt;As an early member of BizOps, you won‚Äôt just analyze problems. You‚Äôll own them end-to-end. You‚Äôll spot opportunities before others see them, turn signal from data into direction, and build the systems and processes that enable Artie to scale with speed and precision. If you get energy from ambiguity, love turning messy into simple, and want meaningful ownership in a company that‚Äôs growing fast - this is that role.&lt;/p&gt;
    &lt;p&gt;Be a Builder: Shape the BizOps foundation of the company as an early member.&lt;/p&gt;
    &lt;p&gt;Be an Owner: Lead high-impact product and business initiatives end-to-end.&lt;/p&gt;
    &lt;p&gt;Go Deep and Broad: Operate across product strategy, data analytics, GTM, and operations.&lt;/p&gt;
    &lt;p&gt;Partner with Founders: Work directly with the CEO and CTO on the problems that matter most.&lt;/p&gt;
    &lt;p&gt;We are building Artie, a real-time data streaming solution focused on databases and data warehouses. Typical ETL solutions leverage batched processes or schedulers (DAGs, Airflow), which cannot achieve real time data syncs. We leverage change data capture (CDC) and stream processing to perform data transfers in a more efficient way, which enables sub-minute latency.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/artie/jobs/gqANVBc-senior-business-operations"/><published>2025-11-06T17:00:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45837425</id><title>The Parallel Search API</title><updated>2025-11-06T20:40:14.522166+00:00</updated><content>&lt;doc fingerprint="19437a9227bb0e96"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;# Introducing Parallel Search: the highest accuracy web search API engineered for AI&lt;/head&gt;
    &lt;p&gt;Web search, built from the ground up for AI&lt;/p&gt;
    &lt;p&gt;A second user has arrived on the web: AI. And it needs fundamentally different infrastructure than humans do.&lt;/p&gt;
    &lt;p&gt;The Parallel Search API, built on our proprietary web index, is now generally available. It's the only web search tool designed from the ground up for AI agents: engineered to deliver the most relevant, token-efficient web data at the lowest cost. The result is more accurate answers, fewer round-trips, and lower costs for every agent.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Human search and AI search solve different problems**&lt;/head&gt;
    &lt;p&gt;Traditional search engines were built for humans. They rank URLs, assuming someone will click through and navigate to a page. The search engine's job ends at the link. The system optimizes for keywords searches, click-through rates, and page layouts designed for browsing - done in milliseconds and as cheaply as possible.&lt;/p&gt;
    &lt;p&gt;The first wave of web search APIs used in AI-based search made this human search paradigm programmatically accessible, but failed to solve the underlying problem of how you design search for an AI agent‚Äôs needs.&lt;/p&gt;
    &lt;p&gt;AI search has to solve a different problem: **what tokens should go in an agent's context window to help it complete the task? We‚Äôre not ranking URLs for humans to click‚Äî we‚Äôre optimizing context and tokens for models to reason over.**&lt;/p&gt;
    &lt;p&gt;This requires a fundamentally different search architecture:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Semantic objectives** that capture intent beyond keyword matching, so agents can specify what they need to accomplish rather than guessing at search terms&lt;/item&gt;
      &lt;item&gt;- **Token-relevance ranking** to prioritize webpages most directly relevant to the objective, not pages optimized for human engagement metrics&lt;/item&gt;
      &lt;item&gt;- **Information-dense excerpts** compressed and prioritized for reasoning quality, so LLMs have the highest-signal tokens in their context window&lt;/item&gt;
      &lt;item&gt;- **Single-call resolution** for complex queries that normally require multiple search hops&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With this search architecture built from the ground up for AIs, agents get access to the most information-dense web tokens in their context. The result is fewer search calls, higher accuracy, lower cost, and lower end-to-end latency.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **On every benchmark that matters for real-world agent use cases, Parallel wins on accuracy**&lt;/head&gt;
    &lt;p&gt;While most existing search systems are optimized for straightforward question answering, we believe the demand for more complex, multifaceted search will only continue to grow. Users and agents alike will increasingly seek answers that require synthesizing information across multiple sources, reasoning over complex objectives, and navigating harder-to-access content on the web.&lt;/p&gt;
    &lt;p&gt;To reflect this shift, we evaluated the performance of Parallel‚Äôs Search API across a range of benchmarks, from the most challenging multi-hop tasks (e.g., BrowseComp) to simple single-hop queries (e.g., SimpleQA).&lt;/p&gt;
    &lt;head rend="h3"&gt;### For complex searches, Parallel is the highest accuracy at the lowest cost&lt;/head&gt;
    &lt;p&gt;Parallel‚Äôs performance advantage is dramatic on challenging queries ‚Äî those that span multiple topics, require deep comprehension of hard to crawl web content, or demand synthesis across scattered sources with multiple reasoning steps. On benchmarks specifically designed to test multi-hop reasoning (HLE, BrowseComp, WebWalker, FRAMES, Batched SimpleQA), Parallel not only achieves higher accuracy but also resolves queries through more efficient reasoning paths.&lt;/p&gt;
    &lt;p&gt;Traditional search APIs get less done in each pass. Agents perform too many sequential searches - compounding latency, inflating context windows, and increasing token costs with every iteration, and decreasing accuracy. Parallel, by contrast, can resolve more complex queries in a single call, resulting in the agent making fewer sequential calls and achieving higher accuracy, lower total cost, and lower end to end latency.&lt;/p&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://lastexam.ai/) consists of 2,500 questions developed by subject-matter experts across dozens of subjects (e.g. math, humanities, natural sciences). Each question has a known solution that is unambiguous and easily verifiable, but requires sophisticated web retrieval and reasoning. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### HLE Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 82 | 47 | | Others | exa | 138 | 24 | | Others | tavily | 190 | 21 | | Others | perplexity | 126 | 30 | | Others | openai gpt-5 | 143 | 45 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://lastexam.ai/) consists of 2,500 questions developed by subject-matter experts across dozens of subjects (e.g. math, humanities, natural sciences). Each question has a known solution that is unambiguous and easily verifiable, but requires sophisticated web retrieval and reasoning. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### BrowseComp Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 156 | 58 | | Others | exa | 233 | 29 | | Others | tavily | 314 | 23 | | Others | perplexity | 256 | 22 | | Others | openai gpt-5 | 253 | 53 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About the benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://openai.com/index/browsecomp/), created by OpenAI, contains 1,266 questions requiring multi-hop reasoning, creative search formulation, and synthesis of contextual clues across time periods. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### WebWalker-Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 42 | 81 | | Others | exa | 107 | 48 | | Others | tavily | 156 | 79 | | Others | perplexity | 91 | 67 | | Others | openai gpt-5 | 88 | 73 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://arxiv.org/abs/2501.07572) is designed to assess the ability of LLMs to perform web traversal. To successfully answer the questions in the benchmark, it requires the ability to crawl and extract content from website subpages. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### FRAMES-Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 42 | 92 | | Others | exa | 81 | 81 | | Others | tavily | 122 | 87 | | Others | perplexity | 95 | 83 | | Others | openai gpt-5 | 68 | 90 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://huggingface.co/datasets/google/frames-benchmark) contains 824 challenging multi-hop questions designed to test factuality, retrieval accuracy, and reasoning. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### Batched SimpleQA - Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 50 | 90 | | Others | exa | 119 | 71 | | Others | tavily | 227 | 59 | | Others | perplexity | 100 | 74 | | Others | openai gpt-5 | 91 | 88 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark was created by batching 3 independent questions from the original SimpleQA dataset[SimpleQA dataset]($https://openai.com/index/introducing-simpleqa/) to create 100 composite, more complex, questions.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Across these multi-hop benchmarks, agents using Parallel achieve state-of-the-art accuracy at ~50% of the cost, compared to workflows built on traditional search APIs.&lt;/p&gt;
    &lt;head rend="h3"&gt;### On simple searches, Parallel is the lowest cost with parity in accuracy&lt;/head&gt;
    &lt;p&gt;We also tested Parallel on single-hop benchmarks like SimpleQA that contain straightforward factual queries that benefit from web search. These benchmarks are saturated with limited room for further accuracy improvements.&lt;/p&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://openai.com/index/introducing-simpleqa/), created by OpenAI, contains 4,326 questions focused on short, fact-seeking queries across a variety of domains. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;### SimpleQA Search&lt;/head&gt;
    &lt;quote&gt;| Series | Model | Cost (CPM) | Accuracy (%) | | --------- | ------------ | ----------- | ------------ | | Parallel | parallel | 17 | 98 | | Others | exa | 57 | 87 | | Others | tavily | 110 | 93 | | Others | perplexity | 52 | 92 | | Others | openai gpt-5 | 37 | 98 |&lt;/quote&gt;
    &lt;head rend="h3"&gt;### About this benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark[benchmark]($https://openai.com/index/introducing-simpleqa/), created by OpenAI, contains 4,326 questions focused on short, fact-seeking queries across a variety of domains. Results are reported on a sample of 100 questions from this benchmark.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Methodology&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;- **Evaluation**: Results are based on tests run using official Search MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/item&gt;
      &lt;item&gt;- **Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/item&gt;
      &lt;item&gt;- **Testing Dates**: Testing was conducted from November 3rd to November 5th.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On SimpleQA, the Parallel Search API matches the accuracy of the leading alternative while delivering the lowest end-to-end cost per-query cost.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **These results are possible because we've built a proprietary web index and a vertically-integrated search stack from the ground up, designed for AIs**&lt;/head&gt;
    &lt;p&gt;We are able to achieve state-of-the-art results because we have spent the last two years building the infrastructure to innovate across the full search stack, enabling optimization at every layer and feedback loops that continuously improve performance.&lt;/p&gt;
    &lt;p&gt;**Crawl:** Infrastructure that prioritizes the hard-to-crawl content on the web that isn‚Äôt included in pretraining data for models: multi-modal, lengthy PDFs, JavaScript-heavy sites. And optimizes recrawls to keep fast-changing data fresh while minimizing burden on website owners.&lt;/p&gt;
    &lt;p&gt;**Index:** One of the fastest-growing, freshest, deepest, and largest web indexes with 1B+ pages added or refreshed daily.&lt;/p&gt;
    &lt;p&gt;**Ranking:** We retrieve and rank with a different optimization objective than traditional search. Instead of ranking URLs for humans to click on, we identify the most relevant and authoritative tokens suitable for LLM reasoning. Our proprietary models and algorithms score based on token relevance, page and domain authority, context window efficiency, and cross-source validation, rather than click-through probability or engagement.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Leading AI teams build on our Search API - and so do we**&lt;/head&gt;
    &lt;p&gt;Today, the most sophisticated builders choose to create and deploy AI, with search powered by Parallel. These companies have tested alternatives and understand that the decisions their agents make, whether it‚Äôs Sourcegraph Amp‚Äôs coding agent solving bugs, _Claygent_ powering every GTM decision, Starbridge discovering government RFPs, or a Fortune 100 insurer underwriting claims better than human underwriters, all depend on the quality of their web data.&lt;/p&gt;
    &lt;p&gt;We use our own Search API as foundational infrastructure to power our Web Agents. For example, the Parallel Task API, our higher-level research API that serves complex, multi-step enrichment and deep research queries, is built using the Search API. Every Task API query that runs in production depends on the Search API performing flawlessly underneath.&lt;/p&gt;
    &lt;p&gt;This architectural decision forces us to hold ourselves to the highest standard. Every performance improvement, latency optimization, and quality enhancement in the Search API directly impacts our own production systems serving millions of queries daily. We feel every token of inefficiency and every accuracy gap immediately in our own products.&lt;/p&gt;
    &lt;p&gt;The result is infrastructure that's been battle-tested and continuously refined under the demands of real-world agent workloads.&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Give your agents access to Parallel Search**&lt;/head&gt;
    &lt;p&gt;Maximizing signal and minimizing noise in an agent‚Äôs context window is the single most important factor in the ability of the agent to complete a task effectively. Give your agents the most accurate and compressed context from the web with the Parallel Search API.&lt;/p&gt;
    &lt;p&gt;Give your agents access to better search. Get started in our Developer Platform[Developer Platform]($https://platform.parallel.ai/play/search) or dive into the documentation[documentation]($https://docs.parallel.ai/search/search-quickstart).&lt;/p&gt;
    &lt;head rend="h2"&gt;## **Notes on Methodology**&lt;/head&gt;
    &lt;p&gt;**Benchmark Details**: Various search providers were evaluated against a wide set of benchmarks ranging from simple benchmarks (SimpleQA) to more complex benchmarks (HLE, BrowseComp, Batched SimpleQA, WebWalker, and Frames).&lt;/p&gt;
    &lt;p&gt;**Evaluation**: Results are based on tests run using official MCP servers provided as an MCP tool to OpenAI's GPT-5 model using the Responses API. In all cases, the MCP tools were limited to only the appropriate web search tool. Answers were evaluated using an LLM as a judge (GPT 4.1).&lt;/p&gt;
    &lt;p&gt;**Cost Calculation**: Cost reflects the average cost per query across all questions run. This cost includes both the search API call and LLM token cost.&lt;/p&gt;
    &lt;p&gt;**Testing Dates**: Testing was conducted from November 3rd to November 5th. &lt;/p&gt;
    &lt;p&gt;By Parallel&lt;/p&gt;
    &lt;p&gt;November 6, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://parallel.ai/blog/introducing-parallel-search"/><published>2025-11-06T17:04:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45837871</id><title>Swift on FreeBSD Preview</title><updated>2025-11-06T20:40:14.069022+00:00</updated><content>&lt;doc fingerprint="e508591b9e45ceda"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;etcwilde
(Evan Wilde)
1&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;We have been hard at work to bring the Swift toolchain to FreeBSD. A preview Swift bundle for FreeBSD 14.3+ is available at https://download.swift.org/tmp-ci-nightly/development/freebsd-14_ci_latest.tar.gz. The bundle contains a Swift development compiler and Swift runtimes needed for compiling Swift programs on, and for, FreeBSD 14 on &lt;code&gt;x86_64&lt;/code&gt; machines.&lt;/p&gt;
        &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
        &lt;p&gt;The Swift compiler and runtimes have a few dependencies. Please install the following dependencies:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;zlib-ng&lt;/item&gt;
          &lt;item&gt;python3&lt;/item&gt;
          &lt;item&gt;sqlite3&lt;/item&gt;
          &lt;item&gt;libuuid&lt;/item&gt;
          &lt;item&gt;curl&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;Known Issues&lt;/head&gt;
        &lt;p&gt;The compiler in the bundle is still under development and isn't part of a release yet and we're not quite done porting everything to FreeBSD.&lt;/p&gt;
        &lt;p&gt;Here is a list of known issues that you may run into while trying things out.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Thread sanitizer reports incorrect failures &lt;/item&gt;
          &lt;item&gt;LLDB is unable to execute Swift expressions &lt;/item&gt;
          &lt;item&gt;Command Plugins in a SwiftPM package hangs &lt;/item&gt;
          &lt;item&gt;Using standard types with C++ interop results in an undefined voidify symbol &lt;/item&gt;
          &lt;item&gt;Importing the C libraries is done through "Glibc". This will change to &lt;code&gt;import FreeBSD&lt;/code&gt;

&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;lld&lt;/code&gt; and &lt;code&gt;lldb&lt;/code&gt; depend on &lt;code&gt;libxml2.so.2&lt;/code&gt;, which is not be available in the system package manager.

&lt;/item&gt;
        &lt;/list&gt;
        &lt;p&gt;We are investigating adding aarch64 support and making the bundle available for all minor versions of FreeBSD 14.&lt;/p&gt;
        &lt;p&gt;As you find more bugs, please file issues at https://github.com/swiftlang/swift/issues.&lt;/p&gt;
        &lt;p&gt;We look forward to hearing your feedback. If you're interested in helping add the finishing polish, please feel free to reach out here on the forums.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 21 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;kebo
(Kenta Kubo)
2&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;On FreeBSD 15, the following error occurs when executing &lt;code&gt;swift&lt;/code&gt;.&lt;/p&gt;
        &lt;quote&gt;
          &lt;code&gt;ld-elf.so.1: Shared object "libutil.so.9" not found, required by "swift"
&lt;/code&gt;
        &lt;/quote&gt;
        &lt;p&gt;As a temporary workaround, &lt;code&gt;doas pkg install compat14x-amd64&lt;/code&gt; will solve the issue.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Great news, thank you. Registered to this forum just to say that.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;etcwilde
(Evan Wilde)
4&lt;/div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;p&gt;On FreeBSD 15, the following error occurs when executing &lt;code&gt;swift&lt;/code&gt; .&lt;/p&gt;
        &lt;/quote&gt;
        &lt;p&gt;Yes, the FreeBSD stability policy appears to be within a major version. The bundle is built for FreeBSD 14. I'm glad to see that you were able to find a workaround though.&lt;/p&gt;
        &lt;quote&gt;
          &lt;p&gt;For -STABLE branches, it's important to make sure that ABI is compatible across dot releases (in other words, user can expect applications that is compiled for X.0 would run without modification on any X.y releases). We also try to maintain ABI compatibility across .0 releases, but they are not strictly enforced except for libraries that already implements versioned symbols.&lt;/p&gt;
        &lt;/quote&gt;
        &lt;p&gt;https://wiki.freebsd.org/Releng/ABI&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;grynspan
(Jonathan Grynspan)
5&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Generally speaking, I would expect the Swift compatibility policy for FreeBSD to be similar to that of Linux. We distribute toolchains for e.g. Ubuntu 22 and Ubuntu 24 that are distinct. @etcwilde that sounds right, I hope?&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://forums.swift.org/t/swift-on-freebsd-preview/83064"/><published>2025-11-06T17:37:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45838365</id><title>Benchmarking the Most Reliable Document Parsing API</title><updated>2025-11-06T20:40:13.777095+00:00</updated><content>&lt;doc fingerprint="a245660aad22ea5b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Benchmarking the Most Reliable Document Parsing API&lt;/head&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;Traditional document parsing benchmarks measure text similarity while ignoring structural preservation and downstream usability. Tensorlake's new Document Parsing model achieves 91.7% accuracy in enterprise documents‚Äîoutperforming Azure, AWS Textract, and open-source alternatives.&lt;/p&gt;
    &lt;p&gt;Document parsing is the foundation of enterprise AI applications. Whether you're building RAG pipelines, automating insurance claims, or extracting data from financial reports, everything starts with one question: Can you consistently transform messy, real-world documents into structured, machine-readable data?&lt;/p&gt;
    &lt;p&gt;Our customers need the best document ingestion API for their use cases. They're comparing Azure, AWS Textract, popular open-source models like Docling and Marker.&lt;/p&gt;
    &lt;p&gt;We built a benchmark that measures what matters: Can downstream systems actually use this output?&lt;/p&gt;
    &lt;head rend="h2"&gt;Measuring What Actually Matters#&lt;/head&gt;
    &lt;p&gt;Tensorlake both reads documents and extracts structured data, so when choosing what to measure accuracy with, we wanted to ensure we were measuring both document parsing with structural preservation and structured extraction for downstream usability.&lt;/p&gt;
    &lt;p&gt;The aspects of Document Parsing that we wanted to measure were:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tables: Ensuring we can parse and measure accuracy of complex tables with merged cells and multi-row headers&lt;/item&gt;
      &lt;item&gt;Reading Order: In multi-column documents, and documents with complex layouts, we measure whether the reading order is preserved while parsing.&lt;/item&gt;
      &lt;item&gt;Structured Extraction Accuracy: Measuring direct downstream usability of extracted data. A small OCR error in parsing a table cell can cause failure in achieving the downstream task, while the overall accuracy of the OCR on the document may be high.&lt;/item&gt;
      &lt;item&gt;Extraction of footnotes, formulas, figures and other non-textual content.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Our Evaluation Methodology#&lt;/head&gt;
    &lt;p&gt;We employ two metrics that better capture these features with real-world reliability:&lt;/p&gt;
    &lt;head rend="h3"&gt;TEDS (Tree Edit Distance Similarity)#&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compares predicted and ground-truth Markdown/HTML tree structures&lt;/item&gt;
      &lt;item&gt;Captures structural fidelity in tables and complex layouts&lt;/item&gt;
      &lt;item&gt;Widely adopted in OCRBench v2 and OmniDocBench evaluations&lt;/item&gt;
      &lt;item&gt;Measures whether the document's logical structure and textual alignment remains intact&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TEDS answers: "Is this table still a table?" Not just "Is the text similar?"&lt;/p&gt;
    &lt;head rend="h3"&gt;JSON F1 (Field-Level Precision and Recall)#&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compares extracted JSON against schema-based ground truth&lt;/item&gt;
      &lt;item&gt;Precision measures correctness of extracted fields&lt;/item&gt;
      &lt;item&gt;Recall measures completeness of required field capture&lt;/item&gt;
      &lt;item&gt;F1 score balances both for overall reliability assessment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;JSON F1 answers: "Can downstream automation actually use this data?" Not just "Is some text present?"&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Together, these metrics answer the essential question: "Can downstream systems use this output?" rather than simply "Is the text similar?"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Stage 1: Document Reading Ability (OCR and Structural Preservation)&lt;lb/&gt; Each parsing model generates Markdown/HTML output. We evaluate using TEDS to measure how well structure is preserved; reading order, table integrity, and layout coherence. You can find our updated dataset published here. We use the public OCRBench v2 and OmniDocBench datasets. However, upon review, we identified inconsistencies in the published ground truth of OCRBench v2. We conducted a comprehensive audit and correction to ensure evaluation accuracy.&lt;/p&gt;
    &lt;p&gt;Stage 2: Structured Extraction Accuracy (Downstream Usability)&lt;lb/&gt; We pass the Markdown through a standardized LLM (GPT-4o) with predefined JSON schemas, measuring JSON F1. This isolates how OCR quality impacts real extraction workflows, where an LLM interprets the parsed text. Initial JSON schemas and reference answers are generated using Gemini Pro 2.5, then human reviewers audit and correct them to ensure high-quality gold standards.&lt;/p&gt;
    &lt;p&gt;This methodology ensures fair, reproducible comparisons by varying only the OCR models (Stage 1) while keeping the extraction model constant (Stage 2).&lt;/p&gt;
    &lt;head rend="h2"&gt;The Results: Public Dataset Performance#&lt;/head&gt;
    &lt;head rend="h3"&gt;Document Parsing Performance#&lt;/head&gt;
    &lt;p&gt;We evaluated leading open-source and proprietary models:&lt;/p&gt;
    &lt;p&gt;Key Findings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tensorlake achieves the highest TEDS score, indicating superior structural preservation&lt;/item&gt;
      &lt;item&gt;The gap between Docling and production-grade systems is substantial&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Table Parsing Performance#&lt;/head&gt;
    &lt;p&gt;We evaluated Tensorlake‚Äôs table parsing accuracy using the OmniDocBench dataset ‚Äî a CVPR-accepted benchmark for comprehensive document understanding tasks (GitHub link).&lt;/p&gt;
    &lt;p&gt;Table accuracy in OmniDocBench is quantified using a combination of tree-based and string-based metrics. In particular, we measured TEDS (Tree Edit Distance Similarity), which assesses both the structural and textual alignment between predicted and ground-truth HTML tables.&lt;/p&gt;
    &lt;p&gt;To reproduce our results, generate Markdown outputs using the models listed below, then run the evaluation method provided in the OmniDocBench repository. We have used 512 document images with tables and v1.5 of the code version. Evaluation outputs are released in Huggingface(link)&lt;/p&gt;
    &lt;p&gt;¬π Marker's Number is from the officially published OmniDocBench repository.&lt;/p&gt;
    &lt;p&gt;Key Findings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;On OmniDocBench's challenging tables, Tensorlake leads with 86.79% TEDS&lt;/item&gt;
      &lt;item&gt;Open-source solutions struggle with table extraction (sub-70% TEDS)&lt;/item&gt;
      &lt;item&gt;Tensorlake maintains table structure even on complex, multi-page tables&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Performance on Real World Enterprise Documents#&lt;/head&gt;
    &lt;p&gt;OCR Models are rarely trained on enterprise documents, because they are not publicly available. We wanted to test how well our model performs and others perform on these documents.&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise Document Performance (100 pages)#&lt;/head&gt;
    &lt;p&gt;We curated 100 document pages spanning banking, retail, and insurance sectors. This represents real production workloads: invoices with water damage, scanned contracts with skewed text, bank statements with multi-level tables.&lt;/p&gt;
    &lt;p&gt;Key Findings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tensorlake achieves 91.7% F1 with standard extraction, beating all competitors&lt;/item&gt;
      &lt;item&gt;The difference between 91.7% and 68.9% F1 is massive: it‚Äôs 5 extra fields correctly extracted out of every 20&lt;/item&gt;
      &lt;item&gt;In production workflows processing thousands of documents daily, this accuracy gap compounds into significant error reduction&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But even comparing the higher F1 scores when parsing a standard form, Azure and Textract jumble the reading order and skip data completely, whereas Tensorlake preserves the complex reading order and groups data correctly and accurately:&lt;/p&gt;
    &lt;head rend="h2"&gt;Delivering the Best Performance/Price Ratio#&lt;/head&gt;
    &lt;p&gt;Accuracy without affordability isn't practical. Here's how Tensorlake compares to other Document Ingestion APIs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Tensorlake: $10 per 1k pages&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;TEDS Score: 86.79&lt;/item&gt;
          &lt;item&gt;F1 Score: 91.7&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Azure: $10 per 1k pages&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;TEDS Score: 78.14&lt;/item&gt;
          &lt;item&gt;F1 Score: 88.1&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AWS Textract: $15 per 1k pages&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;TEDS Score: 80.75&lt;/item&gt;
          &lt;item&gt;F1 Score: 88.4&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tensorlake delivers the highest accuracy than both Azure and AWS Textract, matching Azure's cost while AWS Textract is 50% more expensive.&lt;/p&gt;
    &lt;head rend="h2"&gt;Take the Next Step#&lt;/head&gt;
    &lt;p&gt;When your business depends on accurate document processing, you can't afford to use anything less.&lt;/p&gt;
    &lt;p&gt;Want to discuss your specific use case?&lt;lb/&gt; Schedule a technical demo with our team.&lt;/p&gt;
    &lt;p&gt;Questions about the benchmark?&lt;lb/&gt; Join our Slack community&lt;/p&gt;
    &lt;head rend="h3"&gt;Dr Sarah Guthals&lt;/head&gt;
    &lt;p&gt;Founding DevRel Engineer at Tensorlake&lt;/p&gt;
    &lt;p&gt;Founding DevRel Engineer at Tensorlake, blending deep technical expertise with a decade of experience leading developer engagement at companies like GitHub, Microsoft, and Sentry. With a PhD in Computer Science and a background in founding developer education startups, I focus on building tools, content, and communities that help engineers work smarter with AI and data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tensorlake.ai/blog/benchmarks"/><published>2025-11-06T18:12:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45838540</id><title>Show HN: TabPFN-2.5 ‚Äì SOTA foundation model for tabular data</title><updated>2025-11-06T20:40:13.532168+00:00</updated><content>&lt;doc fingerprint="1d6a74aa8f3ca9cb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;TabPFN-2.5 Model Report&lt;/head&gt;
    &lt;head rend="h3"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;The first tabular foundation model, TabPFN, and its successor TabPFNv2 have impacted tabular AI substantially, with dozens of methods building on it and hundreds of applications across different use cases.&lt;/p&gt;
    &lt;p&gt;This report introduces TabPFN-2.5, the next generation of our tabular foundation model, scaling to 20√É data cells compared to TabPFNv2. On industry standard benchmarks with up to 50,000 data points and 2,000 features, TabPFN-2.5 substantially outperforms tuned tree-based models and matches the accuracy of AutoGluon 1.4, a complex four-hour tuned ensemble that even includes the previous TabPFNv2.&lt;/p&gt;
    &lt;p&gt;For production use cases, we introduce a new distillation engine that converts TabPFN-2.5 into a compact MLP or tree ensemble, preserving most of its accuracy while delivering orders-of-magnitude lower latency and plug-and-play deployment.This new release will immediately strengthen the performance of the many applications andmethods already built on the TabPFN ecosystem.&lt;/p&gt;
    &lt;p&gt;This new release will substantially strengthen the performance of the many applications and methods already built on TabPFN.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Tabular data is ubiquitous, forming the backbone of decision-making in countless domains, from finance to healthcare. For decades, traditional tabular machine learning√¢built on gradient-boosted trees, random forests, and linear or additive models√¢has been the workhorse of applied data science. Yet these methods remain limited: they require extensive dataset-specific tuning, often provide uncalibrated or unreliable uncertainty estimates without significant modification, and lack the generalization and transferability of modern foundation models.&lt;/p&gt;
    &lt;p&gt;Tabular foundation models (TFMs) offer a new paradigm. They address these limitations by pretraining on large synthetic distributions of tabular tasks and performing inference via in-context learning instead of gradient descent. They are training-free predictors meta-trained to yield strong calibration, without the need for time-consuming and labor-intensive hyperparameter tuning necessary for gradient-boosted trees. Their strong generalization makes them particularly attractive for data-scarce domains.&lt;/p&gt;
    &lt;p&gt;Our initial release, TabPFNv1, served as a proof-of-concept that a transformer could learn a Bayesian-like inference algorithm, though it was limited to small (up to 1,000 samples), clean, numerical-only data. Our successor, TabPFNv2, scaled this idea into a practical model for datasets up to 10,000 samples. TabPFNv2 handles the messy and heterogeneous data seen in the real world√¢including categorical features, missing values &amp;amp; outliers.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's New in TabPFN-2.5&lt;/head&gt;
    &lt;p&gt;State-of-the-Art Performance&lt;/p&gt;
    &lt;p&gt;In a forward pass, TabPFN-2.5 outperforms tuned tree-based models (like XGBoost and CatBoost) and matches the accuracy of AutoGluon 1.4 tuned for 4 hours√¢a complex ensemble that includes all previous methods, even TabPFNv2.&lt;/p&gt;
    &lt;p&gt;Improved Scalability&lt;/p&gt;
    &lt;p&gt;We scale the power of in-context learning to datasets of up to 50,000 samples (5√É increase over TabPFNv2) and 2,000 features (4√É increase), making TFMs viable for a much wider range of real-world problems.&lt;/p&gt;
    &lt;p&gt;Fast Inference&lt;/p&gt;
    &lt;p&gt;We've dramatically improved inference latency. Our proprietary distillation engine converts TabPFN-2.5 into a compact MLP or tree ensemble, preserving most of its accuracy while delivering orders-of-magnitude lower latency and plug-and-play deployment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://priorlabs.ai/technical-reports/tabpfn-2-5-model-report"/><published>2025-11-06T18:26:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45838564</id><title>LLMs Encode How Difficult Problems Are</title><updated>2025-11-06T20:40:13.344187+00:00</updated><content>&lt;doc fingerprint="8d9ea52a84b196ab"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 20 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:LLMs Encode How Difficult Problems Are&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large language models exhibit a puzzling inconsistency: they solve complex problems yet frequently fail on seemingly simpler ones. We investigate whether LLMs internally encode problem difficulty in a way that aligns with human judgment, and whether this representation tracks generalization during reinforcement learning post-training. We train linear probes across layers and token positions on 60 models, evaluating on mathematical and coding subsets of Easy2HardBench. We find that human-labeled difficulty is strongly linearly decodable (AMC: $\rho \approx 0.88$) and exhibits clear model-size scaling, whereas LLM-derived difficulty is substantially weaker and scales poorly. Steering along the difficulty direction reveals that pushing models toward "easier" representations reduces hallucination and improves accuracy. During GRPO training on Qwen2.5-Math-1.5B, the human-difficulty probe strengthens and positively correlates with test accuracy across training steps, while the LLM-difficulty probe degrades and negatively correlates with performance. These results suggest that human annotations provide a stable difficulty signal that RL amplifies, while automated difficulty estimates derived from model performance become misaligned precisely as models improve. We release probe code and evaluation scripts to facilitate replication.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: William Gitta Lugoloobi [view email]&lt;p&gt;[v1] Mon, 20 Oct 2025 22:48:23 UTC (1,102 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.18147"/><published>2025-11-06T18:29:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45838864</id><title>Black Hole Flare Is Biggest and Most Distant Seen</title><updated>2025-11-06T20:40:13.190711+00:00</updated><content/><link href="https://www.caltech.edu/about/news/black-hole-flare-is-biggest-and-most-distant-seen"/><published>2025-11-06T18:54:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45839655</id><title>UK outperforms US in creating unicorns from early stage VC investment</title><updated>2025-11-06T20:40:12.933890+00:00</updated><content>&lt;doc fingerprint="bce52a052bb2cc70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;UK outperforms US in creating unicorns from early stage VC investment&lt;/head&gt;
    &lt;p&gt;The UK has created nearly three times as many unicorns than the US per dollar in early stage venture capital (VC) investment in the past decade, highlighting its attractiveness as an investment destination.&lt;/p&gt;
    &lt;p&gt;According to analysis from venture-building firm IMS Digital Ventures, the UK has converted $18.5bn (¬£13.8bn) of early stage investment into 57 successful unicorns, a ratio of 3.08 start ups per $1bn in seed investment.&lt;/p&gt;
    &lt;p&gt;In contrast, the US created just 1.22 unicorns per $1bn, as the country received a staggering $625bn in VC investment over the past decade.&lt;/p&gt;
    &lt;p&gt;Unicorns are privately held start up companies, with valuations of $1bn or more.&lt;/p&gt;
    &lt;p&gt;The UK‚Äôs ability to turn funding into successful start-up companies has caused it to become the second most attractive major economy in Europe and North America for early VC investment.&lt;/p&gt;
    &lt;p&gt;Anastasios Papadopoulos, founder and chief executive of IMS Digital Ventures, said: ‚ÄúThe UK has been a breeding ground for some of the world‚Äôs most innovative and exciting start ups in the last decade.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe UK has all the right ingredients to thrive as a hub for the companies that can shape the industries of the future.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;VC firms eyeball the UK&lt;/head&gt;
    &lt;p&gt;VC investors have increasingly recognised the UK‚Äôs potential as an investment destination over the past ten years, significantly increasing the pool of capital available to investors.&lt;/p&gt;
    &lt;p&gt;Seed investment has jumped from $50m in 2014 to $538m in 2024, while early stage investment surged from $576m to $3bn over the same period.&lt;/p&gt;
    &lt;p&gt;This has been credited to the country‚Äôs strong legal framework as well as London‚Äôs global status as a major financial centre, able to provide start-ups with both the stability and capital needed to get their business off the ground.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finance and insurance driving UK success&lt;/head&gt;
    &lt;p&gt;In particular, the finance and insurance sectors have been key in driving the UK‚Äôs growing success, representing nearly 50 per cent of all companies that have hit unicorn status since 2014.&lt;/p&gt;
    &lt;p&gt;This included neobank Monzo, which raised roughly $50m in funding between 2015 and 2017, and insurance tech firm Marshmallow, which raised $190m.&lt;/p&gt;
    &lt;p&gt;However, artificial intelligence is also widening its UK influence, creating six billion dollar valuation companies since 2014, as more VC firms eye opportunities in the growing sector.&lt;/p&gt;
    &lt;p&gt;Papadopoulos said: ‚ÄúThere‚Äôs a clear opportunity to support more start-ups in high-growth areas such as artificial intelligence, cybersecurity, and biotech.&lt;/p&gt;
    &lt;p&gt;‚ÄúWith the right regulatory environment and continued support for emerging technologies, the UK is well-positioned to build on its strong foundation and create the next generation of British tech unicorns.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cityam.com/uk-outperforms-us-in-creating-unicorns-from-early-stage-vc-investment/"/><published>2025-11-06T20:01:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45839901</id><title>Two billion email addresses were exposed</title><updated>2025-11-06T20:40:12.669862+00:00</updated><content>&lt;doc fingerprint="eb97a9970f70c6b9"&gt;
  &lt;main&gt;
    &lt;p&gt;I hate hyperbolic news headlines about data breaches, but for the "2 Billion Email Addresses" headline to be hyperbolic, it'd need to be exaggerated or overstated - and it isn't. It's rounded up from the more precise number of 1,957,476,021 unique email addresses, but other than that, it's exactly what it sounds like. Oh - and 1.3 billion unique passwords, 625 million of which we'd never seen before either. It's the most extensive corpus of data we've ever processed, by a significant margin.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago, I wrote about the 183M unique email addresses that Synthient had indexed in their threat intelligence platform and then shared with us. I explained that this was only part of the corpus of data they'd indexed, and that it didn't include the credential stuffing records. Stealer log data is obtained by malware running on infected machines. In contrast, credential stuffing lists usually originate from other data breaches where email addresses and passwords are exposed. They're then bundled up, sold, redistributed, and ultimately used to log in to victims' accounts. Not just the accounts they were initially breached from, either, because people reuse the same password over and over again, the data from one breach is frequently usable on completely unrelated sites. A breach of a forum to comment on cats often exposes data that can then be used to log in to the victim's shopping, social media and even email accounts. In that regard, credential stuffing data becomes "the keys to the castle".&lt;/p&gt;
    &lt;p&gt;Let me run through how we verified the data, what you can do about it and for the tech folks, some of the hoops we had to jump through to make processing this volume of data possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data Verification&lt;/head&gt;
    &lt;p&gt;The first person whose data I verified was easy - me üòî An old email address I've had since the 90s has been in credential stuffing lists before, so it wasn't too much of a surprise. Furthermore, I found a password associated with my address, which I'd definitely used many eons ago, and it was about as terrible as you'd expect from that era. However, none of the other passwords associated with my address were familiar. They certainly looked like passwords that other people might have feasibly used, but I'm pretty sure they weren't mine. One was even just an IP address from Perth on the other side of the country, which is both infeasible as a password I would have used, yet eerily close to home. I mean, of all the places in the world an IP address could have appeared from, it had to be somewhere in my own country I've been many times before...&lt;/p&gt;
    &lt;p&gt;Moving on to HIBP subscribers, I reached out to a handful and asked for support verifying the data. I chose a mix of subscribers with many who'd never been involved in any data breach we'd ever seen before; my experience above suggested that there's recycled data in there, and we had previously verified that when investigating those other incidents. However, is the all-new stuff legitimate? The very first response I received was exactly what I was looking for:&lt;/p&gt;
    &lt;quote&gt;#1 is an old password that I don't use anymore. #2 is a more recent password. Thanks for the heads up, I've gone and changed the password for every critical account that used either one.&lt;/quote&gt;
    &lt;p&gt;Perfectly illustrating most people's behaviour with passwords, #2 referred to above was just #1 with two exclamation marks at the end!! (Incidentally, these were simple six and eight-character passwords, and neither of them was in Pwned Passwords either.) He had three passwords in total, which also means one of them, like with my data, was not familiar. However, the most important thing here is that this example perfectly illustrates why we put the effort into processing data like this: #2 was a real, live password that this guy was actively using, and it was sitting right next to his email address, being passed around among criminals. However, through this effort, that credential pair has now become useless, which is precisely what we're aiming for with this exercise, just a couple of billion times over.&lt;/p&gt;
    &lt;p&gt;The second respondent only had one password against their address:&lt;/p&gt;
    &lt;quote&gt;Yes that was a password I used for many years for what I would call throw away or unimportant accounts between 20 and 10 years ago&lt;/quote&gt;
    &lt;p&gt;That was also only eight characters, but this time, we'd seen it in Pwned Passwords many times before. And the observation about the password's age was consistent with my own records, so there's definitely some pretty old data in there.&lt;/p&gt;
    &lt;p&gt;The following response was not at all surprising:&lt;/p&gt;
    &lt;quote&gt;I am familiar with that password... I used it almost 10 years ago... and cannot recall the last time I used it.&lt;/quote&gt;
    &lt;p&gt;That was on a corporate account, too, and the owner of the address duly forwarded my email to the cybersecurity team for further investigation. The single password associated with this lady's email address had a massive nine characters, and also hadn't previously appeared in Pwned Passwords.&lt;/p&gt;
    &lt;p&gt;Next up was a respondent who replied inline to my questions, so I'll list them below with the corresponding answers:&lt;/p&gt;
    &lt;quote&gt;Is this familiar? Yes&lt;/quote&gt;
    &lt;quote&gt;Have you ever used it in the past? Yes and is still on some accounts I do not use any longer.&lt;/quote&gt;
    &lt;quote&gt;And if so, how long ago? Unfortunately, it is still on some active accounts that I have just made a list of to change or close immediately.&lt;/quote&gt;
    &lt;p&gt;This individual's eight-character password with uppercase, lowercase, numbers and a "special" character also wasn't in Pwned Passwords. Similarly, as with the earlier response, that password was still in active use, posing a real risk to the owner. It would pass most password complexity criteria and slip through any service using Pwned Passwords to block bad ones, so again, this highlights why it was so important for us to process the data.&lt;/p&gt;
    &lt;p&gt;The next person had three different passwords against rows with their email address, and they came back with a now common response:&lt;/p&gt;
    &lt;quote&gt;Yes, these are familiar, last used 10 years ago&lt;/quote&gt;
    &lt;p&gt;We'd actually seen all three of them in Pwned Passwords before, many times each. Another respondent with precisely the kind of gamer-like passwords you'd expect a kid to use (one of which we hadn't seen before), also confirmed (I think?) their use:&lt;/p&gt;
    &lt;quote&gt;maybe when i was a kid lol&lt;/quote&gt;
    &lt;p&gt;Responses that weren't an emphatic "yes, that's my data" were scarce. The two passwords against one person's name were both in Pwned Passwords (albeit only once each), yet it's entirely possible that neither of them had been used by this specific individual before. It's also possible they'd forgotten a password they'd used more than a decade ago, or it may have even been automatically assigned to them by the service that was subsequently breached. Put it down as a statistical anomaly, but I thought it was worth mentioning to highlight that being in this data set isn't a guarantee of a genuine password of yours being exposed. If your email address is found in this corpus then that's real, of course, so there must be some truth in the data, but it's a reminder that when data is aggregated from so many different sources over such a long period of time, there's going to be some inconsistencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Searching Pwned Passwords&lt;/head&gt;
    &lt;p&gt;As a brief recap, we load passwords into the service we call Pwned Passwords. When we do so, there is absolutely no association between the password and the email address it appeared next to. This is for both your protection and ours; can you imagine if HIBP was pwned? It's not beyond the realm of possibility, and the impact of exposing billions of credential pairs that can immediately unlock an untold number of accounts would be catastrophic. It's highly risky, and completely unnecessary when you can search for standalone passwords anyway without creating the risk of it being linked back to someone.&lt;/p&gt;
    &lt;p&gt;Think about it: if you have a password of "Fido123!" and you find it's been previously exposed (which it has), it doesn't matter if it was exposed against your email address or someone else's; it's still a bad password because it's named after your dog followed by a very predictable pattern. If you have a genuinely strong password and it's in Pwned Passwords, then you can walk away with some confidence that it really was yours. Either way, you shouldn't ever use that password again anywhere, and Pwned Passwords has done its job.&lt;/p&gt;
    &lt;p&gt;Checking the service is easy, anonymous and depending on your level of technical comfort, can be done in several different ways. Here's a copy and paste from the last Synthient blog post:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use the Pwned Passwords search page. Passwords are protected with an anonymity model, so we never see them (it's processed in the browser itself), but if you're wary, just check old ones you may suspect.&lt;/item&gt;
      &lt;item&gt;Use the k-anonymity API. This is what drives the page in the previous point, and if you're handy with writing code, this is an easy approach and gives you complete confidence in the anonymity aspect.&lt;/item&gt;
      &lt;item&gt;Use 1Password's Watchtower. The password manager has a built-in checker that uses the abovementioned API and can check all the passwords in your vault. (Disclosure: 1Password is a regular sponsor of this blog, and has product placement on HIBP.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My vested interest in 1Password aside, Watchtower is the easiest, fastest way to understand your potential exposure in this incident. And in case you're wondering why I have so many vulnerable and reused passwords, it's a combination of the test accounts I've saved over the years and the 4-digit PINs some services force you to use. Would you believe that every single 4-digit number ever has been pwned?! (If you're interested, the ABC has a fantastic infographic using a heatmap based on HIBP data that shows some very predictable patterns for 4-digit PINs.)&lt;/p&gt;
    &lt;head rend="h2"&gt;This Is Not a Gmail Breach&lt;/head&gt;
    &lt;p&gt;It pains me to say it, but I have to, given the way the stealer logs made ridiculous, completely false headlines a couple of weeks ago:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This story has suddenly gained *way* more traction in recent hours, and something I thought was obvious needs clarifying: this *is not* a Gmail leak, it simply has the credentials of victims infected with malware, and Gmail is the dominant email provider: https://t.co/S75hF4T1es&lt;/p&gt;‚Äî Troy Hunt (@troyhunt) October 27, 2025&lt;/quote&gt;
    &lt;p&gt;There are 32 million different email domains in this latest corpus, of which gmail.com is one. It is, of course, the largest and has 394 million unique email addresses on it. In other words, 80% of the data in this corpus has absolutely nothing to do with Gmail, and the 20% of Gmail addresses have absolutely nothing to do with any sort of security vulnerability on Google's behalf. There - now let reporting sanity prevail!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Technical Bits&lt;/head&gt;
    &lt;p&gt;I wanted to add this just to highlight how painful it has been to deal with this data. This corpus is nearly 3 times the size of the previous largest breach we'd loaded, and HIBP is many times larger than it was in 2019 when we loaded the Collection #1 data. Taking 2 billion records and adding the ones we hadn't already seen in the existing 15 billion corpus, whilst not adversely impacting the live system serving millions of visitors a day, was very non-trivial. Managing the nuances of SQL Server indexes such that we could optimise both inserts and queries is not my idea of fun, and it's been a pretty hard couple of weeks if I'm honest. It's also been a very expensive period as we turned the cloud up to 11 (we run on Azure SQL Hyperscale, which we maxed out at 80 cores for almost two weeks).&lt;/p&gt;
    &lt;p&gt;A simple example of the challenge is that after loading all the email addresses up into a staging table, we needed to create SHA1 hashes of each. Normally, that would involve something to the effect of "update table set column = sha1(email)" and you're done. That crashed completely, so we ended up doing "insert into new table select email, sha1(email)". But on other occasions the breach load required us to do updates on other columns (with no hash creation), which, on mulitple occasions, we had to kill after a day or more of execution with no end in sight. So, we ended up batching in loops (usually 1M records at a time), reporting on progress along the way so we had some idea of when it would actually finish. It was a painful process of trail, waiting ages, error then taking a completely different approach.&lt;/p&gt;
    &lt;p&gt;Notifying our subscribers is another problem. We have 5.9 million of them, and 2.9 million are in this data ü´® Simply sending that many emails at once is hard. It's not so much hard in terms of firing them off, rather it's hard in terms of not ending up on a reputation naughty list or having mail throttled by the receiving server. That's happened many times in the past when loading large, albeit much smaller corpuses; Gmail, for example, suddenly sees a massive spike and slows down the delivery to inboxes. Not such a biggy for sending breach notices, but a major problem for people trying to sign into their dashboard who can no longer receive the email with the "magic" link.&lt;/p&gt;
    &lt;p&gt;What we've done to address that for this incident is to slow down the delivery of emails for the individual breach notification. Whilst I'd originally intended to send the emails at a constant rate over the period of a week, someone listening to me on my Friday live stream had a much better suggestion:&lt;/p&gt;
    &lt;quote&gt;the strategy I've found to best work with large email delivery is to look at the average number of emails you've sent over the last 30 days each time you want to ramp up, and then increase that volume by around 50% per day until you've worked your way through the queue&lt;/quote&gt;
    &lt;p&gt;Which makes a lot of sense, and stacked up as I did more research (thanks Joe!). So, here's what our planned delivery schedule now looks like:&lt;/p&gt;
    &lt;p&gt;That's broken down by hour, increasing in volume by 1.015 times per hour, such that the emails are spread out in a similar, gradually increasing cadence. On a daily basis, that works out at a 45% increase in each 24-hour period, within Joe's suggested 50% threshold. Plus, we obviously have all the other mechanisms such as a dedicated IP, properly configured DKIM, DMARC and SPF, only emailing double-opted-in subscribers and spam-friendly message body construction. So, it could be days before you receive a notification, or just run a haveibeenpwned.com search on demand if you're impatient.&lt;/p&gt;
    &lt;p&gt;We've sent all the domain notification emails instantly because, by definition, they're going to a very wide range of different mail servers; it's just the individual ones we're drop-feeding.&lt;/p&gt;
    &lt;p&gt;Lastly, if you've integrated Pwned Passwords into your service, you'll now see noticeably larger response sizes. The numbers I mentioned in the opening paragraph increase the size of each hash range by an average of about 50%, which will push responses from about 26kb to 40kb. That's when brotli compressed, so obviously, make sure you're making requests that make the most of the compression.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This data is now searchable in HIBP as the Synthient Credential Stuffing Threat Data. It's an entirely separate corpus from that previous Synthient data I mentioned earlier; they're discrete datasets with some crossover, but obviously, this one is significantly larger. And, of course, all the passwords are now searchable per the Pwned Passwords guidance above.&lt;/p&gt;
    &lt;p&gt;If I could close with one request: this was an extremely laborious, time-consuming and expensive exercise for us to complete. We've done our best to verify the integrity of the data and make it searchable in a practical way while remaining as privacy-centric as possible. Sending as many notifications as we have will inevitably lead to a barrage of responses from people wanting access to complete rows of data, grilling us on precisely where it was obtained from or, believe it or not, outright abusing us. Not doing those things would be awesome, and I suggest instead putting the energy into getting a password manager, making passwords strong and unique (or even better, using passkeys where available), and turning on multi-factor auth. That would be an awesome outcome for all üòä&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/"/><published>2025-11-06T20:20:23+00:00</published></entry></feed>