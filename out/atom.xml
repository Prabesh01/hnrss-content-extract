<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-13T16:12:30.727229+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45561672</id><title>Emacs agent-shell (powered by ACP)</title><updated>2025-10-13T16:12:37.896833+00:00</updated><content>&lt;doc fingerprint="35d78c5f8911c81d"&gt;
  &lt;main&gt;
    &lt;p&gt;Not long ago, I introduced acp.el, an Emacs lisp implementation of ACP (Agent Client Protocol), the agent protocol developed between Zed and Google folks.&lt;/p&gt;
    &lt;p&gt;While I've been happily accessing LLMs from my beloved text editor via chatgpt-shell (a multi-model package I built), I've been fairly slow on the AI agents uptake. Probably a severe case of old-man-shouts-at-cloud sorta thing, but hey I want well-integrated tools in my text editor. When I heard of ACP, I knew this was the thing I was waiting for to play around with agents.&lt;/p&gt;
    &lt;p&gt;With an early acp.el client library in place, I set out to build an Emacs-native agent integrationÃ¢Â¦ Today, I have an initial version of agent-shell I can share.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;agent-shell&lt;/code&gt; is a native Emacs shell, powered by comint-mode (check out Mickey's comint article btw). As such, we don't have to dance between char and line modes to interact with things. &lt;code&gt;agent-shell&lt;/code&gt; is just a regular Emacs buffer like any other you're used to.&lt;/p&gt;
    &lt;p&gt;Thanks to ACP, we can now build agent-agnostic experiences by simply configuring our clients to communicate with their respective agents using a common protocol. As users, we benefit from a single, consistent experience, powered by any agent of our choice.&lt;/p&gt;
    &lt;p&gt;Configuring different agents from &lt;code&gt;agent-shell&lt;/code&gt; boils down which agent we want running in the comms process. Here's an example of Gemini CLI vs Claude Code configuration:&lt;/p&gt;
    &lt;code&gt;(defun agent-shell-start-gemini-agent ()
  "Start an interactive Gemini CLI agent shell."
  (interactive)
  (agent-shell--start
   :new-session t
   :mode-line-name "Gemini"
   :buffer-name "Gemini"
   :shell-prompt "Gemini&amp;gt; "
   :shell-prompt-regexp "Gemini&amp;gt; "
   :needs-authentication t
   :authenticate-request-maker (lambda ()
                                 (acp-make-authenticate-request :method-id "gemini-api-key"))
   :client-maker (lambda ()
                   (acp-make-client :command "gemini"
                                    :command-params '("--experimental-acp")
                                    :environment-variables (list (format "GEMINI_API_KEY=%s" (agent-shell-google-key)))))))
&lt;/code&gt;
    &lt;code&gt;(defun agent-shell-start-claude-code-agent ()
  "Start an interactive Claude Code agent shell."
  (interactive)
  (agent-shell--start
   :new-session t
   :mode-line-name "Claude Code"
   :buffer-name "Claude Code"
   :shell-prompt "Claude Code&amp;gt; "
   :shell-prompt-regexp "Claude Code&amp;gt; "
   :client-maker (lambda ()
                   (acp-make-client :command "claude-code-acp"
                                    :environment-variables (list (format "ANTHROPIC_API_KEY=%s" (agent-shell-anthropic-key)))))))
&lt;/code&gt;
    &lt;p&gt;I've yet to try other agents. If you get another agent running, I'd love to hear about it. Maybe submit a pull request?&lt;/p&gt;
    &lt;p&gt;While I've been relying on my acp.el client library, I'm still fairly new to the protocol. I often inspect traffic to see what's going on. After staring at json for far too long, I figured I may as well build some tooling around acp.el to make my life easier. I added a traffic buffer for that. From &lt;code&gt;agent-shell&lt;/code&gt;, you can invoke it via &lt;code&gt;M-x agent-shell-view-traffic&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Developing &lt;code&gt;agent-shell&lt;/code&gt; against paid agents got expensive quickly. Not only expensive, but my edit-compile-run cycle also became boringly slow waiting for agents. While I knew I wanted some sort of fake agent to work against, I didn't want to craft the fake traffic myself. Remember that traffic buffer I showed ya? Well, I can now save that traffic to disk and replay it later. This enabled me to run problematic sessions once and quickly replay multiple times to fix things. While re-playing has its quirks and limitations, it's done the job for now.&lt;/p&gt;
    &lt;p&gt;You can see a Claude Code session below, followed by its replayed counterpart via fake infrastructure.&lt;/p&gt;
    &lt;p&gt;Getting here took quite a bit of work. Having said that, it's only a start. I myself need to get more familiar with agent usage and evolve the package UX however it feels most natural within its new habitat. Lately, I've been experimenting with a quick diff buffer, driven by n/p keys, shown along the permission dialog.&lt;/p&gt;
    &lt;code&gt;#+ATTR_HTML: :width 99%
&lt;/code&gt;
    &lt;p&gt;While I've implemented enough parts of the Agent Client Protocol Schema to make the package useful, it's hardly complete. I've yet to fully familiarize myself with most protocol features.&lt;/p&gt;
    &lt;p&gt;Both of my new Emacs packages, agent-shell and acp.el, are now available on GitHub. As an agent user, go straight to agent-shell. If you're a package author and would like to build an ACP experience, then give acp.el a try. Both packages are brand new and may have rough edges. Be sure to file bugs or feature requests as needed.&lt;/p&gt;
    &lt;p&gt;I've been heads down, working on these packages for some time. If you're using cloud LLM services, you're likely already paying for tokens. If you find my work useful, please consider routing some of those coins to help fund it. Maybe my tools make you more productive at work? Ask your employer to support the work. These packages not only take time and effort, but also cost me money. Help fund the work.&lt;/p&gt;
    &lt;p&gt;powered by LMNO.lol&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xenodium.com/introducing-agent-shell"/><published>2025-10-12T20:37:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566123</id><title>LaTeXpOsEd: A Systematic Analysis of Information Leakage in Preprint Archives</title><updated>2025-10-13T16:12:37.781658+00:00</updated><content>&lt;doc fingerprint="ad9eb10045f3128f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Cryptography and Security&lt;/head&gt;&lt;p&gt; [Submitted on 4 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:You Have Been LaTeXpOsEd: A Systematic Analysis of Information Leakage in Preprint Archives Using Large Language Models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The widespread use of preprint repositories such as arXiv has accelerated the communication of scientific results but also introduced overlooked security risks. Beyond PDFs, these platforms provide unrestricted access to original source materials, including LaTeX sources, auxiliary code, figures, and embedded comments. In the absence of sanitization, submissions may disclose sensitive information that adversaries can harvest using open-source intelligence. In this work, we present the first large-scale security audit of preprint archives, analyzing more than 1.2 TB of source data from 100,000 arXiv submissions. We introduce LaTeXpOsEd, a four-stage framework that integrates pattern matching, logical filtering, traditional harvesting techniques, and large language models (LLMs) to uncover hidden disclosures within non-referenced files and LaTeX comments. To evaluate LLMs' secret-detection capabilities, we introduce LLMSec-DB, a benchmark on which we tested 25 state-of-the-art models. Our analysis uncovered thousands of PII leaks, GPS-tagged EXIF files, publicly available Google Drive and Dropbox folders, editable private SharePoint links, exposed GitHub and Google credentials, and cloud API keys. We also uncovered confidential author communications, internal disagreements, and conference submission credentials, exposing information that poses serious reputational risks to both researchers and institutions. We urge the research community and repository operators to take immediate action to close these hidden security gaps. To support open science, we release all scripts and methods from this study but withhold sensitive findings that could be misused, in line with ethical principles. The source code and related material are available at the project website this https URL&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.03761"/><published>2025-10-13T08:33:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566139</id><title>Spotlight on pdfly, the Swiss Army knife for PDF files</title><updated>2025-10-13T16:12:36.668581+00:00</updated><content>&lt;doc fingerprint="d2c16a62e09737b0"&gt;
  &lt;main&gt;
    &lt;p&gt;Project documentation: pdfly.readthedocs.io&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pdfly&lt;/code&gt; is the youngest project of the &lt;code&gt;py-pdf&lt;/code&gt; organization.
It has been created by Martin Thoma in 2022.&lt;/p&gt;
    &lt;p&gt;It's simply a CLI tool to manipulate PDF files, written in Python and based on the fpdf2 &amp;amp; pypdf libraries.&lt;/p&gt;
    &lt;p&gt;I'm a maintainer of the project ğŸ™‚&lt;/p&gt;
    &lt;head rend="h2"&gt;What can it do?&lt;/head&gt;
    &lt;p&gt;It has meany features, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;display PDF metadata using &lt;code&gt;pdfly meta&lt;/code&gt;and&lt;code&gt;pdfly pagemeta&lt;/code&gt;commands. Example:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;$ pdfly meta minimal-document.pdf
                      Operating System Data
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ         Attribute â”ƒ Value                     â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚         File Name â”‚ /tmp/minimal-document.pdf â”‚
â”‚  File Permissions â”‚ -rw-r--r--                â”‚
â”‚         File Size â”‚ 16,978 bytes              â”‚
â”‚     Creation Time â”‚ 2025-10-13 09:44:32       â”‚
â”‚ Modification Time â”‚ 2025-10-13 09:44:32       â”‚
â”‚       Access Time â”‚ 2025-10-13 09:44:46       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       PDF Data
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ          Attribute â”ƒ Value                                                    â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚       CreationDate â”‚ 2022-04-03 18:05:42+02:00                                â”‚
â”‚            Creator â”‚ TeX                                                      â”‚
â”‚           Producer â”‚ pdfTeX-1.40.23                                           â”‚
â”‚              Pages â”‚ 1                                                        â”‚
â”‚          Encrypted â”‚ None                                                     â”‚
â”‚   PDF File Version â”‚ %PDF-1.5                                                 â”‚
â”‚        Page Layout â”‚                                                          â”‚
â”‚          Page Mode â”‚                                                          â”‚
â”‚             PDF ID â”‚ ID1=b'q\x96\xc3\xe3U\xc1|\x9fS\xba\x9a\r\xcap\xcd\xd0'   â”‚
â”‚                    â”‚ ID2=b'q\x96\xc3\xe3U\xc1|\x9fS\xba\x9a\r\xcap\xcd\xd0'   â”‚
â”‚ Fonts (embedded) â”‚                                                          â”‚
â”‚   Fonts (embedded) â”‚ /KNEUFH+CMR10                                            â”‚
â”‚        Attachments â”‚ []                                                       â”‚
â”‚             Images â”‚ 0 images (0 bytes)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;pdfly&lt;/code&gt;can also combine files into new PDF documents: it can extract specific pages &amp;amp; merge documents (&lt;code&gt;pdfly cat&lt;/code&gt;); selectively remove pages (&lt;code&gt;pdfly rm&lt;/code&gt;); convert images to PDF documents (&lt;code&gt;pdfly x2pdf&lt;/code&gt;); and even compress documents (&lt;code&gt;pdfly compress&lt;/code&gt;) or build booklets (&lt;code&gt;pdfly 2-up&lt;/code&gt;&amp;amp;&lt;code&gt;pdfly booklet&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pdfly&lt;/code&gt;includes some commands to pull out specific content from PDF files:&lt;code&gt;pdfly extract-images&lt;/code&gt;&amp;amp;&lt;code&gt;pdfly extract-annotated-text&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;sometimes you want to edit a PDF file manually, in a text editor. But when you do so, you break its&lt;/p&gt;&lt;code&gt;xref&lt;/code&gt;table, that is an index of byte offsets in the document.&lt;code&gt;pdfly update-offsets&lt;/code&gt;is there to save the day, fixing manually-edited PDF documents, so that they can be opened in a PDF viewer again!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Release 0.5.0 &amp;amp; new features&lt;/head&gt;
    &lt;p&gt;Today we released a new version: &lt;code&gt;pdfly release 0.5.0&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Thanks to several contributors, including developers taking part in Hacktoberfest, new exciting features have been added:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;pdfly sign&lt;/code&gt;allows you to easily sign PDF documents, while&lt;code&gt;pdfly check-sign&lt;/code&gt;makes it easy to check a PDF document signature. Thanks to @moormaster for implementing this in PRs #165 &amp;amp; #166 ğŸ‘ğŸ™.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pdfly extract-annotated-pages&lt;/code&gt;extract only annotated pages from a PDF, hence helping to review or rework pages from a large document iteratively. Thanks to Hal Wine (@hwine) for implementing this in PR #128 ğŸ‘ğŸ™.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pdfly rotate&lt;/code&gt;rotate specific pages of a document. Thanks to Subhajit Sahu (@wolfram77) for implementing this in PR #98 ğŸ‘ğŸ™.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What's next?&lt;/head&gt;
    &lt;p&gt;We have a bunch of feature ideas: &lt;code&gt;up-for-grabs&lt;/code&gt; issues, including some &lt;code&gt;good first issues&lt;/code&gt; aimed specially at new contributors, that are willing to help but new to open-source.&lt;/p&gt;
    &lt;p&gt;Personally, I think the &lt;code&gt;pdfly sign&lt;/code&gt; &amp;amp; &lt;code&gt;check-sign&lt;/code&gt; could become handy to many end-users, and I think we should continue to extend those commands usage options, as described in issue #71.&lt;/p&gt;
    &lt;p&gt;We would also be happy to get your feedbacks, bug reports &amp;amp; feature suggestions! ğŸ™‚&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chezsoi.org/lucas/blog/spotlight-on-pdfly.html"/><published>2025-10-13T08:36:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566253</id><title>Some graphene firms have reaped its potential but others are struggling</title><updated>2025-10-13T16:12:36.583607+00:00</updated><content>&lt;doc fingerprint="6088806b0f7d57fb"&gt;
  &lt;main&gt;
    &lt;p&gt;After graphene was first produced at the University of Manchester in 2004, it was hailed as a wonder material, stronger than steel but lighter than paper. But two decades on, not every UK graphene company has made the most of that potential. Some show promise but others are struggling.&lt;/p&gt;
    &lt;p&gt;Extracted from graphite, commonly used in pencils, graphene is a latticed sheet of carbon one atom thick, and is highly effective at conducting heat and electricity. China is the worldâ€™s biggest producer, using it to try to get ahead in the global race to produce microchips and in sectors such as construction.&lt;/p&gt;
    &lt;p&gt;In the UK, a graphene-enhanced, low-carbon concrete was laid at a Northumbrian Water site in July, developed by the Graphene Engineering Innovation Centre (GEIC) at the University of Manchester and Cemex UK.&lt;/p&gt;
    &lt;p&gt;â€œThe material when it came out of academia was hyped to death â€¦ but the challenge is going from lab to fab,â€ says Ben Jensen, the chief executive of 2D Photonics, a startup spun out from the University of Cambridge that makes graphene-based photonic technology for datacentres.&lt;/p&gt;
    &lt;p&gt;Jensen also invented Vantablack coatings, made of carbon nanotubes â€“ rolled-up sheets of graphene â€“ and known as the worldâ€™s â€œblackest blackâ€ because it absorbs 99.96% of light, at the UK company Surrey NanoSystems that he founded in 2007. The materialâ€™s artistic rights were sold exclusively to the sculptor Anish Kapoor, and BMW used it on its X6 coupe to create the â€œblackest black carâ€ six years ago.&lt;/p&gt;
    &lt;p&gt;â€œThis is the challenge when you have new materials trying to displace an incumbent technology,â€ Jensen says. â€œThe value proposition must be extremely good, but there also must be a way to manufacture the material and manufacture it at scale for the application â€¦ then you have to meet price expectations because thereâ€™s no point in delivering something thatâ€™s costing 10 times more than the incumbent.â€&lt;/p&gt;
    &lt;p&gt;Germanyâ€™s Bayer tried to produce carbon nanotube products in bulk but shut down its pilot factory more than a decade ago after the expected surge in demand failed to materialise. The material is now mainly used as a filler to strengthen plastic products. The company described the potential applications of nanotubes as â€œfragmentedâ€.&lt;/p&gt;
    &lt;p&gt;More promising are the graphene-based optical microchips developed by 2D Photonicsâ€™ subsidiary CamGraPhIC, which are based on research done at the University of Cambridge and Italyâ€™s CNIT research institute.&lt;/p&gt;
    &lt;p&gt;At the moment, silicon-photonics microchips convert electrical data into optical data to transmit it through fibre-optic cables, but the firm says its graphene chips deliver more data in the same period of time and at far lower cost.&lt;/p&gt;
    &lt;p&gt;They consume 80% less energy and can operate in a much wider range of temperatures, reducing the need for costly water- and energy-hungry cooling systems for AI datacentres.&lt;/p&gt;
    &lt;p&gt;Sending data via silicon also causes delays. Jensen compares it to a 16-lane motorway that suddenly narrows to a single lane because of roadworks, forcing everything to slow down. Graphene photonics, he says, are like a motorway with hundreds of lanes.&lt;/p&gt;
    &lt;p&gt;â€œWhat weâ€™ve solved is the ability to grow consistent ultra high-performance graphene and to build it into a device,â€ he says. â€œAnd donâ€™t forget, this is a material thatâ€™s one atom thick. Itâ€™s insanely difficult to do this.â€&lt;/p&gt;
    &lt;p&gt;CamGraPhIC was founded in 2018 by the Cambridge nanotechnology professor Andrea Ferrari, who also runs the Cambridge graphene centre, and Marco Romagnoli, who leads advanced photonics at CNIT in Pisa and is the startupâ€™s chief scientific officer.&lt;/p&gt;
    &lt;p&gt;Its parent, 2D Photonics, has just secured funding of Â£25m from backers including Italyâ€™s sovereign wealth fund, Nato and Sony innovation funds, Bosch Ventures and the UKâ€™s Frontier IP Group, and uses a former Pirelli photonics research site in Pisa. It plans to create a pilot manufacturing site in the Milan area to produce 200mm-wide wafers at scale, and is confident of obtaining the necessary funding of â‚¬317m (Â£276m) by the end of the year.&lt;/p&gt;
    &lt;p&gt;Aside from datacentres, the companyâ€™s chips can be used in high-performance computing, 5G and 6G mobile data systems, aircraft systems, autonomous cars, advanced digital radar and satellite-free space communications.&lt;/p&gt;
    &lt;p&gt;Paragraf, a University of Cambridge spinout based in the nearby village of Somersham, has also fared well over the past decade with backing from the UK Treasury. It produces graphene-based electronic devices, including sensors for electric cars, and biosensors for the early detection of disease and other uses in healthcare and agriculture. It recently secured $55m (Â£41m) from investors including the United Arab Emirates sovereign wealth fund, which took a 12.8% stake in Paragraf.&lt;/p&gt;
    &lt;p&gt;A more recent startup, Graphene Innovations Manchester, launched in 2021 by Vivek Koncherry, struck a deal with Saudi Arabia last December for the worldâ€™s first commercial production of graphene-enriched carbon fibre, used in construction for roofs and facades, as well as street light poles. It has started making it in Tabuk with a local partner, and says it is on track to produce 3,000 tonnes by 2026.&lt;/p&gt;
    &lt;p&gt;Other businesses, however, have found the going tougher. One of the sectorâ€™s first companies was Applied Graphene Materials, founded by Prof Karl Coleman in 2010 and spun out from Durham University. It launched a number of products including an anti-corrosion primer and a protective bike-detailing spray, which made it on to the shelves in Halfords. But the loss-making enterprise was wound down in 2023 and Canadaâ€™s Universal Matter acquired its main business.&lt;/p&gt;
    &lt;p&gt;Ron Mertens, the owner of the website Graphene-Info, says: â€œAs is true in the wider materials industry, things take a very long time to reach the market. Many graphene producers and developers never managed to generate meaningful revenues or become profitable.â€&lt;/p&gt;
    &lt;p&gt;The Gloucestershire-based Versarien grew from a garage startup in 2010. Supported by Innovate UK, a government agency, it has developed graphene powders and other products for use in sensors, low-carbon concrete, paints, inks for electronics and textiles such as Umbro running gear and prototype stealth materials for the US military.&lt;/p&gt;
    &lt;p&gt;The Aim-listed company expanded into Spain and South Korea but ran into financial difficulties and was forced to place several subsidiaries in administration or voluntary liquidation in July. Versarien has been seeking to sell its assets, including its patent portfolio, and only has enough cash to keep going until the end of October.&lt;/p&gt;
    &lt;p&gt;Depending on the deal, it may undertake a solvent liquidation of the company or become a cash shell. An investment deal with a Chinese partner collapsed after the UK government intervened to block any collaboration on technology. It would be a sad end for a once promising graphene business.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/business/2025/oct/13/lab-to-fab-are-promises-of-a-graphene-revolution-finally-coming-true"/><published>2025-10-13T08:53:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566441</id><title>MPTCP for Linux</title><updated>2025-10-13T16:12:36.364300+00:00</updated><content>&lt;doc fingerprint="a7b5e91a5cbdcba9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Multipath TCP or MPTCP is an extension to the standard TCP and is described in RFC 8684. It allows a device to make use of multiple interfaces at once to send and receive TCP packets over a single MPTCP connection. MPTCP can aggregate the bandwidth of multiple interfaces or prefer the one with the lowest latency. It also allows a fail-over if one path is down, and the traffic is seamlessly reinjected on other paths.&lt;/p&gt;
    &lt;code&gt;graph TD;
    subgraph MPTCP
        direction LR
        C_1(&amp;lt;div style="display: inline-block; min-width: 32px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
        S_1((&amp;lt;div style="display: inline-block; min-width: 55px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))
    end

    subgraph TCP
        direction LR
        C_2(&amp;lt;div style="display: inline-block; min-width: 32px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
        S_2((&amp;lt;div style="display: inline-block; min-width: 55px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))
    end

    C_1 &amp;lt;== "5G" ==&amp;gt; S_1
    C_1 &amp;lt;== "Wi-Fi&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Multiple paths (&amp;lt;i&amp;gt;subflows&amp;lt;/i&amp;gt;)&amp;lt;br /&amp;gt;at the same time" ==&amp;gt; S_1

    C_2 x-. "5G" .-x S_2
    C_2 &amp;lt;== "Wi-Fi&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;One path at a time" ==&amp;gt; S_2

    linkStyle 0 stroke:green;
    linkStyle 1 stroke:green;
    linkStyle 2 stroke:red;
    linkStyle 3 stroke:green;
&lt;/code&gt;
    &lt;head rend="h3"&gt;Use cases&lt;/head&gt;
    &lt;p&gt;Thanks to MPTCP, being able to use multiple paths in parallel or simultaneously brings new use-cases, compared to TCP:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seamless handovers: switching from one path to another while preserving established connections, e.g. Apple is using Multipath TCP on smartphones mainly for this reason since 2013.&lt;/item&gt;
      &lt;item&gt;Best network selection: using the â€œbestâ€ available path depending on some conditions, e.g. latency, losses, cost, bandwidth, etc.&lt;/item&gt;
      &lt;item&gt;Network aggregation: using multiple paths at the same time to have a higher throughput, e.g. to combine fixed and mobile networks to send files faster.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Concepts&lt;/head&gt;
    &lt;p&gt;Technically, when a new socket is created with the &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; protocol (Linux-specific), a subflow (or path) is created. This subflow consists of a regular TCP connection that is used to transmit data through one interface. Additional subflows can be negotiated later between the hosts. For the remote host to be able to detect the use of MPTCP, a new field is added to the TCP option field of the underlying TCP subflow. This field contains, amongst other things, a &lt;code&gt;MP_CAPABLE&lt;/code&gt; option that tells the other host to use MPTCP if it is supported. If the remote host or any middlebox in between does not support it, the returned &lt;code&gt;SYN+ACK&lt;/code&gt; packet will not contain MPTCP options in the TCP option field. In that case, the connection will be â€œdowngradedâ€ to plain TCP, and it will continue with a single path.&lt;/p&gt;
    &lt;p&gt;This behavior is made possible by two internal components: the path manager, and the packet scheduler.&lt;/p&gt;
    &lt;head rend="h3"&gt;Path Manager&lt;/head&gt;
    &lt;p&gt;The Path Manager is in charge of subflows, from creation to deletion, and also address announcements. Typically, it is the client side that initiates subflows, and the server side that announces additional addresses via the &lt;code&gt;ADD_ADDR&lt;/code&gt; and &lt;code&gt;REMOVE_ADDR&lt;/code&gt; options.&lt;/p&gt;
    &lt;code&gt;graph LR;
    C_1(&amp;lt;div style="display: inline-block; min-width: 35px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
    S_1((&amp;lt;div style="display: inline-block; min-width: 60px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))

    C_1 -. "Potential subflow" -.- S_1
    C_1 &amp;lt;== "Initial subflow" ==&amp;gt; S_1
    C_1 ~~~|"Subflows creation"| C_1
    S_1 ~~~|"Addresses announcement"| S_1

    linkStyle 0 stroke:orange;
    linkStyle 1 stroke:green;
&lt;/code&gt;
    &lt;p&gt;As of Linux v5.19, there are two path managers, controlled by the &lt;code&gt;net.mptcp.pm_type&lt;/code&gt; sysctl knob: the in-kernel one (type &lt;code&gt;0&lt;/code&gt;) where the same rules are applied for all the connections (see: &lt;code&gt;ip mptcp&lt;/code&gt;) ; and the userspace one (type &lt;code&gt;1&lt;/code&gt;), controlled by a userspace daemon (i.e. &lt;code&gt;mptcpd&lt;/code&gt;) where different rules can be applied for each connection.&lt;/p&gt;
    &lt;head rend="h3"&gt;Packet Scheduler&lt;/head&gt;
    &lt;p&gt;The Packet Scheduler is in charge of selecting which available subflow(s) to use to send the next data packet. It can decide to maximize the use of the available bandwidth, only to pick the path with the lower latency, or any other policy depending on the configuration.&lt;/p&gt;
    &lt;code&gt;graph LR;
    A_2(&amp;lt;div style="display: inline-block; min-width: 40px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-user&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)

    PS{Packet&amp;lt;br /&amp;gt;Scheduler}

    I_21(subflow 1)
    I_22(subflow 2)

    A_2 == "&amp;lt;div style='display: inline-block; min-width: 50px'&amp;gt;fa:fa-box fa:fa-box fa:fa-box&amp;lt;/div&amp;gt;" ==&amp;gt; PS
    PS -- "&amp;lt;div style='display: inline-block; min-width: 32px'&amp;gt;fa:fa-box fa:fa-box&amp;lt;/div&amp;gt;" --&amp;gt; I_21
    PS -- "&amp;lt;div style='display: inline-block; min-width: 14px'&amp;gt;fa:fa-box&amp;lt;/div&amp;gt;" --&amp;gt; I_22
    PS ~~~|"Packets distribution between subflows"| PS
&lt;/code&gt;
    &lt;p&gt;As of Linux v6.8, there is only one packet scheduler, controlled by sysctl knobs in &lt;code&gt;net.mptcp&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;p&gt;As of Linux v6.10, major features of MPTCP include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support of the &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;protocol in&lt;code&gt;socket()&lt;/code&gt;system calls.&lt;/item&gt;
      &lt;item&gt;Fallback from MPTCP to TCP if the peer or a middlebox do not support MPTCP.&lt;/item&gt;
      &lt;item&gt;Path management using either an in-kernel or userspace path manager.&lt;/item&gt;
      &lt;item&gt;Socket options that are commonly used with TCP sockets.&lt;/item&gt;
      &lt;item&gt;Debug features including MIB counters, diag support (used by the &lt;code&gt;ss&lt;/code&gt;command), and tracepoints.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the ChangeLog for more details.&lt;/p&gt;
    &lt;head rend="h2"&gt;Communication&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mailing List: mptcp@lists.linux.dev (plain text only): &lt;list rend="ul"&gt;&lt;item&gt;Archives&lt;/item&gt;&lt;item&gt;Info&lt;/item&gt;&lt;item&gt;Subscribe by sending an empty email in plain text to mptcp+subscribe@lists.linux.dev, and by replying to the challenge email.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;IRC: #mptcp on libera.chat&lt;/item&gt;
      &lt;item&gt;Online Meetings&lt;/item&gt;
      &lt;item&gt;Blog&lt;/item&gt;
      &lt;item&gt;Fediverse&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Projects&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Maintained by MPTCP community members&lt;/item&gt;
      &lt;item&gt;Projects with MPTCP-related enhancements &lt;list rend="ul"&gt;&lt;item&gt;iproute2 (for the &lt;code&gt;ip mptcp&lt;/code&gt;command)&lt;/item&gt;&lt;item&gt;Network Manager: MPTCP features are included starting with v1.40.&lt;/item&gt;&lt;item&gt;Multipath TCP applications: A project to coordinate MPTCP updates for popular TCP applications.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;iproute2 (for the &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mptcp.dev/"/><published>2025-10-13T09:25:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566532</id><title>gsay: Fetch pronunciation of English vocabulary from Google</title><updated>2025-10-13T16:12:35.887346+00:00</updated><content>&lt;doc fingerprint="3e4abc7abbb2734a"&gt;
  &lt;main&gt;
    &lt;p&gt;A simple shell script to fetch pronunciation of an English word from Google.&lt;/p&gt;
    &lt;p&gt;When you search for an Enlgish vocabulary, Google shows a pronunciation in an "answer box" at top of the page. This script fetches that hopefully human-made mp3 sound file.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Query for 2020 and 2024 sound files&lt;/item&gt;
      &lt;item&gt;Support British and American accents&lt;/item&gt;
      &lt;item&gt;Cache to disk (enabled by default)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;curl&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ffplay | mpv | pw-play&lt;/code&gt;: A headless mp3 player, one is enough&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a Debian-like distro, these can be installed with:&lt;/p&gt;
    &lt;code&gt;sudo apt install curl ffmpeg # or mpv&lt;/code&gt;
    &lt;p&gt;Check &lt;code&gt;gsay -h&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;Usage: gsay [OPTIONS] QUERY
DESCRIPTION
    A simple client to fetch/play pronounciation of words from Google

ARGUMENTS
     QUERY
        Query string
        Note: Use "" or '' if query string contains special shell characters
OPTIONS
    [--year | -y]
        Set desired database year: 2020 (default) | 2024
    [--accent | -a]
        Set desired accent: gb (default) | us
    [--link | -l]
        Only print pronounciation link. Don't play their audio
    [--no-cache | -n]
        Disable cache mode: ignore cache and don't save to cache directory
        Default: cache mode is enabled. dir: /home/username/.cache/gsay
    [--debug | -v]
        Increase log verbosity to debug
    [--version | -V]
        Print version
    [--help | -h]
        Display the help message

EXAMPLES
    gsay legend
    gsay -y 2024 -a us Leicester
    gsay -n -y 2020 -a gb Forte
    gsay Pneumonoultramicroscopicsilicovolcanoconiosis
    gsay -l perfect
    gsay carte blanche&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I may be wrong but the &lt;code&gt;2024/04/19&lt;/code&gt;pronounciations sound synthetic to me! Hence,&lt;code&gt;2020/04/29&lt;/code&gt;is default despite being slower and less exhaustive. Caller scripts can run it like&lt;code&gt;gsay -y 2020 || gsay -y 2024&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;The HTTP URLs are faster, HTTPS ones are provided as comments too&lt;/item&gt;
      &lt;item&gt;Fun examples: &lt;code&gt;echo Supercalifragilisticexpialidocious Antidisestablishmentarianism Grandiloquent | xargs -n1 gsay&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Oxford 3000 word list pronunciations, limited to first 1000 words, can be downloaded (cached) to disk like this:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;curl -sL https://github.com/sapbmw/The-Oxford-3000/raw/refs/heads/master/The_Oxford_3000.txt \
    | tr -d '\r' | head -1000 | xargs -I {} gsay -l "{}"&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The early versions of this script supported a scraping mode besides the current heuristic mode. But, recently Google has been preventing scrapers from accessing its search results page. I tested their "Custom Search JSON API" from "Programmable Search Engine", but it doesn't provide the output from Answer Box that contains pronounciations&lt;/item&gt;
      &lt;item&gt;linter: &lt;code&gt;shellcheck&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;formatter: &lt;code&gt;shfmt -i 4 -bn -ci -sr&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/pvonmoradi/gsay"/><published>2025-10-13T09:39:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566548</id><title>Modern Linux tools</title><updated>2025-10-13T16:12:35.647175+00:00</updated><content>&lt;doc fingerprint="3248c1cd4e981f8f"&gt;
  &lt;main&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;bat&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;&lt;code&gt;cat&lt;/code&gt; clone with syntax highlighting and &lt;code&gt;git&lt;/code&gt; integration&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;exa&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;modern replacement for &lt;code&gt;ls&lt;/code&gt;/&lt;code&gt;tree&lt;/code&gt;, not maintained&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;eza&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;modern &lt;code&gt;ls&lt;/code&gt;/&lt;code&gt;tree&lt;/code&gt; based on &lt;code&gt;exa&lt;/code&gt; fork&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;lsd&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;next gen &lt;code&gt;ls&lt;/code&gt;, backwards compatible&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;delta&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;viewer for &lt;code&gt;git&lt;/code&gt; and &lt;code&gt;diff&lt;/code&gt; output&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;ncdu&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;intuitive &lt;code&gt;du&lt;/code&gt; with ncurses interface&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;dust&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;more intuitive version of &lt;code&gt;du&lt;/code&gt; written in rust&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;duf&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;better &lt;code&gt;df&lt;/code&gt; alternative&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;broot&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;better &lt;code&gt;tree&lt;/code&gt; with navigation support&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;fd&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;simple, fast and user-friendly alternative to &lt;code&gt;find&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;ripgrep&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;extremely fast alternative to &lt;code&gt;grep&lt;/code&gt; that respects your gitignore&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;ag&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;code searching tool similar to &lt;code&gt;ack&lt;/code&gt;, but faster&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;fzf&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;general purpose command-line fuzzy &lt;code&gt;find&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;bfs&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;breadth-first &lt;code&gt;find&lt;/code&gt; alternative&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;mcfly&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;fly through your shell &lt;code&gt;history&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;choose&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;human-friendly and fast alternative to &lt;code&gt;cut&lt;/code&gt; and (sometimes) &lt;code&gt;awk&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;jq&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;&lt;code&gt;sed&lt;/code&gt; for JSON data&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;sd&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;intuitive find/replace CLI. &lt;code&gt;sed&lt;/code&gt; alternative&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;bottom&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;another cross-platform graphical process/system monitor&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;glances&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;&lt;code&gt;top&lt;/code&gt;/&lt;code&gt;htop&lt;/code&gt; alternative&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;gtop&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;System monitoring dashboard for terminal&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;hyperfine&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;command-line benchmarking tool&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;gping&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;&lt;code&gt;ping&lt;/code&gt; with a graph&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;procs&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;&lt;code&gt;ps&lt;/code&gt; rust replacement&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;httpie&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;modern, user-friendly command-line HTTP client for the API era&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;curlie&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;power of &lt;code&gt;curl&lt;/code&gt;, the ease of use of &lt;code&gt;httpie&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;xh&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;performance focused alternative of &lt;code&gt;httpie&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;zoxide&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;smarter &lt;code&gt;cd&lt;/code&gt; command inspired by &lt;code&gt;z&lt;/code&gt;&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;micro&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;modern terminal text editor&lt;/cell&gt;
    &lt;/row&gt;
    &lt;row&gt;
      &lt;cell&gt;
        &lt;code&gt;nnn&lt;/code&gt;
      &lt;/cell&gt;
      &lt;cell&gt;fast lean terminal file manager&lt;/cell&gt;
    &lt;/row&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ikrima.dev/dev-notes/linux/linux-modern-tools/"/><published>2025-10-13T09:44:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566660</id><title>Two Paths to Memory Safety: CHERI and OMA</title><updated>2025-10-13T16:12:35.464141+00:00</updated><content>&lt;doc fingerprint="a4eb1c9974b7e359"&gt;
  &lt;main&gt;
    &lt;p&gt;The last year has been brutal for businesses globally. Taking examples from my home country, the UK, the cost is over Â£1B and still rising, as well as the loss of at least one life due to cybercrime.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Marks &amp;amp; Spencer lost Â£300M when ransomware crippled its systems for weeks.&lt;/item&gt;
      &lt;item&gt;The Co-op suffered a related attack, losing over Â£200M in sales and the customer data of more than 20 million people.&lt;/item&gt;
      &lt;item&gt;Jaguar Land Roverâ€™s assembly lines have been shut down for weeks, haemorrhaging Â£70M per week and requiring a Â£1.5B loan secured by the government.&lt;/item&gt;
      &lt;item&gt;Transport for Londonâ€™s systems were compromised, with the ensuing disruption lasting months, costing Â£39mn and exposing 5,000 customersâ€™ banking details. Two teenagers are being prosecuted for the attack.&lt;/item&gt;
      &lt;item&gt;Most tragically, a patient at Kingâ€™s College Hospital died after ransomware delayed critical blood test results. Speaking to friends that were sat in meetings to decide who got blood tests each day, the human toll was evident. Cyberattacks arenâ€™t just about money!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These arenâ€™t isolated incidents - theyâ€™re symptoms of a systemic vulnerability in how we build computer systems.&lt;/p&gt;
    &lt;p&gt;According to the Verizon 2025 Data Breach Investigations Report, credential abuse and exploitation of vulnerabilities continue to dominate as attack vectors, accounting for 22% and 20% of breaches respectively. The exploitation of vulnerabilities saw a 34% surge year-over-year, creating what Verizon describes as a â€œconcerning threat landscapeâ€.&lt;/p&gt;
    &lt;p&gt;Weâ€™re yet to learn the root causes and attack chains involved in each of the examples above, but many involved ransomware, which frequently uses software exploits as a post-initial-access vector to gain control of target systems and spread across a network.&lt;/p&gt;
    &lt;p&gt;Hereâ€™s the kicker: approximately 70% of all software vulnerabilities stem from a single root cause - memory safety issues. This isnâ€™t a new problem. Google, Microsoft, Apple, Mozilla and the Linux Foundation have all reported similar figures for their software over the last two decades. The uncomfortable truth is that current CPUs are fundamentally incapable of preventing these vulnerabilities, and traditional software patches have proven woefully inadequate.&lt;/p&gt;
    &lt;p&gt;Rewriting all the worldâ€™s software into memory safe languages, such as C#, Java and Rust, is unviable. While new projects may be adopting Rust over C/C++, and some critical components are being rewritten into safe languages, the scale and depth of the C and C++ ecosystems makes it practically impossible to rewrite all the worldâ€™s unsafe software. The risk of introducing other (non-memory-safety) issues during a software rewrite also poses a substantial barrier. Given sufficient software compatibility, it is actually easier to swap the hardware!&lt;/p&gt;
    &lt;p&gt;Two architectural approaches have emerged to tackle this trillion-dollar problem at the hardware level:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CHERI: Capability Hardware Enhanced RISC Instructions - pioneered at University of Cambridge (UK), and&lt;/item&gt;
      &lt;item&gt;OMA: Object Memory Architecture - pioneered at University of Bristol (UK) and now being commercialised by Doubtless Computing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both aim to make memory-unsafe systems safe-by-design but they take different paths to get there. Understanding these differences matters because the choice between them will shape the security and performance characteristics of computing for decades to come.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Memory Safety Crisis&lt;/head&gt;
    &lt;p&gt;Before diving into solutions, itâ€™s worth understanding what weâ€™re solving. When software runs, it constantly allocates and deallocates memory - think of it like booking rooms in a hotel. Memory safety vulnerabilities arise when this process goes wrong. If you stay in the same hotel twice, you shouldnâ€™t be able to access your old room even if you remember the number (use-after-free/ use-after-reallocate). Similarly, you shouldnâ€™t be able to enter a neighbouring room (buffer overflow), or use a room without booking one in the first place (invalid pointer dereference). Software has these same problems with memory allocations (room bookings).&lt;/p&gt;
    &lt;p&gt;These bugs become catastrophic vulnerabilities when attackers exploit them to read sensitive data they shouldnâ€™t access, manipulate critical system variables, or inject malicious code. The underlying architecture of todayâ€™s processors - paging-based virtual memory - lacks the granularity needed to enforce security within a single application or process.&lt;/p&gt;
    &lt;p&gt;Memory safety breaks down into three categories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Referential safety ensures pointers genuinely reference allocated memory and canâ€™t be forged. Think of it as ensuring software has a valid booking for a room, ensuring accesses to memory are authorized, and that bookings canâ€™t be faked.&lt;/item&gt;
      &lt;item&gt;Spatial safety prevents accessing memory outside allocated bounds - no going into neighbouring rooms.&lt;/item&gt;
      &lt;item&gt;Temporal safety addresses what happens over time, ensuring memory canâ€™t be accessed after itâ€™s been freed and reallocated. In our hotel analogy, a second stay at the hotel shouldnâ€™t allow you to access your previous room, even if you remember the room number.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Traditional architectures like x86, Arm, and RISC-V rely on coarse-grained page-level protection (typically 4KB or larger pages), which is far too blunt an instrument for modern security needs.&lt;/p&gt;
    &lt;head rend="h2"&gt;CHERI: Capabilities Meet Legacy Systems&lt;/head&gt;
    &lt;p&gt;CHERI, developed over more than a decade by the University of Cambridge and SRI International, extends conventional instruction set architectures with hardware-enforced capabilities. A CHERI capability is a form of fat pointer - it contains not just a memory address but also bounds information, permissions, and validity metadata. Every memory access gets checked against these constraints in hardware, catching violations before they can be exploited.&lt;/p&gt;
    &lt;p&gt;The architecture provides strong referential and spatial safety guarantees. When you have a CHERI capability, you provably have legitimate access to a specific bounded region of memory, and the hardware wonâ€™t let you stray outside those bounds. CHERI achieves this while maintaining compatibility with existing paged memory architectures, which is both its greatest strength and a source of limitations.&lt;/p&gt;
    &lt;p&gt;Hereâ€™s where it gets interesting: CHERIâ€™s capabilities are large. On a 64-bit system, a CHERI pointer requires 129 bits (including the hidden tag bit) - essentially double the data width of the base architecture. This decision to encode all protection metadata within the pointer itself has profound implications. Every data structure that stores pointers effectively doubles in memory consumption for those fields. Capabilities in memory (stack/heap) must be aligned to natural 128-bit boundaries. Cache lines, which are precious and limited, now hold fewer actual pointers. Memory bandwidth requirements increase because for each pointer youâ€™re moving twice as much data around.&lt;/p&gt;
    &lt;p&gt;CHERI provides hardware-enforced referential and spatial safety but leaves temporal safety to software. You can achieve temporal memory safety with CHERI, but it requires modifying your memory allocator and implementing pointer revocation mechanisms - essentially software to scan memory to find and invalidate stale pointers. This software-based approach to temporal safety remains part of the trusted computing base and requires careful verification. Itâ€™s also closely related to software garbage collection.&lt;/p&gt;
    &lt;p&gt;Research has explored various temporal safety mechanisms for CHERI, but they all involve non-trivial software complexity and performance overhead. In theory, hardware acceleration may be possible but is likely to always require software involvement. This is because a CHERI capability covers a range of memory, which may include more than one object. Software allocation and object type information is required to differentiate objects and thus revoke capabilities appropriately.&lt;/p&gt;
    &lt;p&gt;The software ecosystem for CHERI has made impressive progress. Most code recompiles with minimal changes, though the capability width difference can require significant rewrites for certain applications. Additionally, it causes a division in the ISA where load/stores of capabilities must be handled separately from ordinary data. This leads to some complexity in the compiler to detect edge cases where the compiler does not know for certain whether a register or memory slot contains a capability or not. C/C++ code which abuses pointers by treating them as integers, which is uncommon but frequent enough to cause a headache, requires some effort to address.&lt;/p&gt;
    &lt;p&gt;Armâ€™s Morello project, which implemented CHERI on a modified Neoverse N1 core, revealed performance challenges that have pushed commercial CHERI efforts toward smaller embedded processors for the time being. Notably, Arm declined to join the CHERI Alliance, instead indicating they will take a step back from new work on Morello and wait to see if CHERI gains the long-sought commercial traction.&lt;/p&gt;
    &lt;head rend="h2"&gt;OMA: Rethinking Memory From the Ground Up&lt;/head&gt;
    &lt;p&gt;Doubtless Computingâ€™s Object Memory Architecture takes a fundamentally different approach. Rather than extending paged memory, OMA implements object-based memory management directly in hardware. Every allocation becomes a first-class hardware object with its own identity, bounds, and metadata maintained by the processor itself.&lt;/p&gt;
    &lt;p&gt;This architectural choice enables several key advantages. OMA pointers are leaner - 65 bits on a 64-bit architecture, including the hidden tag bit. Rather than carrying all metadata with every pointer, OMA stores object information centrally in hardware-managed directories. This reduces memory bandwidth requirements and means that multiple pointers to the same object donâ€™t duplicate metadata. The hardware maintains a complete understanding of object relationships and lifecycles, enabling optimizations that software-only approaches canâ€™t match.&lt;/p&gt;
    &lt;p&gt;A critical differentiator is temporal safety. OMA implements garbage collection in hardware, scanning for and reclaiming unreachable objects in real-time as part of the processorâ€™s normal operation. This isnâ€™t the same as software garbage collection - itâ€™s parallel, highly optimized, and doesnâ€™t block program execution. By managing object lifecycles in hardware, OMA provides hardware-guaranteed temporal safety alongside referential and spatial protections, completing the trinity of memory safety properties.&lt;/p&gt;
    &lt;p&gt;It would be tempting to say that memory safety is solved by using a managed language like Java, JavaScript, Swift or Python. Unfortunately, this doesnâ€™t hold up in practice. Managed language runtimes, as well as many supporting libraries, are written in C/C++ and suffer memory safety issues just as much as any other C/C++ code. The operating systems and hypervisors are also exposed to these languages, offering yet another attack surface. This leaves managed language apps vulnerable. Memory safe languages, including both Rust and managed languages, are a distinct improvement over traditional C and C++, but only hardware can provide the safety guarantees we need in todayâ€™s systems.&lt;/p&gt;
    &lt;p&gt;For managed languages like Java, JavaScript, Python, C# and Go, the OMA architecture delivers dramatic performance improvements. Doubtless Computingâ€™s analysis of CPython 3.12 reveals that 32-44% of instructions are spent on memory management operations - allocation, deallocation, reference counting, and garbage collection. Moving these operations into parallel hardware execution, along with microarchitectural optimisations derived from hardwareâ€™s new understanding of the structure of data in memory, yields 2-5x speedups for managed language applications. Even C/C++ applications see 1.2-2x improvements as the hardware optimizes memory management functions and eliminates per-object metadata from cache.&lt;/p&gt;
    &lt;p&gt;The architecture maintains full source code compatibility for managed languages - all changes are confined to the runtime. For C/C++, the story is much the same as with CHERI: recompilation with modified standard libraries and a modified compiler, such as LLVM or GCC. Maintaining the pointer width the same as the data width, and the same alignment requirements, avoids the ISA-level split for handling pointers, which simplifies the compiler and improves compatibility with legacy C/C++ code. This compatibility approach differs from CHERIâ€™s and aligns with OMAâ€™s target market: server-class and application processors, where managed languages dominate.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fundamental Trade-offs: Where the Architectures Diverge&lt;/head&gt;
    &lt;p&gt;The philosophical differences between CHERI and OMA create distinct trade-off profiles. CHERI carries all metadata with pointers, enabling incremental adoption where different parts of a program can use capabilities independently. OMAâ€™s centralized metadata requires the hardware to maintain a consistent view of all objects but enables more aggressive optimization. CHERI works within the existing paged memory model, simplifying system software migration. OMA introduces a new memory model that requires deeper changes but delivers performance gains that paged architectures canâ€™t match.&lt;/p&gt;
    &lt;p&gt;These differences manifest in pointer width - CHERIâ€™s 129-bit capabilities versus OMAâ€™s 65-bit pointers. While both exceed the base address width, the doubling effect in CHERI has more severe implications for data structure layouts, cache efficiency, and memory bandwidth. Research on CHERI implementations has shown there is a long road ahead to achieve performance parity for managed languages. In the meantime, OMA offers a shorter path with substantial speedups rather than equal performance.&lt;/p&gt;
    &lt;p&gt;Temporal safety represents perhaps the most significant divergence in security. CHERIâ€™s software-based pointer revocation requires explicit memory scanning and manipulation, adding complexity to the trusted computing base and verification burden. OMAâ€™s hardware garbage collection happens transparently and continuously, providing stronger guarantees with less software complexity. This matters enormously for total cost of ownership - every line of security-critical software that doesnâ€™t need to be written, verified, and maintained is a win.&lt;/p&gt;
    &lt;p&gt;The instruction set philosophies differ too. CHERI historically opts for ISA changes beyond pure memory safety to achieve its security goals, which can complicate adoption. OMA has historically prioritized backward compatibility, though this is adaptable based on market requirements. The consensus in the industry is that software compatibility presents the primary barrier to new processor designs, which favours architectures that minimize disruption.&lt;/p&gt;
    &lt;head rend="h2"&gt;Industrial Relevance and Market Fit&lt;/head&gt;
    &lt;p&gt;CHERI and OMA target fundamentally different computing environments, which is why calling them competitors misses the point. Theyâ€™re complementary solutions to a shared problem, each optimized for distinct use cases.&lt;/p&gt;
    &lt;p&gt;CHERI finds its natural home in embedded systems and microcontrollers. These environments predominantly use C, C++, or Rust with restricted or no dynamic memory allocation. The code bases are smaller and more amenable to the verification required to ensure CHERI capabilities are used correctly. The memory overhead from wider pointers, while still present, matters less in resource-constrained designs that carefully manage every allocation. Four companies - SCI Semiconductor, Codasip, lowRISC, and Secqai - are actively commercializing CHERI for embedded applications. SCIâ€™s ICENI family of CHERIoT microcontrollers, built on Microsoftâ€™s open-source CHERIoT-Ibex core, targets the IoT and operational technology markets. Codasip offers CHERI-enabled RISC-V IP cores for custom processor designs. lowRISCâ€™s Sonata platform provides an open-source FPGA-based development environment for CHERIoT research and prototyping.&lt;/p&gt;
    &lt;p&gt;Armâ€™s experience with CHERI tells an important story about scaling limitations. The Morello project, which implemented CHERI on a modified Neoverse N1 server-class core, yielded results that Arm appears to have found unsatisfactory. There has been no apparent follow-up on the substantial initial investment made into the Arm Morello designs. This assessment seems to reflect the performance challenges that CHERI faces in larger systems.&lt;/p&gt;
    &lt;p&gt;OMAâ€™s sweet spot sits at the opposite end of the spectrum. Application-class and server-class processors running managed languages benefit enormously from hardware-accelerated memory management. Python, Java, JavaScript, C#, and Go all share similar memory models that align naturally with OMAâ€™s object-based approach. These environments already use garbage collection extensively, so moving that functionality into hardware removes overhead, rather than adding it as it would in embedded systems. The performance gains - up to 5x for managed languages - become transformational for data centre workloads where every percentage point of efficiency translates to millions in operating costs.&lt;/p&gt;
    &lt;p&gt;The market dynamics favour different adoption paths. CHERI benefits from strong government backing, particularly from the now-ended UKâ€™s Digital Security by Design programme and recognition from the US White House and NSA. This institutional support hopes to accelerate adoption in defence and critical infrastructure applications. CHERIâ€™s open-source foundation through the CHERI Alliance creates a broad ecosystem but limits opportunities for proprietary differentiation.&lt;/p&gt;
    &lt;p&gt;OMAâ€™s proprietary nature and performance advantages position it for commercial data centre deployment. The technology directly addresses the performance problems that hindered CHERI at scale. While OMA lacks CHERIâ€™s first-mover advantage and government momentum, it offers compelling value for cloud providers and enterprises running managed language workloads. The economic argument is straightforward: if you can eliminate 70% of vulnerabilities while quintupling performance for your Python services, the return on investment is measured in weeks from deployment, rather than years.&lt;/p&gt;
    &lt;p&gt;OMAâ€™s proprietary technology makes it attractive for investment as it can be patented. However, CHERIâ€™s openness makes it possible for independent security teams to verify the safety of the architecture. Open implementations of CHERI processors also enables those designs to be independently verified. Doubtless Computing will need to make its ISA public, which is inevitable anyway for a new CPU as customers will require it. Doubtless will also need to offer a public platform for independent researchers to build confidence in the security claims.&lt;/p&gt;
    &lt;head rend="h2"&gt;The CHERI Ecosystem: Whoâ€™s Building What&lt;/head&gt;
    &lt;p&gt;The CHERI Alliance, formally launched in 2024, coordinates standardization and adoption efforts across industry and academia. Founding members include the FreeBSD Foundation, Capabilities Limited, SCI Semiconductor, Codasip, lowRISC, and the University of Cambridge. Googleâ€™s participation as a founding member signals serious industry interest, though notably Arm is not a member.&lt;/p&gt;
    &lt;p&gt;SCI Semiconductor, based in Cambridge, leads commercialization of Microsoftâ€™s open-source CHERIoT Ibex implementation for embedded systems. Their ICENI family of processors targets microcontroller applications in automotive, industrial control, defence, and aerospace. The company has secured strategic distribution through EPS Global, which specializes in automotive tier-one suppliers and contract manufacturers. SCIâ€™s early access program, in collaboration with lowRISC, allows select partners to begin development on lowRISCâ€™s FPGA-based Sonata platform with guaranteed migration paths to production silicon.&lt;/p&gt;
    &lt;p&gt;Codasip, a RISC-V processor IP vendor, offers the X730 - a CHERI-enabled 64-bit application-class core based on their A730 design. Their â€œCustom Computeâ€ methodology allows customers to license CHERI-enhanced cores or customize them further using Codasip Studio. The company has donated a CHERI SDK built on open-source tools to the CHERI Alliance, making it freely available for anyone implementing CHERI on RISC-V. Codasip is also developing Linux kernel support for RISC-V CHERI, which will be crucial for broader adoption.&lt;/p&gt;
    &lt;p&gt;lowRISC, a not-for-profit organization spun out of Cambridge University, maintains the Sonata evaluation platform and leads the UK-government-funded Sunburst Project. Sonata provides a complete FPGA-based development environment for CHERIoT, enabling software development and hardware experimentation before silicon is available. The Sunburst Projectâ€™s recent expansion to include SCI Semiconductor aims to validate CHERIoT designs through commercial tapeout on GlobalFoundriesâ€™ 22nm process, with all project deliverables remaining open-source.&lt;/p&gt;
    &lt;p&gt;zeroRISC is a startup and partner in the OpenTitan project administered by lowRISC. Their goal is to commercialise the OpenTitan silicon IP through their Integrity Management Platform.&lt;/p&gt;
    &lt;p&gt;Microsoftâ€™s role deserves special mention. Microsoft Research developed CHERIoT-Ibex, an open-source RISC-V core optimized for embedded systems. Theyâ€™ve made this core freely available and co-maintain the CHERIoT Platform repository with SCI Semiconductor. David Weston, Microsoftâ€™s VP of Enterprise and OS Security, has publicly endorsed SCIâ€™s commercialization efforts, stating that CHERI represents a â€œpromising technology that can be used to enhance computer security.â€ This corporate backing from a major software vendor adds credibility to the embedded CHERI ecosystem.&lt;/p&gt;
    &lt;p&gt;The UK governmentâ€™s support through the now-ended Digital Security by Design programme and UKRI funding has been instrumental in advancing CHERI. The programme provided ~Â£190 million in research funding over five years and continues to support development through initiatives like Sunburst. This institutional backing, combined with endorsements from the US White House and NSA, positions CHERI advantageously for government and defence procurements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;CHERI and OMA represent two responses to the memory safety crisis, each with distinct strengths that make them suited to different computing environments. The notion that one must â€œwinâ€ while the other â€œlosesâ€ misunderstands the landscape - the computing world is large enough, and varied enough, that multiple approaches can and should coexist. Cybersecurity principles also demand diversity of solutions.&lt;/p&gt;
    &lt;p&gt;CHERIâ€™s compatibility with existing paged memory architectures and incremental deployment model make it an excellent fit for embedded systems where code bases are manageable, languages are predominantly C/C++/Rust, and the verification burden is acceptable. The active CHERI ecosystem, backed by government support and open-source collaboration, has created momentum that shouldnâ€™t be underestimated. For IoT devices, industrial control systems, and safety-critical embedded applications, CHERI offers a practical path to hardware-enforced memory safety that companies can adopt today.&lt;/p&gt;
    &lt;p&gt;OMAâ€™s object-based architecture and integrated hardware garbage collection (IHGC) deliver transformational performance for managed language workloads. By tackling temporal safety in hardware alongside referential and spatial protections, OMA provides more complete memory safety with less software complexity. The performance gains - up to 5x for Python, Java, JavaScript, C#, and Go - directly address the scalability problems that have limited CHERI in larger systems. For data centres, cloud infrastructure, and application servers where managed languages dominate, OMA presents compelling advantages.&lt;/p&gt;
    &lt;p&gt;Both architectures eliminate memory safety vulnerabilities. The formal guarantees that CHERI can provide are a subset of what OMA delivers, since OMA includes hardware-enforced temporal safety. However, CHERIâ€™s earlier start and ecosystem momentum matter significantly in technology adoption. The question isnâ€™t which architecture is â€œbetterâ€ in absolute terms but rather which is more appropriate for specific use cases and deployment contexts.&lt;/p&gt;
    &lt;p&gt;Looking ahead, memory safety will increasingly become a non-negotiable requirement. The UK National Cyber Security Centre, US White House, and NSA have all called for fundamental changes in how we build secure systems. The attacks on Marks &amp;amp; Spencer, Co-op, Jaguar Land Rover, the NHS, Transport for London, and many others, demonstrate that our current approach isnâ€™t working. Software-only solutions like Rust, while valuable, face adoption barriers that make them insufficient on their own. Hardware-based memory safety, whether through CHERI, OMA, or future approaches we havenâ€™t yet invented, represents the most practical path to eliminating this class of vulnerability at scale.&lt;/p&gt;
    &lt;p&gt;The semiconductor industry moves slowly, with design cycles measured in years and deployment timelines measured in decades. Todayâ€™s architectural decisions will shape computing security through 2040 and beyond. The good news is that we now have proven approaches to memory safety that work in real hardware. CHERI has demonstrated its viability in embedded systems. OMA has shown it can deliver both security and performance for managed languages with a hardware prototype on AWS Cloud FPGAs supporting CPython 3.12 and Jupyter Notebooks. The challenge now isnâ€™t technical feasibility - itâ€™s economic deployment and ecosystem coordination.&lt;/p&gt;
    &lt;p&gt;For embedded designers, CHERI offers immediate benefits with manageable overhead. For cloud and data centre operators, OMA promises to eliminate vulnerabilities while dramatically improving performance. The fundamental insight is that both approaches work by making the right choices for their target markets. We donâ€™t need to pick one winner. We need both, deployed where each makes the most sense, steadily displacing the insecure architectures that enabled the attacks weâ€™ve seen this year. The trillion-dollar memory safety problem is solvable - and the will to deploy the solutions weâ€™ve built is growing as organisations can no longer afford the risk of being vulnerable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ednutting.com/2025/10/05/cheri-vs-oma.html"/><published>2025-10-13T10:05:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566766</id><title>Matrices can be your Friends</title><updated>2025-10-13T16:12:35.180483+00:00</updated><content>&lt;doc fingerprint="2eac01b79ba60999"&gt;
  &lt;main&gt;
    &lt;p&gt;Take an OpenGL matrix:&lt;/p&gt;
    &lt;quote&gt;float m [ 16 ] ;Consider this as a 4x4 array with it's elements laid out into four columns like this:&lt;/quote&gt;
    &lt;quote&gt;m[0] m[4] m[ 8] m[12] m[1] m[5] m[ 9] m[13] m[2] m[6] m[10] m[14] m[3] m[7] m[11] m[15]WARNING: Mathematicians like to see their matrices laid out on paper this way (with the array indices increasing down the columns instead of across the rows as a programmer would usually write them). Look CAREFULLY at the order of the matrix elements in the layout above!&lt;/quote&gt;
    &lt;p&gt;...but we are OpenGL programmers - not mathematicians - right?! The reason OpenGL arrays are laid out in what some people would consider to be the opposite direction to mathematical convention is somewhat lost in the mists of time. However, it turns out to be a happy accident as we will see later.&lt;/p&gt;
    &lt;p&gt;If you are dealing with a matrix which only deals with rigid bodies (ie no scale, shear, squash, etc) then the last row (array elements 3,7,11 and 15) are always 0,0,0 and 1 respectively and so long as they always maintain those values, we can safely forget about them for now.&lt;/p&gt;
    &lt;p&gt;The first three elements of the rightmost column of the matrix is just the overall translation. If you imagine some kind of neat little compact object (like a teapot), then array elements 12,13 and 14 tell you where it is in the world. It doesn't matter what combinations of rotations and translations it took to produce the matrix, the rightmost column tells you where the object basically is. It is often fortunate that the OpenGL matrix array is laid out the way it is because it results in those three elements being consecutive in memory.&lt;/p&gt;
    &lt;p&gt;OK, so now we are down to only nine random-looking numbers. These are the top three elements of each of the first three columns - and collectively they represent the rotation of the object.&lt;/p&gt;
    &lt;p&gt;The easy way to decode those numbers is to imagine what happens to four points near to the origin after they are transformed by the matrix:&lt;/p&gt;
    &lt;quote&gt;(0,1,0) | /(0,0,1) | / |/___(1,0,0) (0,0,0)These are four vertices on a 1x1x1 cube that has one corner at the origin.&lt;/quote&gt;
    &lt;p&gt;After the matrix has transformed this cube, where does it end up?&lt;/p&gt;
    &lt;p&gt;Well, if we neglect the translation part (the bottom row), then the pure rotation part simply describes the new location of the points on the cube:&lt;/p&gt;
    &lt;quote&gt;(1,0,0) ---&amp;gt; ( m[0], m[1], m[2] ) (0,1,0) ---&amp;gt; ( m[4], m[5], m[6] ) (0,0,1) ---&amp;gt; ( m[8], m[9], m[10]) (0,0,0) ---&amp;gt; ( 0, 0, 0 )After that, you just add the translation onto each point so that:&lt;/quote&gt;
    &lt;quote&gt;(1,0,0) ---&amp;gt; ( m[0], m[1], m[2] ) + ( m[12], m[13], m[14] ) (0,1,0) ---&amp;gt; ( m[4], m[5], m[6] ) + ( m[12], m[13], m[14] ) (0,0,1) ---&amp;gt; ( m[8], m[9], m[10]) + ( m[12], m[13], m[14] ) (0,0,0) ---&amp;gt; ( 0, 0, 0 ) + ( m[12], m[13], m[14] )Once you know this, it becomes quite easy to use matrices to position objects exactly where you need them without messing around with multiple calls to glRotate.&lt;/quote&gt;
    &lt;p&gt;Just imagine a little cube at the origin - pretend it's firmly attached to your model. Think about where the cube ends up as the model moves - write down where it's vertices would end up and there is your matrix.&lt;/p&gt;
    &lt;p&gt;So, if I gave you this matrix:&lt;/p&gt;
    &lt;quote&gt;0.707, -0.707, 0, 10 0.707, 0.707, 0, 10 0 , 0 , 1, 0 0 , 0 , 0, 1...you could easily see that the X axis of that little cube is now pointing somewhere between the X and Y axes, the Y axis is pointing somewhere between Y and negative X and the Z axis is unchanged. The entire cube has been moved 10 units off in X and Y. This is a 45 degree rotation about Z and a 10,10,0 translation! You didn't need any hard math - just a mental picture of what the little cube did - and no concerns about the order of operations or anything hard like that. What would have happened to something out at 100,100,0? Well, just imagine it was glued to the cube (on the end of a long stick)...as the cube rotated, the thing at 100,100 would have moved quite a bit too - in fact, you can see that the rotation would put it onto the Y axis and the translation would have moved it 10 units up and to the right.&lt;/quote&gt;
    &lt;p&gt;With practice, you can figure out what that last row of numbers does to the little cube too.&lt;/p&gt;
    &lt;p&gt;So, would you like to know how to use a matrix to squash, stretch, shear, etc? Just think about where the axes of that little cube end up - write them down and you are done. What does a cube of jello look like when there is a strong wind blowing from X=-infinity?&lt;/p&gt;
    &lt;quote&gt;1, 0.3, 0, 0 0, 0.9, 0, 0 0, 0 , 1, 0 0, 0 , 0, 1Look - the Y axis is leaning a third of a unit to the right and the cube got a bit shorter.&lt;/quote&gt;
    &lt;p&gt;Suppose your cartoon character is going to jump vertically, and you want to do a bit of pre-squash before the jump... and post-stretch during the jump. Just gradually vary the matrix from:&lt;/p&gt;
    &lt;quote&gt;1 , 0 , 0, 0 1 , 0 , 0, 0 0 , 0.8, 0, 0 0 , 1.2, 0, 0 0 , 0 , 1, 0 ===&amp;gt; 0 , 0 , 1, 0 0 , 0 , 0, 1 0 , 0 , 0, 1Not bad - he got shorter then longer - how about getting a bit fatter too (conservation of cartoon volume) ?&lt;/quote&gt;
    &lt;quote&gt;1.2, 0 , 0 , 0 0.9,0 , 0 , 0 0 , 0.8, 0 , 0 0 ,1.2, 0 , 0 0 , 0 , 1.2, 0 ===&amp;gt; 0 ,0 ,0.9, 0 0 , 0 , 0 , 1 0 ,0 , 0 , 1Now the cube got smaller in Y and bigger in X and Z then got bigger in Y and smaller in X/Z...easy!&lt;/quote&gt;
    &lt;p&gt;Not only is it easier to think transforms out this way, but it's invariably more efficient too. By seeing the entire transformation as one whole operation on a unit cube, you save a long sequence of glRotate/glTranslate/glScale commands - which each imply a complicated set of multiply/add steps to concatenate the new transform with whatever is on the top of the stack.&lt;/p&gt;
    &lt;p&gt;Finally, there is one matrix that we all need to know - the "Identity" matrix:&lt;/p&gt;
    &lt;quote&gt;1, 0, 0, 0 0, 1, 0, 0 0, 0, 1, 0 0, 0, 0, 1As you can see, this matrix leaves all the axes completely alone and performs no translation. This is a "do nothing" matrix.&lt;/quote&gt;
    &lt;p&gt;Matrices are really easy - it's just a matter of looking at them pictorially.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sjbaker.org/steve/omniv/matrices_can_be_your_friends.html"/><published>2025-10-13T10:23:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567645</id><title>California Will Stop Using Coal as a Power Source Next Month</title><updated>2025-10-13T16:12:34.781792+00:00</updated><content>&lt;doc fingerprint="24f32e590b382448"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;California Will Stop Using Coal as a Power Source Next Month (latimes.com) 73&lt;/head&gt;
    &lt;p&gt;[T]he U.S. got nearly half its electricity from coal-fired plants as recently as 2007. By 2023, that figure had dropped to just 16.2%. California drove an even more dramatic shift, getting just 2.2% of its electricity from coal in 2024 â€” nearly all of it from the Intermountain plant. Operators plan to cut off that final burst of ions next month.&lt;/p&gt;
    &lt;p&gt;"And with improved technology to store power, the change has been made without the power shortages that dogged the state up until 2020..."5&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hardware.slashdot.org/story/25/10/13/032224/california-will-stop-using-coal-as-a-power-source-next-month"/><published>2025-10-13T12:33:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567770</id><title>Show HN: SQLite Online â€“ 11 years of solo development, 11K daily users</title><updated>2025-10-13T16:12:34.492992+00:00</updated><content>&lt;doc fingerprint="5120987566fd4fbd"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Chart for Data Science&lt;/head&gt;
    &lt;code&gt;-- Change first word "SELECT" to "QLINE-SELECT"&lt;/code&gt;
    &lt;quote&gt;SELECT QLINE-SELECT&lt;/quote&gt;
    &lt;code&gt;Ã¢&lt;/code&gt;
    &lt;code&gt;-- Axis X:&lt;/code&gt;
    &lt;code&gt;-- X - column name, axis: x1, x2, ..xn Value: Number&lt;/code&gt;
    &lt;code&gt;-- L - column name, axis: l Value: Text&lt;/code&gt;
    &lt;code&gt;-- T - column name, axis: t Value: UnixTime Number&lt;/code&gt;
    &lt;code&gt;-- Axis Y:&lt;/code&gt;
    &lt;code&gt;-- Y - column name, axis: y1, y2, ..yn Value: Number&lt;/code&gt;
    &lt;code&gt;-- Y - color line: y_cFF00FF (HEX6)&lt;/code&gt;
    &lt;code&gt;-- Option:&lt;/code&gt;
    &lt;code&gt;-- C - color point: c  Value: FF00FF (HEX6)&lt;/code&gt;
    &lt;code&gt;-- V - radius point: v  Value: Number&lt;/code&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QLINE-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QAREA-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QBAR-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QPIE-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QBUBBLE-SELECT example&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sqliteonline.com/"/><published>2025-10-13T12:46:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567877</id><title>No Science, No Startups: The Innovation Engine We're Switching Off</title><updated>2025-10-13T16:12:34.350059+00:00</updated><content>&lt;doc fingerprint="3fc8918d9d618749"&gt;
  &lt;main&gt;
    &lt;p&gt;Tons of words have been written about the Trump Administrations war on Science in Universities. But few people have asked what, exactly, is science? How does it work? Who are the scientists? What do they do? And more importantly, why should anyone (outside of universities) care?&lt;/p&gt;
    &lt;p&gt;(Unfortunately, you wonâ€™t see answers to these questions in the general press â€“ itâ€™s not clickbait enough. Nor will you read about it in the science journalsâ€“ itâ€™s not technical enough. You wonâ€™t hear a succinct description from any of the universities under fire, either â€“ theyâ€™ve long lost the ability to connect the value of their work to the day-to-day life of the general public.)&lt;/p&gt;
    &lt;p&gt;In this post Iâ€™m going to describe how science works, how science and engineering have worked together to build innovative startups and companies in the U.S.â€”and why you should care.&lt;/p&gt;
    &lt;p&gt;(In a previous post I described how the U.S. built a science and technology ecosystem and why investment in science is directly correlated with a countryâ€™s national power. I suggest you read it first.)&lt;/p&gt;
    &lt;p&gt;How Science Works&lt;lb/&gt; I was older than I care to admit when I finally understood the difference between a scientist, an engineer, an entrepreneur and a venture capitalist; and the role that each played in the creation of advancements that made our economy thrive, our defense strong and America great.&lt;/p&gt;
    &lt;p&gt;Scientists&lt;lb/&gt; Scientists (sometimes called researchers) are the people who ask lots of questions about why and how things work. They donâ€™t know the answers. Scientists are driven by curiosity, willing to make educated guesses (the fancy word is hypotheses) and run experiments to test their guesses. Most of the time their hypotheses are wrong. But every time theyâ€™re right they move the human race forward. We get new medicines, cures for diseases, new consumer goods, better and cheaper foods, etc.&lt;/p&gt;
    &lt;p&gt;Scientists tend to specialize in one area â€“ biology, medical research, physics, agriculture, computer science, materials, math, etc. â€” although a few move between areas. The U.S. government has supported scientific research at scale (read billions of $s) since 1940.&lt;/p&gt;
    &lt;p&gt;Scientists tend to fall into two categories: Theorists and Experimentalists.&lt;/p&gt;
    &lt;p&gt;Theorists&lt;lb/&gt; Theorists develop mathematical models, abstract frameworks, and hypotheses for how the universe works. They donâ€™t run experiments themselvesâ€”instead, they propose new ideas or principles, explain existing experimental results, predict phenomena that havenâ€™t been observed yet. Theorists help define what reality might be.&lt;/p&gt;
    &lt;p&gt;Theorists can be found in different fields of science. For example:&lt;/p&gt;
    &lt;p&gt;Physics Quantum field theory, string theory, quantum mechanics&lt;lb/&gt; Biology Neuroscience and cognition, Systems Biology, gene regulation&lt;lb/&gt; Chemistry Molecular dynamics, Quantum chemistry&lt;lb/&gt; Computer Science Design algorithms, prove limits of computation&lt;lb/&gt; Economics Build models of markets or decision-making&lt;lb/&gt; Mathematics Causal inference, Bayesian networks, Deep Learning&lt;/p&gt;
    &lt;p&gt;The best-known 20th-century theorist was Albert Einstein. His tools were a chalkboard and his brain. in 1905 he wrote an equation E=MC2 which told the world that a small amount of mass can be converted into a tremendous amount of energy. When he wrote it down, it was just theory. Other theorists in the 1930s and â€™40s took Einsteinâ€™s theory and provided the impetus for building the atomic bomb. (Leo Szilard conceived neutron chain reaction idea, Hans Bethe led the Theoretical Division at Los Alamos, Edward Teller developed hydrogen bomb theory.) Einsteinâ€™s theory was demonstrably proved correct over Hiroshima and Nagasaki.&lt;/p&gt;
    &lt;p&gt;Experimentalists&lt;lb/&gt; In addition to theorists, other scientists â€“ called experimentalists â€“ design and run experiments in a lab. The pictures you see of scientists in lab coats in front of microscopes, test tubes, particle accelerators or NASA spacecraft are likely experimentalists. They test hypotheses by developing and performing experiments. An example of this would be NASAâ€™s James Webb telescope or the LIGO Gravitational-Wave Observatory experiment. (As weâ€™ll see later, often itâ€™s engineers who build the devices the experimentalists use.)&lt;/p&gt;
    &lt;p&gt;Some of these experimentalists focus on Basic Science, working to get knowledge for its own sake and understand fundamental principles of nature with no immediate practical use in mind.&lt;/p&gt;
    &lt;p&gt;Other experimentalists work in Applied Science, which uses the findings and theories derived from Basic Science to design, innovate, and improve products and processes.&lt;/p&gt;
    &lt;p&gt;Applied scientists solve practical problems oriented toward real-world applications. (Scientists at Los Alamos weretrying to understand the critical mass of U-235 (the minimum amount that would explode.) Basic science lays the groundwork for breakthroughs in applied science. For instance: Quantum mechanics (basic science) led to semiconductors which led to computers (applied science). Germ theory (basic science) led to antibiotics and vaccines (applied science). In the 20th century Applied scientists did not start the companies that make end products. Engineers and entrepreneurs did this. (In the 21st century more Applied Scientists, particularly in life sciences, have also spun out companies from their labs.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Scientists&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Where is Science in the U.S. Done?&lt;lb/&gt; Americaâ€™s unique insight that has allowed it to dominate Science and invention, is that after WWII we gave Research and Development money to universities, rather than only funding government laboratories. No other country did this at scale.&lt;/p&gt;
    &lt;p&gt;Corporate Research Centers&lt;lb/&gt; In the 20th century, U.S. companies put their excess profits into corporate research labs. Basic research in the U.S. was done in at Dupont, Bell Labs, IBM, AT&amp;amp;T, Xerox, Kodak, GE, et al.&lt;/p&gt;
    &lt;p&gt;This changed in 1982, when the Securities and Exchange Commission ruled that it was legal for companies to buy their own stock (reducing the number of shares available to the public and inflating their stock price.) Very quickly Basic Science in corporate research all but disappeared. Companies focused on Applied Research to maximize shareholder value. In its place, Theory and Basic research is now done in research universities.&lt;/p&gt;
    &lt;p&gt;Research Universities&lt;lb/&gt; From the outside (or if youâ€™re an undergraduate) universities look like a place where students take classes and get a degree. However, in a research university there is something equally important going on. Science faculty in these schools not only teach, but they are expected to produce new knowledgeâ€”through experiments, publications, patents, or creative work. Professors get grants and contracts from federal agencies (e.g., NSF, NIH, DoD), foundations, and industry. And the university builds Labs, centers, libraries, and advanced computing facilities that support these activities.&lt;/p&gt;
    &lt;p&gt;In the U.S. there are 542 research universities, ranked by the Carnegie Classification into three categories.&lt;/p&gt;
    &lt;p&gt;R1: 187 Universities â€“ Very High Research Activity&lt;lb/&gt; Conduct extensive research and award many doctoral degrees.&lt;lb/&gt; Examples: Stanford, UC Berkeley, Harvard, MIT, Michigan, Texas A&amp;amp;M â€¦&lt;/p&gt;
    &lt;p&gt;R2: 139 Universities â€“ High Research Activity&lt;lb/&gt; Substantial but smaller research scale.&lt;lb/&gt; Examples: Baylor, Wake Forest, UC Santa Cruz, â€¦&lt;/p&gt;
    &lt;p&gt;R3: 216 Research Colleges/Universities&lt;lb/&gt; Limited research focus; more teaching-oriented doctoral programs.&lt;lb/&gt; Smaller state universities&lt;/p&gt;
    &lt;p&gt;Why Universities Matter to Science&lt;lb/&gt; U.S. universities perform about 50% of all basic science research (physics, chemistry, biology, social sciences, etc.) because they are training grounds for graduate students and postdocs. Universities spend ~$109 billion a year on research. ~$60 billion of that $109 billion comes from the National Institutes for Health (NIH) for biomedical research, National Science Foundation (NSF) for basic science, Department of War (DoW), Department of Energy (DOE), for energy/physics/nuclear, DARPA, NASA. (Companies tend to invest in applied research and development, that leads directly to saleable products.)&lt;/p&gt;
    &lt;p&gt;Professors (especially in Science, Technology, Engineering and Math) run labs that function like mini startups. They ask research questions, then hire grad students, postdocs, and staff and write grant proposals to fund their work, often spending 30â€“50% of their time writing and managing grants. When they get a grant the lead researcher (typically a faculty member/head of the lab) is called the Principal Investigator (PI).&lt;/p&gt;
    &lt;p&gt;The Labs are both workplaces and classrooms. Graduate students and Postdocs do the day-to-day science work as part of their training (often for a Ph.D.). Postdocs are full-time researchers gaining further specialization. Undergraduates may also assist in research, especially at top-tier schools.&lt;/p&gt;
    &lt;p&gt;(Up until 2025, U.S. science was deeply international with ~40â€“50% of U.S. basic research done by foreign-born researchers (graduate students, postdocs, and faculty). Immigration and student visas were a critical part of American research capacity.)&lt;/p&gt;
    &lt;p&gt;The results of this research are shared with the agencies that funded it, published in journals, presented at conferences and often patented or spun off into startups via technology transfer offices. A lot of commercial techâ€”from Google search to CRISPRâ€”started in university labs.&lt;/p&gt;
    &lt;p&gt;Universities support their science researchers with basic administrative staff (for compliance, purchasing, and safety) but uniquely in the U.S., by providing the best research facilities (labs, cleanrooms, telescopes), and core scientific services: DNA sequencing centers, electron microscopes, access to cloud, data analysis hubs, etc. These were the best in the world â€“ until the sweeping cuts in 2025.&lt;/p&gt;
    &lt;p&gt;Engineers Build on the Work of Scientists&lt;lb/&gt; Engineers design and build things on top of the discoveries of scientists. For example, seven years after scientists split the atom, it took 10s of thousands of engineers to build an atomic bomb. From the outset, the engineers knew what they wanted to build because of the basic and applied scientific research that came before them.&lt;/p&gt;
    &lt;p&gt;Scientists Versus Engineers&lt;/p&gt;
    &lt;p&gt;Engineers create plans, use software to test their designs, thenâ€¦ cut sheet metal, build rocket engines, construct buildings and bridges, design chips, build equipment for experimentalists, design cars, etc.&lt;/p&gt;
    &lt;p&gt;As an example, at Nvidia their GPU chips are built in a chip factory (TSMC) using the Applied science done by companies like Applied Materials which in turn is based on Basic science of semiconductor researchers. And the massive data centers OpenAI, Microsoft, Google, et al that use Nvidia chips are being built by mechanical and other types of engineers.&lt;/p&gt;
    &lt;p&gt;My favorite example is that the reusable SpaceX rocket landings are made possible by the Applied Science research on Convex Optimization frameworks and algorithms by Steven Boyd of Stanford. And Boydâ€™s work was based on the Basic science mathematical field of convex analysis (SpaceX, NASA, JPL, Blue Origin, Rocket Lab all use variations of Convex Optimization for guidance, control, and landing.)&lt;/p&gt;
    &lt;p&gt;Startup Entrepreneurs Build Iteratively and Incrementally&lt;lb/&gt; Entrepreneurs build companies to bring new products to market. They hire engineers to build, test and refine products.&lt;/p&gt;
    &lt;p&gt;Engineers and entrepreneurs operate with very different mindsets, goals, and tolerances for risk and failure. (Many great entrepreneurs start as engineers e.g., Musk, Gates, Page/Brin). An engineerâ€™s goal is to design and deliver a solution to a known problem with a given set of specifications.&lt;/p&gt;
    &lt;p&gt;In contrast, entrepreneurs start with a series of unknowns about who are the customers, what are the wanted product features, pricing, etc. They retire each of these risks by building an iterative series of minimum viable products to find product/market fit and customer adoption. They pivot their solution as needed when they discover their initial assumptions are incorrect. (Treating each business unknown as a hypothesis is the entrepreneursâ€™ version of the Scientific Method.)&lt;/p&gt;
    &lt;p&gt;Venture Capitalists Fund Entrepreneurs&lt;lb/&gt; Venture capitalists (VCs) are the people who fund entrepreneurs who work with engineers who build things that applied scientists have proven from basic researchers.&lt;/p&gt;
    &lt;p&gt;Unlike banks which will give out loans for projects that have known specifications and outcomes, VCs invest in a portfolio of much riskier investments. While banks make money on the interest they charge on each loan, VCs take part ownership (equity) in the companies they invest in. While most VC investments fail, the ones that succeed make up for that.&lt;/p&gt;
    &lt;p&gt;Most VCs are not scientists. Few are engineers, some have been entrepreneurs. The best VCs understand technical trends and their investments help shape the future. VCs do not invest in science/researchers. VCs want to minimize the risk of their investment, so they mostly want to take engineering and manufacturing risk, but less so on applied science risk and rarely on basic research risk. Hence the role of government and Universities.&lt;/p&gt;
    &lt;p&gt;VCs invest in projects that can take advantage of science and deliver products within the time horizon of their funds (3â€“7 years). Science often needs decades before a killer app is visible.&lt;/p&gt;
    &lt;p&gt;As the flow of science-based technologies dries up, the opportunities for U.S. venture capital based on deep tech will decline, with its future in countries that are investing in science â€“ China or Europe.&lt;/p&gt;
    &lt;p&gt;Why Have Scientists? Why Not Just a Country of Engineers, Entrepreneurs and VCs (or AI)?&lt;lb/&gt; If youâ€™ve read so far, you might be scratching your head and asking, â€œWhy do we have scientists at all? Why pay for people to sit around and think? Why spend money on people who run experiments when most of those experiments fail? Canâ€™t we replace them with AI?â€&lt;/p&gt;
    &lt;p&gt;The output of this university-industry-government science partnership became the foundation of Silicon Valley, the aerospace sector, the biotechnology industry, Quantum and AI. These investments gave us rockets, cures for cancer, medical devices, the Internet, Chat GPT, AI and more.&lt;/p&gt;
    &lt;p&gt;Investment in science is directly correlated with national power. Weaken science, you weaken the long-term growth of the economy, and national defense.&lt;/p&gt;
    &lt;p&gt;Tech firmsâ€™ investments of $100s of billions in AI data centers is greater than the federal governmentâ€™s R&amp;amp;D expenditures. But these investments are in engineering not in science. The goal of making scientists redundant using artificial general intelligence misses the point that AI will (and is) making scientists more productive â€“ not replacing them.&lt;/p&gt;
    &lt;p&gt;Countries that neglect science become dependent on those that donâ€™t. U.S. post-WWII dominance came from basic science investments (OSRD, NSF, NIH, DOE labs). After WWII ended, the UK slashed science investment which allowed the U.S. to commercialize the British inventions made during the war.&lt;/p&gt;
    &lt;p&gt;The Soviet Unionâ€™s collapse partly reflected failure to convert science into sustained innovation, during the same time that U.S. universities, startups and venture capital created Silicon Valley. Long-term military and economic advantage (nuclear weapons, GPS, AI) trace back to scientific research ecosystems.&lt;/p&gt;
    &lt;p&gt;Lessons Learned&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;Scientists come in two categories&lt;/item&gt;
      &lt;item&gt;Theorists and experimentalists&lt;/item&gt;
      &lt;item&gt;Two types of experimentalists; Basic science (learn new things) or applied science (practical applications of the science)&lt;/item&gt;
      &lt;item&gt;Scientists train talent, create patentable inventions and solutions for national defense&lt;/item&gt;
      &lt;item&gt;Engineers design and build things on top of the discoveries of scientists&lt;/item&gt;
      &lt;item&gt;Entrepreneurs test and push the boundaries of what products could be built&lt;/item&gt;
      &lt;item&gt;Venture Capital provides the money to startups&lt;/item&gt;
      &lt;item&gt;Scientists, engineers, entrepreneurs â€“ these roles are complementary&lt;/item&gt;
      &lt;item&gt;Remove one and the system degrades&lt;/item&gt;
      &lt;item&gt;Science wonâ€™t stop&lt;/item&gt;
      &lt;item&gt;Cut U.S. funding, then science will happen in other countries that understand its relationship to making a nation great â€“ like China.&lt;/item&gt;
      &lt;item&gt;National power is derived from investments in Science&lt;/item&gt;
      &lt;item&gt;Reducing investment in basic and applied science makes America weak&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Appendix â€“ How Does Science Work? â€“ The Scientific Method&lt;lb/&gt; Whether you were a theorist or experimentalist, for the last 500 years the way to test science was by using the scientific method. This method starts by a scientist wondering and asking, â€œHereâ€™s how I think this should work, letâ€™s test the idea.â€&lt;/p&gt;
    &lt;p&gt;The goal of the scientific method is to turn a guess (in science called a hypothesis) into actual evidence. Scientists do this by first designing an experiment to test their guess/hypothesis. They then run the experiment and collect and analyze the result and ask, â€œDid the result validate, invalidate the hypothesis? Or did it give us completely new ideas?â€ Scientists build instruments and run experiments not because of what they know, but because of what they donâ€™t know.&lt;/p&gt;
    &lt;p&gt;These experiments can be simple ones costing thousands of dollars that can be run in a university biology lab while others may require billions of dollars to build a satellite, particle accelerator or telescope. (The U.S. took the lead in Science after WWII when the government realized that funding scientists was good for the American economy and defense.)&lt;/p&gt;
    &lt;p&gt;Good science is reproducible. Scientists just donâ€™t publish their results, but they also publish the details of how they ran their experiment. That allows other scientists to run the same experiment and see if they get the same result for themselves. That makes the scientific method self-correcting (you or others can see mistakes).&lt;/p&gt;
    &lt;p&gt;One other benefit of the scientific method is that scientists (and the people who fund them) expect most of the experiments to fail, but the failures are part of learning and discovery. They teach us what works and what doesnâ€™t. Failure in science testing unknowns means learning and discovery.&lt;/p&gt;
    &lt;p&gt;Filed under: National Security, NIH (National Institutes of Health), NSF (National Science Foundation) |&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://steveblank.com/2025/10/13/no-science-no-startups-the-unseen-engine-were-switching-off/"/><published>2025-10-13T13:02:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568555</id><title>The Peach meme: On CRTs, pixels and signal quality (again)</title><updated>2025-10-13T16:12:33.540874+00:00</updated><content>&lt;doc fingerprint="770791314be19d33"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The Peach meme: On CRTs, pixels and signal quality (again)&lt;/head&gt;
    &lt;p&gt;Autumn 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Memes and reality&lt;/head&gt;
    &lt;p&gt;Roughly a year ago, I wrote a text about the effects of CRT screens on pixel art. It surprised me by becoming one of the most controversial pieces I've published here. In it, I propose the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Classical pixel art techniques are often (but certainly not always) missing in contemporary pixel art, which contributes to making the art look overly blocky.&lt;/item&gt;
      &lt;item&gt;The inherent fuzziness of a (PAL or NTSC) CRT blends and smooths pixel art, especially with dithering and anti-aliasing, into something greater than the sum of its parts.&lt;/item&gt;
      &lt;item&gt;However, contemporary claims that CRTs more or less erased any notion of visible on-screen pixels are false.&lt;/item&gt;
      &lt;item&gt;Signal quality matters.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The last point, about signal quality, was perhaps one I communicated poorly. I also used a popular meme as an illustration of how CRTs and pixel art is usually explained. This meme compares a blown-up sprite of Peach (from Super Mario RPG) to a photo of the same sprite on a CRT. It looks like this:&lt;/p&gt;
    &lt;p&gt;For the record, I want to be very clear that I think this is a poor way of illustrating the effects of a CRT. Firstly, the photo is out of focus - which is understandable, because it's notoriously hard to take a good photo of a CRT screen. Secondly, nobody sits that close to a CRT (or any other screen). Finally, the meme doesn't tell us what connection type is used in the photo.&lt;/p&gt;
    &lt;p&gt;The Peach meme seems to originate from this page, which has no information about the video signal used. All of the pictures on that page are in turn stolen from Twitter/X user CRTpixels, who seems very passionate about CRTs, posts a lot of interesting material and of course does provide information on the signal source. With a bit of searching, it becomes apparent that the video source is S-Video (Tweet screenshot here). S-Video is better than composite, but worse than RGB. Most comparisons on the linked page seem to use either S-Video or composite. For example, check out the original Streets of Rage 2 post (Tweet screenshot here).&lt;/p&gt;
    &lt;head rend="h3"&gt;Close encounters&lt;/head&gt;
    &lt;p&gt;Above is another close-up of a CRT (my own Commodore 1084S, to be precise), connected to an A1200 via the RGB port. The fact that it's in focus is pure luck: my iPhone 15, which I've used for taking all of the photos on this page, was simply in a good mood that day. It's a better illustration of how a CRT works, but it's still a bad illustration of what one actually looks like in real life, at a normal viewing distance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Noise in the signal&lt;/head&gt;
    &lt;p&gt;Let's look at the meme's Peach sprite on some different displays. Peach herself is taken from a sprite sheet I found online: Click here to view the actual image used.&lt;/p&gt;
    &lt;p&gt;The image above shows Peach being displayed on the very same screen, an old 15" 5:4 Samsung LCD TV. The picture source is one of my trusty Amiga 1200s. Peach to the left shows a VGA connection. Peach to the right is using a composite connection. Here we can clearly see the difference in signal quality: composite leads to blurring, colour bleeding (or blending, depending on how you look at it), poor colour fidelity and noticeable "snow" across the entire picture, especially visible in the black areas. If we look at Peach's left shoe, we can see the same effect as in the meme above: it's all but disappeared, only barely visible as a tiny, red smudge. When taking these photos I put a sticker on the screen, right next to the sprite, which shows it's reasonably in focus. You can see the original, with the sticker, here.&lt;/p&gt;
    &lt;p&gt;Here's the Peach sprite again, this time on my C= 1084S CRT. Both pictures are slightly out of focus, just like in the original meme. The picture to the left shows an RGB connection, and the picture to the right is composite. A CRT of this type is typically more forgiving when it comes to composite, or any analog signal really, and the composite display is of better quality on the 1084 than the Samsung TV. Still, we clearly see the difference in signal quality. Using RGB, individual pixels can be discerned, and colour fidelity is much higher. The composite image displays the same artefacts as the original meme: bleeding, blur, and the disappearance of Peach's left shoe. We also see some unwanted colour banding on her dress.&lt;/p&gt;
    &lt;p&gt;Another interesting close-up: Peach on my 47" Philips flatscreen TV. The source is an Amiga 1200 connected via RGB SCART. Here we can see some interesting A/D conversion artefacts, perhaps amplifications of slight noise in the signal. We can also clearly see that up close and slightly out of focus like this, the LCD pixel grid looks pretty similar to the RGB cells of a CRT - especially the one in the original meme.&lt;/p&gt;
    &lt;p&gt;To the left is a screenshot of Netflix' Swedish subtitles for an episode of Law &amp;amp; Order: SVU. To the right is the same picture, photographed off my modern 21" LCD computer monitor. What looks like subpixel smoothing in the photo is in fact not, but rather some kind of chromatic aberration, perhaps amplified by the camera. (Click the picture to see it in full resolution.) I can sort of see it if I look very closely at my screen, far closer than a comfortable viewing distance, and even then it's very faint. Again, the LCD pixel grid is clearly visible in the photo. We can also see that the text is anti-aliased, in order to smooth otherwise rough, pixelated edges. None of this is perceptible at a comfortable viewing distance. This comparison is included just to demonstrate that it's hard to convey the viewing experience of any type of screen using close-up photography.&lt;/p&gt;
    &lt;p&gt;Here's a very good photo of Metal Slug on a C= 1084S (RGB), courtesy of the CRT Database. We can clearly see sharp pixel edges and that the dither above the text "1UP=2" in the upper left corner is, well, a dither. At the same time, the scanlines and slight fuzz of the display also adds a certain something that's hard to reproduce on a modern LCD. What can't be captured - even on a good photo like this - is the complete, particular visual experience created when an image is, essentially, painted by light on glass.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sonic waterfalls&lt;/head&gt;
    &lt;p&gt;Another example of CRT magic that's frequently brought up is that of waterfalls in various versions of Sonic: the Hedgehog on Sega Genesis/Mega Drive, and how a CRT will magically blend their colours together into a stunning water effect.&lt;/p&gt;
    &lt;p&gt;Above, we can see the effect as documented by CRTpixels on Twitter/X. The CRT in use above is a Sony PVM-20L2MD, a high quality screen intended for tasks like professional video production. Once again, CRTpixels points out that a composite signal is in use.&lt;/p&gt;
    &lt;p&gt;I managed to fabricate a decent Sonic screenshot and once more used my A1200 as the image source. Not optimal for historical correctness, but that's what makes it interesting, because I wasn't able to recreate the effect as photographed by CRTpixels.&lt;/p&gt;
    &lt;p&gt;The above shots are both of my 1084S. To the left is RGB, to the right is composite. (All pictures are clickable and link to the full resolution image). As we can see, the 1084S combined with an A1200 gives pretty decent image quality in composite. Nevertheless, the fuzz and colour bleeding provided by the composite signal does make for a much more waterfall-like ambiance than the sharpness of pure RGB, even though it's not as spectacular on the Sega. Unfortunately, composite also deteriorates the rest of the image: The shading on the white part of Sonic's shoe, for example, is intended to be a blueish gray - but becomes a purplish red on composite.&lt;/p&gt;
    &lt;p&gt;Other factors that might affect how the waterfalls look on different setups is whether PAL or NTSC is used and, of course, the quality of the composite signal itself (which I gather is rather bad on the Sega). In short: When it comes to waterfalls in Sonic, the effect relies on poor signal quality, not the specific traits of CRT screens in general - and that goes for a lot of the console-related "CRT superiority" memes commonly posted online. (I want to make it clear that I don't think CRTpixels is to blame for this turn of events; memes have a life of their own.)&lt;/p&gt;
    &lt;head rend="h3"&gt;The Game Boy conundrum&lt;/head&gt;
    &lt;p&gt;One aspect of pixel art perception that was brought up as a reaction to my previous text is that of Game Boy graphics. It's a bit out of scope in this discussion, since the Game Boy doesn't have a CRT screen - but it's still worth mentioning. Back in the roaring nineties I mostly played Tetris, Kwirk and Qix on my Game Boy, which of course aren't titles in need of much pixel art trickery. However, if we look at a few games usually shortlisted for having some of the best graphics on the platform, a pixelated pattern emerges.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Toki Tori on the Game Boy Color. Plenty of dithering, and we can see that not only the sprites and background, but even the digits in the timer, have been anti-aliased by hand. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Kirby's Dream Land uses large, flat single colour areas. Nevertheless, it also employs careful anti-aliasing: look at the edges of the clouds, background structures and even the Kirby sprite itself. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; A beautifully crafted intro screen from Gremlins 2, with ample amounts of dither and anti-alias. Again, even the text has been lovingly smoothed by hand. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Trip World is probably the winner in my book. Anti-aliasing is expertly used across all of the graphics not just to create smoother curves and edges, but also to simulate "thinner" pixels, such as in the tufts of grass in the lower left. Dithering is equally expertly used for several purposes: creating texture, adding visual depth, and of course achieving softer gradient shadows by simulating more than four shades of gray. Bravo! &lt;/p&gt;
    &lt;head rend="h3"&gt;Remaining relevant&lt;/head&gt;
    &lt;p&gt;The fact that pixel art techniques were used on the Game Boy isn't surprising, because they're well-known tools for stretching the graphics capabilities of primitive hardware. Dithering comes from traditional art and print media, and is not as relevant on computers today as it once was - though it's still used from time to time to simulate more on-screen colours than available. Anti-aliasing, on the other hand, is more common than ever, now usually applied on the fly when rendering text, to achieve maximum smoothness.&lt;/p&gt;
    &lt;p&gt;Below is an example of a pixel art logo with no anti-aliasing (top) and manual anti-aliasing (bottom). Just a few extra hues and some carefully placed pixels can make quite a difference, even when scaled up and displayed on a modern LCD screen:&lt;/p&gt;
    &lt;head rend="h3"&gt;Targeting the hardware&lt;/head&gt;
    &lt;p&gt;Another interesting question regarding CRTs, signal quality and pixel art is if artists intentionally targeted specific display hardware.&lt;/p&gt;
    &lt;p&gt;Here's an enlightening quote from Kazuhiro Tanaka, who worked on Metal Slug, where he talks about a kind of sub-pixel precision: "It's a technique where by slightly changing the color of surrounding pixels, to the human eye it looks like the pixels move by around 0.5 pixels." His colleague, Yasuyuki Oda: "Back in the old days, we'd say 'add 0.5 of a pixel', and have them [the artists] draw in the pixels by taking scanlines into account. But with the modern Full HD monitor, the pixels comes out too clearly and too perfectly that you can't have that same taste."&lt;/p&gt;
    &lt;p&gt;Famous Amiga artist Jim Sachs explains anti-aliasing in an interview in Retro Gamer's The Amiga Book: "My style was simply making things as realistic as possible. Since that's how I draw and paint anyway, it was just a matter of developing techniques to work around the resolution and palette limitations of the machines. This didn't take too long - a couple of weeks. I remember a conversation with Kellyn Beck when we were starting Defender Of The Crown. I was trying to explain how I could put intermediate pixels between two highly contrasting pixels to minimise the 'jaggies'. A short time later I learned that there was already a name for this - anti-aliasing."&lt;/p&gt;
    &lt;p&gt;Mark Ferrari gives a good explanation of dithering in this excellent talk. For example, regarding Loom, he says: "We learned to compress dither [in file storage] (...) and we made a game where you could actually have six or seven kinds of blue [on EGA], rather than just four, because of the fact that we could dither it. (...) Some people actually thought it was a VGA game." And, about dithering and relying on the hardware itself: "Back in the days we did this, CTR [sic] monitors were so blurry that we actually counted on the blur to sort of fill those colours in and blend them for us. (...) It didn't look quite as dotty back then."&lt;/p&gt;
    &lt;p&gt;Another question is what kind of setup the artists targeted. Arcade machines of course came with their own, high quality CRT screens. In the case of EGA and VGA graphics, the answer is similarly simple: there's not much to choose from, except typical consumer-level EGA and VGA monitors. On the Amiga, almost all professional graphics artists would have been using - and targeting - a Commodore 1084 monitor (or similar) connected via RGB. On consoles, the answer is less obvious. Whether or not the waterfalls in Sonic: the Hedgehog, for example, was an intentional exploitation of composite colour bleeding/blending, I do not know. If forced to guess, I'd say yes - but then again, a lot of the other graphics looks much better with RGB.&lt;/p&gt;
    &lt;p&gt;By and large, graphics artists did indeed target the typical display hardware of the time, but mostly in a "Does a fish know it's swimming in water?" sort of way. Any skilled artist will, with time, learn the particularities of the medium they're working with and adapt accordingly - no matter if it's oil on canvas or pixels on screen. If you have nothing else to compare it to, you just take it for granted - until something like the Game Boy shows up, and it turns out your technique is equally useful on a small, monochrome LCD screen.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;A CRT will absolutely affect the viewing experience of pixel art, but it also won't magically smooth away all pixels. Close-up photos of screens may give us interesting insights into the underlying technology, but they tell us very little about specific viewing qualities; in fact, the closer we look at them, the more we see similarities rather than differences. In the end, it's our overall perception of the image, at a normal viewing distance, that counts.&lt;/p&gt;
    &lt;p&gt;Signal quality plays a big part in how we perceived old computer games. The poor quality of a composite signal is clearly visible on a flatscreen as well, and the resulting effects have little or nothing to do with the properties of the CRT screens it was usually displayed on.&lt;/p&gt;
    &lt;p&gt;Most importantly: Pixel art techniques remain a huge part of the overall graphics quality, on CRTs and Game Boy as well as on modern flatscreens. But let's not forget that there was a lot of bad, blocky pixel art back in the day as well - on all platforms - which will look like crap regardless of the display hardware. Just like today, some artists lovingly perfected their craft, while others just put in the bare minimum. Many were somewhere in between.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lost in time, like electrons on a phosphor coating&lt;/head&gt;
    &lt;p&gt;I'm afraid the effects of a CRT are very hard to explain or reproduce. It's something that has to be experienced in person, but CRTs are - sadly - few and far between. Close-up photos illustrate something, but they only tell a small fraction of the story. In a hypothetical (dystopian) future where only iPads remain for media consumption, it would be like trying to convey the properties of books by using said iPads for looking at extreme close-up photos of printed letters. It would tell us nothing about variables like paper and print quality, the heft, texture and even scent of a book, how ambient light affects the reading experience, and the sense of accomplishment (or perhaps sadness) from physically feeling you're close to the end, with the thicker bunch of paper having moved gradually from one hand to the other as you've progressed through the story.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; "No, you don't get it, man! Books were awesome! Just look at this!" &lt;/p&gt;
    &lt;p&gt;I can certainly appreciate the frustration. Sometimes, all we want to do is shout "CRTs were magic, bro, just trust me!" And they sort of were. But there was a whole lot more going on with old game graphics than just the screens that displayed it, and some of that stuff is still relevant and applicable when creating pixel art - no matter the target platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.datagubbe.se/crt2/"/><published>2025-10-13T14:13:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568613</id><title>Smartphones and Being Present</title><updated>2025-10-13T16:12:33.236884+00:00</updated><content>&lt;doc fingerprint="3411991d2ac390d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Smartphones and being present&lt;/head&gt;
    &lt;p&gt;I read an article yesterday, stating that on average, people spend 4 hours and 37 minutes on their phones per day1, with South Africans coming in fourth highest in the world at a whopping 5 hours and 11 minutes2.&lt;/p&gt;
    &lt;p&gt;This figure seems really high to me. If we assume people sleep roughly 8 hours per day, that means that one third of their day is spent on their phones. If we also assume people work 8 hours per day (ignoring the fact that they may be using their phones during work hours), that suggests that people spend over half of their free time (and up to 65% of it) glued to their screens.&lt;/p&gt;
    &lt;p&gt;I never wanted to carry the internet around in my pocket. It's too distracting and pulls me out of the present moment, fracturing my attention. I've tried switching to old-school black and white phones before, but always begrudgingly returned to using a smartphone due to the utility of it. The problem, however, is that it comes with too many attention sinks tucked in alongside the useful tools.&lt;/p&gt;
    &lt;p&gt;I care about living an intentional and meaningful life, nurturing relationships, having nuanced conversations, and enjoying the world around me. I don't want to spend this limited time I have on earth watching short form video and getting into arguments on Twitter.&lt;/p&gt;
    &lt;p&gt;This is what I enjoy. Picture taken yesterday in Scarborough, South Africa.&lt;/p&gt;
    &lt;p&gt;I've written at length about how I manage my digital consumption, from turning off notifications to forgoing social media entirely. The underlying premise here is that if you're trying to lose weight, you shouldn't carry cookies around in your pockets. And my phone is the bag of cookies in this metaphor.&lt;/p&gt;
    &lt;p&gt;We're wired to seek out distraction, novel information, and entertainment, and avoid boredom at all costs. But boredom is where creativity and self-reflection do their best work. It's why "all the best ideas come when you're in the shower"â€”we don't usually take our phones with us into the shower (yet).&lt;/p&gt;
    &lt;p&gt;According to Screen Time on my iPhone, on average I spend 30 minutes per day on it, which I think is reasonable, especially considering the most-used apps are by-and-large utility apps like banking and messages. This isn't because I have more self-control than other people. I don't think I do. It's because I know myself, and have set up my digital life to be a positive force, and not an uninspired time-sink.&lt;/p&gt;
    &lt;p&gt;There are many apps and systems to incentivise better relationships with our phones, mostly based around time limits. But these are flawed in three ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I'm an adult, I know how to circumvent these limits, and I will if motivation is low.&lt;/item&gt;
      &lt;item&gt;Time limits don't affect the underlying addiction. You don't quit smoking by only smoking certain hours of the day.&lt;/item&gt;
      &lt;item&gt;The companies that build these apps have tens of thousands of really smart people (and billions of dollars) trying to get me hooked and keep me engaged. The only way to win this game isn't by trying to beat them (I certainly can't), but by not playing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The only way I've found to have a good relationship with my phone is to make it as uninteresting as possible. The first way is to not have recommendation media (think Instagram, TikTok, and all the rest). I'm pro deleting these accounts completely, because it's really easy to re-download the apps on a whim, or visit them in-browser. However some people have found that having them on a dedicated device works by isolating those activities. Something like a tablet at home that is "the only place you're allowed to use Instagram". I can't comment too much on this route, but it seems reasonable.&lt;/p&gt;
    &lt;p&gt;My biggest time sink over the past few years has been YouTube. The algorithm knew me too well and would recommend video after engaging, but ultimately useless video. I could easily burn an entire evening watching absolute junkâ€”leaving me feeling like I'd just wasted what could have otherwise been a beautiful sunset or a tasty home-cooked lasagne. However, at the beginning of this year I learnt that you can turn off your YouTube watch history entirely, which means no recommendations. Here's what my YouTube home screen now looks like:&lt;/p&gt;
    &lt;p&gt;Without the recommendations I very quickly run out of things to watch from the channels I'm subscribed to. It's completely changed my relationship with YouTube since I only watch the videos I actually want to watch, and none of the attention traps. You can turn off your YouTube watch history here, and auto delete your other Google history (like historic searches and navigation) here, which I think is just good practice.&lt;/p&gt;
    &lt;p&gt;I also used my adblocker, AdGuard on Safari which has a useful "block element" feature, to block the recommended videos on the right of YouTube videos. I use this feature to hide shorts as well, since I have no interest in watching them either, and YouTube intentionally makes them impossible to remove. If you're interested in a similar setup, here are the selectors I use to block those elements:&lt;/p&gt;
    &lt;code&gt;youtube.com###items &amp;gt; ytd-item-section-renderer.style-scope.ytd-watch-next-secondary-results-renderer:last-child
youtube.com###sections
youtube.com##[is-shorts]
youtube.com###secondary
&lt;/code&gt;
    &lt;p&gt;The only media that I do sometimes consume on my phone are my RSS feeds, but it's something I'm completely comfortable with since it's explicitly opt-in by design and low volume.&lt;/p&gt;
    &lt;p&gt;While I still have the twitch to check my phone when I'm waiting for a coffee, or in-between activitiesâ€”because my brain's reward system has been trained to do thisâ€”I'm now rewarded with nothing. Over time, I find myself checking my phone less and less. Sometimes I notice the urge, and just let it go, instead focusing on the here and now.&lt;/p&gt;
    &lt;p&gt;I think that while the attention-span-degrading effects of recommendation media are getting most of the headlines, what isn't spoken about as much is the sheer number of hours lost globally to our phones (3.8 million years per day, according to my back-of-the-napkin-math). And while people may argue that this could involve productive work or enjoyable leisure, I suspect that the vast (vast!) majority of that time is short-form entertainment.&lt;/p&gt;
    &lt;p&gt;My solution may sound overkill to many people, but I can say with absolute certainty that it has turned me into a more present, less distracted, and more optimistic person. I have much more time to spend in nature, with friends, or on my hobbies and projects. I can't imagine trading it in for a tiny screen, ever.&lt;/p&gt;
    &lt;p&gt;Give it a try.&lt;/p&gt;
    &lt;p&gt;Happily on the beach for sunset.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://herman.bearblog.dev/being-present/"/><published>2025-10-13T14:20:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568700</id><title>Software update bricks some Jeep 4xe hybrids over the weekend</title><updated>2025-10-13T16:12:33.050715+00:00</updated><content>&lt;doc fingerprint="155561cbaa040794"&gt;
  &lt;main&gt;
    &lt;p&gt;Owners of some Jeep Wrangler 4xe hybrids have been left stranded after installing an over-the-air software update this weekend. The automaker pushed out a telematics update for the Uconnect infotainment system that evidently wasn't ready, resulting in cars losing power while driving and then becoming stranded.&lt;/p&gt;
    &lt;p&gt;Stranded Jeep owners have been detailing their experiences in forum and Reddit posts, as well as on YouTube. The buggy update doesn't appear to brick the car immediately. Instead, the failure appears to occur while drivingâ€”a far more serious problem. For some, this happened close to home and at low speed, but others claim to have experienced a powertrain failure at highway speeds.&lt;/p&gt;
    &lt;p&gt;Jeep pulled the update after reports of problems, but the software had already downloaded to many owners' cars by then. A member of Stellantis' social engagement team told 4xe owners at a Jeep forum to ignore the update pop-up if they haven't installed it yet.&lt;/p&gt;
    &lt;p&gt;Owners were also advised to avoid using either hybrid or electric modes if they had updated their 4xe and not already suffered a powertrain failure. Yesterday, Jeep pushed out a fix.&lt;/p&gt;
    &lt;p&gt;As Crowdstrike showed last year, Friday afternoons are a bad time to push out a software update. Now Stellantis has learned that lesson, too. Ars has reached out to Stellantis, and we'll update this post if we get a reply.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/cars/2025/10/software-update-bricks-some-jeep-4xe-hybrids-over-the-weekend/"/><published>2025-10-13T14:28:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568767</id><title>Ofcom fines 4chan Â£20K and counting for violating UK's Online Safety Act</title><updated>2025-10-13T16:12:32.797009+00:00</updated><content>&lt;doc fingerprint="8ecb095014b22f02"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ofcom fines 4chan Â£20K and counting for pretending UK's Online Safety Act doesn't exist&lt;/head&gt;
    &lt;head rend="h2"&gt;Regulator warns penalties will pile up until internet toilet does its paperwork&lt;/head&gt;
    &lt;p&gt;Ofcom, the UK's Online Safety Act regulator, has fined online message board 4chan Â£20,000 ($26,680) for failing to protect children from harmful content.&lt;/p&gt;
    &lt;p&gt;The fine could rise by a further Â£6,000 â€“ Â£100 per day for a maximum 60 days â€“ if it continues to ignore its duties to comply with the regulator's request for information regarding two separate matters.&lt;/p&gt;
    &lt;p&gt;4chan can stop the additional fines by providing copies of its illegal content risk assessments and information about its qualifying worldwide revenue to Ofcom.&lt;/p&gt;
    &lt;p&gt;The enforcement action announced today is months in the making after Ofcom first opened an investigation into the notorious image board on June 10.&lt;/p&gt;
    &lt;p&gt;It requested the aforementioned risk assessments on April 14, and to this day 4chan still has not complied, the regulator said.&lt;/p&gt;
    &lt;p&gt;When opening the investigation, Ofcom said it was looking to understand whether 4chan has failed, or is failing, to abide by its duties under the Online Safety Act.&lt;/p&gt;
    &lt;p&gt;The watchdog also highlighted that the maximum penalties for these failures, as specified in the legislation, are Â£18 million ($24 million) or 10 percent of an organization's qualifying worldwide revenue, whichever is greater.&lt;/p&gt;
    &lt;p&gt;The Register contacted 4chan for its side of the story.&lt;/p&gt;
    &lt;p&gt;Ofcom's fine is the first made under the Online Safety Act since in-scope organizations' illegal content duties came into force on March 17. It also announced two provisional decisions to take action against file-sharing service Im.ge and pornography service provider AVS Group Ltd for similar failures to respond to information requests.&lt;/p&gt;
    &lt;p&gt;In Im.ge's case, this relates to its duty to implement measures to prevent the circulation of child sexual abuse material (CSAM), and AVS Group was rapped over its duty to implement age-check mechanisms.&lt;/p&gt;
    &lt;p&gt;Both organizations have the chance to appeal Ofcom's findings before it makes a final decision on how to reprimand them.&lt;/p&gt;
    &lt;p&gt;Another porn provider, Youngtek Solutions Ltd, is also under an expanded investigation over its failure to respond to information requests regarding age-checking requirements.&lt;/p&gt;
    &lt;p&gt;Tech secretary Liz Kendall said: "The Online Safety Act is not just law, it's a lifeline. Today we've seen it in action, holding platforms to account so we can protect people across the UK.&lt;/p&gt;
    &lt;p&gt;"Services can no longer ignore illegal content, like encouraging self-harm or suicide, circulating online which can devastate young lives and leave families shattered.&lt;/p&gt;
    &lt;p&gt;"This fine is a clear warning to those who fail to remove illegal content or protect children from harmful material. We fully back the regulator in taking action against all platforms that do not protect users from the darkest corners of the internet."&lt;/p&gt;
    &lt;p&gt;In total, since March 2025, Ofcom has opened 21 investigations into the providers of in-scope apps and websites, and launched five enforcement programs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Playing by the rules&lt;/head&gt;
    &lt;p&gt;In brighter news, others under Ofcom investigation have shown improvements, and several of these cases are now closed.&lt;/p&gt;
    &lt;p&gt;Four file-sharing services under investigation for their child safety measures avoided further action by geo-blocking UK users, much to Ofcom's delight. Krakenfiles, Nippydrive, Nippyshare, and Nippyspace have all blocked British IP addresses instead of following other measures set out in the regulator's codes of practice.&lt;/p&gt;
    &lt;p&gt;Ofcom said it has closed the cases into these sites, and that the measures have "significantly reduced the likelihood that people in the UK will be exposed to any illegal or harmful content."&lt;/p&gt;
    &lt;p&gt;"We will continue to monitor their availability in the UK and reserve the right to reopen our investigations if we have reason to do so. We are pursuing further lines of inquiry against file-sharing services Nippybox and Yolobit, and these investigations remain ongoing."&lt;/p&gt;
    &lt;p&gt;A suicide forum is also now geo-blocking UK IPs after Ofcom began enforcement proceedings.&lt;/p&gt;
    &lt;p&gt;Satisfied for now, the regulator said it will keep tabs on the unnamed provider to see whether that block remains in place over the long term, and ensure it does not provide information on how to bypass it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord says 70,000 photo IDs compromised in customer service breach&lt;/item&gt;
      &lt;item&gt;Germany slams brakes on EU's Chat Control device-scanning snoopfest&lt;/item&gt;
      &lt;item&gt;Imgur yanks Brit access to memes as parent company faces fine&lt;/item&gt;
      &lt;item&gt;Charities warn Ofcom too soft on Online Safety Act violators&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bypassing these measures has been a hot point of discussion since the Online Safety Act's most noticeable rules came into force in July, triggering a surge in VPN subscriptions within days of Brits having to submit their ID cards for age verification purposes.&lt;/p&gt;
    &lt;p&gt;While platforms are forbidden from guiding users toward these types of workarounds, this alone is unlikely to prevent VPNs being used to bypass geo-blocks and similar measures.&lt;/p&gt;
    &lt;p&gt;They do not appear to be going anywhere either. The UK government has previously stated that it does not wish to ban them, since they have many legitimate purposes. But if platforms promote VPNs and other workarounds to children as a means to access their services, then Ofcom will pursue action against them.&lt;/p&gt;
    &lt;head rend="h3"&gt;First look at beefed-up requirements&lt;/head&gt;
    &lt;p&gt;Among Ofcom's proposed amendments to its obligations to platforms was the requirement for in-scope apps and websites to make use of hash-matching technology, which is seen as a more accurate, automated way of preventing the dissemination of illegal content such as CSAM.&lt;/p&gt;
    &lt;p&gt;Hash matching involves a system fingerprinting an image and comparing the hash it generates to a database of known harmful images, which are also hashed. If an image's hash matches or shows signs of similarity with one in the database, then it can be removed entirely autonomously and reported to local authorities for follow-up investigations.&lt;/p&gt;
    &lt;p&gt;Ofcom previously identified "serious compliance concerns" with its CSAM enforcement program at 1Fichier.com and Gofile.io, leading to investigations being opened into them both.&lt;/p&gt;
    &lt;p&gt;After constructive engagement with the regulator, both now deploy hash-matching tech and escaped further action.&lt;/p&gt;
    &lt;p&gt;Suzanne Cater, director of enforcement at Ofcom, said: "Today sends a clear message that any service which flagrantly fails to engage with Ofcom and their duties under the Online Safety Act can expect to face robust enforcement action.&lt;/p&gt;
    &lt;p&gt;"We're also seeing some services take steps to introduce improved safety measures as a direct result of our enforcement action. Services who choose to restrict access rather than protect UK users remain on our watchlist as we continue to monitor their availability to UK users." Â®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2025/10/13/4chan_ofcom_fine/"/><published>2025-10-13T14:34:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568842</id><title>A16Z-backed data firms Fivetran, dbt Labs to merge in all-stock deal</title><updated>2025-10-13T16:12:32.596833+00:00</updated><content>&lt;doc fingerprint="a990c55b08b8a7d1"&gt;
  &lt;main&gt;
    &lt;p&gt;Oct 13 (Reuters) - Data startups Fivetran and dbt Labs will merge in an all-stock deal, creating a combined data infrastructure company with nearly $600 million in annual revenue, the two companies told Reuters.&lt;/p&gt;
    &lt;p&gt;The deal is structured as an all-stock exchange based on an agreed ratio tied to revenues and growth rates, Fivetran Chief Executive George Fraser said in an interview. The combined entity is worth more than its last private valuation, Fraser said, but added that the valuation will ultimately be determined by the market.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;Fivetran was last publicly valued at $5.6 billion in September 2021, while dbt Labs was valued at $4.2 billion in a Series D round in February 2022. The companies share some investors, including Andreessen Horowitz.&lt;/p&gt;
    &lt;p&gt;Upon closing, Fraser will serve as CEO of the combined company, while dbt Labs CEO Tristan Handy will become co-founder and president.&lt;/p&gt;
    &lt;p&gt;The transaction, which unites two highly valued venture-backed startups, marks significant consolidation in the data tooling market as enterprises race to adapt infrastructure for artificial intelligence applications, which require organized access to internal data.&lt;/p&gt;
    &lt;p&gt;"The thing is really unique about this combination is our emphasis on open infrastructure and interoperability... as everyone is trying to figure out how to use their business data in the context of AI," Fraser said.&lt;/p&gt;
    &lt;p&gt;Oakland, California-based Fivetran specializes in automated data movement, helping companies pull information from various sources into a central data warehouse. Philadelphia-based dbt Labs created dbt, an open-source tool for transforming and preparing that data for analysis.&lt;/p&gt;
    &lt;p&gt;Describing the companies' products as complementary, Fraser estimated that 80% to 90% of Fivetran's customers use dbt's tools. The new company will also keep dbt Core, the popular open-source version of dbt Labs' software, available under its current license.&lt;/p&gt;
    &lt;p&gt;The goal is to build a more comprehensive platform for enterprises' data needs, Fraser said, with the increased scale and broader platform strengthening its position for a public listing, even though an IPO is not imminent.&lt;/p&gt;
    &lt;p&gt;Fraser added that the deal is a merger of equals rather than an acquisition as the new company's board will have representation from both Fivetran and dbt Labs, and that the firm will be near cash-flow break-even.&lt;/p&gt;
    &lt;p&gt;Fivetran and dbt Labs expect the deal to close within a year. The Information had earlier reported on talks between the two firms.&lt;/p&gt;
    &lt;p&gt;Reporting by Krystal Hu in San Francisco; Editing by Janane Venkatraman&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/business/a16z-backed-data-firms-fivetran-dbt-labs-merge-all-stock-deal-2025-10-13/"/><published>2025-10-13T14:42:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568955</id><title>AI and the Future of American Politics</title><updated>2025-10-13T16:12:32.472887+00:00</updated><content>&lt;doc fingerprint="bd10923da2f9c589"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;AI and the Future of American Politics&lt;/head&gt;
    &lt;p&gt;Two years ago, Americans anxious about the forthcoming 2024 presidential election were considering the malevolent force of an election influencer: artificial intelligence. Over the past several years, we have seen plenty of warning signs from elections worldwide demonstrating how AI can be used to propagate misinformation and alter the political landscape, whether by trolls on social media, foreign influencers, or even a street magician. AI is poised to play a more volatile role than ever before in Americaâ€™s next federal election in 2026. We can already see how different groups of political actors are approaching AI. Professional campaigners are using AI to accelerate the traditional tactics of electioneering; organizers are using it to reinvent how movements are built; and citizens are using it both to express themselves and amplify their sideâ€™s messaging. Because there are so few rules, and so little prospect of regulatory action, around AIâ€™s role in politics, there is no oversight of these activities, and no safeguards against the dramatic potential impacts for our democracy.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Campaigners&lt;/head&gt;
    &lt;p&gt;Campaignersâ€”messengers, ad buyers, fundraisers, and strategistsâ€”are focused on efficiency and optimization. To them, AI is a way to augment or even replace expensive humans who traditionally perform tasks like personalizing emails, texting donation solicitations, and deciding what platforms and audiences to target.&lt;/p&gt;
    &lt;p&gt;This is an incremental evolution of the computerization of campaigning that has been underway for decades. For example, the progressive campaign infrastructure group Tech for Campaigns claims it used AI in the 2024 cycle to reduce the time spent drafting fundraising solicitations by one-third. If AI is working well here, you wonâ€™t notice the difference between an annoying campaign solicitation written by a human staffer and an annoying one written by AI.&lt;/p&gt;
    &lt;p&gt;But AI is scaling these capabilities, which is likely to make them even more ubiquitous. This will make the biggest difference for challengers to incumbents in safe seats, who see AI as both a tacitly useful tool and an attention-grabbing way to get their race into the headlines. Jason Palmer, the little-known Democratic primary challenger to Joe Biden, successfully won the American Samoa primary while extensively leveraging AI avatars for campaigning.&lt;/p&gt;
    &lt;p&gt;Such tactics were sometimes deployed as publicity stunts in the 2024 cycle; they were firsts that got attention. Pennsylvania Democratic Congressional candidate Shamaine Daniels became the first to use a conversational AI robocaller in 2023. Two long-shot challengers to Rep. Don Beyer used an AI avatar to represent the incumbent in a live debate last October after he declined to participate. In 2026, voters who have seen years of the official White House X account posting deepfaked memes of Donald Trump will be desensitized to the use of AI in political communications.&lt;/p&gt;
    &lt;p&gt;Strategists are also turning to AI to interpret public opinion data and provide more fine-grained insight into the perspective of different voters. This might sound like AIs replacing people in opinion polls, but it is really a continuation of the evolution of political polling into a data-driven science over the last several decades.&lt;/p&gt;
    &lt;p&gt;A recent survey by the American Association of Political Consultants found that a majority of their membersâ€™ firms already use AI regularly in their work, and more than 40 percent believe it will â€œfundamentally transformâ€ the future of their profession. If these emerging AI tools become popular in the midterms, it wonâ€™t just be a few candidates from the tightest national races texting you three times a day. It may also be the member of Congress in the safe district next to you, and your state representative, and your school board members.&lt;/p&gt;
    &lt;p&gt;The development and use of AI in campaigning is different depending on what side of the aisle you look at. On the Republican side, Push Digital Group is going â€œall inâ€ on a new AI initiative, using the technology to create hundreds of ad variants for their clients automatically, as well as assisting with strategy, targeting, and data analysis. On the other side, the National Democratic Training Committee recently released a playbook for using AI. Quiller is building an AI-powered fundraising platform aimed at drastically reducing the time campaigns spend producing emails and texts. Progressive-aligned startups Chorus AI and BattlegroundAI are offering AI tools for automatically generating ads for use on social media and other digital platforms. DonorAtlas automates data collection on potential donors, and RivalMind AI focuses on political research and strategy, automating the production of candidate dossiers.&lt;/p&gt;
    &lt;p&gt;For now, there seems to be an investment gap between Democratic- and Republican-aligned technology innovators. Progressive venture fund Higher Ground Labs boasts $50 million in deployed investments since 2017 and a significant focus on AI. Republican-aligned counterparts operate on a much smaller scale. Startup Caucus has announced one investmentâ€”of $50,000â€”since 2022. The Center for Campaign Innovation funds research projects and events, not companies. This echoes a longstanding gap in campaign technology between Democratic- and Republican-aligned fundraising platforms ActBlue and WinRed, which has landed the former in Republicansâ€™ political crosshairs.&lt;/p&gt;
    &lt;p&gt;Of course, not all campaign technology innovations will be visible. In 2016, the Trump campaign vocally eschewed using data to drive campaign strategy and appeared to be falling way behind on ad spending, but wasâ€”we learned in retrospectâ€”actually leaning heavily into digital advertising and making use of new controversial mechanisms for accessing and exploiting votersâ€™ social media data with vendor Cambridge Analytica. The most impactful uses of AI in the 2026 midterms may not be known until 2027 or beyond.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Organizers&lt;/head&gt;
    &lt;p&gt;Beyond the realm of political consultants driving ad buys and fundraising appeals, organizers are using AI in ways that feel more radically new.&lt;/p&gt;
    &lt;p&gt;The hypothetical potential of AI to drive political movements was illustrated in 2022 when a Danish artist collective used an AI model to found a political party, the Synthetic Party, and generate its policy goals. This was more of an art project than a popular movement, but it demonstrated that AIsâ€”synthesizing the expressions and policy interests of humansâ€”can formulate a political platform. In 2025, Denmark hosted a â€œsummitâ€ of eight such AI political agents where attendees could witness â€œcontinuously orchestrate[d] algorithmic micro-assemblies, spontaneous deliberations, and impromptu policy-makingâ€ by the participating AIs.&lt;/p&gt;
    &lt;p&gt;The more viable version of this concept lies in the use of AIs to facilitate deliberation. AIs are being used to help legislators collect input from constituents and to hold large-scale citizen assemblies. This kind of AI-driven â€œsensemakingâ€ may play a powerful role in the future of public policy. Some research has suggested that AI can be as or more effective than humans in helping people find common ground on controversial policy issues.&lt;/p&gt;
    &lt;p&gt;Another movement for â€œPublic AIâ€ is focused on wresting AI from the hands of corporations to put people, through their governments, in control. Civic technologists in national governments from Singapore, Japan, Sweden, and Switzerland are building their own alternatives to Big Tech AI models, for use in public administration and distribution as a public good.&lt;/p&gt;
    &lt;p&gt;Labor organizers have a particularly interesting relationship to AI. At the same time that they are galvanizing mass resistance against the replacement or endangerment of human workers by AI, many are racing to leverage the technology in their own work to build power.&lt;/p&gt;
    &lt;p&gt;Some entrepreneurial organizers have used AI in the past few years as tools for activating, connecting, answering questions for, and providing guidance to their members. In the UK, the Centre for Responsible Union AI studies and promotes the use of AI by unions; theyâ€™ve published several case studies. The UK Public and Commercial Services Union has used AI to help their reps simulate recruitment conversations before going into the field. The Belgian union ACV-CVS has used AI to sort hundreds of emails per day from members to help them respond more efficiently. Software companies such as Quorum are increasingly offering AI-driven products to cater to the needs of organizers and grassroots campaigns.&lt;/p&gt;
    &lt;p&gt;But unions have also leveraged AI for its symbolic power. In the U.S., the Screen Actors Guild held up the specter of AI displacement of creative labor to attract public attention and sympathy, and the ETUC (the European confederation of trade unions) developed a policy platform for responding to AI.&lt;/p&gt;
    &lt;p&gt;Finally, some union organizers have leveraged AI in more provocative ways. Some have applied it to hacking the â€œbosswareâ€ AI to subvert the exploitative intent or disrupt the anti-union practices of their managers.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Citizens&lt;/head&gt;
    &lt;p&gt;Many of the tasks weâ€™ve talked about so far are familiar use cases to anyone working in office and management settings: writing emails, providing user (or voter, or member) support, doing research.&lt;/p&gt;
    &lt;p&gt;But even mundane tasks, when automated at scale and targeted at specific ends, can be pernicious. AI is not neutral. It can be applied by many actors for many purposes. In the hands of the most numerous and diverse actors in a democracyâ€”the citizensâ€”that has profound implications.&lt;/p&gt;
    &lt;p&gt;Conservative activists in Georgia and Florida have used a tool named EagleAI to automate challenging voter registration en masse (although the toolâ€™s creator later denied that it uses AI). In a nonpartisan electoral management context with access to accurate data sources, such automated review of electoral registrations might be useful and effective. In this hyperpartisan context, AI merely serves to amplify the proclivities of activists at the extreme of their movements. This trend will continue unabated in 2026.&lt;/p&gt;
    &lt;p&gt;Of course, citizens can use AI to safeguard the integrity of elections. In Ghanaâ€™s 2024 presidential election, civic organizations used an AI tool to automatically detect and mitigate electoral disinformation spread on social media. The same year, Kenyan protesters developed specialized chatbots to distribute information about a controversial finance bill in Parliament and instances of government corruption.&lt;/p&gt;
    &lt;p&gt;So far, the biggest way Americans have leveraged AI in politics is in self-expression. About ten million Americans have used the chatbot Resistbot to help draft and send messages to their elected leaders. Itâ€™s hard to find statistics on how widely adopted tools like this are, but researchers have estimated that, as of 2024, about one in five consumer complaints to the U.S. Consumer Financial Protection Bureau was written with the assistance of AI.&lt;/p&gt;
    &lt;p&gt;OpenAI operates security programs to disrupt foreign influence operations and maintains restrictions on political use in its terms of service, but this is hardly sufficient to deter use of AI technologies for whatever purpose. And widely available free models give anyone the ability to attempt this on their own.&lt;/p&gt;
    &lt;p&gt;But this could change. The most ominous sign of AIâ€™s potential to disrupt elections is not the deepfakes and misinformation. Rather, it may be the use of AI by the Trump administration to surveil and punish political speech on social media and other online platforms. The scalability and sophistication of AI tools give governments with authoritarian intent unprecedented power to police and selectively limit political speech.&lt;/p&gt;
    &lt;head rend="h3"&gt;What About the Midterms?&lt;/head&gt;
    &lt;p&gt;These examples illustrate AIâ€™s pluripotent role as a force multiplier. The same technology used by different actorsâ€”campaigners, organizers, citizens, and governmentsâ€”leads to wildly different impacts. We canâ€™t know for sure what the net result will be. In the end, it will be the interactions and intersections of these uses that matters, and their unstable dynamics will make future elections even more unpredictable than in the past.&lt;/p&gt;
    &lt;p&gt;For now, the decisions of how and when to use AI lie largely with individuals and the political entities they lead. Whether or not you personally trust AI to write an email for you or make a decision about you hardly matters. If a campaign, an interest group, or a fellow citizen trusts it for that purpose, they are free to use it.&lt;/p&gt;
    &lt;p&gt;It seems unlikely that Congress or the Trump administration will put guardrails around the use of AI in politics. AI companies have rapidly emerged as among the biggest lobbyists in Washington, reportedly dumping $100 million toward preventing regulation, with a focus on influencing candidate behavior before the midterm elections. The Trump administration seems open and responsive to their appeals.&lt;/p&gt;
    &lt;p&gt;The ultimate effect of AI on the midterms will largely depend on the experimentation happening now. Candidates and organizations across the political spectrum have ample opportunityâ€”but a ticking clockâ€”to find effective ways to use the technology. Those that do will have little to stop them from exploiting it.&lt;/p&gt;
    &lt;p&gt;This essay was written with Nathan E. Sanders, and originally appeared in The American Prospect.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.schneier.com/blog/archives/2025/10/ai-and-the-future-of-american-politics.html"/><published>2025-10-13T14:51:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569043</id><title>Supermassive black holes locked in a stable orbit around each other</title><updated>2025-10-13T16:12:31.206302+00:00</updated><content>&lt;doc fingerprint="b3023af91812cb93"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Researchers have released the first confirmed image of two black holes orbiting each other. The observation confirms a theory that has remained unproven for more than 40 years.&lt;/p&gt;
      &lt;p&gt;The discovery centres on quasar OJ287, located five billion light-years from Earth in the constellation Cancer. Quasars are the luminous cores of distant galaxies, powered by the gravitational energy of supermassive black holes.&lt;/p&gt;
      &lt;p&gt;The image shows two bright points, each representing a jet of high-energy particles emitted by one of the black holes.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The black holes themselves remain invisible, but the image provides clear visual evidence of their position, motion, and dual existence. The larger of the two has a mass estimated at 18 billion times that of the Sun. The smaller is around 150 million times the Sunâ€™s mass.&lt;/p&gt;
    &lt;p&gt;The team behind the discovery used radio data collected a decade ago by the RadioAstron satellite, whose antenna extended to nearly halfway between Earth and the Moon. This allowed for an image resolution roughly 100,000 times higher than that achieved by Earth-based telescopes.&lt;/p&gt;
    &lt;p&gt;Mauri Valtonen, an astronomer at the University of Turku and lead author of the study published in the Astrophysical Journal, said the image marks the first direct evidence of a binary black hole system. â€œFor the first time, we managed to get an image of two black holes circling each other. The black holes are identified by the intense particle jets they emit,â€ he said.&lt;/p&gt;
    &lt;p&gt;The existence of two black holes in OJ287 was first suggested in 1982. Aimo SillanpÃ¤Ã¤, then a graduate student at the University of Turku, observed that the brightness of the quasar changed regularly over a 12-year cycle. The pattern implied that two massive objects were orbiting each other and affecting the quasarâ€™s brightness as they passed through surrounding matter.&lt;/p&gt;
    &lt;p&gt;For decades, scientists monitored the object using various observational tools, including the NASA TESS satellite, which captured visible light from both black holes. However, those observations lacked the resolution to separate the two sources. Only radio telescopes, particularly those operating in space, could deliver the needed clarity.&lt;/p&gt;
    &lt;p&gt;The new image was compared to predictions from models developed by researchers, including calculations by Lankeswar Dey, a doctoral researcher from Mumbai who contributed to orbit predictions for the OJ287 system. The jets appeared exactly where the models said they should, confirming both the orbital pattern and the binary nature of the system.&lt;/p&gt;
    &lt;p&gt;The scientists also detected a new phenomenon in the smaller black holeâ€™s jet. The jet twists in different directions, resembling the motion of a garden hose as it spins. The team attributes this to the speed and direction of the black holeâ€™s orbit, which alters the trajectory of the jet over time. They believe future images will show the jetâ€™s orientation changing as the black hole moves.&lt;/p&gt;
    &lt;p&gt;The presence of two black holes at the centre of a quasar supports long-standing predictions about the evolution of galaxies. Black hole mergers are thought to be common in galactic history, but direct visual proof has been rare. Until now, evidence of binary systems relied on indirect observations, such as gravitational waves or variations in light from distant objects.&lt;/p&gt;
    &lt;p&gt;Valtonen said that the achievement depended on combining past data with modern theoretical models. â€œThe two black holes were exactly where we expected them to be,â€ he said.&lt;/p&gt;
    &lt;p&gt;The use of the now-retired RadioAstron satellite was key to the success of the project. Since 2019, radio observations have relied on ground-based telescopes, which do not have the same imaging capacity.&lt;/p&gt;
    &lt;p&gt;The image of the two black holes was produced by analysing the radio emissions from OJ287 captured during RadioAstronâ€™s mission. Scientists identified the lower two bright spots in the image as the jets from the black holes. A third bright spot was traced to the smaller black holeâ€™s jet.&lt;/p&gt;
    &lt;p&gt;The discovery follows earlier black hole imaging milestones. In 2019, astronomers captured the first image of a black hole in the galaxy Messier 87. Later, a similar image was obtained from the centre of the Milky Way. Both were single black holes.&lt;/p&gt;
    &lt;p&gt;The new image is the first to show two supermassive black holes locked in a stable orbit around each other. The systemâ€™s 12-year orbital period means researchers can track future movements and verify the pattern of interactions between the pair.&lt;/p&gt;
    &lt;p&gt;Valtonen said that even amateur astronomers can detect light from OJ287, though the two black holes themselves remain beyond the range of optical telescopes.&lt;/p&gt;
    &lt;p&gt;HT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.helsinkitimes.fi/themes/themes/science-and-technology/28090-scientists-capture-first-image-of-two-black-holes-in-orbit.html"/><published>2025-10-13T14:59:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569108</id><title>More than 130k Vodafone customers report outage</title><updated>2025-10-13T16:12:31.120502+00:00</updated><content>&lt;doc fingerprint="fc3178710cb0e6c1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vodafone admits 'major outage' as more than 130,000 report problems&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thousands of Vodafone customers across the UK have reported its services are down.&lt;/p&gt;
    &lt;p&gt;Downdetector, which monitors web outages, showed more than 130,000 people had flagged problems affecting their Vodafone broadband or mobile network on Monday afternoon.&lt;/p&gt;
    &lt;p&gt;According to its website, the firm has more than 18 million customers in the UK, including nearly 700,000 home broadband customers.&lt;/p&gt;
    &lt;p&gt;Vodafone said in a statement it was aware of a "major issue on our network affecting broadband, 4G and 5G services".&lt;/p&gt;
    &lt;p&gt;"We appreciate our customers' patience while we work to resolve this as soon as possible," the company said.&lt;/p&gt;
    &lt;p&gt;It comes as people on social media say they are struggling to access Vodafone customer service operators amid ongoing issues affecting mobile data and broadband.&lt;/p&gt;
    &lt;p&gt;Many have also said they are having difficulty accessing the company's website and app, which typically allow people to view the status of its network services.&lt;/p&gt;
    &lt;p&gt;Customers have also taken to social media to complain of "complete outages" in their area.&lt;/p&gt;
    &lt;p&gt;The issues appear to have begun for customers shortly after 15:00 BST.&lt;/p&gt;
    &lt;p&gt;Internet monitor Netblocks said in a post on X, external, live network data showed Vodafone was experiencing "a national outage" impacting both broadband and mobile data.&lt;/p&gt;
    &lt;p&gt;Some customers have expressed being doubly frustrated by not being able to access their Wi-Fi or mobile data.&lt;/p&gt;
    &lt;p&gt;"Sort it out soon please," wrote one frustrated X user - who said they were having to use a coffee shop's Wi-Fi to access online services without the means to do so using their mobile data or broadband.&lt;/p&gt;
    &lt;p&gt;Another said they were self-employed and could not work because of the outage, adding: "Never regretted more having my mobile and broadband on the same network."&lt;/p&gt;
    &lt;p&gt;The issues affecting Vodafone services are also impacting customers of other telecoms firms that use its network.&lt;/p&gt;
    &lt;p&gt;Downdetector saw a similar spike in reports on Monday afternoon from users of the mobile network Voxi, which is owned by Vodafone.&lt;/p&gt;
    &lt;p&gt;Lebara, which piggy-backs off Vodafone's network, has also been affected by the company's outage.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published30 September 2019&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published5 December 2024&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.co.uk/news/articles/c5yldldx659o"/><published>2025-10-13T15:03:53+00:00</published></entry></feed>