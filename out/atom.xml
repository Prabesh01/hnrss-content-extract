<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-09T14:08:16.516527+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45810099</id><title>Show HN: Sparktype ‚Äì a CMS and SSG that runs entirely in the browser</title><updated>2025-11-09T14:08:25.882423+00:00</updated><link href="https://app.sparktype.org"/><published>2025-11-04T12:24:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45856804</id><title>Study identifies weaknesses in how AI systems are evaluated</title><updated>2025-11-09T14:08:24.757681+00:00</updated><content>&lt;doc fingerprint="7dc8d0970fb3495b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;A new study led by the Oxford Internet Institute (OII) at the University of Oxford and involving a team of 42 researchers from leading global institutions including EPFL, Stanford University, the Technical University of Munich, UC Berkeley, the UK AI Security Institute, the Weizenbaum Institute, and Yale University, has found that many of the tests used to measure the capabilities and safety of large language models (LLMs) lack scientific rigour. &lt;/p&gt;
      &lt;p&gt;In Measuring What Matters: Construct Validity in Large Language Model Benchmarks, accepted for publication in the upcoming NeurIPS conference proceedings, researchers review 445 AI benchmarks ‚Äì the standardised evaluations used to compare and rank AI systems. &lt;/p&gt;
      &lt;p&gt;The researchers found that many of these benchmarks are built on unclear definitions or weak analytical methods, making it difficult to draw reliable conclusions about AI progress, capabilities or safety. &lt;/p&gt;
      &lt;p&gt;‚ÄúBenchmarks underpin nearly all claims about advances in AI,‚Äù says Andrew Bean, lead author of the study. ‚ÄúBut without shared definitions and sound measurement, it becomes hard to know whether models are genuinely improving or just appearing to.‚Äù &lt;/p&gt;
      &lt;p&gt;Benchmarks play a central role in how AI systems are designed, deployed, and regulated. They guide research priorities, shape competition between models, and are increasingly referenced in policy and regulatory frameworks, including the EU AI Act, which calls for risk assessments based on ‚Äúappropriate technical tools and benchmarks.‚Äù &lt;/p&gt;
      &lt;p&gt;The study warns that if benchmarks are not scientifically sound, they may give developers and regulators a misleading picture of how capable or safe AI systems really are. &lt;/p&gt;
      &lt;p&gt;‚ÄúThis work reflects the kind of large-scale collaboration the field needs,‚Äù adds Dr. Adam Mahdi. ‚ÄúBy bringing together leading AI labs, we‚Äôre starting to tackle one of the most fundamental gaps in current AI evaluation.‚Äù &lt;/p&gt;
      &lt;p&gt;Key findings &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt; Lack of statistical rigour&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Only 16% of the reviewed studies used statistical methods when comparing model performance. This means that reported differences between systems or claims of superiority could be due to chance rather than genuine improvement. &lt;/p&gt;
      &lt;list start="2" rend="ol"&gt;
        &lt;item&gt; Vague or contested definitions&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Around half of the benchmarks aimed to measure abstract ideas such as reasoning or harmlessness without clearly defining what those terms mean. Without a shared understanding of these concepts, it is difficult to ensure that benchmarks are testing what they intend to.&lt;/p&gt;
      &lt;p&gt;Examples &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Confounding formatting rules ‚Äì A test might ask a model to solve a simple logic puzzle but also require it to present the answer in a very specific, complicated format. If the model gets the puzzle right but fails the formatting, it looks worse than it really is. &lt;/item&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Brittle performance ‚Äì A model might do well on short, primary school-style maths questions, but if you change the numbers or wording slightly, it suddenly fails. This shows it may be memorising patterns rather than truly understanding the problem&lt;/item&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Unsupported claims ‚Äì If a model scores well on multiple-choice questions from medical exams, people might claim it has doctor-level expertise. But passing an exam is only one small part of what doctors do, so the result can be misleading.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Recommendations for better benchmarking &lt;/p&gt;
      &lt;p&gt;The authors stress that these problems are fixable. Drawing on established methods from fields such as psychometrics and medicine, they propose eight recommendations to improve the validity of AI benchmarks. These include: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Define and isolate: Provide a precise, operational definition for the concept being measured and control for unrelated factors. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;Build representative evaluations: Ensure test items represent real-world conditions and cover the full scope of the target skill or behaviour. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;Strengthen analysis and justification: Use statistical methods to report uncertainty and enable robust comparisons; conduct detailed error analysis to understand why a model fails; and justify why the benchmark is a valid measure for its intended purpose. &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The team also provides a Construct Validity Checklist, a practical tool researchers, developers, and regulators can use to assess whether an AI benchmark follows sound design principles before relying on its results. The checklist is available at https://oxrml.com/measuring-what-matters/ &lt;/p&gt;
      &lt;p&gt;The paper, Measuring What Matters: Construct Validity in Large Language Model Benchmarks, will be published as part of the NeurIPS 2025 peer-reviewed conference proceedings in San Diego from 2-7 December. The peer-reviewed paper is available on request. &lt;/p&gt;
      &lt;p&gt;Media spokespeople &lt;/p&gt;
      &lt;p&gt;Lead author: Andrew Bean, Doctoral Student, Oxford Internet Institute, University of Oxford &lt;/p&gt;
      &lt;p&gt;Senior authors: Adam Mahdi, Associate Professor, and Luc Rocher, Associate Professor, Oxford Internet Institute, University of Oxford &lt;/p&gt;
      &lt;p&gt;Contact &lt;/p&gt;
      &lt;p&gt;For more information and briefings, please contact: &lt;lb/&gt; Anthea Milnes, Head of Communications &lt;lb/&gt; Sara Spinks / Veena McCoole, Media and Communications Manager &lt;/p&gt;
      &lt;p&gt;T: +44 (0)1865 280527 &lt;/p&gt;
      &lt;p&gt;M: +44 (0)7551 345493 &lt;/p&gt;
      &lt;p&gt;E: press@oii.ox.ac.uk &lt;/p&gt;
      &lt;p&gt;About the Oxford Internet Institute (OII) &lt;/p&gt;
      &lt;p&gt;The Oxford Internet Institute (OII) has been at the forefront of exploring the human impact of emerging technologies for 25 years. As a multidisciplinary research and teaching department, we bring together scholars and students from diverse fields to examine the opportunities and challenges posed by transformative innovations such as artificial intelligence, large language models, machine learning, digital platforms, and autonomous agents. &lt;/p&gt;
      &lt;p&gt;About the University of Oxford &lt;/p&gt;
      &lt;p&gt;Oxford University was placed number one in the Times Higher Education World University Rankings for the tenth year running in 2025. At the heart of this success are the twin-pillars of our ground-breaking research and innovation and our distinctive educational offer. Oxford is world-famous for research and teaching excellence and home to some of the most talented people from across the globe. &lt;/p&gt;
      &lt;p&gt;Funding information &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;A.M.B. is supported in part by the Clarendon Scholarships and the Oxford Internet Institute‚Äôs Research Programme on AI &amp;amp; Work. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;A.M. is supported by the Oxford Internet Institute‚Äôs Research Programme on AI &amp;amp; Work. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;R.O.K. is supported by a Fellowship from the Cosmos Institute. H.M. is supported by ESRC [ES/P000649/1] and would like to acknowledge the London Initiative for Safe AI. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="4" data-aria-level="1"&gt;C.E. is supported by the EPSRC Centre for Doctoral Training in Health Data Science (EP/S02428X/1) and the AXA Research Fund. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="5" data-aria-level="1"&gt;F.L. is supported by Clarendon and Jason Hu studentships. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="6" data-aria-level="1"&gt;H.R.K.‚Äôs PhD is supported by the Economic and Social Research Council grant ES/P000649/1. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="7" data-aria-level="1"&gt;M.G. was supported by the SMARTY (PCI2024-153434) project funded by the Agencia Estatal de Investigaci√≥n (doi:10.13039/501100011033) and by the European Commission through the Chips Act Joint Undertaking project SMARTY (Grant 101140087). This material is based in part upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-2139841. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="8" data-aria-level="1"&gt;O.D. is supported by the UKRI‚Äôs EPSRC AIMS CDT grant (EP/S024050/1). &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="9" data-aria-level="1"&gt;J.R is supported by the Engineering and Physical Sciences Research Council. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="10" data-aria-level="1"&gt;J.B. would like to acknowledge funding by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 16DII131. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="11" data-aria-level="1"&gt;A. Bibi would like to acknowledge the UK AISI systemic safety grant. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="ÔÇ∑" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;ÔÇ∑&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="12" data-aria-level="1"&gt;A. Bosselut gratefully acknowledges the support of the Swiss National Science Foundation (No. 215390), Innosuisse (PFFS-21-29), the EPFL Center for Imaging, Sony Group Corporation, and a Meta LLM Evaluation Research Grant. &lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.oii.ox.ac.uk/news-events/study-identifies-weaknesses-in-how-ai-systems-are-evaluated/"/><published>2025-11-08T14:18:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45857988</id><title>Opencloud ‚Äì An alternative to Nextcloud written in Go</title><updated>2025-11-09T14:08:24.127172+00:00</updated><content>&lt;doc fingerprint="ef05bc5f19e668bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;For general information about OpenCloud and how to install please visit OpenCloud on Github and OpenCloud GmbH.&lt;/p&gt;
    &lt;p&gt;This is the main repository of the OpenCloud server. It contains the golang codebase for the backend services.&lt;/p&gt;
    &lt;p&gt;The OpenCloud server is released under Apache 2.0. The project is thrilled to receive contributions in all forms. Start hacking now, there are many ways to get involved such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reporting issues or bugs&lt;/item&gt;
      &lt;item&gt;Requesting features&lt;/item&gt;
      &lt;item&gt;Writing documentation&lt;/item&gt;
      &lt;item&gt;Writing code or extend our tests&lt;/item&gt;
      &lt;item&gt;Reviewing code&lt;/item&gt;
      &lt;item&gt;Helping others in the community&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every contribution is meaningful and appreciated! Please refer to our Contribution Guidelines if you want to get started.&lt;/p&gt;
    &lt;p&gt;To build the backend, follow these instructions:&lt;/p&gt;
    &lt;p&gt;Generate the assets needed by e.g., the web UI and the builtin IDP&lt;/p&gt;
    &lt;code&gt;make generate&lt;/code&gt;
    &lt;p&gt;Then compile the &lt;code&gt;opencloud&lt;/code&gt; binary&lt;/p&gt;
    &lt;code&gt;make -C opencloud build&lt;/code&gt;
    &lt;p&gt;That will produce the binary &lt;code&gt;opencloud/bin/opencloud&lt;/code&gt;. It can be started as a local test instance right away with a two step command:&lt;/p&gt;
    &lt;code&gt;opencloud/bin/opencloud init &amp;amp;&amp;amp; opencloud/bin/opencloud server&lt;/code&gt;
    &lt;p&gt;This creates a server configuration (by default in &lt;code&gt;$HOME/.opencloud&lt;/code&gt;) and starts the server.&lt;/p&gt;
    &lt;p&gt;For more setup- and installation options consult the Development Documentation.&lt;/p&gt;
    &lt;p&gt;Important information for contributors about the technology in use.&lt;/p&gt;
    &lt;p&gt;The OpenCloud backend authenticates users via OpenID Connect using either an external IdP like Keycloak or the embedded LibreGraph Connect identity provider.&lt;/p&gt;
    &lt;p&gt;The OpenCloud backend does not use a database. It stores all data in the filesystem. By default, the root directory of the backend is &lt;code&gt;$HOME/.opencloud/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If you find a security-related issue, please contact security@opencloud.eu immediately.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/opencloud-eu/opencloud"/><published>2025-11-08T16:40:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45858905</id><title>Marko ‚Äì A declarative, HTML‚Äëbased language</title><updated>2025-11-09T14:08:23.718719+00:00</updated><content>&lt;doc fingerprint="a876cc8c70be3ce3"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Trusted&lt;/head&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;If you know HTML, CSS, and JavaScript, you know Marko&lt;/p&gt;&lt;p&gt;Streaming, resumable, optimizing compiler, and a tiny runtime&lt;/p&gt;&lt;p&gt;From simple HTML templates to powerful components as needed&lt;/p&gt;&lt;p&gt;Marko is HTML re‚Äëimagined as a language for building dynamic and reactive user interfaces.&lt;/p&gt;&lt;p&gt;Just about any valid HTML is valid Marko, but Marko extends the HTML language to allow building modern applications in a declarative way.&lt;/p&gt;Check it out!&lt;p&gt;Marko streams content to your users as soon as it's ready. No waiting for client side JavaScript bundles or data requests to start rendering.&lt;/p&gt;&lt;p&gt;HTML, assets, and images are loaded as soon as possible with asynchronous content loading in as it completes.&lt;/p&gt;Learn How&lt;p&gt;Browsers and servers are built differently, shouldn't your code be too? Marko compiles your templates to perform their best with optimized, environment-specific output.&lt;/p&gt;&lt;p&gt;Faster loads. Smaller bundles. One seamless language.&lt;/p&gt;Learn How&lt;p&gt;Marko has built-in TypeScript support , with strong type inference that works across templates and components. Editors get full language features like autocompletion, jump-to-definition, syntax highlighting, and clean formatting.&lt;/p&gt;&lt;p&gt;Build confidently. Catch errors early. Write better code, faster.&lt;/p&gt;Explore&lt;p&gt;Need help? Want to Contribute?&lt;/p&gt;&lt;p&gt;Get involved in the Marko Community!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://markojs.com/"/><published>2025-11-08T18:43:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45859243</id><title>Aver√≠a: The Average Font (2011)</title><updated>2025-11-09T14:08:23.336553+00:00</updated><content>&lt;doc fingerprint="367d013713a223d1"&gt;
  &lt;main&gt;
    &lt;p&gt;am not a type designer. This is the story of the creation of a new font, Aver√≠a: the average of all the fonts on my computer. The field of typography has long fascinated me, and I love playing with creative programming ideas, so it was perhaps inevitable that the idea came to me one day of ‚Äúgenerative typography‚Äù. A Google on the subject brought up little, and I put the idea to the back of my mind until it occurred to me that perhaps the process of averaging, or interpolating, existing fonts might bring up interesting results. Luckily at this point I didn't do any more web searching ‚Äì instead I grabbed my laptop and came up with an initial idea for finding what the average of all my fonts might look like ‚Äì by overlaying each letter at low opacity. The results can be seen in the below image.&lt;/p&gt;
    &lt;p&gt;This was done by printing each letter of each font, at the same point size, to lots of separate images, and then averaging them ‚Äì using ImageMagick and PHP. The letters were aligned to the same centre point. I later realised that each font has a ‚Äòbaseline‚Äô defined, and an origin on that baseline which each glyph is drawn relative to. The same process, repeated with equal origins, gives slightly different results (see below) ‚Äì here you can see the baseline is very well-defined, with the glyphs becoming more blurred towards the top right of each.&lt;/p&gt;
    &lt;p&gt;I was quite pleased with the results. It was only later that I discovered this had already been done ‚Äì though it appeared that my end results (whilst not as beautifully animated) had a little more clarity, so I'm glad I tried for myself. But this didn't seem like the end of the journey. Whilst this was an interesting experiment, and showed an lot of correlation between a sample of common fonts (as well as a couple of oddities ‚Äì notably the lower case ‚Äòg‚Äô which clearly exists in two distinct common forms), what I really wanted was an average which somehow preserved the well-defined edges of existing fonts. So I started considering ways to produce a smoother, sharper average of letter forms.&lt;/p&gt;
    &lt;p&gt;One idea which seemed obvious was to simply take the blurry results of the first experiment, and use a threshold to create monochrome images. A few experiments in this direction (I first tried with a lower-case ‚Äòf‚Äô, which I later found was never likely to give good results due to the variance in height of the middle cross-stroke) convinced me that I needed to look into cleverer ways to achieve this. Surely there must be a simple way to average shapes, while keeping the result as a shape?&lt;/p&gt;
    &lt;p&gt;It turns out not to be straightforward. There are many possible ways to ‚Äòmorph‚Äô between two shapes ‚Äì and what might seem the most natural generally depends on our perception of ‚Äòfeatures‚Äô in the shapes. Consider the average of a capital I with serifs, and one without: the natural thing to do would be something like, make the serifs half as big, and use a horizontal stem width about half-way between the two glyphs. That's two feature concepts being applied to the abstract forms¬π. To take a simpler example, what is the average of a square with the same square rotated 45Àö? There are a few possibilities ‚Ä¶&lt;/p&gt;
    &lt;p&gt;So, this stumped me for a while. I decided I needed to get to know fonts better, so I built a simple web app to view the lines, curves and control points present in the fonts I had. On this basis, I started to consider the ways the features (vertices, curves, stems, serifs etc) might be matched up between fonts. However, this was a rabbit hole I might never get to the bottom of - particularly when considering some of the more unusual varieties of font. Perhaps there was a simpler idea that was evading me.&lt;/p&gt;
    &lt;p&gt;Then it occurred to me: since my aim was to average a large number of fonts, perhaps it would be best to use a very simple process, and hope the results averaged out well over a large number of fonts. So, how about splitting each letter perimeter into lots of (say, 500) equally-spaced points, and just average between the corresponding positions of each, on each letter? It would be necessary to match up the points so they were about the same location in each letter, and then the process would be fairly simple¬≤.&lt;/p&gt;
    &lt;p&gt;Having found a simple process to use, I was ready to start. And after about a month of part-time slaving away (sheer fun! Better than any computer game) ‚Äì in the process of which I learned lots about bezier curves and font metrics ‚Äì I had a result. I call it Aver√≠a ‚Äì which is a Spanish word related to the root of the word ‚Äòaverage‚Äô. It actually means mechanical breakdown or damage. This seemed curiously fitting, and I was assured by a Spanish friend-of-a-friend that ‚ÄúAver√≠a is an incredibly beautiful word regardless of its meaning‚Äù. So that's nice.&lt;/p&gt;
    &lt;p&gt;Along the way I naturally called on the counsel of the best designers I know ‚Äì my brother Nick Sayers, Lloyd Thomas, Tom Muller and Chris McGrail, for advice. In the end, I decided to release the font using the SIL Open Font License ‚Äì which means anyone can use it pretty much however they like ‚Äì and to include within the family Regular, Bold and Light variants with Italics. Each is made from the corresponding subsets of the fonts on my machine. Also included is a ‚ÄúGruesa‚Äù version made from all my fonts (725 in total).&lt;lb/&gt; Aver√≠a Family (ZIP, 369kB) [Updated 9 Nov 2011]&lt;lb/&gt; Aver√≠a at The Open Font Library&lt;lb/&gt; *NEW* by popular demand:&lt;lb/&gt; Aver√≠a Serif Family (ZIP, 323kB) OFLB&lt;lb/&gt; Aver√≠a Sans Family (ZIP, 320kB) OFLB&lt;lb/&gt; *NEW* Aver√≠a, Serif and Sans packaged as TTC TrueType collections (so you can install each family in one go, rather than one variant at a time). Thanks Ludwig:&lt;lb/&gt; Aver√≠a TTC Files (ZIP, 946kB)&lt;lb/&gt; *NEW* versions of Aver√≠a, based on OFL fonts from the Google Web Fonts directory - now available through GWF as Aver√≠a Libre:&lt;lb/&gt; Aver√≠a GWF Family (ZIP, 488kB)&lt;lb/&gt; Aver√≠a Serif GWF Family (ZIP, 432kB)&lt;lb/&gt; Aver√≠a Sans GWF Family (ZIP, 426kB)&lt;lb/&gt; Preview all&lt;lb/&gt; Feel free to email me if you have any questions ‚Äì or use the comments box below.&lt;lb/&gt; N.B. I've had a number of emails from people asking if they can use Aver√≠a in various commercial / non-commercial projects. I'd love to hear if you do something with these fonts ‚Äì but there's no need to ask permission. You are absolutely free to use them however you like. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://iotic.com/averia/"/><published>2025-11-08T19:29:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45859471</id><title>Largest cargo sailboat completes first Atlantic crossing</title><updated>2025-11-09T14:08:23.144319+00:00</updated><content>&lt;doc fingerprint="df5cacd41833d6da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;World‚Äôs Largest Cargo Sailboat Completes Historic First Atlantic Crossing&lt;/head&gt;
    &lt;p&gt;The world‚Äôs largest cargo sailboat, Neoliner Origin, completed its first transatlantic voyage on 30 October despite damage to one of its sails during the journey.&lt;/p&gt;
    &lt;p&gt;The 136-metre-long vessel had to rely partly on its auxiliary motor and its remaining sail after the aft sail was damaged in a storm shortly after departure.&lt;/p&gt;
    &lt;p&gt;The French-built roll-on/roll-off (RoRo) cargo ship, which has two semi-rigid sails, first stopped at Saint Pierre and Miquelon, a French overseas territory near Canada, before continuing its journey to Baltimore in the United States.&lt;/p&gt;
    &lt;p&gt;Neoline, the company behind the project, said the damage reduced the vessel‚Äôs ability to perform fully on wind power. The company‚Äôs CEO, Jean Zanuttini, said the crossing was a valuable experience in handling large sail surfaces across the North Atlantic, especially during late-season storms. He added that despite the difficulties, the ship showed strong resilience by reaching its destination with only a short delay in Saint Pierre.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is designed to reduce greenhouse gas emissions by 80 to 90 per cent compared to conventional diesel-powered cargo ships. According to the United Nations Conference on Trade and Development (UNCTAD), global shipping produces about 3 per cent of worldwide greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Zanuttini said the company aims to balance industrial needs with environmental responsibility. He added that wind propulsion offers an advantage because it is a free, widely available, and predictable energy source that does not harm ecosystems.&lt;/p&gt;
    &lt;p&gt;The UK‚Äôs National Clean Maritime Research Hub has reported that wind propulsion systems like those on the Neoliner Origin can cut emissions by over 50 per cent on new vessels optimised for wind conditions. Retrofitted vessels can also achieve reductions of 5 to 20 per cent, and up to 30 per cent when adjusted for wind conditions.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin was designed by the French naval engineering firm Mauric. The company‚Äôs CEO, Vincent Seguin, said the goal was to develop a ship that relies primarily on wind propulsion while ensuring consistent delivery schedules and efficient operation with a smaller crew.&lt;/p&gt;
    &lt;p&gt;Inspired by historic sailing vessels, the Neoliner Origin integrates modern systems such as advanced navigation, anti-drift mechanisms, and automated sail management to comply with current safety and operational standards.&lt;/p&gt;
    &lt;p&gt;The ship can carry up to 5,300 tonnes of cargo, including containers, vehicles, machinery, and specialised goods. It arrived in Baltimore carrying Renault vehicles, French liqueurs, machinery, and other products.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is scheduled to make monthly voyages between Europe and North America, maintaining a commercial cruising speed of around 11 knots.&lt;/p&gt;
    &lt;p&gt;Reference: Reuters&lt;/p&gt;
    &lt;head rend="h4"&gt;‚öìÔ∏è Enhance Your Knowledge. Prevent Accidents. Stay Safe at Sea.&lt;/head&gt;
    &lt;p&gt;1. eBooks for Engine Department&lt;/p&gt;
    &lt;p&gt;Master machinery operations, troubleshooting, and safety procedures with expertly written guides tailored for marine engineers. Prevent costly breakdowns and onboard accidents through practical knowledge.&lt;/p&gt;
    &lt;p&gt;üëâ Explore Engine Department eBooks&lt;/p&gt;
    &lt;p&gt;2. eBooks for Deck Department&lt;/p&gt;
    &lt;p&gt;Sharpen your seamanship, navigation, and cargo-handling skills with real-world case studies and practical insights designed for deck officers and cadets.&lt;/p&gt;
    &lt;p&gt;üëâDiscover Deck Department eBooks&lt;/p&gt;
    &lt;p&gt;3. eBooks on Electrical Fundamentals &amp;amp; Issues&lt;/p&gt;
    &lt;p&gt;Understand marine electrical systems, identify potential faults, and prevent onboard electrical failures with step-by-step explanations from industry experts.&lt;/p&gt;
    &lt;p&gt;4. Pocket Guides for Quick Reference&lt;/p&gt;
    &lt;p&gt;Compact, handy, and loaded with essential checklists‚Äîperfect for on-the-go reference during operations and emergencies at sea.&lt;/p&gt;
    &lt;p&gt;5. Combo Packs to Save Big&lt;/p&gt;
    &lt;p&gt;Access multiple expert eBooks at discounted prices. Ideal for professionals seeking complete safety and operational knowledge across various ship departments.&lt;/p&gt;
    &lt;p&gt;6. Digital Maritime Courses ‚Äì Learn at Your Own Pace&lt;/p&gt;
    &lt;p&gt;Upgrade your competence with Marine Insight Academy‚Äôs online courses. Learn from industry professionals anytime, anywhere, and become a safer, smarter seafarer.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Subscribe To Our Daily Newsletter&lt;/head&gt;
    &lt;p&gt;By subscribing, you agree to our Privacy Policy and may receive occasional deal communications; you can unsubscribe anytime.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.marineinsight.com/shipping-news/worlds-largest-cargo-sailboat-completes-historic-first-atlantic-crossing/"/><published>2025-11-08T19:57:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45860843</id><title>Ironclad ‚Äì formally verified, real-time capable, Unix-like OS kernel</title><updated>2025-11-09T14:08:22.833734+00:00</updated><content>&lt;doc fingerprint="6fd6e97a45ab3f80"&gt;
  &lt;main&gt;
    &lt;p&gt;Ironclad is a (partially) formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software.&lt;/p&gt;
    &lt;p&gt;Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling.&lt;/p&gt;
    &lt;p&gt;Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source.&lt;/p&gt;
    &lt;p&gt;SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of big portions of Ironclad, like cryptography, MAC, and user-facing facilities.&lt;/p&gt;
    &lt;p&gt;Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.&lt;/p&gt;
    &lt;p&gt;Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more.&lt;/p&gt;
    &lt;p&gt;This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page.&lt;/p&gt;
    &lt;p&gt;Additionally, we would like to thank the following organizations:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ironclad-os.org/"/><published>2025-11-08T23:03:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45861984</id><title>How Airbus took off</title><updated>2025-11-09T14:08:22.692884+00:00</updated><content>&lt;doc fingerprint="f5e48050ae83878f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Airbus is an example of successful industrial policy and the rare European company that is better than its American rival. Could its success be copied elsewhere?&lt;/head&gt;
    &lt;p&gt;Would you rather fly in an Airbus or a Boeing? It seems like an easy question.&lt;/p&gt;
    &lt;p&gt;As Alaska Airlines Flight 1282 flight climbed to 16,000 feet on a January evening in 2024, passengers were stunned when a hole was blasted in the side of the plane. They were hit by howling winds as tray tables were ripped from the backs of seats. Were it not for their seatbelts, they would likely have been sucked out of the plane. It later transpired that the plug which sealed the exit door was missing four critical bolts that held it in place.&lt;/p&gt;
    &lt;p&gt;Subscribe for $100 to receive six beautiful issues per year.&lt;/p&gt;
    &lt;p&gt;The Alaska Airlines incident fortunately didn‚Äôt result in any fatalities. Not everyone who has flown on a Boeing 737 MAX in the last few years has been so lucky.&lt;/p&gt;
    &lt;p&gt;2018 and 2019 saw two 737 crashes that killed 346 people after the plane‚Äôs Maneuvering Characteristics Augmentation System, a feature that pushes the plane‚Äôs nose down to prevent stalling, triggered repeatedly due to a faulty sensor. It later transpired that Boeing had not adequately disclosed how the system worked in training manuals.&lt;/p&gt;
    &lt;p&gt;While Boeing wrestles with lawsuits and regulatory investigations, its rival Airbus has stayed out of the headlines ‚Äì a happier place for the manufacturer of commercial airliners.&lt;/p&gt;
    &lt;p&gt;Europe is a graveyard of failed national champions. They span from the glamorous Concorde to obscure ventures like pan-European computer consortium Unidata or notorious Franco-German search engine Quaero.&lt;/p&gt;
    &lt;p&gt;Airbus is the rare success story. European governments pooled resources and subsidized their champion aggressively to face down a titan of American capitalism in a strategically vital sector. Why did Airbus succeed when so many similar initiatives crashed and burned?&lt;/p&gt;
    &lt;p&gt;Airbus prevailed because it was the least European version of a European industrial strategy project ever. It put its customer first, was uninterested in being seen as European, had leadership willing to risk political blowback in the pursuit of a good product, and operated in a unique industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;An industry on the brink&lt;/head&gt;
    &lt;p&gt;In the early days of commercial aviation, US aerospace companies dominated the market for passenger jets.&lt;/p&gt;
    &lt;p&gt;The Buy America Act of 1933 forced the US government to buy from American producers where possible. Military orders supercharged the industry and brought significant knowledge spillovers.&lt;/p&gt;
    &lt;p&gt;The Boeing B-47 bomber, introduced in the late 1940s, pioneered the use of 35-degree swept wings, which point backwards at an angle of 35 degrees and reduce drag at high speeds. This design went on to inspire nearly every commercial airliner around the world.&lt;/p&gt;
    &lt;p&gt;Meanwhile the Boeing 707, the company‚Äôs first ever airliner, shared a fuselage with the KC-135 Stratotanker, a military refueling aircraft.&lt;/p&gt;
    &lt;p&gt;In the face of the US, European aerospace companies cut a sorry figure. The British Aircraft Corporation, Sud Aviation in France, and Messerschmitt-B√∂lkow-Blohm (MBB) in West Germany were all left to compete for orders in a fragmented continental market, with little research or marketing heft. Meanwhile, European airliners who bought American planes could apply for discounted loans from EXIM, the America‚Äôs credit export agency.&lt;/p&gt;
    &lt;p&gt;Between 1960 and 1967, British and French manufacturers saw a 50 percent decline in aircraft deliveries. In 1966, the UK government had even contemplated forcibly merging and nationalizing much of the country‚Äôs industry.&lt;/p&gt;
    &lt;p&gt;European governments had poured money into their national champions in the belief that the maintenance of a civilian aerospace industry was critical for sovereignty, but it was unclear if these companies would survive the decade.&lt;/p&gt;
    &lt;p&gt;Amid this gloomy backdrop, European governments concluded that their industry‚Äôs future depended on cooperation.&lt;/p&gt;
    &lt;p&gt;The UK and France agreed to pool the resources behind Concorde in 1962 to fight what Charles De Gaulle called ‚Äòthe American colonization of the skies‚Äô, but the Germans declined to participate due to their (well-founded) skepticism about the project‚Äôs economics. This didn‚Äôt stop the Germans teaming up with the Dutch on the long-forgotten VFW-Fokker 614. This short-haul jet struggled to find customers at a time when airlines preferred to use cheap prop aircraft for regional city-hopping, dooming the project to collapse once state aid was withdrawn in 1977.&lt;/p&gt;
    &lt;p&gt;In 1965, the French, British, and German governments launched a working group to evaluate the potential of a wide-body commercial aircraft, which would later become the A300. Two years later, the three governments agreed to bear the entire costs of the development of the ‚ÄòEuropean Airbus‚Äô. In 1970, the coalition was formalized with the creation of Airbus Industrie. The consortium quickly expanded to include Spain and the Netherlands.&lt;/p&gt;
    &lt;head rend="h2"&gt;The making of a world leader&lt;/head&gt;
    &lt;p&gt;So how did this unlikely band of brothers go on to build a global leader, rather than another Econ101 case study about the perils of industrial policy?&lt;/p&gt;
    &lt;p&gt;The single biggest factor was a focus on the customer.&lt;/p&gt;
    &lt;p&gt;Unlike many future industrial strategy projects, which would focus on creating European-owned capabilities for their own sake, the Airbus team were seized by the need to build a jet that airliners would want to buy. They didn‚Äôt have much choice: if they failed, there was a reasonable chance the consortium‚Äôs domestic aerospace suppliers would collapse.&lt;/p&gt;
    &lt;p&gt;They were helped enormously in this by their setup. While Airbus didn‚Äôt become a unified corporate entity until 2001, the partnership had a strong central leadership from the beginning. Unlike other industrial consortia, which tended to be leaderless venues for intra-European turf wars, Airbus united marketing, procurement, and design.&lt;/p&gt;
    &lt;p&gt;Roger B√©teille, who led the A300 program, probably bears more responsibility for Airbus‚Äôs early success than anyone else. B√©teille wasn‚Äôt interested in building an inferior European Boeing copy. Instead, he invested significant time in getting to know his potential customers and what they needed. This led to Airbus quickly tossing the original design for a 300-seat A300, in favor of a 225-250 seater, when it became clear that Air France and Lufthansa wanted a smaller product.&lt;/p&gt;
    &lt;p&gt;The revised A300B would prove much cheaper to develop, in part because it allowed the consortium to dispense with the expensive Rolls Royce engine in favour of a cheaper American alternative. In response, the UK exited the project, only to later return with a lower ownership stake.&lt;/p&gt;
    &lt;p&gt;This willingness to risk political blowback and avoid petty chauvinism in equipment choice was rare in industrial strategy.&lt;/p&gt;
    &lt;p&gt;B√©teille went one step further. He designated English the official language of the project, instead of the usual mixture of languages that characterised European projects, and forbade the use of metric measurements to make it easier to sell into the US market.&lt;/p&gt;
    &lt;p&gt;Along with Felix Kracht, Airbus‚Äôs first production director, B√©teille set a division of labour between the different countries that has persisted, with minor adjustments. French firms handled the cockpit, control systems, and lower-center fuselage; Hawker Siddeley (the inventor of the Harrier jump jet) in the UK designed and built the wings; German companies produced various fuselage sections; the Netherlands managed moving wing components; and Spain was responsible for the horizontal tailplane.&lt;/p&gt;
    &lt;p&gt;Based on B√©teille‚Äôs market research, the A300B was optimised for fuel efficiency. The team stripped out unnecessary weight by using composite materials and raised the cabin floor to add cargo space. Hawker Siddeley‚Äôs wings, which would go on to influence industry standards, were designed with a curved shape on top to reduce air resistance, allowing greater lift and fuel efficiency.&lt;/p&gt;
    &lt;p&gt;At a time when almost every commercial jet had three or four engines, Airbus opted for a twin-engine design. The plane could theoretically fly on one and the company concluded that only a single extra engine was needed to provide redundancy for safety. The much cheaper twin-engine design is now the industry standard, even for ultra long-haul flights.&lt;/p&gt;
    &lt;p&gt;Despite the technical ingenuity behind the A300B, early business was slow. By the time the aircraft entered service in 1974, it had struggled to attract commercial interest beyond state-owned flag carriers like Air France, which had placed the first A300B order in 1971 for six jets. Even these airlines continued to operate Boeing-dominated fleets.&lt;/p&gt;
    &lt;p&gt;One problem was unfortunate timing: the oil shock of 1973 had caused operating costs to spiral for airliners, so there was little appetite for experimentation in the air.&lt;/p&gt;
    &lt;p&gt;There was also residual suspicion of European industry among US airliners. Sud Aviation‚Äôs Caravelle had been used by some American airliners, but the company was notorious for its sloppy after sales maintenance and service. There had also been an ugly dispute over landing rights for Concorde, with the US heavily restricting the aircraft‚Äôs operation out of noise concerns. The French suspected more sinister commercial motivations were at work. Jacques Chirac, then French Prime Minister, raised the temperature, declaring that: ‚ÄòThe Airbus consortium will not be daunted by the Americans who killed off the Concorde. ‚Ä¶ We will fight any trade war blow-by-blow as the future of the aeronautical industry and their employees is at stake‚Äô.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, Airbus did everything it could to deemphasize its European heritage as it toured the US. It refused to involve the French or German embassies in its sales efforts, much to their irritation. Airbus representatives drove home how a third of the plane‚Äôs value derived from US-made components, more than any single European partner nation‚Äôs contribution. They also mastered the world of DC lobbying, successfully outmaneuvering Boeing and Lockheed‚Äôs attempts to use anti-trust regulations to shut the European entrant out of the US market.&lt;/p&gt;
    &lt;p&gt;Sustained by early European market commitments and early sales in Asia, Airbus was eventually able to clinch its first US order in 1977. Eastern Airlines (EAL), which had been impressed by the A300B‚Äôs fuel economy and low noise levels, agreed to the trial lease of four aircraft and three spare engines for ‚Ä¶ one dollar. These terms would have been unconscionable for a normal private company, but they were transformative for state-backed Airbus‚Äôs fortunes. Frank Borman, conservative Republican, former NASA astronaut, and EAL‚Äôs CEO emerged as a public champion of the A300B as an ‚ÄòAmerican aircraft‚Äô.&lt;/p&gt;
    &lt;head rend="h2"&gt;The A320&lt;/head&gt;
    &lt;p&gt;B√©teille and Kracht weren‚Äôt content with building one aircraft. From the beginning, Airbus had targeted a 30 percent global market share. This meant building more than wide-body aircraft like the A300B.&lt;/p&gt;
    &lt;p&gt;The A320, which entered operation in 1988 was a narrow-bodied aircraft that could carry 150-180 passengers. It was optimized to fly short- and medium-haul routes economically, and a masterclass in engineering and timing.&lt;/p&gt;
    &lt;p&gt;By the 1980s, airliners were looking to replace their aging narrow-bodied fleets, with the Boeing 272 and McDonnell Douglas DC-9 having been in operation for more than two decades.&lt;/p&gt;
    &lt;p&gt;The A320 was the first commercial aircraft to implement full digital fly-by-wire controls. Before the A320, the pilot‚Äôs controls pulled physical cables attached to the flaps, rudder, and other control surfaces on the plane. Fly-by-wire meant that controls sent electric signals to the plane‚Äôs computers, which then commanded motors to move the control surfaces. This made life easier for the pilots by reducing the need for constant manual adjustment and stripped out heavy components that needed maintenance.&lt;/p&gt;
    &lt;p&gt;The A320 was also the first commercial aircraft to introduce envelope protection, a system that automatically prevents dangerous actions, such as tilting too steeply, flying too slowly, or making maneuvers that could overstress the aircraft structure.&lt;/p&gt;
    &lt;p&gt;Again, the A320 wasn‚Äôt an overnight success, with new technology and existing relations with Boeing slowing uptake. Airbus again relied on British and French orders to gain market credibility. But by the early 1990s, its superior technology combined with Airbus‚Äôs willingness to flex the design, with the A319 (smaller) and A321 (larger) allowing airliners to operate mixed fleets with common cockpits, began to win fans. The A320 is now the most popular airliner family in history and remains in widespread use today.&lt;/p&gt;
    &lt;p&gt;The success of the A320 led Airbus to profitability in the mid-1990s. By 2019, Airbus had displaced Boeing as the largest aerospace company by revenue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Airbus‚Äôs success is so hard to repeat&lt;/head&gt;
    &lt;p&gt;If Airbus proves industrial strategy can work, why haven‚Äôt other European ventures fared better?&lt;/p&gt;
    &lt;p&gt;Good industrial strategy requires favorable market conditions, consistent strategy in the face of political headwinds, and the courage to call it a day if failure seems likely. Getting one of these right is tough, and all three is exceptionally rare.&lt;/p&gt;
    &lt;p&gt;Concorde was a marvel of engineering, but even without US obstructionism, it had little prospect of commercial viability. In today‚Äôs money, it cost ¬£16 billion to develop, roughly ten times the cost of the Boeing 727, making it the most expensive plane of its age by some margin. Its limited passenger capacity, fuel inefficiency, and expensive maintenance meant that a ticket for a round trip cost in excess of ¬£10,000 adjusted for inflation. The ultra-premium air travel market wasn‚Äôt big enough in the 1980s or 1990s to bear the costs of 1960s technology, leading to Concorde‚Äôs retirement in 2003.&lt;/p&gt;
    &lt;p&gt;Other European projects have lacked the centralized control or clear rationale that characterized Airbus.&lt;/p&gt;
    &lt;p&gt;We see this in Unidata, a 1973 consortium that brought together CII (France), Philips (the Netherlands), and Siemens (Germany) to produce a European mainframe line to rival IBM. With no clear leadership, rival members of the consortium pushed their own hardware and software approaches. Engineering efforts were duplicated. The project collapsed within two years amid recriminations.&lt;/p&gt;
    &lt;p&gt;Meanwhile, it was unclear why the 2005 Franco-German search engine project Quaero ever needed to exist. Widely seen as a vanity project at the time, the attempt to build a search engine by committee similarly splintered along national lines. It was also a victim of mission creep, evolving from a direct Google competitor to a multimedia search platform that would be powered by image and voice analysis. The project limped on until its mercy killing in 2013.&lt;/p&gt;
    &lt;p&gt;It‚Äôs also easier to build a global leadership position when your main rival wages a prolonged campaign of self-sabotage. By the new millennium, the competition had been reduced to a simple showdown between Airbus and Boeing. Lockheed had decided to bail on commercial aviation in the 1970s after losing billions of dollars on the L-1011, while Boeing acquired McDonnell Douglas in a $13 billion deal in 1997.&lt;/p&gt;
    &lt;p&gt;While Airbus has retained a strong engineering culture at the helm, this disappeared from Boeing. Harry Stonecipher, Boeing‚Äôs CEO in the early 2000s, notoriously claimed that: ‚ÄòWhen people say I changed the culture of Boeing, that was the intent, so that it is run like a business rather than a great engineering firm‚Äô.&lt;/p&gt;
    &lt;p&gt;Stonecipher‚Äôs successor, James McNerney, took this even further: ‚ÄòEvery 25 years a big moonshot‚Ä¶ and then produce a 707 or a 787 ‚Äì that‚Äôs the wrong way to pursue this business. The more-for-less world will not let you pursue moonshots‚Äô.&lt;/p&gt;
    &lt;p&gt;The McDonnell Douglas acquisition is often marked as a turning point for Boeing. Despite being the acquiring firm, Boeing absorbed much of their target‚Äôs management philosophy. This disconnect was embodied in the company‚Äôs decision to move its headquarters from Seattle (where its main production facility was located) to Chicago, for the sake of just $63 million in tax credits. Fatal crashes in 2018 and 2019 have since caused regulatory investigations and multi-billion dollar compensation claims to pile up, as well as allegations that the company has put shareholders and dividends before safety.&lt;/p&gt;
    &lt;head rend="h2"&gt;A strange industry&lt;/head&gt;
    &lt;p&gt;Does the Airbus story make a good case for a disciplined, well-executed industrial strategy?&lt;/p&gt;
    &lt;p&gt;To answer this question, we need to take a step back from Airbus and Boeing and think about their customers.&lt;/p&gt;
    &lt;p&gt;Airlines have one of the worst business models of any industry. They have eye-watering capital expenditures (a large jet costs in excess of $200 million). The product offering (flights) is relatively undifferentiated, while many of their customers are price-conscious and disloyal. Safety regulations, along with route and landing slot regulations mean there‚Äôs little space to drive painless efficiencies. This leaves airlines with two main routes to success: worsening their service through cost-cutting and engaging in kamikaze price wars.&lt;/p&gt;
    &lt;p&gt;This is why airlines frequently go bankrupt, with US Airways, United Airlines, Northwest Airlines, Delta Air Lines and American Airlines among the dozens to almost collapse in the 2000s. Only three airlines without state ties (Southwest, Ryanair, and Copa) have consistently maintained profitability while avoiding bankruptcy or major restructuring.&lt;/p&gt;
    &lt;p&gt;In his 2007 letter to Berkshire Hathaway shareholders, Warren Buffett described the airline industry as ‚Äòthe worst sort of business‚Äô, and noted that, ‚Äòif a farsighted capitalist had been present at Kitty Hawk, he would have done his successors a huge favor by shooting Orville down‚Äô.&lt;/p&gt;
    &lt;p&gt;Airbus, as a supplier to these businesses, has not been immune to these pressures. In the early 2000s, airliners were enthused about the ‚Äòhub and spoke‚Äô model. Passengers would fly on large aircraft between major hubs, then transfer to smaller aircraft for their final destinations. With a maximum capacity of over 800, the double-decker Airbus A380 would help allow airliners to consolidate their flights between busy international hubs. By the time it entered commercial operation in 2007, fashions had reversed and consumers were willing to pay a premium to fly direct. Airbus never came close to recouping its $25 billion development costs.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, companies like Airbus and Boeing face a constant downward price pressure, operating on single digit margins in good years. The merry-go-round of buyers as airliners fall in and out of bankruptcy makes them fickle customers. With this in mind, Boeing‚Äôs desire to slash costs seems like a much more rational response, even if its execution was flawed.&lt;/p&gt;
    &lt;p&gt;It may be nearly impossible to operate the multi-billion dollar, multi-decade product development cycle this industry requires without some form of government backstop, whether it is a direct subsidy (Airbus) or reliable military orders (Boeing).&lt;/p&gt;
    &lt;p&gt;It is a business that is well-suited to subsidy for other reasons too. Governments are generally better at supporting companies in established markets where innovation takes place slowly and incrementally. This is likely why state-backed efforts have found it easier to be competitive against aerospace companies than Silicon Valley giants working at breakneck pace to keep pace with changing consumer tastes.&lt;/p&gt;
    &lt;p&gt;We can learn from Airbus‚Äôs engineering ingenuity and relentless customer focus. But its success in such an idiosyncratic sector probably isn‚Äôt as template for successful industrial policy in many of the other sectors that some people would like it to be.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://worksinprogress.co/issue/how-airbus-took-off/"/><published>2025-11-09T01:19:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862470</id><title>Tabloid: The Clickbait Headline Programming Language</title><updated>2025-11-09T14:08:22.543622+00:00</updated><content>&lt;doc fingerprint="5205455d1cce1ea4"&gt;
  &lt;main&gt;
    &lt;p&gt;Oops, please turn on JavaScript to enjoy Tabloid :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tabloid.vercel.app/"/><published>2025-11-09T02:53:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862802</id><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><updated>2025-11-09T14:08:22.362399+00:00</updated><content>&lt;doc fingerprint="bc2fcf3649af53d8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican&lt;/head&gt;
    &lt;p&gt;9th November 2025&lt;/p&gt;
    &lt;p&gt;OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they describe as "a more compact and cost-efficient version of GPT-5-Codex". It‚Äôs currently only available via their Codex CLI tool and VS Code extension, with proper API access "coming soon". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.&lt;/p&gt;
    &lt;p&gt;I made a video talking through my progress and demonstrating the final results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a little bit cheeky&lt;/item&gt;
      &lt;item&gt;Codex CLI is written in Rust&lt;/item&gt;
      &lt;item&gt;Iterating on the code&lt;/item&gt;
      &lt;item&gt;Let‚Äôs draw some pelicans&lt;/item&gt;
      &lt;item&gt;Bonus: the --debug option&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;This is a little bit cheeky&lt;/head&gt;
    &lt;p&gt;OpenAI clearly don‚Äôt intend for people to access this model directly just yet. It‚Äôs available exclusively through Codex CLI which is a privileged application‚Äîit gets to access a special backend API endpoint that‚Äôs not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user‚Äôs existing ChatGPT account.&lt;/p&gt;
    &lt;p&gt;I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?&lt;/p&gt;
    &lt;p&gt;This felt like a somewhat absurd loophole, and I couldn‚Äôt resist trying it out and seeing what happened.&lt;/p&gt;
    &lt;head rend="h4"&gt;Codex CLI is written in Rust&lt;/head&gt;
    &lt;p&gt;The openai/codex repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt know much Rust at all.&lt;/p&gt;
    &lt;p&gt;I made my own clone on GitHub and checked it out locally:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:simonw/codex
cd codex&lt;/code&gt;
    &lt;p&gt;Then I fired up Codex itself (in dangerous mode, because I like living dangerously):&lt;/p&gt;
    &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
    &lt;p&gt;And ran this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Figure out how to build the rust version of this tool and then build it&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this‚Äîin figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.&lt;/p&gt;
    &lt;p&gt;Once the compile had succeeded I fed it the design for the new feature I wanted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a new sub-command to the Rust tool called ‚Äúcodex prompt‚Äù&lt;/p&gt;
      &lt;p&gt;codex prompt ‚Äúprompt goes here‚Äù‚Äîthis runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.&lt;/p&gt;
      &lt;p&gt;codex prompt -m &amp;lt;model_name&amp;gt; ‚Äúprompt goes here‚Äù‚Äîsame again but lets you set the model&lt;/p&gt;
      &lt;p&gt;codex prompt ‚Äúprompt goes here‚Äù -s/--system ‚Äúsystem prompt goes here‚Äù‚Äîruns with a custom system/developer message&lt;/p&gt;
      &lt;p&gt;codex prompt --models‚Äîthis lists all available models that can be used with the ‚Äúcodex prompt‚Äù command&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My design for this new sub-command is lifted directly from my own llm command.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterating on the code&lt;/head&gt;
    &lt;p&gt;Codex got to work. I‚Äôve shared the full transcript here (using the tool I described here), but this TODO list it made itself is a useful summary of what it decided to do:&lt;/p&gt;
    &lt;code&gt;Updated Plan
‚îî ‚úî Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ‚úî Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ‚úî Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
&lt;/code&gt;
    &lt;p&gt;I like that it figured out the justfile in the repo and decided to use it to run formatting and linting commands without me needing to tell it to.&lt;/p&gt;
    &lt;p&gt;I tried running the first version of the code it wrote like this:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle' -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;... and it didn‚Äôt quite work. I got this:&lt;/p&gt;
    &lt;code&gt;(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
IÔøΩm ready to helpÔøΩwhat would you like me to do next?IÔøΩm ready to helpÔøΩwhat would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
&lt;/code&gt;
    &lt;p&gt;Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn‚Äôt what I want‚Äîit appeared to be running in Codex‚Äôs normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.&lt;/p&gt;
    &lt;p&gt;I prompted it again, pasting in the broken output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;this did not seem to work‚Äîhere is what happened‚Äînote that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly)‚Äîand then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this new ‚Äôcodex prompt‚Äô command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox‚Äîit should send a single prompt with no tools and then stream and display a response and then stop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This got me a new build, but when I ran it:&lt;/p&gt;
    &lt;code&gt;Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
&lt;/code&gt;
    &lt;p&gt;My guess is that OpenAI‚Äôs custom backend API for Codex doesn‚Äôt like it if you attempt to call it without passing in the expected instructions. Fair enough!&lt;/p&gt;
    &lt;p&gt;Rather than paste that error in I got Codex to try the command itself, so it could see the error:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You try running this and see what happens: ./target/debug/codex prompt ‚ÄôGenerate an SVG of a pelican riding a bicycle‚Äô&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Codex switched back to the default instructions. From its reply:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;cli/src/prompt_cmd.rs#L1-L320&lt;/code&gt;now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (‚Äúdon‚Äôt run tools‚Äù), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.&lt;/quote&gt;
    &lt;p&gt;I guess that will have to do. I asked for one more feature:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;... and we‚Äôre ready to try this thing out!&lt;/p&gt;
    &lt;p&gt;Notably I haven‚Äôt written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.&lt;/p&gt;
    &lt;p&gt;I‚Äôve pushed the working code to a prompt-subcommand branch in my repo if you want to take a look and see how it all works.&lt;/p&gt;
    &lt;head rend="h4"&gt;Let‚Äôs draw some pelicans&lt;/head&gt;
    &lt;p&gt;With the final version of the code built, I drew some pelicans. Here‚Äôs the full terminal transcript, but here are some highlights.&lt;/p&gt;
    &lt;p&gt;This is with the default GPT-5-Codex model:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle"&lt;/code&gt;
    &lt;p&gt;I pasted it into my tools.simonwillison.net/svg-render tool and got the following:&lt;/p&gt;
    &lt;p&gt;I ran it again for GPT-5:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5&lt;/code&gt;
    &lt;p&gt;And now the moment of truth... GPT-5 Codex Mini!&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;I don‚Äôt think I‚Äôll be adding that one to my SVG drawing toolkit any time soon.&lt;/p&gt;
    &lt;head rend="h4"&gt;Bonus: the --debug option&lt;/head&gt;
    &lt;p&gt;I had Codex add a &lt;code&gt;--debug&lt;/code&gt; option to help me see exactly what was going on.&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt -m gpt-5-codex-mini "Generate an SVG of a pelican riding a bicycle" --debug&lt;/code&gt;
    &lt;p&gt;The output starts like this:&lt;/p&gt;
    &lt;code&gt;[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
&lt;/code&gt;
    &lt;code&gt;{
  "model": "gpt-5-codex-mini",
  "instructions": "You are Codex, based on GPT-5. You are running as a coding agent ...",
  "input": [
    {
      "type": "message",
      "role": "developer",
      "content": [
        {
          "type": "input_text",
          "text": "You are a helpful assistant. Respond directly to the user request without running tools or shell commands."
        }
      ]
    },
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Generate an SVG of a pelican riding a bicycle"
        }
      ]
    }
  ],
  "tools": [],
  "tool_choice": "auto",
  "parallel_tool_calls": false,
  "reasoning": {
    "summary": "auto"
  },
  "store": false,
  "stream": true,
  "include": [
    "reasoning.encrypted_content"
  ],
  "prompt_cache_key": "019a66bf-3e2c-7412-b05e-db9b90bbad6e"
}&lt;/code&gt;
    &lt;p&gt;This reveals that OpenAI‚Äôs private API endpoint for Codex CLI is &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also interesting is how the &lt;code&gt;"instructions"&lt;/code&gt; key (truncated above, full copy here) contains the default instructions, without which the API appears not to work‚Äîbut it also shows that you can send a message with &lt;code&gt;role="developer"&lt;/code&gt; in advance of your user prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/"/><published>2025-11-09T04:02:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862833</id><title>Grok 4 Fast now has 2M context window</title><updated>2025-11-09T14:08:22.134406+00:00</updated><content/><link href="https://docs.x.ai/docs/models"/><published>2025-11-09T04:10:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863024</id><title>Forth ‚Äì Is it still relevant?</title><updated>2025-11-09T14:08:21.531413+00:00</updated><content>&lt;doc fingerprint="be229b0a630aca40"&gt;
  &lt;main&gt;
    &lt;p&gt;With all the advantages, it is unfortunate that Forth lost out to C language over the years and have been reduced to a niche. Per ChatGPT: due to C's broader appeal, standardization, and support ecosystem likely contributed to its greater adoption and use in mainstream computing.&lt;/p&gt;
    &lt;p&gt;So, the question is, how to encourage today's world of C programmers to take a look at Forth. How do we convince them that Forth can be 10 times more productive? Well, we do know that by keep saying how elegant Forth is or even bashing how bad C can be probably won't get us anywhere.&lt;/p&gt;
    &lt;p&gt;Bill Muench created eForth for simplicity and educational purpose. Dr. Ting, ported to many processors, described Forth in his well-written eForth genesis and overview. I like the idea and decided to pick it up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;100% C/C++ with multi-platform support. Though classic implementation of primitives in assembly language and scripted high-level words gave the power to Forth, it also became the hurtle for newbies. Because they have to learn the assembly and Forth syntax before peeking into the internal beauty of Forth.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary is just an array. It's remodeled from linear memory linked-list to an array (or a vector in C++'s term) of words.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;To search for a word, simply scan the name string of dictionary entries. So, to define a new word during compile time is just to append those found word pointers to the its parameter array one by one.&lt;/item&gt;
          &lt;item&gt;To execute become just a walk of the word pointers in the array. This is our inner interpreter.&lt;/item&gt;
          &lt;item&gt;Hashtables might go even faster but we'll try that later.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data and Return Stacks are also arrays. With push, pop and [] methods to clarify intentions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Parameter fields are all arrays. Why not!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No vocabulary, or meta-compilation. Except CREATE..DOES&amp;gt;, and POSTPONE, these black-belt skills of Forth greatness are dropped to keep the focus on core concepts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multi-threading and message passing are available From v5.0 and on, multi-core platform can utilize Forth VMs running in parallel. see the multi-threading section below for details&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A thread pool is built-in. Size is defaults to number of cores.&lt;/item&gt;
          &lt;item&gt;Message Passing send/recv with pthread mutex waiting.&lt;/item&gt;
          &lt;item&gt;IO and memory update can be synchronized with lock/unlock.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are fluent in C/C++ and in the process of building your own Forth, skipping the verbage, the easiest path to gain understanding of how things work together is to download release v4.2 and work from there.&lt;/p&gt;
    &lt;p&gt;In the release, a heavily commented ceforth.cpp, the companion ceforth.h, and a config.h. Altogether, about 800 lines. Check them out!&lt;/p&gt;
    &lt;p&gt;The core of current implementation of eForth is the dictionary composed of an array of Code objects that represent each of Forth words.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Code - the heart of eForth, depends on the constructor called, the following fields are populated accordingly&lt;/p&gt;
        &lt;quote&gt;+ name - a string that holds primitive word's name, i.e. NFA in classic FORTH, can also holds branching mnemonic for compound words which classic FORTH keeps on parameter memory + xt - pointer to a lambda function for primitive words i.e. XT in classic FORTH + pf, p1, p2 - parameter arrays of Code objects for compound words, i.e. PFA in classic FORTH + q - holds the literal value which classic FORTH keep on parameter memory&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lit, Var, Str, Bran, Tmp - the polymorphic classes extended from the base class Code which serve the functionalities of primitive words of classic Forth.&lt;/p&gt;
        &lt;quote&gt;+ Lit - numeric literals + Var - variable or constant + Str - string for dostr or dotstr + Bran - Branching opcode + Tmp - temp storage for branching word&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary - an array of Code objects&lt;/p&gt;
        &lt;quote&gt;+ build-it words - constructed by initializer_list at start up, before main is called, degenerated lambdas become function pointers stored in Code.xt dict[0].xt ------&amp;gt; lambda[0] &amp;lt;== These function pointers can be converted dict[1].xt ------&amp;gt; lambda[1] into indices to a jump table ... which is exactly what WASM does dict[N-1].xt ----&amp;gt; lambda[N-1] &amp;lt;== N is number of built-in words + colon (user defined) words - collection of word pointers during compile time dict[N].pf = [ *Code, *Code, ... ] &amp;lt;== These are called the 'threads' in Forth's term dict[N+1].pf = [ *Code, *Code, ... ] So, instead of subroutine threading ... this is 'object' threading. dict[-1].pf = [ *Code, *Code, ... ] It can be further compacted into token (i.e. dict index) threading if desired&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Inner Interpreter - Code.exec() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;if (xt) { xt(this); return; } // run primitive word for (Code *w : pf) { // run colon word try { w-&amp;gt;exec(); } // execute recursively catch (...) { break; } // handle exception if any }&lt;/quote&gt;
        &lt;p&gt;i.e. either we call a built-in word's lambda function or walk the Code.pf array recursively like a depth-first tree search.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Outer Interpreter - forth_core() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;Code *c = find(idiom); // search dictionary if (c) { // word found? if (compile &amp;amp;&amp;amp; !c-&amp;gt;immd) // are we compiling a new word? dict[-1]-&amp;gt;add(c); // then append found code to it else c-&amp;gt;exec(); // or, execute the code return; } DU n = parse_number(idiom); // word not found, try as a number if (compile) // are we compiling a new word? dict[-1]-&amp;gt;add(new Lit(n)); // append numeric literal to it else PUSH(n); // push onto data stack&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the array implementation, the first difference is in array variable read/write.&lt;/p&gt;
    &lt;code&gt;&amp;gt; create narr 10 cells allot
&amp;gt; see narr
&amp;gt; : narr
    0 0 0 0 0 0 0 0 0 0 ;
\       ^----------------- narr 2 cells +&lt;/code&gt;
    &lt;p&gt;While traditional Forths uses &lt;code&gt;narr 2 cells +&lt;/code&gt; to get the memory address of &lt;code&gt;narr[2]&lt;/code&gt;, eforth &lt;code&gt;narr&lt;/code&gt; returns its index (or defining order) in the dictionary. So, &lt;code&gt;narr 2 cells +&lt;/code&gt; will actually get you the index of the second word defined after &lt;code&gt;narr&lt;/code&gt;. You'll be storing the value into that word's empty qf field.
To access the nth element of &lt;code&gt;narr&lt;/code&gt;, use &lt;code&gt;th&lt;/code&gt; instead&lt;/p&gt;
    &lt;code&gt;&amp;gt; : fill-arr
    10 0 do
      i 2* narr i th !
    loop ;
&amp;gt; fill-arr
&amp;gt; see narr
&amp;gt; : narr
    0 2 4 6 8 10 12 14 16 18 ;&lt;/code&gt;
    &lt;p&gt;With arrays, the doors are open. Dynamically expanding variables as well as storing objects instead of just integers. Parameter fields can be filled in compile time or changed on the fly in runtime i.e. self-morphing code. These can be the "scary" features for Forths to come.&lt;/p&gt;
    &lt;p&gt;Most classic Forth systems are build with a few low-level primitives in assembly language and bootstrap the high-level words in Forth itself. Over the years, Dr. Ting have implemented many Forth systems using the same model. See here for the detailed list. However, he eventually stated that it was silly trying to explain Forth in Forth to new comers. There are just not many people know Forth, period.&lt;/p&gt;
    &lt;p&gt;Utilizing modern OS and tool chains, a new generation of Forths implemented in just a few hundreds lines of C code can help someone who did not know Forth to gain the core understanding much quickly. He called the insight Forth without Forth.&lt;/p&gt;
    &lt;p&gt;In 2021-07-04, I got in touched with Dr. Ting mentioning that he taught at the university when I attended. He, as the usual kind and generous him, included me in his last projects all the way till his passing. I am honored that he considered me one of the frogs living in the bottom of the deep well with him looking up to the small opening of the sky together. With cross-platform portability as our guild-line, we built ooeForth in Java, jeForth in Javascript, wineForth for Windows, and esp32forth for ESP micro-controllers using the same code-base. With his last breath in the hospital, he attempted to build it onto an FPGA using Verilog. see ceForth_403 and eJsv32 for details.&lt;/p&gt;
    &lt;p&gt;We hope it can serve as a stepping stone for learning Forth to even building their own, one day.&lt;/p&gt;
    &lt;code&gt;    $ git clone https://github.com/chochain/eforth to your local machine
    $ cd eforth&lt;/code&gt;
    &lt;p&gt;There are two major versions current. eForth. v4 is single-threaded only and v5 default single-threaded but also supports multi-threaded.&lt;/p&gt;
    &lt;p&gt;Checkout the version you are interested in.&lt;/p&gt;
    &lt;code&gt;    $ git checkout v42           # for version 4.2 (latest), or
    $ git checkout master        # for version 5 and on&lt;/code&gt;
    &lt;p&gt;To enable multi-threading, of v5, update the followings in ~/src/config.h&lt;/p&gt;
    &lt;code&gt;    #define DO_MULTITASK   1
    #define E4_VM_POOL_SZ  8&lt;/code&gt;
    &lt;code&gt;    $ make
    $ ./tests/eforth             # to bring up the Forth interpreter&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words‚èé               \ to see available Forth words
    &amp;gt; 1 2 +‚èé               \ see Forth in action
    &amp;gt; bye‚èé  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Once you get pass the above, try the lessons by Dr. Ting.
&lt;/code&gt;
    &lt;code&gt;    $ ./tests/eforth &amp;lt; ./tests/demo.fs&lt;/code&gt;
    &lt;p&gt;Pretty amazing stuffs! To grasp how they were done, study the individual files (*.fs) under ~/tests/demo.&lt;/p&gt;
    &lt;p&gt;Note: MacOS added, thanks to Kristopher Johnson's work.&lt;/p&gt;
    &lt;p&gt;I haven't develop anything useful on Windows for a long time. Just bearly got this compiled on an 2007 Windows7 box. So, take it with a grain of salt. I'm hoping someone can make it more streamlined.&lt;/p&gt;
    &lt;code&gt;* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&amp;gt; Build -&amp;gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory
&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words‚èé               \ to see available Forth words
    &amp;gt; 1 2 +‚èé               \ see Forth in action
    &amp;gt; bye‚èé  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files.
&lt;/code&gt;
    &lt;code&gt;* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk
&lt;/code&gt;
    &lt;code&gt;    $ make wasm
    $ python3 tests/cors.py        # supports COOP&lt;/code&gt;
    &lt;code&gt;* from your browser, open http://localhost:8000/tests/eforth.html
&lt;/code&gt;
    &lt;p&gt;Note: For multi-threading to work, browser needs to receive Cross-Origin policies here for detail in the response header. A Python script ~/tests/cors.py is provided to solve the issue. The same needed to be provided if you use other web server.&lt;/p&gt;
    &lt;code&gt;* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to 'Both NL &amp;amp; CR'
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server
&lt;/code&gt;
    &lt;p&gt;Note: Most ESP32 are dual-core. However core0 is dedicated to WiFi and FreeRTOS house keeping. Forth tasks will be tied to core1 only. So, multi-threading is possible but no performance gain. Actually, singled-threaded v4.2 does a bit better.&lt;/p&gt;
    &lt;p&gt;Forth has been supporting multi-tasking since the 70's. They are single-CPU round-robin/time-slicing systems mostly. Modern system has multiple cores and Forth can certainly take advantage of them. However, unlike most of the matured Forth word sets, multi-threading/processing words are yet to be standardized and there are many ways to do it.&lt;/p&gt;
    &lt;code&gt;* each VM has it's own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication.
&lt;/code&gt;
    &lt;code&gt;1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in "ready to run" tasks.
4. Lastly, event_loop picks up "ready to run" tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task
&lt;/code&gt;
    &lt;p&gt;Before we go too far, make sure the following are updated before your build&lt;/p&gt;
    &lt;code&gt;* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;word&lt;/cell&gt;
        &lt;cell role="head"&gt;stack&lt;/cell&gt;
        &lt;cell role="head"&gt;desc&lt;/cell&gt;
        &lt;cell role="head"&gt;state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;task&lt;/cell&gt;
        &lt;cell&gt;( xt -- t )&lt;/cell&gt;
        &lt;cell&gt;create a task (tid is index to thread pool entry)&lt;p&gt;a free VM from pool is chosen for the task&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;STOP=&amp;gt;HOLD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;rank&lt;/cell&gt;
        &lt;cell&gt;( -- t )&lt;/cell&gt;
        &lt;cell&gt;fetch current task id&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;start&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;start a task&lt;p&gt;The VM is added to event_queue and kick started when picked up by event_loop&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;join&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;wait until the given task is completed&lt;/cell&gt;
        &lt;cell&gt;NEST=&amp;gt;STOP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;lock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;lock (semaphore) IO or memory&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;unlock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;release IO or memory lock&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;send&lt;/cell&gt;
        &lt;cell&gt;( v1 v2 .. vn n t -- )&lt;/cell&gt;
        &lt;cell&gt;send n elements on current stack to designated task's stack (use stack as message queue)&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receiver HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;recv&lt;/cell&gt;
        &lt;cell&gt;( -- v1 v2 .. vn )&lt;/cell&gt;
        &lt;cell&gt;wait, until message to arrive&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;pull&lt;/cell&gt;
        &lt;cell&gt;( n t -- )&lt;/cell&gt;
        &lt;cell&gt;forced fetch stack elements from a completed task&lt;/cell&gt;
        &lt;cell&gt;current NEST&lt;p&gt;target STOP&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;bcast&lt;/cell&gt;
        &lt;cell&gt;( n -- )&lt;/cell&gt;
        &lt;cell&gt;not implemented yet, TODO&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receivers HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;clock&lt;/cell&gt;
        &lt;cell&gt;( -- n )&lt;/cell&gt;
        &lt;cell&gt;fetch microsecond since Epoch, useful for timing&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;    &amp;gt; : once 999999 for rank drop next ;            \ 1M cycles
    &amp;gt; : run clock negate once clock + . ." ms" cr ; \ benchmark
    &amp;gt; ' run constant xt                             \ keep the xt
    &amp;gt; : jobs 1- for xt task start next ;            \ tasks in parallel
    &amp;gt; 4 jobs&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T2 [05.1]&amp;gt;&amp;gt; started on T4 [04.1]&amp;gt;&amp;gt; started on T6 [07.1]&amp;gt;&amp;gt; started on T0 18 ms [06.3]&amp;gt;&amp;gt; finished on T2 18 ms [05.3]&amp;gt;&amp;gt; finished on T4 18 ms [04.3]&amp;gt;&amp;gt; finished on T6 18 ms [07.3]&amp;gt;&amp;gt; finished on T0&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; 0 constant pp                           \ producer task id
    &amp;gt; 0 constant cc                           \ consumer task id
    &amp;gt; : sndr
        1000 ms                               \ delay to simulate some processing
        1 2 3 4 4 cc send                     \ send 4 items from stack
        lock ." sent " cr unlock ;            \ locked IO before write
    &amp;gt; : rcvr
        recv                                  \ wait for sender
        + + +                                 \ sum received 4 items
        lock ." sum=" . cr unlock ;           \ locked IO before write
    &amp;gt; ' sndr task to pp
    &amp;gt; ' rcvr task to cc
    &amp;gt; cc start                                \ start receiver task
    &amp;gt; pp start                                \ start sender task
    &amp;gt; pp join cc join                         \ wait for completion&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T1 [06.1]&amp;gt;&amp;gt; waiting [07.1]&amp;gt;&amp;gt; started on T2 [06.1]&amp;gt;&amp;gt; sending 4 items to VM6.1 sent [07.3]&amp;gt;&amp;gt; finished on T2 [00.3]&amp;gt;&amp;gt; VM7 joint [06.3]&amp;gt;&amp;gt; received =&amp;gt; state=3 sum=10 [06.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM6 joint&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; : sum 0 1000000 for i + next ;          \ add 0 to 1M
    &amp;gt; ' sum task constant tt                  \ create the task
    &amp;gt; tt start tt join                        \ run and wait for completion
    &amp;gt; 1 tt pull ." total=" .                  \ pull the sum&lt;/code&gt;
    &lt;quote&gt;[00.3]&amp;gt;&amp;gt; joining VM7 [07.1]&amp;gt;&amp;gt; started on T1 [07.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM7 joint pulled 1 items from VM7.0 total= 1784293664 -1 -&amp;gt; ok&lt;/quote&gt;
    &lt;code&gt;+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40
&lt;/code&gt;
    &lt;code&gt;+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)
&lt;/code&gt;
    &lt;code&gt;+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&amp;gt; not much overhead with MT
&lt;/code&gt;
    &lt;code&gt;+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &amp;gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &amp;lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn't seem to bother WASM.
&lt;/code&gt;
    &lt;code&gt;+ 1440ms: Dr. Ting's ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)
&lt;/code&gt;
    &lt;p&gt;What is the performance difference?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Code *dict[] - where words are dynamically allocated as a collection of pointers, or&lt;/item&gt;
      &lt;item&gt;Code dict[] - where words are statically created as an array of objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have created a git branch 'static' to compare to the 'master. The static version is about 10% slower on 64-bit machine and about 5% slower on 32-bits. This hasn't been carefully analyzed but my guess is because Code is big at 144-bytes on 64-bit. They might get pushed off L1 cache too often.&lt;/p&gt;
    &lt;p&gt;An array of lambdas vs the classic switch statement, i.e.&lt;/p&gt;
    &lt;code&gt;const Code dict[] {               ///&amp;lt; Forth dictionary
    CODE("+",      TOS += SS.pop()),
    CODE("-",      TOS =  SS.pop() - TOS),
    CODE("*",      TOS *= SS.pop()),
    CODE("/",      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&amp;lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ...
&lt;/code&gt;
    &lt;p&gt;Though syntax clarity is pretty much the same, lambda being function pointers takes an extra jump and the cost of stack-frame setup/teardown. It takes more space and about 15% slower in tight loops. However, with the advance of compilers,&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It does not need a long enum definition, i.e. PLUS, MINUS, ..., which needs to be kept in-sync&lt;/item&gt;
      &lt;item&gt;It is possible to prebuild lambda array as a ROM image or static library that can be transported.&lt;/item&gt;
      &lt;item&gt;A tweak to CODE macro, i.g. adding NEXT, can potentially enable Tail Call Optimization (TCO) which eliminates the stack-frame overhead as did in many functional languages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Though the use of C++ standard libraries helps us understanding what Forth does but, even on machines with GBs, we still need to be mindful of the followings. It gets expensive especially on MCUs.&lt;/p&gt;
    &lt;code&gt;+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes
&lt;/code&gt;
    &lt;p&gt;The current implementation of ~/src/ceforth.h, a Code node takes 144 bytes on a 64-bit machine. On the other extreme, my ~/orig/40x experimental version, a vector linear-memory hybrid, takes only 16 bytes here. Go figure how the classic Forths needs only 2 or 4 bytes per node via linked-field and the final executable in a just a few KB. You might start to understand why the old Forth builders see C/C++ like plaque.&lt;/p&gt;
    &lt;p&gt;I try to release allocated blocks before exiting, however due to the dynamic alloc and resizing of std::vector, eForth dictionary hold on to many Code objects and the names string generated with them, valgrind (or similar tool) could reports lost (or leak). Though these memory blocks should all be reclaimed by the OS, it is something to be mindful of.&lt;/p&gt;
    &lt;p&gt;Current implementation utilize C++ vector as the core storage. Inside a Code object, there are pf, p1, p2 vectors to store branching words similar to that of an AST (Abstract Syntax Tree). The alternative is to stick all words into a single parameter field as done in classic Forth. I have created a branch one_pf doing exactly the same just to check it out. Also, tried polymorphic inner interpreter. So, are they better?&lt;/p&gt;
    &lt;code&gt;+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup.
&lt;/code&gt;
    &lt;p&gt;So, what cachegrind said for 100M loop tight loops and chacha.fs a CPU intensive?&lt;/p&gt;
    &lt;code&gt;| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |
&lt;/code&gt;
    &lt;p&gt;Apparently, grown ~30% in all aspects. I think because having branching primitives, i.e. _if/_else/_then, for/next, in C++ prevent the extra fetch of VM branches. Sort of the difference between having hardware and software branchers. However, my gut feeling is the difference shouldn't be so dramatic especially with the recursive nest(). More research on this...&lt;/p&gt;
    &lt;p&gt;Instead of using vectors (i.e. pf, p1, p2) to keep codes and parameters, this implementation follows classic Forth's model using one big block of parameter memory with words laid down contiguoursly. With 32-bit data, subroutine threaded but hybrid with 16-bit xt offset (to reduce one lookup).&lt;/p&gt;
    &lt;p&gt;It works better with WASM's memory model. It is used as the foundation for weForth. So far, it is stable but tweaked from time to time and&lt;/p&gt;
    &lt;code&gt;&amp;gt; make 50x
&amp;gt; ./tests/eforth50x
&lt;/code&gt;
    &lt;p&gt;Hinted by Sean Pringle's Rethinking Forth and Travis Bemann's wornderful zeptoforth. Nested module (or sub-words), simplified control structures are attemped. Now, moved to eForthX&lt;/p&gt;
    &lt;code&gt;+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Dr. Ting's work on eForth between 1995~2011 eForth references and their Source Code Repo&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210314: Initial&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Started with ~orig/33b code-base, refactor with enum and VA_ARGS macros targeting 100% C/C++.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210707: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Incorporated list-based dict, ss, rs (i.e. ~orig/ting/ceForth40 and ~orig/802) which I proposed to Dr. Ting in our email exchanges.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210816: Code Merge&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Targeting multi-platform. Common source by consolidating ceForth, wineForth, ESP32forth (kept in ~/orig/*). Officially version 8.0&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20220512: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Though the goal of Dr. Ting's is to demonstrate how a Forth can be easily understood and cleanly constructed. However, the token threading method used is costly (slow) because each call needs 2 indirect lookups (token-&amp;gt;dict, dict-&amp;gt;xt). On top of that, C/C++ call-frame needs to be setup/teardown. It is worsen by the branch prediction missing every call stalling the CPU pipeline. Bad stuffs!&lt;/item&gt;
          &lt;item&gt;Refactor to subroutine indirect threading. It's not portable but does speed up 25% (see benchmark above).&lt;/item&gt;
          &lt;item&gt;Using 16-bit offsets for pointer arithmetic which speed up another 5% while maintaining 16-bit parameter space consumption.&lt;/item&gt;
          &lt;item&gt;Since C++ code is at least 4-byte aligned and parameter is 2-byte aligned, the LSB of a given parameter is utilized for colon word identification.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20221118: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;WASM function pointer is U32 (index). Token-indirect worked but the two indirect look-up is even slower. Since WASM uses 64K linear memory block, 16-bit pointer offset is a better option. However, the xt "function pointer" in code space is simply an index to the shared _indirect_function_table. Since LSB is used, so we are forced to use MSB to differentiate primitive word from colon word. This left us 15-bit, i.e. 32K, parameter offset available.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20231011: Review&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Since the original intention of having a pre-compiled ROM dictionary still end up in C++ static initialization run before main(), moved dictionary compilation into dict_compile as function calls gives a little more debugging control and opportunity for fine tuning.&lt;/item&gt;
          &lt;item&gt;LAMBDA_OK option was originally intended for full VM implementation but 2x slower. Dropped to reduce source clutter.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20240308: Refactor for multi-platform, accept dynamic vectors&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experiment various threading and memory pointer models, archive into ~/orig/40x&lt;/item&gt;
          &lt;item&gt;To support cross-platform, i.g. Linux/Cygwin, Arduino/ESP32, Win32, and WASM, there were many conditional compilation branches which make the code really messy. The following were done &lt;list rend="ul"&gt;&lt;item&gt;Separate cross-platform and configuration into ~/src/config.h&lt;/item&gt;&lt;item&gt;Separate platform specific code into ~/platform&lt;/item&gt;&lt;item&gt;add included opcode for Forth script loading&lt;/item&gt;&lt;item&gt;rename 'next_idiom' to 'word', per Forth standard&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20241001: Add multi-threading support&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Shared dictionary and code space amount threads.&lt;/item&gt;
          &lt;item&gt;Refactor source into ceforth, ceforth_sys, and ceforth_task for their specific functions.&lt;/item&gt;
          &lt;item&gt;Introduce VM, states &lt;list rend="ul"&gt;&lt;item&gt;local ss, rs, tos, and user area&lt;/item&gt;&lt;item&gt;align to cache-line width&lt;/item&gt;&lt;item&gt;pass VM&amp;amp; to all lambda and static functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add thread pool and event_loop with affinity to physical cores. &lt;list rend="ul"&gt;&lt;item&gt;task, start, stop, join for thread life-cycle management&lt;/item&gt;&lt;item&gt;add general multi-threading demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add Inter-task communication &lt;list rend="ul"&gt;&lt;item&gt;pthread mutex and condition variables are used for synchronization&lt;/item&gt;&lt;item&gt;rank for task id&lt;/item&gt;&lt;item&gt;send, recv, and pull. Use local stack, as queue, for message passing.&lt;/item&gt;&lt;item&gt;add producer/consumer demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add IO sequencing &lt;list rend="ul"&gt;&lt;item&gt;ANSI-Color trace/logging for different cores&lt;/item&gt;&lt;item&gt;mutex guard used&lt;/item&gt;&lt;item&gt;lock, unlock for output stream synchronization&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC: 20250610: maintenance and memory leak check&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Refactor &lt;list rend="ul"&gt;&lt;item&gt;Macros to reduce verbosity i.e. VM referenced TOS, SS, RS, BRAN, BTGT&lt;/item&gt;&lt;item&gt;Group IO functions to forth_sys module&lt;/item&gt;&lt;item&gt;Macros to clarify intention, i.e. NEST, BASE, ADD_W&lt;/item&gt;&lt;item&gt;Code references replace Code pointers&lt;/item&gt;&lt;item&gt;Rename ms=&amp;gt;clock, delay=&amp;gt;ms (adhere to Forth Standard)&lt;/item&gt;&lt;item&gt;Add destructors to deallocate (reduce valgrind's complaints)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance multi-threading &lt;list rend="ul"&gt;&lt;item&gt;Use std::thread instead of pthread (except device specific CPU affinity)&lt;/item&gt;&lt;item&gt;Handle recursive include - Save/Restore WP&lt;/item&gt;&lt;item&gt;Refined forth_vm state machine transition (QUERY, HOLD, NEST, STOP)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance debugging &lt;list rend="ul"&gt;&lt;item&gt;Add dict() to detail dictionary entries&lt;/item&gt;&lt;item&gt;Add dump() to show memory/parameter field's content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Refactor &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/chochain/eforth"/><published>2025-11-09T04:59:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863057</id><title>Study finds memory decline surge in young people</title><updated>2025-11-09T14:08:21.453765+00:00</updated><content/><link href="https://onepercentrule.substack.com/p/under-40s-declining-memory"/><published>2025-11-09T05:05:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863360</id><title>I Am Mark Zuckerberg</title><updated>2025-11-09T14:08:21.170226+00:00</updated><content>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://iammarkzuckerberg.com/"/><published>2025-11-09T06:13:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45864732</id><title>Ask HN: How would you set up a child‚Äôs first Linux computer?</title><updated>2025-11-09T14:08:20.994279+00:00</updated><content>&lt;doc fingerprint="d1e111d1f886a428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;As a tech parent I think one of the best things I did for both my son and daughter was for their first computer to help them to build and setup their own Linux computer (It was Ubuntu back then but they‚Äôve both moved themselves to Arch these days).&lt;/p&gt;
      &lt;p&gt;We went together and bought a second hand desktop (exciting the people selling to us also) and when I got home I pulled out the Ram, HD and CD drive and set them aside; and then together with a screwdriver we ‚Äúbuilt the computer‚Äù over a few days.&lt;/p&gt;
      &lt;p&gt;In windows when a child goes searching the web for a ‚Äúmovie maker for windows‚Äù they are going to be in a world of hurt either finding expensive commercial options or super scammy sites promising the world.&lt;/p&gt;
      &lt;p&gt;By comparison on Linux if they search the local ‚Äúapp store‚Äù they‚Äôll find stacks and stacks of free, useful, open licensed software.&lt;/p&gt;
      &lt;p&gt;My kids loved the power, freedom and later unexpected community this bought them.&lt;/p&gt;
      &lt;p&gt;Now my friend wants the same for their daughter who is 8 years old.&lt;/p&gt;
      &lt;p&gt;I‚Äôm planning to do the same and go with her parents and her and buy a second hand desktop together and then put Linux on it.&lt;/p&gt;
      &lt;p&gt;My question is where would you go from there? What suggestions do you have? What to install? Any mini ‚Äúcurriculums‚Äù or ideas?&lt;/p&gt;
      &lt;p&gt;Would love to hear your ideas and experiences. Linux with free and open software is the goal and focus.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45864732"/><published>2025-11-09T11:12:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865049</id><title>Visualize FastAPI endpoints with FastAPI-Voyager</title><updated>2025-11-09T14:08:20.192687+00:00</updated><content>&lt;doc fingerprint="2d7d4c5aa849e7b4"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading‚Ä¶ FastAPI Voyager {{ state.version }} scroll to zoom in/out double click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }} {{ tag.routes.length }} {{ route.name }} No routes {{ dumpJson }} Import core data JSON&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.newsyeah.fun/voyager/"/><published>2025-11-09T12:24:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865098</id><title>Alive internet theory</title><updated>2025-11-09T14:08:19.906699+00:00</updated><link href="https://alivetheory.net/"/><published>2025-11-09T12:33:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865159</id><title>Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology</title><updated>2025-11-09T14:08:18.372039+00:00</updated><content>&lt;doc fingerprint="25357b3c1a218080"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt;How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery: A Digital Time Capsule from 1987&lt;/head&gt;
    &lt;p&gt;Picture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to &lt;code&gt;comp.sources.games&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;‚Äúconquest ‚Äì middle earth multi-player game, Part01/05‚Äù&lt;/p&gt;
    &lt;p&gt;That‚Äôs how Ed Barlow announced it at the time, before quickly changed the name to Conquer.&lt;/p&gt;
    &lt;p&gt;This was Conquer ‚Äì a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn‚Äôt just the gameplay, but how it was built and distributed in an era when ‚Äúopen source‚Äù wasn‚Äôt even a term yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 0: University Days.&lt;/head&gt;
    &lt;p&gt;It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy.&lt;/p&gt;
    &lt;p&gt;But by 2006, this piece of computing history was trapped in legal limbo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1: The Quest Begins (2006)&lt;/head&gt;
    &lt;p&gt;As a university student in Spain in the early ‚Äô90s, I‚Äôd encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear ‚Äì typical of the ‚Äúpost it and see what happens‚Äù era of early internet software distribution.&lt;/p&gt;
    &lt;p&gt;I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions.&lt;/p&gt;
    &lt;p&gt;Simple, right?&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 2: Digital Detective Work&lt;/head&gt;
    &lt;p&gt;Finding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums.&lt;/p&gt;
    &lt;p&gt;The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: ‚ÄúYes i delegated it all to adam aeons ago. Im easy on it all‚Ä¶. copyleft didnt exist when i wrote it and it was all for fun so‚Ä¶‚Äù&lt;/p&gt;
    &lt;p&gt;But there was a catch ‚Äì I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 3: The Long Wait (2006-2011)&lt;/head&gt;
    &lt;p&gt;I documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders.&lt;/p&gt;
    &lt;p&gt;Years passed. The project stalled.&lt;/p&gt;
    &lt;p&gt;Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:&lt;/p&gt;
    &lt;p&gt;‚ÄúI heard news of the request to release the code. I grant permission to release the code under GPL.‚Äù ‚Äì Adam Bryant&lt;/p&gt;
    &lt;p&gt;He had found one of my articles online and reached out on his own.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: The Plot Twist ‚Äì Version 5 Emerges (2025)&lt;/head&gt;
    &lt;p&gt;Fast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 ‚Äì a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn‚Äôt just an update; it was a complete reimagining of the game.&lt;/p&gt;
    &lt;p&gt;But V5 had a different legal history. In the ‚Äô90s, there had been commercial arrangements. Would Adam agree to GPL this version too?&lt;/p&gt;
    &lt;p&gt;His response: ‚ÄúI have no issues with applying a new GPL license to Version 5 as well.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 5: The Missing Piece ‚Äì PostScript Magic&lt;/head&gt;
    &lt;p&gt;Just when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps ‚Äì a crucial feature in the pre-GUI era when players needed physical printouts to strategize.&lt;/p&gt;
    &lt;p&gt;Tracking down MaF in 2025 led me to his company, where he‚Äôs now Director of Product Security. His response: ‚ÄúOh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.‚Äù&lt;lb/&gt;Richard Caley: More Than Just a Legal Footnote&lt;/p&gt;
    &lt;p&gt;But not all searches end with an answer. Some end with silence.&lt;/p&gt;
    &lt;p&gt;My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.&lt;/p&gt;
    &lt;p&gt;Then I found him ‚Äì not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org.&lt;/p&gt;
    &lt;p&gt;‚ÄúRichard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.‚Äù&lt;/p&gt;
    &lt;p&gt;Reading those words felt different from finding a historical record. This wasn‚Äôt archival research ‚Äì this was walking into someone‚Äôs house years after they‚Äôd gone and finding a note on the table.&lt;/p&gt;
    &lt;p&gt;The page continued:&lt;/p&gt;
    &lt;p&gt;‚ÄúOver and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.‚Äù&lt;/p&gt;
    &lt;p&gt;The ‚ÄúCaleyisms‚Äù ‚Äì The Man Behind the Code&lt;/p&gt;
    &lt;p&gt;And then I discovered his ‚ÄúCaleyisms‚Äù ‚Äì a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:&lt;/p&gt;
    &lt;p&gt;What‚Äôs a shell suit?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúOil company executive.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How do you prepare for a pyroclastic flow hitting Edinburgh?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúHang 1000 battered Mars bars on strings and stand back?‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;On his book addiction:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúI never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:&lt;/p&gt;
    &lt;p&gt;‚ÄúLack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn‚Äôt make it impossible to read what was written, just harder. But you probably write in green crayon anyway.‚Äù&lt;/p&gt;
    &lt;p&gt;A Digital Office Preserved&lt;/p&gt;
    &lt;p&gt;Exploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his ‚ÄúAbout‚Äù section:&lt;/p&gt;
    &lt;p&gt;‚ÄúThankfully I don‚Äôt have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I‚Äôm not.‚Äù&lt;/p&gt;
    &lt;p&gt;Here was a complete person ‚Äì technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions.&lt;/p&gt;
    &lt;p&gt;The legal reality was harsh: Richard‚Äôs contributions to Conquer couldn‚Äôt be relicensed. The university couldn‚Äôt help contact heirs due to privacy laws.&lt;/p&gt;
    &lt;p&gt;His friends had preserved his memory with a simple ASCII tribute at the end of his page:&lt;/p&gt;
    &lt;quote&gt;^_^&lt;lb/&gt;(O O)&lt;lb/&gt;\_/@@\&lt;lb/&gt;\\~~/&lt;lb/&gt;~~&lt;lb/&gt;- RJC RIP&lt;/quote&gt;
    &lt;p&gt;In the Conquer project documentation, Richard Caley isn‚Äôt remembered as a ‚Äúproblem case‚Äù or ‚Äúunlicensable code.‚Äù He‚Äôs honored as the vibrant person he was ‚Äì the brilliant mind behind the ‚ÄúCaleyisms,‚Äù the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 6: Modern Renaissance ‚Äì Enter GitHub, CICD and Modern Distributions&lt;/head&gt;
    &lt;p&gt;Here‚Äôs where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.&lt;/p&gt;
    &lt;p&gt;For APK packages, I used Melange ‚Äì a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi ‚Äúundistro‚Äù. The irony? I discovered this tool when some friend started to work for the company that created it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 7: The Technical Journey: From USENET to Modern CI/CD&lt;/head&gt;
    &lt;p&gt;The transformation has been remarkable:&lt;/p&gt;
    &lt;p&gt;1987 Original:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Distributed as split USENET posts&lt;/item&gt;
      &lt;item&gt;Manual compilation with system-specific Makefiles&lt;/item&gt;
      &lt;item&gt;No version control or automated testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2025 Revival:&lt;/p&gt;
    &lt;code&gt;# Modern CI/CD with GitHub Actions
- name: Build APK package
  run: melange build conquer.yaml
- name: Build Debian package  
  run: dpkg-buildpackage -b
&lt;/code&gt;
    &lt;p&gt;Key Modern Additions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPLv3 relicensing&lt;/item&gt;
      &lt;item&gt;Make building system modernization&lt;/item&gt;
      &lt;item&gt;C Codebase partially updated to support modern ANSI C99 specification&lt;/item&gt;
      &lt;item&gt;Debian packaging&lt;/item&gt;
      &lt;item&gt;APK packaging with Melange&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can see the complete transformation in the repositories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Conquer v4 ‚Äì The original classic&lt;/item&gt;
      &lt;item&gt;Conquer v5 ‚Äì The advanced rewrite&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Original Conquer v4 code, by Ed Barlow and Adam Bryant&lt;/p&gt;
    &lt;p&gt;(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!)&lt;/p&gt;
    &lt;p&gt;Conquer Version 5 ‚Äì The evolution of the classical Conquer, by Adam Bryant&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 8: The Human Element: Why This Matters&lt;/head&gt;
    &lt;p&gt;This isn‚Äôt just about preserving old games ‚Äì it‚Äôs about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that‚Äôs what you did ‚Äì you shared cool things with the community.&lt;/p&gt;
    &lt;p&gt;Martin Forssen‚Äôs PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator!&lt;/p&gt;
    &lt;p&gt;The 20-year relicensing effort demonstrates something crucial about open source: it‚Äôs not just about code, it‚Äôs about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they‚Äôre weaving the threads that connect computing‚Äôs past to its future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons for Modern Developers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Document everything: Those casual USENET posts became crucial legal evidence decades later&lt;/item&gt;
      &lt;item&gt;License clearly: Ed‚Äôs comment that ‚Äúcopyleft didnt exist when i wrote it‚Äù highlights how licensing landscapes evolve&lt;/item&gt;
      &lt;item&gt;Community matters: Adam found my articles because the community was talking about preservation&lt;/item&gt;
      &lt;item&gt;Technical debt is temporal: What seems like legacy tech today might be tomorrow‚Äôs archaeological treasure&lt;/item&gt;
      &lt;item&gt;Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Continuing Story&lt;/head&gt;
    &lt;p&gt;Both Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades.&lt;/p&gt;
    &lt;p&gt;The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life.&lt;/p&gt;
    &lt;p&gt;Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history.&lt;/p&gt;
    &lt;p&gt;What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?&lt;/p&gt;
    &lt;p&gt;#FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell&lt;/p&gt;
    &lt;p&gt;Read this article in Spanish / Lee este art√≠culo en espa√±ol: &lt;lb/&gt;https://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/&lt;/p&gt;
    &lt;p&gt;This article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/"/><published>2025-11-09T12:44:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865426</id><title>Drax: Speech Recognition with Discrete Flow Matching</title><updated>2025-11-09T14:08:17.873664+00:00</updated><content>&lt;doc fingerprint="e43d58cd0d3a4392"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.&lt;/p&gt;
    &lt;p&gt;Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, a discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as a promising direction for advancing NAR ASR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Community&lt;/head&gt;
    &lt;p&gt;We propose Drax, a non-autoregressive ASR model using discrete flow matching that includes an audio-conditioned intermediate distribution to better match inference dynamics.&lt;lb/&gt;Drax achieves accuracy comparable to state-of-the-art autoregressive models while offering better control over the accuracy-efficiency trade-off point.&lt;/p&gt;
    &lt;p&gt;This is an automated message from the Librarian Bot. I found the following papers similar to this paper.&lt;/p&gt;
    &lt;p&gt;The following papers were recommended by the Semantic Scholar API&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech (2025)&lt;/item&gt;
      &lt;item&gt;UniVoice: Unifying Autoregressive ASR and Flow-Matching based TTS with Large Language Models (2025)&lt;/item&gt;
      &lt;item&gt;From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training (2025)&lt;/item&gt;
      &lt;item&gt;Discrete Diffusion for Generative Modeling of Text-Aligned Speech Tokens (2025)&lt;/item&gt;
      &lt;item&gt;Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing (2025)&lt;/item&gt;
      &lt;item&gt;Flamed-TTS: Flow Matching Attention-Free Models for Efficient Generating and Dynamic Pacing Zero-shot Text-to-Speech (2025)&lt;/item&gt;
      &lt;item&gt;TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling (2025)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please give a thumbs up to this comment if you found it helpful!&lt;/p&gt;
    &lt;p&gt;If you want recommendations for any Paper on Hugging Face checkout this Space&lt;/p&gt;
    &lt;p&gt; You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: &lt;code&gt;

@librarian-bot
	 recommend&lt;/code&gt;&lt;/p&gt;
    &lt;head rend="h2"&gt;Models citing this paper 1&lt;/head&gt;
    &lt;head rend="h2"&gt;Datasets citing this paper 0&lt;/head&gt;
    &lt;p&gt;No dataset linking this paper&lt;/p&gt;
    &lt;head rend="h3"&gt;Spaces citing this paper 0&lt;/head&gt;
    &lt;p&gt;No Space linking this paper&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://huggingface.co/papers/2510.04162"/><published>2025-11-09T13:24:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865546</id><title>Show HN: Pipeflow-PHP ‚Äì Automate anything with pipelines even non-devs can edit</title><updated>2025-11-09T14:08:17.299238+00:00</updated><content>&lt;doc fingerprint="84c8071365d7bdb8"&gt;
  &lt;main&gt;
    &lt;p&gt;Pipeflow is a lightweight pipeline engine for PHP applications. It lets you describe complex automations as a sequence of small, reusable processing steps called stages. The real superpower is that the entire flow can be expressed in a clear XML format that is easy to read, visualise, and reason about‚Äîso even non-developers can review, maintain, and update automations without touching PHP code (but you can also configure the pipelines via hard coded php code). Each stage receives a shared context, performs a focused unit of work, and returns the enriched context to the next stage. By chaining stages together you can orchestrate complex jobs while keeping each piece easy to maintain and test.&lt;/p&gt;
    &lt;p&gt;In other words Pipeflow library gives you the instruments to instantiate one or more pipelines from an xml configuration, providing starting data in an initial context (optionally), and execute them when you want. What you will need to do is use these instruments in your web application to allow your actors to: edit the pipeline's configurations xml (via a text editor), save the pipeline xml configuration somewhere (e.g. your application db), and, when your application need to start a pipeline (manually or through a cron), just load the xml, feed it in the Pipeline class instance, and launch it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why Pipeflow matters&lt;/item&gt;
      &lt;item&gt;Real Use Cases&lt;/item&gt;
      &lt;item&gt;Other example use cases&lt;/item&gt;
      &lt;item&gt;Installation and Documentation&lt;/item&gt;
      &lt;item&gt;Quick introduction to pipelines&lt;/item&gt;
      &lt;item&gt;Extending with custom stages&lt;/item&gt;
      &lt;item&gt;Learn more&lt;/item&gt;
      &lt;item&gt;Contribute to PipeFlow&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Human-friendly configuration ‚Äì describe automations in an XML document that business users and developers alike can read, review, and edit safely.&lt;/item&gt;
      &lt;item&gt;Composable workflows ‚Äì build sophisticated automations by wiring together focused stages instead of writing one-off scripts.&lt;/item&gt;
      &lt;item&gt;Consistent execution model ‚Äì every stage works with the same &lt;code&gt;PipelineContext&lt;/code&gt;, making it straightforward to pass data between steps.&lt;/item&gt;
      &lt;item&gt;Configurable runtime ‚Äì author pipelines either in PHP or in XML, choose the configuration style that best fits your team.&lt;/item&gt;
      &lt;item&gt;Extensible catalogue ‚Äì register your own custom stages to integrate third-party services, generative AI calls, or bespoke business logic.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here is some real use cases which leverages the power of PipeFlow&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;PagineDaColorare.it: A wordpress website that automatically create and published coloring pages for children, daily, using the AI. This website uses two wordpress plugins I've developed (that maybe i will publish in future): one of them exposes pipeflow-php into wordpress, adding some custom stages to manage wordpress (creating posts, saving images, setting custom fields, category and tags) and allowing to modify the pipeline's xml from the wordpress admin panel (so that i can refine it, improve the content creation logic, change the logic on holidays, i.e. Christmas, and so on). The other plugins adds some more custom stages to pipeflow which allows to generate text and images with OpenAI apis. All these new custom stages is then used together to automatically run the coloring page content generation pipeline daily, with a cron. The advantage is that anyone, even non-developers, can refine, mantain, edit the coloring page content generation pipeline logic, simply by changing the XML configuration in the wordpress admin panel. The coloring page content generation pipeline configuration is now quite complex, but is very easy to read, understand and mantain: it combines many different stage types which randomizes coloring pages themes, subjects, actions, asking the supporting of the AI in different phases of the pipeline execution.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fiaberello.it: Similar to the website above, this is another website I've developed with the power of pipeflow. It automaticallys creates and publish fairy tales for children, with a cover image for each tale. This is more a test/example, it's pipeline is more simple and refined than the previous one, so it can be even improved.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Editorial automation for any CMS ‚Äì Create a plugin for your CMS which leverage pipeflow to build custom workflows which can be easily edited and refined by any actor in your team, even non developers: fetch posts, transform content, and trigger publication flows from scheduled pipelines, with editors able to tweak behaviour directly in XML, allowing any actor in your team (including non-developers) to mantain, refine, change the workflow.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Back-office data processing ‚Äì build nightly ETL jobs that consume feeds, clean data, and sync results to downstream services without redeploying code.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marketing and CRM orchestration ‚Äì enrich leads, call external APIs, and keep SaaS tools in sync while letting stakeholders adjust logic themselves.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AI-assisted content workflows ‚Äì combine prompt generation, randomisation, and templating stages to automate creative tasks, like i did on the websites above.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Any automation/workflow you can image, easily mantained by even non-developers - By allowing to create custom stages, you can encapsulate your custom business logic in new custom stages, which then can be used in your pipelines. These pipelines can then be edited, mantained or refined by any actor in your team, easily and visually by an easy to reason and read XML configuration.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The full reference, including installation instructions, quick start, and detailed stage catalogue, lives in DOCUMENTATION.md.&lt;/p&gt;
    &lt;p&gt;A pipeline describes the ordered stages that should run and the data they exchange. Typical stages read or write values from the &lt;code&gt;PipelineContext&lt;/code&gt; which is a container which contains parameters and their values, transform data, or control the flow of execution (loops, conditionals, etc.). The pipeline starts with an empty context, but you can feed a starting context from code if you want to provide the pipeline with prepared data to be available to the stages.&lt;/p&gt;
    &lt;p&gt;Each stage can reads and write data (parameters) to the context and perform operations (even custom operations by implementing custom stages, like calling apis, performing custom business logic operations, etc...), which can then be read and manipulated by the subsequent stages, until the pipelines finish the execution. At that point, the manipulated context is returned by the pipeline (with all the parameters written by the stages that has been executed).&lt;/p&gt;
    &lt;p&gt;Pipelines can be declared in XML so they can be edited without touching PHP code. A minimal XML pipeline looks like the following.&lt;/p&gt;
    &lt;code&gt;&amp;lt;?xml version="1.0" encoding="utf-8"?&amp;gt;
&amp;lt;pipeline id="hello_world"&amp;gt;
  &amp;lt;stages&amp;gt;
    &amp;lt;stage type="SetValue"&amp;gt;
      &amp;lt;settings&amp;gt;
        &amp;lt;param name="parameterName"&amp;gt;message&amp;lt;/param&amp;gt;
        &amp;lt;param name="parameterValue"&amp;gt;Hello Pipeflow!&amp;lt;/param&amp;gt;
      &amp;lt;/settings&amp;gt;
    &amp;lt;/stage&amp;gt;
    &amp;lt;stage type="Echo"&amp;gt;
      &amp;lt;settings&amp;gt;
        &amp;lt;param name="text"&amp;gt;%%message%%&amp;lt;/param&amp;gt;
      &amp;lt;/settings&amp;gt;
    &amp;lt;/stage&amp;gt;
  &amp;lt;/stages&amp;gt;
&amp;lt;/pipeline&amp;gt;&lt;/code&gt;
    &lt;p&gt;Your application tells pipeflow to load the XML configuration, pipeflow will automatically configure the pipeline and prepares it for execution. Your application can then launch the pipeline when it's needed simply by calling the execute() method on the pipeline instance (on demand or even via a cron). If you want, you can also pass a pre-defined starting context (if you want to feed, for example, some data from code into the pipeline execution, that can be used by the stages).&lt;/p&gt;
    &lt;p&gt;Because the pipeline definition is data-driven, you can adjust parameters or reorder stages without redeploying code.&lt;/p&gt;
    &lt;p&gt;### Configuring programmatically via PHP Since XML is the easier way to configure pipelines "visually" and allows also non-developers to edit and mantain them by enabling any actor to manage automations in your web applications, you can also configure the pipelines programmatically in your php code. This may have sense for example for those business logic automations that doesn't need to be edited/mantained from your application administration panels, are fixed (doesn't change often), or doesn't need to be mantained by non-developers actors. More info in the DOCUMENTATION.md&lt;/p&gt;
    &lt;p&gt;Pipeflow ships with a catalogue of built-in stages, but you can register your own custom stages to integrate APIs, internal systems, or platform-specific behaviour. Once registered, custom stages become available to both PHP and XML pipelines, letting you reuse them across projects.&lt;/p&gt;
    &lt;p&gt;The full reference, including installation instructions, control-flow stages, and detailed stage catalogue, lives in DOCUMENTATION.md.&lt;/p&gt;
    &lt;p&gt;Pipeflow thrives on community input and it surely needs improvements and features: Whether you want to improve the core engine, add new features, add new built-in stages, fix bugs, or share feedback from real-world deployments, we would love to collaborate. Check out CONTRIBUTING.md for guidelines on reporting issues, proposing ideas, and submitting pull requests.&lt;/p&gt;
    &lt;p&gt;Pipeflow is distributed under the permissive BSD 3-Clause License, which keeps the project friendly for both open-source and commercial use while encouraging community contributions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/marcosiino/pipeflow-php"/><published>2025-11-09T13:40:43+00:00</published></entry></feed>