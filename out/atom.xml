<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-07T10:40:08.586833+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45491609</id><title>Show HN: Kent Dybvig's Scheme Machine in 400 Lines of C (Heap-Memory Model)</title><updated>2025-10-07T10:40:15.091697+00:00</updated><content>&lt;doc fingerprint="c5d093b93a485002"&gt;
  &lt;main&gt;
    &lt;p&gt; Created &lt;relative-time&gt;February 17, 2023 12:42&lt;/relative-time&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;tool-tip&gt;Save swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b to your computer and use it in GitHub Desktop.&lt;/tool-tip&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Heap based scheme machine. &lt;/p&gt;
    &lt;p&gt; This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;/* Heap based virtual machine described in section 3.4 of Three Implementation Models for Scheme, Dybvig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;*/&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;string.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;ctype.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;assert.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char token[128][32];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int lexer(char* input) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int ii = 0; // input index&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int ti = 0; // token index&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while(input[ii] != '\0')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;switch(input[ii]) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Ignore whitespace and newlines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case ' ':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '\n':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn a left parenthesis into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '(':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = '(';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn a right parenthesis into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case ')':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = ')';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn an apostrophe into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '\'':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = '\'';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Anything else is a symbol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;default:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;for(int i = 0;; ++i) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(input[ii] != ' ' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != ')' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '(' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '\n' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '\0') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][i] = input[ii++];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][i] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int curtok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* nexttok() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return token[curtok++];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* peektok() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return token[curtok];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;typedef struct Pair {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;} Pair;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;typedef struct Text {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;struct Text* cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;} Text;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair text[1280];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* textptr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int istext(void* x) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return x &amp;gt;= (void*)&amp;amp;text &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;x &amp;lt; (void*)&amp;amp;text[1280];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* cons(void* x, void* y) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(istext(textptr));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr-&amp;gt;car = x;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr-&amp;gt;cdr = y;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return textptr++;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read(char* ln);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read(char* ln) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Initialize the lexer and list memory.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;curtok = 0;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr = text;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;lexer(ln);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_exp() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* tok = nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (tok[0] == '(' &amp;amp;&amp;amp; peektok()[0] == ')') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (tok[0] == '\'')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("quote", cons(read_exp(), NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (tok[0] == '(')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return tok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_list() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* tok = peektok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(tok[0] == ')') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(tok[0] == '.') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;tok = read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return tok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* fst = read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* snd = read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(fst, snd);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print(void* exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_exp(void* exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_list(Pair* list);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_cons(Pair* pair);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print(void* exp) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_exp(void* exp) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (istext(exp)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* pair = exp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(!istext(pair-&amp;gt;cdr) &amp;amp;&amp;amp; pair-&amp;gt;cdr != NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("(");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_cons(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("(");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_list(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("%s", exp ? (char*)exp : "()");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_list(Pair* list) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (list-&amp;gt;cdr == NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(list-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(!istext(list-&amp;gt;cdr) &amp;amp;&amp;amp; list-&amp;gt;cdr != NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_cons(list);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(list-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(" ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_list(list-&amp;gt;cdr);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_cons(Pair* pair) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(pair-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(" . ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(pair-&amp;gt;cdr);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* compile(void* exp, void* next) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (istext(exp)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* p = exp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(p-&amp;gt;car, "quote") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(p-&amp;gt;cdr-&amp;gt;car, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "lambda") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("close", cons(p-&amp;gt;cdr-&amp;gt;car, cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, cons("return", NULL)), cons(next, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "if") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return compile(p-&amp;gt;cdr-&amp;gt;car, cons("test", cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, next),&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, next),&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "set!") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, cons("assign", cons(p-&amp;gt;cdr-&amp;gt;car, cons(next, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "call/cc") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* c = cons("conti", cons(cons("argument", cons(compile(p-&amp;gt;cdr-&amp;gt;car, cons("apply", NULL)), NULL)), NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "return") == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return c;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("frame", cons(next, cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* args = (Pair*)p-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* c = compile(p-&amp;gt;car, cons("apply", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (args) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;c = compile(args-&amp;gt;car, cons("argument", cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;args = args-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "return") == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return c;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("frame", cons(next, cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(isdigit(*((char*)exp))) { // a number&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(strcmp(exp, "#t") == 0) { // a boolean&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(strcmp(exp, "#f") == 0) { // a boolean&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else { // a symbol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("refer", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* get(void* env, char* var) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* e = env;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while(env) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* cur = e-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* vars = cur-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* vals = cur-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (vars &amp;amp;&amp;amp; vals) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(vars-&amp;gt;car, var) == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return vals-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vars = vars-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vals = vals-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;e = e-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fprintf(stderr, "No definition in environment for %s.\n", var);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void set(void* env, char* var, char* val) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* ref = get(env, var);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ref = val;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* extend(void* env, void* vars, void* vals) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(cons(vars, vals), env);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* callframe(void* next, void* env, void* rib, void* stack) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(next, cons(env, cons(rib, cons(stack, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* closure(void* body, void* env, void* vars) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(body, cons(env, cons(vars, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* continuation(void* stack) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return closure(cons("nuate", cons(stack, cons("v", NULL))), NULL, cons("v", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* accum;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* env;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* rib;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* stack;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void virtmach() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "halt") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "refer") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = get(env, n-&amp;gt;cdr-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "constant") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "close") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* vars = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* body = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* x = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = closure(body, env, vars);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = x;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "test") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* consequent = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* alternate = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = strcmp(accum, "#f") == 0 ? alternate : consequent;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "assign") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;set(env, n-&amp;gt;cdr-&amp;gt;car, accum);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "conti") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = continuation(stack);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "nuate") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = get(env, n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = cons("return", NULL);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "frame") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = callframe(n-&amp;gt;cdr-&amp;gt;car, env, rib, stack);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "argument") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = cons(accum, rib);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "apply") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* a = accum;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* body = a-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* clos = a-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* vars = a-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;env = extend(env, vars, rib);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = body;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "return") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* s = stack;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = s-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;env = s-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = s-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = s-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fprintf(stderr, "Unhandled operation.\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int main(int argc, char** argv) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// note! repl implies there's a top-level but there isn't...&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("Lisp REPL\n\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("&amp;gt;&amp;gt; ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char buffer[256];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (fgets(buffer, 256, stdin)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = compile(read(buffer), cons("halt", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print(accum);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("&amp;gt;&amp;gt; ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return 0;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gist.github.com/swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b"/><published>2025-10-06T14:06:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45491621</id><title>Mise: Monorepo Tasks</title><updated>2025-10-07T10:40:14.567944+00:00</updated><content>&lt;doc fingerprint="6c502c738fd7a4ba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Monorepo Tasks #6564&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;We're excited to announce Monorepo Tasks, a powerful new feature that brings first-class monorepo support to mise tasks! 🚀&lt;/p&gt;
          &lt;head&gt;What is it?&lt;/head&gt;
          &lt;p&gt;Monorepo Tasks allows you to manage tasks across multiple projects in a single repository, with each project maintaining its own tools, environment variables, and tasks. Think of it as bringing the power of tools like Bazel or Turborepo to mise's task system, but with mise's signature simplicity.&lt;/p&gt;
          &lt;head&gt;Key Features&lt;/head&gt;
          &lt;head&gt;🎯 Unified Task Namespace&lt;/head&gt;
          &lt;p&gt;All tasks across your monorepo are automatically discovered and prefixed with their location:&lt;/p&gt;
          &lt;code&gt;mise //projects/frontend:build
mise //projects/backend:test
mise //services/api:deploy&lt;/code&gt;
          &lt;head&gt;🌳 Smart Tool &amp;amp; Environment Inheritance&lt;/head&gt;
          &lt;p&gt;Define common tools at the root, override them where needed:&lt;/p&gt;
          &lt;code&gt;# Root mise.toml
[tools]
node = "20"      # Inherited everywhere
python = "3.12"

# projects/legacy-app/mise.toml
[tools]
node = "14"      # Override just for this project
# python still inherited!&lt;/code&gt;
          &lt;head&gt;🎭 Powerful Wildcard Patterns&lt;/head&gt;
          &lt;p&gt;Run tasks across multiple projects with ease:&lt;/p&gt;
          &lt;code&gt;# Run tests in ALL projects
mise //...:test

# Run all build tasks under services/
mise //services/...:build

# Run ALL tasks in frontend (wildcards need quotes)
mise '//projects/frontend:*'

# Run all test:* tasks everywhere
mise '//...:test:*'&lt;/code&gt;
          &lt;head&gt;✨ Consistent Execution Anywhere&lt;/head&gt;
          &lt;p&gt;Run tasks from anywhere in the monorepo - they always execute with the correct context, tools, and environment from their config_root.&lt;/p&gt;
          &lt;head&gt;🔒 Automatic Trust Propagation&lt;/head&gt;
          &lt;p&gt;Trust your monorepo root once, and all descendant configs are automatically trusted.&lt;/p&gt;
          &lt;head&gt;Quick Start&lt;/head&gt;
          &lt;p&gt;1. Enable the feature in your root &lt;/p&gt;
          &lt;code&gt;experimental_monorepo_root = true

[tools]
node = "20"
python = "3.12"&lt;/code&gt;
          &lt;p&gt;2. Set the experimental flag:&lt;/p&gt;
          &lt;code&gt;export MISE_EXPERIMENTAL=1&lt;/code&gt;
          &lt;p&gt;3. Add tasks to your projects:&lt;/p&gt;
          &lt;code&gt;# projects/frontend/mise.toml
[tasks.build]
run = "npm run build"

[tasks.test]
run = "npm test"&lt;/code&gt;
          &lt;p&gt;4. Run tasks from anywhere:&lt;/p&gt;
          &lt;code&gt;mise //projects/frontend:build
mise //...:test  # Run tests in all projects!&lt;/code&gt;
          &lt;head&gt;Example Monorepo Structure&lt;/head&gt;
          &lt;p&gt;Run all service builds: &lt;/p&gt;
          &lt;head&gt;Why This Matters&lt;/head&gt;
          &lt;p&gt;Managing monorepos is hard. Coordinating tools, tasks, and environments across dozens of projects is even harder. With Monorepo Tasks, you get:&lt;/p&gt;
          &lt;head&gt;How Does This Compare to Other Tools?&lt;/head&gt;
          &lt;p&gt;The monorepo ecosystem is rich with excellent tools, each with different strengths. Here's how mise's Monorepo Tasks compares:&lt;/p&gt;
          &lt;head&gt;Simple Task Runners&lt;/head&gt;
          &lt;p&gt;Taskfile and Just are fantastic for single-project task automation. They're lightweight and easy to set up, but they weren't designed with monorepos in mind. While you can have multiple Taskfiles/Justfiles in a repo, they don't provide unified task discovery, cross-project wildcards, or automatic tool/environment inheritance across projects.&lt;/p&gt;
          &lt;p&gt;mise's advantage: Automatic task discovery across the entire monorepo with a unified namespace and powerful wildcard patterns.&lt;/p&gt;
          &lt;head&gt;JavaScript-Focused Tools&lt;/head&gt;
          &lt;p&gt;Nx, Turborepo, and Lerna are powerful tools specifically designed for JavaScript/TypeScript monorepos.&lt;/p&gt;
          &lt;p&gt;mise's advantage: Language-agnostic support. While these tools excel in JS/TS ecosystems, mise works equally well with Rust, Go, Python, Ruby, or any mix of languages. You also get unified tool version management (not just tasks) and environment variables across your entire stack.&lt;/p&gt;
          &lt;head&gt;Large-Scale Build Systems&lt;/head&gt;
          &lt;p&gt;Bazel (Google) and Buck2 (Meta) are industrial-strength build systems designed for massive, multi-language monorepos at companies with thousands of engineers.&lt;/p&gt;
          &lt;p&gt;Both are extremely powerful but come with significant complexity:&lt;/p&gt;
          &lt;p&gt;mise's advantage: Simplicity through non-hermetic builds. mise doesn't try to control your entire build environment in isolation - instead, it manages tools and tasks in a flexible, practical way. This "non-hermetic" approach means you can use mise without restructuring your entire codebase or learning a new language. You get powerful monorepo task management with simple TOML configuration - enough power for most teams without the enterprise-level complexity that hermetic builds require.&lt;/p&gt;
          &lt;head&gt;Other Notable Tools&lt;/head&gt;
          &lt;p&gt;Rush (Microsoft) offers strict dependency management and build orchestration for JavaScript monorepos, with a focus on safety and convention adherence.&lt;/p&gt;
          &lt;p&gt;Moon is a newer Rust-based build system that aims to be developer-friendly while supporting multiple languages.&lt;/p&gt;
          &lt;head&gt;The mise Sweet Spot&lt;/head&gt;
          &lt;p&gt;mise's Monorepo Tasks aims to hit the sweet spot between simplicity and power:&lt;/p&gt;
          &lt;p&gt;When to choose mise:&lt;/p&gt;
          &lt;p&gt;When to consider alternatives:&lt;/p&gt;
          &lt;p&gt;The best tool is the one that fits your team's needs. mise's Monorepo Tasks is designed for teams who want powerful monorepo management without the complexity overhead, especially when working across multiple languages.&lt;/p&gt;
          &lt;head&gt;Try It Out!&lt;/head&gt;
          &lt;p&gt;This feature is experimental, which means:&lt;/p&gt;
          &lt;p&gt;Read the full documentation: Monorepo Tasks Guide&lt;/p&gt;
          &lt;head&gt;We Want Your Feedback!&lt;/head&gt;
          &lt;p&gt;Please try it out and let us know:&lt;/p&gt;
          &lt;p&gt;Share your experience in the comments below! 👇&lt;/p&gt;
          &lt;p&gt;Special shoutout to the mise community for the feedback and ideas that led to this feature. Happy building! 🛠️&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 3 comments 9 replies&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Does this support &lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Excited to see this! We're currently using turbo in a mixed Rust/wasm/TS/Python/Go repo, and it's been a bit of a mixed bag (admittedly, I don't know how much of that is because we're unwilling to invest effort into modelling task inputs/outputs correctly in turbo).&lt;/p&gt;
          &lt;p&gt;Compounding the issue is that what we really want a whole bunch of things out of it:&lt;/p&gt;
          &lt;p&gt;Absent these, I don't really see us adopting this anytime soon unfortunately.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;The &lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jdx/mise/discussions/6564"/><published>2025-10-06T14:07:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492803</id><title>OpenZL: An open source format-aware compression framework</title><updated>2025-10-07T10:40:14.375172+00:00</updated><content>&lt;doc fingerprint="b69d42b82801cb99"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenZL is a new open source data compression framework that offers lossless compression for structured data.&lt;/item&gt;
      &lt;item&gt;OpenZL is designed to offer the performance of a format-specific compressor with the easy maintenance of a single executable binary.&lt;/item&gt;
      &lt;item&gt;You can get started with OpenZL today by visiting our Quick Start guide and the OpenZL GitHub repository.&lt;/item&gt;
      &lt;item&gt;Learn more about the theory behind OpenZL in this whitepaper.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Today, we are excited to announce the public release of OpenZL, a new data compression framework. OpenZL offers lossless compression for structured data, with performance comparable to specialized compressors. It accomplishes this by applying a configurable sequence of transforms to the input, revealing hidden order in the data, which can then be more easily compressed. Despite applying distinct transformation permutations for every file type, all OpenZL files can be decompressed using the same universal OpenZL decompressor.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Decade of Lessons&lt;/head&gt;
    &lt;p&gt;When Zstandard was announced, it came with a simple pitch: It promised the same or better compression ratio of prior default but at the much increased speed required by datacenter workloads. By pairing strong entropy coding with a design that fully utilized modern CPU capabilities, Zstandard offered a substantial improvement that justified its presence in datacenters.&lt;/p&gt;
    &lt;p&gt;However, while it was improved over time, remaining within the Zstandard framework offers diminishing returns. So we started looking for the next great leap in data compression.&lt;/p&gt;
    &lt;p&gt;In this quest, one pattern kept repeating: Using generic methods on structured data leaves compression gains on the table. Data isn’t just byte soup. It can be columnar, encode enums, be restricted to specific ranges, or carry highly repetitive fields. More importantly, it has predictable shapes. A bespoke compressor that leans into that structure can beat general-purpose tools on both ratio and speed. But there’s a catch — every bespoke scheme means another compressor and decompressor to create, ship, audit, patch, and trust.&lt;/p&gt;
    &lt;p&gt;OpenZL is our answer to the tension between the performance of format-specific compressors and the maintenance simplicity of a single executable binary.&lt;/p&gt;
    &lt;head rend="h2"&gt;Make the Structure Explicit&lt;/head&gt;
    &lt;p&gt;General compressors rely on a one-size fits all processing strategy, or alternatively spend a lot of their cycles guessing which techniques to use. OpenZL saves those cycles by making the structure an explicit input parameter. Compression can then focus on a sequence of reversible steps that surface patterns before coding.&lt;/p&gt;
    &lt;p&gt;As a user, you provide OpenZL with the data shape (via a preset or a thin format description). Then the trainer, an offline optimization component, builds an effective compression config that can be re-employed for similar data. During encoding that config resolves into a concrete decode recipe that’s embedded into the frame. The universal decoder will directly execute that recipe, without any out-of-band information.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Example Compression Using OpenZL&lt;/head&gt;
    &lt;p&gt;As an example, let’s compress sao, which is part of the Silesia Compression Corpus. This file follows a well-defined format featuring an array of records, each one describing a star. Providing this information to OpenZL is enough to give it an edge over generic lossless compressors, which only see bytes.&lt;/p&gt;
    &lt;p&gt;Comparison on a M1 cpu, using clang-17&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compressor&lt;/cell&gt;
        &lt;cell&gt;zstd -3&lt;/cell&gt;
        &lt;cell&gt;xz -9&lt;/cell&gt;
        &lt;cell&gt;OpenZL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compressed Size&lt;/cell&gt;
        &lt;cell&gt;5,531,935 B&lt;/cell&gt;
        &lt;cell&gt;4,414,351 B&lt;/cell&gt;
        &lt;cell&gt;3,516,649 B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compression Ratio&lt;/cell&gt;
        &lt;cell&gt;x1.31&lt;/cell&gt;
        &lt;cell&gt;x1.64&lt;/cell&gt;
        &lt;cell&gt;x2.06&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compression Speed&lt;/cell&gt;
        &lt;cell&gt;220 MB/s&lt;/cell&gt;
        &lt;cell&gt;3.5 MB/s&lt;/cell&gt;
        &lt;cell&gt;340 MB/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Decompression Speed&lt;/cell&gt;
        &lt;cell&gt;850 MB/s&lt;/cell&gt;
        &lt;cell&gt;45 MB/s&lt;/cell&gt;
        &lt;cell&gt;1200 MB/s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Crucially, OpenZL produces a higher compression ratio while preserving or even improving speed, which is critical for data center processing pipelines.&lt;/p&gt;
    &lt;p&gt;For illustration, this result is achieved using the following simple graph:&lt;/p&gt;
    &lt;head rend="h3"&gt;A Brief Explanation&lt;/head&gt;
    &lt;p&gt;So what is happening in this example?&lt;/p&gt;
    &lt;p&gt;We start by separating the header from the rest, a large table of structures. Then each field gets extracted into its own stream: the array of structures becomes a structure of arrays. After that point, we expect that each stream contains homogeneous data of the same type and semantic meaning. We can now focus on finding an optimal compression strategy for each one.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SRA0 is a position on the X axis. Due to the way the table is generated, the index is mostly sorted, inviting the use of delta to reduce the range of values represented. This mechanically makes the resulting stream easier to compress.&lt;/item&gt;
      &lt;item&gt;SDEC0 is a position on the Y axis. It’s not as well sorted as the X axis, but we can at least exploit the fact that it’s bounded between a minimum and a maximum. This makes the higher bytes more predictable, which can be exploited for better compression with the transpose operation.&lt;/item&gt;
      &lt;item&gt;The other fields (IS, MAG, XRPM, XDPM) share a common property: their cardinality is much lower than their quantities, and there is no relation between 2 consecutive values. This makes them a good target for tokenize, which will convert the stream into a dictionary and an index list.&lt;/item&gt;
      &lt;item&gt;The resulting dictionaries and index lists are very different. They benefit from completely different compression strategies. So they are sent to dedicated processing graphs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The graph continues beyond these steps. But at some point, we can also stop making decisions. The main work is to group data into homogeneous streams. After that, one can count on openzl to take care of the rest.&lt;/p&gt;
    &lt;p&gt;To go even further, we would like to generate compression strategies that are specifically fine-tuned for each stream. This is where the offline trainer stage comes into play.&lt;/p&gt;
    &lt;head rend="h2"&gt;Generate a Compressor Automatically&lt;/head&gt;
    &lt;p&gt;It’s possible to take full control of the compression process, but it’s also not required. A faster strategy is to just describe your data and let the system learn a compression config.&lt;/p&gt;
    &lt;p&gt;Describe the input: With the Simple Data Description Language (SDDL), you sketch how the bytes map to fields — rows, columns, enums, nested records. SDDL is for parsing only; it just tells OpenZL the shape of your data. Alternatively, you can write your own parser function directly using one of the supported languages, and register it with OpenZL to delegate the logic.&lt;/p&gt;
    &lt;p&gt;Learn the config: Starting from a preset, a parser function or an SDDL description, the trainer runs a budgeted search over transform choices and parameters to produce a Plan. It can provide a full set of speed/ratio tradeoffs, or directly target the best configuration respecting some speed constraints. Internally it uses a cluster finder (to group fields that behave alike) and a graph explorer (to try candidate subgraphs and keep score).&lt;/p&gt;
    &lt;p&gt;Resolve at encode-time: While compressing, the encoder turns the Plan into a concrete recipe — the Resolved Graph. If the Plan has control points, it picks the branch that fits the data and records that choice into the frame.&lt;/p&gt;
    &lt;p&gt;Decode without coordination: Each frame chunk carries its own resolved graph. The single decoder checks it, enforces limits, and runs the steps in order. When a plan improves, you just roll out the new plan, no new decompressor needed. Old data keeps decoding; new data get improved gains.&lt;/p&gt;
    &lt;p&gt;In practice the loop is straightforward: describe (SDDL) → train (produce a plan) → compress (emit frames with resolved graphs) → decode anywhere with the same binary.&lt;/p&gt;
    &lt;head rend="h2"&gt;Embracing Changes: Re-Training and In-Flight Control&lt;/head&gt;
    &lt;p&gt;In the real world, data evolves constantly, in both structure and content. A compressor built for one version of a schema would have a short lifetime.&lt;/p&gt;
    &lt;p&gt;Thankfully, with the flexibility offered by compression plans, we can react swiftly to data changes. At Meta, this is the core mission of Managed Compression, originally created to automate dictionary compression with Zstandard, and presented in an earlier blog on how we improved compression at with Zstandard.&lt;/p&gt;
    &lt;p&gt;OpenZL offers a training process that updates compression plans to maintain or improve compression performance, based on provided data samples. Now the synergy with Managed Compression is apparent: Each registered use case is monitored, sampled, periodically re-trained, and receives new configs when they prove beneficial. The decompression side continues to decode both old and new data without any change.&lt;/p&gt;
    &lt;p&gt;Runtime Adaptation: A compression config can include control points that read lightweight statistics at compression time (e.g., string repetition stats, run-length, histogram skew, delta variance) and choose the best branch of the Plan to go to next. Many technologies can be used, and textbook classifiers qualify. Control points handle bursts, outliers, and seasonal shifts without brute-force exploration: exploration is bounded, in order to maintain speed expectations. Taken branches are then recorded into the frame, and the decoder just executes the recorded path.&lt;/p&gt;
    &lt;p&gt;This gives the best of both worlds: dynamic behavior at compression time to handle variations and exceptions — without turning compression into an unbounded search problem — and with zero complexity added to the decoder.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Advantages of the Universal Decoder&lt;/head&gt;
    &lt;p&gt;OpenZL is capable of compressing a vast array of data formats, and they can all be decompressed with a single decompressor binary. Even when the compression configuration changes, the decoder does not. This may sound like operational minutiae, but it’s critical to OpenZL’s deployment success.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One audited surface: Security and correctness reviews focus on a single binary with consistent invariants, fuzzing, and hardening; there’s no myriad of per-format tools that can drift apart.&lt;/item&gt;
      &lt;item&gt;Fleet-wide improvements: A decoder update (security or performance — SIMD kernels, memory bounds, scheduling) benefits every compressed file, even those that predate the change.&lt;/item&gt;
      &lt;item&gt;Operational clarity: Same binary, same CLI, same metrics and dashboards across datasets; patching and rollout are uneventful by design.&lt;/item&gt;
      &lt;item&gt;Continuous training: With one decoder and many compression plans, we can keep improving while the system is live. Train a plan offline, try it on a small slice, then roll it out like any other config change. Backward compatibility is built-in — old frames still decode while new frames get better.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In other words, it’s possible to afford domain-specific compression without fragmenting the ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results With OpenZL&lt;/head&gt;
    &lt;p&gt;When OpenZL is able to understand and parse the file format, it is able to offer large improvements in compression ratio, while still providing fast compression and decompression speed. However, this is no magic bullet. When OpenZL doesn’t understand the input file format, it simply falls back to zstd.&lt;/p&gt;
    &lt;p&gt;OpenZL, through its offline training capabilities, is also able to offer a wide range of configurations in the tradeoff space of compression ratio, compression speed, and decompression speed. Unlike traditional compressors, which offer configuration by setting a compression level, OpenZL offers configuration by serializing the compressor graph. This allows an immense amount of flexibility to select diverse tradeoffs.&lt;/p&gt;
    &lt;p&gt;These results are based on datasets we’ve developed for our whitepaper. The datasets were chosen because they are highly structured and in a format that OpenZL supports. Every figure below is produced with scripts in the OpenZL repository so they can be reproduced, and the input data and logs from our runs have been uploaded to GitHub.&lt;/p&gt;
    &lt;p&gt;Note that data points connected by a line are pareto-optimal. All such points have the property that there is no point in the same dataset which beats them in both metrics.&lt;/p&gt;
    &lt;head rend="h3"&gt;When It’s Not Useful&lt;/head&gt;
    &lt;p&gt;OpenZL relies on a description of some structure to leverage its set of transforms. When there is no structure, there is no advantage. This is typically the case in pure text documents, such as enwik or dickens. In these cases, OpenZL falls back to zstd, offering essentially the same level of performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started With OpenZL&lt;/head&gt;
    &lt;p&gt;OpenZL’s selection of codecs is well-suited to compressing vector, tabular, or tree-structured data, and can be expected to perform well with numeric, string, or binary data. Common examples include timeseries datasets, ML tensors, and database tables. Keep in mind that we are bound by the limits of information theory, so the input needs to have some order that can be uncovered. As time goes on, we plan to incorporate additional codecs, as described in the next section.&lt;/p&gt;
    &lt;p&gt;If your data fits one of the above categories, then give it a try! Visit the OpenZL site and our Quick Start guide to get started.&lt;/p&gt;
    &lt;p&gt;If you want to dive into the code, check out the GitHub repository for source, documentation, and examples. We welcome contributions and feedback from the community!&lt;/p&gt;
    &lt;head rend="h2"&gt;Where We’re Going&lt;/head&gt;
    &lt;p&gt;OpenZL’s general direction is set: make it easier to expose structures, and exploit it with automated compression plans for evolving data.&lt;/p&gt;
    &lt;p&gt;Next up: We’re extending the transform library for time-series and grid-shaped data, improving performance of codecs, and enabling the trainer to find better compression plans faster. We also are actively working to extend SDDL to describe nested data formats more flexibly. Finally, the automated compressor explorer is getting better at proposing safe, testable changes to a compression plan within a specified budget.&lt;/p&gt;
    &lt;p&gt;Where the community can help: If you have a format or a dataset with obvious structure, try compressing it with an OpenZL prebuilt Plan. If it’s promising, try generating a new plan with the trainer or customizing it with our documentation to improve it. If it’s a format that the public might want, send it to us in a PR.&lt;/p&gt;
    &lt;p&gt;You can also contribute to the OpenZL core. If you have a knack for optimizing C/C++, help us speed up the engine or add transforms to cover new data formats. If your super power is reliability, the project would surely benefit from more validation rules and resource caps. And if you care about benchmarks, add your dataset to the harness so others can reproduce your results.&lt;/p&gt;
    &lt;p&gt;How to engage: Open an issue on the GitHub issue board. If you have a use-case for which you would expect OpenZL to do better, provide a few small samples, so that we can analyze them together. You may also contribute to codec optimizations, and propose new graphs, parsers or control points. All these topics do not impact the universality of the decoder.&lt;/p&gt;
    &lt;p&gt;We believe OpenZL opens up a new universe of possibilities to the data compression field, and we’re excited to see what the open source community will do with it!&lt;/p&gt;
    &lt;p&gt;To learn more about Meta Open Source, visit our website, subscribe to our YouTube channel, or follow us on Facebook, Threads, X, Bluesky and LinkedIn.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/"/><published>2025-10-06T16:01:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493358</id><title>Ladybird passes the Apple 90% threshold on web-platform-tests</title><updated>2025-10-07T10:40:14.129972+00:00</updated><content>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/awesomekling/status/1974781722953953601"/><published>2025-10-06T16:52:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493718</id><title>OpenAI ChatKit</title><updated>2025-10-07T10:40:13.545541+00:00</updated><content>&lt;doc fingerprint="22998170f99ebfba"&gt;
  &lt;main&gt;
    &lt;p&gt;ChatKit is a batteries-included framework for building high-quality, AI-powered chat experiences. It’s designed for developers who want to add advanced conversational intelligence to their apps fast—with minimal setup and no reinventing the wheel. ChatKit delivers a complete, production-ready chat interface out of the box.&lt;/p&gt;
    &lt;p&gt;Key features include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deep UI customization so that ChatKit feels like a first-class part of your app&lt;/item&gt;
      &lt;item&gt;Built-in response streaming for interactive, natural conversations&lt;/item&gt;
      &lt;item&gt;Tool and workflow integration for visualizing agentic actions and chain-of-thought reasoning&lt;/item&gt;
      &lt;item&gt;Rich interactive widgets rendered directly inside the chat&lt;/item&gt;
      &lt;item&gt;Attachment handling with support for file and image uploads&lt;/item&gt;
      &lt;item&gt;Thread and message management for organizing complex conversations&lt;/item&gt;
      &lt;item&gt;Source annotations and entity tagging for transparency and references&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Simply drop the ChatKit component into your app, configure a few options, and you're good to go.&lt;/p&gt;
    &lt;p&gt;ChatKit is a framework-agnostic, drop-in chat solution. You don’t need to build custom UIs, manage low-level chat state, or patch together various features yourself. Just add the ChatKit component, give it a client token, and customize the chat experience as needed, no extra work needed.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Generate a client token on your server.&lt;/p&gt;
        &lt;quote&gt;from fastapi import FastAPI from pydantic import BaseModel from openai import OpenAI import os app = FastAPI() openai = OpenAI(api_key=os.environ["OPENAI_API_KEY"]) @app.post("/api/chatkit/session") def create_chatkit_session(): session = openai.chatkit.sessions.create({ # ... }) return { client_secret: session.client_secret }&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install the React bindings&lt;/p&gt;
        &lt;quote&gt;npm install @openai/chatkit-react&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add the ChatKit JS script to your page&lt;/p&gt;
        &lt;quote&gt;&amp;lt;script src="https://cdn.platform.openai.com/deployments/chatkit/chatkit.js" async &amp;gt;&amp;lt;/script&amp;gt;&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Render ChatKit&lt;/p&gt;
        &lt;quote&gt;import { ChatKit, useChatKit } from '@openai/chatkit-react'; export function MyChat() { const { control } = useChatKit({ api: { async getClientSecret(existing) { if (existing) { // implement session refresh } const res = await fetch('/api/chatkit/session', { method: 'POST', headers: { 'Content-Type': 'application/json', }, }); const { client_secret } = await res.json(); return client_secret; }, }, }); return &amp;lt;ChatKit control={control} className="h-[600px] w-[320px]" /&amp;gt;; }&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/openai/chatkit-js"/><published>2025-10-06T17:23:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45494558</id><title>Apps SDK</title><updated>2025-10-07T10:40:13.164827+00:00</updated><content>&lt;doc fingerprint="9dca97fe33d1af9f"&gt;
  &lt;main&gt;
    &lt;p&gt;Our framework to build apps for ChatGPT.&lt;/p&gt;
    &lt;p&gt;Design components and conversational flows that feel native to ChatGPT.&lt;/p&gt;
    &lt;p&gt;Build apps that meet our quality, safety, and policy standards.&lt;/p&gt;
    &lt;p&gt;Identify and prioritize Apps SDK use cases.&lt;/p&gt;
    &lt;p&gt;Create and configure an MCP server.&lt;/p&gt;
    &lt;p&gt;Learn how to deploy your MCP server&lt;/p&gt;
    &lt;p&gt;Improve discovery and behavior with rich metadata.&lt;/p&gt;
    &lt;p&gt;Security and privacy considerations for Apps SDK.&lt;/p&gt;
    &lt;p&gt;Troubleshoot issues in Apps SDK apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://developers.openai.com/apps-sdk/"/><published>2025-10-06T18:27:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45495738</id><title>Translating Cython to Mojo, a first attempt</title><updated>2025-10-07T10:40:12.510195+00:00</updated><content>&lt;doc fingerprint="56b814f1ca2612d1"&gt;
  &lt;main&gt;
    &lt;p&gt;Ever since I heard about Mojo I (and presumably most other people) thought it would be a good language to speed up functions to be called from Python. Everyone knows that vanilla Python can be slow, but one of the reasons that Python programs can be reasonably fast in practice is because Python often leans on libraries written in more performant languages, predominantly C/C++, but increasingly also Rust.&lt;/p&gt;
    &lt;p&gt;Until recently, there has been no real way to call Mojo code from Python, but about a month ago (in Max release 25.4) the ability to call Mojo from Python was added as a beta feature. It’s not fully cooked yet, and it will likely still change a lot, but I wanted to give it a look just to get an idea of where things are heading.&lt;/p&gt;
    &lt;p&gt;One specific idea that I had when I heard about Mojo was that Mojo might be a good replacement for Cython and apparently I was not the only one to have had this thought:&lt;/p&gt;
    &lt;p&gt;The comments are from the HackerNews discussion on Vincent Warmerdam’s blog post titled “Python can run Mojo now” which made it to the front page of HN a while ago.&lt;/p&gt;
    &lt;p&gt;So where can I find a lot of Cython code?&lt;/p&gt;
    &lt;head rend="h2"&gt;Scikit-learn&lt;/head&gt;
    &lt;p&gt;Scikit-learn implements a bunch of machine learning algorithms and related utilities, and makes heavy use of Cython. How hard would it be to translate some of the Cython code in scikit-learn to Mojo?&lt;/p&gt;
    &lt;p&gt;I wanted a piece of code that was relatively simple, both just as I didn’t want to jump into the deep end, but also because there are some restrictions on Mojo functions being called from Python, namely (from the known limitations section of the Mojo/Python interop):&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Functions taking more than 3 arguments. Currently&lt;/p&gt;&lt;code&gt;PyTypeBuilder.add_function()&lt;/code&gt;and related function bindings only support Mojo functions that take up to 3&lt;code&gt;PythonObject&lt;/code&gt;arguments:&lt;code&gt;fn(PythonObject, PythonObject, PythonObject)&lt;/code&gt;.&lt;/quote&gt;
    &lt;head rend="h3"&gt;A simple case: dbscan_inner&lt;/head&gt;
    &lt;p&gt;An example I found that satisfies this criteria is the inner loop of DBSCAN that assigns points to clusters. It’s relatively short and takes exactly three arguments.&lt;/p&gt;
    &lt;p&gt;This is a classic case of a place where you would usually want to call speed up a tight inner loop in Python, in this case written in Cython:&lt;/p&gt;
    &lt;code&gt;# Fast inner loop for DBSCAN.

# Authors: The scikit-learn developers
# SPDX-License-Identifier: BSD-3-Clause

from libcpp.vector cimport vector

from ..utils._typedefs cimport uint8_t, intp_t


def dbscan_inner(const uint8_t[::1] is_core,
object[:] neighborhoods,
                  1] labels):
                  intp_t[::= 0, v
     cdef intp_t i, label_num 
     cdef intp_t[:] neighb
     cdef vector[intp_t] stack
for i in range(labels.shape[0]):
     if labels[i] != -1 or not is_core[i]:
         continue
             
# Depth-first search starting from i, ending at the non-core points.
         # This is very similar to the classic algorithm for computing connected
         # components, the difference being that we label non-core points as
         # part of a cluster (component), but don't expand their neighborhoods.
         while True:
         if labels[i] == -1:
             = label_num
                 labels[i] if is_core[i]:
                 = neighborhoods[i]
                     neighb for i in range(neighb.shape[0]):
                     = neighb[i]
                         v if labels[v] == -1:
                         
                             stack.push_back(v)
if stack.size() == 0:
             break
                 = stack.back()
             i 
             stack.pop_back()
+= 1         label_num &lt;/code&gt;
    &lt;p&gt;It’s not a complicated algorithm, and it labels core points and propagates that label to the neighbors of the core points.&lt;/p&gt;
    &lt;head rend="h3"&gt;Translating to Mojo&lt;/head&gt;
    &lt;p&gt;For the most part I just copied over the Cython code verbatim. There is a bit of boilerplate we need to add to the &lt;code&gt;.mojo&lt;/code&gt; file to make the function callable:&lt;/p&gt;
    &lt;code&gt;from python import PythonObject
from python.bindings import PythonModuleBuilder

from os import abort

@export
fn PyInit__dbscan_inner_mojo() -&amp;gt; PythonObject:
try:
     var m = PythonModuleBuilder("dbscan_inner_mojo")
         "dbscan_inner", docstring="Fast inner loop for DBSCAN.")
         m.def_function[dbscan_inner](return m.finalize()
         except e:
     return abort[PythonObject](String("error creating Python Mojo module:", e))         &lt;/code&gt;
    &lt;p&gt;but other than that, the translation was actually surprisingly straightforward, see if you can spot the differences in the Mojo and Cython versions:&lt;/p&gt;
    &lt;code&gt;fn dbscan_inner(is_core: PythonObject,

                  neighborhoods: PythonObject,raises:
                  labels: PythonObject) var i: Int = 0
     var label_num: Int= 0
     var v: Int = 0
     
var stack: List[Int] = []
     
for i in range(labels.shape[0]):
     if labels[i] != -1 or not is_core[i]:
         continue
             
# Depth-first search starting from i, ending at the non-core points.
         # This is very similar to the classic algorithm for computing connected
         # components, the difference being that we label non-core points as
         # part of a cluster (component), but don't expand their neighborhoods.
         while True:
         if labels[i] == -1:
             = label_num
                 labels[i] if is_core[i]:
                 = neighborhoods[i]
                     neighb for i in range(neighb.shape[0]):
                     = Int(neighb[i])
                         v if labels[v] == -1:
                         
                             stack.append(v)
if len(stack) == 0:
             break
                 = stack.pop()
             i 
+= 1         label_num &lt;/code&gt;
    &lt;p&gt;I defined &lt;code&gt;stack&lt;/code&gt; as a Mojo &lt;code&gt;List[Int]&lt;/code&gt; to replace the C++ &lt;code&gt;vector[intp_t]&lt;/code&gt; implementation in Cython. Other than the changes related to &lt;code&gt;stack&lt;/code&gt;, the only other changes were the initializations of the variables, and casting the entries in neighbors to integers.&lt;/p&gt;
    &lt;p&gt;It was honestly quite a bit simpler than I thought it would be, and the fact that both Cython and Mojo’s syntax is based on Python means a lot of the code “just works”.&lt;/p&gt;
    &lt;p&gt;As part of this experiment, my goal was to change the Python code as little as possible, and all I needed to do in &lt;code&gt;_dbscan.py&lt;/code&gt; was add:&lt;/p&gt;
    &lt;code&gt;import max.mojo.importer
import sys
0, "")
 sys.path.insert(
from _dbscan_inner_mojo import dbscan_inner&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;sys.path.insert(0, "")&lt;/code&gt; is a bit clunky, but the Mojo devs have said this is a temporary workaround.&lt;/p&gt;
    &lt;p&gt;I then ran pytest and all all the dbscan tests passed:&lt;/p&gt;
    &lt;code&gt;============================================================== test session starts ==============================================================
platform linux -- Python 3.12.9, pytest-8.4.1, pluggy-1.6.0
rootdir: /fast/Workspace/scikit-learn
configfile: pyproject.toml
plugins: anyio-4.9.0
collected 30 items                                                                                                                              

tests/test_dbscan.py ..............................                                                                                       [100%]

======================================================== 30 passed, 10 warnings in 0.54s ========================================================&lt;/code&gt;
    &lt;p&gt;The performance however is a bit lacking, presumably because Mojo is iterating over &lt;code&gt;PythonObjects&lt;/code&gt; for which it can’t properly optimize:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Cython average time: 2.78e-05 seconds&lt;/p&gt;&lt;lb/&gt;Mojo average time: 0.0227 seconds&lt;/quote&gt;
    &lt;p&gt;That’s around 800 times slower than Cython. We can however, make some minor tweaks to improve this.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improving performance&lt;/head&gt;
    &lt;p&gt;Let’s look at what is being passed to &lt;code&gt;dbscan_inner&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;core_samples&lt;/code&gt;is a numpy array of bytes (&lt;code&gt;np.uint8&lt;/code&gt;) signifying whether on not a sample is considered a core sample.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;neighborhoods&lt;/code&gt;is a list of numpy arrays of integers that specify which points neighbor each point. Effectively the edges of a graph.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;labels&lt;/code&gt;is a numpy array of integers, initialized to&lt;code&gt;-1&lt;/code&gt;, signifying that the points are currently unlabeled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can transform &lt;code&gt;labels&lt;/code&gt; and &lt;code&gt;is_core&lt;/code&gt; into Mojo Spans (thanks to Owen Hilyard on the Modular Discord for the hints):&lt;/p&gt;
    &lt;code&gt;= labels_py.ctypes.data.unsafe_get_as_pointer[DType.index]()
 var labels_ptr = Span(labels_ptr, Int(labels_py.shape[0]))
 var labels 
= is_core_py.ctypes.data.unsafe_get_as_pointer[DType.bool]()
 var is_core_ptr = Span(is_core_ptr, Int(is_core_py.shape[0])) var is_core &lt;/code&gt;
    &lt;p&gt;Not the prettiest, but this creates the &lt;code&gt;Span&lt;/code&gt;s without copying over the data.&lt;/p&gt;
    &lt;p&gt;The final code looks like:&lt;/p&gt;
    &lt;code&gt;fn dbscan_inner(is_core_py: PythonObject,

                  neighborhoods_py: PythonObject,raises:
                  labels_py: PythonObject) var label_num: Int= 0
     var v: Int = 0
     
var labels_ptr = labels_py.ctypes.data.unsafe_get_as_pointer[DType.index]()
     var labels = Span(labels_ptr, Int(labels_py.shape[0]))
     
var is_core_ptr = is_core_py.ctypes.data.unsafe_get_as_pointer[DType.bool]()
     var is_core = Span[mut=False](is_core_ptr, Int(is_core_py.shape[0]))
     

var stack: List[Int] = []
     
for i in range(len(labels)):
     if labels[i] != -1 or not is_core[i]:
         continue
             
# Depth-first search starting from i, ending at the non-core points.
         # This is very similar to the classic algorithm for computing connected
         # components, the difference being that we label non-core points as
         # part of a cluster (component), but don't expand their neighborhoods.
         while True:
         if labels[i] == -1:
             = label_num
                 labels[i] if is_core[i]:
                 var neighb = neighborhoods_py[i]
                     
for j in range(len(neighb)):
                     = Int(neighb[j])
                         v if labels[v] == -1:
                         
                             stack.append(v)
if len(stack) == 0:
             break
                 = stack.pop()
             i 
+= 1         label_num &lt;/code&gt;
    &lt;p&gt;Testing the performance now, we get:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Cython average time: 2.9e-05 seconds&lt;/p&gt;&lt;lb/&gt;Mojo average time: 8.59e-05 seconds&lt;/quote&gt;
    &lt;p&gt;So around 3x slower than Cython, but a lot faster than before.&lt;/p&gt;
    &lt;p&gt;Ideally we would also translate &lt;code&gt;neighborhoods&lt;/code&gt; into a Mojo type, but it gets a bit tricky here as &lt;code&gt;neighborhoods&lt;/code&gt; is a list of numpy arrays, which can all have different sizes, so simply assigning them to a type is a bit hard. There might be some solution out there, although likely changing the input to &lt;code&gt;dbscan_inner&lt;/code&gt; to something that can more easily be mapped to Mojo is likely the most sensible answer, but that’s beyond the scope of this little test.&lt;/p&gt;
    &lt;p&gt;Even so, the overall performance of DBSCAN as a whole is unchanged, as this inner function isn’t really the slow part of the algorithm (benchmarking code adapted from HDBSCAN):&lt;/p&gt;
    &lt;p&gt;The performance is identical (lines overlap almost exactly), and it’s the other parts of DBSCAN, like the neighborhood calculation, that take up the majority of the time:&lt;/p&gt;
    &lt;code&gt;=== Component Breakdown ===
Data validation: 0.0003s (0.0%)
NearestNeighbors fit: 0.0304s (2.1%)
Radius neighbors computation: 1.3573s (95.1%)
Core sample identification: 0.0019s (0.1%)
Cluster assignment: 0.0002s (0.0%)
Total: 1.4278s&lt;/code&gt;
    &lt;p&gt;In the future, I’d like to look into translating the slower parts of DBSCAN into Mojo, as the neighborhood radius calculation that takes up the most time can probably be parallelized, maybe even on the GPU.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;I chose this example not because it makes a lot of sense to translate it to Mojo, but just because it was easy to do so in a short amount of time. Right now, the Python interop is still a little too bleeding edge to do anything serious with, but at the pace that the language is evolving I doubt that this will be true for long.&lt;/p&gt;
    &lt;p&gt;It was however promising just how simple it was in this case, and most of the effort was in translating the PythonObjects into appropriate Mojo types to allow the compiler to reason about them. If I could request something from the Modular team it would be a “cheat-sheet” for best practices for translating common Python/numpy types into Mojo.&lt;/p&gt;
    &lt;p&gt;A more wholistic approach would be to also reconsider what is being passed to Mojo to make your life a bit easier when it comes to doing these translations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future plans&lt;/head&gt;
    &lt;p&gt;Once the Python interop stabilizes a little I want to see if I can rewrite some more substantial part of scikit-learn in Mojo, and preferably some algorithm that’s amenable to vectorization, possibly even on the GPU, so that I can really play into the strengths of Mojo. If you have any suggestions for an algorithm that is in need of some speeding up, let me know.&lt;/p&gt;
    &lt;p&gt;I think moving a lot of scikit-learn’s more computationally intensive code to Mojo could be an interesting project. There is a project called Mojmelo which is effectively the Mojo ecosystem’s answer to scikit-learn, however, almost no-one uses Mojo just yet.&lt;/p&gt;
    &lt;p&gt;On the other hand, scikit-learn was downloaded 100 Million times last month, so if you can speed up some of scikit-learn’s algorithms you can have a positive impact for a lot of users.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fnands.com/blog/2025/sklearn-mojo-dbscan-inner/"/><published>2025-10-06T20:09:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45496533</id><title>CodeMender: an AI agent for code security</title><updated>2025-10-07T10:40:12.108412+00:00</updated><content>&lt;doc fingerprint="b750e3f46eb396bc"&gt;
  &lt;main&gt;
    &lt;p&gt;Responsibility &amp;amp; Safety&lt;/p&gt;
    &lt;head rend="h1"&gt;Introducing CodeMender: an AI agent for code security&lt;/head&gt;
    &lt;p&gt;Using advanced AI to fix critical software vulnerabilities&lt;/p&gt;
    &lt;p&gt;Today, we’re sharing early results from our research on CodeMender, a new AI-powered agent that improves code security automatically.&lt;/p&gt;
    &lt;p&gt;Software vulnerabilities are notoriously difficult and time-consuming for developers to find and fix, even with traditional, automated methods like fuzzing. Our AI-based efforts like Big Sleep and OSS-Fuzz have demonstrated AI’s ability to find new zero-day vulnerabilities in well-tested software. As we achieve more breakthroughs in AI-powered vulnerability discovery, it will become increasingly difficult for humans alone to keep up.&lt;/p&gt;
    &lt;p&gt;CodeMender helps solve this problem by taking a comprehensive approach to code security that’s both reactive, instantly patching new vulnerabilities, and proactive, rewriting and securing existing code and eliminating entire classes of vulnerabilities in the process. Over the past six months that we’ve been building CodeMender, we have already upstreamed 72 security fixes to open source projects, including some as large as 4.5 million lines of code.&lt;/p&gt;
    &lt;p&gt;By automatically creating and applying high-quality security patches, CodeMender’s AI-powered agent helps developers and maintainers focus on what they do best — building good software.&lt;/p&gt;
    &lt;head rend="h2"&gt;CodeMender in action&lt;/head&gt;
    &lt;p&gt;CodeMender operates by leveraging the thinking capabilities of recent Gemini Deep Think models to produce an autonomous agent capable of debugging and fixing complex vulnerabilities.&lt;/p&gt;
    &lt;p&gt;To do this, the CodeMender agent is equipped with robust tools that let it reason about code before making changes, and automatically validate those changes to make sure they’re correct and don’t cause regressions.&lt;/p&gt;
    &lt;p&gt;While large language models are rapidly improving, mistakes in code security could be costly. CodeMender’s automatic validation process ensures that code changes are correct across many dimensions by only surfacing for human review high-quality patches that, for example, fix the root cause of the issue, are functionally correct, cause no regressions and follow style guidelines.&lt;/p&gt;
    &lt;p&gt;As part of our research, we also developed new techniques and tools that let CodeMender reason about code and validate changes more effectively. This includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Advanced program analysis: We developed tools based on advanced program analysis that include static analysis, dynamic analysis, differential testing, fuzzing and SMT solvers. Using these tools to systematically scrutinize code patterns, control flow and data flow, CodeMender can better identify the root causes of security flaws and architectural weaknesses.&lt;/item&gt;
      &lt;item&gt;Multi-agent systems: We developed special-purpose agents that enable CodeMender to tackle specific aspects of an underlying problem. For example, CodeMender uses a large language model-based critique tool that highlights the differences between the original and modified code in order to verify that the proposed changes do not introduce regressions, and self-correct as needed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Fixing vulnerabilities&lt;/head&gt;
    &lt;p&gt;To effectively patch a vulnerability, and prevent it from re-emerging, Code Mender uses a debugger, source code browser, and other tools to pinpoint root causes and devise patches. We have added two examples of CodeMender patching vulnerabilities in the video carousel below.&lt;/p&gt;
    &lt;p&gt;Example #1: Identifying the root cause of a vulnerability&lt;/p&gt;
    &lt;p&gt;Here’s a snippet of the agent's reasoning about the root cause for a CodeMender-generated patch, after analyzing the results of debugger output and a code search tool.&lt;/p&gt;
    &lt;p&gt;Although the final patch in this example only changed a few lines of code, the root cause of the vulnerability was not immediately clear. In this case, the crash report showed a heap buffer overflow, but the actual problem was elsewhere — an incorrect stack management of Extensible Markup Language (XML) elements during parsing.&lt;/p&gt;
    &lt;p&gt;Example #2: Agent is able to create non-trivial patches&lt;/p&gt;
    &lt;p&gt;In this example, the CodeMender agent was able to come up with a non-trivial patch that deals with a complex object lifetime issue.&lt;/p&gt;
    &lt;p&gt;The agent was not only able to figure out the root cause of the vulnerability, but was also able to modify a completely custom system for generating C code within the project.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proactively rewriting existing code for better security&lt;/head&gt;
    &lt;p&gt;We also designed CodeMender to proactively rewrite existing code to use more secure data structures and APIs.&lt;/p&gt;
    &lt;p&gt;For example, we deployed CodeMender to apply -fbounds-safety annotations to parts of a widely used image compression library called libwebp. When -fbounds-safety annotations are applied, the compiler adds bounds checks to the code to prevent an attacker from exploiting a buffer overflow or underflow to execute arbitrary code.&lt;/p&gt;
    &lt;p&gt;A few years ago, a heap buffer overflow vulnerability in libwebp (CVE-2023-4863) was used by a threat actor as part of a zero-click iOS exploit. With -fbounds-safety annotations, this vulnerability, along with most other buffer overflows in the project where we've applied annotations, would’ve been rendered unexploitable forever.&lt;/p&gt;
    &lt;p&gt;In the video carousel below we show examples of the agent’s decision-making process, including the validation steps.&lt;/p&gt;
    &lt;p&gt;Example #1: Agent’s reasoning steps&lt;/p&gt;
    &lt;p&gt;In this example, the CodeMender agent is asked to address the following -fbounds-safety error on bit_depths pointer:&lt;/p&gt;
    &lt;p&gt;Example #2: Agent automatically corrects errors and test failures&lt;/p&gt;
    &lt;p&gt;Another of CodeMender’s key features is its ability to automatically correct new errors and any test failures that arise from its own annotations. Here is an example of the agent recovering from a compilation error.&lt;/p&gt;
    &lt;p&gt;Example #3: Agent validates the changes&lt;/p&gt;
    &lt;p&gt;In this example, the CodeMender agent modifies a function and then uses the LLM judge tool configured for functional equivalence to verify that the functionality remains intact. When the tool detects a failure, the agent self-corrects based on the LLM judge's feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making software secure for everyone&lt;/head&gt;
    &lt;p&gt;While our early results with CodeMender are promising, we’re taking a cautious approach, focusing on reliability. Currently, all patches generated by CodeMender are reviewed by human researchers before they’re submitted upstream.&lt;/p&gt;
    &lt;p&gt;Using CodeMender, we've already begun submitting patches to various critical open-source libraries, many of which have already been accepted and upstreamed. We’re gradually ramping up this process to ensure quality and systematically address feedback from the open-source community.&lt;/p&gt;
    &lt;p&gt;We’ll also be gradually reaching out to interested maintainers of critical open source projects with CodeMender-generated patches. By iterating on feedback from this process, we hope to release CodeMender as a tool that can be used by all software developers to keep their codebases secure.&lt;/p&gt;
    &lt;p&gt;We will have a number of techniques and results to share, which we intend to publish as technical papers and reports in the coming months. With CodeMender, we've only just begun to explore AI’s incredible potential to enhance software security for everyone.&lt;/p&gt;
    &lt;p&gt;Acknowledgements&lt;/p&gt;
    &lt;p&gt;Credits (listed in alphabetical order):&lt;/p&gt;
    &lt;p&gt;Alex Rebert, Arman Hasanzadeh, Carlo Lemos, Charles Sutton, Dongge Liu, Gogul Balakrishnan, Hiep Chu, James Zern, Koushik Sen, Lihao Liang, Max Shavrick, Oliver Chang and Petros Maniatis.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/"/><published>2025-10-06T21:28:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45497384</id><title>Microsoft is plugging more holes that let you use Windows 11 without MS account</title><updated>2025-10-07T10:40:12.006214+00:00</updated><content>&lt;doc fingerprint="2798ea1532e6f0d7"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft is cracking down on bypass methods that let Windows 11 installs use a local account, and avoid an internet requirement during the setup process. In a new Windows 11 test build released today, Microsoft says it’s removing known workarounds for creating local accounts as they can apparently cause issues during the setup process.&lt;/p&gt;
    &lt;head rend="h1"&gt;Microsoft is plugging more holes that let you use Windows 11 without an online account&lt;/head&gt;
    &lt;p&gt;Microsoft really doesn’t want you creating a local account on Windows 11.&lt;/p&gt;
    &lt;p&gt;Microsoft really doesn’t want you creating a local account on Windows 11.&lt;/p&gt;
    &lt;p&gt;“We are removing known mechanisms for creating a local account in the Windows Setup experience (OOBE),” says Amanda Langowski, the lead for the Windows Insider Program. “While these mechanisms were often used to bypass Microsoft account setup, they also inadvertently skip critical setup screens, potentially causing users to exit OOBE with a device that is not fully configured for use.”&lt;/p&gt;
    &lt;p&gt;The changes mean Windows 11 users will need to complete the OOBE screens with an internet connection and Microsoft account in future versions of the OS.&lt;/p&gt;
    &lt;p&gt;Microsoft already removed the “bypassnro” workaround earlier this year, and today’s changes also disable the “start ms-cxh:localonly” command that Windows 11 users discovered after Microsoft’s previous changes. Using this command now resets the OOBE process and it fails to bypass the Microsoft account requirement.&lt;/p&gt;
    &lt;p&gt;These workarounds have been widely used to avoid a Microsoft account or internet access on Windows 11 Pro and Home installs in recent years. They’re easy to use, so you don’t have to create a custom unattended answer file to force Windows 11 to create a local account.&lt;/p&gt;
    &lt;p&gt;A lot of Windows users simply want to avoid using a Microsoft account or just want to customize the user folder name that Windows 11 creates from the email address of a Microsoft account. Thankfully, Microsoft is now adding a way to name your default user folder during the setup process, although you’ll need to use a command to get a custom folder name. Hopefully this will eventually become a simple option during the setup process.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/793579/microsoft-windows-11-local-account-bypass-workaround-changes"/><published>2025-10-06T23:15:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45497624</id><title>The least amount of CSS for a decent looking site (2023)</title><updated>2025-10-07T10:40:11.833683+00:00</updated><content>&lt;doc fingerprint="8c8abb396bb90f9d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The least amount of CSS for a decent looking site&lt;/head&gt;
    &lt;p&gt;Summary: People often over-engineer solutions, and it leads to them running into problems with their CSS. In this article, we'll take a look at the least amount of CSS that you need to make a decent looking page.&lt;/p&gt;
    &lt;p&gt;The fun part of making a website is that if you write your HTML and nothing else, you have a responsive website.&lt;/p&gt;
    &lt;p&gt;Granted, if you have images they can cause some overflow issues.&lt;/p&gt;
    &lt;p&gt;So we can start things off by fixing that:&lt;/p&gt;
    &lt;code&gt;img {
  max-width: 100%;
  display: block;
}&lt;/code&gt;
    &lt;p&gt;It’s possible you have videos or SVGs that are also causing problems (less likely with SVGs though), so if you need, you can expand upon this a little bit.&lt;/p&gt;
    &lt;code&gt;img,
svg,
video {
  max-width: 100%;
  display: block;
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Improving the typography&lt;/head&gt;
    &lt;p&gt;The first thing we can do is change the font family since the default is never very exciting.&lt;/p&gt;
    &lt;p&gt;We’ll just use a basic &lt;code&gt;system-ui&lt;/code&gt; for this example. It has pretty good support these days, and looks good on every system without having to worry about loading in any extra fonts.&lt;/p&gt;
    &lt;p&gt;In general, the font-size is a little small as well, so we can bump it up, and the default line-height is always a bit tight, so anything within the 1.5 to 1.7 range should do:&lt;/p&gt;
    &lt;code&gt;body {
  font-family: System UI;
  font-size: 1.25rem;
  line-height: 1.5;
}&lt;/code&gt;
    &lt;p&gt;Though not perfect, this is already a huge improvement over the regular defaults.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding Dark Mode Support&lt;/head&gt;
    &lt;p&gt;Many people love dark mode, so let’s enable it based on a user’s system preferences.&lt;/p&gt;
    &lt;p&gt;We can do this by using the &lt;code&gt;color-scheme&lt;/code&gt; property:&lt;/p&gt;
    &lt;code&gt;html {
  color-scheme: light dark;
}&lt;/code&gt;
    &lt;p&gt;This will set the user-agent-styles to either a light or dark theme, based on the users system preferences.&lt;/p&gt;
    &lt;p&gt;If you’d prefer, we can do this without CSS as well!&lt;/p&gt;
    &lt;code&gt;&amp;lt;html lang="en" color-scheme="light dark"&amp;gt;&amp;lt;/html&amp;gt;&lt;/code&gt;
    &lt;head rend="h3"&gt;A small note on following the system preferences&lt;/head&gt;
    &lt;p&gt;While this is really handy, it is a best practice to allow users to manually toggle the color-scheme as well.&lt;/p&gt;
    &lt;p&gt;Some people prefer a dark system theme, but light website themes, and vice-versa.&lt;/p&gt;
    &lt;head rend="h2"&gt;Restraining Content Width&lt;/head&gt;
    &lt;p&gt;Line-length is one of the most important things when it comes to the readability of text.&lt;/p&gt;
    &lt;p&gt;We generally want to try and fall somewhere in the 45-90 characters per line range (for body text, not headlines).&lt;/p&gt;
    &lt;p&gt;To make the website more readable, we’ll limit the content width using a &lt;code&gt;main&lt;/code&gt; element and some CSS magic:&lt;/p&gt;
    &lt;code&gt;main {
  max-width: min(70ch, 100% - 4rem);
  margin-inline: auto;
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;min()&lt;/code&gt; function here will pick whatever is smallest, either &lt;code&gt;70ch&lt;/code&gt; or &lt;code&gt;100% - 4rem&lt;/code&gt;. Because we are inside a &lt;code&gt;min()&lt;/code&gt; function, we don’t need to use a &lt;code&gt;calc()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Whatever the output from that min() function, the width is less than 100%, so the page will be stuck to the left side of the viewport.&lt;/p&gt;
    &lt;p&gt;We can then use margin-inline: auto to center it, as this acts on the margins on the inline axis, so in any horizontal writing modes, that means both the margin-left and margin-right are auto.&lt;/p&gt;
    &lt;p&gt;You might want to switch out the main selector for a .container or .wrapper so you can have more control over where you use it.&lt;/p&gt;
    &lt;p&gt;And with that, our final CSS file looks like this:&lt;/p&gt;
    &lt;code&gt;html {
  color-scheme: light dark;
}

body {
  font-family: system-ui;
  font-size: 1.25rem;
  line-height: 1.5;
}

img,
svg,
video {
  max-width: 100%;
  display: block;
}

main {
  max-width: min(70ch, 100% - 4rem);
  margin-inline: auto;
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Build on top of this&lt;/head&gt;
    &lt;p&gt;This is just a quick start to get things off the ground, though it could be used for a very simple page as well.&lt;/p&gt;
    &lt;p&gt;For the most part, though, you’ll probably want to build on top of this, but it should be able to act as a nice jumping off point!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thecascade.dev/article/least-amount-of-css/"/><published>2025-10-06T23:47:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45498469</id><title>Origami Patterns Solve a Major Physics Riddle</title><updated>2025-10-07T10:40:11.562609+00:00</updated><content>&lt;doc fingerprint="350a413e116f0c2f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Origami Patterns Solve a Major Physics Riddle&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;The amplituhedron is a geometric shape with an almost mystical quality: Compute its volume, and you get the answer to a central calculation in physics about how particles interact.&lt;/p&gt;
    &lt;p&gt;Now, a young mathematician at Cornell University named Pavel (Pasha) Galashin has found that the amplituhedron is also mysteriously connected to another completely unrelated subject: origami, the art of paper folding. In a proof posted in October 2024, he showed that patterns that arise in origami can be translated into a set of points that together form the amplituhedron. Somehow, the way paper folds and the way particles collide produce the same geometric shape.&lt;/p&gt;
    &lt;p&gt;“Pasha has done some brilliant work related to the amplituhedron before,” said Nima Arkani-Hamed, a physicist at the Institute for Advanced Study who introduced the amplituhedron in 2013 with his graduate student at the time, Jaroslav Trnka. “But this is next-level stuff for me.”&lt;/p&gt;
    &lt;p&gt;By drawing on this new link to origami, Galashin was also able to resolve an open conjecture about the amplituhedron, one that physicists had long assumed to be true but hadn’t been able to rigorously prove: that the shape really can be cut up into simpler building blocks that correspond to the calculations physicists want to make. In other words, the pieces of the amplituhedron really do fit together the way they’re supposed to.&lt;/p&gt;
    &lt;p&gt;The result doesn’t just build a bridge between two seemingly disparate areas of study. Galashin and other mathematicians are already exploring what else that bridge can tell them. They’re using it to better understand the amplituhedron — and to answer other questions in a far broader range of settings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Explosive Computations&lt;/head&gt;
    &lt;p&gt;Physicists want to predict what will happen when fundamental particles interact. Say two subatomic particles called gluons collide. They might bounce off each other unchanged, or transform into a set of four gluons, or do something else entirely. Each outcome occurs with a certain probability, which is represented by a mathematical expression called a scattering amplitude.&lt;/p&gt;
    &lt;p&gt;For decades, physicists calculated scattering amplitudes in one of two ways. The first used Feynman diagrams, squiggly-line drawings that describe how particles move and interact. Each diagram represents a mathematical computation; by adding together the computations corresponding to different Feynman diagrams, you can calculate a given scattering amplitude. But as the number of particles in a collision increases, the number of Feynman diagrams you need grows explosively. Things quickly get out of hand: Computing the scattering amplitudes of relatively simple events can require adding thousands or even millions of terms.&lt;/p&gt;
    &lt;p&gt;The second method, introduced in the early 2000s, is called Britto-Cachazo-Feng-Witten (BCFW) recursion. It breaks up complex particle interactions into smaller, simpler interactions that are easier to study. You can calculate amplitudes for these simpler interactions and keep track of them using collections of vertices and edges called graphs. These graphs tell you how to stitch the simpler interactions back together in order to compute the scattering amplitude of the original collision.&lt;/p&gt;
    &lt;p&gt;BCFW recursion requires less work than Feynman diagrams. Instead of adding up millions of terms, you might only need to add up hundreds. But both methods have the same problem: The final answer is often much simpler than the extensive computations it takes to get there, with many terms canceling out in the end.&lt;/p&gt;
    &lt;p&gt;Then, in 2013, Arkani-Hamed and Trnka made a surprising discovery: that the complicated math of particle collisions is actually geometry in disguise.&lt;/p&gt;
    &lt;head rend="h2"&gt;Saved by Geometry&lt;/head&gt;
    &lt;p&gt;In the early 2000s, Alexander Postnikov, a mathematician at the Massachusetts Institute of Technology, was studying a geometric object known as the positive Grassmannian.&lt;/p&gt;
    &lt;p&gt;The positive Grassmannian, which has been a subject of mathematical interest since the 1930s, is built in a highly abstract way. First, take an n-dimensional space and consider all the planes of some given, smaller dimension that live inside it. For example, inside the three-dimensional space we inhabit, you can find infinitely many flat two-dimensional planes that spread out in every direction.&lt;/p&gt;
    &lt;p&gt;Each plane — essentially a slice of the larger n-dimensional space — can be defined by an array of numbers called a matrix. You can compute certain values from this matrix, called minors, that tell you about properties of the plane.&lt;/p&gt;
    &lt;p&gt;Now consider only those planes in your space whose minors are all positive. The collection of all such special “positive” planes gives you a complicated geometric space — the positive Grassmannian.&lt;/p&gt;
    &lt;p&gt;To understand the positive Grassmannian’s rich internal structure, mathematicians divvy it up into different regions, so that each region consists of an assortment of planes that share certain patterns. Postnikov, hoping to make this task easier, came up with a way to keep track of the different regions and how they fit together. He invented what he called plabic (short for “planar bicolored”) graphs — networks of black and white vertices connected by edges, drawn so that no edges cross. Each plabic graph captured one region of the positive Grassmannian, giving mathematicians a visual language for what would otherwise be defined by dense algebraic formulas.&lt;/p&gt;
    &lt;p&gt;Nearly a decade after Postnikov introduced his plabic graphs, Arkani-Hamed and Trnka were trying to calculate the scattering amplitudes of various particle collisions. As they grappled with their BCFW recursion formulas, they noticed something uncanny. The graphs they were using to keep track of their calculations looked just like Postnikov’s plabic graphs. Curious, they drove up to MIT to meet him.&lt;/p&gt;
    &lt;p&gt;“At lunch we said, ‘It’s weird, we’re seeing exactly the same thing,’” Arkani-Hamed recalled.&lt;/p&gt;
    &lt;p&gt;They were right. To calculate the scattering amplitude for a collision of n particles, physicists would have to add up many BCFW terms — and each of those terms corresponded to a region of the positive Grassmannian in n dimensions.&lt;/p&gt;
    &lt;p&gt;Arkani-Hamed and Trnka realized that this geometric connection might make it easier to compute scattering amplitudes. Using data about their particle collision — the momenta of the particles, for instance — they defined a lower-dimensional shadow of the positive Grassmannian. The total volume of this shadow was equal to the scattering amplitude.&lt;/p&gt;
    &lt;p&gt;And so the amplituhedron was born.&lt;/p&gt;
    &lt;p&gt;That was only the beginning of the story. Physicists and mathematicians wanted to confirm, for instance, that the same plabic graphs that defined regions of the positive Grassmannian could also define pieces of the amplituhedron — and that those pieces would have no gaps or overlaps, perfectly fitting together to encompass the shape’s exact volume. This hope came to be known as the triangulation conjecture: Could the amplituhedron be cleanly triangulated, or subdivided, into simpler building blocks?&lt;/p&gt;
    &lt;p&gt;Proving this would cement Arkani-Hamed and Trnka’s vision: that the complicated BCFW formulas that produced a particle collision’s scattering amplitude (albeit inefficiently) could be understood as the sum of the volumes of the amplituhedron’s building blocks.&lt;/p&gt;
    &lt;p&gt;This was no easy task. For one thing, from the get-go it was clear there were really two amplituhedra. The first was defined in momentum-twistor coordinates — a clever mathematical relabeling that made the shape easier to work with because it related naturally to the positive Grassmannian and Postnikov’s plabic graphs. Mathematicians were able to prove the triangulation conjecture for this version of the amplituhedron in 2021.&lt;/p&gt;
    &lt;p&gt;The other version, known as the momentum amplituhedron, was instead defined directly in terms of the momenta of colliding particles. Physicists cared more about this second version, because it spoke the same language as real particle collisions and scattering experiments. But it was also harder to describe mathematically. As a result, the triangulation conjecture remained wide open.&lt;/p&gt;
    &lt;p&gt;If triangulation were to fail for the momentum amplituhedron, then it would mean that the amplituhedron was not the right way to make sense of BCFW formulas for computing scattering amplitudes.&lt;/p&gt;
    &lt;p&gt;For more than a decade, the uncertainty lingered — until the study of paper folds began to suggest a way forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding Bigfoot&lt;/head&gt;
    &lt;p&gt;Pavel Galashin didn’t set out to study either origami or the amplituhedron. In 2018, as one of Postnikov’s graduate students, he and a colleague had just proved an intriguing link between the positive Grassmannian and the Ising model, which is used to study the behavior of systems like ferromagnets. Galashin was now trying to understand a celebrated proof about the Ising model — in particular, about special symmetries it exhibited — in terms of the positive Grassmannian.&lt;/p&gt;
    &lt;p&gt;While working through the proof — a project he intermittently returned to over the next few years — Galashin encountered a couple of intriguing papers where researchers used other kinds of diagrams to make the geometry more tractable: origami crease patterns. These are diagrams of lines that tell you where to fold paper to make, say, a crane or frog.&lt;/p&gt;
    &lt;p&gt;It might seem strange for origami to crop up here. But over the years, the mathematics of origami has turned out to be surprisingly deep. Problems about origami — such as whether a given crease pattern will produce a shape that you can flatten without tearing — are computationally hard to solve. And it’s now known that origami can be used to perform all sorts of computations.&lt;/p&gt;
    &lt;p&gt;In 2023, while probing what origami was doing in papers about the Ising model, Galashin came across a question that caught his attention. Say you only have information about a crease pattern’s outer boundary — the border of the paper, which the creases divide into various line segments. In particular, say you only have information about how those line segments are situated in space before and after folding. Can you always find a complete crease pattern that both satisfies those constraints and produces an origami shape that can flatten properly? Mathematicians had conjectured that the answer was yes, but no one could prove it.&lt;/p&gt;
    &lt;p&gt;Galashin found the conjecture striking, because in his usual area of research, which deals with the positive Grassmannian, examining the boundary of an object is a common way to gain information about it.&lt;/p&gt;
    &lt;p&gt;But for months, he made no progress on it. Then he came to a sudden realization: The problem didn’t just have the same flavor as his own line of work. It could be rewritten in the language of the amplituhedron. The momentum amplituhedron, at that.&lt;/p&gt;
    &lt;p&gt;“It took much longer than I care to admit,” he said. “You don’t expect the connection, so you never realize it. You’re not supposed to see Bigfoot in Manhattan.”&lt;/p&gt;
    &lt;p&gt;But could he prove it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Forget Flat&lt;/head&gt;
    &lt;p&gt;Galashin considered a collision involving some number of particles, and started with a crease pattern boundary that was divided into that number of line segments.&lt;/p&gt;
    &lt;p&gt;He described each line segment with a vector that consisted of two numbers. Next, he wrote down vectors that described what the same segments’ new positions should be after folding. These were determined based on information about the momenta of the particles in his collision of interest.&lt;/p&gt;
    &lt;p&gt;For each segment, he then combined the “before” and “after” vectors into a single four-dimensional vector. By listing the numbers in all these vectors as one set of coordinates, Galashin was able to define a point in a high-dimensional space. And this point didn’t live just anywhere in high-dimensional space — it lived in the momentum amplituhedron.&lt;/p&gt;
    &lt;p&gt;Galashin showed that the answer to the origami question about flat-folding crease patterns was indeed yes — and that whenever such a crease pattern could be found for a given boundary, the point encoded by that boundary had to reside in the amplituhedron.&lt;/p&gt;
    &lt;p&gt;It was an entirely new way to think about the shape. “That’s the most amazing thing to me about Pasha’s work, that this connection to origami just gives you this incredibly beautiful one-line definition of the momentum amplituhedron,” Arkani-Hamed said.&lt;/p&gt;
    &lt;p&gt;Galashin’s new origami-based interpretation gave him an idea for how to finally solve the momentum amplituhedron’s central riddle. He could resolve the triangulation conjecture if he could show that each origami-derived point was situated not just inside the amplituhedron, but inside a very particular region — in just such a way that the regions would lock together without gaps or overlaps.&lt;/p&gt;
    &lt;p&gt;To do that, he devised an algorithm that took a boundary pattern as its input and assigned a unique crease pattern to it. The crease pattern would always obey the rules that linked it to the geometry of the amplituhedron: Namely, when folded, the paper would still be able to flatten.&lt;/p&gt;
    &lt;p&gt;Galashin then represented the crease pattern as a plabic graph: First, he drew a point in the middle of each region of the crease pattern, coloring it white if that region would face up once the paper was folded, and black if the region would face down. He then drew an edge between vertices in regions that shared a crease.&lt;/p&gt;
    &lt;p&gt;Finally, he showed that this graph carved out a region of the amplituhedron. The point encoded by that crease pattern’s boundary sat inside the region.&lt;/p&gt;
    &lt;p&gt;This was enough to resolve the triangulation question. If two regions in the amplituhedron overlapped — that is, if one point in the amplituhedron lived in two different regions — that would be equivalent to being able to match a boundary pattern to two different crease patterns. But Galashin had designed his algorithm to produce a unique match, so that was impossible. Similarly, the algorithm also implied that there could be no gaps: Every point in the amplituhedron could be rewritten as a boundary, and every boundary, when given as an input to the algorithm, landed neatly inside a region.&lt;/p&gt;
    &lt;p&gt;The amplituhedron fit together perfectly.&lt;/p&gt;
    &lt;head rend="h2"&gt;New Dreams&lt;/head&gt;
    &lt;p&gt;For mathematicians, the elegance of the argument was striking.&lt;/p&gt;
    &lt;p&gt;“To relate two seemingly unconnected ideas is always quite beautiful,” said Lauren Williams, a mathematician at Harvard University. “I hadn’t thought about origami crease patterns before, so it was a surprise to see them connected to the amplituhedron.”&lt;/p&gt;
    &lt;p&gt;Galashin shared her surprise. “I don’t have a good explanation for why boundaries of origami are points in the amplituhedron,” he said. “A priori there is no reason why one has to do with the other.” But he hopes that future investigations will uncover a deeper reason for the connection.&lt;/p&gt;
    &lt;p&gt;He is also hopeful that his result can help him with his original goal: to understand models of ferromagnetism and related systems through the lens of the positive Grassmannian. Perhaps using origami could help.&lt;/p&gt;
    &lt;p&gt;More broadly, physicists and mathematicians want to see if they can learn more about the amplituhedron — and wield it in a wider variety of theoretical calculations about particle collisions — by thinking about it in terms of origami. For instance, one goal is to be able to compute the scattering amplitude of a particle collision from the volume of the amplituhedron directly, without breaking it into pieces. Perhaps continuing to explore the link between crease patterns and particle collisions will help achieve this dream.&lt;/p&gt;
    &lt;p&gt;“As a physicist, I would not have come up with this in a million years,” Arkani-Hamed said. “But I find it a spectacular result, and I want to understand it more and see what it might tell us.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/origami-patterns-solve-a-major-physics-riddle-20251006/"/><published>2025-10-07T01:34:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45499170</id><title>Pdoc – Generate API documentation for Python projects</title><updated>2025-10-07T10:40:11.425413+00:00</updated><content>&lt;doc fingerprint="16c91461fc9ed2c5"&gt;
  &lt;main&gt;&lt;p&gt;&lt;code&gt;pdoc&lt;/code&gt; auto-generates API documentation that follows your project's Python module hierarchy.
                It requires no configuration, has first-class support for type annotations,
                cross-links between identifiers, comes with an integrated live-reloading web server,
                and understands numpydoc or Google-style docstrings.
            &lt;/p&gt;&lt;head rend="h2"&gt;Installation&lt;/head&gt;&lt;p&gt;Latest Release: 15.0.4&lt;/p&gt; Documentation Changelog PyPI GitHub &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pdoc.dev/"/><published>2025-10-07T03:40:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45499281</id><title>California law forces Netflix, Hulu to turn down ad volumes</title><updated>2025-10-07T10:40:11.366108+00:00</updated><content/><link href="https://www.politico.com/news/2025/10/06/dial-it-down-california-forces-netflix-hulu-to-lower-ad-volume-00595663"/><published>2025-10-07T04:03:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45499730</id><title>Learning a foreign language–before you're born</title><updated>2025-10-07T10:40:10.990917+00:00</updated><content>&lt;doc fingerprint="d3707dadc9ef5906"&gt;
  &lt;main&gt;
    &lt;p&gt;Can your brain attune itself to a foreign language before you’re born? A UdeM-led team of neuropsychology researchers has found that it can. A few weeks of prenatal exposure to a new language is enough to rewire the language networks in a newborn’s brain. From the very first hours of life, the foreign language heard in the womb is processed along the same neural pathways as the mother tongue, while a completely new foreign language is processed differently.&lt;/p&gt;
    &lt;p&gt;The findings are reported in an article published in Communications Biology. Lead authors Andréanne René and Laura Caron-Desrochers are doctoral students in Université de Montréal’s Department of Psychology, supervised by Professor Anne Gallagher. The study was funded by the Natural Sciences and Engineering Research Council of Canada.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nouvelles.umontreal.ca/en/article/2025/10/03/learning-a-foreign-language-before-you-re-born"/><published>2025-10-07T05:43:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45500485</id><title>Deloitte to refund the Australian government after using AI in $440k report</title><updated>2025-10-07T10:40:10.905662+00:00</updated><content>&lt;doc fingerprint="b60d88152e1fdfd2"&gt;
  &lt;main&gt;
    &lt;p&gt;Deloitte will provide a partial refund to the federal government over a $440,000 report that contained several errors, after admitting it used generative artificial intelligence to help produce it.&lt;/p&gt;
    &lt;p&gt;The Department of Employment and Workplace Relations (DEWR) confirmed Deloitte would repay the final instalment under its contract, which will be made public after the transaction is finalised. It comes as one Labor senator accused the consultancy firm of having a “human intelligence problem”.&lt;/p&gt;
    &lt;p&gt;Deloitte was commissioned by the department to review the targeted compliance framework and its IT system, used to automate penalties in the welfare system if mutual obligations weren’t met by jobseekers, in December 2024.&lt;/p&gt;
    &lt;p&gt;Sign up: AU Breaking News email&lt;/p&gt;
    &lt;p&gt;The subsequent report found widespread issues, including a lack of “traceability” between the rules of the framework and the legislation behind it, as well as “system defects”. It said an IT system was “driven by punitive assumptions of participant non-compliance”.&lt;/p&gt;
    &lt;p&gt;It was first published on 4 July. It was re-uploaded to the DEWR website on Friday, after the Australian Financial Review in August reported that multiple errors had been found, including nonexistent references and citations.&lt;/p&gt;
    &lt;p&gt;University of Sydney academic, Dr Christopher Rudge, who first highlighted the errors, said the report contained “hallucinations” where AI models may fill in gaps, misinterpret data, or try to guess answers.&lt;/p&gt;
    &lt;p&gt;“Instead of just substituting one hallucinated fake reference for a new ‘real’ reference, they’ve substituted the fake hallucinated references and in the new version, there’s like five, six or seven or eight in their place,” he said.&lt;/p&gt;
    &lt;p&gt;“So what that suggests is that the original claim made in the body of the report wasn’t based on any one particular evidentiary source.”&lt;/p&gt;
    &lt;p&gt;The updated review noted a “small number of corrections to references and footnotes”, but the department has said there have been no changes to the review’s recommendations.&lt;/p&gt;
    &lt;p&gt;“Deloitte conducted the independent assurance review and has confirmed some footnotes and references were incorrect,” a spokesperson for the department said.&lt;/p&gt;
    &lt;p&gt;“The substance of the independent review is retained, and there are no changes to the recommendations.”&lt;/p&gt;
    &lt;p&gt;In the updated version of the report, Deloitte added reference to the use of generative AI in its appendix. It states that a part of the report “included the use of a generative artificial intelligence (AI) large language model (Azure OpenAI GPT – 4o) based tool chain licensed by DEWR and hosted on DEWR’s Azure tenancy.”&lt;/p&gt;
    &lt;p&gt;Deloitte did not state that artificial intelligence was the reason behind the errors in its original report. It also stood by the original findings of the review.&lt;/p&gt;
    &lt;p&gt;“The updates made in no way impact or affect the substantive content, findings and recommendations in the report,” it stated in the amended version.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Deloitte said “the matter has been resolved directly with the client”.&lt;/p&gt;
    &lt;p&gt;Rudge said that, despite his criticism, he hesitates to say the whole report should be “regarded as illegitimate”, because the conclusions concur with other widespread evidence.&lt;/p&gt;
    &lt;p&gt;Labor senator Deborah O’Neill, who was on a senate inquiry into the integrity of consulting firms, said it looked like “AI is being left to do the heavy lifting”.&lt;/p&gt;
    &lt;p&gt;“Deloitte has a human intelligence problem. This would be laughable if it wasn’t so lamentable. A partial refund looks like a partial apology for substandard work,” she said.&lt;/p&gt;
    &lt;p&gt;“Anyone looking to contract these firms should be asking exactly who is doing the work they are paying for, and having that expertise and no AI use verified.&lt;/p&gt;
    &lt;p&gt;“Perhaps instead of a big consulting firm, procurers would be better off signing up for a ChatGPT subscription.”&lt;/p&gt;
    &lt;p&gt;The AFR found several incorrect references in the original report, including nonexistent reports by professors at the University of Sydney and the Lund University in Sweden.&lt;/p&gt;
    &lt;p&gt;The paper also reported a made-up reference to a court decision in a robodebt case, Deanna Amato v Commonwealth. Deloitte wrote in its final report that the update “amend[ed] the summary of the Amato proceeding which contained errors”.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/australia-news/2025/oct/06/deloitte-to-pay-money-back-to-albanese-government-after-using-ai-in-440000-report"/><published>2025-10-07T07:51:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45501073</id><title>Buckle Up, the Smart Glasses Backlash Is Coming</title><updated>2025-10-07T10:40:10.535900+00:00</updated><content>&lt;doc fingerprint="c3ee10da139ba938"&gt;
  &lt;main&gt;
    &lt;p&gt;Smart glasses are having a moment right now. At Meta’s Connect conference last month, which is normally reserved for the latest and greatest advancements in VR and XR hardware, the humble Quest was all but forgotten. In its place were not one, not two, but three new pairs of smart glasses, one of which has a displayâa first for Meta. That pivot to smart glasses is also apparently dragging Apple in its wake, with reports that the company is deprioritizing an affordable Vision Pro to focus on its own pair (or pairsÂ plural, actually) of specs.&lt;/p&gt;
    &lt;p&gt;The message is clear: smart glasses, as a category, have arrived, and with that big, bold promise of head-worn, AI-clad camera-equipped computers, is also impending (inevitable, I would say) backlash. Exhibit A: a new warning from San Francisco University. As reported by SFGate, the Bay Area college recently issued a campus-wide alert of a man wearing Ray-Ban Meta AI glasses and filming students (women, specifically) while asking them “inappropriate dating questions.” Those videos have already found their way to TikTok, Instagram, and the like.&lt;/p&gt;
    &lt;p&gt;I’m not going to name the account, which San Francisco University, maybe somewhat misguidedly, called out in its warning, but I watched some of the self-described “pickup lines” since they’re still viewable on Instagram, and can confirm they’re indeed inappropriate. Great. If you’re reading this and thinking, “Okay, so what? Social media has been a cesspool since before people were mad about ‘Obamacare.’ Why is this news?” Well, smart glasses, that’s why.&lt;/p&gt;
    &lt;p&gt;The fact that San Francisco University bothered to call out the wayÂ these videos were recorded (citing the specific name of Meta’s smart glasses and everything) says a lot, and in a lot of ways, that specificity is absolutely fair. As ascendant as smart glasses (or AI glasses, as Meta calls them) have been, there’s a chance that a lot of people may not have them on their radar yet. And the thing is, you shouldÂ know how to identify them. Registering when someone is recording with their phone is pretty obvious (they’re usually holding it in front of their face and pointing it at you), but smart glasses are discreet. Yes, there’s a light on the front of the smart glasses that indicates that someone is taking a video or picture, but you still have to know where to look and what that light means.&lt;/p&gt;
    &lt;p&gt;What I’m getting at is, because of that lack of knowledge around smart glasses and the inherent discreetness of them, people will, and clearly already are, pushing the boundaries. And this example isn’t even the worst one. Last month, after getting to try Meta’s Ray-Ban Display glasses (the ones with a screen) myself, I proclaimed that “these are the smart glasses you’ve been waiting for.” I stand by that statement, but also what I said subsequently, which is that “it’s time to talk about smart glasses.” Specifically, it’s time to talk about how and when we use them.&lt;/p&gt;
    &lt;p&gt;Last month, I spoke to Anshel Sag, a principal analyst at Moor Insights &amp;amp; Strategy who covers the wearable market, about the potential for another Google Glass-scale backlash, and while he says he doesn’t expect the pushback to be quite as severe as in 2013 (Ray-Ban Meta smart glasses do a much better job of blending in), I’m not so sure they’ll slide by unscathed. As desensitized to privacy incursions as people are nowadays, we just haven’t had a real reason to be angry about smart glasses. They’re rising, but they’re just not that popular yet. If they do become as pervasive as companies are speculating, I suspect people will have a lot more examples like the one above that could change their tune. That’s just how outrage works. People don’t care about stuff… until they do.&lt;/p&gt;
    &lt;p&gt;And sure, this one incident at San Francisco University probably won’t move the needle. But what if there are more? What if someone records youÂ with smart glasses without your knowledge, and it’s your face that ends up on some douchebag’s TikTok account? As much as I want to believe that people can use smart glasses responsibly, I think we all know where this is headed, and while the vast majority of people probably won’t abuse the ability to record their surroundings discreetly, an unfortunate and overrepresented subset just might. If smart glasses really are the next big thing, I’m willing to wager the road of public opinion might get a little bit choppy, and this little campus warning is just the start.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gizmodo.com/buckle-up-the-smart-glasses-backlash-is-coming-2000668213"/><published>2025-10-07T09:29:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45501099</id><title>Redis CVE-2025-49844: Use-After-Free may lead to remote code execution</title><updated>2025-10-07T10:40:10.272168+00:00</updated><content>&lt;doc fingerprint="bb7811b34f209d01"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Security Advisory: CVE-2025-49844&lt;/head&gt;
    &lt;head rend="h2"&gt;What happened?&lt;/head&gt;
    &lt;p&gt;As part of an ongoing effort by Redis and the Redis community to maintain Redis’ safety, security, and compliance posture, a security vulnerability in Redis has been identified and remediated in the versions indicated below.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is the vulnerability?&lt;/head&gt;
    &lt;p&gt;[CVE-2025-49844] Lua use-after-free may lead to remote code execution. CVSS Score: 10.0 (Critical)&lt;/p&gt;
    &lt;p&gt;An authenticated user may use a specially crafted Lua script to manipulate the garbage collector, trigger a use-after-free and potentially lead to remote code execution.&lt;/p&gt;
    &lt;head rend="h2"&gt;How can you protect your Redis instance?&lt;/head&gt;
    &lt;p&gt;Exploitation of this vulnerability requires an attacker to first gain authenticated access to your Redis instance.&lt;/p&gt;
    &lt;p&gt;There are several steps you can take to protect your Redis from being accessed by a malicious actor. To minimize the risk of exploitation, it’s important to follow these best practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restrict network access. Ensure that only authorized users and systems have access to the Redis database. Use firewalls and network policies to limit access to trusted sources and prevent unauthorized connectivity.&lt;/item&gt;
      &lt;item&gt;Enforce strong authentication. Enforce the use of credentials for all access to Redis instances. Avoid configurations that allow unauthenticated access, and ensure protected-mode is enabled (in CE and OSS) to prevent accidental exposure.&lt;/item&gt;
      &lt;item&gt;Limit permissions. Ensure that user identities with access to Redis are granted the minimum permissions necessary. Only allow trusted identities to run Lua scripts or any other potentially risky commands.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more details on how to securely configure, deploy, and use Redis, visit the Redis Community Edition and Redis Software documentation sites.&lt;/p&gt;
    &lt;head rend="h2"&gt;How can I remediate?&lt;/head&gt;
    &lt;p&gt;We’ve already upgraded our Redis Cloud service with the fixes, so no additional action is required from you.&lt;/p&gt;
    &lt;p&gt;If you’re self-managing Redis, whether Software or Community versions, upgrade your Redis to the latest release.&lt;/p&gt;
    &lt;p&gt;The versions of Redis OSS, CE, Stack, and Software listed below include the fixes. Once the upgrades are performed, the vulnerability will be remediated in your environment.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Vulnerability&lt;/cell&gt;
        &lt;cell role="head"&gt;Impacted releases&lt;/cell&gt;
        &lt;cell role="head"&gt;Fixed releases&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;[CVE-2025-49844] Lua Use-After-Free may lead to remote code execution CVSS Score: 10.0 (Critical)&lt;/cell&gt;
        &lt;cell&gt;All Redis Software releases&lt;/cell&gt;
        &lt;cell&gt;7.22.2-12 and above, 7.8.6-207 and above, 7.4.6-272 and above, 7.2.4-138 and above, 6.4.2-131 and above&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;All Redis OSS/CE/Stack releases with Lua scripting&lt;/cell&gt;
        &lt;cell&gt;OSS/CE: 8.2.2 and above, 8.0.4 and above, 7.4.6 and above, 7.2.11 and above, Stack: 7.4.0-v7 and above, 7.2.0-v19 and above&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;How can I tell if I was already exposed?&lt;/head&gt;
    &lt;p&gt;We have no evidence of exploitation of these vulnerabilities in Redis Cloud or reported in customer environments.&lt;/p&gt;
    &lt;p&gt;Below are general indicators of potential exploitation that you may use to search within your operating environment.&lt;/p&gt;
    &lt;p&gt;These technical and behavioral indicators or artifacts could be created if exploitation occurred. If you search for these within your Redis environment, you may be able to detect potential exploitation related to your Redis instance.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Access to the Redis database from unauthorized or unknown sources&lt;/item&gt;
      &lt;item&gt;Unknown or anomalous network ingress traffic to the Redis database&lt;/item&gt;
      &lt;item&gt;Unknown or unexpected use of the Redis scripting commands&lt;/item&gt;
      &lt;item&gt;Unknown or unexpected scripts present in your Redis database&lt;/item&gt;
      &lt;item&gt;Unexplained Redis server crashes, specifically crashes with a stack trace that originates from the Lua engine&lt;/item&gt;
      &lt;item&gt;Unknown, unexpected, or anomalous command execution by the redis-server user&lt;/item&gt;
      &lt;item&gt;Unknown or anomalous network egress traffic (or attempts) from the Redis database&lt;/item&gt;
      &lt;item&gt;Unknown or anomalous changes to the file system, in particular in directories that host Redis persistent or configuration files&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Who gets the credit?&lt;/head&gt;
    &lt;p&gt;We thank the following researchers for being so kind as to identify this vulnerability and report it through our published process:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The problem was reported by Wiz researchers Benny Isaacs (@benny_isaacs), Nir Brakha, Sagi Tzadik (@sagitz_) working with Trend Micro, Zero Day Initiative&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://redis.io/blog/security-advisory-cve-2025-49844/"/><published>2025-10-07T09:33:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45501114</id><title>The Mondrian introduction to functional optics</title><updated>2025-10-07T10:40:10.102980+00:00</updated><content>&lt;doc fingerprint="13dc85e44d4ba5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Mondrian introduction to functional optics&lt;/head&gt;
    &lt;p&gt;In this post I’d like to try to discuss what functional optics are, without going too much into why they are so cool, and you should use them, or how they are implemented1 and should be used with a specific language and library.&lt;/p&gt;
    &lt;p&gt;I personally think that functional optics should be a really easy concept to grasp, but currently learning them is harder than it should be mostly due to library implementation details, quite obscure documentation and an exotic usage of weird symbols.&lt;/p&gt;
    &lt;p&gt;Since a picture is worth a thousand words, I will introduce and use a graphical notation to illustrate the concepts we will discuss.&lt;/p&gt;
    &lt;head rend="h2"&gt;Types and values&lt;/head&gt;
    &lt;p&gt;Let’s start introducing our graphical notation from its basic building blocks.&lt;/p&gt;
    &lt;p&gt;We can represent a type with a simple coloured rectangle&lt;/p&gt;
    &lt;p&gt;A value for a given type will be represented as a horizontal line spanning the width of the rectangle&lt;/p&gt;
    &lt;head rend="h2"&gt;Sums and products&lt;/head&gt;
    &lt;p&gt;When considering algebraic data types, we have two ways of combining types, using products and sums.&lt;/p&gt;
    &lt;p&gt;The product of two types &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; is a new type, which we will denote by &lt;code&gt;A*B&lt;/code&gt;, whose values are composed of a value of type &lt;code&gt;A&lt;/code&gt; and a value of type &lt;code&gt;B&lt;/code&gt;. An example of a product type is a tuple like &lt;code&gt;(Int, String)&lt;/code&gt; where each value is pair composed of an integer and a string.&lt;/p&gt;
    &lt;p&gt;Graphically we can represent a product type as two side by side rectangles&lt;/p&gt;
    &lt;p&gt;When it comes to values, we need to upgrade a little bit our graphical interpretation. Since a value in a product type is composed of values of its components, we will just represent it as piecewise horizontal line, composed by horizontal lines (possible at different heights) spanning its horizontal sub-rectangles.&lt;/p&gt;
    &lt;p&gt;On the other hand, the sum of two types is represented by two rectangles one on top of the other&lt;/p&gt;
    &lt;p&gt;A value of a sum type is a horizontal line spanning the width of the whole rectangle. If it is a horizontal line in the top rectangle, it means that we are selecting the first type, and we’re using one of its values.&lt;/p&gt;
    &lt;p&gt;If it is a horizontal line in the bottom rectangle, it means that we are selecting the second type and one of its values.&lt;/p&gt;
    &lt;p&gt;More generally, for any algebraic data type, we can represent it as a sum of products by stacking a series of rectangles one on top of the other, each one potentially divided horizontally in multiple sub-rectangles.&lt;/p&gt;
    &lt;p&gt;In general, we can continue to split any sub-rectangle horizontally or vertically (if you prefer a top-down point of view) or you can place two rectangles side by side or top to bottom.&lt;/p&gt;
    &lt;p&gt;A value of such a type is a piecewise horizontal line which can not cross a horizontal division.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optics&lt;/head&gt;
    &lt;p&gt;Now that we have this graphical representation to represent data types, we can use it to discuss various kinds of optics.&lt;/p&gt;
    &lt;p&gt;In general, we can think of an optic as a way to select, given our graphical representation of a type, one (or more) rectangle inside a given rectangle representing a type. For example in the following picture we are selecting the rectangle with the red boundary inside the main rectangle representing a complex type.&lt;/p&gt;
    &lt;p&gt;If call the main type &lt;code&gt;A&lt;/code&gt; and the selected type &lt;code&gt;B&lt;/code&gt;, we will denote the optic selecting &lt;code&gt;B&lt;/code&gt; inside &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;Optic A B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Before going into inspecting the various kinds of optics, let’s try to see if can can already derive some properties of optics just by looking at their graphical representation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Compositionality&lt;/head&gt;
    &lt;p&gt;One thing that we can notice is that optics compose really well. Suppose we have a type &lt;code&gt;A&lt;/code&gt; represented by the following diagram&lt;/p&gt;
    &lt;p&gt;We can first select a sub-rectangle identifying a type &lt;code&gt;B&lt;/code&gt; with an &lt;code&gt;Optic A B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Starting now with the type &lt;code&gt;B&lt;/code&gt; we can use an &lt;code&gt;Optic B C&lt;/code&gt; to select a type &lt;code&gt;C&lt;/code&gt; inside &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Using now the &lt;code&gt;Optic A B&lt;/code&gt; and the &lt;code&gt;Optic B C&lt;/code&gt; we just chose, we can compose them to obtain an &lt;code&gt;Optic A C&lt;/code&gt; which directly selects &lt;code&gt;C&lt;/code&gt; inside &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This optic composition operation is actually associative and has an identity element, turning optics into a Category.&lt;/p&gt;
    &lt;p&gt;Let’s now start to have a look at some specific families of optics.&lt;/p&gt;
    &lt;head rend="h2"&gt;Iso&lt;/head&gt;
    &lt;p&gt;The simplest optic we can define for any type &lt;code&gt;A&lt;/code&gt; is the one that we can obtain by selecting the whole rectangle.&lt;/p&gt;
    &lt;p&gt;With such a selection we can see that for any value of the outer type &lt;code&gt;A&lt;/code&gt;, we actually have a value of the type identified by the red rectangle, which we will call &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This means that, given an &lt;code&gt;Iso A B&lt;/code&gt;, we can actually define a function &lt;code&gt;view :: A -&amp;gt; B&lt;/code&gt; that for any value of &lt;code&gt;A&lt;/code&gt; gives us a value of &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But in this special case also the converse holds! For any value of &lt;code&gt;B&lt;/code&gt;, since &lt;code&gt;B&lt;/code&gt; is actually &lt;code&gt;A&lt;/code&gt; itself, we have in fact a value of &lt;code&gt;A&lt;/code&gt;. This gives rise to a function &lt;code&gt;review :: B -&amp;gt; A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In fact &lt;code&gt;review . view = id_A&lt;/code&gt; and &lt;code&gt;view . review = id_B&lt;/code&gt; giving rise to a proper isomorphism.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lens&lt;/head&gt;
    &lt;p&gt;In our graphical representation, a &lt;code&gt;Lens&lt;/code&gt; is a vertical slice of the main rectangle.&lt;/p&gt;
    &lt;p&gt;Any vertical slice cuts out a piece out of any horizontal line. In other terms, given a value of the type &lt;code&gt;A&lt;/code&gt; represented by the main rectangle, we have a way to obtain a value of type &lt;code&gt;B&lt;/code&gt; represented by our vertical slice. This means that also in this case we are able to define a function &lt;code&gt;view :: A -&amp;gt; B&lt;/code&gt; which allows us to focus from the main type to one of its component.&lt;/p&gt;
    &lt;p&gt;On the other hand, it’s not possible with &lt;code&gt;Lens&lt;/code&gt;es as it was with &lt;code&gt;Iso&lt;/code&gt;s to build back a value of type &lt;code&gt;A&lt;/code&gt; from a value of type &lt;code&gt;B&lt;/code&gt;, since a value of type &lt;code&gt;B&lt;/code&gt; is only a part of value of type &lt;code&gt;A&lt;/code&gt;. What is actually possible, though, is to update only the part included in the red rectangle of a value of type &lt;code&gt;A&lt;/code&gt;. In other terms, given a &lt;code&gt;Lens A B&lt;/code&gt;, we can define a function &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; which takes a value of type &lt;code&gt;B&lt;/code&gt; and a value of type &lt;code&gt;A&lt;/code&gt; and updates the section of the latter identified by the &lt;code&gt;Lens&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Having a look at the graphical representations of the &lt;code&gt;view&lt;/code&gt; and &lt;code&gt;set&lt;/code&gt; functions, we can convince ourselves that the following properties hold:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If we &lt;code&gt;set&lt;/code&gt;a value and then we&lt;code&gt;view&lt;/code&gt;it, we must get back what we put in:&lt;code&gt;view (set b a) == b&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If we &lt;code&gt;set&lt;/code&gt;what we get out of a&lt;code&gt;view&lt;/code&gt;, nothing changes:&lt;code&gt;set (view a) a == a&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Setting a value twice is the same thing as setting it once: &lt;code&gt;set b (set b a) == set b a&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Moreover, we can notice that composing two lenses with the operation described in the Compositionality section gives us back another lens. A vertical slice of a vertical slice is in fact still a vertical slice of the original rectangle. In other terms this means that &lt;code&gt;Lens&lt;/code&gt;es form a subcategory of the bigger category of &lt;code&gt;Optic&lt;/code&gt;s.&lt;/p&gt;
    &lt;p&gt;Composing adequately &lt;code&gt;set&lt;/code&gt; and &lt;code&gt;view&lt;/code&gt; we can also define a function &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; as &lt;code&gt;over f a = set (f $ view a) a&lt;/code&gt;. This means that if we have a function &lt;code&gt;f :: B -&amp;gt; B&lt;/code&gt; which can transform values of type &lt;code&gt;B&lt;/code&gt;, we can use our lens to extract a &lt;code&gt;B&lt;/code&gt; from an &lt;code&gt;A&lt;/code&gt; via &lt;code&gt;view&lt;/code&gt;, use &lt;code&gt;f&lt;/code&gt; to transform the result, and eventually use &lt;code&gt;set&lt;/code&gt; to update the &lt;code&gt;B&lt;/code&gt; part inside the original &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prism&lt;/head&gt;
    &lt;p&gt;If vertical slices are &lt;code&gt;Lens&lt;/code&gt;es, it is only natural to wonder what are horizontal slices. They correspond to &lt;code&gt;Prism&lt;/code&gt;s, and they are the dual concept of &lt;code&gt;Lens&lt;/code&gt;es. Where a &lt;code&gt;Lens&lt;/code&gt; represents a component in a product type, a &lt;code&gt;Prism&lt;/code&gt; represents a component in a sum type.&lt;/p&gt;
    &lt;p&gt;Looking at values, we can notice that a value in the main type could either be a value of the inner type or it could be completely outside of it. This implies that, given a &lt;code&gt;Prism A B&lt;/code&gt;, we can define a function &lt;code&gt;preview :: A -&amp;gt; Maybe B&lt;/code&gt; which, given a value &lt;code&gt;a :: A&lt;/code&gt; returns a &lt;code&gt;Just b&lt;/code&gt; if &lt;code&gt;a&lt;/code&gt; was inside the sub-rectangle identified by &lt;code&gt;B&lt;/code&gt; and &lt;code&gt;Nothing&lt;/code&gt; otherwise.&lt;/p&gt;
    &lt;p&gt;On the other hard, since a &lt;code&gt;Prism&lt;/code&gt; constitutes a horizontal slice of the main rectangle, if we have a value of the sub-rectangle, we can always interpret it a value of the main rectangle. In other words, this means that for a &lt;code&gt;Prism A B&lt;/code&gt; we can always define a function &lt;code&gt;review :: B -&amp;gt; A&lt;/code&gt; constructing a value of type &lt;code&gt;A&lt;/code&gt; from a value of type &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Again, having a look at the graphical representation we can convince ourselves that the following properties hold for &lt;code&gt;Prism&lt;/code&gt;s:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If we preview through a &lt;code&gt;Prism&lt;/code&gt;what we just built using the same&lt;code&gt;Prism&lt;/code&gt;, we will get a value back:&lt;code&gt;preview (review b) == Just b&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If when we preview we get a &lt;code&gt;Just&lt;/code&gt;, then reviewing the result through the same&lt;code&gt;Prism&lt;/code&gt;will get us to the initial value:&lt;code&gt;preview s == Just a =&amp;gt; review a == s&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a &lt;code&gt;Prism A B&lt;/code&gt; it is also possible to define a function &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; as &lt;code&gt;set = flip $ const review&lt;/code&gt;. This means that, being able to construct an &lt;code&gt;A&lt;/code&gt; from a &lt;code&gt;B&lt;/code&gt;, we are able to substitute a &lt;code&gt;B&lt;/code&gt; inside an &lt;code&gt;A&lt;/code&gt; just by discarding the initial &lt;code&gt;A&lt;/code&gt; and building a new one from &lt;code&gt;B&lt;/code&gt;. Graphically, we can interpret this as using the &lt;code&gt;B&lt;/code&gt; value in the inner rectangle to build an &lt;code&gt;A&lt;/code&gt; value, forgetting about the initial &lt;code&gt;A&lt;/code&gt; value.&lt;/p&gt;
    &lt;p&gt;At this point we can also define another function &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; which allows us to update the &lt;code&gt;B&lt;/code&gt; part inside an &lt;code&gt;A&lt;/code&gt;. We can define it as &lt;code&gt;over f a = maybe a review (f &amp;lt;$&amp;gt; preview a)&lt;/code&gt;. In words, we use &lt;code&gt;preview&lt;/code&gt; to get a &lt;code&gt;Maybe B&lt;/code&gt; and we map &lt;code&gt;f&lt;/code&gt; over it to get another &lt;code&gt;Maybe B&lt;/code&gt;; if we have a value &lt;code&gt;Just b&lt;/code&gt;, then we can use it to construct an &lt;code&gt;A&lt;/code&gt; using &lt;code&gt;review&lt;/code&gt;; on the other hand, if we ended up with a &lt;code&gt;Nothing&lt;/code&gt;, we just keep the initial &lt;code&gt;A&lt;/code&gt;. Graphically, we can interpret this as follows: if the &lt;code&gt;A&lt;/code&gt; value is inside the &lt;code&gt;B&lt;/code&gt; sub-rectangle, we apply &lt;code&gt;f&lt;/code&gt; and then we use the result to build a new &lt;code&gt;A&lt;/code&gt; value; if the value is not in &lt;code&gt;B&lt;/code&gt;, we just leave it alone.&lt;/p&gt;
    &lt;p&gt;Looking at the graphical interpretation, it’s easy to convince ourselves that the composition of two &lt;code&gt;Prism&lt;/code&gt;s is still a &lt;code&gt;Prism&lt;/code&gt;, given that a horizontal slice of a horizontal slice is still a horizontal slice of the main rectangle. In other terms, also &lt;code&gt;Prism&lt;/code&gt;s form a subcategory of the category of &lt;code&gt;Optic&lt;/code&gt;s.&lt;/p&gt;
    &lt;head rend="h2"&gt;Affine traversals&lt;/head&gt;
    &lt;p&gt;Now that we discussed &lt;code&gt;Lens&lt;/code&gt;es and &lt;code&gt;Prism&lt;/code&gt;s, one natural question which might arise is what happens when we try to compose a &lt;code&gt;Lens&lt;/code&gt; and a &lt;code&gt;Prism&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In the picture above we see a &lt;code&gt;Lens&lt;/code&gt; (the blue rectangle) composed with a &lt;code&gt;Prism&lt;/code&gt; (the red rectangle). What we get out of the composition is the lower right rectangle, which is neither a &lt;code&gt;Lens&lt;/code&gt;, nor a &lt;code&gt;Prism&lt;/code&gt;, with respect to the main rectangle. It’s just a single inner rectangle.&lt;/p&gt;
    &lt;p&gt;On the other hand, if you think about it, every inner rectangle of the main rectangle could be obtained by composing &lt;code&gt;Lens&lt;/code&gt;es and &lt;code&gt;Prism&lt;/code&gt;s.&lt;/p&gt;
    &lt;p&gt;An &lt;code&gt;Optic&lt;/code&gt; identifying an inner rectangle is called an &lt;code&gt;AffineTraversal&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Combining the intuitions we had for &lt;code&gt;Lens&lt;/code&gt;es and &lt;code&gt;Prism&lt;/code&gt;s, it’s actually possible to define functions &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; and &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; also for &lt;code&gt;AffineTraversal&lt;/code&gt;s.&lt;/p&gt;
    &lt;p&gt;Moreover, the graphical representation suggests us that also &lt;code&gt;AffineTraversal&lt;/code&gt;s for a subcategory of &lt;code&gt;Optic&lt;/code&gt;s, since a sub-rectangle of a sub-rectangle is actually a sub-rectangle of the initial one.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why stop at one?&lt;/head&gt;
    &lt;p&gt;All the &lt;code&gt;Optic&lt;/code&gt;s that we discussed so far focus on a single sub-rectangle. But, if we want, we can consider also &lt;code&gt;Optic&lt;/code&gt;s which focus on multiple sub-rectangles at the same time.&lt;/p&gt;
    &lt;p&gt;We will denote by &lt;code&gt;Traversal A B&lt;/code&gt; the &lt;code&gt;Optic&lt;/code&gt;s which focus on multiple sub-rectangles of type &lt;code&gt;B&lt;/code&gt; inside a main rectangle of type &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;Traversal&lt;/code&gt;s we can still define &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; which replaces all the selected sub-rectangles of type &lt;code&gt;B&lt;/code&gt;, inside the main rectangle of type &lt;code&gt;A&lt;/code&gt;, with the same vale &lt;code&gt;b&lt;/code&gt; of type &lt;code&gt;B&lt;/code&gt;, to produce a new &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Similarly, we can define &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; which applies a function to all the selected sub-rectangles of type &lt;code&gt;B&lt;/code&gt;, inside the main rectangle of type &lt;code&gt;A&lt;/code&gt;, to produce a new &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another relevant function which makes sense to consider for &lt;code&gt;Traversal&lt;/code&gt;s is &lt;code&gt;toListOf :: A -&amp;gt; [B]&lt;/code&gt;, which extracts all the values of the selected sub-rectangles of type &lt;code&gt;B&lt;/code&gt; from the main rectangle of type &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;As usual, we can notice that &lt;code&gt;Traversal A B&lt;/code&gt; form a subcategory of &lt;code&gt;Optic A B&lt;/code&gt;, since a selection of sub-rectangles inside a selection 0f sub-rectangles is still a selection of sub-rectangles of the main rectangle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The graphical representation we just introduced in this post provides us with a tool to navigate various kinds of &lt;code&gt;Optic&lt;/code&gt;s and their operations. I hope it can provide a concrete way to understand the basic ideas behind &lt;code&gt;Lens&lt;/code&gt;es, &lt;code&gt;Prism&lt;/code&gt;s and other &lt;code&gt;Optic&lt;/code&gt;s and make it easier to use them.&lt;/p&gt;
    &lt;p&gt;Such a representation could also help to explore and shed some light on the mysterious world of &lt;code&gt;Optic&lt;/code&gt;s. One could try to search for other sub-categories in a graphical fashion and then ask what do they correspond to in other &lt;code&gt;Optic&lt;/code&gt; representation. For example, what is the sub-category of &lt;code&gt;Optics&lt;/code&gt; made by multiple horizontal slices? Or the one made by multiple vertical slices?&lt;/p&gt;
    &lt;p&gt;I need also to mention that such a representation is not able, as far as I can see, to fully represent the whole universe of &lt;code&gt;Optic&lt;/code&gt;s. For example, it’s hard to distinguish a &lt;code&gt;Traversal&lt;/code&gt; from a &lt;code&gt;Fold&lt;/code&gt;, or describe what &lt;code&gt;Grate&lt;/code&gt;s are.&lt;/p&gt;
    &lt;p&gt;All in all, I’m confident that describing and explaining optics in this graphical fashion could help people understand their beauty and usefulness! Thanks for reading up to here!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://marcosh.github.io/post/2025/10/07/the-mondrian-introduction-to-functional-optics.html"/><published>2025-10-07T09:35:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45501189</id><title>Nobel Prize in Physics Awarded to John Clarke, Michel Devoret and John Martinis</title><updated>2025-10-07T10:40:09.815769+00:00</updated><content>&lt;doc fingerprint="715db15f2195d5ea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Popular information&lt;/head&gt;
    &lt;p&gt;Popular science background: Quantum properties on a human scale (pdf)&lt;lb/&gt;Populärvetenskaplig information: Kvantegenskaper på mänsklig skala (pdf)&lt;/p&gt;
    &lt;head rend="h2"&gt;Quantum properties on a human scale&lt;/head&gt;
    &lt;p&gt;The Nobel Prize laureates in physics for 2025, John Clarke, Michel H. Devoret and John M. Martinis, used a series of experiments to demonstrate that the bizarre properties of the quantum world can be made concrete in a system big enough to be held in the hand. Their superconducting electrical system could tunnel from one state to another, as if it were passing straight through a wall. They also showed that the system absorbed and emitted energy in doses of specific sizes, just as predicted by quantum mechanics.&lt;/p&gt;
    &lt;head rend="h3"&gt;A series of groundbreaking experiments&lt;/head&gt;
    &lt;p&gt;Quantum mechanics describes properties that are significant on a scale that involves single particles. In quantum physics, these phenomena are called microscopic, even when they are much smaller than can be seen using an optical microscope. This contrasts with macroscopic phenomena, which consist of a large number of particles. For example, an everyday ball is built up of an astronomical amount of molecules and displays no quantum mechanical effects. We know that the ball will bounce back every time it is thrown at a wall. A single particle, however, will sometimes pass straight through an equivalent barrier in its microscopic world and appear on the other side. This quantum mechanical phenomenon is called tunnelling.&lt;/p&gt;
    &lt;p&gt;This year’s Nobel Prize in Physics recognises experiments that demonstrated how quantum tunnelling can be observed on a macroscopic scale, involving many particles. In 1984 and 1985, John Clarke, Michel Devoret and John Martinis conducted a series of experiments at the University of California, Berkeley. They built an electrical circuit with two superconductors, components that can conduct a current without any electrical resistance. They separated these with a thin layer of material that did not conduct any current at all. In this experiment, they showed that they could control and investigate a phenomenon in which all the charged particles in the superconductor behave in unison, as if they are a single particle that fills the entire circuit.&lt;/p&gt;
    &lt;p&gt;This particle-like system is trapped in a state in which current flows without any voltage – a state from which it does not have enough energy to escape. In the experiment, the system shows its quantum character by using tunnelling to escape the zero-voltage state, generating an electrical voltage. The laureates were also able to show that the system is quantised, which means it only absorbs or emits energy in specific amounts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tunnels and crossings&lt;/head&gt;
    &lt;p&gt;To help them, the laureates had concepts and experimental tools that had been developed over decades. Together with the theory of relativity, quantum physics is the foundation of what has come to be called modern physics, and researchers have spent the last century exploring what it entails.&lt;/p&gt;
    &lt;p&gt;Individual particles’ ability to tunnel is well known. In 1928, the physicist George Gamow realised that tunnelling is the reason why some heavy atomic nuclei tend to decay in a particular manner. The interaction between the forces in the nucleus creates a barrier around it, holding in the particles it contains. However, despite this, a small piece of the atomic nucleus can sometimes split off, move outside the barrier and escape – leaving behind a nucleus that has been transformed into another element. Without tunnelling, this type of nuclear decay could not occur.&lt;/p&gt;
    &lt;p&gt;Tunnelling is a quantum mechanical process, which entails that chance plays a role. Some types of atomic nuclei have a tall, wide barrier, so it can take a long while for a piece of the nucleus to appear outside it, while other types decay more easily. If we only look at a single atom, we cannot predict when this will happen, but by watching the decay of a large number of nuclei of the same type, we can measure an expected time before tunnelling occurs. The most common way of describing this is through the concept of half-life, which is how long it takes for half the nuclei in a sample to decay.&lt;/p&gt;
    &lt;p&gt;Physicists were quick to wonder whether it would be possible to investigate a type of tunnelling that involves more than one particle at a time. One approach to new types of experiments originated in a phenomenon that arises when some materials get extremely cold.&lt;/p&gt;
    &lt;p&gt;In an ordinary conductive material, current flows because there are electrons that are free to move through the entire material. In some materials, the individual electrons that push their way through the conductor may become organised, forming a synchronised dance that flows without any resistance. The material has become a superconductor and the electrons are joined together as pairs. These are called Cooper pairs, after Leon Cooper who, along with John Bardeen and Robert Schrieffer, provided a detailed description of how superconductors work (Nobel Prize in Physics 1972).&lt;/p&gt;
    &lt;p&gt;Cooper pairs behave completely differently to ordinary electrons. Electrons have a great deal of integrity and like to stay at a distance from each other – two electrons cannot be in the same place if they have the same properties. We can see this in an atom, for example, where the electrons divide themselves into different energy levels, called shells. However, when the electrons in a superconductor join up as pairs, they lose a bit of their individuality; while two separate electrons are always distinct, two Cooper pairs can be exactly the same. This means the Cooper pairs in a superconductor can be described as a single unit, one quantum mechanical system. In the language of quantum mechanics, they are then described as a single wave function. This wave function describes the probability of observing the system in a given state and with given properties.&lt;/p&gt;
    &lt;p&gt;If two superconductors are joined together with a thin insulating barrier between them, it creates a Josephson junction. This component is named after Brian Josephson, who performed quantum mechanical calculations for the junction. He discovered that interesting phenomena arise when the wave functions on each side of the junction are considered (Nobel Prize in Physics 1973). The Josephson junction rapidly found areas of application, including in precise measurements of fundamental physical constants and magnetic fields.&lt;/p&gt;
    &lt;p&gt;The construction also provided tools for exploring the fundamentals of quantum physics in a new way. One person who did so was Anthony Leggett (Nobel Prize in Physics 2003), whose theoretical work on macroscopic quantum tunnelling at a Josephson junction inspired new types of experiments.&lt;/p&gt;
    &lt;head rend="h3"&gt;The research group starts its work&lt;/head&gt;
    &lt;p&gt;These subjects were a perfect match for John Clarke’s research interests. He was a professor at the University of California, Berkeley, in the US, where he had moved after completing his doctoral degree at the University of Cambridge, UK, in 1968. At UC Berkeley he built up his research group and specialised in exploring a range of phenomena using superconductors and the Josephson junction.&lt;/p&gt;
    &lt;p&gt;By the mid-1980s, Michel Devoret had joined John Clarke’s research group as a postdoc, after receiving his doctorate in Paris. This group also included the doctoral student John Martinis. Together, they took on the challenge of demonstrating macroscopic quantum tunnelling. Vast amounts of care and precision were necessary to screen the experimental setup from all the interference that could affect it. They succeeded in refining and measuring all the properties of their electrical circuit, allowing them to understand it in detail.&lt;/p&gt;
    &lt;p&gt;To measure the quantum phenomena, they fed a weak current into the Josephson junction and measured the voltage, which is related to the electrical resistance in the circuit. The voltage over the Josephson junction was initially zero, as expected. This is because the wave function for the system is enclosed in a state that does not allow a voltage to arise. Then they studied how long it took for the system to tunnel out of this state, causing a voltage. Because quantum mechanics entails an element of chance, they took numerous measurements and plotted their results as graphs, from which they could read the duration of the zero-voltage state. This is similar to how measurements of the half-lives of atomic nuclei are based on statistics of numerous instances of decay.&lt;/p&gt;
    &lt;p&gt;The tunnelling demonstrates how the experimental setup’s Cooper pairs, in their synchronised dance, behave like a single giant particle. The researchers obtained further confirmation of this when they saw that the system had quantised energy levels. Quantum mechanics was named after the observation that the energy in microscopic processes is divided into separate packages, quanta. The laureates introduced microwaves of varying wavelengths into the zero-voltage state. Some of these were absorbed, and the system then moved to a higher energy level. This showed that the zero-voltage state had a shorter duration when the system contained more energy – which is exactly what quantum mechanics predicts. A microscopic particle shut behind a barrier functions in the same way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical and theoretical benefit&lt;/head&gt;
    &lt;p&gt;This experiment has consequences for the understanding of quantum mechanics. Other types of quantum mechanical effects that are demonstrated on the macroscopic scale are composed of many tiny individual pieces and their separate quantum properties. The microscopic components are then combined to cause macroscopic phenomena such as lasers, superconductors and superfluid liquids. However, this experiment instead created a macroscopic effect – a measurable voltage – from a state that is in itself macroscopic, in the form of a common wave function for vast numbers of particles.&lt;/p&gt;
    &lt;p&gt;Theorists like Anthony Leggett have compared the laureates’ macroscopic quantum system with Erwin Schrödinger’s famous thought experiment featuring a cat in a box, where the cat would be both alive and dead if we did not look inside. (Erwin Schrödinger received the Nobel Prize in Physics 1933.) The intention of his thought experiment was to show the absurdity of this situation, because the special properties of quantum mechanics are often erased at a macroscopic scale. The quantum properties of an entire cat cannot be demonstrated in a laboratory experiment.&lt;/p&gt;
    &lt;p&gt;However, Legget has argued that the series of experiments conducted by John Clarke, Michel Devoret and John Martinis showed that there are phenomena that involve vast numbers of particles which together behave just as quantum mechanics predicts. The macroscopic system that consists of many Cooper pairs is still many orders of magnitude smaller than a kitten – but because the experiment measures the quantum mechanical properties that apply to the system as a whole, for a quantum physicist it is fairly similar to Schrödinger’s imaginary cat.&lt;/p&gt;
    &lt;p&gt;This type of macroscopic quantum state offers new potential for experiments using the phenomena that govern the microscopic world of particles. It can be regarded as a form of artificial atom on a large scale – an atom with cables and sockets that can be connected into new test set-ups or utilised in new quantum technology. For example, artificial atoms are used to simulate other quantum systems and aid in understanding them.&lt;/p&gt;
    &lt;p&gt;Another example is the quantum computer experiment subsequently performed by Martinis, in which he utilised exactly the energy quantisation that he and the other two laureates had demonstrated. He used a circuit with quantised states as information-bearing units – a quantum bit. The lowest energy state and the first step upward functioned as zero and one, respectively. Superconducting circuits are one of the techniques being explored in attempts to construct a future quantum computer.&lt;/p&gt;
    &lt;p&gt;This year’s laureates have thus contributed to both practical benefit in physics laboratories and to providing new information for the theoretical understanding of our physical world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading&lt;/head&gt;
    &lt;p&gt;Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, www.kva.se, and at www.nobelprize.org, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at www.nobelprizemuseum.se.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Physics 2025 to&lt;/head&gt;
    &lt;p&gt;JOHN CLARKE&lt;lb/&gt;Born 1942 in Cambridge, UK. PhD 1968 from University of Cambridge, UK. Professor at University of California, Berkeley, USA.&lt;/p&gt;
    &lt;p&gt;MICHEL H. DEVORET&lt;lb/&gt;Born 1953 in Paris, France. PhD 1982 from Paris-Sud University, France. Professor at Yale University, New Haven, CT and University of California, Santa Barbara, USA.&lt;/p&gt;
    &lt;p&gt;JOHN M. MARTINIS&lt;lb/&gt;Born 1958. PhD 1987 from University of Californa, Berkeley, USA. Professor at University of California, Santa Barbara, USA.&lt;/p&gt;
    &lt;p&gt;“for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”&lt;/p&gt;
    &lt;p&gt;Science Editors: Ulf Danielsson, Göran Johansson and Eva Lindroth, the Nobel Committee for Physics&lt;lb/&gt;Text: Anna Davour&lt;lb/&gt;Translation: Clare Barnes&lt;lb/&gt;Illustrations: Johan Jarnestad&lt;lb/&gt;Editor: Sara Gustavsson&lt;lb/&gt;© The Royal Swedish Academy of Sciences&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/physics/2025/popular-information/"/><published>2025-10-07T09:50:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45501279</id><title>Like Vercel, but open source and for all language</title><updated>2025-10-07T10:40:09.125255+00:00</updated><content>&lt;doc fingerprint="c1875194e4671d1"&gt;
  &lt;main&gt;
    &lt;p&gt;An open-source and self-hostable alternative to Vercel, Render, Netlify and the likes. It allows you to build and deploy any app (Python, Node.js, PHP, ...) with zero-downtime updates, real-time logs, team management, customizable environments and domains, etc.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Git-based deployments: Push to deploy from GitHub with zero-downtime rollouts and instant rollback.&lt;/item&gt;
      &lt;item&gt;Multi-language support: Python, Node.js, PHP... basically anything that can run on Docker.&lt;/item&gt;
      &lt;item&gt;Environment management: Multiple environments with branch mapping and encrypted environment variables.&lt;/item&gt;
      &lt;item&gt;Real-time monitoring: Live and searchable build and runtime logs.&lt;/item&gt;
      &lt;item&gt;Team collaboration: Role-based access control with team invitations and permissions.&lt;/item&gt;
      &lt;item&gt;Custom domains: Support for custom domain and automatic Let's Encrypt SSL certificates.&lt;/item&gt;
      &lt;item&gt;Self-hosted and open source: Run on your own servers, MIT licensed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User documentation: devpu.sh/docs&lt;/item&gt;
      &lt;item&gt;Technical documentation: ARCHITECTURE&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Supported on Ubuntu/Debian. Other distros may work but aren't officially supported (yet).&lt;/quote&gt;
    &lt;p&gt;Log in your server, run the following command and follow instructions:&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh | sudo bash&lt;/code&gt;
    &lt;p&gt;You user must have sudo privileges.&lt;/p&gt;
    &lt;p&gt;You will need a fresh Ubuntu/Debian server you can SSH into with sudo privileges. We recommend a CPX31 from Hetzner.&lt;/p&gt;
    &lt;p&gt;You can use the provisioning script to get a server up and running:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sign in or sign up for a Hetzner account: Hetzner Cloud Console&lt;/item&gt;
      &lt;item&gt;Generate an API token: Creating an API token&lt;/item&gt;
      &lt;item&gt;Provision a server (requires &lt;code&gt;--token&lt;/code&gt;; optional:&lt;code&gt;--user&lt;/code&gt;,&lt;code&gt;--name&lt;/code&gt;,&lt;code&gt;--region&lt;/code&gt;,&lt;code&gt;--type&lt;/code&gt;):Tip: run&lt;quote&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh | bash -s -- --token &amp;lt;hetzner_api_key&amp;gt; [--user &amp;lt;login_user&amp;gt;] [--name &amp;lt;hostname&amp;gt;] [--region &amp;lt;fsn1|nbg1|hel1|ash|hil|sin&amp;gt;] [--type &amp;lt;cpx11|cpx21|cpx31|cpx41|cpx51&amp;gt;]&lt;/quote&gt;&lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh | bash -s -- --help&lt;/code&gt;to list regions and types (with specs). Defaults: region&lt;code&gt;hil&lt;/code&gt;, type&lt;code&gt;cpx31&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Configure DNS Records: Go to your DNS provider and create two A records pointing at the server IP for &lt;code&gt;APP_HOSTNAME&lt;/code&gt;(e.g.&lt;code&gt;app.devpu.sh&lt;/code&gt;) and a wildcard on subdomains of&lt;code&gt;DEPLOY_DOMAIN&lt;/code&gt;(e.g.&lt;code&gt;*.devpush.app&lt;/code&gt;). If you're using Cloudflare, set SSL/TLS to "Full (strict)" and keep the records proxied.&lt;/item&gt;
      &lt;item&gt;SSH into your new server: The provision script will have created a user for you. &lt;quote&gt;ssh &amp;lt;login_user&amp;gt;@&amp;lt;server_ip&amp;gt;&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Run hardening for system and SSH:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/harden.sh | sudo bash -s -- --ssh&lt;/code&gt;
    &lt;p&gt;Even if you already have a server, we recommend you harden security (ufw, fail2ban, disabled root SSH, etc). You can do that using &lt;code&gt;scripts/prod/harden.sh&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SSH into the server: &lt;quote&gt;ssh &amp;lt;login_user&amp;gt;@&amp;lt;server_ip&amp;gt;&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Install /dev/push: &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh | sudo bash&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Switch to &lt;code&gt;devpush&lt;/code&gt;user:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo -iu devpush&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Edit &lt;code&gt;.env&lt;/code&gt;:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cd devpush &amp;amp;&amp;amp; vi .env&lt;/code&gt;
    &lt;p&gt;Tip: you will need to fill in at least the following: &lt;code&gt;LE_EMAIL&lt;/code&gt;, &lt;code&gt;APP_HOSTNAME&lt;/code&gt;, &lt;code&gt;DEPLOY_DOMAIN&lt;/code&gt;, &lt;code&gt;EMAIL_SENDER_ADDRESS&lt;/code&gt;, &lt;code&gt;RESEND_API_KEY&lt;/code&gt; and your GitHub app settings (see [environment-variables] for details). &lt;code&gt;SERVER_IP&lt;/code&gt;, &lt;code&gt;SECRET_KEY&lt;/code&gt;, &lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;, &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt; should be pre-filled. You can ignore all commented out environment variables.
5. Start services:&lt;/p&gt;
    &lt;code&gt;scripts/prod/start.sh --migrate&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Visit your URL: &lt;code&gt;https://&amp;lt;APP_HOSTNAME&amp;gt;&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The follwing commands must be run as &lt;code&gt;devpush&lt;/code&gt; user (&lt;code&gt;su - devpush&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;In most cases, you can run an update with:&lt;/p&gt;
    &lt;code&gt;scripts/prod/update.sh --all&lt;/code&gt;
    &lt;p&gt;Alternatively, you can force a full upgrade (with downtime) using:&lt;/p&gt;
    &lt;code&gt;scripts/prod/update.sh --full -y&lt;/code&gt;
    &lt;p&gt;You can update specific components:&lt;/p&gt;
    &lt;code&gt;scripts/prod/update.sh --components &amp;lt;component_name&amp;gt;&lt;/code&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Development scripts target macOS for now.&lt;/quote&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Colima and the Loki Docker plugin: &lt;quote&gt;scripts/dev/install.sh&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Set up environment variables: &lt;quote&gt;cp .env.dev.example .env&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Start the stack (streams logs): &lt;quote&gt;scripts/dev/start.sh&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add &lt;code&gt;--prune&lt;/code&gt;to prune dangling images before build&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;--cache&lt;/code&gt;to use the build cache (default is no cache)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Add &lt;/item&gt;
      &lt;item&gt;Initialize your database once containers are up: &lt;quote&gt;scripts/dev/db-migrate.sh&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the scripts section for more dev utilities.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The app is mounted inside containers, so code changes reflect immediately. Some SSE endpoints may require closing browser tabs to trigger a reload.&lt;/item&gt;
      &lt;item&gt;The workers require a restart: &lt;quote&gt;docker-compose restart worker-arq&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;To apply migrations: &lt;quote&gt;scripts/dev/db-migrate.sh&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Area&lt;/cell&gt;
        &lt;cell role="head"&gt;Script&lt;/cell&gt;
        &lt;cell role="head"&gt;What it does&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/install.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Setup Colima and install Loki Docker plugin&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/start.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start stack with logs (foreground); supports &lt;code&gt;--prune&lt;/code&gt;, &lt;code&gt;--cache&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/build-runners.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Build runner images (default no cache; &lt;code&gt;--cache&lt;/code&gt; to enable)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/db-generate.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Generate Alembic migration (prompts for message)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/db-migrate.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Apply Alembic migrations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/db-reset.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Drop and recreate &lt;code&gt;public&lt;/code&gt; schema in DB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/clean.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop stack and clean dev data (&lt;code&gt;--hard&lt;/code&gt; for global)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/provision-hetzner.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Provision a Hetzner server (API token, regions from API, fixed sizes)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/install.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server setup: Docker, Loki plugin, user, clone repo, create &lt;code&gt;.env&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/harden.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;System hardening (UFW, fail2ban, unattended-upgrades); add &lt;code&gt;--ssh&lt;/code&gt; to harden SSH&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/start.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start services; optional &lt;code&gt;--migrate&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/stop.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop services (&lt;code&gt;--down&lt;/code&gt; for hard stop)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/restart.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Restart services; optional &lt;code&gt;--migrate&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Update by tag; &lt;code&gt;--all&lt;/code&gt; (app+workers), &lt;code&gt;--full&lt;/code&gt; (downtime), or &lt;code&gt;--components&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/db-migrate.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Apply DB migrations in production&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/check-env.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validate required keys exist in &lt;code&gt;.env&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update/app.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Blue‑green update for app&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update/worker-arq.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Drain‑aware blue‑green update for &lt;code&gt;worker-arq&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update/worker-monitor.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Blue‑green update for &lt;code&gt;worker-monitor&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Comments&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_NAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;App name.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/dev/push&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_DESCRIPTION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;App description.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Deploy your Python app without touching a server.&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;URL_SCHEME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;http&lt;/code&gt; (development) or &lt;code&gt;https&lt;/code&gt; (production).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;https&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;LE_EMAIL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Email used to register the Let's Encrypt (ACME) account in Traefik; receives certificate issuance/renewal/expiry notifications.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_HOSTNAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Domain for the app (e.g. &lt;code&gt;app.devpu.sh&lt;/code&gt;).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEPLOY_DOMAIN&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Domain used for deployments (e.g. &lt;code&gt;devpush.app&lt;/code&gt; if you want your deployments available at &lt;code&gt;*.devpush.app&lt;/code&gt;).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_HOSTNAME&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;SERVER_IP&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Public IP of the server&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;SECRET_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;App secret for sessions/CSRF. Generate: &lt;code&gt;openssl rand -hex 32&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fernet key (urlsafe base64, 32 bytes). Generate: `openssl rand -base64 32&lt;/cell&gt;
        &lt;cell&gt;tr '+/' '-_'&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;EMAIL_LOGO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;URL for email logo image. Only helpful for testing, as the app will use &lt;code&gt;app/logo-email.png&lt;/code&gt; if left empty.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;EMAIL_SENDER_NAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Name displayed as email sender for invites/login.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;EMAIL_SENDER_ADDRESS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Email sender used for invites/login.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;RESEND_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;API key for Resend.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub App ID.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_NAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub App name.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_PRIVATE_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub App private key (PEM format).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_WEBHOOK_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub webhook secret for verifying webhook payloads.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_CLIENT_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub OAuth app client ID.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_CLIENT_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub OAuth app client secret.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GOOGLE_CLIENT_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Google OAuth client ID.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GOOGLE_CLIENT_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Google OAuth client secret.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;POSTGRES_DB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;PostgreSQL database name.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;devpush&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;POSTGRES_USER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;PostgreSQL username.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;devpush-app&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;PostgreSQL password. Generate: `openssl rand -base64 24&lt;/cell&gt;
        &lt;cell&gt;tr -d '\n'`&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;REDIS_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Redis connection URL.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;redis://redis:6379&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DOCKER_HOST&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Docker daemon host address.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;tcp://docker-proxy:2375&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;UPLOAD_DIR&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Directory for file uploads.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/app/upload&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TRAEFIK_CONFIG_DIR&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Traefik configuration directory.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/data/traefik&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEFAULT_CPU_QUOTA&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default CPU quota for containers (microseconds).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100000&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEFAULT_MEMORY_MB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default memory limit for containers (MB).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;4096&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;JOB_TIMEOUT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Job timeout in seconds.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;320&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;JOB_COMPLETION_WAIT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Job completion wait time in seconds.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;300&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEPLOYMENT_TIMEOUT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Deployment timeout in seconds.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;300&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;LOG_LEVEL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Logging level.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WARNING&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DB_ECHO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable SQL query logging.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENV&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Environment (development/production).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;development&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ACCESS_DENIED_MESSAGE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Message shown to users who are denied access based on sign-in access control.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Sign-in not allowed for this email.&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ACCESS_DENIED_WEBHOOK&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Optional webhook to receive denied events (read more about Sign-in access control).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;LOGIN_HEADER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTML snippet displayed above the login form.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;TOASTER_HEADER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTML snippet displayed at the top of the toaster (useful to display a permanent toast on all pages).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;You will need to configure a GitHub App with the following settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identifying and authorizing users: &lt;list rend="ul"&gt;&lt;item&gt;Callback URL: add two callback URLs with your domain:&lt;/item&gt;&lt;item&gt;Expire user authorization tokens: No&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Post installation: &lt;list rend="ul"&gt;&lt;item&gt;Setup URL: https://example.com/api/github/install/callback&lt;/item&gt;&lt;item&gt;Redirect on update: Yes&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Webhook: &lt;list rend="ul"&gt;&lt;item&gt;Active: Yes&lt;/item&gt;&lt;item&gt;Webhook URL: https://example.com/api/github/webhook&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Permissions: &lt;list rend="ul"&gt;&lt;item&gt;Repository permissions &lt;list rend="ul"&gt;&lt;item&gt;Administration: Read and write&lt;/item&gt;&lt;item&gt;Checks: Read and write&lt;/item&gt;&lt;item&gt;Commit statuses: Read and write&lt;/item&gt;&lt;item&gt;Contents: Read and write&lt;/item&gt;&lt;item&gt;Deployments: Read and write&lt;/item&gt;&lt;item&gt;Issues: Read and write&lt;/item&gt;&lt;item&gt;Metadata: Read-only&lt;/item&gt;&lt;item&gt;Pull requests: Read and write&lt;/item&gt;&lt;item&gt;Webhook: Read and write&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Account permissions: &lt;list rend="ul"&gt;&lt;item&gt;Email addresses: Read-only&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Repository permissions &lt;/item&gt;
      &lt;item&gt;Subscribe to events: &lt;list rend="ul"&gt;&lt;item&gt;Installation target&lt;/item&gt;&lt;item&gt;Push&lt;/item&gt;&lt;item&gt;Repository&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Provide an access rules file to restrict who can sign up/sign in.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Development: edit &lt;code&gt;./access.json&lt;/code&gt;. If missing, running&lt;code&gt;scripts/dev/start.sh&lt;/code&gt;will sed an allow‑all file.&lt;/item&gt;
      &lt;item&gt;Production: edit &lt;code&gt;/srv/devpush/access.json&lt;/code&gt;on the server.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rules format (any/all may be used):&lt;/p&gt;
    &lt;code&gt;{
  "emails": ["alice@example.com"],
  "domains": ["example.com"],
  "globs": ["*@corp.local", "*.dept.example.com"],
  "regex": ["^[^@]+@(eng|research)\\.example\\.com$"]
}&lt;/code&gt;
    &lt;p&gt;Globs use shell-style wildcards; regex are Python patterns. If the file is missing or empty, all valid emails are allowed.&lt;/p&gt;
    &lt;p&gt;Additionally, if you set the &lt;code&gt;ACCESS_DENIED_WEBHOOK&lt;/code&gt; environment variable, denied sign-in attempts will be posted to the provided URL with the following payload:&lt;/p&gt;
    &lt;code&gt;{
  "email": "user@example.com",
  "provider": "google",
  "ip": "203.0.113.10",
  "user_agent": "Mozilla/5.0"
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/hunvreus/devpush"/><published>2025-10-07T10:07:50+00:00</published></entry></feed>