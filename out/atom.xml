<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-09T15:26:53.339040+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45516000</id><title>We found a bug in Go's ARM64 compiler</title><updated>2025-10-09T15:26:59.658742+00:00</updated><content>&lt;doc fingerprint="3b06c011ce263a54"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Every second, 84 million HTTP requests are hitting Cloudflare across our fleet of data centers in 330 cities. It means that even the rarest of bugs can show up frequently. In fact, it was our scale that recently led us to discover a bug in Go's arm64 compiler which causes a race condition in the generated code.&lt;/p&gt;
      &lt;p&gt;This post breaks down how we first encountered the bug, investigated it, and ultimately drove to the root cause.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Investigating a strange panic&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We run a service in our network which configures the kernel to handle traffic for some products like Magic Transit and Magic WAN. Our monitoring watches this closely, and it started to observe very sporadic panics on arm64 machines.&lt;/p&gt;
      &lt;p&gt;We first saw one with a fatal error stating that traceback did not unwind completely. That error suggests that invariants were violated when traversing the stack, likely because of stack corruption. After a brief investigation we decided that it was probably rare stack memory corruption. This was a largely idle control plane service where unplanned restarts have negligible impact, and so we felt that following up was not a priority unless it kept happening.&lt;/p&gt;
      &lt;p&gt;And then it kept happening.Â &lt;/p&gt;
      &lt;p&gt;When we first saw this bug we saw that the fatal errors correlated with recovered panics. These were caused by some old code which used panic/recover as error handling.Â &lt;/p&gt;
      &lt;p&gt;At this point, our theory was:Â &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;All of the fatal panics happen within stack unwinding.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We correlated an increased volume of recovered panics with these fatal panics.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Recovering a panic unwinds goroutine stacks to call deferred functions.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;A related Go issue (#73259) reported an arm64 stack unwinding crash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Letâs stop using panic/recover for error handling and wait out the upstream fix?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;So we did that and watched as fatal panics stopped occurring as the release rolled out. Fatal panics gone, our theoretical mitigation seemed to work, and this was no longer our problem. We subscribed to the upstream issue so we could update when it was resolved and put it out of our minds.&lt;/p&gt;
      &lt;p&gt;But, this turned out to be a much stranger bug than expected. Putting it out of our minds was premature as the same class of fatal panics came back at a much higher rate. A month later, we were seeing up to 30 daily fatal panics with no real discernible cause; while that might account for only one machine a day in less than 10% of our data centers, we found it concerning that we didnât understand the cause. The first thing we checked was the number of recovered panics, to match our previous pattern, but there were none. More interestingly, we could not correlate this increased rate of fatal panics with anything. A release? Infrastructure changes? The position of Mars? &lt;/p&gt;
      &lt;p&gt;At this point we felt like we needed to dive deeper to better understand the root cause. Pattern matching and hoping was clearly insufficient.Â &lt;/p&gt;
      &lt;p&gt;We saw two classes of this bug -- a crash while accessing invalid memory and an explicitly checked fatal error.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 153 gp=0x4000105340 m=324 mp=0x400639ea08 [GC worker (active)]:
/usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7ff97fffe870 sp=0x7ff97fffe860 pc=0x55558d4098fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1508 +0x68 fp=0x7ff97fffe860 sp=0x7ff97fffe810 pc=0x55558d3a9408
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1102
runtime.gcDrainMarkWorkerIdle(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7ff97fffe810 sp=0x7ff97fffe7a0 pc=0x55558d3ad514
runtime.gcDrain(0x400005bc50, 0x7)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7ff97fffe7a0 sp=0x7ff97fffe6f0 pc=0x55558d3ab248
runtime.markroot(0x400005bc50, 0x17e6, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7ff97fffe6f0 sp=0x7ff97fffe6a0 pc=0x55558d3ab578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7ff97fffe6a0 sp=0x7ff97fffe560 pc=0x55558d3acaa0
runtime.scanstack(0x4014494380, 0x400005bc50)
       /usr/local/go/src/runtime/traceback.go:447 +0x2ac fp=0x7ff97fffe560 sp=0x7ff97fffe4d0 pc=0x55558d3eeb7c
runtime.(*unwinder).next(0x7ff97fffe5b0?)
       /usr/local/go/src/runtime/traceback.go:566 +0x110 fp=0x7ff97fffe4d0 sp=0x7ff97fffe490 pc=0x55558d3eed40
runtime.(*unwinder).finishInternal(0x7ff97fffe4f8?)
       /usr/local/go/src/runtime/panic.go:1073 +0x38 fp=0x7ff97fffe490 sp=0x7ff97fffe460 pc=0x55558d403388
runtime.throw({0x55558de6aa27?, 0x7ff97fffe638?})
runtime stack:
fatal error: traceback did not unwind completely
       stack=[0x4015d6a000-0x4015d8a000
runtime: g8221077: frame.sp=0x4015d784c0 top=0x4015d89fd0&lt;/code&gt;
      &lt;/quote&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 187 gp=0x40003aea80 m=13 mp=0x40003ca008 [GC worker (active)]:
       /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7fff2afde870 sp=0x7fff2afde860 pc=0x55557e2d98fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1489 +0x94 fp=0x7fff2afde860 sp=0x7fff2afde810 pc=0x55557e279434
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1112
runtime.gcDrainMarkWorkerDedicated(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7fff2afde810 sp=0x7fff2afde7a0 pc=0x55557e27d514
runtime.gcDrain(0x4000059750, 0x3)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7fff2afde7a0 sp=0x7fff2afde6f0 pc=0x55557e27b248
runtime.markroot(0x4000059750, 0xb8, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7fff2afde6f0 sp=0x7fff2afde6a0 pc=0x55557e27b578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7fff2afde6a0 sp=0x7fff2afde560 pc=0x55557e27caa0
runtime.scanstack(0x40042cc000, 0x4000059750)
       /usr/local/go/src/runtime/traceback.go:458 +0x188 fp=0x7fff2afde560 sp=0x7fff2afde4d0 pc=0x55557e2bea58
runtime.(*unwinder).next(0x7fff2afde5b0)
goroutine 0 gp=0x40003af880 m=13 mp=0x40003ca008 [idle]:
PC=0x55557e2bea58 m=13 sigcode=1 addr=0x118
SIGSEGV: segmentation violation&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Now we could observe some clear patterns. Both errors occur when unwinding the stack in &lt;code&gt;(*unwinder).next&lt;/code&gt;. In one case we saw an intentional fatal error as the runtime identified that unwinding could not complete and the stack was in a bad state. In the other case there was a direct memory access error that happened while trying to unwind the stack. The segfault was discussed in the GitHub issue and a Go engineer identified it as dereference of a go scheduler struct, m, when unwinding.Â   &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;A review of Go scheduler structs&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Go uses a lightweight userspace scheduler to manage concurrency. Many goroutines are scheduled on a smaller number of kernel threads â this is often referred to as M:N scheduling. Any individual goroutine can be scheduled on any kernel thread. The scheduler has three core types â &lt;code&gt;g&lt;/code&gt;Â  (the goroutine), &lt;code&gt;m&lt;/code&gt; (the kernel thread, or âmachineâ), and &lt;code&gt;p&lt;/code&gt; (the physical execution context, orÂ  âprocessorâ). For a goroutine to be scheduled a free &lt;code&gt;m&lt;/code&gt; must acquire a free &lt;code&gt;p&lt;/code&gt;, which will execute a g. Each &lt;code&gt;g&lt;/code&gt; contains a field for its m if it is currently running, otherwise it will be nil. This is all the context needed for this post but the go runtime docs explore this more comprehensively.Â &lt;/p&gt;
      &lt;p&gt;At this point we can start to make inferences on whatâs happening: the program crashes because we try to unwind a goroutine stack which is invalid. In the first backtrace, if a return address is null, we call &lt;code&gt;finishInternal&lt;/code&gt; and abort because the stack was not fully unwound. The segmentation fault case in the second backtrace is a bit more interesting: if instead the return address is non-zero but not a function then the unwinder code assumes that the goroutine is currently running. It'll then dereference m and fault by accessing &lt;code&gt;m.incgo&lt;/code&gt; (the offset of &lt;code&gt;incgo&lt;/code&gt; into &lt;code&gt;struct m&lt;/code&gt; is 0x118, the faulting memory access). &lt;/p&gt;
      &lt;p&gt;What, then, is causing this corruption? The traces were difficult to get anything useful from â our service has hundreds if not thousands of active goroutines. It was fairly clear from the beginning that the panic was remote from the actual bug. The crashes were all observed while unwinding the stack and if this were an issue any time the stack was unwound on arm64 we would be seeing it in many more services. We felt pretty confident that the stack unwinding was happening correctly but on an invalid stack.Â &lt;/p&gt;
      &lt;p&gt;Our investigation stalled for a while at this point â making guesses, testing guesses, trying to infer if the panic rate went up or down, or if nothing changed. There was a known issue on Goâs GitHub issue tracker which matched our symptoms almost exactly, but what they discussed was mostly what we already knew. At some point when looking through the linked stack traces we realized that their crash referenced an old version of a library that we were also using â Go Netlink.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 1267 gp=0x4002a8ea80 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /usr/local/go/src/runtime/preempt.go:308 +0x3c fp=0x4004cec4c0 sp=0x4004cec4a0 pc=0x46353c
runtime.asyncPreempt()
        /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x4004cec6b0 sp=0x4004cec4c0 pc=0x4a6a8c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0x14360300000000?)
        /go/pkg/mod/github.com/!data!dog/[email protected]/nl/nl_linux.go:803 +0x130 fp=0x4004cfc710 sp=0x4004cec6c0 pc=0xf95de0
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;We spot-checked a few stack traces and confirmed the presence of this Netlink library. Querying our logs showed that not only did we share a library â every single segmentation fault we observed had happened while preempting &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt;.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Whatâs (async) preemption?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;In the prehistoric era of Go (&amp;lt;=1.13) the runtime was cooperatively scheduled. A goroutine would run until it decided it was ready to yield to the scheduler â usually due to explicit calls to &lt;code&gt;runtime.Gosched()&lt;/code&gt; or injected yield points at function calls/IO operations. Since Go 1.14 the runtime instead does async preemption. The Go runtime has a thread &lt;code&gt;sysmon&lt;/code&gt; which tracks the runtime of goroutines and will preempt any that run for longer than 10ms (at time of writing). It does this by sending &lt;code&gt;SIGURG&lt;/code&gt; to the OS thread and in the signal handler will modify the program counter and stack to mimic a call to &lt;code&gt;asyncPreempt&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;At this point we had two broad theories:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go Netlink bug â likely due to &lt;code&gt;unsafe.Pointer&lt;/code&gt; usage which invoked undefined behavior but is only actually broken on arm64&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go runtime bug and we're only triggering it in &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt; for some reason&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;After finding the same bug publicly reported upstream, we were feeling confident this was caused by a Go runtime bug. However, upon seeing that both issues implicated the same function, we felt more skeptical â notably the Go Netlink library uses unsafe.Pointer so memory corruption was a plausible explanation even if we didn't understand why.&lt;/p&gt;
      &lt;p&gt;After an unsuccessful code audit we had hit a wall. The crashes were rare and remote from the root cause. Maybe these crashes were caused by a runtime bug, maybe they were caused by a Go Netlink bug. It seemed clear that there was something wrong with this area of the code, but code auditing wasnât going anywhere. &lt;/p&gt;
      &lt;p&gt;At this point we had a fairly good understanding of what was crashing but very little understanding of why it was happening. It was clear that the root cause of the stack unwinder crashing was remote from the actual crash, and that it had to do with &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;, but why? We were able to capture a coredump of a production crash and view it in a debugger. The backtrace confirmed what we already knew â that there was a segmentation fault when unwinding a stack. The crux of the issue revealed itself when we looked at the goroutine which had been preempted while calling &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;.Â     &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;(dlv) bt
0  0x0000555577579dec in runtime.asyncPreempt2
   at /usr/local/go/src/runtime/preempt.go:306
1  0x00005555775bc94c in runtime.asyncPreempt
   at /usr/local/go/src/runtime/preempt_arm64.s:47
2  0x0000555577cb2880 in github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive
   at
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779
3  0x0000555577cb19a8 in github.com/vishvananda/netlink/nl.(*NetlinkRequest).Execute
   at 
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:532
4  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
5  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
...
(dlv) disass -a 0x555577cb2878 0x555577cb2888
TEXT github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(SB) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go
        nl_linux.go:779 0x555577cb2878  fdfb7fa9        LDP -8(RSP), (R29, R30)
        nl_linux.go:779 0x555577cb287c  ff430191        ADD $80, RSP, RSP
        nl_linux.go:779 0x555577cb2880  ff434091        ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
        nl_linux.go:779 0x555577cb2884  c0035fd6        RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The goroutine was paused between two opcodes in the function epilogue. Since the process of unwinding a stack relies on the stack frame being in a consistent state, it felt immediately suspicious that we preempted in the middle of adjusting the stack pointer. The goroutine had been paused at 0x555577cb2880, between&lt;code&gt; ADD $80, RSP, RSP and ADD $(16&amp;lt;&amp;lt;12), RSP, RSP&lt;/code&gt;.Â &lt;/p&gt;
      &lt;p&gt;We queried the service logs to confirm our theory. This wasnât isolated â the majority of stack traces showed that this same opcode was preempted. This was no longer a weird production crash we couldnât reproduce. A crash happened when the Go runtime preempted between these two stack pointer adjustments. We had our smoking gun.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Building a minimal reproducer&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;At this point we felt pretty confident that this was actually just a runtime bug and it should be reproducible in an isolated environment without any dependencies. The theory at this point was:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Stack unwinding is triggered by garbage collection&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption between a split stack pointer adjustment causes a crash&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;What if we make a function which splits the adjustment and then call it in a loop?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;quote&gt;
        &lt;code&gt;package main

import (
	"runtime"
)

//go:noinline
func big_stack(val int) int {
	var big_buffer = make([]byte, 1 &amp;lt;&amp;lt; 16)

	sum := 0
	// prevent the compiler from optimizing out the stack
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		big_buffer[i] = byte(val)
	}
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		sum ^= int(big_buffer[i])
	}
	return sum
}

func main() {
	go func() {
		for {
			runtime.GC()
		}
	}()
	for {
		_ = big_stack(1000)
	}
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This function ends up with a stack frame slightly larger than can be represented in 16 bits, and so on arm64 the Go compiler will split the stack pointer adjustment into two opcodes. If the runtime preempts between these opcodes then the stack unwinder will read an invalid stack pointer and crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; epilogue for main.big_stack
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
; preemption is problematic between these opcodes
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;After running this for a few minutes the program panicked as expected!&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;SIGSEGV: segmentation violation
PC=0x60598 m=8 sigcode=1 addr=0x118

goroutine 0 gp=0x400019c540 m=8 mp=0x4000198708 [idle]:
runtime.(*unwinder).next(0x400030fd10)
        /home/thea/sdk/go1.23.4/src/runtime/traceback.go:458 +0x188 fp=0x400030fcc0 sp=0x400030fc30 pc=0x60598
runtime.scanstack(0x40000021c0, 0x400002f750)
        /home/thea/sdk/go1.23.4/src/runtime/mgcmark.go:887 +0x290 

[...]

goroutine 1 gp=0x40000021c0 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /home/thea/sdk/go1.23.4/src/runtime/preempt.go:308 +0x3c fp=0x40003bfcf0 sp=0x40003bfcd0 pc=0x400cc
runtime.asyncPreempt()
        /home/thea/sdk/go1.23.4/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40003bfee0 sp=0x40003bfcf0 pc=0x75aec
main.big_stack(0x40003cff38?)
        /home/thea/dev/stack_corruption_reproducer/main.go:29 +0x94 fp=0x40003cff00 sp=0x40003bfef0 pc=0x77c04
Segmentation fault (core dumped)

real    1m29.165s
user    4m4.987s
sys     0m43.212s&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;A reproducible crash with standard library only? This felt like conclusive evidence that our problem was a runtime bug.&lt;/p&gt;
      &lt;p&gt;This was an extremely particular reproducer! Even now with a good understanding of the bug and its fix, some of the behavior is still puzzling. It's a one-instruction race condition, so itâs unsurprising that small changes could have large impact. For example, this reproducer was originally written and tested on Go 1.23.4, but did not crash when compiled with 1.23.9 (the version in production), even though we could objdump the binary and see the split ADD still present! We donât have a definite explanation for this behavior â even with the bug present there remain a few unknown variables which affect the likelihood of hitting the race condition.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;A single-instruction race condition window&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;arm64 is a fixed-length 4-byte instruction set architecture. This has a lot of implications on codegen but most relevant to this bug is the fact that immediate length is limited. &lt;code&gt;add&lt;/code&gt; gets a 12-bit immediate, &lt;code&gt;mov&lt;/code&gt; gets a 16-bit immediate, etc. How does the architecture handle this when the operands don't fit? It depends â &lt;code&gt;ADD&lt;/code&gt; in particular reserves a bit for "shift left by 12" so any 24 bit addition can be decomposed into two opcodes. Other instructions are decomposed similarly, or just require loading an immediate into a register first.Â &lt;/p&gt;
      &lt;p&gt;The very last step of the Go compiler before emitting machine code involves transforming the program into &lt;code&gt;obj.Prog&lt;/code&gt; structs. It's a very low level intermediate representation (IR) that mostly serves to be translated into machine code.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/fa2bb342d7b0024440d996c2d6d6778b7a5e0247/src/cmd/internal/obj/arm64/obj7.go#L856

// Pop stack frame.
// ADD $framesize, RSP, RSP
p = obj.Appendp(p, c.newprog)
p.As = AADD
p.From.Type = obj.TYPE_CONST
p.From.Offset = int64(c.autosize)
p.To.Type = obj.TYPE_REG
p.To.Reg = REGSP
p.Spadj = -c.autosize
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Notably, this IR is not aware of immediate length limitations. Instead, this happens in asm7.go when Go's internal intermediate representation is translated into arm64 machine code. The assembler will classify an immediate in conclass based on bit size and then use that when emitting instructions â extra if needed.&lt;/p&gt;
      &lt;p&gt;The Go assembler uses a combination of (&lt;code&gt;mov, add&lt;/code&gt;) opcodes for some adds that fit in 16-bit immediates, and prefers (&lt;code&gt;add, add + lsl 12&lt;/code&gt;) opcodes for 16-bit+ immediates.Â   &lt;/p&gt;
      &lt;p&gt;Compare a stack of (slightly larger than) &lt;code&gt;1&amp;lt;&amp;lt;15&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;15)
; 	return big_stack[0]
; }
MOVD $32776, R27
ADD R27, RSP, R29
MOVD $32784, R27
ADD R27, RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;With a stack of &lt;code&gt;1&amp;lt;&amp;lt;16&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;16)
; 	return big_stack[0]
; } 
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the larger stack case, there is a point between &lt;code&gt;ADD x, RSP, RSP&lt;/code&gt; opcodes where the stack pointer is not pointing to the tip of a stack frame. We thought at first that this was a matter of memory corruption â that in handling async preemption the runtime would push a function call on the stack and corrupt the middle of the stack. However, this goroutine is already in the function epilogue â any data we corrupt is actively in the process of being thrown away. What's the issue then?  &lt;/p&gt;
      &lt;p&gt;The Go runtime often needs to unwind the stack, which means walking backwards through the chain of function calls. For example: garbage collection uses it to find live references on the stack, panicking relies on it to evaluate &lt;code&gt;defer&lt;/code&gt; functions, and generating stack traces needs to print the call stack. For this to work the stack pointer must be accurate during unwinding because of how golang dereferences sp to determine the calling function. If the stack pointer is partially modified, the unwinder will look for the calling function in the middle of the stack. The underlying data is meaningless when interpreted as directions to a parent stack frame and then the runtime will likely crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/66536242fce34787230c42078a7bbd373ef8dcb0/src/runtime/traceback.go#L373

if innermost &amp;amp;&amp;amp; frame.sp &amp;lt; frame.fp || frame.lr == 0 {
    lrPtr = frame.sp
    frame.lr = *(*uintptr)(unsafe.Pointer(lrPtr))
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When async preemption happens it will push a function call onto the stack but the parent stack frame is no longer correct because sp was only partially adjusted when the preemption happened. The crash flow looks something like this: &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption happens between the two opcodes that &lt;code&gt;add x, rsp&lt;/code&gt; expands to&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Garbage collection triggers stack unwinding (to check for heap object liveness)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder starts traversing the stack of the problematic goroutine and correctly unwinds up to the problematic function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder dereferences &lt;code&gt;sp&lt;/code&gt; to determine the parent function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Almost certainly the data behind &lt;code&gt;sp&lt;/code&gt; is not a function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Crash&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;We saw earlier a faulting stack trace which ended in &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt; â in this case stack unwinding faulted while it was trying to determine the parent frame.Â    &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 90 gp=0x40042cc000 m=nil [preempted (scan)]:
runtime.asyncPreempt2()
/usr/local/go/src/runtime/preempt.go:306 +0x2c fp=0x40060a25d0 sp=0x40060a25b0 pc=0x55557e299dec
runtime.asyncPreempt()
/usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40060a27c0 sp=0x40060a25d0 pc=0x55557e2dc94c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0xff48ce6e060b2848?)
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 +0x130 fp=0x40060b2820 sp=0x40060a27d0 pc=0x55557e9d2880
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Once we discovered the root cause we reported it with a reproducer and the bug was quickly fixed. This bug is fixed in go1.23.12, go1.24.6, and go1.25.0. Previously, the go compiler emitted a single &lt;code&gt;add x, rsp&lt;/code&gt; instruction and relied on the assembler to split immediates into multiple opcodes as necessary. After this change, stacks larger than 1&amp;lt;&amp;lt;12 will build the offset in a temporary register and then add that to &lt;code&gt;rsp&lt;/code&gt; in a single, indivisible opcode. A goroutine can be preempted before or after the stack pointer modification, but never during. This means that the stack pointer is always valid and there is no race condition.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;LDP -8(RSP), (R29, R30)
MOVD $32, R27
MOVK $(1&amp;lt;&amp;lt;16), R27
ADD R27, RSP, RSP
RET&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This was a very fun problem to debug. We donât often see bugs where you can accurately blame the compiler. Debugging it took weeks and we had to learn about areas of the Go runtime that people donât usually need to think about. Itâs a nice example of a rare race condition, the sort of bug that can only really be quantified at a large scale.&lt;/p&gt;
      &lt;p&gt;Weâre always looking for people who enjoy this kind of detective work. Our engineering teams are hiring. &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/"/><published>2025-10-08T13:33:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517134</id><title>The RSS feed reader landscape</title><updated>2025-10-09T15:26:59.215541+00:00</updated><content>&lt;doc fingerprint="be149c54c0323cec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A deep dive into the rss feed reader landscape&lt;/head&gt;
    &lt;p&gt;RSS feeds and, in one form or another, feed readers, have existed for more than 20 years. Their main purpose is enabling their users to consume content from various sources in one place. And especially in recent years, also helping users deal with content overload.&lt;/p&gt;
    &lt;p&gt;Back then there were only a handful of relevant products. Today it's different, there are products for many different situations and use-cases. When first getting into RSS and feed readers, it can be difficult to find out which of this wide range of products are the right ones to use.&lt;/p&gt;
    &lt;p&gt;This article describes the landscape so you can find out which product fits best for your use-case.&lt;/p&gt;
    &lt;p&gt;Side-note: I'm using RSS as a synonym for all web feed standards (Atom, JSON Feed)&lt;/p&gt;
    &lt;head rend="h2"&gt;Classification&lt;/head&gt;
    &lt;p&gt;I attempted a classification of feed readers based on 2 axes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deployment model: local (phone or PC), browser extension, self-hosted, hosted&lt;/item&gt;
      &lt;item&gt;Business model: free, one-time payment, SAAS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The deployment model is based on where data is stored and feed fetching happens. Some products have a web app and mobile apps, but feed fetching happens on the server. In this case it's classified as &lt;code&gt;hosted&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The business model categorization is based on the cheapest option that gives access to the full feature set of the product. A self-hostable product with a hosted option is categorized into &lt;code&gt;free&lt;/code&gt;. A freemium SAAS product is categorized as &lt;code&gt;paid (SAAS)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And here the image in table format, for easily clickable links:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Pricing&lt;/cell&gt;
        &lt;cell role="head"&gt;On-device (phone or PC)&lt;/cell&gt;
        &lt;cell role="head"&gt;Browser extension&lt;/cell&gt;
        &lt;cell role="head"&gt;Self-hosted&lt;/cell&gt;
        &lt;cell role="head"&gt;Hosted&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Paid (one-time)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hosting models&lt;/head&gt;
    &lt;head rend="h3"&gt;Browser extension&lt;/head&gt;
    &lt;p&gt;Feed readers deployed as browser extensions can be installed through the respective stores of the browsers, usually either the Chrome Web Store or the Firefox Add-ons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup typically only requires installing the extension, not even an account is needed. There is no maintenance required beyond the occasional update, which usually happens automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally, with browser storage functionality (local storage or IndexedDB). How much data can be stored depends on the storage of the device. Browser extensions can only store as much data as the browser allows itself to use. But for most users this is easily enough.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device itself. Because the extension only runs if the browser runs, feeds are only fetched if the browser is open. This can lead to missed posts, depending on the publishing frequency of the feed and how often the browser is active.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Since all data is stored on the device, by default it's available only on the device where the extension is installed. If users enable it, the extension supports it, and the user is signed in, browsers can sync data to other devices that have the extension. Storing all data on the device also means that it is accessible offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Extensions can integrate deeply with the browser, and offer features like automatic feed finding of visited websites. Extensions can also provide a comprehensive feature set. Their only limitations are more compute-intensive features (e.g. requiring machine learning), or features that require special infrastructure to run (e.g. emails).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products (free)&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this category I only found one product. Smart-RSS was another one, but was discontinued in February.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-device&lt;/head&gt;
    &lt;p&gt;On-device products are separate applications and installed on the device you want to use them. Either on your iOS or Android phone or tablet, or on your Windows, Mac, or Linux computer. They fetch feeds and store data on that device.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: In general setup is done by installing the application. Some products may require an account, but that is not the norm. Maintenance is similar to browser extensions, the occasional updates. Some applications require manual update installations, others do that automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally on the device, which gives total control over the data. The maximum amount of feeds and articles stored only depend on the available storage of the device.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device. For that to happen the application must be running. Some products may implement a background fetching service, in that case only the device must be turned on. Similar to browser extensions, this limitation may lead to missed posts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Typically the data of on-device feed readers are only available on the device where it's installed. Data sync would need to be done manually or via operating system specific mechanisms (e.g. iCloud), which not all products support. Since data is stored on the device, it's also available offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On-device products can use the full computing power of the device. Combined with the comparatively small storage requirements of one user, it means that some features can be significantly faster than other categories. The exact features depend on the application, and mobile apps are typically less powerful than desktop apps. Limitations are only features that require multiple users (e.g. recommendations) or specific infrastructure (e.g. newsletter subscriptions).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Self-hosted&lt;/head&gt;
    &lt;p&gt;Self-hosted products all fall into the open-source and free category. They are designed to be installed on a server to run continuously, though it is possible to install them on a PC as well. They fetch feeds and store data on the server, and make it available through a web interface.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup requires a server, installing the application, and depending on how it should be accessible, possibly also domain and reverse proxy setup. This needs significantly more technical knowledge than the other options, but with ChatGPT (or others) it should be possible also for fairly non-technical people. This setup is generally more complex with more failure points than the other options, but with a correct setup failures happen rarely, if at all.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: The application stores data on the server it runs on. Since users control their server, they also have total control over the data stored on it. Applications typically use well-established databases, which allows users to inspect and change data with common tools. The amount of data that can be stored is only limited by the available storage on the server. Most servers start at 20 GB, which is enough for most feed reading use-cases. Often, storage can be dynamically extended if more space is needed.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the server. Since it runs continuously, there is no break in feed fetching, and even high frequency feeds are no problem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: The application and all its data is accessible from any device with a web browser by navigating to the server's URL. Data is stored on the server, therefore automatically synced between all devices that use it, but also require internet access.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On average self-hosted products have a wider feature set than browser extension or on-device feed readers. There is no theoretical limit on the feature set, but typically they keep the infrastructure as simple as possible, to keep setup and maintenance straightforward. This makes them slightly less powerful than hosted alternatives.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;p&gt;Self-hosted products are all open-source and free. The only costs are for the server, and the cheapest VPS plans start at ~2$/month.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosted&lt;/head&gt;
    &lt;p&gt;Hosted feed readers are managed services. It's required to create an account to get access to them. All of them are paid SAAS products, and most offer a free plan.&lt;/p&gt;
    &lt;p&gt;On average they have the most polished user experience and most comprehensive feature sets, since they're backed by companies that invest in continuous development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Beyond creating an account, no setup is required. The same for maintenance. Service providers make sure the products work as intended, and deal with everything required to keep the service running, including infrastructure setup, monitoring, backups, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Since data is stored on the servers and databases of the company running the product, users don't have direct control. But through laws like GDPR users have the right to export all their data, or request deletion. Storage is essentially unlimited, though most products have limits to avoid abuse. These limits are mentioned on their pricing page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Similar to self-hosted products, feeds are fetched on the server, which runs continuously and ensures that even high-frequency feeds don't pose a problem. The fetching interval is usually dynamic, based on the popularity of a feed and the publishing frequency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Hosted products are primarily available as web application, and some offer native apps as well. Since data is stored on the server, it's natively synced between devices. Some hosted feed readers also offer offline support.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Hosted feed readers serve many customers at the same time, which makes it necessary to have more complex infrastructure setups. This also enables features that other types of products cannot do, like email receiving, recommendations, or historic feed contents. Consequently hosted options are generally more powerful than other categories, though the specific feature set depends on the product.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All hosted products are SAAS products and charge monthly. &lt;code&gt;Folo&lt;/code&gt; is an outlier, they currently don't have any paid features, but the terms of service indicate that this will come in the future. At that point it will join the others in the &lt;code&gt;Paid (SAAS)&lt;/code&gt; category.&lt;/p&gt;
    &lt;head rend="h2"&gt;App support and offline access for products that don't offer it natively&lt;/head&gt;
    &lt;p&gt;Many of the self-hosted or hosted products don't provide apps or offline access by themselves. However, with the right setup, it's still possible to access the articles offline.&lt;/p&gt;
    &lt;p&gt;Most of these products provide APIs. This can be a proprietary API, or an API based on the old Google Reader API.&lt;/p&gt;
    &lt;p&gt;Mobile apps, for example ReadKit or Fiery Feeds, can not only subscribe to feeds, but also connect to other products through their APIs. They download contents, store them locally, and sync changes back to the connected products.&lt;/p&gt;
    &lt;p&gt;These apps make it possible to use a native mobile app for products that don't provide an app themselves, and get offline access at the same time.&lt;/p&gt;
    &lt;p&gt;FreshRSS, for example, has a list of native apps that support it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A note on newsletters&lt;/head&gt;
    &lt;p&gt;Newsletters are a growing mechanism for delivering (blog) content. Some, but not all, hosted feed readers support newsletters out of the box. But on-device products can't do that at all because of their infrastructure limitations.&lt;/p&gt;
    &lt;p&gt;Even if a feed reader doesn't support newsletters by itself, it's still possible to get newsletters into the feed reader, through services that convert newsletters into RSS feeds.&lt;/p&gt;
    &lt;p&gt;These services generate an email address and give you a corresponding feed URL. Emails to the generated address are added to the feed as new entry. So after signing up to the newsletter and adding the feed URL, the newsletter is added to the feed reader even without native email support.&lt;/p&gt;
    &lt;p&gt;Services that do this are Kill the Newsletter and the Lighthouse Newsletter to RSS tool. Both are free.&lt;/p&gt;
    &lt;head rend="h2"&gt;Products&lt;/head&gt;
    &lt;p&gt;The descriptions highlight the defining and unique aspects of the products, for the full feature list please go to their respective websites. Where available I used the screenshots for their websites, to represent the products as best as possible (test account screenshots wouldn't be as good).&lt;/p&gt;
    &lt;head rend="h3"&gt;NetNewsWire (on-device, free)&lt;/head&gt;
    &lt;p&gt;NetNewsWire is a free, on-device feed reader for Mac and iOS. By default it stores data on the device itself, but can sync via iCloud and using other products as storage. And it provides a Safari extension for easy feed-adding. Notably, it supports AppleScript, which makes it possible to automate certain workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fiery Feeds (on device, paid SAAS)&lt;/head&gt;
    &lt;p&gt;Fiery feeds is a Mac and iOS app. The download is free, and to get the premium features it costs ~15$/year (varies by region). By default it stores data on the device itself, but can sync via iCloud and using the API of other products (e.g. FreshRSS). The main distinguishing features are the customization options of the app, like custom themes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reeder (on-device, SAAS)&lt;/head&gt;
    &lt;p&gt;The current version of Reeder is a Mac and iOS app. The download is free, and to get the premium features it costs ~10$/year. The previous version of Reeder, now called Reeder Classic, is still available as one-time purchase. It also stores data on-device, and can sync via iCloud.&lt;/p&gt;
    &lt;p&gt;The main distinguishing feature is the unified timeline, which includes RSS, podcasts, social media, and more.&lt;/p&gt;
    &lt;head rend="h3"&gt;FreshRSS (self-hosted, free)&lt;/head&gt;
    &lt;p&gt;FreshRSS is a self-hosted feed reader and once set up, it's available as a web app. It is quite powerful, and in addition to normal feed subscriptions offers WebSub as well. It's possible to customize it with themes and extensions, and it's translated into more than 15 languages.&lt;/p&gt;
    &lt;p&gt;Together with Miniflux they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Miniflux&lt;/head&gt;
    &lt;p&gt;Miniflux is a self-hosted feed reader as well, and available as web app after setup. It's focus is on staying simple and fast instead of adding fancy features. It also offers a hosted version, which is 15$/year and has a 15 day trial period.&lt;/p&gt;
    &lt;p&gt;Together with FreshRSS they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Folo (hosted, free)&lt;/head&gt;
    &lt;p&gt;Folo is a relatively new product developed by the creators of RSS Hub. It's a free hosted feed reader, with apps available for every major platform. Their terms of service suggest that at some point they will charge a monthly fee for some premium features, but at the time of writing there were no paid features.&lt;/p&gt;
    &lt;p&gt;Folo is also open-source and therefore theoretically self-hostable, but I haven't found documentation for it.&lt;/p&gt;
    &lt;p&gt;It has a huge feature set, including newsletter support, transforming websites into feeds, AI summaries, and much more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedly (hosted, SAAS)&lt;/head&gt;
    &lt;p&gt;Feedly is the most widely-known product and has the most users of all feed readers. It has a comprehensive features set, and offers a free plan as well. For the past couple of years, it seems that Feedly has focused more on AI features and enterprise customers, but their core product remains solid.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inoreader&lt;/head&gt;
    &lt;p&gt;Inoreader is the second most widely-known product, after Feedly. It too offers a free plan. Their feature list is impressive, with social media support for subscriptions, automation and AI features, public API and integrations. And of course much more.&lt;/p&gt;
    &lt;p&gt;What stands out on Reddit are complaints about price hikes. Though Inoreader probably has tens or hundreds of thousands of users who don't have issues and think the product is great.&lt;/p&gt;
    &lt;head rend="h3"&gt;Readwise Reader&lt;/head&gt;
    &lt;p&gt;Readwise Reader is a relatively new product, from the creators of the original Readwise. It's a great feed reader, though were it really shines is the reading experience. They also have reading views for PDFs, eBooks, and more.&lt;/p&gt;
    &lt;p&gt;The website mentions that it's in beta, but it has been in beta for years now and at this point is a stable product, and has been for awhile.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tiny Tiny RSS&lt;/head&gt;
    &lt;p&gt;Tiny Tiny RSS deserves an honorable mention in this list. It was, and still is, used by many, and has been for a long time, and was often recommended on the RSS subreddit.&lt;/p&gt;
    &lt;p&gt;On October 3rd the maintainer announced that he's going to stop working on it, and will remove all infrastructure on November 1st. Forks of the project with other maintainers may pop up, but at the moment it's too soon to tell what the future of Tiny Tiny RSS will be.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lighthouse&lt;/head&gt;
    &lt;p&gt;Lighthouse is also a relatively new product. It's in beta, which refers to the fact that it doesn't yet have all features necessary to fulfill its vision, which goes beyond simple feed reading.&lt;/p&gt;
    &lt;p&gt;The main differentiator is that it focuses on articles over feeds, and has a separate view for curating articles (the inbox). It's focused on finding high-value content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Similar product categories&lt;/head&gt;
    &lt;p&gt;Feed readers are powerful products, which require manual setup to make them work well. Subscribing to feeds is mandatory, adding tags, filtered views, and rules can make them work even better. But for some use-cases, other product categories are simpler and might work better.&lt;/p&gt;
    &lt;head rend="h3"&gt;News aggregators&lt;/head&gt;
    &lt;p&gt;News aggregators automatically collect and curate news from a large variety of sources. They usually provide some customization options, but focus on news and don't allow arbitrary feed subscriptions like feed readers do.&lt;/p&gt;
    &lt;p&gt;They focus on providing an overview of the most relevant news stories.&lt;/p&gt;
    &lt;p&gt;Examples are Kagi News, Ground News, and SmartNews.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reading lists&lt;/head&gt;
    &lt;p&gt;Reading lists, also called read-it-later apps, are for saving and organizing links you found somewhere on the web. Many feed readers can do the same, but reading lists are optimized for that purpose.&lt;/p&gt;
    &lt;p&gt;Examples are Instapaper and Matter. Karakeep is a self-hosted option.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to choose&lt;/head&gt;
    &lt;p&gt;For most people, going with one of the hosted products is the best option. They're generally the most polished and most powerful products, owing to the fact that they have companies behind them with full-time engineers. They generally also offer a free plan, so if you stay within the limits of those, they will even be free to use.&lt;/p&gt;
    &lt;p&gt;For more specific requirements, products of the other categories can work better. They have different characteristics, and can work better in some situations. For example, if you want total control over your data, self-hosted options are the way to go.&lt;/p&gt;
    &lt;p&gt;It's probably easiest to first decide on the category, and then check out multiple products, or maybe even try them out. Virtually all products support OPML import and export, so moving feed subscriptions from one product to the next is almost zero effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lighthouseapp.io/blog/feed-reader-deep-dive"/><published>2025-10-08T15:17:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518813</id><title>WinBoat: Windows apps on Linux with seamless integration</title><updated>2025-10-09T15:26:59.051420+00:00</updated><content>&lt;doc fingerprint="b48fe95fd1b73cdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; Run Windows apps on 🐧 Linux&lt;lb/&gt;with ✨ seamless integration &lt;/head&gt;
    &lt;head rend="h2"&gt;FFFFF/Features/sssss&lt;/head&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;p&gt;Scroll for more!&lt;/p&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;head rend="h2"&gt;DDDD/Download/ddddd&lt;/head&gt;
    &lt;p&gt;We're excited to have you onboard! Pick your platform below to get started with WinBoat within minutes, not hours.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Contribute/eeeee&lt;/head&gt;
    &lt;p&gt;WinBoat is an open-source project licensed under MIT, and we welcome contributions from the community. Whether you're a developer, designer, or just someone who loves WinBoat, there are many ways you can help us improve and grow.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Community/yyyyy&lt;/head&gt;
    &lt;p&gt;We usually hang out on Discord, come join and chat with us!&lt;/p&gt;
    &lt;head rend="h2"&gt;FFFFF/Frequently Asked Questions/sssss&lt;/head&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;How does it compare to WinApps?&lt;/head&gt;
    &lt;p&gt;With WinApps you do the bulk of the setup manually, and there's no cohesive interface to bring it all together. There's a basic TUI, a taskbar widget, and some CLI commands for you to play with.&lt;lb/&gt; WinBoat does all the setup once you have the pre-requisites installed, displays everything worth seeing in a neat interface for you, and acts like a complete experience. No need to mess with configuration files, no need to memorize a dozen CLI commands, it just works.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;What are the advantages of using this over CrossOver or WINE?&lt;/head&gt;
    &lt;p&gt;You can run stuff that doesn't play well with CrossOver or WINE, and have a full Windows desktop at the same time.&lt;lb/&gt; We've had numerous apps that weren't working nicely (or at all) in Wine, this is one of the reasons we've created WinBoat. Some examples would be Affinity Photo, Paint Tool Sai v1.0, the entire Adobe suite, AeroChat, Acrobat, and of course Office.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will I be able to configure my peripherals / hardware using WinBoat?&lt;/head&gt;
    &lt;p&gt;If your peripheral / hardware uses USB to connect to your device. then yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature and you can use any Windows software needed for configuration, it should work out of the box.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there USB passthrough?&lt;/head&gt;
    &lt;p&gt; Yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature. Please give it a try and let us know what you think! 😄&lt;lb/&gt; If for whatever reason you're stuck with an older version of WinBoat, you can modify the docker-compose.yml file in ~/.winboat once you finished setting up WinBoat. You can add the appropriate USB devices like this, followed by executing docker-compose down and docker-compose up -d in the same folder. Please make sure to remove these changes before you upgrade to &amp;gt;=0.8.0 though, as they are incompatible with our implementation.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there GPU passthrough?&lt;/head&gt;
    &lt;p&gt;Not at the moment, but we plan on eventually implementing GPU acceleration through paravirtualized drivers.&lt;lb/&gt; We have looked at MVisor Win VGPU Driver for OpenGL, which seems promising from our tests, but it's for a different hypervisor (not compatible with QEMU). Some other folks are also working on DirectX drivers but nothing that we can try out yet.&lt;lb/&gt; We have also looked into Looking Glass extensively, specifically their Indirect Display Driver which does not need a second GPU, because it'd be absolutely amazing to have it. We got the driver to compile and start via some hacks, but couldn't get much more than a black screen. The developer says it is not ready for general use yet at all, however we plan to integrate it once it is ready.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Does it run games with anti-cheat that don't run on Linux?&lt;/head&gt;
    &lt;p&gt;Unfortunately running games with kernel anti-cheat is not possible, as they block virtualization.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Any possibility of adding Podman support as a Docker alternative?&lt;/head&gt;
    &lt;p&gt;Podman support is planned. We tried working on it, some contributors also tried working on it, but there's some issues with networking (specifically the guest server being unreachable) that prevent it from being functional for now.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will you make it into a Flatpak?&lt;/head&gt;
    &lt;p&gt;This is on our to-do list, but it'll take some effort because Flatpak is pretty isolated from the rest of the system and apps, so we'd have to find a way to expose installed apps, the Docker binary, and the Docker socket, and many other utilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.winboat.app/"/><published>2025-10-08T17:56:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45521738</id><title>Discord says 70k users may have had their government IDs leaked in breach</title><updated>2025-10-09T15:26:58.960180+00:00</updated><content>&lt;doc fingerprint="52821b91fd9720ef"&gt;
  &lt;main&gt;
    &lt;p&gt;Discord has identified approximately 70,000 users that may have had their government ID photos exposed as part of a customer service data breach announced last week, spokesperson Nu Wexler tells The Verge. A tweet by vx-underground said that the company was being extorted over a breach of its Zendesk instance by a group claiming to have “1.5TB of age verification related photos. 2,185,151 photos.”&lt;/p&gt;
    &lt;head rend="h1"&gt;Discord says 70,000 users may have had their government IDs leaked in breach&lt;/head&gt;
    &lt;p&gt;Discord claims that the attackers are circulating inaccurate information about the breach of a customer service provider as part of an extortion attempt.&lt;/p&gt;
    &lt;p&gt;Discord claims that the attackers are circulating inaccurate information about the breach of a customer service provider as part of an extortion attempt.&lt;/p&gt;
    &lt;p&gt;When we asked about the tweet, Wexler shared this statement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Following last week’s announcement about a security incident involving a third-party customer service provider, we want to address inaccurate claims by those responsible that are circulating online. First, as stated in our blog post, this was not a breach of Discord, but rather a third-party service we use to support our customer service efforts. Second, the numbers being shared are incorrect and part of an attempt to extort a payment from Discord. Of the accounts impacted globally, we have identified approximately 70,000 users that may have had government-ID photos exposed, which our vendor used to review age-related appeals. Third, we will not reward those responsible for their illegal actions.&lt;/p&gt;
      &lt;p&gt;All affected users globally have been contacted and we continue to work closely with law enforcement, data protection authorities, and external security experts. We’ve secured the affected systems and ended work with the compromised vendor. We take our responsibility to protect your personal data seriously and understand the concern this may cause.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In its announcement last week, Discord said that information like names, usernames, emails, the last four digits of credit cards, and IP addresses also may have been impacted by the breach.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/797051/discord-government-ids-leaked-data-breach"/><published>2025-10-08T23:20:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45522406</id><title>Designing a Low Latency 10G Ethernet Core (2023)</title><updated>2025-10-09T15:26:58.916619+00:00</updated><content>&lt;doc fingerprint="ed38fb1129f6f98f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Designing a Low Latency 10G Ethernet Core - Part 1 (Introduction)&lt;/head&gt;
    &lt;p&gt;Links to the other parts in this series:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Introduction (this post)&lt;/item&gt;
      &lt;item&gt;Design Overview and Verification&lt;/item&gt;
      &lt;item&gt;Low Latency Techniques&lt;/item&gt;
      &lt;item&gt;Performance Measurement and Comparison&lt;/item&gt;
      &lt;item&gt;Potential Improvements&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;This is the first in a series of blog posts describing my experience developing a low latency 10G Ethernet core for FPGA. I decided to do this as a personal project to develop expertise in low latency FPGA design and high-speed Ethernet, as well as to experiment with tools and techniques that I could use full-time. As a small spoiler, the design has less than 60ns loopback latency, which is comparable to commercial offerings.&lt;/p&gt;
    &lt;p&gt;These posts will focus on the things that are likely different to a ‘standard’ design, as I believe this will be more interesting to the reader. Specifically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The use of cocotb and pyuvm for verification&lt;/item&gt;
      &lt;item&gt;The techniques implemented to reduce packet processing latency&lt;/item&gt;
      &lt;item&gt;Analysis of commercially available low latency and ‘ultra’-low latency cores&lt;/item&gt;
      &lt;item&gt;Latency measurement results and comparison&lt;/item&gt;
      &lt;item&gt;Other techniques not implemented&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the reader is unfamiliar with Layer 1/2 Ethernet, I would recommend the following resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;10G Ethernet Layer 1 Overview&lt;/item&gt;
      &lt;item&gt;YouTube - The Big MAC Mystery&lt;/item&gt;
      &lt;item&gt;IEEE Standard for Ethernet - Full Ethernet (802.3) spec&lt;/item&gt;
      &lt;item&gt;64B/66B overview - Overview of 10G PCS from the spec above&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Next Post - Design Overview and Verification&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ttchisholm.github.io/ethernet/2023/05/01/designing-10g-eth-1.html"/><published>2025-10-09T01:17:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45523537</id><title>Two things LLM coding agents are still bad at</title><updated>2025-10-09T15:26:58.533580+00:00</updated><content>&lt;doc fingerprint="be40934db2d75e59"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Two things LLM coding agents are still bad at&lt;/head&gt;
    &lt;p&gt;I’ve been trying to slowly ease into using LLMs for coding help again lately (after quitting cold turkey), but something always feels off -- like we’re not quite on the same wavelength. Call it vibe coding or vibe engineering, but I think I’ve finally pinned down two big reasons why their approach to code feels so awkward.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;LLMs don’t copy-paste (or cut and paste) code. For instance, when you ask them to refactor a big file into smaller ones, they’ll "remember" a block or slice of code, use a &lt;code&gt;delete&lt;/code&gt;tool on the old file, and then a&lt;code&gt;write&lt;/code&gt;tool to spit out the extracted code from memory. There are no real&lt;code&gt;cut&lt;/code&gt;or&lt;code&gt;paste&lt;/code&gt;tools. Every tweak is just them emitting&lt;code&gt;write&lt;/code&gt;commands from memory. This feels weird because, as humans, we lean on copy-paste all the time. It’s how we know the code we moved is exactly the same as where we copied it from. I've only seen Codex go against the grain here, sometimes I'd see it issue&lt;code&gt;sed&lt;/code&gt;and&lt;code&gt;awk&lt;/code&gt;to try and replicate that copy-paste interaction, but it doesn't always work.&lt;/item&gt;
      &lt;item&gt;And it’s not just how they handle code movement -- their whole approach to problem-solving feels alien too. LLMs are terrible at asking questions. They just make a bunch of assumptions and brute-force something based on those guesses. Good human developers always pause to ask before making big changes or when they’re unsure (hence the mantra of "there are no bad questions"). But LLMs? They keep trying to make it work until they hit a wall -- and then they just keep banging their head against it. Sure, you can overengineer your prompt to try get them to ask more questions (Roo for example, does a decent job at this) -- but it's very likely they still won't. Maybe the companies building these LLMs do their RL based on making writing code "faster".&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These quirks are why I contest the idea that LLMs are replacing human devs -- they’re still more like weird, overconfident interns. I can’t fully vibe with them yet.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kix.dev/two-things-llm-coding-agents-are-still-bad-at/"/><published>2025-10-09T04:33:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45524293</id><title>The Unknotting Number Is Not Additive</title><updated>2025-10-09T15:26:58.427371+00:00</updated><content>&lt;doc fingerprint="2c790b511bb3d39a"&gt;
  &lt;main&gt;
    &lt;p&gt;On June 30, 2025, Mark Brittenham and Susan Hermiller uploaded a preprint to the arXiv called “Unknotting number is not additive under connected sum” (and an updated version on September 15, 2025). In it, they surprised the mathematical community by giving a counterexample to a long-standing conjecture in knot theory. The story was picked up by publications like Scientific American and Quanta and by math YouTuber Matt Parker.&lt;/p&gt;
    &lt;p&gt;The conjecture is easy to understand, although we need a few definitions first.&lt;/p&gt;
    &lt;p&gt;(Mathematical) knot: We can think of a mathematical knot as a loop of string sitting in three-dimensional space. In other words, if we took a piece of string, tied a knot, and then glued the two ends together, we’d get a mathematical knot.&lt;/p&gt;
    &lt;p&gt;Knot projection: Given any mathematical knot, we draw a two-dimensional version of it in the plane. It is like the shadow of the knot, but with breaks in the knot to indicate which strand is on top and which is on the bottom.&lt;/p&gt;
    &lt;p&gt;Unknotting number: If we have the projection of a knot, we can change some crossings (change which strand is over and which is under) to make it unknotted (called the unknot). To compute the unknotting number of a knot K, u(K), we look at all possible projections and find the fewest number of crossing changes we must make to obtain the unknot.&lt;/p&gt;
    &lt;p&gt;Connected sum: Given two knots, J and K, we can cut each knot at one point and join the cut ends to form a new, larger knot, J#K. This is called the connected sum of the knots.&lt;/p&gt;
    &lt;p&gt;Below, we see a knot called the (2,7) torus knot and its mirror image (left), and their connected sum on the right.&lt;/p&gt;
    &lt;p&gt;Although unknotting numbers are notoriously difficult to compute, we know that the unknotting number of a (p,q) torus knot is (p-1)(q-1)/2. So, the (2,7) torus knots above have unknotting number (2 – 1)(7 – 1)/2 = 3. It is not difficult to check that by changing three crossings of the projections shown above, the (2,7) torus knot becomes the unknot. It turns out that changing two crossings does not suffice in this projection or any projection.&lt;/p&gt;
    &lt;p&gt;Likewise, changing 3 + 3 = 6 crossings of the connected sum will yield the unknot. In fact, it will always be the case that u(J#K) ≤ u(J) + u(K). The question is: are these equal? An “old” conjecture (which was implicit in an article 88 years ago), states:&lt;/p&gt;
    &lt;p&gt;Conjecture: If J and K are knots, then u(J#K) = u(J) + u(K).&lt;/p&gt;
    &lt;p&gt;In their preprint, Brittenham and Hermiller disprove the conjecture by giving a counterexample! Moreover, the counterexample is precisely the one I’ve shown above! The connected sum of the torus knot with its mirror image has unknotting number 5, which is clearly less than 3 + 3.&lt;/p&gt;
    &lt;p&gt;That said, we can’t simply change the five crossings in the above projection to obtain the unknot. We must produce a different projection first. But what is it?&lt;/p&gt;
    &lt;p&gt;I looked for the answer online and found this arXiv preprint by Chao Wang and Yimu Zhang, which gives the details. They provide the projection and the crossings that must be changed. However, the projection has 56 crossings (far more than the original 14!). They assert, but do not show, that the resulting knot—after the five crossings are changed—is the unknot. They end by writing, “We prefer to leave it to the readers as an interesting game.”&lt;/p&gt;
    &lt;p&gt;Never good at resisting a good nerd sniping, I decided to take them up on the challenge. I’m embarrassed to admit how long it took me to confirm their work, but I did it. Here is my redrawn version of the knot projection—the connected sum of the (2,7) torus knot and its mirror image. The circled crossings are the five that must be changed.&lt;/p&gt;
    &lt;p&gt;After having done so, here’s the resulting projection. Wang and Zhang claim that it is the unknot!&lt;/p&gt;
    &lt;p&gt;Without further ado, here are my drawings. This first sequence shows how I get from the usual projection of the connected sum to the projection in which the crossings must be made. The red strands show the part of the projection that has changed from the previous projection.&lt;/p&gt;
    &lt;p&gt;Thus, the final image above is the knot we claim is the unknot. The following sequence of steps shows that it is indeed the unknot.&lt;/p&gt;
    &lt;p&gt;Ta da!!!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://divisbyzero.com/2025/10/08/the-unknotting-number-is-not-additive/"/><published>2025-10-09T06:39:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45524437</id><title>The Forecasting Company (YC S24) Is Hiring a Machine Learning Engineer</title><updated>2025-10-09T15:26:57.983894+00:00</updated><content>&lt;doc fingerprint="cf94bfdaef1ccb2f"&gt;
  &lt;main&gt;
    &lt;p&gt;Foundation models for time series&lt;/p&gt;
    &lt;p&gt;We are on a mission to create the forecasting foundation model to rule them all. Forecasting drives critical decisions worldwide - impacting staffing, supply chain management, finance and more. Our solution provides companies with the models, platform and APIs they need to easily generate the most accurate forecasts possible, helping to significantly reduce waste and enabling smarter, more confident decisions.&lt;/p&gt;
    &lt;p&gt;The forecasting model is at the heart of our technology. As the second founding MLE, you will build, train and deploy large foundation model architectures: implement and combine ideas from the literature, push the state of the art, and ultimately deploy your model for our customers to use in production. Our goal is for our models to be the best for our customers’ use cases - including for capabilities that do not exist yet in academic models.&lt;/p&gt;
    &lt;p&gt;You love your craft, have high standards, stay up-to-date with the latest ideas in ML, and know when to make trade-offs to ship. You live and breathe neural networks, and speak PyTorch or Jax. You are used to diving deep in large amounts of data, and you know what you train your models on. Bonus if you have experience building solid ML infrastructure.&lt;/p&gt;
    &lt;p&gt;You are passionate about your craft, maintain high standards, stay current with the latest tech and know when to make trade-offs to deliver results efficiently. We do not believe great engineers are “jack of all trades”, but rather that they excel at diving deep into complex topics quickly, leveraging a broad range of experiences to solve challenging problems. You are also open to exploring new concepts, technologies, and enjoy quickly throwing prototypes together to kick the tires. You prefer quick feedback loops, rather than aiming for perfection on the first try.&lt;/p&gt;
    &lt;p&gt;Our goal is to provide the most accurate and easy-to-use forecasts to our customers, by leveraging refined information from their own industry. Foundation models for time series are changing this entirely. With the current advances in data processing and model training, we can now pre-train models on diverse temporal data across industries. We provide value to our customers by enabling rapid interaction with our models when provided data and context in natural language, delivering real-time forecasts with accuracy reports. Our customers do not need to be data scientists or have a PhD in Machine Learning to build and ship an accurate forecasting system for their use-cases.&lt;/p&gt;
    &lt;p&gt;Example use cases include demand forecasting for large furniture chains, predicting sales for a restaurant group and revenue forecasting in the gaming industry.&lt;/p&gt;
    &lt;p&gt;The founders Geoff and Joachim are both Machine Learning PhDs who have built forecasting and ML systems from scratch at JP Morgan, Amazon, Google, Bloomberg, and Sonos in the US.&lt;/p&gt;
    &lt;p&gt;We are a global company that happens to be HQed in Paris. Get the best of both worlds — Silicon Valley work ethic and ambition in the center of Paris, right across from the historical Stock Exchange, in the Sentier.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/the-forecasting-company/jobs/cXJzAhA-founding-machine-learning-engineer"/><published>2025-10-09T07:01:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45524624</id><title>The React Foundation</title><updated>2025-10-09T15:26:57.865398+00:00</updated><content>&lt;doc fingerprint="ed2bf7695563fd5c"&gt;
  &lt;main&gt;
    &lt;p&gt;Meta open-sourced React over a decade ago to help developers build better user experiences. Since then, React has grown into one of the world’s most popular open source projects, powering over 50 million websites and products built by companies such as Microsoft, Shopify, Bloomberg, Discord, Coinbase, the NFL, and many others. With React Native, React has expanded to support platforms beyond the web, including mobile, tablets, desktops, TVs, gaming consoles, and even mixed reality devices.&lt;/p&gt;
    &lt;p&gt;This incredible growth is thanks to the thousands of educators, companies, and projects that have contributed to the development of React. The community is the heart of React, and we’re proud to play a part in the cycle of open source innovation throughout the ecosystem that benefits everyone. We’re pleased to give a seat at the table to the people and companies that have made React what it is today.&lt;/p&gt;
    &lt;p&gt;Today, we are excited to announce the next step for React. Several projects within the React ecosystem, including React and React Native, as well as supporting projects such as JSX, will transition to the React Foundation. The React Foundation’s mission is to help the React community and its members. The React Foundation will maintain React’s infrastructure, organize React Conf, and create initiatives to support the React ecosystem. The React Foundation will be part of the Linux Foundation, which has long fostered a vendor-neutral environment for open source projects.&lt;/p&gt;
    &lt;head rend="h2"&gt;Formalizing Governance&lt;/head&gt;
    &lt;p&gt;The React Foundation’s governing board will consist of representatives from Amazon, Callstack, Expo, Meta, Microsoft, Software Mansion, and Vercel, with the intention to expand further over time.&lt;/p&gt;
    &lt;p&gt;There will be a clear separation between the business and technical governance of React. Releases, features, and technical direction will be governed by a new structure driven by the maintainers and contributors of React. This new technical governance structure will be independent of the React Foundation. The React team is actively working on this new technical governance structure and will share more details in a future post on the React blog.&lt;/p&gt;
    &lt;head rend="h2"&gt;Meta and the React Foundation&lt;/head&gt;
    &lt;p&gt;Meta is committing to a five-year partnership with the React Foundation, including over $3 million in funding and dedicated engineering support. This investment will ensure React’s smooth transition to independent governance while maintaining the stability and innovation the community expects. Meta will continue to invest in React and use it as our primary tool for building UI on the web and across many of Meta’s apps. Meta will also continue to have a dedicated team of engineers working full-time on React and React Native.&lt;/p&gt;
    &lt;p&gt;We believe the best of React is yet to come. The React Foundation will unlock new opportunities for collaboration, innovation, and growth that will benefit the entire ecosystem. We’re excited to see what the community will build together under this new model. With strengthened governance, broader industry participation, and continued technical excellence, React is positioned to tackle the next generation of challenges in UI development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://engineering.fb.com/2025/10/07/open-source/introducing-the-react-foundation-the-new-home-for-react-react-native/"/><published>2025-10-09T07:30:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45525336</id><title>N8n raises $180M</title><updated>2025-10-09T15:26:57.686752+00:00</updated><content>&lt;doc fingerprint="bcc70051598c2d6a"&gt;
  &lt;main&gt;
    &lt;quote&gt;We just raised $180 million in Series C funding, bringing our total funding to $240 million and our valuation to $2.5 billion.&lt;lb/&gt;The round is led by Accel, with support from Meritech, Redpoint, Evantic and Visionaries Club. Corporate investors NVentures (NVIDIA’s venture capital arm) and T.Capital also join the round, with previous backers including Felicis Ventures, Sequoia, Highland Europe and HV Capital making follow-on investments as well&lt;/quote&gt;
    &lt;p&gt;This investment recognises something fundamental: the AI race isn't only about smarter models - it's about who can actually put that intelligence to work reliably, inside actual businesses.&lt;/p&gt;
    &lt;p&gt;The AI agent landscape has split into two camps. Some platforms put everything in the hands of AI, you write prompts and hope for the best, with the entire logic determined by the model's interpretation. Others require strict, rule-based routing which is powerful for engineers who code every pathway, but impractical for business users who need to iterate quickly.&lt;/p&gt;
    &lt;p&gt;We've learnt from our community that neither extreme serves businesses well. Pure autonomy creates magic when it works but proves too unpredictable for business-critical workflows. Pure rule-based routing offers predictability but demands more time and often developers for every change.&lt;/p&gt;
    &lt;p&gt;n8n was built for the reality in between: giving flexible control over where your agents sit on this spectrum. You choose the balance - how much autonomy to grant, how much logic to enforce, and crucially, how to adjust that balance as you learn what works.&lt;/p&gt;
    &lt;p&gt;But controlling this balance is only the foundation. Getting agents into production requires two more crucial elements:&lt;/p&gt;
    &lt;p&gt;Orchestration: Connecting agents to your actual tools and data sources, building in human oversight where needed, and establishing the monitoring and triggers that keep everything running&lt;/p&gt;
    &lt;p&gt;Coordination: Bringing together the people who understand the business need with the builders who can make it work - on the same platform, in real time&lt;/p&gt;
    &lt;p&gt;Without both, organisations get stuck in endless development cycles. Engineers build in isolation, business users test and provide feedback, iterations drag on. The agent never reaches production because the people closest to the work can't collaborate effectively with those building the solution.&lt;/p&gt;
    &lt;p&gt;The formula we've proven is straightforward: combine AI, code, and humans in the same process, on the same platform. Technical builders handle architecture whilst domain experts configure and refine. That's coordination, and it only succeeds when the orchestration layer is flexible enough to evolve with your needs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our principles&lt;/head&gt;
    &lt;p&gt;We've been building n8n since 2019, first as an automation tool, then as a platform for AI orchestration and cross-team collaboration. Now we're the platform our community and enterprises tell us finally helps them deploy AI in production.&lt;/p&gt;
    &lt;p&gt;We've built this alongside a fast-growing community contributing videos, templates, nodes, and more. A community we'll never stop caring about or restrict access to. Ever.&lt;/p&gt;
    &lt;p&gt;Flexibility will always be a top product priority. Flexibility to pick any model, connect any tool, and deploy anywhere: our cloud, your server, a Raspberry Pi, or bare metal. Flexibility in the product so it's easy enough to make a quick start but robust enough to handle orchestration's natural complexity.&lt;/p&gt;
    &lt;p&gt;From tinkerers automating lights at home to the United Nations running mission-critical workflows at scale, our ambition is clear: n8n becomes the default platform to build with AI. And more importantly, to deploy AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s next&lt;/head&gt;
    &lt;p&gt;We've made so much progress this year alone: 6x user growth, 10x revenue growth, and major new features like Evaluations, Data Tables, and many more improvements. Yet it still feels early.&lt;/p&gt;
    &lt;p&gt;The industry is moving fast, and so are we. This funding accelerates our roadmap: expanding our integrations, empowering the ecosystem to build their own nodes and share them globally, and evolving n8n beyond the canvas into new interfaces that match how different teams work. We're making the platform easier to start with whilst more powerful at scale - because that's what production AI demands. (We're hiring!)&lt;/p&gt;
    &lt;p&gt;Our community is already pushing n8n from a platform into an ecosystem. We're rapidly seeing people build their own businesses around n8n, and we want to support the community to take this further: with education, early access to features, commercial partnerships, and fun events to bring everyone together.&lt;/p&gt;
    &lt;p&gt;I started n8n to remove repetitive tasks and focus on what I actually enjoyed. Now I see a world where building with AI, leveraging agents to scale yourself, and becoming a 10x operator becomes table stakes, just as using Excel is. The first people who knew Excel were special, but now it's a requirement for many roles.&lt;/p&gt;
    &lt;p&gt;The same will happen with AI. And my ambition is that n8n becomes the default platform to build with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.n8n.io/series-c/"/><published>2025-10-09T09:19:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45526042</id><title>Zippers: Making Functional "Updates" Efficient (2010)</title><updated>2025-10-09T15:26:57.259057+00:00</updated><content>&lt;doc fingerprint="b6c3d03768b1d678"&gt;
  &lt;main&gt;
    &lt;p&gt; In the Haskell stuff, I was planning on moving on to some monad-related&lt;lb/&gt; stuff. But I had a reader write in, and ask me to write another&lt;lb/&gt; post on data structures, focusing on a structured called a&lt;lb/&gt; zipper.&lt;/p&gt;
    &lt;p&gt; A zipper is a remarkably clever idea. It’s not really a single data&lt;lb/&gt; structure, but rather a way of building data structures in functional&lt;lb/&gt; languages. The first mention of the structure seems to be a paper&lt;lb/&gt; by Gerard Huet in 1997, but as he says in the paper, it’s likely that this was&lt;lb/&gt; used before his paper in functional code — but no one thought to formalize it&lt;lb/&gt; and write it up. (In the original version of this post, I said the name of the guy who first wrote about zippers was “Carl Huet”. I have absolutely no idea where that came from – I literally had his paper on my lap as I wrote this post, and I still managed to screwed up his name. My apologies!)&lt;/p&gt;
    &lt;p&gt; It also happens that zippers are one of the rare cases of data structures&lt;lb/&gt; where I think it’s not necessarily clearer to show code. The concept of&lt;lb/&gt; a zipper is very simple and elegant – but when you see a zippered tree&lt;lb/&gt; written out as a sequence of type constructors, it’s confusing, rather&lt;lb/&gt; than clarifying.&lt;/p&gt;
    &lt;p&gt; The basic idea of a zipper is to give you a way of efficiently working with data&lt;lb/&gt; structures in a functional language. There are a lot of cases where in an imperative&lt;lb/&gt; language, there’s some basic operation which is cheap and simple in the imperative&lt;lb/&gt; language, because it’s performed by an in-place update. But in a functional language,&lt;lb/&gt; you can’t update a field of a data structure: instead, you have to create a new copy of the structure with the altered&lt;lb/&gt; field. &lt;/p&gt;
    &lt;p&gt; For example, consider the list &lt;code&gt;[a b c d e f g]&lt;/code&gt;. Implemented&lt;lb/&gt; as a cons-list, it’s a list of 7 cons-cells. Suppose you wanted&lt;lb/&gt; to replace “e” with “q”. In an imperative language, that’s no problem: just&lt;lb/&gt; do a set-car! of the 5th cell. In a functional language, you would&lt;lb/&gt; need to create a new list with “q” instead of&lt;lb/&gt; “e”. You could re-use the common tail &lt;code&gt;[f g]&lt;/code&gt;, but you would need&lt;lb/&gt; to re-create the other 5 cells: you’d need to create a new cell to&lt;lb/&gt; attach “q” to &lt;code&gt;[f g]&lt;/code&gt;. Then you’d need to create a new&lt;lb/&gt; cell to connect “d” to &lt;code&gt;[q f g]&lt;/code&gt;. And so on.&lt;/p&gt;
    &lt;p&gt; That makes the functional program much slower than the imperative one.&lt;lb/&gt; If you’ve got a data structure that conceptually changes over time, and you’re going to make lots of changes,&lt;lb/&gt; the cost of doing it functionally can become very high, because of all of the copying&lt;lb/&gt; you do instead of mutating a data structure.&lt;/p&gt;
    &lt;p&gt; In general, it’s very hard to get around that. You can’t update in place&lt;lb/&gt; in a functional language (at least, not without some serious cleverness, either&lt;lb/&gt; in your code (like monads), you language (like linear types), or your compiler).&lt;lb/&gt; But for many applications, there’s some notion&lt;lb/&gt; of a focus point – that is, a particular key point where changes&lt;lb/&gt; happen — and you can build structures where updates around the focus&lt;lb/&gt; can be performed efficiently.&lt;/p&gt;
    &lt;p&gt; For example, if you’re building a text editor, you’ve got the point&lt;lb/&gt; where the cursor is sitting – and the changes all happen around the cursor.&lt;lb/&gt; The user might type some characters, or delete some characters – but it always&lt;lb/&gt; happens around the cursor.&lt;/p&gt;
    &lt;p&gt; What a zipper does is take a data structure, and unfold it around a focal&lt;lb/&gt; point. Then you can make changes at the focal point very quickly – about as&lt;lb/&gt; quickly as an in-place update in an imperative language.&lt;/p&gt;
    &lt;p&gt; The idea of it is a lot like a gap-buffer. Right now, I’m actually working&lt;lb/&gt; on a text-editor. I’m writing it using a gap-buffer. Conceptually, an&lt;lb/&gt; edit-buffer is one continuous sequence of characters. But if you represent it&lt;lb/&gt; as a continuous sequence of characters, every insert is extremely expensive.&lt;lb/&gt; So what you do is split it into two sub-sequences: one consisting of the&lt;lb/&gt; characters before the cursor point, and one consisting of the&lt;lb/&gt; characters after the cursor point. With that representation,&lt;lb/&gt; inserting a character at the cursor point is O(1). Moving by one character is&lt;lb/&gt; also O(1). Moving by N characters is O(N). With various improvements, you can&lt;lb/&gt; do much better than that – but the key bit is that split between before the&lt;lb/&gt; focus point and after it.&lt;/p&gt;
    &lt;p&gt; A zipper is a tree or graph-based version of a similar idea. For this&lt;lb/&gt; discussion, I’ll describe it in terms of trees; the graph version is more complicated,&lt;lb/&gt; but you should be able to get the idea from seeing how it works on trees. The&lt;lb/&gt; idea is that you take the tree structure, and you split it around a focus. You’re focused on some node in the&lt;lb/&gt; tree. You keep track of a set of nodes that come before you, and a&lt;lb/&gt; set of nodes that come after you – those are basically like the&lt;lb/&gt; pre-gap and post-gap regions of a gap buffer. But because you’re working in a&lt;lb/&gt; tree, you need a bit more information: you need to know the path from&lt;lb/&gt; the root of the tree down to the current node. &lt;/p&gt;
    &lt;p&gt; It’s called a zipper because what you do to create this pre-focus, path,&lt;lb/&gt; and post-focus bits of the structure is unzip the tree. For example,&lt;lb/&gt; look at the tree below. It’s a representation of a string of text represented&lt;lb/&gt; by a tree. In this particular tree, all of the data is stored in the leaves.&lt;lb/&gt; The internal nodes contain metadata, which I haven’t shown in the diagram.&lt;/p&gt;
    &lt;p&gt; Now, suppose I want to put the focus on “mno”. To do that, I climb down&lt;lb/&gt; the tree, unzipping as I go. I start at the root, node N1. Then I go&lt;lb/&gt; right. So I put N1 and its left subtree into the left-context of my&lt;lb/&gt; zipper-tree, and add “Right at N1” to the path. That puts the focus at N3. To&lt;lb/&gt; get to “mno” from N3, I need to go left. So I put N3 and its right child into&lt;lb/&gt; the right context, and add “Left at N3” to the path. Now the focus is at N4.&lt;lb/&gt; To get to “mno”, I need to go right: so I put N4 and its left child into the&lt;lb/&gt; left context, and add “Right at N4” to the path. Now I’ve got the focus set&lt;lb/&gt; where I want it at “mno”; and I’ve got right and left contexts.&lt;/p&gt;
    &lt;p&gt; With the zipper, you can make all sorts of changes very easily at the&lt;lb/&gt; focus. Suppose I want to change the focus node, by inserting some text. I can&lt;lb/&gt; do that functionally, without actually changing anything, by creating a new&lt;lb/&gt; zipper tree which is identical to the old one, but which changes the value of&lt;lb/&gt; the focus node – that is, if I were to add “123” right after “mno”, I could do&lt;lb/&gt; it by creating a new focus node “mno123”, with the same path, left, and right&lt;lb/&gt; contexts. It takes minimal extra memory to create the copy, because I can&lt;lb/&gt; re-use the path and the contexts. &lt;/p&gt;
    &lt;p&gt; I could also add new children nodes. Suppose that instead of adding&lt;lb/&gt; “123” to the focus, I want to keep each leaf containing three characters.&lt;lb/&gt; could replace the focus with a new node, N5, which had children “mno”&lt;lb/&gt; and “123”. I could re-use the “mno” node, and the path, left, and right&lt;lb/&gt; contexts.&lt;/p&gt;
    &lt;p&gt; That’s the beauty of the zipper: most operations can be in terms of local&lt;lb/&gt; changes, re-using most of the structure. If we were using a standard tree,&lt;lb/&gt; then to add a new node in the position of “mno”, we would need to create&lt;lb/&gt; copies of N4, N3, and N1; instead, we only need to create the one new&lt;lb/&gt; node.&lt;/p&gt;
    &lt;p&gt; Doing other things isn’t that difficult either. Suppose we wanted to move&lt;lb/&gt; the focus to “pqr”. We’d need to shift the focus from “mno” to N3, then to N3,&lt;lb/&gt; and then to “pqr”. To get from “mno” to N4, we take the last step off of the&lt;lb/&gt; path – which says we went right at N4 – so we set the focus to N4, and&lt;lb/&gt; re-establish “mno” as its right child. So the focus would be N4, with “jkl” as&lt;lb/&gt; its left child, and “mno” as its right child. To get from N4 to N3, we unroll&lt;lb/&gt; another step of the path: since we went left at N3, that means that N3 is the&lt;lb/&gt; new focus, with N4 as its left child. Then we’d go down to the right from N3,&lt;lb/&gt; so we’d add “right at N3” to the path, and “pqr” would be the new focus.&lt;lb/&gt; Moving the focus like that is a tad more difficult than just traversing&lt;lb/&gt; non-zipper tree, but it’s not significantly slower – and it makes the edits&lt;lb/&gt; much, much faster.&lt;/p&gt;
    &lt;p&gt;So why is it harder to code? Because when we’re dealing with trees, we’re pretty much always dealing with balance. And balance isn’t a local property. No matter which kind of tree you use – red/black, 2/3, AVL – you might need to climb up the tree to do the balance maintenance. That mangles the simple zipper.&lt;/p&gt;
    &lt;p&gt; You’ve got two choices. One is to re-balance&lt;lb/&gt; the tree immediately. You can definitely do that. For&lt;lb/&gt; example, if you think of how you do a re-balance in&lt;lb/&gt; a red-black tree, you climb up the tree doing fixes until you’ve got things rebalanced. You can definitely do that – by using the zipper to move around the tree. But a big part of the point of the zipper is to keep operations local, and the re-balancing is not a&lt;lb/&gt; local operation. Much of the time, you can do things&lt;lb/&gt; locally, but sometimes you’ll be stuck re-zipping as you move the focus up the tree fixing the balance; in&lt;lb/&gt; the worst case, you need to re-zip the entire tree, all the way to the root.&lt;/p&gt;
    &lt;p&gt; The alternative is something called scarring. You put marks in the tree called scars that identify places where you made changes that could trigger a rebalance. (Or more generally,&lt;lb/&gt; in places where you made an edit that could have violated some invariant of the data structure.) You don’t do the fix immediately – you just mark it with&lt;lb/&gt; the scar, and then at some point, whenever it makes sense for your application, you go back to the scars, and fix the tree. (Scaring can also have a more general meaning, which involves memorizing certain paths through&lt;lb/&gt; the tree, so that you can make changes at the leave, then a few steps up, then back at the leaf. It’s a similar concept; in both forms of scarring, you’re optimizing to reduce the cost of zipping up and down the tree. )&lt;/p&gt;
    &lt;p&gt; Either way, it gets a bit more complicated – and when you look at the code&lt;lb/&gt; for a zipper, the re-balancing/invariant fixing has a tendency to dominate the complexity&lt;lb/&gt; of the code. The zipper itself is so simple and so elegant that it just disappears under&lt;lb/&gt; the weight of tree-balancing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://www.goodmath.org/blog/2010/01/13/zippers-making-functional-updates-efficient/"/><published>2025-10-09T11:07:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45526890</id><title>Show HN: I built a web framework in C</title><updated>2025-10-09T15:26:56.630499+00:00</updated><content>&lt;doc fingerprint="f38f151f5efdcd8"&gt;
  &lt;main&gt;
    &lt;p&gt;Lavandula is a lightweight, fast, and intuitive C web framework designed for building modern web applications quickly. It focuses on simplicity, performance, and productivity, providing all the essentials without the bloat of heavier frameworks.&lt;/p&gt;
    &lt;code&gt;#include "lavandula.h" 

// define a route for your app
appRoute(home) {
  return ok("Hello, World");
}

int main() {
  // initialise your app
  App app = createApp();

  // register a route in your app
  get(&amp;amp;app, "/home", home);

  // run the app
  runApp(&amp;amp;app);
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Controller and routing system&lt;/item&gt;
      &lt;item&gt;HTTP endpoint support (GET, POST, etc)&lt;/item&gt;
      &lt;item&gt;Controller local/global middleware pipeline&lt;/item&gt;
      &lt;item&gt;Minimal dependencies (pure C)&lt;/item&gt;
      &lt;item&gt;Quick project scaffolding via the CLI&lt;/item&gt;
      &lt;item&gt;Built-in unit testing framework&lt;/item&gt;
      &lt;item&gt;Environment variable support&lt;/item&gt;
      &lt;item&gt;Built-in logging&lt;/item&gt;
      &lt;item&gt;SQLite integration&lt;/item&gt;
      &lt;item&gt;Built-in JSON library&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;HTTP JSON body parsing&lt;/item&gt;
      &lt;item&gt;Session cookies&lt;/item&gt;
      &lt;item&gt;CORS policy configuration&lt;/item&gt;
      &lt;item&gt;Lavender ORM&lt;/item&gt;
      &lt;item&gt;Embedded Lavandula (ELA) HTML templating engine&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rate Limiting&lt;/item&gt;
      &lt;item&gt;Static file serving&lt;/item&gt;
      &lt;item&gt;PostgreSL, MySQL integrations, etc&lt;/item&gt;
      &lt;item&gt;Potential dependency injection framework&lt;/item&gt;
      &lt;item&gt;Route/Available endpoint listing&lt;/item&gt;
      &lt;item&gt;JSON model and function scaffolding &lt;list rend="ul"&gt;&lt;item&gt;lavu model User name:string age:int&lt;/item&gt;&lt;item&gt;generates User struct, JSON serialization, CRUD endpoints in user_controller.c&lt;/item&gt;&lt;item&gt;URL parameter parsing and routing&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To install Lavandula, follow these setps.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone the repository&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/ashtonjamesd/lavandula.git
cd lavandula&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run the install script&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./install.sh&lt;/code&gt;
    &lt;p&gt;You should see the following:&lt;/p&gt;
    &lt;code&gt;[SUCCESS] 🎉 Lavandula installation completed!

Quick Start:
 lavu new my-project # Create a new project
 cd my-project
 lavu run # Run your project

Documentation:
 GitHub: https://github.com/ashtonjamesd/lavandula&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Finish&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You should now be able to run the Lavu CLI tool. Refer to &lt;code&gt;api.md&lt;/code&gt; for how to use Lavu.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create a new project&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;lavu new myProject
&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;Setting up Lavandula project 'myProject'...

-&amp;gt; Created myProject/lavandula.yml
-&amp;gt; Created myProject/app/app.c
-&amp;gt; Created myProject/app/controllers/home.c
-&amp;gt; Created myProject/app/routes.c
-&amp;gt; Created myProject/makefile
-&amp;gt; Created myProject/tests/tests.c

🎉 Lavandula project 'myProject' setup finished successfully!

Next steps:
  1. cd myProject
  2. lavu run
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;lavu run
&lt;/code&gt;
    &lt;p&gt;Your application will run on http://localhost:3000/.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Read the docs&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome. Feel free to submit pull requests or open issues for feature requests or bugs.&lt;/p&gt;
    &lt;p&gt;Some things that probably need looking at are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;memory leaks&lt;/item&gt;
      &lt;item&gt;outdated and unfinished documentation (API changes warrant a docs update)&lt;/item&gt;
      &lt;item&gt;The JSON library does not currently support nested lists&lt;/item&gt;
      &lt;item&gt;Some tests need to be written...&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lavandula is registered under the MIT License.e&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ashtonjamesd/lavandula"/><published>2025-10-09T12:45:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45527003</id><title>Nobel Prize in Literature 2025: László Krasznahorkai</title><updated>2025-10-09T15:26:56.364580+00:00</updated><content>&lt;doc fingerprint="5757b33da9153196"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Press release&lt;/head&gt;
    &lt;p&gt;English&lt;lb/&gt;English [pdf]&lt;lb/&gt;Swedish&lt;lb/&gt;Swedish [pdf]&lt;/p&gt;
    &lt;p&gt;The Permanent Secretary&lt;/p&gt;
    &lt;p&gt;Press Release&lt;lb/&gt;9 October 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;The Nobel Prize in Literature 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;László Krasznahorkai&lt;/head&gt;
    &lt;p&gt;The Nobel Prize in Literature for 2025 is awarded to the Hungarian author László Krasznahorkai,&lt;/p&gt;
    &lt;p&gt;“for his compelling and visionary oeuvre that, in the midst of apocalyptic terror, reaffirms the power of art”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
    &lt;head rend="h3"&gt;Explore prizes and laureates&lt;/head&gt;
    &lt;p&gt; Look for popular awards and laureates in different fields, and discover the history of the Nobel Prize. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/literature/2025/press-release/"/><published>2025-10-09T12:54:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45527156</id><title>The C++ programmer and educator Rainer Grimm has passed away</title><updated>2025-10-09T15:26:54.990478+00:00</updated><content>&lt;doc fingerprint="2b53115b8ae3f62f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;My ALS Journey (31/31): The End&lt;/head&gt;
    &lt;p&gt;Dear readers, we are extremely sad to inform you that Rainer passed away on October 6, 2025, surrounded by his closest family. After suffering from life-threatening pneumonia, Rainer decided against further life-sustaining measures that would have severely restricted his life. He passed away peacefully, accompanied by his family.&lt;/p&gt;
    &lt;p&gt;&amp;gt;&amp;gt; Rainers Journey with ALS &amp;lt;&amp;lt;&lt;/p&gt;
    &lt;head rend="h2"&gt;Rainers lifework&lt;/head&gt;
    &lt;p&gt;Despite his progressive ALS disease, Rainer remained full of energy and drive until the very end and continued to work on his two life goals:&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Creating Value for the C++ Community&lt;/head&gt;
    &lt;p&gt;First, to share his knowledge and experience of C++ with you through his blog modernescpp.com, his mentoring program, and digital participation in conferences.&lt;/p&gt;
    &lt;p&gt;His last digital appearance was at CppCon 2025, where he had given lectures both digitally and in person in previous years. More recently, Cippi, an initiative founded by Rainer and his wife, Beatrix, has visited conferences such as CppCon and will continue to do so.&lt;/p&gt;
    &lt;p&gt;You can read more about Cippi’s adventures on her blog.&lt;/p&gt;
    &lt;p&gt;If you would like Cippi to visit your conference, please send an email to beatrix.grimm-jaud@ModernesCpp.de.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Raising awareness for ALS&lt;/head&gt;
    &lt;p&gt;Second, to raise awareness of ALS and other neurological diseases in order to collect donations for ALS research.&lt;/p&gt;
    &lt;p&gt;As part of this, Rainer attended a charity run organized in his name by TV Rottenburg on September 28, which raised over €6,000 in donations for ALS research.&lt;lb/&gt;Since Rainer himself had been active as a running coach at TVR for over 15 years before his illness and had coached several athletes to the German championships, he had the opportunity to meet many long-time acquaintances and friends there once again.&lt;/p&gt;
    &lt;p&gt;Over the past two years, Rainer has repeatedly offered his books at a significant discount and donated all proceeds to ALS research.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modernes C++ Mentoring&lt;/head&gt;
    &lt;p&gt;Do you want to stay informed: Subscribe.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank You!&lt;/head&gt;
    &lt;p&gt;As a family, we would like to thank you, the C++ community, for being like a second family to Rainer over the years and providing him with such an essential source of support, both professionally and privately. Especially in the last two years, when ALS took away Rainer’s chance to attend conferences in person, you showed your sympathy and, not least through your support for Rainer’s Cippi initiative, underlined what a great, strong, and empathetic community you are!&lt;/p&gt;
    &lt;p&gt;We cannot say at this point what will happen to his blog, his mentoring, or his book in progress, Modern C++26, but we will keep you informed.&lt;/p&gt;
    &lt;p&gt;Thank you very much!&lt;lb/&gt;Beatrix, Juliette, and Marius&lt;/p&gt;
    &lt;p&gt;Thanks a lot to my Patreon Supporters: Matt Braun, Roman Postanciuc, Tobias Zindl, G Prvulovic, Reinhold Dröge, Abernitzke, Frank Grimm, Sakib, Broeserl, António Pina, Sergey Agafyin, Андрей Бурмистров, Jake, GS, Lawton Shoemake, Jozo Leko, John Breland, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Robert Blanch, Truels Wissneth, Mario Luoni, Friedrich Huber, lennonli, Pramod Tikare Muralidhara, Peter Ware, Daniel Hufschläger, Alessandro Pezzato, Bob Perry, Satish Vangipuram, Andi Ireland, Richard Ohnemus, Michael Dunsky, Leo Goodstadt, John Wiederhirn, Yacob Cohen-Arazi, Florian Tischler, Robin Furness, Michael Young, Holger Detering, Bernd Mühlhaus, Stephen Kelley, Kyle Dean, Tusar Palauri, Juan Dent, George Liao, Daniel Ceperley, Jon T Hess, Stephen Totten, Wolfgang Fütterer, Matthias Grün, Ben Atakora, Ann Shatoff, Rob North, Bhavith C Achar, Marco Parri Empoli, Philipp Lenk, Charles-Jianye Chen, Keith Jeffery, Matt Godbolt, Honey Sukesan, bruce_lee_wayne, Silviu Ardelean, schnapper79, Seeker, and Sundareswaran Senthilvel.&lt;/p&gt;
    &lt;p&gt;Thanks, in particular, to Jon Hess, Lakshman, Christian Wittenhorst, Sherhy Pyton, Dendi Suhubdy, Sudhakar Belagurusamy, Richard Sargeant, Rusty Fleming, John Nebel, Mipko, Alicja Kaminska, Slavko Radman, and David Poole.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;My special thanks to Embarcadero&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;My special thanks to PVS-Studio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;My special thanks to Tipi.build&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;My special thanks to Take Up Code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;My special thanks to SHAVEDYAKS&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Modernes C++ GmbH&lt;/p&gt;
    &lt;p&gt;Modernes C++ Mentoring (English)&lt;/p&gt;
    &lt;p&gt;Rainer Grimm&lt;lb/&gt; Yalovastraße 20&lt;lb/&gt; 72108 Rottenburg&lt;/p&gt;
    &lt;p&gt;Mail: schulung@ModernesCpp.de&lt;/p&gt;
    &lt;p&gt;Mentoring: www.ModernesCpp.org&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.modernescpp.com/index.php/my-als-journey-31-31-the-end/"/><published>2025-10-09T13:05:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45527402</id><title>Figure 03, our 3rd generation humanoid robot</title><updated>2025-10-09T15:26:54.795769+00:00</updated><content>&lt;doc fingerprint="ec95cddb80b22ecf"&gt;
  &lt;main&gt;
    &lt;p&gt;Today we’re introducing Figure 03, our 3rd generation humanoid robot. Figure 03 is designed for Helix, the home, and the world at scale. Our goal is to deliver a truly general-purpose robot - one that can perform human-like tasks and learn directly from people. To realize this vision, our engineering and design teams completed a ground-up hardware and software redesign to ship Figure 03 for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Helix: Figure 03 features a completely redesigned sensory suite and hand system which is purpose-built to enable Helix - Figure's proprietary vision-language-action AI.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The home: Figure 03 has several new features, including soft goods, wireless charging, improved audio system for voice reasoning, and battery safety advancements that make it safer and easier to use in a home environment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mass manufacturing: Figure 03 was engineered from the ground-up for high-volume manufacturing. In order to scale, we established a new supply chain and entirely new process for manufacturing humanoid robots at BotQ.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The world at scale: The lower manufacturing cost and the advancements made for Helix have significant benefits for commercial applications.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Designed for Helix&lt;/head&gt;
    &lt;p&gt;There’s no path to scaling humanoid robots without AI. That’s why we built Figure 03 around one goal - to enable true reasoning throughout the world using Helix. Figure 03 introduces a fully redesigned sensory suite and hand system, purpose-built to bring Helix to life.&lt;/p&gt;
    &lt;p&gt;Figure 03 introduces a next-generation vision system engineered for high-frequency visuomotor control. Its new camera architecture delivers twice the frame rate, one-quarter the latency, and a 60% wider field of view per camera - all within a more compact form factor. Combined with an expanded depth of field, this architecture provides Helix with a denser, more stable perceptual stream. These advancements are essential for intelligent navigation and precise manipulation in complex, cluttered spaces such as homes.&lt;/p&gt;
    &lt;p&gt;Each hand now integrates an embedded palm camera with a wide field of view and low-latency sensing, which offers redundant, close-range visual feedback during grasps. These cameras allow Helix to maintain visual awareness even when the main cameras are occluded (i.e. when reaching into a cabinet or working in confined spaces) and enable continuous, adaptive control in real time.&lt;/p&gt;
    &lt;p&gt;The Figure 03 hands represent a major leap in compliant and tactile design. Softer, more adaptive fingertips increase surface contact area, enabling more stable grasps across objects of varied shapes and sizes. After surveying existing market options, Figure found that current tactile sensors had inherent limitations that could not withstand real-world use. This led to the internal development of our first-generation tactile sensor, guided by three principles: extreme durability, long-term reliability, and high-fidelity sensing.&lt;/p&gt;
    &lt;p&gt;Each fingertip sensor can detect forces as small as three grams of pressure - sensitive enough to register the weight of a paperclip resting on your finger. This precision enables Helix to distinguish between a secure grip and an impending slip before it occurs, allowing fine-grained, dexterous control over fragile, irregular, or moving objects.&lt;/p&gt;
    &lt;p&gt;Figure 03 also includes 10 Gbps mmWave data offload capability, allowing the entire fleet to upload terabytes of data for continuous learning and improvement. Together, these advancements position Figure 03 as uniquely capable of large-scale, end-to-end pixels-to-action learning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed for the Home&lt;/head&gt;
    &lt;p&gt;To operate effectively in the home, a robot must work seamlessly alongside people in their daily environments. With this in mind, Figure 03 introduces several design improvements focused on safety. It features strategically placed multi-density foam to protect against pinch points, and is covered in soft textiles rather than hard machined parts. Figure 03 also has 9% less mass and significantly less volume than Figure 02, making it easier to maneuver through household spaces.&lt;/p&gt;
    &lt;p&gt;The Figure 03 battery pushes the bounds for robot battery safety and incorporates multiple layers of protection against abuse or malfunction, including safeguards at the Battery Management System (BMS), cell, interconnect, and pack levels. The battery has already achieved certification to the UN38.3 standard.&lt;/p&gt;
    &lt;p&gt;Beyond safety, Figure 03 is designed for everyday usability. The soft goods are fully washable and can be removed or replaced without tools, allowing quick and easy swaps. The robot can also be customized with various clothing options, including garments made from cut-resistant and durable materials.&lt;/p&gt;
    &lt;p&gt;To make it easier to communicate naturally with the robot, Figure 03 features an upgraded audio hardware system for better real time speech-to-speech. Compared with Figure 02, its speaker is twice the size and nearly four times more powerful, while the microphone has been repositioned for improved performance and clarity.&lt;/p&gt;
    &lt;p&gt;Continuing our vision for a fully autonomous, wire-free system, Figure 03 is capable of wireless inductive charging alongside wireless data offload. Charging coils in the robot’s feet allow it to simply step onto a wireless stand and charge at 2 kW. In a home setting, this means the robot can automatically dock and recharge itself as needed throughout the day.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed for Mass Manufacturing&lt;/head&gt;
    &lt;p&gt;Humanoid robots have traditionally been designed as engineering prototypes which are time consuming and expensive to produce. Figure 03 is our first robot engineered from the ground-up for high-volume manufacturing. We achieved this through three major initiatives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Design and process reinvention&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Establishing an entirely new supply chain&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The invention of BotQ, our high-volume manufacturing facility&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Moving from Figure 02 to Figure 03 required redesigning nearly every component of the robot with manufacturability and cost in mind. The mechanical and electrical engineering teams aggressively reduced part count, assembly steps, and any components that were not absolutely critical to meet design requirements. While Figure 02 was primarily designed to be manufactured with CNC machining, Figure 03 relies heavily on tooled processes such as die-casting, injection molding, and stamping. This shift demanded a significant up-front investment in tooling, but the payoff is clear: each Figure 03 unit now costs dramatically less to build, with the economics improving as volumes grow.&lt;/p&gt;
    &lt;p&gt;To scale Figure 03, Figure had to build an entirely new supply chain for an industry where one does not currently exist. Figure chose to vertically integrate across many critical module builds including actuators, batteries, sensors, structures, and electronics, all of which were designed completely in-house. For individual components, Figure strategically identified and partnered with suppliers capable of meeting the required volumes, timelines, and strict quality standards demanded by the team. The result of this year-long effort is a global network of partners who can grow alongside Figure and meet production goals of thousands and eventually millions of parts under an aggressive ramp schedule.&lt;/p&gt;
    &lt;p&gt;BotQ is Figure’s dedicated manufacturing facility designed to scale robot production. BotQ’s first-generation manufacturing line will initially be capable of producing up to 12,000 humanoid robots per year, with the goal of producing a total of 100,000 robots over the next four years. Instead of relying on contract manufacturers, Figure brought production of its most critical systems in-house to maintain tight control over quality, iteration, and speed. The facility is equipped with state-of-the-art systems and digital integrations, anchored by our internally developed Manufacturing Execution System (MES). Every subassembly and final assembly passes through this line with full traceability, ensuring quality, repeatability, and continuous improvement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed for the World at Scale&lt;/head&gt;
    &lt;p&gt;Figure’s focus on the home market in no way detracts from the potential of Figure 03 for the commercial market. By solving for the variability and intractability of the home, Figure is developing a truly general-purpose product that can do the widest possible range of tasks in the workforce.&lt;/p&gt;
    &lt;p&gt;Figure 03 is well suited for commercial applications for several reasons. The actuators can perform at 2x faster speeds with improved torque density (nm/kg). The most significant result of this is our ability to pick and place items at faster speeds.&lt;/p&gt;
    &lt;p&gt;The improvements to the hands and sensory suite made for Helix are of major significance for commercial use cases. With the camera and perception system upgrades, Figure 03 will be able to intelligently navigate commercial environments and execute precise manipulation. The changes to the hands highlighted above (added compliance, fingertip surface area, tactile sensing) enable better and more stable grasps across an array of objects such as small pieces of sheet metal and deformable poly bags.&lt;/p&gt;
    &lt;p&gt;Thanks to inductive charging, Figure 03 is capable of near-continuous operation as long as it can step onto a charging mat for a certain period of time during the use case. The fast wireless data offload also means that the robot can offload seamlessly during shift breaks just by returning to the dock.&lt;/p&gt;
    &lt;p&gt;Commercial customers can also design distinct uniforms for their Figure 03 fleet, with the option to use more durable, or cut-proof materials, and make other design changes for specific environments. New side screens on Figure 03 even allow quick identification across large fleets and can be fully customized to match each customer’s branding or operational needs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Figure 03 represents an unprecedented advancement in taking humanoid robots from experimental prototypes to deployable, scalable products. By uniting advanced perception and tactile intelligence with home-safe design and mass-manufacturing readiness, Figure has built a platform capable of learning, adapting, and working across both domestic and commercial settings. Designed for Helix, the home, and the world at scale, Figure 03 establishes the foundation for true general-purpose robotics - one capable of transforming how people live and work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.figure.ai/news/introducing-figure-03"/><published>2025-10-09T13:27:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45527507</id><title>Using a Laptop as an HDMI Monitor for an SBC</title><updated>2025-10-09T15:26:54.723230+00:00</updated><content>&lt;doc fingerprint="2e756d7589369bd2"&gt;
  &lt;main&gt;
    &lt;p&gt;Though I spend the majority of my time working with microcontroller class devices, I also have an embarassingly robust collection of single board computers (SBC), including a few different Raspberry Pi models, the BeagleV Starlight Beta (RIP), and more. Typically when setting up these devices for whatever automation task I have planned for them, I’ll use “headless mode” and configure initial user and network credentials when writing the operating system to the storage device using a tool like Raspberry Pi’s Imager.&lt;/p&gt;
    &lt;p&gt;However, sometimes direct physical access to the SBC with a monitor and keyboard is useful for initial configuration, maintenance operations, or workloads that have a visual component. As someone who doesn’t use any external monitors1 for my daily development, digging up an HDMI monitor, finding somewhere to put it, and connecting it to the device is an annoying process. Furthermore, if I’m on the go I almost certainly don’t have easy access to an external monitor.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Raspberry Pi boot logs shown in VLC media player.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Fortunately, I rarely ever do this because I have a handful of HDMI to USB capture cards, ranging from extremely cheap variants from Amazon, to the higher quality Elgato Cam Link 4k. These are typically used for live streaming a video feed from DSLR / mirrorless cameras or gaming consoles, but they also serve as a great option for capturing video from any other device that has HDMI output. On my System76 Linux daily driver laptop, I can use any number of different video playback applications to display the HDMI output via the capture card. For longer term use cases, I can breathe new life into one of my old laptops, using the capture card to effectively convert it into a monitor.&lt;/p&gt;
    &lt;code&gt;vlc v4l2:///dev/video0
&lt;/code&gt;
    &lt;code&gt;ffplay /dev/video0
&lt;/code&gt;
    &lt;code&gt;cheese v4l2:///dev/video0
&lt;/code&gt;
    &lt;p&gt;If you do want to stream or record the SBC output, OBS will give you even more control. You’ll still need a USB keyboard, but I already use one with my laptop, so temporarily plugging it into the SBC for configuration while I use the laptop as a monitor is minimally disruptive. However, if you find yourself regularly needing to connect to multiple machines, it might be time to consider getting a KVM switch.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Yeah, I just sit here with my one laptop screen. Can you believe that? ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://danielmangum.com/posts/laptop-hdmi-monitor-sbc/"/><published>2025-10-09T13:36:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45527758</id><title>TIL: Python's splitlines does more than just newlines</title><updated>2025-10-09T15:26:54.421789+00:00</updated><content>&lt;doc fingerprint="e795b146e9a118bf"&gt;
  &lt;main&gt;
    &lt;p&gt;(With thanks to Seth Larson for taking me down this rabbit hole.)&lt;/p&gt;
    &lt;p&gt;I always assumed that Python's &lt;code&gt;str.splitlines()&lt;/code&gt; split strings by
"universal newlines", i.e., &lt;code&gt;\n&lt;/code&gt;, &lt;code&gt;\r&lt;/code&gt;, and &lt;code&gt;\r\n&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But it turns out it does a lot more than that. From the docs:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This method splits on the following line boundaries. In particular, the boundaries are a superset of universal newlines.&lt;/p&gt;&lt;th&gt;Representation&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;code&gt;\n&lt;/code&gt;&lt;td&gt;Line Feed&lt;/td&gt;&lt;code&gt;\r&lt;/code&gt;&lt;td&gt;Carriage Return&lt;/td&gt;&lt;code&gt;\r\n&lt;/code&gt;&lt;td&gt;Carriage Return + Line Feed&lt;/td&gt;&lt;code&gt;\v&lt;/code&gt;Â orÂ&lt;code&gt;\x0b&lt;/code&gt;&lt;td&gt;Line Tabulation&lt;/td&gt;&lt;code&gt;\f&lt;/code&gt;Â orÂ&lt;code&gt;\x0c&lt;/code&gt;&lt;td&gt;Form Feed&lt;/td&gt;&lt;code&gt;\x1c&lt;/code&gt;&lt;td&gt;File Separator&lt;/td&gt;&lt;code&gt;\x1d&lt;/code&gt;&lt;td&gt;Group Separator&lt;/td&gt;&lt;code&gt;\x1e&lt;/code&gt;&lt;td&gt;Record Separator&lt;/td&gt;&lt;code&gt;\x85&lt;/code&gt;&lt;td&gt;Next Line (C1 Control Code)&lt;/td&gt;&lt;code&gt;\u2028&lt;/code&gt;&lt;td&gt;Line Separator&lt;/td&gt;&lt;code&gt;\u2029&lt;/code&gt;&lt;td&gt;Paragraph Separator&lt;/td&gt;&lt;/quote&gt;
    &lt;p&gt;This results in some surprising (to me) splitting behavior:&lt;/p&gt;
    &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;   =  
&amp;gt;&amp;gt;&amp;gt;  
 
&lt;/code&gt;
    &lt;p&gt;Whereas I would have expected:&lt;/p&gt;
    &lt;p&gt;This was a good periodic reminder that Unicode does not mean "printable," and that there are still plenty of ecosystems that assign semantics to C0 and C1 control codes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yossarian.net/til/post/python-s-splitlines-does-a-lot-more-than-just-newlines/"/><published>2025-10-09T13:55:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45528141</id><title>Silver Trades to $50 an Ounce</title><updated>2025-10-09T15:26:54.280845+00:00</updated><content>&lt;doc fingerprint="c3ef1d8475b675e7"&gt;
  &lt;main&gt;
    &lt;p&gt;Spot silver has stretched to the $50 level for the 1st time ever. The high price of just traded at $50.03. It is currently trading at $49.94.&lt;/p&gt;
    &lt;p&gt;The move to the upside took out the 2011 high, which my chart had at $49.83. There is some uncertainty regarding that high, but with the high today at $50.01, that will supersede the uncertainty from 2011.&lt;/p&gt;
    &lt;p&gt;Gold, meanwhile, is trading up $1.50 at $4042. It has been stretching to new highs – with some corrective days interspersed – since September 2 when it moved above the April 22 high at $3500. The high price today reached $4046.71. Yesterday the new all-time price high stalled at $4059.31.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://investinglive.com/technical-analysis/silver-trades-to-50-an-ounce-for-the-1st-time-ever-20251009/"/><published>2025-10-09T14:24:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45528342</id><title>Why Self-Host?</title><updated>2025-10-09T15:26:53.925043+00:00</updated><content>&lt;doc fingerprint="ad29105313a62fd3"&gt;
  &lt;main&gt;
    &lt;p&gt;I recently shared my current Homelab setup with a colleague and was asked a pretty simple question I just took for granted... why?&lt;/p&gt;
    &lt;p&gt;Why go through the hassle of configuring servers, installing applications, setting up containers and spending quite a substantial amount of money on hardware that will not even run under optimal data center conditions (consumer-grade internet connection, no failover, no auto migrations)?&lt;/p&gt;
    &lt;p&gt;I will also give some specific recommendations on what you could and maybe should self-host.&lt;/p&gt;
    &lt;head rend="h2"&gt;Privacy&lt;/head&gt;
    &lt;p&gt;You saw that coming.&lt;/p&gt;
    &lt;p&gt;Privacy is not a god-given right but has to be fought for. Big Tech and governments (like with chat control in the EU) want to shine light in every part of your personal life. Self-hosting services can reduce or even completely mitigate the risk of being surveilled. But it also requires a lot of technical knowledge so you can make a difference and educate your family or friends and even host some services for those who don't have the capabilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calendar &amp;amp; Contacts&lt;/head&gt;
    &lt;p&gt;Your calendar says more about you than you probably think. Apart from your full identity it can also give away information about regular contacts, family, coworkers, confidential business meetings, your health information such as medical appointments, sleep and workout routine, legal obligations, financial information like scheduled loans, subscriptions, political beliefs through scheduling to visit a protest and even let's other profile your behavior for identity theft to find out when you're available and when not.&lt;/p&gt;
    &lt;p&gt;Same goes for contacts, your social graph can say so much about you, combined with metadata such as queries for certain contacts and creation dates. Did you recently add an unusual amount of new contacts with the same sex, first name only and phone number? You must be dating. Just created a contact for a doctor? Looks like you're visiting a therapist.&lt;/p&gt;
    &lt;p&gt;Most people don't even think about where their social graph data is stored and probably assume it comes with their phone when in reality that data is being processed by Google, Apple, Samsung or whoever knows.&lt;/p&gt;
    &lt;p&gt;I don't want a single company holding all that sensitive information and possibly deriving data points from that. Even with Apple's Advanced Data Protection your calendars and contacts are not end-to-end encrypted.&lt;/p&gt;
    &lt;head rend="h3"&gt;Location&lt;/head&gt;
    &lt;p&gt;Many many years ago I was running an Android phone with Google services like Google Maps. One day I was looking for a feature in my Google account and saw that GMaps recorded my location history for years with detailed geocoordinates about every trip and every visit.&lt;/p&gt;
    &lt;p&gt;I was fascinated but also scared about that since I've never actually enabled it myself. I do like the fact that I could look up my location for every point in time but I want to be in control about that and know that only I have access to that data.&lt;/p&gt;
    &lt;head rend="h3"&gt;So much more&lt;/head&gt;
    &lt;p&gt;It's beyond the scope of this post to list every possible way, your data can be traced back to you and argument why you should be conscious about that. I want to motivate you to start a new journey!&lt;/p&gt;
    &lt;head rend="h2"&gt;Sovereignty&lt;/head&gt;
    &lt;p&gt;Digital sovereignty for me means to be in control of, choosing what I do with and controlling who I share my data with.&lt;/p&gt;
    &lt;p&gt;You constantly hear about cases of tech companies locking down accounts with no apparent reason and it even happened to me in the past with Google. I do not want to be at the mercy of a giant tech firm which you can not even contact or if - get annoyed by a garbage AI chat bot (see my Microsoft rant for more fun). Besides - why are there no regulatory requirements for tech companies to provide a way to get in contact with an actual human?&lt;/p&gt;
    &lt;p&gt;I like protocols and file standards, no "Gmail" API - we call that thing SMTP and IMAP (yes, they are dated but the best we currently have. Thus I still welcome the new JMAP initiative). Another paragraph without bashing Microsoft? Hell no, Big Tech like Microsoft really wants you to use their AI-Copoilit-enabled-365-Office-Live-Outlook &lt;del&gt;spyware&lt;/del&gt; software - that's why they have recently disabled SMTP access for Office 365 accounts.&lt;/p&gt;
    &lt;head rend="h2"&gt;What to self-host&lt;/head&gt;
    &lt;p&gt;Let's get to the bread and butter of this article and give some straightforward examples on what to self-host.&lt;/p&gt;
    &lt;p&gt;Some of those applications need to be available outside of your local network if you don't want to be constantly connected to a VPN. I will write more about how to do that securely and all available options in an upcoming post. If you want to read that, subscribe to the RSS feed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calendar &amp;amp; Contacts&lt;/head&gt;
    &lt;p&gt;As stated above, calendar and contact data is more sensitive than one might think. This is why I am hosting my own CalDAV / CardDAV server.&lt;/p&gt;
    &lt;p&gt;There are some options on servers for you which all have their ups and downs. Here are just a few:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Radicale (Python, basic web ui, only single user, does not work with apple devices from my experience)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;â BaÃ¯kal (PHP, active development, advanced web ui, multi-user)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DAViCal (PHP, haven't tried)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Xandikos (Python, No built-in authentication, no web ui)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nextcloud (PHP, If you're already using it go for it - too bloated for me)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Being conscious about what other can do with your calendar and contact data also mean to review, which apps have access to your contact book and calendar.&lt;/p&gt;
    &lt;p&gt;Oh no, I said the forbidden phrase: Self-hosted mail server. I was always told to never under any circumstances do that. But it's really not that deep.&lt;/p&gt;
    &lt;p&gt;"Recent" developments like Stalwart or Mailcow made it really easy and straighforward to self-host email. Beware I'm not talking about marketing mails but rather personal inboxes.&lt;/p&gt;
    &lt;p&gt;Of course, you don't want to self-host your mail server at home since it requires a static IP and needs to be reachable from the whole internet. Going into that, you want to start with a clean IP address. Choose a hoster you trust, get a server, look up the IP address in mail blacklists and repeat until you get a clean one. After setting up the server, you want to make sure you can receive mail and every required protocol has been correctly configured. I found the internet.nl online test tool to be super usefull to ensure everything works. Start by sending mails to Google, Microsoft and Yahoo addresses to check if your mails are getting redirected to SPAM. Iterate on that, check DNS, DMARC, SPF, TLS etc.&lt;/p&gt;
    &lt;p&gt;I will probably write a detailed blog post on that in the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;Smart Home&lt;/head&gt;
    &lt;p&gt;When I started hosting my own Home Assistant instance a couple of years ago it was just an experiment to see what I can do since I wasn't really missing anything with Apple Homekit. Since then more and more smart home companies went bankrupt, sunsetted their cloud services, jacked up prices or put free services behind a paywall.&lt;/p&gt;
    &lt;p&gt;For me, Home Assistant paid off a couple of weeks ago when I heard that Philips Hue will force users to create an account just to use any feature for their lights, they already paid real money for. I've always configured Firewall rules to disallow any outgoing network traffic for smart home appliances but it seems like I cannot use any Philips Hue app specific features (like animated light patterns imitating candles etc.) even on my local network. I haven't looked into this but I hope there's some community plugin which emulates this functionality.&lt;/p&gt;
    &lt;p&gt;I will never, under any circumstances, create an online account for an appliance I will only use locally.&lt;/p&gt;
    &lt;p&gt;Also I am now obsessed with tracking energy usage and plan on building and developing a Raspberry Pi + camera device which tracks energy usage of gas meter via machine vision.&lt;/p&gt;
    &lt;head rend="h3"&gt;RSS Aggregator&lt;/head&gt;
    &lt;p&gt;I am subscribed to many news sites and blogs over RSS which is by itself already decentralized and sovereign. This is why self-hosting an RSS aggregator is kind of optional and only the last mile to go.&lt;/p&gt;
    &lt;p&gt;On my iPhone and Mac I'm running NetNewsWire, in my opinion the best RSS reader, even open source and backed by incredible people. NetNewsWire comes with a native integration for FreshRSS - a feed aggregator that also provides many more features like filtering and lets you subscribe to sources which don't natively provide an RSS feed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Location Tracker&lt;/head&gt;
    &lt;p&gt;I've deployed an instance of dawarich (German for "I was there") which is a server for ingesting and viewing geolocation data. It also allows you to choose from many available mobile apps which can track send your current location to the server. At the time of writing this includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;official dawarich app (always shows a navigation icon in the iOS notch)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Overland (high battery drain for me)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;â Owntracks (works best for me on iOS, only app settings are crazy confusing)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ideas &amp;amp; Outlook&lt;/head&gt;
    &lt;p&gt;I recently re-worked my homelab and went from a single big server to a 3 node Kubernetes cluster. This gives me much more flexibility in the kind of applications I can host.&lt;/p&gt;
    &lt;p&gt;This is a list of apps and tools I want to have a look at:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;EteSync: End-to-end encrypted CalDAV &amp;amp; CardDAV&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AnyType: Self-hosting my own AnyType server instance&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Passbolt: Password manager (no I really don't like Bitwarden)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;BirdNET: Monitoring bird species outside with a microphone&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;penpot: Like Figma but free &amp;amp; open source&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Habitica: Habit manager&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;vert: File converter&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;InvoiceShelf: Invoice manager&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There's also selfh.st - a great resource where can spend hours finding self-hostable applications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://romanzipp.com/blog/why-a-homelab-why-self-host"/><published>2025-10-09T14:39:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45528347</id><title>The great software quality collapse or, how we normalized catastrophe</title><updated>2025-10-09T15:26:53.872838+00:00</updated><content/><link href="https://techtrenches.substack.com/p/the-great-software-quality-collapse"/><published>2025-10-09T14:39:29+00:00</published></entry></feed>