<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-05T16:15:16.815700+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46489830</id><title>Trellis AI (YC W24) is hiring engineers to build AI agents for healthcare access</title><updated>2026-01-05T16:15:25.619036+00:00</updated><content>&lt;doc fingerprint="ad510041aad6f0ca"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Trellis builds and deploys computer use agents to get patients access to life-saving medicine.&lt;/head&gt;
        &lt;p&gt;Our computer-use AI agents process billions of dollars worth of therapies annually with patients in all fifty states. We do this by automating document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care. We classify medical referrals, understand chart notes, and automate contract and reimbursement search to provide patients with accurate coverage determinations and cost responsibility. Think of us as the Stripe of healthcare billing and reimbursements.&lt;/p&gt;
        &lt;p&gt;Trellis is a spinout from Stanford AI Lab and is backed by leading investors including YC, General Catalyst, Telesoft Partners, and executives at Google and Salesforce.&lt;/p&gt;
        &lt;head rend="h3"&gt;üßçüèª‚ôÇÔ∏èWhy work with us&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Real impact at massive scale: We serve patients in all fifty states and are scaling to hundreds of healthcare locations. You'll directly see the number of patients who received treatment because of the agents you built.&lt;/item&gt;
          &lt;item&gt;Work with industry experts: Apply your AI alongside healthcare operations leaders who have overseen 50+ healthcare locations, gaining deep domain expertise while building cutting-edge technology.&lt;/item&gt;
          &lt;item&gt;Be at the forefront of AI in healthcare: Build production-grade agentic systems that make critical healthcare decisions, backed by robust evaluation frameworks.&lt;/item&gt;
          &lt;item&gt;Direct customer engagement: Work closely with F500 customers and the founding team. You'll wear multiple hats from technical architecture to customer success.&lt;/item&gt;
          &lt;item&gt;Extreme ownership: Own key parts of Trellis's technical infrastructure and have opportunities to launch new initiatives that process billions in healthcare transactions.&lt;/item&gt;
          &lt;item&gt;World-class team: Join team members who have won international physics olympiads, published economics research, were founding engineers at unicorn startups, and taught AI classes to hundreds of Stanford graduate students.&lt;/item&gt;
          &lt;item&gt;Incredible growth and traction: We've grown revenue 10x in the past few months alone and have XX% market share in the specialty healthcare markets we serve.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;What you'll build&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Agentic frameworks for healthcare decision-making: Design and implement AI systems that autonomously navigate complex reimbursement logic and prior authorization workflows.&lt;/item&gt;
          &lt;item&gt;24/7 AI co-workers: Build and deploy long-running agent workers that triage and process healthcare data around the clock, functioning as reliable digital teammates for care teams.&lt;/item&gt;
          &lt;item&gt;Production-grade AI systems: Develop your agents within our comprehensive evaluation suite, ensuring production-ready performance from day one.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;Requirements&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experience architecting, developing, and testing full-stack code end-to-end&lt;/item&gt;
          &lt;item&gt;Expertise in programming languages such as Python, Go and ML/NLP libraries such as PyTorch, TensorFlow, Transformers&lt;/item&gt;
          &lt;item&gt;Being proactive and a fast-learner with bias for action&lt;/item&gt;
          &lt;item&gt;Experience working with relational and non-relational databases, especially Postgres&lt;/item&gt;
          &lt;item&gt;Experience with data and ML infrastructure&lt;/item&gt;
          &lt;item&gt;Open source contributions and projects are a big plus&lt;/item&gt;
          &lt;item&gt;Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization technologies (e.g., Docker, Kubernetes) is a plus&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;Trellis helps healthcare providers treat more patients, faster‚Äîwhile eliminating pre-service paperwork.&lt;/p&gt;
      &lt;p&gt;We automate document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care.&lt;/p&gt;
      &lt;p&gt;Our AI agent is trained on millions of clinical data points and converts messy, unstructured documents into clean, structured data directly in your EHR.&lt;/p&gt;
      &lt;p&gt;With Trellis, leading healthcare providers and pharmaceutical companies were able to:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Reduce time to treatment by over 90%&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Improve prior authorization approval and reimbursement rates&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Leverage structured data to enhance drug program performance and clinical decision-making&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Administrative costs account for over 20% of U.S. healthcare spending‚Äîdelaying care, draining revenue, and driving staff burnout while having less visibility into patient care than ever before. We built Trellis to tackle this head on.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/trellis-ai/jobs/ngvfeaq-member-of-technical-staff-full-time"/><published>2026-01-04T17:01:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46491486</id><title>Claude Code On-the-Go</title><updated>2026-01-05T16:15:25.266763+00:00</updated><content>&lt;doc fingerprint="54244cd2df97e3eb"&gt;
  &lt;main&gt;
    &lt;p&gt;I run six Claude Code agents in parallel from my phone. No laptop, no desktop‚Äîjust Termius on iOS and a cloud VM.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Setup&lt;/head&gt;
    &lt;code&gt;flowchart LR
    A[Phone] --&amp;gt;|Termius + mosh| B[Tailscale VPN]
    B --&amp;gt; C[Vultr VM]
    C --&amp;gt; D[Claude Code]
    D --&amp;gt;|PreToolUse hook| E[Poke webhook]
    E --&amp;gt;|Push notification| A
&lt;/code&gt;
    &lt;p&gt;The loop is: kick off a task, pocket the phone, get notified when Claude needs input. Async development from anywhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;Infrastructure&lt;/head&gt;
    &lt;p&gt;A Vultr VM in Silicon Valley:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Spec&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Instance&lt;/cell&gt;
        &lt;cell&gt;vhf-8c-32gb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cost&lt;/cell&gt;
        &lt;cell&gt;$0.29/hr (~$7/day when running)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Access&lt;/cell&gt;
        &lt;cell&gt;Tailscale-only (no public SSH)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I pay only when working. Two scripts handle lifecycle:&lt;/p&gt;
    &lt;code&gt;vm-start   # Start VM, wait for Tailscale, connect via mosh
vm-stop    # Halt VM
&lt;/code&gt;
    &lt;p&gt;I also have an iOS Shortcut that calls the Vultr API directly‚Äîstart the VM from my phone before I even open Termius.&lt;/p&gt;
    &lt;p&gt;The VM‚Äôs public IP has no SSH listener. All access goes through Tailscale‚Äôs private network. Defense in depth: cloud firewall blocks everything except Tailscale coordination, local nftables as backup, fail2ban for good measure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mobile Terminal&lt;/head&gt;
    &lt;p&gt;Termius handles SSH and mosh on iOS/Android. Mosh is the key‚Äîit survives network transitions. Switch from WiFi to cellular, walk through a dead zone, put the phone to sleep. The connection persists.&lt;/p&gt;
    &lt;code&gt;mosh --ssh="ssh -p 47892" [email¬†protected]
&lt;/code&gt;
    &lt;p&gt;One gotcha: mosh doesn‚Äôt forward SSH agent. For git operations that need GitHub auth, I use regular SSH inside tmux.&lt;/p&gt;
    &lt;head rend="h2"&gt;Session Persistence&lt;/head&gt;
    &lt;p&gt;The shell auto-attaches to tmux on login. Close Termius, reopen hours later, everything‚Äôs still there.&lt;/p&gt;
    &lt;code&gt;# In .zshrc
if [[ -z "$TMUX" ]]; then
    tmux attach -t main 2&amp;gt;/dev/null || tmux new -s main
fi
&lt;/code&gt;
    &lt;p&gt;Multiple Claude agents run in parallel windows. &lt;code&gt;C-a c&lt;/code&gt; for new window, &lt;code&gt;C-a n&lt;/code&gt; to cycle. Works well on a phone keyboard.&lt;/p&gt;
    &lt;head rend="h2"&gt;Push Notifications&lt;/head&gt;
    &lt;p&gt;This is what makes mobile development practical. Without notifications, you‚Äôd constantly check the terminal. With them, you can walk away.&lt;/p&gt;
    &lt;p&gt;The hook in &lt;code&gt;~/.claude/settings.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;{
  "hooks": {
    "PreToolUse": [{
      "matcher": "AskUserQuestion",
      "hooks": [{
        "type": "command",
        "command": "~/.claude/hooks/poke-notify.sh question"
      }]
    }]
  }
}
&lt;/code&gt;
    &lt;p&gt;When Claude calls &lt;code&gt;AskUserQuestion&lt;/code&gt;, the hook fires. A simple script extracts the question and POSTs to Poke‚Äôs webhook:&lt;/p&gt;
    &lt;code&gt;QUESTION=$(echo "$EVENT_DATA" | jq -r '.tool_input.questions[0].question')
MESSAGE="$PROJECT_NAME: Claude needs input - $QUESTION"
curl -X POST "$API_URL" -d "{\"message\": \"$MESSAGE\"}"
&lt;/code&gt;
    &lt;p&gt;Phone buzzes. Notification shows the question. Tap, respond, continue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trust Model&lt;/head&gt;
    &lt;p&gt;I run Claude Code in permissive mode. The VM is isolated‚Äîno access to production systems, no secrets beyond what‚Äôs needed for development. Worst case: Claude does something unexpected on a disposable VM.&lt;/p&gt;
    &lt;p&gt;Cost control adds another layer. The VM costs $0.29/hr. Even if something runs away, the daily cap is bounded.&lt;/p&gt;
    &lt;head rend="h2"&gt;Parallel Development&lt;/head&gt;
    &lt;p&gt;Git worktrees let me run multiple features simultaneously:&lt;/p&gt;
    &lt;code&gt;~/Code/myproject/              # main
~/Code/myproject-sidebar/      # feature branch
~/Code/myproject-dark-mode/    # another feature
&lt;/code&gt;
    &lt;p&gt;Each worktree gets its own tmux window with a Claude agent. Port allocation is hash-based‚Äîdeterministic from branch name, no conflicts:&lt;/p&gt;
    &lt;code&gt;hash_val = sum(ord(c) for c in branch_name)
django_port = 8001 + (hash_val % 99)
&lt;/code&gt;
    &lt;p&gt;Six agents, six features, one phone.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This Enables&lt;/head&gt;
    &lt;p&gt;Review PRs while waiting for coffee. Kick off a refactor on the train. Fix a bug from the couch while watching TV.&lt;/p&gt;
    &lt;p&gt;The pattern: start a task that will take Claude 10-20 minutes, do something else, get notified, respond, repeat. Development fits into the gaps of the day instead of requiring dedicated desk time.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Components&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vultr&lt;/cell&gt;
        &lt;cell&gt;Cloud VM ($0.29/hr, pay-per-use)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tailscale&lt;/cell&gt;
        &lt;cell&gt;Private network, secure access&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Termius&lt;/cell&gt;
        &lt;cell&gt;iOS/Android SSH client&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mosh&lt;/cell&gt;
        &lt;cell&gt;Network-resilient shell&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;tmux&lt;/cell&gt;
        &lt;cell&gt;Session persistence&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Poke&lt;/cell&gt;
        &lt;cell&gt;Push notifications via webhook&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Claude Code&lt;/cell&gt;
        &lt;cell&gt;The actual work&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The setup took one Claude Code session to build‚Äîgave it my Vultr API key and access to &lt;code&gt;gh&lt;/code&gt;, asked for a secure dev VM. Now I code from my phone.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://granda.org/en/2026/01/02/claude-code-on-the-go/"/><published>2026-01-04T19:48:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46491749</id><title>Show HN: Terminal UI for AWS</title><updated>2026-01-05T16:15:24.623860+00:00</updated><content>&lt;doc fingerprint="2e14c8f8c697e1a6"&gt;
  &lt;main&gt;
    &lt;p&gt;taws provides a terminal UI to interact with your AWS resources. The aim of this project is to make it easier to navigate, observe, and manage your AWS infrastructure in the wild. taws continually watches AWS for changes and offers subsequent commands to interact with your observed resources.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-Profile Support - Easily switch between AWS profiles&lt;/item&gt;
      &lt;item&gt;Multi-Region Support - Navigate across different AWS regions&lt;/item&gt;
      &lt;item&gt;94+ Resource Types - Browse and manage resources across 60+ AWS services&lt;/item&gt;
      &lt;item&gt;Real-time Updates - Refresh resources with a single keystroke&lt;/item&gt;
      &lt;item&gt;Keyboard-Driven - Vim-like navigation and commands&lt;/item&gt;
      &lt;item&gt;Resource Actions - Start, stop, terminate EC2 instances directly&lt;/item&gt;
      &lt;item&gt;Detailed Views - JSON/YAML view of resource details&lt;/item&gt;
      &lt;item&gt;Filtering - Filter resources by name or attributes&lt;/item&gt;
      &lt;item&gt;Autocomplete - Smart resource type autocomplete with fuzzy matching&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew install huseyinbabal/tap/taws&lt;/code&gt;
    &lt;code&gt;scoop bucket add huseyinbabal https://github.com/huseyinbabal/scoop-bucket
scoop install taws&lt;/code&gt;
    &lt;p&gt;Download the latest release from the Releases page.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Architecture&lt;/cell&gt;
        &lt;cell role="head"&gt;Download&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;Apple Silicon (M1/M2/M3)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;taws-aarch64-apple-darwin.tar.gz&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;Intel&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;taws-x86_64-apple-darwin.tar.gz&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;x86_64&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;taws-x86_64-unknown-linux-gnu.tar.gz&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;ARM64&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;taws-aarch64-unknown-linux-gnu.tar.gz&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;x86_64&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;taws-x86_64-pc-windows-msvc.zip&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# macOS Apple Silicon
curl -sL https://github.com/huseyinbabal/taws/releases/latest/download/taws-aarch64-apple-darwin.tar.gz | tar xz
sudo mv taws /usr/local/bin/

# macOS Intel
curl -sL https://github.com/huseyinbabal/taws/releases/latest/download/taws-x86_64-apple-darwin.tar.gz | tar xz
sudo mv taws /usr/local/bin/

# Linux x86_64
curl -sL https://github.com/huseyinbabal/taws/releases/latest/download/taws-x86_64-unknown-linux-gnu.tar.gz | tar xz
sudo mv taws /usr/local/bin/

# Linux ARM64
curl -sL https://github.com/huseyinbabal/taws/releases/latest/download/taws-aarch64-unknown-linux-gnu.tar.gz | tar xz
sudo mv taws /usr/local/bin/&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download &lt;code&gt;taws-x86_64-pc-windows-msvc.zip&lt;/code&gt;from the Releases page&lt;/item&gt;
      &lt;item&gt;Extract the zip file&lt;/item&gt;
      &lt;item&gt;Add the extracted folder to your PATH, or move &lt;code&gt;taws.exe&lt;/code&gt;to a directory in your PATH&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cargo install taws&lt;/code&gt;
    &lt;p&gt;taws is built with Rust. Make sure you have Rust 1.70+ installed, along with a C compiler and linker.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Install Command&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Amazon Linux / RHEL / Fedora&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sudo yum groupinstall "Development Tools" -y&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Ubuntu / Debian&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install build-essential -y&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;xcode-select --install&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;Install Visual Studio Build Tools&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/huseyinbabal/taws.git
cd taws

# Build and run
cargo build --release
./target/release/taws&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AWS Credentials - See Authentication section below&lt;/item&gt;
      &lt;item&gt;IAM Permissions - Your AWS user/role needs appropriate read permissions for the services you want to browse. At minimum, you'll need &lt;code&gt;Describe*&lt;/code&gt;and&lt;code&gt;List*&lt;/code&gt;permissions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;taws uses a credential chain, trying each source in order:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Priority&lt;/cell&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Environment Variables&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;, &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;, &lt;code&gt;AWS_SESSION_TOKEN&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;Credentials File&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;~/.aws/credentials&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Config File&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;~/.aws/config&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;IMDSv2&lt;/cell&gt;
        &lt;cell&gt;EC2 instance metadata (requires IAM role attached to instance)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;For local development, run &lt;code&gt;aws configure&lt;/code&gt; to set up credentials.&lt;/p&gt;
    &lt;p&gt;For EC2 instances, attach an IAM role with appropriate permissions to your instance. taws will automatically use IMDSv2 to fetch credentials.&lt;/p&gt;
    &lt;code&gt;# Launch taws with default profile
taws

# Launch with a specific profile
taws --profile production

# Launch in a specific region
taws --region us-west-2

# Enable debug logging
taws --log-level debug

# Run in read-only mode (blocks all write operations)
taws --readonly

# Use with LocalStack or custom endpoint
taws --endpoint-url http://localhost:4566

# Or via environment variable
AWS_ENDPOINT_URL=http://localhost:4566 taws&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Path&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;~/.config/taws/taws.log&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;~/Library/Application Support/taws/taws.log&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;%APPDATA%\taws\taws.log&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Navigation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Move up&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;k&lt;/code&gt; / &lt;code&gt;‚Üë&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Move selection up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Move down&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;j&lt;/code&gt; / &lt;code&gt;‚Üì&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Move selection down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Page up&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl-u&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Move up by page&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Page down&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl-d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Move down by page&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Top&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;g&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Jump to first item&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bottom&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;G&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Jump to last item&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Views&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Resource picker&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;:&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open resource type selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Describe&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;Enter&lt;/code&gt; / &lt;code&gt;d&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;View resource details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Back&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Esc&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go back to previous view&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Help&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show help screen&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Actions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Refresh&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;r&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Refresh current view&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Filter&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Filter resources&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Profiles&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;p&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Switch AWS profile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Regions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;R&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Switch AWS region&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Quit&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;q&lt;/code&gt; / &lt;code&gt;Ctrl-c&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Exit taws&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;EC2 Actions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Start instance&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;s&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start selected EC2 instance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Stop instance&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;S&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop selected EC2 instance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Terminate&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;T&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Terminate selected EC2 instance&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Press &lt;code&gt;:&lt;/code&gt; to open the resource picker. Type to filter resources:&lt;/p&gt;
    &lt;code&gt;:ec2          # EC2 Instances
:lambda       # Lambda Functions
:s3           # S3 Buckets
:rds          # RDS Instances
:iam-users    # IAM Users
:eks          # EKS Clusters
&lt;/code&gt;
    &lt;p&gt;Use &lt;code&gt;Tab&lt;/code&gt; to autocomplete and &lt;code&gt;Enter&lt;/code&gt; to select.&lt;/p&gt;
    &lt;p&gt;taws supports 30 AWS services with 49 resource types covering 95%+ of typical AWS usage:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Service&lt;/cell&gt;
        &lt;cell role="head"&gt;Resources&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Compute&lt;/cell&gt;
        &lt;cell&gt;EC2&lt;/cell&gt;
        &lt;cell&gt;Instances&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Lambda&lt;/cell&gt;
        &lt;cell&gt;Functions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ECS&lt;/cell&gt;
        &lt;cell&gt;Clusters, Services, Tasks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;EKS&lt;/cell&gt;
        &lt;cell&gt;Clusters&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Auto Scaling&lt;/cell&gt;
        &lt;cell&gt;Auto Scaling Groups&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;S3&lt;/cell&gt;
        &lt;cell&gt;Buckets&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Database&lt;/cell&gt;
        &lt;cell&gt;RDS&lt;/cell&gt;
        &lt;cell&gt;Instances, Snapshots&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DynamoDB&lt;/cell&gt;
        &lt;cell&gt;Tables&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ElastiCache&lt;/cell&gt;
        &lt;cell&gt;Clusters&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Networking&lt;/cell&gt;
        &lt;cell&gt;VPC&lt;/cell&gt;
        &lt;cell&gt;VPCs, Subnets, Security Groups&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ELBv2&lt;/cell&gt;
        &lt;cell&gt;Load Balancers, Listeners, Rules, Target Groups, Targets&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Route 53&lt;/cell&gt;
        &lt;cell&gt;Hosted Zones&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CloudFront&lt;/cell&gt;
        &lt;cell&gt;Distributions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;API Gateway&lt;/cell&gt;
        &lt;cell&gt;REST APIs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Security&lt;/cell&gt;
        &lt;cell&gt;IAM&lt;/cell&gt;
        &lt;cell&gt;Users, Groups, Roles, Policies, Access Keys&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Secrets Manager&lt;/cell&gt;
        &lt;cell&gt;Secrets&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;KMS&lt;/cell&gt;
        &lt;cell&gt;Keys&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ACM&lt;/cell&gt;
        &lt;cell&gt;Certificates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Cognito&lt;/cell&gt;
        &lt;cell&gt;User Pools&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Management&lt;/cell&gt;
        &lt;cell&gt;CloudFormation&lt;/cell&gt;
        &lt;cell&gt;Stacks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CloudWatch&lt;/cell&gt;
        &lt;cell&gt;Log Groups&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CloudTrail&lt;/cell&gt;
        &lt;cell&gt;Trails&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SSM&lt;/cell&gt;
        &lt;cell&gt;Parameters&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;STS&lt;/cell&gt;
        &lt;cell&gt;Caller Identity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Messaging&lt;/cell&gt;
        &lt;cell&gt;SQS&lt;/cell&gt;
        &lt;cell&gt;Queues&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SNS&lt;/cell&gt;
        &lt;cell&gt;Topics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;EventBridge&lt;/cell&gt;
        &lt;cell&gt;Event Buses, Rules&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Containers&lt;/cell&gt;
        &lt;cell&gt;ECR&lt;/cell&gt;
        &lt;cell&gt;Repositories&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DevOps&lt;/cell&gt;
        &lt;cell&gt;CodePipeline&lt;/cell&gt;
        &lt;cell&gt;Pipelines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CodeBuild&lt;/cell&gt;
        &lt;cell&gt;Projects&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Analytics&lt;/cell&gt;
        &lt;cell&gt;Athena&lt;/cell&gt;
        &lt;cell&gt;Workgroups&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Missing a service? Start a discussion to propose adding it!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See Authentication for credential setup.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_PROFILE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default AWS profile to use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_REGION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default AWS region&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fallback region (if &lt;code&gt;AWS_REGION&lt;/code&gt; not set)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;AWS access key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;AWS secret key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_SESSION_TOKEN&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;AWS session token (for temporary credentials)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;AWS_ENDPOINT_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Custom endpoint URL (for LocalStack, etc.)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Some resources may require specific IAM permissions not covered by basic read-only policies&lt;/item&gt;
      &lt;item&gt;Resource counts may vary during loading due to pagination&lt;/item&gt;
      &lt;item&gt;Some global services (IAM, Route53, CloudFront) always use us-east-1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome! Please see our Contributing Guide for details.&lt;/p&gt;
    &lt;p&gt;Important: Before adding a new AWS service, please start a discussion first.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inspired by k9s - the awesome Kubernetes CLI&lt;/item&gt;
      &lt;item&gt;Built with Ratatui - Rust TUI library&lt;/item&gt;
      &lt;item&gt;Uses aws-sigv4 for request signing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è for the AWS community&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/huseyinbabal/taws"/><published>2026-01-04T20:17:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46491821</id><title>Why does a least squares fit appear to have a bias when applied to simple data?</title><updated>2026-01-05T16:15:24.473636+00:00</updated><content/><link href="https://stats.stackexchange.com/questions/674129/why-does-a-linear-least-squares-fit-appear-to-have-a-bias-when-applied-to-simple"/><published>2026-01-04T20:25:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46494734</id><title>During Helene, I just wanted a plain text website</title><updated>2026-01-05T16:15:23.835601+00:00</updated><content>&lt;doc fingerprint="67d6095359d142df"&gt;
  &lt;main&gt;
    &lt;p&gt;We recently passed the one-year anniversary of Hurricane Helene and its devastating impact on Western North Carolina. As a web developer, I am thinking again about my experience with the mobile web on the day after the storm.&lt;/p&gt;
    &lt;p&gt;We recently passed the one-year anniversary of Hurricane Helene and its devastating impact on Western North Carolina. When the storm hit, causing widespread flooding, it wasn‚Äôt just the power that was knocked out for weeks due to all the downed trees. Many cell towers were damaged, leaving people with little to no access to life-saving emergency information.&lt;/p&gt;
    &lt;p&gt;As a web developer, I am thinking again about my experience with the mobile web on the day after the storm, and the following week. I remember trying in vain to find out info about the storm damage and road closures‚Äîwatching loaders spin and spin on blank pages until they timed out trying to load. Once in a while, pages would finally load or partially load, and I could actually click a second or third link. We had a tiny bit of service but not much. At one point we drove down our main street to find service; eventually finding cars congregating in a closed fast-food parking lot, where there were a few bars of service!&lt;/p&gt;
    &lt;p&gt;When I was able to load some government and emergency sites, problems with loading speed and website content became very apparent. We tried to find out the situation with the highways on the government site that tracks road closures. I wasn‚Äôt able to view the big slow loading interactive map and got a pop-up with an API failure message. I wish the main closures had been listed more simply, so I could have seen that the highway was completely closed by a landslide.&lt;/p&gt;
    &lt;p&gt;Other emergency sites I was able to reach had excessive media being loaded like image sliders. At one point, I was linked to an emergency site by a recently updated banner, navigated there, and then clicked an emergency message there that looped me back to the original site I was on. Some time after the storm hit, the local county site put up a message that they were displaying a ‚Äúfaster loading‚Äù experience. Which begs the question of why sites like this are not fast loading to begin with.&lt;/p&gt;
    &lt;head rend="h2"&gt;The best bulleted list I‚Äôve ever read&lt;/head&gt;
    &lt;p&gt;With a developing disaster situation, obviously not all information can be perfect. During the outages, many people got information from the local radio station‚Äôs ongoing broadcasts. The best information I received came from an unlikely place: a simple bulleted list in a daily email newsletter from our local state representative. Every day that newsletter listed food and water, power and gas, shelter locations, road and cell service updates, etc.&lt;/p&gt;
    &lt;p&gt;I was struck by how something as simple as text content could have such a big impact.&lt;/p&gt;
    &lt;p&gt;In having the best information provided in a simple newsletter list, I found myself wishing for faster loading and more direct websites. Especially ones with this sort of info. At that time, even a plain text site with barely any styles or images would have been better.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simply going back to the basics can make the web a better place&lt;/head&gt;
    &lt;p&gt;Outside of the storm situation, we need to talk about loading speed and performance. For many years now, loading speed has been more important than ever because most web traffic is on mobile devices. That‚Äôs nothing new. Yet the web is still filled with a lot of bloat. We have free browser tools to test speed, performance, and slow connection speeds. And we have lightweight architectures or frameworks to choose from.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Is it necessary to have 5MB+ of loaded network assets and over 100 network requests to view a simple brochure-style site?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Why do I still need to download a 10MB PDF for most restaurants, when that could be headings and paragraph text on a webpage that is easy for the restaurant to edit?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Does a WordPress site really need 40 or more plugins?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Why isn‚Äôt page speed discussed and tested earlier in the design and development process? Why does this not seem like a big concern to a lot of businesses?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Limited connectivity isn‚Äôt something that only happens during natural disasters. It can happen all the time in our daily lives. In more rural areas around me, service is already pretty spotty. In the past, while working outdoors in an area without Wi-Fi, I‚Äôve found myself struggling to load or even find instruction manuals or how-to guides from various product manufacturers.&lt;/p&gt;
    &lt;p&gt;We deserve better from not just our government websites, but our local utilities, banks, and healthcare providers. Some are better than others. Out of curiosity, I ran a Google Page Speed Insights scan on one government site that had given me trouble, and received performance scores that were 40 out of 100 and 26 out of 100.&lt;/p&gt;
    &lt;p&gt;We deserve better not just in terms of performance, but with content, information architecture, and basic functionality.&lt;/p&gt;
    &lt;p&gt;A local county has a PDF to explain how to use a part of the website, including what parts of it don‚Äôt work and need to be sent manually. At one point, it displayed a message that the software was only working in Microsoft Edge and not Chrome. The last couple times I used my dental insurance website, it was completely not mobile responsive, requiring the old-school pinch zoom to even get to anything on the page. And the provider search was barely usable and hard to find. This is shocking to see for multi-billion and multi-million dollar companies.&lt;/p&gt;
    &lt;p&gt;These are times when we need to go back to basics when building for the web. For a baseline level of page speed, we can avoid too many scripts, giant media assets on key pages, and holding up the page from loading. We can build things so the JavaScript bundles are not excessively large. Going beyond basics, there‚Äôs a lot that can be optimized for the ‚Äúfirst contentful paint‚Äù and reducing the time before the page can be interacted with (these are part of page speed scans).&lt;/p&gt;
    &lt;p&gt;Just using Semantic HTML and the correct native elements, we also can set a baseline for better accessibility. And make sure interactive elements can be reached with a keyboard and screen readers have a good sense of what things are on the page. Making websites responsive for mobile devices is not optional, and devs have had the CSS tools and experience to do this for over a decade. Information architecture and content is important to plan and revisit. What content are you really trying to provide and how do you get to it?&lt;/p&gt;
    &lt;p&gt;To find areas like these that need improvement, it might just take a conversation with your users and developers. They already know and are experiencing the pain points. The information your user needs the most could just be a simple paragraph or a bulleted list.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sparkbox.com/foundry/helene_and_mobile_web_performance"/><published>2026-01-05T02:36:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46496054</id><title>A spider web unlike any seen before</title><updated>2026-01-05T16:15:23.652836+00:00</updated><content/><link href="https://www.nytimes.com/2025/11/08/science/biggest-spiderweb-sulfur-cave.html"/><published>2026-01-05T07:06:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46496103</id><title>Databases in 2025: A Year in Review</title><updated>2026-01-05T16:15:22.891354+00:00</updated><content>&lt;doc fingerprint="2714991b957a35cc"&gt;
  &lt;main&gt;
    &lt;p&gt;Another year passes. I was hoping to write more articles instead of just these end-of-the-year screeds, but I almost died in the spring semester, and it sucked up my time. Nevertheless, I will go through what I think are the major trends and happenings in databases over the last year.&lt;/p&gt;
    &lt;p&gt;There were many exciting and unprecedented developments in the world of databases. Vibe coding entered the vernacular. The Wu-Tang Clan announced their time capsule project. Rather than raising one massive funding round this year instead of going public, Databricks raised two massive rounds instead of going public.&lt;/p&gt;
    &lt;p&gt;Meanwhile, other events were expected and less surprising. Redis Ltd. switched their license back one year after their rugpull (I called this shot last year). SurrealDB reported great benchmark numbers because they weren't flushing writes to disk and lost data. And Coldplay can break up your marriage. Astronomer did make some pretty good lemonade on that last one though.&lt;/p&gt;
    &lt;p&gt;With that out of the way, let's do this. These articles are getting longer each year, so I apologize in advance.&lt;/p&gt;
    &lt;p&gt;Previous entries:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Databases in 2024: A Year in Review&lt;/item&gt;
      &lt;item&gt;Databases in 2023: A Year in Review&lt;/item&gt;
      &lt;item&gt;Databases in 2022: A Year in Review&lt;/item&gt;
      &lt;item&gt;Databases in 2021: A Year in Review&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Dominance of PostgreSQL Continues&lt;/head&gt;
    &lt;p&gt;I first wrote about how PostgreSQL was eating the database world in 2021. That trend continues unabated as most of the most interesting developments in the database world are happening once again with PostgreSQL. The DBMS's latest version (v18) dropped in November 2025. The most prominent feature is the new asynchronous I/O storage subsystem, which will finally put PostgreSQL on the path to dropping its reliance on the OS page cache. It also added support for skip scans; queries can still use multi-key B+Tree indexes even if they are missing the leading keys (i.e., prefix). There are some additional improvements to the query optimizer (e.g., removing superfluous self-joins).&lt;/p&gt;
    &lt;p&gt;Savvy database connoisseurs will be quick to point out that these are not groundbreaking features and that other DBMSs have had them for years. PostgreSQL is the only major DBMS still relying on the OS page cache. And Oracle has supported skip scans since 2002 (v9i)! You may wonder, therefore, why I am claiming that the hottest action in databases for 2025 happened with PostgreSQL?&lt;/p&gt;
    &lt;p&gt;The reason is that most of the database energy and activity is going into PostgreSQL companies, offerings, projects, and derivative systems.&lt;/p&gt;
    &lt;head rend="h4"&gt;Acquisitions + Releases:&lt;/head&gt;
    &lt;p&gt;In the last year, the hottest data start-up (Databricks) paid $1b for a PostgreSQL DBaaS company (Neon). Next, one of the biggest database companies in the world (Snowflake) paid $250m for another PostgreSQL DBaaS company (CrunchyData). Then, one of the biggest tech companies on the planet (Microsoft) launched a new PostgreSQL DBaaS (HorizonDB). Neon and HorizonDB follow Amazon Aurora's original high-level architecture from the 2010s, with a single primary node separating compute and storage. For now, Snowflake's PostgreSQL DBaaS uses the same core architecture as standard PostgreSQL because they built on Crunchy Bridge.&lt;/p&gt;
    &lt;head rend="h4"&gt;Distributed PostgreSQL:&lt;/head&gt;
    &lt;p&gt;All of the services I listed above are single-primary node architectures. That is, applications send writes to a primary node, which then sends those changes to secondary replicas. But in 2025, there were two announcements on new projects to create scale-out (i.e., horizontal partitioning) services for PostgreSQL. In June 2025, Supabase announced that it had hired Sugu, the Vitess co-creator and former PlanetScale co-founder/CTO, to lead the Multigres project to create sharding middleware for PostgreSQL, similar to how Vitess shards MySQL. Sugu left PlanetScale in 2023 and had to lie back in the cut for two years. He is now likely clear of any legal issues and can make things happen at Supabase. You know it is a big deal when a database engineer joins a company, and the announcement focuses more on the person than the system. The co-founder/CTO of SingleStore joined Microsoft in 2024 to lead HorizonDB, but Microsoft (incorrectly) did not make a big deal about it. Sugu joining Supabase is like Ol' Dirty Bastard (RIP) getting out on parole after two years and then announcing a new record deal on the first day of his release.&lt;/p&gt;
    &lt;p&gt;One month after the Multigres news dropped, PlanetScale announced its own Vitess-for-PostgreSQL project, Neki. PlanetScale launched its initial PostgreSQL DBaaS in March 2025, but the core architecture is single-node stock PostgreSQL with pgBouncer.&lt;/p&gt;
    &lt;head rend="h4"&gt;Commercial Landscape:&lt;/head&gt;
    &lt;p&gt;With Microsoft's introduction of HorizonDB in 2025, all major cloud vendors now have serious projects for their own PostgreSQL offerings. Amazon has offered Aurora PostgreSQL since 2017. Google put out AlloyDB in 2022. ServiceNow launched its RaptorDB service in 2024, based on its 2021 acquisition of Swarm64. Even the old flip-phone IBM has had its cloud version of PostgreSQL since 2018. Oracle released its PostgreSQL service in 2023, though there is a rumor that its in-house PostgreSQL team was collateral damage in its MySQL OCI layoffs in September 2025.&lt;/p&gt;
    &lt;p&gt;There are still a few independent (ISV) PostgreSQL DBaaS companies. Supabase is likely the largest of these by the number of instances. Others include YugabyteDB, TigerData (n√É¬©e TimeScale), PlanetScale, Xata, PgEdge, and Nile. Xata built its original architecture on Amazon Aurora, but this year, it announced it is switching to its own infrastructure. ParadeDB has yet to announce its hosted service. Tembo dropped its hosted PostgreSQL offering in 2025 to pivot to a coding agent that can do some database tuning. Hydra and PostgresML went bust in 2025 (see Deaths section), so they're out of the game. Other systems provide a Postgres-compatible front-end, but the back-end systems are not derived from PostgreSQL (e.g., CockroachDB, CedarDB, Google Spanner). There are also hosting companies that offer PostgreSQL DBaaS alongside other systems, such as Aiven and Tessel.&lt;/p&gt;
    &lt;head rend="h3"&gt;Andy's Take:&lt;/head&gt;
    &lt;p&gt;It is not clear who the next major buyer will be after Databricks and Snowflake bought PostgreSQL companies. Again, every major tech company already has a Postgres offering. EnterpriseDB is the oldest PostgreSQL ISV, but missed out on the two most significant PostgreSQL acquisitions in the last five years. But they can ride Bain Capital's jock for a while, or hope that HPE buys them even though that partnership is from eight years ago. The PostgreSQL M&amp;amp;A playfield is reminiscent of OLAP acquisitions in the late 2000s, when Vertica was the last one waiting at the bus stop after AsterData, Greenplum, and DATAllegro were acquired.&lt;/p&gt;
    &lt;p&gt;The development of the two competing distributed PostgreSQL projects (Multigres, Neki) is welcome news. These projects are not the first time somebody has attempted this: Greenplum, ParAccel, and Citus have been around for two decades for OLAP workloads. Citus supports OLTP workloads, but they started in 2010 focused on analytics. For OLTP, 15 years ago, the NTT RiTaDB project joined forces with GridSQL to create Postgres-XC. Developers from Postgres-XC founded StormDB, which Translattice later acquired in 2013. Postgres-X2 was an attempt to modernize XC, but the developers abandoned that effort. Translattice open-sourced StormDB as Postgres-XL, but the project has been dormant since 2018. YugabyteDB came out in 2016 and is probably the most widely deployed sharded PostgreSQL system (and remains open-source!), but it is a hard fork, so it is only compatible with PostgreSQL v15. Amazon announced its own sharded PostgreSQL (Aurora Limitless) in 2024, but it is closed source.&lt;/p&gt;
    &lt;p&gt;I know Microsoft bought Citus in 2019 but it is hard to keep track of what they were doing before HorizonDB because of their confusing product names. Citus was rebranded as Azure Database for PostgreSQL Hyperscale in 2019 and was then renamed to Azure Cosmos DB for PostgreSQL in 2022. But then there is Azure Database for PostgreSQL with Elastic Clusters that also uses Citus, but it is not the same as the Citus-powered Azure Cosmos DB for PostgreSQL. Microsoft discontinued Azure PostgreSQL Single Server in 2023, but kept Azure PostgreSQL Flexible Server. That is a lot of Azure this and Azure that. It is sort of like how Amazon could not resist adding "Aurora" to DSQL's name. Either way, at least Microsoft was smart enough to keep the name for their new system to just "Azure HorizonDB" (for now).&lt;/p&gt;
    &lt;p&gt;The PlanetScale squad has no love for the other side and is known to throw hands at Neon and Timescale. Database companies popping off at each other is nothing new (see Yugabyte vs. CockroachDB or Databricks vs. Snowflake). I suspect we will see more of this in the future as the PostgreSQL wars heat up. I suggest that these smaller companies call out the big cloud vendors and keep each other's name out of their mouths.&lt;/p&gt;
    &lt;head rend="h2"&gt;MCP For Every Database!&lt;/head&gt;
    &lt;p&gt;If 2023 was the year every DBMS added a vector index, then 2025 was the year that every DBMS added support for Anthropic's Model Context Protocol (MCP). MCP is a standardized client-server JSON-RPC interface that lets LLMS interact with external tools and data sources without requiring custom glue code. An MCP server acts as middleware in front of a DBMS and exposes a listing of tools, data, and actions it provides. An MCP client (e.g., an LLM host such as Claude or ChatGPT) discovers and uses these tools to extend its models' capabilities by sending requests to the server. In the case of databases, the MCP server converts these queries into the appropriate database query (e.g., SQL) or administrative command. In other words, MCP is the middleman who keeps the bricks counted and the cream straight, so the database and LLMs trust each other enough to do business.&lt;/p&gt;
    &lt;p&gt;Anthropic announced MCP in November 2024, but it really took off in March 2025 when OpenAI announced it would support MCP in its ecosystem. Over the next few months, every DBMS vendor released MCP servers for all system categories: OLAP (e.g., ClickHouse, Snowflake, Firebolt, Yellowbrick), SQL (e.g., YugabyteDB, Oracle, PlanetScale), and NoSQL (e.g., MongoDB, Neo4j, Redis). Since there is no official Postgres MCP server, every Postgres DBaaS has released its own (e.g., Timescale, Supabase, Xata). The cloud vendors released multi-database MCP servers that can talk to any of their managed database services (e.g., Amazon, Microsoft, Google). Allowing a single gateway to talk to heterogeneous databases is almost, but not quite, a holy-grail federated database. As far as I know, each request in these MCP servers targets only a single database at a time, so the application is responsible for performing joins across sources.&lt;/p&gt;
    &lt;p&gt;Beyond the official vendor MCP implementations, there are hundreds of rando MCP server implementations for nearly every DBMS. Some of them attempt to support multiple systems (e.g., DBHub, DB MCP Server). DBHub put out a good overview of PostgreSQL MCP servers.&lt;/p&gt;
    &lt;p&gt;An interesting feature that has proven helpful for agents is database branching. Although not specific to MCP servers, branching allows agents to test database changes quickly without affecting production applications. Neon reported in July 2025 that agents create 80% of their databases. Neon was designed from the beginning to support branching (Nikita showed me an early demo when the system was still called "Zenith"), whereas other systems have added branching support later. See Xata's recent comparison article on database branching.&lt;/p&gt;
    &lt;head rend="h3"&gt;Andy's Take:&lt;/head&gt;
    &lt;p&gt;On one hand, I'm happy that there is now a standard for exposing databases to more applications. But nobody should trust an application with unfettered database access, whether it is via MCP or the system's regular API. And it remains good practice only to grant minimal privileges to accounts. Restricting accounts is especially important with unmonitored agents that may start going wild all up in your database. This means that lazy practices like giving admin privileges to every account or using the same account for every service are going to get wrecked when the LLM starts popping off. Of course, if your company leaves its database open to the world while you cause the stock price of one of the wealthiest companies to drop by $600b, then rogue MCP requests are not your top concern.&lt;/p&gt;
    &lt;p&gt;From my cursory examination of a few MCP server implementations, they are simple proxies that translate the MCP JSON requests into database queries. There is no deep introspection to understand what the request aims to do and whether it is appropriate. Somebody is going to try to order 18,000 water cups in your application, and you need to make sure it doesn't crash your database. Some MCP servers have basic protection mechanisms (e.g., ClickHouse only allows read-only queries). DBHub provides a few additional protections, such as capping the number of returned records per request and implementing query timeouts. Supabase's documentation offers best-practice guidelines for MCP agents, but they rely on humans to follow them. And of course, if you rely on humans to do the right thing, bad things will happen.&lt;/p&gt;
    &lt;p&gt;Enterprise DBMSs already have automated guardrails and other safety mechanisms that open-source systems lack, and thus, they are better prepared for an agentic ecosystem. For example, IBM Guardium and Oracle Database Firewall identify and block anomalous queries. I am not trying to shill for these big tech companies. I know we will see more examples in the future of agents ruining lives, like accidentally dropping databases. Combining MCP servers with proxies (e.g., connection pooling) is an excellent opportunity to introduce automated protection mechanisms.&lt;/p&gt;
    &lt;head rend="h2"&gt;MongoDB, Inc. v. FerretDB Inc.&lt;/head&gt;
    &lt;p&gt;MongoDB has been the NoSQL stalwart for two decades now. FerretDB was launched in 2021 by Percona's top brass to provide a middleware proxy that converts MongoDB queries into SQL for a PostgreSQL backend. This proxy allows MongoDB applications to switch over to PostgreSQL without rewriting queries.&lt;/p&gt;
    &lt;p&gt;They coexisted for a few years before MongoDB sent FerretDB a cease-and-desist letter in 2023, alleging that FerretDB infringes MongoDB's patents, copyrights, and trademarks, and that it violates MongoDB's license for its documentation and wire protocol specification. This letter became public in May 2025 when MongoDB went nuclear on FerretDB by filing a federal lawsuit over these issues. Part of their beef is that FerretDB is out on the street, claiming they have a "drop-in replacement" for MongoDB without authorization. MongoDB's court filing has all the standard complaints about (1) misleading developers, (2) diluting trademarks, and (3) damaging their reputation.&lt;/p&gt;
    &lt;p&gt;The story is further complicated by Microsoft's announcement that it donated its MongoDB-compatible DocumentDB to the Linux Foundation. The project website mentions that DocumentDB is compatible with the MongoDB drivers and that it aims to "build a MongoDB compatible open source document database". Other major database vendors, such as Amazon and Yugabyte, are also involved in the project. From a cursory glance, this language seems similar to what MongoDB is accusing FerretDB of doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Andy's Take:&lt;/head&gt;
    &lt;p&gt;I could not find an example of a database company suing another one for replicating their API. The closest is Oracle suing Google for using a clean-room copy of the Java API in Android. The Supreme Court ultimately ruled in favor of Google on fair use grounds, and the case affected how re-implementation is treated legally.&lt;/p&gt;
    &lt;p&gt;I don't know how the lawsuit will play out if it ever goes to trial. A jury of random people off the street may not be able to comprehend the specifics of MongoDB's wire protocol, but they are definitely going to understand that the original name of FerretDB was MangoDB. It is going to be challenging to convince a jury that you were not trying to divert customers when you changed one letter in the other company's name. Never mind that it is not even an original name: there is already a parody DBMS called MangoDB that writes everything to &lt;code&gt;/dev/null&lt;/code&gt; as a joke.&lt;/p&gt;
    &lt;p&gt;And while we are on the topic of database system naming, Microsoft's choice of "DocumentDB" is unfortunate. There are already Amazon DocumentDB (which, by the way, is also compatible with MongoDB, but Amazon probably pays for that), InterSystems DocDB, and Yugabyte DocDB. Microsoft's original name for "Cosmos DB" was also DocumentDB back in 2016.&lt;/p&gt;
    &lt;p&gt;Lastly, MongoDB's court filing claims they "pioneered the development of 'non-relational' databases". This statement is incorrect. The first general-purpose DBMSs were non-relational because the relational model had not yet been invented. General Electric's Integrated Data Store (1964) used a network data model, and IBM's Information Management System (1966) used a hierarchical data model. MongoDB is also not the first document DBMS. That title goes to the object-oriented DBMSs from the late 1980s (e.g., Versant) or the XML DBMSs from the 2000s (e.g., MarkLogic). MongoDB is the most successful of these approaches by a massive margin (except maybe IMS).&lt;/p&gt;
    &lt;head rend="h2"&gt;File Format Battleground&lt;/head&gt;
    &lt;p&gt;File formats are an area of data systems that have been mostly dormant for the last decade. In 2011, Meta released a column-oriented format for Hadoop called RCFile. Two years later, Meta refined RCFile and announced the PAX-based ORC (Optimized Record Columnar File) format. A month after ORC's release, Twitter and Cloudera released the first version of Parquet. Nearly 15 years later, Parquet is the dominant file open-source format.&lt;/p&gt;
    &lt;p&gt;In 2025, there were five new open-source file formats released vying to dethrone Parquet:&lt;/p&gt;
    &lt;p&gt;These new formats joined the other formats released in 2024:&lt;/p&gt;
    &lt;p&gt;SpiralDB made the biggest splash this year with their announcement of donating Vortex to the Linux Foundation and the establishment of their multi-organization steering committee. Microsoft quietly killed off Amudai (or at least closed sourced it) at some point at the end of 2025. The other projects (FastLanes, F3, Anyblox) are academic prototypes. Anyblox won the VLDB Best Paper award this year.&lt;/p&gt;
    &lt;p&gt;This fresh competition has lit a fire in the Parquet developer community to modernize its features. See this in-depth technical analysis of the columnar file format landscape by Parquet PMC Chair (Julien Le Dem).&lt;/p&gt;
    &lt;head rend="h3"&gt;Andy's Take:&lt;/head&gt;
    &lt;p&gt;The main problem with Parquet is not inherent in the format itself. The specification can and has evolved. Nobody expected organizations to rewrite petabytes of legacy files to update them to the latest Parquet version. The problem is that there are so many implementations of reader/writer libraries in different languages, each supporting a distinct subset of the specification. Our analysis of Paraquet files in the wild found that 94% of them use only v1 features from 2013, even though their creation timestamps are after 2020. This lowest common denominator means that if someone creates a Parquet file using v2 features, it is unclear whether a system will have the correct version to read it.&lt;/p&gt;
    &lt;p&gt;I worked on the F3 file format with brilliant people at Tsinghua (Xinyu Zeng, Ruijun Meng, Huanchen Zhang), CMU (Martin Prammer, Jignesh Patel), and Wes McKinney. Our focus is on solving this interoperability problem by providing both native decoders as shared objects (Rust crates) and embedded WASM versions of those decoders in the file. If somebody creates a new encoding and the DBMS does not have a native implementation, it can still read data using the WASM version by passing Arrow buffers. Each decoder targets a single column, allowing a DBMS to use a mix of native and WASM decoders for a single file. AnyBlox takes a different approach, generating a single WASM program to decode the entire file.&lt;/p&gt;
    &lt;p&gt;I don't know who will win the file format war. The next battle is likely to be over GPU support. SpiralDB seems to be making the right moves, but Parquet's ubiquity will be challenging to overcome. I also didn't even discuss how DuckLake seeks to upend Iceberg...&lt;/p&gt;
    &lt;p&gt;Of course, when this topic comes up, somebody always posts this xkcd comic on competing standards. I've seen it before. You don't need to email it to me again.&lt;/p&gt;
    &lt;head rend="h2"&gt;Random Happenings&lt;/head&gt;
    &lt;p&gt;Databases are big money. Let's go through them all!&lt;/p&gt;
    &lt;head rend="h4"&gt;Acquisitions:&lt;/head&gt;
    &lt;p&gt;Lots of movement on the block. Pinecone replaced its CEO in September to prepare for an acquisition, but I have not heard anything else about it. Here are the ones that did happen:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; DataStax √¢ IBM &lt;p&gt;The Cassandra stalwart got picked up by IBM at the beginning of the year for an estimated $3b.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Quickwit √¢ DataDog &lt;p&gt;The leading company behind the Lucene replacement, Tantivy, a full-text search engine, was acquired at the beginning of the year. The good news is that Tantivy development continues unabated.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; SDF √¢ dbt &lt;p&gt;This acquisition was a solid pick-up for dbt as part of their Fusion announcement this year. It allows them to perform more rigorous SQL analysis in their DAGs.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Voyage.ai √¢ MongoDB &lt;p&gt;Mongo picked up an early-stage AI company to expand its RAG capabilities in its cloud offering. One of my best students joined Voyage one week before the announcement. He thought he was going against the "family" by not signing with a database company, only to end up at one.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Neon √¢ Databricks &lt;p&gt;Apparently, there was a bidding war for this PostgreSQL company, but Databricks paid a mouthwatering $1b for it. Neon still exists today as a standalone service, but Databricks quickly rebranded it in its ecosystem as Lakebase.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; CrunchyData √¢ Snowflake &lt;p&gt;You know Snowflake could not let Databricks get all the excitement during the summer, so they paid $250m for the 13-year-old PostgreSQL company CrunchyData. Crunchy had picked up top ex-Citus talent in recent years and was expanding its DBaaS offering before Snowflake wrote them a check. Snowflake announced the public preview of its Postgres service in December 2025.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Informatica √¢ Salesforce &lt;p&gt;The 1990s old-school ETL company Informatica got picked up by Salesforce for $8b. This is after they went public in 1999, reverted to PE in 2015, and went public again in 2021.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Couchbase √¢ Private Equity &lt;p&gt;To be honest, I never understood how Couchbase went public in 2021. I guess they were riding on MongoDB's coattails? Couchbase did interesting work a few years ago by incorporating components from the AsterixDB project at UC Irvine.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Tecton √¢ Databricks &lt;p&gt;Tecton provides Databricks with additional tooling to build agents. Another one of my former students was at the company and is now at Databricks.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Tobiko Data √¢ Fivetran &lt;p&gt;This team is behind two useful tools: SQLMesh and SQLglot. The former is the only viable open-source contender to dbt (see below for their pending merger with Fivetran). SQLglot is a handy SQL parser/deparser that supports a heuristic-based query optimizer. The combination of this in Fivetran and SDF with dbt makes for an interesting technology play in this space in the coming years.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; SingleStore √¢ Private Equity &lt;p&gt;The PE firm buying SingleStore (Vector Capital) has prior experience in managing a database company. They previously purchased the XML database company MarkLogic in 2020 and flipped it to Progress in 2023.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Codership √¢ MariaDB &lt;p&gt;After getting bought by PE in 2024, the MariaDB Corporation went on a buying spree this year. The first up is the company behind the Galera Cluster scale-out middleware for MariaDB. See my 2023 overview of the MariaDB dumpster fire.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; SkySQL √¢ MariaDB &lt;p&gt;And then we have the second MariaDB acquisition. Just so everyone is clear, the original commercial company backing MariaDB was called "SkySQL Corporation" in 2010, but it changed its name to "MariaDB Corporation" in 2014. Then in 2020, the MariaDB Corporation released a MariaDB DBaaS called SkySQL. But because they were hemorrhaging cash, the MariaDB Corporation spun SkySQL Inc. out as an independent company in 2023. And now, in 2025, MariaDB Corporation has come full circle by buying back SkySQL Inc. I did not have this move on my database bingo card this year.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Crystal DBA √¢ Temporal &lt;p&gt;The automated database optimization tool company heads off to Temporal to automatically optimize their databases! I'm happy to hear that Crystal's founder and Berkeley database group alumnus Johann Schleier-Smith is doing well there.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; HeavyDB √¢ Nvidia &lt;p&gt;This system (formerly OmniSci, formerly MapD) was one of the first GPU-accelerated databases, launched in 2013. I couldn't find an official announcement of their closing, aside from an M&amp;amp;A firm listing the successful deal. And then we had a meeting with Nvidia to discuss potential database research collaborations, and some HeavyDB friends showed up.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; DGraph √¢ Istari Digital &lt;p&gt;Dgraph was previously acquired by Hypermode in 2023. It looks like Istari just bought Dgraph and not the rest of Hypermode (or they ditched it). I still haven't met anybody who is actively using Dgraph.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; DataChat √¢ Mews &lt;p&gt;This was one of the first "chat with your database" out of the University of Wisconsin and now CMU-DB professor Jignesh Patel. But they were bought by a European hotel management SaaS. Take that to mean what you think it means.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Datometry √¢ Snowflake &lt;p&gt;Datometry has been working on the perilous problem of automatically converting legacy SQL dialects (e.g., Teradata) to newer OLAP systems for several years. Snowflake picked them up to expand their migration tooling. See Datometry's 2020 CMU-DB tech talk for more info.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; LibreChat √¢ ClickHouse &lt;p&gt;Like Snowflake buying Datometry, ClickHouse's acquisition here is a good example of improving the developer experience for high-performance commodity OLAP engines.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Mooncake √¢ Databricks &lt;p&gt;After buying Neon, Databricks bought Mooncake to enable PostgreSQL to read/write to Apache Iceberg data. See their November 2025 CMU-DB talk for more info.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Confluent √¢ IBM &lt;p&gt;This is the archetype of how to make a company out of a grassroots open-source project. Kafka was originally developed at Linkedin in 2011. Confluent was then spun out as a separate startup in 2014. They went IPO seven years later in 2021. Then IBM wrote a big check to take it over. Like with DataStax, it remains to be seen whether IBM will do to Confluent what IBM normally does with acquired companies, or whether they will be able to remain autonomous like RedHat.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Gel √¢ Vercel &lt;p&gt;Formerly EdgeDB, they provided DSL on top of PostgreSQL that got picked up by Verel at the end of the year.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Kuzu √¢ ??? &lt;p&gt;The embedded graph DBMS out of the University of Waterloo was acquired by an unnamed company in 2025. The KuzuDB company then announced it was abandoning the open-source project. The LadybugDB project is an attempt at maintaining a fork of the Kuzu code.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Mergers:&lt;/head&gt;
    &lt;p&gt;Unexpected news dropped in October 2025 when Fivetran and dbt Labs announced they were merging to form a single company.&lt;/p&gt;
    &lt;p&gt;The last merger I can think of in the database space was the 2019 merger between Cloudera and Hortonworks. But that deal was just weak keys getting stepped on in a kitchen: two companies that were struggling to find market relevance with Hadoop merged into a single company to try to find it (spoiler: they did not). The MariaDB Corporation merger with Angel Pond Holdings Corporation in 2022 via a SPAC technically counts too, but that deal was so MariaDB could backdoor their way to IPO. And it didn't end well for investors. The Fivetran + dbt merger is different (and better) than these two. They are two complementary technology companies combining to become an ETL juggernaut, preparing for a legit IPO in the near future.&lt;/p&gt;
    &lt;head rend="h4"&gt;Funding:&lt;/head&gt;
    &lt;p&gt;Unless I missed them or they weren't announced, there were not as many early-stage funding rounds for database startups. The buzz around vector databases has muted, and VCs are only writing checks for LLM companies.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Databricks - $4b Series L&lt;/item&gt;
      &lt;item&gt;Databricks - $1b Series K&lt;/item&gt;
      &lt;item&gt;ClickHouse - $350m Series C&lt;/item&gt;
      &lt;item&gt;Supabase - $200m Series D&lt;/item&gt;
      &lt;item&gt;Timescale - $110m Series C&lt;/item&gt;
      &lt;item&gt;Supabase - $100m Series E&lt;/item&gt;
      &lt;item&gt;Astronomer - $93m Series D&lt;/item&gt;
      &lt;item&gt;Tessel - $60m Series B&lt;/item&gt;
      &lt;item&gt;Convex - $24m Series B&lt;/item&gt;
      &lt;item&gt;SpiralDB - $22m Series A&lt;/item&gt;
      &lt;item&gt;ParadeDB - $12m Series A&lt;/item&gt;
      &lt;item&gt;CedarDB $5.9m Seed&lt;/item&gt;
      &lt;item&gt;TopK - $5.5m Seed&lt;/item&gt;
      &lt;item&gt;Columnar - $4m Seed&lt;/item&gt;
      &lt;item&gt;SereneDB - $2.1m Pre-Seed&lt;/item&gt;
      &lt;item&gt;Starburst - Undisclosed?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Name Changes:&lt;/head&gt;
    &lt;p&gt;A new category in my yearly write-up is database companies changing the name of their company or system.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; HarperDB √¢ Harper &lt;p&gt;The JSON database company dropped the "DB" suffix from its name to emphasize its positioning as a platform for database-backed applications, similar to Convex and Heroku. I like the Harper people. Their 2021 CMU-DB tech talk presented the worst DBMS idea I have ever heard. Thankfully, they ditched that once they realized how bad it was and switched to LMDB.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; EdgeDB √¢ Gel &lt;p&gt;This was a smart move because the name "Edge" conveys that it is a database for edge devices or services (e.g., Fly.io). But I'm not sure "Gel" conveys the project's higher-level goals. See their 2025 CMU-DB talk on Gel's query language (still called EdgeQL) from a CMU Ph.D. alum.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Timescale √¢ TigerData &lt;p&gt;This is a rare occurrence of a database company renaming itself to distinguish itself from its main database product. It is usually companies renaming themselves to be the name of the database (e.g., "Relational Software, Inc." to "Oracle Systems Corporation", "10gen, Inc." to "MongoDB, Inc."). But it makes sense for the company to try to shed the perception of being a specialized time-series DBMS instead of an improved version of PostgreSQL for general applications, since the former is a much smaller market segment than the latter.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Deaths:&lt;/head&gt;
    &lt;p&gt;In full disclosure, I was a technical advisor for two of these failed startups. My success rate as an advisor is terrible at this point. I was also an advisor for Splice Machine, but they closed shop in 2021. In my defense, I only talk with these companies about technical ideas, not business strategies. And I did tell Fauna they should add SQL support, but they did not take my advice.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Fauna &lt;p&gt;An interesting distributed DBMS based on Dan Abadi's research for deterministic concurrency control. They provided strongly consistent transactions right when the NoSQL fade was waning, and Spanner made transactions cool again. But they had a proprietary query language and made big bets on GraphQL.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; PostgresML &lt;p&gt;The idea seemed obvious: enable people to run ML/AI operations inside of their PostgreSQL DBMS. The challenge was to convince people to migrate their existing databases to their hosted platform. They were pushing pgCat as a proxy to mirror database traffic. One of the co-founders joined Anthropic. The other co-founder created a new proxy project called pgDog.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Derby &lt;p&gt;This is one of the first DBMSs written in Java, dating back to 1997 (originally called "Java DB" or "JBMS"). IBM donated it to the Apache Foundation in the 2000s, and it was renamed as Derby. In October 2025, the project announced that the system would enter "read-only mode" because no one was actively maintaining it anymore.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Hydra &lt;p&gt;Although there is no official announcement for the DuckDB-inside-Postgres startup, the co-founders and employees have scattered to other companies.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; MyScaleDB &lt;p&gt;This was a fork of Clickhouse that adds vector search and full-text indexing using Tantivy. They announced they were closing in May 2025.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Voltron Data &lt;p&gt;This was supposed to be the supergroup of database companies. Think of it like having Run the Jewels team of heavy hitters. You had top engineers from Nvidia Rapids, the inventor of Apache Arrow and Python Pandas, and the Peruvian GPU wizards from BlazingSQL. Then throw in $110m in VC money from top firms that included the future CEO of Intel (and a board of trustee member at CMU). They built a GPU-accelerated database (Theseus), but failed to launch it in a timely manner.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lastly, although not a business, I would be remiss not to mention the closing of IBM Research Almaden. IBM built this site in 1986 and was the database research mecca for decades. I interviewed at Almaden in 2013 and found the scenery to be beautiful. The IBM Research Database Group is not what it used to be. Still, the alum list of this hallowed database ground is impressive: Rakesh Agrawal, Donald Chamberlin, Ronald Fagin, Laura Haas, Mohan, Pat Selinger, Moshe Vardi, Jennifer Widom, and Guy Lohman.&lt;/p&gt;
    &lt;head rend="h3"&gt;Andy's Take:&lt;/head&gt;
    &lt;p&gt;Somebody claimed that I judge the quality of a database based on how much funding the backing company raises for its development. This is obviously not true. I track these happenings because the database research game is crowded and high-energy. Not only am I "competing" against academics at other universities, but big tech companies and small start-ups are also putting out interesting systems I need to follow. The industry research labs are not what they used to be, except for Microsoft Research, which is still aggressively hiring top people and doing incredible work.&lt;/p&gt;
    &lt;p&gt;I predicted in 2022 that there would be a large number of database company closings in 2025. Yes, there were more closings this year than in previous years, but not at the scale I expected.&lt;/p&gt;
    &lt;p&gt;The death of Voltron and sort-of acquihire of HeavyDB seem to continue the trend of the inviability of GPU-accelerated databases. Kinetica has been milking government contracts for years, and Sqream still appears to be kicking it. These companies are still niche, and nobody has been able to make a significant dent in the dominance of CPU-powered DBMSs. I can't say who or what, but you will hear some major GPU-accelerated database announcements by vendors in 2026. It also provides further evidence of the commoditization of OLAP engines; modern systems have gotten so fast that the performance between them is negligible for low-level operations (scans, joins), so the things that differentiate one system from another are user experience and the quality of the query plans their optimizers generate.&lt;/p&gt;
    &lt;p&gt;The Couchbase and SingleStore acquisitions by private equity (PE) firms might signal a future trend in the database industry. Of course, PE acquisitions have happened before, but they all seem to be in recent times: (1) MarkLogic in 2020, (2) Cloudera in 2021, and (3) MariaDB in 2023. The only ones I can find before 2020 were SolidDB in 2007 and Informatica in 2015. PE acquisitions might replace the trend of plateaued database companies being bought by holding companies that milk the maintenance fees until eternity (Actian, Rocket). Even Oracle is still making money off RDB/VMS after buying them 30 years ago!&lt;/p&gt;
    &lt;p&gt;Lastly, props to Nikita Shamgunov. As far as I know, he is the only person to have co-founded two database companies (SingleStore and Neon) that were both acquired in a single year. Like when DMX (RIP) released two #1 albums in a single year (It's Dark and Hell Is Hot, Flesh of My Flesh), I don't think anybody is going to break Nikita's record any time soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Peak Male Performance&lt;/head&gt;
    &lt;p&gt;Talk about a banner year for the database OG Larry Ellison. The man turned 81 and accomplished more in one year than most people do in their lifetime. I will cover it all in chronological order.&lt;/p&gt;
    &lt;p&gt;Larry started the year ranked third-richest in the world. The idea that he would be worth less than Mark Zuckerberg was keeping him up at night. Some were saying Larry's insomnia was due to a diet change after he bought a famous British pub and was eating more pies. But I assure you that Larry's "veg-aquarian" diet has not changed in 30 years. Then, in April 2025, we got the news that Larry had become the second-richest person in the world. He started sleeping a little better, but it still wasn't good enough. There was also still a lot going on in his life that was stressing him out. For example, Larry finally decided to sell his rare, semi-road-legal McLaren F1 supercar, complete with the original owner's manual in the glovebox.&lt;/p&gt;
    &lt;p&gt;In July 2025, Larry graced us with this third tweet in 13 years (known as "#3" by Larry aficionados such as myself). This was an update about the Ellison Institute of Technology (EIT) that Larry established near the University of Oxford. With the name EIT and its association with Oxford, it sounds like it would be a pure research, non-profit institution, similar to Stanford's SRI or CMU's SEI. But it turns out to be an umbrella organization for a series of for-profit companies owned by a California-based limited liability company. Of course, a bunch of weirdos replied to #3 with promises of blockchain-powered cryogenic freezing or room-temperature superconductors. Larry told me he ignores those. Then there are people like this guy who get it.&lt;/p&gt;
    &lt;p&gt;The biggest database news of the year (possibly the century) hit us on Wednesday, September 10th, at approximately 3:00pm EST. After waiting for his turn for decades, Larry Joseph Ellison was finally anointed the richest person in the world. $ORCL shares rose by 40% that morning, and since Larry still owns 40% of the company, his estimated total worth is $393b. To put this in perspective, this not only made Larry the wealthiest person in the world, but also the richest person in the entire history of humanity. The peak net worths, adjusted for inflation, of John D. Rockefeller and Andrew Carnegie (yes, the 'C' in CMU) were only $340b and $310b, respectively.&lt;/p&gt;
    &lt;p&gt;On top of Larry's ascension to the top of the world, Oracle was also involved in the acquisition of the U.S. company controlling TikTok and Larry bankrolling Paramount (controlled by his son from his fourth marriage) bid to take over Warner Bros. The U.S. president even chided Larry to take control of CNN's news division since Larry is the majority shareholder of Paramount.&lt;/p&gt;
    &lt;head rend="h3"&gt;Andy's Take:&lt;/head&gt;
    &lt;p&gt;I don't even know where to begin. Of course, when I found out that Larry Ellison had become the richest person in the world, all thanks to databases, I was heartened that something positive had finally happened in our lives. I don't care that Oracle's stock was artificially pumped up by splashy deals to build AI data centers instead of its traditional software business. I don't care that he dropped down the rankings after personally losing $130b in two months. That's like you and me blowing a paycheck on FortuneCoins. It stings a little, and we had to eat rice and beans for two weeks mixed with expired hot sauce packets we took from Taco Bell, but we'll be alright.&lt;/p&gt;
    &lt;p&gt;Some people claim that Larry is out of touch with ordinary people. Or that he has lost his way because he is involved in things not directly related to databases. They point to things like his Hawaiian robot farm selling lettuce at $24/pound (√¢¬¨41/kg). Or that 81-year-old men don't have naturally blonde hair.&lt;/p&gt;
    &lt;p&gt;The truth is that Larry Ellison has conquered the enterprise database world, competitive sailing, and techbro wellness spas. The obvious next step is to take over a cable TV channel watched by thousands of people waiting in airports every day. Every time I talk with Larry, he makes it clear that he does not care one bit what people say or think about him. He knows his fans love him. His (new) wife loves him. And in the end, that's all that matters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Before we close, I want to give some quick shout outs and words of advice. First is to PT for keeping their database game tight with Turso in lockdown (see you on the outside). Condolences to JT for losing their job for trapping their KevoDB database sidepiece. And be sure to only put in fake data in your database for testing and not to sell it for $175m only to end up getting a seven year bid.&lt;/p&gt;
    &lt;p&gt;My Ph.D. students and I also have a new start-up. I hope to say more on that soon. Word is bond.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cs.cmu.edu/~pavlo/blog/2026/01/2025-databases-retrospective.html"/><published>2026-01-05T07:14:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46496494</id><title>Decorative Cryptography</title><updated>2026-01-05T16:15:22.536374+00:00</updated><content>&lt;doc fingerprint="2c9b5d82ed0d2fb4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Decorative Cryptography&lt;/head&gt;
    &lt;p&gt;All encryption is end-to-end, if you‚Äôre not picky about the ends.&lt;/p&gt;
    &lt;code&gt;config TCG_TPM2_HMAC
    bool "Use HMAC and encrypted transactions on the TPM bus"
    default n
    select CRYPTO_ECDH
    select CRYPTO_LIB_AESCFB
    select CRYPTO_LIB_SHA256
    select CRYPTO_LIB_UTILS
    help
      Setting this causes us to deploy a scheme which uses request
      and response HMACs in addition to encryption for
      communicating with the TPM to prevent or detect bus snooping
      and interposer attacks (see tpm-security.rst).  Saying Y
      here adds some encryption overhead to all kernel to TPM
      transactions.
&lt;/code&gt;
    &lt;p&gt;Last year, I came agross a Linux kernel feature called &lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt;. It
claims to detect or prevent active and passive interposer attackers. That‚Äôs one
of my sleeper agent activation phrases, so I dug in.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt; lives primarily in
drivers/char/tpm/sessions.c
and is discussed at further length in
Documentation/security/tpm/tpm-security.rst.&lt;/p&gt;
    &lt;p&gt;It all sounds really great. We should care about interposer adversaries. It‚Äôs great to use the TPM features that were invented to help us with these problems. Let‚Äôs draw a little picture of what‚Äôs being attempted here.&lt;/p&gt;
    &lt;p&gt;In this threat model, there is an adversary who can access the untrusted bus on which all the TPM traffic is sent during the boot. This can be done using hardware hacking or by hijacking another device that controls the TPM bus (e.g., a BMC).&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt; is a kernel feature, and the kernel boots after the platform
firmware and the boot loader, so it can‚Äôt do anything about interposer
adversaries tampering with firmware and boot loader measurements. Let‚Äôs assume
for now that the firmware and boot loader are just implicitly trusted to have
booted ‚Äúcorrect‚Äù code and successfully made honest measurements of all the boot
stages up to and including the kernel. We also implicitly trust the TPM to
behave correctly, here. Or if you have a newer TPM, don‚Äôt!&lt;/p&gt;
    &lt;p&gt;Someone familiar with the STRIDE model can easily observe the following threats just on the big red wire in our picture above:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Attack&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Spoofing&lt;/cell&gt;
        &lt;cell&gt;Attacker pretends to be the TPM or the CPU to the other device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tampering&lt;/cell&gt;
        &lt;cell&gt;Attacker drops or modifies measurements sent to the TPM&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Repudiation&lt;/cell&gt;
        &lt;cell&gt;Not obviously applicable in this case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Information Disclosure&lt;/cell&gt;
        &lt;cell&gt;Attacker obtains unsealed secrets (e.g., disk encryption keys)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Denial of Service&lt;/cell&gt;
        &lt;cell&gt;Attacker drops measurements sent to the TPM&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Escalation of Privilege&lt;/cell&gt;
        &lt;cell&gt;Not obviously applicable in this case&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The attacker may or may not necessarily get anything out of manipulating the TPM traffic itself (unless they are some kind of degenerate that just likes to talk to TPMs for fun). But folks who are familiar with TPM-based measured boot and attestation should be able to immediately see the value to the attacker of ‚Äúmodifying measurements‚Äù or ‚Äúobtaining unsealed secrets‚Äù.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs take a second to distinguish the two types of attackers here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Passive Interposers aka snoopers can only read from the bus but not modify the data.&lt;/item&gt;
      &lt;item&gt;Active Interposers can read and write to the bus.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The very best thing a passive interposer can do here is Information Disclosure: read data from the bus. Since measurements should typically not be secret, the (legitimate) measurements sent to the TPM are not very interesting. Unsealed secrets (that were sealed to the measurements in the TPM) might very much be! That‚Äôs why security/keys/trusted-keys/trusted_tpm2.c uses an &lt;code&gt;encrypt&lt;/code&gt; session
using the helper
&lt;code&gt;tpm_buf_append_hmac_session&lt;/code&gt;
which is unfortunately a little bit entangled with the &lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt; feature
(but that‚Äôs how software development goes). All that really needs to be done
here for this case is to use an &lt;code&gt;encrypt&lt;/code&gt; session key established using the EK
as discussed widely by many others but also myself.&lt;/p&gt;
    &lt;p&gt;The remainder of this blog post discusses the active interposer case.&lt;/p&gt;
    &lt;p&gt;An active interposer generally wants to do one of two things in this scenario:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;(Tampering, Denial of Service) Tamper with TPM measurements made by the kernel, to falsely attest or unseal as the ‚Äúintended‚Äù code or state, from ‚Äúunintended‚Äù code or state.&lt;/item&gt;
      &lt;item&gt;(Spoofing, Information Disclosure) Interpose the TPM connection and defeat the encrypt session solution for unsealing secrets.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt; feature will
establish an auth session
salted (key-encapsulated) to the EK every time the kernel
extends a PCR
or
gets randomness.
You might say to yourself, ‚Äúself, that‚Äôs a lot of overhead (asymmetric crypto
in the TPM) for common, fast operations (PCR extensions, randomness generation)‚Äù
and
you‚Äôd be right.
Wow, this feature is expensive! Good thing it‚Äôs solving a real problem, right?&lt;/p&gt;
    &lt;p&gt;Every time a session is needed (e.g., every time the kernel needs to extend a PCR), the &lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt; feature key-encapsulates a new session key with
something called the ‚ÄúNull Primary Key‚Äù which is a P256 ECDH key derived from
the Null hierarchy (which means it changes on every boot). It uses this session
key to protect the TPM command by encrypting the inputs and outputs and
adding an HMAC to detect tampering. Great.&lt;/p&gt;
    &lt;p&gt;One problem: how does the kernel know what the Null Primary Key should be? Read this thread to not find out.&lt;/p&gt;
    &lt;p&gt;The kernel takes the Null Primary Key at face value and stashes the Name (hash) of it at &lt;code&gt;/sys/class/tpm/tpm0/null_name&lt;/code&gt; and trusts that userspace will
attest the key later using the EK.&lt;/p&gt;
    &lt;p&gt;This inverts the chain of trust for measured boot: the kernel is responsible for measuring userspace, so that ‚Äúbad‚Äù or ‚Äúmalicious‚Äù or ‚Äúunintended‚Äù userspace cannot impersonate ‚Äúgood‚Äù or ‚Äúwell-behaved‚Äù or ‚Äúintended‚Äù userspace.&lt;/p&gt;
    &lt;p&gt;This means that all the active-interposer attacker has to do to defeat &lt;code&gt;TCG_TPM2_HMAC&lt;/code&gt; is:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Replace or hijack the userspace component responsible for checking the Null Primary Key. Call this ‚ÄúComponent X‚Äù.&lt;/item&gt;
      &lt;item&gt;Interpose HMAC session establishment by creating a fake Null Primary Key themselves (e.g., in software) and pretend to be the TPM responding to requests.&lt;/item&gt;
      &lt;item&gt;Intercept &lt;code&gt;TPM2_PCR_Extend&lt;/code&gt;commands, replacing the measurements as desired (e.g., replace ‚Äúhash of malicious Component X‚Äù with ‚Äúhash of good Component X‚Äù).&lt;/item&gt;
      &lt;item&gt;Malicious component X ignores the ‚Äúwrong‚Äù Null Primary Key name at &lt;code&gt;/sys/class/tpm/tpm0/null_name&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can solve this problem by threat model gerrymandering: simply declare that the active interposer adversary is not able to tamper with userspace, which is stored on physical media less than 12 inches away from the TPM in most cases. Note that full disk encryption using the TPM cannot save you here, because if the booting system can fetch the key, so can the physical adversary. If you still think you have a tamper-proof userspace at this point, ask yourself why you need the kernel to measure it anymore.&lt;/p&gt;
    &lt;p&gt;Adding remote attestation also does not help here, because while a remote system can spot-attest a ‚ÄúNull Primary Key‚Äù, it has no way of knowing which key the kernel used when making its measurements.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;TPM2_TCG_HMAC&lt;/code&gt; was disabled by default again
in August 2025
starting with version 6.18.&lt;/p&gt;
    &lt;p&gt;What lessons can we learn from all this?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Applied cryptography cannot solve a security problem. It can only convert a security problem into a key-management problem.&lt;/p&gt;
        &lt;p&gt;Corollary: If you aren‚Äôt actually solving the key-management problem, your cryptography is strictly decorative. This is not only not helpful, it is actively harmful, because it gives users a false sense of security, leading them to skip other precautions they would have otherwise taken.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Chains of trust are directional. Do not invert them.&lt;/p&gt;
        &lt;p&gt;Corollary:&lt;/p&gt;
        &lt;p&gt;You know what the chain of trust is? It's the chain I go get and beat you with 'til ya understand who's trustin' who here.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unexplainable security features are just marketing materials.&lt;/p&gt;
        &lt;p&gt;Corollary: While attestation protocols can be quite byzantine, they should always boil down to 1 or more of ‚ÄúX checks Y against Z‚Äù and it should always be possible to explain why X, Y, and Z are each trusted. The explanations may lead to more X, Y, Z tuples, and this is fine, but don‚Äôt give up if your questions aren‚Äôt being answered.&lt;/p&gt;
        &lt;p&gt;Corollary 2: When someone comes along with detailed questions about something you‚Äôre responsible for, don‚Äôt take it personally. Instead, build trust by engaging in a good-faith discussion. You‚Äôll either be right, and your answers appreciated, or you‚Äôll learn about a gap in your system you can improve.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Active physical interposer adversaries are a very real part of legitimate threat models. You need an integrated root-of-trust in your CPU in order to solve these. Check out Caliptra, which provides TCG DICE APIs from within the SoC itself as an integrated root-of-trust. This can be used on its own, or in conjunction with a discrete TPM.&lt;/p&gt;
    &lt;p&gt;Opinions expressed here are my own and do not represent the official positions of any employer(s) of mine, past or present&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.dlp.rip/decorative-cryptography"/><published>2026-01-05T08:29:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46497164</id><title>Anna's Archive loses .org domain after surprise suspension</title><updated>2026-01-05T16:15:22.294745+00:00</updated><content>&lt;doc fingerprint="aa9825f1485033cf"&gt;
  &lt;main&gt;
    &lt;p&gt;Anna‚Äôs Archive is a meta-search engine for shadow libraries that allows users to find pirated books and other related sources.&lt;/p&gt;
    &lt;p&gt;The site launched in the fall of 2022, just days after Z-Library was targeted in a U.S. criminal crackdown, to ensure continued availability of ‚Äòfree‚Äô books and articles to the broader public.&lt;/p&gt;
    &lt;p&gt;The site also actively provides assistance to AI researchers who want to use its library for model training. More recently, Anna‚Äôs Archive announced it had created a massive 300TB backup of Spotify, which it is slowly releasing to the public at large.&lt;/p&gt;
    &lt;p&gt;Since its launch, Anna‚Äôs Archive has also received pushback from rightsholders. The site has been blocked in various countries, and was sued in the U.S. after it scraped WorldCat.&lt;/p&gt;
    &lt;p&gt;Despite this legal pressure, the main annas-archive.org domain name remained operational, until it didn‚Äôt.&lt;/p&gt;
    &lt;head rend="h2"&gt;Anna‚Äôs .ORG Domain Suspended&lt;/head&gt;
    &lt;p&gt;A few hours ago, the site‚Äôs original domain name suddenly became unreachable globally. The annas-archive.org domain status was changed to ‚ÄúserverHold,‚Äù which is typically done by the domain registry. This status effectively means that the domain is suspended and under investigation. Similar action has previously been taken against other pirate sites.&lt;/p&gt;
    &lt;p&gt;It is rare to see a .org domain involved in domain name suspensions. The American non-profit Public Interest Registry (PIR), which oversees the .org domains, previously refused to suspend domain names voluntarily, including thepiratebay.org. The registry‚Äôs cautionary stance suggests that the actions against annas-archive.org are backed by a court order.&lt;/p&gt;
    &lt;p&gt;TorrentFreak asked PIR for a comment on their supposed involvement in the domain suspension, hoping to find out more about the legal grounds, but the organization did not immediately reply.&lt;/p&gt;
    &lt;p&gt;Update: PIR‚Äôs marketing director, Kendal Rowe, informs TorrentFreak that ‚Äúunfortunately, PIR is unable to comment on the situation at this time.‚Äù&lt;/p&gt;
    &lt;p&gt;It is possible that, in response to the ‚ÄòDRM-circumventing‚Äô Spotify backup, rightsholders requested an injunction targeting the domain name. However, we have seen no evidence of that. In the WorldCat lawsuit, OCLC requested an injunction to force action from intermediaries, including domain registries, but as far as we know, that hasn‚Äôt been granted yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Anna‚Äôs Archive Remains Resilient&lt;/head&gt;
    &lt;p&gt;This is not the first time Anna‚Äôs Archive has lost a domain name. The site previously moved from its .org domain to a .GS domain, anticipating a domain seizure in the WorldCat case.&lt;/p&gt;
    &lt;p&gt;Ironically, this move resulted in a swift suspension by the .GS registry, after which Anna‚Äôs Archive returned to its .org domain.&lt;/p&gt;
    &lt;p&gt;On Reddit, Anna‚Äôs Archive explains that the recent suspension is a mere hiccup too, pointing users to alternative domains.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe .org domain apparently has been suspended. Our other domains work fine, and we‚Äôve added some more. We recommend checking our Wikipedia page for the latest domains. This unfortunately happens to shadow libraries on a regular basis. ‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWe don‚Äôt believe this has to do with our Spotify backup,‚Äù AnnaArchivist adds.&lt;/p&gt;
    &lt;p&gt;At the time of writing, the site is indeed still operational from the older .li and .se domains, as well as the .in and .pm variants that were just added. However, with legal pressure mounting, there are no guarantees that these domains remain operational.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://torrentfreak.com/annas-archive-loses-org-domain-after-surprise-suspension/"/><published>2026-01-05T10:23:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46497589</id><title>Cigarette smoke effect using shaders</title><updated>2026-01-05T16:15:21.859628+00:00</updated><content>&lt;doc fingerprint="73bcfa116d9d2b3e"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Scene&lt;/head&gt;
    &lt;p&gt;First we render a three.js scene with a plane geometry wrapped in shader material:&lt;/p&gt;
    &lt;quote&gt;const material = new THREE.ShaderMaterial({vertexShader: `void main() {// Final positiongl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);}`,fragmentShader: `void main() {// Final colorgl_FragColor = vec4(0.0, 1.0, 0.0, 1.0);#include &amp;lt;tonemapping_fragment&amp;gt;#include &amp;lt;colorspace_fragment&amp;gt;}`,side: THREE.DoubleSide,wireframe: config.material.wireframe});&lt;/quote&gt;
    &lt;head rend="h2"&gt;Texture&lt;/head&gt;
    &lt;p&gt;Perlin noise will provide the random values needed for the effect. We load a Perlin noise texture and pass it into the fragment shader.&lt;/p&gt;
    &lt;quote&gt;const textureLoader = new THREE.TextureLoader();const texture = textureLoader.load(config.material.textureURL);const material = new THREE.ShaderMaterial({uniforms: {uTexture: new THREE.Uniform(texture),},fragmentShader: `uniform sampler2D uTexture;...`,...});&lt;/quote&gt;
    &lt;head rend="h3"&gt;Fragment UVs&lt;/head&gt;
    &lt;p&gt;To sample the texture, we need the UV coords of each fragment. We can pass the coords from the vertex to the fragment shader using a varying. To confirm it's working, we use the UVs as the fragment's red and green value ‚Äî resulting in a green-red gradient. To see the effect, set state: uv in the controls.&lt;/p&gt;
    &lt;quote&gt;const material = new THREE.ShaderMaterial({vertexShader: `varying vec2 vUv;void main() {// Final positiongl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);// VaryingsvUv = uv;}`,fragmentShader: `varying vec2 vUv;void main() {vec2 textureUv = vUv;gl_FragColor = vec4(vUv, 0.0, 1.0);...}`,});&lt;/quote&gt;
    &lt;head rend="h3"&gt;Map texture to geometry&lt;/head&gt;
    &lt;p&gt;To map the texture onto the material, we use &lt;code&gt;texture(uTexture, textureUv).r;&lt;/code&gt;.
It reads the texture's color value at the given coordinates using the same coordinate space as the fragment shader:&lt;/p&gt;
    &lt;p&gt;Passing the current fragment's UV coordinates to &lt;code&gt;texture()&lt;/code&gt; lets us map the texture onto the material pixel by pixel.
The function returns a normalized RGBA value. Since the texture is grayscale, all three color channels are equal, so we only need the red channel (&lt;code&gt;.r&lt;/code&gt;).
We then assign it to the fragment's color:&lt;/p&gt;
    &lt;quote&gt;fragmentShader: `uniform sampler2D uTexture;varying vec2 vUv;void main() {vec2 textureUv = vUv;// Texturefloat textureImpl = texture(uTexture, textureUv).r;gl_FragColor = vec4(textureImpl, textureImpl, textureImpl, 1.0);...`&lt;/quote&gt;
    &lt;p&gt;To see the effect, set state: texture in the controls (the texture stretches to fit the geometry).&lt;/p&gt;
    &lt;head rend="h3"&gt;Sample size&lt;/head&gt;
    &lt;p&gt;We don't have to use the whole texture. &lt;code&gt;uTextureSampleWidth&lt;/code&gt; and &lt;code&gt;uTextureSampleHeight&lt;/code&gt; is added to enable selecting only a portion of the texture.&lt;/p&gt;
    &lt;quote&gt;fragmentShader: `uniform sampler2D uTexture;uniform float uTextureSampleWidth;uniform float uTextureSampleHeight;varying vec2 vUv;void main() {vec2 textureUv = vUv;// Set texture sample sizetextureUv.x *= uTextureSampleWidth;textureUv.y *= uTextureSampleHeight;// Texturefloat textureImpl = texture(uTexture, textureUv).r;gl_FragColor = vec4(textureImpl, textureImpl, textureImpl, 1.0);...`&lt;/quote&gt;
    &lt;head rend="h3"&gt;Mask&lt;/head&gt;
    &lt;p&gt;Because smoke is translucent, we need to render the texture as a mask instead of an image. If we change the fragment's color to white and use the texture's color value for the alpha channel, it will render the texture as white with varying opacity instead of shades of gray.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ñ™ a white pixel in the texture (value: &lt;code&gt;1&lt;/code&gt;) renders a fully opaque white pixel.&lt;/item&gt;
      &lt;item&gt;‚ñ™ a black pixel in the texture (value: &lt;code&gt;0&lt;/code&gt;) renders a fully transparent pixel.&lt;/item&gt;
      &lt;item&gt;‚ñ™ gray pixels render something in between.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Because where varying opacity, we need to set &lt;code&gt;transparent: true&lt;/code&gt; in the material.
To see the effect, set state: mask in the controls.&lt;/p&gt;
    &lt;quote&gt;const material = new THREE.ShaderMaterial({fragmentShader: `...void main() {gl_FragColor = vec4(1.0, 1.0, 1.0, textureImpl);...}`,transparent: true,...});&lt;/quote&gt;
    &lt;head rend="h2"&gt;Animate&lt;/head&gt;
    &lt;p&gt;To create a smoke rising animation, we set the texture to repeat itself vertically using:&lt;/p&gt;
    &lt;quote&gt;texture.wrapT = THREE.RepeatWrapping;&lt;/quote&gt;
    &lt;p&gt;The result is, when we translate the texture up, a copy of it will fill the space below. We then pass the elapsed time into the shader to provide a continually increasing number and use it to continually lower the y-coord of the texture sample. The creates the effect of the texture moving up. &lt;code&gt;uSpeed&lt;/code&gt; is added to control how fast this happens.&lt;/p&gt;
    &lt;quote&gt;const texture = textureLoader.load(config.material.textureURL);texture.wrapT = THREE.RepeatWrapping;const material = new THREE.ShaderMaterial({uniforms: {uTime: new THREE.Uniform(0),uSpeed: new THREE.Uniform(config.material.speed)...},fragmentShader: `uniform float uTime;uniform float uSpeed;...void main() {// AnimatetextureUv.y -= uTime * uSpeed;// Texturefloat textureImpl = texture(uTexture, textureUv).r;...}`,...});const clock = new THREE.Clock();function onFrame() {const elapsedTime = clock.getElapsedTime();material.uniforms.uTime.value = elapsedTime;...&lt;/quote&gt;
    &lt;head rend="h2"&gt;Remap&lt;/head&gt;
    &lt;p&gt;Currently, the effect isn't transparent enough to look like smoke. The texture has very few black pixels ‚Äî most are gray ‚Äî which makes the smoke appear solid. We can fix this by remapping the texture's color values using:&lt;/p&gt;
    &lt;quote&gt;smoothstep(uRemapLow, uRemapHigh, textureImpl)&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ñ™ &lt;code&gt;uRemapLow&lt;/code&gt;and&lt;code&gt;uRemapHigh&lt;/code&gt;are values between 0 and 1.&lt;/item&gt;
      &lt;item&gt;‚ñ™ &lt;code&gt;textureImpl&lt;/code&gt;is the texture's current pixel color value.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The function works as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ñ™ If &lt;code&gt;textureImpl&lt;/code&gt;&amp;lt;&lt;code&gt;uRemapLow&lt;/code&gt;, it returns 0 (black).&lt;/item&gt;
      &lt;item&gt;‚ñ™ If &lt;code&gt;textureImpl&lt;/code&gt;&amp;gt;&lt;code&gt;uRemapHigh&lt;/code&gt;, it returns 1 (white).&lt;/item&gt;
      &lt;item&gt;‚ñ™ Values in between are mapped smoothly along a curve between 0 and 1.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This allows us to turn dark grays into black and light grays into white while keeping a smooth transition between the two.&lt;/p&gt;
    &lt;quote&gt;const material = new THREE.ShaderMaterial({uniforms: {uRemapLow: new THREE.Uniform(config.material.remap.low),uRemapHigh: new THREE.Uniform(config.material.remap.high)...},fragmentShader: `uniform float uRemapLow;uniform float uRemapHigh;...void main() {// Texturefloat textureImpl = texture(uTexture, textureUv).r;// RemaptextureImpl = smoothstep(uRemapLow, uRemapHigh, textureImpl);...}`,...});&lt;/quote&gt;
    &lt;head rend="h2"&gt;Edges&lt;/head&gt;
    &lt;p&gt;Our smoke effect looks like wallpaper because the edges of the geometry are visible. We can fix this by fading out the texture near the edges using smoothstep. For example, for the left edge:&lt;/p&gt;
    &lt;quote&gt;float fadeEdges = smoothstep(0.0, uEdgeX, vUv.x);&lt;/quote&gt;
    &lt;p&gt;If we set &lt;code&gt;uEdgeX&lt;/code&gt; = &lt;code&gt;0.4&lt;/code&gt;, it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ñ™ returns 0 at &lt;code&gt;vUv.x = 0&lt;/code&gt;(the very edge)&lt;/item&gt;
      &lt;item&gt;‚ñ™ returns 1 at &lt;code&gt;vUv.x &amp;gt;= 0.4&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;‚ñ™ smoothly interpolates values between 0 and 1 for positions in between&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When this value is multiplied by the texture color value, it applies this additional level of opacity to the output:&lt;/p&gt;
    &lt;quote&gt;const material = new THREE.ShaderMaterial({uniforms: {uEdgeX: new THREE.Uniform(config.material.edge.x),uEdgeY: new THREE.Uniform(config.material.edge.y)...},fragmentShader: `uniform float uEdgeX;uniform float uEdgeY;...void main() {// RemaptextureImpl = smoothstep(uRemapLow, uRemapHigh, textureImpl);// Edges// left edgefloat fadeEdges = smoothstep(0.0, uEdgeX, vUv.x);// right edgefadeEdges *= smoothstep(1.0, 1.0 - uEdgeX, vUv.x);// top edgefadeEdges *= smoothstep(0.0, uEdgeY, vUv.y);// bottom edgefadeEdges *= smoothstep(1.0, 1.0 - uEdgeY, vUv.y);textureImpl *= fadeEdges;...}`,...});&lt;/quote&gt;
    &lt;head rend="h2"&gt;Twist&lt;/head&gt;
    &lt;p&gt;To improve the effect, we twist the geometry around the y-axis. Changing the geometry from a 2D plane to a 3D spiral. This requires modifying vertex positions, not color, so we'll modify the vertex shader.&lt;/p&gt;
    &lt;head rend="h3"&gt;Random value&lt;/head&gt;
    &lt;p&gt;For each vertical position on the plane (&lt;code&gt;UV.y&lt;/code&gt;), we want a random angle of twist that gradually changes as we go from bottom to top.
We do this by sampling a &lt;code&gt;1px&lt;/code&gt; wide vertical slice of the texture.
&lt;code&gt;uTwistSampleX&lt;/code&gt; is the x-position of the slice (it can be any value between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;) and is the same for every vertex.&lt;/p&gt;
    &lt;quote&gt;uniform float uTwistSampleX;void main() {float textureY = uv.y;float textureValue = texture(uTexture, vec2(uTwistSampleX, textureY)).r;...&lt;/quote&gt;
    &lt;p&gt;By taking advantage of the fact that the texture stretches to fit the geometry, we can control to how many twists there will be by changing the height of the slice. The taller the slice, the more values, the more variations:&lt;/p&gt;
    &lt;quote&gt;uniform float uTwistSampleHeight;void main() {float textureY = uv.y * uTwistSampleHeight;...&lt;/quote&gt;
    &lt;head rend="h3"&gt;Animation&lt;/head&gt;
    &lt;p&gt;To animate the twists, we use the same technique as before: use elapsed time to continually lower the sample y-coord ‚Äî making the twists rise:&lt;/p&gt;
    &lt;quote&gt;uniform float uTime;uniform float uTwistSpeed;void main() {float textureY = uv.y * uTwistSampleHeight - uTime * uTwistSpeed;...&lt;/quote&gt;
    &lt;head rend="h3"&gt;Position&lt;/head&gt;
    &lt;p&gt;Finally, to get the new position for each vertex, we multiple the random value by a strength value (to increase or decrease the amount of twist). Then modify the x and z values (because we're twisting around the y-axis). &lt;code&gt;rotate2D&lt;/code&gt; will take these values and a desired angle and return the new, twisted x and z values:&lt;/p&gt;
    &lt;quote&gt;const rotate2D = `vec2 rotate2D(vec2 value, float angle) {float s = sin(angle);float c = cos(angle);mat2 m = mat2(c, s, -s, c);return m * value;}`;...float angle = textureValue * uTwistStrength;vec3 twistedPosition = position;twistedPosition.xz = rotate2D(twistedPosition.xz, angle);&lt;/quote&gt;
    &lt;head rend="h3"&gt;Occulsion&lt;/head&gt;
    &lt;p&gt;Occulsion is the concept of one object blocking another from view. If object A is closer to the camera than object B, A occludes B ‚Äî B should not be visible. By default, three.js enables depth writing to handle occlusion. However, because our shader is rendering semi-transparent, overlapping fragments, we need to disable this because we want to see through each layer of smoke. To disable, we set &lt;code&gt;depthWrite: false&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;const material = new THREE.ShaderMaterial({depthWrite: false,...});&lt;/quote&gt;
    &lt;head rend="h2"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;Have any feedback about this note or just want to comment on the state of the economy?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://garden.bradwoods.io/notes/javascript/three-js/shaders/shaders-103-smoke"/><published>2026-01-05T11:32:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46497712</id><title>It's hard to justify Tahoe icons</title><updated>2026-01-05T16:15:21.048874+00:00</updated><content>&lt;doc fingerprint="a2e47b3019328699"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;It‚Äôs hard to justify Tahoe icons&lt;/head&gt;
    &lt;p&gt;I was reading Macintosh Human Interface Guidelines from 1992 and found this nice illustration:&lt;/p&gt;
    &lt;p&gt;accompanied by explanation:&lt;/p&gt;
    &lt;p&gt;Fast forward to 2025. Apple releases macOS Tahoe. Main attraction? Adding unpleasant, distracting, illegible, messy, cluttered, confusing, frustrating icons (their words, not mine!) to every menu item:&lt;/p&gt;
    &lt;p&gt;It‚Äôs bad. But why exactly is it bad? Let‚Äôs delve into it!&lt;/p&gt;
    &lt;p&gt;Disclaimer: screenshots are a mix from macOS 26.1 and 26.2, taken from stock Apple apps only that come pre-installed with the system. No system settings were modified.&lt;/p&gt;
    &lt;head rend="h1"&gt;Icons should differentiate&lt;/head&gt;
    &lt;p&gt;The main function of an icon is to help you find what you are looking for faster.&lt;/p&gt;
    &lt;p&gt;Perhaps counter-intuitively, adding an icon to everything is exactly the wrong thing to do. To stand out, things need to be different. But if everything has an icon, nothing stands out.&lt;/p&gt;
    &lt;p&gt;The same applies to color: black-and-white icons look clean, but they don‚Äôt help you find things faster!&lt;/p&gt;
    &lt;p&gt;Microsoft used to know this:&lt;/p&gt;
    &lt;p&gt;Look how much faster you can find Save or Share in the right variant:&lt;/p&gt;
    &lt;p&gt;It also looks cleaner. Less cluttered.&lt;/p&gt;
    &lt;p&gt;A colored version would be even better (clearer separation of text from icon, faster to find):&lt;/p&gt;
    &lt;p&gt;I know you won‚Äôt like how it looks. I don‚Äôt like it either. These icons are hard to work with. You‚Äôll have to actually design for color to look nice. But the principle stands: it is way easier to use.&lt;/p&gt;
    &lt;head rend="h1"&gt;Consistency between apps&lt;/head&gt;
    &lt;p&gt;If you want icons to work, they need to be consistent. I need to be able to learn what to look for.&lt;/p&gt;
    &lt;p&gt;For example, I see a ‚ÄúCut‚Äù command and next to it. Okay, I think. Next time I‚Äôm looking for ‚ÄúCut,‚Äù I might save some time and start looking for instead.&lt;/p&gt;
    &lt;p&gt;How is Tahoe doing on that front? I present to you: Fifty Shades of ‚ÄúNew‚Äù:&lt;/p&gt;
    &lt;p&gt;I even collected them all together, so the absurdity of the situation is more obvious.&lt;/p&gt;
    &lt;p&gt;Granted, some of them are different operations, so they have different icons. I guess creating a smart folder is different from creating a journal entry. But this?&lt;/p&gt;
    &lt;p&gt;Or this:&lt;/p&gt;
    &lt;p&gt;Or this:&lt;/p&gt;
    &lt;p&gt;There is no excuse.&lt;/p&gt;
    &lt;p&gt;Same deal with open:&lt;/p&gt;
    &lt;p&gt;Save:&lt;/p&gt;
    &lt;p&gt;Yes. One of them is a checkmark. And they can‚Äôt even agree on the direction of an arrow!&lt;/p&gt;
    &lt;p&gt;Close:&lt;/p&gt;
    &lt;p&gt;Find (which is sometimes called Search, and sometimes Filter):&lt;/p&gt;
    &lt;p&gt;Delete (from Cut-Copy-Paste-Delete fame):&lt;/p&gt;
    &lt;p&gt;Minimize window.&lt;/p&gt;
    &lt;p&gt;These are not some obscure, unique operations. These are OS basics, these are foundational. Every app has them, and they are always in the same place. They shouldn‚Äôt look different!&lt;/p&gt;
    &lt;head rend="h1"&gt;Consistency inside the same app&lt;/head&gt;
    &lt;p&gt;Icons are also used in toolbars. Conceptually, operations in a toolbar are identical to operations called through the menu, and thus should use the same icons. That‚Äôs the simplest case to implement: inside the same app, often on the same screen. How hard can it be to stay consistent?&lt;/p&gt;
    &lt;p&gt;Preview:&lt;/p&gt;
    &lt;p&gt;Photos: same and mismatch, but reversed ¬Ø\_(„ÉÑ)_/¬Ø&lt;/p&gt;
    &lt;p&gt;Maps and others often use different symbols for zoom:&lt;/p&gt;
    &lt;head rend="h1"&gt;Icon reuse&lt;/head&gt;
    &lt;p&gt;Another cardinal sin is to use the same icon for different actions. Imagine: I have learned that means ‚ÄúNew‚Äù:&lt;/p&gt;
    &lt;p&gt;Then I open an app and see. ‚ÄúCool‚Äù, I think, ‚ÄúI already know what it means‚Äù:&lt;/p&gt;
    &lt;p&gt;Gotcha!&lt;/p&gt;
    &lt;p&gt;You‚Äôd think: okay, means quick look:&lt;/p&gt;
    &lt;p&gt;Sometimes, sure. Some other times, means ‚ÄúShow completed‚Äù:&lt;/p&gt;
    &lt;p&gt;Sometimes is ‚ÄúImport‚Äù:&lt;/p&gt;
    &lt;p&gt;Sometimes is ‚ÄúUpdates‚Äù:&lt;/p&gt;
    &lt;p&gt;Same as with consistency, icon reuse doesn‚Äôt only happen between apps. Sometimes you see in a toolbar:&lt;/p&gt;
    &lt;p&gt;Then go to the menu in the same app and see means something else:&lt;/p&gt;
    &lt;p&gt;Sometimes identical icons meet in the same menu.&lt;/p&gt;
    &lt;p&gt;Sometimes next to each other.&lt;/p&gt;
    &lt;p&gt;Sometimes they put an entire barrage of identical icons in a row:&lt;/p&gt;
    &lt;p&gt;This doesn‚Äôt help anyone. No user will find a menu item faster or will understand the function better if all icons are the same.&lt;/p&gt;
    &lt;p&gt;The worst case of icon reuse so far has been the Photos app:&lt;/p&gt;
    &lt;p&gt;It feels like the person tasked with choosing a unique icon for every menu item just ran out of ideas.&lt;/p&gt;
    &lt;p&gt;Understandable.&lt;/p&gt;
    &lt;head rend="h1"&gt;Too much nuance&lt;/head&gt;
    &lt;p&gt;When looking at icons, we usually allow for slight differences in execution. That lets us, for example, understand that these technically different road signs mean the same thing:&lt;/p&gt;
    &lt;p&gt;Same applies for icons: if you draw an arrow going out of the box in one place and also an arrow and the box but at a slightly different angle, or with different stroke width, or make one filled, we will understand them as meaning the same thing.&lt;/p&gt;
    &lt;p&gt;Like, is supposed to mean something else from ? Come on!&lt;/p&gt;
    &lt;p&gt;Or two-letter As that only slightly differ in the font size:&lt;/p&gt;
    &lt;p&gt;A pencil is ‚ÄúRename‚Äù but a slightly thicker pencil is ‚ÄúHighlight‚Äù?&lt;/p&gt;
    &lt;p&gt;Arrows that use different diagonals?&lt;/p&gt;
    &lt;p&gt;Three dots occupying ‚Öî of space vs three dots occupying everything. Seriously?&lt;/p&gt;
    &lt;p&gt;Slightly darker dots?&lt;/p&gt;
    &lt;p&gt;The sheet of paper that changes meaning depending on if its corner is folded or if there are lines inside?&lt;/p&gt;
    &lt;p&gt;But the final boss are arrows. They are all different:&lt;/p&gt;
    &lt;p&gt;Supposedly, a user must become an expert at noticing how squished the circle is, if it starts top to right or bottom to right, and how far the arrow‚Äôs end goes.&lt;/p&gt;
    &lt;p&gt;Do I care? Honestly, no. I could‚Äôve given it a shot, maybe, if Apple applied these consistently. But Apple considers and to mean the same thing in one place, and expects me to notice minute details like this in another?&lt;/p&gt;
    &lt;p&gt;Sorry, I can‚Äôt trust you. Not after everything I‚Äôve seen.&lt;/p&gt;
    &lt;head rend="h1"&gt;Detalization&lt;/head&gt;
    &lt;p&gt;Icons are supposed to be easily recognizable from a distance. Every icon designer knows: small details are no-go. You can have them sometimes, maybe, for aesthetic purposes, but you can‚Äôt rely on them.&lt;/p&gt;
    &lt;p&gt;And icons in Tahoe menus are tiny. Most of them fit in a 12√ó12 pixel square (actual resolution is 24√ó24 because of Retina), and because many of them are not square, one dimension is usually even less than 12.&lt;/p&gt;
    &lt;p&gt;It‚Äôs not a lot of space to work with! Even Windows 95 had 16√ó16 icons. If we take the typical DPI of that era at 72 dots per inch, we get a physical icon size of 0.22 inches (5.6 mm). On a modern MacBook Pro with 254 DPI, Tahoe‚Äôs 24√ó24 icons are 0.09 inches (2.4 mm). Sure, 24 is bigger than 16, but in reality, these icons‚Äô area is 4 times as small!&lt;/p&gt;
    &lt;p&gt;So when I see this:&lt;/p&gt;
    &lt;p&gt;I struggle. I can tell they are different. But I definitely struggle to tell what‚Äôs being drawn.&lt;/p&gt;
    &lt;p&gt;Even zoomed in 20√ó, it‚Äôs still a mess:&lt;/p&gt;
    &lt;p&gt;Or here. These are three different icons:&lt;/p&gt;
    &lt;p&gt;Am I supposed to tell plus sign from sparkle here?&lt;/p&gt;
    &lt;p&gt;Some of these lines are half the pixel thicker than the other lines, and that‚Äôs supposed to be the main point:&lt;/p&gt;
    &lt;p&gt;Is this supposed to be an arrow?&lt;/p&gt;
    &lt;p&gt;A paintbrush?&lt;/p&gt;
    &lt;p&gt;Look, a tiny camera.&lt;/p&gt;
    &lt;p&gt;It even got an even tinier viewfinder, which you can almost see if you zoom in 20√ó:&lt;/p&gt;
    &lt;p&gt;Or here. There is a box, inside that box is a circle, and inside it is a tiny letter. &lt;code&gt;i&lt;/code&gt; with a total height of 2 pixels:&lt;/p&gt;
    &lt;p&gt;Don‚Äôt see it?&lt;/p&gt;
    &lt;p&gt;I don‚Äôt. But it‚Äôs there...&lt;/p&gt;
    &lt;p&gt;And this is a window! It even has traffic lights! How adorable:&lt;/p&gt;
    &lt;p&gt;Remember: these are retina pixels, ¬º of a real pixel. Steve Jobs himself claimed they were invisible.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It turns out there‚Äôs a magic number right around 300 pixels per inch, that when you hold something around to 10 to 12 inches away from your eyes, is the limit of the human retina to differentiate the pixels.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And yet, Tahoe icons rely on you being able to see them.&lt;/p&gt;
    &lt;head rend="h1"&gt;Pixel grid&lt;/head&gt;
    &lt;p&gt;When you have so little space to work with, every pixel matters. You can make a good icon, but you have to choose your pixels very carefully.&lt;/p&gt;
    &lt;p&gt;For Tahoe icons, Apple decided to use vector fonts instead of good old-fashioned bitmaps. It saves Apple resources‚Äîdraw once, use everywhere. Any size, any display resolution, any font width.&lt;/p&gt;
    &lt;p&gt;But there‚Äôre downsides: fonts are hard to position vertically, their size doesn‚Äôt map directly to pixels, stroke width doesn‚Äôt map 1-to-1 to pixel grid, etc. So, they work everywhere, but they also look blurry and mediocre everywhere:&lt;/p&gt;
    &lt;p&gt;They certainly start to work better once you give them more pixels.&lt;/p&gt;
    &lt;p&gt;or make graphics simpler. But the combination of small details and tiny icon size is deadly. So, until Apple releases MacBooks with 380+ DPI, unfortunately, we still have to care about the pixel grid.&lt;/p&gt;
    &lt;head rend="h1"&gt;Confusing metaphors&lt;/head&gt;
    &lt;p&gt;Icons might serve another function: to help users understand the meaning of the command.&lt;/p&gt;
    &lt;p&gt;For example, once you know the context (move window), these icons explain what‚Äôs going on faster than words:&lt;/p&gt;
    &lt;p&gt;But for this to work, the user must understand what‚Äôs drawn on the icon. It must be a familiar object with a clear translation to computer action (like Trash can ‚Üí Delete), a widely used symbol, or an easy-to-understand diagram. HIG:&lt;/p&gt;
    &lt;p&gt;A rookie mistake would be to misrepresent the object. For example, this is how selection looks like:&lt;/p&gt;
    &lt;p&gt;But its icon looks like this:&lt;/p&gt;
    &lt;p&gt;Honestly, I‚Äôve been writing this essay for a week, and I still have zero ideas why it looks like that. There‚Äôs an object that looks like this, but it‚Äôs a text block in Freeform/Preview:&lt;/p&gt;
    &lt;p&gt;It‚Äôs called &lt;code&gt;character.textbox&lt;/code&gt; in SF Symbols:&lt;/p&gt;
    &lt;p&gt;Why did it become a metaphor for ‚ÄúSelect all‚Äù? My best guess is it‚Äôs a mistake.&lt;/p&gt;
    &lt;p&gt;Another place uses text selection from iOS as a metaphor. On a Mac!&lt;/p&gt;
    &lt;p&gt;Some concepts have obvious or well-established metaphors. In that case, it‚Äôs a mistake not to use them. For example, bookmarks: . Apple, for some reason, went with a book:&lt;/p&gt;
    &lt;p&gt;Sometimes you already have an interface element and can use it for an icon. However, try not to confuse your users. Dots in a rectangle look like password input, not permissions:&lt;/p&gt;
    &lt;p&gt;Icon here says ‚ÄúCheck‚Äù but the action is ‚ÄúUncheck‚Äù.&lt;/p&gt;
    &lt;p&gt;Terrible mistake: icon doesn‚Äôt help, it actively confuses the user.&lt;/p&gt;
    &lt;p&gt;It‚Äôs also tempting to construct a two-level icon: an object and some sort of indicator. Like, a checkbox and a cross, meaning ‚ÄúDelete checkbox‚Äù:&lt;/p&gt;
    &lt;p&gt;Or a user and a checkmark, like ‚ÄúCheck the user‚Äù:&lt;/p&gt;
    &lt;p&gt;Unfortunately, constructs like this rarely work. Users don‚Äôt build sentences from building blocks you provide; they have no desire to solve these puzzles.&lt;/p&gt;
    &lt;p&gt;Finding metaphors is hard. Nouns are easier than verbs, and menu items are mostly verbs. How does open look? Like an arrow pointing to the top right? Why?&lt;/p&gt;
    &lt;p&gt;I‚Äôm not saying there‚Äôs an obvious metaphor for ‚ÄúOpen‚Äù Apple missed. There isn‚Äôt. But that‚Äôs the point: if you can‚Äôt find a good metaphor, using no icon is better than using a bad, confusing, or nonsensical icon.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a game I like to play to test the quality of the metaphor. Remove the labels and try to guess the meaning. Give it a try:&lt;/p&gt;
    &lt;p&gt;It‚Äôs delusional to think that there‚Äôs a good icon for every action if you think hard enough. There isn‚Äôt. It‚Äôs a lost battle from the start. No amount of money or ‚Äúmanagement decisions‚Äù is going to change that. The problems are 100% self-inflicted.&lt;/p&gt;
    &lt;p&gt;All this being said, I gotta give Apple credit where credit is due. When they are good at choosing metaphors, they are good:&lt;/p&gt;
    &lt;head rend="h1"&gt;Symmetrical actions&lt;/head&gt;
    &lt;p&gt;A special case of a confusing metaphor is using different metaphors for actions that are direct opposites of one another. Like Undo/Redo, Open/Close, Left/Right.&lt;/p&gt;
    &lt;p&gt;It‚Äôs good when their icons use the same metaphor:&lt;/p&gt;
    &lt;p&gt;Because it saves you time and cognitive resources. Learn one, get another one for free.&lt;/p&gt;
    &lt;p&gt;Because of that, it‚Äôs a mistake not to use common metaphors for related actions:&lt;/p&gt;
    &lt;p&gt;Or here:&lt;/p&gt;
    &lt;p&gt;Another mistake is to create symmetry where there is none. ‚ÄúBack‚Äù and ‚ÄúSee all‚Äù?&lt;/p&gt;
    &lt;p&gt;Some menus in Tahoe make both mistakes. E.g. lack of symmetry between Show/Hide and false symmetry between completed/subtasks:&lt;/p&gt;
    &lt;p&gt;Import not mirrored by Export but by Share:&lt;/p&gt;
    &lt;head rend="h1"&gt;Text in icons&lt;/head&gt;
    &lt;p&gt;HIG again:&lt;/p&gt;
    &lt;p&gt;Authors of HIG are arguing against including text as a part of an icon. So something like this:&lt;/p&gt;
    &lt;p&gt;or this:&lt;/p&gt;
    &lt;p&gt;would not fly in 1992.&lt;/p&gt;
    &lt;p&gt;I agree, but Tahoe has more serious problems: icons consisting only of text. Like this:&lt;/p&gt;
    &lt;p&gt;It‚Äôs unclear where ‚Äúmetaphorical, abstract icon text that is not supposed to be read literally‚Äù ends and actual text starts. They use the same font, the same color, so how am I supposed to differentiate? Icons just get in a way: A...Complete? AaFont? What does it mean?&lt;/p&gt;
    &lt;p&gt;I can maybe understand and . Dots are supposed to represent something. I can imagine thinking that led to . But ? No decorations. No effects. Just plain Abc. Really?&lt;/p&gt;
    &lt;head rend="h1"&gt;Text transformations&lt;/head&gt;
    &lt;p&gt;One might think that using icons to illustrate text transformations is a better idea.&lt;/p&gt;
    &lt;p&gt;Like, you look at this:&lt;/p&gt;
    &lt;p&gt;or this:&lt;/p&gt;
    &lt;p&gt;or this:&lt;/p&gt;
    &lt;p&gt;and just from the icon alone understand what will happen with the text. Icon illustrates the action.&lt;/p&gt;
    &lt;p&gt;Also, BIU are well-established in word processing, so all upside?&lt;/p&gt;
    &lt;p&gt;Not exactly. The problem is the same‚Äîtext icon looks like text, not icon. Plus, these icons are excessive. What‚Äôs the point of taking the first letter and repeating it? The word ‚ÄúBold‚Äù already starts with a letter ‚ÄúB‚Äù, it reads just as easily, so why double it? Look at it again:&lt;/p&gt;
    &lt;p&gt;It‚Äôs also repeated once more as a shortcut...&lt;/p&gt;
    &lt;p&gt;There is a better way to design this menu:&lt;/p&gt;
    &lt;p&gt;And it was known to Apple for at least 33 years.&lt;/p&gt;
    &lt;head rend="h1"&gt;System elements in icons&lt;/head&gt;
    &lt;p&gt;Operating system, of course, uses some visual elements for its own purposes. Like window controls, resize handles, cursors, shortcuts, etc. It would be a mistake to use those in icons.&lt;/p&gt;
    &lt;p&gt;Unfortunately, Apple fell into this trap, too. They reused arrows.&lt;/p&gt;
    &lt;p&gt;Key shortcuts:&lt;/p&gt;
    &lt;p&gt;HIG has an entire section on ellipsis specifically and how dangerous it is to use it anywhere else in the menu.&lt;/p&gt;
    &lt;p&gt;And this exact problem is in Tahoe, too.&lt;/p&gt;
    &lt;head rend="h1"&gt;Icons break scanning&lt;/head&gt;
    &lt;p&gt;Without icons, you can just scan the menu from top to bottom, reading only the first letters. Because they all align:&lt;/p&gt;
    &lt;p&gt;In Tahoe, though, some menu items have icons, some don‚Äôt, and they are aligned differently:&lt;/p&gt;
    &lt;p&gt;Some items can have both checkmarks and icons, or have only one of them, or have neither, so we get situations like this:&lt;/p&gt;
    &lt;p&gt;Ugh.&lt;/p&gt;
    &lt;head rend="h1"&gt;Special mention&lt;/head&gt;
    &lt;p&gt;This menu deserves its own category:&lt;/p&gt;
    &lt;p&gt;Same icon for different actions. Missing the obvious metaphor. Somehow making the first one slightly smaller than the second and third. Congratulations! It got it all.&lt;/p&gt;
    &lt;head rend="h1"&gt;Is HIG still relevant?&lt;/head&gt;
    &lt;p&gt;I‚Äôve been mentioning HIG a lot, and you might be wondering: is an interface manual from 1992 still relevant today? Haven‚Äôt computers changed so much that entirely new principles, designs, and idioms apply?&lt;/p&gt;
    &lt;p&gt;Yes and no. Of course, advice on how to adapt your icons to black-and-white displays is obsolete. But the principles‚Äîas long as they are good principles‚Äîstill apply, because they are based on how humans work, not how computers work.&lt;/p&gt;
    &lt;p&gt;Humans don‚Äôt get a new release every year. Our memory doesn‚Äôt double. Our eyesight doesn‚Äôt become sharper. Attention works the same way it always has. Visual recognition, motor skills‚Äîall of this is exactly as it was in 1992.&lt;/p&gt;
    &lt;p&gt;So yeah, until we get a direct chip-to-brain interface, HIG will stay relevant.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;In my opinion, Apple took on an impossible task: to add an icon to every menu item. There are just not enough good metaphors to do something like that.&lt;/p&gt;
    &lt;p&gt;But even if there were, the premise itself is questionable: if everything has an icon, it doesn‚Äôt mean users will find what they are looking for faster.&lt;/p&gt;
    &lt;p&gt;And even if the premise was solid, I still wish I could say: they did the best they could, given the goal. But that‚Äôs not true either: they did a poor job consistently applying the metaphors and designing the icons themselves.&lt;/p&gt;
    &lt;p&gt;I hope this article would be helpful in avoiding common mistakes in icon design, which Apple managed to collect all in one OS release. I love computers, I love interfaces, I love visual communication. It makes me sad seeing perfectly good knowledge already accessible 30 years ago being completely ignored or thrown away today.&lt;/p&gt;
    &lt;p&gt;On the upside: it‚Äôs not that hard anymore to design better than Apple! Let‚Äôs drink to that. Happy New year!&lt;/p&gt;
    &lt;head rend="h1"&gt;Notes&lt;/head&gt;
    &lt;p&gt;During review of this post I was made familiar with Jim Nielsen‚Äôs article, which hits a lot of the same points as I do. I take that as a sign there‚Äôs some common truth behind our reasoning.&lt;/p&gt;
    &lt;p&gt;Also note: Safari ‚Üí File menu got worse since 26.0. Used to have only 4 icons, now it‚Äôs 18!&lt;/p&gt;
    &lt;p&gt;Thanks Kevin, Ryan, and Nicki for reading drafts of this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tonsky.me/blog/tahoe-icons/"/><published>2026-01-05T11:51:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46498309</id><title>Jensen: 'We've done our country a great disservice' by offshoring</title><updated>2026-01-05T16:15:20.575574+00:00</updated><content>&lt;doc fingerprint="8bf8c25713b597b3"&gt;
  &lt;main&gt;
    &lt;p&gt;Bottom Line Up Front: In a recent speech, Nvidia CEO Jensen Huang outlined his plan for bringing manufacturing jobs back to America: force companies to build AI infrastructure in America. Huang says this is essential to ensure that everyday Americans can prosper in the age of AI, not just those with PhDs and college degrees. This is something he is fully aligned with President Donald Trump on, and they‚Äôre already taking noticeable action to make sure it happens.&lt;/p&gt;
    &lt;p&gt;The Details: At a Center for Strategic and International Studies (CSIS) fireside chat on securing U.S. leadership in artificial intelligence, Nvidia founder and CEO Jensen Huang addressed his thoughts on federal industrial policy and the best path forward for the United States. When asked about policy approaches spanning energy, regulation, and ownership frameworks, Huang focused on what he described as foundational constraints to long-term growth, linking energy availability, manufacturing capacity, and technological change.&lt;/p&gt;
    &lt;p&gt;Specifically, Huang said, ‚ÄúPresident Trump walked into a situation where dramatic actions needed to be taken. The first dramatic action that needed to be taken is to reverse the mistakes in energy growth over the course of the last decade. We‚Äôve done our country a great disservice. There are no new industries you can grow without energy.‚Äù&lt;/p&gt;
    &lt;p&gt;The idea is simple: if there is no electricity to power America‚Äôs manufacturing hubs, then there‚Äôs no chance they can thrive. Simply building the manufacturing first and the electricity later will skyrocket costs, further making build-out unsustainable.&lt;/p&gt;
    &lt;p&gt;He extended that argument to social and economic outcomes, adding, ‚ÄúIf we want to fix our social issues, domestic social issues, we have to create prosperity, not just for people with PhDs and college degrees. We have to create prosperity for every segment of the economy. The largest segment of the economy is manufacturing. And we‚Äôve offshored that for too long. For 20 years. We got to bring that back. And we have the ability to do so. And this AI industrial revolution, this flashpoint, is precisely when we should do it.‚Äù&lt;/p&gt;
    &lt;p&gt;Nvidia, through its various partners, is helping build out at least $500 billion in AI infrastructure in the U.S. during Trump‚Äôs 2024 term alone. Nvidia plans to use its leverage as the company at the center of all of this to ensure America is the AI manufacturing hub of the world. This, he says, will help bring those needed and prosperous manufacturing jobs back to the States.&lt;/p&gt;
    &lt;p&gt;The remarks came amid a broader discussion of how governments respond to structural shifts driven by AI, automation, and advanced computing. Rather than focusing on specific regulatory mechanisms or fiscal tools, Huang emphasized the importance of building energy supply and industrial capacity. While politicians focus on demonizing nuclear and coal, or the environmental impact of energy buildout, Huang says we should be focusing on ramping up energy production exponentially across every available vertical.&lt;/p&gt;
    &lt;p&gt;Huang‚Äôs perspective is informed by decades at the intersection of technology and manufacturing. Since founding Nvidia in 1993, he has overseen its transformation into a central supplier of computing platforms for AI, data centers, and high-performance systems. That position provides direct exposure to the industrial requirements behind digital innovation, including power generation, fabrication capacity, and workforce availability. From this vantage point, energy is the basis of the economy from which everything is built.&lt;/p&gt;
    &lt;p&gt;While Huang has spoken highly of the Trump administration, the relevance of these remarks extends beyond any single administration or moment. Markets consistently treat energy infrastructure and manufacturing investment as leading indicators of long-term productivity. AI intensifies that relationship by increasing demand for power-intensive facilities such as semiconductor plants and data centers. In that sense, Huang‚Äôs comments align with a broader recognition that advanced technologies remain limited by the infrastructure built out to support them.&lt;/p&gt;
    &lt;p&gt;By framing AI as an ‚Äúindustrial revolution‚Äù rather than solely a software breakthrough, Huang tied social outcomes to industrial strategy. His argument implies that widespread prosperity depends on whether technological change is paired with domestic production and accessible employment.&lt;/p&gt;
    &lt;p&gt;On the date of publication, Caleb Naysmith did not have (either directly or indirectly) positions in any of the securities mentioned in this article. All information and data in this article is solely for informational purposes. For more information please view the Barchart Disclosure Policy here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.barchart.com/story/news/36862423/weve-done-our-country-a-great-disservice-by-offshoring-nvidias-jensen-huang-says-we-have-to-create-prosperity-for-all-not-just-phds"/><published>2026-01-05T13:02:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46498651</id><title>All AI Videos Are Harmful (2025)</title><updated>2026-01-05T16:15:20.152167+00:00</updated><content>&lt;doc fingerprint="2142197480d0ee41"&gt;
  &lt;main&gt;
    &lt;p&gt;When OpenAI released the first version of Sora, I was excited. For years, I'd had this short story sitting on my hard drive, something I'd written long ago and always dreamed of bringing to life as a short film. The only problem was I didn't have the expertise to shoot a movie, and my Blender 3D skills are rusty for lack of use. But Sora promised something different. I could upload my sketches, input my script, and generate the film in my mind. The creative barrier had finally been lifted.&lt;/p&gt;
    &lt;p&gt;But reality was a bit different from the demos. No matter what I tried, my outputs never looked anything like what OpenAI showcased. The scenes were adjacent to what I wanted, not what I actually needed.&lt;/p&gt;
    &lt;p&gt;It wasn't just Sora. I tested Runway ML, experimented with Veo, and tried to keep my spending reasonable. Every model generated the same kind of thing: something that "looked good" in a superficial way. They excelled at creating clich√© scenes, the kind of generic image that checks all the technical boxes. But creating something that could fit into a coherent narrative, something with intention and specificity? That was nearly impossible.&lt;/p&gt;
    &lt;p&gt;When Sora 2 launched, I started right where I left off. Maybe this time would be different. The videos are more realistic than ever, but the main problem remains unchanged. These tools aren't struggling because they can't generate scenes or dialogue, they sure can. The issue is that they generate what I've come to call "AI Videos," and that's a distinct category with its own aesthetic fingerprint.&lt;/p&gt;
    &lt;head rend="h2"&gt;The New Uncanny Valley&lt;/head&gt;
    &lt;p&gt;Think about how you instantly recognize certain types of content. If I described a video to you right now: fast-paced, someone talking directly to a screen with multiple jump cuts, a ring light's circular reflection visible in their eyes, their bedroom visible in the background. You would instantly say "TikTok video." The format is hard to miss these days.&lt;/p&gt;
    &lt;p&gt;AI-generated videos have developed their own unique look. There's a visual quality that marks them, a subtle wrongness that your brain picks up on even when you can't articulate exactly what's off. It's the new uncanny valley, and I feel an intense revulsion whenever I encounter it. I'm not alone in this reaction either. In my small circle of friends and colleagues, we've all developed the same instinctive aversion.&lt;/p&gt;
    &lt;p&gt;I'm starting to feel the same revulsion for YouTube shorts even when they are created by real people. The reason is, well, YouTube has been secretly using AI to alter real videos, making authentic content start to look artificially generated. You will notice people's faces look smoothed or sharpened, and that happens without the creator's knowledge or consent. The line between real and AI-generated content is blurring from both directions.&lt;/p&gt;
    &lt;p&gt;So if these videos trigger such a negative response in many viewers, where can AI-generated content actually thrive? The answer: with spammers, scammers, rage-baiters, and manipulators.&lt;/p&gt;
    &lt;p&gt;These bad actors are having a field day with AI video tools. A couple months ago, I wrote about AI Video Overviews, I speculated that Google might eventually start using AI-generated videos as enhanced search results, synthesizing information from multiple sources into custom video summaries. That remains speculative. But for harmful content? That's not speculation, it's happening right now, at scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Primary Victims&lt;/head&gt;
    &lt;p&gt;The main targets are older adults. My parents and their peer group are constantly sharing AI-generated videos in their group chats and on social media. Even as I write this, my mother just sent me a video showing Denzel Washington giving life advice, entirely fabricated, of course.&lt;/p&gt;
    &lt;p&gt;There is a wide variety of content. Health misinformation, sensational fake news, videos claiming Obama has embraced Islam, an elderly Tai Chi master giving dubious health tips, Trump supposedly reversing or doubling down on positions he never actually took. The specific claims change daily, but the pattern remains constant.&lt;/p&gt;
    &lt;p&gt;These videos spread like wildfire despite our collective, repeated efforts to educate people. I've spent countless hours explaining why these videos are fake. In my community group chat, I've explained the telltale signs multiple times, like the little cloud icon with eyes that appears on AI-generated content (sora watermark). I've shared practical tips: if a video seems too good or too shocking to be true, search for the information on Google to verify it. Nothing seems to stick.&lt;/p&gt;
    &lt;p&gt;Some days, according to these videos, we're at war. Other days, entire cities have burned down, or a tsunami has devastated Los Angeles. You can't debunk faster than this information spreads.&lt;/p&gt;
    &lt;p&gt;When you find these videos on YouTube, scroll down to the comments. You'll see real people engaging seriously with fabricated content, offering heartfelt responses to synthetic personas, debating points that were never actually made by the people shown in the videos. I get phone calls from family overseas, people reach out, or share what they think is happening right at my doorstep. When I ask where they heard it? They forward a whatsapp video.&lt;/p&gt;
    &lt;p&gt;There's no easy solution to this crisis.&lt;/p&gt;
    &lt;p&gt;AI video technology has found its audience, just not the audience the marketing materials promised. These tools weren't really designed to help people like me overcome technical limitations and bring our stories to life. They were made to enable those who want to manipulate, deceive, and exploit people for engagement, profit, or ideology.&lt;/p&gt;
    &lt;p&gt;I've tried to find legitimate, beneficial use cases for AI video generation. I've thought about educational applications, accessibility features, and experimental art projects. Maybe they exist in theory, but in practice, I keep coming back to the same conclusion.&lt;/p&gt;
    &lt;p&gt;Right now, every AI video I encounter is harmful. Every single one, without exception.&lt;/p&gt;
    &lt;p&gt;Either it's directly harmful like spreading misinformation, impersonating real people, manipulating vulnerable viewers. Or it's indirectly harmful by training us to accept a synthetic reality where nothing can be trusted and everything must be questioned. Even the "harmless" AI videos contribute to a broader erosion of trust in visual media.&lt;/p&gt;
    &lt;p&gt;This technology is devastatingly effective for the purposes bad actors have found for it. The creative barrier I hoped to overcome remains in place. But now there's a new barrier too. The barrier of trust. And that one might be much harder to rebuild.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://idiallo.com/blog/all-ai-videos-are-harmful"/><published>2026-01-05T13:44:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46498662</id><title>Imagine 130M Washing Machines</title><updated>2026-01-05T16:15:20.013757+00:00</updated><content/><link href="https://scottsumner.substack.com/p/imagine-130000000-washing-machines"/><published>2026-01-05T13:46:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46498735</id><title>I switched from VSCode to Zed</title><updated>2026-01-05T16:15:19.216961+00:00</updated><content>&lt;doc fingerprint="8610177126853772"&gt;
  &lt;main&gt;
    &lt;p&gt;For many years VSCode has been my day-to-day IDE for everything: Python, Go, C, occasional frontend development, and what not. It was never perfect but it worked. I like using mainstream tools with minimal configuration, so it suited me perfectly. But recent VSCode developments forced me to look for an alternative. In December I switched to Zed completely, and I think I'm never going back.&lt;/p&gt;
    &lt;head rend="h2"&gt;VSCode no more&lt;/head&gt;
    &lt;p&gt;VSCode felt stable over the years. This changed with the AI era. Now every update there are new AI-related features that I need to figure out how to disable. Few examples. I don't use Github Copilot. My preferred AI tool is a CLI (lately Codex). So I disabled Copilot. But VSCode continued to force it on me. After one update I see "cmd+I to continue with copilot" on every line I edit. Another update I see new inline terminal suggestions and they only interfere with my shell suggestions. There were a few other similar intrusions I don't recall now.&lt;/p&gt;
    &lt;p&gt;So my &lt;code&gt;settings.json&lt;/code&gt; grew into a list of opt-outs. I could still live with that. The biggest issue for me was that VSCode became more buggy, feeling even slower, and crashing frequently ‚Äì not surprising giving the pace of shipping new Copilot features.&lt;/p&gt;
    &lt;p&gt;I still think VSCode is an amazing IDE and I'm grateful to all the maintainers and the greatest extension community. There is a hope the VSCode approach to AI integration becomes less intrusive and more thoughtful, things stabilize, and VSCode "just works" again. But now it was time to look for somethings else.&lt;/p&gt;
    &lt;p&gt;I knew I didn't want to switch to JetBrains IDEs. There are powerful but feel heavy and I don't enjoy using them. Vim, Emacs, and its modern variants are on the opposite spectrum. Probably they'll work great but only after I retire and have the time to configure and learn them properly. And there was Zed that I didn't know much about besides it being modern and lightweight IDE written in Rust. I gave it a try.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zed: first impressions&lt;/head&gt;
    &lt;p&gt;In Zed I felt immediately at home coming from VSCode. The UI is similar. Zed's default keybindings are mostly the same. The biggest UX difference for me was that VSCode shows opened files (a.k.a. open editors) in the left sidebar, which I often used for navigation. In Zed there is no such panel, and the recommended approach is to navigate using file search (&lt;code&gt;Cmd+P&lt;/code&gt;). There is also a way to import VSCode settings automatically. I wanted to start fresh, so I didn't use it. The only configuration I had to do is change the font size and theme, disable inline git blame, and enable autosave.&lt;/p&gt;
    &lt;p&gt;My main impression of Zed was how fast and responsive it is compared to VSCode. I even noticed the slowness of some other tooling, which I got used to, and optimized it. Another highlight is that Zed has been stable for me without any glitches or crashes over the last two weeks. This all brings back joy of programming.&lt;/p&gt;
    &lt;p&gt;I mostly program in Python and sometimes Go. With Go, Zed worked out-of-the-box without any extra setup. With Python, it wasn't so smooth, and I had to spent half a day to get it working. Next is boring details that I wish I knew from the start.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making Zed work for Python&lt;/head&gt;
    &lt;p&gt;First some context. Zed is an IDE that relies on language servers to provide language-specific features like autocomplete, code navigation, type checking, etc. It natively supports multiple Python language servers. One is Pyright, but its capabilities as a language server are limited ‚Äì it's primarily a type checker that other language servers build upon. For example, Microsoft develops Pylance as a language server on top of Pyright. Pylance is the most widely used Python language server, however, it's not open source, so it cannot be used outside of VSCode. Zed uses Basedpyright as the default language server instead.&lt;/p&gt;
    &lt;p&gt;The first problem I encountered when I opened a Python project in Zed is that I saw a lot of type checker errors highlighted in the code. Apparently, Basedpyright ran in a stricter &lt;code&gt;typeCheckingMode&lt;/code&gt;. For my Python projects I used to configure Pyright with &lt;code&gt;typeCheckingMode&lt;/code&gt; unspecified, which defaults to &lt;code&gt;standard&lt;/code&gt;. The Zed docs say that "while Basedpyright in isolation defaults to the¬†&lt;code&gt;recommended&lt;/code&gt;¬†type-checking mode, Zed configures it to use the less-strict¬†&lt;code&gt;standard&lt;/code&gt;¬†mode by default, which matches the behavior of Pyright. This confused me since I definitely saw it working in &lt;code&gt;recommended&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;I tried to specify &lt;code&gt;typeCheckingMode&lt;/code&gt; explicitly in settings.json like shown in the docs:&lt;/p&gt;
    &lt;code&gt;// ...
"lsp": {
    "basedpyright": {
      "settings": {
        "basedpyright.analysis": {
          "typeCheckingMode": "standard"
        }
      }
    }
  }
// ...
&lt;/code&gt;
    &lt;p&gt;This didn't work. There were still a lot of typing errors I didn't want to check for. I figured out eventually that as long as you have &lt;code&gt;pyproject.toml&lt;/code&gt; with the &lt;code&gt;[tool.pyright]&lt;/code&gt; section, the Basedpyright's default &lt;code&gt;typeCheckingMode = "recommended"&lt;/code&gt; is used. My solution was to set &lt;code&gt;typeCheckingMode = "standard"&lt;/code&gt; in every &lt;code&gt;pyproject.toml&lt;/code&gt; explicitly. The solution took me a long time ‚Äì I found several Github issues related to language server settings being ignored or not working as expected, so it looked like a bug at first. Now I see it's rather intended, although not clear from the docs. The lesson: If you define &lt;code&gt;[tool.pyright]&lt;/code&gt; , don't rely on Pyright defaults but set the options explicitly.&lt;/p&gt;
    &lt;p&gt;Next I noticed that I as I edited the code I didn't see new typing errors shown for a file until I changed that file. I'd like to see such errors when, for example, a symbol is deleted but still used in another file. This I fixed by setting &lt;code&gt;"disablePullDiagnostics": true&lt;/code&gt; in settings.json:&lt;/p&gt;
    &lt;code&gt;// ...
  "lsp": {
    "basedpyright": {
      "initialization_options": {
        "disablePullDiagnostics": true
      },
    }
  }
// ...
&lt;/code&gt;
    &lt;p&gt;That's basically it. Virtual environment detection and other Python specifics were smooth. At one point I also tried ty instead of Basedpyright, which announced Beta just recently. It worked well from the start. I still chose Basedpyright because the CI runs Pyright and I want the same type checker locally. But given the success of ruff and uv, there is a high chance of me (and everyone else) switching to ty both for development and CI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping up&lt;/head&gt;
    &lt;p&gt;Zed is now my go-to IDE for Python and Go and my first choice as a general-purpose editor. It's fast, stable, familiar, feature-rich, with nice out-of-the box experience. The Zed extension ecosystem is tiny compared to VSCode, but I found it sufficient for my needs. The only thing I miss is a powerful git diff viewer with side-by-side diffs like GitLens.&lt;/p&gt;
    &lt;p&gt;Zed's AI features are actively developed but easily ignored and don't stand in the way. Zed offers paid plans for edit predictions, which seems like it can be a nice way to keep the project going. I want to wish Zed all the best!&lt;/p&gt;
    &lt;p&gt;As regards to VSCode, they finally got a decent competitor, and the Microsoft leverage may not be sufficient to keep the dominant position. VSCode, wake up!&lt;/p&gt;
    &lt;p&gt;Finally, my minimal Zed's settings.json in full:&lt;/p&gt;
    &lt;code&gt;{
  "autosave": "on_focus_change",
  "git": {
    "inline_blame": {
      "enabled": false
    }
  },
  "icon_theme": {
    "mode": "light",
    "light": "Zed (Default)",
    "dark": "Zed (Default)"
  },
  "base_keymap": "VSCode",
  "ui_font_size": 22,
  "buffer_font_size": 18,
  "theme": {
    "mode": "light",
    "light": "One Light",
    "dark": "One Dark"
  },
  "lsp": {
    "basedpyright": {
      "initialization_options": {
        "disablePullDiagnostics": true
      },
      "settings": {
        "basedpyright.analysis": {
          // Won't take affect if pyproject.toml has `[tool.pyright]`
          "typeCheckingMode": "standard"
        }
      }
    }
  },
  "languages": {
    "Python": {
      "language_servers": ["!ty", "basedpyright", "..."]
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;If you have any questions, comments or suggestions, feel free to join the GitHub discussion.&lt;/p&gt;
    &lt;p&gt;Follow me for more content: GitHub | Bluesky | Twitter | LinkedIn&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tenthousandmeters.com/blog/i-switched-from-vscode-to-zed/"/><published>2026-01-05T13:52:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46498775</id><title>GOG Patrons- Join gamers keeping classics alive</title><updated>2026-01-05T16:15:18.738712+00:00</updated><content>&lt;doc fingerprint="3d241b7b0207ed95"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Obsolete systems&lt;/head&gt;
    &lt;p&gt;Old games often can‚Äôt run on today‚Äôs computers. Without fixes, updates, or legal emulation, they‚Äôre left unplayable.&lt;/p&gt;
    &lt;p&gt;GOG Patrons is a community of like-minded gamers who fund games restoration and want to actively shape its future&lt;/p&gt;
    &lt;p&gt; Remember those games that changed how you think about gaming?&lt;lb/&gt;Games crafted with passion, not by committee? &lt;/p&gt;
    &lt;p&gt;Every year, more of them vanish forever ‚Äì and with them, a piece of who we are.&lt;/p&gt;
    &lt;p&gt;Old games often can‚Äôt run on today‚Äôs computers. Without fixes, updates, or legal emulation, they‚Äôre left unplayable.&lt;/p&gt;
    &lt;p&gt;The original files and assets are often lost or damaged, making faithful restoration nearly impossible.&lt;/p&gt;
    &lt;p&gt;Rights expire or vanish in legal limbo, preventing beloved games from ever being re-released.&lt;/p&gt;
    &lt;p&gt;For nearly two decades, we‚Äôve brought forgotten classics back to life - testing, fixing, and adapting them for modern systems.&lt;/p&gt;
    &lt;p&gt;Because of this, millions of gamers can enjoy games from the '90s and '00s again.&lt;/p&gt;
    &lt;p&gt;Expand our restoration teams and tools to bring more classics back to modern systems ‚Äì safely, legally, and sooner.&lt;/p&gt;
    &lt;p&gt;Support more mods integrations, better compatibility, localization, and new quality-of-life features.&lt;/p&gt;
    &lt;p&gt;Create a home where restored games can evolve ‚Äì with features that respect their legacy and invite the community to help maintain and enhance them for future generations.&lt;/p&gt;
    &lt;p&gt;‚ÄúI just want to say Thank you GOG for bringing this game back. It's things like this why I adore this platform. It helps retain my faith in the gaming industry that a group exists to ensure gems like Alpha Protocol can be enjoyed by future generations.‚Äù ‚Äì ARealHero_&lt;/p&gt;
    &lt;p&gt;‚ÄúThank you so much. I could cry. My favorite game ever made [Breath of Fire IV], finally available again after so long. Only days away from my wedding, feels like a dream come true. Sincerely, thank you for bringing this game back, for me, for many other fans, and the countless people who can now experience the game.‚Äù ‚Äì Xavelrie&lt;/p&gt;
    &lt;p&gt;‚ÄúOne of the community's most requested games (or rather, set of games) has finally been fulfilled. Thank you, GOG, and thank you, Capcom! Since the beginning of my journey with digital gaming platforms, I have dreamed of owning Resident Evil 1, 2, and 3 on some kind of platform, and now I can.‚Äù ‚Äì FurryThales&lt;/p&gt;
    &lt;p&gt;‚ÄúThank you GOG! I never played the original Dino Crisis since I have never had any console, but I've always heard that Dino Crisis is a must play for any gamer. GOG did such a good job giving us the opportunity to experience this on PC.‚Äù ‚Äì Tomas_Casas&lt;/p&gt;
    &lt;p&gt;Connect with classic gaming fans who collect, play, and preserve the games they love.&lt;/p&gt;
    &lt;p&gt;Help decide which games we should focus on.&lt;/p&gt;
    &lt;p&gt;Your nickname will appear on the game pages of titles you help preserve.&lt;/p&gt;
    &lt;p&gt;Exclusive videos, Q&amp;amp;As, inside looks at game restoration, preservation, and more!&lt;/p&gt;
    &lt;p&gt;You can cancel anytime.&lt;/p&gt;
    &lt;p&gt;The GOG Preservation Program is our ongoing effort to save classic games from being lost to time. That means working to secure rights, fixing compatibility so they run hassle-free on modern systems, and even rebuilding missing features so the experience is the best you can get, while staying true to the original.&lt;/p&gt;
    &lt;p&gt;When you become a Patron, your contribution goes directly into supporting GOG's work. It helps us cover our daily operations and things like licensing old titles, hiring engineers to make them playable again, and building tools that keep them alive for the long term.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.gog.com/en/patrons"/><published>2026-01-05T13:57:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46499646</id><title>Show HN: DoNotNotify ‚Äì log and intelligently block notifications on Android</title><updated>2026-01-05T16:15:18.565026+00:00</updated><content>&lt;doc fingerprint="410a056bd3dbf57"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Privacy First Design&lt;/head&gt;
    &lt;p&gt;Your notifications contain sensitive OTPs and personal messages. DoNotNotify processes everything offline. No servers, no tracking.&lt;/p&gt;
    &lt;head rend="h3"&gt;Granular Control&lt;/head&gt;
    &lt;p&gt;Create powerful rules based on app names, message content, or regex patterns. Whitelist urgent alerts, blacklist the noise.&lt;/p&gt;
    &lt;head rend="h3"&gt;Zero Noise&lt;/head&gt;
    &lt;p&gt;Stop the constant buzzing from promotional notifications. Keep only the notifications that actually matter to you.&lt;/p&gt;
    &lt;head rend="h2"&gt;See it in Action&lt;/head&gt;
    &lt;p&gt;Simple, powerful, and clean interface designed for efficiency.&lt;/p&gt;
    &lt;head rend="h2"&gt;Commitment to Privacy&lt;/head&gt;
    &lt;p&gt;We believe privacy is a fundamental right. DoNotNotify does not collect or share any personal information. We don't know who you are, and we don't want to.&lt;/p&gt;
    &lt;p&gt;Read our full Privacy Policy to learn more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://donotnotify.com/"/><published>2026-01-05T15:10:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46499694</id><title>Show HN: A simulator for engineers transitioning from IC to management</title><updated>2026-01-05T16:15:18.231488+00:00</updated><content>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://apmcommunication.com/scenario/backchannel-vp"/><published>2026-01-05T15:13:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46499976</id><title>RevisionDojo, a YC startup, is running astroturfing campaigns targeting kids</title><updated>2026-01-05T16:15:17.988530+00:00</updated><content>&lt;doc fingerprint="ad2284e36b6f0876"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;RevisionDojo is a YC-backed test prep company ($3.4M raised) that sells International Baccalaureate (IB) test prep. Over the past year, users on r/IBO sub-reddit have documented a pattern of unethical marketing practices:&lt;/p&gt;
      &lt;p&gt;*Astroturfing:* Coordinated campaigns where accounts pose as students sharing "cheatsheets" and "predicted exam leaks." Other accounts then upvote, leave supportive comments, and ask follow-up questions‚Äîcreating the illusion of organic student excitement. Multiple threads have exposed this pattern [1][2][3].&lt;/p&gt;
      &lt;p&gt;*Paid fake posts:* High school students report being offered payment to write promotional Reddit posts [4].&lt;/p&gt;
      &lt;p&gt;*Pressuring critics:* Users who post negative reviews report being contacted directly by company representatives, told it's "a shame" they're posting publicly [5]. Critical comments receive coordinated mass downvotes [6].&lt;/p&gt;
      &lt;p&gt;*Soliciting copyrighted materials:* They use TikTok influencers and fake reddit posts to persuade students to sell them official IB exam papers, violating IB policies [7].&lt;/p&gt;
      &lt;p&gt;The r/IBO moderators are actively investigating [8].&lt;/p&gt;
      &lt;p&gt;These practices appear to be working great for them. Recently, they acquired OnePrep (oneprep.xyz), a free SAT prep tool that was already popular on r/sat. Since the acquisition, the same manipulation tactics have been deployed at scale: 150 Trustpilot reviews in a window of a few days [9], and widespread coordinated Reddit manipulation‚Äîmultiple accounts posting "tips" that recommend Oneprep, coordinated upvoting, and fake enthusiasm in comments. The most prominent example was a 2,000+ upvote post removed by moderators for manipulation, but it's part of a sustained campaign across the subreddit.&lt;/p&gt;
      &lt;p&gt;*Sources:*&lt;/p&gt;
      &lt;p&gt;[1] https://www.reddit.com/r/IBO/comments/1p55qun/ [2] https://www.reddit.com/r/IBO/comments/1jsb00a/ [3] https://www.reddit.com/r/IBO/comments/1ohcohi/ [4] https://www.reddit.com/r/IBO/comments/1p55qun/comment/nqmhal3/ [5] https://www.reddit.com/r/IBO/comments/1my1ajx/comment/na94upv/ [6] https://www.reddit.com/r/IBO/comments/1my1ajx/comment/na8zvs4/ [7] https://www.reddit.com/r/IBO/comments/1mej900/ [8] https://www.reddit.com/r/IBO/comments/1my1ajx/comment/nagdkl5/ [9] https://www.trustpilot.com/review/oneprep.xyz&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46499976"/><published>2026-01-05T15:34:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46500022</id><title>CSS sucks because we don't bother learning it (2022)</title><updated>2026-01-05T16:15:17.528392+00:00</updated><content>&lt;doc fingerprint="3d48b01d192a209d"&gt;
  &lt;main&gt;
    &lt;p&gt;Every time I hear someone complaining about how much CSS sucks, I have one question: Did you ever learn CSS? The words want to burst out of my lips but I stay silent and keep to myself. When I was much greener in this field, I used to ask the question. What I noticed is that no one was willing to change their mind. CSS sucked, it was designed by some terrible people, and now we have no choice but to maintain it. The reality is, you can say that about pretty much every programming language. Though people like to point out that CSS is not one. But do we ever set time to learn CSS?&lt;/p&gt;
    &lt;p&gt;When programmers build complex apps that communicate with dozens of other services, they forget one thing. Nowhere in the design, they think about how the result of their work will be presented to a user. In the age of microservices, it becomes ever more difficult for one person to know how all the parts connect together. Being a backend developer takes experience and dedication. You master the programming language, you study your employers architecture, you learn from those who paved the path before you. Every programmer worth their salt agrees with Peter Norvig's essay Teach Yourself programming in Ten Years.&lt;/p&gt;
    &lt;p&gt;It's inconceivable that you can learn a programming language and be effective in it in a short time. There is much more to programming than syntax. Programming is writing, it is problem solving, it is art. You build a mental model of a problem, break it into smaller pieces, and translate it into a language a computer can understand. It takes years to become really good at it.&lt;/p&gt;
    &lt;p&gt;But for some reason, we finish all parts of our application, then we start learning and writing CSS at the same time. Like a college student going through a test, saving the easy questions for last. Only, when they finally get to those questions, they are short on time and realize that it's not as easy as they thought.&lt;/p&gt;
    &lt;p&gt;CSS may not be a programming language per se, but that doesn't mean you can learn it in a day. You can learn the syntax just like you can learn the cool parts of JavaScript in a day. But using CSS to solve a design problem demands just as much planning and experience as you would with any other task.&lt;/p&gt;
    &lt;p&gt;A lot of people bring up how it was nearly impossible to align a div to the center in CSS 2. Many times, they will have an insane HTML structure that makes it impossible to do so. They will spend hours on google looking for ways to do it, and end up with a hack that works as long as you don't touch anything else on the page. With CSS 3, they'll use the same bad HTML structure and use flex box to auto-magically align it. It becomes a pain for the next person to maintain. But in their defense, they hated maintaining it too.&lt;/p&gt;
    &lt;p&gt;Imagine building an application by googling every single line of code. You end up with something that probably works as long as the circumstances don't change. Updating the application becomes a nightmare, it makes you hate programming. That's how and why people hate CSS. They never take the time to learn it. They slap a framework like bootstrap on top of their project, they use &lt;code&gt;!important&lt;/code&gt;, they use &lt;code&gt;position: absolute&lt;/code&gt;, they sprinkle a bunch of classes name in their HTML. They have no idea what they are doing.&lt;/p&gt;
    &lt;p&gt;Is CSS perfect? No, not at all. They could have come up with something better than &lt;code&gt;margin: 0 auto&lt;/code&gt; to center a block element in CSS 2. They could have come up with something better than the &lt;code&gt;content&lt;/code&gt; property in pseudo selectors. But even when I look at those issues, once I understand the behavior, I can plan how I use it.&lt;/p&gt;
    &lt;p&gt;For example, I often advise never to use &lt;code&gt;position: absolute&lt;/code&gt;. Then people ask me, why are you using it in your code then? My answer is, never use it, so you'll know when to use it. When you give someone the ability to use position absolute, they'll align the entire page with it. They'll only notice things are broken when they use a different screen.&lt;/p&gt;
    &lt;p&gt;If you hate CSS, there are thousands of places online where you can learn it. Follow an actual course with an experienced instructor. Learn to design a page using CSS. It's much easier than your traditional programming language, but you can't understand it unless you learn it first.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://idiallo.com/blog/learn-css"/><published>2026-01-05T15:37:38+00:00</published></entry></feed>