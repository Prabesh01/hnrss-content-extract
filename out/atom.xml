<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-03T23:10:25.234606+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46469577</id><title>Daft Punk Easter Egg in the BPM Tempo of Harder, Better, Faster, Stronger?</title><updated>2026-01-03T23:10:32.047722+00:00</updated><content>&lt;doc fingerprint="e65c813589908cb4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Was Daft Punk Having a Laugh When They Chose the Tempo of Harder, Better, Faster, Stronger?&lt;/head&gt;
    &lt;p&gt;Google "harder better faster stronger bpm" and Google‚Äôs ‚ÄúAI Overview‚Äù will tell you:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Daft Punk‚Äôs ‚ÄúHarder, Better, Faster, Stronger‚Äù generally sits around 123 BPM (Beats Per Minute), though some analyses find it slightly higher (like 123.48 BPM) or list different BPMs in remixes/workouts, with exact figures varying slightly by source and version.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spotify‚Äôs metadata database, SongBPM, and most other online BPM databases list it at exactly 123.&lt;/p&gt;
    &lt;p&gt;But I think our helmet-clad robot friends might have been making a little joke that we‚Äôve apparently all missed. The BPM of Harder, Better, Faster, Stronger is actually 123.45.&lt;/p&gt;
    &lt;p&gt;How do I know this? It so happens that for over 10 years I‚Äôve written an app called Tempi that shows the BPM of music in real time, so I know a little bit about the science and algorithms behind music tempo detection.&lt;/p&gt;
    &lt;p&gt;Most tempo detection software works basically the same way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A specialized algorithm called the Fast Fourier Transform (FFT) collects overlapping energy levels at different frequency bands.&lt;/item&gt;
      &lt;item&gt;Those levels are refined into well-defined peaks that represent rhythmic events in the track.&lt;/item&gt;
      &lt;item&gt;Another algorithm (autocorrelation) looks for patterns, or more accurately periodicity, in those peaks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But these patterns are tricky because there‚Äôs all kinds of noise, performance inaccuracies, and rhythmic harmonics throwing things off. All that is to say, a) it‚Äôs complicated and b) it‚Äôs not perfectly accurate.&lt;/p&gt;
    &lt;p&gt;When I make changes to my own system of course I need some way to know if it‚Äôs getting better or worse, so I have a test library of hundreds of song snippets that I score it against. One of these songs is Daft Punk‚Äôs HBFS, and early on I noticed something strange about that track.&lt;/p&gt;
    &lt;p&gt;Almost all electronic music is synced to a sequencer and so obviously is going to have a very steady tempo. But while the vast majority of electronic music tracks I test have an ‚Äúintegral‚Äù tempo ‚Äì meaning their tempo is exactly some round number like 95, and not a fraction like 95.2 ‚Äì my software always finds the BPM of HBFS to be somewhere between 123 and 124, but not exactly either. For years I‚Äôve chalked this up to inconsistencies with my system and didn‚Äôt think much of it. But lately I‚Äôve made improvements to the system so that it‚Äôs much more accurate and it now tells me the BPM of HBFS is 123.4.&lt;/p&gt;
    &lt;p&gt;And that got me thinking, ‚ÄúHmm. Did these guys pick that tempo because they have a sense of humor? And if so, how far would they take it?‚Äù&lt;/p&gt;
    &lt;p&gt;To get to the bottom of this I needed to establish what the BPM of HBFS really is.&lt;/p&gt;
    &lt;head rend="h3"&gt;And that‚Äôs actually pretty easy to do‚Ä¶&lt;/head&gt;
    &lt;p&gt;Here‚Äôs a Venn diagram showing the overlap between human and computer capabilities in the digital realm:&lt;/p&gt;
    &lt;p&gt;Computers can do almost all ‚Äúcomputer-y‚Äù things (i.e. things that can be entirely done on a computer) MUCH better, faster, (and stronger?) than humans. But for the time being there remain a few things that humans can do very easily which computers find difficult. Along with counting traffic lights and crosswalks, one of those things is finding the exact BPM of a song. Not an estimate like most software does, but the exact value with extreme precision across the entire song. Anyone with a basic sense of rhythm and an audio app can do this.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open the song in an audio app like Logic, Audition, Ableton, Reaper, ProTools, etc.&lt;/item&gt;
      &lt;item&gt;Zoom in on the waveform a little bit so you can see the shape of the beats.&lt;/item&gt;
      &lt;item&gt;Find the first obvious beat ‚Äì meaning it has a well-defined waveform peak ‚Äì and the last obvious beat. Let‚Äôs call these ‚Äúbookend‚Äù beats.&lt;/item&gt;
      &lt;item&gt;Measure the exact duration in seconds between the bookend beats.&lt;/item&gt;
      &lt;item&gt;Play the song and count all the beats starting at the first bookend beat and ending at the last bookend beat. (If you have an old school calculator, an easy way to do this is type ‚Äú1+1=‚Äù and then just keep tapping ‚Äú=‚Äù to add 1 on each beat.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then to get the exact tempo of the track, averaged throughout the entire thing, use this formula:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * (number_of_beats - 1) / duration&lt;/code&gt;
    &lt;p&gt;Computers have a rough time of this because they don‚Äôt really know how to ‚Äúkeep a beat‚Äù, and the algorithms that can find the beat do a lot better when they already know the estimated BPM, which is obviously a chicken/egg problem.&lt;/p&gt;
    &lt;p&gt;For the first bookend beat in HBFS I used the first beat after the ‚Äúwhooshing‚Äù intro, at around 5.58s. The last bookend beat I used the last ‚Äúwork‚Äù at about the 3:41.85 mark. (‚ÄúNever‚Äù and ‚ÄúOver‚Äù aren‚Äôt good candidates because you can‚Äôt see their waveform peaks.)&lt;/p&gt;
    &lt;p&gt;That gives exactly 446 beats or 445 intervals.&lt;/p&gt;
    &lt;p&gt;I tried this with two different copies of HBFS. The Discovery CD rip I have of the song has a duration between the bookend beats of 216.282, so:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * 445 / 216.282 = 123.4499403556&lt;/code&gt;
    &lt;p&gt;The ‚ÄúYouTube official audio‚Äù track I tested has a duration of 216.276, so:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * 445 / 216.276 = 123.4533651445&lt;/code&gt;
    &lt;p&gt;The original Discovery CD version has obviously undergone less processing over time than the YouTube version so I tend to think it‚Äôs more representative, and it‚Äôs very close to 123.45 ‚Äì only a 0.00005964 difference! But even the more modern YouTube version closely rounds to 123.45.&lt;/p&gt;
    &lt;p&gt;So hopefully I‚Äôve put this fact to rest:&lt;/p&gt;
    &lt;p&gt;The BPM of Harder, Better, Faster, Stronger is 123.45.&lt;/p&gt;
    &lt;head rend="h2"&gt;But‚Ä¶was this intentional, or just a happy accident?&lt;/head&gt;
    &lt;p&gt;The year is 1999 or 2000. Would the gear Daft Punk uses even support fractional BPMs? And if so out to how many decimal places?&lt;/p&gt;
    &lt;p&gt;From their 2001 interview with Remix Magazine (archive.org) we know that Bangalter says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Our sequencing is done either on an E-mu SP-1200, an Akai MPC, or a PC with Logic Audio software. We do not work on things in just one way.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And from later interviews we know the Akai MPC was specifically an MPC-3000. (Oh, and that‚Äôs Emagic‚Äôs Logic, not Apple‚Äôs. Apple didn‚Äôt acquire Emagic until 2002.)&lt;/p&gt;
    &lt;p&gt;Did the E-mu support fractional BPMs? Yes, but only to 1 decimal place:&lt;/p&gt;
    &lt;p&gt;The Akai MPC-3000? Yep, also to 1 decimal place:&lt;/p&gt;
    &lt;p&gt;What about Emagic‚Äôs Logic?&lt;/p&gt;
    &lt;p&gt;Oooh, look at that. Logic supported BPMs to *4* decimal places.&lt;/p&gt;
    &lt;p&gt;But while we know those three sequencers were used on the Discovery album, I‚Äôm not sure anyone else knows which one was specifically used on HBFS. I‚Äôve searched and searched and it seems this detail has just never been revealed.&lt;/p&gt;
    &lt;p&gt;And to confuse matters more, in a 2013 interview with Time Magazine, Bangalter says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;So we‚Äôve never actually made music with computers! [laughs] Neither Homework nor Discovery nor even Human After All were made with computers.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Was he contradicting himself from 12 years before? Or did he forget? Or maybe it‚Äôs a terminology thing?&lt;/p&gt;
    &lt;p&gt;That the CD version is so close to exactly 123.45 makes me think this was intentional. And if it was? Well played, robots. You managed to leave a little Easter egg hiding in plain sight for 25 years.&lt;/p&gt;
    &lt;p&gt;Update: A Hacker News reader pointed out that I accidentally reversed the durations of the YouTube clip and the CD rip. Fixed!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.madebywindmill.com/tempi/blog/hbfs-bpm/"/><published>2026-01-02T21:27:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46471199</id><title>2026 will be my year of the Linux desktop</title><updated>2026-01-03T23:10:31.469938+00:00</updated><content>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xeiaso.net/notes/2026/year-linux-desktop/"/><published>2026-01-03T00:15:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46473348</id><title>Trump says Venezuela‚Äôs Maduro captured after strikes</title><updated>2026-01-03T23:10:31.009919+00:00</updated><content/><link href="https://www.reuters.com/world/americas/loud-noises-heard-venezuela-capital-southern-area-without-electricity-2026-01-03/"/><published>2026-01-03T06:35:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46475296</id><title>Profiling with Ctrl-C (2024)</title><updated>2026-01-03T23:10:30.894666+00:00</updated><content>&lt;doc fingerprint="2a50811364244ad9"&gt;
  &lt;main&gt;
    &lt;p&gt;I once wrote about how profiler output can be misleading. Someone commented that you don√¢t need profilers - just Ctrl-C your program in a debugger instead, and you√¢ll see the call stack where your program probably spends most of its time. I admit that I sneered at the idea at the time, because, despite those comments√¢ almost aggressive enthusiasm, this method doesn√¢t actually work on the hard problems. But as my outlook on life worsened with age, I came to think that Ctrl-C profiling deserves a shout-out, because it√¢s very effective against stupid problems encountered by lazy people operating in unfriendly environments.&lt;/p&gt;
    &lt;p&gt;I mean, I√¢ve tended to dismiss the stupid problems and focus on the hard ones, but is this a good approach in the real world? Today I√¢m quite ready to accept that most of life is stupid problems encountered by lazy people operating in unfriendly environments. Certainly, one learning experience was becoming such a person myself, by stepping into a senior management role1 and then going back to programming after a few years. Now I√¢m lazy because I got used to not doing anything myself, and I√¢m in an environment which is unfriendly to me, because I forgot how things work, or they no longer work the way they used to. And while I√¢m a bit ashamed to admit this as someone who√¢s developed several profilers himself, I√¢m often not really in the mood to figure out how to use a profiler in a given setting.&lt;/p&gt;
    &lt;p&gt;But, here√¢s a program taking a minute to start up. Well, only in the debug build; this must be why nobody fixed it, but we really should, it sucks to wait for a full minute every time you rebuild &amp;amp; rerun. So I Ctrl-C the thing, and what do you know, there√¢s one billion stack frames from the nlohmann JSON parser, I guess it all gets inlined in the release build; must be what they call √¢zero-cost abstraction√¢2. Another Ctrl-C, another call stack, coming from a different place but again ending up parsing JSON. And I don√¢t know what the fix was - a different JSON parser, or compiling some code with optimizations even in the debug build - but someone fixed it after my Ctrl-C-based report.&lt;/p&gt;
    &lt;p&gt;Or let√¢s say I√¢m trying to switch to the LLD linker from gold, to speed up the linking. Why not the even faster mold? - because I√¢m on MIPS, and mold doesn√¢t support MIPS. But LLD is pretty fast, too; the core was written by the same person, after all. And then I open a core dump from a binary linked with LLD, and gdb is really slow. Hmm. It should have been faster, actually, because I√¢ve also added &lt;code&gt;--gdb-index&lt;/code&gt;, which tells the linker to create, I guess, some index for gdb, making gdb faster than its
slow default behavior, which is reserved for the unfortunate people who don√¢t know the cool flags. But I√¢m not seeing faster,
I√¢m seeing slower. What gives?&lt;/p&gt;
    &lt;p&gt;So, I run gdb under gdb, and Ctrl-C it while it√¢s struggling with the core dump. There√¢s some callstack with &lt;code&gt;dwarf_decode_macro_bytes&lt;/code&gt;. Google quickly brings up some relevant issues, such as √¢Using -ggdb3 and linking with ld.lld leads to cpu/memory hog in
gdb√¢ (Status: UNCONFIRMED) and √¢lld doesn't generate
DW_MACRO_import like ld.bfd does√¢ (Status: RESOLVED WONTFIX.)&lt;/p&gt;
    &lt;p&gt;Apparently gcc generates some DWARF data that gdb is slow to handle. The GNU linker fixes this data, so that gdb doesn√¢t end up handling it slowly. LLD refuses to emulate this behavior of the GNU linker, because it√¢s gcc√¢s fault to have produced that DWARF data in the first place. And gdb refuses to handle LLD√¢s output efficiently, because it√¢s LLD√¢s fault to not have handled gcc√¢s output the way the GNU linker does. So I just remove &lt;code&gt;-ggdb3&lt;/code&gt; - it gives you a bit richer debug info, but it√¢s
not worth the slower linking with gold instead of LLD, nor the slowdown in gdb that you get with LLD. And everyone links happily
ever after.&lt;/p&gt;
    &lt;p&gt;Which goes to show that Ctrl-C profiling is often enough to solve a simple problem, and it√¢s usually much easier than learning how to use a profiler and how to properly read its output. You can connect a debugger to almost anything, all the way down to some chip with nothing like a standard OS that could work with a standard profiler. You can connect a debugger to almost anything especially if it√¢s slow - for example, maybe it√¢s hard to actually invoke the program under gdb because its invocation is buried somewhere very deep, but if it√¢s slow, you can &lt;code&gt;gdb /proc/$pid/exe $pid&lt;/code&gt; after it was
started.&lt;/p&gt;
    &lt;p&gt;A debugger also needs less to work with than a profiler. Unlike perf, gdb will give you a callstack even if the program was compiled without frame pointer support. And you certainly don√¢t need a special build, like gprof√¢s &lt;code&gt;-pg&lt;/code&gt;, or to run on a slow
simulator, like callgrind / KCachegrind. And then the output of a profiler might be easy to
misinterpret - and I√¢ve only scratched the surface the last time I wrote about it.
Eyeballing a few callstacks is more straightforward.&lt;/p&gt;
    &lt;p&gt;Why then do we need profilers at all? Here is a very partial list of reasons, in no particular order.&lt;/p&gt;
    &lt;p&gt;Let√¢s say, completely hypothetically, that you√¢ve switched to the LLD linker, and your program is now 2-3% slower. If you Ctrl-C it, you√¢ll see the same callstacks as with the version linked with gold. But if you have a profiler running on a simulator, similarly to callgrind, then you can find the functions with the most slowdown - and they might not be the ones taking the most time overall, they just have the most slowdown relatively to the old version - and then you can look at the assembly listings and see how much time was spent running each instruction. And then you√¢ll see that the new version has branch-to-address-from-register instructions where the old version had branch-to-constant-offset instructions.&lt;/p&gt;
    &lt;p&gt;Then you will learn about MIPS √¢relocation relaxation√¢ (used also in RISC-V AFAIK.) The compiler √¢assumes the worst√¢ and generates code loading a function address into a register, and then jumping to the address stored in that register. Then, if you√¢re lucky, the linker realizes that it has actually placed the function close enough to the caller for that caller to branch to the function using a constant offset. (Fixed-sized RISC branch instructions cannot encode constant offsets larger than a certain value, so the function needs to be close enough to the caller for the distance to fit into the offset encoding.) And then the linker √¢relaxes√¢ the expensive branch-from-register instruction into a cheaper branch-to-constant-offset instruction. And it turns out that the LLD version you√¢re using doesn√¢t implement relocation relaxation.&lt;/p&gt;
    &lt;p&gt;Of course you, or should I say me, wouldn√¢t need that very, very fancy simulator-based profiler if you weren√¢t the idiot using LLD 9 when LLD 14 was already available, with relocation relaxation implemented back in LLD 10. (I wish I√¢d saved the discussion in the mailing list around this patch; now I can√¢t find it anywhere. There was nobody confident enough in their MIPS knowledge to review the patch, but you don√¢t merge patches without a review, do you? There was even a message saying √¢Happy anniversary to the relocation relaxation patch!√¢ a year after it was submitted without having been merged. Eventually someone said something like √¢we have to either merge or reject it, or we√¢re being rude√¢ and someone else said √¢well, the patch author knows MIPS better than any of us, so let√¢s just merge it.√¢)&lt;/p&gt;
    &lt;p&gt;But, despite having been an idiot here, I maintain that you don√¢t have to be an idiot to have this sort of problem, which a profiler will help solve, and Ctrl-C profiling will not.&lt;/p&gt;
    &lt;p&gt;The broader issue is that Ctrl-C is essentially a sampling profiler - one with an unusually low sampling frequency, but a sampling profiler nonetheless. Very small changes spread across a program are obviously invisible to a sampling profiler. Also, sampling profilers are bad at tail latency - if something is usually fast but occasionally slow, you won√¢t be there to Ctrl-C it when it√¢s slow. (Of course, if √¢slow√¢ means 100 ms instead of the usual 25 ms, you wouldn√¢t manage to Ctrl-C it in time even if you were there - that low sampling frequency comes with some downsides.)&lt;/p&gt;
    &lt;p&gt;Systems involving many threads, processes or machines√¢¬¶ our esteemed √¢random pausing√¢ technique, aka Ctrl-C profiling, is often not great to use with these. And at this point I feel that the idea of replacing all of the various profilers with Ctrl-C is too ridiculous to bother with more counterarguments.&lt;/p&gt;
    &lt;p&gt;But, there are many various kinds of profilers, making it a question which kind to use, and how much legwork finding the problem will take on top of using it. Simulation-based profilers don√¢t have the problem of losing data to a low sampling frequency - they analyze full instruction traces - but they√¢re too slow for anything like a production environment. So you might need some measurements that you can run in production, and then a way to rerun the program on the simulator using inputs that were observed to cause a slowdown in production based on these measurements. Tracing profilers like ftrace / KernelShark are great for looking at examples of tail latency, but they will not reliably take you to the places in the code where the time is spent. Sampling profilers can run in production and take you to the right place in the code, but they√¢re a poor match for code that runs slowly but only occasionally, and even worse for code that occasionally gets stuck waiting for something. And most of these tools have a bunch of non-trivial prerequisites, config knobs and likely ways to misread their output.&lt;/p&gt;
    &lt;p&gt;Conversely, Ctrl-C in a debugger is easy, makes you look very effective when it actually works, and costs almost nothing to try even when it doesn√¢t really help in the end. What√¢s not to like?&lt;/p&gt;
    &lt;p&gt;I often find myself recommending something primitive or ugly, which might actually do better than the √¢proper√¢ approach, or it might have less risky failure modes in the hands of typical users, or it might be easier to tailor to your needs than a more elaborate solution. √¢Profile with Ctrl-C√¢ fits right in - certainly very primitive, yet often compares surprisingly favorably with more sophisticated alternatives. And therefore, I must give Ctrl-C profiling my warmest endorsement!&lt;/p&gt;
    &lt;p&gt;Thanks to Dan Luu for reviewing a draft of this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yosefk.com/blog/profiling-with-ctrl-c.html"/><published>2026-01-03T11:13:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46475395</id><title>Recursive Language Models</title><updated>2026-01-03T23:10:30.604850+00:00</updated><content>&lt;doc fingerprint="cc9c352ac1f5128e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 31 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Recursive Language Models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.24601"/><published>2026-01-03T11:29:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46475437</id><title>X-Clacks-Overhead</title><updated>2026-01-03T23:10:30.179589+00:00</updated><content/><link href="https://hleb.dev/post/x-clacks-overhead/"/><published>2026-01-03T11:37:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46476636</id><title>ParadeDB (YC S23) Is Hiring Database Engineers</title><updated>2026-01-03T23:10:29.993410+00:00</updated><content>&lt;doc fingerprint="10f452a104a33a8"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript must be enabled in order to use Notion. Please enable JavaScript to continue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://paradedb.notion.site/?p=172ea4ce9deb80898ef5d5097bd65544&amp;pm=s"/><published>2026-01-03T13:53:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478061</id><title>Show HN: Offline tiles and routing and geocoding in one Docker Compose stack</title><updated>2026-01-03T23:10:29.643844+00:00</updated><content>&lt;doc fingerprint="3380fb157c3cf942"&gt;
  &lt;main&gt;
    &lt;p&gt;Corviont runs MapLibre UI, vector tiles, Valhalla routing, and SQLite geocoding entirely offline on edge or on-prem devices - with a local map updater shipping next.&lt;/p&gt;
    &lt;p&gt;The Monaco demo is the full Corviont stack in miniature: a MapLibre UI talking to local APIs for tiles, routing, and geocoding - all running in Docker on your machine or edge device.&lt;/p&gt;
    &lt;p&gt;Monaco packaged as a single PMTiles file, served locally with no external tile servers.&lt;/p&gt;
    &lt;p&gt;Valhalla container exposing an HTTP API for offline routing between arbitrary points.&lt;/p&gt;
    &lt;p&gt;SQLite database built from Nominatim data, powering forward and reverse geocoding via a lightweight API.&lt;/p&gt;
    &lt;p&gt;MapLibre frontend wired to these local endpoints.&lt;/p&gt;
    &lt;p&gt;Corviont is built for devices that can‚Äôt rely on a fast, cheap, always-on connection.&lt;lb/&gt;üè≠ Edge &amp;amp; industrial devices&lt;/p&gt;
    &lt;p&gt;Run on industrial PCs, gateways, or embedded boxes so maps and routing keep working even when the WAN link is slow or down.&lt;/p&gt;
    &lt;p&gt;üö¢ Remote and offshore deployments&lt;/p&gt;
    &lt;p&gt;Install on vessels and remote sites with intermittent or satellite-only connectivity so tiles, routing, and search stay instant and local.&lt;/p&gt;
    &lt;p&gt;üöö Field fleets &amp;amp; mobile units&lt;/p&gt;
    &lt;p&gt;Use in vehicles and temporary field setups where devices go offline or change networks, without breaking your app‚Äôs map &amp;amp; routing UX.&lt;/p&gt;
    &lt;p&gt;Ô∏èüõ°Ô∏è Privacy and compliance-sensitive environments&lt;/p&gt;
    &lt;p&gt;Keep location queries and routes inside your own network; all map, routing, and geocoding requests terminate on your devices.&lt;/p&gt;
    &lt;p&gt;The Monaco demo is the first step. It‚Äôs the same architecture we‚Äôll use for larger regions and real fleets - here‚Äôs what‚Äôs on the way:&lt;/p&gt;
    &lt;p&gt;üß© Local map updater&lt;/p&gt;
    &lt;p&gt;A small background service that pulls new map bundles, verifies them, and switches the active dataset without downtime.&lt;/p&gt;
    &lt;p&gt;üóÇ Custom overlays&lt;/p&gt;
    &lt;p&gt;Load your own POIs, geofences, or operational layers (GeoJSON) on top of the base map, rendered directly in the UI.&lt;/p&gt;
    &lt;p&gt;üìç Richer geocoding output&lt;/p&gt;
    &lt;p&gt;Better address results with house numbers, and optional geometry for streets and areas (not just centrepoints) in forward and reverse search.&lt;/p&gt;
    &lt;p&gt;üß± More edge platforms &amp;amp; targets&lt;/p&gt;
    &lt;p&gt;First-class integrations for Portainer and Mender, plus deployment examples for K3s/Kubernetes and edge runtimes on AWS and Azure.&lt;/p&gt;
    &lt;p&gt;If any of these are critical for you, or if something important to your use case isn‚Äôt listed here, tell us in the form below. Your input directly influences what we build first.&lt;/p&gt;
    &lt;p&gt;Email + region is all that‚Äôs required. Notes are optional - we prioritize builds based on demand.&lt;/p&gt;
    &lt;p&gt;The form has been successfully submitted.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.corviont.com/"/><published>2026-01-03T15:55:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478377</id><title>The Most Popular Blogs of Hacker News in 2025</title><updated>2026-01-03T23:10:29.517557+00:00</updated><content>&lt;doc fingerprint="2d4411917efc2687"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Most Popular Blogs of Hacker News in 2025&lt;/head&gt;
    &lt;p&gt;With 2025 wrapped up, I can finally answer a question I‚Äôm curious about every year: who were the most popular bloggers of Hacker News?&lt;/p&gt;
    &lt;p&gt;Who counts as a blogger?&lt;/p&gt;
    &lt;p&gt;I explain more in my methodology page, but it‚Äôs basically anyone who blogs as an individual rather than as part of a company or a team. For example, John Graham-Cumming blogged while he was the CTO of Cloudflare, so I count his personal blog but not his posts to the Cloudflare company blog.&lt;/p&gt;
    &lt;head rend="h2"&gt;#1 Simon Willisonüîó&lt;/head&gt;
    &lt;p&gt;For the third straight year, Simon Willison was the most popular blogger on Hacker News.&lt;/p&gt;
    &lt;p&gt;At first, Simon‚Äôs position at #1 feels obvious: he wrote about AI in a year when everyone‚Äôs obsessed with AI. But there are tons of AI bloggers, and Simon is the only one who‚Äôs popular on HN, so what sets Simon apart?&lt;/p&gt;
    &lt;p&gt;First, Simon isn‚Äôt selling you anything. Simon writes about LLMs as a power user not as a sales pitch from some startup‚Äôs VP of product. He tries every AI tool he can get his hands on with no allegiance to any particular vendor. That allows him to write about how new AI tools fit into the ecosystem at large. It‚Äôs like getting restaurant recommendations from someone who eats out 20 times a week as opposed to someone who owns 20 restaurant chains.&lt;/p&gt;
    &lt;p&gt;Simon is also one of the most prolific bloggers on Hacker News. In 2025 alone, he wrote over 1,000 blog posts, though only 118 were full-length articles (‚Äúonly‚Äù).&lt;/p&gt;
    &lt;p&gt;Simon often finds ideas within walled-garden platforms (e.g., TikTok, Twitter) and simply brings them to the open web, where it‚Äôs easier for HN to discuss. Some of his most popular posts were just short quotes or links with a bit of commentary. ‚ÄúI‚Äôm worried that they put co-pilot in Excel‚Äù is just a quote from a video he watched on TikTok. ‚ÄúA computer can never be held accountable‚Äù is Simon summarizing a few tweets.&lt;/p&gt;
    &lt;p&gt;Simon has said these types of posts are easy to write yet high in value.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Sharing interesting links with commentary is a low effort, high value way to contribute to internet life at large.&lt;/p&gt;
      &lt;p&gt;‚ÄîSimon Willison, ‚ÄúMy approach to running a link blog‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;#2 Jeff Geerlingüîó&lt;/head&gt;
    &lt;p&gt;This is Jeff‚Äôs most successful year on Hacker News, beating his #5 finish in 2023.&lt;/p&gt;
    &lt;p&gt;The #2 spot was an extremely tight race this year. Jeff‚Äôs posts totaled 10,813 upvotes, edging out the #3 blogger by just 9 points (a 0.08% difference). The #4 finisher was just 100 points behind that. Past stories can still accrue upvotes, so this could still flip, but these were the rankings as of midnight on Dec. 31st.&lt;/p&gt;
    &lt;p&gt;Jeff is a popular YouTube creator with over 1M subscribers. He covers some of HN‚Äôs favorite topics, like Raspberry Pi computers, self-hosted software, and computer hardware. YouTube videos rarely succeed on Hacker News, so when Jeff publishes a new video, he often publishes an accompanying blog post. Jeff isn‚Äôt the only YouTuber who does this, but he‚Äôs one of the few who does it well.&lt;/p&gt;
    &lt;p&gt;I‚Äôve seen other YouTube creators try to repurpose their videos by auto-generating a transcript and calling that a blog post. Jeff approaches his blog more thoughtfully.&lt;/p&gt;
    &lt;p&gt;Jeff started out as a blogger, and he still treats his blog readers as first-class citizens. He structures his articles to fit the text medium rather than just lazily scraping dialog from his videos. You can read his post about upgrading storage on his Mac mini and not even realize it‚Äôs adapted from a video.&lt;/p&gt;
    &lt;head rend="h2"&gt;#3 Sean Goedeckeüîó&lt;/head&gt;
    &lt;p&gt;Sean came out of nowhere as a blogging powerhouse this year. He‚Äôd been blogging sporadically since 2020, but he hit a turning point at the end of 2024 with ‚ÄúHow I ship projects at big tech companies.‚Äù It was one of HN‚Äôs top 100 posts of the year and remains Sean‚Äôs most popular post on HN.&lt;/p&gt;
    &lt;p&gt;After his first success on HN, Sean went from publishing every few months to multiple times per week, becoming a regular fixture on the front page.&lt;/p&gt;
    &lt;p&gt;Sean is a Staff Software Engineer at GitHub and previously worked at Zendesk. Like Simon, Sean is extremely prolific. He wrote 140 posts this year. Of those, 47 reached the front page. I‚Äôve had a few years where a lot of my posts reached the front page, but for me that was about 10 articles. I can‚Äôt imagine what it‚Äôs like to have a new article on HN almost every week.&lt;/p&gt;
    &lt;p&gt;Sean explains his strategy in ‚ÄúWriting a tech blog people want to read‚Äù:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;the recipe for a popular post is to have a clear opinion about working in tech that many people disagree with.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I think Sean‚Äôs insight is true, but he‚Äôs selling his own writing a bit short. To me, Sean‚Äôs greatest strength is his ability to explain big tech organizational politics to engineers.&lt;/p&gt;
    &lt;p&gt;Most junior to mid-level developers don‚Äôt care about company politics. They think of office politics as something that strong technical thinkers shouldn‚Äôt have to waste brain cells on. As a result, they can‚Äôt understand why they can‚Äôt get promoted or how their company‚Äôs codebase got so bad. Sean‚Äôs posts explain these phenomena in a way that‚Äôs clear and intelligible to engineers.&lt;/p&gt;
    &lt;p&gt;Sean‚Äôs posts are also a good example of how much luck comes into play on Hacker News, especially for less established authors. Sean‚Äôs top three posts of the year all flopped on their first submission and didn‚Äôt succeed until their second or third try, sometimes months later. Even then, only a third of his posts reached the front page at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;#4 Brian Krebsüîó&lt;/head&gt;
    &lt;p&gt;Brian Krebs is an independent investigative journalist who covers cybercrime. He‚Äôs one of HN‚Äôs most popular bloggers of all time, second only to Paul Graham, the creator of HN. For 11 of the last 12 years, Brian has been one of HN‚Äôs top 10 bloggers.&lt;/p&gt;
    &lt;p&gt;In 2025, Brian mostly stuck to his usual beat of deeply investigated cybersecurity stories, but his second most popular story of the year was a sobering post about the Trump administration‚Äôs steps to undermine free speech in the US. It immediately shot to the #1 slot and stayed there for several hours. Unfortunately, too many users flagged the post, and it was moderated off the front page, which is often the fate of political stories on HN.&lt;/p&gt;
    &lt;head rend="h2"&gt;#5 Neal Agarwalüîó&lt;/head&gt;
    &lt;p&gt;Neal‚Äôs work isn‚Äôt what you might think of as blog posts; they‚Äôre more like interactive art. Some of his posts are games that parody the web, while others are straight-faced visual essays about topics he finds interesting.&lt;/p&gt;
    &lt;p&gt;This was Neal‚Äôs most successful year on HN. Everything he published reached the front page, with about half hitting #1, and the rest peaking at #2. Stimulation Clicker was the 4th most popular post of the entire year.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other notesüîó&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;John Gruber finished the year in #6 despite wondering aloud back in March whether Hacker News had shadowbanned his blog. It was his best year on Hacker News since 2011 and his first appearance in the top 10 since 2020.&lt;/item&gt;
      &lt;item&gt;Mahad Kalam finished at #21 for the year with a single blog post, which became the top post of the year. Byran Huang appeared right behind him, also with a single blog post, which became the #3 most upvoted post of the year.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://refactoringenglish.com/blog/2025-hn-top-5/"/><published>2026-01-03T16:20:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478647</id><title>The C3 Programming Language</title><updated>2026-01-03T23:10:29.276993+00:00</updated><content>&lt;doc fingerprint="3cf56a2aab1fe20c"&gt;
  &lt;main&gt;
    &lt;code&gt;
                   module hello_world;&lt;lb/&gt; import std::io;&lt;lb/&gt; &lt;lb/&gt; fn void main() &lt;lb/&gt;{&lt;lb/&gt;  io::printn("Hello, world!");  &lt;lb/&gt;
                  }&lt;lb/&gt; 
                &lt;/code&gt;
    &lt;code&gt;
                   module hello_world;&lt;lb/&gt; import std::io;&lt;lb/&gt; &lt;lb/&gt; fn void main() &lt;lb/&gt;{&lt;lb/&gt;  io::printn("Hello, world!");  &lt;lb/&gt;
                  }&lt;lb/&gt; 
                &lt;/code&gt;
    &lt;p&gt;C3 fits right into your C/C++ application with full C ABI compatibility out of the box: no need for special "C compatible" types or functions, no limitations on what C3 features you can use from C.&lt;/p&gt;
    &lt;p&gt;A simple and straightforward module system that doesn't get in the way, with defaults that makes sense.&lt;/p&gt;
    &lt;p&gt;C3 empowers you with precise, purpose-built operator overloading ‚Äî no C++ baggage, just clean, expressive code. Ideal for vectors, matrices, and fixed-point math that reads exactly how it should.&lt;/p&gt;
    &lt;p&gt; C3 is a programming language that builds on the syntax and semantics of the C language, with the goal of evolving it while still retaining familiarity for C programmers.&lt;lb/&gt; Thanks to full ABI compatibility with C, it's possible to mix C and C3 in the same project with no effort. As a demonstration, vkQuake was compiled with a small portion of the code converted to C3 and compiled with the c3c compiler. &lt;/p&gt;
    &lt;p&gt;Unlock the full power of compile-time code with macros that read like functions ‚Äî clearer, stronger, and miles beyond C‚Äôs preprocessor.&lt;/p&gt;
    &lt;p&gt;C3 brings programming-by-contract to the mainstream with unobtrusive contracts that are used to express both runtime and compile-time constraints.&lt;/p&gt;
    &lt;p&gt;Error handling that combines the best parts of "Result" errors with the easy use of exceptions and integrates seamlessly with C.&lt;/p&gt;
    &lt;p&gt;C3 generic modules offer superior simplicity and clarity for creating generic types.&lt;/p&gt;
    &lt;p&gt;Type introspection is available both at compile time and runtime, powering flexible macros and functions&lt;/p&gt;
    &lt;p&gt;Write asm as regular inline code without using strings or cryptic constraints.&lt;/p&gt;
    &lt;p&gt;Feel confident in your code's correctness: in debug mode the compiler inserts extensive runtime bounds checks and value checks, which together with contracts will let you catch bugs early.&lt;/p&gt;
    &lt;p&gt;No more anonymous "segmentation fault" errors: the C3 standard library enables detailed stacktraces out of the box for your debug builds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://c3-lang.org"/><published>2026-01-03T16:41:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46479673</id><title>Xr0 verifier, guarantee the safety of C programs at compile time</title><updated>2026-01-03T23:10:29.039294+00:00</updated><content>&lt;doc fingerprint="afe0923f7a3d2208"&gt;
  &lt;main&gt;
    &lt;p&gt;Xr0 is a verifier for C. It eliminates many stubborn instances of undefined behaviour, like use-after-frees, double frees, null pointer dereferences and the use of uninitialised memory.&lt;/p&gt;
    &lt;p&gt;Xr0 uses C-like annotations to verify code:&lt;/p&gt;
    &lt;code&gt;void *
alloc() ~ [ return malloc(1); ] /* caller must free */
{
        return malloc(1);
}
&lt;/code&gt;
    &lt;p&gt;They‚Äôre attached to every function that is potentially unsafe and express what its callers need to know to use it safely:&lt;/p&gt;
    &lt;code&gt;void *
alloc_if(int x) ~ [ if (x) return malloc(1); ] /* caller must free if x != 0 */
{
        if (x) {
                return malloc(1);
        } else {
                return NULL;
        }
}
&lt;/code&gt;
    &lt;p&gt;The really subtle safety bugs creep in through layers of function calls. Xr0 makes this impossible, because everything needed to secure safety is distributed through every function call, so that no subtle mistake can creep in. It ‚Äúquantum entangles‚Äù the safety semantics of every part of the program with every other part. Think of it like a infinitely rich type system that rises to the demands of your program‚Äôs structure. You still have to make the code safe; Xr0 just checks your work. Thus Xr0 is magical like the wand, not the magician. The real magic comes from the programmer.&lt;/p&gt;
    &lt;p&gt;Xr0 is a work in progress and currently verifies a subset of C89. Its most significant limitation is we haven‚Äôt yet implemented verification for loops and recursive functions, so these are being bridged by axiomatic annotations. Xr0 1.0.0 will enable programming in C with no undefined behaviour, but for now it‚Äôs useful for verifying sections of programs.&lt;/p&gt;
    &lt;p&gt;Xr0 is written in pure C and is open source. View it on GitHub or SourceHut.&lt;/p&gt;
    &lt;p&gt;The best way to understand Xr0 is to try it. If you want to see how Xr0 works, be sure to use the debugger, which you can learn about here.&lt;/p&gt;
    &lt;p&gt;Read the tutorial to learn more, and then if you want to go deeper, engage with our theses, which explain how Xr0 will make C safe, and take a look at our vision and roadmap.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xr0.dev"/><published>2026-01-03T18:10:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46480156</id><title>Report: Microsoft kills official way to activate Windows 11/10 without internet</title><updated>2026-01-03T23:10:28.937279+00:00</updated><content/><link href="https://www.neowin.net/news/report-microsoft-quietly-kills-official-way-to-activate-windows-1110-without-internet/#google_vignette"/><published>2026-01-03T18:53:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46480373</id><title>As deep-sea mining race ramps up, mission will assess whether ecosystems recover</title><updated>2026-01-03T23:10:28.444480+00:00</updated><content/><link href="https://www.science.org/content/article/deep-sea-mining-race-ramps-mission-will-assess-whether-ecosystems-recover-afterward"/><published>2026-01-03T19:14:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46480491</id><title>Doesnt: An Esoteric Programming Language</title><updated>2026-01-03T23:10:27.494839+00:00</updated><content/><link href="https://lists.sr.ht/~rabbits/horadric/%3C5d708fd1-1c01-4fb6-a8e5-61213a1e88f8@sheeeeeeeep.art%3E"/><published>2026-01-03T19:25:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46480614</id><title>Xsight Labs E1 DPU a 64-Core Arm Neoverse N2 800G DPU</title><updated>2026-01-03T23:10:27.036467+00:00</updated><content>&lt;doc fingerprint="97ab507249348885"&gt;
  &lt;main&gt;
    &lt;p&gt;Today we have a fun one. A few months ago, I was at Xsight Labs in California and saw the company‚Äôs E1 DPU PCIe card. A few weeks after that, a 1U chassis arrived. We wanted to start our series with a quick look at the really neat DPU, as this is far different from the DPUs we covered a few years ago. If you have not heard of Xsight Labs, we first covered them in 2020, and their X2 switch chip just had a major milestone win, Powering SpaceX Starlink V3 networking.&lt;/p&gt;
    &lt;p&gt;If you want to see a few more angles, we have a short.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Xsight Labs E1 DPU Overview&lt;/head&gt;
    &lt;p&gt;What Xsight Labs is building is not a NIC, or a NIC with a few compute cores attached. Instead, it is more of a miniature server.&lt;/p&gt;
    &lt;p&gt;The Xsight Labs E1 1U platform is much larger than the PCIe card, but that is really the point. The platform we are using is designed to not just be a network offload in a server. Instead, it is designed to be more flexible so that you can build more around the architecture.&lt;/p&gt;
    &lt;p&gt;Starting with the E1 DPU, this is a 64-core Arm Neoverse N2 part built in TSMC 5nm, and you can stick four DDR5-5200 ECC RDIMMs alongside it in the 1RU server.&lt;/p&gt;
    &lt;p&gt;Just to give you some sense, here is the block diagram for the part:&lt;/p&gt;
    &lt;p&gt;Other than the DDR5 memory that we showed, there is a lot more going on. Our unit is still more of a development platform, which you can see from the USB headers. Still there is something neat.&lt;/p&gt;
    &lt;p&gt;Onboard, there are two 400G MACs for a total of 800Gbps of networking. This platform is different because Xsight Labs has validated it with the SONiC-DASH Hero 800G test. That may not sound exciting, but SONiC is the open-source NOS right now running in many organizations. The Hero 800G test is one to validate that the NIC can keep 800Gbps of traffic moving with 120 million connections and 12 million connections per second with zero dropped packets. I think they actually used Keysight CyPerf to test this (I need to double check) which is what you are seeing on STH on everything from the NVIDIA ConnectX-8 C8240 800G Dual 400G NIC Review to lower-end 10G gateway devices.&lt;/p&gt;
    &lt;p&gt;Just as a fun one, here are the heatsinks for the two QSFP112 400Gbps ports:&lt;/p&gt;
    &lt;p&gt;The company says that it passed the SONiC-DASH 800G Hero test with 19% headroom, and further room for optimization. That is important for a few reasons. First, the E1 does not have a NIC IP attached to it along with its compute cores. It is actually using the Arm Neoverse N2 cores to do the networking thanks to features like DPDK. That is very different from many other DPUs on the market that we discussed a few months ago in the Substack.&lt;/p&gt;
    &lt;p&gt;Second, the extra headroom means that CPU cycles are free to do other tasks. That is where the next set of features comes in.&lt;/p&gt;
    &lt;p&gt;If you look around the chassis, you will see a number of PCIe slots that expose PCIe from the DPU that you can see in the block diagram.&lt;/p&gt;
    &lt;p&gt;Those include dual slot PCIe Gen5 x16 slots at the front.&lt;/p&gt;
    &lt;p&gt;Unlike the NVIDIA BlueField-3 DPU where there are explicit versions for both the NIC version and the one that acts as a PCIe root as a ‚ÄúSelf-Hosted‚Äù DPU, the Xsight Labs E1 can do both. Indeed, it can have x16 or x4/x4/x4/x4 bifurcation of its slots.&lt;/p&gt;
    &lt;p&gt;With the ability to push traffic through two 400Gbps ports (800Gbps), and 32 PCIe Gen5 lanes (roughly 800Gbps) the idea is that those free CPU cycles can do other work. For example, we showed off the Xsight Labs E1 800G 64-Core Arm DPU Shown for Hammerspace AI Storage.&lt;/p&gt;
    &lt;p&gt;If you look at the chassis above, it houses five sleds in a 1OU (that is O for Open, not 0) server. As a result, we get 320 Arm Neoverse N2 cores, and 40 SSDs. Since each sled has eight SSDs, which are roughly 800Gbps of storage, and then 800Gbps of networking, it is almost like putting forty PCIe Gen5 SSDs directly on the network, running the storage stack on the DPU between the SSDs and the network ports. While that is an example with SSDs, one could easily see PCIe GPUs or other accelerators also being attached to the E1 in those card slots.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;Another neat point about this DPU, aside from the architecture, is that it is early. NVIDIA BlueField-4 will utilize 64 Arm cores and 800G networking as well, but we had the E1 DPU in our studio before the formal GA launch of the BlueField-4, which is expected in 2026.&lt;/p&gt;
    &lt;p&gt;As you may have surmised, this is really kicking off a series using the DPU. In the next piece, we are going to do something simple, yet profound. If you saw this week‚Äôs Lenovo ThinkCentre neo 50q Tiny QC Review, that consumer Arm system could not install Ubuntu Linux from an ISO, which is very different from the experience we had with the ASRock Rack AMPONED8-2T/BCM with Ampere AmpereOne A192-32X Arm CPU. The next piece in this series is just getting the OS running on this from an ISO, and it is an important server milestone, yet one that other DPUs do not do. For example, our Intel E2100 DPU does not support this and is therefore very difficult to get running outside of narrow use cases. This E1 is an exciting platform, so we have a lot to cover.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.servethehome.com/this-is-the-xsight-labs-e1-dpu-a-64-core-arm-neoverse-n2-800g-dpu/"/><published>2026-01-03T19:34:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46480677</id><title>Show HN: Vibe Coding a static site on a $25 Walmart Phone</title><updated>2026-01-03T23:10:26.726547+00:00</updated><link href="https://stetsonblake.com/%2425+Walmart+Phone+for+Hackers"/><published>2026-01-03T19:39:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46481849</id><title>Scaling Latent Reasoning via Looped Language Models</title><updated>2026-01-03T23:10:26.604699+00:00</updated><content>&lt;doc fingerprint="ac1c362b54d5caca"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 29 Oct 2025 (v1), last revised 17 Nov 2025 (this version, v4)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Scaling Latent Reasoning via Looped Language Models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Modern LLMs are trained to "think" primarily via explicit text generation, such as chain-of-thought (CoT), which defers reasoning to post-training and under-leverages pre-training data. We present and open-source Ouro, named after the recursive Ouroboros, a family of pre-trained Looped Language Models (LoopLM) that instead build reasoning into the pre-training phase through (i) iterative computation in latent space, (ii) an entropy-regularized objective for learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and 2.6B models enjoy superior performance that match the results of up to 12B SOTA LLMs across a wide range of benchmarks. Through controlled experiments, we show this advantage stems not from increased knowledge capacity, but from superior knowledge manipulation capabilities. We also show that LoopLM yields reasoning traces more aligned with final outputs than explicit CoT. We hope our results show the potential of LoopLM as a novel scaling direction in the reasoning era. Our model is available here: this http URL.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Rui-Jie Zhu [view email]&lt;p&gt;[v1] Wed, 29 Oct 2025 17:45:42 UTC (14,928 KB)&lt;/p&gt;&lt;p&gt;[v2] Mon, 3 Nov 2025 06:54:49 UTC (9,619 KB)&lt;/p&gt;&lt;p&gt;[v3] Fri, 14 Nov 2025 02:14:36 UTC (9,607 KB)&lt;/p&gt;&lt;p&gt;[v4] Mon, 17 Nov 2025 20:03:56 UTC (9,607 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.25741"/><published>2026-01-03T21:34:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46482107</id><title>Take One Small Step</title><updated>2026-01-03T23:10:26.264817+00:00</updated><content>&lt;doc fingerprint="50ac33e1f5a79f5a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Take One Small Step&lt;/head&gt;
    &lt;head rend="h2"&gt;Think smaller√¢then act.&lt;/head&gt;
    &lt;p&gt;Imagine a goal you have: walk 30 minutes a day, or lose 25 pounds, or write and publish a book. Doesn√¢t matter what; for now, just imagine one.&lt;/p&gt;
    &lt;p&gt;Got it?&lt;/p&gt;
    &lt;p&gt;Now: Think of the first step you√¢ll take to reach that goal. If you want to lose 25 pounds, for example, you might think √¢start going to the gym 3 times/week√¢, or √¢eat 1,500 calories/day√¢. Or if you√¢re writing a book, you might think √¢write every day for half an hour√¢.&lt;/p&gt;
    &lt;p&gt;Got that first step? Good. Now forget it, and choose a smaller step.&lt;/p&gt;
    &lt;p&gt;No, even smaller. Smaller.&lt;/p&gt;
    &lt;p&gt;Keep going until you√¢ve come to what feels like the smallest, most inconsequential step you could take. That√¢s your first step.&lt;/p&gt;
    &lt;p&gt;Here√¢s an example: Say you want to walk for 30 minutes a day. You may have thought of a first step like √¢start walking tomorrow in the morning before work√¢, or √¢walk for 15 minutes a day√¢.&lt;/p&gt;
    &lt;p&gt;But those steps are too big, and while you might get out for a walk or two√¢maybe even for a week√¢you√¢ll almost certainly fail. I bet you√¢ve experienced this with New Year√¢s resolutions: √¢This year I will walk every day and lose 25 pounds and get fit and√¢¬¶√¢ and a few weeks later, you√¢re eating chips in front of the TV, wearing your walking shoes.&lt;/p&gt;
    &lt;p&gt;Here√¢s the problem: stress, and how you√¢re built to deal with it.&lt;/p&gt;
    &lt;p&gt;When we are stressed/anxious/afraid, the part of the brain called the amygdala activates our √¢fight or flight√¢ response. When that happens, we stop thinking rationally and start looking for the quickest way to relieve the stress/anxiety/fear. In ancient times, this would mean to run, jump, attack, etc. In modern times, that means distracting ourselves with food/drugs/procrastination/something else.&lt;/p&gt;
    &lt;p&gt;So, when you set a big goal and start charging towards it with big steps, it causes stress. And that stress causes you to find ways to escape it.&lt;/p&gt;
    &lt;p&gt;Large steps activate the amygdala. But there√¢s a genuine hack: small steps √¢sneak√¢ past the amygdala without activating the fight or flight response. And If you√¢re like me, I√¢m certain that you overestimate what a √¢small√¢ step really is. Think of it this way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Take large steps towards change: You feel fear, which activates the fight-or-flight response, which causes you to seek short-term relief/comfort, leading to√¢¬¶failure.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Take very small steps: You bypass fear, thereby reducing the urge for immediate comfort, so you can take action and build constructive habits, leading to√¢¬¶success.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How do you do that? Try these strategies instead:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Ask smaller questions, like √¢what√¢s the next step?√¢ or √¢what√¢s one small step I can take to get started√¢.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Think small thoughts: Totally imagine yourself performing the skill/activity√¢visualize completely, with all the senses.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Take small actions: Maybe not √¢read the book√¢, but √¢read one page√¢. Not √¢run a mile√¢, but √¢put out my running shoes every night√¢. One small step.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Solve small problems: Train yourself to see and address small problems before they become big ones.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Focus on smaller rewards.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here√¢s a practical example: imagine again that you want to walk 30 minutes a day. Instead of √¢small√¢ steps like √¢start walking tomorrow in the morning before work√¢, or √¢walk for 15 minutes a day√¢, you might do this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;√¢What√¢s the next step?√¢ You could put your walking shoes and socks by the door.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Think small thoughts: Find a comfortable place, then sit down, close your eyes, and and imagine yourself walking out your door. Visualize the walk√¢how it feels, what you see, what you smell. Keep it positive and easy; not a straining, hard walk, but easy. Slow, and pleasant.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Take small actions: Get up right now and put your walking shoes by the door. You√¢ll see them now. You√¢re one step closer to walking.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Solve small problems: Maybe you don√¢t have walking shoes. That√¢s a small problem you can solve. Go online and order some, or go to the store after work and buy some.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Focus on smaller rewards: You probably want to feel better, or want other √¢big√¢ rewards. Instead, focus on much smaller rewards. You put walking shoes by the door? Celebrate that. You√¢ve already done more than most people who want to walk like you. You walked on a rainy week? That√¢s great! Maybe reward yourself with a better raincoat, or your favorite meal.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then, repeat as often as you need to√¢daily, perhaps. After a week of putting your shoes by the door, ask √¢what√¢s the next step?√¢ It might be √¢put my walking shoes on today√¢. Notice you still haven√¢t walked yet, but you√¢re taking steps towards your goal. Your mind and how you feel will begin to change.&lt;/p&gt;
    &lt;p&gt;Don√¢t dismiss small steps as a waste of time. They√¢re the main way you√¢re going to reach your goals. Just commit to taking one small step right now. Then take another. And another.&lt;/p&gt;
    &lt;p&gt;Soon you√¢ll be amazed at how far you√¢ve come, and how those small steps got you there.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thinkhuman.com/take-one-small-step/"/><published>2026-01-03T21:58:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46482268</id><title>Ask HN: What are you working on? (Jan 2026)</title><updated>2026-01-03T23:10:25.769222+00:00</updated><content>&lt;doc fingerprint="bd5a6eb2a5f792be"&gt;
  &lt;main&gt;
    &lt;p&gt;I've been learning the basics of using Z3 by creating a solver for the daily puzzle game Clues By Sam (very fun game; https://cluesbysam.com/). Repo is https://github.com/DylanSp/clues-by-sam-solver. It uses Playwright to read clues and submit guesses; I've got it working for all 50 puzzles in puzzle pack 1.&lt;/p&gt;
    &lt;p&gt;We‚Äôve optimized the internet for producing information, not for humans consuming it. Most of us are overwhelmed not because content is bad, but because it‚Äôs all delivered in the same rigid format.&lt;/p&gt;
    &lt;p&gt;I‚Äôm working on unrav.io : a way to reshape any web content (article, video, or PDF) into the form that actually fits how you think (summaries, mindmaps, infographics, podcasts, chat, etc.).&lt;/p&gt;
    &lt;p&gt;We just launched a Chrome extension, so it‚Äôs one click on any page. No login, free to try.&lt;/p&gt;
    &lt;p&gt;I built an LED globe with a world viewing portal that uses a raspberry pi and pre-generated AI videos of places around the world. I'm working on upgrading it to do realtime generation of the videos and to improve the hardware so it is more durable and capable of being hauled around for community use.&lt;/p&gt;
    &lt;p&gt;I just launched the beta of my app that uses Elixir/Phoenix. Its a community driven aggregation of technology resources for Michigan, like companies in Michigan that hire tech talent, university programs, incubators in Michigan, etc. It also includes a newsletter thats already fully live and has over 10 subscribers. I'm gathering starting data and feedback now!&lt;/p&gt;
    &lt;p&gt;What sets DeepFabric apart from other dataset generation tools is its ability to ensure high diversity yet domain-anchored relevance through unique topic graph generation algorithms. This guides sample creation to cover all necessary subtopics while avoiding redundancy, which is where other tools often fall short, resulting in model overfit.&lt;/p&gt;
    &lt;p&gt;Constrained decoding and response validation, along with real tool executions within isolated webassembly environments, ensure that generated samples strictly adhere to structured schema, variable constraints, and execution correctness, ensuring datasets have exact syntax and structure for use in model training pipelines. Tool definitions can be directly imported from MCP server schemas and then mocked, or rans as real life tool functions. Using real tools means the model has to adapt and correct when it makes the wrong choice or hallucinationates which makes for much better training data.&lt;/p&gt;
    &lt;p&gt;Once your dataset is generated, it can be automatically uploaded to Hugging Face and directly imported into popular training frameworks like TRL, Unsloth, and Axolotl.&lt;/p&gt;
    &lt;p&gt;Post-training, DeepFabric's built-in evaluation engine assesses model performance, whereby models prove their capabilities on unseen tasks derived from training splits‚Äîcovering evaluation-only questions, answers, and tool traces.&lt;/p&gt;
    &lt;p&gt;An experimental DSL for writing web applications. It's pipeline oriented, polyglot and loosely inspired by Bash pipelines. Rust runtime, fully-featured TypeScript language server (jump to def, hover, etc), full DAP debugging and a BDD-style testing framework built into the language.&lt;/p&gt;
    &lt;p&gt;GET /hello/:world |&amp;gt; jq: `{ world: .params.world }` |&amp;gt; handlebars: `&amp;lt;p&amp;gt;hello, {{world}}&amp;lt;/p&amp;gt;` describe "hello, world" it "calls the route" let world = "world" when calling GET /hello/{{world}} then status is 200 and selector `p` text equals "hello, {{world}}"&lt;/p&gt;
    &lt;p&gt;An vscode extension to organize my lectures using a kanban style structure, saved as markdown files and allows specific md-formats to convert into presentations or other documents (currently marp (pdf, pptx, html) and i'm currently looking into pandoc). It's a vibe coded project i worked on in the evenings over the last 3 months.&lt;/p&gt;
    &lt;p&gt;I used these two polarisers in my microscope and a magneto-optical sensor (which exploits the faraday effect), to visualise magnetic field lines of a magstripe card - https://www.youtube.com/watch?v=c8nM4Z-hkTw&lt;/p&gt;
    &lt;p&gt;I intend to try to use with a floppy disk, however it's not currently working for that.&lt;/p&gt;
    &lt;p&gt;I saw the "TADA" post a week or so back (like "TODO" but you finished it‚Äî"Tada!") and I regretted not having done write ups for projects I did in 2025. So I'm doing that belatedly. (https://engineersneedart.com)&lt;/p&gt;
    &lt;p&gt;Also playing with building analog computers so I can understand them (and will not wait until 2027 to post about what I learned/did).&lt;/p&gt;
    &lt;p&gt;Still on my AI extension for LibreOffice Writer. Growing ok, 1,700+ downloads since launch 3 weeks ago. Still no clue how to benefit from it, but I'm glad I've finally built something that's actually got traction https://extensions.libreoffice.org/en/extensions/show/99471&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46482268"/><published>2026-01-03T22:14:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46482345</id><title>Total monthly number of StackOverflow questions over time</title><updated>2026-01-03T23:10:25.661369+00:00</updated><content/><link href="https://data.stackexchange.com/stackoverflow/query/1926661#graph"/><published>2026-01-03T22:23:34+00:00</published></entry></feed>