<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-15T14:42:33.228009+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45588959</id><title>Show HN: Firm, a text-based work management system</title><updated>2025-10-15T14:42:39.801718+00:00</updated><content>&lt;doc fingerprint="3a9ba6182815e7b8"&gt;
  &lt;main&gt;
    &lt;p&gt;A text-based work management system for technologists.&lt;/p&gt;
    &lt;p&gt;Modern businesses are natively digital, but lack a unified view. Your data is scattered across SaaS tools you don't control, so you piece together answers by jumping between platforms.&lt;/p&gt;
    &lt;p&gt;Your business is a graph: customers link to projects, projects link to tasks, people link to organizations. Firm lets you define these relationships in plain text files (you own!).&lt;/p&gt;
    &lt;p&gt;Version controlled, locally stored and structured as code with the Firm DSL. This structured representation of your work, business-as-code, makes your business readable to yourself and to the robots that help you run it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Everything in one place: Organizations, contacts, projects, and how they relate.&lt;/item&gt;
      &lt;item&gt;Own your data: Plain text files and tooling that runs on your machine.&lt;/item&gt;
      &lt;item&gt;Open data model: Tailor to your business with custom schemas.&lt;/item&gt;
      &lt;item&gt;Automate anything: Search, report, integrate, whatever. It's just code.&lt;/item&gt;
      &lt;item&gt;AI-ready: LLMs can read, write, and query your business structure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Firm CLI is available to download via Github Releases. Install scripts are provided for desktop platforms to make that process easy.&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/42futures/firm/main/install.sh | sudo bash&lt;/code&gt;
    &lt;code&gt;irm https://raw.githubusercontent.com/42futures/firm/main/install.ps1 | iex&lt;/code&gt;
    &lt;p&gt;Firm operates on a "workspace": a directory containing all your &lt;code&gt;.firm&lt;/code&gt; DSL files. The Firm CLI processes every file in this workspace to build a unified, queryable graph of your business.&lt;/p&gt;
    &lt;p&gt;The first step is to add an entity to your workspace. You can do this either by using the CLI or by writing the DSL yourself.&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;firm add&lt;/code&gt; to interactively generate new entities. Out of the box, Firm supports a set of pre-built entity schemas for org mapping, customer relations and work management. The CLI will prompt you for the necessary info and generate corresponding DSL.&lt;/p&gt;
    &lt;code&gt;$ firm add&lt;/code&gt;
    &lt;code&gt;Adding new entity

&amp;gt; Type: organization
&amp;gt; ID: megacorp
&amp;gt; Name: Megacorp Ltd.
&amp;gt; Email: mega@corp.com
&amp;gt; Urls: ["corp.com"]

Writing generated DSL to file my_workspace/generated/organization.firm
&lt;/code&gt;
    &lt;p&gt;Alternatively, you can create a &lt;code&gt;.firm&lt;/code&gt; file and write the DSL yourself.&lt;/p&gt;
    &lt;code&gt;organization megacorp {
  name = "Megacorp Ltd."
  email = "mega@corp.com"
  urls = ["corp.com"]
}
&lt;/code&gt;
    &lt;p&gt;Both of these methods achieve the same result: a new entity defined in your Firm workspace.&lt;/p&gt;
    &lt;p&gt;Once you have entities in your workspace, you can query them using the CLI.&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;firm list&lt;/code&gt; to see all entities of a specific type.&lt;/p&gt;
    &lt;code&gt;$ firm list task&lt;/code&gt;
    &lt;code&gt;Found 7 entities with type 'task'

ID: task.design_homepage
Name: Design new homepage
Is completed: false
Assignee ref: person.jane_doe

...
&lt;/code&gt;
    &lt;p&gt;To view the full details of a single entity, use &lt;code&gt;firm get&lt;/code&gt; followed by the entity's type and ID.&lt;/p&gt;
    &lt;code&gt;$ firm get person john_doe&lt;/code&gt;
    &lt;code&gt;Found 'person' entity with ID 'john_doe'

ID: person.john_doe
Name: John Doe
Email: john@doe.com
&lt;/code&gt;
    &lt;p&gt;The power of Firm lies in its ability to travel a graph of your business. Use &lt;code&gt;firm related&lt;/code&gt; to explore connections to/from any entity.&lt;/p&gt;
    &lt;code&gt;$ firm related contact john_doe&lt;/code&gt;
    &lt;code&gt;Found 1 relationships for 'contact' entity with ID 'john_doe'

ID: interaction.megacorp_intro
Type: Call
Subject: Initial discussion about Project X
Interaction date: 2025-09-30 09:45:00 +02:00
Initiator ref: person.jane_smith
Primary contact ref: contact.john_doe
&lt;/code&gt;
    &lt;p&gt;You've seen the basic commands for interacting with a Firm workspace. The project is a work-in-progress, and you can expect to see more sophisticated features added over time, including a more powerful query engine and tools for running business workflows directly from the CLI.&lt;/p&gt;
    &lt;p&gt;Beyond the CLI, you can integrate Firm's core logic directly into your own software using the &lt;code&gt;firm_core&lt;/code&gt; and &lt;code&gt;firm_lang&lt;/code&gt; Rust packages. This allows you to build more powerful automations and integrations on top of Firm.&lt;/p&gt;
    &lt;p&gt;First, add the Firm crates to your &lt;code&gt;Cargo.toml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;[dependencies]
firm_core = { git = "https://github.com/42futures/firm.git" }
firm_lang = { git = "https://github.com/42futures/firm.git" }&lt;/code&gt;
    &lt;p&gt;You can then load a workspace, build the entity graph, and query it programmatically:&lt;/p&gt;
    &lt;code&gt;use firm_lang::workspace::Workspace;
use firm_core::EntityGraph;

// Load workspace from a directory
let mut workspace = Workspace::new();
workspace.load_directory("./my_workspace")?;
let build = workspace.build()?;

// Build the graph from the workspace entities
let mut graph = EntityGraph::new();
graph.add_entities(build.entities)?;
graph.build();

// Query the graph for a specific entity
let lead = graph.get_entity(&amp;amp;EntityId::new("lead.ai_validation_project"))?;

// Traverse a relationship to another entity
let contact_ref = lead.get_field(FieldId::new("contact_ref"))?;
let contact = contact_ref.resolve_entity_reference(&amp;amp;graph)?;&lt;/code&gt;
    &lt;p&gt;This gives you full access to the underlying data structures, providing a foundation for building custom business automations.&lt;/p&gt;
    &lt;p&gt;Firm is organized as a Rust workspace with three crates:&lt;/p&gt;
    &lt;p&gt;Core data structures and graph operations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Entity data model&lt;/item&gt;
      &lt;item&gt;Typed fields with references&lt;/item&gt;
      &lt;item&gt;Relationship graph with query capabilities&lt;/item&gt;
      &lt;item&gt;Entity schemas and validation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;DSL parsing and generation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tree-sitter-based parser for &lt;code&gt;.firm&lt;/code&gt;files&lt;/item&gt;
      &lt;item&gt;Conversion between DSL and entities&lt;/item&gt;
      &lt;item&gt;Workspace support for multi-file projects&lt;/item&gt;
      &lt;item&gt;DSL generation from entities&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Grammar is defined in tree-sitter-firm.&lt;/p&gt;
    &lt;p&gt;Command-line interface, making the Firm workspace interactive.&lt;/p&gt;
    &lt;p&gt;Firm's data model is built on a few key concepts. Each concept is accessible declaratively through the &lt;code&gt;.firm&lt;/code&gt; DSL for human-readable definitions, and programmatically through the Rust packages for building your own automations.&lt;/p&gt;
    &lt;p&gt;Entities are the fundamental business objects in your workspace, like people, organizations, or projects. Each entity has a unique ID, a type, and a collection of fields.&lt;/p&gt;
    &lt;p&gt;In the DSL, you define an entity with its type and ID, followed by its fields in a block:&lt;/p&gt;
    &lt;code&gt;person john_doe {
    name = "John Doe"
    email = "john@doe.com"
}
&lt;/code&gt;
    &lt;p&gt;In Rust, this corresponds to an &lt;code&gt;Entity&lt;/code&gt; struct:&lt;/p&gt;
    &lt;code&gt;let person = Entity::new(EntityId::new("john_doe"), EntityType::new("person"))
    .with_field(FieldId::new("name"), "John Doe")
    .with_field(FieldId::new("email"), "john@doe.com");&lt;/code&gt;
    &lt;p&gt;Fields are typed key-value pairs attached to an entity. Firm supports a rich set of types:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;String&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Integer&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Float&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Boolean&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Currency&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;DateTime&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;List&lt;/code&gt;of other values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Reference&lt;/code&gt;to other fields or entities&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Path&lt;/code&gt;to a local file&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the DSL, the syntax maps directly to these types:&lt;/p&gt;
    &lt;code&gt;my_task design_homepage {
    title = "Design new homepage"        // String
    priority = 1                         // Integer
    completed = false                    // Boolean
    budget = 5000.00 USD                 // Currency
    due_date = 2024-12-01 at 17:00 UTC   // DateTime
    tags = ["ui", "ux"]                  // List
    assignee = person.jane_doe           // Reference
    deliverable = path"./homepage.zip"   // Path
}
&lt;/code&gt;
    &lt;p&gt;In Rust, these are represented by the &lt;code&gt;FieldValue&lt;/code&gt; enum:&lt;/p&gt;
    &lt;code&gt;let value = FieldValue::Integer(42);&lt;/code&gt;
    &lt;p&gt;The power of Firm comes from connecting entities. You create relationships using &lt;code&gt;Reference&lt;/code&gt; fields.&lt;/p&gt;
    &lt;p&gt;When Firm processes your workspace, it builds the entity graph representing of all your entities (as nodes) and their relationships (as directed edges). This graph is what allows for traversal and querying.&lt;/p&gt;
    &lt;p&gt;In the DSL, creating a relationship is as simple as referencing another entity's ID.&lt;/p&gt;
    &lt;code&gt;contact john_at_acme {
    person_ref = person.john_doe
    organization_ref = organization.acme_corp
}
&lt;/code&gt;
    &lt;p&gt;In Rust, you build the graph by loading entities and calling the &lt;code&gt;.build()&lt;/code&gt; method, which resolves all references into queryable links.&lt;/p&gt;
    &lt;code&gt;let mut graph = EntityGraph::new();
graph.add_entities(workspace.build()?.entities)?;
graph.build(); // Builds relationships from references

// Now you can traverse the graph
let contact = graph.get_entity(&amp;amp;EntityId::new("contact.john_at_acme"))?;
let person_ref = contact.get_field(FieldId::new("person_ref"))?;
let person = person_ref.resolve_entity_reference(&amp;amp;graph)?;&lt;/code&gt;
    &lt;p&gt;Schemas allow you to define and enforce a structure for your entities, ensuring data consistency. You can specify which fields are required or optional and what their types should be.&lt;/p&gt;
    &lt;p&gt;In the DSL, you can define a schema that other entities can adhere to:&lt;/p&gt;
    &lt;code&gt;schema custom_project {
    field {
        name = "title"
        type = "string"
        required = true
    }
    field {
        name = "budget"
        type = "currency"
        required = false
    }
}

custom_project my_project {
    title  = "My custom project"
    budget = 42000 EUR
}
&lt;/code&gt;
    &lt;p&gt;In Rust, you can define schemas programmatically to validate entities.&lt;/p&gt;
    &lt;code&gt;let schema = EntitySchema::new(EntityType::new("project"))
    .with_required_field(FieldId::new("title"), FieldType::String)
    .with_optional_field(FieldId::new("budget"), FieldType::Currency);

schema.validate(&amp;amp;some_project_entity)?;&lt;/code&gt;
    &lt;p&gt;Firm includes schemas for a range of built-in entities like Person, Organization, and Industry.&lt;/p&gt;
    &lt;p&gt;Firm's entity taxonomy is built on the REA model (Resources, Events, Agents) with inspiration from Schema.org, designed for flexible composition and efficient queries.&lt;/p&gt;
    &lt;p&gt;Every entity maps to a Resource (thing with value), an Event (thing that happens), or an Agent (thing that acts).&lt;/p&gt;
    &lt;p&gt;We separate objective reality from business relationships:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fundamental entities represent things that exist independently (&lt;code&gt;Person&lt;/code&gt;,&lt;code&gt;Organization&lt;/code&gt;,&lt;code&gt;Document&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Contextual entities represent your business relationships and processes (&lt;code&gt;Contact&lt;/code&gt;,&lt;code&gt;Lead&lt;/code&gt;,&lt;code&gt;Project&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Entities reference each other rather than extending. One &lt;code&gt;Person&lt;/code&gt; can be referenced by multiple &lt;code&gt;Contact&lt;/code&gt;, &lt;code&gt;Employee&lt;/code&gt;, and &lt;code&gt;Partner&lt;/code&gt; entities simultaneously.&lt;/p&gt;
    &lt;p&gt;When the entity graph is built, all &lt;code&gt;Reference&lt;/code&gt; values automatically create directed edges between entities. This enables traversal queries like "find all Tasks for Opportunities whose Contacts work at Organization X" without complex joins.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/42futures/firm"/><published>2025-10-15T07:01:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45589327</id><title>Europe's Digital Sovereignty Paradox – "Chat Control" Update</title><updated>2025-10-15T14:42:39.045508+00:00</updated><content>&lt;doc fingerprint="2df72237b3c75cdb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Europe's Digital Sovereignty Paradox - "Chat Control" update&lt;/head&gt;
    &lt;p&gt;Can you build tech independence while breaking encryption?&lt;/p&gt;
    &lt;p&gt;October 14th was supposed to be the day the European Council voted to mandate scanning of all private communications, encrypted or not.&lt;/p&gt;
    &lt;p&gt;The vote was pulled at the last minute.&lt;/p&gt;
    &lt;p&gt;Germany withdrew support, creating a blocking minority that blocked the Danish Presidency's hope to get the text approved. Denmark still hopes to push this through by the end of its EU presidency in December. I personally would like to be optimistic and think that the tech community managed to raise enough concerns with EU policymakers.&lt;/p&gt;
    &lt;p&gt;Hundreds of European companies such as Proton, NordVPN, Tuta, Murena, Element, ProcessOne voiced their concerns about Chat Control. These companies are building the European alternatives we need for digital sovereignty. They offer what the EuroStack coalition is demanding: local infrastructure, values-driven technology, independence from US hyperscalers.&lt;/p&gt;
    &lt;p&gt;And EU policy trying to force them to break the very protocols that make sovereignty possible does not seem like the wisest strategic move.&lt;/p&gt;
    &lt;p&gt;What policymakers are missing is that encryption is a built-in foundation of most communication protocols. You cannot turn it on or off depending on what is considered right in a given place at a given moment. You either have secure end-to-end encryption or you don't. There is no "just this once" exception that doesn't become an exploitable technical or administrative vulnerability.&lt;/p&gt;
    &lt;p&gt;When Denmark's Justice Minister suggested that the "completely misguided perception" is that everyone has a right to secure communication, he revealed the fundamental gap: policymakers who don't understand that secure infrastructure is the core of today's Internet backbone, not just for the pure sake of democracy (I swear it hurts to have to explain this), but also for the existential security of European countries.&lt;/p&gt;
    &lt;p&gt;Today, European countries are prioritizing defense spending while missing that digital infrastructure is the battlefield. Networks allow us to control drones, spread misinformation, they are vectors of attacks on critical infrastructure.&lt;/p&gt;
    &lt;p&gt;It is time for Europe to develop a coherent tech strategy. Can we build digital sovereignty while simultaneously undermining the protocols that enable it? Can we demand independence from US tech giants while forcing European alternatives to adopt vulnerabilities that US companies will try to avoid through commercial pressure?&lt;/p&gt;
    &lt;p&gt;The October postponement is an opportunity. Two months for actual infrastructure builders and engineers to inform policy. Two months to bridge the gap between Brussels' political vision and the technical reality of how secure systems actually work.&lt;/p&gt;
    &lt;p&gt;This is exactly the gap I work to bridge: between policymakers who understand the geopolitical stakes and engineers who understand protocol layers. Europe's path to digital sovereignty requires both.&lt;/p&gt;
    &lt;p&gt;Denmark's December push will show us whether Europe is serious about learning from its own technical community, or whether we're condemned to keep making policy that contradicts our stated goals.&lt;/p&gt;
    &lt;p&gt;The European way should be: tech with purpose, built on sound engineering, serving democratic values. Not tech policy that undermines the very infrastructure we need to achieve independence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.process-one.net/blog/chat-control-update-oct-2025/"/><published>2025-10-15T07:52:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590302</id><title>ASP.NET Security Feature Bypass Vulnerability</title><updated>2025-10-15T14:42:38.875771+00:00</updated><content>&lt;doc fingerprint="eeb0cb52b8bf2f47"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;head&gt;CVE-2025-55315 Detail&lt;/head&gt;&lt;p&gt; Awaiting Analysis &lt;/p&gt;&lt;p&gt;This CVE record has been marked for NVD enrichment efforts.&lt;/p&gt;&lt;head&gt;Description&lt;/head&gt;&lt;p&gt;Inconsistent interpretation of http requests ('http request/response smuggling') in ASP.NET Core allows an authorized attacker to bypass a security feature over a network.&lt;/p&gt;&lt;head&gt;Metrics&lt;/head&gt;&lt;p&gt; NVD enrichment efforts reference publicly available information to associate vector strings. CVSS information contributed by other sources is also displayed. &lt;/p&gt;&lt;p&gt; CVSS 4.0 Severity and Vector Strings: &lt;/p&gt;&lt;head&gt;References to Advisories, Solutions, and Tools&lt;/head&gt;&lt;p&gt;By selecting these links, you will be leaving NIST webspace. We have provided these links to other web sites because they may have information that would be of interest to you. No inferences should be drawn on account of other sites being referenced, or not, from this page. There may be other web sites that are more appropriate for your purpose. NIST does not necessarily endorse the views expressed, or concur with the facts presented on these sites. Further, NIST does not endorse any commercial products that may be mentioned on these sites. Please address comments about this page to [email protected].&lt;/p&gt;&lt;head&gt;Weakness Enumeration&lt;/head&gt;&lt;head&gt;Quick Info&lt;/head&gt;CVE Dictionary Entry:&lt;p&gt;CVE-2025-55315&lt;/p&gt;&lt;p&gt;NVD Published Date:&lt;/p&gt;&lt;p&gt;10/14/2025&lt;/p&gt;&lt;p&gt;NVD Last Modified:&lt;/p&gt;&lt;p&gt;10/14/2025&lt;/p&gt;&lt;p&gt;Source:&lt;/p&gt;&lt;p&gt;Microsoft Corporation&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nvd.nist.gov/vuln/detail/CVE-2025-55315"/><published>2025-10-15T10:19:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590681</id><title>Something is broken with the way we measure success on the internet</title><updated>2025-10-15T14:42:38.342593+00:00</updated><content>&lt;doc fingerprint="acf3d92879304fe2"&gt;
  &lt;main&gt;
    &lt;p&gt;Make confident, data-driven decisions with actionable ad spend insights.&lt;/p&gt;
    &lt;p&gt;9 min read&lt;/p&gt;
    &lt;p&gt;A conversion rate of less than 0.1%. That was the moment I realized something was fundamentally broken with the way we measure success on the internet.&lt;/p&gt;
    &lt;p&gt;Simul Sarker&lt;/p&gt;
    &lt;p&gt;CEO of DataCops&lt;/p&gt;
    &lt;p&gt;Last Updated&lt;/p&gt;
    &lt;p&gt;October 15, 2025&lt;/p&gt;
    &lt;p&gt;It all started with a simple, devastating problem. My client’s e-commerce website registered 50,000 visitors last February but made only 47 sales. A conversion rate of less than 0.1%. That was the moment I realized something was fundamentally broken with the way we measure success on the internet.&lt;/p&gt;
    &lt;p&gt;As the head of a digital marketing agency, I am no stranger to confusing analytics. But this was different. An e-commerce client approached me last April, completely bewildered. They were pouring $4,000 a month into Facebook ads, their Google Analytics reports were glowing with green arrows pointing up, yet their business was barely breaking even. The numbers told a story of booming growth, but the bank account told a story of stagnation.&lt;/p&gt;
    &lt;p&gt;My first thought was blunt. "Maybe your products are the problem?" I suggested, half-jokingly. They did not appreciate the feedback.&lt;/p&gt;
    &lt;p&gt;But then I dove deep into their website traffic data, and a strange, unsettling feeling crept in. It was like walking into your own home and sensing that something is out of place, even if you cannot immediately identify what has moved. I should have probably left it alone.&lt;/p&gt;
    &lt;p&gt;Instead, I went down a rabbit hole that would change how I view the entire digital economy.&lt;/p&gt;
    &lt;p&gt;Driven by this discrepancy, I built a simple tracking script. It was not a sophisticated piece of software, just a tool designed to observe how "users" actually interacted with the website. I was not just counting clicks; I was watching behavior.&lt;/p&gt;
    &lt;p&gt;In short, I was looking for the small, imperfect, and unpredictable actions that separate a real human from a bot pretending to be one. With the client's permission, I installed the script. Within a single week, the results were both clarifying and horrifying.&lt;/p&gt;
    &lt;p&gt;A staggering 68% of their website traffic was non-human traffic. This was not the obvious spam that gets filtered out. This was sophisticated bot traffic designed to fool standard analytics platforms.&lt;/p&gt;
    &lt;p&gt;This discovery became an obsession. I started reaching out to other e-commerce owners in private marketing forums and Discord groups. I posed a simple question: "Do your traffic numbers seem weirdly disconnected from your sales?"&lt;/p&gt;
    &lt;p&gt;The response was a deluge. A flood of messages came in, all echoing the same anxious sentiment: "I thought it was just me."&lt;/p&gt;
    &lt;p&gt;Over the next six months, I received permission to install my tracking script on over 200 websites, mostly small to medium sized e-commerce businesses. The results were consistent and shocking. Across this diverse sample, the average level of fake traffic was 73%. This was a systemic issue, a phantom epidemic haunting the digital storefronts of countless entrepreneurs.&lt;/p&gt;
    &lt;p&gt;The bots operating today are disturbingly good. They are not just hitting your site and leaving; they are programmed to mimic engagement, making your marketing ROI calculations dangerously inaccurate. I began to categorize them.&lt;/p&gt;
    &lt;p&gt;These bots are designed to make analytics reports look good. They perform actions that signal a "quality visitor." They scroll down pages, hover their cursors over products, and click on different internal links. But their perfection is their fatal flaw. A human might spend 15 seconds on a product description, or they might spend two minutes. These bots spent between 11 and 13 seconds on every single one. Their scrolling speed was a perfectly constant 3.2 pages per second. Humans are messy; these bots were clinically precise.&lt;/p&gt;
    &lt;p&gt;One of the most bizarre patterns I witnessed was a bot that would add the same $47 item to the shopping cart, wait exactly four minutes, and then abandon it. It repeated this exact process 30 times a day from different IP addresses and user sessions. Why? The purpose is likely to manipulate e-commerce metrics, perhaps to influence a site's internal recommendation algorithms or to make cart abandonment rates look normal amidst a sea of other non-purchasing bots.&lt;/p&gt;
    &lt;p&gt;Your analytics might proudly report a visitor from Instagram or TikTok. However, my investigation revealed that approximately 64% of this referral traffic would land on a page, wait exactly 1.8 seconds without any scrolling or clicking, and then bounce. This still registers as a "visitor from social media," a vanity metric that deceives marketers trying to measure the effectiveness of their campaigns. It is a key component of ad fraud, allowing sellers of fake engagement to "prove" they sent traffic.&lt;/p&gt;
    &lt;p&gt;During my investigation, a source from the e-commerce data industry provided a crucial piece of the puzzle. He explained that his former company was responsible for scraping 70 million retailer web pages every single day. This is a legitimate and massive source of automated traffic.&lt;/p&gt;
    &lt;p&gt;Why do they do this? For vital business intelligence. Major retailers like Amazon do not always notify vendors when they run out of stock. So, brands pay for data scraping services to monitor their own products. These "good bots" check inventory levels, see who is winning the "buy box," ensure product descriptions are correct, and track search result rankings. They even scrape from different locations and mobile device profiles to analyze what banner ads are being shown to different audiences.&lt;/p&gt;
    &lt;p&gt;This confirms that a massive portion of the web is automated. A recent Kurzgesagt video even stated that nearly 50% of all internet traffic is now bots. While some of this is for legitimate competitive analysis and price monitoring, a huge portion is the fraudulent traffic that is draining advertising budgets worldwide.&lt;/p&gt;
    &lt;p&gt;The financial implications of this phantom traffic are staggering. I had one client spending $12,000 per month on Google Ads. After we implemented advanced bot traffic detection and filtering, their reported traffic plummeted by 71%. Their CFO was initially horrified.&lt;/p&gt;
    &lt;p&gt;But then the sales report came in. Their actual sales went up by 34%.&lt;/p&gt;
    &lt;p&gt;Their real conversion rate optimization (CRO) efforts had been working all along, but the results were buried under an avalanche of fake clicks. They were not bad at marketing; they were just spending thousands of dollars advertising to robots programmed never to buy anything. Their marketing ROI went from "terrible" to "excellent" overnight.&lt;/p&gt;
    &lt;p&gt;When I tried to bring this up with a few major ad platforms, the conversation always followed a predictable script. The sales reps were incredibly friendly until I mentioned click fraud or bot traffic. Then, the tone shifted instantly to corporate-speak: "Our AI detection is industry leading" and "We take ad fraud very seriously." It was a polite but firm wall, a clear signal to stop asking questions.&lt;/p&gt;
    &lt;p&gt;One rep I had known for years finally admitted the truth off the record. "Dude, we know," he said. "Everyone knows. But if we filtered it all out properly, our revenue would drop 40% overnight, and investors would have a meltdown."&lt;/p&gt;
    &lt;p&gt;The conflict of interest is immense. Ad platforms get paid per click or impression, regardless of whether that click comes from a potential customer or a server in a click farm.&lt;/p&gt;
    &lt;p&gt;You do not need a custom script to start looking for red flags. Open your Google Analytics or other platform right now and conduct a sanity check.&lt;/p&gt;
    &lt;p&gt;The deeper I dug, the more unsettling the landscape became. I spoke to a startup founder who raised $2 million in funding based on "user growth" metrics that he later discovered were 80% bots. He is now trapped, forced to pretend everything is fine because admitting the truth could jeopardize his company and his relationship with his investors.&lt;/p&gt;
    &lt;p&gt;This is the hidden bot economy. Ad platforms are selling impressions to bots. Businesses are buying fake traffic to inflate their metrics. Analytics companies are dutifully reporting on this bot activity. And the entire industry seems to be nodding along, complicit in a collective charade because admitting the truth would cause the fragile system to collapse.&lt;/p&gt;
    &lt;p&gt;I am now convinced that well over half of the internet is a facade, a digital stage play performed by bots for an audience of other bots. And that percentage is growing every day as AI and automation become more sophisticated.&lt;/p&gt;
    &lt;p&gt;The question is no longer whether your business is affected. The question is, what happens when this digital house of cards finally comes tumbling down?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://joindatacops.com/resources/how-73-of-your-e-commerce-visitors-could-be-fake"/><published>2025-10-15T11:11:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590756</id><title>Leaving serverless led to performance improvement and a simplified architecture</title><updated>2025-10-15T14:42:38.154448+00:00</updated><content/><link href="https://www.unkey.com/blog/serverless-exit"/><published>2025-10-15T11:20:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590900</id><title>Ireland is making basic income for artists program permanent</title><updated>2025-10-15T14:42:37.961696+00:00</updated><content>&lt;doc fingerprint="7fea01d9548b374e"&gt;
  &lt;main&gt;
    &lt;p&gt;Several years after launching a trial, Ireland is set to make its basic income for artists program permanent starting in 2026.&lt;/p&gt;
    &lt;p&gt;Under the program, selected artists receive a weekly payment of approximately $375, or about $1,500 per month. There are 2,000 spots available, with applications set to open in September 2026; eligibility criteria have not yet been announced. The government may expand the program to additional applicants in the future, should more funding become available, according to Irish broadcaster RTÉ.&lt;/p&gt;
    &lt;p&gt; The current program, which began in 2022 and is set to end in February after a six-month extension agreed to earlier this year, was launched to support the arts sector following the pandemic. Many artists suffered disproportionate income losses during that time due to the cancelation of live performances and events.&lt;lb/&gt;For the pilot, applicants could apply under visual arts, theater, literature, music, dance, opera, film, circuses, and architecture. They were required to submit two pieces of evidence proving that they were professional cultural workers, such as proof of income from art sales, membership in a professional body, or reviews. At the time, the New York Times reported that more than 9,000 people applied, with 8,200 deemed eligible and 2,000 randomly selected to receive payments. Another 1,000 eligible applicants were placed in a control group to be monitored but not receive funds. &lt;/p&gt;
    &lt;p&gt;The announcement follows the release of an external report by UK-based consultants Alma Economics, which found that the pilot cost €72 million to date but generated nearly €80 million in total benefits to the Irish economy. The report also found that recipients’ arts-related income increased by more than €500 per month on average, income from non-arts work decreased by around €280, and reliance on other social programs declined, with participants receiving €100 less per month on average.&lt;/p&gt;
    &lt;p&gt;“The economic return on this investment in Ireland’s artists and creative arts workers is having an immediate positive impact on the sector and the economy overall,” Patrick O’Donovan, minister for culture, communications, and sport, said in a statement.&lt;/p&gt;
    &lt;p&gt;The report further estimated that a permanent, “scaled-up” program would likely result in artists producing 22 percent more work, while lowering the average cost of art to consumers by 9 to 25 percent.&lt;/p&gt;
    &lt;p&gt; In October, the government released the results of a public survey on the scheme, which found that 97 percent of respondents support the program. However, 47 percent of the 17,000 respondents said artists should be selected based on economic need, while 37.5 percent favored selection by merit. Only 14 percent preferred random selection.&lt;lb/&gt;Ireland’s BIA program is a form of universal basic income, a policy that grants all citizens a recurring payment regardless of socioeconomic status or other factors. Such programs have grown increasingly mainstream—if not widely implemented—in recent years, as fears rise over the effects of artificial intelligence and other technology-driven job losses. Many UBI advocates have cited Ireland’s program as evidence that the model works. &lt;/p&gt;
    &lt;p&gt;“As the pilot shows, basic income works and people need a UBI now to face and deal with the many social, economic, and ecological crises of our world. The Network will continue to help demonstrate basic income within communities and show how it is a sustainable policy,” the UBI Lab Network said in a statement calling for a nationwide program.&lt;/p&gt;
    &lt;p&gt;“We need no further pilots. People need a UBI now to face and deal with the many social, economic, and ecological crises of our world,” Reinhard Huss, organizer of UBI Lab Leeds, told Business Insider in June.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.artnews.com/art-news/news/ireland-basic-income-artists-program-permanent-1234756981/"/><published>2025-10-15T11:40:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590921</id><title>Show HN: Trott – search,sort,extract social media videos(ig,yt,tiktok)</title><updated>2025-10-15T14:42:37.676048+00:00</updated><content>&lt;doc fingerprint="ce02b587139ef663"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The Problem&lt;/head&gt;
    &lt;p&gt;Saved reels, shorts, and videos lack search, organization, and context. You save hundreds across platformsâtravel destinations, recipes, product reviews, tutorialsâbut can never find them when you need them.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Search&lt;/head&gt;
    &lt;p&gt;Manual scrolling through hundreds of posts to find that recipe, product, or tutorial&lt;/p&gt;
    &lt;head rend="h3"&gt;Lost Context&lt;/head&gt;
    &lt;p&gt;Key details buried in videosâingredients, steps, locations, product specs&lt;/p&gt;
    &lt;head rend="h3"&gt;No Organization&lt;/head&gt;
    &lt;p&gt;Can't categorize or group content by topic, genre, or collection&lt;/p&gt;
    &lt;head rend="h2"&gt;See Trott in Action&lt;/head&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;p&gt;AI-powered organization with smart integrations for every content type&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;Three steps: Share, Process, Organize&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Share Content&lt;/head&gt;
    &lt;p&gt;Share reels, shorts, and videos from Instagram, YouTube, or other platforms directly to Trott&lt;/p&gt;
    &lt;head rend="h3"&gt;2. AI Processing&lt;/head&gt;
    &lt;p&gt;Automatic extraction of locations, recipes, steps, or product details based on content type using LLMs&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Search &amp;amp; Use&lt;/head&gt;
    &lt;p&gt;Fuzzy search, AI chat, and smart integrationsâmaps for travel, recipe cards for cooking, tutorials for learning&lt;/p&gt;
    &lt;head rend="h2"&gt;Hear from our friends who've tried Trott&lt;/head&gt;
    &lt;p&gt;Real feedback from our beta testers and early adopters&lt;/p&gt;
    &lt;p&gt;"Bro this app is insane!! I literally had like 1000+ travel reels saved and never looked at them again. Now I actually planned my Goa trip using them lol"&lt;/p&gt;
    &lt;p&gt;Mihir&lt;/p&gt;
    &lt;p&gt;Travel enthusiast&lt;/p&gt;
    &lt;p&gt;"Okay so you can literally chat with it?? I asked 'show me those aesthetic cafes in Bali' and boom - found every single reel I saved months ago. Mind = blown ð¤¯"&lt;/p&gt;
    &lt;p&gt;Divyanshu&lt;/p&gt;
    &lt;p&gt;Digital nomad&lt;/p&gt;
    &lt;p&gt;"I mean I helped build this so I'm biased but like... we really cooked with this one ð¥ My saved reels folder was a disaster and now even I'm impressed with myself"&lt;/p&gt;
    &lt;p&gt;Sudipta&lt;/p&gt;
    &lt;p&gt;Adventure seeker&lt;/p&gt;
    &lt;head rend="h2"&gt;Download Trott Today&lt;/head&gt;
    &lt;p&gt;Available on iOS and Android. Start organizing your saved reels, shorts, and videos in seconds.&lt;/p&gt;
    &lt;p&gt;ð Built in public for RevenueCat Shipathon 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://trott.hattimatimlabs.in"/><published>2025-10-15T11:43:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45590949</id><title>Show HN: Halloy – the modern IRC client I hope will outlive me</title><updated>2025-10-15T14:42:37.223724+00:00</updated><content>&lt;doc fingerprint="3f7a5c1966185a9a"&gt;
  &lt;main&gt;
    &lt;p&gt;Halloy is an open-source IRC client written in Rust, with the Iced GUI library. It aims to provide a simple and fast client for Mac, Windows, and Linux platforms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation for latest release: https://halloy.chat.&lt;/item&gt;
      &lt;item&gt;Documentation for main branch (when building from source): https://unstable.halloy.chat.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Join #halloy on libera.chat if you have questions or looking for help.&lt;/p&gt;
    &lt;p&gt;Halloy is also available from Flathub and Snap Store.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IRCv3.2 capabilities&lt;/item&gt;
      &lt;item&gt;SASL support&lt;/item&gt;
      &lt;item&gt;DCC Send&lt;/item&gt;
      &lt;item&gt;Keyboard shortcuts&lt;/item&gt;
      &lt;item&gt;Auto-completion for nicknames, commands, and channels&lt;/item&gt;
      &lt;item&gt;Notifications support&lt;/item&gt;
      &lt;item&gt;Multiple channels at the same time across servers&lt;/item&gt;
      &lt;item&gt;Command bar for for quick actions&lt;/item&gt;
      &lt;item&gt;Custom themes&lt;/item&gt;
      &lt;item&gt;Portable mode&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Halloy is released under the GPL-3.0 License. For more details, see the LICENSE file.&lt;/p&gt;
    &lt;p&gt;For any questions, suggestions, or issues, please open an issue on the GitHub repository.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/squidowl/halloy"/><published>2025-10-15T11:45:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591082</id><title>Helpcare AI (YC F24) Is Hiring</title><updated>2025-10-15T14:42:36.834387+00:00</updated><content>&lt;doc fingerprint="439da654fe15b36e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Ideal Candidate:&lt;/p&gt;
      &lt;p&gt;- Worked at an early-stage startup (pre-seed, seed, series A)&lt;/p&gt;
      &lt;p&gt;- 7yrs of full-stack experience. (python, react preferred, open to other)&lt;/p&gt;
      &lt;p&gt;- Some experience with LLM / Agentic Applications.&lt;/p&gt;
      &lt;p&gt;- Some experience with Data Ingestion.&lt;/p&gt;
      &lt;p&gt;- Bonus 2x / yr.&lt;/p&gt;
      &lt;p&gt;- $120,000+ / yr. with generous equity.&lt;/p&gt;
      &lt;p&gt;Tech Stack:&lt;/p&gt;
      &lt;p&gt;Python, React, Fast API, Supabase&lt;/p&gt;
      &lt;p&gt;Who we are:&lt;/p&gt;
      &lt;p&gt;- Mission to improve the world's capacity for care&lt;/p&gt;
      &lt;p&gt;- Respectful, intelligent, positive team&lt;/p&gt;
      &lt;p&gt;- A-players that are excited to build the best&lt;/p&gt;
      &lt;p&gt;- Well funded, YC- Company with incredible customer demand&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45591082"/><published>2025-10-15T12:00:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591149</id><title>Garbage Collection for Rust: The Finalizer Frontier</title><updated>2025-10-15T14:42:35.968105+00:00</updated><content>&lt;doc fingerprint="b6a84895ac650758"&gt;
  &lt;main&gt;&lt;p&gt;Also available as: DOI, PDF (arxiv).&lt;/p&gt;&lt;p&gt;See also: Experiment (DOI).&lt;/p&gt;&lt;p&gt;Abstract Rust is a non-Garbage Collected (GCed) language, but the lack of GC makes expressing data-structures that require shared ownership awkward, inefficient, or both. In this paper we explore a new design for, and implementation of, GC in Rust, called Alloy. Unlike previous approaches to GC in Rust, Alloy allows existing Rust destructors to be automatically used as GC finalizers: this makes Alloy integrate better with existing Rust code than previous solutions but introduces surprising soundness and performance problems. Alloy provides novel solutions for the core problems: finalizer safety analysis rejects unsound destructors from automatically being reused as finalizers; finalizer elision optimises away unnecessary finalizers; and premature finalizer prevention ensures that finalizers are only run when it is provably safe to do so.&lt;/p&gt;&lt;p&gt; Amongst the ways one can classify programming languages are whether they are Garbage Collected (GCed) or not: GCed languages enable implicit memory management; non-GCed languages require explicit memory management (e.g &lt;code&gt;C&lt;/code&gt;'s &lt;code&gt;malloc&lt;/code&gt; / &lt;code&gt;free&lt;/code&gt; functions). Rust's use of affine types [25, p. 5] and
ownership does not fit within this classification: it is not GCed but it has implicit scope-based
memory management. Most portions of Rust programs are as succinct as a GCed equivalent, but
ownership is too inflexible to express shared ownership for data-structures that require multiple
owners (e.g. doubly linked lists). Workarounds such as reference counting impose an extra
burden on the programmer, make mistakes more likely, and often come with a performance
penalty.
&lt;/p&gt;&lt;p&gt; In an attempt to avoid such problems, there are now a number of GCs for Rust (e.g. [2, 11, 14, 32, 33]). Most introduce a user-visible type &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; which takes a value v of type &lt;code&gt;T&lt;/code&gt; and moves v to the 'GC
heap'. The &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; value itself is a wrapper around a pointer to v on the GC heap. &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; can be
cloned (i.e. duplicated) and dereferenced to a value of type &lt;code&gt;&amp;amp;T&lt;/code&gt; (i.e. a type-safe pointer) at
will by the user. When no &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; wrappers pointing to v can be found, indirectly or directly,
from the program's roots (e.g. variables on the stack), then the GC heap memory for v can be
reclaimed.
&lt;/p&gt;&lt;p&gt; It has proven hard to find a satisfying design and implementation for a GC for Rust, as perhaps suggested by the number of attempts to do so. We identify two fundamental challenges for GC for Rust: how to give &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; an idiomatic and complete API; and how to make finalizers
(i.e. the code that is run just before a value is collected by the GC) safe, performant, and
ergonomic.
&lt;/p&gt;&lt;p&gt;In this paper we introduce Alloy, a new GC for Rust: an example of its use is shown in Listing 1. Alloy uses conservative garbage collection (i.e. treating each reachable machine word as a potential pointer), which naturally solves the API challenge. However, the finalization challenge is much more involved: the causes of this challenge, and our solutions to it, occupy the bulk of this paper.&lt;/p&gt;&lt;p&gt; Normal Rust code uses destructors (i.e. code which is run just before a value is reclaimed by Rust's implicit memory management) extensively. Although finalizers and destructors may seem to be synonyms, existing GCs for Rust cannot reuse destructors as finalizers: the latter must be manually implemented for each type that needs it. Unfortunately, even this is trickier than it appears: it is not possible to implement a finalizer for &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; if &lt;code&gt;T&lt;/code&gt; is an external library; some parts of destructors are
automatically created by the Rust compiler, but hand-written finalizers must duplicate those parts
manually; and users can accidentally cause a type's finalizer to be run more than once. In short,
finalization in existing GCs for Rust is unpalatable.
&lt;/p&gt;&lt;p&gt;GCs for Rust are not alone in requiring manually written finalizers. In a close cousin to our work, a GC proposal for C++, the reuse of destructors as finalizers was ruled out due to seemingly insoluble problems [8, p. 32], which we divide into four categories: (1) some safe destructors are not safe finalizers; (2) finalizers can be run prematurely; (3) running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks; (4) and finalizers are prohibitively slower than destructors. All are, at least to some degree, classical GC problems; all are exacerbated in some way by Rust; and none, with the partial exception of #2, has existing solutions.&lt;/p&gt;&lt;p&gt;We show that it is possible to reuse most Rust destructors as finalizers in a satisfying way. We introduce novel solutions to the long-standing problems this implies by making use of some of Rust's unusual static guarantees. We thus gain a better GC for Rust and solutions to open GC problems. Our solutions, in order, are: (1) finalizer safety analysis extends Rust's static analyses to reject programs whose destructors are not provably safe to be used as finalizers; (2) premature finalizer prevention automatically inserts fences to prevent the GC from being 'tricked' into collecting values before they are dead; (3) we run finalizers on a separate thread; and (4) and finalizer elision statically optimises away finalizers if the underlying destructor duplicates the GC's work.&lt;/p&gt;&lt;p&gt;Alloy as an implementation is necessarily tied to Rust, though most of the novel techniques in this paper rely on general properties of affine types and ownership. While we do not wish to claim generality without evidence, it seems likely that many of the techniques in this paper will generalise to other ownership-based languages, as and when such emerge.&lt;/p&gt;&lt;p&gt;Although Alloy is not production ready, its performance is already reasonable: when we control for the (admittedly somewhat slow) conservative GC (BDWGC) Alloy currently uses, the performance of Alloy varies from 0.74Ã to, in the worst case, 1.17Ã that of reference counting. Alloy is also sufficiently polished (e.g. good quality error messages) in other ways for it to: show a plausible path forwards for those who may wish to follow it; and to allow others to evaluate whether GC for Rust is a good idea or not.&lt;/p&gt;&lt;p&gt;This paper is divided into four main parts: GC and Rust background (Section 2); Alloy's basic design (Section 3); destructor and finalizer challenges and solutions (Sections 4 to 7); and evaluation (Section 8). The first three parts have the challenge that our work straddles two areas that can seem mutually exclusive: GC and Rust. We have tried to provide sufficient material for readers expert in one of these areas to gain adequate familiarity with the other, without boring either, but we encourage readers to skip material they are already comfortable with.&lt;/p&gt;&lt;p&gt;2.1 The Challenges of Shared Ownership in Rust&lt;/p&gt;&lt;p&gt; Rust uses affine types and ownership to statically guarantee that: a value has a single owner (e.g. a variable); an owner can move (i.e. permanently transfer the ownership of) a value to another owner; and when a value's owner goes out of scope, the value's destructor is run and its backing memory reclaimed. An owner can pass references to a value to other code, subject to the following static restrictions: there can be multiple immutable references ('&lt;code&gt;&amp;amp;&lt;/code&gt;') to a value or a single
mutable reference ('&lt;code&gt;&amp;amp;mut&lt;/code&gt;'); and references cannot outlast the owner. These rules allow many
Rust programs to be as succinct as their equivalents in GCed languages. This suggests that
the search for a good GC for Rust may be intellectually stimulating but of little practical
value.
&lt;/p&gt;&lt;p&gt;However, there are many programs which need to express data structures which do not fit into the restrictions of affine types and ownership. These are often described as 'cyclic data-structures', but in this paper we use the more abstract term 'shared ownership', which includes, but is not limited to, cyclic data-structures.&lt;/p&gt;&lt;p&gt; A common way of expressing shared ownership is to use the reference counting type &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; from
Rust's standard library. For many data-structures, this is a reasonable solution, but some forms of shared
ownership require juggling strong and weak counts. This complicates programs (see Listing 2) and can
cause problems when values live for shorter or longer than intended.
&lt;/p&gt;&lt;p&gt;A different solution is to store values in a vector and use integer indices into that vector. Such indices are morally closer to machine pointers than normal Rust references: the indices can become stale, dangle, or may never have been valid in the first place. The programmer must also manually deal with issues such as detecting unused values, compaction, and so on. In other words, the programmer ends up writing a partial GC themselves. A variant of this idea are arenas, which gradually accumulate multiple values but free all of them in one go: values can no longer be reclaimed too early, though arenas tend to unnecessarily increase the lifetime of values.&lt;/p&gt;&lt;p&gt; A type-based approach is &lt;code&gt;GhostCell&lt;/code&gt; [35], which uses branding to statically ensure that at any given
point only one part of a program can access a shared ownership data-structure. This necessarily excludes
common use cases where multiple owners (e.g. in different threads) need to simultaneously access
disjoint parts of a data-structure.
&lt;/p&gt;&lt;p&gt; Although it is easily overlooked, some workarounds (e.g. &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;) rely on using unsafe Rust
(i.e. parts of the language, often involving pointers, that are not fully statically checked by the
compiler). Pragmatically, we assume that widely used code, even if technically unsafe, has
been pored over sufficiently that it is trustworthy in practise. However, 'new' solutions that a
programmer implements using unsafe Rust are unlikely to immediately reach the same level of
trustworthiness.
&lt;/p&gt;&lt;p&gt;While we do not believe that every Rust program would be improved by GC, the variety of workarounds already present in Rust code, and the difficultly of creating new ones, suggests that there is a subset that would benefit from GC.&lt;/p&gt;GC is a venerable field and has accumulated terminology that can seem unfamiliar or unintuitive. We mostly use the same terminology as Jones et al [19], the major parts of which we define here.&lt;p&gt;A program which uses GC is split between the mutator (the user's program) and the collector (the GC itself). At any given point in time, a thread is either running as a mutator or a collector. In our context, all threads run as a collector at least sometimes (for reasons that will become apparent later, some threads always run as a collector). Tracing and reclamation is performed during a collection phase. Our collections always stop-the-world, where all threads running mutator code are paused while collection occurs.&lt;/p&gt;&lt;p&gt;A tracing GC is one that scans memory looking for reachable values from a program's roots: values, including cycles of values, that are not reachable from the roots can then be reclaimed. In contrast, a pure reference counting GC does not scan memory, and thus cannot free values that form a cycle. Increasingly, GC implementations make use of multiple techniques (see [3]) but, for simplicity's sake, we assume that implementations wholly use one technique or another except otherwise stated. For brevity, we use 'GC' as a short-hand for 'tracing GC'; when we deal with other kinds of GC (e.g. reference counting), we explicitly name them.&lt;/p&gt;&lt;p&gt; We refer to memory which is allocated via &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; as being on the GC heap. We use the term 'GC value'
to refer both to the pointer wrapped in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; and the underlying value on the GC heap, even though
multiple pointers / wrappers can refer to a single value on the GC heap, unless doing so would lead to
ambiguity.
&lt;/p&gt;&lt;p&gt; We use 'Alloy' to refer to the combination of: our extension to the Rust language; our modifications to the &lt;code&gt;rustc&lt;/code&gt; compiler; and our integration of the Boehm-Demers-Weiser GC (BDWGC) into the runtime of
programs compiled with our modified &lt;code&gt;rustc&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;In this section we outline Alloy's basic design and implementation choices â the rest of the paper then goes into detail on the more advanced aspects.&lt;/p&gt;&lt;p&gt;Alloy provides a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; type that exposes an API modelled on the &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; type from Rust's
standard library, because &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;: is conceptually similar to &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;; widely used in Rust code, and
its API familiar; and that API reflects long-term experience about what Rust programmers
need.
&lt;/p&gt;&lt;p&gt; When a user calls &lt;code&gt;Gc::new(v)&lt;/code&gt;, the value &lt;code&gt;v&lt;/code&gt; is moved to the GC heap: the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; value returned
to the user is a simple wrapper around a pointer to &lt;code&gt;v&lt;/code&gt;'s new address. The same underlying
GCed value may thus have multiple, partly or wholly overlapping, references active at any
point. To avoid undermining Rust's ownership system, dereferencing a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; produces an
immutable (i.e. '&lt;code&gt;&amp;amp;&lt;/code&gt;') reference to the underlying value. If the user wishes to mutate the underlying
value, they must use other Rust types that enable interior mutability (e.g. &lt;code&gt;RefCell&amp;lt;T&amp;gt;&lt;/code&gt; or
&lt;code&gt;Mutex&amp;lt;T&amp;gt;&lt;/code&gt;).
&lt;/p&gt;&lt;p&gt; One feature that Alloy explicitly supports is the ability in Rust to cast references to raw pointers and back again. This can occur in two main ways. &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; can be dereferenced to &lt;code&gt;&amp;amp;T&lt;/code&gt; which can
then, as with any other reference, be converted to *const T (i.e. a C-esque pointer to T).
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; also supports the common Rust functions (&lt;code&gt;into_raw&lt;/code&gt; and &lt;code&gt;from_raw&lt;/code&gt;) which wrap the
value-to-pointer conversion in a slightly higher-level API. The ability to convert references to raw
pointers is used in many places (e.g. Rust's standard C Foreign Function Interface (FFI)).
We believe that a viable GC for Rust must allow the same conversions, but doing so has a
profound impact because Rust allows raw pointers to be converted to the integer type &lt;code&gt;usize&lt;/code&gt; and
back1.
&lt;/p&gt;&lt;p&gt;Having acknowledged that pointers can be 'disguised' as integers, it is then inevitable that Alloy must be a conservative GC: if a machine word's integer value, when considered as a pointer, falls within a GCed block of memory, then that block itself is considered reachable (and is transitively scanned). Since a conservative GC cannot know if a word is really a pointer, or is a random sequence of bits that happens to be the same as a valid pointer, this over-approximates the live set (i.e. the blocks that the GC will not reclaim). Typically the false detection rate is very low (see e.g. a Java study which measures it at under 0.01% of the live set [28]).&lt;/p&gt;&lt;p&gt;Conservative GC occupies a grey zone in programming language semantics: in most languages, and most compiler's internal semantics, conservative GC is, formally speaking, unsound; and furthermore some languages (including Rust) allow arbitrary 'bit fiddling' on pointers, temporarily obscuring the address they are referring to. Despite this, conservative GC is widely used, including in the two most widespread web browsers: Chrome uses it in its Blink rendering engine [1] and Safari uses it in its JavaScript VM JavaScriptCore [26]. Even in 2025, we lack good alternatives to conservative GC: there is no cross-platform API for precise GC; and while some compilers such as LLVM provide some support for GC features [23], we have found them incomplete and buggy. Despite the potential soundness worries, conservative GC thus remains a widely used technique.&lt;/p&gt;&lt;p&gt; Conservative GC enables Alloy to make a useful ergonomic improvement over most other GCs for Rust whose &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is only cloneable. Such types can be duplicated, but doing so requires
executing arbitrary user code. To make the possible run-time cost of this clear, Rust has no
direct syntax for cloning: users must explicitly call &lt;code&gt;Rc::clone(&amp;amp;v)&lt;/code&gt; to duplicate a value &lt;code&gt;v&lt;/code&gt;. In
contrast, since Alloy's &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is just a wrapper around a pointer it is not just cloneable but
also copyable: duplication only requires copying bytes (i.e. no arbitrary user code need be
executed). Copying is implied by assignment (i.e. &lt;code&gt;w = v&lt;/code&gt;), reducing the need for explicit
cloning2.
This is not just a syntactic convenience but also reflects an underlying semantic difference: duplicating a
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; in Alloy is is a cheaper and simpler operation than most other GCs for Rust which which tend to
rely, at least in part, on reference counting.
&lt;/p&gt;&lt;p&gt; There is one notable limitation of &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s API relative to &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;. The latter, by definition, knows how
many references there are to the underlying data, allowing the value stored inside it to be mutably
borrowed at run-time if there is only a single reference to it (via &lt;code&gt;get_mut&lt;/code&gt; and &lt;code&gt;make_mut&lt;/code&gt;). In contrast,
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; cannot know how many references there are to the underlying data. As we shall see in Section 8,
some Rust programs are built around the performance advantages of this API (e.g. turning 'copy on
write' into just 'write' in some important cases).
&lt;/p&gt;&lt;p&gt;The most visible aspect of Alloy is its fork, and extension of, the standard Rust compiler &lt;code&gt;rustc&lt;/code&gt;. We
forked &lt;code&gt;rustc&lt;/code&gt; 1.79.0, adding or changing approximately 5,500 Lines of Code (LoC) in the core compiler,
and adding approximately 2,250 LoC of tests.
&lt;/p&gt;&lt;p&gt; Alloy uses BDWGC [9] as the underlying conservative GC, because it is the most widely ported conservative GC we know of. We use BDWGC's &lt;code&gt;GC_set_finalize_on_demand(1)&lt;/code&gt; API, which causes
finalizers to be run on their own thread.
&lt;/p&gt;&lt;p&gt; We had to make some minor changes to BDWGC to suit our situation. First, we disabled BDWGC's parallel collector because it worsens Alloy's performance. It is unclear to us why this happens: we observe significant lock contention within BDWGC during GC collections, but have not correlated this with a cause. Second, BDWGC cannot scan pointers stored in thread locals because these are platform dependent. Fortunately, &lt;code&gt;rustc&lt;/code&gt; uses LLVM's thread local storage
implementation, which stores such pointers in the &lt;code&gt;PT_TLS&lt;/code&gt; segment of the ELF binary: we modified
BDWGC to scan this ELF segment during each collection. Third, BDWGC dynamically intercepts
thread creation calls so that it can can scan their stacks, but (for bootstrapping reasons) is
unable to do so in our context: we explicitly changed Alloy to register new threads with
BDWGC.
&lt;/p&gt;&lt;p&gt;In many GCed languages, 'destructor' and 'finalizer' are used as synonyms, as both terms refer to code run when a value's lifetime has ended. In existing GCs for Rust, these two terms refer to completely different hierarchies of code (i.e. destructors and finalizers are fundamentally different). In Alloy, in contrast, a reasonable first approximation is that finalizers are a strict subset of destructors. In this section we pick apart these differences, before describing the challenges of using destructors as finalizers.&lt;/p&gt;&lt;p&gt;When a value in Rust is dropped (i.e. at the point its owner goes out of lexical scope) its destructor is automatically run. Rust's destructors enable a style of programming that originated in C++ called RAII (Resource Acquisition Is Initialization) [30, Section 14.4]: when a value is dropped, the underlying resources it possesses (e.g. file handles or heap memory) are released. Destructors are used frequently in Rust code (to give a rough idea: approximately 15% of source-level types in our benchmark suite have destructors).&lt;/p&gt;&lt;p&gt; Rust destructors are formed of two parts, run in the following order: a user-defined drop method; and automatically inserted drop glue. Drop methods are optional and users can provide one for a type by implementing the &lt;code&gt;Drop&lt;/code&gt; trait's &lt;code&gt;drop&lt;/code&gt; method. Drop glue recursively calls destructors of contained types
(e.g. fields in a struct). Although it is common usage to conflate 'destructor' in Rust with drop methods,
drop glue is an integral part of a Rust destructor: we therefore use 'destructor' as the umbrella term for
both drop methods and drop glue.
&lt;/p&gt;&lt;p&gt; When considering finalizers for a GC for Rust, there are several layers of design choices. We will shortly see that finalizers cause a number of challenges (Section 4.1) and one choice would be to forbid finalizers entirely. However, this would mean that one could not sensibly embed types that have destructors in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. While Rust does not always call destructors, the situations where this occurs are
best considered 'exceptional': not calling destructors from &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; would completely undermine
reasonable programmer expectations. Because of this, Alloy, and indeed virtually all GCs for Rust,
support finalizers in some form.
&lt;/p&gt;&lt;p&gt; However, existing GCs force distinct notions of destructors and finalizers onto the programmer. Where the former have the &lt;code&gt;Drop&lt;/code&gt; trait, the latter typically have a &lt;code&gt;Finalize&lt;/code&gt; trait. If a user type needs to be
finalized then the user must provide an implementation of the &lt;code&gt;Finalize&lt;/code&gt; trait. However, doing so
introduces a number of problems: (1) external libraries are unlikely to provide finalizers, so they must be
manually implemented by each consumer; (2) Rust's orphan rule [27, Section 6.12] prevents one
implementing traits for types defined in external libraries (i.e. unless a library's types were designed to
support &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;, those types cannot be directly GCed); (3) one cannot automatically replicate drop glue
for finalizers; and (4) one cannot replicate &lt;code&gt;rustc&lt;/code&gt;'s refusal to allow calls to the equivalent of
&lt;code&gt;Drop::drop&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;Programmers can work around problems #1 and #2 in various ways. For example, they can wrap external library types in newtypes (zero-cost wrappers) and implement finalizers on those instead [20, Section 19.3]. Doing so is tedious but not conceptually difficult.&lt;/p&gt;&lt;p&gt; Problem #3 has partial solutions: for example, [14] uses the &lt;code&gt;Trace&lt;/code&gt; macro to generate finalizer glue (the
finalizer equivalent of drop glue) for struct fields. This runs into an unsolvable variant of problem #2:
types in external libraries will not implement this trait and cannot be recursively scanned for finalizer
glue.
&lt;/p&gt;&lt;p&gt; Problem #4 is impossible to solve in Rust as-is. One cannot define a function that can never be called â what use would such a function have? A possible partial solution might seem to be for the &lt;code&gt;finalize&lt;/code&gt;
method take ownership of the value, but &lt;code&gt;Drop::drop&lt;/code&gt; does not do so because that would not allow drop
glue to be run afterwards.
&lt;/p&gt;&lt;p&gt;4.1 General Challenges When Using Destructors as Finalizers&lt;/p&gt;&lt;p&gt;We have stated as our aim that Alloy should use destructors as finalizers. Above we explained some Rust-specific challenges â but there are several non-Rust-specific challenges too! Fundamentally, finalizers and destructors have different, and sometimes incompatible, properties. The best guide to these differences, and the resulting problems, is Boehm [6], supplemented by later work on support for GC in the C++ specification [8]3.&lt;/p&gt;&lt;p&gt;An obvious difference between destructors and finalizers is when both are run. While C++ and Rust define precisely when a destructor will be run4, finalizers run at an unspecified point in time. This typically happens at some point after the equivalent destructor would run, though a program may exit before any given finalizer is run5. There are, however, two situations which invert this. First, if a thread exits due to an error, and the program is either not compiled with unwinding, or the thread has crossed a non-unwinding ABI boundary, then destructors might not be run at all, where a GC will naturally run the equivalent finalizers: we do not dwell on this, as both behaviours are reasonable in their different contexts. Second, and more surprisingly, it is possible for finalizers in non-error situations to run prematurely, that is before the equivalent destructor [6, section 3.4].&lt;/p&gt;&lt;p&gt;A less obvious difference relates to where destructors and finalizers are run. Destructors run in the same thread as the last owner of a value. However, running finalizers in the same thread as the last owner of the value can lead to race conditions [24] and deadlocks [6, section 3.3] if a finalizer tries to access a resource that the mutator expects to have exclusive access too. When such problems affect destructors in normal Rust code, it is the clear result of programmer error, since they should have taken into account the predictable execution point of destructors. However, since finalizers do not have a predictable execution point, there is no way to safely access shared resources if they are run on the same thread. The only way to avoid this is to run finalizers on a non-mutator thread â but not all Rust types / destructors are safe to run on another thread.&lt;/p&gt;&lt;p&gt;There are several additional differences such as: finalizers can reference other GCed values that are partly, or wholly, 'finalized' and may have had their backing memory reused; and finalizers can resurrect values by copying the reference passed to the finalizer and storing it somewhere.&lt;/p&gt;&lt;p&gt;Over time, finalizers have thus come to be viewed with increasing suspicion. Java, for example, has deprecated, and intends eventually removing, per-type finalizers: instead it has introduced deliberately less flexible per-object 'cleaners', whose API prevents problems such as object resurrection and per-class finalization [13].&lt;/p&gt;&lt;p&gt;4.2 The Challenge of Finalizers for Alloy&lt;/p&gt;&lt;p&gt;At this point we hope to have convinced the reader that: a viable GC for Rust needs to be able to use existing destructors as finalizers whenever possible; but that finalizers, even in existing GCs, cause various problems.&lt;/p&gt;&lt;p&gt;It is our belief that some problems with finalizers are fundamental. For example, finalizers inevitably introduce latency between the last use of a value and its finalization.&lt;/p&gt;&lt;p&gt; Some problems with finalizers are best considered the accidental artefacts of older designs. Java's cleaners, for example, can be thought of as a more restrictive version of finalizers that allow most common use-cases but forbid by design many dangerous use cases. For example, per-class/struct finalization can easily be replaced by per-object/value finalization; and object resurrection can be prevented if object access requires a level of indirection. Alloy benefits from our better shared understanding of such problems and the potential solutions: it trivially addresses per-object/value finalization (&lt;code&gt;Gc::new_unfinalizable&lt;/code&gt; function turns finalization off
for specific values) and, as we shall see later, via only slightly more involved means, object
resurrection.
&lt;/p&gt;&lt;p&gt;However, that leaves many problems that are potentially in the middle: they are not obviously fundamental, but there are not obvious fixes for them either. In our context, where we wish to use destructors as finalizers, four problems have hitherto been thought insoluble [8, p. 32]: (1) finalizers are prohibitively slower than destructors; (2) finalizers can run prematurely; (3) running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks; (4) some safe destructors are not safe finalizers.&lt;/p&gt;&lt;p&gt;Fortunately for us, Rust's unusual static guarantees, suitably expanded by Alloy, allow us to address each problem in novel, satisfying, ways. In the following section, we tackle these problems in the order above, noting that we tackle problems #1 and #2 separately, and #3 and #4 together.&lt;/p&gt;&lt;p&gt;As we shall see in Section 8, there is a correlation between the number of finalizers that are run and overhead from GC (with a worst case, albeit a definite outlier, in our experiment of 3.35Ã slowdown). In this section we show how to reduce the number of finalizers that are run, which helps reduce this overhead.&lt;/p&gt;&lt;p&gt;A variety of factors contribute to the finalizer performance overhead, including: a queue of finalizers must be maintained, whereas destructors can be run immediately; finalizers run some time after the last access of a value, making cache misses more likely; and finalizers can cause values (including values they own) to live for longer (e.g. leading to increased memory usage and marking overhead). Most of these factors are inherent to any GC and our experience of using and working on BDWGCâ a mature, widely used GC â does not suggest that it is missing optimisations which would overcome all of this overhead.&lt;/p&gt;&lt;p&gt; Instead, whenever possible, Alloy elides finalizers so that they do not need to be run at all. We are able to do this because: (1) BDWGC is responsible for all allocations and will, if necessary GC allocations even if they are not directly wrapped in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;; and (2) many Rust destructors only free memory which
BDWGC would, albeit with some latency, do anyway.
&lt;/p&gt;&lt;p&gt; Consider the standard Rust type &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; which heap allocates space for a value; when a &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; value
is dropped, the heap allocation will be freed. We can then make two observations. First, &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;'s drop
method solely consists of a &lt;code&gt;deallocate&lt;/code&gt; call. Second, while we informally say that &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; allocates on
the 'heap' and &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; allocates on the 'GC heap', all allocations in Alloy are made through BDWGC and
stored in the same heap.
&lt;/p&gt;&lt;p&gt; When used as a finalizer, &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method is thus unneeded, as the underlying memory will be
freed by BDWGC anyway. This means that there is no need to run a finalizer for a type such as
&lt;code&gt;Gc&amp;lt;Box&amp;lt;u8&amp;gt;&amp;gt;&lt;/code&gt; at all, and the finalizer can be statically elided. However, we cannot elide a
finalizer for a type such as &lt;code&gt;Gc&amp;lt;Box&amp;lt;Rc&amp;lt;u8&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; because &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method must be run for the
reference count to be decremented. As this shows, we must consider the complete destructor, and
not just the top-level drop method, when deciding whether a corresponding finalizer can be
elided.
&lt;/p&gt;&lt;p&gt;5.1 Implementing Finalizer Elision&lt;/p&gt;&lt;p&gt;Finalizer elision statically determines which type's destructors do not require corresponding finalizers and elides them. It does so conservatively, and deals correctly with drop glue.&lt;/p&gt;&lt;p&gt; As shown in Algorithm 1, any type which implements the &lt;code&gt;Drop&lt;/code&gt; trait requires finalization unless it also
implements the new &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; marker trait (i.e. a trait without methods). This
trait can be used by a programmer to signify that a type's drop method need not be called if the type is
placed inside a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. The 'Drop' part of the trait name is deliberate (i.e. it is not a simplification of
'destructor') as it allows the programmer to reason about a type locally (i.e. without considering drop
glue or concrete type paramaters). If the type has a transitively reachable field whose type implements
the &lt;code&gt;Drop&lt;/code&gt; trait but not the &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; trait, then then the top-level type still
requires finalization.
&lt;/p&gt;&lt;p&gt; Even though neither normal Rust destructors or Alloy finalizers are guaranteed to run, a program whose destructors or finalizers never run would probably not be usable (leaking resources such as memory, deadlocking, and so on). We therefore make &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; an unsafe trait,
because implementing it inappropriately is likely to lead to undesired â though not incorrect! â
behaviour at run-time.
&lt;/p&gt;&lt;p&gt; Alloy modifies the standard Rust library to implement &lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt; on the following types:
&lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;Vec&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;RawVec&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;VecDeque&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;LinkedList&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;BTreeMap&amp;lt;K, V&amp;gt;&lt;/code&gt;, &lt;code&gt;BTreeSet&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;HashMap&amp;lt;K, V&amp;gt;&lt;/code&gt;, &lt;code&gt;HashSet&amp;lt;T&amp;gt;&lt;/code&gt;,
&lt;code&gt;RawTable&amp;lt;K, V&amp;gt;&lt;/code&gt;6,
and &lt;code&gt;BinaryHeap&amp;lt;T&amp;gt;&lt;/code&gt;. Fortunately, not only are these types' drop methods compatible with
&lt;code&gt;DropMethodFinalizerElidable&lt;/code&gt;, but they are extensively used in real Rust code: they enable significant
numbers of finalizers to be elided.
&lt;/p&gt;&lt;p&gt; Listing 3 shows the new const compiler intrinsic &lt;code&gt;needs_finalizer&lt;/code&gt; we added to implement
Algorithm 1. The intrinsic is evaluated at compile-time: its result can be inlined into &lt;code&gt;Gc::new&lt;/code&gt;, allowing
the associated conditional to be removed too. In other words â compiler optimisations allowing â the
'does this specific type require a finalizer?' check has no run-time overhead.
&lt;/p&gt;&lt;p&gt;Most of us assume that finalizers are always run later than the equivalent destructor would have run, but they can sometimes run before [6, section 3.4], undermining soundness. Such premature finalization is also possible in Alloy as described thus far (see Listing 4). In this section we show how to prevent premature finalization.&lt;/p&gt;&lt;p&gt;There are two aspects to premature finalization. First, language specifications often do not define, or do not precisely define, when the earliest point that a value can be finalized is. While this means that, formally, there is no 'premature' finalization, it seems unlikely that language designers anticipated some of the resulting implementation surprises (see e.g. this example in Java [29]). Second, compiler optimisations â at least in LLVM â are 'GC unaware', so optimisations such as scalar replacement can change the point in a program when GCed values appear to be finalizable.&lt;/p&gt;&lt;p&gt; In our context, it is natural to define premature finalization as a (dynamic) finalizer for a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; value
running before the (static) &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; owner has gone out of scope. Similar to the high-level proposal mooted
in [7, Solution 1], we must ensure that the dynamic lifetime of a reference derived from a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; matches
or exceeds the lifetime of the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; itself.
&lt;/p&gt;&lt;p&gt; Our solution relies on adjusting &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method to keep alive a GCed value for at least the static
lifetime of the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; itself. In other words, we ensure that the conservative GC will always see a pointer
to a GCed value while the corresponding &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is in-scope.
&lt;/p&gt;&lt;p&gt; However, there is a major problem to overcome: copyable types such as &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; are forbidden from
having destructors. The fundamental challenge we have to solve is that each copied value will have a
destructor called on it, which has the potential for any shared underlying value to be destructed more
than once. Alloy explicitly allows &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; â but no other copyable type â to have a destructor, but to
ensure it doesn't cause surprises in the face of arbitrary numbers of copies, the destructor must be
idempotent. Our task is made easier because &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; naturally has no drop glue from Rust's perspective:
&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; consists of a field with a pointer type, and such types are opaque from a destruction
perspective.
&lt;/p&gt;&lt;p&gt; We therefore only need to make sure that &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method is idempotent. Fortunately, this is
sufficient for our purposes: we want the drop method to inhibit finalization but that does not
require run-time side effects. To achieve this, we use a fence. These come in various flavours.
What we need is a fence that prevents both: the compiler from reordering computations
around a particular syntactic point; and the CPU from reordering computations around a
particular address. We copy the platform specific code from the BDWGC &lt;code&gt;GC_reachable_here&lt;/code&gt;
macro7
into &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;'s drop method, which achieves the effect we require.
&lt;/p&gt;&lt;p&gt;6.1 Optimising Premature Finalizer Prevention&lt;/p&gt;&lt;p&gt;The drop method we add to &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; fully prevents premature finalization. It also naturally solves a
performance problem with the suggested solution for C++ in [7, Solution 1], which requires keeping
alive all pointers, no matter their type, for their full scope. By definition, our solution only
keeps alive &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; values: the compiler is free to optimise values of other types as it so wishes.
However, on an artificial microbenchmark we observed a noticeable overhead from our fence
insertion.
&lt;/p&gt;&lt;p&gt; We thus implemented a simple optimisation: we only insert fences for a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; if it has a finalizer.
Intuitively, it seems that we should not generate drop methods in such cases, but this is difficult to do
directly inside &lt;code&gt;rustc&lt;/code&gt;. Instead, we suppress calls to the drop methods of such types: the two approaches
are functionally equivalent, though ours does put an extra burden on dead-code elimination in the
compiler tool-chain.
&lt;/p&gt;&lt;p&gt; Alloy adds a new pass &lt;code&gt;RemoveElidableDrops&lt;/code&gt; to &lt;code&gt;rustc&lt;/code&gt;'s Mid-Level Intermediate Representation
(MIR) processing. MIR is best thought of as the main IR inside &lt;code&gt;rustc&lt;/code&gt;: it contains the complete set of
functions in the program, where each function consists of a sequence of basic blocks. Simplifying
somewhat, function and drop method calls are represented as different kinds of terminators on basic
blocks. Terminators reference both a callee and a successor basic block.
&lt;/p&gt;&lt;p&gt; The &lt;code&gt;remove_elidable_drops&lt;/code&gt; pass iterates over a program's MIR, identifies drop method
terminators which reference elidable finalizers, and turns them into 'goto' terminators to the
successor basic basic block. Algorithm 4 in the Appendix presents a more formal version of this
algorithm.
&lt;/p&gt;&lt;p&gt;In this section we address two high-level problems: running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks; and some safe destructors are not safe finalizers. Addressing the former problem is conceptually simple â finalizers must be run on a separate thread â but we must ensure that doing so is sound. We therefore consider this a specific instance of the latter problem, treating both equally in this section.&lt;/p&gt;&lt;p&gt;We therefore introduce Finalizer Safety Analysis (FSA), which prevents unsafe (in the sense of 'not safe Rust') destructors being used as finalizers. As a first approximation, FSA guarantees that finalizers are memory safe, cycle safe (i.e. do not access already finalized objects), and thread safe. We present the three main components of FSA individually before bringing them together.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; can store, directly or indirectly, normal Rust references (i.e. &lt;code&gt;&amp;amp;&lt;/code&gt; and &lt;code&gt;&amp;amp;mut&lt;/code&gt;), at which point it is
subject to Rust's normal borrow checker rules and cannot outlive the reference. However, finalizers
implicitly extend the lifetime of a GCed value, including any stored references: accessing a reference in a
finalizer could undermine Rust's borrow checking rules.
&lt;/p&gt;&lt;p&gt; A simple way of avoiding this problem is to forbid &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; from storing, directly or indirectly,
references. This might seem to be no great loss: storing references in a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; largely nullifies the
'GCness' of &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. However, we found the result hard to use, as it can make simple tasks such as
gradually migrating existing code to use &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; painful.
&lt;/p&gt;&lt;p&gt; A moderate, but in our experience insufficient, relaxation is to recognise that only types that need a finalizer can possibly have problems with references, and to forbid such types from storing references in &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. For example, if there is no drop method for &lt;code&gt;struct S{x: &amp;amp;u8}&lt;/code&gt;
then its destructor is safe to use as a finalizer, since its non-drop aspects will not use the &lt;code&gt;&amp;amp;u8&lt;/code&gt;
reference.
&lt;/p&gt;&lt;p&gt; The eventual rule we alighted upon for FSA is that a destructor for a type &lt;code&gt;T&lt;/code&gt; can be used as a
finalizer provided the destructor's drop methods do not obtain references derived from &lt;code&gt;T&lt;/code&gt;'s
fields (including fields reachable from its attributes). Using Rust's terminology, we forbid
projections (which include a struct's fields, indexes into a vector, and so on) in destructors from
generating references. Any non-projection references that are used in a destructor are by
definition safe to use, as they either exist only for the duration of the drop method (references to
variables on the stack) or will exist for the remainder of the program (references to global
variables).
&lt;/p&gt;&lt;p&gt;This rule over-approximates the safe set of destructors. For example, a drop method that creates a new value and tries to obtain a reference to a field in it (i.e. a projection) cannot be a destructor under FSA, even though the reference cannot outlast the drop method. We found that attempting to relax our rule further to deal with such cases rapidly complicates exposition and implementation.&lt;/p&gt;&lt;p&gt;One of the main motivations for GCs is that they solve problems with cyclic data structures. However, finalizers can be unsound if they access state shared within members of a cycle. Listing 5 shows an example of undefined behaviour when two GCed values create a cycle and both their finalizers reference the other GCed value. Whichever order the finalizers are run in, at least one of the finalizers will see the other GCed value as partly or wholly 'finalized'.&lt;/p&gt;&lt;p&gt;Most languages and systems we are aware of assume that users either don't run into this problem (finalization cycles are considered rare in GCed languages [19, p. 229]) or know how to deal with it when they do (e.g. refactoring the types into parts that do and don't require finalization [6, p. 11]). There is no fully automatic solution to this problem. Some GCs offer weak references, which allow users to detect when finalization cycles have been broken, though they still have to deal with the consequences manually.&lt;/p&gt;&lt;p&gt; We wanted to provide users with static guarantees that their destructors will not behave unexpectedly when used as finalizers in a cycle. A first attempt at enforcing such a property might seem to be that a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; cannot have, directly or indirectly, fields of type &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. This would indeed
prevent the mistakes we want to catch but also disallow shared ownership! We therefore
check only that a type's destructor does not, directly or indirectly, access a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. This allows
GCed types to express shared ownership so long as their destructor(s) do not access other GC
types.
&lt;/p&gt;&lt;p&gt; To make this check easier to implement, we introduce an auto trait [27, Section. 11], a kind of marker trait that the compiler propagates automatically. An auto trait &lt;code&gt;A&lt;/code&gt; will be automatically implemented for a
type &lt;code&gt;T&lt;/code&gt; unless one of the following is true: there is an explicit negative implementation of &lt;code&gt;A&lt;/code&gt; for &lt;code&gt;T&lt;/code&gt;; or &lt;code&gt;T&lt;/code&gt;
contains a field that is not itself &lt;code&gt;A&lt;/code&gt;. Informally, we say that a negative implementation of an auto-trait
pollutes containing types.
&lt;/p&gt;&lt;p&gt; Our new auto trait is called &lt;code&gt;FinalizerSafe&lt;/code&gt;, and we provide a single negative implementation
&lt;code&gt;impl&amp;lt;T&amp;gt; !FinalizerSafe for Gc&amp;lt;T&amp;gt;&lt;/code&gt;. This naturally handles transitively reachable code, allowing FSA
itself to only check that a destructor's direct field accesses are &lt;code&gt;FinalizerSafe&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;7.3 Destructors Need to be Runnable on a Finalizer Thread&lt;/p&gt;&lt;p&gt;Running finalizers on the same thread as a mutator can cause problems when the finalizer accesses state shared with the mutator (see Section 4.1 for a general description and Listing 6 for a concrete example). The most general solution to this problem is to run finalizers on a separate finalizer thread that never runs mutator code.&lt;/p&gt;&lt;p&gt; We must therefore ensure that it is safe to run a type's destructor on the finalizer thread. A conservative definition is that &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is safe to use if &lt;code&gt;T&lt;/code&gt; implements both of Rust's existing &lt;code&gt;Send&lt;/code&gt; (denoting
a type that can be permanently moved from one thread to another) and &lt;code&gt;Sync&lt;/code&gt; (denoting a type that can be
safely accessed simultaneously by multiple threads) auto traits. However, requiring that finalization be
restricted to types that implement both &lt;code&gt;Send&lt;/code&gt; and &lt;code&gt;Sync&lt;/code&gt; can be frustrating, particularly because more
types implement &lt;code&gt;Send&lt;/code&gt; than &lt;code&gt;Sync&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; It may seem sufficient for &lt;code&gt;T&lt;/code&gt; to implement &lt;code&gt;Send&lt;/code&gt; alone so that the value can be safely sent to the finalizer
thread. However, this would not prevent a finalizer indirectly accessing state shared with a
non-GCed value via a mechanism such as &lt;code&gt;Arc&lt;/code&gt;, causing the very problems we are trying to
avoid.
&lt;/p&gt;&lt;p&gt; FSA thus ignores whether a type implements &lt;code&gt;Send&lt;/code&gt; or &lt;code&gt;Sync&lt;/code&gt; (or not) and instead examines the
destructor directly. To pass FSA: the destructor must not access thread locals; and any types the
destructor accesses via projections must implement both &lt;code&gt;Send&lt;/code&gt; and &lt;code&gt;Sync&lt;/code&gt;. Intuitively, this allows a
non-&lt;code&gt;Send&lt;/code&gt;-or-&lt;code&gt;Sync&lt;/code&gt; type &lt;code&gt;T&lt;/code&gt; to have a safe finalizer provided that &lt;code&gt;T&lt;/code&gt;'s destructor only access the &lt;code&gt;Send&lt;/code&gt; and
&lt;code&gt;Sync&lt;/code&gt; 'subset' of &lt;code&gt;T&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; This rule shows clearly that FSA is a form of abstract interpretation rather than a mere extension of the type system8. After careful examination we believe this is compatible with Rust's semantics (and &lt;code&gt;rustc&lt;/code&gt; and LLVM's
implementations) at the time of writing, but it is worth knowing that this rule would be unsafe in other
languages and implementations (for example our assumption would be unsafe in Java due to
synchronisation removal [31]). We leave it as an open question to others as to whether Rust should
deliberately permit or forbid such checks in its semantics.
&lt;/p&gt;&lt;p&gt;The implementation of the finalization thread is fairly simple. For example, we do not need to explicitly synchronise memory between the mutator and finalization threads because BDWGC's stop-the-world collection phase already synchronises all memory between threads.&lt;/p&gt;&lt;p&gt; FSA integrates the seemingly separate components presented above into one. It iterates over every function in a Rust program analysing destructors of types that are used in &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. Algorithm 2 shows the
essence of FSA (for example eliding details of caching which Alloy uses to speed up compile
times).
&lt;/p&gt;&lt;p&gt; Because FSA is a form of abstract interpretation, we need to determine when to run FSA on a program. In essence, whenever a previously unchecked type &lt;code&gt;T&lt;/code&gt; is used to create a new &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;, FSA is run. As well as
the &lt;code&gt;Gc::new&lt;/code&gt; constructor, &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; instances can be created with conversion traits such as &lt;code&gt;From&lt;/code&gt;. We
annotated each such entry point with a new &lt;code&gt;rustc&lt;/code&gt;-only attribute &lt;code&gt;rustc_fsa_entry_point&lt;/code&gt;: calls to
functions with this attribute lead to FSA checks.
&lt;/p&gt;&lt;p&gt; A naive implementation of FSA would be a notable cost, so Alloy uses several optimisations. As alluded to above, FSA caches the results of various checks to avoid pointlessly repeating work. We also extend &lt;code&gt;FinalizerSafe&lt;/code&gt; with negative implementations for &lt;code&gt;&amp;amp;T&lt;/code&gt;, and &lt;code&gt;&amp;amp;mut T&lt;/code&gt;. If a type &lt;code&gt;T&lt;/code&gt; implements all of
&lt;code&gt;FinalizerSafe&lt;/code&gt;, &lt;code&gt;Send&lt;/code&gt;, and &lt;code&gt;Sync&lt;/code&gt;, we know that there can be no unsafe projections used in a destructor,
and can bypass most FSA checks entirely (though we still need to check for thread local accesses).
Across our benchmark suite, FSA increases compilation time in release mode by a modest
0.8â1.6%.
&lt;/p&gt;&lt;p&gt; Algorithm 2 also captures Alloy's approach to error messages. Rather than just inform a user that 'your drop method has not passed FSA', Alloy pinpoints which field or line in a drop method caused FSA to fail: &lt;code&gt;EmitReferenceError&lt;/code&gt; informs the user when a reference in a type is used in a way that violates
FSA (see Section 7.1); and &lt;code&gt;EmitFinalizerUnsafeError&lt;/code&gt; when a drop method contains code which is
unsafe (e.g. references a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; type, an opaque function, etc.). Listing 7 shows an example of the errors
reported by Alloy: note that it pinpoints the line within a drop method that caused an FSA
error.
&lt;/p&gt;&lt;p&gt;7.4.1 Awkward Kinds of Functions&lt;/p&gt;&lt;p&gt;FSA can encounter two kinds of 'awkward' functions.&lt;/p&gt;&lt;p&gt; First, some functions (e.g. due to use of trait objects, or FFIs) do not have a body available when FSA runs: using such a function necessarily causes an FSA check to fail. One common class of functions which causes this are Rust intrinsics (e.g. &lt;code&gt;min_align_of&lt;/code&gt; etc.): we audited the most frequently used of
these and annotated those which are FSA-safe with a new &lt;code&gt;rustc_fsa_safe_fn&lt;/code&gt; attribute. Other functions
whose bodies are unknown cause FSA to fail.
&lt;/p&gt;&lt;p&gt; Second, in most cases, FSA runs on Rust functions whose generic types have been replaced with concrete types (in Rust terminology, functions have been 'monomorphised'). Sometimes, however, FSA encounters functions (e.g. intrinsics or functions with certain annotations) whose generic types have not yet been replaced. FSA can still run on such functions, but will reject them unless all generic types imply the &lt;code&gt;FinalizerSafe&lt;/code&gt;, &lt;code&gt;Send&lt;/code&gt;, and &lt;code&gt;Sync&lt;/code&gt; traits. Note that calling a method on a generically typed value will
lead to FSA finding a method without a body: as in the first case above, this will cause FSA to
fail.
&lt;/p&gt;&lt;p&gt; The common theme to both is that we wish FSA to be sound, at which point we forego completeness. This can cause users frustration when FSA raises an error on code they know is FSA safe. As is common in Rust, we therefore provide an unsafe escape hatch which allows users to silence FSA errors when they can prove to their satisfaction that doing so does undermine correctness. We experimented with a per-type approach, but found that unduly restrictive: we therefore provide a per-value escape hatch with the &lt;code&gt;unsafe FinalizerUnchecked&amp;lt;T&amp;gt;&lt;/code&gt; type. Values wrapped in this type are
considered safe to use at all points in FSA. Our aim is that users should rarely need to resort to this
escape hatch, but, as is not uncommon in Rust, there are valid idioms of use where we found it
necessary.
&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Version&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;cell role="head"&gt;#benchmarks&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;Debian CLBG Rust#2&lt;/cell&gt;&lt;cell&gt;Heap allocation microbenchmark&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;Debian CLBG Rust#1&lt;/cell&gt;&lt;cell&gt;Regular expression matching&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;v0.15.0-dev&lt;/cell&gt;&lt;cell&gt;Terminal emulator&lt;/cell&gt;&lt;cell&gt;10&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;v9.0.0&lt;/cell&gt;&lt;cell&gt;Unix find replacement&lt;/cell&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;v0.13.4&lt;/cell&gt;&lt;cell&gt;Lexer / parser library&lt;/cell&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;v14.1.1&lt;/cell&gt;&lt;cell&gt;Fast grep replacement&lt;/cell&gt;&lt;cell&gt;13&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;git #35b780&lt;/cell&gt;&lt;cell&gt;SOM AST VM&lt;/cell&gt;&lt;cell&gt;26&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;git #35b780&lt;/cell&gt;&lt;cell&gt;SOM bytecode VM&lt;/cell&gt;&lt;cell&gt;26&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;, etc.). Binary Trees and Regex-Redux are classic
stand-alone GC benchmarks; the other 'benchmarks' represent benchmark suites (e.g. Ripgrep contains 13
benchmarks). The middle portion of the table shows a variety of 'normal' Rust programs; the bottom portion
of the program shows three implementations of the SOM programming language.&lt;p&gt;In this section we explain our methodology and our experimental results.&lt;/p&gt;&lt;p&gt;There is no existing benchmark suite for GCs for Rust. Even if such a suite did exist, it may not have been suitable for our purposes because in experiment EGCvs we want to compare programs using existing shared ownership approaches. We searched through roughly the 100 most popular Rust libraries on &lt;code&gt;crates.io&lt;/code&gt; (the de facto standard Rust package system) looking for suitable candidates. In
practise this meant we looked for crates using reference counting. In the interests of brevity,
for the rest of this section we use '&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;' to cover both &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; and its thread-safe cousin
&lt;code&gt;Arc&amp;lt;T&amp;gt;&lt;/code&gt;.
&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell role="head"&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell role="head"&gt;Weak&amp;lt;T&amp;gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;107&lt;/cell&gt;&lt;cell&gt;9,450&lt;/cell&gt;&lt;cell&gt;1,970&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;cell&gt;421&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;299&lt;/cell&gt;&lt;cell&gt;1,825&lt;/cell&gt;&lt;cell&gt;23&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;108&lt;/cell&gt;&lt;cell&gt;109&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;104&lt;/cell&gt;&lt;cell&gt;249&lt;/cell&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;206&lt;/cell&gt;&lt;cell&gt;35&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;464&lt;/cell&gt;&lt;cell&gt;39&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;, we also show
how many weak references are left in: this is a proxy both for partial porting, and also how the extent weak
references. This is a proxy for the extent of changes that cyclic data-structures impose upon source code.&lt;p&gt;Table 1 shows the resulting suite: note that, except for Binary Trees and Regex-Redux, the 'benchmarks' are themselves benchmark suites. Collectively, our suite contains â depending on whether you count the SOM implementations' (identical) benchmark suites collectively or separately â 62 or 88 benchmarks. Table 2 shows how often relevant types are used after porting. Table 3 shows the distribution of heap data at run-time. This shows that our suite contains benchmarks with a variety of memory patterns.&lt;/p&gt;&lt;p&gt; Binary Trees is allocation intensive and sufficiently simple that it can be easily and meaningfully ported to additional shared ownership strategies: Rust-GC, a user library for GC for Rust [14]; and &lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt;, a non-GC memory arena [10]. Alacritty, fd, and Ripgrep are well known Rust programs, all
of which have their own benchmark suites. grmtools is a parsing library which uses &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; extensively
in error recovery: we benchmarked it using 28KLoC of real Java source code, which we mutated with
syntax errors.
&lt;/p&gt;&lt;p&gt; SOM is a small, but complete, language in the Smalltalk mould, which has a wide variety of implementations. Our suite includes two of these: som-rs-ast (which represents programs as ASTs); and som-rs-bc (which represents programs as bytecode). Both are existing ports of a Java SOM VM into Rust and use &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;. We use the same SOM &lt;code&gt;core-lib&lt;/code&gt; benchmarks for both, derived from git commit
#afd5a6.
&lt;/p&gt;&lt;p&gt; We were not able to port all parts of all programs. In particular, some programs make extensive use of the &lt;code&gt;make_mut&lt;/code&gt; and &lt;code&gt;get_mut&lt;/code&gt; functions in &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;, which allow a programmer to mutate their contents if, at
run-time, they only have a single owner. There is not, and cannot be, equivalent functionality with a
copyable &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; type. In some cases we were able to successfully use alternative mechanisms. In others
we judged the usages to either be rare at run-time (i.e. not worth porting), or too difficult to port (i.e. too
much of the program is built around the resulting assumptions). In a small number of cases we
ended up introducing bugs. Alacritty's UTF-8 support is an example, resulting in deadlocks.
Whenever we encountered a bug in our porting, we reverted back to &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; for that portion of the
port.
&lt;/p&gt;&lt;table&gt;&lt;row span="5"&gt;&lt;cell role="head"&gt;Allocated (#)&lt;/cell&gt;&lt;cell role="head"&gt;GC owned (%)&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Box&amp;lt;T&amp;gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;125&lt;/cell&gt;&lt;cell&gt;8,770&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;2.70&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;3,222,201&lt;/cell&gt;&lt;cell&gt;3,222,190&lt;/cell&gt;&lt;cell&gt;100.00&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;17,821&lt;/cell&gt;&lt;cell&gt;306,902&lt;/cell&gt;&lt;cell&gt;61&lt;/cell&gt;&lt;cell&gt;1.23&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;2,283&lt;/cell&gt;&lt;cell&gt;19,859,431&lt;/cell&gt;&lt;cell&gt;4,038,605&lt;/cell&gt;&lt;cell&gt;44.19&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;45&lt;/cell&gt;&lt;cell&gt;3,132&lt;/cell&gt;&lt;cell&gt;78&lt;/cell&gt;&lt;cell&gt;15.39&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;12,786&lt;/cell&gt;&lt;cell&gt;521,366&lt;/cell&gt;&lt;cell&gt;26,069&lt;/cell&gt;&lt;cell&gt;17.97&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;15&lt;/cell&gt;&lt;cell&gt;8,586,976&lt;/cell&gt;&lt;cell&gt;1,533,728&lt;/cell&gt;&lt;cell&gt;76.95&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;15&lt;/cell&gt;&lt;cell&gt;2,397,931&lt;/cell&gt;&lt;cell&gt;1,530,325&lt;/cell&gt;&lt;cell&gt;99.71&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; values. For example, a program consisting of a single &lt;code&gt;Gc&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; would have a
'GC Owned' value of 100% because the &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; is owned by the &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. As we shall see later, there can be a
number of knock-on effects when a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; owns other such values.&lt;p&gt;8.1.2 What We Couldn't Include in the Benchmark Suite&lt;/p&gt;&lt;p&gt;We tried porting 10 other programs that are not included in our benchmark suite. To avoid readers wondering if we have 'cherry-picked' our eventual benchmark suite, we briefly report why those other programs have been excluded. All excluded benchmarks are shown in Table 4 in the Appendix.&lt;/p&gt;&lt;p&gt;Several programs (e.g. numbat, mini-moka, and salsa), once ported, turned out to be uninteresting from a GC benchmarking perspective. Irrespective of the number of source locations that reference memory allocation types, the benchmarks we could run from them allocated sufficiently little memory that there are no worthwhile differences between different allocation strategies. Put another way: these programs are in a sense 'the same' from our evaluation perspective.&lt;/p&gt;&lt;p&gt; Two programs (bevy and rust-analyzer) did not run correctly after porting. Both extensively use the &lt;code&gt;make_mut&lt;/code&gt; or &lt;code&gt;get_mut&lt;/code&gt; functions in &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; and reverting those changes made the benchmarks
uninteresting.
&lt;/p&gt;&lt;p&gt; We also ported RustPython, but were unable to adjust it to faithfully implement Python-level destructors. In essence, in RustPython's default configuration, its representation of objects is not compatible with FSA. This means that we can not run Python &lt;code&gt;__del__&lt;/code&gt; methods in the
finalizer thread. Although technically this is still compatible with Python's semantics, we
felt this would be a misleading comparison, as our port of RustPython would be doing less
work.
&lt;/p&gt;&lt;p&gt;Our experiment can be seen as a comparison of Alloy against 'normal' Rust. Fortunately, Alloy is a strict superset of 'normal' Rust: only if users explicitly opt into GC does Alloy really become a 'GC for Rust'. This allows us to use the same compiler, standard library, and so on, removing several potential confounding factor in our results. We compile two binaries: one without logging features compiled and one with. We only use the latter when reporting collector related metrics.&lt;/p&gt;&lt;p&gt; A challenge in our experiment is that different allocation strategies can use different underlying allocators. In particular, Alloy has to use BDWGC, but, for example, &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; can use a modern allocator
such as jemalloc. Much has changed in the performance of allocators since BDWGC's 1980s roots: in
&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;-only benchmarks, we observe an inherent overhead from BDWGC of 2â26% relative to jemalloc
(see Table 6 in the Appendix), which is a significant, and variable, confounding factor. Fortunately,
BDWGC can be used as a 'traditional' allocator that allocates and frees on demand (i.e. no
conservative GC occurs): in the main experiment, we thus use BDWGC as the allocator for all
benchmarks.
&lt;/p&gt;&lt;p&gt;We want to understand the memory usage of different allocation strategies over the lifetime of a benchmark. However, there is no single metric which captures 'memory usage', nor even an agreed set of metrics [5]. We use two metrics to capture different facets: (1) heap footprint, the amount of live heap memory recorded by by Heaptrack [34] at every allocation and deallocation; and (2) Resident Set Size (RSS), the total physical memory in RAM used by the process (including memory-mapped files, stack, and code/text segments), sampled at 10Hz. The overhead of recording heap footprint is much greater than RSS, but it provides a more detailed view of memory usage.&lt;/p&gt;&lt;p&gt;Another pair of confounding factors are the initial and maximum sizes of the GC heap: too-small values can lead to frequent resizing and/or 'thrashing'; large values to unrealistically few collections. What 'small' and 'large' are varies by benchmark, and 'careful' (or thoughtless) choices can significantly distort one's view of performance. BDWGC uses an adaptive strategy by default, growing the heap size as it detects that it would benefit from doing so. To give some sense of whether a different strategy and/or heap size would make a difference, we ran our benchmarks with three different fixed heap sizes. Doing so either has little effect or speeds benchmarks up; when it does so, the impact is generally under 10% and is at most 28% (the detailed results are presented in Table 9 in the Appendix). Broadly speaking, this suggests that BDWGC's default heap sizing approach, at least in our context, is not significantly distorting our view of performance.&lt;/p&gt;&lt;p&gt; We ran each benchmark in our suite 30 times. We report wall-clock times as returned by the standard Unix &lt;code&gt;time&lt;/code&gt; utility. The SOM benchmarks are run using its conventional rebench
tool; we adjusted rebench to use &lt;code&gt;time&lt;/code&gt; for consistency with our other benchmarks. We ran
all benchmarks on an AMD EPYC 7773X 64-Core 3.5GHz CPU with 128GiB RAM, running
Debian 12 ('bookworm'). We turned off turbo boost and hyper-threading, as both can colour
results.
&lt;/p&gt;&lt;p&gt;Except where otherwise stated, we report means and 99% confidence intervals for all metrics. We use the arithmetic mean for individual benchmarks and the geometric mean for benchmark suites.&lt;/p&gt;&lt;p&gt;When plotting time-series (i.e. sampled) memory metrics, we face the challenge that different configurations of the same benchmark can execute at different speeds. We thus resample each benchmark's data to 1000 evenly spaced points using linear interpolation. We chose 1000 samples because it is considerably above the visual resolution of our plots. After normalization, we calculate the arithmetic mean of the memory footprint measurement at each grid point (and not the raw underlying data) across all runs of the same benchmark. We record 99% confidence intervals at each point and show the result as shaded regions around the mean.&lt;/p&gt;&lt;p&gt;The main results for EGCvs can be seen in Fig. 1. Though there is variation, Alloy has an overhead on wall-clock time of 5% on our benchmark suite. The effect on memory is more variable though, unsurprisingly, Alloy typically has a larger average heap footprint (i.e. allocated memory lives for longer). This metric needs to treated with slight caution: benchmarks which allocate relatively small amounts of memory (see Table 3) can make the relative effect of average heap footprint seem much worse than it is in absolute terms.&lt;/p&gt;&lt;p&gt; Binary Trees is sufficiently simple that we also used it to compare against &lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt; and Rust-GC.
The time-series data in Fig. 2 is particularly illuminating (for completeness, Table 5 in the Appendix has
the raw timings). Alloy is around 3.5Ã slower than &lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt;. The time-series data for the latter shows it
going through distinct phases: a (relatively long) allocation phase, a (relatively moderate) 'work' phase,
and a (relatively short) deallocation phase. Put another way: these clear phases make Binary Trees a
perfect match for an arena. In the other approaches, the 'work' phase occupies a much greater proportion
of their execution, because it also incorporates allocator work. Alloy is around 1.3Ã faster than &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;,
but both have similar memory profiles. Alloy is around 3Ã faster than Rust-GC and has an
average heap footprint around 4Ã smaller, reflecting Alloy's advantage in not being a user-land
library that relies in part on &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;. Although we caution against over-interpreting a single
benchmark, this does give us at least some idea of the performance ceiling and floor for different
approaches.
&lt;/p&gt;&lt;p&gt; The time-series data in Fig. 2 helps explain other factors. For example, it shows that som-rs-bc leaks memory on the JSON Small benchmark (we suspect it also leaks in some other benchmarks, though rarely as visibly). This is because &lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt; keeps alive values in cycles; Alloy does not leak memory on
som-rs-bc, as it naturally deals correctly with cycles.
&lt;/p&gt;&lt;p&gt; We can see from the time-series data that Ripgrep has a complex heap footprint pattern. This may suggest a memory leak, but in fact it is a consequence of the inevitable delay in freeing memory in a GC. In general, GC notices that memory is unused later than reference counting, but this is exacerbated further by finalizers. Surprisingly, finalizers can lengthen or shorten an allocation's lifetime. GCed values with finalizers tend to have longer lifetimes, because they have to wait in the finalizer queue. However, when a finalizer calls &lt;code&gt;free&lt;/code&gt; on
indirectly owned values, those are immediately marked as not live, rather than having to
wait until the next collection to be discovered as such. This, albeit indirectly, explains the
seemingly random peaks and troughs in memory usage one can observe in Ripgrep's time-series
data.
&lt;/p&gt;&lt;p&gt; The results of EElision are shown in Fig. 3. In general, there is a fairly clear correlation: the more finalizers are removed, and the greater the proportion of the overall heap the memory owned by &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is,
the better the metrics become. However, there are several caveats. First, when all finalizers are removed,
BDWGC does not start a finalizer thread or invoke locking related to it, unduly flattering the time-based
metrics. Second, the quantity of finalizers is only a partial proxy for cost: some finalizers free
up large graphs of indirectly owned values, which can take some time to run. Third, some
benchmarks change the work they do: grmtools speeds up so much that its error recovery
algorithm has time to do more work, so while finalizer hugely benefits its GC pause time,
its wall-clock time changes much less. Finally, since finalizers can cause indirectly owned
allocations to be freed earlier than the GC itself does naturally, removing them can cause
indirectly owned values to live for longer: Ripgrep's average heap footprint highlights this
issue.
&lt;/p&gt;&lt;p&gt;The results for EPremOpt are shown in Fig. 4. We created three configurations of Alloy. None has no fences, and thus is unsound, but allows us to approximate (allowing for possible vagaries from running unsound code!) the best possible outcome. Naive inserts all possible fences. Optimised inserts only necessary fences. Once confidence intervals are taken into account, there are no statistically significant results for this experiment. Although it is possible that benchmarking 'noise' is hiding a meaningful result, our data suggests that any such differences are likely to be minimal. To make up for this disappointment, the fact that there is no difference between any of these suggests that, on non-artificial benchmarks, premature finalizer prevention is not a noticeable cost.&lt;/p&gt;&lt;p&gt; Any performance judgements we make are necessarily contingent on our methodology the benchmark suite we chose, including the proportion of benchmarks that we ported, and the way we process and present data. For example, we did not port external libraries to use &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; so many benchmarks use a
variety of allocation strategies. Even had we ported everything, we would not be able to say, for example,
that finalizer elision will always improve performance by exactly the factor we see in our experiment:
there undoubtedly exist reasonable, non-pathological, programs which will see performance changes
outside the ranges that our results suggest.
&lt;/p&gt;&lt;p&gt;Using BDWGC as the allocator for all benchmarks has the advantage of removing 'pure' allocator performance as a confounding factor, but does mean that some of the performance characteristics of benchmarks will be changed (e.g due to the portion of time we spend in the allocator; or BDWGC's adaptive heap sizing strategy). A generic, modern conservative GC, using the insights of recent non-GC allocators, would almost certainly give different â though we suspect not profoundly different â results. To the best of our knowledge there is currently no production-quality modern, generic conservative, GC we could use instead, though we are aware of at least one attempt to create such an alternative: it will be interesting to rerun our experiments if and when that arrives.&lt;/p&gt;&lt;p&gt;The RSS memory metric we collect is at Linux's whim: if it does not update as frequently as we expect, we will see artificially 'smoothed' data that may miss out peaks and troughs. Similar, our interpolation of time-series data onto a normalised grid can also smooth data. We manually checked a large quantity of data to ensure this was not a significant effect; by running benchmarks 30 times means it is also less more likely that peaks and troughs are caught at least sometimes.&lt;/p&gt;&lt;p&gt;In this paper we hope to have given sufficient background on GC and the use of destructors and finalizers in general. In this section we mostly survey the major parts of the GC for Rust landscape more widely. Our survey is inevitably incomplete, in part because this is a rapidly evolving field (a number of changes have occurred since the most recent equivalent survey we are aware of [16]). We also cover some relevant non-Rust GC work not mentioned elsewhere.&lt;/p&gt;&lt;p&gt; Early versions of Rust had 'managed pointers' (using the &lt;code&gt;@T&lt;/code&gt; syntax) which were intended to
represent GC types [16]. The core implementation used reference counting though there
were several, sometimes short-lived, cycle detectors [17]. Managed pointer support was
removed9 
around a year before the first stable release of Rust. This was not the end of the story for
'GC as a core part of Rust', with core Rust developers exploring the problem space in more
detail [15, 21, 22]. Over time these efforts dwindled, and those interested in GC for Rust largely
moved from anticipating &lt;code&gt;rustc&lt;/code&gt; support to expecting to have to do everything in user-level
libraries.
&lt;/p&gt;&lt;p&gt; One of the earliest user-level GC for Rust libraries is Bacon-Rajan-CC [12]. This provides a type &lt;code&gt;Cc&amp;lt;T&amp;gt;&lt;/code&gt;
which is similar in intention to Alloy's &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;. The mechanism by which objects are collected is rather
different: they have a naive reference count, which causes objects outside a cycle to have deterministic
destruction; and users can manually invoke a cycle detector, which uses trial deletion in the style of Bacon and
Rajan [4]10 
to identify objects in unused cycles. Cycle detection requires users manually implementing a &lt;code&gt;Trace&lt;/code&gt; trait
which traverses a type's fields. Destructors are used as finalizers: to avoid the problems with Rust
references we solved in Section 7.1, Bacon-Rajan-CC imposes a &lt;code&gt;T:'static&lt;/code&gt; lifetime bound on the type
parameter passed to &lt;code&gt;Cc&amp;lt;T&amp;gt;&lt;/code&gt;. Simplifying slightly, this means that any references in such a type must be
valid for the remaining lifetime of the program, a severe restriction. Unlike our approach to the access of
already-finalized values (Section 7.2), it can only detect such accesses at runtime, leading to a (safe) Rust
&lt;code&gt;panic&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; Probably the best known GC for Rust is Rust-GC [14] (partly covered in Section 4). Rust-GC's &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;
provides a similar API to Alloy, with the notable exception that its &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; is not, and cannot be, copyable,
thus always requiring calls to &lt;code&gt;Gc::clone&lt;/code&gt;. Although, like Alloy, Rust-GC allows &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; values to be
converted into pointers, its lack of conservative GC means that users must ensure that a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; wrapper
is kept alive for the entire lifetime of pointers derived from it. Similarly to Bacon-Rajan-CC,
GCed values are reference counted, with occasional tracing sweeps to identify cycles, though
Rust-GC performs cycle detection automatically (i.e. it doesn't require manual calls to a
function such as &lt;code&gt;collect_cycles&lt;/code&gt;). Drop methods are not used as finalizers: if a finalizer is
required, a manual implementation of the &lt;code&gt;Finalize&lt;/code&gt; trait must be provided; finalizer glue can be
largely, though not fully (see Section 4), automatically created by the provided &lt;code&gt;Trace&lt;/code&gt; macro.
Rust-GC detects accesses to already-finalized values dynamically at run-time, panicking
if they occur. Unlike Bacon-Rajan-CC, these accesses are detected by recording what the
collector's state is in: if the collector is in a 'sweep' phase, any access of a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; leads to a
panic. We have not yet verified whether cross-thread collection / sweeping can evade this
check.
&lt;/p&gt;&lt;p&gt; An example of moving beyond reference counting in a GC for Rust is Shifgrethor [2]. It requires &lt;code&gt;Gc&lt;/code&gt;
values to be created by a &lt;code&gt;Root&amp;lt;'root&amp;gt;&lt;/code&gt;: the resulting &lt;code&gt;Gc&amp;lt;'root, T&amp;gt;&lt;/code&gt; is then tied to the lifetime of the
&lt;code&gt;Root&amp;lt;'root&amp;gt;&lt;/code&gt;. This allows roots to be precisely identified, but requires explicitly having access to a
&lt;code&gt;Root&amp;lt;'root&amp;gt;&lt;/code&gt; whenever a &lt;code&gt;Gc&amp;lt;'root, T&amp;gt;&lt;/code&gt; is used. As with Rust-GC, Shifgrethor requires users to
manually implement a &lt;code&gt;Finalize&lt;/code&gt; trait, though Shifgrethor's is more restrictive: not only can other
GCed values not be accessed (implicitly solving the same problem as Section 7.2) but any other
type without the same &lt;code&gt;'root&lt;/code&gt; lifetime as the GCed value is forbidden. This means that many
seemingly safe finalizers require implementing the unsafe &lt;code&gt;UnsafeFinalize&lt;/code&gt; trait. We view
Shifgrethor as proof that accurately tracking GC roots in normal Rust without reference
counting is possible, though it cannot deal with references being converted into pointers and
&lt;code&gt;usize&lt;/code&gt;s.
&lt;/p&gt;&lt;p&gt; A different means of tackling the root-finding problem is GcArena [32], which uses branding in a similar way to &lt;code&gt;GhostCell&lt;/code&gt;s (see Section 2). In essence, users provide a special 'root' type which is the
only place where roots can be stored. Mutating the heap can only be done in the context
of functions that are passed a branded reference to the GCed heap. Once such a function
has completed, GcArena is in full control of the GC heap, and knows that only the root
type needs to be scanned for roots. This leads to a precise guarantee about GC reference
lifetimes. However, if code executes in an arena for too long, the system can find itself starved of
resources, with no way of recovering, even if much of the arena is no longer used. GcArena
was originally part of the Piccolo VM (which was itself previously called Luster), a Lua VM
written in Rust. Such VMs have a frequently executed main loop which is a natural point for a
program to relinquish references to the GCed heap, but this is not true of many other GCed
programs.
&lt;/p&gt;&lt;p&gt; One attempt to improve upon Rust-GC is Bronze [11], though it shows how challenging it can be to meaningfully improve GC for Rust: both of its main advances have subsequently been disabled because they are not just unsound but actively lead to crashes. First, Bronze tried to solve the root-finding problem by using LLVM's &lt;code&gt;gc.root&lt;/code&gt;
intrinsic at function entries to generate stack-maps (a run-time mechanism for accurately tracking active
pointers). This rules out the false positives that are inevitable in conservative GC. However, Bronze
could not track nested references: if a &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; was used as a field in a struct, it was not tracked
by the GC. Second, Bronze tried to give GC in Rust similar semantics to non-ownership
languages such as Java. It did this by allowing shared mutation, undermining Rust's borrow
checker.
&lt;/p&gt;&lt;p&gt;Chrome's rendering engine Blink uses the conservative GC Oilpan. It has the interesting property that it has two classes of finalizers. 'Full finalizers' are similar to finalizers in Alloy, running on a finalizer thread at an indeterminate future point, but with the difference that they can only reference parts of a GCed value. To mitigate this, 'pre-finalizers' are run by the collector on the same thread as mutator as soon as an object as recognised as unused, and can access all of a GCed value. Pre-finalizers are necessary, but not encouraged, because they implicitly pause the stop-the-world phase of the collector. This reflects the fact that latency is a fundamental concern for a rendering engine: Alloy currently makes no pretences to being low latency.&lt;/p&gt;&lt;p&gt;We introduced a novel design for GC in Rust that solves a number of outstanding challenges in GC for Rust, as well as â by taking advantage of Rust's unusual static guarantees â some classical GC finalizer problems. By making integration with existing Rust code easier than previous GCs for Rust, we hope to have shown a pragmatic route for partial or wholesale migration of Rust code that would benefit from GC.&lt;/p&gt;&lt;p&gt; Challenges and future opportunities remain. For example, Alloy is an 'all or nothing' cost: if you want to use &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; in a single location, you must pay the costs of the GC runtime and so
on. Alloy's absolute speed is, we believe, limited by BDWGC: it is probable that using a
semi-precise GC and/or a faster conservative GC could change our view of the absolute performance
speed
&lt;/p&gt;&lt;p&gt; In summary, we do not claim that Alloy is the ultimate design for GC in Rust â reasonable people may, for example, disagree on whether the costs of conservative GC are worth the gains â but it does show what can be achieved if one is willing to alter the language's design and &lt;code&gt;rustc&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;The accompanying artefact [18] contains: the source code necessary to run this paper's experiment (including generating figures etc.) from scratch; and data from a run of the experiment that we used in this paper.&lt;/p&gt;&lt;p&gt;This work was funded by an EPSRC PhD studentship and the Shopify / Royal Academy of Engineering Research Chair in Language Engineering. We thank Steve Klabnik and Andy Wingo for comments.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Benchmark&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;cell role="head"&gt;Reason for exclusion&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;bevy&lt;/cell&gt;&lt;cell&gt;ECS game engine in Rust&lt;/cell&gt;&lt;cell&gt;Unable to port successfully (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;dyon&lt;/cell&gt;&lt;cell&gt;Scripting language in Rust&lt;/cell&gt;&lt;cell&gt;Unable to port successfully (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;jiff&lt;/cell&gt;&lt;cell&gt;A datetime library for Rust&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;mini-moka&lt;/cell&gt;&lt;cell&gt;Concurrent in-memory cache library&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;numbat&lt;/cell&gt;&lt;cell&gt;Math search engine&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;rkyv&lt;/cell&gt;&lt;cell&gt;Zero-copy deserialization framework&lt;/cell&gt;&lt;cell&gt;Insufficient &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; coverage in benchmarks&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;RustPython&lt;/cell&gt;&lt;cell&gt;Python interpreter written in Rust&lt;/cell&gt;&lt;cell&gt;Difficulty retro-fitting &lt;code&gt;__del__&lt;/code&gt; semantics (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;rust-analyzer&lt;/cell&gt;&lt;cell&gt;Language server for Rust&lt;/cell&gt;&lt;cell&gt;Unable to port successfully (see Section 8.1.2)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;salsa&lt;/cell&gt;&lt;cell&gt;Incremental recomputation library&lt;/cell&gt;&lt;cell&gt;Too few allocations to measure&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;WLambda&lt;/cell&gt;&lt;cell&gt;Scripting language written in Rust&lt;/cell&gt;&lt;cell&gt;Insufficient &lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; coverage in benchmarks&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="5"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt; (Rust-GC)&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Arena&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;0.41 [0.39, 0.45]&lt;/cell&gt;&lt;cell&gt;0.40 [0.38, 0.44]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;0.11 [0.11, 0.11]&lt;/cell&gt;&lt;cell&gt;0.15 [0.14, 0.15]&lt;/cell&gt;&lt;cell&gt;0.33 [0.32, 0.33]&lt;/cell&gt;&lt;cell&gt;0.03 [0.03, 0.04]&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;0.33 [0.29, 0.38]&lt;/cell&gt;&lt;cell&gt;0.31 [0.26, 0.37]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;3.06 [3.00, 3.14]&lt;/cell&gt;&lt;cell&gt;3.24 [3.17, 3.31]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;0.47 [0.47, 0.47]&lt;/cell&gt;&lt;cell&gt;0.45 [0.45, 0.46]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;1.61 [1.55, 1.69]&lt;/cell&gt;&lt;cell&gt;1.52 [1.45, 1.59]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;0.92 [0.88, 0.95]&lt;/cell&gt;&lt;cell&gt;0.79 [0.76, 0.82]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;0.28 [0.27, 0.29]&lt;/cell&gt;&lt;cell&gt;0.29 [0.28, 0.30]&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;cell&gt;â&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;cell role="head"&gt;Ratio&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;jemalloc&lt;/cell&gt;&lt;cell&gt;BDWGC&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;0.36 [0.33, 0.40]&lt;/cell&gt;&lt;cell&gt;0.40 [0.38, 0.44]&lt;/cell&gt;&lt;cell&gt;1.11&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;0.12 [0.12, 0.12]&lt;/cell&gt;&lt;cell&gt;0.15 [0.14, 0.15]&lt;/cell&gt;&lt;cell&gt;1.26&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;0.30 [0.25, 0.36]&lt;/cell&gt;&lt;cell&gt;0.31 [0.26, 0.37]&lt;/cell&gt;&lt;cell&gt;1.02&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;3.09 [3.01, 3.17]&lt;/cell&gt;&lt;cell&gt;3.24 [3.17, 3.31]&lt;/cell&gt;&lt;cell&gt;1.05&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;0.45 [0.44, 0.45]&lt;/cell&gt;&lt;cell&gt;0.45 [0.45, 0.46]&lt;/cell&gt;&lt;cell&gt;1.01&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;1.46 [1.40, 1.53]&lt;/cell&gt;&lt;cell&gt;1.52 [1.45, 1.59]&lt;/cell&gt;&lt;cell&gt;1.04&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;0.77 [0.74, 0.80]&lt;/cell&gt;&lt;cell&gt;0.79 [0.76, 0.82]&lt;/cell&gt;&lt;cell&gt;1.02&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;0.28 [0.27, 0.29]&lt;/cell&gt;&lt;cell&gt;0.29 [0.28, 0.30]&lt;/cell&gt;&lt;cell&gt;1.02&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;-only code (i.e., no GC). The ratio column shows BDWGC time divided by jemalloc time.&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;jemalloc&lt;/cell&gt;&lt;cell&gt;BDWGC&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;User time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;jemalloc&lt;/cell&gt;&lt;cell&gt;BDWGC&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Gc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;Rc&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Heap Size (MiB)&lt;/cell&gt;&lt;cell role="head"&gt;Relative wall-clock time&lt;/cell&gt;&lt;cell role="head"&gt;Benchmarks failed&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alacritty&lt;/cell&gt;&lt;cell&gt;16&lt;/cell&gt;&lt;cell&gt;0.96 [0.91, 0.99]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.98 [0.95, 1.02]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.94 [0.89, 0.98]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Binary Trees&lt;/cell&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;cell&gt;0.88 [0.82, 1.02]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;cell&gt;0.90 [0.80, 1.01]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;16&lt;/cell&gt;&lt;cell&gt;0.87 [0.82, 0.94]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;fd&lt;/cell&gt;&lt;cell&gt;16&lt;/cell&gt;&lt;cell&gt;0.94 [0.90, 0.99]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.94 [0.88, 0.98]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.94 [0.89, 1.00]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;grmtools&lt;/cell&gt;&lt;cell&gt;1024&lt;/cell&gt;&lt;cell&gt;1.01 [1.00, 1.02]&lt;/cell&gt;&lt;cell&gt;2/4 (Eclipse, Jenkins)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;2048&lt;/cell&gt;&lt;cell&gt;1.00 [1.00, 1.01]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;4096&lt;/cell&gt;&lt;cell&gt;1.01 [1.00, 1.02]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Regex-Redux&lt;/cell&gt;&lt;cell&gt;256&lt;/cell&gt;&lt;cell&gt;0.94 [0.92, 0.95]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;512&lt;/cell&gt;&lt;cell&gt;0.93 [0.90, 0.94]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;1024&lt;/cell&gt;&lt;cell&gt;0.96 [0.92, 1.07]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Ripgrep&lt;/cell&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.96 [0.95, 0.96]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.95 [0.94, 0.95]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;128&lt;/cell&gt;&lt;cell&gt;0.94 [0.93, 0.95]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-ast&lt;/cell&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.72 [0.71, 0.74]&lt;/cell&gt;&lt;cell&gt;2/4 (Fannkuch, TreeSort)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;96&lt;/cell&gt;&lt;cell&gt;0.74 [0.73, 0.75]&lt;/cell&gt;&lt;cell&gt;2/4 (Fannkuch, TreeSort)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;128&lt;/cell&gt;&lt;cell&gt;0.75 [0.74, 0.76]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;som-rs-bc&lt;/cell&gt;&lt;cell&gt;32&lt;/cell&gt;&lt;cell&gt;0.79 [0.78, 0.80]&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;64&lt;/cell&gt;&lt;cell&gt;0.79 [0.77, 0.80]&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;128&lt;/cell&gt;&lt;cell&gt;0.84 [0.83, 0.86]&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Fin. elided (%)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Table 10. Percentage of finalizers Alloy was able to elide for each benchmark.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Wall-clock time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Before elision&lt;/cell&gt;&lt;cell&gt;After elision&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;User time (s)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Before elision&lt;/cell&gt;&lt;cell&gt;After elision&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Avg. heap footprint (MiB)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Before elision&lt;/cell&gt;&lt;cell&gt;After elision&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Alacritty â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;fd â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;som-rs-ast â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;grmtools â¶&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Ripgrep â¶&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;som-rs-bc â¶&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;size_t&lt;/code&gt; and &lt;code&gt;uintptr_t&lt;/code&gt; types respectively. Rust now has a provenance lint to nudge users in this general direction, but the &lt;code&gt;as&lt;/code&gt; keyword still allows arbitrary conversions.
    &lt;code&gt;y = Gc::clone(&amp;amp;v)&lt;/code&gt; is available, since every copyable type is also cloneable.
    &lt;code&gt;RawTable&lt;/code&gt; is contained in the separate &lt;code&gt;hashbrown&lt;/code&gt; crate which is then included in Rust's standard library. We previously maintained a fork of this, but synchronising it is painful. For now, at least, we have hacked explicit knowledge of &lt;code&gt;RawTable&lt;/code&gt; into the &lt;code&gt;needs_finalize&lt;/code&gt; function.
    &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/"/><published>2025-10-15T12:08:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591222</id><title>Show HN: Scriber Pro – Offline AI transcription for macOS</title><updated>2025-10-15T14:42:35.852205+00:00</updated><content>&lt;doc fingerprint="68fec097b143b4f5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Scriber Pro&lt;/head&gt;
    &lt;p&gt;Offline AI transcription for macOS&lt;/p&gt;
    &lt;p&gt; • 4.5hr video → 3.5min. Faster than Rev, Otter, or any online service.&lt;lb/&gt; • More accurate on long context. No 2-hour upload limits.&lt;lb/&gt; • 100% offline. Your data never leaves your Mac. &lt;/p&gt;
    &lt;p&gt;All HN promo codes claimed! Thanks for the response. Download on Mac App Store&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Scriber Pro?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stupid fast: 4.5hr video → 3.5min. Seriously.&lt;/item&gt;
      &lt;item&gt;Any format: MP3, WAV, MP4, MOV, M4A, FLAC—drop it in, it works.&lt;/item&gt;
      &lt;item&gt;Perfect timecodes: 5min or 5hr file, timecodes stay accurate. No drift, no chunking errors.&lt;/item&gt;
      &lt;item&gt;Works offline: On a plane. In a coffee shop. No internet, no problem.&lt;/item&gt;
      &lt;item&gt;Your data stays yours: Everything processes on your Mac. No cloud uploads, no surveillance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Export Anywhere&lt;/head&gt;
    &lt;p&gt; Timecode formats: SRT, VTT, JSON (with precise timestamps)&lt;lb/&gt; Documents: PDF, DOCX, TXT, Markdown&lt;lb/&gt; Data: CSV, JSON&lt;lb/&gt; One transcription, eight formats. Perfect timecodes whether it's 3min or 3hr. &lt;/p&gt;
    &lt;p&gt;Contact: [email protected] | Main Site&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scriberpro.cc/hn/"/><published>2025-10-15T12:16:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591264</id><title>They Clean the Balls in a Ball Pit</title><updated>2025-10-15T14:42:35.601204+00:00</updated><content>&lt;doc fingerprint="e5d003771a3c2e68"&gt;
  &lt;main&gt;
    &lt;p&gt;Ball pits, invented by designers Charlotte Rude and Hjördis Olsson-Une for Ikea in 1970, went on to become wildly popular. Fast food restaurants, amusement parks, play centers and community recreation facilities have all featured them.&lt;/p&gt;
    &lt;p&gt;To the wary parent, they seem like hotbeds of germs. Anecdotal stories (like these or these on Reddit, from people who worked at facilities with ball pits) of the slapdash way they're cleaned—or not cleaned—don't help the rumors:&lt;/p&gt;
    &lt;quote&gt;- "A place I worked with a ball pit would just load up the balls in mesh bags and have one of the janitors drive through a car wash with the balls in the bed of their truck."&lt;/quote&gt;
    &lt;quote&gt;- "I worked at this play place called Catch Air. We would clean the balls individually by hand every few weeks. Really shitty job."&lt;/quote&gt;
    &lt;quote&gt;- "Sometimes little kids being little kids, there will be someone who'd poop or throw up in the ballpit. And a messy job too, its almost guaranteed you'll get covered in it if you are the lucky one who goes in to fish out every ball."&lt;/quote&gt;
    &lt;quote&gt;- "Babies will also chew and sneeze on everything, including the balls in the pit."&lt;/quote&gt;
    &lt;quote&gt;- "When I worked at Chuck E Cheese we had a late night scheduled every six months to clean the ball pit. We would empty them all into bus tubs and run them thru the giant dishwasher. They smelled VERY strongly of urine, as I recall."&lt;/quote&gt;
    &lt;quote&gt;- "Worked at McDonalds for years. The only time the ball pit got cleaned was when kids started coming out with poo on them."&lt;/quote&gt;
    &lt;quote&gt;- "If you think they are nasty under normal circumstances, wait until they have about 12 years of dust sitting on them. The kind that gets sticky after awhile ... Yeah it was as disgusting as you are picturing it."&lt;/quote&gt;
    &lt;p&gt;That said, ball pit cleaning machines do exist, and responsible facilities like TQ Playtopia in Oklahoma City use them regularly.&lt;/p&gt;
    &lt;p&gt;"Our amazing cleaning crew uses Tuesdays to deep clean the entire playground, and sanitize EVERYTHING," the company writes. "Every ball from every pit gets run through our ball washer- that alone takes 5 hours!"&lt;/p&gt;
    &lt;p&gt;Here's what the machines do:&lt;/p&gt;
    &lt;p&gt;Create a Core77 Account&lt;/p&gt;
    &lt;p&gt;Already have an account? Sign In&lt;/p&gt;
    &lt;p&gt;By creating a Core77 account you confirm that you accept the Terms of Use&lt;/p&gt;
    &lt;p&gt;Please enter your email and we will send an email to reset your password.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.core77.com/posts/138608/Heres-How-They-Clean-the-Balls-in-a-Ball-Pit"/><published>2025-10-15T12:19:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591707</id><title>I Almost Got Hacked by a 'Job Interview'</title><updated>2025-10-15T14:42:35.490212+00:00</updated><content/><link href="https://blog.daviddodda.com/how-i-almost-got-hacked-by-a-job-interview"/><published>2025-10-15T12:56:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591799</id><title>Apple M5 chip</title><updated>2025-10-15T14:42:35.370102+00:00</updated><content>&lt;doc fingerprint="39dbf13f092261dc"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple unleashes M5, the next big leap in AI performance for Apple silicon&lt;/head&gt;
    &lt;p&gt; M5 delivers over 4x the peak GPU compute performance for AI compared to M4, featuring a next-generation GPU with a Neural Accelerator in each core, a more powerful CPU, a faster Neural Engine, and higher unified memory bandwidth &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today announced M5, delivering the next big leap in AI performance and advances to nearly every aspect of the chip. Built using third-generation 3-nanometer technology, M5 introduces a next-generation 10-core GPU architecture with a Neural Accelerator in each core, enabling GPU-based AI workloads to run dramatically faster, with over 4x the peak GPU compute performance compared to M4.1 The GPU also offers enhanced graphics capabilities and third-generation ray tracing that combined deliver a graphics performance that is up to 45 percent higher than M4.1 M5 features the world’s fastest performance core, with up to a 10-core CPU made up of six efficiency cores and up to four performance cores.2 Together, they deliver up to 15 percent faster multithreaded performance over M4.1 M5 also features an improved 16-core Neural Engine, a powerful media engine, and a nearly 30 percent increase in unified memory bandwidth to 153GB/s.1 M5 brings its industry-leading power-efficient performance to the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro, allowing each device to excel in its own way. All are available for pre-order today. &lt;/p&gt;
    &lt;p&gt;“M5 ushers in the next big leap in AI performance for Apple silicon,” said Johny Srouji, Apple’s senior vice president of Hardware Technologies. “With the introduction of Neural Accelerators in the GPU, M5 delivers a huge boost to AI workloads. Combined with a big increase in graphics performance, the world’s fastest CPU core, a faster Neural Engine, and even higher unified memory bandwidth, M5 brings far more performance and capabilities to MacBook Pro, iPad Pro, and Apple Vision Pro.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Next-Generation GPU Architecture Optimized for AI and Graphics&lt;/head&gt;
    &lt;p&gt;With the next-generation GPU architecture in M5, every compute block of the chip is optimized for AI. The 10-core GPU features a dedicated Neural Accelerator in each core, delivering over 4x peak GPU compute compared to M4, and over 6x peak GPU compute for AI performance compared to M1.1 And now with M5, the new 14-inch MacBook Pro and iPad Pro benefit from dramatically accelerated processing for AI-driven workflows, such as running diffusion models in apps like Draw Things, or running large language models locally using platforms like webAI. &lt;/p&gt;
    &lt;p&gt;The next-generation GPU and enhanced shader cores in M5 also deliver increased graphics performance, achieving up to 30 percent faster performance compared to M4 and up to 2.5x faster performance than M1.1 M5 also includes Apple’s third-generation ray-tracing engine, providing up to a 45 percent graphics uplift in apps using ray tracing.1 Combined with rearchitected second-generation dynamic caching, the GPU provides smoother gameplay, more realistic visuals in 3D applications, and faster rendering times for complex graphics projects and other visually intensive applications. With M5, Apple Vision Pro renders 10 percent more pixels with the micro-OLED displays, and refresh rates increase up to 120Hz, resulting in crisper details, more fluid display performance, and reduced motion blur. &lt;/p&gt;
    &lt;p&gt;The GPU architecture is engineered for seamless integration with Apple’s software frameworks. Applications using built-in Apple frameworks and APIs — like Core ML, Metal Performance Shaders, and Metal 4 — can automatically see immediate increases in performance. Developers can also build solutions for their apps by directly programming the Neural Accelerators using Tensor APIs in Metal 4. &lt;/p&gt;
    &lt;head rend="h2"&gt;A Faster Neural Engine to Power Intelligent Features&lt;/head&gt;
    &lt;p&gt;The faster 16-core Neural Engine delivers powerful AI performance with incredible energy efficiency, complementing the Neural Accelerators in the CPU and GPU to make M5 fully optimized for AI workloads. For example, AI-powered features on Apple Vision Pro — like the ability to transform 2D photos into spatial scenes in the Photos app, or generating a Persona — operate with greater speed and efficiency. &lt;/p&gt;
    &lt;p&gt;The Neural Engine in M5 also enhances performance for Apple Intelligence.3 On-device AI tools like Image Playground get faster, and the overall performance of Apple Intelligence models are enhanced by the faster Neural Engine and unified memory in M5.4 Also, developers using Apple’s Foundation Models framework will get faster performance. &lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced Memory to Do Even More with AI&lt;/head&gt;
    &lt;p&gt;M5 offers unified memory bandwidth of 153GB/s, providing a nearly 30 percent increase over M4 and more than 2x over M1. The unified memory architecture enables the entire chip to access a large single pool of memory, which allows MacBook Pro, iPad Pro, and Apple Vision Pro to run larger AI models completely on device. It fuels the faster CPU, GPU, and Neural Engine as well, offering higher multithreaded performance in apps, faster graphics performance in creative apps and games, and faster AI performance running models on the Neural Accelerators in the GPU or the Neural Engine. And with 32GB of memory capacity, M5 also helps users to seamlessly run demanding creative suites like Adobe Photoshop and Final Cut Pro simultaneously, while uploading large files to the cloud in the background. &lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Silicon and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The power-efficient performance of M5 helps the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro meet Apple’s high standards for energy efficiency, and reduces the total amount of energy consumed over the product’s lifetime. &lt;/p&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using preproduction 14-inch MacBook Pro systems with Apple M5, 10-core CPU, and 10-core GPU; production 14-inch MacBook Pro systems with Apple M4, 10-core CPU, and 10-core GPU; and production 13-inch MacBook Pro systems with Apple M1, 8-core CPU, and 8-core GPU. Performance measured using select industry‑standard benchmarks. Performance tests are conducted using specific computer systems and reflect the approximate performance of MacBook Pro.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using shipping competitive systems and select industry-standard benchmarks.&lt;/item&gt;
      &lt;item&gt;Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
      &lt;item&gt;Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/"/><published>2025-10-15T13:02:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591801</id><title>Apple Vision Pro upgraded with M5 chip</title><updated>2025-10-15T14:42:35.206663+00:00</updated><content>&lt;doc fingerprint="b7cdbb1d7322b0d5"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple Vision Pro upgraded with the powerful M5 chip and comfortable Dual Knit Band&lt;/head&gt;
    &lt;p&gt; The latest version improves performance, display rendering, battery life, and comfort, while offering innovative features with visionOS 26 and all-new spatial apps and Apple Immersive content &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today introduced Apple Vision Pro with the powerful M5 chip that delivers a leap forward in performance, improved display rendering, faster AI-powered workflows, and extended battery life. The upgraded Vision Pro also comes with the soft, cushioned Dual Knit Band to help users achieve an even more comfortable fit, and visionOS 26, which unlocks innovative spatial experiences, including widgets, new Personas, an interactive Jupiter Environment, and new Apple Intelligence features with support for additional languages.1 There are over 1 million apps and thousands of games on the App Store, hundreds of 3D movies on the Apple TV app, and all-new series and films in Apple Immersive with a selection of live NBA games coming soon. Vision Pro with M5 and the Dual Knit Band is now available to pre-order on apple.com. Customers can book a demo at Apple Store locations today and it will be available nationwide beginning Wednesday, October 22. &lt;/p&gt;
    &lt;p&gt;“With the breakthrough performance of M5, the latest Apple Vision Pro delivers faster performance, sharper details throughout the system, and even more battery life, setting a new standard for what’s possible in spatial computing,” said Bob Borchers, Apple’s vice president of Worldwide Product Marketing. “Paired with the comfortable Dual Knit Band, innovative features in visionOS 26, and all-new Apple Immersive experiences spanning adventure, documentary, music, and sports, spatial computing is even more capable, entertaining, and magical with the new Vision Pro.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Leap Forward in Performance with M5&lt;/head&gt;
    &lt;p&gt;M5 provides an even faster, smoother, and more responsive experience for Apple Vision Pro users, while introducing new opportunities for developers to create more advanced spatial and immersive experiences. Built using third-generation 3-nanometer technology, M5 on Vision Pro features an advanced 10-core CPU that delivers higher multithreaded performance, resulting in faster experiences throughout the system, including faster load times for apps and widgets and more responsive web browsing. The next-generation 10-core GPU architecture brings support for hardware-accelerated ray tracing and mesh shading, enabling developers to add remarkable detail to lighting, shadows, and reflections in games like Control. &lt;/p&gt;
    &lt;p&gt;With M5, Apple Vision Pro renders 10 percent more pixels on the custom micro-OLED displays compared to the previous generation, resulting in a sharper image with crisper text and more detailed visuals. Vision Pro can also increase the refresh rate up to 120Hz for reduced motion blur when users look at their physical surroundings, and an even smoother experience when using Mac Virtual Display. Vision Pro with M5 works alongside the purpose-built R1 chip, which processes input from 12 cameras, five sensors, and six microphones, and streams new images to the displays within 12 milliseconds to create a real-time view of the world. The high-performance battery now supports up to two and a half hours of general use, and up to three hours of video playback, all on a single charge.2 And it’s easy to use Vision Pro for longer periods at home, at an office, or while commuting by connecting the battery to power. &lt;/p&gt;
    &lt;p&gt;The 16-core Neural Engine makes AI-powered features run up to 50 percent faster for system experiences — like capturing a Persona or transforming photos into spatial scenes — and up to 2x faster for third-party apps compared to the previous generation.3 With M5, developers such as JigSpace are pioneering new use cases for enterprises that combine spatial computing with on-device AI. Using Apple’s Foundation Models framework, the new JigSpace app for Vision Pro taps into the on-device model at the core of Apple Intelligence to make complex information easier to understand. Users can parse through complex datasets with natural language and learn about sophisticated objects, like wind turbines, using interactive 3D models. &lt;/p&gt;
    &lt;head rend="h2"&gt;The New Dual Knit Band Offers a More Comfortable Fit&lt;/head&gt;
    &lt;p&gt;The Dual Knit Band delivers an even more comfortable fit for users. It features upper and lower straps that are 3D-knitted as a single piece to create a unique dual-rib structure that provides cushioning, breathability, and stretch. The lower strap features flexible fabric ribs embedded with tungsten inserts that provide a counterweight for additional comfort, balance, and stability. And the intuitive dual-function Fit Dial allows users to make fine-tuned adjustments to achieve their ideal fit. The new Dual Knit Band comes in small, medium, and large sizes; is available to purchase separately; and is compatible with the previous-generation Apple Vision Pro. Customers can easily find the size that is right for them using the Apple Store app for iPhone. &lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful Spatial Experiences with visionOS 26&lt;/head&gt;
    &lt;p&gt;visionOS 26 brings a set of powerful spatial experiences to Apple Vision Pro. Widgets seamlessly integrate into a user’s space and reappear every time they put Vision Pro on, making it easy to check the time or weather, play music or podcasts, decorate their space with photos, or access ChatGPT. Striking enhancements to Persona make communicating in apps like FaceTime feel even more natural and familiar. Spatial scenes, which use generative AI to add lifelike depth to photos, make memories come to life. Users can play back 180-degree, 360-degree, and wide field-of-view video from popular action cameras, so they can enjoy their footage the way it was meant to be seen, and creators can publish videos in these formats to apps like Safari and Vimeo. With iPadOS 26.1, available later this fall, the Apple Vision Pro app comes to iPad, offering users another great way to discover new content, queue apps and games to download, find tips, and quickly access information about their Vision Pro. &lt;/p&gt;
    &lt;head rend="h2"&gt;New Apps, Content, and Games to Explore&lt;/head&gt;
    &lt;p&gt;There are over 1 million apps available for Apple Vision Pro, including more than 3,000 apps built for visionOS. Users can design their dream home with HomeByMe and Lowe’s Style Studio, outfit their closet with Balenciaga, and browse stunning artwork with Christie’s Select and Art Authority Museum. They can explore extraordinary locations around the world with Epic Earth and Explore POV, transform their physical space into a planetarium with Space Vision, or travel back in time with D-Day: The Camera Soldier. &lt;/p&gt;
    &lt;p&gt;Apple Vision Pro remains the ultimate entertainment device. With the new Vision Pro, users can experience concerts like never before with Amplium; tune into their favorite teams with apps from major sports leagues; or enjoy a personal theater with apps from popular streaming services on a screen that appears up to 100 feet wide. Apple Immersive continues to redefine what is possible in storytelling, and Vision Pro users can enjoy new series and films on the Apple TV app. Later this season, users in the Lakers’ broadcast territory will be able to watch select live games in Apple Immersive, and new titles from the Audi F1 Project, the BBC, HYBE, and Red Bull will launch in Apple Immersive in the coming months.4 The Apple TV app is also home to one of the largest digital collections of 3D movies available, featuring recent blockbusters like Superman, Jurassic World Rebirth, How to Train Your Dragon, and Wicked. &lt;/p&gt;
    &lt;p&gt;Gaming on Apple Vision Pro is next level with its ultra-high-resolution displays, advanced Spatial Audio system, low latency, and responsive controls across a variety of input methods, including popular game controllers like Sony DualSense, which now supports multidevice pairing. &lt;/p&gt;
    &lt;p&gt;Players will be able to enjoy iPad games like Where Winds Meet, POOLS, and Sniper Elite 4, fun spatial games like Porta Nubi and Glassbreakers: Champions of Moss, and the latest titles on consoles and PCs with apps like Portal and Steam Link. And with support for the PlayStation VR2 Sense controller, players get a new class of immersive games with high-performance motion tracking in six degrees of freedom, finger touch detection, and vibration support. Elu Legend, Pickle Pro, Ping Pong Club, and Spatial Rifts are some of the first games available with support for the PlayStation VR2 controller. &lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced Capabilities for Pro Users and Enterprises&lt;/head&gt;
    &lt;p&gt;With Apple Vision Pro, users can supercharge their workflows and discover new ways to realize their creative visions. Artists can design new works using apps like Crayon and Da Vinci Eye. Photographers can edit images with color accuracy from any location and in any lighting condition using Pixelmator on MacBook Pro with Mac Virtual Display. Filmmakers can scout locations from anywhere by viewing spatial media — including panoramas and spatial videos shot on iPhone — on a large wraparound display. And pro users can assemble and rehearse their presentations while in a seat-for-seat replica of the Steve Jobs Theater at Apple Park using Keynote. With Logitech Muse — a digital pencil built for Vision Pro — users can create and collaborate with a new level of precision. Apps like Crayon, doppl by Interaptix, Sketch Pro, and Spatial Analogue are adding support for Muse over the coming weeks. &lt;/p&gt;
    &lt;p&gt;Businesses around the world are harnessing the power of spatial computing on Apple Vision Pro every day to invent new solutions and streamline operations across design, education, healthcare, sales, and more. CAE, the multinational technology company that specializes in simulation and instruction solutions, uses Vision Pro to help pilots complete training activities outside of specialized centers, featuring true-to-life flight deck environments and scenarios. At Porsche, drivers can visualize and personalize new vehicles in select showrooms before taking delivery. And by seamlessly blending digital content with the physical world, Visage provides high-quality, three-dimensional medical imaging, helping hospitals like UC San Diego Health improve patient care. &lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Vision Pro and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. Apple Vision Pro is made with 100 percent recycled aluminum in the frame and battery enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled cobalt in the battery. Vision Pro is designed to last and meets Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled. &lt;/p&gt;
    &lt;p&gt;Pricing and Availability &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro with the M5 chip and Dual Knit Band starts at $3,499 (U.S.), and is available in 256GB, 512GB, and 1TB storage capacities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers can pre-order Apple Vision Pro with the M5 chip and Dual Knit Band today in Australia, Canada, France, Germany, Hong Kong, Japan, the UAE, the UK, and the U.S. It will be available for pre-order in China mainland and Singapore on Friday, October 17.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro with the M5 chip and Dual Knit Band will be available in Apple Store locations in Australia, Canada, China mainland, Hong Kong, France, Germany, Japan, Singapore, the UAE, the UK, and the U.S. on Wednesday, October 22. It will be available in South Korea and Taiwan later.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers can book a demo of Apple Vision Pro online. Demos are hosted at all Apple Store locations where Vision Pro is available. Demos of the latest Vision Pro will feature the new Dual Knit Band, and customers can ask to see new features, apps, and experiences, including the Spatial Gallery app, Apple Intelligence features like Genmoji and Writing Tools, and extended previews of several Apple Immersive experiences, including the new sports documentary Tour De Force from CANAL+ and MotoGP in select markets.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro comes with the new Dual Knit Band, a Light Seal, two Light Seal Cushions, an Apple Vision Pro Cover for the front of the device, Polishing Cloth, Battery, USB-C Charge Cable, and the 40W Dynamic Power Adapter with 60W Max.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dual Knit Band is available to purchase separately for $99 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Vision Pro Travel Case is available for $199 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For users who require vision correction, ZEISS Optical Inserts — Readers will be available for $99 (U.S.), and ZEISS Optical Inserts — Prescription will be available for $149 (U.S.).5&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Logitech Muse is now available to pre-order for $129.95 (U.S.) from logitech.com and the Apple Store online in countries and regions where Apple Vision Pro is available. It will be available alongside Apple Vision Pro with M5 and the Dual Knit Band on Wednesday, October 22.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PlayStation VR2 Sense controller and Controller Charging Station will be available for $249.95 (U.S.) from the Apple Store online in the U.S. beginning Tuesday, November 11.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover Apple Vision Pro, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit apple.com/applecare.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Image Playground is available in English (Australia, Canada, India, Singapore, UK, U.S.), French (Canada, France), German, Italian, Japanese, and Spanish (Mexico, Spain) when Apple Intelligence is enabled. Feature availability varies by region.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in August and September 2025 using preproduction Apple Vision Pro (M5) units and software. Testing consisted of full battery discharge while performing each of the following tasks: video playback, internet browsing, spatial video capture, and FaceTime. Video playback tested in conjunction with an Environment, using 2D movie content purchased from the Apple TV app. Internet browsing tested using 20 popular websites. FaceTime tested between two Apple Vision Pro units with Personas enabled. Tested with Wi‑Fi associated to a network. Battery life depends on device settings, usage, network, environmental conditions, and many other factors. Battery tests are conducted using specific Apple Vision Pro units; actual results may vary.&lt;/item&gt;
      &lt;item&gt;Testing conducted by Apple in September 2025 using preproduction Apple Vision Pro (M5) and production Apple Vision Pro (M2) units. Up to 2x faster performance results were achieved when tested with prerelease Draw Things v1.20250820.0 on Apple Vision Pro (M5), v1.20250903.0 on Apple Vision Pro (M2), and a 768x768 text-to-image generation with step-distilled Qwen Image model at 6-bit quantization in two steps. When tested with Photos app by creating spatial scenes from photos, performance results were up to 1.5x faster. Performance tests are conducted using specific Apple Vision Pro units and reflect the approximate performance of Apple Vision Pro.&lt;/item&gt;
      &lt;item&gt;Additional information about titles from the Audi F1 Project, the BBC, HYBE, and Red Bull will be provided by these creators closer to their availability.&lt;/item&gt;
      &lt;item&gt;A valid prescription is required. Not all prescriptions are supported. Vision correction accessories are sold separately. ZEISS Optical Inserts — Prescription are only available to purchase online.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/"/><published>2025-10-15T13:03:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591865</id><title>Mac Source Ports – Run old games on new Macs</title><updated>2025-10-15T14:42:34.672704+00:00</updated><content>&lt;doc fingerprint="27614135739545fa"&gt;
  &lt;main&gt;
    &lt;p&gt;Mac Source Ports features native app builds of source ports of your favorite games for both Apple Silicon and Intel Macs, signed and notarized whenever possible.&lt;/p&gt;
    &lt;p&gt;Developer: Stainless Games&lt;lb/&gt;Release Date: June 13, 1997&lt;/p&gt;
    &lt;p&gt;An example of controversy for controversy's sake, Carmageddon basically took what people wanted to do in other racing games - crash into other cars and run over pedestrians - and turned it into the primary gameplay loop. They took the macabre joke about getting points for hitting people in your car and made it a gameplay mechanic. The game was successful both from a critical and commercial perspective, as well as its goal as a controversy magnet.&lt;lb/&gt;The dethrace project is a source port where in lieu of source code they're reverse engineering it, and according to their Twitter account they're approximately 70% of the way there. The game is very playable but may crash in some places, so I'm introducing a new tag: Early Access. This probably could use a better name but I'm using it to convey the notion that the project doesn't consider itself completely finished (though there are reports of people making it through the entire game), but it's still pretty awesome so I figured if nothing else it's worth putting up a quick build.&lt;/p&gt;
    &lt;p&gt;Developer: Pumpkin Studios&lt;lb/&gt;Release Date: April 10, 1999&lt;lb/&gt;Source Code Release Date: December 6, 2004&lt;/p&gt;
    &lt;p&gt;Warzone 2100 is a post-apocalyptic real-time strategy game from 1999 whose source was released in 2004 and whose content was released as freeware in 2008.&lt;lb/&gt;Although my aim is to host signed and notarized game bundles on Mac Source Ports, the Warzone 2100 Project has done incredible work on this port and has logistical reasons for not being notarized yet. While they work through that process, I decided it was worth making an exception to the site's policy so that Apple Silicon gamers looking for a full, free and polished RTS would be able to find it.&lt;lb/&gt;Because the app bundle is not notarized, on first run you may run into issues. The shortest answer is to right-click on the app bundle (wz2100.app) and select Open. The long answer is here.&lt;/p&gt;
    &lt;p&gt;Developer: Grey Matter Interactive&lt;lb/&gt;Release Date: November 19, 2001&lt;lb/&gt;Source Code Release Date: August 12, 2010&lt;/p&gt;
    &lt;p&gt;Return to Castle Wolfenstein is a fantastic single player game with lots of little touches you might have missed the first time around and that you don't see much anymore. Still abolutely worth firing up just to blast some Nazis. This source port also includes the multiplayer as a separate app, which still works on the servers running to this day.&lt;/p&gt;
    &lt;p&gt;Developer: id Software&lt;lb/&gt;Release Date: December 9, 1997&lt;lb/&gt;Source Code Release Date: December 22, 2001&lt;/p&gt;
    &lt;p&gt;Quake II is a first-person shooter, the second in the Quake series. Yamagi Quake2 is the most mature and advanced port actively being maintained.&lt;/p&gt;
    &lt;p&gt;Developer: New World Computing&lt;lb/&gt;Release Date: October 1, 1996&lt;/p&gt;
    &lt;p&gt;Heroes of Might and Magic II is a 4X turn-based strategy game. Ranked once by PC Gamer as the sixth-best game of all time it features resource building, new factions, skills, and a single-player campaign.&lt;/p&gt;
    &lt;p&gt;Developer: Chris Sawyer&lt;lb/&gt;Release Date: October 15, 2002&lt;/p&gt;
    &lt;p&gt;Another game from the mind of Chris Sawyer, RollerCoaster Tycoon 2 shares the same pixel art style and hardcore interface as his other games.&lt;/p&gt;
    &lt;p&gt;Developer: Epic MegaGames&lt;lb/&gt;Release Date: May 7, 1998&lt;/p&gt;
    &lt;p&gt;Although never as big as Mario or Sonic, Jazz Jackrabbit did well enough with a hungry PC gaming crowd to merit a second game in the series. It's your standard shareware sequel story: more levels, more twists, better technology. If you liked the original you'll like this one.&lt;lb/&gt;It also has a very confusing release strategy. The original game was shareware, when you bought it you got the full Jazz Jackrabbit 2 game. Later, it was re-released with an additional episode under the title Jazz Jackrabbit 2: The Secret Files. Then came a release called Jazz Jackrabbit 2: The Christmas Chronicles, which adds Christmas-themed levels. So when you get the game on GOG you might spot two entries, neither of which look like they're the base game, but both should work in Jazz² Resurrection.&lt;/p&gt;
    &lt;p&gt;Developer: Thalion Software&lt;lb/&gt;Release Date: April 11, 1993&lt;lb/&gt;Source Code Release Date: May 7, 2023&lt;/p&gt;
    &lt;p&gt;The Commodore Amiga was one of those computers where it jumped ahead of the competition by several miles, but then stayed there for a long time and got surpassed by the competition. I think this is why there's such a distinctive look to the games the platform and why it was so accessible to smaller game designers, the types we'd call "indie" today.&lt;lb/&gt;Ambermoon is an RPG for the Amiga that really looks like an Amiga game. It was the second part of an unfinished trilogy. Although the original game's source has been released, the source port we're pointing to is Ambermoon.net which like it sounds is a recreation of the original game in C#/.NET (the original game was Amiga-specific Assembly language and isn't a great candidate for portability).&lt;lb/&gt;In addition to being able to download it below from the developer's GitHub page, the game is also available on itch.io as a "Name your own price" download in case you want to support or tip the developer.&lt;/p&gt;
    &lt;p&gt;Developer: Bungie&lt;lb/&gt;Release Date: December 21, 1994&lt;lb/&gt;Source Code Release Date: January 2000&lt;/p&gt;
    &lt;p&gt;The year is 1994. The world can't get enough of DOOM. Everyone that is except for you because you own an Apple Macintosh and DOOM is a PC game. You comfort yourself with your superior port of Wolfenstein 3-D but it's just not the same.&lt;lb/&gt;Bungie Software Products Corporation to the rescue! Marathon was released as the Mac's answer to DOOM, and a game which was its opposite, as it was not on the PC. Bungie would go on to make a trilogy of games in the Marathon universe before starting work on the Mac-exclusive Halo&lt;lb/&gt;Of course what really happened is Microsoft bought Bungie and Halo became an Xbox exclusive. Halo and Marathon may not share a universe, but Bungie put Marathon references in all of their Halo titles, including embedding the Marathon logo in the original Halo box art.&lt;lb/&gt;Bungie released all three Marathon titles as freeware in 2005 so the downloads from the Aleph One project include the entire game. No need to dig out your old discs here.&lt;/p&gt;
    &lt;p&gt;Developer: Bungie&lt;lb/&gt;Release Date: November 24, 1995&lt;lb/&gt;Source Code Release Date: January 2000&lt;/p&gt;
    &lt;p&gt;Marathon 2, released a year after the original, was also released for Windows 95. The game featured engine improvements and a plot that took place 17 years after the original. The graphics for this release have been upgraded from the release on XBLA.&lt;lb/&gt;Bungie released all three Marathon titles as freeware in 2005 so the downloads from the Aleph One project include the entire game. No need to dig out your old discs here.&lt;/p&gt;
    &lt;p&gt;Developer: Tom Kidd / Mac Source Ports&lt;lb/&gt;Release Date: February 23, 2022&lt;/p&gt;
    &lt;p&gt;Extractor is an app from Mac Source Ports that extracts files from GOG Windows-based installers. Think of it as a GUI version of innoextract.&lt;lb/&gt;Right now, Extractor does exactly two things: lists the files in an installer, and extracts the files from an installer. We hope to expand it in the future but for now it's a simple application.&lt;/p&gt;
    &lt;p&gt;Developer: Hard Light Productions&lt;lb/&gt;Release Date: February 11, 2024&lt;/p&gt;
    &lt;p&gt;Knossos.NET is a utility that aids in downloading and configuring the FreeSpace 2 Open Source Project, aids in configuring the content from a GOG installer or other location, and can even help with mod management and multiplayer support. Check it out if you want to play FreeSpace 2 with as little hassle as possible.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.macsourceports.com/"/><published>2025-10-15T13:07:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591902</id><title>M5 MacBook Pro</title><updated>2025-10-15T14:42:34.230848+00:00</updated><content>&lt;doc fingerprint="bdcaf12d1526c1d3"&gt;
  &lt;main&gt;&lt;p&gt;M5 brings next-generation speed and powerful on-device AI to college students, business users, and aspiring creators.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Available in 14”&lt;/item&gt;&lt;item&gt;Up to 6x faster &lt;lb/&gt;than M16&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Sizes. The 14-inch model is available with the M5, M4 Pro, or M4 Max chip. The 16‑inch model is available with the M4 Pro or M4 Max chip.&lt;/p&gt;&lt;p&gt;Colors. Available in two stunning finishes. MacBook Pro shown in Space Black.&lt;/p&gt;&lt;p&gt;Display. The brilliant Liquid Retina XDR display delivers up to 1,600 nits peak HDR brightness and a 1,000,000:1 contrast ratio for stunning visuals with true blacks and bright highlights.&lt;/p&gt;&lt;p&gt;Connectivity. Every MacBook Pro comes with three Thunderbolt 4 or 5 ports, an HDMI port, a MagSafe 3 port, an SDXC card slot, and a headphone jack. Connect high-speed peripherals and drive multiple external displays.11&lt;/p&gt;&lt;p&gt;Camera. The 12MP Center Stage camera keeps you in frame as you move around. And Desk View lets you share your workspace.&lt;/p&gt;&lt;p&gt;Mics and speakers. With a studio-quality three-mic array and a six-speaker sound system that supports Spatial Audio and Dolby Atmos, MacBook Pro brings incredible audio to any space.&lt;/p&gt;&lt;p&gt;Durability. Made with 100 percent recycled aluminum in the enclosure, MacBook Pro is exceptionally well built and designed to last.&lt;/p&gt;&lt;p&gt;Happily ever faster.&lt;/p&gt;&lt;p&gt;The M5 chip joins M4 Pro and M4 Max to create the most advanced series of chips ever built for a pro laptop. Each chip delivers phenomenal single- and multithreaded CPU performance and faster unified memory — giving you the kind of speed you’ve never thought possible. And with powerful Neural Accelerators in the M5 chip, you can fly through AI tasks at mind-bending speeds.&lt;/p&gt;&lt;p&gt;Up to 6x faster AI performance than M16&lt;/p&gt;&lt;p&gt;A powerful Neural Accelerator is built into each GPU core of the M5 chip, which dramatically speeds up AI tasks like image generation from diffusion models and large language model (LLM) prompt processing. The 16-core Neural Engine drives Apple Intelligence features, making on-device AI powerful and energy efficient.&lt;/p&gt;&lt;p&gt;Run graphics-intensive workflows with responsiveness that keeps up with your imagination. M5 features a GPU with enhanced shader cores and a third-generation ray tracing engine, so gaming feels more immersive and realistic. And Dynamic Caching optimizes on-chip memory to significantly increase GPU utilization — driving huge performance boosts for pro apps and games.&lt;/p&gt;&lt;p&gt;M5 brings next-generation speed and powerful on-device AI to college students, business users, and aspiring creators.&lt;/p&gt;&lt;p&gt;M4 Pro delivers even more power for scientists, engineers, software developers, and creative pros tackling intensive projects.&lt;/p&gt;&lt;p&gt;Our most advanced chip ever built for a pro laptop. M4 Max is perfect for 3D VFX artists, AI developers, and film composers.&lt;/p&gt;&lt;p&gt;The 14‑inch MacBook Pro with M5 brings serious speed and advanced on-device AI to the personal, professional, and creative work you do every day. Effortlessly multitask across apps like Asana and Keynote. Breeze through memory-intensive projects such as editing high-resolution photos and videos. M5 also powers AI features that boost your productivity — whether you want to summarize pages of lecture notes or create AI assistants that automate daily workflows for your business.&lt;/p&gt;&lt;p&gt;Faster time to first token performance6&lt;/p&gt;&lt;p&gt;Faster AI video enhancing performance in Topaz Video14&lt;/p&gt;&lt;p&gt;Faster render performance with ray tracing in Blender15&lt;/p&gt;&lt;p&gt;Faster AI speech enhancement in Adobe Premiere Pro16&lt;/p&gt;&lt;p&gt;Faster gaming performance in Cyberpunk 2077: Ultimate17&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode18&lt;/p&gt;&lt;p&gt;For those who need more power, M4 Pro speeds up everything from database design and data modeling to DNA sequencing. Whether you choose the 14- or 16‑inch model, MacBook Pro with M4 Pro handles demanding workflows with ease and delivers graphics performance that makes 3D rendering and animation faster.&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift19&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI20&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW21&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within22&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB23&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode24&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop25&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift26&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI27&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW28&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within29&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB30&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode31&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop32&lt;/p&gt;&lt;p&gt;Available on the 14- and 16‑inch MacBook Pro, the M4 Max chip is designed for the most extreme workflows. Interact with large language models with hundreds of billions of parameters. Rip through intensive creative workloads, like detailed visual effects, 3D animation, film scoring, and 8K video editing. M4 Max redefines what a laptop can do.&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift33&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI34&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW35&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within36&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB37&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode38&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop39&lt;/p&gt;&lt;p&gt;Faster render performance in Redshift40&lt;/p&gt;&lt;p&gt;Faster video retiming performance in Topaz Video AI41&lt;/p&gt;&lt;p&gt;Faster basecalling performance in Oxford Nanopore MinKNOW42&lt;/p&gt;&lt;p&gt;Faster gaming performance in World of Warcraft: The War Within43&lt;/p&gt;&lt;p&gt;Faster simulation of dynamical systems in MATLAB44&lt;/p&gt;&lt;p&gt;Faster project build performance in Xcode45&lt;/p&gt;&lt;p&gt;Faster Neural Filter and function performance in Adobe Photoshop46&lt;/p&gt;&lt;p&gt;Built for AI. From the silicon up.&lt;/p&gt;&lt;p&gt;Apple silicon, and every major subsystem that powers it, is designed for AI — creating a platform that comprehensively unites hardware, software, and ecosystem. So you can run demanding on-device AI workloads with incredible power efficiency. Always knowing that security and privacy are designed in, not just bolted on.&lt;/p&gt;&lt;p&gt;Mac is optimized to handle the world’s most advanced AI apps. Run image generation apps like DiffusionBee, LLM apps like Msty AI and LM Studio, and video enhancement apps like Topaz Video.&lt;/p&gt;&lt;p&gt;Transform vocals with AI plug-ins like MicDrop for Logic Pro. And make complex image modifications in seconds with Generative Fill in Adobe Photoshop.&lt;/p&gt;&lt;p&gt;Apple Intelligence helps you write, express yourself, and get things done effortlessly. Turn a quick note into a polished announcement. Remove distractions from photos with Clean Up. Create unique images with new ChatGPT styles in Image Playground. And use intelligent actions in the Shortcuts app to create automations — like comparing an audio transcription to typed notes and extracting information from a PDF. Apple Intelligence is AI — for you and I.47&lt;/p&gt;&lt;p&gt;Apple Intelligence is designed to protect your privacy at every step. It’s integrated into the core of your Mac through on-device processing. So it’s aware of your personal information without collecting your personal information. And with groundbreaking Private Cloud Compute, Apple Intelligence can draw on larger server-based models, running on Apple silicon, to handle more complex requests for you while protecting your privacy.&lt;/p&gt;&lt;p&gt;All-day battery life. &lt;lb/&gt;Think outside the outlet. &lt;/p&gt;&lt;p&gt;MacBook Pro has the longest battery life ever in a Mac — up to 24 hours — and supports fast charge, allowing it to charge up to 50 percent in just 30 minutes.48 All models provide the same performance whether they’re plugged in or not, so you can spend more time thinking about an outlet for your passion, not your laptop.&lt;/p&gt;&lt;p&gt;macOS Tahoe introduces Liquid Glass, a refined yet familiar look. With new ways to boost your productivity, work seamlessly with iPhone, and get even more from Apple Intelligence, it’s the most beautiful and powerful version of macOS yet.&lt;/p&gt;Learn more about macOS Tahoe&lt;p&gt;Even better together.&lt;/p&gt;&lt;p&gt;Mac and iPhone are incredible on their own. But when you use them together, they work wonders. Thanks to Continuity, you can move seamlessly across devices to share files and photos, hand off tasks, and even control your iPhone from your Mac.&lt;/p&gt;&lt;p&gt;Mail, Uber Eats&lt;/p&gt;&lt;p&gt;Uber Eats&lt;/p&gt;&lt;p&gt;Notes, Microsoft PowerPoint&lt;/p&gt;&lt;p&gt;Phone app&lt;/p&gt;&lt;p&gt;Your ambitions. There’s an app for that.&lt;/p&gt;&lt;p&gt;Tens of thousands of apps are optimized for Apple silicon — from your go-to productivity apps to your favorite games and hardest-working pro apps. With MacBook Pro, they all soar.&lt;/p&gt;&lt;p&gt;Adobe Lightroom&lt;/p&gt;&lt;p&gt;Xcode&lt;/p&gt;&lt;p&gt;MATLAB&lt;/p&gt;&lt;p&gt;Keynote&lt;/p&gt;&lt;p&gt;Adobe InDesign&lt;/p&gt;&lt;p&gt;Blender&lt;/p&gt;&lt;p&gt;Logic Pro&lt;/p&gt;&lt;p&gt;DaVinci Resolve Studio&lt;/p&gt;&lt;p&gt;Cyberpunk 2077: Ultimate&lt;/p&gt;&lt;p&gt;Let there be delight.&lt;/p&gt;&lt;p&gt;Up to 1,600 nits peak HDR brightness&lt;/p&gt;&lt;p&gt;1,000 nits sustained HDR brightness&lt;/p&gt;&lt;p&gt;1,000,000:1 contrast ratio&lt;/p&gt;&lt;p&gt;Down to 1 nit brightness in dark environments&lt;/p&gt;&lt;p&gt;Up to 1,000 nits SDR brightness outdoors&lt;/p&gt;&lt;p&gt;1,000,000,000 colors&lt;/p&gt;&lt;p&gt;Go from the sunniest terrace to the darkest studio with more ease than ever. The eye-popping Liquid Retina XDR display offers up to 1,600 nits peak HDR brightness. And it provides up to 1,000 nits of brightness for SDR content in bright light so you can see what’s on your screen more clearly outside. In low-light situations, it dims to 1 nit so you can work comfortably in darker spaces.&lt;/p&gt;&lt;p&gt;The ultimate show and tell.&lt;/p&gt;&lt;p&gt;The 12MP Center Stage camera helps you look sharp in any light. Together with the advanced mics and speakers, it lets you take charge of the meeting from afar.&lt;/p&gt;&lt;p&gt;No compromises.&lt;/p&gt;&lt;p&gt;Security starts with Apple silicon and extends to the macOS architecture. This deep integration of hardware and software along with automatic software updates helps keep MacBook Pro stable and protected for the long term. The security architecture also powers features such as Touch ID, Find My, and advanced defenses that protect against viruses and malware.&lt;/p&gt;&lt;p&gt;Unlock your Mac, sign in to apps, and make secure payments with your fingertip. The Secure Enclave keeps your fingerprint data safe.&lt;/p&gt;&lt;p&gt;Locate your misplaced MacBook Pro and remotely lock or erase it if needed.&lt;/p&gt;&lt;p&gt;Encrypt and protect your files and data without having to think about it.&lt;/p&gt;&lt;p&gt;Don’t know which model you have?&lt;/p&gt;&lt;p&gt;Click the Apple logo in the upper left of your screen and choose About This Mac.&lt;/p&gt;&lt;p&gt;Here’s what you get with the new 14‑inch MacBook Pro with M5.&lt;/p&gt;&lt;p&gt;Fly through demanding AI tasks up to 86x faster.1&lt;/p&gt;&lt;p&gt;A stunning Liquid Retina XDR display.&lt;/p&gt;&lt;p&gt;Built for&lt;lb/&gt;Apple Intelligence.&lt;/p&gt;&lt;p&gt;Here’s what you get with the 16‑inch MacBook Pro with M4 Max.&lt;/p&gt;&lt;p&gt;Fly through demanding tasks up to 7.8x faster.4&lt;/p&gt;&lt;p&gt;A stunning Liquid Retina XDR display.&lt;/p&gt;&lt;p&gt;Built for&lt;lb/&gt;Apple Intelligence.&lt;/p&gt;&lt;p&gt;Here’s what you get with the new 14‑inch MacBook Pro with M5.&lt;/p&gt;&lt;p&gt;Fly through demanding AI tasks up to 6x faster.6&lt;/p&gt;&lt;p&gt;More ports and faster charging.&lt;/p&gt;&lt;p&gt;More detailed graphics and gaming with hardware-accelerated ray tracing.&lt;/p&gt;&lt;p&gt;A stunning Liquid Retina XDR display.&lt;/p&gt;&lt;p&gt;Here’s what you get with the 16‑inch MacBook Pro with M4 Max.&lt;/p&gt;&lt;p&gt;Fly through demanding tasks up to 3.5x faster.7&lt;/p&gt;&lt;p&gt;More detailed graphics and gaming with hardware-accelerated ray tracing.&lt;/p&gt;&lt;p&gt;A faster Neural Engine to get more done with AI-powered features.&lt;/p&gt;&lt;p&gt;A display with more consistent brightness in any light.&lt;/p&gt;&lt;p&gt;Get credit toward a new MacBook Pro when you trade in an eligible device.8&lt;/p&gt;See what your device is worth&lt;p&gt;Pay over time, interest‑free.&lt;/p&gt;&lt;p&gt;When you choose to check out at Apple with Apple Card Monthly Installments.◊&lt;/p&gt;&lt;p&gt;Pay for your new Mac over time, interest-free with Apple Card.◊ Simply choose to check out at Apple with Apple Card Monthly Installments as your payment option when you make your purchase. And enjoy 3% Daily Cash back, all up front. Terms apply.&lt;/p&gt;Learn more, Apple Card Monthly Installments&lt;p&gt;Save with Apple Trade In.&lt;/p&gt;&lt;p&gt;Get credit toward your next Mac when you trade in an eligible device.8&lt;/p&gt;&lt;p&gt;Just add a trade-in when you choose a new product. Once your eligible device has been received and verified, we’ll credit the value to your payment method. Or choose to check out with Apple Card Monthly Installments and we’ll apply the credit instantly. Terms apply.&lt;/p&gt;Learn more, Apple Trade In&lt;p&gt;Save with education pricing.&lt;/p&gt;&lt;p&gt;Students and educators can save exclusively through the Apple Store.**&lt;/p&gt;&lt;p&gt;Students and educators can save on MacBook Pro with education pricing.&lt;/p&gt;Learn more, Education Pricing&lt;p&gt;Join an online Personal Setup session.&lt;/p&gt;&lt;p&gt;Talk one on one with a Specialist to set up your Mac and discover new features.&lt;/p&gt;&lt;p&gt;When you buy your new Mac directly from Apple, you’ll get access to Personal Setup. In these online sessions, a Specialist can guide you through setup and data transfer or focus on features that help you make the most of your Mac. Best of all, you can join whenever works for you, from wherever you are.&lt;/p&gt;Learn more, Personal Setup&lt;p&gt;Customize your Mac.&lt;/p&gt;&lt;p&gt;Choose your chip, memory, storage, even color.&lt;/p&gt;&lt;p&gt;Build the Mac that’s best for you. When you buy online at Apple, you can customize your Mac just the way you want. Whether you need an extra-powerful chip, more memory, or additional storage, you can tailor any new Mac to suit your needs.&lt;/p&gt;Shop Mac&lt;p&gt;Get flexible delivery and easy pickup.&lt;/p&gt;&lt;p&gt;Choose two‑hour delivery from an Apple Store, free delivery, or easy pickup options.&lt;/p&gt;&lt;p&gt;Get your new Apple products quickly and easily with two‑hour delivery from an Apple Store, free next‑day delivery, or convenient Apple pickup options.&lt;/p&gt;Learn more, delivery and pickup options&lt;p&gt;Shop live with a Specialist.&lt;/p&gt;&lt;p&gt;Let us guide you live over video and answer all of your questions.&lt;/p&gt;&lt;p&gt;We can help you choose the product you need while guiding you through the online Apple Store. You won’t appear on camera. Available 7 a.m.–7 p.m. PT.&lt;/p&gt;Shop together with a Specialist&lt;p&gt;Explore a shopping experience designed around you.&lt;/p&gt;&lt;p&gt;Use the Apple Store app to get a more personal way to shop.&lt;/p&gt;&lt;p&gt;Get personalized product recommendations, compare models, access Your Saves, and track your orders. Opt in today to get updates on new products, promotions, flexible payment options, and store events.&lt;/p&gt;&lt;p&gt;Scan the QR code to get started.&lt;/p&gt;&lt;p&gt;Strikingly thin and fast so you can work, play, or create anywhere.&lt;/p&gt;&lt;p&gt;The most advanced Mac laptops for demanding workflows.&lt;/p&gt;&lt;p&gt;Our approach.&lt;/p&gt;&lt;p&gt;Using recycled materials, like 100% recycled aluminum in the enclosure, reduces the need to mine new material, which avoids the carbon emissions and environmental impacts of mining.&lt;/p&gt;Learn more in our 14-inch MacBook Pro M5 Product Environmental Report (PDF) Learn more in our 14-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF) Learn more in our 16-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF)&lt;p&gt;How you can help.&lt;/p&gt;&lt;p&gt;You can protect the earth’s precious resources by trading in, passing down, or recycling devices and accessories you no longer use. You can bring them into any Apple Store for free, secure recycling. We also offer other ways to recycle, including mail-in options.&lt;/p&gt;Learn how to trade in or recycle devices&lt;p&gt;Our approach.&lt;/p&gt;&lt;p&gt;Using electricity from renewable sources like wind and solar across our global supply chain — instead of fossil fuels — significantly reduces carbon emissions from manufacturing Apple products.&lt;/p&gt;Learn more in our 14-inch MacBook Pro M5 Product Environmental Report (PDF) Learn more in our 14-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF) Learn more in our 16-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF)&lt;p&gt;How you can help.&lt;/p&gt;&lt;p&gt;You can extend the lifespan of your batteries and Apple products by using Optimized Battery Charging. It works by learning your charging habits and delaying the final charge — from 80% to 100% — until you are likely to need it.&lt;/p&gt;Learn more about Optimized Battery Charging&lt;p&gt;Our approach.&lt;/p&gt;&lt;p&gt;MacBook Pro comes in paper packaging that is 100% fiber-based, as part of our commitment to remove plastic from the packaging of all Apple products.&lt;/p&gt;Learn more in our 14-inch MacBook Pro M5 Product Environmental Report (PDF) Learn more in our 14-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF) Learn more in our 16-inch MacBook Pro M4 Pro and M4 Max Product Environmental Report (PDF)&lt;p&gt;How you can help.&lt;/p&gt;&lt;p&gt;New Apple products come in paper packaging that’s 100% fiber-based. In most places, you can put the entire box into your household recycling bin. You can also bring Apple packaging to any Apple Store and we’ll recycle it for free.&lt;/p&gt;Learn more about recycling&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/macbook-pro/"/><published>2025-10-15T13:10:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45591905</id><title>iPad Pro with M5 chip</title><updated>2025-10-15T14:42:33.924608+00:00</updated><content>&lt;doc fingerprint="bddbbebdc82a4ddc"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 15, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple introduces the powerful new iPad Pro with the M5 chip&lt;/head&gt;
    &lt;p&gt; The new iPad Pro features the next generation of Apple silicon, with a big leap in AI performance, faster storage, and the game-changing capabilities of iPadOS 26 &lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today introduced the new iPad Pro featuring the incredibly powerful M5 chip. M5 unlocks the most advanced iPad experience ever, packing an incredible amount of power and AI performance into the ultraportable design of iPad Pro. Featuring a next-generation GPU with a Neural Accelerator in each core, M5 delivers a big boost in performance for iPad Pro users, whether they’re working on cutting-edge projects or tapping into AI for productivity. The new iPad Pro delivers up to 3.5x the AI performance than iPad Pro with M41 and up to 5.6x faster than iPad Pro with M1.2 N1, the new Apple-designed wireless networking chip, enables the latest generation of wireless technologies with support for Wi-Fi 7 on iPad Pro. The C1X modem comes to cellular models of iPad Pro, delivering up to 50 percent faster cellular data performance than its predecessor with even greater efficiency, allowing users to do more on the go. Available in space black and silver, iPad Pro comes in 11-inch and 13-inch sizes, and features the Ultra Retina XDR display for an unparalleled viewing experience. The game-changing features of iPadOS 26 supercharge iPad Pro and help users handle demanding creative and professional tasks with ease. With staggering performance gains and breakthrough improvements over M1 models, there has never been a better time to upgrade. The new iPad Pro is available to pre-order starting today, and will be available in stores beginning Wednesday, October 22. &lt;/p&gt;
    &lt;p&gt;“Powered by the next generation of Apple silicon, the new iPad Pro delivers our most advanced and versatile iPad experience yet,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “iPad Pro with M5 unlocks endless possibilities for creativity and productivity — with a huge leap in AI performance and a big boost in graphics, superfast wireless connectivity, and game-changing iPadOS 26 features, it pushes the boundaries of what iPad can do yet again.” &lt;/p&gt;
    &lt;head rend="h2"&gt;M5: The Next Big Leap in AI for iPad&lt;/head&gt;
    &lt;p&gt;Apple silicon continues to set iPad apart with industry-leading performance, advanced technologies, power efficiency, and AI capabilities. With the M5 chip powering iPad Pro, AI on iPad takes its next big leap, with a more advanced GPU and CPU, and a faster Neural Engine. The 10-core GPU introduces a new architecture with a Neural Accelerator in each core, resulting in a massive boost in GPU performance for AI workloads. M5 delivers AI performance that’s up to 3.5x faster compared to M4,1 and up to 5.6x faster than iPad Pro with M1.2 The new iPad Pro is designed for AI and accelerates a wide variety of workloads, such as on-device diffusion-based image generation in apps like Draw Things, and AI video masking in apps like DaVinci Resolve. And the faster 16-core Neural Engine delivers the most energy-efficient performance for on-device AI, perfect for apps that use the Foundation Models framework and for Apple Intelligence features like creating in Image Playground.3 &lt;/p&gt;
    &lt;head rend="h2"&gt;Next-Level Performance with M5&lt;/head&gt;
    &lt;p&gt;The M5 chip brings next-level performance, with a significant boost to graphics performance and a faster CPU. Incorporating a third-generation ray-tracing engine enabling more realistic lighting, reflections, and shadows — M5 is ideal for visually intensive applications and gaming — iPad Pro has up to 1.5x faster 3D rendering with ray tracing than the previous-generation iPad Pro,1 and up to a whopping 6.7x faster rendering performance than iPad Pro with M1.2 M5 has up to a 10-core CPU, with four performance cores and six efficiency cores, and is the world’s fastest CPU core. The faster CPU is perfect for a range of users, including graphic designers working with complex vector graphics in apps like Adobe Illustrator, architects who routinely multitask across apps like SketchUp and Morpholio Trace, and business users who need to quickly launch and access large files across multiple apps. &lt;/p&gt;
    &lt;p&gt;iPad Pro with M5 delivers: &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 6.7x faster 3D rendering with ray tracing in Octane X when compared to iPad Pro with M1,2 and up to 1.5x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 6x faster video transcode performance in Final Cut Pro for iPad when compared to iPad Pro with M1,2 and up to 1.2x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 4x faster AI image generation performance in Draw Things for iPad when compared to iPad Pro with M1,2 and up to 2x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 3.7x faster AI video upscaling performance in DaVinci Resolve for iPad when compared to iPad Pro with M1,2 and up to 2.3x faster than iPad Pro with M4.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Faster Memory Bandwidth and Storage for More Seamless Multitasking&lt;/head&gt;
    &lt;p&gt;iPad Pro brings new enhancements to accelerate overall speed and responsiveness, including an increase in unified memory bandwidth, faster storage read and write speeds, more starting unified memory, and fast charge support. With over 150GB/s of unified memory bandwidth — a nearly 30 percent increase compared to the previous generation — the new iPad Pro helps users multitask across more apps, process AI models faster, play demanding games, and more. The new iPad Pro offers up to 2x faster storage read and write speeds, and the 256GB and 512GB models start with 12GB of unified memory — 50 percent more than before, bringing even more value. And with the new windowing system in iPadOS 26, iPad Pro users will experience more seamless multitasking, enhancing even the most complex workflows. Additionally, iPad Pro supports fast charge — enabling up to a 50 percent charge in around 30 minutes4 with an optional high-wattage USB-C power adapter like Apple’s new 40W Dynamic Power Adapter with 60W Max.5 &lt;/p&gt;
    &lt;head rend="h2"&gt;The C1X and N1 Chips Come to iPad&lt;/head&gt;
    &lt;p&gt;Cellular models of iPad Pro feature C1X, a cellular modem designed by Apple that brings users up to 50 percent faster cellular data performance, and for active cellular users, up to 30 percent less power usage than iPad Pro with M4. Cellular models of iPad Pro allow users to enjoy GPS and location capabilities, so they can navigate with even more confidence. Users can also enjoy 5G cellular support, so they can stay connected for work or leisure all around the world. And with eSIM, users can quickly and securely add a new plan, connect and transfer existing cellular plans digitally, and stay in touch with family and friends regardless of Wi-Fi availability — perfect for users working on the go, like frequent business travelers or architects out in the field. &lt;/p&gt;
    &lt;p&gt;The new iPad Pro also features N1, a new Apple-designed wireless networking chip that enables Wi-Fi 7, Bluetooth 6, and Thread. N1 brings better performance when connected to 5GHz networks, and improves the overall performance and reliability of features like Personal Hotspot and AirDrop. &lt;/p&gt;
    &lt;head rend="h2"&gt;An Unrivaled Design and Display&lt;/head&gt;
    &lt;p&gt;iPad Pro offers users the ultimate level of portability in a stunningly thin and light design. Available in space black and silver, the 11-inch model is just 5.3 mm thin, and the 13-inch model is even thinner at a striking 5.1 mm. The Ultra Retina XDR display — the world’s most advanced display — features groundbreaking tandem OLED technology that delivers extreme brightness, incredibly precise contrast, and technologies like ProMotion and True Tone. iPad Pro supports 1000 nits of full-screen brightness for SDR and HDR content, and 1600 nits peak brightness for HDR. And for users who work with high-end, color-managed workflows or in challenging lighting conditions, iPad Pro offers a nano-texture display glass option for reduced glare that is precisely etched at a nanometer scale, maintaining image quality and contrast while scattering ambient light. &lt;/p&gt;
    &lt;p&gt;The new iPad Pro adds the ability to drive external displays at up to 120Hz — ideal for creative workflows like video editing as well as gaming. And for users with a 120Hz external display, iPad Pro also brings new support for Adaptive Sync, which provides the lowest possible latency in external display performance, resulting in smoother motion and fewer perceived glitches, useful for low-latency use cases like gaming. &lt;/p&gt;
    &lt;head rend="h2"&gt;iPadOS 26 Supercharges the iPad Experience&lt;/head&gt;
    &lt;p&gt;iPadOS 26 introduces a new design and powerful features that help users handle demanding creative and professional tasks with ease, and push the capabilities and versatility of iPad even further. &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The beautiful new design is crafted with Liquid Glass, a translucent new material that reflects and refracts its surroundings, while reacting to users’ input and dynamically transforming to bring greater focus to the content they care about most.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An entirely new, powerful, and intuitive windowing system helps users control, organize, and switch between apps, all while maintaining the simplicity of iPad. And with a new menu bar, users can access the commands available in an app with a simple swipe down from the top of the display, or by moving their cursor to the top.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;iPadOS 26 introduces new ways to manage, access, and organize files with a supercharged Files app featuring an updated List view and new folder customization options. With folders in the Dock, users can conveniently access downloads, documents, and more from anywhere. Additionally, users can set a default app for opening specific files or file types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Preview app comes to iPad, giving users a dedicated app to view and edit PDFs, with powerful features like Apple Pencil Markup and AutoFill built in.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Taking advantage of Apple silicon, iPadOS 26 unlocks new capabilities for creative pros with Background Tasks, more control over their audio input, and the ability to capture high-quality recordings with local capture.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Intelligence delivers helpful and relevant intelligence that is deeply integrated across operating systems, while taking an extraordinary step forward for privacy in AI.6 New features across iPadOS 26 include Live Translation in Phone, FaceTime, and Messages;7 new intelligent actions in Shortcuts; the ability to identify and automatically categorize relevant actions in Reminders; and more.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Advanced Accessories for iPad Pro&lt;/head&gt;
    &lt;p&gt;Accessories extend the versatility of iPad Pro, opening up even more possibilities for creativity and productivity. Apple Pencil Pro and Apple Pencil (USB-C) offer users two incredible options for illustrating, note-taking, annotating, and more. The thin and light Magic Keyboard for iPad Pro provides the most advanced experience with a floating design, function row, and gorgeous aluminum palm rest. iPad Pro is also compatible with the Smart Folio for iPad Pro, which attaches magnetically and supports multiple viewing angles. &lt;/p&gt;
    &lt;head rend="h2"&gt;iPad Pro and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The new iPad Pro is made with 30 percent recycled content by weight, including 100 percent recycled aluminum in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled cobalt in the battery. It is manufactured with 55 percent renewable electricity, like wind and solar, across the supply chain. iPad Pro is also designed to last and offers industry-leading software support while meeting Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled. &lt;/p&gt;
    &lt;p&gt;Pricing and Availability &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers can pre-order iPad Pro with M5 starting today on apple.com/store, and in the Apple Store app in 31 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, starting Wednesday, October 22.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 11-inch and 13-inch iPad Pro with M5 will be available in silver and space black finishes in 256GB, 512GB, 1TB, and 2TB configurations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 11-inch iPad Pro starts at $999 (U.S.) for the Wi-Fi model, and $1,199 (U.S.) for the Wi-Fi + Cellular model. The 13-inch iPad Pro starts at $1,299 (U.S.) for the Wi-Fi model, and $1,499 (U.S.) for the Wi-Fi + Cellular model. Additional technical specifications, including nano-texture glass options, are available at apple.com/store.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;With education savings, the 11-inch iPad Pro starts at $899 (U.S.), and the 13-inch iPad Pro starts at $1,199 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Pencil Pro and Apple Pencil (USB-C) are compatible with the new iPad Pro. Apple Pencil Pro is available for $129 (U.S.), and $119 (U.S.) with education savings. Apple Pencil (USB-C) is available for $79 (U.S.), and $69 (U.S.) with education savings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Magic Keyboard for iPad Pro is available in black and white finishes. The 11-inch Magic Keyboard is available for $299 (U.S.), and the new 13-inch Magic Keyboard is available for $349 (U.S.). With education savings, the 11-inch Magic Keyboard is available for $279 (U.S.), and the 13-inch Magic Keyboard is available for $329 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Magic Keyboard for iPad Air with M3 is now available in black, and is compatible with the 11-inch and 13-inch iPad Air. The 11-inch Magic Keyboard is available for $269 (U.S.), and the 13-inch Magic Keyboard is available for $319 (U.S.). With education savings, the 11-inch Magic Keyboard is available for $249 (U.S.), and the 13-inch Magic Keyboard is available for $299 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Apple-designed 40W Dynamic Power Adapter with 60W Max is available for $39 (U.S.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new iPad, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit apple.com/applecare.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple offers great ways to save on the latest iPad. Customers can trade in their current iPad and get credit toward a new one by visiting the Apple Store online, the Apple Store app, or an Apple Store location. To see what their device is worth, and for terms and conditions, customers can visit apple.com/shop/trade-in.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers in the U.S. who shop at Apple using Apple Card can pay monthly at 0 percent APR when they choose to check out with Apple Card Monthly Installments, and they’ll get 3 percent Daily Cash back — all up front. More information — including details on eligibility, exclusions, and Apple Card terms — is available at apple.com/apple-card/monthly-installments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Images in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Results are compared to iPad Pro 13-inch (M4) units with 10-core CPU and 16GB of unified memory.&lt;/item&gt;
      &lt;item&gt;Results are compared to iPad Pro 12.9-inch (5th generation) units with 8-core CPU and 16GB of unified memory.&lt;/item&gt;
      &lt;item&gt;Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.&lt;/item&gt;
      &lt;item&gt;Testing was conducted by Apple in August and September 2025. See apple.com/ipad-pro for more information.&lt;/item&gt;
      &lt;item&gt;The 40W Dynamic Power Adapter with 60W Max is available in Canada, China mainland, Japan, Mexico, Taiwan, the Philippines, and the U.S.&lt;/item&gt;
      &lt;item&gt;Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
      &lt;item&gt;Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified). Live Translation in Phone and FaceTime is available for one-on-one calls in English (UK, U.S.), French (France), German (Germany), Portuguese (Brazil), and Spanish (Spain) when Apple Intelligence is enabled, on a compatible iPhone, iPad, or Mac. Later this year, Live Translation in Phone and FaceTime will add language support for Chinese (Mandarin, simplified), Chinese (Mandarin, traditional), Italian, Japanese, and Korean. Some features may not be available in all regions or languages.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/"/><published>2025-10-15T13:10:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45592401</id><title>Pwning the Entire Nix Ecosystem</title><updated>2025-10-15T14:42:33.774358+00:00</updated><content>&lt;doc fingerprint="4f2c49954c2797ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Pwning the Entire Nix Ecosystem&lt;/head&gt;
    &lt;p&gt;last year at nixcon, me and my friend lexi gave a lightning talk about how we found a vulnerability in nixpkgs that would have allowed us to pwn pretty much the entire nix ecosystem and inject malicious code into nixpkgs. it only took us about a day from starting our search to reporting it and getting it fixed. since i unfortunately was too sick to attend this years nixcon, i thought it might be a good time to write up what we found and how we did it.&lt;/p&gt;
    &lt;head rend="h2"&gt;github actions: the easy target #&lt;/head&gt;
    &lt;p&gt;github actions is a ci/cd system by github that can do pretty much anything in a repo. it’s an easy target for attackers because if you have access to a workflow, you can just commit code without authorization and then you have a supply chain attack. plus, it’s all written in yaml 🇳🇴, which was NEVER meant to be executed !!&lt;/p&gt;
    &lt;code&gt;name: learn-github-actions
on: [push]
jobs:
  check-bats-version:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm install -g bats
      - run: bats -v
&lt;/code&gt;
    &lt;p&gt;this is a simple example of a github action. nothing fancy, just running some commands when code is pushed.&lt;/p&gt;
    &lt;head rend="h2"&gt;the dangerous pull_request_target #&lt;/head&gt;
    &lt;p&gt;actions run when a trigger activates them. there are a bunch of different triggers like pushes, commits, or pull requests. but there’s a special one called &lt;code&gt;pull_request_target&lt;/code&gt; that has a few critical differences from regular &lt;code&gt;pull_request&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;crucially, unlike &lt;code&gt;pull_request&lt;/code&gt;, &lt;code&gt;pull_request_target&lt;/code&gt; has read/write and secret access by default, even on pull requests from forks. this isn’t vulnerable by itself, but things go south when you start trusting user input from those PRs.&lt;/p&gt;
    &lt;p&gt;github even warns about this in their docs:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Warning: For workflows that are triggered by the&lt;/p&gt;&lt;code&gt;pull_request_target&lt;/code&gt;event, the&lt;code&gt;GITHUB_TOKEN&lt;/code&gt;is granted read/write repository permission unless the&lt;code&gt;permissions&lt;/code&gt;key is specified and the workflow can access secrets, even when it is triggered from a fork.&lt;/quote&gt;
    &lt;p&gt;so we started looking for workflows in nixpkgs that use &lt;code&gt;pull_request_target&lt;/code&gt; and found 14 files. some of them were secure, like this labeler example:&lt;/p&gt;
    &lt;code&gt;name: "Label PR"
on:
  pull_request_target:
jobs:
  labels:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/labeler@8558fd74291d67161a8a
        with:
          repo-token: $
&lt;/code&gt;
    &lt;p&gt;this is safe because it just passes the token to a trusted action. but then we found some more interesting ones…&lt;/p&gt;
    &lt;head rend="h2"&gt;the editorconfig vulnerability #&lt;/head&gt;
    &lt;p&gt;the first vulnerable workflow we found was for checking editorconfig rules. here’s a simplified version of what it was doing:&lt;/p&gt;
    &lt;code&gt;steps:
  - name: Get list of changed files from PR
    run: gh api [...] | jq [ ... ] &amp;gt; "$HOME/changed_files"
  - uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871
    with:
      ref: refs/pull/$/merge
  - name: Checking EditorConfig
    run: cat "$HOME/changed_files" | xargs -r editorconfig-checker
&lt;/code&gt;
    &lt;p&gt;the workflow would:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;get a list of files changed in the PR&lt;/item&gt;
      &lt;item&gt;checkout the PR code&lt;/item&gt;
      &lt;item&gt;run editorconfig-checker on those files&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;the problem? it was using &lt;code&gt;xargs&lt;/code&gt; to pass the filenames to editorconfig-checker. if you’ve read the man page for xargs, you’ll see this warning:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It is not possible for xargs to be used securely&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;basically, we could create a file with a name that’s actually a command line argument. for example, if we added a file called &lt;code&gt;--help&lt;/code&gt; to our PR, when the workflow ran &lt;code&gt;cat "$HOME/changed_files" | xargs -r editorconfig-checker&lt;/code&gt;, the filename would be passed as an argument to editorconfig-checker, causing it to print its help message instead of checking files.&lt;/p&gt;
    &lt;p&gt;this is a classic command injection vulnerability. we didn’t take it further to try to execute arbitrary code since editorconfig-checker is written in go and we’d need to audit it more deeply, but it’s most likely possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;the code owners vulnerability: local file inclusion #&lt;/head&gt;
    &lt;p&gt;the second vulnerable workflow we found was even more serious. it was checking the CODEOWNERS file in PRs:&lt;/p&gt;
    &lt;code&gt;steps:
  - uses: actions/checkout@eef61447b9ff4aafe5dcd4e0bbf
    with:
      ref: refs/pull/$/merge
      path: pr
  - run: nix-build base/ci -A codeownersValidator
  - run: result/bin/codeowners-validator
    env:
      OWNERS_FILE: pr/ci/OWNERS
&lt;/code&gt;
    &lt;p&gt;the workflow would:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;checkout the PR code&lt;/item&gt;
      &lt;item&gt;build the codeowners validator&lt;/item&gt;
      &lt;item&gt;run the validator on the OWNERS file from the PR&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;the validator would echo the contents of the OWNERS file if there was an error. this meant we could put whatever we wanted in that file and it would get printed in the logs.&lt;/p&gt;
    &lt;p&gt;but it gets worse. since the workflow was checking out our PR code, we could replace the OWNERS file with a symbolic link to ANY file on the runner. like, say, the github actions credentials file:&lt;/p&gt;
    &lt;code&gt;$ rm OWNERS
$ ln -s /home/runner/runners/2.320.0/.credentials OWNERS
&lt;/code&gt;
    &lt;p&gt;when the validator ran, it would try to read our symlinked file and helpfully print out an error message containing the first line:&lt;/p&gt;
    &lt;p&gt;and just like that, we had a github actions token with read/write access to nixpkgs. this would let us push directly to nixpkgs, bypassing all the normal review processes.&lt;/p&gt;
    &lt;head rend="h2"&gt;the fix #&lt;/head&gt;
    &lt;p&gt;after we found these vulnerabilities, we reported them to the nixpkgs maintainers, in this case infinisil, who immediately took action:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;they disabled the vulnerable workflows in the repos action settings&lt;/item&gt;
      &lt;item&gt;they fixed the vulnerabilities by properly separating untrusted data from privileged operations&lt;/item&gt;
      &lt;item&gt;they renamed the fixed workflows after the security fixes, this is because of another pitfall with &lt;code&gt;pull_request_target&lt;/code&gt;allowing you to target any branch the action is on, even if it’s 5 or 10 years old as long as it hasn’t been disabled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;the key lessons from this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;avoid mixing untrusted data and secrets, or be very careful with them&lt;/item&gt;
      &lt;item&gt;only allow the permissions you really need&lt;/item&gt;
      &lt;item&gt;read the docs about permissions very carefully&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;if you think your org has vulnerable github actions, you can use the panic button too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;go to your org at https://github.com/[org]&lt;/item&gt;
      &lt;item&gt;go to the “Settings” tab&lt;/item&gt;
      &lt;item&gt;go to “Actions” → “General” section&lt;/item&gt;
      &lt;item&gt;under “Policies”, switch “All repositories” to “Disable”&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;conclusion #&lt;/head&gt;
    &lt;p&gt;it only took us about a day to find, report, and help fix a vulnerability that could have compromised the entire nix ecosystem. this shows how important it is to be careful with github actions, especially when dealing with &lt;code&gt;pull_request_target&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;big thanks to intrigus and everyone at KITCTF (intrigus gave a talk about exactly these issues that taught us how this works), and thanks to infinisil for fixing this on the same day we reported it.&lt;/p&gt;
    &lt;p&gt;if you want to learn more, check out these resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://kitctf.de/talks/2023-10-26-insecure-github-actions/insecure-github-actions.pdf&lt;/item&gt;
      &lt;item&gt;https://securitylab.github.com/resources/github-actions-preventing-pwn-requests/&lt;/item&gt;
      &lt;item&gt;https://github.com/NixOS/nixpkgs/pull/351446&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;also, if you’re curious, you can watch our original lightning talk from nixcon&lt;/p&gt;
    &lt;p&gt;anyway that’s all. stay safe with your github actions. meow :3&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ptrpa.ws/nixpkgs-actions-abuse"/><published>2025-10-15T13:41:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45592766</id><title>You are the scariest monster in the woods</title><updated>2025-10-15T14:42:33.607185+00:00</updated><content>&lt;doc fingerprint="77131db61f2e28a5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You are the scariest monster in the woods&lt;/head&gt;
    &lt;p&gt;I don’t really believe in the threat of AGI (Artificial General Intelligence—human-level intelligence) partly because I don’t believe in the possibility of AGI and I’m highly skeptical that the current technology underpinning LLMs will provide a route to it. But I also think there’s something we should actually be afraid of long before AGI, if it ever comes.&lt;/p&gt;
    &lt;p&gt;When talking about humans in any context, whether it’s us vs sharks, or us vs wolves, or us vs &amp;lt;insert anything that scares us&amp;gt;, and especially when it’s us vs &amp;lt;some technology&amp;gt;, I am reminded of The Gruffalo. In this children’s story, a timid mouse convinces a scary monster (The Gruffalo) that the mouse is the scariest animal in the woods. In reality though, the forest animals are frightened of the Gruffulo with it’s terrible tusks, and terrible claws, and terrible teeth.&lt;/p&gt;
    &lt;p&gt;We (humans) are the scariest animal in the woods. We’re the scariest animal anywhere. At any time, in any location, under any circumstances, if there’s a human present then that’s the scariest motherfucker in the woods. We’re a danger to every living thing, ourselves included. Our collective ability to survive, adapt, control, kill, or wipe out any other species is unmatched.&lt;/p&gt;
    &lt;p&gt;Anyone trying to tell you otherwise is trying to distract you. AI is not the monster to be afraid of; we are.&lt;/p&gt;
    &lt;p&gt;Just like a hammer, sword, or a rifle lying on a ground is nothing to be feared, so too is AI. It’s just an inanimate object; a tool, potentially. Now, if you equip humans with a hammer, or sword, or rifle, or AI then you’ve just made the scariest monster in the woods (that’s you) even more terrifying.&lt;/p&gt;
    &lt;p&gt;To bring this around to more concrete thoughts: I do not believe that AI will enslave us, destroy our democracies, or our environment, or rob us of our skills, our purpose, or our jobs. That’s what humans will do. What we’ve always tried to do.&lt;/p&gt;
    &lt;p&gt;We don’t need to worry about AI itself, we need to be concerned about what “humans + AI” will do. Humans will do what they’ve always tried to do—gain power, enslave, kill, control, exploit, cheat, or just be lazy and avoid the hard work—but now with new abilities that we couldn’t have dreamed of.&lt;/p&gt;
    &lt;p&gt;I’m not saying “don’t worry”. I’m saying don’t worry about the technology of AI and continue to recognise that humans, and how they will use a technology, has always been our biggest threat.&lt;/p&gt;
    &lt;p&gt;The means accepting that AI isn’t something passively happening to us. It’s not a meteor heading towards Earth that we play no part in it or have no control over. It’s a thing we’re building, for other humans to use. We’re not building AI for gerbils here. How would we like other humans to use AI? How would we not like them to use it? We’re building and using this technology but pretending that unlike cars, and guns, and knives, and nuclear weapons, that we are powerless to understand, control, or regulate it for the betterment of humanity.&lt;/p&gt;
    &lt;p&gt;The scariest monster in the woods just got scarier and we can’t ignore that.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jamie.ideasasylum.com/2025/10/15/you-are-the-scariest-monster-in-the-woods"/><published>2025-10-15T14:04:13+00:00</published></entry></feed>