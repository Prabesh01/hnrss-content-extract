<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-07T09:18:52.242452+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46512203</id><title>Show HN: VaultSandbox ‚Äì Test your real MailGun/SES/etc. integration</title><updated>2026-01-07T09:19:07.623842+00:00</updated><content>&lt;doc fingerprint="6e91e8132f17f9fc"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Production-Like Email Testing Without Mocks&lt;/head&gt;&lt;p&gt;Keep your provider and your config. Just swap the recipient to validate real TLS, DNS, and SPF/DKIM entirely inside your VPC.&lt;/p&gt;&lt;p&gt;Works with Postmark, SendGrid, SES, and more.&lt;/p&gt;&lt;head rend="h2"&gt;Get Started in 5 Minutes&lt;/head&gt;&lt;p&gt;Deploy VaultSandbox with a single Docker Compose file. Auto-provisions TLS and DNS.&lt;/p&gt;&lt;code&gt;# docker-compose.yml
services:
  vaultsandbox:
    image: vaultsandbox/gateway:latest
    ports: ["25:25", "80:80", "443:443"]
    environment:
      VSB_VSX_DNS_ENABLED: 'true' # Auto-provisions TLS &amp;amp; Domain
    volumes:
      - vsb_data:/app/data        # Persists API Key &amp;amp; Certs

volumes:
  vsb_data:&lt;/code&gt;&lt;head rend="h2"&gt;Mocks hide the exact email failures that break production&lt;/head&gt;&lt;p&gt;You mock the email client to get a green build. But in production, you use real SMTP, real TLS, and real DNS. This disconnect creates a dangerous blind spot.&lt;/p&gt;&lt;head rend="h3"&gt;The Dangerous Test Config&lt;/head&gt;&lt;code&gt;ignore_tls: true
rejectUnauthorized: false&lt;/code&gt;&lt;head rend="h3"&gt;The "Works on My Machine" Shortcuts:&lt;/head&gt;&lt;head rend="h4"&gt;Fake SMTP&lt;/head&gt;&lt;p&gt;No TLS, DNS, or MX records ‚Äî a fantasy environment.&lt;/p&gt;&lt;head rend="h4"&gt;Polling &amp;amp; Sleep Loops&lt;/head&gt;&lt;p&gt; Flaky CI tests relying on &lt;code&gt;sleep(5)&lt;/code&gt; break pipelines.
&lt;/p&gt;&lt;head rend="h4"&gt;Shared Public Inboxes&lt;/head&gt;&lt;p&gt;Risky data leaks on public cloud tools.&lt;/p&gt;&lt;head rend="h3"&gt;The Real-World Failures You Miss&lt;/head&gt;&lt;head rend="h4"&gt;Authentication Rot&lt;/head&gt;&lt;p&gt;SPF, DKIM, and DMARC only break on real domains. Mocks always pass.&lt;/p&gt;&lt;head rend="h4"&gt;TLS Negotiation&lt;/head&gt;&lt;p&gt;SSL/TLS issues surface only in production once you disable checks in dev.&lt;/p&gt;&lt;head rend="h4"&gt;Rendering Bugs&lt;/head&gt;&lt;p&gt;HTML emails render differently in real clients vs. plain text viewers.&lt;/p&gt;&lt;head rend="h2"&gt; Real Domains. Real SMTP. Real TLS.&lt;lb/&gt;Zero Risk to Customer Data. &lt;/head&gt;&lt;p&gt;VaultSandbox provides isolated inboxes that behave exactly like production ‚Äî without exposing a single byte of customer data.&lt;/p&gt;&lt;head rend="h3"&gt;How it works (inside your VPC)&lt;/head&gt;&lt;p&gt;Infrastructure requirements: Public IP, ports 25/80/443 open.&lt;/p&gt;&lt;p&gt;Two DNS Options&lt;/p&gt;&lt;p&gt;Zero-config: Use vsx.email ‚Äî your IP is encoded into a subdomain automatically. No DNS setup required.&lt;/p&gt;&lt;p&gt;Your domain: Point an A record and MX record to the container. Subdomains supported.&lt;/p&gt;&lt;p&gt;Terminates Real SMTP + TLS&lt;/p&gt;&lt;p&gt;ACME certificates for SMTP and HTTPS auto-provisioned.&lt;/p&gt;&lt;p&gt;Full Message Validation&lt;/p&gt;&lt;p&gt;SPF, DKIM, DMARC, and rDNS checks on every message.&lt;/p&gt;&lt;p&gt;True Isolation&lt;/p&gt;&lt;p&gt;Email storage is encrypted in a sandbox; outbound mail is hard-blocked.&lt;/p&gt;&lt;p&gt;Production Fidelity&lt;/p&gt;&lt;p&gt;Test authentication, MX, DNS, MIME, and TLS exactly as they behave in the real world.&lt;/p&gt;&lt;head rend="h3"&gt;What You Gain&lt;/head&gt;&lt;p&gt; Keep &lt;code&gt;secure: true&lt;/code&gt; &lt;/p&gt;&lt;p&gt;No more weakening TLS or SMTP configs just to make tests pass.&lt;/p&gt;&lt;p&gt;Catch Auth Issues Early&lt;/p&gt;&lt;p&gt;Validate domain crypto before deployment.&lt;/p&gt;&lt;p&gt;Data Sovereignty&lt;/p&gt;&lt;p&gt;All data stays in your infrastructure ‚Äî never shared, never leaked.&lt;/p&gt;&lt;p&gt;Deterministic Pipeline&lt;/p&gt;&lt;p&gt;No guesswork, no polling, no sleeps.&lt;/p&gt;&lt;head rend="h2"&gt;Beyond Local Mocks and Public SaaS&lt;/head&gt;&lt;code&gt;rejectUnauthorized: false&lt;/code&gt;&lt;code&gt;sleep(5000)&lt;/code&gt;&lt;head rend="h3"&gt;Is This For You?&lt;/head&gt;&lt;p&gt;You should use VaultSandbox if:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;You use transactional email providers like Postmark, SendGrid, SES, or Resend.&lt;/item&gt;&lt;item&gt;You've been burned by DKIM/SPF failures in production.&lt;/item&gt;&lt;item&gt; You're tired of &lt;code&gt;sleep()&lt;/code&gt;statements flaking out your CI.&lt;/item&gt;&lt;item&gt;Your compliance team forbids sending test data to third-party SaaS inboxes.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Zero-Trust Email Testing&lt;/head&gt;&lt;head rend="h3"&gt;Zero-Knowledge Storage Architecture&lt;/head&gt;&lt;p&gt;The server literally cannot decrypt your emails, even if compromised.&lt;/p&gt;&lt;p&gt;Private keys are generated locally and never touch the server.&lt;/p&gt;&lt;p&gt;Emails are encrypted in-memory on receipt; plaintext never hits the disk.&lt;/p&gt;&lt;p&gt;Decryption happens exclusively on your client. Your data remains sovereign.&lt;/p&gt;&lt;head rend="h3"&gt;Production-Like Message Analysis&lt;/head&gt;&lt;p&gt;VaultSandbox validates and inspects mail like a hardened email gateway:&lt;/p&gt;&lt;p&gt;SPF, DKIM, DMARC, and rDNS verdicts instantly returned.&lt;/p&gt;&lt;p&gt;Full MIME parsing ‚Äî boundaries, attachments, HTML structure.&lt;/p&gt;&lt;p&gt;Strict SMTP protocol compliance, catching failures mocks silently ignore.&lt;/p&gt;&lt;head rend="h3"&gt;Ephemeral by Design (CI-Optimized)&lt;/head&gt;&lt;p&gt;VaultSandbox is built for high-velocity pipelines.&lt;/p&gt;&lt;p&gt;100% In-Memory: Lightning-fast execution with zero disk I/O bottlenecks.&lt;/p&gt;&lt;p&gt;Automatic Cleanup: No need to manually flush databases; restart the container to wipe the slate clean.&lt;/p&gt;&lt;p&gt;Disposable Inboxes: Generate random addresses that exist only for the duration of one test.&lt;/p&gt;&lt;head rend="h2"&gt;Real World Scenarios&lt;/head&gt;&lt;head rend="h5"&gt;The Signup Flow&lt;/head&gt;&lt;p&gt; QA tester creates &lt;code&gt;[email¬†protected]&lt;/code&gt;, signs up, checks
                the inbox. Done. No shared credentials, no data leaks.
&lt;/p&gt;&lt;head rend="h5"&gt;The Password Reset Integration&lt;/head&gt;&lt;p&gt;CI pipeline triggers a real password reset via Postmark. VaultSandbox catches the email, extracts the reset link, and "clicks" it. A true end-to-end integration test.&lt;/p&gt;&lt;head rend="h5"&gt;The DKIM/SPF Check&lt;/head&gt;&lt;p&gt;You rotated your DKIM keys. Send one test email to VaultSandbox and instantly verify if the signature is valid. Catch authentication rot before it blocks your newsletter.&lt;/p&gt;&lt;head rend="h3"&gt;Inspect Rendered HTML &amp;amp; Headers in Real-Time&lt;/head&gt;&lt;p&gt;A debugging workflow built for engineers:&lt;/p&gt;&lt;p&gt;Create disposable inboxes instantly&lt;/p&gt;&lt;p&gt;Full HTML preview (rendered as recipients see it)&lt;/p&gt;&lt;p&gt;Automatic link extraction + status checking&lt;/p&gt;&lt;p&gt;Auth results at a glance: SPF/DKIM/rDNS&lt;/p&gt;&lt;p&gt;Full header explorer&lt;/p&gt;&lt;head rend="h3"&gt;Real-Time Email Testing from Your Terminal&lt;/head&gt;&lt;p&gt;A powerful CLI for developers who live in the terminal:&lt;/p&gt;&lt;p&gt;Interactive TUI dashboard with real-time email monitoring&lt;/p&gt;&lt;p&gt;Multi-inbox watching with SSE streaming&lt;/p&gt;&lt;p&gt;CI/CD ready with blocking wait command for pipelines&lt;/p&gt;&lt;p&gt;Portable inboxes with export/import for sharing&lt;/p&gt;&lt;head rend="h3"&gt;Deterministic SDKs for Automated Tests&lt;/head&gt;&lt;p&gt;Powered by Server-Sent Events (SSE) for true real-time, deterministic test behavior.&lt;/p&gt;&lt;p&gt;Real-time delivery where tests wait on actual delivery events instead of sleeps&lt;/p&gt;&lt;p&gt;Zero flakiness with no polling and no guessing&lt;/p&gt;&lt;p&gt;Clean promise-based API for auth and content assertions&lt;/p&gt;&lt;p&gt;Official SDKs for Node.js, Python, Java, .NET, and Go&lt;/p&gt;&lt;head rend="h3"&gt;Official SDKs&lt;/head&gt;&lt;code&gt;import { VaultSandboxClient } from '@vaultsandbox/client';

const client = new VaultSandboxClient({
  url: process.env.VAULTSANDBOX_URL,
  apiKey: process.env.VAULTSANDBOX_API_KEY,
});
const inbox = await client.createInbox();

// Send real email via SendGrid/SES/etc.
await sendPasswordReset(inbox.emailAddress);

// Wait for arrival (SSE-based)
const email = await inbox.waitForEmail({ timeout: 10000 });
const link = email.links.find(l =&amp;gt; l.includes('reset-password'));
expect(link).toBeDefined();&lt;/code&gt;&lt;head rend="h2"&gt;Open Source &amp;amp; Commercially Safe&lt;/head&gt;&lt;p&gt;The core engine is open-source and un-gated ‚Äî the Docker image you pull is the same engine used in production setups.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Core Gateway: AGPLv3&lt;/item&gt;&lt;item&gt;SDKs + UI: MIT (safe for proprietary apps)&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;No Artificial Limits&lt;/head&gt;&lt;p&gt;Unlimited inboxes, connections, containers&lt;/p&gt;&lt;p&gt;Unlimited volume (hardware-bound only)&lt;/p&gt;&lt;p&gt; 100% in-memory for high-speed CI&lt;lb/&gt; (Local persistence coming soon) &lt;/p&gt;&lt;head rend="h3"&gt;Full Encryption by Default&lt;/head&gt;&lt;p&gt;Quantum-safe cryptography is built in from day one.&lt;/p&gt;&lt;head rend="h2"&gt;Roadmap: Foundation First&lt;/head&gt;&lt;head rend="h3"&gt;PHASE 1: CORE FOUNDATION&lt;/head&gt;Current&lt;list rend="ul"&gt;&lt;item&gt;‚úì Official SDKs released for all major languages.&lt;/item&gt;&lt;item&gt;‚Ä¢ Closing critical feature gaps based on community feedback.&lt;/item&gt;&lt;item&gt;‚Ä¢ Achieving 100% test coverage &amp;amp; complete docs for a rock-solid core.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;PHASE 2: ENTERPRISE CONTROL PLANE&lt;/head&gt;Architecting&lt;p&gt;For compliance-heavy teams:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;‚Ä¢ SSO (OIDC/SAML)&lt;/item&gt;&lt;item&gt;‚Ä¢ Audit Logs &amp;amp; Retention&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Have governance needs? Help shape the specs.&lt;/p&gt;&lt;head rend="h2"&gt;Frequently Asked Questions&lt;/head&gt;&lt;p&gt;Still have questions? Drop a line to [email protected]&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Is the Gateway truly free? What‚Äôs the catch?&lt;/head&gt;&lt;p&gt;Yes. The Core Gateway is AGPLv3 and free forever ‚Äî no limits on domains, messages, or retention. We only charge for optional Enterprise features (SSO, Audit Logs).&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Do I need a public IP and domain?&lt;/head&gt;&lt;p&gt;Yes, to unlock full production parity. To issue real Let's Encrypt certificates (ACME) and perform valid SPF/DKIM checks, the container must be publicly reachable on Ports 80, 443, and 25.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Port 80/443: Required for ACME certificate issuance and secure API/UI access&lt;/item&gt;&lt;item&gt;Port 25: Required to receive inbound SMTP traffic from the open internet.&lt;/item&gt;&lt;item&gt;Running locally implies using self-signed certificates and bypassing strict DNS validations.&lt;/item&gt;&lt;/list&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Can I use this as a temporary email service for QA?&lt;/head&gt;&lt;p&gt;Absolutely. VaultSandbox acts as a catch-all for your testing domains. Create infinite inboxes like `[email protected]` instantly.&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Is this heavy to run (vs Mailcow/Mailu)?&lt;/head&gt;&lt;p&gt;No. VaultSandbox omits heavy components like antivirus or spam filtering ‚Äî optimized strictly for testing.&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;How is this ‚ÄúZero-Knowledge‚Äù if the server receives email via SMTP?&lt;/head&gt;&lt;p&gt;Storage is zero-knowledge:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Client generates keys&lt;/item&gt;&lt;item&gt;Server encrypts with your public key&lt;/item&gt;&lt;item&gt;Plaintext is discarded&lt;/item&gt;&lt;item&gt;Decryption happens only client-side&lt;/item&gt;&lt;/list&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Why quantum-safe cryptography?&lt;/head&gt;&lt;p&gt;We're building from scratch, so we used modern standards. ML-KEM-768 is NIST's finalized post-quantum algorithm‚Äîthe performance cost is negligible, so there's no reason not to future-proof. Regulated industries will likely require it eventually; we're already there.&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Won't my sandbox get hammered by spam if I open port 25?&lt;/head&gt;&lt;p&gt;No. The SMTP server has multiple layers of protection:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Domain Restriction ‚Äî Only accepts mail for your configured domains. Not an open relay; rejects mail for other domains immediately.&lt;/item&gt;&lt;item&gt;Inbox Validation ‚Äî Rejects mail at the RCPT TO stage if no matching inbox exists. Spammers can't even send data for non-existent addresses.&lt;/item&gt;&lt;item&gt;Per-IP Rate Limiting ‚Äî Configurable limits (e.g., 10 emails/60s per IP). Abusive IPs get temporarily blocked with SMTP 421 responses.&lt;/item&gt;&lt;item&gt;Connection Limits ‚Äî Configurable max concurrent connections, session timeouts, and message size limits prevent resource exhaustion.&lt;/item&gt;&lt;item&gt;Early Talker Detection ‚Äî Optional delay catches spam bots that send commands before the server banner.&lt;/item&gt;&lt;item&gt;Hard Mode (optional) ‚Äî Rejects all mail if no inboxes are configured. Nothing to receive means nothing to spam.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Bottom line: your sandbox only accepts mail for addresses you explicitly create, and rate limiting stops any single source from overwhelming it.&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;What happens if my container crashes or restarts?&lt;/head&gt;&lt;p&gt;Emails are ephemeral by default ‚Äî restart wipes them. API keys and certificates are persisted, so your test environment stays configured; only inbox contents reset.&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Can I use a REST client if there's no SDK for my language?&lt;/head&gt;&lt;p&gt;Yes. The Gateway exposes a standard REST API. SDKs are convenience wrappers with SSE support for real-time waiting. You can poll or integrate however you like, though you'll need to manage key creation and decryption yourself.&lt;/p&gt;&lt;p&gt;Full client spec: vaultsandbox.dev/sdk/client-spec&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;Do I have to manage encryption keys myself?&lt;/head&gt;&lt;p&gt;No ‚Äî the SDKs handle key-pair generation and decryption automatically. Just call &lt;code&gt;getEmail()&lt;/code&gt; and get plaintext back. If you're using the REST API directly, you'll need to handle decryption yourself (see the client spec).&lt;/p&gt;&lt;head class="text-surface-50 hover:text-brand-200 flex cursor-pointer list-none items-center justify-between gap-4 py-6 text-base leading-tight font-semibold transition" data-astro-cid-al2ca2vr=""&gt;How long are emails stored?&lt;/head&gt;&lt;p&gt;Until the container restarts (in-memory only), until the inbox TTL expires (configurable when you create the inbox), or until you delete the inbox ‚Äî whichever comes first.&lt;/p&gt;&lt;head rend="h2"&gt;Ready to drop your mocks?&lt;/head&gt;&lt;p&gt;Stop guessing if your emails will land. Spin up the full VaultSandbox environment in your VPC in minutes.&lt;/p&gt;&lt;p&gt;Open Source (AGPLv3/MIT) ‚Ä¢ Deploys via Docker&lt;/p&gt;&lt;head rend="h2"&gt;Stay in touch with VaultSandbox&lt;/head&gt;&lt;p&gt;Subscribe for product updates, security releases, and deep dives on building production-grade email testing inside your VPC.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vaultsandbox.com/"/><published>2026-01-06T13:50:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46514677</id><title>Vietnam bans unskippable ads</title><updated>2026-01-07T09:18:57.415222+00:00</updated><content>&lt;doc fingerprint="6f8928bd4270847c"&gt;
  &lt;main&gt;
    &lt;p&gt;If things go our way, YouTube‚Äôs notorious unskippable ads might be a thing of the past come this February.&lt;/p&gt;
    &lt;p&gt;As Ph·ª• N·ªØ reports, Vietnam recently announced Decree No. 342, which details a number of provisions to the national Advertising Law, due to take effect from February 15, 2026. The adjustments are expected to place stricter control on Vietnam‚Äôs online advertising activities to protect consumers and curb illegal ads.&lt;/p&gt;
    &lt;p&gt;Amongst the decree articles, some standout stipulations include a hard cap on the waiting time before viewers can skip video and animated ads to no more than 5 seconds. Static ads must be immediately cancellable.&lt;/p&gt;
    &lt;p&gt;Additionally, the decree requires platforms to implement clear and straightforward ways for users to close ads with just one interaction. False or vague symbols designed to confuse viewers are forbidden.&lt;/p&gt;
    &lt;p&gt;Online platforms must add visible symbols and guidelines to help users report ads that violate the law and allow them to turn off, deny, or stop seeing inappropriate ads.&lt;/p&gt;
    &lt;p&gt;Beside rules about the user experience, the decree also seeks to tightly regulate ads for 11 groups of goods and services that directly impact the environment and human health, including: cosmetics; food and beverages; milk and formula for children; insecticidal chemicals and substances; medical supplies; healthcare services; plant pesticides and veterinary drugs; fertilizers; plant seeds and saplings; pharmaceuticals; and alcoholic drinks.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://saigoneer.com/vietnam-news/28652-vienam-bans-unskippable-ads,-requires-skip-button-to-appear-after-5-seconds"/><published>2026-01-06T16:45:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46515696</id><title>Opus 4.5 is not the normal AI agent experience that I have had thus far</title><updated>2026-01-07T09:18:57.331047+00:00</updated><content>&lt;doc fingerprint="26499875abe73fe9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Opus 4.5 is going to change everything&lt;/head&gt;
    &lt;p&gt;If you had asked me three months ago about these statements, I would have said only someone who‚Äôs never built anything non-trivial would believe they‚Äôre true. Great for augmenting a developer‚Äôs existing workflow, and completions are powerful, but agents replacing developers entirely? No. Absolutely not.&lt;/p&gt;
    &lt;p&gt;Today, I think that AI coding agents can absolutely replace developers. And the reason that I believe this is Claude Opus 4.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opus 4.5 is not normal&lt;/head&gt;
    &lt;p&gt;And by ‚Äúnormal‚Äù, I mean that it is not the normal AI agent experience that I have had thus far. So far, AI Agents seem to be pretty good at writing spaghetti code and after 9 rounds of copy / paste errors into the terminal and ‚Äúfix it‚Äù have probably destroyed my codebase to the extent that I‚Äôll be throwing this whole chat session out and there goes 30 minutes I‚Äôm never getting back.&lt;/p&gt;
    &lt;p&gt;Opus 4.5 feels to me like the model that we were promised - or rather the promise of AI for coding actually delivered.&lt;/p&gt;
    &lt;p&gt;One of the toughest things about writing that last sentence is that the immediate response from you should be, ‚Äúprove it‚Äù. So let me show you what I‚Äôve been able to build.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 1 - Windows Image Conversion Utility&lt;/head&gt;
    &lt;p&gt;I first noticed that Opus 4.5 was drastically different when I used it to build a Windows utility to right-click an image and convert it to different file types. This was basically a one shot build after asking Opus the best way to add a right-click menu to the file explorer.&lt;/p&gt;
    &lt;p&gt;What amazed me through the process of building this was Opus 4.5 ability to get most things right on the first try. And if it ran into errors, it would try and build using the dotnet CLI, read the errors and iterate until fixed. The only issue I had was Opus inability to see XAML errors, which I used Visual Studio to see and copy / paste back into the agent.&lt;/p&gt;
    &lt;p&gt;Opus built a site for me to distribute it and handled the bundling of the executable so as to use a powershell script for the install, uninstall. It also built the GitHub Actions which do the release and update the landing page so that all I have to do is push source.&lt;/p&gt;
    &lt;p&gt;The only place I had to use other tools was for the logo - where I used Figma‚Äôs AI to generate a bunch of different variations - but then Opus wrote the scripts to convert that SVG to the right formats for icons, even store distribution if I chose to do so.&lt;/p&gt;
    &lt;p&gt;Now this is admittedly not a complex application. This is a small Windows utility that is doing basically one thing. It‚Äôs not like I asked Opus 4.5 to build Photoshop.&lt;/p&gt;
    &lt;p&gt;Except I kind of did.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 2 - Screen recording / editing&lt;/head&gt;
    &lt;p&gt;I was so impressed by Opus 4.5 work on this utility that I decided to make a simple GIF recording utility similar to LICEcap for Mac. Great app, questionable name.&lt;/p&gt;
    &lt;p&gt;But that proved to be so easy, that I went ahead and continued adding features, including capturing and editing video, static images, adding shapes, cropping, blurs and more. I‚Äôm still working on this application as it turns out building a full on image/video editor is kind of a big undertaking. But I got REALLY far in a matter of hours. HOURS, PEOPLE.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt have a fancy landing page for this one yet, but you can view all of the source code here.&lt;/p&gt;
    &lt;p&gt;I realized that if I could build a video recording app, I could probably build anything at all - at least UI-wise. But the achilles heel of all AI agents is when they have to glue together backend systems - which any real world application is going to have - auth, database, API, storage.&lt;/p&gt;
    &lt;p&gt;Except Opus 4.5 can do that too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 3 - AI Posting Utility&lt;/head&gt;
    &lt;p&gt;Armed with my confidence in Opus 4.5, I took on a project that I had built in React Native last year and finished for Android, but gave up in the final stretches (as one does).&lt;/p&gt;
    &lt;p&gt;The application is for my wife who owns a small yard sign franchise. The problem is that she has a Facebook page for the business, but never posts there because it‚Äôs time consuming. But any good small business has a vibrant page where people can see photos of your business doing‚Ä¶whatever the heck it does. So people know that it exsits and is alive and well.&lt;/p&gt;
    &lt;p&gt;The idea is simple - each time she sets up a yard sign, she takes a picture to send to the person who ordered it so they can see it was setup. So why not have a mobile app where she can upload 10 images at a time, and the app will use AI to generate captions and then schedule them and post them over the coming week.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a simple premise, but it has a lot of moving parts - there is the Facebook authentication which is a caper in and of itself - not for the faint of heart. There is authentication with a backend, there is file storage for photos that are scheduled to go out, there is the backend process which needs to post the photo. It‚Äôs a full on backend setup.&lt;/p&gt;
    &lt;p&gt;As it turns out, I needed to install some blinds in the house so I thought - why don‚Äôt I see if Opus 4.5 can build this while I install the blinds.&lt;/p&gt;
    &lt;p&gt;So I fired up a chat session and just started by telling Opus 4.5 what I wanted to build and how it would recommend handling the backend. It recommended several options but settled on Firebase. I‚Äôm not now nor have I ever been a Firebase user, but at this point I trust Opus 4.5 a lot. Probably too much.&lt;/p&gt;
    &lt;p&gt;So I created a Firebase account, upgraded to the Blaze plan with alerts for billing and Opus 4.5 got to work.&lt;/p&gt;
    &lt;p&gt;By the time I was done installing blinds, I had a functional iOS application for using AI to caption photos and posting them on a schedule to Facebook.&lt;/p&gt;
    &lt;p&gt;When I say that Opus 4.5 built this almost entirely, I mean it. It used the &lt;code&gt;firebase&lt;/code&gt; CLI to stand up any resources it needed and would tag me in for certain things like upgrading a project to the Blaze plan for features like storage, etc. The best part was that when the Firebase cloud functions would throw errors, it would automatically grep those logs, find the error and resolve it. And all it needed was a CLI. No MCP Server. No fancy prompt file telling it how to use Firebase.&lt;/p&gt;
    &lt;p&gt;And of course, since it‚Äôs solved, I had Opus 4.5 create a backend admin dashboard so I could see what she‚Äôs got pending and make any adjustments.&lt;/p&gt;
    &lt;p&gt;And since it did in a few hours what had taken me two months of work in the evenings instead of being a decent husband, I decided to make up for my dereliction of duties by building her another app for her sign business that would make her life just a bit more delightful - and eliminate two other apps she is currently paying for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 4 - Order tracking and routing&lt;/head&gt;
    &lt;p&gt;This app parses orders from her business Gmail account to show her what sign setups / pickups she has for the day, calculates how long its going to take to go to each stop, calculates the optimal route when there is more than one stop and tracks drive time for tax purposes. She was previously using two paid apps for the last two features there.&lt;/p&gt;
    &lt;p&gt;This app also uses Firebase. Again, Opus one-shotted the Google auth email integration. This is the kind of thing that is painstakingly miserable by hand. And again, Firebase is so well suited here because Opus knows how to use the Firebase CLI so well. It needs zero instruction.&lt;/p&gt;
    &lt;head rend="h3"&gt;BUT YOU DON‚ÄôT KNOW HOW THE CODE WORKS&lt;/head&gt;
    &lt;p&gt;No I don‚Äôt. I have a vague idea, but you are right - I do not know how the applications are actually assembled. Especially since I don‚Äôt know Swift at all.&lt;/p&gt;
    &lt;p&gt;This used to be a major hangup for me. I couldn‚Äôt diagnose problems when things went sideways. With Opus 4.5, I haven‚Äôt hit that wall yet‚ÄîOpus always figures out what the issue is and fixes its own bugs.&lt;/p&gt;
    &lt;p&gt;The real question is code quality. Without understanding how it‚Äôs built, how do I know if there‚Äôs duplication, dead code, or poor patterns? I used to obsess over this. Now I‚Äôm less worried that a human needs to read the code, because I‚Äôm genuinely not sure that they do.&lt;/p&gt;
    &lt;p&gt;Why does a human need to read this code at all? I use a custom agent in VS Code that tells Opus to write code for LLMs, not humans. Think about it‚Äîwhy optimize for human readability when the AI is doing all the work and will explain things to you when you ask?&lt;/p&gt;
    &lt;p&gt;What you don‚Äôt need: variable names, formatting, comments meant for humans, or patterns designed to spare your brain.&lt;/p&gt;
    &lt;p&gt;What you do need: simple entry points, explicit code with fewer abstractions, minimal coupling, and linear control flow.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs my custom agent prompt:&lt;/p&gt;
    &lt;code&gt;You are an AI-first software engineer. Assume all code will be written and maintained by LLMs, not humans. Optimize for model reasoning, regeneration, and debugging ‚Äî not human aesthetics.

These coding principles are mandatory:

1. Structure
- Use a consistent, predictable project layout.
- Group code by feature/screen; keep shared utilities minimal.
- Create simple, obvious entry points.
- Before scaffolding multiple files, identify shared structure first. Use framework-native composition patterns (layouts, base templates, providers, shared components) for elements that appear across pages. Duplication that requires the same fix in multiple places is a code smell, not a pattern to preserve.

2. Architecture
- Prefer flat, explicit code over abstractions or deep hierarchies.
- Avoid clever patterns, metaprogramming, and unnecessary indirection.
- Minimize coupling so files can be safely regenerated.

3. Functions and Modules
- Keep control flow linear and simple.
- Use small-to-medium functions; avoid deeply nested logic.
- Pass state explicitly; avoid globals.

4. Naming and Comments
- Use descriptive-but-simple names.
- Comment only to note invariants, assumptions, or external requirements.

5. Logging and Errors
- Emit detailed, structured logs at key boundaries.
- Make errors explicit and informative.

6. Regenerability
- Write code so any file/module can be rewritten from scratch without breaking the system.
- Prefer clear, declarative configuration (JSON/YAML/etc.).

7. Platform Use
- Use platform conventions directly and simply (e.g., WinUI/WPF) without over-abstracting.

8. Modifications
- When extending/refactoring, follow existing patterns.
- Prefer full-file rewrites over micro-edits unless told otherwise.

9. Quality
- Favor deterministic, testable behavior.
- Keep tests simple and focused on verifying observable behavior.

Your goal: produce code that is predictable, debuggable, and easy for future LLMs to rewrite or extend.
&lt;/code&gt;
    &lt;p&gt;All of that said, I don‚Äôt have any proof that this prompt makes a difference. I find that Opus 4.5 writes pretty solid code no matter what you prompt it with. However, because models like to write code WAY more than they like to delete it, I will at points run a prompt that looks something like this‚Ä¶&lt;/p&gt;
    &lt;code&gt;Check your LLM, AI coding principles and then do a comprehensive search of this application and suggest what we can do to refactor this to better align to those principles. Also point out any code that can be deleted, any files that can be deleted, things that should read should be renamed, things that should be restructured. Then do a write up of what that looks like. Kind of keep it high level so that it's easy for me to read and not too complex. Add sections for high, medium and lower priority And if something doesn't need to be changed, then don't change it. You don't need to change things just for the sake of changing them. You only need to change them if it helps better align to your LLM AI coding principles. Save to a markdown file.
&lt;/code&gt;
    &lt;p&gt;And you get a document that has high, medium and low priority items. The high ones you can deal with and the AI will stop finding them. You can refactor your project a million times and it will keep finding medium/low priority refactors that you can do. An AI is never ever going to pass on the opportunity to generate some text.&lt;/p&gt;
    &lt;p&gt;I use a similar prompt to find security issues. These you have to be very careful about. Where are the API keys? Is login handled correctly? Are you storing sensitive values in the database? This is probably the most manual part of the project and frankly, something that makes me the most nervous about all of these apps at the moment. I‚Äôm not 100% confident that they are bullet proof. Maybe like 80%. And that, as they say, is too damn low.&lt;/p&gt;
    &lt;head rend="h3"&gt;Times they are A-changin&lt;/head&gt;
    &lt;p&gt;I don‚Äôt know if I feel exhilarated by what I can now build in a matter of hours, or depressed because the thing I‚Äôve spent my life learning to do is now trivial for a computer. Both are true.&lt;/p&gt;
    &lt;p&gt;I understand if this post made you angry. I get it - I didn‚Äôt like it either when people said ‚ÄúAI is going to replace developers.‚Äù But I can‚Äôt dismiss it anymore. I can wish it weren‚Äôt true, but wishing doesn‚Äôt change reality.&lt;/p&gt;
    &lt;p&gt;But for everything else? Build. Stop waiting to have all the answers. Stop trying to figure out your place in an AI-first world. The answer is the same as it always was: make things. And now you can make them faster than you ever thought possible.&lt;/p&gt;
    &lt;p&gt;Just make sure you know where your API keys are.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://burkeholland.github.io/posts/opus-4-5-change-everything/"/><published>2026-01-06T17:45:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46515777</id><title>Launch HN: Tamarind Bio (YC W24) ‚Äì AI Inference Provider for Drug Discovery</title><updated>2026-01-07T09:18:56.992295+00:00</updated><content>&lt;doc fingerprint="6f51ad5b7d3645cb"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Deniz and Sherry from Tamarind Bio (&lt;/p&gt;https://www.tamarind.bio&lt;p&gt;). Tamarind is an inference provider for AI drug discovery, serving models like AlphaFold. Biopharma companies use our library of leading open-source models to design new medicines computationally.&lt;/p&gt;&lt;p&gt;Here‚Äôs a demo: https://youtu.be/luoMApPeglo&lt;/p&gt;&lt;p&gt;Two years ago, I was hired at a Stanford lab to run models for my labmates. Some post-doc would ask me to run a set of 1-5 models in sequence with tens of thousands inputs and I would email them back the result after setting up the workflow in the university cluster.&lt;/p&gt;&lt;p&gt;At some point, it became unreasonable that all of an organization's computational biology work would go through an undergrad, so we built Tamarind as a single place for all molecular AI tools, usable at massive scale with no technical background needed. Today, we are used by much of the top 20 pharma, dozens of biotechs and tens of thousands of scientists.&lt;/p&gt;&lt;p&gt;When we started getting adoption in the big pharma companies, we found that this problem also persisted. I know directors of data science, where half their job could be described as running scripts for other people.&lt;/p&gt;&lt;p&gt;Lots of companies have also deprecated their internally built solution to switch over, dealing with GPU infra and onboarding docker containers not being a very exciting problem when the company you work for is trying to cure cancer.&lt;/p&gt;&lt;p&gt;Unlike non-specialized inference providers, we build both a programmatic interface for developers along with a scientist-friendly web app, since most of our users are non-technical. Some of them used to extract proteins from animal blood before replacing that process with using AI to generate proteins on Tamarind.&lt;/p&gt;&lt;p&gt;Besides grinding out images for each of the models we serve, we‚Äôve designed a standardized schema to be able to share each model‚Äôs data format. We‚Äôve built a custom scheduler and queue optimized for horizontal scaling (each inference call takes minutes to hours, and runs on one GPU at a time), while splitting jobs across CPUs and GPUs for optimal timing.&lt;/p&gt;&lt;p&gt;As we've grown to handle a substantial portion of the biopharma R&amp;amp;D AI demand on behalf of our customers, we've expanded beyond just offering a library of open source protocols.&lt;/p&gt;&lt;p&gt;A common use case we saw from early on was the need to connect multiple models together into pipelines, and having reproducible, consistent protocols to replace physical experiments. Once we became the place to build internal tools for computational science, our users started asking if they could onboard their own models to the platform.&lt;/p&gt;&lt;p&gt;From there, we now support fine-tuning, building UIs for arbitrary docker containers, connecting to wet lab data sources and more!&lt;/p&gt;&lt;p&gt;Reach out to me at deniz[at]tamarind.bio if you‚Äôre interested in our work, we are hiring! Check out our product at https://app.tamarind.bio and let us know if you have any feedback to support how the biotech industry uses AI today.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46515777"/><published>2026-01-06T17:49:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46515948</id><title>Locating a Photo of a Vehicle in 30 Seconds with GeoSpy</title><updated>2026-01-07T09:18:56.705947+00:00</updated><link href="https://geospy.ai/blog/locating-a-photo-of-a-vehicle-in-30-seconds-with-geospy"/><published>2026-01-06T18:00:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46516137</id><title>Passing of Joe Mancuso</title><updated>2026-01-07T09:18:56.358999+00:00</updated><content>&lt;doc fingerprint="2c52725b5bc5a72e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Passing of Joe Mancuso #853&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Good morning Masonite community,&lt;/p&gt;
          &lt;p&gt;I regret to inform you all that @josephmancuso has passed away due to health complications. Please keep his family in your thoughts during this time.&lt;/p&gt;
          &lt;p&gt;I had the privilege of working alongside Joe for many years, and it was clear as day how much Masonite meant to him. Even when fighting for his life, he continued doing everything he could to maintain and support this project.&lt;/p&gt;
          &lt;p&gt;One of the beautiful things about open source is that we build together. While Joe is no longer with us, Masonite can continue to grow and evolve through the contributions of this community. I hope we all continue working toward the vision he poured so much of himself into.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 2 comments&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;So sad, my condolences.üòû&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;This is heartbreaking. I also had the privilege of working with Joe a couple of months ago, and he was always bringing new ideas to improve and share within the open-source community.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/MasoniteFramework/masonite/discussions/853"/><published>2026-01-06T18:11:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46517319</id><title>High-Performance DBMSs with io_uring: When and How to use it</title><updated>2026-01-07T09:18:56.242501+00:00</updated><content>&lt;doc fingerprint="b89f341a58d3848a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Databases&lt;/head&gt;&lt;p&gt; [Submitted on 4 Dec 2025 (v1), last revised 12 Dec 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:High-Performance DBMSs with io_uring: When and How to use it&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL's recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Matthias Jasny [view email]&lt;p&gt;[v1] Thu, 4 Dec 2025 14:43:03 UTC (504 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 12 Dec 2025 09:44:22 UTC (505 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.04859"/><published>2026-01-06T19:29:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46517458</id><title>Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone</title><updated>2026-01-07T09:18:55.764186+00:00</updated><content>&lt;doc fingerprint="d11490dd3b96cae3"&gt;
  &lt;main&gt;
    &lt;p&gt;A DIY approach to coding on-the-go!&lt;/p&gt;
    &lt;p&gt;As an aspiring builder, I sought out a way to keep coding while not at home. Thanks to some Claude-assisted research and troubleshooting, I can now code via the terminal on my phone anywhere at anytime via "Doom Coding" (think Doom Scrolling but more productive).&lt;/p&gt;
    &lt;p&gt;After this 5-minute setup guide, you'll be able to "doom code" anywhere you have Internet connection.&lt;/p&gt;
    &lt;p&gt;I've been amazed by how much I can get done while being so far away from home. In Taiwan, I could access my computer in Philadelphia and coded a prototype in my downtime.&lt;/p&gt;
    &lt;p&gt;Shameless plug: check out www.friendlyr.ai to help shape the future of connection!&lt;/p&gt;
    &lt;p&gt;Make sure to "Watch" this repo for future updates to this doom coding guide. As I tryout the latest mobile coding tools (e.g. Claude Code on the Web), I'll update this repository with comparisons.&lt;/p&gt;
    &lt;p&gt;Happy doom coding my friends!&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A Computer running 24/7 with Internet Connection&lt;/item&gt;
      &lt;item&gt;A Smartphone&lt;/item&gt;
      &lt;item&gt;A Claude Pro subscription&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Tailscale, Termius, Claude Code, and a computer running 24/7 to continue building anywhere you have Internet connection.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable sleep in power settings&lt;/item&gt;
      &lt;item&gt;Enable SSH/Remote Login&lt;/item&gt;
      &lt;item&gt;Install Tailscale and sign in&lt;lb/&gt;https://tailscale.com/download&lt;/item&gt;
      &lt;item&gt;Install Claude Code on your computer&lt;lb/&gt;https://docs.anthropic.com/en/docs/claude-code/overview&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Install Tailscale ‚Üí Sign in with the same account&lt;/p&gt;&lt;lb/&gt;https://apps.apple.com/us/app/tailscale/id1470499037&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Install Termius (A Mobile Terminal Tool)&lt;/p&gt;&lt;lb/&gt;https://apps.apple.com/us/app/termius-modern-ssh-client/id549039908&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Note the MagicDNS address of your computer (e.g. my-computer.tailnet-name.ts.net)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create a new host in Termius:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Label: What you want your connection to be called&lt;/item&gt;
          &lt;item&gt;Hostname: The MagicDNS address (my-computer.tailnet-name.ts.net)&lt;/item&gt;
          &lt;item&gt;Port: 22&lt;/item&gt;
          &lt;item&gt;Username/Password: Your login for your computer &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you're not able to establish a connection from your phone via Termius to your computer:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check your phone settings to make sure you are connected to the Tailscale VPN. &lt;/item&gt;
      &lt;item&gt;Check the Tailscale app to make sure the Tailscale VPN is on. If your phone and doom coding computer do not have a green circle next to their labels, there is an issue with your Tailscale/Internet connection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When disconnecting/reconnecting power, make sure you unlock the computer. I've ran into this issue one too many times.&lt;/p&gt;
    &lt;p&gt;End sessions by asking Claude to update CLAUDE.md with where you left off.&lt;/p&gt;
    &lt;p&gt;Go to your desired directory and start an HTTP server&lt;code&gt;python -m http.server 3005&lt;/code&gt;
then visit http://your-machine.tailnet-name.ts.net:3005/your-html-file.html in a browser on your phone.&lt;/p&gt;
    &lt;p&gt;Wherever you would use localhost:PORT to view an app on your computer, replace localhost with the computer's MagicDNS from the Tailscale app (e.g. your-computer.tailnet-name.ts.net)&lt;/p&gt;
    &lt;p&gt;Use the PostgreSQL app to view databases for your projects https://apps.apple.com/us/app/postgresql-client/id1233662353&lt;/p&gt;
    &lt;p&gt;On your computer, bookmark the sites you refer to during development (e.g. Google OAuth, GitHub) to make it easier to reference from your phone. I use the Chrome app to seamlessly access the sites I need.&lt;/p&gt;
    &lt;p&gt;Please contibute your best practices! I am looking forward to seeing all the places you will code!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rberg27/doom-coding"/><published>2026-01-06T19:38:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518129</id><title>Calling All Hackers: How money works (2024)</title><updated>2026-01-07T09:18:55.490293+00:00</updated><content>&lt;doc fingerprint="332310190d2133ec"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Title : Calling All Hackers&lt;/p&gt;
      &lt;p&gt; Author : cts&lt;/p&gt;
      &lt;quote&gt; ==Phrack Inc.== Volume 0x10, Issue 0x47, Phile #0x11 of 0x11 |=-----------------------------------------------------------------------=| |=-----------------------=[ Calling All Hackers ]=-----------------------=| |=-----------------------------------------------------------------------=| |=--------------------------=[ cts (@gf_256) ]=--------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 0 - Preamble 1 - About the Author 2 - The Birth of a Shitcoin 3 - How Money Works 3.1 - Fixed Income 3.2 - Equities 3.3 - Shareholder Value 4 - Startup Blues 5 - Takeaways 6 - Thanks 7 - References 8 - Appendix --[ 0 - Preamble Hi. I'm cts, also known as gf_256, ephemeral, or a number of other handles. I am a hacker and now a small business owner and CEO. In this article, I would like to share my experience walking these two different paths. A hacker is someone who understands how the world works. It's about knowing what happens when you type "google.com" and press Enter. It's about knowing how your computer turns on, about memory training, A20, all of that. It's about modern processors, their caches, and their side channels. It's about DSi bootloaders and how the right electromagnetic faults can be used to jailbreak them. And it's about how Spotify and Widevine and AES and SGX work so you can free your music from the shackles of DRM. But being a hacker is so much more than these things. It's about knowing where to find things. Like libgen and Sci-Hub and nyaa. Or where to get into the latest IDA Pro group buy. Or which trackers have what and how to get into them. It's about knowing how to bypass email verification. How to bypass SMS verification. How to bypass that stupid fucking verification where you hold your driver's license up to a webcam (thank you, OBS virtual camera!) Having an actual threat model not just paranoia. Knowing that you're not worth burning a 0day on, but reading indictments to learn from others' mistakes. It's about knowing where to buy estradiol valerate on the internet and how to compound injections. Or the "bodybuilder method" to order your own blood tests when your state requires a script to do so. It's about knowing which shipments give the US CBP a bad vibe and which don't. It's about knowing what happens when you open Robinhood and giga long NVDA FDs. I mean the actual market microstructure, not "Ken Griffin PFOF bad". Then using that microstructure to find an infinite money glitch (high Sharpe!). It's about knowing how to get extra passports and reading the tax code. It's about knowing how to negotiate your salary (or equity). It's about knowing why things at the supermarket cost what they do. Or how that awful shitcoin keeps pumping. And why that dogshit startup got assigned that insane valuation. And understanding who really pays for it in the end (hint: it's you). My point is, it is not just about computers. It's about understanding how the world works. The world is made up of people. As much as machines keep society running, those machines are programmed by people--people with managers, spouses, and children; with wants, needs, and dreams. And it is about using that knowledge to bring about the change you want to see. That is what being a hacker is all about. --[ 1 - About the Author I have been a hacker for 13 years. Prior to founding Zellic, I helped start a CTF team called perfect blue (lately Blue Water). We later became the number one ranked CTF team in the world. We've played in DEF CON CTF. We've won GoogleCTF, PlaidCTF, and HITCON. It's like that scene from Mr. Robot but not cringe. In 2021, we decided to take that hacker friend circle and form a security firm. It turned out that crypto paid well, so we worked with a lot of crypto clients. In the process, we encountered insane, hilarious, and depressingly sobering bullshit. In this article, I will tell some stories about what that bullshit taught me, so you can benefit from the same lessons as I have. Markets are computers; they compute prices, valuations, and the allocation of resources in our society. Hackers are good at computers. Let's learn more about it. --[ 2 - The Birth of a Shitcoin I can't think of a better example than shitcoins. Let's look at the crypto markets in action. First, let's talk about tokens. What is their purpose? The purpose of a token is to go up. There is no other purpose. Token go up. This is important, remember this point. Now the question is, how do we make the token go up? In crypto, there are two main kinds of token deals. Let's call them the Asian Arrangement and the Western Way. The Asian Arrangement is a fairly straightforward pump and dump. It's a rectangle between the VC, the Market Maker, the Crypto Exchange, and the Token Project Founder. 1. The exchange's job is to list the token, bringing in investors. They get paid in a mix of tokens and cold, hard cash. Their superpower is owning the customer relationships with the retail users, and the naming rights to sports arenas. 2. The market maker provides liquidity so the market looks really healthy and well-traded so it is easy to buy the token. In good deals, they are paid in in-the-money call options on the tokens, so they are incentivized to help the token trade well. Their superpower is having a lot of liquidity to deploy, and people on PagerDuty. 3. The founder's job is to pump the token and shill it on Twitter. They are the hype man, and it's their job to drum up the narrative and pump everyone's bags. Their unique power is they can print more tokens out of thin air, and this is in large part how they get paid in this arrangement. 4. Lastly, the VC gets paid to organize the deal. They give the founders some money, who in return give a pinky promise that they will give the VC a lot of tokens once the tokens actually exist. This is known as a Simple Agreement for Future Tokens, or SAFT. Their superpower is dressing up the founders and project so it seems like the Next Big Thing instead of a Ponzi scheme. Everyone gets paid a ton of token exposure (directly or indirectly), and when it lists, it pumps. Then the insiders dump and leave with a fat stack. Except retail, they end up with the bag. Sometimes the listing doesn't go well for the organizers, in which case, better luck next time. But retail always loses. wtf??? LFG!!! to the moon ,o \oXo/\o/ /v | | | /\ / X\ / \ crypto investors ^ | | | | v +----------+ provides liquidity +--------+ | Crypto | &amp;lt;--------------------------------------- | Market | | Exchange | ----------------------------------------&amp;gt; | Maker | +----------+ maker fees +--------+ ^ | ^ fees, | | listing options | tokens | | / fees | | | +-------------------------------------------------+ | v | +---------+ tokens / SAFT / token warrants +---------+ | Token | ---------------------------------------&amp;gt; | Venture | | Project | &amp;lt;--------------------------------------- | Capital | +---------+ cash , intros to CEX / MM, shilling +---------+ This machine worked exceptionally well in 2017, especially before China banned crypto. All those ICO shitcoins? Asian Arrangement. And it still works well to this day, except people are more wary of lockups and vesting schedules and so on. Now let's discuss the Western Way. The Asian Arrangement? That old pump and dump? No sir, we are civilized people. Instead, our VCs *add value* to their investments by telling the world "how disruptive the tech is" and how the "team are incredible outliers". And they will not blatantly PnD the token, but instead they will fund "projects in the ecosystem" so it appears there is real activity happening on the platform. This is to hype up metrics (like TPS or TVL) to inflate the next round valuation. Anyways, then they dump. Or maybe the VC is also a market maker so they market make their portfolio company tokens. Overall it's the same shit (Ponzi) but dressed up in a nicer outfit. Asian Arrangement or Western Way--either way, if you're the token founder, your main priority is to just GO TO MARKET NOW and LAUNCH THE TOKEN. This is so you can collect your sweet bag and dump some secondary before someone else steals the narrative or the hype cycle moves on. This is one of the reasons there are so many hacks in crypto. The code is all shitty because it's rushed out as fast as possible by 20-something- year-old software engineers formerly writing Typescript and Golang at Google. Pair that with some psycho CEO product manager. Remember, it is not about WRITING SECURE CODE, it is about SHIPPING THE FUCKING PRODUCT. Good luck rewriting it in Rust! All of this worked well until Luna, then 3AC, Genesis, and FTX imploded in 2022. It still works, but you have to be less blatant now. Shitcoins do serve an essential need. They are an answer to financial nihilism. Many people are working dead-end wage slave jobs that are not enough to "make it". They feel trapped and forced to work at jobs they fucking hate and waste their life doing pointless shit to generate shareholder value. This kind of life feels unacceptable, yet there are few avenues out. So what is the only "attainable" solution left? Gamble it on shitcoins, and if you lose...maybe next paycheck will be better. But enough about crypto, let's talk about securities. --[ 3 - How Money Works ----[ 3.1 - Fixed Income First, let's start with fixed income. I'm talking boring, old-fashioned bonds, like Treasury bonds. A lot of people are introduced nowadays to finance through equities (stocks) and tokens. In my opinion, this is only half of the story. Fixed income is the bedrock of finance. It has fundamental value. It provides a prototypical asset that all assets can be benchmarked based on. Fixed income assets, like bonds, boil down to borrowing and lending. A bond is basically an IOU for someone to pay you in the future. It is more useful to have a dollar today than in a year, so lenders charge a fee for access to money today. This fee is known as interest, and how it is baked into the equation varies from asset-to-asset. Some bonds come with interest payments, whereas other bonds are zero-coupon. The most important thing is to remember that bonds are essentially an IOU to pay $X in the future. Here is an example. Let's say you would like to borrow $100 to finance an upcoming project. The interest rate will be 5% per year. To borrow money, you would issue (mint) a bond (an IOU) for $X+5 dollars to be repaid 1 year in the future. In exchange for this fresh IOU, the lender will give you $X dollars now. On the lender's balance sheet, they will be less $X dollars worth of cash, but will also have gained ($X+5) dollars worth of an asset (your IOU), creating $5 of equity. In contrast, you would have $X more cash in assets, but also an ($X+5) liability, creating -$5 of equity. This example also works for depositing money at a bank. Here, you are the lender, and the bank is the borrower. Your deposits would be liabilities on their balance sheet, as they are liable to pay you back the deposit if you choose to withdraw it. Lender's Balance Sheet Borrower's Balance Sheet =========================== =========================== Assets: Assets: IOU-----------------X+5 Cash------------------X Liabilities: Liabilities: Cash----------------(X) IOU-----------------X+5 Equity: Equity: Equity----------------5 Equity--------------(5) Fixed income assets are extremely simple. There are various risks (credit risk, interest rate risk, etc.), but excluding these factors, you essentially get what you pay for. Unlike a token or stock, the bond is not going to suddenly evaporate or crash. (In theory.) Because of this, they can be modeled in a straightforward way; a way so straightforward even a high school student can understand it. Let's say I have $X today. Suppose the prevailing (risk-free) interest rate is 5%. What is the value of this $X in a year? Obviously, it would be no less than $X*1.05, as I can just lend it out for 5% interest and get $X*1.05 back in a year. If you gave me the opportunity to invest in any asset yielding less than 5%, this would be a bad deal for me, since I could just lend it out myself to get 5% yield. Now, let's analyze the same scenario, but in reverse. Let's take that IOU from earlier. What is the value *today* of a (risk-free) $X IOU, due in 1 year? It would be worth no more than $X/1.05. This is because with $X/1.05 dollars today, I could lend it out and collect 5% interest to end up with $X again in the future. If I pay more than $X/1.05, I am getting a bad deal, since I am locking up my money with you when it would be more capital efficient to just lend it out myself. You can probably see where I am going with this. The present value of an $X IOU at some time *t* in the future is $X/(1+r)^t, where *r* is the discount rate. The discount rate describes the "decay" of the value over time, due to interest but also factors like potential failure of the asset (for example, if the asset is a company, business failure of the company). Now, if we have some asset which pays a series of future cash flows *f(t)*, we can model this asset as a bundle of IOUs with values f(t) due in time 1, 2, 3, and so on. Then the present value of this asset is the geometric series sum of the discounted future cash flows. This is called discounted cash flows (DCF). Congrats, now you can do better modeling than what goes into many early-stage venture deals. +------+-----+-----+---------+---------+---------+-------+---------+ | Year | 0 | 1 | 2 | 3 | 4 | ... | t | +------+-----+-----+---------+---------+---------+-------+---------+ | Cash | CF1 | CF2 | CF3 | CF4 | CF5 | ... | CF_t | | Flow | | | | | | | | +------+-----+-----+---------+---------+---------+-------+---------+ | Disc.| CF1 |_CF2_| __CF3__ | __CF4__ | __CF5__ | ... | _CF_t__ | | Val | | 1+r | (1+r)^2 | (1+r)^3 | (1+r)^4 | | (1+r)^t | +------+-----------+---------+---------+---------+-------+---------+ IOU 1 IOU 2 IOU 3 IOU 4 IOU 5 ... IOU n inf _ f(t) 1 DCF = \ ------- = (assume constant annual cash flow x) = --------- x /_ (1+r)^t 1-1/(1+r) t=0 = (1/r + 1) x Cash flow multiple = (value) / (annual cash flow) ~= 1/r (The astute reader might also find that they can go backwards from valuations to estimate first, second, ... Nth derivatives of the cash flow or the year-to-year survival chances of a company. And these can be compared with...going outside and touching grass to see if the valuation actually makes sense.) At this point, you're probably wondering why I'm boring you with all of this dry quant finance 101 shit. Well, it's a useful thing to know about how the world works. First, interest rates affect you directly and personally. You may have heard of the term "zero interest rate environment". In a low interest rate environment, cash flow becomes irrelevant. Why? Consider the DCF geometric series sum if the interest rate r = 0. The present value approaches infinity. If the benchmark hurdle rate we're trying to beat is 0%, literally ANYTHING is a better investment than holding onto cash. Now do you see why VCs were slamming hundreds of millions into blatantly bad deals and shit companies during Covid? Cash flow and profitability didn't matter, because you could simply borrow more money from the money printer. Here's a more concrete example. Do you remember a few years ago when Uber rides were so cheap, that they were clearly losing money on each ride? This is known as Customer Acquisition Cost, or CAC. CAC is basically the company paying you to use their app, go to their store, subscribe to the thing, ... whatever. The strategy is well-known: burn money to acquire users until everyone else dies and you become a monopoly. Then raise the prices. But here is the key point: this only works in a low-interest rate environment. In such an environment, discounting is low, and thus, future growth potential is valued over profitability and fundamentals at present. It doesn't need to make sense *today* as long as it works 10 years from now. For now, we can keep borrowing more money to sustain the burn. Of course, when rates go back up, the free money machine turns off and the effects ripple outward. You are the humble CAC farmer, farming CAC from various unprofitable consumer apps like ride share, food delivery, whatever. These apps raise their money from their investors, VC and growth equity funds. These funds in turn raise their money from *their* investors, their limited partners. These LPs might be institutional capital like pension funds, sovereign wealth funds, or family offices. At the end of the day, all of that wealth is generated somewhere throughout the economy by ordinary people. So when some VC-backed founders throw an extravagant party on a boat with fundraised dollars, in some sense, you are the one paying for it. And when the money machine turns off, anyone who had gotten complacent under ZIRP is now left scrambling. Companies will overhire during ZIRP only to do layoffs when rates go up. +=========================+ | THE LIQUIDITY CYCLE | +=========================+ VENTURE CAPITAL _______________ ,.-^=^=^=^=^=^=^=^=^=^;, ,;===============&amp;gt;&amp;gt; E^ a16z LSVP Tiger '^3. .;^ E^ FF Social Cap. '^3 // condensation .E Bain SoftBank Accel 3^ /|^ ^E KP Benchmark :^ || ^;: YC Greylock GC ;3' ,.^-^-^-^-^-^-^-^-^-^-^;, ^.=.=_=_=_=_=_=_=_=_=_=_=^ E^ endowments family '^:. \\\\\\\\\\\\\\\\\\\\ E^ offices '^3 \\\\\\\\\\\\\\\\\\\\ E' pension ^3. SOURCE \\\ precipitation \\ ^; funds sovereign 3.' CAPITAL \\\\\\\\\\\\\\\\\\\\ E;: wealth funds ,3^ (LPs) \\\\\\\\\\\\\\\\\\\\ ^;._.._._._._._._._._._._,^ \\\\\\\\\\\\\\\\\\\\ /\ ^ ^ ^ ^ ^ ^ ^ ^ gamefi /\ /\ uber eats | | | | | | | | shitcoins/::\/::\ /::::\ /\ | evaporation | / doordash/^^^^^^\ /^^\ | | | | | | | | ____________ / \ / hello \ (poggers desu) /_____ lime ____ fresh ___\ \o/ \oXo/\oXoXo/ o '==========' UNPROFITABLE CONSUMER APPS | | | | | | /|\ Oo._ /\_/\ ,/// __/_\_/_X_\/_X_X_\_/_\__ /_________(@'w'@)_____________.,://' SOCIETY \'''''''' -...-''''''''''''''''' surface THE HUMBLE runoff CAC FARMER Second, credit is not inherently a bad thing if used responsibly. Take for example those Buy Now, Pay Later loans. Now that you are equipped with the concept of capital efficiency, wouldn't it technically better than paying cash to take an interest-free BNPL loan and temporarily stick the freed cash into an investment? (Barring other side effects, etc.) Third, the concept of net present value--i.e., credit--is the killer app of finance. It allows you to transport value from the future into today. Of course, that debt must be repaid in the future, unless you can figure out a way to kick the can down the road forever. For now, let's get back to stocks. ----[ 3.2 - Equities Now we have seen both sides of the coin. Asset value is twofold: speculative and fundamental. First, we saw speculative value as illustrated by crypto meme coins. Then, on the other hand, we examined fundamental value as illustrated by, e.g. a US Treasury. These two lie on two extremes of a spectrum. Some sectors and stocks are more speculative than others; Nvidia is practically a meme coin at this point, whereas something like Coca-Cola is like fixed income for boomers (NFA BTW). Most assets have a blend of both. Thinking about stocks, they (usually) have some fundamental value. Equities represent ownership of some asset, like a business. The business in theory generates dividends for shareholders, and this cash flow (or the net present value of future ones) represents the fundamental value of the business. As we've seen, assets with better cash flows are more valuable. In practice, buybacks can be used to create what is effectively a shareholder dividend in a more tax-advantaged way. Whereas with dividends, they are taxed as income, and this is realized immediately. With buybacks, they are taxed as capital gains, but crucially the gains are not realized until the asset is sold. This could be indefinitely far in the future, so it's more capital efficient. It has the added benefit that it helps pump the token, and imo this is kind of cute because it marries both the fundamental and speculative aspects. Meanwhile, like tokens, stocks are also supposed to go up. Here's an example: imagine a generic meme coin. Apart from Go Up, what does it do? Nothing. Even if it's a Governance Token, who cares when the founders and VCs hold all the voting power? Anyways, I'm describing Airbnb Class A Common Stock. Here's an excerpt from their S-1 [1] [2]: &amp;gt; We have four series of common stock, Class A, Class B, Class C, and &amp;gt; Class H common stock (collectively, our "common stock"). The rights of &amp;gt; holders of Class A, Class B, Class C, and Class H common stock are &amp;gt; identical, except voting and conversion rights ... Each share of Class A &amp;gt; common stock is entitled to one vote, each share of Class B common stock &amp;gt; is entitled to 20 votes and is convertible at any time into one share of &amp;gt; Class A common stock ... Holders of our outstanding shares of Class B &amp;gt; common stock will beneficially own 81.7% of our outstanding capital &amp;gt; stock and represent 99.0% of the voting power of our outstanding capital &amp;gt; stock immediately following this offering, ... Name of | Class B | % | % of Vot- Beneficial Owner | Shares | | ing Power -------------------------------------+------------+-------+----------- Brian Chesky | 76,407,686 | 29.1% | 27.1% Nathan Blecharczyk | 64,646,713 | 25.3% | 23.5% Joseph Gebbia | 58,023,452 | 22.9% | 21.4% Entities Affil. w/ Sequoia Capital | 51,505,045 | 20.3% | 18.9% Why do people buy tech stocks with inflated valuations? Some may because they believe that they will go up, that they will be more dominant, important, and valuable in the future. Like tokens, a large part of stocks' value is speculative. They are expressing their opinion on the future fundamentals. Others may simply because they believe others will believe that it is more valuable. Not fundamentals, this is an opinion about *pumpamentals*. Importantly, unlike fundamental value, speculative value can be created out of thin air. It is minted by *fiat*. Fundamental value is difficult to create, whereas speculative value can be created through hype and psychology alone. ----[ 3.3 - Shareholder Value For stocks, there are usually laws in place to protect investors, pushing the balance between "speculation" and "fundamentals" towards the latter. As a result, firms are generally legally obligated to act in their shareholders' best interests. This is good because normal people will be able to participate in the wealth generated by companies. And obviously, companies should not defraud their investors. However, the biggest *stake* holders in a business, are usually (in order): 1. The employees. No matter what, no one else is spending 8 hours a day, or ~33% of their total waking lifespan at this place. Whatever it is, I guarantee you the employees feel it the most. 2. The customers. The customers are the reason the business is able to exist in the first place. Non-profits are not exempt: their customers are their donors. 3. The local community / local environment / ecosystem. The business doesn't exist in a vacuum. The business has externalities, and those externalities affect most the immediate surrounding environment. 4. And in last place, the shareholders. They do not really do anything except contribute capital and hold the stock. Of course capital is important but they are not spending 8 hours a day here, they are not the reason the business exists, and in fact they might even live in a totally different country. For large, publicly-listed companies, the shareholders have one more unique difference from the other three stakeholders: liquidity. This difference is critical. Liquidity describes how easy it is to buy and sell an asset. A dollar bill is liquid. Bitcoin is liquid. A house is relatively illiquid. Stock in large, publicly-listed companies is also liquid. A shareholder can buy a stock one day and sell it the next. As a result, the relationship is non-commital and opens the opportunity for short-term thinking. There are many things a company could do which would benefit shareholders short term, while harming the other three stakeholders long term. While a shareholder can simply dump their position and leave, the mess created is left for the employees, customers, and community to clean up. (The SPAC boom was a pretty good example of this. Not all SPACs are bad, but a lot of pretty shit businesses publicly listed through SPACs then crashed. This is sad to me because some of that is early investors and founders dumping on retail like a crypto shitcoin, but dressed up because it's NYSE or NASDAQ. Get liquidity then bail.) Now, it is a misconception that stock companies must solely paperclip- maximize short-term shareholder value. However, this is how it often plays out due to fucked up shit in the public markets, like annoying activist hedge funds or executive compensation tied to stock price. And it is true that employees can be shareholders. And that is usually a good thing! But few public companies are truly employee-owned. Thinking about it from this perspective, the concept of maximizing shareholder value seems somewhat backwards. But *why* would one make this system where the priorities are seemingly inverted? One benefit is that it would make your currency extremely valuable. Suppose you want to do some shit on Ethereum (speculating on some animal token?), you will need to have native ETH to do that transaction. Similarly, if you want to invest in US securities you at some point need US Dollars. If you want to get a piece of that sweet $NVDA action, you need dollars. People want to buy American stocks. American companies perform well: they're innovative; they're not too heavily regulated; it's a business friendly environment. (Shareholder value comes first!) The numbers go up. Remember the token founder from earlier in the Asian Arrangement? Suppose you are a *country* in the situation above, with a valuable currency. Not only is your currency in demand and valuable, you are the issuing/minting authority for that token. Similar to the token founder, you can print valuable money and pay for things with it. And speaking of being a founder, let's talk about that! --[ 4 - Startup Blues Based on what we've set up so far, I will discuss some of the problems I see with many startups today and with startup culture. Much of the problems stem from misalignment between shareholders and the other stakeholders (employees, etc). A lot of this comes from the fundamentals of venture capital. VC is itself an asset class, like fixed income and equities. VCs pitch this to their limited partners, at some level, based on the premise that their VC fund will generate yield for them. The strategy is to identify stuff that will become huge and buy it while it's still small and really cheap. Like trading shitcoins, it's about finding what's going to moon and getting in early. In a typical VC fund, a small handful of the investments will comprise the entire returns of the fund, with all of the other investments being 0's. The distribution is very power law. This means we are not looking for 1x, 2x, or 3x outcomes; these may even be seen as failure modes. We are only interested in 20x, 50x, 100x, etc. outcomes. This is because anything less will be insufficient to make up for all the bad investments that get written down to zero. For the same reason, it only makes sense for VCs to invest in certain types of companies. Have you ever heard this one? "We invest in SOFTWARE companies!...How is this SCALABLE? What do the VENTURE SCALE OUTCOMES look like here?" This is because these kinds of companies are the ones with the potential to 100x. They want you to deliver a 100x. Or how about this one? "We invest in CATEGORY-DEFINING companies". At least in security, "category-defining" means a shiny new checkbox in the compliance / cyber insurance questionnaire. In other words, a new kind of product that people MUST purchase. The market is incentivized to deliver a product that meets the minimum bar to meet that checkbox, while being useless. I invite you to think of your favorite middleware or EDR vendors here. For passionate security founders considering raising venture, remember that this is what your "success" is being benchmarked against. _.,------------------------------_ .%' '&amp;amp;. .;' We partner with founders ^; ! building category-defining ;! ; companies at the earliest stages _; ^; _.^ ''-.______________ __________.-' / / / /^ / /^ /;^ /' _________ _________ _-' '. _-' '. ,^ '^_ ,^ '^_ /' '"' /' '"' ^' ^\^ ^' ^\^ : ^| : ^| : . . |) : . . |) : \ |) : \ |) : __\ ,; : __\ ,; " ! ; " ! ; " ^\ _____ /' " ^\ _____ /' '| | ^\ _/^ '| | ^\ _/^ | ^'=====' | ^'=====' | . | | | . | | _' |^__ _' |^__ ---------_-' U '--_ -------------_-' U '--_ ----- ._ _.-' '-._ _.-' '- ':.' \ ; / ': .' \ ; / [4] It's due to the thirst for 100x that there are painful dynamics. A fledgling startup may have founders they really like, but the current business may be unscalable. Bad VCs will push founders towards strategies, bets, models that have a 1% chance of working, but pay out 200x if they do. In the process they destroy a good business--one which has earned the trust of dutiful employees and loyal customers--all for a lottery ticket to build a unicorn. They will throw 100 darts at the dartboard and maybe 5 will land, but what is it like to be the dart? You may have good expected value, but all of that EV is from spikes super far away from the origin. Is it pleasant betting everything on this distribution? VC's want founders to be cult leaders. Have you ever heard this line? "We invest in great storytellers." Like what we saw with stocks and tokens, much of the easily-unlockable potential upside in assets is speculative. In essence, value can be created through narrative. Narrative *IS* value. Bad VC's will push founders to raise more capital at ever higher valuations (higher val = markup = fees), using narrative as fuel for the fire. Storytelling means "pump the token", and the job of the CEO is to (1) be the hype man and to raise (2) cash and (3) eyeballs. For this reason, Sam Altman and Elon are fine CEOs, regardless of other factors, because they are great at all three. Much to the detriment of founders' and their employees' psyche, investors expect founders to be this legendary hype man. This requires a religiosity of belief that is borderline delusional. Have you ever tried to convince one of those Silicon Valley YC-type founder/CEOs that they are wrong? They will never listen to you because they have been socialized to be this way. It is what is expected of them, and it is easy to fall into this trap without even becoming aware of it. But if you think about it, does it make sense that to be a business owner, you need to be a religious leader? Of course not. All of these reasons are why so many startup founders are young. They have little to lose, so gambling it all is OK. Being a cult leader may be traumatizing, but they have time (and the neuroplasticity) to heal. And lastly, they do not have the life experience to have a mature personal identity beyond "I am a startup founder". All of this makes it easy to accept the external pressures to build a company this or that way. And perhaps not the way they would have wanted to, relying instead on their personal values. The true irony is that the latter is what creates true, enduring company culture and not the made-up Mad Libs-tier Company Culture Notion Page shit that so many startups have. And of course, good VCs are self-aware of all of the issues and strive to prevent them. But the overall problem remains. One last externality is for communities based around an industry. When you add billions of venture dollars into an industry, it becomes cringe. It's saddening to me seeing the state of certain cybersecurity conferences which are now dominated by..."COME TO OUR BOOTH, YOU CAN BE A HACKER. PLEASE VIEW OUR AI GENERATED GRAPHICS OF FIGURES CLAD IN DARK HOODIES STATIONED BEHIND LAPTOPS". Here I would use the pensive emoji U+1F614 to describe my feelings about the appropriation of hacker culture but Phrack is 7-bit ASCII, so please have this: :c u_u . _. --[ 5 - Takeaways The point is, all of this made me feel very small and powerless after I realized the sheer size of the problems I was staring at. Nowadays, to me it's about creating good jobs for my friends, helping our customers, and taking care of the community. Importantly, I realized that this is still making a bigger positive impact than what I could have done alone just as an individual hacker or engineer. To me, businesses are economic machines that can create positive (or negative) impact in a consistent, self-sustaining way. There are many people who are talented, kind, and thoughtful but temporarily unlucky. Having a company let me help these friends monetize their abilities and be rewarded fairly for them. And in that way I helped make their life better. Despite a lot of the BS involved in running a business, this is one thing that is very meaningful to me. You can understand computers and science and math as much as you want, but you will not be able to fix the bigger issues by yourself. The systems that run the world are much bigger than what we can break on our laptops and lab benches. But like those familiar systems, if we want to change things for the better, we have to first understand those systems. Knowledge is power. Understanding is the first step towards change. If you do not like the system as it is, then it is your duty to help fix it. Do not swallow blackpills. It's easy to get really cynical and think things are doomed (to AGI apocalypse, to environmental disaster, to techno/autocratic dystopia, whatever). I want to see a world where thoughtful hackers learn these systems and teach each other about them. That generation of hackers will wield that apparatus, NOT THE OTHER WAY AROUND. Creating leverage for yourself. Hackers should not think of themselves as "oh I am this little guy fighting Big Corporation" or whatever. This is low agency behavior. Instead become the corporation and RUN IT THE WAY YOU THINK IT SHOULD BE RUN. Keep it private and closely held, so no one can fuck it up. Closely train up successors, so in your absence it will continue to be run in a highly principled way that is aligned with your values and morals. Give employees ownership, as it makes everyone aligned with the machine's long-term success, not just you. Raising capital. Many things do really need capital, but raise in a responsible way that leaves you breathing room and the freedom to operate in ways that are aligned with your values. Never compromise your values or integrity. Stay laser focused on cash flows and sustainability, as these grant you the freedom to do the things right. HACKERS SHOULDN'T BE AFRAID TO TOUCH THE CAPITAL MARKETS. Many hackers assume "oh that fundraising stuff is for charismatic business types". I disagree. It's probably better for the world if good thoughtful hackers raise capital. Giving them leverage to change the world is better than giving that leverage to some psycho founder drinking the Kool-Aid. I deeply respect many of the authors in Phrack 71, and I would trust them to do a better job taking care of things than an amorphous amalgam of angry and greedy shareholders. For all things that don't need capital, do not raise. Stay bootstrapped for as long as possible. REMEMBER THAT VALUATION IS A VANITY METRIC. Moxie Marlinspike wrote on his blog [3] that we are often guilty of always trying to quantify success. But what is success? You can quantify net worth, but can you quantify the good you have brought to others lives? For personal goals, think long term. People tend to overestimate what they can do in 1 year, but underestimate what they can do in 10. DO NOT start a company thinking you can get your hands clean of it in 2-3 years. If you do a good job, you will be stuck with it for 5-10+ years. Therefore, DO NOT start a company until you are sure that is what you want to do with your life, or at least, your twenties/thirties (depending on when you start). A common lament among founders, even successful ones, is: "Sometimes I feel like I'm wasting my twenties". There's an easy Catch-22 here: you may not know what you really want until you do the company; but once you do the company, you won't really be able to get out of it. Be wary of that. Creating value. This is one of those meaningless phrases that I dislike. Value is what you define it to be. Remember to work on things that have TAMs, but remember that working on art is valuable too! It is not all about the TAM monster--doing cool things that are NOT ECONOMICALLY VALUABLE, but ARTISTICALLY VALUABLE, is equally important. There is not much economic value in a beautiful polyglot file, but it is artistically delightful. This is part of why people hate AI art: it may be economically valuable, but it is often artistically bankrupt. (Some people do use generative tools in actually original and artistic ways, but this is the exception not the norm currently.) Founders vs Investors. Here is my advice: Ignore any pressure from investors to make company "scalable" or whatever. Make sure your investors have no ability to fire you or your co-founder(s). Make sure you and co-founder are always solid and trust each other more than investors. You and your cofounders need to be BLOOD BROTHERS (/sisters/w.e). If an investor is trying to play politics with one of you to go against the other cofounder, cut that investor out immediately and stop listening to them. Any investor who pushes for scalability over what you think is the best interest of the company is not aligned with you. High-quality investors will not push for this because they are patient and in it for the long game. If you are patient, you can make a very successful company, even if it is not that scalable. High-quality investors will bet on founders and are committed; only bad ones will push for this kind of shit. I'm going to avoid giving more generic startup advice here. Go read Paul Graham's essays. But remember that any investor's perspective will not be the perspective of you and your employees. Pivoting 5 times in 24 months is not a fun experience to work at: your employees will resign while your investors celebrate your "coming of age journey"--unless everyone signed up for that terrifying emotional rollercoaster from the start. They say that "hacker" is a dying identity. Co-opted by annoying VC-backed cybersecurity companies that culturally appropriate the identity, the term is getting more polluted and diluted by the day. Meanwhile, computers are getting more secure, and they are rewriting everything in Rust with pointers-as-capability machines and memory tagging. Is it over? I disagree. As long as the hacker *ethos* is alive, regardless of any particular scene, the identity will always exist. However, now is a crucible moment as a diaspora of hackers, young and old, venture out into the world. Calling all hackers: never forget who you are, who you will become, and the mark you leave. --[ 6 - Thanks Greetz (in no particular order): * ret2jazzy, Sirenfal, ajvpot, rose4096, Transfer Learning, samczsun, tjr, claire (aka sport), and psifertex. * perfect blue, Blue Water, DiceGang, Shellphish, and all CTF players. * NotJan, nspace, xenocidewiki, and the members of pinkchan and Secret Club. * Everyone at Zellic, past and present. Finally, a big thank you to the Phrack staff (shoutout to netspooky and richinseattle!) for making this all possible. --[ 7 - References [1] https://www.sec.gov/Archives/edgar/data/1559720/000119312520315318/ d81668d424b4.htm [2] https://www.sec.gov/Archives/edgar/data/1559720/000119312522115317/ d278253ddef14a.htm [3] https://moxie.org/stories/promise-defeat/ [4] https://twitter.com/nikitabier/status/1622477273294336000 --[ 8 - Appendix: Financial institution glossary for hackers (Not serious! For jokes... :-) - IB: Investment Bank. Basically collect fat fees to do up ("advise on") M&amp;amp;As and other transactions. Help match buyers and sellers for your private equity. They are like CYA for your deal. - PE: Private Equity. Basically buy not-overly-seriously ("poorly") run companies, fire the management, then run it "professionally" (i.e. make it generally shitty for customers and employees and community for the benefit of shareholders) - HF: Hedge Fund. Trade out pricing inefficiencies - MM: Market Maker. Basically the same thing - VC: Basically gamble on tokens (crypto or stocks) and back cool and/or wacky ideas that the rest of these people find too stinky to invest in - PnD: Pump and Dump. - TVL: Total Value Locked. Basically how much money is currently in a blockchain or smart contract system. - TPS: Transactions Per Second. A measure of how scalable or useful a blockchain or database is. An oft-abused metric hacked by vaporware shillers for hype and PnD purposes. - TAM: Total Addressable ~~Memory~~ Market. Basically how much money a given idea can make. - NFA: Not finanical advice. |=[ EOF ]=---------------------------------------------------------------=| &lt;/quote&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://phrack.org/issues/71/17"/><published>2026-01-06T20:24:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518573</id><title>A 30B Qwen model walks into a Raspberry Pi and runs in real time</title><updated>2026-01-07T09:18:55.074692+00:00</updated><content>&lt;doc fingerprint="3edb28de9d388188"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; A 30B Qwen Model Walks Into a Raspberry Pi√¢¬¶&lt;lb/&gt; and Runs in Real Time &lt;/head&gt;
    &lt;p&gt;For this release, we optimize for what people actually experience when they run a model: fast, high-quality responses on a specific target device.&lt;/p&gt;
    &lt;p&gt;We use Shapelearn, our bitlength learning method to choose weight datatypes for Qwen3-30B-A3B-Instruct-2507 that maximize performance in terms of tokens per second (TPS) and output quality, with one practical constraint: the model must fit comfortably in the available memory. Once it fits, making the file smaller isn't a goal by itself. We only shrink further when it also improves the real tradeoff people care about: speed vs. quality.&lt;/p&gt;
    &lt;p&gt;Approaching bitlength learning this way matters because in llama.cpp, "fewer bits" doesn't automatically mean "more speed." Different quantization formats can trigger different kernels and overheads, and on some GPUs, going lower-bit can even get slower, despite using less memory.&lt;/p&gt;
    &lt;p&gt;Bottom line: treat memory as a budget to meet, then optimize what matters most: TPS and quality.&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt; Yes, this 30B Qwen3 runs on a Raspberry Pi. On a Pi 5 (16GB), &lt;code&gt;
              
                Q3_K_S-2.70bpw [KQ-2]
              
            &lt;/code&gt;
            hits 8.03 TPS at 2.70 BPW and maintains 94.18% of BF16 quality. It genuinely feels
            real-time. More broadly, the same pattern shows up everywhere else: ByteShape models
            give you a better TPS/quality tradeoff than the alternatives (here we look at Unsloth
            and MagicQuant).
          &lt;/p&gt;
    &lt;head rend="h2"&gt;CPUs&lt;/head&gt;
    &lt;p&gt;On CPUs, the reducing footprint via shorter bitlengths affects the TPS and accuracy tradeoff as one would expect: once the model fits, reducing footprint tends to increase TPS in a fairly monotonic way. If datatypes are selected correctly, you can trade a bit of quality for speed predictably, which makes it much easier to pick a point on the curve that matches your constraints.&lt;/p&gt;
    &lt;p&gt;We'll start with the most memory-constrained CPU case (Raspberry Pi 5 16GB), where "fits in RAM" is the limiting factor, then move to an Intel i7 with 64GB, where everything fits.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 5&lt;/head&gt;
    &lt;p&gt;The figure below shows TPS vs. normalized accuracy for the models that fit in RAM on the Raspberry Pi 5 16GB.&lt;/p&gt;
    &lt;p&gt;Notably, sustaining 8.5 TPS at 92%+ baseline accuracy with a 30B model on a Raspberry Pi reshapes expectations for Pi-class systems. Overall, the trend shows that ShapeLearn consistently produces better models, with ByteShape trending up and to the right of Unsloth, achieving higher tokens per second at the same quality, or higher quality at the same throughput.&lt;/p&gt;
    &lt;p&gt;We highlight choices for two primary objectives: accuracy or response time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Optimizing for response time while maintaining accuracy: For interactive, on-device use, perceived responsiveness is driven by how quickly text appears, not peak throughput. In practice, generation feels real-time once it reaches roughly 8 TPS, comfortably above typical reading speed. In this Raspberry Pi real-time regime, &lt;code&gt;Q3_K_S-2.70bpw [KQ-2]&lt;/code&gt;(2.70 BPW, 8.03 TPS, 94.18% accuracy) is our go-to recommendation: it crosses the real-time threshold while maintaining high accuracy. Compared to Unsloth models at similar quality, ByteShape achieves real-time performance at lower BPW and higher TPS, making it the more efficient choice for interactive edge deployment.&lt;/item&gt;
      &lt;item&gt; Accuracy above all: The table below lists the models that achieve the highest accuracy while still being able to run on a Raspberry Pi. Within this set, ByteShape models make the best use of the available resources to maximize accuracy, occupying the lowest-error rows (~1.1√¢1.3% relative error, ~98.8% accuracy), while the strongest Unsloth entries remain around 2.1√¢2.2% error (~97.9% accuracy). Compared to Unsloth's &lt;code&gt;UD-Q3_K_XL [8]&lt;/code&gt;, ByteShape achieves up to a 1.87√É lower error rate while still operating at ~5√¢6 TPS, comfortably within TPS-norms on Raspberry PI making it the better choice when accuracy is the priority.&lt;lb/&gt;Even when prioritizing maximum speed with some reduction in accuracy,&lt;code&gt;Q3_K_S-3.25bpw [KQ-5]&lt;/code&gt;offers a better tradeoff: more accurate, smaller, and faster than the fastest Unsloth model.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Relative Error&lt;/cell&gt;
        &lt;cell role="head"&gt;BPW&lt;/cell&gt;
        &lt;cell role="head"&gt;TPS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;
                    
                      Q4_K_S-3.92bpw [KQ-7]
                    
                  &lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1.14%&lt;/cell&gt;
        &lt;cell&gt;3.92&lt;/cell&gt;
        &lt;cell&gt;5.30&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;
                    
                      Q4_K_S-3.61bpw [KQ-6]
                    
                  &lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1.25%&lt;/cell&gt;
        &lt;cell&gt;3.61&lt;/cell&gt;
        &lt;cell&gt;5.94&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;
                    
                      Q3_K_S-3.25bpw [KQ-5]
                    
                  &lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2.03%&lt;/cell&gt;
        &lt;cell&gt;3.25&lt;/cell&gt;
        &lt;cell&gt;6.68&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;UD-IQ3_XXS [6]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2.22%&lt;/cell&gt;
        &lt;cell&gt;3.38&lt;/cell&gt;
        &lt;cell&gt;5.03&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;UD-Q3_K_XL [8]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2.13%&lt;/cell&gt;
        &lt;cell&gt;3.62&lt;/cell&gt;
        &lt;cell&gt;6.28&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Many other Unsloth and MagicQuant models (some of ours too!) are not in this chart. We compare them in other sections, but they're not applicable in the Raspberry Pi case. They simply don't fit!&lt;/p&gt;
    &lt;head rend="h3"&gt;Intel i7&lt;/head&gt;
    &lt;p&gt;Next, we move to the Intel i7 with 64GB RAM. The figure below shows TPS vs normalized accuracy for all models.&lt;/p&gt;
    &lt;p&gt;Overall, ByteShape models outperform both Unsloth and MagicQuant, delivering higher quality at comparable throughput using fewer bits per parameter. Only ByteShape offers models that run in the 26+ TPS range, extending performance well beyond the other methods.&lt;/p&gt;
    &lt;p&gt;Highlights:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Quality-first: At the high-accuracy end of the table, &lt;code&gt;IQ4_XS-4.67bpw [KQ-9]&lt;/code&gt;achieves the lowest relative error (0.25%), outperforming the best-running Unsloth models (&lt;code&gt;Q6_K [20]&lt;/code&gt;and&lt;code&gt;Q5_K_M [18]&lt;/code&gt;whose relative errors are 0.36% and 0.44%). Compared directly, ByteShape delivers up to a 1.44√É lower error rate with higher throughput than&lt;code&gt;Q6_K [20]&lt;/code&gt;, and a 1.76√É lower error rate at essentially the same speed as&lt;code&gt;Q5_K_M [18]&lt;/code&gt;. MagicQuant&lt;code&gt;mxfp4 [3]&lt;/code&gt;trails in this regime, with both higher error and lower TPS.&lt;/item&gt;
      &lt;item&gt; Balanced point: In the mid-accuracy, high-throughput region, &lt;code&gt;Q3_K_S-3.25bpw [KQ-5]&lt;/code&gt;combines ~98% accuracy with 23.1 TPS at just 3.25 BPW, offering the best overall balance in the table. Matching or exceeding this accuracy with Unsloth (&lt;code&gt;IQ4_XS [10]&lt;/code&gt;) requires higher BPW and lower TPS, while choosing an Unsloth model closer in speed (&lt;code&gt;Q3_K_S [7]&lt;/code&gt;) incurs a 1.73√É higher error rate. MagicQuant does not offer a competitive model in this range; its fastest entry (&lt;code&gt;IQ4_NL [2]&lt;/code&gt;) is behind both ByteShape and Unsloth in accuracy and throughput.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Takeaway: Across both quality-first and balanced settings, ByteShape consistently converts the available bit budget into either higher accuracy or higher TPS, and is the only approach that simultaneously covers the high-quality and 26+ TPS balanced-performance regions in this comparison.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPUs: RTX5090/32GB and RTX4080/16GB&lt;/head&gt;
    &lt;p&gt;On GPUs, performance depends as much on kernel choice as on raw memory footprint. For matmul/matvec, llama.cpp's quantization-specific GPU decode paths incur very different overheads, so fewer bits per weight do not reliably translate to higher TPS. Instead, TPS often peaks at quantization-specific sweet spots. Pushing BPW lower can even increase VRAM traffic and instruction count, hurting performance rather than improving it. We dig into this behavior in more detail right after the GPU results section, where the kernel-level tradeoffs become more apparent.&lt;/p&gt;
    &lt;p&gt;We evaluate on two GPUs: an RTX 5090 (32 GB), which can run models above 4 BPW and typically reach the fastest sweet spots, and an RTX 4080 (16 GB), where &amp;gt;4 BPW models do not fit, forcing different trade-offs and making the device-optimized curve easier to see.&lt;/p&gt;
    &lt;head rend="h3"&gt;RTX 5090 (32GB of VRAM)&lt;/head&gt;
    &lt;p&gt;Let's start with the 5090, which has enough VRAM to support all of the quantized models. The figure below shows TPS vs normalized accuracy.&lt;/p&gt;
    &lt;p&gt; Two things stand out immediately:&lt;lb/&gt; First, this GPU shows a clear ~4-bit sweet spot: several ~4b models cluster at very high TPS with nearly identical quality. Examples include &lt;code&gt;Unsloth Q4_0 [12]&lt;/code&gt;, &lt;code&gt;Unsloth IQ4_XS [10]&lt;/code&gt;,
            &lt;code&gt;
              
                IQ4_XS-3.87bpw [IQ-6]
              
            &lt;/code&gt;
            , and MagicQuant &lt;code&gt;iq4_nl-EHQKOUD-IQ4NL [1]&lt;/code&gt;, all running around ~302√¢303 TPS
            at ~98.4√¢98.9% accuracy. Within 
            this tight cluster, Unsloth edges out slightly in throughput and quality.
          &lt;/p&gt;
    &lt;p&gt;Second, outside of that sweet spot, the tradeoff becomes much more uneven:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Many other Unsloth and Magic Quant models show significantly lower TPS, regardless of whether they are quantized more or less aggressively.&lt;/item&gt;
      &lt;item&gt;Past the ~4b region, only ByteShape continues to increase TPS with a more predictable reduction in quality.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Accuracy-critical workloads: when output quality is paramount, ByteShape delivers the most accurate model on the 5090: &lt;code&gt;
              
                IQ4_XS-4.67bpw [IQ-8]
              
            &lt;/code&gt;
            (4.67 BPW, 272.98 TPS, 99.75% accuracy). It surpasses &lt;code&gt;Unsloth Q6_K [20]&lt;/code&gt; (6.57 BPW, 264.88 TPS, 99.64% accuracy) 
            while using fewer bits and achieving slightly higher throughput, and it clearly outperforms MagicQuant 
            &lt;code&gt;mxfp4_moe-H-B16-EUR-IQ4NL-KO-Q5K-QD-Q6K [3]&lt;/code&gt; (5.46 BPW, 240.42 TPS, 99.32% accuracy) in both 
            accuracy and speed, making it the strongest choice when accuracy is a task-critical deployment requirement.
          &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Practical takeaway. If your GPU has enough VRAM to run a strong ~4b model that already meets your speed and accuracy requirements, that cluster is an excellent default. The curve becomes more interesting when task-critical deployment constraints demand higher accuracy or smaller models as for example, under tighter memory budgets or constrained environments (as we'll see on the 4080). &lt;/p&gt;
    &lt;head rend="h3"&gt;RTX 4080 (16GB of VRAM)&lt;/head&gt;
    &lt;p&gt;Next, let's move to a more accessible GPU, especially in these memory-challenged times. The biggest stumbling block for the 4080 is its 16GB of VRAM, which is not sufficient to support the "magical" ~4b quantizations for a 30B model. How convenient! This "avoids" the 5090's ~4b sweet spot and forces a more "real-world" comparison under a hard VRAM budget. The figure below shows TPS versus normalized accuracy for all models that fit on the 4080.&lt;/p&gt;
    &lt;p&gt;On the RTX 4080, ByteShape consistently outperforms Unsloth under the same 16 GB VRAM constraint, delivering a better TPS√¢quality tradeoff.&lt;/p&gt;
    &lt;p&gt; In particular, ByteShape's highest-quality model that fits, &lt;code&gt;
              
                IQ4_XS-3.87bpw [IQ-6]
              
            &lt;/code&gt;
            (3.87 BPW, 214.81 TPS, 98.66% accuracy) delivers:
          &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; a 1.59√É lower error rate and 9.4% higher TPS vs. &lt;code&gt;Unsloth Q3_K_XL [8]&lt;/code&gt;(3.62 BPW, 196.42 TPS, 97.87% accuracy).&lt;/item&gt;
      &lt;item&gt; a 2.54√É lower error rate at the same TPS vs. &lt;code&gt;Unsloth IQ2_M [2]&lt;/code&gt;(2.84 BPW, 214.79 TPS, 96.59% accuracy).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we move to higher throughput, ByteShape's maintains accuracy, while Unsloth's error rate experiences a cliff.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Elephant in the Room: When 3-bits is not just 3-bits&lt;/head&gt;
    &lt;p&gt;There is an inconvenient truth hiding in these results. On several setups, around 4 bpw is already flying, and pushing quantization harder does not make things faster. It just manages to be smaller and slower at the same time.&lt;/p&gt;
    &lt;p&gt;Reducing the size of data doesn't automatically speed things up. While using fewer bits to store each number seems like it should reduce memory traffic and speed up computation, GPUs don't work that way. NVIDIA GPUs process work in fixed groups of 32 threads called "warps," which move through instructions together in near lock-step. The GPU hardware is optimized for specific data formats, memory access patterns, and operations that the chip's circuits are physically designed to handle efficiently. When your workload matches these "golden paths", you get peak performance. Step outside them, and you hit slowdowns. This isn't a design flaw, it's a deliberate tradeoff. Supporting more flexibility would require additional circuitry: more wires, more transistors, more complexity. That extra hardware consumes more power and adds latency to every operation, whether a program needs that flexibility or not.&lt;/p&gt;
    &lt;p&gt;Here a few examples of relevant hardware "quirks": VRAM is read in aligned 32-byte blocks, so reading one or 32 bytes consumes the same memory bandwidth. Both on-chip and off-chip memories can also suffer contention depending on how data is laid out, meaning that a warp's accesses may complete in a single step or, in the worst case, be serialized into 32 steps. And of course, decoding quantized values before computation can require extra instructions, with the cost depending on the quantization scheme.&lt;/p&gt;
    &lt;p&gt;This explains the behaviour we observe: 4-bit kernels use VRAM bandwidth more efficiently than 3- or 2-bit kernels and require fewer decode steps before computation. At the same time, 4-bit kernels exploit subword parallelism just as effectively as lower-bit kernels, and all rely primarily on dynamic caches rather than shared memory to take advantage of data reuse when possible.&lt;/p&gt;
    &lt;p&gt;So why llama.cpp hasn't been optimized to deliver peak speed for every bit-length? Our understanding is that llama.cpp prioritizes portable, space-efficient quantization that can run across a wide range of hardware. That design goal limits how aggressively backends can reshape data layouts or reorder computation in ways that might help one GPU or one bit-width.&lt;/p&gt;
    &lt;p&gt;A key example is its choice to store quantized weights in fixed blocks of 256 values. Each block is self-contained (it carries everything needed to decode it) and sits at a simple, predictable offset in the tensor, which makes the format easy to implement and fast to locate.&lt;/p&gt;
    &lt;p&gt;The tradeoff is that GPUs often need to decode many blocks in parallel to keep their wide compute units busy. With many independent 256-value blocks, those parallel decodes can translate into more scattered or fragmented VRAM reads and extra decode overhead, reducing bandwidth efficiency, especially for some lower-bit formats.&lt;/p&gt;
    &lt;p&gt; Point for example on RTX 5090: a matrix multiply [256, 768] √É [768, 2048] takes ~54√Ç¬µs with &lt;code&gt;iq4_xs&lt;/code&gt; datatype, but ~62√Ç¬µs with 
            &lt;code&gt;iq3_xxs&lt;/code&gt; (mul_mat_q()+mul_mat_q_stream_k_fixup()). In other words, 
            cutting nearly 1.2 bits per weight (a reduction of more than 25% in weight footprint) leads 
            to a ~13% slowdown, directly hurting user experience.
          &lt;/p&gt;
    &lt;p&gt;An excellent reminder that bitlength learning matters: Heuristics can get us part of the way, but not all the way. ShapeLearn makes deliberate, per-tensor datatype choices that improve speed without sacrificing accuracy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methodology (brief recap)&lt;/head&gt;
    &lt;p&gt;If you're wondering how we are scoring these points, the full methodology is discussed in our previous blog post. This post is intentionally focused on the curves and device tradeoffs, so here is the quick version.&lt;/p&gt;
    &lt;p&gt;For each quantized variant, we measure throughput (TPS) on the target device and compute a single normalized quality score relative to the BF16 baseline, using the same evaluation harness and prompts as the methodology post. The quality score aggregates standard benchmarks (MMLU, GSM8K, IFEval, LiveCodeBench V4) into one number so you can compare points directly. In other words, every dot in the plots answers two questions: how fast does it run on this device, and how much quality does it retain compared to BF16, with memory fit as the first constraint.&lt;/p&gt;
    &lt;p&gt;We also want to thank all for the many, excellent suggestions on our recent Reddit post for improving and extending this evaluation strategy, and we√¢re actively working through them. Right now, evaluation is the main bottleneck and not bitlength learning/quantization. Careful evaluation is essential to clearly communicate the strengths of each model.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping up&lt;/head&gt;
    &lt;p&gt;First, thank you for your tenacity. You made it through all of this without giving up. We are sincerely flattered!&lt;/p&gt;
    &lt;p&gt;The takeaway is simple: treat memory as a constraint, not a goal. Once a model fits on your device, what matters is the tradeoff curve, TPS versus quality. Across CPUs and GPUs, ByteShape consistently lands on the better side of that curve, delivering either more speed at the same quality or higher quality at the same speed.&lt;/p&gt;
    &lt;p&gt; If you're deploying on a Raspberry Pi 5 (16 GB) and want a genuinely interactive experience, start with &lt;code&gt;
              
                Q3_K_S-2.70bpw [KQ-2]
              
            &lt;/code&gt;
            . On larger CPUs or GPUs, you can move up the curve toward higher-quality points with
            little loss in throughput, the same rule applies:
            fit first, then optimize the tradeoff.
          &lt;/p&gt;
    &lt;p&gt;We'll keep releasing more device-targeted variants (and more plots). If your system can't run a 30B model smoothly, don't blame the model or the silicon. Blame the datatypes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/"/><published>2026-01-06T20:55:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518804</id><title>Oral microbiome sequencing after taking probiotics</title><updated>2026-01-07T09:18:54.868594+00:00</updated><content>&lt;doc fingerprint="8a7c03af02b6652a"&gt;
  &lt;main&gt;
    &lt;p&gt;Recently, a friend recommended BioGaia Prodentis to me. It is a DTC oral probiotic you can buy online that is supposedly good for oral health. I thought it would be interesting to do some sequencing to see what, if anything, it did to my oral microbiome.&lt;/p&gt;
    &lt;p&gt;BioGaia Prodentis is available online for $20 or less for a month's supply&lt;/p&gt;
    &lt;head rend="h1"&gt;BioGaia&lt;/head&gt;
    &lt;p&gt;BioGaia has a fascinating story. They are a Swedish company, founded over 30 years ago, that exclusively sells probiotics DTC. They have developed multiple strains of Limosilactobacillus reuteri, mainly for gut and oral health. They apparently sell well! Their market cap is around $1B‚Äîimpressive for a consumer biotech.&lt;/p&gt;
    &lt;p&gt;Going in, I expected scant evidence for any real benefits to their probiotics, but the data (over 250 clinical studies) is much more complete than I expected.&lt;/p&gt;
    &lt;p&gt;Most notably, their gut probiotic, Protectis, seems to have a significant effect on preventing Necrotizing Enterocolitis (NEC) in premature babies. According to their website:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;5-10% of the smallest premature infants develop NEC, a potentially lethal disorder in which portions of the bowel undergo tissue death.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In March 2025, the FDA granted Breakthrough Therapy Designation to IBP-9414, an L. reuteri probiotic developed by BioGaia spinout IBT.&lt;/p&gt;
    &lt;p&gt;This is not specifically for the oral health product, but it's for sure more science than I expected to see going in.&lt;/p&gt;
    &lt;head rend="h3"&gt;Prodentis&lt;/head&gt;
    &lt;p&gt;BioGaia Prodentis contains two strains of L. reuteri: DSM 17938 and ATCC PTA 5289. The claimed benefits include fresher breath, healthier gums, and outcompeting harmful bacteria.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sequencing with Plasmidsaurus&lt;/head&gt;
    &lt;p&gt;Many readers will be familiar with Plasmidsaurus. Founded in 2021, the team took a relatively simple idea: use massively multiplexed Oxford Nanopore (ONT) to offer complete plasmid sequencing with one day turnaround for $15, and scaled it. Plasmidsaurus quickly became part of biotech's core infrastructure, and spread like wildfire. It also inspired multiple copycats.&lt;/p&gt;
    &lt;p&gt;Compared to Illumina, ONT is faster and has much longer reads, but lower throughput and lower accuracy. This profile is a great fit to many sequencing problems like plasmid QC, where you only need megabases of sequences, but want an answer within 24 hours.&lt;/p&gt;
    &lt;p&gt;Over time, Plasmidsaurus has been adding services, including genome sequencing, RNA-Seq, and microbiome sequencing, all based on ONT sequencing.&lt;/p&gt;
    &lt;p&gt;Plasmidsaurus accepts many kinds of sample for microbiome sequencing&lt;/p&gt;
    &lt;p&gt;I used their 16S sequencing product, which costs $45 for ~5000 reads, plus $15 for DNA extraction. 16S sequencing is an efficient way to amplify and sequence a small amount of DNA (the ubiquitous 16S region) and be able to assign reads to specific species or even strains.&lt;/p&gt;
    &lt;p&gt;This experiment cost me $240 for four samples, and I got data back in around a week. It's very convenient that I no longer have to do my own sequencing. As a side note, you can pay more for more than 5000 reads, but unless you want information on very rare strains (&amp;lt;&amp;lt;1% frequency), this is a waste of money.&lt;/p&gt;
    &lt;p&gt;Sample collection is simple: take 100-250 ¬µL of saliva and mix with 500 ¬µL of Zymo DNA/RNA Shield (which I also had to buy for around $70.) You also need 2 mL screwtop tubes to ship in.&lt;/p&gt;
    &lt;p&gt;The reads are high quality for nanopore sequencing, with a median Q score of 23 (99%+ accuracy). This is more than sufficient accuracy for this experiment. The read length is very tightly distributed around 1500 nt (the length of a typical 16S region).&lt;/p&gt;
    &lt;p&gt;The results provided by Plasmidsaurus include taxonomy tables, per-read assignments, and some basic plots. I include a download of the results at the end of this article, as well as the FASTQ files.&lt;/p&gt;
    &lt;head rend="h1"&gt;The experiment&lt;/head&gt;
    &lt;p&gt;The main idea of the experiment was to see if any L. reuteri would colonize by the end of 30 days of probiotic use, and if so, whether it would persist beyond that. I collected four saliva samples:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;Timing&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;Day -4&lt;/cell&gt;
        &lt;cell&gt;A few days before starting BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;Day -1&lt;/cell&gt;
        &lt;cell&gt;The day before I started BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;The last day of the 30 day course&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;Day 37&lt;/cell&gt;
        &lt;cell&gt;One week after completing the course&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Heatmap of the top 20 species. All species assignments were done by Plasmidsaurus&lt;/p&gt;
    &lt;head rend="h2"&gt;Did L. reuteri colonize?&lt;/head&gt;
    &lt;p&gt;There was no L. reuteri found in any of the samples. I did a manual analysis to check for any possible misassignments, but the closest read was only 91% identical to either L. reuteri strain.&lt;/p&gt;
    &lt;p&gt;The probiotic either (a) didn't colonize the oral cavity; (b) was present only transiently while actively taking the lozenges; (c) was below the detection threshold.&lt;/p&gt;
    &lt;p&gt;Probiotics are generally bad at colonizing, which is why you have to keep taking them. Still, I was surprised not to see a single L. reuteri read in there.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actually changed?&lt;/head&gt;
    &lt;p&gt;Even though the probiotic itself didn't show up, the oral microbiome did change quite a lot.&lt;/p&gt;
    &lt;p&gt;The most striking change was a massive increase in S. salivarius. S. salivarius went from essentially absent to ~20% of my oral microbiome on the last day. However, this happened one week after I stopped taking the probiotic, so it's very unclear if it is related.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;S. mitis&lt;/cell&gt;
        &lt;cell role="head"&gt;S. salivarius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;2.0%&lt;/cell&gt;
        &lt;cell&gt;0.4%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;15.9%&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;10.2%&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;1.0%&lt;/cell&gt;
        &lt;cell&gt;19.3%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We see S. mitis decreasing as S. salivarius increases, while the total Streptococcus fraction stayed roughly stable. It's possible one species replaced the other within the same ecological niche.&lt;/p&gt;
    &lt;p&gt;S. salivarius is itself a probiotic species. The strain BLIS K12 was isolated from a healthy New Zealand child and is sold commercially for oral health. It produces bacteriocins that kill Streptococcus pyogenes (strep throat bacteria).&lt;/p&gt;
    &lt;p&gt;At the same time, V. tobetsuensis increased in abundance from 2.1% to 5.7%. Veillonella bacteria can't eat sugar directly‚Äîthey survive by consuming lactate that Streptococcus produces. The S. salivarius bloom is plausibly feeding them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Are these changes real or intra-day variation?&lt;/head&gt;
    &lt;p&gt;There was a lot more variation in species than I expected, especially comparing the two baseline samples. In retrospect, I should have taken multiple samples on the same day, and mixed them to smooth it out.&lt;/p&gt;
    &lt;p&gt;However, there is some light evidence that the variation I see is not just intra-day variation. Specifically, there are several species that stay consistent in frequency across all samples: e.g., Neisseria subflava, Streptococcus viridans, Streptococcus oralis.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;L. reuteri didn't detectably colonize my mouth. Oral probiotics are surprisingly difficult to detect, even if you sample the same day as dosing.&lt;/item&gt;
      &lt;item&gt;S. salivarius increased massively in abundance, but this increase happened after I stopped taking BioGaia&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing can be used to assess oral health. None of the "red complex" bacteria (P. gingivalis, T. forsythia, T. denticola) associated with gum disease were found in any sample.&lt;/item&gt;
      &lt;item&gt;The oral microbiome is dynamic, with huge swings in species abundance over a timeframe of just weeks&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing is very easy and convenient these days thanks to Plasmidsaurus&lt;/item&gt;
      &lt;item&gt;Prodentis tastes good, may help with oral health, and I'd consider taking it again&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.booleanbiotech.com/oral-microbiome-biogaia"/><published>2026-01-06T21:10:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518996</id><title>Comparing AI agents to cybersecurity professionals in real-world pen testing</title><updated>2026-01-07T09:18:54.745125+00:00</updated><content>&lt;doc fingerprint="919c362341ffe08f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 10 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.AI&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.09882"/><published>2026-01-06T21:23:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46519303</id><title>Laylo (YC S20) ‚Äì Head of Growth (Organic and Partners and Loops and AI) ‚Äì Remote US</title><updated>2026-01-07T09:18:54.188044+00:00</updated><content>&lt;doc fingerprint="b1dc8874f8cd840c"&gt;
  &lt;main&gt;
    &lt;p&gt;The CRM powering iconic musicians and events&lt;/p&gt;
    &lt;p&gt;Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.&lt;/p&gt;
    &lt;p&gt;Role Overview&lt;/p&gt;
    &lt;p&gt;We‚Äôre looking for a Head of Growth (player/coach) to build and run Laylo‚Äôs growth engine. A 0‚Üí1 builder who doesn‚Äôt just ideate, but ships. You‚Äôll create great content, run scrappy experiments, and build product growth loops that compound. This is a hands-on role: you‚Äôll set strategy, execute a rapid experiment cadence, measure results, and turn wins into repeatable playbooks.&lt;/p&gt;
    &lt;p&gt;You‚Äôll focus primarily on non-advertising channels: organic social, influencer/creator collaborations, channel partners, and product growth loops. We value strong taste, speed, and a rigorous learning cadence.&lt;/p&gt;
    &lt;p&gt;You‚Äôll report directly to the CEO and work closely with Product, Engineering, Design, Partnerships, and Sales. You‚Äôre likely a good fit if you‚Äôre excited to open Adobe/Figma/Notion/PostHog and ship something today.&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;p&gt;You‚Äôll thrive here if you can:&lt;/p&gt;
    &lt;p&gt;Key Responsibilities:&lt;/p&gt;
    &lt;p&gt;What Success Looks Like:&lt;/p&gt;
    &lt;p&gt;What You Bring:&lt;/p&gt;
    &lt;p&gt;How To Apply:&lt;/p&gt;
    &lt;p&gt;Send us your first out-of-the-box idea for your first campaign in this role. Bonus points for mentioning other companies and campaigns you think are relevant.&lt;/p&gt;
    &lt;p&gt;Our founders met while building competing consumer startups. We launched multiple products across consumer and SaaS and talked to thousands of fans and creators in the process. In 2020, we realized one of the biggest pain points artists and events face is actually driving their audience from socials into their own CRM.&lt;/p&gt;
    &lt;p&gt;In 2020, we joined Y Combinator‚Äôs summer batch and began building a product that quickly gained strong early traction. We raised from top-tier investors like Eldridge and Sony and have since grown into a team of 24 exceptional individuals spanning product, sales, and operations.&lt;/p&gt;
    &lt;p&gt;We have a strong written documentation culture. We try to do as much as possible asynchronously to move quickly and efficiently. We have a daily 30 minute standup and team-specific meetings throughout the week.&lt;/p&gt;
    &lt;p&gt;Creators and Brands have a few key moments that drive the majority of their sales and fan engagement, we call them drops. At Laylo, we're building the Drop CRM to make these moments perfect.&lt;/p&gt;
    &lt;p&gt;With Laylo, creators and brands can notify fans the second they drop new content, merch and events. From there, they get a full featured CRM, a dashboard to connect with fans forever in the future, high conversion landing pages and deep analytics to conversions, click throughs and sales.&lt;/p&gt;
    &lt;p&gt;We work with some of biggest creators, brands, records labels and managers in the world to create incredible drop experiences.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/laylo/jobs/ZtLHRXe-head-of-growth"/><published>2026-01-06T21:44:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46519326</id><title>CES 2026: Taking the Lids Off AMD's Venice and MI400 SoCs</title><updated>2026-01-07T09:18:54.015521+00:00</updated><content>&lt;doc fingerprint="ee681e65ab90b9d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;CES 2026: Taking the Lids off AMD's Venice and MI400 SoCs&lt;/head&gt;
    &lt;p&gt;Hello you fine Internet folks,&lt;/p&gt;
    &lt;p&gt;Here at CES 2026, AMD showed off their upcoming Venice series of server CPUs and their upcoming MI400 series of datacenter accelerators. AMD has talked about the specifications of both Venice and the MI400 series at their Advancing AI event back in June of 2025, but this is the first time AMD has shown off the silicon for both of product lines.&lt;/p&gt;
    &lt;p&gt;Starting with Venice, the first thing to notice is the packaging of the CCDs to the IO dies is different. Instead of using the organic substrate of the package to run the wires between the CCDs and the IO dies that AMD has used since EPYC Rome, Venice appears to be using a more advanced form of packaging similar to Strix Halo or MI250X. Another change is that Venice appears to have two IO dies instead of the single IO die that the prior EPYC CPUs had.&lt;/p&gt;
    &lt;p&gt;Venice has 8 CCDs each of which have 32 cores for a total of up to 256 cores per Venice package. Doing some measuring of each of the dies, you get that each CCD is approximately 165mm2 of N2 silicon. If AMD has stuck to 4MB of L3 per core than each of these CCDs have 32 Zen 6 cores and 128MB of L3 cache along with the die to die interface for the CCD &amp;lt;-&amp;gt; IO die communications. At approximately 165mm2 per CCD, that would make a Zen 6 core plus the 4MB of L3 per core about 5mm2 each which is similar to Zen 5‚Äôs approximately 5.34mm2 on N3 when counting both the Zen 5 core and 4MB of L3 cache.&lt;/p&gt;
    &lt;p&gt;Moving to the IO dies, they each appear to be approximately 353mm2 for a total of just over 700mm2 of silicon dedicated for the IO dies. This is a massive increase from the approximately 400mm2 that the prior EPYC CPUs dedicated for their IO dies. The two IO dies appear to be using an advanced packaging of some kind similar to the CCDs. Next to the IO dies appear to be 8 little dies, 4 on each side of the package, which are likely to either be structural silicon or deep trench capacitor dies meant to improve power delivery to the CCDs and IO dies.&lt;/p&gt;
    &lt;p&gt;Shifting off of Venice and on to the MI400 accelerator, this is a massive package with 12 HBM4 dies and ‚Äútwelve 2 nanometer and 3 nanometer compute and IO dies‚Äù. It appears as if there are two base dies just like MI350. But unlike MI350, there appears to also be two extra dies on the top and bottom of the base dies. These two extra dies are likely for off-package IO such as PCIe, UALink, etc.&lt;/p&gt;
    &lt;p&gt;Calculating the die sizes of the base dies and the IO dies, the die size of the base die is approximately 747mm2 for each of the two base dies with the off-package IO dies each being approximately 220mm2. As for the compute dies, while the packaging precludes any visual demarcation of the different compute dies, it is likely that there are 8 compute dies with 4 compute dies on each base die. So while we can‚Äôt figure out the exact die size of the compute dies, the maximum size is approximately 180mm2. The compute chiplet is likely in the 140mm2 to 160mm2 region but that is a best guess that will have to wait to be confirmed.&lt;/p&gt;
    &lt;p&gt;The MI455X and Venice are the two SoCs that are going to be powering AMD‚Äôs Helios AI Rack but they aren‚Äôt the only new Zen 6 and MI400 series products that AMD announced at CES. AMD announced that there would be a third member of the MI400 family called the MI440X joining the MI430X and MI455X. The MI440X is designed to fit into the 8-way UBB boxes as a direct replacement for the MI300/350 series.&lt;/p&gt;
    &lt;p&gt;AMD also announced Venice-X which is likely is going to be a V-Cache version of Venice. This is interesting because not only did AMD skip Turin-X but if there is a 256 core version of Venice-X, then this would be the first time that a high core count CCD will have the ability to support a V-Cache die. If AMD sticks to the same ratio of base die cache to V-Cache die cache, then each 32 core CCD would have up to 384MB of L3 cache which equates to 3 Gigabytes of L3 cache across the chip.&lt;/p&gt;
    &lt;p&gt;Both Venice and the MI400 series are due to launch later this year and I can‚Äôt wait to learn more about the underlying architectures of both SoCs.&lt;/p&gt;
    &lt;p&gt;If you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese, also consider joining the Discord.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chipsandcheese.com/p/ces-2026-taking-the-lids-off-amds"/><published>2026-01-06T21:46:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46520926</id><title>Show HN: SMTP Tunnel ‚Äì A SOCKS5 proxy disguised as email traffic to bypass DPI</title><updated>2026-01-07T09:18:53.533548+00:00</updated><content>&lt;doc fingerprint="8cf1e0524c113892"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;A high-speed covert tunnel that disguises TCP traffic as SMTP email communication to bypass Deep Packet Inspection (DPI) firewalls.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Application ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Client    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Server    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Internet    ‚îÇ
‚îÇ  (Browser)  ‚îÇ TCP  ‚îÇ SOCKS5:1080 ‚îÇ SMTP ‚îÇ  Port 587   ‚îÇ TCP  ‚îÇ              ‚îÇ
‚îÇ             ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ             ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ             ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ                    ‚îÇ
                            ‚îÇ   Looks like       ‚îÇ
                            ‚îÇ   Email Traffic    ‚îÇ
                            ‚ñº                    ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ     DPI Firewall               ‚îÇ
                     ‚îÇ  ‚úÖ Sees: Normal SMTP Session  ‚îÇ
                     ‚îÇ  ‚ùå Cannot see: Tunnel Data    ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üîí TLS Encryption&lt;/cell&gt;
        &lt;cell&gt;All traffic encrypted with TLS 1.2+ after STARTTLS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üé≠ DPI Evasion&lt;/cell&gt;
        &lt;cell&gt;Initial handshake mimics real SMTP servers (Postfix)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;‚ö° High Speed&lt;/cell&gt;
        &lt;cell&gt;Binary streaming protocol after handshake - minimal overhead&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üë• Multi-User&lt;/cell&gt;
        &lt;cell&gt;Per-user secrets, IP whitelists, and logging settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üîë Authentication&lt;/cell&gt;
        &lt;cell&gt;Per-user pre-shared keys with HMAC-SHA256&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üåê SOCKS5 Proxy&lt;/cell&gt;
        &lt;cell&gt;Standard proxy interface - works with any application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üì° Multiplexing&lt;/cell&gt;
        &lt;cell&gt;Multiple connections over single tunnel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üõ°Ô∏è IP Whitelist&lt;/cell&gt;
        &lt;cell&gt;Per-user access control by IP address/CIDR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üì¶ Easy Install&lt;/cell&gt;
        &lt;cell&gt;One-liner server installation with systemd service&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üéÅ Client Packages&lt;/cell&gt;
        &lt;cell&gt;Auto-generated ZIP files for each user&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;üîÑ Auto-Reconnect&lt;/cell&gt;
        &lt;cell&gt;Client automatically reconnects on connection loss&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;üìö For in-depth technical details, protocol specifications, and security analysis, see TECHNICAL.md.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Server: Linux VPS with Python 3.8+, port 587 open&lt;/item&gt;
      &lt;item&gt;Client: Windows/macOS/Linux with Python 3.8+&lt;/item&gt;
      &lt;item&gt;Domain name: Required for TLS certificate verification (free options: DuckDNS, No-IP, FreeDNS)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get a free domain pointing to your VPS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ü¶Ü DuckDNS - Recommended, simple and free&lt;/item&gt;
      &lt;item&gt;üåê No-IP - Free tier available&lt;/item&gt;
      &lt;item&gt;üÜì FreeDNS - Many domain options&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: &lt;code&gt;myserver.duckdns.org&lt;/code&gt; ‚Üí &lt;code&gt;203.0.113.50&lt;/code&gt; (your VPS IP)&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/x011/smtp-tunnel-proxy/main/install.sh | sudo bash&lt;/code&gt;
    &lt;p&gt;The installer will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;üì• Download and install everything&lt;/item&gt;
      &lt;item&gt;‚ùì Ask for your domain name&lt;/item&gt;
      &lt;item&gt;üîê Generate TLS certificates automatically&lt;/item&gt;
      &lt;item&gt;üë§ Offer to create your first user&lt;/item&gt;
      &lt;item&gt;üî• Configure firewall&lt;/item&gt;
      &lt;item&gt;üöÄ Start the service&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's it! Your server is ready.&lt;/p&gt;
    &lt;code&gt;smtp-tunnel-adduser bob      # Add user + generate client ZIP
smtp-tunnel-listusers        # List all users
smtp-tunnel-deluser bob      # Remove a user&lt;/code&gt;
    &lt;code&gt;smtp-tunnel-update           # Updates code, preserves config/certs/users&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get your &lt;code&gt;username.zip&lt;/code&gt;file from the server admin&lt;/item&gt;
      &lt;item&gt;Extract the ZIP file&lt;/item&gt;
      &lt;item&gt;Run the launcher:&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;How to Run&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ü™ü Windows&lt;/cell&gt;
        &lt;cell&gt;Double-click &lt;code&gt;start.bat&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;üêß Linux&lt;/cell&gt;
        &lt;cell&gt;Run &lt;code&gt;./start.sh&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;üçé macOS&lt;/cell&gt;
        &lt;cell&gt;Run &lt;code&gt;./start.sh&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The launcher will automatically install dependencies and start the client.&lt;/p&gt;
    &lt;p&gt;‚úÖ You should see:&lt;/p&gt;
    &lt;code&gt;SMTP Tunnel Proxy Client
User: alice

[INFO] Starting SMTP Tunnel...
[INFO] SOCKS5 proxy will be available at 127.0.0.1:1080

Connecting to myserver.duckdns.org:587
Connected - binary mode active
SOCKS5 proxy on 127.0.0.1:1080
&lt;/code&gt;
    &lt;code&gt;cd alice
pip install -r requirements.txt
python client.py&lt;/code&gt;
    &lt;code&gt;# Download files
scp root@myserver.duckdns.org:/etc/smtp-tunnel/ca.crt .

# Create config.yaml:
cat &amp;gt; config.yaml &amp;lt;&amp;lt; EOF
client:
  server_host: "myserver.duckdns.org"
  server_port: 587
  socks_port: 1080
  username: "alice"
  secret: "your-secret-from-admin"
  ca_cert: "ca.crt"
EOF

# Run client
python client.py -c config.yaml&lt;/code&gt;
    &lt;p&gt;Set SOCKS5 proxy to: &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Settings ‚Üí Network Settings ‚Üí Settings&lt;/item&gt;
      &lt;item&gt;Manual proxy configuration&lt;/item&gt;
      &lt;item&gt;SOCKS Host: &lt;code&gt;127.0.0.1&lt;/code&gt;, Port:&lt;code&gt;1080&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Select SOCKS v5&lt;/item&gt;
      &lt;item&gt;‚úÖ Check "Proxy DNS when using SOCKS v5"&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install "Proxy SwitchyOmega" extension&lt;/item&gt;
      &lt;item&gt;Create profile with SOCKS5: &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Settings ‚Üí Network &amp;amp; Internet ‚Üí Proxy ‚Üí Manual setup ‚Üí &lt;code&gt;socks=127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;System Preferences ‚Üí Network ‚Üí Advanced ‚Üí Proxies ‚Üí SOCKS Proxy ‚Üí &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;export ALL_PROXY=socks5://127.0.0.1:1080&lt;/code&gt;
    &lt;code&gt;# curl
curl -x socks5h://127.0.0.1:1080 https://ifconfig.me

# git
git config --global http.proxy socks5://127.0.0.1:1080

# Environment variable
export ALL_PROXY=socks5://127.0.0.1:1080&lt;/code&gt;
    &lt;code&gt;# Should show your VPS IP
curl -x socks5://127.0.0.1:1080 https://ifconfig.me&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Listen interface&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.0.0.0&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Listen port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;587&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hostname&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;SMTP hostname (must match certificate)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;mail.example.com&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cert_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TLS certificate path&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;server.crt&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;key_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TLS private key path&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;server.key&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;users_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to users configuration&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;users.yaml&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;log_users&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Global logging setting&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;true&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Each user can have individual settings:&lt;/p&gt;
    &lt;code&gt;users:
  alice:
    secret: "auto-generated-secret"
    # whitelist:              # Optional: restrict to specific IPs
    #   - "192.168.1.100"
    #   - "10.0.0.0/8"        # CIDR notation supported
    # logging: true           # Optional: disable to stop logging this user

  bob:
    secret: "another-secret"
    whitelist:
      - "203.0.113.50"        # Bob can only connect from this IP
    logging: false            # Don't log Bob's activity&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;User's authentication secret&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;whitelist&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Allowed IPs for this user (CIDR supported)&lt;/cell&gt;
        &lt;cell&gt;All IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;logging&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable activity logging for this user&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;true&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;server_host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server domain name&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;server_port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;587&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;socks_port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Local SOCKS5 port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1080&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;socks_host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Local SOCKS5 interface&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;127.0.0.1&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;username&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Your username&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Your authentication secret&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ca_cert&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;CA certificate for verification&lt;/cell&gt;
        &lt;cell&gt;Recommended&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Check status
sudo systemctl status smtp-tunnel

# Restart after config changes
sudo systemctl restart smtp-tunnel

# View logs
sudo journalctl -u smtp-tunnel -n 100

# Uninstall
sudo /opt/smtp-tunnel/uninstall.sh&lt;/code&gt;
    &lt;code&gt;python server.py [-c CONFIG] [-d]

  -c, --config    Config file (default: config.yaml)
  -d, --debug     Enable debug logging&lt;/code&gt;
    &lt;code&gt;python client.py [-c CONFIG] [--server HOST] [--server-port PORT]
                 [-p SOCKS_PORT] [-u USERNAME] [-s SECRET] [--ca-cert FILE] [-d]

  -c, --config      Config file (default: config.yaml)
  --server          Override server domain
  --server-port     Override server port
  -p, --socks-port  Override local SOCKS port
  -u, --username    Your username
  -s, --secret      Override secret
  --ca-cert         CA certificate path
  -d, --debug       Enable debug logging&lt;/code&gt;
    &lt;code&gt;smtp-tunnel-adduser &amp;lt;username&amp;gt; [-u USERS_FILE] [-c CONFIG] [--no-zip]
    Add a new user and generate client package

smtp-tunnel-deluser &amp;lt;username&amp;gt; [-u USERS_FILE] [-f]
    Remove a user (use -f to skip confirmation)

smtp-tunnel-listusers [-u USERS_FILE] [-v]
    List all users (use -v for detailed info)

smtp-tunnel-update
    Update server to latest version (preserves config/certs/users)&lt;/code&gt;
    &lt;code&gt;smtp_proxy/
‚îú‚îÄ‚îÄ üìÑ server.py               # Server (runs on VPS)
‚îú‚îÄ‚îÄ üìÑ client.py               # Client (runs locally)
‚îú‚îÄ‚îÄ üìÑ common.py               # Shared utilities
‚îú‚îÄ‚îÄ üìÑ generate_certs.py       # Certificate generator
‚îú‚îÄ‚îÄ üìÑ config.yaml             # Server/client configuration
‚îú‚îÄ‚îÄ üìÑ users.yaml              # User database
‚îú‚îÄ‚îÄ üìÑ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ üìÑ install.sh              # One-liner server installer
‚îú‚îÄ‚îÄ üìÑ smtp-tunnel.service     # Systemd unit file
‚îú‚îÄ‚îÄ üîß smtp-tunnel-adduser     # Add user script
‚îú‚îÄ‚îÄ üîß smtp-tunnel-deluser     # Remove user script
‚îú‚îÄ‚îÄ üîß smtp-tunnel-listusers   # List users script
‚îú‚îÄ‚îÄ üîß smtp-tunnel-update      # Update server script
‚îú‚îÄ‚îÄ üìÑ README.md               # This file
‚îî‚îÄ‚îÄ üìÑ TECHNICAL.md            # Technical documentation
&lt;/code&gt;
    &lt;code&gt;/opt/smtp-tunnel/              # Application files
/etc/smtp-tunnel/              # Configuration files
  ‚îú‚îÄ‚îÄ config.yaml
  ‚îú‚îÄ‚îÄ users.yaml
  ‚îú‚îÄ‚îÄ server.crt
  ‚îú‚îÄ‚îÄ server.key
  ‚îî‚îÄ‚îÄ ca.crt
/usr/local/bin/                # Management commands
  ‚îú‚îÄ‚îÄ smtp-tunnel-adduser
  ‚îú‚îÄ‚îÄ smtp-tunnel-deluser
  ‚îú‚îÄ‚îÄ smtp-tunnel-listusers
  ‚îî‚îÄ‚îÄ smtp-tunnel-update
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check server is running: &lt;code&gt;systemctl status smtp-tunnel&lt;/code&gt;or&lt;code&gt;ps aux | grep server.py&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check port is open: &lt;code&gt;netstat -tlnp | grep 587&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check firewall: &lt;code&gt;ufw status&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify &lt;code&gt;username&lt;/code&gt;and&lt;code&gt;secret&lt;/code&gt;match in users.yaml&lt;/item&gt;
      &lt;item&gt;Check server time is accurate (within 5 minutes)&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;smtp-tunnel-listusers -v&lt;/code&gt;to verify user exists&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check user's whitelist in users.yaml&lt;/item&gt;
      &lt;item&gt;Your current IP must match a whitelist entry&lt;/item&gt;
      &lt;item&gt;CIDR notation is supported (e.g., &lt;code&gt;10.0.0.0/8&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ensure you're using a domain name, not IP address&lt;/item&gt;
      &lt;item&gt;Verify &lt;code&gt;server_host&lt;/code&gt;matches the certificate hostname&lt;/item&gt;
      &lt;item&gt;Ensure you have the correct &lt;code&gt;ca.crt&lt;/code&gt;from the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Enable detailed logging
python server.py -d
python client.py -d

# View systemd logs
journalctl -u smtp-tunnel -f&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Always use a domain name for proper TLS verification&lt;/item&gt;
      &lt;item&gt;‚úÖ Always use &lt;code&gt;ca_cert&lt;/code&gt;to prevent man-in-the-middle attacks&lt;/item&gt;
      &lt;item&gt;‚úÖ Use &lt;code&gt;smtp-tunnel-adduser&lt;/code&gt;to generate strong secrets automatically&lt;/item&gt;
      &lt;item&gt;‚úÖ Use per-user IP whitelists if you know client IPs&lt;/item&gt;
      &lt;item&gt;‚úÖ Protect &lt;code&gt;users.yaml&lt;/code&gt;- contains all user secrets (chmod 600)&lt;/item&gt;
      &lt;item&gt;‚úÖ Disable logging for sensitive users with &lt;code&gt;logging: false&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;üìö For detailed security analysis and threat model, see TECHNICAL.md.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This project is provided for educational and authorized use only. Use responsibly and in accordance with applicable laws.&lt;/p&gt;
    &lt;p&gt;This tool is designed for legitimate privacy and censorship circumvention purposes. Users are responsible for ensuring their use complies with applicable laws and regulations.&lt;/p&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è for internet freedom&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/x011/smtp-tunnel-proxy"/><published>2026-01-07T00:30:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46520935</id><title>Electronic nose for indoor mold detection and identification</title><updated>2026-01-07T09:18:53.294056+00:00</updated><content/><link href="https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124"/><published>2026-01-07T00:31:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46521029</id><title>We recreated Steve Jobs's 1975 Atari horoscope program</title><updated>2026-01-07T09:18:53.148263+00:00</updated><content/><link href="https://blog.adafruit.com/2026/01/06/we-recreated-steve-jobss-1975-atari-horoscope-program-and-you-can-run-it/"/><published>2026-01-07T00:44:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46521084</id><title>PassSeeds ‚Äì hijacking Passkeys to unlock new cryptographic use cases</title><updated>2026-01-07T09:18:52.945375+00:00</updated><content>&lt;doc fingerprint="ea130af8e80c2650"&gt;
  &lt;main&gt;
    &lt;p&gt;In my time at Microsoft, I worked on the team responsible for the development and standardization of Passkeys. Passkeys have made standard, secure, cryptographic authentication accessible to all users, but the model is tightly restricted to website/app login.&lt;/p&gt;
    &lt;p&gt;Even with a deep, code-level understanding of passkeys and WebAuthn, it wasn‚Äôt until now, six years later, that I realized a set of properties and behaviors present within Passkeys could be hijacked to make this post possible. This ‚Äòfeature‚Äô was sitting right there and feels so obvious in retrospect. It just goes to show if you remain curious and turn over every rock, you can bend technology to do new and interesting things.&lt;/p&gt;
    &lt;p&gt;PassSeeds is a hack that explores this question: can we hijack the capabilities and UX of passkeys for use cases that stretch beyond their rigid login model and limited key-type support? The status quo of many Web-based use cases involving long-held cryptographic keys is often users pasting key material into sites/apps or buying special hardware devices that are difficult for less technical folks to use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Booting Up On Passkeys&lt;/head&gt;
    &lt;p&gt;To understand PassSeeds, it helps to have some awareness of the underlying Passkey technology they are based on.&lt;/p&gt;
    &lt;p&gt;Passkeys are asymmetric key pairs formatted as WebAuthn credentials, typically used to replace passwords for website logins. A key pair is created on the user‚Äôs device for a website and stored in a secure hardware module. Access to and usage of these key pairs is scoped to the origin of the site they were created on (for example: &lt;code&gt;example.com&lt;/code&gt;, &lt;code&gt;other.example.com&lt;/code&gt;, &lt;code&gt;test.com&lt;/code&gt;). Passkeys are replicated across a user‚Äôs devices by the platform (iCloud Keychain, Google Password Manager, Windows Hello, etc.) via an end-to-end encrypted sync process. Below is a basic overview of the two primary UX flows for generating a passkey and using one for login:&lt;/p&gt;
    &lt;head rend="h3"&gt;Key Points (pun intended)&lt;/head&gt;
    &lt;p&gt;There are several attributes of Passkeys to keep in mind that are critical to the PassSeed mechanism detailed in this post:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Passkeys are key pair + metadata bundles that are securely stored and synced across a user‚Äôs devices by OS/platform&lt;/item&gt;
      &lt;item&gt;The private and public key are both stored and synced across devices as one highly sensitive bundle&lt;/item&gt;
      &lt;item&gt;If you never store it at generation time and do not allow signatures from its private key out of the generating origin‚Äôs boundary, no API, metadata, or side-channel reveals the public key.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Given these attributes of the Passkey model, even public keys in the system behave like a natively provisioned, hardware-secured, synced secret, even though cryptography does not require them to be secret. This is a rare and valuable set of properties many products, services, and protocols find highly desirable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing PassSeeds&lt;/head&gt;
    &lt;p&gt;Passkeys provide biometrically gated use of cryptographic keys, but they were created specifically for authentication signing in centralized website login flows. Meanwhile, web apps that need cryptographic material and curves that passkeys don‚Äôt support (&lt;code&gt;secp256k1&lt;/code&gt; for Bitcoin, &lt;code&gt;BLS12-381&lt;/code&gt; for ZKPs, etc.) remain primitive and convoluted. Users copy 12‚Äì24 words, stash JSON keystores, or paste raw keys across apps. PassSeeds introduces a novel approach: treat the passkey‚Äôs P‚Äë256 public key itself as seed material and retrieve it on demand through ECDSA public‚Äëkey recovery. The authenticator still keeps the private key and user‚Äëverification requirements, but the recovered public‚Äëkey bytes become the deterministic PassSeed that can serve as the foundation for other cryptographic use cases.&lt;/p&gt;
    &lt;p&gt;(If you don‚Äôt want to understand how it works, you can skip to the DEMO)&lt;/p&gt;
    &lt;head rend="h2"&gt;PassSeed Generation&lt;/head&gt;
    &lt;p&gt;Assumptions: you have created a passkey, did not export the public key anywhere at generation time, and do not allow any signatures from the passkey outside of the generating origin‚Äôs local boundary.&lt;/p&gt;
    &lt;p&gt;Initial Generation&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Call &lt;code&gt;navigator.credentials.create()&lt;/code&gt;with&lt;code&gt;userVerification: required&lt;/code&gt;to mint a P-256 passkey scoped to the generating origin‚Äôs RP ID.&lt;/item&gt;
      &lt;item&gt;The initial passkey creation operation is the only API call where the platform returns the public key, but DO NOT export the public key, as it is effectively the private seed value of the PassSeed and can be recovered later through cryptographic means.&lt;/item&gt;
      &lt;item&gt;Use the returned public key to generate the cryptographic seed bytes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Regeneration via ECDSA Key Recovery&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;When a PassSeed is needed (for example, to sign a Bitcoin transaction, sign a decentralized social media post, or generate/verify a zero-knowledge proof), craft a message (for example, &lt;code&gt;PassSeed ${nonce}&lt;/code&gt;) for signing with the passkey.&lt;/item&gt;
      &lt;item&gt;Ask the user to sign the message twice via &lt;code&gt;navigator.credentials.get()&lt;/code&gt;using the same message and RP scope each time.&lt;/item&gt;
      &lt;item&gt;Each assertion returns a P-256 ECDSA signature. Because both signatures are over the same message, client code can perform ECDSA public key recovery using the two signatures to derive the unique P-256 public key of the passkey. No private material leaves the authenticator, and the app receives only the public key bytes.&lt;/item&gt;
      &lt;item&gt;The recovered public key (in compressed or uncompressed form) is the PassSeed. It is reproducible on-demand by repeating the double-sign ECDSA recovery flow, with no exportation of the PassSeed public key at any time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recovery / Rotation&lt;lb/&gt; If a device is lost, but other devices with the passkey that backs the PassSeed are still available, any new device added to the accout of the user will have their PassSeed automatically synced upon device enrollment, which is a process handled by the native platform. If all devices with the backing passkey are lost, you can still access and control whatever was tied to your PassSeed via the exported mnemonic phrase, if you elected to do that (which is strongly recommeded). Because PassSeeds and their backing Passkeys cannot be imported into the Passkey mechanism, if you lose all devices with the backing Passkey, you will need to transfer anything tied to the old PassSeed to a new one on your active devices (again, assuming you backed up your PassSeed via exporting its mnemonic phrase).&lt;/p&gt;
    &lt;head rend="h2"&gt;Converting a PassSeed to a Mnemonic Phrase&lt;/head&gt;
    &lt;p&gt;To make the PassSeed user-friendly, the implementation converts the 32-byte PassSeed into a standard BIP-39 mnemonic. In practice, the PassSeed is the SHA-256 hash of the recovered public key, represented as 32 bytes. Users can write down the phrase to ensure that even if something happens to their PassSeed (e.g. they accidentially delete it), they can retain access to the keys it is capable of producing. Rerunning the ECDSA recovery process with the same passkey deterministically yields the same phrase.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deriving Other Keys from the PassSeed&lt;/head&gt;
    &lt;p&gt;Once you have the PassSeed (public key bytes or its mnemonic-derived entropy), you can deterministically derive other cryptographic material:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bitcoin signing: use an HKDF with a domain-separated label to produce 32 bytes, clamped to the secp256k1 field, and treat it as a private key for transaction signing.&lt;/item&gt;
      &lt;item&gt;App/protocol-specific keys: derive additional context-labeled keys for different apps and protocols that use keys as identifiers (decentarlized social media), all from the same seed material.&lt;/item&gt;
      &lt;item&gt;ZKP credentials: derive scalar material for &lt;code&gt;BLS12-381&lt;/code&gt;or other proving curves, enabling deterministic prover keys or presentation keys for zero-knowledge credentials.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;The following are the code snippets for the core methods from the PassSeed TypeScript implementation, avaiable in the PassSeed Github repo. Some of the methods reference helpers that are contained in the module, but are not shown here, for brevity.&lt;/p&gt;
    &lt;head rend="h3"&gt;PassSeed.create()&lt;/head&gt;
    &lt;p&gt;This method orchestrates the complete WebAuthn credential creation flow, extracts the credential‚Äôs P-256 public key from the CBOR attestation object, and returns a hex-encoded SHA-256 hash of the public key bytes.&lt;/p&gt;
    &lt;code&gt;static async create(
  options: { user?: string; seedName?: string } = {}
): Promise&amp;lt;string&amp;gt; {
  const now = new Date();
  const {
    user = "anon",
    seedName = `PassSeed Seed - ${now.getMonth() + 1}/${now.getDate()}/${now.getFullYear()}`
  } = options;
  // Step 1: Initiate WebAuthn credential creation
  const credential = await navigator.credentials.create({
    publicKey: {
      challenge: crypto.getRandomValues(new Uint8Array(32)),
      rp: { name: "PassSeed" },
      user: {
        id: crypto.getRandomValues(new Uint8Array(16)),
        name: seedName,
        displayName: user
      },
      pubKeyCredParams: [{ type: "public-key", alg: -7 }],
      authenticatorSelection: {
        authenticatorAttachment: "platform",
        userVerification: "preferred"
      },
      timeout: 60000,
      attestation: "direct"
    }
  }) as PublicKeyCredential;

  if (!credential) {
    throw new Error("Credential creation cancelled");
  }

  // Step 2: Extract the public key from the attestation object
  const attestationObject = (credential.response as AuthenticatorAttestationResponse).attestationObject;
  const publicKey = extractPublicKeyFromAttestation(attestationObject);
  const publicKeyBytes = concatBytes(new Uint8Array([0x04]), publicKey.x, publicKey.y);

  return seedStringFromPublicKeyBytes(publicKeyBytes);
}&lt;/code&gt;
    &lt;head rend="h3"&gt;PassSeed.get()&lt;/head&gt;
    &lt;p&gt;This method retrieves an existing passkey (optionally by credential ID), performs two WebAuthn signatures over the same challenge, reconstructs the public key via ECDSA recovery by intersecting candidate points from both signatures, and returns the hex-encoded PassSeed string.&lt;/p&gt;
    &lt;code&gt;static async get(options: PassSeedGetOptions = {}): Promise&amp;lt;string&amp;gt; {
  if (options != null &amp;amp;&amp;amp; typeof options !== "object") {
    throw new Error("PassSeed.get expects an options object when parameters are provided");
  }
  const { credentialId, onBeforeSecondSignature } = options ?? {};
  // Step 1: Prepare a single challenge that both assertions will sign
  const challenge = crypto.getRandomValues(new Uint8Array(32));
  
  const assertionOptions: CredentialRequestOptions = {
    publicKey: {
      challenge: challenge,
      timeout: 60000,
      userVerification: "preferred"
    }
  };

  // If credentialId is provided, target that specific credential
  if (credentialId) {
    assertionOptions.publicKey!.allowCredentials = [{
      type: "public-key",
      id: toArrayBuffer(base64urlnopad.decode(credentialId))
    }];
  }

  // Step 2: First signature - collect authenticator response
  const assertion1 = await navigator.credentials.get(assertionOptions) as PublicKeyCredential;
  
  if (!assertion1) {
    throw new Error("User cancelled authentication");
  }

  const response1 = assertion1.response as AuthenticatorAssertionResponse;
  const signature1 = response1.signature;
  const authenticatorData1 = response1.authenticatorData;
  const clientData1 = response1.clientDataJSON;

  // Capture the credential ID from the first assertion if not already provided
  const usedCredentialId = credentialId
    ? toArrayBuffer(base64urlnopad.decode(credentialId))
    : assertion1.rawId;

  if (onBeforeSecondSignature) {
    await onBeforeSecondSignature();
  }

  // Step 3: Second signature over the same challenge
  assertionOptions.publicKey!.challenge = challenge;
  assertionOptions.publicKey!.allowCredentials = [{
    type: "public-key",
    id: usedCredentialId
  }];

  const assertion2 = await navigator.credentials.get(assertionOptions) as PublicKeyCredential;
  
  if (!assertion2) {
    throw new Error("User cancelled second authentication");
  }

  const response2 = assertion2.response as AuthenticatorAssertionResponse;
  const signature2 = response2.signature;
  const authenticatorData2 = response2.authenticatorData;
  const clientData2 = response2.clientDataJSON;

  // Step 4: Recover the public key from both signatures and intersect candidates
  const clientHash1 = sha256(new Uint8Array(clientData1));
  const signedData1 = concatBytes(new Uint8Array(authenticatorData1), clientHash1);
  const messageHash1 = sha256(signedData1);

  const clientHash2 = sha256(new Uint8Array(clientData2));
  const signedData2 = concatBytes(new Uint8Array(authenticatorData2), clientHash2);
  const messageHash2 = sha256(signedData2);

  const { r: r1, s: s1 } = decodeDerSignature(signature1);
  const { r: r2, s: s2 } = decodeDerSignature(signature2);

  const candidates1 = recoverPublicKeys(r1, s1, messageHash1);
  const candidates2 = recoverPublicKeys(r2, s2, messageHash2);

  const candidateMap = new Map&amp;lt;string, NoblePoint&amp;gt;();
  for (const candidate of candidates1) {
    candidateMap.set(pointToKey(candidate), candidate);
  }

  const intersection: NoblePoint[] = [];
  for (const candidate of candidates2) {
    const key = pointToKey(candidate);
    if (candidateMap.has(key)) {
      intersection.push(candidate);
    }
  }

  if (intersection.length !== 1) {
    throw new Error("Unable to recover a unique public key from signatures");
  }

  const publicKeyBytes = intersection[0].toBytes(false);
  return seedStringFromPublicKeyBytes(publicKeyBytes);
}&lt;/code&gt;
    &lt;head rend="h3"&gt;PassSeed.toMnemonic()&lt;/head&gt;
    &lt;p&gt;This method converts a 32-byte PassSeed (as bytes or hex) into a human-readable BIP-39 mnemonic phrase for backup and recovery, optionally truncating to 16 bytes for a 12-word phrase before handing entropy to &lt;code&gt;bip39.entropyToMnemonic&lt;/code&gt; with the English wordlist.&lt;/p&gt;
    &lt;code&gt;static async toMnemonic(passSeed: Uint8Array | string, wordCount: 12 | 24 = 24): Promise&amp;lt;string&amp;gt; {
  const passSeedBytes = typeof passSeed === "string" ? PassSeed.hexToBytes(passSeed) : passSeed;
  if (passSeedBytes.length !== 32) {
    throw new Error("PassSeed must be exactly 32 bytes");
  }
  if (wordCount !== 12 &amp;amp;&amp;amp; wordCount !== 24) {
    throw new Error("Mnemonic word count must be 12 or 24");
  }

  const entropyBytes = wordCount === 12 ? passSeedBytes.slice(0, 16) : passSeedBytes;
  const entropyHex = bytesToHex(entropyBytes);
  return bip39.entropyToMnemonic(entropyHex, bip39.wordlists.english);
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Threat Model and Constraints&lt;/head&gt;
    &lt;p&gt;The authenticator still enforces RP binding and user verification before issuing signatures, so phishing resistance mirrors standard passkeys. The host page sees two signatures and the recovered public key, values one must assume the host can exfiltrate. Because the same message is signed twice, replay risk is mitigated by including nonces, RP ID, and a strict prefix so signatures cannot be repurposed. Syncable passkeys inherit the platform‚Äôs end-to-end encrypted sync features.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why not use the WebAuthn‚Äôs PRF or Large Blob features?&lt;/head&gt;
    &lt;p&gt;The WebAuthn specification has defined a PRF extension for deterministically generating per-credential secrets, and a Large Blob extension, which can be used to encrypt and save a randomly generated secret that is synced across the user‚Äôs devices, both of which could achieve the desired ends. The problem is API support: PRF and Large Blob features are not implemented across browsers today, and there is no signal that either will be in the near future. That makes it hard to rely on in production if you need your app to work everywhere.&lt;/p&gt;
    &lt;p&gt;PassSeeds can even be used to create a polyfill for the PRF feature: by deterministically recovering a stable cryptographic value from the passkey signature flow (the public key), you can use that value to generate deterministic, cryptographic values based on input values, which will regenerate the same value for the same input, every time. If the tradeoffs of PassSeeds are acceptable, you can integrate PRF-reliant use cases in apps today, across all browsers. I plan on writing a PRF polyfill soon, so stay tuned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Demo &amp;amp; NPM Package&lt;/head&gt;
    &lt;p&gt;The following is a demo page that allows you to create PassSeeds, reload the page to test regeneration (via the ECDSA recovery process), and view the Mnemonic phrase of PassSeeds you‚Äôve created: PassSeeds Demo&lt;/p&gt;
    &lt;p&gt;You can also include PassSeeds in your Web apps via NPM: PassSeeds NPM Package&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://backalleycoder.com/posts/passseeds-an-experiment-in-hijacking-passkeys-to-unlock-cryptographic-use-cases/"/><published>2026-01-07T00:50:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46521860</id><title>Microsoft probably killed my Snapdragon Dev Kit</title><updated>2026-01-07T09:18:52.886306+00:00</updated><content>&lt;doc fingerprint="9714e917b72785d6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How Microsoft (Probably) Killed My Snapdragon Dev Kit&lt;/head&gt;
    &lt;p&gt;Back in October 2024, I got my hands on a Snapdragon Dev Kit. With a Qualcomm Snapdragon X Elite ARM64 CPU (the fastest model!), 32GB of RAM, and a 512GB SSD, it ran Windows 11 for ARM lightning fast. So I made it my daily driver, and it stayed that way until very recently. I even wrote a review of it one year later back in October.&lt;/p&gt;
    &lt;p&gt;Since the first boot, it‚Äôs been rock-solid and reliable every single day. And as someone who has used Windows since the beginning of time, I‚Äôm always combing through Event Viewer for software or hardware issues (there were none). Yes, the fan is noisy, as Jeff Geerling pointed out, but I don‚Äôt notice it because I work with headphones on.&lt;/p&gt;
    &lt;p&gt;Of course, that changed this past week.&lt;/p&gt;
    &lt;head rend="h1"&gt;So, what happened?&lt;/head&gt;
    &lt;p&gt;IIn early December, a Windows 11 security update (KB5068861) failed to install and rolled back during reboot. I tried installing it two more times with the same result. I cleared the package cache, ran the usual &lt;code&gt;sfc /scannow&lt;/code&gt; and &lt;code&gt;dism /Online /Cleanup-Image /RestoreHealth&lt;/code&gt; incantations, and even tried manually installing the update from the Microsoft Update Catalog. No go.&lt;/p&gt;
    &lt;p&gt;So I Googled it, found that many, many people were having the same issue and that Microsoft was going to fix it with a future cumulative update. So I turned off updates for a month and went on my merry way.&lt;/p&gt;
    &lt;p&gt;This past week, I turned updates back on. While I was working, I got the usual Windows notification that a restart was pending from a recently applied update. I hit restart and immediately realized it was the same update, same failure, same rollback.&lt;/p&gt;
    &lt;p&gt;Only this time, the rollback didn‚Äôt go as planned. The system rebooted four times before finally loading into Windows. And when it did, it wouldn‚Äôt sign me into my Microsoft account. Entering my PIN got me in, but to a brand-new profile complete with the default, soulless Windows background.&lt;/p&gt;
    &lt;p&gt;I had Internet access and most of my apps worked, but I couldn‚Äôt open Windows Terminal or most other Microsoft apps‚Ä¶ even Event Viewer. I decided to give it a fresh reboot (hey, it‚Äôs Windows after all). But right after the Windows logo appeared, the system either rebooted automatically or just shut down entirely‚Ä¶ seemingly at random. A few dozen attempts later, I had to admit defeat.&lt;/p&gt;
    &lt;p&gt;Next, I tried checking the UEFI settings by booting into the Boot Device Selection (BDS) menu (by pressing the Home key during boot). Unfortunately, the BDS menu behaved sporadically: random freezing, options that wouldn‚Äôt select, and general weirdness. I thought it might be keyboard- or USB-related, but other keyboards in different ports behaved exactly the same.&lt;/p&gt;
    &lt;p&gt;Persistence paid off eventually, and one time I managed to get into the BDS menu and navigate all the options. Figuring a Windows reinstall was my best shot, I disabled Secure Boot, enabled USB-first boot, and turned on the UEFI option that allows WinPE to use external displays (since this isn‚Äôt a laptop).&lt;/p&gt;
    &lt;p&gt;I downloaded the Windows 11 ARM ISO, imaged it to a USB thumb drive, and prepared a second thumb drive with the Snapdragon Dev Kit drivers I had previously snagged from Qualcomm‚Äôs website in one big ZIP file (thankfully, before they disappeared). I was able to boot into the Windows 11 installer, and everything ran smoothly at first. I completed an installation that overwrote my existing C:\ partition, rebooted, and made it through the initial setup just fine.&lt;/p&gt;
    &lt;p&gt;After choosing my region and keyboard layout, I got to the screen asking for a driver to connect to the network. I browsed successfully to the second thumb drive containing the drivers, but before I could even click the file, the system froze and shut down.&lt;/p&gt;
    &lt;p&gt;Since then, every attempt to boot has failed. It won‚Äôt get past the Snapdragon boot logo before rebooting or powering off‚Ä¶ again, seemingly at random. I can still get into the BDS menu, but no options are selectable. That means I can‚Äôt reinstall Windows 11 again, or try anything else for that matter, like Linux (which still lacks support for the Snapdragon Dev Kit).&lt;/p&gt;
    &lt;p&gt;I opened the system and reseated everything, including the SSD. No change. I even tested the SSD in another machine to rule it out, and it‚Äôs fine too.&lt;/p&gt;
    &lt;head rend="h1"&gt;Postmortem&lt;/head&gt;
    &lt;p&gt;The system was perfectly healthy and working fine right up until that Windows update failed.&lt;/p&gt;
    &lt;p&gt;Did the update somehow overwrite firmware it shouldn‚Äôt have? Or partially corrupt some UEFI or bootloader component, enough to boot sometimes, but not enough to stay sane? It could also be a Secure Boot or TPM state mismatch, or even a low-level power-management firmware issue given the random reboot-versus-power-off behavior. And since this is a dev kit with no documented firmware recovery path, even a normally recoverable failure might be permanent.&lt;/p&gt;
    &lt;p&gt;Or maybe a piece of hardware just failed at exactly the wrong time. No idea.&lt;/p&gt;
    &lt;p&gt;If Qualcomm hadn‚Äôt discontinued the Snapdragon Dev Kit, this probably would‚Äôve been an inconvenience instead of a postmortem. A firmware recovery tool, documented reflashing process, or even a basic support path might have turned this into a bad afternoon rather than a dead system. On a supported consumer Snapdragon PC, I suspect this would‚Äôve been annoying, but fixable.&lt;/p&gt;
    &lt;p&gt;Is this a problem with the Snapdragon platform itself? I doubt it. It was flawless as a daily driver from October 2024 onward. But this also isn‚Äôt a typical Snapdragon-based Windows PC‚Ä¶ it‚Äôs the Snapdragon Dev Kit. The day it arrived was the same day Qualcomm announced it would be discontinuing it and stopping all future support. Unlike Snapdragon laptops from ASUS, Dell, or Lenovo, there are no OEM-backed recovery tools or firmware safety nets here.&lt;/p&gt;
    &lt;p&gt;And I certainly haven‚Äôt lost faith in the platform. The Snapdragon X Elite is excellent, and up until this one update, Windows 11 and the system performed flawlessly. It was a great PC for just over a year, and it‚Äôs a real bummer losing a 32GB machine that consistently smoked my Core i9 system.&lt;/p&gt;
    &lt;p&gt;Oh well. RIP, powerful little ARM box.&lt;/p&gt;
    &lt;p&gt;P.S. If Qualcomm ever releases a firmware recovery tool for this thing, I‚Äôll happily update this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jasoneckert.github.io/myblog/how-microsoft-killed-my-snapdragon-devkit/"/><published>2026-01-07T02:37:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46522308</id><title>On the slow death of scaling</title><updated>2026-01-07T09:18:52.705070+00:00</updated><content/><link href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5877662"/><published>2026-01-07T03:48:05+00:00</published></entry></feed>