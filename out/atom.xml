<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-05T00:51:13.049363+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45809193</id><title>What is a manifold?</title><updated>2025-11-05T00:51:18.815427+00:00</updated><content>&lt;doc fingerprint="ba91984004c1afe9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Is a Manifold?&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Standing in the middle of a field, we can easily forget that we live on a round planet. We’re so small in comparison to the Earth that from our point of view, it looks flat.&lt;/p&gt;
    &lt;p&gt;The world is full of such shapes — ones that look flat to an ant living on them, even though they might have a more complicated global structure. Mathematicians call these shapes manifolds. Introduced by Bernhard Riemann in the mid-19th century, manifolds transformed how mathematicians think about space. It was no longer just a physical setting for other mathematical objects, but rather an abstract, well-defined object worth studying in its own right.&lt;/p&gt;
    &lt;p&gt;This new perspective allowed mathematicians to rigorously explore higher-dimensional spaces — leading to the birth of modern topology, a field dedicated to the study of mathematical spaces like manifolds. Manifolds have also come to occupy a central role in fields such as geometry, dynamical systems, data analysis and physics.&lt;/p&gt;
    &lt;p&gt;Today, they give mathematicians a common vocabulary for solving all sorts of problems. They’re as fundamental to mathematics as the alphabet is to language. “If I know Cyrillic, do I know Russian?” said Fabrizio Bianchi, a mathematician at the University of Pisa in Italy. “No. But try to learn Russian without learning Cyrillic.”&lt;/p&gt;
    &lt;p&gt;So what are manifolds, and what kind of vocabulary do they provide?&lt;/p&gt;
    &lt;head rend="h2"&gt;Ideas Taking Shape&lt;/head&gt;
    &lt;p&gt;For millennia, geometry meant the study of objects in Euclidean space, the flat space we see around us. “Until the 1800s, ‘space’ meant ‘physical space,’” said José Ferreirós, a philosopher of science at the University of Seville in Spain — the analogue of a line in one dimension, or a flat plane in two dimensions.&lt;/p&gt;
    &lt;p&gt;In Euclidean space, things behave as expected: The shortest distance between any two points is a straight line. A triangle’s angles add up to 180 degrees. The tools of calculus are reliable and well defined.&lt;/p&gt;
    &lt;p&gt;But by the early 19th century, some mathematicians had started exploring other kinds of geometric spaces — ones that aren’t flat but rather curved like a sphere or saddle. In these spaces, parallel lines might eventually intersect. A triangle’s angles might add up to more or less than 180 degrees. And doing calculus can become a lot less straightforward.&lt;/p&gt;
    &lt;p&gt;The mathematical community struggled to accept (or even understand) this shift in geometric thinking.&lt;/p&gt;
    &lt;p&gt;But some mathematicians wanted to push these ideas even further. One of them was Bernhard Riemann, a shy young man who had originally planned to study theology — his father was a pastor — before being drawn to mathematics. In 1849, he decided to pursue his doctorate under the tutelage of Carl Friedrich Gauss, who had been studying the intrinsic properties of curves and surfaces, independent of the space surrounding them.&lt;/p&gt;
    &lt;p&gt;In 1854, Riemann was required to deliver a lecture to secure a teaching position at the University of Göttingen. His assigned topic: the foundations of geometry. On June 10, despite a fear of public speaking, he described a new theory in which he generalized Gauss’ ideas about the geometry of surfaces to an arbitrary number of dimensions (and even to infinite dimensions).&lt;/p&gt;
    &lt;p&gt;Gauss was immediately impressed with the lecture, which involved not just math but also philosophy and physics. But most mathematicians found Riemann’s ideas too vague and abstract to be of much use. “Many scientists and philosophers were saying, ‘This is nonsense,’” Ferreirós said. And so, for decades, the work was largely ignored. Riemann’s lecture didn’t appear in print until 1868, two years after his death.&lt;/p&gt;
    &lt;p&gt;But by the end of the 19th century, mathematical greats like Henri Poincaré had recognized the importance of Riemann’s ideas. And in 1915, Albert Einstein used them in his general theory of relativity, bringing them out of the realm of philosophical abstraction and into the real world. By the middle of the 20th century, they had become a mathematical staple.&lt;/p&gt;
    &lt;p&gt;Riemann had introduced a concept that could encompass all possible geometries, in any number of dimensions. A concept that would change how mathematicians view space.&lt;/p&gt;
    &lt;p&gt;A manifold.&lt;/p&gt;
    &lt;head rend="h2"&gt;Charted Territory&lt;/head&gt;
    &lt;p&gt;The term “manifold” comes from Riemann’s Mannigfaltigkeit, which is German for “variety” or “multiplicity.”&lt;/p&gt;
    &lt;p&gt;A manifold is a space that looks Euclidean when you zoom in on any one of its points. For instance, a circle is a one-dimensional manifold. Zoom in anywhere on it, and it will look like a straight line. An ant living on the circle will never know that it’s actually round. But zoom in on a figure eight, right at the point where it crosses itself, and it will never look like a straight line. The ant will realize at that intersection point that it’s not in a Euclidean space. A figure eight is therefore not a manifold.&lt;/p&gt;
    &lt;p&gt;Similarly, in two dimensions, the surface of the Earth is a manifold; zoom in far enough anywhere on it, and it’ll look like a flat 2D plane. But the surface of a double cone — a shape consisting of two cones connected at their tips — is not a manifold.&lt;/p&gt;
    &lt;p&gt;Manifolds address a problem that mathematicians would otherwise have to deal with: A shape’s properties can change depending on the nature and dimension of the space it lives in (and how it sits in that space). For instance, lay a piece of string on a table, and connect its ends without lifting it. You’ll get a simple loop. Now hold the string in the air and tie its ends together. By considering the string in three dimensions, you can pass it over and under itself before you connect the ends, creating all sorts of knots beyond the simple loop. They all represent the same one-dimensional manifold — the looped string — but they have different properties when considered in two versus three dimensions.&lt;/p&gt;
    &lt;p&gt;Mathematicians avoid such ambiguities by focusing on the manifold’s intrinsic properties. The defining property of manifolds — that at any point, they look Euclidean — is immensely helpful on that front. Because it’s possible to think about any small patch of the manifold in terms of Euclidean space, mathematicians can use traditional calculus techniques to, say, compute its area or volume, or describe movement on it.&lt;/p&gt;
    &lt;p&gt;To do this, mathematicians divide a given manifold into several overlapping patches and represent each with a “chart” — a set of some number of coordinates (equal to the manifold’s dimension) that tell you where you are on the manifold. Crucially, you also need to write down rules that describe how the coordinates of overlapping charts relate to one another. The collection of all these charts is called an atlas.&lt;/p&gt;
    &lt;p&gt;You can then use this atlas — whose charts translate smaller regions of your potentially complicated manifold into familiar Euclidean space — to measure and explore the manifold one patch at a time. If you want to understand how a function behaves on a manifold, or get a sense of its global structure, you can break the problem up into pieces, solve each piece on a different chart, in Euclidean space, and then stitch together the results from all the charts in the atlas to get the full answer you’re seeking.&lt;/p&gt;
    &lt;p&gt;Today, this approach is ubiquitous throughout math and physics.&lt;/p&gt;
    &lt;head rend="h2"&gt;Manifold Uses&lt;/head&gt;
    &lt;p&gt;Manifolds are crucial to our understanding of the universe, for one. In his general theory of relativity, Einstein described space-time as a four-dimensional manifold, and gravity as that manifold’s curvature. And the three-dimensional space we see around us is also a manifold — one that, as manifolds do, appears Euclidean to those of us living within it, even though we’re still trying to figure out its global shape.&lt;/p&gt;
    &lt;p&gt;Even in cases where manifolds don’t seem to be present, mathematicians and physicists try to rewrite their problems in the language of manifolds to make use of their helpful properties. “So much of physics comes down to understanding geometry,” said Jonathan Sorce, a theoretical physicist at Princeton University. “And often in surprising ways.”&lt;/p&gt;
    &lt;p&gt;Consider a double pendulum, which consists of one pendulum hanging from the end of another. Small changes in the double pendulum’s initial conditions lead it to carve out very different trajectories through space, making its behavior hard to predict and understand. But if you represent the configuration of the pendulum with just two angles (one describing the position of each of its arms), then the space of all possible configurations looks like a doughnut, or torus — a manifold. Each point on this torus represents one possible state of the pendulum; paths on the torus represent the trajectories the pendulum might follow through space. This allows researchers to translate their physical questions about the pendulum into geometric ones, making them more intuitive and easier to solve. This is also how they study the movements of fluids, robots, quantum particles and more.&lt;/p&gt;
    &lt;p&gt;Similarly, mathematicians often view the solutions to complicated algebraic equations as a manifold to better understand their properties. And they analyze high-dimensional datasets — such as those recording the activity of thousands of neurons in the brain — by looking at how those data points might sit on a lower-dimensional manifold.&lt;/p&gt;
    &lt;p&gt;Asking how scientists use manifolds is akin to asking how they use numbers, Sorce said. “They are at the foundation of everything.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/what-is-a-manifold-20251103/"/><published>2025-11-04T09:58:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45810430</id><title>Chaining FFmpeg with a Browser Agent</title><updated>2025-11-05T00:51:18.445612+00:00</updated><link href="https://100x.bot/a/chaining-ffmpeg-with-browser-agent"/><published>2025-11-04T12:52:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45811093</id><title>Show HN: A CSS-Only Terrain Generator</title><updated>2025-11-05T00:51:18.220858+00:00</updated><content>&lt;doc fingerprint="109996e321a537ae"&gt;
  &lt;main&gt;
    &lt;p&gt;CSS Terrain Generator Regenerate Restart Undo Redo Import Export Heightmap CSS VOX TXT PNG Copy Embed Open Codepen Download Code move raise lower about world size ✕ ✕ landmass coverage small medium large terrain type pampas hilly alpinist biome temperate arctic desert camera settings rotate x 45° tilt y 60° zoom 50% pan x 0px lift y 0px animate reset to defaults minimap heightmap matrix v0.0.1 Regenerate&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://terra.layoutit.com"/><published>2025-11-04T13:58:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45811447</id><title>Optimizing Datalog for the GPU</title><updated>2025-11-05T00:51:18.109025+00:00</updated><content/><link href="https://danglingpointers.substack.com/p/optimizing-datalog-for-the-gpu"/><published>2025-11-04T14:31:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45812000</id><title>How devtools map minified JS code back to your TypeScript source code</title><updated>2025-11-05T00:51:17.968312+00:00</updated><content>&lt;doc fingerprint="2e607229161f0532"&gt;
  &lt;main&gt;
    &lt;p&gt;Source maps are the main piece in the jigsaw puzzle of mapping symbols and locations from "built" JavaScript files back to the original source code. When you debug minified JavaScript in your browser's DevTools and see the original source with proper variable names and formatting, you're witnessing source maps in action.&lt;/p&gt;
    &lt;p&gt;For example, when your browser encounters an error at &lt;code&gt;bundle.min.js:1:27698&lt;/code&gt;, the source map translates this to &lt;code&gt;src/index.ts:73:16&lt;/code&gt;, revealing exactly where the issue occurred in your original TypeScript code:&lt;/p&gt;
    &lt;p&gt;But how does this actually work under the hood? In this post, we'll take a deep dive into the internals of source maps, exploring their format, encoding mechanisms, and how devtools use them to bridge the gap between production code and developer-friendly sources.&lt;/p&gt;
    &lt;head rend="h2"&gt;The TypeScript Build Pipeline&lt;/head&gt;
    &lt;p&gt;Modern JavaScript builds typically involve three main stages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Transpilation: TypeScript → JavaScript&lt;/item&gt;
      &lt;item&gt;Bundling: Combining modules into a single file&lt;/item&gt;
      &lt;item&gt;Minification: Compressing code for production&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At each stage, source maps preserve the connection back to the original code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Stage 0: Source TS files&lt;/head&gt;
    &lt;p&gt;The original TypeScript source files with full type annotations.&lt;/p&gt;
    &lt;head rend="h4"&gt;Source Files&lt;/head&gt;
    &lt;quote&gt;1export function add(a: number, b: number): number {2 return a + b;3}&lt;/quote&gt;
    &lt;quote&gt;1import { add } from './add';23export function computeFibonacci(n: number): number {4 if (n &amp;lt;= 1) return n;5 return add(computeFibonacci(n - 1), computeFibonacci(n - 2));6}&lt;/quote&gt;
    &lt;quote&gt;1import { computeFibonacci } from './fibonacci';23const result = computeFibonacci(10);4console.log(`Fibonacci(10) = ${result}`);&lt;/quote&gt;
    &lt;p&gt;No source map at this stage&lt;/p&gt;
    &lt;head rend="h2"&gt;The Source Map File Format&lt;/head&gt;
    &lt;p&gt;Source maps use JSON format, typically with a &lt;code&gt;.js.map&lt;/code&gt; extension. Let's examine a source map structure from our &lt;code&gt;add.js.map&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;{
  "version": 3,
  "file": "add.js",
  "sourceRoot": "",
  "sources": ["add.ts"],
  "names": ["add", "a", "b"],
  "mappings": "AAAA,OAAO,SAAS,IAAI,CAAC,EAAE;EACrB,OAAO,IAAI;AACb"
}
&lt;/code&gt;
    &lt;head rend="h5"&gt;Fields Breakdown:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;version&lt;/code&gt;: Indicates the source map version (currently always&lt;code&gt;3&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;file&lt;/code&gt;: The generated file name this source map corresponds to.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sourceRoot&lt;/code&gt;: Optional prefix for all source URLs. Useful when sources are hosted elsewhere.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sources&lt;/code&gt;: Array of original source file paths from which the generated file was built.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sourcesContent&lt;/code&gt;: Optional array containing the actual source code. This allows DevTools to display sources even if the original files aren't accessible. Usually disabled in production builds.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;names&lt;/code&gt;: Array of original identifiers (variable names, function names, etc.) that appear in the source. Referenced by the mappings.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mappings&lt;/code&gt;: The compressed mapping data. This is the heart of the source map and uses VLQ encoding. More on this below.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Understanding the Mappings: VLQ Encoding&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;mappings&lt;/code&gt; field is where the real magic happens. It contains the actual position mappings between every token in the generated JavaScript file and its corresponding location in the original source files.&lt;/p&gt;
    &lt;p&gt;Essentially, it answers the question: "For this character at line X, column Y in the minified file, where was it originally located?"&lt;/p&gt;
    &lt;p&gt;This mapping data tracks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The file path and name of the original source file&lt;/item&gt;
      &lt;item&gt;The exact line and column in the source file&lt;/item&gt;
      &lt;item&gt;The original variable/function name (if renamed during minification)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But instead of storing this as a massive JSON array of positions, which would be larger than the minified code itself, source maps use a highly compressed format. Here's what the encoded string looks like:&lt;/p&gt;
    &lt;code&gt;"AAAA,OAAO,SAAS,IAAI,CAAC,EAAE;EACrB,OAAO,IAAI;AACb"
&lt;/code&gt;
    &lt;p&gt;To keep file sizes manageable, mappings use Variable Length Quantity (VLQ) encoding with Base64 characters. Let's break this down.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Mapping Structure&lt;/head&gt;
    &lt;p&gt;The mappings string is a series of segments separated by commas and semicolons:&lt;/p&gt;
    &lt;code&gt;"segment,segment,segment;segment,segment;segment"
&lt;/code&gt;
    &lt;p&gt;We'll see significance of commas and semicolons shortly, but first, what is a "segment"?&lt;/p&gt;
    &lt;p&gt;Each segment represents a mapping from a position in the generated file to a position in the source file. Segments come in three flavors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;1 value: This referenced column doesn't map to any source (e.g., webpack-generated code)&lt;/p&gt;
        &lt;code&gt;[generatedColumn]&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;4 values: This is the most common case, mapping a position in the generated file to a position in the source file:&lt;/p&gt;
        &lt;code&gt;[generatedColumn, sourceFileIndex, sourceLine, sourceColumn]&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;5 values: Same as 4, plus a reference to the original name of the variable/function:&lt;/p&gt;
        &lt;code&gt;[generatedColumn, sourceFileIndex, sourceLine, sourceColumn, nameIndex]&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most common case is 4 values (basic position mapping). The 5th value is only added when a variable or function was renamed during minification.&lt;/p&gt;
    &lt;p&gt;But wait, notice that segments only contain the column in the generated file, not the line number. How does the decoder know which line a segment belongs to?&lt;/p&gt;
    &lt;p&gt;The answer lies in the structure: semicolons act as line breaks. The position of segments between semicolons determines their line number in the generated file.&lt;/p&gt;
    &lt;p&gt;This is why empty lines in the generated file still need semicolons, they maintain the line count even with no mappings.&lt;/p&gt;
    &lt;p&gt;Let's see how this works with a real example:&lt;/p&gt;
    &lt;p&gt;Notice how the decoded values give relative positions, each value represents the difference from the previous position, not absolute coordinates. This is crucial: instead of encoding large column numbers like 27698 in minified files, source maps only store small deltas like +7 or +15, making the encoded strings much more compact.&lt;/p&gt;
    &lt;p&gt;Now that we understand the mapping structure, let's see how these numbers actually get transformed into the Base64 alphabet characters we see in the mappings string.&lt;/p&gt;
    &lt;head rend="h3"&gt;How VLQ Encoding Works&lt;/head&gt;
    &lt;p&gt;VLQ (Variable Length Quantity) encoding is an efficient way to represent numbers using as few bytes as possible. It's perfect for source maps because most position differences are small numbers.&lt;/p&gt;
    &lt;p&gt;The encoding process has three main steps:&lt;/p&gt;
    &lt;p&gt;1. Encode the sign bit&lt;/p&gt;
    &lt;p&gt;Since we need to handle both positive and negative differences (code can move backward), VLQ uses the least significant bit (LSB) to encode the sign:&lt;/p&gt;
    &lt;code&gt;Positive number: LSB = 0
Negative number: LSB = 1

Examples:
 5 → binary: 101 → with sign bit: 1010 (LSB=0 for positive)
-5 → binary: 101 → with sign bit: 1011 (LSB=1 for negative)
&lt;/code&gt;
    &lt;p&gt;2. Split into 5-bit groups&lt;/p&gt;
    &lt;p&gt;Each Base64 character can represent 6 bits, but we need 1 bit as a "continuation" flag to indicate if more characters follow. This leaves 5 bits for data:&lt;/p&gt;
    &lt;code&gt;[continuation bit][5 data bits]
       ↑              ↑
   1 = more coming    actual value bits
   0 = last character
&lt;/code&gt;
    &lt;p&gt;3. Convert to Base64&lt;/p&gt;
    &lt;p&gt;Map each 6-bit value to a Base64 character:&lt;/p&gt;
    &lt;code&gt;A=0, B=1, C=2... Z=25, a=26, b=27... z=51, 0=52, 1=53... 9=61, +=62, /=63
&lt;/code&gt;
    &lt;head rend="h6"&gt;Example&lt;/head&gt;
    &lt;p&gt;Lets go through the steps to encode the number 7:&lt;/p&gt;
    &lt;p&gt;That's why in our mapping example, the value 7 is encoded as 'O'!&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;I hope this deep dive into JavaScript source maps has shed light on how they function under the hood and adds to your appreciation for the amount of position data they efficiently encode.&lt;/p&gt;
    &lt;p&gt;P.S. Stay tuned: source maps support is coming to parca-agent and Polar Signals Cloud, bringing the same debugging magic to your performance profiling workflow!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.polarsignals.com/blog/posts/2025/11/04/javascript-source-maps-internals"/><published>2025-11-04T15:21:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45812024</id><title>This Day in 1988, the Morris worm infected 10% of the Internet within 24 hours</title><updated>2025-11-05T00:51:17.731047+00:00</updated><content>&lt;doc fingerprint="ff40223f0be08a6f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;37 years ago this week, the Morris worm infected 10% of the Internet within 24 hours — worm slithered out and sparked a new era in cybersecurity&lt;/head&gt;
    &lt;p&gt;The Internet contracted worms a year before the World Wide Web was even a thing.&lt;/p&gt;
    &lt;p&gt;This week in 1988, Cornell graduate student Robert Tappan Morris unleashed his eponymous worm upon the Internet. The wave of infections grew to 10% of the entire Internet within 24 hours, causing astronomically expensive damage for the time. However, the pioneering Morris worm malware wasn’t made with malice, says an FBI retrospective on the “programming error.” It was designed to gauge the size of the Internet, resulting in a classic case of unintended consequences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Morris worm dissection&lt;/head&gt;
    &lt;p&gt;Known to be something of a prankster, Morris must have felt some foreboding about releasing his ‘innocent’ program into the wild. Evidence of this comes from his release method. “He released it by hacking into an MIT computer from his Cornell terminal in Ithaca, New York,” according to the FBI.&lt;/p&gt;
    &lt;p&gt;The Morris worm was written in C and targeted BSD UNIX systems, like VAX and Sun-3 machines. Specifically, the FBI writes, it “exploited a backdoor in the Internet’s electronic mail system and a bug in the ‘finger’ program that identified network users.” In contrast to computer viruses, the worm Morris had devised had no need of a host program, but could self-replicate and spread autonomously.&lt;/p&gt;
    &lt;p&gt;Thankfully, the Morris worm wasn’t written to cause damage to files. Due to those unintended consequences, though, it precipitated massive slowdowns, and messaging delays and system crashes were common symptoms. It became a computer news sensation in the worst possible way. Just to get rid of the worm in a timely fashion, some institutions ended up wiping complete systems and unplugging networks for as long as a week.&lt;/p&gt;
    &lt;p&gt;Among the Morris worm's casualties were prestigious institutions such as Berkeley, Harvard, Princeton, Stanford, Johns Hopkins, NASA, and the Lawrence Livermore National Laboratory.&lt;/p&gt;
    &lt;head rend="h2"&gt;Whodunit?&lt;/head&gt;
    &lt;p&gt;Experts worked hard to find a fix, and while they did so, the question of who was behind the worm came to the fore. Understandably, whoever created and unleashed this worm needed to feel some consequences, and thus, the FBI was brought in.&lt;/p&gt;
    &lt;p&gt;Apparently, Morris sought to anonymously explain and apologize for the worm, but an inadvertent slip of his initials by a friend landed Morris in it.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;FBI interviews and computer file analysis would subsequently confirm Morris was the culprit. He was indicted under the rather freshly inked Computer Fraud and Abuse Act of 1986. After a court appearance for his misdemeanors in 1989, Morris ended up not with jail time, but with a fine, probation, and 400 hours of community service to complete.&lt;/p&gt;
    &lt;head rend="h2"&gt;Computer worms have been around longer than the World Wide Web&lt;/head&gt;
    &lt;p&gt;Back in November 1988, the Internet bore little resemblance to what it is today. For example, the World Wide Web (WWW) wasn’t even a thing. Though the WWW would soon form the core experience for the first tide of surfers in the 90s.&lt;/p&gt;
    &lt;p&gt;At the time, the Internet’s backbone was the NSFNET, the recent successor to ARPANET. Its purpose was mostly to expand the prior backbone’s reach beyond military and defense institutions, and it more broadly embraced academia. While we are here, it is worth mentioning that NSFNET was decommissioned in 1995, and succeeded by the commercial Internet, which emerged in the 1990s off the back of private ISPs and commercial backbones.&lt;/p&gt;
    &lt;p&gt;So, when we talk about 10% of the Internet being paralyzed by the Morris Worm, contemporary estimates are that about 6,000 of the approximately 60,000 connected systems were infected and impacted. Moreover, when we highlighted the potentially massive costs of this first worm propagating, estimates range from $100,000 to millions of dollars.&lt;/p&gt;
    &lt;p&gt;Computer worms have remained a scary phenomenon in recent times. For example, we reported on the first-generation AI worm, the Morris II generative AI worm, last year.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;sb5k&lt;/header&gt;I was working at DEC when the worm slithered its way across the Internet, as part of an engineering team. I also helped manage our Ultrix systems; our IT department knew VMS only.Reply&lt;lb/&gt;I don't remember which CPU was in our systems, but the worm was not able to run on our systems, but I did find it dropped in them.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Gaston404&lt;/header&gt;I completely disagree with the tone of the article. Depicting this as an accident without consequences and limited effect is simply incorrect.Reply&lt;lb/&gt;Back then as a part time job I managed some of the traffic routing through Washington DC. Mail relays were shutdown and backed up queues were spooked off to tape. By today’s standards the volume of traffic may seem trivial but when many of these links ran at 56kbps or less. It was a mess. The main way administrators communicated with each other was email. This also affected collaboration between University researchers and access to the NSF super computer centers.&lt;lb/&gt;At the time rumors maintained that Morris used exploits that he learned from his father who had a consulting agreement with the NSA. So if this is true there is a certain level of non-originality.&lt;lb/&gt;On one hand stronger persecution may have reduced follow on internet crime. On the other hand the fragility demonstrated by this crime, resulted in the creation of procedures to deal with outages. If anything the naive sense of trusted collaboration that pervaded the Internet started to fade.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;derekullo&lt;/header&gt;In 9 years, Tiktok has infected over 90% of the internet!Reply&lt;lb/&gt;Much slower but also much more insidious!&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;DS426&lt;/header&gt;Reply&lt;quote/&gt;The next big social media craze is probably just around the corner. I shutter to think how ludicrous it will be.derekullo said:In 9 years, Tiktok has infected over 90% of the internet!&lt;lb/&gt;Much slower but also much more insidious!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomshardware.com/tech-industry/cyber-security/on-this-day-in-1988-the-morris-worm-slithered-out-and-sparked-a-new-era-in-cybersecurity-10-percent-of-the-internet-was-infected-within-24-hours"/><published>2025-11-04T15:23:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45812606</id><title>Pg_lake: Postgres with Iceberg and data lake access</title><updated>2025-11-05T00:51:17.186812+00:00</updated><content>&lt;doc fingerprint="fb9ba072642955ea"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; integrates Iceberg and data lake files into Postgres. With the &lt;code&gt;pg_lake&lt;/code&gt; extensions, you can use Postgres as a stand-alone lakehouse system that supports transactions and fast queries on Iceberg tables, and can directly work with raw data files in object stores like S3.&lt;/p&gt;
    &lt;p&gt;At a high level, &lt;code&gt;pg_lake&lt;/code&gt; lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create and modify Iceberg tables directly from PostgreSQL, with full transactional guarantees and query them from other engines&lt;/item&gt;
      &lt;item&gt;Query and import data from Parquet, CSV, JSON, and Iceberg files stored in S3 or other compatible object stores&lt;/item&gt;
      &lt;item&gt;Export query results back to S3 in Parquet, CSV, or JSON formats using COPY commands&lt;/item&gt;
      &lt;item&gt;Read geospatial formats supported by GDAL, such as GeoJSON and Shapefiles&lt;/item&gt;
      &lt;item&gt;Use compression transparently with .gz and .zst&lt;/item&gt;
      &lt;item&gt;Use the built-in map type for semi-structured or key–value data&lt;/item&gt;
      &lt;item&gt;Combine heap, Iceberg, and external Parquet/CSV/JSON files in the same SQL queries and modifications — all with full transactional guarantees and no SQL limitations&lt;/item&gt;
      &lt;item&gt;Infer table columns and types from external data sources such as Iceberg, Parquet, JSON, and CSV files&lt;/item&gt;
      &lt;item&gt;Leverage DuckDB’s query engine underneath for fast execution without leaving Postgres&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are two ways to set up &lt;code&gt;pg_lake&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using Docker, for an easy, ready-to-run test environment.&lt;/item&gt;
      &lt;item&gt;Building from source, for a manual setup or development use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both approaches include the PostgreSQL extensions, the &lt;code&gt;pgduck_server&lt;/code&gt; application and setting up S3-compatible storage.&lt;/p&gt;
    &lt;p&gt;Follow the Docker README to set up and run &lt;code&gt;pg_lake&lt;/code&gt; with Docker.&lt;/p&gt;
    &lt;p&gt;Once you’ve built and installed the required components, you can initialize &lt;code&gt;pg_lake&lt;/code&gt; inside Postgres.&lt;/p&gt;
    &lt;p&gt;Create all required extensions at once using &lt;code&gt;CASCADE&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;CREATE EXTENSION pg_lake CASCADE;
NOTICE:  installing required extension "pg_lake_table"
NOTICE:  installing required extension "pg_lake_engine"
NOTICE:  installing required extension "pg_extension_base"
NOTICE:  installing required extension "pg_lake_iceberg"
NOTICE:  installing required extension "pg_lake_copy"
CREATE EXTENSION&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;pgduck_server&lt;/code&gt; is a standalone process that implements the Postgres wire-protocol (locally), and underneath uses &lt;code&gt;DuckDB&lt;/code&gt; to execute queries.&lt;/p&gt;
    &lt;p&gt;When you run &lt;code&gt;pgduck_server&lt;/code&gt; it starts listening to port &lt;code&gt;5332&lt;/code&gt; on unix domain socket:&lt;/p&gt;
    &lt;code&gt;pgduck_server
LOG pgduck_server is listening on unix_socket_directory: /tmp with port 5332, max_clients allowed 10000
&lt;/code&gt;
    &lt;p&gt;As &lt;code&gt;pgduck_server&lt;/code&gt; implements Postgres wire protocol, you can access it via &lt;code&gt;psql&lt;/code&gt; on port &lt;code&gt;5332&lt;/code&gt; and host &lt;code&gt;/tmp&lt;/code&gt; and run commands via DuckDB.&lt;/p&gt;
    &lt;p&gt;For example, you can get the DuckDB version:&lt;/p&gt;
    &lt;code&gt;psql -p 5332 -h /tmp

select version() as duckdb_version; 
duckdb_version 
---------------- 
v1.3.2 (1 row)&lt;/code&gt;
    &lt;p&gt;You can also provide some additional settings while starting the server, to see all:&lt;/p&gt;
    &lt;code&gt;pgduck_server --help
&lt;/code&gt;
    &lt;p&gt;There are some important settings that should be adjusted, especially on production systems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--memory_limit&lt;/code&gt;: Optionally specify the maximum memory of pgduck_server similar to DuckDB's memory_limit, the default is 80 percent of the system memory&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--init_file_path &amp;lt;path&amp;gt;&lt;/code&gt;: Execute all statements in this file on start-up&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--cache_dir&lt;/code&gt;: Specify the directory to use to cache remote files (from S3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pgduck_server&lt;/code&gt; relies on the DuckDB secrets manager for credentials and it follows the credentials chain by default for AWS and GCP. Make sure your cloud credentials are configured properly — for example, by setting them in ~/.aws/credentials.&lt;/p&gt;
    &lt;p&gt;Once you set up the credential chain, you should set the &lt;code&gt;pg_lake_iceberg.default_location_prefix&lt;/code&gt;. This is the location where Iceberg tables are stored:&lt;/p&gt;
    &lt;code&gt;SET pg_lake_iceberg.default_location_prefix TO 's3://testbucketpglake';&lt;/code&gt;
    &lt;p&gt;You can also set the credentials on &lt;code&gt;pgduck_server&lt;/code&gt; for local development with &lt;code&gt;minio&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can create Iceberg tables by adding &lt;code&gt;USING iceberg&lt;/code&gt; to your &lt;code&gt;CREATE TABLE&lt;/code&gt; statements.&lt;/p&gt;
    &lt;code&gt;CREATE TABLE iceberg_test USING iceberg 
      AS SELECT 
            i as key, 'val_'|| i  as val
         FROM 
            generate_series(0,99)i;&lt;/code&gt;
    &lt;p&gt;Then, query it:&lt;/p&gt;
    &lt;code&gt;SELECT count(*) FROM iceberg_test;
 count 
-------
   100
(1 row)&lt;/code&gt;
    &lt;p&gt;You can then see the Iceberg metadata location:&lt;/p&gt;
    &lt;code&gt;SELECT table_name, metadata_location FROM iceberg_tables;


    table_name     |                                                metadata_location
-------------------+--------------------------------------------------------------------------------------------------------------------
 iceberg_test      | s3://testbucketpglake/postgres/public/test/435029/metadata/00001-f0c6e20a-fd1c-4645-87c9-c0c64b92992b.metadata.json&lt;/code&gt;
    &lt;p&gt;You can import or export data directly using &lt;code&gt;COPY&lt;/code&gt; in Parquet, CSV, or newline-delimited JSON formats.  The format is automatically inferred from the file extension, or you can specify it explicitly with &lt;code&gt;COPY&lt;/code&gt; options like &lt;code&gt;WITH (format 'csv', compression 'gzip')&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;-- Copy data from Postgres to S3 with format parquet
-- Read from any data source, including iceberg tables, heap tables or any query results
COPY (SELECT * FROM iceberg_test) TO 's3://testbucketpglake/parquet_data/iceberg_test.parquet';

-- Copy back from S3 to any table in Postgres
-- This example copies into an iceberg table, but could be heap table as well
COPY iceberg_test FROM 's3://testbucketpglake/parquet_data/iceberg_test.parquet';&lt;/code&gt;
    &lt;p&gt;You can create a foreign table directly from a file or set of files without having to specify column names or types.&lt;/p&gt;
    &lt;code&gt;-- use the files under the path, can use * for all files
CREATE FOREIGN TABLE parquet_table() 
SERVER pg_lake 
OPTIONS (path 's3://testbucketpglake/parquet_data/*.parquet');

-- note that we infer the columns from the file
\d parquet_table
              Foreign table "public.parquet_table"
 Column |  Type   | Collation | Nullable | Default | FDW options 
--------+---------+-----------+----------+---------+-------------
 key    | integer |           |          |         | 
 val    | text    |           |          |         | 
Server: pg_lake
FDW options: (path 's3://testbucketpglake/parquet_data/*.parquet')

-- and, query it
select count(*) from parquet_table;
 count 
-------
   100
(1 row)
&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;pg_lake&lt;/code&gt; instance consists of two main components: PostgreSQL with the pg_lake extensions and pgduck_server.&lt;/p&gt;
    &lt;p&gt;Users connect to PostgreSQL to run SQL queries, and the &lt;code&gt;pg_lake&lt;/code&gt; extensions integrate with Postgres’s hooks to handle query planning, transaction boundaries, and overall orchestration of execution.&lt;/p&gt;
    &lt;p&gt;Behind the scenes, parts of query execution are delegated to DuckDB through pgduck_server, a separate multi-threaded process that implements the PostgreSQL wire protocol (locally). This process runs DuckDB together with our duckdb_pglake extension, which adds PostgreSQL-compatible functions and behavior.&lt;/p&gt;
    &lt;p&gt;Users typically don’t need to be aware of &lt;code&gt;pgduck_server&lt;/code&gt;; it operates transparently to improve performance. When appropriate, &lt;code&gt;pg_lake&lt;/code&gt; delegates scanning of the data and the computation to DuckDB’s highly parallel, column-oriented execution engine.&lt;/p&gt;
    &lt;p&gt;This separation also avoids the threading and memory-safety limitations that would arise from embedding DuckDB directly inside the Postgres process, which is designed around process isolation rather than multi-threaded execution. Moreover, it lets us interact with the query engine directly by connecting to it using standard Postgres clients.&lt;/p&gt;
    &lt;p&gt;The team behind pg_lake has a lot of experience building Postgres extensions (e.g. Citus, pg_cron, pg_documentdb). Over time, we’ve learned that large, monolithic PostgreSQL extensions are harder to evolve and maintain.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; follows a modular design built around a set of interoperating components — mostly implemented as PostgreSQL extensions, others as supporting services or libraries.&lt;lb/&gt; Each part focuses on a well-defined layer, such as table and metadata management, catalog and object store integration, query execution, or data format handling. This approach makes it easier to extend, test, and evolve the system, while keeping it familiar to anyone with a PostgreSQL background.&lt;/p&gt;
    &lt;p&gt;The current set of components are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;pg_lake_iceberg: a PostgreSQL extension that implements the Iceberg specification&lt;/item&gt;
      &lt;item&gt;pg_lake_table: a PostgreSQL extension that implements a foreign data wrapper to query files in object storage&lt;/item&gt;
      &lt;item&gt;pg_lake_copy: a PostgreSQL extension that implements COPY to/from your data lake&lt;/item&gt;
      &lt;item&gt;pg_lake_engine: a common module for different pg_lake extensions&lt;/item&gt;
      &lt;item&gt;pg_extension_base: A foundational building block for other extensions&lt;/item&gt;
      &lt;item&gt;pg_extension_updater: An extension for updating all extensions on start-up. See README.md.&lt;/item&gt;
      &lt;item&gt;pg_lake_benchmark: a PostgreSQL extension that performs various benchmarks on lake tables. See README.md.&lt;/item&gt;
      &lt;item&gt;pg_map: A generic map type generator&lt;/item&gt;
      &lt;item&gt;pgduck_server: a stand-alone server that loads DuckDB into the same server machine and exposes DuckDB via the PostgreSQL protocol&lt;/item&gt;
      &lt;item&gt;duckdb_pglake: a DuckDB extension that adds missing PostgreSQL functions to DuckDB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; development started in early 2024 at Crunchy Data with the goal of bringing Iceberg to PostgreSQL. The first few months were focused on building a robust integration of an external query engine (DuckDB). To get to market early, we made the query/import/export features available to Crunchy Bridge customers as Crunchy Bridge for Analytics.&lt;/p&gt;
    &lt;p&gt;Next, we started building a comprehensive implementation of the Iceberg (v2) protocol with support for transactions and almost all PostgreSQL features. In November 2024, we relaunched Crunchy Bridge for Analytics as Crunchy Data Warehouse available on Crunchy Bridge and on-premises.&lt;/p&gt;
    &lt;p&gt;In June 2025, Crunchy Data was acquired by Snowflake. Following the acquisition, Snowflake decided to open source the project as &lt;code&gt;pg_lake&lt;/code&gt; in November 2025. The initial version is 3.0 because of the two prior generations. If you’re currently a Crunchy Data Warehouse user there will be an automatic upgrade path, though some names will change.&lt;/p&gt;
    &lt;p&gt;Full project documentation can be found in the docs directory.&lt;/p&gt;
    &lt;p&gt;Copyright (c) Snowflake Inc. All rights reserved. Licensed under the Apache 2.0 license.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; is dependent on third-party projects Apache Avro and DuckDB. During build, &lt;code&gt;pg_lake&lt;/code&gt; applies patches to Avro and certain DuckDB extensions in order to provide the &lt;code&gt;pg_lake&lt;/code&gt; functionality. The source code associated with the Avro and DuckDB extensions is downloaded from the applicable upstream repos and the source code associated with those projects remains under the original licenses. If you are packaging or redistributing packages that include &lt;code&gt;pg_lake&lt;/code&gt;, please note that you should review those upstream license terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Snowflake-Labs/pg_lake"/><published>2025-11-04T16:12:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45813310</id><title>Launch HN: Plexe (YC X25) – Build production-grade ML models from prompts</title><updated>2025-11-05T00:51:16.690358+00:00</updated><content>&lt;doc fingerprint="d1d50ecbdfaae78"&gt;
  &lt;main&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;Your Agentic ML Engineering&lt;/p&gt;
    &lt;p&gt;Team&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your raw data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and it will build a production-ready model thatâs engineered for your exact business challenge.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
    &lt;p&gt;Spotlight&lt;/p&gt;
    &lt;p&gt;Spotlight&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Featured in BIâs 10 Most Exciting AI Startups from YC Spring 2025&lt;/p&gt;
    &lt;p&gt;Featured in BIâs 10 Most Exciting AI Startups from YC Spring 2025&lt;/p&gt;
    &lt;p&gt;Plexe AI Redefines Credit Underwriting With Real-Time ML Models&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Solutions&lt;/p&gt;
    &lt;p&gt;Solutions&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your data into your competitive advantage.&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most. Youâll see whatâs working, whatâs not, and where the real opportunities are hiding. No code, no setup, no fuss.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and weâll build a production-ready model thatâs engineered for your exact business challenge. Whether itâs predicting churn or fraud detection, youâll go from idea to working AI in hours, not months.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most. Youâll see whatâs working, whatâs not, and where the real opportunities are hiding. No code, no setup, no fuss.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and weâll build a production-ready model thatâs engineered for your exact business challenge. Whether itâs predicting churn or fraud detection, youâll go from idea to working AI in hours, not months.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.plexe.ai/"/><published>2025-11-04T17:07:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45813343</id><title>NoLongerEvil-Thermostat – Nest Generation 1 and 2 Firmware</title><updated>2025-11-05T00:51:16.133166+00:00</updated><content>&lt;doc fingerprint="1eabf0080969b3e8"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;WARNING: EXPERIMENTAL SOFTWARE&lt;p&gt;This project is currently in the experimental/testing phase. Do NOT use this firmware on any thermostat that is critical for your heating or cooling needs. Flashing this firmware may brick your device or cause unexpected behavior. Only proceed if you have a backup thermostat or can afford to have your device non-functional during testing.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;This directory contains the tools and firmware needed to flash custom firmware to Nest Thermostat devices using the OMAP DFU (Device Firmware Update) interface.&lt;/p&gt;
    &lt;p&gt;This firmware loader uses the OMAP bootloader interface to flash custom bootloader and kernel images to Nest Thermostat devices. The device must be put into DFU mode to accept new firmware.&lt;/p&gt;
    &lt;p&gt;Important: After flashing this firmware, your device will no longer contact Nest/Google servers. It will operate independently and connect to the NoLongerEvil platform instead, giving you complete control over your thermostat.&lt;/p&gt;
    &lt;p&gt;The custom firmware flashes the device with modified bootloader and kernel components that redirect all network traffic from the original Nest/Google servers to a server we specify. This server hosts a reverse-engineered replica of their API, allowing the thermostat to function independently while giving you complete control over your device data and settings.&lt;/p&gt;
    &lt;p&gt;By intercepting the communication layer, the thermostat believes it's communicating with the official Nest infrastructure, but instead connects to the NoLongerEvil platform. This approach ensures full compatibility with the device's existing software while breaking free from Google's cloud dependency.&lt;/p&gt;
    &lt;code&gt;git clone --recurse-submodules https://github.com/codykociemba/NoLongerEvil-Thermostat.git
cd NoLongerEvil-Thermostat&lt;/code&gt;
    &lt;p&gt;Before building, you'll need to install some required packages:&lt;/p&gt;
    &lt;code&gt;sudo apt-get update
sudo apt-get install build-essential libusb-1.0-0-dev gcc&lt;/code&gt;
    &lt;p&gt;First, install Xcode Command Line Tools:&lt;/p&gt;
    &lt;code&gt;xcode-select --install&lt;/code&gt;
    &lt;p&gt;Then install libusb using Homebrew (the build script will attempt to install this automatically if missing):&lt;/p&gt;
    &lt;code&gt;# Install Homebrew if you don't have it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install libusb
brew install libusb&lt;/code&gt;
    &lt;code&gt;chmod +x build.sh
./build.sh&lt;/code&gt;
    &lt;p&gt;The build script will automatically detect your operating system (Linux, macOS, or Windows) and build the appropriate binary.&lt;/p&gt;
    &lt;p&gt;IMPORTANT: You must start the installer script BEFORE rebooting the device.&lt;/p&gt;
    &lt;code&gt;chmod +x install.sh
./install.sh&lt;/code&gt;
    &lt;code&gt;chmod +x install.sh
./install.sh&lt;/code&gt;
    &lt;p&gt;Note for macOS: You may need to grant USB permissions. If you encounter permission issues, check System Preferences → Security &amp;amp; Privacy.&lt;/p&gt;
    &lt;p&gt;The script will wait for the device to enter DFU mode.&lt;/p&gt;
    &lt;p&gt;Follow these steps carefully:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Charge the device - Ensure your Nest Thermostat is properly charged (at least 50% battery recommended)&lt;/item&gt;
      &lt;item&gt;Remove from wall - Remove the Nest from its back plate/wall mount&lt;/item&gt;
      &lt;item&gt;Connect via USB - Plug the Nest into your computer using a micro USB cable&lt;/item&gt;
      &lt;item&gt;Wait for the installer - Make sure the &lt;code&gt;install.sh&lt;/code&gt;script is running and waiting&lt;/item&gt;
      &lt;item&gt;Reboot the device - Press and hold down on the display for 10-15 seconds until the device reboots&lt;/item&gt;
      &lt;item&gt;DFU mode active - Once it reboots, the device will enter DFU mode and the installer script will recognize it and begin flashing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The firmware installer will automatically detect the device and flash the custom bootloader (x-load, u-boot) and kernel (uImage).&lt;/p&gt;
    &lt;p&gt;After the firmware is flashed successfully, you should see our logo on the device screen:&lt;/p&gt;
    &lt;p&gt;Important:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Keep the device plugged in via USB&lt;/item&gt;
      &lt;item&gt;Wait for the device to complete its boot sequence (this may take 3-4 minutes)&lt;/item&gt;
      &lt;item&gt;Do not disconnect or power off the device during this time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once the device has fully rebooted:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Visit https://nolongerevil.com in your web browser&lt;/item&gt;
      &lt;item&gt;Register an account (or sign in if you already have one)&lt;/item&gt;
      &lt;item&gt;Navigate to your Dashboard&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You will see a "No devices" screen that prompts you for an entry code.&lt;/p&gt;
    &lt;p&gt;To link your Nest device to your NoLongerEvil account:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;On your Nest device, navigate to: Settings → Nest App → Get Entry Code&lt;/item&gt;
      &lt;item&gt;The device will display a unique entry code&lt;/item&gt;
      &lt;item&gt;Enter this code on the NoLongerEvil dashboard&lt;/item&gt;
      &lt;item&gt;Your device is now linked and ready to use!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The firmware installation process installs three components:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;x-load.bin - First-stage bootloader (X-Loader for OMAP)&lt;/item&gt;
      &lt;item&gt;u-boot.bin - Second-stage bootloader (Das U-Boot) loaded at address 0x80100000&lt;/item&gt;
      &lt;item&gt;uImage - Linux kernel image loaded at address 0x80A00000&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After flashing, the device jumps to execution at 0x80100000 (u-boot).&lt;/p&gt;
    &lt;p&gt;This tool provides low-level access to the device's boot process. Use responsibly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only use on devices you own&lt;/item&gt;
      &lt;item&gt;Improper firmware can brick your device (Don't sue me bro)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project builds upon the excellent work of several security researchers and developers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;grant-h / ajb142 - omap_loader, the USB bootloader tool used to flash OMAP devices&lt;/item&gt;
      &lt;item&gt;exploiteers (GTVHacker) - Original research and development of the Nest DFU attack, which demonstrated the ability to flash custom firmware to Nest devices gen 1 &amp;amp; gen 2&lt;/item&gt;
      &lt;item&gt;FULU and all bounty backers - For funding the Nest Learning Thermostat Gen 1/2 bounty and supporting the right-to-repair movement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Without their groundbreaking research, open-source contributions, and advocacy for device ownership rights, this work would not be possible. Thank you!&lt;/p&gt;
    &lt;p&gt;We are committed to transparency and the right-to-repair movement. The firmware images and backend API server code will be open sourced soon, allowing the community to audit, improve, and self-host their own infrastructure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/codykociemba/NoLongerEvil-Thermostat"/><published>2025-11-04T17:10:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45813767</id><title>Codemaps: Understand Code, Before You Vibe It</title><updated>2025-11-05T00:51:15.902833+00:00</updated><content>&lt;doc fingerprint="3fc096052cb3ae5f"&gt;
  &lt;main&gt;
    &lt;quote&gt;“Your code is your understanding of the problem you’re exploring. So it’s only when you have your code in your head that you really understand the problem.” — Paul Graham&lt;/quote&gt;
    &lt;p&gt;Software development only becomes engineering with understanding. Your ability to reason through your most challenging coding tasks is constrained by your mental model of how things work — in other words, how quickly and how well you onboard to any codebase for solving any problem. However most AI vibe coding tools are aimed at relieving you of that burden by reading → thinking → writing the code for you, increasing the separation from you and your code. This is fine for low value, commodity tasks, but absolutely unacceptable for the hard, sensitive, and high value work that defines real engineering.&lt;/p&gt;
    &lt;p&gt;We all need more AI that turns your brain ON, not OFF.&lt;/p&gt;
    &lt;p&gt;Today we are announcing Windsurf Codemaps, which are first-of-its-kind AI-annotated structured maps of your code, powered by SWE-1.5 and Claude Sonnet 4.5. Building on our popular work from DeepWiki and Ask Devin, Codemaps is the next step in hyper-contextualized codebase understanding, grounded in precise code navigation.&lt;/p&gt;
    &lt;p&gt;Every engineering task — debugging, refactors, new features — starts with understanding. Great engineers aren’t just good at writing code; they’re good at reading it, building mental models that span files, layers, and systems.&lt;/p&gt;
    &lt;p&gt;But modern codebases are sprawling: hundreds of files, multiple services, dense abstractions. Based on own experience and deep conversations with our customers across the Fortune 500, even top engineers spend much of their deep-work time finding and remembering what matters.&lt;/p&gt;
    &lt;p&gt;It’s a huge tax on productivity:&lt;/p&gt;
    &lt;p&gt;This is the frontier that AI coding tools haven’t yet solved. Onboarding isn’t even a onetime cost, you pay it every time you switch context and codebases. The faster and better you understand your codebase, the faster and better you’ll be able to fix it yourself, or prompt agents to do it.&lt;/p&gt;
    &lt;p&gt;Until today, the standard approach by Copilot, Claude Code, Codex, and even Windsurf Cascade, was to have you ask questions of a generalist agent with access to your code in a typical chat experience. But those solutions don’t solve focused onboarding and strongly grounded navigation to onboard, debug, and better context engineer for your codebase.&lt;/p&gt;
    &lt;p&gt;At Cognition, we’ve been investing far more deeply in understanding:&lt;/p&gt;
    &lt;p&gt;Codemaps is our next investment in tooling that makes engineers the best versions of themselves.&lt;/p&gt;
    &lt;p&gt;When you first open Codemaps (click the new maps icon or Cmd+Shift+C in Windsurf) with a codebase opened in Windsurf, you can enter in a prompt for the task you are trying to do, or take one of the automatic suggestions. You can choose a Fast (SWE-1.5) or Smart (Sonnet 4.5) model to generate your Codemap. Every Codemap is snapshots your code and respects ZDR.&lt;/p&gt;
    &lt;p&gt;Based on our demos to customers, you will experience Codemaps best on your own codebase and asking a question about how or where some functionality works. In our dogfooding, we find particular effectiveness tracing through client-server problems or a data pipeline or debugging auth/security issues:&lt;/p&gt;
    &lt;p&gt;If all you wanted was to quickly jump through grouped and nested parts of your code that related to your question, this is already an improvement compared to asking the same question in Cascade, where answers are not as densely linked to the exact lines of code.&lt;/p&gt;
    &lt;p&gt;You can also toggle over to a visually drawn Codemap, which performs the same functions when you click on individual nodes: they send you to the exact part of the codebase you clicked on.&lt;/p&gt;
    &lt;p&gt;However, if you want a little more context, then you can hit “See more” in any section to expand our “trace guide” that gives a more descriptive explanation of what groups the discovered lines together.&lt;/p&gt;
    &lt;p&gt;Finally, inside Cascade you can also reference a codemap for the agent with &lt;code&gt;@{codemap}&lt;/code&gt; (all of it, or a particular subsection) in your prompt to provide more specific context and dramatically improve the performance of your agent for your task.&lt;/p&gt;
    &lt;p&gt;We feel that the popular usage of “vibe coding” has strayed far from the original intent, into a blanket endorsement of plowing through any and all AI generated code slop. If you look at the difference between the most productive vs the problematic AI-assisted coders, the productive ones can surf the vibes of code that they understand well, whereas people get into trouble when the code they generate and maintain starts to outstrip their ability to understand it.&lt;/p&gt;
    &lt;p&gt;To understand is to be accountable. As AI takes on more of the easy work, the hard problems left to humans are the ones that demand real comprehension: debugging complex systems, refactoring legacy code, making architecture decisions. In this new era, the engineer’s role shifts from authoring to accountability — you might not write every line, but you’re still responsible for what ships. That accountability depends on understanding what the AI produced, why it changed, and whether it’s safe. Codemaps closes that gap by giving both the human and the AI a shared picture of the system: how it’s structured, how data flows, where dependencies live. Codemaps is our latest Fast Agent, but as we discussed in the Semi-Async Valley of Death, our goal isn't just about speed, it is to help your human engineers stay in flow, stay on top of their code, and to move faster and more confidently on the hardest problems, never shipping slop that they don't understand.&lt;/p&gt;
    &lt;p&gt;Augment engineers for high value work, relieve them of low value work. The other local minima that the coding agent industry has gotten stuck in is in the general messaging of replacing engineers for low value work and not having any solutions for the hardest tasks apart from “pls ultrathink high, no mistakes”, which only gives autonomy to the agent, at the expense of the engineer. The long history of human-machine collaboration teaches us that we can always do more with the synergy rather than humans-alone or AI-alone. Our view is that the AI product that engineers will love most is the one that makes them better at their job, not the one that tries to replace them with a sloppy facsimile of themselves.&lt;/p&gt;
    &lt;p&gt;With Codemaps, we are now exposing to humans some of the indexing and analysis we do inside of our coding agents. These artifacts are sharable today across teams for learning and discussion, but we have yet to benchmark how much better they can make our coding agents like Devin and Cascade in solving challenging tasks on their own. We also see opportunities for connecting and annotating codemaps, as well as defining an open &lt;code&gt;.codemap&lt;/code&gt; protocol that can be used by other code agents and custom tooling built by you. Complementing our Fast Context feature, this is an advancement in human-readable automatic context engineering.&lt;/p&gt;
    &lt;p&gt;You can try Codemaps on the latest versions of Windsurf, or DeepWiki!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cognition.ai/blog/codemaps"/><published>2025-11-04T17:47:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45815279</id><title>Singapore to cane scammers as billions lost in financial crimes</title><updated>2025-11-05T00:51:15.710550+00:00</updated><content>&lt;doc fingerprint="2f7394b1092897db"&gt;
  &lt;main&gt;
    &lt;p&gt;The measure, passed in a parliamentary session today, comes as financial frauds are exploding in the Southeast Asian country and globally.&lt;/p&gt;
    &lt;p&gt;Scam victims in Singapore have lost around S$3.8 billion (US$2.9 billion) since 2020, with a record S$1.1 billion in losses last year, according to data from the local police.&lt;/p&gt;
    &lt;p&gt;The pervasiveness of the problem alarmed authorities, with the number of cases reaching nearly 20,000 in the first half of this year, with S$456.4 million in losses.&lt;/p&gt;
    &lt;p&gt;“Scams are by far the most prevalent crime type in Singapore today,” Sim Ann, senior minister of state for home affairs, said during the session.&lt;/p&gt;
    &lt;p&gt;“They make up 60% of all reported crimes,” she said.&lt;/p&gt;
    &lt;p&gt;Singapore already uses caning for several crimes, such as vandalism, serious sexual offenses and robbery.&lt;/p&gt;
    &lt;p&gt;The Southeast Asian financial hub has implemented a series of measures to combat the surge in scams, including by restricting access to key banking and telecoms services for individuals who are linked to scam activities.&lt;/p&gt;
    &lt;p&gt;The country also passed a new law earlier this year that would allow the police to control the bank accounts of individuals who they suspect to be scam targets and limit what transactions they can do.&lt;/p&gt;
    &lt;p&gt;Singapore’s police and the central bank have also worked with major retail banks since 2022 to distinguish scams from legitimate transactions, trace fund flows and freeze accounts suspected to be linked to criminal operations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.freemalaysiatoday.com/category/highlight/2025/11/04/singapore-to-cane-scammers-as-billions-lost-in-financial-crimes"/><published>2025-11-04T20:02:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45815623</id><title>Precompiled headers and why Squid won't be using them (2023)</title><updated>2025-11-05T00:51:15.620353+00:00</updated><content>&lt;doc fingerprint="3dc4b2f154213ce0"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;First thing, what are precompiled headers?&lt;/head&gt;
    &lt;p&gt;Once an entire dependency tree is exploded, a single c++ include file can become huge, and easily span tens if not hundreds of source files; these will need to be parsed for each compilation unit (c++ file), resulting in a large amount of duplicate work.&lt;/p&gt;
    &lt;p&gt;So compiler writers came up with the clever idea to optionally save an intermediate state of key headers, to reduce the amount of duplicate work. gcc , clang, msvc all support some variant of the precompiled headers idea.&lt;/p&gt;
    &lt;head rend="h2"&gt;How do they work in practice?i&lt;/head&gt;
    &lt;p&gt;Each compiler has its own quirks.&lt;/p&gt;
    &lt;p&gt;On GCC&lt;/p&gt;
    &lt;p&gt;A precompiled header has the same name as the header it accelerates with an additional &lt;code&gt;.gch&lt;/code&gt; suffix, placed in the same directory as the header file it refers to. It is generated by calling the compiler with the same exact command line arguments as used to build the code, with the additional switches &lt;code&gt;-x c++-header&lt;/code&gt; . If a precompiled header is present, it will be automatically used&lt;/p&gt;
    &lt;head rend="h3"&gt;On clang&lt;/head&gt;
    &lt;p&gt;A precompiled header has the same name as the header it accelerates with an additional &lt;code&gt;.pch&lt;/code&gt; suffix. It is generated by calling the compiler with the same arguments as used to build the code, with the additional switches &lt;code&gt;-x c++-header -emit-pch &lt;/code&gt;(the latter might be implicit if the former is supplied). To use it, it is not enough that it be present; the compiler switch &lt;code&gt;-include-pch &amp;lt;pch-file-path&amp;gt;&lt;/code&gt; must be used.&lt;/p&gt;
    &lt;p&gt;On top of this: clang internal documentation highlights that there can only be one precompiled header and it must be included at the beginning of the translation unit&lt;/p&gt;
    &lt;head rend="h3"&gt;On MSVC&lt;/head&gt;
    &lt;p&gt;This is not yet a specific target for squid&lt;/p&gt;
    &lt;head rend="h2"&gt;Could it work for squid?&lt;/head&gt;
    &lt;p&gt;Yes, in theory. Our coding guidelines mandate that each c++ file start including “squid.h”, which in turn includes our whole portability abstraction layer, which in turn takes in several system files. On my Ubuntu Linux system, a total of 206 header files have to be read and parsed just for this purpose for each of the over 800 files that make up squid. Sounds promising!&lt;/p&gt;
    &lt;head rend="h2"&gt;Does it work for squid?&lt;/head&gt;
    &lt;p&gt;In short, unfortunately not. I have experimented with a feature branch, and the results are not what I was hoping for, under several dimensions.&lt;/p&gt;
    &lt;head rend="h3"&gt;The good: performance gains&lt;/head&gt;
    &lt;p&gt;I ran some checks, on a NUC6i7KYB (Intel(R) Core(TM) i7-6770HQ CPU @ 2.60GHz, with 16 GiB core, SSD). The test command was&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;git clean -fdx &amp;amp;&amp;amp; ./bootstrap.sh &amp;amp;&amp;amp; ./configure &amp;amp;&amp;amp; time (make -s -j12 all &amp;amp;&amp;amp; make -s -j12 check)&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Over 6 attempts, wall clock time averaged 10 minutes and 18 seconds without precompiled headers, and 9 minutes and 48 seconds with them, so a roughly 30 seconds (or about 5%) compile time improvement with gcc. Good but not earth shaking.&lt;/p&gt;
    &lt;head rend="h3"&gt;The bad: poor integration with the autotools toolchain (gcc edition)&lt;/head&gt;
    &lt;p&gt;Autotools’ stance on precompiled headers is pretty clear:&lt;/p&gt;
    &lt;p&gt;This is how I’ve done it. It’s hacky, but some parts of it may not apply to other projects’ setup.&lt;/p&gt;
    &lt;p&gt;In configure.ac, define an user argument &lt;code&gt;--enable-precompiled-headers&lt;/code&gt; , and react to it with an automake conditional &lt;code&gt;ENABLE_PCH_GCC&lt;/code&gt; .&lt;/p&gt;
    &lt;p&gt;In src/Makefile.am , define a custom Makefile rule that builds the precompiled header:&lt;/p&gt;
    &lt;code&gt;$(top_srcdir)/include/squid.h.gch: $(top_srcdir)/include/squid.h
    $(CXXCOMPILE) -x c++-header -o $@ $&amp;lt;&lt;/code&gt;
    &lt;p&gt;What’s wrong with this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;src/Makefile.am is touching files in include/ &lt;lb/&gt;This is necessary because include/ doesn’t have a Makefile.am of its own, and the top level Makefile.am doesn’t have access to the CXXCOMPILE variable.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;srcdir&lt;/code&gt;shouldn’t be mucked about at build time; that’s what&lt;code&gt;builddir&lt;/code&gt;is for&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then, add a section&lt;/p&gt;
    &lt;code&gt;if ENABLE_PCH_GCC&lt;/code&gt;
    &lt;p&gt;which is then referenced in&lt;/p&gt;
    &lt;code&gt;BUILT_SOURCES = \
   dnl ... \
   $(PCH_FILE)&lt;/code&gt;
    &lt;p&gt;This will pull in the precompiled header in the list of dependencies of squid, unit tests, and files to clean up. We can’t really control the order this gets built in, but it isn’t a big deal: if we need to compile anything before the precompiled header is built, everything will still work, just without the speed bump.&lt;/p&gt;
    &lt;head rend="h3"&gt;The worse: poor integration with the autotools toolchain (clang edition)&lt;/head&gt;
    &lt;p&gt;Clang has one extra problem compared to gcc: to actually use the precompiled header, it needs the &lt;code&gt;-include-pch&lt;/code&gt; &amp;lt;file&amp;gt; option. If the option is used, the file needs to be there, or the build will fail.&lt;/p&gt;
    &lt;p&gt;Which makes being unable to control the build order a showstopper. We would need to build the precompiled header file without that flag before we do anything else. But looking at the generated &lt;code&gt;src/Makefile&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;all: $(BUILT_SOURCES)&lt;/code&gt;
    &lt;p&gt;One way to make sure that we only add the –&lt;code&gt;include-pch&lt;/code&gt; option would be to send it down the recursive make invocation, except we don’t control that.&lt;/p&gt;
    &lt;head rend="h3"&gt;That’s it, I give up&lt;/head&gt;
    &lt;p&gt;The benefit is just not worth the number of hacks and complexity.&lt;/p&gt;
    &lt;head rend="h3"&gt;What could make it work?&lt;/head&gt;
    &lt;p&gt;gcc gets this behaviour right; it would be great if clang took inspiration from them. At the very least, do not fail building if the included pch was missing. This would enable treating it for what it is: an optimisation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://squidproxy.wordpress.com/2023/10/10/precompiled-headers-and-why-squid-wont-be-using-them/"/><published>2025-11-04T20:38:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45816041</id><title>I took all my projects off the cloud, saving thousands of dollars</title><updated>2025-11-05T00:51:15.506402+00:00</updated><content/><link href="https://rameerez.com/send-this-article-to-your-friend-who-still-thinks-the-cloud-is-a-good-idea/"/><published>2025-11-04T21:22:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45816191</id><title>BlackRock's Larry Fink: "Tokenization", Digital IDs, &amp; Social Credit</title><updated>2025-11-05T00:51:15.438537+00:00</updated><content/><link href="https://thewinepress.substack.com/p/tokenization-blackrocks-larry-fink"/><published>2025-11-04T21:39:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45816853</id><title>Mr Tiff</title><updated>2025-11-05T00:51:15.213558+00:00</updated><content>&lt;doc fingerprint="6498b19bb326a2bd"&gt;
  &lt;main&gt;
    &lt;p&gt;For as long as I have published my books, one of my overarching goals was to give credit to those who actually invented the hardware and software that we use.&lt;/p&gt;
    &lt;p&gt;I have spent 10,000+ hours to create an accurate record of their work but I'm not complaining. The 'as-close-to-possible' truth of invention by individuals or teams meant identifying the work, educating myself, writing questions, and sending emails. And after that process, I set up a chat because it all gets down to talking to someone on the other side of the world, about something that happened 30 or 40 years ago.&lt;/p&gt;
    &lt;p&gt;If the invention involves a team, I try to interview more than one person, so I can cross-check the facts. Not to call anyone out, it’s just that, given time, we all forget the facts. And everyone adds their personal take. It’s because of that, for example, that I know the English musician Peter Gabriel really did visit Apple's research labs as they tested the Apple Sound Chip, and gave the team his personal approval to use the song 'Red Rain' for the Macintosh II launch. Wil Oxford, Steve Perlman, Mike Potel, Mark Lentczner and Steve Milne told me so.&lt;/p&gt;
    &lt;p&gt;As I was wrapping up Version 2.3 of Inventing the Future, I spoke with Steve M and Mark about the AIFF (Audio Interchange File Format) audio standard that they built around the same time as their VIP visit. They did so as professional programmers, amateur musicians and electronic music experts. Milne and Lentczner knew users needed a standard file format to make their work lives easier and to fend off confusion in the nascent MIDI marketplace. But it didn't exist. So Steve and Mark consulted with users and manufacturers in the Apple cafeteria after hours. This work is interesting on its own but it also underpinned other research. The AIFF, Apple Sound Chip, and MIDI Manager work scaffolded QuickTime and its extensible video formats and programs in 1991. Senior engineer Toby Farrand told me:&lt;/p&gt;
    &lt;p&gt;Audio drove the development of QuickTime more than anything.&lt;/p&gt;
    &lt;p&gt;So who or what drove the development of AIFF?&lt;/p&gt;
    &lt;p&gt;Steve and Mark referred me to the IFF (Interchange File Format (IFF) and the TIFF (Tag Image File Format) that were built before AIFF, in 1985 and 1986 respectively. These file formats were the benchmark for open media standards. My search pivoted, as it always does, to understand those inventions. I expected to be able to find the engineer or engineers names, track them down and interview them. It has worked around 100 times before.&lt;/p&gt;
    &lt;p&gt;Jerry Morrison created IFF while working at Electronic Arts and then went to Apple, where he liaised with the AIFF team. I could easily background his work.&lt;/p&gt;
    &lt;p&gt;So I turned my attention to TIFF, built initially as an image standard for desktop publishing. TIFF was able to store monochrome, grayscale, and color images, alongside metadata such as size, compression algorithms, and color space information. In many ways, it was a lot like AIFF so I was keen to know more. But I couldn't find a TIFF creator. No matter how I enquired, Aldus created TIFF.&lt;/p&gt;
    &lt;p&gt;To be clear, while a search for AIFF will offer up a company (Apple) not a person, I was able to find Milne and Lentczner in part because of their unique names and because Apple publicised the AIFF work and those publications are archived.&lt;/p&gt;
    &lt;p&gt;All I had was Aldus, an American company that created desktop publishing with the help of Apple and Adobe. In fact, Paul Brainerd, the cofounder of Aldus coined the term 'desktop publishing' to quickly explain the technicality of what they were doing to potential investors. But Aldus and their seminal product, PageMaker, are long gone, and there were no breadcrumbs for TIFF's creation.&lt;/p&gt;
    &lt;p&gt;Finally, after a day-long trawl through MacWeek back issues, I found Steve Carlson. (below)&lt;/p&gt;
    &lt;p&gt;Then I ran a similar length search through the Computer History Museum’s amazing Oral Histories transcriptions. Brainerd mentioned Carlson's name in an interview. (below)&lt;/p&gt;
    &lt;p&gt;But it was too brief an explanation so I kept looking. Then the trail went cold.&lt;/p&gt;
    &lt;p&gt;And that was because, folks had misspelt his name when quoting him and then that was copied into magazines, and reviews and so forth. Brainerd's CHM interview transcript was wrong. But I didn’t know that.&lt;/p&gt;
    &lt;p&gt;I just kept looking for Steve Carlson.&lt;/p&gt;
    &lt;p&gt;I found other inventors because they had unique middle or last names or by random methods such as searching glider pilot licences in the Napa Valley after a tip from a former colleague that 'so and so' was a pilot in retirement. I had no tips, no links, nothing.&lt;/p&gt;
    &lt;p&gt;Why couldn’t I find Steve Carlson?&lt;/p&gt;
    &lt;p&gt;All the while, the answer was right under my nose. I had downloaded the final Aldus TIFF specifications document, hoping to find the author’s name. However, the name is seemingly written in white text on white paper - making it invisible. What?&lt;/p&gt;
    &lt;p&gt;See below where I have highlighted the region with a blue block over the text.&lt;/p&gt;
    &lt;p&gt;For a reason I can’t recall, I downloaded a plain text version and typed in Carlson to see if he was mentioned, but I must have paused at ‘Carls...' and the search functionality automatically filled in the rest. Suddenly I was staring at:&lt;/p&gt;
    &lt;p&gt;Author/Editor/Arbitrator: Steve Carlsen.&lt;/p&gt;
    &lt;p&gt;‘Carls-EN’&lt;/p&gt;
    &lt;p&gt;A quick trip to Google patents, and a search for Steve Carlsen, Stephen Carlsen. Bingo! Stephen E. Carlsen’s patents at Aldus (and Adobe) in Issaquah, WA.&lt;/p&gt;
    &lt;p&gt;I checked the geography, as most folks of a certain age do not stray far from the addresses filed in their patents, and typed Stephen’s correctly spelled surname into the online US White Pages for Washington State. There was ‘a’ Stephen Carlsen listed in a retirement village in WA. His age matched, but there were no public facing email addresses.&lt;/p&gt;
    &lt;p&gt;I searched bulletin boards on the topic of TIFF, as I had found a former Apple engineer that way. Don had picked an abbreviation of his initials and numbers to post on BBS in his college days and then carried that same combination into adulthood. Many of us did. I took a punt pasting his unique prefix into hotmail, gmail etc. and found Don and interviewed him, but - Stephen Carlsen did not show up in a BBS. So, no email to try.&lt;/p&gt;
    &lt;p&gt;My ‘last straw' method for finding someone is a stamped envelope. I wrote, printed and mailed a one-page letter to Stephen's listed address, and crossed my fingers. Four months later he popped up in my email.&lt;/p&gt;
    &lt;p&gt;It was a surprise and a relief. We swapped a few emails, and he confirmed the TIFF catalyst story. For Stephen it was 'no big deal'. Once he had built the initial TIFF, Aldus needed to convince 3rd party developers and scanner manufacturers to agree to TIFF as a standard.&lt;/p&gt;
    &lt;p&gt;“We had to define and promote an industry standard for storing and processing scanned images, so that we wouldn't have to write import filters for every model of every scanner that would soon be entering the budding desktop scanner market."&lt;/p&gt;
    &lt;p&gt;Stephen himself did much of the evangelizing as Paul Brainerd later pointed out:&lt;/p&gt;
    &lt;p&gt;“(Steve) developed the standard, and then we went out and promoted it in a series of meetings with specific companies - as well as some workshops we ran in Seattle and the Bay Area during the Seybold shows and the MacWorld shows.”&lt;/p&gt;
    &lt;p&gt;I sent Stephen a draft of what I had written and he sent a prompt reply saying - ‘Looks good’.&lt;/p&gt;
    &lt;p&gt;I followed up asking him how he ended up at a tiny startup in Seattle called Aldus.&lt;/p&gt;
    &lt;p&gt;At that time, I was interviewing for a graphics position at Boeing Computer Services in Seattle, and noticed a small wanted ad that sounded really interesting, and seemed to be an excellent match for my background and interests. I interviewed with Paul and the 5-person mostly-ex-Atex engineering team, and I was hired.&lt;/p&gt;
    &lt;p&gt;Out of curiosity I put Stephen's email address, now that I knew it, into a Duck Duck search and found him helping people online with TIFF queries long after Aldus had been acquired by Adobe. He also contributed to a Google Group called tiffcentral.&lt;/p&gt;
    &lt;p&gt;Having interviewed so many people across more than a decade, I’ve got pretty good at judging those who would like to talk or type, those who are verbose and those that are not. I knew Stephen had said what he was going to say. I added his pioneering work on TIFF to the AIFF story and moved on.&lt;/p&gt;
    &lt;p&gt;Two years had flown by when I received an email yesterday. His ex-wife Peggy found my paper letter and wrote to me. Stephen passed away earlier this year.&lt;/p&gt;
    &lt;p&gt;Thank you for your interest in and support of Stephen’s brilliant work creating TIFF. I’m not surprised Stephen didn’t finish corresponding with you, as he had begun to struggle with using his computer and phone. Some days were better than others for him, but he began to lose touch with people during those months you were reaching out to him. He was a humble man, and I guess never pushed to be recognized, although I believe those who worked with him knew the truth. His last week was in my home, where he was never left alone.&lt;/p&gt;
    &lt;p&gt;Peggy finished the email with, ‘I called him Mr TIFF up to his last moment.'&lt;/p&gt;
    &lt;p&gt;The 10,000+ hours of book research disappeared in an instant. As sad as it was, I could see clearly that all of my work was worth it. Every single second. Because of this email.&lt;/p&gt;
    &lt;p&gt;Mr TIFF.&lt;/p&gt;
    &lt;p&gt;Last night, as everyone in my house went to sleep, I took a deep breath and edited the Wikipedia page for TIFF, the Tag Image File Format.&lt;/p&gt;
    &lt;p&gt;It no longer reads ‘created by Aldus’, it reads ‘…created by Stephen Carlsen, an engineer at Aldus'&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://inventingthefuture.ghost.io/mr-tiff/"/><published>2025-11-04T22:57:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45816879</id><title>Patching 68K Software – SimpleText</title><updated>2025-11-05T00:51:15.010378+00:00</updated><content>&lt;doc fingerprint="b2497ef403174708"&gt;
  &lt;main&gt;
    &lt;p&gt;Someone asked to have SimpleText open a smaller text window at startup. Initially, I assumed this would be a fairly easy fix by just overwriting a few constant values in SimpleText code. It turned out to be a pain -- but I learned a lot along the way.&lt;lb/&gt;You need to have the code editor (from one of the Apple developer CDs) in your ResEdit preference file in order to disassemble code resources within ResEdit. Then, open each 'CODE' resource of SimpleText and search for _SizeWindow (A91D). Or, just skim the code until you see system calls that look like they have something to do with windows. Here is a nice chunk in routine Anon48. A new window is created, then it looks at the main device, looks at the size of the menu bar (MBarHeight), sets the port, and moves and sizes the window.&lt;lb/&gt;But, uh oh, earlier in the code it checks what type of window it is opening. A patch is going to need to avoid resizing code for pictures, video, and the about box.&lt;lb/&gt;I could not locate any obvious constants to adjust. Instead, I would need to inject a more complicated routine that detects whether it was a text window and substitute a new rectangle for the size. But, you cannot simply insert code, as it would move all subsequent code down, and the jumps (subroutine calls) that cross over that location would now jump to the wrong spots. So, I need to jump out of their code to my own (appended at the end of the code resource) and return.&lt;lb/&gt;For example, SimpleText's code to get the size of MBarHeight can easily be performed elsewhere. My routine need only return the MBarHeight in register D0 before returning. That gives me 8 bytes to overwrite with my jump.&lt;lb/&gt;Here is my replacement code. It still is only 8 bytes. But, I now jump to my subroutine, check the result, and jump over their resizing code if my routine says it is changing the window size.&lt;lb/&gt;In my subroutine, I make sure all the needed information is in registers (which I checked that SimpleText was not using), I call my various functions and then perform any work that was lost from overwriting or jumping over the original code. Specifically, I get the MBarHeight into D0 and set the current port to the window.&lt;lb/&gt;Easy! But, later in the code, SimpleText reads the content of whatever document is being opened and once again resizes the window. So, I needed to patch later code as well. How could I determine at that point that a replacement window size was being used? I simply store the result of the first subroutine (see SetRecentResult above) and then check it on later calls.&lt;lb/&gt;Where could I store this information? it is not possible to add global variables and the registers are all reused by SimpleText between the first and second routines. Well, you can store a variable (or an entire structure with many variables) within the code itself. Here is my little workaround for CodeWarrior.&lt;lb/&gt;A couple of other tricks.&lt;lb/&gt;1. The system routine GetHandleSize has some glue code (they intercept the call in a local library before calling the system). I needed this call, but didn't want to add the weight of CodeWarrior's libary. So, I defined the direct call to GetHandleSize (I didn't need the glue fix).&lt;lb/&gt;2. You can pass any of the scratch registers (D0-D2, A0-A1, FP0-FP3) to a C function. The way of defining that in CodeWarrior is noted below. You cannot use any other registers. To make debugging easier, I wrote the original subroutine as a true C function, and the register-&amp;gt;C function as a wrapper.&lt;lb/&gt;3. CodeWarrior does not support BSR for some reason. Use JSR instead. Also, a called routine must be placed before the caller routine in order to generate a short relative JSR rather than absolute address. See my 'RecentResult' example above, where the routines that call RecentResult are placed after it in code.&lt;lb/&gt;4. SimpleText stores literals (strings, constants) at the end of the 'CODE' resource. After that is where I placed my code. Unfortunately, this breaks disassembly in ResEdit. Below, do you see 'A9FF'? That's the '_Debugger' trap call. It is follow by the rest of the code, and the MacsBug symbols for "SimpleTextWindowChoicePrep'&lt;lb/&gt;I then needed to hand compute the JSR patched in the original SimpleText code to this location at the end of the code resource.&lt;lb/&gt;5. To make it easy to redefine window sizes in the future, I added a resource.&lt;lb/&gt;The ResEdit definition of this resource is the TMPL. By the way, I have experienced corruption twice with ResEdit 2.1.3. Perhaps it has a bug with templates?&lt;lb/&gt;I doubt this information will be useful to most people. However, it may help avoid some frustrating issues for those few people that attempt patching old software.&lt;lb/&gt;Attached is the hacked version of SimpleText.&lt;lb/&gt;- David&lt;/p&gt;
    &lt;p&gt;You need to have the code editor (from one of the Apple developer CDs) in your ResEdit preference file in order to disassemble code resources within ResEdit. Then, open each 'CODE' resource of SimpleText and search for _SizeWindow (A91D). Or, just skim the code until you see system calls that look like they have something to do with windows. Here is a nice chunk in routine Anon48. A new window is created, then it looks at the main device, looks at the size of the menu bar (MBarHeight), sets the port, and moves and sizes the window.&lt;/p&gt;
    &lt;p&gt;But, uh oh, earlier in the code it checks what type of window it is opening. A patch is going to need to avoid resizing code for pictures, video, and the about box.&lt;/p&gt;
    &lt;p&gt;I could not locate any obvious constants to adjust. Instead, I would need to inject a more complicated routine that detects whether it was a text window and substitute a new rectangle for the size. But, you cannot simply insert code, as it would move all subsequent code down, and the jumps (subroutine calls) that cross over that location would now jump to the wrong spots. So, I need to jump out of their code to my own (appended at the end of the code resource) and return.&lt;/p&gt;
    &lt;p&gt;For example, SimpleText's code to get the size of MBarHeight can easily be performed elsewhere. My routine need only return the MBarHeight in register D0 before returning. That gives me 8 bytes to overwrite with my jump.&lt;/p&gt;
    &lt;p&gt;Here is my replacement code. It still is only 8 bytes. But, I now jump to my subroutine, check the result, and jump over their resizing code if my routine says it is changing the window size.&lt;/p&gt;
    &lt;p&gt;In my subroutine, I make sure all the needed information is in registers (which I checked that SimpleText was not using), I call my various functions and then perform any work that was lost from overwriting or jumping over the original code. Specifically, I get the MBarHeight into D0 and set the current port to the window.&lt;/p&gt;
    &lt;p&gt;Easy! But, later in the code, SimpleText reads the content of whatever document is being opened and once again resizes the window. So, I needed to patch later code as well. How could I determine at that point that a replacement window size was being used? I simply store the result of the first subroutine (see SetRecentResult above) and then check it on later calls.&lt;/p&gt;
    &lt;p&gt;Where could I store this information? it is not possible to add global variables and the registers are all reused by SimpleText between the first and second routines. Well, you can store a variable (or an entire structure with many variables) within the code itself. Here is my little workaround for CodeWarrior.&lt;/p&gt;
    &lt;p&gt;A couple of other tricks.&lt;/p&gt;
    &lt;p&gt;1. The system routine GetHandleSize has some glue code (they intercept the call in a local library before calling the system). I needed this call, but didn't want to add the weight of CodeWarrior's libary. So, I defined the direct call to GetHandleSize (I didn't need the glue fix).&lt;/p&gt;
    &lt;p&gt;2. You can pass any of the scratch registers (D0-D2, A0-A1, FP0-FP3) to a C function. The way of defining that in CodeWarrior is noted below. You cannot use any other registers. To make debugging easier, I wrote the original subroutine as a true C function, and the register-&amp;gt;C function as a wrapper.&lt;/p&gt;
    &lt;p&gt;3. CodeWarrior does not support BSR for some reason. Use JSR instead. Also, a called routine must be placed before the caller routine in order to generate a short relative JSR rather than absolute address. See my 'RecentResult' example above, where the routines that call RecentResult are placed after it in code.&lt;/p&gt;
    &lt;p&gt;4. SimpleText stores literals (strings, constants) at the end of the 'CODE' resource. After that is where I placed my code. Unfortunately, this breaks disassembly in ResEdit. Below, do you see 'A9FF'? That's the '_Debugger' trap call. It is follow by the rest of the code, and the MacsBug symbols for "SimpleTextWindowChoicePrep'&lt;/p&gt;
    &lt;p&gt;I then needed to hand compute the JSR patched in the original SimpleText code to this location at the end of the code resource.&lt;/p&gt;
    &lt;p&gt;5. To make it easy to redefine window sizes in the future, I added a resource.&lt;/p&gt;
    &lt;p&gt;The ResEdit definition of this resource is the TMPL. By the way, I have experienced corruption twice with ResEdit 2.1.3. Perhaps it has a bug with templates?&lt;/p&gt;
    &lt;p&gt;I doubt this information will be useful to most people. However, it may help avoid some frustrating issues for those few people that attempt patching old software.&lt;/p&gt;
    &lt;p&gt;Attached is the hacked version of SimpleText.&lt;/p&gt;
    &lt;p&gt;- David&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tinkerdifferent.com/threads/patching-68k-software-simpletext.4793/"/><published>2025-11-04T22:59:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45816968</id><title>Google Removed 749M Anna's Archive URLs from Its Search Results</title><updated>2025-11-05T00:51:14.806268+00:00</updated><content>&lt;doc fingerprint="3b2013d053b71323"&gt;
  &lt;main&gt;
    &lt;p&gt;Anna’s Archive is a meta-search engine for shadow libraries that allows users to find pirated books and other related sources.&lt;/p&gt;
    &lt;p&gt;The site launched in the fall of 2022, just days after Z-Library was targeted in a U.S. criminal crackdown, to ensure continued availability of ‘free’ books and articles to the broader public.&lt;/p&gt;
    &lt;p&gt;In the three years since then, Anna’s Archive has built up quite the track record. The site has been blocked in various countries, was sued in the U.S. after it scraped WorldCat, and actively provides assistance to AI researchers who want to use its library for model training.&lt;/p&gt;
    &lt;p&gt;Despite legal pressure, Annas-archive.org and the related .li and .se domains remain operational. This is a thorn in the side of publishers who are actively trying to take the site down. In the absence of options to target the site directly, they ask third-party intermediaries such as Google to lend a hand.&lt;/p&gt;
    &lt;head rend="h2"&gt;749 Million URLs&lt;/head&gt;
    &lt;p&gt;Google and other major search engines allow rightsholders to request removal of allegedly infringing URLs. The aim is to ensure that pirate sites no longer show up in search results when people search for books, movies, music, or other copyrighted content.&lt;/p&gt;
    &lt;p&gt;The Pirate Bay, for example, has been a popular target; Google has removed more than 4.2 million thepiratebay.org URLs over the years in response to copyright holder complaints. While this sounds like a sizable number, it pales in comparison to the volume of takedowns targeting Anna’s Archive.&lt;/p&gt;
    &lt;p&gt;Google’s transparency report reveals that rightsholders asked Google to remove 784 million URLs, divided over the three main Anna’s Archive domains. A small number were rejected, mainly because Google didn’t index the reported links, resulting in 749 million confirmed removals.&lt;/p&gt;
    &lt;p&gt;The comparison to sites such as The Pirate Bay isn’t fair, as Anna’s Archive has many more pages in its archive and uses multiple country-specific subdomains. This means that there’s simply more content to take down. That said, in terms of takedown activity, the site’s three domain names clearly dwarf all pirate competition.&lt;/p&gt;
    &lt;head rend="h2"&gt;5% of All Google Takedowns, Ever&lt;/head&gt;
    &lt;p&gt;Since Google published its first transparency report in May 2012, rightsholders have flagged 15.1 billion allegedly infringing URLs. That’s a staggering number, but the fact that 5% of the total targeted Anna’s Archive URLs is remarkable.&lt;/p&gt;
    &lt;p&gt;Penguin Random House and John Wiley &amp;amp; Sons are the most active publishers targeting the site, but they are certainly not alone. According to Google data, more than 1,000 authors or publishers have sent DMCA notices targeting Anna’s Archive domains.&lt;/p&gt;
    &lt;p&gt;Yet, there appears to be no end in sight. Rightsholders are reporting roughly 10 million new URLs per week for the popular piracy library, so there is no shortage of content to report.&lt;/p&gt;
    &lt;p&gt;With these DMCA takedown notices, publishers are aiming to make it as difficult as possible for people to find books on the site using Google. This works, as many URLs are now delisted while others are actively being demoted by the search engine for book-related queries.&lt;/p&gt;
    &lt;p&gt;That said, the Anna’s Archive website is certainly not unfindable. Searching for the site’s name in Google still shows the main domain as the top search result.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://torrentfreak.com/google-removed-749-million-annas-archive-urls-from-its-search-results/"/><published>2025-11-04T23:11:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45816981</id><title>Analyzing the Performance of WebAssembly vs. Native Code</title><updated>2025-11-05T00:51:14.402119+00:00</updated><content>&lt;doc fingerprint="6f09809a4d733ca8"&gt;
  &lt;main&gt;
    &lt;p&gt;spacing=nonfrench&lt;/p&gt;
    &lt;head rend="h1"&gt;Not So Fast: &lt;lb/&gt;Analyzing the Performance of WebAssembly vs. Native Code&lt;/head&gt;
    &lt;head rend="h6"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;All major web browsers now support WebAssembly, a low-level bytecode intended to serve as a compilation target for code written in languages like C and C++. A key goal of WebAssembly is performance parity with native code; previous work reports near parity, with many applications compiled to WebAssembly running on average slower than native code. However, this evaluation was limited to a suite of scientific kernels, each consisting of roughly 100 lines of code. Running more substantial applications was not possible because compiling code to WebAssembly is only part of the puzzle: standard Unix APIs are not available in the web browser environment. To address this challenge, we build Browsix-Wasm, a significant extension to Browsix [29] that, for the first time, makes it possible to run unmodified WebAssembly-compiled Unix applications directly inside the browser. We then use Browsix-Wasm to conduct the first large-scale evaluation of the performance of WebAssembly vs. native. Across the SPEC CPU suite of benchmarks, we find a substantial performance gap: applications compiled to WebAssembly run slower by an average of 45% (Firefox) to 55% (Chrome), with peak slowdowns of (Firefox) and (Chrome). We identify the causes of this performance degradation, some of which are due to missing optimizations and code generation issues, while others are inherent to the WebAssembly platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;1 Introduction&lt;/head&gt;
    &lt;p&gt;Web browsers have become the most popular platform for running user-facing applications, and until recently, JavaScript was the only programming language supported by all major web browsers. Beyond its many quirks and pitfalls from the perspective of programming language design, JavaScript is also notoriously difficult to compile efficiently [12, 17, 31, 30]. Applications written in or compiled to JavaScript typically run much slower than their native counterparts. To address this situation, a group of browser vendors jointly developed WebAssembly.&lt;/p&gt;
    &lt;p&gt;WebAssembly is a low-level, statically typed language that does not require garbage collection, and supports interoperability with JavaScript. The goal of WebAssembly is to serve as a universal compiler target that can run in a browser [16, 15, 18].111The WebAssembly standard is undergoing active development, with ongoing efforts to extend WebAssembly with features ranging from SIMD primitives and threading to tail calls and garbage collection. This paper focuses on the initial and stable version of WebAssembly [18], which is supported by all major browsers. Towards this end, WebAssembly is designed to be fast to compile and run, to be portable across browsers and architectures, and to provide formal guarantees of type and memory safety. Prior attempts at running code at native speed in the browser [13, 14, 4, 38], which we discuss in related work, do not satisfy all of these criteria.&lt;/p&gt;
    &lt;p&gt;WebAssembly is now supported by all major browsers [34, 8] and has been swiftly adopted by several programming languages. There are now backends for C, C++, C#, Go, and Rust [39, 24, 2, 1] that target WebAssembly. A curated list currently includes more than a dozen others [10]. Today, code written in these languages can be safely executed in browser sandboxes across any modern device once compiled to WebAssembly.&lt;/p&gt;
    &lt;p&gt;A major goal of WebAssembly is to be faster than JavaScript. For example, the paper that introduced WebAssembly [18] showed that when a C program is compiled to WebAssembly instead of JavaScript (asm.js), it runs 34% faster in Google Chrome. That paper also showed that the performance of WebAssembly is competitive with native code: of the 24 benchmarks evaluated, the running time of seven benchmarks using WebAssembly is within 10% of native code, and almost all of them are less than slower than native code. Figure 1 shows that WebAssembly implementations have continuously improved with respect to these benchmarks. In 2017, only seven benchmarks performed within 1.1 of native, but by 2019, this number increased to 13.&lt;/p&gt;
    &lt;p&gt;These results appear promising, but they beg the question: are these 24 benchmarks representative of WebAssembly’s intended use cases?&lt;/p&gt;
    &lt;head rend="h5"&gt;The Challenge of Benchmarking WebAssembly&lt;/head&gt;
    &lt;p&gt;The aforementioned suite of 24 benchmarks is the PolybenchC benchmark suite [5], which is designed to measure the effect of polyhedral loop optimizations in compilers. All the benchmarks in the suite are small scientific computing kernels rather than full applications (e.g., matrix multiplication and LU Decomposition); each is roughly 100 LOC. While WebAssembly is designed to accelerate scientific kernels on the Web, it is also explicitly designed for a much richer set of full applications.&lt;/p&gt;
    &lt;p&gt;The WebAssembly documentation highlights several intended use cases [7], including scientific kernels, image editing, video editing, image recognition, scientific visualization, simulations, programming language interpreters, virtual machines, and POSIX applications. Therefore, WebAssembly’s strong performance on the scientific kernels in PolybenchC do not imply that it will perform well given a different kind of application.&lt;/p&gt;
    &lt;p&gt;We argue that a more comprehensive evaluation of WebAssembly should rely on an established benchmark suite of large programs, such as the SPEC CPU benchmark suites. In fact, the SPEC CPU 2006 and 2017 suite of benchmarks include several applications that fall under the intended use cases of WebAssembly: eight benchmarks are scientific applications (e.g., 433.milc, 444.namd, 447.dealII, 450.soplex, and 470.lbm), two benchmarks involve image and video processing (464.h264ref and 453.povray), and all of the benchmarks are POSIX applications.&lt;/p&gt;
    &lt;p&gt;Unfortunately, it is not possible to simply compile a sophisticated native program to WebAssembly. Native programs, including the programs in the SPEC CPU suites, require operating system services, such as a filesystem, synchronous I/O, and processes, which WebAssembly and the browser do not provide. The SPEC benchmarking harness itself requires a file system, a shell, the ability to spawn processes, and other Unix facilities. To overcome these limitations when porting native applications to the web, many programmers painstakingly modify their programs to avoid or mimic missing operating system services. Modifying well-known benchmarks, such as SPEC CPU, would not only be time consuming but would also pose a serious threat to validity.&lt;/p&gt;
    &lt;p&gt;The standard approach to running these applications today is to use Emscripten, a toolchain for compiling C and C++ to WebAssembly [39]. Unfortunately, Emscripten only supports the most trivial system calls and does not scale up to large-scale applications. For example, to enable applications to use synchronous I/O, the default Emscripten MEMFS filesystem loads the entire filesystem image into memory before the program begins executing. For SPEC, these files are too large to fit into memory.&lt;/p&gt;
    &lt;p&gt;A promising alternative is to use Browsix, a framework that enables running unmodified, full-featured Unix applications in the browser [28, 29]. Browsix implements a Unix-compatible kernel in JavaScript, with full support for processes, files, pipes, blocking I/O, and other Unix features. Moreover, it includes a C/C++ compiler (based on Emscripten) that allows programs to run in the browser unmodified. The Browsix case studies include complex applications, such as LaTeX, which runs entirely in the browser without any source code modifications.&lt;/p&gt;
    &lt;p&gt;Unfortunately, Browsix is a JavaScript-only solution, since it was built before the release of WebAssembly. Moreover, Browsix suffers from high performance overhead, which would be a significant confounder while benchmarking. Using Browsix, it would be difficult to tease apart the poorly performing benchmarks from performance degradation introduced by Browsix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; • &lt;p&gt;Browsix-Wasm: We develop Browsix-Wasm, a significant extension to and enhancement of Browsix that allows us to compile Unix programs to WebAssembly and run them in the browser with no modifications. In addition to integrating functional extensions, Browsix-Wasm incorporates performance optimizations that drastically improve its performance, ensuring that CPU-intensive applications operate with virtually no overhead imposed by Browsix-Wasm ().&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; • &lt;p&gt;Browsix-SPEC: We develop Browsix-SPEC, a harness that extends Browsix-Wasm to allow automated collection of detailed timing and hardware on-chip performance counter information in order to perform detailed measurements of application performance ().&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; • &lt;p&gt;Performance Analysis of WebAssembly: Using Browsix-Wasm and Browsix-SPEC, we conduct the first comprehensive performance analysis of WebAssembly using the SPEC CPU benchmark suite (both 2006 and 2017). This evaluation confirms that WebAssembly does run faster than JavaScript (on average 1.3 faster across SPEC CPU). However, contrary to prior work, we find a substantial gap between WebAssembly and native performance: code compiled to WebAssembly runs on average 1.55 slower in Chrome and 1.45 slower in Firefox than native code ().&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; • &lt;p&gt;Root Cause Analysis and Advice for Implementers: We conduct a forensic analysis with the aid of performance counter results to identify the root causes of this performance gap. We find the following results:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt; 1. &lt;p&gt;The instructions produced by WebAssembly have more loads and stores than native code (2.02 more loads and 2.30 more stores in Chrome; 1.92 more loads and 2.16 more stores in Firefox). We attribute this to reduced availability of registers, a sub-optimal register allocator, and a failure to effectively exploit a wider range of x86 addressing modes.&lt;/p&gt;&lt;/item&gt;&lt;item&gt; 2. &lt;p&gt;The instructions produced by WebAssembly have more branches, because WebAssembly requires several dynamic safety checks.&lt;/p&gt;&lt;/item&gt;&lt;item&gt; 3. &lt;p&gt;Since WebAssembly generates more instructions, it leads to more L1 instruction cache misses.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We provide guidance to help WebAssembly implementers focus their optimization efforts in order to close the performance gap between WebAssembly and native code ().&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; 1. &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Browsix-Wasm and Browsix-SPEC are available at https://browsix.org.&lt;/p&gt;
    &lt;head rend="h2"&gt;2 From Browsix to Browsix-Wasm&lt;/head&gt;
    &lt;p&gt;Browsix [29] mimics a Unix kernel within the browser and includes a compiler (based on Emscripten [39, 33]) that compiles native programs to JavaScript. Together, they allow native programs (in C, C++, and Go) to run in the browser and freely use operating system services, such as pipes, processes, and a filesystem. However, Browsix has two major limitations that we must overcome. First, Browsix compiles native code to JavaScript and not WebAssembly. Second, the Browsix kernel has significant performance issues. In particular, several common system calls have very high overhead in Browsix, which makes it hard to compare the performance of a program running in Browsix to that of a program running natively. We address these limitations by building a new in-browser kernel called Browsix-Wasm, which supports WebAssembly programs and eliminates the performance bottlenecks of Browsix.&lt;/p&gt;
    &lt;head rend="h5"&gt;Emscripten Runtime Modifications&lt;/head&gt;
    &lt;p&gt;Browsix modifies the Emscripten compiler to allow processes (which run in WebWorkers) to communicate with the Browsix kernel (which runs on the main thread of a page). Since Browsix compiles native programs to JavaScript, this is relatively straightforward: each process’ memory is a buffer that is shared with the kernel (a SharedArrayBuffer), thus system calls can directly read and write process memory. However, this approach has two significant drawbacks. First, it precludes growing the heap on-demand; the shared memory must be sized large enough to meet the high-water-mark heap size of the application for the entire life of the process. Second, JavaScript contexts (like the main context and each web worker context) have a fixed limit on their heap sizes, which is currently approximately 2.2 GB in Google Chrome [6]. This cap imposes a serious limitation on running multiple processes: if each process reserves a 500 MB heap, Browsix would only be able to run at most four concurrent processes. A deeper problem is that WebAssembly memory cannot be shared across WebWorkers and does not support the Atomic API, which Browsix processes use to wait for system calls.&lt;/p&gt;
    &lt;p&gt;Browsix-Wasm uses a different approach to process-kernel communication that is also faster than the Browsix approach. Browsix-Wasm modifies the Emscripten runtime system to create an auxiliary buffer (of 64MB) for each process that is shared with the kernel, but is distinct from process memory. Since this auxiliary buffer is a SharedArrayBuffer the Browsix-Wasm process and kernel can use Atomic API for communication. When a system call references strings or buffers in the process’s heap (e.g., writev or stat), its runtime system copies data from the process memory to the shared buffer and sends a message to the kernel with locations of the copied data in auxiliary memory. Similarly, when a system call writes data to the auxiliary buffer (e.g., read), its runtime system copies the data from the shared buffer to the process memory at the memory specified. Moreover, if a system call specifies a buffer in process memory for the kernel to write to (e.g., read), the runtime allocates a corresponding buffer in auxiliary memory and passes it to the kernel. In case the system call is either reading or writing data of size more than 64MB, Browsix-Wasm divides this call into several calls such that each call only reads or writes at maximum 64MB of data. The cost of these memory copy operations is dwarfed by the overall cost of the system call invocation, which involves sending a message between process and kernel JavaScript contexts. We show in §4.2.1 that Browsix-Wasm has negligible overhead.&lt;/p&gt;
    &lt;head rend="h5"&gt;Performance Optimization&lt;/head&gt;
    &lt;p&gt;While building Browsix-Wasm and doing our preliminary performance evaluation, we discovered several performance issues in parts of the Browsix kernel. Left unresolved, these performance issues would be a threat to the validity of a performance comparison between WebAssembly and native code. The most serious case was in the shared filesystem component included with Browsix/Browsix-Wasm, BrowserFS. Originally, on each append operation on a file, BrowserFS would allocate a new, larger buffer, copying the previous and new contents into the new buffer. Small appends could impose substantial performance degradation. Now, whenever a buffer backing a file requires additional space, BrowserFS grows the buffer by at least 4 KB. This change alone decreased the time the 464.h264ref benchmark spent in Browsix from 25 seconds to under 1.5 seconds. We made a series of improvements that reduce overhead throughout Browsix-Wasm. Similar, if less dramatic, improvements were made to reduce the number of allocations and the amount of copying in the kernel implementation of pipes.&lt;/p&gt;
    &lt;head rend="h2"&gt;3 Browsix-SPEC&lt;/head&gt;
    &lt;p&gt;To reliably execute WebAssembly benchmarks while capturing performance counter data, we developed Browsix-SPEC. Browsix-SPEC works with Browsix-Wasm to manage spawning browser instances, serving benchmark assets (e.g., the compiled WebAssembly programs and test inputs), spawning perf processes to record performance counter data, and validating benchmark outputs.&lt;/p&gt;
    &lt;p&gt;We use Browsix-SPEC to run three benchmark suites to evaluate WebAssembly’s performance: SPEC CPU2006, SPEC CPU2017, and PolyBenchC. These benchmarks are compiled to native code using Clang 4.0, and WebAssembly using Browsix-Wasm. We made no modifications to Chrome or Firefox, and the browsers are run with their standard sandboxing and isolation features enabled. Browsix-Wasm is built on top of standard web platform features and requires no direct access to host resources – instead, benchmarks make standard HTTP requests to Browsix-SPEC.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.1 Browsix-SPEC Benchmark Execution&lt;/head&gt;
    &lt;p&gt;Figure 2 illustrates the key pieces of Browsix-SPEC in play when running a benchmark, such as 401.bzip2 in Chrome. First (1), the Browsix-SPEC benchmark harness launches a new browser instance using a WebBrowser automation tool, Selenium.222https://www.seleniumhq.org/ (2) The browser loads the page’s HTML, harness JS, and Browsix-Wasm kernel JS over HTTP from the benchmark harness. (3) The harness JS initializes the Browsix-Wasm kernel and starts a new Browsix-Wasm process executing the runspec shell script (not shown in Figure 2). runspec in turn spawns the standard specinvoke (not shown), compiled from the C sources provided in SPEC 2006. specinvoke reads the speccmds.cmd file from the Browsix-Wasm filesystem and starts 401.bzip2 with the appropriate arguments. (4) After the WebAssembly module has been instantiated but before the benchmark’s main function is invoked, the Browsix-Wasm userspace runtime does an XHR request to Browsix-SPEC to begin recording performance counter stats. (5) The benchmark harness finds the Chrome thread corresponding to the Web Worker 401.bzip2 process and attaches perf to the process. (6) At the end of the benchmark, the Browsix-Wasm userspace runtime does a final XHR to the benchmark harness to end the perf record process. When the runspec program exits (after potentially invoking the test binary several times), the harness JS POSTs (7) a tar archive of the SPEC results directory to Browsix-SPEC. After Browsix-SPEC receives the full results archive, it unpacks the results to a temporary directory and validates the output using the cmp tool provided with SPEC 2006. Finally, Browsix-SPEC kills the browser process and records the benchmark results.&lt;/p&gt;
    &lt;head rend="h2"&gt;4 Evaluation&lt;/head&gt;
    &lt;p&gt;We use Browsix-Wasm and Browsix-SPEC to evaluate the performance of WebAssembly using three benchmark suites: SPEC CPU2006, SPEC CPU2017, and PolyBenchC. We include PolybenchC benchmarks for comparison with the original WebAssembly paper [18], but argue that these benchmarks do not represent typical workloads. The SPEC benchmarks are representative and require Browsix-Wasm to run successfully. We run all benchmarks on a 6-Core Intel Xeon E5-1650 v3 CPU with hyperthreading and 64 GB of RAM running Ubuntu 16.04 with Linux kernel v4.4.0. We run all benchmarks using two state-of-the-art browsers: Google Chrome 74.0 and Mozilla Firefox 66.0. We compile benchmarks to native code using Clang 4.0333The flags to Clang are -O2 -fno-strict-aliasing. and to WebAssembly using Browsix-Wasm (which is based on Emscripten with Clang 4.0).444Browsix-Wasm runs Emscripten with the flags -O2 -s TOTAL_MEMORY=1073741824 -s ALLOW_MEMORY_GROWTH=1 -fno-strict-aliasing. Each benchmark was executed five times. We report the average of all running times and the standard error. The execution time measured is the difference between wall clock time when the program starts, i.e. after WebAssembly JIT compilation concludes, and when the program ends.&lt;/p&gt;
    &lt;head rend="h3"&gt;4.1 PolyBenchC Benchmarks&lt;/head&gt;
    &lt;p&gt;Haas et al. [18] used PolybenchC to benchmark WebAssembly implementations because the PolybenchC benchmarks do not make system calls. As we have already argued, the PolybenchC benchmarks are small scientific kernels that are typically used to benchmark polyhedral optimization techniques, and do not represent larger applications. Nevertheless, it is still valuable for us to run PolybenchC with Browsix-Wasm, because it demonstrates that our infrastructure for system calls does not have any overhead. Figure 3(a) shows the execution time of the PolyBenchC benchmarks in Browsix-Wasm and when run natively. We are able to reproduce the majority of the results from the original WebAssembly paper [18]. We find that Browsix-Wasm imposes a very low overhead: an average of 0.2% and a maximum of 1.2%.&lt;/p&gt;
    &lt;head rend="h3"&gt;4.2 SPEC Benchmarks&lt;/head&gt;
    &lt;p&gt;We now evaluate Browsix-Wasm using the C/C++ benchmarks from SPEC CPU2006 and SPEC CPU2017 (the new C/C++ benchmarks and the speed benchmarks), which use system calls extensively. We exclude four data points that either do not compile to WebAssembly555400.perlbench, 403.gcc, 471.omnetpp, and 456.hmmer from SPEC CPU2006 do not compile with Emscripten. or allocate more memory than WebAssembly allows.666From SPEC CPU2017, the ref dataset of 638.imagick_s and 657.xz_s require more than 4 GB RAM. However, these benchmarks do work with their test dataset. Table 1 shows the absolute execution times of the SPEC benchmarks when running with Browsix-Wasm in both Chrome and Firefox, and when running natively.&lt;/p&gt;
    &lt;p&gt;WebAssembly performs worse than native for all benchmarks except for 429.mcf and 433.milc. In Chrome, WebAssembly’s maximum overhead is 2.5 over native and 7 out of 15 benchmarks have a running time within 1.5 of native. In Firefox, WebAssembly is within 2.08 of native and performs within 1.5 of native for 7 out of 15 benchmarks. On average, WebAssembly is 1.55 slower than native in Chrome, and 1.45 slower than native in Firefox. Table 2 shows the time required to compile the SPEC benchmarks using Clang and Chrome. (To the best of our knowledge, Firefox cannot report WebAssembly compile times.) In all cases, the compilation time is negligible compared to the execution time. However, the Clang compiler is orders of magnitude slower than the WebAssembly compiler. Finally, note that Clang compiles benchmarks from C++ source code, whereas Chrome compiles WebAssembly, which is a simpler format than C++.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Benchmark&lt;/cell&gt;
        &lt;cell&gt;Native&lt;/cell&gt;
        &lt;cell role="head"&gt;Google Chrome&lt;/cell&gt;
        &lt;cell role="head"&gt;Mozilla Firefox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;401.bzip2&lt;/cell&gt;
        &lt;cell&gt;370 0.6&lt;/cell&gt;
        &lt;cell&gt;864 6.4&lt;/cell&gt;
        &lt;cell&gt;730 1.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;429.mcf&lt;/cell&gt;
        &lt;cell&gt;221 0.1&lt;/cell&gt;
        &lt;cell&gt;180 0.9&lt;/cell&gt;
        &lt;cell&gt;184 0.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;433.milc&lt;/cell&gt;
        &lt;cell&gt;375 2.6&lt;/cell&gt;
        &lt;cell&gt;369 0.5&lt;/cell&gt;
        &lt;cell&gt;378 0.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;444.namd&lt;/cell&gt;
        &lt;cell&gt;271 0.8&lt;/cell&gt;
        &lt;cell&gt;369 9.1&lt;/cell&gt;
        &lt;cell&gt;373 1.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;445.gobmk&lt;/cell&gt;
        &lt;cell&gt;352 2.1&lt;/cell&gt;
        &lt;cell&gt;537 0.8&lt;/cell&gt;
        &lt;cell&gt;549 3.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;450.soplex&lt;/cell&gt;
        &lt;cell&gt;179 3.7&lt;/cell&gt;
        &lt;cell&gt;265 1.2&lt;/cell&gt;
        &lt;cell&gt;238 0.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;453.povray&lt;/cell&gt;
        &lt;cell&gt;110 1.9&lt;/cell&gt;
        &lt;cell&gt;275 1.3&lt;/cell&gt;
        &lt;cell&gt;229 1.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;458.sjeng&lt;/cell&gt;
        &lt;cell&gt;358 1.4&lt;/cell&gt;
        &lt;cell&gt;602 2.5&lt;/cell&gt;
        &lt;cell&gt;580 2.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;462.libquantum&lt;/cell&gt;
        &lt;cell&gt;330 0.8&lt;/cell&gt;
        &lt;cell&gt;444 0.2&lt;/cell&gt;
        &lt;cell&gt;385 0.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;464.h264ref&lt;/cell&gt;
        &lt;cell&gt;389 0.7&lt;/cell&gt;
        &lt;cell&gt;807 11.0&lt;/cell&gt;
        &lt;cell&gt;733 2.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;470.lbm&lt;/cell&gt;
        &lt;cell&gt;209 1.1&lt;/cell&gt;
        &lt;cell&gt;248 0.3&lt;/cell&gt;
        &lt;cell&gt;249 0.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;473.astar&lt;/cell&gt;
        &lt;cell&gt;299 0.5&lt;/cell&gt;
        &lt;cell&gt;474 3.5&lt;/cell&gt;
        &lt;cell&gt;408 1.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;482.sphinx3&lt;/cell&gt;
        &lt;cell&gt;381 7.1&lt;/cell&gt;
        &lt;cell&gt;834 1.8&lt;/cell&gt;
        &lt;cell&gt;713 3.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;641.leela_s&lt;/cell&gt;
        &lt;cell&gt;466 2.7&lt;/cell&gt;
        &lt;cell&gt;825 4.6&lt;/cell&gt;
        &lt;cell&gt;717 1.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;644.nab_s&lt;/cell&gt;
        &lt;cell&gt;2476 11&lt;/cell&gt;
        &lt;cell&gt;3639 5.6&lt;/cell&gt;
        &lt;cell&gt;3829 6.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Slowdown: geomean&lt;/cell&gt;
        &lt;cell&gt;–&lt;/cell&gt;
        &lt;cell&gt;1.55&lt;/cell&gt;
        &lt;cell&gt;1.45&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Slowdown: median&lt;/cell&gt;
        &lt;cell&gt;–&lt;/cell&gt;
        &lt;cell&gt;1.53&lt;/cell&gt;
        &lt;cell&gt;1.54&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Benchmark&lt;/cell&gt;
        &lt;cell&gt;Clang 4.0&lt;/cell&gt;
        &lt;cell role="head"&gt;Google Chrome&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;401.bzip2&lt;/cell&gt;
        &lt;cell&gt;1.9 0.018&lt;/cell&gt;
        &lt;cell&gt;0.53 0.005&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;429.mcf&lt;/cell&gt;
        &lt;cell&gt;0.3 0.003&lt;/cell&gt;
        &lt;cell&gt;0.15 0.005&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;433.milc&lt;/cell&gt;
        &lt;cell&gt;2.2 0.02&lt;/cell&gt;
        &lt;cell&gt;0.3 0.003&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;444.namd&lt;/cell&gt;
        &lt;cell&gt;4.6 0.02&lt;/cell&gt;
        &lt;cell&gt;0.78 0.004&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;445.gobmk&lt;/cell&gt;
        &lt;cell&gt;12.1 0.2&lt;/cell&gt;
        &lt;cell&gt;1.4 0.014&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;450.soplex&lt;/cell&gt;
        &lt;cell&gt;6.9 0.01&lt;/cell&gt;
        &lt;cell&gt;1.2 0.009&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;453.povray&lt;/cell&gt;
        &lt;cell&gt;15.3 0.03&lt;/cell&gt;
        &lt;cell&gt;1.2 0.012&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;458.sjeng&lt;/cell&gt;
        &lt;cell&gt;1.9 0.01&lt;/cell&gt;
        &lt;cell&gt;0.35 0.001&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;462.libquantum&lt;/cell&gt;
        &lt;cell&gt;6.9 0.03&lt;/cell&gt;
        &lt;cell&gt;0.15 0.002&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;464.h264ref&lt;/cell&gt;
        &lt;cell&gt;10.3 0.06&lt;/cell&gt;
        &lt;cell&gt;1.0 0.03&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;470.lbm&lt;/cell&gt;
        &lt;cell&gt;0.3 0.001&lt;/cell&gt;
        &lt;cell&gt;0.14 0.004&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;473.astar&lt;/cell&gt;
        &lt;cell&gt;0.73 0.005&lt;/cell&gt;
        &lt;cell&gt;0.24 0.004&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;482.sphinx3&lt;/cell&gt;
        &lt;cell&gt;3.0 0.04&lt;/cell&gt;
        &lt;cell&gt;0.48 0.007&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;641.leela_s&lt;/cell&gt;
        &lt;cell&gt;4.3 0.05&lt;/cell&gt;
        &lt;cell&gt;0.74 0.003&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;644.nab_s&lt;/cell&gt;
        &lt;cell&gt;4.1 0.03&lt;/cell&gt;
        &lt;cell&gt;0.41 0.001&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;4.2.1 Browsix-Wasm Overhead&lt;/head&gt;
    &lt;p&gt;It is important to rule out the possibility that the slowdown that we report is due to poor performance in our implementation of Browsix-Wasm. In particular, Browsix-Wasm implements system calls without modifying the browser, and system calls involve copying data (§2), which may be costly. To quantify the overhead of Browsix-Wasm, we instrumented its system calls to measure all time spent in Browsix-Wasm. Figure 4 shows the percentage of time spent in Browsix-Wasm in Firefox using the SPEC benchmarks. For 14 of the 15 benchmarks, the overhead is less than 0.5%. The maximum overhead is 1.2%. On average, the overhead of Browsix-Wasm is only 0.2%. Therefore, we conclude that Browsix-Wasm has negligible overhead and does not substantially affect the performance counter results of programs executed in WebAssembly.&lt;/p&gt;
    &lt;head rend="h4"&gt;4.2.2 Comparison of WebAssembly and asm.js&lt;/head&gt;
    &lt;p&gt;A key claim in the original work on WebAssembly was that it is significantly faster than asm.js. We now test that claim using the SPEC benchmarks. For this comparison, we modified Browsix-Wasm to also support processes compiled to asm.js. The alternative would have been to benchmark the asm.js processes using the original Browsix. However, as we discussed earlier, Browsix has performance problems that would have been a threat to the validity of our results. Figure 5 shows the speedup of the SPEC benchmarks using WebAssembly, relative to their running time using asm.js using both Chrome and Firefox. WebAssembly outperforms asm.js in both browsers: the mean speedup is 1.54 in Chrome and 1.39 in Firefox.&lt;/p&gt;
    &lt;p&gt;Since the performance difference between Chrome and Firefox is substantial, in Figure 6 we show the speedup of each benchmark by selecting the best-performing browser for WebAssembly and the best-performing browser of asm.js (i.e., they may be different browsers). These results show that WebAssembly consistently performs better than asm.js, with a mean speedup of 1.3. Haas et al. [18] also found that WebAssembly gives a mean speedup of 1.3 over asm.js using PolyBenchC.&lt;/p&gt;
    &lt;head rend="h2"&gt;5 Case Study: Matrix Multiplication&lt;/head&gt;
    &lt;p&gt;In this section, we illustrate the performance differences between WebAssembly and native code using a C function that performs matrix multiplication, as shown in Figure 7(a). Three matrices are provided as arguments to the function, and the results of A () and B () are stored in C (), where are constants defined in the program.&lt;/p&gt;
    &lt;p&gt;In WebAssembly, this function is – slower than native in both Chrome and Firefox with a variety of matrix sizes (Figure 8). We compiled the function with -O2 and disabled automatic vectorization, since WebAssembly does not support vectorized instructions.&lt;/p&gt;
    &lt;p&gt;Figure 7(b) shows native code generated for the matmul function by clang-4.0. Arguments are passed to the function in the rdi, rsi, and rdx registers, as specified in the System V AMD64 ABI calling convention [9]. Lines 7(b) - 7(b) are the body of the first loop with iterator i stored in r8d. Lines 7(b) - 7(b) contain the body of the second loop with iterator k stored in r9d. Lines 7(b) - 7(b) comprise the body of the third loop with iterator j stored in rcx. Clang is able to eliminate a cmp instruction in the inner loop by initializing rcx with , incrementing rcx on each iteration at line 7(b), and using jne to test the zero flag of the status register, which is set to 1 when rcx becomes 0.&lt;/p&gt;
    &lt;p&gt;Figure 7(c) shows x86-64 code JITed by Chrome for the WebAssembly compiled version of matmul. This code has been modified slightly – nops in the generated code have been removed for presentation. Function arguments are passed in the rax, rcx, and rdx registers, following Chrome’s calling convention. At lines 1– 3, the contents of registers rax, rdx, and rcx are stored on the stack, due to registers spills at lines 7 - 9. Lines 7–45 are the body of the first loop with iterator i stored in edi. Lines 18–42 contain the body of second loop with iterator k stored in r11. Lines 27–39 are the body of the third loop with iterator j stored in eax. To avoid memory loads due to register spilling at lines 7– 9 in the first iteration of the first loop, an extra jump is generated at line 5. Similarly, extra jumps are generated for the second and third loops at line 16 and line 25 respectively.&lt;/p&gt;
    &lt;head rend="h3"&gt;5.1 Differences&lt;/head&gt;
    &lt;p&gt;The native code JITed by Chrome has more instructions, suffers from increased register pressure, and has extra branches compared to Clang-generated native code.&lt;/p&gt;
    &lt;head rend="h4"&gt;5.1.1 Increased Code Size&lt;/head&gt;
    &lt;p&gt;The number of instructions in the code generated by Chrome (Figure 7(c)) is 53, including nops, while clang generated code (Figure 7(b)) consists of only 28 instructions. The poor instruction selection algorithm of Chrome is one of the reasons for increased code size.&lt;/p&gt;
    &lt;p&gt;Additionally, Chrome does not take advantage of all available memory addressing modes for x86 instructions. In Figure 7(b) Clang uses the add instruction at line 7(b) with register addressing mode, loading from and writing to a memory address in the same operation. Chrome on the other hand loads the address in ecx, adds the operand to ecx, finally storing ecx at the address, requiring 3 instructions rather than one on lines 3537.&lt;/p&gt;
    &lt;head rend="h4"&gt;5.1.2 Increased Register Pressure&lt;/head&gt;
    &lt;p&gt;Code generated by Clang in Figure 7(b) does not generate any spills and uses only 10 registers. On the other hand, the code generated by Chrome (Figure 7(c)) uses 13 general purpose registers – all available registers (r13 and r10 are reserved by V8). As described in Section 5.1.1, eschewing the use of the register addressing mode of the add instruction requires the use of a temporary register. All of this register inefficiency compounds, introducing three register spills to the stack at lines 1–3. Values stored on the stack are loaded again into registers at lines 7–9 and line 18.&lt;/p&gt;
    &lt;head rend="h4"&gt;5.1.3 Extra Branches&lt;/head&gt;
    &lt;p&gt;Clang (Figure 7(b)) generates code with a single branch per loop by inverting the loop counter (line 7(b)). In contrast, Chrome (Figure 7(c)) generates more straightforward code, which requires a conditional jump at the start of the loop. In addition, Chrome generates extra jumps to avoid memory loads due to register spills in the first iteration of a loop. For example, the jump at line 5 avoids the spills at lines 7– 9.&lt;/p&gt;
    &lt;head rend="h2"&gt;6 Performance Analysis&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;perf Event&lt;/cell&gt;
        &lt;cell&gt;Wasm Summary&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;all-loads-retired (r81d0) (Figure 9(a))&lt;/cell&gt;
        &lt;cell&gt;Increased register&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;all-stores-retired (r82d0) (Figure 9(b))&lt;/cell&gt;
        &lt;cell&gt;pressure&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;branches-retired (r00c4) (Figure 9(c))&lt;/cell&gt;
        &lt;cell&gt;More branch&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;conditional-branches (r01c4) (Figure 9(d))&lt;/cell&gt;
        &lt;cell&gt;statements&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;instructions-retired (r1c0) (Figure 9(e))&lt;/cell&gt;
        &lt;cell&gt;Increased code size&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;cpu-cycles (Figure 9(f))&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;L1-icache-load-misses (Figure 10)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We use Browsix-SPEC to record measurements from all supported performance counters on our system for the SPEC CPU benchmarks compiled to WebAssembly and executed in Chrome and Firefox, and the SPEC CPU benchmarks compiled to native code (Section 3).&lt;/p&gt;
    &lt;p&gt;Table 3 lists the performance counters we use here, along with a summary of the impact of Browsix-Wasm performance on these counters compared to native. We use these results to explain the performance overhead of WebAssembly over native code. Our analysis shows that the inefficiences described in Section 5 are pervasive and translate to reduced performance across the SPEC CPU benchmark suite.&lt;/p&gt;
    &lt;head rend="h3"&gt;6.1 Increased Register Pressure&lt;/head&gt;
    &lt;p&gt;This section focuses on two performance counters that show the effect of increased register pressure. Figure 9(a) presents the number of load instructions retired by WebAssembly-compiled SPEC benchmarks in Chrome and Firefox, relative to the number of load instructions retired in native code. Similarly, Figure 9(b) shows the number of store instructions retired. Note that a “retired” instruction is an instruction which leaves the instruction pipeline and its results are correct and visible in the architectural state (that is, not speculative).&lt;/p&gt;
    &lt;p&gt;Code generated by Chrome has 2.02 more load instructions retired and 2.30 more store instructions retired than native code. Code generated by Firefox has 1.92 more load instructions retired and 2.16 more store instructions retired than native code. These results show that the WebAssembly-compiled SPEC CPU benchmarks suffer from increased register pressure and thus increased memory references. Below, we outline the reasons for this increased register pressure.&lt;/p&gt;
    &lt;head rend="h4"&gt;6.1.1 Reserved Registers&lt;/head&gt;
    &lt;p&gt;In Chrome, matmul generates three register spills but does not use two x86-64 registers: r13 and r10 (Figure 7(c), lines 7– 9). This occurs because Chrome reserves these two registers.777https://github.com/v8/v8/blob/7.4.1/src/x64/register-x64.h For the JavaScript garbage collector, Chrome reserves r13 to point to an array of GC roots at all times. In addition, Chrome uses r10 and xmm13 as dedicated scratch registers. Similarly, Firefox reserves r15 as a pointer to the start of the heap, and r11 and xmm15 are JavaScript scratch registers.888https://hg.mozilla.org/mozilla-central/file/tip/js/src/jit/x64/Assembler-x64.h None of these registers are available to WebAssembly code.&lt;/p&gt;
    &lt;head rend="h4"&gt;6.1.2 Poor Register Allocation&lt;/head&gt;
    &lt;p&gt;Beyond a reduced set of registers available to allocate, both Chrome and Firefox do a poor job of allocating the registers they have. For example, the code generated by Chrome for matmul uses 12 registers while the native code generated by Clang only uses 10 registers (Section 5.1.2). This increased register usage—in both Firefox and Chrome—is because of their use of fast but not particularly effective register allocators. Chrome and Firefox both use a linear scan register allocator [36], while Clang uses a greedy graph-coloring register allocator [3], which consistently generates better code.&lt;/p&gt;
    &lt;head rend="h4"&gt;6.1.3 x86 Addressing Modes&lt;/head&gt;
    &lt;p&gt;The x86-64 instruction set offers several addressing modes for each operand, including a register mode, where the instruction reads data from register or writes data to a register, and memory address modes like register indirect or direct offset addressing, where the operand resides in a memory address and the instruction can read from or write to that address. A code generator could avoid unnecessary register pressure by using the latter modes. However, Chrome does not take advantage of these modes. For example, the code generated by Chrome for matmul does not use the register indirect addressing mode for the add instruction (Section 5.1.2), creating unnecessary register pressure.&lt;/p&gt;
    &lt;head rend="h3"&gt;6.2 Extra Branch Instructions&lt;/head&gt;
    &lt;p&gt;This section focuses on two performance counters that measure the number of branch instructions executed. Figure 9(c) shows the number of branch instructions retired by WebAssembly, relative to the number of branch instructions retired in native code. Similarly, Figure 9(d) shows the number of conditional branch instructions retired. In Chrome, there are and more unconditional and conditional branch instructions retired respectively, whereas in Firefox, there are and more retired. These results show that all the SPEC CPU benchmarks incur extra branches, and we explain why below.&lt;/p&gt;
    &lt;head rend="h4"&gt;6.2.1 Extra Jump Statements for Loops&lt;/head&gt;
    &lt;p&gt;As with matmul (Section 5.1.3), Chrome generates unnecessary jump statements for loops, leading to significantly more branch instructions than Firefox.&lt;/p&gt;
    &lt;head rend="h4"&gt;6.2.2 Stack Overflow Checks Per Function Call&lt;/head&gt;
    &lt;p&gt;A WebAssembly program tracks the current stack size with a global variable that it increases on every function call. The programmer can define the maximum stack size for the program. To ensure that a program does not overflow the stack, both Chrome and Firefox add stack checks at the start of each function to detect if the current stack size is less than the maximum stack size. These checks includes extra comparison and conditional jump instructions, which must be executed on every function call.&lt;/p&gt;
    &lt;head rend="h4"&gt;6.2.3 Function Table Indexing Checks&lt;/head&gt;
    &lt;p&gt;WebAssembly dynamically checks all indirect calls to ensure that the target is a valid function and that the function’s type at runtime is the same as the type specified at the call site. In a WebAssembly module, the function table stores the list of functions and their types, and the code generated by WebAssembly uses the function table to implement these checks. These checks are required when calling function pointers and virtual functions in C/C++. The checks lead to extra comparison and conditional jump instructions, which are executed before every indirect function call.&lt;/p&gt;
    &lt;head rend="h3"&gt;6.3 Increased Code Size&lt;/head&gt;
    &lt;p&gt;The code generated by Chrome and Firefox is considerably larger than the code generated by Clang. We use three performance counters to measure this effect. (i) Figure 9(e) shows the number of instructions retired by benchmarks compiled to WebAssembly and executed in Chrome and Firefox relative to the number of instructions retired in native code. Similarly, Figure 9(f) shows the relative number of CPU cycles spent by benchmarks compiled to WebAssembly, and Figure 10 shows the relative number of L1 instruction cache load misses.&lt;/p&gt;
    &lt;p&gt;Figure 9(e) shows that Chrome executes an average of 1.80 more instructions than native code and Firefox executes an average of 1.75 more instructions than native code. Due to poor instruction selection, a poor register allocator generating more register spills (Section 6.1), and extra branch statements (Section 6.2), the size of generated code for WebAssembly is greater than native code, leading to more instructions being executed. This increase in the number of instructions executed leads to increased L1 instruction cache misses in Figure 10. On average, Chrome suffers 2.83 more I-cache misses than native code, and Firefox suffers from 2.04 more L1 instruction cache misses than native code. More cache misses means that more CPU cycles are spent waiting for the instruction to be fetched.&lt;/p&gt;
    &lt;p&gt;We note one anomaly: although 429.mcf has 1.6 more instructions retired in Chrome than native code and 1.5 more instructions retired in Firefox than native code, it runs faster than native code. Figure 3(b) shows that its slowdown relative to native is 0.81 in Chrome and 0.83 in Firefox. The reason for this anomaly is attributable directly to its lower number of L1 instruction cache misses. 429.mcf contains a main loop and most of the instructions in the loop fit in the L1 instruction cache. Similarly, 433.milc performance is better due to fewer L1 instruction cache misses. In 450.soplex there are 4.6 more L1 instruction cache misses in Chrome and Firefox than native because of several virtual functions being executed, leading to more indirect function calls.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Performance Counter&lt;/cell&gt;
        &lt;cell&gt;Chrome&lt;/cell&gt;
        &lt;cell&gt;Firefox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;all-loads-retired&lt;/cell&gt;
        &lt;cell&gt;2.02&lt;/cell&gt;
        &lt;cell&gt;1.92&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;all-stores-retired&lt;/cell&gt;
        &lt;cell&gt;2.30&lt;/cell&gt;
        &lt;cell&gt;2.16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;branch-instructions-retired&lt;/cell&gt;
        &lt;cell&gt;1.75&lt;/cell&gt;
        &lt;cell&gt;1.65&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conditional-branches&lt;/cell&gt;
        &lt;cell&gt;1.65&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;instructions-retired&lt;/cell&gt;
        &lt;cell&gt;1.80&lt;/cell&gt;
        &lt;cell&gt;1.75&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;cpu-cycles&lt;/cell&gt;
        &lt;cell&gt;1.54&lt;/cell&gt;
        &lt;cell&gt;1.38&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;L1-icache-load-misses&lt;/cell&gt;
        &lt;cell&gt;2.83&lt;/cell&gt;
        &lt;cell&gt;2.04&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;6.4 Discussion&lt;/head&gt;
    &lt;p&gt;It is worth asking if the performance issues identified here are fundamental. We believe that two of the identified issues are not: that is, they could be ameliorated by improved implementations. WebAssembly implementations today use register allocators (§6.1.2) and code generators (§6.2.1) that perform worse than Clang’s counterparts. However, an offline compiler like Clang can spend considerably more time to generate better code, whereas WebAssembly compilers must be fast enough to run online. Therefore, solutions adopted by other JITs, such as further optimizing hot code, are likely applicable here [19, 32].&lt;/p&gt;
    &lt;p&gt;The four other issues that we have identified appear to arise from the design constraints of WebAssembly: the stack overflow checks (§6.2.2), indirect call checks (§6.2.3), and reserved registers (§6.1.1) have a runtime cost and lead to increased code size (§6.3). Unfortunately, these checks are necessary for WebAssembly’s safety guarantees. A redesigned WebAssembly, with richer types for memory and function pointers [23], might be able to perform some of these checks at compile time, but that could complicate the implementation of compilers that produce WebAssembly. Finally, a WebAssembly implementation in a browser must interoperate with a high-performance JavaScript implementation, which may impose its own constraints. For example, current JavaScript implementations reserve a few registers for their own use, which increases register pressure on WebAssembly.&lt;/p&gt;
    &lt;head rend="h2"&gt;7 Related Work&lt;/head&gt;
    &lt;head rend="h5"&gt;Precursors to WebAssembly&lt;/head&gt;
    &lt;p&gt;There have been several attempts to execute native code in browsers, but none of them met all the design criteria of WebAssembly.&lt;/p&gt;
    &lt;p&gt;ActiveX [13] allows web pages to embed signed x86 libraries, however these binaries have unrestricted access to the Windows API. In contrast, WebAssembly modules are sandboxed. ActiveX is now a deprecated technology.&lt;/p&gt;
    &lt;p&gt;Native Client [37, 11] (NaCl) adds a module to a web application that contains platform specific machine code. NaCl introduced sandboxing techniques to execute platform specific machine code at near native speed. Since NaCl relies on static validation of machine code, it requires code generators to follow certain patterns, hence, supporting only a subset of the x86, ARM, and MIPS instructions sets in the browser. To address the inherent portability issue of NaCl, Portable NaCl (PNaCl) [14] uses LLVM Bitcode as a binary format. However, PNaCl does not provide significant improvement in compactness over NaCl and still exposes compiler and/or platform-specific details such as the call stack layout. Both have been deprecated in favor of WebAssembly.&lt;/p&gt;
    &lt;p&gt;asm.js is a subset of JavaScript designed to be compiled efficiently to native code. asm.js uses type coercions to avoid the dynamic type system of JavaScript. Since asm.js is a subset of JavaScript, adding all native features to asm.js such as 64-bit integers will first require extending JavaScript. Compared to asm.js, WebAssembly provides several improvements: (i) WebAssembly binaries are compact due to its lightweight representation compared to JavaScript source, (ii) WebAssembly is more straightforward to validate, (iii) WebAssembly provides formal guarantees of type safety and isolation, and (iv) WebAssembly has been shown to provide better performance than asm.js.&lt;/p&gt;
    &lt;p&gt;WebAssembly is a stack machine, which is similar to the Java Virtual Machine [21] and the Common Language Runtime [25]. However, WebAssembly is very different from these platforms. For example WebAssembly does not support objects and does not support unstructured control flow.&lt;/p&gt;
    &lt;p&gt;The WebAssembly specification defines its operational semantics and type system. This proof was mechanized using the Isabelle theorem prover, and that mechanization effort found and addressed a number of issues in the specification [35]. RockSalt [22] is a similar verification effort for NaCl. It implements the NaCl verification toolchain in Coq, along with a proof of correctness with respect to a model of the subset of x86 instructions that NaCl supports.&lt;/p&gt;
    &lt;head rend="h5"&gt;Analysis of SPEC Benchmarks using performance counters&lt;/head&gt;
    &lt;p&gt;Several papers use performance counters to analyze the SPEC benchmarks. Panda et al. [26] analyze the SPEC CPU2017 benchmarks, applying statistical techniques to identify similarities among benchmarks. Phansalkar et al. perform a similar study on SPEC CPU2006 [27]. Limaye and Adegija identify workload differences between SPEC CPU2006 and SPEC CPU2017 [20].&lt;/p&gt;
    &lt;head rend="h2"&gt;8 Conclusions&lt;/head&gt;
    &lt;p&gt;This paper performs the first comprehensive performance analysis of WebAssembly. We develop Browsix-Wasm, a significant extension of Browsix, and Browsix-SPEC, a harness that enables detailed performance analysis, to let us run the SPEC CPU2006 and CPU2017 benchmarks as WebAssembly in Chrome and Firefox. We find that the mean slowdown of WebAssembly vs. native across SPEC benchmarks is 1.55 for Chrome and 1.45 for Firefox, with peak slowdowns of 2.5 in Chrome and 2.08 in Firefox. We identify the causes of these performance gaps, providing actionable guidance for future optimization efforts.&lt;/p&gt;
    &lt;head rend="h5"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We thank the reviewers and our shepherd, Eric Eide, for their constructive feedback. This work was partially supported by NSF grants 1439008 and 1413985.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;[1] Blazor. https://blazor.net/. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[2] Compiling from Rust to WebAssembly. https://developer.mozilla.org/en-US/docs/WebAssembly/Rust_to_wasm. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[3] LLVM Reference Manual. https://llvm.org/docs/CodeGenerator.html.&lt;/item&gt;
      &lt;item&gt;[4] NaCl and PNaCl. https://developer.chrome.com/native-client/nacl-and-pnacl. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[5] PolyBenchC: the polyhedral benchmark suite. http://web.cs.ucla.edu/~pouchet/software/polybench/. [Online; accessed 14-March-2017].&lt;/item&gt;
      &lt;item&gt;[6] Raise Chrome JS heap limit? - Stack Overflow. https://stackoverflow.com/questions/43643406/raise-chrome-js-heap-limit. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[7] Use cases. https://webassembly.org/docs/use-cases/.&lt;/item&gt;
      &lt;item&gt;[8] WebAssembly. https://webassembly.org/. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[9] System V Application Binary Interface AMD64 Architecture Processor Supplement. https://software.intel.com/sites/default/files/article/402129/mpx-linux64-abi.pdf, 2013.&lt;/item&gt;
      &lt;item&gt;[10] Steve Akinyemi. A curated list of languages that compile directly to or have their VMs in WebAssembly. https://github.com/appcypher/awesome-wasm-langs. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[11] Jason Ansel, Petr Marchenko, Úlfar Erlingsson, Elijah Taylor, Brad Chen, Derek L. Schuff, David Sehr, Cliff L. Biffle, and Bennet Yee. Language-independent Sandboxing of Just-in-time Compilation and Self-modifying Code. In Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI ’11, pages 355–366. ACM, 2011.&lt;/item&gt;
      &lt;item&gt;[12] Michael Bebenita, Florian Brandner, Manuel Fahndrich, Francesco Logozzo, Wolfram Schulte, Nikolai Tillmann, and Herman Venter. SPUR: A Trace-based JIT Compiler for CIL. In Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications, OOPSLA ’10, pages 708–725. ACM, 2010.&lt;/item&gt;
      &lt;item&gt;[13] David A Chappell. Understanding ActiveX and OLE. Microsoft Press, 1996.&lt;/item&gt;
      &lt;item&gt;[14] Alan Donovan, Robert Muth, Brad Chen, and David Sehr. PNaCl: Portable Native Client Executables. https://css.csail.mit.edu/6.858/2012/readings/pnacl.pdf, 2010.&lt;/item&gt;
      &lt;item&gt;[15] Brendan Eich. From ASM.JS to WebAssembly. https://brendaneich.com/2015/06/from-asm-js-to-webassembly/, 2015. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[16] Eric Elliott. What is WebAssembly? https://tinyurl.com/o5h6daj, 2015. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[17] Andreas Gal, Brendan Eich, Mike Shaver, David Anderson, David Mandelin, Mohammad R. Haghighat, Blake Kaplan, Graydon Hoare, Boris Zbarsky, Jason Orendorff, Jesse Ruderman, Edwin W. Smith, Rick Reitmaier, Michael Bebenita, Mason Chang, and Michael Franz. Trace-based Just-in-time Type Specialization for Dynamic Languages. In Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI ’09, pages 465–478. ACM, 2009.&lt;/item&gt;
      &lt;item&gt;[18] Andreas Haas, Andreas Rossberg, Derek L. Schuff, Ben L. Titzer, Michael Holman, Dan Gohman, Luke Wagner, Alon Zakai, and JF Bastien. Bringing the Web Up to Speed with WebAssembly. In Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2017, pages 185–200. ACM, 2017.&lt;/item&gt;
      &lt;item&gt;[19] Thomas Kotzmann, Christian Wimmer, Hanspeter Mössenböck, Thomas Rodriguez, Kenneth Russell, and David Cox. Design of the Java HotSpot Client Compiler for Java 6. ACM Trans. Archit. Code Optim., 5(1):7:1–7:32, 2008.&lt;/item&gt;
      &lt;item&gt;[20] Ankur Limaye and Tosiron Adegbija. A Workload Characterization of the SPEC CPU2017 Benchmark Suite. In 2018 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), pages 149–158, 2018.&lt;/item&gt;
      &lt;item&gt;[21] Tim Lindholm, Frank Yellin, Gilad Bracha, and Alex Buckley. The Java Virtual Machine Specification, Java SE 8 Edition. Addison-Wesley Professional, 1st edition, 2014.&lt;/item&gt;
      &lt;item&gt;[22] Greg Morrisett, Gang Tan, Joseph Tassarotti, Jean-Baptiste Tristan, and Edward Gan. RockSalt: Better, Faster, Stronger SFI for the x86. In Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI ’12, pages 395–404. ACM, 2012.&lt;/item&gt;
      &lt;item&gt;[23] Greg Morrisett, David Walker, Karl Crary, and Neal Glew. From System F to Typed Assembly Language. ACM Trans. Program. Lang. Syst., 21(3):527–568, 1999.&lt;/item&gt;
      &lt;item&gt;[24] Richard Musiol. A compiler from Go to JavaScript for running Go code in a browser. https://github.com/gopherjs/gopherjs, 2016. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[25] George C. Necula, Scott McPeak, Shree P. Rahul, and Westley Weimer. CIL: Intermediate Language and Tools for Analysis and Transformation of C Programs. In R. Nigel Horspool, editor, Compiler Construction, pages 213–228. Springer, 2002.&lt;/item&gt;
      &lt;item&gt;[26] Reena Panda, Shuang Song, Joseph Dean, and Lizy K. John. Wait of a Decade: Did SPEC CPU 2017 Broaden the Performance Horizon? In 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA), pages 271–282, 2018.&lt;/item&gt;
      &lt;item&gt;[27] Aashish Phansalkar, Ajay Joshi, and Lizy K. John. Analysis of Redundancy and Application Balance in the SPEC CPU2006 Benchmark Suite. In Proceedings of the 34th Annual International Symposium on Computer Architecture, ISCA ’07, pages 412–423. ACM, 2007.&lt;/item&gt;
      &lt;item&gt;[28] Bobby Powers, John Vilk, and Emery D. Berger. Browsix: Unix in your browser tab. https://browsix.org.&lt;/item&gt;
      &lt;item&gt;[29] Bobby Powers, John Vilk, and Emery D. Berger. Browsix: Bridging the Gap Between Unix and the Browser. In Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS ’17, pages 253–266. ACM, 2017.&lt;/item&gt;
      &lt;item&gt;[30] Gregor Richards, Sylvain Lebresne, Brian Burg, and Jan Vitek. An Analysis of the Dynamic Behavior of JavaScript Programs. In Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI ’10, pages 1–12. ACM, 2010.&lt;/item&gt;
      &lt;item&gt;[31] Marija Selakovic and Michael Pradel. Performance Issues and Optimizations in JavaScript: An Empirical Study. In Proceedings of the 38th International Conference on Software Engineering, ICSE ’16, pages 61–72. ACM, 2016.&lt;/item&gt;
      &lt;item&gt;[32] Toshio Suganuma, Toshiaki Yasue, Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani. A Dynamic Optimization Framework for a Java Just-in-time Compiler. In Proceedings of the 16th ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, OOPSLA ’01, pages 180–195. ACM, 2001.&lt;/item&gt;
      &lt;item&gt;[33] Luke Wagner. asm.js in Firefox Nightly | Luke Wagner’s Blog. https://blog.mozilla.org/luke/2013/03/21/asm-js-in-firefox-nightly/. [Online; accessed 21-May-2019].&lt;/item&gt;
      &lt;item&gt;[34] Luke Wagner. A WebAssembly Milestone: Experimental Support in Multiple Browsers. https://hacks.mozilla.org/2016/03/a-webassembly-milestone/, 2016. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[35] Conrad Watt. Mechanising and Verifying the WebAssembly Specification. In Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2018, pages 53–65. ACM, 2018.&lt;/item&gt;
      &lt;item&gt;[36] Christian Wimmer and Michael Franz. Linear Scan Register Allocation on SSA Form. In Proceedings of the 8th Annual IEEE/ACM International Symposium on Code Generation and Optimization, CGO ’10, pages 170–179. ACM, 2010.&lt;/item&gt;
      &lt;item&gt;[37] Bennet Yee, David Sehr, Greg Dardyk, Brad Chen, Robert Muth, Tavis Ormandy, Shiki Okasaka, Neha Narula, and Nicholas Fullagar. Native Client: A Sandbox for Portable, Untrusted x86 Native Code. In IEEE Symposium on Security and Privacy (Oakland’09), IEEE, 2009.&lt;/item&gt;
      &lt;item&gt;[38] Alon Zakai. asm.js. http://asmjs.org/. [Online; accessed 5-January-2019].&lt;/item&gt;
      &lt;item&gt;[39] Alon Zakai. Emscripten: An LLVM-to-JavaScript Compiler. In Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion, OOPSLA ’11, pages 301–312. ACM, 2011.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ar5iv.labs.arxiv.org/html/1901.09056"/><published>2025-11-04T23:13:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45817114</id><title>Bluetui – A TUI for managing Bluetooth on Linux</title><updated>2025-11-05T00:51:13.827900+00:00</updated><content>&lt;doc fingerprint="e4d181ddbeaa2ea"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux based OS with bluez installed.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;You might need to install nerdfonts for the icons to be displayed correctly.&lt;/p&gt;
    &lt;p&gt;You can download the pre-built binaries from the release page release page&lt;/p&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from crates.io&lt;/p&gt;
    &lt;code&gt;cargo install bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the extra repository:&lt;/p&gt;
    &lt;code&gt;pacman -S bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the lamdness Gentoo Overlay:&lt;/p&gt;
    &lt;code&gt;sudo eselect repository enable lamdness
sudo emaint -r lamdness sync
sudo emerge -av net-wireless/bluetui&lt;/code&gt;
    &lt;p&gt;If you are a user of x-cmd, you can run:&lt;/p&gt;
    &lt;code&gt;x install bluetui&lt;/code&gt;
    &lt;p&gt;Run the following command:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/pythops/bluetui
cd bluetui
cargo build --release&lt;/code&gt;
    &lt;p&gt;This will produce an executable file at &lt;code&gt;target/release/bluetui&lt;/code&gt; that you can copy to a directory in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Tab&lt;/code&gt;: Switch between different sections.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;j&lt;/code&gt; or &lt;code&gt;Down&lt;/code&gt; : Scroll down.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;k&lt;/code&gt; or &lt;code&gt;Up&lt;/code&gt;: Scroll up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;s&lt;/code&gt;: Start/Stop scanning.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt;: Show help.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;esc&lt;/code&gt;: Dismiss the help pop-up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;ctrl+c&lt;/code&gt; or &lt;code&gt;q&lt;/code&gt;: Quit the app.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;p&lt;/code&gt;: Enable/Disable the pairing.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;o&lt;/code&gt;: Power on/off the adapter.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;d&lt;/code&gt;: Enable/Disable the discovery.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;u&lt;/code&gt;: Unpair the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Connect/Disconnect the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;t&lt;/code&gt;: Trust/Untrust the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;e&lt;/code&gt;: Rename the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Pair the device.&lt;/p&gt;
    &lt;p&gt;Keybindings can be customized in the default config file location &lt;code&gt;$HOME/.config/bluetui/config.toml&lt;/code&gt; or from a custom path with &lt;code&gt;-c&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;# Possible values: "Legacy", "Start", "End", "Center", "SpaceAround", "SpaceBetween"
layout = "SpaceAround"

# Window width
# Possible values: "auto" or a positive integer
width = "auto"

toggle_scanning = "s"

[adapter]
toggle_pairing = "p"
toggle_power = "o"
toggle_discovery = "d"

[paired_device]
unpair = "u"
toggle_trust = "t"
rename = "e"&lt;/code&gt;
    &lt;p&gt;GPLv3&lt;/p&gt;
    &lt;p&gt;Bluetui logo: Marco Bulgarelli&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/pythops/bluetui"/><published>2025-11-04T23:29:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45817167</id><title>Uncle Sam wants to scan your iris and collect your DNA, citizen or not</title><updated>2025-11-05T00:51:13.636681+00:00</updated><content>&lt;doc fingerprint="fbca09582881b604"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Uncle Sam wants to scan your iris and collect your DNA, citizen or not&lt;/head&gt;
    &lt;head rend="h2"&gt;DHS rule would expand biometric collection to immigrants and some citizens linked to them&lt;/head&gt;
    &lt;p&gt;If you're filing an immigration form - or helping someone who is - the Feds may soon want to look in your eyes, swab your cheek, and scan your face. The US Department of Homeland Security wants to greatly expand biometric data collection for immigration applications, covering immigrants and even some US citizens tied to those cases.&lt;/p&gt;
    &lt;p&gt;DHS, through its component agency US Citizenship and Immigration Services, on Monday proposed a sweeping expansion of the agency's collection of biometric data. While ostensibly about verifying identities and preventing fraud in immigration benefit applications, the proposed rule goes much further than simply ensuring applicants are who they claim to be.&lt;/p&gt;
    &lt;p&gt;First off, the rule proposes expanding when DHS can collect biometric data from immigration benefit applicants, as "submission of biometrics is currently only mandatory for certain benefit requests and enforcement actions." DHS wants to change that, including by requiring practically everyone an immigrant is associated with to submit their biometric data.&lt;/p&gt;
    &lt;p&gt;"DHS proposes in this rule that any applicant, petitioner, sponsor, supporter, derivative, dependent, beneficiary, or individual filing or associated with a benefit request or other request or collection of information, including U.S. citizens, U.S. nationals and lawful permanent residents, and without regard to age, must submit biometrics unless DHS otherwise exempts the requirement," the rule proposal said.&lt;/p&gt;
    &lt;p&gt;DHS also wants to require the collection of biometric data from "any alien apprehended, arrested or encountered by DHS."&lt;/p&gt;
    &lt;p&gt;It's not explicitly stated in the rule proposal why US citizens associated with immigrants who are applying for benefits would have to have their biometric data collected. DHS didn't answer questions to that end, though the rule stated that US citizens would also be required to submit biometric data "when they submit a family-based visa petition."&lt;/p&gt;
    &lt;head rend="h3"&gt;Give me your voice, your eye print, your DNA samples&lt;/head&gt;
    &lt;p&gt;In addition to expanded collection, the proposed rule also changes the definition of what DHS considers to be valid biometric data.&lt;/p&gt;
    &lt;p&gt;"Government agencies have grouped together identifying features and actions, such as fingerprints, photographs, and signatures under the broad term, biometrics," the proposal states. "DHS proposes to define the term 'biometrics' to mean 'measurable biological (anatomical, physiological or molecular structure) or behavioral characteristics of an individual,'" thus giving DHS broad leeway to begin collecting new types of biometric data as new technologies are developed.&lt;/p&gt;
    &lt;p&gt;The proposal mentions several new biometric technologies DHS wants the option to use, including ocular imagery, voice prints and DNA, all on the table per the new rule.&lt;/p&gt;
    &lt;p&gt;"The rule proposes to grant DHS express authority to require, request, or accept raw DNA or DNA test results," DHS said, including "to prove or disprove … biological sex" in situations where that can affect benefit eligibility.&lt;/p&gt;
    &lt;p&gt;DHS wants to use all that data for identity enrollment, verification and management of the immigration lifecycle, national security and criminal history checks, "the production of secure identity documents," to prove familial relationships, and to perform other administrative functions, the rule states.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Facial recognition works better in the lab than on the street, researchers show&lt;/item&gt;
      &lt;item&gt;EU biometric border system launch hits inevitable teething problems&lt;/item&gt;
      &lt;item&gt;Vietnam to collect biometrics - even DNA - for new ID cards&lt;/item&gt;
      &lt;item&gt;Altman's eyeball-scanning biometric blockchain orbs officially come to America&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we noted in our story last week about DHS' new rule expanding biometric data collection on entry into and exit from the US, biometric technology - especially the often-used facial recognition scan - is ripe for misuse and prone to errors.&lt;/p&gt;
    &lt;p&gt;This new proposed rule goes far beyond subjecting immigrants to algorithmic identification tech prone to misidentifying non-white individuals, however, and reaches a new level of surveillance, with DHS seeking to collect and keep DNA test results - including partial profiles - from immigrants and some US citizens to verify family ties or biological sex when relevant. It's not much more assuring that DHS also wants to collect new forms of biometric data like voice records, which are increasingly easy to spoof with AI.&lt;/p&gt;
    &lt;p&gt;When we asked DHS questions about its biometric expansion proposal, it only sent us a statement identical to the one it sent last week when we inquired about the new entry/exit biometric requirements. The agency didn't respond when we asked for a statement pertaining to this latest proposed rule.&lt;/p&gt;
    &lt;p&gt;DHS is taking comments on the proposal until January 2; so far the submissions are nearly entirely negative, with posters decrying the plan as government overreach, comparing the proposal to communist China, and calling it a violation of Constitutional guarantees against unreasonable search and seizure. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2025/11/04/dhs_wants_to_collect_biometric_data/"/><published>2025-11-04T23:35:27+00:00</published></entry></feed>