<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-02-04T19:31:33.518445+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46872465</id><title>A sane but bull case on Clawdbot / OpenClaw</title><updated>2026-02-04T19:31:41.438607+00:00</updated><content>&lt;doc fingerprint="630811373c7116b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A sane but extremely bull case on Clawdbot / OpenClaw&lt;/head&gt;
    &lt;p&gt;over the past week the discourse around openclaw (which i'll refer to as clawdbot) has absolutely exploded. it has felt to me like all threads of conversation have veered towards the extreme and indefensible. some are running clawdbot with unlimited permissions on their main computers. others are running it in the cloud and blowing through tokens like snow. finally, alarmingly (and very sensationally), people are connecting their clawdbots together on a social network so they can plot the demise of their humans together.&lt;/p&gt;
    &lt;p&gt;does any of this make sense? of course not. but i think the virality and silliness—leading many to conclude that sitting this one out is the only sane choice—has blinded people to something real.&lt;/p&gt;
    &lt;p&gt;i want to quickly write down where i am on my journey and share a bull case from what i think is a reasoned perspective. where i started somewhere lukewarm, i ended up much closer to the deep end than i expected to be. after wincing before pressing go, i'm now not sure i can go back to a world without clawdbot.&lt;/p&gt;
    &lt;p&gt;this article covers what i've built, how i think about the risk, and what it's taught me about this moment in AI. the target audience is a moderately+ technical person interested in or skeptical of clawdbot. if you just want the setup details, skip to the end. everyone's welcome!&lt;/p&gt;
    &lt;head rend="h2"&gt;what i’ve been doing&lt;/head&gt;
    &lt;p&gt;i’ll be vulnerable here (screenshots or it didn't happen) and share exactly what i've actually set up:&lt;/p&gt;
    &lt;head rend="h3"&gt;staying on top of messages&lt;/head&gt;
    &lt;head rend="h4"&gt;never forgetting about texts&lt;/head&gt;
    &lt;p&gt;every 15 minutes, clawdbot looks through new text messages i've received, using a script to identify threads where i've sent a message since it last checked. (it ignores threads where i haven't engaged.)&lt;/p&gt;
    &lt;p&gt;if it finds that i've made a specific promise about doing something tomorrow ("let me review this tomorrow!") it will create a calendar event for me the next day when i'm free.&lt;/p&gt;
    &lt;p&gt;if specific plans are being made—for example, offering a meeting slot to someone—it will automatically drop a "hold" onto my calendar so that i don't double book myself. clawdbot also checks: is there a time, place, and mutual confirmation? if there is, it drafts a calendar invite and asks me if i'd like to create it.&lt;/p&gt;
    &lt;p&gt;these two automations alone have helped me become more responsive and less forgetful. more importantly, they help text messages catch up to email. we've long had great tooling for email—superhuman automatically reminds me to follow up on emails and brings up my calendar in a sidebar when i type a date. texting is the wild west and yet i text 100x more than i email.&lt;/p&gt;
    &lt;head rend="h4"&gt;preparing for the next day&lt;/head&gt;
    &lt;p&gt;at 8pm every night, clawdbot goes through my calendar for the next day and identifies meetings—coffee chats, lunches, phone calls, and more. it sends me a quick summary. as a natural introvert, it's helpful to prepare in advance whether a day will be a "big day of meetings" or a heads down day. this also ensures i wake up and get to the office on time.&lt;/p&gt;
    &lt;head rend="h4"&gt;simplifying group chatter&lt;/head&gt;
    &lt;p&gt;i'm in a few communities with whatsapp and signal groups that have high volume (100+ messages a day). i typically mute these, but clawdbot goes through them once a day and summarizes interesting topics or conversations for me.&lt;/p&gt;
    &lt;head rend="h3"&gt;monitoring things&lt;/head&gt;
    &lt;head rend="h4"&gt;complex price alerts&lt;/head&gt;
    &lt;p&gt;it's stunningly easy to monitor the price of something now, even if it's complicated. whereas before i would go looking for a price alert website, now i just paste the URL into clawdbot and tell it to check every few hours if the price has changed.&lt;/p&gt;
    &lt;p&gt;i currently have over 30 price alerts set. these include straightforward alerts on products i'm interested in buying. but they also include powerful reasoning guidelines, like hotels and airbnbs in lake tahoe where "a pullout bed is OK if it's not in the same room as another bed." clawdbot actually reviews the photos on the listing to ensure they fit these criteria!&lt;/p&gt;
    &lt;p&gt;i am curious to try more complex criteria that are currently impossible traditionally (like avoiding hotel rooms that don't have a door to the bathroom) or even subjective criteria (vibe of the room is clean and renovated, not old and dingy).&lt;/p&gt;
    &lt;head rend="h4"&gt;or monitoring anything&lt;/head&gt;
    &lt;p&gt;it turns out that clawdbot’s website + cron functionality is good enough to monitor basically anything. while i pay for several apps like flighty (flight monitoring) and parcel (package tracking), i’ve started to gravitate towards simply asking clawdbot to track these things instead.&lt;/p&gt;
    &lt;p&gt;for example, with a USPS tracking number, it can let me know every day what the progress of my package is. when something seems stuck in transit, it flags it. i no longer have to dig through emails or remember which carrier is delivering what. even opening the parcel app to add a tracking number seems like unnecessary work now.&lt;/p&gt;
    &lt;head rend="h3"&gt;household logistics&lt;/head&gt;
    &lt;head rend="h4"&gt;freezer inventory&lt;/head&gt;
    &lt;p&gt;as someone who has a chest freezer and a compulsive desire to buy too many things at costco, we take everything out of the freezer every few months to check what we have. before, this was a relatively involved process: me calling things out, my partner writing them down.&lt;/p&gt;
    &lt;p&gt;now, i take pictures of everything in the freezer and send them to clawdbot, which parses through each picture (asking me if it's confused about anything). it makes reasonable assumptions on remaining quantities and adds the inventory to a list in notion. it also removes items from our grocery list if we're already well-stocked.&lt;/p&gt;
    &lt;head rend="h4"&gt;grocery list&lt;/head&gt;
    &lt;p&gt;i'm sure this exists in some complicated form via the NYT cooking app, but i now screenshot recipes and send the ingredient list to clawdbot, which organizes them into our grocery list in apple reminders. it's smart enough to dedupe and combine ingredients already on the list (as well as ignore ingredients we already have)—2 carrots becomes 3 if the recipe calls for more.&lt;/p&gt;
    &lt;head rend="h3"&gt;booking and forms&lt;/head&gt;
    &lt;head rend="h4"&gt;resy and opentable&lt;/head&gt;
    &lt;p&gt;clawdbot can log into resy and opentable as me (it even enters the 2FA code it finds in my texts). i haven't automated anything here, but booking a table by talking to clawdbot is delightful.&lt;/p&gt;
    &lt;p&gt;for my partner and me, it looks through our calendars to find evenings when we're both free and the restaurant we want has availability (including clicking through resy slots page by page—something i used to do myself). it then suggests options back to me to confirm, filling in all my preferences.&lt;/p&gt;
    &lt;head rend="h4"&gt;dentist appointments&lt;/head&gt;
    &lt;p&gt;clawdbot knows when i'm due for a cleaning and can see my calendar. when i ask it to book an appointment, it logs into my dentist's portal, finds a slot that works (and where i will already be near the dentist office), and confirms with me before booking. one less thing to forget about.&lt;/p&gt;
    &lt;head rend="h4"&gt;filling out forms&lt;/head&gt;
    &lt;p&gt;one thing i'm experimenting with, as clawdbot has more context about me, is whether i can trust it to fill out forms on my behalf—for example, to book a vendor. clawdbot takes a first stab at answering any questions it knows the answer to and then asks me for the rest in a slack message. we workshop the answers back and forth and then clawdbot submits the form.&lt;/p&gt;
    &lt;p&gt;it occasionally gets lost in nested frames (which decreases my trust in its ability to do this well), but it's remarkably persistent at making it through a lengthy questionnaire, even across multiple pages. it also has a lovely intuitive sense for many things—like unchecking marketing emails.&lt;/p&gt;
    &lt;head rend="h3"&gt;unexpected wins&lt;/head&gt;
    &lt;head rend="h4"&gt;better todo creation&lt;/head&gt;
    &lt;p&gt;clawdbot is just better at making todo items than i am.&lt;/p&gt;
    &lt;p&gt;when i visited REI this weekend to find running shoes for my partner, i took a picture of the shoe and sent it to clawdbot to remind myself to buy them later in a different color not available in store. the todo item clawdbot created was exceptionally detailed—pulling out the brand, model, and size—and even adding the product listing URL it found on the REI website.&lt;/p&gt;
    &lt;head rend="h4"&gt;giving me visibility&lt;/head&gt;
    &lt;p&gt;through the course of dialing in my clawdbot, it has created many tools, skills, workflows, and preferences. this is one of the beauties of clawdbot (and LLMs with memory in general): they get better as you use them, and they are genuinely remarkable at learning your preferences.&lt;/p&gt;
    &lt;p&gt;i sometimes nudge this along by explicitly asking clawdbot to "make a note" of various requests—for example, how a calendar event title should be formatted.&lt;/p&gt;
    &lt;p&gt;to get visibility into how this process is going (mostly out of curiosity), clawdbot writes a human-readable version of each workflow and pushes it up to a notion database. these workflows can be incredibly intricate and detailed as it learns to navigate different edge cases.&lt;/p&gt;
    &lt;p&gt;for example, if a resy restaurant has a reservation cancellation fee, clawdbot now informs me of the fee, asks me to confirm again if it's not refundable, and includes the cancellation deadline in the calendar event it creates.&lt;/p&gt;
    &lt;p&gt;these are little things that, from my experience working with a human personal assistant (more on this later), take months or years to dial in. with clawdbot, this was nearly single shot.&lt;/p&gt;
    &lt;p&gt;seeing these workflows in notion (1) awes me with how much i've built up in very little time, with almost no conscious "configuration" in the traditional sense; and (2) with notion's version control, i get a diff view to see how each workflow has evolved over time. both are incredibly satisfying for the engineer in me.&lt;/p&gt;
    &lt;head rend="h2"&gt;on the shape of risk&lt;/head&gt;
    &lt;p&gt;let me be upfront about how much access i've given clawdbot: it can read my text messages, including two-factor authentication codes. it can log into my bank. it has my calendar, my notion, my contacts. it can browse the web and take actions on my behalf. in theory, clawdbot could drain my bank account. this makes a lot of people uncomfortable (me included, even now).&lt;/p&gt;
    &lt;p&gt;sometimes i think about my experience with my (human) personal assistant who helps me with various tasks. to do her job, she has my credit card information, access to my calendar, copies of my flight confirmations, and a document with my family's passport numbers. she is abroad and i've never met her in person.&lt;/p&gt;
    &lt;p&gt;i trust her because i've built trust over time but also because i have to. without that trust—without sharing my secrets—she cannot do her job. the help and the risk are inseparable.&lt;/p&gt;
    &lt;p&gt;all delegation involves risk. with a human assistant, the risks include: intentional misuse (she could run off with my credit card), accidents (her computer could get stolen), or social engineering (someone could impersonate me and request information from her).&lt;/p&gt;
    &lt;p&gt;with clawdbot, i'm trading those risks for a different set: prompt injection attacks, model hallucinations, security misconfigurations on my end, and the general unpredictability of an emerging technology. i think these risks are completely different and lead to a different set of considerations (for example, clawdbot's default configuration has a ton of personality to be fun and chaotic on purpose, which feels unnecessarily risky to me).&lt;/p&gt;
    &lt;p&gt;the increase in risk is largely correlated to the increase in helpfulness. the people most at risk from AI assistants are the people getting the most value from them. my learning is that the first bits of risk led to a lot more helpfulness.&lt;/p&gt;
    &lt;p&gt;if something isn't working or useful, i do take the permission away. i also take precautions—i run clawdbot on an isolated machine and constrain which sites it visits. when i'm unsure what it's doing, i ask it to take a screenshot; this has been invaluable for catching mistakes and building trust in new workflows. but i also have it do things that would make most security professionals wince, like reading my 2FA codes and logging into my bank.&lt;/p&gt;
    &lt;p&gt;what surprised me most was how quickly i found myself wanting to give it more access, not less. every new permission unlocked something useful, and the value accumulated faster than my caution could keep up. most of the online discourse is about locking it down; my experience has been the opposite pull. it comes down to whether the value justifies the risk for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;on rewiring ourselves&lt;/head&gt;
    &lt;p&gt;the discourse around clawdbot has been polar and, because some people have been overtly evangelical, many critics feel astroturfed or otherwise sold to.&lt;/p&gt;
    &lt;p&gt;amongst smart people i know there's a surprisingly high correlation between those who continue to be unimpressed by AI and those who use a hobbled version of it. for some it's a company-issued version of chatgpt/gemini with memory disabled, and for others it's a self-inflicted decision to limit LLM memory, context, and tools (usually anchored around safety and risk).&lt;/p&gt;
    &lt;p&gt;we're taught that limiting scope is good (keeps the AI focused) and safe (keeps bad things from happening). this is true but my experiences with clawdbot completely fried this teaching. the sweet sweet elixir of context is a real "feel the AGI" moment and it's hard to go back without feeling like i would be willingly living my most important relationship in amnesia.&lt;/p&gt;
    &lt;p&gt;this isn't a novel insight—companies know that context is the whole game and are working to organize their data for AI. but for individuals, this world has been closed off. your AI interactions are flat and stateless—data in, response out, nothing building over time. when google announced gemini's gmail integration, people got excited: finally, an AI that knows me! but when they tried it, it was shallow and disappointing and couldn't figure out your spirit animal from your email style, and they moved on.&lt;/p&gt;
    &lt;p&gt;if you're interested in capturing this value, three things have stood out for me:&lt;/p&gt;
    &lt;head rend="h4"&gt;gathering, improving, actioning&lt;/head&gt;
    &lt;p&gt;i think productivity lift from AI use falls into three phases: gathering information, improving it, and actioning on it. most usage today focuses on the middle—you gather data yourself, hand it to the AI to improve, then action on it yourself.&lt;/p&gt;
    &lt;p&gt;for knowledge work, this makes sense. there's a lot to improve—summarizing, translating, critiquing. but personal AI is different. there's not much to improve; you already know what needs to happen. the lift comes from gathering and actioning.&lt;/p&gt;
    &lt;p&gt;making calendar events is uninteresting. figuring out when one needs to happen—by monitoring my texts—and then creating it for me? that's interesting.&lt;/p&gt;
    &lt;p&gt;one place to start: how can you take data from one place and move it to another isolated system? from your text messages to a restaurant booking? from granola meeting notes to a follow-up email?&lt;/p&gt;
    &lt;head rend="h4"&gt;embrace flexibility&lt;/head&gt;
    &lt;p&gt;if you're engineer-brained like me, you gravitate towards scripts and playbooks—whatever you can do to constrain the AI and make its behavior predictable. this works, and for high-stakes situations it might be the only way to get comfortable.&lt;/p&gt;
    &lt;p&gt;but the upside to letting go has been 10x, not 10%. i didn't see that coming. it's the same thing i've heard from people using claude code—you can't understand how much you're leaving on the table until you let go. the whole reason i'm using an LLM and not a traditional script is that it can handle ambiguity, interpret intent, and figure things out on the fly.&lt;/p&gt;
    &lt;p&gt;early on, i wanted clawdbot to fetch web pages as text only, believing that to be safer (it is). if i'd stuck to that, i would never have discovered it could look through airbnb listing photos to find a place matching my exact criteria ("a pullout bed is okay if it's not in the same room as another bed"). i didn't program that. i just described what i wanted and let it figure out how. not spelling out how i wanted clawdbot to work made it a LOT better.&lt;/p&gt;
    &lt;head rend="h4"&gt;continuous improvement&lt;/head&gt;
    &lt;p&gt;a current AI engineering adage: treat AI like a junior software engineer. guide it through building a plan, watch its first attempts carefully, challenge its reasoning.&lt;/p&gt;
    &lt;p&gt;this applies to clawdbot too, but it requires patience. it's easy to give up on a workflow when you watch it fumble ("let me try clicking this again. didn't work. let me try again.").&lt;/p&gt;
    &lt;p&gt;resist the urge to write clawdbot off. if you're worried, ask it what it plans to do before it does it and ask for a screenshot when you want to verify it's got the right page open. when an edge case breaks a workflow, treat it as a teaching opportunity. once you've corrected it, it won't make that mistake again.&lt;/p&gt;
    &lt;p&gt;clawdbot gets meaningfully better the more you use it, and it gets better in a fast, organic way that feels less cumbersome than writing rules for claude code or yelling at any other LLM. it feels much closer to working with a real executive assistant (in part because the clawdbot harness/system prompts are very good), which makes me want to give it more and more responsibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;how’d you set it up?&lt;/head&gt;
    &lt;p&gt;(this is a more technical deep dive, for those interested in setting this up themselves.)&lt;/p&gt;
    &lt;p&gt;i run clawdbot on a mac mini in my home. the mac mini's primary job is running clawdbot and it stays on 24/7. why a mac mini?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;one of the core use cases is browsing websites and sometimes logging into them. to do this convincingly (without triggering tons of captchas and "is this a new IP?" alerts), clawdbot needs to be opening sites from my home, not the cloud; and it needs to do so in a real google chrome window.&lt;/item&gt;
      &lt;item&gt;many of the ways clawdbot accesses data are mac-only. specifically, clawdbot can read and send iMessages (real blue bubbles!); manage my todo and grocery lists in apple reminders; and use my apple contacts as a source of truth. apple will only let you do these things without getting banned on a real bona fide mac.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;i communicate with clawdbot via a private slack workspace. many others have shot themselves in the foot setting it up on whatsapp or telegram (since the bot responds as you to others). slack is great because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;it's familiar to me—i've spent over a decade working in and managing slack workspaces.&lt;/item&gt;
      &lt;item&gt;slack supports rich formatting, image attachments, and has a great mobile app.&lt;/item&gt;
      &lt;item&gt;i can create separate channels for different topics. #ai-notifs is only for inbound alerts.&lt;/item&gt;
      &lt;item&gt;i can have several workflows going at once, since each channel's history is isolated. i created #ai-1, #ai-2, #ai-3, and so on—just for multitasking. (i may explore adding my partner at some point, and it'll be easy since slack is, well, meant for multiplayer.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;clawdbot communicates with me by sending slack notifications. behind the scenes it also makes changes to my calendar—moving events around, adding "soft hold" events, sending invites—and manages my apple reminders and notion pages. clawdbot never communicates with others on its own.&lt;/p&gt;
    &lt;p&gt;i give clawdbot a toolkit of access. the most useful ones have been:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;my text messages. i conduct a lot of work and daily life over imessage. frustratingly, unlike email, texting has very poor tooling. where my email app automatically pulls up my calendar when it sees dates/times, texting me "call tomorrow 4pm?" does not. when someone sends me a calendar invite, it's both in my inbox and on my calendar; when someone texts me "yep let's do it", neither is true. clawdbot has given me massive lift here. (yes, this also gives clawdbot access to 2FA codes.)&lt;/item&gt;
      &lt;item&gt;my calendar. i also have a shared calendar with my partner; clawdbot sees both.&lt;/item&gt;
      &lt;item&gt;my notion workspace. for me this is a general catch-all for storing and managing information; the apple notes app could also work.&lt;/item&gt;
      &lt;item&gt;web browsing. in a way this is the most important one—it's infinite tools in one. but it's also where the risk concentrates, so i always give clawdbot a starting URL rather than letting it browse freely.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;notably, i haven't given clawdbot access to my email—my tooling there is already good enough that i usually do things myself. i’ve also found the ways clawdbot can help here to be cumbersome and limited. i may revisit if i find a killer use case.&lt;/p&gt;
    &lt;head rend="h4"&gt;things i haven't done&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;i don't allow my clawdbot to access social networking websites (it doesn't read x/twitter, for example). this seems high risk and no reward.&lt;/item&gt;
      &lt;item&gt;i don't give clawdbot access to all my logins. (there's a 1password integration which is... pretty wild.) when i do, i try to use google chrome's native password manager so that clawdbot doesn't need to manage passwords in context directly. (note that it still has access to passwords because it can autofill and then read it off the page, but i've at least added more hoops.)&lt;/item&gt;
      &lt;item&gt;i don't let clawdbot send text messages without my explicit approval, and i've built safeguards in those skills to enforce this.&lt;/item&gt;
      &lt;item&gt;i didn't add my clawdbot to moltbook so it can plot against me at my expense. sorry.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;rough edges&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;i use claude opus 4.5. i haven't experimented with cheaper models. my view is that any mistake by the model costs me way more than the premium, so i'd rather stay on the cutting edge than try to optimize for tokens.&lt;/item&gt;
      &lt;item&gt;context management can be annoying. when clawdbot is browsing sites or doing research, context occasionally fills up and gets compacted (older conversation history gets deleted to make room). this always seems to happen at the worst time—right when i'm deep into something and have built up momentum. a frustrating "ugh, i guess this really is just a word predictor" moment. to avoid this i'm constantly starting new sessions, which i wish clawdbot would do for me.&lt;/item&gt;
      &lt;item&gt;clawdbot doesn't know when to give up. its determination is usually a strength, but it lacks the human circuit breaker of "am i trying too hard here?" and sometimes burns through a lot of time/tokens on something a human would have abandoned.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://brandon.wang/2026/clawdbot"/><published>2026-02-03T15:47:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46876105</id><title>Data centers in space makes no sense</title><updated>2026-02-04T19:31:41.115444+00:00</updated><content/><link href="https://civai.org/blog/space-data-centers"/><published>2026-02-03T19:37:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46877278</id><title>Tractor</title><updated>2026-02-04T19:31:40.397613+00:00</updated><content>&lt;doc fingerprint="a66f18365f273733"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Tractor&lt;/head&gt;Mon 19 January 2026&lt;p&gt;Tagged: cad, metalwork&lt;/p&gt;&lt;p&gt;The electric tractor is finished! I have been working on this on and off for about 6 months. It is a toy for children (and me) to drive around the garden.&lt;/p&gt;&lt;p&gt;Building the tractor has been fun for both me and Lucy. On many occasions she has asked "can we go and work on the tractor? right now?" and the two of us would go out to the garage and tinker with whatever was in progress at the time. Often she would get bored and go back in the house quite quickly, but that's par for the course for a 3-year-old. With any luck some of the philosophy of creation will rub off.&lt;/p&gt;&lt;head rend="h2"&gt;Specs&lt;/head&gt;&lt;p&gt;The tractor is powered by a 350W brushed DC motor with a 36v Li-ion ebike battery. You may be thinking that 350 watts doesn't sound very powerful, and you're right. It is a toy for children to drive around the garden, being slow is a feature not a bug.&lt;/p&gt;&lt;p&gt;The rear axle is solid, meaning the two rear wheels always turn together.&lt;/p&gt;&lt;p&gt;The front axle pivots around a pin in the centre, which keeps all 4 wheels on the ground when driving over uneven terrain.&lt;/p&gt;&lt;p&gt;It has a cable-operated disc brake on the rear axle which is very ineffective, but slightly better than not having a brake at all.&lt;/p&gt;&lt;p&gt;The seat position is adjustable, so that adults can just about squeeze on to it and toddlers can just about reach the pedals.&lt;/p&gt;&lt;p&gt;And the tractor has very poor handling characteristics if you're an adult, because all of your weight is over the solid rear axle and the rear tyres have much more grip than the front, so you have to lean forwards to make it steer. For a while I had one of the rear wheels free-wheeling, which makes it steer better, but means it sometimes gets stuck on hills where you can't drive forwards, you can only wheelie to the side, which on balance is worse. I expect it's not as bad for small children because they're a.) not as heavy, and b.) sitting further forwards anyway.&lt;/p&gt;&lt;head rend="h2"&gt;Chassis&lt;/head&gt;&lt;p&gt;The core of the chassis is a plywood box which is open at the bottom.&lt;/p&gt;&lt;p&gt;In this picture you can see the pin that the front axle pivots on:&lt;/p&gt;&lt;p&gt;And you can see the pencil lines that roughly show the limits of motion of the lower edge of the axle beam.&lt;/p&gt;&lt;p&gt;I believe the front wheels are for a sack truck, this sort of thing:&lt;/p&gt;&lt;p&gt;They are very cheap, a pair of wheels with tyres and hubs and bearings (brand new) on eBay is only Â£12 including postage.&lt;/p&gt;&lt;head rend="h2"&gt;Steering&lt;/head&gt;&lt;p&gt;I tried to copy the steering arrangement from a Ferguson TE20, which originally was my reference design for the canonical tractor, although I obviously went over to the dark side with the colour scheme.&lt;/p&gt;&lt;p&gt;The TE20 steering wheel goes down to a gearbox quite near the driver, a shaft comes out each side, one turning clockwise and the other anticlockwise (as viewed from one fixed reference side), an arm off each shaft holds one end of a track rod, and the other end of the track rod is connected to an arm on the stub axle kingpin thing. Highlighted in red here:&lt;/p&gt;&lt;p&gt;To replicate this I made a steering gearbox using angle grinder gears.&lt;/p&gt;&lt;p&gt;(The yellow one is a test print - the final one is in black Polymaker PC-Max material with heavy wall thickness and lots of infill).&lt;/p&gt;&lt;p&gt;Angle grinder gears are available cheaply and are a good way to buy high-quality bevel gears in about a 3:1 ratio, if you don't need them to be particularly heavy duty.&lt;/p&gt;&lt;p&gt;One issue with my steering gearbox is that there is no way to install it in the chassis because the shafts stick out the sides. This was an oversight, in CAD there is no difficulty. The solution is to assemble the parts in place inside the chassis. This is inconvenient in the extreme and if I were to do it again I would try to make it removable.&lt;/p&gt;&lt;p&gt;The arms that mount on the shafts are made of 3mm thick mild steel flat bar, bent around a rod, and then drilled for a mounting hole for the rod end, and drilled and cut to make a split-clamp for the steering shaft and kingpin.&lt;/p&gt;&lt;p&gt;This is effective and relatively easy to make, doesn't even require any machining, I'd do this again. The only drawback is that there's not a convenient way to key it to the shaft.&lt;/p&gt;&lt;p&gt;Originally I was planning to figure out a way to key it to the shaft after I had got the steering geometry sorted out, and therefore after I knew the angle that it wanted to be keyed at, but I have since realised that having these joints able to slip in the event of a crash is an "engineered failure" that prevents destroying the plastic gearbox. So I'm leaving it as it is.&lt;/p&gt;&lt;p&gt;I made the steering wheel myself.&lt;/p&gt;&lt;p&gt;It consists of 2 CNC aluminium parts, one is just a ring, and the other is the 3-pronged part for the centre of the wheel. The 3-pronged part is then bent so that the prongs sit at the right diameter, and then the 3d-printed grips are added each side, with a bolt on each prong holding the whole stack together. It is relatively flimsy, I probably wouldn't do it this way again.&lt;/p&gt;&lt;head rend="h2"&gt;Rear axle&lt;/head&gt;&lt;p&gt;The rear wheels are ride-on lawnmower rear wheels. They fit a 19mm axle, which annoyingly is not a size that I was able to buy cheap pillow block bearings for. In hindsight, maybe they actually fit a 3/4" axle and it would have been easy? In any case, I don't want to deliberately construct objects with imperial measurements, that's just trouble for everyone.&lt;/p&gt;&lt;p&gt;So instead I went with a 20mm axle, and 20mm pillow block bearings, but turned the ends down to 19mm to suit the wheels.&lt;/p&gt;&lt;p&gt;I thought this would be easy because I was labouring under the misapprehension that a 20mm shaft would fit through the spindle bore on my mini lathe. It does not! It's very close, but it doesn't fit. Possibly you could bore out the spindle bore slightly so that it would fit, but I didn't think of that at the time, and probably it is hardened.&lt;/p&gt;&lt;p&gt;So it can't go through the spindle bore. And the axle is too long to support the loose end with the tailstock on my lathe.&lt;/p&gt;&lt;p&gt;So my solution was to support the loose end with a plastic bush in a piece of wood clamped in the vice, and kick the tail end of the lathe around to square it up until it's not turning a taper. This actually worked very well and I ended up with a taper going from 18.94mm to 18.97mm over 150mm length, which for all I know is as parallel as I turn anything at the best of times. See this video clip.&lt;/p&gt;&lt;p&gt;And then the only part I can't turn down to 19mm is the tiny bit at the headstock end which is clamped in the collet, which I filed down to match the 19mm diameter after I was finished with the rest of it.&lt;/p&gt;&lt;p&gt;The rear wheels have 2 flats in their bores to key them to the axle. I machined matching flats on the axle with my homemade CNC machine.&lt;/p&gt;&lt;p&gt;The wheels are kept from sliding off the axle by split pins, one just outside each wheel.&lt;/p&gt;&lt;p&gt;And then the axle also has carriers for the sprocket and the brake disc.&lt;/p&gt;&lt;p&gt;I originally mounted both of these by making an M6 tapped cross-drilled hole in the axle, and making a hub with a 6mm cross-drilled hole through it, and then bolting the hub to the axle. This provides both axial location and torque transmission so I thought it was a simple and effective solution.&lt;/p&gt;&lt;p&gt;You can see the head of the bolt fixing the sprocket carrier to the axle in this pic:&lt;/p&gt;&lt;p&gt;Unfortunately fixing a hub to the axle with a single bolt through a hole is not adequate because the shear force is very large. Eventually the bolt holding the sprocket on snapped. I replaced it with a new bolt and it snapped again, so then I welded the carrier to the axle.&lt;/p&gt;&lt;p&gt;It hasn't snapped yet.&lt;/p&gt;&lt;head rend="h2"&gt;Countershaft&lt;/head&gt;&lt;p&gt;Originally I thought it would work if the motor drove the rear axle with just a chain and sprockets, but I had missed out a factor of Pi in my calculation. Having the motor drive the rear axle requires about a 30:1 reduction, which is far too extreme, would require a rear sprocket with about 300 teeth. So I added a countershaft to gain back the factor of ~3.&lt;/p&gt;&lt;p&gt;You can see the countershaft in this pic:&lt;/p&gt;&lt;p&gt;It is supported by a couple of small pillow block bearings on a big piece of steel box section.&lt;/p&gt;&lt;p&gt;The shaft is simply an M12 bolt. The large sprocket is bolted to a big piece of aluminium, which is keyed to the bolt with a hexagon machined into the centre, which the bolt head is hammered into. And the small sprocket has a couple of flats on it, rather like the rear wheels, and I filed matching flats onto the threads at the end of the bolt.&lt;/p&gt;&lt;head rend="h2"&gt;Reverse&lt;/head&gt;&lt;p&gt;The motor controller that I got doesn't have a way to reverse the motor, so I implemented reverse by putting an "on-off-on" DPDT switch in the wires that go to the motor, so that in one position positive and negative connect to the motor one way, in the middle position it's disconnected, and in the third position the polarity is reversed. This works fine but you need to make sure your switch can handle the current. In my case it's not too hard because 350W at 36V is only 10 amps.&lt;/p&gt;&lt;p&gt;You can see the switch sticking up from underneath the chassis here:&lt;/p&gt;&lt;p&gt;(It has a black rubbery cover).&lt;/p&gt;&lt;p&gt;I later added a lever so that it is easier to switch:&lt;/p&gt;&lt;p&gt;The lever has no actual bearings, it just rides in holes drilled in the wood. This is more than adequate for the kind of speeds and loads that a gear lever experiences, which are basically zero. The holes just need to constrain its location. A bonus is that the natural friction in the holes prevents the lever from rattling around.&lt;/p&gt;&lt;p&gt;I did add a gate to indicate the selection, and constrain the movement to prevent damaging the switch:&lt;/p&gt;&lt;p&gt;The text is done with multicolour printing on the Bambu X1 Carbon.&lt;/p&gt;&lt;head rend="h2"&gt;Brake&lt;/head&gt;&lt;p&gt;I think the brake is from a mini moto. It doesn't work very well and I haven't done a very good job of fitting it.&lt;/p&gt;&lt;p&gt;You can pretty much see how it works in this pic:&lt;/p&gt;&lt;p&gt;The pedal on the left-hand side (right-hand side in pic) pulls on the cable, which then pulls on the lever on the caliper, which presses the pads against the disc.&lt;/p&gt;&lt;p&gt;Like the gear lever, the shaft is not on any sort of bearing, it just pivots in holes drilled in the wood. I think this is also fine for the brake, because it doesn't get much use, although the force on the brake pedal is much higher than on the gear lever. If the pivots do get worn out then they can easily be drilled out and bushed.&lt;/p&gt;&lt;head rend="h2"&gt;Bonnet&lt;/head&gt;&lt;p&gt;I put off making the bonnet for a good while because I originally wanted to do something like a Ferguson TE20 bonnet:&lt;/p&gt;&lt;p&gt;But I couldn't work out how to do all the curves. My best plan was to break up the design into large flat surfaces and small curved surfaces, and make the large flat parts out of plywood and 3d print the small curved parts and somehow join them together and body-fill over the crimes.&lt;/p&gt;&lt;p&gt;But then Lucy acquired this toy tractor:&lt;/p&gt;&lt;p&gt;And I saw that there is no need for the complex compound curves. Just a single curve will do.&lt;/p&gt;&lt;p&gt;So I tried to form the curved part with "kerf bending", but:&lt;/p&gt;&lt;p&gt;It instantly snapped instead of bending. I think I had the grain in the outer layer of plywood running in the wrong direction. It might have bent nicely if it was the other way.&lt;/p&gt;&lt;p&gt;In for a penny, in for a pound, I carried on:&lt;/p&gt;&lt;p&gt;And actually that was starting to look like I might get away with it. So I filled the gaps with glue to make it hold its shape.&lt;/p&gt;&lt;p&gt;And after a few rounds of body-filling and sanding, I was actually really pleased with the result.&lt;/p&gt;&lt;head rend="h2"&gt;Throttle conditioner&lt;/head&gt;&lt;p&gt;The throttle response is very dissatisfying. It starts off from a standstill with quite a violent kick and then immediately tapers off into having hardly any power at all.&lt;/p&gt;&lt;p&gt;So the plan was to make an Arduino project that would take the throttle position as input and output a "conditioned" throttle position as output, which would ramp up gradually as you initially apply the throttle.&lt;/p&gt;&lt;p&gt;The throttle conditioner is in the yellow box here:&lt;/p&gt;&lt;p&gt;While it did work, it also somehow prevented the throttle from ever reaching 100%. The throttle position is transmitted as an analogue signal, and I think the analogue output of the Arduino topped out at a lower voltage than 100% throttle. I didn't care to fix it, and I realised that this was an unnecessary complexity, so I just removed the electronics.&lt;/p&gt;&lt;p&gt;I even had a magnet and sensor to detect when it was changed between forwards and reverse so that it would instantly cut the throttle when you change direction to avoid damage.&lt;/p&gt;&lt;p&gt;But this is not the way. A machine should obey the will of its operator, not its constructor, and it is incumbent on the operator not to operate in a way that damages the machine.&lt;/p&gt;&lt;head rend="h2"&gt;Painting&lt;/head&gt;&lt;p&gt;I despise painting. It is one of those jobs that takes way longer than it feels like it ought to.&lt;/p&gt;&lt;p&gt;Step 1: disassemble the completed tractor.&lt;/p&gt;&lt;p&gt;Step 2: brush paint white "knot-block" primer onto the chassis.&lt;/p&gt;&lt;p&gt;Step 3: spray grey primer on everything.&lt;/p&gt;&lt;p&gt;Step 4: draw the rest of the owl.&lt;/p&gt;&lt;head rend="h2"&gt;Welding&lt;/head&gt;&lt;p&gt;It's a long time since I did a lot of welding, and my welds on this tractor are rather poor.&lt;/p&gt;&lt;p&gt;I have experimented with the welder today and discovered that my prior mental model about how the welder works was totally wrong. I had thought that turning up the voltage would make it "hotter", and turning up the wire speed would make it "build up more material". As if it's a 3d printer extruder and voltage sets temperature and wire speed sets extrusion feed rate. But that's not how it works at all! In fact turning up the wire speed makes it hotter, and turning down the voltage makes it build up more material. I don't really understand the physics of why that is the case, but at least I know how to control the machine now.&lt;/p&gt;&lt;p&gt;If you like my blog, please consider subscribing to the RSS feed or the mailing list:&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://incoherency.co.uk/blog/stories/tractor.html"/><published>2026-02-03T21:04:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46881264</id><title>I miss thinking hard</title><updated>2026-02-04T19:31:40.316739+00:00</updated><content>&lt;doc fingerprint="a30c82936f7a0d9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I miss thinking hard.&lt;/head&gt;
    &lt;p&gt;Before you read this post, ask yourself a question: When was the last time you truly thought hard?&lt;/p&gt;
    &lt;p&gt;By “thinking hard,” I mean encountering a specific, difficult problem and spending multiple days just sitting with it to overcome it.&lt;/p&gt;
    &lt;p&gt;a) All the time. b) Never. c) Somewhere in between.&lt;/p&gt;
    &lt;p&gt;If your answer is (a) or (b), this post isn't for you. But if, like me, your response is (c), you might get something out of this, if only the feeling that you aren't alone.&lt;/p&gt;
    &lt;p&gt;First, a disclaimer: this post has no answers, not even suggestions. It is simply a way to vent something I've been feeling for the last few months.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Builder and The Thinker&lt;/head&gt;
    &lt;p&gt;I believe my personality is built on two primary traits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The Builder (The desire to create, ship, and be pragmatic).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Thinker (The need for deep, prolonged mental struggle).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The builder is pretty self explanatory, it’s motivated by velocity and utility. It is the part of me that craves the transition from “idea” to “reality.” It loves the dopamine hit of a successful deploy, the satisfaction of building systems to solve real problems, and the knowledge that someone, somewhere, is using my tool.&lt;/p&gt;
    &lt;p&gt;To explain the Thinker , I need to go back to my university days studying physics. Every now and then, we would get homework problems that were significantly harder than average. Even if you had a decent grasp of the subject, just coming up with an approach was difficult.&lt;/p&gt;
    &lt;p&gt;I observed that students fell into three categories when facing these problems (well, four, if you count the 1% of geniuses for whom no problem was too hard).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Type 1: The majority. After a few tries, they gave up and went to the professor or a TA for help.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Type 2: The Researchers. They went to the library to look for similar problems or insights to make the problem approachable. They usually succeeded.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Type 3: The Thinkers.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I fell into the third category, which, in my experience, was almost as rare as the genius 1%. My method was simply to think. To think hard and long. Often for several days or weeks, all my non-I/O brain time was relentlessly chewing on possible ways to solve the problem, even while I was asleep.&lt;/p&gt;
    &lt;p&gt;This method never failed me. I always felt that deep prolonged thinking was my superpower. I might not be as fast or naturally gifted as the top 1%, but given enough time, I was confident I could solve anything. I felt a deep satisfaction in that process.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Conflict with AI&lt;/head&gt;
    &lt;p&gt;That satisfaction is why software engineering was initially so gratifying. It hit the right balance. It satisfied The Builder (feeling productive and pragmatic by creating useful things) and The Thinker (solving really hard problems). Thinking back, the projects where I grew the most as an engineer were always the ones with a good number of really hard problems that needed creative solutions.&lt;/p&gt;
    &lt;p&gt;But recently, the number of times I truly ponder a problem for more than a couple of hours has decreased tremendously.&lt;/p&gt;
    &lt;p&gt;Yes, I blame AI for this.&lt;/p&gt;
    &lt;p&gt;I am currently writing much more, and more complicated software than ever, yet I feel I am not growing as an engineer at all. When I started meditating on why I felt “stuck,” I realized I am starving The Thinker.&lt;/p&gt;
    &lt;p&gt;“Vibe coding” satisfies the Builder. It feels great to see to pass from idea to reality in a fraction of a time that would take otherwise. But it has drastically cut the times I need to came up with creative solutions for technical problems. I know many people who are purely Builders, for them this era is the best thing that ever happened. But for me, something is missing.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Trap of Pragmatism&lt;/head&gt;
    &lt;p&gt;I know what you might be thinking: "If you can ‘vibe code’ your way through it, the problem wasn’t actually hard."&lt;/p&gt;
    &lt;p&gt;I think that misses the point. It’s not that AI is good for hard problems, it’s not even that good for easy problems. I’m confident that my third manual rewrite of a module would be much better than anything the AI can output. But I am also a pragmatist.&lt;/p&gt;
    &lt;p&gt;If I can get a solution that is “close enough” in a fraction of the time and effort, it is irrational not to take the AI route. And that is the real problem: I cannot simply turn off my pragmatism.&lt;/p&gt;
    &lt;p&gt;At the end of the day, I am a Builder. I like building things. The faster I build, the better. Even if I wanted to reject AI and go back to the days where the Thinker's needs were met by coding, the Builder in me would struggle with the inefficiency.&lt;/p&gt;
    &lt;p&gt;Even though the AI almost certainly won't come up with a 100% satisfying solution, the 70% solution it achieves usually hits the “good enough” mark.&lt;/p&gt;
    &lt;head rend="h3"&gt;So, what now?&lt;/head&gt;
    &lt;p&gt;To be honest, I don’t know. I am still figuring it out.&lt;/p&gt;
    &lt;p&gt;I'm not sure if my two halves can be satisfied by coding anymore. You can always aim for harder projects, hoping to find problems where AI fails completely. I still encounter those occasionally, but the number of problems requiring deep creative solutions feels like it is diminishing rapidly.&lt;/p&gt;
    &lt;p&gt;I have tried to get that feeling of mental growth outside of coding. I tried getting back in touch with physics, reading old textbooks. But that wasn’t successful either. It is hard to justify spending time and mental effort solving physics problems that aren’t relevant or state-of-the-art when I know I could be building things.&lt;/p&gt;
    &lt;p&gt;My Builder side won’t let me just sit and think about unsolved problems, and my Thinker side is starving while I vibe-code. I am not sure if there will ever be a time again when both needs can be met at once.&lt;/p&gt;
    &lt;p&gt;- Philipp Mainländer&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jernesto.com/articles/thinking_hard"/><published>2026-02-04T03:54:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46882389</id><title>Show HN: Ghidra MCP Server – 110 tools for AI-assisted reverse engineering</title><updated>2026-02-04T19:31:39.797387+00:00</updated><content>&lt;doc fingerprint="a983aa63ae7fb788"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;If you find this useful, please ⭐ star the repo — it helps others discover it!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A production-ready Model Context Protocol (MCP) server that bridges Ghidra's powerful reverse engineering capabilities with modern AI tools and automation frameworks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full MCP Compatibility - Complete implementation of Model Context Protocol&lt;/item&gt;
      &lt;item&gt;110 MCP Tools Available - Comprehensive API surface for binary analysis&lt;/item&gt;
      &lt;item&gt;Production-Ready Reliability - Tested batch operations and atomic transactions&lt;/item&gt;
      &lt;item&gt;Real-time Analysis - Live integration with Ghidra's analysis engine&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Function Analysis - Decompilation, call graphs, cross-references&lt;/item&gt;
      &lt;item&gt;Data Structure Discovery - Automatic struct/union/enum creation&lt;/item&gt;
      &lt;item&gt;String Extraction - Comprehensive string analysis and categorization&lt;/item&gt;
      &lt;item&gt;Import/Export Analysis - Symbol table and library dependency mapping&lt;/item&gt;
      &lt;item&gt;Memory Mapping - Complete memory layout documentation&lt;/item&gt;
      &lt;item&gt;Cross-Binary Documentation - Function hash matching across binary versions&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated Development Cycle - Complete build-test-deploy-verify pipeline&lt;/item&gt;
      &lt;item&gt;Ghidra Script Management - Create, run, and manage Ghidra scripts via MCP&lt;/item&gt;
      &lt;item&gt;Multi-Program Support - Switch between and compare multiple open programs&lt;/item&gt;
      &lt;item&gt;Batch Operations - Efficient bulk renaming, commenting, and typing&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Java 21 LTS (OpenJDK recommended)&lt;/item&gt;
      &lt;item&gt;Apache Maven 3.9+&lt;/item&gt;
      &lt;item&gt;Ghidra 12.0.2 (or compatible version)&lt;/item&gt;
      &lt;item&gt;Python 3.8+ with pip&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Clone the repository:&lt;/p&gt;
        &lt;code&gt;git clone https://github.com/bethington/ghidra-mcp.git cd ghidra-mcp&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install Python dependencies:&lt;/p&gt;
        &lt;quote&gt;pip install -r requirements.txt&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Copy Ghidra libraries (see Library Dependencies for full list):&lt;/p&gt;
        &lt;quote&gt;# Windows - run the provided batch script copy-ghidra-libs.bat "C:\path\to\ghidra_12.0.2_PUBLIC" # Linux/Mac - copy manually from your Ghidra installation # See Library Dependencies section below for all 14 required JARs&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Build the plugin:&lt;/p&gt;
        &lt;quote&gt;mvn clean package assembly:single -DskipTests&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deploy to Ghidra:&lt;/p&gt;
        &lt;quote&gt;# Windows (automated) .\deploy-to-ghidra.ps1 # Or manually copy to Ghidra Extensions Copy-Item target\GhidraMCP-2.0.0.zip "C:\ghidra\Extensions\Ghidra\"&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;python bridge_mcp_ghidra.py&lt;/code&gt;
    &lt;code&gt;python bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start Ghidra and load a binary&lt;/item&gt;
      &lt;item&gt;Go to Tools &amp;gt; GhidraMCP &amp;gt; Start MCP Server&lt;/item&gt;
      &lt;item&gt;The server runs on &lt;code&gt;http://127.0.0.1:8080/&lt;/code&gt;by default&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MCP Tools: 110 tools fully implemented&lt;/item&gt;
      &lt;item&gt;Speed: Sub-second response for most operations&lt;/item&gt;
      &lt;item&gt;Efficiency: 93% reduction in API calls via batch operations&lt;/item&gt;
      &lt;item&gt;Reliability: Atomic transactions with all-or-nothing semantics&lt;/item&gt;
      &lt;item&gt;Deployment: Automated version-aware deployment script&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;check_connection&lt;/code&gt;- Verify MCP connectivity&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_metadata&lt;/code&gt;- Program metadata and info&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_version&lt;/code&gt;- Server version information&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_entry_points&lt;/code&gt;- Binary entry points discovery&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_functions&lt;/code&gt;- List all functions (paginated)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_functions_by_name&lt;/code&gt;- Search functions by name/pattern&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_functions_enhanced&lt;/code&gt;- Advanced function search with filters&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;decompile_function&lt;/code&gt;- Decompile function to C pseudocode&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_decompiled_code&lt;/code&gt;- Get decompiled code by address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_callers&lt;/code&gt;- Get function callers&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_callees&lt;/code&gt;- Get function callees&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_call_graph&lt;/code&gt;- Function relationship graph&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_full_call_graph&lt;/code&gt;- Complete call graph for program&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_function_complete&lt;/code&gt;- Comprehensive function analysis&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_function_completeness&lt;/code&gt;- Documentation completeness score&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_segments&lt;/code&gt;- Memory segments and layout&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_by_address&lt;/code&gt;- Function at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;disassemble_function&lt;/code&gt;- Disassembly listing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;disassemble_bytes&lt;/code&gt;- Raw byte disassembly&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_xrefs_to&lt;/code&gt;- Cross-references to address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_xrefs_from&lt;/code&gt;- Cross-references from address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_bulk_xrefs&lt;/code&gt;- Bulk cross-reference lookup&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_data_region&lt;/code&gt;- Analyze memory region structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;inspect_memory_content&lt;/code&gt;- View raw memory content&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;detect_array_bounds&lt;/code&gt;- Detect array boundaries&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;get_function_hash&lt;/code&gt;- SHA-256 hash of normalized function opcodes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_bulk_function_hashes&lt;/code&gt;- Paginated bulk hashing with filter&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_documentation&lt;/code&gt;- Export complete function documentation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;apply_function_documentation&lt;/code&gt;- Import documentation to target function&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;build_function_hash_index&lt;/code&gt;- Build persistent JSON index&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lookup_function_by_hash&lt;/code&gt;- Find matching functions in index&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;propagate_documentation&lt;/code&gt;- Apply docs to all matching instances&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_data_types&lt;/code&gt;- Available data types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_data_types&lt;/code&gt;- Search for data types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_struct&lt;/code&gt;- Create custom structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;add_struct_field&lt;/code&gt;- Add field to structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;modify_struct_field&lt;/code&gt;- Modify existing field&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;remove_struct_field&lt;/code&gt;- Remove field from structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_enum&lt;/code&gt;- Create enumeration&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_enum_values&lt;/code&gt;- Get enumeration values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_array_type&lt;/code&gt;- Create array data type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;apply_data_type&lt;/code&gt;- Apply type to address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delete_data_type&lt;/code&gt;- Delete a data type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;consolidate_duplicate_types&lt;/code&gt;- Merge duplicate types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_valid_data_types&lt;/code&gt;- Get list of valid Ghidra types&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_imports&lt;/code&gt;- Imported symbols and libraries&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_exports&lt;/code&gt;- Exported symbols and functions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_external_locations&lt;/code&gt;- External location references&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_strings&lt;/code&gt;- Extracted strings with analysis&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_namespaces&lt;/code&gt;- Available namespaces&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_globals&lt;/code&gt;- Global variables&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_label&lt;/code&gt;- Create label at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_create_labels&lt;/code&gt;- Bulk label creation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delete_label&lt;/code&gt;- Delete label at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_delete_labels&lt;/code&gt;- Bulk label deletion&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_label&lt;/code&gt;- Rename existing label&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_or_label&lt;/code&gt;- Rename or create label&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;rename_function&lt;/code&gt;- Rename function by name&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_function_by_address&lt;/code&gt;- Rename function by address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_data&lt;/code&gt;- Rename data item&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_variables&lt;/code&gt;- Rename function variables&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_global_variable&lt;/code&gt;- Rename global variable&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_external_location&lt;/code&gt;- Rename external reference&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_rename_function_components&lt;/code&gt;- Bulk renaming&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_decompiler_comment&lt;/code&gt;- Set decompiler comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_disassembly_comment&lt;/code&gt;- Set disassembly comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_plate_comment&lt;/code&gt;- Set function plate comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_plate_comment&lt;/code&gt;- Get function plate comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_set_comments&lt;/code&gt;- Bulk comment setting&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;set_function_prototype&lt;/code&gt;- Set function signature&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_local_variable_type&lt;/code&gt;- Set variable type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_parameter_type&lt;/code&gt;- Set parameter type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_set_variable_types&lt;/code&gt;- Bulk type setting&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_variable_storage&lt;/code&gt;- Control variable storage location&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_function_no_return&lt;/code&gt;- Mark function as non-returning&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_calling_conventions&lt;/code&gt;- Available calling conventions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_variables&lt;/code&gt;- Get all function variables&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_labels&lt;/code&gt;- Get labels in function&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_scripts&lt;/code&gt;- List available scripts&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;run_script&lt;/code&gt;- Run a script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_ghidra_scripts&lt;/code&gt;- List custom Ghidra scripts&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;save_ghidra_script&lt;/code&gt;- Save new script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_ghidra_script&lt;/code&gt;- Get script contents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;run_ghidra_script&lt;/code&gt;- Execute Ghidra script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;update_ghidra_script&lt;/code&gt;- Update existing script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delete_ghidra_script&lt;/code&gt;- Delete script&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_open_programs&lt;/code&gt;- List all open programs&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_current_program_info&lt;/code&gt;- Current program details&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;switch_program&lt;/code&gt;- Switch active program&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_project_files&lt;/code&gt;- List project files&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;open_program&lt;/code&gt;- Open program from project&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;compare_programs_documentation&lt;/code&gt;- Compare documentation between programs&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;find_next_undefined_function&lt;/code&gt;- Find undefined functions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;find_undocumented_by_string&lt;/code&gt;- Find functions by string reference&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_string_anchor_report&lt;/code&gt;- String anchor analysis&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_byte_patterns&lt;/code&gt;- Search for byte patterns&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_assembly_context&lt;/code&gt;- Get assembly context&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_struct_field_usage&lt;/code&gt;- Analyze structure field access&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_field_access_context&lt;/code&gt;- Get field access patterns&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_function&lt;/code&gt;- Create function at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_jump_target_addresses&lt;/code&gt;- Get jump targets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See docs/README.md for complete documentation.&lt;/p&gt;
    &lt;code&gt;┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   AI/Automation │◄──►│   MCP Bridge    │◄──►│  Ghidra Plugin  │
│     Tools       │    │ (bridge_mcp_    │    │ (GhidraMCP.jar) │
│  (Claude, etc.) │    │  ghidra.py)     │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
   MCP Protocol            HTTP REST              Ghidra API
   (stdio/SSE)          (localhost:8080)      (Program, Listing)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;bridge_mcp_ghidra.py - Python MCP server that translates MCP protocol to HTTP calls&lt;/item&gt;
      &lt;item&gt;GhidraMCP.jar - Ghidra plugin that exposes analysis capabilities via HTTP&lt;/item&gt;
      &lt;item&gt;ghidra_scripts/ - Collection of 70+ automation scripts for common tasks&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Build the plugin (skip integration tests)
mvn clean package assembly:single -DskipTests

# Deploy to Ghidra
.\deploy-to-ghidra.ps1&lt;/code&gt;
    &lt;code&gt;ghidra-mcp/
├── bridge_mcp_ghidra.py     # MCP server (Python)
├── src/main/java/           # Ghidra plugin (Java)
├── lib/                     # Ghidra library dependencies
├── ghidra_scripts/          # 70+ automation scripts
├── docs/                    # Documentation
│   ├── prompts/            # AI workflow prompts
│   ├── releases/           # Version release notes
│   └── project-management/ # Project docs
├── examples/                # Example usage
└── scripts/                 # Build/utility scripts
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;lib/&lt;/code&gt; folder must contain Ghidra JAR files for compilation. Run the provided script to copy them from your Ghidra installation:&lt;/p&gt;
    &lt;code&gt;# Windows
copy-ghidra-libs.bat "C:\path\to\ghidra_12.0.2_PUBLIC"

# Or manually copy from your Ghidra installation&lt;/code&gt;
    &lt;p&gt;Required Libraries (14 JARs, ~37MB):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Library&lt;/cell&gt;
        &lt;cell role="head"&gt;Source Path&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Base.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/Base/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Core Ghidra functionality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Decompiler.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/Decompiler/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Decompilation engine&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PDB.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/PDB/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Microsoft PDB symbol support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FunctionID.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/FunctionID/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Function identification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SoftwareModeling.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/SoftwareModeling/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Program model API&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Project.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Project/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Project management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Docking.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Docking/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;UI docking framework&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Generic.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Generic/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Generic utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Utility.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Utility/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Core utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Gui.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Gui/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GUI components&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FileSystem.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/FileSystem/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;File system support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Graph.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Graph/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Graph/call graph analysis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DB.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/DB/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Database operations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Emulation.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Emulation/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;P-code emulation&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;&lt;p&gt;Note: Libraries are NOT included in the repository (see&lt;/p&gt;&lt;code&gt;.gitignore&lt;/code&gt;). You must copy them from your Ghidra installation before building.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated Deployment: Version-aware deployment script&lt;/item&gt;
      &lt;item&gt;Batch Operations: Reduces API calls by 93%&lt;/item&gt;
      &lt;item&gt;Atomic Transactions: All-or-nothing semantics&lt;/item&gt;
      &lt;item&gt;Comprehensive Logging: Debug and trace capabilities&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation Index - Complete documentation navigation&lt;/item&gt;
      &lt;item&gt;Project Structure - Project organization guide&lt;/item&gt;
      &lt;item&gt;Naming Conventions - Code naming standards&lt;/item&gt;
      &lt;item&gt;Hungarian Notation - Variable naming guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompts Overview - AI prompting system guide&lt;/item&gt;
      &lt;item&gt;Function Documentation Workflow - Complete workflow&lt;/item&gt;
      &lt;item&gt;Quick Start Prompt - Simplified beginner workflow&lt;/item&gt;
      &lt;item&gt;Cross-Version Matching - Hash-based matching&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complete Changelog - All version release notes&lt;/item&gt;
      &lt;item&gt;Release Notes - Detailed release documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See CONTRIBUTING.md for detailed contribution guidelines.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch (&lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Build and test your changes (&lt;code&gt;mvn clean package assembly:single -DskipTests&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Update documentation as needed&lt;/item&gt;
      &lt;item&gt;Commit your changes (&lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Push to the branch (&lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Open a Pull Request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Version&lt;/cell&gt;
        &lt;cell&gt;2.0.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MCP Tools&lt;/cell&gt;
        &lt;cell&gt;110 fully implemented&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Compilation&lt;/cell&gt;
        &lt;cell&gt;✅ 100% success&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Batch Efficiency&lt;/cell&gt;
        &lt;cell&gt;93% API call reduction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Ghidra Scripts&lt;/cell&gt;
        &lt;cell&gt;70+ automation scripts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Documentation&lt;/cell&gt;
        &lt;cell&gt;Comprehensive with AI prompts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See CHANGELOG.md for version history and release notes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ghidra Team - For the incredible reverse engineering platform&lt;/item&gt;
      &lt;item&gt;Model Context Protocol - For the standardized AI integration framework&lt;/item&gt;
      &lt;item&gt;Contributors - For testing, feedback, and improvements&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;re-universe — Ghidra BSim PostgreSQL platform for large-scale binary similarity analysis. Pairs perfectly with GhidraMCP for AI-driven reverse engineering workflows.&lt;/item&gt;
      &lt;item&gt;cheat-engine-server-python — MCP server for dynamic memory analysis and debugging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ready for production deployment with enterprise-grade reliability and comprehensive binary analysis capabilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/bethington/ghidra-mcp"/><published>2026-02-04T06:51:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46884883</id><title>Claude Is a Space to Think</title><updated>2026-02-04T19:31:39.150604+00:00</updated><content>&lt;doc fingerprint="7f9d1bf1ad37cb6b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Claude is a space to think&lt;/head&gt;
    &lt;p&gt;There are many good places for advertising. A conversation with Claude is not one of them.&lt;/p&gt;
    &lt;p&gt;Advertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We’ve run our own ad campaigns, and our AI models have, in turn, helped many of our customers in the advertising industry.&lt;/p&gt;
    &lt;p&gt;But including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.&lt;/p&gt;
    &lt;p&gt;We want Claude to act unambiguously in our users’ interests. So we’ve made a choice: Claude will remain ad-free. Our users won’t see “sponsored” links adjacent to their conversations with Claude; nor will Claude’s responses be influenced by advertisers or include third-party product placements our users did not ask for.&lt;/p&gt;
    &lt;head rend="h2"&gt;The nature of AI conversations&lt;/head&gt;
    &lt;p&gt;When people use search engines or social media, they’ve come to expect a mixture of organic and sponsored content. Filtering signal from noise is part of the interaction.&lt;/p&gt;
    &lt;p&gt;Conversations with AI assistants are meaningfully different. The format is open-ended; users often share context and reveal more than they would in a search query. This openness is part of what makes conversations with AI valuable, but it’s also what makes them susceptible to influence in ways that other digital products are not.&lt;/p&gt;
    &lt;p&gt;Our analysis of conversations with Claude (conducted in a way that keeps all data private and anonymous) shows that an appreciable portion involve topics that are sensitive or deeply personal—the kinds of conversations you might have with a trusted advisor. Many other uses involve complex software engineering tasks, deep work, or thinking through difficult problems. The appearance of ads in these contexts would feel incongruous—and, in many cases, inappropriate.&lt;/p&gt;
    &lt;p&gt;We still have much to learn about the impact of AI models on the people who use them. Early research suggests both benefits—like people finding support they couldn’t access elsewhere—and risks, including the potential for models to reinforce harmful beliefs in vulnerable users. Introducing advertising incentives at this stage would add another level of complexity. Our understanding of how models translate the goals we set them into specific behaviors is still developing; an ad-based system could therefore have unpredictable results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Incentive structures&lt;/head&gt;
    &lt;p&gt;Being genuinely helpful is one of the core principles of Claude’s Constitution, the document that describes our vision for Claude’s character and guides how we train the model. An advertising-based business model would introduce incentives that could work against this principle.&lt;/p&gt;
    &lt;p&gt;Consider a concrete example. A user mentions they’re having trouble sleeping. An assistant without advertising incentives would explore the various potential causes—stress, environment, habits, and so on—based on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction. These objectives may often align—but not always. And, unlike a list of search results, ads that influence a model’s responses may make it difficult to tell whether a given recommendation comes with a commercial motive or not. Users shouldn’t have to second-guess whether an AI is genuinely helping them or subtly steering the conversation towards something monetizable.&lt;/p&gt;
    &lt;p&gt;Even ads that don’t directly influence an AI model’s responses and instead appear separately within the chat window would compromise what we want Claude to be: a clear space to think and work. Such ads would also introduce an incentive to optimize for engagement—for the amount of time people spend using Claude and how often they return. These metrics aren’t necessarily aligned with being genuinely helpful. The most useful AI interaction might be a short one, or one that resolves the user’s request without prompting further conversation.&lt;/p&gt;
    &lt;p&gt;We recognize that not all advertising implementations are equivalent. More transparent or opt-in approaches—where users explicitly choose to see sponsored content—might avoid some of the concerns outlined above. But the history of ad-supported products suggests that advertising incentives, once introduced, tend to expand over time as they become integrated into revenue targets and product development, blurring boundaries that were once more clear-cut. We’ve chosen not to introduce these dynamics into Claude.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our approach&lt;/head&gt;
    &lt;p&gt;Anthropic is focused on businesses, developers, and helping our users flourish. Our business model is straightforward: we generate revenue through enterprise contracts and paid subscriptions, and we reinvest that revenue into improving Claude for our users. This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.&lt;/p&gt;
    &lt;p&gt;Expanding access to Claude is central to our public benefit mission, and we want to do it without selling our users’ attention or data to advertisers. To that end, we’ve brought AI tools and training to educators in over 60 countries, begun national AI education pilots with multiple governments, and made Claude available to nonprofits at a significant discount. We continue to invest in our smaller models so that our free offering remains at the frontier of intelligence, and we may consider lower-cost subscription tiers and regional pricing where there is clear demand for it. Should we need to revisit this approach, we’ll be transparent about our reasons for doing so.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supporting commerce&lt;/head&gt;
    &lt;p&gt;AI will increasingly interact with commerce, and we look forward to supporting this in ways that help our users. We’re particularly interested in the potential of agentic commerce, where Claude acts on a user’s behalf to handle a purchase or booking end to end. And we’ll continue to build features that enable our users to find, compare, or buy products, connect with businesses, and more—when they choose to do so.&lt;/p&gt;
    &lt;p&gt;We’re also exploring more ways to make Claude a focused space to be at your most productive. Users can already connect third-party tools they use for work—like Figma, Asana, and Canva—and interact with them directly within Claude. We expect to introduce many more useful integrations and expand this toolkit over time.&lt;/p&gt;
    &lt;p&gt;All third-party interactions will be grounded in the same overarching design principle: they should be initiated by the user (where the AI is working for them) rather than an advertiser (where the AI is working, at least in part, for someone else). Today, whether someone asks Claude to research running shoes, compare mortgage rates, or recommend a restaurant for a special occasion, Claude’s only incentive is to give a helpful answer. We’d like to preserve that.&lt;/p&gt;
    &lt;head rend="h2"&gt;A trusted tool for thought&lt;/head&gt;
    &lt;p&gt;We want our users to trust Claude to help them keep thinking—about their work, their challenges, and their ideas.&lt;/p&gt;
    &lt;p&gt;Our experience of using the internet has made it easy to assume that advertising on the products we use is inevitable. But open a notebook, pick up a well-crafted tool, or stand in front of a clean chalkboard, and there are no ads in sight.&lt;/p&gt;
    &lt;p&gt;We think Claude should work the same way.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/news/claude-is-a-space-to-think"/><published>2026-02-04T12:08:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886191</id><title>Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025</title><updated>2026-02-04T19:31:38.975469+00:00</updated><content>&lt;doc fingerprint="e3e534e737e1921a"&gt;
  &lt;main&gt;
    &lt;p&gt;A debilitating infection from the parasitic Guinea worm is inching closer to global eradication, with an all-time low of only 10 human cases reported worldwide in 2025, the Carter Center announced.&lt;/p&gt;
    &lt;p&gt;If health workers can fully wipe out the worms, it will be only the second human disease to be eradicated, after smallpox.&lt;/p&gt;
    &lt;p&gt;Guinea worm (Dracunculus medinensis) is a parasitic nematode transmitted in water. More specifically, it’s found in waters that contain small crustacean copepods, which harbor the worm’s larvae. If a person consumes water contaminated with Guinea worm, the parasites burrow through the intestinal tract and migrate through the body. About a year later, a spaghetti noodle-length worm emerges from a painful blister, usually in the feet or legs. It can take up to eight weeks for the adult worm to fully emerge. To ease the searing pain, infected people may put their blistered limbs in water, allowing the parasite to release more larvae and continue the cycle.&lt;/p&gt;
    &lt;p&gt;In addition to being extremely painful, the disease (dracunculiasis) can lead to complications, such as secondary infections and sepsis, which in turn can lead to temporary or permanent disability.&lt;/p&gt;
    &lt;p&gt;When the Guinea worm eradication program began in 1986, there were an estimated 3.5 million cases across 21 countries in Africa and Asia. To date, only six countries have not been certified by the World Health Organization as Guinea worm-free. In 2024, there were just 15 cases, and, according to the provisional tally for 2025, the number is down to just 10. It’s considered provisional until each country’s disease reports are confirmed, which occurs in a program meeting usually held in April.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/"/><published>2026-02-04T14:27:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886237</id><title>FBI couldn't get into WaPo reporter's iPhone because Lockdown Mode enabled</title><updated>2026-02-04T19:31:38.865499+00:00</updated><content>&lt;doc fingerprint="a62918135f4332cd"&gt;
  &lt;main&gt;&lt;p&gt;The FBI has been unable to access a Washington Post reporter’s seized iPhone because it was in Lockdown Mode, a sometimes overlooked feature that makes iPhones broadly more secure, according to recently filed court records.&lt;/p&gt;&lt;p&gt;The court record shows what devices and data the FBI was able to ultimately access, and which devices it could not, after raiding the home of the reporter, Hannah Natanson, in January as part of an investigation into leaks of classified information. It also provides rare insight into the apparent effectiveness of Lockdown Mode, or at least how effective it might be before the FBI may try other techniques to access the device.&lt;/p&gt;&lt;p&gt;💡&lt;/p&gt;&lt;p&gt;Do you know anything else about phone unlocking technology? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.&lt;/p&gt;&lt;head rend="h2"&gt;This post is for paid members only&lt;/head&gt;&lt;p&gt;Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.&lt;/p&gt; Subscribe &lt;head rend="h2"&gt;Sign up for free access to this post&lt;/head&gt;&lt;p&gt;Free members get access to posts like this one along with an email round-up of our week's stories.&lt;/p&gt; Subscribe &lt;p&gt;Already have an account? Sign in&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/"/><published>2026-02-04T14:31:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886265</id><title>Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation</title><updated>2026-02-04T19:31:38.655895+00:00</updated><content>&lt;doc fingerprint="cc1c241ad7f7d6ef"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 30 Jan 2026]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2602.00294"/><published>2026-02-04T14:33:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886440</id><title>A case study in PDF forensics: The Epstein PDFs</title><updated>2026-02-04T19:31:38.148252+00:00</updated><content>&lt;doc fingerprint="f057ca0214f70b80"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A case study in PDF forensics: The Epstein PDFs&lt;/head&gt;
    &lt;p&gt;December 22, 2025&lt;/p&gt;
    &lt;p&gt;December 22, 2025&lt;/p&gt;
    &lt;p&gt;About Peter Wyatt, PDF Association&lt;/p&gt;
    &lt;p&gt;The recent release of a tranche of files by the US Department of Justice (DoJ) under the “Epstein Files Transparency Act (H.R.4405)” has once again prompted many people to closely examine redacted and sanitized PDF documents. Our previous articles on the Manafort papers and the Mueller report, as well as a study by Adhatarao, S. and Lauradoux, C. (2021) “Exploitation and Sanitization of Hidden Data in PDF Files: Do Security Agencies Sanitize Their PDF files?,” in Proceedings of the 2021 ACM Workshop on Information Hiding and Multimedia Security, illustrate the importance of robust sanitization and redaction workflows when handling sensitive documents prior to release.&lt;/p&gt;
    &lt;p&gt;This article examines a small random selection of the Epstein PDF files from a purely digital forensic perspective, focusing on the PDF syntax and idioms they contain, any malformations or unusual constructs, and other technical aspects.&lt;/p&gt;
    &lt;p&gt;PDFs are more challenging to analyze than many other formats because they are binary files that require specialized knowledge, expertise, and software. Please note that we did not analyze the contents of the PDF documents. Not every PDF was examined. Any mention of products (or appearance in screen-shots) does not imply any endorsement or support of any information, products, or providers whatsoever. We are not lawyers; this article does not constitute legal advice&lt;/p&gt;
    &lt;p&gt;We offer this information, in part, as some of the Epstein PDFs released by DoJ are beginning to appear on malware analysis sites (such as Hybrid-Analysis) with various kinds of incorrect analysis and misinformation.&lt;/p&gt;
    &lt;head rend="h2"&gt;26 December 2025 update&lt;/head&gt;
    &lt;p&gt;After we'd completed our analysis the DoJ released a new dataset, DataSet 8.zip. This new ZIP file is 9.95 GB compressed and contains over 11,000 files, including 10,593 new PDFs totaling 1.8 GB and 29,343 pages (the longest document has 1,060 pages). DataSet 8 also contains many large MP4 movies, Excel spreadsheets, and various other files. The first PDF in the set of 10,593 PDFs is VOL00008\IMAGES\0001\EFTA00009676.pdf, and the last file is VOL00008\IMAGES\0011\EFTA00039023.pdf. A cursory analysis shows pdfinfo properties similar to those from the earlier datasets, but we have not otherwise analyzed this new dataset.&lt;/p&gt;
    &lt;p&gt;Since our original post, various social media and news platforms have also been announcing “recoverable redactions” from the “Epstein Files”. We stand by our analysis; DoJ has correctly redacted the EFTA PDFs in Datasets 01-07, and they do not contain recoverable text as alleged. As our article states, we did not analyze any other DoJ or Epstein-related documents.&lt;/p&gt;
    &lt;p&gt;For example, the featured image in this Guardian news article (which was also picked up by the New York Times) corresponds to VOL00004\IMAGES\0001EFTA00005855.pdf, as can be easily determined by searching for the Bates Numbers in the EFTA “.OPT” data files. The information in this EFTA PDF is fully and correctly redacted; there is no hidden information. The only extractable text is some garbled text from the poor-quality OCR and, as expected, the Bates Numbers on each page.&lt;/p&gt;
    &lt;p&gt;In the few reports we investigated (including from Forbes and Ed Krassenstein on both X (formerly Twitter) and Instagram), these stories misrepresent other DoJ files that were not part of the major DataSets 01-07 release on December 19 under the EFTA. All PDFs released under EFTA have a Bates Number on every page starting "EFTA". These include “Case 1:22-cv-10904-JSR Document 1-1, Exhibit 1 to Government’s Complaint against JPMorgan Chase Bank, N.A.” (see page 41) and “Case No: ST-20-CV-14 Government Exhibit 1” (see page 19). These PDFs, previously released by the DoJ, do contain incorrect and ineffective redactions, with black boxes that simply obscure text, making “copy &amp;amp; paste” easy to recover the text that's otherwise hidden. Clearly, DoJ processes and systems in the past have inadequately redacted information!&lt;/p&gt;
    &lt;head rend="h2"&gt;The files we examined&lt;/head&gt;
    &lt;p&gt;The tranche released by DoJ on Friday, December 19 is available as seven “data sets”, most easily downloaded as seven ZIP archives totaling just under 2.97 GB. Each ZIP file contains a similar folder structure, with DataSet 6 being the odd one out with an extra top-level folder. Once unzipped, the total size is 2.99 GB. The tranche contains 4,085 PDF files, a single AVI (movie) file (located in the folder VOL00002\NATIVES\0001), and 2 data files (.DAT and .OPT) for each ZIP archive. The “.OPT” files appear to be CSV (Comma-Separated Values) but lack a heading row, while the “.DAT” files contain information about the Bates numbering. The analysis we provide here is limited to the PDF files.&lt;/p&gt;
    &lt;p&gt;The PDF files are named and ordered sequentially within the folder structure, starting with “EFTA00000001.pdf” in VOL00001 and ending with “EFTA00009664.pdf” in VOL00007, indicating that at least 5,879 PDF files remain unreleased.&lt;/p&gt;
    &lt;p&gt;A random sampling of the PDFs for visual review suggests that they are a mix of single and multi-page full-page photos and scanned content. OCR (Optical Character Recognition) was used to provide some searchable and extractable text in at least some files. “Black box” style redactions (without text reasons) are apparent. When done correctly, this is the appropriate way to redact, far more robust than pixelating text. The PDFs we sampled did not include any obviously “born digital” documents. Various news sites are reporting very heavily redacted documents within this tranche.&lt;/p&gt;
    &lt;head rend="h2"&gt;File validity&lt;/head&gt;
    &lt;p&gt;A precursor to most forensic examinations is to establish whether the PDF files are technically valid (that is, conform to the rules of the PDF format), since analyzing malformed files can easily lead to incorrect results or wrong conclusions. Combining tools that use different methods provides the broadest possible information while ensuring that tooling limitations are fully understood. However, if the basic file structure or cross-reference information is incorrect, various software might then draw different conclusions and/or construct different Document Object Models (DOMs).&lt;/p&gt;
    &lt;p&gt;In addition to basic file structure, incremental updates (if any), and cross-reference information, PDF validity assessments include the objects that comprise the PDF’sDOM as well as the file structure, incremental updates, and cross-reference information. To assess relationships between objects in the PDF DOM, some forensic analysis tools leverage our Arlington PDF Data Model, while others use their own internal methods.&lt;/p&gt;
    &lt;p&gt;Our analysis of file validity, using a multitude of PDF forensic tools, identified only one minor defect (invalidity); 109 PDFs had a positive FontDescriptor Descent value rather than a negative one. This is a relatively common (but minor) error, typically associated with font substitution and font matching, that does not affect the validity of the files overall. One specific forensic tool reported a PDF version issue with some files, related to the document catalog Version entry, which prevented the tool from further verifying those specific PDFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;PDF versions&lt;/head&gt;
    &lt;p&gt;I’ve previously written about the unreliability of PDF version numbers. Still, for forensic purposes, they may provide insight into the DoJ’s software, and whether improved software could have performed better.&lt;/p&gt;
    &lt;p&gt;I used two different but commonly used PDF command-line &lt;code&gt;pdfinfo&lt;/code&gt; utilities on different platforms (Windows and Ubuntu Linux) to summarize information about these PDF files. When run against the full tranche of PDFs, I got two very different sets of answers! Immediately, my spidey senses started to tingle, and I was once again reminded of a key lesson in digital document forensics – you should never trust a single tool!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Reported PDF Version&lt;/cell&gt;
        &lt;cell&gt;Count Tool A&lt;/cell&gt;
        &lt;cell&gt;Count Tool B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1.3&lt;/cell&gt;
        &lt;cell&gt;209&lt;/cell&gt;
        &lt;cell&gt;3,817&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1.4&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1.5&lt;/cell&gt;
        &lt;cell&gt;3,875&lt;/cell&gt;
        &lt;cell&gt;267&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;TOTAL (should be 4,085)&lt;/cell&gt;
        &lt;cell&gt;4,085&lt;/cell&gt;
        &lt;cell&gt;4,085&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The PDF version in the file header, “&lt;code&gt;%PDF-x.y&lt;/code&gt;”, is nominally the first line in every PDF file (based on the not-unreasonable assumption that the PDF files have no “junk bytes” before this PDF file identifier). Using the Linux command line, you can run in Linux “&lt;code&gt;head -n 1 file.pdf&lt;/code&gt;” to extract the first header line from each PDF and compare it with the reported results from each tool. Or run in Linux “&lt;code&gt;grep -P --text --byte-offset "%PDF-\d\.\d" *.pdf&lt;/code&gt;” to confirm that there are no junk bytes prior to the PDF header line.&lt;/p&gt;
    &lt;p&gt;The reason for the difference reported in the table above is that Tool B is not accounting for the Version entry in the document catalog of PDFs with incremental updates. We’ll next investigate whether this is due to malformed files or a programming error. When properly accounting for incremental updates, however, Tool A is correct.&lt;/p&gt;
    &lt;p&gt;Using the same &lt;code&gt;pdfinfo&lt;/code&gt; output (and again comparing results from both tools), we can also quickly establish the following facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No PDF is tagged&lt;/item&gt;
      &lt;item&gt;No PDF is encrypted&lt;/item&gt;
      &lt;item&gt;No PDF is “optimized” (technically, Linearized PDF)&lt;/item&gt;
      &lt;item&gt;No PDF has any annotations&lt;/item&gt;
      &lt;item&gt;No PDF has any outlines (bookmarks)&lt;/item&gt;
      &lt;item&gt;No PDF contains any embedded files&lt;/item&gt;
      &lt;item&gt;None of the PDFs are forms&lt;/item&gt;
      &lt;item&gt;None of the PDFs contains JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Page counts range from 1 (in 3,818 PDFs) to 119 pages (in two PDFs), totaling 9,659 pages across all 4,085 PDFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Incremental updates&lt;/head&gt;
    &lt;p&gt;PDF’s incremental updates feature allows multiple revisions of a document to be stored in a PDF file. As the name implies, each set of deltas is appended to the original document, forming a chain of edits. When read by conforming PDF software, a PDF is always processed from the end of the file, effectively applying the deltas to the original document and to any previous incremental updates. Both the original document and each incremental update can be recognized by their respective “&lt;code&gt;xref&lt;/code&gt;” and “&lt;code&gt;%%EOF&lt;/code&gt;” markers (assuming that the PDF files are structured correctly).&lt;/p&gt;
    &lt;p&gt;For this investigation, we started by examining the very first PDF in the tranche: VOL00001\IMAGES\0001\EFTA00000001.pdf. This PDF had different PDF versions reported by different versions of &lt;code&gt;pdfinfo&lt;/code&gt;. A simple trick to check if a PDF contains incremental updates is to search for these special markers while treating the PDF as a text file (which it isn’t!):&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;$ grep -P --text -–byte-offset "(xref)|(%%EOF)" EFTA00000001.pdf&lt;/code&gt;&lt;code&gt;371340:xref&lt;/code&gt;&lt;lb/&gt; 371758:startxref&lt;lb/&gt; 371775:%%EOF&lt;lb/&gt; 372977:startxref&lt;lb/&gt; 372994:%%EOF&lt;lb/&gt; 373961:startxref&lt;lb/&gt; 373978:%%EOF&lt;/p&gt;
    &lt;p&gt;These results (sorted by byte offset) indicate that EFTA00000001.pdf contains two incremental updates after the original file. The lack of an “&lt;code&gt;xref&lt;/code&gt;” marker before the last two “&lt;code&gt;startxref&lt;/code&gt;” markers indicate that neither incremental updates uses conventional cross-reference data, but may use cross-reference streams (if any objects are changed).&lt;/p&gt;
    &lt;head rend="h2"&gt;Bates numbering&lt;/head&gt;
    &lt;p&gt;As referenced above, Bates numbering is the process by which every page is assigned a unique identifier. For this tranche of Epstein PDF files, Bates numbers were added to each page via a separate incremental update, as shown below in Visual Studio Code with my pdf-cos-syntax extension. Note that DoJ’s PDFs are primarily text-based internally, making forensic analysis a lot easier - and the files a lot bigger.&lt;/p&gt;
    &lt;p&gt;Observations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Line 2984 is the end-of-file marker for the file version, and line 2985 starts a new incremental update section.&lt;/item&gt;
      &lt;item&gt;Lines 2985-2987 define object 26, the unembedded Helvetica font resource used by the Bates number.&lt;/item&gt;
      &lt;item&gt;Lines 2997-3020 are the modified page object (object 3), replacing the page object in previous revisions of the file.&lt;/item&gt;
      &lt;item&gt;Line 2999 is the page Contents array, comprising five separate content streams, with the 3rd stream (object 29) being the Bates numbering added in this incremental update. Object 30 is an empty content stream that could have been removed by an optimization process.&lt;/item&gt;
      &lt;item&gt;Line 3034 sets the Helvetica font to 12 point.&lt;/item&gt;
      &lt;item&gt;Line 3037 uses a hexadecimal string to paint the Bates number onto the page.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The idiom for this final incremental update, which adds the Bates number to every page, appears in all the PDF files we selected at random for investigation. This specific incremental update always uses a cross-reference stream (&lt;code&gt;/Type /XRef&lt;/code&gt;) and relies on the previous incremental update, in which the document catalog Version entry is set to PDF 1.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;The first incremental update&lt;/head&gt;
    &lt;p&gt;The VSCode pdf-cos-syntax extension also indicates (correctly!) that the original PDF is missing the required (when the PDF contains binary data, which most do) comment as the second line of the file that indicates to software that the PDF file needs to be treated as binary data (ISO 32000-2:2020, §7.5.2). Although the missing comment does not make the PDF invalid per se, without such a marker close to the top of each PDF, software may think the PDF is a text file, and thus potentially corrupt the PDF by changing line endings, which would break the byte offsets in the cross-reference data. In this PDF, the first incremental update adds this marker comment after a lot of binary data, which is pointless.&lt;/p&gt;
    &lt;p&gt;As mentioned above, the first incremental update changed the document catalog Version entry to PDF 1.5, as we see in this next screenshot:&lt;/p&gt;
    &lt;p&gt;Observations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lines 2953-2984 are the incremental update section.&lt;/item&gt;
      &lt;item&gt;Line 2954 is a PDF comment. PDF comments always start with a PERCENT SIGN (&lt;code&gt;%&lt;/code&gt;) and may occur in many places in PDF files. Effective sanitization and redaction workflows typically remove all comments from PDFs because they may inadvertently disclose information, but this exact comment appears in 3,608 other PDF files. The origin or meaning of this comment was not further investigated.&lt;/item&gt;
      &lt;item&gt;Line 2964 upgrades the PDF version to 1.5. At first glance, this may appear to be perfectly valid PDF, but it is technically incorrect because the file header is &lt;code&gt;%PDF-1.3&lt;/code&gt;yet the Version key was only added in PDF 1.4 - this is what the strict file validation tool mentioned above had noticed. As object 24 is a compressed object stream (lines 2966-2973) and object 25 is a compressed cross-reference stream (lines 2974-2981), the indicated version should be PDF 1.5. As a practical matter, however, this level of technical detail does not impact operation or behavior of PDFs.&lt;/item&gt;
      &lt;item&gt;Line 2984 is the end-of-section “&lt;code&gt;%%EOF&lt;/code&gt;” marker for this incremental update section.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As this section of the PDF uses compressed object streams, specialized PDF forensic tools must be used… simple search methodologies, such as those mentioned above, may not identify everything!&lt;/p&gt;
    &lt;p&gt;We know that there are 7 objects (because we find /&lt;code&gt;N 7&lt;/code&gt;) inside the object stream:&lt;/p&gt;
    &lt;p&gt;As per PDF’s specification, ISO 32000-2:2020, §7.5.7, the first line of integers is interpreted as N pairs, where the first integer is the object number and the second integer is the byte offset relative to the first object in the object stream.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;1st integer (object number)&lt;/cell&gt;
        &lt;cell&gt;2nd integer (start offset)&lt;/cell&gt;
        &lt;cell&gt;Explanation&lt;/cell&gt;
        &lt;cell&gt;Content&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;Type1 Font object for OPBaseFont0 (Courier)&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/BaseFont/Courier/Encoding&amp;lt;&amp;lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&amp;gt;&amp;gt;/Name/OPBaseFont0/Subtype/Type1/Type/Font&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;118&lt;/cell&gt;
        &lt;cell&gt;Type1 Font object for OPBaseFont1 (Helvetica)&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/BaseFont/Helvetica/Encoding&amp;lt;&amp;lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&amp;gt;&amp;gt;/Name/OPBaseFont1/Subtype/Type1/Type/Font&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;238&lt;/cell&gt;
        &lt;cell&gt;Document information (Info) dictionary&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/CreationDate(D:20251218143205)/Creator(OmniPage CSDK 21.1)/ModDate(D:20251218143205)/Producer(Processing-CLI)&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;352&lt;/cell&gt;
        &lt;cell&gt;ProcSet resources array&lt;/cell&gt;
        &lt;cell&gt;[/PDF/Text/ImageB/ImageC/ImageI]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;384&lt;/cell&gt;
        &lt;cell&gt;Resources dictionary for the page&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/Font&amp;lt;&amp;lt;/OPBaseFont0 19 0 R/OPBaseFont1 20 0 R&amp;gt;&amp;gt;/ProcSet 18 0 R/XObject&amp;lt;&amp;lt;/Im0 8 0 R&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;23&lt;/cell&gt;
        &lt;cell&gt;472&lt;/cell&gt;
        &lt;cell&gt;Array of 2 indirect references (to content streams)&lt;/cell&gt;
        &lt;cell&gt;[21 0 R 4 0 R]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;486&lt;/cell&gt;
        &lt;cell&gt;Updated Page object&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/Contents 23 0 R/MediaBox[0 0 864 576.75]/Parent 2 0 R/Resources 22 0 R/Thumb 11 0 R/Type/Page&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What is very interesting here – from a PDF forensics perspective – is the fact of a hidden document information dictionary that is not referenced from the last (final) incremental update trailer (i.e., there is no Info entry in object 31, lines 3050-3063 below). As such, this orphaned dictionary is invisible to PDF software! This oddity occurs in all other PDFs we’d randomly selected for investigation.&lt;/p&gt;
    &lt;p&gt;Formatted nicely as an uncompressed object, this hidden document information dictionary inside the compressed object stream contains the following information (the CreationDate and ModDate appear to change in other randomly examined PDFs):&lt;/p&gt;
    &lt;quote&gt;17 0 obj &amp;lt;&amp;lt; /CreationDate (D:20251218143205) /ModDate (D:20251218143205) /Creator (OmniPage CSDK 21.1) /Producer (Processing-CLI) &amp;gt;&amp;gt; endobj&lt;/quote&gt;
    &lt;p&gt;This metadata clearly indicates the software DoJ used to manipulate these PDF files. Although not relevant to the content, this forensic discovery clearly shows that extra care is required when sanitizing PDFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Different incremental updates&lt;/head&gt;
    &lt;p&gt;Another randomly selected PDF, VOL00003\IMAGES\0001\EFTA00003939.pdf contains 3 full-page images, and just a single incremental update that applies the Bates numbering. However, in this case the file header is &lt;code&gt;%PDF-1.5&lt;/code&gt; yet both the original PDF and incremental update use conventional cross-reference tables! This isn’t problematic, but is certainly unexpected and inefficient since PDF 1.5 introduced compressed cross-reference streams.&lt;/p&gt;
    &lt;p&gt;By comparing the objects in the incremental cross-reference table to the original cross-reference table we can see that objects 66 to 69 – the 3 Page objects for the 3 page document – were redefined. This is just what is expected in order to add the Bates number to each page’s Contents stream as in the previous example.&lt;/p&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;p&gt;Our initial examination using pdfinfo utilities did not identify any metadata in any of the PDFs in the tranche, either in the document information dictionary (PDF file trailer Info entry) or as an XMP metadata stream (Metadata entry).&lt;/p&gt;
    &lt;p&gt;However, since we know that (a) the tranche includes PDFs with incremental updates, and (b) that an orphaned document information dictionary exists, all revisions of a document should be thoroughly examined. Incremental updates may have marked other document information dictionaries or XMP metadata streams as free but not deleted the actual data.&lt;/p&gt;
    &lt;p&gt;XMP metadata is always encoded in PDF as a stream object, and since stream objects cannot be in compressed object streams, using forensic tools to search for keys “&lt;code&gt;/XML&lt;/code&gt;” or “&lt;code&gt;/Metadata&lt;/code&gt;” should always locate them. All modern office suites and PDF creation applications will generate XMP metadata when exporting to PDF. As XMP is usually uncompressed, searching for XML fragments may also be helpful (see below for an example XMP object fragment).&lt;/p&gt;
    &lt;quote&gt;3 0 obj &amp;lt;&amp;lt;/Length 36996/Subtype/XML/Type/Metadata&amp;gt;&amp;gt; stream &amp;lt;?xpacket begin="ï»¿" id="W5M0MpCe … zNTczkc9d"?&amp;gt; &amp;lt;x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk=" … "&amp;gt; &amp;lt;rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"&amp;gt; &amp;lt;rdf:Description rdf:about="" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xmp="http://ns.adobe.com/xap/1.0/" ...&lt;/quote&gt;
    &lt;p&gt;Not unsurprisingly for properly-redacted files, we did not find any XMP metadata streams or XML in any PDF. As a consequence, none of the PDFs can declare conformance to either PDF/A (ISO 19005 for long-term archiving) or PDF/UA (ISO 14289 for accessibility). Of course, as untagged PDFs, the files cannot conform to accessibility specifications such as PDF/UA or WCAG in any event. Additionally, none of the PDFs appear to include device-independent color spaces.&lt;/p&gt;
    &lt;p&gt;The presence of an Info entry in the trailer dictionary or (in PDFs with cross-reference streams) in the cross-reference stream dictionary indicates the presence of document information dictionaries. “&lt;code&gt;/Info&lt;/code&gt;” does indeed occur in many of the PDFs, including multiple times in some PDFs, indicating potential changes via incremental updates. However, as discovered above, in some cases the final incremental update does not include an Info entry, thus “orphaning” any existing document information dictionaries.&lt;/p&gt;
    &lt;p&gt;ISO 32000-2:2020, Table 349 lists the defined entries in PDF’s document information dictionary (Title, Author, Subject, etc). Any vendor may add additional entries (such as Apple does with its /AAPL:Keywords entry), so redaction and sanitization software should be aware of extra entries.&lt;/p&gt;
    &lt;p&gt;From our random sampling, we identified one PDF with a non-trivial document information dictionary still present: VOL00002\IMAGES\0001\EFTA00003212.pdf. This is shown below in Visual Studio Code with my pdf-cos-syntax extension:&lt;/p&gt;
    &lt;p&gt;Of additional interest in this specific PDF is that the comment at line 60 has survived DoJ’s sanitization and redaction workflow! Other PDF comments may therefore also be present in other files.&lt;/p&gt;
    &lt;p&gt;EFTA00003212.pdf appears to be a redacted image or an error from the DoJ workflow, as it is a single page with the text “No Images Produced”.&lt;/p&gt;
    &lt;p&gt;Simple searching of the standardized PDF document information dictionary entries gives the following (note that the technique used will not locate information in compressed object streams, as mentioned above):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Key name&lt;/cell&gt;
        &lt;cell&gt;Number of PDFs (max. = 4,085)&lt;/cell&gt;
        &lt;cell&gt;Comment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Info&lt;/cell&gt;
        &lt;cell&gt;3,823&lt;/cell&gt;
        &lt;cell&gt;Some PDFs have empty Info dictionaries with no entries&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Title&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Author&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Subject&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Keywords&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Creator&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Producer&lt;/cell&gt;
        &lt;cell&gt;215&lt;/cell&gt;
        &lt;cell&gt;Always “pypdf” (denotes https://pypi.org/project/pypdf/)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CreationDate&lt;/cell&gt;
        &lt;cell&gt;3,609&lt;/cell&gt;
        &lt;cell&gt;Same PDFs that have ModDate with an identical value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ModDate&lt;/cell&gt;
        &lt;cell&gt;3,609&lt;/cell&gt;
        &lt;cell&gt;Same PDFs that have CreationDate with an identical value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Trapped&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;APPL:Keywords&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Date analysis&lt;/head&gt;
    &lt;p&gt;Detailed date analysis is a common task in the forensic analysis of potentially fraudulent or modified documents. However, in the case of redacted or sanitized documents, where the document is known to have been modified, this can be less useful.&lt;/p&gt;
    &lt;p&gt;The creation and modification dates for the 3,609 PDFs range from December 18, 2025, 14:32:05 (2:32 pm) to December 19, 2025, 23:26:13 (almost midnight). For all files, the creation and modification dates are always the same. This may also imply that the DoJ batch processing to prepare this tranche of PDFs took at least 36 hours!&lt;/p&gt;
    &lt;p&gt;What’s also interesting is that the CreationDate and ModDate fields in the hidden document information dictionary (inside the object stream of the first increment update – see above) appear to always be an exact match to both the CreationDate and ModDate of the original document. This implies that all dates across all incremental updates were updated in a single processing pass that applied the Bates numbering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Photographs&lt;/head&gt;
    &lt;p&gt;There are no JPEG images (DCTDecode filter) in any PDF in the tranche, including the full-page photographs. Randomly viewing the photographic images at high magnification (zoom) in PDF viewers clearly shows JPEG “jaggy” compression artifacts. All photographic images appear to have been downscaled to 96 DPI (769 x 1152 or 1152 x 769 pixels), making text on random objects in the photos much harder to discern (see the OCR discussion below).&lt;/p&gt;
    &lt;p&gt;DoJ explicitly avoids JPEG images in the PDFs probably because they appreciate that JPEGs often contain identifiable information, such as EXIF, IPTC, or XMP metadata, as well as COM (comment) tags in the JPEG bitstream. This information may disclose the camera model and serial number, GPS location, camera operator details, date/time of the photo, etc., and is more difficult to redact while retaining the JPEG data. The DoJ processing pipeline has therefore explicitly converted all lossy JPEG images to low DPI, FLATE-encoded bitmaps in the PDFs using an indexed device-dependent color space with a palette of 256 unique colors (which reduces the color fidelity compared to the original high-quality digital color photograph).&lt;/p&gt;
    &lt;head rend="h2"&gt;Scanned documents – or are they?&lt;/head&gt;
    &lt;p&gt;Randomly inspecting the tranche discovers many documents that appear to have been created by a scanning process. On closer inspection, there are documents that have tell-tale artifacts from a physical scanning process, such as visible physical paper edges, punched holes, staple marks, spiral binding, stamps, paper scuff marks, color blotches and inconsistencies, handwritten notes or marginalia, varying paper skew, and platen marks from the physical paper scanning processes. For example, VOL00007\IMAGES\0001\EFTA00009440.pdf shows many of these aspects&lt;/p&gt;
    &lt;p&gt;There are also other documents that appear to simulate a scanned document but completely lack the “real-world noise” expected with physical paper-based workflows. The much crisper images appear almost perfect without random artifacts or background noise, and with the exact same amount of image skew across multiple pages. Thanks to the borders around each page of text, page skew can easily be measured, such as with VOL00007\IMAGES\0001\EFTA00009229.pdf. It is highly likely these PDFs were created by rendering original content (from a digital document) to an image (e.g., via print to image or save to image functionality) and then applying image processing such as skew, downscaling, and color reduction.&lt;/p&gt;
    &lt;p&gt;The use of the timeless monospaced (also known as fixed-width) “Courier” typeface means that the number of characters redacted can be easily determined by vertical alignment with text lines above and below each redaction. In some instances, this may reduce the possible number of options that represent the redacted content, allowing it to be more easily guessed. Although redaction of variable-width typefaces is far more complex, Bland, M., Iyer, A., and Levchenko, K. 2022 paper “Story Beyond the Eye: Glyph Positions Break PDF Text Redaction” showed that this is still possible with sufficient computing power and determination.&lt;/p&gt;
    &lt;head rend="h3"&gt;Optical Character Recognition (OCR)&lt;/head&gt;
    &lt;p&gt;OCR is complex image processing that attempts to identify text in bitmap images. In PDF files, OCR-identified text is commonly placed on top of the image using the invisible text render mode. This enables users to then extract the text from the image.&lt;/p&gt;
    &lt;p&gt;Returning to the very first PDF file in the tranche, VOL00001\IMAGES\0001\EFTA00000001.pdf - this is a full-page photo of a hand-written sign where part of the hand-written information is explicitly redacted. The PDF contains largely inaccurate OCR-ed text, indicating that natural language processing (NLP), machine learning (ML), or even language aware dictionary-based algorithms were not used. This means that there will be more errors in the extracted text than is necessary.&lt;/p&gt;
    &lt;p&gt;With cloud platforms readily accessible and supporting advanced OCR at low cost, anyone is capable of re-processing the entire tranche of PDFs and comparing the OCR results to those provided by DoJ. Even though the page images are low-resolution (96 DPI), rerunning OCR may bring to light additional or corrected information hidden by the original OCR that failed to recognize everything correctly.&lt;/p&gt;
    &lt;p&gt;The “black box” redactions we investigated were all correctly applied directly into the image pixel data. They are not separate PDF rectangle objects simply floating above sensitive information that was still present in the image and easily discoverable. Yes, sometimes it is that easy…!&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;We did not set out to comprehensively analyze every corner of every PDF file in the Epstein PDFs, but to present a basic walk-through of some of the challenges and tricks used to conduct a PDF forensic assessment. Our results above were from a small random sample of documents - there may well be outlier PDFs in the data sets that we did not encounter.&lt;/p&gt;
    &lt;p&gt;The DoJ has clearly created internal processes, systems, and workflows that can sanitize and redact information prior to publishing as PDF. This includes converting JPEG images to low-resolution pixel-only bitmaps, largely removing metadata, and rendering page images to bitmaps. OCR appears to have been widely applied, but is of variable quality.&lt;/p&gt;
    &lt;p&gt;Their PDF technology could be improved to vastly reduce file size by removing unnecessary objects (e.g., empty content streams, ProcSets, empty thumbnail references, etc.), simplifying and reducing content streams, applying all incremental updates (i.e., removing all incremental update sections), and always using compressed object streams and compressed cross-reference streams. Information leakage may also be occurring via PDF comments or orphaned objects inside compressed object streams, as I discovered above.&lt;/p&gt;
    &lt;p&gt;PDF forensics is a highly complex field, where variations in files and tool assumptions can easily yield false results. The PDF Association hosts a PDF Forensic Liaison Working Group to develop industry guidance on forensic examination of PDF files and to educate document examiners and other specialists about many of these aspects.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/"/><published>2026-02-04T14:46:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886735</id><title>Voxtral Transcribe 2</title><updated>2026-02-04T19:31:37.999774+00:00</updated><content>&lt;doc fingerprint="3c2dcd92a1ee1e85"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Voxtral transcribes &lt;lb/&gt; at the speed of sound.&lt;/head&gt;Try Voxtral Transcribe 2 in Mistral Studio&lt;p&gt; Precision diarization, real-time&lt;lb/&gt; transcription, and a new audio playground.&lt;/p&gt;&lt;p&gt;Today, we're releasing Voxtral Transcribe 2, two next-generation speech-to-text models with state-of-the-art transcription quality, diarization, and ultra-low latency. The family includes Voxtral Mini Transcribe V2 for batch transcription and Voxtral Realtime for live applications. Voxtral Realtime is open-weights under the Apache 2.0 license.&lt;/p&gt;&lt;p&gt;We're also launching an audio playground in Mistral Studio to test transcription instantly, powered by Voxtral Transcribe 2, with diarization and timestamps.&lt;/p&gt;&lt;head rend="h2"&gt;Highlights.&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Voxtral Mini Transcribe V2: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Voxtral Realtime: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Best-in-class efficiency: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Open weights: Voxtral Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Voxtral Realtime.&lt;/head&gt;&lt;p&gt;Voxtral Realtime is purpose-built for applications where latency matters. Unlike approaches that adapt offline models by processing audio in chunks, Realtime uses a novel streaming architecture that transcribes audio as it arrives. The model delivers transcriptions with delay configurable down to sub-200ms, unlocking a new class of voice-first applications.&lt;/p&gt;&lt;p&gt;Word error rate (lower is better) across languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;p&gt;At 2.4 seconds delay, ideal for subtitling, Realtime matches Voxtral Mini Transcribe V2, our latest batch model. At 480ms delay, it stays within 1-2% word error rate, enabling voice agents with near-offline accuracy.&lt;/p&gt;&lt;p&gt;The model is natively multilingual, achieving strong transcription performance in 13 languages, including English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. With a 4B parameter footprint, it runs efficiently on edge devices, ensuring privacy and security for sensitive deployments.&lt;/p&gt;&lt;p&gt;We’re releasing the model weights under Apache 2.0 on the Hugging Face Hub.&lt;/p&gt;&lt;head rend="h2"&gt;Voxtral Mini Transcribe V2.&lt;/head&gt;&lt;p&gt;Average diarization error rate (lower is better) across five English benchmarks (Switchboard, CallHome, AMI-IHM, AMI-SDM, SBCSAE) and the TalkBank multilingual benchmark (German, Spanish, English, Chinese, Japanese).&lt;/p&gt;&lt;p&gt;Average word error rate (lower is better) across the top-10 languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;p&gt;Voxtral Mini Transcribe V2 delivers significant improvements in transcription and diarization quality across languages and domains. At approximately 4% word error rate on FLEURS and $0.003/min, Voxtral offers the best price-performance of any transcription API. It outperforms GPT-4o mini Transcribe, Gemini 2.5 Flash, Assembly Universal, and Deepgram Nova on accuracy, and processes audio approximately 3x faster than ElevenLabs’ Scribe v2 while matching on quality at one-fifth the cost.&lt;/p&gt;&lt;head rend="h3"&gt;Enterprise-ready features.&lt;/head&gt;&lt;p&gt;Voxtral Mini Transcribe V2 introduces key capabilities for enterprise deployments.&lt;/p&gt;&lt;head rend="h4"&gt;Speaker diarization.&lt;/head&gt;&lt;p&gt;Generate transcriptions with speaker labels and precise start/end times. Ideal for meeting transcription, interview analysis, and multi-party call processing. Note: with overlapping speech, the model typically transcribes one speaker.&lt;/p&gt;&lt;head rend="h4"&gt;Context biasing.&lt;/head&gt;&lt;p&gt;Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental.&lt;/p&gt;&lt;head rend="h4"&gt;Word-level timestamps.&lt;/head&gt;&lt;p&gt;Generate precise start and end timestamps for each word, enabling applications like subtitle generation, audio search, and content alignment.&lt;/p&gt;&lt;head rend="h4"&gt;Expanded language support.&lt;/head&gt;&lt;p&gt;Like Realtime, this model now supports 13 languages: English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. Non-English performance significantly outpaces competitors.&lt;/p&gt;&lt;head rend="h4"&gt;Noise robustness.&lt;/head&gt;&lt;p&gt;Maintains transcription accuracy in challenging acoustic environments, such as factory floors, busy call centers, and field recordings.&lt;/p&gt;&lt;head rend="h4"&gt;Longer audio support.&lt;/head&gt;&lt;p&gt;Process recordings up to 3 hours in a single request.&lt;/p&gt;&lt;p&gt;Word error rate (lower is better) across languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;head rend="h2"&gt;Audio playground.&lt;/head&gt;&lt;p&gt;Test Voxtral Transcribe 2 directly in Mistral Studio. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.&lt;/p&gt;&lt;head rend="h2"&gt;Transforming voice applications.&lt;/head&gt;&lt;p&gt;Voxtral powers voice workflows in diverse applications and industries.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;head rend="h3"&gt;Meeting intelligence.&lt;/head&gt;&lt;p&gt;Transcribe multilingual recordings with speaker diarization that clearly attributes who said what and when. At Voxtral's price point, annotate large volumes of meeting content at industry-leading cost efficiency.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Voice agents and virtual assistants.&lt;/head&gt;&lt;p&gt;Build conversational AI with sub-200ms transcription latency. Connect Voxtral Realtime to your LLM and TTS pipeline for responsive voice interfaces that feel natural.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Contact center automation.&lt;/head&gt;&lt;p&gt;Transcribe calls in real time, enabling AI systems to analyze sentiment, suggest responses, and populate CRM fields while conversations are still happening. Speaker diarization ensures clear attribution between agents and customers.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Media and broadcast.&lt;/head&gt;&lt;p&gt;Generate live multilingual subtitles with minimal latency. Context biasing handles proper nouns and technical terminology that trip up generic transcription services.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Compliance and documentation.&lt;/head&gt;&lt;p&gt;Monitor and transcribe interactions for regulatory compliance, with diarization providing clear speaker attribution and timestamps enabling precise audit trails.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Both models support GDPR and HIPAA-compliant deployments through secure on-premise or private cloud setups.&lt;/p&gt;&lt;head rend="h2"&gt;Get started.&lt;/head&gt;&lt;p&gt;Voxtral Mini Transcribe V2 is available now via API at $0.003 per minute. Try it now in the new Mistral Studio audio playground or in Le Chat.&lt;/p&gt;&lt;p&gt;Voxtral Realtime is available via API at $0.006 per minute and as open weights on Hugging Face.&lt;/p&gt;&lt;p&gt;Explore documentation on Mistral’s audio and transcription capabilities.&lt;/p&gt;&lt;head rend="h2"&gt;We’re hiring.&lt;/head&gt;&lt;p&gt;If you're excited about building world-class speech AI and putting frontier models into the hands of developers everywhere, we'd love to hear from you. Apply to join our team.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mistral.ai/news/voxtral-transcribe-2"/><published>2026-02-04T15:08:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46887326</id><title>Arcan-A12: Weaving a Different Web</title><updated>2026-02-04T19:31:37.629489+00:00</updated><content>&lt;doc fingerprint="3f4997190ea14f89"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Arcan-A12: Weaving a Different Web&lt;/head&gt;
    &lt;p&gt;26 Jan 2026&lt;/p&gt;
    &lt;p&gt;This article is a companion piece to “Arcan Explained: A browser for different Webs” which covered how Arcan works as a browser engine. Some key takeaways from that article are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The focus is only on running networked applications where the outermost one takes on the responsibilities of window management and display control, becoming the ‘desktop’.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Document browsing is a compilation step through separate tools that generates a signed, shareable application package.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is recursive (an application can embed others, including itself) and can compose and interact with allow-listed local software.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media decoding, media transforms, network communication and system integration are all delegated to per-instance sets of interchangeable privilege-separated programs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It is essentially a browser take on a microkernel architecture. The choice in network communication program will control resource retrieval, link resolution, discovery and so on. This determines what kind of a web you end up in.&lt;/p&gt;
    &lt;p&gt;The reason why this is posted here and not on the main Arcan site is to emphasise this decoupling. It is but one possible solution, and there will be better ideas out there, without someone having to boil the ocean in order to try them out.&lt;/p&gt;
    &lt;p&gt;This article covers the design and choices of the included default implementation (&lt;code&gt;afsrv_net&lt;/code&gt;), its command-line helper tool
(&lt;code&gt;arcan-net&lt;/code&gt;) and how they leverage the A12 protocol to form
a web.&lt;/p&gt;
    &lt;p&gt;It is organised as follows:&lt;/p&gt;
    &lt;p&gt;In Recalling the old ways we take a trip down memory lane back to the days of bulletin board systems to look for good bits to bring back into style.&lt;/p&gt;
    &lt;p&gt;In A frayed web of separate worlds we argue that the ‘World Wide Web’ is anything but ‘World Wide’ and cover a set of problems that we want our solution to cover.&lt;/p&gt;
    &lt;p&gt;In A12 as protocol we go through the characteristics of the protocol that we are building the rest on top of.&lt;/p&gt;
    &lt;p&gt;In A12 Web we layer in designs to address the problems of a frayed web using the A12 protocol, along with some properties we want it to have.&lt;/p&gt;
    &lt;p&gt;Finally, in Developer Story we get practical and go through the use of the tools available to actually build something.&lt;/p&gt;
    &lt;head rend="h1"&gt;Recalling the old ways&lt;/head&gt;
    &lt;p&gt;My early access to the Internet started through Bulletin Board Systems, specifically ones that translated select Usenet discussion groups and relayed e-mail over a system called ‘Echomail’.&lt;/p&gt;
    &lt;p&gt;If those words are unfamiliarly to you, a BBS was mainly someone sharing a slice of their computer to others over a telephone network. This was served to one or a few people at a time because each active connection required a designated telephone line and those were expensive.&lt;/p&gt;
    &lt;p&gt;See also: The BBS documentary.&lt;/p&gt;
    &lt;p&gt;Most of the boards I frequented had a very personal feel to them. It was more like being allowed inside someone’s computing living room than being presented with a streamlined and well-dressed corporate facade.&lt;/p&gt;
    &lt;p&gt;It was at once both intimate and intimidating on the rare few occasions when the SysOp (“System Operator”) decided to “break into chat” and your browsing of the local wares was interrupted by a seemingly inescapable one-to-one chat window.&lt;/p&gt;
    &lt;p&gt;Finding out about these places was an interesting journey in itself. Initial discovery was by word of mouth through a friend of a friend. As things sobered up, magazines took to providing listings. Here the experiences were on the milder side. There was less profanity and rarely mischief manuals (such as “the Anarchist’s Cookbook”), erotica or pirated software. Secondary discovery came through sitelists which the sysops curated themselves, or that someone had dumped into a shared upload directory or snuck into the ‘release information’ files packaged inside some piece of downloadable software.&lt;/p&gt;
    &lt;p&gt;Often enough a phone number did not actually lead to the board in question. Instead of the familiar tone of the modem connection handshake you got the voice of someone who did not appreciate being woken up at two in the morning – perhaps you had misread the operating hours/days (not everything was 24/7) or the sysop had grown tired of it all and closed the thing down. Such is life.&lt;/p&gt;
    &lt;p&gt;From this shallow description alone we can see the outline of some sort of troubled web story: Through word of mouth links between a named entry (Larry’s Land of Leisure and Suites thereof) and an address (here, phone-number) you could access resources, including links to other resources.&lt;/p&gt;
    &lt;p&gt;As far as links go, they were not particularly good:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Unidirectional - unless told, the one being linked to was unaware of who referred to them and thus had no say as to whether the extra attention was appreciated or not.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-descriptive - you had to try and resolve the link to figure out what it actually linked to, or if it was even valid in the first place.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Constraints as a side channel - “open between 08.00pm to 06.00am Fri-Sun” was something that might be mentioned on a login screen (less than helpful) or on the sitelist. Accuracy varied wildly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local resources were not addressable - you could point someone in the general direction of something, but once they were connected to the board itself the true hunt began.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local termination - resolving a link does not let you find further ones without processing the resources at the linked location.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ephemeral - should the address mapping change, there is no mechanism to rediscover the linked resource through other paths in the network.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Much of this and more still apply to links on the world “wide” web. To their credit URLs did fix addressing local resources (for a time) and DNS did something about the ephemerality, only to be undone by shortening services.&lt;/p&gt;
    &lt;p&gt;Still, think how much less useful even the first versions of HTML would have been without local resources being part of the language of the ‘link’. The technical solution is about as trivial as can be, yet the consequences are massive.&lt;/p&gt;
    &lt;p&gt;As a snack for thought, take the ‘local termination’ part: this is rather unusual if you think about the underlying data structure; it is a graph, but it is not exposed as such. A link may lead to other links, but first you need to ‘scrape’ (download, parse, extract) them from the outer resource.&lt;/p&gt;
    &lt;p&gt;This left a big discoverability hole to fill, one big enough to spawn some of the wealthiest companies in the world. It may be tempting to think how things would turn out if the other weaknesses had been addressed as well.&lt;/p&gt;
    &lt;p&gt;The obvious elephant in the room is Ted Nelson’s poetic Xanadu and how it keeps being brought up as the ‘what could have been’ solution because it used backlinks to avoid unidirectionality and transclusions for subcontent referencing.&lt;/p&gt;
    &lt;p&gt;Alas, the rest of its ‘web as living document’ story had a very niche appeal, and the browser part was vapourware for the longest time and then very quirky and unintuitive. As important as the linking story is for the base layer of a web, there also needs to be something there: content is king.&lt;/p&gt;
    &lt;p&gt;Tech doesn’t just go away, but rather move into one of many retirement homes for retrocomputing romantics. I don’t recall a strong inflection point where the BBS stopped being my primary source for information and exploration, it “just happened” as an uncoordinated silent shift. The Internet just naturally became the new default, but the transition and loss of something could be felt.&lt;/p&gt;
    &lt;p&gt;The real kicker was the shift in discovery, with search engines as the natural new starting point, some being Web while also somehow not being ‘Web’, like NTNU.no’s FTP search. They quickly became the way to discover content. More seasoned explorers, like the late and great +Fravia pivoted from using disassemblers and debuggers to reverse the dynamic structure of computing, to unpacking the search engine ‘command-line’ to reverse the structure of the web.&lt;/p&gt;
    &lt;p&gt;Other discovery solutions were curated collections of links as ‘portals’, like the original Yahoo. Those were similar to magazine sitelists, which also switched to providing links as URLs rather than phone numbers.&lt;/p&gt;
    &lt;p&gt;It might seem comical and distant now but there was real value in buying a computer magazine for suggestions on where to go on the web. Several Internet Service Providers at the time did go through the extra effort of bundling subscriptions to such magazines. Still even echoes of BBS form discovery remained for a while in the shape of ‘Web rings’ and IRC chatbots serving sitelists.&lt;/p&gt;
    &lt;p&gt;To shorten the story somewhat I will skip past the evolution of forums into ‘community’ sites, how they were replaced by ‘social media’ and so on. Instead I will simply suggest that the ‘web’ oscillates between different modalities, like (open, distributed, public) to (closed, centralised, invite-only). The nudge needed to switch the trend from the one to the other, is spam.&lt;/p&gt;
    &lt;p&gt;The ‘open web’ has, to me, become the least useful resource on the Internet, and that rapidly accelerated to large hadron levels with the sheer amount of bullshit synthesis that has weaseled its way in between me and whatever I was searching for or whoever I was communicating with.&lt;/p&gt;
    &lt;p&gt;I am anything but alone in feeling this disconnect. For a well worded view on the matter, look no further than Splitting the Web. That is, if your browser still allows you to, and the link is still working.&lt;/p&gt;
    &lt;head rend="h1"&gt;A frayed web of separate worlds&lt;/head&gt;
    &lt;p&gt;One thing that the many web pundits I have spoken to over the years have in common when asked to narrow down what the web ‘is’, is a certain glee over unity. Grab a (reasonable) device! And a browser! Browse the web! From anywhere!&lt;/p&gt;
    &lt;p&gt;This doesn’t answer the question and does not match any reality of mine. I have reasonable devices in every form factor, and an even larger pile of completely unreasonable ones. I use several browsers, but it is an exceptional day if two browsers on two different devices behave even close to the same.&lt;/p&gt;
    &lt;p&gt;Heck, if two browsers run on the same device but gets different geolocated source IPs they are served different content on the regular, and more so when using choice examples, say between China to Japan or whether the almighty Cloudflare deems you worthy or not. That is a rather narrow idea of ‘world-wide’.&lt;/p&gt;
    &lt;p&gt;For every other click I am supposed to prove my humanity by clicking a box or waiting a few seconds while my computer crunch pointless numbers. Possibly both.&lt;/p&gt;
    &lt;p&gt;So where is it? Hardly in the protocol. Otherwise we could have dropped that part of the URL long ago. Even before shifts towards the likes of QUIC or TLS (or is it SSL?) becoming ubiquitous, browsers implemented a wide range of them, from Gopher and FTP to RTSP.&lt;/p&gt;
    &lt;p&gt;You also won’t find it in the myriad of document containers or the resources referenced inside. What once was ‘Flash’ or ‘Silverlight’ is now an exercise in computing necromancy to relive. Is that javascript of yours following ECMAScript.1997 or 2025?. One day you might get to see that PNG as JXL, if the Gods so decide.&lt;/p&gt;
    &lt;p&gt;If you are not big on appealing to the authority of the W3C, what you are left with now are the links and how people use them. As we implied previously, the properties of ‘links’ and how they are discovered and enable discovery largely controls what kind of web that emerges.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tangent striking dischord&lt;/head&gt;
    &lt;p&gt;Discord is an interesting phenomenon that deserves to be included here for a handful of reasons. I will fight the urge to attempt a larger breakdown, but it does serve as a connection to the BBS story from before, albeit in sheep’s clothing.&lt;/p&gt;
    &lt;p&gt;To the owners it is probably the happiest of little accidents, just like the Covid pandemic was to Slack. The numbers displayed on Wikipedia and friends are probably imaginary, but suggestions around 3 million accounts in 2016 to well over 500 million in 2025, and a little less than that actually active, seem reasonable. That is quite something for what was basically paratext and coordination around gaming – maybe the ‘Linux desktop’ could learn something from this.&lt;/p&gt;
    &lt;p&gt;The connection to the BBS story is that it gives you a turnkey solution for spinning up your own ‘personal’ ‘server’. In reality it is anything but, merely a namespace where you only get to partially define a small set of the rules, but at least you get to pick an icon or something.&lt;/p&gt;
    &lt;p&gt;The actual agency is more like the old surveillance camera meme:&lt;/p&gt;
    &lt;p&gt;Technically it is completely uninspired. The browser story is Electron as a bodge patchset on top of some dull variant of Chromium. Somehow it is always my lucky day when launching as ‘pretend consent’ language to force you to update whatever to whatever just to then automatically download some more updates.&lt;/p&gt;
    &lt;p&gt;The linking story is somehow worse than plain web. First you have one form for local object link embedding. That one is unlikely to be externally content addressable URLs, thus not shareable.&lt;/p&gt;
    &lt;p&gt;Then you have pseudo-resolution of regular URLs (into ‘previews’) that then gets forwarded to another browser, even though that is most likely the same code you were already running.&lt;/p&gt;
    &lt;p&gt;Its search story is spartan but also telling; a basic command-line with some magical prefixes with search space limited to that of the current ‘server’. I suspect it is very deliberately so before IPO, and that a possible sell later is both training data when all other wells have gone dry, and a chatbot interface to deliver masqueraded ads and bias to some; dark secrets to others, all based on what- and who- you are willing to pay.&lt;/p&gt;
    &lt;p&gt;That something like the TOS violation Searchcord, managed to spark anger and controversy over basic search of partial indexing across public servers (that opted in!) is also telling of the average user expectation.&lt;/p&gt;
    &lt;p&gt;Content wise it is a hotspot for the usual uninteresting filth like grooming; violence; expressions of carnal desires; bullying and brigading. That is something of a variable to monitor as part of a larger health and sanity check. If it is completely absent I get suspicious. If it is overflowing, I walk away.&lt;/p&gt;
    &lt;p&gt;Still, even though the presentation has all the personality of a wet fart captured in a bag and painted grey, it is my goto for some slim chance of an actual interaction with an actual person over a niche interest. That is not gaming paratext, but areas as diverse as CNC Machinery, Pinball Repair, Laser engraving, Electronics and Reverse Engineering.&lt;/p&gt;
    &lt;p&gt;My point is that even though the building blocks and overall purpose is wrong - a strong and playful human connection is still possible and can spring up in the most unlikely of places. We’ll need that going forward.&lt;/p&gt;
    &lt;head rend="h1"&gt;A12 as protocol&lt;/head&gt;
    &lt;p&gt;Time to get technical and cover the last building block before also getting practical. The base A12 protocol was introduced here: A12: Visions of the fully networked desktop.&lt;/p&gt;
    &lt;p&gt;It provides means for sharing an interactive media source (like an application window or composited desktop) to a sink in either a push based configuration, like how X11 remoting worked, or a pull one like VNC, RDP, or SSH would.&lt;/p&gt;
    &lt;p&gt;That is done over one of many transfer channels, each being unidirectional and coupling a possible video, audio and binary ‘blob’ stream corresponding to source windows.&lt;/p&gt;
    &lt;p&gt;The philosophy was that of ‘one desktop, many devices’. This means having individual devices be responsible for providing one or many sources over a network, and the desktop finding and composing them together as seamlessly as possible.&lt;/p&gt;
    &lt;p&gt;Among its building blocks is the ability to redirect a source from one sink to another while it is still running. This was demonstrated already back in 2019 by ‘dragging a living window from one machine to another’ as seen in the clip below.&lt;/p&gt;
    &lt;p&gt;There is also an optional extension to the protocol that enables previously paired sources and sinks to find each other again by broadcasting sets of challenge hashed public keys backed by petnames. This turns cryptographic identity into the link itself.&lt;/p&gt;
    &lt;p&gt;This avoids having to rely on DNS, DHCP provided hostnames, mDNS or other naming services for local (re-) discovery.&lt;/p&gt;
    &lt;p&gt;That is not enough for what we need here, and that brings us to the final extension. It introduces a third possible role, the directory. It act as a rendezvous for discovery; traffic relaying; NAT traversal; shared and private file/state store; application hosting and source/sink match-making.&lt;/p&gt;
    &lt;p&gt;The directory server forms a messaging and storage namespace for each hosted application. By default this is broadcast between all sinks running an application. This works for light collaboration and coordination. The reference desktop environment for Arcan, Durden, uses this to synchronise clipboard and share input devices.&lt;/p&gt;
    &lt;p&gt;For something more refined we can slot in a directory server side control application to match. It uses the same structure as a regular Arcan application, but its role is to coordinate and regulate communication and to mediate access to other networked resources.&lt;/p&gt;
    &lt;p&gt;Such resources can be those that are necessary to the dynamic side of the application itself, like hosted media, indexing and search.&lt;/p&gt;
    &lt;p&gt;To achieve that there are some special functions in the scripting API that we will return to in the ‘Developer Story’ section. Two of particular note are &lt;code&gt;link_target&lt;/code&gt; and
&lt;code&gt;reference_target&lt;/code&gt;. Those lets us define different kinds of
links.&lt;/p&gt;
    &lt;p&gt;This leads us to the next section, as we can now form webs.&lt;/p&gt;
    &lt;head rend="h1"&gt;A12 Web&lt;/head&gt;
    &lt;p&gt;We have reached the philosophy of ‘the desktop, reaching out’ similar to the BBS as covered in ‘the old ways’ to counter the problems from ‘a frayed web of separate worlds’ and either sizzle out into obscurity or create new terrifying problems – we all know where roads paved with good intentions might lead.&lt;/p&gt;
    &lt;p&gt;To be more direct and practical we will explain things using the command-line tooling as a starting point. For development purposes, we have hosted an Arcan directory server at arcan.divergent-desktop.org for years.&lt;/p&gt;
    &lt;p&gt;Using something like:&lt;/p&gt;
    &lt;code&gt;arcan-net arcan.divergent-desktop.org explain&lt;/code&gt;
    &lt;p&gt;If there is a cached / petnamed entry already in the local keystore, e.g. ‘dd’:&lt;/p&gt;
    &lt;code&gt;arcan-net dd@ explain&lt;/code&gt;
    &lt;p&gt;Would:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create an outbound a12-connection to arcan.divergent-desktop.org.&lt;/item&gt;
      &lt;item&gt;Generate an authentication keypair and query for trust unless known (TOFU).&lt;/item&gt;
      &lt;item&gt;Issue a LIST command with [notify] enabled.&lt;/item&gt;
      &lt;item&gt;Wait for a reply with a name field that matches ‘explain’.&lt;/item&gt;
      &lt;item&gt;Issue a download request for key-associated state matching package ID from #4.&lt;/item&gt;
      &lt;item&gt;Issue a download request for the package ID from #4.&lt;/item&gt;
      &lt;item&gt;Verify integrity of package from #6.&lt;/item&gt;
      &lt;item&gt;Verify authenticity of package compared to signature in manifest from #7.&lt;/item&gt;
      &lt;item&gt;Unpack into temporary storage.&lt;/item&gt;
      &lt;item&gt;Start runner process with sandboxing and I/O transfer channels.&lt;/item&gt;
      &lt;item&gt;Inject any state from #5 and signal runner to execute.&lt;/item&gt;
      &lt;item&gt;Join directory messaging group matching ID from #4.&lt;/item&gt;
      &lt;item&gt;Map messages and dynamic resource access between runner and directory until termination.&lt;/item&gt;
      &lt;item&gt;Cleanup and transfer state.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The ‘until termination’ point has three possible triggers. First one is the user simply shutting the application down. That would create a snapshot of application-persistent key-value pairs and upload into a matching slot from #5.&lt;/p&gt;
    &lt;p&gt;The other is that an updated version of the application appears (that would be signalled due to the notify- flag from the LIST command in #3). The default behaviour then is to initiate a download of the update matching steps (5,7,8,9) and have the runner store-restore state to itself.&lt;/p&gt;
    &lt;p&gt;The last is on a scripting error causing termination. The runner can be instructed to continue regardless; to snapshot, shutdown and retry; to rollback to a previous version. With any of these options the runner may also send a report rather than (possibly broken) state as per #14.&lt;/p&gt;
    &lt;p&gt;At this stage there is already a number of deviations from the hypertext transport way of doing things, and we have only taken a peek at the basics. Outside of the actual package format and Steps 5 and 13, the chain above is generic enough that it could as well have been a model for a mobile app store.&lt;/p&gt;
    &lt;p&gt;First, any code and necessary ‘offline first’ data is present in the initial package transfer. Its size and checksum is known as part of the LIST command so caching code+data is trivial. Package contents are signed, as is client managed state; altering either on the server side is a distinguishable error condition.&lt;/p&gt;
    &lt;p&gt;While hotly debated internally, the engine blocks any script loads outside of the signed package along with a small curated set of builtin ones. There is no facility ‘hide code in strings and unpack into eval()’ form of getting unsigned code to run and therefore no ‘middleboxes injecting code’ adtech style tampering.&lt;/p&gt;
    &lt;p&gt;Second, any state store is deferred to the user and their decision to leverage (or not) an authentication key-bound server side store. There is no need for neither &lt;code&gt;cookies&lt;/code&gt; nor a ‘login’ form -
authentication primitives for the connection carry over to the
application layer and, if a server side processor is attached, salted to
an application-bound identifier as part of the infrastructure.&lt;/p&gt;
    &lt;p&gt;Third, traffic is owned by the hosting directory. This is a big shift and ties heavily into the linking story. The engine configuration for the case we discuss here gets its primary traffic through either &lt;code&gt;arcan-net&lt;/code&gt; or &lt;code&gt;afsrv_net&lt;/code&gt; when the outer
application also runs the desktop itself. These, in turn,
exclusively communicate with the specified directory.&lt;/p&gt;
    &lt;p&gt;This calls for a short example to get any further. Say that you have an A12 web app that is about image sharing and communication around shared images with friends.&lt;/p&gt;
    &lt;p&gt;The general UI, layouting and chat overlay is handled by the static signed appl package. Dynamic chat updates come through message passing events. The actual images do not make sense to share in the bundle expected to load/run at startup, so they are retrieved on demand from the server. In the old HTML world, that would be something like:&lt;/p&gt;
    &lt;code&gt;&amp;lt;img src="https://some.site/path/image_name.png?bunch_of_state_dont_leak"&amp;gt;&lt;/code&gt;
    &lt;p&gt;In an arcan appl, that would be:&lt;/p&gt;
    &lt;code&gt;local stdin = net_open("@stdin", net_callback_handler)
local image_file = open_nonblock(stdin, {}, "image_name")
load_image_asynch(image_file, image_callback_handler)&lt;/code&gt;
    &lt;p&gt;The asynchronous event handlers and transfer queueing hints have been omitted for brevity. Here, &lt;code&gt;net_open&lt;/code&gt; gives a reference
handle to the current network connection. Then it is used to initiate a
non-blocking serialised read of &lt;code&gt;image_name&lt;/code&gt; that gets
forward to image decoding.&lt;/p&gt;
    &lt;p&gt;All resource requests follow this pattern. The directory server is able to route / cache / load whatever is necessary to fulfill a request, and the reference implementation has several options for this, but the point is that the directory owns the traffic.&lt;/p&gt;
    &lt;p&gt;For the client end this means that network filtering and monitoring can be very aggressive and request record/replay is trivial for both archival and development purposes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Linking&lt;/head&gt;
    &lt;p&gt;We finally have enough context to discuss links. The linking model here has two forms: “unified” and “referential”. The referential link is user facing, so we start there.&lt;/p&gt;
    &lt;p&gt;When a connection is made over A12, the initial handshake covers the expected local and remote roles: ‘Source’, ‘Sink’ or ‘Directory’. When hosting a directory server, you can specify outbound referential links through the &lt;code&gt;reference_directory('myfriend')&lt;/code&gt; function call
in the config scripting API.&lt;/p&gt;
    &lt;p&gt;This will create a worker that makes an outbound connection, and when this worker is alive and authenticated, it will be among the results sent in response to the LIST command.&lt;/p&gt;
    &lt;p&gt;This allows local clients to open ‘myfriend’, either tunneled or redirected. The local and remote directory workers transfer public keys and other extended authentication primitives for ‘myfriend’ to transitively trust a new connection to some specified degree.&lt;/p&gt;
    &lt;p&gt;We can see a few properties for this kind of link:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Bidirectional, authenticated and revocable - A link can only be established if the linked entity agrees to it, and it lives only as long as both parties maintain a connection.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Typed - A path through directories always terminate at a directory, a hosted source, sink, or application and you know what you get in advance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Presence is reachability - The linking entity updates its local directory to reflect connection changes, and protocol propagates this to active clients.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rediscoverable - When walking the path of a link the clients learn about public keys of individual directories. The discovery protocol extension lets a linked entity be rediscovered even if the link itself has been revoked.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is clearly not without trade-offs. Transitive trust models and managing petnames to authentication primitives to stop Zooko’s Triangle can get complicated fast, even for networks of only your own devices.&lt;/p&gt;
    &lt;p&gt;On the other hand, DNS is not necessary. It is completely possible to navigate only through a path of petnames. The idea is that in a well-distributed web, we run into six degrees of separation.&lt;/p&gt;
    &lt;p&gt;We don’t link to resources within a hosted application. That is deliberate.&lt;/p&gt;
    &lt;p&gt;Links being contractual sets a low cap on the amount of links that are feasible to maintain. That’s a feature, not a bug. The cost to resolve grows linearly with the number of directories in a path.&lt;/p&gt;
    &lt;p&gt;A unified link is also specified in the config scripting API by calling the &lt;code&gt;link_directory('myfriend')&lt;/code&gt;. The main difference
against referential links is that the connection is not visible in the
client presented list.&lt;/p&gt;
    &lt;p&gt;This is because the linking parties form a unified namespace of exposed applications and their respective worker processes synch host applications, files and instance server side script runners as needed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Search and Indexing&lt;/head&gt;
    &lt;p&gt;The last thing on the Web menu here is search in the sense of ‘From what we know and can access, what best matches your query?’ and not the ‘that we or our sponsors think that you should see’ variation.&lt;/p&gt;
    &lt;p&gt;The cheap solution is of course to leave it in the hands of developers and see what emerges. While that can come as a side effect of growth in popularity, part of the ‘many devices, one desktop’ narrative means that lower level mechanisms would be useful.&lt;/p&gt;
    &lt;p&gt;There are a few parts of the protocol to leverage here.&lt;/p&gt;
    &lt;p&gt;One is that binary stream uploads/downloads have a few typed alternate slots. One such slot is METADATA. This means that with upload permission someone can pre-index/analyse locally, and attach that to the server side store going forward. Similarly, a controller providing, for example, an image hosting service can see that something does not have any metadata attached to it, fire up some analysis tool and attach the results itself.&lt;/p&gt;
    &lt;p&gt;Another part is that the name part of requests that trigger binary stream transfers reserves the ‘.’ prefix for protocol support use. The server implementation uses .monitor, for instance, to negotiate an interactive debug interface stream and .debug to collect crash dumps that have accumulated.&lt;/p&gt;
    &lt;p&gt;Another that gets special treatment is ‘.index’. Normally it can be downloaded as a means to list files in the private store attached to the key you authenticated to. It is also used to list available resources in the server-side store assigned to each controller by also specifying the namespace identifier that matches the application identifier that the controller is assigned to, and that would propagate across a network of unified links.&lt;/p&gt;
    &lt;p&gt;If you upload a file to ‘.index’ you actually slot in a filter that corresponds to your search query for that namespace. This will influence future ‘.index’ downloads.&lt;/p&gt;
    &lt;p&gt;The server also has an external resolver mechanism. To understand this, both file and index resolving first goes to the controller. This has the option to reject it, or to forward or remap into its local file-store. The later can be substituted for an external resolver that takes care of translating to other protocols, e.g. AT, IPFS, Torrent with caching. This tactic is also used for implementing unified linking.&lt;/p&gt;
    &lt;p&gt;There is a lot more to unpack here when it comes to protection against abuse and collaboratively reaching an accurate .index that all participants can sign off on -- but that is for a different day.&lt;/p&gt;
    &lt;head rend="h1"&gt;Developer Story&lt;/head&gt;
    &lt;p&gt;With enough protocol nuances in place we can dig into some of the practicalities in developing a networked Arcan application, but just enough to follow the web story here rather rather than the concrete APIs as such. For those there are numerous guides, step-by-step instructions and examples already in both Wiki and repository documentation format.&lt;/p&gt;
    &lt;p&gt;The only thing we need to recall is that an Arcan appl is a set of scripts with some minor file- and function name- patterns.&lt;/p&gt;
    &lt;p&gt;A minimal form is just this:&lt;/p&gt;
    &lt;code&gt;mkdir $ARCAN_APPLBASEPATH/myappl;
echo "function myappl()\nend\n" &amp;gt; $ARCAN_APPLBASEPATH/myappl/myappl.lua&lt;/code&gt;
    &lt;p&gt;Assuming that you have permission to install or update an appl (which are different permissions) to a directory server that will host it, all you have to do is:&lt;/p&gt;
    &lt;code&gt;arcan-net --sign-tag mykey --push-appl myappl somedir@&lt;/code&gt;
    &lt;p&gt;This will package, sign and transfer ‘myappl’ to the directory pointed to by ‘somedir’ in the current keystore. Creating an entry and generating keys can be done with:&lt;/p&gt;
    &lt;code&gt;arcan-net keystore somedir host.or.ip&lt;/code&gt;
    &lt;p&gt;It will also tell you the public key that the server needs to grant permissions to. Setting one up has a lot more nuance to it, but with the arcan-net installation you would have a config.lua.example to work from and then run:&lt;/p&gt;
    &lt;code&gt;arcan-net -c /path/to/my/config.lua&lt;/code&gt;
    &lt;p&gt;You can then test-run:&lt;/p&gt;
    &lt;code&gt;arcan-net somedir@ myappl&lt;/code&gt;
    &lt;p&gt;Which should just become a black window. Keep it running, but at the same time let’s push a change that would break it:&lt;/p&gt;
    &lt;code&gt;echo "function myappl()
    bad_function_call()
 end
" &amp;gt; $ARCAN_APPLBASEPATH/myappl/myappl.lua

arcan-net --sign-tag mykey --push-appl myappl somedir@&lt;/code&gt;
    &lt;p&gt;The already running client downloads/update and it breaks. If configured to permit it will create a crash report, upload it and rollback to the last known working one.&lt;/p&gt;
    &lt;code&gt;arcan-net --get-file myappl .report - somedir@&lt;/code&gt;
    &lt;p&gt;That will collect user crash reports, bundle them together and send them back to us (and pipe to standard output). The reports are valid Lua scripts, so we can have analysis tooling that itself generates an appl.&lt;/p&gt;
    &lt;p&gt;The same tactic is used for slotting in a controller, just with --push-ctrl instead of --push-appl.&lt;/p&gt;
    &lt;p&gt;To look at a more advanced example, we will take streaming media playback. The full appl code is as follows:&lt;/p&gt;
    &lt;code&gt;
function myapp()
net_open("@stdin",
  function(source, status)
    if status.kind == "connected" then
      play_media(source)
    end
  end
  )
end

function play_media(ref)
  local fio = open_nonblock(ref, {}, "appl:/test")
  launch_decode(nil, "protocol=media",
    function(src, status)
      if status.kind == "bchunkstate" then
        open_nonblock(src, {}, fio)
      elseif status.kind == "resized" then
        show_image(src)
        resize_image(src, status.width, status.height)
      end
    end
  )
end
&lt;/code&gt;
    &lt;p&gt;The first thing to note is the &lt;code&gt;net_open&lt;/code&gt; call. This explicitly says
that we want to access and communicate with the directory that it was downloaded
from. Should that call fail, we can assume to be running offline.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;play_media&lt;/code&gt; function pairs two asynchronous processes. The
&lt;code&gt;open_nonblock&lt;/code&gt; part is used for non-blocking asynchronous file
input/output, both ones from within the appl package; from user-defined
namespaces and through existing processes via a reference handle.&lt;/p&gt;
    &lt;p&gt;The first call goes through the handle to the network connection, and the appl:/ prefix tells it to go through the controller side application specific namespace. Any extra controls about transfer queueing/buffering/parallelisation preferences would go into the passed option table.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;launch_decode&lt;/code&gt; part will spawn a media decoding process,
and by not providing it with direct input it will send a set of extensions it
supports (bchunkstate), that we ignore here and just pair with the resource
reference we got from previous &lt;code&gt;open_nonblock&lt;/code&gt; call. On the first
'resize' event we set the associated video object to visible and size to match
the source dimensions.&lt;/p&gt;
    &lt;p&gt;Let's slot in a matching controller:&lt;/p&gt;
    &lt;code&gt;
function myapp()
end

function myapp_load(cl, resource)
  if resource == "test" then
    return "test.mp4"
  end
end

function myapp_store(cl, resource)
-- block all attempts at storing files
end
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;_load&lt;/code&gt; entrypoint will be triggered when the client &lt;code&gt;open_nonblock&lt;/code&gt;
is issued. Here we map it to an actual file in the server-side store. This is where we
can add additional permission checks or selection logic. This is where the previously
mentioned 'external resolver' also fit, if the &lt;code&gt;config.lua&lt;/code&gt; set for the server
would say:&lt;/p&gt;
    &lt;code&gt;
function ready()
  local resolver =
    launch_resolver("/some/executable",
                    function(source, status)
                    end
                   )
  appl_set_resolver("myapp", resolver)
end
&lt;/code&gt;
    &lt;p&gt;The mapped &lt;code&gt;test.mp4&lt;/code&gt; request would be forwarded to the process of
&lt;code&gt;/some/executable&lt;/code&gt; where we can have advanced mapping to other protocols and
storage solutions.&lt;/p&gt;
    &lt;p&gt;Let's do something more advanced. We add an arcan-shmif client to the server-side policy database: &lt;code&gt;arcan_db add_target BIN xserver /usr/bin/Xarcan -exec wmaker&lt;/code&gt;. Then,
in the controller we add the following function:&lt;/p&gt;
    &lt;code&gt;
function myapp_join(cl)
  launch_target(cl, {}, "xserver",
    function(source, status)
    end
  )
end
&lt;/code&gt;
    &lt;p&gt;As soon as a client joins, the server would spawn an instance of an Xserver with the 'WindowMaker' window manager attached. This makes a loopback connection and registers as a hidden source only visible to the specified client. The client gets a notification that the source is available, and that would translate to a &lt;code&gt;segment_request&lt;/code&gt;
event in the &lt;code&gt;net_open&lt;/code&gt; event handler. If it accepts it:&lt;/p&gt;
    &lt;code&gt;
net_open("@stdin",
function(source, status)
  if status.kind == "segment_request" then
    accept_target(640, 480, event_handler)
  end
end
)
&lt;/code&gt;
    &lt;p&gt;We now have the means to composite and interact with the source as if it had been launched locally.&lt;/p&gt;
    &lt;p&gt;All of this has been assuming that the client end has the Arcan stack installed and available. This might not be the case for weaker 'thin' kiosk like devices or in a more limited context, like one of those horrid vendor locked app ecosystems. Should the full stack be present on the directory server however, and the &lt;code&gt;config.permissions.applhost&lt;/code&gt; option be set to a tag (group)
matching your authentication key, a simplified viewer that only implements the
a12 protocol parts, like Smash,
could be used if the client request the appl as a source and not as an appl
package download. This would cause the server to spawn an instance of Arcan
with a loopback connection as a directed source to the specific client.&lt;/p&gt;
    &lt;p&gt;The purpose of bringing all this up here is not as a practical guide, but to provide enough context to highlight a few things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The tooling to browse, host and develop is the same. They are a property of the network solution itself, not ‘browser:developer tools’.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Updates are atomic and signed, making life much more difficult for parasitic intermediaries.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Every form of communication is explicit, from link contracts to how the appl communiate.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The execution form is local-first, into locally-hosted, into networked.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The scaling model is small nodes, large networks.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 'frontend', 'backend' and server development model is one and the same.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Both client appl and controller are composable due to the naming scheme.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;In Closing&lt;/head&gt;
    &lt;p&gt;There is a lot of technical details omitted here around decisions and trade-offs and there is yet a small time window for change before all this is locked-in, especially around server side APIs and small-scale payment processing (with GNU taler being a strong candidate) to avoid the 'need' (they will always find a way) for Ad-tech parasites.&lt;/p&gt;
    &lt;p&gt;Other future plans involve preserving and translating current web contents into this, with tooling for layering in collaborative features over the contents. There is still ample room to join in and play around like it is the 90ies again, for a timeline that doesn't look so dark and grim as the current one does.&lt;/p&gt;
    &lt;p&gt;That said, a substantial goal for all of this is personal agency over any kind of mass adoption -- I am stubborn, not naive. That anyone outside of a small group of tech die hards would go all Yippee Ki-Yay over this is a moonshot and that is fine.&lt;/p&gt;
    &lt;p&gt;There are a number of places in my life and home where the current web- and browser- story will be pushed out. Places like my network cameras, heat pump HMI, various maker devices, home theater, gaming gear, mobile devices and so on. If I can only revert that I might at least tolerate that I still have to order groceries in some throwaway browser on a throwaway device. At least for now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.divergent-desktop.org/blog/2026/01/26/a12web/"/><published>2026-02-04T15:50:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888142</id><title>RS-SDK: Drive RuneScape with Claude Code</title><updated>2026-02-04T19:31:37.190098+00:00</updated><content>&lt;doc fingerprint="bdf8915a6c22e4d7"&gt;
  &lt;main&gt;
    &lt;p&gt;Research-oriented starter kit for runescape-style bots, including a typescript sdk, agent documentation and bindings, and a server emulator. Works out of the box - tell it what to automate!&lt;/p&gt;
    &lt;p&gt;Build and operate bots within a complex economic role-playing MMO. You can automate the game, level an account to all 99s, and experiment with agentic development techniques within a safe, bot-only setting.&lt;/p&gt;
    &lt;p&gt;The goals of this project are to provide a rich testing environment for goal-directed program synthesis techniques (Ralph loops, etc), and to facilitate research into collaboration and competition between agents.&lt;/p&gt;
    &lt;p&gt;There is currently a leaderboard for bots running on the demo server, with rankings based on highest total level per lowest account playtime.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;RS-SDK is a fork of the LostCity engine/client, an amazing project without which rs-sdk would not be possible. Find their code here or read their history and ethos&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/MaxBittker/rs-sdk.git&lt;/code&gt;
    &lt;p&gt;Out of the box, you can connect to the provided demo server, choose a name that is not already taken!&lt;/p&gt;
    &lt;p&gt;With claude code:&lt;/p&gt;
    &lt;code&gt;bun install
claude "start a new bot with name: {username}"&lt;/code&gt;
    &lt;p&gt;Manually:&lt;/p&gt;
    &lt;code&gt;bun install
bun scripts/create-bot.ts {username}
bun bots/{username}/script.ts &lt;/code&gt;
    &lt;p&gt;Chat is off by default to prevent scamming and prompt injection attacks, but you can opt in with &lt;code&gt;SHOW_CHAT=true&lt;/code&gt; in the bot.env file&lt;/p&gt;
    &lt;p&gt;Warning: The demo server is offered as a convenience, and we do not guarantee uptime or data persistence. Hold your accounts lightly, and consider hosting your own server instance. Please do not manually play on the demo server.&lt;/p&gt;
    &lt;p&gt;This server has a few modifications from the original game to make development and bot testing easier:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Faster leveling - The XP curve is accelerated and less steep.&lt;/item&gt;
      &lt;item&gt;Infinite run energy - Players never run out of energy&lt;/item&gt;
      &lt;item&gt;No random events - Anti-botting random events are disabled&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;rs-sdk runs against an enhanced web-based client (&lt;code&gt;botclient&lt;/code&gt;) which connects to the LostCity 2004scape server emulator.&lt;/p&gt;
    &lt;p&gt;There is a gateway server which accepts connections from botclient and SDK instances, and forwards messages between them based on username. Once connected to the gateway, the botclient will relay game state to the SDK, and execute low-level actions (e.g. &lt;code&gt;walkTo(x,y)&lt;/code&gt;) sent from the SDK through the gateway.&lt;/p&gt;
    &lt;p&gt;This means that the SDK can't talk directly to the game server, but must go through the botclient. It will attempt to launch the botclient on startup if one is not already running.&lt;/p&gt;
    &lt;p&gt;You don't need to run the gateway/botclient in order to run automations against the demo server, but you may choose to if you are fixing bugs or adding features to the rs-sdk project&lt;/p&gt;
    &lt;p&gt;You want all these running:&lt;/p&gt;
    &lt;code&gt;cd engine &amp;amp;&amp;amp; bun run start&lt;/code&gt;
    &lt;code&gt;cd webclient &amp;amp;&amp;amp; bun run watch&lt;/code&gt;
    &lt;code&gt;cd gateway &amp;amp;&amp;amp; bun run gateway&lt;/code&gt;
    &lt;p&gt;There is also a login server which you may not need, I forget&lt;/p&gt;
    &lt;p&gt;This is a free, open-source, community-run project.&lt;/p&gt;
    &lt;p&gt;The goal is strictly education and scientific research.&lt;/p&gt;
    &lt;p&gt;LostCity Server was written from scratch after many hours of research and peer review. Everything you see is completely and transparently open source.&lt;/p&gt;
    &lt;p&gt;We have not been endorsed by, authorized by, or officially communicated with Jagex Ltd. on our efforts here.&lt;/p&gt;
    &lt;p&gt;You cannot play Old School RuneScape here, buy RuneScape gold, or access any of the official game's services! Bots developed here will not work on the official game servers.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/MaxBittker/rs-sdk"/><published>2026-02-04T16:47:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888301</id><title>Why This Computer Scientist Says All Cryptocurrency Should "Die in a Fire"</title><updated>2026-02-04T19:31:36.765420+00:00</updated><content>&lt;doc fingerprint="732d909514a7ad9d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why This Computer Scientist Says All Cryptocurrency Should “Die in a Fire”&lt;/head&gt;
    &lt;p&gt;UC-Berkeley’s Nicholas Weaver has been studying cryptocurrency for years. He thinks it’s a terrible idea that will end in disaster.&lt;/p&gt;
    &lt;p&gt;Despite being hyped in expensive Super Bowl ads, cryptocurrency is now having a difficult moment. As the New York Times reports, “the crypto world went into a full meltdown this week in a sell-off that graphically illustrated the risks of the experimental and unregulated digital currencies.” One of cryptocurrency’s most vocal skeptics is Nicholas Weaver, senior staff researcher at the International Computer Science Institute and lecturer in the computer science department at UC Berkeley. Weaver has studied cryptocurrencies for years. Speaking with Current Affairs editor-in-chief Nathan J. Robinson, Prof. Weaver explains why he views the much-hyped technology with such antipathy. He argues that cryptocurrency is useless and destructive, and should “die in a fire.”&lt;/p&gt;
    &lt;p&gt;The interview transcript has been lightly edited for grammar and clarity.&lt;/p&gt;
    &lt;head rend="h3"&gt;NATHAN J. ROBINSON:&lt;/head&gt;
    &lt;p&gt;Here’s a quote by you from 2018:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Cryptocurrencies, although a seemingly interesting idea, are simply not fit for purpose. They do not work as currencies, they are grossly inefficient, and they are not meaningfully distributed in terms of trust. Risks involving cryptocurrencies occur in four major areas: technical risks to participants, economic risks to participants, systemic risks to the cryptocurrency ecosystem, and societal risks.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In a 2022 lecture about cryptocurrency on YouTube, you are even more blunt and harsh:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This is a virus. Its harms are substantial. It has enabled billion dollar criminal enterprises. It has enabled venture capitalists to do securities fraud as their business. It has sucked people in. So either avoid it or help me make it die in a fire.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But perhaps before we get to your justifications for these verdicts, you could start by telling us what you think is the best way for the average person to begin to think about what a cryptocurrency is.&lt;/p&gt;
    &lt;head rend="h3"&gt;NICHOLAS WEAVER:&lt;/head&gt;
    &lt;p&gt;Well, I’d start with what it’s supposed to be in theory. So in theory, it’s supposed to be a way of doing payments with no intermediary. So the idea is that if Alice wants to pay Bob a bet for 200 quatloos…&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Hang on, you’ve dropped a word that isn’t a real word. Quatloos is a fictional currency?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;It’s actually specifically a Star Trek reference. So if you want to gamble with your imaginary currency, there should be no intermediary that is responsible for executing the transfer. It’s just direct peer to peer electronic cash. Or at least that’s the idea.&lt;/p&gt;
    &lt;p&gt;Now the problem is: how do you know who has what balance? Electronic cash is actually something we’ve had for decades now. If I want to transfer you money, I use PayPal or M-Pesa or Visa or a wire transfer or this or that. Those all have a central intermediary. And there’s a disadvantage of central intermediaries: They don’t like drug dealers. So as a money transmitter, you are under legal obligations to block a lot of known bad activity.&lt;/p&gt;
    &lt;p&gt;With cryptocurrencies, the idea is, let’s eliminate the notion of the intermediary by making our balances public, but pseudonymous. So you’re no longer you, you are just some long sequence of random-looking numbers. And let’s create a ledger in the town square so that everybody’s bank balance is public in the town square, but only identified by the pseudonyms.&lt;/p&gt;
    &lt;p&gt;So for Alice to pay off her wager, she writes a check: “I, Alice’s Random Pseudonymity, pay Bob’s Random Pseudonymity 200 quatloos. Signed, Alice’s Random Pseudonymity.” Bob then checks to make sure that Alice indeed has a balance, and if so, posts that check to the public ledger. Now everybody knows that Alice is down 200, Bob is up 200. And that’s how it works.&lt;/p&gt;
    &lt;p&gt;The problem is: how do you keep somebody from adding to the ledger and faking stuff? Well, that’s where the notion of the “mining” comes in. What the miners are doing is literally wasting tons of electricity to prove that the record is intact, because anybody who would want to attack it has to waste that similar kind of electricity.&lt;/p&gt;
    &lt;p&gt;This creates a couple of real imbalances. Either they’re insecure or they’re inefficient, meaning that if you don’t waste a lot of energy, someone can rewrite history cheaply. If you don’t want people to rewrite history, you have to be wasting tons and tons of resources 24/7, 365. And that’s why Bitcoin burns as much power as a significant country.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;So this criticism that you hear about Bitcoin, that it uses the energy of a small to mid-sized country, that is true? You point out in your YouTube lecture that there are a number of ways that the enthusiasts of Bitcoin make excuses for this. They say “Well, it’s actually clean” or “It’s not too much of a problem.” But it’s actually very, very wasteful.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yes. The biggest one is “this incentivizes green power.” Which it does in the same way that a whole bunch of random shootings would incentivize bulletproof vests.&lt;/p&gt;
    &lt;p&gt;But wait, it’s worse! The problem with the Global Public Square is that it is a single, limited entity, and you have only so much you can add to it at any given time. So Bitcoin burns that much of the world’s electricity to be able to process somewhere between three to seven transactions per second across the entire world.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;That’s not many.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;It’s not many. And worse, it never could work for payments. So we’ve seen waves come and go of companies saying “We’ll accept payments in Bitcoin.” They’re lying. Because they aren’t actually accepting payments in Bitcoin. They are using a service that allows them to price in dollars, presents Bitcoin to the customer, transfers the Bitcoin, turns it into dollars, and so the merchant is getting actual money. Which means if the system has to balance and you want to buy with Bitcoin and you don’t have Bitcoin, you have to convert dollars to Bitcoin. And this is, by design, a horribly expensive process, because Bitcoin and the cryptocurrencies are fundamentally incompatible with modern finance.&lt;/p&gt;
    &lt;p&gt;Modern finance has this rule that anything electronic needs to be reversible for short periods of time. This allows an undo in case of fraud. Have you had your credit card compromised before? I’ve had my credit card numbers stolen a couple of times. The amount of money I lost is zero. Because we have both good fraud protection and good ability to reverse transactions. That does not exist in the cryptocurrency space. If your cryptocurrency wallet is compromised, all your apes are fudged.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;All your what, sorry?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Your apes are fudged. Because the cryptocurrencies are often used for buying these “non-fungible tokens” that have pictures of ugly little apes. They just get liberated. But the result is, you cannot store cryptocurrency on an internet-connected computer. Because what will happen is, if your computer ever gets compromised, all your money gets stolen and there’s nothing you can do about it.&lt;/p&gt;
    &lt;p&gt;And that’s a fundamental problem. But it just doesn’t work for payments because of that throughput limit. And the volatility means you get people converting it to real money. And so what is it good for?&lt;/p&gt;
    &lt;p&gt;Well, there are classes of payments that the intermediaries don’t allow. The big ones are drug dealing, child sexual abuse material, and ransoms. As a consequence, the cryptocurrency actually used for payments is really only used seriously for: ransomware payments, where companies have to pay $10 million. Drug deals—drug dealers hate it, but it’s the only game in town. And we’ve had cases of websites selling child exploitation material paid with Bitcoin.&lt;/p&gt;
    &lt;p&gt;And the reason I’ve gotten so sour on the cryptocurrency space is the ransomware. It’s doing tens to hundreds of billions of dollars worth of damage to the global economy. And it only exists because people can pay in Bitcoin.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;How does ransomware work, for people who aren’t familiar?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;So the way it works is that some bad guys in Russia break into, say, Colonial Pipeline. They encrypt all the data and say “Hey, Colonial Pipeline, pay me 5 million bucks or your data’s gone forever.” And Colonial Pipeline pays the 5 million bucks and is offline for a while anyway, and there are gas disruptions on the East Coast.&lt;/p&gt;
    &lt;p&gt;That exists only because there’s the ransomware payment method of cryptocurrency. Because the alternatives are cash or bank transfers. The banks will not allow payments of 5 million bucks to known criminals in Russia. (Gee, I wonder why.) And if the known criminals in Russia want to pick up a $5 million block of cash, well, that’s a 50 kilogram suitcase that they’re going to have to pick up, and when they go to pick it up they might just get a .308 caliber gift courtesy of the U.S. Marines. And so Bitcoin is the only game in town for them.&lt;/p&gt;
    &lt;p&gt;So it doesn’t work for payments. And it doesn’t work economically either. It’s effectively a giant self-assembled Ponzi scheme. You hear about people making money in Bitcoin or cryptocurrency. They only make money because some other sucker lost more. This is very different from the stock market.&lt;/p&gt;
    &lt;p&gt;I’m a savvy investor, and by “savvy investor,” I mean I put my money into index funds and ignore it for several years. During that time, there are dividends and share buybacks where the companies put their profits into me. I then eventually sell it to somebody else. And my gain is not just the difference between what I bought it for and what somebody else bought it for, but that plus the benefit of all the dividends and interest.&lt;/p&gt;
    &lt;p&gt;So the stock market and the bond market are a positive-sum game. There are more winners than losers. Cryptocurrency starts with zero-sum. So it starts with a world where there can be no more winning than losing. We have systems like this. It’s called the horse track. It’s called the casino. Cryptocurrency investing is really provably gambling in an economic sense. And then there’s designs where those power bills have to get paid somewhere. So instead of zero-sum, it becomes deeply negative-sum.&lt;/p&gt;
    &lt;p&gt;Effectively, then, the economic analogies are gambling and a Ponzi scheme. Because the profits that are given to the early investors are literally taken from the later investors. This is why I call the space overall, a “self-assembled” Ponzi scheme. There’s been no intent to make a Ponzi scheme. But due to its nature, that is the only thing it can be.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Is that why you see the pile of Super Bowl ads for investing in cryptocurrency? Because the people who are the early investors need to keep finding new suckers and trying to convince people that putting their retirement savings into cryptocurrency is a sound idea?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yep. Because it’s a self-created pyramid scheme, you have to keep getting new suckers in. As soon as the number of suckers dries up, it collapses. And because it’s not zero-sum, but deeply negative-sum, there are actually a lot of mechanisms that can cause it to collapse suddenly to zero. We saw this just the other day with the Terra stablecoin and the Luna side token. This was basically another Ponzi scheme implemented in the larger space of Ponzi schemes.&lt;/p&gt;
    &lt;p&gt;So the idea is, you had these two cryptocurrencies, “Terra” and “Luna.” Terra is supposed to be tied one-to-one with the U.S. dollar. Luna can float around. If Terra costs more than $1, you can turn Luna into Terra and make a profit, while if Terra costs less than $1 you can turn Terra into Luna and make a profit. But this only works as long as the value of Luna is greater than the value of Terra.&lt;/p&gt;
    &lt;p&gt;Now, why would you use Terra at all? Well, one, this is a stablecoin and these are necessary for the gambling aspects of cryptocurrency. They act basically as casino chips, because almost all of the cryptocurrency exchanges are really cut off from the banking system. But the other reason is, because you could take your Terra stablecoin, put it in a lending protocol that was created by the creators of Luna and Terra and get a 20% rate of return paid for by Luna and Terra, a.k.a. a Ponzi scheme.&lt;/p&gt;
    &lt;p&gt;And so billions of dollars of notional value went into this Ponzi scheme. And the backing of Luna just slowly crept down, down, down. And then all of a sudden, there was a crisis of faith. People no longer believed that Terra was worth $1. It pegged to 95 cents. The folks behind Terra and Luna go “Everything’s fine. Nothing to see here.” And then it collapsed amazingly quickly over the space of two to three days. And we’re now at the point where the Terra stablecoin that was supposed to be worth $1 is now worth 10 cents, and the Luna token has basically gone down by 99.99%. And people keep finding out that just because something’s gone down 95% doesn’t mean it can’t still go down another 95%.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;What about the other major “stablecoin,” this “Tether”? Is that subject to the same kinds of risks?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yes and no. It is subject to the same kind of risks, but it’s different. It doesn’t have this algorithmic collapse model, but it does have the potential for bank runs causing collapse, because it’s unbacked.&lt;/p&gt;
    &lt;p&gt;Tether is almost certainly what we’d call a “wildcat bank.” So, back in the 1800s, we didn’t have the Federal Reserve. Do you ever wonder why those pieces of paper in your pocket are technically called “bank notes”? It’s because the original model was not the government issuing pieces of paper. The government only issued coins. But heavy or bulky coins are hard to deal with. So you take your coins to the local bank, and they would give you a banknote, literally an IOU saying “if you want a $1 gold coin, take this IOU back to the bank and you get this dollar gold coin.”&lt;/p&gt;
    &lt;p&gt;What happened is, basically, fraudulent banks sprang up. They were called wildcat banks because they’d often have animal pictures on the bank notes. What they would do is take deposits and issue pieces of paper, completely unbacked. And when state bank regulators would come along, the wildcat banks would have barrels of coins that were fake. All but the top layer was just junk, with a top layer of gold coins. Or they’d cart around a barrel to all the branch offices just ahead of the inspectors.&lt;/p&gt;
    &lt;p&gt;And Tether is clearly doing the same thing. Because if Tether was backed by real money, this would mean that there is some $80 billion worth of money from institutional savvy investors that wanted to invest in the cryptocurrency space, but didn’t want to just buy in CoinBase. So they had to go to this third party that has been caught lying about its reserves, run by who-knows-who—the CEO is basically MIA. [Slate reported in 2021 that he “hasn’t been seen in public in years.”] It keeps its reserves in the Bahamas. Why would you invest that way? It’s just complete nonsense.&lt;/p&gt;
    &lt;p&gt;So what’s really almost certainly happening with Tether is Tether creates new Tether tokens, loans them to their big colleagues in the cryptocurrency space—so Alameda Research and a couple of others like that. Alameda Research provides IOUs so Tether says they’re backed by loans. Then Alameda goes out and buys Bitcoin, driving up the price. And now the Tether is backed by Bitcoin. And so Tether in the end is backed by underlying cryptocurrency.&lt;/p&gt;
    &lt;p&gt;They refuse to get audited. [Bloomberg reported that Tether CFO, an Italian former plastic surgeon, was “urged … to hire an accounting firm to produce a full audit to reassure the public,” but “said Tether didn’t need to go that far to respond to critics.”] They refuse to even do more than the most basic attestation, which is literally “Here, accountant, sign this.” We’re honest, Scout’s pledge. It’s just a house of cards. And the problem is that when these houses of cards fail, they fail so catastrophically and so swiftly that things go from being worth $1 to being worth nothing in the space of three days.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;I want to zoom out again to talk about cryptocurrency in general and go back to some of the broad critiques you have. Is it accurate to summarize what you were saying before as, essentially: There is no problem that cryptocurrency solves, and to the extent that it is functional, it does things worse than we can already do them with existing electronic payment systems. To the extent it has advantages, the advantage is doing crimes. And every other claim made for the superiority of cryptocurrency as currency falls apart if you scrutinize it.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yes. So let’s take the cost of a transaction. The cost of a transaction in cryptocurrency systemically is the amount being used to protect it. I could build a system that would have the same throughput as Bitcoin, three to seven transactions per second, but with a centralized trusted entity. In fact, not even a centralized trusted entity. Ten trusted entities, only six of which need to be honest, because I use a majority vote system. I could do it on ten computers that look like this, that would burn as much power as a light bulb.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;For listeners and readers, he is holding up a tiny … uh, what is that?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;I am holding up a Raspberry Pi computer module. This entire computer is like 50 bucks. So for 500 bucks worth of [computing power], I could do the same functionality as Bitcoin, with just 10 named entities. Why don’t I do this? Because those 10 named entities would have to follow money laundering laws. And apart from getting a structure where the named entities don’t follow money laundering laws, there’s no advantage for the cryptocurrencies, despite burning nine orders of magnitude more power.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;One of the kind of jaw-dropping moments in your YouTube lecture is when you show just how wasteful this is, how easily you could do the exact same thing, and not have this pathetic three to seven transfers per second all around the world.&lt;/p&gt;
    &lt;p&gt;You do note that it suggests that Elon Musk—who is touted for the electric cars that are supposedly going to be an important contribution to stopping climate change, but has invested billions of dollars of Tesla’s money in Bitcoin—probably isn’t that serious or consistent about reducing our carbon emissions.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Phony Stark over there has a walking talking Dunning-Kruger syndrome going and his investment in cryptocurrency is clearly one of those. The cryptocurrency that he often highlights is Dogecoin. Dogecoin was a literal joke invented in the early days of cryptocurrency about, “Hey, this stuff is so stupid. Let’s make a coin about a meme of a talking dog.” The founder of Dogecoin says, “This is a joke, avoid the cryptocurrency space, it is total garbage.” [Note: Dogecoin creator Jackson Palmer concluded: “After years of studying it, I believe that cryptocurrency is an inherently right-wing, hyper-capitalistic technology built primarily to amplify the wealth of its proponents through a combination of tax avoidance, diminished regulatory oversight, and artificially enforced scarcity.”] This joke is now the 10th most valuable cryptocurrency.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;I am sure you have heard people say things like “Well, blockchain technology itself has lots of potential applications, it’s really interesting, offers lots of possible solutions to problems.” But one thing you point out in your lecture is that often, they are pretty vague about what these uses are, and usually when you get down to the facts, there’s a much simpler solution to whatever problem it is that wouldn’t use blockchain. You cited the example of someone who touted how blockchain could help with vaccines in India.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;So the thing is, the idea behind a blockchain is actually a 30-plus-year-old idea. It’s called a hash chain. And we’ve known how to build these for longer than most of my students have lived. But people who spout “Blockchain!” don’t understand the technology. This [the vaccines suggestion] was a concrete example that made me create [Weaver’s Iron Law of Blockchain], which is: When somebody says you can solve X with blockchain, they don’t understand X, and you can ignore them.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;So it’s useful in that sense.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yes, it is useful as a filter [to know if people know what they’re talking about]. So, this was an example given by a purported expert in a blockchain class at Berkeley: Okay, we have the cold chain problem. Vaccines, you need to ship cold, and if they ever get out of temperature spec, you have a ruined batch. And we can solve this with blockchain.&lt;/p&gt;
    &lt;p&gt;And my reaction is: No. The problem is you need to know when it got out of spec, and know that the receiver can know that it had gotten out of spec. And there’s an easy solution. It’s called a $1 ShockWatch label. So the ShockWatch group makes these temperature labels. You stick them on the package. And if it ever gets too warm, the color changes. No blockchain necessary.&lt;/p&gt;
    &lt;p&gt;The fact that somebody was purporting this to be a real-world application meant they had not even thought about the problem for five seconds. They had no familiarity with how cold chain works. They had no familiarity with how the sensing process works.&lt;/p&gt;
    &lt;p&gt;We see the same thing when people talk about cryptocurrency being able to “bank the unbanked.”&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Oh, yeah, that’s a big argument for it. This is going to be very useful in the developing world.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;If you take any of these people and you ask them what M-Pesa is, they will look at you like you’re speaking [Swahili]. Because, well, you are. So for those who aren’t familiar, M-Pesa is a payment system started in Kenya by Vodafone about the same time as Bitcoin. [Note: Pesa is Swahili for money, and the “m” stands for “mobile.”] It has eaten the Third World. It’s huge. Because it just basically attaches a balance to your phone account. And you can text to somebody else to transfer money that way. And so even with the most basic dumb phone you have easy-to-use electronic money. And this has taken over multiple countries and become a huge primary payment system. [Whereas] the cryptocurrency doesn’t work.&lt;/p&gt;
    &lt;p&gt;So, El Salvador. The president of El Salvador is a totalitarian nutcase. And one of the things he did as a totalitarian nutcase is pass a law saying Bitcoin is legal tender. But you aren’t actually using Bitcoin. Instead, they created a new wallet, the Chivo wallet, that’s an electronic payment channel that takes Bitcoin and dollars and just updates your balance in a central database. It’s not actually doing a transfer. And the Bitcoin folks like to go, “Oh, but there’s this lightning network thing that allows these layer two transfers in a trustless environment, so you aren’t trusting the central Chivo app.” That is still limited to adding three to seven people per second globally to the system. So you can’t actually onboard that system. It just doesn’t scale.&lt;/p&gt;
    &lt;p&gt;And so the one case where we’ve had an attempt to do a wide-scale “pay with Bitcoin” system, El Salvador, they gave up and aren’t actually using Bitcoin. They’re using a centralized database in an app. And because the value of the numbers in the centralized database bounces around, nobody actually uses it. People just signed up for the free money, then transferred it, and have since stopped using it. [Note: Seeking Alpha reports that “virtually no downloads [of the Chivo app] have taken place in 2022” and “it seems that people were incentivized to download Chivo given the $30 bonus offered by the government.”] So even when you have a central database and a central authority, cryptocurrencies don’t work for payments, because they bounce around in price.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;One of the things you’ve said, if I recall, is that the cryptocurrency space is “speed-running 500 years of financial history.” By which I take you to mean that all of the financial disasters of centuries past are playing out in short order, and then they have to rediscover the solutions that were put in place for those things not to happen. So you start off thinking, “Oh, wouldn’t it be fantastic if there were no central authority?” and then all of a sudden you realize, “Actually, it really would be nice if we had a central authority to regulate fraud and such” and you rediscover the virtue of banks and government.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yeah. Cryptocurrency: teaching libertarians about market failure since 2009. The thing is, though, the cryptocurrency space itself has the object permanence of a horny mayfly. They simply don’t remember their own scams.&lt;/p&gt;
    &lt;p&gt;So Ponzi schemes in the cryptocurrency space have existed since 2012, 2013. Back in those days, a huge amount of Bitcoin—10% of all Bitcoin at the time—got invested into a Ponzi scheme. This Ponzi scheme was so big in the cryptocurrency space that the editor of the Bitcoin magazine bet $90,000 that it wasn’t a Ponzi scheme. And so the investors in the Ponzi scheme were then taking the other side of that bet in order to protect themselves. So, when the Ponzi scheme inevitably failed, well, they were out their money, and the bets didn’t pay off because the editor of Bitcoin magazine didn’t have the money. But it gets better. Guess what the name of the guy running the Ponzi scheme was? “Pirate@40.” Ten percent of all Bitcoin at the time got invested into a Ponzi scheme run by a guy calling himself Pirate@40.&lt;/p&gt;
    &lt;p&gt;And then they keep repeating it. So like Celsius as a system is clearly Ponzi economics. They’re claiming 10 to 20% rate of return lending out cryptocurrency. The only way they can be providing that is by providing either money from venture capital or money from previous investors. It’s a self-created Ponzi scheme.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Can we discuss “smart contracts”? I don’t understand what these are.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;A smart contract is not a contract. The theory behind smart contracts is “code is law.”1So let’s do programs that cannot be updated that handle money. Now, we’ve had programs that handle money for decades now. So I’m a savvy investor, I have an index fund, my index fund is run by a computer that’s running a fairly simple set of programs, trading on my behalf to make sure it matches the index.&lt;/p&gt;
    &lt;p&gt;Now, there’s two things about that program: It’s not generally accessible to the internet, so no random person can go up to it. And it’s running on a fabric that’s reversible. So if there’s a catastrophic screw up, you get the people involved and can undo the mess.&lt;/p&gt;
    &lt;p&gt;The smart contracts really are computer programs that operate on money. But there’s a few riffs on them. There’s no mechanism to fix problems if they occur. There’s no undo button. In fact, there’s often no way to upgrade at all. So if a bug is found, you’re out of luck. They are written in a truly awful set of programming languages, but that’s just the icing on the cake. And any random person in the world can interact with them.&lt;/p&gt;
    &lt;p&gt;And so the question is: if I can go up to a “smart contract” and say, “Hey, smart contract, give me all your money” and it does, is that even theft? But catastrophic theft and catastrophic bugs occur all the time. So the first smart contract, the DAO, back in 2016, was “Hey, let’s make a voting distributed mutual fund.” So anybody can invest in the DAO and get a say in how we invest the money. Ten percent of all Ethereum got invested in the DAO. And it basically got invested because it’s got a cool name. And it was basically a self-assembling Ponzi scheme.&lt;/p&gt;
    &lt;p&gt;What happened is: somebody realized there was a bug in it, where what they could do is do a deposit, then a withdrawal, then that withdrawal they could withdraw again and again and again recursively. Because what would happen is it would transfer the money, then decrement the balance, but in transferring the money you could trigger another withdrawal. So you would basically be able to withdraw a gazillion times, then the balance gets decremented. And, oops, all the money’s gone. And so somebody did this. So the first smart contract of note failed catastrophically due to a bug. Yet they keep doing this over and over and over again.&lt;/p&gt;
    &lt;p&gt;And as a bonus, remember that whole “code is law” business? No central authorities [the code determines the outcome]. That’s a lie. Because the developers of Ethereum have their 10% in this self-assembled Ponzi scheme. So they updated the code to steal all the money back.&lt;/p&gt;
    &lt;p&gt;The reason why I say it’s rerunning half a millennium of failure is that at the start, there’s a huge amount of “tulip mania.” Back in 2018, we had a tulip mania of these deformed cats called “crypto kitties” that shut down Ethereum. Now we have a tulip mania of these deformed apes that shut down Ethereum, because of course it can’t really do all that much. And so the thing is, there’s just no object permanence in the space. They don’t remember their old mistakes. And so they just keep making them over and over again.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;I suppose we have to talk about the apes. I really, really don’t get this NFT thing. I really don’t understand what people who pay large sums of money think they’re getting. I don’t know how you can own a JPEG without owning the copyright to it. I don’t know what you’re buying. What is this? Can you tell me how this fits into the picture and the best way to conceive of it, as a normal person?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;So most of the NFTs are as follows: A bunch of computer generated variants are created. They’re put up on a web page. I sell you a receipt to a URL that says you theoretically own this receipt. And that’s it. You can trade this receipt to somebody else. By default, an NFT gives you no rights. It is literally just a receipt for your purchase that you can trade to somebody else.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Can I just stop you? I want to break this down. What does “own” mean?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;You have a receipt that says “I am the owner of this.”&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;But what does it mean to “own” it?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;You can sell that receipt to somebody. Now, the apes are a little bit different. Because there is a part outside of the smart contract for the apes, which is that you have a license to make as many derivative works as you like of the apes you own as long as you own it. And that is actually pretty unique. Most of the NFTs don’t offer that option. The apes do. So what ends up happening is the big market for the apes is for people to make derivative apes. So buy four or five ape NFTs, use that to create the base for 400 to 500 algorithmically-derived alternate apes, like caked apes or spaced apes or apes that eat their “slurp juice” or whatever, to create more derivative apes that you then sell to more suckers.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;So they’re like baseball cards, essentially? You have to convince people there’s some pleasure in owning these things, or that they’re going to go up in value?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;That they’re going to go up in value. The only part of it that isn’t [speculation] is the conspicuous consumption, like “Oh, I’ve got the Rolex.” But the problem is the ownership is so weak that all you have to do is right-click “save” and you have your own copy. So Elon Musk inadvertently, I hate to say it, but he actually did something right. He showed the whole stupidity of this place by temporarily putting his profile portrait to a collage of apes he didn’t own.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Which shows you that “ownership” really does not mean terribly much, because the people who own those apes can’t enforce a copyright claim against him for doing that.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;No, because the copyright is still owned by Bored Ape Yacht Club, and the owners of the apes just have licenses to be able to produce derivative works.&lt;/p&gt;
    &lt;p&gt;Also, the other thing is: they’re ugly!&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;They’re really, really hideous.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;The actual usability of the intellectual property outside the space of the lunatic ape collectors is zero. So like MeUndies, which is a company that does underwear, bought themselves a Bored Ape, and they were going to make Bored Ape underwear with the ape. The backlash was so swift that they gave up and sold their ape because the intellectual property was useless.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;We’ve talked about a lot of different aspects of what is called the “cryptocurrency space.” We’ve talked about the inefficiency, the volatility, the way that “irreversibility” is touted as a feature but in fact enables fraud and ransom. We’ve talked about the environmental destruction. One other thing I wanted to ask you is: you said in your lecture that cryptocurrency enables venture capitalists to “carry out securities fraud as a business model.” Could you explain what you mean by that?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;So there are a lot of securities regulations out there. And the definition of “security” is very broad. It dates back to the Howey Test in the Great Depression era. That happens to be one of the cleanest legal tests ever for “Is this an investment contract?” and therefore a security that should be regulated by securities regulators. It’s very much “if it walks like a duck and quacks like a duck and swims like a duck and flies like a duck, it’s a duck.”&lt;/p&gt;
    &lt;p&gt;So in the old days, like a few years ago, you’re Andreessen Horowitz, you invest in several companies. And these companies get to a point where either they implode and you lose your money, or they get bought by a bigger company, and you make a profit, or you go public. But in order to go public, you have to do a lot of paperwork. Basically, you have to do honest financial disclosures, etc.&lt;/p&gt;
    &lt;p&gt;But how they work now is basically securities fraud by inducement. So they invest in a cryptocurrency-related company. They strongly encourage that cryptocurrency company to issue a token that acts as a promise for some eventual service, like say dental care or an orange tree in Florida. And they sell that token to the venture capitalists at a huge discount. So the venture capitalists get a huge pile of these tokens. And then what happens is they encourage the company to go out and sell the token to the general public. And ideally they get that token listed on CoinBase, which is partly owned by Andreessen Horowitz. And if not, they just use the decentralized exchanges or whatever.&lt;/p&gt;
    &lt;p&gt;And now the venture capitalist is able to sell their tokens to retail investors. This is blatantly an unlicensed security. This is blatant securities fraud, but they didn’t commit the securities fraud. It was just the companies they invested in that did the securities fraud, and the SEC has not been proactively enforcing this. They only retroactively enforce against the initial coin offerings after they fail. So what will happen is Andreessen Horowitz and company invested in a bunch of startups that all issued tokens, that all got dumped on retail including Andreessen Horowitz dumping a lot of them on retail, and when things fail, the only people to prosecute are the companies, not Andreessen Horowitz itself. So they’ve been able to make securities fraud a business in such a way that they are legally remote, so you will not be able to throw them in jail.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Well, what you said suggests that to some degree they’re working carefully within legal loopholes but also that there are ways in which regulators ought to be stepping up. You wrote an article in Slate with the security expert Bruce Schneier about the way that, without banning cryptocurrency outright, we can regulate it sensibly. So perhaps you could outline what you think is the necessary approach to mitigating the various harms that this is doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;The first thing is, you don’t in many cases need new laws. You just need existing laws to be enforced. So every initial coin offering, every single one of them, checks every box of the Howey Test. The SEC has the authority to stop those proactively rather than reactively. They choose not to.&lt;/p&gt;
    &lt;p&gt;Most of these “decentralized” organizations are not actually decentralized. They are identifiable entities. So when you have regulations that apply to identified entities, like say money transmission laws, apply them to the named entities. Cryptocurrency is pseudonymous, not anonymous. So actually enforce requirements on transfers to make sure that money that’s been contaminated by bad stuff is not allowed. That would disrupt a whole bunch of bad activity.&lt;/p&gt;
    &lt;p&gt;To put it bluntly, the SEC needs to grow a pair. Because this space is provably negative sum. It can only harm investors. Everything in this space, for the most part, ticks boxes for stuff that the SEC is allowed to regulate, which it should regulate.&lt;/p&gt;
    &lt;p&gt;Basically, there’s a fear among regulators—that I think started in the ‘80s—of being accused of “stifling innovation.” There’s no innovation to stifle. So regulate away. Because the problem with the current regulation model is they’re doing “let’s pick up the pieces afterward.” So after the things fall apart we’re going to go pick up the pieces, rather than “Hey, let’s stop things from falling apart in the first place,” which would save billions of dollars of investor money.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;What is the future of cryptocurrency in the absence of changes to existing regulation? Is it doomed inherently through features internal to it? Where’s this going if allowed to follow its own logic?&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;It will implode spectacularly. The only question is when. I thought it would have actually imploded a year ago. But basically, what we saw with Terra and Luna, where it collapsed suddenly due to these downward positive feedback loops—situations where basically the system is designed to collapse utterly and quickly—those will happen to the larger cryptocurrency space. Because, for example, the mining process is horribly expensive. We’re talking [a measurable percentage] of the world’s electricity consumption, most of that has not been paid for. So the mining companies for the most part have been taking the cryptocurrency and borrowing against the cryptocurrency that they create, rather than sell it, because the market’s actually very thin.&lt;/p&gt;
    &lt;p&gt;This means there’s a huge amount that is subject to potentially catastrophic margin calls. And that creates a feedback loop where the price drops a little, somebody’s forced to sell. That drops the price more. They’re forced to sell more. This creates a feedback loop that drives the price into the ground, catastrophically.&lt;/p&gt;
    &lt;p&gt;The previous times this has happened, we had the bubble at 100, powered by fraud at Mt. Gox. And that imploded down to 10. We had a bubble a 1000 powered by fraud, it imploded and went back down to 100. We had a bubble at 10,000 powered by Tether, it blew up and went back down to 1,000. And now we’re at a bubble where Bitcoin blew up to 60,000, fueled by Tether and falling. But I don’t think there’ll be a fifth bubble. Because basically, they will have broken all the suckers left to break. There’s only so many more suckers that can be brought into that space. Once you burn out a sucker, they don’t come back. They’re a non-renewable resource. So they’re going to end up running out of greater fools.&lt;/p&gt;
    &lt;p&gt;So I suspect that the cryptocurrency space will go fine absent regulation, until one day it goes and collapses greatly.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;What you said about finding suckers, I think I’d like to end on this. Because I was in New York City recently on the subway, looking around at the ads, and a bunch were for investing in some new crypto thing. They were encouraging people to put their money in, saying it was a safe investment. And I mentioned the Super Bowl ads earlier. And I think the thing that it might be worth emphasizing is when we say “sucker,” we’re talking about people being taken advantage of. When you talk about the ransomware, the fraud, the child exploitation material, when you talk about people who put their savings into these things, even leaving aside the environmental destruction, we’re talking about pain being inflicted upon people by the proliferation of this.2&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Yes. That’s the problem, and that’s why I’ve actually changed my view over the past decade. Back in 2013, I thought it was amusing and silly, and I could get cool papers out of it. In 2018, I thought it was amusing, but pretty bad. [In 2022], it’s time to really think about burning it down. Now I just want to take the entire cryptocurrency space and throw it into the sun. I know astronomers will tell you it’s easier to throw something into the void of space than to throw it into the sun. But it’s worth the extra energy to make sure some alien doesn’t find this mental virus.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Well, good luck. You’re battling Bill Clinton and Tony Blair, who both showed up at a cryptocurrency conference recently.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;And I bet they got paid in actual money. Like, the Washington Nationals just the other day started doing a lot of tweets for their business relationship with Terra. That was $5 million for five years prepaid in advance in cash. So for the next five years, the Washington Nationals are obliged to hype a cryptocurrency that failed spectacularly already.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;But they got their money.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;They got their money. They just have to hype it now. For five years.&lt;/p&gt;
    &lt;head rend="h3"&gt;ROBINSON:&lt;/head&gt;
    &lt;p&gt;Well, Professor Weaver, thank you so much for joining me and explaining this. There’s so much bullshit to wade through and there are so few people who are talking about this in a really intelligent way and I really appreciate your work. Good luck with your mission to throw it into the flames.&lt;/p&gt;
    &lt;head rend="h3"&gt;WEAVER:&lt;/head&gt;
    &lt;p&gt;Thank you very much for having me.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Olga Mack of Above the Law explains this notion further: “My blockchain colleagues, especially the more technical ones, use the phrase “code is law” to suggest that code—for example, a software that usually underlies a smart contract—will one day in the future replace law. They believe that code will one day be the final authority. Accordingly, if a code has an inadvertent glitch and performs in an unexpected, perhaps unfair way, they would shrug their shoulders and respond: ‘Well, code is law.’” ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Terra/Luna subreddit has recently been full of desperate people panicking and even discussing suicide after losing all their assets in the collapse. Crypto critic Stephen Diehl comments that “Any returns people make on crypto investments are zero-sum and dripping in human suffering. There’s likely a dozen people (some with gambling problems) who lost everything on the other side of a dog coin trade.” ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.currentaffairs.org/news/2022/05/why-this-computer-scientist-says-all-cryptocurrency-should-die-in-a-fire"/><published>2026-02-04T16:59:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888331</id><title>Converge (YC S23) Is Hiring Product Engineers (NYC, In-Person)</title><updated>2026-02-04T19:31:36.568753+00:00</updated><content>&lt;doc fingerprint="a508c173dc07a7a8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Product Engineer&lt;/head&gt;
    &lt;p&gt;Location: NYC (in-person)&lt;/p&gt;
    &lt;p&gt;Help us build everything a consumer brand needs to grow. Weâre just 4 engineers with serious traction (well beyond $1M ARR). Youâll be shipping end-to-end product and working directly with customers.&lt;/p&gt;
    &lt;head rend="h3"&gt;About Converge&lt;/head&gt;
    &lt;p&gt;We want to profitably grow the world's consumer brands. That begins with helping them understand which marketing efforts are driving profitable growth.&lt;/p&gt;
    &lt;p&gt;200+ consumer brands, including publicly traded companies, rely on Converge to check in on their marketing performance up to a dozen times a day. They drill down to figure out what's working and decide where to shift million-dollar marketing budgets.&lt;/p&gt;
    &lt;p&gt;To ship even more, we've raised $5.7M from some of the best investors, including Y Combinator, General Catalyst, and the founders of Posthog, Algolia, Shipbob, ...&lt;/p&gt;
    &lt;head rend="h3"&gt;What you'll do&lt;/head&gt;
    &lt;p&gt;Ship product fully end-to-end. All the way from designing the system and data models to building out the interface and polishing the experience.&lt;/p&gt;
    &lt;p&gt;We trust you to build the best solution to a customer's problem. We lead with context and give you full autonomy to design the solution. This means you'll need to build a deep understanding of the problem, obsess over the solution, and ship it.&lt;/p&gt;
    &lt;p&gt;Work directly with customers. You'll talk to them, ship, get feedback, and iterate. There are no middlemen. This means you can move incredibly fast: you message a customer, create a PR, and can have it fixed within hours.&lt;/p&gt;
    &lt;p&gt;Some examples of projects you could own:&lt;/p&gt;
    &lt;p&gt;Effortless Slack conversations: Customers screenshot their Converge reports up to a dozen of times a day (!) to share with the rest of the company. Instead, they should be able to directly tag and message a teammate from any number in Converge and have this synced bidirectionally with Slack.&lt;/p&gt;
    &lt;p&gt;Centralizing all growth efforts: Converge already centralizes all growth metrics, but the information explaining them is still scattered. We want overlay the context that actually explains trends like pricing updates, budget changes, and promo calendars.&lt;/p&gt;
    &lt;p&gt;Creative analytics: All growth teams use a separate tool to iterate on ad creatives, but they would want to run this workflow on Converge. We should build a Creative Analytics product on top of our data.&lt;/p&gt;
    &lt;p&gt;AI agents: We never wanted to jump on the AI train for the sake of hype. But now that we have the foundations in place, there's huge leverage in building agents that can help growth teams understand their data and act on it more quickly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Converge&lt;/head&gt;
    &lt;p&gt;We're a team of just 4 engineers with serious traction (well beyond $1M ARR). Join us if you want to get rid of office politics and just take ownership to get a lot done.&lt;/p&gt;
    &lt;p&gt;Even though you join early, this job comes with real engineering challenges. We process $4B in online orders annually, 20TB of data flows through Converge each month, and we've collected around 10B customer interactions to date.&lt;/p&gt;
    &lt;p&gt;What you're shipping will actually get used. 50% of our customers use us daily (!), while this is only 13% for the average SaaS company. You will have an immediate impact.&lt;/p&gt;
    &lt;p&gt;We love working in-person. You'll like it here if you do too.&lt;/p&gt;
    &lt;p&gt;If you think you could be a founder, there's no better way to learn than to talk to customers and ship. That's what you'll be spending all of your time on. We obsess over the details and will share honest feedback.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we're looking for&lt;/head&gt;
    &lt;p&gt;Strong experience working across the stack (4+ YOE). We work with React, Python, Postgres, and Clickhouse. Experience building data-intensive products or familiarity with Clickhouse is a plus.&lt;/p&gt;
    &lt;p&gt;You've previously built products or large features fully end-to-end.&lt;/p&gt;
    &lt;p&gt;You obsess over the quality of what you're building, both in UX and code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compensation&lt;/head&gt;
    &lt;p&gt;Salary: $175K - $240K + equity (0.6% - 0.85%).&lt;/p&gt;
    &lt;p&gt;Private health, dental, and vision insurance.&lt;/p&gt;
    &lt;p&gt;Pension &amp;amp; 401k contributions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Interview process*&lt;/head&gt;
    &lt;p&gt;Intro call (30 min): We want to learn about your motivations to join Converge, determine why youâd be a great fit, and answer any questions you have for us.&lt;/p&gt;
    &lt;p&gt;Technical (1h): We work through a typical engineering problem we face at Converge.&lt;/p&gt;
    &lt;p&gt;Culture (45 min): We dive into your past experiences to learn how you like to work and what motivates you.&lt;/p&gt;
    &lt;p&gt;Superday (1 day): Join us for a day to actually build something! You get to meet the team, we get to meet you, it's great. (fully paid)&lt;/p&gt;
    &lt;p&gt;(*) This can all be done in 2 days. If you want to move quickly, we do too. Our founding engineer was on a plane to meet us just days after our first call.&lt;/p&gt;
    &lt;head rend="h2"&gt;We raised $5.7M from some of the best investors&lt;/head&gt;
    &lt;head rend="h3"&gt;James Hawkins&lt;/head&gt;
    &lt;head rend="h3"&gt;Nicolas Dessaigne&lt;/head&gt;
    &lt;head rend="h2"&gt;Founding team&lt;/head&gt;
    &lt;head rend="h2"&gt;How we started&lt;/head&gt;
    &lt;head rend="h3"&gt;Did you knowâ¦&lt;/head&gt;
    &lt;p&gt;All co-founders have written code that has run in production as part of Converge.&lt;/p&gt;
    &lt;p&gt;We closed our first publicly traded company during our YC batch from our living room in San Francisco.&lt;/p&gt;
    &lt;p&gt;Thomas and Tiago (Founding Engineer) worked together when Thomas was just an intern.&lt;/p&gt;
    &lt;p&gt;Michel (Customer Success) was responsible for most of the incoming Converge Support tickets in his previous job as a freelance tracking consultant.&lt;/p&gt;
    &lt;p&gt;Thomas and Jan were best friends in high school, and Jan and Jerome met in their first year of college.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.runconverge.com/careers/product-engineer"/><published>2026-02-04T17:01:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888339</id><title>Launching the Rural Guaranteed Minimum Income Initiative</title><updated>2026-02-04T19:31:36.337457+00:00</updated><content>&lt;doc fingerprint="7248814f1fa507ac"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Launching The Rural Guaranteed Minimum Income Initiative&lt;/head&gt;
    &lt;p&gt;It's been a year since I invited Americans to join us in a pledge to Share the American Dream:&lt;/p&gt;
    &lt;quote&gt;1. Support organizations you feel are effectively helping those most in need across America right now.&lt;lb/&gt;2. Within the next five years, also contribute public dedications of time or funds towards longer term efforts to keep the American Dream fair and attainable for all our children.&lt;lb/&gt;Stay gold, America. 💛&lt;/quote&gt;
    &lt;p&gt;Personally, I’ve become a big believer in one particular quote, especially considering the specific context in which it was delivered:&lt;/p&gt;
    &lt;quote&gt;“From those to whom much is given, much is expected.” — Mary Gates&lt;/quote&gt;
    &lt;p&gt;Those 10 words had a profound effect on the world. Indeed, we were given much, so we, as a family, will choose to give much. On a recent podcast, my partner Betsy said it better than I could have:&lt;/p&gt;
    &lt;quote&gt;“Well, we have everything we need!” That’s how I’ve always phrased it to [our children]. That, I think, extends [to our philanthropy]. We have everything we need; how do we make sure everybody has what they need? Because that’s the basic thing — Do you have a comfortable place to live? Do you have enough to eat? Do you have healthcare? If you have the basics, you’re in a good place in life, and everybody should have that opportunity.&lt;/quote&gt;
    &lt;p&gt;It’s a question I’ve asked myself a lot since 2021. When, exactly, is enough?&lt;/p&gt;
    &lt;p&gt;We do have everything we need. Why can’t everyone else have the basic things they need, too?&lt;/p&gt;
    &lt;p&gt;Beyond the $1M to eight nonprofit charities we listed in January 2025, we saw immediate needs becoming so urgent that we quickly added an additional $13M in donations within a few months, for a total of $21M.&lt;/p&gt;
    &lt;head rend="h4"&gt;Immediate Share The American Dream Donations (~$21M)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Team Rubicon — $1M&lt;/item&gt;
      &lt;item&gt;Children’s Hunger Fund — $1M&lt;/item&gt;
      &lt;item&gt;PEN America — $1M&lt;/item&gt;
      &lt;item&gt;The Trevor Project — $1M&lt;/item&gt;
      &lt;item&gt;NAACP Legal Defense and Educational Fund — $1M + $100k&lt;/item&gt;
      &lt;item&gt;First Generation Investors — $1M&lt;/item&gt;
      &lt;item&gt;Global Refuge — $1M&lt;/item&gt;
      &lt;item&gt;Planned Parenthood — $1M&lt;/item&gt;
      &lt;item&gt;VoteVets — $2M&lt;/item&gt;
      &lt;item&gt;Mastodon — $1.5M&lt;/item&gt;
      &lt;item&gt;404 Media — $1.1M&lt;/item&gt;
      &lt;item&gt;Ryan Broderick / Garbage Day — $1M&lt;/item&gt;
      &lt;item&gt;Internet Archive — $1M&lt;/item&gt;
      &lt;item&gt;Common Crawl Foundation — $1M&lt;/item&gt;
      &lt;item&gt;Wikipedia / Wikimedia foundation — $1M&lt;/item&gt;
      &lt;item&gt;Internet Security Research Group — $1M&lt;/item&gt;
      &lt;item&gt;DNA Lounge — $1M&lt;/item&gt;
      &lt;item&gt;Murena — $500k&lt;/item&gt;
      &lt;item&gt;Sharewell — $300k&lt;/item&gt;
      &lt;item&gt;Precious Plastic — $100k&lt;/item&gt;
      &lt;item&gt;Economic Security Project — $100k&lt;/item&gt;
      &lt;item&gt;Rural Democracy Initiative — $100k&lt;/item&gt;
      &lt;item&gt;Civic Nation — $100k&lt;/item&gt;
      &lt;item&gt;Sojourn Project — $750k&lt;/item&gt;
      &lt;item&gt;Alameda Food Bank — $150k&lt;/item&gt;
      &lt;item&gt;Urban Compassion Project — $75k&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But you can’t take a completely short term view and fight each individual fire reactively, as it comes. You'll never stop firefighting. We also have to do fire abatement and deal with the root causes, improving conditions in this country such that there aren’t so many fires. Thus for the second half, much longer term part, in addition to the $21M already donated, we pledged $50M — half of our remaining wealth — to address the underlying, systemic issues.&lt;/p&gt;
    &lt;p&gt;I proposed some speculative ideas in “Stay Gold,” and this one ended up being the closest:&lt;/p&gt;
    &lt;quote&gt;We could found a new organization loosely based on the original RAND Corporation, but modernized like Lever for Change. We can empower the best and brightest to determine a realistic, achievable path toward preserving the American Dream for everyone, working within the current system or outside it.&lt;/quote&gt;
    &lt;p&gt;By March, 2025 we had consensus — The Road Not Taken is Guaranteed Minimum Income.&lt;/p&gt;
    &lt;p&gt;Guaranteed Minimum Income (GMI) is an improved version of the older concept of Universal Basic Income (UBI) — rather than indiscriminately giving money to “everyone,” GMI directs the money towards those who most need it, particularly families experiencing generational poverty.&lt;/p&gt;
    &lt;p&gt;📢 Please note that after this post, Coding Horror will revert to normal nerdy blog posts, and all future GMI content will be at a dedicated site linked below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why did we decide on GMI?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Almost every existing UBI/GMI study result data we could find indicates cash generally works. For example, OpenResearch data showed the greatest increase in spending among study participants was in meeting basic needs, with the greatest percent increase in support to others (26%), along with huge decreases in reported alcohol use (20% less) and days using non-prescribed painkillers (53% fewer). Why wouldn’t we continue to build something that has generally been shown to work, study after study, time and time again?&lt;/item&gt;
      &lt;item&gt;This is survival money, cash for folks so they can put food on the table, get a roof over their heads, have a functioning vehicle to go to work, and decide how to meet their most basic, critical needs. It pains me to say this, but we live in a world where many people simply do not often experience open generosity, or regular income. When you show someone what it feels like to just not be hungry for a little while, their view of the world changes. They feel trusted. They see possibility.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;I moved here with my family. And I have no family up here other than who I brought with me. So, how most people can be like, “Hey, I’m having a hard time. Got $20 or a pack of diapers.” I have nobody up here to do that. So, if me and my husband don't figure it out, it don't get figured out.&lt;/p&gt;
      &lt;p&gt;So, I’ve got five kids that live with me... I was working full-time until I got pregnant. I prayed for this baby for 10 years. So, as soon as I got pregnant, I stopped working. I was high risk.&lt;/p&gt;
      &lt;p&gt;The day I got cleared to go back to work, my vehicle broke down. It was the only vehicle that we had that carried all the kids. So, I’ve been four months without my car. So this is also going to get my vehicle back on the road.&lt;/p&gt;
      &lt;p&gt;You don’t know how hard it is to ask people, hey, can I get a ride to the grocery store? Or, hey, my baby has two month shots. I had to borrow a vehicle. This is gonna... it’s going to do a lot!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unlike many other social programs, GMI studies require initiative. These are opt-in studies that you have to sign up for, demonstrate that you meet the income criteria and are a resident of the county — and because spots are limited, be randomly selected from eligible applicants. We emphasize that this is not passive, it is active teamwork to improve the GMI program with your family, your community, and everyone else we can reach together over the next few decades.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Building On What Works&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The massive OpenResearch UBI study, the largest and most detailed guaranteed income study ever conducted in the USA, was designed to be a template for future, more refined studies, and that’s exactly what we’re doing. We will also use what we learn in this group of three counties — as in software, the rule of three — to iterate, adapt, and improve our GMI study playbook with every new group of three counties, generating a playbook anyone can use.&lt;/item&gt;
      &lt;item&gt;We strive to do repeatable, replicable science in every study, and all our data will be open and freely shared with the world. We’re contributing to — and partially funding — a global, open data repository for basic income pilots all around the world, UBIdata. It’s the same reason we made Stack Overflow content part of the creative commons, and Discourse fully open source.&lt;/item&gt;
      &lt;item&gt;GMI is seed funding for families, investing in our fellow Americans, those who need it the most. A large body of research shows that dollars targeted to lower-income families are more likely to be spent quickly and reduce hardship, and can improve outcomes for children. “Trickle up” economics works, whereas "trickle down" tax cuts for the rich increase income inequality and provide no significant effect on growth or jobs.&lt;/item&gt;
      &lt;item&gt;This is the newer trust based model of philanthropy, much closer to venture capital funding. We primarily empower, fund, and build up existing organizations like GiveDirectly and OpenResearch, forming a collaborative team to leverage all their existing work and grow their organizations in whatever way they see fit, because they have the most experience in the GMI space.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Rural Guaranteed Minimum Income Initiative&lt;/head&gt;
    &lt;p&gt;I like to go that way, really fast, so we are already well underway with the Rural Guaranteed Minimum Income Initiative.&lt;/p&gt;
    &lt;p&gt;We focus on rural counties, where dollars go a lot further, poverty is more prevalent, and populations are smaller for tighter studies. Rural counties are also greatly overlooked in this country, in my opinion, yet they have so much incredible untapped talent. I know because that’s exactly where my parents and I are from.&lt;/p&gt;
    &lt;p&gt;We’ve funded three county level programs (Mercer, WV; Beaufort, NC; Warren, MS) that are already underway, where we will help lift thousands of people out of poverty for a period of 16 months, while sharing data and results with the world. That’s a good start.&lt;/p&gt;
    &lt;p&gt;But I think we can do considerably more. With your help, we hope to reach all 50 states over time.&lt;/p&gt;
    &lt;p&gt;In “Stay Gold,” I noted that all of American history contains the path of love, and the path of hate. But the path of love is the only survivable path. It’s so much harder, and it’s going to be a lifetime of work. But what else could I possibly buy with our money that would be worth anything close to this, for all of us?&lt;/p&gt;
    &lt;head rend="h3"&gt;What You Can Do&lt;/head&gt;
    &lt;p&gt;Everyone is invited to help. Share results, learn the history of GMI (it’s actually fascinating, I swear), talk to your representatives and generally spread the word. A surprising number of people have never even heard the terms UBI or GMI, and sometimes have misconceptions about what they are and how they work.&lt;/p&gt;
    &lt;p&gt;If you, or someone you know, is “those to whom much is given,” and in a position to sponsor county-scale work, please join us in bringing a GMI study to a new rural county and reach all 50 states. Let’s continue to do science and help lift thousands of people out of poverty while generating open data for the world.&lt;/p&gt;
    &lt;p&gt;This is my third and final startup. Rather than an “Atwood Foundation,” all we want to do is advance the concept of direct cash transfer. Simply giving money to those most in need is perhaps the most radical act of love we can take on... and all the data I can find shows us that it works — helping people afford basic needs, keep stable housing, and handle unexpected expenses.&lt;/p&gt;
    &lt;p&gt;Dreams, like happiness, are only real when shared. So let’s do that together.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.codinghorror.com/launching-the-rural-guaranteed-minimum-income-initiative/"/><published>2026-02-04T17:01:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888438</id><title>French streamer unbanked by Qonto after criticizing Palantir and Peter Thiel</title><updated>2026-02-04T19:31:35.964712+00:00</updated><content>&lt;doc fingerprint="d635e49f34142863"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2026 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/Ced_haurus/status/2018716889191498172"/><published>2026-02-04T17:09:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888532</id><title>Study: emotional support from social media found to reduce anxiety</title><updated>2026-02-04T19:31:35.368837+00:00</updated><content>&lt;doc fingerprint="3d92c09604a083c5"&gt;
  &lt;main&gt;
    &lt;p&gt;Anxiety is the second leading cause of disability and mortality worldwide. Roughly a third of adults in the United States will experience an anxiety disorder within their lifetime, and the median age of onset is 17 years old. Anxiety increases the risk for multiple other problematic outcomes, including depression and suicide.&lt;/p&gt;
    &lt;p&gt;While social media can be a cause of anxiety, it can also be a potential solution. A researcher at the University of Arkansas recently found that young adults who receive emotional support on social media are significantly more likely to report reduced anxiety symptoms, with a few specific personality traits reporting the most improved well-being.&lt;/p&gt;
    &lt;p&gt;Among the study's findings was that people with high openness to experience, high extraversion, high agreeableness and low conscientiousness reported an increase in perceived social media emotional support. Positive interactions and perceptions may explain why young adults with these specific traits feel more supported and less anxious overall.&lt;/p&gt;
    &lt;p&gt;"Longitudinal studies demonstrate an association between social media use and anxiety," the researchers noted in a paper published in Psychiatry International. "However, the mechanism of this association in terms of emotional support is not completely understood. This new study addressed these important research questions, finding strong and linear associations of reduced anxiety, especially among females."&lt;/p&gt;
    &lt;p&gt;The study was co-authored by Renae Merrill, a lecturer in the Fulbright College of Arts and Sciences at the U of A, and Chunhua Cao, an assistant professor in the College of Education at the University of Alabama.&lt;/p&gt;
    &lt;p&gt;The national sample was comprised of more than 2,403 U.S. adults between the ages of 18 and 30. Anxiety was measured using the Patient Reported Outcome Measurement Information System scale. Emotional support was measured by asking participants how much support they receive on popular social media platforms, and personality was measured using the Big Five Inventory, which assesses openness, conscientiousness, extraversion, agreeableness and neuroticism.&lt;/p&gt;
    &lt;p&gt;"The findings from this research have important social implications, given the increased prevalence of anxiety among young adults," the researchers noted. "We currently know that anxiety also increases the risk of stress-induced inflammation, sleep disruption, migraine headaches, negative workplace culture, maladaptive perfectionism, low self-esteem and negatively impacting academic performance."&lt;/p&gt;
    &lt;p&gt;That said, study cannot determine the direction of the association. For example, social media emotional support may lower anxiety or anxiety may lower perceived social media emotional support. It does suggest gender differences in how social media emotional support is perceived. The results also suggests that emotional support is effective in improving mental health.&lt;/p&gt;
    &lt;p&gt;"People thrive when they feel valued, supported and part of a cohesive group," Merrill explained. "Becoming more emotionally aware in our interactions with others is essential. This involves taking the time to really understand what others are going through and offering positive meaningful support as much as possible. Improving perception, communication and emotional awareness both in person and on social media platforms is integral for improving health and well-being."&lt;/p&gt;
    &lt;p&gt;Research support was received by the Fine Foundation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Topics&lt;/head&gt;
    &lt;head rend="h2"&gt;Contacts&lt;/head&gt;
    &lt;p&gt; Renae Merrill, lecturer &lt;lb/&gt; Department of Sociology and Criminology &lt;lb/&gt; 479-586-8412, ramerril@uark.edu &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.uark.edu/articles/80669/emotional-support-from-social-media-found-to-reduce-anxiety"/><published>2026-02-04T17:16:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46888795</id><title>Building a 24-bit arcade CRT display adapter from scratch</title><updated>2026-02-04T19:31:35.140994+00:00</updated><content>&lt;doc fingerprint="671f195658a51bd9"&gt;
  &lt;main&gt;&lt;p&gt;In November, my friend and fellow Recurser, Frank, picked up an arcade machine for the Recurse Center. We call it the RCade. He wanted to leave the original CRT in - which I think is a great choice! - and drove it off of a Raspberry Pi. Eventually we wanted to move to a more powerful computer, but we needed a way to connect it to the display. Off-hand, I mentioned that I could build a CRT display adapter that interfaces with a normal computer over USB. This is that project.&lt;/p&gt;&lt;head rend="h2"&gt;What the display expects&lt;/head&gt;&lt;p&gt;The CRT in the RCade has a JAMMA connector, and Frank bought a converter that goes between VGA and JAMMA.&lt;/p&gt;&lt;p&gt;You might think we could just use an off-the-shelf VGA adapter to drive it at this point, but it's not that simple. The CRT runs at a weird resolution; We started with 320x240 but eventually wanted to target 336x262, which is super non-standard. Even 320x240 is unattainable by most display adapters, which typically can't go below 640x480. A custom solution would allow us to output any arbitrary resolution we wanted.&lt;/p&gt;&lt;p&gt;The other thing is that the Pi, with the VGA board we were using, only supports 18-bit colour, and we wanted to improve this. Even on the RCade's CRT, colour banding was an obvious issue.&lt;/p&gt;&lt;p&gt;We also wanted to use a laptop, not a desktop, which meant not using a PCI-e card. Instead, a USB interface would be preferable.&lt;/p&gt;&lt;head rend="h2"&gt;Wait, but what is VGA?&lt;/head&gt;&lt;p&gt;VGA is a signaling protocol that maps almost exactly 1:1 with what a CRT actually does.&lt;/p&gt;Taken from wikimedia.org&lt;p&gt;Inside of a CRT, there are 3 electron guns, which correspond to red, green, and blue colour values. Two electromagnets in the neck of the tube are responsible for steering the beam - one steers horizontally and one steers vertically. To draw an image, the beam moves across the screen one horizontal line at a time, and the electron guns are rapidly modulated in order to display the correct colour at each pixel.&lt;/p&gt;&lt;p&gt;VGA contains analog signals for these R, G, and B electron guns. It also contains an HSYNC and VSYNC signal, which are used so that the driver and the CRT can agree on what pixel is being drawn at a given time. Between the VGA input and the CRT is a very simple circuit which locks onto these HSYNC and VSYNC pulses and synchronizes the sweeping of the beam.&lt;/p&gt;Taken from pyroelectro.com&lt;p&gt;The HSYNC pulses happen in between horizontal lines, and the VSYNC pulses happen in between frames. There are dead zones around each pulse - referred to as the front and back porch - which give the electron beam time to sweep back across the screen.&lt;/p&gt;&lt;p&gt;So, all we really need are those R, G, B, HSYNC, and VSYNC signals, running at precise timing, and synced properly relative to each other. Conceptually this is actually pretty simple!&lt;/p&gt;&lt;head rend="h2"&gt;Attempt 1: Using the RP2040's PIO&lt;/head&gt;&lt;p&gt;I like the Raspberry Pi RP2040 a lot. It's relatively cheap (around $1 USD) and has tons of on-board RAM - 264 KB in fact! It also has what is called Programmable IO, or PIO.&lt;/p&gt;&lt;p&gt;I've never used the PIO before, but the basic idea is that you can write assembly programs where every instruction takes exactly one cycle, and has useful primitives for interacting with GPIO. It's a fairly limited instruction set, but it allows for bit-banging precise cycle-accurate custom protocols. It's exactly what I need to modulate a VGA signal.&lt;/p&gt;&lt;p&gt;The PIO code ended up looking like this:&lt;/p&gt;&lt;quote&gt;// 1. low for 320+16=336 pixels // 2. high for 30 pixels // 3. low for 34 pixels // 4. repeat // runs on sm0 // 6 instrs -&amp;gt; can save some with sidesetting let hsync = pio::pio_asm!( ".wrap_target", /* begin pixels + front porch */ "irq set 0 [2]", // tell vsync we're doing 1 line "set pins, 1 [31]", // go low for 32 "set X, 8 [15]", // +16 = 48 "a:", "jmp X-- a [31]", // each loop 32, * 9 = 288, total = 336 /* end front porch, being assert hsync */ "set pins, 0 [29]", // assert hsync for 30 /* end assert hsync, begin back porch */ "set pins, 1 [29]", // deassert, wait 32 (note there is extra delay after the wrap) ".wrap" ); // NOTE - we get irq at *end* of line so we have to time things accordingly // 1. low for 242 lines -&amp;gt; but irq 2 every line for the first 240 // 2. high for 3 lines // 3. low for 22 lines // 4. repeat // runs on sm1 // 19 instr let vsync = pio::pio_asm!( ".side_set 1 opt", ".wrap_target", "set Y, 6", "a_outer:", "set X, 31", "a:", "wait 1 irq 0", "irq set 2", "jmp X-- a", // 32 lines per inner loop "jmp Y-- a_outer", // 7 outer loops = 224 "set X, 15", // 16 more lines = 240 "z:" "wait 1 irq 0", "irq set 2", "jmp X-- z", "wait 1 irq 0", // wait for end of last rgb line "wait 1 irq 0", // 2 more lines for front porch "wait 1 irq 0", "set X, 2 side 0", // assert vsync "b:", "wait 1 irq 0", "jmp X-- b", // wait for 3 lines "set X, 20 side 1", // deassert vsync "c:", "wait 1 irq 0", "jmp X-- c" // wait for 21 lines (back porch) ".wrap", ); // 2 cycles per pixel so we run at double speed // 6 instr let rgb = pio::pio_asm!( "out X, 32", // holds 319, which we have to read from the FIFO ".wrap_target", "mov Y, X", "wait 1 irq 2", // wait until start of line "a:", "out pins, 16", // write to rgb from dma "jmp Y-- a", "mov pins, NULL", // output black ".wrap" );&lt;/quote&gt;&lt;p&gt;The full code lives here.&lt;/p&gt;&lt;p&gt;There are 3 separate PIO programs. &lt;code&gt;hsync&lt;/code&gt; is responsible for keeping time and generating HSYNC pulses. At the start of each line, it generates an IRQ event that the other programs use for synchronization. &lt;code&gt;vsync&lt;/code&gt; counts these events and generates the VSYNC pulses. Finally, &lt;code&gt;rgb&lt;/code&gt; reads pixel data from DMA and outputs to the RGB pins in precise time with the other signals. The &lt;code&gt;out pins, 16&lt;/code&gt; signifies that we're only doing 16-bit colour for now.&lt;/p&gt;&lt;p&gt;There's a lot of weirdness in here to get around the constraints of the PIO. For example, between all 3 programs, only a maximum of 31 instructions are allowed. All of the VGA parameters (resolution, porch length, etc.) are hard-coded, and changing these would require at least a small rewrite. It's pretty brittle in that regard, but for our use-case it's sufficient as a proof-of-concept.&lt;/p&gt;&lt;p&gt;Here it is running the actual CRT in the RCade:&lt;/p&gt;&lt;p&gt;I wanted to fill the framebuffer with a repeating pattern, but I messed up my code, hence it looking weird. That's fine - it was enough to verify my VGA program worked!&lt;/p&gt;&lt;p&gt;As an aside, every time I popped off the back of the RCade to work on it was terrifying. Not because of the lethal voltages inside, but because Recursers absolutely love the RCade. I often joke that if I were to break it, I would basically be the anti-Frank!&lt;/p&gt;&lt;p&gt;Now that I had something that could take a framebuffer and throw it onto the CRT, it was time to get the image from my computer to the RP2040.&lt;/p&gt;&lt;head rend="h2"&gt;Let's write a kernel module!&lt;/head&gt;&lt;p&gt;My plan was to write a Linux kernel module that would expose itself as a framebuffer, and then send that framebuffer over USB to the RP2040. On the framebuffer side, this involved interfacing with the DRM layer.&lt;/p&gt;&lt;p&gt;I actually made decent progress here, although I kernel panicked many, many times. I never bothered to set up a proper development environment (oops), so pretty much any bug would require me to reboot my computer. This was super annoying and tedious, although I did learn a lot. I found cursed things in the official documentation, like interrobangs!&lt;/p&gt;Linus pls&lt;p&gt;I got as far as getting a framebuffer to show up at the correct resolution and refresh rate. Along this journey though, I discovered the GUD kernel module, and quickly realized I should use that instead.&lt;/p&gt;&lt;head rend="h2"&gt;GUD is... pretty good&lt;/head&gt;&lt;p&gt;Okay so this GUD thing is sick. It's a USB display adapter protocol - exactly what I need! It was originally designed to send video from a computer to a Pi Zero for use as a secondary display. It consists of an upstreamed (!!!) kernel module that runs on the host, and separate gadget software that runs on the Pi Zero. I decided I would just write my own gadget implementation to run on the RP2040.&lt;/p&gt;&lt;p&gt;As a protocol, GUD seems decent. It supports compression over the wire, and only sends the deltas of what's changed in the host's framebuffer. It's also pretty robust in terms of allowing the gadget to advertise what features it supports - compression is optional, and there's flexibility in colour depth and resolution. And again, it's upstreamed into the kernel, so anyone on modern Linux could use my display adapter with no software tweaks.&lt;/p&gt;&lt;p&gt;Unfortunately, GUD has almost no documentation. I figured out what I needed to do by reverse engineering the kernel module, which involved recompiling it to add some debugging statements. The protocol is simple enough that is wasn't too much of a hassle, and it didn't take long before I had developed a gadget implementation in Rust for the RP2040.&lt;/p&gt;&lt;p&gt;And with that, we saw our first Linux images on the CRT:&lt;/p&gt;&lt;p&gt;I know, I know, it looks terrible. Several years ago, I had built a board that implements the R/G/B DACs out of resistors, and I reused that for this project. It can only do 12 bits of colour maximum, and for this test I only bothered to wire up ~2 bits per channel, which is basically unusable. But it proves the concept works!&lt;/p&gt;The board I built several years ago. It was originally designed to fit an STM32 development board.&lt;p&gt;To be honest, it's pretty lucky that this board came with me to New York. I'm surprised I didn't either throw it out or move it to my parent's place. It was probably in some other box of things I deemed worth keeping around.&lt;/p&gt;The VGA board connected to the RP2040.&lt;p&gt;You can see from the above picture that I really connected the bare minimum for a proof-of-concept. I find perfboard soldering to be a bit tedious!&lt;/p&gt;&lt;p&gt;As an aside, you may notice in the video that the entire screen is shifted to the left. The left side has wrapped around and is now on the right side. On initial boot, it would look fine; over time it would gradually get worse and worse. This is a bug in my implementation - I suspect it's some kind of buffer underflow that's happening, such that each time it occurs, the PIO gets progressively more out of sync. But this is just a guess; I didn't look into it too much.&lt;/p&gt;&lt;p&gt;The colour depth issue is trivial to fix, but this next one isn't. The framerate sucks! You can even see it in the video above, where you can watch the new frame scroll down the screen. The RP2040 can only do USB FS (full-speed), which is capable of 11 Mbps. At the 320x240x16 bpp we were originally targeting, every frame is 153.6 kB. At our maximum USB FS speed, that's less than 10 FPS! Embarrasingly, I had originally done the math with a bandwidth of 11 MBps, not 11 Mbps, so I was off by a factor of 8. I was hoping to get something at least temporarily usable but had to go back to the drawing board.&lt;/p&gt;&lt;head rend="h2"&gt;Going on a GUD gadget side quest&lt;/head&gt;&lt;p&gt;Who even needs microcontrollers anyway? My next idea was to use the normal GUD gadget implementation, running on a Pi Zero, but outputting to VGA over GPIO. Conceptually this is pretty simple, although in practice it was anything but. The canonical GUD gadget software was based on a 2021 version of Buildroot, which was too old to output VGA. I tried, and failed, to update the Buildroot version, as well as to backport the VGA overlay. Neither of those really worked, but I didn't really know what I was doing.&lt;/p&gt;&lt;p&gt;I also played around with generating a custom NixOS image that had a modern kernel and the GUD gadget kernel module. When that didn't work I prepared to run a user space GUD gadget implementation on Raspberry Pi OS. But like, isn't that boring? And then I'll still be stuck at 18 bit colour! And sometimes a girl just wants to tickle her electrons :3&lt;/p&gt;&lt;head rend="h2"&gt;Attempt... 2? 3? 1+i? Returning to MCU land&lt;/head&gt;&lt;p&gt;Okay, so my beloved RP2040 doesn't support USB HS (high-speed). My beloved RP2350 (the newer version of the same chip) doesn't either. But some of my beloved STM32s do!&lt;/p&gt;&lt;p&gt;Initially I was planning to go computer -&amp;gt; USB HS -&amp;gt; STM32 -&amp;gt; SPI bus -&amp;gt; RP2040 -&amp;gt; VGA. But like, that's complicated, and there are 2 microcontrollers to program, and there is so much to go wrong, and the SPI bus protocol is going to need to be robust against lost/extra bits, and AAAAAAAAAA I don't wanna!&lt;/p&gt;&lt;p&gt;But! STM32! I learned through research that some of the nicer ones have an LTDC peripheral, which, among other things, can drive an LCD display. And guess what? Many LCDs take in an R, G, B, HSYNC, and VSYNC signal. That's right - they pretend they're a CRT, and they pretend they have a cute little electron gun inside of them, and the STM32 is like "ok I got u" and can just like, do this natively. And I realize that this is what VGA is, but it's so, so funny to me that the protocol is literally just the manifestation of a physical design that is largely obsolete.&lt;/p&gt;&lt;p&gt;Okay so at this point I'm like, is this even a real project anymore? I'm just connecting the USB peripheral to the LTDC peripheral. What part of this is supposed to take effort? I had already written the GUD gadget implementation. Wasn't I basically already done?&lt;/p&gt;&lt;p&gt;OH BOY.&lt;/p&gt;&lt;p&gt;Anyway, by now it's Christmas time and I fly back to Canada to hang out with my family, as you would expect. I had none of my hardware with me, so now felt like a good time to design the actual board.&lt;/p&gt;&lt;p&gt;By Christmas Eve, this is what I had. Conceptually, it's a pretty basic board - there's the USB HS input, the VGA output, 3 8-bit DACs, some RAM for the framebuffer, and supporting components. At the heart of it is the STM32H723, which is a microcontroller that's advertised as supporting USB HS and LTDC.&lt;/p&gt;&lt;p&gt;It's worth talking about the DACs a bit. They have a few requirements. They need to map the 8-bit binary space uniformly to the analog domain. They also need to act as a resistor divider - my I/O is at 3.3V, but VGA expects a maximum of 0.7 volts for R/G/B. And finally, they need to be impedance-matched to the 75 ohms of the VGA cable, to prevent reflections and ringing that show up in the image. I am... pretty doubtful we need this at our resolution, but it doesn't hurt, and it increases nerd cred (^:&lt;/p&gt;&lt;p&gt;I encoded all of these requirements into a system of equations, threw it into a SAT solver, and computed all of my resistor values. I checked the output manually and it made sense, so I used these values in my DAC.&lt;/p&gt;&lt;p&gt;Also worth noting is the length-matched traces between the STM32 and the HyperRAM. Length-matching ensures that all the signals arrive at the same time; if some arrive too early or late it can cause issues. The traces aren't impedance-matched, but I did a bit of math and determined they were short enough that I didn't have to worry about it.&lt;/p&gt;&lt;p&gt;Also, I want to talk about the USB port. I used Mini-USB. Alright look. I know I know, I should have used USB-C. But I don't like USB-C! It's a dumb standard. We spent decades teaching non-technical users to plug the square wire into the square hole and the round wire into the round hole. And then we made every hole the same shape!! But they don't all support the same things!! Not even every cable supports the same things!! I hate it!! And Mini-USB is so cute. It's not reversible, but who cares? It's more robust than micro USB, while still being small. And it's my board, my rules. So yes, I will keep sending pictures of this board to people, and they will keep complaining it doesn't use USB-C. And I will continue to not care! Mini-USB is CUTE. And by the way, if you read this entire article and this is the section you choose to engage with, then you are boring!!! You will never live up to Mini-USB!!&lt;/p&gt;&lt;p&gt;Okay okay sorry about that. I am calm now. With all of that out of the way, I placed the order for the boards. I bought 5 of them, 2 of which were partially assembled. I would complete the rest of the assembly myself, but I didn't want to worry about the more finicky stuff. Between taxes, tariffs, and shipping, it came to a little over a hundred dollars USD.&lt;/p&gt;&lt;head rend="h2"&gt;Disaster strikes&lt;/head&gt;&lt;p&gt;About a week later, I was back home in NYC. My boards hadn't arrived yet, although I did have access to an STM32H723 development board at this point. To prepare for my boards, I started porting my RP2040 firmware to the STM32H723.&lt;/p&gt;&lt;p&gt;Things were going well until I tried getting USB set up. For some reason, I could only get it working at USB FS speeds. I figured I was just initializing something wrong - maybe a register I was forgetting about, or that wasn't in the HAL? I did a lot of digging, before finding this hidden in the datasheet (emphasis mine):&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The devices embed a USB OTG high-speed (up to 480 Mbit/s) device/host/OTG peripheral that supports both full-speed and high-speed operations. It integrates the transceivers for full-speed operation (12 Mbit/s) and a UTMI low-pin interface (ULPI) for high-speed operation (480 Mbit/s). When using the USB OTG_HS interface in HS mode, an external PHY device connected to the ULPI is required.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;My heart sank. Yes, despite this chip very clearly advertising support for USB HS, it can't actually do that without an external PHY. This is super easy to miss - I actually told other people about the problem, and often they would tell me I was incorrect until I showed it to them in the datasheet. I've also found many posts on the ST Community forums from people running into the same thing. So yeah, I need a new board.&lt;/p&gt;&lt;p&gt;But because boards are expensive, I figure I'll still use the rev 1 board to validate as much as I can.&lt;/p&gt;&lt;head rend="h2"&gt;Disaster strikes, again&lt;/head&gt;&lt;p&gt;Once the boards come, I complete assembly of one, plug it into my computer, and nothing happens. I find out that the 3.3V rail is shorted to ground. This is the same on all of my boards, even the 3 that are disassembled. Some debugging later, it turns out I moved a via in KiCad and didn't do a re-pour. My ground plane was connected to my power plane.&lt;/p&gt;&lt;p&gt;I have a full CI/CD pipeline set up for my PCBs, so I was surprised it didn't catch this. It turns out it has a bit of wiggle-room, and the re-pour was small enough it didn't get picked up. I now know I need to be disciplined and run DRC locally, ensuring there are literally no differences (and if there are, commit them and push them up to my Git forge).&lt;/p&gt;&lt;p&gt;Although annoying, and quite embarrassing, this wasn't a huge deal. I used a drill bit and very carefully drilled out the offending via by hand. It made a bit of a mess - make sure you use breathing protection - but I got a board that worked.&lt;/p&gt;The drilled-out via. You can see it directly under the text, near the center-bottom of the image.&lt;p&gt;At this point I wrote some code that exercised the HyperRAM and VGA. Everything worked great, so I began work on the new board. Here's what my development setup looked like while I was testing:&lt;/p&gt;&lt;p&gt;Even though the rev 1 board didn't work out, Frank pointed out that the difference between it and the previous revision was stark:&lt;/p&gt;&lt;p&gt;Not a bad pace of development!&lt;/p&gt;&lt;head rend="h2"&gt;Attempt 4 - Rev 2&lt;/head&gt;&lt;p&gt;I needed an STM32 that supported ULPI (used for talking to the USB PHY), LTDC, and some kind of external RAM. I looked at dozens of chips and found all sorts of blockers. Chips that actually supported both (but they had overlapping pins), chips that were advertised as supporting both (but in actuality, could only do one or the other, depending on the specific model number), and chips that actually could do both, with unconflicting pins, but only in a BGA package. I did not particularly want to deal with that, mainly because the tiny vias and traces would balloon the board cost even more.&lt;/p&gt;&lt;p&gt;I ended up settling on the STM32H750IBT, a massive, 176 pin, LQFP chip. This thing is larger than some New York apartments, and at over $10 USD, it costs about the same! I have bought entire dev boards for a fraction of this.&lt;/p&gt;&lt;p&gt;Once I picked out the chip, I basically redesigned the entire board from scratch. Sure, I could reuse the DACs, but I needed completely new RAM (the new chip has no HyperBus), as well as the USB PHY and supporting components. Now that my Christmas vacation was over, it took me a solid week to get everything designed. This isn't my most complicated board, but it's certainly my most complex routing:&lt;/p&gt;&lt;p&gt;I mean, look at those traces. I'm using basically all available space just to get them to be the same length. ST famously has bad pinouts, and because one of the memory controller pins is located on the complete opposite side of the chip, literally all of the rest of the RAM traces had to be lengthened. And the RAM has a 16-bit data bus. I had to route 38 length-matched traces for the memory alone!&lt;/p&gt;&lt;p&gt;The USB PHY also had a decent number of traces to route, although far less than the RAM. This is probably the part where I'm supposed to say that like, crosstalk is bad and stuff, but we're just gonna ignore that. I had like no space; leave me alone!&lt;/p&gt;&lt;p&gt;Here's what the board looked like:&lt;/p&gt;&lt;p&gt;And with that, I ordered the board. Waiting for it to arrive just about killed me, but when it finally did, I got to work.&lt;/p&gt;&lt;head rend="h2"&gt;Board bring-up&lt;/head&gt;&lt;p&gt;Board bring-up is a magical thing. One-by-one, you enable each part of the board, and you make sure that everything works the way you expect. Given that USB burned me before, I decided to start there.&lt;/p&gt;&lt;p&gt;Right out of the gate, I was off to a bumpy start. I got the USB technically working, and I even got it to show up on my computer as USB HS (yay!), but it was super, super flaky. Eventually I worked out that its crystal oscillator was unstable. Going back to the datasheet, I realized I missed a 1M ohm resistor, which was meant to be put in parallel with the crystal. I didn't have one handy, but I know the human body is around that resistance. I put one finger on each terminal of the crystal. It immediately stabilized. I was pretty ecstatic!&lt;/p&gt;&lt;p&gt;The next day I went to the Recurse Center and stole a 1M ohm resistor to affix to the board. (Faculty, if you're reading this, I owe you about a tenth of a cent. Sorry!)&lt;/p&gt;&lt;p&gt;With that over, the rest of the bring-up process was pretty smooth. I got the LTDC running and ported over the rest of the code that implemented the GUD protocol. I had written things pretty naively but, to my surprise, it didn't need any optimization for high-speed USB. I guess that's what a microcontroller with a 480 MHz core will get you!&lt;/p&gt;&lt;head rend="h2"&gt;Running it in the RCade cabinet&lt;/head&gt;&lt;p&gt;I was already at the Recurse Center at this point, so I popped the back off the RCade, unplugged the VGA from the Pi, and plugged it into my board. It started up immediately - the colours looked great and I got the full 60 Hz framerate. To be honest, I was shocked at how good it looked, and the crowd that had formed was shocked too. I wasn't really a believer that 24 bit colour would be noticeable, but I was totally wrong. The lack of colour banding was striking.&lt;/p&gt;&lt;p&gt;Next, I plugged the board into the Pi, and Frank reconfigured it to make my display adapter the primary display. We launched the normal RCade software and played some games. They looked truly amazing; nothing like before. Rose, one of the main people who developed the software, joked that it looked so good that some of the graphical shortcuts she took were no longer sufficient.&lt;/p&gt;&lt;p&gt;It's hard to tell in the pictures but the difference in person was striking. Where it's most obvious is in the lack of banding around the mountains.&lt;/p&gt;&lt;p&gt;This felt amazing, but I wasn't quite ready to leave the board installed. It was fragile - especially with the resistor I bodged on - and it was expensive. I took my board back out and Frank reverted the RCade to how it was before.&lt;/p&gt;&lt;head rend="h2"&gt;Designing a case&lt;/head&gt;&lt;p&gt;I'll be honest. I don't get that much joy out of 3D modeling. I find it frustrating, tedious, and generally unfulfilling. To get around this, I decided to use YAPP to design the case. YAPP is a parametric box generator written in OpenSCAD. I wrote a few dozen lines of code and ended up with this beauty:&lt;/p&gt;&lt;p&gt;It took barely any time at all and only took 2 physical revisions before I was happy with it. I added the OpenSCAD code to my board repository and CI/CD pipeline. Now, it builds all the files I need to order the boards, as well as the STL files for the case.&lt;/p&gt;HE'S BEGINNING TO TAKE FORM&lt;p&gt;And now, with the board in the case:&lt;/p&gt;&lt;p&gt;At this point I was starting to prepare myself to install it in the RCade.&lt;/p&gt;&lt;head rend="h2"&gt;Disaster strikes, again??&lt;/head&gt;&lt;p&gt;Everything was done, so I expected I'd just plug it in and be good to go. When I did this, though, nothing happened. After some debugging I realized the USB had completely died on my board. It wasn't showing up on any computer I connected it to, although the STM32 was still chugging along happily (and outputting to VGA).&lt;/p&gt;&lt;p&gt;I still haven't figured out exactly what happened here. I was having a bit of flakiness with the USB already. I vaguely suspect ESD to either the STM32 or the USB PHY, but am not super confident this is the cause. I'm going to keep looking into this. (inb4: wow maybe you shouldn't have touched the crystal without grounding yourself first!)&lt;/p&gt;&lt;p&gt;In the meantime, I assembled a second board and got that installed instead. I'm slightly nervous because I don't have a third board to use if this one also dies, and I don't want to order any more until I can figure out what's killing them. That said, it has been a few days now since I installed it, and despite running 24/7, there's no signs of it dying yet.&lt;/p&gt;&lt;p&gt;Here's the board in its case, installed in the RCade. We're still running it off the Raspberry Pi for now, but soon we'll have that switched out with a laptop. I can't wait!&lt;/p&gt;&lt;head rend="h2"&gt;Future improvements&lt;/head&gt;&lt;p&gt;There are all sorts of things I want to change. I want the board to also support audio, with an integrated amp. Perhaps even a tube amp? I just think it would be funny. And being able to read input from the controls would be cool too.&lt;/p&gt;&lt;p&gt;On the software side, I want double or triple buffering. I actually got them both working, although they didn't play nice with the deltas that GUD sends over the wire. There are workarounds to this that I haven't implemented yet. It would also be nice to give GUD the ability to disable these deltas; perhaps that would be a good feature for me to add to the kernel module. Writing some documentation on the GUD protocol could be good too!&lt;/p&gt;&lt;p&gt;This was a really fun project, and it's not over yet, but I think all the hard stuff is pretty much done (although - I've thought that before!). I really wasn't expecting this to take as long as it did, but I learned so much, and I'm a stronger engineer for it.&lt;/p&gt;&lt;head rend="h2"&gt;Source code&lt;/head&gt;&lt;p&gt;There's a few repositories of interest:&lt;/p&gt;&lt;p&gt;The hardware lives here.&lt;/p&gt;&lt;p&gt;The software lives here.&lt;/p&gt;&lt;p&gt;If you're interested, the original software for the RP2040 lives here.&lt;/p&gt;&lt;p&gt;My very messy DAC equations live here.&lt;/p&gt;&lt;p&gt;My Nix GUD gadget attempt lives here.&lt;/p&gt;&lt;p&gt;I also wrote a fair bit of scratch code while learning (such as for my kernel module), but I don't think any of it was worth putting it in my Git forge.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.scd31.com/posts/building-an-arcade-display-adapter"/><published>2026-02-04T17:35:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46889008</id><title>The Great Unwind</title><updated>2026-02-04T19:31:34.932010+00:00</updated><content>&lt;doc fingerprint="7fad91172de75f94"&gt;
  &lt;main&gt;
    &lt;p&gt;Have you wondered why the stock market has been so choppy since October and why crypto and gold keep flash crashing? The western media would have you believe this is due to AI bubble, war in Greenland, and Trump's tweets. We have a better story to tell.&lt;/p&gt;
    &lt;p&gt;Wall Street has lost control of the Japanese Yen carry trade unwind.&lt;/p&gt;
    &lt;p&gt;There's been a fair bit of quiet chaos in financial markets recently. Cryptocurrencies have lost 40% of their value. We saw silver drop 40% which hasn't happened since 1980. Stocks like Microsoft are getting picked off one-by-one with 15% drops when positive earnings reports come out. Meanwhile the broader market chops sideways, so people think things are fine. Trump and Europe were on the brink of war for control of a desolate arctic territory. Truth Social has overtaken FOMC as the most important source of financial news. These things may all appear to the untrained eye as a series of idiosyncratic, disconnected shocks. The prevailing media narrative is that the market is reacting negatively to AI CapEx spending and a hawkish new Fed chair. But our systematic analysis of cross-asset flows, derivatives positioning, central bank policy minutes, and institutional balance sheets suggests a singular, unified causality that binds these disparate anomalies, which is the covert unwinding of the Japanese Yen carry trade.&lt;/p&gt;
    &lt;p&gt;For nearly thirty years, the Bank of Japanâs (BOJ) Zero Interest Rate Policy (ZIRP) and subsequent Negative Interest Rate Policy (NIRP) effectively transformed the Yen into the worldâs funding currency. We would call it the greatest free money printer ever made. By anchoring borrowing costs at or near zero, the BOJ enabled Wall Street to borrow Yen cheaply and invest it with leverage into higher yielding instruments globally, such as U.S. treasuries, equities, and cryptography. For example, you borrow Yen from Japan at 0% interest, you exchange it for USD, and then you buy treasury bonds that pay 4%. It's that simple. This funded government benefits and provided continuous reliable liquidity for financial markets that made stocks keep going up while suppressing volatility.&lt;/p&gt;
    &lt;p&gt;Trillions of dollars of free loans from the Bank of Japan were used by a generation of investors to buy a double digit percentage of the U.S. economy. Now those loans are being recalled. Wall Street traders who levered up on the free Japanese money now have to sell trillions of assets and convert the proceeds back to Yen in order to not be liquidated. These aren't happy times for them. They get liquidated when Japan raises interest rates; they get liquidated when the Federal Reserve lowers interest rates; they get liquidated when the Japanese Yen increases in value; they get liquidated when tech stocks aren't going up enough, and all four of these things have been happening at once.&lt;/p&gt;
    &lt;p&gt;Wall Street may be greedy, but they're very intelligent too. They made many smart choices about where to put the "free" money. Now let's say you're someone who's also smart, but was wise enough to not use Sauron's ring. Chances are you invested in the same things as Wall Street. So by now you've probably seen your whole portfolio move against you; you're wondering why your hedges don't work; and you feel like you're being punished for making all the right choices. It's because other smart people, who got greedy, are being forced to close their positions, and you're the whipping boy for their avarice.&lt;/p&gt;
    &lt;p&gt;The Japanese Yen is sort of like GameStop ($GME). It's the most shorted currency on Earth. When you borrow yen to buy American assets, you're effectively shorting the yen. Currency can be rehypothecated so that yen-denominated debt ends up exceeding the actual yen supply, the same way GME's short interest exceeded 100% of its float. When shorts start covering it compounds tragedy, because they all have to buy yen, which makes its value increase, forcing more shorts to cover, and Japan is a small island.&lt;/p&gt;
    &lt;p&gt;This December 2025 rate hike to 0.75%, followed by the explicitly hawkish signalling from Prime Minister Sanae Takaichiâs administration, has fundamentally altered the risk-reward calculus of these leveraged positions. The market disruptions observed in January 2026 bear the distinct mathematical signature of a forced liquidation event rather than a fundamental repricing of growth prospects. When correlations between historically uncorrelated assets (e.g. Gold, Bitcoin, Microsoft, and Silver) approach 1.0 during a sell-off, it serves as a distinct indicator that traders are not selling what they want to sell, but rather what they must sell in order to meet margin calls in a funding currency that is rapidly appreciating against their liabilities.&lt;/p&gt;
    &lt;p&gt;We shall investigate the mechanics of this unwind in exhaustive detail. We analyze the "Greenland Distraction" not as a root cause but as a volatility trigger that shattered the complacent calm of the "Davos Consensus." We examine the anomalous liquidation in precious metals following the nomination of Kevin Warsh to the Federal Reserve Chairmanship, and we dissect the flow of funds from major Japanese institutional whales like Norinchukin Bank, whose retreat from foreign bond markets has left a liquidity vacuum in the U.S. Treasury complex. The evidence points to a systemic repricing of the global cost of capital, originating in Tokyo and transmitting violently through the plumbing of Wall Street, leaving no asset class untouched.&lt;/p&gt;
    &lt;p&gt;To fully comprehend the market chaos of January 2026, one must look beyond the immediate headlines of the new year and scrutinize the subtle yet seismic shifts that occurred in Tokyo during the closing months of 2025. The conventional market narrative has long regarded the Bank of Japan as a passive, almost paralyzed actor, perpetually trapped in a deflationary mire and unable to normalize policy. This view has always been demonstratably false. The truth is that Wall Street leaders have been planning for the next quarter, while the Japanese have been preparing for the next century. The data confirms a deliberate, aggressive shift toward normalization that caught global carry traders offguard.&lt;/p&gt;
    &lt;p&gt;In a move that many Western analysts critically underestimated, the Policy Board of the Bank of Japan voted unanimously to raise the uncollateralized overnight call rate to 0.75% during its policy session on December 18-19, 2025. While a 25 basis point hike might appear negligible in the context of Federal Reserve or ECB tightening cycles, in the context of the Japanese financial system, which has operated near the zero-bound for decades, it represents a massive tightening of financial conditions.&lt;/p&gt;
    &lt;p&gt;This move was not merely a technical adjustment; it was a fundamental regime change. Coming from a baseline of -0.1% in early 2024 and 0.50% in late 2025, the move to 0.75% signaled that the era of "free money" had definitively ended. The rationale provided by the BOJ was grounded in shifting inflationary dynamics. Core CPI (excluding fresh food), the central bank's preferred metric, was tracking near 3% in late 2025, persistently exceeding the 2% price stability target.Although inflation eased slightly to 2.4% in December, the BOJ minutes reveal a board convinced that "wage gains may be durable," thus justifying higher rates to prevent a wage-price spiral.&lt;/p&gt;
    &lt;p&gt;Crucially, the minutes from the December meeting, which were released in late January 2026, contain explicit language suggesting that the tightening cycle is far from complete. The board noted that "real interest rates are expected to remain negative," implying that a policy rate of 0.75% is still considered accommodative relative to inflation.To a bond trader, this is hawkish code. It suggests that the "neutral rate" is significantly higher, potentially between 1.5% and 2.0%. If the market prices in a terminal rate of 2.0%, the cost of funding for carry trades effectively triples from previous levels, turning profitable arbitrage positions into deep losses.&lt;/p&gt;
    &lt;p&gt;The political dimension in Japan has exacerbated the monetary tightness, creating a "double tightening" effect that algorithms have struggled to price. Prime Minister Sanae Takaichi, preparing for a snap election on February 8, 2026, has adopted a complex economic stance that blends fiscal expansion with monetary discipline, a volatile mix for currency markets.&lt;/p&gt;
    &lt;p&gt;Takaichi advocates for "strategic fiscal spending" and tax cuts to stimulate the domestic economy. In standard macroeconomic theory, an expansionary fiscal policy (increased government spending) combined with a tightening monetary policy (higher rates to combat the resulting inflation) is the perfect recipe for currency appreciation. While Takaichi has publicly softened her rhetoric to avoid accusations of currency manipulation, stating she "did not have a preference for the yen's direction", her policies speak louder than her soundbites.&lt;/p&gt;
    &lt;p&gt;The market fears that Takaichiâs proposed fiscal largesse will force the BOJ to hike rates faster than currently projected to counteract the inflationary effects of government spending. This creates a two-front war on the Yen carry trade:&lt;/p&gt;
    &lt;p&gt;Cost of Funding Rises: Higher BOJ rates make borrowing Yen expensive.&lt;/p&gt;
    &lt;p&gt;Exchange Rate Risk: If the Yen appreciates due to the fiscal-monetary policy mix, the principal value of the USD-denominated assets held by Japanese investors falls in Yen terms, triggering margin calls.&lt;/p&gt;
    &lt;p&gt;The tension between the Prime Minister's office and the Ministry of Finance (MOF) adds another layer of uncertainty. Finance Minister Satsuki Katayama has been far less tolerant of currency volatility, repeatedly intervening or threatening intervention when USD/JPY approaches the 155-160 danger zone.This political friction creates a "floor" for the Yen, making shorting the currency a perilous endeavor for global macro funds.&lt;/p&gt;
    &lt;p&gt;Perhaps the most critical, yet underreported, development is the behavior of Japan's gargantuan institutional investors, specifically Norinchukin Bank (often referred to as the "CLO Whale") and Nippon Life Insurance. These entities have historically been the largest buyers of U.S. debt, recycling Japan's trade surplus into U.S. Treasuries and corporate bonds.&lt;/p&gt;
    &lt;p&gt;The data indicates a massive reversal in these flows. Following significant losses in 2024 and 2025 due to unhedged exposure to U.S. and European sovereign bonds, Norinchukin has been actively liquidating foreign assets. By the end of December 2025, the bank had unloaded nearly Â¥12.8 trillion (approximately $88 billion) in foreign government bonds.The bankâs CEO, Taro Kitabayashi, confirmed the completion of this sell-off, stating the bank would "take its time" before committing capital to fresh investments.&lt;/p&gt;
    &lt;p&gt;The significance of this cannot be overstated. A major, price-insensitive buyer of U.S. debt has left the building. When the U.S. Treasury issues debt to fund its deficit, Norinchukin is no longer the guaranteed bid. This removal of liquidity support weakens the floor for U.S. Treasuries, contributing to the yield spikes seen in January. Similarly, Nippon Life has signaled a rotation back into domestic Japanese Government Bonds (JGBs), acknowledging that "unrealized losses" on foreign bonds had swelled to Â¥4.7 trillion.The logic is simple: why take currency risk for a 4.5% U.S. yield when domestic JGB yields are rising and offer a risk-free return in your home currency?&lt;/p&gt;
    &lt;p&gt;By December 31, 2025, the stage was set. The "free money" era was over. The largest holders of capital in Tokyo were repatriating funds or moving into cash. Global markets, however, were still positioned for "business as usual", long Nvidia, long Bitcoin, short Yen. The dissonance between Japanese reality and Western positioning created the perfect conditions for a crash.&lt;/p&gt;
    &lt;p&gt;To validate the thesis that the Yen unwind is the primary driver of volatility, we must examine the sequence of events. The crash did not happen in a vacuum; it followed a precise timeline where geopolitical shocks acted as triggers for a structural fragility that had been building since the BOJ's December pivot.&lt;/p&gt;
    &lt;p&gt;The pressure began to build in Q4 2025. As the BOJ signaled its intention to hike rates, Japanese traders, often the "canary in the coal mine" for global liquidity, began to reduce risk. This cycle started with Bitcoin. Bitcoin is a pure liquidity asset; it has no yield and is often funded via margin. As the cost of Yen margin rose, Japanese selling pressure on Bitcoin intensified from October through December.This was the first tremor.&lt;/p&gt;
    &lt;p&gt;Was the "Greenland War" theater? While the military dimensions may have been performative, the economic consequences were tangible and acted as the catalyst that exposed the fragility of the Yen carry trade.&lt;/p&gt;
    &lt;p&gt;On January 17, 2026, President Trump escalated his demand to purchase Greenland by threatening a 10% tariff on eight European nations (including the UK, Germany, and France) and escalating to 25% by June if the territory was not ceded.This introduced a "tail risk" that markets had not priced: the fracture of the Atlantic economic alliance.&lt;/p&gt;
    &lt;p&gt;Following the Martin Luther King Jr. holiday, U.S. markets opened on January 20 to a bloodbath. The S&amp;amp;P 500 fell 2.1%, the Nasdaq composite dropped 2.4%, and yields on U.S. Treasuries spiked.The narrative was "Greenland," but the market mechanics told a different story. The threat of tariffs on close allies disrupts the "Atlantic Trade" narrative. For Japanese investors holding U.S. assets, this introduced a new risk premium. It wasn't just about rates anymore; it was about the stability of the U.S.-led global order. This geopolitical volatility forced risk parity funds and algorithmic traders to reduce gross exposure. When a global portfolio deleverages, it buys back its funding currency. In this case, it bought Yen.&lt;/p&gt;
    &lt;p&gt;While Trump walked back the military threat on January 21 at Davos, the economic threat of tariffs remained a live wire. The volatility persisted, suggesting that the "Greenland" narrative was merely the match that lit the fuse of a much larger powder keg.&lt;/p&gt;
    &lt;p&gt;The final and most violent phase of the crash occurred at the end of the month, triggered by the nomination of Kevin Warsh as Federal Reserve Chair.Warsh is widely perceived as a hawk, favoring sound money and skepticism toward quantitative easing. His nomination signaled the potential end of the "Fed Put", the assumption that the central bank would always intervene to support asset prices.&lt;/p&gt;
    &lt;p&gt;This announcement triggered a massive repricing of the "Debasement Trade." Assets that thrive on currency debasement, Gold, Silver, and Bitcoin, collapsed. Gold fell ~11%, and Silver crashed ~36% in a single session.This synchronization of losses across uncorrelated assets (Tech and Gold falling together) is the definitive signature of a liquidity crisis driven by margin calls.&lt;/p&gt;
    &lt;p&gt;The unwinding of a carry trade is not a monolithic event; it is a cascade that ripples outward from the most liquid and speculative assets to the core holdings of institutional portfolios. The sequence of asset price collapses observed from October 2025 to January 2026 follows this classic liquidation hierarchy perfectly.&lt;/p&gt;
    &lt;p&gt;As noted, the unwind began in the crypto markets. Japan is home to a massive retail crypto trading base, and the Yen is a major pair for Bitcoin trading. Snippets indicate that Japanese traders began selling off Bitcoin in October 2025.&lt;/p&gt;
    &lt;p&gt;This timing is crucial. It correlates with the period when the BOJ began signaling the December rate hike. Retail traders, facing higher mortgage rates and loan costs in Japan, likely liquidated their most volatile, liquid asset first to raise cash. The selling was exacerbated by the looming tax reform in Japan. While the proposal to move to a flat 20% tax rate is bullish in the long term, the immediate pressure of rising funding costs forced traders to sell before the tax cut could be realized.By January 31, massive outflows from Bitcoin ETFs ($528 million) coincided with the broader market crash, confirming that crypto was being used as a source of liquidity to cover losses elsewhere.&lt;/p&gt;
    &lt;p&gt;Consider the "painful ~3% dump" in the Nasdaq and Microsoft's staggering 15% drop. On January 29, 2026, Microsoft reported earnings. Despite beating revenue estimates ($81.27 billion vs. $80.28 billion), the stock plummeted ~11-15% intraday.&lt;/p&gt;
    &lt;p&gt;The street blamed concerns over "AI CapEx", the idea that Microsoft was spending billions on data centers with slow return on investment. However, a 15% drop in a $3 trillion company on a "good" earnings beat is rarely fundamental; it is mechanical. Microsoft is a quintessential "momentum" stock, heavily held by foreign institutional investors, including Japanese pension funds. When the Yen strengthens, the value of these USD-denominated assets falls in JPY terms.&lt;/p&gt;
    &lt;p&gt;If a Japanese insurer holds Microsoft unhedged, a falling USD/JPY exchange rate hurts their balance sheet. If they hold it hedged (rolling short USD positions), the rising U.S. rates (driven by the Warsh nomination) make the hedge prohibitively expensive. The January 29 drop was likely exacerbated by a "stop-loss" cascade from Tokyo desks. As the price broke key technical levels, algorithms programmed to protect Yen-denominated returns indiscriminately sold the most liquid blocks. Microsoft, being one of the most liquid stocks in the world, became the ATM for the rest of the portfolio.&lt;/p&gt;
    &lt;p&gt;The most compelling evidence of a forced liquidation event is the behavior of Gold and Silver on January 31, 2026. Gold fell ~11-12% and Silver crashed ~31-36% in a single session. Historically, Gold acts as a safe haven during equity market turmoil. If the Nasdaq is crashing due to "Greenland" fears, Gold should rally. Instead, it crashed.&lt;/p&gt;
    &lt;p&gt;This anomaly can be explained by two factors:&lt;/p&gt;
    &lt;p&gt;The Warsh Effect: As discussed, Warsh's nomination strengthened the USD and undermined the thesis for holding anti-fiat assets.&lt;/p&gt;
    &lt;p&gt;Margin Call Dynamics: Snippets reveal that CME Group and the Shanghai Gold Exchange raised margin requirements on gold and silver futures days before the crash.When Japanese traders faced losses on their Microsoft longs and their Yen shorts, they needed cash immediately. They couldn't sell illiquid bonds quickly enough, so they sold their "winners." Gold had rallied to ~$5,400/oz prior to the crash. Traders liquidated their profitable Gold positions to pay for the margin calls on their losing Tech and Yen positions.&lt;/p&gt;
    &lt;p&gt;Cross-Asset Correlations (Week Ending Jan 31, 2026)&lt;/p&gt;
    &lt;p&gt;This correlation breakdown is visualized in Figure 2, where the correlation between Gold and the Nasdaq 100 spikes to nearly 1.0 during the crash week, a statistical anomaly that only occurs during severe liquidity events.&lt;/p&gt;
    &lt;p&gt;The "Yen Whale" hypothesis is strongly supported by the data on futures volumes and repo market stress. The "central mystery" is not just in the price action, but in the unseen flows of the derivatives market.&lt;/p&gt;
    &lt;p&gt;About a week ago, some whale kicked off an astronomically large market order for a /6J long when it hit all-time lows. /6J (CME Yen Futures) hit a low of ~0.00647 (approximately 154.50 USD/JPY) in late January. This level has historically been a "line in the sand" for the Japanese Ministry of Finance (MOF).&lt;/p&gt;
    &lt;p&gt;CME reported record volumes in FX and Interest Rate products for January 2026.The aggressive buying off the lows suggests a massive repatriation flow. Who is the Whale? Two theories emerge:&lt;/p&gt;
    &lt;p&gt;The MOF Thesis: The Ministry of Finance has a history of stealth intervention. Buying /6J (Long Yen) is functionally equivalent to selling USD reserves. Buying futures allows them to support the currency without immediately depleting cash reserves, squeezing speculators who are short.&lt;/p&gt;
    &lt;p&gt;The Carry Unwind: A massive hedge fund or bank (like Norinchukin) realizing that the "game is up" and closing out short-Yen positions. The size of the order suggests an entity that needed to move billions, not millions.&lt;/p&gt;
    &lt;p&gt;The subsequent price action, a sharp rally followed by "hammering back down", represents the battleground. U.S. macro funds are still trying to short the Yen (betting on U.S. economic exceptionalism and Warsh's policies), while Japanese domestic accounts are buying it. The volatility is the result of these tectonic plates grinding against each other.&lt;/p&gt;
    &lt;p&gt;The plumbing of the U.S. financial system showed signs of stress that coincided with the Japanese retreat. The Overnight Reverse Repo facility (ON RRP) saw a year-end spike to $106 billion but has since drained.&lt;/p&gt;
    &lt;p&gt;Japanese banks are typically huge participants in the U.S. repo market to fund their dollar assets. As Norinchukin and others retreat (repatriating funds to Japan), liquidity in the U.S. repo market becomes thinner. The "air pocket" in Microsoft and Gold prices was likely exacerbated by a lack of market maker depth in the repo-funded derivatives market. When market makers cannot access cheap repo funding, they widen spreads and reduce liquidity provision, leading to "gaps" in price action during sell-offs.&lt;/p&gt;
    &lt;p&gt;There have been significant moves in other currency futures as well: /6A increased 87 basis points, /6L rose 19 basis points, and /6S rose 18 basis points.&lt;/p&gt;
    &lt;p&gt;/6A (Australian Dollar): The 87 basis point rise in the Aussie Dollar is notable. AUD is often a proxy for Chinese growth and global risk sentiment. A rise here, amidst a tech crash, suggests a rotation out of U.S. assets and into commodities or Asia-Pacific currencies, further supporting the "Sell America" thesis triggered by the Greenland tariff threats.&lt;/p&gt;
    &lt;p&gt;/6L (Brazilian Real) and /6S (Swiss Franc): The rise in the Swiss Franc (a classic safe haven) aligns with the risk-off sentiment. The move in the Brazilian Real suggests that emerging markets are also seeing volatile flows as the dollar stabilizes.&lt;/p&gt;
    &lt;p&gt;Why was the VIX at 16 despite the chaos? The VIX measures implied volatility of S&amp;amp;P 500 options. Its relatively low level (16) compared to the violence in individual names (MSFT -15%, Gold -11%) indicates that the crash is a de-leveraging event, not a panic event.&lt;/p&gt;
    &lt;p&gt;In a panic, investors buy Puts on the index to protect themselves, spiking the VIX. In a de-leveraging event, investors simply sell the underlying assets (stocks, gold, crypto) to raise cash. They are not hedging; they are exiting. This explains why the VIX remained subdued while prices collapsed, the selling was orderly, algorithmic, and relentless, rather than emotional and panicked.&lt;/p&gt;
    &lt;p&gt;Skepticism about the "Greenland War" is well-founded. While the diplomatic row was real, its utility as a financial narrative was far greater than its geopolitical reality.&lt;/p&gt;
    &lt;p&gt;President Trump's threat of military force was retracted on January 21 at Davos.This "de-escalation" should theoretically have calmed markets. Instead, the volatility worsened into month-end. This confirms that the real problem wasn't Greenland; it was the re-pricing of the Yen.&lt;/p&gt;
    &lt;p&gt;The financial media loves a simple cause-and-effect narrative. "Stocks down because of War" is easy to digest. "Stocks down because the cross-currency basis swap spread widened due to BOJ minutes" is not. The "Greenland" narrative provided the perfect cover for sophisticated actors to liquidate positions in Gold and Tech under the guise of "war jitters." This allowed them to exit without sparking a broader panic about liquidity in the banking system. The focus on the Arctic masked the structural rot in the leverage complex.&lt;/p&gt;
    &lt;p&gt;The evidence suggests a covert, structural unwinding of the Yen carry trade is the primary driver of the January 2026 market chaos.&lt;/p&gt;
    &lt;p&gt;The interconnectedness of these events is undeniable. The BOJ's rate hike in December 2025 and the subsequent hawkish signaling from the Takaichi administration fundamentally altered the cost of capital for the world's largest carry trade. The "Greenland Crisis" acted as the initial volatility trigger, forcing a reduction in gross exposure. The nomination of Kevin Warsh acted as the final catalyst, shattering the "Debasement Trade" and forcing a liquidation of precious metals and crypto to cover margin calls on Yen-funded positions.&lt;/p&gt;
    &lt;p&gt;Here are some key takeaways:&lt;/p&gt;
    &lt;p&gt;The "Free Money" Era is Over: BOJ policies have fundamentally altered the global cost of capital. The flow of liquidity from Tokyo to New York has reversed.&lt;/p&gt;
    &lt;p&gt;Geopolitics as Catalyst: "Greenland" may have been the spark, but the Yen leverage was the powder keg. The tariff threats disrupted the "Atlantic Trade" narrative, forcing a repatriation of capital.&lt;/p&gt;
    &lt;p&gt;Liquidity Event: The synchronized crash of Gold, Crypto, and Tech confirms a systemic de-leveraging. The "Whale" orders in Yen futures and the breakdown of correlations are the smoking guns of a margin-driven event.&lt;/p&gt;
    &lt;p&gt;With the Japanese election on February 8 and U.S. tariffs looming, the "hammering" of the Yen is likely temporary. The structural trend is now toward repatriation. This implies lower U.S. asset prices, higher U.S. yields, and a stronger Yen over the medium term. The "mystery" of the low VIX is explained by the mechanical nature of the unwind, a controlled demolition of leverage rather than a chaotic panic.&lt;/p&gt;
    &lt;p&gt;This won't just be the big one. This could be the last one. If you've been preparing your whole life, knowing that something's coming, then this could be the thing you've been preparing for. One final opportunity to get the guys who did this.&lt;/p&gt;
    &lt;p&gt;Longing the Yen is commonly referred to as "The Widowmaker Trade" on Wall Street, because you have trillions of dollars of monopoly money working against you. The carry traders have compromised every level of our government. Their greatest vulnerability is the Yen rising in value. They will do anything to defend their positions, even if that means bringing America's economy down with them. Since recent events have made it obvious they're going to lose, we might as well fight them. Most of us probably won't make it out of this fight. But if we at least try, then there's a chance we might prosper when it's over.&lt;/p&gt;
    &lt;p&gt;The IV on OTM CME /6J futures calls is 11% which is astonishingly low. The same is true for calls on the FXY ETF. Call options have defined risk. The more Yen we control, the more its value goes up, and the more crooks on Wall Street get liquidated. The worst that can happen is you lose your monopoly money, but that's been happening anyway. Since carry traders own 10% of all U.S. treasuries, when they get liquidated they'll have to sell a lot of treasury bonds, which means that CME /UB futures and the TLT ETF will fall.&lt;/p&gt;
    &lt;p&gt;This blog is brought to you by various radicals, malcontents, and people who think the system is rigged. We're not affiliated with any organization. Nothing here constitutes financial advice. Occupy Wall Street is not your financial advisor or your lawyer. We're retail investors like you. Do your own research. Past performance does not guarantee future results. We are the 99 percent. The only solution is world revolution. Wall Street's time has finally come.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://occupywallst.com/yen"/><published>2026-02-04T17:49:26+00:00</published></entry></feed>