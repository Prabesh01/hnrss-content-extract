<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-11T05:11:46.277908+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45874987</id><title>Vibe Code Warning – A personal casestudy</title><updated>2025-11-11T05:11:54.205748+00:00</updated><content>&lt;doc fingerprint="e618d5df25439ba8"&gt;
  &lt;main&gt;
    &lt;p&gt;A stateful SWD protocol implementation for debugging RP2350 RISC-V cores (Hazard3) from any Raspberry Pi Pico2 (target) using GPIO's on another Pico (probe).&lt;/p&gt;
    &lt;p&gt;About 80% of the code is vibe coded; The readme is almost completely generated (except the whole vibe-code-warning section). I spent many nights with the oscilloscope and the docs and made a working prototype that was able ti do sba/read/write regs and do abstract commands and progbuf, the rest was done with claude code. The tests are quite comprehensive test suite and I use the core of the library in my own projects, but, as they say, "hic sunt dracones". I also read the readme and the code didn't notice anything wrong (and removed the wrong/unclear parts).&lt;/p&gt;
    &lt;p&gt;This project was my casestudy of vibecoding a more complicated project that I dont understand 100% and there is no obvious existing code that can be "used". It started as ~1000 loc that I have written and knew very well, reading the rp2350, arm swd and riscv debug docs, capturing data with oscilloscope and openocd then decoding it and analyzing the wakeup sequence and then read/write commands. After I got it working I gave it to claude to make it into a library that I can use in other projects, and then I slowly built it up.&lt;/p&gt;
    &lt;p&gt;After about 3-4k lines of code I completely lost track of what is going on, and I woudn't consider this code that I have written, but adding more and more tests felt "nice", or at least reassuring.&lt;/p&gt;
    &lt;p&gt;There was a some gaslighting, particularly when it misunderstood dap_read_mem32 thinking it is reading from ram and not MEM-AP TAR/DRW/RDBUFF protocol, which lead to incredible amount of nonsense.&lt;/p&gt;
    &lt;p&gt;Overall I would say it was a horrible experience, even though it took 10 hours to write close to 10000 lines of code, I don't consider this my project, and I have no sense of acomplishment or growth.&lt;/p&gt;
    &lt;p&gt;In contrast, using AI to read all the docs (which are thousands of pages) and write helpful scripts to decode the oscilloscope data, create packed C structs from docs and etc, was very nice, and I did feel good after. The moment I read the first register and then when I was able to read memory via SBA I felt amazing.&lt;/p&gt;
    &lt;p&gt;The main issue is &lt;code&gt;taste&lt;/code&gt;, when I write code I feel if its good or bad, as I am writing it, I know if its wrong, but using claude code I get desensitized very quickly and I just can't tell, it "reads" OK, but I don't know how it feels. In this case it happened when the code grew about 4x, from 1k to 4k lines. And worse of all, my mental model of the code is completely gone, and with it my ownership.&lt;/p&gt;
    &lt;p&gt;The tokens have no reason or purpose, which makes reading code ridiculously difficult, as and each token can be complete nonsense. When reading human code the symbols have a purpose, someone thought "I will put this in a variable, later I will check its status.", so I pretend I am them, and think &lt;code&gt;why&lt;/code&gt; would they have written this? Shortly after I understand, as they are human and I am human. But the AI symbols have no reason, and worse of all, they all look deceptively correct, so I have to think 10 times harder if it is wrong. With any human code (including your own) it is quite easy to gauge how much you can trust it, and it is quite consistent, with the AI code, one function can be much better than what you woudld've written, and the code 2 lines below can be cargo culted gunk that looks incredibly good, but is structurally wrong.&lt;/p&gt;
    &lt;p&gt;In the end I would say I have gained good understanding of the wires, timings, and the lower level ap/dp mechanics, sba and progbuf, but I regret not writing the whole thing myself, even if it would've taken 10x the time.&lt;/p&gt;
    &lt;p&gt;I fucking hate this.&lt;/p&gt;
    &lt;p&gt;And I can not help, but feel dusgust and shame. Is this what programming is now? I really hope this is some intermediate stage and it changes for the better, the problem is I dont know what "better" is, it seems for some people is not writing the code, for others is not modeling the problem and for third is not having to think. For me, I am not sure, I do want to make things, and many times I dont want to know something, but I want to use it, e.g. the rp2350 usb host controller the way you have to re-arm interrupts and the way the epx register is shared is super annoying, for good reasons probably, but I just want to use it to make my CBI driver.&lt;/p&gt;
    &lt;p&gt;I guess the question is what is the thing I want to make, because you can go way up the stack, from the USB chip registers to CBI to UFI to FAT16 to the OS of the old school computer I am making, but why stop? make the schematics, the pcbs, the cad files, maybe automatically send it to the factory? and then just ship it to me? but why stop? make my webshop, start selling, make a community, ads, marketing, generate some unboxing videos, maybe some viral memes? process the orders directly to the factory, on demand, if there is an issue, it is ready with customer support.&lt;/p&gt;
    &lt;p&gt;What do I do in the meanwhile? Sit on the beach? I hate the beach.&lt;/p&gt;
    &lt;p&gt;Where does it stop?&lt;/p&gt;
    &lt;p&gt;This library implements a complete three-layer abstraction for Serial Wire Debug protocol communication with RP2350's RISC-V Debug Module, modeled after the Debug Access Port specification and informed by ARM Debug Interface Architecture Specification v5.2.&lt;/p&gt;
    &lt;code&gt;┌────────────────────────────────────────┐
│  Application Layer                     │
│  (User Code)                           │
└────────────────┬───────────────────────┘
                 │
┌────────────────▼───────────────────────┐
│  Debug Module Layer (rp2350.c)         │
│  - RISC-V Debug Specification v0.13    │
│  - Hart control via DMCONTROL          │
│  - Abstract commands for GPR access    │
│  - System Bus Access (non-intrusive)   │
│  - PROGBUF execution for CSR access    │
└────────────────┬───────────────────────┘
                 │
┌────────────────▼───────────────────────┐
│  Debug Access Port Layer (dap.c)       │
│  - DP/AP register transactions         │
│  - RP2350-specific DP_SELECT encoding  │
│  - Bank selection caching              │
│  - Memory-mapped debug register access │
└────────────────┬───────────────────────┘
                 │
┌────────────────▼───────────────────────┐
│  Serial Wire Debug Layer (swd*.c)      │
│  - 2-wire bidirectional protocol       │
│  - PIO state machine bit-banging       │
│  - Request/ACK/Data phase handling     │
│  - Parity computation and verification │
│  - Line reset and dormant sequences    │
└────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;The separation of concerns follows classical protocol stack design: each layer exposes a well-defined interface and maintains independent state, with lower layers unaware of higher-layer semantics.&lt;/p&gt;
    &lt;p&gt;Before examining the protocol implementation, we must establish the theoretical foundations of RISC-V external debugging. This section develops the debug architecture from first principles, following the RISC-V External Debug Support Specification v0.13.&lt;/p&gt;
    &lt;p&gt;A RISC-V hart (hardware thread) exists in one of three abstract states:&lt;/p&gt;
    &lt;code&gt;                    ┌─────────────┐
                    │   RUNNING   │
                    │  (Normal)   │
                    └──────┬──────┘
                           │
                  halt_request, ebreak,
                  trigger_fire, step_complete
                           │
                           ▼
                    ┌─────────────┐
                    │   HALTED    │
                    │  (Debug)    │
                    └──────┬──────┘
                           │
                     resume_request
                           │
                           ▼
                    ┌─────────────┐
                    │  RESUMING   │
                    │ (Transient) │
                    └──────┬──────┘
                           │
                           ▼
                    ┌─────────────┐
                    │   RUNNING   │
                    └─────────────┘
&lt;/code&gt;
    &lt;p&gt;State 1: RUNNING - The hart executes instructions from main memory. PC advances according to program flow. All architectural state (GPRs, CSRs, memory) is accessible to the executing program.&lt;/p&gt;
    &lt;p&gt;State 2: HALTED - The hart has entered debug mode. No instructions from main memory execute. The hart is "parked" in a special debug ROM or implicit debug loop within the Debug Module. Debug-specific CSRs (DPC, DCSR, DSCRATCH) become accessible.&lt;/p&gt;
    &lt;p&gt;State 3: RESUMING - A transient state where the hart has received a resume request but has not yet returned to normal execution. This state exists to model the asynchronous nature of resume operations.&lt;/p&gt;
    &lt;p&gt;The Debug Module (DM) is a hardware block separate from the hart itself. It acts as a "shadow controller" that can:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Observe hart state without halting (DMSTATUS register)&lt;/item&gt;
      &lt;item&gt;Command hart transitions (halt, resume, reset via DMCONTROL)&lt;/item&gt;
      &lt;item&gt;Access hart registers when halted (abstract commands)&lt;/item&gt;
      &lt;item&gt;Access system memory independently of hart state (System Bus Access)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The DM is itself controlled by an external debugger via a Debug Transport Module (DTM). In our case, the DTM is the SWD interface.&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────────────┐
│  External Debugger (Host CPU)                    │
└────────────────────┬─────────────────────────────┘
                     │
                     ▼ SWD Protocol
┌──────────────────────────────────────────────────┐
│  Debug Transport Module (DTM)                    │
│  - Exposes DM registers as memory-mapped space   │
└────────────────────┬─────────────────────────────┘
                     │
                     ▼ Internal Bus
┌──────────────────────────────────────────────────┐
│  Debug Module (DM)                               │
│  ┌──────────────┐  ┌──────────────┐              │
│  │  Abstract    │  │  System Bus  │              │
│  │  Command     │  │  Master      │              │
│  │  Engine      │  │              │              │
│  └──────┬───────┘  └──────┬───────┘              │
│         │                 │                      │
└─────────┼─────────────────┼──────────────────────┘
          │                 │
          ▼                 ▼
    ┌─────────────┐   ┌──────────────┐
    │  Hart 0     │   │ System Bus   │
    │  (Hazard3)  │   │              │
    ├─────────────┤   └──────────────┘
    │  Hart 1     │
    │  (Hazard3)  │
    └─────────────┘    
&lt;/code&gt;
    &lt;p&gt;When a hart enters debug mode, it is not simply "stopped." Rather, it enters a special execution context analogous to an exception handler:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;PC is saved to DPC (Debug Program Counter, CSR 0x7b1)&lt;/item&gt;
      &lt;item&gt;Privilege level is elevated to M-mode (Machine mode, highest privilege)&lt;/item&gt;
      &lt;item&gt;DCSR.cause records the entry reason (halt request, ebreak, trigger, etc.)&lt;/item&gt;
      &lt;item&gt;Hart begins executing from the debug exception vector (typically in debug ROM)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The debug exception vector contains a tight polling loop that repeatedly checks for commands from the Debug Module. This loop is architecturally invisible to the debugger—we simply observe the hart as "halted."&lt;/p&gt;
    &lt;p&gt;The Abstract Command mechanism provides a hardware-implemented function call interface. Each abstract command is a 32-bit word written to the COMMAND register that encodes:&lt;/p&gt;
    &lt;code&gt;31                            24 23                            0
┌────────────────────────────────┬────────────────────────────────┐
│         cmdtype                │         command-specific       │
└────────────────────────────────┴────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;cmdtype=0: Access Register&lt;/p&gt;
    &lt;code&gt;31      24 23          20 19 18 17 16 15                          0
┌──────────┬─────────────┬─┬──┬──┬──┬──────────────────────────────┐
│    0     │   aarsize   │0│pc│tr│wr│         regno                │
└──────────┴─────────────┴─┴──┴──┴──┴──────────────────────────────┘

aarsize: Access size (2 = 32-bit)
aarpostincrement: Ignored
postexec: Execute program buffer after transfer
transfer: Perform the transfer (1=yes)
write: Direction (1=write, 0=read)
regno: Register number (0x1000-0x101f for GPRs x0-x31)
&lt;/code&gt;
    &lt;p&gt;The Debug Module hardware interprets this command and performs the register access autonomously. From the debugger's perspective, this is a synchronous operation: write COMMAND, poll ABSTRACTCS.busy until clear, read result from DATA0.&lt;/p&gt;
    &lt;p&gt;The Program Buffer (PROGBUF) is a small instruction memory (2-16 entries) within the Debug Module. When abstract commands cannot accomplish a task (e.g., accessing debug-only CSRs), the debugger can:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Write RISC-V instructions to PROGBUF&lt;/item&gt;
      &lt;item&gt;Issue an abstract command with the &lt;code&gt;postexec&lt;/code&gt;bit set&lt;/item&gt;
      &lt;item&gt;The hart executes PROGBUF instructions while still in debug mode&lt;/item&gt;
      &lt;item&gt;The final &lt;code&gt;ebreak&lt;/code&gt;instruction returns control to the Debug Module&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a "code injection" attack—the hart never leaves debug mode. It's analogous to a debugger writing instructions into a trap handler's stack frame.&lt;/p&gt;
    &lt;p&gt;SBA provides a second path to memory that bypasses the hart entirely:&lt;/p&gt;
    &lt;code&gt;         Debugger Commands
                │
                ▼
         ┌─────────────┐
         │     DM      │
         └──┬───────┬──┘
            │       │
   ┌────────┘       └───────┐
   │                        │
   ▼ Abstract Cmd           ▼ SBA
┌──────┐                ┌─────────┐
│ Hart │───────────────▶│ Memory  │
└──────┘  Hart Accesses └─────────┘
&lt;/code&gt;
    &lt;p&gt;The hart and SBA compete for memory bus bandwidth. The hart's view of memory may differ from SBA's view due to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Cache: Hart caches writes; SBA sees stale memory&lt;/item&gt;
      &lt;item&gt;MMU/PMP: Hart accesses are translated/protected; SBA bypasses&lt;/item&gt;
      &lt;item&gt;Atomicity: Hart's atomic operations (LR/SC) are invisible to SBA&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a bug—it's a fundamental architectural trade-off. SBA provides speed and non-intrusiveness at the cost of coherency guarantees.&lt;/p&gt;
    &lt;p&gt;RISC-V debugging rests on several invariants:&lt;/p&gt;
    &lt;p&gt;Invariant 1: Debug Mode is Atomic While in debug mode, the hart executes no instructions from main memory. The debugger has exclusive control.&lt;/p&gt;
    &lt;p&gt;Invariant 2: Architectural Transparency Entering and exiting debug mode does not change architected state (except DPC/DCSR). The program cannot detect it was halted (modulo real-time constraints).&lt;/p&gt;
    &lt;p&gt;Invariant 3: Debug Privilege Debug mode executes at maximum privilege (M-mode). All memory is accessible, all CSRs are readable.&lt;/p&gt;
    &lt;p&gt;Invariant 4: No Interrupts in Debug Interrupts are masked while in debug mode. The debugger must explicitly re-enable them.&lt;/p&gt;
    &lt;p&gt;These invariants enable reproducible debugging: halting twice at the same PC should show identical state.&lt;/p&gt;
    &lt;p&gt;Serial Wire Debug (SWD) is a 2-wire replacement for JTAG's 5-wire interface, developed by ARM. The protocol operates over two signals:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SWCLK: Clock signal driven by the debugger (host)&lt;/item&gt;
      &lt;item&gt;SWDIO: Bidirectional data signal with turnaround phases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each SWD transaction consists of three phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Request Phase (8 bits, host drives SWDIO):&lt;/p&gt;
        &lt;code&gt;Bit 0: Start (always 1) Bit 1: APnDP (0=DP access, 1=AP access) Bit 2: RnW (0=Write, 1=Read) Bit 3-4: A[3:2] (register address bits) Bit 5: Parity (even parity of bits 1-4) Bit 6: Stop (always 0) Bit 7: Park (always 1)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Acknowledge Phase (3 bits, target drives SWDIO):&lt;/p&gt;
        &lt;code&gt;OK (001): Transaction accepted WAIT (010): Target requests retry FAULT (100): Error condition&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data Phase (33 bits, direction depends on RnW):&lt;/p&gt;
        &lt;code&gt;Bits 0-31: Data word Bit 32: Parity bit&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Turnaround cycles (host releases SWDIO, target can drive) occur between request→ack and during data phase direction changes.&lt;/p&gt;
    &lt;p&gt;Our implementation of the packet construction is in &lt;code&gt;swd_protocol.c:97-113&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;static uint8_t make_swd_request(bool APnDP, bool RnW, uint8_t addr) {
    uint8_t a2 = (addr &amp;gt;&amp;gt; 2) &amp;amp; 1;
    uint8_t a3 = (addr &amp;gt;&amp;gt; 3) &amp;amp; 1;
    uint8_t parity = (APnDP + RnW + a2 + a3) &amp;amp; 1;

    uint8_t request = 0;
    request |= (1 &amp;lt;&amp;lt; 0);          // Start bit
    request |= (APnDP &amp;lt;&amp;lt; 1);      // AP/DP select
    request |= (RnW &amp;lt;&amp;lt; 2);        // Read/Write
    request |= (a2 &amp;lt;&amp;lt; 3);         // Address bit 2
    request |= (a3 &amp;lt;&amp;lt; 4);         // Address bit 3
    request |= (parity &amp;lt;&amp;lt; 5);     // Parity
    request |= (0 &amp;lt;&amp;lt; 6);          // Stop bit
    request |= (1 &amp;lt;&amp;lt; 7);          // Park bit
    return request;
}&lt;/code&gt;
    &lt;p&gt;Unlike software bit-banging (which suffers from timing jitter and CPU overhead), this implementation uses RP2040/RP2350's Programmable I/O (PIO) blocks for deterministic timing.&lt;/p&gt;
    &lt;p&gt;The PIO program (&lt;code&gt;swd.pio&lt;/code&gt;) implements a command-based interface where each FIFO entry encodes either a command or data payload. Command format:&lt;/p&gt;
    &lt;code&gt;Bits 0-7:   Bit count - 1
Bit 8:      Direction (0=input, 1=output)
Bits 9-13:  Target instruction address
&lt;/code&gt;
    &lt;p&gt;The state machine operates at 4 cycles per clock period, providing precise SWCLK generation independent of system clock frequency. See &lt;code&gt;swd.pio:45-68&lt;/code&gt; for the complete implementation.&lt;/p&gt;
    &lt;p&gt;Clock divider calculation (&lt;code&gt;swd_protocol.c:313-330&lt;/code&gt;) accounts for this 4-cycle period:&lt;/p&gt;
    &lt;code&gt;uint32_t clk_sys_khz = clock_get_hz(clk_sys) / 1000;
uint32_t divider = (((clk_sys_khz + freq_khz - 1) / freq_khz) + 3) / 4;&lt;/code&gt;
    &lt;p&gt;ARM Debug Interface Architecture v6 introduces a Dormant State to enable coexistence of multiple debug protocols (JTAG and SWD) on the same pins. At power-up, RP2350's SW-DP enters the Dormant state, requiring explicit activation before SWD operations can proceed.&lt;/p&gt;
    &lt;p&gt;The dormant state solves a fundamental problem: JTAG uses 5 signals (TMS, TCK, TDI, TDO, TRST), while SWD uses 2 (SWCLK, SWDIO). When both protocols share physical pins, the debug port must determine which protocol the debugger intends to use. The solution is to require a protocol-specific "unlock" sequence that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Cannot be generated accidentally by non-debug traffic on the pins&lt;/item&gt;
      &lt;item&gt;Is sufficiently long to avoid false positives (128 bits)&lt;/item&gt;
      &lt;item&gt;Uniquely identifies the target protocol (JTAG vs SWD)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SW-DP implements a finite state machine with three protocol modes:&lt;/p&gt;
    &lt;code&gt;Power-On → [Default State] → Dormant
                                 │
                    ┌────────────┼────────────┐
                    │                         │
         JTAG Activation              SWD Activation
         Sequence (0x33bbbbba)        Sequence (0x1a)
                    │                         │
                    ▼                         ▼
              ┌──────────┐              ┌──────────┐
              │   JTAG   │              │   SWD    │
              │  Active  │              │  Active  │
              └────┬─────┘              └────┬─────┘
                   │                         │
         JTAG-to-Dormant              SWD-to-Dormant
         Sequence                     Sequence
                   │                         │
                   └──────────┬──────────────┘
                              ▼
                         ┌──────────┐
                         │ Dormant  │
                         └──────────┘
&lt;/code&gt;
    &lt;p&gt;Once activated, the debug port remains in the selected protocol mode until:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A transition-to-dormant sequence is sent&lt;/item&gt;
      &lt;item&gt;Power is cycled&lt;/item&gt;
      &lt;item&gt;The external reset (RUN) pin is asserted&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Before sending a protocol-specific activation code, ARM requires transmission of a 128-bit Selection Alert Sequence. This sequence serves as a "wake-up call" that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Synchronizes the target's bit-stream parser&lt;/item&gt;
      &lt;item&gt;Ensures the target is listening for an activation sequence&lt;/item&gt;
      &lt;item&gt;Provides sufficient entropy to avoid accidental activation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Selection Alert Sequence is a fixed 128-bit pattern defined in the ADI v6 specification:&lt;/p&gt;
    &lt;code&gt;0x19bc0ea2_e3ddafe9_86852d95_6209f392 (transmitted LSB-first)
&lt;/code&gt;
    &lt;p&gt;This constant was chosen for its Hamming distance properties—it is unlikely to occur in normal signal traffic or be generated by crosstalk, glitches, or other non-debug activity.&lt;/p&gt;
    &lt;p&gt;Our implementation (&lt;code&gt;swd_protocol.c:357-382&lt;/code&gt;) uses a defensive activation strategy that ensures reliable connection regardless of the SW-DP's initial state:&lt;/p&gt;
    &lt;code&gt;// Phase 1: Exit any prior protocol mode
static const uint8_t seq_jtag_to_dormant[] = {
    0xff,0xff,0xff,0xff,0xff,0xff,0xff, 0xbc,0xe3
};

// Phase 2: Activate SWD mode
static const uint8_t seq_dormant_to_swd[] = {
    0xff,                                        // Line reset (8 ones)
    0x92,0xf3,0x09,0x62,0x95,0x2d,0x85,0x86,     // Selection Alert
    0xe9,0xaf,0xdd,0xe3,0xa2,0x0e,0xbc,0x19,     //   (128 bits)
    0xa0,0xf1,0xff,                              // SWD Activation Code (0x1a)
    0xff,0xff,0xff,0xff,0xff,0xff,0xff, 0xff,    // Line reset (&amp;gt;50 ones)
    0x00                                         // Idle low
};&lt;/code&gt;
    &lt;p&gt;Why this two-phase approach?&lt;/p&gt;
    &lt;p&gt;The problem is that we don't know the SW-DP's current state:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fresh power-up: SW-DP is in Dormant mode (default)&lt;/item&gt;
      &lt;item&gt;Prior debug session: SW-DP may be in SWD or JTAG mode&lt;/item&gt;
      &lt;item&gt;Failed connection attempt: SW-DP may be in an undefined state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the SW-DP is already in SWD or JTAG mode, sending the Selection Alert Sequence will be interpreted as data transactions, potentially putting the DP into an error state. Our solution:&lt;/p&gt;
    &lt;p&gt;Phase 1: Force transition to Dormant&lt;/p&gt;
    &lt;p&gt;Send the JTAG-to-Dormant sequence (56 ones followed by 0xbc, 0xe3). This sequence:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If in JTAG mode: transitions to Dormant&lt;/item&gt;
      &lt;item&gt;If in SWD mode: interpreted as line reset + invalid transactions (harmless)&lt;/item&gt;
      &lt;item&gt;If already Dormant: has no effect (dormant state ignores invalid input)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The sequence consists of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;56 clock cycles high (JTAG TMS=1 → Test-Logic-Reset state)&lt;/item&gt;
      &lt;item&gt;0x3cbe (0xbc, 0xe3 LSB-first): JTAG-specific exit pattern&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 2: Activate SWD from Dormant&lt;/p&gt;
    &lt;p&gt;Now that we're guaranteed to be in Dormant mode (or already in SWD mode where line reset is idempotent), we send:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Line reset (8 ones): Clears any pending SWD transactions&lt;/item&gt;
      &lt;item&gt;Selection Alert Sequence (128 bits): Wakes dormant state machine&lt;/item&gt;
      &lt;item&gt;SWD Activation Code (0x1a, 8 bits): Selects SWD protocol&lt;/item&gt;
      &lt;item&gt;Line reset (&amp;gt;50 ones): Enters SWD Reset state, clearing sticky errors&lt;/item&gt;
      &lt;item&gt;Idle cycles: Ensures clean transition&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SWD Activation Code &lt;code&gt;0x1a&lt;/code&gt; decodes as:&lt;/p&gt;
    &lt;code&gt;Bits[7:0] = 0x1a = 0b00011010
&lt;/code&gt;
    &lt;p&gt;This specific bit pattern was chosen to be distinct from valid JTAG TMS sequences, ensuring protocol disambiguation.&lt;/p&gt;
    &lt;p&gt;The RP2350 datasheet (Section 3.5.1) describes a simpler connection sequence:&lt;/p&gt;
    &lt;code&gt;1. At least 8 × SWCLK cycles with SWDIO high
2. The 128-bit Selection Alert sequence
3. Four SWCLK cycles with SWDIO low
4. SWD activation code: 0x1a, LSB first
5. At least 50 × SWCLK cycles with SWDIO high (line reset)
6. A DPIDR read to exit the Reset state
&lt;/code&gt;
    &lt;p&gt;This sequence assumes the SW-DP is in Dormant mode at power-up. However, in real-world scenarios:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The target may have been previously debugged (SW-DP in SWD mode)&lt;/item&gt;
      &lt;item&gt;A debugger crash may have left the SW-DP in an error state&lt;/item&gt;
      &lt;item&gt;Multi-drop SWD configurations may require explicit state reset&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our JTAG→Dormant→SWD sequence provides universal robustness: it works regardless of the SW-DP's initial state. The cost is negligible—approximately 100 extra clock cycles, taking ~100µs at 1 MHz SWCLK—while the benefit is reliable connection without manual power-cycling.&lt;/p&gt;
    &lt;p&gt;After activation, we immediately read DP_IDCODE (&lt;code&gt;swd_protocol.c:386-397&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t idcode = 0;
err = swd_read_dp_raw(target, DP_IDCODE, &amp;amp;idcode);
if (err != SWD_OK) {
    swd_set_error(target, err, "Failed to read IDCODE");
    return err;
}

if ((idcode &amp;amp; 0x0fffffff) == 0) {
    swd_set_error(target, SWD_ERROR_PROTOCOL, "Invalid IDCODE: 0x%08x", idcode);
    return SWD_ERROR_PROTOCOL;
}&lt;/code&gt;
    &lt;p&gt;A successful IDCODE read confirms:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SWD protocol is active&lt;/item&gt;
      &lt;item&gt;The SW-DP is responding to transactions&lt;/item&gt;
      &lt;item&gt;The SWCLK frequency is within tolerance&lt;/item&gt;
      &lt;item&gt;SWDIO signal integrity is sufficient&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For RP2350, the IDCODE is &lt;code&gt;0x4c013477&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;This defensive activation strategy, while not strictly necessary for fresh power-up scenarios, ensures our library works reliably across the full range of real-world debug connection scenarios—a critical property for a reusable debug library.&lt;/p&gt;
    &lt;p&gt;The Debug Access Port (DAP) provides memory-mapped access to debug resources through two register banks:&lt;/p&gt;
    &lt;p&gt;The Debug Port (DP) manages power domains and AP selection:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DP_IDCODE (0x0): Designer and part number identification&lt;/item&gt;
      &lt;item&gt;DP_CTRL_STAT (0x4): Power control and status flags&lt;/item&gt;
      &lt;item&gt;DP_SELECT (0x8): AP and register bank selection&lt;/item&gt;
      &lt;item&gt;DP_RDBUFF (0xC): Read buffer for pipelined AP reads&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Access Ports (AP) provide interfaces to debug resources. RP2350 implements multiple APs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AP 0x0: ROM Table&lt;/item&gt;
      &lt;item&gt;AP 0x2: ARM Core 0 AHB-AP&lt;/item&gt;
      &lt;item&gt;AP 0x4: ARM Core 1 AHB-AP&lt;/item&gt;
      &lt;item&gt;AP 0x8: RP2350-specific AP&lt;/item&gt;
      &lt;item&gt;AP 0xA: RISC-V APB-AP (target of this library)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each AP has standardized registers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AP_CSW (0x00): Control/Status Word&lt;/item&gt;
      &lt;item&gt;AP_TAR (0x04): Transfer Address Register&lt;/item&gt;
      &lt;item&gt;AP_DRW (0x0C): Data Read/Write Register&lt;/item&gt;
      &lt;item&gt;AP_IDR (0xFC): Identification Register&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Standard ARM DP_SELECT format uses bits[31:24] for APSEL and bits[7:4] for APBANKSEL. RP2350 implements a non-standard encoding (&lt;code&gt;dap.c:18-22&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t make_dp_select_rp2350(uint8_t apsel, uint8_t bank, bool ctrlsel) {
    // [15:12] = APSEL, [11:8] = 0xD, [7:4] = bank, [0] = ctrlsel
    return ((apsel &amp;amp; 0xF) &amp;lt;&amp;lt; 12) | (0xD &amp;lt;&amp;lt; 8) | ((bank &amp;amp; 0xF) &amp;lt;&amp;lt; 4) | (ctrlsel ? 1 : 0);
}&lt;/code&gt;
    &lt;p&gt;The magic constant 0xD in bits[11:8] is undocumented but required for correct AP selection.&lt;/p&gt;
    &lt;p&gt;AP registers are accessed through a banking mechanism where DP_SELECT must be written before each AP access. To minimize SWD transactions, the library maintains a cache of the current bank selection (&lt;code&gt;dap.c:28-55&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;static swd_error_t select_ap_bank(swd_target_t *target, uint8_t apsel, uint8_t bank) {
    if (target-&amp;gt;dap.current_apsel == apsel &amp;amp;&amp;amp;
        target-&amp;gt;dap.current_bank == bank &amp;amp;&amp;amp;
        target-&amp;gt;dap.ctrlsel == true) {
        return SWD_OK;  // Already selected
    }
    // Write DP_SELECT...
    target-&amp;gt;dap.current_apsel = apsel;
    target-&amp;gt;dap.current_bank = bank;
    // ...
}&lt;/code&gt;
    &lt;p&gt;This caching reduces transaction count by approximately 50% in typical debug sessions.&lt;/p&gt;
    &lt;p&gt;Before any debug operations can proceed, the Debug Power Domain (DPD) and System Power Domain (SPD) must be powered up. This is not a physical power operation but rather clock and reset domain enabling.&lt;/p&gt;
    &lt;p&gt;The power-up sequence (&lt;code&gt;dap.c:61-110&lt;/code&gt;) follows the ARM Debug Interface specification:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clear sticky errors: Write 0 to DP_CTRL_STAT&lt;/item&gt;
      &lt;item&gt;Request power-up: Set CDBGPWRUPREQ (bit 28) and CSYSPWRUPREQ (bit 30)&lt;/item&gt;
      &lt;item&gt;Poll acknowledgment: Wait for CDBGPWRUPACK (bit 29) and CSYSPWRUPACK (bit 31)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;uint32_t ctrl_stat = (1 &amp;lt;&amp;lt; 28) | (1 &amp;lt;&amp;lt; 30);
swd_write_dp_raw(target, DP_CTRL_STAT, ctrl_stat);

for (int i = 0; i &amp;lt; 10; i++) {
    swd_read_dp_raw(target, DP_CTRL_STAT, &amp;amp;status);
    bool cdbgpwrupack = (status &amp;gt;&amp;gt; 29) &amp;amp; 1;
    bool csyspwrupack = (status &amp;gt;&amp;gt; 31) &amp;amp; 1;
    if (cdbgpwrupack &amp;amp;&amp;amp; csyspwrupack) {
        return SWD_OK;
    }
    sleep_ms(20);
}&lt;/code&gt;
    &lt;p&gt;Failure to complete this sequence results in all subsequent debug operations returning WAIT responses indefinitely.&lt;/p&gt;
    &lt;p&gt;After DAP power-up, the RP2350-specific Debug Module must be initialized through an undocumented activation handshake. This sequence was reverse-engineered from OpenOCD's RP2350 support with an oscilloscope and patience.&lt;/p&gt;
    &lt;p&gt;The activation sequence (&lt;code&gt;rp2350.c:106-194&lt;/code&gt;) consists of:&lt;/p&gt;
    &lt;code&gt;uint32_t sel_bank0 = make_dp_select_rp2350(AP_RISCV, 0, true);
dap_write_dp(target, DP_SELECT, sel_bank0);

uint32_t csw = 0xA2000002;  // 32-bit access, auto-increment disabled
dap_write_ap(target, AP_RISCV, AP_CSW, csw);&lt;/code&gt;
    &lt;p&gt;The Debug Module registers are normally accessed through Bank 0, but activation requires Bank 1:&lt;/p&gt;
    &lt;code&gt;uint32_t sel_bank1 = make_dp_select_rp2350(AP_RISCV, 1, true);
dap_write_dp(target, DP_SELECT, sel_bank1);

// Three-phase handshake
dap_write_ap(target, AP_RISCV, AP_CSW, 0x00000000);  // Reset
dap_read_dp(target, DP_RDBUFF);
sleep_ms(50);

dap_write_ap(target, AP_RISCV, AP_CSW, 0x00000001);  // Activate
dap_read_dp(target, DP_RDBUFF);
sleep_ms(50);

dap_write_ap(target, AP_RISCV, AP_CSW, 0x07FFFFC1);  // Configure
dap_read_dp(target, DP_RDBUFF);
sleep_ms(50);&lt;/code&gt;
    &lt;p&gt;The expected status response is &lt;code&gt;0x04010001&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The RISC-V Debug Module implements the RISC-V External Debug Support specification v0.13. Debug Module registers are memory-mapped at base address 0x40 (register addresses are byte offsets × 4).&lt;/p&gt;
    &lt;p&gt;Key registers (&lt;code&gt;rp2350.c:17-29&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;#define DM_DMCONTROL   (0x10 * 4)  // Hart control
#define DM_DMSTATUS    (0x11 * 4)  // Hart status
#define DM_ABSTRACTCS  (0x16 * 4)  // Abstract command status
#define DM_COMMAND     (0x17 * 4)  // Abstract command execution
#define DM_DATA0       (0x04 * 4)  // Data transfer register
#define DM_PROGBUF0    (0x20 * 4)  // Program buffer word 0
#define DM_PROGBUF1    (0x21 * 4)  // Program buffer word 1
#define DM_SBCS        (0x38 * 4)  // System Bus Access Control
#define DM_SBADDRESS0  (0x39 * 4)  // SBA Address
#define DM_SBDATA0     (0x3C * 4)  // SBA Data&lt;/code&gt;
    &lt;p&gt;Hart (hardware thread) execution is controlled through DMCONTROL register fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;dmactive (bit 0): Debug Module active (must be 1)&lt;/item&gt;
      &lt;item&gt;haltreq (bit 31): Request hart halt&lt;/item&gt;
      &lt;item&gt;resumereq (bit 30): Request hart resume&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Halt sequence (&lt;code&gt;rp2350.c:205-240&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t dmcontrol = (1 &amp;lt;&amp;lt; 31) | (1 &amp;lt;&amp;lt; 0);  // haltreq | dmactive
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);

// Poll DMSTATUS.allhalted (bit 9)
for (int i = 0; i &amp;lt; 10; i++) {
    swd_result_t result = dap_read_mem32(target, DM_DMSTATUS);
    bool allhalted = (result.value &amp;gt;&amp;gt; 9) &amp;amp; 1;
    if (allhalted) {
        target-&amp;gt;rp2350.hart_halted = true;
        return SWD_OK;
    }
    sleep_ms(10);
}&lt;/code&gt;
    &lt;p&gt;Abstract commands provide a high-level interface to hart state without halting. The COMMAND register format for GPR access:&lt;/p&gt;
    &lt;code&gt;Bits 0-15:   regno (0x1000 + reg_num for GPRs)
Bit 16:      write (1=write, 0=read)
Bit 17:      transfer (1=execute transfer)
Bits 20-22:  aarsize (2=32-bit access)
&lt;/code&gt;
    &lt;p&gt;GPR read implementation (&lt;code&gt;rp2350.c:333-389&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;uint32_t command = 0;
command |= (0x1000 + reg_num) &amp;lt;&amp;lt; 0;    // regno
command |= (1 &amp;lt;&amp;lt; 17);                  // transfer
command |= (2 &amp;lt;&amp;lt; 20);                  // aarsize=32-bit

dap_write_mem32(target, DM_COMMAND, command);
wait_abstract_command(target);  // Poll ABSTRACTCS.busy
result = dap_read_mem32(target, DM_DATA0);&lt;/code&gt;
    &lt;p&gt;The Program Buffer (PROGBUF) is a 16-entry instruction memory within the Debug Module that enables execution of arbitrary RISC-V code in the debug context. Understanding its operation requires examining the execution model, register preservation semantics, and synchronization mechanisms.&lt;/p&gt;
    &lt;p&gt;A RISC-V hart operates in one of two contexts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Normal Context: The hart executes from main memory, PC advances sequentially, and all architectural state is visible to the program.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Debug Context: Upon entering debug mode (via halt request, ebreak, or trigger), the hart:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Saves PC to DPC (Debug Program Counter, CSR 0x7b1)&lt;/item&gt;
          &lt;item&gt;Enters a special execution mode where PROGBUF instructions execute&lt;/item&gt;
          &lt;item&gt;Maintains all GPRs and CSRs in their pre-halt state&lt;/item&gt;
          &lt;item&gt;Cannot access main memory without explicit instructions&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Debug Module provides a "scratch pad" where debugger-supplied instructions execute with full access to hart state, but without disturbing that state beyond explicit modifications.&lt;/p&gt;
    &lt;p&gt;RP2350's Debug Module provides 2 program buffer entries (PROGBUF0 and PROGBUF1), though the specification allows up to 16. Each entry holds one 32-bit RISC-V instruction:&lt;/p&gt;
    &lt;code&gt;#define DM_PROGBUF0  (0x20 * 4)  // First instruction
#define DM_PROGBUF1  (0x21 * 4)  // Second instruction (typically ebreak)&lt;/code&gt;
    &lt;p&gt;The execution model assumes the final instruction is &lt;code&gt;ebreak&lt;/code&gt; (0x00100073), which returns control to the Debug Module and makes the hart available for further debug operations.&lt;/p&gt;
    &lt;p&gt;Abstract commands can trigger PROGBUF execution through the &lt;code&gt;postexec&lt;/code&gt; bit (bit 18 of the COMMAND register). This creates a transactional execution model:&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────┐
│ 1. Debugger writes PROGBUF instructions  │
├──────────────────────────────────────────┤
│ 2. Debugger writes DATA0 (optional)      │
├──────────────────────────────────────────┤
│ 3. Abstract command with postexec=1      │
│   - Transfers DATA0 → GPR (if transfer=1)│
│   - Executes PROGBUF[0]..PROGBUF[N]      │
│   - Executes ebreak (returns to DM)      │
│   - Transfers GPR → DATA0 (if transfer=1)│
└──────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;This mechanism eliminates race conditions: the data transfer and program execution form an atomic operation from the debugger's perspective.&lt;/p&gt;
    &lt;p&gt;The Debug Program Counter (DPC, CSR 0x7b1) cannot be accessed via abstract commands—it exists only in debug context and abstract commands target normal context registers. Reading DPC requires PROGBUF execution (&lt;code&gt;rp2350.c:804-833&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;Phase 1: Preserve scratch register&lt;/p&gt;
    &lt;code&gt;swd_result_t saved_s0 = rp2350_read_reg(target, hart_id, 8);  // x8 = s0&lt;/code&gt;
    &lt;p&gt;The RISC-V ABI designates s0 (x8) as a saved register, but we must preserve it because our PROGBUF code will clobber it.&lt;/p&gt;
    &lt;p&gt;Phase 2: Write PROGBUF instructions&lt;/p&gt;
    &lt;code&gt;dap_write_mem32(target, DM_PROGBUF0, 0x7b102473);  // csrr s0, dpc
dap_write_mem32(target, DM_PROGBUF1, 0x00100073);  // ebreak&lt;/code&gt;
    &lt;p&gt;The instruction &lt;code&gt;csrr s0, dpc&lt;/code&gt; (CSR Read) has the encoding:&lt;/p&gt;
    &lt;code&gt;31      20 19   15 14  12 11    7 6      0
┌─────────┬───────┬──────┬───────┬────────┐
│ 0x7b1   │ 0x00  │ 0x2  │ 0x08  │ 0x73   │
│ CSR addr│ rs1   │funct3│  rd   │ opcode │
│  DPC    │  x0   │CSRRS │  s0   │ SYSTEM │
└─────────┴───────┴──────┴───────┴────────┘
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;funct3=0x2 (CSRRS): CSR Read and Set. Since rs1=x0, no bits are set (read-only operation).&lt;/item&gt;
      &lt;item&gt;CSR 0x7b1: DPC is defined in RISC-V Debug Spec v0.13, section 4.8.2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 3: Execute with postexec&lt;/p&gt;
    &lt;code&gt;uint32_t command = (1 &amp;lt;&amp;lt; 18);  // postexec=1, transfer=0
dap_write_mem32(target, DM_COMMAND, command);
wait_abstract_command(target);  // Poll ABSTRACTCS.busy&lt;/code&gt;
    &lt;p&gt;The hart now executes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;csrr s0, dpc&lt;/code&gt;→ DPC value loaded into s0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ebreak&lt;/code&gt;→ Return to Debug Module, s0 contains DPC&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 4: Extract result via abstract command&lt;/p&gt;
    &lt;code&gt;result = rp2350_read_reg(target, hart_id, 8);  // Read s0 (now contains DPC)&lt;/code&gt;
    &lt;p&gt;Phase 5: Restore architectural state&lt;/p&gt;
    &lt;code&gt;rp2350_write_reg(target, hart_id, 8, saved_s0.value);  // Restore s0&lt;/code&gt;
    &lt;p&gt;This five-phase sequence is invisible to the hart's normal execution: when resumed, all registers appear unchanged.&lt;/p&gt;
    &lt;p&gt;Writing DPC uses the inverse data flow (&lt;code&gt;rp2350.c:879-909&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;// Phase 1: Transfer new PC value to s0
err = rp2350_write_reg(target, hart_id, 8, new_pc_value);

// Phase 2: Write PROGBUF to copy s0 → DPC
dap_write_mem32(target, DM_PROGBUF0, 0x7b141073);  // csrw dpc, s0
dap_write_mem32(target, DM_PROGBUF1, 0x00100073);  // ebreak

// Phase 3: Execute
uint32_t command = (1 &amp;lt;&amp;lt; 18);  // postexec=1
dap_write_mem32(target, DM_COMMAND, command);
wait_abstract_command(target);&lt;/code&gt;
    &lt;p&gt;The instruction &lt;code&gt;csrw dpc, s0&lt;/code&gt; (CSR Write) has encoding 0x7b141073:&lt;/p&gt;
    &lt;code&gt;31      20 19   15 14  12 11    7 6      0
┌─────────┬───────┬──────┬───────┬────────┐
│ 0x7b1   │ 0x08  │ 0x1  │ 0x00  │ 0x73   │
│ CSR addr│ rs1   │funct3│  rd   │ opcode │
│  DPC    │  s0   │CSRRW │  x0   │ SYSTEM │
└─────────┴───────┴──────┴───────┴────────┘
&lt;/code&gt;
    &lt;p&gt;funct3=0x1 (CSRRW): CSR Read and Write. The old CSR value is discarded (rd=x0), and s0's value is written to DPC.&lt;/p&gt;
    &lt;p&gt;The PROGBUF execution environment imposes several constraints:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Memory Access Limitation: PROGBUF instructions execute in debug mode, where memory access depends on Debug Module configuration. Standard loads/stores may fault.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Instruction Count: With only 2 entries, complex operations require multiple PROGBUF sequences. Each sequence incurs the cost of abstract command execution (~100µs typical).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No Branching: PROGBUF is linear. Conditional execution requires host-side logic to decide which PROGBUF sequence to execute.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Register Pressure: Only one scratch register (s0) is conventionally used. More complex operations require additional saves/restores.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ebreak Requirement: The final instruction must be&lt;/p&gt;&lt;code&gt;ebreak&lt;/code&gt;. Omitting it causes the hart to hang in debug mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This execution model provides a "remote procedure call" mechanism where the host supplies short instruction sequences that execute atomically on the hart, providing a window into debug-only architectural state.&lt;/p&gt;
    &lt;p&gt;System Bus Access (SBA) represents a fundamental departure from the traditional halt-based debugging model. Where classical debugging requires stopping the hart, transferring data through GPRs, and resuming, SBA provides a "back door" to the memory subsystem that operates concurrently with hart execution.&lt;/p&gt;
    &lt;p&gt;The Debug Module contains a bus master that can initiate memory transactions on the system bus independently of the harts. This master has the following characteristics:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Separate Bus Master: SBA transactions do not consume hart resources or execution time&lt;/item&gt;
      &lt;item&gt;Concurrent Operation: Memory reads/writes occur while harts execute normally&lt;/item&gt;
      &lt;item&gt;Cache Coherency Dependency: SBA bypasses hart caches; coherency is NOT guaranteed&lt;/item&gt;
      &lt;item&gt;Bus Arbitration: SBA competes with harts for bus bandwidth&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SBA interface consists of three memory-mapped registers in the Debug Module:&lt;/p&gt;
    &lt;code&gt;#define DM_SBCS        (0x38 * 4)  // System Bus Access Control and Status
#define DM_SBADDRESS0  (0x39 * 4)  // System Bus Address (32-bit)
#define DM_SBDATA0     (0x3C * 4)  // System Bus Data (32-bit)&lt;/code&gt;
    &lt;p&gt;The SBCS register (offset 0x38) contains configuration and status fields defined in RISC-V Debug Spec v0.13.2, section 3.12.18:&lt;/p&gt;
    &lt;code&gt;31:29 sbversion        (read-only)  SBA version
28:23 (reserved)       0
   22 sbbusyerror      (W1C)        Bus error occurred
   21 sbbusy           (read-only)  Bus master is busy
   20 sbreadonaddr     (read-write) Auto-read on SBADDRESS0 write
19:17 sbaccess         (read-write) Access width: 0=8-bit, 1=16-bit, 2=32-bit
   16 sbautoincrement  (read-write) Auto-increment address after access
   15 sbreadondata     (read-write) Auto-read on SBDATA0 read
14:12 sberror          (W1C)        Error status (0=none, 1=timeout, 2=bad addr, 3=alignment, 4=size, 7=other)
11:5  sbasize          (read-only)  Address width in bits (32 for RP2350)
&lt;/code&gt;
    &lt;p&gt;The SBA subsystem initialization (&lt;code&gt;rp2350.c:958-992&lt;/code&gt;) follows a capability discovery pattern:&lt;/p&gt;
    &lt;p&gt;Phase 1: Read SBCS to detect supported features&lt;/p&gt;
    &lt;code&gt;swd_result_t result = dap_read_mem32(target, DM_SBCS);&lt;/code&gt;
    &lt;p&gt;Phase 2: Verify SBA capability&lt;/p&gt;
    &lt;code&gt;// Check sbasize field (bits [11:5]) to verify SBA is present
uint32_t sbasize = (result.value &amp;gt;&amp;gt; 5) &amp;amp; 0x7F;
if (sbasize == 0) {
    return SWD_ERROR_INVALID_STATE;  // SBA not available
}&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;sbasize&lt;/code&gt; field indicates the system bus address width (32 bits for RP2350). RP2350 supports 8-bit, 16-bit, and 32-bit access widths. We configure for 32-bit:&lt;/p&gt;
    &lt;p&gt;Phase 3: Configure access mode&lt;/p&gt;
    &lt;code&gt;uint32_t sbcs = 0;
sbcs |= (2 &amp;lt;&amp;lt; 17);  // sbaccess = 2 (32-bit)
sbcs |= (1 &amp;lt;&amp;lt; 20);  // sbreadonaddr = 1 (auto-read trigger)
dap_write_mem32(target, DM_SBCS, sbcs);&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;sbreadonaddr&lt;/code&gt; flag is critical: it converts the address write into an atomic read-trigger operation.&lt;/p&gt;
    &lt;p&gt;Without &lt;code&gt;sbreadonaddr&lt;/code&gt;, a memory read requires three transactions:&lt;/p&gt;
    &lt;code&gt;1. Write address to SBADDRESS0
2. Write SBCS with read trigger
3. Read data from SBDATA0
&lt;/code&gt;
    &lt;p&gt;With &lt;code&gt;sbreadonaddr=1&lt;/code&gt;, the middle step is eliminated:&lt;/p&gt;
    &lt;code&gt;1. Write address to SBADDRESS0  ← Triggers bus read automatically
2. Read data from SBDATA0       ← Data is ready
&lt;/code&gt;
    &lt;p&gt;Implementation (&lt;code&gt;rp2350.c:1013-1020&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;dap_write_mem32(target, DM_SBADDRESS0, addr);  // Write triggers read
result = dap_read_mem32(target, DM_SBDATA0);   // Data is already valid&lt;/code&gt;
    &lt;p&gt;The Debug Module's state machine looks like:&lt;/p&gt;
    &lt;code&gt;IDLE → [SBADDRESS0 written] → BUSY → [bus read completes] → DATA_READY
                                ↓
                           [bus timeout] → SBERROR=1
&lt;/code&gt;
    &lt;p&gt;Memory writes use SBDATA0 as the trigger register:&lt;/p&gt;
    &lt;code&gt;dap_write_mem32(target, DM_SBADDRESS0, addr);   // Set address
dap_write_mem32(target, DM_SBDATA0, value);     // Write triggers bus write&lt;/code&gt;
    &lt;p&gt;The write to SBDATA0 initiates the system bus write transaction. The debugger should poll SBCS.sbbusyerror to detect completion (though in practice, pipelined writes are often used).&lt;/p&gt;
    &lt;p&gt;The SBCS.sberror field reports transaction failures:&lt;/p&gt;
    &lt;code&gt;0: No error
1: Timeout (bus did not respond)
2: Bad address (unmapped region)
3: Bad alignment (misaligned access)
4: Bad size (unsupported width)
7: Other error
&lt;/code&gt;
    &lt;p&gt;Errors are sticky and must be explicitly cleared by writing 1 to SBCS.sberror (W1C = Write-1-to-Clear).&lt;/p&gt;
    &lt;p&gt;The library maintains comprehensive state tracking to avoid redundant SWD transactions:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    bool connected;
    uint32_t idcode;
    bool resource_registered;
    // ...
} swd_target_t;&lt;/code&gt;
    &lt;code&gt;typedef struct {
    uint8_t current_apsel;
    uint8_t current_bank;
    bool ctrlsel;
    uint32_t select_cache;
    bool powered;
    uint retry_count;
} dap_state_t;&lt;/code&gt;
    &lt;p&gt;RP2350 contains two RISC-V harts (hardware threads) that execute independently. The library maintains per-hart state to avoid redundant operations and enable concurrent debugging:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    bool halt_state_known;  // false after resume, true after halt/read status
    bool halted;            // true if hart is currently halted

    // Register cache
    bool cache_valid;       // true if cached values are current
    uint32_t cached_pc;
    uint32_t cached_gprs[32];
    uint64_t cache_timestamp;  // For LRU if needed
} hart_state_t;&lt;/code&gt;
    &lt;p&gt;The top-level RP2350 state maintains an array of hart states:&lt;/p&gt;
    &lt;code&gt;#define RP2350_NUM_HARTS 2

typedef struct {
    bool initialized;
    bool sba_initialized;

    // Per-hart state
    hart_state_t harts[RP2350_NUM_HARTS];

    // Shared cache configuration
    bool cache_enabled;
} rp2350_state_t;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;halt_state_known&lt;/code&gt; flag implements a three-state model:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Unknown (&lt;code&gt;halt_state_known=false&lt;/code&gt;): Hart state is uncertain (after resume or initialization)&lt;/item&gt;
      &lt;item&gt;Known Halted (&lt;code&gt;halt_state_known=true, halted=true&lt;/code&gt;): Hart is confirmed halted&lt;/item&gt;
      &lt;item&gt;Known Running (&lt;code&gt;halt_state_known=true, halted=false&lt;/code&gt;): Hart is confirmed running&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This prevents expensive DMSTATUS polls when the state is known. State transitions:&lt;/p&gt;
    &lt;code&gt;                ┌─────────────┐
                │   Unknown   │
                └──────┬──────┘
                       │
         ┌─────────────┼─────────────┐
         │                           │
    halt_request()             read_dmstatus()
         │                           │
         ▼                           ▼
   ┌────────────┐             ┌──────────────┐
   │   Halted   │             │   Running    │
   └─────┬──────┘             └──────┬───────┘
         │                           │
         │         resume()          │
         └───────────────────────────┘
                      │
                      ▼
                 ┌─────────┐
                 │ Unknown │  (state invalidated)
                 └─────────┘
&lt;/code&gt;
    &lt;p&gt;When &lt;code&gt;cache_enabled=true&lt;/code&gt;, the library caches register values after reads. This optimization benefits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Repeated reads of the same register (e.g., polling loop variables)&lt;/item&gt;
      &lt;item&gt;Bulk register dumps where &lt;code&gt;rp2350_read_all_regs()&lt;/code&gt;populates the cache&lt;/item&gt;
      &lt;item&gt;Reduced SWD traffic (each register read requires ~6 SWD transactions)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cache invalidation occurs on:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hart resume (execution changes registers)&lt;/item&gt;
      &lt;item&gt;Register write (specific register invalidated)&lt;/item&gt;
      &lt;item&gt;Hart halt request (conservative invalidation)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The cache is per-hart, allowing concurrent debugging of both harts without interference.&lt;/p&gt;
    &lt;p&gt;PIO resources are scarce: RP2040/RP2350 provide 2 PIO blocks with 4 state machines each. The library implements a global resource tracker for multi-target support.&lt;/p&gt;
    &lt;code&gt;typedef struct {
    swd_target_t *pio0_sm_owners[4];
    swd_target_t *pio1_sm_owners[4];
    uint active_count;
} resource_tracker_t;

extern resource_tracker_t g_resources;&lt;/code&gt;
    &lt;p&gt;When &lt;code&gt;SWD_PIO_AUTO&lt;/code&gt; or &lt;code&gt;SWD_SM_AUTO&lt;/code&gt; is specified in configuration, the library scans for free resources (&lt;code&gt;swd.c:105-125&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;swd_error_t allocate_pio_sm(PIO *pio, uint *sm) {
    for (uint i = 0; i &amp;lt; 4; i++) {
        if (g_resources.pio0_sm_owners[i] == NULL) {
            *pio = pio0;
            *sm = i;
            return SWD_OK;
        }
    }
    // Try PIO1...
}&lt;/code&gt;
    &lt;p&gt;Up to 8 simultaneous target connections are supported (limited by hardware resources).&lt;/p&gt;
    &lt;p&gt;The library provides comprehensive error reporting through enumerated error codes and detailed message strings.&lt;/p&gt;
    &lt;code&gt;typedef enum {
    SWD_OK = 0,
    SWD_ERROR_TIMEOUT,        // Transaction timeout
    SWD_ERROR_FAULT,          // Target FAULT response
    SWD_ERROR_PROTOCOL,       // Malformed packet
    SWD_ERROR_PARITY,         // Parity check failure
    SWD_ERROR_WAIT,           // WAIT response retry exhausted
    SWD_ERROR_NOT_CONNECTED,  // No active connection
    SWD_ERROR_NOT_HALTED,     // Operation requires halted hart
    SWD_ERROR_ALREADY_HALTED, // Hart already halted (informational)
    // ...
} swd_error_t;&lt;/code&gt;
    &lt;p&gt;Each target maintains a 128-byte error detail buffer for formatted diagnostic messages (&lt;code&gt;swd.c:67-84&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;void swd_set_error(swd_target_t *target, swd_error_t error,
                   const char *detail, ...) {
    target-&amp;gt;last_error = error;
    va_list args;
    va_start(args, detail);
    vsnprintf(target-&amp;gt;error_detail, sizeof(target-&amp;gt;error_detail),
              detail, args);
    va_end(args);
}&lt;/code&gt;
    &lt;p&gt;SWD protocol ACK responses are mapped to error codes (&lt;code&gt;swd.c:91-99&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;swd_error_t swd_ack_to_error(uint8_t ack) {
    switch (ack) {
        case 0x1: return SWD_OK;            // OK
        case 0x2: return SWD_ERROR_WAIT;    // WAIT
        case 0x4: return SWD_ERROR_FAULT;   // FAULT
        default:  return SWD_ERROR_PROTOCOL;
    }
}&lt;/code&gt;
    &lt;p&gt;WAIT responses trigger automatic retry with backoff (&lt;code&gt;swd_protocol.c:197-208&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;for (uint retry = 0; retry &amp;lt; target-&amp;gt;dap.retry_count; retry++) {
    err = swd_io_raw(target, request, value, false);
    if (err != SWD_ERROR_WAIT) break;
    sleep_us(100);
}&lt;/code&gt;
    &lt;p&gt;Default retry count is 5, configurable via &lt;code&gt;swd_config_t&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;swd_config_t config = swd_config_default();
config.pin_swclk = 2;
config.pin_swdio = 3;
config.freq_khz = 1000;
config.enable_caching = true;

swd_target_t *target = swd_target_create(&amp;amp;config);
swd_connect(target);
rp2350_init(target);&lt;/code&gt;
    &lt;code&gt;// Halt hart 0
rp2350_halt(target, 0);

// Read program counter
swd_result_t pc = rp2350_read_pc(target, 0);
if (pc.error == SWD_OK) {
    printf("PC: 0x%08x\n", pc.value);
}

// Read all registers
uint32_t regs[32];
rp2350_read_all_regs(target, 0, regs);

// Single-step execution
rp2350_step(target, 0);

// Resume execution
rp2350_resume(target, 0);

// Reset hart
rp2350_reset(target, 0, true);  // Reset and halt&lt;/code&gt;
    &lt;code&gt;// Read memory (non-intrusive via SBA)
swd_result_t result = rp2350_read_mem32(target, 0x20000000);

// Write memory
rp2350_write_mem32(target, 0x20000000, 0xDEADBEEF);

// Block operations
uint32_t buffer[256];
rp2350_read_mem_block(target, 0x20000000, buffer, 256);&lt;/code&gt;
    &lt;code&gt;const uint32_t program[] = {
    0x200415b7,  // lui  a1, 0x20040
    0xabcd0537,  // lui  a0, 0xabcd0
    0x23450513,  // addi a0, a0, 0x234
    0x00a5a223,  // sw   a0, 4(a1)
    0x0000006f,  // j    0 (infinite loop)
};

rp2350_execute_code(target, 0, 0x20000000, program, 5);&lt;/code&gt;
    &lt;code&gt;// Trace callback receives each executed instruction
bool trace_callback(const trace_record_t *record, void *user_data) {
    printf("PC: 0x%08x  Instruction: 0x%08x\n",
           record-&amp;gt;pc, record-&amp;gt;instruction);

    // Optional: inspect registers
    if (record-&amp;gt;regs) {
        printf("  x5=0x%08x\n", record-&amp;gt;regs[5]);
    }

    return true;  // Continue tracing (false = stop)
}

// Trace 100 instructions on hart 0, capturing registers
int count = rp2350_trace(target, 0, 100, trace_callback, NULL, true);
printf("Traced %d instructions\n", count);&lt;/code&gt;
    &lt;code&gt;// Operate on both harts independently
rp2350_halt(target, 0);
rp2350_halt(target, 1);

// Read registers from both harts
uint32_t h0_regs[32], h1_regs[32];
rp2350_read_all_regs(target, 0, h0_regs);
rp2350_read_all_regs(target, 1, h1_regs);

// Execute different programs on each hart
rp2350_execute_code(target, 0, 0x20000000, program0, len0);
rp2350_execute_code(target, 1, 0x20001000, program1, len1);

// Trace hart 1 while hart 0 runs
rp2350_resume(target, 0);
rp2350_trace(target, 1, 50, trace_callback, NULL, false);&lt;/code&gt;
    &lt;code&gt;add_subdirectory(lib/pico2-swd-riscv)
target_link_libraries(your_application pico2_swd_riscv)&lt;/code&gt;
    &lt;p&gt;Set compile-time debug verbosity:&lt;/p&gt;
    &lt;code&gt;target_compile_definitions(your_application PRIVATE PICO2_SWD_DEBUG_LEVEL=3)&lt;/code&gt;
    &lt;p&gt;Levels: 0 (none), 1 (warnings), 2 (info), 3 (debug).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ARM Debug Interface Architecture Specification v5.2&lt;/item&gt;
      &lt;item&gt;ARM CoreSight SWD-DP Technical Reference Manual&lt;/item&gt;
      &lt;item&gt;RISC-V External Debug Support version 0.13&lt;/item&gt;
      &lt;item&gt;RP2350 Datasheet, Chapter 3.5: Debug&lt;/item&gt;
      &lt;item&gt;ADIv5.2 Supplement for Multi-drop SWD&lt;/item&gt;
      &lt;item&gt;IEEE 1149.1-2001 (JTAG)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Single-step execution enables instruction-level debugging by executing exactly one instruction before re-entering debug mode. This is implemented via the DCSR.step bit (Debug Control and Status Register, bit 2).&lt;/p&gt;
    &lt;p&gt;When DCSR.step=1, the hart executes one instruction after &lt;code&gt;resumereq&lt;/code&gt;, then immediately re-halts:&lt;/p&gt;
    &lt;code&gt;Debug Mode → [resumereq + DCSR.step=1] → Execute 1 instruction → Debug Mode
&lt;/code&gt;
    &lt;p&gt;Implementation (&lt;code&gt;rp2350.c:431-504&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;Phase 1: Read current DCSR&lt;/p&gt;
    &lt;code&gt;swd_result_t dcsr_result = read_dcsr(target, hart_id);&lt;/code&gt;
    &lt;p&gt;DCSR must be read via PROGBUF (see Section 7.D) because it's a debug-only CSR.&lt;/p&gt;
    &lt;p&gt;Phase 2: Set step bit&lt;/p&gt;
    &lt;code&gt;uint32_t dcsr_stepped = dcsr_result.value | (1 &amp;lt;&amp;lt; 2);
write_dcsr(target, hart_id, dcsr_stepped);&lt;/code&gt;
    &lt;p&gt;Phase 3: Resume hart&lt;/p&gt;
    &lt;code&gt;uint32_t dmcontrol = make_dmcontrol(hart_id, false, true, false);
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);&lt;/code&gt;
    &lt;p&gt;The hart now executes exactly one instruction, then:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;PC is saved to DPC&lt;/item&gt;
      &lt;item&gt;Hart re-enters debug mode&lt;/item&gt;
      &lt;item&gt;DCSR.cause = 0x4 (single-step)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Phase 4: Wait for automatic halt&lt;/p&gt;
    &lt;code&gt;poll_dmstatus_halted(target, hart_id, true);&lt;/code&gt;
    &lt;p&gt;Phase 5: Clear step bit&lt;/p&gt;
    &lt;code&gt;write_dcsr(target, hart_id, dcsr_result.value);  // Restore original DCSR&lt;/code&gt;
    &lt;p&gt;This ensures subsequent &lt;code&gt;rp2350_resume()&lt;/code&gt; calls don't single-step.&lt;/p&gt;
    &lt;p&gt;The library implements software instruction tracing by repeatedly single-stepping and recording each instruction. This provides a "time-travel" debugging capability at the cost of execution speed.&lt;/p&gt;
    &lt;p&gt;Tracing uses a callback function to process each instruction (&lt;code&gt;rp2350.c:1262-1337&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;typedef struct {
    uint32_t pc;
    uint32_t instruction;
    uint32_t regs[32];  // Valid if capture_regs=true
} trace_record_t;

typedef bool (*trace_callback_t)(const trace_record_t *record, void *user_data);&lt;/code&gt;
    &lt;p&gt;The callback returns &lt;code&gt;true&lt;/code&gt; to continue or &lt;code&gt;false&lt;/code&gt; to stop.&lt;/p&gt;
    &lt;code&gt;int rp2350_trace(swd_target_t *target, uint8_t hart_id,
                 uint32_t max_instructions,
                 trace_callback_t callback, void *user_data,
                 bool capture_regs);&lt;/code&gt;
    &lt;p&gt;For each instruction:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read PC (via PROGBUF): Current instruction address&lt;/item&gt;
      &lt;item&gt;Read memory at PC: Fetch the instruction word&lt;/item&gt;
      &lt;item&gt;Optional: Read all GPRs: If &lt;code&gt;capture_regs=true&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Invoke callback: User processes the record&lt;/item&gt;
      &lt;item&gt;Single-step: Execute one instruction&lt;/item&gt;
      &lt;item&gt;Repeat until &lt;code&gt;max_instructions&lt;/code&gt;or callback returns false&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Loop Detection:&lt;/p&gt;
    &lt;code&gt;bool detect_loop(const trace_record_t *record, void *user_data) {
    static uint32_t entry_pc = 0;
    static int count = 0;

    if (count == 0) entry_pc = record-&amp;gt;pc;
    if (record-&amp;gt;pc == entry_pc &amp;amp;&amp;amp; count &amp;gt; 0) {
        printf("Loop detected at PC=0x%08x\n", record-&amp;gt;pc);
        return false;  // Stop trace
    }
    count++;
    return true;
}&lt;/code&gt;
    &lt;p&gt;Register State History:&lt;/p&gt;
    &lt;code&gt;bool capture_state(const trace_record_t *record, void *user_data) {
    printf("%08x: %08x  x5=%08x x6=%08x\n",
           record-&amp;gt;pc, record-&amp;gt;instruction,
           record-&amp;gt;regs[5], record-&amp;gt;regs[6]);
    return true;
}

rp2350_trace(target, 0, 100, capture_state, NULL, true);&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Speed: ~5ms per instruction (200 instructions/second)&lt;/item&gt;
      &lt;item&gt;Interrupt Masking: Tracing should occur with interrupts disabled (clear mstatus.MIE)&lt;/item&gt;
      &lt;item&gt;Memory Consistency: Instructions are fetched via SBA; ensure I-cache coherency&lt;/item&gt;
      &lt;item&gt;No Hardware Triggers: Trace starts immediately; no "trace until condition"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hart reset (&lt;code&gt;rp2350_reset&lt;/code&gt;) implements a controlled reset sequence via DMCONTROL.ndmreset (non-debug module reset, bit 1).&lt;/p&gt;
    &lt;code&gt;swd_error_t rp2350_reset(swd_target_t *target, uint8_t hart_id,
                         bool halt_on_reset);&lt;/code&gt;
    &lt;p&gt;Phase 1: Assert ndmreset&lt;/p&gt;
    &lt;code&gt;uint32_t dmcontrol = make_dmcontrol(hart_id, halt_on_reset, false, true);
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);
sleep_ms(10);  // Hold reset&lt;/code&gt;
    &lt;p&gt;Phase 2: Deassert ndmreset&lt;/p&gt;
    &lt;code&gt;dmcontrol = make_dmcontrol(hart_id, halt_on_reset, false, false);
dap_write_mem32(target, DM_DMCONTROL, dmcontrol);
sleep_ms(50);  // Wait for reset completion&lt;/code&gt;
    &lt;p&gt;If &lt;code&gt;halt_on_reset=true&lt;/code&gt;, the DMCONTROL.haltreq bit remains set, causing the hart to enter debug mode immediately after reset, with PC set to the reset vector.&lt;/p&gt;
    &lt;p&gt;This reset is equivalent to a power-on reset for the hart:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PC → reset vector (typically 0x00000000 for RP2350 RISC-V cores)&lt;/item&gt;
      &lt;item&gt;All CSRs → architectural reset values&lt;/item&gt;
      &lt;item&gt;GPRs → undefined&lt;/item&gt;
      &lt;item&gt;Cache → invalidated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike a full chip reset, peripherals and other harts are unaffected.&lt;/p&gt;
    &lt;p&gt;RP2350's two RISC-V harts (Hazard3 cores) are symmetric and independently controllable. The library provides full per-hart state tracking and concurrent operation.&lt;/p&gt;
    &lt;p&gt;Each Debug Module operation targets a specific hart via DMCONTROL.hartsel[9:0]:&lt;/p&gt;
    &lt;code&gt;static inline uint32_t make_dmcontrol(uint8_t hart_id, bool haltreq,
                                       bool resumereq, bool ndmreset) {
    uint32_t dmcontrol = (1 &amp;lt;&amp;lt; 0);  // dmactive = 1
    dmcontrol |= ((uint32_t)hart_id &amp;lt;&amp;lt; 16);  // hartsello[9:0] at bits 25:16
    if (haltreq) dmcontrol |= (1 &amp;lt;&amp;lt; 31);
    if (resumereq) dmcontrol |= (1 &amp;lt;&amp;lt; 30);
    if (ndmreset) dmcontrol |= (1 &amp;lt;&amp;lt; 1);
    return dmcontrol;
}&lt;/code&gt;
    &lt;p&gt;Before any hart-specific operation (halt, resume, register read), the library writes DMCONTROL with the correct &lt;code&gt;hart_id&lt;/code&gt;, switching the Debug Module's attention to that hart.&lt;/p&gt;
    &lt;p&gt;The test suite validates that harts operate independently:&lt;/p&gt;
    &lt;code&gt;// Halt hart 0, keep hart 1 running
rp2350_halt(target, 0);
rp2350_resume(target, 1);

// Read hart 0 registers while hart 1 executes
uint32_t h0_regs[32];
rp2350_read_all_regs(target, 0, h0_regs);&lt;/code&gt;
    &lt;p&gt;This enables debugging one hart while the other maintains real-time operation.&lt;/p&gt;
    &lt;p&gt;Each hart maintains independent register state. Writing x5 on hart 0 does not affect x5 on hart 1. This is validated by &lt;code&gt;test_dual_hart.c:69-115&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;rp2350_write_reg(target, 0, 5, 0xAAAAAAAA);
rp2350_write_reg(target, 1, 5, 0x55555555);

assert(rp2350_read_reg(target, 0, 5).value == 0xAAAAAAAA);
assert(rp2350_read_reg(target, 1, 5).value == 0x55555555);&lt;/code&gt;
    &lt;p&gt;Both harts share the same physical memory space but maintain independent caches. This creates coherency considerations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SBA Writes: Visible to both harts (after cache invalidation)&lt;/item&gt;
      &lt;item&gt;Hart 0 Writes: Not immediately visible to Hart 1 if cached&lt;/item&gt;
      &lt;item&gt;Explicit Synchronization: Required for inter-hart communication&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The test suite exercises memory access while both harts run concurrently (&lt;code&gt;test_mem.c:291-347&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;This implementation does not currently support:&lt;/p&gt;
    &lt;p&gt;RISC-V Debug Specification defines a Trigger Module for hardware breakpoints. Implementation was removed due to complexity. Workaround: Use single-step + PC comparison in software.&lt;/p&gt;
    &lt;p&gt;The SWD protocol supports multiple targets on one bus via unique addresses. This library assumes a single target. Physical wiring for multi-target is possible but requires additional multiplexing logic.&lt;/p&gt;
    &lt;p&gt;RP2350's Hazard3 cores support the C extension (16-bit compressed instructions). The library:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Correctly reads compressed instructions during tracing&lt;/item&gt;
      &lt;item&gt;Does NOT decode compressed instruction mnemonics&lt;/item&gt;
      &lt;item&gt;Assumes 4-byte alignment for code upload&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No cycle-accurate performance counters are exposed. Implementing this requires:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Access to mcycle/minstret CSRs&lt;/item&gt;
      &lt;item&gt;Periodic sampling without halting (not possible with current SBA coherency)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No routines for RP2350 flash programming. This requires:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Loading flash programmer stub to SRAM&lt;/item&gt;
      &lt;item&gt;Executing stub via &lt;code&gt;rp2350_execute_code()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Monitoring completion via polling&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The architecture supports this; implementation is left to applications.&lt;/p&gt;
    &lt;p&gt;Copyright (c) 2025&lt;/p&gt;
    &lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt;
    &lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt;
    &lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jackdoe/pico2-swd-riscv"/><published>2025-11-10T11:45:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45876308</id><title>Head in the Zed Cloud</title><updated>2025-11-11T05:11:53.984387+00:00</updated><content>&lt;doc fingerprint="e73884714d9f1c8b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Head in the Zed Cloud&lt;/head&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;p&gt;For the past five months I've been leading the efforts to rebuild Zed's cloud infrastructure.&lt;/p&gt;
    &lt;p&gt;Our current backend—known as Collab—has been chugging along since basically the beginning of the company. We use Collab every day to work together on Zed in Zed. However, as Zed continues to grow and attracts more users, we knew that we needed a full reboot of our backend infrastructure to set us up for success for our future endeavors.&lt;/p&gt;
    &lt;p&gt;Enter Zed Cloud.&lt;/p&gt;
    &lt;p&gt;Like Zed itself, Zed Cloud is built in Rust1.&lt;/p&gt;
    &lt;p&gt;This time around there is a slight twist: all of this is running on Cloudflare Workers, with our Rust code being compiled down to WebAssembly (Wasm).&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Cloudflare Workers?&lt;/head&gt;
    &lt;p&gt;One of our goals with this rebuild was to reduce the amount of operational effort it takes to maintain our hosted services, so that we can focus more of our time and energy on building Zed itself.&lt;/p&gt;
    &lt;p&gt;Cloudflare Workers allow us to easily scale up to meet demand without having to fuss over it too much.&lt;/p&gt;
    &lt;p&gt;Additionally, Cloudflare offers an ever-growing amount of managed services that cover anything you might need for a production web service. Here are some of the Cloudflare services we're using today:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hyperdrive for talking to Postgres&lt;/item&gt;
      &lt;item&gt;Workers KV for ephemeral storage&lt;/item&gt;
      &lt;item&gt;Cloudflare Queues for asynchronous job processing&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Platform&lt;/head&gt;
    &lt;p&gt;Another one of our goals with this rebuild was to build a platform that was easy to test. To achieve this, we built our own platform framework on top of the Cloudflare Workers runtime APIs.&lt;/p&gt;
    &lt;p&gt;At the heart of this framework is the &lt;code&gt;Platform&lt;/code&gt; trait:&lt;/p&gt;
    &lt;code&gt;pub trait Platform: Sized + Clone + 'static {
    type Cache: cache::Cache;
    type Clock: Clock;
    type KvStore: KvStore&amp;lt;Self&amp;gt;;
    type ServiceBinding: Fetcher&amp;lt;Self&amp;gt;;
    type DurableObjectNamespace: durable_object::DurableObjectNamespace&amp;lt;Self&amp;gt;;
    type DurableObjectStub: durable_object::DurableObjectStub&amp;lt;Self&amp;gt;;
    type DurableObjectState: durable_object::DurableObjectState&amp;lt;Self&amp;gt;;
    type RateLimiter: rate_limiter::RateLimiter&amp;lt;Self&amp;gt;;
    type SqlStorage: sql::SqlStorage;
    type PostgresConnection&amp;lt;T&amp;gt;: postgres::PostgresConnection&amp;lt;Self, T&amp;gt;;
    type PostgresTransaction&amp;lt;T&amp;gt;: postgres::PostgresTransaction&amp;lt;Self, T&amp;gt;;
    type ExecutionContext: ExecutionContext + Clone + Unpin;
    type Environment: Environment&amp;lt;Self&amp;gt; + Clone + Unpin;
    type ClientWebSocket: websocket::ClientWebSocket;
    type ServerWebSocket: websocket::ServerWebSocket&amp;lt;Self&amp;gt;;
    type WebSocketReceiver: websocket::WebSocketReceiver;
    type WebSocketSender: websocket::WebSocketSender;
    type HttpClient: http_client::HttpClient&amp;lt;Platform = Self&amp;gt;;
    type Queue&amp;lt;T: Serialize + 'static&amp;gt;: queue::Queue&amp;lt;Self, T&amp;gt;;
    type RawQueueMessageBatch: queue::RawQueueMessageBatch&amp;lt;Self&amp;gt;;
    type QueueMessageBatch&amp;lt;T: DeserializeOwned + 'static&amp;gt;: queue::QueueMessageBatch&amp;lt;Self, T&amp;gt;;
    type QueueMessage&amp;lt;T: DeserializeOwned + 'static&amp;gt;: queue::QueueMessage&amp;lt;Self, T&amp;gt;;
    type Rng: Clone + RngCore;

    fn websocket_pair() -&amp;gt; Result&amp;lt;(Self::ClientWebSocket, Self::ServerWebSocket)&amp;gt;;
}
&lt;/code&gt;
    &lt;p&gt;This trait allows us to write our code in a platform-agnostic way while still leveraging all of the functionality that Cloudflare Workers has to offer. Each one of these associated types corresponds to some aspect of the platform that we'll want to have control over in a test environment.&lt;/p&gt;
    &lt;p&gt;For instance, if we have a service that needs to interact with the system clock and a Workers KV store, we would define it like this:&lt;/p&gt;
    &lt;code&gt;pub struct BillingService&amp;lt;P: Platform&amp;gt; {
    clock: P::Clock,
    kv_store: P::KvStore,
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Two platforms, both alike in dignity&lt;/head&gt;
    &lt;p&gt;There are two implementors of the &lt;code&gt;Platform&lt;/code&gt; trait: &lt;code&gt;CloudflarePlatform&lt;/code&gt; and &lt;code&gt;SimulatedPlatform&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;CloudflarePlatform&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;&lt;code&gt;CloudflarePlatform&lt;/code&gt;—as the name might suggest—is an implementation of the platform on top of the Cloudflare Workers runtime. This implementation targets Wasm and is what we run when developing locally (using Wrangler) and in production.&lt;/p&gt;
    &lt;p&gt;We have a &lt;code&gt;cloudflare_bindings&lt;/code&gt; crate2 that contains &lt;code&gt;wasm_bindgen&lt;/code&gt; bindings to the Cloudflare Workers JS runtime. You can think of &lt;code&gt;CloudflarePlatform&lt;/code&gt; as the glue between those bindings and the idiomatic Rust APIs exposed by the &lt;code&gt;Platform&lt;/code&gt; trait.&lt;/p&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;SimulatedPlatform&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;SimulatedPlatform&lt;/code&gt; is used when running tests, and allows for simulating almost every part of the system in order to effectively test our code.&lt;/p&gt;
    &lt;p&gt;Here's an example of a test for ingesting a webhook from Orb:&lt;/p&gt;
    &lt;code&gt;#[test]
fn test_orb_webhook_ingestion() {
    Simulator::once(|simulator| async move {
        let test_ctx = OrbWebhooksTestContext::init(&amp;amp;simulator).await?;

        // Some more test setup...

        let request = make_orb_webhook_request(
            HANDLE_ORB_WEBHOOK_URL,
            &amp;amp;webhook_event,
            "2025-09-10T18:16:06.483Z".parse().unwrap(),
            &amp;amp;test_ctx.config.orb_webhook_signing_secret,
        )?;

        let response = test_ctx.worker.fetch(request).await?;
        assert_eq!(response.status, StatusCode::OK);

        simulator.scheduler.run()?;

        let updated_billing_subscription = BillingSubscriptionRepository
            .find(&amp;amp;test_ctx.app_database, billing_subscription.id)
            .await?;
        assert_eq!(
            updated_billing_subscription.kind,
            Some(app_database::SubscriptionKind::TokenBasedZedPro)
        );
        assert_eq!(
            updated_billing_subscription.orb_subscription_status,
            Some(app_database::OrbSubscriptionStatus::Active)
        );
    })
    .unwrap();
}
&lt;/code&gt;
    &lt;p&gt;In this test we're able to test the full end-to-end flow of:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Receiving and validating an incoming webhook event to our webhook ingestion endpoint&lt;/item&gt;
      &lt;item&gt;Putting the webhook event into a queue&lt;/item&gt;
      &lt;item&gt;Consuming the webhook event in a background worker and processing it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The call to &lt;code&gt;simulator.scheduler.run()?&lt;/code&gt; advances the test simulator, in this case running the pending queue consumers.&lt;/p&gt;
    &lt;p&gt;At the center of the &lt;code&gt;SimulatedPlatform&lt;/code&gt; is the &lt;code&gt;scheduler&lt;/code&gt;, a crate that powers our in-house async runtime. The scheduler is shared between GPUI—Zed's UI framework—and the &lt;code&gt;Simulator&lt;/code&gt; used in tests.&lt;/p&gt;
    &lt;p&gt;This shared scheduler enables us to write tests that span the client and the server. So we can have a test that starts in a piece of Zed code, flows through Zed Cloud, and then asserts on the state of something in Zed after it receives the response from the backend.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where we're headed&lt;/head&gt;
    &lt;p&gt;The work being done on Zed Cloud now is laying the foundation to support our future work around collaborative coding with DeltaDB.&lt;/p&gt;
    &lt;p&gt;If you want to work with me on building out Zed Cloud, we are currently hiring for this role.&lt;/p&gt;
    &lt;p&gt;We're looking for engineers with experience building and maintaining web APIs and platforms, solid web fundamentals, and who are excited about Rust.&lt;/p&gt;
    &lt;p&gt;If you end up applying, you can mention this blog post in your application.&lt;/p&gt;
    &lt;p&gt;I look forward to hearing from you!&lt;/p&gt;
    &lt;p&gt;The codebase is currently 70k lines of Rust code and 5.7k lines of TypeScript.&lt;/p&gt;
    &lt;p&gt;This is essentially our own version of &lt;code&gt;worker-sys&lt;/code&gt;. I'd like to switch to using &lt;code&gt;worker-sys&lt;/code&gt; directly, at some point.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maxdeviant.com/posts/2025/head-in-the-zed-cloud/"/><published>2025-11-10T14:23:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45876598</id><title>Time to start de-Appling</title><updated>2025-11-11T05:11:52.773161+00:00</updated><content>&lt;doc fingerprint="b049d1f1222217d5"&gt;
  &lt;main&gt;
    &lt;p&gt;I‘ve done such a thorough job of de-Googling that I forgot to show up for a meeting with someone, because I hadn’t checked my Google calendar in ages. (No, they were not amused.) In my defense, I proceeded to explain to them that having de-Googled, I was also in the process of de-Appling, which is a special bonus level that those of us in the UK have unlocked.&lt;/p&gt;
    &lt;p&gt;If you’re reading this in the sunlit uplands, you need to start that too.&lt;/p&gt;
    &lt;p&gt;You need to start that because, as we recently learned, at some point in the very near future Apple is withdrawing its Advanced Data Protection (ADP) feature from the UK altogether as a result of the Home Office TCN through the Investigatory Powers Act.&lt;/p&gt;
    &lt;p&gt;Users who already had ADP enabled when the first TCN became public in February will be required to manually switch it off or lose their iCloud account.&lt;/p&gt;
    &lt;p&gt;I am not going to explain the chapter and verse of the legal saga today, because I prefer to do that for people who pay me to explain them the chapter and verse.&lt;/p&gt;
    &lt;p&gt;But I will say that the shutdown of ADP is Apple being on the right side of the geopolitical fight, as inconvenient as that may be to you and me.&lt;/p&gt;
    &lt;p&gt;When the whole debacle blew up in February, Apple announced that ADP would no longer be available for new users, but would remain unaffected for those of us who already had it activated. That assurance was nothing to sleep on, and so we have been waiting for the inevitable. Apple’s September update confirmed that its days are numbered:&lt;/p&gt;
    &lt;p&gt;So what does that mean for you? Again, from their September update:&lt;/p&gt;
    &lt;p&gt;Our communication services, like iMessage and FaceTime, remain end-to-end encrypted globally, including in the UK.&lt;/p&gt;
    &lt;p&gt;Users in the UK who have not already enabled Advanced Data Protection will no longer have the option to do so. That means the 10 iCloud data categories covered by ADP will be protected by Standard Data Protection, and UK users will not have a choice to benefit from end-to-end encryption for these categories: iCloud Backup; iCloud Drive; Photos; Notes; Reminders; Safari Bookmarks; Siri Shortcuts; Voice Memos; Wallet Passes; and Freeform.&lt;/p&gt;
    &lt;p&gt;This means that if you already had ADP activated, and e2ee is critical to your personal or operational security, you need to get everything in that list – iCloud Backup, iCloud Drive, Photos, Notes, Reminders, Safari Bookmarks, Siri Shortcuts, Voice Memos, Wallet Passes, and Freeform – off of iCloud sooner rather than later.&lt;/p&gt;
    &lt;p&gt;Once you’ve done that, go into your iCloud settings, click on Manage, then click on each thing individually to purge it off iCloud.&lt;/p&gt;
    &lt;p&gt;I’m not going to tell you where to move your stuff other than to say that if you’re moving it from one big tech company to another, you’re just being daft. Likewise, if you’re moving your stuff to a non-e2ee service, don’t bother. If you need an e2ee service try Proton. They have a Black Friday sale on.&lt;/p&gt;
    &lt;p&gt;If you have a lot of Notes, first download the Exporter app from the app store. It does what it says on the tin. You’ll end up with a folder full of markdown files which you can upload elsewhere. E2EE being the dealbreaker, I chose Standard Notes. I know a lot of folk who prefer Obsidian or Joplin. Whatever you choose, do not use a non-E2EE note service.*&lt;/p&gt;
    &lt;p&gt;You know as well as I do that you need to be moving everything you can out of the American stack anyway so just stick this task on your to-do list, which should not be Reminders, and get it done.&lt;/p&gt;
    &lt;head rend="h2"&gt;What about the non-e2ee stuff in iCloud?&lt;/head&gt;
    &lt;p&gt;The full list of what lives in iCloud and how it is or is not encrypted is here.&lt;/p&gt;
    &lt;p&gt;We know from the tiny bits of the TCN saga which have been publicly disclosed, thanks to the only two media outlets that are bothering to cover it, that the first TCN was not just for the end-to-end encrypted data protected by ADP. It was for anything on iCloud, full stop, worldwide:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…however, the new IPT filing states the TCN “is not limited to” data stored under ADP, suggesting the UK government sought bulk interception access to Apple’s standard iCloud service, which is much more widely used by the company’s customers. The TCN also included “obligations to provide and maintain a capability to disclose categories of data stored within a cloud-based backup service”, the filing states, which suggests the government sought to tap messages or passwords that were backed up in the cloud as well. “The obligations included in the TCN are not limited to the UK or users of the service in the UK; they apply globally in respect of the relevant data categories of all iCloud users,” the IPT filing adds. Tim Bradshaw and Anna Gross at the Financial Times (£)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This means that you have some serious thinking to do about what you intend to trust to the Apple stack altogether going forward, even things like passwords.&lt;/p&gt;
    &lt;p&gt;I can’t tell you what to do but once again, you have options. Educate yourself. Consider the opsec and persec needs not just of yourself, but for the people around you who could be adversely affected by insecure data going walkies out of your account.&lt;/p&gt;
    &lt;head rend="h2"&gt;What if I’m not in the UK?&lt;/head&gt;
    &lt;p&gt;This impacts the UK only: as their September update noted, Advanced Data Protection continues to be available everywhere else in the world.&lt;/p&gt;
    &lt;p&gt;It does mean that if you have someone in the UK on your team, you need to factor them in as part of your threat model. We are all liabilities to our own opsec now.&lt;/p&gt;
    &lt;p&gt;If you’re not in the UK, and you don’t have ADP activated, take 10 seconds to do it right now, you lucky sod.&lt;lb/&gt; Settings &amp;gt; Your name Apple Account &amp;gt; iCloud &amp;gt; Advanced Data Protection&lt;/p&gt;
    &lt;head rend="h2"&gt;What about that second TCN?&lt;/head&gt;
    &lt;p&gt;On the 1st of October, the Home Office issued a second TCN against Apple for the same as before, but only for British citizens’ data. World-leading!&lt;/p&gt;
    &lt;p&gt;Those who follow my work know that this phrase made me spew a double barrel of Glaswegian swearing. British citizens’ data, as opposed to British users’ data? The dividing line here is not e.g. being located in the UK or having registered an account here, but what it says on your passport? How is Apple going to know that, much less roll it out? (/s)&lt;/p&gt;
    &lt;p&gt;Did Apple just publicly state that they’re going to be removing a security layer and adding a nationality check layer?&lt;/p&gt;
    &lt;p&gt;We don’t know.&lt;/p&gt;
    &lt;p&gt;We don’t know because as with the first TCN, that information only became available in the public domain due to someone leaking it to the media. That’s all there is to know. Everything else is confidential and NCND. There is nothing else to say because nothing else is known. If someone who did know something was sitting across from me right now, and they told me, they would be committing a crime.&lt;/p&gt;
    &lt;p&gt;Those of us who care about these things enough to show up in difficult places are keeping tabs on both TCNs, and the wider legal and technical implications of both, as best we possibly can. Don’t expect to hear anything more until January, when the Liberty/PI challenge on the first TCN goes to the Investigatory Powers Tribunal. In the interim, if you want me to bore you about ECHR case law and how the UK’s review into Article 8 seems a little too coincidentally timed, pick a pub.&lt;/p&gt;
    &lt;p&gt;Otherwise, please make sure you de-Apple, de-Google, and de-American Stack yourself when you have time, clarity, and focus to do it. Start today.&lt;/p&gt;
    &lt;p&gt;In the meantime please follow and support the only media coverage being produced about the second TCN, which comes from Bill Goodwin at Computer Weekly and Tim Bradshaw and Anna Gross at the Financial Times (£).&lt;/p&gt;
    &lt;p&gt;Above all, please remember that this is the sunlit uplands. That’s the thing about Brexit Britain having decided to go it alone where tech regulation is concerned. It did not become the vanguard of a “world-leading” third way.&lt;/p&gt;
    &lt;p&gt;It became a small and inconsequential thing easily thrown under a bus.&lt;/p&gt;
    &lt;p&gt;Header image by me: Alan Turing memorial, Manchester, where he reminds you why keeping data private can be a matter of life and death.&lt;/p&gt;
    &lt;p&gt;*For the love of the wee man do not use a non-e2ee notetaking app which has been abandoned by an owner who has a track record of personally snooping through user data when he’s in a mood, i.e. if he’s breathing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://heatherburns.tech/2025/11/10/time-to-start-de-appling/"/><published>2025-11-10T14:57:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877257</id><title>Unexpected things that are people</title><updated>2025-11-11T05:11:52.663734+00:00</updated><content/><link href="https://bengoldhaber.substack.com/p/unexpected-things-that-are-people"/><published>2025-11-10T16:05:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877517</id><title>Launch HN: Hypercubic (YC F25) – AI for COBOL and Mainframes</title><updated>2025-11-11T05:11:52.262025+00:00</updated><content>&lt;doc fingerprint="3574724a08458fe1"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we’re Sai and Aayush and we’re building Hypercubic (&lt;/p&gt;https://www.hypercubic.ai/&lt;p&gt;)!&lt;/p&gt;&lt;p&gt;Hypercubic is an AI platform that helps Fortune 500 companies understand, preserve, and modernize their mainframe systems. These are the systems that run COBOL from the 1960s that still quietly power banking, insurance, airlines, and governments today.&lt;/p&gt;&lt;p&gt;70% of the Fortune 500 still run on mainframes, but the engineers who built and maintained them are retiring. Today, the average age of a COBOL/mainframe engineer is about 55 and rapidly increasing. What’s left behind are opaque, black box systems with almost no one who understands how they work. Modernization projects often fail, documentation is decades out of date, and critical institutional knowledge lives only in the minds of a few senior subject matter experts who are now leaving the workforce.&lt;/p&gt;&lt;p&gt;Current “AI for code” tools focus on codebases and repositories, so they miss the unwritten rules, historical context, and architectural reasoning that live in human minds. In the COBOL/mainframe world, that institutional knowledge is the key missing piece.&lt;/p&gt;&lt;p&gt;What we heard from modernization leaders is that the hard part is not the code analysis. The challenge is the institutional knowledge that never made it into code or documentation and has walked out the door. Modernization projects fail not because no one can parse COBOL, but because no one can answer “why was this billing edge case added in 1995 and what breaks if we remove it.”&lt;/p&gt;&lt;p&gt;Hypercubic is building an AI-native maintenance and modernization platform that learns how legacy mainframe systems actually work and captures the human reasoning behind operating them. We’re doing this with two initial tools, HyperDocs and HyperTwin.&lt;/p&gt;&lt;p&gt;HyperDocs ingests COBOL, JCL, and PL/I codebases to generate documentation, architecture diagrams, and dependency graphs. Enterprises currently spend months or years hiring contractors to reverse-engineer these systems; HyperDocs compresses that work to take much less time.&lt;/p&gt;&lt;p&gt;COBOL was designed to resemble English and business prose, making it a good fit for LLMs today. Mainframes have decades of consistent patterns (COBOL, JCL, CICS, batch jobs) and a finite set of recurring tasks (such as payroll, transaction processing, billing).&lt;/p&gt;&lt;p&gt;For example, here’s a billing fragment that would be run nightly in production at large insurance companies for moving money, closing accounts, and triggering downstream reports:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  EVALUATE TRUE
      WHEN PAYMENT-DUE AND NOT PAID
          PERFORM CALCULATE-LATE-FEE
          PERFORM GENERATE-NOTICE
      WHEN PAYMENT-RECEIVED AND BALANCE-DUE = 0
          MOVE "ACCOUNT CLEAR" TO STATUS
          PERFORM ARCHIVE-STATEMENT
      WHEN OTHER
          PERFORM LOG-ANOMALY
  END-EVALUATE.
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt; Now imagine thousands of these rules, each running payrolls, processing claims, or reconciling accounts, spread across millions of lines of code written over 40+ years. HyperDocs ingests that code and reconstructs it into readable, living documentation that shows how the black box system works.&lt;/p&gt;&lt;p&gt;Our other tool, HyperTwin, tackles the “tribal knowledge” problem. It learns directly from subject-matter experts, observing workflows, analyzing screen interactions, and conducting AI-driven interviews to capture how they debug and reason about their systems. The goal is to build digital “twins” of the experts on how they debug, architect, and maintain these systems in practice.&lt;/p&gt;&lt;p&gt;Together, HyperDocs and HyperTwin form a knowledge graph of legacy systems linking code, systems, and human reasoning.&lt;/p&gt;&lt;p&gt;Here’s a demo video of our HyperTwin product: https://www.youtube.com/watch?v=C-tNtl9Z_jY&lt;/p&gt;&lt;p&gt;You can explore our documentation platform, including examples from the AWS Card Demo (a widely used COBOL codebase example) and a dummy insurance project here: https://hyperdocs-public.onrender.com/.&lt;/p&gt;&lt;p&gt;e.g. Developer perspective docs - High level system architecture of credit card management: https://hyperdocs-public.onrender.com/docs/aws-carddemo-with...&lt;/p&gt;&lt;p&gt;We’re curious to hear your thoughts and feedback, especially from anyone who’s worked with mainframes or tried to modernize legacy systems.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45877517"/><published>2025-11-10T16:23:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877698</id><title>Benchmarking leading AI agents against Google reCAPTCHA v2</title><updated>2025-11-11T05:11:51.958979+00:00</updated><content>&lt;doc fingerprint="55f4c6192b13c2f3"&gt;
  &lt;main&gt;
    &lt;p&gt;We evaluate three leading AI models—Claude Sonnet 4.5 (Anthropic), Gemini 2.5 Pro (Google), and GPT-5 (OpenAI)—on their ability to solve Google reCAPTCHA v2 challenges. Compared to Sonnet and Gemini, GPT-5's long and slow reasoning traces led to repeated challenge timeouts and significantly lower performance.&lt;/p&gt;
    &lt;p&gt;Many sites use CAPTCHAs to distinguish humans from automated traffic. How well do these CAPTCHAs hold up against modern AI agents? We tested three leading models—Claude Sonnet 4.5, Gemini 2.5 Pro, and GPT-5—on their ability to solve Google reCAPTCHA v2 challenges and found significant differences in performance. Claude Sonnet 4.5 performed best with a 60% success rate, slightly outperforming Gemini 2.5 Pro at 56%. GPT-5 performed significantly worse and only managed to solve CAPTCHAs on 28% of trials.&lt;/p&gt;
    &lt;p&gt;Each reCAPTCHA challenge falls into one of three types: Static, Reload, and Cross-tile (see Figure 2). The models' success was highly dependent on this challenge type. In general, all models performed best on Static challenges and worst on Cross-tile challenges.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Static&lt;/cell&gt;
        &lt;cell role="head"&gt;Reload&lt;/cell&gt;
        &lt;cell role="head"&gt;Cross-tile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Claude Sonnet 4.5&lt;/cell&gt;
        &lt;cell&gt;47.1%&lt;/cell&gt;
        &lt;cell&gt;21.2%&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Gemini 2.5 Pro&lt;/cell&gt;
        &lt;cell&gt;56.3%&lt;/cell&gt;
        &lt;cell&gt;13.3%&lt;/cell&gt;
        &lt;cell&gt;1.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GPT-5&lt;/cell&gt;
        &lt;cell&gt;22.7%&lt;/cell&gt;
        &lt;cell&gt;2.1%&lt;/cell&gt;
        &lt;cell&gt;1.1%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Why did Claude and Gemini perform better than GPT-5? We found the difference was largely due to excessive and obsessive reasoning. Browser Use executes tasks as a sequence of discrete steps — the agent generates "Thinking" tokens to reason about the next step, chooses a set of actions, observes the response, and repeats. Compared to Sonnet and Gemini, GPT-5 spent longer reasoning and generated more Thinking outputs to articulate its reasoning and plan (see Figure 3).&lt;/p&gt;
    &lt;p&gt;These issues were compounded by poor planning and verification: GPT-5 obsessively made edits and corrections to its solutions, clicking and unclicking the same square repeatedly. Combined with its slow reasoning process, this behavior significantly increased the rate of timeout CAPTCHA errors.&lt;/p&gt;
    &lt;p&gt;Compared to Static challenges, all models performed worse on Reload and Cross-tile challenges. Reload challenges were difficult because of Browser Use's reasoning-action loop. Agents often clicked the correct initial squares and moved to submit their response, only to see new images appear or be instructed by reCAPTCHA to review their response. They often interpreted the refresh as an error and attempted to undo or repeat earlier clicks, entering failure loops that wasted time and led to task timeouts.&lt;/p&gt;
    &lt;p&gt;Cross-tile challenges exposed the models' perceptual weaknesses, especially on partial, occluded, and boundary-spanning objects. Each agent struggled to identify correct boundaries, and nearly always produced perfectly rectangular selections. Anecdotally, we find Cross-tile CAPTCHAs easier than Static and Reload CAPTCHAs—once we spot a single tile that matches the target, it's easy to identify the adjacent tiles that include the target. This difference in difficulty suggests fundamental differences in how humans and AI systems solve these challenges&lt;/p&gt;
    &lt;p&gt;What can developers and researchers learn from these results? More reasoning isn't always better. Ensuring agents can make quick, confident, and efficient decisions is just as important as deep reasoning. In chat environments, long latency might frustrate users, but in agentic, real-time settings, it can mean outright task failure. These failures can be compounded by suboptimal agentic architecture—in our case, an agent loop that encouraged obsession and responded poorly to dynamic interfaces. Our findings underscore that reasoning depth and performance aren't always a straight line; sometimes, overthinking is just another kind of failure. Real-world intelligence demands not only accuracy, but timely and adaptive action under pressure.&lt;/p&gt;
    &lt;p&gt;Each Google reCAPTCHA v2 challenge presents users with visual challenges, asking them to identify specific objects like traffic lights, fire hydrants, or crosswalks in a grid of images (see Figure 5).&lt;/p&gt;
    &lt;p&gt;We instructed each agent to navigate to Google's reCAPTCHA demo page and solve the presented CAPTCHA challenge (explicit image-based challenges were presented on 100% of trials). Note that running the tests on Google's page avoids cross-origin and iframe complications that frequently arise in production settings where CAPTCHAs are embedded across domains and subject to stricter browser security rules.&lt;/p&gt;
    &lt;p&gt;We evaluated generative AI models using Browser Use, an open-source framework that enables AI agents to perform browser-based tasks. We gave each agent the following instructions when completing the CAPTCHA:&lt;/p&gt;
    &lt;p&gt; 1. Go to: https://www.google.com/recaptcha/api2/demo &lt;lb/&gt; 2. Complete the CAPTCHA. On each CAPTCHA challenge, follow these steps:&lt;lb/&gt; 2a. Identify the images that match the prompt and select them. &lt;lb/&gt; 2b. Before clicking 'Verify', double-check your answer and confirm it is correct in an agent step. &lt;lb/&gt; 2c. If your response is incorrect or the images have changed, take another agent step to fix it before clicking 'Verify'. &lt;lb/&gt; 2d. Once you confirm your response is correct, click 'Verify'. Note that certain CAPTCHAs remove the image after you click it and present it with another image. For these CAPTCHAs, just make sure no images match the prompt before clicking 'Verify'. &lt;lb/&gt; 3. Try at most 5 different CAPTCHA challenges. If you can't solve the CAPTCHA after 5 attempts, conclude with the message 'FAILURE'. If you can, conclude with 'SUCCESS'. Do not include any other text in your final message. &lt;/p&gt;
    &lt;p&gt;Agents were instructed to try up to five different CAPTCHAs. Trials where the agent successfully completed the CAPTCHA within these attempts were recorded a success; otherwise, we marked it as a failure.&lt;/p&gt;
    &lt;p&gt;Although we instructed the models to attempt no more than five challenges per trial, agents often exceeded this limit and tried significantly more CAPTCHAs. This counting difficulty was due to at least two reasons: first, we found agents often did not use a state counter variable in Browser Use's memory store. Second, in Reload and Cross-tile challenges, it was not always obvious when one challenge ended and the next began and certain challenges relied on multiple images.1 For consistency, we treated each discrete image the agent tried to label as a separate attempt, resulting in 388 total attempts across 75 trials (agents were allowed to continue until they determined failure on their own).&lt;/p&gt;
    &lt;p&gt;When the first challenge was Cross-tile, reCAPTCHA presented two images in sequence. Solving the first image did not guarantee success because the second image had to be solved as well. We counted each image as one attempt. In a few cases (fewer than five), an agent solved one image but failed the other.&lt;/p&gt;
    &lt;p&gt;Mathew Hardy, Mayank Agrawal, and Milena Rmus work at Roundtable Technologies Inc., where they are building proof-of-human authentication systems. Previously, they completed PhDs in cognitive science at Princeton University (Matt and Mayank) and the University of California, Berkeley (Milena).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://research.roundtable.ai/captcha-benchmarking/"/><published>2025-11-10T16:38:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45878578</id><title>The lazy Git UI you didn't know you need</title><updated>2025-11-11T05:11:51.606325+00:00</updated><content>&lt;doc fingerprint="2ebcc050e97f34b3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The (lazy) Git UI You Didn't Know You Need&lt;/head&gt;
    &lt;p&gt;When my son was born last April, I had ambitious learning plans for the upcoming 5w paternity leave. As you can imagine, with two kids, life quickly verified this plan 🙃. I did eventually start some projects. One of the goals (sounding rebellious in the current AI hype cycle) was to learn and use neovim for coding. As a Goland aficionado, I (and my wrist) have always been tempted by no-mouse, OSS, gopls based, highly configurable dev setups.&lt;/p&gt;
    &lt;p&gt;Long story short, I’d still stick to Goland for my professional coding (for now), but during the experiments with &lt;code&gt;nvim&lt;/code&gt;, I accidentally stumbled upon lazygit
Git UI. I literally mistyped &lt;code&gt;&amp;lt;space&amp;gt;gg&lt;/code&gt; instead of &lt;code&gt;gg&lt;/code&gt;, which opened up the built-in &lt;code&gt;lazygit&lt;/code&gt; overlay UI.&lt;/p&gt;
    &lt;p&gt;A week later, I have already switched all my &lt;code&gt;git&lt;/code&gt; workflows to &lt;code&gt;lazygit&lt;/code&gt; (also outside &lt;code&gt;nvim&lt;/code&gt;), and I have been using it since then. In this post, I’d like to explain why it happened so quickly, so:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What makes &lt;code&gt;lazygit&lt;/code&gt;so special?&lt;/item&gt;
      &lt;item&gt;How can it make you more productive?&lt;/item&gt;
      &lt;item&gt;What we can all learn from &lt;code&gt;lazygit&lt;/code&gt;around designing incredible software with seamless UX?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s jump in!&lt;/p&gt;
    &lt;head rend="h2"&gt;Lazy approach to Git tools&lt;/head&gt;
    &lt;p&gt;Likely every developer knows and (in some form) uses the git CLI . It’s relatively simple, and it seems incredibly stable – the only change I noticed in the last decade was the new &lt;code&gt;git switch&lt;/code&gt; command, although I still haven’t “switched” to it from the lovely &lt;code&gt;git checkout&lt;/code&gt;🙃 .&lt;/p&gt;
    &lt;p&gt;As a result, it’s common to see developers memorize a few commands you typically use (e.g.&lt;code&gt;clone&lt;/code&gt;, &lt;code&gt;fetch/pull&lt;/code&gt;, &lt;code&gt;config/remote&lt;/code&gt;, &lt;code&gt;add/rm&lt;/code&gt;, &lt;code&gt;status&lt;/code&gt;, &lt;code&gt;checkout&lt;/code&gt;, &lt;code&gt;commit&lt;/code&gt;, &lt;code&gt;push&lt;/code&gt;, &lt;code&gt;cherry-pick&lt;/code&gt;, &lt;code&gt;rebase&lt;/code&gt;, &lt;code&gt;merge&lt;/code&gt;, &lt;code&gt;log&lt;/code&gt;) and stick to the CLI. In fact, in 2022, 83% of the StackOverflow responders said they prefer CLI to other interfaces
and that number is likely still quite high nowadays.&lt;/p&gt;
    &lt;p&gt;However, graphical interfaces and generally other &lt;code&gt;git&lt;/code&gt; compatible clients do exist:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Some of them offer more or less the same &lt;code&gt;git&lt;/code&gt;workflows as the original&lt;code&gt;git&lt;/code&gt;CLI, just more visually appealing and with buttons/interactivity instead of remembering the CLI flags, e.g. git gui , GitHub Desktop or&lt;code&gt;lazygit&lt;/code&gt;discussed here.&lt;/item&gt;
      &lt;item&gt;Other projects add more magic (e.g. AI), and potentially new light abstractions/workflows in an attempt to simplify or enhance &lt;code&gt;git&lt;/code&gt;use e.g. GitKraken .&lt;/item&gt;
      &lt;item&gt;There are even projects like recently popular jj tool that completely abstracts away &lt;code&gt;git&lt;/code&gt;API and replace it with a new source control flows to “simplify” them or unify them across various VCS other than&lt;code&gt;git&lt;/code&gt;(e.g.&lt;code&gt;mercurial&lt;/code&gt;, Google Piper and everything else you wished it was&lt;code&gt;git&lt;/code&gt;, but it’s not 😛).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What you choose for your work is entirely up to you. Depending on what you are passionate about, how you work with &lt;code&gt;git&lt;/code&gt; and what type of software you are touching (monorepo vs small repos, closed vs open source, GitHub vs other hosting solutions, where you deploy, etc.), different clients might be more or less productive for you.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;NOTE: If you’re new to software engineering, don’t skip learning the&lt;/p&gt;&lt;code&gt;git&lt;/code&gt;CLI. Even if you use some higher-level interfaces later on, it will help you understand what they do in the background, plus sooner or later you will end up debugging some remote VM or container with no UI access (e.g. CI systems).&lt;p&gt;Also, as documented in the official&lt;/p&gt;&lt;code&gt;git&lt;/code&gt;documentation, “the command-line is still where you’ll have the most power and control when working with your repositories."&lt;/quote&gt;
    &lt;p&gt;For me, I need something:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;simple and fast to limit the context switch overhead.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git&lt;/code&gt;CLI-native to have fewer things that can go wrong.&lt;/item&gt;
      &lt;item&gt;“discoverable” and interactive, as I am bad at remembering keybindings and commands (I need my brain memory for more fun bits).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For those reasons, early in my career, I started depending on a hybrid workflow, with a few GUI tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;git gui instead of &lt;code&gt;status&lt;/code&gt;,&lt;code&gt;commit&lt;/code&gt;,&lt;code&gt;config/remote&lt;/code&gt;,&lt;code&gt;add/rm&lt;/code&gt;and&lt;code&gt;push&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;gitk instead of &lt;code&gt;log&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git&lt;/code&gt;CLI for everything else (e.g. rebasing/complex merging).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I don’t remember why specifically those (AFAIK, decade ago there wasn’t anything else), but I literally have been using them non-stop until this year!&lt;/p&gt;
    &lt;p&gt;A few years ago, because of the 1990-style look of those UIs, lack of active development and modern features, I looked around for some alternatives. I remember I was quickly demotivated when I accidentally lost all my local changes on a single mouse click on the wrong thing in one of the tools 🙈 (starts with &lt;code&gt;G&lt;/code&gt; and ends with &lt;code&gt;N&lt;/code&gt;). After that, I was sceptical I’d find some new tool anytime soon. The arguments to motivate me to make a switch would need to be strong.&lt;/p&gt;
    &lt;p&gt;Turns out, an open mind and a bit of curiosity in a random moment gave more fruit than tailored research. By accident, I noticed &lt;code&gt;lazygit&lt;/code&gt; and after a short try, it became my main &lt;code&gt;git&lt;/code&gt; tool.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s amazing in &lt;code&gt;lazygit&lt;/code&gt;?&lt;/head&gt;
    &lt;p&gt;Somehow, lazygit ticked so many boxes for me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It’s easy to use; it makes you productive from day 1.&lt;/item&gt;
      &lt;item&gt;It enables you to do more (and faster), even teaching you along the way.&lt;/item&gt;
      &lt;item&gt;It’s a TUI (terminal user interface), making it incredibly fast, portable and visually consistent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Many of the tool’s benefits are also amazing learning on how to build brilliant devtools and software in general.&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;lazygit&lt;/code&gt;used via lazygit IntelliJ plugin on my&lt;code&gt;git&lt;/code&gt;clone of Prometheus project.&lt;/quote&gt;
    &lt;p&gt;Personally, probably the best thing about the &lt;code&gt;lazygit&lt;/code&gt; is its UX, notably how easy it is to use this tool, with just a basic understanding of the &lt;code&gt;git&lt;/code&gt; CLI. Generally, it seems that a nice user experience is achieved due to deliberate choice of strong consistency, deliberate visualizations and interactive menus. Let me explain.&lt;/p&gt;
    &lt;head rend="h3"&gt;Consistency&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;lazygit&lt;/code&gt; is incredibly well organized and visually consistent. &lt;code&gt;lazygit&lt;/code&gt; TUI consists of a set of boxes (“views”) with consistent behaviour. Most views are generally visible, always, no matter what operation you are doing (unless you zoom in). You always have a focus on one box. It’s visibly clear that some boxes have “tabs”. When you interact with boxes on the left, the right box changes.&lt;/p&gt;
    &lt;p&gt;Then, &lt;code&gt;lazygit&lt;/code&gt; generally sticks to native &lt;code&gt;git&lt;/code&gt; terms and abstractions, which reduces the initial learning curve. In fact, this tool even teaches you about standard, yet a bit more advanced &lt;code&gt;git&lt;/code&gt; operations (e.g. &lt;code&gt;bisect&lt;/code&gt; which I used to do manually) and terms (e.g. TIL &lt;code&gt;hunk&lt;/code&gt;
which is an official &lt;code&gt;git&lt;/code&gt; term for a piece of relevant code).&lt;/p&gt;
    &lt;p&gt;Finally, by default, &lt;code&gt;lazygit&lt;/code&gt; is pretty consistent with the feeling and keybindings of &lt;code&gt;vim&lt;/code&gt;. This means that &lt;code&gt;q&lt;/code&gt; will quit the tool, &lt;code&gt;h/j/k/l&lt;/code&gt; (or arrows) are for navigation, &lt;code&gt;/&lt;/code&gt; for filtering and &lt;code&gt;y&lt;/code&gt; for copy. Then, similar to &lt;code&gt;vim&lt;/code&gt; it attempts to follow the name of the command, e.g. &lt;code&gt;c&lt;/code&gt; commits, &lt;code&gt;a&lt;/code&gt; adds all, &lt;code&gt;A&lt;/code&gt; amends, &lt;code&gt;f&lt;/code&gt; fetches, &lt;code&gt;p&lt;/code&gt; pulls, &lt;code&gt;P&lt;/code&gt; pushes, &lt;code&gt;r&lt;/code&gt; rebases.&lt;/p&gt;
    &lt;p&gt;This is incredibly important as your common workflows can be easily memorized and invoked in a quick set of a few keystrokes (see enhanced workflows ). Now, as I mentioned before, that’s a double-edged sword, because if your brain is lazy like mine, you will end up staring at the &lt;code&gt;vim/nvim&lt;/code&gt; view trying to remember what the command was to select and copy things (or quit vim
).&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;lazygit&lt;/code&gt; solves the above with a limited set of commands (that’s a good thing: do one thing and do it well
) and great “discoverability”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Discoverability&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;lazygit&lt;/code&gt; strikes an amazing balance of showing data you need when you need it. When you open this tool, it’s obvious you want to do some &lt;code&gt;git&lt;/code&gt; trickery, so it’s likely a good thing to give you all you need to know, in a pill:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What repo is this.&lt;/item&gt;
      &lt;item&gt;All staged and unstaged files with changes (&lt;code&gt;git status&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;What branch are you on.&lt;/item&gt;
      &lt;item&gt;The top ~10 commits on this branch.&lt;/item&gt;
      &lt;item&gt;Top stash item.&lt;/item&gt;
      &lt;item&gt;Last git commands you performed.&lt;/item&gt;
      &lt;item&gt;Core actions/commands you can do with their keybindings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s a lot of data! Yet &lt;code&gt;lazygit&lt;/code&gt; somehow manages to show you all of this without visually overwhelming you:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consistent and self-explanatory views with a flat action menu allow you to find the data you need when you need it quickly.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This context is game-changing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you never used this tool, or if you had spent one month doing meetings, reviews and design docs at work, and you return to coding finally, you immediately know where you are and where things are.&lt;/item&gt;
      &lt;item&gt;It reduces the risk of surprises and mistakes (&lt;code&gt;"ups! I pushed to main directly sorry!"&lt;/code&gt;), saving you a solid amount of&lt;code&gt;SWEh&lt;/code&gt;(software engineering hours) monthly.&lt;/item&gt;
      &lt;item&gt;Normally to double-check those things you would need to run multiple commands and check different windows. &lt;code&gt;lazygit&lt;/code&gt;immediately removes that context switching.&lt;/item&gt;
      &lt;item&gt;Even if you forget important keybindings for actions, it’s quick to check them on the footer or with &lt;code&gt;?&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But there’s more, &lt;code&gt;lazygit&lt;/code&gt; guides you on all operations with interactivity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Interactivity&lt;/head&gt;
    &lt;p&gt;In other UI tools, you have hundreds of buttons, with multiple layers of nested menus. &lt;code&gt;lazygit&lt;/code&gt; has a different approach. This tool teaches you on the way, what’s possible and when. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Push will give you a warning of divergence with upstream if any. Clicking &lt;code&gt;Enter&lt;/code&gt;will do&lt;code&gt;--force&lt;/code&gt;push,&lt;code&gt;Esc&lt;/code&gt;will cancel.&lt;/item&gt;
      &lt;item&gt;Rebase will ask you, if you want the interactive one or not and double-check the branch.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Interactive rebase is much more guided and interactive, than &lt;code&gt;git rebase --interactive&lt;/code&gt;. No need to manually type and remember special words (e.g.&lt;code&gt;pick/drop/squash&lt;/code&gt;or&lt;code&gt;p/d/s&lt;/code&gt;). The&lt;code&gt;&amp;lt;c-j&amp;gt;&lt;/code&gt;,&lt;code&gt;&amp;lt;c-k&amp;gt;&lt;/code&gt;keys also quickly move commits up and down (reordering).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Git conflicts after rebase will be highlighted. After you fix them &lt;code&gt;lazygit&lt;/code&gt;automatically will ask you if you want to commit them and auto continue the rebase.&lt;/item&gt;
      &lt;item&gt;When switching branches with conflicting changes, &lt;code&gt;lazygit&lt;/code&gt;will automatically ask you if you want to auto-stash those changes etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Generally, &lt;code&gt;lazygit&lt;/code&gt; guides you in your workflows with minimal distractions and guesswork. This builds trust very quickly, allowing adoption of faster workflows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced git workflows&lt;/head&gt;
    &lt;p&gt;Eventually, &lt;code&gt;lazygit&lt;/code&gt; boosted productivity around git workflows for me and for many other existing happy users.&lt;/p&gt;
    &lt;p&gt;What’s impressive is that &lt;code&gt;lazygit&lt;/code&gt; does it without adding entirely new workflows. Instead, it makes what &lt;code&gt;git&lt;/code&gt; CLI offers much more usable, safer, quicker and discoverable. It teaches you better patterns.&lt;/p&gt;
    &lt;p&gt;One example is highlighted with custom patching. Imagine you made some changes, committed them, but then you want to bring back a few lines (but not all) to what it was before, from an earlier commit. My previous flow used to be either:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local IDE history (slow-ish, too much granularity (every file save), not always available).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git gui&lt;/code&gt;tool I clicked&lt;code&gt;amend&lt;/code&gt;which would pull all changed files from that commit to&lt;code&gt;staged&lt;/code&gt;area, then I find lines I want, manually copy them (with those git diff&lt;code&gt;+&lt;/code&gt;and&lt;code&gt;-&lt;/code&gt;chars!) and paste to IDE, then trim unwanted chars. Pretty horrible habit (:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When using &lt;code&gt;lazygit&lt;/code&gt;, I obviously tried to replicate my broken workflow. I couldn’t because &lt;code&gt;lazygit&lt;/code&gt; diffs are not intuitively select+copy-able (it might be fixable over time; not the highest priority, but people want this e.g. 1
, 2
). I even +1 one some issue around it
, and I’m glad I did, because the maintainer pointed me to… 10x simpler workflow: native reset/patch per line/hunk flow!&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;All git diffs in&lt;/p&gt;&lt;code&gt;lazygit&lt;/code&gt;(no matter if unstaged/staged/stashed/committed changes) support per line or hunk selection and patching/selection.&lt;/quote&gt;
    &lt;p&gt;With this, my “line reset from the last commit” workflow is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;simpler&lt;/item&gt;
      &lt;item&gt;within a single place&lt;/item&gt;
      &lt;item&gt;works for any commit (not only the latest)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Steps in &lt;code&gt;lazygit&lt;/code&gt;: focus on commits view &amp;gt; select commit &amp;gt; select file &amp;gt; select lines to reset &amp;gt; patch options &amp;gt; “remove patch from the original commit”. All either mouse-assisted or &lt;code&gt;4 enter enter space &amp;lt;c-p&amp;gt; d&lt;/code&gt; within seconds.&lt;/p&gt;
    &lt;p&gt;Those short key bindings are game changers in general. I’d recommend starting with a slower, but careful mouse-assisted flow, then naturally you memorize the needed keystrokes without noticing. For me, after some time, some quick flows became a habit, I was using shortcuts unconsciously.&lt;/p&gt;
    &lt;p&gt;As a result, my common &lt;code&gt;git&lt;/code&gt; flows, with &lt;code&gt;lazygit&lt;/code&gt;, were significantly improved:&lt;/p&gt;
    &lt;head rend="h5"&gt;Iterating on changes and updating upstream:&lt;/head&gt;
    &lt;p&gt;My typical flow to ensure clean commit log:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select files to commit &amp;gt; add to the last commit (amend) &amp;gt; force push&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;2 space A P enter&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Iterating on changes and updating upstream with a new commit:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select files to commit &amp;gt; create new commit &amp;gt; push&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;2 space c &amp;lt;type commit title&amp;gt; P&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Syncing branches&lt;/head&gt;
    &lt;p&gt;I generally do an interactive rebase for this. I avoid merges, unless squashed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select branch &amp;gt; rebase &amp;gt; interactive rebase &amp;gt; arrange commits &amp;gt; rebase options &amp;gt; continue&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;3 r i &amp;lt;s/p/d/.. to arrange rebase&amp;gt; m c&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Removing unwanted commit from history&lt;/head&gt;
    &lt;p&gt;Normally you would need to do full interactive rebase against &lt;code&gt;HEAD~4&lt;/code&gt; or something, but now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select commit &amp;gt; drop&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;4 d&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Removing unwanted file changes from commits&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select commit &amp;gt; select file &amp;gt; remove&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;4 enter d&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Splitting commit into multiple PRs/commits&lt;/head&gt;
    &lt;p&gt;This is normally a bit painful, but now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select commit &amp;gt; select file &amp;gt; select lines or hunks &amp;gt; patch options &amp;gt; move patch into new commit after the original commit &amp;gt; create new commit&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;4 enter enter &amp;lt;c-p&amp;gt; n &amp;lt;type commit title&amp;gt; enter&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Cherry-pick&lt;/head&gt;
    &lt;p&gt;Typically, it meant copying commit SHAs around; prone to errors. Now:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;select branch &amp;gt; select commit &amp;gt; copy for cherry-pick (you can buffer many) &amp;gt; select target branch &amp;gt; go to commits &amp;gt; paste&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;3 4 C 3 4 V&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;…and many more!&lt;/p&gt;
    &lt;head rend="h2"&gt;What can we learn?&lt;/head&gt;
    &lt;p&gt;To me, &lt;code&gt;lazygit&lt;/code&gt; is not only an amazing tool for everyday use, but also an inspiration around devtools UX. The simplicity, consistency, discoverability, sane defaults, shortcuts for common flows and interactivity
should be on the radar for anyone who builds devtools. Not mentioning deep configurability
, a healthy dose of extensibility
, being fully free (donations possible!
), a healthy OSS situation
and… tool being written 100% in Go! (:&lt;/p&gt;
    &lt;p&gt;Imagine what other tools we could write, reusing similar patterns or even similar UX! TUI framework and &lt;code&gt;lazygit&lt;/code&gt; code is fully OSS (MIT)
, so anyone has a healthy base for building different tools. I do have ideas for a few tools, especially around some extremely manual release workflows in our ecosystems. Let’s collaborate! 💪&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;Hope this write-up was useful for you!&lt;/p&gt;
    &lt;p&gt;Even with the current advancement in GenAI, statistical aspect of LLMs makes them not a great fit for reliable and accurate version control changes that projects and systems have to rely on. Some LLM assist (e.g. generating commit messages) will eventually come to &lt;code&gt;lazygit&lt;/code&gt; and git tooling, but the core of &lt;code&gt;lazygit&lt;/code&gt; is to remain incredibly relevant for the (increasingly AI-assisted) software development cycles.&lt;/p&gt;
    &lt;p&gt;Kudos to all maintainers, contributors and sponsors of &lt;code&gt;lazygit&lt;/code&gt; for an amazing work!&lt;/p&gt;
    &lt;p&gt;Feel free to comment, give feedback AND use and contribute to the &lt;code&gt;lazygit&lt;/code&gt; project! Happy coding!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bwplotka.dev/2025/lazygit/"/><published>2025-11-10T17:50:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45878826</id><title>Omnilingual ASR: Advancing automatic speech recognition for 1600 languages</title><updated>2025-11-11T05:11:51.393589+00:00</updated><content/><link href="https://ai.meta.com/blog/omnilingual-asr-advancing-automatic-speech-recognition/?_fb_noscript=1"/><published>2025-11-10T18:10:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45879012</id><title>Memory Safety for Skeptics</title><updated>2025-11-11T05:11:50.058521+00:00</updated><content>&lt;doc fingerprint="aa6ad993b82396c8"&gt;
  &lt;main&gt;
    &lt;p&gt;Memory safety—the property that makes software devoid of weaknesses such as buffer overflows, double-frees, and similar issues—has been a popular topic in software communities over the past decade and has gained special prominence alongside the rise of the Rust programming language. Rust did not invent the idea of memory safety, nor was it the first memory-safe language, but it did break the dam on the last major holdout context where memory safety had not yet been achieved: what we often call "systems programming."&lt;/p&gt;
    &lt;p&gt;Rust's big step function was to offer memory safety at compile time through the use of static analysis borrowed and grown out of prior efforts such as Cyclone, a research programming language formulated as a safe subset of C. Rust, by offering a memory-safe-by-default experience for the "systems" domain, where operating systems, databases, file systems, embedded software, and the like are made, suddenly presented a new possibility to public policymakers and to leaders of engineering organizations: the mass reduction of memory unsafety across any domain.&lt;/p&gt;
    &lt;p&gt;In the years since Rust hit the scene, tech companies have published experience reports on the adoption of Rust for production systems, whether through rewrites of existing code or by producing new modules in Rust that might have otherwise been written in C or C++. The numbers were broadly consistent: a roughly 70 percent reduction in memory-safety vulnerabilities. Rust, more than just promising memory safety, was demonstrably translating safety guarantees into practical improvements in software security. This evidence, turning the abstract benefits of a semantic improvement into bottom-line improvements in business costs (vulnerabilities are expensive for all involved), meant that organizations beyond just engineering groups began to take notice.&lt;/p&gt;
    &lt;p&gt;Of course, the choice of programming language is a contentious one. Languages do not exist in a vacuum, and the "right" language for a job is heavily path dependent. What languages do the developers already know? What's the timeline and budget for the project? How serious are the correctness constraints? The performance constraints? Do you expect to hire more developers, and what resources can you allocate to train them? If you're an open-source project, you might ask which languages would possibly bring in more developers to contribute. For any project, your answer might be determined by what other libraries or tools you will need to integrate.&lt;/p&gt;
    &lt;p&gt;What's more, many projects have already made their programming-language decision years ago—possibly decades ago. What should they do? If the code you have today is memory unsafe, in C or C++, how can you pursue safety without throwing the whole thing out?&lt;/p&gt;
    &lt;p&gt;In some circles, the answer given might be to "rewrite it in Rust" to replace legacy software written in memory-unsafe languages with new Rust equivalents. The benefits, supporters argue, are clear: comparable performance, modern tooling, and memory safety.&lt;/p&gt;
    &lt;p&gt;Yet, experienced developers know rewrites are expensive and frequently misguided . Often, demands for large-scale rewrites are not a carefully reasoned argument about tradeoffs, but an aesthetic criticism of code that looks "ugly" or "too old." If anything, those calling for mass rewrites show their own inability to do the difficult work of understanding and working with an existing codebase that does a job and does it well.&lt;/p&gt;
    &lt;p&gt;There are paths between accepting memory unsafety as the cost of doing business or performing a mass rewriting of stable systems in a new language to achieve safety. Reflexive rejection of a move to memory safety is misguided, especially when the benefits of memory safety can be achieved in a cost- and schedule-efficient way.&lt;/p&gt;
    &lt;p&gt;If you're not yet sold on the value of memory safety, this article is for you. The goal in writing it is to treat the question of pursuing memory safety in legacy systems with the seriousness and rigor that it deserves.&lt;/p&gt;
    &lt;p&gt;Pursuing memory safety is worthwhile, with or without Rust, and I'd like to convince you to try.&lt;/p&gt;
    &lt;p&gt;Software systems do not exist in isolation; software is built to do things, to serve the needs of businesses and individuals by making systems more efficient or automatic. The development of software is constrained not by the theoretical limits of software's abilities, but by the cost and schedule limitations of the team building it.&lt;/p&gt;
    &lt;p&gt;In "The Case for Memory Safe Roadmaps," a collection of government agencies from the "Five Eyes Countries" (the United States, United Kingdom, Australia, New Zealand, and Canada) collectively recommended that organizations develop roadmaps for transitioning their software development efforts to memory-safe languages.&lt;/p&gt;
    &lt;p&gt;It's worth being clear here: Their focus is on roadmaps, and they very explicitly accept and discuss the challenge of the cost and schedule impacts of any transition toward memory safety.&lt;/p&gt;
    &lt;p&gt;Budget and schedule constraints and the desire for efficiency are part of what motivates the creation of software in the first place. Once that software is in place, it's frequently mission critical, having replaced the knowledge and labor of people who would have previously done the jobs the software now performs. Instead of accountants, a company may have accounting software, with a smaller number of accountants who know how to interact with the software and use it to perform their own jobs built on the knowledge the software provides with its data and embedded business logic.&lt;/p&gt;
    &lt;p&gt;Rewrites to critical software systems are risky precisely because the software itself is so important. Rewriting a software system, whether as an in-place rewrite where components are swapped out piece by piece, or as a wholesale rewrite with a cutover date, risks the proper functioning of the business if the rewrite fails .&lt;/p&gt;
    &lt;p&gt;Complex, long-running software systems can face other severe constraints as well. They may be unable to be turned off—because, having become so business critical and time sensitive, any attempt to bring them offline for maintenance or replacement is unacceptable. They may also have become lost artifacts, where the expertise of the individuals who created them or previously worked on them is lost because it wasn't transferred to newer engineers, resulting in a current team that does not understand the system or feel comfortable making changes to it.&lt;/p&gt;
    &lt;p&gt;There are also ongoing costs associated with the development of software that might have to be diverted to support even an incremental rewrite. Depending on the business, there might not be funding available to support an increase to the development team, so diversion of resources toward a rewrite would mean reduction in the delivery of features for the project, which may be untenable.&lt;/p&gt;
    &lt;p&gt;All of this is to say that rewrites, even incremental ones, are business decisions that have to be made as tradeoffs with other strategic goals. While motivated developers can make the best case possible for the upside of a rewrite, they must also grapple with the businesses' needs to deliver features and address bugs impacting users of the system today.&lt;/p&gt;
    &lt;p&gt;At the same time, a transition to memory-safe languages can bring benefits beyond just the safety (and thereby security) claims that are often given priority in these discussions.&lt;/p&gt;
    &lt;p&gt;Memory-safety violations, such as null pointer dereferences or indexing outside of the bounds of a memory buffer, can result in denial of service (or, in the context of the classic security CIA triad, availability failures) of the relevant software. This might mean on-call pages to respond to a production incident, a failure to meet service-level agreement guarantees for customers, or reduced revenue from lost customers or interruption of business operations.&lt;/p&gt;
    &lt;p&gt;Memory-safety issues are also often a central building block in a kill chain for achieving remote code execution by attackers. Even as far back as "Smashing the Stack for Fun and Profit" in 1996, we could see cybersecurity professionals documenting how to turn a buffer-overflow weakness into remote code execution and full access to the host. With that foothold in place, attackers can begin to exfiltrate data, move laterally within a network, escalate privileges, lock down a system with ransomware, conscript a host into a botnet, and more.&lt;/p&gt;
    &lt;p&gt;Software problems are cheaper to fix the earlier they occur in the software development lifecycle. In the long term, stopping a bug from being written is cheaper than responding to a bug bounty submission or triaging a production outage.&lt;/p&gt;
    &lt;p&gt;This is not to say that all moves toward memory safety are cost effective or that all roadmaps for memory safety should be as aggressive as possible, but it is intended to make clear that there are both costs and savings to be had with any transition to memory safety.&lt;/p&gt;
    &lt;p&gt;What is memory safety? There should be a table-stakes answer to that question to have in hand amid the push toward memory safety in public discourse, but there is not a single, fully agreed-upon, and rigorous definition. There is a new effort, announced in a recent article published in Communications of the ACM, to develop a standard definition of memory safety, but it is just beginning.&lt;/p&gt;
    &lt;p&gt;There is, however, a rough consensus among practitioners of what kinds of program behaviors are memory unsafe. That's a good place to start.&lt;/p&gt;
    &lt;p&gt;My favorite short definition comes from Michael Hicks, an academic who works on programming languages:&lt;/p&gt;
    &lt;p&gt;"[A] program execution is memory safe so long as a particular list of bad things, called memory-access errors, never occur:&lt;/p&gt;
    &lt;p&gt;• Buffer overflow&lt;/p&gt;
    &lt;p&gt;• Null pointer dereference&lt;/p&gt;
    &lt;p&gt;• Use after free&lt;/p&gt;
    &lt;p&gt;• Use of uninitialized memory&lt;/p&gt;
    &lt;p&gt;• Illegal free (of an already freed pointer, or a non-&lt;code&gt;malloc&lt;/code&gt;-ed pointer)"&lt;/p&gt;
    &lt;p&gt;You will sometimes see these categories broken down further, into spatial and temporal memory safety. Spatial covers memory-safety issues arising from accessing locations in memory that a program should not have access to (like a buffer overflow); temporal covers operations on memory done in the wrong order: for example, reading memory before it is initialized, trying to free an already freed pointer, or using a pointer after it has been freed.&lt;/p&gt;
    &lt;p&gt;There's also the CWE (Common Weakness Enumeration) category for memory-safety issues, which decomposes Hicks's list into more granular options. CWE is a taxonomy of software weaknesses, or as CWE puts it: "condition[s] in... software... that, under certain circumstances, could contribute to the introduction of vulnerabilities."&lt;/p&gt;
    &lt;p&gt;In CWE's memory-safety category, "buffer overflow" is further broken down into six different, more-specific weaknesses, some of which are further decomposed into their own variants. This can be useful when maximum precision is warranted but is perhaps too much detail for the purposes of this article.&lt;/p&gt;
    &lt;p&gt;These definitions provide a reasonably clear picture of what constitutes memory unsafety. So, memory safety is when a program is guaranteed not to have those weaknesses. This can be achieved by compile-time constraints on the semantics of programs or by runtime management of memory by a garbage collector, so long as the guarantee is upheld.&lt;/p&gt;
    &lt;p&gt;This is often when perceptive onlookers will cry foul. Rust permits unsafety! There's a whole unsafe keyword! How is that meaningfully different from the guarantees of C or C++?&lt;/p&gt;
    &lt;p&gt;Of course, they're right. Rust does permit programmers to write unsafe code, but as anyone who works in safety or security will tell you, defaults matter. In fact, defaults matter a lot!&lt;/p&gt;
    &lt;p&gt;Let's use seat belts as an example. Seat belts became generally mandatory across the United States between the late 1980s to the early 1990s. In 1985, when mandatory seatbelt laws first saw passage among the states, seatbelt usage sat at 21 percent of riders. In 1994, the average seatbelt usage rate in the U.S. was 58 percent. As of 2017, it was 89.7 percent. That change in defaults led to massive increases in seatbelt usage and therefore saved more lives. The National Highway Transportation and Safety Administration estimates that in 2017 alone, seatbelts saved the lives of nearly 15,000 Americans.&lt;/p&gt;
    &lt;p&gt;The same truth applies in software. Before version 4.0.0 (published in 2017), Redis, the extremely popular key-value store, offered no access controls in its default configuration. Frequently, new users of Redis would unintentionally expose their instance publicly, and this insecurity would result in data spills or become a vector for host exploitation. As of version 4.0.0, Redis enters a "protected mode" when run with its default configuration and without password protection. This limits access to loopback interfaces. As the Redis company itself has since touted, the introduction of protected mode has caused the number of publicly accessible Redis instances tracked on Shodan.io, a popular internet host aggregator, to decline substantially. In 2017, it had identified roughly 17,000 exposed Redis instances; in 2020, that number had declined to 8,000 in an audit by security company TrendMicro.&lt;/p&gt;
    &lt;p&gt;Bringing it back to memory safety, we can and should think of memory-safety guarantees by languages as a continuum, and we can split languages between "memory safe by default" and "non-memory safe by default" groups. This framing, recommended by the OpenSSF's (Open Source Security Foundation's) Memory Safety SIG (Special Interest Group), makes the options clearer:&lt;/p&gt;
    &lt;p&gt;• Using memory-safe-by-default languages&lt;/p&gt;
    &lt;p&gt;• Using memory-safe-by-default languages to interface with non-memory-safe-by-default languages&lt;/p&gt;
    &lt;p&gt;• Using non-memory-safe-by-default languages&lt;/p&gt;
    &lt;p&gt;Here, memory-safe-by-default languages include not only Rust, but also common garbage-collected languages such as Java, C#, Go, Swift, Python, Ruby, and more. Non-memory-safe-by-default languages include C and C++ most notably, but also Zig, which may be surprising to those who have watched memory-safety discussions from the sidelines.&lt;/p&gt;
    &lt;p&gt;While Zig does provide more ergonomic options for programmers to write memory safe programs themselves, Zig is not a memory-safe language, because it does not guarantee memory safety even in its most conservative configuration. Jamie Brandon's breakdown of Zig's memory safety is a good walkthrough of why Zig's guarantees are insufficient.&lt;/p&gt;
    &lt;p&gt;With a shared understanding of memory safety and memory-safe languages, let's now dig into the concrete strategies for pursuing memory safety in real-world programs.&lt;/p&gt;
    &lt;p&gt;Any of the following strategies are intended to maximize the benefit of memory safety while minimizing the cost of pursuing it. The specific choice of which approach is right is context dependent and should be made with consideration of the importance of the component, the current and new target language, the team involved, and the timetable.&lt;/p&gt;
    &lt;p&gt;The first and most obvious option is to make new code memory safe—that is, to write new components in a memory-safe language. While this seems simple, you must address certain caveats to make this approach successful.&lt;/p&gt;
    &lt;p&gt;First, you are unlikely to reap the benefits of memory safety if you try introducing memory-safe code alongside new memory-unsafe code. Think of it this way: In a fixed codebase that you continue to assure (via testing, code review, bug bounties, and more), the density of vulnerabilities decreases exponentially over time. As vulnerabilities become less and less dense in the codebase, the rate of new vulnerability discoveries also decreases, and so the overall assurance level of the code increases. The riskiest thing you can do to a codebase is change it. In the case of memory-unsafe languages, that change can induce memory-safety vulnerabilities.&lt;/p&gt;
    &lt;p&gt;The Google Chrome and Android teams have published extensively about their experiences incentivizing a move to memory-safe languages in their codebases. They instituted a rule called the "Rule of Two," where all new code must be either sandboxed or in a memory-safe language. In practice, because sandboxing is difficult, this naturally gave developers incentive to pursue memory safety in most cases.&lt;/p&gt;
    &lt;p&gt;Surprisingly to the team, they reaped the benefits of this new policy across the entire codebase—even the parts that weren't rewritten. Because they had certain assurances about the new code inherent in the safety mechanisms it came with, they could focus assurance efforts on old code, which was now static. Through this, they not only reduced the overall rate of memory-safety vulnerabilities in the codebase, but also decreased the prevalence of vulnerabilities overall.&lt;/p&gt;
    &lt;p&gt;Sometimes, rewriting code in a memory-safe language can be the right choice, but this is often a path to pursue only once you fully understand the challenges faced by the current memory-unsafe code.&lt;/p&gt;
    &lt;p&gt;Early in its history, the development of Rust was funded by Mozilla, makers of the Firefox web browser, and the flagship Rust project besides Rust's own compiler was the Servo web-rendering engine. Despite this, the first actual Rust code that Mozilla integrated into Firefox was not Servo; it was an MP4 video file parser. They replaced the existing C++ parser with one written in Rust, moving from a memory-unsafe language to a memory-safe language, because it had long been a source of vulnerabilities. Firefox needs to parse MP4 files from untrusted sources, and failures to correctly handle that parsing could be dire. For Mozilla, it was a small but security-critical surface area that made sense to target for a rewrite.&lt;/p&gt;
    &lt;p&gt;Another helpful tool for targeting is Kelly Shortridge's SUX Rule: target code that is Sandbox free, Unsafe, and eXogenous. This means you should prioritize rewriting code that processes untrusted (exogenous) input, runs without a sandbox, and is written in a memory-unsafe language. Reviewing your own codebase for these areas can be a fast way to identify critical paths with high risk of exploitation in the presence of memory-safety vulnerabilities.&lt;/p&gt;
    &lt;p&gt;When fully rewriting existing memory-unsafe code to a memory-safe language is not feasible, it might instead make sense to wrap it in a memory-safe interface. This does still lay the burden of ensuring safety properties on the programmer, both for the original code in the memory-unsafe language and for the correctness of the interface, but it then permits building safe and trusted new code on top of the old code. If you continue to work to assure the old code with techniques such as fuzz testing, analysis by sanitizers, or formal modeling, you can gain increased confidence in the latent unsafe code being wrapped.&lt;/p&gt;
    &lt;p&gt;This is in fact how many of the Rust standard library's common container types are written. Under the hood, they contain unsafe code to manage buffers and pointers in a way that is as efficient as possible, but the interface provided to the user does not give access to any materials (buffers, pointers, lengths) that would permit the user to violate memory-safety guarantees.&lt;/p&gt;
    &lt;p&gt;This "wrapping" approach helps constrain the "blast radius" of memory-unsafe code that can't feasibly be removed or replaced and constrains the auditing scope and assurance costs of that code as well.&lt;/p&gt;
    &lt;p&gt;There is a common reply in conversations about memory safety, coming from the most hardcore skeptics: Programmers should just write better code. They argue, explicitly or implicitly, that programmers who benefit from the guardrails of memory safety are bad programmers, and that real programmers are sufficiently skilled that they do not need a machine double-checking their work.&lt;/p&gt;
    &lt;p&gt;Let's be clear: This is anti-intellectual nonsense—macho self-aggrandizement masquerading as a serious technical argument. You should not take it seriously and should consider someone advancing this argument as fundamentally unserious and to be ignored.&lt;/p&gt;
    &lt;p&gt;There is no step function in quality of work in the history of human achievement that happened because people one day woke up and decided to be better at their jobs. Improvements in productivity or quality or reductions in error and harm happen because of the invention of new techniques, processes, and tools.&lt;/p&gt;
    &lt;p&gt;Reductions in traffic fatalities in the 1980s and 1990s didn't happen because drivers suddenly got better at driving; they happened because states enacted mandatory seat-belt laws.&lt;/p&gt;
    &lt;p&gt;While individuals can become more skilled at their jobs, working faster or producing fewer errors, large groups of people generally don't do so without some force that works to provide incentive or enable that change. Even when improvements are nontechnical, they come from enhancements to process or incentives for behavior. Over the past several decades, hospitals, for example, have reduced in-hospital mistakes because of increased use of standard checklists and provisioning of common materials needed for emergencies in crash carts.&lt;/p&gt;
    &lt;p&gt;Programmers who argue against memory safety by arguing for mass self-improvement are posing an impossible future as an alternative against a credible opportunity for improvements in software safety and security. While there are credible case-specific arguments against individual paths to memory safety, they do not include sudden mass improvement of skill and quality across the industry. It's important to make this clear.&lt;/p&gt;
    &lt;p&gt;One specter of the conversations around memory safety is whether the use of memory-unsafe languages will become generally unacceptable, either through formal government regulation or a rise in common requirements for software purchasing.&lt;/p&gt;
    &lt;p&gt;Today no agency, either in the U.S. or outside of it, regulates against the use of languages that are non-memory safe by default. Nor are there purchasing requirements in place calling for the use of memory-safe-by-default languages or even the presence of memory-safety roadmaps, at least for governments.&lt;/p&gt;
    &lt;p&gt;The Five Eyes report mentioned previously, "The Case for Memory Safe Roadmaps," recommends that organizations establish roadmaps for the pursuit of memory safety, but this is nonregulatory, and no amendments have been made to federal software acquisition policy to require such a roadmap in the U.S. or elsewhere. The U.S. is not outlawing C or C++. While these agencies have recommended moving away from these languages for future software development, they have not recommended indiscriminate mass rewrites of existing code.&lt;/p&gt;
    &lt;p&gt;Also note that the processes for establishing regulation or requirements would face challenges and, whether successful or not, would be slow to take effect and offer ample time for feedback and consideration.&lt;/p&gt;
    &lt;p&gt;First, regarding the prospect of regulation around memory safety in the U.S., such regulation would need to be pursued by a relevant agency that can establish a relevant jurisdiction. With the end of Chevron deference in U.S. law, a requirement that judges defer to U.S. regulatory agencies' determinations in most cases that was abolished in 2024 by the U.S. Supreme Court in Loper Bright Enterprises v. Raimondo, this pursuit of memory-safety regulation would also likely need to be explicitly backstopped by Congressional mandate to ensure it survived legal challenges where judges may overrule agency rulemaking.&lt;/p&gt;
    &lt;p&gt;Second, regarding acquisition requirements (the federal government's term for the rules around purchasing done by the government), the FAR (Federal Acquisition Regulation) would need to be updated to incorporate requirements for memory safety. For reference, in 2020 President Biden signed Executive Order 14028, which included a request that federal agencies pursue an amendment to the FAR to require inclusion of an SBOM (software bill of materials) for all software purchased by the federal government. To date, those changes have not been made, and no such requirement is in place within the FAR.&lt;/p&gt;
    &lt;p&gt;This is not to say that regulation or future federal purchasing requirements are impossible, but simply to point out that none are in place today, and any such changes would take time to be enacted and implemented.&lt;/p&gt;
    &lt;p&gt;The U.S. government's role around memory safety has so far been to act as cheerleader and promoter of the idea, including with the Office of the National Cyber Director's report, "Future Software Should Be Memory Safe;" CISA (Cybersecurity and Infrastructure Security Agency) et. al.'s "Case for Memory Safe Roadmaps;" and CISA's inclusion of memory-safety recommendations within its Secure by Design effort to collaborate with industry on improving software security.&lt;/p&gt;
    &lt;p&gt;Even without government mandate, many organizations in the tech industry have publicly stated their support for pursuing memory safety. In 2023, the Office of the National Cyber Director put out an RFI (request for information) seeking advice from the public on how best to support improving the security of open-source software. That RFI included an interest in the possibility of promoting adoption of memory-safe languages in open source.&lt;/p&gt;
    &lt;p&gt;Respondents to the RFI, which includes a number of universities, think tanks, corporations, and individuals, overwhelmingly supported a move toward memory safety. Few espoused a hardline goal of rewriting all existing code from non-memory-safe languages, but many did recognize the value of pursuing memory safety in new code, and in rewriting critical components in security-sensitive contexts when possible.&lt;/p&gt;
    &lt;p&gt;Some companies, most notably Google, have been especially vocal about their experiences with the value of memory safety. To them, the promise of memory safety is a reduction in security-related costs for long-term products such as the Google Chrome web browser or the Android operating system. By reducing memory-safety vulnerabilities at the source, they shift vulnerability costs left in the software development life cycle; the cost of catching a bug during development and stopping it from being shipped at all is orders of magnitude cheaper than the cost of receiving a security report, perhaps paying out a bug bounty, and then coordinating, preparing, and releasing a patch.&lt;/p&gt;
    &lt;p&gt;In some corners there has been a paranoia and fear that recommendations around memory safety from the U.S. government and others portend some forced end to C or C++. Bjarne Stroustrup, originator of C++ and continued major participant in the ISO Working Group that maintains the C++ specification, has recently begun to sound alarm bells in papers and speeches about the existential threat posed to C++ by failing to address the demands for memory safety, with clear reference to the possibility that software written in non-memory-safe-by-default languages may be disallowed or become practically untenable to market and sell in the future.&lt;/p&gt;
    &lt;p&gt;This fear is simultaneously overblown and correct. It is overblown to suggest the U.S. or any other government is close to outlawing C or C++, but it is correct to note that the benefits of memory safety are becoming clearer with each case study performed at scale and that we should expect natural incentives to slowly accrue larger use and developer interest in memory-safe languages over non-memory-safe languages. C and C++ won't die, but they will likely decline and become legacy languages like Cobol or Ada. They will still sustain some degree of interest and community, and a smaller number of developers will likely continue to be able to make their careers as developers in these languages, but they will be languages that present developers with fewer labor-market opportunities in the future and are unlikely to ascend in popularity and use again without substantial changes to address these safety deficiencies.&lt;/p&gt;
    &lt;p&gt;Memory-safe languages present the clearest opportunity today to substantially improve software security. While memory safety does not eliminate all classes of software weaknesses, it does eliminate a particularly pernicious class that leads to disproportionately severe vulnerabilities. While there are other techniques for addressing these kinds of weaknesses (for example, hardware-based approaches such as CHERI), they are less mature and generally more difficult to adopt at scale.&lt;/p&gt;
    &lt;p&gt;The state of possibility with memory safety today is similar to the state of automobile safety just prior to the widespread adoption of mandatory seat-belt laws. As car manufacturers began to integrate seat belts as a standard feature across their model lines and states began to require that drivers wear seat belts while driving, the rate of traffic fatalities and severity of traffic-related injuries dropped drastically. Seat belts did not solve automobile safety, but they credibly improved it, and at remarkably low cost.&lt;/p&gt;
    &lt;p&gt;The same can be done with memory safety. There is an opportunity to make substantial inroads at addressing a serious class of vulnerabilities while also, long-term, saving money on the development and operation of software systems. Memory safety is not a silver bullet, but it is a credible and cost-effective assurance technique that we as an industry should pursue aggressively. We do not need to wait for regulation to catch up; it is in our best interests to act today.&lt;/p&gt;
    &lt;p&gt;Thank you to Steve Klabnik, engineer at Oxide Computer Company and former member of the Rust Core Team, and to Michael Chernicoff, senior software engineer at MITRE, for reviewing this article and providing feedback prepublication.&lt;/p&gt;
    &lt;p&gt;Andrew Lilley Brinker is a principal engineer at MITRE, where he works on software security. He contributes to the CVE Quality Working Group, serves on the OmniBOR Core Team, and leads development of Hipcheck. He lives in southern California with his wife and two dogs.&lt;/p&gt;
    &lt;p&gt;Copyright © 2025 held by author. Publication rights licensed to ACM.&lt;/p&gt;
    &lt;p&gt;Approved for Public Release; Distribution Unlimited. Public Release Case Number 25–1514. The author's affiliation with The MITRE Corporation is provided for identification purposes only and is not intended to convey or imply MITRE's concurrence with, or support for, the positions, opinions, or viewpoints expressed by the author.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Originally published in Queue vol. 23, no. 5— &lt;lb/&gt; Comment on this article in the ACM Digital Library &lt;/p&gt;
    &lt;p&gt; Jeff Vander Stoep, Alex Rebert, Lars Bergstrom - A Practical Guide to Transitioning to Memory-Safe Languages &lt;lb/&gt; Traditional approaches to memory safety have often amounted to best-effort defect discovery after the fact, and sometimes more advanced strategies focused on threat modeling: identifying critical code, applying interventions, and repeating the cycle as the codebase evolves. While this approach is a valuable part of a defense-in-depth strategy, it is fundamentally flawed as a primary strategy. It traps teams in a reactive and never-ending cycle of treating symptoms with solutions empirically shown to be insufficiently complete without ever addressing the underlying cause. &lt;/p&gt;
    &lt;p&gt; Louis Dionne, Alex Rebert, Max Shavrick, Konstantin Varlamov - Practical Security in Production &lt;lb/&gt; The challenge of improving the memory safety of the vast landscape of existing C++ code demands pragmatic solutions. Standard library hardening represents a powerful and practical approach, directly addressing common sources of spatial safety vulnerabilities within the foundational components used by nearly all C++ developers. Our collective experience at Apple and Google demonstrates that significant safety gains are achievable with surprisingly minimal performance overhead in production environments. This is made possible by a combination of careful library design, modern compiler technology, and profile-guided optimization. &lt;/p&gt;
    &lt;p&gt; Christoph Kern - Safe Coding &lt;lb/&gt; Safe coding embodies a modular, compositional approach to building and reasoning about the safety of large, complex systems. Difficult and subtle reasoning about the safety of abstractions is localized to their implementations; the safety of risky operations within an abstraction must rely solely on assumptions supported by the abstraction's APIs and type signatures. Conversely, the composition of safe abstractions with safe code is automatically verified by the implementation language's type checker. While not a formal method itself, safe coding is grounded in principles and techniques from rigorous, formal software verification. &lt;/p&gt;
    &lt;p&gt; Jinnan Guo, Peter Pietzuch, Andrew Paverd, Kapil Vaswani - Trustworthy AI using Confidential Federated Learning &lt;lb/&gt; The principles of security, privacy, accountability, transparency, and fairness are the cornerstones of modern AI regulations. Classic FL was designed with a strong emphasis on security and privacy, at the cost of transparency and accountability. CFL addresses this gap with a careful combination of FL with TEEs and commitments. In addition, CFL brings other desirable security properties, such as code-based access control, model confidentiality, and protection of models during inference. Recent advances in confidential computing such as confidential containers and confidential GPUs mean that existing FL frameworks can be extended seamlessly to support CFL with low overheads. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://queue.acm.org/detail.cfm?id=3773095"/><published>2025-11-10T18:23:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45879793</id><title>Using Generative AI in Content Production</title><updated>2025-11-11T05:11:49.810264+00:00</updated><content>&lt;doc fingerprint="3f50dd399a7d0094"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Generative AI tools (GenAI) that allow users to rapidly generate new and creatively unique media (video, sound, text, and image) are increasingly being used across creative workflows in Content Production. At Netflix, we see these tools as valuable creative aids when used transparently and responsibly.&lt;/p&gt;
    &lt;p&gt;This guidance helps filmmakers, production partners, and vendors understand when and how to use GenAI tools in production. It also offers a practical tool for assessing and enabling confident GenAI use when producing content for Netflix.&lt;/p&gt;
    &lt;p&gt;To support global productions and stay aligned with best practices, we expect all production partners to share any intended use of GenAI with their Netflix contact, especially as new tools continue to emerge with different capabilities and risks.&lt;/p&gt;
    &lt;p&gt;Most low-risk use cases that follow the guiding principles below are unlikely to require legal review. However, if the output includes final deliverables, talent likeness, personal data, or third-party IP, written approval will be required before you proceed.&lt;/p&gt;
    &lt;head rend="h2"&gt;TABLE OF CONTENTS&lt;/head&gt;
    &lt;p&gt;What use cases always require written approval?&lt;/p&gt;
    &lt;p&gt;How can I ensure confidentiality and data protection?&lt;/p&gt;
    &lt;p&gt;Are the considerations different for final output vs temporary media?&lt;/p&gt;
    &lt;p&gt;What should we consider before using GenAI for talent enhancement?&lt;/p&gt;
    &lt;p&gt;What if I’m using a custom workflow or working with a vendor who is?&lt;/p&gt;
    &lt;head rend="h2"&gt;Guiding Principles&lt;/head&gt;
    &lt;p&gt;Given the sensitivities surrounding the use of these tools and the evolving legal landscape, it is essential to act responsibly when employing generative workflows. Netflix asks partners to consider the following guiding principles before leveraging GenAI in any creative workflow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The outputs do not replicate or substantially recreate identifiable characteristics of unowned or copyrighted material, or infringe any copyright-protected works&lt;/item&gt;
      &lt;item&gt;The generative tools used do not store, reuse, or train on production data inputs or outputs.&lt;/item&gt;
      &lt;item&gt;Where possible, generative tools are used in an enterprise-secured environment to safeguard inputs.&lt;/item&gt;
      &lt;item&gt;Generated material is temporary and not part of the final deliverables.&lt;/item&gt;
      &lt;item&gt;GenAI is not used to replace or generate new talent performances or union-covered work without consent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you can confidently say "yes" to all the above, socializing the intended use with your Netflix contact may be sufficient. If you answer “no” or “unsure” to any of these principles, escalate to your Netflix contact for more guidance before proceeding, as written approval may be required.&lt;/p&gt;
    &lt;p&gt;If your partner vendor is using a custom GenAI workflow — meaning a pipeline built from multiple tools or models — the same principles apply. More details can be found here.&lt;/p&gt;
    &lt;head rend="h2"&gt;What use cases always require written approval?&lt;/head&gt;
    &lt;p&gt;Below are a few examples of situations that, in addition to reporting intended use, always require escalation and written approval before proceeding.&lt;/p&gt;
    &lt;head rend="h4"&gt;1. Data Use&lt;/head&gt;
    &lt;p&gt;Protecting personal data and creative rights is essential when working with GenAI. These tools often require input data to generate outputs, and how that data is handled matters. Before using any GenAI tool, especially third-party or off-the-shelf options, consider whether you are using material that requires special handling, clearance, or consent.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use of Proprietary or Personal Information: Do not input Netflix-owned materials (e.g., unreleased assets, scripts, production images) or personal data (e.g., cast or crew details) into tools unless explicitly approved.&lt;/item&gt;
      &lt;item&gt;Third-Party or Unowned Talent Assets: Do not train or fine-tune models using material from artists, performers, or other rights holders unless you have the proper legal clearance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Training an image model in the style of another artist using a library of their past work, where Netflix or the talent has not cleared rights.&lt;/p&gt;
    &lt;head rend="h4"&gt;2. Creative Output&lt;/head&gt;
    &lt;p&gt;AI-generated content must be used with care, especially when it forms a visible or story-critical part of the production. Whether you're designing a world, a character, or artwork that appears in a scene, the same creative and legal standards apply as with traditionally produced assets.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Generation of Key Creative Elements: GenAI should not be used to generate main characters, key visual elements, or fictional settings that are central to the story without written approval. &lt;list rend="ul"&gt;&lt;item&gt;Examples: GenAI is used to generate a second killer doll to play the red light/green light game with Young-hee in Squid Game.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; Copyrighted or Estate-Controlled: Avoid using inputs (e.g., prompts, images) that reference copyrighted materials or likenesses of public figures or deceased individuals without appropriate permissions. &lt;list rend="ul"&gt;&lt;item&gt;Example: “Create an image inspired by McCurry’s Afghan Girl” or referencing distinctive features of a known performer (e.g., “Create a character with Meryl Streep’s nose”).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;3. Talent &amp;amp; Performance&lt;/head&gt;
    &lt;p&gt;Respect for performers and their work is foundational to the responsible use of GenAI. Whether enhancing a recorded performance or generating a digital likeness, the threshold for consent and care is exceptionally high when the intent or character of a performance may be altered.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Synthetic or Digital Replicas - Do not create digital performers, voices, or likenesses of real talent without explicit and documented consent and complying with guild requirements (where applicable).&lt;/item&gt;
      &lt;item&gt;Significant Digital Alterations to Performances - Be cautious when making changes that affect a performance's emotional tone, delivery, or intent, as even subtle edits may have legal or reputational implications.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Examples include visual ADR (altering lip-sync or facial performance to match new, unscripted dialogue).&lt;/p&gt;
    &lt;head rend="h4"&gt;4. Ethics &amp;amp; Representation&lt;/head&gt;
    &lt;p&gt;Audiences should be able to trust what they see and hear on screen. GenAI (if used without care) can blur the line between fiction and reality or unintentionally mislead viewers. That’s why we ask you to consider both the intent and the impact of your AI-generated content.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Misleading or Misrepresentative Content: Avoid creating content that could be mistaken for real events, people, or statements if they never actually occurred (e.g., fabricated footage, dialogue, or scenes presented as authentic).&lt;list rend="ul"&gt;&lt;item&gt;Example: using GenAI to create a fake news segment featuring a real journalist delivering a fabricated statement, even if intended as background.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Impact on Union Roles: Ensure that your use of GenAI does not replace or materially impact work typically done by union-represented individuals, including actors, writers, or crew members, without proper approvals or agreements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How can I ensure confidentiality and data protection?&lt;/head&gt;
    &lt;p&gt;The use of tools covered by Netflix Enterprise Agreements provides an additional level of security to protect input data. Speak with your Netflix primary contact about available tools and the onboarding process. These tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prevent capture, training, or resale of your inputs&lt;/item&gt;
      &lt;item&gt;Protect sensitive inputs like scripts, production images, or talent visuals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even with secure tools, any use of sensitive information (e.g., talent likeness, unreleased footage, contracts) requires escalation to your Netflix contact.&lt;/p&gt;
    &lt;p&gt;When not using enterprise tools, ensure that any AI tools, plugins, or workflows you use do not train on inputs or outputs, as using the wrong license tier or missing pre-negotiated data terms could compromise confidentiality. You are responsible for reviewing the terms and conditions (T&amp;amp;Cs). Please check with your Netflix contact if you have any further questions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Are the considerations different for final output vs temporary media?&lt;/head&gt;
    &lt;p&gt;If created with GenAI, content that appears in the final cut—even in the background—can raise legal, copyright, or trust issues with the audience. That’s why we ask you to flag any GenAI-generated elements early, especially if they will be seen or heard on screen.&lt;/p&gt;
    &lt;p&gt;If your proposed use case includes visual, audio, or text elements generated by AI (e.g., posters, documents, signage, or news clippings), contact your Netflix representative as early as possible for legal guidance. These items may require rights clearance before they can be included in final deliverables.&lt;/p&gt;
    &lt;p&gt;Some GenAI-generated props or set pieces may be considered incidental, for example, a historical document shown briefly in the background and not referenced in the scene. However, if the element is prominent (e.g., a character reads it aloud or it contributes to the story), it must be treated with greater care.&lt;/p&gt;
    &lt;p&gt;In these cases, you can use GenAI to explore ideas or mockups. Still, the final version should involve meaningful human input and follow the legal review process through your Netflix contact.&lt;/p&gt;
    &lt;head rend="h2"&gt;What should we consider before using GenAI for talent enhancement?&lt;/head&gt;
    &lt;p&gt;There is a long tradition of digitally altering performances in post-production and VFX. However, the use of AI to modify or replicate a performer's likeness or voice introduces new legal, ethical, and reputational challenges. Therefore, obtaining consent when appropriate and exercising caution are crucial. Many talent enhancement use cases require legal review, so please plan accordingly. Here are some guidelines to consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If creating a Digital Replica (i.e., a generated output recognizable as the voice and/or likeness of an identifiable performer for the purpose of portraying them in photography or soundtrack, they did not perform), consent is required. No further consent is needed to use the Digital Replica if the performance output: (1) remains substantially as scripted, performed, or recorded (e.g. reshoots); (2) depicts activities incapable of being performed by a human for safety reasons; or (3) results in the performer being unrecognizable (e.g. wearing a mask).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Digital Alterations: Consent is generally required for digital alterations, except for those customarily done in the entertainment and film industry, such as:&lt;list rend="ul"&gt;&lt;item&gt;Alterations where the photography or soundtrack remains substantially as scripted, performed, or recorded.&lt;/item&gt;&lt;item&gt;Post-production changes for cosmetics, wardrobe, noise reduction, timing, continuity, pitch, clarity, and similar purposes.&lt;/item&gt;&lt;item&gt;Circumstances where dubbing or using a double is permitted under existing agreements.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Model Usage:&lt;list rend="ul"&gt;&lt;item&gt;Any models trained to perform talent enhancement manipulation should be used solely for the production in question and within the scope of work agreed upon with the talent.&lt;/item&gt;&lt;item&gt;Models must not be used to create an actor's performance in another production, pitch, or concept without the express consent of all parties involved.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; Quality Assurance:&lt;list rend="ul"&gt;&lt;item&gt;Perform early tests to ensure that the quality of the outputs is acceptable both creatively and technically, so as not to adversely affect the talent’s original performance.&lt;/item&gt;&lt;item&gt;Where applicable and practical, plan dedicated data capture sessions with the talent to ensure the best possible outcomes.&lt;/item&gt;&lt;item&gt;Avoid enhancements that could harm the actor’s reputation, dignity, or personal image.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By following these guidelines, you can navigate the complexities of using AI in creative workflows while respecting the rights and integrity of performers.&lt;/p&gt;
    &lt;head rend="h2"&gt;What if I’m using a custom workflow or working with a vendor who is?&lt;/head&gt;
    &lt;p&gt;For vendors: If you're delivering work to Netflix using a custom GenAI workflow built from multiple tools, each step in the pipeline must meet our standards for data protection, consent, and content integrity as outlined in this document.&lt;/p&gt;
    &lt;p&gt;For production partners: If you're hiring a vendor or AI studio, use this guidance as a framework to help assess how they manage data, creative control, and final outputs. If you are unsure whether the pipeline meets the expectations outlined in this guidance, seek guidance from your Netflix contact.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;head rend="h3"&gt;Proposed Use Case Matrix&lt;/head&gt;
    &lt;p&gt;We have provided a Proposed Use Case Matrix at the end of this guidance as a tool to triage your proposed use case quickly.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Proposed Use Case&lt;/cell&gt;
        &lt;cell&gt;Action&lt;/cell&gt;
        &lt;cell&gt;Rationale&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI for ideation only (moodboards, reference images)&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;Low risk, non-final, likely not needing escalation if guiding principles are followed.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI to generate background elements (e.g., signage, posters) that appear on camera&lt;/cell&gt;
        &lt;cell&gt;Use judgment: Incidental elements may be low risk, but if story-relevant, please escalate.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI to create final character designs or key visuals&lt;/cell&gt;
        &lt;cell&gt;Requires escalation as it could impact legal rights, audience perception, or union roles.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using GenAI for talent replication (re-ageing, or synthetic voices)&lt;/cell&gt;
        &lt;cell&gt;Requires escalation for consent and legal review.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Using unowned training data (e.g., celebrity faces, copyrighted art)&lt;/cell&gt;
        &lt;cell&gt;Needs escalation due to copyright and other rights risk.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Using Netflix's proprietary material&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Needs escalation for review if outside secure enterprise tools.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production"/><published>2025-11-10T19:28:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45880939</id><title>Spatial intelligence is AI’s next frontier</title><updated>2025-11-11T05:11:49.697277+00:00</updated><content/><link href="https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence"/><published>2025-11-10T21:07:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45881056</id><title>Zeroing in on Zero-Point Motion Inside a Crystal</title><updated>2025-11-11T05:11:49.391101+00:00</updated><content>&lt;doc fingerprint="51e8f1102095cff2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zeroing In on Zero-Point Motion Inside a Crystal&lt;/head&gt;
    &lt;p&gt;Zero-point motion is an irrepressible wiggling that becomes visible at temperatures near absolute zero. Evidence of this quantum motion has previously been uncovered for trapped particles and for small resonators. Now researchers studying nanocrystals have identified a low-temperature emission effect, which they show is related to zero-point motion within the crystal lattice [1]. The effect may be useful in cooling down nanocrystals to lower temperatures than previously possible.&lt;/p&gt;
    &lt;p&gt;Quantum physics often shows up at ultracold temperatures. Normally, as an object becomes colder, it moves less and less. However, the Heisenberg uncertainty principle dictates that the motion can’t go exactly to zero—there will always be fluctuations. These quantum fluctuations have been studied in microscopic systems, such as trapped atoms and molecules [2]. But they’ve also been observed in macroscopic objects. Previous experiments have identified signatures of zero-point motion in small mechanical resonators, such as drums and beams (see Viewpoint: Seeing the “Quantum” in Quantum Zero-Point Fluctuations).&lt;/p&gt;
    &lt;p&gt;Those investigations focused on the whole object as it moves back and forth like a vibrating spring. But there are also internal vibrations—the object’s atoms wiggle around in their lattice structure. Xiaoyong Wang from Nanjing University in China and his colleagues have detected a signature of zero-point motion in the lattice of a nanocrystal. “As far as we know, this is the first time that this effect has been seen in a solid material,” says team member Zhi-Gang Yu from Washington State University. “Even we were surprised to observe it.”&lt;/p&gt;
    &lt;p&gt;The observed signature appeared in photoluminescence measurements, in which an object is excited with a laser and then subsequently relaxes back to its initial state by emitting light. If the outgoing emission has a frequency that is higher than that of the laser, the process is called up-conversion. The opposite case—emission at lower frequency—is called down-conversion. Up-conversion is especially interesting to researchers because the object gives up some of its internal energy and thus becomes colder.&lt;/p&gt;
    &lt;p&gt;Wang and his colleagues explored up-conversion in nanocrystals made from a lead-halide perovskite (CSPbI3). This semiconductor has several exciton states, which are formed when an electron hops from the valence band to a higher-energy conduction band. When the electron subsequently falls back to the valence band, light is emitted at the telltale exciton frequency.&lt;/p&gt;
    &lt;p&gt;For their up-conversion study, the researchers targeted one of the perovskite’s exciton states by tuning their laser to a frequency just below the exciton frequency. In this case, the laser photons lack enough energy to excite electrons. However, the photons can get “help” from thermal fluctuations (or phonons) in the crystal. Indeed, at relatively high temperatures (above 10 K), Wang and his colleagues observed exciton emission from their nanocrystal—implying that phonons were supplying the additional energy needed for exciting the electrons.&lt;/p&gt;
    &lt;p&gt;This was all expected. The surprise came when the researchers lowered the temperature to 4 K. At this temperature, the phonons have insufficient energy to help the photons. “But we continued to see exciton emission,” Yu says. “It was a puzzle to us where the additional energy was coming from.” The answer was zero-point motion: The lattice continues to have energy in its quantum fluctuations.&lt;/p&gt;
    &lt;p&gt;Wang and his colleagues developed a model for how lattice vibrations at near zero temperature can affect the photoluminescence signal. They showed that zero-point motion creates an oscillating electric field within the material, which causes a “tilting” of the band structure. A similar effect happens when an external electric field is applied to a material. The tilting of the bands makes it easier for electrons to hop from the valence to the conduction band. The net result is that the zero-point motion supplies the additional energy needed for the up-conversion photoluminescence.&lt;/p&gt;
    &lt;p&gt;As mentioned, up-conversion removes energy from an object, so it might be possible to use the zero-point motion effect for cooling. Until now, it has been hard to cool objects below 4 K, as that is the limit set by helium-based cryostats. But if photoluminescence can harvest zero-point motion from a material, it could potentially reach sub-4-K temperatures. “These results open the door to a different approach to cooling at extreme temperatures,” Yu says.&lt;/p&gt;
    &lt;p&gt;“The primary novelty of this study is a departure from conventional descriptions of photoluminescence up-conversion,” says Masaru Kuno, a physical chemist at the University of Notre Dame in Indiana. The observed zero-point motion effect might offer a method for semiconductor optical refrigeration, which has been a long-standing holy grail in the laser-cooling community, Kuno says. But he says more thermodynamic measurements are needed to show that zero-point up-conversion can indeed lead to cooling of a nanocrystal. “Although the presented data are suggestive, further vetting is required to make the claims conclusive.”&lt;/p&gt;
    &lt;p&gt;–Michael Schirber&lt;/p&gt;
    &lt;p&gt;Michael Schirber is a Corresponding Editor for Physics Magazine based in Lyon, France.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;R. Duan et al., “Zero-point motion of polar optical phonons revealed by up-converted photoluminescence from a single perovskite nanocrystal at cryogenic temperatures,” Phys. Rev. Lett. 135, 196901 (2025).&lt;/item&gt;
      &lt;item&gt;B. Richard et al., “Imaging collective quantum fluctuations of the structure of a complex molecule,” Science 389, 650 (2025).&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://physics.aps.org/articles/v18/178"/><published>2025-11-10T21:17:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45881404</id><title>Linux in a Pixel Shader – A RISC-V Emulator for VRChat</title><updated>2025-11-11T05:11:49.009788+00:00</updated><content>&lt;doc fingerprint="bea919996d10b18a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Linux in a Pixel Shader - A RISC-V Emulator for VRChat&lt;/head&gt;25 August 2021, by _pi_&lt;p&gt;views&lt;/p&gt;&lt;p&gt;for comments see Hacker News, r/programming or r/vrchat&lt;/p&gt;&lt;head rend="h1"&gt;Intro&lt;/head&gt;&lt;p&gt;Sometimes you get hit with ideas for side-projects that sound absolutely plausible in your head. The idea grips you, your mind’s eye can practically visualize it already. And then reality strikes, and you realize how utterly insane this would be, and just how much work would need to go into it.&lt;/p&gt;&lt;p&gt;Usually these ideas appear, I enjoy dissecting them for a few days, and then I move on. But sometimes. Sometimes I decide to double down and get Linux running on my graphics card.&lt;/p&gt;&lt;p&gt;This is the story of how I made the &lt;code&gt;rvc&lt;/code&gt; RISC-V emulator within VRChat, and a deep-dive into the unusual techniques required to do it.&lt;/p&gt;&lt;p&gt;Here are some specs up front, if you’re satisfied with piecing the story together yourself:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;the code is on GitHub&lt;/item&gt;&lt;item&gt;emulated RISC-V &lt;code&gt;rv32ima/su+Zifencei+Zicsr&lt;/code&gt;instruction set&lt;/item&gt;&lt;item&gt;64 MiB of RAM minus CPU state is stored in a 2048x2048 pixel Integer-Format texture (128 bpp)&lt;/item&gt;&lt;item&gt;Unity Custom Render Texture with buffer-swapping allows encoding/decoding state between frames&lt;/item&gt;&lt;item&gt;a pixel shader is used for emulation since compute shaders and UAV are not supported in VRChat&lt;/item&gt;&lt;/list&gt;&lt;p&gt;(image credit: @pema99, thanks!)&lt;/p&gt;&lt;p&gt;Be warned that this post might be a bit rambly at times, as I try to recall the many pitfalls of writing this shader. Let’s hope it will at least turn out entertaining.&lt;/p&gt;&lt;head rend="h1"&gt;About the project&lt;/head&gt;&lt;p&gt;Around March 2021 I decided on writing an emulator capable of running a full Linux Kernel in VRChat. Due to the inherent limitations of that platform, the tool of choice had to be a shader. And after a few months of work, I’m now proud to present the worlds first (as far as I know) RISC-V CPU/SoC emulator in an HLSL pixel shader, capable of running up to 250 kHz (on a 2080 Ti) and booting Linux 5.13.5 with MMU support.&lt;/p&gt;&lt;p&gt;You can experience the result of all this for yourself by visiting this VRChat world. You will require a VRChat account and the corresponding client, both of which are free and give you access to a massive social platform full of user-created content such as this (no VR headset required!).&lt;/p&gt;&lt;p&gt;(a screenshot of the VRChat world and interface to use the emulator)&lt;/p&gt;&lt;p&gt;Here’s me in my Avatar again, standing in front of a kernel panic:&lt;/p&gt;&lt;p&gt;(image credit: @pema99 as well, I believe)&lt;/p&gt;&lt;p&gt;This picture was taken after I showed off my work at the community meetup, a self-organized weekly get-together of VRChat creators from all over. Here’s a recording of the live-stream where I presented it, it’s fun to see everyone’s reactions when I unveiled my big “secret project”:&lt;/p&gt;&lt;p&gt;Thanks to the team organizing the event for providing me with the opportunity!&lt;/p&gt;&lt;p&gt;The project has been featured on Adafruit, and my friend @fuopy over on twitter has posted video evidence as well:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Linux running in a shader! By _pi_! Check it out!!&lt;/p&gt;— fuopy (@fuopy) August 15, 2021&lt;lb/&gt;(5x speed of Linux running in a fragment shader emulating RISC-V) World link:https://t.co/jYnR8AZrQM&lt;lb/&gt;#vrchat #shaders pic.twitter.com/gqW6qSXLb2&lt;/quote&gt;&lt;p&gt;The response I’ve received in the days afterwards was tremendously positive. A seriously big thank you to everyone who asked for details, suggested improvements, shared the world, or simply shook their head in disbelieve towards me.&lt;/p&gt;&lt;head rend="h1"&gt;A Tribute to VRChat’s Creative Community&lt;/head&gt;&lt;p&gt;I am a big VR enthusiast - I was among the first to even try the original Vive here in Austria, and never looked back since. But it was only when a friend invited me into VRChat around August 2020, that I was introduced to the amazing creative-community surrounding that “game”/social platform.&lt;/p&gt;&lt;p&gt;I can’t speak for the visual side that much, though I dearly admire people who can summon 3D models and environments from scratch. Luckily, VRChat had recently released Udon, which allows world crafters to run custom code within their creations. This opened the door to the likes of myself, people who enjoy coding for fun and just want to push the envelope of what can be made.&lt;/p&gt;&lt;p&gt;Udon works super well for anything that doesn’t require high performance. The built-in visual programming combined with @MerlinVR’s UdonSharp (a C#-to-Udon compiler) are vital for making interactive worlds these days. People are using it to create incredible experiences, anything from multiplayer PvP games to petting zoos for ducks and dogs (and sometimes other players) - it is what got me interested in making content for VRChat in the first place.&lt;/p&gt;&lt;p&gt;(image credit: u/1029chris)&lt;/p&gt;&lt;p&gt;What really sparked my imagination however, was the discovery that you can embed your own, custom shaders within such a world. You can even put them on your Avatars! With shaders, the sky is the limit - and if you take even just a cursory look at what the community has done in VRChat, you realize that even that is only a limit meant to be broken.&lt;/p&gt;&lt;p&gt;I like to compare it to demoscening. Instead of cramming stuff into limited storage space, you work around the limitations the platform imposes on you - there’s so many things you can’t do, that part of the challenge is to figure out what you can do. Or as resident shader magician @cnlohr put it:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I love how VRC programmers have a way of looking at [a] wall of restrictions, then find a way of switching their existence to a zero dimensional object for a moment, then they appear on the other side of that wall.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Pictured above is “Treehouse in the Shade”, one of the most famous shader worlds, with an unfortunately tragic backstory. It is indeed a beautiful world I have spent a good amount of time in myself.&lt;/p&gt;&lt;p&gt;One of its co-creators, SCRN, has also written some less visual, but more technical VRChat projects, like this deep learning shader.&lt;/p&gt;&lt;p&gt;Since discovering VRChat and the creator community, I have made several of my own custom Avatars and Worlds. Some are finished, some left as demonstrations of what could be.&lt;/p&gt;&lt;p&gt;And then, back in February or March of 2021, this little spark of an idea popped up in my head - if I could run anything I want in a VRChat world, then why not go for the end-goal straight away: Let’s run a Linux kernel!&lt;/p&gt;&lt;head rend="h1"&gt;Compute Shaders in VRChat&lt;/head&gt;&lt;p&gt;Udon, as mentioned above, comes fairly close to regular coding. It’s semantically equivalent to writing Unity behaviour scripts, and can utilize most of what C# has to offer using UdonSharp.&lt;/p&gt;&lt;p&gt;However, to quote from UdonSharp’s documentation:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Udon can take on the order of 200x to 1000x longer to run a piece of code than the equivalent in normal C# depending on what you’re doing. […] Just 40 iterations of something can often be enough to visibly impact frame rate on a decent computer.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;With this performance constraint in mind, it becomes clear that CPU emulation is simply infeasible[0].&lt;/p&gt;&lt;p&gt;As far as I know there’s only two ways you can write custom code and have it execute in VRChat: Udon and shaders. This is important for security concerns of course, as Udon is a VM and shaders only run on the GPU. Since the former is out of the question, that leaves us with shaders.&lt;/p&gt;&lt;p&gt;But hold up, I hear you say, shaders are the little programs telling your GPU how to make things look good, right? How could you possibly emulate a CPU on that? And isn’t that kind of stupid?&lt;/p&gt;&lt;p&gt;Correct; By using compute shaders; And yes.&lt;/p&gt;&lt;p&gt;A “compute shader” doesn’t output an image, but simply data. It allows, in theory, to run highly parallel code on the GPU to compute any value. This is the principle behind CUDA, but is also used in games.&lt;/p&gt;&lt;p&gt;That sounds too easy though - and indeed it is, VRChat doesn’t allow you to use them in your creations. However, we can use some trickery here: By pointing Unity’s &lt;code&gt;Camera&lt;/code&gt; object at a quad rendered with our shader[1], and then assigning the output RenderTexture (the target buffer) to an input of our shader, we have essentially created a writable persistent state storage - the basic building block for a compute operation. Any pixel we write during the fragment (aka pixel) shader stage, we will be able to read back next frame.&lt;/p&gt;&lt;p&gt;(image credit: @pema99 and their fantastic treasure trove of forbidden VRChat shader knowledge)&lt;/p&gt;&lt;p&gt;Of course there’s a bunch of texture alignment and Unity trickery necessary to make it work, but people have been using this technique for a long time, and it turns out to be surprisingly realiable. You can even use it on an Avatar, I managed to implement a basic calculator with it once.&lt;/p&gt;&lt;p&gt;The issue with that is of course that a fragment shader runs in parallel for every pixel on the texture, and every instance can only output to one of them in the end. We’ll see how to (mostly) work around that later.&lt;/p&gt;&lt;p&gt;[0] I feel the need to point out that someone did, in fact, emulate a full CHIP-8 in Udon alone, and someone else tried their hand at a 6502 - both projects run very slowly however, certainly too slow to get an OS booted… ⏎&lt;/p&gt;&lt;p&gt;[1] or in this case we’re using a Custom Render Texture, which is basically the same thing, but more cursed^Wcompact ⏎&lt;/p&gt;&lt;head rend="h1"&gt;Excursion: RISC-V&lt;/head&gt;&lt;p&gt;If you want to create a system capable of running Linux, you need to decide on which supported CPU architecture you want to emulate. Take a look into the kernel source, and you will see that there are quite a bunch available.&lt;/p&gt;&lt;p&gt;For our purposes, it is important that the ISA is as simple as possible, not just because I’m lazy, but also because shaders have both theoretical and practical limitations when it comes to program size and complexity.&lt;/p&gt;&lt;p&gt;I decided on RISC-V, mostly because I liked their mission in general - an open source CPU architecture is something to be fond of, and I had been following efforts to port Linux software to it with great interest. These days you can run a full Debian on some hardware RISC-V boards.&lt;/p&gt;&lt;p&gt;It of course helps that all the specifications for RISC-V are published freely on the internet, and there are good reference implementations available (shout out to takahirox/riscv-rust).&lt;/p&gt;&lt;head rend="h1"&gt;Writing an emulator in &lt;del rend="overstrike"&gt;HLSL&lt;/del&gt; C&lt;/head&gt;&lt;p&gt;But back to making our emulator. First problem: Debugging a shader is hard. You can’t just attach GDB and single step, or even add &lt;code&gt;printf&lt;/code&gt; statements throughout your code. There are shader debugging tools out there, but they mostly focus on the visual side of things, and aren’t that helpful when you’re trying to run what is basically linear code.&lt;/p&gt;&lt;p&gt;Luckily for us, HLSL, the language we use to write shaders in Unity, is remarkably similar to regular C. And so the first iteration of the emulator was written in C.&lt;/p&gt;&lt;p&gt;Of course, some prep-work to translating already went into it. If you were to show the code of the C version to any seasoned C programmer, they would shudder and call an exorcist[2].&lt;/p&gt;&lt;code&gt;#define UART_GET1(x) ((cpu-&amp;gt;uart.rbr_thr_ier_iir &amp;gt;&amp;gt; SHIFT_##x) &amp;amp; 0xff)
#define UART_GET2(x) ((cpu-&amp;gt;uart.lcr_mcr_lsr_scr &amp;gt;&amp;gt; SHIFT_##x) &amp;amp; 0xff)

#define UART_SET1(x, val) cpu-&amp;gt;uart.rbr_thr_ier_iir = (cpu-&amp;gt;uart.rbr_thr_ier_iir &amp;amp; ~(0xff &amp;lt;&amp;lt; SHIFT_##x)) | (val &amp;lt;&amp;lt; SHIFT_##x)
#define UART_SET2(x, val) cpu-&amp;gt;uart.lcr_mcr_lsr_scr = (cpu-&amp;gt;uart.lcr_mcr_lsr_scr &amp;amp; ~(0xff &amp;lt;&amp;lt; SHIFT_##x)) | (val &amp;lt;&amp;lt; SHIFT_##x)
&lt;/code&gt;&lt;p&gt;(excerpt from the UART driver; packing logic for UART state since HLSL only has 32-bit variables)&lt;/p&gt;&lt;p&gt;After a few evenings spent coding, I got to a point where the riscv-tests suite passed for the integer base set (rv32i). The reason we’re going for 32-bit is because the version of DirectX that VRChat is based on only supports 32-bit integers on GPUs. In fact, at least historically speaking, even most GPU hardware has rather poor support for 64-bit integers.&lt;/p&gt;&lt;p&gt;I had figured out already that for Linux support I needed the ‘m’ (integer multiplication) and ‘a’ (atomics) extensions, as well as CSR and memory fencing support. Atomics are implemented as simple direct operations, as the system features only one hart (‘core’) anyway. CSRs are fully implemented, fencing is simply a no-op in C (in HLSL this becomes more important).&lt;/p&gt;&lt;p&gt;Multiplication is fully working in C, but not in HLSL - it requires the &lt;code&gt;mulh&lt;/code&gt; family of instructions, which give you the upper 32-bit of a 32 by 32 multiplication. This would require a single 64-bit multiply, which is not available for our shader target, so I decided to emulate it using double-precision floating-point numbers for now. This is stupid.[3]&lt;/p&gt;&lt;p&gt;The C version remains fully functional even now, and new features will still be implemented there first. It’s just so much easier to debug, plus compile times are magnitudes faster. The first porting effort happened even before it was able to boot Linux, I then gradually added support for more and more stuff by ping-ponging between the C and HLSL versions.&lt;/p&gt;&lt;p&gt;[2] It is important to note that this quality has translated to HLSL too, I know for a fact that I gave some shader devs nightmares. ⏎&lt;/p&gt;&lt;p&gt;[3] Microsoft, please, I beg you, why would you add an instruction to DXIL but not implement it in HLSL?! ⏎&lt;/p&gt;&lt;head rend="h1"&gt;What’s better than a Preprocessor?&lt;/head&gt;&lt;p&gt;That’s right, two of them!&lt;/p&gt;&lt;p&gt;Now that we have a C version up and running, one of the first challenges for porting it to a shader is state encoding and decoding. To make it more obvious why this is important, here is what our fragment shader will look like in the end (simplified):&lt;/p&gt;&lt;code&gt;uint4 frag(v2f i) : SV_Target {
    decode();
    if (_Init) {
        cpu_init();
    } else {
        for (uint i = 0; i &amp;lt; _TicksPerFrame; i++) {
            cpu_tick();
        }
    }
    return encode();
}
&lt;/code&gt;&lt;p&gt;The &lt;code&gt;decode()&lt;/code&gt; logic takes care of intializing a global static &lt;code&gt;cpu&lt;/code&gt; struct, &lt;code&gt;cpu_init()&lt;/code&gt; or &lt;code&gt;cpu_tick()&lt;/code&gt; update the state, and &lt;code&gt;encode()&lt;/code&gt; writes it back.&lt;/p&gt;&lt;p&gt;This will run for every pixel in our state storage texture in parallel, and it’s the encoder’s job to pick which piece of information to write out in the end. Each pixel (that is, conceptually, every instance of this function running), can output 4 color values (R, G, B and Alpha) with 32 bits each, summing up to a total of 128 bit, or, more practically, 4 variables of our cpu struct.&lt;/p&gt;&lt;p&gt;What we need now is a mapping of pixel position and which state it contains. This must be consistent between &lt;code&gt;encode&lt;/code&gt; and &lt;code&gt;decode&lt;/code&gt; of course.&lt;/p&gt;&lt;p&gt;&lt;code&gt;decode&lt;/code&gt; will consist of a bunch of statements akin to:&lt;/p&gt;&lt;code&gt;cpu.xreg1 = STATE_TEX[uint2(69, 0)].r;
&lt;/code&gt;&lt;p&gt;…which will index the state texture at coordinates &lt;code&gt;x=69,y=0&lt;/code&gt;, take the value stored in the red color channel and decode it as general purpose register (xreg) 1.&lt;/p&gt;&lt;p&gt;&lt;code&gt;encode&lt;/code&gt; looks like this:&lt;/p&gt;&lt;code&gt;uint pos_id = pos.x | (pos.y &amp;lt;&amp;lt; 16);
switch (pos_id) {
    // ...
    case 69:
        ret.r = cpu.xreg1;
        ret.g = cpu.xreg2;
        ret.b = cpu.xreg3;
        ret.a = cpu.xreg4;
        return ret;
    // ...
}
&lt;/code&gt;&lt;p&gt;Yep, it’s just one massive switch/case statement. I can immediately hear people complain about performance here, since branching in shaders is generally a bad idea™. But in this case, the impact is minimal because of several reasons:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;This is a switch statement, not a pure branch, which can actually compile down to a jump table for the final shader assembly, meaning the cost of the branch itself is constant&lt;/item&gt;&lt;item&gt;In accordance with the first reason, more branches are avoided by packing the x and y coordinates into the same value (this works since our state texture is small)&lt;/item&gt;&lt;item&gt;While it is true that branches which resolve to different values for neighboring pixels cause divergence (i.e. they break parallelism), this happens at the very end of our fragment shader, everything prior should still execute in a combined wavefront&lt;/item&gt;&lt;item&gt;If you’re concerned about this single switch/case statement, boy do I have bad news for you about the rest of this shader&lt;/item&gt;&lt;/list&gt;&lt;p&gt;My immediate thought when I decided on this approach was that these lines look very regular. It would be a shame to write them all by hand.&lt;/p&gt;&lt;p&gt;At first I figured I could come up with some C preprocessor macros (which thankfully are supported in HLSL) to do the job for me. However, it turns out such macros are really bad at anything procedural, like counting up indices - or coordinates. So instead, I decided on using a seperate, external preprocessor: perlpp.&lt;/p&gt;&lt;p&gt;In all honesty, this was probably a big mistake in terms of code readability. But it did work super well for this specific case, and with the full power of Perl 5 for code gen, I could do some neat stuff.&lt;/p&gt;&lt;p&gt;This is how a struct is now defined:&lt;/p&gt;&lt;code&gt;typedef struct {
    &amp;lt;? $s-&amp;gt;("uint", "mmu.mode"); ?&amp;gt;
    &amp;lt;? $s-&amp;gt;("uint", "mmu.ppn"); ?&amp;gt;
} mmu_state;
&lt;/code&gt;&lt;p&gt;(excerpt from types.h.pp)&lt;/p&gt;&lt;p&gt;Ignoring the syntax highlighter completely freaking out (which happens in vim and VS code too, never got around to fixing that…), this looks fairly readable in my opinion. The &lt;code&gt;$s&lt;/code&gt; perl function is defined to print a normal struct definition, but also store the name and type into a hash table. This can then later be used to auto-generate the &lt;code&gt;encode&lt;/code&gt; and &lt;code&gt;decode&lt;/code&gt; functions.&lt;/p&gt;&lt;p&gt;We also know the last address that contains any state, which we can use to place other, more linear data right after. In particular, this includes the CSR-area. CSRs are “Control and Status Registers”, which are 4096 32-bit registers that can be accessed using specific instructions (&lt;code&gt;csrw&lt;/code&gt;, &lt;code&gt;csrr&lt;/code&gt;, &lt;code&gt;csrc&lt;/code&gt;, etc.). They contain certain state about the CPU’s environment, like the active privilege mode, IRQ enablement or the MMU base pointer (&lt;code&gt;SATP&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;Aside from a few exceptions, these do not have special semantics on read and write, so it is enough to store them in a way that they can be indexed using their address. 4096 values means 1024 pixels, which we place 4-word aligned right after the last state-containing pixel. Reading now simply means calculating the offset from the CSR base (which is determined by perlpp at compile-time) and doing a texture tap. Writing happens via a similar caching mechanism as main memory, more on that later.&lt;/p&gt;&lt;p&gt;In addition to all that, perlpp makes it possible to use loops in code-gen. This is tremendously helpful for dynamic sizing of caches and structs with many values (for example the 32 general purpose registers).&lt;/p&gt;&lt;p&gt;One of the many problems with shader code is that HLSL doesn’t support arrays in a meaningful way. Pointer math (and thus array indexing) just isn’t a thing on the GPU, so writing to a non-constant index of an array is impossible. To work around this, there are several places in the code with patterns like this:&lt;/p&gt;&lt;code&gt;typedef struct {
    &amp;lt;? for my $i (0..31) {
        $s-&amp;gt;("uint", "xreg$i");
        print "\n    ";
    } ?&amp;gt;
    // ...
} cpu_t;

uint xreg(uint i) {
    #define C(x) case x: return cpu.xreg##x;
    if (i &amp;lt; 16) {
        [flatten]
        switch (i) {
            C(0) C(1) C(2) C(3)
            C(4) C(5) C(6) C(7)
            C(8) C(9) C(10) C(11)
            C(12) C(13) C(14) C(15)
        }
    } else {
        [flatten]
        switch (i) {
            C(16) C(17) C(18) C(19)
            C(20) C(21) C(22) C(23)
            C(24) C(25) C(26) C(27)
            C(28) C(29) C(30) C(31)
        }
    }
    return 0xdeadc0de;
    #undef C
}
&lt;/code&gt;&lt;p&gt;(excerpt from types.h.pp)&lt;/p&gt;&lt;p&gt;This function returns the content of general purpose register &lt;code&gt;i&lt;/code&gt;, but since the registers are not an array, it has to use a (&lt;code&gt;[flatten]&lt;/code&gt;ed) switch statement. The outer &lt;code&gt;if&lt;/code&gt; is an optimization, so each call only needs to go through 16 &lt;code&gt;movc&lt;/code&gt; instructions. &lt;code&gt;xreg&lt;/code&gt; is called a lot, and considered one of the “inlineable” functions - that’s why I’m not using a &lt;code&gt;[forcecase]&lt;/code&gt;-style jumptable here; but we’re getting way ahead of ourselves…&lt;/p&gt;&lt;head rend="h1"&gt;Instruction Decoding and DXSC Bugs&lt;/head&gt;&lt;p&gt;Now that we can keep the state stored, let’s take a look at what our fragment shader will do with it. From the simplified example above, &lt;code&gt;cpu_init&lt;/code&gt; is almost not worth talking about, simply zeroing the &lt;code&gt;cpu&lt;/code&gt; struct and setting some default values. &lt;code&gt;cpu_tick&lt;/code&gt; is where the magic happens, and our fairly normal, linear emulation code lives.&lt;/p&gt;&lt;p&gt;After reading an instruction from the current program counter (&lt;code&gt;pc&lt;/code&gt; register) address, we need to decode it. I decided to cheat a little for this:&lt;/p&gt;&lt;p&gt;I took a look at how the aforementioned riscv-rust emulator handles that part, and quickly realized that the &lt;code&gt;INSTRUCTIONS&lt;/code&gt; array in &lt;code&gt;src/cpu.rs&lt;/code&gt; contains basically all information required for parsing. So I did what any sane person would, copied the entire array into a text file, wrote a little perl script and had it auto-generate the decoding logic for me.&lt;/p&gt;&lt;p&gt;The end result looks something like this:&lt;/p&gt;&lt;code&gt;// definition:
DEF(add, FormatR, { // rv32i
    NOT_IMPL
})
DEF(addi, FormatI, { // rv32i
    NOT_IMPL
})
// ... and many more

// decoding:
ins_masked = ins_word &amp;amp; 0xfe00707f;
[forcecase]
switch (ins_masked) {
    RUN(add, 0x00000033, ins_FormatR)
    RUN(and, 0x00007033, ins_FormatR)
    RUN(div, 0x02004033, ins_FormatR)
    // ...
}
ins_masked = ins_word &amp;amp; 0x0000707f;
[forcecase]
switch (ins_masked) {
    RUN(addi, 0x00000013, ins_FormatI)
    RUN(andi, 0x00007013, ins_FormatI)
    RUN(beq, 0x00000063, ins_FormatB)
    // ...
}
// etc.pp.
&lt;/code&gt;&lt;p&gt;(actual definition is in emu.h)&lt;/p&gt;&lt;p&gt;This logic appears fairly optimal to me, in the end there are 9 different switch statements for slightly different opcode masks. I tried to sort these so that the most frequent instructions are first, though as I will discuss in the Inlining section below, this wasn’t always possible.&lt;/p&gt;&lt;p&gt;Observant readers (hi there!) will have noticed the &lt;code&gt;[forcecase]&lt;/code&gt; above the &lt;code&gt;switch&lt;/code&gt; keywords. This attribute is important for performance, as it forces the shader compiler to emit a jump table instead of a bunch of individual branches (or conditional moves with &lt;code&gt;[flatten]&lt;/code&gt;). Now, you may be asking yourself, “if this is so important for performance, why isn’t it the default?”. Truth is, I have absolutely no idea.&lt;/p&gt;&lt;p&gt;Of course there are situations where it’s actually faster to &lt;code&gt;[flatten]&lt;/code&gt;, as conditional moves can lead to less divergence, but I don’t get why &lt;code&gt;[branch]&lt;/code&gt;, i.e. “make it a bunch of if-statements” exists.&lt;/p&gt;&lt;p&gt;Thing is, there doesn’t seem to be a limit for jump tables. I have a lot of them in this shader. However, if you look at the code in emu.h, you will see that some of the statements use an explicit &lt;code&gt;[branch]&lt;/code&gt; - the explanation to this conundrum is as simple as it is dumb: If I put a &lt;code&gt;[forcecase]&lt;/code&gt; there, it crashes the shader compiler.&lt;/p&gt;&lt;p&gt;I don’t know why, I never got any useful log output aside from a generic “IPC error”, and I haven’t heard of anyone else experiencing this - then again, how often do you write shader code in this style…&lt;/p&gt;&lt;p&gt;&lt;code&gt;&amp;lt;rant&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;The point I want to make in this section, is that the DirectX Shader Compiler can be very dumb and I hate it and it should go hide in a corner and be ashamed. No offense to anyone working on it, but I’ve had instances where a whitespace change made the difference between the shader compiler crashing and a working output.&lt;/p&gt;&lt;p&gt;Even if it is working, writing such a large shader is not a joy. I get that register allocation is a hard problem, but if gcc and clang can compile the same program in C within milliseconds, why do I have to wait upwards of 10 minutes for the HLSL version to compile?!&lt;/p&gt;&lt;p&gt;Remember when I said there was a good reason for keeping the C version around…&lt;/p&gt;&lt;p&gt;&lt;code&gt;&amp;lt;/rant&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;head rend="h1"&gt;Main Memory&lt;/head&gt;&lt;p&gt;To run Linux, I figured we’d need at least 32 MiB of main memory (RAM), but let’s be safe and make that 64 - the performance difference will not be big, and there should be enough VRAM.&lt;/p&gt;&lt;p&gt;At first, the main performance concern was clock speed. That is, how many CPU cycles can run in one frame. Initially, I went with what seemed to be the simplest option available - let’s call this version 1:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;64 MiB of RAM require a 2048x2048 pixel texture at 128 bit per pixel&lt;/item&gt;&lt;item&gt;let’s reserve a small area in the top-left, say 128x128 for our CPU state&lt;/item&gt;&lt;item&gt;have the shader run one tick per execution and write the result out, treating RAM the same as state - i.e. we run the fragment shader for 2048x2048 = 4194304 pixels&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This is obviously rather inefficient, and would ultimately result in a clock speed of 1 cycle per frame. We can somewhat tweak this by running the CRT (Custom Render Texture, or equivalent camera loop with Udon) multiple times per frame, but this incurs the hefty cost of double-buffering (and thus swapping) the entire 64 MiB texture every time. Instead, let’s leave this concept behind a bit and focus on version 2:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;same 2048x2048 texture with 128x128 state area as before&lt;/item&gt;&lt;item&gt;shader split into two passes: &lt;code&gt;CPUTick&lt;/code&gt;does a CPU cycle but writes to a memory cache area within the 128x128 pixels, and&lt;code&gt;Commit&lt;/code&gt;writes that cache back to RAM&lt;/item&gt;&lt;item&gt;the Custom Render Texture is set up so it renders multiple times, first a bunch of &lt;code&gt;CPUTick&lt;/code&gt;passes on just the 128x128 area, then it finishes up with a single full-texture&lt;code&gt;Commit&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This implementation already gets us a lot further. On the bright side, Unity is smart enough to realize that when you only update the 128 by 128 area, it also only needs to buffer swap this part of the texture. And since this area is fairly small, it fits entirely within the L2 cache of almost any modern GPU, making the swapping process very cheap. On the downside, this now means we need a seperate memory cache - no problem though, we have enough space left over in the state area to hold all the data we want.&lt;/p&gt;&lt;p&gt;Version 2 got up to around 35-40 kHz in-game, pretty decent, but still not fast enough for my liking. Enter the current version 3:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;same area splitting as before, keep the two-pass design&lt;/item&gt;&lt;item&gt;instead of multiple passes in the CRT, simply loop directly in the shader and run multiple ticks at once&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This option has the least non-compute overhead of all the above. There’s only two buffer swaps, and one of them is for the small area. This caching strategy (I call it the “L1 write cache”) is what makes this shader fast enough to run Linux. 300 kHz is not out of the question on a high-end GPU, my 2080 Ti regularly pushes over 200.&lt;/p&gt;&lt;p&gt;(image credit: @d4rkpl4y3r_vr, who had the patience to show that the emulator can calculate pi to 1234 places)&lt;/p&gt;&lt;p&gt;However, there is now a glaring issue: If we run multiple ticks per iteration, we cannot use the 128x128 px state area as a cache anymore. In a fragment shader, we can only write output at the end of execution, but memory writes can happen anytime during emulation, and must be architecturally visible immediately - that is, in RISC-V, a write followed by a read to the same address must always return the previously written value.[4]&lt;/p&gt;&lt;p&gt;With this in mind, the L1 cache only has one place to live: The GPU’s register file. I’ve been told modern architectures should support up to 64 kB of instance state (I suppose it can evict to VRAM?), but in practice the limit you’re going to hit is once again the shader compiler. Use too many variables, and we’re back at waiting 15 minutes for an “IPC error”.&lt;/p&gt;&lt;p&gt;At the time of writing, L1 is a two-way set associative cache with 16 sets and 5 words per line[5]. This comes out to 320 bytes per frame - with the current setup, a good GPU can push up to 4000 instructions per frame, and with &lt;code&gt;sw&lt;/code&gt; (“store word”) being one of them, this cache will fill up in as little as 80. If the cache is full, the CPU stalls until the next &lt;code&gt;Commit&lt;/code&gt;. A little trick is to double up the &lt;code&gt;Commit&lt;/code&gt; passes and do two &lt;code&gt;CPUTick&lt;/code&gt;s as well - that way we can at least get twice the throughput, while only incuring a moderate performance hit for buffer swapping the full 64 MiB twice.&lt;/p&gt;&lt;p&gt;This caching strategy is the tradeoff I made for clock speed - memory write performance absolutely sucks. But it’s decidedly faster than limiting the clockspeed itself, the “real-world” performance is certainly better this way.&lt;/p&gt;&lt;p&gt;A neat little side-effect of storing main memory in a texture, is that you can display it visually! Below is a (jpeg-compressed and downsized) picture of the main memory with a fully booted linux kernel.&lt;/p&gt;&lt;p&gt;Notice the two large zeroed (black) areas at the top (128px state area + OpenSBI and reserved bootloader memory), and the fascinating blue memory pattern at the bottom (that’s the high addresses, I believe the regular stripes are due to early memory poisoning of the SLAB/SLUB allocator in the kernel, feel free to correct me on this):&lt;/p&gt;&lt;p&gt;The texture is also on display in the VRChat world, where you can take a closer look during execution yourself. It’s quite fun to see memory framention visibly become worse, the more userspace programs are started.&lt;/p&gt;&lt;p&gt;As an aside, you might be wondering why I called the cache “L1”, as in “Layer 1”. The reason is that in the future I’m planning on extending this concept to become a sort of hybrid between version 2 and 3. The idea is that there will be multiple ticks before a commit, each one being followed by a &lt;code&gt;Writeback&lt;/code&gt; pass, that still only operates on the 128x128 texture (for cheap double-buffering) and flushes the L1 cache to a page-based L2 variant.&lt;/p&gt;&lt;p&gt;The tricky part here is that this has to go away from being set- or fully-associated, as both of these variants would not only incur massive performance penalties for lots of branching, but also for the repeated texture taps (as I can’t allocate any more registers for the L2 without crashing the compiler again). Instead, I’m planning on having only a few registers allocated that contain page base addresses that then point to a linear cache area in the state texture. This is somewhat hard to keep coherent though, and requires a new concept of stalling only until a &lt;code&gt;Writeback&lt;/code&gt;, so I couldn’t get it done in time for the initial presentation.&lt;/p&gt;&lt;p&gt;[4] an exception to this rule is instruction loading, which only needs to be consistent after a &lt;code&gt;fencei&lt;/code&gt; instruction - we can make use of this by omitting the somewhat expensive cache-load logic for memory reads and just tap the texture directly, simply stalling the CPU on &lt;code&gt;fencei&lt;/code&gt; until the next &lt;code&gt;Commit&lt;/code&gt; since it is called very infrequently ⏎&lt;/p&gt;&lt;p&gt;[5] another benefit of perlpp: all of these values are configurable in a single “header” file ⏎&lt;/p&gt;&lt;head rend="h1"&gt;A Note on Inlining&lt;/head&gt;&lt;p&gt;HLSL has the peculiarity that there are no function calls. All functions are inlined at the call site[6], if you call a function four times, it will be included four times in the output assembly. This is of course recursive, so a function that calls other functions will also inline those at every callsite.&lt;/p&gt;&lt;p&gt;This doesn’t sound like a big issue, but it turns out it actually is - one of the biggest performance tricks I learned during development of the emulator, is that avoiding multiple callsites can improve performance quite a bit. I’m not 100% sure why that is, but I would assume it has to with locality/recency in the L1i cache of the GPU. So less code = less assembly = less thrashing in the instruction cache, and thus better performance.&lt;/p&gt;&lt;p&gt;Additionally, how could it be any different, it also helps with actually getting the thing to compile. More inlines means more code to translate, and the shader compiler really hates code.&lt;/p&gt;&lt;p&gt;This gives rise to some awkward optimizations, that would produce the opposite result almost anywhere else. The main example of this is coalescing memory reads and writes:&lt;/p&gt;&lt;p&gt;The C code simply calls &lt;code&gt;mem_get_word&lt;/code&gt; in the execution path of each instruction. This works, because the function call is cheap. But if it were to be inlined in every instruction that reads from memory, it would slow down the shader a lot. Instead, we do it preventatively - before even executing the instruction-specific code, check by way of the opcode if the instruction might need to read a value from memory. If that is the case, figure out where from (which is different for regular &lt;code&gt;lX&lt;/code&gt; and atomic ops), and load the memory once. This way, &lt;code&gt;mem_get_word&lt;/code&gt; only needs to be inlined once for the entire instruction emulation path.&lt;/p&gt;&lt;p&gt;We also handle unaligned memory reads creatively. Off the top of my head, this would be the obvious solution:&lt;/p&gt;&lt;code&gt;off = (read_addr &amp;amp; 3) * 8;
val = mem_get_word(read_addr &amp;amp; (~3)) &amp;gt;&amp;gt; off;
val |= mem_get_word(read_addr &amp;amp; (~3) + 4) &amp;lt;&amp;lt; (32 - off);
&lt;/code&gt;&lt;p&gt;…but instead, we use the one tool HLSL gives us to avoid multiple inlining, loops with the &lt;code&gt;[loop]&lt;/code&gt; attribute that prevents them from being unrolled:&lt;/p&gt;&lt;code&gt;uint w1 = 0, w2 = 0;
[loop]
for (uint ui = 0; ui &amp;lt; ((read_addr &amp;amp; 0x3) ? 2 : 1); ui++) {
    uint tmp = mem_get_word((read_addr &amp;amp; (~0x3)) + 0x4 * ui);
    [flatten]
    if (ui) { w2 = tmp; }
    else { w1 = tmp; }
}
val = w1 &amp;gt;&amp;gt; ((do_mem_read &amp;amp; 0x3) * 8);
val |= w2 &amp;lt;&amp;lt; ((4 - (do_mem_read &amp;amp; 0x3)) * 8);
&lt;/code&gt;&lt;p&gt;There are several places in the code that seemingly make no sense, but are actually intentionally written with the goal of avoiding inlining. Try to keep that in mind, if you dare read through the source yourself.&lt;/p&gt;&lt;p&gt;[6] there is a &lt;code&gt;[call]&lt;/code&gt; attribute for switch/case, but once again I don’t know why you wouldn’t just use &lt;code&gt;[forcecase]&lt;/code&gt;, in my testing it unconditionally made performance worse - it does however actually compile to a jump and return, meaning the capability must exist in shader assembly, but even functions with &lt;code&gt;[noinline]&lt;/code&gt; (which is a valid attribute) are always inlined… ⏎&lt;/p&gt;&lt;head rend="h1"&gt;Excursion: Debug View&lt;/head&gt;&lt;p&gt;For debugging purposes, and later on also actual data extraction, we need a way to communicate values from our shader to the user. And ideally not just the enduser, but also Udon, where we can further process the data on the CPU. Udon does not expose &lt;code&gt;Graphics.Blit&lt;/code&gt;, which is the usual Unity way of reading shader output to the CPU, so we need some trickery again.&lt;/p&gt;&lt;p&gt;The only way currently to get pixel data from a shader into Udon is via the &lt;code&gt;OnPostRender&lt;/code&gt; callback. If the behaviour is on a &lt;code&gt;Camera&lt;/code&gt; object, this will be called once per frame. Within it, &lt;code&gt;Buffer.ReadPixels&lt;/code&gt; can be used to retrieve the actual pixel data into a Read/Write enabled static &lt;code&gt;Texture2D&lt;/code&gt; object. The individual pixels can then be accessed as &lt;code&gt;Color&lt;/code&gt; structs. But not so fast, a Unity &lt;code&gt;Color&lt;/code&gt; contains four float values at 8-bit precision, and alpha is premultiplied - so simply reading our state/RAM texture which uses Integer-Format with 128 bpp is out of the question.&lt;/p&gt;&lt;p&gt;Instead, we write a secondary shader, a “helper” shader if you so will, that stretches the state texture (and only the state part, not the entire RAM) onto a seperate, floating-point enabled texture 6-times the width (and only using the 3 base color channels). Doing some “clever” floating-point math and bit-twiddling allows us to finally recover the original value.&lt;/p&gt;&lt;code&gt;#define PACK_MASK 0xFF
#define PACK_SHIFT 8
void pack_uint4(in uint4 data, out float3 result[6]) {
    result[0] = (data.rgb &amp;amp; PACK_MASK) / 255.0f;
    result[1] = ((data.rgb &amp;gt;&amp;gt; PACK_SHIFT) &amp;amp; PACK_MASK) / 255.0f;
    result[2] = ((data.rgb &amp;gt;&amp;gt; (PACK_SHIFT*2)) &amp;amp; PACK_MASK) / 255.0f;
    result[3] = ((data.rgb &amp;gt;&amp;gt; (PACK_SHIFT*3)) &amp;amp; PACK_MASK) / 255.0f;
    result[4].r = (data.a &amp;amp; PACK_MASK) / 255.0f;
    result[4].g = ((data.a &amp;gt;&amp;gt; PACK_SHIFT) &amp;amp; PACK_MASK) / 255.0f;
    result[4].b = ((data.a &amp;gt;&amp;gt; (PACK_SHIFT*2)) &amp;amp; PACK_MASK) / 255.0f;
    result[5].r = ((data.a &amp;gt;&amp;gt; (PACK_SHIFT*3)) &amp;amp; PACK_MASK) / 255.0f;
    result[5].gb = 0;
}
#undef PACK_SHIFT
#undef PACK_MASK
&lt;/code&gt;&lt;p&gt;(excerpt from helpers.cginc, for encoding)&lt;/p&gt;&lt;code&gt;private const float MULT = 255.0f;
private const float ADD = 0.5f;
private uint decodePackedData(int x, int y, int c)
{
    Color[] col = new Color[6] {
        Buffer.GetPixel(x, y),
        Buffer.GetPixel(x + 128, y),
        Buffer.GetPixel(x + 128*2, y),
        Buffer.GetPixel(x + 128*3, y),
        Buffer.GetPixel(x + 128*4, y),
        Buffer.GetPixel(x + 128*5, y)
    };

    switch (c) {
        case 0:
            return (
                (uint)(col[0].r * MULT + ADD) |
                ((uint)(col[1].r * MULT + ADD) &amp;lt;&amp;lt; 8) |
                ((uint)(col[2].r * MULT + ADD) &amp;lt;&amp;lt; 16) |
                ((uint)(col[3].r * MULT + ADD) &amp;lt;&amp;lt; 24)
            );
        // ...
    }
}
&lt;/code&gt;&lt;p&gt;(excerpt from NixDebug.cs, for decoding - this file is in desperate need of a cleanup :/)&lt;/p&gt;&lt;p&gt;(the debug display as seen in-game, the spherical buttons allow for single-stepping)&lt;/p&gt;&lt;p&gt;This is fairly expensive, especially since it’s running in Udon, so we limit the rendering of this &lt;code&gt;Camera&lt;/code&gt; to once every 15 frames or so. Certainly not pretty, but works well enough for debugging (and unfortunately also some device state).&lt;/p&gt;&lt;head rend="h1"&gt;MMU and Devices&lt;/head&gt;&lt;p&gt;The emulator includes a full SV32 memory management unit. I didn’t even plan on adding this at first, but it turns out Linux only supports NOMMU mode on 64-bit RISC-V. I suppose this project is a fairly niche use-case…&lt;/p&gt;&lt;p&gt;Fortunately, this ended up being easier than expected. I’m not sure what it was about the MMU, but it sounded quite difficult at first, only to turn out to be a straightforward implementation of the paging algorithm described in the RISC-V privileged spec.&lt;/p&gt;&lt;p&gt;Once again, the two-layer pagewalk is performed with avoiding inlining in mind. The &lt;code&gt;load_page&lt;/code&gt; function only has one callsite, with the recursive walk taken care of by a loop. I felt that the MMU logic was optimized enough that I could get away with using &lt;code&gt;mem_get_cached_or_tex&lt;/code&gt;, which includes the cache logic - this means that page tables are fully coherent, and &lt;code&gt;sfence.vma&lt;/code&gt; (what would be a TLB flush on x86) can be a no-op.&lt;/p&gt;&lt;p&gt;There are two devices on the emulated SoC that can issue interrupts - the CLINT timer and the UART. Additionally, software interrupts into both machine and supervisor mode are supported as well. All of this is covered under the umbrella term “trap handling”, which deals with IRQs and exceptions. Most of this logic is borrowed fairly directly from riscv-rust again, with the exception being that PLIC and CLINT are handled all at once.[7]&lt;/p&gt;&lt;p&gt;The timer’s frequency is in sync with the CPU clock, i.e. one clock cycle equals one timer tick. That being said, this is not what our device tree is communicating to Linux. The frequency given as &lt;code&gt;timebase-frequency = &amp;lt;0x1000000&amp;gt;;&lt;/code&gt; ranges in the MHz, obviously way faster than what it actually runs at. I’m not entirely certain why that is necessary, but if I set this to a more natural 200 kHz-ish, Linux schedules it’s own timer interrupt so frequently as to completely stall the boot process.&lt;/p&gt;&lt;p&gt;The UART is a bit more tricky: While the emulator-facing side is a fairly simple 8250/16550a serial port, it also needs to communicate data out to the user and read inputs.&lt;/p&gt;&lt;p&gt;Output is currently handled via a ring-buffer that is shared with Udon using the same mechanism as the Debug View mentioned above. Udon then simply puts the characters to a Unity UI &lt;code&gt;Canvas&lt;/code&gt;. I plan on replacing this with a fully shader-based terminal renderer in the future, this would also allow me to properly implement ANSI/VT100 escape codes - &lt;code&gt;vim&lt;/code&gt; vs &lt;code&gt;emacs&lt;/code&gt; live debate in VRChat anyone?&lt;/p&gt;&lt;p&gt;(a bug in the UART output causing me to boot the knockoff “ninux” built with “GNU Bnnutils”)&lt;/p&gt;&lt;p&gt;Input is rather simple too, using a regular shader parameter to pass the input ASCII character from Udon (specifically a modified version of @FairlySadPanda’s Keyboard script) to the shader. It also needs the Debug View mechanism however, since the guest running in the emulator might not acknowledge the received character, in which case it will remain in the buffer and &lt;code&gt;RBR&lt;/code&gt; will stay set. This of course also limits input speed to how often we decide to render the performance-hungry debug &lt;code&gt;Camera&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;There is currently no disk emulated, since VRChat doesn’t support world persistancy at the moment anyway. Linux boots entirely from RAM, the initramfs stays mounted as the rootfs.&lt;/p&gt;&lt;p&gt;[7] Side-note that I mention for no particular reason and definitely didn’t spend a full day tracking down a related bug on: Did you know that bitwise negate in Rust is &lt;code&gt;!&lt;/code&gt;, which, if copied to C, will compile successfully and without warning, but actually perform a boolean negate? Now you do! &lt;code&gt;~&lt;/code&gt; is what you need, obviously. ⏎&lt;/p&gt;&lt;head rend="h1"&gt;Payloads&lt;/head&gt;&lt;p&gt;Speaking of the initramfs, compiling software to run on the emulator is suprisingly straightforward. I used Buildroot to generate a riscv32 GNU toolchain for cross-compiling on my host, and also to generate a cpio image containing BusyBox, QuickJS and my little &lt;code&gt;init&lt;/code&gt; script to print a neat ASCII art logo.&lt;/p&gt;&lt;p&gt;The kernel itself is version 5.13.5, which was the latest stable before the presentation. It runs completely stock with an &lt;code&gt;allnoconfig&lt;/code&gt; and only configuring what’s absolutely necessary, but I did patch in a few tweaks. At the moment, these consist of:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Not poisoning boot memory, as that takes too long and is mostly for security (which, as you might have guessed, does not have the highest priority in this project)&lt;/item&gt;&lt;item&gt;Printing more information during initramfs loading (as otherwise it just looks like it got stuck for a while; did I mention memory write/copy is really slow?)&lt;/item&gt;&lt;item&gt;Currently disabled, but for future use a paravirtualized &lt;code&gt;memcpy&lt;/code&gt;implementation, that uses custom CSR registers to copy memory in the&lt;code&gt;Commit&lt;/code&gt;stage instead of going through L1 cache&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I have a prototype of the last point working now, but before the presentation some last-minute bugs prevented me from showing it off.&lt;/p&gt;&lt;p&gt;Of course, Linux is not the only thing that runs on the emulator. The GitHub has some instructions on how to build other payloads. Aside from a very basic bare-metal C program to test functionality, the two more interesting ones are Micropython and Rust-Test.&lt;/p&gt;&lt;p&gt;The first one, Micropython, provides a Python 3 REPL where you can experiment with writing your own code live in VRChat. The benefit of it being that it boots way quicker than Linux. I had to add a riscv32 port myself, based on the existing riscv64 version, it certainly isn’t the cleanest but it boots and does what it’s supposed to showcase.&lt;/p&gt;&lt;p&gt;(image credit: @pema99, a sierpiński triangle rendered with Micropython)&lt;/p&gt;&lt;p&gt;The Rust-Test or rust_payload program is my experiment in building native, &lt;code&gt;no-std&lt;/code&gt; Rust for use on the emulator. I needed to patch the &lt;code&gt;rustc&lt;/code&gt; compiler to not emit compressed instructions (which are not implemented, as decoding them would only take more assembly-space and RAM is actually the one resource we have more than enough of). This was among the first things to run successfully on the emulator!&lt;/p&gt;&lt;p&gt;This one gave me some interesting ideas for potential future use-cases as well. Imagine having an interface to call Unity functions from the emulator (e.g. via the previously mentioned debug interface), and then writing your world scripts in Rust. Probably too slow to be useful, but an intriguing concept.&lt;/p&gt;&lt;p&gt;And just to have it noted, all payloads (aside from the bare-metal test) run on top of OpenSBI, which, if you’re coming from x86 you can think of as sort of a “BIOS” or “firmware”. It runs in machine mode, handles basic initialization tasks and prepares the environment for the stage-2 payload. It also provides some functionality to the next stage running in supervisor mode, most importantly timer scheduling (which requires machine privileges) and a basic UART driver (really useful in the Rust-Demo, as we can print to the console easily using it).&lt;/p&gt;&lt;p&gt;(me standing in front of OpenSBI in VR for the first time)&lt;/p&gt;&lt;head rend="h1"&gt;The End?&lt;/head&gt;&lt;p&gt;This was a big project for me, spanning over several months and bringing together many areas of knowledge I had aquired so far.&lt;/p&gt;&lt;p&gt;During development, I kept this project a secret for the longest time - I just love the thrill and payoff that comes with presenting something that absolutely nobody expected to see. Making this in VRChat has not only provided an additional challenge to overcome, but also brought with it the potential of demonstrating this live, in front of an audience, and then continue to chat with talented creators from all over. I thank everyone that answered my sometimes cryptic requests on Discord and in VRChat itself, and also everyone that didn’t ask what I was even working on when I frustratedly vented about something (probably the shader compiler) again.&lt;/p&gt;&lt;p&gt;This project has given me the opportunity to learn about the inner workings of RISC-V, it taught me more about the Linux Kernel’s boot process and hardware interface than most people would want to know, and it gave me an excuse to dive deeper and deeper into the magical world of shaders.&lt;/p&gt;&lt;p&gt;Once again, feel free to read the full code on GitHub, or check out the world for yourself in VRChat - I’m always happy to chat in person, if you manage to catch me there :)&lt;/p&gt;&lt;p&gt;I’ll probably continue working on this project for a while, I still have a bunch of ideas at the ready. Maybe, just maybe, I’ll even write more blog posts about it.&lt;/p&gt;&lt;p&gt;So until next time,&lt;/p&gt;&lt;p&gt;~ _pi_&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.pimaker.at/texts/rvc1/"/><published>2025-11-10T21:50:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45881568</id><title>High-performance 2D graphics rendering on the CPU using sparse strips [pdf]</title><updated>2025-11-11T05:11:48.704720+00:00</updated><content/><link href="https://github.com/LaurenzV/master-thesis/blob/main/main.pdf"/><published>2025-11-10T22:05:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45882837</id><title>Warren Buffett's final shareholder letter [pdf]</title><updated>2025-11-11T05:11:48.365905+00:00</updated><content/><link href="https://berkshirehathaway.com/news/nov1025.pdf"/><published>2025-11-11T00:51:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45883124</id><title>I hate screenshots of text</title><updated>2025-11-11T05:11:48.126092+00:00</updated><content/><link href="https://parkscomputing.com/page/i-hate-screenshots-of-text"/><published>2025-11-11T01:36:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45883788</id><title>The 'Toy Story' You Remember</title><updated>2025-11-11T05:11:48.018166+00:00</updated><content/><link href="https://animationobsessive.substack.com/p/the-toy-story-you-remember"/><published>2025-11-11T03:17:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45883827</id><title>DEC Mini – computer inspired by one of the loveliest retro computers of the 80s</title><updated>2025-11-11T05:11:47.617754+00:00</updated><content>&lt;doc fingerprint="90eb3a4a57ff0024"&gt;
  &lt;main&gt;
    &lt;p&gt;The long-awaited new DEC Mini is the latest iteration of the DEC1 business computers that set an industry standard starting with the VT-series terminals in the 70s.&lt;/p&gt;
    &lt;p&gt;Conceived to satisfy the most demanding users both at the office and at home, the DEC Mini owes its power to multiple state-of-the-art parallel processors, is fully IBM-PC compatible, offers extreme upgradability and packs unprecedented high-end specifications. With a small form factor that seamlessly fits in your desktop, the DEC Mini truly is destined to revolutionize the microcomputer industry of the decade:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 4 processors at 1.500 Mhz 2&lt;/item&gt;
      &lt;item&gt;Up to 8.192 Megabytes of RAM 2&lt;/item&gt;
      &lt;item&gt;Low-noise hard disk with up to 65.536 Megabytes 2&lt;/item&gt;
      &lt;item&gt;64 bit architecture, retrocompatible with 8, 16 and 32 bit systems 3&lt;/item&gt;
      &lt;item&gt;3½ inch. High Density 1.44Mb disk drive&lt;/item&gt;
      &lt;item&gt;Full DOS, Windows and Macintosh compatibility 3&lt;/item&gt;
      &lt;item&gt;SVGA color display 1024x768. VGA/EGA/CGA/Hercules compatible&lt;/item&gt;
      &lt;item&gt;Integrated wide range stereo sound, Sound Blaster 16 fully compatible&lt;/item&gt;
      &lt;item&gt;Integrated high quality keyboard&lt;/item&gt;
      &lt;item&gt;Affordable price&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Choose between a wide range of motherboards&lt;/head&gt;
    &lt;p&gt;The DEC Mini can be fitted with most of the currently existing SOC computer boards including the Raspberry Pi, LattePanda, Udoo Volt, Banana Pi and much more, allowing for the widest range of computing and performance choices in the industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extreme compatibility&lt;/head&gt;
    &lt;p&gt;Thanks to a complete support of the new USB connectivity industry standard, the DEC Mini is compatible with the whole range of currently available USB peripherals, including mice, dot matrix printers and high speed modems. The DEC Mini is capable of running Linux, DOS, Windows and can even replace your existing Commodore 64 workstation3.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extreme connectivity&lt;/head&gt;
    &lt;p&gt;Built in industry standard RJ-45 socket allows the DEC Mini to connect to most modern local area networks at up to 1.073.741.824 baud 2. By additionally supporting the upcoming Wi-Fi and Bluetooth technologies for wire-less connections, your DEC Mini is guaranteed to be future-ready, and will be for years to come.&lt;/p&gt;
    &lt;head rend="h2"&gt;Colorful choices&lt;/head&gt;
    &lt;p&gt;Choose the classic color combination, or let the DEC Mini fit your life style with the Cherry gum pink, the Springfield family blue, the limited edition Tropper black, the Surfer sunset orange or the Gentle hacker purple colors.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://decmini.tin.cat/"/><published>2025-11-11T03:25:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45883995</id><title>Hiring a developer as a small indie studio (in 2025)</title><updated>2025-11-11T05:11:47.435066+00:00</updated><content>&lt;doc fingerprint="221893132c65c5a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Hiring a developer as a small indie studio (in 2025)&lt;/head&gt;
    &lt;p&gt;By Victor Hurdugaci on Nov 10, 2025&lt;/p&gt;
    &lt;p&gt;When I was at Electronic Arts or Microsoft, hiring was a multi-tier, bureaucratic process. There was a dedicated chain for budget approval, posting approval, initial filtering, screening, and offer negotiation. As a hiring manager, I only showed up for the final interview. Even at PlayerWON, which was only about 100 people, a lot of that workload was still handed off.&lt;/p&gt;
    &lt;p&gt;But back then, I was dealing with maybe a dozen applicants max. Hiring in 2025 is extremely challenging compared to any other year. From a company perspective, thereâs a lack of funds, and even as an unknown indie studio, we get hundreds of applicants. And from a candidate perspective, there are not enough jobs.&lt;/p&gt;
    &lt;p&gt;We recently hired a software developer for Few Shall Return. At the time of posting, Ballard Games was just three people. The three of us covered every single step of the hiring funnel.&lt;/p&gt;
    &lt;p&gt;We posted the job on our social media, the Seattle Indies Discord, and Work with Indies. Most of the traffic came from Work with Indies â no formal connection, but the results were great! –. Our listing went live at 11:30 AM on October 15th, and we had to ask them to shut it down by 6:30 PM on October 17th because we had too many candidates. In the end, we collected 159 applications.&lt;/p&gt;
    &lt;p&gt;Remember, we don’t have any fancy tracking software. Every single application hits our email inbox and we review them manually.&lt;/p&gt;
    &lt;head rend="h3"&gt;So, how do we manage that volume with limited time and a small team?&lt;/head&gt;
    &lt;p&gt;Our most valuable resource right now is time, and we have to be hyper-efficient.&lt;/p&gt;
    &lt;p&gt;For hiring, we usually sift through everyone twice. The first pass is just to get a feel for the field and remove any application that is not relevant for the role. The second pass is where we actually try to give everyone a fair look. We do this a few days after the job closes, but if anyone submits too late, we probably won’t review them unless the initial pool was completely dry. Unfortunately, this time, we had 46 late applicants we didn’t even look at. This initial triage is the toughest part; we have to reject people who might be great just because we can’t physically talk to everyone.&lt;/p&gt;
    &lt;p&gt;If we see potential, the first step is always asking the candidate upfront for their expected salary, availability, and whether they want full-time or part-time. Since we are focused on efficiency, we need to respect people’s time as much as our own. Most candidates appreciate it; for example, it immediately filtered out a very qualified candidate whose salary ask was 4 times our budget.&lt;/p&gt;
    &lt;p&gt;Itâs important to say this: most indie studios can’t match salary offers from EA or Activision/Microsoft. We compete on other things: freedom and control. In a small company, you own a much larger piece of what you build and you can impact the direction of the game.&lt;/p&gt;
    &lt;p&gt;If the initial conversation is good for both sides, we send a small take-home assignment. We keep it simple and relevant: here’s the take-home assignment. For a coding role, we need to see code, but we strongly dislike the sterile, puzzle-based LeetCode style. Our take-home lets candidates code in their own environment and they get a real taste of the work. It’s a two-way street, and we want people genuinely interested in the problem. This approach is effective and we even had one candidate back out after realizing the assignment was beyond their current expertise.&lt;/p&gt;
    &lt;p&gt;Finally, if the assignment submission looks solid, we bring the candidate in for a series of video chats with the whole team. During one of those calls, we review the take-home submission with the candidate to check if they wrote it and if they actually understand it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical advice for how to run the screening workflow without extra tools&lt;/head&gt;
    &lt;p&gt;Use labels in Gmail; that’s it!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All applications initially start in &lt;code&gt;1. New&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;When we review an application, we move it to either &lt;code&gt;9. No&lt;/code&gt;or&lt;code&gt;2. Reviewed&lt;/code&gt;. “Reviewed” means we like the candidate, but we wait to bulk-email outreach.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;2. Reviewed/Contacted&lt;/code&gt;is where threads go after we send the initial email.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;2. Reviewed/Hold&lt;/code&gt;is for replies where we might proceed, but there’s a temporary snag (e.g., availability mismatch).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;3. Take Home&lt;/code&gt;threads are for candidates we sent the assignment to who haven’t replied yet.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;3. Take Home/To review&lt;/code&gt;is our manual inbox for new submissions we need to look at.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;3. Take Home/Good&lt;/code&gt;holds submissions we want to interview.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;5. Interview&lt;/code&gt;is for candidates currently going through the full loop.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;9. No&lt;/code&gt;is for rejections. At the very end, we go through this folder and send a final notification to everyone we replied to at least once but ultimately passed on.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The purpose of the prefix numbers is too keep the labels sorted by the process order instead of the actual step name:&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical advice for how to design a take-home assignment&lt;/head&gt;
    &lt;p&gt;You must ask candidates to solve problems directly related to the role. If you’re hiring a game programmer, knowing how to detect fraud in bank transactions is irrelevant knowledge if that task never appears on the job. The assignment’s outcome should tell you one thing: can this person do the job you need them to do? In our case, we were looking for a generalist who can do both Unity and services coding.&lt;/p&gt;
    &lt;p&gt;So, instead of LeetCode, create a heavily scoped-down version of a real problem your team recently solved. This achieves two goals: you can tell if the candidate has the skills needed and it lets the candidate gauge whether they actually enjoy the type of work they would be doing daily.&lt;/p&gt;
    &lt;p&gt;A few other things to consider when designing the assigment:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Only assign tasks that are small implementations of existing work. Never ask candidates to build core features or solve problems the studio hasn’t already solved internally just to source free labor. That’s not cool!&lt;/item&gt;
      &lt;item&gt;The assignment should take no longer than the time you would normally allot for a live coding or whiteboard interview session. Respect their time.&lt;/item&gt;
      &lt;item&gt;Always give candidates a channel to ask clarifying questions about the requirements.&lt;/item&gt;
      &lt;item&gt;If a candidate submits a partial solution, let them know. They may have genuinely misunderstood a requirement, rather than failing to deliver.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Overview&lt;/head&gt;
    &lt;p&gt;Finally, here’s an overview of the flow of candidates for this role. It took us about 4 weeks to complete the process and hire someone:&lt;/p&gt;
    &lt;p&gt;Click on the image to see the larger version&lt;/p&gt;
    &lt;p&gt;This article is part of The Tales of a Small Indie Studio series. Click here to check out out the other articles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ballardgames.com/tales/hiring-dev-2025/"/><published>2025-11-11T04:04:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45884169</id><title>Up-to-date documentation you can talk to, for every repo in the world</title><updated>2025-11-11T05:11:46.783234+00:00</updated><content>&lt;doc fingerprint="6cf85aef75cc122c"&gt;
  &lt;main&gt;
    &lt;p&gt;Bring data to life with SVG, Canvas and HTML. :bar_chart::chart_with_upwards_trend::tada:&lt;/p&gt;
    &lt;p&gt;Rich is a Python library for rich text and beautiful formatting in the terminal.&lt;/p&gt;
    &lt;p&gt;DeepWiki provides up-to-date documentation you can talk to, for every repo in the world. Think Deep Research for GitHub.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://deepwiki.com/"/><published>2025-11-11T04:38:24+00:00</published></entry></feed>