<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-02-04T16:33:07.054140+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46869901</id><title>Emerge Career (YC S22) is hiring a product designer</title><updated>2026-02-04T16:33:13.590847+00:00</updated><content>&lt;doc fingerprint="3d88781899c444b5"&gt;
  &lt;main&gt;
    &lt;p&gt;All-in-one re-entry &amp;amp; workforce development training platform&lt;/p&gt;
    &lt;p&gt;Emerge Career’s mission is to break the cycle of poverty and incarceration. We’re not just building software; we’re creating pathways to real second chances. Through an all-in-one platform deeply embedded within the criminal justice system, we recruit, train, and place justice-impacted individuals into life-changing careers.&lt;/p&gt;
    &lt;p&gt;Our vision is to become the country’s unified workforce development system, replacing disconnected brick-and-mortar job centers with one integrated, tech-powered solution that meets low-income individuals exactly where they are. Today, the federal government spends billions annually on education and training programs, yet only about 70% of participants graduate, just 38.6% secure training-related employment, and average first-year earnings hover around $34,708.&lt;/p&gt;
    &lt;p&gt;By contrast, our seven-person team has already outperformed the job centers in two entire states (Vermont and South Dakota) in just the past year. With an 89% graduation rate and 92% of graduates securing training-related employment, our alumni aren’t just getting jobs—they’re launching new lives with average first-year earnings of $77,352. The results speak for themselves, and we’re just getting started.&lt;/p&gt;
    &lt;p&gt;Before Emerge, our founders Zo and Gabe co-founded Ameelio, an award-winning tech nonprofit that is dismantling the prison communication duopoly. Backed by tech luminaries like Reid Hoffman, Vinod Khosla, and Jack Dorsey, and by major criminal-justice philanthropies such as Arnold Ventures and the Mellon Foundation, Ameelio became a recognized leader in the space. Because of this experience both Zo and Gabe understood what it took to create change from within the system. After serving over 1M people impacted by incarceration, they witnessed firsthand the gap in second-chance opportunities and the chronic unemployment plaguing those impacted by the justice system. Emerge Career is committed to solving this issue.&lt;/p&gt;
    &lt;p&gt;Our students are at the heart of our work. Their journeys have captured national attention on CBS, NBC, and in The Boston Globe, and our programs now serve entire states and cities. And we’re not doing it alone: our vision has attracted support from Alexis Ohanian (776), Michael Seibel, Y Combinator, the Opportunity Fund, and public figures like Diana Taurasi, Deandre Ayton, and Marshawn Lynch. All of us believe that, with the right mix of technology and hands-on practice, we can redefine workforce development and deliver true second chances at scale.&lt;/p&gt;
    &lt;p&gt;Emerge Career was designed to tackle two systemic issues: recidivism, fueled by post-incarceration unemployment and poverty, and labor shortages in key industries. Over 60% of formerly incarcerated people remain unemployed a year after incarceration, seeking work but not finding it. The reality is shocking, workforce development programs are severely limited inside prison, with only one-third of incarcerated people ever participating. To worsen, the available prison jobs offer meager wages, often less than $1 per hour, and often do not equip individuals with the skills for long-term stable employment.&lt;/p&gt;
    &lt;p&gt;We call this a Founding Design Engineer role, even three years in and with multiple contracts under our belt, for two reasons. First, you'll be our very first engineer, joining our co-founder, who's built the entire platform solo to date. Second, our growth is now outpacing our systems, and we can't keep up on maintenance alone. We're at a critical juncture: we can either hire someone to simply care for what exists, or we can bring on a talent who believes that, with the right blend of technology and hands-on practice, we can unify the workforce-development system and deliver second chances at true scale. We hope that can be you.&lt;/p&gt;
    &lt;p&gt;This is not a traditional engineering job. You'll build features in React and TypeScript, but your real job is helping students finish. That means understanding the human problem first: why do people disengage? What makes someone choose to keep going when the payoff is months away? You'll answer those questions through direct conversations, usability research, and watching how people actually use what you build. Then you'll prototype fast, ship real software, and measure whether it worked. Some days that looks like code. Other days it looks like a phone call, a support ticket, or a whiteboard session figuring out how to turn a one-off fix into a system that scales.&lt;/p&gt;
    &lt;p&gt;This role blends engineering, product, design, and program operations. We're looking for someone who believes good design can inspire a person to invest in their own future, and who wants to prove it, week after week, by shipping work that measurably helps students succeed. If you want to be close to users, own outcomes end to end, and build something that actually matters, you'll thrive here.&lt;/p&gt;
    &lt;p&gt;You design by building. You don't hand off mockups and wait. You open Cursor, Claude Code, or whatever gets you closest to a real, testable thing fastest. You might already be shipping code in production — or you're itching to. You believe the fastest path to a great design is putting something real in front of a real user and watching what happens.&lt;/p&gt;
    &lt;p&gt;You are relentlessly scrappy. You prototype in hours, not weeks. You'd rather test an ugly thing that teaches you something than polish a beautiful thing nobody's used yet. You know that at this stage, speed of learning is the only thing that matters. Fidelity comes later. Signal comes first.&lt;/p&gt;
    &lt;p&gt;You refuse to be blocked. When engineering bandwidth isn't there, you don't sit around. You figure it out — a Figma prototype, a coded prototype, a quick hack in the codebase. You treat "waiting for a developer" as a personal failure. You find a way or you make one.&lt;/p&gt;
    &lt;p&gt;You think in outcomes, not outputs. You don't measure your work in screens delivered. You measure it in whether students finished, whether they came back, whether the thing you shipped actually moved a number that matters. You're obsessed with the gap between what you designed and what actually happened.&lt;/p&gt;
    &lt;p&gt;You talk to users constantly. Not in scheduled quarterly research sprints — in real conversations, every week. You build relationships with students. You know their names, their blockers, their moments of doubt. Your best design ideas come from a 10-minute phone call, not a brainstorm.&lt;/p&gt;
    &lt;p&gt;You have strong taste but low ego. You have opinions about what good looks like and you'll fight for them. But when the data says you're wrong, you move on fast. You don't fall in love with your work. You fall in love with the problem.&lt;/p&gt;
    &lt;p&gt;You believe everyone deserves a second chance. You treat everyone with dignity. You know how to meet people exactly where they are — with empathy and compassion — helping create a space where everyone feels seen and valued, regardless of their background.&lt;/p&gt;
    &lt;p&gt;You work hard. You show up early, stay late, and do what needs to get done — no ego, no excuses. This isn't a 9-to-5. The team puts in 10+ hour days because we care about the mission and each other. If that sounds miserable, this isn't for you. If it sounds exciting, you'll fit right in.&lt;/p&gt;
    &lt;p&gt;Talking to students — a lot. Your week starts and ends with users. You'll build real relationships with students, not just run usability sessions. You'll understand why someone almost quit, what message made them log back in, what screen confused them at 11pm. These conversations are your primary design tool.&lt;/p&gt;
    &lt;p&gt;Prototyping at the speed of conversation. You hear a problem on a call Tuesday. By Wednesday you have something testable — a coded prototype, a functional hack, a Figma flow wired to real data. By Thursday a student is using it. By Friday you know if it worked. That's the cycle. Repeat.&lt;/p&gt;
    &lt;p&gt;Shipping real product, not just designs. You'll work in our React and TypeScript codebase — or use AI tools like Cursor and Claude Code to get there. The goal isn't to become a full-time engineer. The goal is to never let "it hasn't been built yet" slow down learning. Some of what you build will go straight to production. Some will be throwaway prototypes. You'll know the difference.&lt;/p&gt;
    &lt;p&gt;Designing the moments that keep students going. The hardest design problem here isn't layout or typography. It's commitment. Students are betting months of effort on a future they have to imagine. You'll study where they disengage, what triggers doubt, and what reignites momentum. Then you'll design the moments — an interface, a message, a milestone — that help someone choose to keep going. How do you make a better life in three months feel worth the sacrifice today? You'll own that problem.&lt;/p&gt;
    &lt;p&gt;Measuring what matters. Polished decks don't matter here. You'll define success metrics for what you ship, track whether completion rates moved, whether more students hit the next milestone, whether the intervention you designed actually intervened. You'll close the loop between design and outcome every time.&lt;/p&gt;
    &lt;p&gt;Working across the entire stack of the student experience. Some days that looks like interface design. Other days it looks like rethinking a Customer.io campaign, redesigning an onboarding flow, or sitting with the ops team to understand why students in one facility disengage faster than another. You go where the problem is.&lt;/p&gt;
    &lt;p&gt;Documenting your work clearly. Our work spans months and involves multiple teams. You'll create visibility when a change impacts operations and help others understand how features affect training and service delivery. Precision matters.&lt;/p&gt;
    &lt;p&gt;Start Date: ASAP&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/emerge-career/jobs/omqT34S-founding-product-designer"/><published>2026-02-03T12:00:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46871173</id><title>Agent Skills</title><updated>2026-02-04T16:33:13.475605+00:00</updated><content>&lt;doc fingerprint="8f77afff0b4fb448"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Why Agent Skills?&lt;/head&gt;Agents are increasingly capable, but often don’t have the context they need to do real work reliably. Skills solve this by giving agents access to procedural knowledge and company-, team-, and user-specific context they can load on demand. Agents with access to a set of skills can extend their capabilities based on the task they’re working on. For skill authors: Build capabilities once and deploy them across multiple agent products. For compatible agents: Support for skills lets end users give agents new capabilities out of the box. For teams and enterprises: Capture organizational knowledge in portable, version-controlled packages.&lt;head rend="h2"&gt;What can Agent Skills enable?&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Domain expertise: Package specialized knowledge into reusable instructions, from legal review processes to data analysis pipelines.&lt;/item&gt;&lt;item&gt;New capabilities: Give agents new capabilities (e.g. creating presentations, building MCP servers, analyzing datasets).&lt;/item&gt;&lt;item&gt;Repeatable workflows: Turn multi-step tasks into consistent and auditable workflows.&lt;/item&gt;&lt;item&gt;Interoperability: Reuse the same skill across different skills-compatible agent products.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://agentskills.io/home"/><published>2026-02-03T14:09:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46872465</id><title>A sane but bull case on Clawdbot / OpenClaw</title><updated>2026-02-04T16:33:13.085631+00:00</updated><content>&lt;doc fingerprint="630c10373c7116b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A sane but extremely bull case on Clawdbot / OpenClaw&lt;/head&gt;
    &lt;p&gt;over the past week the discourse around openclaw (which i'll refer to as clawdbot) has absolutely exploded. it has felt to me like all threads of conversation have veered towards the extreme and indefensible. some are running clawdbot with unlimited permissions on their main computers. others are running it in the cloud and blowing through tokens like snow. finally, alarmingly (and very sensationally), people are connecting their clawdbots together on a social network so they can plot the demise of their humans together.&lt;/p&gt;
    &lt;p&gt;does any of this make sense? of course not. but i think the virality and silliness—leading many to conclude that sitting this one out is the only sane choice—has blinded people to something real.&lt;/p&gt;
    &lt;p&gt;i want to quickly write down where i am on my journey and share a bull case from what i think is a reasoned perspective. where i started somewhere lukewarm, i ended up much closer to the deep end than i expected to be. after wincing before pressing go, i'm now not sure i can go back to a world without clawdbot.&lt;/p&gt;
    &lt;p&gt;this article covers what i've built, how i think about the risk, and what it's taught me about this moment in AI. the target audience is a moderately+ technical person interested in or skeptical of clawdbot. if you just want the setup details, skip to the end. everyone's welcome!&lt;/p&gt;
    &lt;head rend="h2"&gt;what i’ve been doing&lt;/head&gt;
    &lt;p&gt;i’ll be vulnerable here (screenshots or it didn't happen) and share exactly what i've actually set up:&lt;/p&gt;
    &lt;head rend="h3"&gt;staying on top of messages&lt;/head&gt;
    &lt;head rend="h4"&gt;never forgetting about texts&lt;/head&gt;
    &lt;p&gt;every 15 minutes, clawdbot looks through new text messages i've received, using a script to identify threads where i've sent a message since it last checked. (it ignores threads where i haven't engaged.)&lt;/p&gt;
    &lt;p&gt;if it finds that i've made a specific promise about doing something tomorrow ("let me review this tomorrow!") it will create a calendar event for me the next day when i'm free.&lt;/p&gt;
    &lt;p&gt;if specific plans are being made—for example, offering a meeting slot to someone—it will automatically drop a "hold" onto my calendar so that i don't double book myself. clawdbot also checks: is there a time, place, and mutual confirmation? if there is, it drafts a calendar invite and asks me if i'd like to create it.&lt;/p&gt;
    &lt;p&gt;these two automations alone have helped me become more responsive and less forgetful. more importantly, they help text messages catch up to email. we've long had great tooling for email—superhuman automatically reminds me to follow up on emails and brings up my calendar in a sidebar when i type a date. texting is the wild west and yet i text 100x more than i email.&lt;/p&gt;
    &lt;head rend="h4"&gt;preparing for the next day&lt;/head&gt;
    &lt;p&gt;at 8pm every night, clawdbot goes through my calendar for the next day and identifies meetings—coffee chats, lunches, phone calls, and more. it sends me a quick summary. as a natural introvert, it's helpful to prepare in advance whether a day will be a "big day of meetings" or a heads down day. this also ensures i wake up and get to the office on time.&lt;/p&gt;
    &lt;head rend="h4"&gt;simplifying group chatter&lt;/head&gt;
    &lt;p&gt;i'm in a few communities with whatsapp and signal groups that have high volume (100+ messages a day). i typically mute these, but clawdbot goes through them once a day and summarizes interesting topics or conversations for me.&lt;/p&gt;
    &lt;head rend="h3"&gt;monitoring things&lt;/head&gt;
    &lt;head rend="h4"&gt;complex price alerts&lt;/head&gt;
    &lt;p&gt;it's stunningly easy to monitor the price of something now, even if it's complicated. whereas before i would go looking for a price alert website, now i just paste the URL into clawdbot and tell it to check every few hours if the price has changed.&lt;/p&gt;
    &lt;p&gt;i currently have over 30 price alerts set. these include straightforward alerts on products i'm interested in buying. but they also include powerful reasoning guidelines, like hotels and airbnbs in lake tahoe where "a pullout bed is OK if it's not in the same room as another bed." clawdbot actually reviews the photos on the listing to ensure they fit these criteria!&lt;/p&gt;
    &lt;p&gt;i am curious to try more complex criteria that are currently impossible traditionally (like avoiding hotel rooms that don't have a door to the bathroom) or even subjective criteria (vibe of the room is clean and renovated, not old and dingy).&lt;/p&gt;
    &lt;head rend="h4"&gt;or monitoring anything&lt;/head&gt;
    &lt;p&gt;it turns out that clawdbot’s website + cron functionality is good enough to monitor basically anything. while i pay for several apps like flighty (flight monitoring) and parcel (package tracking), i’ve started to gravitate towards simply asking clawdbot to track these things instead.&lt;/p&gt;
    &lt;p&gt;for example, with a USPS tracking number, it can let me know every day what the progress of my package is. when something seems stuck in transit, it flags it. i no longer have to dig through emails or remember which carrier is delivering what. even opening the parcel app to add a tracking number seems like unnecessary work now.&lt;/p&gt;
    &lt;head rend="h3"&gt;household logistics&lt;/head&gt;
    &lt;head rend="h4"&gt;freezer inventory&lt;/head&gt;
    &lt;p&gt;as someone who has a chest freezer and a compulsive desire to buy too many things at costco, we take everything out of the freezer every few months to check what we have. before, this was a relatively involved process: me calling things out, my partner writing them down.&lt;/p&gt;
    &lt;p&gt;now, i take pictures of everything in the freezer and send them to clawdbot, which parses through each picture (asking me if it's confused about anything). it makes reasonable assumptions on remaining quantities and adds the inventory to a list in notion. it also removes items from our grocery list if we're already well-stocked.&lt;/p&gt;
    &lt;head rend="h4"&gt;grocery list&lt;/head&gt;
    &lt;p&gt;i'm sure this exists in some complicated form via the NYT cooking app, but i now screenshot recipes and send the ingredient list to clawdbot, which organizes them into our grocery list in apple reminders. it's smart enough to dedupe and combine ingredients already on the list (as well as ignore ingredients we already have)—2 carrots becomes 3 if the recipe calls for more.&lt;/p&gt;
    &lt;head rend="h3"&gt;booking and forms&lt;/head&gt;
    &lt;head rend="h4"&gt;resy and opentable&lt;/head&gt;
    &lt;p&gt;clawdbot can log into resy and opentable as me (it even enters the 2FA code it finds in my texts). i haven't automated anything here, but booking a table by talking to clawdbot is delightful.&lt;/p&gt;
    &lt;p&gt;for my partner and me, it looks through our calendars to find evenings when we're both free and the restaurant we want has availability (including clicking through resy slots page by page—something i used to do myself). it then suggests options back to me to confirm, filling in all my preferences.&lt;/p&gt;
    &lt;head rend="h4"&gt;dentist appointments&lt;/head&gt;
    &lt;p&gt;clawdbot knows when i'm due for a cleaning and can see my calendar. when i ask it to book an appointment, it logs into my dentist's portal, finds a slot that works (and where i will already be near the dentist office), and confirms with me before booking. one less thing to forget about.&lt;/p&gt;
    &lt;head rend="h4"&gt;filling out forms&lt;/head&gt;
    &lt;p&gt;one thing i'm experimenting with, as clawdbot has more context about me, is whether i can trust it to fill out forms on my behalf—for example, to book a vendor. clawdbot takes a first stab at answering any questions it knows the answer to and then asks me for the rest in a slack message. we workshop the answers back and forth and then clawdbot submits the form.&lt;/p&gt;
    &lt;p&gt;it occasionally gets lost in nested frames (which decreases my trust in its ability to do this well), but it's remarkably persistent at making it through a lengthy questionnaire, even across multiple pages. it also has a lovely intuitive sense for many things—like unchecking marketing emails.&lt;/p&gt;
    &lt;head rend="h3"&gt;unexpected wins&lt;/head&gt;
    &lt;head rend="h4"&gt;better todo creation&lt;/head&gt;
    &lt;p&gt;clawdbot is just better at making todo items than i am.&lt;/p&gt;
    &lt;p&gt;when i visited REI this weekend to find running shoes for my partner, i took a picture of the shoe and sent it to clawdbot to remind myself to buy them later in a different color not available in store. the todo item clawdbot created was exceptionally detailed—pulling out the brand, model, and size—and even adding the product listing URL it found on the REI website.&lt;/p&gt;
    &lt;head rend="h4"&gt;giving me visibility&lt;/head&gt;
    &lt;p&gt;through the course of dialing in my clawdbot, it has created many tools, skills, workflows, and preferences. this is one of the beauties of clawdbot (and LLMs with memory in general): they get better as you use them, and they are genuinely remarkable at learning your preferences.&lt;/p&gt;
    &lt;p&gt;i sometimes nudge this along by explicitly asking clawdbot to "make a note" of various requests—for example, how a calendar event title should be formatted.&lt;/p&gt;
    &lt;p&gt;to get visibility into how this process is going (mostly out of curiosity), clawdbot writes a human-readable version of each workflow and pushes it up to a notion database. these workflows can be incredibly intricate and detailed as it learns to navigate different edge cases.&lt;/p&gt;
    &lt;p&gt;for example, if a resy restaurant has a reservation cancellation fee, clawdbot now informs me of the fee, asks me to confirm again if it's not refundable, and includes the cancellation deadline in the calendar event it creates.&lt;/p&gt;
    &lt;p&gt;these are little things that, from my experience working with a human personal assistant (more on this later), take months or years to dial in. with clawdbot, this was nearly single shot.&lt;/p&gt;
    &lt;p&gt;seeing these workflows in notion (1) awes me with how much i've built up in very little time, with almost no conscious "configuration" in the traditional sense; and (2) with notion's version control, i get a diff view to see how each workflow has evolved over time. both are incredibly satisfying for the engineer in me.&lt;/p&gt;
    &lt;head rend="h2"&gt;on the shape of risk&lt;/head&gt;
    &lt;p&gt;let me be upfront about how much access i've given clawdbot: it can read my text messages, including two-factor authentication codes. it can log into my bank. it has my calendar, my notion, my contacts. it can browse the web and take actions on my behalf. in theory, clawdbot could drain my bank account. this makes a lot of people uncomfortable (me included, even now).&lt;/p&gt;
    &lt;p&gt;sometimes i think about my experience with my (human) personal assistant who helps me with various tasks. to do her job, she has my credit card information, access to my calendar, copies of my flight confirmations, and a document with my family's passport numbers. she is abroad and i've never met her in person.&lt;/p&gt;
    &lt;p&gt;i trust her because i've built trust over time but also because i have to. without that trust—without sharing my secrets—she cannot do her job. the help and the risk are inseparable.&lt;/p&gt;
    &lt;p&gt;all delegation involves risk. with a human assistant, the risks include: intentional misuse (she could run off with my credit card), accidents (her computer could get stolen), or social engineering (someone could impersonate me and request information from her).&lt;/p&gt;
    &lt;p&gt;with clawdbot, i'm trading those risks for a different set: prompt injection attacks, model hallucinations, security misconfigurations on my end, and the general unpredictability of an emerging technology. i think these risks are completely different and lead to a different set of considerations (for example, clawdbot's default configuration has a ton of personality to be fun and chaotic on purpose, which feels unnecessarily risky to me).&lt;/p&gt;
    &lt;p&gt;the increase in risk is largely correlated to the increase in helpfulness. the people most at risk from AI assistants are the people getting the most value from them. my learning is that the first bits of risk led to a lot more helpfulness.&lt;/p&gt;
    &lt;p&gt;if something isn't working or useful, i do take the permission away. i also take precautions—i run clawdbot on an isolated machine and constrain which sites it visits. when i'm unsure what it's doing, i ask it to take a screenshot; this has been invaluable for catching mistakes and building trust in new workflows. but i also have it do things that would make most security professionals wince, like reading my 2FA codes and logging into my bank.&lt;/p&gt;
    &lt;p&gt;what surprised me most was how quickly i found myself wanting to give it more access, not less. every new permission unlocked something useful, and the value accumulated faster than my caution could keep up. most of the online discourse is about locking it down; my experience has been the opposite pull. it comes down to whether the value justifies the risk for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;on rewiring ourselves&lt;/head&gt;
    &lt;p&gt;the discourse around clawdbot has been polar and, because some people have been overtly evangelical, many critics feel astroturfed or otherwise sold to.&lt;/p&gt;
    &lt;p&gt;amongst smart people i know there's a surprisingly high correlation between those who continue to be unimpressed by AI and those who use a hobbled version of it. for some it's a company-issued version of chatgpt/gemini with memory disabled, and for others it's a self-inflicted decision to limit LLM memory, context, and tools (usually anchored around safety and risk).&lt;/p&gt;
    &lt;p&gt;we're taught that limiting scope is good (keeps the AI focused) and safe (keeps bad things from happening). this is true but my experiences with clawdbot completely fried this teaching. the sweet sweet elixir of context is a real "feel the AGI" moment and it's hard to go back without feeling like i would be willingly living my most important relationship in amnesia.&lt;/p&gt;
    &lt;p&gt;this isn't a novel insight—companies know that context is the whole game and are working to organize their data for AI. but for individuals, this world has been closed off. your AI interactions are flat and stateless—data in, response out, nothing building over time. when google announced gemini's gmail integration, people got excited: finally, an AI that knows me! but when they tried it, it was shallow and disappointing and couldn't figure out your spirit animal from your email style, and they moved on.&lt;/p&gt;
    &lt;p&gt;if you're interested in capturing this value, three things have stood out for me:&lt;/p&gt;
    &lt;head rend="h4"&gt;gathering, improving, actioning&lt;/head&gt;
    &lt;p&gt;i think productivity lift from AI use falls into three phases: gathering information, improving it, and actioning on it. most usage today focuses on the middle—you gather data yourself, hand it to the AI to improve, then action on it yourself.&lt;/p&gt;
    &lt;p&gt;for knowledge work, this makes sense. there's a lot to improve—summarizing, translating, critiquing. but personal AI is different. there's not much to improve; you already know what needs to happen. the lift comes from gathering and actioning.&lt;/p&gt;
    &lt;p&gt;making calendar events is uninteresting. figuring out when one needs to happen—by monitoring my texts—and then creating it for me? that's interesting.&lt;/p&gt;
    &lt;p&gt;one place to start: how can you take data from one place and move it to another isolated system? from your text messages to a restaurant booking? from granola meeting notes to a follow-up email?&lt;/p&gt;
    &lt;head rend="h4"&gt;embrace flexibility&lt;/head&gt;
    &lt;p&gt;if you're engineer-brained like me, you gravitate towards scripts and playbooks—whatever you can do to constrain the AI and make its behavior predictable. this works, and for high-stakes situations it might be the only way to get comfortable.&lt;/p&gt;
    &lt;p&gt;but the upside to letting go has been 10x, not 10%. i didn't see that coming. it's the same thing i've heard from people using claude code—you can't understand how much you're leaving on the table until you let go. the whole reason i'm using an LLM and not a traditional script is that it can handle ambiguity, interpret intent, and figure things out on the fly.&lt;/p&gt;
    &lt;p&gt;early on, i wanted clawdbot to fetch web pages as text only, believing that to be safer (it is). if i'd stuck to that, i would never have discovered it could look through airbnb listing photos to find a place matching my exact criteria ("a pullout bed is okay if it's not in the same room as another bed"). i didn't program that. i just described what i wanted and let it figure out how. not spelling out how i wanted clawdbot to work made it a LOT better.&lt;/p&gt;
    &lt;head rend="h4"&gt;continuous improvement&lt;/head&gt;
    &lt;p&gt;a current AI engineering adage: treat AI like a junior software engineer. guide it through building a plan, watch its first attempts carefully, challenge its reasoning.&lt;/p&gt;
    &lt;p&gt;this applies to clawdbot too, but it requires patience. it's easy to give up on a workflow when you watch it fumble ("let me try clicking this again. didn't work. let me try again.").&lt;/p&gt;
    &lt;p&gt;resist the urge to write clawdbot off. if you're worried, ask it what it plans to do before it does it and ask for a screenshot when you want to verify it's got the right page open. when an edge case breaks a workflow, treat it as a teaching opportunity. once you've corrected it, it won't make that mistake again.&lt;/p&gt;
    &lt;p&gt;clawdbot gets meaningfully better the more you use it, and it gets better in a fast, organic way that feels less cumbersome than writing rules for claude code or yelling at any other LLM. it feels much closer to working with a real executive assistant (in part because the clawdbot harness/system prompts are very good), which makes me want to give it more and more responsibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;how’d you set it up?&lt;/head&gt;
    &lt;p&gt;(this is a more technical deep dive, for those interested in setting this up themselves.)&lt;/p&gt;
    &lt;p&gt;i run clawdbot on a mac mini in my home. the mac mini's primary job is running clawdbot and it stays on 24/7. why a mac mini?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;one of the core use cases is browsing websites and sometimes logging into them. to do this convincingly (without triggering tons of captchas and "is this a new IP?" alerts), clawdbot needs to be opening sites from my home, not the cloud; and it needs to do so in a real google chrome window.&lt;/item&gt;
      &lt;item&gt;many of the ways clawdbot accesses data are mac-only. specifically, clawdbot can read and send iMessages (real blue bubbles!); manage my todo and grocery lists in apple reminders; and use my apple contacts as a source of truth. apple will only let you do these things without getting banned on a real bona fide mac.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;i communicate with clawdbot via a private slack workspace. many others have shot themselves in the foot setting it up on whatsapp or telegram (since the bot responds as you to others). slack is great because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;it's familiar to me—i've spent over a decade working in and managing slack workspaces.&lt;/item&gt;
      &lt;item&gt;slack supports rich formatting, image attachments, and has a great mobile app.&lt;/item&gt;
      &lt;item&gt;i can create separate channels for different topics. #ai-notifs is only for inbound alerts.&lt;/item&gt;
      &lt;item&gt;i can have several workflows going at once, since each channel's history is isolated. i created #ai-1, #ai-2, #ai-3, and so on—just for multitasking. (i may explore adding my partner at some point, and it'll be easy since slack is, well, meant for multiplayer.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;clawdbot communicates with me by sending slack notifications. behind the scenes it also makes changes to my calendar—moving events around, adding "soft hold" events, sending invites—and manages my apple reminders and notion pages. clawdbot never communicates with others on its own.&lt;/p&gt;
    &lt;p&gt;i give clawdbot a toolkit of access. the most useful ones have been:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;my text messages. i conduct a lot of work and daily life over imessage. frustratingly, unlike email, texting has very poor tooling. where my email app automatically pulls up my calendar when it sees dates/times, texting me "call tomorrow 4pm?" does not. when someone sends me a calendar invite, it's both in my inbox and on my calendar; when someone texts me "yep let's do it", neither is true. clawdbot has given me massive lift here. (yes, this also gives clawdbot access to 2FA codes.)&lt;/item&gt;
      &lt;item&gt;my calendar. i also have a shared calendar with my partner; clawdbot sees both.&lt;/item&gt;
      &lt;item&gt;my notion workspace. for me this is a general catch-all for storing and managing information; the apple notes app could also work.&lt;/item&gt;
      &lt;item&gt;web browsing. in a way this is the most important one—it's infinite tools in one. but it's also where the risk concentrates, so i always give clawdbot a starting URL rather than letting it browse freely.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;notably, i haven't given clawdbot access to my email—my tooling there is already good enough that i usually do things myself. i’ve also found the ways clawdbot can help here to be cumbersome and limited. i may revisit if i find a killer use case.&lt;/p&gt;
    &lt;head rend="h4"&gt;things i haven't done&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;i don't allow my clawdbot to access social networking websites (it doesn't read x/twitter, for example). this seems high risk and no reward.&lt;/item&gt;
      &lt;item&gt;i don't give clawdbot access to all my logins. (there's a 1password integration which is... pretty wild.) when i do, i try to use google chrome's native password manager so that clawdbot doesn't need to manage passwords in context directly. (note that it still has access to passwords because it can autofill and then read it off the page, but i've at least added more hoops.)&lt;/item&gt;
      &lt;item&gt;i don't let clawdbot send text messages without my explicit approval, and i've built safeguards in those skills to enforce this.&lt;/item&gt;
      &lt;item&gt;i didn't add my clawdbot to moltbook so it can plot against me at my expense. sorry.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://brandon.wang/2026/clawdbot"/><published>2026-02-03T15:47:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46872540</id><title>New York’s budget bill would require “blocking technology” on all 3D printers</title><updated>2026-02-04T16:33:12.948418+00:00</updated><content/><link href="https://blog.adafruit.com/2026/02/03/new-york-wants-to-ctrlaltdelete-your-3d-printer/"/><published>2026-02-03T15:51:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46873574</id><title>221 Cannon is Not For Sale</title><updated>2026-02-04T16:33:12.720960+00:00</updated><content>&lt;doc fingerprint="ec0da09223e19cd5"&gt;
  &lt;main&gt;
    &lt;p&gt;Like most people, I’ve had my identity stolen once or twice in my life. It’s annoying, but thankfully I’ve avoided some of the more catastrophic outcomes when criminals begin impersonating you.&lt;/p&gt;
    &lt;p&gt;These days, however, it seems like someone is really trying to change that: a scammer has now tried to impersonate me multiple times in a six figure land deal in my hometown of Wilton, CT. So while I usually use this blog to write about finding weird things on the internet, it’s now time for a story about something weird on the internet finding me.&lt;/p&gt;
    &lt;p&gt;The story begins with my brother Alexander and I purchasing a small parcel of vacant land at 221 Cannon Road in Wilton, Connecticut in 2015. It’s been over 10 years since we purchased it and we have never listed it for sale. Nor do we have plans to sell it.&lt;/p&gt;
    &lt;p&gt;And yet, three different real estate agents have now contacted us to let us know that someone has been impersonating us and attempting to sell our property out from under us.&lt;/p&gt;
    &lt;p&gt;The first time it happened, it was pretty upsetting, but now that it’s happened another two times, I figured it was time to write a blog post about it.&lt;/p&gt;
    &lt;head rend="h2"&gt;The First Attempt (March 2024)&lt;/head&gt;
    &lt;p&gt;In March 2024, I received an email from a real estate attorney in Wilton, asking if I was the “Fred Benenson” who co-owned property in town with an “Ed Benenson.” He explained that a realtor at a major brokerage had been working with someone claiming to be us, and that there was already an offer on the table. The attorney was doing his due diligence before representing the sellers — and something didn’t add up.&lt;/p&gt;
    &lt;p&gt;I replied within minutes: Neither of us had spoken to anyone about selling the property. It was pretty concerning.&lt;/p&gt;
    &lt;p&gt;The realtor had been contacted through Zillow by someone claiming to be me. They’d had a phone conversation — she noted the person had a “middle European” accent — and the scammer had provided accurate details about the property, including its exact acreage. The impostor gave her the email address &lt;code&gt;[email protected]&lt;/code&gt; and the phone number (516) 828-0305. He also provided a fake email for my brother: &lt;code&gt;[email protected]&lt;/code&gt;. Notice the subtle misspelling — “Benenson” without the second “n” in the email, and the hyphenated “out-look.com” domain.&lt;/p&gt;
    &lt;p&gt;She had walked the property, taken drone photos, pulled comps, and listed for a price well above what we paid for it. The property had been live on dozens of real estate websites for days before anyone caught it. A builder had already submitted a full-price cash offer.&lt;/p&gt;
    &lt;p&gt;The scammer had even e-signed a purchase agreement.&lt;/p&gt;
    &lt;p&gt;When the attorney requested identification before closing, the impostor provided a New York State driver’s license. It had my father’s name (which I share with him) and his correct date of birth and home address. But the photo was of a complete stranger.&lt;/p&gt;
    &lt;p&gt;I have no idea who that guy is in on the license, but it’s definitely not my Dad. The license wouldn’t fool anyone who knew my father, but it didn’t need to – in a transaction conducted entirely by email and text message, with a closing that the scammer would never actually attend, the ID just needed to look plausible enough to keep things moving forward. (Though if you look closely at his signature, it’s clearly not written by hand.)&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Was Caught&lt;/head&gt;
    &lt;p&gt;The attorney deserves most of the credit here. He told me this was the second time in nine months he’d encountered this exact scheme on vacant land in Wilton – his policy is that he won’t represent owners of vacant land without independently verifying ownership. That’s what led him to track me down, and that’s what stopped the sale.&lt;/p&gt;
    &lt;p&gt;The realtor was an innocent victim in this too. She’d done her job by walking the property, pulling comps, etc., all in good faith. When I initially suggested (perhaps unfairly) that this felt like lead generation, the attorney took me aside and vouched for her. I’m glad I listened to him!&lt;/p&gt;
    &lt;p&gt;I apologized to her, and she graciously forwarded me all of her text message exchanges with the scammer. Reading through them was fascinating. The impostor was responsive, polite, and generally knew the right things to say. But there were tells: slightly awkward phrasing (“Hi good morning”), declining a for-sale sign (“No I don’t think that will be necessary”), and a general reluctance to engage in any way that might require showing up in person.&lt;/p&gt;
    &lt;head rend="h2"&gt;Going to the FBI&lt;/head&gt;
    &lt;p&gt;After gathering everything I could — the fake ID, the realtor’s text messages, the scammer’s email addresses and phone number, and the attorney’s notes from a prior similar case — I contacted the FBI field office in Connecticut. They directed me to “walk it in” to the office in New York City.&lt;/p&gt;
    &lt;p&gt;The experience was, frankly, underwhelming. The FBI wouldn’t let me submit any of our documentation. Instead, they required me to write out the entire complaint by hand on a single piece of paper and hand it to the guard. He made some calls while I waited, and by the end he seemed at least somewhat interested. He gave me the standard line: 2-3 weeks if I hear from anyone.&lt;/p&gt;
    &lt;p&gt;I never heard from anyone.&lt;/p&gt;
    &lt;p&gt;The attorney, meanwhile, checked with his title company about recording an affidavit on the land records — something that would alert any future buyer or title searcher that the property had been targeted by fraud, and providing our verified contact information.&lt;/p&gt;
    &lt;head rend="h2"&gt;It’s Happening Again (February 2026)&lt;/head&gt;
    &lt;p&gt;I thought this was behind us. Then, this past week, nearly two years later, I was contacted by two more real estate agents, both reaching out to warn me that someone was once again trying to sell 221 Cannon Road.&lt;/p&gt;
    &lt;p&gt;The first was a agent in Wilton who reached out via Instagram DM, of all places — it was the only way he could find to contact me. He explained that his team had received an inquiry to list 221 Cannon Road and had sent paperwork to “Fred and Alex” the night before to sign. But he’d done something smart: he’d noticed he had a mutual friend with my brother, and when he asked him about the situation, he flagged that the conversation with “Alex” didn’t sound right.&lt;/p&gt;
    &lt;p&gt;“I had a really bad feeling it wasn’t,” he told me.&lt;/p&gt;
    &lt;p&gt;The second agent, a woman at Berkshire Hathaway, sent a carefully worded email explaining that she’d been contacted by someone claiming to have authority to sell our property, but that “several standard verification steps raised concerns” and she chose not to proceed. She reached out purely as a courtesy to let us know.&lt;/p&gt;
    &lt;p&gt;Which is about when I decided I should write something about this. Not only because it’s a fascinating scam that seems to be getting more common, but because I figured this post might show up for the next broker who might be doing research on the address.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vacant Land Fraud&lt;/head&gt;
    &lt;p&gt;This type of scam targets a very specific vulnerability: vacant land has no occupants to notice a for-sale sign, no neighbors who’d immediately recognize something is wrong, and closings often happen remotely.&lt;/p&gt;
    &lt;p&gt;Here’s how it works:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The scammer identifies vacant land through public records or Zillow. They look for parcels that are owned free and clear (no mortgage), haven’t changed hands recently, and are in desirable areas.&lt;/item&gt;
      &lt;item&gt;They contact a real estate agent through a platform like Zillow, posing as the owner. They know the property details because that information is publicly available.&lt;/item&gt;
      &lt;item&gt;They communicate primarily through text and email, avoiding in-person meetings. They provide fake identification if asked.&lt;/item&gt;
      &lt;item&gt;They agree to whatever price the agent suggests (because they don’t actually own the property, any sale is pure profit).&lt;/item&gt;
      &lt;item&gt;They push for a quick closing and attempt to direct proceeds to an account they control.&lt;/item&gt;
      &lt;item&gt;If questioned, they disappear. The scammer who targeted us in 2024 simply stopped responding once the attorney asked for an in-person closing.&lt;/item&gt;
      &lt;item&gt;If they get farther they’ll pocket the earnest money deposit which would have been significant in my case.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A similar scheme in nearby Fairfield wasn’t caught in time: someone had a $1.5 million home built on land they didn’t own without the actual owners knowing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What You Can Do&lt;/head&gt;
    &lt;p&gt;If you own vacant land there are a couple of things you can do, but the most effective one is probably to register the address with a Fraud / No-Authority notice. This involves calling the County Recorder / Register of Deeds and ask how to record one of these (names vary by state):&lt;lb/&gt; • Owner Affidavit&lt;lb/&gt; • Affidavit of Fact&lt;lb/&gt; • Notice of Non-Authority to Convey&lt;lb/&gt; • Fraud Alert / Title Alert Notice&lt;lb/&gt; • Statement of Ownership / Anti-Fraud Notice:&lt;/p&gt;
    &lt;p&gt;You could also setup up Google Alerts for your address and you’ll be notified if it appears online.&lt;/p&gt;
    &lt;p&gt;Finally, and this certainly isn’t for everyone, you can make yourself easily findable online. One reason the attorney was able to verify ownership quickly in 2024 was that it’s fairly easy to gooogle me. If you own property, make sure there’s some way for a diligent attorney or agent to reach the real you.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Property Is Not For Sale&lt;/head&gt;
    &lt;p&gt;In case it isn’t clear, 221 Cannon Road is not for sale. It has never been for sale. If you are a real estate professional who has been contacted about listing or purchasing this property, please reach out to me directly.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fredbenenson.com/blog/2026/02/03/221-cannon-is-not-for-sale/"/><published>2026-02-03T16:56:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46874097</id><title>Deno Sandbox</title><updated>2026-02-04T16:33:12.409456+00:00</updated><content>&lt;doc fingerprint="84be1f18cd2fafa2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Deno Sandbox&lt;/head&gt;
    &lt;p&gt;Over the past year, we’ve seen a shift in what Deno Deploy customers are building: platforms where users generate code with LLMs, and that code runs immediately without review. That code frequently calls LLMs itself, which means it needs API keys and network access.&lt;/p&gt;
    &lt;p&gt;This isn’t the traditional “run untrusted plugins” problem. It’s deeper: LLM-generated code, calling external APIs with real credentials, without human review. Sandboxing the compute isn’t enough. You need to control network egress and protect secrets from exfiltration.&lt;/p&gt;
    &lt;p&gt;Deno Sandbox provides both. And when the code is ready, you can deploy it directly to Deno Deploy without rebuilding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandboxes?&lt;/head&gt;
    &lt;p&gt;You don’t want to run untrusted code (generated by your LLMs, your users LLMs, or even hand written by users) directly on your server. It will compromise your system, steal your API keys, and call out to evil.com. You need isolation.&lt;/p&gt;
    &lt;p&gt;Deno Sandbox gives you lightweight Linux microVMs (running in the Deno Deploy cloud) to run untrusted code with defense-in-depth security. You create or programmatically via our JavaScript or Python SDKs, and they boot in under a second. You can also interact with them via SSH, HTTP, or even open a VS Code window directly into the sandbox.&lt;/p&gt;
    &lt;code&gt;import { Sandbox } from "@deno/sandbox";

await using sandbox = await Sandbox.create();
await sandbox.sh`ls -lh /`;&lt;/code&gt;
    &lt;head rend="h2"&gt;Secrets That Can’t Be Stolen&lt;/head&gt;
    &lt;p&gt;But there is more. In Deno Sandbox, secrets never enter the environment. Code sees only a placeholder:&lt;/p&gt;
    &lt;code&gt;import { Sandbox } from "@deno/sandbox";

await using sandbox = await Sandbox.create({
  secrets: {
    OPENAI_API_KEY: {
      hosts: ["api.openai.com"],
      value: process.env.OPENAI_API_KEY,
    },
  },
});

await sandbox.sh`echo $OPENAI_API_KEY`;
// DENO_SECRET_PLACEHOLDER_b14043a2f578cba75ebe04791e8e2c7d4002fd0c1f825e19...&lt;/code&gt;
    &lt;p&gt;The real key materializes only when the sandbox makes an outbound request to an approved host. If prompt-injected code tries to exfiltrate that placeholder to &lt;code&gt;evil.com&lt;/code&gt;? Useless.&lt;/p&gt;
    &lt;head rend="h2"&gt;Network Egress Control&lt;/head&gt;
    &lt;p&gt;You can also restrict which hosts the sandbox can talk to:&lt;/p&gt;
    &lt;code&gt;await using sandbox = await Sandbox.create({
  allowNet: ["api.openai.com", "*.anthropic.com"],
});&lt;/code&gt;
    &lt;p&gt;Any request to an unlisted host gets blocked at the VM boundary.&lt;/p&gt;
    &lt;p&gt;Both features are implemented via an outbound proxy similar to coder/httpjail. This gives us a chokepoint for policy enforcement. We plan to add more capabilities here: analytics for outbound connections and programmatic hooks for trusted code to inspect or modify requests.&lt;/p&gt;
    &lt;p&gt;If you’re running untrusted JavaScript or TypeScript, combine this with Deno’s &lt;code&gt;--allow-net&lt;/code&gt; flag for defense in depth: VM-level network restrictions plus
runtime-level permissions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandbox to Production&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;sandbox.deploy()&lt;/code&gt; deploys code from your sandbox directly to Deno Deploy.&lt;/p&gt;
    &lt;code&gt;const build = await sandbox.deploy("my-app", {
  production: true,
  build: { mode: "none", entrypoint: "server.ts" },
});

const revision = await build.done;
console.log(revision.url);&lt;/code&gt;
    &lt;p&gt;One call to go from sandbox to production deployment. No rebuilding in a different CI system, no re-authenticating with a different tool. Just turn your dev environment directly into a production ready, auto-scaling serverless deployment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Persistence&lt;/head&gt;
    &lt;p&gt;Sandboxes are ephemeral by default, but when you need state we have you covered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Volumes: read-write storage for caches, databases, user data&lt;/item&gt;
      &lt;item&gt;Snapshots: read-only images for pre-installed toolchains and volume base&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run &lt;code&gt;apt-get install&lt;/code&gt; once, snapshot it, and every future sandbox boots with
everything already installed. Create read-write volumes from the snapshots to
create a fresh development environment in seconds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical Details&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Spec&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Regions&lt;/cell&gt;
        &lt;cell&gt;Amsterdam, Chicago&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vCPUs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;768 MB - 4 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Lifetime&lt;/cell&gt;
        &lt;cell&gt;Ephemeral or timeout (supports extending on demand)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Max lifetime&lt;/cell&gt;
        &lt;cell&gt;30 minutes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Boot time&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 1 second&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Perfect for AI agents executing code, vibe-coding environments, secure plugin systems, ephemeral CI runners, and customer-supplied code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pricing&lt;/head&gt;
    &lt;p&gt;Deno Sandbox is included in your Deno Deploy plan with competitive, usage-based pricing. You pay for compute time, not wall-clock time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;$0.05/h CPU time (40h included with Pro)&lt;/item&gt;
      &lt;item&gt;$0.016/GB-h memory (1000 GB-h included with Pro)&lt;/item&gt;
      &lt;item&gt;$0.20/GiB-month volume storage (5 GiB included with Pro)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Enterprise pricing available—contact deploy@deno.com.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Started&lt;/head&gt;
    &lt;p&gt;Deno Sandbox launches in beta today, alongside the general availability of Deno Deploy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Landing page: deno.com/sandbox&lt;/item&gt;
      &lt;item&gt;Docs: docs.deno.com/sandbox&lt;/item&gt;
      &lt;item&gt;JavaScript SDK: jsr.io/@deno/sandbox or npm&lt;/item&gt;
      &lt;item&gt;Python SDK: pypi.org/project/deno-sandbox&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’re excited to see what you (or your AI agents) build with Deno Sandbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://deno.com/blog/introducing-deno-sandbox"/><published>2026-02-03T17:33:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46874619</id><title>Xcode 26.3 – Developers can leverage coding agents directly in Xcode</title><updated>2026-02-04T16:33:12.252537+00:00</updated><content>&lt;doc fingerprint="bd64c349434690ed"&gt;
  &lt;main&gt;
    &lt;p&gt; UPDATE February 3, 2026 &lt;/p&gt;
    &lt;head rend="h1"&gt;Xcode 26.3 unlocks the power of agentic coding&lt;/head&gt;
    &lt;p&gt; Developers can leverage coding agents, including Anthropic’s Claude Agent and OpenAI’s Codex, directly in Xcode to tackle complex tasks autonomously, helping them develop apps faster than ever &lt;/p&gt;
    &lt;p&gt;Xcode 26.3 introduces support for agentic coding, a new way in Xcode for developers to build apps using coding agents such as Anthropic’s Claude Agent and OpenAI’s Codex. With agentic coding, Xcode can work with greater autonomy toward a developer’s goals — from breaking down tasks to making decisions based on the project architecture and using built-in tools. &lt;/p&gt;
    &lt;p&gt;Expanding on the intelligence features introduced in Xcode 26, which brought a brand-new coding assistant for writing and editing in Swift, this release gives coding agents access to even more of Xcode’s capabilities. Agents like Claude Agent and Codex can now collaborate throughout the entire development life cycle, giving developers the power to streamline workflows, iterate faster, and bring ideas to life like never before. Agents can search documentation, explore file structures, update project settings, and verify their work visually by capturing Xcode Previews and iterating through builds and fixes. &lt;/p&gt;
    &lt;p&gt;“At Apple, our goal is to make tools that put industry-leading technologies directly in developers’ hands so they can build the very best apps,” said Susan Prescott, Apple’s vice president of Worldwide Developer Relations. “Agentic coding supercharges productivity and creativity, streamlining the development workflow so developers can focus on innovation.” &lt;/p&gt;
    &lt;p&gt;With seamless access to Claude Agent and Codex, developers can bring the advanced reasoning of these models directly into their app-building workflow.1 This connection combines the power of these agents with Xcode’s native capabilities to provide the best results when developing for Apple platforms, giving developers the flexibility to work with the model that best fits their project. &lt;/p&gt;
    &lt;p&gt;In addition to these built-in integrations, Xcode 26.3 makes its capabilities available through the Model Context Protocol, an open standard that gives developers the flexibility to use any compatible agent or tool with Xcode. &lt;/p&gt;
    &lt;p&gt;Availability &lt;/p&gt;
    &lt;p&gt;Xcode 26.3 is available as a release candidate for all members of the Apple Developer Program starting today, with a release coming soon on the App Store. &lt;/p&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Images in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Anthropic and OpenAI’s terms of service may apply.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/"/><published>2026-02-03T18:04:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46875228</id><title>AliSQL: Alibaba's open-source MySQL with vector and DuckDB engines</title><updated>2026-02-04T16:33:11.829476+00:00</updated><content>&lt;doc fingerprint="3f90b0c4553671e2"&gt;
  &lt;main&gt;
    &lt;p&gt;AliSQL is Alibaba's MySQL branch, forked from official MySQL and used extensively in Alibaba Group's production environment. It includes various performance optimizations, stability improvements, and features tailored for large-scale applications.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Quickly build your DuckDB node: How to set up a DuckDB node&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AliSQL Version: 8.0.44 (LTS)&lt;/item&gt;
      &lt;item&gt;Based on: MySQL 8.0.44&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;DuckDB Storage Engine:AliSQL integrates DuckDB as a native storage engine, allowing users to operate DuckDB with the same experience as MySQL. By leveraging AliSQL for rapid deployment of DuckDB service nodes, users can easily achieve lightweight analytical capabilities.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vector Storage:AliSQL natively supports enterprise-grade vector processing for up to 16,383 dimensions. By integrating a highly optimized HNSW algorithm for high-performance Approximate Nearest Neighbor (ANN) search, AliSQL empowers users to build AI-driven applications—such as semantic search and recommendation systems—seamlessly using standard SQL interfaces.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;DDL Optimization (planned):AliSQL delivers a faster, safer, and lighter DDL experience through innovations such as enhanced Instant DDL, parallel B+tree construction, a non-blocking lock mechanism, and real-time DDL apply—significantly improving schema change efficiency and virtually eliminating replication lag.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;RTO Optimization (planned):AliSQL deeply optimizes the end-to-end crash recovery path to accelerate instance startup, shorten RTO, and restore service quickly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Replication Optimization (planned): AliSQL significantly boosts replication throughput and minimizes lag by implementing Binlog Parallel Flush, Binlog in Redo, and specialized optimizations for large transactions and DDL operations.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CMake 3.x or higher&lt;/item&gt;
      &lt;item&gt;Python3&lt;/item&gt;
      &lt;item&gt;C++17 compliant compiler (GCC 7+ or Clang 5+)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build Instructions:&lt;/p&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/alibaba/AliSQL.git
cd AliSQL

# Build the project (release build)
sh build.sh -t release -d /path/to/install/dir

# For development/debugging (debug build)
sh build.sh -t debug -d /path/to/install/dir

# Install the built MySQL server
make install&lt;/code&gt;
    &lt;p&gt;Build Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-t release|debug&lt;/code&gt;: Build type (default: debug)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-d &amp;lt;dest_dir&amp;gt;&lt;/code&gt;: Installation directory (default: /usr/local/alisql or $HOME/alisql)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-s &amp;lt;server_suffix&amp;gt;&lt;/code&gt;: Server suffix (default: alisql-dev)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-g asan|tsan&lt;/code&gt;: Enable sanitizer&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-c&lt;/code&gt;: Enable GCC coverage (gcov)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-h, --help&lt;/code&gt;: Show help&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Issues: https://github.com/alibaba/AliSQL/issues&lt;/item&gt;
      &lt;item&gt;Alibaba Cloud RDS: DuckDB-based Analytical Instance&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;For DuckDB-specific support, see the DuckDB Support Options.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;AliSQL 8.0 became an open-source project in December 2025 and is actively maintained by engineers at Alibaba Group.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch&lt;/item&gt;
      &lt;item&gt;Make your changes with appropriate tests&lt;/item&gt;
      &lt;item&gt;Submit a pull request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For bug reports and feature requests, please use the GitHub Issues page.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the GPL-2.0 license. See the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;AliSQL is based on MySQL, which is licensed under GPL-2.0. The DuckDB integration follows the same licensing terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/alibaba/AliSQL"/><published>2026-02-03T18:40:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46876105</id><title>Data centers in space makes no sense</title><updated>2026-02-04T16:33:11.572177+00:00</updated><content/><link href="https://civai.org/blog/space-data-centers"/><published>2026-02-03T19:37:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46877278</id><title>Tractor</title><updated>2026-02-04T16:33:10.557615+00:00</updated><content>&lt;doc fingerprint="a66f18365f273733"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Tractor&lt;/head&gt;Mon 19 January 2026&lt;p&gt;Tagged: cad, metalwork&lt;/p&gt;&lt;p&gt;The electric tractor is finished! I have been working on this on and off for about 6 months. It is a toy for children (and me) to drive around the garden.&lt;/p&gt;&lt;p&gt;Building the tractor has been fun for both me and Lucy. On many occasions she has asked "can we go and work on the tractor? right now?" and the two of us would go out to the garage and tinker with whatever was in progress at the time. Often she would get bored and go back in the house quite quickly, but that's par for the course for a 3-year-old. With any luck some of the philosophy of creation will rub off.&lt;/p&gt;&lt;head rend="h2"&gt;Specs&lt;/head&gt;&lt;p&gt;The tractor is powered by a 350W brushed DC motor with a 36v Li-ion ebike battery. You may be thinking that 350 watts doesn't sound very powerful, and you're right. It is a toy for children to drive around the garden, being slow is a feature not a bug.&lt;/p&gt;&lt;p&gt;The rear axle is solid, meaning the two rear wheels always turn together.&lt;/p&gt;&lt;p&gt;The front axle pivots around a pin in the centre, which keeps all 4 wheels on the ground when driving over uneven terrain.&lt;/p&gt;&lt;p&gt;It has a cable-operated disc brake on the rear axle which is very ineffective, but slightly better than not having a brake at all.&lt;/p&gt;&lt;p&gt;The seat position is adjustable, so that adults can just about squeeze on to it and toddlers can just about reach the pedals.&lt;/p&gt;&lt;p&gt;And the tractor has very poor handling characteristics if you're an adult, because all of your weight is over the solid rear axle and the rear tyres have much more grip than the front, so you have to lean forwards to make it steer. For a while I had one of the rear wheels free-wheeling, which makes it steer better, but means it sometimes gets stuck on hills where you can't drive forwards, you can only wheelie to the side, which on balance is worse. I expect it's not as bad for small children because they're a.) not as heavy, and b.) sitting further forwards anyway.&lt;/p&gt;&lt;head rend="h2"&gt;Chassis&lt;/head&gt;&lt;p&gt;The core of the chassis is a plywood box which is open at the bottom.&lt;/p&gt;&lt;p&gt;In this picture you can see the pin that the front axle pivots on:&lt;/p&gt;&lt;p&gt;And you can see the pencil lines that roughly show the limits of motion of the lower edge of the axle beam.&lt;/p&gt;&lt;p&gt;I believe the front wheels are for a sack truck, this sort of thing:&lt;/p&gt;&lt;p&gt;They are very cheap, a pair of wheels with tyres and hubs and bearings (brand new) on eBay is only Â£12 including postage.&lt;/p&gt;&lt;head rend="h2"&gt;Steering&lt;/head&gt;&lt;p&gt;I tried to copy the steering arrangement from a Ferguson TE20, which originally was my reference design for the canonical tractor, although I obviously went over to the dark side with the colour scheme.&lt;/p&gt;&lt;p&gt;The TE20 steering wheel goes down to a gearbox quite near the driver, a shaft comes out each side, one turning clockwise and the other anticlockwise (as viewed from one fixed reference side), an arm off each shaft holds one end of a track rod, and the other end of the track rod is connected to an arm on the stub axle kingpin thing. Highlighted in red here:&lt;/p&gt;&lt;p&gt;To replicate this I made a steering gearbox using angle grinder gears.&lt;/p&gt;&lt;p&gt;(The yellow one is a test print - the final one is in black Polymaker PC-Max material with heavy wall thickness and lots of infill).&lt;/p&gt;&lt;p&gt;Angle grinder gears are available cheaply and are a good way to buy high-quality bevel gears in about a 3:1 ratio, if you don't need them to be particularly heavy duty.&lt;/p&gt;&lt;p&gt;One issue with my steering gearbox is that there is no way to install it in the chassis because the shafts stick out the sides. This was an oversight, in CAD there is no difficulty. The solution is to assemble the parts in place inside the chassis. This is inconvenient in the extreme and if I were to do it again I would try to make it removable.&lt;/p&gt;&lt;p&gt;The arms that mount on the shafts are made of 3mm thick mild steel flat bar, bent around a rod, and then drilled for a mounting hole for the rod end, and drilled and cut to make a split-clamp for the steering shaft and kingpin.&lt;/p&gt;&lt;p&gt;This is effective and relatively easy to make, doesn't even require any machining, I'd do this again. The only drawback is that there's not a convenient way to key it to the shaft.&lt;/p&gt;&lt;p&gt;Originally I was planning to figure out a way to key it to the shaft after I had got the steering geometry sorted out, and therefore after I knew the angle that it wanted to be keyed at, but I have since realised that having these joints able to slip in the event of a crash is an "engineered failure" that prevents destroying the plastic gearbox. So I'm leaving it as it is.&lt;/p&gt;&lt;p&gt;I made the steering wheel myself.&lt;/p&gt;&lt;p&gt;It consists of 2 CNC aluminium parts, one is just a ring, and the other is the 3-pronged part for the centre of the wheel. The 3-pronged part is then bent so that the prongs sit at the right diameter, and then the 3d-printed grips are added each side, with a bolt on each prong holding the whole stack together. It is relatively flimsy, I probably wouldn't do it this way again.&lt;/p&gt;&lt;head rend="h2"&gt;Rear axle&lt;/head&gt;&lt;p&gt;The rear wheels are ride-on lawnmower rear wheels. They fit a 19mm axle, which annoyingly is not a size that I was able to buy cheap pillow block bearings for. In hindsight, maybe they actually fit a 3/4" axle and it would have been easy? In any case, I don't want to deliberately construct objects with imperial measurements, that's just trouble for everyone.&lt;/p&gt;&lt;p&gt;So instead I went with a 20mm axle, and 20mm pillow block bearings, but turned the ends down to 19mm to suit the wheels.&lt;/p&gt;&lt;p&gt;I thought this would be easy because I was labouring under the misapprehension that a 20mm shaft would fit through the spindle bore on my mini lathe. It does not! It's very close, but it doesn't fit. Possibly you could bore out the spindle bore slightly so that it would fit, but I didn't think of that at the time, and probably it is hardened.&lt;/p&gt;&lt;p&gt;So it can't go through the spindle bore. And the axle is too long to support the loose end with the tailstock on my lathe.&lt;/p&gt;&lt;p&gt;So my solution was to support the loose end with a plastic bush in a piece of wood clamped in the vice, and kick the tail end of the lathe around to square it up until it's not turning a taper. This actually worked very well and I ended up with a taper going from 18.94mm to 18.97mm over 150mm length, which for all I know is as parallel as I turn anything at the best of times. See this video clip.&lt;/p&gt;&lt;p&gt;And then the only part I can't turn down to 19mm is the tiny bit at the headstock end which is clamped in the collet, which I filed down to match the 19mm diameter after I was finished with the rest of it.&lt;/p&gt;&lt;p&gt;The rear wheels have 2 flats in their bores to key them to the axle. I machined matching flats on the axle with my homemade CNC machine.&lt;/p&gt;&lt;p&gt;The wheels are kept from sliding off the axle by split pins, one just outside each wheel.&lt;/p&gt;&lt;p&gt;And then the axle also has carriers for the sprocket and the brake disc.&lt;/p&gt;&lt;p&gt;I originally mounted both of these by making an M6 tapped cross-drilled hole in the axle, and making a hub with a 6mm cross-drilled hole through it, and then bolting the hub to the axle. This provides both axial location and torque transmission so I thought it was a simple and effective solution.&lt;/p&gt;&lt;p&gt;You can see the head of the bolt fixing the sprocket carrier to the axle in this pic:&lt;/p&gt;&lt;p&gt;Unfortunately fixing a hub to the axle with a single bolt through a hole is not adequate because the shear force is very large. Eventually the bolt holding the sprocket on snapped. I replaced it with a new bolt and it snapped again, so then I welded the carrier to the axle.&lt;/p&gt;&lt;p&gt;It hasn't snapped yet.&lt;/p&gt;&lt;head rend="h2"&gt;Countershaft&lt;/head&gt;&lt;p&gt;Originally I thought it would work if the motor drove the rear axle with just a chain and sprockets, but I had missed out a factor of Pi in my calculation. Having the motor drive the rear axle requires about a 30:1 reduction, which is far too extreme, would require a rear sprocket with about 300 teeth. So I added a countershaft to gain back the factor of ~3.&lt;/p&gt;&lt;p&gt;You can see the countershaft in this pic:&lt;/p&gt;&lt;p&gt;It is supported by a couple of small pillow block bearings on a big piece of steel box section.&lt;/p&gt;&lt;p&gt;The shaft is simply an M12 bolt. The large sprocket is bolted to a big piece of aluminium, which is keyed to the bolt with a hexagon machined into the centre, which the bolt head is hammered into. And the small sprocket has a couple of flats on it, rather like the rear wheels, and I filed matching flats onto the threads at the end of the bolt.&lt;/p&gt;&lt;head rend="h2"&gt;Reverse&lt;/head&gt;&lt;p&gt;The motor controller that I got doesn't have a way to reverse the motor, so I implemented reverse by putting an "on-off-on" DPDT switch in the wires that go to the motor, so that in one position positive and negative connect to the motor one way, in the middle position it's disconnected, and in the third position the polarity is reversed. This works fine but you need to make sure your switch can handle the current. In my case it's not too hard because 350W at 36V is only 10 amps.&lt;/p&gt;&lt;p&gt;You can see the switch sticking up from underneath the chassis here:&lt;/p&gt;&lt;p&gt;(It has a black rubbery cover).&lt;/p&gt;&lt;p&gt;I later added a lever so that it is easier to switch:&lt;/p&gt;&lt;p&gt;The lever has no actual bearings, it just rides in holes drilled in the wood. This is more than adequate for the kind of speeds and loads that a gear lever experiences, which are basically zero. The holes just need to constrain its location. A bonus is that the natural friction in the holes prevents the lever from rattling around.&lt;/p&gt;&lt;p&gt;I did add a gate to indicate the selection, and constrain the movement to prevent damaging the switch:&lt;/p&gt;&lt;p&gt;The text is done with multicolour printing on the Bambu X1 Carbon.&lt;/p&gt;&lt;head rend="h2"&gt;Brake&lt;/head&gt;&lt;p&gt;I think the brake is from a mini moto. It doesn't work very well and I haven't done a very good job of fitting it.&lt;/p&gt;&lt;p&gt;You can pretty much see how it works in this pic:&lt;/p&gt;&lt;p&gt;The pedal on the left-hand side (right-hand side in pic) pulls on the cable, which then pulls on the lever on the caliper, which presses the pads against the disc.&lt;/p&gt;&lt;p&gt;Like the gear lever, the shaft is not on any sort of bearing, it just pivots in holes drilled in the wood. I think this is also fine for the brake, because it doesn't get much use, although the force on the brake pedal is much higher than on the gear lever. If the pivots do get worn out then they can easily be drilled out and bushed.&lt;/p&gt;&lt;head rend="h2"&gt;Bonnet&lt;/head&gt;&lt;p&gt;I put off making the bonnet for a good while because I originally wanted to do something like a Ferguson TE20 bonnet:&lt;/p&gt;&lt;p&gt;But I couldn't work out how to do all the curves. My best plan was to break up the design into large flat surfaces and small curved surfaces, and make the large flat parts out of plywood and 3d print the small curved parts and somehow join them together and body-fill over the crimes.&lt;/p&gt;&lt;p&gt;But then Lucy acquired this toy tractor:&lt;/p&gt;&lt;p&gt;And I saw that there is no need for the complex compound curves. Just a single curve will do.&lt;/p&gt;&lt;p&gt;So I tried to form the curved part with "kerf bending", but:&lt;/p&gt;&lt;p&gt;It instantly snapped instead of bending. I think I had the grain in the outer layer of plywood running in the wrong direction. It might have bent nicely if it was the other way.&lt;/p&gt;&lt;p&gt;In for a penny, in for a pound, I carried on:&lt;/p&gt;&lt;p&gt;And actually that was starting to look like I might get away with it. So I filled the gaps with glue to make it hold its shape.&lt;/p&gt;&lt;p&gt;And after a few rounds of body-filling and sanding, I was actually really pleased with the result.&lt;/p&gt;&lt;head rend="h2"&gt;Throttle conditioner&lt;/head&gt;&lt;p&gt;The throttle response is very dissatisfying. It starts off from a standstill with quite a violent kick and then immediately tapers off into having hardly any power at all.&lt;/p&gt;&lt;p&gt;So the plan was to make an Arduino project that would take the throttle position as input and output a "conditioned" throttle position as output, which would ramp up gradually as you initially apply the throttle.&lt;/p&gt;&lt;p&gt;The throttle conditioner is in the yellow box here:&lt;/p&gt;&lt;p&gt;While it did work, it also somehow prevented the throttle from ever reaching 100%. The throttle position is transmitted as an analogue signal, and I think the analogue output of the Arduino topped out at a lower voltage than 100% throttle. I didn't care to fix it, and I realised that this was an unnecessary complexity, so I just removed the electronics.&lt;/p&gt;&lt;p&gt;I even had a magnet and sensor to detect when it was changed between forwards and reverse so that it would instantly cut the throttle when you change direction to avoid damage.&lt;/p&gt;&lt;p&gt;But this is not the way. A machine should obey the will of its operator, not its constructor, and it is incumbent on the operator not to operate in a way that damages the machine.&lt;/p&gt;&lt;head rend="h2"&gt;Painting&lt;/head&gt;&lt;p&gt;I despise painting. It is one of those jobs that takes way longer than it feels like it ought to.&lt;/p&gt;&lt;p&gt;Step 1: disassemble the completed tractor.&lt;/p&gt;&lt;p&gt;Step 2: brush paint white "knot-block" primer onto the chassis.&lt;/p&gt;&lt;p&gt;Step 3: spray grey primer on everything.&lt;/p&gt;&lt;p&gt;Step 4: draw the rest of the owl.&lt;/p&gt;&lt;head rend="h2"&gt;Welding&lt;/head&gt;&lt;p&gt;It's a long time since I did a lot of welding, and my welds on this tractor are rather poor.&lt;/p&gt;&lt;p&gt;I have experimented with the welder today and discovered that my prior mental model about how the welder works was totally wrong. I had thought that turning up the voltage would make it "hotter", and turning up the wire speed would make it "build up more material". As if it's a 3d printer extruder and voltage sets temperature and wire speed sets extrusion feed rate. But that's not how it works at all! In fact turning up the wire speed makes it hotter, and turning down the voltage makes it build up more material. I don't really understand the physics of why that is the case, but at least I know how to control the machine now.&lt;/p&gt;&lt;p&gt;If you like my blog, please consider subscribing to the RSS feed or the mailing list:&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://incoherency.co.uk/blog/stories/tractor.html"/><published>2026-02-03T21:04:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46881264</id><title>I miss thinking hard</title><updated>2026-02-04T16:33:10.436522+00:00</updated><content>&lt;doc fingerprint="a30c82936f7a0d9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I miss thinking hard.&lt;/head&gt;
    &lt;p&gt;Before you read this post, ask yourself a question: When was the last time you truly thought hard?&lt;/p&gt;
    &lt;p&gt;By “thinking hard,” I mean encountering a specific, difficult problem and spending multiple days just sitting with it to overcome it.&lt;/p&gt;
    &lt;p&gt;a) All the time. b) Never. c) Somewhere in between.&lt;/p&gt;
    &lt;p&gt;If your answer is (a) or (b), this post isn't for you. But if, like me, your response is (c), you might get something out of this, if only the feeling that you aren't alone.&lt;/p&gt;
    &lt;p&gt;First, a disclaimer: this post has no answers, not even suggestions. It is simply a way to vent something I've been feeling for the last few months.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Builder and The Thinker&lt;/head&gt;
    &lt;p&gt;I believe my personality is built on two primary traits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The Builder (The desire to create, ship, and be pragmatic).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Thinker (The need for deep, prolonged mental struggle).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The builder is pretty self explanatory, it’s motivated by velocity and utility. It is the part of me that craves the transition from “idea” to “reality.” It loves the dopamine hit of a successful deploy, the satisfaction of building systems to solve real problems, and the knowledge that someone, somewhere, is using my tool.&lt;/p&gt;
    &lt;p&gt;To explain the Thinker , I need to go back to my university days studying physics. Every now and then, we would get homework problems that were significantly harder than average. Even if you had a decent grasp of the subject, just coming up with an approach was difficult.&lt;/p&gt;
    &lt;p&gt;I observed that students fell into three categories when facing these problems (well, four, if you count the 1% of geniuses for whom no problem was too hard).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Type 1: The majority. After a few tries, they gave up and went to the professor or a TA for help.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Type 2: The Researchers. They went to the library to look for similar problems or insights to make the problem approachable. They usually succeeded.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Type 3: The Thinkers.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I fell into the third category, which, in my experience, was almost as rare as the genius 1%. My method was simply to think. To think hard and long. Often for several days or weeks, all my non-I/O brain time was relentlessly chewing on possible ways to solve the problem, even while I was asleep.&lt;/p&gt;
    &lt;p&gt;This method never failed me. I always felt that deep prolonged thinking was my superpower. I might not be as fast or naturally gifted as the top 1%, but given enough time, I was confident I could solve anything. I felt a deep satisfaction in that process.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Conflict with AI&lt;/head&gt;
    &lt;p&gt;That satisfaction is why software engineering was initially so gratifying. It hit the right balance. It satisfied The Builder (feeling productive and pragmatic by creating useful things) and The Thinker (solving really hard problems). Thinking back, the projects where I grew the most as an engineer were always the ones with a good number of really hard problems that needed creative solutions.&lt;/p&gt;
    &lt;p&gt;But recently, the number of times I truly ponder a problem for more than a couple of hours has decreased tremendously.&lt;/p&gt;
    &lt;p&gt;Yes, I blame AI for this.&lt;/p&gt;
    &lt;p&gt;I am currently writing much more, and more complicated software than ever, yet I feel I am not growing as an engineer at all. When I started meditating on why I felt “stuck,” I realized I am starving The Thinker.&lt;/p&gt;
    &lt;p&gt;“Vibe coding” satisfies the Builder. It feels great to see to pass from idea to reality in a fraction of a time that would take otherwise. But it has drastically cut the times I need to came up with creative solutions for technical problems. I know many people who are purely Builders, for them this era is the best thing that ever happened. But for me, something is missing.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Trap of Pragmatism&lt;/head&gt;
    &lt;p&gt;I know what you might be thinking: "If you can ‘vibe code’ your way through it, the problem wasn’t actually hard."&lt;/p&gt;
    &lt;p&gt;I think that misses the point. It’s not that AI is good for hard problems, it’s not even that good for easy problems. I’m confident that my third manual rewrite of a module would be much better than anything the AI can output. But I am also a pragmatist.&lt;/p&gt;
    &lt;p&gt;If I can get a solution that is “close enough” in a fraction of the time and effort, it is irrational not to take the AI route. And that is the real problem: I cannot simply turn off my pragmatism.&lt;/p&gt;
    &lt;p&gt;At the end of the day, I am a Builder. I like building things. The faster I build, the better. Even if I wanted to reject AI and go back to the days where the Thinker's needs were met by coding, the Builder in me would struggle with the inefficiency.&lt;/p&gt;
    &lt;p&gt;Even though the AI almost certainly won't come up with a 100% satisfying solution, the 70% solution it achieves usually hits the “good enough” mark.&lt;/p&gt;
    &lt;head rend="h3"&gt;So, what now?&lt;/head&gt;
    &lt;p&gt;To be honest, I don’t know. I am still figuring it out.&lt;/p&gt;
    &lt;p&gt;I'm not sure if my two halves can be satisfied by coding anymore. You can always aim for harder projects, hoping to find problems where AI fails completely. I still encounter those occasionally, but the number of problems requiring deep creative solutions feels like it is diminishing rapidly.&lt;/p&gt;
    &lt;p&gt;I have tried to get that feeling of mental growth outside of coding. I tried getting back in touch with physics, reading old textbooks. But that wasn’t successful either. It is hard to justify spending time and mental effort solving physics problems that aren’t relevant or state-of-the-art when I know I could be building things.&lt;/p&gt;
    &lt;p&gt;My Builder side won’t let me just sit and think about unsolved problems, and my Thinker side is starving while I vibe-code. I am not sure if there will ever be a time again when both needs can be met at once.&lt;/p&gt;
    &lt;p&gt;- Philipp Mainländer&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jernesto.com/articles/thinking_hard"/><published>2026-02-04T03:54:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46882389</id><title>Show HN: Ghidra MCP Server – 110 tools for AI-assisted reverse engineering</title><updated>2026-02-04T16:33:09.994689+00:00</updated><content>&lt;doc fingerprint="a983aa63ae7fb788"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;If you find this useful, please ⭐ star the repo — it helps others discover it!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A production-ready Model Context Protocol (MCP) server that bridges Ghidra's powerful reverse engineering capabilities with modern AI tools and automation frameworks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full MCP Compatibility - Complete implementation of Model Context Protocol&lt;/item&gt;
      &lt;item&gt;110 MCP Tools Available - Comprehensive API surface for binary analysis&lt;/item&gt;
      &lt;item&gt;Production-Ready Reliability - Tested batch operations and atomic transactions&lt;/item&gt;
      &lt;item&gt;Real-time Analysis - Live integration with Ghidra's analysis engine&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Function Analysis - Decompilation, call graphs, cross-references&lt;/item&gt;
      &lt;item&gt;Data Structure Discovery - Automatic struct/union/enum creation&lt;/item&gt;
      &lt;item&gt;String Extraction - Comprehensive string analysis and categorization&lt;/item&gt;
      &lt;item&gt;Import/Export Analysis - Symbol table and library dependency mapping&lt;/item&gt;
      &lt;item&gt;Memory Mapping - Complete memory layout documentation&lt;/item&gt;
      &lt;item&gt;Cross-Binary Documentation - Function hash matching across binary versions&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated Development Cycle - Complete build-test-deploy-verify pipeline&lt;/item&gt;
      &lt;item&gt;Ghidra Script Management - Create, run, and manage Ghidra scripts via MCP&lt;/item&gt;
      &lt;item&gt;Multi-Program Support - Switch between and compare multiple open programs&lt;/item&gt;
      &lt;item&gt;Batch Operations - Efficient bulk renaming, commenting, and typing&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Java 21 LTS (OpenJDK recommended)&lt;/item&gt;
      &lt;item&gt;Apache Maven 3.9+&lt;/item&gt;
      &lt;item&gt;Ghidra 12.0.2 (or compatible version)&lt;/item&gt;
      &lt;item&gt;Python 3.8+ with pip&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Clone the repository:&lt;/p&gt;
        &lt;code&gt;git clone https://github.com/bethington/ghidra-mcp.git cd ghidra-mcp&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install Python dependencies:&lt;/p&gt;
        &lt;quote&gt;pip install -r requirements.txt&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Copy Ghidra libraries (see Library Dependencies for full list):&lt;/p&gt;
        &lt;quote&gt;# Windows - run the provided batch script copy-ghidra-libs.bat "C:\path\to\ghidra_12.0.2_PUBLIC" # Linux/Mac - copy manually from your Ghidra installation # See Library Dependencies section below for all 14 required JARs&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Build the plugin:&lt;/p&gt;
        &lt;quote&gt;mvn clean package assembly:single -DskipTests&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deploy to Ghidra:&lt;/p&gt;
        &lt;quote&gt;# Windows (automated) .\deploy-to-ghidra.ps1 # Or manually copy to Ghidra Extensions Copy-Item target\GhidraMCP-2.0.0.zip "C:\ghidra\Extensions\Ghidra\"&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;python bridge_mcp_ghidra.py&lt;/code&gt;
    &lt;code&gt;python bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start Ghidra and load a binary&lt;/item&gt;
      &lt;item&gt;Go to Tools &amp;gt; GhidraMCP &amp;gt; Start MCP Server&lt;/item&gt;
      &lt;item&gt;The server runs on &lt;code&gt;http://127.0.0.1:8080/&lt;/code&gt;by default&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MCP Tools: 110 tools fully implemented&lt;/item&gt;
      &lt;item&gt;Speed: Sub-second response for most operations&lt;/item&gt;
      &lt;item&gt;Efficiency: 93% reduction in API calls via batch operations&lt;/item&gt;
      &lt;item&gt;Reliability: Atomic transactions with all-or-nothing semantics&lt;/item&gt;
      &lt;item&gt;Deployment: Automated version-aware deployment script&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;check_connection&lt;/code&gt;- Verify MCP connectivity&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_metadata&lt;/code&gt;- Program metadata and info&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_version&lt;/code&gt;- Server version information&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_entry_points&lt;/code&gt;- Binary entry points discovery&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_functions&lt;/code&gt;- List all functions (paginated)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_functions_by_name&lt;/code&gt;- Search functions by name/pattern&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_functions_enhanced&lt;/code&gt;- Advanced function search with filters&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;decompile_function&lt;/code&gt;- Decompile function to C pseudocode&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_decompiled_code&lt;/code&gt;- Get decompiled code by address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_callers&lt;/code&gt;- Get function callers&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_callees&lt;/code&gt;- Get function callees&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_call_graph&lt;/code&gt;- Function relationship graph&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_full_call_graph&lt;/code&gt;- Complete call graph for program&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_function_complete&lt;/code&gt;- Comprehensive function analysis&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_function_completeness&lt;/code&gt;- Documentation completeness score&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_segments&lt;/code&gt;- Memory segments and layout&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_by_address&lt;/code&gt;- Function at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;disassemble_function&lt;/code&gt;- Disassembly listing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;disassemble_bytes&lt;/code&gt;- Raw byte disassembly&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_xrefs_to&lt;/code&gt;- Cross-references to address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_xrefs_from&lt;/code&gt;- Cross-references from address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_bulk_xrefs&lt;/code&gt;- Bulk cross-reference lookup&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_data_region&lt;/code&gt;- Analyze memory region structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;inspect_memory_content&lt;/code&gt;- View raw memory content&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;detect_array_bounds&lt;/code&gt;- Detect array boundaries&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;get_function_hash&lt;/code&gt;- SHA-256 hash of normalized function opcodes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_bulk_function_hashes&lt;/code&gt;- Paginated bulk hashing with filter&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_documentation&lt;/code&gt;- Export complete function documentation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;apply_function_documentation&lt;/code&gt;- Import documentation to target function&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;build_function_hash_index&lt;/code&gt;- Build persistent JSON index&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lookup_function_by_hash&lt;/code&gt;- Find matching functions in index&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;propagate_documentation&lt;/code&gt;- Apply docs to all matching instances&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_data_types&lt;/code&gt;- Available data types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_data_types&lt;/code&gt;- Search for data types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_struct&lt;/code&gt;- Create custom structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;add_struct_field&lt;/code&gt;- Add field to structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;modify_struct_field&lt;/code&gt;- Modify existing field&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;remove_struct_field&lt;/code&gt;- Remove field from structure&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_enum&lt;/code&gt;- Create enumeration&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_enum_values&lt;/code&gt;- Get enumeration values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_array_type&lt;/code&gt;- Create array data type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;apply_data_type&lt;/code&gt;- Apply type to address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delete_data_type&lt;/code&gt;- Delete a data type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;consolidate_duplicate_types&lt;/code&gt;- Merge duplicate types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_valid_data_types&lt;/code&gt;- Get list of valid Ghidra types&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_imports&lt;/code&gt;- Imported symbols and libraries&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_exports&lt;/code&gt;- Exported symbols and functions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_external_locations&lt;/code&gt;- External location references&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_strings&lt;/code&gt;- Extracted strings with analysis&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_namespaces&lt;/code&gt;- Available namespaces&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_globals&lt;/code&gt;- Global variables&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_label&lt;/code&gt;- Create label at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_create_labels&lt;/code&gt;- Bulk label creation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delete_label&lt;/code&gt;- Delete label at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_delete_labels&lt;/code&gt;- Bulk label deletion&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_label&lt;/code&gt;- Rename existing label&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_or_label&lt;/code&gt;- Rename or create label&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;rename_function&lt;/code&gt;- Rename function by name&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_function_by_address&lt;/code&gt;- Rename function by address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_data&lt;/code&gt;- Rename data item&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_variables&lt;/code&gt;- Rename function variables&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_global_variable&lt;/code&gt;- Rename global variable&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename_external_location&lt;/code&gt;- Rename external reference&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_rename_function_components&lt;/code&gt;- Bulk renaming&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_decompiler_comment&lt;/code&gt;- Set decompiler comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_disassembly_comment&lt;/code&gt;- Set disassembly comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_plate_comment&lt;/code&gt;- Set function plate comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_plate_comment&lt;/code&gt;- Get function plate comment&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_set_comments&lt;/code&gt;- Bulk comment setting&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;set_function_prototype&lt;/code&gt;- Set function signature&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_local_variable_type&lt;/code&gt;- Set variable type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_parameter_type&lt;/code&gt;- Set parameter type&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_set_variable_types&lt;/code&gt;- Bulk type setting&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_variable_storage&lt;/code&gt;- Control variable storage location&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;set_function_no_return&lt;/code&gt;- Mark function as non-returning&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_calling_conventions&lt;/code&gt;- Available calling conventions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_variables&lt;/code&gt;- Get all function variables&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_labels&lt;/code&gt;- Get labels in function&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_scripts&lt;/code&gt;- List available scripts&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;run_script&lt;/code&gt;- Run a script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_ghidra_scripts&lt;/code&gt;- List custom Ghidra scripts&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;save_ghidra_script&lt;/code&gt;- Save new script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_ghidra_script&lt;/code&gt;- Get script contents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;run_ghidra_script&lt;/code&gt;- Execute Ghidra script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;update_ghidra_script&lt;/code&gt;- Update existing script&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delete_ghidra_script&lt;/code&gt;- Delete script&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;list_open_programs&lt;/code&gt;- List all open programs&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_current_program_info&lt;/code&gt;- Current program details&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;switch_program&lt;/code&gt;- Switch active program&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;list_project_files&lt;/code&gt;- List project files&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;open_program&lt;/code&gt;- Open program from project&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;compare_programs_documentation&lt;/code&gt;- Compare documentation between programs&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;find_next_undefined_function&lt;/code&gt;- Find undefined functions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;find_undocumented_by_string&lt;/code&gt;- Find functions by string reference&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;batch_string_anchor_report&lt;/code&gt;- String anchor analysis&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;search_byte_patterns&lt;/code&gt;- Search for byte patterns&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_assembly_context&lt;/code&gt;- Get assembly context&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;analyze_struct_field_usage&lt;/code&gt;- Analyze structure field access&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_field_access_context&lt;/code&gt;- Get field access patterns&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;create_function&lt;/code&gt;- Create function at address&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_function_jump_target_addresses&lt;/code&gt;- Get jump targets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See docs/README.md for complete documentation.&lt;/p&gt;
    &lt;code&gt;┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   AI/Automation │◄──►│   MCP Bridge    │◄──►│  Ghidra Plugin  │
│     Tools       │    │ (bridge_mcp_    │    │ (GhidraMCP.jar) │
│  (Claude, etc.) │    │  ghidra.py)     │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
   MCP Protocol            HTTP REST              Ghidra API
   (stdio/SSE)          (localhost:8080)      (Program, Listing)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;bridge_mcp_ghidra.py - Python MCP server that translates MCP protocol to HTTP calls&lt;/item&gt;
      &lt;item&gt;GhidraMCP.jar - Ghidra plugin that exposes analysis capabilities via HTTP&lt;/item&gt;
      &lt;item&gt;ghidra_scripts/ - Collection of 70+ automation scripts for common tasks&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Build the plugin (skip integration tests)
mvn clean package assembly:single -DskipTests

# Deploy to Ghidra
.\deploy-to-ghidra.ps1&lt;/code&gt;
    &lt;code&gt;ghidra-mcp/
├── bridge_mcp_ghidra.py     # MCP server (Python)
├── src/main/java/           # Ghidra plugin (Java)
├── lib/                     # Ghidra library dependencies
├── ghidra_scripts/          # 70+ automation scripts
├── docs/                    # Documentation
│   ├── prompts/            # AI workflow prompts
│   ├── releases/           # Version release notes
│   └── project-management/ # Project docs
├── examples/                # Example usage
└── scripts/                 # Build/utility scripts
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;lib/&lt;/code&gt; folder must contain Ghidra JAR files for compilation. Run the provided script to copy them from your Ghidra installation:&lt;/p&gt;
    &lt;code&gt;# Windows
copy-ghidra-libs.bat "C:\path\to\ghidra_12.0.2_PUBLIC"

# Or manually copy from your Ghidra installation&lt;/code&gt;
    &lt;p&gt;Required Libraries (14 JARs, ~37MB):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Library&lt;/cell&gt;
        &lt;cell role="head"&gt;Source Path&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Base.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/Base/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Core Ghidra functionality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Decompiler.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/Decompiler/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Decompilation engine&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PDB.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/PDB/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Microsoft PDB symbol support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FunctionID.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Features/FunctionID/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Function identification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;SoftwareModeling.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/SoftwareModeling/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Program model API&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Project.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Project/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Project management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Docking.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Docking/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;UI docking framework&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Generic.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Generic/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Generic utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Utility.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Utility/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Core utilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Gui.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Gui/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GUI components&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FileSystem.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/FileSystem/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;File system support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Graph.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Graph/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Graph/call graph analysis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DB.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/DB/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Database operations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Emulation.jar&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Framework/Emulation/lib/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;P-code emulation&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;&lt;p&gt;Note: Libraries are NOT included in the repository (see&lt;/p&gt;&lt;code&gt;.gitignore&lt;/code&gt;). You must copy them from your Ghidra installation before building.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated Deployment: Version-aware deployment script&lt;/item&gt;
      &lt;item&gt;Batch Operations: Reduces API calls by 93%&lt;/item&gt;
      &lt;item&gt;Atomic Transactions: All-or-nothing semantics&lt;/item&gt;
      &lt;item&gt;Comprehensive Logging: Debug and trace capabilities&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation Index - Complete documentation navigation&lt;/item&gt;
      &lt;item&gt;Project Structure - Project organization guide&lt;/item&gt;
      &lt;item&gt;Naming Conventions - Code naming standards&lt;/item&gt;
      &lt;item&gt;Hungarian Notation - Variable naming guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompts Overview - AI prompting system guide&lt;/item&gt;
      &lt;item&gt;Function Documentation Workflow - Complete workflow&lt;/item&gt;
      &lt;item&gt;Quick Start Prompt - Simplified beginner workflow&lt;/item&gt;
      &lt;item&gt;Cross-Version Matching - Hash-based matching&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complete Changelog - All version release notes&lt;/item&gt;
      &lt;item&gt;Release Notes - Detailed release documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See CONTRIBUTING.md for detailed contribution guidelines.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch (&lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Build and test your changes (&lt;code&gt;mvn clean package assembly:single -DskipTests&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Update documentation as needed&lt;/item&gt;
      &lt;item&gt;Commit your changes (&lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Push to the branch (&lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Open a Pull Request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Version&lt;/cell&gt;
        &lt;cell&gt;2.0.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MCP Tools&lt;/cell&gt;
        &lt;cell&gt;110 fully implemented&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Compilation&lt;/cell&gt;
        &lt;cell&gt;✅ 100% success&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Batch Efficiency&lt;/cell&gt;
        &lt;cell&gt;93% API call reduction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Ghidra Scripts&lt;/cell&gt;
        &lt;cell&gt;70+ automation scripts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Documentation&lt;/cell&gt;
        &lt;cell&gt;Comprehensive with AI prompts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See CHANGELOG.md for version history and release notes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ghidra Team - For the incredible reverse engineering platform&lt;/item&gt;
      &lt;item&gt;Model Context Protocol - For the standardized AI integration framework&lt;/item&gt;
      &lt;item&gt;Contributors - For testing, feedback, and improvements&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;re-universe — Ghidra BSim PostgreSQL platform for large-scale binary similarity analysis. Pairs perfectly with GhidraMCP for AI-driven reverse engineering workflows.&lt;/item&gt;
      &lt;item&gt;cheat-engine-server-python — MCP server for dynamic memory analysis and debugging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ready for production deployment with enterprise-grade reliability and comprehensive binary analysis capabilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/bethington/ghidra-mcp"/><published>2026-02-04T06:51:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46883337</id><title>Broken Proofs and Broken Provers</title><updated>2026-02-04T16:33:09.831667+00:00</updated><content>&lt;doc fingerprint="c709d2bd96ec1315"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Broken proofs and broken provers&lt;/head&gt;[&lt;code&gt;&lt;nobr&gt;general&lt;/nobr&gt;&lt;/code&gt; 
  
    
    &lt;code&gt;&lt;nobr&gt;verification&lt;/nobr&gt;&lt;/code&gt; 
  
    
    &lt;code&gt;&lt;nobr&gt;Isabelle&lt;/nobr&gt;&lt;/code&gt; 
  
    
    &lt;code&gt;&lt;nobr&gt;memories&lt;/nobr&gt;&lt;/code&gt; 
  
]

&lt;p&gt;People expect perfection. Consider the reaction when someone who has been vaccinated against a particular disease nevertheless dies of it. Mathematical proof carries the aura of perfection, but again people’s expectations will sometimes be dashed. As outlined in an earlier post, the verification of a real world system is never finished. We can seldom capture 100% of reality, so failure remains possible. Even in a purely mathematical proof, there are plenty of ways to screw up. Plus, proof assistants have bugs.&lt;/p&gt;&lt;head rend="h3"&gt;Some badly broken proofs&lt;/head&gt;&lt;p&gt;Many years ago, I refereed a paper about the verification of some obscure application. I recall that the theoretical framework depended on several parameters, among them $z$, a nonzero complex number. This context was repeated for all the theorems in the paper: each included the assumption $\forall z.\, z\not=0$. Needless to say, that assumption is flatly false. The author of the paper had presumably intended to write something like $\forall z.\, z\not=0 \to \cdots$. The error is easy to overlook, and I only became suspicious because the proofs looked too simple. The entire development was invalid.&lt;/p&gt;&lt;p&gt;Isabelle would have helped here. For one thing, Sledgehammer warns you if it detects a contradiction in your background theory. And also, when you have a series of theorems that all depend on the same context, you can prove them within a locale, with assumptions such as $z\not=0$ laid out clearly. Even without locales, the Isabelle practice of listing the assumptions separately in the theorem statement would have avoided the problem. Isabelle newbies frequently ask why we prefer inference rules with explicit premises and conclusions over formulas like $\forall x.\,P(x) \to Q(x)$. It is to avoid the confusing clutter of quantifiers and implications and the further clutter of the proof steps needed to get rid of them (&lt;code&gt;intros&lt;/code&gt; in Rocq).&lt;/p&gt;&lt;p&gt;But in some cases, Isabelle itself can be the problem. Once, a student had proved some false statement and then used it to prove all the other claims (easily!). But how did he prove the false statement in the first place? Actually he didn’t: his proof was stuck in a loop. By a quirk of multithreading: when processing a theory file, If one Isabelle thread gets bogged down, other threads will still race ahead under the assumption that the bogged-down proof will eventually succeed. Such issues are easily identified if you run your theory in batch mode: it would simply time out. I have given an example of this error in another post. Experienced users know to be wary when proofs go through too easily.&lt;/p&gt;&lt;p&gt;Another way to prove nonsense is getting your definitions wrong. With luck, the lemmas that you have to prove about your definitions will reveal any errors. Apart from that, you will be okay provided the definitions do not appear in the main theorem. Recently I completed a large proof where I was deeply unsure that I understood the subject matter. Fortunately, the headline result included none of the intricate definitions involved in the work. The key point is that making a definition in a proof assistant does not compromise its consistency. If the definition is wrong, theorems mentioning it will not mean what you think they mean, but you will not be able to prove $1=0$.&lt;/p&gt;&lt;p&gt;This is also the answer to those who complain that $x/0=0$ in Isabelle (also, in HOL and Lean): if your theorem does not mention1 the division symbol then it doesn’t matter. And if it does mention division, then the only possible discrepancy between Isabelle’s interpretation and the traditional one involves division by zero; in that case, there is no traditional interpretation to disagree with.&lt;/p&gt;&lt;head rend="h3"&gt;Soundness bugs in proof assistants&lt;/head&gt;&lt;p&gt;We expect proof assistants to be correct, but how trustworthy are they really? I spent a little time tracking down soundness errors in a few of them: first, naturally, Isabelle, where there has been one error every 10 years.&lt;/p&gt;&lt;p&gt;In 2025 (last February), somebody showed how to prove false in Isabelle/HOL using normalisation by evaluation, which bypasses the proof kernel. This was not a kernel bug, and unlikely to bump into by accident, but it was obviously unacceptable and was fixed in the following Isabelle release.&lt;/p&gt;&lt;p&gt;In 2015, Ondřej Kunčar found a bug in Isabelle/HOL’s treatment of overloaded definitions. A particularly cunning circular definition was accepted and could be used to prove false. I recall arguing that this was not really a soundness bug. But just above, I have noted how important it is that definitions preserve consistency: in particular, that they can be eliminated (in principle) by substitution. Kunčar and Popescu put a great effort into not just fixing this bug but putting the definition mechanism onto a sound theoretical bases.&lt;/p&gt;&lt;p&gt;In 2005, Obua discovered that essentially no checks were being performed on overloaded definitions. He discovered a not-quite-so cunning circular definition that could be used to prove false (details in the previous paper).&lt;/p&gt;&lt;p&gt;There must have been earlier soundness bugs in Isabelle, but I cannot remember any beyond those above. Definitions were not being checked for circularity because Isabelle was specialised research software and I couldn’t be bothered to stop people from hanging themselves: that old UNIX spirit. But good computer systems do protect users.&lt;/p&gt;&lt;p&gt;An early soundness bug in HOL88 also involved definitions. It was omitting to check that all the variables on the right hand side of the definition also appeared on the left-hand side. That leads to a contradiction trivially. A subtler error is to allow a definition where the right hand side is “more polymorphic” than the left and depends on some property of a type.&lt;/p&gt;&lt;p&gt;I can still remember a soundness bug that I introduced into LCF 40 years ago. I was coding 𝛼-conversion: a function to test whether two λ-expressions were equivalent up to renaming of bound variables. For example, $\lambda x.x$ and $\lambda y.y$ are 𝛼-equivalent. But I was coding in LISP and used a popular optimisation of testing for pointer equality, overlooking that it made no sense here. My code regarded $\lambda x.x$ and $\lambda y.x$ as equivalent. This sort of bug is particularly dangerous because it is in the kernel.&lt;/p&gt;&lt;p&gt;I have never heard of any soundness bug in Rocq, but fortunately, the Rocq team maintain a convenient list of critical bugs. It’s scary, and you have to wonder what they did wrong. After all, Lean is based on a similar calculus and seems to have a good soundness record. Another seriously buggy proof assistant is PVS; at least, it was 30 years ago. PVS has no proof kernel.&lt;/p&gt;&lt;p&gt;My impression is that the LCF style systems, including the HOL family as well as Isabelle, have an excellent record for soundness, confirming Robin Milner’s conception from half a century ago – and with no countervailing penalty.&lt;/p&gt;&lt;head rend="h3"&gt;So can we rely on machine proofs?&lt;/head&gt;&lt;p&gt;Of the woeful tales related above, I am not aware of any that had practical implications. Even soundness bugs seem to have a limited impact. Griffioen and Huisman wrote of PVS&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The obvious question thus arises, why use a proof tool that probably contains soundness bugs? … PVS is still a very critical reader of proofs.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;A close examination of almost any proof published in a mathematics journal will identify errors. Most are easy to fix, but the persistence of errors must undermine our confidence in published mathematics. Let’s recall once again that remarkable group of footnotes from The Axiom of Choice, by T J Jech:&lt;/p&gt;&lt;p&gt;This exact list was used by DeMillo et al. as evidence for the strength of the mathematical community and decades later, in my own grant proposal, as evidence for its weakness. In the case of machine proofs, with the crucial caveat that abstract models of the real world often turn out to be inadequate, we do not find errors. Evidence from testing suggests that verification works.&lt;/p&gt;&lt;p&gt;In my corner of the world of interactive theorem proving, we take soundness seriously. Mike Gordon strongly promoted a definitional approach: no axioms ever, all proof developments built upon pure higher-logic from definitions alone, to avoid any danger of inconsistency. Many of the variants of the HOL system owe their existence to a desire for ever greater rigour. For example, John Harrison writes “HOL Light is distinguished by its clean and simple design and extremely small logical kernel.” The HOL light kernel was later verified. The apotheosis of this project is the Candle theorem prover, created by porting HOL Light to the CakeML language. Candle has been proved to correctly implement higher-order logic, and moreover, this theorem has been established for its compiled machine code. We have no way of knowing whether higher-order logic is consistent, but if it isn’t, there will be nothing left of mathematics.&lt;/p&gt;&lt;p&gt;Incidentally, higher-order logic is remarkably self-contained. Over past decades, the HOL provers and Isabelle/HOL have gained numerous extensions: recursive datatypes, general recursive function definitions with pattern matching, inductive definitions and coinductive definitions. These are all definable within higher order logic, whereas similar capabilities in dependent type theories always seem to require extensions to the kernel. And that means, any bugs are kernel bugs. In view of the much greater logical strength of dependent type theories, this situation is hard to understand.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;directly or indirectly (see the first comment below) ↩&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lawrencecpaulson.github.io/2026/01/15/Broken_proofs.html"/><published>2026-02-04T09:00:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46885862</id><title>Thatcher Effect – Optical Illusion and Explanation</title><updated>2026-02-04T16:33:09.438442+00:00</updated><content>&lt;doc fingerprint="37a3d35f70b78dfa"&gt;
  &lt;main&gt;
    &lt;p&gt;Click Anywhere to see the faces rotate. Try not to scream.&lt;/p&gt;
    &lt;p&gt;What: The thatcher effect, as you may have just experienced in the interactive examples above, shows that when a face is upside down, but its features (eyes and mouth in this case) are themselves upside down, thus appearing right side up, the brain has a hard time recognizing the face to be tampered with, or wrong at all. This is a great example of how the brain processes faces, and how it can be fooled by simple tricks.&lt;/p&gt;
    &lt;p&gt;This effect was first documented by Peter Thompson in 1980 [1], and since then has spurred a series of experiments and studies on the topics of facial recognition and the brain’s ability to process faces. My favorite is this [2] paper from 2009, showing that monkeys experience the same effect. This again, does make sense, but the fact that they did the study itself is really the surprise.&lt;/p&gt;
    &lt;p&gt;How To: Click anywhere on the image to see the faces rotate. Try not to scream. There’s no other special sauce here really, you know what the effect is going to be time and time again, so you can attempt to force your brain to do the calculations, and sometimes it feels like I can get close, but then after the flip, nope, still fooled.&lt;/p&gt;
    &lt;p&gt;Explain It: The brain is good at recognizing faces, and it does so by processing the features of the face in a routine manner, which happens… well, every time you see a face. When a face is shown upside down, the brain can’t really use its same mechanisms but instead will look at the individual features and process them as they are. By all accounts, they tend to look correct (As they would if the face was not upside down), so nothing seems odd at all.&lt;/p&gt;
    &lt;p&gt;Of course, this can say a little about how our brain perceives the world around us, but there is without question a lot more to learn in the space, and as such, the studies keep on coming!&lt;/p&gt;
    &lt;p&gt;I've researched these optical illusions in my spare time but am clearly not any kind of expert and my explainations are pretty smooth brained, if you find something mis-cited, earlier examples, or general mistakes please new let me know via toymaker@toms.toys, be kind!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://optical.toys/thatcher-effect/"/><published>2026-02-04T13:59:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886191</id><title>Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025</title><updated>2026-02-04T16:33:09.008602+00:00</updated><content>&lt;doc fingerprint="e3e534e737e1921a"&gt;
  &lt;main&gt;
    &lt;p&gt;A debilitating infection from the parasitic Guinea worm is inching closer to global eradication, with an all-time low of only 10 human cases reported worldwide in 2025, the Carter Center announced.&lt;/p&gt;
    &lt;p&gt;If health workers can fully wipe out the worms, it will be only the second human disease to be eradicated, after smallpox.&lt;/p&gt;
    &lt;p&gt;Guinea worm (Dracunculus medinensis) is a parasitic nematode transmitted in water. More specifically, it’s found in waters that contain small crustacean copepods, which harbor the worm’s larvae. If a person consumes water contaminated with Guinea worm, the parasites burrow through the intestinal tract and migrate through the body. About a year later, a spaghetti noodle-length worm emerges from a painful blister, usually in the feet or legs. It can take up to eight weeks for the adult worm to fully emerge. To ease the searing pain, infected people may put their blistered limbs in water, allowing the parasite to release more larvae and continue the cycle.&lt;/p&gt;
    &lt;p&gt;In addition to being extremely painful, the disease (dracunculiasis) can lead to complications, such as secondary infections and sepsis, which in turn can lead to temporary or permanent disability.&lt;/p&gt;
    &lt;p&gt;When the Guinea worm eradication program began in 1986, there were an estimated 3.5 million cases across 21 countries in Africa and Asia. To date, only six countries have not been certified by the World Health Organization as Guinea worm-free. In 2024, there were just 15 cases, and, according to the provisional tally for 2025, the number is down to just 10. It’s considered provisional until each country’s disease reports are confirmed, which occurs in a program meeting usually held in April.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/"/><published>2026-02-04T14:27:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886237</id><title>FBI couldn't get into WaPo reporter's iPhone because Lockdown Mode enabled</title><updated>2026-02-04T16:33:08.941335+00:00</updated><content>&lt;doc fingerprint="a62918135f4332cd"&gt;
  &lt;main&gt;&lt;p&gt;The FBI has been unable to access a Washington Post reporter’s seized iPhone because it was in Lockdown Mode, a sometimes overlooked feature that makes iPhones broadly more secure, according to recently filed court records.&lt;/p&gt;&lt;p&gt;The court record shows what devices and data the FBI was able to ultimately access, and which devices it could not, after raiding the home of the reporter, Hannah Natanson, in January as part of an investigation into leaks of classified information. It also provides rare insight into the apparent effectiveness of Lockdown Mode, or at least how effective it might be before the FBI may try other techniques to access the device.&lt;/p&gt;&lt;p&gt;💡&lt;/p&gt;&lt;p&gt;Do you know anything else about phone unlocking technology? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.&lt;/p&gt;&lt;head rend="h2"&gt;This post is for paid members only&lt;/head&gt;&lt;p&gt;Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.&lt;/p&gt; Subscribe &lt;head rend="h2"&gt;Sign up for free access to this post&lt;/head&gt;&lt;p&gt;Free members get access to posts like this one along with an email round-up of our week's stories.&lt;/p&gt; Subscribe &lt;p&gt;Already have an account? Sign in&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/"/><published>2026-02-04T14:31:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886265</id><title>Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation</title><updated>2026-02-04T16:33:08.875147+00:00</updated><content>&lt;doc fingerprint="cc1c241ad7f7d6ef"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 30 Jan 2026]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2602.00294"/><published>2026-02-04T14:33:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886440</id><title>A case study in PDF forensics: The Epstein PDFs</title><updated>2026-02-04T16:33:08.211075+00:00</updated><content>&lt;doc fingerprint="f057ca0214f70b80"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A case study in PDF forensics: The Epstein PDFs&lt;/head&gt;
    &lt;p&gt;December 22, 2025&lt;/p&gt;
    &lt;p&gt;December 22, 2025&lt;/p&gt;
    &lt;p&gt;About Peter Wyatt, PDF Association&lt;/p&gt;
    &lt;p&gt;The recent release of a tranche of files by the US Department of Justice (DoJ) under the “Epstein Files Transparency Act (H.R.4405)” has once again prompted many people to closely examine redacted and sanitized PDF documents. Our previous articles on the Manafort papers and the Mueller report, as well as a study by Adhatarao, S. and Lauradoux, C. (2021) “Exploitation and Sanitization of Hidden Data in PDF Files: Do Security Agencies Sanitize Their PDF files?,” in Proceedings of the 2021 ACM Workshop on Information Hiding and Multimedia Security, illustrate the importance of robust sanitization and redaction workflows when handling sensitive documents prior to release.&lt;/p&gt;
    &lt;p&gt;This article examines a small random selection of the Epstein PDF files from a purely digital forensic perspective, focusing on the PDF syntax and idioms they contain, any malformations or unusual constructs, and other technical aspects.&lt;/p&gt;
    &lt;p&gt;PDFs are more challenging to analyze than many other formats because they are binary files that require specialized knowledge, expertise, and software. Please note that we did not analyze the contents of the PDF documents. Not every PDF was examined. Any mention of products (or appearance in screen-shots) does not imply any endorsement or support of any information, products, or providers whatsoever. We are not lawyers; this article does not constitute legal advice&lt;/p&gt;
    &lt;p&gt;We offer this information, in part, as some of the Epstein PDFs released by DoJ are beginning to appear on malware analysis sites (such as Hybrid-Analysis) with various kinds of incorrect analysis and misinformation.&lt;/p&gt;
    &lt;head rend="h2"&gt;26 December 2025 update&lt;/head&gt;
    &lt;p&gt;After we'd completed our analysis the DoJ released a new dataset, DataSet 8.zip. This new ZIP file is 9.95 GB compressed and contains over 11,000 files, including 10,593 new PDFs totaling 1.8 GB and 29,343 pages (the longest document has 1,060 pages). DataSet 8 also contains many large MP4 movies, Excel spreadsheets, and various other files. The first PDF in the set of 10,593 PDFs is VOL00008\IMAGES\0001\EFTA00009676.pdf, and the last file is VOL00008\IMAGES\0011\EFTA00039023.pdf. A cursory analysis shows pdfinfo properties similar to those from the earlier datasets, but we have not otherwise analyzed this new dataset.&lt;/p&gt;
    &lt;p&gt;Since our original post, various social media and news platforms have also been announcing “recoverable redactions” from the “Epstein Files”. We stand by our analysis; DoJ has correctly redacted the EFTA PDFs in Datasets 01-07, and they do not contain recoverable text as alleged. As our article states, we did not analyze any other DoJ or Epstein-related documents.&lt;/p&gt;
    &lt;p&gt;For example, the featured image in this Guardian news article (which was also picked up by the New York Times) corresponds to VOL00004\IMAGES\0001EFTA00005855.pdf, as can be easily determined by searching for the Bates Numbers in the EFTA “.OPT” data files. The information in this EFTA PDF is fully and correctly redacted; there is no hidden information. The only extractable text is some garbled text from the poor-quality OCR and, as expected, the Bates Numbers on each page.&lt;/p&gt;
    &lt;p&gt;In the few reports we investigated (including from Forbes and Ed Krassenstein on both X (formerly Twitter) and Instagram), these stories misrepresent other DoJ files that were not part of the major DataSets 01-07 release on December 19 under the EFTA. All PDFs released under EFTA have a Bates Number on every page starting "EFTA". These include “Case 1:22-cv-10904-JSR Document 1-1, Exhibit 1 to Government’s Complaint against JPMorgan Chase Bank, N.A.” (see page 41) and “Case No: ST-20-CV-14 Government Exhibit 1” (see page 19). These PDFs, previously released by the DoJ, do contain incorrect and ineffective redactions, with black boxes that simply obscure text, making “copy &amp;amp; paste” easy to recover the text that's otherwise hidden. Clearly, DoJ processes and systems in the past have inadequately redacted information!&lt;/p&gt;
    &lt;head rend="h2"&gt;The files we examined&lt;/head&gt;
    &lt;p&gt;The tranche released by DoJ on Friday, December 19 is available as seven “data sets”, most easily downloaded as seven ZIP archives totaling just under 2.97 GB. Each ZIP file contains a similar folder structure, with DataSet 6 being the odd one out with an extra top-level folder. Once unzipped, the total size is 2.99 GB. The tranche contains 4,085 PDF files, a single AVI (movie) file (located in the folder VOL00002\NATIVES\0001), and 2 data files (.DAT and .OPT) for each ZIP archive. The “.OPT” files appear to be CSV (Comma-Separated Values) but lack a heading row, while the “.DAT” files contain information about the Bates numbering. The analysis we provide here is limited to the PDF files.&lt;/p&gt;
    &lt;p&gt;The PDF files are named and ordered sequentially within the folder structure, starting with “EFTA00000001.pdf” in VOL00001 and ending with “EFTA00009664.pdf” in VOL00007, indicating that at least 5,879 PDF files remain unreleased.&lt;/p&gt;
    &lt;p&gt;A random sampling of the PDFs for visual review suggests that they are a mix of single and multi-page full-page photos and scanned content. OCR (Optical Character Recognition) was used to provide some searchable and extractable text in at least some files. “Black box” style redactions (without text reasons) are apparent. When done correctly, this is the appropriate way to redact, far more robust than pixelating text. The PDFs we sampled did not include any obviously “born digital” documents. Various news sites are reporting very heavily redacted documents within this tranche.&lt;/p&gt;
    &lt;head rend="h2"&gt;File validity&lt;/head&gt;
    &lt;p&gt;A precursor to most forensic examinations is to establish whether the PDF files are technically valid (that is, conform to the rules of the PDF format), since analyzing malformed files can easily lead to incorrect results or wrong conclusions. Combining tools that use different methods provides the broadest possible information while ensuring that tooling limitations are fully understood. However, if the basic file structure or cross-reference information is incorrect, various software might then draw different conclusions and/or construct different Document Object Models (DOMs).&lt;/p&gt;
    &lt;p&gt;In addition to basic file structure, incremental updates (if any), and cross-reference information, PDF validity assessments include the objects that comprise the PDF’sDOM as well as the file structure, incremental updates, and cross-reference information. To assess relationships between objects in the PDF DOM, some forensic analysis tools leverage our Arlington PDF Data Model, while others use their own internal methods.&lt;/p&gt;
    &lt;p&gt;Our analysis of file validity, using a multitude of PDF forensic tools, identified only one minor defect (invalidity); 109 PDFs had a positive FontDescriptor Descent value rather than a negative one. This is a relatively common (but minor) error, typically associated with font substitution and font matching, that does not affect the validity of the files overall. One specific forensic tool reported a PDF version issue with some files, related to the document catalog Version entry, which prevented the tool from further verifying those specific PDFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;PDF versions&lt;/head&gt;
    &lt;p&gt;I’ve previously written about the unreliability of PDF version numbers. Still, for forensic purposes, they may provide insight into the DoJ’s software, and whether improved software could have performed better.&lt;/p&gt;
    &lt;p&gt;I used two different but commonly used PDF command-line &lt;code&gt;pdfinfo&lt;/code&gt; utilities on different platforms (Windows and Ubuntu Linux) to summarize information about these PDF files. When run against the full tranche of PDFs, I got two very different sets of answers! Immediately, my spidey senses started to tingle, and I was once again reminded of a key lesson in digital document forensics – you should never trust a single tool!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Reported PDF Version&lt;/cell&gt;
        &lt;cell&gt;Count Tool A&lt;/cell&gt;
        &lt;cell&gt;Count Tool B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1.3&lt;/cell&gt;
        &lt;cell&gt;209&lt;/cell&gt;
        &lt;cell&gt;3,817&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1.4&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1.5&lt;/cell&gt;
        &lt;cell&gt;3,875&lt;/cell&gt;
        &lt;cell&gt;267&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;TOTAL (should be 4,085)&lt;/cell&gt;
        &lt;cell&gt;4,085&lt;/cell&gt;
        &lt;cell&gt;4,085&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The PDF version in the file header, “&lt;code&gt;%PDF-x.y&lt;/code&gt;”, is nominally the first line in every PDF file (based on the not-unreasonable assumption that the PDF files have no “junk bytes” before this PDF file identifier). Using the Linux command line, you can run in Linux “&lt;code&gt;head -n 1 file.pdf&lt;/code&gt;” to extract the first header line from each PDF and compare it with the reported results from each tool. Or run in Linux “&lt;code&gt;grep -P --text --byte-offset "%PDF-\d\.\d" *.pdf&lt;/code&gt;” to confirm that there are no junk bytes prior to the PDF header line.&lt;/p&gt;
    &lt;p&gt;The reason for the difference reported in the table above is that Tool B is not accounting for the Version entry in the document catalog of PDFs with incremental updates. We’ll next investigate whether this is due to malformed files or a programming error. When properly accounting for incremental updates, however, Tool A is correct.&lt;/p&gt;
    &lt;p&gt;Using the same &lt;code&gt;pdfinfo&lt;/code&gt; output (and again comparing results from both tools), we can also quickly establish the following facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No PDF is tagged&lt;/item&gt;
      &lt;item&gt;No PDF is encrypted&lt;/item&gt;
      &lt;item&gt;No PDF is “optimized” (technically, Linearized PDF)&lt;/item&gt;
      &lt;item&gt;No PDF has any annotations&lt;/item&gt;
      &lt;item&gt;No PDF has any outlines (bookmarks)&lt;/item&gt;
      &lt;item&gt;No PDF contains any embedded files&lt;/item&gt;
      &lt;item&gt;None of the PDFs are forms&lt;/item&gt;
      &lt;item&gt;None of the PDFs contains JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Page counts range from 1 (in 3,818 PDFs) to 119 pages (in two PDFs), totaling 9,659 pages across all 4,085 PDFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Incremental updates&lt;/head&gt;
    &lt;p&gt;PDF’s incremental updates feature allows multiple revisions of a document to be stored in a PDF file. As the name implies, each set of deltas is appended to the original document, forming a chain of edits. When read by conforming PDF software, a PDF is always processed from the end of the file, effectively applying the deltas to the original document and to any previous incremental updates. Both the original document and each incremental update can be recognized by their respective “&lt;code&gt;xref&lt;/code&gt;” and “&lt;code&gt;%%EOF&lt;/code&gt;” markers (assuming that the PDF files are structured correctly).&lt;/p&gt;
    &lt;p&gt;For this investigation, we started by examining the very first PDF in the tranche: VOL00001\IMAGES\0001\EFTA00000001.pdf. This PDF had different PDF versions reported by different versions of &lt;code&gt;pdfinfo&lt;/code&gt;. A simple trick to check if a PDF contains incremental updates is to search for these special markers while treating the PDF as a text file (which it isn’t!):&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;$ grep -P --text -–byte-offset "(xref)|(%%EOF)" EFTA00000001.pdf&lt;/code&gt;&lt;code&gt;371340:xref&lt;/code&gt;&lt;lb/&gt; 371758:startxref&lt;lb/&gt; 371775:%%EOF&lt;lb/&gt; 372977:startxref&lt;lb/&gt; 372994:%%EOF&lt;lb/&gt; 373961:startxref&lt;lb/&gt; 373978:%%EOF&lt;/p&gt;
    &lt;p&gt;These results (sorted by byte offset) indicate that EFTA00000001.pdf contains two incremental updates after the original file. The lack of an “&lt;code&gt;xref&lt;/code&gt;” marker before the last two “&lt;code&gt;startxref&lt;/code&gt;” markers indicate that neither incremental updates uses conventional cross-reference data, but may use cross-reference streams (if any objects are changed).&lt;/p&gt;
    &lt;head rend="h2"&gt;Bates numbering&lt;/head&gt;
    &lt;p&gt;As referenced above, Bates numbering is the process by which every page is assigned a unique identifier. For this tranche of Epstein PDF files, Bates numbers were added to each page via a separate incremental update, as shown below in Visual Studio Code with my pdf-cos-syntax extension. Note that DoJ’s PDFs are primarily text-based internally, making forensic analysis a lot easier - and the files a lot bigger.&lt;/p&gt;
    &lt;p&gt;Observations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Line 2984 is the end-of-file marker for the file version, and line 2985 starts a new incremental update section.&lt;/item&gt;
      &lt;item&gt;Lines 2985-2987 define object 26, the unembedded Helvetica font resource used by the Bates number.&lt;/item&gt;
      &lt;item&gt;Lines 2997-3020 are the modified page object (object 3), replacing the page object in previous revisions of the file.&lt;/item&gt;
      &lt;item&gt;Line 2999 is the page Contents array, comprising five separate content streams, with the 3rd stream (object 29) being the Bates numbering added in this incremental update. Object 30 is an empty content stream that could have been removed by an optimization process.&lt;/item&gt;
      &lt;item&gt;Line 3034 sets the Helvetica font to 12 point.&lt;/item&gt;
      &lt;item&gt;Line 3037 uses a hexadecimal string to paint the Bates number onto the page.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The idiom for this final incremental update, which adds the Bates number to every page, appears in all the PDF files we selected at random for investigation. This specific incremental update always uses a cross-reference stream (&lt;code&gt;/Type /XRef&lt;/code&gt;) and relies on the previous incremental update, in which the document catalog Version entry is set to PDF 1.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;The first incremental update&lt;/head&gt;
    &lt;p&gt;The VSCode pdf-cos-syntax extension also indicates (correctly!) that the original PDF is missing the required (when the PDF contains binary data, which most do) comment as the second line of the file that indicates to software that the PDF file needs to be treated as binary data (ISO 32000-2:2020, §7.5.2). Although the missing comment does not make the PDF invalid per se, without such a marker close to the top of each PDF, software may think the PDF is a text file, and thus potentially corrupt the PDF by changing line endings, which would break the byte offsets in the cross-reference data. In this PDF, the first incremental update adds this marker comment after a lot of binary data, which is pointless.&lt;/p&gt;
    &lt;p&gt;As mentioned above, the first incremental update changed the document catalog Version entry to PDF 1.5, as we see in this next screenshot:&lt;/p&gt;
    &lt;p&gt;Observations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lines 2953-2984 are the incremental update section.&lt;/item&gt;
      &lt;item&gt;Line 2954 is a PDF comment. PDF comments always start with a PERCENT SIGN (&lt;code&gt;%&lt;/code&gt;) and may occur in many places in PDF files. Effective sanitization and redaction workflows typically remove all comments from PDFs because they may inadvertently disclose information, but this exact comment appears in 3,608 other PDF files. The origin or meaning of this comment was not further investigated.&lt;/item&gt;
      &lt;item&gt;Line 2964 upgrades the PDF version to 1.5. At first glance, this may appear to be perfectly valid PDF, but it is technically incorrect because the file header is &lt;code&gt;%PDF-1.3&lt;/code&gt;yet the Version key was only added in PDF 1.4 - this is what the strict file validation tool mentioned above had noticed. As object 24 is a compressed object stream (lines 2966-2973) and object 25 is a compressed cross-reference stream (lines 2974-2981), the indicated version should be PDF 1.5. As a practical matter, however, this level of technical detail does not impact operation or behavior of PDFs.&lt;/item&gt;
      &lt;item&gt;Line 2984 is the end-of-section “&lt;code&gt;%%EOF&lt;/code&gt;” marker for this incremental update section.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As this section of the PDF uses compressed object streams, specialized PDF forensic tools must be used… simple search methodologies, such as those mentioned above, may not identify everything!&lt;/p&gt;
    &lt;p&gt;We know that there are 7 objects (because we find /&lt;code&gt;N 7&lt;/code&gt;) inside the object stream:&lt;/p&gt;
    &lt;p&gt;As per PDF’s specification, ISO 32000-2:2020, §7.5.7, the first line of integers is interpreted as N pairs, where the first integer is the object number and the second integer is the byte offset relative to the first object in the object stream.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;1st integer (object number)&lt;/cell&gt;
        &lt;cell&gt;2nd integer (start offset)&lt;/cell&gt;
        &lt;cell&gt;Explanation&lt;/cell&gt;
        &lt;cell&gt;Content&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;Type1 Font object for OPBaseFont0 (Courier)&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/BaseFont/Courier/Encoding&amp;lt;&amp;lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&amp;gt;&amp;gt;/Name/OPBaseFont0/Subtype/Type1/Type/Font&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;118&lt;/cell&gt;
        &lt;cell&gt;Type1 Font object for OPBaseFont1 (Helvetica)&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/BaseFont/Helvetica/Encoding&amp;lt;&amp;lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&amp;gt;&amp;gt;/Name/OPBaseFont1/Subtype/Type1/Type/Font&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;238&lt;/cell&gt;
        &lt;cell&gt;Document information (Info) dictionary&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/CreationDate(D:20251218143205)/Creator(OmniPage CSDK 21.1)/ModDate(D:20251218143205)/Producer(Processing-CLI)&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;352&lt;/cell&gt;
        &lt;cell&gt;ProcSet resources array&lt;/cell&gt;
        &lt;cell&gt;[/PDF/Text/ImageB/ImageC/ImageI]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;384&lt;/cell&gt;
        &lt;cell&gt;Resources dictionary for the page&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/Font&amp;lt;&amp;lt;/OPBaseFont0 19 0 R/OPBaseFont1 20 0 R&amp;gt;&amp;gt;/ProcSet 18 0 R/XObject&amp;lt;&amp;lt;/Im0 8 0 R&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;23&lt;/cell&gt;
        &lt;cell&gt;472&lt;/cell&gt;
        &lt;cell&gt;Array of 2 indirect references (to content streams)&lt;/cell&gt;
        &lt;cell&gt;[21 0 R 4 0 R]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;486&lt;/cell&gt;
        &lt;cell&gt;Updated Page object&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;&amp;lt;/Contents 23 0 R/MediaBox[0 0 864 576.75]/Parent 2 0 R/Resources 22 0 R/Thumb 11 0 R/Type/Page&amp;gt;&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What is very interesting here – from a PDF forensics perspective – is the fact of a hidden document information dictionary that is not referenced from the last (final) incremental update trailer (i.e., there is no Info entry in object 31, lines 3050-3063 below). As such, this orphaned dictionary is invisible to PDF software! This oddity occurs in all other PDFs we’d randomly selected for investigation.&lt;/p&gt;
    &lt;p&gt;Formatted nicely as an uncompressed object, this hidden document information dictionary inside the compressed object stream contains the following information (the CreationDate and ModDate appear to change in other randomly examined PDFs):&lt;/p&gt;
    &lt;quote&gt;17 0 obj &amp;lt;&amp;lt; /CreationDate (D:20251218143205) /ModDate (D:20251218143205) /Creator (OmniPage CSDK 21.1) /Producer (Processing-CLI) &amp;gt;&amp;gt; endobj&lt;/quote&gt;
    &lt;p&gt;This metadata clearly indicates the software DoJ used to manipulate these PDF files. Although not relevant to the content, this forensic discovery clearly shows that extra care is required when sanitizing PDFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Different incremental updates&lt;/head&gt;
    &lt;p&gt;Another randomly selected PDF, VOL00003\IMAGES\0001\EFTA00003939.pdf contains 3 full-page images, and just a single incremental update that applies the Bates numbering. However, in this case the file header is &lt;code&gt;%PDF-1.5&lt;/code&gt; yet both the original PDF and incremental update use conventional cross-reference tables! This isn’t problematic, but is certainly unexpected and inefficient since PDF 1.5 introduced compressed cross-reference streams.&lt;/p&gt;
    &lt;p&gt;By comparing the objects in the incremental cross-reference table to the original cross-reference table we can see that objects 66 to 69 – the 3 Page objects for the 3 page document – were redefined. This is just what is expected in order to add the Bates number to each page’s Contents stream as in the previous example.&lt;/p&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;p&gt;Our initial examination using pdfinfo utilities did not identify any metadata in any of the PDFs in the tranche, either in the document information dictionary (PDF file trailer Info entry) or as an XMP metadata stream (Metadata entry).&lt;/p&gt;
    &lt;p&gt;However, since we know that (a) the tranche includes PDFs with incremental updates, and (b) that an orphaned document information dictionary exists, all revisions of a document should be thoroughly examined. Incremental updates may have marked other document information dictionaries or XMP metadata streams as free but not deleted the actual data.&lt;/p&gt;
    &lt;p&gt;XMP metadata is always encoded in PDF as a stream object, and since stream objects cannot be in compressed object streams, using forensic tools to search for keys “&lt;code&gt;/XML&lt;/code&gt;” or “&lt;code&gt;/Metadata&lt;/code&gt;” should always locate them. All modern office suites and PDF creation applications will generate XMP metadata when exporting to PDF. As XMP is usually uncompressed, searching for XML fragments may also be helpful (see below for an example XMP object fragment).&lt;/p&gt;
    &lt;quote&gt;3 0 obj &amp;lt;&amp;lt;/Length 36996/Subtype/XML/Type/Metadata&amp;gt;&amp;gt; stream &amp;lt;?xpacket begin="ï»¿" id="W5M0MpCe … zNTczkc9d"?&amp;gt; &amp;lt;x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk=" … "&amp;gt; &amp;lt;rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"&amp;gt; &amp;lt;rdf:Description rdf:about="" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xmp="http://ns.adobe.com/xap/1.0/" ...&lt;/quote&gt;
    &lt;p&gt;Not unsurprisingly for properly-redacted files, we did not find any XMP metadata streams or XML in any PDF. As a consequence, none of the PDFs can declare conformance to either PDF/A (ISO 19005 for long-term archiving) or PDF/UA (ISO 14289 for accessibility). Of course, as untagged PDFs, the files cannot conform to accessibility specifications such as PDF/UA or WCAG in any event. Additionally, none of the PDFs appear to include device-independent color spaces.&lt;/p&gt;
    &lt;p&gt;The presence of an Info entry in the trailer dictionary or (in PDFs with cross-reference streams) in the cross-reference stream dictionary indicates the presence of document information dictionaries. “&lt;code&gt;/Info&lt;/code&gt;” does indeed occur in many of the PDFs, including multiple times in some PDFs, indicating potential changes via incremental updates. However, as discovered above, in some cases the final incremental update does not include an Info entry, thus “orphaning” any existing document information dictionaries.&lt;/p&gt;
    &lt;p&gt;ISO 32000-2:2020, Table 349 lists the defined entries in PDF’s document information dictionary (Title, Author, Subject, etc). Any vendor may add additional entries (such as Apple does with its /AAPL:Keywords entry), so redaction and sanitization software should be aware of extra entries.&lt;/p&gt;
    &lt;p&gt;From our random sampling, we identified one PDF with a non-trivial document information dictionary still present: VOL00002\IMAGES\0001\EFTA00003212.pdf. This is shown below in Visual Studio Code with my pdf-cos-syntax extension:&lt;/p&gt;
    &lt;p&gt;Of additional interest in this specific PDF is that the comment at line 60 has survived DoJ’s sanitization and redaction workflow! Other PDF comments may therefore also be present in other files.&lt;/p&gt;
    &lt;p&gt;EFTA00003212.pdf appears to be a redacted image or an error from the DoJ workflow, as it is a single page with the text “No Images Produced”.&lt;/p&gt;
    &lt;p&gt;Simple searching of the standardized PDF document information dictionary entries gives the following (note that the technique used will not locate information in compressed object streams, as mentioned above):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Key name&lt;/cell&gt;
        &lt;cell&gt;Number of PDFs (max. = 4,085)&lt;/cell&gt;
        &lt;cell&gt;Comment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Info&lt;/cell&gt;
        &lt;cell&gt;3,823&lt;/cell&gt;
        &lt;cell&gt;Some PDFs have empty Info dictionaries with no entries&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Title&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Author&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Subject&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Keywords&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Creator&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Producer&lt;/cell&gt;
        &lt;cell&gt;215&lt;/cell&gt;
        &lt;cell&gt;Always “pypdf” (denotes https://pypi.org/project/pypdf/)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CreationDate&lt;/cell&gt;
        &lt;cell&gt;3,609&lt;/cell&gt;
        &lt;cell&gt;Same PDFs that have ModDate with an identical value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ModDate&lt;/cell&gt;
        &lt;cell&gt;3,609&lt;/cell&gt;
        &lt;cell&gt;Same PDFs that have CreationDate with an identical value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Trapped&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Only EFTA00003212.pdf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;APPL:Keywords&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Date analysis&lt;/head&gt;
    &lt;p&gt;Detailed date analysis is a common task in the forensic analysis of potentially fraudulent or modified documents. However, in the case of redacted or sanitized documents, where the document is known to have been modified, this can be less useful.&lt;/p&gt;
    &lt;p&gt;The creation and modification dates for the 3,609 PDFs range from December 18, 2025, 14:32:05 (2:32 pm) to December 19, 2025, 23:26:13 (almost midnight). For all files, the creation and modification dates are always the same. This may also imply that the DoJ batch processing to prepare this tranche of PDFs took at least 36 hours!&lt;/p&gt;
    &lt;p&gt;What’s also interesting is that the CreationDate and ModDate fields in the hidden document information dictionary (inside the object stream of the first increment update – see above) appear to always be an exact match to both the CreationDate and ModDate of the original document. This implies that all dates across all incremental updates were updated in a single processing pass that applied the Bates numbering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Photographs&lt;/head&gt;
    &lt;p&gt;There are no JPEG images (DCTDecode filter) in any PDF in the tranche, including the full-page photographs. Randomly viewing the photographic images at high magnification (zoom) in PDF viewers clearly shows JPEG “jaggy” compression artifacts. All photographic images appear to have been downscaled to 96 DPI (769 x 1152 or 1152 x 769 pixels), making text on random objects in the photos much harder to discern (see the OCR discussion below).&lt;/p&gt;
    &lt;p&gt;DoJ explicitly avoids JPEG images in the PDFs probably because they appreciate that JPEGs often contain identifiable information, such as EXIF, IPTC, or XMP metadata, as well as COM (comment) tags in the JPEG bitstream. This information may disclose the camera model and serial number, GPS location, camera operator details, date/time of the photo, etc., and is more difficult to redact while retaining the JPEG data. The DoJ processing pipeline has therefore explicitly converted all lossy JPEG images to low DPI, FLATE-encoded bitmaps in the PDFs using an indexed device-dependent color space with a palette of 256 unique colors (which reduces the color fidelity compared to the original high-quality digital color photograph).&lt;/p&gt;
    &lt;head rend="h2"&gt;Scanned documents – or are they?&lt;/head&gt;
    &lt;p&gt;Randomly inspecting the tranche discovers many documents that appear to have been created by a scanning process. On closer inspection, there are documents that have tell-tale artifacts from a physical scanning process, such as visible physical paper edges, punched holes, staple marks, spiral binding, stamps, paper scuff marks, color blotches and inconsistencies, handwritten notes or marginalia, varying paper skew, and platen marks from the physical paper scanning processes. For example, VOL00007\IMAGES\0001\EFTA00009440.pdf shows many of these aspects&lt;/p&gt;
    &lt;p&gt;There are also other documents that appear to simulate a scanned document but completely lack the “real-world noise” expected with physical paper-based workflows. The much crisper images appear almost perfect without random artifacts or background noise, and with the exact same amount of image skew across multiple pages. Thanks to the borders around each page of text, page skew can easily be measured, such as with VOL00007\IMAGES\0001\EFTA00009229.pdf. It is highly likely these PDFs were created by rendering original content (from a digital document) to an image (e.g., via print to image or save to image functionality) and then applying image processing such as skew, downscaling, and color reduction.&lt;/p&gt;
    &lt;p&gt;The use of the timeless monospaced (also known as fixed-width) “Courier” typeface means that the number of characters redacted can be easily determined by vertical alignment with text lines above and below each redaction. In some instances, this may reduce the possible number of options that represent the redacted content, allowing it to be more easily guessed. Although redaction of variable-width typefaces is far more complex, Bland, M., Iyer, A., and Levchenko, K. 2022 paper “Story Beyond the Eye: Glyph Positions Break PDF Text Redaction” showed that this is still possible with sufficient computing power and determination.&lt;/p&gt;
    &lt;head rend="h3"&gt;Optical Character Recognition (OCR)&lt;/head&gt;
    &lt;p&gt;OCR is complex image processing that attempts to identify text in bitmap images. In PDF files, OCR-identified text is commonly placed on top of the image using the invisible text render mode. This enables users to then extract the text from the image.&lt;/p&gt;
    &lt;p&gt;Returning to the very first PDF file in the tranche, VOL00001\IMAGES\0001\EFTA00000001.pdf - this is a full-page photo of a hand-written sign where part of the hand-written information is explicitly redacted. The PDF contains largely inaccurate OCR-ed text, indicating that natural language processing (NLP), machine learning (ML), or even language aware dictionary-based algorithms were not used. This means that there will be more errors in the extracted text than is necessary.&lt;/p&gt;
    &lt;p&gt;With cloud platforms readily accessible and supporting advanced OCR at low cost, anyone is capable of re-processing the entire tranche of PDFs and comparing the OCR results to those provided by DoJ. Even though the page images are low-resolution (96 DPI), rerunning OCR may bring to light additional or corrected information hidden by the original OCR that failed to recognize everything correctly.&lt;/p&gt;
    &lt;p&gt;The “black box” redactions we investigated were all correctly applied directly into the image pixel data. They are not separate PDF rectangle objects simply floating above sensitive information that was still present in the image and easily discoverable. Yes, sometimes it is that easy…!&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;We did not set out to comprehensively analyze every corner of every PDF file in the Epstein PDFs, but to present a basic walk-through of some of the challenges and tricks used to conduct a PDF forensic assessment. Our results above were from a small random sample of documents - there may well be outlier PDFs in the data sets that we did not encounter.&lt;/p&gt;
    &lt;p&gt;The DoJ has clearly created internal processes, systems, and workflows that can sanitize and redact information prior to publishing as PDF. This includes converting JPEG images to low-resolution pixel-only bitmaps, largely removing metadata, and rendering page images to bitmaps. OCR appears to have been widely applied, but is of variable quality.&lt;/p&gt;
    &lt;p&gt;Their PDF technology could be improved to vastly reduce file size by removing unnecessary objects (e.g., empty content streams, ProcSets, empty thumbnail references, etc.), simplifying and reducing content streams, applying all incremental updates (i.e., removing all incremental update sections), and always using compressed object streams and compressed cross-reference streams. Information leakage may also be occurring via PDF comments or orphaned objects inside compressed object streams, as I discovered above.&lt;/p&gt;
    &lt;p&gt;PDF forensics is a highly complex field, where variations in files and tool assumptions can easily yield false results. The PDF Association hosts a PDF Forensic Liaison Working Group to develop industry guidance on forensic examination of PDF files and to educate document examiners and other specialists about many of these aspects.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/"/><published>2026-02-04T14:46:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46886735</id><title>Voxtral Transcribe 2</title><updated>2026-02-04T16:33:07.730132+00:00</updated><content>&lt;doc fingerprint="3c2dcd92a1ee1e85"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Voxtral transcribes &lt;lb/&gt; at the speed of sound.&lt;/head&gt;Try Voxtral Transcribe 2 in Mistral Studio&lt;p&gt; Precision diarization, real-time&lt;lb/&gt; transcription, and a new audio playground.&lt;/p&gt;&lt;p&gt;Today, we're releasing Voxtral Transcribe 2, two next-generation speech-to-text models with state-of-the-art transcription quality, diarization, and ultra-low latency. The family includes Voxtral Mini Transcribe V2 for batch transcription and Voxtral Realtime for live applications. Voxtral Realtime is open-weights under the Apache 2.0 license.&lt;/p&gt;&lt;p&gt;We're also launching an audio playground in Mistral Studio to test transcription instantly, powered by Voxtral Transcribe 2, with diarization and timestamps.&lt;/p&gt;&lt;head rend="h2"&gt;Highlights.&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Voxtral Mini Transcribe V2: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Voxtral Realtime: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Best-in-class efficiency: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Open weights: Voxtral Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Voxtral Realtime.&lt;/head&gt;&lt;p&gt;Voxtral Realtime is purpose-built for applications where latency matters. Unlike approaches that adapt offline models by processing audio in chunks, Realtime uses a novel streaming architecture that transcribes audio as it arrives. The model delivers transcriptions with delay configurable down to sub-200ms, unlocking a new class of voice-first applications.&lt;/p&gt;&lt;p&gt;Word error rate (lower is better) across languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;p&gt;At 2.4 seconds delay, ideal for subtitling, Realtime matches Voxtral Mini Transcribe V2, our latest batch model. At 480ms delay, it stays within 1-2% word error rate, enabling voice agents with near-offline accuracy.&lt;/p&gt;&lt;p&gt;The model is natively multilingual, achieving strong transcription performance in 13 languages, including English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. With a 4B parameter footprint, it runs efficiently on edge devices, ensuring privacy and security for sensitive deployments.&lt;/p&gt;&lt;p&gt;We’re releasing the model weights under Apache 2.0 on the Hugging Face Hub.&lt;/p&gt;&lt;head rend="h2"&gt;Voxtral Mini Transcribe V2.&lt;/head&gt;&lt;p&gt;Average diarization error rate (lower is better) across five English benchmarks (Switchboard, CallHome, AMI-IHM, AMI-SDM, SBCSAE) and the TalkBank multilingual benchmark (German, Spanish, English, Chinese, Japanese).&lt;/p&gt;&lt;p&gt;Average word error rate (lower is better) across the top-10 languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;p&gt;Voxtral Mini Transcribe V2 delivers significant improvements in transcription and diarization quality across languages and domains. At approximately 4% word error rate on FLEURS and $0.003/min, Voxtral offers the best price-performance of any transcription API. It outperforms GPT-4o mini Transcribe, Gemini 2.5 Flash, Assembly Universal, and Deepgram Nova on accuracy, and processes audio approximately 3x faster than ElevenLabs’ Scribe v2 while matching on quality at one-fifth the cost.&lt;/p&gt;&lt;head rend="h3"&gt;Enterprise-ready features.&lt;/head&gt;&lt;p&gt;Voxtral Mini Transcribe V2 introduces key capabilities for enterprise deployments.&lt;/p&gt;&lt;head rend="h4"&gt;Speaker diarization.&lt;/head&gt;&lt;p&gt;Generate transcriptions with speaker labels and precise start/end times. Ideal for meeting transcription, interview analysis, and multi-party call processing. Note: with overlapping speech, the model typically transcribes one speaker.&lt;/p&gt;&lt;head rend="h4"&gt;Context biasing.&lt;/head&gt;&lt;p&gt;Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental.&lt;/p&gt;&lt;head rend="h4"&gt;Word-level timestamps.&lt;/head&gt;&lt;p&gt;Generate precise start and end timestamps for each word, enabling applications like subtitle generation, audio search, and content alignment.&lt;/p&gt;&lt;head rend="h4"&gt;Expanded language support.&lt;/head&gt;&lt;p&gt;Like Realtime, this model now supports 13 languages: English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. Non-English performance significantly outpaces competitors.&lt;/p&gt;&lt;head rend="h4"&gt;Noise robustness.&lt;/head&gt;&lt;p&gt;Maintains transcription accuracy in challenging acoustic environments, such as factory floors, busy call centers, and field recordings.&lt;/p&gt;&lt;head rend="h4"&gt;Longer audio support.&lt;/head&gt;&lt;p&gt;Process recordings up to 3 hours in a single request.&lt;/p&gt;&lt;p&gt;Word error rate (lower is better) across languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;head rend="h2"&gt;Audio playground.&lt;/head&gt;&lt;p&gt;Test Voxtral Transcribe 2 directly in Mistral Studio. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.&lt;/p&gt;&lt;head rend="h2"&gt;Transforming voice applications.&lt;/head&gt;&lt;p&gt;Voxtral powers voice workflows in diverse applications and industries.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;head rend="h3"&gt;Meeting intelligence.&lt;/head&gt;&lt;p&gt;Transcribe multilingual recordings with speaker diarization that clearly attributes who said what and when. At Voxtral's price point, annotate large volumes of meeting content at industry-leading cost efficiency.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Voice agents and virtual assistants.&lt;/head&gt;&lt;p&gt;Build conversational AI with sub-200ms transcription latency. Connect Voxtral Realtime to your LLM and TTS pipeline for responsive voice interfaces that feel natural.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Contact center automation.&lt;/head&gt;&lt;p&gt;Transcribe calls in real time, enabling AI systems to analyze sentiment, suggest responses, and populate CRM fields while conversations are still happening. Speaker diarization ensures clear attribution between agents and customers.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Media and broadcast.&lt;/head&gt;&lt;p&gt;Generate live multilingual subtitles with minimal latency. Context biasing handles proper nouns and technical terminology that trip up generic transcription services.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Compliance and documentation.&lt;/head&gt;&lt;p&gt;Monitor and transcribe interactions for regulatory compliance, with diarization providing clear speaker attribution and timestamps enabling precise audit trails.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Both models support GDPR and HIPAA-compliant deployments through secure on-premise or private cloud setups.&lt;/p&gt;&lt;head rend="h2"&gt;Get started.&lt;/head&gt;&lt;p&gt;Voxtral Mini Transcribe V2 is available now via API at $0.003 per minute. Try it now in the new Mistral Studio audio playground or in Le Chat.&lt;/p&gt;&lt;p&gt;Voxtral Realtime is available via API at $0.006 per minute and as open weights on Hugging Face.&lt;/p&gt;&lt;p&gt;Explore documentation on Mistral’s audio and transcription capabilities.&lt;/p&gt;&lt;head rend="h2"&gt;We’re hiring.&lt;/head&gt;&lt;p&gt;If you're excited about building world-class speech AI and putting frontier models into the hands of developers everywhere, we'd love to hear from you. Apply to join our team.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mistral.ai/news/voxtral-transcribe-2"/><published>2026-02-04T15:08:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46887564</id><title>Microsoft's Pivotal AI Product Is Running into Big Problems</title><updated>2026-02-04T16:33:07.664362+00:00</updated><content/><link href="https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28"/><published>2026-02-04T16:08:55+00:00</published></entry></feed>