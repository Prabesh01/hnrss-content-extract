<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-03T17:08:56.325637+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46467677</id><title>Fighting Fire with Fire: Scalable Oral Exams</title><updated>2026-01-03T17:09:01.803624+00:00</updated><content>&lt;doc fingerprint="2c4be0012943dea6"&gt;
  &lt;main&gt;
    &lt;p&gt;It all started with cold calling.&lt;/p&gt;
    &lt;p&gt;In our new "AI/ML Product Management" class (co-taught with Konstantinos Rizakos), the "pre-case" submissions (short assignments meant to prepare students for class discussion) were looking suspiciously good. Not "strong student" good. More like "this reads like a McKinsey memo that went through three rounds of editing," good.&lt;/p&gt;
    &lt;p&gt;So we started cold calling students randomly during class.&lt;/p&gt;
    &lt;p&gt;The result was... illuminating. Many students who had submitted thoughtful, well-structured work could not explain basic choices in their own submission after two follow-up questions. Some could not participate at all. This gap was too consistent to blame on nerves or bad luck. If you cannot defend your own work live, then the written artifact is not measuring what you think it is measuring.&lt;/p&gt;
    &lt;p&gt;Brian Jabarian has been doing interesting work on this problem, having shown that AI is actually better than humans at conducting job interviews. Why? Humans get tired, have biases, and are less consistent at following a script. His results both inspired us and gave us the confidence to try something that would have sounded absurd two years ago: running the final exam with a Voice AI agent.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why oral exams? And why now?&lt;/head&gt;
    &lt;p&gt;The core problem is simple: students have immediate access to LLMs that can handle most exam questions we traditionally use for assessment. The old equilibrium, where take-home work could reliably measure understanding, is dead. Gone. Kaput.&lt;/p&gt;
    &lt;p&gt;We can go pen and paper in the classroom. We did that as well for the midterm.&lt;/p&gt;
    &lt;p&gt;Oral exams are another natural response. They force real-time reasoning, application to novel prompts, and defense of actual decisions. The problem? Oral exams are a logistical nightmare. You cannot run them for a large class without turning the final exam period into a month-long hostage situation.&lt;/p&gt;
    &lt;p&gt;Unless you cheat.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enter the Voice Agent&lt;/head&gt;
    &lt;p&gt;We used ElevenLabs Conversational AI to build the examiner. The platform bundles the messy parts (speech-to-text, text-to-speech, turn-taking, interruption handling, …) into something usable. And here is the thing that surprised me: a basic version for a low-stakes setting (e.g., an assignment) can be up and running in literally minutes. Minutes. Just write a prompt describing what the agent should ask the student, and you are done.&lt;/p&gt;
    &lt;p&gt;Two features mattered a lot for our setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynamic variables: pass the student's name, project details, and other per-student context into the conversation as parameters&lt;/item&gt;
      &lt;item&gt;Workflows: build a structured flow with sub-agents instead of a single "chatty" agent trying to do everything&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What the exam looked like&lt;/head&gt;
    &lt;p&gt;We ran a two-part oral exam.&lt;/p&gt;
    &lt;p&gt;Part 1: "Talk me through your project." The agent asks about the student's capstone project: goals, data, modeling choices, evaluation, failure modes. This is where the "LLM did my homework" strategy dies. You can paste an assignment into ChatGPT. It is much harder to improvise consistent answers about specific decisions when someone is drilling into details.&lt;/p&gt;
    &lt;p&gt;Part 2: "Now do a case." The agent picks one of the cases we discussed in class and asks questions spanning the topics we covered: basically testing whether students absorbed the material or just showed up.&lt;/p&gt;
    &lt;p&gt;To handle this structure, we split the exam into sub-agents in a workflow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Authentication agent: Asks for the student's ID and refuses to proceed without a valid one. (In a more productized version, we would integrate with NYU SSO instead of checking against a list.)&lt;/item&gt;
      &lt;item&gt;Project discussion agent: Gets project context injected via parameters. The prompt includes details of each project so the agent can ask informed questions. The next step is obvious: connect retrieval over the student's submitted slides and reports so the agent can quote and probe precisely.&lt;/item&gt;
      &lt;item&gt;Case discussion agent: Selects a case and runs structured questioning. Again, RAG would help with richer case details.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This "many small agents" approach is not just aesthetic. It prevents the system from drifting into unbounded conversation, and it makes debugging possible.&lt;lb/&gt;If you want to try: Link to try the voice agent (use Konstantinos as the name and kr888 as the net id to authenticate; the project was a "LinkedIn Recruiter, an agent that scans profiles and automatically sends personalized DMs to candidates on behalf of a recruiter. It engages in the first 3 turns of chat to answer basic questions (salary, location) before handing off to a human.")&lt;/p&gt;
    &lt;head rend="h2"&gt;By the Numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;36 students examined over 9 days&lt;/item&gt;
      &lt;item&gt;25 minutes average (range: 9–64)&lt;/item&gt;
      &lt;item&gt;65 messages per conversation on average&lt;/item&gt;
      &lt;item&gt;0.42 USD per student (15 USD total)&lt;/item&gt;
      &lt;item&gt;89% of LLM grades within 1 point&lt;/item&gt;
      &lt;item&gt;Shortest exam (9 min) → highest score (19/20)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The economics&lt;/head&gt;
    &lt;p&gt;Let's talk money.&lt;/p&gt;
    &lt;p&gt;Total cost for 36 students: 15 USD.&lt;/p&gt;
    &lt;p&gt;That's 8 USD for Claude (the chair and heaviest grader), 2 USD for Gemini, 0.30 USD for OpenAI, and roughly 5 USD for ElevenLabs voice minutes. Forty-two cents per student.&lt;/p&gt;
    &lt;p&gt;The alternative? 36 students × 25-minute exam × 2 graders = 30 hours of human time. At TA rates (~25/hour), that's 750. At faculty rates, it's "we don't do oral exams because they don't scale."&lt;/p&gt;
    &lt;p&gt;For 15 dollars, we got: real-time oral examination, a three-model grading council with deliberation, structured feedback with verbatim quotes, a complete audit trail, and—as you'll see—a diagnosis of our own teaching gaps.&lt;/p&gt;
    &lt;p&gt;The unit economics in terms of cost work. We will see next that the real benefit is in the value that is delivered, not in the 50x cost savings.&lt;/p&gt;
    &lt;head rend="h2"&gt;What broke (and how we fixed it)&lt;/head&gt;
    &lt;p&gt;The first version had problems. Here is what we learned.&lt;/p&gt;
    &lt;head rend="h3"&gt;1) The voice was intimidating&lt;/head&gt;
    &lt;p&gt;A few students complained that the agent sounded severe. We had cloned Foster Provost's voice because, frankly, his clone was much more accurate than the clones of our own voices. But the students found it... intense. Here is an email from a student:&lt;/p&gt;
    &lt;quote&gt;I had prepared thoroughly and felt confident in my understanding of the material, but the intensity of the interviewer's voice during the exam unexpectedly heightened my anxiety and affected my performance. The experience was more triggering than I anticipated, which made it difficult to fully demonstrate my knowledge. Throughout the course, I have actively participated and engaged with the material, and I had hoped to better demonstrate my knowledge in this interview.&lt;/quote&gt;
    &lt;p&gt;And here is another:&lt;/p&gt;
    &lt;quote&gt;Just got done with my oral exam. [...] I honestly didn't feel comfortable with it at all. The voice you picked was so condescending that it actually dropped my confidence. [...] I don't know why but the agent was shouting at me.&lt;/quote&gt;
    &lt;p&gt;Fix: We are split on that. We love FakeFoster. But next time we will A/B test, and we will try to test other voices. At the end of the day, we want to optimize for comprehension, not charisma. ElevenLabs has guidance on voice and personality tuning: they treat this as a product design problem, and probably a good idea.&lt;/p&gt;
    &lt;head rend="h3"&gt;2) The agent stacked questions&lt;/head&gt;
    &lt;p&gt;This was the biggest real issue. The agent would ask something like: "Explain your metric choice, and also tell me what baselines you tried, and why you did not use X, and what you would do next."&lt;/p&gt;
    &lt;p&gt;That is not one question. That is four questions wearing a trench coat. The cognitive load for an oral exam is already high. Stacking questions makes it brutal.&lt;/p&gt;
    &lt;p&gt;Fix: Hard rule in the prompt: one question at a time. If you want multi-part probing, chain it across turns. For grading the exam, we included an "interference protocol": students received full credit if they had questions stacked like that and answered only some of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;3) Clarifications became moving targets&lt;/head&gt;
    &lt;p&gt;Student: "Can you repeat the question?"&lt;lb/&gt; Agent: paraphrases the question in a subtly different way&lt;/p&gt;
    &lt;p&gt;Now the student is solving a different problem than the one they were asked. Very frustrating.&lt;/p&gt;
    &lt;p&gt;Fix: Explicit instruction in the prompt: repeat verbatim when asked to repeat. No paraphrasing. Same words.&lt;/p&gt;
    &lt;head rend="h3"&gt;4) The agent did not let students think&lt;/head&gt;
    &lt;p&gt;Humans rush to fill silence. Agents do too. Students would pause to think, and the agent would jump in with follow-up probes or worse: interpret the silence as confusion and move on.&lt;/p&gt;
    &lt;p&gt;Fix: Tell the agent to allow think-time without probing aggressively. It made the exam feel less like an interrogation. We also increased the time-out before the agent asks "Are you there?" from 5 to 10 seconds.&lt;/p&gt;
    &lt;head rend="h3"&gt;5) Lack of randomization&lt;/head&gt;
    &lt;p&gt;We asked the agent to "randomly select" a case study. It did not.&lt;/p&gt;
    &lt;p&gt;From December 12–18, when Zillow was in the case list, the agent picked Zillow 88% of the time. After we removed Zillow from the prompt on December 18, the agent immediately latched onto Predictive Policing—picking it for 16 out of 21 exams on December 19 alone.&lt;/p&gt;
    &lt;p&gt;LLMs are not random. They have implicit preferences and ordering biases. Asking an LLM to "pick randomly" is like asking a human to "think of a number between 1 and 10"—you're going to get a lot of 7s.&lt;/p&gt;
    &lt;p&gt;Fix: Pass an explicit random number as a parameter and map it to cases deterministically. Do the randomization in code, not in the prompt.&lt;/p&gt;
    &lt;head rend="h2"&gt;Grading: the council deliberation actually worked&lt;/head&gt;
    &lt;p&gt;OK, so here is where things got interesting.&lt;/p&gt;
    &lt;p&gt;We graded using a "council of LLMs" approach, an idea we borrowed from Andrej Karpathy. Three models (Claude, Gemini, ChatGPT) assessed each transcript independently. Then they saw each other's assessments and revised. Finally, the chair (Claude) synthesized the final grade with evidence.&lt;/p&gt;
    &lt;p&gt;Round 1 was a mess. When the models graded independently, agreement was poor: 0% of grades matched exactly, and only 23% were within 2 points. The average maximum disagreement was nearly 4 points on a 20-point scale.&lt;/p&gt;
    &lt;p&gt;And here's the kicker: Gemini was a softie: It averaged 17/20. Claude averaged 13.4/20. That's a 3.6-point gap—the difference between a B+ and a B-.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Claude and OpenAI were already aligned: 70% of their grades were within 1 point of each other in Round 1.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 1 Mean&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 2 Mean&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Claude&lt;/cell&gt;
        &lt;cell&gt;13.4/20&lt;/cell&gt;
        &lt;cell&gt;13.9/20&lt;/cell&gt;
        &lt;cell&gt;+0.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI&lt;/cell&gt;
        &lt;cell&gt;14.0/20&lt;/cell&gt;
        &lt;cell&gt;14.0/20&lt;/cell&gt;
        &lt;cell&gt;+0.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Gemini&lt;/cell&gt;
        &lt;cell&gt;17.0/20&lt;/cell&gt;
        &lt;cell&gt;15.0/20&lt;/cell&gt;
        &lt;cell&gt;-2.0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Then came consultation. After each model saw the others' assessments and evidence, agreement improved dramatically:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Improvement&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Perfect agreement&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;21%&lt;/cell&gt;
        &lt;cell&gt;+21 pp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Within 1 point&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;62%&lt;/cell&gt;
        &lt;cell&gt;+62 pp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Within 2 points&lt;/cell&gt;
        &lt;cell&gt;23%&lt;/cell&gt;
        &lt;cell&gt;85%&lt;/cell&gt;
        &lt;cell&gt;+62 pp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Mean max difference&lt;/cell&gt;
        &lt;cell&gt;3.93 pts&lt;/cell&gt;
        &lt;cell&gt;1.41 pts&lt;/cell&gt;
        &lt;cell&gt;-2.52 pts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Gemini lowered its grades by an average of 2 points after seeing Claude's and OpenAI's more rigorous assessments. It couldn't justify giving 17s when Claude was pointing to specific gaps in the experimentation discussion.&lt;/p&gt;
    &lt;p&gt;But here's what's interesting: the disagreement wasn't random. Problem Framing and Metrics had 100% agreement within 1 point. Experimentation? Only 57%.&lt;/p&gt;
    &lt;p&gt;Why? When students give clear, specific answers, graders agree. When students give vague hand-wavy answers, graders (human or AI) disagree on how much partial credit to give. The low agreement on experimentation reflects genuine ambiguity in student responses, not grader noise.&lt;/p&gt;
    &lt;p&gt;The grading was stricter than my own default. That's not a bug. Students will be evaluated outside the university, and the world is not known for grade inflation. (Just in case you are wondering, I graded all exams myself and I asked the TA to also grade the exams; we mostly agreed with the LLM grades, and I aligned mostly with the softie Gemini. However, when examining the cases when my grades disagreed with the council, I found that the council was more consistent across students and I often thought that the council graded more strictly but more fairly.)&lt;/p&gt;
    &lt;p&gt;The feedback was better than any human would produce. The system generated structured "strengths / weaknesses / actions" summaries with verbatim quotes from the transcript. Sample feedback from the highest scorer:&lt;/p&gt;
    &lt;quote&gt;"Your understanding of metric trade-offs and Goodhart's Law risks was exceptional—the hot tub example perfectly illustrated how optimizing for one metric can corrupt another."&lt;/quote&gt;
    &lt;p&gt;Sample from a B- student:&lt;/p&gt;
    &lt;quote&gt;"Practice articulating complete A/B testing designs: state a hypothesis, define randomization unit, specify guardrail metrics, and establish decision criteria for shipping or rolling back."&lt;/quote&gt;
    &lt;p&gt;Specific. Actionable. Tied to evidence. No human grader has the time to generate that for every student.&lt;/p&gt;
    &lt;head rend="h2"&gt;It diagnosed our teaching gaps&lt;/head&gt;
    &lt;p&gt;Ha! This one stung.&lt;/p&gt;
    &lt;p&gt;When we analyzed performance by topic, one bar stuck out like a sore thumb: Experimentation. Mean score: 1.94 out of 4. Compare that to Problem Framing at 3.39.&lt;/p&gt;
    &lt;p&gt;The breakdown was brutal:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3 students (8%) scored 0—couldn't discuss it at all&lt;/item&gt;
      &lt;item&gt;7 students (19%) scored 1—superficial understanding&lt;/item&gt;
      &lt;item&gt;15 students (42%) scored 2—basic understanding&lt;/item&gt;
      &lt;item&gt;0 students scored 4—no one demonstrated mastery&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We had rushed through A/B testing methodology in class. The external grader made it impossible to ignore.&lt;/p&gt;
    &lt;p&gt;The grading output became a mirror reflecting our own weaknesses as instructors. Ooof.&lt;/p&gt;
    &lt;head rend="h3"&gt;Duration ≠ Quality&lt;/head&gt;
    &lt;p&gt;One finding I found strangely fascinating: exam duration had zero correlation with score (r = -0.03). The shortest exam—9 minutes—got the highest score (19/20). The longest—64 minutes—scored 12/20.&lt;/p&gt;
    &lt;p&gt;Taking longer doesn't mean you know more. If anything, it signals struggling to articulate. Confidence is efficient.&lt;/p&gt;
    &lt;head rend="h2"&gt;Anti-cheating (or: trust but verify)&lt;/head&gt;
    &lt;p&gt;We asked students to record themselves while taking the exam (webcam + audio). This discourages blatantly outsourcing the conversation, having multiple people in the room, or having an LLM in voice mode whispering answers. It also gives us a backup record in case something goes really badly.&lt;/p&gt;
    &lt;p&gt;And here is an underrated benefit of this whole setup: the exam is powered by guidelines, not by secret questions. We can publish exactly how the exam works—the structure, the skills being tested, the types of questions. No surprises. The LLM will pick the specific questions live, and the student will have to handle them.&lt;/p&gt;
    &lt;p&gt;This reduces anxiety and pushes students toward actual preparation instead of guessing what the instructor "wants." And it eliminates the leaked-exam problem entirely. Practice all you want—it will only make you better prepared.&lt;/p&gt;
    &lt;head rend="h2"&gt;What the students said&lt;/head&gt;
    &lt;p&gt;We surveyed students before releasing grades to capture their experience. Some of the results:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only 13% preferred the AI oral format. 57% wanted traditional written exams. 83% found it more stressful.&lt;/item&gt;
      &lt;item&gt;But here's the thing: 70% agreed it tested their actual understanding: the highest-rated item. They accepted the assessment but not the delivery.&lt;/item&gt;
      &lt;item&gt;At the same time, they almost universally liked the flexibility of taking the exam at their own place and time. Yes, many of them would have also preferred a take-home exam instead of the oral exam, but this format is dead now.&lt;/item&gt;
      &lt;item&gt;83% of students found the oral exam framework more stressful than a written exam.&lt;/item&gt;
      &lt;item&gt;The fix is clear: one question at a time, slower pacing, calmer tone. The concept works. The execution needs iteration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Try it yourself&lt;/head&gt;
    &lt;p&gt;If you want to experiment with this approach, here are some resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompt for the voice agent&lt;/item&gt;
      &lt;item&gt;Prompt for the grading council&lt;/item&gt;
      &lt;item&gt;Link to try the voice agent (use Konstantinos as the name and kr888 as the net id to authenticate; the project was a "LinkedIn Recruiter, an agent that scans profiles and automatically sends personalized DMs to candidates on behalf of a recruiter. It engages in the first 3 turns of chat to answer basic questions (salary, location) before handing off to a human.")&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What I would change next time&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Slower pacing and a calmer voice: We love you FakeFoster, but GenZ is not ready for you. Perhaps we will deploy FakePanos next time. Too bad ElevenLabs hasn't perfected thick accents yet to deliver a real Panos experience.&lt;/item&gt;
      &lt;item&gt;RAG over student artifacts (slides, reports, notebooks). ElevenLabs supports this directly. If the agent can quote the student's own submission, the exam becomes much harder to game and much more diagnostically useful.&lt;/item&gt;
      &lt;item&gt;Better case randomization with explicit seeding and tracking. Randomness that "feels random" is not enough. Pass explicit parameters.&lt;/item&gt;
      &lt;item&gt;Audit triggers in grading. If the LLM committee disagrees beyond a threshold, flag for human review. The point of a committee is not to pretend the result is always certain; it is to surface uncertainty.&lt;/item&gt;
      &lt;item&gt;Accessibility defaults. Offer practice runs, allow extra time, and provide alternatives when voice interaction creates unnecessary barriers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The bigger point&lt;/head&gt;
    &lt;p&gt;Take-home exams are dead. Reverting to pen-and-paper exams in the classroom feels like a regression. In our case, we wanted to check that the students who worked in the team projects actually contributed and understood what they submitted; we would not be able to do that with pen-and-paper exams in the classroom.&lt;/p&gt;
    &lt;p&gt;We need assessments that evolve towards formats that reward understanding, decision-making, and real-time reasoning. Oral exams used to be standard until they could not scale. Now, AI is making them scalable again.&lt;/p&gt;
    &lt;p&gt;And here is the delicious part: you can give the whole setup to the students and let them prepare for the exam by practicing it multiple times. Unlike traditional exams, where leaked questions are a disaster, here the questions are generated fresh each time. The more you practice, the better you get. That is... actually how learning is supposed to work.&lt;/p&gt;
    &lt;p&gt;Fight fire with fire.&lt;/p&gt;
    &lt;p&gt;Thanks to Brian Jabarian for the inspiration and for giving us confidence that these interviews will work, Foster Provost for lending his voice to create the FakeFoster agent (sorry, students found you intimidating!), and Andrej Karpathy for the council-of-LLMs idea.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.behind-the-enemy-lines.com/2025/12/fighting-fire-with-fire-scalable-oral.html"/><published>2026-01-02T18:18:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46468517</id><title>Jank Lang Hit Alpha</title><updated>2026-01-03T17:09:01.234459+00:00</updated><content>&lt;doc fingerprint="9d9d3879498c19d0"&gt;
  &lt;main&gt;
    &lt;p&gt;Most simply, jank is a Clojure dialect on LLVM with C++ interop. Less simply, jank is a general-purpose programming language which embraces the interactive, functional, value-oriented nature of Clojure and the desire for the native runtime and performance of C++. jank aims to be strongly compatible with Clojure. While Clojure's default host is the JVM and its interop is with Java, jank's host is LLVM and its interop is with C++.&lt;/p&gt;
    &lt;p&gt;jank is currently in alpha! Look here for details.&lt;/p&gt;
    &lt;p&gt;Read the jank book.&lt;/p&gt;
    &lt;code&gt;; Comments begin with a ;
(println "meow") ; =&amp;gt; nil

; All built-in data structures are persistent and immutable.
(def george {:name "George Clooney"}) ; =&amp;gt; #'user/george

; Though all data is immutable by default, side effects are adhoc.
(defn say-hi [who]
  (println (str "Hi " (:name who) "!"))
  (assoc who :greeted? true))

; Doesn't change george.
(say-hi george) ; =&amp;gt; {:name "George Clooney"
                ;     :greeted? true}

; Many core functions for working with immutable data.
(apply + (distinct [12 8 12 16 8 6])) ; =&amp;gt; 42

; Interop with C++ can happen *seamlessly*.
(defn sleep [ms]
  (let [duration (cpp/std.chrono.milliseconds ms)]
    (cpp/std.this_thread.sleep_for duration)))&lt;/code&gt;
    &lt;p&gt;If you'd like your name, company, or logo here, you can sponsor this project for at least $25/m.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jank-lang/jank"/><published>2026-01-02T19:39:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46468600</id><title>Publish on your own site, syndicate elsewhere</title><updated>2026-01-03T17:09:00.880180+00:00</updated><content>&lt;doc fingerprint="385cdb519a5f2b83"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;POSSE&lt;/head&gt;
    &lt;p&gt;POSSE is an abbreviation for Publish (on your) Own Site, Syndicate Elsewhere, the practice of posting content on your own site first, then publishing copies or sharing links to third parties (like social media silos) with original post links to provide viewers a path to directly interacting with your content.&lt;/p&gt;
    &lt;p&gt;▶️ watch Zach’s 1min* video intro to POSSE&lt;/p&gt;
    &lt;head rend="h2"&gt;Why&lt;/head&gt;
    &lt;p&gt;Let your friends read your posts, their way. POSSE lets your friends keep using whatever they use to read your stuff (e.g. social media silos like Instagram, Tumblr, Twitter, Neocities, etc.).&lt;/p&gt;
    &lt;p&gt;Stay in touch with friends now, not some theoretical future. POSSE is about staying in touch with current friends now, rather than the potential of staying in touch with friends in the future.&lt;/p&gt;
    &lt;p&gt;Friends are more important than federation. By focusing on relationships that matter to people rather than architectural ideals, from a human perspective, POSSE is more important than federation. Additionally, if federated approaches take a POSSE approach first, they will likely get better adoption (everyone wants to stay in touch with their friends), and thereby more rapidly approach that federated future.&lt;/p&gt;
    &lt;p&gt;POSSE is beyond blogging. It's a key part of why and how the IndieWeb movement is different from just "everyone blog on their own site", and also different from "everyone just install and run (YourFavoriteSocialSoftware)" etc. monoculture solutions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why In General&lt;/head&gt;
    &lt;p&gt;POSSE is considered a robust and preferable syndication model for the following reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce 3rd party dependence. By posting directly to your own site, you're not dependent on 3rd Party services to do so -- if you can access your site, you can publish your content. On the contrary with PESOS, when the 3rd party site is down, you are unable to add content.&lt;/item&gt;
      &lt;item&gt;Ownership. By posting first on your own site, you create a direct ownership chain that can be traced back to you without any intervening 3rd party services (silos) TOS's getting in the way (which is a vulnerability of PESOS).&lt;/item&gt;
      &lt;item&gt;Own canonical URLs to your content. Canonical URLs to your content are on your domain.&lt;/item&gt;
      &lt;item&gt;Copies can cite the original. By posting content first to your own site (and thus creating a permalink for it), copies that you post on 3rd Party services can link or cite the original on your site (see syndication_formats and POSSE Notes to Twitter)&lt;/item&gt;
      &lt;item&gt;Better search. Searching public content on your own domain (with any web search engine of your choice) works better than depending on silos exclusively to search your posts (e.g. Twitter for a while only showed recent tweets in search results. Facebook still has very poor search results).&lt;/item&gt;
      &lt;item&gt;backfeed can be used to pull in (reverse syndicate) responses from other services&lt;/item&gt;
      &lt;item&gt;allows taking advantage of other services' social layers and aggregation features while storing the canonical copy of your content on your own site&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why Link To Your Original&lt;/head&gt;
    &lt;p&gt;Common POSSE practice is to link from POSSE copies to your original, using a permashortlink. Here are a few reasons why:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discovery of your original content. discovery of your original content from the copies on 3rd party services is enabled by the permashortlinks to your originals posted on said services&lt;/item&gt;
      &lt;item&gt;Subvert spammers who copy your posts. When spammers (e.g. @sin3rss) mindlessly copy from your POSSE copies and repost, they also copy the link back to the original, and thus provide more distribution for people to find and view your original post. "2011-01-09 internet aikido" of a sort.&lt;/item&gt;
      &lt;item&gt;Better ranking for your original posts. If/when your POSSE copies are themselves copied by others and (re)posted elsewhere (e.g. manual retweets, RSS bots etc.), when the copies link to your original posts, search engines figure that out by following those links back to the original and ranking it higher.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How to&lt;/head&gt;
    &lt;head rend="h3"&gt;How to implement&lt;/head&gt;
    &lt;p&gt;This section is for web developers implementing POSSE.&lt;/p&gt;
    &lt;head rend="h4"&gt;In General&lt;/head&gt;
    &lt;p&gt;In general, when your content posting software posts something, it should also post a copy to the silo destinations of your choice, with an original post link (e.g. permashortlink or permashortcitation) back to your original.&lt;/p&gt;
    &lt;p&gt;The details of how to do so vary per destination. See the silo-specific sections below.&lt;/p&gt;
    &lt;p&gt;Once you have posted the copy to the silo, you should:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;link to the syndicated copy from the original in a posts-elsewhere section on your post.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;User Interface&lt;/head&gt;
    &lt;p&gt;The best user interface (UI) is automatic, dependable, and invisible. If you can implement POSSEing in a way that always does exactly what you want, predictably, then no explicit UI is needed.&lt;/p&gt;
    &lt;head rend="h5"&gt;Preview&lt;/head&gt;
    &lt;p&gt;One way to provide more predictability and inspire confidence is to show what will be POSSEd (within the limitations of the destination) as a preview before publishing&lt;/p&gt;
    &lt;p&gt;(needs screenshot)&lt;/p&gt;
    &lt;p&gt;Twitter is perhaps the most popular POSSE destination and a good place to start.&lt;/p&gt;
    &lt;p&gt;If you can start posting notes (tweets) to your own site and POSSEing to Twitter, instead of posting directly to Twitter, you have taken a big step towards owning your data.&lt;/p&gt;
    &lt;p&gt;Details:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API Access - posting new tweets works nicely due to permanent API tokens, and the return value contains a URL to the posted &lt;list rend="ul"&gt;&lt;item&gt;As of 2022-11, Twitter is rejecting new API access for applications used to POSSE/backfeed on the grounds that they may violate twitter’s rules and/or policies — Barnaby Walters&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Supports very complete web action endpoints, so semi-manual posting is easy to implement &lt;list rend="ul"&gt;&lt;item&gt;What are these endpoints? Is this still the case in 2022? — Barnaby Walters&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See POSSE to Twitter for details on how to POSSE both notes and articles (blog posts) to Twitter.&lt;/p&gt;
    &lt;p&gt;There are two options for POSSEing to Facebook currently:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manually crosspost&lt;/item&gt;
      &lt;item&gt;Semi-automatically with the Bridgy browser extension for Facebook&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Medium&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can create posts via the posts API&lt;/item&gt;
      &lt;item&gt;Medium also supports manual POSSE via the Import Post function, which preserves rel-canonical links to the original URL&lt;/item&gt;
      &lt;item&gt;Shane Becker and Ben Werdmüller manually POSSE to Medium&lt;/item&gt;
      &lt;item&gt;Chris Aldrich uses the WordPress Medium Plugin to POSSE to Medium. They also support bulk migration (aka mass POSSE) for porting across lots of posts after which posts can be POSSEd by means of their plugin.&lt;/item&gt;
      &lt;item&gt;Aaron Gustafson Wrote a Jekyll plugin to POSSE to Medium.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;WordPress&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How does veganstraightedge.com do it? (all his articles are manually POSSEd to WordPress.com)&lt;/item&gt;
      &lt;item&gt;Chris Aldrich uses a WordPress plugin WordPress Crosspost to POSSE from a self-hosted WordPress install to WordPress.com.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Plain Text Notes&lt;/head&gt;
    &lt;p&gt;Some destinations (e.g. SMS or push notifications) may require a pure plain text representation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;h-entry_to_text is a method of generating a plain text representation from an arbitrary h-entry&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Software&lt;/head&gt;
    &lt;p&gt;Software and libraries to implement POSSE:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PHP &lt;list rend="ul"&gt;&lt;item&gt;The POSSE namespace in php-helpers (might be moved to a separate package) contains various truncation, preparation and syndication functions including HTML =&amp;gt; plaintext µblog syntax converter&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Python &lt;list rend="ul"&gt;&lt;item&gt;SiloRider is a command-line tool, implemented in Python, that lets you implement POSSE to various services (Twitter and Mastodon as of 2018-08-01).&lt;/item&gt;&lt;item&gt;Feed2Toot is another command-line python tool that parses any number of RSS feeds and posts their content on ActivityPub based services (tested with: Mastodon, Pleroma). Contains some neat bells and whistles like advanced post filtering, numerous options for feed parsing and toot formatting.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Docker &lt;list rend="ul"&gt;&lt;item&gt;POSSE Party: self-hosted software for POSSE&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Services&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bridgy Publish is POSSE-as-a-service. It supports Twitter, Flickr, GitHub and Mastodon. You can use it interactively or programmatically via webmention.&lt;/item&gt;
      &lt;item&gt;Mugged Tweets - will POSSE a note to a mug (may require first POSSEing to Twitter)&lt;/item&gt;
      &lt;item&gt;IFTTT allows automatically reposting content with an RSS or Atom feed to a number of silos incuding Twitter, Tumblr, and Facebook&lt;/item&gt;
      &lt;item&gt;EchoFeed&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Publishing Flows&lt;/head&gt;
    &lt;p&gt;There's at least two ways to implement a POSSE content posting flow:&lt;/p&gt;
    &lt;head rend="h5"&gt;Client to site to silo&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The user writes a piece of content using a publishing client &lt;list rend="ul"&gt;&lt;item&gt;Optional: client provides UI for selecting which 3rd party services to push to if it knows about them, with optional customizations for per service&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Having finished the content, the user publishes content to their server (optionally: with metadata of which 3rd party services and any customizations thereof) &lt;list rend="ul"&gt;&lt;item&gt;Optional: client can generate a permalink knowing the state of the server, and publish to that permalink&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The server publishes the content, generates a permalink and summary (and/or customized content suited to 3rd party services) if necessary&lt;/item&gt;
      &lt;item&gt;The server posts copies with permalinks to 3rd party services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User only has to interact with one site over the internet, their own&lt;/item&gt;
      &lt;item&gt;Syndication can be done fully automatically by the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disadvantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;any?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Client to site and silo&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The user writes a piece of content using a publishing client&lt;/item&gt;
      &lt;item&gt;Having finished the content, the user publishes it to their server&lt;/item&gt;
      &lt;item&gt;The client queries the server for the URL of the content it just pushed&lt;/item&gt;
      &lt;item&gt;The publishing client presents the user with an interface for selecting: &lt;list rend="ul"&gt;&lt;item&gt;Which 3rd party services to publish to&lt;/item&gt;&lt;item&gt;The exact content published to the services, pre-filled with a summary based on the produced content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The user selects the services and submits the form&lt;/item&gt;
      &lt;item&gt;The publishing client posts the content summaries out to the 3rd party services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More user control over timing and editing of copies of content to 3rd party services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disadvantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syndication requires a manual step each time&lt;/item&gt;
      &lt;item&gt;Dependent on client connectivity directly to 3rd party services (problematic in flakey mobile situations, or when client is publishing using domain-censored internet access).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;IndieWeb Examples&lt;/head&gt;
    &lt;p&gt;The following IndieWebCamp participants' sites support a POSSE architecture. If you have an implementation, add it, make screenshots or a screencast or blog about it and post the details/link here. In date order (earliest first) :&lt;/p&gt;
    &lt;head rend="h3"&gt;Tantek&lt;/head&gt;
    &lt;p&gt;Tantek.com as of 2010-01-01[1] (2010-01-26 Twitter syndication started[2] and caught up[3][4]). Tantek Çelik implemented POSSE in Falcon on tantek.com.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;all self-hosted posts are openly with PuSH v0.4 + h-feed and Atom real-time syndicated with a PubsubHubbub hub to StatusNet, other subscribers etc. (also to Google Buzz til it shutdown)&lt;/item&gt;
      &lt;item&gt;note (and article titles), reply, RSVP posts are snowflake copied by the personal site server to Twitter with permashortlink citation links/references (see Whistle for details) back to the original. Copies of notes to Twitter are also automatically recopied from there to Facebook.&lt;/item&gt;
      &lt;item&gt;likes of tweets are "copied" (more like propagated) to Twitter using Bridgy publish&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Barnaby Walters&lt;/head&gt;
    &lt;p&gt;Waterpigs.co.uk as of 2012-03-12. Barnaby Walters implemented POSSE over at waterpigs.co.uk&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;as of 2012-09-25 all collections (notes, articles, activity) are PuSH-subscribable feeds.&lt;/item&gt;
      &lt;item&gt;Using the Client to Server to 3rd Parties flow --Waterpigs.co.uk 06:08, 25 September 2012 (PDT)&lt;/item&gt;
      &lt;item&gt;Syndicating to Twitter + Facebook&lt;/item&gt;
      &lt;item&gt;As of 2014-06-19 Taproot can now optionally post additional POSSE tweets when updating a note or article — example of updated note and POSSE tweet for the update. Note that Bridgy successfully backfeeds silo interactions from the update tweet as well as the original POSSE tweet&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Brennan Novak&lt;/head&gt;
    &lt;p&gt;brennannovak.com as of 2012-07-01[5][6]. Brennan Novak implemented POSSE on his site brennannovak.com with copies posted to Twitter and Facebook&lt;/p&gt;
    &lt;head rend="h3"&gt;Aaron Parecki&lt;/head&gt;
    &lt;p&gt;aaronparecki.com as of 2012-08-19[7][8]. Aaron Parecki implemented POSSE on his site aaronparecki.com with copies posted to Twitter containing permashortlinks back to originals on his own site.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;as of 2012-08-19 all collections (notes, articles, replies) are PuSH-subscribable feeds.&lt;/item&gt;
      &lt;item&gt;Posting UI as of 2012-09-09: http://aaronparecki.com/2012/253/note/3&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Sandeep Shetty&lt;/head&gt;
    &lt;p&gt;User:Sandeep.io First post POSSE'd on 2012-11-05. I primarily syndicate to Twitter using a very lo-fi solution of adding silo (Facebook, Twiiter, Google+) provided share links to each post that I can manually click to prefill content, edit and post. I've avoided API integration because of the extensive experience I've had using Facebook API and dealing with it's random changes. "Integration" has high costs sometimes so I keep it as simple as possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ben Werdmuller&lt;/head&gt;
    &lt;p&gt;werd.io as of 2013-05-31 [9]. Ben Werdmuller implemented POSSE in his idno platform via plugins. New content has an associated Activity Streams object type; POSSE plugins listen for post events associated with those object types and syndicate appropriately.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Notes and articles are syndicated to Twitter and Facebook&lt;/item&gt;
      &lt;item&gt;Images are syndicated to Facebook, Flickr and Twitter&lt;/item&gt;
      &lt;item&gt;Places are syndicated to Foursquare&lt;/item&gt;
      &lt;item&gt;More plugins are very easily possible; the Foursquare plugin took about an hour to build&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Shane Becker&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Shane Becker using Dark Matter on veganstraightedge.com (since 2013-07-17[10]) with automatic rel-syndication markup on manual POSSEing:&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Glenn Jones&lt;/head&gt;
    &lt;p&gt;glennjones.net as of 2014-01-14 Glenn Jones The blog implemented POSSE using a new version of transmat.io system. New content added to transmat is associated with objects types. A POSSE twitter plugins listens for post events syndicating content. At moment only notes are syndicated.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jeremy Keith&lt;/head&gt;
    &lt;p&gt;adactio.com as of 2014-05-27 Jeremy Keith has implemented POSSE using his own custom CMS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Notes have been POSSEd since he first started posting them on his own site, on 2014-05-27 (Note POSSE copy may say 2014-05-26 presumably because of timezone differences, Jeremy's is in BST, while a PDT viewer sees datetime adjusted accordingly). See also related blog post 2014-06-01.&lt;/item&gt;
      &lt;item&gt;Photos have been POSSEd to Twitter since he first started posting them on his own site on 2014-07-05 and to Flickr since 2014-07-08. Examples: &lt;list rend="ul"&gt;&lt;item&gt;http://adactio.com/notes/6978/&lt;/item&gt;&lt;item&gt;http://adactio.com/notes/7021 - first photo POSSEd to both Twitter and Flickr:&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Shane Hudson&lt;/head&gt;
    &lt;p&gt;shanehudson.net as of 2014-09-19 Shane Hudson has implemented POSSE to Twitter for Craft CMS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Previously working on Wordpress but he was not keen on the UX.&lt;/item&gt;
      &lt;item&gt;Has reply contexts working but has to manually copy the ID.&lt;/item&gt;
      &lt;item&gt;Not yet POSSEing photos but plans to.&lt;/item&gt;
      &lt;item&gt;Currently he has to manually copy the tweet from the main text box to a 140 character limit tweet text box. He plans to make that automatic.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;Ravi Sagar&lt;/head&gt;
    &lt;p&gt;http://www.ravisagar.in/blog/implementing-posse-my-site Implementing POSSE on my site as of 2018-02-21.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The new blogs and notes are posted on Drupal&lt;/item&gt;
      &lt;item&gt;http://www.ravisagar.in/rss-social.xml RSS Feed is generated for the blogs and notes tagged with "Share" keyword&lt;/item&gt;
      &lt;item&gt;Using Rebrandly to create shortlinks for the RSS Feed&lt;/item&gt;
      &lt;item&gt;Using Zapier to share the newly created rebrandly links to Twitter and Linkedin&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;Ludovic Chabant&lt;/head&gt;
    &lt;p&gt;ludovic.chabant.com as of 2018-07-30 Ludovic Chabant has implement POSSE to Twitter and Mastodon from PieCrust CMS, using SiloRider&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SiloRider is CMS independent -- it only relies on Microformats found in the published markup.&lt;/item&gt;
      &lt;item&gt;New articles are posted as title and link.&lt;/item&gt;
      &lt;item&gt;New microblogging updates are mostly copied verbatim (if the fit the external service's character limits), and support photo posts, including multi-photo posts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;Adam Dawkins&lt;/head&gt;
    &lt;p&gt;adamdawkins.uk as of 2019-01-16 Adam Dawkins has implemented POSSE using his own custom CMS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Notes have been POSSEd since he first started posting them on his own site, on 2019-01-16&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Examples&lt;/head&gt;
    &lt;head rend="h3"&gt;Shaun Ewing&lt;/head&gt;
    &lt;p&gt;shaun.net as of 2020-01-16 Shaun Ewing has implemented POSSE using Jekyll, and custom APIs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More information https://shaun.net/notes/taking-back-control-of-my-content/&lt;/item&gt;
      &lt;item&gt;Syndication is still manual, and I'm still working on Level 3/4 "IndieMark" items such as WebMentions, etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;capjamesg&lt;/head&gt;
    &lt;p&gt;capjamesg has been syndicating his notes from his own site to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Twitter using brid.gy&lt;/item&gt;
      &lt;item&gt;micro.blog using micro.blog's feed polling system&lt;/item&gt;
      &lt;item&gt;The fediverse using fed.brid.gy&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This syndication happens automatically whenever James posts a note using his Micropub client or his Microsub feed reader.&lt;/p&gt;
    &lt;head rend="h3"&gt;... add more here ...&lt;/head&gt;
    &lt;p&gt;... Add a link to your POSSE–enabled site and the date you started syndicating copies of your content out to 3rd party social sharing/publishing services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Partial POSSE sites&lt;/head&gt;
    &lt;p&gt;Sites which only POSSE some of their content, and still post directly to the same silo they POSSE to.&lt;/p&gt;
    &lt;p&gt;Other partial POSSE sites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User:Hupili.net implements a partial POSSE with the following setups: &lt;list rend="ul"&gt;&lt;item&gt;SNSAPI is a lightweight middleware to unify the data structure and interfaces of different social networking services. It gives the scripting flexibility for developer users to manipulate social silos.&lt;/item&gt;&lt;item&gt;SNSRouter is a web UI built upon SNSAPI where one can read an aggregated timeline from different sites, mass forward messages, and update statuses on all channels.&lt;/item&gt;&lt;item&gt;As is said in one of the description paragraph above, this model is not truly POSSE. One can not (hardly) distinguish original/ syndicated status. I'm planning to put a page with permlink on my site upon each status update and then use SNSAPI to syndicate to other silos.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other Approaches&lt;/head&gt;
    &lt;head rend="h3"&gt;COPE&lt;/head&gt;
    &lt;p&gt;COPE is short for Create Once, Publish Everywhere (COPE), which explicitly lacks a first "Publish Once" step, and thus is more about duplicating the content across various destinations.&lt;/p&gt;
    &lt;p&gt;Without a first "Publish Once" step on a site you "Own", and thus lacking original post permalinks, the COPE strategy fails to actually draw people to any one canonical place to read/view your stuff, and thus all it does is grow (likely) disjoint audiences across other people’s sites.&lt;/p&gt;
    &lt;p&gt;Articles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2009-10-13 COPE: Create Once, Publish Everywhere by Daniel Jacobson, Director of Application Development for NPR. (Original https://www.programmableweb.com/news/cope-create-once-publish-everywhere/2009/10/13 offline due to site-death of programmableweb.com in 2022)&lt;/item&gt;
      &lt;item&gt;2019-10-28 Create Once, Publish Everywhere With WordPress by Leonardo Losovitz in Smashing Magazine&lt;/item&gt;
      &lt;item&gt;2019 WordCamp Taipei talk: Create Once, Publish Everywhere video on WordPress.tv&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;POSE&lt;/head&gt;
    &lt;p&gt;POSE, Publish Once Syndicate Everywhere, was a broader predecessor of POSSE that also included publishing once on one particular silo, and then syndicating out to other silos.&lt;/p&gt;
    &lt;head rend="h3"&gt;PESOS&lt;/head&gt;
    &lt;p&gt;A similar but opposite approach is PESOS where content is posted first to 3rd party services and then copied/syndicated into a personal site.&lt;/p&gt;
    &lt;p&gt;If exact copies of content are posted on both a personal site and 3rd party services, there's no way to tell (short of comparing possibly non-existent sub-second accurate published dates) whether a site is using POSSE or PESOS. Sites can provably support POSSE by including perma(short)links in syndicated copies that link/reference back to published originals.&lt;/p&gt;
    &lt;head rend="h3"&gt;PESETAS&lt;/head&gt;
    &lt;p&gt;PESETAS is like PESOS but copying/syndicating everything to a particular silo (without any involvement of a personal site).&lt;/p&gt;
    &lt;p&gt;For example, most silos support cross-posting to Twitter, thus you could connect everything to your Twitter account and always (auto-)cross-post there to keep a copy.&lt;/p&gt;
    &lt;p&gt;E.g. Tumblr has a UI for cross-posting to Twitter. See Webapps StackExchange post for documentation and screenshots of UI.&lt;/p&gt;
    &lt;p&gt;Tumblr is a better PESETAS destination however, since it is well established, allows for a wider variety of content, and allows more text, and links to URLs directly instead of linkwrapping them like Twitter does.&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h2"&gt;Brainstorming&lt;/head&gt;
    &lt;head rend="h3"&gt;CRUD&lt;/head&gt;
    &lt;p&gt;All of the above, and to date (2013-222), POSSE has solely described syndicating the Creation of content on your site (publishing) to other sites. This model has been quite successful and perhaps may be sufficient.&lt;/p&gt;
    &lt;p&gt;However, it is worth exploring the potential utility of a full CRUD protocol for POSSE.&lt;/p&gt;
    &lt;head rend="h3"&gt;Create&lt;/head&gt;
    &lt;p&gt;Create is the POSSE default. You create content on your site, you POSSE your creates to other sites. All of this is described above, and in silo-specific details on silo pages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Read&lt;/head&gt;
    &lt;p&gt;Read as a verb is interesting when applied to POSSE.&lt;/p&gt;
    &lt;p&gt;At a minimum, it's useful to implement storing links to syndicated copies of your content to provide for the future possibility of reading from downstream POSSE copies.&lt;/p&gt;
    &lt;p&gt;See:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;u-syndication for how to markup links to syndicated copies of your content&lt;/item&gt;
      &lt;item&gt;syndication-link-use-cases for why to do so&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Actual direct uses of Reading from downstream POSSE copies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reverse-syndication / backfeed of activity around the POSSE copy onto your original:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In addition, keeping a u-syndication link to the POSSE copy enables deleting it to perform an Update or a Delete action, as described in the following sections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update&lt;/head&gt;
    &lt;p&gt;If a POSSE destination allows updates/edits, then when you edit your post, you could propagate that update to the downstream POSSE copy as well.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E.g. Facebook allows editing the text of a post (including any links in the text), person tags, but not the image of a photo post&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the destination disallows updates/edits, like Twitter, it is still possible to virtually POSSE updates by deleting the POSSE tweet and reposting, i.e.:&lt;/p&gt;
    &lt;p&gt;Consider only POSSEing updates to Twitter:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;if no one has replied to it yet (otherwise you'd break a threaded conversation on Twitter)&lt;/item&gt;
      &lt;item&gt;if your changes would be shown in the truncated copy on Twitter (i.e. if your changes are past the 140 (more like 120) character horizon, no point in churning the Twitter copy).&lt;/item&gt;
      &lt;item&gt;within a very short time window, maybe like 2-5 minutes, because otherwise the update will be seen as a duplicate to people who are reading you on Twitter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of these concerns are regarding the experience that you provide to your friends reading your tweets on Twitter, which of course should be the whole (design) reason you're bothering to POSSE to Twitter in the first place.&lt;/p&gt;
    &lt;p&gt;For details, see silo-specific POSSE sections:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Facebook: POSSE to Facebook (to-do: needs details re: edit text ok, but no photo editing, photo posts need delete/repost to simulate POSSE update)&lt;/item&gt;
      &lt;item&gt;Flickr: (UI supports manually updating the image of a photo post, but is that available in the API? and if so, file a Bridgy Publish feature request GitHub issue to support POSSE Update to Flickr (including the image of a photo post)&lt;/item&gt;
      &lt;item&gt;Twitter: POSSE to Twitter (to-do: copy the above delete/repost strategy to there)&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Delete&lt;/head&gt;
    &lt;p&gt;Deletes seem fairly straightforward to POSSE, especially to services which themselves propagate deletes to clients.&lt;/p&gt;
    &lt;p&gt;E.g. one can delete a note on Twitter at any point.&lt;/p&gt;
    &lt;p&gt;Similar to updates, consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;if there are already replies to a POSSE copy (or activity like favorites/retweets), consider keeping it to keep conversation threading (and others' favorites/retweets).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, if you really feel like deleting the content from your site and POSSE copies (e.g. on Twitter), go ahead and do so.&lt;/p&gt;
    &lt;p&gt;Perhaps this is an opportunity for the UI for the deletion of a post to check to see if there's been any activity (replies, favorites, retweets) on the POSSE copy before performing the delete. One possible implementation could involve the UI informing the user of this activity (or lack of it) and reconfirming the delete request on a per-service basis.&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h4"&gt;IndieWeb Examples&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Grant Richmond supports POSSE deletes on twitter as of 2018-10-10, by checking if a post on his site has been unpublished / deleted and sending the appropriate api request for likes, reposts and notes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h3"&gt;Worry about search engines and duplicates&lt;/head&gt;
    &lt;p&gt;Q: Do we need to worry about search engines penalizing apparently duplicate posts?&lt;/p&gt;
    &lt;p&gt;A: That's why the POSSE copies SHOULD always link back to the originals. So that search engines can infer that the copies are just copies. Ideally POSSE copies on silos should use rel-canonical to link back to the originals, but even without explicit rel-canonical, the explicit link back to the original is a strong hint that it is an original.&lt;/p&gt;
    &lt;p&gt;This is also an advantage of POSSE over PESOS. With PESOS - there's no way to tell what's the original and what's the copy - so they do look like duplicates.&lt;/p&gt;
    &lt;head rend="h3"&gt;POSSE-post-discovery and backlinks&lt;/head&gt;
    &lt;p&gt;Q: Brid.gy can use posse-post-discovery to find the relationship between a syndicated post and the original when there is not explicit link. Does this mean I should stop adding backlinks to syndicated copies?&lt;/p&gt;
    &lt;p&gt;A: POSSEing without a backlink is considered a last resort, and has some costs associated with it. See posse-post-discovery#Tradeoffs for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;POSSE or Send Webmentions First&lt;/head&gt;
    &lt;p&gt;In short, POSSE first, then send webmentions.&lt;/p&gt;
    &lt;p&gt;See: Webmention FAQ: POSSE or Send Webmentions First for details and reasoning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2010-05-26 POSSE first described online as a concept in Tantek Celik on DiSo 2.0: Down to Brass Tacks(archived monkinetic original) : &lt;p&gt;Publish on your own site, own your URLs, your permalinks, and&lt;/p&gt;&lt;lb/&gt;Syndicate out to other sites. Your text updates to Twitter, your checkins to Foursquare, your photos to Flickr etc.&lt;/item&gt;
      &lt;item&gt;2010-10-06 POSSE+backfeed conceptual architecture (predating the terms) &lt;lb/&gt;Note the arrows to/from the "Personal site" in the middle. Arrows outward are conceptually illustrating POSSE, while those returning, backfeed.&lt;lb/&gt;See 2011-01-10 post relating/expanding on it: On Owning Your Data: Follow-up to @Zeldman and the #indieweb&lt;/item&gt;
      &lt;item&gt;2011-06-25 IndieWebCamp 2011 session: "Publish Then Syndicate and Replicate" further explored POSSE conceptually.&lt;/item&gt;
      &lt;item&gt;2012-06-21 POSSE term defined: http://tantek.com/2012/173/t1/posse-core-indieweb-approach&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Related conceptually:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;sometime before 2014-06-21[11]: POSE (Publish Once Syndicate Everywhere) term defined at some point prior to POSSE. Conceptually it was looser than POSSE, as "once" could be interpreted as on a silo rather than your "own site", which POSSE (and the conceptual predecessors) made explicit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Articles&lt;/head&gt;
    &lt;p&gt;Articles and blog posts about POSSE, especially implementing it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hipster :&lt;/item&gt;
      &lt;item&gt;An audience/context-conscious POSSE syndication plugin for WordPress&lt;/item&gt;
      &lt;item&gt; Ars Technica) How Google’s AMP project speeds up the Web—by sandblasting HTML (&lt;p&gt;[…] this nudges publishers toward an idea that's big in the IndieWeb movement: Publish (on your) Own Site, Syndicate Elsewhere (or POSSE for short).&lt;/p&gt;&lt;p&gt;The idea is to own the canonical copy of the content on your own site but then to send that content everywhere you can. Or rather, everywhere you want to reach your readers. Facebook Instant Article? Sure, hook up the RSS feed. Apple News? Send the feed over there, too. AMP? Sure, generate an AMP page. No need to stop there—tap the new Medium API and half a dozen others as well.&lt;/p&gt;&lt;p&gt;Reading is a fragmented experience. Some people will love reading on the Web, some via RSS in their favorite reader, some in Facebook Instant Articles, some via AMP pages on Twitter, some via Lynx in their terminal running on a restored TRS-80 (seriously, it can be done. See below). The beauty of the POSSE approach is that you can reach them all from a single, canonical source.&lt;/p&gt;&lt;p&gt;[…]&lt;/p&gt;&lt;p&gt;For the Web's sake, let's hope Google sticks with AMP long enough to convince publishers that the real future is speeding up their own pages and embracing a POSSE-style approach.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;2018-07-31 : Stepping back from POSSE (archived)&lt;/item&gt;
      &lt;item&gt;2023-10-23 : The poster’s guide to the internet of the future (archived) &lt;list rend="ul"&gt;&lt;item&gt;Mentions POSSE by name, micro.blog, Bridgy, and links to this page&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2024-09-27 : POSSE: Reclaiming social media in a fragmented world&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;POSSE as methodology for non-web scenarios&lt;/head&gt;
    &lt;head rend="h3"&gt;POSSE git repositories&lt;/head&gt;
    &lt;p&gt;As discussed #indieweb it is also possible POSSE your git repositories to git "silos", such as GitHub or GitLab. An easy way of doing this was described by Christian Weiske at [12].&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h2"&gt;Sessions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2011: Publish Then Syndicate and Replicate&lt;/item&gt;
      &lt;item&gt;2013/Secure Cross-Posting&lt;/item&gt;
      &lt;item&gt;2014/SF/possepatterns&lt;/item&gt;
      &lt;item&gt;2016/Brighton/howposse&lt;/item&gt;
      &lt;item&gt;2016/StaticPOSSE&lt;/item&gt;
      &lt;item&gt;2016/Dusseldorf/syndication&lt;/item&gt;
      &lt;item&gt;2017/Berlin/possepesos&lt;/item&gt;
      &lt;item&gt;2019/Amsterdam/syndication&lt;/item&gt;
      &lt;item&gt;2019/NYC/syndication&lt;/item&gt;
      &lt;item&gt;2019/Düsseldorf/syndicate&lt;/item&gt;
      &lt;item&gt;2024/Brighton/posse&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;See Also&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;POSSE reply&lt;/item&gt;
      &lt;item&gt;PESOS&lt;/item&gt;
      &lt;item&gt;PESETAS&lt;/item&gt;
      &lt;item&gt;why&lt;/item&gt;
      &lt;item&gt;original post link&lt;/item&gt;
      &lt;item&gt;microsyntax for POSSEing to plain text destinations&lt;/item&gt;
      &lt;item&gt;rel-canonical&lt;/item&gt;
      &lt;item&gt;Documentation on syndication formats&lt;/item&gt;
      &lt;item&gt;posts-elsewhere&lt;/item&gt;
      &lt;item&gt;2017-11-09 Nicolas Hoizey: Medium is only an edge server of your POSSE CDN, your own blog is the origin&lt;/item&gt;
      &lt;item&gt;2018-03-24 Hacker News comment thread: https://news.ycombinator.com/item?id=16663850&lt;/item&gt;
      &lt;item&gt;HN ibid: "Why won't a link on these platforms suffice since they have their "cards"?"&lt;/item&gt;
      &lt;item&gt;HN ibid: "This is an interesting thing, but too complicated and over-broad for the mere-mortal." &amp;lt;-- page introduction needs simplifying, simpler instructions to setup POSSE, acknowledge where POSSE usability is in the Generations spectrum&lt;/item&gt;
      &lt;item&gt;HN ibid: "Facebook is just a glorified RSS feed with centralized discover ability." &amp;lt;-- debunk with comparing Facebook#Features (and Twitter#Features) vs RSS plumbing feature set. A visual diagram/table comparison might help.&lt;/item&gt;
      &lt;item&gt;HN ibid: "This really is not possible with RSS at all, especially since the silos don’t want to support RSS in any meaningful way." &amp;lt;-- perhaps add a whole subsection in "Why" explaining why RSS is insufficient compared to POSSE.&lt;/item&gt;
      &lt;item&gt;2021-11-07 Hacker News comment thread: https://news.ycombinator.com/item?id=29115696&lt;/item&gt;
      &lt;item&gt;Recommend non-realtime POSSE to Twitter and other social media due to their active use as part of the surveillance apparatus of local and national law enforcement: https://theintercept.com/2020/07/09/twitter-dataminr-police-spy-surveillance-black-lives-matter-protests/&lt;/item&gt;
      &lt;item&gt;Jetpack 8.9 adds Social Previews which allows one to preview how your posts will appear on Facebook, Twitter, and Google search results before you hit the publish button!&lt;/item&gt;
      &lt;item&gt;Consider a deliberate ethical use of POSSEing, e.g. see Code of Ethics for an example set of explicit self-stated “Rules of engagement”&lt;/item&gt;
      &lt;item&gt;“Pluralistic is my mutli-channel publishing effort – a project to push the limits of POSSE (post own site, share everywhere)” Pluralistic: 05 May 2021&lt;/item&gt;
      &lt;item&gt;Cory Doctorow explains how he uses POSSE. This Week in Google (time offset 474s): https://www.youtube.com/watch?v=qyU2cZLFsik&amp;amp;t=474s &lt;p&gt;I try not to get locked into anyone else’s walled garden. I … pursue this publishing strategy they call POSSE, post own site syndicate everywhere …&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;articles: 2018-02-06 Dries Buytaert To PESOS or to POSSE? and 2018-02-16 Dries Buytaert My POSSE plan for evolving my site&lt;/item&gt;
      &lt;item&gt;https://twitter.com/SaraSoueidan/status/1539870410317221888 &lt;list rend="ul"&gt;&lt;item&gt;"What Matthias said.&lt;lb/&gt;Write on your own blogs, syndicate elsewhere.&lt;lb/&gt;Own your content! There's nothing like it." @SaraSoueidan June 23, 2022&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;"What Matthias said.&lt;/item&gt;
      &lt;item&gt;Brainstorm: Tantek Çelik: POSSE advantages are largely distribution (immediately) and discovery (over time). if neither of those two are happening, then it's not worth keeping it around. Date-time-proof-of-posting can be solved by sending your original post (or a POSSE/tweet copy) to the Internet Archive and does not require keeping the POSSE/tweet copy.&lt;/item&gt;
      &lt;item&gt;https://andy-bell.co.uk/how-im-dealing-with-twitter-in-a-hands-off-manner/&lt;/item&gt;
      &lt;item&gt;Why: 2023-07-13 Jeremy Keith: The syndicate &lt;p&gt;We’ll see how long it lasts. We’ll see how long any of them last. Today’s social media darlings are tomorrow’s Friendster and MySpace.&lt;/p&gt;&lt;p&gt;When the current crop of services wither and die, my own website will still remain in full bloom.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;https://mastodon.social/@davidpierce/111284796654263440 &lt;list rend="ul"&gt;&lt;item&gt;"For the last six months or so I've been obsessed with POSSE, a decade-old idea about how to mix the best of blogging and social media. For a story and for The Vergecast, I tried to figure out how POSSE could work — and why it might not https://www.theverge.com/2023/10/23/23928550/posse-posting-activitypub-standard-twitter-tumblr-mastodon" @davidpierce October 23, 2023&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;to-do: draw an updated diagram without Twitter (replace with Bluesky), and to Fediverse via BridgyFed with a line that ends in "Y" with 📤 📥 on the ends&lt;/item&gt;
      &lt;item&gt;update any references / instructions to POSSE to Twitter to note historical importance and current lack of automated support&lt;/item&gt;
      &lt;item&gt;to-do: add a http://micro.blog section to the "How to" section; make sure to link to micro.blog&lt;/item&gt;
      &lt;item&gt;Why: 2024-02-24 Pluralistic: Vice surrenders &lt;p&gt;This is the moment for POSSE (Post Own Site, Share Everywhere), a strategy that sees social media as a strategy for bringing readers to channels that you control&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Curation is the last best hope of intelligent discourse.&lt;/item&gt;
      &lt;item&gt;https://hachyderm.io/@pluralistic@mamot.fr/111987590552793552&lt;/item&gt;
      &lt;item&gt;^ actual permalink: https://mamot.fr/@pluralistic/111987590098901216 &lt;list rend="ul"&gt;&lt;item&gt;"If there was ever a moment when the obvious, catastrophic, imminent risk of trusting Big Tech intermediaries to sit between you and your customers or audience, it was now. This is *not* the moment to be "social first." This is the moment for POSSE (Post Own Site, Share Everywhere), a strategy that sees social media as a strategy for bringing readers to channels that *you* control:https://pluralistic.net/2022/02/19/now-we-are-two/#two-much-posse14/" @pluralistic February 24, 2024&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2024-03-09 Molly White: POSSE &lt;p&gt;I just finally deployed something I've been working on for a few weeks now: a feed of my writing, posting, reading, and other various activity that lives on my website at https://www.mollywhite.net/feed&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Why: to have another way to search your stuff, since sometimes (often? usually now?) large web web search engines like Google or even DDG are very poor at site-specific searching (e.g. site:http://tantek.com), whereas social media silos like Twitter are very good at profile-specific searches (e.g. from:t).&lt;/item&gt;
      &lt;item&gt;IndieWeb Example: 2024-03-09 Molly White deployed automatic POSSE to Twitter/Mastodon/Bluesky: POSSE&lt;/item&gt;
      &lt;item&gt;https://mastodon.social/@flokosiol/112438679946887082 &lt;quote/&gt;with embedded photo of Laura presenting a text slide on a stage:&lt;p&gt;"Starting day 2 of #btconf with Laura Kalbag and some #indieweb vibes." @flokosiol May 14, 2024&lt;/p&gt;&lt;quote/&gt;— a rephrasing of POSSE.&lt;p&gt;Social media etiquette:&lt;/p&gt;&lt;p&gt;Post to your own site first, then mirror those posts to third-party platforms.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;2024-09-27 Molly White: POSSE: Reclaiming social media in a fragmented world&lt;/item&gt;
      &lt;item&gt;don't POSSE to X, says Richard MacManus https://cybercultural.com/p/web-values/&lt;/item&gt;
      &lt;item&gt;Molly White talks POSSE and more at SXSW 2025 2025-03-09&lt;/item&gt;
      &lt;item&gt;https://changelog.com/friends/85#t=6099&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://indieweb.org/POSSE#"/><published>2026-01-02T19:48:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46469577</id><title>Daft Punk Easter Egg in the BPM Tempo of Harder, Better, Faster, Stronger?</title><updated>2026-01-03T17:09:00.712941+00:00</updated><content>&lt;doc fingerprint="e65c813589908cb4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Was Daft Punk Having a Laugh When They Chose the Tempo of Harder, Better, Faster, Stronger?&lt;/head&gt;
    &lt;p&gt;Google "harder better faster stronger bpm" and Google’s “AI Overview” will tell you:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Daft Punk’s “Harder, Better, Faster, Stronger” generally sits around 123 BPM (Beats Per Minute), though some analyses find it slightly higher (like 123.48 BPM) or list different BPMs in remixes/workouts, with exact figures varying slightly by source and version.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spotify’s metadata database, SongBPM, and most other online BPM databases list it at exactly 123.&lt;/p&gt;
    &lt;p&gt;But I think our helmet-clad robot friends might have been making a little joke that we’ve apparently all missed. The BPM of Harder, Better, Faster, Stronger is actually 123.45.&lt;/p&gt;
    &lt;p&gt;How do I know this? It so happens that for over 10 years I’ve written an app called Tempi that shows the BPM of music in real time, so I know a little bit about the science and algorithms behind music tempo detection.&lt;/p&gt;
    &lt;p&gt;Most tempo detection software works basically the same way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A specialized algorithm called the Fast Fourier Transform (FFT) collects overlapping energy levels at different frequency bands.&lt;/item&gt;
      &lt;item&gt;Those levels are refined into well-defined peaks that represent rhythmic events in the track.&lt;/item&gt;
      &lt;item&gt;Another algorithm (autocorrelation) looks for patterns, or more accurately periodicity, in those peaks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But these patterns are tricky because there’s all kinds of noise, performance inaccuracies, and rhythmic harmonics throwing things off. All that is to say, a) it’s complicated and b) it’s not perfectly accurate.&lt;/p&gt;
    &lt;p&gt;When I make changes to my own system of course I need some way to know if it’s getting better or worse, so I have a test library of hundreds of song snippets that I score it against. One of these songs is Daft Punk’s HBFS, and early on I noticed something strange about that track.&lt;/p&gt;
    &lt;p&gt;Almost all electronic music is synced to a sequencer and so obviously is going to have a very steady tempo. But while the vast majority of electronic music tracks I test have an “integral” tempo – meaning their tempo is exactly some round number like 95, and not a fraction like 95.2 – my software always finds the BPM of HBFS to be somewhere between 123 and 124, but not exactly either. For years I’ve chalked this up to inconsistencies with my system and didn’t think much of it. But lately I’ve made improvements to the system so that it’s much more accurate and it now tells me the BPM of HBFS is 123.4.&lt;/p&gt;
    &lt;p&gt;And that got me thinking, “Hmm. Did these guys pick that tempo because they have a sense of humor? And if so, how far would they take it?”&lt;/p&gt;
    &lt;p&gt;To get to the bottom of this I needed to establish what the BPM of HBFS really is.&lt;/p&gt;
    &lt;head rend="h3"&gt;And that’s actually pretty easy to do…&lt;/head&gt;
    &lt;p&gt;Here’s a Venn diagram showing the overlap between human and computer capabilities in the digital realm:&lt;/p&gt;
    &lt;p&gt;Computers can do almost all “computer-y” things (i.e. things that can be entirely done on a computer) MUCH better, faster, (and stronger?) than humans. But for the time being there remain a few things that humans can do very easily which computers find difficult. Along with counting traffic lights and crosswalks, one of those things is finding the exact BPM of a song. Not an estimate like most software does, but the exact value with extreme precision across the entire song. Anyone with a basic sense of rhythm and an audio app can do this.&lt;/p&gt;
    &lt;p&gt;Here’s how:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open the song in an audio app like Logic, Audition, Ableton, Reaper, ProTools, etc.&lt;/item&gt;
      &lt;item&gt;Zoom in on the waveform a little bit so you can see the shape of the beats.&lt;/item&gt;
      &lt;item&gt;Find the first obvious beat – meaning it has a well-defined waveform peak – and the last obvious beat. Let’s call these “bookend” beats.&lt;/item&gt;
      &lt;item&gt;Measure the exact duration in seconds between the bookend beats.&lt;/item&gt;
      &lt;item&gt;Play the song and count all the beats starting at the first bookend beat and ending at the last bookend beat. (If you have an old school calculator, an easy way to do this is type “1+1=” and then just keep tapping “=” to add 1 on each beat.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then to get the exact tempo of the track, averaged throughout the entire thing, use this formula:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * (number_of_beats - 1) / duration&lt;/code&gt;
    &lt;p&gt;Computers have a rough time of this because they don’t really know how to “keep a beat”, and the algorithms that can find the beat do a lot better when they already know the estimated BPM, which is obviously a chicken/egg problem.&lt;/p&gt;
    &lt;p&gt;For the first bookend beat in HBFS I used the first beat after the “whooshing” intro, at around 5.58s. The last bookend beat I used the last “work” at about the 3:41.85 mark. (“Never” and “Over” aren’t good candidates because you can’t see their waveform peaks.)&lt;/p&gt;
    &lt;p&gt;That gives exactly 446 beats or 445 intervals.&lt;/p&gt;
    &lt;p&gt;I tried this with two different copies of HBFS. The Discovery CD rip I have of the song has a duration between the bookend beats of 216.282, so:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * 445 / 216.282 = 123.4499403556&lt;/code&gt;
    &lt;p&gt;The “YouTube official audio” track I tested has a duration of 216.276, so:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * 445 / 216.276 = 123.4533651445&lt;/code&gt;
    &lt;p&gt;The original Discovery CD version has obviously undergone less processing over time than the YouTube version so I tend to think it’s more representative, and it’s very close to 123.45 – only a 0.00005964 difference! But even the more modern YouTube version closely rounds to 123.45.&lt;/p&gt;
    &lt;p&gt;So hopefully I’ve put this fact to rest:&lt;/p&gt;
    &lt;p&gt;The BPM of Harder, Better, Faster, Stronger is 123.45.&lt;/p&gt;
    &lt;head rend="h2"&gt;But…was this intentional, or just a happy accident?&lt;/head&gt;
    &lt;p&gt;The year is 1999 or 2000. Would the gear Daft Punk uses even support fractional BPMs? And if so out to how many decimal places?&lt;/p&gt;
    &lt;p&gt;From their 2001 interview with Remix Magazine (archive.org) we know that Bangalter says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Our sequencing is done either on an E-mu SP-1200, an Akai MPC, or a PC with Logic Audio software. We do not work on things in just one way.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And from later interviews we know the Akai MPC was specifically an MPC-3000. (Oh, and that’s Emagic’s Logic, not Apple’s. Apple didn’t acquire Emagic until 2002.)&lt;/p&gt;
    &lt;p&gt;Did the E-mu support fractional BPMs? Yes, but only to 1 decimal place:&lt;/p&gt;
    &lt;p&gt;The Akai MPC-3000? Yep, also to 1 decimal place:&lt;/p&gt;
    &lt;p&gt;What about Emagic’s Logic?&lt;/p&gt;
    &lt;p&gt;Oooh, look at that. Logic supported BPMs to *4* decimal places.&lt;/p&gt;
    &lt;p&gt;But while we know those three sequencers were used on the Discovery album, I’m not sure anyone else knows which one was specifically used on HBFS. I’ve searched and searched and it seems this detail has just never been revealed.&lt;/p&gt;
    &lt;p&gt;And to confuse matters more, in a 2013 interview with Time Magazine, Bangalter says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;So we’ve never actually made music with computers! [laughs] Neither Homework nor Discovery nor even Human After All were made with computers.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Was he contradicting himself from 12 years before? Or did he forget? Or maybe it’s a terminology thing?&lt;/p&gt;
    &lt;p&gt;That the CD version is so close to exactly 123.45 makes me think this was intentional. And if it was? Well played, robots. You managed to leave a little Easter egg hiding in plain sight for 25 years.&lt;/p&gt;
    &lt;p&gt;Update: A Hacker News reader pointed out that I accidentally reversed the durations of the YouTube clip and the CD rip. Fixed!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.madebywindmill.com/tempi/blog/hbfs-bpm/"/><published>2026-01-02T21:27:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46469623</id><title>Linux kernel security work</title><updated>2026-01-03T17:09:00.131621+00:00</updated><content>&lt;doc fingerprint="1632919690e4360c"&gt;
  &lt;main&gt;
    &lt;p&gt;Lots of the CVE world seems to focus on “security bugs” but I’ve found that it is not all that well known exactly how the Linux kernel security process works. I gave a talk about this back in 2023 and at other conferences since then, attempting to explain how it works, but I also thought it would be good to explain this all in writing as it is required to know this when trying to understand how the Linux kernel CNA issues CVEs.&lt;/p&gt;
    &lt;p&gt;This is a post in the series about the Linux kernel CVE release process:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux kernel versions, how the Linux kernel releases are numbered.&lt;/item&gt;
      &lt;item&gt;Tracking kernel commits across branches, how to keep track of Linux kernel commits as they move from the main release branch into the different stable releases in an automated way.&lt;/item&gt;
      &lt;item&gt;Linux kernel security work (this post), how the Linux kernel security team works to fix reported security bugs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;tl;dr&lt;/head&gt;
    &lt;p&gt;Summary up front for those not wanting to read a wall of text:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Linux kernel security team work to fix reported issues as quickly as possible and get the fixes merged to public trees, and do not do any announcements anywhere.&lt;/item&gt;
      &lt;item&gt;The Linux kernel security team and the CVE team are different groups of people, all of whom do this work on their own recognition, not associated with any company.&lt;/item&gt;
      &lt;item&gt;Only send plain text emails to the kernel security team.&lt;/item&gt;
      &lt;item&gt;Do not email the kernel security team and expect to get a CVE assigned.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Reactive, not proactive, security work&lt;/head&gt;
    &lt;p&gt;The Linux kernel security team is group of Linux kernel developers who are responsible for triaging potential security bugs that are reported to them, and get them fixed as soon as possible. They do this work as “reactive” for security issues, independent of the great “proactive” kernel security work that the Kernel Self-protection project has been doing for the past 10+ years.&lt;/p&gt;
    &lt;head rend="h1"&gt;Kernel security team&lt;/head&gt;
    &lt;p&gt;As can be seen in the in-kernel documentation to contact the security team, just email the address in that document the potential issue that you have found, without using HTML or any binary attachments, and the developers there will take the report and usually ask questions and work to resolve the issue if it turns out to actually be a real security issue. Many issues reported are not, and so the reporter is told to send their bug report to the respective mailing list and work on it with the developers there, in public.&lt;/p&gt;
    &lt;p&gt;When reporting a bug, just send a simple, plain text email to the security alias. Do not send an email that contains a binary attachment as opening unsolicited binary files is not anything anyone should be doing. Also do not use markdown formatting, just plain text. Also, no encryption is needed, as it will not work due to the email alias handling (i.e. one address to many individuals.) If you are forced to use encryption to report security problems, please reconsider this policy as it feels counterproductive (UK government, this means you…)&lt;/p&gt;
    &lt;p&gt;The members of the security team contain a handful of core kernel developers that have experience dealing with security bugs, and represent different major subsystems of the kernel. They do this work as individuals, and specifically can NOT tell their employer, or anyone else, anything that is discussed on the security alias before it is resolved. This arrangement has allowed the kernel security team to remain independent and continue to operate across the different governments that the members operate in, and it looks to become the normal way project security teams work with the advent of the European Union’s new CRA law coming into affect which places requirements on response time of companies that receive notice of potential security issues in their projects.&lt;/p&gt;
    &lt;head rend="h2"&gt;How the fix happens&lt;/head&gt;
    &lt;p&gt;The way the security team works is when a bug is reported, if the members do not have experience in that specific subsystem, they drag the maintainers of that subsystem into the email chain, and work to get the bug resolved. If a subsystem has a continued number of bugs reported over time, the maintainer can be “asked” if they wish to join the alias to help remove the additional “hop” of bug triage happening. This is what has caused the alias members to naturally grow over time to end up representing the major portions of the kernel with the most issues.&lt;/p&gt;
    &lt;p&gt;Ideally the bug reporter also provides a working fix for the issue, allowing them to get the proper credit for the fix but of course that does not always happen. If no fix is provided, the developers involve work to resolve the bug as soon as they can, and when they agree it is resolved, get it merged into the main kernel branch and the stable kernel releases as soon as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;No embargoes&lt;/head&gt;
    &lt;p&gt;As the documentation states, no embargoes longer than 7 days are allowed, once a working fix is made, as there’s no real reason to hold off on getting a fix merged at that time. Only very few changes ever have any embargo at all, as it’s more bother than it is worth.&lt;/p&gt;
    &lt;p&gt;Once the bug is fixed in the kernel trees, the developer’s work is finished, and it is up to the reporter if they wish to “announce” a bugfix or not. The kernel security team on their own do not do any reporting or external communication at all. Only later, if the fix is warranted to justify a CVE being assigned, is the commit announced as a security fix, but that work is done by the kernel CVE team, NOT the kernel security team.&lt;/p&gt;
    &lt;p&gt;More about how the kernel CVE team works in a later post in this series…&lt;/p&gt;
    &lt;head rend="h1"&gt;A bug is a bug is a bug&lt;/head&gt;
    &lt;p&gt;This “do not announce anything” policy has been present in the kernel security team since the very beginning, and as you can imagine, has caused much “disagreement” by those outside of the kernel community. This came up soon after the kernel security team was established in a 2008 email thread with Linus:&lt;/p&gt;
    &lt;code&gt;  On Wed, 16 Jul 2008, pageexec@freemail.hu wrote:
  &amp;gt;
  &amp;gt; you should check out the last few -stable releases then and see how
  &amp;gt; the announcement doesn't ever mention the word 'security' while fixing
  &amp;gt; security bugs

  Umm. What part of "they are just normal bugs" did you have issues with?
  I expressly told you that security bugs should not be marked as such,
  because bugs are bugs.

  &amp;gt; in other words, it's all the more reason to have the commit say it's
  &amp;gt; fixing a security issue.

  No.

  &amp;gt; &amp;gt; I'm just saying that why mark things, when the marking have no meaning?
  &amp;gt; &amp;gt; People who believe in them are just _wrong_.
  &amp;gt;
  &amp;gt; what is wrong in particular?

  You have two cases:

  - people think the marking is somehow trustworthy.

    People are WRONG, and are misled by the partial markings, thinking that
    unmarked bugfixes are "less important". They aren't.

  - People don't think it matters

    People are right, and the marking is pointless.
    In either case it's just stupid to mark them. I don't want to do it,
    because I don't want to perpetuate the myth of "security fixes" as a
    separate thing from "plain regular bug fixes".

    They're all fixes. They're all important. As are new features, for that
    matter.

  &amp;gt; when you know that you're about to commit a patch that fixes a security
  &amp;gt; bug, why is it wrong to say so in the commit?

  It's pointless and wrong because it makes people think that other bugs
  aren't potential security fixes.

  What was unclear about that?

  Linus
&lt;/code&gt;
    &lt;p&gt;The whole email thread is worth reading.&lt;/p&gt;
    &lt;head rend="h2"&gt;No one knows how you use open source&lt;/head&gt;
    &lt;p&gt;The primary reason why the kernel does not do any security announcements is that almost any bugfix at the level of an operating system kernel can be a “security issue” given the issues involved (memory leaks, denial of service, information leaks, etc.) Also, given that Linux is open source, the developers involved in fixing problems do NOT know how Linux is being used. A simple bugfix for a minor thing for one user could be a major system vulnerability fix for a different user, all depending on how Linux is being used. Ben Hawkes said it best in a wonderful essay about “What is a good Linux kernel bug”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;âIt’s hard to capture the fact that a bug can be super serious in one type of deployment, somewhat important in another, or no big deal at all – and that the bug can be all of this at the same time. Vulnerability remediation is hard.â â Ben Hawkes&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Always remember, kernel developers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;do not know your use case.&lt;/item&gt;
      &lt;item&gt;do not know what code you use.&lt;/item&gt;
      &lt;item&gt;do not want to know any of this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, overall, the kernel security bug policy can be boiled down to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fix known bugs as soon as possible.&lt;/item&gt;
      &lt;item&gt;Get releases out to users as quickly as possible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For those that are always worried “what if a bugfix causes problems”, they should remember that a fix for a known bug is better than the potential of a fix causing a future problem as future problems, when found, will be fixed then. You never want to have “known bugfixes” not resolved on your system at any time. So much so that recent laws will soon be preventing you that being allowed for many countries.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware security issues&lt;/head&gt;
    &lt;p&gt;As history has shown us with Spectre and Meltdown, this “no embargo” policy does not always work well when working with problems that cross operating systems and hardware platforms, possibly requiring firmware or microcode updates. Because of this, the kernel developers have been forced to come up with a “Hardware Security policy” to handle these types of issues.&lt;/p&gt;
    &lt;p&gt;This different workflow involves the creation of a special encrypted and restricted email list containing just the needed kernel and hardware developers that are required to get the problem solved. With this process, embargoes are grumpily tolerated for now. Many different hardware bugs have been resolved in Linux over the years through this process, but as a participant in some of these efforts, it is clunky, awkward, and often times extremely slow. The kernel developers involved really do not like this process, and hopefully this will be phased out over time as many hardware issues have been resolved in the past year without having to get this special process involved at all.&lt;/p&gt;
    &lt;p&gt;Also, due to the CRA timelines, long embargo times will probably not even be possible for hardware companies to handle. How that is going to interact with microcode and firmware updates in the next few years is going to be an “interesting” thing to watch evolve.&lt;/p&gt;
    &lt;head rend="h1"&gt;How this all started&lt;/head&gt;
    &lt;p&gt;Way back in 2005, there was not any “official” way to contact anyone about kernel security bugs. It was just an ad-hock group of people that developers “knew” they could email problems to. That obviously did not really scale, and was not helpful for anyone who did not know how the kernel developers worked. This came to a head in 2005 with this email from Steve Bergman:&lt;/p&gt;
    &lt;code&gt;From: Steve Bergman &amp;lt;steve@rueb.com&amp;gt;
To: linux-kernel@vger.kernel.org
Subject: Proper procedure for reporting possible security vulnerabilities?
Date: Mon, 10 Jan 2005 10:46:57 -0600

There seems to be some confusion in certain quarters as to the proper
procedure for reporting possible kernel security issues.

REPORTING-BUGS says send bug reports to the maintainer of that area of
the kernel. However, what about areas for which a maintainer is not
listed? (e.g. VM) It seems that some take that to mean send it
directly to Linus and if you don't hear something back quickly, release
an exploit to the wild.

So what is the preferred procedure and is it documented somewhere?
Should it be made more prominent?

Thanks for any information,
Steve Bergman
&lt;/code&gt;
    &lt;p&gt;That naturally kicked off a bit of discussion, so 36 emails later, the idea of a central email alias that could handle reported security issues was decided on and a few months later, was written up by Chris Wright:&lt;/p&gt;
    &lt;code&gt;From: Chris Wright &amp;lt;chrisw@osdl.org&amp;gt;
To: torvalds@osdl.org
Cc: akpm@osdl.org, alan@lxorguk.ukuu.org.uk,
    marcelo.tosatti@cyclades.com, linux-kernel@vger.kernel.org
Subject: [PATCH] Security contact info
Date: Wed, 9 Mar 2005 01:05:50 -0800

Add security contact info and relevant documentation.

Signed-off-by: Chris Wright &amp;lt;chrisw@osdl.org&amp;gt;

 MAINTAINERS                |    5 +++++
 REPORTING-BUGS             |    4 ++++
 Documentation/SecurityBugs |   38 ++++++++++++++++++++++++++++++++++++++
 3 files changed, 47 insertions(+)
&lt;/code&gt;
    &lt;head rend="h1"&gt;No security announcements&lt;/head&gt;
    &lt;p&gt;As stated earlier, the kernel security team does not do any sort of announcements at all, or any public statements anywhere. They are also not responsible for assigning CVE ids to any kernel bugfixes, that is a different team’s responsibility that happens after kernel bugfixes are in public kernel releases, and almost never before.&lt;/p&gt;
    &lt;p&gt;Because they do not do any announcements, there is also no “early announcement” list, despite many companies constantly asking to “join the security pre-announcement security list” requests we get.&lt;/p&gt;
    &lt;p&gt;The primary reason there is no pre-announcement list is overall they should always be considered public and contain leaks. Otherwise, why would your government allow them to exist? Unless the list is for a project that is not really used by anyone…&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://www.kroah.com/log/blog/2026/01/02/linux-kernel-security-work/"/><published>2026-01-02T21:31:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46471199</id><title>2026 will be my year of the Linux desktop</title><updated>2026-01-03T17:08:59.329462+00:00</updated><content>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xeiaso.net/notes/2026/year-linux-desktop/"/><published>2026-01-03T00:15:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46471712</id><title>A Basic Just-In-Time Compiler (2015)</title><updated>2026-01-03T17:08:59.126116+00:00</updated><content>&lt;doc fingerprint="2e629a9dea369a89"&gt;
  &lt;main&gt;
    &lt;p&gt; nullprogram.com/blog/2015/03/19/ &lt;/p&gt;
    &lt;p&gt; (The author is currently open to employment opportunities in the United States.) &lt;/p&gt;
    &lt;p&gt;This article was discussed on Hacker News and on reddit.&lt;/p&gt;
    &lt;p&gt;Monday’s /r/dailyprogrammer challenge was to write a program to read a recurrence relation definition and, through interpretation, iterate it to some number of terms. It’s given an initial term (&lt;code&gt;u(0)&lt;/code&gt;) and a sequence of operations, &lt;code&gt;f&lt;/code&gt;, to apply to the previous
term (&lt;code&gt;u(n + 1) = f(u(n))&lt;/code&gt;) to compute the next term. Since it’s an
easy challenge, the operations are limited to addition, subtraction,
multiplication, and division, with one operand each.&lt;/p&gt;
    &lt;p&gt;For example, the relation &lt;code&gt;u(n + 1) = (u(n) + 2) * 3 - 5&lt;/code&gt; would be
input as &lt;code&gt;+2 *3 -5&lt;/code&gt;. If &lt;code&gt;u(0) = 0&lt;/code&gt; then,&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;u(1) = 1&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(2) = 4&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(3) = 13&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(4) = 40&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(5) = 121&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;…&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rather than write an interpreter to apply the sequence of operations, for my submission (mirror) I took the opportunity to write a simple x86-64 Just-In-Time (JIT) compiler. So rather than stepping through the operations one by one, my program converts the operations into native machine code and lets the hardware do the work directly. In this article I’ll go through how it works and how I did it.&lt;/p&gt;
    &lt;p&gt;Update: The follow-up challenge uses Reverse Polish notation to allow for more complicated expressions. I wrote another JIT compiler for my submission (mirror).&lt;/p&gt;
    &lt;head rend="h3"&gt;Allocating Executable Memory&lt;/head&gt;
    &lt;p&gt;Modern operating systems have page-granularity protections for different parts of process memory: read, write, and execute. Code can only be executed from memory with the execute bit set on its page, memory can only be changed when its write bit is set, and some pages aren’t allowed to be read. In a running process, the pages holding program code and loaded libraries will have their write bit cleared and execute bit set. Most of the other pages will have their execute bit cleared and their write bit set.&lt;/p&gt;
    &lt;p&gt;The reason for this is twofold. First, it significantly increases the security of the system. If untrusted input was read into executable memory, an attacker could input machine code (shellcode) into the buffer, then exploit a flaw in the program to cause control flow to jump to and execute that code. If the attacker is only able to write code to non-executable memory, this attack becomes a lot harder. The attacker has to rely on code already loaded into executable pages (return-oriented programming).&lt;/p&gt;
    &lt;p&gt;Second, it catches program bugs sooner and reduces their impact, so there’s less chance for a flawed program to accidentally corrupt user data. Accessing memory in an invalid way will causes a segmentation fault, usually leading to program termination. For example, &lt;code&gt;NULL&lt;/code&gt;
points to a special page with read, write, and execute disabled.&lt;/p&gt;
    &lt;head rend="h4"&gt;An Instruction Buffer&lt;/head&gt;
    &lt;p&gt;Memory returned by &lt;code&gt;malloc()&lt;/code&gt; and friends will be writable and
readable, but non-executable. If the JIT compiler allocates memory
through &lt;code&gt;malloc()&lt;/code&gt;, fills it with machine instructions, and jumps to
it without doing any additional work, there will be a segmentation
fault. So some different memory allocation calls will be made instead,
with the details hidden behind an &lt;code&gt;asmbuf&lt;/code&gt; struct.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;#define PAGE_SIZE 4096

struct asmbuf {
    uint8_t code[PAGE_SIZE - sizeof(uint64_t)];
    uint64_t count;
};
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;To keep things simple here, I’m just assuming the page size is 4kB. In a real program, we’d use &lt;code&gt;sysconf(_SC_PAGESIZE)&lt;/code&gt; to discover the page
size at run time. On x86-64, pages may be 4kB, 2MB, or 1GB, but this
program will work correctly as-is regardless.&lt;/p&gt;
    &lt;p&gt;Instead of &lt;code&gt;malloc()&lt;/code&gt;, the compiler allocates memory as an anonymous
memory map (&lt;code&gt;mmap()&lt;/code&gt;). It’s anonymous because it’s not backed by a
file.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;struct asmbuf *
asmbuf_create(void)
{
    int prot = PROT_READ | PROT_WRITE;
    int flags = MAP_ANONYMOUS | MAP_PRIVATE;
    return mmap(NULL, PAGE_SIZE, prot, flags, -1, 0);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Windows doesn’t have POSIX &lt;code&gt;mmap()&lt;/code&gt;, so on that platform we use
&lt;code&gt;VirtualAlloc()&lt;/code&gt; instead. Here’s the equivalent in Win32.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;struct asmbuf *
asmbuf_create(void)
{
    DWORD type = MEM_RESERVE | MEM_COMMIT;
    return VirtualAlloc(NULL, PAGE_SIZE, type, PAGE_READWRITE);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Anyone reading closely should notice that I haven’t actually requested that the memory be executable, which is, like, the whole point of all this! This was intentional. Some operating systems employ a security feature called W^X: “write xor execute.” That is, memory is either writable or executable, but never both at the same time. This makes the shellcode attack I described before even harder. For well-behaved JIT compilers it means memory protections need to be adjusted after code generation and before execution.&lt;/p&gt;
    &lt;p&gt;The POSIX &lt;code&gt;mprotect()&lt;/code&gt; function is used to change memory protections.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_finalize(struct asmbuf *buf)
{
    mprotect(buf, sizeof(*buf), PROT_READ | PROT_EXEC);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Or on Win32 (that last parameter is not allowed to be &lt;code&gt;NULL&lt;/code&gt;),&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_finalize(struct asmbuf *buf)
{
    DWORD old;
    VirtualProtect(buf, sizeof(*buf), PAGE_EXECUTE_READ, &amp;amp;old);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Finally, instead of &lt;code&gt;free()&lt;/code&gt; it gets unmapped.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_free(struct asmbuf *buf)
{
    munmap(buf, PAGE_SIZE);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;And on Win32,&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_free(struct asmbuf *buf)
{
    VirtualFree(buf, 0, MEM_RELEASE);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;I won’t list the definitions here, but there are two “methods” for inserting instructions and immediate values into the buffer. This will be raw machine code, so the caller will be acting a bit like an assembler.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;asmbuf_ins(struct asmbuf *, int size, uint64_t ins);
asmbuf_immediate(struct asmbuf *, int size, const void *value);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;head rend="h3"&gt;Calling Conventions&lt;/head&gt;
    &lt;p&gt;We’re only going to be concerned with three of x86-64’s many registers: &lt;code&gt;rdi&lt;/code&gt;, &lt;code&gt;rax&lt;/code&gt;, and &lt;code&gt;rdx&lt;/code&gt;. These are 64-bit (&lt;code&gt;r&lt;/code&gt;) extensions
of the original 16-bit 8086 registers. The sequence of
operations will be compiled into a function that we’ll be able to call
from C like a normal function. Here’s what it’s prototype will look
like. It takes a signed 64-bit integer and returns a signed 64-bit
integer.&lt;/p&gt;
    &lt;p&gt;The System V AMD64 ABI calling convention says that the first integer/pointer function argument is passed in the &lt;code&gt;rdi&lt;/code&gt; register.
When our JIT compiled program gets control, that’s where its input
will be waiting. According to the ABI, the C program will be expecting
the result to be in &lt;code&gt;rax&lt;/code&gt; when control is returned. If our recurrence
relation is merely the identity function (it has no operations), the
only thing it will do is copy &lt;code&gt;rdi&lt;/code&gt; to &lt;code&gt;rax&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There’s a catch, though. You might think all the mucky platform-dependent stuff was encapsulated in &lt;code&gt;asmbuf&lt;/code&gt;. Not quite. As
usual, Windows is the oddball and has its own unique calling
convention. For our purposes here, the only difference is that the
first argument comes in &lt;code&gt;rcx&lt;/code&gt; rather than &lt;code&gt;rdi&lt;/code&gt;. Fortunately this only
affects the very first instruction and the rest of the assembly
remains the same.&lt;/p&gt;
    &lt;p&gt;The very last thing it will do, assuming the result is in &lt;code&gt;rax&lt;/code&gt;, is
return to the caller.&lt;/p&gt;
    &lt;p&gt;So we know the assembly, but what do we pass to &lt;code&gt;asmbuf_ins()&lt;/code&gt;? This
is where we get our hands dirty.&lt;/p&gt;
    &lt;head rend="h4"&gt;Finding the Code&lt;/head&gt;
    &lt;p&gt;If you want to do this the Right Way, you go download the x86-64 documentation, look up the instructions we’re using, and manually work out the bytes we need and how the operands fit into it. You know, like they used to do out of necessity back in the 60’s.&lt;/p&gt;
    &lt;p&gt;Fortunately there’s a much easier way. We’ll have an actual assembler do it and just copy what it does. Put both of the instructions above in a file &lt;code&gt;peek.s&lt;/code&gt; and hand it to &lt;code&gt;nasm&lt;/code&gt;. It will produce a raw binary
with the machine code, which we’ll disassemble with &lt;code&gt;nidsasm&lt;/code&gt; (the
NASM disassembler).&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ nasm peek.s
$ ndisasm -b64 peek
00000000  4889F8            mov rax,rdi
00000003  C3                ret
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;That’s straightforward. The first instruction is 3 bytes and the return is 1 byte.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;asmbuf_ins(buf, 3, 0x4889f8);  // mov   rax, rdi
// ... generate code ...
asmbuf_ins(buf, 1, 0xc3);      // ret
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;For each operation, we’ll set it up so the operand will already be loaded into &lt;code&gt;rdi&lt;/code&gt; regardless of the operator, similar to how the
argument was passed in the first place. A smarter compiler would embed
the immediate in the operator’s instruction if it’s small (32-bits or
fewer), but I’m keeping it simple. To sneakily capture the “template”
for this instruction I’m going to use &lt;code&gt;0x0123456789abcdef&lt;/code&gt; as the
operand.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;mov   rdi, 0x0123456789abcdef
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Which disassembled with &lt;code&gt;ndisasm&lt;/code&gt; is,&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;00000000  48BFEFCDAB896745  mov rdi,0x123456789abcdef
         -2301
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Notice the operand listed little endian immediately after the instruction. That’s also easy!&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;long operand;
scanf("%ld", &amp;amp;operand);
asmbuf_ins(buf, 2, 0x48bf);         // mov   rdi, operand
asmbuf_immediate(buf, 8, &amp;amp;operand);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Apply the same discovery process individually for each operator you want to support, accumulating the result in &lt;code&gt;rax&lt;/code&gt; for each.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;switch (operator) {
    case '+':
        asmbuf_ins(buf, 3, 0x4801f8);   // add   rax, rdi
        break;
    case '-':
        asmbuf_ins(buf, 3, 0x4829f8);   // sub   rax, rdi
        break;
    case '*':
        asmbuf_ins(buf, 4, 0x480fafc7); // imul  rax, rdi
        break;
    case '/':
        asmbuf_ins(buf, 3, 0x4831d2);   // xor   rdx, rdx
        asmbuf_ins(buf, 3, 0x48f7ff);   // idiv  rdi
        break;
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;As an exercise, try adding support for modulus operator (&lt;code&gt;%&lt;/code&gt;), XOR
(&lt;code&gt;^&lt;/code&gt;), and bit shifts (&lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;). With the addition of these
operators, you could define a decent PRNG as a recurrence relation. It
will also eliminate the closed form solution to this problem so
that we actually have a reason to do all this! Or, alternatively,
switch it all to floating point.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calling the Generated Code&lt;/head&gt;
    &lt;p&gt;Once we’re all done generating code, finalize the buffer to make it executable, cast it to a function pointer, and call it. (I cast it as a &lt;code&gt;void *&lt;/code&gt; just to avoid repeating myself, since that will implicitly
cast to the correct function pointer prototype.)&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;asmbuf_finalize(buf);
long (*recurrence)(long) = (void *)buf-&amp;gt;code;
// ...
x[n + 1] = recurrence(x[n]);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;That’s pretty cool if you ask me! Now this was an extremely simplified situation. There’s no branching, no intermediate values, no function calls, and I didn’t even touch the stack (push, pop). The recurrence relation definition in this challenge is practically an assembly language itself, so after the initial setup it’s a 1:1 translation.&lt;/p&gt;
    &lt;p&gt;I’d like to build a JIT compiler more advanced than this in the future. I just need to find a suitable problem that’s more complicated than this one, warrants having a JIT compiler, but is still simple enough that I could, on some level, justify not using LLVM.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nullprogram.com/blog/2015/03/19/"/><published>2026-01-03T01:18:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46472230</id><title>Adventure 751 (1980)</title><updated>2026-01-03T17:08:58.951896+00:00</updated><content>&lt;doc fingerprint="351c59d775a584fd"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;COME WITH ME TO COLOSSAL CAVE. WHERE MAGIC ABOUNDS AND TREASURES ARE FOUND. BID YOUR FINGERS FOLLOW YOUR COMMANDS AND I WILL BE YOUR EYES AND HANDS. YET BEWARE THE FIERY DRAGON, FOR HE KNOWS NOT WHETHER YOU ARE WIZARD OR SIMPLE CHARLATAN!&lt;/p&gt;
      &lt;p&gt;HOW BEST TO CONQUER COLOSSAL CAVE? WITH DARING AND SKILL … OH CLEVER KNAVE!&lt;/p&gt;
      &lt;p&gt;— Early 80s Adventure poster, from the CompuServe Incorporated Information Service Division&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Adventure 751 has been, by my reckoning, the most sought-after variation of Crowther/Woods Adventure. It was generally available on the online portal CompuServe from nearly the beginning of the service and it disappeared when they shut down their games in the 90s. Arthur O’Dwyer started a web page in 2016 (with semi-regular updates!) dedicated to hunting down a copy.&lt;/p&gt;
    &lt;p&gt;To finish off a wild 2025 in game preservation, Arthur O’Dwyer announced the game has been found (by LanHawk, a regular amongst the comments here) and is playable.&lt;/p&gt;
    &lt;p&gt;In 1958, the Electrical Engineering Department of the University of Arizona in Tucson received a donation of equipment in order to form an Analog Computer Laboratory. Analog computers deal with full electrical signals rather than 0s and 1s (think music on record vs. on computer). These could do particular computations (like differential equations) faster than digital devices of the time.&lt;/p&gt;
    &lt;p&gt;The University of Arizona’s lab was more cobbled-together than the for-sale-new device depicted above, as they made “two small but flexible computers complete with homemade removable patchboards” to start with but quite quickly changed mission to be a hybrid laboratory. By hybrid, I don’t mean just having digital and analog computers side-by-side, but trying to make computers that use both digital and analog components. Their name officially became The University of Arizona Analog/Hybrid Computer Laboratory. Designs included the “ASTRAC I”, a “iterative differential analyzer”, “APE 1”, a “teaching aid in statistics” that followed a similar design, and an “ASTRAC II” which was now “solid state” and “ultra-fast” and was supported by both the Air Force and NASA.&lt;/p&gt;
    &lt;p&gt;(Warning: My next three paragraphs consolidate three different accounts which differ somewhat.)&lt;/p&gt;
    &lt;p&gt;Three of the students in the 1969-1970 school year were Alexander B. Trevor, John Goltz and Jeff Wilkins. The trio were discussing the possibility of starting a time-sharing company. This was a little late to the game; Dartmouth with General Electric had developed the concept in the early 60s (where a large computer could have its time split into many parts allowing for multiple computers connected; including remote connections Dartmouth had thousands) and by the time Trevor, Goltz, and Wilkins came to the idea there were other companies like Tymshare and National CSS involved.&lt;/p&gt;
    &lt;p&gt;Jeff Wilkins’s father-in-law, Harry Gard, Sr., was a co-founder of Golden United Life Insurance; at the time the insurance company was still getting their computing via other companies, but Gard was keen on Golden United having a computer of their own. The original intent was to buy a mini-computer like the PDP-15 but Goltz (who was working with Wilkins and doing the purchase through DEC) got a call that he could have a KA-10 for just “a little more” (one of the PDP-10s, a full mainframe rather than minicomputer). While Goltz was an engineer and not a salesperson, John Goltz managed to persuade the board of Golden United to part with the money for the upgrade. This enabled the computer to more feasibly do time-sharing with many customers.&lt;/p&gt;
    &lt;p&gt;After graduating Wilkins moved to Columbus (followed by Goltz; Trevor was drafted to the Army so didn’t join them until ’71) to be at Golden United’s new spin-off, CompuServe; Wilkins at the age of 27 became President. Their first developed product was LIDIS (Life Insurance Data Information System); there were plenty of life insurance companies in Columbus to sell to.&lt;/p&gt;
    &lt;p&gt;The company had rapid success; by 1973 they moved to a new building, and by 1974 had not one but seven mainframes “and were using them not only to support a thriving time sharing business, but also to heat our office buildings.” CompuServe stayed with corporate clients, although Wilkins was alert to trends in personal computers; he hired his brother-in-law to track computer magazine news, given the fact most of the operations done by time-sharing could be done more easily with PCs.&lt;/p&gt;
    &lt;p&gt;One of those personal computers was the TRS-80, launching in 1977 as part of the “Trinity” with the Commodore PET and Apple II from the same year. The TRS-80 was sold through Radio Shack stores that were already well-established across the nation, but it was still difficult to move product when the concept of a personal computer was only a vague notion to many buyers. A Radio Shack manager in Columbus named Bill Louden bought one of the early models (serial model 10) as Radio Shack refused to give out demo units; his purchase became the only demo available in the Midwest and people wanting to experience a TRS-80 went specifically to Columbus, driving and even flying in.&lt;/p&gt;
    &lt;p&gt;Simultaneous to this, Wilkins was watching the new market for “modems” which connected personal computers to networks via the phone. He also had computers sitting idle by night (as businesses using them were running them during the day); since he already had the resources, it would be a straightforward matter to have a new commercial-facing venture.&lt;/p&gt;
    &lt;p&gt;Wilkins thus laid out in 1978 an idea for a new product based on European Videotex services. Videotex is its own rabbit hole that I’m not going to touch on much here; starting in the mid-70s there were experiments with turning televisions into networked services.&lt;/p&gt;
    &lt;p&gt;The important point here is that the “television as an appliance” thought process was being applied to make “computer as an appliance” and this would help interest computing to the masses. Wilkins launched a new service MicroNET (“to get microcomputer owners’ attention and suggest the power of the computer network”) and tapped the previously mentioned Midwest Computer Club for a “beta-test”.&lt;/p&gt;
    &lt;p&gt;The test service was launched for free; Bill Louden called it “a hacker’s dream” and a good way to sell modems (110 and 300 baud). Quoting Bill:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We had access to many of the DEC-10’s features, storage, and better processing power, but of most significance we had started using two programs: One was a store-and-forward messaging system, called Infoplex, which allowed us to share text message files with one another even if we were not online at the same time. The other was a modified version of a program that allowed a user to send a live one-line text message to the CompuServe system operator. Our version, modified by Russ Ranshaw of CompuServe, allowed us to send one-line live messages to each other if we saw one another online. We called it the SEND program.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It had all the regular offerings later associated with CompuServe, including games. Both Star Trek and Adventure were available (this is before Microsoft Adventure came out, so it was the original mainframe version). Eventually in the early 1979 a price structure was added: $9 startup, prime time use $12 per hour, non-prime time use $5 per hour, 300 baud more expensive as a “premium” service. Q2 revenues in 1979 were $4.2 million; this was almost a rounding error in the scheme of the business as a whole, but of course personal computers were about to hit the time-sharing companies with fatal blows.&lt;/p&gt;
    &lt;p&gt;A competitor, The Source, was launched in 1979 but “from scratch” by the entrepreneur William F. von Meister (that is, not piggybacking off an existing time-sharing business). Their main relevance to the story here is not only did they have games (the usual like Star Trek) they also tapped Dartmouth College to work on new games. (Remember these are being developed for mainframes or minicomputers, so we’re not talking about typical personal computer programmers! Hence work being drawn from colleges with access.)&lt;/p&gt;
    &lt;p&gt;I don’t have an official notice of solicitation — it may even have come via word of mouth — but CompuServe also must have had contact with mainframe/minicomputer sites in order to get their own games. A 1984 games catalog lists House of Banshi, which is simply Dungeon/Zork (“CompuServe’s rendition of the original game of ZORK.”) Dor Sageth from the catalog is another famous “lost game” which started life on an institutional computer (mentioned by Jason Scott back in 2011). Listed on page 2 is both “Original Adventure” (as the service launched with) and “New Adventure”.&lt;/p&gt;
    &lt;p&gt;In 1977, David Long went to the University of Chicago to work as a computer operator. The college had just bought two of the newest computers from DEC, the PDP-20. One was for general use by the college and the other was for specifically the Graduate School of Business; Long “tended to work 50-60 hours a week on GSB stuff”. 1977 was also the year the “standard” Crowther/Woods Adventure was finalized, and David Long was able to get a copy direct from the author:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Don was kind enough to transmit the source program to the present author in mid-1977.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As he notes, given his work schedule, and the time he spent with GSB affairs, “no one cared if I spent another 10-20 hours on Adventure”. He finished “Adventure 501” by November 1978:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are inside a building, a well house for a large spring. Off to one side is a small pantry.&lt;/p&gt;
      &lt;p&gt;There is a shiny brass lamp nearby.&lt;/p&gt;
      &lt;p&gt;There is a leather sack here.&lt;/p&gt;
      &lt;p&gt;Taped to the wall is a faded poster.&lt;/p&gt;
      &lt;p&gt;READ POSTER&lt;/p&gt;
      &lt;p&gt;The poster has a picture of a thin man with a long white beard. He is wearing a high pointed cap embroidered with strange symbols, and he is pointing a finger at you. Below the picture are the words: “I want you!–To report all good ideas for extensions to this game to me without delay. Remember: ask not what ADVENTURE can do to you; ask what you can do for ADVENTURE.”&lt;/p&gt;
      &lt;p&gt;“A public service of the John Dillinger Died for You Society.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A safe is hiding behind the poster. Found treasures get dropped in the safe rather than on the ground.&lt;/p&gt;
    &lt;p&gt;I’ve played Adventure 501 before; a version had been available for some time (with the mysterious addition of a spider, which isn’t Long’s). The archive LanHawk extracted also includes the authentic ’78 version of Adventure 501, so I was able to cross-check with what I already played.&lt;/p&gt;
    &lt;p&gt;Further expansions eventually led to a “version 6” in January of 1980, including a new area as well as an “improved syntax parser”. (More on the parser later.) An in game “billboard” gives version updates:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;( 19-Jan-1980 ) Congratulations to Robert Silverman, the first adventurer to set foot in the Courtyard of Aldor’s Castle.&lt;/p&gt;
      &lt;p&gt;( 25-Feb-1980 ) Adventurers may now enter the Castle Keep, although construction continues within. Some scoring bugs have been fixed.&lt;/p&gt;
      &lt;p&gt;Who will be first to discover the secret of the black bird?&lt;/p&gt;
      &lt;p&gt;( 3-Mar-1980 ) There is a slight bug on the perfume. For full score, you must drop it somewhere, look, and take it again.&lt;/p&gt;
      &lt;p&gt;( 7-Mar-1980 ) 6.04 is released. Expansion of the castle continues — it is far from complete. Several unique new features and puzzles have recently been designed and are now being implemented.&lt;/p&gt;
      &lt;p&gt;The format of most hints has been altered. I hope you agree that the new hints are more in keeping with the flavor of the game.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The game I’m referring to as “Adventure 751” seems to have been entirely wrapped up by the end of the school year. Sometime before the end of the calendar year Long sold the game to CompuServe for “a thousand dollars”. (As they used the PDP-10/20 like Long did, no conversion work was needed and they could run the executable without compilation.) Long seems to have been somewhat protective of his source code so distribution past that point was relatively minimal, although he did give source copies of both 501 and 751 to the Illinois Institute of Technology. (See, comparatively: Woods and his regret freely sending out Adventure 350 to anyone who asked, making it so that when he wrote “v2.0” he was much more careful who had access.)&lt;/p&gt;
    &lt;p&gt;The parser is “improved” over both Adventure 350 and Adventure 501. There is some sense of trying to “outdo Zork”. (See relatedly: Warp bragging about its own system, and Synapse Software calling their system BTZ or “Better Than Zork”.) Quoting Long:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…Dungeon (Zork) and Adventure-6 were developed almost completely independently. The advanced parser, the object containment facility, and virtually all the game puzzles were designed and implemented prior to our receiving any version of Dungeon. With all due modesty (none), I will point out that Adventure’s containment facility is at least as powerful as Dungeon’s, if not more so, since Adventure’s facility permits searching for contained objects in open containers down to any desired level of containment. Further, the parser permits a few constructs not currently permitted in Dungeon (at least in the version we have at U.C.), such as permitting any number of objects (up to some limits imposed by compiled array sizes) to be specified following transitive verbs. In addition, Adventure’s parser can handle multiple verb constructs such as “GET AND THROW AXE” properly. Finally, Adventure’s parser is slightly better about doing the right things with the various applications of the group words “ALL” and “TREASURES”. A planned enhancement for Release 7 will permit such constructs as “PUSH ALL OF THE BUTTONS” or “TAKE BOTH SACKS”, etc.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;GET AND THROW AXE is uncommon even in modern parsers. Trying to GET AND THROW BREAD in Savoir-Faire (2002) gets the response “You can’t see any such thing.”&lt;/p&gt;
    &lt;p&gt;Dennis Donovan (of CompuServe) made a map in November of 1980 which Arthur O’Dwyer scanned in high resolution with some image cleanup by James Lindell Dean, so I’m going to use it to illustrate the journey.&lt;/p&gt;
    &lt;p&gt;Arthur tested the build with a walkthrough that has been around for a while to confirm this is indeed the “real” Adventure 751; I’m going to play it normally. I am re-mapping the 501 content although I am allowing myself to look at my old posts if I need to; you can also squint at a blurry version of my 501 map where the blue rooms are extensions to Adventure 350.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are standing at the end of a road before a small brick building. Around you is a forest. A small stream flows out of the building and down a gully.&lt;/p&gt;
      &lt;p&gt;GO EAST&lt;/p&gt;
      &lt;p&gt;You’re in a flat circular clearing surrounded by dense forest. Not far away is a helicopter. Its engine is idling slowly. Several jac-booted Orcs are standing guard around the aircraft.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Going east normally enters the building. Unexpected! Trying to enter gets a message about needing a flight pass.&lt;/p&gt;
    &lt;p&gt;The building is still there, but you need to use the command IN to enter, and then can go IN again to get in farther.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are inside a building, a well house for a large spring. Off to one side is a small storeroom.&lt;/p&gt;&lt;lb/&gt;There is a shiny brass lamp nearby.&lt;lb/&gt;There is a leather sack here.&lt;p&gt;Taped to the wall is a faded poster.&lt;/p&gt;&lt;lb/&gt;There is a small matchbox here.&lt;p&gt;IN&lt;/p&gt;&lt;p&gt;You’re in the caretaker’s storeroom.&lt;/p&gt;&lt;lb/&gt;A yellow pill-shaped tablet, as large as a doughnut, lies nearby.&lt;lb/&gt;There are some keys on the ground here.&lt;lb/&gt;There is food here.&lt;lb/&gt;There is a bottle of water here.&lt;/quote&gt;
    &lt;p&gt;Helpfully, the leather sack works as a container; keep in mind this is not a two-word parser so to operate it you need to use PUT X IN SACK. In fact, it works with multiple items at once. That is…&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;PUT TABLET AND KEYS AND FOOD AND BOTTLE IN SACK&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;…will take care of scooping up all four.&lt;/p&gt;
    &lt;p&gt;Other than the helicopter pad being different, and a slightly different building layout, there’s a new object at the grate that goes into the cave:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are in a 20-foot depression floored with bare dirt. Set into the dirt is a strong steel grate mounted in concrete. A dry streambed leads into the depression.&lt;/p&gt;&lt;lb/&gt;There is a large cloth bag lying nearby.&lt;lb/&gt;The grate is locked.&lt;/quote&gt;
    &lt;p&gt;The cloth bag is full of grey powder and if you EMPTY BAG it will scatter all over the place and you won’t be able to pick it up again: “Grey powder has been strewn all about.” I assume this is a softlock, simply from checking what’s inside the bag. (Crowther/Woods really was polite when it came to softlocks. It had the vase breaking when you dropped it, ruining a treasure, but the structure of the game was such that getting all the treasures was an aspirational goal rather than a requirement for having a satisfying playthrough. The various extensions, including the one from Woods himself, often were not so careful. You could eat the food early in Crowther/Woods rather than give it to the appropriate creature, but there’s a built in expectation that EAT FOOD is going to remove it from the object list; just checking what’s inside a container doesn’t suggest such a drastic change.)&lt;/p&gt;
    &lt;p&gt;I’m not going to go underground at all during this session but rather stay outside. The forest, rather than being a method to steer the player back to the caves, includes a “billboard” (as seen earlier, also in the image above) and a castle in the distance.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are in open forest, with a deep valley to one side. Not far off is a large billboard.&lt;/p&gt;
      &lt;p&gt;GO NORTH&lt;/p&gt;
      &lt;p&gt;You are standing behind a large billboard on a ridge above a deep valley. To the north, the forest gives way to dense swamp and then to open flatlands. Far beyond, the land rises sharply towards the impassible Misty Mountains. Nestled at the base of a distant cliff are the stone turrets of a tall white castle.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The outdoors keeps going. At least some of this area I recognize from 501, although it goes a little farther than that game did.&lt;/p&gt;
    &lt;p&gt;Going west of the building leads to a “dense forest” with some mushrooms…&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are in dense forest, with a hill to one side. The trees appear to thin out towards the north and east.&lt;/p&gt;&lt;lb/&gt;There are some oddly-colored mushrooms here.&lt;p&gt;GO WEST&lt;/p&gt;&lt;p&gt;You are at the high point of a wide grassy knoll, partially surrounded by dense forest. The land rises to the south and east, and drops off sharply to the north and west. The air smells of sea water.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;…and a sandy beach. The beach includes a “large wooden box” (the box is empty) where you can go up to find an Ocean Vista with some flowers, the first treasure I’ve found.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You’re on sandy beach.&lt;/p&gt;&lt;lb/&gt;A large wooden box has washed up on the shore.&lt;p&gt;GO NORTH&lt;/p&gt;&lt;p&gt;You are at a jumble of large broken rocks and blackened shoals.&lt;/p&gt;&lt;lb/&gt;A gentle path leads up to the top of the nearby cliffs. A narrow treacherous path disappears among the rocks at the foot of the cliff.&lt;p&gt;GO UP&lt;/p&gt;&lt;p&gt;You are on a high cliff overlooking the sea. Far below the rolling breakers smash into a jumble of blackened shoals. The thunder of the surf is deafening.&lt;/p&gt;&lt;lb/&gt;There are some beautiful flowers here!&lt;/quote&gt;
    &lt;p&gt;The “blackened shoals” are incidentally a University of Chicago in-joke created by a friend of Long’s (Eric Weber); it refers to the professors Black and Scholes who made a famous mathematical model for financial markets. There’s an entire hour-long documentary called Trillion Dollar Bet about it (“this solved the ancient problem of risk and return in the stock market”); it is blamed for more than one market crash, including Black Monday from 1987.&lt;/p&gt;
    &lt;p&gt;This is also the location I remembered something very cruel from Adventure 501 that carries over here. Original Crowther/Woods had a limited number of “random” exits that could sometimes go somewhere else (north goes to a different forest than the normal exit, for instance); other authors basing their games off Adventure sometimes ran with this (even affecting home games, like in Phantom’s Revenge). Going north from the shoals will sometimes go to the cliff already seen, and sometimes it will go to a new room altogether. Back when I played 501 I only found the new room by referring to the CompuServe map!&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You’re at blackened shoals.&lt;/p&gt;&lt;p&gt;GO NORTH&lt;/p&gt;&lt;p&gt;You are at Thunder Hole, a funnel shaped cavern opening onto the sea. The noise of the surf pounding against the outer rocks of the cave is amplified by the peculiar shape of the cave, causing a thunder-like booming sound to reverberate throughout the cave. Outside, a narrow path leads south towards some large rocks.&lt;/p&gt;&lt;p&gt;GO EAST&lt;/p&gt;&lt;p&gt;You are in a dimly lit passage behind Thunder Hole. Etched into the rock wall are the ominous words:&lt;/p&gt;&lt;p&gt;You are approaching the River Styx.&lt;/p&gt;&lt;lb/&gt;Lasciate Ogni Speranza Voi Ch’Entrate.&lt;p&gt;A hideous black dog bares his teeth and growls at your approach.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;I do not remember the method for getting by the dog. I assume I need to go underground first. (I’m pretty sure all of this is 501 territory, though.)&lt;/p&gt;
    &lt;p&gt;If instead of heading west to the beach you head north from the mushrooms/grassy knoll, you arrive at some “salt flats”.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You’re on grassy knoll.&lt;/p&gt;&lt;p&gt;A tiny little man dressed all in green runs straight at you, shouts “Phuce!”, aims a kick squarely at your kneecap, misses, and disappears into the forest.&lt;/p&gt;&lt;p&gt;GO NORTH&lt;/p&gt;&lt;p&gt;You are at the edge of a trackless salt marsh. Tall reeds obscure the view. In the mud is the partial word “-RO–O”. The missing letters have been washed away by the tide.&lt;/p&gt;&lt;lb/&gt;A wooden pole has been stuck in the mud here.&lt;/quote&gt;
    &lt;p&gt;I’m not sure what the tiny man is about, yet. Saying phuce gets the response “nothing happens.”&lt;/p&gt;
    &lt;p&gt;The salt flats are a maze that lead up to a swamp which is just a continuation of the maze.&lt;/p&gt;
    &lt;p&gt;Notice there’s a.) two “dead end” rooms which aren’t really dead ends and b.) one “death exit” from one of the swamp rooms which just kills you for going a particular direction (“You’ve wandered into a quicksand pit and drowned.”). Neither of these are polite and neither of these are used in Crowther/Woods (you could die walking in the dark by falling in a pit, but this was well-telegraphed by the game).&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are at the edge of an open area of wet sand. The dense foliage appears to grow thinner towards the northeast. A small sign stuck in the muck reads: “Site of Proposed Municipal Parking Lot — D.M. Witt, Contractor.”&lt;/p&gt;&lt;lb/&gt;Foul smelling gasses bubble up through the wet sand.&lt;/quote&gt;
    &lt;p&gt;This room has multiple death-exits, which is obnoxious given the restore-a-save procedure (where you need to decline resurrection, leave the game, restart the game, decline instructions, RESUME to load as save, confirm you are loading a save game, and then finally type what you named the save). I think this is all a dead end although I haven’t checked every exit as of yet (see: obnoxious restore-a-save procedure).&lt;/p&gt;
    &lt;p&gt;I believe from here I’ll need to plunge underground, so this seems like a good place to pause for now since I know that’s going to open things wide up. Happy 2026!&lt;/p&gt;
    &lt;p&gt;(If you still haven’t read it, be sure to check out Arthur O’Dwyer’s post; he is planning a follow-up which hacks a bit more at the data. Also thanks to Ethan Johnson for some source assistance.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bluerenga.blog/2026/01/01/adventure-751-1980/"/><published>2026-01-03T02:38:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46472667</id><title>IQuest-Coder: A new open-source code model beats Claude Sonnet 4.5 and GPT 5.1 [pdf]</title><updated>2026-01-03T17:08:58.866903+00:00</updated><content/><link href="https://github.com/IQuestLab/IQuest-Coder-V1/blob/main/papers/IQuest_Coder_Technical_Report.pdf"/><published>2026-01-03T04:01:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46472772</id><title>Show HN: uvx ptn, scan a QR, get a terminal in your phone</title><updated>2026-01-03T17:08:58.286136+00:00</updated><content>&lt;doc fingerprint="fe94ac5fdbc6b2d5"&gt;
  &lt;main&gt;
    &lt;p&gt; 1. &lt;code&gt;uvx ptn&lt;/code&gt;&lt;lb/&gt; 2. Scan the QR&lt;lb/&gt; 3. Access your terminal from your phone&lt;/p&gt;
    &lt;p&gt;I wanted to vibe code from bed.&lt;/p&gt;
    &lt;p&gt;ngrok requires registration and the free tier sucks. Cloudflare Quick Tunnel works great but is hard to use directly on the phone. Termius requires complicated setup: port forwarding, firewall rules, key management... Tried Claude Code web, but it can't access my local hardware and environment. Also tried Happy, but it's too bulky and updates lag behind.&lt;/p&gt;
    &lt;p&gt;So I built something simpler: run a command, scan a QR, start typing.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One command, instant access - No SSH, no port forwarding, no config files. Cloudflare tunnel + QR code.&lt;/item&gt;
      &lt;item&gt;Actually usable on mobile - Essential buttons and gestures for everyday terminal use.&lt;/item&gt;
      &lt;item&gt;Multi-tab shared sessions - Run builds in one tab, tail logs in another. Sessions and tabs persist across reconnects.&lt;/item&gt;
      &lt;item&gt;Cross-platform - Windows (PowerShell, CMD, WSL), Linux/macOS (Bash, Zsh, Fish). Auto-detects your shells.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Install&lt;/cell&gt;
        &lt;cell role="head"&gt;Update&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;uvx (no install)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;uvx ptn&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;uvx --refresh ptn&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;uv tool&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;uv tool install ptn&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;uv tool upgrade ptn&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;pipx&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;pipx install ptn&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;pipx upgrade ptn&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;pip&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;pip install ptn&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;pip install -U ptn&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;One-line install (uv + ptn):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;OS&lt;/cell&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;powershell -ExecutionPolicy ByPass -c "irm https://raw.githubusercontent.com/lyehe/porterminal/master/install.ps1 | iex"&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;macOS/Linux&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;curl -LsSf https://raw.githubusercontent.com/lyehe/porterminal/master/install.sh | sh&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Requires Python 3.12+ and cloudflared (auto-installed if missing).&lt;/p&gt;
    &lt;code&gt;ptn                    # Start in current directory
ptn ~/projects/myapp   # Start in specific folder
ptn --no-tunnel        # Local network only
ptn -b                 # Run in background
ptn -p                 # Enable password protection
ptn -dp                # Toggle default password requirement in config
ptn -v                 # Verbose startup logs
ptn --init             # Create .ptn/ptn.yaml config
ptn -V                 # Show version
ptn -U                 # Update to latest version
ptn --check-update     # Check if update available&lt;/code&gt;
    &lt;p&gt;Run &lt;code&gt;ptn --init&lt;/code&gt; to create a starter config, or create &lt;code&gt;ptn.yaml&lt;/code&gt; manually:&lt;/p&gt;
    &lt;code&gt;# Custom buttons (appear in toolbar)
buttons:
  - label: "claude"
    send:
      - "claude"
      - 100        # delay in ms
      - "\r"
  - label: "tmux"
    send: "tmux\r"

# Update checker settings
update:
  notify_on_startup: true   # Show update notification
  check_interval: 86400     # Seconds between checks (default: 24h)

# Security settings
security:
  require_password: true    # Always prompt for password at startup
  max_auth_attempts: 5      # Max failed attempts before disconnect&lt;/code&gt;
    &lt;p&gt;Config is searched in order: &lt;code&gt;$PORTERMINAL_CONFIG_PATH&lt;/code&gt;, &lt;code&gt;./ptn.yaml&lt;/code&gt;, &lt;code&gt;./.ptn/ptn.yaml&lt;/code&gt;, &lt;code&gt;~/.ptn/ptn.yaml&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Use password if your screen can be exposed to others:&lt;/p&gt;
    &lt;code&gt;ptn -p                 # Prompt for password this session
ptn -dp                # Enable password by default (toggle)&lt;/code&gt;
    &lt;p&gt;Password is per-session (never saved to disk). See docs/security.md for details.&lt;/p&gt;
    &lt;p&gt;Connection fails? Cloudflare tunnel sometimes blocks connections. Restart the server (&lt;code&gt;Ctrl+C&lt;/code&gt;, then &lt;code&gt;ptn&lt;/code&gt;) to get a fresh tunnel URL.&lt;/p&gt;
    &lt;p&gt;Issues and PRs welcome.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/lyehe/porterminal
cd porterminal
uv sync
uv run ptn&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/lyehe/porterminal"/><published>2026-01-03T04:22:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46473348</id><title>Trump says Venezuela’s Maduro captured after strikes</title><updated>2026-01-03T17:08:58.024330+00:00</updated><content>&lt;doc fingerprint="bfe9d1711e13e8af"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON, Jan 3 (Reuters) - The U.S. attacked Venezuela and deposed its long-serving President Nicolas Maduro in an overnight operation Saturday, President Donald Trump said, in Washington's most direct intervention in Latin America since the 1989 invasion of Panama.&lt;/p&gt;
    &lt;p&gt;"The United States of America has successfully carried out a large scale strike against Venezuela and its leader, President Nicolas Maduro, who has been, along with his wife, captured and flown out of the country," Trump said in a Truth Social post.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;Attacks by U.S. forces knocked out electricity in part of Caracas and captured Maduro in or near one of his safe houses, rushing in so quickly he was not able to secure its steel doors, Trump told Fox News in a telephone interview. Maduro and his wife, Trump said, were transported to the USS Iwo Jima, an amphibious assault ship in the Caribbean, ahead of their transfer to the United States, where they both face charges.&lt;/p&gt;
    &lt;p&gt;The removal of Maduro, who led Venezuela with a heavy hand for more than 12 years, potentially opens a power vacuum in the Latin American country. Venezuelan Vice President Delcy Rodriguez — Maduro’s presumptive successor — is in Russia, four sources familiar with her movements said, stoking confusion about who is next in line to govern the South American country.&lt;/p&gt;
    &lt;p&gt;Russia's foreign ministry said the report that Rodriguez is in Russia was "fake."&lt;/p&gt;
    &lt;p&gt;Venezuela's ruling "Chavismo" movement, named for Maduro's predecessor Hugo Chavez, said civilians and military personnel died in Saturday's strikes but did not give figures. Trump told Fox that "a couple of guys were hit" but that no U.S. personnel died.&lt;/p&gt;
    &lt;p&gt;Asked what was next for Venezuelans, Trump was noncommittal while saying the United States would be "very much" involved in Venezuela's future.&lt;/p&gt;
    &lt;p&gt;“We're making that decision now,” Trump said, adding that "we can't take a chance" at letting someone else take over where Maduro left off. The United States would be "very strongly involved" in Venezuela's oil industry, Trump said.&lt;/p&gt;
    &lt;p&gt;While the president was ebullient in his Fox interview, any serious destabilization in the nation of 28 million people threatens to hand Trump the type of quagmire that has marked U.S. foreign policy for much of the 21st century, including the invasions of Afghanistan and Iraq that overthrew their governments.&lt;/p&gt;
    &lt;p&gt;Critics called Saturday's operation an illegal act, while Trump administration officials stuck to their messaging in recent weeks that the U.S. military's actions related to Venezuela are needed to fight drug trafficking.&lt;/p&gt;
    &lt;p&gt;The U.S. has not made such a direct intervention in its backyard region since the invasion of Panama 37 years ago to depose military leader Manuel Noriega over allegations that he led a drug-running operation. The United States has leveled similar charges against Maduro, accusing him of running a "narco-state" and rigging the 2024 election.&lt;/p&gt;
    &lt;p&gt;Maduro, a 63-year-old former bus driver handpicked by the dying Hugo Chavez to succeed him in 2013, has denied those claims and said Washington was intent on taking control of his nation's oil reserves, the largest in the world.&lt;/p&gt;
    &lt;p&gt;MADURO MAY FACE CRIMINAL CHARGES IN U.S.&lt;/p&gt;
    &lt;p&gt;Trump said the operation was carried out "in conjunction with U.S. Law Enforcement," promising more details at an 11 a.m. (1600 GMT) press conference at his Mar-a-Lago resort in Florida.&lt;/p&gt;
    &lt;p&gt;Maduro was captured by a team that included U.S. special forces, including the U.S. Army’s Delta Force, a U.S. official told Reuters.&lt;/p&gt;
    &lt;p&gt;A CIA source in Maduro's inner circle helped U.S. forces track his movements in his final days right up until his capture, according to two people familiar with the matter. The people, who were briefed on the operation, also said members of the Venezuelan military cooperated with the United States to secure Maduro's arrest but declined to provide details.&lt;/p&gt;
    &lt;p&gt;One person close to Venezuela's opposition, who asked not to be named, described Maduro's removal as an "inside job" aided by the country's military.&lt;/p&gt;
    &lt;p&gt;Republican U.S. Senator Mike Lee said U.S. Secretary of State Marco Rubio had told him Maduro would stand trial on criminal charges in the United States and that no further action was anticipated inside Venezuela.&lt;/p&gt;
    &lt;p&gt;Maduro was indicted in U.S. federal court in 2020 on narco-terrorism and other charges for running what prosecutors called a scheme to send tons of cocaine to the U.S. through an alleged "Cartel de Los Soles". He has always denied that.&lt;/p&gt;
    &lt;p&gt;"They will soon face the full wrath of American justice on American soil in American courts," Attorney General Pam Bondi said on X about Maduro and his wife.&lt;/p&gt;
    &lt;p&gt;In the Panama case, Noriega spent more than 20 years in prison.&lt;/p&gt;
    &lt;p&gt;Opposition leader and Nobel Peace Prize winner Maria Corina Machado welcomed Maduro's removal, saying on X that her colleague Edmundo Gonzalez - who the opposition, the U.S. and international observers say won a 2024 election - should assume the presidency.&lt;/p&gt;
    &lt;p&gt;"We will restore order, free political prisoners, build an exceptional country and bring our children back home," she said.&lt;/p&gt;
    &lt;head rend="h2"&gt;VENEZUELAN OFFICIALS DECRY U.S. ACTION&lt;/head&gt;
    &lt;p&gt;Venezuelan Defense Minister Vladimir Padrino condemned Saturday's intervention. "In the unity of the people we will find the strength to resist and to triumph," he said in a video message.&lt;/p&gt;
    &lt;p&gt;Another senior Venezuelan official, Interior Minister Diosdado Cabello, appeared on a street wearing a helmet and flak jacket, urging people not to cooperate with the "terrorist enemy."&lt;/p&gt;
    &lt;p&gt;While various Latin American governments oppose Maduro and say he stole the 2024 vote, direct U.S. action revives painful memories of past interventions and is generally strongly opposed by governments and populations in the region.&lt;/p&gt;
    &lt;p&gt;Trump's action recalls the Monroe Doctrine, laid out in 1823 by President James Monroe, laying U.S. claim to influence in the region, as well as the "gunboat diplomacy" seen under Theodore Roosevelt in the early 1900s.&lt;/p&gt;
    &lt;p&gt;Venezuelan allies Russia, Cuba and Iran were quick to condemn the strikes as a violation of sovereignty. Tehran urged the U.N. Security Council to stop the "unlawful aggression."&lt;/p&gt;
    &lt;p&gt;Among major Latin American nations, Argentina's President Javier Milei lauded Venezuela's new "freedom" while Mexico condemned the intervention and Brazil's President Luiz Inacio Lula da Silva said it crossed "an unacceptable line."&lt;/p&gt;
    &lt;p&gt;"A new dawn for Venezuela! The tyrant is gone," U.S. Deputy Secretary of State Christopher Landau wrote on X.&lt;/p&gt;
    &lt;p&gt;The streets of Venezuela appeared calm as the sun rose. Soldiers patrolled some parts and some small pro-Maduro crowds began gathering in Caracas.&lt;/p&gt;
    &lt;p&gt;Others, however, expressed relief.&lt;/p&gt;
    &lt;p&gt;"I'm happy, I doubted for a moment that it was happening because it's like a movie," said merchant Carolina Pimentel, 37, in the city of Maracay. "It's all calm now but I feel like at any moment everyone will be out celebrating."&lt;/p&gt;
    &lt;p&gt;It was unclear under what legal authority the latest U.S. strikes were carried out.&lt;/p&gt;
    &lt;p&gt;Trump’s move risks a backlash from the U.S. Congress, which has the constitutional right to declare war, and from his own political base, which favors an “America first” policy and largely opposes military intervention abroad.&lt;/p&gt;
    &lt;p&gt;In the runup to Saturday's operation, Trump had sought a "blockade" of Venezuelan oil, expanded sanctions against the Maduro government and staged more than two dozen strikes on vessels the U.S. alleges were involved in trafficking drugs, killing more than 110 people.&lt;/p&gt;
    &lt;p&gt;Venezuelan state-run energy company PDVSA's oil production and refining were normal and its most important facilities had suffered no damage according to an initial assessment, two sources with knowledge of the company's operations said.&lt;/p&gt;
    &lt;p&gt;MST Marquee analyst Saul Kavonic said oil prices were likely to jump on the near-term risk to supply but that the U.S. strike could be bearish in the medium term if a new Venezuelan government results in sanctions being lifted and renewed foreign investment.&lt;/p&gt;
    &lt;p&gt;Reporting by Reuters bureaux worldwide; Writing by Andrew Cawthorne and Raphael Satter; Editing by William Mallard, William Maclean, Sergio Non, Rod Nickel&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/world/americas/loud-noises-heard-venezuela-capital-southern-area-without-electricity-2026-01-03/"/><published>2026-01-03T06:35:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46473352</id><title>Ask HN: Expository/Succinct Books on Modern Physics</title><updated>2026-01-03T17:08:57.918770+00:00</updated><content>&lt;doc fingerprint="27a910d72592abea"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;What are some good books which give an overview of all of Modern Physics (or even better, all of Physics)? Mathematical rigour is fine as long as they are clear and starting from undergrad level. Books for each of the quadrants mentioned here - &lt;/p&gt;https://en.wikipedia.org/wiki/Modern_physics&lt;p&gt;I have my eye on John Dirk Walecka's (https://en.wikipedia.org/wiki/John_Dirk_Walecka) books which seem pretty good particularly the ones published by World Scientific Publishing. Three vols on Introduction, Advanced, Topics on Modern Physics and Introduction vols on Classical Mechanics, Quantum Mechanics, Statistical Mechanics, Electricity &amp;amp; Magnetism, General Relativity. - https://www.worldscientific.com/author/Walecka%2C+John+Dirk?...&lt;/p&gt;&lt;p&gt;Dover has Robert Sproull's Modern Physics which seems a bit old. - https://store.doverpublications.com/products/9780486783260&lt;/p&gt;&lt;p&gt;Springer has S.H.Patil's Elements of Modern Physics which seems up to date. - https://link.springer.com/book/10.1007/978-3-030-70143-7&lt;/p&gt;&lt;p&gt;Does anybody have experience with these books both studying and teaching from? I would appreciate it if the knowledgeable folks here can shed some light on this.&lt;/p&gt;&lt;p&gt;What other books provide similar overview of the domain?&lt;/p&gt;&lt;p&gt;Also suggestions on books which provide the needed background Mathematics.&lt;/p&gt;&lt;p&gt;PS: I am finding the the old Soviet era book Fundamentals of Physics by Ivanov quite useful to get an overview - https://mirtitles.org/2018/04/21/fundamentals-of-physics-iva...&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46473352"/><published>2026-01-03T06:35:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46475296</id><title>Profiling with Ctrl-C (2024)</title><updated>2026-01-03T17:08:57.818077+00:00</updated><content>&lt;doc fingerprint="2a50811364244ad9"&gt;
  &lt;main&gt;
    &lt;p&gt;I once wrote about how profiler output can be misleading. Someone commented that you donât need profilers - just Ctrl-C your program in a debugger instead, and youâll see the call stack where your program probably spends most of its time. I admit that I sneered at the idea at the time, because, despite those commentsâ almost aggressive enthusiasm, this method doesnât actually work on the hard problems. But as my outlook on life worsened with age, I came to think that Ctrl-C profiling deserves a shout-out, because itâs very effective against stupid problems encountered by lazy people operating in unfriendly environments.&lt;/p&gt;
    &lt;p&gt;I mean, Iâve tended to dismiss the stupid problems and focus on the hard ones, but is this a good approach in the real world? Today Iâm quite ready to accept that most of life is stupid problems encountered by lazy people operating in unfriendly environments. Certainly, one learning experience was becoming such a person myself, by stepping into a senior management role1 and then going back to programming after a few years. Now Iâm lazy because I got used to not doing anything myself, and Iâm in an environment which is unfriendly to me, because I forgot how things work, or they no longer work the way they used to. And while Iâm a bit ashamed to admit this as someone whoâs developed several profilers himself, Iâm often not really in the mood to figure out how to use a profiler in a given setting.&lt;/p&gt;
    &lt;p&gt;But, hereâs a program taking a minute to start up. Well, only in the debug build; this must be why nobody fixed it, but we really should, it sucks to wait for a full minute every time you rebuild &amp;amp; rerun. So I Ctrl-C the thing, and what do you know, thereâs one billion stack frames from the nlohmann JSON parser, I guess it all gets inlined in the release build; must be what they call âzero-cost abstractionâ2. Another Ctrl-C, another call stack, coming from a different place but again ending up parsing JSON. And I donât know what the fix was - a different JSON parser, or compiling some code with optimizations even in the debug build - but someone fixed it after my Ctrl-C-based report.&lt;/p&gt;
    &lt;p&gt;Or letâs say Iâm trying to switch to the LLD linker from gold, to speed up the linking. Why not the even faster mold? - because Iâm on MIPS, and mold doesnât support MIPS. But LLD is pretty fast, too; the core was written by the same person, after all. And then I open a core dump from a binary linked with LLD, and gdb is really slow. Hmm. It should have been faster, actually, because Iâve also added &lt;code&gt;--gdb-index&lt;/code&gt;, which tells the linker to create, I guess, some index for gdb, making gdb faster than its
slow default behavior, which is reserved for the unfortunate people who donât know the cool flags. But Iâm not seeing faster,
Iâm seeing slower. What gives?&lt;/p&gt;
    &lt;p&gt;So, I run gdb under gdb, and Ctrl-C it while itâs struggling with the core dump. Thereâs some callstack with &lt;code&gt;dwarf_decode_macro_bytes&lt;/code&gt;. Google quickly brings up some relevant issues, such as âUsing -ggdb3 and linking with ld.lld leads to cpu/memory hog in
gdbâ (Status: UNCONFIRMED) and âlld doesn't generate
DW_MACRO_import like ld.bfd doesâ (Status: RESOLVED WONTFIX.)&lt;/p&gt;
    &lt;p&gt;Apparently gcc generates some DWARF data that gdb is slow to handle. The GNU linker fixes this data, so that gdb doesnât end up handling it slowly. LLD refuses to emulate this behavior of the GNU linker, because itâs gccâs fault to have produced that DWARF data in the first place. And gdb refuses to handle LLDâs output efficiently, because itâs LLDâs fault to not have handled gccâs output the way the GNU linker does. So I just remove &lt;code&gt;-ggdb3&lt;/code&gt; - it gives you a bit richer debug info, but itâs
not worth the slower linking with gold instead of LLD, nor the slowdown in gdb that you get with LLD. And everyone links happily
ever after.&lt;/p&gt;
    &lt;p&gt;Which goes to show that Ctrl-C profiling is often enough to solve a simple problem, and itâs usually much easier than learning how to use a profiler and how to properly read its output. You can connect a debugger to almost anything, all the way down to some chip with nothing like a standard OS that could work with a standard profiler. You can connect a debugger to almost anything especially if itâs slow - for example, maybe itâs hard to actually invoke the program under gdb because its invocation is buried somewhere very deep, but if itâs slow, you can &lt;code&gt;gdb /proc/$pid/exe $pid&lt;/code&gt; after it was
started.&lt;/p&gt;
    &lt;p&gt;A debugger also needs less to work with than a profiler. Unlike perf, gdb will give you a callstack even if the program was compiled without frame pointer support. And you certainly donât need a special build, like gprofâs &lt;code&gt;-pg&lt;/code&gt;, or to run on a slow
simulator, like callgrind / KCachegrind. And then the output of a profiler might be easy to
misinterpret - and Iâve only scratched the surface the last time I wrote about it.
Eyeballing a few callstacks is more straightforward.&lt;/p&gt;
    &lt;p&gt;Why then do we need profilers at all? Here is a very partial list of reasons, in no particular order.&lt;/p&gt;
    &lt;p&gt;Letâs say, completely hypothetically, that youâve switched to the LLD linker, and your program is now 2-3% slower. If you Ctrl-C it, youâll see the same callstacks as with the version linked with gold. But if you have a profiler running on a simulator, similarly to callgrind, then you can find the functions with the most slowdown - and they might not be the ones taking the most time overall, they just have the most slowdown relatively to the old version - and then you can look at the assembly listings and see how much time was spent running each instruction. And then youâll see that the new version has branch-to-address-from-register instructions where the old version had branch-to-constant-offset instructions.&lt;/p&gt;
    &lt;p&gt;Then you will learn about MIPS ârelocation relaxationâ (used also in RISC-V AFAIK.) The compiler âassumes the worstâ and generates code loading a function address into a register, and then jumping to the address stored in that register. Then, if youâre lucky, the linker realizes that it has actually placed the function close enough to the caller for that caller to branch to the function using a constant offset. (Fixed-sized RISC branch instructions cannot encode constant offsets larger than a certain value, so the function needs to be close enough to the caller for the distance to fit into the offset encoding.) And then the linker ârelaxesâ the expensive branch-from-register instruction into a cheaper branch-to-constant-offset instruction. And it turns out that the LLD version youâre using doesnât implement relocation relaxation.&lt;/p&gt;
    &lt;p&gt;Of course you, or should I say me, wouldnât need that very, very fancy simulator-based profiler if you werenât the idiot using LLD 9 when LLD 14 was already available, with relocation relaxation implemented back in LLD 10. (I wish Iâd saved the discussion in the mailing list around this patch; now I canât find it anywhere. There was nobody confident enough in their MIPS knowledge to review the patch, but you donât merge patches without a review, do you? There was even a message saying âHappy anniversary to the relocation relaxation patch!â a year after it was submitted without having been merged. Eventually someone said something like âwe have to either merge or reject it, or weâre being rudeâ and someone else said âwell, the patch author knows MIPS better than any of us, so letâs just merge it.â)&lt;/p&gt;
    &lt;p&gt;But, despite having been an idiot here, I maintain that you donât have to be an idiot to have this sort of problem, which a profiler will help solve, and Ctrl-C profiling will not.&lt;/p&gt;
    &lt;p&gt;The broader issue is that Ctrl-C is essentially a sampling profiler - one with an unusually low sampling frequency, but a sampling profiler nonetheless. Very small changes spread across a program are obviously invisible to a sampling profiler. Also, sampling profilers are bad at tail latency - if something is usually fast but occasionally slow, you wonât be there to Ctrl-C it when itâs slow. (Of course, if âslowâ means 100 ms instead of the usual 25 ms, you wouldnât manage to Ctrl-C it in time even if you were there - that low sampling frequency comes with some downsides.)&lt;/p&gt;
    &lt;p&gt;Systems involving many threads, processes or machinesâ¦ our esteemed ârandom pausingâ technique, aka Ctrl-C profiling, is often not great to use with these. And at this point I feel that the idea of replacing all of the various profilers with Ctrl-C is too ridiculous to bother with more counterarguments.&lt;/p&gt;
    &lt;p&gt;But, there are many various kinds of profilers, making it a question which kind to use, and how much legwork finding the problem will take on top of using it. Simulation-based profilers donât have the problem of losing data to a low sampling frequency - they analyze full instruction traces - but theyâre too slow for anything like a production environment. So you might need some measurements that you can run in production, and then a way to rerun the program on the simulator using inputs that were observed to cause a slowdown in production based on these measurements. Tracing profilers like ftrace / KernelShark are great for looking at examples of tail latency, but they will not reliably take you to the places in the code where the time is spent. Sampling profilers can run in production and take you to the right place in the code, but theyâre a poor match for code that runs slowly but only occasionally, and even worse for code that occasionally gets stuck waiting for something. And most of these tools have a bunch of non-trivial prerequisites, config knobs and likely ways to misread their output.&lt;/p&gt;
    &lt;p&gt;Conversely, Ctrl-C in a debugger is easy, makes you look very effective when it actually works, and costs almost nothing to try even when it doesnât really help in the end. Whatâs not to like?&lt;/p&gt;
    &lt;p&gt;I often find myself recommending something primitive or ugly, which might actually do better than the âproperâ approach, or it might have less risky failure modes in the hands of typical users, or it might be easier to tailor to your needs than a more elaborate solution. âProfile with Ctrl-Câ fits right in - certainly very primitive, yet often compares surprisingly favorably with more sophisticated alternatives. And therefore, I must give Ctrl-C profiling my warmest endorsement!&lt;/p&gt;
    &lt;p&gt;Thanks to Dan Luu for reviewing a draft of this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yosefk.com/blog/profiling-with-ctrl-c.html"/><published>2026-01-03T11:13:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46475395</id><title>Recursive Language Models</title><updated>2026-01-03T17:08:57.699322+00:00</updated><content>&lt;doc fingerprint="cc9c352ac1f5128e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 31 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Recursive Language Models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.24601"/><published>2026-01-03T11:29:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46475437</id><title>X-Clacks-Overhead</title><updated>2026-01-03T17:08:57.553195+00:00</updated><content/><link href="https://hleb.dev/post/x-clacks-overhead/"/><published>2026-01-03T11:37:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46476636</id><title>ParadeDB (YC S23) Is Hiring Database Engineers</title><updated>2026-01-03T17:08:57.298764+00:00</updated><content>&lt;doc fingerprint="10f452a104a33a8"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript must be enabled in order to use Notion. Please enable JavaScript to continue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://paradedb.notion.site/?p=172ea4ce9deb80898ef5d5097bd65544&amp;pm=s"/><published>2026-01-03T13:53:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478061</id><title>Show HN: Offline tiles and routing and geocoding in one Docker Compose stack</title><updated>2026-01-03T17:08:57.135741+00:00</updated><content>&lt;doc fingerprint="3380fb157c3cf942"&gt;
  &lt;main&gt;
    &lt;p&gt;Corviont runs MapLibre UI, vector tiles, Valhalla routing, and SQLite geocoding entirely offline on edge or on-prem devices - with a local map updater shipping next.&lt;/p&gt;
    &lt;p&gt;The Monaco demo is the full Corviont stack in miniature: a MapLibre UI talking to local APIs for tiles, routing, and geocoding - all running in Docker on your machine or edge device.&lt;/p&gt;
    &lt;p&gt;Monaco packaged as a single PMTiles file, served locally with no external tile servers.&lt;/p&gt;
    &lt;p&gt;Valhalla container exposing an HTTP API for offline routing between arbitrary points.&lt;/p&gt;
    &lt;p&gt;SQLite database built from Nominatim data, powering forward and reverse geocoding via a lightweight API.&lt;/p&gt;
    &lt;p&gt;MapLibre frontend wired to these local endpoints.&lt;/p&gt;
    &lt;p&gt;Corviont is built for devices that can’t rely on a fast, cheap, always-on connection.&lt;lb/&gt;🏭 Edge &amp;amp; industrial devices&lt;/p&gt;
    &lt;p&gt;Run on industrial PCs, gateways, or embedded boxes so maps and routing keep working even when the WAN link is slow or down.&lt;/p&gt;
    &lt;p&gt;🚢 Remote and offshore deployments&lt;/p&gt;
    &lt;p&gt;Install on vessels and remote sites with intermittent or satellite-only connectivity so tiles, routing, and search stay instant and local.&lt;/p&gt;
    &lt;p&gt;🚚 Field fleets &amp;amp; mobile units&lt;/p&gt;
    &lt;p&gt;Use in vehicles and temporary field setups where devices go offline or change networks, without breaking your app’s map &amp;amp; routing UX.&lt;/p&gt;
    &lt;p&gt;️🛡️ Privacy and compliance-sensitive environments&lt;/p&gt;
    &lt;p&gt;Keep location queries and routes inside your own network; all map, routing, and geocoding requests terminate on your devices.&lt;/p&gt;
    &lt;p&gt;The Monaco demo is the first step. It’s the same architecture we’ll use for larger regions and real fleets - here’s what’s on the way:&lt;/p&gt;
    &lt;p&gt;🧩 Local map updater&lt;/p&gt;
    &lt;p&gt;A small background service that pulls new map bundles, verifies them, and switches the active dataset without downtime.&lt;/p&gt;
    &lt;p&gt;🗂 Custom overlays&lt;/p&gt;
    &lt;p&gt;Load your own POIs, geofences, or operational layers (GeoJSON) on top of the base map, rendered directly in the UI.&lt;/p&gt;
    &lt;p&gt;📍 Richer geocoding output&lt;/p&gt;
    &lt;p&gt;Better address results with house numbers, and optional geometry for streets and areas (not just centrepoints) in forward and reverse search.&lt;/p&gt;
    &lt;p&gt;🧱 More edge platforms &amp;amp; targets&lt;/p&gt;
    &lt;p&gt;First-class integrations for Portainer and Mender, plus deployment examples for K3s/Kubernetes and edge runtimes on AWS and Azure.&lt;/p&gt;
    &lt;p&gt;If any of these are critical for you, or if something important to your use case isn’t listed here, tell us in the form below. Your input directly influences what we build first.&lt;/p&gt;
    &lt;p&gt;Email + region is all that’s required. Notes are optional - we prioritize builds based on demand.&lt;/p&gt;
    &lt;p&gt;The form has been successfully submitted.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.corviont.com/"/><published>2026-01-03T15:55:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478377</id><title>The Most Popular Blogs of Hacker News in 2025</title><updated>2026-01-03T17:08:57.048141+00:00</updated><content>&lt;doc fingerprint="2c4c11916efc2687"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Most Popular Blogs of Hacker News in 2025&lt;/head&gt;
    &lt;p&gt;With 2025 wrapped up, I can finally answer a question I’m curious about every year: who were the most popular bloggers of Hacker News?&lt;/p&gt;
    &lt;p&gt;Who counts as a blogger?&lt;/p&gt;
    &lt;p&gt;I explain more in my methodology page, but it’s basically anyone who blogs as an individual rather than as part of a company or a team. As an example, John Graham-Cumming is the CTO of Cloudflare, so I count his personal blog but not his posts to the Cloudflare company blog.&lt;/p&gt;
    &lt;head rend="h2"&gt;#1 Simon Willison🔗&lt;/head&gt;
    &lt;p&gt;For the third straight year, Simon Willison was the most popular blogger on Hacker News.&lt;/p&gt;
    &lt;p&gt;At first, Simon’s position at #1 feels obvious: he wrote about AI in a year when everyone’s obsessed with AI. But there are tons of AI bloggers, and Simon is the only one who’s popular on HN, so what sets Simon apart?&lt;/p&gt;
    &lt;p&gt;First, Simon isn’t selling you anything. Simon writes about LLMs as a power user not as a sales pitch from some startup’s VP of product. He tries every AI tool he can get his hands on with no allegiance to any particular vendor. That allows him to write about how new AI tools fit into the ecosystem at large. It’s like getting restaurant recommendations from someone who eats out 20 times a week as opposed to someone who owns 20 restaurant chains.&lt;/p&gt;
    &lt;p&gt;Simon is also one of the most prolific bloggers on Hacker News. In 2025 alone, he wrote over 1,000 blog posts, though only 118 were full-length articles (“only”).&lt;/p&gt;
    &lt;p&gt;Simon often finds ideas within walled-garden platforms (e.g., TikTok, Twitter) and simply brings them to the open web, where it’s easier for HN to discuss. Some of his most popular posts were just short quotes or links with a bit of commentary. “I’m worried that they put co-pilot in Excel” is just a quote from a video he watched on TikTok. “A computer can never be held accountable” is Simon summarizing a few tweets.&lt;/p&gt;
    &lt;p&gt;Simon has said these types of posts are easy to write yet high in value.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Sharing interesting links with commentary is a low effort, high value way to contribute to internet life at large.&lt;/p&gt;
      &lt;p&gt;—Simon Willison, “My approach to running a link blog”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;#2 Jeff Geerling🔗&lt;/head&gt;
    &lt;p&gt;This is Jeff’s most successful year on Hacker News, beating his #5 finish in 2023.&lt;/p&gt;
    &lt;p&gt;The #2 spot was an extremely tight race this year. Jeff’s posts totaled 10,813 upvotes, edging out the #3 blogger by just 9 points (a 0.08% difference). The #4 finisher was just 100 points behind that. Past stories can still accrue upvotes, so this could still flip, but these were the rankings as of midnight on Dec. 31st.&lt;/p&gt;
    &lt;p&gt;Jeff is a popular YouTube creator with over 1M subscribers. He covers some of HN’s favorite topics, like Raspberry Pi computers, self-hosted software, and computer hardware. YouTube videos rarely succeed on Hacker News, so when Jeff publishes a new video, he often publishes an accompanying blog post. Jeff isn’t the only YouTuber who does this, but he’s one of the few who does it well.&lt;/p&gt;
    &lt;p&gt;I’ve seen other YouTube creators try to repurpose their videos by auto-generating a transcript and calling that a blog post. That’s not what Jeff does.&lt;/p&gt;
    &lt;p&gt;Jeff started out as a blogger, and he still treats his blog readers as first-class citizens. He structures his articles to fit the text medium rather than just lazily scraping dialog from his videos. You can read his post about upgrading storage on his Mac mini and not even realize it’s adapted from a video.&lt;/p&gt;
    &lt;head rend="h2"&gt;#3 Sean Goedecke🔗&lt;/head&gt;
    &lt;p&gt;Sean came out of nowhere as a blogging powerhouse this year. He’d been blogging sporadically since 2020, but he hit a turning point at the end of 2024 with “How I ship projects at big tech companies.” It was one of HN’s top 100 posts of the year and remains Sean’s most popular post on HN.&lt;/p&gt;
    &lt;p&gt;After his first success on HN, Sean went from publishing every few months to multiple times per week, becoming a regular fixture on the front page.&lt;/p&gt;
    &lt;p&gt;Sean is a Staff Software Engineer at GitHub and previously worked at Zendesk. Like Simon, Sean is extremely prolific. He wrote 140 posts this year. Of those, 47 reached the front page. Most bloggers are happy to make it to the front page a few times per year; Sean was doing it about once a week.&lt;/p&gt;
    &lt;p&gt;Sean explains his strategy in “Writing a tech blog people want to read”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;the recipe for a popular post is to have a clear opinion about working in tech that many people disagree with.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I think Sean’s insight is true, but he’s selling his own writing a bit short. To me, Sean’s greatest strength is his ability to explain big tech organizational politics to engineers.&lt;/p&gt;
    &lt;p&gt;Most junior to mid-level developers don’t care about company politics. They think of office politics as something that strong technical thinkers shouldn’t have to waste brain cells on. As a result, they can’t understand why they can’t get promoted or how their company’s codebase got so bad. Sean’s posts explain these phenomena in a way that’s clear and intelligible to engineers.&lt;/p&gt;
    &lt;p&gt;Sean’s posts are also a good example of how much luck comes into play on Hacker News, especially for less established authors. Sean’s top three posts of the year all flopped on their first submission and didn’t succeed until their second or third try, sometimes months later. Even then, only a third of his posts reached the front page at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;#4 Brian Krebs🔗&lt;/head&gt;
    &lt;p&gt;Brian Krebs is an independent investigative journalist who covers cybercrime. He’s one of HN’s most popular bloggers of all time, second only to Paul Graham, the creator of HN. For 11 of the last 12 years, Brian has been one of HN’s top 10 bloggers.&lt;/p&gt;
    &lt;p&gt;In 2025, Brian mostly stuck to his usual beat of deeply investigated cybersecurity stories, but his second most popular story of the year was a sobering post about the Trump administration’s steps to undermine free speech in the US. It immediately shot to the #1 slot and stayed there for several hours. Unfortunately, too many users flagged the post, and it was moderated off the front page, which is often the fate of political stories on HN.&lt;/p&gt;
    &lt;head rend="h2"&gt;#5 Neal Agarwal🔗&lt;/head&gt;
    &lt;p&gt;Neal’s work isn’t what you might think of as blog posts; they’re more like interactive art. Some of his posts are games that parody the web, while others are straight-faced visual essays about topics he finds interesting.&lt;/p&gt;
    &lt;p&gt;This was Neal’s most successful year on HN. Everything he published reached the front page, with about half hitting #1, and the rest peaking at #2. Stimulation Clicker was the 4th most popular post of the entire year.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other notes🔗&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;John Gruber finished the year in #6 despite wondering aloud back in March whether Hacker News had shadowbanned his blog. It was his best year on Hacker News since 2011 and his first appearance in the top 10 since 2020.&lt;/item&gt;
      &lt;item&gt;Mahad Kalam finished at #21 for the year with a single blog post, which became the top post of the year. Byran Huang appeared right behind him, also with a single blog post, which became the #3 most upvoted post of the year.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://refactoringenglish.com/blog/2025-hn-top-5/"/><published>2026-01-03T16:20:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478457</id><title>IDF database suggests that at least 83% of Gaza dead were civilians</title><updated>2026-01-03T17:08:56.975220+00:00</updated><content/><link href="https://www.972mag.com/israeli-intelligence-database-83-percent-civilians-militants/"/><published>2026-01-03T16:27:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46478647</id><title>The C3 Programming Language</title><updated>2026-01-03T17:08:56.737294+00:00</updated><content>&lt;doc fingerprint="3cf56a2aab1fe20c"&gt;
  &lt;main&gt;
    &lt;code&gt;
                   module hello_world;&lt;lb/&gt; import std::io;&lt;lb/&gt; &lt;lb/&gt; fn void main() &lt;lb/&gt;{&lt;lb/&gt;  io::printn("Hello, world!");  &lt;lb/&gt;
                  }&lt;lb/&gt; 
                &lt;/code&gt;
    &lt;code&gt;
                   module hello_world;&lt;lb/&gt; import std::io;&lt;lb/&gt; &lt;lb/&gt; fn void main() &lt;lb/&gt;{&lt;lb/&gt;  io::printn("Hello, world!");  &lt;lb/&gt;
                  }&lt;lb/&gt; 
                &lt;/code&gt;
    &lt;p&gt;C3 fits right into your C/C++ application with full C ABI compatibility out of the box: no need for special "C compatible" types or functions, no limitations on what C3 features you can use from C.&lt;/p&gt;
    &lt;p&gt;A simple and straightforward module system that doesn't get in the way, with defaults that makes sense.&lt;/p&gt;
    &lt;p&gt;C3 empowers you with precise, purpose-built operator overloading — no C++ baggage, just clean, expressive code. Ideal for vectors, matrices, and fixed-point math that reads exactly how it should.&lt;/p&gt;
    &lt;p&gt; C3 is a programming language that builds on the syntax and semantics of the C language, with the goal of evolving it while still retaining familiarity for C programmers.&lt;lb/&gt; Thanks to full ABI compatibility with C, it's possible to mix C and C3 in the same project with no effort. As a demonstration, vkQuake was compiled with a small portion of the code converted to C3 and compiled with the c3c compiler. &lt;/p&gt;
    &lt;p&gt;Unlock the full power of compile-time code with macros that read like functions — clearer, stronger, and miles beyond C’s preprocessor.&lt;/p&gt;
    &lt;p&gt;C3 brings programming-by-contract to the mainstream with unobtrusive contracts that are used to express both runtime and compile-time constraints.&lt;/p&gt;
    &lt;p&gt;Error handling that combines the best parts of "Result" errors with the easy use of exceptions and integrates seamlessly with C.&lt;/p&gt;
    &lt;p&gt;C3 generic modules offer superior simplicity and clarity for creating generic types.&lt;/p&gt;
    &lt;p&gt;Type introspection is available both at compile time and runtime, powering flexible macros and functions&lt;/p&gt;
    &lt;p&gt;Write asm as regular inline code without using strings or cryptic constraints.&lt;/p&gt;
    &lt;p&gt;Feel confident in your code's correctness: in debug mode the compiler inserts extensive runtime bounds checks and value checks, which together with contracts will let you catch bugs early.&lt;/p&gt;
    &lt;p&gt;No more anonymous "segmentation fault" errors: the C3 standard library enables detailed stacktraces out of the box for your debug builds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://c3-lang.org"/><published>2026-01-03T16:41:06+00:00</published></entry></feed>