<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-08-28T16:12:29.922608+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45046916</id><title>Altered states of consciousness induced by breathwork accompanied by music</title><updated>2025-08-28T16:12:38.182255+00:00</updated><content>&lt;doc fingerprint="3460a321c1b38dd7"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Figures&lt;/head&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;The popularity of breathwork as a therapeutic tool for psychological distress is rapidly expanding. Breathwork practices that increase ventilatory rate or depth, facilitated by music, can evoke subjective experiential states analogous to altered states of consciousness (ASCs) evoked by psychedelic substances. These states include components such as euphoria, bliss, and perceptual differences. However, the neurobiological mechanisms underlying the profound subjective effects of high ventilation breathwork (HVB) remain largely unknown and unexplored. In this study, we investigated the neurobiological substrates of ASCs induced by HVB in experienced practitioners. We demonstrate that the intensity of ASCs evoked by HVB was proportional to cardiovascular sympathetic activation and to haemodynamic alterations in cerebral perfusion within clusters spanning the left operculum/posterior insula and right amygdala/anterior hippocampus; regions implicated in respiratory interoceptive representation and the processing of emotional memories, respectively. These observed regional cerebral effects may underlie pivotal mental experiences that mediate positive therapeutic outcomes of HVB.&lt;/p&gt;
    &lt;p&gt;Citation: Kartar AA, Horinouchi T, Örzsik B, Anderson B, Hall L, Bailey D, et al. (2025) Neurobiological substrates of altered states of consciousness induced by high ventilation breathwork accompanied by music. PLoS One 20(8): e0329411. https://doi.org/10.1371/journal.pone.0329411&lt;/p&gt;
    &lt;p&gt;Editor: Gaëtan Merlhiot, Institut VEDECOM, FRANCE&lt;/p&gt;
    &lt;p&gt;Received: August 6, 2024; Accepted: July 16, 2025; Published: August 27, 2025&lt;/p&gt;
    &lt;p&gt;Copyright: © 2025 Kartar et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.&lt;/p&gt;
    &lt;p&gt;Data Availability: All relevant data for this study are publicly available from the OSF repository (https://doi.org/10.17605/OSF.IO/5WR9Q).&lt;/p&gt;
    &lt;p&gt;Funding: The author(s) received no specific funding for this work.&lt;/p&gt;
    &lt;p&gt;Competing interests: The authors have declared that no competing interests exist.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;High ventilation breathwork (HVB) encompasses contemplative and therapeutic practices, including Conscious Connected Breathing or Holotropic Breathwork, in which a controlled pattern of volitional breathing increases the rate or depth of ventilation and is typically accompanied by evocative music. Despite their distinct historical roots and delivery modalities, these different HVB practices share a purported ability to elicit acute extraordinary alterations in subjective experience that closely resemble the qualia of altered states of consciousness (ASCs) induced by psychedelic substances [1–3]. Converging evidence demonstrates the potential value of psychedelic treatments for specific difficult-to-treat psychiatric and physiological conditions [4–7]. The induction of ASCs is suggested to be critical to the therapeutic action of psychedelic substances [8–10], for which HVB might therefore offer a non-pharmacological alternative, with fewer legal and ethical restrictions to large-scale adoption in clinical treatment. In line with this, the popularity of HVB as a therapeutic tool for psychological distress is rapidly expanding, indexed by an increased number of scientific investigations, see [11,12] for more details.&lt;/p&gt;
    &lt;p&gt;The therapeutic potential of HVB practices is suggested by a long cultural tradition of use to relieve symptoms of psychological distress [11,13] and by emerging preliminary evidence of clinical efficacy from controlled trials in affective and trauma-related disorders [14]. Prolonged hyperventilation/HVB reportedly elicits a wide range of effects on subjective experience that include emotional and psychedelic-like phenomena (ASCs), which range from panic-like sensations to feelings of awe and dissociative symptoms [11]. The 5D-ASC questionnaire is popularly used in ASC research to retrospectively assess such states [15]. A key dimension of this scale is ‘Oceanic Boundlessness’ (OBN); a term coined by Freud in 1920 [16] which describes a set of related feelings including ‘spiritual experience, insightfulness, blissful state, positively experienced depersonalization, and the experience of unity’ [17]. OBN is considered as a defining aspect of ASCs evoked by psychedelic substances, such as psilocybin. However, the neurobiological mechanisms and subjective experience underlying ASCs induced by HVB have not been studied extensively and remain elusive.&lt;/p&gt;
    &lt;p&gt;First, we characterised the subjective experience of HVB to capture the nature and intensity of evoked experiential phenomena. From these data, we aimed to assess whether these effects could be reliably reproduced in controlled experimental settings in comparison to a remote – and more ecologically valid – condition. These findings informed the choice of the ASC variable, OBN, which was ultimately selected as the most widely reported experiential phenomena to identify the critical neurobiological effects of HVB.&lt;/p&gt;
    &lt;p&gt;Then we examined the effects of HVB performed by experienced breathwork practitioners in different experimental settings, and investigated peripheral and central neurophysiological mechanisms underpinning ASCs engendered by HVB. The neurobiological endpoints were selected based on well-characterised neurophysiological effects of hyperventilation (reviewed in [11]). Hyperventilation acutely reduces regional cerebral blood flow (rCBF) through interacting effects of hypocapnia, cerebral alkalosis and hypoxia, resulting in transient perturbation of neurometabolic homeostasis. Further, hyperventilation evokes allostatic changes in action-ready bodily arousal, mediated via the autonomic nervous system via the dominance of sympathetic over parasympathetic drive to the heart and blood vessels. In characterising the neurobiological effects of HVB and associated ASCs, we therefore focused our measurements on two robust indices of neurometabolic and autonomic nervous control: rCBF and heart rate variability (HRV).&lt;/p&gt;
    &lt;p&gt;To our knowledge, no studies have previously reported the relationship between the intensity of ASCs and changes in rCBF induced by HVB practices. Since we could not base our prediction of the regional specificity of such correlations on previous knowledge, we preferred to adopt a whole brain voxelwise exploratory approach. Also, as observations reported on the effects of psychedelics on autonomic nervous system activity have been contrasting [18,19], we could not make precise predictions on the direction of association between HRV and ASCs.&lt;/p&gt;
    &lt;p&gt;Our study was designed to address different objectives through three inter-related experiments: (please see the methods for more details), in 1) HVB was conducted over an online video-conferencing platform with a breathwork facilitator (REMOTE setting). The aim was to characterise the subjective response to remote HVB in a home setting, and inform the choice of the ASC domain to be used as subjective endpoint. In 2), we used pseudo-continuous arterial spin labelling (pCASL) magnetic resonance imaging (MRI) of the brain during HVB to identify the relationship between neural haemodynamic effects of HVB and subjective measures (MRI setting). In 3) HVB was performed in a psychophysiology lab to characterise the relationship between the psychophysiological effects of HVB (autonomic alterations, see ‘psychophysiological session 3’ for more information) and subjective measures (LAB setting).&lt;/p&gt;
    &lt;head rend="h2"&gt;Materials and methods&lt;/head&gt;
    &lt;head rend="h3"&gt;Ethics statement&lt;/head&gt;
    &lt;p&gt;This research was approved by the Research Governance and Ethics Committee (RGEC) in Brighton and Sussex Medical School (BSMS) as ERA/BSMS9AN4/2/2. Recruitment began on 24/11/2021 and ended on 03/03/2022. Participants provided written informed consent before participating.&lt;/p&gt;
    &lt;head rend="h3"&gt;Participants&lt;/head&gt;
    &lt;p&gt;Physically and psychiatrically healthy participants aged 18–65 years old were recruited from the local area through advertisements and flyers distributed at breathwork events, in yoga/meditation centres, and on social media. Participants were eligible to take part if they had either 10 or more experiences of fast-paced breathwork or at least 6 months of any HVB practice (as defined in [11]). They were screened online for eligibility and excluded if they were pregnant, currently experiencing any psychiatric condition (assessed using the Mini International Neuropsychiatric Interview (MINI) to ensure absence of DSM-V listed disorders) [20]. Additional exclusion criteria included a history of epileptic seizures, panic disorder, or syncope in prior HVB, current neurological, musculoskeletal, respiratory, or cardiovascular disease, current pharmacological treatment, and contraindications to MRI.&lt;/p&gt;
    &lt;p&gt;Participants and were financially compensated £10 per hour for their time and up to £10 in travel expenses.&lt;/p&gt;
    &lt;head rend="h3"&gt;Breathwork modality and subjective measures&lt;/head&gt;
    &lt;p&gt;HVB consisted of cyclic breathing without pausing, accompanied by progressively evocative music. This aimed to reproduce the experience of Conscious Connected Breathing, a widely adopted HVB practice typically led by a trained breathwork facilitator. In the online experimental session, instructions were provided by a breathwork facilitator (DB) who hosted the group of online participants. For the LAB and MRI setting, pre-recorded instructions by the same facilitator were delivered to participants. Specific details on breathwork instructions are presented in the supplementary index (S1 Appendix).&lt;/p&gt;
    &lt;head rend="h3"&gt;Questionnaires&lt;/head&gt;
    &lt;p&gt;Self-reported measures were consistent across the three conditions and administered online via Qualtrics (Qualtrics, Provo, UT) [21] within 30 minutes post-HVB. The selected questionnaires assessed: 1) Affect (Positive and Negative Affect Schedule – Expanded Form, PANAS-X [22]); 2) Panic–like symptoms (Panic Symptoms List, PSL [23]), 3) Fear and discomfort (Visual Analogue Scales (VAS) [24]), and 4) Symptoms of ASCs (5-Dimensional Altered States of Consciousness Rating Scale, 5D-ASC [15]).&lt;/p&gt;
    &lt;p&gt;Pre-session questionnaires included the VAS (scored from “0 – no fear and discomfort” to “100 – complete fear and discomfort”) [24] and the PANAS-X, which measured affect using 60 items rated on a 5-point Likert scale from “1 – very slightly or not at all” to “5 – extremely” [25].&lt;/p&gt;
    &lt;p&gt;Post-session questionnaires included the VAS and PANAS-X again, as well as the 5D-ASC, which retrospectively assessed ASCs using 94 items rated via VAS [17]. Questions and responses were grouped into 3 broad subscales: oceanic boundlessness (OBN) as previously mentioned, visionary restructuralisation (VRS) to examine the effect of the HVB on vision, and Dread of Ego Dissolution (DED) which captures the anxiety-inducing effects of the experience related to the idea of the dissolution of the self [15]. The PSL, a 13-item tool used to evaluate panic symptomatology, required participants to rate each item on a five-point scale from “0 – not at all” to “4 – extremely severe”.&lt;/p&gt;
    &lt;p&gt;The PSL and VAS for fear/discomfort were scored based on [24]: a significant panic attack was indicated by an increase in VAS fear by 50 points and 4 or more items rated above mild in the PSL (mild = 2).&lt;/p&gt;
    &lt;head rend="h3"&gt;Online experimental session 1 (REMOTE)&lt;/head&gt;
    &lt;p&gt;The session was conducted remotely via an online video-conferencing platform (Zoom). Preparatory information was sent to participants after screening and enrolment, including the platform link, instructions, and pre- and post-session questionnaires.&lt;/p&gt;
    &lt;p&gt;Participants received instructions on camera setup and were assigned personal participant numbers. They were instructed to be in a private room to avoid interruptions and to position their cameras to capture their chest and stomach for observation of full-body, continuous breaths. A breathwork facilitator remotely guided groups of participants through the 30-minute online breathwork session. Members of the research team were present online to ensure session consistency and to monitor participant engagement in HVB practice. No group experience-sharing (integration) followed the breathwork sessions to avoid memory and experience merging. Instead, participants self-integrated (processed) their session by completing retrospective questionnaires that explored the qualia of the experience within 30 minutes of concluding the session.&lt;/p&gt;
    &lt;head rend="h3"&gt;Neuroimaging experimental session 2 (MRI)&lt;/head&gt;
    &lt;p&gt;Each participant in the neuroimaging session was scanned on a Siemens Prisma 3T magnetic resonance imaging (MRI) scanner fitted with a 32-channel head coil. High-resolution structural scans were obtained during rest using a 3D T1-weighted magnetization-prepared rapid acquisition gradient echo (T1 MPRAGE) sequence (repetition time (TR) = 2300 ms, echo time (TE) = 2.19 ms, flip angle = 9°, matrix = 256 × 256, voxel size = 1.0 × 1.0 × 1.0 mm3, GRAPPA acceleration factor = 2; total acquisition time (TA) = 5m 30s). Additionally, twenty control and label images were acquired per condition using a pCASL with background suppression following the parameter recommendation of the consensus paper [26]: label duration = 2000ms, post-labelling delay (PLD) = 1800ms, TR = 5000 ms, TE = 14 ms, voxel size = 3.4 × 3.4 × 6.0 mm3, TA = 3m 22s), was acquired. A proton density (M0) image was acquired using the same readout and TR as the control and label images to estimate pcASL CBF.&lt;/p&gt;
    &lt;p&gt;Fig 1 is a schematic presentation of the MRI experimental design. Recorded instructions (see S1 Appendix) guided participants to breathe through three phases: BASELINE, START, and SUSTAINED HVB. BASELINE consisted of breathing at a normal rate for 20 minutes. Participants were asked to gradually increase their ventilation rate and/or depth via recorded instructions (START HVB) for approximately 6 minutes. The SUSTAINED HVB phase started after at least 5 minutes of START HVB and once end-tidal CO2 (EtCO2), measured via nasal cannula connected to a capnograph (MICROCAP®, Oridion Medical LTD), was stable at levels ≤20 mmHg (from a typical value of 35–40 mmHg), and was maintained for a further ~20-minutes.&lt;/p&gt;
    &lt;p&gt;MPRAGE = 3D magnetization-prepared rapid gradient-echo, ASE = asymmetric spin-echo spiral, BOLD = blood oxygen level dependent, AP/PA anterior-posterior, posterior-anterior. BASELINE = 25 min 32s, breathwork = 23 min 10s. Relaxing music was played at BASELINE during rest for the participant, and evocative up-tempo music that features in breathwork sessions with instructions recorded by a breathwork facilitator were played during HVB.&lt;/p&gt;
    &lt;p&gt;Scans were performed during BASELINE (10 minutes after the scan start), at the start of HVB (immediately after initiating HVB), and during SUSTAINED HVB (after at least 6 minutes of uninterrupted breathwork).&lt;/p&gt;
    &lt;p&gt;SPM12 [27] and custom written Matlab (The MathWorks Inc., Natick, Massachusetts) scripts were used for image processing and statistics. Rigid-body motion correction was used to realign labelled and control images, and perfusion weighted images were calculated for the realigned control-labelled pairs by subtracting the labelled image from the control. The mean perfusion weighted images were then used to estimate CBF using the one-compartment model [26] and processed to obtain partial volume-corrected [28], tissue-specific (i.e., grey matter (GM) and white matter (WM)) CBF images independently. The pcASL CBF images were normalized maps in MNI space using SPM12 [27]. Participants with prominent arterial transit artifacts in the CBF images, evident by the presence of strong arterial signals upon visual inspection, were excluded from the study.&lt;/p&gt;
    &lt;head rend="h3"&gt;Psychophysiological session 3 (LAB)&lt;/head&gt;
    &lt;p&gt;Participants in the psychophysiology study attended the psychophysiology lab at the Trafford Centre for Medical Research at BSMS. To measure beat-to-beat heart rate (HR) and HRV (computed as the root mean square of successive differences, RMSSD) [29], an electrocardiograph (Firstbeat Bodyguard 2 device) was applied to the torso [28]. To measure EtCO2, the participant was fitted with a nasal cannula connected to a capnograph (MICROCAP®, Oridion Medical LTD). Following a BASELINE period during which the participant was instructed to breathe as normal to relaxing music for 10 minutes, the participant was instructed to perform HVB (see supplementary index for more information). This began as a 5-minute warm-up (START HVB) where the participant performed HVB to lower their EtCO2 to ≤20 mmHg, followed by 25-minutes of HVB (SUSTAINED HVB) where EtCO2 was maintained ≤20 mmHg, aided by recorded instructions from a trained breathwork facilitator. For analyses, the HVB period was defined as starting once EtCO2 was stable below 20 mmHg and was subsequently recorded for 20 minutes. The recovery period began immediately after HVB was terminated, and participants resumed their normal breathing. Participants completed retrospective questionnaires within 30 minutes of the session’s conclusion.&lt;/p&gt;
    &lt;head rend="h4"&gt;Data analysis and statistics.&lt;/head&gt;
    &lt;p&gt;Objective 1: To characterize the subjective response to HVB across different settings (REMOTE, LAB, MRI), we compared affective responses (PANAS-X scores clustered into positive and negative domains), panic-like symptoms (VAS fear/discomfort and PSL) and ASCs. For the 5D-ASC, the percentage maximum score was calculated per participant and dimension [30]. Data were compared across the three experiments to test for differences in self-reported effects. A linear mixed-effects model (LMM) was used to examine the effects of setting on the mean responses within each dimension of the 5D-ASC and for the PSL, accounting for subject-specific variability as a random effect using the lmer package in R; [31]. We used the likelihood ratio test to compare a full model with a fixed effect of setting and a random effect of subject to a reduced model with only a random effect of subject [31]. Post-hoc tests were performed using the emmeans package in R [32], adjusted for multiple comparisons using the Tukey method.&lt;/p&gt;
    &lt;p&gt;For the PANAS-X and VAS, we used an LMM analysis to examine the effects of HVB (pre- versus post-) on setting and the type of question (positive versus negative affect for PANAS; discomfort versus fear for VAS), accounting for subject-specific variability as a random effect. We explored two-way interactions between all the variables and post-hoc tests using the same methods as the previous analyses [32].&lt;/p&gt;
    &lt;p&gt;Objective 2: In order to test the correlations between HVB-induced ASCs and rCBF effects, two contrasts between HVB time points (see MRI experimental design in Fig 1) were studied using paired-samples t-tests in SPM12 [27]: contrast 1) between BASELINE and START HVB grey matter CBF; contrast 2) between BASELINE and SUSTAINED HVB grey matter CBF. Following this, voxel-wise maps of changes in pcASL rCBF (ΔrCBF) were calculated for the contrasts between BASELINE versus SUSTAINED HVB, and START versus SUSTAINED HVB. These ΔrCBF maps were then used for voxelwise correlation analysis with the OBN score, selected as the highest-rated 5D-ASC dimension. Voxel clusters were considered significant at a cluster-forming threshold of p &amp;lt; 0.001, corrected for multiple comparisons using family-wise error (FWE) correction, with a significance level of p &amp;lt; 0.05.&lt;/p&gt;
    &lt;p&gt;Objective 3: To investigate changes in cardiac autonomic drive during HVB and their relationship to the intensity of ASCs, we calculated change in HRV (ΔRMSSD) and HR. Heartbeat timing data were imported from the Firstbeat Bodyguard device into Kubios 3.5.0 HRV scientific 4.1.0 for processing. Raw data contained substantial noise from chest movement. After an initial phase of artefact removal, interbeat interval (IBI) data were smoothed using an automatic noise detection filter at a medium threshold [33]. A repeated measures ANCOVA with contrasts for different orders of an equation was conducted using HRV and OBN (5D-ASC selected from objective 1) as covariates to explain HRV variance over time, with polynomial contrast applied to identify linear and complex patterns, allowing us to characterise dynamic trends in HRV responses to HVB.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Self-reported data from 42 participants were analysed, comprising 31 unique individuals. Study participants enrolled in one to three experimental sessions: n = 15 (age 42.9 ± 12.6 years, 5 females) for the online experimental session; n = 8 (age 41 ± 13.02 years, 2 females) for the session conducted within the psychophysiology lab; and n = 19 (age 43.7 ± 11.9; 7 females) for the MRI experimental session. There were different participants in each condition (3 repeated all conditions, 5 participants participated in 2 conditions, see S1 Fig for key subjective effects of repeated participants). No adverse events, including panic attacks, were reported across all experimental settings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Subjective effect results&lt;/head&gt;
    &lt;p&gt;Generally, measures of fear and discomfort were low in all conditions (Fig 2, panel C). LMM analyses identified only a significant two-way interaction between HVB and question type (fear and discomfort), with post-hoc tests showing a significant increase in discomfort post-HVB. These results indicate that perceived discomfort increased during HVB, while perceived fear remained stable across settings.&lt;/p&gt;
    &lt;p&gt;B) For the 5D-ASC, a linear mixed-effect model did not show an effect of setting (χ2(2) = 3.66, p = 0.160; see ‘Data analysis and statistics’). C) Fear and discomfort assessed by VAS indicated no significant effect of experimental setting on HVB, although there was a trend increase in discomfort and reduction in fear after HVB across all environments. D) Negative affect assessed by PANAS-X was reduced by HVB. There was no significant effect of HVB on positive affect, and no significant effect of environment on negative or positive affect. E) For the PSL, a linear mixed-effect model revealed a significant main effect of setting (χ2(2) = 20.41, p &amp;lt; 0.001; see ‘Data analysis and statistics’). Post-hoc Tukey tests identified significant differences between LAB vs. MRI and MRI vs. REMOTE (LAB – MRI, t(22.11) = −3.78, p = 0.003; LAB – REMOTE, t(28.84) = 0.041, p = 0.999; MRI – REMOTE, t(34.09) = −4.37, p &amp;lt; 0.001).&lt;/p&gt;
    &lt;p&gt;None of the mean individual post-HVB PSL scores were ≥ 2, indicating that no panic symptoms reached a clinically significant threshold (a score of 2 corresponded to ‘moderate’). However, the LMM identified a significant main effect of setting on the PSL, with post-hoc analyses showing the PSL scores were significantly higher in the MRI setting compared to the LAB and REMOTE settings (Fig 2, panel E). LMM analyses on the PANAS-X found only a significant two-way interaction between pre/post-HVB and affect, with post-hoc analyses revealing a significant decrease in negative affect from pre- to post-HVB (Fig 2, panel D). These results indicate that HVB decreased negative affect, while positive affect remained stable across settings.&lt;/p&gt;
    &lt;p&gt;In all three settings, HVB elicited altered subjective experiences indicated by positive scores in all dimensions of the 5D-ASC (Fig 2, panels A and B). The highest rated phenomenon was OBN across all three settings, which was selected as a meaningful proxy indicator of the subjective effects of HVB for analysis. A LMM revealed no significant main effect of setting and no significant interaction effect between setting and dimension (Fig 2, panel B).&lt;/p&gt;
    &lt;head rend="h3"&gt;MRI results&lt;/head&gt;
    &lt;p&gt;Datasets from 13 participants (mean age 43.7 ± 11.9; 7 female) were included in the analysis. Voxel clusters showing statistically significant CBF reductions occupied 12% and 28.5% of global grey matter volume at START and SUSTAINED HVB, respectively. Global CBF was reduced by 30.5% during START (36.2 ± 12.4 ml/100g/min) and 41.6% during SUSTAINED HVB (30.5 ± 8.5 ml/100g/min) relative to BASELINE (52.2 ± 8.2 ml/100g/min).&lt;/p&gt;
    &lt;p&gt;We first identified a region of cortex where HVB-evoked reduction in perfusion (ΔrCBF from BASELINE to SUSTAINED) correlated with the magnitude of ASC in the OBN dimension. This cluster encompassed left parietal operculum/posterior insula (PO/INS) (Fig 3). Here, rCBF in PO/INS was reduced by 7.7% during the START period of HVB (43.7 ± 10 ml/100g/min) and 18.9% during SUSTAINED HVB (38.4 ± 12.7 ml/100g/min) relative to BASELINE (52.2 ± 8.2 ml/100g/min).&lt;/p&gt;
    &lt;p&gt;Data points represent cluster means. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p &amp;lt; 0.001; corrected FWE: p &amp;lt; 0.05).&lt;/p&gt;
    &lt;p&gt;Next, we identified regions of significant positive correlation between OBN score and ΔCBF changes from START to SUSTAINED (Fig 4). The cluster encompassed right basolateral amygdala and extended to the CA1 region of anterior hippocampus (BLA/CA1) rCBF. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p &amp;lt; 0.001; corrected FWE: p &amp;lt; 0.05).&lt;/p&gt;
    &lt;p&gt;Data points represent cluster means. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p &amp;lt; 0.001; corrected FWE: p &amp;lt; 0.05).&lt;/p&gt;
    &lt;p&gt;We then investigated if specific concepts related to OBN, namely, disembodiment, experience of unity and blissful state [17], were associated with ΔCBF in PO/INS from BASELINE to SUSTAINED. Analyses identified negative correlations between ΔCBF and the experience of unity (Fig 5A) and blissful state (Fig 5B), but not disembodiment, indicating that the magnitude of subjective experience related to bliss and unity correlated with a reduction in perfusion in this region.&lt;/p&gt;
    &lt;p&gt;Negative correlation between the intensity of subjective experience (blissful state) and CBF in PO/INS during SUSTAINED HVB, relative to BASELINE. Data points represent cluster means. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p &amp;lt; 0.001; corrected FWE: p &amp;lt; 0.05).&lt;/p&gt;
    &lt;head rend="h3"&gt;HRV results&lt;/head&gt;
    &lt;p&gt;A repeated-measures ANCOVA demonstrated an effect of time on RMSSD through BASELINE and phases of HVB and recovery, indicating a significant within-participant cubic effect. There was a significant interaction effect between OBN and the polynomial cubic contrast, F(1, 6) = 6.211, p &amp;lt; 0.05 (Fig 6).&lt;/p&gt;
    &lt;p&gt;Participants were classified into high and low OBN responders using a cutoff score of 50 (50% of the maximum score) to identify ASC experience based on criteria in psychedelic drug literature, e.g., [34].&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;Our study is the first that aims to characterise the relationship between the intensity of ASCs induced by HVB practices and associated central and autonomic nervous system effects, via changes in pcASL rCBF and HRV, respectively. Our findings identified significant correlations that might indicate possible neurobiological substrates of HVB-evoked ASCs, accompanied by music. First, our findings demonstrated that the experience of HVB can be safely reproduced across different experimental settings. The pattern of self-reported experiences elicited within the MRI scanner and psychophysiology lab were analogous to those experienced at home (a more natural and comfortable environment).&lt;/p&gt;
    &lt;p&gt;During all experimental sessions, participants reported a trend-level reduction in ratings of fear and negative emotions. Additionally, no adverse reactions or panic attacks were experienced by any participants. However, there was a mild increase in discomfort ratings and mild panic-like symptoms were reported during the MRI session – although these were not associated to increased anxiety or panic attacks and might have been evoked by the physical constraints of being inside the MRI chamber. This experience conflicts typical breathwork practice. The observed increase in physical discomfort alongside reductions in fear and negative affect may reflect a hormetic effect, whereby transient physiological or emotional stressors promote longer-term psychological resilience [35,36].&lt;/p&gt;
    &lt;p&gt;Across participants and experimental settings, HVB reliably enhanced ASCs dominated by OBN, which is considered as a defining aspect of ASCs evoked by psychedelic substances, such as psilocybin. Although differences in OBN scores across conditions were not statistically significant, participants in the LAB condition reported noticeably higher scores compared to MRI and REMOTE sessions. This trend suggests that the in-person experience and controlled, quiet environment of the LAB may have enhanced the immersive and evocative qualities of the breathwork experience. In contrast, the MRI setting—despite also involving in-person contact —may have been less conducive due to scanner noise and physical constraints. Finally, the REMOTE condition, which involved no in-person interaction and took place in participants varied home environments, received the lowest OBN ratings. These findings point to the importance of ‘set and setting’, e.g., [37], a concept well-established in psychedelic research in shaping ASCs and subjective response. These results may indicate that physical context and interpersonal presence play a critical role in breathwork outcomes.&lt;/p&gt;
    &lt;p&gt;Interestingly, OBN is reportedly the most accurate predictor of antidepressant actions of psychedelic substances [9,38–40]. In the present study, the magnitude of the OBN experience induced by HVB was comparable to that elicited by serotonergic psychedelic substances, including psilocybin and lysergic acid diethylamide (LSD) [41,42], reinforcing observations of other breathwork studies [1,2].&lt;/p&gt;
    &lt;p&gt;Fast-paced hyperventilation induces cardiovascular sympathetic activation (with relative cardiovagal parasympathetic withdrawal) and cerebral vasoconstriction, the latter is a consequence of respiratory alkalosis, resulting from reduced plasma CO2 and H+, which elevates blood pH [43]. Ergo, we focused our analysis on correlations between OBN and changes in HRV (for which decreases capture pro-sympathetic shifts in cardiac autonomic balance) and CBF (where regional reductions reflect cerebrovascular vasoconstriction). Importantly, decreased EtCO2 is implicated as a critical factor in catalysing stronger, deeper ASCs during breathwork and may predict subacute psychological and physiological outcomes [2,44].&lt;/p&gt;
    &lt;p&gt;Our experiments identified that HVB engendered substantive time-dependent decreases in pcASL CBF. The reduction of rCBF relative to BASELINE in a cluster localized within left posterior insula and left parietal operculum predicted the intensity of OBN. This region encompasses primary interoceptive cortex and represents the state of cardiorespiratory arousal, and is consequently engaged in higher-order respiratory control. Correspondingly, neural activity here is enhanced by chemo-stimulated increases in ventilation [45]. More broadly, this insular-parietal region supports the integration of somatosensory information as well as the cortical representation of afferent respiratory and bodily signals [46], for example in the emergence of conscious motor intentions [47]. It is also implicated in high-level integrative processes which merge external and internal stimuli [48,49] that contribute to a coherent, embodied representation of self [50].&lt;/p&gt;
    &lt;p&gt;These roles are relevant to the interpretations of our finding that rCBF reductions within the PO/INS during SUSTAINED HVB predicted the intensity of self-reported OBN experience. The construct of OBN is closely related to feelings of depersonalization, sense of unity and blissful state [16], and our findings align with the notion that abnormal integration of signals in the posterior insula cortex can result in abnormal body ownership. Studies on ecstatic epilepsy, a rare focal epilepsy, show that the insula is involved in ASC-like experiences, including “heightened self-awareness, mental clarity and unity with everything that exists, accompanied by a sense of bliss and physical well-being” [51]. These overlap with the OBN construct, as assessed in the 5D-ASC [15]. Picard and Craig [52] hypothesised the involvement of the insula in the genesis of ecstatic epilepsy given its role in interoception and self-consciousness, confirmed by intracerebral electrode recordings [53]. Seizures in the mesiotemporal region propagated to the dorsal anterior insula coincide with ecstatic symptoms [54] and stimulation of the mid-dorsal insula region evoked experiences akin to oceanic psychedelic effects [55]. The interruption of interoceptive predictive coding during anterior insula seizures may underlie the ecstatic experience, emphasizing its pivotal role in mystical and psychedelic states [51,52].&lt;/p&gt;
    &lt;p&gt;We then ran an exploratory subsequent analysis (Fig 5) to explore the correlations between sub-dimensions of the 11D-ASC relevant to OBN [17], namely ‘disembodiment’, ‘unity’ and ‘bliss’, and CBF reductions induced by HVB relative to BASELINE. We found that scores of ‘unity’ and ‘bliss’, but not ‘disembodiment’ were associated with CBF reductions (see S1-S3 Tables for details), which concurs with the notion discussed above, specifically pointing to an involvement of the insula in the genesis of blissful feelings. Of note, 5-HT2A– targeting compounds such as psilocybin, renowned for therapeutic utility, are known to induce CBF decreases in different brain regions that correlate with the intensity of psychedelic experiences [56]. Studies found reduced CBF in the insula following psilocybin administration, though it was not linked to the subjective effects assessed via the 5D-ASC [57].&lt;/p&gt;
    &lt;p&gt;CBF reductions occur rapidly following decreased EtCO2 and can be reliably detected in response to very brief periods of hyperventilation. Conversely, the profound experiential changes in emotion and thought processes tend to emerge gradually, and correspondingly psychedelic phenomenology appears contingent on the length of the breathwork session [58]. Our investigation therefore compared HVB-evoked effects during late (SUSTAINED) and early (START) phases of HVB to focus specifically on the haemodynamic changes that occurred once the subjective effects had emerged. By contrasting the START and SUSTAINED phases of hyperventilation, we identified a region of right amygdala/anterior hippocampus, where the intensity of subjective experience (OBN as a covariate) positively correlated with CBF changes. Here, increased rCBF predicted the most intense OBN experience, despite the global reduction in CBF. One possible explanation is that this amygdalo-hippocampal CBF increase reflected increased regional neural activation associated with emergent expression of intense subjective effects. These regions are well established as being specialized for emotion (amygdala) and memory (hippocampus) processing. Their reciprocal interactions enable the formation of episodic representations, integrating the emotional significance and interpretation of memories [59]. Interestingly, increased right amygdala blood-oxygen level-dependent responses to emotional faces in functional MRI (fMRI) have been identified in patients with treatment-resistant depression following administration of psilocybin, predictive of clinical improvements at 1 week. The authors posit that this indicates psilocybin aids individuals’ ability to confront, reappraise, and improve emotional responsiveness [60]. Though speculative, these findings may indicate that HVB facilitates the processing of emotionally salient memories, which is proposed to be an essential therapeutic element in psychedelic-assisted psychotherapies [61,62], consistent with promising results from clinical trials of HVB applied as a therapy for patients with post-traumatic stress disorder (PTSD) [63]. Our finding of increased CBF in the hippocampal region also indicates that a single session of intense hyperventilation selectively alters perfusion to the hippocampus, similar to the effects observed after 20 minutes of hypocapnia-inducing moderate exercise [64]. This finding was interpreted as indicative of short-term metabolic adaptation to the high energy demands of hippocampal neurons, rather than reflecting the effects of mechanical vascular changes [64].&lt;/p&gt;
    &lt;p&gt;HRV is a physiological index of the balance of sympathetic and parasympathetic influences on the heart. The observed reduction in HRV reflects sympathetic activation and withdrawal of parasympathetic drive [65–67], consistent with an action-ready state of psychophysiological engagement. As previously described, OBN characteristically entails a deeply felt positive mood linked to the experience of unity with the self and the world, and in its extreme, is experienced as a mystical or religious experience [17]. Our finding that OBN ratings were related to changes in HRV over time echoes observations from other relevant modalities of ASC induction, such as self-induced cognitive trance [68] or 5-HT agonists, such as LSD [18,69–71] or N,N-Dimethyltryptamine (DMT) [72,73]. Nevertheless, the observed association with a positive mood contrasts the wide acceptance of reduced HRV as an index of stress and negative affective states. During HVB, the physiological state of the body exceeds typical homeostatic boundaries, and the autonomic correlates of this may reinforce a dissociative psychological state of positive affect in line with the premise of hormesis, see [11] for more.&lt;/p&gt;
    &lt;p&gt;This exploratory work is preliminary and limited by a small sample size and a lack of an independent control condition that may, in our neuroimaging session, have prevented us from separating the contributions of haemodynamic effects secondary to CO2 changes from neural activation. We also acknowledge the possibility that our whole brain voxelwise approach has led to reduced sensitivity to detect significant correlations relative to an a priori region of interest (ROI) approach. In addition, from a methodological perspective, it may be argued that the lack of control group exposed only to music may prevent dissociation of the effects of auditory stimuli (the ambient track) and the effects of HVB. Listening to upbeat music does stimulate ventilation and this should be controlled in the future. Helpful input from lived experience populations indicates that music is a powerful support to therapeutic applications of HVB. In choosing our design, we elected not to “dissect” the music component from HVB, as we preferred to consider HVB as a contemplative practice accompanied by music as a whole – and to test it in its entirety [74]. Importantly, both studies [2,75] have dissected the effect of music and breathwork, and elucidate that music is not the main factor in triggering ASCs. This reveals that music alone is unlikely to engender significant ASCs of the magnitude reported in this research. It is also argued that the reductionist approach of breaking down a contemplative practice to dissect an “active ingredient” is less preferable than testing a practice in its entirety [74]. Conjointly, psychedelic therapy sessions do not adhere to one specific psychotherapeutic model, though one consistent feature of the experience is listening to music. During psychedelic therapy sessions, patients are urged to centre their attention inwardly whilst supine and listening to a carefully selected playlist. It is suggested that music can help facilitate therapeutic experiences. As such, we are looking for CBF changes that correspond with ASCs, induced by HVB with music. We elected to proceed to treat the experience as whole, hence no control for music. More hypothesis-driven work is certainly required within the neuroscience of breathwork.&lt;/p&gt;
    &lt;p&gt;Furthermore, our study focused on experienced HVB practitioners and therefore our results may not be generalisable; though this is also a strength as it ensured our practitioners were able to reach the desired state without adverse outcomes. Additionally, we were unable to directly assess relevant mechanisms of therapeutic actions, as our subjective measures did not include clinical parameters relevant to traumatic memories or other forms of psychological distress. Moreover, ASCs initiated by breathwork are inherently dynamic, thus dynamic phenomenological tools, such as those employed by Lewis-Healey et al., [58] may be more sensitive and informative.&lt;/p&gt;
    &lt;p&gt;Our imaging approach was also limited by the absence of correction for physiological noise caused by cardiac and respiratory fluctuations. This is crucial for most physiological fMRI applications for reducing signal artifacts. However, physiological fluctuations (including respiratory frequency and volume changes) can still introduce signal variations in ASL data, but we believe that our approach remains robust. Our analysis inherently averages over multiple cardiac cycles, which helps mitigate the effects of physiological noise on CBF quantification, and although respiration-induced signal changes are observed in some pcASL studies, they are largely associated with motion rather than direct vascular effects [76]. This does not fully eliminate the influence of an overall increase in HR, respiratory rate, or other physiological parameters during changes in breathing conditions—factors that may also impact labelling efficiency and arterial transit times. These considerations are relevant not only to our study, but to other ASL studies where complex, interconnected factors can influence ASL signal and CBF. Practical constraints limit the extent to which additional physiological measurements can be incorporated, particularly in a study as complex as ours. These constraints include scanning time and the potential stress on participants. Furthermore, measuring CBF at the start of the SUSTAINED HVB rather than at the end or during is not ideal, yet, it may capture the physiological ‘trigger condition’ for entry into ASCs, which can continue irrespective of specific physiological threshold conditions, see [2] for more.&lt;/p&gt;
    &lt;p&gt;A further key reason for choosing not to adopt a method of correction for EtCO2 was a high risk of regressing out our primary signal of interest. One plausible mechanistic hypothesis inspiring our work is that ASCs evoked by HVB practices directly result from alterations in EtCO2 and the resulting cerebral pH, causing downstream effects on neuronal function [11]. Therefore, CO2 related physiological signals are likely correlated with experimental effects that were the focus of our investigation, in line with recent work by others [2] and regressing out these signals would severely impact our sensitivity to study the relationship between haemodynamic effects and ASCs. An additional reason is that our measures of EtCO2 (collected by nasal cannula and capnograph) have been occasionally incomplete during the end of HVB sessions when EtCO2 levels had reached particularly low levels, and we felt that application of correction methods using incomplete physiological data would have risked introducing major artifacts.&lt;/p&gt;
    &lt;p&gt;Additionally, we observed prominent arterial transit time (ATT) artifacts in 6 out of 19 participants. These artifacts were characterized by strong arterial signals in the CBF images, which led to their exclusion from the analysis. ATT artifacts can significantly impact the accuracy of perfusion measurements, as they indicate that labelled blood has not yet reached the capillary beds. To address this issue in future research, capturing blood flow dynamics at different delay times through a multi-PLD ASL protocol would reduce the impact of ATT artifacts and increase precision of assessment of cerebral perfusion.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;In conclusion, our exploratory experiments suggest that circuitries supporting the integration of interoceptive representations and processing of affective memories are putative neurobiological substrates of HVB-induced ASCs. Our findings indicate directions for future research towards a better understanding of HVB and ultimately harnessing such practices for future therapeutic applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supporting information&lt;/head&gt;
    &lt;head rend="h3"&gt;S1 Table. Coordinates of significant clusters observed when correlating the intensity of subjective experience (OBN) with ΔCBF during contrasts: BASELINE versus SUSTAINED and START versus SUSTAINED.&lt;/head&gt;
    &lt;p&gt;https://doi.org/10.1371/journal.pone.0329411.s002&lt;/p&gt;
    &lt;p&gt;(DOCX)&lt;/p&gt;
    &lt;head rend="h3"&gt;S2 Table. Coordinates of significant clusters observed when correlating the intensity of subjective experience (Experience of Unity, a component of OBN/5D-ASC) with ΔCBF during BASELINE to SUSTAINED.&lt;/head&gt;
    &lt;p&gt;https://doi.org/10.1371/journal.pone.0329411.s003&lt;/p&gt;
    &lt;p&gt;(DOCX)&lt;/p&gt;
    &lt;head rend="h3"&gt;S3 Table. Coordinates of significant clusters observed when correlating the intensity of subjective experience (Blissful State, a component of OBN/5D-ASC) with CBF during BASELINE to SUSTAINED.&lt;/head&gt;
    &lt;p&gt;https://doi.org/10.1371/journal.pone.0329411.s004&lt;/p&gt;
    &lt;p&gt;(DOCX)&lt;/p&gt;
    &lt;head rend="h3"&gt;S1 Fig. Graph of key subjective effects for repeated participants.&lt;/head&gt;
    &lt;p&gt;https://doi.org/10.1371/journal.pone.0329411.s005&lt;/p&gt;
    &lt;p&gt;(DOCX)&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;The authors wish to acknowledge Dr Guy Fincham, Dr Matthew Wall, and Dr Natalie Ertl for their helpful contribution, and all the participants for their expert insights into breathwork.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;1. Bahi C, Irrmischer M, Franken K, Fejer G, Schlenker A, Deijen JB, et al. Effects of conscious connected breathing on cortical brain activity, mood and state of consciousness in healthy adults. Curr Psychol. 2023;43(12):10578–89.&lt;/item&gt;
      &lt;item&gt;2. Havenith MN, Leidenberger M, Brasanac J, Corvacho M, Carmo Figueiredo I, Schwarz L, et al. Decreased CO2 saturation during circular breathwork supports emergence of altered states of consciousness. Commun Psychol. 2025;3(1):59. pmid:40223145&lt;/item&gt;
      &lt;item&gt;3. Eyerman J. A clinical report of Holotropic Breathwork in 11,000 psychiatric inpatients in a community hospital setting. Multidiscip Assoc Psychedelic Stud Bulletin Special Ed. 2013;23(1):24–7.&lt;/item&gt;
      &lt;item&gt;4. Carhart-Harris R, Giribaldi B, Watts R, Baker-Jones M, Murphy-Beiner A, Murphy R. Trial of psilocybin versus escitalopram for depression. New England J Med. 2021;384(15):1402–11.&lt;/item&gt;
      &lt;item&gt;5. Zeifman RJ, Palhano-Fontes F, Hallak J, Arcoverde E, Maia-Oliveira JP, Araujo DB. The impact of ayahuasca on suicidality: results from a randomized controlled trial. Front Pharmacol. 2019;10.&lt;/item&gt;
      &lt;item&gt;6. Meinhardt MW, Pfarr S, Fouquet G, Rohleder C, Meinhardt ML, Barroso-Flores J, et al. Psilocybin targets a common molecular mechanism for cognitive impairment and increased craving in alcoholism. Sci Adv. 2021;7(47):eabh2399. pmid:34788104&lt;/item&gt;
      &lt;item&gt;7. Almahayni O, Hammond L. Does the Wim Hof Method have a beneficial impact on physiological and psychological outcomes in healthy and non-healthy participants? A systematic review. PLoS One. 2024;19(3):e0286933. pmid:38478473&lt;/item&gt;
      &lt;item&gt;8. Yaden DB, Griffiths RR. The subjective effects of psychedelics are necessary for their enduring therapeutic effects. ACS Pharmacol Transl Sci. 2020;4(2):568–72. pmid:33861219&lt;/item&gt;
      &lt;item&gt;9. Roseman L, Nutt DJ, Carhart-Harris RL. Quality of acute psychedelic experience predicts therapeutic efficacy of psilocybin for treatment-resistant depression. Front Pharmacol. 2018;8:974. pmid:29387009&lt;/item&gt;
      &lt;item&gt;10. Ko K, Knight G, Rucker JJ, Cleare AJ. Psychedelics, mystical experience, and therapeutic efficacy: a systematic review. Front Psych. 2022;13.&lt;/item&gt;
      &lt;item&gt;11. Fincham GW, Kartar A, Uthaug MV, Anderson B, Hall L, Nagai Y, et al. High ventilation breathwork practices: an overview of their effects, mechanisms, and considerations for clinical applications. Neurosci Biobehav Rev. 2023;155:105453. pmid:37923236&lt;/item&gt;
      &lt;item&gt;12. Fincham GW, Epel E, Colasanti A, Strauss C, Cavanagh K. Effects of brief remote high ventilation breathwork with retention on mental health and wellbeing: a randomised placebo-controlled trial. 2024. &lt;/item&gt;
      &lt;item&gt;13. Franco Corso SJ, O’Malley KY, Subaiya S, Mayall D, Dakwar E. The role of non-ordinary states of consciousness occasioned by mind-body practices in mental health illness. J Affect Disord. 2023;335:166–76. pmid:37150220&lt;/item&gt;
      &lt;item&gt;14. Bayley PJ, Schulz-Heik RJ, Tang JS, Mathersul DC, Avery T, Wong M. Randomised clinical non-inferiority trial of breathing-based meditation and cognitive processing therapy for symptoms of post-traumatic stress disorder in military veterans. BMJ Open. 2022;12(8).&lt;/item&gt;
      &lt;item&gt;15. Dittrich A. The standardized psychometric assessment of altered states of consciousness (ASCs) in humans. Pharmacopsychiatry. 1998;31 Suppl 2:80–4. pmid:9754838&lt;/item&gt;
      &lt;item&gt;16. Freud S. Civilization and its discontents. Dover ed. New York: Dover Publications; 1994. &lt;/item&gt;
      &lt;item&gt;17. Studerus E, Gamma A, Vollenweider FX. Psychometric evaluation of the altered states of consciousness rating scale (OAV). PLoS One. 2010;5(8):e12412. pmid:20824211&lt;/item&gt;
      &lt;item&gt;18. Olbrich S, Preller KH, Vollenweider FX. LSD and ketanserin and their impact on the human autonomic nervous system. Psychophysiology. 2021;58(6):e13822. pmid:33772794&lt;/item&gt;
      &lt;item&gt;19. Rosas FE, Mediano PAM, Timmermann C, Luppi AI, Candia-Rivera D, Abbasi-Asl R. The entropic heart: tracking the psychedelic state via heart rate dynamics. 2023. &lt;/item&gt;
      &lt;item&gt;20. American Psychiatric A. Diagnostic and statistical manual of mental disorders. 2013. &lt;/item&gt;
      &lt;item&gt;21. Qualtrics. Qualtrics. https://www.qualtrics.com. &lt;/item&gt;
      &lt;item&gt;22. Watson D, Clark LA. The PANAS-X: Manual for the Positive and Negative Affect Schedule - Expanded Form. 1994; Available from: https://iro.uiowa.edu/esploro/outputs/other/The-PANAS-X-Manual-for-the-Positive/9983557488402771#file-0. &lt;/item&gt;
      &lt;item&gt;23. Schruers K, Klaassen T, Pols H, Overbeek T, Deutz NE, Griez E. Effects of tryptophan depletion on carbon dioxide provoked panic in panic disorder patients. Psychiatry Res. 2000;93(3):179–87. pmid:10760376&lt;/item&gt;
      &lt;item&gt;24. Griez EJ, Colasanti A, van Diest R, Salamon E, Schruers K. Carbon dioxide inhalation induces dose-dependent and age-related negative affectivity. PLoS ONE. 2007;2(10).&lt;/item&gt;
      &lt;item&gt;25. Watson D, Clark LA, Tellegen A. Development and validation of brief measures of positive and negative affect: the PANAS scales. J Pers Soc Psychol. 1988;54(6):1063–70. pmid:3397865&lt;/item&gt;
      &lt;item&gt;26. Alsop DC, Detre JA, Golay X, Günther M, Hendrikse J, Hernandez‐Garcia L, et al. Recommended implementation of arterial spin‐labeled perfusion MRI for clinical applications: a consensus of the ISMRM perfusion study group and the European consortium for ASL in dementia. Magnetic Resonan Med. 2014;73(1):102–16.&lt;/item&gt;
      &lt;item&gt;27. Friston K, Ashburner J, Kiebel S, Nichols T, Penny W. Statistical parametric mapping. 2007. &lt;/item&gt;
      &lt;item&gt;28. Parak J, Tarniceriu A, Renevey P, Bertschi M, Delgado-Gonzalo R, Korhonen I. Evaluation of the beat-to-beat detection accuracy of PulseOn wearable optical heart rate monitor. Annu Int Conf IEEE Eng Med Biol Soc. 2015;2015:8099–102. pmid:26738173&lt;/item&gt;
      &lt;item&gt;29. Shaffer F, Ginsberg JP. An overview of heart rate variability metrics and norms. Front Public Health. 2017;5.&lt;/item&gt;
      &lt;item&gt;30. Carhart-Harris RL, Williams TM, Sessa B, Tyacke RJ, Rich AS, Feilding A, et al. The administration of psilocybin to healthy, hallucinogen-experienced volunteers in a mock-functional magnetic resonance imaging environment: a preliminary investigation of tolerability. J Psychopharmacol. 2011;25(11):1562–7. pmid:20395317&lt;/item&gt;
      &lt;item&gt;31. Bates D, Mächler M, Bolker B, Walker S. Fitting linear mixed-effects models using lme4. Journal of Statistical Software. 2015;67(1):1–48.&lt;/item&gt;
      &lt;item&gt;32. Lenth R. Estimated marginal means, aka least-squares means. 2025. &lt;/item&gt;
      &lt;item&gt;33. Tarvainen MP, Niskanen J-P, Lipponen JA, Ranta-Aho PO, Karjalainen PA. Kubios HRV--heart rate variability analysis software. Comput Methods Programs Biomed. 2014;113(1):210–20. pmid:24054542&lt;/item&gt;
      &lt;item&gt;34. Studerus E. Tolerability, assessment, and prediction of psilocybin-induced altered states of consciousness. University of Zurich; 2012. &lt;/item&gt;
      &lt;item&gt;35. Mattson MP. Hormesis defined. Ageing Res Rev. 2008;7(1):1–7. pmid:18162444&lt;/item&gt;
      &lt;item&gt;36. Pruimboom L, Muskiet FAJ. Intermittent living; the use of ancient challenges as a vaccine against the deleterious effects of modern life - a hypothesis. Med Hypotheses. 2018;120:28–42. pmid:30220336&lt;/item&gt;
      &lt;item&gt;37. Hartogsohn I. Set and setting, psychedelics and the placebo response: an extra-pharmacological perspective on psychopharmacology. J Psychopharmacol. 2016;30(12):1259–67. pmid:27852960&lt;/item&gt;
      &lt;item&gt;38. Roseman L, Nutt DJ, Carhart-Harris RL. Quality of acute psychedelic experience predicts therapeutic efficacy of psilocybin for treatment-resistant depression. Front Pharmacol. 2018;8.&lt;/item&gt;
      &lt;item&gt;39. Timmermann C, Zeifman RJ, Erritzoe D, Nutt DJ, Carhart-Harris RL. Effects of DMT on mental health outcomes in healthy volunteers. Sci Rep. 2024;14(1):3097. pmid:38326357&lt;/item&gt;
      &lt;item&gt;40. Uthaug MV, Lancelotta R, van Oorsouw K, Kuypers KPC, Mason N, Rak J. A single inhalation of vapor from dried toad secretion containing 5-methoxy-N,N-dimethyltryptamine (5-MeO-DMT) in a naturalistic setting is related to sustained enhancement of satisfaction with life, mindfulness-related capacities, and a decrement of psychopathological symptoms. Psychopharmacology. 2019;236(9):2653–66.&lt;/item&gt;
      &lt;item&gt;41. Smigielski L, Scheidegger M, Kometer M, Vollenweider FX. Psilocybin-assisted mindfulness training modulates self-consciousness and brain default mode network connectivity with lasting effects. Neuroimage. 2019;196:207–15. pmid:30965131&lt;/item&gt;
      &lt;item&gt;42. Holze F, Ley L, Müller F, Becker AM, Straumann I, Vizeli P, et al. Direct comparison of the acute effects of lysergic acid diethylamide and psilocybin in a double-blind placebo-controlled study in healthy subjects. Neuropsychopharmacology. 2022;47(6):1180–7. pmid:35217796&lt;/item&gt;
      &lt;item&gt;43. Raichle ME, Plum F. Hyperventilation and cerebral blood flow. Stroke. 1972;3(5):566–75.&lt;/item&gt;
      &lt;item&gt;44. Tennant R, Hiller L, Fishwick R, Platt S, Joseph S, Weich S, et al. The Warwick-Edinburgh Mental Well-being Scale (WEMWBS): development and UK validation. Health Qual Life Outcomes. 2007;5:63. pmid:18042300&lt;/item&gt;
      &lt;item&gt;45. Kartar AA, Colasanti A. Respiratory control and circuitry. In: Reference module in neuroscience and biobehavioral psychology. Elsevier; 2024. &lt;/item&gt;
      &lt;item&gt;46. Betka S, Adler D, Similowski T, Blanke O. Breathing control, brain, and bodily self-consciousness: toward immersive digiceuticals to alleviate respiratory suffering. Biol Psychol. 2022;171:108329. pmid:35452780&lt;/item&gt;
      &lt;item&gt;47. Sirigu A, Desmurget M. Somatosensory awareness in the parietal operculum. Brain. 2021;144(12):3558–60. pmid:34791060&lt;/item&gt;
      &lt;item&gt;48. Felleman DJ, Van Essen DC. Distributed hierarchical processing in the primate cerebral cortex. Cereb Cortex. 1991;1(1):1–47. pmid:1822724&lt;/item&gt;
      &lt;item&gt;49. Sepulcre J, Sabuncu MR, Yeo TB, Liu H, Johnson KA. Stepwise connectivity of the modal cortex reveals the multimodal organization of the human brain. J Neurosci. 2012;32(31):10649–61. pmid:22855814&lt;/item&gt;
      &lt;item&gt;50. Gentile G, Guterstam A, Brozzoli C, Ehrsson HH. Disintegration of multisensory signals from the real hand reduces default limb self-attribution: an fMRI study. J Neurosci. 2013;33(33):13350–66. pmid:23946393&lt;/item&gt;
      &lt;item&gt;51. Picard F. Ecstatic or mystical experience through epilepsy. J Cogn Neurosci. 2023;35(9):1372–81. pmid:37432752&lt;/item&gt;
      &lt;item&gt;52. Picard F, Craig AD. Ecstatic epileptic seizures: a potential window on the neural basis for human self-awareness. Epilepsy Behav. 2009;16(3):539–46. pmid:19836310&lt;/item&gt;
      &lt;item&gt;53. Craig ADB. How do you feel--now? The anterior insula and human awareness. Nat Rev Neurosci. 2009;10(1):59–70. pmid:19096369&lt;/item&gt;
      &lt;item&gt;54. Picard F, Scavarda D, Bartolomei F. Induction of a sense of bliss by electrical stimulation of the anterior insula. Cortex. 2013;49(10):2935–7. pmid:24074887&lt;/item&gt;
      &lt;item&gt;55. Sheikh MM, Koubeissi MZ, Spencer DD, Alkawadri R. The neural networks underlying the illusion of time dilation. Ann Neurol. 2022;91(2):295–7.&lt;/item&gt;
      &lt;item&gt;56. Carhart-Harris RL, Erritzoe D, Williams T, Stone JM, Reed LJ, Colasanti A, et al. Neural correlates of the psychedelic state as determined by fMRI studies with psilocybin. Proc Natl Acad Sci U S A. 2012;109(6):2138–43. pmid:22308440&lt;/item&gt;
      &lt;item&gt;57. Lewis CR, Preller KH, Kraehenmann R, Michels L, Staempfli P, Vollenweider FX. Two dose investigation of the 5-HT-agonist psilocybin on relative and global cerebral blood flow. Neuroimage. 2017;159:70–8. pmid:28711736&lt;/item&gt;
      &lt;item&gt;58. Lewis-Healey E, Tagliazucchi E, Canales-Johnson A, Bekinschtein TA. Breathwork-induced psychedelic experiences modulate neural dynamics. Cerebral Cortex. 2024;34(8).&lt;/item&gt;
      &lt;item&gt;59. Phelps EA. Human emotion and memory: interactions of the amygdala and hippocampal complex. Curr Opin Neurobiol. 2004;14(2):198–202. pmid:15082325&lt;/item&gt;
      &lt;item&gt;60. Roseman L, Demetriou L, Wall MB, Nutt DJ, Carhart-Harris RL. Increased amygdala responses to emotional faces after psilocybin for treatment-resistant depression. Neuropharmacology. 2018;142:263–9.&lt;/item&gt;
      &lt;item&gt;61. Nutt D, Erritzoe D, Carhart-Harris R. Psychedelic psychiatry’s brave new world. Cell. 2020;181(1):24–8. pmid:32243793&lt;/item&gt;
      &lt;item&gt;62. Healy CJ. The acute effects of classic psychedelics on memory in humans. Psychopharmacology (Berl). 2021;238(3):639–53. pmid:33420592&lt;/item&gt;
      &lt;item&gt;63. Seppälä EM, Nitschke JB, Tudorascu DL, Hayes A, Goldstein MR, Nguyen DTH, et al. Breathing-based meditation decreases posttraumatic stress disorder symptoms in U.S. military veterans: a randomized controlled longitudinal study. J Trauma Stress. 2014;27(4):397–405. pmid:25158633&lt;/item&gt;
      &lt;item&gt;64. Steventon JJ, Foster C, Furby H, Helme D, Wise RG, Murphy K. Hippocampal blood flow is increased after 20 min of moderate-intensity exercise. Cerebral Cortex. 2019;30(2):525–33.&lt;/item&gt;
      &lt;item&gt;65. Kety SS, Schmidt CF. Measurement of cerebral blood flow and cerebral oxygen consumption in man. Fed Proc. 1946;5:264. pmid:21064908&lt;/item&gt;
      &lt;item&gt;66. Fincham GW, Kartar A, Uthaug MV, Anderson B, Hall L, Nagai Y, et al. High ventilation breathwork practices: an overview of their effects, mechanisms, and considerations for clinical applications. Neurosci Biobehav Rev. 2023;155:105453. pmid:37923236&lt;/item&gt;
      &lt;item&gt;67. Schüttler D, von Stülpnagel L, Rizas KD, Bauer A, Brunner S, Hamm W. Effect of hyperventilation on periodic repolarization dynamics. Front Physiol. 2020;11.&lt;/item&gt;
      &lt;item&gt;68. Oswald V, Vanhaudenhuyse A, Annen J, Martial C, Bicego A, Rousseaux F. Autonomic nervous system modulation during self-induced non-ordinary states of consciousness. Scient Rep. 2023;13(1).&lt;/item&gt;
      &lt;item&gt;69. dos Santos RG, Valle M, Bouso JC, Nomdedéu JF, Rodríguez-Espinosa J, McIlhenny EH. Autonomic, neuroendocrine, and immunological effects of Ayahuasca. J Clin Psychopharmacol. 2011;31(6):717–26.&lt;/item&gt;
      &lt;item&gt;70. Liechti ME, Dolder PC, Schmid Y. Alterations of consciousness and mystical-type experiences after acute LSD in humans. Psychopharmacol (Berl). 2017;234(9–10):1499–510. pmid:27714429&lt;/item&gt;
      &lt;item&gt;71. Sparber SB, Dwoskin LP, Kleven MS. Studies on the specificity of neurochemical and behavioral effects of LSD-25. Pharmacol Biochem Behav. 1986;24(2):341–5.&lt;/item&gt;
      &lt;item&gt;72. Bonnelle V, Feilding A, Rosas FE, Nutt DJ, Carhart-Harris RL, Timmermann C. Autonomic nervous system activity correlates with peak experiences induced by DMT and predicts increases in wellbeing. bioRxiv. 2024.&lt;/item&gt;
      &lt;item&gt;73. Strassman RJ. Human psychopharmacology of N,N-dimethyltryptamine. Behav Brain Res. 1996;73(1–2):121–4. pmid:8788488&lt;/item&gt;
      &lt;item&gt;74. Crosswell AD, Mayer SE, Whitehurst LN, Picard M, Zebarjadian S, Epel ES. Deep rest: an integrative model of how contemplative practices combat stress and enhance the body’s restorative capacity. Psychol Rev. 2024;131(1):247–70. pmid:38147050&lt;/item&gt;
      &lt;item&gt;75. Canello T, Tlaie A, Chalise K, Schölvinck ML, Pia L, Havenith MN. Non-ordinary states of consciousness evoked by breathwork correlate with improved heart-rate variability. 2024. &lt;/item&gt;
      &lt;item&gt;76. Wu W-C, Edlow BL, Elliot MA, Wang J, Detre JA. Physiological modulations in arterial spin labeling perfusion magnetic resonance imaging. IEEE Trans Med Imaging. 2009;28(5):703–9. pmid:19150788&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0329411"/></entry><entry><id>https://news.ycombinator.com/item?id=45047460</id><title>Open Source is one person</title><updated>2025-08-28T16:12:37.668307+00:00</updated><content>&lt;doc fingerprint="c75b107dde3c9131"&gt;
  &lt;main&gt;
    &lt;p&gt;The Register recently published a story titled Putin on the code: DoD reportedly relies on utility written by Russian dev. They should be ashamed of this story. This poor open source developer is getting beat up now to score some internet points. It’s very upsetting.&lt;/p&gt;
    &lt;p&gt;But anyway, let’s look at some receipts.&lt;/p&gt;
    &lt;p&gt;If you’re not real smrt, it seems like pointing out an open source project is written by one person in a country you don’t like is a bad thing. It could be. But it also could be the software running THE WHOLE F*CKING PLANET is written by one person. In a country. But we have no idea which country. It’s not the same person mind you, but it’s one person.&lt;/p&gt;
    &lt;p&gt;Here’s the thing. Almost all open source is literally one person. What I mean by that is if you look at all the open source projects out there, and there are a lot, we see a pattern of one person no matter how we slice and dice the data.&lt;/p&gt;
    &lt;p&gt;So let’s start with the data. A project exists called ecosyste.ms that catalogs a lot of open source. Most of it I would guess, but not all. They currently have 11.8 million open source projects in their data. You would be right to think that is a big number. I’m told anything over 15 is a big number, but it probably depends how smart you are, or think you are.&lt;/p&gt;
    &lt;p&gt;So what do we mean by one person is open source. What I mean is if we look at all the projects that ecosyste.ms is tracking, how many have a single person maintaining that project? It’s about 7 million. This is also a big number. 7 million open source projects are one person. It’s actually bigger than that, because of the 11.8 million projects ecosyste.ms is tracking, we don’t know how many maintainers 4 million of the projects have. A bunch of those will be one person. Here’s what a graph of this looks like&lt;/p&gt;
    &lt;p&gt;I clipped the graph so it looks nicer. There are projects with hundreds of maintainers. Not a ton, but they exist.&lt;/p&gt;
    &lt;p&gt;Now, the clever people among us are thinking “but Josh, surely these 7 million projects are all things nobody uses, the important open source we all use has loads of maintainers!!!”&lt;/p&gt;
    &lt;p&gt;You would be right to think that. It’s the first thought I had back when I started to look at this data. It’s OK. You’re still in the denial stage. Hopefully you’ll reach anger by the end of this post.&lt;/p&gt;
    &lt;p&gt;So we’re going to use the NPM ecosystem to explain this. I use NPM because they have the richest data in ecosyste.ms to explain my point. I’ve done this same thing across multiple ecosystems and the graphs all look the same.&lt;/p&gt;
    &lt;p&gt;So, what does the NPM maintainer graph look like. Your first thought is probably “why is the left axis green?” It’s not an axis, it’s the single maintainer number. It’s that huge compared to literally all the other data. There are just that many single person NPM projects.&lt;/p&gt;
    &lt;p&gt;So now, let’s look at the number of maintainers for projects with over 1 million downloads this month.&lt;/p&gt;
    &lt;p&gt;This time the graph shows how many downloads projects with over 1 million downloads, and one maintainer or more than one maintainer. It was easier to show the data by creating these two buckets.&lt;/p&gt;
    &lt;p&gt;That’s almost a 50/50 split. Think about that. About half of the 13,000 most downloaded NPM packages are ONE PERSON. We can change the download number and the graph stays this shape. It’s not until I change downloads to 1 billion downloads that we see 1 package maintained by 1 person, and 9 packages maintained by more than 1.&lt;/p&gt;
    &lt;p&gt;This is open source. Open source is one person, even the popular stuff.&lt;/p&gt;
    &lt;p&gt;I will also add, a lot of people own more than one package. So while NPM has over 4 million single person projects, they have about 900,000 maintainers for those 4 million single person projects. This will be an important data point at the end.&lt;/p&gt;
    &lt;p&gt;So here’s the big conclusion. If you want to make a big deal about something, maybe it shouldn’t be what country a sole maintainer is from. Let’s face it, the Russians aren’t dumb enough to backdoor a package owned by a guy living in Russia. They’re going to do something like pretend to be from another country with a name like Jia Tan, not Boris D. Badguy. This isn’t a Rocky and Bullwinkle episode.&lt;/p&gt;
    &lt;p&gt;Anyway, back to the conclusion&lt;/p&gt;
    &lt;p&gt;Open source, the thing that drives the world, the thing Harvard says has an economic value of 8.8 trillion dollars (also a big number). Most of it is one person. And I can promise you not one of those single person projects have the proper amount of resources they need. If you want to talk about possible risks to your supply chain, a single maintainer that’s grossly underpaid and overworked. That’s the risk. The country they are from is irrelevant.&lt;/p&gt;
    &lt;p&gt;And now if we have news stories being written about how a single person maintainer is the bad guy? That’s not cool (this is where your denial is supposed to turn into anger).&lt;/p&gt;
    &lt;p&gt;So what can you do about this? How can you turn your newly denial-turned-anger into action? We don’t really know unfortunately. I discussed this in a podcast episode Hobbyist Maintainers with Thomas DePierre. Like many hard problems, there isn’t an easy solution. But I guarantee the solution isn’t hunting down and demonizing single maintainers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://opensourcesecurity.io/2025/08-oss-one-person/"/></entry><entry><id>https://news.ycombinator.com/item?id=45047572</id><title>Bookmarks.txt is a concept of keeping URLs in plain text files</title><updated>2025-08-28T16:12:36.958445+00:00</updated><content>&lt;doc fingerprint="9d8698724de1ca68"&gt;
  &lt;main&gt;
    &lt;p&gt;bookmarks.txt is a concept of keeping bookmarks in plain text files.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bookmarked URLs are stored in files named &lt;code&gt;bookmarks.txt&lt;/code&gt;. The format is described below.&lt;/item&gt;
      &lt;item&gt;A "global" bookmarks file is located in the home directory (&lt;code&gt;$HOME/bookmarks.txt&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;"Local" bookmarks files could exist in different directories as well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;URLs are stored one per line and could be accompanied with optional titles. Titles are separated from URLs with one space character.&lt;/p&gt;
    &lt;code&gt;URL [title]
&lt;/code&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;a URL without any title&lt;/p&gt;
        &lt;code&gt;https://www.example.com ----------------------- ^ URL&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;a URL with a title&lt;/p&gt;
        &lt;code&gt;https://sul.im personal website -------------- ---------------- ^ ^ URL Optional title&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The plain text nature of bookmark files allows to use any program to manage URLs. The &lt;code&gt;bin/&lt;/code&gt; directory of this repository contains &lt;code&gt;bookmarks&lt;/code&gt; script that could be used to list existing and add new URLs. However nothing should stop you from building your own tools.&lt;/p&gt;
    &lt;p&gt;Use fzf to select a URL and open it in the default browser:&lt;/p&gt;
    &lt;code&gt;./bin/bookmarks | fzf | cut -d ' ' -f 1 | xargs open&lt;/code&gt;
    &lt;p&gt;Add a new URL:&lt;/p&gt;
    &lt;code&gt;./bin/bookmarks https://github.com/soulim/bookmarks.txt&lt;/code&gt;
    &lt;p&gt;This is how I use bookmarks.txt:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;$HOME/bookmarks.txt&lt;/code&gt;contains URLs useful in any context. These are "global" addresses.&lt;/item&gt;
      &lt;item&gt;Each project directory has "local" &lt;code&gt;bookmarks.txt&lt;/code&gt;files with URLs pointing to tools specific to each project (repositories, monitoring tools, dashboards, and so on).&lt;/item&gt;
      &lt;item&gt;A symbolic link &lt;code&gt;$HOME/bin/bookmarks&lt;/code&gt;point to&lt;code&gt;bin/bookmarks&lt;/code&gt;from this directory.&lt;/item&gt;
      &lt;item&gt;With help of fzf I have a nice menu with fuzzy search to select URLs and open them automatically.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;bookmarks.txt is open to code contributions for bug fixes only. As features might carry a long-term maintenance burden, they will not be accepted at this time. Please submit an issue if you have a feature you would like to request.&lt;/p&gt;
    &lt;p&gt;See LICENSE for license text.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/soulim/bookmarks.txt"/></entry><entry><id>https://news.ycombinator.com/item?id=45047897</id><title>Certificates for Onion Services</title><updated>2025-08-28T16:12:36.131432+00:00</updated><content>&lt;doc fingerprint="4f7da5790839b582"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Certificates for Onion Services¶&lt;/head&gt;
    &lt;head rend="h2"&gt;About¶&lt;/head&gt;
    &lt;p&gt;This document tracks existing procedures or proposals for integrating and validating TLS/HTTPS certificates for Onion Services.&lt;/p&gt;
    &lt;p&gt;While some depends on Certificate Authorities (CA) model, others rely on alternative certification and validation procedures that does not require built-in certificate chains in the client software or reliance on financial transactions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction¶&lt;/head&gt;
    &lt;p&gt;Whenever you browse the internet regularly, the connection between your computer and a service is usually encrypted, and the safety of this communication happens through the verification of a special type of certificate.&lt;/p&gt;
    &lt;p&gt;With Onion Services, the connection is peer-to-peer encrypted by default, which means that no additional certificates are needed.&lt;/p&gt;
    &lt;p&gt;But as the web and other internet technologies mature, certificates are starting to be a requirement in order to unleash functionalities, especially in web browsers, such as the faster connection protocol HTTP/2 and payment processing.&lt;/p&gt;
    &lt;p&gt;That's why it's important to improve the certificate ecosystem to fully support Onion Services.&lt;/p&gt;
    &lt;p&gt;This is a hard problem, and an ongoing effort, but there has been some important work done to solve this.&lt;/p&gt;
    &lt;p&gt;The most relevant one should bring automation to the process of issuing certificates for Onion Services, through an enhancement in a protocol called ACME.&lt;/p&gt;
    &lt;p&gt;The ACME for Onions proposal is composed of tools and also an Internet Draft, which hopefully will turn into an Internet Standard soon.&lt;/p&gt;
    &lt;p&gt;We are also looking into other, non-conflicting alternatives that can also be used for certification, so service operators can decide which one fits best their use case.&lt;/p&gt;
    &lt;p&gt;Improving the certificate functionality will put Onion Services in parity with the modern stack of web development.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benefits¶&lt;/head&gt;
    &lt;p&gt;It may be argued that Onion Services connections are already self-authenticated -- since the public key and the URL are tied together and the connection is peer-to-peer encrypted --, and thus making the need for HTTPS pointless, or at most giving only an impression on users of additional security.&lt;/p&gt;
    &lt;p&gt;But having valid HTTPS connection in Onion Services could enable many other enhancements, such as:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Some browser features are available only with HTTPS, like Secure Contexts, Content Security Policy (CSP), Secure cookies, WebAuthn, WebRTC and PaymentRequest.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A user may be using a browser that isn't the Tor browser. For example on iOS there is only Safari, and in such cases the browser will not be aware of the different semantics of security for an onion site, and won't allow the use of secure browser features (such as secure cookies). This limits the kind of web apps people can develop on onionsites as many modern browser APIs mentioned above.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Allows for the usage of HTTP/2, since some browsers only support it if on HTTPS1. In the future, HTTP2 and HTTP3 may only work with TLS, and thus valid certificates.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It also opens up new opportunities such as payment processing, "as current PCI DSS requirements do not allow non-standard TLS"2 and may only work with certificates having some sort of validation3. Payments card networks require HTTPS for a payment to be taken. So if someone wants to do that over an onion site they would need a TLS certificate.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It could be argued that this is also security-in-depth by having yet another layer of encryption atop of other existing encryption layers. Even if the theoretical gain in terms of interception and tampering resistance is not relevant, it would still allow for service operators to split their encryption keys in different servers -- like one with the Onion Service keys and a backend having the TLS keys, thus making a compromise in one of the servers exposing only the cryptographic material of one of the communication layers.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Tor daemon that hosts the onion site might not be the final computer in the chain. In larger organizations, deployment concerns may result in plain HTTP traveling across their network from the Tor daemon to the final web server. Having HTTPs protects those hops in the chain. This is something that distributed setups may need. The same could be said for a web browser using Tor SOCKS proxy somewhere else on the network.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-web based applications, such as IMAP/POP/SMTP etc. can benefit from certificates being valid.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There is simply too much software that isn't aware of onionsites, and trying to force HTTP-over-Onion to be as secure as HTTPS-over-TCP creates a compatibility mess of things which do and don't know about the semantics.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There is value in exposing the existence of an onion site via CT Logs. If someone navigates to the plain web version of a site, and is presented with a certificate containing a Subject Alternative Name (SAN) for both the plain web and the onion site that provides a strong cryptographic guarantee that they are the same site. Effectively this would replace the Onion-Location header with something more authenticated4.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following discussion is not yet conclusive, and the problem space may be hard to solve.&lt;/p&gt;
    &lt;head rend="h2"&gt;Overview¶&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Proposal&lt;/cell&gt;
        &lt;cell role="head"&gt;Certification&lt;/cell&gt;
        &lt;cell role="head"&gt;Validation&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Existing CA validation&lt;/cell&gt;
        &lt;cell&gt;CA/B Baseline Requirements for .onion&lt;/cell&gt;
        &lt;cell&gt;CA chain&lt;/cell&gt;
        &lt;cell&gt;Implemented, fully supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ACME for .onion&lt;/cell&gt;
        &lt;cell&gt;CA/B Baseline Requirements for .onion&lt;/cell&gt;
        &lt;cell&gt;CA chain&lt;/cell&gt;
        &lt;cell&gt;Standardized as RFC 9799, need adoption by CAs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Self-signed certificates&lt;/cell&gt;
        &lt;cell&gt;Self-signed certificate&lt;/cell&gt;
        &lt;cell&gt;None&lt;/cell&gt;
        &lt;cell&gt;Depends on per-application support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Self-signed X.509 from .onion&lt;/cell&gt;
        &lt;cell&gt;Signed by a "CA" derived from the .onion private key&lt;/cell&gt;
        &lt;cell&gt;Check if cert is issued by the .onion private key&lt;/cell&gt;
        &lt;cell&gt;Proof-of-concept, no browser integration&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Same Origin Onion Certificates (SOOC)&lt;/cell&gt;
        &lt;cell&gt;Self-signed certs&lt;/cell&gt;
        &lt;cell&gt;Skip for .onion addresses when conditions match&lt;/cell&gt;
        &lt;cell&gt;Proposal (not yet submitted for specification)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DANE for .onion&lt;/cell&gt;
        &lt;cell&gt;Self-signed certs&lt;/cell&gt;
        &lt;cell&gt;DNSSEC&lt;/cell&gt;
        &lt;cell&gt;Concept, no proposal yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Onion-only CAs&lt;/cell&gt;
        &lt;cell&gt;Checks SAN and an .onion signature in an extension&lt;/cell&gt;
        &lt;cell&gt;CA chain&lt;/cell&gt;
        &lt;cell&gt;Concept, no proposal yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Self-auth certs via PKCS#11 module&lt;/cell&gt;
        &lt;cell&gt;Checks .onion Ed25519 signature in the cert key&lt;/cell&gt;
        &lt;cell&gt;Module returns a custom CA chain&lt;/cell&gt;
        &lt;cell&gt;Design, prototype available&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Main pros and cons¶&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Proposal&lt;/cell&gt;
        &lt;cell role="head"&gt;Pros&lt;/cell&gt;
        &lt;cell role="head"&gt;Cons&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Existing CA validation&lt;/cell&gt;
        &lt;cell&gt;None (already implemented)&lt;/cell&gt;
        &lt;cell&gt;None (already implemented)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ACME for .onion&lt;/cell&gt;
        &lt;cell&gt;No need for client/lib implementation&lt;/cell&gt;
        &lt;cell&gt;Depends on a CA willing to implement&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Self-signed X.509 for .onion&lt;/cell&gt;
        &lt;cell&gt;No CA-reliance for .onion, self-auth.&lt;/cell&gt;
        &lt;cell&gt;Very hard to maintain and standardize, currently Ed25519 is unsupported by major browsers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Same Origin Onion Certificates (SOOC)&lt;/cell&gt;
        &lt;cell&gt;No CA-reliance for .onion&lt;/cell&gt;
        &lt;cell&gt;Very hard to maintain and standardize&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DANE for .onion&lt;/cell&gt;
        &lt;cell&gt;No CA-reliance for any domain or .onion&lt;/cell&gt;
        &lt;cell&gt;Very hard to implement and maintain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Onion-only CAs&lt;/cell&gt;
        &lt;cell&gt;Simplify CA-reliance&lt;/cell&gt;
        &lt;cell&gt;Needs to convince existing CAs or trusted parties to maintain a whole CA organization and infrastructure&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Self-auth certs via PKCS#11 module&lt;/cell&gt;
        &lt;cell&gt;PKCS#11 is well established, future proof, no CA-reliance&lt;/cell&gt;
        &lt;cell&gt;Each Operating System or application would need to configure it; built-in OpenSSL support still underway&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Main implementation characteristics¶&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Proposal&lt;/cell&gt;
        &lt;cell role="head"&gt;Implementation level&lt;/cell&gt;
        &lt;cell role="head"&gt;Additional requirements&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Existing CA validation&lt;/cell&gt;
        &lt;cell&gt;Procedure happens at the CA side&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ACME for .onion&lt;/cell&gt;
        &lt;cell&gt;Procedure happens at the CA side&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Self-signed X.509 for .onion&lt;/cell&gt;
        &lt;cell&gt;Client or TLS library&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Same Origin Onion Certificates (SOOC)&lt;/cell&gt;
        &lt;cell&gt;Client or TLS library&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;DANE for .onion&lt;/cell&gt;
        &lt;cell&gt;Client&lt;/cell&gt;
        &lt;cell&gt;Portable DNSSEC library&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Onion-only CAs&lt;/cell&gt;
        &lt;cell&gt;Client or TLS (only needs CA installation)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Self-auth certs via PKCS#11 module&lt;/cell&gt;
        &lt;cell&gt;Library (PKCS#11 module)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Existing CA validation¶&lt;/head&gt;
    &lt;p&gt;The CA/Browser Forum, a consortium that produces guidelines for X.509 (TLS/HTTPS) certification, created validation rules for Onion Service v2 addresses (in 2015), later extended for Onion Services v3 (in 2020), standardizing the way Certificate Authorities can issue certificates for .onion addresses and supports wildcards5.&lt;/p&gt;
    &lt;p&gt;Only a few commercial providers currently provide this service6.&lt;/p&gt;
    &lt;p&gt;The Appendix B of the CA/B Baseline Requirements (current repository version) for the Issuance and Management of PubliclyâTrusted Certificates (since Version 1.7.4, released in 2021) establishes two validation methods to ensure that someone request the certificate really control a given .onion address:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;An "AgreedâUpon Change to Website" (manually or via ACME), where the service operator must include some secret, such as at the &lt;code&gt;/.well-known/pki-validation&lt;/code&gt;of the site.&lt;/item&gt;
      &lt;item&gt;TLS using ALPN.&lt;/item&gt;
      &lt;item&gt;Checking of a Certificate Signing Request (CSR) signed by the Onion Service private key and containing an specific cryptographic nonce (i.e, a shared secret to be used only once), like using the onion-csr tool.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that both methods does not require that operators disclose the location of the Onion Service, nor them need to have a regular site for the service using DNS. Validation can either happen by accessing directly the Onion Service or by using the service private key to sign a CSR.&lt;/p&gt;
    &lt;p&gt;But still commercial CAs (or financial institution) may still collect identifiable information during the purchase of the certificates.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACME for .onion (CA-validated)¶&lt;/head&gt;
    &lt;p&gt;In general, getting certificates from CAs supporting the CA/B Baseline Requirements for .onion addresses is still a manual, or in the best-case scenario, semi-automated task.&lt;/p&gt;
    &lt;p&gt;The Automatic Certificate Management Environment (ACME) standard (RFC 8555) solves part of the automation problem, and with the arrival of RFC 9799 it also supports methods for validating Onion Services.&lt;/p&gt;
    &lt;p&gt;Having support for .onion address in the ACME standard is the first step for projects like Let's Encrypt to offer free certificates for Onion Services, without financial transactions.&lt;/p&gt;
    &lt;p&gt;Existing proposals to bring ACME for Onion Services are discussed below.&lt;/p&gt;
    &lt;head rend="h3"&gt;ACME for Onions¶&lt;/head&gt;
    &lt;p&gt;The "Automated Certificate Management Environment (ACME) Extensions for ".onion" Domain Names" (draft-misell-acme-onion) is the second known proposal to bring ACME for .onion addresses.&lt;/p&gt;
    &lt;p&gt;This is the proposal that lead to RFC 9799.&lt;/p&gt;
    &lt;p&gt;A detailed analysis on ACME for Onions is available in a special appendix.&lt;/p&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;head rend="h3"&gt;ACME Onion Identifier Validation Extension¶&lt;/head&gt;
    &lt;p&gt;The "Automated Certificate Management Environment (ACME) Onion Identifier Validation Extension" internet draft (draft-suchan-acme-onion-00) was proposed on 2022-05 and is the first known proposal to bring ACME for .onion addresses.&lt;/p&gt;
    &lt;p&gt;As of 2023-06-07, this internet draft is in the expired state, being now supplanted by RFC 9799.&lt;/p&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Relevant mail threads&lt;/item&gt;
      &lt;item&gt;orangepizza/acme-onion-doc: docs about standardize handling onion address in acme context&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Self-signed certificates¶&lt;/head&gt;
    &lt;p&gt;This proposal basically consists in allowing the use of self-signed certificates with Onion Services:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;For web applications like the Tor Browser, this would consist in disabling self-signed certificate warnings when visiting .onion sites. As an alternative, there's also the Self-authenticating TLS Certificates for Onion Services using a PKCS#11 module discussed below and relying on PKCS#11 modules or Authority Information Access (AIA) extensions, which could handle self-signed certificates matching the Onion Service address without the need to merge this logic directly in the applications, as it would remain decoupled in a PKCS#11 module, thus being easier to maintain.&lt;/item&gt;
      &lt;item&gt;For other applications -- like the TorVPN and third-party software --, this would probably require patches or documentation instructing users to accept non-CA signed certificates when accessing Onion Services, which is very hard to provide and to maintain for a wide ranging of tools.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supported key types&lt;/p&gt;
    &lt;p&gt;In this proposal, any key types supported by applications could be used.&lt;/p&gt;
    &lt;p&gt;In case of popular web browsers, the CA/B Baseline Requirements must be taken into account, which as of 2024-09 only allows for RSA or ECDSA keys.&lt;/p&gt;
    &lt;p&gt;It could also be possible to use self-signed certs using Ed25519, which is discussed below and currently not widely supported by browsers.&lt;/p&gt;
    &lt;p&gt;This proposal would not provide:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A self-authentication mechanism (since the certificate is self-signed). This have a huge weight since an important piece of security provided by HTTPS is not just end-to-end encryption but also authentication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supporting self-signed certificates with Onion Services has a huge gain, but also introduces an authentication complexity. That's why proper UI indicators and hints are needed:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;For the encryption state of the site (HTTP and various HTTPS situations).&lt;/item&gt;
      &lt;item&gt;For the authentication state of the site, telling how it was (not) authenticated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are already sketches for different scenarios for how various user interface hints and indicators could exist for Tor Browser and other software maintained by Tor, as well as existing certificate proposals that can change the certificate landscape for Onion Services in the future, which could be adopted by operators instead of relying on self-signed certs.&lt;/p&gt;
    &lt;p&gt;But all these enhancements would still limit the practical application domain of this proposal, since it would be readily available only to a small set of applications like Tor Browser, except if by pursuing some standardization such as the SOOC proposal below.&lt;/p&gt;
    &lt;head rend="h2"&gt;Self-signed X.509 from .onion (self-signed by the .onion address)¶&lt;/head&gt;
    &lt;p&gt;Another option for having HTTPS in Onion Services that may be available in the future is to use Onion Service key pair to self-validate an HTTPS certificate using Ed25519 directly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Onion x509 is an example in how a CA self-signed by an .onion could be constructed.&lt;/item&gt;
      &lt;item&gt;There's also a ticket requesting to add support for self-signed HTTPS onion sites derived from onion service's ed25519 key in the Tor Browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For an overview of Ed25519, check How do Ed5519 keys work?. For details about how Tor implements Ed25519, check prop220 (and rend-spec-v3 for how it implements at the Onion Services level).&lt;/p&gt;
    &lt;p&gt;This proposal has the advantage to not rely on Certificate Authorities, but the disadvantage that needs additional logic both server and client side to make it work, since a CA would needed to be installed for every visited Onion Service using this scheme.&lt;/p&gt;
    &lt;head rend="h3"&gt;On using .onion keys for certification¶&lt;/head&gt;
    &lt;p&gt;It's important to note that the current (as of 2024-09) Onion Services v3 specification does not allow the Master Onion Service identity key to be used for purposes other than generating blinded signing keys (see Section 1.9 from the rend-spec-v3):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Master (hidden service) identity key -- A master signing key pair used as the identity for a hidden service. This key is long term and not used on its own to sign anything; it is only used to generate blinded signing keys as described in [KEYBLIND] and [SUBCRED]. The public key is encoded in the ".onion" address according to [NAMING]. KP_hs_id, KS_hs_id.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;On Ed25519 certificates support in browsers¶&lt;/head&gt;
    &lt;p&gt;Also, while many TLS libraries support the Ed25519 signing scheme used for certificates (like in OpenSSL since version 1.1.1), major web browsers still does not support it (as of 2022-12)7, probably because they're not supported8 by the current (as of 2024-09) CA/B Baseline Requirements:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;6.1.1.3 Subscriber Key Pair Generation&lt;/p&gt;
      &lt;p&gt;The CA SHALL reject a certificate request if one or more of the following conditions are met:&lt;/p&gt;
      &lt;item&gt;The Key Pair does not meet the requirements set forth in Section 6.1.5 and/or Section 6.1.6;&lt;/item&gt;
      &lt;p&gt;[...]&lt;/p&gt;
      &lt;p&gt;6.1.5 Key sizes&lt;/p&gt;
      &lt;p&gt;For RSA key pairs the CA SHALL:&lt;/p&gt;
      &lt;p&gt;â¢ Ensure that the modulus size, when encoded, is at least 2048 bits, and; â¢ Ensure that the modulus size, in bits, is evenly divisible by 8.&lt;/p&gt;
      &lt;p&gt;For ECDSA key pairs, the CA SHALL:&lt;/p&gt;
      &lt;p&gt;â¢ Ensure that the key represents a valid point on the NIST Pâ256, NIST Pâ384 or NIST Pâ521 elliptic curve.&lt;/p&gt;
      &lt;p&gt;No other algorithms or key sizes are permitted.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Implementing X.509 certs derived from the .onion key pair¶&lt;/head&gt;
    &lt;p&gt;In summary, implementing this proposal would require pushing at least two specification changes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A ballot with CA/B Forum about including Ed25519 support.&lt;/item&gt;
      &lt;item&gt;An update in the Onion Services v3 spec, allowing the Onion Service identity keys to either:&lt;list rend="ol"&gt;&lt;item&gt;Also act as Certificate Authority root keys for the service.&lt;/item&gt;&lt;item&gt;Derive long-term (1 year) blinded keys to be used as a Certificate Authority for the service, maybe using the same approach described by Appendix A (&lt;code&gt;[KEYBLIND]&lt;/code&gt;) from rend-spec-v3 but covering the needed use case of a long-term key, i.e, depending in a long-term nonce and not in&lt;code&gt;[TIME-PERIODS]&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's also important to avoid using the Onion Service key directly as the HTTPS certificate. That would:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Expose the Onion Service secret key material to more software than it's needed, like a web server.&lt;/item&gt;
      &lt;item&gt;Make it very difficult to manage offline Onion Service master keys.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Instead, it's better to use the Onion Service key pair to act as a CA that then certifies a separate key pair to be used with HTTPS.&lt;/p&gt;
    &lt;p&gt;Similar to the self-signed certificate proposal, this approach would have limited adoption if only as small number of applications implement it -- such as the Tor Browser --, except if endorsed by many stakeholders in the form of a specification -- like the SOOC proposal discussed below.&lt;/p&gt;
    &lt;head rend="h2"&gt;Self-authenticating TLS Certificates for Onion Services using a PKCS#11 module¶&lt;/head&gt;
    &lt;p&gt;The Self-authenticating TLS Certificates for Onion Services using a PKCS#11 module proposal mentioned above, that relies on PKCS#11 modules or Authority Information Access (AIA) extensions, could also be used to work with a X.509 certificate directly derived from the .onion key pair.&lt;/p&gt;
    &lt;p&gt;But contrary to the previous proposal, it would not need to use Ed25519: it would support a signature scheme where an Ed25519 private key could sign an ECDSA key. This Ed25519 signature could either be created using the .onion private key itself or a fresh Ed25519 subkey, thus avoiding key reuse.&lt;/p&gt;
    &lt;p&gt;Advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Would reduce logic in the Tor Browser by a well-established API.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Does not need to use Ed25519 X.509 certificates: can work with ECDSA which are fully supported by major browsers according to the CA/B Baseline Requirements, and maybe could even work with RSA.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Seems future-proof as PKCS#11 modules are widely used.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No reliance on the CA-model (and hence has increased censorship resistance).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No need to use CT Logs.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Could be used by other browsers as well (such as Brave).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Could be used with any software, library or Operating System with PKCS#11 support.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disadvantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;In the short-to-mid term this would not be supported on OpenSSL (as of 2024-09, support PKCS#11 modules is still underway).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;System-wide support would depend on how each Operating System could support this custom module. So could be hard to add this to TorVPN. But anyway, TorVPN can't validate existing self-signed .onion certs either, as of 2024-09.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Operators currently using self-signed certs would need to migrate to new certificates.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;namecoin/pkcs11mod: Go library for creating pkcs11 modules:&lt;/item&gt;
      &lt;item&gt;Consistent PKCS #11 support in Red Hat Enterprise Linux 8.&lt;/item&gt;
      &lt;item&gt;OpenSSL support for PKCS#11:&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Same Origin Onion Certificates (SOOC)¶&lt;/head&gt;
    &lt;p&gt;The Same Origin Onion Certificates (SOOC) proposal aims to specify when "in very limited circumstances, we shall not care about signatures at all", allowing clients to disable self-signed certificate warnings when visiting .onion sites.&lt;/p&gt;
    &lt;p&gt;The main difference between the SOOC proposal and to simply start allowing self-signed certificates is that SOOC is aimed to be an IETF proposal that could gain momentum and hence have a greater chance to be adopt by many different vendors.&lt;/p&gt;
    &lt;p&gt;See the SOOC document for details.&lt;/p&gt;
    &lt;head rend="h2"&gt;DANE for .onion¶&lt;/head&gt;
    &lt;p&gt;Another option is to use DNS-based Authentication of Named Entities (DANE), with DNS records like this to associate an Onion Service address with a given HTTPS certificate's public key hash:&lt;/p&gt;
    &lt;code&gt;_443._tcp.testk4ae7qr6nhlgahvyicxy7nsrmfmhigtdophufo3vumisvop2gryd.onion. TSLA 3 1 1 AB9BEB9919729F3239AF08214C1EF6CCA52D2DBAE788BB5BE834C13911292ED9
&lt;/code&gt;
    &lt;p&gt;In order for that to work, logic should be implemented in the client software.&lt;/p&gt;
    &lt;p&gt;Drawbacks:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Service operators must update this record whenever a new certificate is issued.&lt;/item&gt;
      &lt;item&gt;Has some limits for wildcard certificates on specific ports.&lt;/item&gt;
      &lt;item&gt;DANE is not widely supported, especially by web browsers.&lt;/item&gt;
      &lt;item&gt;It would only work for service operators willing to publish the .onion address in the DNS.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Onion-only CAs¶&lt;/head&gt;
    &lt;p&gt;This proposal consists of:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Having .onion-only CAs with name constraints (only allowing issuance for .onion). Services available both via DNS-based and .onion domains will need to have two TLS certificates in order to use this approach -- one certificate for the DNS-based domain (as usual) and another only for the .onion address.&lt;/item&gt;
      &lt;item&gt;Certification procedure would be automated, so generated .onion addresses could easily have it's certificates issued by this special type of CA.&lt;/item&gt;
      &lt;item&gt;Certification would then happen by checking a signature in a CSR and comparing the Subject Alternative Name (SAN). Signature must be validated by the .onion address in the SAN.&lt;/item&gt;
      &lt;item&gt;So this type of CA would be mainly a basic notary that attests signatures and issues a corresponding certificate.&lt;/item&gt;
      &lt;item&gt;The name constraint for this type of CA ensures that it only issues certificates for .onion domains.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Security considerations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Suppose there's a malicious or bugged CA of this type that issues a certificate containing a SAN for &lt;code&gt;$address1.onion&lt;/code&gt;but:&lt;list rend="ol"&gt;&lt;item&gt;Without checking whether the CSR has a signature made by &lt;code&gt;$address1.onion&lt;/code&gt;'s private key.&lt;/item&gt;&lt;item&gt;Or if allowing that another, unrelated &lt;code&gt;$address2.onion&lt;/code&gt;actually signs this CSR.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Without checking whether the CSR has a signature made by &lt;/item&gt;
      &lt;item&gt;Even if that's the case, i.e, the CA wrongly issued a certificate for &lt;code&gt;$address1.onion&lt;/code&gt;that did not match the requirements, this certificate won't work in practice, since in a successful Onion Service TLS connection to&lt;code&gt;$address1.onion&lt;/code&gt;the following must happen:&lt;list rend="ol"&gt;&lt;item&gt;The underlying Tor Rendezvous connection should ensure that the client is connected to &lt;code&gt;$address1.onion&lt;/code&gt;(Onion Services connections are self-authenticated by the .onion address).&lt;/item&gt;&lt;item&gt;The Onion Service should then offer it's TLS certificate, which would not be the malicious one (except if the service is already compromised, but in that case the attacker would not need to forge an invalid certificate anyway...).&lt;/item&gt;&lt;item&gt;Then the client's TLS library tests whether the certificate chain can be verified and any SAN in the presented certificate matches &lt;code&gt;$address1.onion&lt;/code&gt;, among other checks (such as expiration).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The underlying Tor Rendezvous connection should ensure that the client is connected to &lt;/item&gt;
      &lt;item&gt;That said, the work done by this special type of CA is only to expand the self-authentication property from the .onion address into a certificate. So the attack surface of this special type of CA may be inherently low.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Implementation considerations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Since Ed25519 certificates probably won't be supported by major browsers/clients in the foreseeable future (see discussion above at the Self-signed X.509 for .onion section), issuance should probably follow the Appendix B of the CA/B Baseline Requirements.&lt;/item&gt;
      &lt;item&gt;The entire certification procedure could happen via Onion Services.&lt;/item&gt;
      &lt;item&gt;Actually the whole CA infrastructure (website, APIs, OCSP etc) could be interacted only via Onion Services, to reduce the attack surface and protect the service location.&lt;/item&gt;
      &lt;item&gt;Important to consider whether would be possible to organizations setup and maintain a Onion-only CA that's as most automated as possible, including root certificate packaging/distribution/rotation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Pros:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Easy to implement on the client side (just need to install the CA).&lt;/item&gt;
      &lt;item&gt;Easy to implement and maintain on Tor-native applications such as Tor Browser and the Tor VPN.&lt;/item&gt;
      &lt;item&gt;Possibly lowest attack surface than with regular CAs!&lt;/item&gt;
      &lt;item&gt;Largest certification expiration dates could be used (like one year).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Might not be easy to find CAs willing to do this, or to a new one to be formed for this purpose.&lt;/item&gt;
      &lt;item&gt;Might need a merge request to include this method in the CA/B Baseline Requirements, if wider acceptance is intended.&lt;/item&gt;
      &lt;item&gt;No guarantees that these special CAs would be installed among all clients and libraries.&lt;/item&gt;
      &lt;item&gt;Need additional security analysis.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Open questions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Need to check if Certificate Revocation Lists (CRLs) are needed, and how to handle it.&lt;/item&gt;
      &lt;item&gt;Need to figure out how OCSP and OCSP Stapling could happen. OSCP connection could be available behind an Onion Service.&lt;/item&gt;
      &lt;item&gt;Does sending certificates to CT Logs still makes sense for this special type of certification?&lt;/item&gt;
      &lt;item&gt;Needs built-in DoS/service abuse protection:&lt;list rend="ul"&gt;&lt;item&gt;An idea for that: implement a simple PoW by additionally requiring that service operators provide a proof-ownership of another .onion address made by an specific vanity address (like limited to 5 or 6 chars).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proposal for Bring Accessible TLS Supports to All Onion Services, where this idea is initially written and discussed with the possibility for some clients to have only this type of CA installed (but in that case it might not accept valid certificates issued by regular CAs, with advantages and disadvantages)&lt;/item&gt;
      &lt;item&gt;Proposal for automated onion service certificate issuance based on fully qualified onion service key signed certificate request, where this proposal is sent to the CA/B Forum.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Custom CAs¶&lt;/head&gt;
    &lt;p&gt;There are also discussions about how to properly manage custom Certificate Authorities, i.e, those not distributed in TLS libraries by default (such as the certificate store in a web browser):&lt;/p&gt;
    &lt;head rend="h2"&gt;Further references¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Meeting notes¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;From the 2024 Lisbon Meeting:&lt;/item&gt;
      &lt;item&gt;From the 2017 Montreal Meeting:&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Blog posts¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Facebook, hidden services, and https certs | The Tor Project:&lt;list rend="ul"&gt;&lt;item&gt;Part four: what do we think about an https cert for a .onion address?&lt;/item&gt;&lt;item&gt;Part five: What remains to be done?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Related issues¶&lt;/head&gt;
    &lt;head rend="h2"&gt;Notes¶&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;But not HTTP/3 yet, since it uses UDP not available via Tor (as of 2023-05). The HTTP/2 standard does not require encryption, but all major browsers require encryption for HTTP/2 and encryption for HTTP/3 is required by default. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See PCI-DSS v4.0 - Appendix G - Term "Strong Cryptography" - page 355, which points only to "industry tested and accepted algorithms". While we could argue that PCI-DSS v4.0 is not precise enough about which transmission protocols might be used, it may be the case that the encryption used by the Onion Services' Rendezvous v3 protocol is not (yet) part of an "industry standard" (needs someone to carefully review this claim and open a merge request to update this information). It also may be the case that PCI-DSS compliance may be hard to get for a system that employs only the Rendezvous v3 protocol to transmit cardholder data between an user and an Onion Service, without TLS atop of it. And users might not trust the connection if not over TLS, or if their browser does not show certificate information. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It's worth note that PCI-DSS does allow for the use of self-signed certificates under some special conditions that may exclude some of the proposals in this document (see PCI-DSS v4.0 - Requirement 4.2 - Applicability Notes - page 106). In practice, this is only applicable for internal links within an organization or for clients and libraries that have the custom Certificate Authorities' root keys on it's keystores and that matches the standard requirements. And users would hardly trust a self-signed certificate for doing online purchases as their browsers would show warning messages. Recommendation (see PCI-DSS v4.0 - Requirement 4.2 - Guidance - page 106) goes instead towards a certificate trusted by a Certificate Authority. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;However, the argument about revealing an onion site that would like to remain hidden, is a real one. For those services, it could be considered options such as a non-CT Logs issuing CA that may not be in the "valid" set, but operated by a friendly to Tor organization, which is added to Tor Browser as a valid certifier. The standards space may be moving towards requiring CT log submissions at some point, so this is something to keep an eye on. Another possibility would be to consider writing a standard for hashing onion site names in CT Logs, so they can be verified, but not revealed (such as what WhatsApp did in their Auditable Key Directory). Such a standard could take years to get to place of usefulness, and probably encounter resistance. Otherwise, the only option for such a service operator is to have a self-signed certificate, or none at all. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For a historical background on Domain Validation (DV) certs, check the CA/B forum thread DV issuance for next-generation onion services. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;As of January 2023, there are only two CAs issuing certificates for .onion domains: DigiCert providing only Extended Validation (EV) certs and HARICA providing only Domain Validated (DV) certs. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;They usually just support X25519, which is a key agreement scheme not to be confused with Ed25519. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is tracked on cabforum/servercert issue #451, which is about adding EdDSA (and hence Ed25519) support in the CA/B Baseline Requirements. Check also the related mail thread (Servercert-wg) Ed25519 certificates. For Let's Encrypt support, check letsencrypt/boulder issue 3649; Request For CertBot To Support The Signing of Ed25519 Certificates and Support Ed25519 and Ed448 forum threads. On IETF, EdDSA and Ed25519 are standardized on RFC 8032, and have Algorithm Identifiers for X.509 Public Key Infrastructure as part of RFC 8410. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://onionservices.torproject.org/research/proposals/usability/certificates/"/></entry><entry><id>https://news.ycombinator.com/item?id=45048419</id><title>The Deletion of Docker.io/Bitnami</title><updated>2025-08-28T16:12:35.642663+00:00</updated><content>&lt;doc fingerprint="ca8a1a59085dec0f"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h5"&gt;Update&lt;/head&gt;
      &lt;p&gt;After evaluating the impact and community feedback, the Bitnami team has postponed the deletion of the Bitnami public catalog (&lt;code&gt;docker.io/bitnami&lt;/code&gt;) until September 29th to give users more time to adapt to the upcoming changes.&lt;lb/&gt;To raise awareness before the registry deletion, we will run a series of brownouts over the coming weeks. During each brownout, a set of 10 container images from &lt;code&gt;docker.io/bitnami&lt;/code&gt; will be temporarily unavailable for 24 hours. The scheduled brownouts are:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item style="list-style-type: none"&gt;
          &lt;list rend="ul"&gt;
            &lt;item&gt;August 28, 08:00 UTC → August 29, 08:00 UTC&lt;/item&gt;
            &lt;item&gt;September 2, 08:00 UTC → September 3, 08:00 UTC&lt;/item&gt;
            &lt;item&gt;September 17, 08:00 UTC → September 18, 08:00 UTC&lt;/item&gt;
          &lt;/list&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The list of affected applications will be published on the day of each brownout via our usual channels.&lt;lb/&gt;As previously announced, since August 28th, we have not published new Bitnami container images or Helm charts to Docker Hub in OCI format. The source code for containers and Helm charts remains available on GitHub under the Apache 2.0 license.&lt;/p&gt;
      &lt;head rend="h3"&gt;What's changing?&lt;/head&gt;
      &lt;p&gt;Starting August 28th, Bitnami will be archiving its OCI registry of charts and images to a new location, Bitnami Legacy, to make room for the new secure, hardened images that will eventually reside in the main Bitnami registry. Users who are currently pulling these images will need to update their pipelines, internal mirrors, and Kubernetes clusters to pull from a new location before that time. A couple of options users have: &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Switch to Bitnami Secure Images &lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Switch to the Bitnami Legacy Registry&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;To retain existing functionality and maintain continuity of systems relying on Bitnami, we recommend switching to Bitnami Secure Images. In addition to a less disruptive transition, BSI helps strengthen your security and compliance posture by adopting the higher-quality images offered as part of BSI. &lt;/p&gt;
      &lt;head rend="h3"&gt;Switching to Bitnami Secure Images (BSI)&lt;/head&gt;
      &lt;p&gt;While some BSI images will be free, they are only for use in development/testing purposes, and a commercial subscription is recommended for access to the entire catalog, as well as stable tags, long-term support versions, and more. &lt;/p&gt;
      &lt;p&gt;Though a BSI subscription provides customers with the entire Bitnami Debian-based image catalog (which will continue to receive updates), we recommend users upgrade and start using the hardened Photon Linux-based images instead. These are designed to be replacement images for any of the Debian images and work with the same Helm charts. &lt;/p&gt;
      &lt;p&gt;The Photon images provide many other benefits not previously available to users of Debian images, including: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Drastically reduced CVE count (e.g., 100+ CVEs to in some cases 0)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;VEX statements for easier triage, along with Known Exploitable Vulnerabilities (KEV) and EPSS scores&lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;A self-service UI/API with powerful reporting and metadata capabilities&lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;More advanced Helm charts are not available on Docker Hub, such as Bitnami’s “distroless charts” which offer an 83% smaller attack surface (by MB).&lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Support for customizing the images built by our secure SLSA 3 software factory &lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Images and Helm charts are delivered to a private and secure OCI registry dedicated to each customer instead of relying on a public registry with rate limits like Docker Hub.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Access to over 90 VM Images in OVA format&lt;/p&gt;
        &lt;/item&gt;
        &lt;item dir="ltr" aria-level="1"&gt;
          &lt;p&gt;Enterprise support for packaging and installation issues&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Switching to Bitnami Legacy Registry&lt;/head&gt;
      &lt;p&gt;Another option for users of Bitnami today is to switch to the historic archive registry called Bitnami Legacy. This is unsupported software that is being made available, at users' own risk, while they make plans for alternatives. As such, this is a temporary solution, and we do not plan to keep this registry around for long. It will quickly begin to accumulate vulnerabilities that are not patched and atrophy as any software frozen in time does. If this is your choice, we strongly recommend copying the images you are using to your own registry; again, this should be considered a temporary solution. While we think there are many better options to make before the August 28th change, this is an option of last resort for those who need more time. &lt;/p&gt;
      &lt;head rend="h3"&gt;Why is it a good time to consider upgrading your security and compliance for open source? &lt;/head&gt;
      &lt;p&gt;So why do all the work now to change what’s maybe been working and update the type of open source images you use? We get it, no one likes change. But the reality is the landscape of open source is changing all around us. For example, from 2019-2023, the number of malicious packages discovered has risen to more than 245,000 according to Sonatype. That’s 2x all the previous years combined. The implication is that bad actors are finding increasing opportunities to exploit open source software that is running in every major software organization around the world. Meanwhile, with the growth of AI and MCP models, open source consumption is only going to increase. So the risk profile tides are quickly rising around us, and having a better boat to be prepared for the impacts of this change is the only responsible response. &lt;/p&gt;
      &lt;p&gt;In addition, the Cyber Resilience Act in the EU creates an impending obligation for many organizations doing business there to provide guarantees about the open source software they use in their organization. It could soon be a liability to use open source that doesn’t have the required documentation to prove it’s been sourced from a safe place and hasn’t been tampered with. &lt;/p&gt;
      &lt;p&gt;This is why the launch of Bitnami Secure Images is so timely. BSI is making it easier than ever for organizations to responsibly prepare for what the future of open source software in our modern world looks like. As with many things, what started out simple has become increasingly complex and requires more care to navigate. Furthermore, BSI has one of the lowest TCOs in the industry, enabling more organizations than ever before to afford cutting-edge supply chain security. BSI is effectively democratizing security and compliance for open source so that it doesn’t require million-dollar contracts from vendors with sky-high valuations. &lt;/p&gt;
      &lt;head rend="h3"&gt;What are Competitors trying to claim about Bitnami? &lt;/head&gt;
      &lt;p&gt;It’s also a great time for the competition to try and steer the narrative about Bitnami. Some have claimed that Bitnami is “pulling their free container images and Helm charts from public access”. However, if we look a little more closely at the changes Bitnami has announced, this statement is inaccurate. For one, Bitnami Helm charts continue to be an open source project, under Apache 2, freely available to the public on GitHub. &lt;/p&gt;
      &lt;p&gt;Second, what is actually changing is the built OCI artifacts. Essentially, Bitnami has been the Jenkins of the internet for many years, but this has become unsustainable. Operating a build pipeline and OCI registry for the general public is very expensive. Just ask those same competitors throwing shade at Bitnami why they have never offered to make their charts or images publicly available at the same scale Bitnami has?&lt;/p&gt;
      &lt;p&gt;So users can continue to freely access the Helm chart source (as well as the Debian images). However, in order to sustain and support the dedicated team of engineers who maintain and build new charts and images, a subscription will be required if an organization needs the images and charts built and hosted in an OCI registry for them. And to reiterate the above again, organizations that choose this path are simultaneously upgrading their security posture and improving their OSS strategy.&lt;/p&gt;
      &lt;head rend="h3"&gt;How do the changes on August 28th work?&lt;/head&gt;
      &lt;p&gt;The changes to the Bitnami repo are slated to begin on Aug 28th. They will not all be at once. Over a multi-week period, the images will be cleaned up from the registry to make room for the new ones. This is being done gradually to minimize the disruptions. However, we can’t be precise about which image will be removed at what time due to the complexity of the 84TB of OCI content that the engineering team will be dealing with. Therefore, it’s best to assume starting Aug 28th, every image used in a key business function should be addressed with an alternate registry. &lt;/p&gt;
      &lt;p&gt;We’re making room in the mainline Bitnami registry so we can populate it with the free tier of Bitnami Secure Images. These hardened Photon have the same names as the Debian images, so they can’t occupy the same registry. And we want new adopters of Bitnami to start with the secure images going forward, as we believe this is the future of open-source software on the internet. In this FAQ, you can find more information about all the details of the upcoming changes.&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt;#bitnami&lt;lb/&gt;#Security&lt;lb/&gt;#helm&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://community.broadcom.com/tanzu/blogs/beltran-rueda-borrego/2025/08/18/how-to-prepare-for-the-bitnami-changes-coming-soon"/></entry><entry><id>https://news.ycombinator.com/item?id=45048736</id><title>Lesser known mobile adtech domains where data is sent</title><updated>2025-08-28T16:12:35.100078+00:00</updated><content>&lt;doc fingerprint="76b820e21296abe6"&gt;
  &lt;main&gt;
    &lt;p&gt;AppGoblin has now run over 40k apps in an emulator, tracking millions of API calls thousands of advertising domains. Unfortunately, some of them are dark, meaning they have no landing page of any kind, and I’m unclear who controls these domains.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;news-cdn.site&lt;/cell&gt;
        &lt;cell&gt;marketingcloudapis.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;kickoffo.site&lt;/cell&gt;
        &lt;cell&gt;onegg.site&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;lazybumblebee.com&lt;/cell&gt;
        &lt;cell&gt;qa-analytics.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;acobt.tech&lt;/cell&gt;
        &lt;cell&gt;yastatic.net&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Let’s see if we can figure them out!&lt;/p&gt;
    &lt;head rend="h2"&gt;qa-analytics.com&lt;/head&gt;
    &lt;p&gt;This one is a mystery. Seems like it’s related to Germany since it’s always resolving to HETZNER and german IPs. Checking the shared IPs, it looks like they do overlap with unity3d.com domains sometimes.&lt;/p&gt;
    &lt;p&gt;Again, this whole list is games.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Woodoku – Wood Block Puzzle&lt;/item&gt;
      &lt;item&gt;Draw Climber&lt;/item&gt;
      &lt;item&gt;Spider Rope Hero: Action Game&lt;/item&gt;
      &lt;item&gt;Running Pet: Dec Rooms&lt;/item&gt;
      &lt;item&gt;Bubble Shooter 2&lt;/item&gt;
      &lt;item&gt;Pirate Treasures: Jewel &amp;amp; Gems&lt;/item&gt;
      &lt;item&gt;Tik Tap Challenge&lt;/item&gt;
      &lt;item&gt;Collect Em All! Clear the Dots&lt;/item&gt;
      &lt;item&gt;Gun Simulator &amp;amp; Lightsaber&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;data deep dive&lt;/head&gt;
    &lt;p&gt;Looking at the requests I can match various keys to values from untiy3d.com API calls! Specifically they share the same `app_key` values.&lt;/p&gt;
    &lt;head rend="h2"&gt;acobt.tech&lt;/head&gt;
    &lt;p&gt;Well that name definitely comes off as esoteric at first. First let’s check the IP cluser and see what we find, of the 233 apps sending/receiving from acobt.tech we have 4 other sites with 1:1 matches that are all sites that do not have any landing pages.&lt;/p&gt;
    &lt;p&gt;acobt.tech 233&lt;lb/&gt;news-cdn.site 233&lt;lb/&gt;inmense.site 232&lt;lb/&gt;kickoffo.site 232&lt;/p&gt;
    &lt;head rend="h2"&gt;searching…&lt;/head&gt;
    &lt;p&gt;Searching the internet shows various hits saying some of these belong to Bigo Ads. Let’s check the apps’ SDKs and see&lt;/p&gt;
    &lt;head rend="h2"&gt;Apps&lt;/head&gt;
    &lt;p&gt;Again we got lots of games, and looking it looks like AppGoblin has indeed already found that each of these has a Bigo Ad SDK.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pizza Ready!&lt;/item&gt;
      &lt;item&gt;Sculpt People&lt;/item&gt;
      &lt;item&gt;Vita Mahjong&lt;/item&gt;
      &lt;item&gt;Modern Bus Simulator: Bus Game&lt;/item&gt;
      &lt;item&gt;Gym Heros: Fighting Game&lt;/item&gt;
      &lt;item&gt;Blockman Go&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;onegg.site&lt;/head&gt;
    &lt;p&gt;Wait, this one also matches the IPs for the other various Bigo Ads. Seems like Bigo really uses a lot of random domains?&lt;/p&gt;
    &lt;head rend="h2"&gt;lazybumblebee.com&lt;/head&gt;
    &lt;p&gt;OK, great name. This one appears in clusters of SDK advertising, making me think it’s related to a mediation SDK of some kind (rather than to one specific ad network). Possibly this is bidmachine.io’s as it is the most common, but really all the top ad newtorks appear nearly 1:1 along side it across the 276 apps I’ve found it in:&lt;lb/&gt;bidmachine.io 275&lt;lb/&gt;unity3d.com 270&lt;lb/&gt;doubleclick.net 269&lt;lb/&gt;mtgglobals.com 267&lt;lb/&gt;rayjump.com 267&lt;lb/&gt;applovin.com 261&lt;lb/&gt;vungle.com 257&lt;/p&gt;
    &lt;head rend="h3"&gt;Example Apps&lt;/head&gt;
    &lt;p&gt;Definitely game focused list here. They almost all call variations of &lt;code&gt;d.lazybumblebee.com/track/sdk-event&lt;/code&gt; &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Helix Jump&lt;/item&gt;
      &lt;item&gt;Going Balls&lt;/item&gt;
      &lt;item&gt;Paper.io 2&lt;/item&gt;
      &lt;item&gt;aquapark.io&lt;/item&gt;
      &lt;item&gt;Snake.io – Fun Snake .io Games&lt;/item&gt;
      &lt;item&gt;Hole.io&lt;/item&gt;
      &lt;item&gt;1945 Air Force: Airplane Games&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Shared IPs&lt;/head&gt;
    &lt;p&gt;Looking around there are lots of examples of shared IP addresses with everestop.io and bidmachine, so I think that might have solved that.&lt;/p&gt;
    &lt;p&gt;everestop.io 172.240.40.172&lt;lb/&gt;bidmachine.io 172.240.40.172&lt;lb/&gt;bidmachine.io 204.74.252.252&lt;lb/&gt;everestop.io 172.240.61.171&lt;lb/&gt;voisetech.com 34.216.198.39&lt;/p&gt;
    &lt;head rend="h2"&gt;SDK?&lt;/head&gt;
    &lt;p&gt;Looks like a lot of the apps have the &lt;code&gt;io.bidmachine&lt;/code&gt; and &lt;code&gt;com.explorestack&lt;/code&gt; SDKs, so I’m thinking that `lazybumblebee.com` does indeed belong to BidMachine and helps it with some app mediation service.&lt;/p&gt;
    &lt;head rend="h2"&gt;marketingcloudapis.com&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;marketingcloudapis.com&lt;/code&gt; is just the kind of generic descriptive name I’d come up with.  &lt;/p&gt;
    &lt;head rend="h3"&gt;Example Apps&lt;/head&gt;
    &lt;p&gt;Example apps, there are a lot of very corporate apps in here along with lots of shopping.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;adidas: Shop Shoes &amp;amp; Clothing&lt;/item&gt;
      &lt;item&gt;Claro música&lt;/item&gt;
      &lt;item&gt;Domino’s Pizza USA&lt;/item&gt;
      &lt;item&gt;SiriusXM: Music, Sports &amp;amp; News&lt;/item&gt;
      &lt;item&gt;GasBuddy: Find &amp;amp; Pay for Gas&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Example API Call&lt;/head&gt;
    &lt;p&gt;Each app sends off two API calls on start to a unique (per app) subdomain on marketingcloudapis.com with the response from the first API call below. The information sent seems somewhat bland compared to the usual deep scraping that advertising SDKs do. So this is likely paired with other API calls already going out.&lt;/p&gt;
    &lt;quote&gt;x-mashery-message-id: 4e9eb0f4-6eaa-4f27-bb66-a3694cffe471 x-mashery-responder: 56bf7c64cc-lnkfz strict-transport-security: max-age=31536000; includeSubDomains; preload Content-Security-Policy: upgrade-insecure-requests x-xss-protection: 1; mode=block x-frame-options: DENY x-content-type-options: nosniff cache-control: no-cache, must-revalidate, max-age=0, no-store, private Referrer-Policy: strict-origin-when-cross-origin Vary: Origin, X-HTTP-Method-Override Content-Length: 339 Content-Type: application/json; charset=UTF-8 Date: Wed, 27 Aug 2025 22:12:39 GMT Connection: keep-alive Keep-Alive: timeout=5 { "nodes": [ { "version": 1, "name": "blocked", "items": { "blocked": 0 } }, { "version": 1, "name": "pushFeaturesInUse", "items": { "inbox": false } }, { "version": 1, "name": "appConfig", "items": { "inApp": { "gateEventProcessingMs": 1000 }, "event": { "activeEvents": [] }, "endpoints": [], "deliveryReceipt": { "deliveryReceiptStatus": 0, "gateDeliveryReceiptProcessingMs": 5000 } } } ] }&lt;/quote&gt;
    &lt;head rend="h3"&gt;Related Domains&lt;/head&gt;
    &lt;p&gt;&lt;del&gt;Checking on domains that are called together, it looks like this is almost always called with &lt;/del&gt;&lt;code&gt;googleapis.com&lt;/code&gt; so possibly this is related to Google, but this is a bit weak as a lot of Android apps have integrations with Google.&lt;/p&gt;
    &lt;p&gt;EDIT: I posted this on HackerNews and user politelemon correctly identified this as SalesForce. Very awesome spot by that user, and it matches the various AppGoblin SDKs for each app as in this example for the Adidas app SDKs.&lt;/p&gt;
    &lt;head rend="h2"&gt;End Results!&lt;/head&gt;
    &lt;p&gt;Much better than I expected. A bit of digging and all the URLs were figured out with the exception of marketingcloudapis.com which I was a bit unsure of, but looks like google.com&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;news-cdn.site -&amp;gt; Bigo Ads&lt;/cell&gt;
        &lt;cell&gt;marketingcloudapis.com -&amp;gt; SalesForce&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;kickoffo.site -&amp;gt; Bigo Ads&lt;/cell&gt;
        &lt;cell&gt;onegg.site -&amp;gt; BIGO Ads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;lazybumblebee.com -&amp;gt; BidMachine&lt;/cell&gt;
        &lt;cell&gt;qa-analytics.com -&amp;gt; Unity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;acobt.tech -&amp;gt; Bigo Ads&lt;/cell&gt;
        &lt;cell&gt;yastatic.net -&amp;gt; Yandex&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jamesoclaire.com/2025/08/28/uncovering-lesser-known-mobile-adtech-domains/"/></entry><entry><id>https://news.ycombinator.com/item?id=45050090</id><title>Claude Code Checkpoints</title><updated>2025-08-28T16:12:34.762672+00:00</updated><content>&lt;doc fingerprint="3786eeec2ca7cebb"&gt;
  &lt;main&gt;
    &lt;p&gt;Continuously monitors your entire project for file changes. No setup required - just select your project folder and start coding.&lt;/p&gt;
    &lt;p&gt;Create instant snapshots of your project state before making risky changes. Each checkpoint captures all files and their contents.&lt;/p&gt;
    &lt;p&gt;See exactly what changed between checkpoints with our built-in diff viewer. Track additions, modifications, and deletions at a glance.&lt;/p&gt;
    &lt;p&gt;Instantly restore your project to any previous checkpoint. Perfect for experimenting with confidence or recovering from mistakes.&lt;/p&gt;
    &lt;p&gt;Seamlessly integrates with Claude Desktop through MCP protocol. Automatic checkpoints when tasks complete.&lt;/p&gt;
    &lt;p&gt;Every checkpoint includes a complete backup of all project files. Your work is always safe and recoverable.&lt;/p&gt;
    &lt;p&gt;Choose your project folder in the Checkpoints app&lt;/p&gt;
    &lt;p&gt;Work with Claude Code as usual - changes are tracked automatically&lt;/p&gt;
    &lt;p&gt;Checkpoints are created automatically when tasks complete&lt;/p&gt;
    &lt;p&gt;One click to restore any previous state if needed&lt;/p&gt;
    &lt;p&gt;Works automatically with Claude Desktop through Model Context Protocol&lt;/p&gt;
    &lt;p&gt;MCP server starts automatically on port 8765. Claude Desktop connects instantly when you open a project.&lt;/p&gt;
    &lt;p&gt;Every task start and completion is tracked. Checkpoints are created automatically at key moments.&lt;/p&gt;
    &lt;p&gt;Claude can list checkpoints, view diffs, and restore previous states through MCP commands.&lt;/p&gt;
    &lt;p&gt;Clean, intuitive checkpoint management&lt;/p&gt;
    &lt;p&gt;Visual comparison between checkpoints&lt;/p&gt;
    &lt;p&gt;Seamless Claude Desktop connection&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://claude-checkpoints.com/"/></entry><entry><id>https://news.ycombinator.com/item?id=45050192</id><title>Windows 11 Update KB5063878 Causing SSD Failures</title><updated>2025-08-28T16:12:34.671350+00:00</updated><content/><link href="https://old.reddit.com/r/msp/comments/1n1sgxx/windows_11_update_kb5063878_causing_ssd_failures/"/></entry><entry><id>https://news.ycombinator.com/item?id=45050415</id><title>Are OpenAI and Anthropic Losing Money on Inference?</title><updated>2025-08-28T16:12:34.164883+00:00</updated><content>&lt;doc fingerprint="271216d2049eed14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Are OpenAI and Anthropic Really Losing Money on Inference?&lt;/head&gt;
    &lt;p&gt;I keep hearing what a cash incinerator AI is, especially around inference. While it seems reasonable on the surface, I've often been wary of these kind of claims, so I decided to do some digging.&lt;/p&gt;
    &lt;p&gt;I haven't seen anyone really try to deconstruct the costs in running inference at scale and the economics really interest me.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This is really napkin math. I don't have any experience at running frontier models at scale, but I do know a lot about the costs and economics of running very high throughput services on the cloud and, also, some of the absolutely crazy margins involved from the hyperscalers vs bare metal. Corrections are most welcome.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Some assumptions&lt;/head&gt;
    &lt;p&gt;I'm only going to look at raw compute costs. This is obviously a complete oversimplification, but given how useful the current models are - even assuming no improvements - I want to stress test the idea that everyone is losing so much money on inference that it is completely unsustainable.&lt;/p&gt;
    &lt;p&gt;I've taken the cost of a single H100 at $2/hour. This is actually more than the current retail rental on demand price, and I (hope) the large AI firms are able to get these for a fraction of this price.&lt;/p&gt;
    &lt;p&gt;Secondly, I'm going to use the architecture of DeepSeek R1 as the baseline, 671B total params with 37B active via mixture of experts. Given this gets somewhat similar performance to Claude Sonnet 4 and GPT5 I think it's a fair assumption to make.&lt;/p&gt;
    &lt;head rend="h2"&gt;Working Backwards: H100 Math From First Principles&lt;/head&gt;
    &lt;head rend="h3"&gt;Production Setup&lt;/head&gt;
    &lt;p&gt;Let's start with a realistic production setup. I'm assuming a cluster of 72 H100s at $2/hour each, giving us $144/hour in total costs.&lt;/p&gt;
    &lt;p&gt;For production latency requirements, I'm using a batch size of 32 concurrent requests per model instance, which is more realistic than the massive batches you might see in benchmarks. With tensor parallelism across 8 GPUs per model instance, we can run 9 model instances simultaneously across our 72 GPUs.&lt;/p&gt;
    &lt;head rend="h4"&gt;Prefill Phase (Input Processing)&lt;/head&gt;
    &lt;p&gt;The H100 has about 3.35TB/s of HBM bandwidth per GPU, which becomes our limiting factor for most workloads. With 37B active parameters requiring 74GB in FP16 precision, we can push through approximately 3,350GB/s ÷ 74GB = 45 forward passes per second per instance.&lt;/p&gt;
    &lt;p&gt;Here's the key insight: each forward pass processes ALL tokens in ALL sequences simultaneously. With our batch of 32 sequences averaging 1,000 tokens each, that's 32,000 tokens processed per forward pass. This means each instance can handle 45 passes/s × 32k tokens = 1.44 million input tokens per second. Across our 9 instances, we're looking at 13 million input tokens per second, or 46.8 billion input tokens per hour.&lt;/p&gt;
    &lt;p&gt;In reality, with MoE you might need to load different expert combinations for different tokens in your batch, potentially reducing throughput by 2-3x if tokens route to diverse experts. However, in practice, routing patterns often show clustering around popular experts, and modern implementations use techniques like expert parallelism and capacity factors to maintain efficiency, so the actual impact is likely closer to a 30-50% reduction rather than worst-case scenarios.&lt;/p&gt;
    &lt;head rend="h4"&gt;Decode Phase (Output Generation)&lt;/head&gt;
    &lt;p&gt;Output generation tells a completely different story. Here we're generating tokens sequentially - one token per sequence per forward pass. So our 45 forward passes per second only produce 45 × 32 = 1,440 output tokens per second per instance. Across 9 instances, that's 12,960 output tokens per second, or 46.7 million output tokens per hour.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raw Cost Per Token&lt;/head&gt;
    &lt;p&gt;The asymmetry is stark: $144 ÷ 46,800M = $0.003 per million input tokens versus $144 ÷ 46.7M = $3.08 per million output tokens. That's a thousand-fold difference!&lt;/p&gt;
    &lt;head rend="h3"&gt;When Compute Becomes the Bottleneck&lt;/head&gt;
    &lt;p&gt;Our calculations assume memory bandwidth is the limiting factor, which holds true for typical workloads. But compute becomes the bottleneck in certain scenarios. With long context sequences, attention computation scales quadratically with sequence length. Very large batch sizes with more parallel attention heads can also shift you to being compute bound.&lt;/p&gt;
    &lt;p&gt;Once you hit 128k+ context lengths, the attention matrix becomes massive and you shift from memory-bound to compute-bound operation. This can increase costs by 2-10x for very long contexts.&lt;/p&gt;
    &lt;p&gt;This explains some interesting product decisions. Claude Code artificially limits context to 200k tokens - not just for performance, but to keep inference in the cheap memory-bound regime and avoid expensive compute-bound long-context scenarios. This is also why providers charge extra for 200k+ context windows - the economics fundamentally change.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World User Economics&lt;/head&gt;
    &lt;p&gt;So to summarise, I suspect the following is the case based on trying to reverse engineer the costs (and again, keep in mind this is retail rental prices for H100s):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Input processing is essentially free (~$0.001 per million tokens)&lt;/item&gt;
      &lt;item&gt;Output generation has real costs (~$3 per million tokens)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These costs map to what DeepInfra charges for R1 hosting, with the exception there is a much higher markup on input tokens.&lt;/p&gt;
    &lt;head rend="h3"&gt;A. Consumer Plans&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;$20/month ChatGPT Pro user: Heavy daily usage but token-limited &lt;list rend="ul"&gt;&lt;item&gt;100k toks/day&lt;/item&gt;&lt;item&gt;Assuming 70% input/30% output: actual cost ~$3/month&lt;/item&gt;&lt;item&gt;5-6x markup for OpenAI&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is your typical power user who's using the model daily for writing, coding, and general queries. The economics here are solid.&lt;/p&gt;
    &lt;head rend="h3"&gt;B. Developer Usage&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude Code Max 5 user ($100/month): 2 hours/day heavy coding &lt;list rend="ul"&gt;&lt;item&gt;~2M input tokens, ~30k output tokens/day&lt;/item&gt;&lt;item&gt;Heavy input token usage (cheap parallel processing) + minimal output&lt;/item&gt;&lt;item&gt;Actual cost: ~$4.92/month → 20.3x markup&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Claude Code Max 10 user ($200/month): 6 hours/day very heavy usage &lt;list rend="ul"&gt;&lt;item&gt;~10M input tokens, ~100k output tokens/day&lt;/item&gt;&lt;item&gt;Huge number of input tokens but relatively few generated tokens&lt;/item&gt;&lt;item&gt;Actual cost: ~$16.89/month → 11.8x markup&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The developer use case is where the economics really shine. Coding agents like Claude Code naturally have a hugely asymmetric usage pattern - they input entire codebases, documentation, stack traces, multiple files, and extensive context (cheap input tokens) but only need relatively small outputs like code snippets or explanations. This plays perfectly into the cost structure where input is nearly free but output is expensive.&lt;/p&gt;
    &lt;head rend="h3"&gt;C. API Profit Margins&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Current API pricing: $3/15 per million tokens vs ~$0.01/3 actual costs&lt;/item&gt;
      &lt;item&gt;Margins: 80-95%+ gross margins&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The API business is essentially a money printer. The gross margins here are software-like, not infrastructure-like.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;We've made a lot of assumptions in this analysis, and some probably aren't right. But even if you assume we're off by a factor of 3, the economics still look highly profitable. The raw compute costs, even at retail H100 pricing, suggest that AI inference isn't the unsustainable money pit that many claim it to be.&lt;/p&gt;
    &lt;p&gt;The key insight that most people miss is just how dramatically cheaper input processing is compared to output generation. We're talking about a thousand-fold cost difference - input tokens at roughly $0.005 per million versus output tokens at $3+ per million.&lt;/p&gt;
    &lt;p&gt;This cost asymmetry explains why certain use cases are incredibly profitable while others might struggle. Heavy readers - applications that consume massive amounts of context but generate minimal output - operate in an almost free tier for compute costs. Conversational agents, coding assistants processing entire codebases, document analysis tools, and research applications all benefit enormously from this dynamic.&lt;/p&gt;
    &lt;p&gt;Video generation represents the complete opposite extreme of this cost structure. A video model might take a simple text prompt as input - maybe 50 tokens - but needs to generate millions of tokens representing each frame. The economics become brutal when you're generating massive outputs from minimal inputs, which explains why video generation remains so expensive and why these services either charge premium prices or limit usage heavily.&lt;/p&gt;
    &lt;p&gt;The "AI is unsustainably expensive" narrative may be serving incumbent interests more than reflecting economic reality. When established players emphasize massive costs and technical complexity, it discourages competition and investment in alternatives. But if our calculations are even remotely accurate, especially for input-heavy workloads, the barriers to profitable AI inference may be much lower than commonly believed.&lt;/p&gt;
    &lt;p&gt;Let's not hype the costs up so much that people overlook the raw economics. I feel everyone fell for this a decade or two ago with cloud computing costs from the hyperscalers and allowed them to become money printers. If we're not careful we'll end up with the same on AI inference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://martinalderson.com/posts/are-openai-and-anthropic-really-losing-money-on-inference/"/></entry><entry><id>https://news.ycombinator.com/item?id=45050538</id><title>Fossjobs: A job board for Free and Open Source jobs</title><updated>2025-08-28T16:12:33.408693+00:00</updated><content>&lt;doc fingerprint="1ae69789721b2f9b"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Technology Assessor&lt;/head&gt;
    &lt;p&gt;2025-08-28 - at NLnet foundation in Amsterdam, Netherlands Full-time&lt;/p&gt;
    &lt;p&gt;This is a job board exclusively for paid free &amp;amp; open source jobs: We only list jobs at organizations that improve and involve FOSS or open hardware projects. Merely using open source as part of the job is not enough.&lt;/p&gt;
    &lt;p&gt;Listings are free. Submit jobs you find! You can also send us job links to submit [(at)] fossjobs [dot] net.&lt;/p&gt;
    &lt;p&gt;Mastodon • IRC • RSS Feeds • GitHub&lt;/p&gt;
    &lt;p&gt;2025-08-28 - at NLnet foundation in Amsterdam, Netherlands Full-time&lt;/p&gt;
    &lt;p&gt;2025-08-25 - at Wikimedia Deutschland e.V. in Germany Full-time&lt;/p&gt;
    &lt;p&gt;2025-07-30 - at Free Software Foundation in Boston, MA, USA, United States Full-time&lt;/p&gt;
    &lt;p&gt;2025-07-30 - at Free Software Foundation in United States Part-time&lt;/p&gt;
    &lt;p&gt;2025-07-17 - at NetKnights GmbH in Kassel, Germany Full-time&lt;/p&gt;
    &lt;p&gt;2025-07-03 - at SYSTOPIA GmbH in Bonn, Germany Full-time&lt;/p&gt;
    &lt;p&gt;2025-06-09 - at Ruth Cheesley, Mautic — Worldwide/Remote Full-time&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.fossjobs.net/"/></entry><entry><id>https://news.ycombinator.com/item?id=45050873</id><title>Microbial metabolite repairs liver injury by restoring hepatic lipid metabolism</title><updated>2025-08-28T16:12:33.183989+00:00</updated><content/><link href="https://journals.asm.org/doi/10.1128/mbio.01718-25"/></entry><entry><id>https://news.ycombinator.com/item?id=45050931</id><title>Important machine learning equations</title><updated>2025-08-28T16:12:33.017521+00:00</updated><content>&lt;doc fingerprint="6c3c4b014c3bd6b5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Most Important Machine Learning Equations: A Comprehensive Guide&lt;/head&gt;&lt;head rend="h2"&gt;Motivation&lt;/head&gt;&lt;p&gt;Machine learning (ML) is a powerful field driven by mathematics. Whether you’re building models, optimizing algorithms, or simply trying to understand how ML works under the hood, mastering the core equations is essential. This blog post is designed to be your go-to resource, covering the most critical and “mind-breaking” ML equations—enough to grasp most of the core math behind ML. Each section includes theoretical insights, the equations themselves, and practical implementations in Python, so you can see the math in action.&lt;/p&gt;&lt;p&gt;This guide is for anyone with a basic background in math and programming who wants to deepen their understanding of ML and is inspired by this tweet from @goyal__pramod. Let’s dive into the equations that power this fascinating field!&lt;/p&gt;&lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;&lt;head rend="h2"&gt;Introduction&lt;/head&gt;&lt;p&gt;Mathematics is the language of machine learning. From probability to linear algebra, optimization to advanced generative models, equations define how ML algorithms learn from data and make predictions. This blog post compiles the most essential equations, explains their significance, and provides practical examples using Python libraries like NumPy, scikit-learn, TensorFlow, and PyTorch. Whether you’re a beginner or an experienced practitioner, this guide will equip you with the tools to understand and apply ML math effectively.&lt;/p&gt;&lt;head rend="h2"&gt;Probability and Information Theory&lt;/head&gt;&lt;p&gt;Probability and information theory provide the foundation for reasoning about uncertainty and measuring differences between distributions.&lt;/p&gt;&lt;head rend="h3"&gt;Bayes’ Theorem&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[P(A|B) = \frac{P(B|A) P(A)}{P(B)}\]&lt;p&gt;Explanation: Bayes’ Theorem describes how to update the probability of a hypothesis ($A$) given new evidence ($B$). It’s a cornerstone of probabilistic reasoning and is widely used in machine learning for tasks like classification and inference.&lt;/p&gt;&lt;p&gt;Practical Use: Applied in Naive Bayes classifiers, Bayesian networks, and Bayesian optimization.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;def bayes_theorem(p_d, p_t_given_d, p_t_given_not_d):
    """
    Calculate P(D|T+) using Bayes' Theorem.
    
    Parameters:
    p_d: P(D), probability of having the disease
    p_t_given_d: P(T+|D), probability of testing positive given disease
    p_t_given_not_d: P(T+|D'), probability of testing positive given no disease
    
    Returns:
    P(D|T+), probability of having the disease given a positive test
    """
    p_not_d = 1 - p_d
    p_t = p_t_given_d * p_d + p_t_given_not_d * p_not_d
    p_d_given_t = (p_t_given_d * p_d) / p_t
    return p_d_given_t

# Example usage
p_d = 0.01  # 1% of population has the disease
p_t_given_d = 0.99  # Test is 99% sensitive
p_t_given_not_d = 0.02  # Test has 2% false positive rate
result = bayes_theorem(p_d, p_t_given_d, p_t_given_not_d) 
print(f"P(D|T+) = {result:.4f}")  # Output: P(D|T+) = 0.3333 
&lt;/code&gt;&lt;head rend="h3"&gt;Entropy&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[H(X) = -\sum_{x \in X} P(x) \log P(x)\]&lt;p&gt;Explanation: Entropy measures the uncertainty or randomness in a probability distribution. It quantifies the amount of information required to describe the distribution and is fundamental in understanding concepts like information gain and decision trees.&lt;/p&gt;&lt;p&gt;Practical Use: Used in decision trees, information gain calculations, and as a basis for other information-theoretic measures.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

def entropy(p):
    """
    Calculate entropy of a probability distribution.
    
    Parameters:
    p: Probability distribution array
    
    Returns:
    Entropy value
    """
    return -np.sum(p * np.log(p, where=p &amp;gt; 0))

# Example usage
fair_coin = np.array([0.5, 0.5])  # fair coin has the same probability of heads and tails
print(f"Entropy of fair coin: {entropy(fair_coin)}")  # Output: 0.6931471805599453 

biased_coin = np.array([0.9, 0.1])  # biased coin has a higher probability of heads
print(f"Entropy of biased coin: {entropy(biased_coin)}")  # Output: 0.4698716731013394 
&lt;/code&gt;&lt;head rend="h3"&gt;Joint and Conditional Probability&lt;/head&gt;&lt;p&gt;Equations:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Joint Probability:&lt;/p&gt;\[P(A, B) = P(A|B) P(B) = P(B|A) P(A)\]&lt;/item&gt;&lt;item&gt;&lt;p&gt;Conditional Probability:&lt;/p&gt;\[P(A|B) = \frac{P(A, B)}{P(B)}\]&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Explanation: Joint probability describes the likelihood of two events occurring together, while conditional probability measures the probability of one event given another. These are the building blocks of Bayesian methods and probabilistic models.&lt;/p&gt;&lt;p&gt;Practical Use: Used in Naive Bayes classifiers and probabilistic graphical models.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;from sklearn.naive_bayes import GaussianNB
import numpy as np

X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])
y = np.array([0, 0, 1, 1])
model = GaussianNB().fit(X, y)
print(model.predict([[2.5, 3.5]]))  # Output: [1]
&lt;/code&gt;&lt;head rend="h3"&gt;Kullback-Leibler Divergence (KLD)&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[D_{KL}(P \| Q) = \sum_{x \in \mathcal{X}} P(x) \log \left( \frac{P(x)}{Q(x)} \right)\]&lt;p&gt;Explanation: KLD measures how much one probability distribution $P$ diverges from another $Q$. It’s asymmetric and foundational in information theory and generative models.&lt;/p&gt;&lt;p&gt;Practical Use: Used in variational autoencoders (VAEs) and model evaluation.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

P = np.array([0.7, 0.3])
Q = np.array([0.5, 0.5])
kl_div = np.sum(P * np.log(P / Q))
print(f"KL Divergence: {kl_div}")  # Output: 0.08228287850505156
&lt;/code&gt;&lt;head rend="h3"&gt;Cross-Entropy&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[H(P, Q) = -\sum_{x \in \mathcal{X}} P(x) \log Q(x)\]&lt;p&gt;Explanation: Cross-entropy quantifies the difference between the true distribution $P$ and the predicted distribution $Q$. It’s a widely used loss function in classification.&lt;/p&gt;&lt;p&gt;Practical Use: Drives training in logistic regression and neural networks.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

y_true = np.array([1, 0, 1])
y_pred = np.array([0.9, 0.1, 0.8])
cross_entropy = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))
print(f"Cross-Entropy: {cross_entropy}")  # Output: 0.164252033486018
&lt;/code&gt;&lt;head rend="h2"&gt;Linear Algebra&lt;/head&gt;&lt;p&gt;Linear algebra powers the transformations and structures in ML models.&lt;/p&gt;&lt;head rend="h3"&gt;Linear Transformation&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[y = Ax + b \quad \text{where } A \in \mathbb{R}^{m \times n}, x \in \mathbb{R}^n, y \in \mathbb{R}^m, b \in \mathbb{R}^m\]&lt;p&gt;Explanation: This equation represents a linear mapping of input $x$ to output $y$ via matrix $A$ and bias $b$. It’s the core operation in neural network layers.&lt;/p&gt;&lt;p&gt;Practical Use: Foundational for linear regression and neural networks.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

A = np.array([[2, 1], [1, 3]])
x = np.array([1, 2])
b = np.array([0, 1])
y = A @ x + b
print(y)  # Output: [4 7]
&lt;/code&gt;&lt;head rend="h3"&gt;Eigenvalues and Eigenvectors&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[Av = \lambda v \quad \text{where } \lambda \in \mathbb{R}, v \in \mathbb{R}^n, v \neq 0\]&lt;p&gt;Explanation: Eigenvalues $\lambda$ and eigenvectors $v$ describe how a matrix $A$ scales and rotates space, crucial for understanding data variance.&lt;/p&gt;&lt;p&gt;Practical Use: Used in Principal Component Analysis (PCA).&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

A = np.array([[4, 2], [1, 3]])
eigenvalues, eigenvectors = np.linalg.eig(A)
print(f"Eigenvalues: {eigenvalues}")
print(f"Eigenvectors:\n{eigenvectors}")
&lt;/code&gt;&lt;head rend="h3"&gt;Singular Value Decomposition (SVD)&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[A = U \Sigma V^T\]&lt;p&gt;Explanation: SVD breaks down a matrix $A$ into orthogonal matrices $U$ and $V$ and a diagonal matrix $\Sigma$ of singular values. It reveals the intrinsic structure of data.&lt;/p&gt;&lt;p&gt;Practical Use: Applied in dimensionality reduction and recommendation systems.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

A = np.array([[1, 2], [3, 4], [5, 6]])
U, S, Vt = np.linalg.svd(A)
print(f"U:\n{U}\nS: {S}\nVt:\n{Vt}")
&lt;/code&gt;&lt;head rend="h2"&gt;Optimization&lt;/head&gt;&lt;p&gt;Optimization is how ML models learn from data.&lt;/p&gt;&lt;head rend="h3"&gt;Gradient Descent&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[\theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(\theta)\]&lt;p&gt;Explanation: Gradient descent updates parameters $\theta$ by moving opposite to the gradient of the loss function $L$, scaled by learning rate $\eta$.&lt;/p&gt;&lt;p&gt;Practical Use: The backbone of training most ML models.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

def gradient_descent(X, y, lr=0.01, epochs=1000):
    m, n = X.shape
    theta = np.zeros(n)
    for _ in range(epochs):
        gradient = (1/m) * X.T @ (X @ theta - y)
        theta -= lr * gradient
    return theta

X = np.array([[1, 1], [1, 2], [1, 3]])
y = np.array([1, 2, 3])
theta = gradient_descent(X, y)
print(theta)  # Output: ~[0., 1.]
&lt;/code&gt;&lt;head rend="h3"&gt;Backpropagation&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[\frac{\partial L}{\partial w_{ij}} = \frac{\partial L}{\partial a_j} \cdot \frac{\partial a_j}{\partial z_j} \cdot \frac{\partial z_j}{\partial w_{ij}}\]&lt;p&gt;Explanation: Backpropagation applies the chain rule to compute gradients of the loss $L$ with respect to weights $w_{ij}$ in neural networks.&lt;/p&gt;&lt;p&gt;Practical Use: Enables efficient training of deep networks.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import torch
import torch.nn as nn

model = nn.Sequential(nn.Linear(2, 1), nn.Sigmoid())
loss_fn = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

X = torch.tensor([[0., 0.], [1., 1.]], dtype=torch.float32)
y = torch.tensor([[0.], [1.]], dtype=torch.float32)

optimizer.zero_grad()
output = model(X)
loss = loss_fn(output, y)
loss.backward()
optimizer.step()
print(f"Loss: {loss.item()}")
&lt;/code&gt;&lt;head rend="h2"&gt;Loss Functions&lt;/head&gt;&lt;p&gt;Loss functions measure model performance and guide optimization.&lt;/p&gt;&lt;head rend="h3"&gt;Mean Squared Error (MSE)&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2\]&lt;p&gt;Explanation: MSE calculates the average squared difference between true $y_i$ and predicted $\hat{y}_i$ values, penalizing larger errors more heavily.&lt;/p&gt;&lt;p&gt;Practical Use: Common in regression tasks.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

y_true = np.array([1, 2, 3])
y_pred = np.array([1.1, 1.9, 3.2])
mse = np.mean((y_true - y_pred)**2)
print(f"MSE: {mse}")  # Output: 0.01
&lt;/code&gt;&lt;head rend="h3"&gt;Cross-Entropy Loss&lt;/head&gt;&lt;p&gt;(See Cross-Entropy above for details.)&lt;/p&gt;&lt;head rend="h2"&gt;Advanced ML Concepts&lt;/head&gt;&lt;p&gt;These equations power cutting-edge ML techniques.&lt;/p&gt;&lt;head rend="h3"&gt;Diffusion Process&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon \quad \text{where} \quad \epsilon \sim \mathcal{N}(0, I)\]&lt;p&gt;Explanation: This describes a forward diffusion process where data $x_0$ is gradually noised over time $t$, a key idea in diffusion models.&lt;/p&gt;&lt;p&gt;Practical Use: Used in generative AI like image synthesis.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import torch

x_0 = torch.tensor([1.0])
alpha_t = 0.9
noise = torch.randn_like(x_0)
x_t = torch.sqrt(torch.tensor(alpha_t)) * x_0 + torch.sqrt(torch.tensor(1 - alpha_t)) * noise
print(f"x_t: {x_t}")
&lt;/code&gt;&lt;head rend="h3"&gt;Convolution Operation&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[(f * g)(t) = \int f(\tau) g(t - \tau) \, d\tau\]&lt;p&gt;Explanation: Convolution combines two functions by sliding one over the other, extracting features in data like images.&lt;/p&gt;&lt;p&gt;Practical Use: Core to convolutional neural networks (CNNs).&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import torch
import torch.nn as nn

conv = nn.Conv2d(1, 1, kernel_size=3)
image = torch.randn(1, 1, 28, 28)
output = conv(image)
print(output.shape)  # Output: torch.Size([1, 1, 26, 26])
&lt;/code&gt;&lt;head rend="h3"&gt;Softmax Function&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[\sigma(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}\]&lt;p&gt;Explanation: Softmax converts raw scores $z_i$ into probabilities, summing to 1, ideal for multi-class classification.&lt;/p&gt;&lt;p&gt;Practical Use: Used in neural network outputs.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import numpy as np

z = np.array([1.0, 2.0, 3.0])
softmax = np.exp(z) / np.sum(np.exp(z))
print(f"Softmax: {softmax}")  # Output: [0.09003057 0.24472847 0.66524096]
&lt;/code&gt;&lt;head rend="h3"&gt;Attention Mechanism&lt;/head&gt;&lt;p&gt;Equation:&lt;/p&gt;\[\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{Q K^T}{\sqrt{d_k}} \right) V\]&lt;p&gt;Explanation: Attention computes a weighted sum of values $V$ based on the similarity between queries $Q$ and keys $K$, scaled by $\sqrt{d_k}$.&lt;/p&gt;&lt;p&gt;Practical Use: Powers transformers in NLP and beyond.&lt;/p&gt;&lt;p&gt;Implementation:&lt;/p&gt;&lt;code&gt;import torch

def attention(Q, K, V):
    d_k = Q.size(-1)
    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))
    attn = torch.softmax(scores, dim=-1)
    return torch.matmul(attn, V)

Q = torch.tensor([[1., 0.], [0., 1.]])
K = torch.tensor([[1., 1.], [1., 0.]])
V = torch.tensor([[0., 1.], [1., 0.]])
output = attention(Q, K, V)
print(output)
&lt;/code&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;This blog post has explored the most critical equations in machine learning, from foundational probability and linear algebra to advanced concepts like diffusion and attention. With theoretical explanations, practical implementations, and visualizations, you now have a comprehensive resource to understand and apply ML math. Point anyone asking about core ML math here—they’ll learn 95% of what they need in one place!&lt;/p&gt;&lt;head rend="h2"&gt;Further Reading&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Pattern Recognition and Machine Learning by Christopher Bishop&lt;/item&gt;&lt;item&gt;Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville&lt;/item&gt;&lt;item&gt;Stanford CS229: Machine Learning&lt;/item&gt;&lt;item&gt;PyTorch Tutorials&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chizkidd.github.io//2025/05/30/machine-learning-key-math-eqns/"/></entry><entry><id>https://news.ycombinator.com/item?id=45050958</id><title>GAN Math (2020)</title><updated>2025-08-28T16:12:32.928296+00:00</updated><content>&lt;doc fingerprint="2b939a13243d9bb9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Math Behind GANs&lt;/head&gt;&lt;p&gt;Generative Adversarial Networks refer to a family of generative models that seek to discover the underlying distribution behind a certain data generating process. This distribution is discovered through an adversarial competition between a generator and a discriminator. As we saw in an earlier introductory post on GANs, the two models are trained such that the discriminator strives to distinguish between generated and true examples, while the generator seeks to confuse the discriminator by producing data that are as realistic and compelling as possible.&lt;/p&gt;&lt;p&gt;In this post, we’ll take a deep dive into the math behind GANs. My primary source of reference is Generative Adversarial Nets by Ian Goodfellow, et al. It is in this paper that Goodfellow first outlined the concept of a GAN, which is why it only makes sense that we commence from the analysis of this paper. Let’s begin!&lt;/p&gt;&lt;head rend="h1"&gt;Motivating the Loss Function&lt;/head&gt;&lt;p&gt;GAN can be seen as an interplay between two different models: the generator and the discriminator. Therefore, each model will have its own loss function. In this section, let’s try to motivate an intuitive understanding of the loss function for each.&lt;/p&gt;&lt;head rend="h2"&gt;Notation&lt;/head&gt;&lt;p&gt;To minimize confusion, let’s define some notation that we will be using throughout this post.&lt;/p&gt;\[\begin{multline} \shoveleft x: \text{Real data} \\ \shoveleft z: \text{Latent vector} \\ \shoveleft G(z): \text{Fake data} \\ \shoveleft D(x): \text{Discriminator's evaluation of real data} \\ \shoveleft D(G(z)): \text{Discriminator's evaluation of fake data} \\ \shoveleft \text{Error}(a, b): \text{Error between } a \text{ and } b\\ \end{multline}\]&lt;head rend="h2"&gt;The Discriminator&lt;/head&gt;&lt;p&gt;The goal of the discriminator is to correctly label generated images as false and empirical data points as true. Therefore, we might consider the following to be the loss function of the discriminator:&lt;/p&gt;\[L_D = \text{Error}(D(x), 1) + \text{Error}(D(G(z)), 0) \tag{1}\]&lt;p&gt;Here, we are using a very generic, unspecific notation for $\text{Error}$ to refer to some function that tells us the distance or the difference between the two functional parameters. (If this reminded you of something like cross entropy or Kullback-Leibler divergence, you are definitely on the right track.)&lt;/p&gt;&lt;head rend="h2"&gt;The Generator&lt;/head&gt;&lt;p&gt;We can go ahead and do the same for the generator. The goal of the generator is to confuse the discriminator as much as possible such that it mislabels generated images as being true.&lt;/p&gt;\[L_G = \text{Error}(D(G(z)), 1) \tag{2}\]&lt;p&gt;The key here is to remember that a loss function is something that we wish to minimize. In the case of the generator, it should strive to minimize the difference between 1, the label for true data, and the discriminator’s evaluation of the generated fake data.&lt;/p&gt;&lt;head rend="h2"&gt;Binary Cross Entropy&lt;/head&gt;&lt;p&gt;A common loss function that is used in binary classification problems is binary cross entropy. As a quick review, let’s remind ourselves of what the formula for cross entropy looks like:&lt;/p&gt;\[H(p, q) = \mathbb{E}_{x \sim p(x)}[- \log q(x)] \tag{3}\]&lt;p&gt;In classification tasks, the random variable is discrete. Hence, the expectation can be expressed as a summation.&lt;/p&gt;\[H(p, q) = - \sum_{x \in \chi} p(x) \log q(x) \tag{4}\]&lt;p&gt;We can simplify this expression even further in the case of binary cross entropy, since there are only two labels: zero and one.&lt;/p&gt;\[H(y, \hat{y}) = - \sum y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \tag{5}\]&lt;p&gt;This is the $\text{Error}$ function that we have been loosely using in the sections above. Binary cross entropy fulfills our objective in that it measures how different two distributions are in the context of binary classification of determining whether an input data point is true or false. Applying this to the loss functions in (1),&lt;/p&gt;\[L_D = - \sum_{x \in \chi, z \in \zeta} \log(D(x)) + \log(1 - D(G(z))) \tag{6}\]&lt;p&gt;We can do the same for (2):&lt;/p&gt;\[L_G = - \sum_{z \in \zeta} \log(D(G(z)) \tag{7}\]&lt;p&gt;Now we have two loss functions with which to train the generator and the discriminator! Note that, for the loss function of the generator, the loss is small if $D(G(z))$ is close to 1, since $\log(1) = 0$. This is exactly the sort of behavior we want from a loss function for the generator. It isn’t difficult to see the cogency of (6) with a similar approach.&lt;/p&gt;&lt;head rend="h2"&gt;Minor Caveats&lt;/head&gt;&lt;p&gt;The original paper by Goodfellow presents a slightly different version of the two loss functions derived above.&lt;/p&gt;\[\max_D \{ \log(D(x)) + \log(1-D(G(z))) \} \tag{8}\]&lt;p&gt;Essentially, the difference between (6) and (8) is the difference in sign, and whether we want to minimize or maximize a given quantity. In (6), we framed the function as a loss function to be minimized, whereas the original formulation presents it as a maximization problem, with the sign obviously flipped.&lt;/p&gt;&lt;p&gt;Then, Goodfellow proceeds by framing (8) as a min-max game, where the discriminator seeks to maximize the given quantity whereas the generator seeks to achieve the reverse. In other words,&lt;/p&gt;\[\min_G \max_D \{ \log(D(x)) + \log(1-D(G(z))) \} \tag{9}\]&lt;p&gt;The min-max formulation is a concise one-liner that intuitively demonstrates the adversarial nature of thecompetition between the generator and the discriminator. However, in practice, we define separate loss functions for the generator and the discriminator as we have done above. This is because the gradient of the function $y = \log x$ is steeper near $x = 0$ than that of the function $y = \log (1 - x)$, meaning that trying to maximize $\log(D(G(z)))$, or equivalently, minimizing $- \log(D(G(z)))$ is going to lead to quicker, more substantial improvements to the performance of the generator than trying to minimize $\log(1 - D(G(z)))$.&lt;/p&gt;&lt;head rend="h1"&gt;Model Optimization&lt;/head&gt;&lt;p&gt;Now that we have defined the loss functions for the generator and the discriminator, it’s time to leverage some math to solve the optimization problem, i.e. finding the parameters for the generator and the discriminator such that the loss functions are optimized. This corresponds to training the model in practical terms.&lt;/p&gt;&lt;head rend="h2"&gt;Training the Discriminator&lt;/head&gt;&lt;p&gt;When training a GAN, we typically train one model at a time. In other words, when training the discriminator, the generator is assumed as fixed. We saw this in action in the previous post on how to build a basic GAN.&lt;/p&gt;&lt;p&gt;Let’s return back to the min-max game. The quantity of interest can be defined as a function of $G$ and $D$. Let’s call this the value function:&lt;/p&gt;\[V(G, D) = \mathbb{E}_{x \sim p_{data}}[\log(D(x))] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))] \tag{10}\]&lt;p&gt;In reality, we are more interested in the distribution modeled by the generator than $p_z$. Therefore, let’s create a new variable, $y = G(z)$, and use this substitution to rewrite the value function:&lt;/p&gt;\[\begin{align} V(G, D) &amp;amp;= \mathbb{E}_{x \sim p_{data}}[\log(D(x))] + \mathbb{E}_{y \sim p_g}[\log(1 - D(y))] \\ &amp;amp;= \int_{x \in \chi} p_{data}(x) \log(D(x)) + p_g(x) \log(1 - D(x)) \, dx \end{align} \tag{11}\]&lt;p&gt;The goal of the discriminator is to maximize this value function. Through a partial derivative of $V(G, D)$ with respect to $D(x)$, we see that the optimal discriminator, denoted as $D^*(x)$, occurs when&lt;/p&gt;\[\frac{p_{data}(x)}{D(x)} - \frac{p_g(x)}{1 - D(x)} = 0 \tag{12}\]&lt;p&gt;Rearranging (12), we get&lt;/p&gt;\[D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \tag{12}\]&lt;p&gt;And this is the condition for the optimal discriminator! Note that the formula makes intuitive sense: if some sample $x$ is highly genuine, we would expect $p_{data}(x)$ to be close to one and $p_g(x)$ to be converge to zero, in which case the optimal discriminator would assign 1 to that sample. On the other hand, for a generated sample $x = G(z)$, we expect the optimal discriminator to assign a label of zero, since $p_{data}(G(z))$ should be close to zero.&lt;/p&gt;&lt;head rend="h2"&gt;Training the Generator&lt;/head&gt;&lt;p&gt;To train the generator, we assume the discriminator to be fixed and proceed with the analysis of the value function. Let’s first plug in the result we found above, namely (12), into the value function to see what turns out.&lt;/p&gt;\[\begin{align} V(G, D^*) &amp;amp;= \mathbb{E}_{x \sim p_{data}}[\log(D^*(x))] + \mathbb{E}_{x \sim p_g}[\log(1 - D^*(x))] \\ &amp;amp;= \mathbb{E}_{x \sim p_{data}} \left[ \log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \right] + \mathbb{E}_{x \sim p_g} \left[ \log \frac{p_g(x)}{p_{data}(x) + p_g(x)} \right] \end{align} \tag{13}\]&lt;p&gt;To proceed from here, we need a little bit of inspiration. Little clever tricks like these are always a joy to look at.&lt;/p&gt;\[\begin{align} V(G, D^*) &amp;amp;= \mathbb{E}_{x \sim p_{data}} \left[ \log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \right] + \mathbb{E}_{x \sim p_g} \left[ \log \frac{p_g(x)}{p_{data}(x) + p_g(x)} \right] \\ &amp;amp;= - \log 4 + \mathbb{E}_{x \sim p_{data}} \left[ \log p_{data}(x) - \log \frac{p_{data}(x) + p_g(x))}{2} \right] \\ &amp;amp; \quad+ \mathbb{E}_{x \sim p_g} \left[ \log p_g(x) - \log\frac{p_{data}(x) + p_g(x))}{2} \right] \end{align} \tag{14}\]&lt;p&gt;If you are confused, don’t worry, you aren’t the only one. Basically, what is happening is that we are exploiting the properties of logarithms to pull out a $- \log4$ that previously did not exist. In pulling out this number, we inevitably apply changes to the terms in the expectation, specifically by dividing the denominator by two.&lt;/p&gt;&lt;p&gt;Why was this necessary? The magic here is that we can now interpret the expectations as Kullback-Leibler divergence:&lt;/p&gt;\[V(G, D^*) = - \log 4 + D_{KL}\left(p_{data} \parallel \frac{p_{data} + p_g}{2} \right) + D_{KL}\left(p_g \parallel \frac{p_g + p_g}{2} \right) \tag{15}\]&lt;p&gt;And it is here that we reencounter the Jensen-Shannon divergence, which is defined as&lt;/p&gt;\[J(P,Q) = \frac{1}{2} \left( D(P \parallel R) + D(Q \parallel R) \right) \tag{16}\]&lt;p&gt;where $R = \frac12(P + Q)$. This means that the expression in (15) can be expressed as a JS divergence:&lt;/p&gt;\[V(G, D^*) = - \log 4 + 2 \cdot D_{JS}(p_{data} \parallel p_g) \tag{15}\]&lt;p&gt;The conclusion of this analysis is simple: the goal of training the generator, which is to minimize the value function $V(G, D)$, we want the JS divergence between the distribution of the data and the distribution of generated examples to be as small as possible. This conclusion certainly aligns with our intuition: we want the generator to be able to learn the underlying distribution of the data from sampled training examples. In other words, $p_g$ and $p_{data}$ should be as close to each other as possible. The optimal generator $G$ is thus one that which is able to mimic $p_{data}$ to model a compelling model distribution $p_g$.&lt;/p&gt;&lt;head rend="h1"&gt;Conclusion&lt;/head&gt;&lt;p&gt;In this post, we took a brief tour of the math behind general adversarial networks. Since the publication of Goodfellow’s work, more GAN models have been introduced and studied by different scholars, such as the Wasserstein GAN or CycleGAN to name just a few. The underlying mathematics for these models are obviously going to be different from what we have seen today, but this is a good starting point nonetheless.&lt;/p&gt;&lt;p&gt;I hope you enjoyed reading this post. In the next post, I plan to explore the concept of Fisher information and the Fisher matrix. It is going to be another math-heavy ride with gradients and Hessians, so keep you belts fastened!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jaketae.github.io/study/gan-math/"/></entry><entry><id>https://news.ycombinator.com/item?id=45051034</id><title>The startup bubble that no one is talking about</title><updated>2025-08-28T16:12:32.690735+00:00</updated><content>&lt;doc fingerprint="2e1583416b211686"&gt;
  &lt;main&gt;
    &lt;p&gt;Figure 1&lt;/p&gt;
    &lt;p&gt;Above is a graph that displays the amount of Form Ds filed, where the entity (read: company/firm) name contains the phrases "fund I", "fund II", "fund III", and "fund IV". The x-axis is not the prettiest, but it is broken down by quarter. You can see that the line for "fund I" sees by far the greatest peak around quarter 3 of 2022, with a steep drop off immediately after. The other lines have a similar, but less pronounced trend.&lt;/p&gt;
    &lt;p&gt;So, what is the significance of this? Companies and firms file Form Ds in compliance with Regulation D, which requires disclosure when raising funds under specific circumstances. I won't go into the details here, but the TLDR is that it isn't always required, but it's not uncommon either. Another piece of context is that venture capital firms (among other financial investment groups) label their individual funds, often by appending Fund [&amp;lt;fund roman numeral&amp;gt;] to describe where the fund falls in their sequence of funds. Here is a search query on the SEC filings database. You can see how the naming convention works. Each fund often constitutes its own entity. My hypothesis here is that, by charting the amount of Form Ds filed with "fund [#]" in the name, we can roughly see the state of venture capital “fund” raising.&lt;/p&gt;
    &lt;p&gt;My Takeaways&lt;/p&gt;
    &lt;p&gt;1. From this graph we can roughly see the ratio of venture firms that make it to a given fund cycle. That's a little hard to claim as the funds get higher in number, because once firms get large enough, they often stop creating sequential funds, instead raising in parallel and creating funds targeting specific industries/products etc. If you are planning to start a venture firm though, you may gain a bit of insight into your odds of longevity.&lt;/p&gt;
    &lt;p&gt;2. Venture funding is about to drop off BIG time.&lt;/p&gt;
    &lt;p&gt;During the early 2020s, everyone and their mom raised a VC fund. This is due to several factors&lt;/p&gt;
    &lt;p&gt;Figure 2&lt;/p&gt;
    &lt;p&gt;Note that I estimated these values by looking at similarities matching entities listed on the Forms that were also associated with Angellist/Sydecar/other fund backend providers.&lt;/p&gt;
    &lt;p&gt;These groups likely also contribute to the fluffing of the venture economy by increasing access to investments in startups*.&lt;/p&gt;
    &lt;p&gt;As interest rates increased, and things settled down, the amount of venture firms raising new funds decrease, as evidenced by the decrease in Form Ds with “fund [#]” in the name after Q3 2022 shown in figure 2.&lt;/p&gt;
    &lt;p&gt;Why we are going to see the effects of the bubble now&lt;/p&gt;
    &lt;p&gt;Making the assumptions that a) most venture funds target a life span of ~10 years and b) the capital deployment stage of funds lasts 2-4 years (again, roughly), we are just passing the moment of peak fund availability.&lt;/p&gt;
    &lt;p&gt;This has all coincided nicely with an immense increase in expectations put on startups focused on AI solutions. Investor interest in wrapper/agent/AI lab companies has seemed insatiable over the past 18 months, in alignment with the end of the funding deployment stage for funds that raised at the peak. This has led to more startups raising rounds at higher valuations (see another keyword search based graph below).&lt;/p&gt;
    &lt;p&gt;My predictions, based on the above data, and my anecdotal experience is that the amount of venture funding available is about to decrease. This will lead to lower valuations as the supply of funds decreases, inducing relative scarcity. As a result many companies will be left “swimming naked as that tide goes out”. This along with other issues such as (very) newly decreasing expectations of the AI vertical as a whole could lead to a sizable contraction. The decrease in available funding will also put more pressure on companies to actually ** make money **. Unless compute becomes much more cost effective in the immediate future, foundational model providers will be required to raise their prices to supplement equity based funding for compute cost, likely causing wrappers and agent companies to do the same. Some users will be priced out, and likely, many companies will no longer be viable.&lt;/p&gt;
    &lt;p&gt;All this to say: A future contraction may not be the exclusive result of changing sentiment in the AI industry. Sure that's part of it, but the availability of VC funds has been destined to decrease since firm fundraising peaked in 2022.&lt;/p&gt;
    &lt;p&gt;Figure 3&lt;/p&gt;
    &lt;p&gt;The offering amount represents the sum of all “total offering amounts” listed on all Form Ds containing “ ai” or “.ai” in the entity names for a given quarter. Note: 2025 sees a dip because only quarters 1 and 2 are accounted for.&lt;/p&gt;
    &lt;p&gt;TJ Jefferson&lt;/p&gt;
    &lt;p&gt;*As a sidenote I do think these services offer ways to anonymize funding sources, and allow potentially less savvy investors (God forbid, unaccredited) to be duped into investing at insanely high valuations.&lt;/p&gt;
    &lt;p&gt;Figure 4&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tj401.com/blog/formd/index.html"/></entry><entry><id>https://news.ycombinator.com/item?id=45051096</id><title>Prosper AI (YC S23) Is Hiring Founding Account Executives (NYC)</title><updated>2025-08-28T16:12:32.579873+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jobs.ashbyhq.com/prosper-ai/29684590-4cec-4af2-bb69-eb5c6d595fb8"/></entry><entry><id>https://news.ycombinator.com/item?id=45051188</id><title>Rendering a Game in Real-Time with AI</title><updated>2025-08-28T16:12:32.313596+00:00</updated><content/><link href="https://blog.jeffschomay.com/rendering-a-game-in-real-time-with-ai"/></entry><entry><id>https://news.ycombinator.com/item?id=45051542</id><title>GPUPrefixSums – state of the art GPU prefix sum algorithms</title><updated>2025-08-28T16:12:31.504072+00:00</updated><content>&lt;doc fingerprint="531d823dc7305afd"&gt;
  &lt;main&gt;
    &lt;p&gt;GPUPrefixSums aims to bring state-of-the-art GPU prefix sum techniques from CUDA and make them available in portable compute shaders. In addition to this, it contributes "Decoupled Fallback," a novel fallback technique for Chained Scan with Decoupled Lookback that should allow devices without forward thread progress guarantees to perform the scan without crashing. The D3D12 implementation includes an extensive survey of GPU prefix sums, ranging from the warp to the device level; all included algorithms utilize wave/warp/subgroup (referred to as "wave" hereon) level parallelism but are completely agnostic of wave size. As a measure of the quality of the code, GPUPrefixSums has also been implemented in CUDA and benchmarked against Nvidia's CUB library. Although GPUPrefixSums aims to be portable to any wave size supported by HLSL, [4, 128], due to hardware limitations, it has only been tested on wave sizes 4, 16, 32, and 64. You have been warned!&lt;/p&gt;
    &lt;p&gt;If you are interested in prefix sums for their use in radix sorting, check out GPUPrefixSum's sibling repository GPUSorting!&lt;/p&gt;
    &lt;p&gt;In Decoupled Fallback, a threadblock will spin for a set amount of cycles while waiting for the reduction of a preceding partition tile. If the maximum spin count is exceeded, the threadblock is free to perform a fallback operation. Multiple thread blocks are allowed to perform fallbacks on the same deadlocking tile, but through use of atomic compare and swap, only one thread block ends up broadcasting its reduction in device memory. Although this means potentially performing redundant calculations, the upside is that fallback performance is no longer limited by the latency of signal propagation between thread blocks.&lt;/p&gt;
    &lt;p&gt;As of writing this 9/22/2024, Decoupled Fallback shows promising results on Apple M GPU's. However the version included here are out of date, with the most up-to-date development occuring in Vello.&lt;/p&gt;
    &lt;p&gt;A prefix sum, also called a scan, is a running total of a sequence of numbers at the n-th element. If the prefix sum is inclusive the n-th element is included in that total, if it is exclusive, the n-th element is not included. The prefix sum is one of the most important algorithmic primitives in parallel computing, underpinning everything from sorting, to compression, to graph traversal.&lt;/p&gt;
    &lt;p&gt;Headless implementation in D3D12, includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce then Scan&lt;/item&gt;
      &lt;item&gt;Chained Scan with Decoupled Lookback&lt;/item&gt;
      &lt;item&gt;Chained Scan with Decoupled Lookback Decoupled Fallback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Visual Studio 2019 or greater&lt;/item&gt;
      &lt;item&gt;Windows SDK 10.0.20348.0 or greater&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The repository folder contains a Visual Studio 2019 project and solution file. Upon building the solution, NuGet will download and link the following external dependencies:&lt;/p&gt;
    &lt;p&gt;See the repository wiki for information on running tests.&lt;/p&gt;
    &lt;p&gt;GPUPrefixSumsCUDA includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce then Scan&lt;/item&gt;
      &lt;item&gt;Chained Scan with Decoupled Lookback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The purpose of this implementation is to benchmark the algorithms and demystify their implementation in the CUDA environment. It is not intended for production or use; instead, a proper implementation can be found in the CUB library.&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Visual Studio 2019 or greater&lt;/item&gt;
      &lt;item&gt;Windows SDK 10.0.20348.0 or greater&lt;/item&gt;
      &lt;item&gt;CUDA Toolkit 12.3.2&lt;/item&gt;
      &lt;item&gt;Nvidia Graphics Card with Compute Capability 7.x or greater.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The repository folder contains a Visual Studio 2019 project and solution file; there are no external dependencies besides the CUDA toolkit. The use of sync primitives necessitates Compute Capability 7.x or greater. See the repository wiki for information on running tests.&lt;/p&gt;
    &lt;p&gt;Released as a Unity package includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce then Scan&lt;/item&gt;
      &lt;item&gt;Chained Scan with Decoupled Lookback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unity 2021.3.35f1 or greater&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Within the Unity package manager, add a package from git URL and enter:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;https://github.com/b0nes164/GPUPrefixSums.git?path=/GPUPrefixSumsUnity&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;See the repository wiki for information on running tests.&lt;/p&gt;
    &lt;p&gt;Barebones implementation--no vectorization, no wave intrinsics--to be used as a testbed.&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;wgpu 22.0&lt;/item&gt;
      &lt;item&gt;pollster 0.3&lt;/item&gt;
      &lt;item&gt;bytemuck 1.16.3&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Duane Merrill and Michael Garland. “Single-pass Parallel Prefix Scan with De-coupled Lookback”. In: 2016. url: https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back&lt;/p&gt;
    &lt;p&gt;Grimshaw, Andrew S. and Duane Merrill. “Parallel Scan for Stream Architectures.” (2012). url: https://libraopen.lib.virginia.edu/downloads/6t053g00z&lt;/p&gt;
    &lt;p&gt;Matt Pettineo. GPU Memory Pools in D3D12. Jul. 2022. url: https://therealmjp.github.io/posts/gpu-memory-pool/&lt;/p&gt;
    &lt;p&gt;Ralph Levien. Prefix sum on portable compute shaders. Nov. 2021. url: https://raphlinus.github.io/gpu/2021/11/17/prefix-sum-portable.html&lt;/p&gt;
    &lt;p&gt;Tyler Sorensen, Hugues Evrard, and Alastair F. Donaldson. “GPU Schedulers: How Fair Is Fair Enoughl”. In: 29th International Conference on Concurrency Theory (CONCUR 2018). Ed. by Sven Schewe and Lijun Zhang. Vol. 118. Leibniz International Proceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, 2018, 23:1–23:17. isbn: 978-3-95977-087-3. doi: 10.4230/LIPIcs.CONCUR.2018.23. url: http://drops.dagstuhl.de/opus/volltexte/2018/9561.&lt;/p&gt;
    &lt;p&gt;Vasily Volkov. “Understanding Latency Hiding on GPUs”. PhD thesis. EECS Department, University of California, Berkeley, Aug. 2016. url: http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.html&lt;/p&gt;
    &lt;p&gt;Zhe Jia et al. Dissecting the NVidia Turing T4 GPU via Microbenchmarking. 2019. arXiv: 1903.07486. url: https://arxiv.org/abs/1903.07486&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/b0nes164/GPUPrefixSums"/></entry><entry><id>https://news.ycombinator.com/item?id=45052429</id><title>How to Install TrueNAS on a Raspberry Pi</title><updated>2025-08-28T16:12:31.290754+00:00</updated><content>&lt;doc fingerprint="df4b0b5709831eec"&gt;
  &lt;main&gt;
    &lt;p&gt;Now that Joel0 in the TrueNAS community has created a fork of TrueNAS that runs on Arm, I thought I'd give it a spin—on a Raspberry Pi.&lt;/p&gt;
    &lt;p&gt;I currently run an Ampere Arm server in my rack with Linux and ZFS as my primary storage server, and a Raspberry Pi with four SATA SSDs and ZFS as backup replica in my studio. My configuration for these Arm NASes is up on GitHub.&lt;/p&gt;
    &lt;p&gt;I've been looking forward to TrueNAS support on Arm for years, though it seems the sentiment in that community was 'Arm servers aren't powerful enough to run serious storage servers'—despite myself and many others doing so for many years... but that's besides the point.&lt;/p&gt;
    &lt;head rend="h2"&gt;On a Raspberry Pi?&lt;/head&gt;
    &lt;p&gt;Yes, in fact.&lt;/p&gt;
    &lt;p&gt;I've found numerous times, running modern applications on slower hardware is an excellent way to expose little configuration flaws and misconceptions that lead to learning how to run the applications much better on more capable machines.&lt;/p&gt;
    &lt;p&gt;From my Pi Dramble to my Petabyte Pi Project, running apps intended for much more powerful hardware taught me a lot. So maybe running TrueNAS, which demands 8 GB of RAM and 16 GB of primary storage, would be a fun learning exercise.&lt;/p&gt;
    &lt;p&gt;I've done it on x86 servers, but that's boring. It's easy. I don't learn much when a project goes off without a hitch, and I'm not forced to look closer at some of the configuration quirks.&lt;/p&gt;
    &lt;p&gt;You can watch the video for a full demo, or read on below:&lt;/p&gt;
    &lt;head rend="h2"&gt;On a Raspberry Pi, there's no UEFI&lt;/head&gt;
    &lt;p&gt;One glaring problem with the Raspberry Pi is no official support for UEFI, a standard way to boot computers and interface operating systems to device firmware. Raspberry Pi only officially supports device-tree-based Linux booting, which is much less standard. That means you can't just throw any old Linux distribution on the Pi, you have to have ones tailored to the Pi. There are good OSes for the Pi, like Raspberry Pi OS, based on Debian. But it's not the same as grabbing Windows on Arm and installing it on my Ampere workstation.&lt;/p&gt;
    &lt;p&gt;To get past this restriction, we have to rely on a community project, forked from Windows on Raspberry Pi. Specifically, I'm using NumberOneGit's rpi5-uefi fork.&lt;/p&gt;
    &lt;p&gt;To get your Pi 5 to support UEFI (CM5 process may be slightly different):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Update the EEPROM to the 2025-06-09 release (or later - check what version you're running in Pi OS with the command &lt;code&gt;rpi-eeprom-update&lt;/code&gt;): a. Typically, you can upgrade using Raspberry Pi Imager,&lt;code&gt;sudo apt full-upgrade -y&lt;/code&gt;, or&lt;code&gt;sudo rpi-eeprom-update -a&lt;/code&gt;. However, at the time of this writing, those methods will get you to the latest stable release (2025-05-08), so until then, use one of these methods: b. Manually update the bootloader with&lt;code&gt;usbboot&lt;/code&gt;from source. c. Switch to the beta bootloader release channel:&lt;code&gt;sudo nano /etc/default/rpi-eeprom-update&lt;/code&gt;, then change&lt;code&gt;latest&lt;/code&gt;to&lt;code&gt;beta&lt;/code&gt;, and run&lt;code&gt;sudo rpi-eeprom-update -a&lt;/code&gt;. d. Verify the bootloader version you're running with&lt;code&gt;rpi-eeprom-update&lt;/code&gt;after a reboot.&lt;/item&gt;
      &lt;item&gt;Download the latest .zip file release from rpi5-uefi Releases.&lt;/item&gt;
      &lt;item&gt;Take a microSD card that's already formatted for the Pi (I just pulled the Pi OS card out of my Pi 5 that I just used for the EEPROM update), and clear out the contents of the FAT32 'bootfs' volume. Copy all the contents of the .zip file you downloaded into that folder (including &lt;code&gt;RPI_EFI.fd&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Eject the microSD card, insert it into the Pi, and power it on with an HDMI display connected.&lt;/item&gt;
      &lt;item&gt;You should see a Raspberry Pi logo and the EDK2 bootloader screen appear. Unless you have NVMe or USB boot media installed, it will say "Press any key to enter the Boot Manager Menu."&lt;/item&gt;
      &lt;item&gt;Since I couldn't find the 'any' key, I pressed 'Enter', then I could navigate through a standard boot manager menu. In there you can configure SD card speeds, set the PCIe bus speed, etc.&lt;/item&gt;
      &lt;item&gt;After you've changed the settings to your liking (see some suggestions for Linux), save and reset.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;TrueNAS on a Pi 5&lt;/head&gt;
    &lt;p&gt;Now that the Pi is booting into UEFI mode, you can install TrueNAS. To do that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download a TrueNAS on Arm ISO from https://truenas-releases.jmay.us (I chose 25.04.2).&lt;/item&gt;
      &lt;item&gt;Use a tool like Etcher to write the ISO to a USB drive.&lt;/item&gt;
      &lt;item&gt;After Etcher finishes, eject the USB drive and insert it into the Pi (I used a USB 3 thumb drive, so I inserted it into one of the blue USB 3 ports on the Pi for maximum speed).&lt;/item&gt;
      &lt;item&gt;If it doesn't automatically boot to the TrueNAS installer, select the external USB drive in the UEFI boot manager and boot into the TrueNAS installer.&lt;/item&gt;
      &lt;item&gt;Follow the TrueNAS installer's prompts to install TrueNAS on any device other than the installer drive or the microSD card (I used a second USB flash drive plugged into the other USB 3 port). Wait for installation to complete.&lt;/item&gt;
      &lt;item&gt;When prompted, reboot and remove the USB drive.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TrueNAS SCALE should boot up, and the first boot can take a while as many services need to generate files, configure services, and start them the first time.&lt;/p&gt;
    &lt;p&gt;In my case, on first boot, the &lt;code&gt;ix-etc&lt;/code&gt; service failed to start (it timed out), and its purpose is to &lt;code&gt;Generate TrueNAS /etc files&lt;/code&gt;. After booting, I chose to enter the Linux console, then ran &lt;code&gt;systemctl start ix-etc&lt;/code&gt;, and rebooted.&lt;/p&gt;
    &lt;p&gt;After a reboot, TrueNAS seemed to launch all its services without issue, including the web UI. I visited the IP address printed on the console, logged in as the admin user I set up during install, and was greeted with the TrueNAS dashboard:&lt;/p&gt;
    &lt;head rend="h2"&gt;Current Limitations&lt;/head&gt;
    &lt;p&gt;Right now, most of the limitations are around missing features in UEFI mode; since Raspberry Pi hasn't pushed RP1 support into the Linux kernel, and nobody's yet reverse-engineered RP1 interfaces, you can't use:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fan header PWM support (no fan control)&lt;/item&gt;
      &lt;item&gt;CSI/DSI connections for displays/cameras&lt;/item&gt;
      &lt;item&gt;GPIO&lt;/item&gt;
      &lt;item&gt;Built-in Ethernet&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Ethernet limitation is especially annoying, as you are forced to use an external USB Ethernet dongle, just like on most non-Qualcomm systems running Windows on Arm.&lt;/p&gt;
    &lt;p&gt;Andrea della Porta from SUSE is working on upstreaming RP1 support into Linux with some help from Raspberry Pi, but progress has been a bit slow.&lt;/p&gt;
    &lt;p&gt;What I've been wondering lately, more and more: why doesn't Raspberry Pi consider official UEFI support in the first place? With or without Microsoft's official blessing, being able to boot vanilla Windows 11 for Arm on the Pi would be neat. Not to mention, any regular Linux Arm distro (including TrueNAS SCALE) would boot too...&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;I recently received a new hardware project, the Homelabs Pi Storage server, which uses a custom CM5 SATA backplane and a 3D printable enclosure for a 6-bay NAS:&lt;/p&gt;
    &lt;p&gt;I got TrueNAS installed on a CM5 Lite (using the same process as above), but when I installed four SATA hard drives, they spun up, but were not recognized. Right now the Pi 5 UEFI support doesn't allow for more than one PCIe device, and the Homelabs Pi Storage server has a PCIe switch that branches off to 2.5 Gbps Ethernet and a 6-port SATA controller.&lt;/p&gt;
    &lt;p&gt;These devices all work perfectly out of the box on Raspberry Pi OS (and I was able to set up a ZFS array, getting 250 MB/s over the built-in 2.5G Ethernet—see below), but they aren't recognized currently when running under UEFI :(&lt;/p&gt;
    &lt;p&gt;I'm already running vanilla ZFS under Raspberry Pi OS on my other Raspberry Pi storage server, and that's running on four SSDs and no hard drives. It can sustain 200 MB/sec writes, and I presume TrueNAS would be able to do the same.&lt;/p&gt;
    &lt;p&gt;There are also NVMe-only boards, like the $50 GeeekPi N16 Quad-NVMe HAT, which provide a pretty small footprint all-flash server option. But again, since those boards use switch chips (because the Pi is limited to 1 PCIe lane), none of those drives would be accessible to TrueNAS as it stands today. Your best bet if you want to use TrueNAS instead of just managing ZFS on you own on a Pi would be to use a single-purpose HAT or SATA controller or HBA in IT mode, to connect disks directly to the Pi.&lt;/p&gt;
    &lt;p&gt;Because of the current UEFI limitations, I would still recommend running TrueNAS on higher-end Arm hardware (like Ampere servers). If you want to stick to an SBC, there's UEFI firmware for RK3588 platforms under active development. It may offer even more functionality for some boards, so check the compatibility list.&lt;/p&gt;
    &lt;p&gt;Or you could be boring and just install TrueNAS on x86, where it's fully supported ;)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jeffgeerling.com/blog/2025/how-install-truenas-on-raspberry-pi"/></entry><entry><id>https://news.ycombinator.com/item?id=45053040</id><title>Mosh (Mobile Shell)</title><updated>2025-08-28T16:12:30.690077+00:00</updated><content>&lt;doc fingerprint="f6d8dd1879200985"&gt;
  &lt;main&gt;&lt;p&gt;Remote terminal application that allows roaming, supports intermittent connectivity, and provides intelligent local echo and line editing of user keystrokes.&lt;/p&gt;&lt;p&gt;Mosh is a replacement for interactive SSH terminals. It's more robust and responsive, especially over Wi-Fi, cellular, and long-distance links.&lt;/p&gt;&lt;p&gt;Mosh is free software, available for GNU/Linux, BSD, macOS, Solaris, Android, Chrome, and iOS.&lt;/p&gt;&lt;p&gt;Mosh automatically roams as you move between Internet connections. Use Wi-Fi on the train, Ethernet in a hotel, and LTE on a beach: you'll stay logged in. Most network programs lose their connections after roaming, including SSH and Web apps like Gmail. Mosh is different.&lt;/p&gt;&lt;p&gt;With Mosh, you can put your laptop to sleep and wake it up later, keeping your connection intact. If your Internet connection drops, Mosh will warn you — but the connection resumes when network service comes back.&lt;/p&gt;&lt;p&gt;SSH waits for the server's reply before showing you your own typing. That can make for a lousy user interface. Mosh is different: it gives an instant response to typing, deleting, and line editing. It does this adaptively and works even in full-screen programs like emacs and vim. On a bad connection, outstanding predictions are underlined so you won't be misled.&lt;/p&gt;&lt;p&gt;You don't need to be the superuser to install or run Mosh. The client and server are executables run by an ordinary user and last only for the life of the connection.&lt;/p&gt;&lt;p&gt;Mosh doesn't listen on network ports or authenticate users. The mosh client logs in to the server via SSH, and users present the same credentials (e.g., password, public key) as before. Then Mosh runs the mosh-server remotely and connects to it over UDP.&lt;/p&gt;&lt;p&gt;Mosh is a command-line program, like ssh. You can use it inside xterm, gnome-terminal, urxvt, Terminal.app, iTerm, emacs, screen, or tmux. But mosh was designed from scratch and supports just one character set: UTF-8. It fixes Unicode bugs in other terminals and in SSH.&lt;/p&gt;&lt;p&gt;Unlike SSH, mosh's UDP-based protocol handles packet loss gracefully, and sets the frame rate based on network conditions. Mosh doesn't fill up network buffers, so Control-C always works to halt a runaway process.&lt;/p&gt;&lt;p&gt;The Mosh package should be installed on both the client and server. Please find your platform below for installation instructions.&lt;/p&gt;&lt;p&gt;This is a standalone OS X package that will work on any supported Macintosh. However, if you are using a package manager such as Homebrew or MacPorts, we suggest using it to get Mosh, for better compatibility and automatic updates.&lt;/p&gt;&lt;p&gt;There is no "native" mosh executable for Windows available at this time. The Chrome version of Mosh is the easiest way to use mosh on Windows.&lt;/p&gt;&lt;quote&gt;C:\&amp;gt; setup.exe -q mosh&lt;/quote&gt;&lt;p&gt;Mosh on Cygwin uses OpenSSH and is suitable for Windows users with advanced SSH configurations. &lt;lb/&gt; Mosh is not compatible with Cygwin's built-in Windows Console terminal emulation. You will need to run Mosh from a full-featured terminal program such as mintty, rxvt, PuTTY, or an X11 terminal emulator.&lt;/p&gt;&lt;quote&gt;$ sudo apt-get install mosh&lt;/quote&gt;&lt;p&gt;The ppa:keithw/mosh-dev PPA tracks the development version of Mosh.&lt;/p&gt;&lt;p&gt;Operating system logos are trademarks or registered trademarks and are displayed for identification only. The vendors shown aren't affiliated with and haven't endorsed Mosh.&lt;/p&gt;&lt;p&gt;Extract mosh-1.4.0.tar.gz (SHA-256 in signed release announcement), then&lt;/p&gt;&lt;quote&gt;$ cd mosh-1.4.0 $ ./configure $ make # make install&lt;/quote&gt;&lt;quote&gt;$ git clone https://github.com/mobile-shell/mosh $ cd mosh $ ./autogen.sh $ ./configure $ make # make install&lt;/quote&gt;&lt;code&gt;debian/control&lt;/code&gt; (in Git) includes an authoritative list of build dependencies.
          &lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Name&lt;/cell&gt;&lt;cell role="head"&gt;Typical package&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Perl (5.14 or newer)&lt;/cell&gt;&lt;cell&gt;perl&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Protocol Buffers&lt;/cell&gt;&lt;cell&gt;protobuf-compiler, libprotobuf-dev&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;ncurses&lt;/cell&gt;&lt;cell&gt;libncurses5-dev&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;zlib&lt;/cell&gt;&lt;cell&gt;zlib1g-dev&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;utempter (optional)&lt;/cell&gt;&lt;cell&gt;libutempter-dev&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;OpenSSL&lt;/cell&gt;&lt;cell&gt;libssl-dev&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;code&gt;pkg-config&lt;/code&gt; is a build-only dependency on most systems.
        &lt;p&gt; Note that &lt;code&gt;mosh-client&lt;/code&gt; receives an AES session key as an environment
              variable.  If you are porting Mosh to a new operating system, please make sure that a
              running process's environment variables are not readable by other users.  We have
              confirmed that this is the case on GNU/Linux, OS X, and FreeBSD.
            &lt;/p&gt;&lt;quote&gt;$ mosh chewbacca.norad.mil&lt;/quote&gt;&lt;p&gt;Mosh will log the user in via SSH, then start a connection on a UDP port between 60000 and 61000.&lt;/p&gt;&lt;quote&gt;$ mosh potus@ackbar.bls.gov&lt;/quote&gt;&lt;quote&gt;$ mosh --server=/tmp/mosh-server r2d2&lt;/quote&gt;&lt;p&gt;The user can specify an alternate path for the &lt;code&gt;mosh-server&lt;/code&gt; on the remote host. The server binary can even
        be installed in the user's home directory.&lt;/p&gt;&lt;quote&gt;$ mosh -p 1234 darth&lt;/quote&gt;&lt;p&gt;Useful when the server is behind a port-forwarder or NAT.&lt;/p&gt;&lt;quote&gt;$ mosh --ssh="ssh -p 2222" figrindan&lt;/quote&gt;&lt;quote&gt;$ mosh --ssh="~/bin/ssh -i ./identity" fett&lt;/quote&gt;&lt;quote&gt;$ mosh --predict=never niennunb&lt;/quote&gt;&lt;p&gt;The &lt;code&gt;-n&lt;/code&gt; switch is a synonym. By contrast,
      passing &lt;code&gt;--predict=always&lt;/code&gt; or &lt;code&gt;-a&lt;/code&gt;
      will enable instant local echo even on low-delay
      links.&lt;/p&gt;&lt;quote&gt;$ mosh pello -- screen -dr&lt;/quote&gt;&lt;p&gt;This reattaches to a long-running screen session.&lt;/p&gt;&lt;p&gt;Normally, logout or exit on the remote host will close the session. Mosh accepts the escape sequence &lt;code&gt;Ctrl-^
    .&lt;/code&gt;  (typically typed with Control-Shift-6, then a
    period) to end the connection forcibly. To send a
    literal Ctrl-^, type &lt;code&gt;Ctrl-^ ^&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;More details can be found in the &lt;code&gt;mosh(1)&lt;/code&gt;, &lt;code&gt;mosh-client(1)&lt;/code&gt;,
  and &lt;code&gt;mosh-server(1)&lt;/code&gt; manual pages.&lt;/p&gt;&lt;p&gt;The Mosh research paper describes the design and evaluation of Mosh in more detail than you may want. The paper was presented at the 2012 USENIX Annual Technical Conference, held June 13–15, 2012, in sunny Boston, Mass.&lt;/p&gt;&lt;p&gt;In addition, the Mosh: A State-of-the-Art Good Old-Fashioned Mobile Shell essay gives further information about the design principles behind Mosh, including the "prophylactic retransmission" technique. The essay was published in USENIX ;login: magazine, August 2012.&lt;/p&gt;&lt;p&gt;(Why you should trust Mosh with your remote terminal needs: we worry about details so obscure, even USENIX reviewers don't want to hear about them.)&lt;/p&gt;&lt;p&gt;Remote-shell protocols traditionally work by conveying a byte-stream from the server to the client, to be interpreted by the client's terminal. (This includes TELNET, RLOGIN, and SSH.) Mosh works differently and at a different layer. With Mosh, the server and client both maintain a snapshot of the current screen state. The problem becomes one of state-synchronization: getting the client to the most recent server-side screen as efficiently as possible.&lt;/p&gt;&lt;p&gt;This is accomplished using a new protocol called the State Synchronization Protocol, for which Mosh is the first application. SSP runs over UDP, synchronizing the state of any object from one host to another. Datagrams are encrypted and authenticated using AES-128 in OCB3 mode. While SSP takes care of the networking protocol, it is the implementation of the object being synchronized that defines the ultimate semantics of the protocol.&lt;/p&gt;&lt;p&gt;Roaming with SSP becomes easy: the client sends datagrams to the server with increasing sequence numbers, including a "heartbeat" at least once every three seconds. Every time the server receives an authentic packet from the client with a sequence number higher than any it has previously received, the IP source address of that packet becomes the server's new target for its outgoing packets. By doing roaming “statelessly” in this manner, roaming works in and out of NATs, even ones that may themselves be roaming. Roaming works even when the client is not aware that its Internet-visible IP address has changed. The heartbeats allow Mosh to inform the user when it hasn't heard from the server in a while (unlike SSH, where users may be unaware of a dropped connection until they try to type).&lt;/p&gt;&lt;p&gt;Mosh runs two copies of SSP, one in each direction of the connection. The connection from client to server synchronizes an object that represents the keys typed by the user, and with TCP-like semantics. The connection from server to client synchronizes an object that represent the current screen state, and the goal is always to convey the client to the most recent server-side state, possibly skipping intermediate frames.&lt;/p&gt;&lt;p&gt;Because SSP works at the object layer and can control the rate of synchronization (in other words, the frame rate), it does not need to send every byte it receives from the application. That means Mosh can regulate the frames so as not to fill up network buffers, retaining the responsiveness of the connection and making sure Control-C always works quickly. Protocols that must send every byte can't do this.&lt;/p&gt;&lt;p&gt;One benefit of working at the terminal layer was the opportunity to build a clean UTF-8 terminal emulator from scratch. Mosh fixes several Unicode bugs in existing terminals and in SSH, and was designed as a fresh start to try to be robust and correct even for pathological inputs.&lt;/p&gt;&lt;p&gt;Only Mosh and the OS X Terminal correctly handle a Unicode combining character in the first column.&lt;/p&gt;&lt;p&gt;Only Mosh will never get stuck in hieroglyphs when a nasty program writes to the terminal. (See Markus Kuhn's discussion of the relationship between ISO 2022 and UTF-8.)&lt;/p&gt;&lt;p&gt;Only Mosh and GNOME Terminal have a defensible rendering when Unicode mixes with an ECMA-48/ANSI escape sequence. The OS X Terminal unwisely tries to normalize its input before the vt500 state machine, causing it to misinterpret and become unusable after receiving the following input!* (This also means the OS X Terminal's interpretation of the incoming octet stream varies depending on how the incoming octets are split across TCP segments, because the normalization only looks ahead to available bytes.)&lt;/p&gt;&lt;p&gt;* We earlier wrote that this misbehaving sequence "crashes" the OS X Terminal.app. This was mistaken—instead, Terminal.app interprets the escape sequence as shutting off keyboard input, and because of an unrelated bug in Terminal.app, it is not possible for the user to restore keyboard input by resetting the terminal from the menu.&lt;/p&gt;&lt;p&gt;In the POSIX framework, the kernel needs to know whether the user is typing in an 8-bit character set or in UTF-8, because in canonical mode (i.e. "cooked" mode), the kernel needs to be able to delete a typed multibyte character sequence from an input buffer. On OS X and Linux, this is done with the "IUTF8" termios flag.) (See diagnostic explaining the need for this flag.)&lt;/p&gt;&lt;p&gt;Mosh sets the IUTF8 flag when possible and stubbornly refuses to start up unless the user has a UTF-8-clean environment. SSH does not set the IUTF8 flag, which can lead to garbage in input buffers.&lt;/p&gt;&lt;p&gt;The other major benefit of working at the terminal-emulation layer is that the Mosh client is free to scribble on the local screen without lasting consequence. We use this to implement intelligent local echo. The client runs a predictive model in the background of the server's behavior, hypothesizing that each keystroke will be echoed at the cursor location and that the backspace and left- and right-arrow keys will have their traditional effect. But only when a prediction is confirmed by the server are these effects actually shown to the user. (In addition, by default predictions are only displayed on high-delay connections or during a network “glitch.”) Predictions are done in epochs: when the user does something that might alter the echo behavior — like hit ESC or carriage return or an up- or down-arrow — Mosh goes back into making background predictions until a prediction from the new batch can be confirmed as correct.&lt;/p&gt;&lt;p&gt;Thus, unlike previous attempts at local echo with TELNET and RLOGIN, Mosh's local echo can be used everywhere, even in full-screen programs like emacs and vi.&lt;/p&gt;&lt;p&gt;We evaluated Mosh using traces contributed by six users, covering about 40 hours of real-world usage and including 9,986 total keystrokes. These traces included the timing and contents of all writes from the user to the host and vice versa. The users were asked to contribute "typical, real-world sessions." In practice, the traces include use of popular programs such as the bash shell and zsh shells, the alpine and mutt e-mail clients, the emacs and vim text editors, the irssi and barnowl chat clients, the links text-mode Web browser, and several programs unique to each user.&lt;/p&gt;&lt;p&gt;To evaluate typical usage of a "mobile" terminal, we replayed the traces over an otherwise unloaded Sprint commercial EV-DO (3G) cellular Internet connection in Cambridge, Mass. A client-side process played the user portion of the traces, and a server-side process waited for the expected user input and then replied (in time) with the prerecorded server output. We speeded up long periods with no activity. The average round-trip time on the link was about half a second.&lt;/p&gt;&lt;p&gt;We replayed the traces over two different transports, SSH and Mosh, and recorded the user interface response latency to each simulated user keystroke. The Mosh predictive algorithm was frozen prior to collecting the traces and was not adjusted in response to their contents or results.&lt;/p&gt;&lt;p&gt;Mosh reduced the median keystroke response time from 503 ms to nearly instant (because more than 70% of the keystrokes could be immediately displayed), and reduced the mean keystroke response time from 515 ms to 173 ms. Qualitatively, Mosh makes remote servers "feel" more like the local machine!&lt;/p&gt;&lt;p&gt;Mosh was written by Keith Winstein, along with Anders Kaseorg, Quentin Smith, Richard Tibbetts, Keegan McAllister, and John Hood.&lt;/p&gt;&lt;p&gt;Practical latency on the Internet is on the increase, with the rise of bufferbloat and sophisticated wireless links that optimize for throughput over delay. And roaming is more common than ever, now that laptops and handheld devices have largely displaced desktops. SSH is great, but frustrating to use when you want to change IP addresses or have a long-delay link or a dodgy connection.&lt;/p&gt;&lt;p&gt;Moreover, TELNET had some good things going for it — a local-echo mode and a well-defined network virtual terminal. Even today, SSH doesn't properly support UTF-8 end-to-end on a POSIX system.&lt;/p&gt;&lt;p&gt;We think so. The design principles that Mosh stands for are conservative: warning the user if the state being displayed is out of date, serializing and checkpointing all transactions so that if there are no warnings, the user knows every prior transaction has succeeded, and handling expected events (like roaming from one WiFi network to another) gracefully.&lt;/p&gt;&lt;p&gt;Those don't seem too controversial, but fancy apps like Gmail-in-Chromium or on Android still behave atrociously on dodgy connections or after switching IP addresses. (Have you ever had Gmail leave an e-mail message in "Sending..." for ten hours while merrily retrieving new mail and not indicating any kind of error? Us too.) We think there may be considerable room for improvement in many network user interfaces from the application of these values.&lt;/p&gt;&lt;p&gt;To diagnose the problem, run &lt;code&gt;locale&lt;/code&gt; on the local
        terminal, and &lt;code&gt;ssh remotehost locale&lt;/code&gt;. To use Mosh,
        both sides of the connection will need to show a UTF-8 locale, like
        &lt;code&gt;LC_CTYPE="en_US.UTF-8"&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;On many systems, SSH will transfer the locale-related environment variables, which are then inherited by &lt;code&gt;mosh-server&lt;/code&gt;.  If this mechanism fails, Mosh (as of
        version 1.2) will pass the variables itself.  If neither
        mechanism is successful, you can do something like&lt;/p&gt;&lt;quote&gt;mosh remotehost --server="LANG=en_US.UTF-8 mosh-server"&lt;/quote&gt;&lt;p&gt;If &lt;code&gt;en_US.UTF-8&lt;/code&gt; does not exist on the remote server,
        you can replace this with a UTF-8 locale that does exist.  You
        may also need to set LANG locally for the benefit of
        &lt;code&gt;mosh-client&lt;/code&gt;.  It is possible that the local and
        remote machines will need different locale names. See also this GitHub
        ticket.&lt;/p&gt;&lt;p&gt;This means that &lt;code&gt;mosh&lt;/code&gt; was able to start
    &lt;code&gt;mosh-server&lt;/code&gt; successfully on the remote machine, but the client is
    not able to communicate with the server.  This generally means that
    some type of firewall is
    blocking the UDP packets between the client and the server.  If you
    had to forward TCP port 22 on a NAT for SSH, then you will have to
    forward UDP ports as well.  Mosh will use the first available
    UDP port, starting at 60001 and stopping at 60999.  If you are only
    going to have a small handful of concurrent sessions on a server, then you can
    forward a smaller range of ports (e.g., 60000 to 60010).
    &lt;/p&gt;&lt;p&gt;Tools like netstat, netcat, socat, and tcpdump can be useful for debugging networking and firewall problems.&lt;/p&gt;&lt;p&gt;This problem can also be the result of a bug in glibc 2.22 that affects programs that link with protobuf and utempter and use aggressive compiler hardening flags. (glibc bugtracker entry, as well as Mosh bugtracker entry.) The problem causes mosh-server to segfault immediately on startup. We believe we have worked around this problem in Mosh 1.2.6, but please report a bug if you find otherwise.&lt;/p&gt;&lt;p&gt;We're really not UTF-8 zealots. But it's a lot easier to correctly implement one terminal emulator than to try to do the right thing in a variety of difficult edge cases. (This is what GNU screen tries to do, and in our experience it leads to some very tricky-to-debug situations.) So mosh just won't start up until the user has everything configured for a UTF-8-clean pathway. It may be annoying, but it also probably reduces frustration down the road. (Unfortunately an 8-bit vt220 and a UTF-8 vt220 are different and incompatible terminal types; the UTF-8 goes in underneath the vt220 state machine.)&lt;/p&gt;&lt;p&gt;As of Mosh 1.2, you can pass arguments to &lt;code&gt;ssh&lt;/code&gt; like so:&lt;/p&gt;&lt;quote&gt;mosh remotehost --ssh="ssh -p 2222"&lt;/quote&gt;&lt;p&gt;Or configure a host alias in &lt;code&gt;~/.ssh/config&lt;/code&gt; with a
        &lt;code&gt;Port&lt;/code&gt; directive.  Mosh will respect that too.&lt;/p&gt;&lt;p&gt;Please make sure that mosh is installed on the client, and mosh (or at least mosh-server) is installed on the server you are trying to connect to. Also, the server is expected to be available on your server's default login &lt;code&gt;PATH&lt;/code&gt;, which is not
  usually true on OS X and BSD servers, or if you install mosh-server
  in your home directory.  In these cases please see the "Server
  binary outside path" instructions in the Usage section,
  above.&lt;/p&gt;&lt;p&gt;In some configurations, SSH canonicalizes the hostname before passing it to the Kerberos GSSAPI plugin. This breaks for Mosh, because the initial forward DNS lookup is done by the Mosh wrapper script. To work around this, invoke Mosh as&lt;/p&gt;&lt;quote&gt;mosh remotehost --ssh="ssh -o GSSAPITrustDns=no"&lt;/quote&gt;&lt;p&gt;This will often fail on a round-robin DNS setup. In that case it is probably best to pick a specific host from the round-robin pool.&lt;/p&gt;&lt;p&gt;Mosh synchronizes only the visible state of the terminal. We are tracking this issue; see this issue and the others which are linked from there. For now, the workaround is to use screen or tmux on the remote side.&lt;/p&gt;&lt;p&gt;Make sure you are running mosh in a terminal that advertises itself as 256-color capable. (This generally means TERM will be xterm-256color or screen-256color-bce.)&lt;/p&gt;&lt;p&gt;On keyboards with the United States layout, this can be typed as Ctrl-Shift-6, or often as Ctrl-6 (this depends on your OS and terminal emulator). On non-US keyboards, it is often hard to find the right key, and sometimes it's not available at all. If your keyboard has a dead key with an accent-circumflex, this is not likely to be the right key. Ctrl-6 sometimes works, though. If you are unable to type this character, you will need to set the &lt;code&gt;MOSH_ESCAPE_KEY&lt;/code&gt; variable; see the Mosh man page for
  details.&lt;/p&gt;&lt;p&gt;Please see the entries for &lt;code&gt;MOSH_SERVER_NETWORK_TMOUT&lt;/code&gt;
      and &lt;code&gt;MOSH_SERVER_SIGNAL_TMOUT&lt;/code&gt; in the mosh-server(1) man page.&lt;/p&gt;&lt;p&gt;Mosh 1.0 was released in March 2012. As of the release of Mosh 1.4.0 in October 2022, as far as the developers are aware:&lt;/p&gt;&lt;p&gt;We think that Mosh's conservative design means that its attack surface compares favorably with more-complicated systems like OpenSSL and OpenSSH. Mosh's track record has so far borne this out. Ultimately, however, only time will tell when the first serious security vulnerability is discovered in Mosh—either because it was there all along or because it was added inadvertently in development. OpenSSH and OpenSSL have had more vulnerabilities, but they have also been released longer and are more prevalent.&lt;/p&gt;&lt;p&gt;In one concrete respect, the Mosh protocol is more secure than SSH's: SSH relies on unauthenticated TCP to carry the contents of the secure stream. That means that an attacker can end an SSH connection with a single phony "RST" segment. By contrast, Mosh applies its security at a different layer (authenticating every datagram), so an attacker cannot end a Mosh session unless the attacker can continuously prevent packets from reaching the other side. A transient attacker can cause only a transient user-visible outage; once the attacker goes away, Mosh will resume the session.&lt;/p&gt;&lt;p&gt;However, in typical usage, Mosh relies on SSH to exchange keys at the beginning of a session, so Mosh will inherit the weaknesses of SSH—at least insofar as they affect the brief SSH session that is used to set up a long-running Mosh session.&lt;/p&gt;&lt;p&gt;Not that we know of—Mosh uses OCB3. The authors of the paper write that the attack is not applicable to OCB3.&lt;/p&gt;&lt;p&gt;Yes, it works great, but please remember to open up UDP ports 60000–61000 on the EC2 firewall.&lt;/p&gt;&lt;p&gt;After you run &lt;code&gt;mosh user@server&lt;/code&gt;, if successful you will be dropped into your login
      shell on the remote machine.

      If you want
      to check that mosh is being used instead of ssh, try typing &lt;code&gt;Ctrl-^ Ctrl-Z&lt;/code&gt;
      to suspend the session (with mosh 1.2.4 or later on the client). Running &lt;code&gt;fg&lt;/code&gt; will then return.
      &lt;/p&gt;&lt;p&gt;The &lt;code&gt;mosh&lt;/code&gt; command is a wrapper script that is designed to be the primary way that
      you use mosh.  In most cases, you can simply just replace "ssh" with "mosh" in your command line.
      Behind the scenes, the &lt;code&gt;mosh&lt;/code&gt; wrapper script will SSH to the server, start up
      &lt;code&gt;mosh-server&lt;/code&gt;, and then close the SSH connection.  Then it will start up the
      &lt;code&gt;mosh-client&lt;/code&gt; executable on the client, passing it the necessary information for
      it to connect to the newly spawned &lt;code&gt;mosh-server&lt;/code&gt; instance.
      &lt;/p&gt;&lt;p&gt;In normal usage, &lt;code&gt;mosh-client&lt;/code&gt; and
      &lt;code&gt;mosh-server&lt;/code&gt; don't need to be run directly.
      &lt;/p&gt;&lt;p&gt;If the &lt;code&gt;mosh&lt;/code&gt; wrapper script isn't working for you, you can try running
    the &lt;code&gt;mosh-client&lt;/code&gt; and &lt;code&gt;mosh-server&lt;/code&gt; programs separately to
    form a connection. This can be a useful debugging technique.&lt;/p&gt;&lt;p&gt;1. Log in to the remote host, and run &lt;code&gt;mosh-server&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;It will give output like:&lt;/p&gt;&lt;quote&gt;$ mosh-server MOSH CONNECT 60004 4NeCCgvZFe2RnPgrcU1PQw mosh-server (mosh 1.1.3) Copyright 2012 Keith Winstein &amp;lt;[email protected]&amp;gt; License GPLv3+: GNU GPL version 3 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. [mosh-server detached, pid = 30261]&lt;/quote&gt;&lt;p&gt;2. On the local host, run:&lt;/p&gt;&lt;quote&gt;$ MOSH_KEY=key mosh-client remote-IP remote-PORT&lt;/quote&gt;&lt;p&gt;where "key" is the 22-byte string printed by mosh-server (in this example, "4NeCCgvZFe2RnPgrcU1PQw"), "remote-PORT" is the port number given by the server (60004 in this case), and "remote-IP" is the IP address of the server. You can look up the server's IP address with "host remotehost".&lt;/p&gt;&lt;p&gt;3. If all goes well, you should have a working Mosh connection. Information about where the process fails can help us debug why Mosh isn't working for you.&lt;/p&gt;&lt;p&gt;This bug is fixed in Mosh 1.2. Thanks to Ed Schouten and Peter Jeremy for tracking this down.&lt;/p&gt;&lt;p&gt;We welcome your contribution! Please join us in &lt;code&gt;#mosh&lt;/code&gt; channel on Libera Chat IRC, visit us on GitHub,
  or email &lt;code&gt;[email protected]&lt;/code&gt;.  To contribute to our code base, please fork the repository on GitHub and open a pull request there.&lt;/p&gt;&lt;p&gt;We're very grateful for assistance and support from:&lt;/p&gt;&lt;p&gt;&lt;code&gt;[email protected]&lt;/code&gt;&lt;lb/&gt; Mosh development and discussion. Sign up or view archives at https://mailman.mit.edu/mailman/listinfo/mosh-devel.&lt;/p&gt;&lt;p&gt;&lt;code&gt;[email protected]&lt;/code&gt;&lt;lb/&gt; Mosh user discussion and site best practices. Sign up or view archives at https://mailman.mit.edu/mailman/listinfo/mosh-users.&lt;/p&gt;&lt;p&gt;&lt;code&gt;#mosh&lt;/code&gt; channel on Libera IRC&lt;lb/&gt; You can connect with a Web client, try an irc:// URL, or manually configure your client for &lt;code&gt;irc.libera.chat&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;At the recommendation of the security community, confidential security-related matters may be sent to: &lt;code&gt;[email protected]&lt;/code&gt;&lt;/p&gt;&lt;quote&gt;pub rsa4096 2012-02-05 [SC] [expires: 2025-02-27] B1A4 7069 121F 6642 BB3D 7F3E 20B7 283A FE25 4C69&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mosh.org"/></entry><entry><id>https://news.ycombinator.com/item?id=45053234</id><title>Anything can be a message queue if you use it wrongly enough</title><updated>2025-08-28T16:12:30.315364+00:00</updated><content>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xeiaso.net/blog/anything-message-queue"/></entry></feed>