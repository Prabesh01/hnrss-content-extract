<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-04T10:45:07.407314+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46137548</id><title>Launch HN: Phind 3 (YC S22) – Every answer is a mini-app</title><updated>2025-12-04T10:45:15.883576+00:00</updated><content>&lt;doc fingerprint="2c6a25dd25d976dd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hi HN,&lt;/p&gt;
      &lt;p&gt;We are launching Phind 3 (https://www.phind.com), an AI answer engine that instantly builds a complete mini-app to answer and visualize your questions in an interactive way. A Phind mini-app appears as a beautiful, interactive webpage — with images, charts, diagrams, maps, and other widgets. Phind 3 doesn’t just present information more beautifully; interacting with these widgets dynamically updates the content on the page and enables new functionality that wasn’t possible before.&lt;/p&gt;
      &lt;p&gt;For example, asking Phind for “options for a one-bedroom apartment in the Lower East Side” (https://www.phind.com/search/find-me-options-for-a-72e019ce-...) gives an interactive apartment-finding experience with customizable filters and a map view. And asking for a “recipe for bone-in chicken thighs” gives you a customizable recipe where changing the seasoning, cooking method, and other parameters will update the recipe content itself in real-time (https://www.phind.com/search/make-me-an-recipe-for-7c30ea6c-...).&lt;/p&gt;
      &lt;p&gt;Unlike Phind 2 and ChatGPT apps, which use pre-built brittle widgets that can’t truly adapt to your task, Phind 3 is able to create tools and widgets for itself in real-time. We learned this lesson the hard way with our previous launch – the pre-built widgets made the answers much prettier, but they didn’t fundamentally enable new functionality. For example, asking for “Give me round-trip flight options from JFK to SEA on Delta from December 1st-5th in both miles and cash” (https://www.phind.com/search/give-me-round-trip-flight-c0ebe...) is not something that neither Phind 2 nor ChatGPT apps can handle, because its Expedia widget can only display cash fares and not those with points. We realized that Phind needs to be able to create and consume its own tools, with schema it designs, all in real time. Phind 3’s ability to design and create fully custom widgets in real-time means that it can answer these questions while these other tools can’t. Phind 3 now generates raw React code and is able to create any tool to harness its underlying AI answer, search, and code execution capabilities.&lt;/p&gt;
      &lt;p&gt;Building on our history of helping developers solve complex technical questions, Phind 3 is able to answer and visualize developers’ questions like never before. For example, asking to “visualize quicksort” (https://www.phind.com/search/make-me-a-beautiful-visualizati...) gives an interactive step-by-step walkthrough of how the algorithm works.&lt;/p&gt;
      &lt;p&gt;Phind 3 can help visualize and bring your ideas to life in seconds — you can ask it to “make me a 3D Minecraft simulation” (https://www.phind.com/search/make-me-a-3d-minecraft-fde7033f...) or “make me a 3D roller coaster simulation” (https://www.phind.com/search/make-me-a-3d-roller-472647fc-e4...).&lt;/p&gt;
      &lt;p&gt;Our goal with Phind 3 is to usher in the era of on-demand software. You shouldn’t have to compromise by either settling for text-based AI conversations or using pre-built webpages that weren’t customized for you. With Phind 3, we create a “personal internet” for you with the visualization and interactivity of the internet combined with the customization possible with AI. We think that this current “chat” era of AI is akin to the era of text-only interfaces in computers. The Mac ushering in the GUI in 1984 didn’t just make computer outputs prettier — it ushered in a whole new era of interactivity and possibilities. We aim to do that now with AI.&lt;/p&gt;
      &lt;p&gt;On a technical level, we are particularly excited about:&lt;/p&gt;
      &lt;p&gt;- Phind 3’s ability to create its own tools with its own custom schema and then consume them&lt;/p&gt;
      &lt;p&gt;- Significant improvements in agentic searching and a new deep research mode to surface hard-to-access information&lt;/p&gt;
      &lt;p&gt;- All-new custom Phind models that blend speed and quality. The new Phind Fast model is based on GLM-4.5-Air while the new Phind Large model is based on GLM 4.6. Both models are state-of-the-art when it comes to reliable code generation, producing over 70% fewer errors than GPT-5.1-Codex (high) on our internal mini-app generation benchmark. Furthermore, we trained custom Eagle3 heads for both Phind Fast and Phind Large for fast inference. Phind Fast runs at up to 300 tokens per second, and Phind Large runs at up to 200 tokens per second, making them the fastest Phind models ever.&lt;/p&gt;
      &lt;p&gt;While we have done Show HNs before for previous Phind versions, we’ve never actually done a proper Launch HN for Phind. As always, we can’t wait to hear your feedback! We are also hiring, so please don’t hesitate to reach out.&lt;/p&gt;
      &lt;p&gt;– Michael&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46137548"/><published>2025-12-03T17:47:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46137783</id><title>Micron Announces Exit from Crucial Consumer Business</title><updated>2025-12-04T10:45:15.433841+00:00</updated><content>&lt;doc fingerprint="c9a9907d4cbbb1ea"&gt;
  &lt;main&gt;
    &lt;p&gt;BOISE, Idaho, Dec. 03, 2025 (GLOBE NEWSWIRE) -- Micron Technology, Inc. (Nasdaq: MU), a leader in innovative memory and storage solutions, today announced its decision to exit the Crucial consumer business, including the sale of Crucial consumer-branded products at key retailers, e-tailers and distributors worldwide.&lt;/p&gt;
    &lt;p&gt;Micron will continue Crucial consumer product shipments through the consumer channel until the end of fiscal Q2 (February 2026). The company will work closely with partners and customers through this transition and will provide continued warranty service and support for Crucial products. Micron will continue to support the sale of Micron-branded enterprise products to commercial channel customers globally.&lt;/p&gt;
    &lt;p&gt;“The AI-driven growth in the data center has led to a surge in demand for memory and storage. Micron has made the difficult decision to exit the Crucial consumer business in order to improve supply and support for our larger, strategic customers in faster-growing segments,” said Sumit Sadana, EVP and Chief Business Officer at Micron Technology. “Thanks to a passionate community of consumers, the Crucial brand has become synonymous with technical leadership, quality and reliability of leading-edge memory and storage products. We would like to thank our millions of customers, hundreds of partners and all of the Micron team members who have supported the Crucial journey for the last 29 years.”&lt;/p&gt;
    &lt;p&gt;This decision reflects Micron’s commitment to its ongoing portfolio transformation and the resulting alignment of its business to secular, profitable growth vectors in memory and storage. By concentrating on core enterprise and commercial segments, Micron aims to improve long-term business performance and create value for strategic customers as well as stakeholders.&lt;/p&gt;
    &lt;p&gt;Micron intends to reduce impact on team members due to this business decision through redeployment opportunities into existing open positions within the company.&lt;/p&gt;
    &lt;p&gt;About Micron Technology, Inc.&lt;/p&gt;
    &lt;p&gt;Micron Technology, Inc. is an industry leader in innovative memory and storage solutions, transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence (AI) and compute-intensive applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience. To learn more about Micron Technology, Inc. (Nasdaq: MU), visit micron.com.&lt;/p&gt;
    &lt;p&gt;Forward-Looking Statements&lt;/p&gt;
    &lt;p&gt;This press release contains forward-looking statements, including statements regarding product supply and support, areas of growth and profitability, and workforce redeployment. These forward-looking statements are subject to a number of risks and uncertainties that could cause actual results to differ materially. Please refer to the documents Micron files with the Securities and Exchange Commission, specifically its most recent Form 10-K and Form 10-Q. These documents contain and identify important factors that could cause actual results to differ materially from those contained in these forward-looking statements. These certain factors can be found at https://investors.micron.com/risk-factor. Although Micron believes that the expectations reflected in the forward-looking statements are reasonable, Micron cannot guarantee future results, levels of activity, or achievements. Micron is under no duty to update any of the forward-looking statements after the date of this press release to conform these statements to actual results.&lt;/p&gt;
    &lt;p&gt;© 2025 Micron Technology, Inc. All rights reserved. Information, products, and/or specifications are subject to change without notice. Micron, the Micron logo, and all other Micron trademarks are the property of Micron Technology, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;
    &lt;p&gt;Micron Media Relations Contact&lt;lb/&gt;Mark Plungy&lt;lb/&gt;+1 (408) 203-2910&lt;lb/&gt;corpcomms@micron.com &lt;lb/&gt;Micron Investor Relations Contact&lt;lb/&gt;Satya Kumar&lt;lb/&gt;+1 (408) 450-6199&lt;lb/&gt;satyakumar@micron.com &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://investors.micron.com/news-releases/news-release-details/micron-announces-exit-crucial-consumer-business"/><published>2025-12-03T18:04:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138238</id><title>Ghostty is now non-profit</title><updated>2025-12-04T10:45:15.265714+00:00</updated><content>&lt;doc fingerprint="af5a505b2f305666"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;Ghostty Is Now Non-Profit&lt;/head&gt;
    &lt;p&gt;Ghostty is now fiscally sponsored by Hack Club, a registered 501(c)(3) non-profit.&lt;/p&gt;
    &lt;p&gt;Fiscal sponsorship is a legal and financial arrangement in which a recognized non-profit extends its tax-exempt status to a project that aligns with its mission. This allows Ghostty to operate as a charitable initiative while Hack Club manages compliance, donations, accounting, and governance oversight.&lt;/p&gt;
    &lt;p&gt;Being non-profit clearly demonstrates our commitment to keeping Ghostty free and open source for everyone. It paves the way for a model for sustainable development beyond my personal involvement. And it also provides important legal protections and assurances to the people and communities that adopt and use Ghostty.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why a Non-Profit?&lt;/head&gt;
    &lt;p&gt;Since the beginning of the project in 2023 and the private beta days of Ghostty, I've repeatedly expressed my intention that Ghostty legally become a non-profit. This intention stems from several core beliefs I have.&lt;/p&gt;
    &lt;p&gt;First, I want to lay bricks for a sustainable future for Ghostty that doesn't depend on my personal involvement technically or financially. Financially, I am still the largest donor to the project, and I intend to remain so, but a non-profit structure allows others to contribute financially without fear of misappropriation or misuse of funds (as protected by legal requirements and oversight from the fiscal sponsor).&lt;/p&gt;
    &lt;p&gt;Second, I want to squelch any possible concerns about a "rug pull". A non-profit structure provides enforceable assurances: the mission cannot be quietly changed, funds cannot be diverted to private benefit, and the project cannot be sold off or repurposed for commercial gain. The structure legally binds Ghostty to the public-benefit purpose it was created to serve.&lt;/p&gt;
    &lt;p&gt;Finally, despite being decades-old technology, terminals and terminal-related technologies remain foundational to modern computing and software infrastructure. They're often out of the limelight, but they're ever present on developer machines, embedded in IDEs, visible as read-only consoles for continuous integration and cloud services, and still one of the primary ways remote access is done on servers around the world.&lt;/p&gt;
    &lt;p&gt;I believe infrastructure of this kind should be stewarded by a mission-driven, non-commercial entity that prioritizes public benefit over private profit. That structure increases trust, encourages adoption, and creates the conditions for Ghostty to grow into a widely used and impactful piece of open-source infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This Means For Ghostty&lt;/head&gt;
    &lt;p&gt;From a technical perspective, nothing changes for Ghostty. Our technical goals for the project remain the same, the license (MIT) remains the same, and we continue our work towards better Ghostty GUI releases and libghostty.&lt;/p&gt;
    &lt;p&gt;Financially, Ghostty can now accept tax-deductible donations in the United States. This opens up new avenues for funding the project and sustaining development over the long term. Most immediately, I'm excited to begin compensating contributors, but I also intend to support upstream dependencies, fund community events, and pay for boring operational costs.&lt;/p&gt;
    &lt;p&gt;All our financial transactions will be transparent down to individual transactions for both inflows and outflows. You can view our public ledger at Ghostty's page on Hack Club Bank. At the time of writing, this is empty, but you'll soon see some initial funding from me and the beginning of paying for some of our operational costs.&lt;/p&gt;
    &lt;p&gt;All applicable names, marks, and intellectual property associated with Ghostty have been transferred to Hack Club and are now owned under the non-profit umbrella. Copyright continues to be held by individual contributors under the continued and existing license structure.&lt;/p&gt;
    &lt;p&gt;From a leadership perspective, I remain the project lead and final authority on all decisions, but as stated earlier, the creation of a non-profit structure lays the groundwork for an eventual future beyond this model.&lt;/p&gt;
    &lt;p&gt;Important note: no funds will be sent to me (Mitchell Hashimoto) or used in any way that personally benefits me. Since I'm both the largest donor and lead of this project, this is a legally guaranteed protection. But also for altruistic reasons, all funds will be directed towards the needs of the project and its community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supporting Hack Club&lt;/head&gt;
    &lt;p&gt;As our fiscal sponsor, Hack Club provides essential services to Ghostty, including accounting, legal compliance, and governance oversight. To support this, 7% of all donations to Ghostty go to Hack Club to cover these costs in addition to supporting their broader mission of empowering young people around the world interested in technology and coding.&lt;/p&gt;
    &lt;p&gt;In the words of Zach Latta, Hack Club's founder and executive director this is a "good-for-good" trade. Instead of donor fees going to a for-profit management company or covering pure overhead of a single project, the fees go to another non-profit doing important work in the tech community and the overhead is amortized across many projects.&lt;/p&gt;
    &lt;p&gt;In addition to the 7% fees, my family is personally donating $150,000 directly to the Hack Club project1 (not to Ghostty within it). Hack Club does amazing work and I would've supported them regardless of their fiscal sponsorship of Ghostty, but I wanted to pair these two things together to amplify the impact of both.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donate&lt;/head&gt;
    &lt;p&gt;Please consider donating to support Ghostty's continued development.&lt;/p&gt;
    &lt;p&gt;I recognize that Ghostty is already in an abnormally fortunate position to have myself as a backer, but I do envision a future where Ghostty is more equally supported by a broader community. And with our new structure, you can be assured about the usage of your funds towards public-benefit goals.&lt;/p&gt;
    &lt;p&gt;This post isn't meant to directly be a fundraising pitch so it is purposely lacking critical details about our funding goals, budget, project goals, project metrics, etc. I'll work on those in the future. In the mean time, if you're interested in talking more about supporting Ghostty, please email me at m@mitchellh.com.&lt;/p&gt;
    &lt;head rend="h3"&gt;Support Ghostty&lt;/head&gt;
    &lt;p&gt;Your contribution helps sustain development and keeps Ghostty free and open source for everyone. Donations are tax-deductible in the United States.&lt;/p&gt;
    &lt;p&gt;Use the EIN above and specify “Ghostty” as the recipient&lt;/p&gt;
    &lt;p&gt;Contact Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;Reach out to Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;7% of donations go to Hack Club to cover administrative costs and support their mission.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank You&lt;/head&gt;
    &lt;p&gt;I'm thankful for Hack Club and their team for working with us to make this happen. I'm also thankful for the Ghostty community who has supported this project and has trusted me and continues to trust me to steward it responsibly.&lt;/p&gt;
    &lt;p&gt;For more information about Ghostty's non-profit structure, see the dedicated page on Ghostty's website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;We haven't finalized the transfer of the funds yet, but it is initiated and will be completed in the coming weeks. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mitchellh.com/writing/ghostty-non-profit"/><published>2025-12-03T18:40:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138632</id><title>Lie groups are crucial to some of the most fundamental theories in physics</title><updated>2025-12-04T10:45:15.145801+00:00</updated><content>&lt;doc fingerprint="e65190820f9d0f14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Are Lie Groups?&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In mathematics, ubiquitous objects called groups display nearly magical powers. Though they’re defined by just a few rules, groups help illuminate an astonishing range of mysteries. They can tell you which polynomial equations are solvable, for instance, or how atoms are arranged in a crystal.&lt;/p&gt;
    &lt;p&gt;And yet, among all the different kinds of groups, one type stands out. Identified in the early 1870s, Lie groups (pronounced “Lee”) are crucial to some of the most fundamental theories in physics, and they’ve made lasting contributions to number theory and chemistry. The key to their success is the way they blend group theory, geometry and linear algebra.&lt;/p&gt;
    &lt;p&gt;In general, a group is a set of elements paired with an operation (like addition or multiplication) that combines two of those elements to produce a third. Often, you can think of a group as the symmetries of a shape — the transformations that leave the shape unchanged.&lt;/p&gt;
    &lt;p&gt;Consider the symmetries of the equilateral triangle. They form a group of six elements, as shown here:&lt;/p&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;(Since a full rotation brings every point on the triangle back to where it started, mathematicians stop counting rotations past 360 degrees.)&lt;/p&gt;
    &lt;p&gt;These symmetries are discrete: They form a set of distinct transformations that have to be applied in separate, unconnected steps. But you can also study continuous symmetries. It doesn’t matter, for instance, if you spin a Frisbee 1.5 degrees, or 15 degrees, or 150 degrees — you can rotate it by any real number, and it will appear the same. Unlike the triangle, it has infinitely many symmetries.&lt;/p&gt;
    &lt;p&gt;These rotations form a group called SO(2). “If you have just a reflection, OK, you have it, and that’s good,” said Anton Alekseev, a mathematician at the University of Geneva. “But that’s just one operation.” This group, on the other hand, “is many, many operations in one package” — uncountably many.&lt;/p&gt;
    &lt;p&gt;Each rotation of the Frisbee can be represented as a point in the coordinate plane. If you plot all possible rotations of the Frisbee in this way, you’ll end up with infinitely many points that together form a circle.&lt;/p&gt;
    &lt;p&gt;This extra property is what makes SO(2) a Lie group — it can be visualized as a smooth, continuous shape called a manifold. Other Lie groups might look like the surface of a doughnut, or a high-dimensional sphere, or something even stranger: The group of all rotations of a ball in space, known to mathematicians as SO(3), is a six-dimensional tangle of spheres and circles.&lt;/p&gt;
    &lt;p&gt;Whatever the specifics, the smooth geometry of Lie groups is the secret ingredient that elevates their status among groups.&lt;/p&gt;
    &lt;head rend="h2"&gt;Off on a Tangent&lt;/head&gt;
    &lt;p&gt;It took time for Marius Sophus Lie to make his way to mathematics. Growing up in Norway in the 1850s, he hoped to pursue a military career once he finished secondary school. Instead, forced to abandon his dream due to poor eyesight, he ended up in university, unsure of what to study. He took courses in astronomy and mechanics, and flirted briefly with physics, botany and zoology before finally being drawn to math — geometry in particular.&lt;/p&gt;
    &lt;p&gt;In the late 1860s, he continued his studies, first in Germany and then in France. He was in Paris in 1870 when the Franco-Prussian War broke out. He soon tried to leave the country, but his notes on geometry, written in German, were mistaken for encoded messages, and he was arrested, accused of being a spy. He was released from prison a month later and quickly returned to math.&lt;/p&gt;
    &lt;p&gt;In particular, he began working with groups. Forty years earlier, the mathematician Évariste Galois had used one class of groups to understand the solutions to polynomial equations. Lie now wanted to do the same thing for so-called differential equations, which are used to model how a physical system changes over time.&lt;/p&gt;
    &lt;p&gt;His vision for differential equations didn’t work out as he’d hoped. But he soon realized that the groups he was studying were interesting in their own right. And so the Lie group was born.&lt;/p&gt;
    &lt;p&gt;The manifold nature of Lie groups has been an enormous boon to mathematicians. When they sit down to understand a Lie group, they can use all the tools of geometry and calculus — something that’s not necessarily true for other kinds of groups. That’s because every manifold has a nice property: If you zoom in on a small enough region, its curves disappear, just as the spherical Earth appears flat to those of us walking on its surface.&lt;/p&gt;
    &lt;p&gt;To see why this is useful for studying groups, let’s go back to SO(2). Remember that SO(2) consists of all the rotations of a Frisbee, and that those rotations can be represented as points on a circle. For now, let’s focus on a sliver of the circle corresponding to very small rotations — say, rotations of less than 1 degree.&lt;/p&gt;
    &lt;p&gt;Here, the curve of SO(2) is barely perceptible. When a Frisbee rotates 1 degree or less, any given point on its rim follows a nearly linear path. That means mathematicians can approximate these rotations with a straight line that touches the circle at just one point — a tangent line. This tangent line is called the Lie algebra.&lt;/p&gt;
    &lt;p&gt;This feature is immensely useful. Math is a lot easier on a straight line than on a curve. And the Lie algebra contains elements of its own (often visualized as arrows called vectors) that mathematicians can use to simplify their calculations about the original group. “One of the easiest kinds of mathematics in the world is linear algebra, and the theory of Lie groups is designed in such a way that it just makes constant use of linear algebra,” said David Vogan of the Massachusetts Institute of Technology.&lt;/p&gt;
    &lt;p&gt;Say you want to compare two different groups. Their respective Lie algebras simplify their key properties, Vogan said, making this task much more straightforward.&lt;/p&gt;
    &lt;p&gt;“The interaction between these two structures,” Alessandra Iozzi, a mathematician at the Swiss Federal Institute of Technology Zurich, said of Lie groups and their algebras, “is something that has an absolutely enormous array of consequences.”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Language of Nature&lt;/head&gt;
    &lt;p&gt;The natural world is full of the kinds of continuous symmetries that Lie groups capture, making them indispensable in physics. Take gravity. The sun’s gravitational pull on the Earth depends only on the distance between them — it doesn’t matter which side of the sun the Earth is on, for instance. In the language of Lie groups, then, gravity is “symmetric under SO(3).” It remains unchanged when the system it’s acting on rotates in three-dimensional space.&lt;/p&gt;
    &lt;p&gt;In fact, all the fundamental forces in physics — gravity, electromagnetism, and the forces that hold together atomic nuclei — are defined by Lie group symmetries. Using that definition, scientists can explain basic puzzles about matter, like why protons are always paired with neutrons, and why the energy of an atom comes in discrete quantities.&lt;/p&gt;
    &lt;p&gt;In 1918, Emmy Noether stunned mathematicians and physicists by proving that Lie groups also underlie some of the most basic laws of conservation in physics. She showed that for any symmetry in a physical system that can be described by a Lie group, there is a corresponding conservation law. For instance, the fact that the laws of physics are the same today as they were yesterday and will be tomorrow — a symmetry known as time translation symmetry, represented by the Lie group consisting of the real numbers — implies that the universe’s energy must be conserved, and vice versa. “I think, even now, it’s a very surprising result,” Alekseev said.&lt;/p&gt;
    &lt;p&gt;Today, Lie groups remain a vital tool for both mathematicians and physicists. “Definitions live in mathematics because they’re powerful. Because there are a lot of interesting examples and they give you a good way to think about something,” Vogan said. “Symmetry is everywhere, and that’s what this stuff is for.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/what-are-lie-groups-20251203/"/><published>2025-12-03T19:12:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46139761</id><title>Show HN: I built a dashboard to compare mortgage rates across 120 credit unions</title><updated>2025-12-04T10:45:14.710187+00:00</updated><content>&lt;doc fingerprint="3c94a31214402b4c"&gt;
  &lt;main&gt;&lt;p&gt;Buying a home or refinancing a mortgage is tough enough without confusing ads from banks and big lenders. Credit unions can offer competitive rates compared to big banks because theyâre member-owned, non-profit institutions. They focus on serving their members, not maximizing profits for shareholders.&lt;/p&gt;&lt;p&gt;But without big budgets and marketing departments, credit union rates arenât always easy to find or compare. Thatâs why we built a daily-updated comparison of mortgage rates from over 120 credit unions across the United States.&lt;/p&gt;&lt;head rend="h2"&gt;Credit Union Mortgage Rates&lt;/head&gt;&lt;p&gt;Last updated: December 3, 2025&lt;/p&gt;&lt;head rend="h3"&gt;30-Year Fixed&lt;/head&gt;Updating...&lt;p&gt;Loading rate comparison table...&lt;/p&gt;&lt;p&gt;Note: These rates are informational and not a commitment to lend. FinFam has no institutional affiliation and does not receive any referral fees.&lt;/p&gt;&lt;head rend="h2"&gt;Why build this dashboard?&lt;/head&gt;&lt;p&gt;When we bought our home, the big bank Iâd been using for years tried to sell me on a mortgage with 7% APR. Turns out a local credit union was offering 5.5% for the exact same mortgage.&lt;/p&gt;&lt;p&gt;What surprised me most wasnât that there were cheaper options, but that two mortgages can be exactly the same product, just with different packaging.&lt;/p&gt;&lt;p&gt;In the USA, the government buys almost all mortgages, requiring them to be standardized. So why the price difference? As explored in this Bloomberg Odd Lots episode about credit card rates, higher rates are mostly to pay for advertising and marketing. Big banks have marketing departments that non-profit credit unions donât have.&lt;/p&gt;&lt;p&gt;That âexclusiveâ inbox offer from Chase or Wells Fargo isnât generosity. Itâs a bet that you wonât shop around. My goal with this tool is simple: help people realize they have options and potentially save thousands of dollars a year.&lt;/p&gt;&lt;head rend="h2"&gt;How the dashboard works&lt;/head&gt;&lt;p&gt;Itâs a little involved! ð&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Rates are collected throughout the day from the websites of approximately 120 credit unions.&lt;/item&gt;&lt;item&gt;National benchmarks come from the St. Louis Federal Reserve Bank, aka FRED: 30-Year Fixed benchmark (15Y). These update weekly.&lt;/item&gt;&lt;item&gt;Credit union eligibility data is manually curated from individual institution websites.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Some rates (around a dozen) are hidden by default because theyâre statistical outliers: likely errors or ultra-specialized products. Toggle âShow outliersâ in the filters if you want to see them anyway.&lt;/p&gt;&lt;p&gt;Found an error? Email blog@finfam.app.&lt;/p&gt;&lt;head rend="h2"&gt;Next Steps: Make Decisions, Get Quotes&lt;/head&gt;&lt;p&gt;Our dashboard can only take you so far. Your actual rate depends on: credit score, down payment (20%+ is ideal), property type (primary residence gets best rates), and whether you pay points for a lower rate (always compare APR).&lt;/p&gt;&lt;p&gt;Next step: Get quotes from multiple lenders by using the rate table above to contact institutions.&lt;/p&gt;&lt;p&gt;Protip: Before submitting to any credit checks, protect your privacy with optoutprescreen.com, another free and regulated service I wish Iâd known about sooner.&lt;/p&gt;&lt;p&gt;Still not sure about buying or refinancing? Check out these interactive guides:&lt;/p&gt;&lt;p&gt;FinFam is built around collaborative financial planning, including community-authored, spreadsheet-powered guides, like those above. Read more in our docs.&lt;/p&gt;&lt;head rend="h2"&gt;Questions or Feedback?&lt;/head&gt;&lt;p&gt;Have questions about these rates or suggestions for improving this tool? Reach out to us at blog@finfam.app.&lt;/p&gt;&lt;p&gt;Donât see your favorite CU here? As long as it has a website with a public rates page and clear eligibility requirements, weâd be happy to add it!&lt;/p&gt;&lt;head rend="h3"&gt;Disclaimers&lt;/head&gt;&lt;p&gt;These rates are informational only and donât represent rate locks. Your actual rate will vary. Contact lenders with the links in the rate table to get your personalized quotes. FinFam has no institutional affiliation and receives no referral fees, nor provides any guarantees.&lt;/p&gt;&lt;p&gt;Shoutout /r/dataisbeautiful for the encouragement. And big thanks to Asheesh Laroia for his guidance on the matter of mortgages. See his spreadsheet-friendly take on the data.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finfam.app/blog/credit-union-mortgages"/><published>2025-12-03T20:35:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46140244</id><title>8086 Microcode Browser</title><updated>2025-12-04T10:45:14.636839+00:00</updated><content>&lt;doc fingerprint="3f1bc214a171d033"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;8086 Microcode Browser&lt;/head&gt;
    &lt;p&gt;Since releasing 486Tang, I’ve been working on recreating the 8086 with a design that stays as faithful as possible to the original chip. That exploration naturally led me deep into the original 8086 microcode — extracted and disassembled by Andrew Jenner in 2020.&lt;/p&gt;
    &lt;p&gt;Like all microcoded CPUs, the 8086 hides a lot of subtle behavior below the assembly layer. While studying it I kept extensive notes, and those eventually evolved into something more useful: an interactive browser for the entire 8086 microcode ROM.&lt;/p&gt;
    &lt;p&gt;So here it is: the online 8086 microcode browser. Every 21-bit micro-instruction is decoded into readable fields. Hover over any field and you’ll get a tooltip explaining what it does. All jump targets are clickable — the 8086 μcode uses a surprising number of indirect jumps, calls, and short branches.&lt;/p&gt;
    &lt;p&gt;One handy feature is Browse by Instruction. Click the button and you’ll get a list of ~300 documented 8086 instructions. Select any one, and the viewer jumps directly to its μcode entry point. Internally there are only about 60 unique μcode entry routines, and this feature makes navigating them effortless.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few fun tidbits about 8086 μcode&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Register IDs change meaning depending on context. For example,&lt;/p&gt;&lt;code&gt;10100&lt;/code&gt;refers to SIGMA (the ALU result) when used as a source, but to tmpaL (the low 8 bits of a temporary ALU register) when used as a destination.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;N and R are the same physical register. Meanwhile, SI is called IJ internally — naming inside the chip is extremely inconsistent and reflects its evolutionary design process.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IP (PC) does not point to the next instruction. It actually points to the next prefetch address. The μcode uses a dedicated micro-operation called CORR to rewind IP back to the true next-instruction boundary when handling branches and interrupts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Almost all arithmetic instructions share the same 4 μinstructions (&lt;/p&gt;&lt;code&gt;008–00B&lt;/code&gt;). The heavy lifting is done by a single micro-operation named XI, which performs different arithmetic behaviors depending on opcode or ModRM bits. The amount of reuse here is elegant — and very 1978 Intel.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nand2mario.github.io/posts/2025/8086_microcode_browser/"/><published>2025-12-03T21:16:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46141745</id><title>Acme, a brief history of one of the protocols which has changed the Internet</title><updated>2025-12-04T10:45:13.839847+00:00</updated><content>&lt;doc fingerprint="6d19b1920b220c9d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;ACME, a brief history of one of the protocols which has changed the Internet Security&lt;/head&gt;
    &lt;head rend="h3"&gt;Preamble&lt;/head&gt;
    &lt;p&gt;I would like to share with you this article I wrote about the ACME protocol, which I “fell in love with” about ten years ago. It is for me a way to give back to this fantastic Free Software and Open Protocols developers community.&lt;/p&gt;
    &lt;p&gt;This article is about the roots, the conception, the standardization, the relation with its ecosystem and the evolution challenges faced by the ACME protocol.&lt;/p&gt;
    &lt;p&gt;To write this article, I had the privilege of interviewing several people who have been involved in the creation and the evolution of ACME: Aaron Gable, Sarah Gran, Jacob Hoffman-Andrews and J.C. Jones (more below).&lt;/p&gt;
    &lt;p&gt;Thank you so much to all of you for your time and support! ð&lt;/p&gt;
    &lt;head rend="h2"&gt;Internet and Network Protocols&lt;/head&gt;
    &lt;head rend="h3"&gt;Open and Standardized Protocols at the Heart of the Internetâs Success&lt;/head&gt;
    &lt;p&gt;During the 1990s, computing underwent a true revolution driven by the rise and global spread of the Internet. The Internet fulfilled the promise embodied in Sun Microsystemsâ slogan “The Network is the Computer”.&lt;/p&gt;
    &lt;p&gt;By interconnecting individual computers, the Internet enabled its users to communicate without limits and without worrying about borders.&lt;/p&gt;
    &lt;p&gt;This unrestricted interconnection emerged at a pivotal moment in modern history: the opposition between the West and the Eastern Bloc led by the USSR hadâalbeit temporarily, as we now knowâfaded away, China was becoming the worldâs factory, and the movement and collaboration between people were much freer and open than ever.&lt;/p&gt;
    &lt;p&gt;The Internet supported a kind of utopia of instant communication and sharing, previously unknown. This utopia was made possible by a set of open and standardized protocols. This was the key to enabling all kinds of different systems to cooperate and communicate seamlessly.&lt;/p&gt;
    &lt;p&gt;There were, of course, isolationist or monopolistic temptations from certain manufacturers or software editors. But open and standardized protocols ultimately prevailed, enabling unprecedented expansion. Built on top of IP, TCP, UDP, and DNS, among others, the HTTP and HTML duo would propel the Web as the Internetâs preferred communication platform for the next 30 years.&lt;/p&gt;
    &lt;head rend="h3"&gt;Limited Use of Encryption&lt;/head&gt;
    &lt;p&gt;The success of this communication utopia was achieved without much concern for ensuring authentication, integrity, and confidentiality of exchanges.&lt;/p&gt;
    &lt;p&gt;In 2015, only ~40% of websites used encryption. The consequences of this negligence in addressing security risks were confirmed by Edward Snowdenâs revelations in 2013: our data was exposed to anyone who wanted and could intercept and collect it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let’s Encrypt is coming&lt;/head&gt;
    &lt;head rend="h3"&gt;The Birth of an Automated and Free Certificate Authority&lt;/head&gt;
    &lt;p&gt;When asked about the main obstacles to the widespread adoption of encryption, J.C. Jones, one of the architects of Letâs Encrypt and now one of its site reliability engineers after leading Firefoxâs cryptographic team, responds:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“More and more information was flowing across the Web, and most data being transferred did not have integrity or confidential protections from TLS. The biggest stumbling block to using TLS everywhere was obtaining and managing server-side certificates, and so: Letâs Encrypt” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Obtaining a certificate was the main obstacle, and this was the priority to address.&lt;/p&gt;
    &lt;p&gt;This view was shared by a group of partners who, starting in 2013, pooled resources to establish Letâs Encrypt, an automated and free certificate authority. Sarah Gran, VP of Advancement at Letâs Encrypt, shares:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Early collaborators included people from Mozilla, Electronic Frontier Foundation, Akamai, Cisco, and the University of Michigan” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And that’s how Let’s Encrypt was born.&lt;/p&gt;
    &lt;p&gt;In the Web ecosystem, certificate authorities are organizations from which you can obtain a certificate for a domain after proving you control it.&lt;/p&gt;
    &lt;p&gt;And so, Let’s Encrypt is since 2015 a certificate authority that delivers for free (as in free beer) TLS Server certificates.&lt;/p&gt;
    &lt;p&gt;On the legal/administrative side, Let’s Encrypt certificate authority operates for the publicâs benefit and is a service provided by the Internet Security Research Group (ISRG), a California public benefit corporation.&lt;/p&gt;
    &lt;p&gt;Regarding Let’s Encrypt results ten years after its birth, they are really impressive (over 700M active certificates, over 60% of all the public TLS server certificates) and as Sarah Gran points out, so is the global HTTPS usage:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“When we started issuance, only about 39% of website visits were HTTPS. Today, itâs nearly 95% in the United States, and over 83% globally. We still have work to do, but we are proud of the progress weâve made over the last ten years” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let’s Encrypt delivers certificates in a automated manner using the ACME protocol which implies no manual action from the site owner nor the certificate authority. So, let’s speak now a little about the automation aspect!&lt;/p&gt;
    &lt;head rend="h3"&gt;Automation: The Core of the Operation&lt;/head&gt;
    &lt;p&gt;From the mid-2020s perspective, the automation at the heart of Letâs Encrypt might seem obvious, but in the first half of the 2010s, it was far from the norm. The ecosystem of public certificate authorities issuing server certificates was no exception.&lt;/p&gt;
    &lt;p&gt;At first glance, automation appears to be there to help website managers reliably deploy the TLS protocol on their sites, but it was first and foremost an absolute prerequisite for the very viability of the Let’s Encrypt project.&lt;/p&gt;
    &lt;p&gt;As Aaron Gable, tech lead of Boulderâthe software at the core of Letâs Encryptâ, confirms:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Automation was always going to be critical to Letâs Encryptâs success. From the very beginning, we knew that there was no way we could scale manual validation on a non-profitâs budget” – Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Indeed, it is worth noting that Letâs Encrypt has operated on an Internet scale from the start with a small team of about fifteen engineers, or even fewer at launch. For this team, automation was the only viable way to fulfill the immense mission they had set for themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACME&lt;/head&gt;
    &lt;head rend="h3"&gt;The Open and automated Protocol That Powers Letâs Encrypt&lt;/head&gt;
    &lt;p&gt;When we talk about automation in relation to Letâs Encrypt, we are talking about ACME (Automated Certificate Management Environment).&lt;/p&gt;
    &lt;p&gt;This protocol allows client software to prove to an ACME-compatible certificate authority that it controls the domain for which it is requesting a certificate.&lt;/p&gt;
    &lt;p&gt;Sarah Gran clarifies an important point:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“An important aspect of how Letâs Encrypt works is that we verify control over a domain, not ownership” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Control vs. ownership of a domainâa nuance everyone should keep in mind.&lt;/p&gt;
    &lt;p&gt;This proof of control involves the client responding to a challenge issued by the ACME-compatible certificate authority. The challenge can be an HTTP, DNS, or TLS challenge, depending on the clientâs choice and certificate authority support. Completing the challenge requires the ACME client to place a value provided by the ACME serverâin a standardized HTTP path, a DNS zone, or a TLS response, respectively. All of these operations involve cryptography, of course.&lt;/p&gt;
    &lt;p&gt;The key point with ACME is that this entire dialogue between the client and the ACME server is executed without any human intervention, enabling the automatic issuance of certificates. Their deployment and integration into the web service can also generally be automated using scripts triggered after issuance.&lt;/p&gt;
    &lt;p&gt;On the Let’s Encrypt website, you can discover more information about how ACME works and get more detailled information about it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Birth of ACME&lt;/head&gt;
    &lt;p&gt;One might wonder whether ACME was part of Letâs Encryptâs design from the beginning.&lt;/p&gt;
    &lt;p&gt;J.C. Jones confirms:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“By late 2014, the idea of an HTTP REST API with “/challenge” and “/certificate” existed, but we hadnât defined much beyond that. We had a series of in-person meetings, in the Mozilla San Francisco office on Embarcadero and the EFF office in the Tenderloin through the spring of 2015 where we worked out the details” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;ACME was indeed at the core of Letâs Encrypt from the start and underwent a refinement process to cover all use cases as thoroughly as possible.&lt;/p&gt;
    &lt;p&gt;To learn more about the roots of ACME and Let’s Encrypt, there is a very informative document to read: the Let’s Encrypt paper for ACM CCS 2019 in London. It mentions the previous work of two teams:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“A group led by Alex Halderman at the University of Michigan and Peter Eckersley at EFF was developing a protocol for automatically issuing and renewing certificates. Simultaneously, a team at Mozilla led by Josh Aas and Eric Rescorla was working on creating a free and automated certificate authority”.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When these two teams discovered each other’s work, they joined forces. ACME and its implementation in Let’s Encrypt were the result of this joint effort supported by the initial partners mentioned above.&lt;/p&gt;
    &lt;head rend="h3"&gt;Securing the Web or the Internet?&lt;/head&gt;
    &lt;p&gt;Speaking of use cases, one might wonder whether the Web was Letâs Encryptâs primary target, or if securing the Internet with its multiple protocols was also part of the objectives.&lt;/p&gt;
    &lt;p&gt;Sarah Gran provides an unambiguous first-level answer:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“From Day One, we have sought to get the web to 100% encryption” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But when asked about the various types of challenges in the protocol, J.C. Jones offers a nuance:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“DNS, TLS-SNI, and HTTP were all in planning in spring 2015, but many of us were less confident in the procedure around the DNS validation. Which is ironic, as it turned out TLS-SNI had a vulnerability so we had to stop using it and our DNS validation was ultimately fine. In general, the collection of us were simply respectful of the great complexity within the DNS” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is a perspective not often publicly expressed by engineers primarily from the Web: their lack of confidence in implementing a DNS challenge stemmed from their humility regarding the complexity of the DNS ecosystem and the level of expertise required to master it.&lt;/p&gt;
    &lt;p&gt;The challenge was ultimately met, and this DNS challengeâthough not its primary purposeâenabled multiple protocols outside HTTP like SMTP to be secured by ACME.&lt;/p&gt;
    &lt;head rend="h2"&gt;Standardization and Open Source&lt;/head&gt;
    &lt;head rend="h3"&gt;Developed in the Open&lt;/head&gt;
    &lt;p&gt;ACME was documented openly from the start, and Certbot, the first open-source ACME client co-developed with the EFF, served as the client side reference implementation.&lt;/p&gt;
    &lt;p&gt;Similarly, a standardization process through the IETF resulted in RFC 8555 in March, 2019.&lt;/p&gt;
    &lt;p&gt;One of the consequences developing an open and standardized protocol was the creation of a multitude of ACME clients covering a very wide range of use cases.&lt;/p&gt;
    &lt;p&gt;J.C. Jones confirms that this was the goal:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“This is what we foresaw, or at least hoped for. The initial client development often had conversations like, âoh, if someone wants that, then theyâll write their own client.â It was a key part of why the REST API needed to be an IETF standard, and was part of the argument at the IETF BoF that resulted in the formation of the ACME Working Group in Q3 2015” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Letâs Encrypt has also always provided constant support to developers by responding in its forum or on its GitHub issue tracker, and all this work has truly paid off. An interesting post has been recently written about support on the Let’s Encrypt blog.&lt;/p&gt;
    &lt;head rend="h3"&gt;Standardization for what benefits?&lt;/head&gt;
    &lt;p&gt;The other question that can be asked is whether or not the standardization process within the IETF has led to an improvement in the ACME protocol thanks to the cooperation that guides this process.&lt;/p&gt;
    &lt;p&gt;Jacob Hoffman-Andrews, one of the RFC 8555 authors working for EFF &amp;amp; Let’s Encrypt, confirms an initial benefit that the ACME protocol has been able to derive from its standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“One of the big changes was from a validation-first flow to a certificate-request-first flow. In other words, earlier drafts had subscribers requesting validation for domain names and then requesting a certificate once those validations were successful. The final RFC has subscribers request a certificate, and then the CA tells the subscriber what validations are needed. This change originated from within the IETF discussion process, and was intended to make handling of wildcard certificates more natural.” – Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Aside this first design improvement, Jacob details a second major improvement of the security of the protocol, improvement that also landed during the IETF standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Another big change, also originated from within the IETF, was to make all requests authenticated, including GET requests. Since ACME is authenticated with signed POSTs, this necessitated the POST-as-GET concept thatâs in ACME today” – Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can see there how IETF iterations can challenge the security of a protocol and leads its development to innovative solutions to tackle the challenges it faces!&lt;/p&gt;
    &lt;p&gt;Last, Jacob adds another information that illustrates the benefits of developing a protocol into the open: it allows the community to evaluate (and sometimes, fix) its security level due to the availability of all materials and often, of the reference implementation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Another very important evolution was the deprecation of the tls-sni-01 challenge method. This was found to be flawed by Frans Rosen, a security researcher. It was replaced with TLS-ALPN-01, developed at IETF with significant input from Google” – Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Letâs Encrypt, ACME, and the Public Certificate Authorities Ecosystem&lt;/head&gt;
    &lt;p&gt;In 2015, the arrival of Letâs Encrypt in the public certificate authorities ecosystem raised a number of questions.&lt;/p&gt;
    &lt;p&gt;What level of cooperation or hostility? What impact on the viability of existing certificate authorities?&lt;/p&gt;
    &lt;p&gt;Here again, the fact that Letâs Encrypt was based on an open protocol, immediately subject to an IETF standardization initiative, enabled collaboration and adoption by the most innovative certificate authorities.&lt;/p&gt;
    &lt;p&gt;I spoke about the External Account Binding (EAB) option of the protocol with J.C. Jones. EAB is a way for an ACME client to authenticate to an ACME server using an identifier and a key value which are verifiable by the server in a repository it maintains. With EAB, an ACME server can filter who can uses its service which is useful for commercial certificate authorities for example; it is an alternative model to Let’s Encrypt one where anybody can ask for a certificate.&lt;/p&gt;
    &lt;p&gt;Using the example of EAB, J.C. Jones confirms the collaboration with certificate authorities that happens during the IETF standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“EAB was an early addition at the IETF ACME Working Group. Many in the room were worried that without a means to bind to a payment method, ACME would not get adoption. In fact, some of the counterarguments to forming ACME were blunted by EAB, as such a mechanism wasnât in the theoretically-competing, already-existent standard: SCEP. SCEP, it was argued, already handled ‘free’ certificate issuance, for private certificate authorities. Anything else needed a feasible path for usage payment.” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Beyond billing, the addition of EAB enabled also some commercial certificate authorities to integrate their existing domain control validation systems with ACME, allowing some of them to skip the challenge step of the ACME protocol.&lt;/p&gt;
    &lt;p&gt;The IETF standardization process, based on an open process, created the necessary discussion space for cooperation among entities that did not necessarily share the same objectives.&lt;/p&gt;
    &lt;p&gt;The result, ten years after the introduction of ACME and the completion of its standardization process in 2019, is that ACME has become the primary means by which all public certificate authoritiesâboth free and commercialârely on for their transition to an automated future of issuing short-lived certificates.&lt;/p&gt;
    &lt;p&gt;Effectively, until early this year, the maximum lifespan of a public TLS server certificate was set to 398 days by the CA/B Forum, the organization that set the rules for public certificate authorities. With the vote of the ballot SC081 at the CA/B Forum in April 2025, it has been decided that the certificate lifespan will decrease gradually starting March 2026 to reach 47 days in March 2029. The automation provided by ACME seems to be one of the main identified levers to help organizations to adapt to this drastic reduction in the lifespan of public TLS server certificates.&lt;/p&gt;
    &lt;head rend="h3"&gt;Created at Let’s Encrypt, adopted everywhere&lt;/head&gt;
    &lt;p&gt;It is important to note that although ACME was developed by the team managing Let’s Encrypt, this protocol is now one of the main protocols for automated certificate acquisition adopted by all public certificate authorities.&lt;/p&gt;
    &lt;p&gt;And outside the public certificate authorities ecosystem, I think it’s fair to say that this protocol is also becoming increasingly popular with technical architects in companies with private certificate authorities.&lt;/p&gt;
    &lt;p&gt;This has been the case in my company for several years now, where we have deployed an ACME endpoint in front of our internal certificate authority. Among the benefits we have seen, we have been able to rely on the vast ACME clients ecosystem in order to provide an ACME client to each OS or middleware that powers our infrastructure. We can see there how certificate obtention agility powered by ACME helps organizations in their journey to global IT agility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Innovation and the adoption challenge&lt;/head&gt;
    &lt;head rend="h3"&gt;The ARI episode&lt;/head&gt;
    &lt;p&gt;We may fear that the development of a protocol supported primarily by a team as small as Let’s Encrypt’s will be fairly limited in terms of evolution and innovation.&lt;/p&gt;
    &lt;p&gt;But the history of ACME shows that its evolution continues after its initial standardization.&lt;/p&gt;
    &lt;p&gt;In 2025, we saw with the ARI (ACME Renewal Information – RFC 9773) extension that the ACME protocol continues to evolve. ARI is a way for a certificate authority to suggest a renewal period to its clients, often earlier than they would have determined themselves. This use case is particularly relevant when the certificate authority needs to mass-revoke certificates that, for example, did not comply with the rules the certificate authority must follow when issuing certificates.&lt;/p&gt;
    &lt;p&gt;More specifically, J.C. Jones and Aaron Gable point two incidents that had to be handled by the Let’s Encrypt team and that were the start for the ARI initiative:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Explicitly, as remediation of https://bugzilla.mozilla.org/show_bug.cgi?id=1619179 and https://bugzilla.mozilla.org/show_bug.cgi?id=1715672 " J.C. Jones and Aaron Gabble&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Support to encourage adoption&lt;/head&gt;
    &lt;p&gt;Aaron Gable leads the effort of designing and implementing ARI. But even if a new extension to the protocol has been produced, it can only reach its potential users after ACME clients have implemented it into their code base. As previously said, the team and some community members invest a lot on providing support to the community. In the case of ARI, this support is oriented to the ACME clients developers in order to make these clients ARI aware.&lt;/p&gt;
    &lt;p&gt;Providing an efficient support and effective resources to the client side ACME actors is a huge part of the challenge in order to keep ACME ecosystem healthy and agile.&lt;/p&gt;
    &lt;p&gt;As illustrates by Sarah Gran, another way to give momentum to a new feature is to lift certain restrictions on access to the certificate authority:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In order to encourage ARI adoption, weâve configured Letâs Encrypt to allow subscribers who renew via ARI to bypass our rate limits.” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Client Side Update Challenge&lt;/head&gt;
    &lt;p&gt;But despite a good support work and incentive measures, Aaron Gable confirms ARI adoption is just at its start:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“There is still much progress to be made. Part of the appeal of the Automated Certificate Management Environment is that many users can set-and-forget their client and configuration. This means that most clients never receive software updates, and even client projects that have implemented ARI in their latest version still have massive install bases that arenât running that version. Weâve worked closely with many clients developers to implement ARI, and contributed implementations ourselves in several cases, but for widespread adoption the whole ecosystem will need to slowly turn over” – Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This situation is really shared with a lot of client side softwares that “just work”(c) and it raises some concerns about how to make an ecosystem keeping track with innovation on its client side.&lt;/p&gt;
    &lt;p&gt;This challenge arises not only in terms of updating the client, but also in terms of updating the configuration. Many ACME clients rely on cron tasks. To have an efficient ARI setup, your task has to run ideally on a daily basis be able to ask the certification authority every day whether the certificate needs to be reissued. This is not the classic cron task setup. So, users have to modify this cron task frequency to reach the ARI goal of certificate reissuance led by certificate authority. Client side ACME setup evolution is a really challenging task.&lt;/p&gt;
    &lt;head rend="h3"&gt;Evolution on server side ACME implementation&lt;/head&gt;
    &lt;p&gt;CA/B Forum has recently asked public certificate authorities to adopt Multi-Perspective Issuance Corroboration (MPIC) to guard against BGP attacks. We have asked Aaron Gable about the impacts that kind of measure have had on ACME server side implementation in the Let’s Encrypt infrastructure:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Weâve had to make few if any changes to our infrastructure to accommodate recent requirements changes such as MPIC and DNSSEC validation. We innovated MPIC (then called Remote Validation) along with a research team at Princeton, and implemented it in 2020. Our experience already running such a service helped inform the requirements as they were incorporated by the CA/B Forum.” – Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The lesson learnt here is that being at the edge of the innovation let you shape part of the future of your ecosystem and significantly lower the impact on your infrastructure of many regulatory measures that come into effect over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future&lt;/head&gt;
    &lt;p&gt;It is really encouraging to see a lot of innovation in the ACME ecosystem.&lt;/p&gt;
    &lt;p&gt;So what evolutions can we expect to see in the future?&lt;/p&gt;
    &lt;p&gt;We have asked the question to Aaron Gable who gave us two upcoming developments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Weâre currently working on standardizing profile selection for ACME, and our deployment of the early draft of this standard has already brought some much-needed flexibility to the WebPKI, enabling us to make changes to our certificate contents with minimal disruption.”&lt;/item&gt;
      &lt;item&gt;“Iâm also excited about a potential future change which would introduce a ‘pubkey’ identifier type, along with a set of challenges that allow the client to demonstrate control over the corresponding keypair. This would fix the gap today that presenting a CSR does not actually prove possession of the key in that CSR.” – Araron Gable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fastly has also recently contributed to ACME in order to improve the &lt;code&gt;dns-01&lt;/code&gt; challenge in a multi-cloud and multi-PKI environment. An IETF draft describing this &lt;code&gt;dns-account-01&lt;/code&gt; challenge is online. This is further proof that the public TLS ecosystem has truly embraced the ACME protocol as its primary automation tool.&lt;/p&gt;
    &lt;p&gt;Another recent development based on ACME has also shed new light on the potential of this protocol: since 2022, a draft is under progress at the IETF in order to write an ACME extension. The goal of this extension is to use ACME to obtain a certificate for a device in order to prove its identity. The challenge is based on device attestation and what’s new in this case is the arrival of a third party, the attestation server.&lt;/p&gt;
    &lt;p&gt;What is remarkable here is that we are no longer dealing with ACME’s initial use case, namely obtaining TLS server certificates: we can see in this IETF draft the potential of ACME as a challenge-based framework to obtain certificate in very different contexts.&lt;/p&gt;
    &lt;p&gt;Indeed, we can venture to say that ACME’s future looks bright ð&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;It is heartening to see that, 30 years after the widespread adoption of the Internet, open and standardized protocols continue to revolutionize its use.&lt;/p&gt;
    &lt;p&gt;ACME and its Let’s Encrypt implementation at scale have enabled the widespread adoption of HTTPS, thereby raising the level of security for billions of Internet users and also of private networks.&lt;/p&gt;
    &lt;p&gt;Having been able to do it inside a non profit organization, providing the Internet with an open and standardized protocol is a great success for all people believing in FreeSoftware and an Open Internet.&lt;/p&gt;
    &lt;p&gt;As a community, I really think we can thank these organizations, teams, and engineers who continue to uphold the promise of efficiency and Freedom brought about by cooperation around open protocols. They inspire new generations (and older ones I guess ð) demonstrating big things can still be achevied today in the open for the common good at the Internet scale!&lt;/p&gt;
    &lt;p&gt;I would like to extend a special thank you to the members of the Let’s Encrypt team, J.C. Jones, Aaron Gable, Sarah Gran and Jacob Hoffman-Andrews, for the time and effort they dedicated to answering my questions. Without them, this article would not have been possible.&lt;/p&gt;
    &lt;p&gt;A big shout out also to Eric Leblond and Philippe Teuwen who carefully proofread some early drafts of the article and Philippe Bonnef and Thibault Meunier for proofreading some of the last drafts. They all gave me so valuable and insightful advices ð&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.brocas.org/2025/12/01/ACME-a-brief-history-of-one-of-the-protocols-which-has-changed-the-Internet-Security/"/><published>2025-12-03T23:28:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46142000</id><title>Kea DHCP: Modern, open source DHCPv4 and DHCPv6 server</title><updated>2025-12-04T10:45:13.562719+00:00</updated><content>&lt;doc fingerprint="ea1b597bc497298e"&gt;
  &lt;main&gt;&lt;head rend="h4"&gt;Kea 3.0, our first LTS version&lt;/head&gt;&lt;p&gt;ISC is excited to announce the release of Kea 3.0.0! This is a major release, and is the first Long-Term Support (LTS) version of Kea.&lt;/p&gt;Read&lt;p&gt;Modern, open source DHCPv4 &amp;amp; DHCPv6 server&lt;/p&gt;&lt;p&gt;ISC distributes TWO full-featured, open source, standards-based DHCP server distributions: Kea DHCP and ISC DHCP. Kea includes all the most-requested features, is far newer, and is designed for a more modern network environment. ISC announced the End of Life for the older ISC DHCP system in 2022. Users of ISC DHCP may find these resources helpful in migrating their DHCP server deployments to the Kea server.&lt;/p&gt;&lt;p&gt;Modular Component Design, Extensible with Hooks Modules. The Kea distribution includes separate daemons for a DHCPv4 server, a DHCPv6 server, and a dynamic DNS (DDNS) module. Many optional features are enabled with dynamically-loaded “Hooks Modules,” which you need run only if you are using them. You can write your own hooks modules (in C++) or try some of the hooks we offer.&lt;/p&gt;&lt;p&gt;On-line Re-configuration with REST API. Kea uses a JSON configuration file that can be modified remotely via &lt;code&gt;set&lt;/code&gt; commands and reloaded without stopping and restarting the server, an operation that could take quite a while with ISC DHCP.&lt;/p&gt;&lt;p&gt;Designed to Integrate with Your Existing Systems. Kea allows you to separate the data from the execution environment, enabling new deployment options. Your network data - leases, host reservation definitions, and most configuration data - can be located separately from the DHCP server itself, using a Kea “backend.”&lt;/p&gt;&lt;p&gt;Kea supports two database backends; MySQL and PostgreSQL. Besides the obvious benefits (you avoid JSON formatting errors, you can quickly and easily mine the data for other purposes) using a database backend enables multiple Kea servers to share the data. Potential benefits:&lt;/p&gt;&lt;p&gt;Web-based graphical dashboard. Kea now has a graphical dashboard for monitoring multiple Kea servers. This system, called Stork, uses agents deployed on the Kea servers to relay information to a centralized management platform, providing the administrator with an easy-to-use quick view of system status and activity.&lt;/p&gt;&lt;p&gt;Modern, higher performance implementation. Kea is multi-threaded, and when configured for efficient operation, it can be performant enough for a large-scale, short-lease duration environment, which is the most demanding scenario.&lt;/p&gt;&lt;p&gt;The core Kea daemons are open source, shared under MPL2.0 licensing. Kea is developed in the open on ISC’s GitLab; we welcome you to open issues and submit patches there. Kea runs on most Linux and Unix platforms, as well as MacOS. If you don’t want to build from our source distribution, we also provide a repository of pre-built packages for most popular operating systems.&lt;/p&gt;&lt;p&gt;Contact ISC for Support&lt;/p&gt;&lt;p&gt;Your major design decisions are whether to deploy in pairs for High Availability and use the default csv file for host and lease data, or to install a separate database for a Kea data “backend.” Some of these decisions can limit your performance. See our Knowledgebase for advice on designing for optimal performance.&lt;/p&gt;&lt;p&gt;Instructions are available for building and installing Kea from the source packages downloadable below. ISC provides pre-built packages for RHEL, Fedora, Ubuntu, and Debian. If you are using any Kea hook libraries, you will also need to install and configure those.&lt;/p&gt;&lt;p&gt;The Kea Administrator Reference Manual (ARM) is the primary reference for Kea configuration. The extensive set of example configuration files in the project repo and our knowledgebase may help you get started. If you are migrating from an existing ISC DHCP deployment, try the Kea Migration Assistant (a special feature of the ISC DHCP distribution). This will enable you to save your current ISC DHCP server configuration as a Kea configuration file. It will still need some manual adjustment, but this tool should translate the bulk of your configuration.&lt;/p&gt;&lt;p&gt;Most users will benefit from joining the kea-users mailing list. Consider joining our Kea project GitLab to log issues, see what we’re working on, submit patches, and participate in development. Consider deploying Stork for a graphical management dashboard. If your DHCP is critical to your business, we recommend you subscribe for technical support from ISC.&lt;/p&gt;&lt;p&gt;Stork aggregates data about the health of the system hosting Kea, as well as the status and activity level of Kea itself. Parameters reported include memory, CPU utilization, software versions, and uptime.&lt;/p&gt;&lt;p&gt;Stork displays configured pools, with # of addresses provisioned and assigned and even tracks pool utilization across shared networks. Graphical elements highlight areas of high utilization to alert the operator to take actionHigh Availability pairs are monitored and their configured role and status are shown, making it easy to see which servers don’t have a backup established, and when a failover event has occurred.&lt;/p&gt;&lt;p&gt;Add, update and view DHCPv4 and DHCPv6 host reservations, using a graphical interface to select a host identifier, assign a hostname, reserve an IP address, associate a client class, and configure boot file information and DHCP options.&lt;/p&gt;&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;Service Options&lt;/cell&gt;&lt;cell role="head"&gt;Gold support&lt;/cell&gt;&lt;cell role="head"&gt;&lt;p&gt;Silver support&lt;/p&gt;&lt;/cell&gt;&lt;cell role="head"&gt;Bronze support&lt;/cell&gt;&lt;cell role="head"&gt;Basic (no support)&lt;/cell&gt;&lt;cell role="head"&gt;Premium (no longer offered)&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Critical issue response&lt;/cell&gt;&lt;cell&gt;30 minutes, 24x7&lt;/cell&gt;&lt;cell&gt;1 hour, 24x7&lt;/cell&gt;&lt;cell&gt;2 hours, business hours only*&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Standard issue response&lt;/cell&gt;&lt;cell&gt;4 business hours*&lt;/cell&gt;&lt;cell&gt;8 business hours*&lt;/cell&gt;&lt;cell&gt;Next business day&lt;/cell&gt;&lt;cell&gt;community support via public mailing list&lt;/cell&gt;&lt;cell&gt;community support via public mailing list&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Early vulnerability notifications&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;3 days&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Kea 3.0 hook libraries (RBAC and Configuration Backend are the only commercially-licensed ones)&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;N/A&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Kea 2.6 and earlier hook libraries included&lt;/cell&gt;&lt;cell&gt;All - Enterprise, Premium and Subscription&lt;/cell&gt;&lt;cell&gt;All - Enterprise, Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Stork support&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Community support via user mailing list&lt;/cell&gt;&lt;cell&gt;Community support via user mailing list&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Purchasing&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;no longer offered&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Pricing based on deployment size and service level.&lt;/p&gt;Contact ISC for a quote&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;VERSION&lt;/cell&gt;&lt;cell role="head"&gt;STATUS&lt;/cell&gt;&lt;cell role="head"&gt;DOCUMENTATION&lt;/cell&gt;&lt;cell role="head"&gt;RELEASE DATE&lt;/cell&gt;&lt;cell role="head"&gt;EOL DATE&lt;/cell&gt;&lt;cell role="head"&gt;DOWNLOAD&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;3.0.2&lt;/cell&gt;&lt;cell&gt;Current Stable - LTS&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;October 2025&lt;/cell&gt;&lt;cell&gt;June 2028&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;2.6.4&lt;/cell&gt;&lt;cell&gt;Current Stable&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;July 2025&lt;/cell&gt;&lt;cell&gt;July 2026&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.1.4&lt;/cell&gt;&lt;cell&gt;Development&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;November 2025&lt;/cell&gt;&lt;cell&gt;June 2026&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.isc.org/kea/"/><published>2025-12-03T23:58:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46142100</id><title>Average DRAM price in USD over last 18 months</title><updated>2025-12-04T10:45:13.493004+00:00</updated><content/><link href="https://pcpartpicker.com/trends/price/memory/"/><published>2025-12-04T00:08:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46142866</id><title>Why WinQuake exists and how it works</title><updated>2025-12-04T10:45:13.332751+00:00</updated><content>&lt;doc fingerprint="e73b81353f2276d7"&gt;
  &lt;main&gt;
    &lt;p&gt;When I took a look at the history of Quake binaries, they all made sense to me. &lt;code&gt;quake.exe&lt;/code&gt; was the original release, able to run on DOS and Windows 95. Then came &lt;code&gt;vquake.exe&lt;/code&gt; to support the hardware accelerated chip Vérité 1000. Later, &lt;code&gt;glquake.exe&lt;/code&gt; generalized hardware acceleration to any vendor providing OpenGL drivers. And to revolutionize Internet deathmatch, id Software released QuakeWorld server and client (&lt;code&gt;qwsv.exe&lt;/code&gt; and &lt;code&gt;qwcl.exe&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;However, I could not figure out the point of &lt;code&gt;winquake.exe&lt;/code&gt;. Until now. Here is what I understood and a little bit of a dive into how it works.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;quake.exe&lt;/code&gt; runs on both DOS and Windows 95 but how well does it perform? A quick benchmark on my Pentium MMX 233MHz, Matrox Mystique PC (320x200 with 101 screen size) and sound on, showed the following numbers.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
        &lt;cell role="head"&gt;Framerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;quake.exe&lt;/code&gt; started from DOS&lt;/cell&gt;
        &lt;cell&gt;48 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;quake.exe&lt;/code&gt; started from Windows 95&lt;/cell&gt;
        &lt;cell&gt;38 fps&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So "framerate" is the beginning of an answer to justify the existence of WinQuake. &lt;code&gt;quake.exe&lt;/code&gt; running from Windows 95 is roughly 25% slower than the same binary started from DOS. And that is to be expected. Windows 95 runs DOS applications in a virtual machine ("DOS BOX"), where memory access, interrupts, and signals are virtualized, which incurs overhead.&lt;/p&gt;
    &lt;p&gt;Another element of the answer comes from Quake Chunnel. &lt;code&gt;quake.exe&lt;/code&gt; can access Windows 95 TCP/IP stack, but only via a convoluted tech from Mpath to bridge a "DOS BOX" to win32 dlls. By having a win32-only application, id Software had guaranteed direct access to &lt;code&gt;winsock.dll&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Last but not least, id Software really wanted Quake to work on Windows NT. Despite their best efforts, the people at DJGPP could not make their DPMI client in &lt;code&gt;quake.exe&lt;/code&gt; compatible with the NT Virtual DOS Machine (NTVDM).&lt;/p&gt;
    &lt;quote&gt;Near pointers don't work under NT - which was a huge disappointment to iD and generated some conference calls to Microsoft.&lt;lb/&gt;- Charles Sandmann[1]&lt;/quote&gt;
    &lt;p&gt;A fun way to start exploring is to first read WQREADME.TXT and then take a look at all the modes available in &lt;code&gt;winquake.exe&lt;/code&gt;. They are configured with the script wq.bat.&lt;/p&gt;
    &lt;quote&gt;Options for running WinQuake: wq max: all features on, but doesn't work on all systems wq fast: maximum speed, but doesn't work on all systems wq fastvid: maximum video speed, but safer, probably slower sound wq fastsnd: maximum sound speed, but safer, probably slower video wq safe: very likely to run, but may be slower wq verysafe: almost sure to run, but probably slower, and no sound&lt;/quote&gt;
    &lt;p&gt;Here are the numbers I got for each mode, still with the same Pentium MMX 233MHz machine and same configuration.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
        &lt;cell role="head"&gt;Framerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq max&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;42.4 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fast&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;41.8 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fastvid&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;45.0 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fastsnd&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;41.8 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq safe&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;45.0 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;wq verysafe&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;40.0 fps*&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Impressive. &lt;code&gt;winquake.exe&lt;/code&gt; managed to bring up the framerate within 6% of &lt;code&gt;quake.exe&lt;/code&gt; running on DOS. Mission accomplished. But how does it works?&lt;/p&gt;
    &lt;p&gt;Each "mode" is configured via command-line flags. This part reveals there are three types of backend for input controls, audio, and video.&lt;/p&gt;
    &lt;quote&gt;max winquake -dinput fast winquake fastvid winquake -wavonly fastsnd winquake -nodirectdraw -nowindirect safe winquake -wavonly -nodirectdraw -nowindirect verysafe winquake -dibonly -nosound -nojoy&lt;/quote&gt;
    &lt;p&gt;Amusingly, the mode that provides the highest framerate, &lt;code&gt;fastvid&lt;/code&gt; keeps everything default but disables an audio backend!&lt;/p&gt;
    &lt;p&gt;"fastvid" was also the name of a tool to fix the Pentium Pro abysmal video write speed on chipset that shipped with buggy "Write Posting". The option in &lt;code&gt;qw.bat&lt;/code&gt; has nothing to do with it.&lt;/p&gt;
    &lt;p&gt;WinQuake can send its sound effects (the music comes from CD tracks) using two audio backends (with &lt;code&gt;-nosound&lt;/code&gt; disables sound effects altogether).&lt;/p&gt;
    &lt;p&gt;The two backends are DirectSound (&lt;code&gt;dsound.h&lt;/code&gt; from DirectX) and what id calls wave sound which is in fact &lt;code&gt;winmm.h&lt;/code&gt;, the Windows MultiMedia audio API, dating back to Windows 3.1.&lt;/p&gt;
    &lt;p&gt;If DirectSound is available, WinQuake uses it to provide the lowest latency. However this backend has a higher impact on the CPU and results in 10% lower framerate. With &lt;code&gt;-wavonly&lt;/code&gt;, users can force usage of &lt;code&gt;WinMM&lt;/code&gt; which results in higher latency but higher framerate.&lt;/p&gt;
    &lt;p&gt;To read user inputs, WinQuake uses either DirectInput (&lt;code&gt;dinput.h&lt;/code&gt; from DirectX) or the legacy Windows API &lt;code&gt;winuser.h&lt;/code&gt;.

&lt;/p&gt;
    &lt;p&gt;By default WinQuake uses &lt;code&gt;winuser.h&lt;/code&gt; but usage of DirectInput can be requested via &lt;code&gt;-dinput&lt;/code&gt; for slightly smoother motion and responsiveness to fast spinning motions. I suspect it was not enabled by default for cases where DirectX was not installed or perhaps fear of driver problems.&lt;/p&gt;
    &lt;p&gt;Joystick inputs are handled with &lt;code&gt;joystickapi.h&lt;/code&gt;. Likewise, it seems drivers may not have been stable since id provided a way to disable it with &lt;code&gt;-nojoy&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The part that was the most interesting to me was the video backends. WinQuake can operate in five modes using GDI, VGA, VESA, Accelerated VESA, or DirectDraw.&lt;/p&gt;
    &lt;p&gt;The Graphics Device Interface (GDI) (&lt;code&gt;wingdi.h&lt;/code&gt;) is the foundation to render anything on the desktop in Windows 95. Applications usually did not use it directly but instead called &lt;code&gt;winuser.h&lt;/code&gt; (which in turns used low-level &lt;code&gt;wingdi.h&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;WinQuake can render to a Device-Independent Bitmaps (DIB) which is a surface to be blitted towards a window though GDI. The surface can be of any dimension so there are no "display mode" to detect here, WinQuake hardcodes its DIB modes to square-pixel resolutions 320x240, 640x480, and 800x600.&lt;/p&gt;
    &lt;p&gt;Because it is using Windows "by the book", DIB mode is the safest mode that should always work. It is also the slowest way to render to the screen because WinQuake first renders to a DIB that is then sent to the GDI and then sent to the video card.&lt;/p&gt;
    &lt;p&gt;While slower, it is not devoid of hardware acceleration. Many graphic cards wanting to perform well under Windows 95 had hardware acceleration implementation of crucial functions such as &lt;code&gt;bitBlt&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Finally, DIB mode is the only one able to render in "windowed" mode. Every other mode takes over and renders in "fullscreen" mode. Note that DIB can also render in pseudo-full screen if WinQuake is started with &lt;code&gt;dibonly&lt;/code&gt; but this is "faked" with a borderless window covering the whole screen.&lt;/p&gt;
    &lt;p&gt;For everything not DIB, WinQuake uses SciTech's MegaGraph Graphics Library. It was a rather expensive lib ($499 in 1997, $1,000 in 2025)[2] but well worth its price because it brought order into the chaos that was the world of video systems in 1997 if a game operated outside GDI.&lt;/p&gt;
    &lt;p&gt;WinQuake could find itself having to deal with the following types of video systems.&lt;/p&gt;
    &lt;quote&gt;1. VBEAF : VESA Accelerator Function 2. VBE2 : VESA Linear Frame Buffer for direct to VRAM write/read. 3. DirectDraw : Only available if DirectX is installed. 4. StandardVGA : That good ol' VGA video mode.&lt;/quote&gt;
    &lt;p&gt;When it starts, WinQuake registers the drivers it wants MGL to load (see &lt;code&gt;registerAllDispDrivers&lt;/code&gt;). MGL then lists all supported resolutions and pick the highest performance drivers to access each of them (in the order list above).&lt;/p&gt;
    &lt;quote&gt;void registerAllDispDrivers(void) { /* Even though these driver require WinDirect, we register * them so that they will still be available even if DirectDraw * is present and the user has disabled the high performance * WinDirect modes. */ MGL_registerDriver(MGL_VGA8NAME,VGA8_driver); if (useWinDirect){ MGL_registerDriver(MGL_LINEAR8NAME,LINEAR8_driver); if (!COM_CheckParm ("-novbeaf")) MGL_registerDriver(MGL_ACCEL8NAME,ACCEL8_driver); } if (useDirectDraw) { MGL_registerDriver(MGL_DDRAW8NAME,DDRAW8_driver); } }&lt;/quote&gt;
    &lt;p&gt;The list of modes and which driver was selected by MGL is available via the command &lt;code&gt;vid_describemodes&lt;/code&gt; in Quake console. In the screenshot below, we can see almost the full house of drivers &lt;code&gt;VGA8.DRV&lt;/code&gt;, &lt;code&gt;DDRAW.DRV&lt;/code&gt;, &lt;code&gt;LINEAR8.DRV&lt;/code&gt;, and the windowed DIB modes.&lt;/p&gt;
    &lt;p&gt;I had never heard of VBE/AF before reading MGL source code. As far as I understand, it never gained much traction and few vendors wrote drivers to support it.&lt;/p&gt;
    &lt;p&gt;Many games used MGL: WinQuake, Hexen II, Grand Theft Auto, Maui Mallard in Cold Shadow, Total Mayhem, Balls of Steel.&lt;/p&gt;
    &lt;p&gt;Microsoft was very much aware that GDI was fine for applications but not enough for video games. Already in Windows 3.1 they had released a game developer SDK called WinG to give a more direct fullscreen access to the screen. The second version of WinG was renamed DirectX and contained the 2D fullscreen API which they called DirectDraw.&lt;/p&gt;
    &lt;quote&gt;Although safer and more reliable, Microsoft Windows imposed many restrictions on applications. One result of this situation was that games, and other high-performance graphics applications, could no longer access the hardware resources directly in order to maximize performance and expand functionalities. For several years game programmers continued to exercise the craft in DOS, and Windows users had to switch to the DOS mode to run games, simulations, and other graphics programs. The resulting situation implied a major contradiction: a graphical operating system in which graphics applications would execute with marginal performance&lt;lb/&gt;The first effort in this direction was a product named WinG, in reference to Windows for Games. WinG was first made available in 1994 and it required Win32 in Windows 3.1. Its main feature is that WinG enabled the game programmer to rapidly transfer bitmaps from system memory into video memory. This made possible the creation of Windows games that executed with much better performance.&lt;lb/&gt;Microsoft renamed the new version of the Game SDK, calling it DirectX 2. Other versions later released were named DirectX 3, DirectX 5, DirectX 6, and currently, DirectX 7.&lt;lb/&gt;- Feng Yuan, "Windows Graphics Programming Win32 GDI and DirectDraw"&lt;/quote&gt;
    &lt;p&gt;In terms of performance, DirectDraw was a step up from GDI but it was also not guaranteed to work due to driver bugs or if the user had not installed DirectX. It can be disabled with &lt;code&gt;nodirectdraw&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Readers may have picked up on something written earlier that was blatantly wrong. Direct access to the hardware is forbidden to Win32 applications. So how is MGL able to bypass GDI/DirectDraw and directly hit VBEAF, VBE, and VGA?&lt;/p&gt;
    &lt;p&gt;That is possible thanks to the secret tech from SciTech called WinDirect. How it works is explained in SciTech MGL Reference Guide v4.pdf.&lt;/p&gt;
    &lt;quote&gt;What is WinDirect?&lt;lb/&gt;A key component of the SciTech MGL, WinDirect is a runtime package for DOS and Windows 95 that provides direct access to the display hardware for both 16 and 32-bit applications. Traditionally Windows applications have had to perform all graphics output using the standard Graphics Device Interface (GDI). Although the GDI is very extensive and powerful, it is also not particularly fast for the sort of graphics that real time applications like interactive video games require.&lt;lb/&gt;WinDirect breaks this barrier by allowing high performance applications to shut down the normal GDI interface, and to take over the entire graphics display hardware just like you would normally do under DOS. Once GDI has been shut down, interactive graphics applications can re-program the display controller and write directly to video memory. A WinDirect application can program any standard VGA graphics mode such as 320x200x256, it can re-program the controller and run standard VGA ModeX style graphics, or it can call the standard VESA BIOS services to run high resolution SuperVGA graphics.&lt;lb/&gt;- MGL v4 Programmer Guide[3]&lt;/quote&gt;
    &lt;p&gt;MGL v4 programmer guide, is a treasure strove of information. If, like me, you wondered what were these &lt;code&gt;WDIR32.DLL&lt;/code&gt; and &lt;code&gt;WDIR16.DLL&lt;/code&gt; libraries that came with WinQuake, the doc mentions them (WinDIRect). Likewise, the doc describes &lt;code&gt;PMPRO16.DLL&lt;/code&gt; and &lt;code&gt;PMPRO32.DLL&lt;/code&gt; as DOS extender independent API for protected mode services. Michael Abrash's Zen Timer is also mentioned in there :)!&lt;/p&gt;
    &lt;p&gt;WinQuake source code does not include MGL. Only the headers and a pre-compiled 32-bit &lt;code&gt;MGLLT.LIB&lt;/code&gt; (MGL Lite) are provided to allow compilation. SciTech did eventually publish the source in 2000[4] but it is no longer available. What was uploaded on GitHub[5] is v5 which by then had dramatically changed (e.g: WinDirect was gone).&lt;lb/&gt; Luckily a kind soul has mirrored MGL v4. If you want to do your own digging, install mglb405.exe and mgls405.exe. Or just download my installation, src.rar.&lt;/p&gt;
    &lt;p&gt;Overall, &lt;code&gt;winquake.exe&lt;/code&gt; was often able to find a fast rendering path, either through DirectDraw or WinDirect. The fallback to DIB mode was not ideal but still a win compared to &lt;code&gt;quake.exe&lt;/code&gt;. Add to that the ability to select a sound backend to optimize for framerate or audio latency and the result was a damn good experience that completely justified the effort.&lt;/p&gt;
    &lt;p&gt;More than 30 years later, you can still run &lt;code&gt;winquake.exe&lt;/code&gt; on Windows 11. Fullscreen does not support widescreen but the windowed mode still works flawlessly. As much as Microsoft has been questionable lately, their commitment to backward compatibility is impressive.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;Why did ID choose DJGPP for Quake?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;SciTech's MGL price&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;MGL v4 Programmer Guide&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[4]&lt;/cell&gt;
        &lt;cell&gt;SciTech Releases MGL 4.0 OpenGL Source Code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[5]&lt;/cell&gt;
        &lt;cell&gt;SciTech Mult-platform Graphics Library&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fabiensanglard.net/winquake/index.html"/><published>2025-12-04T01:58:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46143618</id><title>Euler Conjecture and CDC 6600</title><updated>2025-12-04T10:45:12.691654+00:00</updated><content>&lt;doc fingerprint="bec9d9882d3a9cda"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I don’t think this warning applies here because the array is small, but the danger of this approach in general is that the executable file must contain that compile-time computed data, which means that it takes time to load that memory from disk (SSD, etc.) into the process memory on startup. In contrast, if that memory is allocated at run time directly by the executable, and then filled by cpu instructions, then it can be some 10^3 to 10^5 times faster. You can also see the difference by looking at the size of the executable image (&lt;code&gt;ls -l a.out&lt;/code&gt;). With most modern compilers, you do not see the size of the declared array reflected in the executable size unless they are parameter arrays, arrays initialized at compile time, or arrays in common blocks.&lt;/p&gt;
      &lt;p&gt;Also, if done at compile time, the whole array would need to be computed. That is 10^4 elements in this case (and integer overflows would be generated in doing so). The above run time code only computes 144 elements of the array before finding a solution and stopping.&lt;/p&gt;
      &lt;p&gt;A further question is where does that extra effort get charged? This extra effort is appropriate if the user is paying for that time (e.g. with money, or with elapsed time, or with total throughput through the machine), but not if that overhead is somehow not charged as user time (e.g. in a timeshare or batch environment with many other users). This is why the programmer sometimes writes code to minimize wall time and sometimes to minimize cpu time. Those two goals are not always exactly the same.&lt;/p&gt;
      &lt;p&gt;In the original code, the posix &lt;code&gt;time&lt;/code&gt; command was used for the timings. That command returns three different time values for exactly this reason. If you alone own the machine you are running on, and you want to maximize throughput through that machine every 24 hour period, then it is the elapsed time that is critical. If you are one of many users sharing the machine, then it is the user time that you want to minimize, the system time is not charged to you because while your job is stalled waiting for the disk to respond, someone else’s job is swapped in and is being charged to execute its user time.&lt;/p&gt;
      &lt;p&gt;Here is the timing result of that last version of the code using gfortran -O3 with an Apple M2 cpu&lt;lb/&gt; on MacOS. It computes the &lt;code&gt;i**5&lt;/code&gt; values at run time, so the system time is minimal.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;i^5 =  61917364224
133 110 84 27 144

real    0m0.141s
user    0m0.139s
sys     0m0.002s
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;One other comment about timings is that they are almost never really consistent from run to run. For small segments of code like this, one can do&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;$ time a.out; time a.out; time a.out
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The first results are usually longer than the others, which are then usually more consistent if not identical at the millisecond level. But if timings are measured at the microsecond level, they would show variations too.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fortran-lang.discourse.group/t/euler-conjecture-and-cdc-6600/10501"/><published>2025-12-04T03:50:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144113</id><title>Show HN: A Minimal Monthly Task Planner (printable, offline, no signup)</title><updated>2025-12-04T10:45:12.241834+00:00</updated><content>&lt;doc fingerprint="3f61c1ba9314363"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;PrintCalendar.top&lt;/p&gt;
      &lt;head rend="h3"&gt;Minimal Monthly Task Planner&lt;/head&gt;
      &lt;p&gt;A calm, printer-friendly canvas to map your month, capture notes, and keep a lightweight log of what matters.&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Stay on month&lt;/p&gt;
            &lt;p&gt;Jump to today, share month links, pick Mon/Sun as week start.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Notes that travel&lt;/p&gt;
            &lt;p&gt;Monthly notes with inline editing, saved locally in your browser.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Ready to print&lt;/p&gt;
            &lt;p&gt;Clean A4 layout, dark/light themes, and PDF in one click.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://printcalendar.top/"/><published>2025-12-04T05:29:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144275</id><title>Uncloud - Tool for deploying containerised apps across servers without k8s</title><updated>2025-12-04T10:45:11.328686+00:00</updated><content>&lt;doc fingerprint="6f4f5cfad58e4b63"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Mix and Match Infrastructure&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mix and match cloud and on-premise across regions and providers&lt;/item&gt;
      &lt;item&gt;Deploy customer-facing apps on reliable cloud VMs&lt;/item&gt;
      &lt;item&gt;Run resource-hungry background jobs on budget-friendly bare metal servers&lt;/item&gt;
      &lt;item&gt;Transform that dusty Mac mini into a powerful staging environment&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://uncloud.run/"/><published>2025-12-04T06:02:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144331</id><title>Show HN: Mirror_bridge – C++ Reflection powered Python binding generation</title><updated>2025-12-04T10:45:10.737978+00:00</updated><content>&lt;doc fingerprint="2ab1821826d1f299"&gt;
  &lt;main&gt;
    &lt;p&gt;Modern C++ meets Multiple Languages: Automatic bindings using C++26 reflection - zero boilerplate, pure compile-time magic.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;EXPERIMENTAL: This project requires C++26 reflection (P2996), which is not yet standardized. It only works with Bloomberg's clang-p2996 fork. Not recommended for production use until P2996 lands in standard C++26.&lt;/quote&gt;
    &lt;code&gt;// Write your C++ code once
struct Calculator {
    double value = 0.0;
    double add(double x) { return value += x; }
    double subtract(double x) { return value -= x; }
};&lt;/code&gt;
    &lt;p&gt;Python:&lt;/p&gt;
    &lt;code&gt;import cpp_calc
calc = cpp_calc.Calculator()
calc.add(10)
calc.subtract(3)
print(calc.value)  # 7.0&lt;/code&gt;
    &lt;p&gt;JavaScript (Node.js):&lt;/p&gt;
    &lt;code&gt;const calc = new addon.Calculator();
calc.add(10);
calc.subtract(3);
console.log(calc.x);  // 7.0&lt;/code&gt;
    &lt;p&gt;Lua:&lt;/p&gt;
    &lt;code&gt;local calc = cpp_calc.Calculator()
calc:add(10)
calc:subtract(3)
print(calc.value)  -- 7.0&lt;/code&gt;
    &lt;p&gt;No manual binding code. No wrapper macros. Just pure C++26 reflection. 🎉&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
        &lt;cell role="head"&gt;API&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;✅ Stable&lt;/cell&gt;
        &lt;cell&gt;Python C API&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;import my_module&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;JavaScript&lt;/cell&gt;
        &lt;cell&gt;✅ Stable&lt;/cell&gt;
        &lt;cell&gt;Node.js N-API&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;const mod = require('my_module')&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Lua&lt;/cell&gt;
        &lt;cell&gt;✅ Stable&lt;/cell&gt;
        &lt;cell&gt;Lua C API&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;local mod = require("my_module")&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Mirror Bridge is a header-only library that uses C++26 reflection (P2996) to automatically introspect your C++ classes at compile-time and generate bindings for Python, JavaScript, and Lua. It discovers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Data members - automatic getters/setters with type safety&lt;/item&gt;
      &lt;item&gt;✅ Methods (any number of parameters) - variadic parameter support&lt;/item&gt;
      &lt;item&gt;✅ Constructors - including parameterized constructors&lt;/item&gt;
      &lt;item&gt;✅ Method overloading - automatic name mangling for overloads&lt;/item&gt;
      &lt;item&gt;✅ Smart pointers - &lt;code&gt;std::unique_ptr&lt;/code&gt;,&lt;code&gt;std::shared_ptr&lt;/code&gt;with automatic conversion&lt;/item&gt;
      &lt;item&gt;✅ Nested classes - recursive handling, cross-file dependencies&lt;/item&gt;
      &lt;item&gt;✅ Containers - &lt;code&gt;std::vector&lt;/code&gt;,&lt;code&gt;std::array&lt;/code&gt;with bidirectional conversion&lt;/item&gt;
      &lt;item&gt;✅ Exception handling - C++ exceptions → Python exceptions&lt;/item&gt;
      &lt;item&gt;✅ Enums - automatic conversion to/from Python int&lt;/item&gt;
      &lt;item&gt;✅ Object representation - automatic &lt;code&gt;__repr__&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;✅ Inheritance - reflection automatically discovers inherited members&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Zero overhead: All binding code is generated at compile-time through template metaprogramming and reflection - no runtime costs.&lt;/p&gt;
    &lt;code&gt;# 1. Get the environment
./start_dev_container.sh
# Choose option 1 to pull pre-built image (~2 min)

# 2. Inside container - verify it works
cd /workspace &amp;amp;&amp;amp; ./tests/run_all_tests.sh

# 3. Try an example
cd examples/option2
../../mirror_bridge_auto src/ --module math_module
python3 test_option2.py&lt;/code&gt;
    &lt;p&gt;That's it! See QUICKSTART.md for a detailed walkthrough.&lt;/p&gt;
    &lt;p&gt;Mirror Bridge offers two workflows optimized for different use cases:&lt;/p&gt;
    &lt;p&gt;Just point at a directory - bindings are auto-generated for all classes.&lt;/p&gt;
    &lt;p&gt;Python:&lt;/p&gt;
    &lt;code&gt;mirror_bridge_auto src/ --module my_module&lt;/code&gt;
    &lt;p&gt;Lua:&lt;/p&gt;
    &lt;code&gt;mirror_bridge_auto_lua src/ --module my_module&lt;/code&gt;
    &lt;p&gt;JavaScript (Node.js):&lt;/p&gt;
    &lt;code&gt;mirror_bridge_auto_js src/ --module my_module&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Zero configuration - discovers all classes automatically&lt;/item&gt;
      &lt;item&gt;✅ Perfect for prototyping and small projects&lt;/item&gt;
      &lt;item&gt;✅ Opt-out via comments - mark classes to skip&lt;/item&gt;
      &lt;item&gt;✅ Works for all three languages - Python, Lua, JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;// src/calculator.hpp
struct Calculator {
    double value;
    double add(double x);
};

// src/vector3.hpp
struct Vector3 {
    double x, y, z;
    double length();
};&lt;/code&gt;
    &lt;code&gt;# One command binds BOTH classes
mirror_bridge_auto src/ --module mylib&lt;/code&gt;
    &lt;code&gt;import mylib
calc = mylib.Calculator()
vec = mylib.Vector3()&lt;/code&gt;
    &lt;p&gt;See &lt;code&gt;examples/option2/&lt;/code&gt; for full example.&lt;/p&gt;
    &lt;p&gt;Declarative config for explicit control over what gets bound.&lt;/p&gt;
    &lt;p&gt;Create &lt;code&gt;my_module.mirror&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;module: my_module

include_dirs: src/, include/

Calculator: calculator.hpp
Vector3: vector3.hpp
&lt;/code&gt;
    &lt;code&gt;mirror_bridge_generate my_module.mirror&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Explicit control - only bind what you specify&lt;/item&gt;
      &lt;item&gt;✅ Version control friendly - declarative config&lt;/item&gt;
      &lt;item&gt;✅ Class renaming - &lt;code&gt;Foo::Bar: foo.hpp as Bar&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See &lt;code&gt;examples/option3/&lt;/code&gt; for full example.&lt;/p&gt;
    &lt;p&gt;Full comparison: examples/README.md&lt;/p&gt;
    &lt;p&gt;For easier integration, Mirror Bridge provides single-header amalgamated versions for each language. Just copy one file to your project!&lt;/p&gt;
    &lt;p&gt;Generate single-headers:&lt;/p&gt;
    &lt;code&gt;./amalgamate.sh&lt;/code&gt;
    &lt;p&gt;This creates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;single_header/mirror_bridge_python.hpp&lt;/code&gt;(~1771 lines, 65KB)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;single_header/mirror_bridge_lua.hpp&lt;/code&gt;(~859 lines, 32KB)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;single_header/mirror_bridge_javascript.hpp&lt;/code&gt;(~875 lines, 33KB)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;// Instead of: #include "python/mirror_bridge_python.hpp"
// Just:
#include "mirror_bridge_python.hpp"  // Single self-contained header!

MIRROR_BRIDGE_MODULE(my_module,
    mirror_bridge::bind_class&amp;lt;MyClass&amp;gt;(m, "MyClass");
)&lt;/code&gt;
    &lt;p&gt;See SINGLE_HEADER_GUIDE.md for complete documentation.&lt;/p&gt;
    &lt;code&gt;struct Point { double x, y; };&lt;/code&gt;
    &lt;code&gt;p = my_module.Point()
p.x = 3.0  # Automatic getter/setter
p.y = 4.0&lt;/code&gt;
    &lt;code&gt;struct MathOps {
    double add3(double a, double b, double c) { return a + b + c; }
    double sum5(double a, double b, double c, double d, double e) {
        return a + b + c + d + e;
    }
    void reset() { value = 0; }  // Zero parameters work too
};&lt;/code&gt;
    &lt;code&gt;ops = my_module.MathOps()
ops.add3(1.0, 2.0, 3.0)           # 3 parameters ✓
ops.sum5(1, 2, 3, 4, 5)           # 5 parameters ✓
ops.reset()                        # 0 parameters ✓
# ANY number of parameters supported through variadic templates&lt;/code&gt;
    &lt;code&gt;struct Rectangle {
    Rectangle() : width(0), height(0) {}
    Rectangle(double w, double h) : width(w), height(h) {}
    Rectangle(double w, double h, std::string name)
        : width(w), height(h), name(name) {}

    double width, height;
    std::string name;
};&lt;/code&gt;
    &lt;code&gt;r1 = my_module.Rectangle()              # Default constructor
r2 = my_module.Rectangle(10.0, 5.0)    # 2-parameter constructor
r3 = my_module.Rectangle(10, 5, "box") # 3-parameter constructor
# Automatic constructor discovery and parameter matching&lt;/code&gt;
    &lt;code&gt;struct Printer {
    void print(int value) { /* ... */ }
    void print(double value) { /* ... */ }
    void print(std::string value) { /* ... */ }
};&lt;/code&gt;
    &lt;code&gt;p = my_module.Printer()
p.print_int(42)                    # int overload
p.print_double(3.14)               # double overload
p.print_std__string("hello")       # string overload
# Automatic name mangling distinguishes overloads&lt;/code&gt;
    &lt;code&gt;struct Data {
    std::string name;
    int value;
};

struct ResourceManager {
    std::unique_ptr&amp;lt;Data&amp;gt; unique_data;
    std::shared_ptr&amp;lt;Data&amp;gt; shared_data;

    std::unique_ptr&amp;lt;Data&amp;gt; create_unique(std::string n, int v);
};&lt;/code&gt;
    &lt;code&gt;rm = my_module.ResourceManager()

# Smart pointers convert to/from Python dicts
result = rm.create_unique("test", 42)
print(result)  # {'name': 'test', 'value': 42}

# Set from dict - creates managed pointer automatically
rm.unique_data = {'name': 'data', 'value': 123}

# None handling for null pointers
rm.unique_data = None  # Sets to nullptr&lt;/code&gt;
    &lt;code&gt;struct Address {
    std::string city;
};

struct Person {
    std::string name;
    Address addr;  // Nested!
};&lt;/code&gt;
    &lt;code&gt;p = my_module.Person()
p.addr = {'city': 'Boston'}  # Dict conversion&lt;/code&gt;
    &lt;code&gt;struct Data {
    std::vector&amp;lt;double&amp;gt; values;
    std::array&amp;lt;int, 3&amp;gt; coords;
};&lt;/code&gt;
    &lt;code&gt;d.values = [1.0, 2.0, 3.0]  # List → vector
d.coords = [1, 2, 3]         # List → array&lt;/code&gt;
    &lt;code&gt;double divide(double x) {
    if (x == 0) throw std::runtime_error("Division by zero");
    return value / x;
}&lt;/code&gt;
    &lt;code&gt;try:
    calc.divide(0)
except RuntimeError as e:
    print(e)  # "Division by zero"&lt;/code&gt;
    &lt;code&gt;mirror_bridge/
├── mirror_bridge.hpp           # Single-header library (core reflection logic)
├── mirror_bridge_pch.hpp       # Precompiled header wrapper (optional)
├── mirror_bridge_auto          # Auto-discovery script
├── mirror_bridge_generate      # Config file script
├── mirror_bridge_build         # Direct compilation script
├── mirror_bridge_build_pch     # PCH builder script (optional)
├── start_dev_container.sh      # Docker setup (persistent container)
├── examples/
│   ├── README.md               # Detailed usage guide
│   ├── option2/                # Auto-discovery example
│   └── option3/                # Config file example
└── tests/
    ├── run_all_tests.sh        # Automated test suite
    ├── test_pch.sh             # PCH functionality test
    └── e2e/                    # End-to-end tests
        ├── basic/              # Point2D, Vector3
        ├── containers/         # std::vector, std::array
        ├── nesting/            # Nested classes, cross-file
        └── methods/            # Method binding (Calculator)
&lt;/code&gt;
    &lt;p&gt;Mirror Bridge leverages C++26 reflection at compile-time:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Discovery: Uses &lt;code&gt;std::meta::nonstatic_data_members_of(^^T)&lt;/code&gt;to find all class members&lt;/item&gt;
      &lt;item&gt;Method Introspection: Uses &lt;code&gt;std::meta::members_of&lt;/code&gt;+&lt;code&gt;std::meta::is_function&lt;/code&gt;to find methods&lt;/item&gt;
      &lt;item&gt;Type Extraction: Uses &lt;code&gt;std::meta::type_of&lt;/code&gt;and&lt;code&gt;std::meta::identifier_of&lt;/code&gt;for names&lt;/item&gt;
      &lt;item&gt;Code Generation: Generates Python C API bindings via template metaprogramming&lt;/item&gt;
      &lt;item&gt;Compilation: Compiles to &lt;code&gt;.so&lt;/code&gt;module with reflection-enabled clang&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All binding logic is resolved at compile-time - zero runtime overhead.&lt;/p&gt;
    &lt;p&gt;See CONTRIBUTING.md for technical details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compiler: Bloomberg clang-p2996 (P2996 reflection support) &lt;list rend="ul"&gt;&lt;item&gt;Provided via Docker: &lt;code&gt;./start_dev_container.sh&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Or build from: https://github.com/bloomberg/clang-p2996&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Provided via Docker: &lt;/item&gt;
      &lt;item&gt;Python: 3.7+&lt;/item&gt;
      &lt;item&gt;Platform: Linux (or macOS with Docker)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Inside Docker container:

# Run all automated tests
./tests/run_all_tests.sh

# Output:
# ✓ Built: 12 bindings
# ✓ Passed: 12 tests
# ✓ ALL TESTS PASSED!

# Test coverage:
# - Basic data members (Point2D, Vector3)
# - Containers (std::vector, std::array)
# - Nested classes (2-level, 3-level, cross-file)
# - Methods (Calculator with various signatures)
# - Variadic parameters (3, 4, 5, 6 parameter methods)
# - Constructors with parameters (0, 2, 3 parameters)
# - Method overloading (int/double/string overloads)
# - Smart pointers (unique_ptr, shared_ptr conversion)&lt;/code&gt;
    &lt;p&gt;Advanced feature tests (&lt;code&gt;tests/e2e/advanced/&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Variadic: Methods with 3-6 parameters, weighted sums, format functions&lt;/item&gt;
      &lt;item&gt;Constructors: Default, 2-param, 3-param constructor matching&lt;/item&gt;
      &lt;item&gt;Overloading: Type-based name mangling for overloaded methods&lt;/item&gt;
      &lt;item&gt;Smart Pointers: Bidirectional dict conversion, nullptr handling, return values&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CONTRIBUTING.md - Development guide: setup, testing, CLI tools, architecture&lt;/item&gt;
      &lt;item&gt;examples/README.md - Usage examples and workflow comparisons&lt;/item&gt;
      &lt;item&gt;API Reference - Inline documentation in &lt;code&gt;mirror_bridge.hpp&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Passing bound class instances as parameters (requires reference/pointer handling)&lt;/item&gt;
      &lt;item&gt;Template classes (must be explicitly instantiated before binding)&lt;/item&gt;
      &lt;item&gt;Const method overloads (treated as same method currently)&lt;/item&gt;
      &lt;item&gt;Advanced smart pointers (&lt;code&gt;weak_ptr&lt;/code&gt;, custom deleters)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recently Completed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Variadic parameter support (any number of parameters)&lt;/item&gt;
      &lt;item&gt;✅ Constructor parameter binding&lt;/item&gt;
      &lt;item&gt;✅ Method overloading via name mangling&lt;/item&gt;
      &lt;item&gt;✅ Smart pointer support (&lt;code&gt;unique_ptr&lt;/code&gt;,&lt;code&gt;shared_ptr&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Next:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reference parameters and bound class passing&lt;/item&gt;
      &lt;item&gt;Const method overload distinction&lt;/item&gt;
      &lt;item&gt;Template class binding automation&lt;/item&gt;
      &lt;item&gt;Additional backends (Rust, Lua)&lt;/item&gt;
      &lt;item&gt;Python stub generation (.pyi files)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Mirror Bridge delivers significant performance improvements over pybind11:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple project (1 class): 816ms vs 1,938ms pybind11 (2.4x faster)&lt;/item&gt;
      &lt;item&gt;Medium project (10 classes): 1,543ms vs 3,637ms pybind11 (2.4x faster)&lt;/item&gt;
      &lt;item&gt;Why: Reflection eliminates template metaprogramming overhead&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Function calls: 35ns vs 127ns pybind11 (3.6x faster)&lt;/item&gt;
      &lt;item&gt;Object construction: 47ns vs 256ns pybind11 (5.4x faster)&lt;/item&gt;
      &lt;item&gt;Why: Direct Python C API calls, no template dispatch&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-discovery: &lt;code&gt;mirror_bridge_auto src/ --module name&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;No binding code required vs 18-103 lines for pybind11&lt;/item&gt;
      &lt;item&gt;Instant: Add members/methods → automatically bound&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Methodology: 5 runs per test, median ± stddev reported, identical optimization flags (&lt;code&gt;-O3 -DNDEBUG&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;For even faster builds, use precompiled headers to cache the Mirror Bridge infrastructure:&lt;/p&gt;
    &lt;code&gt;# One-time: Build PCH (takes ~600ms, reuse forever)
./mirror_bridge_build_pch -o build -t release

# Every build: Use PCH for 3-6x faster compilation
mirror_bridge_auto src/ --module my_module --use-pch build/mirror_bridge_pch.hpp.gch&lt;/code&gt;
    &lt;p&gt;Performance with PCH:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple project: 567ms → 194ms (66% faster, 2.9x speedup)&lt;/item&gt;
      &lt;item&gt;Medium project: 1580ms → 252ms (84% faster, 6.3x speedup)&lt;/item&gt;
      &lt;item&gt;One-time cost: ~600ms to build PCH (amortized across all builds)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Shared across projects - build PCH once, use everywhere&lt;/item&gt;
      &lt;item&gt;✅ Debug/Release PCH - separate PCH for different build configurations&lt;/item&gt;
      &lt;item&gt;✅ Zero code changes - just add &lt;code&gt;--use-pch&lt;/code&gt;flag&lt;/item&gt;
      &lt;item&gt;✅ Automatic detection - &lt;code&gt;mirror_bridge_auto&lt;/code&gt;finds PCH automatically&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Complete guide: See PCH_GUIDE.md and WORKFLOW_GUIDE.md&lt;/p&gt;
    &lt;p&gt;Test suite: Run &lt;code&gt;./tests/test_pch.sh&lt;/code&gt; to verify PCH infrastructure&lt;/p&gt;
    &lt;p&gt;Run comprehensive tests yourself:&lt;/p&gt;
    &lt;code&gt;./run_benchmarks.sh&lt;/code&gt;
    &lt;p&gt;See benchmarks/FINAL_RESULTS.md for complete results and analysis.&lt;/p&gt;
    &lt;p&gt;This is an experimental project exploring C++26 reflection. Contributions welcome!&lt;/p&gt;
    &lt;p&gt;Areas needing work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extended parameter support for methods&lt;/item&gt;
      &lt;item&gt;Template class handling&lt;/item&gt;
      &lt;item&gt;Additional backends (Rust, Lua)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache License 2.0 - See LICENSE for details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bloomberg's clang-p2996 - P2996 reflection implementation&lt;/item&gt;
      &lt;item&gt;P2996 Reflection Proposal&lt;/item&gt;
      &lt;item&gt;simdjson - Concept-based design inspiration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Status: Experimental - C++26 reflection is not yet supported on all C++ compilers. This project uses Bloomberg's clang-p2996 implementation.&lt;/p&gt;
    &lt;p&gt;Yes, method binding works! See calculator tests for full examples.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/FranciscoThiesen/mirror_bridge"/><published>2025-12-04T06:12:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144613</id><title>Saturn (YC S24) Is Hiring Senior AI Engineer</title><updated>2025-12-04T10:45:09.992079+00:00</updated><content>&lt;doc fingerprint="9b8e9e540cf160ea"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;Why Saturn?&lt;/head&gt;
      &lt;p&gt;Saturn is revolutionizing financial services with AI, building the operating system for financial advisors. Our mission is to democratize financial advice for one billion people by providing the world's most trusted, intelligent platform for financial planning and compliance.&lt;/p&gt;
      &lt;p&gt;This is a rare chance to build a category-defining company in a high-stakes, regulated environment. We operate with a Dual Mandate: relentless Speed of Execution to deliver reliable, robust products today, and dedicated Speed of Learning to explore the frontier of AI and unlock the next generation of features.&lt;/p&gt;
      &lt;p&gt;If you are driven by the pursuit of greatness, thrive on end-to-end ownership, and want to build the gold standard for AI trust and reliability, we invite you to build with us.&lt;/p&gt;
      &lt;head rend="h3"&gt;Role Overview&lt;/head&gt;
      &lt;p&gt;As a Senior AI Engineer at Saturn, you are the single-threaded owner of critical, customer-facing AI features that form the backbone of the advisory operating system. This is a highly autonomous role requiring robust software engineering fundamentals, deep LLM intuition, and an obsessive focus on product quality in a regulated domain.&lt;/p&gt;
      &lt;p&gt;You will own the entire feature lifecycle: from defining the Gold Standard with our domain experts (Guardians), architecting the agentic workflow, designing and building the comprehensive evaluation suites, to deploying and operating the solution reliably in production. You are expected to move quickly, making pragmatic, data-backed decisions that drive measurable value.&lt;/p&gt;
      &lt;head rend="h3"&gt;What You'll Do&lt;/head&gt;
      &lt;p&gt;1. End-to-End Feature Ownership and Architecture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Ownership: Take complete ownership of a product domain or complex feature, making architectural decisions independently and delivering high-quality results from concept through to long-term maintenance.&lt;/item&gt;
        &lt;item&gt;Defensive Design: Architect and implement fault-tolerant AI systems, incorporating robust fallbacks (via a model-agnostic gateway), retries, and comprehensive monitoring and tracing, driven by the Will to Care about system reliability.&lt;/item&gt;
        &lt;item&gt;Explicit Orchestration: Design and deploy complex, multi-step AI agents using explicit orchestration frameworks, ensuring state transitions are visible, testable, and auditable.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;2. Drive Evaluation and Quality Discipline:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Design Evaluation Strategy: Design, implement, and maintain the comprehensive, systematic evaluation framework (Evals Flywheel) specifically for your features to rigorously measure performance, manage regressions, and ensure quality compounds over time.&lt;/item&gt;
        &lt;item&gt;Domain Partnership: Work directly with our domain experts to translate complex financial and compliance requirements into executable evaluation rubrics and Gold Standard datasets.&lt;/item&gt;
        &lt;item&gt;Quality Feedback Loop: Instrument features end-to-end to rapidly diagnose probabilistic failures, converting production issues into high-priority regression tests.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;3. Elevate Engineering Standards:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Technical Excellence: Write clean, modular, Python code that raises the bar for the team. Actively participate in code review, using the process to mentor peers and reinforce architectural standards.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What You Have&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;5+ years of professional experience in a highly demanding engineering environment.&lt;/item&gt;
        &lt;item&gt;Proven track record (3+ years) of building, shipping, and operating scaled, impactful products where Generative AI or LLMs are a core component.&lt;/item&gt;
        &lt;item&gt;Deep Experience with Agentic Systems: Expertise in RAG pipelines, systematic prompt engineering, agentic workflow orchestration, and defining reliability trade-offs for production systems.&lt;/item&gt;
        &lt;item&gt;Evaluation Focus: Direct, demonstrable experience designing, writing, and maintaining automated evaluation frameworks (&lt;code&gt;evals&lt;/code&gt;) used to rigorously test and improve probabilistic systems.&lt;/item&gt;
        &lt;item&gt;End-to-End Ownership: A history of thriving in ambiguity, taking complete ownership of large features, and driving initiatives forward independently with a strong bias for action.&lt;/item&gt;
        &lt;item&gt;Engineering Excellence: Mastery of Python and modern backend development practices, including system design, testing, CI/CD, and robust production observability.&lt;/item&gt;
        &lt;item&gt;Product &amp;amp; User Focus: Strong product sense and the drive to quickly build domain expertise, translating user needs and compliance context into high-value technical solutions (the expression of Will to Care for the customer).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Saturn Values in Practice:&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Earn Trust: Building verifiably correct, explainable systems (Citation-First, Adviser-in-the-Loop).&lt;/item&gt;
        &lt;item&gt;Pursue Greatness: Driving our Evaluation-Driven Development flywheel to compound quality daily.&lt;/item&gt;
        &lt;item&gt;Seek Truth: Relying on data, traces, and customer feedback (Guardians) to inform every decision.&lt;/item&gt;
        &lt;item&gt;Be Audacious: Taking decisive ownership and building intelligent agents that solve previously unsolvable problems in finance.&lt;/item&gt;
        &lt;item&gt;Will to Care: Obsessively anticipating customer needs and building systems with extreme attention to detail, ensuring long-term quality, reliability, and the success of our users and peers.&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/saturn/jobs/R9s9o5f-senior-ai-engineer"/><published>2025-12-04T07:00:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145154</id><title>The Mysterious Realm of JavaScriptCore (2021)</title><updated>2025-12-04T10:45:09.388142+00:00</updated><content>&lt;doc fingerprint="e200b11260b513b0"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;JavaScriptCore (JSC) is the JavaScript engine used by Safari, Mail, App Store and many other apps in MacOs. The JSC engine is responsible for executing every line of JavaScript (JS) that needs to be executed, whenever we browse to a new website or simply send/receive emails.&lt;/p&gt;
    &lt;p&gt;Finding vulnerabilities in JSC can be intimidating and, in some cases, complicated. In this blog post, we start by learning the fundamentals of JSC. Then, we describe how we developed a tailor-made CodeQL query that uncovers bad side effect modeling vulnerabilities, which could lead to RCE in JSC.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;I’ve always felt intimidated by the fog of war that was laying over the land of browser exploitation. Never have I dared to step foot in there since I thought I was way under-leveled to do so. But, not long ago, I received the magical staff of CodeQL, and now I feel confident enough to explore the realm; I geared up and started my quest! Follow me on this immersive journey to learn the fundamentals of JSC and find some cool (old-school) bugs with CodeQL.&lt;/p&gt;
    &lt;head rend="h3"&gt;Entering the Realm of JSC&lt;/head&gt;
    &lt;p&gt;Goo(gle) the Owl: “Cloning the repository might be a good start.”&lt;lb/&gt; Me: “Waaa! Who are you?”&lt;lb/&gt; Goo the Owl: “You can call me Goo, the all-knowing Owl. What are you doing here?”&lt;lb/&gt; Me: “I just got this new staff and figured I should explore this realm a bit.” [Flashing my CodeQL staff]&lt;lb/&gt; Goo the Owl: “Oh nice! I heard about it from 91,500 places (0.43 seconds to search about it). I’ll help you explore the realm – seems like a good use of my time.”&lt;lb/&gt; Me: “That’s nice of you.&lt;lb/&gt; Me: [WHISPERING] “Show off.”&lt;lb/&gt; Goo the Owl: “Well then, without further ado, let’s clone WebKit and enter the realm!”&lt;lb/&gt; Me: git clone https://github.com/WebKit/WebKit.git&lt;lb/&gt; [Falling through a portal]&lt;lb/&gt; Me: “We’re in!” [Looking at THOUSANDS of slimy blobs waiting in line]&lt;lb/&gt; Me: “Ugh… What are these blobs?”&lt;lb/&gt; Goo the Owl: “These gooey blobs are JavaScript instructions waiting to be executed.”&lt;lb/&gt; Me: [Confused]&lt;lb/&gt; Goo the Owl: “Allow me to elaborate!”&lt;/p&gt;
    &lt;head rend="h3"&gt;JavaScriptCore 101&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;“WebKit is the web browser engine used by Safari, Mail, App Store, and many other apps on macOS, IOS and Linux.” – WebKit description from https://webkit.org&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;JSC is the built-in JS engine for WebKit, meaning it handles each JS script we execute via our browser. Unlike code written in C, which we initially compile into native code that our processor can run, a virtual machine (JSC, for example) executes JS, and our processor executes the code of that virtual machine.&lt;/p&gt;
    &lt;p&gt;Figure 1 – C vs. JavaScript&lt;/p&gt;
    &lt;p&gt;It is well understood that each approach comes with its pros and cons. For example, running a native C function can be a lot faster than executing a similar function written in JS. The reason derives directly from the figure above. JS bytecode must go through another level of execution compared to a pre-compiled programming language, like C.&lt;/p&gt;
    &lt;p&gt;But, since our JS code is running in a virtual machine, we have less room for classic bugs because the virtual machine can do all sorts of checks during runtime and prevent these classic bugs from becoming a problem. Additionally, JS is much more dynamic than C; for instance, we don’t have to declare the arguments’ types when writing a new function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Instruction Processing&lt;/head&gt;
    &lt;p&gt;Every JS script we’ll execute via JSC will go through several phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Lexing (parser/Lexer.cpp) – The Lexer will break down our script into a series of tokens. Breaking down our code is done by pre-defined characters (e.gThe parser will then process these tokens.&lt;/item&gt;
      &lt;item&gt;Parsing (parser/JSParser.cpp) – The parser will build an abstract syntax tree (AST) from the tokens produced by the Lexer. The syntax tree represents our code’s structural details, meaning each node in our tree represents an expression in our code. For example, a node can represent the expression “a + b“; the child of this expression will be the “+” operation, and its children will be the variables “a” and “b.“&lt;/item&gt;
      &lt;item&gt;Low-Level Interpreter (LLInt) – At this phase, we already have a syntax tree representing our code. The LLInt will create bytecode that JSC can execute using the processor. For example, the expression “a+b” we’ve mentioned earlier is translated to bytecode that consists of the following offline assembly opcodes:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;add loc3, loc1, loc2, OperandTypes(126, 126)&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; This is merely adding loc1 with loc2 and saving the result in loc3. The OperandTypes holds metadata about the predicated types of loc1 and loc2.&lt;/p&gt;
    &lt;p&gt;Figure 2 – The primary stages of JavaScript code goes through&lt;/p&gt;
    &lt;head rend="h3"&gt;JS Can Go FAST&lt;/head&gt;
    &lt;p&gt;While we mentioned earlier that there are only three stages in executing a JS instruction, reality suggests there are more stages. Browsers run thousands of lines of JS code on an average website, and usually, there are JS instructions that are in use in a much higher frequency than others. If we only had three stages as mentioned above, we would have to repeatedly execute the same instruction through the virtual machine, which causes a lot of unnecessary overhead. Therefore, JSC (and every other JS engine) uses Just-In-Time (JIT) compilation!&lt;/p&gt;
    &lt;p&gt;In case you’re not familiar with the concept, JIT compilation is the process of compiling a piece of code at runtime instead of the conventional way before execution. In our scenario, JSC will compile often-used instructions to native code that can be executed by our processor instead of compiling these instructions to bytecode run by the virtual machine.&lt;/p&gt;
    &lt;p&gt;This way, these often-used instructions now run with much lower overhead than before. One might say: “If the overhead is a lot lower now, why not JIT compile every instruction?”&lt;/p&gt;
    &lt;p&gt;And the answer to this question is straightforward: The process of JIT compiling is expensive (runtime speaking).&lt;/p&gt;
    &lt;p&gt;JSC creates a profile for each instruction using the LLInt (and other components mentioned later in this blog). Such profiling allows the engine to know which operations are used more often and to JIT to compile them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four Levels of JSC&lt;/head&gt;
    &lt;p&gt;We have discussed the basic workflow of executing instructions in JSC. Now it’s time to turn it up a notch. JSC executes instructions in four different tiers. As the rank of the tier goes up, the overhead of running that instruction goes down.&lt;/p&gt;
    &lt;p&gt;Instructions tier can level up/down during runtime. JSC holds an “execution counter” for each instruction, and each time we’ll execute that operation, JSC will add more points to their counter.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leveling up to the second tier requires 500 points&lt;/item&gt;
      &lt;item&gt;Leveling up to the third tier requires 1,000 points&lt;/item&gt;
      &lt;item&gt;Leveling up to the fourth tier requires 100,000 points&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The transition between tiers is linear. For example, to move from tier level 1 to tier level 3, the instruction must traverse through tier level 2 and only then to tier 3.&lt;/p&gt;
    &lt;p&gt;The four tiers are:&lt;/p&gt;
    &lt;p&gt;1. LLInt – The low-level interpreter, as mentioned earlier, this tier will compile JS instructions into bytecode.&lt;/p&gt;
    &lt;p&gt;2. Baseline JIT (500 points) – As the name might suggest, instructions that are executed under this tier will become JIT-ed. The baseline JIT compiles bytecode operations into native code using a template for each operation. There is no additional logic regarding the relation between other instructions or what’s on – only the template.&lt;/p&gt;
    &lt;p&gt;3. Data Flow Graph (DFG) JIT (1,000 points) – The DFG JIT has an intermediate representation (IR) that is later used by the DFG JIT compiler. The IR will translate the implemented code of a JS instruction into a data-flow graph (see example below). The DFG JIT compiler can now perform complex optimizations that have to do with the code’s flow. For example, let’s take a look at the following JS code snippet:&lt;/p&gt;
    &lt;quote&gt;function Foo(arg) { return this.y * arg[0]; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; By calling Foo in a loop with approximately 1,000 iterations, we can force JSC to compile Foo into DFG JIT. To see the actual DFG IR produced for this code snippet, we can run the following line:&lt;/p&gt;
    &lt;quote&gt;JSC_dumpGraphAtEachPhase=true ./WebKitBuild/Debug/bin/jsc ../dfgMe.js&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The output from this command line contains hundreds of lines, and to keep things as simple as possible, we created a flow graph that represents the DFG IR produced by JSC:&lt;/p&gt;
    &lt;p&gt;Figure 3 – Representing the short function Foo as a Data Flow Graph&lt;/p&gt;
    &lt;p&gt;OSRExit is a mechanism that allows JSC to downgrade the instruction’s tier. This is useful in the event that we add more optimizations to the execution process, i.e. we tell JSC to speculate more about what the operation can do.&lt;/p&gt;
    &lt;p&gt;For instance, JSC will speculate that the use of multiplication here is done by multiplying two integers. In reality, multiplying two integers is much less complicated than multiplying two objects, for example. Therefore, by speculating the argument types, JSC can add more impressive optimizations. In case JSC has been mistaken and guessed incorrectly, and the arguments types are not integers, JSC will perform OSRExit and level down the tier. This way, the new lower tier might have a more significant overhead, but the necessary checks will now remain.&lt;/p&gt;
    &lt;p&gt;4. Faster than Light (FTL) JIT (100,000 points) – Unlike the DFG JIT compiler, the FTL JIT focuses on optimizations regardless of how expensive the optimizing process might be. The FTL JIT reuses the optimizations that were done by the DFG JIT and will add many more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to the Realm&lt;/head&gt;
    &lt;p&gt;Me: “Ohh.”&lt;lb/&gt; Goo the Owl: “And these blobs are going straight to the LLInt.”&lt;lb/&gt; Me: “Oof.”&lt;lb/&gt; Goo the Owl: “This is literally the shortest summary I could give on JSC.”&lt;lb/&gt; Me: “I understand why I never came here.”&lt;lb/&gt; Goo the Owl: “Wanna go back?”&lt;lb/&gt; Me: “No way, too committed by now. Let’s follow the blobs to the LLInt!” [Following the blobs]&lt;lb/&gt; Me: “I’ve noticed that when certain blobs slide through the LLInt, other blobs cut the line and slide before everyone else! Not cool…”&lt;lb/&gt; Goo the Owl: “Calm down, manners police. These blobs cut the line because they have to.”&lt;lb/&gt; Me: “What do you mean, ‘have to’?”&lt;lb/&gt; Goo the Owl: “Some instruction blobs cause side effects. This is perfectly normal in JS.”&lt;lb/&gt; Me: “Side effects? Sounds malicious to me.”&lt;lb/&gt; Goo the Owl: “As I said earlier, this is PERFECTLY NORMAL. Side effects in JS are…”&lt;lb/&gt; [QUICK CUT TO GOO ELABORATING ON SIDE EFFECTS IN JS]&lt;/p&gt;
    &lt;head rend="h3"&gt;Side Effects In JS&lt;/head&gt;
    &lt;p&gt;A JS operation causes side effects if it modifies the state of other variables outside the local environment of that instruction.&lt;/p&gt;
    &lt;p&gt;For instance, in JS, we can concatenate a string with a JS Object like this:&lt;/p&gt;
    &lt;quote&gt;let a = "Hello" + {} // a is now "Hello{}"&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; This concatenation will fail in most program languages, but not in JS. JSC will try to convert unique types (such as JSObject) to a primitive type (e.g. String). Let’s take a look at the function “jsAdd,” which is the implementation of the “+” operator:&lt;/p&gt;
    &lt;quote&gt;ALWAYS_INLINE JSValue jsAdd(JSGlobalObject* globalObject, JSValue v1, JSValue v2) { if (v1.isNumber() &amp;amp;&amp;amp; v2.isNumber()) return jsNumber(v1.asNumber() + v2.asNumber()); return jsAddNonNumber(globalObject, v1, v2); }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; As we can see, if we try to add two numbers, JSC will simply add them and will return the value; otherwise, JSC calls the function jsAddNonNumber. The figure below represents the flow of jsAddNonNumber, while the input is . Each color represents the context of execution:&lt;/p&gt;
    &lt;p&gt;Figure 4 – The code flow of jsAddNonNumber while adding a String with a JSObject&lt;/p&gt;
    &lt;p&gt;We can see that jsAddNonNumber checks the types of the arguments (in our case, arg1 is a String and arg2 is a JSObject) and then tries to convert them into primitive types (e.g., String, Number).&lt;/p&gt;
    &lt;p&gt;By setting the property “toString” in our object (second argument), we could cause JSC to run arbitrary JS code that is not part of the conventional flow of the add operator, i.e., side effect:&lt;/p&gt;
    &lt;quote&gt;let myObj = {'toString' : function(){print("side-effect here"); return "myX";}}; let a = "Hello " + myObj // this will print "side-effect here" // a is "Hello myX"&lt;/quote&gt;
    &lt;head rend="h3"&gt;DFG Optimizations: Redundancy Elimination&lt;/head&gt;
    &lt;p&gt;A widespread DFG JIT optimization is called redundancy elimination. The goal of this optimization is to eliminate redundant guards when compiling an instruction into DFG. To determine which guards are redundant, JSC needs to know which instructions can cause side effects and under which terms (e.g., concerning the argument types passed to the operations). This way, guards that appear before and after an instruction that can’t cause side effects will be considered redundant.&lt;/p&gt;
    &lt;p&gt;Let’s look at the following example:&lt;/p&gt;
    &lt;quote&gt;function Foo(arg){ return arg.someProp / arg.otherProp; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The flow graph that represents this function will look like the following:&lt;/p&gt;
    &lt;p&gt;Figure 5 – Phase 1 – Representing the function from above as DFG before removing redundant guards&lt;/p&gt;
    &lt;p&gt;You might notice that JSC checks that our argument is a valid object twice, before and after fetching for the property “someProp.” This guard makes sure that we still access a JS object before fetching a property from an object. In case JSC has successfully fetched the property “someProp,” the second check is redundant since there are no possible side effects between the first fetch to the second one. Therefore, the graph will then look like the following:&lt;/p&gt;
    &lt;p&gt;Figure 6 – Phase 2 – Representing the function from above as DFG after removing redundant guards&lt;/p&gt;
    &lt;p&gt;Since this optimization removes unnecessary guards, JSC must determine in a rigorous way which guards are redundant.&lt;/p&gt;
    &lt;p&gt;So, to avoid these vulnerable scenarios, JSC does precise modeling for each JS operation. The side effect modeling is in the file DFGAbstractInterpreterInlines.h under the function executeEffects. This function holds a (HUGE) switch case that determines which operation could\could not cause side effects and under which terms. Whenever JSC calls clobberWorld, it assumes that the operation can execute side effects:&lt;/p&gt;
    &lt;p&gt;Figure 7 – Basic side effects modeling in JSC (DFGAbstractInterpreterInlines.h/executeEffects). Each case represents the operation’s code (opcode)&lt;/p&gt;
    &lt;head rend="h3"&gt;Bad Side Effect Modeling: InstanceOf Vulnerability&lt;/head&gt;
    &lt;p&gt;A good use case that shows the risk potential of bad side effect modeling in JSC is the following bug. It was fixed in May 2018 right after commit 3b45a2433371160871a07d288b119b2454e3db19 (which is the last commit vulnerable to this bug). The patch to that vulnerability is quite simple:&lt;/p&gt;
    &lt;p&gt;Figure 8 – Patching the bug by letting JSC know that the operation instanceOf can cause side effects&lt;/p&gt;
    &lt;p&gt;This simple patch suggests that this bug has something to do with bad side effect modeling.&lt;/p&gt;
    &lt;p&gt;With the help of maxpl0it, we can review the exploit that triggers this bug:&lt;/p&gt;
    &lt;quote&gt;class EmptyClass { }; var a = [13.37]; function TriggerClass() { }; var leakme = {}; var trigger = false; var handler = { getPrototypeOf(){ if (trigger){ a[0] = leakme; } return EmptyClass.prototype; }, }; TriggerClass.prototype = new Proxy({}, handler); function addrof(obj){ var toggle = true; function addrof_internal(array){ var _ = (new TriggerClass()) instanceof EmptyClass return array[0]; } for (var i = 0; i &amp;lt; 10000; i++){ addrof_internal(a); } trigger = true; return addrof_internal(a); } print(addrof(leakme));&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The exploit uses classic JSC exploit primitives (leaking addresses using type confusion caused by a bug, AKA, addrof\fakeobj) initially discovered by and mapped out in this great Oct. 2016 article. This exploit implements the function addrof that allows leaking JS object addresses.&lt;/p&gt;
    &lt;p&gt;From the patch, we can deduct that the operation “InstanceOf” wasn’t modeled correctly for side effects, but the real question is: why instanceOf can trigger side effects?&lt;/p&gt;
    &lt;p&gt;Well, the answer to that question lies in the exploit! We can see that by creating a proxy object that handles the function “getPrototypeOf,” we can trigger side effects. The operation that implements the JS instruction instanceOf is operationDefaultHasInstance.&lt;/p&gt;
    &lt;quote&gt;size_t JIT_OPERATION operationDefaultHasInstance(ExecState* exec, JSCell* value, JSCell* proto) // Returns jsBoolean(True|False) on 64-bit. { … }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Note: The parameter “value” corresponds with the new instance of TriggerClass we create under “addrof_internal.”&lt;/p&gt;
    &lt;p&gt;The following flow chart describes why operationDefaultHasInstance causes side effects:&lt;/p&gt;
    &lt;p&gt;Figure 9 – Showing why OperationDefaultHasInstance can cause side effects&lt;/p&gt;
    &lt;p&gt;Fetching for the object prototype, without any guards or checks, allows us to replace the initial object (in our case, TriggerClass) into a proxy object. By doing so, we can replace the function getPrototypeOf with our own arbitrary JS code, AKA side effects.&lt;/p&gt;
    &lt;head rend="h2"&gt;CodeQL Magic&lt;/head&gt;
    &lt;p&gt;[CodeQL Staff shines with bright blue light]&lt;lb/&gt; Goo the Owl: “What’s happening?! Is it going to explode?! I’m way too young to d…”&lt;lb/&gt; Me: “It’s not going to explode… -_-”&lt;lb/&gt; Me: “It found potential in what you’ve said earlier.”&lt;lb/&gt; Goo the Owl: “Potential? What do you mean?”&lt;lb/&gt; Me: “Well, you have explained pretty thoroughly about the whole bad side effect modeling, right?”&lt;lb/&gt; Goo the Owl: “Yeah, so what?”&lt;lb/&gt; Me: “What if we could use my CodeQL staff to find more bugs like this one in the realm?”&lt;lb/&gt; Goo the Owl: “That would be awesome.”&lt;lb/&gt; Me: “I think so too, and I think that this is what the staff wants me to do.”&lt;/p&gt;
    &lt;head rend="h3"&gt;CodeQL: Finding Bad Side Effect Modeling Vulnerabilities in JSC&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;“CodeQL is a framework developed by Semmle and is free to use on open-source projects. It lets a researcher perform variant analysis to find security vulnerabilities by querying code databases generated using CodeQL, which supports many languages such as C/C++, C#, Java, JavaScript, Python and Golang.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just in case you haven’t heard about CodeQL yet, I highly recommend reading my previous blog post, which dives into CodeQL and its capabilities.&lt;/p&gt;
    &lt;p&gt;Let’s try to write a CodeQL query that will find bad side effects modeling vulnerabilities in JSC. To begin with, here is a rough description of the bug:&lt;/p&gt;
    &lt;p&gt;A JS operation might be exposed to a bad side effect modeling bug if:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Under the case that represents the operation in executeEffects (DFGAbstractInterpreterInlines.h), there is no call to clobberWorld.&lt;/item&gt;
      &lt;item&gt;The operation causes side effect.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The best tip we can give you before writing CodeQL queries is to work as organized as possible. As your query’s complexity becomes higher, there is more room for it to fail somehow. Although this is probably true for every coding project you’ve worked on, debugging CodeQL queries can be much more difficult, since we don’t have classic debugging methods and tools that some of you might be familiar with (CodeQL simply doesn’t have any).&lt;/p&gt;
    &lt;p&gt;Let’s start by determining what data we need to extract with CodeQL to recognize the bugs we wish to find. The description of the bug above gives us a hint regarding what information we need to collect. After reading and analyzing the code, we created a diagram that shows which component does what in the JSC side effect modeling, and how the elements are linked&lt;/p&gt;
    &lt;p&gt;Then, I added an example to a possible side effect that an operation might have (same side effect as we showed in the InstanceOf bug, above):&lt;/p&gt;
    &lt;p&gt;Figure 10 – This diagram shows the logical connection between each component in JSC responsible for side effect modeling&lt;/p&gt;
    &lt;p&gt;With this diagram, we can start writing some CodeQL classes. Classes in CodeQL let you inherit from native CodeQL objects (e.g., VariableAccess, Function, Expr) and add layers of complexity such as additional predicates and properties. The first class we created is named ClobberWorldCall, which inherits from the CodeQL class FunctionCall.&lt;/p&gt;
    &lt;p&gt;Ideally, this class will model side effects by analyzing each call to clobberWorld under executeEffects. Let’s review some key features from that class:&lt;/p&gt;
    &lt;quote&gt;import cpp import helperFunctions class ClobberWorldCall extends FunctionCall{ string opCode; string strictTypeConstraintsNode1; string strictTypeConstraintsNode2; string strictTypeConstraintsNode3; string looseTypeConstraintsNode1; string looseTypeConstraintsNode2; string looseTypeConstraintsNode3; // string operandType; ClobberWorldCall() { this.getTarget().hasName("clobberWorld") and exists ( Function executeEffects | executeEffects.hasName("executeEffects") and this.getEnclosingFunction() = executeEffects ) and // Extracting the op code for each call (e.g., ValueAdd, InstanceOf) opCode = getOpForClobberWorld(this) and // Extracting the strict and loose types getStrictTypeConstraints(this, strictTypeConstraintsNode1, strictTypeConstraintsNode2, strictTypeConstraintsNode3) and getLooseTypeConstraints(this, looseTypeConstraintsNode1, looseTypeConstraintsNode2, looseTypeConstraintsNode3) } … }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Although this class seems short, a lot is going on inside it.&lt;/p&gt;
    &lt;p&gt;Our first predicate is quite simple – we look for all the calls to clobberWorld under executeEffects.&lt;/p&gt;
    &lt;p&gt;Then, we call our custom predicate getOpForClobberWorld, which works as follows:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get the basic block that contains the call to clobberWorld.&lt;/item&gt;
      &lt;item&gt;If that basic block is under a case, return the case name (the case name is the operation code (for example, ValueAdd).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After that, we call getStrictTypeConstraints, followed by a call to getLooseTypeConstraints, which was the most difficult bit to write.&lt;/p&gt;
    &lt;p&gt;To be as accurate and efficient as possible, JSC will sometimes call clobberWorld when specific argument types are passed to the operation. For example, adding two numbers in JS won’t cause side effects, but adding two objects may cause side effects. If JSC called clobberWorld when we simply call the add operation, it wouldn’t be efficient. So, JSC will check the argument types and only then decide whether it should call clobberWorld or not.&lt;/p&gt;
    &lt;p&gt;This is exactly where getStrictTypeConstraints and getLooseTypeConstraints come in handy.&lt;/p&gt;
    &lt;p&gt;Here is a snippet from the code that checks for strict constraints:&lt;/p&gt;
    &lt;quote&gt;string getStrictTypeForClobberWorldChild(FunctionCall clobberWorld){ if ( isClobberInsideSwitchCaseOrIfStatement(clobberWorld) = true ) then ( exists ( SwitchCase case, SwitchStmt st, FunctionCall call | st = getInnerSwitchStatement(clobberWorld, "useKind") and st.getExpr() = call and call.getQualifier().(FunctionCall).getTarget().hasName("child1") and case.getSwitchStmt() = st and case.getASuccessor*() = clobberWorld and result = case.getExpr().toString() ) or … else result = "noTypeConstraintsFound" }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; In this snippet, we see that we first check if the call to clobberWorld is under a (specific) Switch Case or an “if” statement.&lt;/p&gt;
    &lt;p&gt;If it is, then we analyze that very switch case/if statement.&lt;/p&gt;
    &lt;p&gt;In this example, we analyze the switch case. JSC can obtain argument types by several methods. For example, one of them is by calling the function useKind, which returns the argument type (mind-blowing). Our code from above should handle these types of cases:&lt;/p&gt;
    &lt;quote&gt;case ArithClz32: { … switch (node-&amp;gt;child1().useKind()) { case Int32Use: case KnownInt32Use: break; default: clobberWorld(); break; } setNonCellTypeForNode(node, SpecInt32Only); break; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Once we finished writing the clobberWorldCall class, we could confidently move on to the next class, dfgOperation.&lt;/p&gt;
    &lt;p&gt;Knowing exactly when JSC calls clobberWorld is not enough to ultimately model operations for side effects. Under the function executeEffects, there is no reference to the actual operation that holds the code we wish to analyze. All we have is the operation code, taken from the switch case under executeEffects.&lt;/p&gt;
    &lt;p&gt;So, in our next step, we will link the opcode (operation code) to the operation’s code under the hood. Once we can link these two, we can start analyzing the operation itself and look for possible side effects.&lt;/p&gt;
    &lt;quote&gt;class DfgOperation extends Function{ SwitchCase dfgEffectCase; FunctionCall dfgCallOperation; Function dfgCompile; string opCode; boolean isClobberWorldCalled; DfgOperation() { // Link the dfgOperation to the dfgCallOperation/dfgSlowCallOperation ( ( dfgCallOperation.getTarget().hasName("callOperation") and dfgCallOperation.getArgument(0) = this.getAnAccess() ) or ( dfgCallOperation.getTarget().hasName("slowPathCall") and dfgCallOperation.getArgument(2) = this.getAnAccess() ) ) and dfgCompile = getSpeculativeJitCompile() // We have 2 known options (all happens under the function SpeculativeJIT::compile): // 1) We call directly to the callOperation from the switch case // 2) We call to a wrapper function named compileSomeOperation from the switch case and ( opCode = getOpCodeSimpleCase(dfgCallOperation) or opCode = getOpCodeByCompileOperation(dfgCallOperation) ) and … // Find if ClobberWorld is called – Actual Linking Stage and if exists ( ClobberWorldCall clobber | clobber.getAnOpCode() = opCode ) then isClobberWorldCalled = true else isClobberWorldCalled = false } … }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Using the figure 10 diagram presented above, we understand that JSC can call an operation using the function callOperation or compile the operation and then call it.&lt;/p&gt;
    &lt;p&gt;So, in our query we first locate all the calls to callOperation/compileOperation, and then, similarly to the clobberWorldCall class, we find the operation code using switch cases or if statements.&lt;/p&gt;
    &lt;p&gt;Once that is done, we can safely link between the clobberWorld calls to the JS operations.&lt;/p&gt;
    &lt;p&gt;Finally, we need to choose which side effects we’re looking for because there are a few options. Since we reviewed earlier the bug in the operation InstanceOf, let’s look for all side effects caused by confusion with proxy objects (we recommend reading the comments):&lt;/p&gt;
    &lt;quote&gt;from FunctionCall fc, VariableAccess jsObjectAccess, Parameter source, DfgOperation operation, Expr asObjArg, Function compareTo where // Extract all accesses to JSObjects isJsObject(jsObjectAccess.getTarget()) and // fc represents all the function calls from a JSObject fc.getQualifier() = jsObjectAccess and // Find functions from ProxyObject that share the function name as fc exists ( Function fromProxy | fromProxy.getParentScope().toString() = "ProxyObject" and compareTo.getName() = fromProxy.getName() and fc.getTarget() = getFunctionWrappers(compareTo) ) and // Make sure JSC does not call clobberWorld for that operation operation.hasACallToClobberWorld() = false and operation.getAParameter() = source and exists // Search for the following flow: // from: operation parameter // to: Converting the parameter to JSObject // or // The parameter is already a JSObject // to: Calling a function from that parameter that exists under ProxyObject and JSObject ( LinkOperationToExecVM config, FunctionCall asObject, ConvertToObjectAndCall config2| ( ( asObject.getTarget().hasName("asObject") or asObject.getTarget().hasName("toObject") ) and asObject.getAnArgument() = asObjArg and config.hasFlow(DataFlow::parameterNode(source), DataFlow::exprNode(asObjArg)) and config2.hasFlow(DataFlow::exprNode(asObject), DataFlow::exprNode(jsObjectAccess)) ) or ( asObjArg = jsObjectAccess.getTarget().getAnAccess() and config.hasFlow(DataFlow::parameterNode(source), DataFlow::exprNode(asObjArg)) ) ) select operation, source, fc, compareTo&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Executing this query against a code database created from commit 35b181a20dc25749df383041f950798bd109f47d produced the following results:&lt;/p&gt;
    &lt;p&gt;Figure 11 – Results from our final query. The left column holds the names of the operations. The middle column shows which argument causes the side effects, and the right column shows which function we should hook using a proxy object.&lt;/p&gt;
    &lt;p&gt;We can see that there are five operations suspected to be bugs, and one of them is the bug we studied earlier – great!&lt;/p&gt;
    &lt;p&gt;Digging deeper through the results revealed a second bad side effects modeling vulnerability, CVE-2018-4233. The vulnerable operation is operationCreateThis. This vulnerability was found and exploited by Samuel Groß in pwn2own 2018. Samuel talked about this vulnerability in his Black Hat 2018 conference talk.&lt;/p&gt;
    &lt;p&gt;We’ve managed to find two critical vulnerabilities in JSC that could lead to RCE using a tailor-made CodeQL query. Running that query against a codebase created from an updated version of JSC shows that the two vulnerabilities previously found by our query no longer exist, meaning they were indeed patched. Keep in mind that it does not mean that there are no more vulnerabilities caused by bad side effect modeling. Adding small changes to our query will allow us to determine what kind of side effects we are looking for, and there could be lots of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;What a journey we’ve had. Thanks to you, the realm is a lot safer now.&lt;/p&gt;
    &lt;p&gt;The truth is, I’ve been playing with CodeQL for the past year and I’ve been focused on finding classic vulnerabilities (in my previous blog, I focused on finding vulnerable calls to memcpy with CodeQL). This time, I wanted to see how effective it is to use CodeQL to find much-complicated vulnerabilities in large and tangled projects like WebKit.&lt;/p&gt;
    &lt;p&gt;I knew that this would not be an easy task, and indeed it wasn’t. But the most challenging part was learning and understanding the internals of JSC and not (as I initially thought) writing the query in CodeQL.&lt;/p&gt;
    &lt;p&gt;Once I had gained enough knowledge about the bugs I wanted to find, writing the query was pretty intuitive (I do have some experience with CodeQL by now, but still…) and fun.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links &amp;amp; References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;http://www.phrack.org/issues/70/3.html&lt;/item&gt;
      &lt;item&gt;https://liveoverflow.com/getting-into-browser-exploitation-new-series-introduction-browser-0x00/&lt;/item&gt;
      &lt;item&gt;https://webkit.org/blog/10308/speculation-in-javascriptcore/&lt;/item&gt;
      &lt;item&gt;https://webkit.org/blog/6411/javascriptcore-csi-a-crash-site-investigation-story/&lt;/item&gt;
      &lt;item&gt;https://saelo.github.io/presentations/blackhat_us_18_attacking_client_side_jit_compilers.pdf&lt;/item&gt;
      &lt;item&gt;https://zon8.re/posts/jsc-internals-part1-tracing-js-source-to-bytecode/&lt;/item&gt;
      &lt;item&gt;https://github.com/assafsion/javascriptcore-bad-side-effect-modeling&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cyberark.com/resources/threat-research-blog/the-mysterious-realm-of-javascriptcore"/><published>2025-12-04T08:33:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145180</id><title>Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs</title><updated>2025-12-04T10:45:09.097710+00:00</updated><content>&lt;doc fingerprint="849e200a55f594ac"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Economics &amp;gt; General Economics&lt;/head&gt;&lt;p&gt; [Submitted on 3 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;econ.GN&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.04047"/><published>2025-12-04T08:38:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145365</id><title>Good news: JavaScript is 30yo today Sad news: its own name doesn't belong to it</title><updated>2025-12-04T10:45:08.842117+00:00</updated><content>&lt;doc fingerprint="4737c13992a7be78"&gt;
  &lt;main&gt;
    &lt;p&gt;Dear Oracle,&lt;/p&gt;
    &lt;p&gt;You have long ago abandoned the JavaScript trademark, and it is causing widespread, unwarranted confusion and disruption.&lt;/p&gt;
    &lt;p&gt;JavaScript is the world’s most popular programming language, powering websites everywhere. Yet, few of the millions who program in it realize that JavaScript is a trademark you, Oracle, control. The disconnect is glaring: JavaScript has become a general-purpose term used by countless individuals and companies, independent of any Oracle product.&lt;/p&gt;
    &lt;p&gt;Oracle’s hold on the JavaScript trademark clearly fits the legal definition of trademark abandonment. A previous blog post addressed this issue, requesting that you, Oracle, release the trademark. Unsurprisingly, the request was met with silence. It is therefore time to take active steps in order to bring the JavaScript trademark into the public domain, where it belongs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trademark abandonment&lt;/head&gt;
    &lt;p&gt;Title 15 of the United States Code, section 1127, states:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A mark shall be deemed to be “abandoned” if either of the following occurs:&lt;/p&gt;
      &lt;item&gt;When its use has been discontinued with intent not to resume such use. Intent not to resume may be inferred from circumstances. Nonuse for 3 consecutive years shall be prima facie evidence of abandonment. “Use” of a mark means the bona fide use of such mark made in the ordinary course of trade, and not made merely to reserve a right in a mark.&lt;/item&gt;
      &lt;item&gt;When any course of conduct of the owner, including acts of omission as well as commission, causes the mark to become the generic name for the goods or services on or in connection with which it is used or otherwise to lose its significance as a mark. Purchaser motivation shall not be a test for determining abandonment under this paragraph.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;In the case of JavaScript, both criteria apply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Netscape, Sun, Oracle&lt;/head&gt;
    &lt;p&gt;The JavaScript trademark is currently held by Oracle America, Inc. (US Serial Number: 75026640, US Registration Number: 2416017). How did this come to be?&lt;/p&gt;
    &lt;p&gt;In 1995, Netscape partnered with Sun Microsystems to create interactive websites. Brendan Eich famously spent only 10 days creating the first version of JavaScript, a dynamic programming language with a rough syntactic lineage from Sun’s Java language. As a result of this partnership, Sun held the JavaScript trademark. In 2009, Oracle acquired Sun Microsystems and the JavaScript trademark as a result.&lt;/p&gt;
    &lt;p&gt;The trademark is simply a relic of this acquisition. Neither Sun nor Oracle has ever built a product using the mark. Legal staff, year after year, have renewed the trademark without question. It’s likely that only a few within Oracle even know they possess the JavaScript trademark, and even if they do, they likely don’t understand the frustration it causes within the developer community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Use it or lose it&lt;/head&gt;
    &lt;p&gt;Oracle has abandoned the JavaScript trademark through nonuse.&lt;/p&gt;
    &lt;p&gt;Oracle has never seriously offered a product called JavaScript. In the 1990s and early 2000s, Netscape Navigator, which supported JavaScript as a browser feature, was a key player. However, Netscape’s usage and influence faded by 2003, and the browser saw its final release in 2008. JavaScript, meanwhile, evolved into a widely used, independent programming language, embedded in multiple browsers, entirely separate from Oracle.&lt;/p&gt;
    &lt;p&gt;The most recent specimen, filed with the USPTO in 2019, references nodejs.org (a project created by Ryan Dahl, the author of this letter) and Oracle’s JavaScript Extension Toolkit (JET). But Node.js is not an Oracle product, and JET is merely a set of JavaScript libraries for Oracle services, particularly Oracle Cloud. There are millions of JavaScript libraries; JET is not special.&lt;/p&gt;
    &lt;p&gt;(Oracle is not even a member of the OpenJS Foundation - the body that the Node.js project lives under now. Nor does Oracle have any involvement whatsoever in the development of Node.js.)&lt;/p&gt;
    &lt;p&gt;Oracle also offers GraalVM, a JVM that can execute JavaScript, among other languages. But GraalVM is far from a canonical JavaScript implementation; engines like V8, JavaScriptCore, and SpiderMonkey hold that role. GraalVM’s product page doesn’t even mention “JavaScript”; you must dig into the documentation to find its support.&lt;/p&gt;
    &lt;p&gt;Oracle’s use of JavaScript in GraalVM and JET does not reflect genuine use of the trademark. These weak connections do not satisfy the requirement for consistent, real-world use in trade.&lt;/p&gt;
    &lt;head rend="h2"&gt;A generic term&lt;/head&gt;
    &lt;p&gt;A mark can also be considered abandoned if it becomes a generic term.&lt;/p&gt;
    &lt;p&gt;In 1996, Netscape announced a meeting of the ECMA International standards organization to standardize the JavaScript programming language. Sun (now Oracle), refused to give up the “JavaScript” mark for this use though, so it was decided that the language would be called “ECMAScript” instead. (Microsoft happily offered up “JScript”, but no-one else wanted that.) Brendan Eich, the creator of JavaScript and a co-signatory of this letter, wrote in 2006 that “ECMAScript was always an unwanted trade name that sounds like a skin disease.”&lt;/p&gt;
    &lt;p&gt;Ecma International formed TC39, a technical steering committee, which publishes ECMA-262, the specification for JavaScript. This committee includes participants from all major browsers, like Google’s Chrome, Apple’s Safari, and Mozilla’s Firefox, as well as representatives from server-side JavaScript runtimes like Node.js and Deno.&lt;/p&gt;
    &lt;p&gt;Oracle’s ownership of the JavaScript trademark only causes confusion. The term “JavaScript” is used freely by millions of developers, companies, and organizations around the world, with no interference from Oracle. Oracle has done nothing to assert its rights over the JavaScript name, likely because they do not believe their claim to the mark would hold up in court. Unlike typical trademark holders who protect their trademarks by extracting licensing fees or enforcing usage restrictions, Oracle has allowed the JavaScript name to be used by anyone. This inaction further supports the argument that the trademark has lost its significance and has become generic.&lt;/p&gt;
    &lt;p&gt;Programmers working with JavaScript have formed innumerable community organizations. These organizations, like the standards bodies, have been forced to painstakingly avoid naming the programming language they are built around—for example, JSConf. Sadly, without risking a legal trademark challenge against Oracle, there can be no “JavaScript Conference” nor a “JavaScript Specification.” The world’s most popular programming language cannot even have a conference in its name.&lt;/p&gt;
    &lt;p&gt;There is a vast misalignment between the trademark’s ownership and its widespread, generic use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free the mark&lt;/head&gt;
    &lt;p&gt;By law, a trademark is abandoned if it is either not used or becomes a generic term. Both apply to JavaScript.&lt;/p&gt;
    &lt;p&gt;It’s time for the USPTO to end the JavaScript trademark and recognize it as a generic name for the world’s most popular programming language, which has multiple implementations across the industry.&lt;/p&gt;
    &lt;p&gt;Oracle, you likely have no real business interest in the mark. It’s renewed simply because legal staff are obligated to renew all trademarks, regardless of their relevance or use.&lt;/p&gt;
    &lt;p&gt;We urge you to release the mark into the public domain. However, asking nicely has been tried before, and it was met with silence. If you do not act, we will challenge your ownership by filing a petition for cancellation with the USPTO.&lt;/p&gt;
    &lt;head rend="h2"&gt;To you, the readers of this letter:&lt;/head&gt;
    &lt;p&gt;If you agree with us, you are encouraged to sign this open letter below. Your support will help raise awareness and add weight to this cause. If you want to sign as an organization (minimum 25 employees), please email companies@javascript.tm.&lt;/p&gt;
    &lt;p&gt;In addition, we’re seeking pro bono assistance from lawyers with experience in trademark law to help file a Petition for Trademark Cancellation with the USPTO. It’s likely that simply asking nicely will not get a response from Oracle; a legal challenge must be made. Reach out to lawyers@javascript.tm if you can help.&lt;/p&gt;
    &lt;p&gt;Sincerely,&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://javascript.tm/letter"/><published>2025-12-04T09:01:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145834</id><title>Unreal Tournament 2004 is back</title><updated>2025-12-04T10:45:08.794727+00:00</updated><content/><link href="https://old.reddit.com/r/unrealtournament/comments/1pdbe69/breaking_unreal_tournament_2004_is_back/"/><published>2025-12-04T10:06:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145960</id><title>Recreating the lost SDK for a 42-year-old operating system: VisiCorp Visi On</title><updated>2025-12-04T10:45:07.962542+00:00</updated><content>&lt;doc fingerprint="af8cd8124713078c"&gt;
  &lt;main&gt;&lt;p&gt;Back in 1983, an office software giant VisiCorp released a graphical multitasking operating system for the IBM PC called VisiOn (or Visi On, or Visi-On, it was before the Internet, so anything goes). It was an "open system", so anyone could make programs for it. Well, if they owned an expensive VAX computer and were prepared to shell out $7,000 on the Software Development Kit.&lt;/p&gt;&lt;p&gt;VisiOn was released earlier than Microsoft Windows, Digital Research GEM, or Apple Macintosh. Its COMDEX demo even predates the annoucement of Apple Lisa. But being first doesn't mean getting things right, so this VisiOn of the future did not win the market. Not a single third-party program was released for the system. No one preserved the SDK for the system. The technical documentation roughly amounts to three terse magazine articles and a single Usenet post. Heck, even the copies of the operating system itself are hard to come by.&lt;/p&gt;&lt;p&gt;Despite its low popularity, VisiOn is historically important. It influenced Microsoft's decisions about Windows, and it is a lesson about failing. So, I thought it would be nice to recreate the SDK for it, Homebrew-style. How difficult could it be, right?!&lt;/p&gt;&lt;p&gt;It took me a month of working 1-2 hours a day to produce a specification that allowed Atsuko to implement a clean-room homebrew application for VisiOn that is capable of bitmap display, menus and mouse handling.&lt;/p&gt;&lt;p&gt;If you're wondering what it felt like: this project is the largest "Sudoku puzzle" I have ever tried to solve. In this note, I have tried to explain the process of solving this puzzle, as well as noteworthy things about VisiOn and its internals. But, first things first...&lt;/p&gt;&lt;p&gt;Pyramid Game is a simple patience card game that demonstrates the basics of application development for VisiOn. It comes with an installer and features loadable fonts, bitmaps, clickable areas ("buttons"), and a menu system.&lt;/p&gt;&lt;p&gt;You now can download the floppy image and the distribution files. Obviously, you will need an installed VisiOn system to run it. The rules of the game can be found on Wikipedia.&lt;/p&gt;&lt;p&gt;The source code is available in its own repo.&lt;/p&gt;&lt;p&gt;The claim of Pyramid being "the first-ever" third-party application is a bit strong. VisiOn was an "open system", and so it is theoretically possible someone bought a VisiOn ToolKit and made third-party applications for VisiOn. But even if they did, they never published or sold them. So, Pyramid is the first-ever published third-party application for VisiOn.&lt;/p&gt;&lt;p&gt;This note is aimed at technically inclined readers with software engineering and coding background who want to learn more about vintage operating systems and reverse engineering. I'll try to keep the explanations simple at the expense of obscuring some of the technical details; if you want the details, please check out the verbose notes and the test application. I hope to document the operating system at a later date.&lt;/p&gt;&lt;p&gt;This note is quite long. Feel free to scroll to a part that interests you and read from there.&lt;/p&gt;&lt;p&gt;Personally, I find this project fascinating in terms of solarpunk and permacomputing. Imagine: you find an ancient device (42 years is ancient for computers, right?!), an artefact of a previous era, without any documentation. You have all the modern knowledge, and you want to make this mysterious device do things it was not supposed to do originally. Of course, with Visi On it's not quite the same; it runs on the IBM PC, a very well-documented and researched hardware platform.&lt;/p&gt;&lt;p&gt;If you have any feedback or comments, please leave them in the Mastodon thread or in the sr.ht ToDo project. Questions are fine, too!&lt;/p&gt;&lt;p&gt;VisiOn was made before many common user interface conventions were invented. It targeted a computer with a tiny resolution of 640x200 pixels, so its authors decided not use any icons. Therefore, VisiOn looks a bit alien. At the same time, it was made by people who knew what they were doing, and it is mostly coherent in its interface decisions.&lt;/p&gt;&lt;p&gt;Here is a copy of the OS tour I gave on Mastodon. I did not insert the clips as inline GIFs because the animations cannot be paused and are very distracting.&lt;/p&gt;&lt;p&gt;One immediately obvious thing here is the "hourglass" icon. Some believe that it might have been the first OS to use the hourglass mouse icon, but no, Xerox and InterLisp had it earlier. Apple Lisa, a contemporary, also had a similar mouse cursor.&lt;/p&gt;&lt;p&gt;The main application of the Visi On Application Manager is called "Services". The biggest diference between "Services" and other applications is that its "exit" button shuts down the whole OS.&lt;/p&gt;&lt;p&gt;You can see the screen has a System Menu at the bottom. The system menu is here to manage windows: make them FULL screen, re-FRAME them, CLOSE into an on-desktop button (we'd say "minimise" today) or OPEN them back. You cannot move the windows by their title bars. The system is very happy to beep at you, like it's a vintage PC game.&lt;/p&gt;&lt;p&gt;VisiOn is a multi-tasking operating system, and it allows launching multiple instances of the same application. To differentiate between them, the user can input the window name during the application startup.&lt;/p&gt;&lt;p&gt;Clip: multiple windows of the same program&lt;/p&gt;&lt;p&gt;In VisiOn, the Tutorial and Help apps implement a simple hyper-text system based on the "button" primitive. The "button" is simply a clickable area on the screen. It highlights by reversing the background and foreground colour when the mouse hovers over the button.&lt;/p&gt;&lt;p&gt;The system uses left-click for most operations. The right click is needed for the "scroll" operation. The user can scroll the documents (if there's something that can be scrolled) and the menu. You can see that the application menu isn't always fully visible, right?&lt;/p&gt;&lt;p&gt;The application menu system in VisiOn is hierarchical. Some operations make the menu behave like a modal window would in Windows or Mac. It is common not to add a "cancel" button in the menu. Instead, the system button STOP is used to cancel the operation.&lt;/p&gt;&lt;p&gt;In other situations, the menu can be navigated back by using the hierarchical menu selector. In either case, the system is "verb" driven - you choose the action ("verb"), and then you choose where the action should apply. The biggest problem is probably that the menu system is inconsistent. Some menus have "back" or "cancel" options, and some don't. Some "verbs" are actually nouns - "Printing". Some verbs start with a capital letter - "Configure" - like they are nouns. Perhaps it is a sign of a menu element that doesn't require "an object". The "object" here is more "grammatical" than a software concept.&lt;/p&gt;&lt;p&gt;The Archives app is the built-in file manager for the VisiOn and is one of the standard apps. Somewhat surprisingly, it puts deleted files into the "Wastebasket" folder. Windows couldn't do that because of Apple's patents - but Apple clearly wasn't the first (I bet it's coming from Xerox).&lt;/p&gt;&lt;p&gt;The Archives app makes it clear that VisiOn's file system supports long file names. VisiOn runs on top of MS-DOS 2.0, so it has to implement its own FS on top of FAT for this to work. The app can also work in two-pane mode, but it divides the screen horizontally, so long file names would fit on the screen easily.&lt;/p&gt;&lt;p&gt;The "verb"-oriented interface requires the app to show a "NEW" item on the screen, though it is a bit confusing. Can you rename a "NEW" file?&lt;/p&gt;&lt;p&gt;Clip: the Archives application&lt;/p&gt;&lt;p&gt;There are some mysterious buttons we have not explored in VisiOn just yet. One of them, TRANSFER, is used to command the applications to perform a "copy-paste" operation. It is impossible to just "copy" a thing and then "paste" it multiple times.&lt;/p&gt;&lt;p&gt;You can see that the OPEN command is completely unnecessary, because the closed window can be opened simply by clicking its minimised button. It would be nice for VisiOn to remove the OPEN button and replace TRANSFER with separate COPY and PASTE buttons. It shouldn't be too difficult to implement - Transfer From and Transfer Into are different system events from the application point of view. The concept of Copy&amp;amp;Paste wasn't ubiqiutous, but it was not unheard of either, because the VisiOn Word has these options in the application menu, in addition to the system's TRANSFER.&lt;/p&gt;&lt;p&gt;By the way, did you notice a cute VisiOn icon in front of some app names? It is actually two "non-printable" characters, 0x16 and 0x17. The system font has a few more useful icons hidden in it.&lt;/p&gt;&lt;p&gt;The last important button on the system menu of the VisiOn operating system is OPTIONS. Some applications have a configuration file, and the contents of the configuration file can be displayed on the right side of the window. The Options window behaves like a separate app with a separate menu. It is kind of similar to a pop-up window.&lt;/p&gt;&lt;p&gt;Curiously, it is possible to open the Options window from within the application. The same Options dialogue is shown by Word either by clicking "OPTIONS" or by clicking "Print&amp;gt;local-print". But then Word also has Cut&amp;amp;Paste menu system that allows copying and pasting within the application (but not between the application windows).&lt;/p&gt;&lt;p&gt;At face value, Visi On is a sleek, minimalist-looking windowing system for office applications. But it was built by people involved with early object-oriented programming, and the sales pitch for the system made some pretty bold claims. Were they true? Let's find out.&lt;/p&gt;&lt;p&gt;This is a spoliers section for those who thought they knew things about Visi On! For everyone else, this is going to be boring - if so, skip to the next section :)&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The primary objectives of Visi-On is a consistent user interface and portability. Visi-On is designed to run on any operating system. ("The Visi On experience")&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Sort of. Claiming "Visi-On is designed to run on any operating system" is like claiming "Unix is designed to run on any hardware". Clearly, it was made with portability in mind, but even supporting CP/M-86 on IBM PC would require a completely different VISION.EXE, and a different installer floppy format (i.e. you couldn't install Visi On Calc we have on a VisiOn running on top of CP/M). Supporting a different computer architecture would have been quite an ordeal.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;It did this by providing a kind of non machine specific "virtual machine" (called the Visi Machine) that all applications were written for. (Toasty Tech)&lt;/p&gt;&lt;/quote&gt;&lt;quote&gt;&lt;p&gt;What you have above Visi On or VOS itself is an interface we call the Visimachine interface. That is all of the calls that you need as a product designer to use all of the facilities provided by Visi On. This is the virtual machine? For product designers, this is the virtual machine. ("Byte", 1983/6)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;The term "virtual machine" used by VisiOn developers means something different from what we mean by the words "virtual machine" today. The closest word we use today would be "API". That's right, Visi On applications use a cross-platform API. Just like almost any other operating system today. I bet it was a really cool idea back in 1983, though.&lt;/p&gt;&lt;p&gt;By the way, "VisiHost" for IBM PC is VISION.EXE. The "VisiMachine", which is not a virtual machine, but a set of system libraries and the desktop manager, is also known as "VOS", "VisiOn Operating System", "Application Manager" or simply "Services".&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The virtual machine provided supports virtual memory and concurrent processing. ("The Visi On Operating Environment", IEEE TCDE Bulletin, September 1983)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Half-true. Visi On indeed implements virtual memory, but it is a software implementation without any memory protection mechanisms. Nothing but good will stops applications from reading or corrupting memory used by other applications.&lt;/p&gt;&lt;p&gt;The words "concurrent processing" might lead you to believe that VisiOn is a truly multitasking system. But its concurrent processing capabilities are quite limited. It is most definitely not a preemptive multitasking system, because if an application hangs, the whole system hangs. There seem to be some provisions for background data processing, at least for printer spooling. I think a flavour of cooperative multitasking might be possible in VisiOn, but so far I could not find a way to run an application in the background, so maybe it is not multitasking at all!&lt;/p&gt;&lt;quote&gt;&lt;p&gt;[The virtual machine] comprises 12 abstract data types. Each abstract data type responds to messages and provides a specific type of service. ("The Visi On Operating Environment", IEEE TCDE Bulletin, September 1983)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Unclear. It seems there are some "messaging" capabilities, but most of the interaction with the OS is still done through regular system calls. So far, I have discovered only messages that create a window, define a menu and request events from the OS. And the messages aren't really related to the "abstract data types". Perhaps, the representation of the objects and data types was different on the source code-level?&lt;/p&gt;&lt;p&gt;Also, this statement contradicts what the authors said about the system in an earlier interview.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Visihost is an object-oriented operating system, and it’s composed of 10 object types... You can establish instances of the objects by just sending messages to them on a Smalltalk message-class type interface. ("Byte", 6/1983)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Half-true. The "objects" do not seem to be "objects" in a modern sense. There is no system of attributes, methods and classes. Instead, there are instances of structures that are passed through the API to the OS. Most of the communication with the OS doesn't happen through messages; it happens through system calls.&lt;/p&gt;&lt;p&gt;In fact, the very same interview confirms this:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;An object in Smalltalk basically is a message, yes, that carries with it something that says what can be done to it. Visi On objects are not that complex. They’re objects... yes, they do have context of what their formatting is, but they aren’t Smalltalk objects.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Next!&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Activities request services from the Visi-Machine via Visi-Ops or via BITS (Basic Interaction Techniques). The two are distinguished in that a Visi-Op call requires a process ID. (A 16 bit number assigned by Visi-Corp to a given application program). ("Visi On from a Software Developer's point of view", 1983)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Mostly false. It seems VisiCorp itself couldn't agree on what BITS means; sometimes it is used for low-level system calls for the kernel ("VisiHost"), and sometimes it is used to talk about patterns of the user interface. Also, a process ID is not assigned by Visi-Corp; it is evaluated at run time.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;VOS (note: VisiMachine) is the only activity that actually does direct Visihost calls. All other calls come through VOS itself. ("Byte", 6/1983)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Mostly true. On the machine code level, applications can and do call the kernel ("VisiHost") directly. But all the existing applications only do so to talk to the Services ("VisiMachine"). On the machine code level, nothing stops the application from calling the VisiHost - this is how VisiMachine is getting things done - but presumably this would harm portability.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Visi On did not, however, include a graphical file manager. ("Visi On", Wikipedia, November 2025)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;False. There is an application called Archive, which is a part of the "Services", and it is a bona fide file manager. It does not have icons, though; but there are no icons in any other parts of VisiOn, either.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The scripts capability is another important aspect of ease of use. It’s a learn mode. It has a window that you can interact with. You can stop that learn mode at any time and tell the system to accept a variable. You open a scripts window and say, “learn.” Then the system prompts you for a name, you type in the name, and that will be the name of a script. ("Byte", 6/1983)&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Unfortunately, this part of VisiOn seems to be missing from the release. And speaking of missing features, the demo from 1983 also has a mysterious SAVE button that is not present in the final release.&lt;/p&gt;&lt;p&gt;Most of the technical documentation about the system available until now comes from the following articles and posts:&lt;/p&gt;&lt;p&gt;Visi On is meant to run on an IBM PC XT with a hard disk. It won't run properly on an IBM PC AT, and it won't run in most emulators. The pre-installed unprotected version with an AT patch available on ToastyTech runs in some emulators (86Box and PCEm). There are three software packages that can be installed in VisiOn: Word, Calc and Graph. Trying to install them from any old floppy is not possible due to various copy-protection methods (more on this soon).&lt;/p&gt;&lt;p&gt;The installed copy of VisiOn on the hard drive has the executable file &lt;code&gt;VISION.EXE&lt;/code&gt;, and a bunch of cryptic files in the &lt;code&gt;VISI_ON&lt;/code&gt; folder. Most interesting of those are:&lt;/p&gt;&lt;code&gt;     856 PROGRAMS.VOS -- ??? binary data
  200000 RESERVED.VOS -- resources for the applications? swap?
  777728 SEG00000.VOS -- the actual software installed in the OS?
    3290 SEGMENTS.VOS -- ??? binary data
&lt;/code&gt;&lt;p&gt;The files don't have an obvious structure. To grasp a feeling of the file, I use my favourite tool: Load Image From Raw Data in GNU IMP.&lt;/p&gt;&lt;p&gt;Scrolling through the segments surfaces a high-resolution font file and a garbled startup screen:&lt;/p&gt;&lt;p&gt;Are the installed files encrypted?&lt;/p&gt;&lt;p&gt;The installation floppies have the files with names matching those on the hard disk, but they have different content. It is obvious that the contents are encrypted by some simple method. For example, here is the contents of the first installation floppy:&lt;/p&gt;&lt;code&gt;    3110 16 Dec  1983 00000009.VOS -- same as the installed version, but encrypted
   10334 16 Dec  1983 00000010.VOS -- same as the installed version, but encrypted
     110 16 Dec  1983 H0000000.VOS -- a binary directory of files
   65536 16 Dec  1983 SEG10002.VOS -- overlay, seemingly encrypted
   65536 16 Dec  1983 SEG10003.VOS -- overlay, -""-
   65536 16 Dec  1983 SEG10005.VOS -- overlay, -""-
   44604 16 Dec  1983 VINSTALL.COM -- installer tool
   71680 16 Dec  1983 VISION.EXE   -- the program itself, very clearly it is encrypted in some simple way
&lt;/code&gt;&lt;p&gt;The contents of the files show a repeating pattern. For example, in SEG10003.VOS:&lt;/p&gt;&lt;code&gt;0000fe50  3c 6a 4f 3c 3c 6a 4f 3c  3c 6a 4f 3c 3c 6a 4f 3c  |&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;|
0000fe60  3c 6a b0 3c c3 6a 4f 3c  3c 6a 4f 3c 3c 6a 4f 3c  |&amp;lt;j.&amp;lt;.jO&amp;lt;&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;|
0000fe70  3c 6a 4f 3c 3c 6a 4f 3c  3c 6a 4f 3c 3c 6a 4f 3c  |&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;&amp;lt;jO&amp;lt;|
&lt;/code&gt;&lt;p&gt;Such a repeating pattern is indicative of an encryption with XOR. This is a very poor encryption technique; not only can the encryption key be guessed easily, but a long sequence of zero-bytes will expose the key as it is.&lt;/p&gt;&lt;p&gt;The installation floppies are not only encrypted, but also copy-protected with "out-of-bounds" sectors. They require special emulation methods, but thankfully those methods are well described in 86Box and HxC floppy tool documentation.&lt;/p&gt;&lt;p&gt;With a simple encryption and decryption tool, I managed to change the text in the Tutorial app shipped with the operating system and package it back to the (still copy-protected) floppy.&lt;/p&gt;&lt;p&gt;A floppy with a Visi On program has dozens of files named &lt;code&gt;00001000.VOS&lt;/code&gt;, &lt;code&gt;00001234.VOS&lt;/code&gt; and so on. Which files are mandatory, and what is in them? Lots of trial and error ("let's delete this file, let's put back this file") shows that a floppy must have the following files:&lt;/p&gt;&lt;code&gt;00000000.VOS&lt;/code&gt; - simply 12 zeroes&lt;code&gt;00001000.VOS&lt;/code&gt; - the description of the floppy (disk label and the list of programs on it), encrypted&lt;code&gt;00001001.VOS&lt;/code&gt; - a copy-protection mechanism, twice-encrypted&lt;code&gt;00001000.VOS&lt;/code&gt;,&lt;p&gt;The patterns in the unencrypted files can be observed by simply looking at the files. For example, this is a fragment of &lt;code&gt;00001000.VOS&lt;/code&gt; from the Visi On Calc package:&lt;/p&gt;&lt;code&gt;00000080  16 17 20 43 6f 6e 76 65  72 74 20 74 6f 20 43 61  |.. Convert to Ca|
00000090  6c 63 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |lc..............|
000000a0  31 2e 30 00 00 00 00 00  00 00 00 00 01 00 41 04  |1.0...........A.|
000000b0  00 00 00 00 00 00 00 00                           |........|
&lt;/code&gt;
&lt;p&gt;Note: IBM PC is a little-endian architecture. The byte sequence &lt;code&gt;41 04&lt;/code&gt; should be read as &lt;code&gt;0x0441&lt;/code&gt;, or 1089 in decimal. Sure enough, &lt;code&gt;00001089.VOS&lt;/code&gt; stores the installation script for the program, referencing other files on the floppy disk:&lt;/p&gt;&lt;code&gt;00000000  a7 43 16 17 20 43 6f 6e  76 65 72 74 20 74 6f 20  |.C.. Convert to | &amp;lt;- magic number + logo + name
00000010  43 61 6c 63 00 00 00 00  00 00 00 00 00 00 00 00  |Calc............|
00000020  00 00 31 2e 30 00 00 00  00 00 00 00 00 00 01 00  |..1.0...........| &amp;lt;- version
00000030  03 00 02 00 00 00 00 00  00 00 00 00 00 00 0a 00  |................|
00000040  00 00 01 00 42 04 01 00  02 00 43 04 01 00 01 00  |....B.....C.....| &amp;lt;- 0x442 - first file to install 
00000050  44 04 01 00 02 00 45 04  01 00 02 00 46 04 01 00  |D.....E.....F...|
00000060  02 00 47 04 01 00 02 00  48 04 01 00 01 00 49 04  |..G.....H.....I.|
00000070  01 00 01 00 4a 04 01 00  01 00 4b 04 01 00 01 00  |....J.....K.....|
00000080  00 00 02 00 4c 04                                 |....L.|           &amp;lt;- .... 0x44c - last file to install
&lt;/code&gt;
&lt;p&gt;A big obstacle in developing applications is the copy-protection mechanism in &lt;code&gt;00001001.VOS&lt;/code&gt;. The file itself is lightly encrypted with XOR, and then heavily encrypted with XOR once again. Decrypting it and loading it in Ghidra allowed me to understand (generally speaking) that this little tool is an x86 program with a custom header and a single entry point. This entry point is called by the installer to check that the floppy is copy-protected and to decrypt the contents of the floppy.&lt;/p&gt;&lt;p&gt;Atsuko eventually rewrote the copy-protection binary, to skip the encryption and floppy checks. This version of &lt;code&gt;00001001.VOS&lt;/code&gt; is very useful even for installing VisiCorp's programs, as it allows using regular floppy disks, or to tweak the program sources before the installation.&lt;/p&gt;&lt;p&gt;Fun note: the XOR encryption key on software disks is stored in plain text at the beginning of every &lt;code&gt;00001001.VOS&lt;/code&gt; file. Such a glaring oversight!&lt;/p&gt;&lt;p&gt;Checking unencrypted files (looking closely at their contents in a hex editor) revealed the internal structure of a program package:&lt;/p&gt;&lt;code&gt;main()&lt;/code&gt; function is, and&lt;p&gt;The type of VOS file is determined by two independent factors:&lt;/p&gt;&lt;p&gt;Operating system development needs a good debugger. Even the history of Windows hints that a good debugger is essential for building a trillion-dollar software empire. And, as you can imagine, Visi On doesn't run under debuggers, so an IBM PC emulator with a built-in debugger is a must.&lt;/p&gt;&lt;p&gt;There are multiple debugging emulators: Qemu, MAME, Bochs, DosBox and MartyPC. None could run Visi On. Among these, Bochs was my primary target, as it can emulate a Mouse Systems mouse - the only mouse type supported by Visi On. Thanks to built-in debugging features, I produced a simple patch that allowed Visi On to boot in Bochs and Qemu. The patch simply skips a few mouse-related checks:&lt;/p&gt;&lt;code&gt;--- visionat.exe.dmp
+++ viatmice.exe.dmp
@@ -2534,4 +2534,4 @@
 0000a010  e8 7a 00 eb 49 b0 83 e8  47 00 e8 81 00 8b 1e 80  |.z..I...G.......|
-0000a020  0b 8d 57 05 ec a8 01 74  f8 8d 57 00 ec 24 f8 3c  |..W....t..W..$.&amp;lt;|
-0000a030  80 75 ee e8 78 00 e8 54  00 eb 23 c7 06 7e 0b ff  |.u..x..T..#..~..|
+0000a020  0b 8d 57 05 ec a8 01 90  90 8d 57 00 ec 24 f8 3c  |..W.......W..$.&amp;lt;|
+0000a030  80 90 90 e8 78 00 e8 54  00 eb 23 c7 06 7e 0b ff  |....x..T..#..~..|
 0000a040  ff 06 b0 33 b4 35 cd 21  8c c0 07 0b c3 bb 7a 06  |...3.5.!......z.|
&lt;/code&gt;
&lt;p&gt;The Bochs interface rhymes visually with VisiOn, being monochrome and pixelated.&lt;/p&gt;&lt;p&gt;If you want to reverse engineer a multi-tasking graphical operating system, the first thing you probably should figure out is its mouse driver. When you start an application, you cannot know where it will be loaded into the computer's memory until it is started. And when it is started, it is already too late to look at the application's initialisation. We need to stop the operating system the very moment we ask to start the program. In other words, the moment we release the mouse button after the double click.&lt;/p&gt;&lt;p&gt;Visi On uses serial mice connected over the COM port. Looking at the emulator events, I can see that the COM port is configured to be interrupt-driven. On an IBM PC, the handler for COM1 port interrupts is known as IRQ4/INT 0x0c. In other words, the address of the mouse driver is recorded in the interrupt table of the computer - it is set to &lt;code&gt;1a68:0000&lt;/code&gt;, which, by the way, is exactly where it is in VISION.EXE.&lt;/p&gt;&lt;p&gt;In Bochs, you cannot set up a breakpoint (sometimes known as "pause") at the interrupt address, but you can set up a breakpoint for the next instruction. When I figured this out, it was easy to set a breakpoint at the mouse driver and understand how the mouse driver works.&lt;/p&gt;&lt;p&gt;Now I could simulate mouse clicking in the following way. RAM address &lt;code&gt;0x1f21b&lt;/code&gt; holds the mouse button status. Writing "1" there makes the OS think there was a right button click. Writing "2" and then "0" works as "press and release the left mouse button". With this, I managed to pinpoint the moment the OS starts an applications.&lt;/p&gt;&lt;p&gt;A tool that can convert machine code back to something human-readable is called a disassembler. There are many options, but I went with NSA's Ghidra as it is the tool I've used in the past to reverse-engineer the Sumikko Gurashi computer.&lt;/p&gt;&lt;p&gt;Normally, disassembly is a straightforward process. Truth to be told, I expected the whole reverse engineering process to take a couple of weekends. If only life was so simple...&lt;/p&gt;&lt;p&gt;Here is a bit of the disassembly of now-open-source contemporary text editor EDLIN from Microsoft, as seen by Ghidra:&lt;/p&gt;&lt;code&gt;       0000:0119 50              PUSH       AX
       0000:011a b4 30           MOV        AH,0x30     ; syscall 0x30
       0000:011c cd 21           INT        0x21        ; an MS-DOS call
       0000:011e 3c 02           CMP        AL,0x2
       0000:0120 7d 05           JGE        LAB_0000_0127
       0000:0122 ba 8a 10        MOV        DX,0x108a   ; pointer to an error message
       0000:0125 eb e7           JMP        LAB_0000_010e
&lt;/code&gt;
&lt;p&gt;Here is the corresponding source code:&lt;/p&gt;&lt;code&gt;;----- Check Version Number --------------------------------------------;
        push    ax
        mov     ah,Get_Version
        int     21h
        cmp     al,2
        jae     vers_ok                         ; version &amp;gt;= 2, enter editor
        mov     dx,offset dg:bad_vers_err
        jmp     short errj
;-----------------------------------------------------------------------;
&lt;/code&gt;
&lt;p&gt;The disassembly basically matches the source code and thus is easy to understand.&lt;/p&gt;&lt;p&gt;Compare with the disassembly coming from VisiOn:&lt;/p&gt;&lt;code&gt;       64c5:0c55 c7 06 16        MOV        word ptr [0x16],0x0
                 00 00 00
       64c5:0c5b 8b 1e 16 00     MOV        BX,word ptr [0x16]
       64c5:0c5f 89 1e 18 00     MOV        word ptr [0x18],BX
       64c5:0c63 8b 0e 18 00     MOV        CX,word ptr [0x18]
       64c5:0c67 89 0e 9c 15     MOV        word ptr [0x159c],CX
       64c5:0c6b 8b 16 9c 15     MOV        DX,word ptr [0x159c]
       64c5:0c6f 89 16 de 09     MOV        word ptr [0x9de],DX
       64c5:0c73 83 ec 02        SUB        SP,0x2
       64c5:0c76 c7 46 d6        MOV        word ptr [BP + -0x2a],0x1
                 01 00
       64c5:0c7b 83 ec 02        SUB        SP,0x2
       64c5:0c7e c7 46 d4        MOV        word ptr [BP + -0x2c],0x1742
                 42 17
       64c5:0c83 e8 9e 00        CALL       define_window
&lt;/code&gt;
&lt;p&gt;Can you follow the logic?&lt;/p&gt;&lt;code&gt;var_0x16 = 0
BX = var_0x16
var_0x18 = BX
CX = var_0x18
var_0x159c = CX
DX = var_0x159c
var_0x9de = DX
**whack the stack!**
BP[-0x2a] = 1
**whack the stack!**
BP[-0x2c] = 0x1742
CALL       define_window
&lt;/code&gt;
&lt;p&gt;Do you also feel your blood boiling from seeing the "hot potato" variable definition? It should have been&lt;/p&gt;&lt;code&gt;var_0x16 = 0
var_0x18 = 0
var_0x9de = 0
var_0x159c = 0
BX = 0
CX = 0
DX = 0
CALL define_window(0x1742, 1)
&lt;/code&gt;
&lt;p&gt;The comment "whack the stack!" above is quite representative of what is happening in the code.&lt;/p&gt;&lt;p&gt;Most computers nowadays have a stack. If you don't know what a "stack" is, imagine: you work as a clerk, and your assignments come in the form of sheets of paper with tasks. You put new sheets with tasks on top of the sheets you already have. When you need to process the next task, you usually take the topmost sheet. You might feel bad for all the old tasks at the bottom of the stack, but it is the easiest way to keep track of things.&lt;/p&gt;&lt;p&gt;Here is where "stack frames" come. Now, imagine that you have a coworker obsessed with efficiency. They think that some old tasks should be done before newer tasks, and some new tasks should be done after old tasks. To do so, they take a chunk of the sheets from the stack, rearrange them as they see fit, and put them back in. Sometimes they even grab multiple unrelated chunks of the stack at once. A chunk of a stack is a "stack frame".&lt;/p&gt;&lt;p&gt;Using stack frames simplifies code compilation for subroutines, because a subroutine can assume that it can do whatever it wants with its stack frame, treating it like its own private memory allocated on the global stack. "Forgetting" the data from the stack frame is as simple as moving the stack pointer.&lt;/p&gt;&lt;p&gt;This technique used to be common on x86-based computers some 40 years ago. Ghidra doesn't support it at all. Bochs doesn't care about the BP stack and can only show you the SP stack. VisiOn almost never uses the SP stack directly; most of the applications are working with the BP stack.&lt;/p&gt;&lt;p&gt;I believe this is a property of the C compiler Visi On used. A different compiler might have used SP, just like modern compilers do. And most certainly, a hypothetical Visi On port for Motorola 68k CPU, a processor that doesn't have a BP register, would not need to emulate the BP stack frame.&lt;/p&gt;&lt;p&gt;The IBM PC, VisiOn target computer, is built around the Intel 8088 processor. A remarkable thing about this processor is that it uses the segment memory model. In a nutshell, at any given moment in time, the program has access to no more than four fragments of the computer's RAM, each 64 kilobytes in size: the code segment, the data segment, the stack segment, and the "extra" segment. This memory organisation simplifies porting programs from 8-bit computers, and in theory allows a straightforward implementation of multi-tasking for small programs. If you have 640 kilobytes of RAM, and your program is configured to use a single segment for all four segments (CS, DS, SS and ES), you could easily load 10 programs at once.&lt;/p&gt;&lt;p&gt;But, as it happens, segments are quite limiting. A single data segment can store about 35 pages of "plain text" in a common 8-bit encoding. If you want to store a long document in the computer's RAM (a novel or a thesis), your program will need to switch between multiple data segments.&lt;/p&gt;&lt;p&gt;By the way, a memory reference to data within a single segment is called a "short pointer". A memory reference to a different segment is called a "far segment". To unambiguously identify a region in memory, you need a "long pointer" consisting of a segment and offset pair.&lt;/p&gt;&lt;p&gt;Things are much worse if a program doesn't fit in a single code segment. For programs running under DOS, it is usually not an issue: the program can assume it has a monopoly over the computer's RAM and just use "CALL FAR" and "JMP FAR" to change the current code segment. Even so, the operating system might load the program into any available memory segment. If the program uses "far" calls or pointers, the operating system must perform a "relocation". This is how things were done in DOS and early Windows versions.&lt;/p&gt;&lt;p&gt;VisiOn's approach to memory management is different from DOS. Each code segment is position-independent; it cannot use far CALLs or long pointers. Large programs are split into multiple code segments. When a program is executing a code segment 1 and needs to call a function from a code segment 2, for example, it must do so through the operating system. The benefit of this approach is a software implementation of "virtual memory". If a program is, for example, 2 megabytes large, and the computer only has 512 kB of RAM, the operating system can only keep in RAM the segments of the program that are being executed right now. When a program requests a segment not in the RAM, the OS can load it from the hard drive, in a form of swapping.&lt;/p&gt;&lt;p&gt;By the way, most of the time the ES segment is set to the kernel/OS/VisiHost data segment, and SS is set to DS (the current applications' data segment).&lt;/p&gt;&lt;p&gt;Even so, VisiOn could have been "normal" about their implementation of virtual memory. A far call might have looked like this: &lt;code&gt;call_segment(segment_number, function_address)&lt;/code&gt;. Instead, it looks like this: &lt;code&gt;call(). Magic!&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This is what cross-segment calls look like in Ghidra (and it would look exactly the same in any other disassembler):&lt;/p&gt;&lt;code&gt;    5e32:009b cd c1       INT 0xc1                    ; Call operating system entry point 0xc1
    5e32:009d 28 08       SUB byte ptr [BX + SI],CL   ; ??? Change a random memory byte ???
&lt;/code&gt;
&lt;p&gt;The disassembler assumes that bytes &lt;code&gt;0x28 0x08&lt;/code&gt; encode a command. It is a normal thing to assume; this is how the Intel x86 processor normally works. But in this case, it is not a command, it is a 16-bit number: &lt;code&gt;0x0828&lt;/code&gt;. The OS tweaks the return address from the INT 0xc1 handler so these two bytes are skipped by the processor.&lt;/p&gt;&lt;p&gt;I call this kind of number "magic pointers", because a long pointer normally must be two 16-bit numbers: a segment and an offset. But in VisiOn, a single 16-bit number encodes both. This is implemented in a really clever way. Remember the "entry points" table I mentioned?&lt;/p&gt;&lt;p&gt;The "entry points" table has pairs of 16-bit numbers: segment and offset. For example, if a function is stored in a segment file 0x0002 at the offset 0x1234, the table will have both numbers written down:&lt;/p&gt;&lt;code&gt;&amp;lt;entry_points_table:0&amp;gt; 0x1234 0x0002
&lt;/code&gt;
&lt;p&gt;Now, what is the "magic pointer" then? It is a pointer (or offset) to the address of a row in this table, in bytes, relative to the beginning of the code segment where the entry points table is stored. Baaam!&lt;/p&gt;&lt;p&gt;The code above, &lt;code&gt;INT 0xc1 ; 0x0828&lt;/code&gt; basically tells the OS:&lt;/p&gt;&lt;code&gt;offset&lt;/code&gt; and &lt;code&gt;segment&lt;/code&gt;&lt;code&gt;segment:offset&lt;/code&gt;&lt;p&gt;Moreover, the &lt;code&gt;segment&lt;/code&gt; references in the entry points table are dynamically refreshed. The operating system keeps track of the physical RAM address where each segment is loaded.&lt;/p&gt;&lt;p&gt;VisiOn is unusually aggressive at memory management compared to its contemporaries; it keeps swapping code segments in and out. This is very troublesome for debugging.&lt;/p&gt;&lt;p&gt;Imagine that the program you are debugging, currently loaded to the computer's RAM at segment &lt;code&gt;0x5e32&lt;/code&gt;, makes a cross-segment call at the offset &lt;code&gt;0x9b&lt;/code&gt; (like in the code snippet in the previous chapter). Let's say you're not interested in what is happening in this call, and you want to just "step over" the function call. You expect that when the far call is completed, your program will continue starting from the address &lt;code&gt;0x5e32:0x09f&lt;/code&gt; (the next command after the "magic pointer"). Oh, how naive!&lt;/p&gt;&lt;p&gt;The operating system can (and often does) decide to swap your program out of RAM during the far call. When the OS swaps your program back in, it will put it in the next available code segment, for example, &lt;code&gt;0x4c4b&lt;/code&gt;. The execution will continue not from &lt;code&gt;0x5e3d:0x09f&lt;/code&gt; but from &lt;code&gt;0x4c4b:0x09f&lt;/code&gt;. Your breakpoint at &lt;code&gt;0x5e32:0x09f&lt;/code&gt; won't activate; the debugger's "step over" function simply doesn't work.&lt;/p&gt;&lt;p&gt;All the code segments in VisiOn have a command &lt;code&gt;jmp [es:0x0]&lt;/code&gt; at the address &lt;code&gt;0x9&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;When an application's function is called (be it &lt;code&gt;main&lt;/code&gt;, an event handler, or a "magic pointer" call), the OS pushes &lt;code&gt;0x9&lt;/code&gt; on the stack as the &lt;code&gt;return address&lt;/code&gt; before &lt;code&gt;jmp&lt;/code&gt; to the function's entry point.&lt;/p&gt;&lt;p&gt;When a function finishes its work and executes a &lt;code&gt;ret&lt;/code&gt; command, the CPU gets the return address from the stack (&lt;code&gt;0x9&lt;/code&gt;) and executes the command &lt;code&gt;jmp [es:0x0]&lt;/code&gt;. This is a far jump, but where does it jump to? The answer is: the CPU reads a long pointer from &lt;code&gt;es:0&lt;/code&gt; (the beginning of the OS kernel data segment); then jumps to it. The code at this point will decide what is the next &lt;code&gt;jmp&lt;/code&gt; destination. This technique is called "jumping into a trampoline".&lt;/p&gt;&lt;p&gt;If you're writing your program in assembly (and you shouldn't be), then no one stops you from replacing &lt;code&gt;ret&lt;/code&gt; at the end of your functions with:&lt;/p&gt;&lt;code&gt;add SP, 2
jmp [es:0x0]
&lt;/code&gt;
&lt;p&gt;You can avoid "returning to &lt;code&gt;0x9&lt;/code&gt;", but you still must jump into the trampoline. Fun!&lt;/p&gt;&lt;p&gt;A major part of the reverse-engineering effort was focused on trying to understand the internals of two smallest applications available for the OS, the Tutorial app ("tutor") and the Convert To Calc app ("cvtcalc"). The Tutorial app is 6.3 kilobytes of machine code, but that's actually quite a lot: 3525 lines (about 80 A4 sheets) of disassembly.&lt;/p&gt;&lt;p&gt;One thing that really simplified the debugging was adding Bochs' "magic breakpoints" to the Tutor and CVTCalc apps. Magic breakpoints work like this: when the emulator encounters a useless instruction - &lt;code&gt;xchg bx, bx&lt;/code&gt; - it treats it as a breakpoint. These breakpoints happen as if by "magic", without any need to simulate mouse click events or figure out segment relocation between the calls to the OS. The only downside: this command needs to be "squeezed in" into the existing machine code. Thankfully, some of the machine instructions in the Tutor app are &lt;code&gt;NOP&lt;/code&gt; ("do nothing"), so I replaced a few of those with &lt;code&gt;xchg bx, bx&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Most operating systems provide "system calls", a set of library methods that can manage disks, RAM, and so on. Graphical operating systems often provide calls for creating windows, and even handling the mouse and keyboard. Visi On is no exception.&lt;/p&gt;&lt;p&gt;A standard way to make a system call on an IBM PC-compatible is to call a software interrupt. The operating system tells the CPU that it can handle a certain software interrupt; a program uses this interrupt to communicate with the OS; the OS can return control to the program when the system call is finished. This is how system calls work in MS-DOS, for example:&lt;/p&gt;&lt;code&gt;;; Print a character
mov DL, '!'     ; the character to print in the DL register
mov AH, 2       ; function number 2 in the AH register
int 0x21        ; MS-DOS system call
&lt;/code&gt;
&lt;p&gt;VisiOn registers multiple interrupt handlers; among those, three are commonly used: &lt;code&gt;0xc0&lt;/code&gt;, &lt;code&gt;0xc1&lt;/code&gt; and &lt;code&gt;0xc2&lt;/code&gt;. The interrupts &lt;code&gt;0xc1&lt;/code&gt; and &lt;code&gt;0xc2&lt;/code&gt; are used for direct and indirect "magic pointer" function calls. &lt;code&gt;0xc0&lt;/code&gt; is the system call interrupt; it is the interface to the VisiHost.&lt;/p&gt;&lt;p&gt;Designed with portability in mind, VisiHost accepts arguments to the system calls through the stack: different processors might have different registers, but VisiOn most definitely needs to have a stack to work. A VisiOn system call looks like this:&lt;/p&gt;&lt;code&gt;;; Get the Segment ID for own data segment
push process_id         ; put "process_id" variable on the stack
push 0x219              ; push the syscall number and the size of the arguments in bytes on the stack
int 0xc0                ; call VisiHost
&lt;/code&gt;
&lt;p&gt;I originally thought that &lt;code&gt;0x219&lt;/code&gt; is the number of the syscall, but very quickly discovered that there are only ~0x70 syscall handlers, so the actual syscall number is simply &lt;code&gt;0x19&lt;/code&gt;. It took a bit of trial, error, reading the disassembly of the kernel, and stepping through a call to understand that &lt;code&gt;0x02&lt;/code&gt; is the number of the arguments passed to the syscall times two.&lt;/p&gt;&lt;p&gt;The reason for that is simple: the application's stack is stored in its own data segment. When the operating system takes control, it uses its own data segment with its own stack. To pass the parameters between the stacks, the OS copies all the syscall arguments from one stack to the other.&lt;/p&gt;&lt;p&gt;There aren't that many system calls that a regular application makes. Among those, the first two calls an application makes are &lt;code&gt;0x17&lt;/code&gt; and &lt;code&gt;0x19&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;0x17&lt;/code&gt; returns the process ID for the current application.&lt;/p&gt;&lt;p&gt;&lt;code&gt;0x19&lt;/code&gt; takes a process ID as an argument and returns the data segment ID for the application. A VisiOn application absolutely must know its own Data Segment ID. The Segment ID is passed to all the syscalls; for example, when the application asks the OS to print a string on the screen, it needs to pass around not only the offset to the string relative to a data segment, but also the Segment ID for this data segment.&lt;/p&gt;&lt;p&gt;These two are followed by a system call &lt;code&gt;0x18&lt;/code&gt; - "get Application Manager data" - which I will describe later.&lt;/p&gt;&lt;p&gt;A bare-bones application for VisiOn must:&lt;/p&gt;&lt;p&gt;All of this is done with system calls &lt;code&gt;0x21&lt;/code&gt; and &lt;code&gt;0x22&lt;/code&gt;. How did I find this out? There was no silver bullet, I've been running the same code in the debugger over and over again, tweaking some parameters, commenting out some bits of code here and there, and eventually asking Atsuko to write a small assembly program following the specifications I provided to confirm the discoveries experimentally.&lt;/p&gt;&lt;p&gt;Originally, I thought that &lt;code&gt;0x21&lt;/code&gt; was something like "create windows &amp;amp; menus" and &lt;code&gt;0x22&lt;/code&gt; was "redraw the window and maybe wait for an event". But something didn't feel right. &lt;code&gt;0x21&lt;/code&gt; is always called with a different structure as the argument: sometimes it defines a window, sometimes it defines a menu and the event handlers, and sometimes it destroys all the created UI elements. &lt;code&gt;0x22&lt;/code&gt; always returns a value, and sometimes it makes the application go into the background.&lt;/p&gt;&lt;p&gt;So, my conclusion is: most likely, &lt;code&gt;0x21&lt;/code&gt; is "send the message" and &lt;code&gt;0x22&lt;/code&gt; is "receive the message (maybe wait for one)". I don't have many examples of "messages", but I managed to partially describe "create the window" and "wait for the events" structures.&lt;/p&gt;&lt;p&gt;These messages resemble Smalltalk, but they are relatively rare compared to other types of system calls. It makes me think that at some point VisiOn left behind its Smalltalk roots, and the "messages" subsystem might be just a remnant of the original design.&lt;/p&gt;&lt;p&gt;"Create the menu and wait for an event" function does something wacky. The structure we pass to the syscall &lt;code&gt;0x21&lt;/code&gt; accepts a pointer as one of the arguments. In the original VisiOn apps, it points to a structure created on a stack. For the sake of simplicity, we placed this structure in the data segment. Things worked until we added on-screen buttons; clicking a button would crash the system. Why? The operating system used this pointer to access data from both after and before the pointer. In other words, this is a pointer to the middle of a structure!&lt;/p&gt;&lt;p&gt;Why would anyone do that? No idea. This detail of the implementation likely didn't matter for programs written in Visi C, and most developers probably didn't even know about it.&lt;/p&gt;&lt;p&gt;The articles in the BYTE magazine tell us that if an application wants to draw on the screen, print a text, read a file from the disk, or define an on-screen button, it needs to do so through VisiMachine. Indeed, while VisiHost system calls can do a great many things, the applications I tried to reverse-engineer never called them directly. For example, there are syscalls &lt;code&gt;0x34&lt;/code&gt; and &lt;code&gt;0x35&lt;/code&gt; for drawing a bitmap on the screen and copying a bitmap from the screen, but these syscalls are only ever called from the Services app. Moreover, they're not "window-aware": with these calls, the application can draw on the screen outside of its own window!&lt;/p&gt;&lt;p&gt;So, if we want to be good citizens, we need to follow the standard call convention and reach out to the VisiMachine. But how?!&lt;/p&gt;&lt;p&gt;The most common system call in any application is &lt;code&gt;0x1e&lt;/code&gt;. This call seemingly does almost anything, including but not limited to: reading data from files, printing text on the screen and creating on-screen buttons. Sounds like a "VisiOp" (VisiMachine) call, doesn't it?&lt;/p&gt;&lt;p&gt;Figuring out the VisiOp calls was really challenging. The number of arguments for the call is always different, and even the arguments themselves are different between different runs of the same program. This call is intense!&lt;/p&gt;&lt;p&gt;When a program starts, it asks the OS for the Application Manager data segment using syscall &lt;code&gt;0x18&lt;/code&gt;. From this segment, the program copies into its own segment:&lt;/p&gt;&lt;p&gt;If you're just looking at disassembly, this operation is simply copying 372 bytes (12 + 1 * 2 + 2 + 170 words) from one segment to the other.&lt;/p&gt;&lt;p&gt;When a program needs to call a VisiOp, the syscall &lt;code&gt;0x1e&lt;/code&gt; receives:&lt;/p&gt;&lt;p&gt;Additionally, the application sets a flag at the &lt;code&gt;segment+offset&lt;/code&gt; of the Application Manager before this call, and clears it after the call.&lt;/p&gt;&lt;p&gt;My understanding of the Virtual Device IDs is limited and is based on the actions taken by the OS.&lt;/p&gt;&lt;code&gt;// VT = Virtual Terminal
#define DEVICE_VT 0x3
#define DEVICE_MEM 0x4
#define DEVICE_MENU 0xc

#define SYS_MESSAGE 0x0
#define SYS_CALL 0x1
&lt;/code&gt;
&lt;p&gt;The "Virtual Device" IDs are sort of similar to the list of "data types" from the article "The Visi On Operating Environment":&lt;/p&gt;&lt;code&gt;PROGRAM 
PROCESS 
MEMORY SEGMENT
PORT 
RASTER
DEVICE
FILE
BACKGROUND 
FONT
MOUSE
SOUNDMAKER 
KEYBOARD
&lt;/code&gt;
&lt;p&gt;But it couldn't be the same thing! Both "font management" (FONT) and "define clickable area" (MOUSE) are managed through the &lt;code&gt;DEVICE_VT&lt;/code&gt;. Did the specification for the system change between this article and the OS release? No idea.&lt;/p&gt;&lt;p&gt;Things get really interesting and confusing if you consider that the &lt;code&gt;0x1e&lt;/code&gt; system call requires a "function" ID to operate. For example, if you want to load a font, you need to look up the "function" ID &lt;code&gt;0x18&lt;/code&gt;, and pass it along with the &lt;code&gt;DEVICE_VT&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As you can imagine, it is impossible to load a font in a &lt;code&gt;DEVICE_MEM&lt;/code&gt;, and it is impossible to read a file from &lt;code&gt;DEVICE_VT&lt;/code&gt;. What is the point of using both device ID and function ID, then? I don't know. But considering that we pass the number of arguments twice, perhaps, there is no meaning to it. Perhaps, VisiOps were implemented by two different teams who couldn't agree on how to pass the arguments between the VisiHost and the VisiMachine.&lt;/p&gt;&lt;p&gt;The true nature of "function" IDs is "magic" pointers. The "function ID" for any VisiOp is simply an offset to a function in the "magic" pointers list for the Application Manager. There are over 600 "magic" pointers in the Application Manager (you can find the list in &lt;code&gt;SEG10003.VOS&lt;/code&gt; at offset &lt;code&gt;0xa600&lt;/code&gt;), but only 170 of them are used as VisiOps.&lt;/p&gt;&lt;p&gt;While VisiOn has a VisiOp that can copy data between two segments by their Segment IDs, every now and then it can be useful to resolve the physical address for a given memory segment. This is most definitely not a cross-platform approach, but VisiOn applications use it when they want to peek inside the Application Manager's data segment.&lt;/p&gt;&lt;p&gt;The memory access dance is done this way:&lt;/p&gt;&lt;code&gt;segID2seg = es:[[es:0x6]+[es:0x4]]&lt;/code&gt;&lt;code&gt;es:[segID2seg+segID]&lt;/code&gt; stores flags of the segment ID (swapped in/out, used for read/write)&lt;code&gt;es:[segID2seg+segID+2]&lt;/code&gt; stores the physical location of the segment in the RAM, if it is loaded&lt;p&gt;If the segment is not present in RAM (swapped out), it is possible to ask the OS to load it for you. I highly suspect syscall &lt;code&gt;0x05&lt;/code&gt; is responsible for segment loading, but most apps are not using it. All the normally required memory segments are present in the RAM as if by "magic", anyways. The Pyramid game is using this call to ensure the font segment is in the RAM. Without this call, it might not load in time on a slow machine like an XT; this is probably related to the DMA disk operations initiated by the OS.&lt;/p&gt;&lt;p&gt;It isn't too difficult to use VisiOn's Virtual Terminal Device for text output and on-screen buttons, but displaying graphics and custom fonts required a bit of trial and error. The reason, of course, is the lack of references: VisiOn only displays images on the splash screen of programs like Word and Calc!&lt;/p&gt;&lt;p&gt;I think there must be a VisiOp function for displaying a bitmapped image. But, for some reason, when VisiOn Calc draws a splash screen, it uses something completely different: a custom font.&lt;/p&gt;&lt;p&gt;The bitmapped image is divided into glyphs, glyphs (1-127) are loaded as a font, and then the image on the screen is printed as if it was just a string. The Convert To Calc logo, printed with the default font, looks like this:&lt;/p&gt;&lt;p&gt;You can see that this method allows image compression: empty blocks are represented by spaces.&lt;/p&gt;&lt;p&gt;The VisiOp "load font" loads a font from a Segment ID passed to it. This means an application must know how to find a (dynamically-assigned!) Segment ID for any of its segments. The code that resolves a Segment ID for a magic pointer &lt;code&gt;0x810&lt;/code&gt; is so clever it made me flip my table:&lt;/p&gt;&lt;code&gt;mov ax, [cs:0x810+2]
&lt;/code&gt;
&lt;p&gt;Convert To Calc has multiple code and data segments. One of those segments has a table of "magic" pointers. The "magic" pointer at offset &lt;code&gt;0x810&lt;/code&gt; is a "magic" pointer to the file with the font. So far, nothing out of the ordinary.&lt;/p&gt;&lt;p&gt;As I mentioned before, the operating system fills out the "magic" pointer table (list of entry points) with the Segment IDs when it starts an application. The Segment IDs are filled out "in place". The entry points list in the Tutorial app is stored in a segment that doesn't have any code in it.&lt;/p&gt;&lt;p&gt;But Convert To Calc has a couple of functions exported from the "entry points and magic pointers" segment. When a cross-segment call is made to such a function, the current list of magic pointers and Segment IDs is stored right in the same code segment. A "magic" pointer, simply being an offset from the beginning of the file, can be read with a simple &lt;code&gt;mov&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;mov ax, [cs:magic_pointer]   ;; entry point offset
mov ax, [cs:magic_pointer+2] ;; entry point Segment ID
&lt;/code&gt;
&lt;p&gt;So, &lt;code&gt;mov ax, [cs:0x810+2]&lt;/code&gt; called from the code segment with the entry points table allows the program to know what Segment ID was assigned to the font segment.&lt;/p&gt;&lt;p&gt;Printing text through the VisiOn's virtual terminal in the graphical mode, for all intents and purposes, behaves like a proper Bit blit. One of the VisiOp parameters accepts a ROP code ("Raster OPeration").&lt;/p&gt;&lt;p&gt;VisiOn takes an interesting approach to ROPs and bitmap displaying. You might know that Windows supported ternary BitBLT with JIT-generated machine code for display rendering. VisiOn uses binary ROPs, similar to the ROPs in Xerox Alto or Bell Labs BLIT, and it also produces JIT machine code, but it produces the code for the "glyph space".&lt;/p&gt;&lt;p&gt;Among other things, VisiOn will break each character into bits when you load a font and then emit the machine code that will produce the required bits. Basically, if your font array was &lt;code&gt;font[char_id][bit_num]&lt;/code&gt;, it will be converted into &lt;code&gt;font_jit[bit_num][char_id]&lt;/code&gt;. I am not sure why; maybe there are some performance benefits to this approach.&lt;/p&gt;&lt;p&gt;If this sounds like an unnecessary headache, remember that bitmapped output on CGA is a headache already. The screen buffer in CGA is interlaced: odd and even lines are stored in separate memory blocks. The pixels on the screen are bit-packed, too. If you want to plot a pixel at coordinates (1,1), your program will need to:&lt;/p&gt;&lt;p&gt;These calculations are expensive, so it only makes sense to make the video driver slightly more complicated but feature-rich. For example, if you're reading the pixel from RAM anyway, you can choose between ADD, OR, NOT, or XOR pixel operations for free.&lt;/p&gt;&lt;p&gt;There are 16 available ROPs in total. Here is a checkerboard background and a circle drawn on top of it with different ROPs:&lt;/p&gt;&lt;p&gt;Each application is shipped with something I call a "mini-file-system". The format of it is primitive: the number of entries, the list of pointers to the entries, and then the entries themselves. Each entry has a header similar to the "segment header" used by the installer, consisting of the magic number and the length of the entry.&lt;/p&gt;&lt;p&gt;The mini-FS, among other things, is used for the built-in help system. Entries to the mini-FS can be referenced from the menu system, so the OS could "magically" display the right entry when the user clicks "HELP".&lt;/p&gt;&lt;p&gt;Naturally, the application can read entries from the mini-FS with a simple VisiOp call.&lt;/p&gt;&lt;p&gt;This reverse-engineering project ended up being much bigger than I anticipated. We have a working application, yes, but so far I've documented less than 10% of all the VisiHost and VisiOp calls. We still don't know how to implement keyboard input, or how to work with timers and background processes (if it is possible).&lt;/p&gt;&lt;p&gt;Atsuko and I would like to continue working on this SDK, but considering our other projects, I cannot imagine it taking as much priority as it has so far. This may be as far as we get. But this is pretty far already. If one were to follow these notes, they should be able to discover and document new VisiOps, say, from Word or Graph, very fast.&lt;/p&gt;&lt;p&gt;I discovered two funny bugs in the process of reverse-engineering.&lt;/p&gt;&lt;p&gt;If you've done any graphical programming for windowed environments, you would expect that the &lt;code&gt;Create_Window()&lt;/code&gt; function requires window dimensions for a freshly-created window. VisiOn is free from such prejudice. As far as I can tell, applications are not supposed to freely decide what their window size should be. The Application Manager's option sheet has fields "window width" and "window height" that define the dimensions for most windows (except for the Application Manager, Help and Tutorial windows).&lt;/p&gt;&lt;p&gt;Naturally, the application can read the dimensions of its window so it can resize the contents inside. But if the window dimensions are too small, some of the applications would crash, and would take down the whole system:&lt;/p&gt;&lt;p&gt;VisiOn loves to beep at the user. It beeps every time a menu option is chosen or an on-screen button is clicked.&lt;/p&gt;&lt;p&gt;If you are tired of the noise, you'd appreciate that Application Manager has an option to replace the sound with a "visual beep". It is implemented as a flashing area of 32x16 pixels around the mouse cursor. Every time the flashing is about to happen, an image "below" the cursor is preserved in RAM to be restored after the "visual beep" is over. However, the memory allocated for this bitmap is never freed. It takes between 200 and 1000 clicks to fill the RAM with useless copies of the mouse cursor, and then the system crashes.&lt;/p&gt;&lt;p&gt;Huge thanks to:&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://git.sr.ht/~nkali/vision-sdk/tree/main/item/note/index.md"/><published>2025-12-04T10:25:39+00:00</published></entry></feed>