<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-13T20:11:27.831083+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45566139</id><title>Spotlight on pdfly, the Swiss Army knife for PDF files</title><updated>2025-10-13T20:11:36.192406+00:00</updated><content>&lt;doc fingerprint="d2c16a62e09737b0"&gt;
  &lt;main&gt;
    &lt;p&gt;Project documentation: pdfly.readthedocs.io&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pdfly&lt;/code&gt; is the youngest project of the &lt;code&gt;py-pdf&lt;/code&gt; organization.
It has been created by Martin Thoma in 2022.&lt;/p&gt;
    &lt;p&gt;It's simply a CLI tool to manipulate PDF files, written in Python and based on the fpdf2 &amp;amp; pypdf libraries.&lt;/p&gt;
    &lt;p&gt;I'm a maintainer of the project 🙂&lt;/p&gt;
    &lt;head rend="h2"&gt;What can it do?&lt;/head&gt;
    &lt;p&gt;It has meany features, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;display PDF metadata using &lt;code&gt;pdfly meta&lt;/code&gt;and&lt;code&gt;pdfly pagemeta&lt;/code&gt;commands. Example:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;$ pdfly meta minimal-document.pdf
                      Operating System Data
┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃         Attribute ┃ Value                     ┃
┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         File Name │ /tmp/minimal-document.pdf │
│  File Permissions │ -rw-r--r--                │
│         File Size │ 16,978 bytes              │
│     Creation Time │ 2025-10-13 09:44:32       │
│ Modification Time │ 2025-10-13 09:44:32       │
│       Access Time │ 2025-10-13 09:44:46       │
└───────────────────┴───────────────────────────┘
                       PDF Data
┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃          Attribute ┃ Value                                                    ┃
┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       CreationDate │ 2022-04-03 18:05:42+02:00                                │
│            Creator │ TeX                                                      │
│           Producer │ pdfTeX-1.40.23                                           │
│              Pages │ 1                                                        │
│          Encrypted │ None                                                     │
│   PDF File Version │ %PDF-1.5                                                 │
│        Page Layout │                                                          │
│          Page Mode │                                                          │
│             PDF ID │ ID1=b'q\x96\xc3\xe3U\xc1|\x9fS\xba\x9a\r\xcap\xcd\xd0'   │
│                    │ ID2=b'q\x96\xc3\xe3U\xc1|\x9fS\xba\x9a\r\xcap\xcd\xd0'   │
│ Fonts (embedded) │                                                          │
│   Fonts (embedded) │ /KNEUFH+CMR10                                            │
│        Attachments │ []                                                       │
│             Images │ 0 images (0 bytes)                                       │
└────────────────────┴──────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;pdfly&lt;/code&gt;can also combine files into new PDF documents: it can extract specific pages &amp;amp; merge documents (&lt;code&gt;pdfly cat&lt;/code&gt;); selectively remove pages (&lt;code&gt;pdfly rm&lt;/code&gt;); convert images to PDF documents (&lt;code&gt;pdfly x2pdf&lt;/code&gt;); and even compress documents (&lt;code&gt;pdfly compress&lt;/code&gt;) or build booklets (&lt;code&gt;pdfly 2-up&lt;/code&gt;&amp;amp;&lt;code&gt;pdfly booklet&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pdfly&lt;/code&gt;includes some commands to pull out specific content from PDF files:&lt;code&gt;pdfly extract-images&lt;/code&gt;&amp;amp;&lt;code&gt;pdfly extract-annotated-text&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;sometimes you want to edit a PDF file manually, in a text editor. But when you do so, you break its&lt;/p&gt;&lt;code&gt;xref&lt;/code&gt;table, that is an index of byte offsets in the document.&lt;code&gt;pdfly update-offsets&lt;/code&gt;is there to save the day, fixing manually-edited PDF documents, so that they can be opened in a PDF viewer again!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Release 0.5.0 &amp;amp; new features&lt;/head&gt;
    &lt;p&gt;Today we released a new version: &lt;code&gt;pdfly release 0.5.0&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Thanks to several contributors, including developers taking part in Hacktoberfest, new exciting features have been added:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;pdfly sign&lt;/code&gt;allows you to easily sign PDF documents, while&lt;code&gt;pdfly check-sign&lt;/code&gt;makes it easy to check a PDF document signature. Thanks to @moormaster for implementing this in PRs #165 &amp;amp; #166 👍🙏.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pdfly extract-annotated-pages&lt;/code&gt;extract only annotated pages from a PDF, hence helping to review or rework pages from a large document iteratively. Thanks to Hal Wine (@hwine) for implementing this in PR #128 👍🙏.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pdfly rotate&lt;/code&gt;rotate specific pages of a document. Thanks to Subhajit Sahu (@wolfram77) for implementing this in PR #98 👍🙏.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What's next?&lt;/head&gt;
    &lt;p&gt;We have a bunch of feature ideas: &lt;code&gt;up-for-grabs&lt;/code&gt; issues, including some &lt;code&gt;good first issues&lt;/code&gt; aimed specially at new contributors, that are willing to help but new to open-source.&lt;/p&gt;
    &lt;p&gt;Personally, I think the &lt;code&gt;pdfly sign&lt;/code&gt; &amp;amp; &lt;code&gt;check-sign&lt;/code&gt; could become handy to many end-users, and I think we should continue to extend those commands usage options, as described in issue #71.&lt;/p&gt;
    &lt;p&gt;We would also be happy to get your feedbacks, bug reports &amp;amp; feature suggestions! 🙂&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chezsoi.org/lucas/blog/spotlight-on-pdfly.html"/><published>2025-10-13T08:36:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566441</id><title>MPTCP for Linux</title><updated>2025-10-13T20:11:35.750775+00:00</updated><content>&lt;doc fingerprint="a7b5e91a5cbdcba9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Multipath TCP or MPTCP is an extension to the standard TCP and is described in RFC 8684. It allows a device to make use of multiple interfaces at once to send and receive TCP packets over a single MPTCP connection. MPTCP can aggregate the bandwidth of multiple interfaces or prefer the one with the lowest latency. It also allows a fail-over if one path is down, and the traffic is seamlessly reinjected on other paths.&lt;/p&gt;
    &lt;code&gt;graph TD;
    subgraph MPTCP
        direction LR
        C_1(&amp;lt;div style="display: inline-block; min-width: 32px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
        S_1((&amp;lt;div style="display: inline-block; min-width: 55px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))
    end

    subgraph TCP
        direction LR
        C_2(&amp;lt;div style="display: inline-block; min-width: 32px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
        S_2((&amp;lt;div style="display: inline-block; min-width: 55px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))
    end

    C_1 &amp;lt;== "5G" ==&amp;gt; S_1
    C_1 &amp;lt;== "Wi-Fi&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Multiple paths (&amp;lt;i&amp;gt;subflows&amp;lt;/i&amp;gt;)&amp;lt;br /&amp;gt;at the same time" ==&amp;gt; S_1

    C_2 x-. "5G" .-x S_2
    C_2 &amp;lt;== "Wi-Fi&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;One path at a time" ==&amp;gt; S_2

    linkStyle 0 stroke:green;
    linkStyle 1 stroke:green;
    linkStyle 2 stroke:red;
    linkStyle 3 stroke:green;
&lt;/code&gt;
    &lt;head rend="h3"&gt;Use cases&lt;/head&gt;
    &lt;p&gt;Thanks to MPTCP, being able to use multiple paths in parallel or simultaneously brings new use-cases, compared to TCP:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seamless handovers: switching from one path to another while preserving established connections, e.g. Apple is using Multipath TCP on smartphones mainly for this reason since 2013.&lt;/item&gt;
      &lt;item&gt;Best network selection: using the “best” available path depending on some conditions, e.g. latency, losses, cost, bandwidth, etc.&lt;/item&gt;
      &lt;item&gt;Network aggregation: using multiple paths at the same time to have a higher throughput, e.g. to combine fixed and mobile networks to send files faster.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Concepts&lt;/head&gt;
    &lt;p&gt;Technically, when a new socket is created with the &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; protocol (Linux-specific), a subflow (or path) is created. This subflow consists of a regular TCP connection that is used to transmit data through one interface. Additional subflows can be negotiated later between the hosts. For the remote host to be able to detect the use of MPTCP, a new field is added to the TCP option field of the underlying TCP subflow. This field contains, amongst other things, a &lt;code&gt;MP_CAPABLE&lt;/code&gt; option that tells the other host to use MPTCP if it is supported. If the remote host or any middlebox in between does not support it, the returned &lt;code&gt;SYN+ACK&lt;/code&gt; packet will not contain MPTCP options in the TCP option field. In that case, the connection will be “downgraded” to plain TCP, and it will continue with a single path.&lt;/p&gt;
    &lt;p&gt;This behavior is made possible by two internal components: the path manager, and the packet scheduler.&lt;/p&gt;
    &lt;head rend="h3"&gt;Path Manager&lt;/head&gt;
    &lt;p&gt;The Path Manager is in charge of subflows, from creation to deletion, and also address announcements. Typically, it is the client side that initiates subflows, and the server side that announces additional addresses via the &lt;code&gt;ADD_ADDR&lt;/code&gt; and &lt;code&gt;REMOVE_ADDR&lt;/code&gt; options.&lt;/p&gt;
    &lt;code&gt;graph LR;
    C_1(&amp;lt;div style="display: inline-block; min-width: 35px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
    S_1((&amp;lt;div style="display: inline-block; min-width: 60px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))

    C_1 -. "Potential subflow" -.- S_1
    C_1 &amp;lt;== "Initial subflow" ==&amp;gt; S_1
    C_1 ~~~|"Subflows creation"| C_1
    S_1 ~~~|"Addresses announcement"| S_1

    linkStyle 0 stroke:orange;
    linkStyle 1 stroke:green;
&lt;/code&gt;
    &lt;p&gt;As of Linux v5.19, there are two path managers, controlled by the &lt;code&gt;net.mptcp.pm_type&lt;/code&gt; sysctl knob: the in-kernel one (type &lt;code&gt;0&lt;/code&gt;) where the same rules are applied for all the connections (see: &lt;code&gt;ip mptcp&lt;/code&gt;) ; and the userspace one (type &lt;code&gt;1&lt;/code&gt;), controlled by a userspace daemon (i.e. &lt;code&gt;mptcpd&lt;/code&gt;) where different rules can be applied for each connection.&lt;/p&gt;
    &lt;head rend="h3"&gt;Packet Scheduler&lt;/head&gt;
    &lt;p&gt;The Packet Scheduler is in charge of selecting which available subflow(s) to use to send the next data packet. It can decide to maximize the use of the available bandwidth, only to pick the path with the lower latency, or any other policy depending on the configuration.&lt;/p&gt;
    &lt;code&gt;graph LR;
    A_2(&amp;lt;div style="display: inline-block; min-width: 40px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-user&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)

    PS{Packet&amp;lt;br /&amp;gt;Scheduler}

    I_21(subflow 1)
    I_22(subflow 2)

    A_2 == "&amp;lt;div style='display: inline-block; min-width: 50px'&amp;gt;fa:fa-box fa:fa-box fa:fa-box&amp;lt;/div&amp;gt;" ==&amp;gt; PS
    PS -- "&amp;lt;div style='display: inline-block; min-width: 32px'&amp;gt;fa:fa-box fa:fa-box&amp;lt;/div&amp;gt;" --&amp;gt; I_21
    PS -- "&amp;lt;div style='display: inline-block; min-width: 14px'&amp;gt;fa:fa-box&amp;lt;/div&amp;gt;" --&amp;gt; I_22
    PS ~~~|"Packets distribution between subflows"| PS
&lt;/code&gt;
    &lt;p&gt;As of Linux v6.8, there is only one packet scheduler, controlled by sysctl knobs in &lt;code&gt;net.mptcp&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;p&gt;As of Linux v6.10, major features of MPTCP include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support of the &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;protocol in&lt;code&gt;socket()&lt;/code&gt;system calls.&lt;/item&gt;
      &lt;item&gt;Fallback from MPTCP to TCP if the peer or a middlebox do not support MPTCP.&lt;/item&gt;
      &lt;item&gt;Path management using either an in-kernel or userspace path manager.&lt;/item&gt;
      &lt;item&gt;Socket options that are commonly used with TCP sockets.&lt;/item&gt;
      &lt;item&gt;Debug features including MIB counters, diag support (used by the &lt;code&gt;ss&lt;/code&gt;command), and tracepoints.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the ChangeLog for more details.&lt;/p&gt;
    &lt;head rend="h2"&gt;Communication&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mailing List: mptcp@lists.linux.dev (plain text only): &lt;list rend="ul"&gt;&lt;item&gt;Archives&lt;/item&gt;&lt;item&gt;Info&lt;/item&gt;&lt;item&gt;Subscribe by sending an empty email in plain text to mptcp+subscribe@lists.linux.dev, and by replying to the challenge email.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;IRC: #mptcp on libera.chat&lt;/item&gt;
      &lt;item&gt;Online Meetings&lt;/item&gt;
      &lt;item&gt;Blog&lt;/item&gt;
      &lt;item&gt;Fediverse&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Projects&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Maintained by MPTCP community members&lt;/item&gt;
      &lt;item&gt;Projects with MPTCP-related enhancements &lt;list rend="ul"&gt;&lt;item&gt;iproute2 (for the &lt;code&gt;ip mptcp&lt;/code&gt;command)&lt;/item&gt;&lt;item&gt;Network Manager: MPTCP features are included starting with v1.40.&lt;/item&gt;&lt;item&gt;Multipath TCP applications: A project to coordinate MPTCP updates for popular TCP applications.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;iproute2 (for the &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mptcp.dev/"/><published>2025-10-13T09:25:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566638</id><title>American solar farms</title><updated>2025-10-13T20:11:34.940936+00:00</updated><content>&lt;doc fingerprint="ab95e1f33b2412f0"&gt;
  &lt;main&gt;
    &lt;p&gt;Last week, Jake Stid, a postdoctoral research associate at Michigan State University, announced Ground-Mounted Solar Energy in the United States (GM-SEUS). This is a 15K-array, 2.9M-panel dataset of utility and commercial-grade solar farms across the lower 48 states plus the District of Columbia. This dataset was constructed by a team of researchers including alumni from NOAA, NASA and the USGS.&lt;/p&gt;
    &lt;p&gt;Below is a heatmap of the assets catalogued in this dataset.&lt;/p&gt;
    &lt;p&gt;GM-SEUS is broken up into two datasets, one for arrays and another panels. Below you can see a solar farm with the array outlined in red and the panels covered purple.&lt;/p&gt;
    &lt;p&gt;In this post, I'll explore GM-SEUS's Solar Farm dataset.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Workstation&lt;/head&gt;
    &lt;p&gt;I'm using a 5.7 GHz AMD Ryzen 9 9950X CPU. It has 16 cores and 32 threads and 1.2 MB of L1, 16 MB of L2 and 64 MB of L3 cache. It has a liquid cooler attached and is housed in a spacious, full-sized Cooler Master HAF 700 computer case.&lt;/p&gt;
    &lt;p&gt;The system has 96 GB of DDR5 RAM clocked at 4,800 MT/s and a 5th-generation, Crucial T700 4 TB NVMe M.2 SSD which can read at speeds up to 12,400 MB/s. There is a heatsink on the SSD to help keep its temperature down. This is my system's C drive.&lt;/p&gt;
    &lt;p&gt;The system is powered by a 1,200-watt, fully modular Corsair Power Supply and is sat on an ASRock X870E Nova 90 Motherboard.&lt;/p&gt;
    &lt;p&gt;I'm running Ubuntu 24 LTS via Microsoft's Ubuntu for Windows on Windows 11 Pro. In case you're wondering why I don't run a Linux-based desktop as my primary work environment, I'm still using an Nvidia GTX 1080 GPU which has better driver support on Windows and ArcGIS Pro only supports Windows natively.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing Prerequisites&lt;/head&gt;
    &lt;p&gt;I'll use GDAL 3.9.3 and a few other tools to help analyse the data in this post.&lt;/p&gt;
    &lt;code&gt;$ sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable
$ sudo apt update
$ sudo apt install \
    gdal-bin \
    jq
&lt;/code&gt;
    &lt;p&gt;I'll use DuckDB v1.4.1, along with its H3, JSON, Lindel, Parquet and Spatial extensions, in this post.&lt;/p&gt;
    &lt;code&gt;$ cd ~
$ wget -c https://github.com/duckdb/duckdb/releases/download/v1.4.1/duckdb_cli-linux-amd64.zip
$ unzip -j duckdb_cli-linux-amd64.zip
$ chmod +x duckdb
$ ~/duckdb
&lt;/code&gt;
    &lt;code&gt;INSTALL h3 FROM community;
INSTALL lindel FROM community;
INSTALL json;
INSTALL parquet;
INSTALL spatial;
&lt;/code&gt;
    &lt;p&gt;I'll set up DuckDB to load every installed extension each time it launches.&lt;/p&gt;
    &lt;code&gt;$ vi ~/.duckdbrc
&lt;/code&gt;
    &lt;code&gt;.timer on
.width 180
LOAD h3;
LOAD lindel;
LOAD json;
LOAD parquet;
LOAD spatial;
&lt;/code&gt;
    &lt;p&gt;The maps in this post were mostly rendered with QGIS version 3.44. QGIS is a desktop application that runs on Windows, macOS and Linux. The application has grown in popularity in recent years and has ~15M application launches from users all around the world each month.&lt;/p&gt;
    &lt;p&gt;I used QGIS' Tile+ plugin to add basemaps from Esri to the maps in this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Analysis-Ready Data&lt;/head&gt;
    &lt;p&gt;I'll download a dataset containing the US CENSUS State codes. This will let me map the state ID in the arrays dataset to their state name.&lt;/p&gt;
    &lt;code&gt;$ wget https://gist.github.com/a8dx/2340f9527af64f8ef8439366de981168/raw/81d876daea10eab5c2675811c39bcd18a79a9212/US_State_Bounding_Boxes.csv
&lt;/code&gt;
    &lt;p&gt;I'll download the ZIP file of deliverables for GM-SEUS.&lt;/p&gt;
    &lt;code&gt;$ wget -O GMSEUS_v1_0.zip \
    'https://zenodo.org/records/14827819/files/GMSEUS_v1_0.zip?download=1'
$ unzip GMSEUS_v1_0.zip
&lt;/code&gt;
    &lt;p&gt;I'll extract the projection used. This proj4 string will be used to below to re-project the data into EPSG:4326.&lt;/p&gt;
    &lt;code&gt;$ gdalsrsinfo \
    -o proj4 \
    GMSEUS_v1_0/GPKG/GMSEUS_Arrays_Final.gpkg
&lt;/code&gt;
    &lt;code&gt;+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs
&lt;/code&gt;
    &lt;p&gt;I'll use DuckDB to clean up the values and produce both a geometry field and a bounding box for each feature in this dataset. This will make working with this dataset remotely, such as from AWS S3, much easier.&lt;/p&gt;
    &lt;code&gt;$ ~/duckdb
&lt;/code&gt;
    &lt;p&gt;This following produced a ZStandard-compressed, spatially-sorted Parquet file of the arrays dataset. I dropped the Z dimension as it was unused. The unknown values have been turned into NULLs. The original GPKG file was 108 MB and the resulting Parquet file is 37 MB.&lt;/p&gt;
    &lt;code&gt;COPY (
   WITH a AS (
       SELECT * EXCLUDE(geom),
              ST_FORCE2D(
                ST_FLIPCOORDINATES(
                  ST_TRANSFORM(
                      geom,
                      '+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs',
                      'EPSG:4326'))) geometry
       FROM   ST_READ('GMSEUS_v1_0/GPKG/GMSEUS_Arrays_Final.gpkg')
   )
   SELECT   a.* EXCLUDE (geometry,
                         tilt,
                         tiltEst,
                         instYr,
                         instYrLT,
                         effInit,
                         avgAzimuth,
                         avgLength,
                         avgSpace,
                         avgWidth),
            {'xmin': ST_XMIN(ST_EXTENT(geometry)),
             'ymin': ST_YMIN(ST_EXTENT(geometry)),
             'xmax': ST_XMAX(ST_EXTENT(geometry)),
             'ymax': ST_YMAX(ST_EXTENT(geometry))} AS bbox,
             ST_ASWKB(geometry) geometry,
             CASE WHEN instYr::INT     = -9999 THEN NULL ELSE instYr::INT   END AS instYr,
             CASE WHEN instYrLT::INT   = -9999 THEN NULL ELSE instYrLT::INT END AS instYrLT,
             CASE WHEN numRow::INT     = -9999 THEN NULL ELSE numRow::INT   END AS numRow,
             CASE WHEN tilt::INT       = -9999 THEN NULL ELSE tilt::INT     END AS tilt,
             CASE WHEN tiltEst::INT    = -9999 THEN NULL ELSE tiltEst::INT  END AS tiltEst,
             CASE WHEN effInit::INT    = -9999 THEN NULL ELSE effInit       END AS effInit,
             CASE WHEN avgAzimuth::INT = -9999 THEN NULL ELSE avgAzimuth    END AS avgAzimuth,
             CASE WHEN avgLength::INT  = -9999 THEN NULL ELSE avgLength     END AS avgLength,
             CASE WHEN avgSpace::INT   = -9999 THEN NULL ELSE avgSpace      END AS avgSpace,
             CASE WHEN avgWidth::INT   = -9999 THEN NULL ELSE avgWidth      END AS avgWidth,
             b.NAME state_name
   FROM     a
   JOIN     'US_State_Bounding_Boxes.csv' b ON a.STATEFP = b.STATEFP
   ORDER BY HILBERT_ENCODE([ST_Y(ST_CENTROID(geometry)),
                            ST_X(ST_CENTROID(geometry))]::double[2])
) TO 'arrays.parquet' (
   FORMAT            'PARQUET',
   CODEC             'ZSTD',
   COMPRESSION_LEVEL 22,
   ROW_GROUP_SIZE    15000);
&lt;/code&gt;
    &lt;p&gt;The original GPKG file for the panels dataset was 1.1 GB and the resulting Parquet file is 334 MB.&lt;/p&gt;
    &lt;code&gt;COPY (
   WITH a AS (
       SELECT * EXCLUDE(geom),
              ST_FORCE2D(
                ST_FLIPCOORDINATES(
                  ST_TRANSFORM(
                      geom,
                      '+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs',
                      'EPSG:4326'))) geometry
       FROM   ST_READ('GMSEUS_v1_0/GPKG/GMSEUS_Panels_Final.gpkg')
   )
   SELECT   * EXCLUDE (geometry,
                       rowSpace),
            {'xmin': ST_XMIN(ST_EXTENT(geometry)),
             'ymin': ST_YMIN(ST_EXTENT(geometry)),
             'xmax': ST_XMAX(ST_EXTENT(geometry)),
             'ymax': ST_YMAX(ST_EXTENT(geometry))} AS bbox,
             ST_ASWKB(geometry) geometry,
             CASE WHEN rowSpace::INT = -9999 THEN NULL ELSE rowSpace END AS rowSpace
   FROM     a
   ORDER BY HILBERT_ENCODE([ST_Y(ST_CENTROID(geometry)),
                            ST_X(ST_CENTROID(geometry))]::double[2])
) TO 'panels.parquet' (
   FORMAT            'PARQUET',
   CODEC             'ZSTD',
   COMPRESSION_LEVEL 22,
   ROW_GROUP_SIZE    15000);
&lt;/code&gt;
    &lt;head rend="h2"&gt;Solar Arrays&lt;/head&gt;
    &lt;p&gt;The arrays Parquet file has 15,017 rows. Below is an example record.&lt;/p&gt;
    &lt;code&gt;$ echo "SELECT * EXCLUDE(bbox,
                         geometry),
               bbox::JSON bbox
        FROM   'arrays.parquet'
        LIMIT  1" \
    | ~/duckdb -json \
    | jq -S .
&lt;/code&gt;
    &lt;code&gt;[
  {
    "COUNTYFP": "019",
    "GCR1": 0.6996,
    "GCR2": 0.614,
    "STATEFP": "45",
    "Source": "OSM",
    "arrayID": 2807,
    "avgAzimuth": 170.63,
    "avgLength": 47.76166666666666,
    "avgSpace": 3.003333333333333,
    "avgWidth": 4.776666666666666,
    "bbox": {
      "xmax": -79.97229830431786,
      "xmin": -79.97325770533094,
      "ymax": 32.87833627192598,
      "ymin": 32.87808294640646
    },
    "capMW": 0.246,
    "capMWest": 0.246,
    "effInit": 0.197963503102977,
    "instYr": 2021,
    "instYrLT": 2021,
    "latitude": 32.87818725544087,
    "longitude": -79.97276617375104,
    "modType": "c-si",
    "mount": "fixed_axis",
    "nativeID": "9324",
    "newBound": 1,
    "numRow": 6.0,
    "numRow_1": 6,
    "state_name": "South Carolina",
    "tilt": 30,
    "tiltEst": 30,
    "totArea": 1779.0,
    "totRowArea": 1244.93,
    "version": "v1.0"
  }
]
&lt;/code&gt;
    &lt;p&gt;Below are the field names, data types, percentages of NULLs per column, number of unique values and minimum and maximum values for each column.&lt;/p&gt;
    &lt;code&gt;$ ~/duckdb
&lt;/code&gt;
    &lt;code&gt;SELECT   column_name,
         column_type,
         null_percentage,
         approx_unique,
         min,
         max
FROM     (SUMMARIZE
          FROM READ_PARQUET('arrays.parquet'))
WHERE    column_name != 'geometry'
AND      column_name != 'bbox'
ORDER BY 1;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬─────────────┬─────────────────┬───────────────┬─────────────────────┬────────────────────┐
│ column_name │ column_type │ null_percentage │ approx_unique │         min         │        max         │
│   varchar   │   varchar   │  decimal(9,2)   │     int64     │       varchar       │      varchar       │
├─────────────┼─────────────┼─────────────────┼───────────────┼─────────────────────┼────────────────────┤
│ COUNTYFP    │ VARCHAR     │            0.00 │           235 │ 001                 │ 810                │
│ GCR1        │ DOUBLE      │            0.00 │          5057 │ 0.1047              │ 1.0                │
│ GCR2        │ DOUBLE      │            0.00 │          5013 │ 0.1245              │ 0.988              │
│ STATEFP     │ VARCHAR     │            0.00 │            49 │ 01                  │ 56                 │
│ Source      │ VARCHAR     │            0.00 │             6 │ CCVPV               │ USPVDB             │
│ arrayID     │ BIGINT      │            0.00 │         13155 │ 1                   │ 15017              │
│ avgAzimuth  │ DOUBLE      │           32.84 │          4295 │ 25.0                │ 269.27             │
│ avgLength   │ DOUBLE      │           39.79 │          8358 │ 4.02                │ 449.5004           │
│ avgSpace    │ DOUBLE      │           39.79 │          8623 │ 0.024               │ 20.0               │
│ avgWidth    │ DOUBLE      │           39.79 │          9185 │ 0.67625             │ 29.80222222222222  │
│ capMW       │ DOUBLE      │            0.00 │          5280 │ 0.001250225184651   │ 1051.703           │
│ capMWest    │ DOUBLE      │            0.00 │          7863 │ 0.004               │ 3170.1             │
│ effInit     │ DOUBLE      │            0.49 │            39 │ 0.132210289727273   │ 0.205484167047619  │
│ instYr      │ INTEGER     │            0.00 │            24 │ 1985                │ 2024               │
│ instYrLT    │ INTEGER     │            0.24 │            17 │ 2009                │ 2023               │
│ latitude    │ DOUBLE      │            0.00 │         16986 │ 25.53796582594631   │ 48.99547137225406  │
│ longitude   │ DOUBLE      │            0.00 │         15656 │ -124.10440474967092 │ -67.15066374183608 │
│ modType     │ VARCHAR     │            0.00 │             3 │ c-si                │ thin-film          │
│ mount       │ VARCHAR     │            0.00 │            10 │ dual_axis           │ unknown            │
│ nativeID    │ VARCHAR     │            0.00 │         15141 │ 1                   │ York Solar         │
│ newBound    │ BIGINT      │            0.00 │             2 │ 0                   │ 1                  │
│ numRow      │ DOUBLE      │            0.00 │          1461 │ 0.0                 │ 56782.0            │
│ numRow_1    │ INTEGER     │            0.00 │          1117 │ 0                   │ 56782              │
│ state_name  │ VARCHAR     │            0.00 │            57 │ Alabama             │ Wyoming            │
│ tilt        │ INTEGER     │           55.46 │            47 │ 0                   │ 83                 │
│ tiltEst     │ INTEGER     │           55.46 │            30 │ 10                  │ 43                 │
│ totArea     │ DOUBLE      │            0.00 │         13182 │ 54.0                │ 13735113.0         │
│ totRowArea  │ DOUBLE      │            0.00 │         15396 │ 44.97               │ 7223924.662        │
│ version     │ VARCHAR     │            0.00 │             1 │ v1.0                │ v1.0               │
├─────────────┴─────────────┴─────────────────┴───────────────┴─────────────────────┴────────────────────┤
│ 29 rows                                                                                      6 columns │
└────────────────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;I'll generate a heatmap of the asset locations in this dataset.&lt;/p&gt;
    &lt;code&gt;CREATE OR REPLACE TABLE h3_4_stats AS
    SELECT   H3_LATLNG_TO_CELL(
                bbox.ymin,
                bbox.xmin, 4) AS h3_4,
             COUNT(*) num_buildings
    FROM     READ_PARQUET('arrays.parquet')
    WHERE    bbox.xmin BETWEEN -178.5 AND 178.5
    GROUP BY 1;

COPY (
    SELECT ST_ASWKB(H3_CELL_TO_BOUNDARY_WKT(h3_4)::geometry) geometry,
           num_buildings
    FROM   h3_4_stats
) TO 'h3_4_stats.gpkg'
  WITH (FORMAT GDAL,
        DRIVER 'GPKG',
        LAYER_CREATION_OPTIONS 'WRITE_BBOX=YES');
&lt;/code&gt;
    &lt;p&gt;Normally I would produce a Parquet file as even with 10s of thousands of records it'll generate in seconds versus a minute or so with GPKG. But ArcGIS Pro 3.5 didn't want to open the Parquet file I generated. QGIS 3.44 was fine with it but I wanted to use Esri's Nova basemap for the rendering below.&lt;/p&gt;
    &lt;p&gt;ArcGIS Pro 3.6 should be released sometime in the next few weeks so I'll re-examine this issue when it's out.&lt;/p&gt;
    &lt;p&gt;Below is the relationship between the sources of data and the installation year.&lt;/p&gt;
    &lt;code&gt;PIVOT    'arrays.parquet'
ON       Source
USING    COUNT(*)
GROUP BY instYr
ORDER BY instYr;
&lt;/code&gt;
    &lt;code&gt;┌────────┬───────┬───────┬───────────────┬───────┬───────┬────────┐
│ instYr │ CCVPV │ CWSD  │ GMSEUSgeorect │  OSM  │  SAM  │ USPVDB │
│ int32  │ int64 │ int64 │     int64     │ int64 │ int64 │ int64  │
├────────┼───────┼───────┼───────────────┼───────┼───────┼────────┤
│   1985 │     0 │     0 │             0 │     0 │     0 │      1 │
│   1986 │     0 │     0 │             0 │     1 │     0 │      0 │
│   2002 │     0 │     0 │             0 │     0 │     0 │      1 │
│   2005 │     0 │     0 │             0 │    26 │     0 │      0 │
│   2006 │     0 │     0 │             0 │     2 │     0 │      1 │
│   2007 │     0 │     0 │             0 │    44 │     0 │      5 │
│   2008 │     0 │     0 │             0 │    58 │     1 │     11 │
│   2009 │     5 │     0 │             0 │    10 │     5 │     19 │
│   2010 │    20 │     0 │             0 │    71 │    20 │     37 │
│   2011 │    24 │     0 │             2 │   193 │    30 │    102 │
│   2012 │    59 │     0 │             2 │   267 │    88 │    157 │
│   2013 │    83 │     0 │             3 │   259 │    82 │    209 │
│   2014 │   102 │     0 │             1 │   335 │   119 │    291 │
│   2015 │   107 │     3 │             0 │   532 │   125 │    320 │
│   2016 │   145 │     1 │             2 │   564 │   170 │    412 │
│   2017 │   135 │     0 │             1 │   661 │   167 │    476 │
│   2018 │    66 │    34 │             4 │   644 │   210 │    414 │
│   2019 │    28 │    39 │             6 │   467 │   178 │    453 │
│   2020 │    10 │    75 │             1 │   437 │   186 │    496 │
│   2021 │     5 │    33 │             6 │   406 │   241 │    446 │
│   2022 │     1 │   173 │             3 │   231 │   354 │    166 │
│   2023 │     0 │     0 │             3 │   176 │   722 │    134 │
│   2024 │     0 │     0 │             0 │    31 │  1571 │      0 │
├────────┴───────┴───────┴───────────────┴───────┴───────┴────────┤
│ 23 rows                                               7 columns │
└─────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Below is the relationship between the mount and mod type.&lt;/p&gt;
    &lt;code&gt;PIVOT    'arrays.parquet'
ON       modType
USING    COUNT(*)
GROUP BY mount
ORDER BY mount;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬───────┬───────┬───────────┐
│    mount    │ c-si  │  csp  │ thin-film │
│   varchar   │ int64 │ int64 │   int64   │
├─────────────┼───────┼───────┼───────────┤
│ dual_axis   │   301 │    18 │         1 │
│ fixed_axis  │  6057 │    32 │       208 │
│ mixed       │     2 │     0 │         0 │
│ mixed_df    │   189 │     7 │         0 │
│ mixed_dfs   │    94 │     0 │         0 │
│ mixed_ds    │    38 │     1 │         0 │
│ mixed_fs    │    60 │     0 │         1 │
│ single_axis │  2876 │    11 │       231 │
│ unknown     │  4885 │     5 │         0 │
└─────────────┴───────┴───────┴───────────┘
&lt;/code&gt;
    &lt;p&gt;Below are the array capacity counts rounded to the neared 100 MW and broken down by source.&lt;/p&gt;
    &lt;code&gt;WITH a AS (
    SELECT   Source,
             ROUND(capMW / 100) * 100 AS capacity,
             COUNT(*) num_recs
    FROM     'arrays.parquet'
    GROUP BY 1, 2
)
PIVOT    a
ON       Source
USING    SUM(num_recs)
GROUP BY capacity
ORDER BY capacity;
&lt;/code&gt;
    &lt;code&gt;┌──────────┬────────┬────────┬───────────────┬────────┬────────┬────────┐
│ capacity │ CCVPV  │  CWSD  │ GMSEUSgeorect │  OSM   │  SAM   │ USPVDB │
│  double  │ int128 │ int128 │    int128     │ int128 │ int128 │ int128 │
├──────────┼────────┼────────┼───────────────┼────────┼────────┼────────┤
│      0.0 │    790 │    356 │            33 │   5295 │   4022 │   3669 │
│    100.0 │   NULL │      2 │          NULL │     67 │    143 │    350 │
│    200.0 │   NULL │   NULL │             1 │     22 │     49 │     73 │
│    300.0 │   NULL │   NULL │          NULL │     17 │     21 │     49 │
│    400.0 │   NULL │   NULL │          NULL │      6 │     13 │      7 │
│    500.0 │   NULL │   NULL │          NULL │      4 │     11 │      2 │
│    600.0 │   NULL │   NULL │          NULL │      2 │      3 │   NULL │
│    700.0 │   NULL │   NULL │          NULL │      1 │      3 │   NULL │
│    800.0 │   NULL │   NULL │          NULL │   NULL │      2 │      1 │
│    900.0 │   NULL │   NULL │          NULL │   NULL │      1 │   NULL │
│   1000.0 │   NULL │   NULL │          NULL │   NULL │      1 │   NULL │
│   1100.0 │   NULL │   NULL │          NULL │      1 │   NULL │   NULL │
├──────────┴────────┴────────┴───────────────┴────────┴────────┴────────┤
│ 12 rows                                                     7 columns │
└───────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;head rend="h2"&gt;Solar Panels&lt;/head&gt;
    &lt;p&gt;The panels Parquet file has 2,917,782 rows. Below is an example record.&lt;/p&gt;
    &lt;code&gt;$ echo "SELECT * EXCLUDE(bbox,
                         geometry),
               bbox::JSON bbox
        FROM   'panels.parquet'
        LIMIT  1" \
    | ~/duckdb -json \
    | jq -S .
&lt;/code&gt;
    &lt;code&gt;[
  {
    "Source": "gmseus",
    "arrayID": 2807.0,
    "bbox": {
      "xmax": -79.97312295800064,
      "xmin": -79.97325770533483,
      "ymax": 32.87833627193374,
      "ymin": 32.87830393275682
    },
    "panelID": 2620732,
    "rowArea": 29.1,
    "rowAzimuth": 174.62,
    "rowLength": 12.77,
    "rowMount": "fixed_axis",
    "rowSpace": 8.42,
    "rowWidth": 3.0,
    "version": "v1.0"
  }
]
&lt;/code&gt;
    &lt;p&gt;Below are the field names, data types, percentages of NULLs per column, number of unique values and minimum and maximum values for each column.&lt;/p&gt;
    &lt;code&gt;$ ~/duckdb
&lt;/code&gt;
    &lt;code&gt;SELECT   column_name,
         column_type,
         null_percentage,
         approx_unique,
         min,
         max
FROM     (SUMMARIZE
          FROM READ_PARQUET('panels.parquet'))
WHERE    column_name != 'geometry'
AND      column_name != 'bbox'
ORDER BY 1;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬─────────────┬─────────────────┬───────────────┬───────────────┬─────────────┐
│ column_name │ column_type │ null_percentage │ approx_unique │      min      │     max     │
│   varchar   │   varchar   │  decimal(9,2)   │     int64     │    varchar    │   varchar   │
├─────────────┼─────────────┼─────────────────┼───────────────┼───────────────┼─────────────┤
│ Source      │ VARCHAR     │            0.00 │             3 │ CCVPV         │ gmseus      │
│ arrayID     │ DOUBLE      │            0.08 │          9451 │ 1.0           │ 15017.0     │
│ panelID     │ BIGINT      │            0.00 │       2703164 │ 1             │ 2917782     │
│ rowArea     │ DOUBLE      │            0.00 │         88974 │ 15.01         │ 1999.76     │
│ rowAzimuth  │ DOUBLE      │            0.00 │         14901 │ 90.0          │ 270.0       │
│ rowLength   │ DOUBLE      │            0.00 │         26759 │ 4.02          │ 530.05      │
│ rowMount    │ VARCHAR     │            0.00 │             3 │ dual_axis     │ single_axis │
│ rowSpace    │ DOUBLE      │            0.17 │         13376 │ 7.4765186e-08 │ 20.0        │
│ rowWidth    │ DOUBLE      │            0.00 │          1863 │ 0.45          │ 102.14      │
│ version     │ VARCHAR     │            0.00 │             1 │ v1.0          │ v1.0        │
├─────────────┴─────────────┴─────────────────┴───────────────┴───────────────┴─────────────┤
│ 10 rows                                                                         6 columns │
└───────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Below is the relationship between the sources of data and the row mount.&lt;/p&gt;
    &lt;code&gt;PIVOT    'panels.parquet'
ON       Source
USING    COUNT(*)
GROUP BY rowMount
ORDER BY rowMount;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬────────┬────────┬─────────┐
│  rowMount   │ CCVPV  │  OSM   │ gmseus  │
│   varchar   │ int64  │ int64  │  int64  │
├─────────────┼────────┼────────┼─────────┤
│ dual_axis   │     44 │   5975 │   80225 │
│ fixed_axis  │  13344 │ 118639 │  163512 │
│ single_axis │ 189699 │ 743371 │ 1602973 │
└─────────────┴────────┴────────┴─────────┘
&lt;/code&gt;
    &lt;p&gt;Of the 15,017 arrays in this dataset, only 5,358 have any panels in them.&lt;/p&gt;
    &lt;code&gt;.maxrows 20

SELECT   a.arrayID,
         COUNT(DISTINCT b.panelID)
FROM     READ_PARQUET('arrays.parquet') a
JOIN     READ_PARQUET('panels.parquet') b
ON       ST_COVERS(a.geometry, b.geometry)
GROUP BY a.arrayID
ORDER BY 2 DESC;
&lt;/code&gt;
    &lt;code&gt;┌─────────┬───────────────────────────┐
│ arrayID │ count(DISTINCT b.panelID) │
│  int64  │           int64           │
├─────────┼───────────────────────────┤
│   11958 │                     56762 │
│   14225 │                     51140 │
│   12162 │                     43741 │
│   12433 │                     37304 │
│   14461 │                     31898 │
│   13229 │                     30093 │
│    6589 │                     27080 │
│   13329 │                     25120 │
│   12597 │                     24054 │
│   12224 │                     23449 │
│      ·  │                         · │
│      ·  │                         · │
│      ·  │                         · │
│    1792 │                         1 │
│    2286 │                         1 │
│     863 │                         1 │
│    1816 │                         1 │
│    8997 │                         1 │
│   12358 │                         1 │
│    6564 │                         1 │
│    3845 │                         1 │
│    6574 │                         1 │
│     991 │                         1 │
├─────────┴───────────────────────────┤
│ 5358 rows (20 shown)      2 columns │
└─────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Below is a solar farm in Nevada where some arrays have panels and others do not.&lt;/p&gt;
    &lt;p&gt;I was interested in seeing the solar farm with 56K panels. Below are its coordinates.&lt;/p&gt;
    &lt;code&gt;SELECT ST_CENTROID(geometry)
FROM   'arrays.parquet'
WHERE  arrayID = 11958;
&lt;/code&gt;
    &lt;code&gt;┌────────────────────────────────────────────────┐
│             st_centroid(geometry)              │
│                    geometry                    │
├────────────────────────────────────────────────┤
│ POINT (-115.34248808114013 35.611919498003175) │
└────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Even this has arrays without marked panels.&lt;/p&gt;
    &lt;p&gt;I'm looking forward to v2 of this dataset with better panel detection. It'll be great to get a good approximation of how many are deployed in the US.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tech.marksblogg.com/american-solar-farms.html"/><published>2025-10-13T10:02:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566644</id><title>Dutch government takes control of Chinese-owned chipmaker Nexperia</title><updated>2025-10-13T20:11:34.833683+00:00</updated><content>&lt;doc fingerprint="b514b9655bb771e3"&gt;
  &lt;main&gt;
    &lt;p&gt;The Dutch government has taken control of Nexperia, a Chinese-owned semiconductor maker based in the Netherlands, in an extraordinary move to ensure a sufficient supply of its chips remains available in Europe amid rising global trade tensions.&lt;/p&gt;
    &lt;p&gt;Nexperia, a subsidiary of China's Wingtech Technology, specializes in the high-volume production of chips used in automotive, consumer electronics and other industries, making it vital for maintaining Europe's technological supply chains.&lt;/p&gt;
    &lt;p&gt;On Sunday evening, the Dutch Minister of Economic Affairs revealed that it had invoked the "Goods Availability Act" on the company in September in order "to prevent a situation in which the goods produced by Nexperia (finished and semi-finished products) would become unavailable in an emergency."&lt;/p&gt;
    &lt;p&gt;Following the announcement from The Hague, Wingtech plunged its maximum daily limit of 10% on the Shanghai Stock Exchange.&lt;/p&gt;
    &lt;p&gt;The Goods Availability Act allows The Hague to intervene in private companies to ensure the availability of critical goods in preparation for emergency situations, and its use comes amid escalation in the U.S.-China trade war.&lt;/p&gt;
    &lt;p&gt;The government statement said the "highly exceptional" move had been made after the ministry had observed "recent and acute signals of serious governance shortcomings and actions" within Nexperia.&lt;/p&gt;
    &lt;p&gt;"These signals posed a threat to the continuity and safeguarding on Dutch and European soil of crucial technological knowledge and capabilities. Losing these capabilities could pose a risk to Dutch and European economic security," it said, identifying the automotive industry as particularly vulnerable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Governance changes&lt;/head&gt;
    &lt;p&gt;In a corporate filing dated Oct.13, lodged with the Shanghai Stock Exchange, Wingtech confirmed Nexperia was under temporary external management and had been asked to suspend changes to the company's assets, business or personnel for up to a year, according to a Google translation.&lt;/p&gt;
    &lt;p&gt;Wingtech Chairman Zhang Xuezheng had been immediately suspended from his roles as executive director of Nexperia Holdings and nonexecutive director of Nexperia after the ministerial order, according to the filing.&lt;/p&gt;
    &lt;p&gt;The filing added that Nexperia's daily operations will continue, with the impact of the measures not yet quantifiable.&lt;/p&gt;
    &lt;p&gt;"The Dutch government's decision to freeze Nexperia's global operations under the pretext of 'national security' constitutes excessive intervention driven by geopolitical bias, rather than a fact-based risk assessment," Wingtech said in a deleted WeChat post, which was archived and translated by Chinese policy blog Pekingnology.&lt;/p&gt;
    &lt;p&gt;It added that since it acquired Nexperia in 2019, Wingtech "has strictly abided by the laws and regulations of all jurisdictions where it operates, maintaining transparent operations and sound governance," and employs "thousands of local staff" through research and development and manufacturing sites in the Netherlands, Germany and Britain.&lt;/p&gt;
    &lt;p&gt;A spokesperson from Nexperia told CNBC that the company had no further comments, but that it "complies with all existing laws and regulations, export controls and sanctions regimes," and remained in regular contact with relevant authorities.&lt;/p&gt;
    &lt;p&gt;The Netherlands' move comes after Beijing tightened its restrictions on the export of rare earth elements and magnets Thursday, which could impact Europe's automotive industry.&lt;/p&gt;
    &lt;p&gt;The move could also further strain trade relations between China and the Netherlands, following years of restrictions on Dutch company ASML's exports of advanced semiconductor manufacturing equipment to China.&lt;/p&gt;
    &lt;p&gt;In 2023, the Netherlands had also investigated Nexperia's proposed acquisition of chip firm startup Nowi, though the deal was later approved.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/10/13/dutch-government-takes-control-of-chinese-owned-chipmaker-nexperia.html"/><published>2025-10-13T10:03:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566660</id><title>Two Paths to Memory Safety: CHERI and OMA</title><updated>2025-10-13T20:11:34.483344+00:00</updated><content>&lt;doc fingerprint="a4eb1c9974b7e359"&gt;
  &lt;main&gt;
    &lt;p&gt;The last year has been brutal for businesses globally. Taking examples from my home country, the UK, the cost is over £1B and still rising, as well as the loss of at least one life due to cybercrime.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Marks &amp;amp; Spencer lost £300M when ransomware crippled its systems for weeks.&lt;/item&gt;
      &lt;item&gt;The Co-op suffered a related attack, losing over £200M in sales and the customer data of more than 20 million people.&lt;/item&gt;
      &lt;item&gt;Jaguar Land Rover’s assembly lines have been shut down for weeks, haemorrhaging £70M per week and requiring a £1.5B loan secured by the government.&lt;/item&gt;
      &lt;item&gt;Transport for London’s systems were compromised, with the ensuing disruption lasting months, costing £39mn and exposing 5,000 customers’ banking details. Two teenagers are being prosecuted for the attack.&lt;/item&gt;
      &lt;item&gt;Most tragically, a patient at King’s College Hospital died after ransomware delayed critical blood test results. Speaking to friends that were sat in meetings to decide who got blood tests each day, the human toll was evident. Cyberattacks aren’t just about money!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These aren’t isolated incidents - they’re symptoms of a systemic vulnerability in how we build computer systems.&lt;/p&gt;
    &lt;p&gt;According to the Verizon 2025 Data Breach Investigations Report, credential abuse and exploitation of vulnerabilities continue to dominate as attack vectors, accounting for 22% and 20% of breaches respectively. The exploitation of vulnerabilities saw a 34% surge year-over-year, creating what Verizon describes as a “concerning threat landscape”.&lt;/p&gt;
    &lt;p&gt;We’re yet to learn the root causes and attack chains involved in each of the examples above, but many involved ransomware, which frequently uses software exploits as a post-initial-access vector to gain control of target systems and spread across a network.&lt;/p&gt;
    &lt;p&gt;Here’s the kicker: approximately 70% of all software vulnerabilities stem from a single root cause - memory safety issues. This isn’t a new problem. Google, Microsoft, Apple, Mozilla and the Linux Foundation have all reported similar figures for their software over the last two decades. The uncomfortable truth is that current CPUs are fundamentally incapable of preventing these vulnerabilities, and traditional software patches have proven woefully inadequate.&lt;/p&gt;
    &lt;p&gt;Rewriting all the world’s software into memory safe languages, such as C#, Java and Rust, is unviable. While new projects may be adopting Rust over C/C++, and some critical components are being rewritten into safe languages, the scale and depth of the C and C++ ecosystems makes it practically impossible to rewrite all the world’s unsafe software. The risk of introducing other (non-memory-safety) issues during a software rewrite also poses a substantial barrier. Given sufficient software compatibility, it is actually easier to swap the hardware!&lt;/p&gt;
    &lt;p&gt;Two architectural approaches have emerged to tackle this trillion-dollar problem at the hardware level:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CHERI: Capability Hardware Enhanced RISC Instructions - pioneered at University of Cambridge (UK), and&lt;/item&gt;
      &lt;item&gt;OMA: Object Memory Architecture - pioneered at University of Bristol (UK) and now being commercialised by Doubtless Computing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both aim to make memory-unsafe systems safe-by-design but they take different paths to get there. Understanding these differences matters because the choice between them will shape the security and performance characteristics of computing for decades to come.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Memory Safety Crisis&lt;/head&gt;
    &lt;p&gt;Before diving into solutions, it’s worth understanding what we’re solving. When software runs, it constantly allocates and deallocates memory - think of it like booking rooms in a hotel. Memory safety vulnerabilities arise when this process goes wrong. If you stay in the same hotel twice, you shouldn’t be able to access your old room even if you remember the number (use-after-free/ use-after-reallocate). Similarly, you shouldn’t be able to enter a neighbouring room (buffer overflow), or use a room without booking one in the first place (invalid pointer dereference). Software has these same problems with memory allocations (room bookings).&lt;/p&gt;
    &lt;p&gt;These bugs become catastrophic vulnerabilities when attackers exploit them to read sensitive data they shouldn’t access, manipulate critical system variables, or inject malicious code. The underlying architecture of today’s processors - paging-based virtual memory - lacks the granularity needed to enforce security within a single application or process.&lt;/p&gt;
    &lt;p&gt;Memory safety breaks down into three categories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Referential safety ensures pointers genuinely reference allocated memory and can’t be forged. Think of it as ensuring software has a valid booking for a room, ensuring accesses to memory are authorized, and that bookings can’t be faked.&lt;/item&gt;
      &lt;item&gt;Spatial safety prevents accessing memory outside allocated bounds - no going into neighbouring rooms.&lt;/item&gt;
      &lt;item&gt;Temporal safety addresses what happens over time, ensuring memory can’t be accessed after it’s been freed and reallocated. In our hotel analogy, a second stay at the hotel shouldn’t allow you to access your previous room, even if you remember the room number.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Traditional architectures like x86, Arm, and RISC-V rely on coarse-grained page-level protection (typically 4KB or larger pages), which is far too blunt an instrument for modern security needs.&lt;/p&gt;
    &lt;head rend="h2"&gt;CHERI: Capabilities Meet Legacy Systems&lt;/head&gt;
    &lt;p&gt;CHERI, developed over more than a decade by the University of Cambridge and SRI International, extends conventional instruction set architectures with hardware-enforced capabilities. A CHERI capability is a form of fat pointer - it contains not just a memory address but also bounds information, permissions, and validity metadata. Every memory access gets checked against these constraints in hardware, catching violations before they can be exploited.&lt;/p&gt;
    &lt;p&gt;The architecture provides strong referential and spatial safety guarantees. When you have a CHERI capability, you provably have legitimate access to a specific bounded region of memory, and the hardware won’t let you stray outside those bounds. CHERI achieves this while maintaining compatibility with existing paged memory architectures, which is both its greatest strength and a source of limitations.&lt;/p&gt;
    &lt;p&gt;Here’s where it gets interesting: CHERI’s capabilities are large. On a 64-bit system, a CHERI pointer requires 129 bits (including the hidden tag bit) - essentially double the data width of the base architecture. This decision to encode all protection metadata within the pointer itself has profound implications. Every data structure that stores pointers effectively doubles in memory consumption for those fields. Capabilities in memory (stack/heap) must be aligned to natural 128-bit boundaries. Cache lines, which are precious and limited, now hold fewer actual pointers. Memory bandwidth requirements increase because for each pointer you’re moving twice as much data around.&lt;/p&gt;
    &lt;p&gt;CHERI provides hardware-enforced referential and spatial safety but leaves temporal safety to software. You can achieve temporal memory safety with CHERI, but it requires modifying your memory allocator and implementing pointer revocation mechanisms - essentially software to scan memory to find and invalidate stale pointers. This software-based approach to temporal safety remains part of the trusted computing base and requires careful verification. It’s also closely related to software garbage collection.&lt;/p&gt;
    &lt;p&gt;Research has explored various temporal safety mechanisms for CHERI, but they all involve non-trivial software complexity and performance overhead. In theory, hardware acceleration may be possible but is likely to always require software involvement. This is because a CHERI capability covers a range of memory, which may include more than one object. Software allocation and object type information is required to differentiate objects and thus revoke capabilities appropriately.&lt;/p&gt;
    &lt;p&gt;The software ecosystem for CHERI has made impressive progress. Most code recompiles with minimal changes, though the capability width difference can require significant rewrites for certain applications. Additionally, it causes a division in the ISA where load/stores of capabilities must be handled separately from ordinary data. This leads to some complexity in the compiler to detect edge cases where the compiler does not know for certain whether a register or memory slot contains a capability or not. C/C++ code which abuses pointers by treating them as integers, which is uncommon but frequent enough to cause a headache, requires some effort to address.&lt;/p&gt;
    &lt;p&gt;Arm’s Morello project, which implemented CHERI on a modified Neoverse N1 core, revealed performance challenges that have pushed commercial CHERI efforts toward smaller embedded processors for the time being. Notably, Arm declined to join the CHERI Alliance, instead indicating they will take a step back from new work on Morello and wait to see if CHERI gains the long-sought commercial traction.&lt;/p&gt;
    &lt;head rend="h2"&gt;OMA: Rethinking Memory From the Ground Up&lt;/head&gt;
    &lt;p&gt;Doubtless Computing’s Object Memory Architecture takes a fundamentally different approach. Rather than extending paged memory, OMA implements object-based memory management directly in hardware. Every allocation becomes a first-class hardware object with its own identity, bounds, and metadata maintained by the processor itself.&lt;/p&gt;
    &lt;p&gt;This architectural choice enables several key advantages. OMA pointers are leaner - 65 bits on a 64-bit architecture, including the hidden tag bit. Rather than carrying all metadata with every pointer, OMA stores object information centrally in hardware-managed directories. This reduces memory bandwidth requirements and means that multiple pointers to the same object don’t duplicate metadata. The hardware maintains a complete understanding of object relationships and lifecycles, enabling optimizations that software-only approaches can’t match.&lt;/p&gt;
    &lt;p&gt;A critical differentiator is temporal safety. OMA implements garbage collection in hardware, scanning for and reclaiming unreachable objects in real-time as part of the processor’s normal operation. This isn’t the same as software garbage collection - it’s parallel, highly optimized, and doesn’t block program execution. By managing object lifecycles in hardware, OMA provides hardware-guaranteed temporal safety alongside referential and spatial protections, completing the trinity of memory safety properties.&lt;/p&gt;
    &lt;p&gt;It would be tempting to say that memory safety is solved by using a managed language like Java, JavaScript, Swift or Python. Unfortunately, this doesn’t hold up in practice. Managed language runtimes, as well as many supporting libraries, are written in C/C++ and suffer memory safety issues just as much as any other C/C++ code. The operating systems and hypervisors are also exposed to these languages, offering yet another attack surface. This leaves managed language apps vulnerable. Memory safe languages, including both Rust and managed languages, are a distinct improvement over traditional C and C++, but only hardware can provide the safety guarantees we need in today’s systems.&lt;/p&gt;
    &lt;p&gt;For managed languages like Java, JavaScript, Python, C# and Go, the OMA architecture delivers dramatic performance improvements. Doubtless Computing’s analysis of CPython 3.12 reveals that 32-44% of instructions are spent on memory management operations - allocation, deallocation, reference counting, and garbage collection. Moving these operations into parallel hardware execution, along with microarchitectural optimisations derived from hardware’s new understanding of the structure of data in memory, yields 2-5x speedups for managed language applications. Even C/C++ applications see 1.2-2x improvements as the hardware optimizes memory management functions and eliminates per-object metadata from cache.&lt;/p&gt;
    &lt;p&gt;The architecture maintains full source code compatibility for managed languages - all changes are confined to the runtime. For C/C++, the story is much the same as with CHERI: recompilation with modified standard libraries and a modified compiler, such as LLVM or GCC. Maintaining the pointer width the same as the data width, and the same alignment requirements, avoids the ISA-level split for handling pointers, which simplifies the compiler and improves compatibility with legacy C/C++ code. This compatibility approach differs from CHERI’s and aligns with OMA’s target market: server-class and application processors, where managed languages dominate.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fundamental Trade-offs: Where the Architectures Diverge&lt;/head&gt;
    &lt;p&gt;The philosophical differences between CHERI and OMA create distinct trade-off profiles. CHERI carries all metadata with pointers, enabling incremental adoption where different parts of a program can use capabilities independently. OMA’s centralized metadata requires the hardware to maintain a consistent view of all objects but enables more aggressive optimization. CHERI works within the existing paged memory model, simplifying system software migration. OMA introduces a new memory model that requires deeper changes but delivers performance gains that paged architectures can’t match.&lt;/p&gt;
    &lt;p&gt;These differences manifest in pointer width - CHERI’s 129-bit capabilities versus OMA’s 65-bit pointers. While both exceed the base address width, the doubling effect in CHERI has more severe implications for data structure layouts, cache efficiency, and memory bandwidth. Research on CHERI implementations has shown there is a long road ahead to achieve performance parity for managed languages. In the meantime, OMA offers a shorter path with substantial speedups rather than equal performance.&lt;/p&gt;
    &lt;p&gt;Temporal safety represents perhaps the most significant divergence in security. CHERI’s software-based pointer revocation requires explicit memory scanning and manipulation, adding complexity to the trusted computing base and verification burden. OMA’s hardware garbage collection happens transparently and continuously, providing stronger guarantees with less software complexity. This matters enormously for total cost of ownership - every line of security-critical software that doesn’t need to be written, verified, and maintained is a win.&lt;/p&gt;
    &lt;p&gt;The instruction set philosophies differ too. CHERI historically opts for ISA changes beyond pure memory safety to achieve its security goals, which can complicate adoption. OMA has historically prioritized backward compatibility, though this is adaptable based on market requirements. The consensus in the industry is that software compatibility presents the primary barrier to new processor designs, which favours architectures that minimize disruption.&lt;/p&gt;
    &lt;head rend="h2"&gt;Industrial Relevance and Market Fit&lt;/head&gt;
    &lt;p&gt;CHERI and OMA target fundamentally different computing environments, which is why calling them competitors misses the point. They’re complementary solutions to a shared problem, each optimized for distinct use cases.&lt;/p&gt;
    &lt;p&gt;CHERI finds its natural home in embedded systems and microcontrollers. These environments predominantly use C, C++, or Rust with restricted or no dynamic memory allocation. The code bases are smaller and more amenable to the verification required to ensure CHERI capabilities are used correctly. The memory overhead from wider pointers, while still present, matters less in resource-constrained designs that carefully manage every allocation. Four companies - SCI Semiconductor, Codasip, lowRISC, and Secqai - are actively commercializing CHERI for embedded applications. SCI’s ICENI family of CHERIoT microcontrollers, built on Microsoft’s open-source CHERIoT-Ibex core, targets the IoT and operational technology markets. Codasip offers CHERI-enabled RISC-V IP cores for custom processor designs. lowRISC’s Sonata platform provides an open-source FPGA-based development environment for CHERIoT research and prototyping.&lt;/p&gt;
    &lt;p&gt;Arm’s experience with CHERI tells an important story about scaling limitations. The Morello project, which implemented CHERI on a modified Neoverse N1 server-class core, yielded results that Arm appears to have found unsatisfactory. There has been no apparent follow-up on the substantial initial investment made into the Arm Morello designs. This assessment seems to reflect the performance challenges that CHERI faces in larger systems.&lt;/p&gt;
    &lt;p&gt;OMA’s sweet spot sits at the opposite end of the spectrum. Application-class and server-class processors running managed languages benefit enormously from hardware-accelerated memory management. Python, Java, JavaScript, C#, and Go all share similar memory models that align naturally with OMA’s object-based approach. These environments already use garbage collection extensively, so moving that functionality into hardware removes overhead, rather than adding it as it would in embedded systems. The performance gains - up to 5x for managed languages - become transformational for data centre workloads where every percentage point of efficiency translates to millions in operating costs.&lt;/p&gt;
    &lt;p&gt;The market dynamics favour different adoption paths. CHERI benefits from strong government backing, particularly from the now-ended UK’s Digital Security by Design programme and recognition from the US White House and NSA. This institutional support hopes to accelerate adoption in defence and critical infrastructure applications. CHERI’s open-source foundation through the CHERI Alliance creates a broad ecosystem but limits opportunities for proprietary differentiation.&lt;/p&gt;
    &lt;p&gt;OMA’s proprietary nature and performance advantages position it for commercial data centre deployment. The technology directly addresses the performance problems that hindered CHERI at scale. While OMA lacks CHERI’s first-mover advantage and government momentum, it offers compelling value for cloud providers and enterprises running managed language workloads. The economic argument is straightforward: if you can eliminate 70% of vulnerabilities while quintupling performance for your Python services, the return on investment is measured in weeks from deployment, rather than years.&lt;/p&gt;
    &lt;p&gt;OMA’s proprietary technology makes it attractive for investment as it can be patented. However, CHERI’s openness makes it possible for independent security teams to verify the safety of the architecture. Open implementations of CHERI processors also enables those designs to be independently verified. Doubtless Computing will need to make its ISA public, which is inevitable anyway for a new CPU as customers will require it. Doubtless will also need to offer a public platform for independent researchers to build confidence in the security claims.&lt;/p&gt;
    &lt;head rend="h2"&gt;The CHERI Ecosystem: Who’s Building What&lt;/head&gt;
    &lt;p&gt;The CHERI Alliance, formally launched in 2024, coordinates standardization and adoption efforts across industry and academia. Founding members include the FreeBSD Foundation, Capabilities Limited, SCI Semiconductor, Codasip, lowRISC, and the University of Cambridge. Google’s participation as a founding member signals serious industry interest, though notably Arm is not a member.&lt;/p&gt;
    &lt;p&gt;SCI Semiconductor, based in Cambridge, leads commercialization of Microsoft’s open-source CHERIoT Ibex implementation for embedded systems. Their ICENI family of processors targets microcontroller applications in automotive, industrial control, defence, and aerospace. The company has secured strategic distribution through EPS Global, which specializes in automotive tier-one suppliers and contract manufacturers. SCI’s early access program, in collaboration with lowRISC, allows select partners to begin development on lowRISC’s FPGA-based Sonata platform with guaranteed migration paths to production silicon.&lt;/p&gt;
    &lt;p&gt;Codasip, a RISC-V processor IP vendor, offers the X730 - a CHERI-enabled 64-bit application-class core based on their A730 design. Their “Custom Compute” methodology allows customers to license CHERI-enhanced cores or customize them further using Codasip Studio. The company has donated a CHERI SDK built on open-source tools to the CHERI Alliance, making it freely available for anyone implementing CHERI on RISC-V. Codasip is also developing Linux kernel support for RISC-V CHERI, which will be crucial for broader adoption.&lt;/p&gt;
    &lt;p&gt;lowRISC, a not-for-profit organization spun out of Cambridge University, maintains the Sonata evaluation platform and leads the UK-government-funded Sunburst Project. Sonata provides a complete FPGA-based development environment for CHERIoT, enabling software development and hardware experimentation before silicon is available. The Sunburst Project’s recent expansion to include SCI Semiconductor aims to validate CHERIoT designs through commercial tapeout on GlobalFoundries’ 22nm process, with all project deliverables remaining open-source.&lt;/p&gt;
    &lt;p&gt;zeroRISC is a startup and partner in the OpenTitan project administered by lowRISC. Their goal is to commercialise the OpenTitan silicon IP through their Integrity Management Platform.&lt;/p&gt;
    &lt;p&gt;Microsoft’s role deserves special mention. Microsoft Research developed CHERIoT-Ibex, an open-source RISC-V core optimized for embedded systems. They’ve made this core freely available and co-maintain the CHERIoT Platform repository with SCI Semiconductor. David Weston, Microsoft’s VP of Enterprise and OS Security, has publicly endorsed SCI’s commercialization efforts, stating that CHERI represents a “promising technology that can be used to enhance computer security.” This corporate backing from a major software vendor adds credibility to the embedded CHERI ecosystem.&lt;/p&gt;
    &lt;p&gt;The UK government’s support through the now-ended Digital Security by Design programme and UKRI funding has been instrumental in advancing CHERI. The programme provided ~£190 million in research funding over five years and continues to support development through initiatives like Sunburst. This institutional backing, combined with endorsements from the US White House and NSA, positions CHERI advantageously for government and defence procurements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;CHERI and OMA represent two responses to the memory safety crisis, each with distinct strengths that make them suited to different computing environments. The notion that one must “win” while the other “loses” misunderstands the landscape - the computing world is large enough, and varied enough, that multiple approaches can and should coexist. Cybersecurity principles also demand diversity of solutions.&lt;/p&gt;
    &lt;p&gt;CHERI’s compatibility with existing paged memory architectures and incremental deployment model make it an excellent fit for embedded systems where code bases are manageable, languages are predominantly C/C++/Rust, and the verification burden is acceptable. The active CHERI ecosystem, backed by government support and open-source collaboration, has created momentum that shouldn’t be underestimated. For IoT devices, industrial control systems, and safety-critical embedded applications, CHERI offers a practical path to hardware-enforced memory safety that companies can adopt today.&lt;/p&gt;
    &lt;p&gt;OMA’s object-based architecture and integrated hardware garbage collection (IHGC) deliver transformational performance for managed language workloads. By tackling temporal safety in hardware alongside referential and spatial protections, OMA provides more complete memory safety with less software complexity. The performance gains - up to 5x for Python, Java, JavaScript, C#, and Go - directly address the scalability problems that have limited CHERI in larger systems. For data centres, cloud infrastructure, and application servers where managed languages dominate, OMA presents compelling advantages.&lt;/p&gt;
    &lt;p&gt;Both architectures eliminate memory safety vulnerabilities. The formal guarantees that CHERI can provide are a subset of what OMA delivers, since OMA includes hardware-enforced temporal safety. However, CHERI’s earlier start and ecosystem momentum matter significantly in technology adoption. The question isn’t which architecture is “better” in absolute terms but rather which is more appropriate for specific use cases and deployment contexts.&lt;/p&gt;
    &lt;p&gt;Looking ahead, memory safety will increasingly become a non-negotiable requirement. The UK National Cyber Security Centre, US White House, and NSA have all called for fundamental changes in how we build secure systems. The attacks on Marks &amp;amp; Spencer, Co-op, Jaguar Land Rover, the NHS, Transport for London, and many others, demonstrate that our current approach isn’t working. Software-only solutions like Rust, while valuable, face adoption barriers that make them insufficient on their own. Hardware-based memory safety, whether through CHERI, OMA, or future approaches we haven’t yet invented, represents the most practical path to eliminating this class of vulnerability at scale.&lt;/p&gt;
    &lt;p&gt;The semiconductor industry moves slowly, with design cycles measured in years and deployment timelines measured in decades. Today’s architectural decisions will shape computing security through 2040 and beyond. The good news is that we now have proven approaches to memory safety that work in real hardware. CHERI has demonstrated its viability in embedded systems. OMA has shown it can deliver both security and performance for managed languages with a hardware prototype on AWS Cloud FPGAs supporting CPython 3.12 and Jupyter Notebooks. The challenge now isn’t technical feasibility - it’s economic deployment and ecosystem coordination.&lt;/p&gt;
    &lt;p&gt;For embedded designers, CHERI offers immediate benefits with manageable overhead. For cloud and data centre operators, OMA promises to eliminate vulnerabilities while dramatically improving performance. The fundamental insight is that both approaches work by making the right choices for their target markets. We don’t need to pick one winner. We need both, deployed where each makes the most sense, steadily displacing the insecure architectures that enabled the attacks we’ve seen this year. The trillion-dollar memory safety problem is solvable - and the will to deploy the solutions we’ve built is growing as organisations can no longer afford the risk of being vulnerable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ednutting.com/2025/10/05/cheri-vs-oma.html"/><published>2025-10-13T10:05:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567153</id><title>The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2025</title><updated>2025-10-13T20:11:34.249890+00:00</updated><content>&lt;doc fingerprint="d53d327d895121e6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2025&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2025 was awarded "for having explained innovation-driven economic growth" with one half to Joel Mokyr "for having identified the prerequisites for sustained growth through technological progress" and the other half jointly to Philippe Aghion and Peter Howitt "for the theory of sustained growth through creative destruction"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Nobel Prizes and laureates&lt;/head&gt;
    &lt;p&gt;Six prizes were awarded for achievements that have conferred the greatest benefit to humankind. The 14 laureates' work and discoveries range from quantum tunnelling to promoting democratic rights.&lt;/p&gt;
    &lt;p&gt;See them all presented here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Explore prizes and laureates&lt;/head&gt;
    &lt;p&gt; Look for popular awards and laureates in different fields, and discover the history of the Nobel Prize. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/economic-sciences/2025/summary/"/><published>2025-10-13T11:23:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567770</id><title>Show HN: SQLite Online – 11 years of solo development, 11K daily users</title><updated>2025-10-13T20:11:34.002565+00:00</updated><content>&lt;doc fingerprint="5120987566fd4fbd"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Chart for Data Science&lt;/head&gt;
    &lt;code&gt;-- Change first word "SELECT" to "QLINE-SELECT"&lt;/code&gt;
    &lt;quote&gt;SELECT QLINE-SELECT&lt;/quote&gt;
    &lt;code&gt;â&lt;/code&gt;
    &lt;code&gt;-- Axis X:&lt;/code&gt;
    &lt;code&gt;-- X - column name, axis: x1, x2, ..xn Value: Number&lt;/code&gt;
    &lt;code&gt;-- L - column name, axis: l Value: Text&lt;/code&gt;
    &lt;code&gt;-- T - column name, axis: t Value: UnixTime Number&lt;/code&gt;
    &lt;code&gt;-- Axis Y:&lt;/code&gt;
    &lt;code&gt;-- Y - column name, axis: y1, y2, ..yn Value: Number&lt;/code&gt;
    &lt;code&gt;-- Y - color line: y_cFF00FF (HEX6)&lt;/code&gt;
    &lt;code&gt;-- Option:&lt;/code&gt;
    &lt;code&gt;-- C - color point: c  Value: FF00FF (HEX6)&lt;/code&gt;
    &lt;code&gt;-- V - radius point: v  Value: Number&lt;/code&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QLINE-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QAREA-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QBAR-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QPIE-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QBUBBLE-SELECT example&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sqliteonline.com/"/><published>2025-10-13T12:46:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568613</id><title>Smartphones and being present</title><updated>2025-10-13T20:11:33.579098+00:00</updated><content>&lt;doc fingerprint="3411991d2ac390d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Smartphones and being present&lt;/head&gt;
    &lt;p&gt;I read an article yesterday, stating that on average, people spend 4 hours and 37 minutes on their phones per day1, with South Africans coming in fourth highest in the world at a whopping 5 hours and 11 minutes2.&lt;/p&gt;
    &lt;p&gt;This figure seems really high to me. If we assume people sleep roughly 8 hours per day, that means that one third of their day is spent on their phones. If we also assume people work 8 hours per day (ignoring the fact that they may be using their phones during work hours), that suggests that people spend over half of their free time (and up to 65% of it) glued to their screens.&lt;/p&gt;
    &lt;p&gt;I never wanted to carry the internet around in my pocket. It's too distracting and pulls me out of the present moment, fracturing my attention. I've tried switching to old-school black and white phones before, but always begrudgingly returned to using a smartphone due to the utility of it. The problem, however, is that it comes with too many attention sinks tucked in alongside the useful tools.&lt;/p&gt;
    &lt;p&gt;I care about living an intentional and meaningful life, nurturing relationships, having nuanced conversations, and enjoying the world around me. I don't want to spend this limited time I have on earth watching short form video and getting into arguments on Twitter.&lt;/p&gt;
    &lt;p&gt;This is what I enjoy. Picture taken yesterday in Scarborough, South Africa.&lt;/p&gt;
    &lt;p&gt;I've written at length about how I manage my digital consumption, from turning off notifications to forgoing social media entirely. The underlying premise here is that if you're trying to lose weight, you shouldn't carry cookies around in your pockets. And my phone is the bag of cookies in this metaphor.&lt;/p&gt;
    &lt;p&gt;We're wired to seek out distraction, novel information, and entertainment, and avoid boredom at all costs. But boredom is where creativity and self-reflection do their best work. It's why "all the best ideas come when you're in the shower"—we don't usually take our phones with us into the shower (yet).&lt;/p&gt;
    &lt;p&gt;According to Screen Time on my iPhone, on average I spend 30 minutes per day on it, which I think is reasonable, especially considering the most-used apps are by-and-large utility apps like banking and messages. This isn't because I have more self-control than other people. I don't think I do. It's because I know myself, and have set up my digital life to be a positive force, and not an uninspired time-sink.&lt;/p&gt;
    &lt;p&gt;There are many apps and systems to incentivise better relationships with our phones, mostly based around time limits. But these are flawed in three ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I'm an adult, I know how to circumvent these limits, and I will if motivation is low.&lt;/item&gt;
      &lt;item&gt;Time limits don't affect the underlying addiction. You don't quit smoking by only smoking certain hours of the day.&lt;/item&gt;
      &lt;item&gt;The companies that build these apps have tens of thousands of really smart people (and billions of dollars) trying to get me hooked and keep me engaged. The only way to win this game isn't by trying to beat them (I certainly can't), but by not playing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The only way I've found to have a good relationship with my phone is to make it as uninteresting as possible. The first way is to not have recommendation media (think Instagram, TikTok, and all the rest). I'm pro deleting these accounts completely, because it's really easy to re-download the apps on a whim, or visit them in-browser. However some people have found that having them on a dedicated device works by isolating those activities. Something like a tablet at home that is "the only place you're allowed to use Instagram". I can't comment too much on this route, but it seems reasonable.&lt;/p&gt;
    &lt;p&gt;My biggest time sink over the past few years has been YouTube. The algorithm knew me too well and would recommend video after engaging, but ultimately useless video. I could easily burn an entire evening watching absolute junk—leaving me feeling like I'd just wasted what could have otherwise been a beautiful sunset or a tasty home-cooked lasagne. However, at the beginning of this year I learnt that you can turn off your YouTube watch history entirely, which means no recommendations. Here's what my YouTube home screen now looks like:&lt;/p&gt;
    &lt;p&gt;Without the recommendations I very quickly run out of things to watch from the channels I'm subscribed to. It's completely changed my relationship with YouTube since I only watch the videos I actually want to watch, and none of the attention traps. You can turn off your YouTube watch history here, and auto delete your other Google history (like historic searches and navigation) here, which I think is just good practice.&lt;/p&gt;
    &lt;p&gt;I also used my adblocker, AdGuard on Safari which has a useful "block element" feature, to block the recommended videos on the right of YouTube videos. I use this feature to hide shorts as well, since I have no interest in watching them either, and YouTube intentionally makes them impossible to remove. If you're interested in a similar setup, here are the selectors I use to block those elements:&lt;/p&gt;
    &lt;code&gt;youtube.com###items &amp;gt; ytd-item-section-renderer.style-scope.ytd-watch-next-secondary-results-renderer:last-child
youtube.com###sections
youtube.com##[is-shorts]
youtube.com###secondary
&lt;/code&gt;
    &lt;p&gt;The only media that I do sometimes consume on my phone are my RSS feeds, but it's something I'm completely comfortable with since it's explicitly opt-in by design and low volume.&lt;/p&gt;
    &lt;p&gt;While I still have the twitch to check my phone when I'm waiting for a coffee, or in-between activities—because my brain's reward system has been trained to do this—I'm now rewarded with nothing. Over time, I find myself checking my phone less and less. Sometimes I notice the urge, and just let it go, instead focusing on the here and now.&lt;/p&gt;
    &lt;p&gt;I think that while the attention-span-degrading effects of recommendation media are getting most of the headlines, what isn't spoken about as much is the sheer number of hours lost globally to our phones (3.8 million years per day, according to my back-of-the-napkin-math). And while people may argue that this could involve productive work or enjoyable leisure, I suspect that the vast (vast!) majority of that time is short-form entertainment.&lt;/p&gt;
    &lt;p&gt;My solution may sound overkill to many people, but I can say with absolute certainty that it has turned me into a more present, less distracted, and more optimistic person. I have much more time to spend in nature, with friends, or on my hobbies and projects. I can't imagine trading it in for a tiny screen, ever.&lt;/p&gt;
    &lt;p&gt;Give it a try.&lt;/p&gt;
    &lt;p&gt;Happily on the beach for sunset.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://herman.bearblog.dev/being-present/"/><published>2025-10-13T14:20:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568708</id><title>Roger Dean – His legendary artwork in gaming history (Psygnosis)</title><updated>2025-10-13T20:11:31.856245+00:00</updated><content>&lt;doc fingerprint="26228153ffa48fbf"&gt;
  &lt;main&gt;
    &lt;p&gt;We spoke with the man behind the Psygnosis logo – and so much more!&lt;/p&gt;
    &lt;p&gt;English artist Roger Dean is a living legend, and his work in the video game industry represent just a small chapter in his extraordinary career. Dean was born in 1944 in Kent, but spent much of his childhood in Greece and Hong Kong. His father was an engineer in the British Army, so the family had to move wherever his work took him. In particular, the years he lived in Hong Kong would later become an important source of inspiration for him.&lt;/p&gt;
    &lt;p&gt;After returning to England, he studied art, architecture, and furniture design, and it was actually in the latter field that he had his first breakthrough. He designed what he called the Sea Urchin Chair, a predecessor to the famous bean bag chair.&lt;/p&gt;
    &lt;p&gt;But it was as a visual artist that he truly made his mark. In 1968, he created his first album cover, for the British rock band The Gun, and later became heavily involved with the prog rock bands Yes and Asia. His cover for Asia’s debut album was voted the second-best album cover of all time by readers of Rolling Stone Magazine in 1982, and it was also Dean who designed the very first logo for Richard Branson’s newly established Virgin Records.&lt;/p&gt;
    &lt;p&gt;It was in the 1980s that Roger Dean first became involved in the video game industry, where he was not only responsible for a number of iconic game covers, but also some of gaming’s most recognizable logos.&lt;/p&gt;
    &lt;p&gt;When we reached out to Dean to ask if he would like to do an interview with us, we honestly didn’t expect him to respond. And if he did, we assumed it would be just a small handful of questions answered by e-mail. But not only was he interested in talking with us, we ended up having a long and pleasant video call, during which he happily showed us his work and chatted about a variety of topics.&lt;/p&gt;
    &lt;p&gt;Note that our main focus was on Dean’s work with games, so if you’d like to read more about everything else he’s done, you could, for example, check out this profile interview at We Love Vinyl. You should also visit his website.&lt;/p&gt;
    &lt;p&gt;In this article, we present an edited version of that conversation, supplemented with a bit of extra information about the topics we discuss.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Black Onyx and Psygnosis&lt;/head&gt;
    &lt;p&gt;We start in the mid eighties, which is when Dean first gets involved in the games industry. His first cover artwork was created for The Black Onyx, a game you’ve probably never heard of unless you’re very interested in the history of gaming. Because even though the producer and designer of that game was an American – Henk Rogers, who we’ll talk more about later – the game was only released in Japan. While it isn’t a famous game, it is an early example of a role-playing game developed in Japan, and it would help influence how Japanese developers approached the genre.&lt;/p&gt;
    &lt;p&gt;For European gamers, it’s probably Dean’s other contract that proved the most memorable. When the British publisher Psygnosis was formed in 1984, they reached out to Roger Dean to create their logo. This would mark the start of a long lasting relationship which would shape much of the visual identity of the well remembered publisher.&lt;/p&gt;
    &lt;p&gt;JF: How did you get involved with the games industry? I know that your first work was on The Black Onyx …&lt;/p&gt;
    &lt;p&gt;RD: That’s right! Well, Henk Rogers, who now publishes Tetris, sought me out – though this was before he got the rights to Tetris. He was aware of my work in music. So he knew my music and my books, and of course my album covers. He contacted me through my publishing company, and came to visit.&lt;/p&gt;
    &lt;p&gt;JF: But that game only came out in Japan?&lt;/p&gt;
    &lt;p&gt;RD: That’s correct, yes.&lt;/p&gt;
    &lt;p&gt;But about the same time I met Henk, I also met Jonathan Ellis of Psygnosis. I had met with Imagine Software before – two of the people from Imagine formed Psygnosis with Jonathan Ellis – and I did a whole bunch of Psygnosis stuff.&lt;/p&gt;
    &lt;p&gt;JF: They contacted you? They’d seen your artwork already?&lt;/p&gt;
    &lt;p&gt;RD: Yes, they contacted me. They’d certainly seen the books. We sold enormous amounts of posters and books back then. During the seventies, my posters, books, calendars etcetera sold about 65 million copies, and by the mid eighties we’d passed a hundred million sales. So it was out there, you know. Much more than today.&lt;/p&gt;
    &lt;p&gt;JF: The owl logo, was that your idea?&lt;/p&gt;
    &lt;p&gt;RD: Yeah, sure. That was my job. They gave me an idea about the kind of name that they wanted, so even the name was partly mine. Both the name and the owl… they were very clear about what they wanted, but they didn’t know visually or even how to put the words together. So the word came to me in the end, and the visuals.&lt;/p&gt;
    &lt;p&gt;JF: Do you remember how you came up with the idea of putting an owl in there?&lt;/p&gt;
    &lt;p&gt;RD: What can I say? *laughs*&lt;/p&gt;
    &lt;p&gt;JF: Did you see or play the games before you did the covers?&lt;/p&gt;
    &lt;p&gt;RD: That’s not how it worked. It was the same with the music. Very often I had to finish the covers long before the games were done, and the content of the games was as much influenced by the cover as the cover was by the content.&lt;/p&gt;
    &lt;p&gt;In fact, I would say that the cover was influenced by them describing what they wanted to do for the game, and then me visualizing it. And then they would reproduce that to some degree themselves in the games.&lt;/p&gt;
    &lt;p&gt;HAJ: So they just said: This is what we are thinking, and then you started working?&lt;/p&gt;
    &lt;p&gt;RD: They described the game, usually in much more extravagant terms than what the reality was. They would say they were making an interective movie, and I’d say «wow!». And when I saw it, there would be these little matchstick figures…&lt;/p&gt;
    &lt;p&gt;JF: What was the process like?&lt;/p&gt;
    &lt;p&gt;RD: Well, it was very different from the work I was used to doing, so from that point of view it was good fun for me. Like going in another direction, I enjoyed that a lot. Especially the designs I did for The Shadow of the Beast, they were very different from any album covers I’d made.&lt;/p&gt;
    &lt;p&gt;JF: Did you ever work on actual game [design] for them?&lt;/p&gt;
    &lt;p&gt;RD: No, I remember when we did a game called Barbarian. The developers got very excited and asked me what I thought of their dragon. And I said, «what dragon?» Because I’d put a dragon on the box, and they’d then put my dragon in the game. And I said, «oh, you have to show me.» And they said, «it’s at the end of the first level, you haven’t gotten beyond the first level?» And I said «noo… I haven’t even started the first level!»&lt;/p&gt;
    &lt;p&gt;JF: Did they ever come back to you and ask you to redo something?&lt;/p&gt;
    &lt;p&gt;RD: Not really. Maybe on one occation only. I can’t even remember what it was, but I did the lettering for it, and I found them another artist. In the end, that was a turning point for me, because they were already producing more games than I could possibly manage. So I would end up doing logos, but getting other artists to do the art.&lt;/p&gt;
    &lt;p&gt;JF: Yeah, I see some of your covers are listed as a collaboration with you and Tim White.&lt;/p&gt;
    &lt;p&gt;RD: Tim White, yes. There was a number of artists in it. Chris Voss, I think. Peter Jones, maybe. Yeah. There was a few other artists who did covers.&lt;/p&gt;
    &lt;p&gt;JF: So you did the logos, and they did the paintings?&lt;/p&gt;
    &lt;p&gt;RD: They did the painting, yes.&lt;/p&gt;
    &lt;p&gt;JF: Was there a community of artists who did covers?&lt;/p&gt;
    &lt;p&gt;RD: Well, I knew the artist because I had published the books, and that was in very recent history. You know, within ten years of when we had the publishing company.&lt;/p&gt;
    &lt;p&gt;JF: I love all the covers you did for Psygnosis. Unfortunately, I don’t own so many, only Terrorpods I think. You did the logo there, I think?&lt;/p&gt;
    &lt;p&gt;RD: Terrorpods is interesting because I did the drawings for that. The painting was done by Tim White, but it was my drawing. I drew the machine.&lt;/p&gt;
    &lt;p&gt;JF: It’s one of my favorite covers.&lt;/p&gt;
    &lt;p&gt;RD: Yeah, it’s pretty good, I like it.&lt;/p&gt;
    &lt;p&gt;JF: There was also some re-use of older album covers. Did you help facilitate that?&lt;/p&gt;
    &lt;p&gt;RD: No, it’s the other way around. There were game ideas that became album covers. So game covers that became albums. Barbarian without the barbarian became a cover for a solo album by Steve Howe [from Yes], for instance.&lt;/p&gt;
    &lt;p&gt;JF: Ah, I see.&lt;/p&gt;
    &lt;p&gt;RD: The rule that I have is that there can be no confusion. So I never use a painting for one album cover on another. That would not be good. But if it was a totally different thing the rules and the licensing arrangements allowed me to do that.&lt;/p&gt;
    &lt;p&gt;JF: So you made sure of that going into the projects?&lt;/p&gt;
    &lt;p&gt;RD: From the very beginning, yes. I kept all the rights.&lt;/p&gt;
    &lt;head rend="h2"&gt;The evolution of game covers&lt;/head&gt;
    &lt;p&gt;We asked Roger Dean whether he ever received the finished game boxes he had worked on, and not only did get the boxes – he still has them! He then suggested showing us a few, and returned shortly afterward with the boxes for Shadow of the Beast I and II. Two large cardboard boxes with cover art that is both stunning and unique.&lt;/p&gt;
    &lt;p&gt;This led to a conversation about how game boxes have evolved over the years, and Dean’s thoughts on the subject.&lt;/p&gt;
    &lt;p&gt;JF: Where did that [SotB] style come from?&lt;/p&gt;
    &lt;p&gt;RD: I was very interested in mechanical things. So when I was a student, a lot of my work was about ideas for machinery. So Shadow of the Beast was natural, a very easy connection, and it was good fun.&lt;/p&gt;
    &lt;p&gt;JF: Those boxes are really unusual.&lt;/p&gt;
    &lt;p&gt;RD: Well, of course. There are no boxes at all today, are there.&lt;/p&gt;
    &lt;p&gt;JF: No… I was thinking about that because those big old boxes, they were almost like the the old records, compared to what came later…&lt;/p&gt;
    &lt;p&gt;RD: Yeah, and these are floppy disks inside. One also besides the floppy disks, I think it had a cassette, and a t-shirt. So it, so it had a book of instructions, floppy disk, cassette and t-shirt.&lt;/p&gt;
    &lt;p&gt;JF: Yeah. You don’t get that today.&lt;/p&gt;
    &lt;p&gt;RD: No. And the t-shirt was kind of weird because you couldn’t choose the size, right?&lt;/p&gt;
    &lt;p&gt;JF: Oh, well, it could be a gift for someone, if it didn’t fit…&lt;/p&gt;
    &lt;p&gt;RD: It would have had to be. Yeah. *laughs*&lt;/p&gt;
    &lt;p&gt;JF: But what I was getting at … I assume you’ve seen how game boxes just shrunk and became smaller and smaller, and now we don’t even have them. How do you feel about that?&lt;/p&gt;
    &lt;p&gt;RD: Well, I don’t know. It’s the same problem, of course, with music. And what happened was that for a very short period of time, music made the perfect gift. You know, a 12 inch vinyl, it looked like and felt like something you would both like to give and receive. And that concept of the gift was really strong.&lt;/p&gt;
    &lt;p&gt;You know, back when the vinyl was normal, getting a record for your birthday or Christmas was a big deal. And a big deal to give because they were relatively expensive. They weren’t even affordable by young people until quite a few years after they were invented. But it was a big deal, that gift idea. When it first went to CD, the record companies destroyed the idea of a gift because they stripped out a lot of what made it special.&lt;/p&gt;
    &lt;p&gt;I mean, one of Yes’s biggest albums in terms of its impact and iconography was Close to the Edge. And when it came out in vinyl, the cover had the new logo, but the painting was inside. When it came out on CD, there was no painting, it was just a folded sheet of paper inside. It was black and white, no image. And I thought, you know, this is treating the customers with so little respect. It was just amazing.&lt;/p&gt;
    &lt;p&gt;And as the industry went into decline, shortly after that, you could see, there was no respect. No respect for the music, for the bands and for the fans. It was their own fault that they were in trouble. The only country where the quality was persistent was Japan. Their CDs were always beautiful. In the West? They were rubbish.&lt;/p&gt;
    &lt;p&gt;JF: Would you say the same was true for games?&lt;/p&gt;
    &lt;p&gt;RD: It wasn’t really the size, it was the complete lack of care that really troubled me enormously. I quite like the small versions [of records] that came out in Japan because they were like a kind of bonsai, but everything was there. All the art was there. In fact, Japan had the bonus of having the translation, so you got more than the basic thing. It was good.&lt;/p&gt;
    &lt;p&gt;HAJ: Do you follow modern video game art?&lt;/p&gt;
    &lt;p&gt;RD: No, I don’t really. People show me stuff and I go, «wow, that’s pretty cool.» But I don’t go out of my way to follow it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tetris, and The Black Onyx part two&lt;/head&gt;
    &lt;p&gt;Few games – if any – are more famous than Tetris. We won’t go into the history of this addictive puzzle game; you’ve probably heard it before. But it was the aforementioned Henk Rogers who ended up securing the rights to the game, and he also founded The Tetris Company together with the original Tetris creator Alexey Pajitnov. When the time came to create an official Tetris logo in 1997, Roger Dean was the one they contacted.&lt;/p&gt;
    &lt;p&gt;This, however, was not the only collaboration between Dean and Rogers. The other was an ambitious sequel to The Black Onyx that was sadly cancelled before completion. Based on what Dean tells us below, it sounds like a really ambitious project.&lt;/p&gt;
    &lt;p&gt;JF: You also worked on Tetris.&lt;/p&gt;
    &lt;p&gt;RD: I did the Tetris logo. That was just a word, so much less interesting than the Psygnosis logo. But Tetris is a very interesting game…&lt;/p&gt;
    &lt;p&gt;JF: You knew Henk Rogers, did he always want you to do the logo?&lt;/p&gt;
    &lt;p&gt;RD: That was more than 25 years ago. Yeah, he he wanted me to do it because there were hundreds of versions out there. Not done by him, but by the various companies that’d license it. And people did pirate versions. Everyone had their own version of Tetris. So he wanted only one version of the logo. If someone had a license, they had to use the authorized logo. It was an attempt to put discipline into it, really.&lt;/p&gt;
    &lt;p&gt;And then two or three years ago he handed over the management of Tetris to his daughter, Maya, and she changed the logo again. But it’s the same rules, one logo. Although it’s slightly different to mine.&lt;/p&gt;
    &lt;p&gt;JF: And The Black Onyx?&lt;/p&gt;
    &lt;p&gt;RD: A much, much, more lavish version of The Black Onyx was due to come out in the States, and I worked on that. It was my job to put together the team that did the content and the packaging, and that included the story, music, landscapes, costumes, everything. I didn’t do it alone, but I put together the team.&lt;/p&gt;
    &lt;p&gt;JF: This was actual game development?&lt;/p&gt;
    &lt;p&gt;RD: Yes, this was a full-on role-playing game. A lot of the artwork appears in my book, Dragon’s Dream. But the very big, lavish production never happened, sadly. That was very disappointing. We worked on it for some years, it was good fun.&lt;/p&gt;
    &lt;p&gt;JF: Do you know why it didn’t happen?&lt;/p&gt;
    &lt;p&gt;RD: I’m not a hundred percent sure. It was a huge amount of work. It was a real shame that it never happened, because while the technology has moved on, the design would still be valid today. The music is incredible.&lt;/p&gt;
    &lt;p&gt;HAJ: So is there a chance it could see the light of day?&lt;/p&gt;
    &lt;p&gt;RD: Heh, yeah, I think Henk Rogers would like to see it published. He owns the game, and I own the artwork. The big game was supposed to be called Onyx.&lt;/p&gt;
    &lt;p&gt;JF: This was much more advanced than the original?&lt;/p&gt;
    &lt;p&gt;RD: Way more advanced. Too advanced for it’s time, really. It would have needed 24 CDs for each episode. DVDs arrived in the middle of it, but that would have only divided the number of CDs by three.&lt;/p&gt;
    &lt;p&gt;JF: Do you remember any game projects that were particularly exciting to work with?&lt;/p&gt;
    &lt;p&gt;RD: Well, you know what? Onyx, in the end, was the most exciting. Because that was the first time I got really hands on with the content.&lt;/p&gt;
    &lt;p&gt;And as I said, it’s still never seen the light of day. It is very interesting, because two weeks ago I had a visit from Henk Rogers. He’s doing a book called The Perfect Game about Tetris, and he’s doing an audio book. And in that he talks about different projects, including Black Onyx. For Black Onyx, he used some of the music that we created for the project, and it was really good by any standards. It was a great piece of music, not a great piece of game music, but a great piece of music. Even the music should be published. It hasn’t been, but it should be.&lt;/p&gt;
    &lt;p&gt;HAJ: Who did that music?&lt;/p&gt;
    &lt;p&gt;RD: Well, we did it in collaboration with two people called Youth and Jaz. Jaz Coleman was orchestral minded, but he was also a singer for a band called Killing Joke. So he had his rock and roll credentials. But he worked with Prague Symphony Orchestra and things like that. Youth (Martin Glover) was very much into electronic music. He had a band called The Orb, and he worked with people like Paul McCartney. Oh, he did all kinds of stuff. But his big interest was electronic music at the time.&lt;/p&gt;
    &lt;p&gt;Between them, one producing, one arranging, they made a lovely soundtrack. And it had people like Steve Howe from Yes performing on it.&lt;/p&gt;
    &lt;p&gt;HAJ: Is there a chance that we will hear this music in the future?&lt;/p&gt;
    &lt;p&gt;RD: Well, I think yes, because we were all listening to it at least two weeks ago, and that’s exactly what everyone was saying. This music has got to be available. It’s got to be out there.&lt;/p&gt;
    &lt;p&gt;HAJ: I really want to play this game now … but but the artwork for this game will be out in your next book or calendar?&lt;/p&gt;
    &lt;p&gt;RD: Some of it will, but it’s in my book, Dragon’s Dream, which was published in 2008.&lt;/p&gt;
    &lt;p&gt;JF: Was it ever possible to actually play the game – did it get that far into development?&lt;/p&gt;
    &lt;p&gt;RD: No. Henk would probably tell me I’m wrong, but I’m not even sure gameplay was ever fully developed. The overall concept had to be because we couldn’t structure what we did without that, but we were filling in a lot of gaps. Too many gaps.&lt;/p&gt;
    &lt;p&gt;I mean, we did a lot of things which were done for the first time. At the time, I studied kendo, which is Japanese martial art with the sword. And my sensei had studied medieval European sword and pole arm spear techniques. For the sword fighting, it was broken up into kata, which is attack, defend, counterattack – sequences that were from real techniques. In a fight you could put it together and it looks so amazingly convincing, and you could watch it from any angle. And we we recorded it in motion capture. So it was very realistic. And it was not just because the motion capture is realistic, but because these were genuine sword techniques.&lt;/p&gt;
    &lt;p&gt;JF: I know The Tetris Company worked with another company [Digital Eclipse] for an «interactive museum» about Tetris, so I was wondering if something could maybe be saved and published in a similar way?&lt;/p&gt;
    &lt;p&gt;RD: Well, there is something which is possible. We developed a process that Henk called Track and Field. Track was when the characters followed a specific route, and Field was when they could wander wherever you liked. They couldn’t wander over the whole world because they’d get lost and it would be boring. You had to have a mechanism to bring them back, but you needed them to follow a path.&lt;/p&gt;
    &lt;p&gt;So you could do it like a movie where there was a sequence that was completely constructed. You could watch it from different angles, but you it was a complete construction, but then you could break off into a game. If for instance it was like Lord of the Rings, they could be climbing the mountain path, but when they’re in the dragon’s lair, then they’d come into the field – the game aspect, where they can wander wherever they want. But once they’re out again, they’re back on the track.&lt;/p&gt;
    &lt;p&gt;So there’s bits when you can just watch it, it looks great, and then there’s bits when you’re frantically interactive.&lt;/p&gt;
    &lt;p&gt;HAJ: Did you work on any other interesting projects like this?&lt;/p&gt;
    &lt;p&gt;RD: Before I met either Henk or Jonathan Ellis, we worked on an idea for doing a project called Taitan, which was an arcade game [cabinet]. We said we were going to manufacture the machines ourselves, and talked to Taito Electronics about licensing the motherboards from them. But instead, they decided to buy out our business, so that’s how that went.&lt;/p&gt;
    &lt;p&gt;Henk Rogers also got involved with a virtual reality project with us. He was the first who saw this, and he invested in it. We built maybe a dozen prototypes. But again, we were too far ahead of the technology. Mitsubishi supplied the monitors … they were the size of a small car. We had to cut great chunks out of the pods we were making. They were very elegant, but we had to cut massive amounts out of them just to fit in the monitors. They were bigger behind than the screen.&lt;/p&gt;
    &lt;p&gt;JF: How do you view your game art compared to the rest of the work that you’ve done?&lt;/p&gt;
    &lt;p&gt;RD: In many ways, it was like returning to roots for me because I never did do fine art at college. I did Canterbury College of Art for four years, Royal College for three. My focus was on architecture. You know, the I studied basically what kind of spaces made us feel good, what kind of spaces made us feel uncomfortable. And my view is very strongly that modern architecture is not good for us. There should have been a better way.&lt;/p&gt;
    &lt;p&gt;This is what I’m very interested in and focused on now. We’re looking to build a visitor center and museum.&lt;/p&gt;
    &lt;p&gt;HAJ: Where?&lt;/p&gt;
    &lt;p&gt;RD: We’re looking at two sites. They’ll be different. One is in England, near here, near where I live, and one is in California.&lt;/p&gt;
    &lt;p&gt;JF: Thanks a lot for your time. It’s an honor for us.&lt;/p&gt;
    &lt;p&gt;RD: No, it’s an honor for me. And fun.&lt;/p&gt;
    &lt;p&gt;HAJ: Thank you for doing this.&lt;/p&gt;
    &lt;p&gt;RD: Thank you.&lt;/p&gt;
    &lt;p&gt;Please visit Roger Dean’s website for more of his art.&lt;/p&gt;
    &lt;p&gt;And visit this page for more content in English, including a lot of other interviews with games industry people.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spillhistorie.no/2025/10/03/legends-of-the-games-industry-roger-dean/"/><published>2025-10-13T14:29:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568767</id><title>Ofcom fines 4chan £20K and counting for violating UK's Online Safety Act</title><updated>2025-10-13T20:11:31.515924+00:00</updated><content>&lt;doc fingerprint="8ecb095014b22f02"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ofcom fines 4chan £20K and counting for pretending UK's Online Safety Act doesn't exist&lt;/head&gt;
    &lt;head rend="h2"&gt;Regulator warns penalties will pile up until internet toilet does its paperwork&lt;/head&gt;
    &lt;p&gt;Ofcom, the UK's Online Safety Act regulator, has fined online message board 4chan £20,000 ($26,680) for failing to protect children from harmful content.&lt;/p&gt;
    &lt;p&gt;The fine could rise by a further £6,000 – £100 per day for a maximum 60 days – if it continues to ignore its duties to comply with the regulator's request for information regarding two separate matters.&lt;/p&gt;
    &lt;p&gt;4chan can stop the additional fines by providing copies of its illegal content risk assessments and information about its qualifying worldwide revenue to Ofcom.&lt;/p&gt;
    &lt;p&gt;The enforcement action announced today is months in the making after Ofcom first opened an investigation into the notorious image board on June 10.&lt;/p&gt;
    &lt;p&gt;It requested the aforementioned risk assessments on April 14, and to this day 4chan still has not complied, the regulator said.&lt;/p&gt;
    &lt;p&gt;When opening the investigation, Ofcom said it was looking to understand whether 4chan has failed, or is failing, to abide by its duties under the Online Safety Act.&lt;/p&gt;
    &lt;p&gt;The watchdog also highlighted that the maximum penalties for these failures, as specified in the legislation, are £18 million ($24 million) or 10 percent of an organization's qualifying worldwide revenue, whichever is greater.&lt;/p&gt;
    &lt;p&gt;The Register contacted 4chan for its side of the story.&lt;/p&gt;
    &lt;p&gt;Ofcom's fine is the first made under the Online Safety Act since in-scope organizations' illegal content duties came into force on March 17. It also announced two provisional decisions to take action against file-sharing service Im.ge and pornography service provider AVS Group Ltd for similar failures to respond to information requests.&lt;/p&gt;
    &lt;p&gt;In Im.ge's case, this relates to its duty to implement measures to prevent the circulation of child sexual abuse material (CSAM), and AVS Group was rapped over its duty to implement age-check mechanisms.&lt;/p&gt;
    &lt;p&gt;Both organizations have the chance to appeal Ofcom's findings before it makes a final decision on how to reprimand them.&lt;/p&gt;
    &lt;p&gt;Another porn provider, Youngtek Solutions Ltd, is also under an expanded investigation over its failure to respond to information requests regarding age-checking requirements.&lt;/p&gt;
    &lt;p&gt;Tech secretary Liz Kendall said: "The Online Safety Act is not just law, it's a lifeline. Today we've seen it in action, holding platforms to account so we can protect people across the UK.&lt;/p&gt;
    &lt;p&gt;"Services can no longer ignore illegal content, like encouraging self-harm or suicide, circulating online which can devastate young lives and leave families shattered.&lt;/p&gt;
    &lt;p&gt;"This fine is a clear warning to those who fail to remove illegal content or protect children from harmful material. We fully back the regulator in taking action against all platforms that do not protect users from the darkest corners of the internet."&lt;/p&gt;
    &lt;p&gt;In total, since March 2025, Ofcom has opened 21 investigations into the providers of in-scope apps and websites, and launched five enforcement programs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Playing by the rules&lt;/head&gt;
    &lt;p&gt;In brighter news, others under Ofcom investigation have shown improvements, and several of these cases are now closed.&lt;/p&gt;
    &lt;p&gt;Four file-sharing services under investigation for their child safety measures avoided further action by geo-blocking UK users, much to Ofcom's delight. Krakenfiles, Nippydrive, Nippyshare, and Nippyspace have all blocked British IP addresses instead of following other measures set out in the regulator's codes of practice.&lt;/p&gt;
    &lt;p&gt;Ofcom said it has closed the cases into these sites, and that the measures have "significantly reduced the likelihood that people in the UK will be exposed to any illegal or harmful content."&lt;/p&gt;
    &lt;p&gt;"We will continue to monitor their availability in the UK and reserve the right to reopen our investigations if we have reason to do so. We are pursuing further lines of inquiry against file-sharing services Nippybox and Yolobit, and these investigations remain ongoing."&lt;/p&gt;
    &lt;p&gt;A suicide forum is also now geo-blocking UK IPs after Ofcom began enforcement proceedings.&lt;/p&gt;
    &lt;p&gt;Satisfied for now, the regulator said it will keep tabs on the unnamed provider to see whether that block remains in place over the long term, and ensure it does not provide information on how to bypass it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord says 70,000 photo IDs compromised in customer service breach&lt;/item&gt;
      &lt;item&gt;Germany slams brakes on EU's Chat Control device-scanning snoopfest&lt;/item&gt;
      &lt;item&gt;Imgur yanks Brit access to memes as parent company faces fine&lt;/item&gt;
      &lt;item&gt;Charities warn Ofcom too soft on Online Safety Act violators&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bypassing these measures has been a hot point of discussion since the Online Safety Act's most noticeable rules came into force in July, triggering a surge in VPN subscriptions within days of Brits having to submit their ID cards for age verification purposes.&lt;/p&gt;
    &lt;p&gt;While platforms are forbidden from guiding users toward these types of workarounds, this alone is unlikely to prevent VPNs being used to bypass geo-blocks and similar measures.&lt;/p&gt;
    &lt;p&gt;They do not appear to be going anywhere either. The UK government has previously stated that it does not wish to ban them, since they have many legitimate purposes. But if platforms promote VPNs and other workarounds to children as a means to access their services, then Ofcom will pursue action against them.&lt;/p&gt;
    &lt;head rend="h3"&gt;First look at beefed-up requirements&lt;/head&gt;
    &lt;p&gt;Among Ofcom's proposed amendments to its obligations to platforms was the requirement for in-scope apps and websites to make use of hash-matching technology, which is seen as a more accurate, automated way of preventing the dissemination of illegal content such as CSAM.&lt;/p&gt;
    &lt;p&gt;Hash matching involves a system fingerprinting an image and comparing the hash it generates to a database of known harmful images, which are also hashed. If an image's hash matches or shows signs of similarity with one in the database, then it can be removed entirely autonomously and reported to local authorities for follow-up investigations.&lt;/p&gt;
    &lt;p&gt;Ofcom previously identified "serious compliance concerns" with its CSAM enforcement program at 1Fichier.com and Gofile.io, leading to investigations being opened into them both.&lt;/p&gt;
    &lt;p&gt;After constructive engagement with the regulator, both now deploy hash-matching tech and escaped further action.&lt;/p&gt;
    &lt;p&gt;Suzanne Cater, director of enforcement at Ofcom, said: "Today sends a clear message that any service which flagrantly fails to engage with Ofcom and their duties under the Online Safety Act can expect to face robust enforcement action.&lt;/p&gt;
    &lt;p&gt;"We're also seeing some services take steps to introduce improved safety measures as a direct result of our enforcement action. Services who choose to restrict access rather than protect UK users remain on our watchlist as we continue to monitor their availability to UK users." ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2025/10/13/4chan_ofcom_fine/"/><published>2025-10-13T14:34:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568955</id><title>AI and the Future of American Politics</title><updated>2025-10-13T20:11:31.364919+00:00</updated><content>&lt;doc fingerprint="bd10923da2f9c589"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;AI and the Future of American Politics&lt;/head&gt;
    &lt;p&gt;Two years ago, Americans anxious about the forthcoming 2024 presidential election were considering the malevolent force of an election influencer: artificial intelligence. Over the past several years, we have seen plenty of warning signs from elections worldwide demonstrating how AI can be used to propagate misinformation and alter the political landscape, whether by trolls on social media, foreign influencers, or even a street magician. AI is poised to play a more volatile role than ever before in America’s next federal election in 2026. We can already see how different groups of political actors are approaching AI. Professional campaigners are using AI to accelerate the traditional tactics of electioneering; organizers are using it to reinvent how movements are built; and citizens are using it both to express themselves and amplify their side’s messaging. Because there are so few rules, and so little prospect of regulatory action, around AI’s role in politics, there is no oversight of these activities, and no safeguards against the dramatic potential impacts for our democracy.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Campaigners&lt;/head&gt;
    &lt;p&gt;Campaigners—messengers, ad buyers, fundraisers, and strategists—are focused on efficiency and optimization. To them, AI is a way to augment or even replace expensive humans who traditionally perform tasks like personalizing emails, texting donation solicitations, and deciding what platforms and audiences to target.&lt;/p&gt;
    &lt;p&gt;This is an incremental evolution of the computerization of campaigning that has been underway for decades. For example, the progressive campaign infrastructure group Tech for Campaigns claims it used AI in the 2024 cycle to reduce the time spent drafting fundraising solicitations by one-third. If AI is working well here, you won’t notice the difference between an annoying campaign solicitation written by a human staffer and an annoying one written by AI.&lt;/p&gt;
    &lt;p&gt;But AI is scaling these capabilities, which is likely to make them even more ubiquitous. This will make the biggest difference for challengers to incumbents in safe seats, who see AI as both a tacitly useful tool and an attention-grabbing way to get their race into the headlines. Jason Palmer, the little-known Democratic primary challenger to Joe Biden, successfully won the American Samoa primary while extensively leveraging AI avatars for campaigning.&lt;/p&gt;
    &lt;p&gt;Such tactics were sometimes deployed as publicity stunts in the 2024 cycle; they were firsts that got attention. Pennsylvania Democratic Congressional candidate Shamaine Daniels became the first to use a conversational AI robocaller in 2023. Two long-shot challengers to Rep. Don Beyer used an AI avatar to represent the incumbent in a live debate last October after he declined to participate. In 2026, voters who have seen years of the official White House X account posting deepfaked memes of Donald Trump will be desensitized to the use of AI in political communications.&lt;/p&gt;
    &lt;p&gt;Strategists are also turning to AI to interpret public opinion data and provide more fine-grained insight into the perspective of different voters. This might sound like AIs replacing people in opinion polls, but it is really a continuation of the evolution of political polling into a data-driven science over the last several decades.&lt;/p&gt;
    &lt;p&gt;A recent survey by the American Association of Political Consultants found that a majority of their members’ firms already use AI regularly in their work, and more than 40 percent believe it will “fundamentally transform” the future of their profession. If these emerging AI tools become popular in the midterms, it won’t just be a few candidates from the tightest national races texting you three times a day. It may also be the member of Congress in the safe district next to you, and your state representative, and your school board members.&lt;/p&gt;
    &lt;p&gt;The development and use of AI in campaigning is different depending on what side of the aisle you look at. On the Republican side, Push Digital Group is going “all in” on a new AI initiative, using the technology to create hundreds of ad variants for their clients automatically, as well as assisting with strategy, targeting, and data analysis. On the other side, the National Democratic Training Committee recently released a playbook for using AI. Quiller is building an AI-powered fundraising platform aimed at drastically reducing the time campaigns spend producing emails and texts. Progressive-aligned startups Chorus AI and BattlegroundAI are offering AI tools for automatically generating ads for use on social media and other digital platforms. DonorAtlas automates data collection on potential donors, and RivalMind AI focuses on political research and strategy, automating the production of candidate dossiers.&lt;/p&gt;
    &lt;p&gt;For now, there seems to be an investment gap between Democratic- and Republican-aligned technology innovators. Progressive venture fund Higher Ground Labs boasts $50 million in deployed investments since 2017 and a significant focus on AI. Republican-aligned counterparts operate on a much smaller scale. Startup Caucus has announced one investment—of $50,000—since 2022. The Center for Campaign Innovation funds research projects and events, not companies. This echoes a longstanding gap in campaign technology between Democratic- and Republican-aligned fundraising platforms ActBlue and WinRed, which has landed the former in Republicans’ political crosshairs.&lt;/p&gt;
    &lt;p&gt;Of course, not all campaign technology innovations will be visible. In 2016, the Trump campaign vocally eschewed using data to drive campaign strategy and appeared to be falling way behind on ad spending, but was—we learned in retrospect—actually leaning heavily into digital advertising and making use of new controversial mechanisms for accessing and exploiting voters’ social media data with vendor Cambridge Analytica. The most impactful uses of AI in the 2026 midterms may not be known until 2027 or beyond.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Organizers&lt;/head&gt;
    &lt;p&gt;Beyond the realm of political consultants driving ad buys and fundraising appeals, organizers are using AI in ways that feel more radically new.&lt;/p&gt;
    &lt;p&gt;The hypothetical potential of AI to drive political movements was illustrated in 2022 when a Danish artist collective used an AI model to found a political party, the Synthetic Party, and generate its policy goals. This was more of an art project than a popular movement, but it demonstrated that AIs—synthesizing the expressions and policy interests of humans—can formulate a political platform. In 2025, Denmark hosted a “summit” of eight such AI political agents where attendees could witness “continuously orchestrate[d] algorithmic micro-assemblies, spontaneous deliberations, and impromptu policy-making” by the participating AIs.&lt;/p&gt;
    &lt;p&gt;The more viable version of this concept lies in the use of AIs to facilitate deliberation. AIs are being used to help legislators collect input from constituents and to hold large-scale citizen assemblies. This kind of AI-driven “sensemaking” may play a powerful role in the future of public policy. Some research has suggested that AI can be as or more effective than humans in helping people find common ground on controversial policy issues.&lt;/p&gt;
    &lt;p&gt;Another movement for “Public AI” is focused on wresting AI from the hands of corporations to put people, through their governments, in control. Civic technologists in national governments from Singapore, Japan, Sweden, and Switzerland are building their own alternatives to Big Tech AI models, for use in public administration and distribution as a public good.&lt;/p&gt;
    &lt;p&gt;Labor organizers have a particularly interesting relationship to AI. At the same time that they are galvanizing mass resistance against the replacement or endangerment of human workers by AI, many are racing to leverage the technology in their own work to build power.&lt;/p&gt;
    &lt;p&gt;Some entrepreneurial organizers have used AI in the past few years as tools for activating, connecting, answering questions for, and providing guidance to their members. In the UK, the Centre for Responsible Union AI studies and promotes the use of AI by unions; they’ve published several case studies. The UK Public and Commercial Services Union has used AI to help their reps simulate recruitment conversations before going into the field. The Belgian union ACV-CVS has used AI to sort hundreds of emails per day from members to help them respond more efficiently. Software companies such as Quorum are increasingly offering AI-driven products to cater to the needs of organizers and grassroots campaigns.&lt;/p&gt;
    &lt;p&gt;But unions have also leveraged AI for its symbolic power. In the U.S., the Screen Actors Guild held up the specter of AI displacement of creative labor to attract public attention and sympathy, and the ETUC (the European confederation of trade unions) developed a policy platform for responding to AI.&lt;/p&gt;
    &lt;p&gt;Finally, some union organizers have leveraged AI in more provocative ways. Some have applied it to hacking the “bossware” AI to subvert the exploitative intent or disrupt the anti-union practices of their managers.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Citizens&lt;/head&gt;
    &lt;p&gt;Many of the tasks we’ve talked about so far are familiar use cases to anyone working in office and management settings: writing emails, providing user (or voter, or member) support, doing research.&lt;/p&gt;
    &lt;p&gt;But even mundane tasks, when automated at scale and targeted at specific ends, can be pernicious. AI is not neutral. It can be applied by many actors for many purposes. In the hands of the most numerous and diverse actors in a democracy—the citizens—that has profound implications.&lt;/p&gt;
    &lt;p&gt;Conservative activists in Georgia and Florida have used a tool named EagleAI to automate challenging voter registration en masse (although the tool’s creator later denied that it uses AI). In a nonpartisan electoral management context with access to accurate data sources, such automated review of electoral registrations might be useful and effective. In this hyperpartisan context, AI merely serves to amplify the proclivities of activists at the extreme of their movements. This trend will continue unabated in 2026.&lt;/p&gt;
    &lt;p&gt;Of course, citizens can use AI to safeguard the integrity of elections. In Ghana’s 2024 presidential election, civic organizations used an AI tool to automatically detect and mitigate electoral disinformation spread on social media. The same year, Kenyan protesters developed specialized chatbots to distribute information about a controversial finance bill in Parliament and instances of government corruption.&lt;/p&gt;
    &lt;p&gt;So far, the biggest way Americans have leveraged AI in politics is in self-expression. About ten million Americans have used the chatbot Resistbot to help draft and send messages to their elected leaders. It’s hard to find statistics on how widely adopted tools like this are, but researchers have estimated that, as of 2024, about one in five consumer complaints to the U.S. Consumer Financial Protection Bureau was written with the assistance of AI.&lt;/p&gt;
    &lt;p&gt;OpenAI operates security programs to disrupt foreign influence operations and maintains restrictions on political use in its terms of service, but this is hardly sufficient to deter use of AI technologies for whatever purpose. And widely available free models give anyone the ability to attempt this on their own.&lt;/p&gt;
    &lt;p&gt;But this could change. The most ominous sign of AI’s potential to disrupt elections is not the deepfakes and misinformation. Rather, it may be the use of AI by the Trump administration to surveil and punish political speech on social media and other online platforms. The scalability and sophistication of AI tools give governments with authoritarian intent unprecedented power to police and selectively limit political speech.&lt;/p&gt;
    &lt;head rend="h3"&gt;What About the Midterms?&lt;/head&gt;
    &lt;p&gt;These examples illustrate AI’s pluripotent role as a force multiplier. The same technology used by different actors—campaigners, organizers, citizens, and governments—leads to wildly different impacts. We can’t know for sure what the net result will be. In the end, it will be the interactions and intersections of these uses that matters, and their unstable dynamics will make future elections even more unpredictable than in the past.&lt;/p&gt;
    &lt;p&gt;For now, the decisions of how and when to use AI lie largely with individuals and the political entities they lead. Whether or not you personally trust AI to write an email for you or make a decision about you hardly matters. If a campaign, an interest group, or a fellow citizen trusts it for that purpose, they are free to use it.&lt;/p&gt;
    &lt;p&gt;It seems unlikely that Congress or the Trump administration will put guardrails around the use of AI in politics. AI companies have rapidly emerged as among the biggest lobbyists in Washington, reportedly dumping $100 million toward preventing regulation, with a focus on influencing candidate behavior before the midterm elections. The Trump administration seems open and responsive to their appeals.&lt;/p&gt;
    &lt;p&gt;The ultimate effect of AI on the midterms will largely depend on the experimentation happening now. Candidates and organizations across the political spectrum have ample opportunity—but a ticking clock—to find effective ways to use the technology. Those that do will have little to stop them from exploiting it.&lt;/p&gt;
    &lt;p&gt;This essay was written with Nathan E. Sanders, and originally appeared in The American Prospect.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.schneier.com/blog/archives/2025/10/ai-and-the-future-of-american-politics.html"/><published>2025-10-13T14:51:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569350</id><title>NanoChat – The best ChatGPT that $100 can buy</title><updated>2025-10-13T20:11:30.888318+00:00</updated><content>&lt;doc fingerprint="8c198122f1657e6"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;The best ChatGPT that $100 can buy.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This repo is a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase. nanochat is designed to run on a single 8XH100 node via scripts like speedrun.sh, that run the entire pipeline start to end. This includes tokenization, pretraining, finetuning, evaluation, inference, and web serving over a simple UI so that you can talk to your own LLM just like ChatGPT. nanochat will become the capstone project of the course LLM101n being developed by Eureka Labs.&lt;/p&gt;
    &lt;p&gt;The fastest way to feel the magic is to run the speedrun script speedrun.sh, which trains and inferences the $100 tier of nanochat. On an 8XH100 node at $24/hr, this gives a total run time of about 4 hours. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like Lambda), and kick off the training script:&lt;/p&gt;
    &lt;code&gt;bash speedrun.sh&lt;/code&gt;
    &lt;p&gt;Alternatively, since the script runs for 4 hours, I like to launch it like this inside a new screen session &lt;code&gt;speedrun&lt;/code&gt; (and also log output to &lt;code&gt;speedrun.log&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;screen -L -Logfile speedrun.log -S speedrun bash speedrun.sh&lt;/code&gt;
    &lt;p&gt;See the screen cheatsheet if you are less familiar. You can watch it go inside the screen session, or detach with &lt;code&gt;Ctrl-a d&lt;/code&gt; and &lt;code&gt;tail speedrun.log&lt;/code&gt; to view progress. Now wait 4 hours. Once it's done, you can talk to your LLM via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run &lt;code&gt;source .venv/bin/activate&lt;/code&gt;), and serve it:&lt;/p&gt;
    &lt;code&gt;python -m scripts.chat_web&lt;/code&gt;
    &lt;p&gt;And then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example http://209.20.xxx.xxx:8000/, etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).&lt;/p&gt;
    &lt;p&gt;You can also &lt;code&gt;cat report.md&lt;/code&gt; file which appeared in the project directory and contains the "report card" of the run, i.e. a bunch of evaluations and metrics. At the very end, you'll see a summary table, for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Characters: 333,989&lt;/item&gt;
      &lt;item&gt;Lines: 8,304&lt;/item&gt;
      &lt;item&gt;Files: 44&lt;/item&gt;
      &lt;item&gt;Tokens (approx): 83,497&lt;/item&gt;
      &lt;item&gt;Dependencies (uv.lock lines): 2,004&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;BASE&lt;/cell&gt;
        &lt;cell role="head"&gt;MID&lt;/cell&gt;
        &lt;cell role="head"&gt;SFT&lt;/cell&gt;
        &lt;cell role="head"&gt;RL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CORE&lt;/cell&gt;
        &lt;cell&gt;0.2219&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ARC-Challenge&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.2875&lt;/cell&gt;
        &lt;cell&gt;0.2807&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ARC-Easy&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3561&lt;/cell&gt;
        &lt;cell&gt;0.3876&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;GSM8K&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0250&lt;/cell&gt;
        &lt;cell&gt;0.0455&lt;/cell&gt;
        &lt;cell&gt;0.0758&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HumanEval&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0671&lt;/cell&gt;
        &lt;cell&gt;0.0854&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;MMLU&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3111&lt;/cell&gt;
        &lt;cell&gt;0.3151&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ChatCORE&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0730&lt;/cell&gt;
        &lt;cell&gt;0.0884&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Total wall clock time: 3h51m&lt;/p&gt;
    &lt;p&gt;(Your table might be missing the RL number by default). For a lot more information around the speedrun script and what to look for and expect, please refer to the walkthrough that I posted in Discussions of the repo: "Introducing nanochat: The best ChatGPT that $100 can buy".&lt;/p&gt;
    &lt;p&gt;Unsurprisingly, $100 is not enough to train a highly performant ChatGPT clone. In fact, LLMs are famous for their multi-million dollar capex. For our purposes, I think there are two more scales of interest. First is the ~$300 tier d26 model (i.e. depth=26) that trains in ~12 hours, which slightly outperforms GPT-2 CORE score. Second is the $1000 tier (~41.6 hours), just because it's a nice round number. But both of these are not yet fully supported and therefore not attached here in the master branch yet.&lt;/p&gt;
    &lt;p&gt;That said, to give a sense, the example changes needed for the speedrun.sh file to train a GPT-2 grade model d26 only involve three changes:&lt;/p&gt;
    &lt;code&gt;...
# you'll need to download more data shards for pretraining
# get the number of parameters, multiply 20 to get tokens, multiply by 4.8 to get chars,
# divide by 250 million to get number of shards. todo need to improve this...
python -m nanochat.dataset -n 450 &amp;amp;
...
# use --depth to increase model size. to not oom, halve device batch size 32 -&amp;gt; 16:
torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- --depth=26 --device_batch_size=16
...
# make sure to use the same later during midtraining:
torchrun --standalone --nproc_per_node=8 -m scripts.mid_train -- --device_batch_size=16&lt;/code&gt;
    &lt;p&gt;That's it! The biggest thing to pay attention to is making sure you have enough data shards to train on (the code will loop and do more epochs over the same training set otherwise, decreasing learning speed a bit), and managing your memory/VRAM, primarily by decreasing the &lt;code&gt;device_batch_size&lt;/code&gt; until things fit (the scripts automatically compensates by increasing the number of gradient accumulation loops, simply turning parallel compute to sequential compute).&lt;/p&gt;
    &lt;p&gt;And a bit more about computing environments that will run nanochat:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The code will run just fine on the Ampere 8XA100 GPU node as well, but a bit slower.&lt;/item&gt;
      &lt;item&gt;All code will run just fine on even a single GPU by omitting &lt;code&gt;torchrun&lt;/code&gt;, and will produce ~identical results (code will automatically switch to gradient accumulation), but you'll have to wait 8 times longer.&lt;/item&gt;
      &lt;item&gt;If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for &lt;code&gt;--device_batch_size&lt;/code&gt;in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. Less than that you'll have to know a bit more what you're doing and get more creative.&lt;/item&gt;
      &lt;item&gt;Most of the code is fairly vanilla PyTorch so it should run on anything that supports that - xpu, mps, or etc, but I haven't implemented this out of the box so it might take a bit of tinkering.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;nanochat is designed to be short and sweet. One big advantage of this is that we can package up all of the files together and copy paste them to your favorite LLM to ask arbitrary questions. As an example, I like to package up the repo using the files-to-prompt utility like so:&lt;/p&gt;
    &lt;code&gt;files-to-prompt . -e py -e md -e rs -e html -e toml -e sh --ignore "*target*" --cxml &amp;gt; packaged.txt&lt;/code&gt;
    &lt;p&gt;This includes all py, rs, html, toml, sh files, excludes the &lt;code&gt;rustbpe/target&lt;/code&gt; folder, and chooses the cxml output format. Everything is written to the &lt;code&gt;packaged.txt&lt;/code&gt; file, which atm measures ~330KB (i.e. well below ~100K tokens for a state of the art LLM), and ~8K lines of code in 45 files.&lt;/p&gt;
    &lt;p&gt;Alternatively, I recommend using DeepWiki from Devin/Cognition to ask questions of this repo. In the URL of this repo, simply change github.com to deepwiki.com, and you're off.&lt;/p&gt;
    &lt;p&gt;I haven't invested too much here but some tests exist, especially for the tokenizer. Run e.g. as:&lt;/p&gt;
    &lt;code&gt;python -m pytest tests/test_rustbpe.py -v -s&lt;/code&gt;
    &lt;p&gt;nanochat is nowhere finished. The goal is to improve the state of the art in micro models that are accessible to work with end to end on budgets of &amp;lt; $1000 dollars. Accessibility is about overall cost but also about cognitive complexity - nanochat is not an exhaustively configurable LLM "framework"; there will be no giant configuration objects, model factories, or if-then-else monsters in the code base. It is a single, cohesive, minimal, readable, hackable, maximally-forkable "strong baseline" codebase designed to run start to end and produce a concrete ChatGPT clone and its report card.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The name (nanochat) derives from my earlier project nanoGPT, which only covered pretraining.&lt;/item&gt;
      &lt;item&gt;nanochat is also inspired by modded-nanoGPT, which gamified the nanoGPT repo with clear metrics and a leaderboard, and borrows a lot of its ideas and some implementation for pretraining.&lt;/item&gt;
      &lt;item&gt;Thank you to HuggingFace for fineweb and smoltalk.&lt;/item&gt;
      &lt;item&gt;Thank you Lambda for the compute used in developing this project.&lt;/item&gt;
      &lt;item&gt;Thank you to chief LLM whisperer 🧙♂️ Alec Radford for advice/guidance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you find nanochat helpful in your research cite simply as:&lt;/p&gt;
    &lt;code&gt;@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that $100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}&lt;/code&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/karpathy/nanochat"/><published>2025-10-13T15:22:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569371</id><title>Android's sideloading limits are its most anti-consumer move</title><updated>2025-10-13T20:11:30.293801+00:00</updated><content>&lt;doc fingerprint="8f42830190be3051"&gt;
  &lt;main&gt;
    &lt;p&gt;I’m a huge fan of open source, and that’s one of the reasons I’m drawn to Android. However, new requirements surrounding sideloaded apps, which will start rolling out in October 2025, may be the most anti-consumer move yet by Google. Mandatory enforcement of the requirement will begin in September 2026 (starting with specific countries), marking a turning point where the freedom to install any app comes with conditions set by Google.&lt;/p&gt;
    &lt;p&gt;I’ve used apps like NewPipe (a media/YouTube client) and Blokada (an ad blocker) for years now. However, these apps aren’t available on the Google Play Store, so I have to obtain them from third-party sources, such as F-Droid. With Google tightening the rules around sideloaded apps, I fear I may lose access to some of the apps I love most on Android because they aren’t verified. Sideloading isn’t going away, but people may seek alternatives because it may feel like the gates are narrowing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Google actually changed&lt;/head&gt;
    &lt;head rend="h3"&gt;The rules, the timeline, and what “certified” really means&lt;/head&gt;
    &lt;p&gt;Google's talk around "verified developers" sounds harmless and, in some ways, helpful. As reported on the Android Developer Blog, it is like "an ID check at the airport which confirms a traveler's identity but is separate from the security screening of their bags." Google's analogy, however, may be oversimplified. When this is enforced, the only way a developer’s app will be installable on devices that include Google Mobile Services (GMS) — which typically provide access to the Play Store — is by completing ID verification using government-issued documents or contact information. This will be rolled out globally in 2027.&lt;/p&gt;
    &lt;p&gt;Apps will be blocked from installing on most mainstream phones if their developer can't complete this verification. However, there are certain devices that will remain unaffected, even though they are just a tiny fraction of the total devices. These categories include all devices that do not pass Google's certification test, primarily custom ROMs or de-Googled phones.&lt;/p&gt;
    &lt;p&gt;Strictly speaking, Google is not removing sideloading, but it is redefining and limiting participation in the Android ecosystem by creating a mandatory Google-controlled choke point. While this may be a subtle shift, it clearly takes an open source project from anyone being able to participate (including anonymous or pseudonymous distribution) to only those whom Google allows to participate (via centralized developer identity verification).&lt;/p&gt;
    &lt;head rend="h2"&gt;Security theater or real gain?&lt;/head&gt;
    &lt;head rend="h3"&gt;Testing Google’s justification&lt;/head&gt;
    &lt;p&gt;There is a rational justification for tightening rules around sideloaded apps. It could be framed as user protection against malicious apps or against bad actors who cloak themselves with fake identities. While this is reasonable, the real question is whether it adds significant security for everyday users.&lt;/p&gt;
    &lt;p&gt;This is a valid question because security checks already exist. Google Play Protect makes Android secure by scanning sideloaded apps. Android flags unsafe installs, and it’s always given us the choice of blocking apps from unknown sources. Even if these are imperfect, they’re defenses that already exist.&lt;/p&gt;
    &lt;p&gt;Google’s new move almost feels like it’s based on the assumption that identity equals integrity. Does a verified government-issued identification equate to user safety? This logic is flawed: historically, we've seen malware slip through the Play Store—signed and “verified”—several times. However, what the new rule does is shift the basis of trust away from existing on-device security warnings and your best judgment.&lt;/p&gt;
    &lt;p&gt;Critics may even contend that this new rule erodes your right to make informed decisions about your own devices, and that feels more like selective control. Ultimately, many people may view this as Google’s way of shielding itself from criticism over sideloaded malware and protecting the integrity of its ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;There will be collateral damage&lt;/head&gt;
    &lt;head rend="h3"&gt;The ecosystems that depend on openness&lt;/head&gt;
    &lt;p&gt;This may be the most significant anti-consumer move, simply due to its profound impact. It could hit big developers or commercial apps, as well as entire ecosystems built around freely distributed APKs without verification. F-Droid hosts an incredible number of apps not available on the Play Store. Many of these tools exist because they see a need to operate outside the long, controlling arm of Google. This sideloading rule may make them unavailable on mainstream devices even though they’re safe.&lt;/p&gt;
    &lt;p&gt;This is a risk that also affects indie developers and hobbyists. Certain apps can no longer justify the time, effort, or privacy trade-offs required for identity verification. Many one-off projects and apps for niche communities may fall under this category. Ultimately, what we may end up with is a shrunken ecosystem, and if this happens, it will hurt all of us.&lt;/p&gt;
    &lt;p&gt;However, innovation may be the biggest casualty in all of this. Android is great because of its flexibility. It is an ecosystem for everyone. The imposition of a single, centralized gatekeeper will stifle grassroots innovation, as not everyone will be willing or able to contribute, and this will invariably impact the pace and extent of innovation we see on Android.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new reality for Android users&lt;/head&gt;
    &lt;p&gt;Although Google would argue that the intentions behind the new rules for sideloading apps are to protect and secure users, it will likely feel limiting to many Android users, let alone removing the sense of autonomy on our devices. Of course, sideloading will still be possible, but it creates friction for people who use or make apps that aren’t officially available on the Play Store. The fear is that it may be the beginning of the end for independent developers, hobbyists, and niche app communities.&lt;/p&gt;
    &lt;p&gt;Of course, there are workarounds: using non-certified devices, backing up APKs, or exploring alternative app stores. Sadly, the trade-offs for each workaround may range from technical complexity to potential security risks. You should be careful when sideloading apps on Android. However, one thing is clear: Android's openness is closing. What we don’t know is if it will become a completely closed ecosystem someday.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.makeuseof.com/androids-sideloading-limits-are-anti-consumer-move-yet/"/><published>2025-10-13T15:24:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569966</id><title>Jeep software update bricks vehicles, leaves owners stranded</title><updated>2025-10-13T20:11:29.819907+00:00</updated><content>&lt;doc fingerprint="9d775d83986f01fc"&gt;
  &lt;main&gt;
    &lt;p&gt;A software update to Jeep 4xE models caused major malfunctions over the weekend – leaving many owners stranded and some in danger after their power failed.&lt;/p&gt;
    &lt;p&gt;The culprit appears to have been a buggy "over the air" (OTA) software update to the company’s uconnect software on Friday October 10, which “bricked” vehicles if owners installed it.&lt;/p&gt;
    &lt;p&gt;A Jeep customer support representative on a 4XE forum posted Saturday: “Please exercise extreme caution this evening if you have completed the update. If you have NOT completed the update and see the pop-up, please continue deferring..."&lt;/p&gt;
    &lt;p&gt;Posting as “Kori”, they told Jeep customers on the forum that the issue was “a telematics module box update” – and later added that the software update was cancelled the same day.&lt;/p&gt;
    &lt;p&gt;But not before multiple users across the US had updated their vehicles and suffered the immediate consequences.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jeep software update issue&lt;/head&gt;
    &lt;p&gt;Some described losing power abruptly whilst driving in the wake of the update. One Jeep owner, Kerry Hollis, who works in IT infrastructure at Wells Fargo, told The Stack: “This was a software change that obviously wasn’t tested thoroughly and was dangerous and could have had life safety implications.&lt;/p&gt;
    &lt;p&gt;“Fortunately, for me, I lost propulsion while going at low speed in my neighborhood, so I was able to pull over, restart and limp back to my home. I’ve read stories of others that weren’t in that situation, going at highway speeds, and in traffic...&lt;/p&gt;
    &lt;p&gt;"Stellantis reacted quickly but it shouldn’t have happened..."&lt;/p&gt;
    &lt;p&gt;He added: It’s concerning... that most auto manufacturers and new vehicles even have the ability to be disabled by the manufacturer or even worse, someone with a malicious intent.”&lt;/p&gt;
    &lt;p&gt;Jeep describes unconnect as software that “gives you access to the latest available features and enhancements. Updates can be performed over any password-protected Wi-Fi network. Select vehicles with connected service capabilities are eligible for over-the-air updates,” it adds. (The software can also be found in other marques from parent company Stellantis, but it appears only Jeep brands were affected by this update.)&lt;/p&gt;
    &lt;head rend="h3"&gt;See also: Ford eyes $1B in software sales&lt;/head&gt;
    &lt;p&gt;Another owner, Stephen Gutowski, owner of the reload.com news site, told The Stack: “On Friday night, my 2024 Jeep Wrangler Willys 4xe asked me to run an update when I got back home. I clicked ‘yes’ without really thinking about it.&lt;/p&gt;
    &lt;p&gt;"What's the worst that could happen, right?&lt;/p&gt;
    &lt;p&gt;He added: “Well, the next morning, I saw posts on the 4xe Facebook group I'm in that the update essentially bricked the 2024 Wranglers. I'm glad I saw that before I went out to my Jeep because I was prepared for something to maybe be wrong and did a test drive in my parking lot …”&lt;/p&gt;
    &lt;p&gt;“Sure enough, after driving maybe a half mile around my parking lot, the Jeep killed the gas and told me to put it in park. The dash lit up like a Christmas tree. The check engine light came on. Worse, it refused to go back into drive. It was just dead where it sat… I was [eventually] able to limp it back to my parking spot. I called my local dealership and they said it was a nationwide issue on at least the 2024 Wrangler 4xes…”&lt;/p&gt;
    &lt;head rend="h3"&gt;"Pretty scary"&lt;/head&gt;
    &lt;p&gt;Gutowski added: “On Sunday morning I saw Jeep's messages in the 4xe forum and the fix was ota’d to my Jeep. So, I let my car run for 15 minutes and did two power cycles. The check engine light went away, and everything seemed to be working normally again. Took it for a test drive around the neighborhood, and it drove like nothing ever happened.”&lt;/p&gt;
    &lt;p&gt;“It seems like it could have been extremely dangerous if I hadn't read about the problem before taking my car out on the road… imagine if it went dead on the highway. Pretty scary. Honestly, this feels like more of a modern car problem. I doubt this will be the last car to get bricked by an ota update. At least they were able to fix it with an ota update in a day.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Sign up for The Stack&lt;/head&gt;
    &lt;p&gt;Interviews, insight, intelligence, and exclusive events for digital leaders.&lt;/p&gt;
    &lt;p&gt;No spam. Unsubscribe anytime.&lt;/p&gt;
    &lt;p&gt;Posting on 4XE Forums, another Jeep owner going by “EmiK” wrote: “I just had to have my 2024 4XE towed to the dealer because it was having problems recognizing the gears, the CEL [check engine light] came on and it wouldn't drive.&lt;/p&gt;
    &lt;p&gt;"The dealer called me and said 4 others came in this hour.”&lt;/p&gt;
    &lt;p&gt;Another angry customer posted on the 4XE forum that “your negligence could have gotten me and a thousand others killed.&lt;/p&gt;
    &lt;quote&gt;“Wranglers are stopping dead on the HIGHWAY. the highway where most of us are doing 60+mph. dealerships are charging us over $200 for this. i am a marine corps wife, and we haven’t gotten paid due to the shutdown, so i can’t even afford to have them “look” at my car—plus, why should we, as owners, pay for your mess up? i would sue if i was in the position to do so. this lazy and unfinished update is leaving thousands of us stranded with a brick instead of a car. if someone dies from this, expect a damn big lawsuit—i’d be joining that.”&lt;/quote&gt;
    &lt;p&gt;The Stack could not reach a Jeep dealership for comment.We have also contacted Jeep owner Stellantis for a comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Don't push to production on a Friday...&lt;/head&gt;
    &lt;p&gt;The company may want to closely read CrowdStrike’s post-mortem after a buggy software update from the cybersecurity company bricked over eight million Windows computers globally in July 2024, causing cancelled flights, hospital outages and banking errors, among other issues.&lt;/p&gt;
    &lt;p&gt;CrowdStrike promised after the incident to roll out stronger software release controls/improve quality assurance. Among other pledges, it said it would start to “implement a staggered deployment strategy… in which updates are gradually deployed to larger portions of the sensor base, starting with a canary deployment…”*&lt;/p&gt;
    &lt;p&gt;*Editor's note: This is a fairly basic control and it is striking that so many organisations no longer seem to do this in their rush to push out software updates.&lt;/p&gt;
    &lt;p&gt;Affected? Have strong views on OTA software updates in vehicles or software QA? Work on uconnect and want to chat? Pop us an email or message via Signal on @Targett.11&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.thestack.technology/jeep-software-update-bricks-vehicles-leaves-owners-stranded/"/><published>2025-10-13T16:08:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45570537</id><title>Environment variables are a legacy mess: Let's dive deep into them</title><updated>2025-10-13T20:11:29.510274+00:00</updated><content>&lt;doc fingerprint="bc5368305ea99e14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Environment variables are a legacy mess: Let's dive deep into them&lt;/head&gt;
    &lt;p&gt;Programming languages have rapidly evolved in recent years. But in software development, the new often meets the old, and the scaffolding that OS gives for running new processes hasn’t changed much since Unix.&lt;/p&gt;
    &lt;p&gt;If you need to parametrize your application at runtime by passing a few ad-hoc variables (without special files or a custom solution involving IPC or networking), you’re doomed to a pretty awkward, outdated interface:&lt;/p&gt;
    &lt;head rend="h2"&gt;Environment variables.&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;export SECRET_API_KEY=2u845102348u234&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;There are no namespaces for them, no types. Just a flat, embarrassingly global dictionary of strings.&lt;/p&gt;
    &lt;p&gt;But what exactly are these envvars? Is it some kind of special dictionary inside the OS? If not, who owns them and how do they propagate?&lt;/p&gt;
    &lt;head rend="h2"&gt;Where do they come from?&lt;/head&gt;
    &lt;p&gt;In a nutshell: they’re passed from parent to child.&lt;/p&gt;
    &lt;code&gt;    841 ?        00:00:00 sshd
   1520 ?        00:00:00  \_ sshd-session
   1616 ?        00:00:00      \_ sshd-session
   5521 pts/0    00:00:00          \_ bash
   5545 pts/0    00:00:00              \_ nu
   5549 pts/0    00:00:00                  \_ bash
   5560 pts/0    00:00:00                      \_ ps
&lt;/code&gt;
    &lt;p&gt;On Linux, a program must use the &lt;code&gt;execve&lt;/code&gt; syscall to execute another program.
Whether you type &lt;code&gt;ls&lt;/code&gt; in Bash, call &lt;code&gt;subprocess.run&lt;/code&gt; in Python, or launch a
code editor, it ultimately comes down to &lt;code&gt;execve&lt;/code&gt;, preceded by a
&lt;code&gt;clone&lt;/code&gt;/&lt;code&gt;fork&lt;/code&gt;. The &lt;code&gt;exec*&lt;/code&gt; family of C functions also relies on &lt;code&gt;execve&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;SYSCALL_DEFINE3(execve,
		const char __user *, filename,
		const char __user *const __user *, argv,
		const char __user *const __user *, envp)
&lt;/code&gt;
    &lt;p&gt;This system call takes three arguments: &lt;code&gt;filename&lt;/code&gt;, &lt;code&gt;argv&lt;/code&gt;, &lt;code&gt;envp&lt;/code&gt;.
For example, for an &lt;code&gt;ls -lah&lt;/code&gt; invocation:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;/usr/bin/ls&lt;/code&gt;is the&lt;code&gt;filename&lt;/code&gt;(the executable path),&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;['ls', '-lah']&lt;/code&gt;is the&lt;code&gt;argv&lt;/code&gt;array of command line arguments – the implicit first (“zero”) argument is usually the executable name,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;['PATH=/bin:/usr/bin', 'USER=allvpv']&lt;/code&gt;is the&lt;code&gt;envp&lt;/code&gt;array of envvars (typically much longer).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By default, all envvars are passed from the parent to the child. However, nothing prevents a parent process from passing a completely different or even empty environment when calling &lt;code&gt;execve&lt;/code&gt;! In practice, most tooling passes the
environment down: Bash, Python’s &lt;code&gt;subprocess.run&lt;/code&gt;, the C library &lt;code&gt;execl&lt;/code&gt;, and
so on.&lt;/p&gt;
    &lt;p&gt;And this is what you expect – variables are inherited by child processes. That’s the point – to track the environment.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Which tools do not pass the parent’s environment? For example, the&lt;/p&gt;&lt;code&gt;login&lt;/code&gt;executable, used when signing into a system, sets up a fresh environment for its children.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Where do they go?&lt;/head&gt;
    &lt;p&gt;After launching the new program, the kernel dumps the variables on the stack as a sequence of null-terminated strings which contain the envvar definitions. Here is a hex view:&lt;/p&gt;
    &lt;code&gt;    484f 4d45 3d2f 0069 6e69 743d 2f73 6269  HOME=/ init=/sbi
    6e2f 696e 6974 004e 4554 574f 524b 5f53  n/init NETWORK_S
    4b49 505f 454e 534c 4156 4544 3d00 5445  KIP_ENSLAVED= TE
    524d 3d6c 696e 7578 0042 4f4f 545f 494d  RM=linux BOOT_IM
    4147 453d 2f76 6d6c 696e 757a 2d36 2e31  AGE=/vmlinuz-6.1
    342e 302d 3333 2d67 656e 6572 6963 0064  4.0-33-generic.d
    726f 705f 6361 7073 3d00 5041 5448 3d2f  rop_caps= PATH=/
    7573 722f 6c6f 6361 6c2f 7362 696e 3a2f  usr/local/sbin:/
    7573 722f 6c6f 6361 6c2f 6269 6e3a 2f75  usr/local/bin:/u
    7372 2f73 6269 6e3a 2f75 7372 2f62 696e  sr/sbin:/usr/bin
    3a2f 7362 696e 3a2f 6269 6e00 5057 443d  :/sbin:/bin PWD=
    2f00 726f 6f74 6d6e 743d 2f72 6f6f 7400  / rootmnt=/root
&lt;/code&gt;
    &lt;p&gt;This static layout can’t easily be modified or extended; the program must copy those variables into its own data structure. Let’s look at how Bash, C, and Python store envvars internally. I analyzed their source code and here is a summary.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bash&lt;/head&gt;
    &lt;p&gt;It stores the variables in a hashmap. Or, more precisely, in a stack of hashmaps.&lt;/p&gt;
    &lt;p&gt;When you spawn a new process using Bash, it traverses the stack of hashmaps to find variables marked as exported and copies them into the environment array passed to the child.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Side note: Why is traversing the stack needed?&lt;/p&gt;&lt;p&gt;Each function invocation in Bash creates a new local scope – a new entry on the stack. If you declare your variable with&lt;/p&gt;&lt;code&gt;local&lt;/code&gt;, it ends up in this locally-scoped hashmap.&lt;p&gt;What’s interesting is that you can export a&lt;/p&gt;&lt;code&gt;local&lt;/code&gt;variable too!&lt;code&gt;function locallyScoped() { local PATH="$PATH:/opt/secret/bin" export PATH env # &amp;lt;- sees the PATH with /opt/scecret/bin } locallyScoped env # &amp;lt;- sees the PATH without modification&lt;/code&gt;&lt;p&gt;I wouldn’t have learned this without diving into Bash source. My intuitive (wrong) assumption was that&lt;/p&gt;&lt;code&gt;export&lt;/code&gt;automatically makes the variable global – like&lt;code&gt;declare -g&lt;/code&gt;! Super interesting stuff.&lt;/quote&gt;
    &lt;head rend="h3"&gt;The default C library on Linux: &lt;code&gt;glibc&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;glibc&lt;/code&gt; exposes a dynamic &lt;code&gt;environ&lt;/code&gt; array, managed via &lt;code&gt;putenv&lt;/code&gt; and &lt;code&gt;getenv&lt;/code&gt;
library functions. It uses an array, so the time complexity of &lt;code&gt;getenv&lt;/code&gt; and
&lt;code&gt;putenv&lt;/code&gt; is linear in the number of envvars. Remember – envvars are not a
high-performance dictionary and you should not abuse them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Python&lt;/head&gt;
    &lt;p&gt;Python couples its environment to the C library, which can cause surprising inconsistencies.&lt;/p&gt;
    &lt;p&gt;If you’ve programmed some Python, you’ve probably used the &lt;code&gt;os.environ&lt;/code&gt;
dictionary. On startup, &lt;code&gt;os.environ&lt;/code&gt; is built from the C library’s &lt;code&gt;environ&lt;/code&gt;
array.&lt;/p&gt;
    &lt;p&gt;But those dictionary values are NOT the “ground truth” for child processes. Rather, each change to &lt;code&gt;os.environ&lt;/code&gt; invokes the native &lt;code&gt;os.putenv&lt;/code&gt; function,
which in turn calls the C library’s &lt;code&gt;putenv&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note that the propagation is one-directional: modifying&lt;/p&gt;&lt;code&gt;os.environ&lt;/code&gt;will call&lt;code&gt;os.putenv&lt;/code&gt;, but not the other way around. Call&lt;code&gt;os.putenv&lt;/code&gt;, and&lt;code&gt;os.environ&lt;/code&gt;won’t be updated.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Liberal format&lt;/head&gt;
    &lt;p&gt;The Linux kernel is very liberal about the format of environment variables, and so is &lt;code&gt;glibc&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For example, your C program can manipulate the environment – the global &lt;code&gt;environ&lt;/code&gt; array – such that several variables share the same name but have
different values. And when you execute a child process, it will inherit this
“broken” setup.&lt;/p&gt;
    &lt;p&gt;You don’t even need an equals sign separating name from value! The usual entry is &lt;code&gt;NAME=VALUE&lt;/code&gt;, but nothing prevents you from adding &lt;code&gt;NONSENSE_WITH_EMOJI 😀&lt;/code&gt;
to the array.&lt;/p&gt;
    &lt;p&gt;The kernel happily accepts any null-terminated string as an “environment variable” definition. It just imposes a size limitation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Single variable: 128 KiB on a typical x64 Intel CPU. This is for the whole definition – name + equal sign + value. It’s computed as&lt;/p&gt;&lt;code&gt;PAGE_SIZE * 32&lt;/code&gt;. No modern hardware uses pages smaller than 4 KiB, so you can treat it as a lower bound, unless you need to deal with some legacy embedded systems.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Total: 2 MiB on a typical machine. This limit is shared by envvars and the command line arguments. The calculation is a bit more complicated (see the&lt;/p&gt;&lt;code&gt;execve(2)&lt;/code&gt;man page):&lt;code&gt;max(32 * PAGE_SIZE, min(MAX_STACK_SIZE / 4, 6 MB))&lt;/code&gt;&lt;p&gt;On a typical system, the limiting factor is the&lt;/p&gt;&lt;code&gt;MAX_STACK_SIZE&lt;/code&gt;. Remember, initially the envvars are dumped on the stack! To prevent unpredictable crashes, the system allows only 1/4 of the stack for the envvars.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Quirks&lt;/head&gt;
    &lt;p&gt;But the fact that you can do something does not mean that you should. For example, if you start Bash with the “broken” environment – duplicated names and entries without &lt;code&gt;=&lt;/code&gt; – it deduplicates the variables and drops the nonsense.&lt;/p&gt;
    &lt;p&gt;One interesting edge case is a space inside the variable name. My beloved shell – Nushell – has no problem with the following assignment:&lt;/p&gt;
    &lt;code&gt;$env."Deployment Environment" = "prod"
&lt;/code&gt;
    &lt;p&gt;Python is fine with it, too. Bash, on the other hand, can’t reference it because whitespace isn’t allowed in variable names. Fortunately, the variable isn’t lost – Bash keeps such entries in a special hashmap called &lt;code&gt;invalid_env&lt;/code&gt; and still passes them to child processes.&lt;/p&gt;
    &lt;head rend="h2"&gt;The standard format&lt;/head&gt;
    &lt;p&gt;So what name and value can you safely use for your envvar? A popular misconception, repeated on StackOverflow and by ChatGPT, is that POSIX permits only uppercase envvars, and everything else is undefined behavior.&lt;/p&gt;
    &lt;p&gt;But this is seriously NOT what the standard says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;These strings have the form name=value; names shall not contain the character ‘=’. For values to be portable across systems conforming to POSIX.1-2017, the value shall be composed of characters from the portable character set (except NUL and as indicated below). There is no meaning associated with the order of strings in the environment. If more than one string in an environment of a process has the same name, the consequences are undefined.&lt;/p&gt;
      &lt;p&gt;Environment variable names used by the utilities in the Shell and Utilities volume of POSIX.1-2017 consist solely of uppercase letters, digits, and the &amp;lt;underscore&amp;gt; ( ‘_’ ) from the characters defined in Portable Character Set and do not begin with a digit. Other characters may be permitted by an implementation; applications shall tolerate the presence of such names. Uppercase and lowercase letters shall retain their unique identities and shall not be folded together. The name space of environment variable names containing lowercase letters is reserved for applications. Applications can define any environment variables with names from this name space without modifying the behavior of the standard utilities.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, POSIX-specified utilities use uppercase envvars, but that’s not prescriptive for your programs. Quite the contrary: you’re encouraged to use lowercase for your envvars so they don’t collide with the standard tools.&lt;/p&gt;
    &lt;p&gt;The only strict rule is that a variable name cannot contain an equals sign. POSIX requires compliant applications to preserve all variables that conform to this rule.&lt;/p&gt;
    &lt;p&gt;But in reality, not many applications use lowercase. The proper etiquette in software development is to use &lt;code&gt;ALL_UPPERCASE&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;My pragmatic recommendation is…&lt;/head&gt;
    &lt;p&gt;…to use &lt;code&gt;^[A-Z_][A-Z0-9_]*$&lt;/code&gt; for names, and UTF-8 for values. You shouldn’t
hit problems on Linux. If you want to be super safe: instead of UTF-8, use the
POSIX-mandated Portable Character Set
(PCS) – essentially
ASCII without control characters.&lt;/p&gt;
    &lt;p&gt;Please subscribe to my RSS feed! 😇&lt;/p&gt;
    &lt;p&gt;Independent blogging is not possible without RSS. Start using RSS today.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wow, I really enjoyed writing this…&lt;/head&gt;
    &lt;p&gt;…and I hope it wasn’t a boring read.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://allvpv.org/haotic-journey-through-envvars/"/><published>2025-10-13T16:49:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45570720</id><title>Optery (YC W22) – Hiring Tech Lead with Node.js Experience (U.S. &amp; Latin America)</title><updated>2025-10-13T20:11:29.134052+00:00</updated><content>&lt;doc fingerprint="738af76944b7ba2c"&gt;
  &lt;main&gt;
    &lt;p&gt;Skip to content Use promo code: 04SxyxNX at checkout for 20% Off 🎉 with Optery’s Fall Sale! 🍁 Getting Started Personal Business Pricing Personal Business Sites We Cover Family Business Optery for Business Partnership Program API for Partners Book Optery for Business Demo Client Stories Business Use Cases PII Removal for Execs is Not Enough Guide to Enterprise Data Removal Services Resources Help Desk Blog Data Broker Directory For High-Risk Communities About Us Opt Out Guides Product Updates Customer Reviews Optery in the Press Search Toggle search Sign In Sign Up Free Getting Started Personal Business Pricing Personal Business Sites We Cover Family Business Optery for Business Partnership Program API for Partners Book Optery for Business Demo Client Stories Business Use Cases PII Removal for Execs is Not Enough Guide to Enterprise Data Removal Services Resources Help Desk Blog Data Broker Directory For High-Risk Communities About Us Opt Out Guides Product Updates Customer Reviews Optery in the Press Careers Ready to safeguard your personal data? Join the movement of people strengthening their privacy Sign Up Free&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.optery.com/careers/"/><published>2025-10-13T17:03:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45570973</id><title>America's future could hinge on whether AI slightly disappoints</title><updated>2025-10-13T20:11:28.823037+00:00</updated><content>&lt;doc fingerprint="7fe089016e6199bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;America's future could hinge on whether AI slightly disappoints&lt;/head&gt;
    &lt;head rend="h3"&gt;If the economy's single pillar goes down, Trump's presidency will be seen as a disaster.&lt;/head&gt;
    &lt;p&gt;A burning question that’s on a lot of people’s minds right now is: Why is the U.S. economy still holding up? The manufacturing industry is hurting badly from Trump’s tariffs, the payroll numbers are looking weak, and consumer sentiment is at Great Recession levels:&lt;/p&gt;
    &lt;p&gt;And yet despite those warning signs, there has been nothing even remotely resembling an economic crash yet. Unemployment is rising a little bit but still extremely low, while the prime-age employment rate — my favorite single indicator of the health of the labor market — is still near all-time highs. The New York Fed’s GDP nowcast thinks that GDP growth is currently running at a little over 2%, while the Atlanta Fed’s nowcast puts it even higher.&lt;/p&gt;
    &lt;p&gt;One possibility is that everything is just fine with the economy — that Trump’s tariffs aren’t actually that high because of all the exemptions, and/or that economists are exaggerating the negative effects of tariffs in the first place. Weak consumer confidence could be a partisan “vibecession”, payroll slowdown could be from illegal immigrants being deported or leaving en masse, and manufacturing’s woes could be from some other sector-specific factor.&lt;/p&gt;
    &lt;p&gt;Another possibility is that tariffs are bad, but are being canceled out by an even more powerful force — the AI boom. The FT reports:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Pantheon Macroeconomics estimates that US GDP would have grown at a mere 0.6 per cent annualised rate in the first half were it not for AI-related spending, or half the actual rate.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Paul Kedrosky came up with similar numbers. Jason Furman does a slightly different calculation, and arrives at an even starker number:&lt;/p&gt;
    &lt;p&gt;And here’s an impressive chart:&lt;/p&gt;
    &lt;p&gt;The Economist writes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[L]ook beyond AI and much of the economy appears sluggish. Real consumption has flatlined since December. Jobs growth is weak. Housebuilding has slumped, as has business investment in non-AI parts of the economy[.]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And in a post entitled “America is now one big bet on AI”, Ruchir Sharma writes that “AI companies have accounted for 80 per cent of the gains in US stocks so far in 2025.” In fact, more than a fifth of the entire S&amp;amp;P 500 market cap is now just three companies — Nvidia, Microsoft, and Apple — two of which are basically big bets on AI.&lt;/p&gt;
    &lt;p&gt;Now as Furman points out, this doesn’t necessarily mean that without AI, the U.S. economy would be stalling out. If the economy wasn’t pouring resources into AI, it might be pouring them into something else, spurring growth that was almost as fast as what we actually saw. But it’s also possible that without AI, America would be crashing from tariffs.&lt;/p&gt;
    &lt;p&gt;Trump certainly seems to think AI is a golden goose worth protecting. Joey Politano points out that even as Trump has slapped tariffs on a plethora of industries, he has left AI and its supply chain mostly untouched:&lt;/p&gt;
    &lt;p&gt;But despite Trump’s tariff exemptions, the AI sector could very well crash in the next year or two. And if it does, it could do a lot more than just hurt Americans’ employment prospects and stock portfolios.&lt;/p&gt;
    &lt;p&gt;If AI is really the only thing protecting America from the scourge of Trump’s tariffs, then a bust in the sector could change the country’s entire political economy. A crash and recession would immediately flip the narrative on Trump’s whole presidency, much as the housing crash of 2008 cemented George W. Bush’s legacy as a failure. And because Trump’s second term is looking so transformative1, the fate of the AI sector could potentially determine the entire fate of the country.&lt;/p&gt;
    &lt;p&gt;So a whole lot is riding on the question of whether an AI bust will crash the economy. The stakes could hardly be higher.&lt;/p&gt;
    &lt;head rend="h4"&gt;The case everyone is making for an AI bubble&lt;/head&gt;
    &lt;p&gt;A lot of bubbles are purely financial beasts, driven by irrationality or coordination problems in the markets for stocks, bonds, and derivatives. For example, you can have a speculative bubble, in which a bunch of people know an asset is overpriced, but think they can sell out before the crash, and so they keep buying and buying and pushing the price up and up. You can also have an extrapolative bubble, when people see the price of something going up and up, and mistakenly decide that it must be due to some underlying positive trend.&lt;/p&gt;
    &lt;p&gt;But a much simpler possibility is that investors could make a big mistake about how valuable some technology is. They could honestly believe that AI is going to create immense amounts of value, and they could just end up being wrong. Then when they realize that the technology isn’t all it’s cracked up to be, they could temper their expectations, which would cause a price crash in AI stocks.2 But the stock crash wouldn’t be the real problem; far more painful would be the wave of loan defaults and financial distress that would result from AI’s actual shortcomings.&lt;/p&gt;
    &lt;p&gt;If there’s an AI crash, it’ll probably be this latter type. Jeff Bezos calls it an “industrial bubble”, and I think that’s as good a name as any. This kind of bubble is still a financial phenomenon, since the banking system gets hurt. But the cause is a mistake about real technology, rather than asset markets going haywire.&lt;/p&gt;
    &lt;p&gt;Everyone who’s talking about an AI bubble is basically warning that the technology itself might disappoint. For example, here are some excerpts from a big Bloomberg feature about the possibility of an AI bubble:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Even some of AI’s biggest cheerleaders acknowledge the market is frothy, while still professing their belief in the technology’s long-term potential. AI, they say, is poised to reshape multiple industries, cure diseases and generally accelerate human progress…Yet never before has so much money been spent so rapidly on a technology that, for all its potential, remains somewhat unproven as a profit-making business model…&lt;/p&gt;
      &lt;p&gt;The data center spending spree is overshadowed by persistent skepticism about the payoff from AI technology. In August, investors were rattled after researchers at the Massachusetts Institute of Technology found that 95% of organizations saw zero return on their investment in AI initiatives.&lt;/p&gt;
      &lt;p&gt;More recently, researchers at Harvard and Stanford offered a possible explanation for why. Employees are using AI to create “workslop,” which the researchers define as “AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task.”…&lt;/p&gt;
      &lt;p&gt;AI developers have also been confronting a different challenge. OpenAI…Anthropic and others have for years bet on the so-called scaling laws…Over the past year, however, these developers have experienced diminishing returns…Some have also struggled to match their own hype. After months of touting GPT-5 as a significant leap, OpenAI’s release of its latest AI model in August was met with mixed reviews…&lt;/p&gt;
      &lt;p&gt;There’s also the risk that the AI industry’s vast data center buildout, entailing a huge increase in electricity consumption, will be held back by the realities of strained national power networks.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When you bring up concerns like this to an AI engineer, executive, or founder, they tend to just smile at you indulgently, secure in the knowledge that their invention is everything it’s cracked up to be, and that much better things are already in the pipeline.&lt;/p&gt;
    &lt;p&gt;But this doesn’t reassure me. Because when we look at the history of industrial bubbles, and of new technologies in general, it becomes clear that in order to cause a crash, AI doesn’t have to fail. It just has to mildly disappoint the most ardent optimists.&lt;/p&gt;
    &lt;p&gt;This is why I think an AI crash is more likely than a lot of people in the tech world — or the Trump administration — realize.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why AI could crash even if AI is just as useful as the optimists expect&lt;/head&gt;
    &lt;head rend="h2"&gt;Keep reading with a 7-day free trial&lt;/head&gt;
    &lt;p&gt;Subscribe to Noahpinion to keep reading this post and get 7 days of free access to the full post archives.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether"/><published>2025-10-13T17:24:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571814</id><title>Programming in Assembly Is Brutal, Beautiful, and Maybe Even a Path to Better AI</title><updated>2025-10-13T20:11:28.698902+00:00</updated><content>&lt;doc fingerprint="e6910170b05c4ffe"&gt;
  &lt;main&gt;
    &lt;p&gt;Rollercoaster Tycoon wasn’t the most fashionable computer game out there in 1999. But if you took a look beneath the pixels—the rickety rides, the crowds of hungry, thirsty, barfing people (and the janitors mopping in their wake)—deep down at the level of the code, you saw craftsmanship so obsessive that it bordered on insane. Chris Sawyer, the game’s sole developer, wrote the whole thing in assembly.&lt;/p&gt;
    &lt;p&gt;Certain programming languages, like Python or Go or C++, are called “high-level” because they work sort of like human language, written in commands and idioms that might fit in at a poetry slam. Generally speaking, a piece of software like a compiler transforms this into what the machine really reads: blocks of 1s and 0s (or maybe hex) that tell actual transistors how to behave. Assembly, the lowest of the “low-level” languages, has a near one-to-one correspondence with the machine’s native tongue. It’s coding straight to metal. To build a complex computer game from assembly is like weaving a tapestry from shedded cat fur.&lt;/p&gt;
    &lt;p&gt;Why would anyone do this? I recently asked Sawyer, who lives in his native Scotland. He told me that efficiency was one reason. In the 1990s, the tools for high-level programming weren’t all there. Compilers were terribly slow. Debuggers sucked. Sawyer could avoid them by doing his own thing in x86 assembly, the lingua franca of Intel chips.&lt;/p&gt;
    &lt;p&gt;We both knew that wasn’t the real reason, though. The real reason was love. Before turning to roller coasters, Sawyer had written another game in assembly, Transport Tycoon. It puts players in charge of a city’s roads, rail stations, runways, and ports. I imagined Sawyer as a model-train hobbyist—laying each stretch of track, hand-sewing artificial turf, each detail a choice and a chore. To move these carefully crafted pixels from bitmaps to display, Sawyer had to coax out the chip’s full potential. “RollerCoaster Tycoon only came about because I was familiar with the limits of what was possible,” he told me.&lt;/p&gt;
    &lt;p&gt;Working within the limits? A foreign idea, perhaps, in this age of digital abundance, when calling a single function in an AI training algorithm can engage a million GPUs. With assembly, you get one thing and one thing only, and it is the thing you ask for—even, as many a coder has learned the hard way, if it is wrong. Assembly is brutal and beautiful that way. It requires you to say exactly what you mean.&lt;/p&gt;
    &lt;p&gt;I’ve done assembly’s creators a disservice. They wanted things to be easier, not harder. I imagine they were tired of loading up punchcards and flipping switches on their steampunk leviathans. Perhaps they dreamed of a world like ours, where computers can do so much with such minimal guidance.&lt;/p&gt;
    &lt;p&gt;The first assembly language, created in the 1940s by Kathleen Booth (though she has not always gotten her due, surprise surprise), hardly resembled language. Codes stood in for codes. To tell the machine to perform an operation—say, “0,0111” in machine code—you’d instead employ a series of letters and symbols, which a new piece of software, called an assembler, would translate into binary. Soon, the commands got human-friendlier mnemonics like “MOV.”&lt;/p&gt;
    &lt;p&gt;To know assembly was to know the CPU itself—what it could do and, even more, what it couldn’t. A chip’s physical design, how the circuits connecting the logic gates of AND and XOR are actually laid, defines how it works. Its functions are pretty basic, breaking down instructions into elementary steps: Fetch something from memory and put it in a temporary cubby, known as a register. Decode it there. Perform some operations, like comparing two values, or adding them. Ship it back off the memory.&lt;/p&gt;
    &lt;p&gt;As chips advanced, new dialects of assembly evolved. The code that landed the first human on the moon was assembly—designed for only one chip, the Apollo 11 Guidance Computer. If you want to read the leaked source code of the Furby, you’ll need fluency in 6502. To hack your Ti-83 calculator, you’ll need z80. Learning the language of one chip—say, Intel’s x86—and then moving to Arm is like studying Arabic in Beirut and then trying to get by in Tunis or Khartoum. Good luck.&lt;/p&gt;
    &lt;p&gt;I learned x86 assembly in college as a refugee from math. Where my classmates seemed to enjoy the drab incantations of Java, I loved the logic game that was assembly. It was easy to fail, but to fail in ways that were explainable if you looked at the circuits and registers. How masterful I felt coding in the simple commands of this not-quite-language; how fragile I knew that mastery to be. To say, put these bytes there—no, there, at that register, in those capacitors. Remember this. Forget that. To grind away, painting each figurine, one by one.&lt;/p&gt;
    &lt;p&gt;It’s true that there’s no longer much point in using assembly in the day-to-day work of coding. High-level languages are so efficient that their abstraction is almost always preferable. Even assembly’s inventor moved on to other ventures; one of Booth’s final papers, in the 1990s, used neural networks to match seals with their barks. Sawyer switched over too. He’s been dabbling in home automation recently—lights, temperature sensors, sound systems, and the like, coded on Raspberry Pis using Python, which he initially found “quite off-putting,” he told me. But even on that tiny processor, it gets the job done just fine.&lt;/p&gt;
    &lt;p&gt;Then along comes something like DeepSeek to remind you that humans can still communicate better with our hardware. Earlier this year, the Chinese company that made these incredibly efficient AI models upended the narrative that AI advancement can come only from more chips and more energy. Assembly was one surprising reason. DeepSeek’s engineers reached into the subfloor of Nvidia’s chips, commanding each individual machine to compress data from 32 bits to 8 bits—sacrificing precision for efficiency—at precisely the right moments. Observers were stunned. You could do that? The DeepSeek engineers had tapped an art most others had forgotten.&lt;/p&gt;
    &lt;p&gt;I was similarly taken when, in 2023, researchers at DeepMind taught a machine x86 assembly, then asked it to improve on the long-standing sort() function in C. The AI made strange, unintuitive choices, performing odd jumps between registers, and in the end cut precisely one step. A fraction of a millisecond saved, perhaps. But happening countless times a day, now that the new algorithm has been officially adopted.&lt;/p&gt;
    &lt;p&gt;To me, it was a reminder that we humans created these machines, and even as they appear to spiral into complexity beyond our comprehension, they remain under our command. We can always make them work better. It was like what Sawyer said when he recounted his recent Raspberry Pi–enabled home coding experiment. It was probably just his imagination, but the display had been a little laggy, he thought. He’d redo the code if he could, he said. But alas, Sawyer and the machine did not speak the same assembly language.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.wired.com/story/programming-assembly-artificial-intelligence/"/><published>2025-10-13T18:37:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571918</id><title>Reverse Engineering a 1979 Camera's Spec</title><updated>2025-10-13T20:11:28.558516+00:00</updated><content>&lt;doc fingerprint="2ece9e338d31439f"&gt;
  &lt;main&gt;
    &lt;p&gt;I bought a 1979 Chinon CM-4 film camera in Tijuana. Film is expensive, so before wasting a roll I decided to learn exactly how this machine works â by taking apart its specs, one line at a time.&lt;/p&gt;
    &lt;p&gt;So here is my three step plan&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Understand what I really have in my hands. Michael Butkus created a comprehensive document that covers the details and specifications of the Chinon CM 4. My main goal with this document (aside from knowing what every button does) is to understand the specs and know exactly how every aspect influences the photos captured.&lt;/item&gt;
      &lt;item&gt;Make sense of the numbers on my lens. I was hoping that lenses would make sense by themselvesâthe only easy part is to make it focus and unfocusâso at least knowing what my lens in particular can do is a must. I’m also curious about how optics and the actual process of taking a picture work.&lt;/item&gt;
      &lt;item&gt;Take photographs. I’m doing all of these steps just to know which technical skills I’m lacking. Once I have the theory, I can start putting everything into action by taking interesting photographs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;My Camera&lt;/head&gt;
    &lt;p&gt;Here are some pictures of the camera I bought (they were taken with an iPhone, so chill).&lt;/p&gt;
    &lt;p&gt;As you can see by the big labels at the front view of the camera, it is a Chinon CM-4. Chinon was a small Japanese maker of SLRs in the â70s. In 2004 Kodak bought them, but in 1979 this was just another independent company making clever machines.&lt;/p&gt;
    &lt;p&gt;This camera specifically started to be fabricated in 1979, and I wasn’t able to find much information on when it was discontinued.&lt;/p&gt;
    &lt;p&gt;It has a brother called the CM-4S, which only differs by having a self-timer added. I don’t really know what it is, but I’m looking forward to finding out.&lt;/p&gt;
    &lt;p&gt;And yeah, I think that is really all the history that we need to know about this camera.&lt;/p&gt;
    &lt;head rend="h2"&gt;Specification&lt;/head&gt;
    &lt;p&gt;There is this guy called Michael Butkus who created a website for manuals for old cameras, and of course, he has a manual for the Chinon CM-4. This is right now the holy grail for understanding what I have in my hands.&lt;/p&gt;
    &lt;p&gt;So let’s start by analyzing each spec according to the document:&lt;/p&gt;
    &lt;head rend="h3"&gt;What 35mm SLR with an LED Meter Really Means&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Type: 35 mm SLR compact camera with LED type light measuring system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let’s break down the whole sentence.&lt;/p&gt;
    &lt;p&gt;35 mm refers to the film that can be used with this camera. In the metric system, 1 millimeter is 1/1000 of a meter or 0.1 centimeters (or about 1.38 inches). This is exactly the measurement of the film from top to bottom; you can even use a ruler to verify that.&lt;/p&gt;
    &lt;p&gt;SLR stands for Single Lens Reflex, which is a type of camera design that means you look through the same lens that you take the picture with. There are other types like Rangefinder, which has a separate optical window for seeing the target. Here is a diagram of a digital SLR, but the same concepts apply here too.&lt;/p&gt;
    &lt;p&gt;Since the light bounces from the prism into the viewfinder, you are seeing exactly how the picture will look. This avoids parallax errors, which are the kind of errors that arise when there is a difference between what you see and what the camera captures. This is also known as TTL or Through The Lens viewing.&lt;/p&gt;
    &lt;p&gt;And now, the final part: LED type light measuring system.&lt;/p&gt;
    &lt;p&gt;This refers to this part on the back of the camera:&lt;/p&gt;
    &lt;p&gt;It’s the three LEDs next to the viewfinder. They are three colors, each with its own meaning: red for overexposed, green for correct, and yellow for underexposed. So let’s take a look at what exposure actually is.&lt;/p&gt;
    &lt;p&gt;Exposure basically involves three different things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;ISO â The greater the ISO the greater the sensitivity, faster films need less light for the same exposure. Film is created with a certain ISO so there is no way to change that; the greater the ISO, the brighter the image will be, but also a lot of grain (known as noise in digital cammeras) will be introduced.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aperture â This controls the amount of light that the lens receives inside itself. This is used for controlling the depth of field, so you can blur the background.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shutter speed â How fast the shutter opens up to allow light to enter the film. This can also be used for controlling motion blur.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So basically, for the light meter to work, it has an independent sensor that measures light, checks the ISO, aperture, and shutter speed, and gives you a preview when you half-click the shooting button, telling you if it’s too much light, too little, or the right amount.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why 35mm Film Produces 24Ã36mm Photos&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Picture Format: 24 x 36 mm.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;35mm film somehow makes 24Ã36mm photos. The trick? The film runs sideways Obviously, it’s because this is done sideways, as shown in this picture:&lt;/p&gt;
    &lt;p&gt;Consequently, you ask yourself, why 35mm? Historically, before film, still photography plates were the norm, and Kodak sold 70mm plates. But a guy named Edison with his pal Dickson wanted to take more pictures, so they cut them in half, doubling the amount of pictures they could take. Why did it stay? Larger film is more expensive and smaller will look more grainy, especially in cinemas. And since equipment for manufacturing and distributing is expensive, standardization was needed. Basically, it was the right compromise at the right time.&lt;/p&gt;
    &lt;p&gt;Film is exactly where the magic happens; the camera is just a dark box that lets light enter for a tiny moment. Black and white film consists of a clever combination of chemicals into layers that, when exposed to light, will modify silver and create a negative of the image you just captured. For color film, it’s a bit more complex, but the same principle appliesâit has more layers combining dye and silver.&lt;/p&gt;
    &lt;p&gt;We generally use the term grain to refer to the silver that makes up the photo. The more sensitive the film is, the bigger those grains will be, and this is why film photos have little imperfections. These grains can also be linked to ISOâthe greater the ISO, the greater the size of the grain.&lt;/p&gt;
    &lt;p&gt;The revelation of film, also known as development, is also a chemical process that goes through a bunch of chemicals sequentially:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Development is also the name for the first step; it’s for stabilizing the silver. If it stays too long, it can ruin the image by augmenting the grain, losing details, and creating excessive contrast.&lt;/item&gt;
      &lt;item&gt;Stop bath â Stops these chemicals from developing by using more chemicals.&lt;/item&gt;
      &lt;item&gt;Fixing â Removes all the unexposed silver, and from now on it is no longer light sensitive.&lt;/item&gt;
      &lt;item&gt;Washing â Lastly, we wash the chemicals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In theory, you can do this; kits are for sale for developing color and black and white film, but it can be extremely toxic if you are not careful. I think it’s something I’m not really interested in, just because of the risk it implies.&lt;/p&gt;
    &lt;p&gt;This is why you should never open the back of my camera when it’s loadedâit will expose the film to light and fog those frames. Also, if you notice, you can’t reshoot in the same way as in digital; it will superimpose both pictures. Actually, I think when loading the first film into my camera, it actually got a bit exposed to light (sad).&lt;/p&gt;
    &lt;head rend="h3"&gt;Why the Mirror Slaps â and How Engineers Made It Shockless&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Mirror: Large, quick return, shockless system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Once light passes through the lens, it reaches the reflex mirror. Its job is to direct light up through the prism to the viewfinder, letting you see exactly what the camera will capture.&lt;/p&gt;
    &lt;p&gt;As shown above, the mirror sits in front of the film. When you press the shutter button, the mirror flips up, allowing light to hit the film and trigger the chemical reaction that records the image. Early cameras kept the mirror hidden when film wasnât loaded, so you couldnât see through the viewfinder until you advanced to the next frame. The quick return system was invented so the mirror would immediately return to its position after a shot, restoring your view.&lt;/p&gt;
    &lt;p&gt;Because the mirror moves rapidly before the shutter opens, older cameras produced a noticeable vibration (also known as slap) that could cause motion blur at slower shutter speeds. A shockless system uses springs and cushions to absorb this impact, minimizing vibration.&lt;/p&gt;
    &lt;p&gt;A larger mirror lets more light reach the prism, resulting in a brighter, clearer viewfinder image.&lt;/p&gt;
    &lt;head rend="h3"&gt;From Cloth Curtains to Compact Metal Blades: The Seiko Shutter&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Shutter: Seiko MFC metal focal plane shutter.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The shutter is the part of the camera that opens to let light hit the film and capture an image. The one in this camera looks like this:&lt;/p&gt;
    &lt;p&gt;Seiko, a Japanese manufacturer now known for watches, built these shutters with a reputation for engineering and precision.&lt;/p&gt;
    &lt;p&gt;MFC stands for âMetal Focal-plane Compact.â Metal is specified because early cameras used cloth curtains; metal shutters are more durable, consistent, and capable of higher speeds. Hereâs a camera with a cloth curtain:&lt;/p&gt;
    &lt;p&gt;Focal-plane means the shutter sits right in front of the film inside the camera body, enabling faster shutter speeds. It exposes the film from top to bottom:&lt;/p&gt;
    &lt;p&gt;An alternative is the leaf shutter, which is built into the lens near the aperture. Leaf shutters are bulkier and more complex, but produce less vibration and capture images in a circular pattern from the outside in:&lt;/p&gt;
    &lt;p&gt;Early focal-plane shutters were large, gear-heavy, and used cloth curtains, limiting how compact cameras could be. By the late 1970s, manufacturers like Seiko refined shutters into smaller, lighter modules, making mass production and standardization possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;From 1 Second to 1/1000 of a Second to Freeze Time&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Shutter Speeds: 1 sec. - 1/1000 sec., “B”.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Shutter speed determines how long the cameraâs shutter stays open, controlling how much light reaches the film. On this camera, you can choose speeds from 1 second (long exposure) to 1/1000 of a second (very fast).&lt;/p&gt;
    &lt;p&gt;Thereâs also a âBâ (Bulb) mode, which keeps the shutter open for as long as you hold down the shutter releaseâuseful for long exposures like night photography.&lt;/p&gt;
    &lt;p&gt;Slower shutter speeds (like 1s or Bulb) let in more light and can create motion blur, while faster speeds (like 1/1000s) freeze action and reduce brightness.&lt;/p&gt;
    &lt;p&gt;This range covers most situations for film photographers using ISO 100â400. For lower ISO (25â100), youâll need slower speeds or Bulb mode to avoid underexposure. With higher ISO (800â1600), even the fastest shutter speed may let in too much light, risking overexposure.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Viewfinder Recreates Reality&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewfinder: Fixed eye-level pentaprism, central split image with microprism collar and ground glass.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When photography was first invented, images were captured in a dark room with a tiny holeâthis âcamera obscuraâ (Latin for âdark chamberâ) projected an inverted image onto a surface inside. Light travels in straight lines, so the scene outside appears upside down and reversed.&lt;/p&gt;
    &lt;p&gt;To let us see the image right-side up through the viewfinder, the camera uses a pentaprismâa five-sided prism that cleverly flips the light back to its original orientation. In this camera, the pentaprism sits at eye level, so what you see matches the scene in front of you.&lt;/p&gt;
    &lt;p&gt;Manual focusing aids help you get sharp images. The central split image is a circle in the middle of the viewfinder, divided in half; when the subject is in focus, the two halves align perfectly. Surrounding this is the microprism collarâif the image is out of focus, it appears grainy; when focused, the grain disappears.&lt;/p&gt;
    &lt;p&gt;All of this sits on ground glass, which has a matte texture created by tiny scratches. This diffuses the light, allowing you to see the image clearly from any angleâordinary glass wouldnât work, as it doesnât scatter light.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why the Scene Looks Smaller Through the Camera&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewfinder Magnification: 0.87x (id 50 mm, 00).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Viewfinder magnification tells you how large the scene appears when you look through the viewfinder compared to seeing it with your naked eye. A value of 0.87x means the viewfinder image is 13% smaller than life-size. For comparison, hereâs an original picture and another one scaled down by 13%:&lt;/p&gt;
    &lt;p&gt;This only affects what you see through the viewfinder, not the actual photo captured.&lt;/p&gt;
    &lt;p&gt;The parentheses specify the conditions for this specific magnification, itâs with a 50mm lens focused at infinity. Infinity might seem a bit abstract but basically it tells you that the lens is adjusted to receive from far away. The spec lists “00” instead of the infinity symbol, since not everyone could print it. This lets you compare magnification across different lenses.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why You See Less Than Whatâs Captured&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewfinder Visibility: 92%.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This specification tells you how much of the actual photo area you can see through the viewfinder. With 92% visibility, about 8% of the imageâmostly around the edgesâwonât be visible when you compose your shot.&lt;/p&gt;
    &lt;p&gt;Achieving 100% viewfinder visibility requires a larger, more precisely aligned prism and mirror, which adds weight and cost. Most SLRs offer 90â95% visibility to keep cameras lighter and more affordable.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Camera Helps You With Exposure&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Exposure Meter: TTL, Center weighted full aperture system employing one silicon blue photo cell, 3 steps exposure indicator with 3 LEDs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The exposure meter uses a silicon blue photo cell to measure light. When photons hit the silicon surface, they knock electrons loose, creating a small electric current proportional to the light intensity. Based on the ISO and aperture settings, the meter provides feedback on whether your shot will be overexposed or underexposed.&lt;/p&gt;
    &lt;p&gt;Hereâs a visual example of underexposed and overexposed photos:&lt;/p&gt;
    &lt;p&gt;TTL (Through The Lens) means the meter measures the light that actually passes through the lens, so any lens changes or filters will affect the exposure reading.&lt;/p&gt;
    &lt;p&gt;Center weighted means the meter prioritizes light from the center of the frame over the edges.&lt;/p&gt;
    &lt;p&gt;A full aperture system keeps the viewfinder bright by measuring light at the lensâs maximum aperture. When you take a photo, the lens stops down to your chosen aperture only for the instant of exposure.&lt;/p&gt;
    &lt;p&gt;Unfortunately, the light meter on my camera doesnât work. But since exposure is a physical process, I can use a phone app to measure light and determine the right settings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exposure Value: Turning Camera Settings Into Numbers&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Exposure Range: EV+2 (F/1.9, 1 sec.) to EV+18 (F/16, 1/1000 sec.) - ASA 100 F/1.9 lens.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is probably the most technical line, packed with symbols and acronyms.&lt;/p&gt;
    &lt;p&gt;As mentioned earlier, aperture is the part of the lens that controls how much light enters. Its unit is the f-stop, defined as:&lt;/p&gt;
    &lt;code&gt;f_number = f / d

where

f = focal length of the lens
d = diameter of the entrance pupil
&lt;/code&gt;
    &lt;p&gt;Because lenses have multiple glass elements that bend light, we use the concept or optical center to refer to the point where light can be treated as if it bent once, usually referring to the last glass element. The focal length is the distance (in mm) from the lensâs optical center to the film.&lt;/p&gt;
    &lt;p&gt;Aperture blades create a circular opening that limits how much light passes through. The entrance pupil is the perceived diameter (in mm) of this opening, as seen through the front glassâsince the glass can change how large the hole appears.&lt;/p&gt;
    &lt;p&gt;The larger the denominator in the f-number, the smaller the opening.&lt;/p&gt;
    &lt;p&gt;EV stands for Exposure Value. It represents a combination of aperture and shutter speed for a given ISO. EV 0â6 means a dark scene, EV 7â12 is normal daylight, and EV 12â18 is very bright.&lt;/p&gt;
    &lt;p&gt;To calculate EV for any settings, use:&lt;/p&gt;
    &lt;code&gt;EV_iso = log2((n^2) / t) - log2(iso/100)

or for ISO 100:

EV_100 = log2((n^2) / t)

where 

iso = ISO number of the film
n = f-number
t = shutter speed in seconds
&lt;/code&gt;
    &lt;p&gt;The light meter receives the EV from the sensor and compares it to this formula. If the measured value is higher, itâs overexposed; if lower, itâs underexposed.&lt;/p&gt;
    &lt;p&gt;Here, the spec means the light meter can measure correctly from EV 2 (f/1.9, 1 secâthe brightest setting) to EV 18 (f/16, 1/1000 secâthe darkest setting), using ISO 100 and a lens with a maximum aperture of f/1.9.&lt;/p&gt;
    &lt;p&gt;If you use higher ISO, the range shifts downwardâthe camera can meter darker scenes. This happens because, in the formula, higher ISO with the same settings lowers the EV.&lt;/p&gt;
    &lt;p&gt;For setting aperture manually, we can use the Sunny 16 rule, set your shutter speed as close as possible to your ISO, then choose the aperture based on lighting conditions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;f/16 â bright sun&lt;/item&gt;
      &lt;item&gt;f/11 â sun with a few clouds&lt;/item&gt;
      &lt;item&gt;f/8 â mostly cloudy&lt;/item&gt;
      &lt;item&gt;f/5.6 â overcast or outdoor shade&lt;/item&gt;
      &lt;item&gt;f/4 â deep shade&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For other situations (like indoors), it’s best to use a light meter.&lt;/p&gt;
    &lt;head rend="h3"&gt;From ASA &amp;amp; DIN to ISO&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;ASA Range: 25-1600 (DIN 15-33) with safety lock.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Previously, film sensitivity was measured using two standards: ASA (American Standards Association), mainly used in the US, and DIN (Deutsches Institut fÃ¼r Normung), used in Europe. ASA uses a linear scale, while DIN is logarithmic.&lt;/p&gt;
    &lt;p&gt;In 1974, the International Organization for Standardization (ISO) unified these standards. Today, we refer to film sensitivity simply as ISOâlike ISO 100 or ISO 400. The higher the ISO number, the more sensitive the film is to light. Note that “ISO” here refers to the rating, not the actual ISO standard number.&lt;/p&gt;
    &lt;p&gt;Relevant ISO standards for film include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ISO 6: Black &amp;amp; white negatives&lt;/item&gt;
      &lt;item&gt;ISO 2240: Color negatives&lt;/item&gt;
      &lt;item&gt;ISO 5800: Slide (reversal) films&lt;/item&gt;
      &lt;item&gt;ISO 2720: How meters and film speed are linked (exposure index)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Chinon CM-4 supports film speeds from ISO 25 (low sensitivity, for bright conditions) to ISO 1600 (high sensitivity, for low light).&lt;/p&gt;
    &lt;p&gt;The safety lock means you can’t accidentally change the ISO setting. On this camera, you must pull the dialâs edge and rotate it to set your desired ISO.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Camera Syncs Light and Shutter&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Synchronization: Strobe sync at 1/60 sec.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In photography, “flash” usually refers to any burst of light used to illuminate a scene, but technically, a “strobe” is an electronic flash unit that emits a very short, intense pulse of light.&lt;/p&gt;
    &lt;p&gt;Synchronization ensures the flash fires precisely when the shutter is fully open. This is called X-sync, which is designed for electronic xenon flashes (named for the gas inside the bulb). Other sync types, like M-sync or FP-sync, were used for older flash technologies.&lt;/p&gt;
    &lt;p&gt;On this camera, the fastest shutter speed for safe flash use is 1/60 second. Using a faster speed will only light part of the image. Slower speeds (below 1/60 second) allow more ambient light into the photoâthis technique is called slow sync.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the K-Mount Let Different Brands Share Lenses&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Lens Mount: Chinon Universal Bayonet Mount.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This piece allows the lens to mount to the camera. It looks something like this:&lt;/p&gt;
    &lt;p&gt;Basically, this is a Penta K-Mount, a standard that was adopted by Chinon and the rest of the market for 35mm SLR cameras, so you can use a bunch of lenses by a bunch of manufacturers.&lt;/p&gt;
    &lt;head rend="h3"&gt;How Film Moves, Counts, and Rewinds&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Film Advance: Single stroke in an arc of 130Â° with 25Â° stand off.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;At the top right of the camera is a lever for advancing the film and cocking the shutter for the next shot.&lt;/p&gt;
    &lt;p&gt;To use it, swing the lever through a 130-degree arc. When at rest, the lever isnât lockedâit has 25 degrees of free movement, making it easier to grip and operate.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Film Counter: Automatically indicates number of exposures and resets to “S” when camera back is opened.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Next to the lever is a counter that shows how many shots youâve taken. Opening the camera back resets it to “S” (start); after the first advance, it moves to 0.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Film Rewind: Folding crank type.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Film rolls typically have 24 to 36 frames, but the camera doesnât track this. If you shoot past the end, you may overlap exposures.&lt;/p&gt;
    &lt;p&gt;When the roll is finished, rewind manually using the crank handle. It stays folded when not in use; lift it 90 degrees to rewind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lenses&lt;/head&gt;
    &lt;p&gt;Letâs start with the obvious question: why do we need a lens? Weâve learned that taking pictures with film is a physical reaction between light and chemicals inside a cleverly built black box. So, whatâs the purpose of adding lenses?&lt;/p&gt;
    &lt;p&gt;Light can be described as rays for simplicity, but in reality, it behaves more like a wave. If you take a picture without a lens, the film receives light from all directions, overexposing the frame and creating a completely white image.&lt;/p&gt;
    &lt;p&gt;You might think, âJust use a tiny pinhole so only a small amount of light entersââlike the camera obscura mentioned earlier.&lt;/p&gt;
    &lt;p&gt;With a tiny pinhole (and nothing in between), everything is in focus, but you lose detail due to diffraction. Only a limited number of rays (or waves) enter, and you need to keep the shutter open longer. If you increase the pinhole size, the image becomes blurrier because rays overlap.&lt;/p&gt;
    &lt;p&gt;Using a curved glass (a lens) gathers much more light, bends it (refraction), and focuses it to a single point on the image plane, creating a sharp image.&lt;/p&gt;
    &lt;p&gt;This happens because the pinhole limits the light that enters, meaning it will loose some amount of information, while the lens bends it, mapping all light into a single point in the frame. But only one plane can be on focus with a lens because it can only bend the light from one distance perfectly at a time.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Lens&lt;/head&gt;
    &lt;p&gt;By googling around, we can find that this is an Auto Chinon 50mm f/1.9&lt;/p&gt;
    &lt;p&gt;Let’s check the fron of the lens first&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Auto Chinon: This was one of the most mainstream lens series in the 1960sâ80s, paired with Chinon’s SLR cameras. “Auto” refers to the lens typeâit maintains full exposure while focusing and composing, allowing all light to reach the viewfinder. When you take a picture, it mechanically adjusts the aperture to your chosen setting. This is different from older “preset” lenses, where setting the f-stop made the viewfinder darker.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;50mm: As previously mentioned, the focal length is the distance from the lensâs optical center to the film. This is considered a “standard” or “normal” lens because it gives a field of view close to what the human eye naturally sees, making it very versatile.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1:1.9: This is the maximum aperture of the lens. In modern notation, it should be expressed as f/1.9. For this lens, the aperture diameter is 26.3mm. The notation is written as a ratio, where 1 represents a unit of focal length, which in this lens is 50mm.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;49Ã: This is the diameter of the filter threadâthe size of the spiral at the front of the lens. It specifies what accessory size (like filters) you can attach. You can still use larger filters with a step-up or step-down adapter ring.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Made in Japan: You don’t expect me to explain this one, right?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And finally let’s figure out what these crazy looking numbers around the lens mean.&lt;/p&gt;
    &lt;head rend="h2"&gt;Controlling the Actual Aperture&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;16 &amp;amp;mldr; 1.9&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the scale the lens has for aperture, each known as full stop. Each succesive number halves the amount of light entering.&lt;/p&gt;
    &lt;p&gt;These numbers are not evenly spaced because depends on the area of the circle, so it involves the radius, meaning the diameter divided by 2, which ends up in the f-stop being multiplied by the square root of 2 to define its full stop.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Far Can You Focus&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;ft m &amp;amp;mldr;&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the focus distance scale, the green line will tell you (on meters and feets) at what distance your lense is focused. As previously mentioned the infinity mark means very far objects, which in practice for a 50mm lens is around 30-50 meters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Depth of Field Helper&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;16 &amp;amp;mldr; | &amp;amp;mldr; 16&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is known as the DOF or Depth Of Field scale. The line at the middle specifies the focus point, meaning that objects at exactly that will be perfectly sharp. Because of optics, objects a bit in front or behind will also look sharp, this extra sharpness zone is the DOF.&lt;/p&gt;
    &lt;p&gt;In essence, this scale shows: “When you set the aperture to f/X, objects between Y and Z distances will appear sharp”.&lt;/p&gt;
    &lt;head rend="h1"&gt;Some of my Pictures&lt;/head&gt;
    &lt;p&gt;Seems like I loaded the film incorrectly and nothing was on them, so I hate my life right now. Let’s skip this part then.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;By exploring my cameraâs specs, Iâve learned how cameras work and gained insight into their evolution. Itâs amazing how clever chemistry and engineering made it possible for anyone to capture moments, and in a time where everyone feels that was a long time ago.&lt;/p&gt;
    &lt;p&gt;If youâve read this far, I hope youâre inspired to stay curious, explore new topics, google things around, use chatgpt as a mentor, and appreciate what weâve achieved as humans. I may not become a photographer, but the process of learning and writing this blog has been incredibly rewarding.&lt;/p&gt;
    &lt;p&gt;I havenât done anything impressive with my new camera yet, but at least I know my challenge is creativity, not technical knowledge.&lt;/p&gt;
    &lt;p&gt;To sum it up: The real lesson is that specs are a roadmap, whether itâs cameras, computers, or chemistry, manuals are underrated teachers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.mano.lol/posts/film/"/><published>2025-10-13T18:45:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45572130</id><title>Ask HN: Has AI stolen the satisfaction from programming?</title><updated>2025-10-13T20:11:28.381596+00:00</updated><content>&lt;doc fingerprint="a3c191c91af6bd96"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I've been trying to articulate why coding feels less pleasant now.&lt;/p&gt;
      &lt;p&gt;The problem: You can't win anymore.&lt;/p&gt;
      &lt;p&gt;The old way: You'd think about the problem. Draw some diagrams. Understand what you're actually trying to do. Then write the code. Understanding was mandatory. You solved it.&lt;/p&gt;
      &lt;p&gt;The new way: The entire premise of AI coding tools is to automate the thinking, not just the typing. You're supposed to describe a problem and get a solution without understanding the details. That's the labor-saving promise.&lt;/p&gt;
      &lt;p&gt;So I feel pressure to always, always, start by info dumping the problem description to AI and gamble for a one-shot. Voice transcription for 10 minutes, hit send, hope I get something first try, if not hope I can iterate until something works. And when even something does work = zero satisfaction because I don't have the same depth of understanding of the solution. Its no longer my code, my idea. It's just some code I found online. `import solution from chatgpt`&lt;/p&gt;
      &lt;p&gt;If I think about the problem, I feel inefficient. "Why did you waste 2 hours on that? AI would've done it in 10 minutes."&lt;/p&gt;
      &lt;p&gt;If I use AI to help, the work doesn't feel like mine. When I show it to anyone, the implicit response is: "Yeah, I could've prompted for that too."&lt;/p&gt;
      &lt;p&gt;The steering and judgment I apply to AI outputs is invisible. Nobody sees which suggestions I rejected, how I refined the prompts, or what decisions I made. So all credit flows to the AI by default.&lt;/p&gt;
      &lt;p&gt;The result: Nothing feels satisfying anymore. Every problem I solve by hand feels too slow. Every problem I solve with AI feels like it doesn't count. There's this constant background feeling that whatever I just did, someone else would've done it better and faster.&lt;/p&gt;
      &lt;p&gt;I was thinking of all the classic exploratory learning blog posts. Things that sounded fun. Writing a toy database to understand how they work, implementing a small Redis clone. Now that feels stupid. Like I'd be wasting time on details the AI is supposed to handle. It bothers me that my reaction to these blog posts has changed so much. 3 years ago I would be bookmarking a blog post to try it out for myself that weekend. Now those 200 lines of simple code feels only one sentence prompt away and thus waste of time.&lt;/p&gt;
      &lt;p&gt;Am I alone in this?&lt;/p&gt;
      &lt;p&gt;Does anyone else feel this pressure to skip understanding? Where thinking feels like you're not using the tool correctly? In the old days, I understood every problem I worked on. Now I feel pressure to skip understanding and just ship. I hate it.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45572130"/><published>2025-10-13T19:07:15+00:00</published></entry></feed>