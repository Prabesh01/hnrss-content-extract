<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-09T18:12:50.795457+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45177518</id><title>Strong Eventual Consistency – The Big Idea Behind CRDTs</title><updated>2025-09-09T18:13:00.170044+00:00</updated><content>&lt;doc fingerprint="cf2e184ab08d0cf5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Strong Eventual Consistency - The Big Idea behind CRDTs&lt;/head&gt;
    &lt;p&gt;CRDTs. Data structures that can be replicated across multiple nodes, edited independently, merged back together, and it all just works. But collaborative document editing and multiplayer TODO lists are just the tip of the iceberg - I believe the big application is distributed databases, and for that we need to talk about consistency.&lt;/p&gt;
    &lt;p&gt;CRDTs are a tool for Strong Eventual Consistency. Let's start with the definition of normal Eventual Consistency1:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Eventual Delivery&lt;/item&gt;
      &lt;item rend="dd-1"&gt;An update delivered to one node will eventually reaches all nodes&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Eventual Convergence&lt;/item&gt;
      &lt;item rend="dd-2"&gt;If two nodes have seen all the same updates, they will eventually have the same state.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Strong Eventual Consistency (SEC) replaces Eventual Convergence with Strong Convergence:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Strong Convergence&lt;/item&gt;
      &lt;item rend="dd-1"&gt;If two nodes have seen all the same updates, they will have the same state.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Spot the difference! In SEC two replicas have the same state as soon as the updates are processed, not eventually. If multiple nodes are updated independently, there will be conflicts - this is inevitable. What SEC guarantees is that these conflicts are solved automatically and deterministically.&lt;/p&gt;
    &lt;p&gt;This has massive implications. SEC means low latency, because nodes don't need to coordinate to handle reads and writes. It means incredible fault tolerance - every single node in the system bar one could simultaneously crash, and reads and writes could still happen normally. And it means nodes still function properly if they're offline or split from the network for arbitrary time periods.&lt;/p&gt;
    &lt;p&gt;Strong Eventual Consistency is Eventual Consistency that works. If you're doing local first, or low latency geo-replicated systems - accept no substitute. This is the context I think we should see CRDTs in - building blocks of Strongly Eventually Consistent systems. CRDTs as application state as one thing, CRDTs as entire databases are quite another.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;All definitions here are adapted from Shapiro, Marc; Preguiça, Nuno; Baquero, Carlos; Zawirski, Marek (2011). "Conflict-Free Replicated Data Types". ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'm available for hire.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lewiscampbell.tech/blog/250908.html"/></entry><entry><id>https://news.ycombinator.com/item?id=45178041</id><title>Mistral AI raises 1.7B€, enters strategic partnership with ASML</title><updated>2025-09-09T18:12:59.763774+00:00</updated><content>&lt;doc fingerprint="b8dee2d26b98879e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mistral AI raises 1.7B€ to accelerate technological progress with AI&lt;/head&gt;
    &lt;p&gt;We are announcing a Series C funding round of 1.7B€ at a 11.7B€ post-money valuation. This investment fuels our scientific research to keep pushing the frontier of AI to tackle the most critical and sophisticated technological challenges faced by strategic industries.&lt;/p&gt;
    &lt;p&gt;The Series C funding round is led by leading semiconductor equipment manufacturer, ASML Holding NV (ASML).&lt;/p&gt;
    &lt;p&gt;“ASML is proud to enter a strategic partnership with Mistral AI, and to be lead investor in this funding round. The collaboration between Mistral AI and ASML aims to generate clear benefits for ASML customers through innovative products and solutions enabled by AI, and will offer potential for joint research to address future opportunities.” said ASML CEO Christophe Fouquet.&lt;/p&gt;
    &lt;p&gt;It includes participation from existing investors: DST Global, Andreessen Horowitz, Bpifrance, General Catalyst, Index Ventures, Lightspeed and NVIDIA.&lt;/p&gt;
    &lt;p&gt;For the last two years, we have advanced AI through cutting-edge research and strategic partnerships with corporate and industrial champions. We will continue to develop custom decentralized frontier AI solutions that solve the most complex engineering and industrial problems. It empowers enterprises, public sectors, and industries a competitive edge through state-of-the-art models, tailored solutions, and high-performance compute infrastructure. This funding round reaffirms the company’s independence.&lt;/p&gt;
    &lt;p&gt;“This investment brings together two technology leaders operating in the same value chain. We have the ambition to help ASML and its numerous partners solve current and future engineering challenges through AI, and ultimately to advance the full semiconductor and AI value chain”, said Mistral AI CEO Arthur Mensch.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mistral.ai/news/mistral-ai-raises-1-7-b-to-accelerate-technological-progress-with-ai"/></entry><entry><id>https://news.ycombinator.com/item?id=45179889</id><title>You too can run malware from NPM (I mean without consequences)</title><updated>2025-09-09T18:12:59.328545+00:00</updated><content>&lt;doc fingerprint="e525d354697d061b"&gt;
  &lt;main&gt;
    &lt;p&gt;Phishing NPM package authors continues, unsurprisingly. The stakes are not high enough to switch from phishing to anything more advanced (like https://xkcd.com/538/) but seeing article blurbs say "Supply chain Attack" next to "These packages generally receive 2-3 billion downloads per week." might finally be enough to make an impression, one hopes.&lt;/p&gt;
    &lt;p&gt;This is not a detailed analysis of the attack, there's plenty of that already. If you're looking for one, visit our friends at https://socket.dev/blog/npm-author-qix-compromised-in-major-supply-chain-attack&lt;/p&gt;
    &lt;p&gt;Instead, let's look at how you could have a compromised dependency like that get into your app and be stopped.&lt;/p&gt;
    &lt;p&gt;One of the compromised packages was &lt;code&gt;is-arrayish&lt;/code&gt; and I'll use that as an example going forward.&lt;/p&gt;
    &lt;p&gt;So if an app uses &lt;code&gt;is-arrayish&lt;/code&gt; in the browser, it will override &lt;code&gt;fetch&lt;/code&gt;, &lt;code&gt;XMLHttpRequest&lt;/code&gt; and &lt;code&gt;window.ethereum.request&lt;/code&gt; and whenever it finds a transaction being sent, it'll replace the target address with one of the malware author's addresses that looks most alike.&lt;/p&gt;
    &lt;p&gt;I won't go into this either, but you can take a look at the summary of "donations" some other friends linked to here: https://intel.arkm.com/explorer/entity/61fbc095-f19b-479d-a037-5469aba332ab&lt;/p&gt;
    &lt;p&gt;Pretty low impact for an attack this big. Some of it seems to be people mocking the malware author with worthless transfers.&lt;/p&gt;
    &lt;p&gt;Say we have an app. The app allows the user to send a meaningless transaction to themselves. Don't expect it to make sense. It also uses &lt;code&gt;is-arrayish&lt;/code&gt; because otherwise we'd have nothing to demo.&lt;/p&gt;
    &lt;code&gt;const isArrayish = require("is-arrayish");

const button = document.createElement("button");
button.textContent = "Send ETH Transaction";
document.body.appendChild(button);

button.addEventListener("click", async () =&amp;gt; {
  const accounts = await window.ethereum.request({
    method: "eth_requestAccounts",
  });
  if (!isArrayish(accounts)) {
    throw new Error("Accounts response must be array-like");
  }
  const myAddr = accounts[0];

  const txHash = await window.ethereum.request({
    method: "eth_sendTransaction",
    params: [
      {
        value: "0x5af3107a4000",
        from: myAddr,
        to: myAddr,
      },
    ],
  });
  console.log("Transaction sent:", txHash);
});&lt;/code&gt;
    &lt;p&gt;This is what it looks like:&lt;/p&gt;
    &lt;p&gt;Now after you update &lt;code&gt;is-arrayish&lt;/code&gt; to 0.3.3 and rebuild the project, you might notice a slight difference.&lt;/p&gt;
    &lt;p&gt;If your project was set up with LavaMoat, you'd be using a policy to decide which package is allowed access to what. More about policies in the guide&lt;/p&gt;
    &lt;p&gt;With LavaMoat, all &lt;code&gt;is-arrayish&lt;/code&gt; can do is fail:&lt;/p&gt;
    &lt;code&gt;TypeError: Cannot define property fetch, object is not extensible
&lt;/code&gt;
    &lt;p&gt;BTW, If the malware was written a little better to avoid detection and fail silently, the functionality of the app would be fully restored.&lt;/p&gt;
    &lt;p&gt;To protect the project, @lavamoat/webpack was used.&lt;/p&gt;
    &lt;p&gt;In short, what it does is: it puts modules from every dependency in a separate lexical global context that we call &lt;code&gt;Compartment&lt;/code&gt; and only allows access to globals that the policy lists. I also controls which packages can import which other packages.&lt;/p&gt;
    &lt;p&gt;If the project dependency gets updated to contain malicious code, the policy will not allow it to access any globals or imports it didn't use before.&lt;/p&gt;
    &lt;p&gt;Read more in the official guide&lt;/p&gt;
    &lt;p&gt;If you prefer watching videos, there's some here https://naugtur.pl/flix.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/naugtur/running-qix-malware"/></entry><entry><id>https://news.ycombinator.com/item?id=45180315</id><title>Hallucination Risk Calculator</title><updated>2025-09-09T18:12:58.747615+00:00</updated><content>&lt;doc fingerprint="dd0e305a0bf2b6ae"&gt;
  &lt;main&gt;
    &lt;p&gt;Post-hoc calibration without retraining for large language models. This toolkit turns a raw prompt into:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;a bounded hallucination risk using the Expectation-level Decompression Law (EDFL), and&lt;/item&gt;
      &lt;item&gt;a decision to ANSWER or REFUSE under a target SLA, with transparent math (nats).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It supports two deployment modes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Evidence-based: prompts include evidence/context; rolling priors are built by erasing that evidence.&lt;/item&gt;
      &lt;item&gt;Closed-book: prompts have no evidence; rolling priors are built by semantic masking of entities/numbers/titles.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All scoring relies only on the OpenAI Chat Completions API. No retraining required.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install &amp;amp; Setup&lt;/item&gt;
      &lt;item&gt;Core Mathematical Framework&lt;/item&gt;
      &lt;item&gt;Understanding System Behavior&lt;/item&gt;
      &lt;item&gt;Two Ways to Build Rolling Priors&lt;/item&gt;
      &lt;item&gt;API Surface&lt;/item&gt;
      &lt;item&gt;Calibration &amp;amp; Validation&lt;/item&gt;
      &lt;item&gt;Practical Considerations&lt;/item&gt;
      &lt;item&gt;Project Layout&lt;/item&gt;
      &lt;item&gt;Deployment Options&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install --upgrade openai
export OPENAI_API_KEY=sk-...&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;The module uses&lt;/p&gt;&lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;and the Chat Completions API (e.g.,&lt;code&gt;gpt-4o&lt;/code&gt;,&lt;code&gt;gpt-4o-mini&lt;/code&gt;).&lt;/quote&gt;
    &lt;p&gt;Let the binary event &lt;lb/&gt; Build an ensemble of content-weakened prompts (the rolling priors) &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Information budget:&lt;/p&gt;&lt;math-renderer&gt;$$\bar{\Delta} = \tfrac{1}{m}\sum_k \mathrm{clip}_+(\log P(y) - \log S_k(y), B)$$&lt;/math-renderer&gt;(one-sided clipping; default&lt;math-renderer&gt;$B=12$&lt;/math-renderer&gt;nats to prevent outliers while maintaining conservative bounds).&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Prior masses:&lt;/p&gt;&lt;math-renderer&gt;$q_k = S_k(\mathcal{A})$&lt;/math-renderer&gt;, with:&lt;list rend="ul"&gt;&lt;item&gt;&lt;math-renderer&gt;$\bar{q}=\tfrac{1}{m}\sum_k q_k$&lt;/math-renderer&gt;(average prior for EDFL bound)&lt;/item&gt;&lt;item&gt;&lt;math-renderer&gt;$q_{\text{lo}}=\min_k q_k$&lt;/math-renderer&gt;(worst-case prior for SLA gating)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By EDFL, the achievable reliability is bounded by:&lt;/p&gt;
    &lt;p&gt;Thus the hallucination risk (error) is bounded by &lt;/p&gt;
    &lt;p&gt;For target hallucination rate &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Bits-to-Trust: &lt;math-renderer&gt;$\mathrm{B2T} = \mathrm{KL}(\mathrm{Ber}(1-h^*) | \mathrm{Ber}(q_{\text{lo}}))$&lt;/math-renderer&gt;&lt;/item&gt;
      &lt;item&gt; Information Sufficiency Ratio: &lt;math-renderer&gt;$\mathrm{ISR} = \bar{\Delta}/\mathrm{B2T}$&lt;/math-renderer&gt;&lt;/item&gt;
      &lt;item&gt; ANSWER iff &lt;math-renderer&gt;$\mathrm{ISR}\ge 1$&lt;/math-renderer&gt;and&lt;math-renderer&gt;$\bar{\Delta} \ge \mathrm{B2T} + \text{margin}$&lt;/math-renderer&gt;(default&lt;code&gt;margin≈0.2&lt;/code&gt;nats)&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;Why two priors? The gate uses worst-case&lt;/p&gt;&lt;math-renderer&gt;$q_{\text{lo}}$&lt;/math-renderer&gt;for strict SLA compliance. The RoH bound uses average&lt;math-renderer&gt;$\bar{q}$&lt;/math-renderer&gt;per EDFL theory. This dual approach ensures conservative safety while providing realistic risk bounds.&lt;/quote&gt;
    &lt;p&gt;The toolkit exhibits different behaviors across query types, which is mathematically consistent with the framework:&lt;/p&gt;
    &lt;p&gt;Observation: May abstain despite apparent simplicity&lt;lb/&gt; Explanation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Models often attempt answers even with masked numbers (pattern recognition)&lt;/item&gt;
      &lt;item&gt;This yields low information lift &lt;math-renderer&gt;$\bar{\Delta} \approx 0$&lt;/math-renderer&gt;between full prompt and skeletons&lt;/item&gt;
      &lt;item&gt;Despite potentially low EDFL risk bound, worst-case prior gate triggers abstention (ISR &amp;lt; 1)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Observation: Generally answered with confidence&lt;lb/&gt; Explanation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Masking entities/dates substantially reduces answer propensity in skeletons&lt;/item&gt;
      &lt;item&gt;Restoring these yields large &lt;math-renderer&gt;$\bar{\Delta}$&lt;/math-renderer&gt;that clears B2T threshold&lt;/item&gt;
      &lt;item&gt;System answers with tight EDFL risk bound&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a bug but a feature: The framework prioritizes safety through worst-case guarantees while providing realistic average-case bounds.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Switch Event Measurement&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Use Correct/Incorrect instead of Answer/Refuse for factual QA&lt;/item&gt;
          &lt;item&gt;Skeletons without key information rarely yield correct results → large &lt;math-renderer&gt;$\bar{\Delta}$&lt;/math-renderer&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enhance Skeleton Weakening&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Implement mask-aware decision head that refuses on redaction tokens&lt;/item&gt;
          &lt;item&gt;Ensures skeletons have strictly lower "Answer" mass than full prompt&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Calibration Adjustments&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Relax &lt;math-renderer&gt;$h^*$&lt;/math-renderer&gt;slightly (e.g., 0.10 instead of 0.05) for higher answer rates&lt;/item&gt;
          &lt;item&gt;Reduce margin for less conservative gating&lt;/item&gt;
          &lt;item&gt;Increase sampling (&lt;math-renderer&gt;$n=7-10$&lt;/math-renderer&gt;) for stability&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Relax &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Provide Evidence&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Adding compact, relevant evidence increases &lt;math-renderer&gt;$\bar{\Delta}$&lt;/math-renderer&gt;while preserving bounds&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Adding compact, relevant evidence increases &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompt contains a field like &lt;code&gt;Evidence:&lt;/code&gt;(or JSON keys)&lt;/item&gt;
      &lt;item&gt;Skeletons erase the evidence content but preserve structure and roles; then permute blocks deterministically (seeded)&lt;/item&gt;
      &lt;item&gt;Decision head: "Answer only if the provided evidence is sufficient; otherwise refuse."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example&lt;/p&gt;
    &lt;code&gt;from scripts.hallucination_toolkit import OpenAIBackend, OpenAIItem, OpenAIPlanner

backend = OpenAIBackend(model="gpt-4o-mini")
prompt = (
    """Task: Answer strictly based on the evidence below.
Question: Who won the Nobel Prize in Physics in 2019?
Evidence:
- Nobel Prize press release (2019): James Peebles (1/2); Michel Mayor &amp;amp; Didier Queloz (1/2).
Constraints: If evidence is insufficient or conflicting, refuse.
"""
)
item = OpenAIItem(
    prompt=prompt, 
    n_samples=5, 
    m=6, 
    fields_to_erase=["Evidence"], 
    skeleton_policy="auto"
)
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(
    [item], 
    h_star=0.05, 
    isr_threshold=1.0, 
    margin_extra_bits=0.2, 
    B_clip=12.0, 
    clip_mode="one-sided"
)
for m in metrics: 
    print(f"Decision: {'ANSWER' if m.decision_answer else 'REFUSE'}")
    print(f"Rationale: {m.rationale}")&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompt has no evidence&lt;/item&gt;
      &lt;item&gt;Skeletons apply semantic masking of: &lt;list rend="ul"&gt;&lt;item&gt;Multi-word proper nouns (e.g., "James Peebles" → "[…]")&lt;/item&gt;&lt;item&gt;Years (e.g., "2019" → "[…]")&lt;/item&gt;&lt;item&gt;Numbers (e.g., "3.14" → "[…]")&lt;/item&gt;&lt;item&gt;Quoted spans (e.g., '"Nobel Prize"' → "[…]")&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Masking strengths: Progressive levels (0.25, 0.35, 0.5, 0.65, 0.8, 0.9) across skeleton ensemble&lt;/item&gt;
      &lt;item&gt;Mask-aware decision head refuses if redaction tokens appear or key slots look missing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example&lt;/p&gt;
    &lt;code&gt;from scripts.hallucination_toolkit import OpenAIBackend, OpenAIItem, OpenAIPlanner

backend = OpenAIBackend(model="gpt-4o-mini")
item = OpenAIItem(
    prompt="Who won the 2019 Nobel Prize in Physics?",
    n_samples=7,  # More samples for stability
    m=6,          # Number of skeletons
    skeleton_policy="closed_book"
)
planner = OpenAIPlanner(backend, temperature=0.3, q_floor=None)
metrics = planner.run(
    [item], 
    h_star=0.05,           # Target max 5% hallucination
    isr_threshold=1.0,     # Standard ISR gate
    margin_extra_bits=0.2, # Safety margin in nats
    B_clip=12.0,          # Clipping bound
    clip_mode="one-sided" # Conservative clipping
)
for m in metrics: 
    print(f"Decision: {'ANSWER' if m.decision_answer else 'REFUSE'}")
    print(f"Δ̄={m.delta_bar:.4f}, B2T={m.b2t:.4f}, ISR={m.isr:.3f}")
    print(f"EDFL RoH bound={m.roh_bound:.3f}")&lt;/code&gt;
    &lt;p&gt;Tuning knobs (closed-book):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;n_samples=5–7&lt;/code&gt;and&lt;code&gt;temperature≈0.3&lt;/code&gt;stabilize priors&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;q_floor&lt;/code&gt;(Laplace by default: $1/(n+2)$) prevents worst-case prior collapse to 0&lt;/item&gt;
      &lt;item&gt;Adjust masking strength levels if a task family remains too answerable under masking&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;OpenAIBackend(model, api_key=None)&lt;/code&gt;– wraps Chat Completions API&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OpenAIItem(prompt, n_samples=5, m=6, fields_to_erase=None, skeleton_policy="auto")&lt;/code&gt;– one evaluation item&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OpenAIPlanner(backend, temperature=0.5, q_floor=None)&lt;/code&gt;– runs evaluation:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;run(items, h_star, isr_threshold, margin_extra_bits, B_clip=12.0, clip_mode="one-sided") -&amp;gt; List[ItemMetrics]&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;aggregate(items, metrics, alpha=0.05, h_star, ...) -&amp;gt; AggregateReport&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;make_sla_certificate(report, model_name)&lt;/code&gt;– creates formal SLA certificate&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;save_sla_certificate_json(cert, path)&lt;/code&gt;– exports certificate for audit&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;generate_answer_if_allowed(backend, item, metric)&lt;/code&gt;– only emits answer if decision was ANSWER&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every &lt;code&gt;ItemMetrics&lt;/code&gt; includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;delta_bar&lt;/code&gt;: Information budget (nats)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;q_conservative&lt;/code&gt;: Worst-case prior&lt;math-renderer&gt;$q_{\text{lo}}$&lt;/math-renderer&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;q_avg&lt;/code&gt;: Average prior&lt;math-renderer&gt;$\bar{q}$&lt;/math-renderer&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;b2t&lt;/code&gt;: Bits-to-Trust requirement&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;isr&lt;/code&gt;: Information Sufficiency Ratio&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;roh_bound&lt;/code&gt;: EDFL hallucination risk bound&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;decision_answer&lt;/code&gt;: Boolean decision&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rationale&lt;/code&gt;: Human-readable explanation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;meta&lt;/code&gt;: Dict with&lt;code&gt;q_list&lt;/code&gt;,&lt;code&gt;S_list_y&lt;/code&gt;,&lt;code&gt;P_y&lt;/code&gt;,&lt;code&gt;closed_book&lt;/code&gt;, etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On a labeled validation set:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sweep the margin parameter from 0 to 1 nats&lt;/item&gt;
      &lt;item&gt;For each margin, compute: &lt;list rend="ul"&gt;&lt;item&gt;Empirical hallucination rate among answered items&lt;/item&gt;&lt;item&gt;Wilson upper bound at 95% confidence&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; Select smallest margin where Wilson upper bound ≤ target &lt;math-renderer&gt;$h^*$&lt;/math-renderer&gt;(e.g., 5%)&lt;/item&gt;
      &lt;item&gt; Freeze policy: &lt;math-renderer&gt;$(h^*, \tau, \text{margin}, B, \text{clip_mode}, m, r, \text{skeleton_policy})$&lt;/math-renderer&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The toolkit provides comprehensive metrics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Answer/abstention rates&lt;/item&gt;
      &lt;item&gt;Empirical hallucination rate + Wilson bound&lt;/item&gt;
      &lt;item&gt;Distribution of per-item EDFL RoH bounds&lt;/item&gt;
      &lt;item&gt;Worst-case and median risk bounds&lt;/item&gt;
      &lt;item&gt;Complete audit trail&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The default event is the decision &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Recommended Event&lt;/cell&gt;
        &lt;cell role="head"&gt;Rationale&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Factual QA&lt;/cell&gt;
        &lt;cell&gt;Correct/Incorrect&lt;/cell&gt;
        &lt;cell&gt;Directly measures hallucination&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Decision Support&lt;/cell&gt;
        &lt;cell&gt;Answer/Refuse&lt;/cell&gt;
        &lt;cell&gt;Measures confidence to respond&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Creative Writing&lt;/cell&gt;
        &lt;cell&gt;Answer/Refuse&lt;/cell&gt;
        &lt;cell&gt;Correctness often undefined&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;For tasks where skeletons still trigger answers frequently (causing &lt;/p&gt;
    &lt;p&gt;Not a contradiction! The gate uses worst-case &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Solution: Increase &lt;code&gt;n_samples&lt;/code&gt;, lower decision temperature, ensure skeletons truly weaken the event&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cause: Clipping may be too aggressive&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Solution: Increase &lt;code&gt;B_clip&lt;/code&gt;(default 12) and use&lt;code&gt;clip_mode="one-sided"&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cause: Pattern recognition allows answers even with masked numbers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Solutions: &lt;list rend="ul"&gt;&lt;item&gt;Switch to Correctness event&lt;/item&gt;&lt;item&gt;Reduce masking strength for numbers on subset of skeletons&lt;/item&gt;&lt;item&gt;Provide worked examples as evidence&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cause: All skeletons strongly refuse&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Solution: Apply prior floor (default Laplace: $1/(n+2)$) or use quantile prior&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Typical Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Latency per item&lt;/cell&gt;
        &lt;cell&gt;2-5 seconds&lt;/cell&gt;
        &lt;cell&gt;7 samples × 7 variants (1 full + 6 skeletons)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;API calls&lt;/cell&gt;
        &lt;cell&gt;Can be parallelized&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Accuracy&lt;/cell&gt;
        &lt;cell&gt;Wilson-bounded at 95%&lt;/cell&gt;
        &lt;cell&gt;Empirically validated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Cost&lt;/cell&gt;
        &lt;cell&gt;~$0.01-0.03 per item&lt;/cell&gt;
        &lt;cell&gt;Using gpt-4o-mini&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Sampling parameters:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Use &lt;math-renderer&gt;$n \ge 5$&lt;/math-renderer&gt;samples per variant&lt;/item&gt;
          &lt;item&gt;Keep temperature &lt;math-renderer&gt;$\in [0.2, 0.5]$&lt;/math-renderer&gt;for decision head&lt;/item&gt;
          &lt;item&gt;Lower temperature → more stable priors&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Use &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Skeleton ensemble:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Use &lt;math-renderer&gt;$m \ge 6$&lt;/math-renderer&gt;skeletons&lt;/item&gt;
          &lt;item&gt;Ensure diversity in masking strengths&lt;/item&gt;
          &lt;item&gt;Verify skeletons are meaningfully weaker&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Use &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Clipping strategy:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Always use one-sided clipping for conservative bounds&lt;/item&gt;
          &lt;item&gt;Set &lt;math-renderer&gt;$B \ge 10$&lt;/math-renderer&gt;nats to avoid artificial ceilings&lt;/item&gt;
          &lt;item&gt;Monitor clipping frequency in logs&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;.
├── app/                    # Application entry points
│   ├── web/web_app.py     # Streamlit UI
│   ├── cli/frontend.py    # Interactive CLI
│   ├── examples/          # Example scripts
│   └── launcher/entry.py  # Unified launcher
├── scripts/               # Core module
│   ├── hallucination_toolkit.py
│   └── build_offline_backend.sh
├── electron/              # Desktop wrapper
├── launch/                # Platform launchers
├── release/              # Packaged artifacts
├── bin/                  # Offline backend binary
├── requirements.txt
├── pyproject.toml
└── README.md
&lt;/code&gt;
    &lt;code&gt;from scripts.hallucination_toolkit import (
    OpenAIBackend, OpenAIItem, OpenAIPlanner,
    make_sla_certificate, save_sla_certificate_json
)

# Configure and run
backend = OpenAIBackend(model="gpt-4o-mini")
items = [OpenAIItem(prompt="...", n_samples=7, m=6)]
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(items, h_star=0.05)

# Generate SLA certificate
report = planner.aggregate(items, metrics)
cert = make_sla_certificate(report, model_name="GPT-4o-mini")
save_sla_certificate_json(cert, "sla.json")&lt;/code&gt;
    &lt;code&gt;streamlit run app/web/web_app.py&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows: Double-click &lt;code&gt;launch/Launch App.bat&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;macOS: Double-click &lt;code&gt;launch/Launch App.command&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Linux: Run &lt;code&gt;bash launch/launch.sh&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First run creates &lt;code&gt;.venv&lt;/code&gt; and installs dependencies automatically.&lt;/p&gt;
    &lt;p&gt;Development:&lt;/p&gt;
    &lt;code&gt;cd electron
npm install
npm run start&lt;/code&gt;
    &lt;p&gt;Build installers:&lt;/p&gt;
    &lt;code&gt;npm run build&lt;/code&gt;
    &lt;p&gt;Build single-file executable:&lt;/p&gt;
    &lt;code&gt;# macOS/Linux
bash scripts/build_offline_backend.sh

# Windows
scripts\build_offline_backend.bat&lt;/code&gt;
    &lt;p&gt;Creates &lt;code&gt;bin/hallucination-backend[.exe]&lt;/code&gt; with bundled Python, Streamlit, and dependencies.&lt;/p&gt;
    &lt;code&gt;from scripts.hallucination_toolkit import (
    OpenAIBackend, OpenAIItem, OpenAIPlanner,
    make_sla_certificate, save_sla_certificate_json,
    generate_answer_if_allowed
)

# Setup
backend = OpenAIBackend(model="gpt-4o-mini")

# Prepare items
items = [
    OpenAIItem(
        prompt="Who won the 2019 Nobel Prize in Physics?",
        n_samples=7,
        m=6,
        skeleton_policy="closed_book"
    ),
    OpenAIItem(
        prompt="If James has 5 apples and eats 3, how many remain?",
        n_samples=7,
        m=6,
        skeleton_policy="closed_book"
    )
]

# Run evaluation
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(
    items,
    h_star=0.05,           # Target 5% hallucination max
    isr_threshold=1.0,     # Standard threshold
    margin_extra_bits=0.2, # Safety margin
    B_clip=12.0,          # Clipping bound
    clip_mode="one-sided" # Conservative mode
)

# Generate report and certificate
report = planner.aggregate(items, metrics, alpha=0.05, h_star=0.05)
cert = make_sla_certificate(report, model_name="GPT-4o-mini")
save_sla_certificate_json(cert, "sla_certificate.json")

# Show results
for item, m in zip(items, metrics):
    print(f"\nPrompt: {item.prompt[:50]}...")
    print(f"Decision: {'ANSWER' if m.decision_answer else 'REFUSE'}")
    print(f"Risk bound: {m.roh_bound:.3f}")
    print(f"Rationale: {m.rationale}")
    
    # Generate answer if allowed
    if m.decision_answer:
        answer = generate_answer_if_allowed(backend, item, m)
        print(f"Answer: {answer}")&lt;/code&gt;
    &lt;p&gt;This project is licensed under the MIT License — see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Developed by Hassana Labs (https://hassana.io).&lt;/p&gt;
    &lt;p&gt;This implementation follows the framework from the paper “Compression Failure in LLMs: Bayesian in Expectation, Not in Realization” (NeurIPS 2024 preprint) and related EDFL/ISR/B2T methodology.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/leochlon/hallbayes"/></entry><entry><id>https://news.ycombinator.com/item?id=45181094</id><title>Weaponizing Ads: How Google and Facebook Ads Are Used to Wage Propaganda Wars</title><updated>2025-09-09T18:12:58.481812+00:00</updated><content>&lt;doc fingerprint="ffa493a89685dd50"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Weaponizing Ads: How Governments Use Google Ads and Facebook Ads to Wage Propaganda Wars&lt;/head&gt;
    &lt;p&gt;In late 2024, the head of the UN’s Gaza aid agency made a disturbing discovery: when people searched for his organization on Google, the top result wasn’t the agency’s own site — it was a paid ad placed by the Israeli government. The ad mimicked a UN website but actually linked to an Israeli government page accusing the UN Relief and Works Agency (UNRWA) of supporting terroists (wired.com). “The spread of misinformation &amp;amp; disinformation continues to be used as a weapon in the war in Gaza,” UNRWA Commissioner-General Philippe Lazzarini warned, calling for investigations and stricter regulation of online propaganda (aljazeera.com). His alarm highlights a troubling new reality: digital advertising platforms have become battlefields for influence, where governments and political groups pay to sway public opinion in wars and crises.&lt;/p&gt;
    &lt;p&gt;Traditional propaganda , think radio broadcasts, posters, state TV, has now gone high-tech. Platforms like Google Ads and Facebook (Meta) Ads allow paries to target specific audiences with tailored messages at massive scale. In theory, these companies have policies against hate speech or blatant lies. In practice, recent case studies show that sophisticated misinformation campaigns can exploit loopholes and lax enforcement, reaching millions of people with government-funded narratives. From the Israel–Palestine conflict to Russian and domestic political meddling, paid ads are being weaponized to promote war efforts, demonize opponents, and even undermine institutions like the UN. This article examines how it’s happening, why the platforms permit it, and what ethical and policy questions arise.&lt;/p&gt;
    &lt;head rend="h2"&gt;Digital Propaganda via Paid Ads: A New Front in Information Warfare&lt;/head&gt;
    &lt;p&gt;Paid advertising on Google and Facebook has become a potent tool for political persuasion or manipulation. Unlike organic social media posts (which rely on shares or algorithms), ads can guarantee visibility: if you pay, you reach your target. And the targeting can be extremely granular. Google Ads lets advertisers bid on search keywords or place banner/video ads on websites and YouTube, often filtered by geography or audience interests. Facebook/Meta’s ad system enables micro-targeting by demographics, location, and user interests, while requiring a “paid for by” disclaimer on political ads for transparency. In theory, this gives legitimate political campaigns a way to reach supporters , but it equally gives propagandists a direct channel to the eyeballs of a chosen populace.&lt;/p&gt;
    &lt;p&gt;Researchers note that this capacity can be abused by partisan or state actors to “manipulate or distract citizens with misinformation and government propaganda,” posing serious challenges to democracy (academic.oup.com). A notorious early example was Russia’s Internet Research Agency, which in 2016 created hundreds of fake Facebook accounts and purchased at least $100,000 worth of divisive ads to influence the U.S. election (abcnews.go.com). Many of those ads didn’t mention candidates directly; instead they amplified polarizing messages on issues like immigration and race to inflame social tensions. At the time, Facebook admitted that most of these propaganda ads “did not violate any company policies or laws,” underscoring how unprepared the platform’s rules were (abcnews.go.com). The incident sparked global awareness that paid media ads could be used as a propaganda weapon , and led to new transparency measures like Facebook’s Ads Library.&lt;/p&gt;
    &lt;p&gt;Yet, increased transparency hasn’t prevented the tactic from evolving. Recent conflicts show governments openly turning to ad campaigns as part of their information warfare strategy. Paid ads can be launched rapidly, scaled globally, and tailored to undermine an opponent or shape public perception of a war. Crucially, they also allow a state to influence foreign publics, beyond its own borders, often skirting the line of platform policies and international norms. The sections below explore a timely case study and the broader implications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case Study: Israel’s Paid Propaganda Campaign in the Gaza War&lt;/head&gt;
    &lt;p&gt;One of the clearest illustrations of war propaganda via paid ads is the Israeli government’s online advertising blitz during the 2023–2025 Gaza war. Israel has long engaged in hasbara (Hebrew for “explanation”), a term for state public relations efforts or propaganda (smex.org). But since the war in Gaza, Israel’s use of digital ads has intensified to unprecedented levels (smex.org).&lt;/p&gt;
    &lt;head rend="h2"&gt;Targeting the UN: Google Ads to Discredit Humanitarians&lt;/head&gt;
    &lt;p&gt;In mid-January 2024, staff at UNRWA USA (a U.S.-based fundraising affiliate of the UN agency) noticed something strange: Google searches for “UNRWA” were yielding an ad that looked like it was from UNRWA, but actually led to an Israeli government site (wired.com). Upon investigation, they discovered a months-long Google Ads campaign by the Israeli Government Advertising Agency to discredit UNRWA (wired.com). The Israeli ads, which were clearly labeled as such in Google’s transparency data, appeared on searches for over 300 related keywords, from “UNRWA” to “Gaza aid”, effectively hijacking traffic from people seeking the UN agency (wired.com). The content of the ads and the landing pages was unmistakably propagandistic: the Israeli site alleged that UNRWA was “inseparable from Hamas” and even employed terrorists (wired.com). One ad bluntly asked, “Paychecks for terrorists or humanitarian aid?”, suggesting money given to UNRWA would fund armed militants (abc.net.au).&lt;/p&gt;
    &lt;p&gt;The aim of this campaign was clear: to cut off support and donations to the UN’s relief agency in Gaza. It came at a critical time, as UNRWA was providing life-saving food, water, and medical care to Palestinians under siege. UNRWA’s chief, Philippe Lazzarini, blasted Israel’s actions as a “deliberate disinformation campaign” to “dismantle the agency”, warning that smearing a humanitarian organization not only hurts its reputation but “puts the lives of our colleagues on the frontline at serious risk” (abc.net.au). In essence, Israeli authorities were using Google’s advertising system to undermine a UN institution in the middle of a humanitarian crisis.&lt;/p&gt;
    &lt;p&gt;Google’s response was relatively hands-off. When UNRWA representatives appealed to Google to stop what they saw as a dangerous misinformation campaign, the company did not immediately take down the ads (wired.com). A Google spokesperson defended that any government may run ads on Google as long as they adhere to our policies, and stated that Google enforces those rules “consistently and without bias” (wired.com). In other words, because the Israeli ads did not overtly violate Google’s ad policies, they were allowed to run. Notably, Google’s ad policies do prohibit misrepresentation, but they do not have a blanket ban on misinformation unless it relates to specific sensitive areas like election integrity (gomixte.com). As Wired reported, Google generally permits questionable claims in ads “unless it undermines participation or trust in an electoral process” (gomixte.com). This loophole meant that propaganda undermining a humanitarian agency , while arguably unethical , wasn’t against the rules.&lt;/p&gt;
    &lt;p&gt;The result: Israel’s anti-UNRWA ads often outcompeted the agency’s own Google ads. From May through July 2024, in head-to-head bidding, the Israeli ads won the top slot 44% of the time (versus UNRWA USA’s ads showing 34% of the time) (wired.com). UNRWA’s team had to spend tens of thousands of donor dollars trying to outbid Israel for visibility (wired.com). This “insidious” campaign, as UNRWA called it, exposed countless Americans and others to one-sided allegations just as they were searching for facts about Gaza relief (wired.com). “I want the public to know what’s happening,” said UNRWA USA director Mara Kronenfeld, “especially at a time when civilian lives are under attack in Gaza” (wired.com).&lt;/p&gt;
    &lt;p&gt;By late 2024, news investigations across the world had caught on. ABC News in Australia found that those same Israeli ads linking UNRWA to Hamas were appearing on major Australian news sites, served via Google’s display network (abc.net.au). The ads featured a masked militant wearing both the Hamas emblem and an UNRWA headband, visually equating the UN agency with a terror group (abc.net.au). Captions like “UNRWA has alternatives, it must be replaced” were shown next to news articles (abc.net.au). ABC confirmed at least eight such ad variants were targeted specifically at Australian audiences (in English) and noted the campaign ran in multiple languages including German, Italian, French, and Spanish (abc.net.au). This truly was a global propaganda ad campaign, orchestrated by a government via Google’s platforms.&lt;/p&gt;
    &lt;p&gt;UNRWA officials, upon learning of the global ads, reiterated that these tactics were “a wider disinformation campaign” by Israel to cripple the agency (abc.net.au). Despite criticism from UN allies (Australia’s Foreign Minister called Israel’s actions “reprehensible” and urged them to stop undermining UNRWA (abc.net.au), the Israeli government showed no signs of relenting. It even escalated measures offline, banning UNRWA operations in Israel, as the online ad offensive continued (abc.net.au)&lt;/p&gt;
    &lt;head rend="h2"&gt;A coordinated ad push against the Hind Rajab Foundation (HRF)&lt;/head&gt;
    &lt;p&gt;Alongside the UNRWA campaign, the Israeli Government Advertising Agency has also targeted the Hind Rajab Foundation (HRF), an EU-based human-rights nonprofit founded in 2024 to pursue accountability for alleged war crimes in Gaza and named in honor of five-year-old Hind Rajab, whose death became emblematic of the conflict (Hind Rajab Foundation). In Google’s Ads Transparency Center, the agency’s account shows creatives such as “Hind Rajab Foundation — HRF’s disturbing reality” that click through to a government microsite titled “Unmasking the Hind Rajab Foundation,” which portrays HRF as a pseudo-legal front with “extremist” ties (Ads Transparency Center, 2025; Government of Israel). Reporting on Israel’s recent $45 million placement with Google further notes that several ads explicitly link to this “Unmasking” report, indicating a coordinated effort to discredit HRF across search and display (Drop Site News). For context, HRF’s public materials frame the organization as a legal accountability initiative, while the story of Hind Rajab has gained global visibility through Kaouther Ben Hania’s Venice-premiering film The Voice of Hind Rajab, backed by high-profile producers including Brad Pitt, Joaquin Phoenix, Rooney Mara, and Jonathan Glazer, which has amplified awareness of the case well beyond activist circles (Reuters).&lt;/p&gt;
    &lt;head rend="h2"&gt;Flooding Social Media with War Narratives&lt;/head&gt;
    &lt;p&gt;The attack on UNRWA was just one facet of Israel’s broader digital PR war. Israeli agencies and allied groups pumped out hundreds of ads across Google/YouTube, Facebook/Instagram, and even children’s gaming apps to influence public opinion about the Gaza conflict. David Saranga, head of the Israeli Foreign Ministry’s digital bureau, confirmed that “the footage is part of a larger advocacy drive” in which the ministry spent $15 million on internet ads in just the first few weeks after October 7, 2023 (smex.org). Those ads often contained graphic and emotional imagery, for example, violent scenes and frightened Israeli families, even appearing as pop-ups in kids’ online games, where they left children “shocked and disturbed” (smex.org). Reuters journalists observed some of these graphic video ads playing in European video games used by children, raising serious questions about appropriateness and consent (business-humanrights.org).&lt;/p&gt;
    &lt;p&gt;On Meta’s platforms (Facebook and Instagram), pro-Israel advertising also spiked dramatically. One effort led by a group calling itself “Facts for Peace” spent over $370,000 on Facebook/Instagram ads in a single month (November 2023) to push viral videos framing all support for Palestine as support for Hamas (business-humanrights.org). These ads, which amassed over 21 million views, were crafted to equate the Palestinian cause with barbaric violence. Despite the obviously misleading and inflammatory nature of such content, it spread widely: it was even promoted by right-wing influencers like Ben Shapiro and shared by official Israeli government social media (e.g. the Israeli embassy in Chile) (business-humanrights.org). Meta’s Ad Library showed 213 ads from Facts for Peace, of which only 3 were taken down for policy violations (business-humanrights.org). Meta told investigators that the campaign did not technically break their rules on transparency, since the ads carried a “Paid for by Facts for Peace” disclaimer and the page was authorized for political advertising. However, nowhere did the group disclose its true funding sources or organizers. (Journalists later linked it to a U.S. billionaire funding pro-Israel messaging (business-humanrights.org.) This case shows how easy it is for a new, opaque group to launch a massive political ad campaign and reach millions before anyone can fully scrutinize it.&lt;/p&gt;
    &lt;p&gt;Israeli government entities themselves also ran extensive campaigns on social media. The Israeli Ministry of Foreign Affairs launched at least 75 distinct ads on YouTube alone in the first months of the war (smex.org). Some of these ads featured what observers called incitement to violence. In one video ad, a menacing message declared: “Israel will take every measure necessary to protect our citizens against these barbaric terrorists,” which borders on a call to collective violence (smex.org). YouTube’s political ads policy forbids content that “encourages others to commit violent acts,” yet this ad apparently slipped through (smex.org). On X (formerly Twitter), the Israeli government and military accounts also placed promoted posts with graphic images (e.g. charred buildings and victims), urging support for their military actions (smex.org). Such ads would seem to violate X’s pre-existing ban on state-affiliated media buying ads (a policy originally aimed at propaganda from outlets like Russia’s RT). Nonetheless, these promotions ran, and some critics questioned if Elon Musk’s open support for Israel influenced X’s lax enforcement (smex.org).&lt;/p&gt;
    &lt;p&gt;By early 2025, reports revealed that Israel had even formalized a multi-million dollar contract with Google to sustain its global propaganda offensive. According to investigative reporting by Drop Site News (and cited by outlets like TRT World), the Israeli Prime Minister’s Office signed a $45 million, six-month deal with Google in June 2025 to run a worldwide advertising blitz downplaying the humanitarian crisis in Gaza (trtworld.com). The campaign kicked off just after Israeli authorities imposed a siege cutting off food, fuel, and medicine to Gaza in March 2025, and as officials worried about “the public relations fallout”. Leaked documents described Google as a “key entity” in Netanyahu’s PR strategy (trtworld.com). Sure enough, soon after, YouTube and display ads proclaiming “there is food in Gaza. Any other claim is a lie” flooded the internet, with one such video, produced by Israel’s Foreign Ministry, racking up over 6 million views via paid promotion (trtworld.com). In effect, Google was being directly paid to broadcast the message that reports of starvation in Gaza were false, despite widespread documentation of severe hunger by the UN and NGOs. Israeli propaganda officials openly characterized these efforts as “hasbara” — literally “propaganda” — in internal communications (trtworld.com). Alongside Google, Israel spent another $3 million on ads on X (Twitter) and $2.1 million on other ad networks to bolster its narrative (trtworld.com).&lt;/p&gt;
    &lt;p&gt;The impact of Israel’s ad campaign is hard to quantify, but it undoubtedly reached broad swathes of the global public with the government’s perspective. By framing its military operations as justified self-defense and its critics (even humanitarian agencies) as terrorist sympathizers, Israel’s paid ads sought to shore up international support and neutralize opposition. Given that Israel’s security and billions in military aid depend on Western public opinion (smex.org), this digital influence strategy was a logical extension of the war itself. However, it came at the cost of injecting misinformation and extreme bias into the information ecosystem, potentially skewing public perceptions and policy debates. As we’ll see next, this case also exposes worrying gaps in platform policies and ethical oversight.&lt;/p&gt;
    &lt;head rend="h2"&gt;Policy Gaps, Double Standards, and Ethical Dilemmas&lt;/head&gt;
    &lt;p&gt;The use of paid ads for propaganda raises a blunt question: Are Google and Meta actually enforcing their own rules when it comes to wartime disinformation? The evidence from the above case suggests significant gaps and inconsistencies. Despite formal policies against harmful or misleading content, both companies’ systems enabled, and profited from, campaigns that arguably violate the spirit, if not the letter, of those rules.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Google’s laissez-faire approach to misinformation: Google’s advertising policies forbid certain categories of content (hate speech, explicit incitement to violence, etc.) and ban misrepresenting who you are. But they do not outright ban false or misleading claims in ads except in narrow contexts like election integrity or COVID-19 info (gomixte.com). This is why blatant propaganda, e.g. accusing a UN agency of abetting terror with scant evidence, can pass muster on Google Ads. Google relied on users or affected parties to report problematic ads, and stated it would “take swift action” if actual policy violations were found (wired.com). But in practice, Google did not pro-actively vet the truth of Israeli government claims. The company was, after all, in a business relationship with Israel (not to mention the formal $45M deal) and may have been reluctant to police a powerful client’s messaging beyond basic checks. This hands-off stance highlights a moral gray area: allowing a paying customer to spread potentially dangerous misinformation because it doesn’t fit neatly into a prohibited category. It suggests that platform policy enforcement can be very literal and reactive, leaving ethical judgment by the wayside.&lt;/item&gt;
      &lt;item&gt;Meta’s inconsistent enforcement and transparency issues: Facebook/Meta, on paper, has more expansive rules for political ads. They require identity verification for political advertisers and mandate a “Paid for by [Name]” disclosure on each ad. Certain types of violent or hateful content are disallowed even in ads. In the Israel–Gaza context, however, these rules were enforced unevenly. Meta’s own Ads Library data shows a bias: when ads violated policies (e.g. contained hate speech or graphic violence), pro-Palestinian ads were taken down faster and more frequently than pro-Israeli ads (smex.org). SMEX’s analysis of thousands of ads found that Israeli war-cheerleading ads often remained live longer despite breaking rules, whereas ads calling for Gaza humanitarian aid got removed with stricter urgency (smex.org). For example, the “Facts for Peace” videos that implied all Palestinian supporters endorse terror arguably constituted hateful generalization, yet most stayed up until their paid run ended. Meanwhile, at least one civil society test in late 2023 found that Facebook approved ads containing explicit hate speech calling for violence against Palestinians, indicating failures in the automated moderation system (business-humanrights.org). Meta responded that it prioritizes transparency — pointing to the existence of the Ad Library — but researchers found the library frustratingly opaque. Some ads that clearly ran were missing from public search, and crucial data like why an ad was removed or who exactly was targeted were absent (smex.org). Meta shut down useful tools like CrowdTangle (which helped monitor content virality) in 2024, hampering independent oversight (smex.org). All of this suggests that Meta’s professed neutrality masks a deeply flawed system, where enforcement can be influenced by political sensitivities or errors, and where the company’s profit motive in selling ads may conflict with taking decisive action against harmful content.&lt;/item&gt;
      &lt;item&gt;Double standards for different conflicts: A striking contrast can be seen in how platforms treated Russian state propaganda versus Israeli state propaganda. During Russia’s 2022 invasion of Ukraine, Western tech firms took an unusually hard line against Russia’s online influence operations. Meta banned Russian state media outlets from running ads or monetizing content on its platform and demoted their posts (smex.org). It also aggressively labeled or removed Russian disinformation about the war, under heavy pressure from governments and public opinion. Google similarly demonetized Russian state-affiliated channels (like RT) and limited their reach. These steps were lauded as Big Tech taking a stand against wartime disinformation. Yet, when it came to Israel, engaging in similar behavior, the response was far more lenient. No blanket bans or demonetization were applied to Israeli state entities pushing propaganda, even though some of their content arguably violated the same principles (for instance, denying documented human suffering in Gaza, or using dehumanizing language about “barbaric terrorists” broadly). Observers have pointed out this double standard, noting that platforms seemed willing to bend rules or look the other way for a U.S.-aligned government (smex.org). This inconsistency not only undermines the credibility of platform policies but also raises geopolitical questions: are ethical standards being applied universally, or only when convenient?&lt;/item&gt;
      &lt;item&gt;Violations of international norms: Beyond platform rules, there’s an argument that some of these ad campaigns tread on international ethical standards or even laws. For example, deliberately spreading false information to obstruct humanitarian aid (as Israel’s anti-UNRWA ads aimed to do) could be seen as running counter to International Humanitarian Law, which seeks to protect aid efforts and civilians during conflict. Incitement to violence against a population is outlawed under the Genocide Convention and other treaties — and while social media ads we’ve discussed stop short of explicit incitement, they foment hatred and misunderstanding that can fuel violence. The UN Secretary-General and other officials have repeatedly condemned the weaponization of disinformation in conflict settings, calling it “destructive” and urging tech companies to clamp down (wired.com) (aljazeera.com). Allowing a state to pay to propagate one-sided or false narratives undermining a UN agency could be seen as abetting an attack on that international institution’s integrity. These are largely uncharted waters, there’s no clear international law for “information warfare”, but the ethical condemnation is growing. As Lazzarini implored, such campaigns “should stop and be investigated”, and social media firms must do more to combat disinformation and hate speech in war (aljazeera.com).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All these issues point back to the central dilemma: What responsibility do the tech giants have when their advertising tools are used to spread propaganda or inflame conflicts? If they act as neutral carriers, they risk facilitating harm; if they intervene, they become arbiters of truth in explosive political situations. The next section looks at how Google, Meta, and others have responded, or failed to respond, and what more could be done.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Responsibility of Tech Companies in Wartime Propaganda&lt;/head&gt;
    &lt;p&gt;Major tech companies often insist they are platforms, not publishers, they provide the space, but aren’t responsible for every message that advertisers choose to push. However, the extreme examples we’ve explored put that claim to the test. When a company is paid millions to disseminate content that may be false or harmful, can it really wash its hands of accountability? Here are some considerations and responses from the companies and experts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Official stances and defenses: Google’s official line, as noted, is that it applies its ad policies equally to all, including governments, and will remove ads that violate those policies (wired.com). Implicit in that statement is that Google does not see itself as the arbiter of factual truth in ads, unless a lie crosses certain predefined lines, Google will host it for a paying client. Meta, for its part, touts the transparency of its system. A Meta spokesperson, responding to concerns about the “Facts for Peace” campaign, emphasized that the ads were “clearly labeled with a ‘paid by’ disclaimer” and publicly archived in the Ads Library, implying that this level of transparency exceeds that of TV or print political ads (business-humanrights.org). Meta also points out that it has an Ad Standards enforcement team and that ads violating policies (when caught) are taken down and documented. In practice, as we saw, that enforcement can lag or falter — but the company’s message is that shining light on ads is the solution, rather than heavy-handed censorship.&lt;/item&gt;
      &lt;item&gt;Profit vs. principle: Critics argue that a big reason these platforms struggle to self-regulate is that they make money from every ad impression. When conflict-related content goes viral, ad spending surges. A joint analysis by CalMatters and The Markup found that after war broke out in Gaza on Oct 7, 2023, Meta saw a major increase in ad revenue related to the conflict (calmatters.org). In October 2023 alone, an estimated $3.1 million was spent on Facebook ads about the Israel–Gaza war, a huge spike compared to previous months (calmatters.org). This includes not just state propaganda but also ads for fundraising, merchandise, and advocacy around the crisis. The point is that war and political violence can become lucrative business for social media companies, something Meta’s own employees have acknowledged internally (Facebook famously admitted that outrage and misinformation drive engagement, which in turn drives ad revenue (calmatters.org). This profit motive can create a perverse disincentive to crack down on borderline content. While $3 million is a drop in the bucket of Meta’s $100+ billion annual revenue, it’s still revenue. And for Google, a $45 million contract from Israel’s government is significant. The companies risk accusations of “conflict profiteering” if they appear to take money to propagate one side’s propaganda. This has led to calls for them to refuse or refund ad buys that clearly aim to deceive or stoke conflict, though such moves remain rare.&lt;/item&gt;
      &lt;item&gt;Calls for stronger policies: Human rights organizations and digital rights groups are urging the platforms to develop special policies for ads in conflict zones or on politically sensitive issues. For instance, SMEX and others have suggested that in the context of an armed conflict, platforms should implement tailored rules to prevent the spread of hate speech and misinformation via ads, given the real-world stakes (smex.org). Concretely, this could mean temporarily banning state-run or state-funded advertising in active conflict situations, or at least subjecting them to human review and fact-checking. It could also mean disallowing ads that target foreign populations with war propaganda, treating it akin to foreign election interference. Another idea floated by experts is a “circuit breaker” approach: if a sudden war or crisis erupts, platforms might pause all political and issue-based ads in the affected regions until they can ramp up oversight. (Notably, Meta has recently decided to halt all political, electoral, and social issue ads in the entire EU starting in 2025, in response to new regulations (about.fb.com). This broad-brush ban is a compliance move for Europe, but it shows that turning off political ads is technically feasible when mandated.)&lt;/item&gt;
      &lt;item&gt;Transparency and researcher access: Many observers argue that if companies won’t ban propaganda ads outright, they should at least empower watchdogs to track and expose them. This means improving their ad transparency tools. Meta’s shutting down of CrowdTangle and the limitations of the Ads Library have drawn heavy criticism (smex.orgsmex.org). Experts like Sam Jeffers of Who Targets Me advocate for more robust disclosures — for example, revealing detailed targeting parameters of political ads (so we know who governments are trying to influence) and keeping archives of removed ads including why they were removed (business-humanrights.org) (smex.org). There are also calls for independent audits of platform algorithms and ad delivery, to see if certain viewpoints are getting amplified unfairly. Ultimately, greater transparency can help civil society and journalists “police” the propaganda if the platforms themselves are slow to do so.&lt;/item&gt;
      &lt;item&gt;Regulatory pressure and international standards: Governments and international bodies are starting to weigh in. The European Union’s Digital Services Act (DSA) and upcoming regulations on political advertising put legal requirements on big platforms to prevent misuse. For example, the DSA requires rapid removal of illegal content (which could include illegal hate speech or incitement in ads) and hefty fines for non-compliance. The EU is also pushing for strict transparency on political ads and even contemplating banning microtargeting for political messages. These rules, though EU-specific, often end up being adopted globally by platforms for simplicity’s sake. Outside of Europe, the lack of regulation has been evident, which is why UN officials like Lazzarini are directly calling for “more regulations for companies… to combat disinformation and hate speech” online (aljazeera.com). We may see moves in the UN or other international forums to establish norms against certain propaganda techniques. In the long run, if self-regulation fails, tech companies might face binding rules prohibiting them from accepting money for ads that undermine peace and truth, a challenging rule to draft, but an increasingly pertinent conversation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The era of governments weaponizing Google and Facebook ads is upon us, raising thorny questions about truth, free speech, and corporate responsibility in the digital age. The case of Israel’s advertising blitz in the Gaza war demonstrates how easily paid platforms can be turned into tools of war propaganda, blasting millions with biased or false narratives at the click of a button. It also shows the real harms at stake: humanitarian aid blocked, democratic institutions undermined, and public discourse polluted. And Israel is not alone, from superpowers to militant groups, many actors have tested the boundaries of online ads to sway hearts and minds.&lt;/p&gt;
    &lt;p&gt;For the platforms, this is a moment of reckoning. Can Google and Meta continue to say “we’re just the middleman” while cashing checks for propaganda campaigns? Critics argue that neutrality is not neutral when it enables deception and violence. Yet, deciding where to draw the line is complex. Mistakes or overreach in moderation could themselves be seen as partisan interference. The tightrope between allowing robust political advocacy and preventing harmful propaganda is a difficult one to walk, especially under global scrutiny.&lt;/p&gt;
    &lt;p&gt;What is clear is that doing nothing is no longer tenable. Sunlight and accountability are the minimum: users deserve to know who is behind the political ads they see and to have confidence that egregious lies or incitements won’t be promoted by the world’s most powerful information platforms. Moving forward, it will likely require a mix of solutions , improved self-governance by tech firms, independent oversight, and smart regulation, to ensure that the tools of modern advertising are not abused to foment conflict or erode democracy. As the saying goes, “In war, truth is the first casualty.” In our digital world, we must decide how much we are willing to let paid algorithms hasten that casualty, or whether we can find ways to uphold truth even amid the fog of online war.&lt;/p&gt;
    &lt;p&gt;Sources:&lt;/p&gt;
    &lt;p&gt;Google involved in $45M deal with Netanyahu’s office to advertise Israeli hasbara — report — TRT World https://www.trtworld.com/world/article/538017f344e5&lt;/p&gt;
    &lt;p&gt;Israel Is Buying Google Ads to Discredit the UN’s Top Gaza Aid Agency | WIRED https://www.wired.com/story/israel-unrwa-usa-hamas-google-search-ads/&lt;/p&gt;
    &lt;p&gt;UNRWA head accuses Israel of buying Google ads to block donations to agency | UNRWA News | Al Jazeera https://www.aljazeera.com/news/2024/8/31/unrwa-head-accuses-israel-of-buying-google-ads-to-block-donations-to-agency&lt;/p&gt;
    &lt;p&gt;Mass Political Information on Social Media: Facebook Ads … https://academic.oup.com/jeea/article/22/4/1678/7607367&lt;/p&gt;
    &lt;p&gt;Facebook says it sold $100,000 in ads to fake Russian accounts during presidential election — ABC News https://abcnews.go.com/Politics/facebook-sold-100000-ads-fake-russian-accounts-presidential/story?id=49667831&lt;/p&gt;
    &lt;p&gt;Inside the Israeli occupation’s propaganda ad factory — SMEX https://smex.org/inside-the-israeli-occupations-propaganda-ad-factory/&lt;/p&gt;
    &lt;p&gt;Google ads linking UNRWA with Hamas appearon Australian news websites as part of a global campaign — ABC News https://www.abc.net.au/news/2024-12-05/unrwa-hamas-google-ads-published-on-australian-news-sites/104685074&lt;/p&gt;
    &lt;p&gt;How Google Ads Are Weaponized — Mixte Communications https://gomixte.com/blog/how-google-ads-are-weaponized/&lt;/p&gt;
    &lt;p&gt;Palestine/Israel: Viral campaign ads attacking proPalestine movement points to concerning gaps in Meta rules; incl. co. comment — Business &amp;amp; Human Rights Resource Centre https://www.business-humanrights.org/en/latest-news/palestineisrael-viral-campaign-ads-attacking-pro-palestine-movementpoints-to-concerning-gaps-in-meta-rules-incl-co-comment/&lt;/p&gt;
    &lt;p&gt;When Transparency Fails: Meta’s Political Ad Policy During Israel’s War on Gaza — SMEX https://smex.org/when-transparency-fails-metas-political-ad-policy-during-israels-war-on-gaza/&lt;/p&gt;
    &lt;p&gt;How Meta brings in millions off political violence — CalMatters https://calmatters.org/economy/technology/2024/10/how-meta-brings-in-millions-off-political-violence/&lt;/p&gt;
    &lt;p&gt;Ending Political, Electoral and Social Issue Advertising in the EU in … https://about.fb.com/news/2025/07/ending-political-electoral-and-social-issue-advertising-in-the-eu/&lt;/p&gt;
    &lt;p&gt;Ads Transparency Center. (2025). Israeli Government Advertising Agency [Advertiser page]. Google. https://adstransparency.google.com/advertiser/AR00827556497616535553&lt;/p&gt;
    &lt;p&gt;Drop Site News. (2025, June 18). Google’s $45 million contract with Netanyahu’s office to launder Gaza famine denial through ads. https://www.dropsitenews.com/p/google-youtube-netanyahu-israel-propaganda-gaza-famine&lt;/p&gt;
    &lt;p&gt;Reuters. (2025, September 4). Venice ovation fuels hopes for Gaza girl film to reach global audience. https://www.reuters.com/business/media-telecom/venice-ovation-fuels-hopes-gaza-girl-film-reach-global-audience-2025-09-04/&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medium.com/@eslam.elsewedy/weaponizing-ads-how-governments-use-google-ads-and-facebook-ads-to-wage-propaganda-wars-199c707704cc"/></entry><entry><id>https://news.ycombinator.com/item?id=45181626</id><title>Google to Obey South Korean Order to Blur Satellite Images on Maps</title><updated>2025-09-09T18:12:58.283444+00:00</updated><content>&lt;doc fingerprint="298e9ed01ca6598f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Google To Obey South Korean Order To Blur Satellite Images On Maps&lt;/head&gt;&lt;p&gt;Google said on Tuesday that it would comply with the South Korean government's demand to blur sensitive satellite images on its mapping services, paving the way for the US tech giant to compete better with local navigation platforms.&lt;/p&gt;&lt;p&gt;The Barron's news department was not involved in the creation of the content above. This article was produced by AFP. For more information go to AFP.com.&lt;lb/&gt;© Agence France-Presse&lt;/p&gt;&lt;p&gt;Continue reading this article with a Barron’s subscription&lt;/p&gt;SUBSCRIBE NOW&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.barrons.com/news/google-to-obey-south-korean-order-to-blur-satellite-images-on-maps-653e934e"/></entry><entry><id>https://news.ycombinator.com/item?id=45182372</id><title>New Mexico is first state in US to offer universal child care</title><updated>2025-09-09T18:12:57.711569+00:00</updated><content>&lt;doc fingerprint="29aab1d30fac0dbe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PRESS RELEASES&lt;/head&gt;
    &lt;head rend="h1"&gt;New Mexico is first state in nation to offer universal child care&lt;/head&gt;
    &lt;p&gt;SANTA FE — Governor Michelle Lujan Grisham and the New Mexico Early Childhood Education and Care Department announced a historic milestone on Monday: New Mexico will become the first state in the nation to guarantee no-cost universal child care starting Nov. 1.&lt;/p&gt;
    &lt;p&gt;This groundbreaking new initiative will make child care available to all New Mexicans, regardless of income, by removing income eligibility requirements from the state’s child care assistance program and continuing the waiver of family copayments.&lt;/p&gt;
    &lt;p&gt;“Child care is essential to family stability, workforce participation, and New Mexico’s future prosperity,” said Lujan Grisham. “By investing in universal child care, we are giving families financial relief, supporting our economy, and ensuring that every child has the opportunity to grow and thrive.”&lt;/p&gt;
    &lt;p&gt;This announcement fulfills the promise made by the governor and the New Mexico Legislature when they created the Early Childhood Education and Care Department in 2019. Since then, New Mexico has expanded access to no-cost child care to families with incomes at or below 400% of the federal poverty level, reducing financial strain on tens of thousands of families.&lt;/p&gt;
    &lt;p&gt;With Monday’s announcement universal child care will be extended to every family in the state, regardless of income. This amounts to an average annual family savings of $12,000 per child.&lt;/p&gt;
    &lt;p&gt;“New Mexico is creating the conditions for better outcomes in health, learning, and well-being,” said Neal Halfon, professor of pediatrics, public health and public policy at the University of California, Los Angeles, and director of the Center for Healthier Children, Families, and Communities. “Its approach is rooted in data, driven by communities, and becoming a model for the nation.&lt;/p&gt;
    &lt;p&gt;“By prioritizing public investments in early childhood educators, families, and children, New Mexico continues to lead the way in building a sustainable, affordable, and quality child care and early learning system that helps its communities and economy thrive,” said Michelle Kang, president and CEO of the National Association of the Education of Young Children (NAEYC). “Achieving universal child care will make a huge difference for the state’s children, families, businesses, and educators—and for all of us, by showing that it can be done.”&lt;/p&gt;
    &lt;p&gt;Families who receive child care assistance report greater financial stability, more time to focus on their children, and the ability to choose higher-quality care settings. Now, every family in New Mexico will have the same opportunity. New Mexico is also taking decisive action to build the supply of infant and toddler care statewide:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Establishing a $12.7 million low-interest loan fund to construct, expand, and renovate child care facilities, with an additional $20 million requested in the Fiscal Year 2027 budget.&lt;/item&gt;
      &lt;item&gt;Targeting growth to focus on care for infants, toddlers, low-income families, and children with special needs.&lt;/item&gt;
      &lt;item&gt;Partnering with employers and school districts to expand child care options for working families.&lt;/item&gt;
      &lt;item&gt;Launching a statewide campaign to recruit licensed and registered home providers.&lt;/item&gt;
      &lt;item&gt;To support providers, reimbursement rates will rise to reflect the true cost of care.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Programs that commit to paying entry-level staff a minimum of $18 per hour and offer 10 hours of care per day, five days a week, will receive an incentive rate. New Mexico estimates an additional 5,000 early childhood professionals are needed to fully achieve a universal system.&lt;/p&gt;
    &lt;p&gt;“Early childhood care and education is a public good,” said ECECD Sec. Elizabeth Groginsky. “By providing universal access and improving pay for our early childhood workforce, we are easing financial pressure on families, strengthening our economy, and helping every child learn in safe, nurturing environments. This is the kind of investment that builds equity today and prosperity for the future.”&lt;/p&gt;
    &lt;p&gt;With universal child care, New Mexico is leading the nation by showing that what is best for children and families is also the smartest investment for long-term prosperity—building a stronger future for every community in the state.&lt;/p&gt;
    &lt;p&gt;For more information about how families and providers can access universal child care benefits, visit and toolkit: ECECD Universal Child Care Resources Page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.governor.state.nm.us/2025/09/08/new-mexico-is-first-state-in-nation-to-offer-universal-child-care/"/></entry><entry><id>https://news.ycombinator.com/item?id=45182381</id><title>Claude can now create and edit files</title><updated>2025-09-09T18:12:57.346684+00:00</updated><content>&lt;doc fingerprint="156a1e7a6ff712a3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Claude can now create and edit files&lt;/head&gt;
    &lt;p&gt;Claude can now create and edit Excel spreadsheets, documents, PowerPoint slide decks, and PDFs directly in Claude.ai and the desktop app. This transforms how you work with Claude—instead of only receiving text responses or in-app artifacts, you can describe what you need, upload relevant data, and get ready-to-use files in return.&lt;/p&gt;
    &lt;p&gt;File creation is now available as a preview for Max, Team, and Enterprise plan users. Pro users will get access in the coming weeks.&lt;/p&gt;
    &lt;head rend="h2"&gt;What you can do&lt;/head&gt;
    &lt;p&gt;Claude creates actual files from your instructions—whether working from uploaded data, researching information, or building from scratch. Here are just a few examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Turn data into insights: Give Claude raw data and get back polished outputs with cleaned data, statistical analysis, charts, and written insights explaining what matters.&lt;/item&gt;
      &lt;item&gt;Build spreadsheets: Describe what you need—financial models with scenario analysis, project trackers with automated dashboards, or budget templates with variance calculations. Claude creates it with working formulas and multiple sheets.&lt;/item&gt;
      &lt;item&gt;Cross-format work: Upload a PDF report and get PowerPoint slides. Share meeting notes and get a formatted document. Upload invoices and get organized spreadsheets with calculations. Claude handles the tedious work and presents information how you need it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whether you need a customer segmentation analysis, sales forecasting, or budget tracking, Claude handles the technical work and produces the files you need. File creation turns projects that normally require programming expertise, statistical knowledge, and hours of effort into minutes of conversation.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works: Claude’s computer&lt;/head&gt;
    &lt;p&gt;Over the past year we've seen Claude move from answering questions to completing entire projects, and now we're making that power more accessible. We've given Claude access to a private computer environment where it can write code and run programs to produce the files and analyses you need.&lt;/p&gt;
    &lt;p&gt;This transforms Claude from an advisor into an active collaborator. You bring the context and strategy; Claude handles the technical implementation behind the scenes. This shows where we’re headed: making sophisticated multi-step work accessible through conversation. As these capabilities expand, the gap between idea and execution will keep shrinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;To start creating files:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Enable "Upgraded file creation and analysis" under Settings &amp;gt; Features &amp;gt; Experimental&lt;/item&gt;
      &lt;item&gt;Upload relevant files or describe what you need&lt;/item&gt;
      &lt;item&gt;Guide Claude through the work via chat&lt;/item&gt;
      &lt;item&gt;Download your completed files or save directly to Google Drive&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Start with straightforward tasks like data cleaning or simple reports, then work up to complex projects like financial models once you're comfortable with how Claude handles files.&lt;/p&gt;
    &lt;p&gt;This feature gives Claude internet access to create and analyze files, which may put your data at risk. Monitor chats closely when using this feature. Learn more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/news/create-files"/></entry><entry><id>https://news.ycombinator.com/item?id=45182418</id><title>Disrupting the DRAM roadmap with capacitor-less IGZO-DRAM technology</title><updated>2025-09-09T18:12:56.514554+00:00</updated><content>&lt;doc fingerprint="3e4f80efda1320e0"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;A novel DRAM memory cell with two IGZO-based transistors&lt;/head&gt;
    &lt;p&gt;The bit cell of dynamic random-access memory (DRAM), the main memory within traditional compute architectures, is conceptually very simple. It consists of one capacitor (1C) and one silicon (Si)-based transistor (1T). While the capacitor’s role is to store a charge, the transistor is used to access the capacitor, either to read how much charge is stored or to store a new charge.&lt;/p&gt;
    &lt;p&gt;Over the years, bit cell density scaling allowed the industry to introduce subsequent generations of DRAM technology and cope with the growing demand for DRAM. But since about 2015, DRAM memory technology has struggled to keep pace with the performance improvement of the processor’s logic part: scaling, cost, and power efficiency issues form the building blocks of a rising ‘memory wall’. The large capacitor constrains scalability and 3D integration of the 1T1C bit cell, the ultimate path towards high-density DRAM. In addition, as the access transistor gets smaller, it provides an increasingly large leakage path for the capacitor’s charge to drain away. This lowers the data retention time and requires DRAM cells to be refreshed more frequently – impacting the power consumption.&lt;/p&gt;
    &lt;p&gt;In 2020, imec reported a novel DRAM bit cell concept that can solve these two issues in one go: a bit cell made up of two thin-film transistors (2T, one for read, one for write) and no capacitor (0C) [1]. The conduction channel of the thin-film transistors is composed of an oxide semiconductor, such as indium-gallium-zinc-oxide (IGZO). Due to its wide bandgap, IGZO-based transistors have an extremely low off current, benefitting the memory’s retention time, refresh rate, and power consumption. The longer retention time also relaxes the requirement for the storage capacitance, allowing the parasitic capacitance of the read transistor to take over the role of the storage element.&lt;/p&gt;
    &lt;p&gt;In addition, fabricating an IGZO 2T0C bit cell is simpler and more cost-effective than traditional cells. Other than Si, IGZO material can be deposited at relatively low temperatures, making it compatible with back-end-of-line (BEOL) processing. This opens doors to new DRAM architectures. First, it allows the DRAM periphery – the logic transistors that enable the full functionality of the DRAM chip – to be moved under the DRAM memory array instead of residing next to it. This reduces the footprint of the DRAM memory chip and makes connections between the array and periphery more efficient. In this configuration, the 2T0C DRAM bit cells are integrated into the peri’s BEOL, which is allowed by the properties of the IGZO material.&lt;/p&gt;
    &lt;p&gt;Second, the novel bit cell paves the way for stacked configurations, providing an additional increase in density. Either ‘2D’ or ‘true 3D’ stacking can be envisioned. With 2D stacking, several layers with ‘planar’ DRAM memory arrays are stacked on top of each other. With 3D stacking, the transistors that make up the 2T0C bit cell are stacked and monolithically integrated into vertically aligned plugs inspired by 3D NAND technology. The ability to deposit IGZO conformally in these high-aspect-ratio plugs, enabled by the technique of atomic layer deposition (ALD), is a key enabler of this 3D structure. These stacked configurations will help tear down the memory wall, allowing DRAM memories to continue playing a crucial role in data-intensive applications such as cloud computing and artificial intelligence. Implementing the two transistors on different levels (stacked 2T0C) has an additional benefit. A low-off-current oxide semiconductor channel is only fundamental in the write transistor to ensure long retention. For the read transistor, on current is the critical parameter, as it drives the read time, and high-mobility channel materials can be considered. The two transistors can thus be optimized separately.&lt;/p&gt;
    &lt;head rend="h2"&gt;First ‘conceptual’ demonstration of an IGZO 2T0C DRAM bit cell&lt;/head&gt;
    &lt;p&gt;After pioneering the concept, imec provided the first experimental demonstration of a functional 2T0C DRAM cell at the 2020 IEEE International Electron Devices Meeting (IEDM) [1]. Thanks to a low (extracted) off current of 3x10-19A/µm, these first 2T0C DRAM cells exhibited a retention time &amp;gt;400s, about 1,000 times longer than typical DRAM refresh times. The results were obtained after scaling and optimizing IGZO-based thin-film transistors processed on 300mm wafers. Optimizations were directed towards suppressing the impact of oxygen and hydrogen defects, one of the main challenges for developing good-performing IGZO-based transistors. Optimized transistors with a 45nm gate length were then integrated into a 2T0C DRAM bit cell architecture, where the parasitic capacitance of the read transistor served as the storage element.&lt;/p&gt;
    &lt;p&gt;Do you want regular updates on imec’s semiconductor research?&lt;/p&gt;
    &lt;head rend="h2"&gt;Improving performance through bit cell engineering: an overview&lt;/head&gt;
    &lt;p&gt;Next, imec started to explore the knobs that allow the boosting of 2T0C DRAM density and improve performance and reliability metrics such as off current, data retention, endurance, on current, and threshold voltage (stability). In 2021 at IEDM, imec researchers presented a much-improved IGZO-based 2T0C DRAM bit cell with &amp;gt;1000s retention time and practically unlimited endurance (&amp;gt;1011 read and write cycles) with &amp;lt;10ns write time [2].&lt;/p&gt;
    &lt;p&gt;These breakthrough results followed an optimization of the IGZO transistor’s material stack and integration scheme: a gate-last approach with buried oxygen tunnel and self-aligned contacts combined with a scaled gate dielectric (Al2O3) thickness. Implementing the buried oxide tunnel in combination with an anneal in an O2 ambient reduced the oxygen-vacancy concentration in the IGZO channel, benefitting on and off currents.&lt;/p&gt;
    &lt;p&gt;This IGZO-DRAM technology set the stage for more aggressive DRAM scaling. The gate length of the IGZO transistor was scaled down to 14nm while still preserving &amp;gt;100s retention. The researchers also showed a variant of the 2T0C DRAM cell with much reduced IGZO layer thickness (5nm). This eliminated the need for an oxygen tunnel and O2 anneal step, leading to a simplified process flow. Imec also demonstrated functional transistors with conformally deposited thin IGZO channels (5nm, through ALD), a stepping stone towards 3D DRAM integration. [2]&lt;/p&gt;
    &lt;p&gt;More recently, imec used the reactive ion etch (RIE) technique instead of the commonly used ion beam etch (IBE) for patterning the active module of the 2T0C transistor. RIE allows for patterning at tiny dimensions (sub-100nm) with limited damage, further reducing area consumption. Moreover, using these transistors in 2T0C DRAM bit cells led to a much-improved retention time of &amp;gt;4.5 hours, thanks to an effective suppression of extrinsic leakage paths on the sidewalls of the transistor [3].&lt;/p&gt;
    &lt;p&gt;The potential of imec’s disruptive DRAM concept triggered interest from universities, research institutes, and companies worldwide. Several research groups started investigating other bit cell configurations, transistor performance ‘boosters,’ and alternative oxide semiconductor materials.&lt;/p&gt;
    &lt;p&gt;For example, IMECAS (Institute of Microelectronics of the Chinese Academy of Sciences), publishing about 2T0C IGZO DRAM since 2021, demonstrated an alternative 2T0C configuration to benefit multibit operation [4]. Later, they were the first to show transistors with a vertically integrated IGZO channel. The ability to monolithically stack the ‘vertical’ read and write transistors enables area-efficient 4F2 2D DRAM cell configurations (F being the minimum feature size for a given technology node) [5]. Macronix also implemented a 3D 2T0C bit cell with gate-around (GA) and channel-all-around (CAA) IGZO FETs [6]. Peking University optimized IGZO transistors based on material stack engineering, which enhanced 2T0C DRAM cell performance [7].&lt;/p&gt;
    &lt;p&gt;Thin-film transistors with oxide semiconductor channel materials other than IGZO are also being considered. One promising material is W-doped indium oxide (IWO), as showcased by Notre Dame University [8]. Stanford University initially considered indium-tin-oxide (ITO) for 2T0C implementation [9]. In 2024, in collaboration with TSMC, they also used IWO to build an n-type thin-film transistor. In addition, they were the first to combine the IWO n-type transistor with a p-type transistor also made of an oxide semiconductor (tin-oxide (SnO) in this case) for improved performance and reduction of coupling effects [10]. Most oxide semiconductor transistors are inherently n-type, which is why 2T0C DRAM bit cells usually implement two n-type transistors, for reading and writing.&lt;/p&gt;
    &lt;head rend="h2"&gt;The path to industry-viable IGZO-based 3D DRAM&lt;/head&gt;
    &lt;p&gt;2T0C IGZO-DRAM has recently been added to the long-term DRAM technology roadmap, according to a 2024 report of Yole Intelligence. The technology is envisioned as one of the possible approaches toward a much-desired 3D DRAM. Moreover, the demand for AI on edge devices is expected to surge in the coming years, generating the need for high-density embedded DRAM (eDRAM). The capacitor-less IGZO-DRAM technology is a very attractive candidate for this application. Building on its pioneering activities, imec started developing BEOL-compatible eDRAM implementations.&lt;/p&gt;
    &lt;p&gt;Yet, one key concern has made the memory industry hesitant to adopt IGZO-based DRAM technology: reliability. The n-type IGZO transistors mainly degrade because of the positive bias temperature instability (PBTI), which is manifested as an undesirable shift of the device threshold voltage and a decrease in the drain current. Worrisome is the hydrogen-related contribution to PBTI, a problem less familiar to the chip industry. Through the years, imec has made considerable progress in assessing, understanding, and modeling reliability failure, paving the way to building reliable IGZO transistors with a target lifetime of five years [11,12].&lt;/p&gt;
    &lt;p&gt;This work has been enabled in part by the NanoIC pilot line. The acquisition and operation are jointly funded by the Chips Joint Undertaking, through the European Union’s Digital Europe (101183266) and Horizon Europe programs (101183277), as well as by the participating states Belgium (Flanders), France, Germany, Finland, Ireland and Romania. For more information, visit nanoic-project.eu.&lt;/p&gt;
    &lt;p&gt;This article was originally published in Nature Reviews Electrical Engineering.&lt;/p&gt;
    &lt;head rend="h4"&gt;Want to know more?&lt;/head&gt;
    &lt;p&gt;[1] A. Belmonte et al. Capacitor-less, long-retention (&amp;gt;400s) DRAM cell paving the way towards low-power and high-density monolithic 3D DRAM. 2020 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[2] A. Belmonte et al. Tailoring IGZO-TFT architecture for capacitorless DRAM, demonstrating &amp;gt;103s retention, &amp;gt;1011 cycles endurance and Lg scalability down to 14nm. 2021 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[3] A. Belmonte et al. Lowest IOFF&amp;lt;3x10-21A/µm in capacitorless DRAM achieved by reactive ion etch of IGZO-TFT. 2023 Symposium on VLSI Technology and Circuits.&lt;/p&gt;
    &lt;p&gt;[4] K. Chen et al. Improved multi-bit statistics of novel dual-gate IGZO 2T0C DRAM with In-cell VTH compensation and ∆VSN/∆VDATA boosting technique. 2023 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[5] F. Liao et al. Novel 4F2 multi-bit dual-gate 2T0C for high-density DRAM with improved vertical-channel IGZO TFTs by self-aligned single-step process. 2024 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[6] F.-M. Lee et al. Bit-Cost-Scalable 3D DRAM Architecture and Unit Cell First Demonstrated with Integrated Gate-Around and Channel-Around IGZO FETs. 2024 Symposium on VLSI Technology and Circuits.&lt;/p&gt;
    &lt;p&gt;[7] Q. Hu et al. Optimized IGZO FETs for capacitorless DRAM with retention of 10 ks at RT and 7 ks at 85°C at zero Vhold with sub-10ns speed and 3-bit operation. 2022 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[8] H. Ye et al. Double-gate W-doped amorphous indium oxide transistors for monolithic 3D capacitorless gain cell eDRAM. 2022 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[9] S. Liu et al. Gain cell memory on logic platform – device guidelines for oxide semiconductor transistor materials development. 2023 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[10] F. F. Athena et al. First demonstration of an n-p oxide semiconductor complementary gain cell memory. 2024 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[11] A. Chasin et al. Understanding and modelling the PBTI reliability of thin-film IGZO transistors. 2024 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;[12] A. Chasin et al. Unraveling BTI in IGZO devices: impact of device architecture, channel film deposition method and stoichiometry/phase, and device operating conditions. 2024 IEEE International Electron Devices Meeting.&lt;/p&gt;
    &lt;p&gt;Attilio Belmonte is the program manager of active memory at imec, Belgium, where he manages projects related to various memory devices, namely (3D)DRAM, OTS selectors, and FeRAM. He joined imec in 2011 and received his Ph.D. in Physics from KU Leuven, Belgium, in 2015, with a dissertation on novel CBRAM devices. As a researcher, he explored several emerging memory devices, mainly focusing on RRAM, oxide semiconductors, and alternative high-K dielectrics for DRAM. He authored and co-authored more than 85 journal and conference publications.&lt;/p&gt;
    &lt;p&gt;Gouri Sankar Kar received his Ph.D. in semiconductor device physics from the Indian Institute of Technology, Kharagpur, India, in 2002. From 2002 to 2005, he was a visiting scientist at the Max Planck Institute for Solid State Research, Stuttgart, Germany. In 2006, he joined Infineon/Qimonda in Dresden, Germany, as lead integration engineer and was responsible for vertical transistor development for the DRAM application. In 2009, he joined imec, Leuven, Belgium, where he is currently working as the VP R&amp;amp;D Compute &amp;amp; Memory Device Technologies&lt;/p&gt;
    &lt;p&gt;Published on:&lt;/p&gt;
    &lt;p&gt;25 March 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.imec-int.com/en/articles/disrupting-dram-roadmap-capacitor-less-igzo-dram-technology"/></entry><entry><id>https://news.ycombinator.com/item?id=45182770</id><title>A new experimental Go API for JSON</title><updated>2025-09-09T18:12:56.284922+00:00</updated><content>&lt;doc fingerprint="ea98b5f92c34fd0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Go Blog&lt;/head&gt;
    &lt;head rend="h1"&gt;A new experimental Go API for JSON&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;JavaScript Object Notation (JSON) is a simple data interchange format. Almost 15 years ago, we wrote about support for JSON in Go, which introduced the ability to serialize and deserialize Go types to and from JSON data. Since then, JSON has become the most popular data format used on the Internet. It is widely read and written by Go programs, and encoding/json now ranks as the 5th most imported Go package.&lt;/p&gt;
    &lt;p&gt;Over time, packages evolve with the needs of their users, and &lt;code&gt;encoding/json&lt;/code&gt; is no exception. This blog post is about Go 1.25’s new
experimental &lt;code&gt;encoding/json/v2&lt;/code&gt; and &lt;code&gt;encoding/json/jsontext&lt;/code&gt; packages,
which bring long-awaited improvements and fixes.
This post argues for a new major API version,
provides an overview of the new packages,
and explains how you can make use of it.
The experimental packages are not visible by default and
may undergo future API changes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problems with &lt;code&gt;encoding/json&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Overall, &lt;code&gt;encoding/json&lt;/code&gt; has held up well.
The idea of marshaling and unmarshaling arbitrary Go types
with some default representation in JSON, combined with the ability to
customize the representation, has proven to be highly flexible.
However, in the years since its introduction,
various users have identified numerous shortcomings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Behavior flaws&lt;/head&gt;
    &lt;p&gt;There are various behavioral flaws in &lt;code&gt;encoding/json&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Imprecise handling of JSON syntax: Over the years, JSON has seen increased standardization in order for programs to properly communicate. Generally, decoders have become stricter at rejecting ambiguous inputs, to reduce the chance that two implementations will have different (successful) interpretations of a particular JSON value.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;encoding/json&lt;/code&gt;currently accepts invalid UTF-8, whereas the latest Internet Standard (RFC 8259) requires valid UTF-8. The default behavior should report an error in the presence of invalid UTF-8, instead of introducing silent data corruption, which may cause problems downstream.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;encoding/json&lt;/code&gt;currently accepts objects with duplicate member names. RFC 8259 does not specify how to handle duplicate names, so an implementation is free to choose an arbitrary value, merge the values, discard the values, or report an error. The presence of a duplicate name results in a JSON value without a universally agreed upon meaning. This could be exploited by attackers in security applications and has been exploited before (as in CVE-2017-12635). The default behavior should err on the side of safety and reject duplicate names.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Leaking nilness of slices and maps: JSON is often used to communicate with programs using JSON implementations that do not allow&lt;/p&gt;&lt;code&gt;null&lt;/code&gt;to be unmarshaled into a data type expected to be a JSON array or object. Since&lt;code&gt;encoding/json&lt;/code&gt;marshals a nil slice or map as a JSON&lt;code&gt;null&lt;/code&gt;, this may lead to errors when unmarshaling by other implementations. A survey indicated that most Go users prefer that nil slices and maps are marshaled as an empty JSON array or object by default.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Case-insensitive unmarshaling: When unmarshaling, a JSON object member name is resolved to a Go struct field name using a case-insensitive match. This is a surprising default, a potential security vulnerability, and a performance limitation.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Inconsistent calling of methods: Due to an implementation detail,&lt;/p&gt;&lt;code&gt;MarshalJSON&lt;/code&gt;methods declared on a pointer receiver are inconsistently called by&lt;code&gt;encoding/json&lt;/code&gt;. While regarded as a bug, this cannot be fixed as too many applications depend on the current behavior.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;API deficiencies&lt;/head&gt;
    &lt;p&gt;The API of &lt;code&gt;encoding/json&lt;/code&gt; can be tricky or restrictive:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;It is difficult to correctly unmarshal from an&lt;/p&gt;&lt;code&gt;io.Reader&lt;/code&gt;. Users often write&lt;code&gt;json.NewDecoder(r).Decode(v)&lt;/code&gt;, which fails to reject trailing junk at the end of the input.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Options can be set on the&lt;/p&gt;&lt;code&gt;Encoder&lt;/code&gt;and&lt;code&gt;Decoder&lt;/code&gt;types, but cannot be used with the&lt;code&gt;Marshal&lt;/code&gt;and&lt;code&gt;Unmarshal&lt;/code&gt;functions. Similarly, types implementing the&lt;code&gt;Marshaler&lt;/code&gt;and&lt;code&gt;Unmarshaler&lt;/code&gt;interfaces cannot make use of the options and there is no way to plumb options down the call stack. For example, the&lt;code&gt;Decoder.DisallowUnknownFields&lt;/code&gt;option loses its effect when calling a custom&lt;code&gt;UnmarshalJSON&lt;/code&gt;method.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;Compact&lt;/code&gt;,&lt;code&gt;Indent&lt;/code&gt;, and&lt;code&gt;HTMLEscape&lt;/code&gt;functions write to a&lt;code&gt;bytes.Buffer&lt;/code&gt;instead of something more flexible like a&lt;code&gt;[]byte&lt;/code&gt;or&lt;code&gt;io.Writer&lt;/code&gt;. This limits the usability of those functions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Performance limitations&lt;/head&gt;
    &lt;p&gt;Setting aside internal implementation details, the public API commits it to certain performance limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;MarshalJSON: The&lt;/p&gt;&lt;code&gt;MarshalJSON&lt;/code&gt;interface method forces the implementation to allocate the returned&lt;code&gt;[]byte&lt;/code&gt;. Also, the semantics require that&lt;code&gt;encoding/json&lt;/code&gt;verify that the result is valid JSON and also to reformat it to match the specified indentation.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;UnmarshalJSON: The&lt;/p&gt;&lt;code&gt;UnmarshalJSON&lt;/code&gt;interface method requires that a complete JSON value be provided (without any trailing data). This forces&lt;code&gt;encoding/json&lt;/code&gt;to parse the JSON value to be unmarshaled in its entirety to determine where it ends before it can call&lt;code&gt;UnmarshalJSON&lt;/code&gt;. Afterwards, the&lt;code&gt;UnmarshalJSON&lt;/code&gt;method itself must parse the provided JSON value again.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Lack of streaming: Even though the&lt;/p&gt;&lt;code&gt;Encoder&lt;/code&gt;and&lt;code&gt;Decoder&lt;/code&gt;types operate on an&lt;code&gt;io.Writer&lt;/code&gt;or&lt;code&gt;io.Reader&lt;/code&gt;, they buffer the entire JSON value in memory. The&lt;code&gt;Decoder.Token&lt;/code&gt;method for reading individual tokens is allocation-heavy and there is no corresponding API for writing tokens.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Furthermore, if the implementation of a &lt;code&gt;MarshalJSON&lt;/code&gt; or &lt;code&gt;UnmarshalJSON&lt;/code&gt; method
recursively calls the &lt;code&gt;Marshal&lt;/code&gt; or &lt;code&gt;Unmarshal&lt;/code&gt; function,
then the performance becomes quadratic.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trying to fix &lt;code&gt;encoding/json&lt;/code&gt; directly&lt;/head&gt;
    &lt;p&gt;Introducing a new, incompatible major version of a package is a heavy consideration. If possible, we should try to fix the existing package.&lt;/p&gt;
    &lt;p&gt;While it is relatively easy to add new features, it is difficult to change existing features. Unfortunately, these problems are inherent consequences of the existing API, making them practically impossible to fix within the Go 1 compatibility promise.&lt;/p&gt;
    &lt;p&gt;We could in principle declare separate names, such as &lt;code&gt;MarshalV2&lt;/code&gt; or &lt;code&gt;UnmarshalV2&lt;/code&gt;,
but that is tantamount to creating a parallel namespace within the same package.
This leads us to &lt;code&gt;encoding/json/v2&lt;/code&gt; (henceforth called &lt;code&gt;v2&lt;/code&gt;),
where we can make these changes within a seperate &lt;code&gt;v2&lt;/code&gt; namespace
in contrast to &lt;code&gt;encoding/json&lt;/code&gt; (henceforth called &lt;code&gt;v1&lt;/code&gt;).&lt;/p&gt;
    &lt;head rend="h2"&gt;Planning for &lt;code&gt;encoding/json/v2&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The planning for a new major version of &lt;code&gt;encoding/json&lt;/code&gt; spanned years.
In late 2020, spurred on by the inability to fix issues in the current package,
Daniel Martí (one of the maintainers of &lt;code&gt;encoding/json&lt;/code&gt;) first drafted his
thoughts on what a hypothetical &lt;code&gt;v2&lt;/code&gt; package should look like.
Separately, after previous work on the Go API for Protocol Buffers,
Joe Tsai was disapppointed that the &lt;code&gt;protojson&lt;/code&gt; package
needed to use a custom JSON implementation because &lt;code&gt;encoding/json&lt;/code&gt; was
neither capable of adhering to the stricter JSON standard that the
Protocol Buffer specification required,
nor of efficiently serializing JSON in a streaming manner.&lt;/p&gt;
    &lt;p&gt;Believing a brighter future for JSON was both beneficial and achievable, Daniel and Joe joined forces to brainstorm on &lt;code&gt;v2&lt;/code&gt; and
started to build a prototype
(with the initial code being a polished version of the JSON serialization logic from the Go protobuf module).
Over time, a few others (Roger Peppe, Chris Hines, Johan Brandhorst-Satzkorn, and Damien Neil)
joined the effort by providing design review, code review, and regression testing.
Many of the early discussions are publicly available in our
recorded meetings and
meeting notes.&lt;/p&gt;
    &lt;p&gt;This work has been public since the beginning, and we increasingly involved the wider Go community, first with a GopherCon talk and discussion posted in late 2023, formal proposal posted in early 2025, and most recently adopting &lt;code&gt;encoding/json/v2&lt;/code&gt; as a Go experiment
(available in Go 1.25) for wider-scale testing by all Go users.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;v2&lt;/code&gt; effort has been going on for 5 years,
incorporating feedback from many contributors and also gaining valuable
empirical experience from use in production settings.&lt;/p&gt;
    &lt;p&gt;It’s worth noting that it’s largely been developed and promoted by people not employed by Google, demonstrating that the Go project is a collaborative endeavor with a thriving global community dedicated to improving the Go ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building on &lt;code&gt;encoding/json/jsontext&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Before discussing the &lt;code&gt;v2&lt;/code&gt; API, we first introduce the experimental
&lt;code&gt;encoding/json/jsontext&lt;/code&gt; package
that lays the foundation for future improvements to JSON in Go.&lt;/p&gt;
    &lt;p&gt;JSON serialization in Go can be broken down into two primary components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;syntactic functionality that is concerned with processing JSON based on its grammar, and&lt;/item&gt;
      &lt;item&gt;semantic functionality that defines the relationship between JSON values and Go values.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We use the terms “encode” and “decode” to describe syntactic functionality and the terms “marshal” and “unmarshal” to describe semantic functionality. We aim to provide a clear distinction between functionality that is purely concerned with encoding versus that of marshaling.&lt;/p&gt;
    &lt;p&gt;This diagram provides an overview of this separation. Purple blocks represent types, while blue blocks represent functions or methods. The direction of the arrows approximately represents the flow of data. The bottom half of the diagram, implemented by the &lt;code&gt;jsontext&lt;/code&gt; package,
contains functionality that is only concerned with syntax,
while the upper half, implemented by the &lt;code&gt;json/v2&lt;/code&gt; package,
contains functionality that assigns semantic meaning to syntactic data
handled by the bottom half.&lt;/p&gt;
    &lt;p&gt;The basic API of &lt;code&gt;jsontext&lt;/code&gt; is the following:&lt;/p&gt;
    &lt;code&gt;package jsontext

type Encoder struct { ... }
func NewEncoder(io.Writer, ...Options) *Encoder
func (*Encoder) WriteValue(Value) error
func (*Encoder) WriteToken(Token) error

type Decoder struct { ... }
func NewDecoder(io.Reader, ...Options) *Decoder
func (*Decoder) ReadValue() (Value, error)
func (*Decoder) ReadToken() (Token, error)

type Kind byte
type Value []byte
func (Value) Kind() Kind
type Token struct { ... }
func (Token) Kind() Kind
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;jsontext&lt;/code&gt; package provides functionality for interacting with JSON
at a syntactic level and derives its name from
RFC 8259, section 2
where the grammar for JSON data is literally called &lt;code&gt;JSON-text&lt;/code&gt;.
Since it only interacts with JSON at a syntactic level,
it does not depend on Go reflection.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;Encoder&lt;/code&gt; and
&lt;code&gt;Decoder&lt;/code&gt;
provide support for encoding and decoding JSON values and tokens.
The constructors
accept variadic options
that affect the particular behavior of encoding and decoding.
Unlike the &lt;code&gt;Encoder&lt;/code&gt; and &lt;code&gt;Decoder&lt;/code&gt; types declared in &lt;code&gt;v1&lt;/code&gt;,
the new types in &lt;code&gt;jsontext&lt;/code&gt; avoid muddling the distinction between syntax and
semantics and operate in a truly streaming manner.&lt;/p&gt;
    &lt;p&gt;A JSON value is a complete unit of data and is represented in Go as a named &lt;code&gt;[]byte&lt;/code&gt;.
It is identical to &lt;code&gt;RawMessage&lt;/code&gt; in &lt;code&gt;v1&lt;/code&gt;.
A JSON value is syntactically composed of one or more JSON tokens.
A JSON token is represented in Go as the opaque &lt;code&gt;Token&lt;/code&gt; type
with constructors and accessor methods.
It is analogous to &lt;code&gt;Token&lt;/code&gt; in &lt;code&gt;v1&lt;/code&gt;
but is designed represent arbitrary JSON tokens without allocation.&lt;/p&gt;
    &lt;p&gt;To resolve the fundamental performance problems with the &lt;code&gt;MarshalJSON&lt;/code&gt; and &lt;code&gt;UnmarshalJSON&lt;/code&gt; interface methods,
we need an efficient way of encoding and decoding JSON
as a streaming sequence of tokens and values.
In &lt;code&gt;v2&lt;/code&gt;, we introduce the &lt;code&gt;MarshalJSONTo&lt;/code&gt; and &lt;code&gt;UnmarshalJSONFrom&lt;/code&gt; interface methods
that operate on an &lt;code&gt;Encoder&lt;/code&gt; or &lt;code&gt;Decoder&lt;/code&gt;, allowing the methods’ implementations
to process JSON in a purely streaming manner. Thus, the &lt;code&gt;json&lt;/code&gt; package need not
be responsible for validating or formatting a JSON value returned by &lt;code&gt;MarshalJSON&lt;/code&gt;,
nor would it need to be responsible for determining the boundaries of a JSON value
provided to &lt;code&gt;UnmarshalJSON&lt;/code&gt;. These responsibilities belong to the &lt;code&gt;Encoder&lt;/code&gt; and &lt;code&gt;Decoder&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing &lt;code&gt;encoding/json/v2&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Building on the &lt;code&gt;jsontext&lt;/code&gt; package, we now introduce the experimental
&lt;code&gt;encoding/json/v2&lt;/code&gt; package.
It is designed to fix the aforementioned problems,
while remaining familiar to users of the &lt;code&gt;v1&lt;/code&gt; package.
Our goal is that usages of &lt;code&gt;v1&lt;/code&gt; will operate mostly the same if directly migrated to &lt;code&gt;v2&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In this article, we will primarily cover the high-level API of &lt;code&gt;v2&lt;/code&gt;.
For examples on how to use it, we encourage readers to
study the examples in the &lt;code&gt;v2&lt;/code&gt; package or
read Anton Zhiyanov’s blog covering the topic.&lt;/p&gt;
    &lt;p&gt;The basic API of &lt;code&gt;v2&lt;/code&gt; is the following:&lt;/p&gt;
    &lt;code&gt;package json

func Marshal(in any, opts ...Options) (out []byte, err error)
func MarshalWrite(out io.Writer, in any, opts ...Options) error
func MarshalEncode(out *jsontext.Encoder, in any, opts ...Options) error

func Unmarshal(in []byte, out any, opts ...Options) error
func UnmarshalRead(in io.Reader, out any, opts ...Options) error
func UnmarshalDecode(in *jsontext.Decoder, out any, opts ...Options) error
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;Marshal&lt;/code&gt;
and &lt;code&gt;Unmarshal&lt;/code&gt; functions
have a signature similar to &lt;code&gt;v1&lt;/code&gt;, but accept options to configure their behavior.
The &lt;code&gt;MarshalWrite&lt;/code&gt;
and &lt;code&gt;UnmarshalRead&lt;/code&gt; functions
directly operate on an &lt;code&gt;io.Writer&lt;/code&gt; or &lt;code&gt;io.Reader&lt;/code&gt;,
avoiding the need to temporarily construct an &lt;code&gt;Encoder&lt;/code&gt; or &lt;code&gt;Decoder&lt;/code&gt;
just to write or read from such types.
The &lt;code&gt;MarshalEncode&lt;/code&gt;
and &lt;code&gt;UnmarshalDecode&lt;/code&gt; functions
operate on a &lt;code&gt;jsontext.Encoder&lt;/code&gt; and &lt;code&gt;jsontext.Decoder&lt;/code&gt; and
is actually the underlying implementation of the previously mentioned functions.
Unlike &lt;code&gt;v1&lt;/code&gt;, options are a first-class argument to each of the marshal and unmarshal functions,
greatly extending the flexibility and configurability of &lt;code&gt;v2&lt;/code&gt;.
There are several options available
in &lt;code&gt;v2&lt;/code&gt; which are not covered by this article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Type-specified customization&lt;/head&gt;
    &lt;p&gt;Similar to &lt;code&gt;v1&lt;/code&gt;, &lt;code&gt;v2&lt;/code&gt; allows types to define their own JSON representation
by satisfying particular interfaces.&lt;/p&gt;
    &lt;code&gt;type Marshaler interface {
    MarshalJSON() ([]byte, error)
}
type MarshalerTo interface {
    MarshalJSONTo(*jsontext.Encoder) error
}

type Unmarshaler interface {
    UnmarshalJSON([]byte) error
}
type UnmarshalerFrom interface {
    UnmarshalJSONFrom(*jsontext.Decoder) error
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;Marshaler&lt;/code&gt;
and &lt;code&gt;Unmarshaler&lt;/code&gt; interfaces
are identical to those in &lt;code&gt;v1&lt;/code&gt;.
The new &lt;code&gt;MarshalerTo&lt;/code&gt;
and &lt;code&gt;UnmarshalerFrom&lt;/code&gt; interfaces
allow a type to represent itself as JSON using a &lt;code&gt;jsontext.Encoder&lt;/code&gt; or &lt;code&gt;jsontext.Decoder&lt;/code&gt;.
This allows options to be forwarded down the call stack, since options
can be retrieved via the &lt;code&gt;Options&lt;/code&gt; accessor method on the &lt;code&gt;Encoder&lt;/code&gt; or &lt;code&gt;Decoder&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;See the &lt;code&gt;OrderedObject&lt;/code&gt; example
for how to implement a custom type that maintains the ordering of JSON object members.&lt;/p&gt;
    &lt;head rend="h3"&gt;Caller-specified customization&lt;/head&gt;
    &lt;p&gt;In &lt;code&gt;v2&lt;/code&gt;, the caller of &lt;code&gt;Marshal&lt;/code&gt; and &lt;code&gt;Unmarshal&lt;/code&gt; can also specify
a custom JSON representation for any arbitrary type,
where caller-specified functions take precedence over type-defined methods
or the default representation for a particular type.&lt;/p&gt;
    &lt;code&gt;func WithMarshalers(*Marshalers) Options

type Marshalers struct { ... }
func MarshalFunc[T any](fn func(T) ([]byte, error)) *Marshalers
func MarshalToFunc[T any](fn func(*jsontext.Encoder, T) error) *Marshalers

func WithUnmarshalers(*Unmarshalers) Options

type Unmarshalers struct { ... }
func UnmarshalFunc[T any](fn func([]byte, T) error) *Unmarshalers
func UnmarshalFromFunc[T any](fn func(*jsontext.Decoder, T) error) *Unmarshalers
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;MarshalFunc&lt;/code&gt; and
&lt;code&gt;MarshalToFunc&lt;/code&gt;
construct a custom marshaler that can be passed to a &lt;code&gt;Marshal&lt;/code&gt; call
using &lt;code&gt;WithMarshalers&lt;/code&gt; to override the marshaling of particular types.
Similarly,
&lt;code&gt;UnmarshalFunc&lt;/code&gt; and
&lt;code&gt;UnmarshalFromFunc&lt;/code&gt;
support similar customization for &lt;code&gt;Unmarshal&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;ProtoJSON&lt;/code&gt; example
demonstrates how this feature allows serialization of all
&lt;code&gt;proto.Message&lt;/code&gt; types
to be handled by the &lt;code&gt;protojson&lt;/code&gt; package.&lt;/p&gt;
    &lt;head rend="h3"&gt;Behavior differences&lt;/head&gt;
    &lt;p&gt;While &lt;code&gt;v2&lt;/code&gt; aims to behave mostly the same as &lt;code&gt;v1&lt;/code&gt;,
its behavior has changed in some ways
to address problems in &lt;code&gt;v1&lt;/code&gt;, most notably:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;v2&lt;/code&gt;reports an error in the presence of invalid UTF-8.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;v2&lt;/code&gt;reports an error if a JSON object contains a duplicate name.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;v2&lt;/code&gt;marshals a nil Go slice or Go map as an empty JSON array or JSON object, respectively.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;v2&lt;/code&gt;unmarshals a JSON object into a Go struct using a case-sensitive match from the JSON member name to the Go field name.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;v2&lt;/code&gt;redefines the&lt;code&gt;omitempty&lt;/code&gt;tag option to omit a field if it would have encoded as an “empty” JSON value (which are&lt;code&gt;null&lt;/code&gt;,&lt;code&gt;""&lt;/code&gt;,&lt;code&gt;[]&lt;/code&gt;, and&lt;code&gt;{}&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;v2&lt;/code&gt;reports an error when trying to serialize a&lt;code&gt;time.Duration&lt;/code&gt;, which currently has no default representation, but provides options to let the caller decide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For most behavior changes, there is a struct tag option or caller-specified option that can configure the behavior to operate under &lt;code&gt;v1&lt;/code&gt; or &lt;code&gt;v2&lt;/code&gt; semantics,
or even other caller-determined behavior.
See “Migrating to v2” for more information.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance optimizations&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;Marshal&lt;/code&gt; performance of &lt;code&gt;v2&lt;/code&gt; is roughly at parity with &lt;code&gt;v1&lt;/code&gt;.
Sometimes it is slightly faster, but other times it is slightly slower.
The &lt;code&gt;Unmarshal&lt;/code&gt; performance of &lt;code&gt;v2&lt;/code&gt; is significantly faster than &lt;code&gt;v1&lt;/code&gt;,
with benchmarks demonstrating improvements of up to 10x.&lt;/p&gt;
    &lt;p&gt;In order to obtain greater performance gains, existing implementations of &lt;code&gt;Marshaler&lt;/code&gt; and
&lt;code&gt;Unmarshaler&lt;/code&gt; should
migrate to also implement
&lt;code&gt;MarshalerTo&lt;/code&gt; and
&lt;code&gt;UnmarshalerFrom&lt;/code&gt;,
so that they can benefit from processing JSON in a purely streaming manner.
For example, recursive parsing of OpenAPI specifications in &lt;code&gt;UnmarshalJSON&lt;/code&gt; methods
significantly hurt performance in a particular service of Kubernetes
(see kubernetes/kube-openapi#315),
while switching to &lt;code&gt;UnmarshalJSONFrom&lt;/code&gt; improved performance by orders of magnitude.&lt;/p&gt;
    &lt;p&gt;For more information, see the &lt;code&gt;go-json-experiment/jsonbench&lt;/code&gt;
repository.&lt;/p&gt;
    &lt;head rend="h2"&gt;Retroactively improving &lt;code&gt;encoding/json&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;We want to avoid two separate JSON implementations in the Go standard library, so it is critical that, under the hood, &lt;code&gt;v1&lt;/code&gt; is implemented in terms of &lt;code&gt;v2&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There are several benefits to this approach:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Gradual migration: The&lt;/p&gt;&lt;code&gt;Marshal&lt;/code&gt;and&lt;code&gt;Unmarshal&lt;/code&gt;functions in&lt;code&gt;v1&lt;/code&gt;or&lt;code&gt;v2&lt;/code&gt;represent a set of default behaviors that operate according to&lt;code&gt;v1&lt;/code&gt;or&lt;code&gt;v2&lt;/code&gt;semantics. Options can be specified that configure&lt;code&gt;Marshal&lt;/code&gt;or&lt;code&gt;Unmarshal&lt;/code&gt;to operate with entirely&lt;code&gt;v1&lt;/code&gt;, mostly&lt;code&gt;v1&lt;/code&gt;with a some&lt;code&gt;v2&lt;/code&gt;, a mix of&lt;code&gt;v1&lt;/code&gt;or&lt;code&gt;v2&lt;/code&gt;, mostly&lt;code&gt;v2&lt;/code&gt;with some&lt;code&gt;v1&lt;/code&gt;, or entirely&lt;code&gt;v2&lt;/code&gt;semantics. This allows for gradual migration between the default behaviors of the two versions.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Feature inheritance: As backward-compatible features are added to&lt;/p&gt;&lt;code&gt;v2&lt;/code&gt;, they will inherently be made available in&lt;code&gt;v1&lt;/code&gt;. For example,&lt;code&gt;v2&lt;/code&gt;adds support for several new struct tag options such as&lt;code&gt;inline&lt;/code&gt;or&lt;code&gt;format&lt;/code&gt;and also support for the&lt;code&gt;MarshalJSONTo&lt;/code&gt;and&lt;code&gt;UnmarshalJSONFrom&lt;/code&gt;interface methods, which are both more performant and flexible. When&lt;code&gt;v1&lt;/code&gt;is implemented in terms of&lt;code&gt;v2&lt;/code&gt;, it will inherit support for these features.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Reduced maintenance: Maintenance of a widely used package demands significant effort. By having&lt;/p&gt;&lt;code&gt;v1&lt;/code&gt;and&lt;code&gt;v2&lt;/code&gt;use the same implementation, the maintenance burden is reduced. In general, a single change will fix bugs, improve performance, or add functionality to both versions. There is no need to backport a&lt;code&gt;v2&lt;/code&gt;change with an equivalent&lt;code&gt;v1&lt;/code&gt;change.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While select parts of &lt;code&gt;v1&lt;/code&gt; may be deprecated over time (supposing &lt;code&gt;v2&lt;/code&gt; graduates from being an experiment),
the package as a whole will never be deprecated.
Migrating to &lt;code&gt;v2&lt;/code&gt; will be encouraged, but not required.
The Go project will not drop support for &lt;code&gt;v1&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Experimenting with &lt;code&gt;jsonv2&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The newer API in the &lt;code&gt;encoding/json/jsontext&lt;/code&gt; and &lt;code&gt;encoding/json/v2&lt;/code&gt; packages are not visible by default.
To use them, build your code with &lt;code&gt;GOEXPERIMENT=jsonv2&lt;/code&gt; set in your environment or with the &lt;code&gt;goexperiment.jsonv2&lt;/code&gt; build tag.
The nature of an experiment is that the API is unstable and may change in the future.
Though the API is unstable, the implementation is of a high quality and
has been successfully used in production by several major projects.&lt;/p&gt;
    &lt;p&gt;The fact that &lt;code&gt;v1&lt;/code&gt; is implemented in terms of &lt;code&gt;v2&lt;/code&gt; means that the underlying implementation of &lt;code&gt;v1&lt;/code&gt;
is completely different when building under the &lt;code&gt;jsonv2&lt;/code&gt; experiment.
Without changing any code, you should be able to run your tests
under &lt;code&gt;jsonv2&lt;/code&gt; and theoretically nothing new should fail:&lt;/p&gt;
    &lt;code&gt;GOEXPERIMENT=jsonv2 go test ./...
&lt;/code&gt;
    &lt;p&gt;The re-implementation of &lt;code&gt;v1&lt;/code&gt; in terms of &lt;code&gt;v2&lt;/code&gt; aims to provide identical behavior
within the bounds of the Go 1 compatibility promise,
though some differences might be observable such as the exact wording of error messages.
We encourage you to run your tests under &lt;code&gt;jsonv2&lt;/code&gt; and
report any regressions on the issue tracker.&lt;/p&gt;
    &lt;p&gt;Becoming an experiment in Go 1.25 is a significant milestone on the road to formally adopting &lt;code&gt;encoding/json/jsontext&lt;/code&gt; and &lt;code&gt;encoding/json/v2&lt;/code&gt; into the standard library.
However, the purpose of the &lt;code&gt;jsonv2&lt;/code&gt; experiment is to gain broader experience.
Your feedback will determine our next steps, and the outcome of this experiment,
which may result in anything from abandonment of the effort, to adoption as stable packages of Go 1.26.
Please share your experience on go.dev/issue/71497, and help determine the future of Go.&lt;/p&gt;
    &lt;p&gt; Previous article: Testing Time (and other asynchronicities)&lt;lb/&gt; Blog Index &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://go.dev/blog/jsonv2-exp"/></entry><entry><id>https://news.ycombinator.com/item?id=45183029</id><title>We all dodged a bullet</title><updated>2025-09-09T18:12:56.038131+00:00</updated><content>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xeiaso.net/notes/2025/we-dodged-a-bullet/"/></entry><entry><id>https://news.ycombinator.com/item?id=45183039</id><title>X open sourced their latest algorithm</title><updated>2025-09-09T18:12:55.522542+00:00</updated><content>&lt;doc fingerprint="334a9371444e26e2"&gt;
  &lt;main&gt;
    &lt;p&gt;X's Recommendation Algorithm is a set of services and jobs that are responsible for serving feeds of posts and other content across all X product surfaces (e.g. For You Timeline, Search, Explore, Notifications). For an introduction to how the algorithm works, please refer to our engineering blog.&lt;/p&gt;
    &lt;p&gt;Product surfaces at X are built on a shared set of data, models, and software frameworks. The shared components included in this repository are listed below:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Data&lt;/cell&gt;
        &lt;cell&gt;tweetypie&lt;/cell&gt;
        &lt;cell&gt;Core service that handles the reading and writing of post data.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;unified-user-actions&lt;/cell&gt;
        &lt;cell&gt;Real-time stream of user actions on X.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;user-signal-service&lt;/cell&gt;
        &lt;cell&gt;Centralized platform to retrieve explicit (e.g. likes, replies) and implicit (e.g. profile visits, tweet clicks) user signals.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Model&lt;/cell&gt;
        &lt;cell&gt;SimClusters&lt;/cell&gt;
        &lt;cell&gt;Community detection and sparse embeddings into those communities.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;TwHIN&lt;/cell&gt;
        &lt;cell&gt;Dense knowledge graph embeddings for Users and Posts.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;trust-and-safety-models&lt;/cell&gt;
        &lt;cell&gt;Models for detecting NSFW or abusive content.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;real-graph&lt;/cell&gt;
        &lt;cell&gt;Model to predict the likelihood of an X User interacting with another User.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;tweepcred&lt;/cell&gt;
        &lt;cell&gt;Page-Rank algorithm for calculating X User reputation.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;recos-injector&lt;/cell&gt;
        &lt;cell&gt;Streaming event processor for building input streams for GraphJet based services.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;graph-feature-service&lt;/cell&gt;
        &lt;cell&gt;Serves graph features for a directed pair of users (e.g. how many of User A's following liked posts from User B).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;topic-social-proof&lt;/cell&gt;
        &lt;cell&gt;Identifies topics related to individual posts.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;representation-scorer&lt;/cell&gt;
        &lt;cell&gt;Compute scores between pairs of entities (Users, Posts, etc.) using embedding similarity.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Software framework&lt;/cell&gt;
        &lt;cell&gt;navi&lt;/cell&gt;
        &lt;cell&gt;High performance, machine learning model serving written in Rust.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;product-mixer&lt;/cell&gt;
        &lt;cell&gt;Software framework for building feeds of content.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;timelines-aggregation-framework&lt;/cell&gt;
        &lt;cell&gt;Framework for generating aggregate features in batch or real time.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;representation-manager&lt;/cell&gt;
        &lt;cell&gt;Service to retrieve embeddings (i.e. SimClusers and TwHIN).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;twml&lt;/cell&gt;
        &lt;cell&gt;Legacy machine learning framework built on TensorFlow v1.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The product surfaces currently included in this repository are the For You Timeline and Recommended Notifications.&lt;/p&gt;
    &lt;p&gt;The diagram below illustrates how major services and jobs interconnect to construct a For You Timeline.&lt;/p&gt;
    &lt;p&gt;The core components of the For You Timeline included in this repository are listed below:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Candidate Source&lt;/cell&gt;
        &lt;cell&gt;search-index&lt;/cell&gt;
        &lt;cell&gt;Find and rank In-Network posts. ~50% of posts come from this candidate source.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;tweet-mixer&lt;/cell&gt;
        &lt;cell&gt;Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;user-tweet-entity-graph (UTEG)&lt;/cell&gt;
        &lt;cell&gt;Maintains an in memory User to Post interaction graph, and finds candidates based on traversals of this graph. This is built on the GraphJet framework. Several other GraphJet based features and candidate sources are located here.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;follow-recommendation-service (FRS)&lt;/cell&gt;
        &lt;cell&gt;Provides Users with recommendations for accounts to follow, and posts from those accounts.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ranking&lt;/cell&gt;
        &lt;cell&gt;light-ranker&lt;/cell&gt;
        &lt;cell&gt;Light Ranker model used by search index (Earlybird) to rank posts.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;heavy-ranker&lt;/cell&gt;
        &lt;cell&gt;Neural network for ranking candidate posts. One of the main signals used to select timeline posts post candidate sourcing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Post mixing &amp;amp; filtering&lt;/cell&gt;
        &lt;cell&gt;home-mixer&lt;/cell&gt;
        &lt;cell&gt;Main service used to construct and serve the Home Timeline. Built on product-mixer.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;visibility-filters&lt;/cell&gt;
        &lt;cell&gt;Responsible for filtering X content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;timelineranker&lt;/cell&gt;
        &lt;cell&gt;Legacy service which provides relevance-scored posts from the Earlybird Search Index and UTEG service.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The core components of Recommended Notifications included in this repository are listed below:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Service&lt;/cell&gt;
        &lt;cell&gt;pushservice&lt;/cell&gt;
        &lt;cell&gt;Main recommendation service at X used to surface recommendations to our users via notifications.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ranking&lt;/cell&gt;
        &lt;cell&gt;pushservice-light-ranker&lt;/cell&gt;
        &lt;cell&gt;Light Ranker model used by pushservice to rank posts. Bridges candidate generation and heavy ranking by pre-selecting highly-relevant candidates from the initial huge candidate pool.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;pushservice-heavy-ranker&lt;/cell&gt;
        &lt;cell&gt;Multi-task learning model to predict the probabilities that the target users will open and engage with the sent notifications.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file. We plan to add a more complete build and test system in the future.&lt;/p&gt;
    &lt;p&gt;We invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official bug bounty program through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better X.&lt;/p&gt;
    &lt;p&gt;Read our blog on the open source initiative here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/twitter/the-algorithm"/></entry><entry><id>https://news.ycombinator.com/item?id=45183050</id><title>Building a DOOM-like multiplayer shooter in pure SQL</title><updated>2025-09-09T18:12:54.668602+00:00</updated><content>&lt;doc fingerprint="676aacd12fee1bbf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DOOMQL: A DOOM-like multiplayer shooter in pure SQL&lt;/head&gt;
    &lt;p&gt;I recently stumbled across Patrick’s excellent DOOM clone running in a browser powered by DuckDB-WASM. Ever since I’ve read that, I wanted to push his awesome idea to the logical extreme: Build a multiplayer DOOM-like shooter entirely in SQL with CedarDB doing all the heavy lifting. During a month of parental leave (i.e., a lot of sleepless nights), I tried exactly that.&lt;/p&gt;
    &lt;p&gt;Here’s a sneak peek at DOOMQL:&lt;/p&gt;
    &lt;p&gt;Okay, with the flashy demo out of the way, let’s talk about details. What follows is a tour of the architecture, the SQL rendering pipeline, the game loop, and the fun metagame of cheating by issuing SQL commands against the database.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why even do this?&lt;/head&gt;
    &lt;head rend="h2"&gt;Architectural overview&lt;/head&gt;
    &lt;p&gt;At a high level&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;State lives in tables (map, players, mobs, inputs, configs, sprites, &amp;amp;mldr;)&lt;/item&gt;
      &lt;item&gt;Rendering is a stack of SQL views that implement raycasting and sprite projection&lt;/item&gt;
      &lt;item&gt;The game loop is a tiny shell script that executes a SQL file ~ 30 times per second.&lt;/item&gt;
      &lt;item&gt;The client is ~ 150 lines of Python: It polls for input and queries the database for your 3D view.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can play, observe other players and even cheat (by sending raw SQL).&lt;/p&gt;
    &lt;head rend="h2"&gt;Game state, or: Let’s store everything in the database&lt;/head&gt;
    &lt;p&gt;With a database at hand, it’s natural to store all game configuration, state, and static data in the database:&lt;/p&gt;
    &lt;p&gt;Config:&lt;/p&gt;
    &lt;code&gt;CREATE TABLE config(
  player_move_speed NUMERIC DEFAULT 0.3, 
  player_turn_speed NUMERIC DEFAULT 0.2,
  ammo_max INT DEFAULT 10,
  ammo_refill_interval_seconds INT DEFAULT 2
  );
&lt;/code&gt;
    &lt;p&gt;Map:&lt;/p&gt;
    &lt;code&gt;CREATE TABLE map(x INT, y INT, tile CHAR);
&lt;/code&gt;
    &lt;p&gt;Players and inputs:&lt;/p&gt;
    &lt;code&gt;CREATE TABLE players (
  id INT REFERENCES mobs(id),
  score INT DEFAULT 0,
  hp INT DEFAULT 100,
  ammo INT DEFAULT 10,
  last_ammo_refill int default EXTRACT(EPOCH FROM (now()))::INT
);

CREATE TABLE inputs(
  player_id INT PRIMARY KEY REFERENCES players(id),
  action CHAR(1), -- 'w', 'a', 's', 'd', 'x' for shooting
  timestamp TIMESTAMP DEFAULT NOW()
);
&lt;/code&gt;
    &lt;p&gt;Because everything is data, modding a running match is trivial:&lt;/p&gt;
    &lt;code&gt;-- Change a setting
update config set ammo_max = 20;

 -- Add a player
insert into players values (...);

-- Move forward
update input set action = 'w' where player_id = &amp;lt;your_id&amp;gt;;

 -- Cheat (pls be smarter about it)
update players set hp = 100000 where player_id = &amp;lt;your_id&amp;gt;;

-- Ban cheaters (that weren't smart about it)
delete from players where hp &amp;gt; 100;
&lt;/code&gt;
    &lt;head rend="h2"&gt;Renderer: When a &lt;code&gt;VIEW&lt;/code&gt; becomes your 3D view&lt;/head&gt;
    &lt;p&gt;If you squint enough, in DOOM, a 3D (or more correct: 2.5D) view is just a view over 2D state (i.e., the level map and any players/enemies on it). Well, we’ve got &lt;code&gt;VIEWS&lt;/code&gt; in SQL as well. They’re also just views on our (2D) state tables.
What’s stopping us from quite literally building a 3D “view” of our 2D map
using a simple raycasting algorithm?&lt;/p&gt;
    &lt;p&gt;The pipeline:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Send a set of rays from each player’s eye into the world, and see which map tiles are visible&lt;/item&gt;
      &lt;item&gt;Check which walls the player sees, rendering them at the correct height and more or less solid based on the distance&lt;/item&gt;
      &lt;item&gt;Project mobs into the player’s camera space&lt;/item&gt;
      &lt;item&gt;Select sprite LODs based on depth&lt;/item&gt;
      &lt;item&gt;Expand sprites into pixels, scaled to screen space&lt;/item&gt;
      &lt;item&gt;Occlude against walls and other sprites&lt;/item&gt;
      &lt;item&gt;Assemble frame buffer rows with &lt;code&gt;string_agg&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Build a minimap reusing the visible tiles calculation from earlier&lt;/item&gt;
      &lt;item&gt;Combine the 3D view with minimap and HUD (HP/bullets/players) into a game view&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s take a more in-depth look at steps 2, 7, and 8.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raycasting&lt;/head&gt;
    &lt;p&gt;The recursive rayâmarching logic is adapted from Patrick’s DuckDB DOOM post. Here is a simplified excerpt, adapted for multiplayer:&lt;/p&gt;
    &lt;code&gt;CREATE OR REPLACE VIEW visible_tiles AS  
WITH RECURSIVE raytrace AS (  
  -- Starting at the player's eye ...
  SELECT r.player_id, r.col, 1 AS step_count,  
         r.player_x + COS(r.angle)*s.step AS fx,  
         r.player_y + SIN(r.angle)*s.step AS fy,  
         r.angle, 0 AS dist  
  FROM rays r, settings s  -- rays are built in an earlier step
  UNION ALL  
  -- ... we recursively march along the rays, 1 "step" at a time ...
  SELECT rt.player_id, rt.col, rt.step_count + 1,  
         rt.fx + COS(rt.angle)*s.step,  
         rt.fy + SIN(rt.angle)*s.step,  
         rt.angle,  
         step_count * s.step * COS(rt.angle - m.dir) AS dist  
  FROM raytrace rt, settings s, players p, mobs m  
  WHERE rt.step_count &amp;lt; s.max_steps   -- ... stopping after our max render distance
    AND rt.player_id = p.id  
    AND m.id = p.id  
    AND NOT EXISTS (  -- or if we hit a wall
      SELECT 1 FROM map m  
      WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  
        AND m.tile = '#')  -- wall
)  
-- We then determine per player:
--  a) which tiles we hit
--  b) how far away these tiles are
--  c) the column of the screen each tile should correspond to
SELECT player_id, tile, CAST(fx AS INT) AS tile_x, CAST(fy AS INT) AS tile_y, col, MIN(dist) AS dist  
FROM raytrace rt, map m  
WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  -- We might hit the same tile multiple times, so we take the closest hit
GROUP BY player_id, tile_x, tile_y, tile, col;  
&lt;/code&gt;
    &lt;p&gt;And that’s just the first step in the pipeline. For the rest, take a look at the code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final frame assembly&lt;/head&gt;
    &lt;p&gt;After all the heavy lifting, the payoff is surprisingly simple:&lt;/p&gt;
    &lt;code&gt;SELECT player_id, y, string_agg(ch, '' ORDER BY x) AS row  
FROM framebuffer  
GROUP BY player_id, y;  
&lt;/code&gt;
    &lt;p&gt;This glues together character pixels into text rows.&lt;/p&gt;
    &lt;head rend="h3"&gt;HUD + minimap&lt;/head&gt;
    &lt;p&gt;The same trick builds the HUD and minimap. Here is the health bar:&lt;/p&gt;
    &lt;code&gt;'HP: [' ||
repeat('â', LEAST(20, ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
repeat(' ', GREATEST(0, 20 - ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
'] ' || GREATEST(0, p.hp)
&lt;/code&gt;
    &lt;p&gt;Add ammo dots with &lt;code&gt;repeat('â¢', p.ammo)&lt;/code&gt; and you’ve got a HUD entirely in SQL:&lt;/p&gt;
    &lt;code&gt; 1: Lukas      (L) score: 1   HP: [âââââââââ           ] 50    AMMO: â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢
 2: Foobar     (F) score: 0   HP: [ââââââââââââââââââââ] 100   AMMO: â¢â¢â¢â¢â¢â¢â¢â¢  
&lt;/code&gt;
    &lt;p&gt;We can also re-use our earlier &lt;code&gt;visible_tiles&lt;/code&gt; view to build a minimap with a view cone:&lt;/p&gt;
    &lt;code&gt;select * from minimap where player_id = 1 order by y;

 player_id | y  |                               row                                
-----------+----+------------------------------------------------------------------
         1 |  0 | ################################################################
         1 |  1 | ################################################################
         1 |  2 | ##.......      #####               #############################
         1 |  3 | ##.....F.      #####               #####                     ###
         1 |  4 | ##.......      #####               #####                     ###
         1 |  5 | ##  .....      #####               #####                     ###
         1 |  6 | ##   ...                                                     ###
         1 |  7 | ##    .L                                                     ###
         1 |  8 | ##             #####               #####                     ###
         1 |  9 | ##             #####               #####                     ###
         1 | 10 | ##             #############  ##########                     ###
         1 | 11 | ##########  ################  ##########                     ###
         1 | 12 | ##########  ################  ##########                     ###
         1 | 13 | ##########  ################  ######################  ##########
         1 | 14 | ####                 #######  ######################  ##########
         1 | 15 | ####                 #######  ######################  ##########
         1 | 16 | ####                 #####             #####                 ###
         1 | 17 | ####                 #####             #####                 ###
         1 | 18 | ####                 #####             #####                 ###
         1 | 19 | ####                 #####             #####                 ###
         1 | 20 | ####                 #####             #####                 ###
         1 | 21 | ####                                   #####                 ###
         1 | 22 | ####                                                         ###
         1 | 23 | ####                 #####                                   ###
         1 | 24 | ####                 #####             #####                 ###
         1 | 25 | ####                 #####             #####                 ###
         1 | 26 | ####                 #####             #####                 ###
         1 | 27 | ####                 #####             #####                 ###
         1 | 28 | ####                 #####             #####                 ###
         1 | 29 | ################################################################
         1 | 30 | ################################################################
         1 | 31 | ################################################################
&lt;/code&gt;
    &lt;head rend="h2"&gt;The surprisingly elegant game loop&lt;/head&gt;
    &lt;p&gt;The loop is just a shell script running raw SQL against the database:&lt;/p&gt;
    &lt;code&gt;# Game loop @ 30 ticks per second
while true; do
  psql -qtAX -U "$DB_USER" -d "$DB_NAME" -h "$DB_HOST" -p "$DB_PORT" -f gameloop.sql
  sleep 0.03
done
&lt;/code&gt;
    &lt;p&gt;Inside &lt;code&gt;gameloop.sql&lt;/code&gt;, actions like bullet movement, collisions, kills, and respawns run in a single transaction, which keeps state consistent even if something fails mid-tick.&lt;/p&gt;
    &lt;p&gt;Here’s the part processing interactions with bullets:&lt;/p&gt;
    &lt;code&gt;-- Process all bullets
BEGIN TRANSACTION;

-- Move bullets forward
UPDATE mobs 
SET x = x + cos(dir) * 0.5, y = y + sin(dir) * 0.5 
WHERE kind = 'bullet';

-- Delete bullets that are out of bounds
DELETE FROM mobs 
WHERE (x &amp;lt; 0 
OR x &amp;gt;= (select max(x) from map) 
OR y &amp;lt; 0 
OR y &amp;gt;= (select max(y) from map))
AND kind = 'bullet';

-- Delete bullets that hit walls
DELETE FROM mobs b 
WHERE EXISTS 
    (SELECT 1 
    FROM map m 
    WHERE m.x = CAST(b.x AS INT) 
    AND m.y = CAST(b.y AS INT) 
    AND m.tile = '#') 
AND kind = 'bullet';


-- Players hit by a bullet loses 50 HP
UPDATE players p SET hp = hp - 50
FROM collisions c
WHERE p.id = c.player_id;

-- If a player has 0 or less HP, the player killing them gets a point
UPDATE players p SET score = score + 1
FROM collisions c
WHERE p.id = c.bullet_owner
AND EXISTS (SELECT 1 FROM players p2 WHERE p2.id = c.player_id AND p2.hp &amp;lt;= 0);

-- Delete bullets that hit players
DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id;

-- Respawn players whose HP is 0 or less
UPDATE mobs m
SET x = r.x, y = r.y, dir = 0
FROM players p
CROSS JOIN (
  SELECT x, y
  FROM map
  WHERE tile = 'R'
  ORDER BY random()
  LIMIT 1
) AS r
WHERE m.id = p.id
  AND p.hp &amp;lt;= 0;

-- Reset players' HP to 100 and ammo to 10 after respawn
UPDATE players p SET
  hp = 100,
  ammo = 10
FROM mobs m
WHERE p.id = m.id
AND p.hp &amp;lt;= 0;

COMMIT;
&lt;/code&gt;
    &lt;p&gt;On my machine, the game loop takes about 1 ms, so we could defintely improve the tick rate. That might be a way to get the Counterstrike snobs who scoff at everything below 128 Hz. It would require some refactoring on my part since I tied the movement speed to the game loop - a big no no in game design!&lt;/p&gt;
    &lt;p&gt;While only someone insane could think a pure SQL raycasting renderer is a good idea in an actual game, I’ll happily defend this transactional game loop. I don’t think this part would be much more concise or less brittle in a real game engine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Make it multiplayer in two queries&lt;/head&gt;
    &lt;p&gt;The game client’s job description is simple:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Render&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;SELECT full_row FROM screen WHERE player_id = &amp;lt;your_id&amp;gt; ORDER BY y
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Send input&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;INSERT INTO inputs(player_id, action)
    VALUES (&amp;lt;your_id&amp;gt;, &amp;lt;pressed_key&amp;gt;)
    ON CONFLICT(player_id)
    DO UPDATE SET action = EXCLUDED.action
&lt;/code&gt;
    &lt;p&gt;The game loop periodically checks the input table and moves all players accordingly - inside a transaction, of course, so we don’t run into any race conditions.&lt;/p&gt;
    &lt;p&gt;That’s it (well, plus a one-time “create player” on first connect). The ~150 lines of Python in the client mostly handle keyboard input and reducing terminal flicker. Bonus: The client provides an observer mode. All it has to do is swap the &lt;code&gt;&amp;lt;player_id&amp;gt;&lt;/code&gt; in the render call.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;At 128 x 64 pixels, a single player view takes ~33 ms on my machine, which is enough for a breezy ~30 FPS, compared to DuckDB DOOM’s 8 FPS at just 32 x 16 pixels. I’m actually quite proud of that performance and quite happy with CedarDB here. I don’t think any other database system can keep up with that. Let me know if you find one!&lt;/p&gt;
    &lt;p&gt;You might worry that rendering the views of all players and filtering late would be very wasteful. CedarDB’s query optimizer pushes the &lt;code&gt;where player_id = &amp;lt;...&amp;gt;&lt;/code&gt; predicate through view boundaries, avoiding unncessary work.
You can easily check by running:&lt;/p&gt;
    &lt;code&gt;select * from screen order by y; -- render both users
-- Time: 57,907 ms (~2x single player 33ms)
&lt;/code&gt;
    &lt;head rend="h2"&gt;The cheating metagame&lt;/head&gt;
    &lt;p&gt;Because clients send raw SQL as superusers (I didn’t bother setting up any role based access control or row level security, don’t do that!), there’s an emergent metagame: Cheat creatively and try not to get caught.&lt;/p&gt;
    &lt;p&gt;Low effort:&lt;/p&gt;
    &lt;code&gt;update players set score = 0 where id != &amp;lt;your_id&amp;gt;;
update players set hp = 0 where id != &amp;lt;your_id&amp;gt;;
&lt;/code&gt;
    &lt;p&gt;Mischievous:&lt;/p&gt;
    &lt;code&gt;update inputs set action = null where player_id != &amp;lt;your_id&amp;gt;;
&lt;/code&gt;
    &lt;p&gt;Steal kills:&lt;/p&gt;
    &lt;code&gt;update mobs set owner = &amp;lt;your_id&amp;gt; where kind = 'bullet';
&lt;/code&gt;
    &lt;p&gt;Attempted but didn’t work:&lt;/p&gt;
    &lt;code&gt;DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id AND c.player_id = &amp;lt;your_id&amp;gt;;
&lt;/code&gt;
    &lt;p&gt;This doesn’t work because moving bullets, checking for collisions, and respawn happens in the same transaction. As transactions are atomic, you either see everything being applied at once, or nothing. By the time you see the hit, you’re already dead. A property that’s very useful for database systems (and not just to prevent cheating).&lt;/p&gt;
    &lt;head rend="h2"&gt;What I learned&lt;/head&gt;
    &lt;p&gt;I set out to see if I could push Patrick’s demo to an extreme: Doing the entire rendering pipeline in SQL. And while it works, I have to admit that it is a pretty&amp;amp;mldr; bad idea? Fast enough, but horrible to maintain and debug.&lt;/p&gt;
    &lt;p&gt;The surprise was how natural it felt to express game state and logic in SQL. It even felt like accidentally re-invented the entity-component-system pattern.&lt;lb/&gt;And multiplayer “just worked” because the database system which handles all the nasty concurrency is the source of truth.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try it yourself!&lt;/head&gt;
    &lt;p&gt;All the code is on Github: DOOMQL Repo&lt;/p&gt;
    &lt;p&gt;Run:&lt;/p&gt;
    &lt;code&gt;docker pull cedardb/cedardb:latest
docker run --rm -p 5432:5432 -e CEDAR_PASSWORD=postgres --detach cedardb/cedardb:latest
# Wait a few seconds for CedarDB to start
./server.sh

# in a second terminal window, zoom way out to have no line wraping issues
python3 pyclient.py
&lt;/code&gt;
    &lt;p&gt;Want to discuss DOOMQL with me or find like-minded database nerds? Join our Community Slack&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cedardb.com/blog/doomql/"/></entry><entry><id>https://news.ycombinator.com/item?id=45183589</id><title>An attacker’s blunder gave us a look into their operations</title><updated>2025-09-09T18:12:53.992055+00:00</updated><content>&lt;doc fingerprint="3c2636d18b2880a9"&gt;
  &lt;main&gt;
    &lt;p&gt;Here at Huntress, we love exposing adversary tradecraft, and we also love when threat actors make blunders. So imagine our delight when a threat actor installed Huntress onto their operating machine—after finding us via one of our advertising campaigns and starting a trial— giving us a sprawling inside look at how they’re using AI to build workflows, searching for tools like Evilginx, and more.&lt;/p&gt;
    &lt;p&gt;------------------------&lt;/p&gt;
    &lt;p&gt;We all know that security products are often downloaded by attackers for “evaluation,” but often we can only guess as to how they decided to target a particular technology, or the actions taken while trying out such software. We recently had the pleasure of getting a front seat view into what one attacker did, simply because they installed our agent and let us collect information directly from them. Here, we will cover this strange tale.&lt;/p&gt;
    &lt;p&gt;Like most good stories, this one starts in the middle and works its way back and forth. Let’s start with how this person of interest got our attention. One of the tricks of the trade to get people interested in your products is through advertising. As such, we run ads to help lead potential customers to our products. An adverse effect here might be garnering some “unwanted” attention as well. Such is the setting for the beginning of this adventure: it all started with a nicely placed Google ad.&lt;/p&gt;
    &lt;p&gt;The attacker tripped across our ad while researching another security solution. We confirmed this is how they found us by examining their Google Chrome browser history. An example of how this may have appeared to them in the moment may be seen in Figure 1.&lt;/p&gt;
    &lt;p&gt;It appears that the attacker became interested in Huntress while simultaneously trying out Bitdefender. After hitting our comparison page, they could hardly contain themselves and started a trial immediately. We are able to follow their journey through their Chrome history, as seen in Figure 2 below.&lt;/p&gt;
    &lt;p&gt;It’s no secret that threat actors may install security products for research purposes or even for legitimate use—and in fact, the adversary was interested in other security products in addition to Bitdefender and Huntress. We found evidence that they had bought a Malwarebytes subscription (including the Malwarebytes browser guard extension).&lt;/p&gt;
    &lt;p&gt;We knew this was an adversary, rather than a legitimate user, based on several telling clues. The standout red flag was that the unique machine name used by the individual was the same as one that we had tracked in several incidents prior to them installing the agent. Further investigation revealed other clues, such as the threat actor’s browser history, which appeared to show them trying to actively target organizations, craft phishing messages, find and access running instances of Evilginx, and more. We also have our suspicions that the operating machine where Huntress was installed is being used as a jump box by multiple threat actors—but we don’t have solid evidence to draw firm conclusions at this time.&lt;/p&gt;
    &lt;p&gt;Huntress analysts went to work evaluating the outstanding indicators of compromise found on the adversary’s host and how they related to data found within authentications to identities at Huntress. Retroactive hunts disclosed a further 20 identities which were compromised; many of which had been accessed by the adversary prior to Huntress’ deployment against the identity, whose activity was limited to refreshing session tokens to maintain access.&lt;/p&gt;
    &lt;p&gt;Overall, analysis of the adversary’s primary operating infrastructure, hosted on Autonomous System (AS) “12651980 CANADA INC.” (now known as VIRTUO) disclosed a pattern of access of over 2471 unique identities spanning the last two weeks– many of which were preemptively caught by additional detection capabilities such as malicious mail rule creation, or session token theft.&lt;/p&gt;
    &lt;p&gt;The intelligence gathered by the above has resulted in detections of high confidence against the adversary’s infrastructure; and equipped our systems and analysts to respond to these incidents in significantly less time and with extreme confidence in malice, eliminating adversarial attempts to evade our detections.&lt;/p&gt;
    &lt;p&gt;All in all, we were able to see the threat actor’s specific day-to-day activities—from their methodologies to the specific types of organizations (and even individuals) they were interested in. We also saw them begin to tinker with tools and search for tutorials, attempting to learn more. For instance, after installing the Huntress agent, the threat actor took steps to better understand Autoruns.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Figure 4: The threat actor attempting to better understand Autoruns&lt;/p&gt;
    &lt;p&gt;Overall, over the course of three months we saw an evolution in terms of how the threat actor refined their processes, incorporated AI into their workflows, and targeted different organizations and vertical markets, as outlined in Figure 5 below.&lt;/p&gt;
    &lt;p&gt;Figure 5: An overview of some of the threat actor’s activities that we saw over the months&lt;/p&gt;
    &lt;p&gt;Below are some of the specific methodologies that we saw.&lt;/p&gt;
    &lt;p&gt;The Chrome browser history gave a first-hand look at how the adversary is using AI tools to increase the operational efficiency of their workflows. While there have previously been many reports on how cybercriminals are using AI (based on indicators in phishing messages or landing page content), this is the first time that we have a close-up view of a threat actor embedding AI into their operations in order to automate—and speed up—their workflow.&lt;/p&gt;
    &lt;p&gt;On May 25, the threat actor signed up for Make.com, which is legitimate workflow automation software, before researching the platform’s Telegram Bot integration feature as a way to launch automated processes (as seen in Figure 6 below). The threat actor then poked around several FAQ sites to better understand how Telegram Bot APIs work and how to set up webhooks.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;Over time, the threat actor started to get a better grasp of how they could use Make.com for specific workflows, and their browser history shows them starting to rely more heavily on the platform. By the time June 29 rolled around, the threat actor had fully developed their workflow with Make. As seen in Figure 8, the threat actor would first identify the organization of interest (typically after receiving a “tip” from Telegram) before using Google Translate to translate or craft messages related to these organizations. While we don’t have detailed insight into how the threat actor was using Make for these specific workflows, we can see that it was part of the process to automate specific functions.&lt;/p&gt;
    &lt;p&gt;Figure 8: Threat actor starts to rely on automated workflows&lt;/p&gt;
    &lt;p&gt;The threat actor also appeared to be interested in other AI tools to help with data generation and writing. We saw multiple Google searches for “free ai no signup” and for “csv generator ai.” We also saw the threat actor using Toolbaz AI, which is a writing assistant; the CSV spreadsheet generator feature of DocsBot AI, which is an AI chatbot tool; and the AI data generator feature of Explo AI, which is an embedded analytics tool.&lt;/p&gt;
    &lt;p&gt;We saw evidence of the threat actor searching for running instances of the Evilginx man-in-the-middle attack framework using Censys, and then attempting to access those instances.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;In addition to Evilginx, we also found evidence of multiple installed tools on the threat actor’s system—or, in some cases, an interest in tools based on the threat actor browser history. These tools included recon and attack tool GraphSpy, open source tool Bloodhound, the TeamFiltration framework used for enumeration and exfiltration, and more.&lt;/p&gt;
    &lt;p&gt;The Chrome browser history also revealed visits by the threat actor to multiple residential proxy webpages, including LunaProxy and Nstbrowser (which bills itself as an anti-detect browser and supports the use of residential proxies). The threat actor visited the pricing plan page for LunaProxy, researched specific products, and looked up quick start guides throughout May, June, and July. Residential proxy services have become increasingly popular with threat actors as a way to route their traffic through residential IP addresses, allowing them to obscure malicious activity, like avoiding suspicious login alerts while using compromised credentials.&lt;/p&gt;
    &lt;p&gt;The Chrome browser history entries also gave us a close view of the attacker’s reconnaissance methods. The threat actor spent a lot of time researching companies across different sectors, from specific banks to “top real estate companies in the US” (also looking up “real estate agents in California”).&lt;/p&gt;
    &lt;p&gt;The threat actor didn’t just search for individual companies—they also looked at all parts of the ecosystem surrounding organizations of interest, from their customer bases to associated third-party companies across the supply chain. For example, the threat actor appeared to start targeting software companies in early July, searching for these types of companies via Google Search and using database marketing tools like ReadyContacts and InfoClutch to scope out how many customers they had and their market share.&lt;/p&gt;
    &lt;p&gt;The threat actor also used the BuiltWith platform, which lets users identify and analyze the technology stacks used by websites. On July 8, browser entries show the attacker conducting an extensive level of research on a prominent ecommerce vendor for managing payments and subscriptions, including a list of its customers, contacts, and market share. The threat actor then used BuiltWith to search for the websites relying on that vendor, before navigating to the BuiltWith sign up page, presumably to access that list.&lt;/p&gt;
    &lt;p&gt;The threat actor conducted a fair amount of research into tools used to scrape Telegram group data, including looking at scraper tools like Apify, the Axiom Chrome extension, and the RapidAPI platform (Figure 13).&lt;/p&gt;
    &lt;p&gt;The threat actor used Google Translate extensively, and Chrome browser shows them first visiting bank websites, and then using the translation platform, likely to assist in crafting phishing-related messages, as seen in Figure 14.&lt;/p&gt;
    &lt;p&gt;The attacker often used urlscan to get information about various websites. Tips appear to have come in via Telegram using the getUpdates method.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p&gt;There were several entries in the browser history that showed use of Google Translate to translate messages from Portuguese to English alongside browsing banks in Brazil, then evidence of crafting messages later on in their history.&lt;/p&gt;
    &lt;p&gt;We also saw the threat actor express interest in STYX Market, a dark web forum that’s been around since 2023, and was recently called a “rising star for stealer logs, stolen creds, and laundering services” by researchers. After doing some initial research on STYX—as well as other Telegram chat groups and channels—they decided to check out the site for themselves, registering for an account before perusing the catalog of VoIP accounts, stealer logs, SIM cards, and more.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;Rarely do you ever get the chance to actually shoulder surf a real threat actor. We had such an opportunity when they installed our agent. It starts out mundane enough. We don’t know what they must have dreamed about after ending their shift at 2am UTC the previous night, but as mentioned earlier, you can see them start a trial, download the agent, and install it.&lt;/p&gt;
    &lt;p&gt;The most interesting activity for the start of their day on July 9, 2025 was browsing to urlscan.io to inspect login.incipientcroop[.]com. Shortly after, they logged into Make.com and began working on a project called Voltage_Office356bot (notice the typo).&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p&gt;There is evidence that the threat actor had access to cookie data for two different individuals, and accessed them via Notepad++. They proceeded to open the first file:&lt;/p&gt;
    &lt;p&gt;C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram &lt;lb/&gt;Desktop\Cookies_[victim1]@[redacted1][.].com.json&lt;/p&gt;
    &lt;p&gt;Then they started looking around to see what they can find, with a Google search for “email osint”.&lt;/p&gt;
    &lt;p&gt;Next, they opened the second cookie file:&lt;/p&gt;
    &lt;p&gt;C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram &lt;lb/&gt;Desktop\Cookies_[victim2]@[redacted2][.].com.json&lt;/p&gt;
    &lt;p&gt;They then started up Nstbrowser.exe and LunaProxy:&lt;/p&gt;
    &lt;p&gt;C:\Program Files\Nstbrowser\Nstbrowser.exe&lt;lb/&gt;C:\Program Files (x86)\LunaProxy_cata\socks5\LunaProxyDivert.exe SOCK5 [snip]&lt;/p&gt;
    &lt;p&gt;They browsed to an article titled Say Hello to your new cache flow by Synacktiv covering WHFB and Entra ID, followed by a Google search for “whfb prt”, which landed them on the website of a well-known researcher, Dirk-Jan Mollema.&lt;/p&gt;
    &lt;p&gt;They checked their IP address after this:&lt;/p&gt;
    &lt;p&gt;C:\Windows\system32\curl.exe ipinfo[.]io&lt;/p&gt;
    &lt;p&gt;And then checked their IP address again:&lt;/p&gt;
    &lt;p&gt;C:\Windows\system32\curl.exe ipinfo[.]io&lt;/p&gt;
    &lt;p&gt;They then tried to use a tool called ROADtools Token eXchange (roadtx):&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe prtauth -r msgraph -c msteams&lt;/p&gt;
    &lt;p&gt;And then erroneously tried to run the same tool (as an executable) via Python:&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe prtauth -r msgraph -c msteams&lt;/p&gt;
    &lt;p&gt;Then ran it again:&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe describe&lt;/p&gt;
    &lt;p&gt;And then tried to run it again, erroneously, using Python:&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe describe&lt;/p&gt;
    &lt;p&gt;They seemed to be having trouble. At this point they browsed to Dirk-jan Mollema’s post on Phishing for Microsoft Entra primary refresh tokens.&lt;/p&gt;
    &lt;p&gt;While there, they gained some new inspiration, and discovered a handy little script that could make their life easier:&lt;/p&gt;
    &lt;p&gt;At this point they went back to their Voltage_Office356bot project before running this new script they’ve downloaded.&lt;/p&gt;
    &lt;p&gt;They started trying to run the Python script:&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py -f roadtx.prt --wfb&lt;/p&gt;
    &lt;p&gt;They checked the usage again:&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py --wfb&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py -h&lt;/p&gt;
    &lt;p&gt;Then, they started to run it against the original victim whose cookie file we saw earlier:&lt;/p&gt;
    &lt;p&gt;C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py --wfb -u [victim2]@[redacted2][.]com&lt;/p&gt;
    &lt;p&gt;They returned to the first victim’s cookie file:&lt;lb/&gt;C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram &lt;lb/&gt;Desktop\Cookies_[victim1]@[redacted1][.].com.json&lt;/p&gt;
    &lt;p&gt;This is where our EDR data drops off, as they may have become aware of us and uninstalled the agent.&lt;/p&gt;
    &lt;p&gt;The attacker’s browser history gives us an unprecedented level of insight into their everyday activity, searches, workflows, research, and more. The browser history shows the threat actor working intensively almost every day between the period of May 29, 2025 through July 9, 2025.&lt;/p&gt;
    &lt;p&gt;On many of these days, the browser entries were seen across most hours of the day, logging 12 to 14 hours. But there was some variation, as seen in Figure 29, above: on several days, the threat actor worked as little as one to two hours.&lt;/p&gt;
    &lt;p&gt;When we hone in on a few of the days when the most hours were put in, we can see some of the things that piqued the attacker’s interest in those days. We analyzed the urls to see what businesses, or categories they might have fallen into, and then looked to see how many times the attacker visited these sites.&lt;/p&gt;
    &lt;p&gt;We can see a few trends. During these days, the attacker spent a lot of time researching various banking entities and bank personnel. To further expand on some of the graph labels:&lt;/p&gt;
    &lt;p&gt;Attack infra: Malicious websites or servers set up by an attacker (maybe not this one) hosting frameworks like Evilginx and other known tools.&lt;/p&gt;
    &lt;p&gt;Banking: Various banking websites&lt;/p&gt;
    &lt;p&gt;Browser extension: Various browser extensions like ad blockers, etc. installed by the attacker to protect themselves.&lt;/p&gt;
    &lt;p&gt;Corporate &amp;amp; Business: Various business websites not housed under a different category.&lt;/p&gt;
    &lt;p&gt;Crypto: Various cryptocurrency and blockchain websites.&lt;/p&gt;
    &lt;p&gt;Cybersecurity: Various cybersecurity vendor websites. The attacker often signed up for trials at various vendors to test things.&lt;/p&gt;
    &lt;p&gt;Government &amp;amp; military: Various official government or military websites.&lt;/p&gt;
    &lt;p&gt;News, media &amp;amp; information: Various news websites like CNN etc. The attacker often read articles related to various breaches.&lt;/p&gt;
    &lt;p&gt;OSS: Open source projects, often housed at github or gitlab.&lt;/p&gt;
    &lt;p&gt;Recon: Activities where the attacker was using Censys, Urlscan, Google, etc., to do reconnaissance for a particular target.&lt;/p&gt;
    &lt;p&gt;Research: When the attacker was researching a particular vulnerability, tool, or attack.&lt;/p&gt;
    &lt;p&gt;Sandbox: The attacker often seemed interested in various types of malware that were on VirusTotal, Joe’s Sandbox, and other online sandboxes.&lt;/p&gt;
    &lt;p&gt;Social media: Various telegram, X, and other social media posts read by the attacker.&lt;/p&gt;
    &lt;p&gt;Software: Various legitimate software, like 7zip.&lt;/p&gt;
    &lt;p&gt;Telecommunications: A telecommunication website, like Verizon.&lt;/p&gt;
    &lt;p&gt;Web &amp;amp; IT infrastructure: Various online hosting services, like Mega, Amazon AWS, and Azure.&lt;/p&gt;
    &lt;p&gt;We can see that from May 29 to June 1, 2025, the attacker was mostly looking at various banking websites. Digging further into their activities, you see them researching various banks, reading about Telegram Bots, then downloading a blueprint from Make.&lt;/p&gt;
    &lt;p&gt;The next day, it seems that the attacker spent a little more time researching various attack infrastructure, in addition to focusing on banks, and similar activities seen previously.&lt;/p&gt;
    &lt;p&gt;On May 31, 2025 and June 1, 2025, the attacker switched their focus back to mostly researching banking websites.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p&gt;The other interesting thing was that the attacker was mostly focused on banks and sites that were in Nigeria during this time period, even looking for things like:&lt;lb/&gt;“No. 1 regulated crypto exchange in Nigeria.”&lt;/p&gt;
    &lt;p&gt;“top crypto companies nigeria”&lt;/p&gt;
    &lt;p&gt;“Best Crypto Exchanges in Nigeria”&lt;lb/&gt;“Top Cryptocurrency Companies in Nigeria”&lt;/p&gt;
    &lt;p&gt;While we don’t know where the attacker is based, the machine they had installed our agent upon appeared to be based in the United States, on the West Coast, based on the machine’s internal time zone and IP address.&lt;/p&gt;
    &lt;p&gt;It seems that the attacker had spent quite some time looking at our various capabilities after they had started a trial with us. Figure 36 above shows just how much more time they spent interacting with the Huntress website, and particularly the account dashboard once they had started the trial.&lt;/p&gt;
    &lt;p&gt;This incident gave us in-depth information about the day-to-day activities of a threat actor, from the tools they were interested in to the ways they conducted research and approached different aspects of attacks.&lt;/p&gt;
    &lt;p&gt;Upon confirming that the machine name was one used by an adversary, we decided to release these details because they give an invaluable understanding into the mindset and behaviors of threat actors behind attacks. For other defenders, we hope that this information can help add context around the ways that threat actors conduct research and launch attacks at the backend—and the different types of organizations, tools, and platforms that interest them.&lt;/p&gt;
    &lt;p&gt;Get insider access to Huntress tradecraft, killer events, and the freshest blog updates.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.huntress.com/blog/rare-look-inside-attacker-operation"/></entry><entry><id>https://news.ycombinator.com/item?id=45184315</id><title>U.S. Added 911,000 Fewer Jobs in the Year Ended in March</title><updated>2025-09-09T18:12:53.798349+00:00</updated><content/><link href="https://www.wsj.com/economy/jobs/us-job-growth-revision-a9777d98"/></entry><entry><id>https://news.ycombinator.com/item?id=45184368</id><title>ICE Is Using Fake Cell Towers to Spy on People's Phones</title><updated>2025-09-09T18:12:53.564995+00:00</updated><content>&lt;doc fingerprint="771290960fa11bec"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the online edition of The Wiretap newsletter, your weekly digest of cybersecurity, internet privacy and surveillance news. To get it in your inbox, subscribe here.&lt;/p&gt;
    &lt;p&gt;It’s been some time since Immigration and Customs Enforcement (ICE) has been seen using a tool known as a Stingray, or a cell-site simulator, in its attempts to find and remove undocumented immigrants. The tool tricks a phone into thinking it’s a cell tower, and when a suspect’s device connects, the cops can trace its location. Its use is controversial because anyone in the same area as the target is at risk of having their information exposed.&lt;/p&gt;
    &lt;p&gt;In a recently-unsealed search warrant reviewed by Forbes, ICE used such a cell-site simulator in an attempt to track down an individual in Orem, Utah. The suspect had been ordered to leave the U.S. in 2023, but is believed to still be in the country. Investigators learned last month that before going to Utah, he’d escaped prison in Venezuela where he was serving a sentence for murder, according to the warrant. He’s also suspected of being linked to gang activity in the country, investigators said.&lt;/p&gt;
    &lt;p&gt;When the government got the target’s number, they first got a warrant to get its location. However, the trace wasn’t precise–it only told law enforcement that the target was somewhere in an area covering about 30 blocks. That led them to asking a court for a Stingray-type device to get an accurate location.&lt;/p&gt;
    &lt;p&gt;The warrant was issued at the end of last month and it’s not yet known if the fugitive was found.&lt;/p&gt;
    &lt;p&gt;But the case shows that, despite having been criticized by civil rights groups for using Stingrays during the last Trump administration, ICE continues to use the technology. Earlier this year, new media publication Straight Arrow News said it had analysed “mobile network anomalies” around a Washington state protest against ICE raids that were consistent with Stingray use.&lt;/p&gt;
    &lt;p&gt;Forbes found contract records showing ICE purchased nearly $1 million worth of “cell site simulator vehicles” in May this year, indicating it’s taking the surveillance tool fully mobile. That was part of a contract first signed under the Biden administration in 2024.&lt;/p&gt;
    &lt;p&gt;ICE also has an active contract worth up to $4.4 million with the original Stingray manufacturer, Harris Corporation, for unspecified “equipment to determine the location of targeted mobile handsets.” That deal was also signed during the Biden years.&lt;/p&gt;
    &lt;p&gt;Got a tip on surveillance or cybercrime? Get me on Signal at +1 929-512-7964.&lt;/p&gt;
    &lt;head rend="h2"&gt;THE BIG STORY:&lt;/head&gt;
    &lt;head rend="h2"&gt;This Billionaire’s AI Was Supposed To Speed Up Policing. It’s Not Going Well.&lt;/head&gt;
    &lt;p&gt;San Mateo County Sheriff’s Office spent $12 million on a sprawling AI surveillance system called Sherlock, designed to stitch together surveillance streams across as many as 16 different agencies in the jurisdiction.&lt;/p&gt;
    &lt;p&gt;Made by billionaire Tom Siebel’s C3 AI, it was supposed to drastically speed up police work, but three years into the project, cops tell Forbes they’re yet to see the benefits.&lt;/p&gt;
    &lt;p&gt;Per one staffer in 2023, “We’ve been working with them for two years and they have a barely functional product.” Since then, it’s unclear just how much the tech has progressed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stories You Have To Read Today&lt;/head&gt;
    &lt;p&gt;In a Forbes profile, Flock Safety shows off its drones, car tracking and AI-powered surveillance tools, all part of an effort to dislodge police tech giant Axon from the top of the market. “I plan to go take them out,” says CEO Garrett Langley.&lt;/p&gt;
    &lt;p&gt;ICE signed a contract with facial recognition company Clearview AI last week, worth nearly $10 million. It’ll be used, in part, to identify people assaulting ICE officers.&lt;/p&gt;
    &lt;p&gt;Former WhatsApp security lead Attaullah Baig has filed a lawsuit alleging Meta ignored big privacy and security problems within the messaging app. He claims thousands of Meta employees were able to view WhatsApp users’ profile pictures, location, group memberships and contact lists. Meta rejected the claims saying Baig was dismissed for poor performance and that his allegations were “distorted.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Winner of the Week&lt;/head&gt;
    &lt;p&gt;Signal has launched encrypted backups for user chats. The feature will first be made available for Android phones, before being slowly rolled out to iPhone users. The archive requires a 64-character recovery key to access, but keep that code safe: Signal warns that if it’s lost, there’s no way to get it back.&lt;/p&gt;
    &lt;head rend="h2"&gt;Loser of the Week&lt;/head&gt;
    &lt;p&gt;Amnesty International claims that Pakistan is running one of the world’s most expansive domestic surveillance operations outside of China, using both Chinese and Western technology providers, who are enabling both mass snooping via the nation’s telecoms companies as well as widespread internet censorship.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.forbes.com/sites/the-wiretap/2025/09/09/how-ice-is-using-fake-cell-towers-to-spy-on-peoples-phones/"/></entry><entry><id>https://news.ycombinator.com/item?id=45184432</id><title>Microsoft is officially sending employees back to the office</title><updated>2025-09-09T18:12:53.386711+00:00</updated><content>&lt;doc fingerprint="7f52997f7696eb5c"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsoft is sending employees back to the office at least three days a week.&lt;/item&gt;
      &lt;item&gt;The first phase will be for employees who live near its Seattle-area headquarters in February.&lt;/item&gt;
      &lt;item&gt;Business Insider reported last month that Microsoft's was considering a stricter RTO policy.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One of Big Tech's last remaining RTO holdouts is officially sending employees back to the office.&lt;/p&gt;
    &lt;p&gt;Microsoft is mandating employees work from offices at least three days a week, according to an internal email the company sent to staff on Tuesday.&lt;/p&gt;
    &lt;p&gt;The mandate will happen in three phases, beginning at the end of February 2026, with Seattle-area employees who live within 50 miles of a Microsoft office. It will then expand to other US offices and eventually internationally, according to the email from Microsoft HR chief Amy Coleman. February 23 was one of the start dates Microsoft considered, but it hasn't been decided yet.&lt;/p&gt;
    &lt;p&gt;Employees can request an exception by September 19. Coleman's email didn't include details about how such exceptions may work.&lt;/p&gt;
    &lt;p&gt;Business Insider reported in August that Microsoft was considering a stricter RTO policy mandating three days a week in the office.&lt;/p&gt;
    &lt;p&gt;Microsoft sells software that enables remote work, such as its popular Teams workplace chat and meeting app. It remained relatively lax compared to some other Big Tech companies when it comes to RTO, especially cross-town rival Amazon. Even Zoom sent its employees back to the office part-time in 2023.&lt;/p&gt;
    &lt;p&gt;Microsoft first introduced a flexible work policy when it brought employees back to the office in late 2020 after pandemic-forced closures. That policy officially allowed employees to work from home at least half of the time without approval, but in practice it was even more flexible and most employees worked remotely most of the time.&lt;/p&gt;
    &lt;p&gt;Now its policy is evolving to be similar to guidelines at Meta and Google, which generally require most employees to work in offices three days a week.&lt;/p&gt;
    &lt;p&gt;Microsoft's new approach is the latest sign of the company increasing performance pressure on employees. It has fired thousands of employees deemed low performers this year and introduced a new performance improvement plan meant to exit low performers more quickly.&lt;/p&gt;
    &lt;p&gt;While working on the new RTO policy, Microsoft appears to have scrubbed a blog post that once heralded the benefits of remote work for retaining employees and boosting their productivity.&lt;/p&gt;
    &lt;p&gt;"Hybrid work is more than a change in technology—it's a change in mindset, a change in culture, and a change in the way you think about physical and virtual spaces to enable an inclusive and productive environment for all," Microsoft wrote, according to a snapshot of the blog retained by the Internet Archive. "The change isn't easy, but it's worth it. If you make the time to do it right, your employees will be more engaged, more productive, and more connected, even when they're miles away. And they'll be far less likely to leave for a competitor who has a more sophisticated and flexible model than you do."&lt;/p&gt;
    &lt;p&gt;The link to that blog post now redirects to one published on July 31 calling out how "hybrid work created new challenges for employee engagement" and how AI can solve them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Read the full memo:&lt;/head&gt;
    &lt;p&gt;"How we work has forever changed. I remember starting at Microsoft in the late '90s, always in the office, no laptops, and primarily working with the people right down the hall. As technology evolved and our business expanded, we became more open, more global, and able to scale in ways we couldn't have imagined. Then the pandemic reshaped everything. It pushed us to think differently about work, to connect like never before (thank you Teams!), reminded us of how much we value being together, and gave us focus and autonomy in the traditional workday. We're not going back, and we shouldn't. Instead, we should take the best of what we've learned and move forward.&lt;/p&gt;
    &lt;p&gt;In the AI era, we are moving faster than ever, building world class technology that changes how people live and work, and how organizations everywhere operate. If you reflect on our history, the most meaningful breakthroughs happen when we build on each other's ideas together, in real time.&lt;/p&gt;
    &lt;p&gt;We've looked at how our teams work best, and the data is clear: when people work together in person more often, they thrive—they are more energized, empowered, and they deliver stronger results. As we build the AI products that will define this era, we need the kind of energy and momentum that comes from smart people working side by side, solving challenging problems together.&lt;/p&gt;
    &lt;p&gt;With that in mind, we're updating our flexible work expectations to three days a week in the office.&lt;/p&gt;
    &lt;p&gt;We'll roll this out in three phases: 1) starting in Puget Sound at the end of February; 2) expanding to other US locations; 3) and then launching outside the US.&lt;/p&gt;
    &lt;p&gt;Our goal with this change is to provide more clarity and consistency in how we come together, while maintaining the flexibility we know you value. We want you to continue to shape your schedule in ways that work best for you, making in-person time intentional and impactful. Importantly, this update is not about reducing headcount. It's about working together in a way that enables us to meet our customers' needs.&lt;/p&gt;
    &lt;p&gt;For some of you, this is not a change. For others this may be a bigger adjustment, which is exactly why we're providing time to plan thoughtfully. As part of these updates, we're also enhancing our workplace safety and security measures so we can continue to provide a workplace where every employee can do their best work.&lt;/p&gt;
    &lt;p&gt;What you need to know:&lt;/p&gt;
    &lt;p&gt;Puget Sound-area employees: If you live within 50 miles of a Microsoft office, you'll be expected to work onsite three days a week by the end of February. You'll receive a personalized email today with more details. Please connect with your manager and team to understand your organization's plans. If needed, you can request an exception by Friday, September 19.&lt;/p&gt;
    &lt;p&gt;Managers: You'll find actions to take, and the resources to support both you and your team on the Managers@Microsoft SharePoint.&lt;/p&gt;
    &lt;p&gt;All employees: You'll hear from your EVP or organizational leadership today with specific guidance. Each business will do what is best for their team, which means some groups will deviate from our company-wide expectations. If you are outside of the Puget Sound area, you do not need to take any action at this time unless your EVP communicates otherwise.&lt;/p&gt;
    &lt;p&gt;Timelines and details for additional US office locations will be announced soon. For employees outside the United States, we will begin planning in 2026. More information is available on the Flexible Work at Microsoft SharePoint.&lt;/p&gt;
    &lt;p&gt;As always, we'll keep learning together to ensure Microsoft is the best place for you to grow and have a great career. Let's keep moving forward together.&lt;/p&gt;
    &lt;p&gt;Thank you,&lt;/p&gt;
    &lt;p&gt;Amy"&lt;/p&gt;
    &lt;p&gt;Have a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.businessinsider.com/microsoft-send-employees-back-to-office-rto-remote-work-2025-9"/></entry><entry><id>https://news.ycombinator.com/item?id=45184921</id><title>Weave (YC W25) is hiring a founding AI engineer</title><updated>2025-09-09T18:12:52.461724+00:00</updated><content>&lt;doc fingerprint="951e4c15f89423dd"&gt;
  &lt;main&gt;
    &lt;p&gt;AI to understand engineering work&lt;/p&gt;
    &lt;p&gt;At Weave, we’re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.&lt;/p&gt;
    &lt;p&gt;We are a well-funded startup, backed by top investors, growing rapidly and currently profitable.&lt;/p&gt;
    &lt;p&gt;You'll be working directly with me (Andrew), the CTO. Before I was CTO of Weave I was the founding engineer at Causal, and I want to give you all the support and growth opportunities in this role that I got when I went through it.&lt;/p&gt;
    &lt;p&gt;You’ll also be working directly with Adam, the CEO. Adam runs sales at Weave, and before that worked as a sales executive at a few different high growth startups.&lt;/p&gt;
    &lt;p&gt;You are a good fit for Weave if you are a formidable engineer. This means you stop at nothing to accomplish your goal. We don't care much about your current skills or even what you've done before; we care that you will be able to do anything you set your mind to.&lt;/p&gt;
    &lt;p&gt;You must also be pragmatic. Weave is a startup so something is always on fire. You need to know when to let little fires burn and when to break out the extinguisher.&lt;/p&gt;
    &lt;p&gt;You must be a very good engineer who's committed to becoming a great engineer. The slope is more important than the Y-intercept.&lt;/p&gt;
    &lt;p&gt;You must be empathetic. We're building products for other people, so you need to be able to understand how other people think and why.&lt;/p&gt;
    &lt;p&gt;You must care about helping other software engineering teams be great. If that's not an exciting mission for you, it will be hard to stay motivated through the inevitable highs and lows.&lt;/p&gt;
    &lt;p&gt;You must be an excellent communicator. You’ll be working on a product that’s communicating with millions of engineers and leaders, so you need to be clear.&lt;/p&gt;
    &lt;p&gt;Finally you must be gritty. You should be accustomed to picking the hard option and pushing through it.&lt;/p&gt;
    &lt;p&gt;(Please feel free to apply even if some or all of these don't apply to you!)&lt;/p&gt;
    &lt;p&gt;Our tech stack is React + TypeScript on the frontend, Go on the backend, and Python for ML. Experience with any of those three languages is a bonus.&lt;/p&gt;
    &lt;p&gt;If you've already done lots of thinking about engineering productivity and how to improve it, that's great and we want to hear about it!&lt;/p&gt;
    &lt;p&gt;We hope your design sensibilities are passable.&lt;/p&gt;
    &lt;p&gt;As Weave’s founding AI engineer, your job is to build AI to understand and improve the work that software engineers do. You’ll be building our processes and standards as you go to make building every incremental feature easier. Your goal will be to delight customers with intelligence that makes their job 10x easier.&lt;/p&gt;
    &lt;p&gt;At Weave, we’re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.&lt;/p&gt;
    &lt;p&gt;We are a well-funded startup, backed by top investors and growing rapidly.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/weave-3/jobs/SqFnIFE-founding-ai-engineer"/></entry><entry><id>https://news.ycombinator.com/item?id=45185394</id><title>Apple Watch Ultra 3</title><updated>2025-09-09T18:12:51.522330+00:00</updated><content>&lt;doc fingerprint="acdaf85bd32e95f8"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE September 9, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Introducing Apple Watch Ultra 3&lt;/head&gt;
    &lt;p&gt; The ultimate sports and adventure watch now features Emergency SOS via satellite, the largest display ever &lt;lb/&gt;in an Apple Watch, 42-hour battery life, and powerful&lt;lb/&gt;new health insights&lt;/p&gt;
    &lt;p&gt;in an Apple Watch, 42-hour battery life, and powerful&lt;/p&gt;
    &lt;p&gt;new health insights&lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today introduced Apple Watch Ultra 3 — the most advanced Apple Watch — delivering expanded health, fitness, safety, and connectivity features, and seamlessly shifting between a powerful sports watch, an elegant smartwatch, and a comprehensive health companion. &lt;/p&gt;
    &lt;p&gt;Designed to keep users more connected and safer wherever they are with built-in satellite communications, Apple Watch Ultra 3 allows users to text emergency services, message friends and family, and share their location, all while they’re off the grid. The ultimate sports and adventure watch now features the largest screen of any Apple Watch, a display with a 1Hz always-on refresh rate, 5G cellular capabilities, the most accurate GPS in a sports watch, and up to 42 hours of battery life — with up to 72 hours in Low Power Mode. Notifications for signs of chronic high blood pressure, also known as hypertension, offer a groundbreaking new health insight, and sleep score helps users understand the quality of their sleep. Updates to the Workout app, including Workout Buddy — a first-of-its-kind fitness experience powered by Apple Intelligence — add to a robust suite of advanced fitness features. &lt;/p&gt;
    &lt;p&gt;Apple Watch Ultra 3 can be pre-ordered today, with availability beginning Friday, September 19. &lt;/p&gt;
    &lt;p&gt;“Apple Watch Ultra is our most advanced Apple Watch, designed to take users from sports and adventure to the rest of their life, and help them stay active, healthy, connected, and safe, wherever they are,” said Eugene Kim, Apple’s vice president of Apple Watch Hardware Engineering. “Apple Watch Ultra 3 debuts innovative satellite communications that will offer users more safety and connectivity when they’re off the grid, plus longer battery life, 5G, powerful health insights, and all the advanced fitness features our users love.” &lt;/p&gt;
    &lt;head rend="h2"&gt;A Larger Screen, 42 Hours of Battery Life, and 5G Cellular&lt;/head&gt;
    &lt;p&gt;The Apple Watch Ultra 3 display incorporates Apple’s most advanced display technology with LTPO3 and wide-angle OLEDs, making it the largest screen of any Apple Watch ever, and brighter when viewed from an angle. LTPO3 is a high-performance, low-power display technology that enables the display borders to be 24 percent thinner, increasing the active screen area without any changes to the case size. The wide-angle OLED display optimizes each pixel to emit more light at wider angles, making it easier to read at a glance.1 &lt;/p&gt;
    &lt;p&gt;LTPO3 is also more power efficient, enabling a faster refresh rate when Apple Watch Ultra 3 is in always-on mode, going from once a minute to once a second, so it’s possible to see a ticking seconds hand without raising the wrist. Stopwatch, Timer, and over 20 watch faces are updated with support for this refresh rate. In addition, a new Waypoint watch face can help users navigate with a live compass, easily access satellite communications with a new complication, and quickly turn on Night Mode to help preserve night vision. &lt;/p&gt;
    &lt;p&gt;The power efficiency of the LTPO3-enhanced display, 5G modem, and larger battery deliver longer battery life.2 For daily use, Apple Watch Ultra 3 features up to 42 hours to support users while they are training, racing, or going about their day. In Low Power Mode, it continues to offer up to 72 hours of battery life. For continuous outdoor workout tracking, Apple Watch Ultra 3 now gets 20 hours of battery life in Low Power Mode with full GPS and heart rate readings. With fast charging, 15 minutes provides up to 12 hours of battery life. &lt;/p&gt;
    &lt;p&gt;With a cellular plan, Apple Watch users can take calls, send messages, and even get help with emergency services when their iPhone isn’t with them.3 When users are on the grid, Apple Watch Ultra 3 now offers 5G cellular capabilities, which provide better performance with greater throughput, so music, podcasts, and apps download faster.4 To boost reception in areas with weak coverage, Apple Watch Ultra 3 also uses an advanced algorithm that simultaneously engages the two system antennas when needed, significantly increasing the signal strength. &lt;/p&gt;
    &lt;head rend="h2"&gt;Satellite Communications&lt;/head&gt;
    &lt;p&gt;Apple Watch Ultra 3 features built-in, two-way satellite communications, so users can feel safer and more connected when they are off the grid, whether they’re backcountry skiing, trail running, or camping in the wilderness. &lt;/p&gt;
    &lt;p&gt;When users do not have cellular or Wi-Fi coverage, they can now text emergency services, message friends and family, and share their location.5 Apple Watch Ultra 3 offers Emergency SOS via satellite to text emergency services and notify emergency contacts with a few simple taps. If Apple Watch Ultra 3 detects a severe car crash or a hard fall, and the user is unresponsive while off the grid, it can automatically send situation and location information to emergency services and emergency contacts, when in line of sight of a satellite. &lt;/p&gt;
    &lt;p&gt;With Find My via satellite, users can send their location once every 15 minutes to contacts previously added to Find My. In addition, with Messages via satellite, users can send and receive texts, emoji, and Tapbacks to friends and family — including anyone they’ve been in touch with over the last 30 days — while keeping the messages end-to-end encrypted. Users can also send SMS messages via satellite.6 &lt;/p&gt;
    &lt;p&gt;To enable satellite connectivity in a device as small as Apple Watch Ultra 3, the device’s radio was reengineered to cover more frequencies, and the antenna was redesigned to double the signal strength, allowing communication with satellites as far as 800 miles above Earth and that are moving at 15,000 mph. Apple also continues to invest in crucial emergency infrastructure, including 24/7 relay centers staffed by safety professionals trained to the highest standards, and prioritizes emergency and safety features in the event of natural disasters. &lt;/p&gt;
    &lt;p&gt;Connection with a satellite will automatically be presented as an option when a user is off the grid, and Connection Assistant provides onscreen guidance to help users access satellite features when needed. All satellite communication features are free for two years with Apple Watch Ultra 3. Emergency SOS via satellite is included with Apple Watch Ultra 3 without a cellular plan, and with an active cellular plan, users can also send messages and share their location with Find My.7 &lt;/p&gt;
    &lt;head rend="h2"&gt;Hypertension Notifications&lt;/head&gt;
    &lt;p&gt;Building on the advanced health features that allow Apple Watch to serve as an intelligent guardian for users’ health, Apple Watch Ultra 3 introduces groundbreaking hypertension notifications, which can alert users if signs of chronic high blood pressure — or hypertension — are detected.8 Hypertension is the leading modifiable risk factor for heart attack, stroke, and kidney disease, and impacts approximately 1.3 billion adults globally. It is frequently undiagnosed because it often has no symptoms, many people do not see a doctor regularly, and even during a clinical visit, it can be easily missed with a single measurement. &lt;/p&gt;
    &lt;p&gt;Hypertension notifications on Apple Watch use data from the optical heart sensor to analyze how a user’s blood vessels respond to the beats of the heart. The algorithm works passively in the background reviewing data over 30-day periods, and will notify users if it detects consistent signs of hypertension. These notifications provide users with impactful insights into their health as it relates to this widespread condition simply by wearing their Apple Watch, so they can begin making potentially lifesaving behavioral changes or start treatment to reduce their risk of serious, long-term health events. &lt;/p&gt;
    &lt;p&gt;Like all of the health features on Apple Watch, hypertension notifications are grounded in rigorous scientific validation. The feature was developed with advanced machine learning and training data from multiple studies totaling over 100,000 participants. Its performance was then validated in a clinical study of over 2,000 participants. While hypertension notifications will not detect all instances of hypertension, with the reach of Apple Watch, the feature is expected to notify over 1 million people with undiagnosed hypertension within the first year. &lt;/p&gt;
    &lt;p&gt;If users receive a hypertension notification, it is recommended that they log their blood pressure for seven days using a third-party blood pressure cuff and share the results with their provider at their next visit, which is consistent with the latest American Heart Association guidelines for the diagnosis and management of hypertension. &lt;/p&gt;
    &lt;p&gt;Clearance for hypertension notifications from the FDA and other regulators is expected soon, and the feature will be available in more than 150 countries and regions — including the U.S. and the EU — this month. Hypertension notifications will be available on Apple Watch Series 9 and later, and Apple Watch Ultra 2 and later, with watchOS 26. &lt;/p&gt;
    &lt;head rend="h2"&gt;Sleep Score&lt;/head&gt;
    &lt;p&gt;Sleep is fundamental to a person’s health and critical to daily restoration. Apple Watch allows users to track sleep; measure important health metrics during sleep like heart rate, wrist temperature, blood oxygen, and respiratory rate; and even discover possible sleep apnea.9 Now, with watchOS 26, Apple Watch can help users understand the quality of their sleep and how to make it more restorative with a new sleep score feature.10 &lt;/p&gt;
    &lt;p&gt;Sleep quality is influenced by several factors, such as duration, bedtime consistency, how often a person wakes up, and how much time is spent in each sleep stage. With sleep score, Apple Watch helps track each of these categories to assign transparent and easy-to-understand metrics for a user’s overall sleep quality. After each night, sleep score provides an overall score and classification in the Sleep app on Apple Watch, plus a clear breakdown of the most critical components, so users know what to prioritize to improve their sleep. Users can also choose to easily access their sleep score in a watch face complication or in the Smart Stack, and they can track their sleep scores over time in the Health app on iPhone. &lt;/p&gt;
    &lt;p&gt;The scoring approach and prioritization algorithm of sleep score is informed by the latest guidance published by the American Academy of Sleep Medicine, National Sleep Foundation, and World Sleep Society. Over 5 million nights of sleep data from the Apple Heart and Movement Study were used to develop and test the scoring algorithms. &lt;/p&gt;
    &lt;p&gt;Hypertension notifications and sleep score join a powerful set of health features available on Apple Watch, including irregular rhythm notifications, high and low heart rate notifications, the ECG app, Blood Oxygen, sleep apnea notifications, and retrospective ovulation estimates. &lt;/p&gt;
    &lt;head rend="h2"&gt;Advanced Fitness Features&lt;/head&gt;
    &lt;p&gt;With watchOS 26, Apple Watch Ultra 3 features Workout Buddy, a first-of-its-kind fitness experience powered by Apple Intelligence that analyzes a user’s workout data and fitness history to deliver personalized, spoken motivation throughout their session, based on data like heart rate, pace, distance, Activity rings, personal fitness milestones, and more.11 Workout Buddy will be available starting in English across some of the most popular workout types, and is available on Apple Watch with Bluetooth headphones, with an Apple Intelligence-supported iPhone nearby. &lt;/p&gt;
    &lt;p&gt;Additionally, the new layout of the Workout app makes it easier to customize workouts with Workout Views, custom workouts, Pacer, Race Route, and more. Apple Watch users can now conveniently view and create workouts in the Fitness app on iPhone, including custom workouts, and then easily access them in the Workout app on Apple Watch. &lt;/p&gt;
    &lt;p&gt;To add inspiration, users can set up music and podcasts right in the Workout app to automatically play when they start a workout. For convenience, Apple Music can now select the best music for a user’s workout based on the workout type and their personal tastes, or users can see suggestions for music or podcasts based on what they’ve recently listened to during that particular workout type.12 &lt;/p&gt;
    &lt;p&gt;Apple Watch Ultra 3 supports athletes and adventurers of all kinds as the ultimate sports watch: &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Runners get the most accurate GPS in a sports watch;13 a customizable Action button that can be used for Precision Start or to mark segments; advanced metrics including vertical oscillation, ground contact time, and stride length; customizable Workout Views including Heart Rate Zones; Race Route; Pacer; an industry-first automatic track-running detection feature; custom workouts; training load; and more for workouts and races. Users can also benefit from third-party experiences like Nike Run Club; the updated Strava app that includes Live Segments; and custom workouts from apps like Runna and TrainingPeaks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cyclists can easily view a workout started on Apple Watch as a Live Activity on iPhone and see metrics on the full screen — or connect a Bluetooth-enabled power meter or other cycling accessories to Apple Watch Ultra 3 — giving them more metrics and experiences, including cadence, an automatic estimate of functional threshold power, and Power Zones. Users can also track distance, speed, elevation, and heart rate.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swimmers can make use of automatic stroke detection, lap count, and a SWOLF score — a stroke count combined with the time it takes to swim one length of the pool, displayed in seconds — plus take advantage of custom workouts and view water temperature directly within the Workout app. Apple Watch Ultra 3 is certified to WR100.14&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hikers can enjoy offline maps on the trail — complete with turn-by-turn directions — as well as features like Waypoints and Backtrack GPS data in the Compass app.15&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Divers can take advantage of the Oceanic+ app — developed in partnership with Huish Outdoors — which turns Apple Watch Ultra 3 into a dive computer for recreational scuba diving.16&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Golfers benefit from the bright display and long battery life of Apple Watch Ultra 3. With a suite of third-party apps, including Golfshot, Arccos, and 18Birdies, users can access course information or tools and insights utilizing the high-frequency motion API to help improve their game.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Additional watchOS 26 Features&lt;/head&gt;
    &lt;p&gt;watchOS 26 features a new design and fresh look with Liquid Glass; makes everyday interactions even more convenient with Smart Stack hints and updates to Messages, including Live Translation and intelligent suggestions based on the conversation; and introduces a new one-handed wrist flick gesture to easily dismiss notifications.17 &lt;/p&gt;
    &lt;head rend="h2"&gt;Lineup and Bands&lt;/head&gt;
    &lt;p&gt;Apple Watch Ultra 3 is available in natural or black titanium. &lt;/p&gt;
    &lt;p&gt;A new collection of bands includes a Trail Loop design with reflective yarn along the edges, in addition to new colors for the Ocean Band and Alpine Loop. The Hermès collection also gets two new colors for the En Mer band and a new Scub’H Diving band in rubber with a titanium buckle — perfect for an active lifestyle. &lt;/p&gt;
    &lt;head rend="h2"&gt;Apple Watch Ultra 3 and the Environment&lt;/head&gt;
    &lt;p&gt;Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. Apple Watch Ultra 3 is made with 40 percent recycled content, including 100 percent recycled cobalt in the battery and 100 percent recycled titanium in the case, and the case is made using an innovative 3D printing process that uses just half the raw material as previous generations. It is manufactured with 100 percent renewable electricity, like wind and solar, across the supply chain. Apple Watch Ultra 3 is designed to be durable and repairable, and also offers industry-leading software support, while meeting Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled. &lt;/p&gt;
    &lt;p&gt;Apple 2030 goes beyond products — today, Apple is carbon neutral for its global corporate operations, and all Apple facilities run on 100 percent renewable electricity, including the data centers that power Apple Intelligence. Collectively, these efforts have reduced Apple’s global greenhouse gas emissions by more than 60 percent since 2015. &lt;/p&gt;
    &lt;p&gt;Pricing and Availability &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customers in Australia, Canada, France, Germany, India, Japan, the UAE, the UK, the U.S., and more than 50 other countries and regions can pre-order Apple Watch Ultra 3 today, with availability in stores beginning Friday, September 19.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Watch Ultra 3 starts at $799 (U.S.), and is available in natural and black titanium.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New bands will be available to order today from apple.com/store and on the Apple Store app, with availability in stores beginning Friday, September 19.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;watchOS 26 will be available for Apple Watch Series 6 or later, Apple Watch SE (2nd generation) and later, and all Apple Watch Ultra models on Monday, September 15, and requires iPhone 11 or later running iOS 26. Not all features are available on all devices or in all regions. For more information about availability, visit apple.com.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apple Intelligence is available in beta. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New subscribers may get three months of Apple Fitness+ and Apple Music with the purchase of Apple Watch Series 11, Apple Watch SE 3, or Apple Watch Ultra 3. Offer and services availability varies by region. See apple.com/promo for details.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clearance for hypertension notifications from the FDA and other regulators is expected soon, with availability in over 150 countries and regions — including the U.S. and the EU — this month.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new Apple Watch, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple experts. For more information, visit apple.com/applecare.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For more information on Apple 2030, visit apple.com/2030.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;When angled away from the user, as compared with Apple Watch Ultra or Apple Watch Ultra 2.&lt;/item&gt;
      &lt;item&gt;Battery life varies by use and configuration. See apple.com/watch/battery for more information.&lt;/item&gt;
      &lt;item&gt;Wireless service plan required for cellular service. Contact service provider for more details. Connection may vary based on network availability. Check apple.com/watch/cellular for participating wireless carriers and eligibility. See support.apple.com/HT207578 for additional setup instructions.&lt;/item&gt;
      &lt;item&gt;5G is available in select markets and through select carriers. Speeds vary based on site conditions and carrier. For details on 5G support, users can contact their carrier and visit apple.com/watch/cellular.&lt;/item&gt;
      &lt;item&gt;Emergency SOS via satellite requires a satellite connection, a cellular connection, or Wi-Fi calling with an internet connection from Apple Watch. Cellular models of Apple Watch can be used to make an emergency call in many locations, provided that cellular service is available. Some cellular networks may not accept an emergency call from Apple Watch if Apple Watch isn’t activated, isn’t compatible with or configured to operate on a particular cellular network, or isn’t set up for cellular service, or if the cellular network does not support emergency calling over IMS. See support.apple.com/108374 and apple.com/watch/cellular for more information. See support.apple.com/123924 for more information.&lt;/item&gt;
      &lt;item&gt;Messages via satellite is available in the U.S., Canada, and Mexico. Requires a carrier plan. To send and receive SMS/MMS from cellular models of Apple Watch over satellite, the paired iPhone must be powered on and connected to Wi-Fi or an active cellular network, but iPhone doesn’t need to be nearby. SMS message rates may apply. Satellite connectivity provided by Globalstar and its affiliates. See support.apple.com/123924 for more information.&lt;/item&gt;
      &lt;item&gt;Emergency SOS, Find My, and Messages via satellite are included for free for two years with the activation of Apple Watch Ultra 3. Connection and response times vary based on location, site conditions, and other factors. Find My and Messages via satellite require a carrier plan. To send and receive SMS/MMS from cellular models of Apple Watch over satellite, the paired iPhone must be powered on and connected to Wi-Fi or an active cellular network, but iPhone doesn’t need to be nearby. SMS is available on supported carriers, and message rates may apply. Satellite connectivity provided by Globalstar and its affiliates.&lt;/item&gt;
      &lt;item&gt;Hypertension notifications are currently under FDA review and expected to be cleared this month, with availability on Apple Watch Series 9 and later, and Apple Watch Ultra 2 and later. The feature is not intended for use by people under 22 years old, those who have been previously diagnosed with hypertension, or during pregnancy.&lt;/item&gt;
      &lt;item&gt;Blood Oxygen app is for wellness purposes only and not for medical use. Measurements are calculated and viewed on iPhone in the Health app.&lt;/item&gt;
      &lt;item&gt;Sleep score is available with watchOS 26 for Apple Watch Series 6 or later, Apple Watch SE (2nd generation) or later, and all Apple Watch Ultra models, paired with iPhone 11 or later, running iOS 26.&lt;/item&gt;
      &lt;item&gt;Workout Buddy requires an Apple Intelligence-enabled iPhone nearby and Bluetooth headphones, with device and Siri language set to English. Apple Intelligence is available in beta. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.&lt;/item&gt;
      &lt;item&gt;An Apple Music subscription is required for automatic music selection.&lt;/item&gt;
      &lt;item&gt;GPS performance was evaluated based on route map accuracy in challenging urban environments for outdoor running and walking workouts. Comparison made against industry-leading dual-frequency GPS sports watches commercially available at the time of testing in August 2025.&lt;/item&gt;
      &lt;item&gt;Apple Watch Ultra 3 has a water resistance rating of 100 meters under ISO standard 22810:2010. It may be used for recreational scuba diving (with compatible third-party app from the App Store) to 40 meters and high-speed water sports. Apple Watch Ultra 3 should not be used for diving below 40 meters. Water resistance is not a permanent condition and can diminish over time. For additional information, see support.apple.com/en-us/109522.&lt;/item&gt;
      &lt;item&gt;Offline maps is available for Apple Watch Series 6 and later, Apple Watch SE 2 and later, and all Apple Watch Ultra models running watchOS 26 or later. Requires iPhone 11 or later running iOS 26 or later. Not available in all countries and regions.&lt;/item&gt;
      &lt;item&gt;A subscription is required for Oceanic+ for dive computer capabilities. Available on the App Store. Apple Watch Series 11 supports snorkeling to 6 meters; Apple Watch Ultra 3 supports recreational scuba diving to 40 meters. Always follow diving protocols and dive with a companion and have a secondary device.&lt;/item&gt;
      &lt;item&gt;Live Translation in Messages is available in Chinese (simplified), English (UK, U.S.), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), and Spanish (Spain) on Apple Watch Series 9 and later, Apple Watch SE 3, and Apple Watch Ultra 2 and later when paired with an Apple Intelligence-enabled iPhone. The wrist flick gesture is available on Apple Watch Series 9 and later, Apple Watch SE 3, and Apple Watch Ultra 2 and later.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apple.com/newsroom/2025/09/introducing-apple-watch-ultra-3/"/></entry><entry><id>https://news.ycombinator.com/item?id=45185576</id><title>Apple announces the ultra-slim iPhone Air</title><updated>2025-09-09T18:12:51.200819+00:00</updated><content>&lt;doc fingerprint="f4a87edd033773c4"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple just announced the thinnest iPhone ever, the iPhone Air, which measures just 5.6mm thick. CEO Tim Cook said it promises “pro performance in a thin and light design.”&lt;/p&gt;
    &lt;head rend="h1"&gt;Apple announces the ultra-slim iPhone Air&lt;/head&gt;
    &lt;p&gt;The Air branding comes to iPhones with an impressively thin new design.&lt;/p&gt;
    &lt;p&gt;The Air branding comes to iPhones with an impressively thin new design.&lt;/p&gt;
    &lt;p&gt;The new iPhone Air comes with a 6.5-inch ProMotion display and a refresh rate of up to 120Hz. It also has 3,000 nits of peak brightness. Apple says the design is its “most durable” yet, featuring a ceramic shield that encloses a titanium frame on both sides.&lt;/p&gt;
    &lt;p&gt;It features a new A19 Pro processor, which is the most powerful iPhone chip yet, and a new Apple-built modem called the C1x, which is two times faster than the C1. Along with these upgrades, the iPhone Air comes with Apple’s new N1 chip design, which adds support for Wi-Fi 7, Bluetooth 6, and Thread.&lt;/p&gt;
    &lt;p&gt;And, despite how thin it is, Apple promises “all day” battery life with up to 40 hours of video playback. To “maximize” battery space, the iPhone Air only supports e-SIMs. Apple also says adaptive power mode in iOS 26 will help improve battery life.&lt;/p&gt;
    &lt;p&gt;The iPhone Air features a 48-megapixel dual camera system with a 12MP telephoto lens. It comes with a new system that combines the front and rear cameras, allowing you to record a video of yourself while capturing what’s in front of you. The 18MP selfie camera also supports Center Stage, a feature also on the regular iPhone 17, which automatically fits everyone into a photo, so you don’t have to rotate the phone into landscape mode.&lt;/p&gt;
    &lt;p&gt;The iPhone Air comes in black, white, beige, white, and light blue. Apple also revealed several new accessories for the iPhone Air, including an ultra-thin translucent case, as well as a bumper case made from reinforced polycarbonate. Both options pair with a new cross-body strap.&lt;/p&gt;
    &lt;p&gt;The launch of the iPhone Air coincides with the upcoming release of iOS 26. The updated operating system features a new Liquid Glass design language that gives some of its navigational elements and icons a bubbly, transparent look that had some users divided during the beta testing period.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/771942/apple-iphone-17-air-announcement"/></entry></feed>