<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-12T23:10:09.155489+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45899189</id><title>A brief look at FreeBSD</title><updated>2025-11-12T23:10:17.004749+00:00</updated><content>&lt;doc fingerprint="d69c7959c92f8ae6"&gt;
  &lt;main&gt;
    &lt;p&gt;Recently I've been playing around with FreeBSD in a virtual machine. The reason for this is that (if all goes well) some time in December my new Framework laptop will arrive, replacing my current X1 Carbon that is starting to show signs of old age (e.g. a keyboard where certain keys don't always work). Framework in turn has a strong focus on Linux compatibility, and FreeBSD compatibility to a certain degree. The FreeBSD foundation in turn is sponsoring work on improving the laptop experience of FreeBSD, with a focus on Framework laptops in particular.&lt;/p&gt;
    &lt;p&gt;In other words, if I ever wanted to run FreeBSD on a laptop, a Framework laptop would probably be the best option, and using a new laptop means I can just wipe the installation and replace it with Fedora if FreeBSD turns out to not be worth it. But before I do that, I needed to figure out if it's even worth the effort and what I might have to keep in mind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why FreeBSD?&lt;/head&gt;
    &lt;p&gt;Before I discuss my experience playing around with FreeBSD thus far, let's discuss why I would even consider using FreeBSD. After all, I'm pretty happy with my current Fedora Silverblue, minus some paper cuts here and there. But hey, Linux wouldn't be Linux without paper cuts.&lt;/p&gt;
    &lt;p&gt;The first reason for looking into FreeBSD is the more cohesive experience it claims (or at least its users claim) to have. That is, it's not just a kernel but a kernel plus userspace utilities and a bunch of other things. Whether this actually matters for end users is difficult to say, but as somebody who might want to contribute back it could be a benefit. For example, say you want to contribute a function (e.g. a hypothetical &lt;code&gt;get_dns_without_blocking_the_calling_thread&lt;/code&gt; function) to the
C standard library and this function requires some kernel changes. For Linux
this means contributing a change to at least two to three different projects:
the kernel, and glibc, and maybe musl for increased portability. In contrast,
for FreeBSD you just contribute to, well, FreeBSD.&lt;/p&gt;
    &lt;p&gt;The second reason is the availability of software. While some programs are not available on FreeBSD (e.g. lua-language-server is not available) or others lag behind a bit at times (e.g. Electron updates apparently can take a while to become available), it seems there's a surprising amount of software available.&lt;/p&gt;
    &lt;p&gt;The third reason is the (at least claimed) stability of FreeBSD as a whole. Combined with the availability of packages this means that in theory you can get a system as stable as e.g. Fedora Silverblue, but with a lot more (and more frequently updated) software available.&lt;/p&gt;
    &lt;p&gt;There are some additional nice-to-have's that aren't necessarily unique to FreeBSD that are still potentially interesting. For example, ZFS seems interesting but Btrfs is probably close enough for most people. FreeBSD also has jails and had them for a long time, but Linux has LXC (basically FreeBSD jails), Podman, and basically whatever else builds on top of the Open Container Initiative.&lt;/p&gt;
    &lt;p&gt;Of these reason the first one is the most important one: a system that's more cohesive, rather than something that feels more like a car engine with a bunch of components bolted on top, each maintained by a different person.&lt;/p&gt;
    &lt;head rend="h2"&gt;The setup&lt;/head&gt;
    &lt;p&gt;Until my new laptop arrives I have no spare computer available that I'm willing to wipe just to play with FreeBSD, so instead I used a virtual machine. Specifically, I have an M1 Mac Mini that I use for testing Inko on macOS that is turned off most of the time, so I used that as the VM host. This way I can play around with FreeBSD regardless of whether I'm using my desktop computer or my laptop.&lt;/p&gt;
    &lt;p&gt;The VM was actually set up a while ago so I could more easily test Inko on FreeBSD, using FreeBSD 14.0 which I've since upgraded to 14.3 (more on that later). For the file system I'm using ZFS. Because this installation is used for testing there's no desktop environment, instead it's a bare-bones server-like setup. Note that because the VM runs on an M1 Mac Mini, the architecture is aarch64 instead of x86-64. This in turn may affect the experience (i.e. certain default settings may depend on this, though I don't know this for certain).&lt;/p&gt;
    &lt;p&gt;The use of a VM also means I've not yet been able how well FreeBSD supports the Framework laptop hardware wise. I know there's been a lot of progress on improving laptop support in the last few months, but until I actually have a new laptop I can't verify this. This means the rest of this article focuses just on the software and user experience side of things.&lt;/p&gt;
    &lt;p&gt;What follows is a collection of the various steps I took to set things up and my experience thus far.&lt;/p&gt;
    &lt;head rend="h2"&gt;Configuring the network&lt;/head&gt;
    &lt;p&gt;Let's start with the first and probably most important step: setting up the network. After all, what good is an operating system if you can't download pictures of cats. I don't fully remember how I actually set up the network as it's been a while, but it involved adding the following to &lt;code&gt;/etc/rc.conf&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;hostname="freebsd-mini"
ifconfig_vtnet0="DHCP"
ifconfig_vtnet0_ipv6="inet6 accept_rtadv"
&lt;/code&gt;
    &lt;p&gt;DHCP is managed using the "dhclient" service, which I think starts automatically by default. This also brings me to my first small annoyance with FreeBSD: the sensible thing to do would be something like &lt;code&gt;sudo service dhclient CMD&lt;/code&gt; to do
something with the service (e.g. restart it), but instead this will fail with
the following:&lt;/p&gt;
    &lt;code&gt;/etc/rc.d/dhclient: ERROR: /etc/rc.d/dhclient: no interface specified
&lt;/code&gt;
    &lt;p&gt;When I first encountered this error I thought there was something wrong with the mentioned file (&lt;code&gt;/etc/rc.d/dhclient&lt;/code&gt;). After a bit of digging it turns out that
you also have to specify the interface when running the &lt;code&gt;service&lt;/code&gt; command, i.e:&lt;/p&gt;
    &lt;code&gt;sudo service dhclient restart vtnet0
&lt;/code&gt;
    &lt;p&gt;I suppose the idea here is that you can have multiple DHCP clients for different interfaces and want to manage them separately. Personally I'd prefer it if leaving out the interface results in the command applying to all configured interfaces, but I'll write this off as me just not understanding FreeBSD well enough yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;DNS caching&lt;/head&gt;
    &lt;p&gt;For DNS, FreeBSD by default just queries whatever nameservers &lt;code&gt;/etc/resolv.conf&lt;/code&gt;
defines, in contrast to most Linux distributions that ship something like
dnsmasq to handle this by default.&lt;/p&gt;
    &lt;p&gt;To enable DNS caching you have two (somewhat confusingly named) options (and maybe more that I'm not aware of): unbound and local_unbound. The difference between the two is that "unbound" is a full-blown DNS resolved, while "local_unbound" is meant solely for responding to and caching queries from the local machine. Or in grug speak: unbound for other grugs in network, local_unbound only for grug itself.&lt;/p&gt;
    &lt;p&gt;The FreeBSD handbook covers how to set up local_unbound. The handbook mentions that the DNS servers used prior to enabling local_unbound must support DNSSEC, otherwise DNS queries will fail. My dumb grug brain decided to ignore that part thinking it wouldn't be relevant. As a result I got to spend the next hour trying to figure out why DNS queries didn't work, only to realise it's because my Mikrotik router (the upstream DNS server that I use as a network wide DNS cache) doesn't support DNSSEC.&lt;/p&gt;
    &lt;p&gt;To resolve this, I had to figure out how to disable DNSSEC while still being able to cache DNS queries locally. Thanks to this broken looking website I figured out you can do so by creating &lt;code&gt;/var/unbound/conf.d/disable-dnssec.conf&lt;/code&gt;
with the following contents:&lt;/p&gt;
    &lt;code&gt;server:
    module-config: "iterator"
&lt;/code&gt;
    &lt;p&gt;Then you restart the service using &lt;code&gt;sudo service local_unboun restart&lt;/code&gt; and off
you go. It would be nice if the FreeBSD handbook discussed disabling DNSSEC as
it would've saved me quite some time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Changing a few default settings&lt;/head&gt;
    &lt;p&gt;OK so we got a working network connection and DNS caching, let's take a look at the defaults that FreeBSD provides (or doesn't). Specifically, I read this article a while back and was wondering how much of the article is still relevant.&lt;/p&gt;
    &lt;head rend="h3"&gt;ASLR and W^X protection&lt;/head&gt;
    &lt;p&gt;First up, ASLR and W^X. The mentioned article lists a bunch of ASLR settings though it seems to leave out a few for 64-bits executables. Based on this manual page and the article at least the following settings are of interest for a 64-bits system:&lt;/p&gt;
    &lt;code&gt;kern.elf64.allow_wx
kern.elf64.aslr.enable
kern.elf64.aslr.honor_sbrk
kern.elf64.aslr.pie_enable
kern.elf64.aslr.stack
&lt;/code&gt;
    &lt;p&gt;In my VM the defaults are as follows:&lt;/p&gt;
    &lt;code&gt;kern.elf64.allow_wx: 1
kern.elf64.aslr.enable: 1
kern.elf64.aslr.honor_sbrk: 0
kern.elf64.aslr.pie_enable: 1
kern.elf64.aslr.stack: 1
&lt;/code&gt;
    &lt;p&gt;For 32-bits executables it seems ASLR is disabled, though I don't know enough about ASLR to determine if that's good or bad. For 64-bits only systems this doesn't matter anyway.&lt;/p&gt;
    &lt;p&gt;Based on this I think the only setting worth changing is setting &lt;code&gt;kern.elf64.allow_wx&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt;, given this protection is widely enabled by other
operating systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;PID randomization&lt;/head&gt;
    &lt;p&gt;PID randomization is disabled by default and is enabled using the following &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;kern.randompid=1
&lt;/code&gt;
    &lt;p&gt;Whether this is useful is difficult to say. OpenBSD does this by default, while Linux doesn't appear to enable this. I tried figuring out what a good value for this setting is, but I haven't been able to find a good answer.&lt;/p&gt;
    &lt;p&gt;Given that it's unclear what the actual benefit of PID randomization is and that it feels like security through obscurity, I've left this option disabled.&lt;/p&gt;
    &lt;head rend="h3"&gt;Disallow non-root from reading &lt;code&gt;dmesg&lt;/code&gt; and the likes&lt;/head&gt;
    &lt;p&gt;By default non-root users can read the system message buffer through &lt;code&gt;dmesg&lt;/code&gt;. In
contrast, Linux (or at least Fedora) disallows this by default. Because this
buffer may contain sensitive information, I think it's a good idea to disallow
this using the following setting:&lt;/p&gt;
    &lt;code&gt;security.bsd.unprivileged_read_msgbuf=0
&lt;/code&gt;
    &lt;head rend="h3"&gt;Hiding processes of other users&lt;/head&gt;
    &lt;p&gt;By default a user can see the processes of other users, similar to most (all?) Linux distributions. You can turn this off using the following settings:&lt;/p&gt;
    &lt;code&gt;security.bsd.see_other_uids=0
security.bsd.see_other_gids=0
security.bsd.see_jail_proc=0
&lt;/code&gt;
    &lt;p&gt;For a desktop environment I would actually leave this enabled though, as it makes debugging a little easier. For a server there's no reason for user A to be able to see processes of user B, so it's probably best to disable this for such setups.&lt;/p&gt;
    &lt;head rend="h3"&gt;Other defaults&lt;/head&gt;
    &lt;p&gt;There are many more defaults that may be worth looking into, but based on what I could find most of those won't need to be changed in most cases. It certainly doesn't seem to be as bad (anymore) as it might've once been.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enabling pkgbase&lt;/head&gt;
    &lt;p&gt;OK we now have a sensible system. At this point I was still running FreeBSD 14.0, so I figured it was time to upgrade to 14.3 before doing anything else. This brings me to this thing called "pkgbase". Basically this is a new way of updating FreeBSD installation that's still under development but scheduled for release in FreeBSD 15. Without going into it too deeply, FreeBSD offers (at least for now) two ways of updating your system:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;pkg&lt;/code&gt;is used for updating individual packages (e.g. your text editor)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;freebsd-update&lt;/code&gt;is used for updating FreeBSD itself (e.g. from 14.0 to 14.3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The pkgbase project/thing aims to unify this so you only need to use the &lt;code&gt;pkg&lt;/code&gt;
command for both. Basically it's what every Linux distribution has been doing
for decades at this point.&lt;/p&gt;
    &lt;p&gt;Until FreeBSD 15 is released you'll need to manually enable this. The FreeBSD handbook discusses how to do this so I won't cover this. I did run into a few issues/quirks when enabling it:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The &lt;code&gt;fetch&lt;/code&gt;command from the handbook just froze and I ended up having to use&lt;code&gt;curl&lt;/code&gt;to download it instead. I don't remember why though, maybe it might've been due to those self-inflicted DNS issues I mentioned earlier&lt;/item&gt;
      &lt;item&gt;You have to edit a config file to update to a new version. This seems a little clunky and difficult to automate (without overwriting the entire configuration file)&lt;/item&gt;
      &lt;item&gt;After the upgrade I ended up with a bazillion &lt;code&gt;.pkgsave&lt;/code&gt;files, similar to what this article discusses. I ended up just removing these using the&lt;code&gt;find&lt;/code&gt;command mentioned in said article. Why were these files created? No idea, but let's hope this doesn't keep happening&lt;/item&gt;
      &lt;item&gt;I figured you'd just run &lt;code&gt;pkg update&lt;/code&gt;to update the system or maybe something like&lt;code&gt;pkg update --system&lt;/code&gt;, but instead you have to run&lt;code&gt;sudo pkg update -r FreeBSD-base&lt;/code&gt;. It's not a big issue, but it would be nice not having to remember the&lt;code&gt;FreeBSD-base&lt;/code&gt;bit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After going through this process everything did work fine, so that's nice. One thing I'd like to see is &lt;code&gt;pkg&lt;/code&gt; creating ZFS snapshots before upgrading to a new
FreeBSD version, but perhaps that's something I have to explicitly enable
somewhere (I have yet to figure this out).&lt;/p&gt;
    &lt;head rend="h2"&gt;Package management&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;pkg&lt;/code&gt; tool itself is quite nice, and unlike &lt;code&gt;dnf&lt;/code&gt; it's pretty darn fast when
it doesn't have to download anything. It also doesn't automatically update the
package database when you least expect it, instead requiring you to explicitly
run &lt;code&gt;pkg update&lt;/code&gt;. I much prefer this over having to remember to use &lt;code&gt;dnf -C&lt;/code&gt; to
avoid having to wait 30 seconds for it to refresh the database.&lt;/p&gt;
    &lt;p&gt;Which brings me to the downloading bit: &lt;code&gt;pkg&lt;/code&gt; downloads packages sequentially,
instead of downloading them concurrently (a feature requested since
2017). This is a bit annoying
because while I have a gigabit internet connection, the FreeBSD mirrors appear
to be limited to a speed of around 100 megabits/second. Depending on the number
of packages that need to be downloaded this means having to wait longer than
strictly necessary. Considering every Linux package manager that I know of
supports concurrent downloads, this is a bit annoying.&lt;/p&gt;
    &lt;p&gt;When it comes to packages, FreeBSD has a surprising large number of packages available, and from what I can tell most of them are also up to date, though there are some exceptions. For example, stylua isn't available in the Fedora repository (though you can use my copr repository), while FreeBSD does have it (though the version is almost one year out of date). This will differ per package and its popularity, so your mileage may vary.&lt;/p&gt;
    &lt;p&gt;A weird quirk I ran into is that for certain packages &lt;code&gt;pkg info NAME&lt;/code&gt; only works
for installed packages, which the output of &lt;code&gt;pkg help info&lt;/code&gt; doesn't make clear.
It seems the closest equivalent is &lt;code&gt;pkg search -f NAME&lt;/code&gt;, though that gives you
the information of all packages that match &lt;code&gt;NAME&lt;/code&gt;, not just the package with
that exact name.&lt;/p&gt;
    &lt;p&gt;To summarise, &lt;code&gt;pkg&lt;/code&gt; feels similar to &lt;code&gt;dnf&lt;/code&gt;: a bit clunky and not as fast as it
should be, but manageable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Firewalls&lt;/head&gt;
    &lt;p&gt;The world of firewalls on Linux is a bit of a mess, with different distributions using different firewalls (ufw, firewalld, etc). Fedora uses firewalld which is...OK, but I'm not a fan of the confusing CLI.&lt;/p&gt;
    &lt;p&gt;FreeBSD has not one, not two but three competing firewalls: PF, IPFW, and IPF. All seem to come with their own configuration syntax and semantics (e.g. ordering of rules). It seems PF is generally recommended because it's based on PF from OpenBSD, though FreeBSD uses a fork which has diverged a lot and (from what I could find) wasn't (isn't?) kept in sync with OpenBSD's PF.&lt;/p&gt;
    &lt;p&gt;I haven't figured out yet which one should be used, but there being three competing firewalls feels more like something you'd expect in Linux and not a BSD.&lt;/p&gt;
    &lt;head rend="h2"&gt;Resource usage&lt;/head&gt;
    &lt;p&gt;On a totally different note, it's refreshing to see how few processes a basic FreeBSD installation runs: about 50 or so (fewer if you disable all the TTY console processes), compared to the 100-150 or so you'll end up with when using a stock Fedora Server installation. This isn't necessarily better (and depending on what those processes do might be worse), but at least in theory it means fewer moving parts to worry about.&lt;/p&gt;
    &lt;head rend="h2"&gt;CLI quirks&lt;/head&gt;
    &lt;p&gt;This is something that does annoy me far more than it should: the differences between GNU and BSD CLI programs. Specifically, GNU programs tend to support both short and long form options (e.g. &lt;code&gt;-h&lt;/code&gt; and &lt;code&gt;--help&lt;/code&gt;) while the FreeBSD
toolchain seems to stubbornly reject this and generally only supports short
options. The output of &lt;code&gt;--help&lt;/code&gt; is often also utterly useless on FreeBSD. Take
the &lt;code&gt;ln --help&lt;/code&gt; command for example, on Fedora it outputs the following:&lt;/p&gt;
    &lt;code&gt;$ ln --help
Usage: ln [OPTION]... [-T] TARGET LINK_NAME
  or:  ln [OPTION]... TARGET
  or:  ln [OPTION]... TARGET... DIRECTORY
  or:  ln [OPTION]... -t DIRECTORY TARGET...
In the 1st form, create a link to TARGET with the name LINK_NAME.
In the 2nd form, create a link to TARGET in the current directory.
In the 3rd and 4th forms, create links to each TARGET in DIRECTORY.
Create hard links by default, symbolic links with --symbolic.
By default, each destination (name of new link) should not already exist.
When creating hard links, each TARGET must exist.  Symbolic links
can hold arbitrary text; if later resolved, a relative link is
interpreted in relation to its parent directory.

[options and a bunch or extra stuff here]
&lt;/code&gt;
    &lt;p&gt;Meanwhile on FreeBSD:&lt;/p&gt;
    &lt;code&gt;$ ln --help
ln: illegal option -- -
usage: ln [-s [-F] | -L | -P] [-f | -i] [-hnv] source_file [target_file]
       ln [-s [-F] | -L | -P] [-f | -i] [-hnv] source_file ... target_dir
&lt;/code&gt;
    &lt;p&gt;Oh OK, I guess doing the sensible thing is too much to ask for so let's just use &lt;code&gt;-h&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ ln -h
usage: ln [-s [-F] | -L | -P] [-f | -i] [-hnv] source_file [target_file]
       ln [-s [-F] | -L | -P] [-f | -i] [-hnv] source_file ... target_dir
&lt;/code&gt;
    &lt;p&gt;What about the manual page? Isn't FreeBSD better in that regard? Well, no: the manual page for &lt;code&gt;ln&lt;/code&gt; on both Fedora and FreeBSD is about the same, except the
GNU version of &lt;code&gt;ln&lt;/code&gt; supports a whole bunch of extra long options that aren't
present on FreeBSD (e.g. &lt;code&gt;--no-target-directory&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Another annoyance is that FreeBSD is more pedantic about the position of options when combined with sub commands. For example, &lt;code&gt;bectl -h create&lt;/code&gt; works
(though it's output is the same as &lt;code&gt;bectl -h&lt;/code&gt;) but &lt;code&gt;bectl create -h&lt;/code&gt; produces an
error, then proceeds to spit out the same output as &lt;code&gt;bectl -h&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Of course you can install GNU coreutils (or the Rust rewrite if you like not having a working system), but then you might as well stick with Linux in the first place.&lt;/p&gt;
    &lt;p&gt;To be honest, I feel the FreeBSD core utilities are a straight up downgrade compared to GNU coreutils. Maybe I'll change my mind over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;ZFS&lt;/head&gt;
    &lt;p&gt;I haven't had the time yet to play around with ZFS beyond creating a new boot environment using &lt;code&gt;bectl&lt;/code&gt;, so I can't comment on ZFS just yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Jails&lt;/head&gt;
    &lt;p&gt;Similar to ZFS I have yet to play with jails. I want to look into bastille specifically since it seems to be the closest to Podman (i.e. it has a concept similar to &lt;code&gt;Dockerfile&lt;/code&gt;/&lt;code&gt;Containerfile&lt;/code&gt; files), but I haven't had a chance yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Profiling&lt;/head&gt;
    &lt;p&gt;This is something I still need to figure out: what is the FreeBSD approved way of profiling userspace applications? On Linux you'd use something like perf to collect your data and hotspot to visualize it, but on FreeBSD it seems there are only a bunch of different rocks you have to bang together yourself.&lt;/p&gt;
    &lt;p&gt;For example, there's dtrace but I haven't been able to figure out how you use it without having to write a bunch of D scripts yourself. There are also some other FreeBSD specific tools such as pmcstat, but I have yet to figure out how to use them.&lt;/p&gt;
    &lt;p&gt;Basically what I want is something like &lt;code&gt;profile-the-damn-thing PROGRAM&lt;/code&gt;
followed by &lt;code&gt;visualize-the-damn-thing DATA&lt;/code&gt; and that's it. If you happen to know
of such a tool, please let me know!&lt;/p&gt;
    &lt;head rend="h2"&gt;The community&lt;/head&gt;
    &lt;p&gt;While not related to the technical merits of FreeBSD, I do feel this is worth mentioning. The FreeBSD community is...difficult. What I mean by this is that it feels much like the average Linux community in the early 2000s: it looks down on others (in this case Linux users), it appears rather unwelcoming and at times downright toxic. Any time you mention anything vaguely related to Linux you'll inevitably cause somebody to go on a massive rant about how FreeBSD is better than Linux.&lt;/p&gt;
    &lt;p&gt;It also seems there's a general dislike for change, even if said change is for the better. It feels like a form of "tech boomerism": change is bad because it's not what we're used to, even if the end result is in fact better.&lt;/p&gt;
    &lt;p&gt;Of course not everybody is like this, but at least the two main community platforms that I know of (the FreeBSD subreddit and the FreeBSD forums) seem to suffer from this problem quite a bit.&lt;/p&gt;
    &lt;p&gt;Solving this results in a bit of a circular problem: for a community to become more mature and less toxic it needs to grow and attract a more diverse pool of members, but this only happens if those wanting to join aren't pushed away in the first place by the behavior of existing members. I don't know how you'd break such a cycle short of having good leadership and a lot of luck.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions thus far&lt;/head&gt;
    &lt;p&gt;Thus far I'm not entirely sure if I'd see myself using FreeBSD, though I'd have to play around with FreeBSD on physical hardware to get a better understanding. For example, I'm curious how well KDE works when installed using the upcoming FreeBSD 15 installer (I'd use GNOME but due to its systemd dependency it's unlikely to keep working on FreeBSD in the future). I'm also curious about how well the Framework laptop is supported.&lt;/p&gt;
    &lt;p&gt;Besides that there is a bigger question that I need to answer for myself: given the quirks of FreeBSD, what actually would the benefit of using it be? Sure there's ZFS, but Linux has Btrfs (and technically you can also use ZFS on Linux, even if it's painful). Sure, the FreeBSD kernel and userspace are part of the same project, but does that matter if the kernel doesn't necessarily perform better or faster and the userspace is subpar compared to that of Linux? Sure, FreeBSD may use fewer resources but does that matter if your WiFi card isn't supported?&lt;/p&gt;
    &lt;p&gt;The only way to answer these questions is to give FreeBSD a try on my Framework laptop when it arrives later this year, at which point I'll write a follow-up article to share my thoughts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yorickpeterse.com/articles/a-brief-look-at-freebsd/"/><published>2025-11-12T12:10:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45900108</id><title>Micro.blog launches new 'Studio' tier with video hosting</title><updated>2025-11-12T23:10:16.580082+00:00</updated><content>&lt;doc fingerprint="b4db0e54e8a9e6f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Micro.blog offers an indie alternative to YouTube with its ‚ÄòStudio‚Äô video hosting plan&lt;/head&gt;
    &lt;p&gt;The core of Micro.blog‚Äôs mission is to make it easy for people to own their presence on the web. At first, it was a simple blog host that also incorporated a Twitter-like social timeline that put short (title-less) and long (titled) posts on equal footing. In the years since its 2017 launch, Manton Reece ‚Äî Micro.blog‚Äôs founder ‚Äî has added a plethora of features that expand upon that mission. Here‚Äôs a list off the top of my head:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hosting podcasts&lt;/item&gt;
      &lt;item&gt;Bookmarking/archiving webpages&lt;/item&gt;
      &lt;item&gt;Fediverse compatibility with native replies to Mastodon and novel reply gathering from Bluesky&lt;/item&gt;
      &lt;item&gt;Crossposting to other social networks&lt;/item&gt;
      &lt;item&gt;Photo blogging&lt;/item&gt;
      &lt;item&gt;Custom domain name registration&lt;/item&gt;
      &lt;item&gt;Private notes&lt;/item&gt;
      &lt;item&gt;Book/Movie/TV Show blogging&lt;/item&gt;
      &lt;item&gt;Reading tracking&lt;/item&gt;
      &lt;item&gt;Automatic newsletters&lt;/item&gt;
      &lt;item&gt;Open APIs to manage your content&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of this is hosted on your own website, (optionally, but strongly encouraged) at your own domain name. I‚Äôve never seen anything else like it.&lt;/p&gt;
    &lt;p&gt;There are plans ranging from $1/month to $15/month that include subsets of these features, depending on how much a blogging ‚Äúpower user‚Äù you are.&lt;/p&gt;
    &lt;p&gt;Reece‚Äôs next1 big foray with Micro.blog: video hosting, which launched yesterday.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Micro.blog Studio adds longer video hosting for your blog, with uploads up to 20 minutes. You can read some of the technical bits here. It can automatically copy videos to PeerTube and Bluesky too.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That‚Äôs a quaint description for what promises to be a significant challenge.2 Because if hosting videos were easy, YouTube wouldn‚Äôt be the only3 game in town. And that‚Äôs exactly why Reece has pursued it. It‚Äôs not good for the open web for so much of its video content to live centralized at one host. John Gruber lamented this following Jimmy Kimmel‚Äôs suspension:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The big problem is YouTube. With YouTube, Google has a centralized chokehold on video. We need a way that‚Äôs as easy and scalable to host video content, independently, as it is for written content. I don‚Äôt know what the answer to that is, technically, but we ought to start working on it with urgency.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just like Micro.blog encourages people to own their text, reading lists, podcasts, photos, and social network interactions at their own domain, that ethos now extends to videos too.&lt;/p&gt;
    &lt;p&gt;One of the great things about Micro.blog is how it enables the Publish to Own Site, Syndicate Elsewhere (POSSE) framework. That‚Äôs manifested in features like its automatic crossposting to Bluesky, Flickr, LinkedIn, Mastodon, Medium, Nostr, Pixelfed, Threads, and Tumblr. And manual crossposting elsewhere. This allows the ‚Äúsource of truth‚Äù to be at your own website that you control, but you won‚Äôt miss out on conversations and audiences in other places. With expanded video hosting, Reece has added PeerTube as another automatic crossposting destination, and hopes to also enable YouTube if and when Google approves his application. It‚Äôs not about only posting to your website, but instead centralizing your website as the first and primary place you post and then getting your text, images, audio, and now video out to other networks from there.&lt;/p&gt;
    &lt;p&gt;As you can probably tell, I‚Äôm pretty excited about Micro.blog taking on the challenge of being that ‚Äôindie-focused, YouTube alternative‚Äù that Reece envisioned. I haven‚Äôt upgraded my plan yet, but only because I mainly post shorter videos (covered by my current ‚ÄòPremium‚Äô plan), but I‚Äôm very glad it now exists as an option.&lt;/p&gt;
    &lt;p&gt;There‚Äôs never been a better time to own your spot on the web. If you haven‚Äôt checked out Micro.blog before, I think it‚Äôs a compelling place to look.&lt;/p&gt;
    &lt;p&gt;Update 2025-11-11: I was in a hurry when I posted this earlier, and it slipped my mind to include some wants and wishes that I have for Micro.blog‚Äôs video hosting capabilities. It‚Äôs a short list, due to both Reece‚Äôs solid offering from the outset, and my lack of imagination. üòÜ&lt;/p&gt;
    &lt;p&gt;Scale time limits across the tiers. I really think video hosting would be a stronger offering if it were available more consistently across Micro.blog‚Äôs tiers. For example, 1-minute videos at $5/month, 5-minute videos at $10/month, 10-minute videos at $15/month, and 20-minute videos at $20/month. All with the same capabilities, but limited by length.&lt;/p&gt;
    &lt;p&gt;This was something that I know Reece considered, but ultimately decided against in the name of simplicity. He didn‚Äôt want to muck up the existing plans, and (rightly) considers them a tremendous value with their current features. He obviously hopes that people will upgrade to the higher-priced Studio plan specifically for the new video stuff.&lt;/p&gt;
    &lt;p&gt;But I think tying some video features (multiple resolutions and fast playback on your blog) to the 20-minute time limit and $20 plan creates more confusion, a feature gap, and missed opportunity. Take me for example. I think I could reasonably say that I‚Äôm a Micro.blog power user. But even I‚Äôm not sure if I‚Äôm correct in saying that those unique features are limited to the Studio plan. I know everyone gets video uploads up to 1 minute in length. (Maybe not everyone, though. Does Micro.one users at $1/month get the ‚Äúnew‚Äù video features? I‚Äôm not sure.&lt;/p&gt;
    &lt;p&gt;Historically, most of the videos I post are around 90 seconds in length. I‚Äôm far more likely to shave 30 seconds off my videos to fit a 1-minute time limit than I am to double my monthly cost to show those extra 30 seconds. There‚Äôs too big a gap between 1-minute videos and 20-minute videos to make it seem worthwhile. In my mind, I‚Äôd be ‚Äúwasting‚Äù the extra $10/month ($120/year) by not posting 20-minute videos. But I‚Äôd be more likely to pay a little extra money for a little extra time. And then if I started hitting that new limit, I‚Äôd feel incentivized and validated graduating up to the next tier. I worry that Reece will see more infrastructure cost with a bunch of 1-minute videos being uploaded and served, but won‚Äôt see an accompanying bump in revenue, since we‚Äôre all getting the 1-minute videos for ‚Äúfree, and I don‚Äôt see a significant portion of Micro.blog users needing the 20-minutes.&lt;/p&gt;
    &lt;p&gt;Said one more way, I think giving people a little headroom to grow into hosting their videos on Micro.blog will make them more likely to upgrade over time. Once that habit has solidified, and users are comfortable with it, paying $5 more for the next jump in time limit isn‚Äôt a big ask. But jumping right into the Studio plan for $10-$15 extra is kind of off-putting. The gap between 1 minute and 20 is just too big.&lt;/p&gt;
    &lt;p&gt;Support 4K resolution. A pie-in-the-sky request, I know. 4K videos are huge. But I can nearly always see the difference, and choose higher quality playback every time. I‚Äôd love for my videos to appear at full-quality if they‚Äôre uploaded that way.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;To be clear, Micro.blog has had the ability to host videos ‚Äî or nearly any other kind of file upload ‚Äî and show them on your blog for years. But it‚Äôs been limited by file size, not an optimized part of the offering. The Studio tier makes it a first-rate feature, with smooth playback, automatic conversion to multiple resolutions, and ups the limit to a healthy 20 minutes no matter the file size. And the old file size-limited video uploads should still work for folks who rely on that workflow. üëå‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Sure, Vimeo exists, but it‚Äôs expensive and limited, and it‚Äôs future is uncertain. Plus, you‚Äôre still posting to a&lt;/p&gt;&lt;code&gt;vimeo.com&lt;/code&gt;domain. And, of course, many people post videos to Instagram, Facebook, TikTok, X, and other social networks. But I‚Äôd argue that videos there serve the algorithm first and users second. Micro.blog‚Äôs Studio tier flips that. It‚Äôs meant to serve the user first, and there is no algorithm at all.‚Ü©Ô∏é&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://heydingus.net/blog/2025/11/micro-blog-offers-an-indie-alternative-to-youtube-with-its-studio-video-hosting-plan"/><published>2025-11-12T13:46:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45900370</id><title>Fighting the New York Times' invasion of user privacy</title><updated>2025-11-12T23:10:16.355652+00:00</updated><content>&lt;doc fingerprint="941e81541c87d3a5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fighting the New York Times‚Äô invasion of user privacy&lt;/head&gt;
    &lt;p&gt;Trust, security, and privacy guide every product and decision we make.&lt;/p&gt;
    &lt;p&gt;Each week, 800 million people use ChatGPT to think, learn, create, and handle some of the most personal parts of their lives. People entrust us with sensitive conversations, files, credentials, memories, searches, payment information, and AI agents that act on their behalf. We treat this data as among the most sensitive information in your digital life‚Äîand we‚Äôre building our privacy and security protections to match that responsibility.&lt;/p&gt;
    &lt;p&gt;Today, that responsibility is being tested.&lt;/p&gt;
    &lt;p&gt;The New York Times is demanding that we turn over 20 million of your private ChatGPT conversations. They claim they might find examples of you using ChatGPT to try to get around their paywall.&lt;/p&gt;
    &lt;p&gt;This demand disregards long-standing privacy protections, breaks with common-sense security practices, and would force us to turn over tens of millions of highly personal conversations from people who have no connection to the Times‚Äô baseless lawsuit against OpenAI.&lt;/p&gt;
    &lt;p&gt;They have tried this before. Originally, the Times wanted you to lose the ability to delete your private chats. We fought that and restored your right to remove them. Then they demanded we turn over 1.4 billion of your private ChatGPT conversations. We pushed back, and we‚Äôre pushing back again now. Your private conversations are yours‚Äîand they should not become collateral in a dispute over online content access.&lt;/p&gt;
    &lt;p&gt;We respect strong, independent journalism and partner with many publishers and newsrooms. Journalism has historically played a critical role in defending people‚Äôs right to privacy throughout the world. However, this demand from the New York Times does not live up to that legacy, and we‚Äôre asking the court to reject it. We will continue to explore every option available to protect our users‚Äô privacy.&lt;/p&gt;
    &lt;p&gt;We are accelerating our security and privacy roadmap to protect your data. OpenAI is one of the most targeted organizations in the world. We have invested significant time and resources building systems to prevent unauthorized access to your data by adversaries ranging from organized criminal groups to state-sponsored intelligence services.&lt;/p&gt;
    &lt;p&gt;However, if the Times succeeds in its demand, we will be forced to hand over the very same data we‚Äôre protecting‚Äîyour data‚Äîto third parties, including the Times‚Äô lawyers and paid consultants.&lt;/p&gt;
    &lt;p&gt;Our long-term roadmap includes advanced security features designed to keep your data private, including client-side encryption for your messages with ChatGPT. We believe these features will help keep your private conversations private and inaccessible to anyone else, even OpenAI. We will build fully automated systems to detect safety issues in our products. Only serious misuse and critical risks‚Äîsuch as threats to someone‚Äôs life, plans to harm others, or cybersecurity threats‚Äîmay ever be escalated to a small, highly vetted team of human reviewers. These security features are in active development and we will share more details about them, and other short-term mitigations, in the very near future.&lt;/p&gt;
    &lt;p&gt;The privacy and security protections must become more powerful as AI becomes more deeply integrated into people‚Äôs lives. We are committed to a future where you can trust that your most personal AI conversations are safe, secure, and truly private.&lt;/p&gt;
    &lt;p&gt;‚ÄîDane Stuckey, Chief Information Security Officer, OpenAI&lt;/p&gt;
    &lt;p&gt;Why are The New York Times and other plaintiffs demanding this?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The New York Times is suing OpenAI. As part of their baseless lawsuit, they‚Äôve demanded the court to force us to hand over 20 million user conversations. This would allow them to access millions of user conversations that are unrelated to the case.&lt;/item&gt;
      &lt;item&gt;We strongly believe this is an overreach. It risks your privacy without actually helping resolve the lawsuit. That‚Äôs why we‚Äôre fighting it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What led to this stage of the process?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Times‚Äô lawyers argued to the court that their request should be granted, in part because another AI company previously agreed to hand over 5 million private chats of their users in an unrelated court case.&lt;/item&gt;
      &lt;item&gt;We strongly disagree that this is relevant to our case and we‚Äôre continuing to appeal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Did you offer any other solutions to the Times?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We presented several privacy-preserving options to The Times, including targeted searches over the sample (e.g., to search for chats that might include text from a New York Times article so they only receive the conversations relevant to their claims), as well as high-level data classifying how ChatGPT was used in the sample.&lt;/item&gt;
      &lt;item&gt;These were rejected by The Times.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Is the NYT obligated to keep this data private?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yes. The Times would be legally obligated at this time to not make any data public outside the court process. That said, if the Times continues to push to access it in any way that will make the conversations public, we will fight to protect your privacy at every step.&lt;/item&gt;
      &lt;item&gt;The Times‚Äô original request in this lawsuit was also much broader. It initially demanded 1.4 billion private ChatGPT conversations, which we successfully pushed back on through the legal process. That presented red flags to us that suggested this was not a thoughtful or genuinely necessary request.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How are these 20 million chats selected?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 20 million user conversations were randomly sampled from Dec. 2022 to Nov. 2024.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Is my data potentially impacted?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This data includes a random sampling of consumer ChatGPT conversations from Dec. 2022 to Nov. 2024.&lt;/item&gt;
      &lt;item&gt;Conversations outside of this time window are not potentially impacted.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Are business customers potentially impacted?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This does not impact ChatGPT Enterprise, ChatGPT Edu, ChatGPT Business (formerly ‚ÄúTeam‚Äù) customers, or API customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What are you doing to protect my personal information and privacy?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We are taking all affected chats and running them through a de-identifying procedure to remove or ‚Äúscrub‚Äù personal identifying information (or ‚ÄúPII‚Äù) and other information (e.g., passwords or other sensitive information) from these conversations.&lt;/item&gt;
      &lt;item&gt;We would also push to only allow the Times to view this data in a secure environment maintained under strict legal protocols.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How will you store this data?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The content covered by the court order is currently stored separately in a secure system. It‚Äôs protected under legal hold, meaning it can‚Äôt be accessed or used for purposes other than meeting legal obligations.&lt;/item&gt;
      &lt;item&gt;Only a small, audited OpenAI legal and security team would be able to access this data as necessary to comply with our legal obligations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Who will be able to access this data?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Times‚Äô outside counsel attorneys of record in the case and their hired technical consultants would be able to access the conversations. We will push to only allow The Times to view this data in a secured environment maintained under strict legal protocols.&lt;/item&gt;
      &lt;item&gt;If The Times continues to push to access it in any way that will make the conversations public, we will fight to protect your privacy at every step.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Does this court order violate GDPR or my rights under European or other privacy laws?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We are taking steps to comply at this time because we must follow the law, but The New York Times‚Äô demand does not align with our privacy standards. That is why we‚Äôre challenging it.&lt;/item&gt;
      &lt;item&gt;As mentioned, we‚Äôve taken additional steps to protect your privacy, such as de-identifying data and removing personally identifiable information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Will you keep us updated?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yes. We‚Äôre committed to transparency and will keep you informed. We‚Äôll share meaningful updates, including any changes to the order or how it affects your data.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/fighting-nyt-user-privacy-invasion"/><published>2025-11-12T14:08:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45900978</id><title>Learn Prolog Now</title><updated>2025-11-12T23:10:15.828814+00:00</updated><content>&lt;doc fingerprint="4d56f3b1a1661f95"&gt;
  &lt;main&gt;
    &lt;p&gt;Learn Prolog Now! is an introductory course to programming in Prolog. The online version has been available since 2001, and now there is also a throughly revised version available in book form.&lt;/p&gt;
    &lt;p&gt;We wanted to do two things with this course. First, we wanted to provide a text that was relatively self contained, a text that would permit someone with little or no knowledge of computing to pick up the basics of Prolog with the minimum of fuss. We also wanted the text to be clear enough to make it useful for self study. We believe that if you read the text, and do the associated exercises, you will gain a useful partial entry to the world of Prolog.&lt;/p&gt;
    &lt;p&gt;But only a partial entry, and this brings us to our second point. We want to emphasize the practical aspects of Prolog. Prolog is something you do. You can't learn a programming language simply by reading about it, and if you really want to get the most out of this course, we strongly advise you to get hold of a Prolog interpreter (you'll find pointers to some nice ones on this website) and work through all the Practical Sessions that we provide. And of course, don't stop with what we provide. The more you program, the better you'll get....&lt;/p&gt;
    &lt;p&gt;We hope you enjoy the course. And whether you're using this book to teach yourself Prolog, or you're using it as the basis for teaching others, we would like to hear from you. Please send us any comments/corrections you have so that we can take them into account in later versions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lpn.swi-prolog.org/lpnpage.php?pageid=top"/><published>2025-11-12T14:54:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45901855</id><title>Waymo robotaxis are now giving rides on freeways in LA, SF and Phoenix</title><updated>2025-11-12T23:10:15.741214+00:00</updated><content>&lt;doc fingerprint="ee28c00b2634fced"&gt;
  &lt;main&gt;
    &lt;p&gt;Sixteen years ago, engineers working on the Google self-driving project conducted their first autonomous vehicle tests on the freeway that connects Silicon Valley to San Francisco.&lt;/p&gt;
    &lt;p&gt;The company would eventually become Waymo, autonomous vehicle testing would expand ‚Äî fanning out to other cities. Eventually, the company launched commercial robotaxi services in Phoenix, San Francisco, and Los Angeles. Other cities soon followed.&lt;/p&gt;
    &lt;p&gt;But freeways, despite some of that early testing, would remain out of reach. Until today.&lt;/p&gt;
    &lt;p&gt;Waymo said Wednesday it will begin offering robotaxi rides that use freeways across San Francisco, Phoenix, and Los Angeles, a critical expansion for the company that it says will reduce ride times by up to 50%. That stat could help attract a whole new group of users who need to travel between the many towns and suburbs within the greater San Francisco Bay Area or quicken commutes across the sprawling Los Angeles and Phoenix metro areas.&lt;/p&gt;
    &lt;p&gt;Using freeways is also essential for Waymo to offer rides to and from the San Francisco Airport, a location the company is currently testing in.&lt;/p&gt;
    &lt;p&gt;The service won‚Äôt be offered to all Waymo riders at first, the company said. Waymo riders who want to experience freeway rides can note their preference in the Waymo app. Once the rider hails a ride, they may be matched with a freeway trip, according to the company.&lt;/p&gt;
    &lt;p&gt;The company‚Äôs robotaxi routes will now stretch to San Jose, an expansion that will create a unified 260-mile service area across the Peninsula, according to Waymo. The company said it will also begin curbside drop off and pick up service at the San Jose Mineta International Airport. It already offers curbside service to the Sky Harbor Phoenix International Airport.&lt;/p&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages ‚Äî part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages ‚Äî part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;p&gt;‚ÄúFreeway driving is one of those things that‚Äôs very easy to learn, but very hard to master when we‚Äôre talking about full autonomy without a human driver as a backup, and at scale,‚Äù Waymo co-CEO Dmitri Dolgov said in a media briefing with reporters. ‚ÄúIt took time to do it properly, with a strong focus on system safety and reliability.‚Äù&lt;/p&gt;
    &lt;p&gt;Waymo robotaxis have been spotted on freeways for months. TechCrunch took a test ride last year in the Phoenix area that included freeways. The company has provided trips to employees for more than a year. It also expanded testing to include closed course and simulation&lt;/p&gt;
    &lt;p&gt;While many assume freeway driving is easier, it comes with its own set of challenges, principal software engineer Pierre Kreitmann said in a recent briefing. He noted that critical events happen less often on freeways, which means there are fewer opportunities to expose Waymo‚Äôs self-driving system to rare scenarios and prove how the system performs when it really matters. The company chose to augment its public road driving with a combination of closed course and simulation testing.&lt;/p&gt;
    &lt;p&gt;This expanded testing and validation of the software was done to ensure the vehicles transition smoothly and safely between freeways and surface streets, and recognize and adapt to the unique context of the road around them, Kreitman said.&lt;/p&gt;
    &lt;p&gt;Waymo has also expanded its operational protocols, including how it coordinates with safety officials like California Highway Patrol, now that its robotaxis are on freeways.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2025/11/12/waymo-robotaxis-are-now-giving-rides-on-freeways-in-these-3-cities/"/><published>2025-11-12T16:06:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45901904</id><title>The last-ever penny will be minted today in Philadelphia</title><updated>2025-11-12T23:10:15.515603+00:00</updated><content>&lt;doc fingerprint="4ea09c6c6896a7e7"&gt;
  &lt;main&gt;
    &lt;p&gt;The American penny passed away today after a prolonged illness. It was 238 years old.&lt;/p&gt;
    &lt;p&gt;The last penny was minted Wednesday afternoon at the US Mint in Philadelphia, overseen by US Treasurer Brandon Beach. President Donald Trump announced via social media in February that he instructed the Mint to stop making the once-popular coin, citing the cost of production.&lt;/p&gt;
    &lt;p&gt;The penny costs nearly four cents to mint, more than the coin‚Äôs worth. Once valuable enough to buy ‚Äúpenny candy‚Äù like gumballs and feed parking meters or toll booths, today the penny lives mostly in coin jars, junk drawers or ‚Äúleave a penny/take a penny‚Äù trays.&lt;/p&gt;
    &lt;p&gt;Beach said Wednesday that the final coins pressed will be auctioned off and that the actual last pennies put into circulation from the US Mint were struck in June.&lt;/p&gt;
    &lt;p&gt;The penny outlived its sibling, the half-penny, by 168 years. It‚Äôs survived by the nickel, dime, quarter, and rarely seen half-dollar and dollar coins.&lt;/p&gt;
    &lt;p&gt;Despite its demise, the penny will remain legal tender.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problems despite long planned end&lt;/head&gt;
    &lt;p&gt;For a coin that seems obsolete, its removal from circulation is causing more problems than expected, especially for retailers.&lt;/p&gt;
    &lt;p&gt;Some merchants plan to round prices to the nearest nickel, often a penny or two more. Others are asking customers to pay with pennies to help supply. But in some states, merchants could face legal trouble for rounding up or down.&lt;/p&gt;
    &lt;p&gt;Additionally, any savings from discontinuing the one-cent coin could be offset by the need to press more nickels, which costs the US Mint more money than the penny.&lt;/p&gt;
    &lt;p&gt;The government‚Äôs phasing out of the penny has been ‚Äúa bit chaotic,‚Äù said Mark Weller, executive director of Americans for Common Cents. The pro-penny group is funded primarily by Artazn, the company that provides the blanks used to make pennies. ‚ÄúBy the time we reach Christmas, the problems will be more pronounced with retailers not having pennies.‚Äù&lt;/p&gt;
    &lt;p&gt;Weller said other countries that removed low denomination coins, like Canada, Australia and Switzerland, had guidance for afterwards. Not so in the United States.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe had a social media post (by Trump) during Super Bowl Sunday, but no real plan for what retailers would have to do,‚Äù he said, referring to the president‚Äôs February announcement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Different rounding plans&lt;/head&gt;
    &lt;p&gt;Kwik Trip, a family-owned convenience store chain that operates in the Midwest, decided to round down cash purchases in stores where it hasn‚Äôt been able to find pennies.&lt;/p&gt;
    &lt;p&gt;‚ÄúThere‚Äôs no way that we wanted to charge (customers) an extra 2 cents because we just didn‚Äôt think that was fair,‚Äù said John McHugh, spokesperson for the company. ‚ÄúI mean, it‚Äôs not their fault that there there‚Äôs a penny shortage.‚Äù&lt;/p&gt;
    &lt;p&gt;But with 20 million customers a year, and 17% of them paying with cash, the policy will eventually cost Kwik Trip a couple of million dollars a year, McHugh said.&lt;/p&gt;
    &lt;p&gt;It‚Äôs not just businesses that face increased costs. Rounding to the closest nickel will cost consumers about $6 million a year, according to a July study by the Federal Reserve Bank of Richmond. That is fairly modest, coming to about five cents each across 133 million American households.&lt;/p&gt;
    &lt;p&gt;And rounding is not a national solution.&lt;/p&gt;
    &lt;p&gt;Four states - Delaware, Connecticut, Michigan and Oregon - as well as numerous cities, including New York, Philadelphia, Miami and Washington, DC, require merchants to provide exact change, according to the National Association of Convenience Stores (NACS).&lt;/p&gt;
    &lt;p&gt;In addition, the law covering the federal food assistance program known as SNAP requires that recipients not be charged more than other customers. Since SNAP recipients use a debit card that‚Äôs charged the precise amount, if merchants round down prices for cash purchases, they could be opening themselves to legal problems and fines, said Jeff Lenard, spokesperson for NACS.&lt;/p&gt;
    &lt;p&gt;‚ÄúRounding down on all transactions presents several challenges beyond the loss of an average of 2 cents per transaction,‚Äù Lenard said. ‚ÄúWe desperately need legislation that allows rounding so retailers can make change for these customers.‚Äù&lt;/p&gt;
    &lt;p&gt;For that reason, NACS and other retail groups recently wrote to Congress asking for legislation to deal with the questions raised by the end of penny production.&lt;/p&gt;
    &lt;head rend="h2"&gt;End of a ‚Äòwonderful life‚Äô&lt;/head&gt;
    &lt;p&gt;The penny was one of the nation‚Äôs first coins, first minted in 1787, six years before the Mint itself was established.&lt;/p&gt;
    &lt;p&gt;Benjamin Franklin is widely credited with designing the first penny known as the Fugio cent. Its current form arrived in 1909 on the centennial of Abraham Lincoln‚Äôs birth, when it became the first American coin to feature a president.&lt;/p&gt;
    &lt;p&gt;But it has declined in both use and popularity ever since. The Treasury Department now says there are an estimated 300 billion pennies in circulation. That comes to a bit less than $9 for every American. But most of those coins are ‚Äúseverely underutilized.‚Äù So, outcry from the public over its demise has been muted.&lt;/p&gt;
    &lt;p&gt;Joe Ditler, a 74-year old writer and historian from Colorado, said he still has an old cigar box filled with mostly pennies given to him by his grandfather. He remembers flattening pennies on railroad tracks or souvenir machines in amusement parks.&lt;/p&gt;
    &lt;p&gt;However, he only occasionally uses pennies to make a cash purchase. And he often tosses the one-cent coin in the tip jar.&lt;/p&gt;
    &lt;p&gt;‚ÄúThey bring back memories that have stayed with me all my life,‚Äù he said. ‚ÄúThe penny has had a wonderful life. But it‚Äôs probably time for it to go away.‚Äù&lt;/p&gt;
    &lt;p&gt;-CNN‚Äôs Danny Freeman contributed to this report&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnn.com/2025/11/12/business/last-penny-minted"/><published>2025-11-12T16:10:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45902898</id><title>Project Euler</title><updated>2025-11-12T23:10:15.107438+00:00</updated><content>&lt;doc fingerprint="8638e1d922bae329"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;About Project Euler&lt;/head&gt;
    &lt;head rend="h3"&gt;What is Project Euler?&lt;/head&gt;
    &lt;p&gt;Project Euler is a series of challenging mathematical/computer programming problems that will require more than just mathematical insights to solve. Although mathematics will help you arrive at elegant and efficient methods, the use of a computer and programming skills will be required to solve most problems.&lt;lb/&gt; The motivation for starting Project Euler, and its continuation, is to provide a platform for the inquiring mind to delve into unfamiliar areas and learn new concepts in a fun and recreational context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Who are the problems aimed at?&lt;/head&gt;
    &lt;p&gt;The intended audience include students for whom the basic curriculum is not feeding their hunger to learn, adults whose background was not primarily mathematics but had an interest in things mathematical, and professionals who want to keep their problem solving and mathematics on the cutting edge.&lt;/p&gt;
    &lt;p&gt;Currently we have 1364972 registered members who have solved at least one problem, representing 220 locations throughout the world, and collectively using 113 different programming languages to solve the problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can anyone solve the problems?&lt;/head&gt;
    &lt;p&gt;The problems range in difficulty and for many the experience is inductive chain learning. That is, by solving one problem it will expose you to a new concept that may allow you to undertake a previously inaccessible problem. So determined participants will be able to slowly but surely work their way through the problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;What next?&lt;/head&gt;
    &lt;p&gt;In order to track your progress it is necessary to setup an account and have Cookies enabled.&lt;/p&gt;
    &lt;p&gt;If you already have an account, then Sign In. Otherwise, please Register ‚Äì it's completely free!&lt;/p&gt;
    &lt;p&gt;However, as the problems are challenging, you may wish to view the Problems before registering.&lt;/p&gt;
    &lt;p&gt;"Project Euler exists to encourage, challenge, and develop the skills and enjoyment of anyone with an interest in the fascinating world of mathematics."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://projecteuler.net"/><published>2025-11-12T17:24:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45903161</id><title>Launch HN: JSX Tool (YC F25) ‚Äì A Browser Dev-Panel IDE for React</title><updated>2025-11-12T23:10:14.669231+00:00</updated><content>&lt;doc fingerprint="ae4ab77c7123cd5c"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, We‚Äôre Jamie &amp;amp; Dan, building JSX Tool (&lt;/p&gt;https://jsxtool.com&lt;p&gt;) a new inspector/dev panel IDE that allows you to navigate to any line of your React project‚Äôs JSX with just a click and a command click to explore your render stack.&lt;/p&gt;&lt;p&gt;Demo video: https://www.youtube.com/watch?v=JIIXvN7vhrs&lt;/p&gt;&lt;p&gt;I‚Äôve been writing React code for nearly a decade. Since I first saw source maps in the days of Babel and Redux, I‚Äôve always wanted to be able to edit my code from the source maps. I‚Äôve also always wanted to be able to inspect my JSX like it was HTML.&lt;/p&gt;&lt;p&gt;Last year, I found my first real use of AI was taking ad-hoc CSS changes in the Chrome element inspector, pasting them into ChatGPT, and asking for the equivalent in Tailwind. I‚Äôd then paste those changes into my React TSX files.&lt;/p&gt;&lt;p&gt;I wanted to streamline this process but came to the conclusion that to do so I needed to build a JSX inspector. I had to write a custom AST parser to create a mapping between the JSX and HTML. So I hacked on an inspector for a couple of months that connected JSX to the DOM in both directions.&lt;/p&gt;&lt;p&gt;The next feature was adding a CSS editor, like the one in the browser inspectors but for JSX. Unlike styling a piece of HTML I decided that any in memory style edits to a React fiber should be globally applied, as if you had tweaked that line of code in your codebase.&lt;/p&gt;&lt;p&gt;Finally, I was able to add the two AI features I really wanted: (1) prompt for in-memory styles for when I was pixel tweaking, and (2) save those temporary changes back to my codebase in the convention of the codebase I was working in.&lt;/p&gt;&lt;p&gt;To accomplish talking to the filesystem from the Chrome extension I built a little local server that mounts from the root of your project and allows the extension to send file-system commands back to your project root. We named this the ‚ÄúDev Server‚Äù. (Note: You can fully use us as a JSX inspector without this server installed.)&lt;/p&gt;&lt;p&gt;After all that, I found that to convert myself as a user I needed it to be a pretty fully functional IDE. I needed vim bindings, I needed a typechecker, I needed auto-complete, I needed a linter, I needed code search and I needed a proper file explorer. Fortunately we were able to take advantage of the dev-server architecture we had stumbled onto in order to add an LSP server and Rip Grep. At this point, after months of dog fooding, I use JSX Tool for almost all of my website edits.&lt;/p&gt;&lt;p&gt;We‚Äôre still rough around the edges for mobile but we‚Äôre working on that.&lt;/p&gt;&lt;p&gt;All of the IDE stuff not involving AI is free and works fine without AI. We let you get a taste of the prompting stuff for free but apply some rate limits.&lt;/p&gt;&lt;p&gt;The extension itself is not open source but the dev server with the LSP is. It‚Äôs a great foundation if you want to build any sort of in-browser IDE and it's nearly React agnostic. Building the dev server was a big undertaking so I‚Äôd love to see someone fork it and find value in it.&lt;/p&gt;&lt;p&gt;In the future we want to start adding things that we are in a position to take advantage of over something like Cursor, such as letting AI give you code suggestions for runtime exceptions or work with the network logs. We think that the convenience of having your IDE in the dev panel gives us a leg up in convenience and workflow context.&lt;/p&gt;&lt;p&gt;Anyway, regardless of how you feel about AI coding, I wanted to make something that was useful with or without AI. We‚Äôd love it if you gave it a spin and we want to share anything we can about the technical side of the product that you might find interesting.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45903161"/><published>2025-11-12T17:43:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45903325</id><title>Steam Frame</title><updated>2025-11-12T23:10:14.137864+00:00</updated><content>&lt;doc fingerprint="97fc7fa59f8fbace"&gt;
  &lt;main&gt;&lt;p&gt; Install Steam &lt;/p&gt; login | language &lt;p&gt; ÁÆÄ‰Ωì‰∏≠Êñá (Simplified Chinese) ÁπÅÈ´î‰∏≠Êñá (Traditional Chinese) Êó•Êú¨Ë™û (Japanese) ÌïúÍµ≠Ïñ¥ (Korean) ‡πÑ‡∏ó‡∏¢ (Thai) –ë—ä–ª–≥–∞—Ä—Å–∫–∏ (Bulgarian) ƒåe≈°tina (Czech) Dansk (Danish) Deutsch (German) Espa√±ol - Espa√±a (Spanish - Spain) Espa√±ol - Latinoam√©rica (Spanish - Latin America) ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ (Greek) Fran√ßais (French) Italiano (Italian) Bahasa Indonesia (Indonesian) Magyar (Hungarian) Nederlands (Dutch) Norsk (Norwegian) Polski (Polish) Portugu√™s (Portuguese - Portugal) Portugu√™s - Brasil (Portuguese - Brazil) Rom√¢nƒÉ (Romanian) –†—É—Å—Å–∫–∏–π (Russian) Suomi (Finnish) Svenska (Swedish) T√ºrk√ße (Turkish) Ti·∫øng Vi·ªát (Vietnamese) –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ (Ukrainian) Report a translation problem &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://store.steampowered.com/sale/steamframe"/><published>2025-11-12T17:54:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45903404</id><title>Steam Machine</title><updated>2025-11-12T23:10:13.476183+00:00</updated><content>&lt;doc fingerprint="97fc7fa59f8fbace"&gt;
  &lt;main&gt;&lt;p&gt; Install Steam &lt;/p&gt; login | language &lt;p&gt; ÁÆÄ‰Ωì‰∏≠Êñá (Simplified Chinese) ÁπÅÈ´î‰∏≠Êñá (Traditional Chinese) Êó•Êú¨Ë™û (Japanese) ÌïúÍµ≠Ïñ¥ (Korean) ‡πÑ‡∏ó‡∏¢ (Thai) –ë—ä–ª–≥–∞—Ä—Å–∫–∏ (Bulgarian) ƒåe≈°tina (Czech) Dansk (Danish) Deutsch (German) Espa√±ol - Espa√±a (Spanish - Spain) Espa√±ol - Latinoam√©rica (Spanish - Latin America) ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ (Greek) Fran√ßais (French) Italiano (Italian) Bahasa Indonesia (Indonesian) Magyar (Hungarian) Nederlands (Dutch) Norsk (Norwegian) Polski (Polish) Portugu√™s (Portuguese - Portugal) Portugu√™s - Brasil (Portuguese - Brazil) Rom√¢nƒÉ (Romanian) –†—É—Å—Å–∫–∏–π (Russian) Suomi (Finnish) Svenska (Swedish) T√ºrk√ße (Turkish) Ti·∫øng Vi·ªát (Vietnamese) –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ (Ukrainian) Report a translation problem &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://store.steampowered.com/sale/steammachine"/><published>2025-11-12T17:59:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45903586</id><title>Async and Finaliser Deadlocks</title><updated>2025-11-12T23:10:13.014574+00:00</updated><content>&lt;doc fingerprint="f6fc9bd664a397fc"&gt;
  &lt;main&gt;
    &lt;p&gt;Two days ago I was listening to the Oxide podcast on futurelocks, a very complicated bug involving async code in Rust. I must admit that I struggled to understand what was going on, partly because of the subject matter, and partly because podcasts are my backdrop to household chores1. At some point towards the end, though, someone phrased things in a way that my pea brain could immediately understand.&lt;/p&gt;
    &lt;p&gt;In essence, I think futurelocks are a complex instance of a long-standing problem with (what I will call for now) asynchronous code. You may notice that I did not say a √¢well known√¢ problem. Personally, I only realised this problem exists a couple of years ago. For better or worse, subsequent discussions with many other folk have convinced me that my lack of awareness is common.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deadlocking finalisers&lt;/head&gt;
    &lt;p&gt;Helpfully, Oxide have a thoughtful writeup of the futurelock problem. However, even though I like to flatter myself that I√¢m a competent Rust programmer, I had to work hard to understand precisely what√¢s going on.&lt;/p&gt;
    &lt;p&gt;Fortunately we can create a simplified version of the underlying problem in Python:&lt;/p&gt;
    &lt;quote&gt;import threading mutex = threading.Lock() class T: def __del__(self): print("acquiring") mutex.acquire() print("acquired") mutex.release() t = T() mutex.acquire() t = None mutex.release()&lt;/quote&gt;
    &lt;p&gt;In essence, this code is modelling a classic programming need. A mutex (colloquially a √¢lock√¢) guards a shared resource (e.g. a network socket, counter, etc.). When the garbage collector determines that an object is no longer used, it runs its finaliser i.e. its &lt;code&gt;__del__&lt;/code&gt; method. In this case the finaliser
acquires the mutex (i.e. locks it), allowing it do something with the shared resource
the mutex is guarding, and then releases the mutex (i.e. unlocks it).&lt;/p&gt;
    &lt;p&gt;Unfortunately, when I run this code in CPython, it hangs at the terminal having written just:&lt;/p&gt;
    &lt;quote&gt;$ python3 t.py acquiring&lt;/quote&gt;
    &lt;p&gt;What√¢s going on? Why hasn√¢t it printed &lt;code&gt;acquired&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;Before I explain why it hangs, it might help if I show one √¢fix√¢: if I remove the line &lt;code&gt;t = None&lt;/code&gt; and rerun the program it works as expected:&lt;/p&gt;
    &lt;quote&gt;$ python3 t.py acquiring acquired $&lt;/quote&gt;
    &lt;p&gt;The problem, in essence, is that my original program uses mutexes in a language implementation that runs finalisers interleaved with user code on the same operating system thread. I was able to craft this program to show what I wanted because I happen to know that CPython√¢s garbage collector uses reference counting2: the &lt;code&gt;t = None&lt;/code&gt; line meant
that the &lt;code&gt;T&lt;/code&gt; object created on line 10 was immediately recognised as unused,
and its finaliser executed.&lt;/p&gt;
    &lt;p&gt;The finaliser then tried to acquire the mutex (line 6). That mutex is shared with code outside the object, and unfortunately the √¢main√¢ part of the program has already grabbed the lock (line 8). At this point we have a classic deadlock: one part of the program holds a lock; another part will not continue until it has managed to grab that lock; but the latter needs to complete for the former to complete, and that is not possible. No matter how long I wait, this program will never print &lt;code&gt;acquired&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The reason I have ended up in this unfortunate situation is because the finaliser is executed asynchronously in-between lines 12 (&lt;code&gt;t=None&lt;/code&gt;) and 13
(&lt;code&gt;mutex.release()&lt;/code&gt;) on the same thread as the √¢main√¢ program. My experience is
that we√¢re so used to the general idea of finalisers that we don√¢t stop to
think how different their execution is to that of normal functions.&lt;/p&gt;
    &lt;p&gt;Most obviously, my program has no explicit calls to &lt;code&gt;t.__del__()&lt;/code&gt;: another part
of CPython√¢s run-time called that method on my behalf. Less obviously,
CPython√¢s run-time chose when to call &lt;code&gt;__del__&lt;/code&gt;. It happened to do so at the
point that I wrote &lt;code&gt;t=None&lt;/code&gt; but it could have done so at any point from then
on, and still satisfied Python√¢s specification. Indeed, I can cause CPython to
call &lt;code&gt;__del__&lt;/code&gt; at different points in many ways. For example, if I√¢d written
&lt;code&gt;t2=t&lt;/code&gt; just after &lt;code&gt;t=T()&lt;/code&gt;, my program would not have hung.&lt;/p&gt;
    &lt;p&gt;This is √¢non-local√¢ reasoning at work. In general, I can√¢t statically guarantee look at a line of Python code and know whether it will cause one or more finalisers to run unless I also understand every other part of the system which potentially relates to that line.&lt;/p&gt;
    &lt;head rend="h2"&gt;The history of this problem&lt;/head&gt;
    &lt;p&gt;I said earlier that this was a long-standing problem. This 2012 post from Andy Wingo uses a very similar example to the one above, so that√¢s 13 years ago. But √¢ and I√¢ve learnt this in inevitable whenever it comes to anything relating to programming languages and memory √¢ Hans Boehm got there much earlier, in 2002. His wonderful paper Destructors, Finalizers, and Synchronization is one of those reads where I can split my life into before/after.&lt;/p&gt;
    &lt;p&gt;In my case, I was pointed at this paper by Jacob Hughes during the work for what ultimately became √¢Alloy√¢, the garbage collector for Rust that we wrote up as Garbage Collection for Rust: The Finalizer Frontier. Boehm√¢s insights in his paper had a profound effect on the design goals we set for Alloy: the pun in the title of our paper is a fairly direct result of the challenges that we realised Boehm had implicitly set us in his paper.&lt;/p&gt;
    &lt;p&gt;Boehm√¢s paper dates from a period when Java, in particular, was experiencing all sorts of problems caused by the widespread use of finalisers3. Amongst them is the example I wrote in Python above. Boehm explicitly, and clearly, explains exactly the problem that I happened to show in Python above: finalisers that try to acquire mutexes can cause surprising deadlocks. As Boehm points out, this isn√¢t an odd thing to want to do:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There is usually not much of a point in writing a finalizer that touches only the object being finalized, since such object updates wouldn√¢t normally be observable. Thus useful finalizers must touch global shared state.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In other words: finalisers often need to use mutexes to update other objects.&lt;/p&gt;
    &lt;p&gt;The situation in CPython isn√¢t too bad in this regard. Reference counting gives me a fighting chance of working out in advance when finalisers will be called. If I get it wrong then, assuming my program is deterministic, I will get deadlocks at the same point in execution on every run. That makes debugging annoying but plausible.&lt;/p&gt;
    &lt;p&gt;In a non-reference counted implementation, such as Java implementations, things are much worse: finalisers can be called at any point; and even in seemingly deterministic programs, they will tend to be called at different points in different executions. Debugging such cases must have been an absolute nightmare!&lt;/p&gt;
    &lt;head rend="h2"&gt;The solution for garbage collectors&lt;/head&gt;
    &lt;p&gt;Fortunately the solution is quite simple, and is most clearly articulated on a slide accompanying Boehm√¢s paper:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Garbage collectors should run finalizers from a separate thread4&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To truly understand why this is the solution, we need to define some new terminology. Until now I have been using √¢asynchronous√¢ in its colloquial sense of √¢allow one operating system thread to interleave two different portions of code√¢. Technical folk like to call this concurrent execution. In contrast, parallel execution is when two portions of code are run on two operating system threads. Unfortunately in day-to-day use these two terms are interchangeable, leading to endless confusion.&lt;/p&gt;
    &lt;p&gt;In our situation, I find it easier to think of cooperative multitasking vs. preemptive multitasking.&lt;/p&gt;
    &lt;p&gt;I used to use a GUI-based operating system called RISC OS which used cooperative multitasking. A program would do some work and voluntarily give control back to the operating system, which would then hand control over to another program. If a program did not give control back (i.e. did not √¢cooperate√¢), either due to a bug or because the work it was doing was taking longer than the author had anticipated, the entire system would appear to freeze. This happened frustratingly often, particularly for new versions of software.&lt;/p&gt;
    &lt;p&gt;Modern operating systems instead switch control between different programs when the operating system chooses (i.e. preemptively): one program cannot hog execution and stop others running.&lt;/p&gt;
    &lt;p&gt;Garbage collectors like CPython√¢s run finalizers in a √¢cooperative√¢ way: they implicitly hope that the finalizer executes quickly, or at least does not get stuck forever. In our running example, we saw a case where a finalizer would not cooperate: it wanted to acquire a lock that it could never get, and thus was stuck forever.&lt;/p&gt;
    &lt;p&gt;It might be tempting to look at our example and say that it√¢s the programmer√¢s fault for writing a non-cooperative finalizer. The problem is that there is no way to write a cooperative finalizer that achieves the desired outcome. I might try waiting for other code to let go of the mutex with something like:&lt;/p&gt;
    &lt;quote&gt;class T: def __del__(self): while not mutex.acquire(blocking=False): time.sleep(0.1) print("acquired")&lt;/quote&gt;
    &lt;p&gt;but this will still hang forever and cause my CPU to get very hot! The finalizer will only be called once: it can√¢t temporarily let the √¢main√¢ code run and release the mutex, despite my vague attempt above.&lt;/p&gt;
    &lt;p&gt;We now have, I hope, the terminology to understand the solution Boehm is emphasising:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Garbage collectors should run finalizers from a separate thread&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As we√¢ve seen above, finalizers cannot be guaranteed to be cooperative in and of themselves. The solution is then simple: running them on another thread doesn√¢t require them to be cooperative! In other words, if the &lt;code&gt;__del__&lt;/code&gt; method
from our original example was run on another thread, then the program could not
have deadlocked: one thread would have waited until the other had released the
mutex, then continued.&lt;/p&gt;
    &lt;p&gt;This is the approach that modern JVMs take. It is also the approach we realised we were duty-bound to take in Alloy: finalizers are always run on a separate thread. This turned out to have huge implications which we did our level best to address. If you read the paper, you√¢ll realise that a huge chunk of it is devoted to making it possible to safely run as many Rust destructors √¢ most of which were not written in anticipation of multi-threading √¢ as possible on other threads.&lt;/p&gt;
    &lt;head rend="h2"&gt;From finalisers to futurelocks&lt;/head&gt;
    &lt;p&gt;At this point I can imagine many people feeling frustrated that I have dumbed down the futurelocks problem that I motivated this post with. It√¢s clearly more complex than the simple finalizer deadlock I√¢ve used as a running example. Indeed, a good-faith reader might reasonably question whether the two things share anything in common other than deadlocking.&lt;/p&gt;
    &lt;p&gt;My belief is that they share something fundamental in common: cooperative multitasking and the interleaving execution of arbitrary code on the same thread. As soon as you have those two ingredients, it seems to me that you have the potential for deadlocks&lt;/p&gt;
    &lt;p&gt;In my view, async runtimes often (not always, but often) share an important flaw with cooperative multitasking: they hope that the next future / promise cooperates and returns control. If it cannot return control, the system will be stuck.&lt;/p&gt;
    &lt;p&gt;In the futurelocks example, the flaw is that the &lt;code&gt;select!&lt;/code&gt; macro
commits to running one future when another future is the one that can unlock
the mutex. Thus &lt;code&gt;select!&lt;/code&gt; implicitly hopes that the future it is committed to
is the one that allows the system to make progress. That hope is sometimes dashed.&lt;/p&gt;
    &lt;p&gt;We can thus see some interesting similarities and differences between finaliser deadlocks and futurelock deadlocks.&lt;/p&gt;
    &lt;p&gt;Both are based on the misplaced hope that code will always cooperate √¢ sometimes it is impossible for code to cooperate, even if it wants to. However, if we could guarantee what code will execute at any given point, we could at least assure ourselves that only truly cooperative code will be executed. Alas, one does not know which future / promise / finaliser will be executed or resumed: it could have come from anywhere, at any point in the past.&lt;/p&gt;
    &lt;p&gt;However, one reason I suspect that async programmers run into this issue less frequently is that that while finalisers can run at any arbitrary point, async schedulers only run code at &lt;code&gt;await&lt;/code&gt;s or when a future has completed. In other
words, the possible interleavings are many fewer in the async case. However,
√¢many fewer√¢ is very different to √¢none√¢. Could one create a variant of the
&lt;code&gt;select!&lt;/code&gt; macro that fixes the particular problem? Yes: but one could always
create other seemingly valid async code that leads to the same problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solutions?&lt;/head&gt;
    &lt;p&gt;Is there a way to solve futurelocks short of causing the system to exit if a deadlock is detected at run-time? I must admit that I am pessimistic.&lt;/p&gt;
    &lt;p&gt;Why don√¢t we just ban people from using mutexes in async functions? This is clearly possible √¢ but async system code often needs to utilise multiple threads for the same performance reasons as non-async code. If you need that, you√¢re almost certainly going to want to use mutexes to safely share state amongst futures that might end up executing on different threads.&lt;/p&gt;
    &lt;p&gt;Can we create a static analysis that rules out the bad cases? The non-local nature of the problem means that type systems definitely won√¢t be enough to completely solve the problem, though we might be able to make it rule out some cases. Perhaps a more sophisticated, bespoke, static analysis could do what we want, but I suspect that it will be hard to create an analysis which accepts enough good cases and rejects enough bad cases to be worthwhile.&lt;/p&gt;
    &lt;p&gt;Perhaps we should just run all potentially deadlocking futures in another thread? That sounds just like the solution to the problem of deadlocking finalisers! However, the only way this would work is if every potentially deadlocking future / promise was executed on a thread that did not currently hold a mutex. In general, we won√¢t be able to tell if a particular future / promise might have the potential to deadlock. That would cause us having to put many, perhaps most, futures on a thread where we know they can√¢t interfere with any other half-executed future. For deeply nested async functions, this could require the use of an unbounded number of threads. I suspect the resulting performance would be terrible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;As this post might have suggested, I am less optimistic about the long term desirability of async code than many other people. Async does solve some problems extremely well √¢ but it introduces new ones that I, and I believe many others, find harder to reason about. This post has touched on one, but there are others5.&lt;/p&gt;
    &lt;p&gt;Fundamentally, one way the analogy in this post breaks down is that scheduling finalisers has a simple, correct, fairly efficient solution: put them on their own thread. I do not see that there is, or can be, a practical equivalent for the async case, where scheduling is necessarily more complex. I fear that futurelocks will always be a problem.&lt;/p&gt;
    &lt;p&gt;Personally, I love the fact that (at least on non-embedded devices), operating system threads are cheap to create and run √¢ and they give true parallelism to boot! Rust also makes writing reliable multi-threaded code vastly easier than in any other language. When problems do occur, which so far is very rare6, I find them relatively easy to debug.&lt;/p&gt;
    &lt;p&gt;Threads aren√¢t a complete solution, though. In particular, they√¢re a very heavyweight way of solving problems like √¢which of my many open network sockets has data for me to read?√¢ For those cases, I manually use &lt;code&gt;poll&lt;/code&gt; or its
equivalents. I√¢m not a fan of the API √¢ the number of ways to detect when a
file has been fully read with &lt;code&gt;poll&lt;/code&gt; is mind boggling and not consistent
across platforms √¢ but at
least problems with it remain localised to the code calling &lt;code&gt;poll&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;However, I appreciate that such opinions put me in a tiny minority. Despite that, I hope that my post has shown you that there is a more general problem which is worth knowing about. I also encourage you to listen to the Oxide podcast, which is one of my favourite technical podcasts! Without a poke from that, I wouldn√¢t have thought to write this post at all!&lt;/p&gt;
    &lt;head rend="h3"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;When I realised I can see how many podcast hours I rack up in a year, I got a real sense of how much time I spend on chores!&lt;/p&gt;
    &lt;p&gt;When I realised I can see how many podcast hours I rack up in a year, I got a real sense of how much time I spend on chores!&lt;/p&gt;
    &lt;p&gt;PyPy does not deadlock on this example as written. If I add:&lt;/p&gt;
    &lt;quote&gt;import gc gc.collect()&lt;/quote&gt;
    &lt;p&gt;between &lt;code&gt;t = None&lt;/code&gt; and &lt;code&gt;mutex.release()&lt;/code&gt; then it does.&lt;/p&gt;
    &lt;p&gt;PyPy does not deadlock on this example as written. If I add:&lt;/p&gt;
    &lt;quote&gt;import gc gc.collect()&lt;/quote&gt;
    &lt;p&gt;between &lt;code&gt;t = None&lt;/code&gt; and &lt;code&gt;mutex.release()&lt;/code&gt; then it does.&lt;/p&gt;
    &lt;p&gt;Boehm, I√¢m sure, was also aware of many of these problems from his work on BDWGC, the retrofittable garbage collector for C/C++. Java, though, was the hot topic of the day.&lt;/p&gt;
    &lt;p&gt;Boehm, I√¢m sure, was also aware of many of these problems from his work on BDWGC, the retrofittable garbage collector for C/C++. Java, though, was the hot topic of the day.&lt;/p&gt;
    &lt;p&gt;As I understand matters, JVMs were required to do this, but did not always do so. I believe a common mistake was for low-memory situations to call finalizers during allocation i.e. potentially on the same thread as code holding a lock that finalizer would try to acquire.&lt;/p&gt;
    &lt;p&gt;As I understand matters, JVMs were required to do this, but did not always do so. I believe a common mistake was for low-memory situations to call finalizers during allocation i.e. potentially on the same thread as code holding a lock that finalizer would try to acquire.&lt;/p&gt;
    &lt;p&gt;For example: incomprehensible backtraces; futures that the code forgets to execute; the bifurcation of the ecosystem; and, in Rust at least, a significant increase in language complexity.&lt;/p&gt;
    &lt;p&gt;For example: incomprehensible backtraces; futures that the code forgets to execute; the bifurcation of the ecosystem; and, in Rust at least, a significant increase in language complexity.&lt;/p&gt;
    &lt;p&gt;The only nasty case I√¢ve found was due to the unspecified nature of temporary lifetime extension. Once I realised the problem, the fix was, fortunately, trivial.&lt;/p&gt;
    &lt;p&gt;The only nasty case I√¢ve found was due to the unspecified nature of temporary lifetime extension. Once I realised the problem, the fix was, fortunately, trivial.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tratt.net/laurie/blog/2025/async_and_finaliser_deadlocks.html"/><published>2025-11-12T18:12:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45903840</id><title>Valve Announces New Steam Machine, Steam Controller and Steam Frame</title><updated>2025-11-12T23:10:12.774434+00:00</updated><content>&lt;doc fingerprint="94d0b4ad0c11766b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Valve Announces New Steam Machine, Steam Controller &amp;amp; Steam Frame&lt;/head&gt;
    &lt;p&gt; Valve just sent over the press release announcing three new Steam Hardware devices. &lt;lb/&gt;The recent leaks have panned out and Valve just announced a new Steam Controller, the return to Steam Machine as a Linux-powered living room gaming console, and Steam Frame as their long rumored VR headset.&lt;lb/&gt;The new Steam Controller looks similar to the Steam Deck controls sans the screen and tech.&lt;lb/&gt;The new Steam Machine is running SteamOS and powered by an AMD desktop class CPU and GPU. It will double as a conventional (Linux-based) PC. The Steam Machine uses a semi-custom AMD Zen 4 based SoC with RDNA3 graphics and 16GB of RAM and 8GB of GDDR6 vRAM.&lt;lb/&gt;The Steam Frame is their lightweight VR headset that is wireless and said to be comfortable. The Steam Frame is powered by a Qualcomm Snapdragon 8 Gen 3 ARM64 SoC with 16GB of LPDDR5x RAM and running SteamOS.&lt;lb/&gt;These new Steam devices will be coming out in "early 2026". Exact launch timing and pricing will be shared in the new year.&lt;/p&gt;
    &lt;p&gt;The recent leaks have panned out and Valve just announced a new Steam Controller, the return to Steam Machine as a Linux-powered living room gaming console, and Steam Frame as their long rumored VR headset.&lt;/p&gt;
    &lt;p&gt;The new Steam Controller looks similar to the Steam Deck controls sans the screen and tech.&lt;/p&gt;
    &lt;p&gt;The new Steam Machine is running SteamOS and powered by an AMD desktop class CPU and GPU. It will double as a conventional (Linux-based) PC. The Steam Machine uses a semi-custom AMD Zen 4 based SoC with RDNA3 graphics and 16GB of RAM and 8GB of GDDR6 vRAM.&lt;/p&gt;
    &lt;p&gt;The Steam Frame is their lightweight VR headset that is wireless and said to be comfortable. The Steam Frame is powered by a Qualcomm Snapdragon 8 Gen 3 ARM64 SoC with 16GB of LPDDR5x RAM and running SteamOS.&lt;/p&gt;
    &lt;p&gt;These new Steam devices will be coming out in "early 2026". Exact launch timing and pricing will be shared in the new year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.phoronix.com/news/Steam-Machines-Frame-2026"/><published>2025-11-12T18:26:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45903995</id><title>How Tube Amplifiers Work</title><updated>2025-11-12T23:10:12.259469+00:00</updated><content>&lt;doc fingerprint="a0721267a80a378a"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell/&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;How Tube Amplifiers Work&lt;/head&gt;
          &lt;p&gt;By Rob Robinette&lt;/p&gt;
          &lt;p&gt;Have you ever looked at the guts of a guitar amplifier and wondered what all those parts do? Well, I'll walk you through the signal flow and discuss the components in this very simple but great sounding 1950's Fender 5F1 Champ guitar amplifier. Once you understand the simple 5F1 you'll be able to understand more complicated amps. 5F1 was Fender's internal model code for the 1950's tweed Champ. Although this page discusses Guitar tube amps everything here applies to audio stereo tube amplifiers too with the goal of distortion prevention in audio amps being the biggest difference.&lt;/p&gt;
          &lt;head&gt;5F1 Champ Amplifier&lt;/head&gt;
          &lt;head&gt;5F1 Chassis&lt;/head&gt;
          &lt;p&gt;Volume control on top, Circuit Board inside, tubes on bottom: V1 Preamp Tube on right, V2 Power Tube in center, V3 Rectifier Tube on left. The Power Transformer and Output Transformer are attached to the other side of the chassis.&lt;/p&gt;
          &lt;p&gt;WARNING: A tube amplifier chassis contains lethal high voltage even when unplugged--sometimes over 700 volts AC and 500 volts DC. If you have not been trained to work with high voltage then have an amp technician service your amp. See more tube amplifier safety info here.&lt;/p&gt;
          &lt;p&gt;We'll start with the amplifier layout diagram. If things get too cluttered you can refer back up to this clean diagram. The guitar input jacks are at the upper right, the circuit board is in the center, the power transformer (PT) is on the left and the tubes and speaker jack are at the bottom. The output transformer (OT) is not shown but "OT In" are the output transformer primary wires and "OT Out" are the secondary wires.&lt;/p&gt;
          &lt;head&gt;5F1 Champ Guitar Amplifier Layout Diagram&lt;/head&gt;
          &lt;p&gt;I added component numbers to this layout that match the schematic diagram below. Compare this to the picture of the chassis above. I have had questions about the grounding scheme shown in this layout. Grounding the V2 power tube grid leak (R9) and the power tube cathode resistor (R8) and cathode bypass cap (C6) to the first filter capacitor's ground (C3) is best practice and should result in a quieter amp. Click the image to download the pdf.&lt;/p&gt;
          &lt;head&gt;Annotated Layout With Signal Flow and Component Function&lt;/head&gt;
          &lt;p&gt;Tracing the signal path on this layout diagram and the schematic below will help you understand how this amp works.&lt;/p&gt;
          &lt;head&gt;Signal Flow Overview&lt;/head&gt;
          &lt;p&gt;Signal flow is shown above and below (orange arrows above, fat red line below). Signal from the guitar enters at upper right guitar Input Jack 1 or 2 and flows down to the circuit board and then to the preamp tube V1A at bottom right where the signal goes through its first stage of amplification. The signal then goes up to the circuit board and on to the volume control at top center, then back down to tube V1B (the second half of the first tube) for its second stage of amplification. From there the audio signal goes back to the circuit board then down to the power tube V2 for the third stage of amplification. V2's output goes out the blue wire to the output transformer (not shown) for a current boost, then from the output transformer via the green wire to the speaker jack (to the right of V2) and on to the speaker. I have added component numbers to the layout diagram above that match the schematic below.&lt;/p&gt;
          &lt;head&gt;Annotated Weber 5F1 Schematic&lt;/head&gt;
          &lt;p&gt;The signal flow in red seems much simpler on the amp's schematic. Component numbers match the Layout diagram above. V1A is one half of tube V1, V1B is the other half. Voltages shown are approximate. Click the image for the full size schematic. Click here for the clean schematic.&lt;/p&gt;
          &lt;p&gt;These are pretty much all the symbols you'll need to know to read tube amp schematics.&lt;/p&gt;
          &lt;head&gt;Table of Contents&lt;/head&gt;
          &lt;p&gt;How Cathode Bypass Capacitors Work&lt;/p&gt;
          &lt;p&gt;The Long Tail Pair Phase Inverter&lt;/p&gt;
          &lt;p&gt;Ultra-Linear Output Transformers&lt;/p&gt;
          &lt;p&gt;Impedance Mismatch Between the Power Tube and Speaker&lt;/p&gt;
          &lt;p&gt;Magnatone 280 Amp With Stereo Harmonic Pitch-Shift Tremolo&lt;/p&gt;
          &lt;p&gt;How Humbucking Guitar Pickups Work&lt;/p&gt;
          &lt;p&gt;Transistor Equivalent Circuits&lt;/p&gt;
          &lt;p&gt;Calculating Parallel Resistance&lt;/p&gt;
          &lt;p&gt;How Voltage Dividers and Pots Work&lt;/p&gt;
          &lt;p&gt;Measuring In Circuit Resistance&lt;/p&gt;
          &lt;p&gt;Your Calculator's Engineering Mode&lt;/p&gt;
          &lt;head&gt;How Amps Work&lt;/head&gt;
          &lt;p&gt;The next few paragraphs will help you visualize the flow of electrons through simple circuits. Learning to visualize the flow of individual electrons was a breakthrough for me in understating tube amplifier electronics.&lt;/p&gt;
          &lt;p&gt;Electric guitars generate an alternating current (AC) audio signal. The guitar's pickups are small electric generators. Pickups have magnets (poles) that magnetize the metal guitar strings. The movement of the magnetic field surrounding the magnetized strings generates electricity in the pickup's coil. The coil is simply a thin insulated wire wrapped around a spool and when a magnetic field cuts through a coil of wire it generates an electric voltage (electronic pressure) and current (electron flow) in the coil's wire.&lt;/p&gt;
          &lt;head&gt;Guitar Pickup&lt;/head&gt;
          &lt;p&gt;The black and white wires leaving the guitar pickup are the two ends of one long coil wire. A humbucker pickup is simply two of these coils connected end-to-end (in series).&lt;/p&gt;
          &lt;head&gt;Standard Guitar Circuit&lt;/head&gt;
          &lt;p&gt;The Pickup on the left is a wire coil that generates the guitar signal. The Tone Control bleeds high frequencies to ground. The Volume Pot is wired as a variable voltage divider. The Volume Pot bleeds guitar signal to ground to lower the guitar's output volume.&lt;/p&gt;
          &lt;p&gt;I've been asked many times, "What is voltage?" It's pretty simple really. Like electrical charges repel the same way like magnetic poles repel. So if you cram a bunch of negatively charged electrons together onto the metal plates of a battery their negative charges repel one other--they want elbow room. The tighter they are packed together the higher the pressure so I like to think of negative voltage as electron pressure.&lt;/p&gt;
          &lt;p&gt;A quick note about 'Conventional Current Flow.' In electric circuits negatively charged electrons actually flow from the negative '-' battery terminal to the positive '+' terminal. That's right, the electricity in your car flows from the battery's - terminal through the ground wire, through the car's body, through the radio's ground wire to the radio and then through the positive power wire back to the battery. The problem is that Benjamin Franklin guessed wrong on the polarity and direction of electrical flow so conventionally we think of electricity as flowing from + to -. People say electric current flows + to - (conventional current flow) but electrons flow - to +. With tube electronics it's easier to think in terms of how the electrons are really moving in order to understand them.&lt;/p&gt;
          &lt;p&gt;If you connect a wire across a battery's terminals the jammed together electrons in the negative terminal see the wire as a pipe with lots of room so they flow down the wire. When you have an 'excess' of electrons tightly packed together you have negative voltage. When you have a 'scarcity' of electrons, or electrons are pulled apart from one another, you have a positive voltage.&lt;/p&gt;
          &lt;p&gt;When I think about a wire with very high positive voltage on it I imagine the wire as an empty pipe with very few electrons in it with lots of 'elbow room' so electrons really want to flow into that wire. Ground or earth represents an unlimited supply of electrons at zero volts (or neutral voltage). Touch that high voltage wire wire to a ground and the electrons hanging out there will rush in to fill the void of electrons in the wire. Voltage is the force of electrons wanting to move from a conductor crowded with electrons to a conductor with fewer electrons and more elbow room. Current is the measure of how many electrons are flowing through a conductor--the more electrons flowing, the higher the current. Keep this in mind when thinking about amp circuits, high voltage is an extreme scarcity of electrons and ground represents an unlimited supply of electrons.&lt;/p&gt;
          &lt;p&gt;As a guitar string vibrates it moves one way and generates a positive voltage in the pickup coil, then as the string reverses direction the voltage is reversed and a negative voltage is generated. This occurs with every string vibration so an alternating current (positive-negative-positive-negative. . .) makes up the audio signal put out by the guitar. I'll repeat that because it's a very important concept, as the guitar string moves one direction over the guitar pickup coil it generates a negative voltage (excess electrons), then as the string reverses direction the electron pressure (voltage) and electron flow (current) reverses too and a positive voltage is generated (scarcity of electrons) and this repeats with every vibration of the string creating an Alternating Current (AC) electrical signal. This is why guitar audio signals are AC, or alternating current--as the strings alternate their direction of travel the signal voltage alternates between + and -. This tiny little AC signal is what the guitar amp will amplify until it's strong enough to move a speaker cone in and out. The speaker cone alternates in and out with the alternating current from the guitar's pickup coil. For every guitar string movement there is a corresponding speaker cone movement.&lt;/p&gt;
          &lt;p&gt;An AC guitar audio signal on a wire alternates between positive and negative voltage. A negative signal voltage packs electrons closer together (excess of electrons = negative voltage). The positive half of the AC guitar signal pulls electrons apart and creates a scarcity of electrons. Remember, voltage = electron pressure.&lt;/p&gt;
          &lt;p&gt;If you graph a guitar audio signal the pitch of the guitar string's sound is expressed as wave spacing (frequency) and loudness is expressed as wave height (amplitude). A high frequency sound will have tight wave spacing and a low frequency sound will have wide wave spacing. In the graph below the high E string is on the left and the low E is on the right. A quiet sound will have short waves and a loud sound will have tall waves.&lt;/p&gt;
          &lt;p&gt;The direct relationship between string movement and electricity generated in the pickup coil is the key to understanding guitar amplification. Our guitar amplifier will simply make the electric audio waves taller to boost their loudness.&lt;/p&gt;
          &lt;p&gt;When multiple strings are played the multiple electric waves are summed into complex waves. See my short youtube video to see guitar audio on an oscilloscope.&lt;/p&gt;
          &lt;head&gt;Guitar AC Voltage Audio Signal&lt;/head&gt;
          &lt;p&gt;Fender Stratocaster connected directly to an oscilloscope. Each 'wave' on the oscilloscope is caused by one string vibration. The highest voltage (peak of wave) is created by the fastest string speed when it's moving directly over the pickup. The zero voltage point (center of graph) is when the string stops moving and reverses its direction. The left side of the graph shows a high open E string pluck followed by a pluck of the low open E. Voltage is on the left scale and time runs along the bottom. The top half of the signal is positive voltage and the bottom half is negative. The signal's voltage and current alternate between positive and negative. The tight wave spacing on the left is an indication of high frequency and pitch. The wave height is an indication of power and loudness. The high open E + low open E strings' signal on the right is a summation of the two strings' signals combined into a complex wave--the high open E wave is 'written' onto the large low open E wave. The speaker cone will move just like this graph. Every little twitch on that line makes the speaker cone twitch. When the graph goes high with a positive voltage the speaker cone moves outward, when the graph goes low with a negative voltage the cone moves inward.&lt;/p&gt;
          &lt;head&gt;WARNING&lt;/head&gt;
          &lt;p&gt;Amplifiers have large capacitors that store enough electricity to kill even when the amplifier is unplugged. If you open an amplifier you MUST verify no voltage remains in the capacitors before working inside it.&lt;/p&gt;
          &lt;head&gt;Guitar Audio Signal Input&lt;/head&gt;
          &lt;p&gt;The guitar cable's tip conductor connects to the input jack's "T" tip terminal. The cable's sleeve connects to the "G" ground terminal. The guitar signal travels down the wire and through grid stopper resistor R3.&lt;/p&gt;
          &lt;p&gt;The guitar's alternating current audio signal enters the amplifier at guitar input jack 1 or 2. 1 is the Hi input and 2 is the Lo, -6dB quieter input. Resistor R1 on jack 1 is the 'input resistor.' It sets the amp's input impedance to 1,000,000 ohms (1M) to boost the signal voltage from the guitar. [Bonus info: R1 also functions as the 'grid leak' resistor for Tube V1A's grid. A grid leak drains off unwanted DC voltage to keep the tube's control grid near 0 DC volts.] The '1M' written on R1 is its rating of 1 megaohm. See more on impedance here and see this web page for grad school level information on how Fender multiple input jacks and jumpering channels works.&lt;/p&gt;
          &lt;p&gt;The signal moves from the guitar jacks down the yellow wires to resistors R2 or R3, which are 'grid stopper' resistors. They help stabilize the amplifier by removing much of the audio signal above human hearing. The "68K" written on the resistor refers to its resistance value of 68,000 ohms or 68 kilohms. [Bonus info: R2 and R3 also act as 'mixing resistors' and prevent interaction between two simultaneous inputs like two guitars or a guitar and microphone. Sometimes you will see resistor values written as 1K5 which simply means 1.5 kilohms.]&lt;/p&gt;
          &lt;head&gt;Preamp Stage&lt;/head&gt;
          &lt;p&gt;Signal from resistor R3 travels down the wire to tube V1A's grid (pin 2) then out the plate to coupling capacitor C1. Tube V1 is split into two identical halves, A &amp;amp; B.&lt;/p&gt;
          &lt;p&gt;After going through grid stopper resistor R3 the audio signal flows down the wire to the preamp tube's control grid, which is the entry to the 'A' half of the preamp tube (V1A). It's called V1A because tubes were called 'Valves' and this is tube number 1 and we're using the 'A' half of the tube. 12AX7 is the type of tube which happens to be the most popular preamp tube in use and it's really two tubes in one.&lt;/p&gt;
          &lt;p&gt;I recommend you now read How Tubes Work and come back here when finished.&lt;/p&gt;
          &lt;p&gt;The preamp tube amplifies the guitar audio signal then sends it out pin 1 (plate) up the yellow wire to capacitor C1, which is a 'coupling capacitor' or 'cap.' Coupling caps are sometimes also called 'blocking caps' because they block DC voltage but allow the AC guitar signal to pass. The 0.022uF written on the cap is it's rating of 0.022 microfarads (0.000,000,022 Farads). In some old documents you'll see "micro-micro" or "uu" which means pico Farad.&lt;/p&gt;
          &lt;p&gt;Use this chart to help convert capacitor size such as: .1uF = 100nF and 1nF = 1000pF.&lt;/p&gt;
          &lt;p&gt;Capacitors are made of two conductive plates separated by an insulator or dielectric. Common dielectrics are mica, polypropylene, ceramic and even paper and oil.&lt;/p&gt;
          &lt;p&gt;How capacitors block DC but let AC pass: Caps are made with sandwiched but separated conductive plates. The separated plates cannot flow DC current but AC fluctuates between positive and negative voltage. When the AC guitar signal negative voltage (excess electrons) is applied to the input plate the electrons repel electrons on the output plate so they move off the plate and flow out of the capacitor. When a positive voltage is applied (scarcity of electrons) to the input plate the output plate attracts electrons so electrons flow into the capacitor.&lt;/p&gt;
          &lt;p&gt;That's how capacitors really work but I like to visualize them as having a stretchable rubber membrane inside that blocks the flow of electricity. When voltage is applied to a capacitor the 'rubber membrane' stretches and bulges as electrons try to flow through it. The higher the voltage the more the membrane bulges. If you quickly reverse the capacitor's voltage polarity it will go from bulging one way to bulging the other way. This is what a small AC signal does--it stretches the 'membrane' back and forth as the voltage alternates which allows electrons on both sides of the capacitor to move back and forth (alternate) but a constant DC voltage that is trying to flow in one direction will be blocked by the membrane.&lt;/p&gt;
          &lt;p&gt;If you are familiar with hydraulics a coupling capacitor is like a piston in a hydraulic line. Small alternating pressure changes will make the piston move back and forth so fluid is moved on both sides of the piston -- this is how small alternating current signals move through a capacitor.&lt;/p&gt;
          &lt;p&gt;High voltage DC (direct current) power used by the tube is brought in through resistor R5, which is a 'load resistor.' We'll discuss the function of the load resistor later. The wire between tube pin 1 (plate) and R5 carries up to 250 volts DC. That wire carries both the AC audio signal out and the high voltage DC power the tube needs in. Coupling capacitor C1 allows the AC audio signal to pass through but blocks the DC on the wire and keeps it out of the volume pot.&lt;/p&gt;
          &lt;head&gt;Volume and Output Stage Driver&lt;/head&gt;
          &lt;p&gt;Signal flows from capacitor C1 to the Volume pot then down the orange wire to tube V1B's grid (pin 7) then out the plate (pin 6) to capacitor C2, then to a fork in the road--resistor R9 one way and the other way down the yellow wire to the power tube V2.&lt;/p&gt;
          &lt;p&gt;After going through capacitor C1 the audio signal flows up the yellow wire to the volume potentiometer (pot) which acts as a variable voltage divider. Volume knob left = more signal bled to ground and lower volume. Volume knob right = less signal bled to ground and higher volume. [Bonus info: The volume pot also functions as V1B's grid leak resistor] For more info see voltage dividers and potentiometers.&lt;/p&gt;
          &lt;p&gt;The signal then flows from the volume pot down the orange wire all the way to tube V1B's pin 7 (grid). V1B is the second half of the preamp tube. This second gain stage is called the output stage driver because it boosts the signal to the level needed by the power tube. The audio signal leaves tube V1B via pin 6 (plate) and flows up the yellow wire to capacitor C2, another coupling cap that blocks DC. High voltage DC is fed to the tube via load resistor R7. After C2 the signal flows down the yellow wire to the power tube's pin 5 (grid). Resistor R9 has a dual function. It adds input impedance to the power tube amplifier circuit and acts as the tube's 'grid leak' resistor which keeps the grid at 0 volts DC.&lt;/p&gt;
          &lt;head&gt;Power Tube to Output Transformer to Speaker Jack&lt;/head&gt;
          &lt;p&gt;Signal leaves V2's pin 3 and flows out the blue wire to the Output Transformer's primary winding then out the secondary winding to the speaker jack.&lt;/p&gt;
          &lt;p&gt;The power tube, V2 is sometimes referred to as the output tube. V2 is the final stage of amplification and its purpose is to amplify for power (voltage x current) where V1A and V1B were focused on voltage amplification. The signal enters the power tube at pin 5 (grid) and leaves via pin 3 (plate). It then goes to the output transformer (OT) which is mounted on the backside of the chassis and is not shown on the layout diagram.&lt;/p&gt;
          &lt;p&gt;Like we saw with the guitar's pickup, magnetism can be used to generate electricity in a coil. You can also do the reverse and pass electricity through a coil and generate magnetism. The amplifier's output transformer uses both of these principles to pass alternating current (AC) from its primary (input) winding to the iron core as magnetic flux and on to the secondary (output) winding as alternating current.&lt;/p&gt;
          &lt;p&gt;The output transformer's windings are really just two wire coils wrapped around an iron core. The input, or primary winding uses electric current flowing through it to generate a magnetic field or flux. This magnetic field fluctuates with the guitar AC signal voltage and is captured by the transformer's iron core. The captured magnetic flux flowing through the core generates a voltage and current in the secondary winding. You can alter the voltage and current from primary to secondary by changing the ratio of coil wraps from primary coil to secondary.&lt;/p&gt;
          &lt;head&gt;Transformers&lt;/head&gt;
          &lt;p&gt;Current flowing into the primary winding (above left) induces magnetic flux flow around the transformer iron core which in turn induces an electric voltage and current in the secondary winding. Put fewer wire wraps on the secondary (output) winding and its voltage will decrease (step down) but its current will increase. Most guitar amp transformers are of the 'double window' type (bottom of left diagram) and made with laminated iron magnetic cores. 5F1 transformers are shown on the right. The Power Transformer is lying on its side while the Output Transformer is standing vertically. Positioning transformers 90¬∫ out of phase with one another like this reduces interference hum.&lt;/p&gt;
          &lt;p&gt;Example: The primary winding has 200 wraps of wire in its coil and the secondary has 100 wraps. If a 10 volt alternating current is applied to the primary winding the secondary will generate 1/2 of the input or 5 volts. The current will change proportionally in the opposite direction. If 1 ampere of AC current is applied to the primary the secondary will generate 2 amps. This is what an amplifier's output transformer does, it steps down the signal's voltage but steps up the current because the speaker's voice coil needs current to generate a magnetic field to move the speaker cone.&lt;/p&gt;
          &lt;p&gt;The output transformer's primary takes in a high voltage, low current signal (high impedance signal) and puts out a low voltage, high current signal (low impedance signal) through the green wire to the speaker jack and on to the speaker. For you mechanical types you can think of the output transformer as a gearbox that alters speed (voltage) and torque (current). The power tubes send large voltage swing into the output transformer and you can think of this as high speed from an "engine". The transformer gears this high speed (high speed, low torque=high voltage, low current) down for much less speed (less voltage swing) but much more torque (current).&lt;/p&gt;
          &lt;p&gt;The alternating current audio signal flows through the speaker's voice coil which generates a magnetic field. The voice coil is simply a single wire wrapped into a coil as shown below. The magnetic field created by the voice coil is either attracted to or repelled by the speaker's magnet. Positive voltage generates a repulsive magnetic force and the speaker coil and cone moves outward away from the speaker magnet, negative voltage generates an attractive magnetic force and pulls the speaker cone inward. The speaker cone alternates between moving outward and inward as the signal voltage alternates between positive and negative. For every guitar string movement there is a corresponding speaker cone movement.&lt;/p&gt;
          &lt;head&gt;Speaker Voice Coil is an Electromagnet&lt;/head&gt;
          &lt;p&gt;Electric current flowing through the speaker's voice coil generates a magnetic field. When the electric current in the voice coil reverses, the magnetic field also reverses causing attraction and repulsion to the speaker magnet.&lt;/p&gt;
          &lt;p&gt;This magnetic attraction and repulsion moves the voice coil and speaker cone back and forth to create air pressure waves that our ears perceive as sound--the sweet sound of electric guitar. When the speaker cone moves outward a positive air pressure wave is created and when the cone moves inward a negative (low pressure) wave trough is generated. These air pressure waves move our ear drums in and out. The ear drum movement is translated into neuron activity which is sent to the brain where pleasure is created, thus electric guitar + amp = pleasure ;)&lt;/p&gt;
          &lt;p&gt;Bonus Info: You can determine the ohm rating of a guitar speaker by measuring the DC ohms (resistance) between the speaker terminals (while disconnected from the amp) and then multiply by 1.2. Example: You measure 6.5 ohms: 6.5 x 1.2 = 7.8 ohms = 8 ohm speaker.&lt;/p&gt;
          &lt;head&gt;Speaker&lt;/head&gt;
          &lt;p&gt;The 'voice coil' is an electromagnet that interacts with the speaker magnet. The 'spider' supports the voice coil but allows it to move in and out freely. This excellent DIY speaker recone video shows speaker parts and function in detail.&lt;/p&gt;
          &lt;head&gt;Bonus Info: How Microphones Work&lt;/head&gt;
          &lt;p&gt;Dynamic microphones work exactly in reverse of how a speaker works. They have a diaphragm like a speaker cone that gets moved by sound (air pressure waves). The diaphragm moves a coil of wire wrapped around a magnet. The coil moving through the magnetic field creates electricity in the coil wire--an alternating current signal voltage.&lt;/p&gt;
          &lt;head&gt;Microphone&lt;/head&gt;
          &lt;p&gt;When the microphone diaphragm moves the coil, electricity is generated.&lt;/p&gt;
          &lt;p&gt;When a singer sings a note her vocal chords vibrate like a guitar string. The movement of the vocal chords create air pressure waves that strike the microphone diaphragm and cause it to move. Speaking of diaphragms, our ear drums are diaphragms that when moved by sound waves cause neurons to fire to communicate with our brain. Yea, our ears are biological dynamic microphones.&lt;/p&gt;
          &lt;p&gt;When a positive, high pressure sound wave hits the microphone diaphragm it is pushed inward and a positive electrical current and voltage are created. When the low pressure wave trough hits the diaphragm it is pulled outward and a negative current and voltage are created in the coil. The microphone creates an alternating current voltage signal similar to an electric guitar AC voltage signal.&lt;/p&gt;
          &lt;head&gt;Negative Feedback&lt;/head&gt;
          &lt;p&gt;The 5F1 amplifier uses negative feedback (NFB) to reduce distortion, increase headroom, decrease damping factor and improve stability but a drawback is it also reduces overall amplifier gain. Negative feedback works by taking the speaker output voltage and feeding it back into the amp's signal stream before the driver or phase inverter circuit. A feedback resistor reduces the voltage to a suitable level before it joins the amp's signal stream. It's negative feedback because the signal is out of phase so when it's injected into the amp's signal stream it reduces the amp's signal voltage.&lt;/p&gt;
          &lt;p&gt;A green wire running from the 5F1's speaker jack carries the amplified audio signal through resistor R13 and injects the feedback at V1B's pin 8 (cathode). Resistor R13 is the Feedback Resistor and controls the level of feedback voltage passed to the cathode. Adding a switch to the NFB circuit is a common modification. Removing feedback makes an amp more aggressive with earlier break up and distortion at lower volume levels.&lt;/p&gt;
          &lt;p&gt;So the main purpose of a guitar amplifier is to take the tiny AC electrical signal generated by the guitar's pickup coil and make it strong enough to push and pull a speaker cone. The guitar amp is also used to shape the tone and control signal distortion giving us the clean, mellow sound of jazz guitar or the animal growl of hard rock. Distortion is an important part of guitar amplifier design and this is the primary difference between guitar and audio amplifiers. Audio amps are usually designed for absolute minimum distortion.&lt;/p&gt;
          &lt;head&gt;Power Supply&lt;/head&gt;
          &lt;p&gt;Now that we've covered the signal flow I'll go back and cover the other amplifier components that I didn't mention. Wall plug power of 120 volts AC (USA or 100, 220 or 240 volts AC in other countries) runs to the fuse F1. Fender guitar amp fuses are MDL type "slow blow" or "time delay", size 3AG, 1/4 inch (6mm) wide by 1 1/4 inch (30mm) long. The fuse is a 250 volt, 2 amp slow blow fuse. Slow blow means it won't blow instantaneously when the turn-on power surge runs through it. Sustained current greater than 2 amps is required to blow the fuse. Next the power flows to the power switch S1, which is located on the volume pot.&lt;/p&gt;
          &lt;p&gt;120 AC volts RMS (average) wall power equals 169.7 volts peak (Vp) and 339.4 volts peak-to-peak (Vpp).&lt;/p&gt;
          &lt;p&gt;Bonus Info: Alternating Current (AC) voltage is normally given in volts RMS (root-mean-square), which is a form of voltage averaging equal to a DC voltage. Always consider AC voltage as RMS unless it is specified as peak Vp or peak-to-peak Vpp. Multimeters show voltage in RMS. Our standard 120 volts AC wall power is RMS. You can convert RMS voltage to peak voltage by multiplying RMS by 1.414, so 120 volts AC at the wall is actually 169.7 volts measured from the + wave peak to 0. You can convert peak voltage to RMS by multiplying by 0.707. To convert RMS voltage to peak-to-peak voltage you multiply RMS by 2.828, so 120 volts AC at the wall is actually 339.4 volts measured from the + wave peak to the - wave peak. You can convert peak-to-peak to RMS by multiplying by 0.354.&lt;/p&gt;
          &lt;p&gt;AC voltage in the United States runs at 60 cycles per second, which is called Hertz (Hz). 120 volt wall power goes from zero to +169.7 volts, then down through zero to -169.7 volts, then back up to zero 60 times per second. This is why AC electrical noise picked up by guitar amps is often described as a 60 Hertz hum. Why is our wall power 60 cycles per second? Because power company electrical generators in the US turn at 60 revolutions per second (3600 revolutions per minute or RPM).&lt;/p&gt;
          &lt;p&gt;Bonus Bonus Info: Visualizing Alternating Current. One way to visualize how AC electricity flows is to think of the amplifier's power system as a rope and pulley system. Think of the wall power plug and the amplifier's power transformer as pulleys. A loop of rope representing the hot and neutral wires would be wrapped tightly around the wall power and transformer pulleys.&lt;/p&gt;
          &lt;p&gt;The power company's AC generator is like a hand grabbing the power rope (hot wire) and pushing it forward a few feet then stopping the rope movement and pulling the rope back, then pushing the rope again, then pulling it in this alternating pattern (doing one push-pull cycle 60 times per second). Electrons actually alternate their movement forward and backward, reversing course through AC wires and circuits like this rope movement.&lt;/p&gt;
          &lt;p&gt;Bonus Bonus Bonus Info: 240 volt circuits in the United States use two 120 volt hot wires instead of 120 volt's single hot wire and ground (called neutral). For 240 volts one wire pushes at +120 volts while the other pulls at -120 volts (like using two hands, one hand on each of the two ropes in the analogy above), then they alternate the pushing and pulling at the same 60 cycles per second for 240 volts of power. Alright, back to the amplifier. . .&lt;/p&gt;
          &lt;p&gt;After the amp's fuse and On/Off switch the 120v AC RMS runs to the power transformer (PT), through its primary winding, then back to the wall plug via the white Neutral wire. The white Neutral wire is a ground wire and is connected to the same ground as the Safety Ground wire at the building's electrical service entrance.&lt;/p&gt;
          &lt;p&gt;The 5F1's power transformer high voltage winding is rated at 325-0-325v. This means the transformer has a grounded 0 volt center tap and simultaneously puts out +325 volts AC RMS on one secondary winding wire and -325v on the other for a 650 volt AC RMS wire-to-wire voltage (650 volts AC RMS = 1,838 volts peak-to-peak :O ). Yes, that's high voltage that can kill you. At this very high voltage the 5F1 power transformer only needs to be rated for a paltry 70 milliamps (0.070 amp) max AC current to run the amp circuit.&lt;/p&gt;
          &lt;p&gt;The power transformer has three secondary windings. The first winding as discussed above steps the 120v RMS AC wall power up to 325 volts RMS AC. Two other small secondary windings step the 120v AC down to 6.3 volts RMS AC and 5 volts RMS AC. Notice all voltages in transformer secondaries are always AC because a transformer can't pass DC from primary to secondary. The 6.3 volts are used to power the pilot light and heat the preamp and power tubes' heater filaments which heat the tubes' cathodes. The 5 volts are used to directly heat the rectifier tube's cathode.&lt;/p&gt;
          &lt;p&gt;Bonus Info: When I first learned that the power transformer primary coil was made up of one long wire that directly connects the 120v hot wire to the neutral (ground) wire I wondered why it didn't short out. The reason is the primary and secondary coils are coupled together by the transformer's iron core. Alternating current in the primary coil creates a magnetic field or flux that is captured by the core. That flux in the core creates an AC voltage in the secondary coil. The load (impedance) placed on the secondary winding by the amplifier is transferred through the core to the primary coil. That impedance keeps the primary coil from "shorting out."&lt;/p&gt;
          &lt;head&gt;Power Cord Wiring&lt;/head&gt;
          &lt;p&gt;Modern U.S. wall cords and sockets have a narrow blade for Hot (black wire 120v), a wide blade for Neutral (white wire ground), and a round or 'D' shaped prong for the chassis Safety Ground (green wire ground). Power cord wire colors are sometimes non-standard so use a multimeter to identify Hot and Neutral. Europeans sometimes use the letters E: Earth (safety ground), L: Line (hot) and N: Neutral to describe the three plug wires.&lt;/p&gt;
          &lt;p&gt;The 325 volts AC power from the power transformer is fed directly into V3, the rectifier tube. V3 is a full wave dual plate rectifier tube that converts alternating current (AC) into direct current (DC). The power transformer and rectifier work together as an electron pump which pulls electrons out of the amp circuit creating a positive voltage (electron scarcity = positive voltage). The amplifier's electronics need DC to amplify. The amp is powered by DC but the guitar signal moving through the amp is AC.&lt;/p&gt;
          &lt;p&gt;The flow of power starts at the power transformer at far left. 325V AC on each high voltage secondary wire powers the V3 rectifier tube. V3 puts out 360V of DC. Note the yellow wires running to V1's pins 1 &amp;amp; 6 carry both high voltage DC power into the tube and the AC signal out (orange arrows). This diagram shows "conventional" current flow but the actual electrons flow in the opposite direction.&lt;/p&gt;
          &lt;p&gt;360 volts of DC flows out of V3's pin 8 (cathode) and is referred to as B+ voltage (from old Battery Positive designation). Tube rectifiers are popular in guitar amps due to their dynamic power sag which adds to the amp's playing dynamics and note "bloom". Audio stereo tube amps usually use solid state rectifiers to reduce voltage sag that would be seen as distortion to the Hi Fi listener.&lt;/p&gt;
          &lt;p&gt;The B+ DC voltage flows to the output transformer's primary winding and to the circuit board's three large filter/reservoir capacitors, C3, C4 and C5 and two voltage dropping resistors, R10 &amp;amp; R11. These resistors and capacitors form RC (resistance capacitance) low pass filters that take the lumpy, pulsing DC output of the rectifier tube and smooth it out--the smoother the better. Any waves or ripples left over in the DC power would be added to our audio signal and heard as hum in the preamp and power tubes. These big capacitors also function as current reservoirs that help feed the amp during high demand. The hydraulic equivalent of a filter capacitor is a hydraulic accumulator. The '16¬µF 475V' written on the cap is its rating of 16 micro Farads and 475 volts. The '10K 2W' written on resistor R10 is its rating of 10,000 ohms and 2 watts. Here's an online RC Ripple Filter Calculator.&lt;/p&gt;
          &lt;p&gt;The voltage dropping resistors separate the amp's power into three power supply nodes, B+1, B+2 and B+3. The 360 volts DC from the rectifier is B+1 then it's stepped down to 325 volts DC (B+2) then to 250 volts DC (B+3). The 360 volts DC B+1 direct from the rectifier is fed to the output transformer's primary input which flows on to the power tube plates. The 325 volts DC B+2 is connected to the power tube pin 4--the screen grid. The 250 volts DC B+3 is used to power the preamp tube. The filter capacitors and voltage dropping resistors also decouple the three B+ power nodes to prevent interaction, feedback and oscillation between the preamp stages and power tube. With no guitar signal present the 'idle' voltage at the V1 preamp tube's plate pins 1 and 6 will be around 170 volts DC after flowing through the Load Resistors R5 and R7.&lt;/p&gt;
          &lt;head&gt;How Chokes Work&lt;/head&gt;
          &lt;p&gt;Although the Champ does not use a choke many amps do use them to filter the power supply. Typically the choke is placed between the power tube plate and power tube screen power nodes. This is done as a cost savings measure. A choke would have to be very large and expensive to filter the entire power supply for a 50 or 100 watt amplifier.&lt;/p&gt;
          &lt;p&gt;When electrical current flows through a wire it creates a magnetic field around the wire. Chokes are inductors that use this magnetic field to reduce changes in voltage and current. When no current flows through a wire (you can have voltage but no current) there is no magnetic field generated around the wire. When current increases some of the current will be used to grow a magnetic field around the wire. When current decreases the magnetic field shrinks and the magnetic energy is converted into electrical current. These inductor properties "fight" current changes.&lt;/p&gt;
          &lt;p&gt;A choke is simply one long wire wound in many loops. A choke will have two leads which are simply the two ends of the one long wire. The wire is usually looped around an iron core which makes it work better. Looping the wire increases the effect of the induced magnetic field ("inductor" comes from the word "induced").&lt;/p&gt;
          &lt;p&gt;When power supply voltage ripple flows through a choke, the choke "fights" the ripple. As ripple voltage increases, ripple current increases through the choke. The choke will convert some of the current increase into a magnetic field. The choke's magnetic field is stored energy. As the power supply ripple voltage decreases the choke's magnetic field collapses and converts into current. So increasing voltage and current are cut, and decreasing voltage and current are reinforced which reduces the amplitude of voltage ripple.&lt;/p&gt;
          &lt;p&gt;This simple looped wire is a small air core inductor.&lt;/p&gt;
          &lt;p&gt;Inductors in AC circuits work the same way. Inductance "fights" changes in current and AC audio signals are made up of voltage and current changes. A small inductor can remove high frequencies. A larger value inductor can remove medium and high frequencies. A very high value inductor, like the choke in power supplies, can remove all audio frequencies.&lt;/p&gt;
          &lt;head&gt;Amp Total Power Usage&lt;/head&gt;
          &lt;p&gt;How is it that the 5F1 Champ uses 0.75 amps of 6.3 volt current, 2 amps of 5 volt current and 42ma of high voltage current and yet it uses a 2 amp fuse? It's due to power conversion.&lt;/p&gt;
          &lt;p&gt;This is the power conversion for the 5F1 Champ&lt;/p&gt;
          &lt;p&gt;First we will convert the current from amps to watts:&lt;/p&gt;
          &lt;p&gt;The Champ's 5Y3 rectifier tube datasheet shows it uses 2 amps of 5v heater current: 2a x 5v = 10 watts (this is also be called 10 VA)&lt;/p&gt;
          &lt;p&gt;The 6V6GT power tube datasheet shows it 0.45 amps of 6.3v heater current: 0.45a x 6.3v = 2.835 watts&lt;/p&gt;
          &lt;p&gt;The 12AX7 datasheet shows it uses 0.3 amps of 6.3v heater current: 0.3a x 6.3v = 1.89 watts&lt;/p&gt;
          &lt;p&gt;The amp uses 42ma of high voltage DC.&lt;/p&gt;
          &lt;p&gt;We have a typical 19v drop across the 470 ohm power tube cathode resistor: 19v / 470 = 40ma&lt;/p&gt;
          &lt;p&gt;We have a 1.5v drop across both of the 12AX7 cathode resistors: 1.5v / 1.5k = 1ma each, 2ma total&lt;/p&gt;
          &lt;p&gt;42ma x 370v = 15.5 watts&lt;/p&gt;
          &lt;p&gt;Total the watts: 10w + 2.835w + 1.89w + 15.5w = 30.225 watts of power used by the power transformer secondaries.&lt;/p&gt;
          &lt;p&gt;Now we convert the secondary watts to primary watts:&lt;/p&gt;
          &lt;p&gt;If our mains voltage is 125 volts then 30.225w / 125v = 0.24 amps of mains current. We can estimate that the transformer looses about 10% for a total of 0.26 amps, so a 2 amp fuse has a lot of headroom for turn-on power surge.&lt;/p&gt;
          &lt;p&gt;If our mains voltage is 240 volts then 30.225w / 240v = 0.13 amps + 0.01 amp efficiency loss for a total of 0.14 amps, so a 1 amp fuse could be used.&lt;/p&gt;
          &lt;p&gt;Well that's it for the 5F1 Champ. It's a great sounding but simple guitar amp. The signal flow is very similar to most other Fender amps, they just have more parts. Really understanding the 5F1 will help you understand other more complex amps.&lt;/p&gt;
          &lt;head&gt;Fender Original 5F1 Layout and Schematic&lt;/head&gt;
          &lt;head&gt;5E3 Tweed Deluxe Annotated Schematic&lt;/head&gt;
          &lt;p&gt;The 5E3 Deluxe is the most common tube amp kit available. It uses two 6V6GT power tubes in a Class AB push-pull configuration. Click the image to view the full size (readable) annotated schematic.&lt;/p&gt;
          &lt;head&gt;5E3 Layout with Signal Flow and Annotations&lt;/head&gt;
          &lt;p&gt;Notice how convoluted the signal path is compared to the schematic. Input jacks are at top right and the speaker jack is bottom center. Click the image to view the full size (readable) annotated layout.&lt;/p&gt;
          &lt;head&gt;The Pinnacle of tweed Amps, the 1959 5F6-A Bassman with Annotations&lt;/head&gt;
          &lt;p&gt;My 5F6-A Bassman amp is the sweetest amp I have ever heard. See this for an explanation of How the Bassman Works.&lt;/p&gt;
          &lt;p&gt;Bonus Info: How Fender multiple guitar input jacks and channel jumpering works&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell/&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://robrobinette.com/How_Amps_Work.htm"/><published>2025-11-12T18:35:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45904161</id><title>Blasting Yeast with UV Light</title><updated>2025-11-12T23:10:12.173597+00:00</updated><content/><link href="https://chillphysicsenjoyer.substack.com/p/results-from-blasting-yeast-with"/><published>2025-11-12T18:46:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45905620</id><title>Making the Clang AST Leaner and Faster</title><updated>2025-11-12T23:10:11.963605+00:00</updated><content>&lt;doc fingerprint="2e39b2fc44c70653"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Making the Clang AST Leaner and Faster&lt;/head&gt;
    &lt;p&gt;Modern C++ codebases ‚Äî from browsers to GPU frameworks ‚Äî rely heavily on templates, and that often means massive abstract syntax trees. Even small inefficiencies in Clang‚Äôs AST representation can add up to noticeable compile-time overhead.&lt;/p&gt;
    &lt;p&gt;This post walks through a set of structural improvements I recently made to Clang‚Äôs AST that make type representation smaller, simpler, and faster to create ‚Äî leading to measurable build-time gains in real-world projects.&lt;/p&gt;
    &lt;p&gt;A couple of months ago, I landed a large patch in Clang that brought substantial compile-time improvements for heavily templated C++ code.&lt;/p&gt;
    &lt;p&gt;For example, in stdexec ‚Äî the reference implementation of the &lt;code&gt;std::execution&lt;/code&gt; feature slated for C++26 ‚Äî the slowest test (&lt;code&gt;test_on2.cpp&lt;/code&gt;) saw a 7% reduction in build time.&lt;/p&gt;
    &lt;p&gt;Also the Chromium build showed a 5% improvement (source).&lt;/p&gt;
    &lt;p&gt;At a high level, the patch makes the Clang AST leaner: it reduces the memory footprint of type representations and lowers the cost of creating and uniquing them.&lt;/p&gt;
    &lt;p&gt;These improvements will ship with Clang 22, expected in the next few months.&lt;/p&gt;
    &lt;head rend="h2"&gt;How elaboration and qualified names used to work&lt;/head&gt;
    &lt;p&gt;Consider this simple snippet:&lt;/p&gt;
    &lt;code&gt;namespace NS {
  struct A {};
}
using T = struct NS::A;
&lt;/code&gt;
    &lt;p&gt;The type of &lt;code&gt;T&lt;/code&gt; (&lt;code&gt;struct NS::A&lt;/code&gt;) carries two pieces of information:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It‚Äôs elaborated ‚Äî the &lt;code&gt;struct&lt;/code&gt;keyword appears.&lt;/item&gt;
      &lt;item&gt;It‚Äôs qualified ‚Äî &lt;code&gt;NS::&lt;/code&gt;acts as a nested-name-specifier.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here‚Äôs how the AST dump looked before this patch:&lt;/p&gt;
    &lt;code&gt;ElaboratedType 'struct NS::A' sugar
`-RecordType 'test::NS::A'
  `-CXXRecord 'A'
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;RecordType&lt;/code&gt; represents a direct reference to the previously declared &lt;code&gt;struct A&lt;/code&gt; ‚Äî a kind of canonical view of the type, stripped of syntactic details like &lt;code&gt;struct&lt;/code&gt; or namespace qualifiers.&lt;/p&gt;
    &lt;p&gt;Those syntactic details were stored separately in an &lt;code&gt;ElaboratedType&lt;/code&gt; node that wrapped the &lt;code&gt;RecordType&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Interestingly, an &lt;code&gt;ElaboratedType&lt;/code&gt; node existed even when no elaboration or qualification appeared in the source (example). This was needed to distinguish between an explicitly unqualified type and one that lost its qualifiers through template substitution.&lt;/p&gt;
    &lt;p&gt;However, this design was expensive: every &lt;code&gt;ElaboratedType&lt;/code&gt; node consumed 48 bytes, and creating one required extra work to uniquify it ‚Äî an important step for Clang‚Äôs fast type comparisons.&lt;/p&gt;
    &lt;head rend="h2"&gt;A more compact representation&lt;/head&gt;
    &lt;p&gt;The new approach removes &lt;code&gt;ElaboratedType&lt;/code&gt; entirely. Instead, elaboration and qualifiers are now stored directly inside &lt;code&gt;RecordType&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The new AST dump for the same example looks like this:&lt;/p&gt;
    &lt;code&gt;RecordType 'struct NS::A' struct
|-NestedNameSpecifier Namespace 'NS'
`-CXXRecord 'A'
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;struct&lt;/code&gt; elaboration now fits into previously unused bits within &lt;code&gt;RecordType&lt;/code&gt;, while the qualifier is tail-allocated when present ‚Äî making the node variably sized.&lt;/p&gt;
    &lt;p&gt;This change both shrinks the memory footprint and eliminates one level of indirection when traversing the AST.&lt;/p&gt;
    &lt;head rend="h2"&gt;Representing &lt;code&gt;NestedNameSpecifier&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt; is Clang‚Äôs internal representation for name qualifiers.&lt;/p&gt;
    &lt;p&gt;Before this patch, it was represented by a pointer (&lt;code&gt;NestedNameSpecifier*&lt;/code&gt;) to a uniqued structure that could describe:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The global namespace (&lt;code&gt;::&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;A named namespace (including aliases)&lt;/item&gt;
      &lt;item&gt;A type&lt;/item&gt;
      &lt;item&gt;An identifier naming an unknown entity&lt;/item&gt;
      &lt;item&gt;A &lt;code&gt;__super&lt;/code&gt;reference (Microsoft extension)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For all but cases (1) and (5), each &lt;code&gt;NestedNameSpecifier&lt;/code&gt; also held a prefix ‚Äî the qualifier to its left.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;::XX
&lt;/code&gt;
    &lt;p&gt;This would be stored as a linked list:&lt;/p&gt;
    &lt;code&gt;[id: XX] -&amp;gt; [type: NestedClassTemplate&amp;lt;T&amp;gt;] -&amp;gt; [type: Class] -&amp;gt; [namespace: Namespace]
&lt;/code&gt;
    &lt;p&gt;Internally, that meant seven allocations totaling around 160 bytes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt;(identifier) ‚Äì 16 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt;(type) ‚Äì 16 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;TemplateSpecializationType&lt;/code&gt;‚Äì 48 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;QualifiedTemplateName&lt;/code&gt;‚Äì 16 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt;(type) ‚Äì 16 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;RecordType&lt;/code&gt;‚Äì 32 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt;(namespace) ‚Äì 16 bytes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The real problem wasn‚Äôt just size ‚Äî it was the uniquing cost. Every prospective node has to be looked up in a hash table for a pre-existing instance.&lt;/p&gt;
    &lt;p&gt;To make matters worse, &lt;code&gt;ElaboratedType&lt;/code&gt; nodes sometimes leaked into these chains, which wasn‚Äôt supposed to happen and led to several long-standing bugs.&lt;/p&gt;
    &lt;head rend="h2"&gt;A new, smarter &lt;code&gt;NestedNameSpecifier&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;After this patch, &lt;code&gt;NestedNameSpecifier&lt;/code&gt; becomes a compact, tagged pointer ‚Äî just one machine word wide.&lt;/p&gt;
    &lt;p&gt;The pointer uses 8-byte alignment, leaving three spare bits. Two bits are used for kind discrimination, and one remains available for arbitrary use.&lt;/p&gt;
    &lt;p&gt;When non-null, the tag bits encode:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A type&lt;/item&gt;
      &lt;item&gt;A declaration (either a &lt;code&gt;__super&lt;/code&gt;class or a namespace)&lt;/item&gt;
      &lt;item&gt;A namespace prefixed by the global scope (&lt;code&gt;::Namespace&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;A special object combining a namespace with its prefix&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When null, the tag bits instead encode:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;An empty nested name (the terminator)&lt;/item&gt;
      &lt;item&gt;The global name&lt;/item&gt;
      &lt;item&gt;An invalid/tombstone entry (for hash tables)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Other changes include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The ‚Äúunknown identifier‚Äù case is now represented by a &lt;code&gt;DependentNameType&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Type prefixes are handled directly in the type hierarchy.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Revisiting the earlier example, after the patch its AST dump becomes:&lt;/p&gt;
    &lt;code&gt;DependentNameType 'Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;::XX' dependent
`-NestedNameSpecifier TemplateSpecializationType 'Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;' dependent
  `-name: 'Namespace::Class::NestedClassTemplate' qualified
    |-NestedNameSpecifier RecordType 'Namespace::Class'
    | |-NestedNameSpecifier Namespace 'Namespace'
    | `-CXXRecord 'Class'
    `-ClassTemplate NestedClassTemplate
&lt;/code&gt;
    &lt;p&gt;This representation now requires only four allocations (156 bytes total):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;DependentNameType&lt;/code&gt;‚Äì 48 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;TemplateSpecializationType&lt;/code&gt;‚Äì 48 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;QualifiedTemplateName&lt;/code&gt;‚Äì 16 bytes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;RecordType&lt;/code&gt;‚Äì 40 bytes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That‚Äôs almost half the number of nodes.&lt;/p&gt;
    &lt;p&gt;While &lt;code&gt;DependentNameType&lt;/code&gt; is larger than the previous 16-byte ‚Äúidentifier‚Äù node, the additional space isn‚Äôt wasted ‚Äî it holds cached answers to common queries such as ‚Äúdoes this type reference a template parameter?‚Äù or ‚Äúwhat is its canonical form?‚Äù.&lt;/p&gt;
    &lt;p&gt;These caches make those operations significantly cheaper, further improving performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping up&lt;/head&gt;
    &lt;p&gt;There‚Äôs more in the patch than what I‚Äôve covered here, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;RecordType&lt;/code&gt;now points directly to the declaration found at creation, enriching the AST without measurable overhead.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;RecordType&lt;/code&gt;nodes are now created lazily.&lt;/item&gt;
      &lt;item&gt;The redesigned &lt;code&gt;NestedNameSpecifier&lt;/code&gt;simplified several template instantiation transforms.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each of these could warrant its own write-up, but even this high-level overview shows how careful structural changes in the AST can lead to tangible compile-time wins.&lt;/p&gt;
    &lt;p&gt;I hope you found this deep dive into Clang‚Äôs internals interesting ‚Äî and that it gives a glimpse of the kind of small, structural optimizations that add up to real performance improvements in large C++ builds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cppalliance.org/mizvekov,/clang/2025/10/20/Making-Clang-AST-Leaner-Faster.html"/><published>2025-11-12T20:02:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45906223</id><title>I built a platform where audiences fund debates between public thinkers</title><updated>2025-11-12T23:10:11.599753+00:00</updated><content>&lt;doc fingerprint="905704d240f3f992"&gt;
  &lt;main&gt;
    &lt;p&gt;Create debates with your favorite thinkers. Shape what gets discussed.&lt;/p&gt;
    &lt;p&gt;Tomorrow at 7PM ‚Ä¢ Hosted by Sarah Chen&lt;/p&gt;
    &lt;p&gt;Join our debate as nutrition experts discuss the controversial topic of seed oils and their impact on human health.&lt;/p&gt;
    &lt;p&gt;Three ways to participate&lt;/p&gt;
    &lt;p&gt;Every ticket directly funds the debates you want to see&lt;/p&gt;
    &lt;p&gt;Your support helps your favorite thinkers earn from sharing their knowledge&lt;/p&gt;
    &lt;p&gt;Be part of making important debates happen on topics you care about&lt;/p&gt;
    &lt;p&gt;$5&lt;/p&gt;
    &lt;p&gt;Make this debate happen&lt;/p&gt;
    &lt;p&gt;$25&lt;/p&gt;
    &lt;p&gt;Make this debate happen&lt;/p&gt;
    &lt;p&gt;$99&lt;/p&gt;
    &lt;p&gt;Make this debate happen&lt;/p&gt;
    &lt;p&gt;Use X Spaces, YouTube, or any other platform&lt;/p&gt;
    &lt;p&gt;Logosive handles all ticketing and payments&lt;/p&gt;
    &lt;p&gt;Earn from every ticket sold&lt;/p&gt;
    &lt;p&gt;Zero upfront cost&lt;/p&gt;
    &lt;p&gt;Audiences are waiting&lt;/p&gt;
    &lt;p&gt;You purchase tickets in advance but will not be charged until after the debate is completed. If a debate is cancelled, you pay nothing.&lt;/p&gt;
    &lt;p&gt;Debaters earn a significant share of ticket revenue based on the agreement with organizers. For popular debates, this can mean $10,000-$100,000+. You also grow your audience and establish thought leadership in your field.&lt;/p&gt;
    &lt;p&gt;Yes! Creating debates is completely free. Logosive only takes a platform fee when tickets are sold and the debate completes successfully. This aligns our incentives - we only make money when you do.&lt;/p&gt;
    &lt;p&gt;Debates happen on platforms you already use: X Spaces, YouTube Live, Zoom, etc. Logosive handles ticketing and payments while you use familiar tools. Before each debate, you'll receive the link to join.&lt;/p&gt;
    &lt;p&gt;Yes! Debates can be created by debaters or hosts. You can create a debate, participate in it, and earn from ticket sales. Of course, you can also create debates without being a debater or host - Logosive supports both options.&lt;/p&gt;
    &lt;p&gt;VIP ticket holders can submit questions for the debaters. Premier and VIP holders vote on which questions should be asked. Questions with the most votes get asked during the debate, so the audience directly shapes the conversation.&lt;/p&gt;
    &lt;p&gt;Every ticket helps make debates happen. Higher tiers let you shape the conversation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://logosive.com"/><published>2025-11-12T20:35:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45906604</id><title>OmniAI (YC W24) Is Hiring Forward Deployed Engineers</title><updated>2025-11-12T23:10:10.869529+00:00</updated><content>&lt;doc fingerprint="37913b7b0d2086c3"&gt;
  &lt;main&gt;
    &lt;p&gt;AI Agents for Commercial Lending&lt;/p&gt;
    &lt;p&gt;Engineering at Omni&lt;lb/&gt; We‚Äôre building the AI-powered infrastructure layer for small business lending. Helping banks and fintechs automate the messy work of collecting documents, filling out financial models, and doing public research on millions of SMBs across the country.&lt;/p&gt;
    &lt;p&gt;There are 34 million small businesses in the U.S., and every one of them needs capital. We‚Äôre making it radically easier for lenders to serve them. At Omni we run everything from initial application, third party data aggregation, OCR and financial data extraction, and continuous borrower communication.&lt;/p&gt;
    &lt;p&gt;You can see a demo of the product here: https://finovate.com/videos/finovatefall-2025-omniai/&lt;/p&gt;
    &lt;p&gt;This role is on site in San Francisco. No exceptions.&lt;/p&gt;
    &lt;p&gt;As a Forward Deployed Engineer (FDE), you‚Äôll work directly with our customers ‚Äî banks, fintechs, and lenders ‚Äî to bring Omni‚Äôs platform to life inside their organizations. You‚Äôll sit alongside their teams, design integrations, and help transform how they operate day-to-day.&lt;/p&gt;
    &lt;p&gt;Expect to:&lt;/p&gt;
    &lt;p&gt;This is a deeply technical and highly visible role. You‚Äôll be both an engineer and an ambassador, shaping how banks adopt AI-first infrastructure&lt;/p&gt;
    &lt;p&gt;There‚Äôs a lot that goes into commercial lending, and we‚Äôre tackling every step of the process. Some of the core concepts will be:&lt;/p&gt;
    &lt;p&gt;You‚Äôll also help bridge the gap between our engineering roadmap and the real-world challenges lenders face.&lt;/p&gt;
    &lt;p&gt;We primarily use **Node, TypeScript, React/Next.js, Postgres, Docker, and K8.**&lt;lb/&gt; We integrate with external systems like Salesforce, Hubspot, nCino, and several bank specific core systems (Jack Henry, Fiserv, etc.). This role also requires willingness to occasionally get your hands dirty with some esoteric banking tech. We‚Äôre talking SOAP APIs, SFTP servers, and the occasional fax machine API.&lt;/p&gt;
    &lt;p&gt;On the AI side, we mainly interface with OpenAI and Gemini models. Customers can deploy Omni either via cloud or VPC, so familiarity with containerization and DevOps is valuable.&lt;/p&gt;
    &lt;p&gt;Competitive Pay &amp;amp; Equity: Attractive salary and meaningful equity packages&lt;/p&gt;
    &lt;p&gt;Health &amp;amp; Wellness: Medical, dental, and vision coverage for you and your family&lt;/p&gt;
    &lt;p&gt;Flexible Time Off: Unlimited PTO and paid holidays&lt;/p&gt;
    &lt;p&gt;Daily Lunch: Team meals provided&lt;/p&gt;
    &lt;p&gt;Real Impact: Own and ship features you believe in.&lt;/p&gt;
    &lt;p&gt;Phone Screen&lt;lb/&gt; Take 30 minutes to chat with one of the founders. Learn a bit about your interests, and share what we‚Äôre working on at Omni. We are looking for people with a strong interest in startups, and would love to hear about prior startup experience. Also really interested in seeing any open source work.&lt;/p&gt;
    &lt;p&gt;Architecture Interview&lt;lb/&gt; A 1 hour call with both founders where we design a hypothetical feature. There‚Äôs no coding involved. Instead we‚Äôll discuss a new feature, and do a collaborative walk though of the architecture required. We want to think about everything from database design to UI.&lt;/p&gt;
    &lt;p&gt;Onsite&lt;lb/&gt; You‚Äôll spend the day working with us at our SF office. Meals will be covered, as well as any travel and accommodation. We‚Äôll spend the day building out an MVP of the feature we planned out during the architecture interview. You'll be using your own computer, and using whatever language/environment you are most comfortable with. By the end of the day we are expecting two things:&lt;/p&gt;
    &lt;p&gt;At Omni, we‚Äôre rebuilding how banks and fintechs lend to small businesses.&lt;/p&gt;
    &lt;p&gt;There are 34 million small businesses in the U.S., yet getting a loan still means weeks of emails, PDFs, and paperwork. Every deal starts with a pile of documents ‚Äî tax returns, bank statements, corporate filings, and contracts that no one wants to read but everyone depends on.&lt;/p&gt;
    &lt;p&gt;Omni is changing that. We work directly with lenders to modernize the entire stack, from document intake to underwriting, and we‚Äôre doing it with a small, fast-moving team that ships real systems used in production every day.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/omniai/jobs/fuTMf2w-forward-deployed-engineer"/><published>2025-11-12T21:00:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45907259</id><title>Homebrew no longer allows bypassing Gatekeeper for unsigned/unnotarized software</title><updated>2025-11-12T23:10:09.972472+00:00</updated><content>&lt;doc fingerprint="760419b45cb6b368"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 10.7k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;head rend="h3"&gt;Verification&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; This issue's title and/or description do not reference a single formula e.g. &lt;code&gt;brew install wget&lt;/code&gt;. If they do, open an issue at https://github.com/Homebrew/homebrew-core/issues/new/choose instead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Provide a detailed description of the proposed feature&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;--no-quarantine&lt;/code&gt; is used to forcibly bypass Gatekeeper, which is a built-in macOS security mechanism. This is used to run unsigned/unnotarized applications.&lt;/p&gt;
    &lt;p&gt;macOS Tahoe is the final release to support Intel systems, and last year Apple updated macOS runtime protection to make it harder to override Gatekeeper. Macs with Apple silicon also don't "permit native arm64 code to execute unless a valid signature is attached". Finally, we are ending support for all casks that fail Gatekeeper checks on September 1st, 2026.&lt;/p&gt;
    &lt;p&gt;With the above in mind, it's time to deprecate the &lt;code&gt;--no-quarantine&lt;/code&gt; flag from &lt;code&gt;brew&lt;/code&gt;. It intentionally bypasses macOS security mechanisms, which we already actively discourage. Deprecating now will give a decent lead time for users using it to come up with another solution or adjust their workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is the motivation for the feature?&lt;/head&gt;
    &lt;p&gt;Intel support is coming to an end from both Apple and Homebrew. This flag is primarily used to override a macOS security mechanism, which we do not want to encourage. Since we are requiring casks fulfill Gatekeeper checks next year, there is no reason to keep this flag.&lt;/p&gt;
    &lt;head rend="h3"&gt;How will the feature be relevant to at least 90% of Homebrew users?&lt;/head&gt;
    &lt;p&gt;We will provide a safer experience for our users, and stop making it easier to bypass OS-level security.&lt;/p&gt;
    &lt;head rend="h3"&gt;What alternatives to the feature have been considered?&lt;/head&gt;
    &lt;p&gt;None. Macs with Apple silicon are the platform that will be supported in the future, and Apple is making it harder to bypass Gatekeeper as is.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Homebrew/brew/issues/20755"/><published>2025-11-12T21:50:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45907541</id><title>Marble: A Multimodal World Model</title><updated>2025-11-12T23:10:09.611771+00:00</updated><content>&lt;doc fingerprint="1815cb1fadd45c6f"&gt;
  &lt;main&gt;
    &lt;p&gt;November 12, 2025Marble, our frontier multimodal world model, is available to everyone starting today&lt;/p&gt;
    &lt;head rend="h1"&gt;Marble: A Multimodal World Model&lt;/head&gt;
    &lt;p&gt;Spatial intelligence is the next frontier in AI, demanding powerful world models to realize its full potential. World models should reconstruct, generate, and simulate 3D worlds; and allow both humans and agents to interact with them. Spatially intelligent world models will transform a wide variety of industries over the coming years.&lt;/p&gt;
    &lt;p&gt;Two months ago we shared a preview of Marble, our World Model that creates 3D worlds from image or text prompts. Since then, Marble has been available to an early set of beta users to create 3D worlds for themselves.&lt;/p&gt;
    &lt;p&gt;Today we are making Marble, a first-in-class generative multimodal world model, generally available for anyone to use. We have also drastically expanded Marble's capabilities, and are excited to highlight them here:&lt;/p&gt;
    &lt;p&gt;Multimodal Marble: Marble is now massively multimodal. Marble can create 3D worlds from text, images, video, or coarse 3D layouts; Marble also lets you interactively edit, expand, and combine worlds. Once generated, 3D worlds can be exported as Gaussian splats, meshes, or videos. These new capabilities let users create and edit worlds with fine-grained control; and makes those worlds more useful than ever before.&lt;/p&gt;
    &lt;p&gt;Marble Labs: We are launching Marble Labs, a creative hub where imagination meets experimentation. It is where artists, engineers, and designers push the boundaries of world models, showcasing bold ideas, real-world workflows, and new possibilities across gaming, VFX, design, robotics, and beyond. Marble Labs is also home to in-depth case studies, tutorials, and documentation that give anyone the tools to learn, build, and share their own 3D worlds.&lt;/p&gt;
    &lt;p&gt;Sign up at marble.worldlabs.ai and start creating worlds for yourself!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Marble World Model&lt;/head&gt;
    &lt;p&gt;Our human experience of the world is inherently multimodal: we use all of our senses to make sense of the world around us. We integrate sight, sound, touch, and language to build up a mental model of the outside world; these different representations work together, enriching and reinforcing each other to let us reason about the world and act within it.&lt;/p&gt;
    &lt;p&gt;World models should work similarly. They should be massively multimodal, able to lift whatever input signals are available into a full 3D world, and they should be able to iteratively update their understanding of the world as new information becomes available.&lt;/p&gt;
    &lt;p&gt;Marble is the first of its kind - a next-generation world model making strides toward this vision. It can now create 3D worlds from a wide variety of input types, and lets users iteratively edit or expand worlds.&lt;/p&gt;
    &lt;p&gt;Marble's new capabilities let you dive as deep as you want in controlling your generated worlds. You can quickly create full 3D worlds from a simple image or text prompt or interactively edit worlds in both 2D and 3D, bringing to life a precise vision of a world in your mind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Text and Image to World&lt;/head&gt;
    &lt;p&gt;To start, Marble can create a full 3D world from a single image or a short text prompt. This is the simplest and easiest way to create worlds. Marble can generate worlds with a wide variety of scene types and artistic styles.&lt;/p&gt;
    &lt;p&gt;Image prompts make it easy to combine Marble with other AI tools. You can generate images with your favorite image generation model, then bring it to Marble to lift it to a full 3D world.&lt;/p&gt;
    &lt;p&gt;Text and image prompts are intuitive and powerful, but limited in creative control: Marble must invent all the details of the world that are not present in the input text or image prompt. This is often magical; but sometimes you may want to steer Marble more directly toward a desired world.&lt;/p&gt;
    &lt;head rend="h2"&gt;Multi-Image and Video to World&lt;/head&gt;
    &lt;p&gt;An easy way to create worlds with more creative control is multi-image prompting. Marble can accept different prompt images for different parts of the world, stitching them together into a unified 3D world.&lt;/p&gt;
    &lt;p&gt;Multi-image prompts let you create worlds with more precision. Unlike text or single-image prompts where Marble must invent all parts of the world not present in the prompt, with multi-image prompts you can control what the generated world will look like from different angles.&lt;/p&gt;
    &lt;p&gt;This leads to a brand-new workflow for generating worlds. You can use your favorite image generation tool to iterate separately on the input views, and Marble will lift them into full 3D worlds while also adding seamless transitions between the input views.&lt;/p&gt;
    &lt;p&gt;Multi-image prompts can also be used to create worlds inspired by real-world spaces. Marble can input a few photos or a short video depicting a real-world location from different angles, and it will combine them to generate a 3D world with elements of the real-world space.&lt;/p&gt;
    &lt;head rend="h2"&gt;World Editing&lt;/head&gt;
    &lt;p&gt;The creative process is highly iterative for many users. Often, generating a world is only the start of a creative journey. Seeing a generated 3D world often kicks off a dozen more ideas for changing it or improving it.&lt;/p&gt;
    &lt;p&gt;Marble includes AI-native world editing tools. Edits can be small and local: remove an object, touch up an area. They can also be more drastic: swap objects, change the visual style, or re-structure large parts of the world. This gives a new level of fine-grained control to the world creation process.&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;World editing lets you re-imagine the same space in endless different ways.&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;head rend="h2"&gt;Chisel: Sculpting Worlds in 3D&lt;/head&gt;
    &lt;p&gt;Marble's multimodal inputs and editing features give a lot of control over your generated 3D worlds. But sometimes, creating the world exactly as you see it in your mind's eye requires finer-grained control over the scene layout or exact sizes and positions of objects.&lt;/p&gt;
    &lt;p&gt;For these situations we are introducing Chisel, an AI-native tool to sculpt Marble worlds directly in 3D.&lt;/p&gt;
    &lt;p&gt;Chisel is a new experimental editing mode for advanced users to create 3D worlds. It lets you lay out the coarse structure of your world in 3D using coarse 3D shapes like boxes or planes, or importing existing 3D assets into the scene.&lt;/p&gt;
    &lt;p&gt;After laying out the coarse 3D scene, you can add a text prompt to describe the visual style of the scene, or additional elements not present in the coarse layout. Marble will combine these inputs to give you a fully detailed 3D world.&lt;/p&gt;
    &lt;p&gt;Chisel decouples structure from style. The coarse 3D scene determines the world's structure, while the text prompt controls its overall style. The two can be mixed in any combination, adding a whole new dimension of control to world generation.&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Coarse 3D After&lt;/p&gt;
    &lt;p&gt;Coarse 3D Before&lt;/p&gt;
    &lt;p&gt;Generated World After&lt;/p&gt;
    &lt;p&gt;Generated World Before&lt;/p&gt;
    &lt;p&gt;The coarse 3D scene can be as simple or complex as you want. In addition to building the coarse 3D scene out of basic blocks and walls, you can import existing 3D assets of objects. Objects will be restyled based on the text prompt to give a cohesive 3D world.&lt;/p&gt;
    &lt;p&gt;Varying the text prompt can give rise to 3D worlds with drastically different visual styles and appearances that all share a common structure determined by the coarse 3D scene.&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Large Worlds by Expanding and Composing&lt;/head&gt;
    &lt;p&gt;Sometimes bigger really is better. Larger worlds give more possibilities, more space, more room for your creativity to shine. Marble offers two ways to make bigger worlds than ever before.&lt;/p&gt;
    &lt;p&gt;After a world has been generated, Marble allows one-step expansion to make it larger. You are in control of this process: you can select a region of the world to be expanded, and Marble will create more content to fill the selected region.&lt;/p&gt;
    &lt;p&gt;Expansion can make worlds larger. Regions of the world that previously broke down into artifacts can become crisp and clean after expansion. Expansion can also be used to add detail to targeted regions of a world. Sometimes the back of a table or the far corner of a room is not a crisp as the room's center; expanding the world in that region can improve it.&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;In addition to generating individual worlds, you can compose any number of worlds to build out extremely large spaces with Marble's composer mode. This composition is entirely under your control: you can choose exactly which worlds to compose, and exactly how to lay them out relative to each other. Composing is yet another way to build worlds that follow your creative vision.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exporting Worlds to 3D and Video&lt;/head&gt;
    &lt;p&gt;After creating a world with Marble you have many options to export it for incorporation into downstream projects.&lt;/p&gt;
    &lt;p&gt;Gaussian splats are the highest-fidelity representation for Marble worlds. They represent 3D scenes as a large set of semitransparent particles. You can render Gaussian splats in the browser using Spark, our open-source cross-platform renderer integrated with THREE.js.&lt;/p&gt;
    &lt;p&gt;Marble worlds can also be exported as triangle meshes. Marble can generate both collider meshes, which are low-fidelity meshes intended for coarse physics simulation; and high-quality meshes which are intended to match the visual fidelity of Gaussian splats as closely as possible. Exporting worlds as meshes lets them interoperate with many industry-standard tools.&lt;/p&gt;
    &lt;p&gt;Mesh&lt;/p&gt;
    &lt;p&gt;Splats&lt;/p&gt;
    &lt;p&gt;Mesh with lighting&lt;/p&gt;
    &lt;p&gt;Mesh with lighting&lt;/p&gt;
    &lt;p&gt;Marble worlds exist in full 3D, but sometimes a video is the best way to share a world. You can use Marble to render generated worlds to videos with pixel-accurate camera control, letting you frame every shot just as you imagine it. In fact, nearly all the videos in this post were generated directly from Marble.&lt;/p&gt;
    &lt;p&gt;Marble can also enhance exported videos. Enhanced videos can add detail, remove artifacts, and add dynamic elements to the scene, while maintaining pixel-perfect camera control and adhering to the structure of the generated 3D world.&lt;/p&gt;
    &lt;p&gt;Enhanced Video&lt;/p&gt;
    &lt;p&gt;Original Video&lt;/p&gt;
    &lt;p&gt;Enhanced Video&lt;/p&gt;
    &lt;p&gt;Original Video&lt;/p&gt;
    &lt;p&gt;Enhanced Video&lt;/p&gt;
    &lt;p&gt;Original Video&lt;/p&gt;
    &lt;head rend="h2"&gt;Marble Labs: A Glimpse of Future Possibilities&lt;/head&gt;
    &lt;p&gt;While flexing your creativity in Marble, Marble Labs may further inspire your imagination. This is where artists, engineers, and designers are already shaping what comes next. From cinematic filmmaking and interactive worlds to robotics simulations and therapeutic environments, these projects show how Marble is transforming imagination into reality. Each one reflects a new way of building with world models, both creative and technical. Explore Marble Labs to see what others are creating and discover how you can start building your own worlds today.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Marble to Spatial Intelligence&lt;/head&gt;
    &lt;p&gt;Marble is a state-of-the-art generative world model. Today it lets you create worlds from diverse input types, edit them, expand them, and export them. These capabilities give you unprecedented levels of control when creating worlds, and are already enabling a wide variety of creative use cases across industries.&lt;/p&gt;
    &lt;p&gt;But Marble is just a step on our journey toward spatial intelligence. Going forward, a key opportunity is interactivity. Future world models will let humans and agents alike interact with generated worlds in new ways, unlocking even more use cases in simulation, robotics, and beyond.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try Marble Today&lt;/head&gt;
    &lt;p&gt;Marble is available today at marble.worldlabs.ai. Sign up now and start creating worlds!&lt;/p&gt;
    &lt;p&gt;If you are excited about this vision and want to help us build it, join us!&lt;/p&gt;
    &lt;head rend="h2"&gt;Read More&lt;/head&gt;
    &lt;p&gt;November 10, 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;From Words to Worlds: Spatial Intelligence is AI‚Äôs Next Frontier&lt;/head&gt;
    &lt;p&gt;A manifesto piece explaining what spatial intelligence is, why it matters, and how we‚Äôre building the world models that will unlock it‚Äîwith impact that will reshape creativity, embodied intelligence, and human progress.&lt;/p&gt;
    &lt;p&gt;October 16, 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;RTFM: A Real-Time Frame Model&lt;/head&gt;
    &lt;p&gt;A research preview of RTFM, a new generative world model that generates video in real-time as you interact with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.worldlabs.ai/blog/marble-world-model"/><published>2025-11-12T22:11:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45907839</id><title>Jasmine: A Simple, Performant and Scalable Jax-Based World Modeling Codebase</title><updated>2025-11-12T23:10:09.438166+00:00</updated><content>&lt;doc fingerprint="4c9ca52ac4fbc0af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 30 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:While world models are increasingly positioned as a pathway to overcoming data scarcity in domains such as robotics, open training infrastructure for world modeling remains nascent. We introduce Jasmine, a performant JAX-based world modeling codebase that scales from single hosts to hundreds of accelerators with minimal code changes. Jasmine achieves an order-of-magnitude faster reproduction of the CoinRun case study compared to prior open implementations, enabled by performance optimizations across data loading, training and checkpointing. The codebase guarantees fully reproducible training and supports diverse sharding configurations. By pairing Jasmine with curated large-scale datasets, we establish infrastructure for rigorous benchmarking pipelines across model families and architectural ablations.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.27002"/><published>2025-11-12T22:35:29+00:00</published></entry></feed>