<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-06T20:11:02.764025+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45488261</id><title>Structured Procrastination (1995)</title><updated>2025-10-06T20:11:12.205541+00:00</updated><content>&lt;doc fingerprint="161270546c3194f9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author practices jumping rope with seaweed while work awaits.&lt;/p&gt;
    &lt;p&gt;``. . . anyone can do any amount of work, provided it isn't the work he is supposed to be doing at that moment." -- Robert Benchley, in Chips off the Old Benchley, 1949&lt;/p&gt;
    &lt;p&gt;I have been intending to write this essay for months. Why am I finally doing it? Because I finally found some uncommitted time? Wrong. I have papers to grade, textbook orders to fill out, an NSF proposal to referee, dissertation drafts to read. I am working on this essay as a way of not doing all of those things. This is the essence of what I call structured procrastination, an amazing strategy I have discovered that converts procrastinators into effective human beings, respected and admired for all that they can accomplish and the good use they make of time. All procrastinators put off things they have to do. Structured procrastination is the art of making this bad trait work for you. The key idea is that procrastinating does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing; they do marginally useful things, like gardening or sharpening pencils or making a diagram of how they will reorganize their files when they get around to it. Why does the procrastinator do these things? Because they are a way of not doing something more important. If all the procrastinator had left to do was to sharpen some pencils, no force on earth could get him do it. However, the procrastinator can be motivated to do difficult, timely and important tasks, as long as these tasks are a way of not doing something more important.&lt;/p&gt;
    &lt;p&gt;Structured procrastination means shaping the structure of the tasks one has to do in a way that exploits this fact. The list of tasks one has in mind will be ordered by importance. Tasks that seem most urgent and important are on top. But there are also worthwhile tasks to perform lower down on the list. Doing these tasks becomes a way of not doing the things higher up on the list. With this sort of appropriate task structure, the procrastinator becomes a useful citizen. Indeed, the procrastinator can even acquire, as I have, a reputation for getting a lot done.&lt;/p&gt;
    &lt;p&gt;The most perfect situation for structured procrastination that I ever had was when my wife and I served as Resident Fellows in Soto House, a Stanford dormitory. In the evening, faced with papers to grade, lectures to prepare, committee work to be done, I would leave our cottage next to the dorm and go over to the lounge and play ping-pong with the residents, or talk over things with them in their rooms, or just sit there and read the paper. I got a reputation for being a terrific Resident Fellow, and one of the rare profs on campus who spent time with undergraduates and got to know them. What a set up: play ping pong as a way of not doing more important things, and get a reputation as Mr. Chips.&lt;/p&gt;
    &lt;p&gt;Procrastinators often follow exactly the wrong tack. They try to minimize their commitments, assuming that if they have only a few things to do, they will quit procrastinating and get them done. But this goes contrary to the basic nature of the procrastinator and destroys his most important source of motivation. The few tasks on his list will be by definition the most important, and the only way to avoid doing them will be to do nothing. This is a way to become a couch potato, not an effective human being.&lt;/p&gt;
    &lt;p&gt;At this point you may be asking, "How about the important tasks at the top of the list, that one never does?" Admittedly, there is a potential problem here.&lt;/p&gt;
    &lt;p&gt;The trick is to pick the right sorts of projects for the top of the list. The ideal sorts of things have two characteristics, First, they seem to have clear deadlines (but really don't). Second, they seem awfully important (but really aren't). Luckily, life abounds with such tasks. In universities the vast majority of tasks fall into this category, and I'm sure the same is true for most other large institutions. Take for example the item right at the top of my list right now. This is finishing an essay for a volume in the philosophy of language. It was supposed to be done eleven months ago. I have accomplished an enormous number of important things as a way of not working on it. A couple of months ago, bothered by guilt, I wrote a letter to the editor saying how sorry I was to be so late and expressing my good intentions to get to work. Writing the letter was, of course, a way of not working on the article. It turned out that I really wasn't much further behind schedule than anyone else. And how important is this article anyway? Not so important that at some point something that seems more important won't come along. Then I'll get to work on it.&lt;/p&gt;
    &lt;p&gt;Another example is book order forms. I write this in June. In October, I will teach a class on Epistemology. The book order forms are already overdue at the book store. It is easy to take this as an important task with a pressing deadline (for you non-procrastinators, I will observe that deadlines really start to press a week or two after they pass.) I get almost daily reminders from the department secretary, students sometimes ask me what we will be reading, and the unfilled order form sits right in the middle of my desk, right under the wrapping from the sandwich I ate last Wednesday. This task is near the top of my list; it bothers me, and motivates me to do other useful but superficially less important things. But in fact, the book store is plenty busy with forms already filed by non-procrastinators. I can get mine in mid-Summer and things will be fine. I just need to order popular well-known books from efficient publishers. I will accept some other, apparently more important, task sometime between now and, say, August 1st. Then my psyche will feel comfortable about filling out the order forms as a way of not doing this new task.&lt;/p&gt;
    &lt;p&gt;The observant reader may feel at this point that structured procrastination requires a certain amount of self-deception, since one is in effect constantly perpetrating a pyramid scheme on oneself. Exactly. One needs to be able to recognize and commit oneself to tasks with inflated importance and unreal deadlines, while making oneself feel that they are important and urgent. This is not a problem, because virtually all procrastinators have excellent self-deceptive skills also. And what could be more noble than using one character flaw to offset the bad effects of another?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://structuredprocrastination.com"/><published>2025-10-06T06:35:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488441</id><title>Flightcontrol: A PaaS that deploys to your AWS account</title><updated>2025-10-06T20:11:11.915757+00:00</updated><content>&lt;doc fingerprint="bd1863730f143a8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Build your dreams&lt;lb/&gt;on AWS, effortlessly&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flightcontrol is a PaaS that deploys to your AWS account&lt;/item&gt;
      &lt;item&gt;Servers, Lambdas, workers, crons, static sites, databases &amp;amp; Redis&lt;/item&gt;
      &lt;item&gt;We are your devops team with 24/7 emergency support&lt;/item&gt;
      &lt;item&gt;Companies outgrowing other PaaS or homegrown AWS switch to Flightcontrol to regain reliability, security, and scalability at a reasonable cost&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Over $1 million of AWS resources under management&lt;/head&gt;
    &lt;head rend="h2"&gt;The old way&lt;/head&gt;
    &lt;p&gt;"Our AWS setup is consuming too much time &amp;amp; attention"&lt;/p&gt;
    &lt;p&gt;Your team gets bogged down with complex Terraform scripts, manual configuration, and endless CI/CD pipelines. You could hire DevOps engineers, but they are expensive and it's hard to find really good ones. It will do the job, but now your developer productivity suffers as they are dependent on the infra team to make changes or spin up new services.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new way&lt;/head&gt;
    &lt;p&gt;"Flightcontrol gives our team the power to manage bare metal AWS without needing to hire specific talent"&lt;/p&gt;
    &lt;p&gt;Save thousands of dollars and months of time because Flightcontrol significantly reduces DevOps overhead. It empowers your developers ship like crazy without needing AWS or infrastructure expertise. Your developers gain full autonomy while benefiting from AWS's unmatched scalability, reliability, and flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simple, powerful deployments without worrying about low level AWS config&lt;/head&gt;
    &lt;p&gt;We take the best AWS services, put together a best-in-class setup, and make them super easy to use.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your AWS account to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your git repository to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Define your services (servers, APIs, databases, etc)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flightcontrol fully automates infrastructure provisioning, CI/CD, and deployments. All within your own AWS account where you retain full visibility and control&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Flightcontrol simplifies your deployments by providing a user-friendly dashboard designed specifically for developers, not DevOps engineers. Forget the frustration of navigating AWS’s overwhelming and fragmented console. With Flightcontrol, you see your entire infrastructure clearly in one intuitive interface, allowing you to manage deployments, services, and scaling with confidence.&lt;/p&gt;
    &lt;p&gt;Deployments become as easy as a simple git push or webhook integration. Flightcontrol handles your CI/CD automation entirely, enabling your team to deploy confidently and quickly without maintaining complex Terraform or CDK scripts. You get the simplicity of platforms like Vercel or Heroku, paired with the raw power, near perfect reliability, and immense flexibility of AWS. Your developers can ship faster and stay focused on building great products.&lt;/p&gt;
    &lt;head rend="h2"&gt;Serve all your use-cases from a single platform&lt;/head&gt;
    &lt;p&gt;Static Sites&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;S3&lt;/item&gt;
      &lt;item&gt;Lambda@Edget&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Web &amp;amp; GPU Servers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Network Servers&lt;/p&gt;
    &lt;p&gt;UDP &amp;amp; TCP with multiple ports&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Private Servers&lt;/p&gt;
    &lt;p&gt;HTTP, HTTPS, TCP, UDP&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Background Workers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Job Runner&lt;/p&gt;
    &lt;p&gt;Cron &amp;amp; API triggered jobs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lambda&lt;/p&gt;
    &lt;p&gt;With function url support&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lambda&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Databases&lt;/p&gt;
    &lt;p&gt;Postgres, MySQL, MariaDB&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RDS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Redis&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ElastiCache&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;S3 Bucket&lt;/p&gt;
    &lt;p&gt;File &amp;amp; object storage&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;S3&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Significantly reduce your DevOps overhead&lt;/head&gt;
    &lt;p&gt;Flightcontrol becomes your devops team. We guarantee support for everything managed through Flightcontrol. You don't have to worry about anything that's amiss in AWS — let us know and we'll fix it ASAP (but rest assured, this almost never happens!).&lt;/p&gt;
    &lt;p&gt;Get 24/7 emergency support on our Business plan for ultimate peace of mind.&lt;/p&gt;
    &lt;p&gt;Need some extra devops support beyond the Flightcontrol platform? We offer DevOps Support Add-ons to supplement your team. This is ideal for teams that need extra infrastructure help but don't need a full time devops engineer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ephemeral preview environments&lt;/head&gt;
    &lt;p&gt;The fastest moving engineering teams use preview environments to view changes before committing them.&lt;/p&gt;
    &lt;p&gt;Flightcontrol can automatically spin up temporary infrastructure for each pull request and then clean it up when the pull request is merged.&lt;/p&gt;
    &lt;p&gt;Preview environments mean no more conflicts on staging, no more delays, and significantly fewer bugs in production. Enable all stakeholders to see and test changes before merging code.&lt;/p&gt;
    &lt;p&gt;Each preview environment is cost-optimized, intelligently sharing resources such as load balancers and RDS instances, ensuring you maintain control over spending. Database seeding per environment means realistic testing scenarios, catching issues before they go live. Your team will experience faster releases, fewer bugs, and smoother collaboration.&lt;/p&gt;
    &lt;head rend="h2"&gt;World class support with 6 minute median response time&lt;/head&gt;
    &lt;p&gt;Imagine never worrying about infrastructure issues again. Flightcontrol becomes your DevOps team, providing exceptional, responsive support. With guaranteed smooth operations for everything managed by Flightcontrol, you can rest easy knowing your infrastructure is covered by experts around the clock.&lt;/p&gt;
    &lt;p&gt;With a median first response time of 6 minutes, our dedicated support team is accessible via email and Slack, ensuring rapid resolution whenever you need it. Need some extra DevOps help? Don’t hire full time! Our DevOps support add-on gives you expert guidance tailored specifically to your unique requirements, removing the need to hire a full-time DevOps engineer.&lt;/p&gt;
    &lt;p&gt;Visual Config? Code config? Both!&lt;/p&gt;
    &lt;p&gt;Infrastructure-as-code designed for moving fast&lt;/p&gt;
    &lt;p&gt;Deploy close to your users&lt;/p&gt;
    &lt;p&gt;Choose today from 28 AWS regions. Multi-region deploys in early access.&lt;/p&gt;
    &lt;p&gt;Observability&lt;/p&gt;
    &lt;p&gt;Stay on top of things with our metrics and alerts, or add sidecars like Datadog.&lt;/p&gt;
    &lt;p&gt;Nixpacks&lt;/p&gt;
    &lt;p&gt;Build any language or framework without writing a Dockerfile. The modern successor to Heroku buildpacks.&lt;/p&gt;
    &lt;p&gt;Stale while revalidate + Next.js &amp;amp; Svelte ISR&lt;/p&gt;
    &lt;p&gt;Blazing fast speed with CloudFront's stale-while-revalidate support&lt;/p&gt;
    &lt;p&gt;AWS cost transparency&lt;/p&gt;
    &lt;p&gt;Understand exactly where the dollars are going by project, environment, and service.&lt;/p&gt;
    &lt;p&gt;Preview environments, fullstack&lt;/p&gt;
    &lt;p&gt;Deploy your all your services for every pull request to a cost optimized environment.&lt;/p&gt;
    &lt;p&gt;Bring your monoliths and your microservices&lt;/p&gt;
    &lt;p&gt;Your architecture will work with us, no matter how big or small.&lt;/p&gt;
    &lt;p&gt;Your domain, with https&lt;/p&gt;
    &lt;p&gt;Connect your domain with a couple DNS records. No messing with SSL certificates.&lt;/p&gt;
    &lt;p&gt;Peak edge performance&lt;/p&gt;
    &lt;p&gt;World-class performance with CloudFront, Stale-While-Revalidate, and edge-based Next.js ISR. Even multi-region.&lt;/p&gt;
    &lt;p&gt;Monorepos, with watch paths&lt;/p&gt;
    &lt;p&gt;Put all your stuff in one place, that's fine with us. And only deploy changed files with watch paths.&lt;/p&gt;
    &lt;p&gt;Maintenance mode&lt;/p&gt;
    &lt;p&gt;Block traffic to your app while you're doing something important (we assume).&lt;/p&gt;
    &lt;p&gt;API &amp;amp; deploy hooks&lt;/p&gt;
    &lt;p&gt;Trigger deploys from CI. More thorough API is coming, we promise.&lt;/p&gt;
    &lt;p&gt;Notifications&lt;/p&gt;
    &lt;p&gt;Get alerted in Slack or email when things go south. Or when they go north.&lt;/p&gt;
    &lt;p&gt;Rollback&lt;/p&gt;
    &lt;p&gt;It happens to the best of us, so we've got your back when the inevitable happens.&lt;/p&gt;
    &lt;p&gt;Private VPC networking&lt;/p&gt;
    &lt;p&gt;Each environment is deployed to a new or existing VPC. Get private services and private databases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deploy every language globally&lt;/head&gt;
    &lt;p&gt;Every language and framework works beautifully in the Flightcontrol universe. Welcome home.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Connect your AWS and Git Repo with 1-click&lt;/head&gt;
    &lt;p&gt;Everything is deployed to your AWS account where you have full ownership and control. Without the frustrating limitations of black box PaaS.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Zero-config or customize to your heart's content&lt;/head&gt;
    &lt;p&gt;It will often "just work", but we also support many customizations like pulling from image registries or fine-tuning autoscaling.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Automatic deploys with git push or webhook&lt;/head&gt;
    &lt;p&gt;Fully automated infra provisioning, builds and deploys. All without having to use the AWS console.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trusted by thousands of developers&lt;/head&gt;
    &lt;p&gt;We've got your back with the most helpful, responsive support in the industry&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise grade no matter your size&lt;/head&gt;
    &lt;p&gt;Customers of all sizes rely on us for production, from startups to large enterprises&lt;/p&gt;
    &lt;head rend="h3"&gt;Save a fortune on devops costs&lt;/head&gt;
    &lt;p&gt;We delay the need for infra engineers by a few years. And then we enable them to focus on more meaningful work&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.flightcontrol.dev/"/><published>2025-10-06T07:07:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489533</id><title>Nobel Prize in Physiology or Medicine 2025</title><updated>2025-10-06T20:11:11.593883+00:00</updated><content>&lt;doc fingerprint="9384913f192e615e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Press release&lt;/head&gt;
    &lt;p&gt;English&lt;lb/&gt;English (pdf)&lt;lb/&gt;Swedish&lt;lb/&gt;Swedish (pdf)&lt;/p&gt;
    &lt;p&gt;6 October 2025&lt;/p&gt;
    &lt;p&gt;The Nobel Assembly at Karolinska Institutet has decided to award the 2025 Nobel Prize in Physiology or Medicine to:&lt;/p&gt;
    &lt;p&gt;Mary E. Brunkow&lt;lb/&gt;Institute for Systems Biology,&lt;lb/&gt;Seattle, USA&lt;/p&gt;
    &lt;p&gt;Fred Ramsdell&lt;lb/&gt;Sonoma Biotherapeutics,&lt;lb/&gt;San Francisco, USA&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi&lt;lb/&gt;Osaka University,&lt;lb/&gt;Osaka, Japan&lt;/p&gt;
    &lt;p&gt;“for their discoveries concerning peripheral immune tolerance”&lt;/p&gt;
    &lt;head rend="h2"&gt;They discovered how the immune system is kept in check&lt;/head&gt;
    &lt;p&gt;The body’s powerful immune system must be regulated, or it may attack our own organs. Mary E. Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their groundbreaking discoveries concerning peripheral immune tolerance that prevents the immune system from harming the body.&lt;/p&gt;
    &lt;p&gt;Every day, our immune system protects us from thousands of different microbes trying to invade our bodies. These all have different appearances, and many have developed similarities with human cells as a form of camouflage. So how does the immune system determine what it should attack and what it should defend?&lt;/p&gt;
    &lt;p&gt;Mary Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their fundamental discoveries relating to peripheral immune tolerance. The laureates identified the immune system’s security guards, regulatory T cells, which prevent immune cells from attacking our own body.&lt;/p&gt;
    &lt;p&gt;“Their discoveries have been decisive for our understanding of how the immune system functions and why we do not all develop serious autoimmune diseases,” says Olle Kämpe, chair of the Nobel Committee.&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi was swimming against the tide in 1995, when he made the first key discovery. At the time, many researchers were convinced that immune tolerance only developed due to potentially harmful immune cells being eliminated in the thymus, through a process called central tolerance. Sakaguchi showed that the immune system is more complex and discovered a previously unknown class of immune cells, which protect the body from autoimmune diseases.&lt;/p&gt;
    &lt;p&gt;Mary Brunkow and Fred Ramsdell made the other key discovery in 2001, when they presented the explanation for why a specific mouse strain was particularly vulnerable to autoimmune diseases. They had discovered that the mice have a mutation in a gene that they named Foxp3. They also showed that mutations in the human equivalent of this gene cause a serious autoimmune disease, IPEX.&lt;/p&gt;
    &lt;p&gt;Two years after this, Shimon Sakaguchi was able to link these discoveries. He proved that the Foxp3 gene governs the development of the cells he identified in 1995. These cells, now known as regulatory T cells, monitor other immune cells and ensure that our immune system tolerates our own tissues.&lt;/p&gt;
    &lt;p&gt;The laureates’ discoveries launched the field of peripheral tolerance, spurring the development of medical treatments for cancer and autoimmune diseases. This may also lead to more successful transplantations. Several of these treatments are now undergoing clinical trials.&lt;/p&gt;
    &lt;head rend="h2"&gt;Illustrations&lt;/head&gt;
    &lt;p&gt;The illustrations are free to use for non-commercial purposes. Attribute “© The Nobel Committee for Physiology or Medicine. Ill. Mattias Karlén”&lt;/p&gt;
    &lt;p&gt;Illustration: The Nobel Prize in Physiology or Medicine 2025&lt;lb/&gt;Illustration: How T cells discover a virus&lt;lb/&gt;Illustration: How harmful T cells are eliminated&lt;lb/&gt;Illustration: The experiment that inspired Sakaguchi&lt;lb/&gt;Illustration: Sakaguchi defines a new class of T cells&lt;lb/&gt;Illustration: Brunkow and Ramsdell find the scurfy mutation&lt;lb/&gt;Illustration: How regulatory T cells protect us&lt;/p&gt;
    &lt;head rend="h2"&gt;Read more about this year’s prize&lt;/head&gt;
    &lt;p&gt;Popular science background: They understood how the immune system is kept in check (pdf)&lt;lb/&gt;Scientific background to the Nobel Prize in Physiology or Medicine 2025 (pdf)&lt;/p&gt;
    &lt;p&gt;Mary E. Brunkow, born 1961. Ph.D. from Princeton University, Princeton, USA. Senior Program Manager at the Institute for Systems Biology, Seattle, USA.&lt;/p&gt;
    &lt;p&gt;Fred Ramsdell, born 1960. Ph.D. 1987 from the University of California, Los Angeles, USA. Scientific Advisor, Sonoma Biotherapeutics, San Francisco, USA.&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi, born 1951. M.D. 1976 and Ph.D. 1983 from Kyoto University, Japan. Distinguished Professor at the Immunology Frontier Research Center, Osaka University, Japan.&lt;/p&gt;
    &lt;p&gt;Prize amount: 11 million Swedish kronor, to be shared equally between the laureates.&lt;lb/&gt;Press contact: Pernilla Witte, +46 8 524 86 107, [email protected] or Thomas Perlmann, [email protected], Secretary-General, The Nobel Assembly at Karolinska Institutet.&lt;/p&gt;
    &lt;p&gt;Illustrations: © The Nobel Committee for Physiology or Medicine.&lt;/p&gt;
    &lt;p&gt;The Nobel Assembly, consisting of 50 professors at Karolinska Institutet, awards the Nobel Prize in Physiology or Medicine. Its Nobel Committee evaluates the nominations. Since 1901 the Nobel Prize has been awarded to scientists who have made the most important discoveries for the benefit of humankind.&lt;/p&gt;
    &lt;p&gt;Nobel Prize® is the registered trademark of the Nobel Foundation&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/medicine/2025/press-release/"/><published>2025-10-06T09:41:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489999</id><title>Show HN: I've build a platform for writing technical/scientific documents</title><updated>2025-10-06T20:11:11.301584+00:00</updated><content>&lt;doc fingerprint="e4a541928d31a8b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The best way to write a thesis or notes&lt;/head&gt;
    &lt;p&gt;Elevate your thesis effortlessly with the ultimate paper writing experience!&lt;/p&gt;
    &lt;p&gt;MonsterWriter assists students write exceptional academic papers by providing customized layouts that meet university requirements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Revolutionize Your Thesis Workflow&lt;/head&gt;
    &lt;p&gt;Say goodbye to thesis writing struggles and hello to unmatched productivity and success!&lt;/p&gt;
    &lt;p&gt;MonsterWriter has helped students like you turn in outstanding thesis papers, and now it's your turn to join them!&lt;/p&gt;
    &lt;head rend="h3"&gt;Focus on writing, not on formatting&lt;/head&gt;
    &lt;p&gt;By using the app, students can more effectively manage their time and avoid last-minute cramming&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Better time management&lt;/item&gt;
      &lt;item&gt;Improved quality of work&lt;/item&gt;
      &lt;item&gt;Easy access&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Add citations automatically&lt;/head&gt;
    &lt;p&gt;The details of your citations will be added automatically by MonsterWriter when you enter a website link, the ISBN, or the DOI code of a quote you recently used in your paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don't stress about citations styles&lt;/item&gt;
      &lt;item&gt;Beautifully organized References&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Write your way&lt;/head&gt;
    &lt;p&gt;Express yourself with rich text and content&lt;/p&gt;
    &lt;p&gt;MonsterWriter provides features for complex content. Equations, footnotes, bibliography, table of contents, captions, and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pricing&lt;/head&gt;
    &lt;p&gt;Help support further development and unlock new features&lt;/p&gt;
    &lt;head rend="h3"&gt;Don't let thesis writing stress you out anymore.&lt;/head&gt;
    &lt;p&gt;Download MonsterWriter and get on the path to success!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.monsterwriter.com"/><published>2025-10-06T10:58:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45490439</id><title>Modern messaging: Running your own XMPP server</title><updated>2025-10-06T20:11:10.305594+00:00</updated><content>&lt;doc fingerprint="ddf8a45a3902bcc6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Modern messaging: Running your own XMPP server&lt;/head&gt;
    &lt;p&gt;Since a years we know, or might suspect, our chats are listend on, our uploaded files are sold for advertising or what purpose ever and the chance our social messengers leak our private data is incredibly high. It is about time to work against this.&lt;/p&gt;
    &lt;p&gt;Since 3 years the European Commission works on a plan to automatically monitor all chat, email and messenger conversations.12 If this is going to pass, and I strongly hope it will not, the European Union is moving into a direction we know from states suppressing freedom of speech.&lt;/p&gt;
    &lt;p&gt;I went for setting up my own XMPP server, as this does not have any big resource requirements and still support clustering (for high-availabilty purposes), encryption via OMEMO, file sharing and has support for platforms and operating systems. Also the ecosystem with clients and multiple use cases evolved over the years to provide rock-solid software and solutions for multi-user chats or event audio and video calls.&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;All steps and settings are bundled in a repository containing Ansible roles: https://codeberg.org/codedge/chat&lt;/p&gt;
    &lt;p&gt;All code snippets written below work in either Debian os Raspberry Pi OS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Setting up your own XMPP server&lt;/head&gt;
    &lt;p&gt;The connection from your client to the XMPP server is encrypted and we need certificates for our server. First thing to do is setting up our domains and point it to the IP - both IPv4 and IPv6 is supported and we can specify both later in our configuration.&lt;/p&gt;
    &lt;p&gt;I assume the server is going to be run under &lt;code&gt;xmpp.example.com&lt;/code&gt; and you all the following domains have been set up.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;your main xmpp server address&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;conference.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for MUC (Multi User Chat)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;proxy.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for SOCKS5 proxy support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;pubsub.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for publish/subscribe support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;upload.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for file uploads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;stun.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for audio&amp;amp;video calling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;turn.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for audio&amp;amp;video calling&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Fill in the IPv6 addresses accordingly.&lt;/p&gt;
    &lt;p&gt;ejabberd is a robust server software, that is included in most Linux distributions.&lt;/p&gt;
    &lt;p&gt;Install from Process One repository&lt;lb/&gt;I discovered ProcessOne, the company behind ejabberd, also provides a Debian repository.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Install from Github&lt;lb/&gt;To get the most recent one, I use the packages offered in their code repository. Installing version 25.07 just download the asset from the release:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Make sure the fowolling ports are opened in your firewall, taken from ejabberd firewall settings.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;5222: Jabber/XMPP client connections, plain or STARTTLS&lt;/item&gt;
      &lt;item&gt;5223: Jabber client connections, using the old SSL method&lt;/item&gt;
      &lt;item&gt;5269: Jabber/XMPP incoming server connections&lt;/item&gt;
      &lt;item&gt;5280/5443: HTTP/HTTPS for Web Admin and many more&lt;/item&gt;
      &lt;item&gt;7777: SOCKS5 file transfer proxy&lt;/item&gt;
      &lt;item&gt;3478/5349: STUN+TURN/STUNS+TURNS service&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Port &lt;code&gt;1883&lt;/code&gt;, used for MQTT, is also mentioned in the ejabberd docs, but we do not use this in our setup. So this port stays closed.&lt;/p&gt;
    &lt;p&gt;Depending how you installed ejabberd the config file is either at &lt;code&gt;/etc/ejabberd/conf/ejabberd.yml&lt;/code&gt;
or &lt;code&gt;/opt/ejabberd/conf/ejabberd.yml&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;General configuration&lt;/head&gt;
    &lt;p&gt;The configuration is a balance of 70:30 between having a privacy-focused setup for your users and meeting most of the suggestions of the XMPP complicance test. That means, settings that protect the provacy of the users are higher rated despite not passing the test.&lt;/p&gt;
    &lt;p&gt;Therefore notable privacy and security settings are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;XMPP over HTTP is disabled (mod_bosh)&lt;/item&gt;
      &lt;item&gt;Discover then a user last accessed a server is disabled (mod_last)&lt;/item&gt;
      &lt;item&gt;Delete uploaded files on a regular base (see upload config)&lt;/item&gt;
      &lt;item&gt;Register account via a web page is disabled (mod_register_web)&lt;/item&gt;
      &lt;item&gt;In-band registration can be enabled, default off, captcha secured (mod_register, see registration config)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;The configuration file is in YAML format. Keep an eye for indentation.&lt;/p&gt;
    &lt;p&gt;Let’s start digging into the configuration.&lt;/p&gt;
    &lt;p&gt;Set the domain of your server&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Set the database type&lt;lb/&gt;Instead of using the default &lt;code&gt;mnesia&lt;/code&gt; type, we opt for &lt;code&gt;sql&lt;/code&gt;, better said &lt;code&gt;sqlite&lt;/code&gt;.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Generate DH params&lt;lb/&gt;Generate a fresh set of params for the DH key exchange. In your terminal run&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;and link the new file in the ejabberd configuration.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Ensure TLS for server-to-server connections&lt;lb/&gt;Use TLS for server-to-server (s2s) connections.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The listners&lt;lb/&gt;The listeners aka &lt;code&gt;request_handlers&lt;/code&gt; inside the config especially for &lt;code&gt;/admin&lt;/code&gt;, &lt;code&gt;/captcha&lt;/code&gt;, &lt;code&gt;/upload&lt;/code&gt; and &lt;code&gt;/ws&lt;/code&gt; are important.
All of them listen on port &lt;code&gt;5443&lt;/code&gt;. Only one request handler is attached to port &lt;code&gt;5280&lt;/code&gt;, the &lt;code&gt;/.well-known/acme-challenge&lt;/code&gt;.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;ACLs &amp;amp; Access rules&lt;/head&gt;
    &lt;p&gt;For adminstration of ejabberd we need a user with admin rights and properly set up ACLs and access rules. There is a separat section for ACLs inside the config in which we set up an admin user name &lt;code&gt;root&lt;/code&gt;. The name of the user
is important for later, when we actually create this user.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The &lt;code&gt;access_rules&lt;/code&gt; should already be set up, just to confirm that you have a correct entry for the &lt;code&gt;configure&lt;/code&gt; action.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Now the new &lt;code&gt;root&lt;/code&gt; user needs to be create by running this command on the console.
Watch out to put in the correct domain.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Another user can be registered with the same command.&lt;lb/&gt;We set &lt;code&gt;root&lt;/code&gt; as the admin user in the config previously. That is how ejabberd knows which user has admin permissions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Enable file uploads&lt;/head&gt;
    &lt;p&gt;Enabling file uploads is done with &lt;code&gt;mod_http_upload&lt;/code&gt;.
First, create a folder where the uploads should be stored.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Now update the ejabberd configuration like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The allowed file upload size is defined in the &lt;code&gt;max_size&lt;/code&gt; param and is set to 10MB.&lt;/p&gt;
    &lt;p&gt;Make sure, to delete uploaded files in a reasonable amount of time via cronjob. This is an example of a cronjob, that deletes files that are older than 1 week.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Registration&lt;/head&gt;
    &lt;p&gt;Registration in ejabberd is done via &lt;code&gt;mod_register&lt;/code&gt;
and can be enabled with these entries in the config file:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;If you want to enable registration for your server make sure you enable a captcha for it. Otherwise you will get a lot of spam and fake registrations.&lt;/p&gt;
    &lt;p&gt;ejabberd provides a working captcha script, that you can copy to your server and link in your configuration. You will need &lt;code&gt;imaggemagick&lt;/code&gt; and &lt;code&gt;gstools&lt;/code&gt; installed
on you system. In the &lt;code&gt;ejabberd.yml&lt;/code&gt; config file&lt;/p&gt;
    &lt;head rend="h2"&gt;Add TLS&lt;/head&gt;
    &lt;p&gt;ejabberd can provision TLS certificates on its own. No need to install certbot. To not expose ejabberd directly to the internet, &lt;code&gt;nginx&lt;/code&gt; is put in front of the XMPP server. Instead of using nginx, every other web server (caddy, &amp;amp;mldr;)
or proxy can be used as well.&lt;/p&gt;
    &lt;p&gt;Here is a sample config for nginx:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Alternative connection methods&lt;/head&gt;
    &lt;p&gt;The nginx vhosts offers files, &lt;code&gt;host-meta&lt;/code&gt; and &lt;code&gt;host-meta.json&lt;/code&gt;, for indicating which other connection methods (BOSH, WS) your server offers. The details can be read in XEP-0156 extension.
Opposite to the examples in the XEP, there is no BOSH, but only a websocket connection our server offers. The BOSH part is removed from the config file.&lt;/p&gt;
    &lt;p&gt;host-meta&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;host-meta.json&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Put that file in a folder your nginx serves. Have a look at the path and URL it is expected to be, see &lt;code&gt;.well-known&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Choose your client&lt;/head&gt;
    &lt;p&gt;Clients I can recommend are Profanity, an easy to use command-line client, and Monal for MacOS and iOS. A good overview of client can be found on the offical XMPP website.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Citizen-led initiative collecting information about Chat Controle https://fightchatcontrol.eu ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Explanation by Patrick Breyer, former member of the European Parliament https://www.patrick-breyer.de/en/posts/chat-control/ ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.codedge.de/posts/modern-messaging-running-your-own-xmpp-server"/><published>2025-10-06T12:02:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45490549</id><title>AMD signs AI chip-supply deal with OpenAI, gives it option to take a 10% stake</title><updated>2025-10-06T20:11:09.736608+00:00</updated><content>&lt;doc fingerprint="6196304d0924efba"&gt;
  &lt;main&gt;
    &lt;p&gt;SAN FRANCISCO, Oct 6 (Reuters) - AMD (AMD.O) will supply artificial intelligence chips to OpenAI in a multi-year deal that would bring in tens of billions of dollars in annual revenue and give the ChatGPT creator the option to buy up to roughly 10% of the chipmaker.&lt;/p&gt;
    &lt;p&gt;Shares of the chipmaker surged more than 34% on Monday, putting them on track for their biggest one-day gain in over nine years and adding roughly $80 billion to the company's market value.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The deal, latest in a string of investment commitments, underscores OpenAI and the broader AI industry's voracious appetite for computing power as companies race toward developing AI technology that meets or exceeds human intelligence.&lt;/p&gt;
    &lt;p&gt;"We view this deal as certainly transformative, not just for AMD, but for the dynamics of the industry," AMD executive vice president Forrest Norrod told Reuters on Sunday.&lt;/p&gt;
    &lt;head rend="h2"&gt;VOTE OF CONFIDENCE&lt;/head&gt;
    &lt;p&gt;The agreement closely ties the startup at the center of the AI boom to AMD, one of the strongest rivals of Nvidia (NVDA.O), which recently agreed to make substantial investments in OpenAI.&lt;/p&gt;
    &lt;p&gt;Analysts said it was a major vote of confidence in AMD's AI chips and software but is unlikely to dent Nvidia's dominance, as the market leader continues to sell every AI chip it can make.&lt;/p&gt;
    &lt;p&gt;It covers the deployment of hundreds of thousands of AMD's AI chips, or graphics processing units (GPUs), equivalent to six gigawatts, over several years beginning in the second half of 2026. This is roughly equivalent to the energy needs of 5 million U.S. households, or about thrice the amount of power produced by the Hoover Dam.&lt;/p&gt;
    &lt;p&gt;AMD said OpenAI would build a one-gigawatt facility based on its forthcoming MI450 series of chips beginning next year, and that it would begin to recognize revenue then.&lt;/p&gt;
    &lt;p&gt;AMD executives expect the deal to net tens of billions of dollars in annual revenue. Because of the ripple effect of the agreement, AMD expects to receive more than $100 billion in new revenue over four years from OpenAI and other customers, they said.&lt;/p&gt;
    &lt;p&gt;The chipmaker is expected to report revenue of $32.78 billion this year, according to LSEG data. In contrast, analysts are expecting Nvidia to report revenue of $206.26 billion for the current fiscal year.&lt;/p&gt;
    &lt;p&gt;"AMD has really trailed Nvidia for quite some time. So I think it helps validate their technology," said Leah Bennett, chief investment strategist at Concurrent Asset Management.&lt;/p&gt;
    &lt;p&gt;Shares of Nvidia dipped more than 1%.&lt;/p&gt;
    &lt;p&gt;OpenAI CEO Sam Altman said the AMD deal will help his startup build enough AI infrastructure to meet its needs.&lt;/p&gt;
    &lt;p&gt;It was not immediately clear how OpenAI would fund the massive deal.&lt;/p&gt;
    &lt;p&gt;OpenAI, which is valued at $500 billion, generated around $4.3 billion in revenue in the first half of 2025 and burned through $2.5 billion in cash, according to media reports.&lt;/p&gt;
    &lt;head rend="h2"&gt;DEAL DETAILS&lt;/head&gt;
    &lt;p&gt;As part of the arrangement, AMD issued a warrant that gives OpenAI the ability to buy up to 160 million shares of AMD for 1 cent each over the course of the chip deal. The warrant vests in tranches based on milestones that the two companies have agreed on.&lt;/p&gt;
    &lt;p&gt;The first tranche will vest after the initial shipment of MI450 chips set for the second half of 2026. The remaining milestones include specific AMD stock price targets that escalate to $600 a share for the final installment of stock to unlock.&lt;/p&gt;
    &lt;p&gt;In September, Nvidia announced a deal to supply OpenAI with at least 10 gigawatts worth of its systems.&lt;/p&gt;
    &lt;p&gt;In contrast with the startup's deal with AMD where it will take a stake in the chipmaker, Nvidia will invest $100 billion in the ChatGPT parent under the terms of the agreement announced in September.&lt;/p&gt;
    &lt;p&gt;Taking a stake in AMD could give OpenAI "the power to potentially influence corporate strategy. With Nvidia, OpenAI is simply the client and not a part-owner," said Dan Coatsworth, head of markets at A.J. Bell.&lt;/p&gt;
    &lt;p&gt;OPENAI WANTS MORE GPUs&lt;/p&gt;
    &lt;p&gt;OpenAI has worked with AMD for years, providing inputs on the design of older generations of AI chips such as the MI300X.&lt;/p&gt;
    &lt;p&gt;The San Francisco-based AI company has been taking a number of steps to ensure it has the chips needed for its future needs.&lt;/p&gt;
    &lt;p&gt;Altman has floated expectations of reaching 250 gigawatts of compute in total by 2033, The Information has reported.&lt;/p&gt;
    &lt;p&gt;OpenAI's deal last month with Nvidia includes the deployment of one gigawatt of the chip giant's next-generation Vera Rubin processors in late 2026.&lt;/p&gt;
    &lt;p&gt;OpenAI is also in the process of developing its own silicon for AI use and has partnered with Broadcom (AVGO.O), Reuters reported last year.&lt;/p&gt;
    &lt;p&gt;The startup and its main backer, Microsoft (MSFT.O), announced last month that they had signed a non-binding agreement to restructure OpenAI into a for-profit entity.&lt;/p&gt;
    &lt;p&gt;A person familiar with the matter said the deal with AMD does not change any of OpenAI's ongoing compute plans, including that effort or its partnership with Microsoft.&lt;/p&gt;
    &lt;p&gt;Reporting by Max A. Cherney in San Francisco; Additional reporting by Deepa Seetharaman in San Francisco and Arsheeya Bajwa and Sukriti Gupta in Bengaluru; Editing by Muralikumar Anantharaman and Anil D'Silva&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/business/amd-signs-ai-chip-supply-deal-with-openai-gives-it-option-take-10-stake-2025-10-06/"/><published>2025-10-06T12:17:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45491609</id><title>Show HN: Kent Dybvig's Scheme Machine in 400 Lines of C (Heap-Memory Model)</title><updated>2025-10-06T20:11:09.190468+00:00</updated><content>&lt;doc fingerprint="c5d093b93a485002"&gt;
  &lt;main&gt;
    &lt;p&gt; Created &lt;relative-time&gt;February 17, 2023 12:42&lt;/relative-time&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;tool-tip&gt;Save swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b to your computer and use it in GitHub Desktop.&lt;/tool-tip&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Heap based scheme machine. &lt;/p&gt;
    &lt;p&gt; This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;/* Heap based virtual machine described in section 3.4 of Three Implementation Models for Scheme, Dybvig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;*/&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;string.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;ctype.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;assert.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char token[128][32];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int lexer(char* input) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int ii = 0; // input index&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int ti = 0; // token index&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while(input[ii] != '\0')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;switch(input[ii]) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Ignore whitespace and newlines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case ' ':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '\n':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn a left parenthesis into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '(':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = '(';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn a right parenthesis into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case ')':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = ')';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn an apostrophe into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '\'':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = '\'';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Anything else is a symbol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;default:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;for(int i = 0;; ++i) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(input[ii] != ' ' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != ')' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '(' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '\n' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '\0') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][i] = input[ii++];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][i] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int curtok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* nexttok() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return token[curtok++];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* peektok() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return token[curtok];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;typedef struct Pair {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;} Pair;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;typedef struct Text {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;struct Text* cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;} Text;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair text[1280];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* textptr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int istext(void* x) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return x &amp;gt;= (void*)&amp;amp;text &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;x &amp;lt; (void*)&amp;amp;text[1280];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* cons(void* x, void* y) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(istext(textptr));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr-&amp;gt;car = x;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr-&amp;gt;cdr = y;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return textptr++;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read(char* ln);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read(char* ln) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Initialize the lexer and list memory.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;curtok = 0;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr = text;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;lexer(ln);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_exp() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* tok = nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (tok[0] == '(' &amp;amp;&amp;amp; peektok()[0] == ')') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (tok[0] == '\'')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("quote", cons(read_exp(), NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (tok[0] == '(')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return tok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_list() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* tok = peektok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(tok[0] == ')') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(tok[0] == '.') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;tok = read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return tok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* fst = read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* snd = read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(fst, snd);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print(void* exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_exp(void* exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_list(Pair* list);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_cons(Pair* pair);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print(void* exp) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_exp(void* exp) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (istext(exp)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* pair = exp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(!istext(pair-&amp;gt;cdr) &amp;amp;&amp;amp; pair-&amp;gt;cdr != NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("(");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_cons(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("(");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_list(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("%s", exp ? (char*)exp : "()");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_list(Pair* list) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (list-&amp;gt;cdr == NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(list-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(!istext(list-&amp;gt;cdr) &amp;amp;&amp;amp; list-&amp;gt;cdr != NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_cons(list);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(list-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(" ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_list(list-&amp;gt;cdr);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_cons(Pair* pair) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(pair-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(" . ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(pair-&amp;gt;cdr);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* compile(void* exp, void* next) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (istext(exp)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* p = exp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(p-&amp;gt;car, "quote") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(p-&amp;gt;cdr-&amp;gt;car, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "lambda") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("close", cons(p-&amp;gt;cdr-&amp;gt;car, cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, cons("return", NULL)), cons(next, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "if") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return compile(p-&amp;gt;cdr-&amp;gt;car, cons("test", cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, next),&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, next),&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "set!") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, cons("assign", cons(p-&amp;gt;cdr-&amp;gt;car, cons(next, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "call/cc") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* c = cons("conti", cons(cons("argument", cons(compile(p-&amp;gt;cdr-&amp;gt;car, cons("apply", NULL)), NULL)), NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "return") == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return c;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("frame", cons(next, cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* args = (Pair*)p-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* c = compile(p-&amp;gt;car, cons("apply", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (args) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;c = compile(args-&amp;gt;car, cons("argument", cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;args = args-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "return") == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return c;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("frame", cons(next, cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(isdigit(*((char*)exp))) { // a number&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(strcmp(exp, "#t") == 0) { // a boolean&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(strcmp(exp, "#f") == 0) { // a boolean&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else { // a symbol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("refer", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* get(void* env, char* var) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* e = env;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while(env) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* cur = e-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* vars = cur-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* vals = cur-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (vars &amp;amp;&amp;amp; vals) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(vars-&amp;gt;car, var) == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return vals-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vars = vars-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vals = vals-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;e = e-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fprintf(stderr, "No definition in environment for %s.\n", var);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void set(void* env, char* var, char* val) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* ref = get(env, var);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ref = val;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* extend(void* env, void* vars, void* vals) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(cons(vars, vals), env);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* callframe(void* next, void* env, void* rib, void* stack) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(next, cons(env, cons(rib, cons(stack, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* closure(void* body, void* env, void* vars) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(body, cons(env, cons(vars, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* continuation(void* stack) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return closure(cons("nuate", cons(stack, cons("v", NULL))), NULL, cons("v", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* accum;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* env;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* rib;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* stack;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void virtmach() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "halt") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "refer") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = get(env, n-&amp;gt;cdr-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "constant") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "close") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* vars = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* body = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* x = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = closure(body, env, vars);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = x;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "test") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* consequent = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* alternate = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = strcmp(accum, "#f") == 0 ? alternate : consequent;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "assign") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;set(env, n-&amp;gt;cdr-&amp;gt;car, accum);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "conti") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = continuation(stack);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "nuate") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = get(env, n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = cons("return", NULL);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "frame") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = callframe(n-&amp;gt;cdr-&amp;gt;car, env, rib, stack);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "argument") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = cons(accum, rib);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "apply") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* a = accum;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* body = a-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* clos = a-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* vars = a-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;env = extend(env, vars, rib);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = body;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "return") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* s = stack;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = s-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;env = s-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = s-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = s-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fprintf(stderr, "Unhandled operation.\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int main(int argc, char** argv) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// note! repl implies there's a top-level but there isn't...&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("Lisp REPL\n\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("&amp;gt;&amp;gt; ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char buffer[256];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (fgets(buffer, 256, stdin)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = compile(read(buffer), cons("halt", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print(accum);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("&amp;gt;&amp;gt; ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return 0;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gist.github.com/swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b"/><published>2025-10-06T14:06:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45491621</id><title>Mise: Monorepo Tasks</title><updated>2025-10-06T20:11:08.551042+00:00</updated><content>&lt;doc fingerprint="7c542d728fd7a4ba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Monorepo Tasks #6564&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;We're excited to announce Monorepo Tasks, a powerful new feature that brings first-class monorepo support to mise tasks! 🚀&lt;/p&gt;
          &lt;head&gt;What is it?&lt;/head&gt;
          &lt;p&gt;Monorepo Tasks allows you to manage tasks across multiple projects in a single repository, with each project maintaining its own tools, environment variables, and tasks. Think of it as bringing the power of tools like Bazel or Turborepo to mise's task system, but with mise's signature simplicity.&lt;/p&gt;
          &lt;head&gt;Key Features&lt;/head&gt;
          &lt;head&gt;🎯 Unified Task Namespace&lt;/head&gt;
          &lt;p&gt;All tasks across your monorepo are automatically discovered and prefixed with their location:&lt;/p&gt;
          &lt;code&gt;mise //projects/frontend:build
mise //projects/backend:test
mise //services/api:deploy&lt;/code&gt;
          &lt;head&gt;🌳 Smart Tool &amp;amp; Environment Inheritance&lt;/head&gt;
          &lt;p&gt;Define common tools at the root, override them where needed:&lt;/p&gt;
          &lt;code&gt;# Root mise.toml
[tools]
node = "20"      # Inherited everywhere
python = "3.12"

# projects/legacy-app/mise.toml
[tools]
node = "14"      # Override just for this project
# python still inherited!&lt;/code&gt;
          &lt;head&gt;🎭 Powerful Wildcard Patterns&lt;/head&gt;
          &lt;p&gt;Run tasks across multiple projects with ease:&lt;/p&gt;
          &lt;code&gt;# Run tests in ALL projects
mise //...:test

# Run all build tasks under services/
mise //services/...:build

# Run ALL tasks in frontend (wildcards need quotes)
mise '//projects/frontend:*'

# Run all test:* tasks everywhere
mise '//...:test:*'&lt;/code&gt;
          &lt;head&gt;✨ Consistent Execution Anywhere&lt;/head&gt;
          &lt;p&gt;Run tasks from anywhere in the monorepo - they always execute with the correct context, tools, and environment from their config_root.&lt;/p&gt;
          &lt;head&gt;🔒 Automatic Trust Propagation&lt;/head&gt;
          &lt;p&gt;Trust your monorepo root once, and all descendant configs are automatically trusted.&lt;/p&gt;
          &lt;head&gt;Quick Start&lt;/head&gt;
          &lt;p&gt;1. Enable the feature in your root &lt;/p&gt;
          &lt;code&gt;experimental_monorepo_root = true

[tools]
node = "20"
python = "3.12"&lt;/code&gt;
          &lt;p&gt;2. Set the experimental flag:&lt;/p&gt;
          &lt;code&gt;export MISE_EXPERIMENTAL=1&lt;/code&gt;
          &lt;p&gt;3. Add tasks to your projects:&lt;/p&gt;
          &lt;code&gt;# projects/frontend/mise.toml
[tasks.build]
run = "npm run build"

[tasks.test]
run = "npm test"&lt;/code&gt;
          &lt;p&gt;4. Run tasks from anywhere:&lt;/p&gt;
          &lt;code&gt;mise //projects/frontend:build
mise //...:test  # Run tests in all projects!&lt;/code&gt;
          &lt;head&gt;Example Monorepo Structure&lt;/head&gt;
          &lt;p&gt;Run all service builds: &lt;/p&gt;
          &lt;head&gt;Why This Matters&lt;/head&gt;
          &lt;p&gt;Managing monorepos is hard. Coordinating tools, tasks, and environments across dozens of projects is even harder. With Monorepo Tasks, you get:&lt;/p&gt;
          &lt;head&gt;How Does This Compare to Other Tools?&lt;/head&gt;
          &lt;p&gt;The monorepo ecosystem is rich with excellent tools, each with different strengths. Here's how mise's Monorepo Tasks compares:&lt;/p&gt;
          &lt;head&gt;Simple Task Runners&lt;/head&gt;
          &lt;p&gt;Taskfile and Just are fantastic for single-project task automation. They're lightweight and easy to set up, but they weren't designed with monorepos in mind. While you can have multiple Taskfiles/Justfiles in a repo, they don't provide unified task discovery, cross-project wildcards, or automatic tool/environment inheritance across projects.&lt;/p&gt;
          &lt;p&gt;mise's advantage: Automatic task discovery across the entire monorepo with a unified namespace and powerful wildcard patterns.&lt;/p&gt;
          &lt;head&gt;JavaScript-Focused Tools&lt;/head&gt;
          &lt;p&gt;Nx, Turborepo, and Lerna are powerful tools specifically designed for JavaScript/TypeScript monorepos.&lt;/p&gt;
          &lt;p&gt;mise's advantage: Language-agnostic support. While these tools excel in JS/TS ecosystems, mise works equally well with Rust, Go, Python, Ruby, or any mix of languages. You also get unified tool version management (not just tasks) and environment variables across your entire stack.&lt;/p&gt;
          &lt;head&gt;Large-Scale Build Systems&lt;/head&gt;
          &lt;p&gt;Bazel (Google) and Buck2 (Meta) are industrial-strength build systems designed for massive, multi-language monorepos at companies with thousands of engineers.&lt;/p&gt;
          &lt;p&gt;Both are extremely powerful but come with significant complexity:&lt;/p&gt;
          &lt;p&gt;mise's advantage: Simplicity through non-hermetic builds. mise doesn't try to control your entire build environment in isolation - instead, it manages tools and tasks in a flexible, practical way. This "non-hermetic" approach means you can use mise without restructuring your entire codebase or learning a new language. You get powerful monorepo task management with simple TOML configuration - enough power for most teams without the enterprise-level complexity that hermetic builds require.&lt;/p&gt;
          &lt;head&gt;Other Notable Tools&lt;/head&gt;
          &lt;p&gt;Rush (Microsoft) offers strict dependency management and build orchestration for JavaScript monorepos, with a focus on safety and convention adherence.&lt;/p&gt;
          &lt;p&gt;Moon is a newer Rust-based build system that aims to be developer-friendly while supporting multiple languages.&lt;/p&gt;
          &lt;head&gt;The mise Sweet Spot&lt;/head&gt;
          &lt;p&gt;mise's Monorepo Tasks aims to hit the sweet spot between simplicity and power:&lt;/p&gt;
          &lt;p&gt;When to choose mise:&lt;/p&gt;
          &lt;p&gt;When to consider alternatives:&lt;/p&gt;
          &lt;p&gt;The best tool is the one that fits your team's needs. mise's Monorepo Tasks is designed for teams who want powerful monorepo management without the complexity overhead, especially when working across multiple languages.&lt;/p&gt;
          &lt;head&gt;Try It Out!&lt;/head&gt;
          &lt;p&gt;This feature is experimental, which means:&lt;/p&gt;
          &lt;p&gt;Read the full documentation: Monorepo Tasks Guide&lt;/p&gt;
          &lt;head&gt;We Want Your Feedback!&lt;/head&gt;
          &lt;p&gt;Please try it out and let us know:&lt;/p&gt;
          &lt;p&gt;Share your experience in the comments below! 👇&lt;/p&gt;
          &lt;p&gt;Special shoutout to the mise community for the feedback and ideas that led to this feature. Happy building! 🛠️&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 2 comments 6 replies&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Does this support &lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Excited to see this! We're currently using turbo in a mixed Rust/wasm/TS/Python/Go repo, and it's been a bit of a mixed bag (admittedly, I don't know how much of that is because we're unwilling to invest effort into modelling task inputs/outputs correctly in turbo).&lt;/p&gt;
          &lt;p&gt;Compounding the issue is that what we really want a whole bunch of things out of it:&lt;/p&gt;
          &lt;p&gt;Absent these, I don't really see us adopting this anytime soon unfortunately.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jdx/mise/discussions/6564"/><published>2025-10-06T14:07:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492055</id><title>Novel Stable and Low-Energy Earth-Moon Cycle Orbits [pdf]</title><updated>2025-10-06T20:11:07.761796+00:00</updated><content/><link href="https://ross.aoe.vt.edu/papers/ross-roberts-tsoukkas-2025-AAS-25-621.pdf"/><published>2025-10-06T14:51:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492564</id><title>Launch HN: Grapevine (YC S19) – A company GPT that actually works</title><updated>2025-10-06T20:11:07.316436+00:00</updated><content>&lt;doc fingerprint="a74e481eafb1f0bb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop wasting time searching.&lt;/head&gt;
    &lt;head rend="h1"&gt;Stop wasting time searching.&lt;/head&gt;
    &lt;head rend="h1"&gt;Stop wasting time searching.&lt;/head&gt;
    &lt;p&gt;One AI agent that searches across your docs, code, and communicationâso you donât have to.&lt;/p&gt;
    &lt;p&gt;Thread&lt;/p&gt;
    &lt;p&gt;Aleks&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I wish there were a company GPT that ACTUALLY worked + wasn't exorbitantly expensive ðªðª&lt;/p&gt;
    &lt;p&gt;1 reply&lt;/p&gt;
    &lt;p&gt;Grapevine&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I can help with that, and you can get started for free!&lt;/p&gt;
    &lt;p&gt;Thread&lt;/p&gt;
    &lt;p&gt;Aleks&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I wish there were a company GPT that ACTUALLY worked + wasn't exorbitantly expensive ðªðª&lt;/p&gt;
    &lt;p&gt;1 reply&lt;/p&gt;
    &lt;p&gt;Grapevine&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I can help with that, and you can get started for free!&lt;/p&gt;
    &lt;p&gt;Thread&lt;/p&gt;
    &lt;p&gt;Aleks&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I wish there were a company GPT that ACTUALLY worked + wasn't exorbitantly expensive ðªðª&lt;/p&gt;
    &lt;p&gt;1 reply&lt;/p&gt;
    &lt;p&gt;Grapevine&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I can help with that, and you can get started for free!&lt;/p&gt;
    &lt;head rend="h2"&gt;What if ChatGPT was aware of my company's context?&lt;/head&gt;
    &lt;head rend="h3"&gt;We've all wondered it at some point.&lt;/head&gt;
    &lt;head rend="h3"&gt;What if AI already understood your companyâso you could skip the busywork, the repetitive asks, the frustration?&lt;/head&gt;
    &lt;head rend="h3"&gt;It could take care of the many chores that exist in work today, making our days a little less annoying and little more fun.&lt;/head&gt;
    &lt;head rend="h3"&gt;Other products we've tried haven't quite worked. Some of us have tried to build it ourselves.&lt;/head&gt;
    &lt;head rend="h3"&gt;That's why we built Grapevine. And it finally works.&lt;/head&gt;
    &lt;p&gt;#team-infra&lt;/p&gt;
    &lt;p&gt;For commonly asked cross-team questions&lt;/p&gt;
    &lt;p&gt;Johnny&lt;/p&gt;
    &lt;p&gt;Jul 28th at 4:23 PM&lt;/p&gt;
    &lt;p&gt;Hey Infra team, Iâd like to create a new S3 bucket...&lt;/p&gt;
    &lt;p&gt;Actual Slack thread&lt;/p&gt;
    &lt;p&gt;3 sources&lt;/p&gt;
    &lt;p&gt;Real examples of us using Grapevine internally, over the last 2 months&lt;/p&gt;
    &lt;p&gt;&amp;gt;85%&lt;/p&gt;
    &lt;p&gt;&amp;gt;85%&lt;/p&gt;
    &lt;p&gt;&amp;gt;85%&lt;/p&gt;
    &lt;p&gt;of answers are helpful &amp;amp; accurate&lt;/p&gt;
    &lt;p&gt;of answers are helpful &amp;amp; accurate&lt;/p&gt;
    &lt;p&gt;*from hundreds of real questions from beta customers&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started in under 30 minutes&lt;/head&gt;
    &lt;p&gt;10 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Connect your data and setup Slack bot&lt;/head&gt;
    &lt;p&gt;30 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Start asking questions&lt;/head&gt;
    &lt;p&gt;2 days&lt;/p&gt;
    &lt;head rend="h6"&gt;Tackle queries with full historical context&lt;/head&gt;
    &lt;p&gt;Over time&lt;/p&gt;
    &lt;head rend="h6"&gt;Grapevine keeps learning and getting sharper&lt;/head&gt;
    &lt;head rend="h2"&gt;Get started in under 30 minutes&lt;/head&gt;
    &lt;p&gt;10 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Connect your data and setup Slack bot&lt;/head&gt;
    &lt;p&gt;30 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Start asking questions&lt;/head&gt;
    &lt;p&gt;2 days&lt;/p&gt;
    &lt;head rend="h6"&gt;Tackle queries with full historical context&lt;/head&gt;
    &lt;p&gt;Over time&lt;/p&gt;
    &lt;head rend="h6"&gt;Grapevine keeps learning and getting sharper&lt;/head&gt;
    &lt;head rend="h2"&gt;Get started in under 30 minutes&lt;/head&gt;
    &lt;p&gt;10 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Connect your data and setup Slack bot&lt;/head&gt;
    &lt;p&gt;30 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Start asking questions&lt;/head&gt;
    &lt;p&gt;2 days&lt;/p&gt;
    &lt;head rend="h6"&gt;Tackle queries with full historical context&lt;/head&gt;
    &lt;p&gt;Over time&lt;/p&gt;
    &lt;head rend="h6"&gt;Grapevine keeps learning and getting sharper&lt;/head&gt;
    &lt;head rend="h3"&gt;Always Secure&lt;/head&gt;
    &lt;head rend="h6"&gt;Encrypted at rest&lt;/head&gt;
    &lt;p&gt;Data is encrypted using industry-standard AES-256, protecting your companyâs knowledge even when itâs not in use.&lt;/p&gt;
    &lt;head rend="h6"&gt;Encrypted at rest&lt;/head&gt;
    &lt;p&gt;Data is encrypted using industry-standard AES-256, protecting your companyâs knowledge even when itâs not in use.&lt;/p&gt;
    &lt;head rend="h6"&gt;Encrypted at rest&lt;/head&gt;
    &lt;p&gt;All data is encrypted using industry-standard AES-256&lt;/p&gt;
    &lt;head rend="h6"&gt;Isolated databases&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately to ensure maximum privacy and security.&lt;/p&gt;
    &lt;head rend="h6"&gt;Isolated databases&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately to ensure maximum privacy and security.&lt;/p&gt;
    &lt;head rend="h6"&gt;Isolated databases&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately&lt;/p&gt;
    &lt;head rend="h6"&gt;SOC II Compliant&lt;/head&gt;
    &lt;p&gt;Built to Gather's SOC II Type 2 standards, with regularly scheduled security audits and more details upon request.&lt;/p&gt;
    &lt;head rend="h6"&gt;SOC II Compliant&lt;/head&gt;
    &lt;p&gt;Built to Gather's SOC II Type 2 standards, with regularly scheduled security audits and more details upon request.&lt;/p&gt;
    &lt;head rend="h6"&gt;SOC II Compliant&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately&lt;/p&gt;
    &lt;p&gt;Grapevine will not train models on your data&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started today.&lt;/head&gt;
    &lt;head rend="h2"&gt;What if ChatGPT was aware of my company's context?&lt;/head&gt;
    &lt;p&gt;We've all wondered this at some point. And we finally built a version of this that works. But don't take our word for itâtry it today!&lt;/p&gt;
    &lt;p&gt;#team-infra&lt;/p&gt;
    &lt;p&gt;For commonly asked cross-team questions&lt;/p&gt;
    &lt;p&gt;Johnny&lt;/p&gt;
    &lt;p&gt;Jul 28th at 4:23 PM&lt;/p&gt;
    &lt;p&gt;Hey Infra team, Iâd like to create a new S3 bucket...&lt;/p&gt;
    &lt;p&gt;Actual Slack thread&lt;/p&gt;
    &lt;p&gt;3 sources&lt;/p&gt;
    &lt;p&gt;Real examples of us using Grapevine internally, over the last 2 months&lt;/p&gt;
    &lt;p&gt;#team-infra&lt;/p&gt;
    &lt;p&gt;For commonly asked cross-team questions&lt;/p&gt;
    &lt;p&gt;Johnny&lt;/p&gt;
    &lt;p&gt;Jul 28th at 4:23 PM&lt;/p&gt;
    &lt;p&gt;Hey Infra team, Iâd like to create a new S3 bucket...&lt;/p&gt;
    &lt;p&gt;Actual Slack thread&lt;/p&gt;
    &lt;p&gt;3 sources&lt;/p&gt;
    &lt;p&gt;Real examples of us using Grapevine internally, over the last 2 months&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://getgrapevine.ai/"/><published>2025-10-06T15:39:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492803</id><title>OpenZL: An open source format-aware compression framework</title><updated>2025-10-06T20:11:07.094471+00:00</updated><content>&lt;doc fingerprint="b69d42b82801cb99"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenZL is a new open source data compression framework that offers lossless compression for structured data.&lt;/item&gt;
      &lt;item&gt;OpenZL is designed to offer the performance of a format-specific compressor with the easy maintenance of a single executable binary.&lt;/item&gt;
      &lt;item&gt;You can get started with OpenZL today by visiting our Quick Start guide and the OpenZL GitHub repository.&lt;/item&gt;
      &lt;item&gt;Learn more about the theory behind OpenZL in this whitepaper.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Today, we are excited to announce the public release of OpenZL, a new data compression framework. OpenZL offers lossless compression for structured data, with performance comparable to specialized compressors. It accomplishes this by applying a configurable sequence of transforms to the input, revealing hidden order in the data, which can then be more easily compressed. Despite applying distinct transformation permutations for every file type, all OpenZL files can be decompressed using the same universal OpenZL decompressor.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Decade of Lessons&lt;/head&gt;
    &lt;p&gt;When Zstandard was announced, it came with a simple pitch: It promised the same or better compression ratio of prior default but at the much increased speed required by datacenter workloads. By pairing strong entropy coding with a design that fully utilized modern CPU capabilities, Zstandard offered a substantial improvement that justified its presence in datacenters.&lt;/p&gt;
    &lt;p&gt;However, while it was improved over time, remaining within the Zstandard framework offers diminishing returns. So we started looking for the next great leap in data compression.&lt;/p&gt;
    &lt;p&gt;In this quest, one pattern kept repeating: Using generic methods on structured data leaves compression gains on the table. Data isn’t just byte soup. It can be columnar, encode enums, be restricted to specific ranges, or carry highly repetitive fields. More importantly, it has predictable shapes. A bespoke compressor that leans into that structure can beat general-purpose tools on both ratio and speed. But there’s a catch — every bespoke scheme means another compressor and decompressor to create, ship, audit, patch, and trust.&lt;/p&gt;
    &lt;p&gt;OpenZL is our answer to the tension between the performance of format-specific compressors and the maintenance simplicity of a single executable binary.&lt;/p&gt;
    &lt;head rend="h2"&gt;Make the Structure Explicit&lt;/head&gt;
    &lt;p&gt;General compressors rely on a one-size fits all processing strategy, or alternatively spend a lot of their cycles guessing which techniques to use. OpenZL saves those cycles by making the structure an explicit input parameter. Compression can then focus on a sequence of reversible steps that surface patterns before coding.&lt;/p&gt;
    &lt;p&gt;As a user, you provide OpenZL with the data shape (via a preset or a thin format description). Then the trainer, an offline optimization component, builds an effective compression config that can be re-employed for similar data. During encoding that config resolves into a concrete decode recipe that’s embedded into the frame. The universal decoder will directly execute that recipe, without any out-of-band information.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Example Compression Using OpenZL&lt;/head&gt;
    &lt;p&gt;As an example, let’s compress sao, which is part of the Silesia Compression Corpus. This file follows a well-defined format featuring an array of records, each one describing a star. Providing this information to OpenZL is enough to give it an edge over generic lossless compressors, which only see bytes.&lt;/p&gt;
    &lt;p&gt;Comparison on a M1 cpu, using clang-17&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compressor&lt;/cell&gt;
        &lt;cell&gt;zstd -3&lt;/cell&gt;
        &lt;cell&gt;xz -9&lt;/cell&gt;
        &lt;cell&gt;OpenZL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compressed Size&lt;/cell&gt;
        &lt;cell&gt;5,531,935 B&lt;/cell&gt;
        &lt;cell&gt;4,414,351 B&lt;/cell&gt;
        &lt;cell&gt;3,516,649 B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compression Ratio&lt;/cell&gt;
        &lt;cell&gt;x1.31&lt;/cell&gt;
        &lt;cell&gt;x1.64&lt;/cell&gt;
        &lt;cell&gt;x2.06&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compression Speed&lt;/cell&gt;
        &lt;cell&gt;220 MB/s&lt;/cell&gt;
        &lt;cell&gt;3.5 MB/s&lt;/cell&gt;
        &lt;cell&gt;340 MB/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Decompression Speed&lt;/cell&gt;
        &lt;cell&gt;850 MB/s&lt;/cell&gt;
        &lt;cell&gt;45 MB/s&lt;/cell&gt;
        &lt;cell&gt;1200 MB/s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Crucially, OpenZL produces a higher compression ratio while preserving or even improving speed, which is critical for data center processing pipelines.&lt;/p&gt;
    &lt;p&gt;For illustration, this result is achieved using the following simple graph:&lt;/p&gt;
    &lt;head rend="h3"&gt;A Brief Explanation&lt;/head&gt;
    &lt;p&gt;So what is happening in this example?&lt;/p&gt;
    &lt;p&gt;We start by separating the header from the rest, a large table of structures. Then each field gets extracted into its own stream: the array of structures becomes a structure of arrays. After that point, we expect that each stream contains homogeneous data of the same type and semantic meaning. We can now focus on finding an optimal compression strategy for each one.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SRA0 is a position on the X axis. Due to the way the table is generated, the index is mostly sorted, inviting the use of delta to reduce the range of values represented. This mechanically makes the resulting stream easier to compress.&lt;/item&gt;
      &lt;item&gt;SDEC0 is a position on the Y axis. It’s not as well sorted as the X axis, but we can at least exploit the fact that it’s bounded between a minimum and a maximum. This makes the higher bytes more predictable, which can be exploited for better compression with the transpose operation.&lt;/item&gt;
      &lt;item&gt;The other fields (IS, MAG, XRPM, XDPM) share a common property: their cardinality is much lower than their quantities, and there is no relation between 2 consecutive values. This makes them a good target for tokenize, which will convert the stream into a dictionary and an index list.&lt;/item&gt;
      &lt;item&gt;The resulting dictionaries and index lists are very different. They benefit from completely different compression strategies. So they are sent to dedicated processing graphs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The graph continues beyond these steps. But at some point, we can also stop making decisions. The main work is to group data into homogeneous streams. After that, one can count on openzl to take care of the rest.&lt;/p&gt;
    &lt;p&gt;To go even further, we would like to generate compression strategies that are specifically fine-tuned for each stream. This is where the offline trainer stage comes into play.&lt;/p&gt;
    &lt;head rend="h2"&gt;Generate a Compressor Automatically&lt;/head&gt;
    &lt;p&gt;It’s possible to take full control of the compression process, but it’s also not required. A faster strategy is to just describe your data and let the system learn a compression config.&lt;/p&gt;
    &lt;p&gt;Describe the input: With the Simple Data Description Language (SDDL), you sketch how the bytes map to fields — rows, columns, enums, nested records. SDDL is for parsing only; it just tells OpenZL the shape of your data. Alternatively, you can write your own parser function directly using one of the supported languages, and register it with OpenZL to delegate the logic.&lt;/p&gt;
    &lt;p&gt;Learn the config: Starting from a preset, a parser function or an SDDL description, the trainer runs a budgeted search over transform choices and parameters to produce a Plan. It can provide a full set of speed/ratio tradeoffs, or directly target the best configuration respecting some speed constraints. Internally it uses a cluster finder (to group fields that behave alike) and a graph explorer (to try candidate subgraphs and keep score).&lt;/p&gt;
    &lt;p&gt;Resolve at encode-time: While compressing, the encoder turns the Plan into a concrete recipe — the Resolved Graph. If the Plan has control points, it picks the branch that fits the data and records that choice into the frame.&lt;/p&gt;
    &lt;p&gt;Decode without coordination: Each frame chunk carries its own resolved graph. The single decoder checks it, enforces limits, and runs the steps in order. When a plan improves, you just roll out the new plan, no new decompressor needed. Old data keeps decoding; new data get improved gains.&lt;/p&gt;
    &lt;p&gt;In practice the loop is straightforward: describe (SDDL) → train (produce a plan) → compress (emit frames with resolved graphs) → decode anywhere with the same binary.&lt;/p&gt;
    &lt;head rend="h2"&gt;Embracing Changes: Re-Training and In-Flight Control&lt;/head&gt;
    &lt;p&gt;In the real world, data evolves constantly, in both structure and content. A compressor built for one version of a schema would have a short lifetime.&lt;/p&gt;
    &lt;p&gt;Thankfully, with the flexibility offered by compression plans, we can react swiftly to data changes. At Meta, this is the core mission of Managed Compression, originally created to automate dictionary compression with Zstandard, and presented in an earlier blog on how we improved compression at with Zstandard.&lt;/p&gt;
    &lt;p&gt;OpenZL offers a training process that updates compression plans to maintain or improve compression performance, based on provided data samples. Now the synergy with Managed Compression is apparent: Each registered use case is monitored, sampled, periodically re-trained, and receives new configs when they prove beneficial. The decompression side continues to decode both old and new data without any change.&lt;/p&gt;
    &lt;p&gt;Runtime Adaptation: A compression config can include control points that read lightweight statistics at compression time (e.g., string repetition stats, run-length, histogram skew, delta variance) and choose the best branch of the Plan to go to next. Many technologies can be used, and textbook classifiers qualify. Control points handle bursts, outliers, and seasonal shifts without brute-force exploration: exploration is bounded, in order to maintain speed expectations. Taken branches are then recorded into the frame, and the decoder just executes the recorded path.&lt;/p&gt;
    &lt;p&gt;This gives the best of both worlds: dynamic behavior at compression time to handle variations and exceptions — without turning compression into an unbounded search problem — and with zero complexity added to the decoder.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Advantages of the Universal Decoder&lt;/head&gt;
    &lt;p&gt;OpenZL is capable of compressing a vast array of data formats, and they can all be decompressed with a single decompressor binary. Even when the compression configuration changes, the decoder does not. This may sound like operational minutiae, but it’s critical to OpenZL’s deployment success.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One audited surface: Security and correctness reviews focus on a single binary with consistent invariants, fuzzing, and hardening; there’s no myriad of per-format tools that can drift apart.&lt;/item&gt;
      &lt;item&gt;Fleet-wide improvements: A decoder update (security or performance — SIMD kernels, memory bounds, scheduling) benefits every compressed file, even those that predate the change.&lt;/item&gt;
      &lt;item&gt;Operational clarity: Same binary, same CLI, same metrics and dashboards across datasets; patching and rollout are uneventful by design.&lt;/item&gt;
      &lt;item&gt;Continuous training: With one decoder and many compression plans, we can keep improving while the system is live. Train a plan offline, try it on a small slice, then roll it out like any other config change. Backward compatibility is built-in — old frames still decode while new frames get better.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In other words, it’s possible to afford domain-specific compression without fragmenting the ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results With OpenZL&lt;/head&gt;
    &lt;p&gt;When OpenZL is able to understand and parse the file format, it is able to offer large improvements in compression ratio, while still providing fast compression and decompression speed. However, this is no magic bullet. When OpenZL doesn’t understand the input file format, it simply falls back to zstd.&lt;/p&gt;
    &lt;p&gt;OpenZL, through its offline training capabilities, is also able to offer a wide range of configurations in the tradeoff space of compression ratio, compression speed, and decompression speed. Unlike traditional compressors, which offer configuration by setting a compression level, OpenZL offers configuration by serializing the compressor graph. This allows an immense amount of flexibility to select diverse tradeoffs.&lt;/p&gt;
    &lt;p&gt;These results are based on datasets we’ve developed for our whitepaper. The datasets were chosen because they are highly structured and in a format that OpenZL supports. Every figure below is produced with scripts in the OpenZL repository so they can be reproduced, and the input data and logs from our runs have been uploaded to GitHub.&lt;/p&gt;
    &lt;p&gt;Note that data points connected by a line are pareto-optimal. All such points have the property that there is no point in the same dataset which beats them in both metrics.&lt;/p&gt;
    &lt;head rend="h3"&gt;When It’s Not Useful&lt;/head&gt;
    &lt;p&gt;OpenZL relies on a description of some structure to leverage its set of transforms. When there is no structure, there is no advantage. This is typically the case in pure text documents, such as enwik or dickens. In these cases, OpenZL falls back to zstd, offering essentially the same level of performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started With OpenZL&lt;/head&gt;
    &lt;p&gt;OpenZL’s selection of codecs is well-suited to compressing vector, tabular, or tree-structured data, and can be expected to perform well with numeric, string, or binary data. Common examples include timeseries datasets, ML tensors, and database tables. Keep in mind that we are bound by the limits of information theory, so the input needs to have some order that can be uncovered. As time goes on, we plan to incorporate additional codecs, as described in the next section.&lt;/p&gt;
    &lt;p&gt;If your data fits one of the above categories, then give it a try! Visit the OpenZL site and our Quick Start guide to get started.&lt;/p&gt;
    &lt;p&gt;If you want to dive into the code, check out the GitHub repository for source, documentation, and examples. We welcome contributions and feedback from the community!&lt;/p&gt;
    &lt;head rend="h2"&gt;Where We’re Going&lt;/head&gt;
    &lt;p&gt;OpenZL’s general direction is set: make it easier to expose structures, and exploit it with automated compression plans for evolving data.&lt;/p&gt;
    &lt;p&gt;Next up: We’re extending the transform library for time-series and grid-shaped data, improving performance of codecs, and enabling the trainer to find better compression plans faster. We also are actively working to extend SDDL to describe nested data formats more flexibly. Finally, the automated compressor explorer is getting better at proposing safe, testable changes to a compression plan within a specified budget.&lt;/p&gt;
    &lt;p&gt;Where the community can help: If you have a format or a dataset with obvious structure, try compressing it with an OpenZL prebuilt Plan. If it’s promising, try generating a new plan with the trainer or customizing it with our documentation to improve it. If it’s a format that the public might want, send it to us in a PR.&lt;/p&gt;
    &lt;p&gt;You can also contribute to the OpenZL core. If you have a knack for optimizing C/C++, help us speed up the engine or add transforms to cover new data formats. If your super power is reliability, the project would surely benefit from more validation rules and resource caps. And if you care about benchmarks, add your dataset to the harness so others can reproduce your results.&lt;/p&gt;
    &lt;p&gt;How to engage: Open an issue on the GitHub issue board. If you have a use-case for which you would expect OpenZL to do better, provide a few small samples, so that we can analyze them together. You may also contribute to codec optimizations, and propose new graphs, parsers or control points. All these topics do not impact the universality of the decoder.&lt;/p&gt;
    &lt;p&gt;We believe OpenZL opens up a new universe of possibilities to the data compression field, and we’re excited to see what the open source community will do with it!&lt;/p&gt;
    &lt;p&gt;To learn more about Meta Open Source, visit our website, subscribe to our YouTube channel, or follow us on Facebook, Threads, X, Bluesky and LinkedIn.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/"/><published>2025-10-06T16:01:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492888</id><title>"Be Different" doesn't work for building products anymore</title><updated>2025-10-06T20:11:06.920562+00:00</updated><content/><link href="https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building"/><published>2025-10-06T16:09:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493143</id><title>One to two Starlink satellites are falling back to Earth each day</title><updated>2025-10-06T20:11:06.556446+00:00</updated><content>&lt;doc fingerprint="f6121e362ac0ec89"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;1 to 2 Starlink satellites are falling back to Earth each day&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Watch from multiple locations as a Starlink satellite reenters Earth’s atmosphere, burning up over California, on September 25, 2025. Currently, there are 1 to 2 Starlink satellites falling back to Earth each day. Soon there will be more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Starlink satellites are falling&lt;/head&gt;
    &lt;p&gt;It might not be long before you look up and see a fiery, slow-moving object streaking across your night sky and, clearly, breaking into pieces. That’s if you haven’t seen such a thing already. There are currently one to two Starlink satellites falling back to Earth every day, according to retired Harvard astrophysicist Jonathan McDowell. His acclaimed website Jonathan’s Space Report is widely regarded as the definitive source on spacecraft that go up … and come down. When we asked him about the deluge of Starlink satellite breakups that have recently been flooding social media, he pointed us to his graph showing Starlink reentries over time.&lt;/p&gt;
    &lt;p&gt;There are more than 8,000 Starlink satellites overhead at this moment. They’re a product of the space transportation company SpaceX. And that number is growing. Plus there are other companies and countries also deploying more and more satellites, adding to the number of satellites in Earth orbit. Many of these are in low-Earth orbits, which extend up to an altitude of 1,200 miles (2,000 km) above our planet. And the lifespan of low-Earth orbit satellites, such as Starlink, is only about 5 to 7 years. Soon, McDowell told us, there will be up to 5 satellite reentries per day. He said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;With all constellations deployed, we expect about 30,000 low-Earth orbit satellites (Starlink, Amazon Kuiper, others) and perhaps another 20,000 satellites at 1,000 km [620 miles] from the Chinese systems. For the low-orbit satellites we expect a 5-year replacement cycle, and that translates to 5 reentries a day. It’s not clear if the Chinese will orbit-lower theirs or just accelerate us to chain-reaction Kessler syndrome.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Kessler syndrome is a scenario in which the density of objects in low-Earth orbit is high enough that collisions between objects cause a cascade, with each collision generating space debris that increases the likelihood of further collisions. Read more about the Kessler syndrome here.&lt;/p&gt;
    &lt;p&gt;Watch our interviews with Jonathan McDowell:&lt;/p&gt;
    &lt;p&gt;Space junk and other human-made space hazards&lt;/p&gt;
    &lt;p&gt;The truth about Near-Earth Collisions&lt;/p&gt;
    &lt;p&gt;Catch a falling SpaceX Starlink&lt;/p&gt;
    &lt;head rend="h3"&gt;How to tell the difference between space junk and meteors&lt;/head&gt;
    &lt;p&gt;In many of the images online showing the fiery disintegration of something in our atmosphere, a photographer is asking:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;What did I just see?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So, is there a quick way to tell the difference between a meteor and space junk burning up overhead? McDowell explained:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The easy ‘meteor vs. space junk’ discriminator is speed. A meteor from solar orbit, even a big fireball, lasts only a few seconds and is gone, whizzz. Space junk goes more like airplane angular speed (really faster than a plane, but higher so it cancels out) and may be overhead for a couple of minutes.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Watch a Russian rocket reenter Earth’s atmosphere over southeastern Australia in May 2020.&lt;/p&gt;
    &lt;head rend="h3"&gt;How solar activity affects Starlink satellites and others&lt;/head&gt;
    &lt;p&gt;As SpaceX launches more and more Starlink satellites, more of them also come falling back to Earth. But they don’t all fall out of orbit for the same reason. Besides the fact that some of them are at the end of their lifespans, there are other reasons satellites can reenter.&lt;/p&gt;
    &lt;p&gt;For example, high solar activity can shorten the lifespan of satellites, and we’re just past a solar maximum and still in the period of high solar activity. Solar storms heat Earth’s upper atmosphere, causing it to “puff up.” The result is an increase in atmospheric drag: low-Earth orbit satellites like Starlink (and ISS, and Earth-observing satellites) find themselves flying through thicker air than usual. That extra air density creates aerodynamic drag, which slows the satellites down and causes them to lose altitude.&lt;/p&gt;
    &lt;p&gt;Operators might be able to boost some satellites back up. But, if they can’t, the satellites can reenter the atmosphere prematurely. That’s what happened in early 2022, when a solar storm doomed 40 recently launched Starlink satellites.&lt;/p&gt;
    &lt;head rend="h3"&gt;Also, malfunctions can occur&lt;/head&gt;
    &lt;p&gt;Solar activity isn’t the only thing that brings satellites down. Malfunctions can occur. For example, on July 12, 2024, a Falcon 9 rocket failed during the second stage, leaving 20 Starlink satellites in the “wrong” orbit. In that case, McDowell said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;All but two of the satellites reentered on the day of launch, and the last one reentered on July 20, eight days after launch.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Recent Starlink satellites reentries shared on social media&lt;/head&gt;
    &lt;p&gt;Here’s a sample of some of the recent Starlink satellite reentries that people have witnessed. Keep in mind that many of the reentries are not being witnessed. That’s because some 70% of Earth’s surface is water, so in many places the reentries happen overhead where no one is around to see them. Also, reentries that happen in the middle of the night or during bright daylight are less likely to be witnessed.&lt;/p&gt;
    &lt;p&gt;September 25, 2025: A Starlink satellite lit up the sky over the Bay Area in California.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;WATCH: Starlink debris seen over the skies of Sacramento County, California.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;A reentry observed over California at 0245 UTC Sep 26 (7.45pm PDT Thu Sep 25) is consistent with Starlink 1586.&lt;/p&gt;
      &lt;p&gt;— Jonathan McDowell (@planet4589.bsky.social) 2025-09-26T23:51:48.535Z&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;September 22, 2025: A Starlink satellite burned up over Saskatchewan, Canada.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Here's the official Global Meteor Network camera video from Lucky Lake, Saskatchewan! This video is courtesy University of Western Ontario and Defence R&amp;amp;D Canada.I counted 13 pieces in the video, how many do we think made it to the ground and are sitting on canola stubble east of Saskatoon?&lt;/p&gt;
      &lt;p&gt;— Prof. Sam Lawler (@sundogplanets.mastodon.social.ap.brid.gy) 2025-09-26T15:52:56.000Z&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Starlink 1066 reentered over Canada at about 0600 UTC Sep 23.&lt;/p&gt;
      &lt;p&gt;— Jonathan McDowell (@planet4589.bsky.social) 2025-09-23T23:39:15.840Z&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;September 21, 2025: This Starlink reentry created a stir when it burned up over Texas.&lt;/p&gt;
    &lt;quote&gt;
      &lt;section&gt;@hearts4hoovestherapy&lt;/section&gt;
      &lt;p&gt;Well that was cool! #Hearts4Hooves #fyppppppppppppppppppppppp #goviral #foryoupage #fyp?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Starlink 1636, launched in Aug 2020, reentered over Texas last night (Sep 22 0130 UTC / Sep 21 8.30pm CDT) and was observed widely.&lt;/p&gt;
      &lt;p&gt;— Jonathan McDowell (@planet4589.bsky.social) 2025-09-23T00:27:13.160Z&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;What effect do the disintegrating satellites have on Earth’s atmosphere?&lt;/head&gt;
    &lt;p&gt;In 2023, the National Oceanic and Atmospheric Administration (NOAA) shared a scientific investigation of Earth’s stratosphere. The stratosphere is the layer of atmosphere more than 7 miles (11 km) above Earth’s surface, where jet planes fly and the ozone layer exists. NOAA said the stratosphere:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;… contains an unexpected quantity of particles with a variety of exotic metals. The scientists believe the particles come from satellites and spent rocket boosters as they are vaporized by the intense heat of reentry.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The researchers found particles containing the rare elements niobium and hafnium. They also found a significant number of particles contained copper, lithium and aluminum at concentrations far exceeding the abundance found in space dust. The use of these elements in heat-resistant, high-performance alloys pointed at the spaceflight industry as the culprit.&lt;/p&gt;
    &lt;p&gt;These tiny particles could absorb and reflect the sun’s rays. They could also serve as surfaces for ozone-destroying chemical reactions. And these particles could change our planet’s atmosphere in ways we still don’t fully understand. Research in this area is ongoing.&lt;/p&gt;
    &lt;p&gt;Bottom line: There are now one to two Starlink satellites falling back to Earth each day, burning up in the atmosphere with consequences not fully understood.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://earthsky.org/human-world/1-to-2-starlink-satellites-falling-back-to-earth-each-day/"/><published>2025-10-06T16:32:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493358</id><title>Ladybird passes the Apple 90% threshold on web-platform-tests</title><updated>2025-10-06T20:11:06.114852+00:00</updated><content>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/awesomekling/status/1974781722953953601"/><published>2025-10-06T16:52:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493432</id><title>OpenAI DevDay 2025: Opening keynote [video]</title><updated>2025-10-06T20:11:05.358282+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=hS1YqcewH0c"/><published>2025-10-06T17:00:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493453</id><title>UpCodes (YC S17) is hiring remote engineers across the Americas</title><updated>2025-10-06T20:11:04.944054+00:00</updated><content>&lt;doc fingerprint="f1efd1e76f34fe34"&gt;
  &lt;main&gt;
    &lt;p&gt;Try for Free&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://up.codes/careers?utm_source=HN"/><published>2025-10-06T17:01:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45493713</id><title>Beginnings: The Dempster Dumpster</title><updated>2025-10-06T20:11:04.583917+00:00</updated><content>&lt;doc fingerprint="4ed1d93eafb3af08"&gt;
  &lt;main&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp George Roby Dempster* was born in 1887 to Scottish &amp;amp; Irish immigrants. By age sixteen he had a job running a locomotive (while not in school), having previously worked various railroad jobs in Virgina. As a young adult, Dempster later worked as an equipment operator on the Panama Canal project, and in the early 1930's he formed a construction company with his brothers back home in Knoxville. It was during this time that Dempster developed a novel device for the lifting and transporting of portable storage containers which would be of great significance not only to the refuse collection industry, but to the betterment of sanitation practices in general.&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp The first Dempster Dumpster lifts were employed by the family company on their construction sites, and consisted of a hydraulic hoist mounted to motor truck whereby open top buckets could be engaged, lifted and transported. The device also allowed for emptying of the shallow buckets by simply tipping them as they were held in the raised position by the hoist. First patented in February 1935, the device began to attract the attention of rival operators and before long Dempster Brothers Incorporated was in the truck equipment business.&lt;/p&gt;
    &lt;p&gt;Model 200 LF showing hookup, lift, carry and dump sequence&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp Though Dempster probably didn't originally envision his invention as refuse collector, it turned out to be a perfectly timed solution to what was becoming a critical sanitation problem in many cities. On the collection front, refuse packer trucks were first beginning to gain favor by the late 1930's, but refuse storage methods left much to be desired. Particularly troublesome were businesses and apartments, which generated large concentrations of waste in densely populated areas. This was further exacerbated by a trend toward disposable packaging used by all manner of consumer products, which greatly increased the volume of refuse. Rows of overflowing trash cans were not an uncommon eyesore, a blight on many otherwise modern cities. Another method, was the refuse vault, which had to be shoveled out by the collectors, was not only unsanitary but a tedious waste of manpower.&lt;/p&gt;
    &lt;p&gt;Model H Dumpster system: 6-yard container is raised by lifting against pins welded on each side of bin, power provided by a hydraulic reeving hoist&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp With the availability of larger and now fully enclosed containers with hinged bottom dumping, the Dumpster system first began to attract the attention of sanitation officials. Not surprisingly, it was Dempster's hometown of Knoxville that became America's first "Dumpster City" in 1937, with the purchase of a single Dumpster truck and eighteen containers of two cubic yard capacity each. Not only did the system generate favorable public response, the city also cut collection costs by more than half compared to the old method of open dump trucks. One driver could now pick up, empty and return each container without the need for any additional men. The containers sealed out insects and vermin, and sealed in refuse from wind and weather. This method is termed the "short haul" system. Because small capacity containers are used, it was practical for situations where the disposal point was relatively close to the collection area. At this time, many American municipalities still had dumps located within or near the city limits.&lt;/p&gt;
    &lt;p&gt;To dump, an arrester hook suspends top section of container while hoist is lowered allowing bottom-hinged floor to swing open.&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp There would be many more "Dumpster Cities" in the future. Though it did not happen overnight, the Dempster Dumpster changed refuse handling practice on such a scale that to this day, the term "Dumpster" is commonly used to describe any large refuse storage container, a brand recognition factor that would be the envy of any company. Perhaps this is due to the fact that the "Dumpster" was a piece of equipment that the public had extremely intimate contact with. For example, a Gar Wood Load-Packer might pass briefly by your house two days a week, but a Dumpster was on the street almost all the time, emblazoned with the trademarked name for every user to see.&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp Heavy-duty Dumpster lift hoists were introduced which featured direct-lift hydraulic rams with pivot arms and chains. Dubbed model series 'LF' and 'LFW' (Load Forward) they not only eliminated the cables and pulleys of the old reeving hoist, but also boosted the dead lift capacity to handle bigger containers. The Load Forward hoist would become Dempster's most popular model. Production continued during World War II, with Dempster supplying units to the armed forces as well as other necessary war material.&lt;/p&gt;
    &lt;p&gt;Larger LF (Load Forward) series were capable of lifting more weight than the model H, and the carried filled dumpsters in a forward position over the rear axle. They were well suited as site dumpers in rock quarries. This model 300 LF is carrying a load of stone in a 3-yard bottom-hinged dumpster&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp During the 1940s, Dempster obviously saw great promise in the refuse collection body market and introduced the Dumpster Kolector,, a massive ten-cubic yard end-dumping container fitted with a single trailer axle. It was designed to be towed behind a light truck, and when filled was merely hauled away by a Dumpster hoist truck which could also deliver an empty unit. This system eliminated down time for the crew, and the same Dumpster hoist could service commercial/apartment containers throughout the route. This "satellite" system would find more widespread use in the 1960's with modern front loaders, and eventually spawned "trains" of multiple trailers pulled by a single truck.&lt;/p&gt;
    &lt;p&gt;Dumpster Kolector trailer towed on route by pickup, carried to dump by LFW hoist truck&lt;/p&gt;
    &lt;p&gt;&amp;amp;nbsp&amp;amp;nbsp&amp;amp;nbsp Dempster's Dumpster system was steadily improved in the years following the war, and was an unqualified success. He built a quality product and advertised it heavily. The system was the solution to the dire need of municipalities for sanitary refuse storage, a need not initially addressed by the "big three" rear loader manufacturers, and it spread like wildfire across the country. Their only major competitor was cross-town rival Brooks Brothers, but that firm's Load-Lugger system was better suited to industrial and construction waste and never quite matched Dempster's aggressive marketing and broad selection of containers.&lt;/p&gt;
    &lt;p&gt;Light-duty model 150 "B" from the 1930s. This was similar to the "H", but used a single direct lift hydraulic cylinder instead of reeving hoist. Load was carried rearward in position shown here.&lt;/p&gt;
    &lt;p&gt;At the opposite end of the spectrum from the 150 "B" was this rugged 400 "LF" or Load-Forward model. A pair of massive cylinders did the heavy lifting&lt;/p&gt;
    &lt;p&gt;A horizontally mounted cylinder was used to slide the load forward on to the chassis&lt;/p&gt;
    &lt;p&gt;The Model "BG" (below grade) used a double-spool drum winch which was capable of lifting and lowering containers great distances&lt;/p&gt;
    &lt;p&gt;The Model "BG" raises Dumpster from a deep work pit&lt;/p&gt;
    &lt;p&gt;Dempster 6-cubic yard garbage container from 1940...&lt;/p&gt;
    &lt;p&gt;...raised to the transport position...&lt;/p&gt;
    &lt;p&gt;...and in dumping position.&lt;/p&gt;
    &lt;p&gt;Dempster pioneered the containerization of commercial and residential waste.&lt;/p&gt;
    &lt;p&gt;City of Plainview, Texas: Model LF dumping an 8-yard refuse Dumpster. This is a "sump bottom" type of container, preferred for use in rubbish/garbage collection with liquids present&lt;/p&gt;
    &lt;p&gt;This 1950 model LFW hoist riding atop a REO truck chassis belonging to the City of Baltimore, Bureau of Sanitation, is preparing to lift a Dumpster container. Note the attractive lettering and pinstriping on the hoist, as well as on the ten yard Dumpster container. Idle containers served as a "billboard" for sanitation departments which took great pride in their modern equipment.&lt;/p&gt;
    &lt;p&gt;Dempster Dumpsters in Baltimore, 1950 film (courtesy of Periscope Films)&lt;/p&gt;
    &lt;p&gt;GMC tandem cabover with the big LFW-503C&lt;/p&gt;
    &lt;p&gt;Type DTLF was similar to the LFW, but carried the container in a level position&lt;/p&gt;
    &lt;p&gt;1955: Dempster Dumpster at work in Pampa, Texas (video courtesy of Refuse Truck Media)&lt;/p&gt;
    &lt;p&gt;1957: Dempster Dumpster LFW-253C (video courtesy of Refuse Truck Media)&lt;/p&gt;
    &lt;p&gt;REFERENCES&lt;/p&gt;
    &lt;p&gt;Fountain Citians Who Made A Difference: George R. Dempster&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.classicrefusetrucks.com/albums/DE/DE01.html"/><published>2025-10-06T17:22:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45494126</id><title>How the US got left behind in the electric car race</title><updated>2025-10-06T20:11:04.153457+00:00</updated><content>&lt;doc fingerprint="fffd11bd689395a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How the US got left behind in the global electric car race&lt;/head&gt;
    &lt;p&gt;You could be forgiven for thinking that electric cars might finally be gaining momentum in the US.&lt;/p&gt;
    &lt;p&gt;After all, sales of battery cars topped 1.2 million last year, more than five times the number just four years earlier. Hybrid sales have jumped by a factor of three.&lt;/p&gt;
    &lt;p&gt;Battery-powered cars accounted for 10% of overall sales in August - a new high, according to S&amp;amp;P Global Mobility.&lt;/p&gt;
    &lt;p&gt;And in updates to investors this week, General Motors, Ford, Tesla and other companies all reported record electric sales over the past three months.&lt;/p&gt;
    &lt;p&gt;This marked a bright spot in an industry wrestling with the fallout from still high interest rates and buyers on edge over inflation, tariffs and the wider economy.&lt;/p&gt;
    &lt;p&gt;But analysts say the boom was caused by a dash to buy before the end of a government subsidy that helped knock as much as $7,500 (£5,588) off the price of certain battery electric, plug-in hybrid or fuel cell vehicles.&lt;/p&gt;
    &lt;p&gt;With that tax credit gone as of the end of September, carmakers are expecting momentum to shift into reverse.&lt;/p&gt;
    &lt;p&gt;"It's going to be a vibrant industry, but it's going to be smaller, way smaller than we thought," Ford chief executive Jim Farley said at an event on Tuesday.&lt;/p&gt;
    &lt;p&gt;"I expect that EV demand is going to drop off pretty precipitously," the chief financial officer of General Motors, Paul Jacobson, said at a conference last month, adding it would take time to see how quickly buyers would come back.&lt;/p&gt;
    &lt;p&gt;Even with the recent gains, the US, the world's second biggest car market, stood out as a laggard in electric car sales compared to much of the rest of the world.&lt;/p&gt;
    &lt;p&gt;In the UK, for example, sales of battery electric and hybrid cars made up nearly 30% of new sales last year, according to the International Energy Agency (IEA). Latest industry figures suggest that number is even higher.&lt;/p&gt;
    &lt;p&gt;In Europe, they accounted for roughly one in five sales, while in China, the world's biggest car market, sales of such cars accounted for almost half of overall sales last year, according to the IEA, and they are expected to become the majority this year.&lt;/p&gt;
    &lt;p&gt;Take-up in some other countries, like Norway and Nepal, is even greater.&lt;/p&gt;
    &lt;p&gt;Electric vehicles (EVs) tend to account for a smaller share of sales in Latin America, Africa and other parts of Asia - but growth there has been surging.&lt;/p&gt;
    &lt;head rend="h2"&gt;Policy differences&lt;/head&gt;
    &lt;p&gt;Analysts say adoption in the US has been slowed by comparatively weak government support for the sector, which has limited the kinds of subsidies, trade-in programmes and rules that have helped the industry in places such as China, the UK and Europe.&lt;/p&gt;
    &lt;p&gt;Former President Joe Biden pushed hard to increase take-up, aiming for electric cars to account for half of all sales in the US by 2030.&lt;/p&gt;
    &lt;p&gt;His administration tightened rules on emissions, boosted demand through purchases for government fleets, nudged carmakers to invest with loans and grants for EV investments, spent billions building charging stations and expanded the $7,500 tax credit as a sweetener for buyers.&lt;/p&gt;
    &lt;p&gt;Supporters cast those efforts in part as a competitive imperative, warning that without these US carmakers would risk losing out to competitors from China and other countries.&lt;/p&gt;
    &lt;p&gt;But President Donald Trump, who recently called climate change a "con job", has pushed to scrap many of those measures, including the $7,500 credit, arguing that they were pushing people to buy cars they would not otherwise want.&lt;/p&gt;
    &lt;p&gt;"We're saying ... you're not going to be forced to make all of those cars," he said this summer, while signing a bill aimed at striking down rules from California, which would have phased out sales of petrol-only cars in the state by 2035. "You can make them, but it'll be by the market, judged by the market."&lt;/p&gt;
    &lt;p&gt;Electric cars have become more affordable in the US in recent years - but they still cost more than comparable petrol-powered vehicles.&lt;/p&gt;
    &lt;p&gt;And Chinese carmakers like BYD, which have made rapid inroads in other markets thanks to low prices, have been effectively shut out of the US, due to high tariffs targeting cars made in China, backed by both Biden and Trump.&lt;/p&gt;
    &lt;p&gt;As of August, the average transaction price of an electric car in the US was more than $57,000, according to auto industry research firm Kelley Blue Book, about 16% higher than the average for all cars.&lt;/p&gt;
    &lt;p&gt;The least expensive battery car on offer, a Nissan Leaf, costs about $30,000 (£22,000). By comparison, several models can be found for under £20,000 in the UK.&lt;/p&gt;
    &lt;p&gt;Analysts say what buyers do next hinges on how carmakers set prices in the months ahead, as they contend not only with the end of the tax credit but also tariffs on foreign cars and certain car parts that Trump introduced this spring.&lt;/p&gt;
    &lt;p&gt;Hyundai said this week it would offset the loss of the tax credit by lowering the price for its range of Ioniq EVs. But Tesla said the cost for monthly lease payments of some of its cars would rise.&lt;/p&gt;
    &lt;p&gt;Stephanie Brinley, associate director of S&amp;amp;P Global Mobility, said she did not expect to see many firms follow Hyundai's example, given the pressures from tariffs.&lt;/p&gt;
    &lt;p&gt;While some buyers may opt for EVs anyway, "next year is going to be hard," she warned, noting that her firm is calling for overall car sales to fall by roughly 2% in 2026.&lt;/p&gt;
    &lt;p&gt;"It would have been difficult enough if all you had to deal with is new tariffs, but with new tariffs and the incentive going away, there's two impacts."&lt;/p&gt;
    &lt;p&gt;Carmakers had already been scaling back their investments in electric cars.&lt;/p&gt;
    &lt;p&gt;Researchers say Trump's policy changes could reduce those investments even more.&lt;/p&gt;
    &lt;p&gt;"It's a big hit to the EV industry - there's no tiptoeing around it," said Katherine Yusko, research analyst at the American Security Project&lt;/p&gt;
    &lt;p&gt;"The subsidies were initially a way to level the playing field and now that they're gone the US has a lot of ground to make up."&lt;/p&gt;
    &lt;p&gt;However Ms Brinley said she was hesitant to declare the US behind in an industry still testing out technology alternatives.&lt;/p&gt;
    &lt;p&gt;"Is [electric] really the right thing?" she said. "Saying that we're behind assumes that this is the only and best solution and I think it's a little early to say that."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c8ex2l58en4o"/><published>2025-10-06T17:56:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45494558</id><title>Apps SDK</title><updated>2025-10-06T20:11:03.448892+00:00</updated><content>&lt;doc fingerprint="9dca97fe33d1af9f"&gt;
  &lt;main&gt;
    &lt;p&gt;Our framework to build apps for ChatGPT.&lt;/p&gt;
    &lt;p&gt;Design components and conversational flows that feel native to ChatGPT.&lt;/p&gt;
    &lt;p&gt;Build apps that meet our quality, safety, and policy standards.&lt;/p&gt;
    &lt;p&gt;Identify and prioritize Apps SDK use cases.&lt;/p&gt;
    &lt;p&gt;Create and configure an MCP server.&lt;/p&gt;
    &lt;p&gt;Learn how to deploy your MCP server&lt;/p&gt;
    &lt;p&gt;Improve discovery and behavior with rich metadata.&lt;/p&gt;
    &lt;p&gt;Security and privacy considerations for Apps SDK.&lt;/p&gt;
    &lt;p&gt;Troubleshoot issues in Apps SDK apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://developers.openai.com/apps-sdk/"/><published>2025-10-06T18:27:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45494730</id><title>Nearly half of drivers killed in (Ohio County) crashes had THC in their blood</title><updated>2025-10-06T20:11:03.241023+00:00</updated><content>&lt;doc fingerprint="f7d990199383405d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nearly half of drivers killed in crashes had THC in their blood&lt;/head&gt;
    &lt;head rend="h2"&gt;THC-impaired driving deaths are soaring, and legalization hasn’t slowed the trend.&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Date:&lt;/item&gt;
      &lt;item rend="dd-1"&gt;October 5, 2025&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Source:&lt;/item&gt;
      &lt;item rend="dd-2"&gt;American College of Surgeons&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Summary:&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Over 40% of fatal crash victims had THC levels far above legal limits, showing cannabis use before driving remains widespread. The rate didn’t drop after legalization, suggesting policy changes haven’t altered risky habits. Experts warn that the lack of public awareness around marijuana’s dangers behind the wheel is putting lives at risk.&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Share:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key Takeaways&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In a review of 246 deceased drivers, 41.9% tested positive for active THC in their blood, with an average level of 30.7 ng/mL -- far exceeding most state impairment limits.&lt;/item&gt;
      &lt;item&gt;The high rate of THC positivity remained consistent over six years and was unaffected by the state's legalization of recreational cannabis during the study period.&lt;/item&gt;
      &lt;item&gt;Messaging around the dangers of smoking cannabis and driving needs to be stronger, authors argue.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;New study findings show that over 40% of drivers who died in motor vehicle collisions tested positive for active delta-9-tetrahydrocannabinol (THC) in their system, with average blood levels far exceeding those considered to cause impairment. The research highlights a significant and persistent public health risk that is unchanged by the legalization of recreational cannabis, the authors said.&lt;/p&gt;
    &lt;p&gt;The research will be presented at the American College of Surgeons (ACS) Clinical Congress 2025 in Chicago, October 4-7.&lt;/p&gt;
    &lt;p&gt;Researchers analyzed coroner records from Montgomery County in Ohio from January 2019 to September 2024, focusing on 246 deceased drivers who were tested for THC following a fatal crash. When autopsies are performed, drug screening is typically part of the process. The study period included the state's legalization of recreational cannabis in 2023.&lt;/p&gt;
    &lt;p&gt;"I was surprised to see that level," said lead author Akpofure P. Ekeh, MBBS, FACS, a professor of surgery at Wright State University in Dayton, Ohio. "An average level of 30.7 ng/mL generally means those people must have consumed marijuana at some time close to driving. This isn't about residual use; it's about recent consumption."&lt;/p&gt;
    &lt;p&gt;Key Study Findings&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;High Prevalence: 103 drivers (41.9%) overall tested positive for THC, with yearly rates ranging from 25.7% to 48.9%.&lt;/item&gt;
      &lt;item&gt;No Effect from Legalization: The rate of drivers who tested positive for THC did not change significantly before or after legalization (42.1% vs. 45.2%), indicating that legal status did not influence the behavior of those who chose to drive after use.&lt;/item&gt;
      &lt;item&gt;Consistent Over Time: The high rate of THC positivity showed no significant change over the six-year study period.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The study notes that blood THC levels are typically drawn by the coroner within hours of death, providing an accurate snapshot of a driver's state at the time of the crash. Most states that have set legal limits for driving range from 2 to 5 nanograms per milliliter (ng/mL) -- a threshold the average level in this study (30.7 ng/mL) far exceeded.&lt;/p&gt;
    &lt;p&gt;"The messaging over the last few years has been just the push towards recreational legalization," Dr. Ekeh noted. "The problem is that from a public health standpoint, there has not been enough emphasis on some of the downsides and the dangers that can occur. People should treat smoking marijuana just like they treat alcohol: don't smoke and drive."&lt;/p&gt;
    &lt;p&gt;Co-authors are Lois Nguapa, BS; Clara Mussin Phillips, BS; and Ann Cardosi, BS, MPH.&lt;/p&gt;
    &lt;p&gt;Citation: Ekeh A, et al. Cannabis Prevalence in Drivers Involved in Motor Vehicle Crash Fatalities over a 6-Year Period, Scientific Forum, American College of Surgeons (ACS) Clinical Congress 2025.&lt;/p&gt;
    &lt;p&gt;Note: This research was presented as an abstract at the ACS Clinical Congress Scientific Forum. Research abstracts presented at the ACS Clinical Congress Scientific Forum are reviewed and selected by a program committee but are not yet peer reviewed.&lt;/p&gt;
    &lt;p&gt;Story Source:&lt;/p&gt;
    &lt;p&gt;Materials provided by American College of Surgeons. Note: Content may be edited for style and length.&lt;/p&gt;
    &lt;p&gt;Cite This Page:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sciencedaily.com/releases/2025/10/251005085621.htm"/><published>2025-10-06T18:43:00+00:00</published></entry></feed>