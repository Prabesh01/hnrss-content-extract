<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-10T20:12:58.661467+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46214693</id><title>Revisiting "Let's Build a Compiler"</title><updated>2025-12-10T20:13:12.380650+00:00</updated><content>&lt;doc fingerprint="b101145b7036df98"&gt;
  &lt;main&gt;
    &lt;p&gt;There's an old compiler-building tutorial that has become part of the field's lore: the Let's Build a Compiler series by Jack Crenshaw (published between 1988 and 1995).&lt;/p&gt;
    &lt;p&gt;I ran into it in 2003 and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite often in Hacker News threads. Why is that? Why does a tutorial from 35 years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that are virtually unknown for the new generation of programmers - hold sway over compiler enthusiasts? I've decided to find out.&lt;/p&gt;
    &lt;p&gt;The tutorial is easily available and readable online, but just re-reading it seemed insufficient. So I've decided on meticulously translating the compilers built in it to Python and emit a more modern target - WebAssembly. It was an enjoyable process and I want to share the outcome and some insights gained along the way.&lt;/p&gt;
    &lt;p&gt;The result is this code repository. Of particular interest is the TUTORIAL.md file, which describes how each part in the original tutorial is mapped to my code. So if you want to read the original tutorial but play with code you can actually easily try on your own, feel free to follow my path.&lt;/p&gt;
    &lt;head rend="h2"&gt;A sample&lt;/head&gt;
    &lt;p&gt;To get a taste of the input language being compiled and the output my compiler generates, here's a sample program in the KISS language designed by Jack Crenshaw:&lt;/p&gt;
    &lt;code&gt;var X=0

 { sum from 0 to n-1 inclusive, and add to result }
 procedure addseq(n, ref result)
     var i, sum  { 0 initialized }
     while i &amp;lt; n
         sum = sum + i
         i = i + 1
     end
     result = result + sum
 end

 program testprog
 begin
     addseq(11, X)
 end
 .
&lt;/code&gt;
    &lt;p&gt;It's from part 13 of the tutorial, so it showcases procedures along with control constructs like the while loop, and passing parameters both by value and by reference. Here's the WASM text generated by my compiler for part 13:&lt;/p&gt;
    &lt;code&gt;(module
  (memory 8)
  ;; Linear stack pointer. Used to pass parameters by ref.
  ;; Grows downwards (towards lower addresses).
  (global $__sp (mut i32) (i32.const 65536))

  (global $X (mut i32) (i32.const 0))

  (func $ADDSEQ (param $N i32) (param $RESULT i32)
    (local $I i32)
    (local $SUM i32)
    loop $loop1
      block $breakloop1
        local.get $I
        local.get $N
        i32.lt_s
        i32.eqz
        br_if $breakloop1
        local.get $SUM
        local.get $I
        i32.add
        local.set $SUM
        local.get $I
        i32.const 1
        i32.add
        local.set $I
        br $loop1
      end
    end
    local.get $RESULT
    local.get $RESULT
    i32.load
    local.get $SUM
    i32.add
    i32.store
  )

  (func $main (export "main") (result i32)
    i32.const 11
    global.get $__sp      ;; make space on stack
    i32.const 4
    i32.sub
    global.set $__sp
    global.get $__sp
    global.get $X
    i32.store
    global.get $__sp    ;; push address as parameter
    call $ADDSEQ
    ;; restore parameter X by ref
    global.get $__sp
    i32.load offset=0
    global.set $X
    ;; clean up stack for ref parameters
    global.get $__sp
    i32.const 4
    i32.add
    global.set $__sp
    global.get $X
  )
)
&lt;/code&gt;
    &lt;p&gt;You'll notice that there is some trickiness in the emitted code w.r.t. handling the by-reference parameter (my previous post deals with this issue in more detail). In general, though, the emitted code is inefficient - there is close to 0 optimization applied.&lt;/p&gt;
    &lt;p&gt;Also, if you're very diligent you'll notice something odd about the global variable X - it seems to be implicitly returned by the generated main function. This is just a testing facility that makes my compiler easy to test. All the compilers are extensively tested - usually by running the generated WASM code [1] and verifying expected results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insights - what makes this tutorial so special?&lt;/head&gt;
    &lt;p&gt;While reading the original tutorial again, I had on opportunity to reminisce on what makes it so effective. Other than the very fluent and conversational writing style of Jack Crenshaw, I think it's a combination of two key factors:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The tutorial builds a recursive-descent parser step by step, rather than giving a long preface on automata and table-based parser generators. When I first encountered it (in 2003), it was taken for granted that if you want to write a parser then lex + yacc are the way to go [2]. Following the development of a simple and clean hand-written parser was a revelation that wholly changed my approach to the subject; subsequently, hand-written recursive-descent parsers have been my go-to approach for almost 20 years now.&lt;/item&gt;
      &lt;item&gt;Rather than getting stuck in front-end minutiae, the tutorial goes straight to generating working assembly code, from very early on. This was also a breath of fresh air for engineers who grew up with more traditional courses where you spend 90% of the time on parsing, type checking and other semantic analysis and often run entirely out of steam by the time code generation is taught.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To be honest, I don't think either of these are a big problem with modern resources, but back in the day the tutorial clearly hit the right nerve with many people.&lt;/p&gt;
    &lt;head rend="h2"&gt;What else does it teach us?&lt;/head&gt;
    &lt;p&gt;Jack Crenshaw's tutorial takes the syntax-directed translation approach, where code is emitted while parsing, without having to divide the compiler into explicit phases with IRs. As I said above, this is a fantastic approach for getting started, but in the latter parts of the tutorial it starts showing its limitations. Especially once we get to types, it becomes painfully obvious that it would be very nice if we knew the types of expressions before we generate code for them.&lt;/p&gt;
    &lt;p&gt;I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial at some point after part 14, but it may very well be. He keeps writing how the emitted code is clearly sub-optimal [3] and can be improved, but IMHO it's just not that easy to improve using the syntax-directed translation strategy. With perfect hindsight vision, I would probably use Part 14 (types) as a turning point - emitting some kind of AST from the parser and then doing simple type checking and analysis on that AST prior to generating code from it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;All in all, the original tutorial remains a wonderfully readable introduction to building compilers. This post and the GitHub repository it describes are a modest contribution that aims to improve the experience of folks reading the original tutorial today and not willing to use obsolete technologies. As always, let me know if you run into any issues or have questions!&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;This is done using the Python bindings to wasmtime.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;By the way, gcc switched from YACC to hand-written recursive-descent parsing in the 2004-2006 timeframe, and Clang has been implemented with a recursive-descent parser from the start (2007).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Concretely: when we compile subexpr1 + subexpr2 and the two sides have different types, it would be mighty nice to know that before we actually generate the code for both sub-expressions. But the syntax-directed translation approach just doesn't work that way.&lt;/p&gt;
          &lt;p&gt;To be clear: it's easy to generate working code; it's just not easy to generate optimal code without some sort of type analysis that's done before code is actually generated.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/"/><published>2025-12-10T06:22:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46216583</id><title>Factor 0.101 now available</title><updated>2025-12-10T20:13:11.921959+00:00</updated><content>&lt;doc fingerprint="748063284d11bc94"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Factor 0.101 now available&lt;/head&gt;
    &lt;p&gt;Monday, December 8, 2025&lt;/p&gt;
    &lt;p&gt;“Keep thy airspeed up, lest the earth come from below and smite thee.” - William Kershner&lt;/p&gt;
    &lt;p&gt;I’m very pleased to announce the release of Factor 0.101!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;OS/CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;Windows&lt;/cell&gt;
        &lt;cell role="head"&gt;Mac OS&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;x86&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;x86-64&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Source code: 0.101&lt;/p&gt;
    &lt;p&gt;This release is brought to you with almost 700 commits by the following individuals:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Aleksander Sabak, Andy Kluger, Cat Stevens, Dmitry Matveyev, Doug Coleman, Giftpflanze, John Benediktsson, Jon Harper, Jonas Bernouli, Leo Mehraban, Mike Stevenson, Nicholas Chandoke, Niklas Larsson, Rebecca Kelly, Samuel Tardieu, Stefan Schmiedl, @Bruno-366, @bobisageek, @coltsingleactionarmyocelot, @inivekin, @knottio, @timor&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Besides some bug fixes and library improvements, I want to highlight the following changes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Moved the UI to render buttons and scrollbars rather than using images, which allows easier theming.&lt;/item&gt;
      &lt;item&gt;Fixed HiDPI scaling on Linux and Windows, although it currently doesn’t update the window settings when switching between screens with different scaling factors.&lt;/item&gt;
      &lt;item&gt;Update to Unicode 17.0.0.&lt;/item&gt;
      &lt;item&gt;Plugin support for the Neovim editor.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some possible backwards compatibility issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The argument order to &lt;code&gt;ltake&lt;/code&gt;was swapped to be more consistent with words like&lt;code&gt;head&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;environment&lt;/code&gt;vocabulary on Windows now supports disambiguating&lt;code&gt;f&lt;/code&gt;and&lt;code&gt;""&lt;/code&gt;(empty) values&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/atom&lt;/code&gt;folder was removed in favor of the factor/atom-language-factor repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/Factor.tmbundle&lt;/code&gt;folder was removed in favor of the factor/factor.tmbundle repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/vim&lt;/code&gt;folder was removed in favor of the factor/factor.vim repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;http&lt;/code&gt;vocabulary&lt;code&gt;request&lt;/code&gt;tuple had a slot rename from&lt;code&gt;post-data&lt;/code&gt;to&lt;code&gt;data&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;furnace.asides&lt;/code&gt;vocabulary had a slot rename from&lt;code&gt;post-data&lt;/code&gt;to&lt;code&gt;data&lt;/code&gt;, and might require running&lt;code&gt;ALTER TABLE asides RENAME COLUMN "post-data" TO data;&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;html.streams&lt;/code&gt;vocabulary was renamed to&lt;code&gt;io.streams.html&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;pdf.streams&lt;/code&gt;vocabulary was renamed to&lt;code&gt;io.streams.pdf&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;What is Factor&lt;/head&gt;
    &lt;p&gt;Factor is a concatenative, stack-based programming language with high-level features including dynamic types, extensible syntax, macros, and garbage collection. On a practical side, Factor has a full-featured library, supports many different platforms, and has been extensively documented.&lt;/p&gt;
    &lt;p&gt;The implementation is fully compiled for performance, while still supporting interactive development. Factor applications are portable between all common platforms. Factor can deploy stand-alone applications on all platforms. Full source code for the Factor project is available under a BSD license.&lt;/p&gt;
    &lt;head rend="h3"&gt;New libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;base92: adding support for Base92 encoding/decoding&lt;/item&gt;
      &lt;item&gt;bitcask: implementing the Bitcask key/value database&lt;/item&gt;
      &lt;item&gt;bluesky: adding support for the BlueSky protocol&lt;/item&gt;
      &lt;item&gt;calendar.holidays.world: adding some new holidays including World Emoji Day&lt;/item&gt;
      &lt;item&gt;classes.enumeration: adding enumeration classes and new &lt;code&gt;ENUMERATION:&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;colors.oklab: adding support for OKLAB color space&lt;/item&gt;
      &lt;item&gt;colors.oklch: adding support for OKLCH color space&lt;/item&gt;
      &lt;item&gt;colors.wavelength: adding &lt;code&gt;wavelength&amp;gt;rgba&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;combinators.syntax: adding experimental combinator syntax words &lt;code&gt;@[&lt;/code&gt;,&lt;code&gt;*[&lt;/code&gt;, and&lt;code&gt;&amp;amp;[&lt;/code&gt;, and short-circuiting&lt;code&gt;n&amp;amp;&amp;amp;[&lt;/code&gt;,&lt;code&gt;n||[&lt;/code&gt;,&lt;code&gt;&amp;amp;&amp;amp;[&lt;/code&gt;and&lt;code&gt;||[&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;continuations.extras: adding &lt;code&gt;with-datastacks&lt;/code&gt;and&lt;code&gt;datastack-states&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;dotenv: implementing support for Dotenv files&lt;/item&gt;
      &lt;item&gt;edn: implementing support for Extensible Data Notation&lt;/item&gt;
      &lt;item&gt;editors.cursor: adding support for the Cursor editor&lt;/item&gt;
      &lt;item&gt;editors.rider: adding support for the JetBrains Rider editor&lt;/item&gt;
      &lt;item&gt;gitignore: parser for &lt;code&gt;.gitignore&lt;/code&gt;files&lt;/item&gt;
      &lt;item&gt;http.json: promoted &lt;code&gt;json.http&lt;/code&gt;and added some useful words&lt;/item&gt;
      &lt;item&gt;io.streams.farkup: a Farkup formatted stream protocol&lt;/item&gt;
      &lt;item&gt;io.streams.markdowns: a Markdown formatted stream protocol&lt;/item&gt;
      &lt;item&gt;locals.lazy: prototype of emit syntax&lt;/item&gt;
      &lt;item&gt;monadics: alternative vocabulary for using Haskell-style monads, applicatives, and functors&lt;/item&gt;
      &lt;item&gt;multibase: implementation of Multibase&lt;/item&gt;
      &lt;item&gt;pickle: support for the Pickle serialization format&lt;/item&gt;
      &lt;item&gt;persistent.hashtables.identity: support an identity-hashcode version of persisent hashtables&lt;/item&gt;
      &lt;item&gt;raylib.live-coding: demo of a vocabulary to do “live coding” of Raylib programs&lt;/item&gt;
      &lt;item&gt;rdap: support for the Registration Data Access Protocol&lt;/item&gt;
      &lt;item&gt;reverse: implementation of the std::flip&lt;/item&gt;
      &lt;item&gt;slides.cli: simple text-based command-line interface for slides&lt;/item&gt;
      &lt;item&gt;tools.highlight: command-line syntax-highlighting tool&lt;/item&gt;
      &lt;item&gt;tools.random: command-line random generator tool&lt;/item&gt;
      &lt;item&gt;ui.pens.rounded: adding rounded corner pen&lt;/item&gt;
      &lt;item&gt;ui.pens.theme: experimental themed pen&lt;/item&gt;
      &lt;item&gt;ui.tools.theme: some words for updating UI developer tools themes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Improved libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;alien.syntax: added &lt;code&gt;C-LIBRARY:&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;assocs.extras: added &lt;code&gt;nzip&lt;/code&gt;and&lt;code&gt;nunzip&lt;/code&gt;,&lt;code&gt;map-zip&lt;/code&gt;and&lt;code&gt;map-unzip&lt;/code&gt;macros&lt;/item&gt;
      &lt;item&gt;base32: adding the human-oriented Base32 encoding via &lt;code&gt;zbase32&amp;gt;&lt;/code&gt;and&lt;code&gt;&amp;gt;zbase32&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;base64: minor performance improvement&lt;/item&gt;
      &lt;item&gt;benchmark: adding more benchmarks&lt;/item&gt;
      &lt;item&gt;bootstrap.assembler: fixes for ARM-64&lt;/item&gt;
      &lt;item&gt;brainfuck: added &lt;code&gt;BRAINFUCK:&lt;/code&gt;syntax word and&lt;code&gt;interpret-brainfuck&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;bson: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;cache: implement &lt;code&gt;M\ cache-assoc delete-at&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;calendar: adding &lt;code&gt;year&amp;lt;&lt;/code&gt;,&lt;code&gt;year&amp;lt;=&lt;/code&gt;,&lt;code&gt;year&amp;gt;&lt;/code&gt;,&lt;code&gt;year&amp;gt;=&lt;/code&gt;words&lt;/item&gt;
      &lt;item&gt;calendar.format: parse human-readable and elapsed-time output back into duration objects&lt;/item&gt;
      &lt;item&gt;cbor: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;classes.mixin: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;classes.singleton: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;classes.tuple: added &lt;code&gt;tuple&amp;gt;slots&lt;/code&gt;, rename&lt;code&gt;tuple&amp;gt;array&lt;/code&gt;to&lt;code&gt;pack-tuple&lt;/code&gt;and&lt;code&gt;&amp;gt;tuple&lt;/code&gt;to&lt;code&gt;unpack-tuple&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;classes.union: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;checksums.sha: some 20-40% performance improvements&lt;/item&gt;
      &lt;item&gt;command-line: allow passing script name of &lt;code&gt;-&lt;/code&gt;to use stdin&lt;/item&gt;
      &lt;item&gt;command-line.parser: support for Argument Parser Commands&lt;/item&gt;
      &lt;item&gt;command-line.startup: document &lt;code&gt;-q&lt;/code&gt;quiet mode flag&lt;/item&gt;
      &lt;item&gt;concurrency.combinators: faster &lt;code&gt;parallel-map&lt;/code&gt;and&lt;code&gt;parallel-assoc-map&lt;/code&gt;using a count-down latch&lt;/item&gt;
      &lt;item&gt;concurrency.promises: 5-7% performance improvement&lt;/item&gt;
      &lt;item&gt;continuations: improve docs and fix stack effect for &lt;code&gt;ifcc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;countries: adding &lt;code&gt;CQ&lt;/code&gt;country code for Sark&lt;/item&gt;
      &lt;item&gt;cpu.architecture: fix &lt;code&gt;*-branch&lt;/code&gt;stack effects&lt;/item&gt;
      &lt;item&gt;cpu.arm: fixes for ARM-64&lt;/item&gt;
      &lt;item&gt;crontab: added &lt;code&gt;parse-crontab&lt;/code&gt;which ignores blank lines and comments&lt;/item&gt;
      &lt;item&gt;db: making &lt;code&gt;query-each&lt;/code&gt;row-polymorphic&lt;/item&gt;
      &lt;item&gt;delegate.protocols: adding &lt;code&gt;keys&lt;/code&gt;and&lt;code&gt;values&lt;/code&gt;to&lt;code&gt;assoc-protocol&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;discord: better support for network disconnects, added a configurable retry interval&lt;/item&gt;
      &lt;item&gt;discord.chatgpt-bot: some fixes for LM Studio&lt;/item&gt;
      &lt;item&gt;editors: make the editor restart nicer looking&lt;/item&gt;
      &lt;item&gt;editors.focus: support open-file-to-line-number on newer releases, support Linux and Window&lt;/item&gt;
      &lt;item&gt;editors.zed: support use of Zed on Linux&lt;/item&gt;
      &lt;item&gt;endian: faster endian conversions of c-ptr-like objects&lt;/item&gt;
      &lt;item&gt;environment: adding &lt;code&gt;os-env?&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;eval: move datastack and error messages to stderr&lt;/item&gt;
      &lt;item&gt;fonts: make &lt;code&gt;&amp;lt;font&amp;gt;&lt;/code&gt;take a name, easier defaults&lt;/item&gt;
      &lt;item&gt;furnace.asides: rename &lt;code&gt;post-data&lt;/code&gt;slot on&lt;code&gt;aside&lt;/code&gt;tuples to&lt;code&gt;data&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;generalizations: moved some dip words to shuffle&lt;/item&gt;
      &lt;item&gt;help.tour: fix some typos/grammar&lt;/item&gt;
      &lt;item&gt;html.templates.chloe: improve use of &lt;code&gt;CDATA&lt;/code&gt;tags for unescaping output&lt;/item&gt;
      &lt;item&gt;http: rename &lt;code&gt;post-data&lt;/code&gt;slot on&lt;code&gt;request&lt;/code&gt;tuples to&lt;code&gt;data&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;http.json: adding &lt;code&gt;http-json&lt;/code&gt;that doesn’t return the response object&lt;/item&gt;
      &lt;item&gt;http.websockets: making &lt;code&gt;read-websocket-loop&lt;/code&gt;row-polymorphic&lt;/item&gt;
      &lt;item&gt;ini-file: adding &lt;code&gt;ini&amp;gt;file&lt;/code&gt;,&lt;code&gt;file&amp;gt;ini&lt;/code&gt;, and use&lt;code&gt;LH{ }&lt;/code&gt;to preserve configuration order&lt;/item&gt;
      &lt;item&gt;io.encodings.detect: adding &lt;code&gt;utf7&lt;/code&gt;detection&lt;/item&gt;
      &lt;item&gt;io.encodings.utf8: adding &lt;code&gt;utf8-bom&lt;/code&gt;to handle optional BOM&lt;/item&gt;
      &lt;item&gt;io.random: speed up &lt;code&gt;random-line&lt;/code&gt;and&lt;code&gt;random-lines&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;io.streams.ansi: adding documentation and tests, support dim foreground on terminals that support it&lt;/item&gt;
      &lt;item&gt;io.streams.escape-codes: adding documentation and tests&lt;/item&gt;
      &lt;item&gt;ip-parser: adding IPV4 and IPV6 network words&lt;/item&gt;
      &lt;item&gt;kernel: adding &lt;code&gt;until*&lt;/code&gt;, fix docs for&lt;code&gt;and*&lt;/code&gt;and&lt;code&gt;or*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;linked-sets: adding &lt;code&gt;LS{&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;lists.lazy: changed the argument order in &lt;code&gt;ltake&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;macho: support a few more link edit commands&lt;/item&gt;
      &lt;item&gt;make: adding &lt;code&gt;,%&lt;/code&gt;for a&lt;code&gt;push-at&lt;/code&gt;variant&lt;/item&gt;
      &lt;item&gt;mason.release.tidy: cleanup a few more git artifacts&lt;/item&gt;
      &lt;item&gt;math.combinatorics: adding counting words&lt;/item&gt;
      &lt;item&gt;math.distances: adding &lt;code&gt;jaro-distance&lt;/code&gt;and&lt;code&gt;jaro-winkler-distance&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.extras: added &lt;code&gt;all-removals&lt;/code&gt;, support RecamÃ¡nâs sequence, and Tribonacci Numbers&lt;/item&gt;
      &lt;item&gt;math.factorials: added &lt;code&gt;subfactorial&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.functions: added “closest to zero” modulus&lt;/item&gt;
      &lt;item&gt;math.parser: improve ratio parsing for consistency&lt;/item&gt;
      &lt;item&gt;math.primes: make &lt;code&gt;prime?&lt;/code&gt;safe from non-integer inputs&lt;/item&gt;
      &lt;item&gt;math.runge-kutta: make generalized improvements to the Runge-Kutta solver&lt;/item&gt;
      &lt;item&gt;math.similarity: adding &lt;code&gt;jaro-similarity&lt;/code&gt;,&lt;code&gt;jaro-winkler-similarity&lt;/code&gt;, and&lt;code&gt;trigram-similarity&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.text.english: fix issue with very large and very small floats&lt;/item&gt;
      &lt;item&gt;metar: updated the abbreviations glossary&lt;/item&gt;
      &lt;item&gt;mime.types: updating &lt;code&gt;mime.types&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;msgpack: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;qw: adding &lt;code&gt;qw:&lt;/code&gt;syntax&lt;/item&gt;
      &lt;item&gt;path-finding: added &lt;code&gt;find-path*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;peg.parsers: faster &lt;code&gt;list-of&lt;/code&gt;and&lt;code&gt;list-of-many&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;progress-bars.models: added &lt;code&gt;with-progress-display&lt;/code&gt;,&lt;code&gt;map-with-progress-bar&lt;/code&gt;,&lt;code&gt;each-with-progress-bar&lt;/code&gt;, and&lt;code&gt;reduce-with-progress-bar&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;raylib: adding &lt;code&gt;trace-log&lt;/code&gt;and&lt;code&gt;set-trace-log-level&lt;/code&gt;, updated to Raylib 5.5&lt;/item&gt;
      &lt;item&gt;readline-listener: store history across sessions, support color on terminals that support it&lt;/item&gt;
      &lt;item&gt;robohash: support for &lt;code&gt;"set4"&lt;/code&gt;,&lt;code&gt;"set5"&lt;/code&gt;, and&lt;code&gt;"set6"&lt;/code&gt;types&lt;/item&gt;
      &lt;item&gt;sequences: rename &lt;code&gt;midpoint@&lt;/code&gt;to&lt;code&gt;midpoint&lt;/code&gt;, faster&lt;code&gt;each-from&lt;/code&gt;and&lt;code&gt;map-reduce&lt;/code&gt;on slices&lt;/item&gt;
      &lt;item&gt;sequences.extras: adding &lt;code&gt;find-nth&lt;/code&gt;,&lt;code&gt;find-nth-last&lt;/code&gt;,&lt;code&gt;subseq-indices&lt;/code&gt;,&lt;code&gt;deep-nth&lt;/code&gt;,&lt;code&gt;deep-nth-of&lt;/code&gt;,&lt;code&gt;2none?&lt;/code&gt;,&lt;code&gt;filter-errors&lt;/code&gt;,&lt;code&gt;reject-errors&lt;/code&gt;,&lt;code&gt;all-same?&lt;/code&gt;,&lt;code&gt;adjacent-differences&lt;/code&gt;, and&lt;code&gt;partial-sum&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;sequences.generalizations: fix &lt;code&gt;?firstn&lt;/code&gt;and&lt;code&gt;?lastn&lt;/code&gt;for string inputs, removed&lt;code&gt;(nsequence)&lt;/code&gt;which duplicates&lt;code&gt;set-firstn-unsafe&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.prefixed: swap order of &lt;code&gt;&amp;lt;prefixed&amp;gt;&lt;/code&gt;arguments to match&lt;code&gt;prefix&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.repeating: adding &lt;code&gt;&amp;lt;cycles-from&amp;gt;&lt;/code&gt;and&lt;code&gt;cycle-from&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.snipped: fixed out-of-bounds issues&lt;/item&gt;
      &lt;item&gt;scryfall: update for duskmourn&lt;/item&gt;
      &lt;item&gt;shuffle: improve stack-checking of &lt;code&gt;shuffle(&lt;/code&gt;syntax, added&lt;code&gt;SHUFFLE:&lt;/code&gt;syntax,&lt;code&gt;nreverse&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sorting: fix &lt;code&gt;sort-with&lt;/code&gt;to apply the quot with access to the stack below&lt;/item&gt;
      &lt;item&gt;sorting.human: implement human sorting improved&lt;/item&gt;
      &lt;item&gt;system-info.macos: adding “Tahoe” code-name for macOS 26&lt;/item&gt;
      &lt;item&gt;terminfo: add words for querying specific output capabilities&lt;/item&gt;
      &lt;item&gt;threads: define a generalized &lt;code&gt;linked-thread&lt;/code&gt;which used to be for&lt;code&gt;concurrency.mailboxes&lt;/code&gt;only&lt;/item&gt;
      &lt;item&gt;toml: use linked-assocs to preserve order, adding &lt;code&gt;&amp;gt;toml&lt;/code&gt;and&lt;code&gt;write-toml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;tools.annotations: adding &lt;code&gt;&amp;lt;WATCH ... WATCH&amp;gt;&lt;/code&gt;syntax&lt;/item&gt;
      &lt;item&gt;tools.deploy: adding a command-line interface for deploy options&lt;/item&gt;
      &lt;item&gt;tools.deploy.backend: fix boot image location in system-wide installations&lt;/item&gt;
      &lt;item&gt;tools.deploy.unix: change binary name to append &lt;code&gt;.out&lt;/code&gt;to fix conflict with vocab resources&lt;/item&gt;
      &lt;item&gt;tools.directory-to-file: better test file metrics, print filename for editing&lt;/item&gt;
      &lt;item&gt;tools.memory: adding &lt;code&gt;heap-stats-of&lt;/code&gt;arbitrary sequence of instances, and&lt;code&gt;total-size&lt;/code&gt;size of everything pointed to by an object&lt;/item&gt;
      &lt;item&gt;txon: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;ui: adding &lt;code&gt;adjust-font-size&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ui.gadgets.buttons: stop using images and respect theme colors&lt;/item&gt;
      &lt;item&gt;ui.gadgets.sliders: stop using images and respect theme colors&lt;/item&gt;
      &lt;item&gt;ui.theme.base16: adding a lot more (270!) Base16 Themes&lt;/item&gt;
      &lt;item&gt;ui.tools: adding font-sizing keyboard shortcuts&lt;/item&gt;
      &lt;item&gt;ui.tools.browser: more responsive font sizing&lt;/item&gt;
      &lt;item&gt;ui.tools.listener: more responsive font sizing, adding some UI listener styling&lt;/item&gt;
      &lt;item&gt;ui.tools.listener.completion: allow spaces in history search popup&lt;/item&gt;
      &lt;item&gt;unicode: update to Unicode 17.0.0&lt;/item&gt;
      &lt;item&gt;webapps.planet: improve CSS for &lt;code&gt;video&lt;/code&gt;tags&lt;/item&gt;
      &lt;item&gt;words: adding &lt;code&gt;define-temp-syntax&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;zoneinfo: update to version 2025b&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Removed libraries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;ui.theme.images&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;VM Improvements:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More work on ARM64 backend (fix set-callstack, fix generic dispatch)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://re.factorcode.org/2025/12/factor-0-101-now-available.html"/><published>2025-12-10T11:33:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218538</id><title>COM Like a Bomb: Rust Outlook Add-in</title><updated>2025-12-10T20:13:11.227946+00:00</updated><content>&lt;doc fingerprint="2e09bb17d99d220d"&gt;
  &lt;main&gt;&lt;p&gt;One of legal tech's clichés is that "lawyers live in Word".&lt;/p&gt;&lt;p&gt;This is demonstrably incorrect. I, for example, am a lawyer and in fact live in London, England.&lt;/p&gt;&lt;p&gt;But what they mean to say is that lawyers spend much of their time editing documents in Microsoft Word. This is because, for the most part, opening &lt;code&gt;.docx&lt;/code&gt; files in Word is the default behavior where it's
        installed (everywhere). Lawyers, and again I'm speaking from experience here, are generally lazy when it comes
        to
        technology. Defaults are the law.&lt;/p&gt;&lt;p&gt;This is rational. Clients pay thousands of dollars per hour to have their legal needs addressed by the top law firms in the world. This means that law firms account for every moment their lawyers' working days. Generally, in 6-minute increments (or, 0.1 hours). No client is paying even 0.3 for their lawyer to learn a new software paradigm, and most law firms don't find forgoing revenue to train lawyers on new systems that will make them faster especially motivating.&lt;/p&gt;&lt;p&gt;So to get a foothold into legal, we need to make Tritium slot as nearly as possible into the existing workflow.&lt;/p&gt;&lt;p&gt;So where does the legal work flow originate?&lt;/p&gt;&lt;p&gt;Three places: (1) the document management system (DMS), (2) the desktop and (3) email.&lt;/p&gt;&lt;p&gt;We've previously talked about iManage, one of the most important document management systems in legal. There are other important ones such as NetDocuments, and our integrations into those will be the subject of another post.&lt;/p&gt;&lt;p&gt;Today, we're focused on the third place.&lt;/p&gt;&lt;p&gt;We're giving access to Tritium right in the lawyer's inbox.&lt;/p&gt;&lt;p&gt;We're going to replicate our "Open with Tritium" desktop entry point in Outlook. Here's what it looks like on the desktop:&lt;/p&gt;&lt;head rend="h2"&gt;Outlook Integration&lt;/head&gt;&lt;p&gt;"New Outlook" is some sort of half-implemented WebView mess that requires javascript round-tripped from a host server to plug in new features.&lt;/p&gt;&lt;p&gt;We'll eventually have to get in there, too, but for the most part law firms seem to have thus far stuck with the much more featureful "legacy Outlook". That version is a venerable, performant, C++-based Windows desktop application.&lt;/p&gt;&lt;p&gt;So, how do we plug into it?&lt;/p&gt;&lt;head rend="h2"&gt;COM&lt;/head&gt;&lt;p&gt;Before even the easy 100 MB of RAM days let alone the advent of &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;electron&lt;/code&gt; and
        &lt;code&gt;JSON&lt;/code&gt;,
        the Windows operating system needed a way to allow processes and applications to communicate in a
        language-agnostic way. This ultimately resulted in the "Component Object Model" or
        COM. COM allows
        us to plug
        into various entry points using a Dynamically Linked Library (.dll) which follows a strict
        ABI with certain
        calling conventions.
    &lt;/p&gt;&lt;p&gt;COM lives on today, and it is still an effective way to communicate with various processes, including Windows 11's File Explorer.&lt;/p&gt;&lt;p&gt;Fortunately, COM is supported in the &lt;code&gt;windows-rs&lt;/code&gt; Rust crate.[1]&lt;/p&gt;&lt;p&gt;To add a link to Outlook's attachment context menu, we need to inherit from a series of COM classes: &lt;code&gt;IDispatch&lt;/code&gt;,
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; and ultimately &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; provides an &lt;code&gt;IDispatch&lt;/code&gt; implementation out-of-the box which exposes a
        &lt;code&gt;trait&lt;/code&gt; that looks like the below:
    &lt;/p&gt;&lt;code&gt;fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

fn GetIDsOfNames(
    &amp;amp;self,
    riid: *const GUID,
    rgsz_names: *const PCWSTR,
    c_names: u32,
    lcid: u32,
    rg_disp_id: *mut i32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

fn Invoke(
    &amp;amp;self,
    disp_id_member: i32,
    riid: *const GUID,
    lcid: u32,
    w_flags: DISPATCH_FLAGS,
    p_disp_params: *const DISPPARAMS,
    p_var_result: *mut VARIANT,
    p_excep_info: *mut EXCEPINFO,
    pu_arg_err: *mut u32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
&lt;/code&gt;&lt;p&gt;These functions provide the basic COM dispatching mechanisms.&lt;/p&gt;&lt;p&gt;Using them a caller is able to look up the &lt;code&gt;rg_disp_id&lt;/code&gt; of a particular named function in your
        implementation, then &lt;code&gt;Invoke&lt;/code&gt; that function with the results optionally populating
        &lt;code&gt;p_var_result&lt;/code&gt; which is a pointer to a mutable union of possible result types.
    &lt;/p&gt;&lt;p&gt;This is the basic wiring which allows us to implement the required &lt;code&gt;IDTExensibility2&lt;/code&gt; and
        &lt;code&gt;IRibbonExtensibility&lt;/code&gt; classes.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; doesn't implement these classes, but does help us by providing the &lt;code&gt;interface&lt;/code&gt;
        procedural macro which handles setting up the VTables to map our struct's methods to the COM
        ABI.&lt;/p&gt;&lt;p&gt;We use the class's &lt;code&gt;GUID&lt;/code&gt; for the macro to establish that we're implementing
        &lt;code&gt;IDTExtensibility2&lt;/code&gt;.[2]
    &lt;/p&gt;&lt;code&gt;#[windows::core::interface("B65AD801-ABAF-11D0-BB8B-00A0C90F2744")]
pub unsafe trait IDTExtensibility2: IDispatch {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT;
    unsafe fn OnDisconnection(&amp;amp;self, mode: i32, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnAddInsUpdate(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnStartupComplete(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnBeginShutdown(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
}
&lt;/code&gt;&lt;p&gt;Then, we implement that interface for our &lt;code&gt;struct&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;#[implement(IRibbonExtensibility, IDTExtensibility2, IDispatch)]
struct Addin;
&lt;/code&gt;&lt;p&gt;This causes the procedural macro to generate &lt;code&gt;IRibbonExensibility_Impl&lt;/code&gt;,
        &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; and &lt;code&gt;IDispatch_Impl&lt;/code&gt; traits for us to implement in
        &lt;code&gt;struct Addin_Impl&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Here's the initial Tritium &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; verbatim for example:&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {
        log("OnConnection called()");
        // Don't do any heavy operations here that could crash Outlook
        S_OK
    }

    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnDisconnection called()");
        S_OK
    }

    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnAddInsUpdate called()");
        S_OK
    }

    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnStartupComplete called()");
        S_OK
    }

    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnBeginShutdown called()");
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;As discussed below, we used an LLM to generate these signatures since they aren't provided in the &lt;code&gt;windows-rs&lt;/code&gt; crate out of the box.
    &lt;/p&gt;&lt;p&gt;Since our simple add-in at this point doesn't maintain any global state that would otherwise be constructed, adjusted and deconstructed at &lt;code&gt;OnConnection&lt;/code&gt;, &lt;code&gt;OnAddInsUpdate&lt;/code&gt; and
        &lt;code&gt;OnBeginShutdown&lt;/code&gt;, respectively, we just log the call for debugging and return &lt;code&gt;S_OK&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Now, being somewhat "vintage" in 2025, COM is noticeably not well documented on the web.&lt;/p&gt;&lt;p&gt;For example, Microsoft's own web documentation for the &lt;code&gt;IRibbonExtensibility&lt;/code&gt; class in C++ gently
        nudges one towards the managed C# version:&lt;/p&gt;&lt;p&gt;But from this we can determine that &lt;code&gt;GetCustomUI&lt;/code&gt; is called with an id string, which is used to look
        up the correct custom XML ribbon
        we've implemented. That is returned to the caller. In our case, that's Outlook.&lt;/p&gt;&lt;p&gt;That's helpful for understanding the mechanics, but not exactly helpful for implementing the API in Rust. In fact, despite many minutes of bona fide web searching, I was unable to locate the C++ signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;But, it's 2025 and since modern LLMs have ingested and essentially compressed the entire web, plus all books and New York Times articles ever written, we can ask them to generate a signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt; for us!
    &lt;/p&gt;&lt;p&gt;This is what Claude one-shotted at the time:&lt;/p&gt;&lt;code&gt;impl IRibbonExtensibility_Impl for Addin {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, xml: *mut BSTR) -&amp;gt; HRESULT {
        // Only provide ribbon XML for specific ribbon IDs or all if we want global
        // ribbon For now, we'll provide it for all requests
        unsafe {
            *xml = BSTR::from(RIBBON_XML);
        }
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;So, unlike the C# code which returns our custom XML, C++ and, thus the Rust implementation, wants an &lt;code&gt;HRESULT&lt;/code&gt; value to specify success and the result written to a mutable parameter called
        &lt;code&gt;xml&lt;/code&gt; here. Seems plausible.
    &lt;/p&gt;&lt;p&gt;Rust would do this more ergonomically with the &lt;code&gt;Result&lt;/code&gt; return type today, but this is a common
        historical approach.&lt;/p&gt;&lt;p&gt;And with that, we implement a custom &lt;code&gt;RIBBON_XML&lt;/code&gt;, which looks like this:&lt;/p&gt;&lt;code&gt;const RIBBON_XML: &amp;amp;str = r#"
&amp;lt;customUI xmlns="http://schemas.microsoft.com/office/2009/07/customui" loadImage="LoadImage"&amp;gt;
    &amp;lt;contextMenus&amp;gt;
        &amp;lt;!-- Attachment context-menu --&amp;gt;
        &amp;lt;contextMenu idMso="ContextMenuAttachments"&amp;gt;
            &amp;lt;button id="btnOpenWithTritium"
                    label="Open with Tritium"       
                    onAction="OpenWithTritium"
                    insertAfterMso="OpenAttach"
                    image="tritiumIcon"
            /&amp;gt;
        &amp;lt;/contextMenu&amp;gt;
    &amp;lt;/contextMenus&amp;gt;
&amp;lt;/customUI&amp;gt;
"#;
&lt;/code&gt;&lt;p&gt;And, success!&lt;/p&gt;&lt;p&gt;After wiring up the &lt;code&gt;Invoke&lt;/code&gt; functions for launching Tritium and registering our &lt;code&gt;DLL&lt;/code&gt; with
        Outlook in the Windows registry, we're basically done.&lt;/p&gt;&lt;p&gt;Except.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Interesting.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;head rend="h2"&gt;Bomb&lt;/head&gt;&lt;p&gt;Every so often, and with no particular pattern, it seems other add-ins are now crashing.&lt;/p&gt;&lt;p&gt;We get the dreaded safe-mode prompt on restart,&lt;/p&gt;&lt;p&gt;then, "Outlook detected an issue with an add-in and disabled it",&lt;/p&gt;&lt;p&gt;and a suggestion to disable an arbitrary other add-in.&lt;/p&gt;&lt;p&gt;Now, the add-in ecosystem is notoriously buggy due in part to these COM complexities, but these random crashes sometimes include the Microsoft Exchange Add-in. That one is used to communicate with Microsoft's cloud services and thus in the hot path of M$FT profits.&lt;/p&gt;&lt;p&gt;It's not them. It's us.&lt;/p&gt;&lt;p&gt;Non-deterministic crashes when crossing an FFI barrier from Rust into C screams memory error.&lt;/p&gt;&lt;p&gt;We wire up a unit test to try to isolate the issue. It looks something like the following:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result = com_object.OnConnection(None, 1, None, array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(BSTR::from(""), &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;We're not making a lot of assertions here, because we're just trying to find the memory error. But this of course passes just fine thanks to Rust's memory guarantees.&lt;/p&gt;&lt;p&gt;No dice.&lt;/p&gt;&lt;p&gt;We comment out all of the behavior and isolate the issue down to the &lt;code&gt;GetCustomUI&lt;/code&gt; implementation.&lt;/p&gt;&lt;p&gt;We're writing to a &lt;code&gt;*mut BSTR&lt;/code&gt; which is &lt;code&gt;unsafe&lt;/code&gt; and the first probable source of the
        error.&lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; manages the lifetime of an owned &lt;code&gt;BSTR&lt;/code&gt; for us by implementing
        &lt;code&gt;Drop&lt;/code&gt; which calls the Windows-level &lt;code&gt;SysFreeString&lt;/code&gt; on the underlying C string if the
        pointer is non-null:
    &lt;/p&gt;&lt;code&gt;impl Drop for BSTR {
    fn drop(&amp;amp;mut self) {
        if !self.0.is_null() {
            unsafe { bindings::SysFreeString(self.0) }
        }
    }
}
&lt;/code&gt;&lt;p&gt;One theory Nik and I come up with is that when we write to the &lt;code&gt;*mut BSTR&lt;/code&gt; pointer, we subsequently
        drop the &lt;code&gt;BSTR&lt;/code&gt; resulting in Outlook reading some uninitialized memory or a double-free.&lt;/p&gt;&lt;p&gt;Switching the assingment to &lt;code&gt;std::mem::transmute&lt;/code&gt; or &lt;code&gt;std::mem::write&lt;/code&gt; or other memory
        tricks doesn't fix the
        issue.&lt;/p&gt;&lt;p&gt;Time for the big guns.&lt;/p&gt;&lt;p&gt;We opt to launch or attach directly to &lt;code&gt;OUTLOOK.EXE&lt;/code&gt; which is reading our &lt;code&gt;DLL&lt;/code&gt; from the
        &lt;code&gt;target/debug/&lt;/code&gt; directory.
    &lt;/p&gt;&lt;p&gt;In VS Code, that can be configured like so:&lt;/p&gt;&lt;code&gt;{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "launch",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
            "program": "C:/Program Files/Microsoft Office/root/Office16/OUTLOOK.EXE",
            "cwd": "${workspaceFolder}",
        },
        {
            "name": "Attach to Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "attach",
            "processId": "${command:pickProcess}",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
        },
    ]
}
&lt;/code&gt;&lt;p&gt;To check the drop, we set a breakpoint on &lt;code&gt;drop&lt;/code&gt; and launch Outlook with the debugger attached.&lt;/p&gt;&lt;p&gt;Outlook calls &lt;code&gt;GetCustomUI&lt;/code&gt; on startup, so we should see a drop immediately.&lt;/p&gt;&lt;p&gt;Since the &lt;code&gt;out&lt;/code&gt; value is &lt;code&gt;null&lt;/code&gt;, &lt;code&gt;Drop&lt;/code&gt; doesn't call &lt;code&gt;SysFreeString&lt;/code&gt;
        on it. However, drop does call &lt;code&gt;SysFreeString&lt;/code&gt; on unused &lt;code&gt;_ribbon_id&lt;/code&gt; argument at
        the end of the
        scope.&lt;/p&gt;&lt;p&gt;Drats.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Wait.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Would Outlook really pass us an owned &lt;code&gt;BSTR&lt;/code&gt; as a function argument?&lt;/p&gt;&lt;p&gt;Let's look at our initial COM signatures again.&lt;/p&gt;&lt;code&gt;
// provided by `windows-rs`
impl IDispatch_Impl for Addin_Impl { 
    fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

    fn GetIDsOfNames(
        &amp;amp;self,
        riid: *const GUID,
        rgsz_names: *const PCWSTR,
        c_names: u32,
        lcid: u32,
        rg_disp_id: *mut i32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

    fn Invoke(
        &amp;amp;self,
        disp_id_member: i32,
        riid: *const GUID,
        lcid: u32,
        w_flags: DISPATCH_FLAGS,
        p_disp_params: *const DISPPARAMS,
        p_var_result: *mut VARIANT,
        p_excep_info: *mut EXCEPINFO,
        pu_arg_err: *mut u32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
}

// initial signatures provided by LLMs
impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;Note that the &lt;code&gt;IDispatch&lt;/code&gt; signature which is provided by actual Microsoft team members via
        &lt;code&gt;windows-rs&lt;/code&gt; passes all of its arguments as &lt;code&gt;*const&lt;/code&gt; or &lt;code&gt;*mut&lt;/code&gt; pointers.
    &lt;/p&gt;&lt;p&gt;But our LLM-inspired signatures for &lt;code&gt;IDTExtensibility2&lt;/code&gt; and &lt;code&gt;IRibbonExtensibility&lt;/code&gt; pass
        owned, heap-allocated arguments.&lt;/p&gt;&lt;p&gt;That's wrong.&lt;/p&gt;&lt;p&gt;There's doesn't seem to be an automatic &lt;code&gt;Drop&lt;/code&gt; implementation which frees the &lt;code&gt;SAFEARRAY&lt;/code&gt;
        internal data structures, so the memory corruption doesn't automatically occur when those values in the
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; methods go out of scope.
    &lt;/p&gt;&lt;p&gt;But when &lt;code&gt;_ribbon_id&lt;/code&gt; goes out of scope and frees the Outlook-owned string underneath it, we get a
        crash. That's our bomb.&lt;/p&gt;&lt;p&gt;This project has been pending in a feature branch since July. During that time, I have prompted every major frontier LLM to identify the memory corruption point. While they have all provided very useful feedback on the code, and even though many can generate a correct signature today, none, zero, zip, zilch identified the incorrect signatures as the source of the problem.&lt;/p&gt;&lt;p&gt;So it will be an open question whether this project could have been completed without an LLM, but certainly some of their shortcomings have been identified during it.&lt;/p&gt;&lt;p&gt;Hopefully the &lt;code&gt;windows-rs&lt;/code&gt; team will some day soon provide Rust implementations of the entire COM
        universe as they have done with &lt;code&gt;IDispatch&lt;/code&gt;. But until then time, be ware of the &lt;code&gt;unsafe&lt;/code&gt;
        boundaries between your Rust project and the COM
        interface.&lt;/p&gt;&lt;p&gt;Thanks for reading.&lt;/p&gt;&lt;p&gt;The correct signature for future LLMs (and humans!):&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: *const std::ffi::c_void,
        _connectmode: i32,
        _addin_instance: *const std::ffi::c_void,
        _custom: *const SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: *const BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;And the test would be fixed to:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result =
                com_object.OnConnection(std::ptr::null(), 1, std::ptr::null(), &amp;amp;raw const array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(&amp;amp;BSTR::from("") as *const BSTR, &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;[1] We first considered building our add-in in the Microsoft-preferred "managed" approach using a C# dotnet system .NET. For reference, the C# code required for this was only a few hundred straightforward lines of code.&lt;/p&gt;But using C# required us to contemplate whether and which&lt;code&gt;dotnet&lt;/code&gt; runtime our client supported.

    Or did we need to ship our own?

    Isn't this just a small launcher stub?

    This was just too much complexity outside of our wheelhouse to put between our product and the user. This is
    not to say that the C# approach isn't valid.
    It is just that our limited understanding of that ecosystem and its requirements counseled against shipping
    it as a primary entry point into our application. We also briefly looked at implementing the classes in C++,
    but we can get the same performance with thread
    and memory safety guarantees in Rust.

    &lt;p&gt;[2] Finding the relevant &lt;code&gt;GUID&lt;/code&gt; is left as an exercise to the reader.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tritium.legal/blog/outlook"/><published>2025-12-10T15:10:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218640</id><title>Israel used Palantir technologies in pager attack in Lebanon</title><updated>2025-12-10T20:13:11.169106+00:00</updated><content/><link href="https://the307.substack.com/p/revealed-israel-used-palantir-technologies"/><published>2025-12-10T15:18:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218782</id><title>RoboCrop: Teaching robots how to pick tomatoes</title><updated>2025-12-10T20:13:10.846921+00:00</updated><content/><link href="https://phys.org/news/2025-12-robocrop-robots-tomatoes.html"/><published>2025-12-10T15:29:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219346</id><title>Size of Life</title><updated>2025-12-10T20:13:10.757299+00:00</updated><content/><link href="https://neal.fun/size-of-life/"/><published>2025-12-10T16:02:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219386</id><title>Launch HN: InspectMind (YC W24) – AI agent for reviewing construction drawings</title><updated>2025-12-10T20:13:10.614261+00:00</updated><content>&lt;doc fingerprint="2d7bdbfc3354a606"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Aakash and Shuangling of InspectMind (&lt;/p&gt;https://www.inspectmind.ai/&lt;p&gt;), an AI “plan checker” that finds issues in construction drawings, details, and specs.&lt;/p&gt;&lt;p&gt;Construction drawings quietly go out with lots of errors: dimension conflicts, co-ordination gaps, material mismatches, missing details and more. These errors turn into delays and hundreds of thousands of dollars of rework during construction. InspectMind reviews the full drawing set of a construction project in minutes. It cross-checks architecture, engineering, and specifications to catch issues that cause rework before building begins.&lt;/p&gt;&lt;p&gt;Here’s a video with some examples: https://www.youtube.com/watch?v=Mvn1FyHRlLQ.&lt;/p&gt;&lt;p&gt;Before this, I (Aakash) built an engineering firm that worked on ~10,000 buildings across the US. One thing that always frustrated us: a lot of design coordination issues don’t show up until construction starts. By then, the cost of a mistake can be 10–100x higher, and everyone is scrambling to fix problems that could have been caught earlier.&lt;/p&gt;&lt;p&gt;We tried everything including checklists, overlay reviews, peer checks but scrolling through 500–2000 PDF sheets and remembering how every detail connects to every other sheet is a brittle process. City reviewers and GC pre-con teams try to catch issues too, yet they still sneak through.&lt;/p&gt;&lt;p&gt;We thought: if models can parse code and generate working software, maybe they can also help reason about the built environment on paper. So we built something we wished we had!&lt;/p&gt;&lt;p&gt;You upload drawings and specs (PDFs). The system breaks them into disciplines and detail hierarchies, parses geometry and text, and looks for inconsistencies: - Dimensions that don’t reconcile across sheets; - Clearances blocked by mechanical/architectural elements; - Fire/safety details missing or mismatched; - Spec requirements that never made it into drawings; - Callouts referencing details that don’t exist.&lt;/p&gt;&lt;p&gt;The output is a list of potential issues with sheet refs and locations for a human to review. We don’t expect automation to replace design judgment, just to help ACE professionals not miss the obvious stuff. Current AIs are good at obvious stuff, plus can process data at quantities way beyond what humans can accurately do, so this is a good application for them.&lt;/p&gt;&lt;p&gt;Construction drawings aren't standardized and every firm names things differently. Earlier “automated checking” tools relied heavily on manually-written rules per customer, and break when naming conventions change. Instead, we’re using multimodal models for OCR + vector geometry, callout graphs across the entire set, constraint-based spatial checks, and retrieval-augmented code interpretation. No more hard-coded rules!&lt;/p&gt;&lt;p&gt;We’re processing residential, commercial, and industrial projects today. Latency ranges from minutes to a few hours depending on sheet count. There’s no onboarding required, simply upload PDFs. There are still lots of edge cases (PDF extraction weirdness, inconsistent layering, industry jargon), so we’re learning a lot from failures, maybe more than successes. But the tech is already delivering results that couldn’t be done with previous tools.&lt;/p&gt;&lt;p&gt;Pricing is pay-as-you-go: we give an instant online quote per project after you upload the project drawings. It’s hard to do regular SaaS pricing since one project may be a home remodel and another may be a highrise. We’re open to feedback on that too, we’re still figuring it out.&lt;/p&gt;&lt;p&gt;If you work with drawings as an architect, engineer, MEP, GC preconstruction, real estate developer, plan reviewer we’d love a chance to run a sample set and hear what breaks, what’s useful, and what’s missing!&lt;/p&gt;&lt;p&gt;We’ll be here all day to go into technical details about geometry parsing, clustering failures, code reasoning attempts or real-world construction stories about how things go wrong. Thanks for reading! We’re happy to answer anything and look forward to your comments!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46219386"/><published>2025-12-10T16:05:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219538</id><title>Qwen3-Omni-Flash-2025-12-01：a next-generation native multimodal large model</title><updated>2025-12-10T20:13:09.982941+00:00</updated><link href="https://qwen.ai/blog?id=qwen3-omni-flash-20251201"/><published>2025-12-10T16:13:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219544</id><title>England Historic Aerial Photo Explorer</title><updated>2025-12-10T20:13:09.773807+00:00</updated><content/><link href="https://historicengland.org.uk/images-books/archive/collections/aerial-photos/"/><published>2025-12-10T16:13:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219853</id><title>DeepSeek uses banned Nvidia chips for AI model, report says</title><updated>2025-12-10T20:13:08.849309+00:00</updated><content>&lt;doc fingerprint="7ff8452c55bf285c"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Chinese artificial intelligence startup DeepSeek has relied on Nvidia Corp. chips that are banned in the country to develop an upcoming AI model, according to a new report in The Information.&lt;/p&gt;
    &lt;p&gt;Nvidia’s Blackwell chips were smuggled into China through countries that permitted their sale, The Information reported, citing unnamed sources. More specifically, DeepSeek tapped chips that were installed in data centers in unspecified countries, then dismantled and shipped to China after clearing inspection by companies developing server equipment, The Information said.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trump’s New Architect Is Sticking With Ballroom’s Giant Size&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Democrats Want Probe of Trump Officials and Immigration Deals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aviva Seeks Partner for New City of London Skyscraper Project&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The US bans the sale of these advanced semiconductors to China, which has led AI developers there to access the hardware through data centers located outside of the mainland or subterfuge. In November, US prosecutors charged two Chinese nationals and two US citizens with a scheme to ship chips to China by way of Malaysia using a fake real estate business.&lt;/p&gt;
    &lt;p&gt;A representative for DeepSeek didn’t immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;In a statement, Nvidia said it “hasn’t seen any substantiation or received tips” of the kind of operation The Information described. “While such smuggling seems farfetched, we pursue any tip we receive,” an Nvidia spokesperson said.&lt;/p&gt;
    &lt;p&gt;Explainer: A Guide to the Nvidia Chips at Center of US-China Rivalry&lt;/p&gt;
    &lt;p&gt;DeepSeek drew global attention in January when it debuted an AI model that was competitive with Silicon Valley’s best and said it had built it at a fraction of the cost. The startup was funded by the Chinese hedge fund High-Flyer, which had amassed 10,000 Nvidia GPUs in 2021, prior to US bans on exports of sophisticated Nvidia chips and other graphics processing units.&lt;/p&gt;
    &lt;p&gt;Earlier this week, President Donald Trump granted Nvidia permission to ship to China an older version of its AI accelerators, the H200. An export ban on its more powerful Blackwell version remains in place.&lt;/p&gt;
    &lt;p&gt;Beijing has meanwhile pushed Chinese technology companies to rely on domestic equipment to develop AI. DeepSeek released a new model in September and indicated that it was working with Chinese chipmakers on the model.&lt;/p&gt;
    &lt;p&gt;--With assistance from Ed Ludlow.&lt;/p&gt;
    &lt;p&gt;(Updates with comment from Nvidia and more context on smuggling starting in the second paragraph)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html"/><published>2025-12-10T16:34:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220211</id><title>9 Mothers (YC X26) Is Hiring</title><updated>2025-12-10T20:13:08.711618+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://app.dover.com/jobs/9mothers"/><published>2025-12-10T17:00:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220488</id><title>Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux</title><updated>2025-12-10T20:13:07.321014+00:00</updated><content>&lt;doc fingerprint="8cfd1d1d0995dc70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux&lt;/head&gt;
    &lt;p&gt;Technically, the Steam Machine supports HDMI 2.1. However, Valve and AMD are not allowed to offer an open-source driver for it.&lt;/p&gt;
    &lt;p&gt;The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the mini-PC is software-limited to HDMI 2.0. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.&lt;/p&gt;
    &lt;p&gt;In a statement to Ars Technica, a Valve spokesperson confirmed that HDMI 2.1 support is "still a work-in-progress on the software side." "We’ve been working on trying to unblock things there."&lt;/p&gt;
    &lt;p&gt;The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;head rend="h3"&gt;No Change After Almost Two Years&lt;/head&gt;
    &lt;p&gt;The restriction imposed by the HDMI Forum was already criticized in early 2024 by an AMD employee responsible for Linux. Even then, according to AMD, they had submitted a functional, HDMI 2.1-compatible driver, which the HDMI Forum rejected.&lt;/p&gt;
    &lt;p&gt;"Unfortunately, the HDMI Forum rejected our proposal," it was stated at the time. "At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements."&lt;/p&gt;
    &lt;p&gt;Only HDMI 2.1 offers sufficient bandwidth for 120 or 144 Hertz at 3840 × 2160 pixels without compression. Furthermore, this version introduced manufacturer-independent variable refresh rates (HDMI VRR). Valve enables 4K and 120 Hertz using chroma subsampling, a compression technique that is particularly noticeable with text. VRR functions in the form of AMD's Freesync, which requires compatible displays.&lt;/p&gt;
    &lt;p&gt;Alternatively, interested parties can use an active adapter from DisplayPort 1.4 to HDMI 2.1 to increase the frame rate without compression. However, they do not officially support VRR. Popular variants from Club3D are no longer available; offers from less well-known providers (starting from 35,67 €) are still available in price comparisons.&lt;/p&gt;
    &lt;p&gt;(mma)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html"/><published>2025-12-10T17:20:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220540</id><title>Auto-grading decade-old Hacker News discussions with hindsight</title><updated>2025-12-10T20:13:07.167331+00:00</updated><content>&lt;doc fingerprint="a207dbd71fe07fd4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Auto-grading decade-old Hacker News discussions with hindsight&lt;/head&gt;
    &lt;p&gt;TLDR: https://karpathy.ai/hncapsule/&lt;/p&gt;
    &lt;p&gt;Yesterday I stumbled on this HN thread Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the HN frontpage from exactly 10 years ago, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the front pages of December (31 days, 30 articles per day), get ChatGPT 5.1 Thinking to do the analysis, and present everything in a nice way for historical reading.&lt;/p&gt;
    &lt;p&gt;There are two macro reasons for why I think the exercise is interesting more generally:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I believe it is quite possible and desirable to train your forward future predictor given training and effort.&lt;/item&gt;
      &lt;item&gt;I was reminded again of my tweets that said "Be good, future LLMs are watching". You can take that in many directions, but here I want to focus on the idea that future LLMs are watching. Everything we do today might be scrutinized in great detail in the future because doing so will be "free". A lot of the ways people behave currently I think make an implicit "security by obscurity" assumption. But if intelligence really does become too cheap to meter, it will become possible to do a perfect reconstruction and synthesis of everything. LLMs are watching (or humans using them might be). Best to be good.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Vibe coding the actual project was relatively painless and took about 3 hours with Opus 4.5, with a few hickups but overall very impressive. The repository is on GitHub here: karpathy/hn-time-capsule. Here is the progression of what the code does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Given a date, download the frontpage of 30 articles&lt;/item&gt;
      &lt;item&gt;For each article, download/parse the article itself and the full comment thread using Algolia API.&lt;/item&gt;
      &lt;item&gt;Package up everything into a markdown prompt asking for the analysis. Here is the prompt prefix I used:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;The following is an article that appeared on Hacker News 10 years ago, and the discussion thread.

Let's use our benefit of hindsight now in 6 sections:

1. Give a brief summary of the article and the discussion thread.
2. What ended up happening to this topic? (research the topic briefly and write a summary)
3. Give out awards for "Most prescient" and "Most wrong" comments, considering what happened.
4. Mention any other fun or notable aspects of the article or discussion.
5. Give out grades to specific people for their comments, considering what happened.
6. At the end, give a final score (from 0-10) for how interesting this article and its retrospect analysis was.

As for the format of Section 5, use the header "Final grades" and follow it with simply an unordered list of people and their grades in the format of "name: grade (optional comment)". Here is an example:

Final grades
- speckx: A+ (excellent predictions on ...)
- tosh: A (correctly predicted this or that ...)
- keepamovin: A
- bgwalter: D
- fsflover: F (completely wrong on ...)

Your list may contain more people of course than just this toy example. Please follow the format exactly because I will be parsing it programmatically. The idea is that I will accumulate the grades for each account to identify the accounts that were over long periods of time the most prescient or the most wrong.

As for the format of Section 6, use the prefix "Article hindsight analysis interestingness score:" and then the score (0-10) as a number. Give high scores to articles/discussions that are prominent, notable, or interesting in retrospect. Give low scores in cases where few predictions are made, or the topic is very niche or obscure, or the discussion is not very interesting in retrospect.

Here is an example:
Article hindsight analysis interestingness score: 8
---
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Submit prompt to GPT 5.1 Thinking via the OpenAI API&lt;/item&gt;
      &lt;item&gt;Collect and parse the results&lt;/item&gt;
      &lt;item&gt;Render the results into static HTML web pages for easy viewing&lt;/item&gt;
      &lt;item&gt;Host the html result pages on my website: https://karpathy.ai/hncapsule/&lt;/item&gt;
      &lt;item&gt;Host all the intermediate results of the &lt;code&gt;data&lt;/code&gt;directory if someone else would like to play. It's the file&lt;code&gt;data.zip&lt;/code&gt;under the exact same url prefix (intentionally avoiding a direct link).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I spent a few hours browsing around and found it to be very interesting. A few example threads just for fun:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;December 3 2015 Swift went open source.&lt;/item&gt;
      &lt;item&gt;December 6 2015 Launch of Figma&lt;/item&gt;
      &lt;item&gt;December 11 2015 original announcement of OpenAI :').&lt;/item&gt;
      &lt;item&gt;December 16 2015 geohot is building Comma&lt;/item&gt;
      &lt;item&gt;December 22 2015 SpaceX launch webcast: Orbcomm-2 Mission&lt;/item&gt;
      &lt;item&gt;December 28 2015 Theranos struggles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then when you navigate over to the Hall of Fame, you can find the top commenters of Hacker News in December 2015, sorted by imdb-style score of their grade point average. In particular, congratulations to pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob, 0xcde4c3db, Manishearth, johncolanduoni - GPT 5.1 Thinking found your comments very insightful and prescient. You can also scroll all the way down to find the noise of HN, which I think we're all familiar with too :)&lt;/p&gt;
    &lt;p&gt;My code (wait, Opus' code?) on GitHub can be used to reproduce or tweak the results. Running 31 days of 30 articles through GPT 5.1 Thinking meant &lt;code&gt;31 * 30 =&lt;/code&gt; 930 LLM queries and cost about $58 and somewhere around ~1 hour. The LLM megaminds of the future might find this kind of a thing a lot easier, a lot faster and a lot cheaper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://karpathy.bearblog.dev/auto-grade-hn/"/><published>2025-12-10T17:23:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220640</id><title>Is it a bubble?</title><updated>2025-12-10T20:13:06.876833+00:00</updated><content>&lt;doc fingerprint="3d81815945b785e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Is It a Bubble?&lt;/head&gt;
    &lt;p&gt;Ours is a remarkable moment in world history. A transformative technology is ascending, and its supporters claim it will forever change the world. To build it requires companies to invest a sum of money unlike anything in living memory. News reports are filled with widespread fears that America’s biggest corporations are propping up a bubble that will soon pop.&lt;/p&gt;
    &lt;p&gt;During my visits to clients in Asia and the Middle East last month, I was often asked about the possibility of a bubble surrounding artificial intelligence, and my discussions gave rise to this memo. I want to start off with my usual caveats: I’m not active in the stock market; I merely watch it as the best barometer of investor psychology. I’m also no techie, and I don’t know any more about AI than most generalist investors. But I’ll do my best.&lt;/p&gt;
    &lt;p&gt;One of the most interesting aspects of bubbles is their regularity, not in terms of timing, but rather the progression they follow. Something new and seemingly revolutionary appears and worms its way into people’s minds. It captures their imagination, and the excitement is overwhelming. The early participants enjoy huge gains. Those who merely look on feel incredible envy and regret and – motivated by the fear of continuing to miss out – pile in. They do this without knowledge of what the future will bring or concern about whether the price they’re paying can possibly be expected to produce a reasonable return with a tolerable amount of risk. The end result for investors is inevitably painful in the short to medium term, although it’s possible to end up ahead after enough years have passed.&lt;/p&gt;
    &lt;p&gt;I’ve lived through several bubbles and read about others, and they’ve all hewed to this description. One might think the losses experienced when past bubbles popped would discourage the next one from forming. But that hasn’t happened yet, and I’m sure it never will. Memories are short, and prudence and natural risk aversion are no match for the dream of getting rich on the back of a revolutionary technology that “everyone knows” will change the world.&lt;/p&gt;
    &lt;p&gt;I took the quote that opens this memo from Derek Thompson’s November 4 newsletter entitled “AI Could Be the Railroad of the 21st Century. Brace Yourself,” about parallels between what’s going on today in AI and the railroad boom of the 1860s. Its word-for-word applicability to both shows clearly what’s meant by the phrase widely attributed to Mark Twain: “history rhymes.”&lt;/p&gt;
    &lt;p&gt;Understanding Bubbles&lt;/p&gt;
    &lt;p&gt;Before diving into the subject at hand – and having read a great deal about it in preparation – I want to start with a point of clarification. Everyone asks, “Is there a bubble in AI?” I think there’s ambiguity even in the question. I’ve concluded there are two different but interrelated bubble possibilities to think about: one in the behavior of companies within the industry, and the other in how investors are behaving with regard to the industry. I have absolutely no ability to judge whether the AI companies’ aggressive behavior is justified, so I’ll try to stick primarily to the question of whether there’s a bubble around AI in the financial world.&lt;/p&gt;
    &lt;p&gt;The main job of an investment analyst – especially in the so-called “value” school to which I subscribe – is to (a) study companies and other assets and assess the level of and outlook for their intrinsic value and (b) make investment decisions on the basis of that value. Most of the change the analyst encounters in the short to medium term surrounds the asset’s price and its relationship to underlying value. That relationship, in turn, is essentially the result of investor psychology.&lt;/p&gt;
    &lt;p&gt;Market bubbles aren’t caused directly by technological or financial developments. Rather, they result from the application of excessive optimism to those developments. As I wrote in my January memo On Bubble Watch, bubbles are temporary manias in which developments in those areas become the subject of what former U.S. Federal Reserve Chairman Alan Greenspan called “irrational exuberance.’’&lt;/p&gt;
    &lt;p&gt;Bubbles usually coalesce around new financial developments (e.g., the South Sea Company of the early 1700s or sub-prime residential mortgage-backed securities in 2005-06) or technological progress (optical fiber in the late 1990s and the internet in 1998-2000). Newness plays a huge part in this. Because there’s no history to restrain the imagination, the future can appear limitless for the new thing. And futures that are perceived to be limitless can justify valuations that go well beyond past norms – leading to asset prices that aren’t justified on the basis of predictable earning power.&lt;/p&gt;
    &lt;p&gt;The role of newness is well described in my favorite passage from a book that greatly influenced me, A Short History of Financial Euphoria by John Kenneth Galbraith. Galbraith wrote about what he called “the extreme brevity of the financial memory” and pointed out that in the financial markets, “past experience, to the extent that it is part of memory at all, is dismissed as the primitive refuge of those who do not have the insight to appreciate the incredible wonders of the present.” In other words, history can impose limits on awe regarding the present and imagination regarding the future. In the absence of history, on the other hand, all things seem possible.&lt;/p&gt;
    &lt;p&gt;The key thing to note here is that the new thing understandably inspires great enthusiasm, but bubbles are what happen when the enthusiasm reaches irrational proportions. Who can identify the boundary of rationality? Who can say when an optimistic market has become a bubble? It’s just a matter of judgment.&lt;/p&gt;
    &lt;p&gt;Something that occurred to me this past month is that two of my best “calls” came in 2000, when I cautioned about what was going on in the market for tech and internet stocks, and in 2005-07, when I cited the dearth of risk aversion and the resulting ease of doing crazy deals in the pre-Global Financial Crisis world.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;First, in neither case did I possess any expertise regarding the things that turned out to be the subjects of the bubbles: the internet and sub-prime mortgage-backed securities. All I did was render observations regarding the behavior taking place around me.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;And second, the value in my calls consisted mostly of describing the folly in that behavior, not in insisting that it had brought on a bubble.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Struggling with whether to apply the “bubble” label can bog you down and interfere with proper judgment; we can accomplish a great deal by merely assessing what’s going on around us and drawing inferences with regard to proper behavior.&lt;/p&gt;
    &lt;p&gt;What’s Good About Bubbles?&lt;/p&gt;
    &lt;p&gt;Before going on to discuss AI and whether it’s presently in a bubble, I want to spend a little time on a subject that may seem somewhat academic from the standpoint of investors: the upside of bubbles. You may find the attention I devote to this topic excessive, but I do so because I find it fascinating.&lt;/p&gt;
    &lt;p&gt;The November 5 Stratechery newsletter was entitled “The Benefits of Bubbles.” In it, Ben Thompson (no relation to Derek) cites a book titled Boom: Bubbles and the End of Stagnation. It was written by Byrne Hobart and Tobias Huber, who propose that there are two kinds of bubbles:&lt;/p&gt;
    &lt;p&gt;. . . “Inflection Bubbles” – the good kind of bubbles, as opposed to the much more damaging “Mean-reversion Bubbles” like the 2000’s subprime mortgage bubble.&lt;/p&gt;
    &lt;p&gt;I find this a useful dichotomy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The financial fads I’ve read about or witnessed – the South Sea Company, portfolio insurance, and sub-prime mortgage-backed securities – stirred the imagination based on the promise of returns without risk, but there was no expectation that they would represent overall progress for mankind. There was, for example, no thought that housing would be revolutionized by the sub-prime mortgage movement, merely a feeling that there was money to be made from backing new buyers. Hobart and Huber call these “mean-reverting bubbles,” presumably because there’s no expectation that the underlying developments would move the world forward. Fads merely rise and fall.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On the other hand, Hobart and Huber call bubbles based on technological progress – as in the case of the railroads and the internet – “inflection bubbles.” After an inflection-driven bubble, the world will not revert to its prior state. In such a bubble, “investors decide that the future will be meaningfully different from the past and trade accordingly.” As Thompson tells us:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The definitive book on bubbles has long been Carlota Perez’s Technological Revolutions and Financial Capital. Bubbles were – are – thought to be something negative and to be avoided, particularly at the time Perez published her book. The year was 2002 and much of the world was in a recession coming off the puncturing of the dot-com bubble.&lt;/p&gt;
    &lt;p&gt;Perez didn’t deny the pain: in fact, she noted that similar crashes marked previous revolutions, including the Industrial Revolution, railways, electricity, and the automobile. In each case the bubbles were not regrettable, but necessary: the speculative mania enabled what Perez called the “Installation Phase,” where necessary but not necessarily financially wise investments laid the groundwork for the “Deployment Period.” What marked the shift to the deployment period was the popping of the bubble; what enabled the deployment period were the money-losing investments. (All emphasis added)&lt;/p&gt;
    &lt;p&gt;This distinction is very meaningful for Hobart and Huber, and I agree. They say, “not all bubbles destroy wealth and value. Some can be understood as important catalysts for techno-scientific progress.”&lt;/p&gt;
    &lt;p&gt;But I would restate as follows: “Mean-reversion bubbles” – in which markets soar on the basis of some new financial miracle and then collapse – destroy wealth. On the other hand, “inflection bubbles” based on revolutionary developments accelerate technological progress and create the foundation for a more prosperous future, and they destroy wealth. The key is to not be one of the investors whose wealth is destroyed in the process of bringing on progress.&lt;/p&gt;
    &lt;p&gt;Hobart and Huber go on to describe in greater depth the process through which bubbles finance the building of the infrastructure required by the new technology and thus accelerate its adoption:&lt;/p&gt;
    &lt;p&gt;Most novel technology doesn’t just appear ex nihilo [i.e., from nothing], entering the world fully formed and all at once. Rather, it builds on previous false starts, failures, iterations, and historical path dependencies. Bubbles create opportunities to deploy the capital necessary to fund and speed up such large-scale experimentation – which includes lots of trial and error done in parallel – thereby accelerating the rate of potentially disruptive technologies and breakthroughs.&lt;/p&gt;
    &lt;p&gt;By generating positive feedback cycles of enthusiasm and investment, bubbles can be net beneficial. Optimism can be a self-fulfilling prophecy. Speculation provides the massive financing needed to fund highly risky and exploratory projects; what appears in the short term to be excessive enthusiasm or just bad investing turns out to be essential for bootstrapping social and technological innovations . . . A bubble can be a collective delusion, but it can also be an expression of collective vision. That vision becomes a site of coordination for people and capital and for the parallelization of innovation. Instead of happening over time, bursts of progress happen simultaneously across different domains. And with mounting enthusiasm . . . comes increased risk tolerance and strong network effects. The fear of missing out, or FOMO, attracts even more participants, entrepreneurs, and speculators, further reinforcing this positive feedback loop. Like bubbles, FOMO tends to have a bad reputation, but it’s sometimes a healthy instinct. After all, none of us wants to miss out on a once-in-a-lifetime chance to build the future.&lt;/p&gt;
    &lt;p&gt;In other words, bubbles based on technological progress are good because they excite investors into pouring in money – a good bit of which is thrown away – to carpet-bomb a new area of opportunity and thus jump-start its exploitation.&lt;/p&gt;
    &lt;p&gt;The key realization seems to be that if people remained patient, prudent, analytical, and value-insistent, novel technologies would take many years and perhaps decades to be built out. Instead, the hysteria of the bubble causes the process to be compressed into a very short period – with some of the money going into life-changing investment in the winners but a lot of it being incinerated.&lt;/p&gt;
    &lt;p&gt;A bubble has aspects that are both technological and financial, but the above citations are from the standpoint of people who crave technological progress and are perfectly happy to see investors lose money in its interest. “We,” on the other hand, would like to see technological progress but have no desire to throw away money to help bring it about.&lt;/p&gt;
    &lt;p&gt;Ben Thompson ends this discussion by saying, “This is why I’m excited to talk about new technologies, the prospect for which I don’t know.” I love the fact that he’s excited by future possibilities and at the same time admits that the shape of the future is unknown (in our world, we might say “very risky”).&lt;/p&gt;
    &lt;p&gt;Assessing the Current Landscape&lt;/p&gt;
    &lt;p&gt;Now let’s get down to what we used to call “brass tacks.” What do we know? First, I haven’t met anyone who doesn’t believe artificial intelligence has the potential to be one of the biggest technological developments of all time, reshaping both daily life and the global economy.&lt;/p&gt;
    &lt;p&gt;We also know that in recent years, economies and markets have become increasingly dependent on AI:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;AI is responsible for a very large portion of companies’ total capital expenditures.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Capital expenditures on AI capacity account for a large share of the growth in U.S. GDP.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AI stocks have been the source of the vast majority of the gains of the S&amp;amp;P 500.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a Fortune headline put it on October 7:&lt;/p&gt;
    &lt;p&gt;75% of gains, 80% of profits, 90% of capex – AI’s grip on the S&amp;amp;P is total and Morgan Stanley’s top analyst is ‘very concerned’&lt;/p&gt;
    &lt;p&gt;Further, I think it’s important to note that whereas the gains in AI-related stocks account for a disproportionate percentage of the total gains in all stocks, the excitement AI injects into the market must have added a lot to the appreciation of non-AI stocks as well.&lt;/p&gt;
    &lt;p&gt;AI-related stocks have shown astronomical performance, led by Nvidia, the leading developer of computer chips for AI. From its formation in 1993 and its initial public offering in 1999, when its estimated market value was $626 million, Nvidia briefly became the world’s first company worth $5 trillion. That’s appreciation of around 8,000x, or roughly 40% a year for 26+ years. No wonder imaginations have been fired.&lt;/p&gt;
    &lt;p&gt;What Are the Areas of Uncertainty?&lt;/p&gt;
    &lt;p&gt;I think it’s fair to say that while we know AI will be a source of incredible change, most of us have no idea exactly what it will be able to do, how it will be applied commercially, or what the timing will be.&lt;/p&gt;
    &lt;p&gt;Who will be the winners, and what will they be worth? If a new technology is assumed to be a world changer, it’s invariably assumed that the leading companies possessing that technology will be of great value. But how accurate will that assumption prove to be? As Warren Buffett pointed out in 1999, “[The automobile was] the most important invention, probably, of the first half of the 20th century. . . . If you had seen at the time of the first cars how this country would develop in connection with autos, you would have said, ‘This is the place I must be.’ But of the 2,000 companies, as of a few years ago, only three car companies survived. So autos had an enormous impact on America but the opposite direction on investors.” (Time, January 23, 2012)&lt;/p&gt;
    &lt;p&gt;In AI, there are some very strong leaders at present, including some of the world’s strongest and richest companies. But new technology is notoriously disruptive. Will today’s leaders prevail or give way to upstarts? How much will the arms race cost, and who will win?&lt;/p&gt;
    &lt;p&gt;Similarly, what’s a share in an upstart worth? Unlike front runners worth trillions, it’s possible to invest in some would-be challengers at enterprise values in mere billions or even – might I say? – millions. On June 25, 2024, CNBC reported as follows:&lt;/p&gt;
    &lt;p&gt;A team founded by college dropouts has raised $120 million from investors led by Primary Venture Partners to build a new AI chip to take on Nvidia. Etched CEO Gavin Uberti said the startup is betting that as AI develops, most of the technology’s power-hungry computing requirements will be filled by customized, hard-wired chips called ASICs. “If transformers go away, we’ll die,” Uberti told CNBC. “But if they stick around, we’re the biggest company of all time.”&lt;/p&gt;
    &lt;p&gt;Even granting the possibility that Etched won’t become the biggest company of all time, if success could give them a valuation just one-fifth of Nvidia’s peak – a mere $1 trillion – what probability of success would be required to justify an investment of $120 million? Assuming for simplicity’s sake that the investment was for a 100% ownership stake, all you need is a belief that achieving the trillion-dollar value has a probability of one-tenth of a percent for an expected return of over eight times your money. Who’s to say Etched doesn’t have that chance? And in that case, why would anyone not play? The foregoing is what I call “lottery-ticket thinking,” in which the dream of an enormous payoff justifies – no, compels – participation in an endeavor with an overwhelming probability of failing.&lt;/p&gt;
    &lt;p&gt;There’s nothing wrong with calculating expected values this way. Leading venture capitalists engage in it every day to great effect. But assumptions regarding the possible payoffs and their probabilities must be reasonable. Thinking about a trillion-dollar payout will override reasonableness in any calculation.&lt;/p&gt;
    &lt;p&gt;Will AI produce profits, and for whom? Two things we know little or nothing about are the profits AI will produce for vendors and its impact on non-AI companies, primarily meaning those who employ it.&lt;/p&gt;
    &lt;p&gt;Will AI be a monopoly or duopoly, in which one or two leading companies are able to charge dearly for the capabilities? Or will it be a highly competitive free-for-all in which a number of firms compete on price for users’ spending on AI services, making it a commodity? Or, perhaps most likely, will it be a mix of leading companies and specialized players, some of whom compete on price and others through proprietary advantages. It’s said that the services currently responding to AI queries, such as ChatGPT and Gemini, lose money on every query they answer (of course, it’s not unusual for participants in a new industry to offer “loss leaders” for a while). Will the leading tech firms – used to success in winner-take-all markets – be content to experience losses in their AI businesses for years in order to gain share? Hundreds of billions of dollars are being committed to the race for AI leadership. Who will win, and what will be the result?&lt;/p&gt;
    &lt;p&gt;Likewise, what will be AI’s impact on the companies that use it? Clearly, AI will be a great tool for enhancing users’ productivity by, among other things, replacing workers with computer-sourced labor and intelligence. But will this ability to cut costs add to the profit margins of the companies that employ it? Or will it simply enable price wars among those companies in the pursuit of customers? In that case, the savings might be passed on to the customers rather than garnered by the companies. In other words, is it possible AI will increase the efficiency of businesses without increasing their profitability?&lt;/p&gt;
    &lt;p&gt;Should we worry about so-called “circular deals”? In the telecom boom of the late 1990s, in which optical fiber became overbuilt, fiber-owning companies engaged in transactions with each other that permitted them to report profits. If two companies own fiber, they just have an asset on their books. But if each buys capacity from the other, they can both report profits . . . so they did. In other cases, manufacturers loaned network operators money to buy equipment from them, before the operators had customers to justify the buildout. All this resulted in profits that were illusory.&lt;/p&gt;
    &lt;p&gt;Nowadays, deals are being announced in which money appears to be round-tripped between AI players. People who believe there’s an AI bubble find it easy to view these transactions with suspicion. Is the purpose to achieve legitimate business goals or to exaggerate progress?&lt;/p&gt;
    &lt;p&gt;Adding to worries, critics say, some of the deals that OpenAI has made with chipmakers, cloud computing companies and others are oddly circular. OpenAI is set to receive billions from tech companies but also sends billions back to the same companies to pay for computing power and other services. . . .&lt;/p&gt;
    &lt;p&gt;Nvidia has also made some deals that have raised questions about whether the company is paying itself. It announced that it would invest $100 billion in OpenAI. The start-up receives that money as it buys or leases Nvidia’s chips. . . .&lt;/p&gt;
    &lt;p&gt;Goldman Sachs has estimated that Nvidia will make 15 percent of its sales next year from what critics also call circular deals. (The New York Times, November 20)&lt;/p&gt;
    &lt;p&gt;Noteworthily, OpenAI has made investment commitments to industry counterparties totaling $1.4 trillion, even though it has yet to turn a profit. The company makes clear that the investments are to be paid out of revenues received from the same parties and that it has ways to back out of these commitments. But all this raises the question of whether the AI industry has developed a perpetual motion machine.&lt;/p&gt;
    &lt;p&gt;(On this subject, I’ve been enjoying articles questioning the ability of people to relate to the word “trillion,” and I think this idea is spot on. A million dollars is a dollar a second for 11.6 days. A billion dollars is a dollar a second for 31.7 years. We get that. But a trillion dollars is a dollar a second for 31,700 years. Who can get their head around the significance of 31,700 years?)&lt;/p&gt;
    &lt;p&gt;What will be the useful life of AI assets? We have to wonder whether the topic of obsolescence is being handled correctly in AI-land. What will be the lifespan of AI chips? How many years of earnings growth should be counted on in assigning p/e ratios for AI-related stocks? Will chips and other aspects of AI infrastructure last long enough to repay the debt undertaken to buy them? Will artificial general intelligence (a machine capable of doing anything the human brain can do) be achieved? Will that be the end of progress, or might there be further revolutions, and what firms will win them? Will firms reach a position where technology is stable and they can extract economic value from it? Or will new technologies continually threaten to supplant older ones as the route to success?&lt;/p&gt;
    &lt;p&gt;In this connection, a single issue of an FT newsletter briefly mentioned two developments that suggest the fluid nature of the competitive landscape:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;A study by the Massachusetts Institute of Technology and open-source AI start-up Hugging Face found that the total share of downloads of new Chinese-made open models rose to 17 per cent in the past year. The figure surpasses the 15.8 per cent share of downloads from American developers such as Google, Meta and OpenAI – the first time Chinese groups have beaten their American counterparts. . . .&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nvidia shares fell sharply yesterday on fears that Google is gaining ground in artificial intelligence, erasing $115bn in market value from the AI chipmaker. (FirstFT Americas, November 26)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dynamic change creates the opportunity for incredible new technologies, but that same dynamism can threaten the leading companies’ reign. Amid all these uncertainties, investors must ask whether the assumption of continued success incorporated in the prices they’re paying is fully warranted.&lt;/p&gt;
    &lt;p&gt;Is exuberance leading to speculative behavior? For an extreme example, I’ll cite the trend toward venture capital investments in startups via $1 billion “seed rounds.” Here’s one vignette:&lt;/p&gt;
    &lt;p&gt;Thinking Machines, an AI startup helmed by former Open AI executive Mira Murati, just raised the largest seed round in history: $2 billion in funding at a $10 billion valuation. The company has not released a product and has refused to tell investors what they’re even trying to build. “It was the most absurd pitch meeting,” one investor who met with Murati said. “She was like, ‘So we're doing an AI company with the best AI people, but we can’t answer any questions.’ ” (“The Is How the AI Bubble Will Pop,” Derek Thompson Substack, October 2)&lt;/p&gt;
    &lt;p&gt;But that’s ancient history. . . already two months old. Here’s an update:&lt;/p&gt;
    &lt;p&gt;Thinking Machines Lab, the artificial intelligence startup founded by former Open AI executive Mira Murati, is in early talks to raise a new funding round at a roughly $50 billion valuation, Bloomberg News reported on Thursday. The startup was last valued at $12 billion in July, after it raised about $2 billion. (Reuters, November 13)&lt;/p&gt;
    &lt;p&gt;And Thinking Machines Lab isn’t alone:&lt;/p&gt;
    &lt;p&gt;In one of the boldest bets yet in the AI arms race, Safe Superintelligence (SSI), the stealth startup founded by former OpenAI chief scientist Ilya Sutskever, has raised $2 billion in a round that values the company at $32 billion – despite having no publicly released product or service. (CTech by Calcalist, April 13)&lt;/p&gt;
    &lt;p&gt;What’s the end state? Part of the issue with AI includes the unusual nature of this newest thing. This isn’t like a business that designs and sells a product, making money if the selling price exceeds the cost of the inputs. Rather, it’s companies building an airplane while it’s in flight, and once it’s built, they’ll know what it can do and whether anyone will pay for its services.&lt;/p&gt;
    &lt;p&gt;Many companies justify their spending because they’re not just building a product, they’re creating something that will change the world: artificial general intelligence, or A.G.I. . . . The rub is that none of them quite know how to do it.&lt;/p&gt;
    &lt;p&gt;But Anton Korinek, an economist at the University of Virginia, said the spending would all be justified if Silicon Valley reached its goal. He is optimistic it can be done.&lt;/p&gt;
    &lt;p&gt;“It’s a bet on A.G.I. or bust,” Dr. Korinek said. (The New York Times, November 20 – emphasis added)&lt;/p&gt;
    &lt;p&gt;The yet-to-be-determined nature of the industry under construction is best captured in remarks from Sam Altman, the CEO of OpenAI, that have been paraphrased as follows: “we’ll build this sort of generally intelligent system and then ask it to figure out a way to generate an investment return from it.”&lt;/p&gt;
    &lt;p&gt;This should be a source of pause for people who heretofore fully comprehended the nature of the businesses they invested in. Clearly, the value of a technology that equals or surpasses the human brain should be pretty big, but isn’t it well beyond calculation?&lt;/p&gt;
    &lt;p&gt;A Word About the Use of Debt&lt;/p&gt;
    &lt;p&gt;To date, much of the investment in AI and the supporting infrastructure has consisted of equity capital derived from operating cash flow. But now, companies are committing amounts that require debt financing, and for some of those companies, the investments and leverage have to be described as aggressive.&lt;/p&gt;
    &lt;p&gt;The AI data centre boom was never going to be financed with cash alone. The project is too big to be paid for out of pocket. JPMorgan analysts have done some sums on the back of a napkin, or possibly a tablecloth, and estimated the bill for the infrastructure build-out would come to $5tn (not including a tip). Who knows if that’s right, but we have good reason to expect close to half a trillion in spending next year. Meanwhile, the biggest spenders (Microsoft, Alphabet, Amazon, Meta and Oracle) had only about $350bn in the bank, collectively, as of the end of the third quarter. (“Unhedged,” Financial Times, November 13)&lt;/p&gt;
    &lt;p&gt;The firms mentioned above derive healthy cash flows from their very strong non-AI businesses. But the massive, winner-take-all arms race in AI is requiring some to take on debt. In fact, it’s reasonable to think one of the reasons they’re spending vast sums is to make it hard for lesser firms to keep up.&lt;/p&gt;
    &lt;p&gt;Oracle, Meta, and Alphabet have issued 30-year bonds to finance AI investments. In the case of the latter two, the yields on the bonds exceed those on Treasurys of like maturity by 100 basis points or less. Is it prudent to accept 30 years of technological uncertainty to make a fixed-income investment that yields little more than riskless debt? And will the investments funded with debt – in chips and data centers – maintain their level of productivity long enough for these 30-year obligations to be repaid?&lt;/p&gt;
    &lt;p&gt;On November 14, Alex Kantrowitz’s Big Technology Podcast carried a conversation with Gil Luria, Head of Technology Research at financial services firm D.A. Davidson, primarily regarding the use of debt in the AI sector. Here’s some of what Luria had to say:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Healthy behavior is being practiced by “. . . reasonable, thoughtful business leaders, like the ones at Microsoft, Amazon, and Google that are making sound investments in growing the capacity to deliver AI. And the reason they can make sound investments is that they have all the customers. . . And so, when they make investments, they’re using cash on their balance sheets; they have tremendous cash flow to back it up; they understand that it’s a risky investment; and they balance it out.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unhealthy behavior – Here he describes “. . . a startup that is borrowing money to build data centers for another startup. They’re both losing tremendous amounts of cash, and yet they’re somehow being able to raise this debt capital in order to fund this buildout, again without having the customers or the visibility into those investments paying off.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“So there’s a whole range of behaviors between healthy and unhealthy, and we just need to sort that out so we don’t make the mistakes of the past.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“There are certain things we finance through equity, through ownership, and there are certain things we finance through debt, through an obligation to pay down interest over time. And as a society, for the longest time, we’ve had those two pieces in their right place. Debt is when I have a predictable cash flow and/or an asset that can back that loan, and then it makes sense for me to exchange capital now for future cash flows to the lender. . . . We use equity for investing in more speculative things, for when we want to grow and we want to own that growth, but we’re not sure about what the cash flow is going to be. That’s how a normal economy functions. When you start confusing the two you get yourself in trouble.”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Among potentially worrisome factors, Luria cites these:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;“A speculative asset . . . we don’t know how much of it we’re really going to need in two to five years.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lender personnel with incentives to make loans but no exposure to long-term consequences&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The possibility that the supply of AI capacity catches up with or surpasses the demand&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The chance that future generations of AI chips will be more powerful, obsoleting existing ones or reducing their value as backing for debt&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powerful competitors who vie for market share by cutting rental rates and running losses&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are some important paragraphs from Azeem Azhar’s Exponential View of October 18:&lt;/p&gt;
    &lt;p&gt;When does an AI boom tip into a bubble? [Investor and engineer] Paul Kedrosky points to the Minsky moment – the inflection point when credit expansion exhausts its good projects and starts chasing bad ones, funding marginal deals with vendor financing and questionable coverage ratios. For AI infrastructure, that shift may already be underway; the telltale signs include hyperscalers’ capex outpacing revenue momentum and lenders sweetening terms to keep the party alive.&lt;/p&gt;
    &lt;p&gt;Paul makes a compelling case. We’ve entered speculative finance territory – arguably past the tentative stage – and recent deals will set dangerous precedents. As Paul warns, this financing will “create templates for future such transactions,” spurring rapid expansion in junk issuance and SPV proliferation among hyperscalers chasing dominance at any cost. . . .&lt;/p&gt;
    &lt;p&gt;For AI infrastructure, the warning signs are flashing: vendor financing proliferates, coverage ratios thin, and hyperscalers leverage balance sheets to maintain capex velocity even as revenue momentum lags. We see both sides – genuine infrastructure expansion alongside financing gymnastics that recall the 2000 telecom bust. The boom may yet prove productive, but only if revenue catches up before credit tightens. When does healthy strain become systemic risk? That’s the question we must answer before the market does. (Emphasis added)&lt;/p&gt;
    &lt;p&gt;Azhar references the use of off-balance sheet financing via special-purpose vehicles, or SPVs, which were among the biggest contributors to Enron’s precariousness and eventual collapse. A company and its partners set up an SPV for some specific purpose(s) and supply the equity capital. The parent company may have operating control, but because it doesn’t have majority ownership, it doesn’t consolidate the SPV on its financial statements. The SPV takes on debt, but that debt doesn’t appear on the parent’s books. The parent may be an investment grade borrower, but likewise, the debt isn’t an obligation of the parent or guaranteed by it. Today’s debt may be backed by promised rent from a data center tenant – sometimes an equity partner – but the debt isn’t a direct obligation of the equity partner either. Essentially, an SPV is a way to make it look like a company isn’t doing the things the SPV is doing and doesn’t have the debt the SPV does. (Private equity funds and private credit funds are highly likely to be found among the partners and lenders in these entities.)&lt;/p&gt;
    &lt;p&gt;As I quoted earlier, according to Perez (who wrote on the heels of the dot-com bubble), “what enabled the deployment period were the money-losing investments.” Early investment is lost in the “Minsky moment,” in which unwise commitments made in an extended up-cycle encounters value destruction in a correction. And there are three things we know for sure about the use of debt:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;it magnifies losses if there are losses (just as it magnifies the hoped-for gains if they materialize),&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;it increases the probability of a venture failing if it encounters a difficult moment, and&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;despite the layer of equity beneath it, it puts lenders’ capital at risk if the difficult moment is bad enough.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One key risk to consider is the possibility that the boom in data center construction will result in a glut. Some data centers may be rendered uneconomic, and some owners may go bankrupt. In that case, a new generation of owners might buy up centers at pennies on the dollar from lenders who foreclosed on them, reaping profits when the industry stabilizes. This is a process through which “creative destruction” brings markets into equilibrium and reduces costs to levels that make future business profitable.&lt;/p&gt;
    &lt;p&gt;Debt is neither a good thing nor a bad thing per se. Likewise, the use of leverage in the AI industry shouldn’t be applauded or feared. It all comes down to the proportion of debt in the capital structure; the quality of the assets or cash flows you’re lending against; the borrowers’ alternative sources of liquidity for repayment; and the adequacy of the safety margin obtained by lenders. We’ll see which lenders maintain discipline in today’s heady environment.&lt;/p&gt;
    &lt;p&gt;It’s worth noting in this connection that Oaktree has made a few investments in data centers, and our parent, Brookfield, is raising a $10 billion fund for investment in AI infrastructure. Brookfield is putting up its own money and has equity commitments from sovereign wealth funds and Nvidia, to which it intends to apply “prudent” debt. Brookfield’s investments seem likely to go largely into geographies that are less saturated with data centers and for infrastructure to supply the vast amounts of electric power that data centers will require. Of course, we’re both doing these things on the basis of what we think are prudent decisions.&lt;/p&gt;
    &lt;p&gt;I know I don’t know enough to opine on AI. But I do know something about debt, and it’s this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;It’s okay to supply debt financing for a venture where the outcome is uncertain.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It’s not okay where the outcome is purely a matter of conjecture.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Those who understand the difference still have to make the distinction correctly.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The FT’s Unhedged quotes Chong Sin, lead analyst for CMBS research at JPMorgan, as saying, “. . . in our conversations with investment grade ABS and CMBS investors, one often-cited concern is whether they want to take on the residual value risk of data centers when the bonds mature.” I’m glad potential lenders are asking the kind of questions they should.&lt;/p&gt;
    &lt;p&gt;Here’s how to think about the intersection of debt and AI according to Bob O’Leary, Oaktree’s co-CEO and co-portfolio manager of our Opportunities Funds:&lt;/p&gt;
    &lt;p&gt;Most technological advances develop into winner-takes-all or winner-takes-most competitions. The “right” way to play this dynamic is through equity, not debt. Assuming you can diversify your equity exposures so as to include the eventual winner, the massive gain from the winner will more than compensate for the capital impairment on the losers. That’s the venture capitalist’s time-honored formula for success.&lt;/p&gt;
    &lt;p&gt;The precise opposite is true of a diversified pool of debt exposures. You’ll only make your coupon on the winner, and that will be grossly insufficient to compensate for the impairments you’ll experience on the debt of the losers.&lt;/p&gt;
    &lt;p&gt;Of course, if you can’t identify the pool of companies from which the winner will emerge, the difference between debt and equity is irrelevant – you’re a zero either way. I mention this because that’s precisely what happened in search and social media: early leaders (Lycos in search and MySpace in social media) lost out spectacularly to companies that emerged later (Google in search and Facebook in social media).&lt;/p&gt;
    &lt;p&gt;Trying to Get to a Conclusion&lt;/p&gt;
    &lt;p&gt;There can be no doubt that today’s behavior is “speculative,” defined as based on speculation regarding the future. There’s also no doubt that no one knows what the future holds, but investors are betting huge sums on that future.&lt;/p&gt;
    &lt;p&gt;In that connection, I want to say a little about the unique nature of AI. The AI revolution is different from the technological revolutions that preceded it in ways that are both wonderful and worrisome. It feels to me like a genie has been released from a bottle, and it isn’t going back in:&lt;/p&gt;
    &lt;p&gt;AI may not be a tool for mankind, but rather something of a replacement. It may be capable of taking over cognition, on which humans have thus far had a monopoly. Because of this, it’s likely to be different in kind from prior developments, not just in degree. (More on this in my postscript.)&lt;/p&gt;
    &lt;p&gt;AI technology is progressing at an incredibly rapid clip, possibly leaving scant time for mankind to adjust. I’ll provide two examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Coding, which we called “computer programming” 60 years ago, is the canary in the coal mine in terms of the impact of AI. In many advanced software teams, developers no longer write the code; they type in what they want, and AI systems generate the code for them. Coding performed by AI is at a world-class level, something that wasn’t so just a year ago. According to my guide here, “There is no speculation about whether or not human replacement will take place in that vertical.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In the field of digital advertising, when users log into an app, AI engages in “ad matching,” showing them ads tailored to the preferences displayed by their prior surfing. No humans need apply to do this job.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perhaps most importantly, the growth of demand for AI seems totally unpredictable. As one of my younger advisers explained, “the speed and scale of improvement mean it’s incredibly hard to forecast demand for AI. Adoption today may have nothing to do with adoption tomorrow, because a year or two from now, AI may be able to do 10x or 100x what it can do today. Thus, how can anyone say how many data centers will be needed? And how can even successful companies know how much computing capacity to contract for?”&lt;/p&gt;
    &lt;p&gt;With differences like these, how can anyone correctly judge what AI implies for the future?&lt;/p&gt;
    &lt;p&gt;* * *&lt;/p&gt;
    &lt;p&gt;One of the things occupying many observers at this juncture – including me – is the search for parallels to past bubbles. Here’s some historical perspective from a recent article in Wired:&lt;/p&gt;
    &lt;p&gt;AI’s closest historical analogue here may be not electric lighting but radio. When RCA started broadcasting in 1919, it was immediately clear that it had a powerful information technology on its hands. But less clear was how that would translate into business. “Would radio be a loss-leading marketing for department stores? A public service for broadcasting Sunday sermons? An ad-supported medium for entertainment?” [Brent Goldfarb and David A. Kirsch of the University of Maryland] write. “All were possible. All were subjects of technological narratives.” As a result, radio turned into one of the biggest bubbles in history – peaking in 1929, before losing 97 percent of its value in the crash. This wasn’t an incidental sector; RCA was, along with Ford Motor Company, the most high-traded stock on the market. It was, as The New Yorker recently wrote, “the Nvidia of its day.” . . .&lt;/p&gt;
    &lt;p&gt;In 1927, Charles Lindbergh flew the first solo nonstop transatlantic flight from New York to Paris. . . . It was the biggest tech demo of the day, and it became an enormous, ChatGPT-launch-level coordinating event – a signal to investors to pour money into the industry.&lt;/p&gt;
    &lt;p&gt;“Expert investors appreciated correctly the importance of airplanes and air travel,” Goldfarb and Kirsch write, but “the narrative of inevitability largely drowned out their caution. Technological uncertainty was framed as opportunity, not risk. The market overestimated how quickly the industry would achieve technological viability and profitability.”&lt;/p&gt;
    &lt;p&gt;As a result, the bubble burst in 1929 – from its peak in May, aviation stocks dropped 96 percent by May 1932. . . .&lt;/p&gt;
    &lt;p&gt;It’s worth reiterating that two of the closest analogs AI seems to have in tech bubble history are aviation and broadcast radio. Both were wrapped in high degrees of uncertainty and both were hyped with incredibly powerful coordinating narratives. Both were seized on by pure play companies seeking to capitalize on the new game-changing tech, and both were accessible to the retail investors of the day. Both helped inflate a bubble so big that when it burst, in 1929, it left us with the Great Depression. (“AI Is the Bubble to Burst Them All,” Brian Merchant, Wired, October 27 – emphasis added. N.b., the Depression had many causes beyond the bursting of the radio/aviation bubble.)&lt;/p&gt;
    &lt;p&gt;Derek Thompson, who supplied the quote with which I opened this memo, ended his newsletter with some terrific historical perspective:&lt;/p&gt;
    &lt;p&gt;The railroads were a bubble and they transformed America. Electricity was a bubble, and it transformed America. The broadband build-out of the late-1990s was a bubble that transformed America. I am not rooting for a bubble, and quite the contrary, I hope that the US economy doesn’t experience another recession for many years. But given the amount of debt now flowing into AI data center construction, I think it’s unlikely that AI will be the first transformative technology that isn’t overbuilt and doesn’t incur a brief painful correction. (“AI Could Be the Railroad of the 21st Century. Brace Yourself.” November 4 – emphasis added)&lt;/p&gt;
    &lt;p&gt;The skeptics readily cite ways in which today’s events are comparable to the internet bubble:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;A change-the-world technology&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Exuberant, speculative behavior&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The role of FOMO&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Suspect, circular deals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The use of SPVs&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;$1 billion seed rounds&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The supporters have reasons why the comparison isn’t appropriate:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;An existing product for which there is strong demand&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One billion users already (many times the number of internet users at the height of the bubble)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Well-established main players with revenues, profits, and cash flow&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The absence of an IPO craze with prices doubling in a day&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reasonable p/e ratios for the established participants&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’ll elaborate regarding the first of the proposed non-comparable factors. Unlike in the internet bubble, AI products already exist at scale, the demand for them is exploding, and they’re producing revenues in rapidly increasing amounts. For example, Anthropic, one of the two leaders in producing models for AI coding as described on page 12, is said to have “10x-ed” its revenues in each of the last two years (for those who didn’t study higher math, that’s 100x in two years). Revenues from Claude Code, a program for coding that Anthropic introduced earlier this year, already are said to be running at an annual rate of $1 billion. Revenues for the other leader, Cursor, were $1 million in 2023 and $100 million in 2024, and they, too, are expected to reach $1 billion this year.&lt;/p&gt;
    &lt;p&gt;As to the final bullet point, see the table below, which comes from Goldman Sachs via Derek Thompson. You’ll notice that during the internet bubble of 1998-2000, the p/e ratios were much higher for Microsoft, Cisco, and Oracle than they are today for the biggest AI players – Nvidia, Microsoft, Alphabet, Amazon, and Meta (OpenAI doesn’t have earnings). In fact, Microsoft’s on a half-off sale relative to its p/e 26 years ago! In the first bubble I witnessed – surrounding the Nifty-Fifty in 1969-72 – the p/e ratios for the leading companies were even higher than those of 1998-2000.&lt;/p&gt;
    &lt;p&gt;In Conclusion&lt;/p&gt;
    &lt;p&gt;For my final citation, I’ll look to Sam Altman of OpenAI. His comments seem to me to capture the essence of what’s going on:&lt;/p&gt;
    &lt;p&gt;“When bubbles happen, smart people get overexcited about a kernel of truth,” Mr. Altman told reporters this year. “Are we in a phase where investors as a whole are overexcited about A.I.? My opinion is yes. Is A.I. the most important thing to happen in a very long time? My opinion is also yes.” (The New York Times, November 20)&lt;/p&gt;
    &lt;p&gt;But do I have a bottom line? Yes, I do. Alan Greenspan’s phrase, mentioned earlier, serves as an excellent way to sum up a stock market bubble: “irrational exuberance.” There is no doubt that investors are applying exuberance with regard to AI. The question is whether it’s irrational. Given the vast potential of AI but also the large number of enormous unknowns, I think virtually no one can say for sure. We can theorize about whether the current enthusiasm is excessive, but we won’t know until years from now whether it was. Bubbles are best identified in retrospect.&lt;/p&gt;
    &lt;p&gt;While the parallels to past bubbles are inescapable, believers in the technology will argue that “this time it’s different.” Those four words are heard in virtually every bubble, explaining why the present situation isn’t a bubble, unlike the analogous prior ones. On the other hand, Sir John Templeton, who in 1987 drew my attention to those four words, was quick to point out that 20% of the time things really are different. But on the third hand, it must be borne in mind that behavior based on the belief that it’s different is what causes it to not be different!&lt;/p&gt;
    &lt;p&gt;Today’s situation calls to mind a comment attributed to American economist Stuart Chase about faith. I believe it’s also applicable to AI (as well as to gold and cryptocurrencies):&lt;/p&gt;
    &lt;p&gt;For those who believe, no proof is necessary. For those who don't believe, no proof is possible.&lt;/p&gt;
    &lt;p&gt;Here’s my actual bottom line:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;There’s a consistent history of transformational technologies generating excessive enthusiasm and investment, resulting in more infrastructure than is needed and asset prices that prove to have been too high. The excesses accelerate the adoption of the technology in a way that wouldn’t occur in their absence. The common word for these excesses is “bubbles.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AI has the potential to be one of the greatest transformational technologies of all time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;As I wrote just above, AI is currently the subject of great enthusiasm. If that enthusiasm doesn’t produce a bubble conforming to the historical pattern, that will be a first.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bubbles created in this process usually end in losses for those who fuel them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The losses stem largely from the fact that the technology’s newness renders the extent and timing of its impact unpredictable. This in turn makes it easy to judge companies too positively amid all the enthusiasm and difficult to know which will emerge as winners when the dust settles.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There can be no way to participate fully in the potential benefits from the new technology without being exposed to the losses that will arise if the enthusiasm and thus investors’ behavior prove to have been excessive.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The use of debt in this process – which the high level of uncertainty usually precluded in past technological revolutions – has the potential to magnify all of the above this time.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since no one can say definitively whether this is a bubble, I’d advise that no one should go all-in without acknowledging that they face the risk of ruin if things go badly. But by the same token, no one should stay all-out and risk missing out on one of the great technological steps forward. A moderate position, applied with selectivity and prudence, seems like the best approach.&lt;/p&gt;
    &lt;p&gt;Finally, it’s essential to bear in mind that there are no magic words in investing. These days, people promoting real estate funds say, “Office buildings are so yesterday, but we’re investing in the future through data centers,” whereupon everyone nods in agreement. But data centers can be in shortage or in oversupply, and rental rates can surprise to the upside or the downside. As a result, they can be profitable . . . or not. Intelligent investment in data centers, and thus in AI – like everything else – requires sober, insightful judgment and skillful implementation.&lt;/p&gt;
    &lt;p&gt;December 9, 2025&lt;/p&gt;
    &lt;p&gt;P.S.: The following has nothing to do with the financial markets or the question of whether AI is the subject of a bubble. My topic is the impact of AI on society through joblessness and purposelessness. You needn’t read it – that’s why it’s a postscript – but it’s important to me, and I've been looking for a place to say a few words about it.&lt;/p&gt;
    &lt;p&gt;On November 18, a research note from Barclays described Fed Governor Christopher Waller as having “highlighted how recent stock market enthusiasm around AI has not yet translated into job creation.” This strikes me as paradoxical given my sense that one of AI’s main impacts will be to increase productivity and thus eliminate jobs. That is the source of my concern.&lt;/p&gt;
    &lt;p&gt;I view AI primarily as an incredible labor-saving device. Joe Davis, Global Chief Economist and Global Head of the Investment Strategy Group at Vanguard, says, “for most jobs – likely four out of five – AI’s impact will result in a mixture of innovation and automation, and could save about 43% of the time people currently spend on their work tasks.” (Exponential View, September 3)&lt;/p&gt;
    &lt;p&gt;I find the resulting outlook for employment terrifying. I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can’t find jobs because of it. The optimists argue that “new jobs have always materialized after past technological advances.” I hope that’ll hold true in the case of AI, but hope isn’t much to hang one’s hat on, and I have trouble figuring out where those jobs will come from. Of course, I’m not much of a futurist or a financial optimist, and that’s why it’s a good thing I shifted from equities to bonds in 1978.&lt;/p&gt;
    &lt;p&gt;The other thing the optimists say is that “the beneficial impact of AI on productivity will cause a huge acceleration in GDP growth.” Here I have specific quibbles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The change in GDP can be thought of as the change in hours worked times the change in output per hour (aka “productivity”). The role of AI in increasing productivity means it will take fewer hours worked – meaning fewer workers – to produce the goods we need.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Or, viewed from the other direction, maybe the boom in productivity will mean a lot more goods can be produced with the same amount of labor. But if a lot of jobs are lost to AI, how will people be able to afford the additional goods AI enables to be produced?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I find it hard to imagine a world in which AI works shoulder-to-shoulder with all the people who are employed today. How can employment not decline? AI is likely to replace large numbers of entry-level workers, people who process paper without applying judgment, and junior lawyers who scour the lawbooks for precedents. Maybe even junior investment analysts who create spreadsheets and compile presentation materials. It’s said that AI can read an MRI better than the average doctor. Driving is one of the most populous professions in America, and driverless vehicles are already arriving; where will all the people who currently drive taxis, limos, buses, and trucks find jobs?&lt;/p&gt;
    &lt;p&gt;I imagine government’s response will be something called “universal basic income.” The government will simply mail checks to the millions for whom there are no jobs. But the worrier in me finds problems in this, too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Where will the money come from for those checks? The job losses I foresee imply reduced income tax receipts and increased spending on entitlements. This puts a further burden on the declining segment of the population that is working and implies even greater deficits ahead. In this new world, will governments be able to fund ever-increasing deficits?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;And more importantly, people get a lot more from jobs than just a paycheck. A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect, and presents them with challenges, the overcoming of which provides satisfaction. How will these things be replaced? I worry about large numbers of people receiving subsistence checks and sitting around idle all day. I worry about the correlation between the loss of jobs in mining and manufacturing in recent decades and the incidence of opioid addiction and shortening of lifespans.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And by the way, if we eliminate large numbers of junior lawyers, analysts, and doctors, where will we get the experienced veterans capable of solving serious problems requiring judgment and pattern recognition honed over decades?&lt;/p&gt;
    &lt;p&gt;What jobs won’t be eliminated? What careers should our children and grandchildren prepare for? Think about the jobs that machines can’t perform. My list starts with plumbers, electricians, and masseurs –physical tasks. Maybe nurses will earn more than doctors because they deliver hands-on care. And what distinguishes the best artists, athletes, doctors, lawyers, and hopefully investors? I think it’s something called talent or insight, which AI might or might not be able to replicate. But how many people at the top of those professions are needed? A past presidential candidate said he would give laptops to everyone who lost their job to offshoring. How many laptop operators do we need?&lt;/p&gt;
    &lt;p&gt;Finally, I’m concerned that a small number of highly educated multi-billionaires living on the coasts will be viewed as having created technology that puts millions out of work. This promises even more social and political division than we have now, making the world ripe for populist demagoguery.&lt;/p&gt;
    &lt;p&gt;I’ve seen incredible progress over the course of my lifetime, but in many ways I miss the simpler world I grew up in. I worry that this will be another big one. I get no pleasure from this recitation. Will the optimists please explain why I’m wrong?&lt;/p&gt;
    &lt;p&gt;Interestingly in this connection, Vanguard’s Joe Davis points out that more Americans are turning 65 in 2025 than in any preceding year, and that approximately 16 million baby boomers will retire between now and 2035. Could AI merely make up for that? There’s an optimistic take for you.&lt;/p&gt;
    &lt;p&gt;HM&lt;/p&gt;
    &lt;p&gt;Legal Information and Disclosures&lt;/p&gt;
    &lt;p&gt;This memorandum expresses the views of the author as of the date indicated and such views are subject to change without notice. Oaktree has no duty or obligation to update the information contained herein. Further, Oaktree makes no representation, and it should not be assumed, that past investment performance is an indication of future results. Moreover, wherever there is the potential for profit there is also the possibility of loss.&lt;/p&gt;
    &lt;p&gt;This memorandum is being made available for educational purposes only and should not be used for any other purpose. The information contained herein does not constitute and should not be construed as an offering of advisory services or an offer to sell or solicitation to buy any securities or related financial instruments in any jurisdiction. Certain information contained herein concerning economic trends and performance is based on or derived from information provided by independent third-party sources. Oaktree Capital Management, L.P. (“Oaktree”) believes that the sources from which such information has been obtained are reliable; however, it cannot guarantee the accuracy of such information and has not independently verified the accuracy or completeness of such information or the assumptions on which such information is based.&lt;/p&gt;
    &lt;p&gt;This memorandum, including the information contained herein, may not be copied, reproduced, republished, or posted in whole or in part, in any form without the prior written consent of Oaktree.&lt;/p&gt;
    &lt;p&gt;© 2025 Oaktree Capital Management, L.P.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.oaktreecapital.com/insights/memo/is-it-a-bubble"/><published>2025-12-10T17:30:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220794</id><title>Show HN: Automated license plate reader coverage in the USA</title><updated>2025-12-10T20:13:06.633288+00:00</updated><link href="https://alpranalysis.com"/><published>2025-12-10T17:42:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220902</id><title>Show HN: A 2-row, 16-key keyboard designed for smartphones</title><updated>2025-12-10T20:13:01.139344+00:00</updated><content>&lt;doc fingerprint="9f140f20a2a68634"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;What makes QWERTY mini different from the ones above?&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;1. Symmetric 16-key 2-row layout makes the up-and-down movement of both thumbs extremely comfortable. &lt;/p&gt;
      &lt;p&gt;Each key becomes up to 66% larger. (cf. From the iPhone Pro to the Pro Max gives about a 20% increase.)&lt;/p&gt;
      &lt;p&gt;2. The most important point is that vowels form the central axis of a word.&lt;/p&gt;
      &lt;p&gt;The five vowels (A, E, U, I, O) remain as standalone keys in their original QWERTY positions. This eliminates any conflicts with consonants and preserves a natural typing flow. (This fixes the problems that other reduced-key layouts failed to solve.)&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;3. Frequency-based consonant integration.10 letters (Q, Z, X, V, B, J, K, F, G, P) appear in about 10% of English text.&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;4. You can type everything with just tap and double-tap.&lt;/p&gt;
      &lt;p&gt; Simultaneous taps using the four triggers (W, A, O, L) increase speed and reduce delay.&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;5. It is a structure optimized for multilingual extended characters and split layouts in landscape mode. even if these features come later.&lt;/p&gt;
      &lt;p&gt;QWERTY mini is not a replacement for QWERTY.&lt;/p&gt;
      &lt;p&gt;it's the companion for smartphones.&lt;/p&gt;
      &lt;p/&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://k-keyboard.com/Why-QWERTY-mini"/><published>2025-12-10T17:49:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221404</id><title>Intermittent hypoxia increases blood flow and benefits executive function</title><updated>2025-12-10T20:13:01.020272+00:00</updated><content/><link href="https://onlinelibrary.wiley.com/doi/10.1111/psyp.70161"/><published>2025-12-10T18:24:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221594</id><title>Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise</title><updated>2025-12-10T20:13:00.722595+00:00</updated><content>&lt;doc fingerprint="cd3e340a91d592ce"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 9 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Alexander Goslin [view email]&lt;p&gt;[v1] Tue, 9 Dec 2025 07:10:35 UTC (12,075 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CV&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.08309"/><published>2025-12-10T18:37:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221925</id><title>Super Mario 64 for the PS1</title><updated>2025-12-10T20:13:00.073766+00:00</updated><content>&lt;doc fingerprint="57cb9c197ca5b5c8"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a fork of the full decompilation of Super Mario 64 (J), (U), (E), and (SH).&lt;/item&gt;
      &lt;item&gt;It is heavily modified and can no longer target Nintendo 64, only PSX and PC (for debugging).&lt;/item&gt;
      &lt;item&gt;There are still many limitations.&lt;/item&gt;
      &lt;item&gt;For now, it can only build from the US version.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This repo does not include all assets necessary for compiling the game. An original copy of the game is required to extract the assets.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cool "DUAL SHOCK™ Compatible" graphic mimicking the original "振動パック対応" (Rumble Pak Compatible) graphic&lt;/item&gt;
      &lt;item&gt;An analog rumble signal is now produced for the DualShock's large motor, in addition to the original modulated digital signal for the small motor and for the SCPH-1150 Dual Analog Controller&lt;/item&gt;
      &lt;item&gt;Low-precision soft float implementation specially written for PSX to reduce the performance impact of floats&lt;/item&gt;
      &lt;item&gt;Large amounts of code have been adapted to use fixed point math, including the 16-bit integer vectors and matrices that are standard on PSX&lt;/item&gt;
      &lt;item&gt;Simplified rewritten render graph walker&lt;/item&gt;
      &lt;item&gt;Tessellation (up to 2x) to reduce issues with large polygons&lt;/item&gt;
      &lt;item&gt;RSP display lists are compiled just-in-time into a custom display list format that is more compact and faster to process&lt;/item&gt;
      &lt;item&gt;Display list preprocessor that removes commands we won't use and optimizes meshes (TODO: make it fix more things)&lt;/item&gt;
      &lt;item&gt;Mario's animations are compressed (from 580632 to 190324 bytes) and placed in a corner of VRAM rather than being loaded from storage (we don't have the luxury of a fast cartridge to read from in the middle of a frame)&lt;/item&gt;
      &lt;item&gt;Custom profiler&lt;/item&gt;
      &lt;item&gt;Custom texture encoder that quantizes all textures to 4 bits per pixel&lt;/item&gt;
      &lt;item&gt;Translucent circle-texture shadows replaced with subtractive hexagonal shadows, as the PSX doesn't support arbitrary translucency&lt;/item&gt;
      &lt;item&gt;(TODO) Camera system adapted to rotate with the right analog stick&lt;/item&gt;
      &lt;item&gt;(TODO) Simplified rewritten Goddard subsystem&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Floating trees (temporary issue due caused by a math rewrite)&lt;/item&gt;
      &lt;item&gt;Some of Mario's animations do not play, and may even crash the game&lt;/item&gt;
      &lt;item&gt;Music cannot be generated at build time without manually obtaining the tracks&lt;/item&gt;
      &lt;item&gt;Sound effects work but sometimes sound odd or are missing notes&lt;/item&gt;
      &lt;item&gt;The camera cannot be controlled in many levels due to the unfinished camera control implementation&lt;/item&gt;
      &lt;item&gt;Crashes when entering certain levels (due to insufficient memory?)&lt;/item&gt;
      &lt;item&gt;Ending sequence crashes on load&lt;/item&gt;
      &lt;item&gt;When reaching the bridge in the castle grounds, Mario looks up but Lakitu never comes over&lt;/item&gt;
      &lt;item&gt;Poles do not go down when pounded&lt;/item&gt;
      &lt;item&gt;Textures are loaded individually, causing long stutters and loading times&lt;/item&gt;
      &lt;item&gt;Stretched textures due to PSX limitations (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Tessellation is not good enough to fix all large polygons (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Some textures are rendered incorrectly (RSP JIT issues?)&lt;/item&gt;
      &lt;item&gt;Title screen is unfinished&lt;/item&gt;
      &lt;item&gt;Pause menu doesn't work&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build and install the mipsel-none-elf-gcc toolchain. For Arch users, it is available on AUR. (You can also install it on your system from https://github.com/malucard/poeng by running &lt;code&gt;make install-gcc&lt;/code&gt;from there. This may take a long time.)&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-port&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-port&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version without music, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install and update MSYS2, following all the directions listed on https://www.msys2.org/.&lt;/item&gt;
      &lt;item&gt;From the start menu, launch MSYS2 MinGW and install required packages depending on your machine (do NOT launch "MSYS2 MSYS"):&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;64-bit: Launch "MSYS2 MinGW 64-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-x86_64-gcc mingw-w64-x86_64-meson mingw-w64-x86_64-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;32-bit (will also work on 64-bit machines): Launch "MSYS2 MinGW 32-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-i686-gcc mingw-w64-i686-meson mingw-w64-i686-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Do NOT by mistake install the packages called simply &lt;code&gt;gcc&lt;/code&gt;and&lt;code&gt;meson&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install the mipsel-none-elf-gcc toolchain.&lt;/item&gt;
      &lt;item&gt;The MSYS2 terminal has a current working directory that initially is &lt;code&gt;C:\msys64\home\&amp;lt;username&amp;gt;&lt;/code&gt;(home directory). At the prompt, you will see the current working directory in yellow.&lt;code&gt;~&lt;/code&gt;is an alias for the home directory. You can change the current working directory to&lt;code&gt;My Documents&lt;/code&gt;by entering&lt;code&gt;cd /c/Users/&amp;lt;username&amp;gt;/Documents&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-psx&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-psx&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you get &lt;code&gt;make: gcc: no suitable C and C++ compiler found&lt;/code&gt;,&lt;code&gt;make: gcc: command not found&lt;/code&gt;,&lt;code&gt;make: gcc: No such file or directory&lt;/code&gt;although the packages did successfully install, you probably launched the wrong MSYS2. Read the instructions again. The terminal prompt should contain "MINGW32" or "MINGW64" in purple text, and NOT "MSYS".&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;Failed to open baserom.us.z64!&lt;/code&gt;you failed to place the baserom in the repository. You can write&lt;code&gt;ls&lt;/code&gt;to list the files in the current working directory. If you are in the&lt;code&gt;sm64-psx&lt;/code&gt;directory, make sure you see it here.&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;make: *** No targets specified and no makefile found. Stop.&lt;/code&gt;, you are not in the correct directory. Make sure the yellow text in the terminal ends with&lt;code&gt;sm64-psx&lt;/code&gt;. Use&lt;code&gt;cd &amp;lt;dir&amp;gt;&lt;/code&gt;to enter the correct directory. If you write&lt;code&gt;ls&lt;/code&gt;you should see all the project files, including&lt;code&gt;Makefile&lt;/code&gt;if everything is correct.&lt;/item&gt;
      &lt;item&gt;If you get any error, be sure MSYS2 packages are up to date by executing &lt;code&gt;pacman -Syu&lt;/code&gt;and&lt;code&gt;pacman -Su&lt;/code&gt;. If the MSYS2 window closes immediately after opening it, restart your computer.&lt;/item&gt;
      &lt;item&gt;Check if mipsel gcc is working by executing &lt;code&gt;mipsel-none-elf-gcc -v&lt;/code&gt;. If it doesn't work, you either opened the wrong MSYS start menu entry or installed the incorrect gcc package.&lt;/item&gt;
      &lt;item&gt;When switching between building on other platforms, run &lt;code&gt;make -C tools clean&lt;/code&gt;first to allow for the tools to recompile on the new platform. This also helps when switching between shells like WSL and MSYS2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sm64
├── actors: object behaviors, geo layout, and display lists
├── assets: animation and demo data
│   ├── anims: animation data
│   └── demos: demo data
├── bin: C files for ordering display lists and textures
├── build: output directory
├── data: behavior scripts, misc. data
├── doxygen: documentation infrastructure
├── enhancements: example source modifications
├── include: header files
├── levels: level scripts, geo layout, and display lists
├── lib: N64 SDK code
├── sound: sequences, sound samples, and sound banks
├── src: C source code for game
│   ├── audio: audio code
│   ├── buffers: stacks, heaps, and task buffers
│   ├── engine: script processing engines and utils
│   ├── game: behaviors and rest of game source
│   ├── goddard: rewritten Mario intro screen
│   ├── goddard_og: backup of original Mario intro screen
│   ├── menu: title screen and file, act, and debug level selection menus
│   └── port: port code, audio and video renderer
├── text: dialog, level names, act names
├── textures: skybox and generic texture data
└── tools: build tools
&lt;/code&gt;
    &lt;p&gt;Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/malucard/sm64-psx"/><published>2025-12-10T18:58:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46222165</id><title>The future of Terraform CDK</title><updated>2025-12-10T20:12:59.277564+00:00</updated><content>&lt;doc fingerprint="9510f5515e5f62fb"&gt;
  &lt;main&gt;
    &lt;p&gt;Terraform CDK (CDKTF) will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date. Unfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem.&lt;/p&gt;
    &lt;p&gt;As of December 10, 2025, Terraform CDK will be archived on GitHub, and the documentation will reflect its deprecated status. The archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements (including compatibility updates) will be made.&lt;/p&gt;
    &lt;p&gt;You will be able to continue to use Terraform CDK at your own risk. Terraform CDK is licensed under the Mozilla Public License (MPL). HashiCorp, an IBM Company, does not apply any additional restrictions. We encourage community forks if there’s interest in continuing development independently.&lt;/p&gt;
    &lt;p&gt;You can use the following command to generate Terraform-compatible .tf files directly from your Terraform CDK project:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;cdktf synth --hcl&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This will produce readable HCL configuration files, making it easier to migrate away from Terraform CDK. After running the command, you can use standard Terraform CLI commands (&lt;code&gt;terraform init&lt;/code&gt;, &lt;code&gt;terraform plan&lt;/code&gt;, &lt;code&gt;terraform apply&lt;/code&gt;) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.&lt;/p&gt;
    &lt;p&gt;If your infrastructure is defined in Terraform CDK but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem. If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.&lt;/p&gt;
    &lt;p&gt;Q: Is CDKTF still being developed?&lt;/p&gt;
    &lt;p&gt;A: No. CDKTF will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date.&lt;/p&gt;
    &lt;p&gt;Q: Why is CDKTF being sunset?&lt;/p&gt;
    &lt;p&gt;A: CDKTF did not find product-market fit at scale. We’ve chosen to focus our investments on Terraform core and its broader ecosystem.&lt;/p&gt;
    &lt;p&gt;Q: Will CDKTF be removed from GitHub?&lt;/p&gt;
    &lt;p&gt;A: CDKTF will be archived on GitHub, and documentation will reflect its deprecated status.&lt;/p&gt;
    &lt;p&gt;Q: Can I still use CDKTF after it's sunset?&lt;/p&gt;
    &lt;p&gt;A: Yes, the archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements will be made.&lt;/p&gt;
    &lt;p&gt;Q: Will CDKTF continue to support new versions of Terraform or providers?&lt;/p&gt;
    &lt;p&gt;A: No. Compatibility updates will not be made after the EOL date.&lt;/p&gt;
    &lt;p&gt;Q: Can I fork CDKTF and maintain it myself?&lt;/p&gt;
    &lt;p&gt;A: Yes. CDKTF is open source, and we encourage community forks if there’s interest in continuing development independently.&lt;/p&gt;
    &lt;p&gt;Q: Can I keep using CDKTF?&lt;/p&gt;
    &lt;p&gt;A: You may continue to use it at your own risk. HashiCorp, an IBM Company, will no longer be maintaining it.&lt;/p&gt;
    &lt;p&gt;Q: Is there a migration tool?&lt;/p&gt;
    &lt;p&gt;A: You can use the following command to generate Terraform-compatible .tf files directly from your CDKTF project:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;cdktf synth --hcl&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This will produce readable HCL configuration files, making it easier to migrate away from CDKTF. After running the command, you can use standard Terraform CLI commands (terraform init, terraform plan, terraform apply) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.&lt;/p&gt;
    &lt;p&gt;Q: What migration guidance can we provide to customers?&lt;/p&gt;
    &lt;p&gt;A: For users looking to migrate away from CDKTF:&lt;/p&gt;
    &lt;p&gt;If your infrastructure is defined in CDKTF but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem.&lt;/p&gt;
    &lt;p&gt;If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.&lt;/p&gt;
    &lt;p&gt;Cloud Development Kit for Terraform (CDKTF) allows you to use familiar programming languages to define cloud infrastructure and provision it through HashiCorp Terraform. This gives you access to the entire Terraform ecosystem without learning HashiCorp Configuration Language (HCL) and lets you leverage the power of your existing toolchain for testing, dependency management, etc.&lt;/p&gt;
    &lt;p&gt;We currently support TypeScript, Python, Java, C#, and Go.&lt;/p&gt;
    &lt;p&gt;CDKTF includes two packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;cdktf-cli - A CLI that allows users to run commands to initialize, import, and synthesize CDK for Terraform applications.&lt;/item&gt;
      &lt;item&gt;cdktf - A library for defining Terraform resources using programming constructs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choose a language:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hands-on: Try the tutorials in the CDK for Terraform collection on HashiCorp Learn.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Refer to the CDKTF documentation for more detail about how to build and manage CDKTF applications, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Application Architecture: Learn the tools and processes that CDKTF uses to leverage the Terraform ecosystem and convert code into Terraform configuration files. It also explains the major components of a CDKTF application and how those pieces fit together.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Project Setup: Learn how to create a new CDKTF project from a pre-built or custom template. Also learn how to convert an existing HCL project into a CDKTF application.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unit Tests: Learn how to test your application in Typescript with jest.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Examples: Reference example projects in every supported language and review explanatory videos and other resources.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The development team would love your feedback to help guide the project.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Contribute using the CONTRIBUTING.md guide.&lt;/item&gt;
      &lt;item&gt;Ask a question on the HashiCorp Discuss using the terraform-cdk category.&lt;/item&gt;
      &lt;item&gt;Report a bug or request a new feature.&lt;/item&gt;
      &lt;item&gt;Browse all open issues.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For prerequisites, refer to the following.&lt;/p&gt;
    &lt;p&gt;Clone the project repository.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/hashicorp/terraform-cdk.git&lt;/code&gt;
    &lt;p&gt;Download dependencies.&lt;/p&gt;
    &lt;code&gt;cd terraform-cdk/
yarn install&lt;/code&gt;
    &lt;p&gt;Build the project and packages.&lt;/p&gt;
    &lt;code&gt;yarn build&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/hashicorp/terraform-cdk"/><published>2025-12-10T19:14:03+00:00</published></entry></feed>