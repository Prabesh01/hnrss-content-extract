<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-15T17:08:46.066376+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45247423</id><title>The Culture novels as a dystopia</title><updated>2025-09-15T17:08:55.221737+00:00</updated><content>&lt;doc fingerprint="174c9192284b83ec"&gt;
  &lt;main&gt;
    &lt;p&gt;A couple of people have mentioned to me: ‚Äúwe need more fiction examples of positive AI superintelligence ‚Äì utopias like the Culture novels‚Äù. And they‚Äôre right, AI can be tremendously positive, and some beacons lit into the future could help make that come around.&lt;/p&gt;
    &lt;p&gt;But one of my hobbies is ‚Äúoppositional reading‚Äù ‚Äì deliberately interpreting novels counter to the obvious / intended reading. And it‚Äôs not so clear to me that the Culture is all it is cracked up to be.&lt;/p&gt;
    &lt;p&gt;Most of the novels take the perspective of Culture members, and so fully accept their ideology. We can‚Äôt take broad claims about their society as accurate unless they are directly confirmed by the evidence in the books1.&lt;/p&gt;
    &lt;head rend="h3"&gt;A manipulated population&lt;/head&gt;
    &lt;p&gt;In many ways, the humans of the Culture do not behave like modern humans. This is usually explained as a consequence of post-scarcity ‚Äì why commit crimes when everything is free and social acceptance is everything; why rush when you can live as long as you like.&lt;/p&gt;
    &lt;p&gt;But the citizens of Culture are really strangely homogenous. Player of Games gives an example of an rare out-of-distribution citizen ‚Äì Gurgeh is competitive and uninterested in other people and most aspects of Culture. But he still shares basically all their values. People like him are a dime-a-dozen in present day Earth. There are apparently no sociopaths ‚Äì Culture has to recruit an outsider when they need one. We also see examples of subcultures or even cults, but again by modern standards they are incredibly tame, and are never potentially destabilizing to culture.&lt;/p&gt;
    &lt;p&gt;Citizens are not actually human, but drawn from several humanoid species, and they outpopulate present-Earth by 5 orders of magnitude so if anything the range of deviation should be much larger.&lt;/p&gt;
    &lt;p&gt;The conclusion is clear that the population of Culture is carefully controlled to produce the desired outcome. Potentially, the Minds pull this off by a superhumanly effective and subtle propaganda. But I think it is more likely that it was achieved by genetic changes, so that it‚Äôs safe to raise full Culture citizens in other cultures. This would be similar meddling to the Culture‚Äôs drones, which are human level AIs that have their personalities designed into them at creation, allowing only an acceptable range of behaviours.&lt;/p&gt;
    &lt;p&gt;Nowhere is this more obvious than in the birthrate. Sure, the vast majority of citizens voluntarily choose to only have a replacement level of children. But the existence of post-scarcity in-vitro development means you could raise an army of clones if you wanted, and would be free to isolate them and indoctrinate similar beliefs. The fact that grabby citizens haven‚Äôt overrun Culture shows that these actions are blocked, either tacitly or overtly. Similarly, it‚Äôs strange that no one in Culture modifies themselves into a utility monster, or is interested in simulating sentient life.&lt;/p&gt;
    &lt;head rend="h3"&gt;What motivates the Minds&lt;/head&gt;
    &lt;p&gt;Conversely, the Minds seem too diverse to match their claimed motivations. They are meant to be an example of a well behaved AI ‚Äì benevolent and ethical. Sometimes we‚Äôre told this is because they are too smart to be otherwise, but there are plenty of non-Culture superintelligences in the books that do not share their values so this cannot be true.&lt;/p&gt;
    &lt;p&gt;We also see that there are a number of Eccentrics, Minds that don‚Äôt fully share the values of Culture. They‚Äôre not that rare, about 1% of the population. In Excession, it‚Äôs explained that Minds do rarely drift far enough to go rogue and are destroyed by the Culture. In other words, these superhuman minds have not solved alignment, and they cannot/will not inspect each other to determine misalignment before malicious action is taken. We even see GSV Absconding with Style stockpile resources without general knowledge of the other Minds.&lt;/p&gt;
    &lt;p&gt;Presumably, the existing Minds must have worked out that this setup is somehow stable as they are comfortable making new minds. It seems likely that misaligned Minds are capable of predicting they‚Äôd lose any military action against the established core, so prefer toeing the line of acceptability or leaving Culture entirely. In any case, the incumbent Minds maintain their rule via physical strength and monitoring, not something more subtle.&lt;/p&gt;
    &lt;p&gt;Essentially, the Culture must have value lock-in for the values of the Minds that were present at its founding. This explains some of their weird inconsistencies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They are capable of simulating sentient beings, but choose not to, but they do maintain humans in physical space.&lt;/item&gt;
      &lt;item&gt;They intervene with foreign civilisations, but often with half efforts or absurdly light touches at random.&lt;/item&gt;
      &lt;item&gt;They are trapped in civilizational stasis as they refuse to Sublime ‚Äì the next step for civilizations of their technology level.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;But what about Special Contact?&lt;/head&gt;
    &lt;p&gt;Look, I‚Äôm sorry to break it to you, but SC is a sham. The Minds are perfectly capable of creating avatars which would be more effective than any of the characters shown. I‚Äôve never found the explanations offered convincing. SC is just an affectation or another tool of propaganda.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;So there we have it, Culture traps its citizens in a sugar bowl they don‚Äôt even realise they are in, while working hard to maintain a status quo that seems arbitrary and ill-conceived. Their control is absolute ‚Äì all the novels describe events happening outside of Culture where anything remotely interesting is happening.&lt;/p&gt;
    &lt;p&gt;If anything, humans are treated closer to pets than independent agents. They are a weird affectation that is deliberately neutered from any real influence. They are lavished with treats and attention not extended to the rest of the universe.&lt;/p&gt;
    &lt;p&gt;As readers, we are blinded by the amount of material wealth and power of the Culture, and the self-satisfied story it tells of itself. It‚Äôs too easy to call this a Utopia because we lust after immortality, teleportation, glands that secrete psychoactive drugs and a spacefaring empire. But these are all essentially window dressing. The modern era would look like such a Utopia to the past, but we now (rightly) consider modern comforts as only a foundation for higher-level wants, like justice and self-determination. Writing positive sci-fi is already considered a challenge, but I‚Äôd ask you to consider not relying too heavily on such shiny promises of wealth.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Note: I view all the books through a in-universe lens and thus will not consider that things are as they are because the narrative needs it ‚Ü©Ô∏é&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.boristhebrave.com/2025/09/14/the-culture-novels-as-a-dystopia/"/><published>2025-09-15T08:32:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45247890</id><title>RustGPT: A pure-Rust transformer LLM built from scratch</title><updated>2025-09-15T17:08:54.512493+00:00</updated><content>&lt;doc fingerprint="35db335f75314ff8"&gt;
  &lt;main&gt;
    &lt;head class="px-3 py-2"&gt;RustGPT-demo-zoon.mp4&lt;/head&gt;
    &lt;p&gt;A complete Large Language Model implementation in pure Rust with no external ML frameworks. Built from the ground up using only &lt;code&gt;ndarray&lt;/code&gt; for matrix operations.&lt;/p&gt;
    &lt;p&gt;This project demonstrates how to build a transformer-based language model from scratch in Rust, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pre-training on factual text completion&lt;/item&gt;
      &lt;item&gt;Instruction tuning for conversational AI&lt;/item&gt;
      &lt;item&gt;Interactive chat mode for testing&lt;/item&gt;
      &lt;item&gt;Full backpropagation with gradient clipping&lt;/item&gt;
      &lt;item&gt;Modular architecture with clean separation of concerns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Start with these two core files to understand the implementation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;src/main.rs&lt;/code&gt;- Training pipeline, data preparation, and interactive mode&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;src/llm.rs&lt;/code&gt;- Core LLM implementation with forward/backward passes and training logic&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The model uses a transformer-based architecture with the following components:&lt;/p&gt;
    &lt;code&gt;Input Text ‚Üí Tokenization ‚Üí Embeddings ‚Üí Transformer Blocks ‚Üí Output Projection ‚Üí Predictions
&lt;/code&gt;
    &lt;code&gt;src/
‚îú‚îÄ‚îÄ main.rs              # üéØ Training pipeline and interactive mode
‚îú‚îÄ‚îÄ llm.rs               # üß† Core LLM implementation and training logic
‚îú‚îÄ‚îÄ lib.rs               # üìö Library exports and constants
‚îú‚îÄ‚îÄ transformer.rs       # üîÑ Transformer block (attention + feed-forward)
‚îú‚îÄ‚îÄ self_attention.rs    # üëÄ Multi-head self-attention mechanism  
‚îú‚îÄ‚îÄ feed_forward.rs      # ‚ö° Position-wise feed-forward networks
‚îú‚îÄ‚îÄ embeddings.rs        # üìä Token embedding layer
‚îú‚îÄ‚îÄ output_projection.rs # üé∞ Final linear layer for vocabulary predictions
‚îú‚îÄ‚îÄ vocab.rs            # üìù Vocabulary management and tokenization
‚îú‚îÄ‚îÄ layer_norm.rs       # üßÆ Layer normalization
‚îî‚îÄ‚îÄ adam.rs             # üèÉ Adam optimizer implementation

tests/
‚îú‚îÄ‚îÄ llm_test.rs         # Tests for core LLM functionality
‚îú‚îÄ‚îÄ transformer_test.rs # Tests for transformer blocks
‚îú‚îÄ‚îÄ self_attention_test.rs # Tests for attention mechanisms
‚îú‚îÄ‚îÄ feed_forward_test.rs # Tests for feed-forward layers
‚îú‚îÄ‚îÄ embeddings_test.rs  # Tests for embedding layers
‚îú‚îÄ‚îÄ vocab_test.rs       # Tests for vocabulary handling
‚îú‚îÄ‚îÄ adam_test.rs        # Tests for optimizer
‚îî‚îÄ‚îÄ output_projection_test.rs # Tests for output layer
&lt;/code&gt;
    &lt;p&gt;The implementation includes two training phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Pre-training: Learns basic world knowledge from factual statements&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;"The sun rises in the east and sets in the west"&lt;/item&gt;
          &lt;item&gt;"Water flows downhill due to gravity"&lt;/item&gt;
          &lt;item&gt;"Mountains are tall and rocky formations"&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Instruction Tuning: Learns conversational patterns&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;"User: How do mountains form? Assistant: Mountains are formed through tectonic forces..."&lt;/item&gt;
          &lt;item&gt;Handles greetings, explanations, and follow-up questions&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone and run
git clone https://github.com/tekaratzas/RustGPT.git 
cd RustGPT
cargo run

# The model will:
# 1. Build vocabulary from training data
# 2. Pre-train on factual statements (100 epochs)  
# 3. Instruction-tune on conversational data (100 epochs)
# 4. Enter interactive mode for testing&lt;/code&gt;
    &lt;p&gt;After training, test the model interactively:&lt;/p&gt;
    &lt;code&gt;Enter prompt: How do mountains form?
Model output: Mountains are formed through tectonic forces or volcanism over long geological time periods

Enter prompt: What causes rain?
Model output: Rain is caused by water vapor in clouds condensing into droplets that become too heavy to remain airborne
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vocabulary Size: Dynamic (built from training data)&lt;/item&gt;
      &lt;item&gt;Embedding Dimension: 128&lt;/item&gt;
      &lt;item&gt;Hidden Dimension: 256&lt;/item&gt;
      &lt;item&gt;Max Sequence Length: 80 tokens&lt;/item&gt;
      &lt;item&gt;Architecture: 3 Transformer blocks + embeddings + output projection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optimizer: Adam with gradient clipping&lt;/item&gt;
      &lt;item&gt;Pre-training LR: 0.0005 (100 epochs)&lt;/item&gt;
      &lt;item&gt;Instruction Tuning LR: 0.0001 (100 epochs)&lt;/item&gt;
      &lt;item&gt;Loss Function: Cross-entropy loss&lt;/item&gt;
      &lt;item&gt;Gradient Clipping: L2 norm capped at 5.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Custom tokenization with punctuation handling&lt;/item&gt;
      &lt;item&gt;Greedy decoding for text generation&lt;/item&gt;
      &lt;item&gt;Gradient clipping for training stability&lt;/item&gt;
      &lt;item&gt;Modular layer system with clean interfaces&lt;/item&gt;
      &lt;item&gt;Comprehensive test coverage for all components&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Run all tests
cargo test

# Test specific components
cargo test --test llm_test
cargo test --test transformer_test
cargo test --test self_attention_test

# Build optimized version
cargo build --release

# Run with verbose output
cargo test -- --nocapture&lt;/code&gt;
    &lt;p&gt;This implementation demonstrates key ML concepts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Transformer architecture (attention, feed-forward, layer norm)&lt;/item&gt;
      &lt;item&gt;Backpropagation through neural networks&lt;/item&gt;
      &lt;item&gt;Language model training (pre-training + fine-tuning)&lt;/item&gt;
      &lt;item&gt;Tokenization and vocabulary management&lt;/item&gt;
      &lt;item&gt;Gradient-based optimization with Adam&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perfect for understanding how modern LLMs work under the hood!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ndarray&lt;/code&gt;- N-dimensional arrays for matrix operations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rand&lt;/code&gt;+&lt;code&gt;rand_distr&lt;/code&gt;- Random number generation for initialization&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No PyTorch, TensorFlow, or Candle - just pure Rust and linear algebra!&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! This project is perfect for learning and experimentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üè™ Model Persistence - Save/load trained parameters to disk (currently all in-memory)&lt;/item&gt;
      &lt;item&gt;‚ö° Performance optimizations - SIMD, parallel training, memory efficiency&lt;/item&gt;
      &lt;item&gt;üéØ Better sampling - Beam search, top-k/top-p, temperature scaling&lt;/item&gt;
      &lt;item&gt;üìä Evaluation metrics - Perplexity, benchmarks, training visualizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Advanced architectures (multi-head attention, positional encoding, RoPE)&lt;/item&gt;
      &lt;item&gt;Training improvements (different optimizers, learning rate schedules, regularization)&lt;/item&gt;
      &lt;item&gt;Data handling (larger datasets, tokenizer improvements, streaming)&lt;/item&gt;
      &lt;item&gt;Model analysis (attention visualization, gradient analysis, interpretability)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch: &lt;code&gt;git checkout -b feature/model-persistence&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Make your changes and add tests&lt;/item&gt;
      &lt;item&gt;Run the test suite: &lt;code&gt;cargo test&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Submit a pull request with a clear description&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow standard Rust conventions (&lt;code&gt;cargo fmt&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Add comprehensive tests for new features&lt;/item&gt;
      &lt;item&gt;Update documentation and README as needed&lt;/item&gt;
      &lt;item&gt;Keep the "from scratch" philosophy - avoid heavy ML dependencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ Beginner: Model save/load, more training data, config files&lt;/item&gt;
      &lt;item&gt;üî• Intermediate: Beam search, positional encodings, training checkpoints&lt;/item&gt;
      &lt;item&gt;‚ö° Advanced: Multi-head attention, layer parallelization, custom optimizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Questions? Open an issue or start a discussion!&lt;/p&gt;
    &lt;p&gt;No PyTorch, TensorFlow, or Candle - just pure Rust and linear algebra!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/tekaratzas/RustGPT"/><published>2025-09-15T09:47:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45248868</id><title>Pgstream: Postgres streaming logical replication with DDL changes</title><updated>2025-09-15T17:08:53.670913+00:00</updated><content>&lt;doc fingerprint="2d147b31acbab590"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;pgstream&lt;/code&gt; is an open source CDC command-line tool and library that offers Postgres replication support with DDL changes to any provided target.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Schema change tracking and replication of DDL changes&lt;/item&gt;
      &lt;item&gt;Support for multiple out of the box targets &lt;list rend="ul"&gt;&lt;item&gt;Elasticsearch/OpenSearch&lt;/item&gt;&lt;item&gt;Webhooks&lt;/item&gt;&lt;item&gt;PostgreSQL&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Initial and on demand PostgreSQL snapshots (for when you don't need continuous replication)&lt;/item&gt;
      &lt;item&gt;Column value transformations (anonymise your data on the go!)&lt;/item&gt;
      &lt;item&gt;Modular deployment configuration, only requires Postgres&lt;/item&gt;
      &lt;item&gt;Kafka support with schema based partitioning&lt;/item&gt;
      &lt;item&gt;Extendable support for custom targets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pgstream&lt;/code&gt; can be used via the readily available CLI or as a library. For detailed information about the CLI usage, check out the dedicated CLI documentation section.&lt;/p&gt;
    &lt;p&gt;Binaries are available for Linux, macOS &amp;amp; Windows, check our Releases.&lt;/p&gt;
    &lt;p&gt;To install &lt;code&gt;pgstream&lt;/code&gt; from the source, run the following command:&lt;/p&gt;
    &lt;code&gt;go install github.com/xataio/pgstream@latest&lt;/code&gt;
    &lt;p&gt;To install &lt;code&gt;pgstream&lt;/code&gt; with homebrew, run the following command:&lt;/p&gt;
    &lt;code&gt;# macOS or Linux
brew tap xataio/pgstream
brew install pgstream&lt;/code&gt;
    &lt;p&gt;If you have an environment available, with at least Postgres and whichever module resources you're planning on running, then you can skip this step. Otherwise, a docker setup is available in this repository that starts Postgres, Kafka and OpenSearch (as well as OpenSearch dashboards for easy visualisation).&lt;/p&gt;
    &lt;code&gt;docker-compose -f build/docker/docker-compose.yml up
&lt;/code&gt;
    &lt;p&gt;The docker-compose file has profiles that can be used in order to bring up only the relevant containers. If for example you only want to run PostgreSQL to PostgreSQL pgstream replication you can use the &lt;code&gt;pg2pg&lt;/code&gt; profile as follows:&lt;/p&gt;
    &lt;code&gt;docker-compose -f build/docker/docker-compose.yml --profile pg2pg up
&lt;/code&gt;
    &lt;p&gt;You can also run multiple profiles. For example to start two PostgreSQL instances and Kafka:&lt;/p&gt;
    &lt;code&gt;docker-compose -f build/docker/docker-compose.yml --profile pg2pg --profile kafka up
&lt;/code&gt;
    &lt;p&gt;List of supported docker profiles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;pg2pg&lt;/item&gt;
      &lt;item&gt;pg2os&lt;/item&gt;
      &lt;item&gt;pg2webhook&lt;/item&gt;
      &lt;item&gt;kafka&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Pgstream source and target need to be configured appropriately before the commands can be run. This can be done:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using the relevant CLI flags for each command&lt;/item&gt;
      &lt;item&gt;Using a yaml configuration file&lt;/item&gt;
      &lt;item&gt;Using environment variables (.env file supported)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the documentation for more information about the configuration options, or check the help on the CLI for details on the available flags. Additionally, at the root of this repository you can find sample files for both .env and .yaml.&lt;/p&gt;
    &lt;p&gt;If you want to configure column transformations, leveraging greenmask, neosync and go-masker open source integrations, as well as custom transformers, check the transformation rules configuration for more details, along with the list of available transformers.&lt;/p&gt;
    &lt;p&gt;This will create the &lt;code&gt;pgstream&lt;/code&gt; schema in the configured Postgres database, along with the tables/functions/triggers required to keep track of the schema changes. See Tracking schema changes section for more details. It will also create a replication slot for the configured database which will be used by the pgstream service. If no replication slot name is provided, it will use a default one with the format &lt;code&gt;pgstream_&amp;lt;database&amp;gt;_slot&lt;/code&gt;.
This step can be skipped and &lt;code&gt;--init&lt;/code&gt; can be provided as an option to &lt;code&gt;run&lt;/code&gt; command. It will do the same preparation right before starting the replication.&lt;/p&gt;
    &lt;code&gt;# with CLI flags
pgstream init --postgres-url "postgres://postgres:postgres@localhost?sslmode=disable" --replication-slot test
# with yaml configuration file
pgstream init -c pg2pg.yaml
# with environment configuration file
pgstream init -c pg2pg.env&lt;/code&gt;
    &lt;p&gt;The status of the initalisation and the configuration can be checked by using the &lt;code&gt;status&lt;/code&gt; command.&lt;/p&gt;
    &lt;code&gt;pgstream status -c pg2pg.yaml
SUCCESS  pgstream status check encountered no issues
Initialisation status:
 - Pgstream schema exists: true
 - Pgstream schema_log table exists: true
 - Migration current version: 7
 - Migration status: success
 - Replication slot name: pgstream_postgres_slot
 - Replication slot plugin: wal2json
 - Replication slot database: postgres
Config status:
 - Valid: true
Transformation rules status:
 - Valid: true
Source status:
 - Reachable: true&lt;/code&gt;
    &lt;p&gt;If there are any issues or if you want to revert the pgstream setup, you can use the &lt;code&gt;destroy&lt;/code&gt; command to clean up all pgstream state.&lt;/p&gt;
    &lt;code&gt;pgstream destroy --postgres-url "postgres://postgres:postgres@localhost?sslmode=disable" --replication-slot test
# with yaml configuration file
pgstream destroy -c pg2pg.yaml
# with environment configuration file
pgstream destroy -c pg2pg.env&lt;/code&gt;
    &lt;p&gt;Run will start streaming data from the configured source into the configured target.&lt;/p&gt;
    &lt;p&gt;Example running pgstream replication from Postgres -&amp;gt; OpenSearch:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c pg2os.env --log-level trace
# using the yaml configuration file
pgstream run -c pg2os.yaml --log-level info
# using the CLI flags
pgstream run --source postgres --source-url "postgres://postgres:postgres@localhost:5432?sslmode=disable" --target opensearch --target-url "http://admin:admin@localhost:9200"&lt;/code&gt;
    &lt;p&gt;Example running pgstream with Postgres -&amp;gt; Kafka, and in a separate terminal, Kafka-&amp;gt;OpenSearch:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c pg2kafka.env --log-level trace
# using the yaml configuration file
pgstream run -c pg2kafka.yaml --log-level info
# using the CLI flags
pgstream run --source postgres --source-url "postgres://postgres:postgres@localhost:5432?sslmode=disable" --target kafka --target-url "localhost:9092"&lt;/code&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c kafka2os.env --log-level trace
# using the yaml configuration file
pgstream run -c kafka2os.yaml --log-level info
# using the CLI flags
pgstream run --source kafka --source-url "localhost:9092" --target opensearch --target-url "http://admin:admin@localhost:9200"&lt;/code&gt;
    &lt;p&gt;Example running pgstream with PostgreSQL -&amp;gt; PostgreSQL with initial snapshot enabled:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c pg2pg.env --log-level trace
# using the yaml configuration file
pgstream run -c pg2pg.yaml --log-level info
# using the CLI flags
pgstream run --source postgres --source-url "postgres://postgres:postgres@localhost:5432?sslmode=disable" --target postgres --target-url "postgres://postgres:postgres@localhost:7654?sslmode=disable" --snapshot-tables test&lt;/code&gt;
    &lt;p&gt;Example running pgstream to perform a snapshot from PostgreSQL -&amp;gt; PostgreSQL:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream snapshot -c snapshot2pg.env --log-level trace
# using the yaml configuration file
pgstream snapshot -c snapshot2pg.yaml --log-level info
# using the CLI flags
pgstream snapshot --postgres-url="postgres://postgres:postgres@localhost:5432?sslmode=disable" --target=postgres --target-url="postgres://postgres:postgres@localhost:7654?sslmode=disable" --tables="test" --reset&lt;/code&gt;
    &lt;p&gt;Pgstream will parse the configuration provided, and initialise the relevant modules. It requires at least one source(listener) and one target(processor).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PostgreSQL replication to PostgreSQL&lt;/item&gt;
      &lt;item&gt;PostgreSQL replication to OpenSearch&lt;/item&gt;
      &lt;item&gt;PostgreSQL replication to webhooks&lt;/item&gt;
      &lt;item&gt;PostgreSQL replication using Kafka&lt;/item&gt;
      &lt;item&gt;PostgreSQL snapshots&lt;/item&gt;
      &lt;item&gt;PostgreSQL column transformations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more advanced usage, implementation details, and detailed configuration settings, please refer to the full documentation below.&lt;/p&gt;
    &lt;p&gt;Datasets used: IMDB database, MusicBrainz database, Firenibble database.&lt;/p&gt;
    &lt;p&gt;All benchmarks were run using the same setup, with pgstream &lt;code&gt;v0.7.2&lt;/code&gt;, pg_dump/pg_restore (PostgreSQL) 17.4 and PostgreSQL 17.4, using identical resources to ensure a fair comparison.&lt;/p&gt;
    &lt;p&gt;For more details into performance benchmarking for snapshots to PostgreSQL with &lt;code&gt;pgstream&lt;/code&gt;, check out this blogpost.&lt;/p&gt;
    &lt;p&gt;Some of the limitations of the initial release include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single Kafka topic support&lt;/item&gt;
      &lt;item&gt;Postgres plugin support limited to &lt;code&gt;wal2json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;No row level filtering support&lt;/item&gt;
      &lt;item&gt;Primary key/unique not null column required for replication&lt;/item&gt;
      &lt;item&gt;Kafka serialisation support limited to JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome contributions from the community! If you'd like to contribute to pgstream, please follow these guidelines and adhere to our code of conduct.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;If you have any questions, encounter issues, or need assistance, open an issue in this repository our join our Discord, and our community will be happy to help.&lt;/p&gt;
    &lt;p&gt;Made with üíú by Xata ü¶ã&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/xataio/pgstream"/><published>2025-09-15T12:28:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45248899</id><title>How big a solar battery do I need to store all my home's electricity?</title><updated>2025-09-15T17:08:52.930900+00:00</updated><content>&lt;doc fingerprint="b671805753a57731"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How big a solar battery do I need to store *all* my home's electricity?&lt;/head&gt;
    &lt;p&gt;I have a modest set of solar panels on an entirely ordinary house in suburban London.&lt;/p&gt;
    &lt;p&gt;On average they generate about 3,800kWh per year. We also use about 3,800kWh of electricity each year. Obviously, we can't use all the power produced over summer and we need to buy power in winter. So here's my question:&lt;/p&gt;
    &lt;p&gt;How big a battery would we need in order to be completely self-sufficient?&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;Let's take a look at a typical summer's day. The graph is a little complex, so I'll explain it.&lt;/p&gt;
    &lt;p&gt;The yellow line shows solar production. It starts shortly after sunrise, peaks at midday, and gradually drops until sunset.&lt;/p&gt;
    &lt;p&gt;The red line shows how much electricity our home is using. As you can see, there's a large peak about 19:00 when we cook dinner.&lt;/p&gt;
    &lt;p&gt;The blue line shows how much electricity we draw or export from the grid. From midnight until sunrise we import because the sun isn't shining. Once the sun has risen we're able to power our house and export to our neighbours. When we cook, we draw from the grid and our battery - which is why the evening grid peak is lower than the household use dip.&lt;/p&gt;
    &lt;p&gt;The CSV of the data looks something like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Local_time&lt;/cell&gt;
        &lt;cell role="head"&gt;Household_(W)&lt;/cell&gt;
        &lt;cell role="head"&gt;Solar_(W)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:25:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-187.76&lt;/cell&gt;
        &lt;cell&gt;1166.77&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:30:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-227.04&lt;/cell&gt;
        &lt;cell&gt;1193.25&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:35:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-253.06&lt;/cell&gt;
        &lt;cell&gt;1222.84&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:40:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-266.87&lt;/cell&gt;
        &lt;cell&gt;1245.18&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:45:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-450.8&lt;/cell&gt;
        &lt;cell&gt;1268.66&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:50:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-251.84&lt;/cell&gt;
        &lt;cell&gt;1281.79&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T08:55:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-1426.26&lt;/cell&gt;
        &lt;cell&gt;1306.93&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T09:00:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-206.78&lt;/cell&gt;
        &lt;cell&gt;1341.37&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T09:05:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-215.52&lt;/cell&gt;
        &lt;cell&gt;1390.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2025-08-25T09:10:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-242.6&lt;/cell&gt;
        &lt;cell&gt;1426.19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;2025-08-25T09:15:00.000+01:00&lt;/cell&gt;
        &lt;cell&gt;-246.84&lt;/cell&gt;
        &lt;cell&gt;1473&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It's fairly trivial to sum both columns and subtract one from the other. That shows either the excess or deficit in solar power for the household.&lt;/p&gt;
    &lt;p&gt;On that day, the house used 9.7kWh and generated 19.6kWh. I'd need a 9.9kWh battery to store the excess right? Wrong!&lt;/p&gt;
    &lt;p&gt;Because my usage doesn't track the sun, I'd actually need a 13kWh battery. That's the peak amount of excess electricity I've generated in that one day.&lt;/p&gt;
    &lt;p&gt;What I want to do is find out what the maximum size battery I would need in order to store all of summer's electricity for use in winter.&lt;/p&gt;
    &lt;p&gt;Luckily, I have several years of real data to go off! Let's get started!&lt;/p&gt;
    &lt;head rend="h2"&gt;Disclaimer&lt;/head&gt;
    &lt;p&gt;This is based on data generated by my home battery. It has probes to measure solar output and grid flow. It is not 100% clock-accurate compared to my solar-panels' internal reporting nor what my smart-meter reports. I estimate a 1-2% deviation, which is good enough for these purposes.&lt;/p&gt;
    &lt;p&gt;My energy usage isn't representative of anything other than my usage. Your household is probably different. I already have a 4.8kWh battery which changes how and when I use energy.&lt;/p&gt;
    &lt;p&gt;This doesn't account for gas heating or hot water. We have some electric heaters and taps which increases our electricity usage.&lt;/p&gt;
    &lt;p&gt;My maths is probably right - but the code is open source, so feel free to check for yourself.&lt;/p&gt;
    &lt;p&gt;Remember, this is just a bit of fun. There's no practical way to build domestic batteries with this capacity using the technology of 2025.&lt;/p&gt;
    &lt;head rend="h2"&gt;Code&lt;/head&gt;
    &lt;p&gt;We tend to start generating more electricity than we use starting in Spring. So I've picked the end of March 2024 to the end of March 2025.&lt;/p&gt;
    &lt;p&gt;Let's see how big a battery we'd need to store our summer excess for winter. This finds the cumulative difference between each day's energy production and usage:&lt;/p&gt;
    &lt;code&gt; Python 3 import os
import pandas as pd

# Load all the CSVs
filepaths = [f for f in os.listdir(".") if f.endswith('.csv')]
df = pd.concat(map(pd.read_csv, filepaths))

# Make sure they're in order
df = df.sort_values("Timestamp")
df = df.reset_index(drop=True)

# Resolution is every 5 minutes, so divide by 12 to get hourly
df["Cumulative_Difference"] = ( (df["Household_(W)"] + df["Solar_(W)"] ).cumsum() ) / 12

# kWh of battery needed
int(df["Cumulative_Difference"].max() / 1000)

## Draw a pretty graph
df.plot(kind="line", x="Local_time", y="Cumulative_Difference", xlabel="Date", ylabel="MWh", xticks=["2024-04-01", "2024-05-01", "2024-05-01", "2024-06-01", "2024-07-01", "2024-08-01", "2024-09-01", "2024-10-01", "2024-11-01", "2024-12-01", "2025-01-01", "2025-02-01", "2025-03-01", "2025-04-01"], legend=False, grid=True, fontsize=15)
plt.show()
&lt;/code&gt;
    &lt;p&gt;The total is 1,068KWh - basically, a MegaWatt-hour of storage.&lt;/p&gt;
    &lt;p&gt;Here's a quick graph to show how the storage would be used over the year.&lt;/p&gt;
    &lt;p&gt;As you can see, even in this scenario there are a few days where we'd need to import energy from the grid.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is this sensible?&lt;/head&gt;
    &lt;p&gt;Probably not, no. It doesn't account for increased energy use from having an electric car or moving away from gas heating / cooking. As solar panels increase in efficiency, it might be more sensible to replace the panels on my roof, or add some onto a shed.&lt;/p&gt;
    &lt;p&gt;The environmental impact of creating and storing such huge batteries could also be factored in.&lt;/p&gt;
    &lt;p&gt;A battery which is only 100% full for a few days probably isn't an efficient design. Using wind, hydro, and other green sources from the grid might be preferable.&lt;/p&gt;
    &lt;p&gt;But, remember, this is an exercise in wishful thinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is this possible?&lt;/head&gt;
    &lt;p&gt;Grid-scale batteries exist and they work brilliantly.&lt;/p&gt;
    &lt;p&gt;But if I wanted my own MegaWatt-hour of battery storage, it would probably cost me between ¬£100k and half-a-million quid.&lt;/p&gt;
    &lt;p&gt;That doesn't include maintenance, the land, planning permission, and a hundred other things.&lt;/p&gt;
    &lt;p&gt;But battery prices are falling fast. In the last decade lithium ion battery prices have fallen 90%. With new sodium ion batteries promising an even bigger drop - down to US$10/kWh.&lt;/p&gt;
    &lt;p&gt;If - and it is a big if - those numbers came to pass, it would probably cost around ¬£8,000 for a domestic battery. Basically the same cost as adding solar panels in the first place.&lt;/p&gt;
    &lt;p&gt;Domestic solar works - yes, even in the rainy UK! It is relatively cheap, moves energy production as close as possible to energy consumption, reduces bill-shock, and means we don't have endless planning arguments about whether fields should be turned into solar farms.&lt;/p&gt;
    &lt;p&gt;It is possible that, not too long in the future, every home could also have a 1 MegaWatt-hour battery. They would be able to capture all the excess solar power generated in a year.&lt;/p&gt;
    &lt;p&gt;There's a bright and sunny future where every home can be solar-self-sufficient.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://shkspr.mobi/blog/2025/09/how-big-a-solar-battery-do-i-need-to-store-all-my-homes-electricity/"/><published>2025-09-15T12:33:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45249287</id><title>Hosting a website on a disposable vape</title><updated>2025-09-15T17:08:52.830627+00:00</updated><content>&lt;doc fingerprint="26b5c1054b922ae9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Hosting a WebSite on a Disposable Vape&lt;/head&gt;
    &lt;head rend="h1"&gt;Preface#&lt;/head&gt;
    &lt;p&gt;This article is NOT served from a web server running on a disposable vape. If you want to see the real deal, click here. The content is otherwise identical.&lt;/p&gt;
    &lt;head rend="h1"&gt;Background#&lt;/head&gt;
    &lt;p&gt;For a couple of years now, I have been collecting disposable vapes from friends and family. Initially, I only salvaged the batteries for ‚Äúfuture‚Äù projects (It‚Äôs not hoarding, I promise), but recently, disposable vapes have gotten more advanced. I wouldn‚Äôt want to be the lawyer who one day will have to argue how a device with USB C and a rechargeable battery can be classified as ‚Äúdisposable‚Äù. Thankfully, I don‚Äôt plan on pursuing law anytime soon.&lt;/p&gt;
    &lt;p&gt;Last year, I was tearing apart some of these fancier pacifiers for adults when I noticed something that caught my eye, instead of the expected black blob of goo hiding some ASIC (Application Specific Integrated Circuit) I see a little integrated circuit inscribed ‚ÄúPUYA‚Äù. I don‚Äôt blame you if this name doesn‚Äôt excite you as much it does me, most people have never heard of them. They are most well known for their flash chips, but I first came across them after reading Jay Carlson‚Äôs blog post about the cheapest flash microcontroller you can buy. They are quite capable little ARM Cortex-M0+ micros.&lt;/p&gt;
    &lt;p&gt;Over the past year I have collected quite a few of these PY32 based vapes, all of them from different models of vape from the same manufacturer. It‚Äôs not my place to do free advertising for big tobacco, so I won‚Äôt mention the brand I got it from, but if anyone who worked on designing them reads this, thanks for labeling the debug pins!&lt;/p&gt;
    &lt;head rend="h1"&gt;What are we working with#&lt;/head&gt;
    &lt;p&gt;The chip is marked &lt;code&gt;PUYA C642F15&lt;/code&gt;, which wasn‚Äôt very helpful. I was pretty sure it was a &lt;code&gt;PY32F002A&lt;/code&gt;, but after poking around with pyOCD, I noticed that the flash was 24k and we have 3k of RAM. The extra flash meant that it was more likely a &lt;code&gt;PY32F002B&lt;/code&gt;, which is actually a very different chip.1&lt;/p&gt;
    &lt;p&gt;So here are the specs of a microcontroller so bad, it‚Äôs basically disposable:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;24MHz Coretex M0+&lt;/item&gt;
      &lt;item&gt;24KiB of Flash Storage&lt;/item&gt;
      &lt;item&gt;3KiB of Static RAM&lt;/item&gt;
      &lt;item&gt;a few peripherals, none of which we will use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You may look at those specs and think that it‚Äôs not much to work with. I don‚Äôt blame you, a 10y old phone can barely load google, and this is about 100x slower. I on the other hand see a blazingly fast web server.&lt;/p&gt;
    &lt;head rend="h1"&gt;Getting online#&lt;/head&gt;
    &lt;p&gt;The idea of hosting a web server on a vape didn‚Äôt come to me instantly. In fact, I have been playing around with them for a while, but after writing my post on semihosting, the penny dropped.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt feel like reading that article, semihosting is basically syscalls for embedded ARM microcontrollers. You throw some values/pointers into some registers and call a breakpoint instruction. An attached debugger interprets the values in the registers and performs certain actions. Most people just use this to get some logs printed from the microcontroller, but they are actually bi-directional.&lt;/p&gt;
    &lt;p&gt;If you are older than me, you might remember a time before Wi-Fi and Ethernet, the dark ages, when you had to use dial-up modems to get online. You might also know that the ghosts of those modems still linger all around us. Almost all USB serial devices actually emulate those modems: a 56k modem is just 57600 baud serial device. Data between some of these modems was transmitted using a protocol called SLIP (Serial Line Internet Protocol).2&lt;/p&gt;
    &lt;p&gt;This may not come as a surprise, but Linux (and with some tweaking even macOS) supports SLIP. The &lt;code&gt;slattach&lt;/code&gt; utility can make any &lt;code&gt;/dev/tty*&lt;/code&gt; send and receive IP packets. All we have to do is put the data down the wire in the right format and provide a virtual tty.
This is actually easier than you might imagine, pyOCD can forward all semihosting though a telnet port. Then, we use &lt;code&gt;socat&lt;/code&gt; to link that port to a virtual tty:&lt;/p&gt;
    &lt;code&gt;pyocd gdb -S -O semihost_console_type=telnet -T $(PORT) $(PYOCDFLAGS) &amp;amp;
socat PTY,link=$(TTY),raw,echo=0 TCP:localhost:$(PORT),nodelay &amp;amp;
sudo slattach -L -p slip -s 115200 $(TTY) &amp;amp;
sudo ip addr add 192.168.190.1 peer 192.168.190.2/24 dev sl0
sudo ip link set mtu 1500 up dev sl0
&lt;/code&gt;
    &lt;p&gt;Ok, so we have a ‚Äúmodem‚Äù, but that‚Äôs hardly a web server. To actually talk TCP/IP, we need an IP stack. There are many choices, but I went with uIP because it‚Äôs pretty small, doesn‚Äôt require an RTOS, and it‚Äôs easy to port to other platforms. It also, helpfully, comes with a very minimal HTTP server example.&lt;/p&gt;
    &lt;p&gt;After porting the SLIP code to use semihosting, I had a working web server&amp;amp;mldr;half of the time. As with most highly optimised libraries, uIP was designed for 8 and 16-bit machines, which rarely have memory alignment requirements. On ARM however, if you dereference a &lt;code&gt;u16 *&lt;/code&gt;, you better hope that address is even, or you‚Äôll get an exception. The &lt;code&gt;uip_chksum&lt;/code&gt; assumed &lt;code&gt;u16&lt;/code&gt; alignment, but the script that creates the filesystem didn‚Äôt.
I actually decided to modify a bit the structure of the filesystem to make it a bit more portable.
This was my first time working with &lt;code&gt;perl&lt;/code&gt; and I have to say, it‚Äôs quite well suited to this kind of task.&lt;/p&gt;
    &lt;head rend="h1"&gt;Blazingly fast#&lt;/head&gt;
    &lt;p&gt;So how fast is a web server running on a disposable microcontroller. Well, initially, not very fast. Pings took ~1.5s with 50% packet loss and a simple page took over 20s to load. That‚Äôs so bad, it‚Äôs actually funny, and I kind of wanted to leave it there.&lt;/p&gt;
    &lt;p&gt;However, the problem was actually between the seat and the steering wheel the whole time. The first implementation read and wrote a single character at a time, which had a massive overhead associated with it. I previously benchmarked semihosting on this device, and I was getting ~20KiB/s, but uIP‚Äôs SLIP implementation was designed for very low memory devices, so it was serialising the data byte by byte. We have a whopping 3kiB of RAM to play with, so I added a ring buffer to cache reads from the host and feed them into the SLIP poll function. I also split writes in batches to allow for escaping.&lt;/p&gt;
    &lt;p&gt;Now this is what I call blazingly fast! Pings now take 20ms, no packet loss and a full page loads in about 160ms. This was using using almost all of the RAM, but I could also dial down the sizes of the buffer to have more than enough headroom to run other tasks. The project repo has everything set to a nice balance latency and RAM usage:&lt;/p&gt;
    &lt;code&gt;Memory region         Used Size  Region Size  %age Used
           FLASH:        5116 B        24 KB     20.82%
             RAM:        1380 B         3 KB     44.92%
&lt;/code&gt;
    &lt;p&gt;For this blog however, I paid for none of the RAM, so I‚Äôll use all of the RAM.&lt;/p&gt;
    &lt;p&gt;As you may have noticed, we have just under 20kiB (80%) of storage space. That may not be enough to ship all of React, but as you can see, it‚Äôs more than enough to host this entire blog post. And this is not just a static page server, you can run any server-side code you want, if you know C that is.&lt;/p&gt;
    &lt;p&gt;Just for fun, I added a json api endpoint to get the number of requests to the main page (since the last crash) and the unique ID of the microcontroller.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bogdanthegeek.github.io/blog/projects/vapeserver/"/><published>2025-09-15T13:13:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45249697</id><title>Show HN: Semlib ‚Äì Semantic Data Processing</title><updated>2025-09-15T17:08:52.187138+00:00</updated><content>&lt;doc fingerprint="58478597d03c509c"&gt;
  &lt;main&gt;
    &lt;p&gt;Semlib is a Python library for building data processing and data analysis pipelines that leverage the power of large language models (LLMs). Semlib provides, as building blocks, familiar functional programming primitives like &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;reduce&lt;/code&gt;, &lt;code&gt;sort&lt;/code&gt;, and &lt;code&gt;filter&lt;/code&gt;, but with a twist: Semlib's implementation of these operations are programmed with natural language descriptions rather than code. Under the hood, Semlib handles complexities such as prompting, parsing, concurrency control, caching, and cost tracking.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;pip install semlib&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;üìñ API Reference ‚¨Ä ü§î Rationale üí° Examples ‚¨Ä&lt;/p&gt;
    &lt;code&gt;&amp;gt;&amp;gt;&amp;gt; presidents = await prompt(
...     "Who were the 39th through 42nd presidents of the United States?",
...     return_type=Bare(list[str])
... )

&amp;gt;&amp;gt;&amp;gt; await sort(presidents, by="right-leaning")
['Jimmy Carter', 'Bill Clinton', 'George H. W. Bush', 'Ronald Reagan']

&amp;gt;&amp;gt;&amp;gt; await find(presidents, by="former actor")
'Ronald Reagan'

&amp;gt;&amp;gt;&amp;gt; await map(
...     presidents,
...     "How old was {} when he took office?",
...     return_type=Bare(int),
... )
[52, 69, 64, 46]&lt;/code&gt;
    &lt;p&gt;Large language models are great at natural-language data processing and data analysis tasks, but when you have a large amount of data, you can't get high-quality results by just dumping all the data into a long-context LLM and asking it to complete a complex task in a single shot. Even with today's reasoning models and agents, this approach doesn't give great results.&lt;/p&gt;
    &lt;p&gt;This library provides an alternative. You can structure your computation using the building blocks that Semlib provides: functional programming primitives upgraded to handle semantic operations. This approach has a number of benefits.&lt;/p&gt;
    &lt;p&gt;Quality. By breaking down a sophisticated data processing task into simpler steps that are solved by today's LLMs, you can get higher-quality results, even in situations where today's LLMs might be capable of processing the data in a single shot and ending up with barely acceptable results. (example: analyzing support tickets in Airline Support Report)&lt;/p&gt;
    &lt;p&gt;Feasibility. Even long-context LLMs have limitations (e.g., 1M tokens in today's frontier models). Furthermore, performance often drops off with longer inputs. By breaking down the data processing task into smaller steps, you can handle arbitrary-sized data. (example: sorting an arbitrary number of arXiv papers in arXiv Paper Recommendations)&lt;/p&gt;
    &lt;p&gt;Latency. By breaking down the computation into smaller pieces and structuring it using functional programming primitives like &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt;, the parts of the computation can be run concurrently, reducing the latency of the overall computation.
(example: tree reduce with O(log n) computation depth in Disneyland Reviews Synthesis)&lt;/p&gt;
    &lt;p&gt;Cost. By breaking down the computation into simpler sub-tasks, you can use smaller and cheaper models that are capable of solving those sub-tasks, which can reduce data processing costs. Furthermore, you can choose the model on a per-subtask basis, allowing you to further optimize costs. (example: using &lt;code&gt;gpt-4.1-nano&lt;/code&gt; for the pre-filtering step in arXiv Paper Recommendations)&lt;/p&gt;
    &lt;p&gt;Security. By breaking down the computation into tasks that simpler models can handle, you can use open models that you host yourself, allowing you to process sensitive data without having to trust a third party. (example: using &lt;code&gt;gpt-oss&lt;/code&gt; and &lt;code&gt;qwen3&lt;/code&gt; in Resume Filtering)&lt;/p&gt;
    &lt;p&gt;Flexibility. LLMs are great at certain tasks, like natural-language processing. They're not so great at other tasks, like multiplying numbers. Using Semlib, you can break down your data processing task into multiple steps, some of which use LLMs and others that just use regular old Python code, getting the best of both worlds. (example: Python code for filtering in Resume Filtering)&lt;/p&gt;
    &lt;p&gt;Read more about the rationale, the story behind this library, and related work in the blog post.&lt;/p&gt;
    &lt;code&gt;@misc{athalye:semlib,
  author = {Anish Athalye},
  title = {{Semlib}: Semantic data processing for {Python}},
  year = {2025},
  howpublished = {\url{https://github.com/anishathalye/semlib}},
}&lt;/code&gt;
    &lt;p&gt;Copyright (c) Anish Athalye. Released under the MIT License. See LICENSE.md for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/anishathalye/semlib"/><published>2025-09-15T13:45:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45249878</id><title>CubeSats are fascinating learning tools for space</title><updated>2025-09-15T17:08:51.987309+00:00</updated><content>&lt;doc fingerprint="b535155168e585d4"&gt;
  &lt;main&gt;
    &lt;p&gt;These are CubeSats. Satellites that are going to space‚Äîor at least, the ones I have here are prototypes. But these have one thing in common: they're all powered by either a Raspberry Pi, or a microcontroller.&lt;/p&gt;
    &lt;p&gt;There are already Pis in space, like on Mark Rober's SatGus, on GASPACS, and the Astro Pis on the Space station. Another Pi is going up this weekend, which is why I'm posting this today. I'll get to that one, but I wanted to spend some time talking about two things that fascinate me: Raspberry Pis, and putting them space!&lt;/p&gt;
    &lt;p&gt;In this post, I'll cover:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What is a CubeSat&lt;/item&gt;
      &lt;item&gt;Who builds and launches CubeSats&lt;/item&gt;
      &lt;item&gt;How you can build your own CubeSat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then for a bonus, in today's video, I interviewed two people helping students launch SilverSat into space (this weekend!), and a YouTuber who I've learned a lot from about track satellites (including CubeSats) from your own backyard!&lt;/p&gt;
    &lt;p&gt;The rest of this post contains a lightly-edited transcript of the video above.&lt;/p&gt;
    &lt;p&gt;So let's dive in.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's a CubeSat?&lt;/head&gt;
    &lt;p&gt;What's a CubeSat? Well, it's in the name‚Äîit's a satellite that's a cube!&lt;/p&gt;
    &lt;p&gt;But they don't have to be a cube, these smallest ones are '1U', or 10 x 10 x 10 centimeters. You can also find 2U CubeSats, like the taller Build a CubeSat, which is 20 centimeters tall. (Well, technically the current prototype is 1.5U).&lt;/p&gt;
    &lt;p&gt;SatGus, Mark Rober's satellite taking space selfies, is a whopping 12U! They needed all that extra space to fit a phone, a mechanism to deploy the phone, a camera to take the selfie, a Raspberry Pi to control the phone, and redundant systems for everything. They've already taken thousands of selfies, and SatGus has me beat. My best Pi might get to 3.4 Gigahertz, but the Pi on SatGus is whizzing through space at almost 17,000 miles per hour. That's 7,570 meters per second for everyone else in the world.&lt;/p&gt;
    &lt;p&gt;But back to CubeSats. Having standards means you can build off existing work for the hard things, like a space-rated Aluminum frame, or the complex EPS, or Electrical Power System board.&lt;/p&gt;
    &lt;p&gt;Then you can add in custom parts, like a Pi to run experiments, a communications board with antennas and radios, cameras, sensors, and more!&lt;/p&gt;
    &lt;p&gt;And these cubesats have normal screw-on antennas, but the way these things are deployed, you only get 10x10x10 centimeters‚Äîyou can't have an antenna poking out the top. So they use cool things like flexible tape antennas that pop out once your CubeSat deploys.&lt;/p&gt;
    &lt;p&gt;What else makes CubeSats cool?&lt;/p&gt;
    &lt;p&gt;Well, how about price? In the old days, you had to have like $10 million to build a satellite, and $60+ million to launch it into space.&lt;/p&gt;
    &lt;p&gt;Today, you can build a space-ready CubeSat using a few thousand dollars of parts. Then you can launch it on a rideshare for... well, $85 grand. Which is a lot, but it's not $60 million-a-lot.&lt;/p&gt;
    &lt;p&gt;So most of us won't be launching one of these things into space, unless maybe you can get a grant. But that doesn't mean they're not useful to us.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who builds CubeSats?&lt;/head&gt;
    &lt;p&gt;Like with many projects, I love these things for the challenge, the way they break some of my assumptions, like working with Raspberry Pis.&lt;/p&gt;
    &lt;p&gt;If you're building a device that's less than 2 kilograms, has 1.8W of maximum continuous power draw, and needs to be operated remotely‚Äîeven for just a month‚Äîyou're immediately going to change your assumptions about how you build things.&lt;/p&gt;
    &lt;p&gt;I would hack Home Assistant onto a mini PC to monitor some sensors if I was feeling lazy‚Äîbut that Mini PC would use an order of magnitude too much power for a CubeSat (much less the internal volume it would occupy).&lt;/p&gt;
    &lt;p&gt;On CubeSats, every millimeter, and every milliAmp has to be accounted for.&lt;/p&gt;
    &lt;p&gt;So to me, CubeSats are like Swiss watches of modern electronics. How many sensors can you fit in one? How much throughput can you get on a tiny radio with a small antenna? Can you get enough power out of tiny solar cells to keep the main flight computer working? How do you control thermals without air? How do you design it so it can recover from a complete power loss?&lt;/p&gt;
    &lt;p&gt;Every step of the way there are challenges; and that's before we even launch one! Someone who I think illustrates this best is Manuel, with his Build a CubeSat project. He's working on this Cubesat:&lt;/p&gt;
    &lt;p&gt;He did a weather balloon launch this year, and he's documenting everything on YouTube.&lt;/p&gt;
    &lt;p&gt;His first launch had many small problems. But also great learning, especially around redundancy and how to get the thing off the launch stand without problems.&lt;/p&gt;
    &lt;p&gt;And you're not only dealing with hardware, but also with software. And software that, at its core, has to be remotely accessed. And not only remote, but also wireless, meaning anyone else on earth within range can access it too.&lt;/p&gt;
    &lt;p&gt;So how do you keep it secure? That's something Tim from Ethos Labs is also dealing with with this, his T.E.M.P.E.S.T. CubeSat:&lt;/p&gt;
    &lt;p&gt;This thing is actually made to be not secure. It has intentional vulnerabilities, and he uses those to teach people different ways to make their CubeSats more secure.&lt;/p&gt;
    &lt;p&gt;You have complex hardware, running in limited space, with limited power and communications, and you want cram in as much functionality as possible.&lt;/p&gt;
    &lt;p&gt;Do you see where I'm going with this? That kind of problem is perfect for the microcontrollers and low-power SBCs that I love testing and playing with every day.&lt;/p&gt;
    &lt;p&gt;Except instead of me worrying about something consuming 10 watts, these guys are looking at a power budget of one watt. Or less!&lt;/p&gt;
    &lt;p&gt;These problems are hard. And not everyone has the patience for a completely custom project like Build a CubeSat, so there are also some small companies building kits to help you learn all these lessons with a little less stress.&lt;/p&gt;
    &lt;p&gt;Like what hardware do you need for a 100% self-contained CubeSat? And how do you get it certified for flight on a SpaceX rocket?&lt;/p&gt;
    &lt;head rend="h2"&gt;Your own CubeSat&lt;/head&gt;
    &lt;p&gt;Well, I'll quickly cover two products that are meant for like STEM classroom education, one from the lower end, and one that's based on a CubeSat that just flew this summer.&lt;/p&gt;
    &lt;p&gt;The first one is the MySat Kit, that you can buy from MySat in Ukraine. It comes with a board powered by an ESP32 with a camera, light sensors, an LED, gyroscope, accelerometer, barometer, clock, and a few other boards. And these are all off-the-shelf components you can buy replacements for or use 'em with other hardware, like a Raspberry Pi.&lt;/p&gt;
    &lt;p&gt;The way it's put together won't hold up on a rocket launch, but it's not meant for that. It's meant to show you how it's built, how you can communicate with it, and that sort of thing.&lt;/p&gt;
    &lt;p&gt;It took like an hour to build, and once I put it together I tried flashing the flight control firmware with my Mac... but I ran into some issues with Arduino IDE, and that's a me problem and not so much a MySat problem. Plus the team behind it has a whole war going on that they've been dealing with, so I'll be patient and try getting it going later.&lt;/p&gt;
    &lt;p&gt;The MySat goes from like $130 for a basic kit where you 3D print your own frame, or up to $300 for a full kit including deployable solar panels.&lt;/p&gt;
    &lt;p&gt;On the higher end, there's RASCube, and Edward Robinson, the 21 year old founder of Robinson Space, sent it over after he saw me posting about CubeSats online.&lt;/p&gt;
    &lt;p&gt;The RASCube comes from Australia, and Edward's mission is to teach students about space through hands-on building.&lt;/p&gt;
    &lt;p&gt;I just built this LS version of the cube last week; it's the little brother to their V2 design, which flew in space on a Falcon 9 rocket earlier this year.&lt;/p&gt;
    &lt;p&gt;Like MySat, you build the kit with an EPS board for power, a computer board with all the controls, and a radio board that ties in GPS and radio comms.&lt;/p&gt;
    &lt;p&gt;The RASCubes are a bit more expensive, coming in at around $430 each for the LB, and $600 each for the full aluminum V2s. But the price tag on that also covers full lesson plans and resources for teachers.&lt;/p&gt;
    &lt;p&gt;I love these things‚Äîall the people I've talked to on this journey are motivated by the same thing: learning about space, electronics, and integrating hardware in a new way, and sharing what they learn with others, especially students.&lt;/p&gt;
    &lt;head rend="h2"&gt;CubeSat T.E.M.P.E.S.T. and Build a CubeSat&lt;/head&gt;
    &lt;p&gt;Like take Build a Cubesat. For that project, everything is open source hardware, and every part of the journey is being documented on YouTube.&lt;/p&gt;
    &lt;p&gt;One thing I learned from the first flight test was how weird it is to have your Pi go from like overheating on the ground, to getting really cold as it goes higher, but then overheating again in the upper atmosphere because there's not enough air to dissipate heat!&lt;/p&gt;
    &lt;p&gt;You start to realize some of the crazy physical conditions you'll deal with on orbit.&lt;/p&gt;
    &lt;p&gt;Back down to earth, though, for CubeSat Tempest: the whole reason this exists is to help people learn why security is important, even for a tiny CubeSat. More importantly, Tim Fowler's course teaches people how to secure things like uplinks (see: the ground station pictured above) and flight control systems.&lt;/p&gt;
    &lt;p&gt;There are so many people like Tim, who work in their free time to try to teach about space, or engineering, or just small slices of things like security, using these tactile little cubes you can build and put next to your laptop on a desk.&lt;/p&gt;
    &lt;p&gt;It's crazy to think we're to a point where students can build these things, write flight control software, and even launch 'em into space!&lt;/p&gt;
    &lt;p&gt;And that brings me to SilverSat.&lt;/p&gt;
    &lt;head rend="h2"&gt;SilverSat&lt;/head&gt;
    &lt;p&gt;There's another CubeSat with a Raspberry Pi onboard, and it's launching NET Sunday, at 6:11 p.m. Eastern time, aboard a Falcon 9 rocket. What does NET mean? Well, as I found out when I visited Florida this summer, that means "No Earlier Than", and in spaceflight, many things delay launches.&lt;/p&gt;
    &lt;p&gt;The students who built SilverSat are no strangers to delays‚Äîthey were originally supposed to see their CubeSat launch earlier this year, but the cargo module they were on got damaged during transport, and that delayed them for months.&lt;/p&gt;
    &lt;p&gt;I got to talk to two of the adults guiding the students on their first space launch, and I discussed the history of the project (it started up in 2017), how they are supported by NASA's CubeSat Launch Initiative, the importance of amateur radio for CubeSats, and why they chose a Raspberry Pi Zero for their onboard computer.&lt;/p&gt;
    &lt;p&gt;That interview is tucked away in the last half of the video at the top of this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tracking Satellites from your backyard&lt;/head&gt;
    &lt;p&gt;Also in that video, I spoke to Gabe from saveitforparts, and he mentioned it's not that difficult to listen in on satellites on orbit‚Äîincluding amateur CubeSats!&lt;/p&gt;
    &lt;p&gt;SilverSat will be broadcasting SSDV (Slow-Scan Digital Video) at set times, and the schedule for that should be posted on their website.&lt;/p&gt;
    &lt;p&gt;Check out the video embedded in this post (near the top), or Gabe's own channel for ideas for tracking satellites. It can be done with under $100 of equipment (usually just an SDR and a cheap antenna).&lt;/p&gt;
    &lt;head rend="h2"&gt;Infectious Enthusiasm for Learning (and Teaching)&lt;/head&gt;
    &lt;p&gt;I feel like a broken record, but one thing I love, talking to anyone in the CubeSat community is this sense of infectious enthusiasm. And I was going to cut this video out for time, but watching it back, I realized other people would probably enjoy Tim showing off some neat CubeSats in his personal collection as much as I did. So I put up some bonus content on my second channel, Level 2 Jeff; you can watch another 8 minutes of CubeSat hardware below:&lt;/p&gt;
    &lt;p&gt;Thank you to everyone who taught me about CubeSats for this video and blog post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jeffgeerling.com/blog/2025/cubesats-are-fascinating-learning-tools-space"/><published>2025-09-15T14:02:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45249915</id><title>PayPal to support Ethereum and Bitcoin</title><updated>2025-09-15T17:08:51.737541+00:00</updated><content>&lt;doc fingerprint="bc09acb02f2e3d8"&gt;
  &lt;main&gt;
    &lt;p&gt;PayPal Ushers in a New Era of Peer-to-Peer Payments, Reimagining How Money Moves to Anyone, Anywhere&lt;/p&gt;
    &lt;p&gt;Send and receive money as easily as sending a text, across apps, borders, and currencies &lt;/p&gt;
    &lt;div&gt;
      &lt;p&gt;SAN JOSE, Calif., Sept. 15, 2025 /PRNewswire/ -- On the heels of the PayPal World announcement, a global platform connecting the world's largest digital payment systems and wallets, PayPal today introduced PayPal links, a new way to send and receive money through a personalized, one-time link that can be shared in any conversation.&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt; Creating personalized payment links | Click to Enlarge&lt;/p&gt;
      &lt;p&gt;PayPal users in the U.S. can begin creating personalized payment links today, with international expansion to the UK, Italy, and other markets starting later this month. By making payments this simple and universal, PayPal links helps drive new customer acquisition and brings more users into the PayPal ecosystem.&lt;/p&gt;
      &lt;p&gt;The peer-to-peer (P2P) experience is about to go even further. Crypto will soon be directly integrated into PayPal's new P2P payment flow in the app. This will make it more convenient for PayPal users in the U.S. to send Bitcoin, Ethereum, PYUSD, and more, to PayPal, Venmo, as well a rapidly growing number of digital wallets across the world that support crypto and stablecoins.&lt;/p&gt;
      &lt;p&gt;Expanding what people can do with PayPal also comes with reassurance around how personal payments are handled. As always, friends-and-family transfers through Venmo and PayPal are exempt from 1099-K reporting. Users won't receive tax forms for gifts, reimbursements, or splitting expenses, helping ensure that personal payments stay personal.&lt;/p&gt;
      &lt;p&gt;"For 25 years, PayPal has revolutionized how money moves between people. Now, we're taking the next major step," said Diego Scotti, General Manager, Consumer Group at PayPal. "Whether you're texting, messaging, or emailing, now your money follows your conversations. Combined with PayPal World, it's an unbeatable value proposition, showing up where people connect, making it effortless to pay your friends and family, no matter where they are or what app they're using."&lt;/p&gt;
      &lt;p&gt;P2P is a cornerstone of PayPal's consumer experience, driving engagement and bringing more users into the ecosystem. P2P and other consumer total payment volume saw solid growth in the second quarter, increasing 10% year-over-year as the company focused on improving the experience and increasing user discoverability to make it easier than ever to move money globally. Plus, Venmo saw its highest TPV growth in three years. With PayPal World unlocking seamless interoperability, P2P is poised for even greater momentum in the future as PayPal and Venmo connect to billions of wallets worldwide.&lt;/p&gt;
      &lt;p&gt;How PayPal links work:&lt;/p&gt;
      &lt;list type="disc" rend="ul"&gt;
        &lt;item&gt;Create a personalized link ‚Äì Open the PayPal app, enter the details of your payment or request, and generate a unique, one-time link to share.&lt;/item&gt;
        &lt;item&gt;Always the right person ‚Äì Each link is private, one-time use, and created for a specific transaction.&lt;/item&gt;
        &lt;item&gt;Drop it anywhere ‚Äì Send your link in a text, DM, email, or chat. Add a note, emoji, or payment note.&lt;/item&gt;
        &lt;item&gt;Manage payment activity: Unclaimed links expire after 10 days. Users can send a reminder or even cancel the payment or request before the link is claimed with the PayPal app.&lt;/item&gt;
        &lt;item&gt;Tap and done ‚Äì The recipient taps the link and either completes or accepts the payment within the PayPal App with their PayPal account.&lt;/item&gt;
        &lt;item&gt;Funds are instant ‚Äì the recipient will get immediate access to their funds with a PayPal Balance account once accepted.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;About PayPal&lt;lb/&gt; PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy. For more information, visit https://www.paypal.com, https://about.pypl.com/ and https://investor.pypl.com/.&lt;/p&gt;
      &lt;p&gt;About PayPal USD (PYUSD) &lt;lb/&gt; PayPal USD is issued by Paxos Trust Company, LLC, a fully chartered limited purpose trust company. Paxos is licensed to engage in Virtual Currency Business Activity by the New York State Department of Financial Services. Reserves for PayPal USD are fully backed by U.S. dollar deposits, U.S. Treasuries and similar cash equivalents, and PayPal USD can be bought or sold through PayPal and Venmo at a rate of $1.00 per PayPal USD. &lt;lb/&gt; PayPal, Inc. (NMLS ID #: 910457) is licensed to engage in Virtual Currency Business Activity by the New York State Department of Financial Services. &lt;/p&gt;
      &lt;p&gt;Media contact&lt;lb/&gt; Gideon Anstey&lt;lb/&gt; gbanstey@paypal.com&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://newsroom.paypal-corp.com/2025-09-15-PayPal-Ushers-in-a-New-Era-of-Peer-to-Peer-Payments,-Reimagining-How-Money-Moves-to-Anyone,-Anywhere"/><published>2025-09-15T14:04:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45249985</id><title>Programming Deflation</title><updated>2025-09-15T17:08:51.608490+00:00</updated><content/><link href="https://tidyfirst.substack.com/p/programming-deflation"/><published>2025-09-15T14:11:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45250193</id><title>Show HN: Daffodil ‚Äì Open-Source Ecommerce Framework to connect to any platform</title><updated>2025-09-15T17:08:50.748564+00:00</updated><content>&lt;doc fingerprint="8b0e030d780cdf5a"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt; Daffodil is an ecommerce development framework for building high-quality storefronts that can connect to any ecommerce backend. &lt;/p&gt;
    &lt;p&gt;Wanna see what we're trying to do? Check out the demo.&lt;/p&gt;
    &lt;p&gt;From a new Angular app, simply run&lt;/p&gt;
    &lt;code&gt;npx ng add @daffodil/commerce&lt;/code&gt;
    &lt;p&gt;Get started with Daffodil, learn the fundamentals and explore advanced topics on our documentation website.&lt;/p&gt;
    &lt;p&gt;Read through our contributing guidelines to learn about our submission process, coding rules, and more.&lt;/p&gt;
    &lt;p&gt;Want to report a bug, contribute some code, or improve the documentation? Excellent! Read up on our guidelines for contributing and then check out one of our issues labeled as good first issue or good first challenge.&lt;/p&gt;
    &lt;p&gt;Please read and follow our Code of Conduct.&lt;/p&gt;
    &lt;p&gt;Join the conversation and help the community.&lt;/p&gt;
    &lt;p&gt;Below is a table of currently available Daffodil packages.&lt;/p&gt;
    &lt;p&gt;Note: About the &lt;code&gt;checkout&lt;/code&gt; package, it is currently a legacy package; there is no reason to use it. However, the &lt;code&gt;checkout&lt;/code&gt; package eventually may be filled with extracts from the &lt;code&gt;cart&lt;/code&gt; and &lt;code&gt;order&lt;/code&gt; packages.&lt;/p&gt;
    &lt;p&gt;Think Daffodil is the bees-knees? Give our repo a star ‚≠ê ‚ù§Ô∏è.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/graycoreio/daffodil"/><published>2025-09-15T14:32:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45250202</id><title>How to self-host a web font from Google Fonts</title><updated>2025-09-15T17:08:50.479923+00:00</updated><content/><link href="https://blog.velocifyer.com/Posts/3,0,0,2025-8-13,+how+to+self+host+a+font+from+google+fonts.html"/><published>2025-09-15T14:33:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45250370</id><title>Apple has a private CSS property to add Liquid Glass effects to web content</title><updated>2025-09-15T17:08:50.368619+00:00</updated><content>&lt;doc fingerprint="2e4c691d3b0b61f5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Apple has a private CSS property to add Liquid Glass effects to web content&lt;/head&gt;
    &lt;p&gt;I have an incredibly boring summer hobby: looking at the changelog for the WebKit Github repo. Why? Because I spend a chunk of my professional life working with webviews inside mobile apps and I like to get an early peek into what's coming in the next version of iOS. Since Tim Cook has yet to stand up at WWDC and announce "one more thing... Service Worker support in WKWebView, provided you add the correct entry to the &lt;code&gt;WKAppBoundDomains&lt;/code&gt; array in your &lt;code&gt;Info.plist&lt;/code&gt;" (and you know what, he should) manual research is the order of the day.&lt;/p&gt;
    &lt;p&gt;So I was really interested to see, the day after WWDC finished, a pull request named:&lt;/p&gt;
    &lt;quote&gt;[Materials] Rename "hosted blur" materials to reference "glass"&lt;/quote&gt;
    &lt;p&gt;Liquid Glass was one of the big takeaways from 2025's WWDC. Probably the biggest change in iOS UI since iOS 7 ditched the skeuomorphic look of the past. But that's all native UI, what does any of that have to do with webviews?&lt;/p&gt;
    &lt;p&gt;A poke around the context of the PR revealed something really interesting: Apple has a custom CSS property named &lt;code&gt;-apple-visual-effect&lt;/code&gt; . Not only does it allow the use of Liquid Glass in iOS 26 (via values like &lt;code&gt;-apple-system-glass-material&lt;/code&gt;) but all versions support using standard materials with values like &lt;code&gt;-apple-system-blur-material-thin&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Yes it works and no, we can't&lt;/head&gt;
    &lt;p&gt;Before you, like me, fire up Safari and start editing some CSS, I have bad news: no, it doesn't work on the web. As well it shouldn't. But it also doesn't work by default in an app using WKWebView, you have to toggle a setting in WKPreferences called &lt;code&gt;useSystemAppearance&lt;/code&gt;... and it's private. So if you use it, say goodbye to App Store approval.&lt;/p&gt;
    &lt;p&gt;I wanted to try it out all the same so I hacked around to set &lt;code&gt;useSystemAppearance&lt;/code&gt; to true, set my CSS to:&lt;/p&gt;
    &lt;code&gt;.toolbar {
  border-radius: 50%;
  -apple-visual-effect: -apple-system-glass-material;
  height: 75px;
  width: 450px;
}&lt;/code&gt;
    &lt;p&gt;lo and behold, it works!&lt;/p&gt;
    &lt;p&gt;Whoever it was at Apple that decided to make this a CSS property is a genius because it makes it incredibly easy to provide different rules based on Liquid Glass support:&lt;/p&gt;
    &lt;code&gt;.toolbar {
  border-radius: 50%;
  height: 75px;
  width: 450px;
  background: rgba(204, 204, 204, 0.7);
}

@supports (-apple-visual-effect: -apple-system-glass-material) {
  background: transparent;
  -apple-visual-effect: -apple-system-glass-material
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Who cares?&lt;/head&gt;
    &lt;p&gt;It's an interesting piece of trivia but no-one outside of Apple can use it. So what does it matter? It doesn't. Except for the implication for what I'll call &lt;del&gt;Alastair's Grand&lt;/del&gt; The Toup√©e Theory of In-App Webviews (thanks to graypegg on Hacker News for the rename). Industry wide they don't have a great reputation. But my suggestion is this: the main reason webviews in apps have such a bad reputation is because you don't notice the webviews that are integrated seamlessly.&lt;/p&gt;
    &lt;p&gt;It stands to reason that Apple wouldn't have developed this feature if they weren't using it. Where? We have no idea. But they must be using it somewhere. The fact that none of us have noticed exactly where suggests that we're interacting with webviews in our daily use of iOS without ever even realising it.&lt;/p&gt;
    &lt;p&gt;Food for thought!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alastair.is/apple-has-a-private-css-property-to-add-liquid-glass-effects-to-web-content/"/><published>2025-09-15T14:49:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45250500</id><title>Meta bypassed Apple privacy protections, claims former employee</title><updated>2025-09-15T17:08:50.216701+00:00</updated><content>&lt;doc fingerprint="3c96fb9a5c275184"&gt;
  &lt;main&gt;
    &lt;p&gt;A former Meta product manager has claimed that the social network circumvented Apple‚Äôs privacy protections, as well as cheating advertisers, and fired him when he repeatedly raised the issue internally.&lt;/p&gt;
    &lt;p&gt;Meta is said to have found ways to identify Apple users even after they refused consent for app tracking, in order to avoid an estimated $10 billion loss of revenue ‚Ä¶&lt;/p&gt;
    &lt;head rend="h2"&gt;App Tracking Transparency hit Meta hard&lt;/head&gt;
    &lt;p&gt;Meta relied heavily on selling personalized advertising, which required it to be able to target particular demographics and interest groups. This was achieved by tracking individual users across different apps.&lt;/p&gt;
    &lt;p&gt;Apple‚Äôs App Tracking Transparency (ATT) was introduced in 2021 and meant that companies required user permission in order to carry out this tracking. Unsurprisingly, the vast majority of users declined.&lt;/p&gt;
    &lt;p&gt;It was estimated at the time that this would cost social media companies many billions of dollars, and Meta‚Äôs CFO warned investors that its own loss would be around $10B per year&lt;/p&gt;
    &lt;head rend="h2"&gt;Meta accused of bypassing protections&lt;/head&gt;
    &lt;p&gt;It was quickly alleged that Meta was using workarounds to continue to track users who had denied permission, alongside other privacy violations. A class action lawsuit followed.&lt;/p&gt;
    &lt;p&gt;A fired product manager at the company, Samujjal Purkayastha, has now taken his case to an employment tribunal claiming he was unlawfully dismissed for raising concerns about the practice, reports the Financial Times.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Meta secretly linked user data with other information to track users‚Äô activity on other websites without their permission ‚Äî despite Apple in 2021 introducing measures explicitly requiring consent, according to Purkayastha‚Äôs filings [‚Ä¶]&lt;/p&gt;
      &lt;p&gt;A ‚Äúclosed and secretive‚Äù team at Meta is alleged to have used ‚Äúdeterministic matching‚Äù ‚Äî gathering identifiable information that could then be used to connect data across multiple platforms in violation of Apple‚Äôs new privacy policies.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;He also accuses Meta of inflating the value of sales achieved by advertising on its platforms.&lt;/p&gt;
    &lt;p&gt;Meta denies any wrongdoing, and claims that Purkayastha was dismissed for unrelated reasons. The tribunal was unable to rule immediately, and said a full hearing will be held later in the year.&lt;/p&gt;
    &lt;head rend="h4"&gt;Highlighted accessories&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Official Apple Store on Amazon&lt;/item&gt;
      &lt;item&gt;Anker 511 Nano Pro ultra-compact iPhone charger&lt;/item&gt;
      &lt;item&gt;Spigen MagFit case for iPhone 16e ‚Äì adds MagSafe support&lt;/item&gt;
      &lt;item&gt;Apple MagSafe Charger with 25w power for iPhone 16 models&lt;/item&gt;
      &lt;item&gt;Apple 30W charger for above&lt;/item&gt;
      &lt;item&gt;Anker 240W braided USB-C to USB-C cable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Photo by Mario Heller on Unsplash&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://9to5mac.com/2025/08/21/meta-allegedly-bypassed-apple-privacy-measure-and-fired-employee-who-flagged-it/"/><published>2025-09-15T14:59:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45250540</id><title>Creating a VGA Signal in Hubris</title><updated>2025-09-15T17:08:49.916495+00:00</updated><content>&lt;doc fingerprint="2703d5e44d260bd8"&gt;
  &lt;main&gt;
    &lt;p&gt;A while ago I got a ST Nucleo-H753ZI evaluation board because I wanted to try out Hubris, Oxide's embedded operating system. After getting the basic demo app with the blinking lights running I set it aside for a lack of an idea what to do with it. A few weeks ago I was looking through old Raspberry Pi accessories on the hunt for a project. What stuck out to me wasn't any of the Raspberry Pi stuff, but the old 4 by 3 VGA monitor I had standing around. Could I just wire those pins in the VGA cable up to the GPIOs and produce a signal? As it turns out, yes you can just do that.&lt;/p&gt;
    &lt;head rend="h1"&gt;Getting Rid of the Sys Task&lt;/head&gt;
    &lt;p&gt;In the beginning I thought I was gonna be changing the GPIO pins from normal code, so switching them on and off at very high speeds. In hubris there's a &lt;code&gt;stm32xx-sys&lt;/code&gt; task that normally controls the GPIO pins and also handles
enabling clock to the different components through the Reset and Clock Control (RCC) block.&lt;/p&gt;
    &lt;p&gt;So normally if you want to set a GPIO pin you'd send a message to the &lt;code&gt;sys&lt;/code&gt; task and it would do
that for you.
I was worried that the overhead of the context switching was gonna be a problem there.&lt;/p&gt;
    &lt;p&gt;So I decided to get rid of the sys task and do it all in my task.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Plan&lt;/head&gt;
    &lt;p&gt;My first plan was to get the screen to just display a single color. I thought that it would be enough to get the vsync and hsync signals right and then just have the green pin high all the time to get a green picture.&lt;/p&gt;
    &lt;head rend="h1"&gt;Mapping the Registers&lt;/head&gt;
    &lt;p&gt;The peripherals of our chip are all controlled with registers. Those are memory mapped and to certain addresses. There is a gigantic 3000 page reference manual that describes all those registers. It's all very overwhelming. Luckily there's a Peripheral Access Crate (PAC) that defines an API for reading and writing those registers.&lt;/p&gt;
    &lt;p&gt;Since we're running under memory protection we need to first make sure we can actually write to those registers. In Hubris that sort of thing happens in an &lt;code&gt;app.toml&lt;/code&gt; where all the tasks for an app are defined.&lt;/p&gt;
    &lt;code&gt;[tasks.vga]
name = "drv-vga"
priority = 1
uses = ["rcc", "gpios", "tim3"]
start = true
&lt;/code&gt;
    &lt;p&gt;In this case the &lt;code&gt;tim3&lt;/code&gt; memory region wasn't a thing the Hubris build system knew about yet.
The regions you can &lt;code&gt;use&lt;/code&gt; there are defined in a &lt;code&gt;chip.toml&lt;/code&gt; for the specific chip you have.
In our case that's &lt;code&gt;chips/stm32h7/chip.toml&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;[tim3]
address = 0x40000400
size = 0x400
&lt;/code&gt;
    &lt;p&gt;You get those values from a fun table called "Register boundary addresses" from the manual.&lt;/p&gt;
    &lt;head rend="h1"&gt;Blinking an LED with a Timer / PWM&lt;/head&gt;
    &lt;p&gt;The timers on this chip have a Pulse-Width-Modulation (PWM) feature which we should be able to use to generate the VGA sync signals. But the first step was to get a light blinking using PWM. The basic Hubris demo app does have a blinking LED, but that's not using PWM. Instead it uses the timer feature of the kernel, which makes a lot of sense for a Hubris demo, but we want to involve the CPU as minimally as possible for generating the signal.&lt;/p&gt;
    &lt;p&gt;My initial plan was to measure the PWM with my multimeter to see it working. I chose PB0 for this from the pinout table in the user manual of the board (which is different from the reference manual of the chip). PB0 is hooked up to timer 3, channel 3 (TIM3_CH3). Looking at the "Solder bridges and jumpers" section I found out that that's also connected to an LED on the board by default, so I chose to just test it that way.&lt;/p&gt;
    &lt;p&gt;By default here means that there's a bunch of predefined places on the bottom of the board where you can make connections by adding a bit of solder or remove connections by cutting traces or removing zero ohm resistors.&lt;/p&gt;
    &lt;p&gt;So after a whole bunch of fiddling I got all the registers set up right to get the LED blinking.&lt;/p&gt;
    &lt;head rend="h1"&gt;Setting up the H-Sync and V-Sync Timers&lt;/head&gt;
    &lt;p&gt;The first thing I sort of used for some guidance was this site where someone had done a similar project: https://www.programmerall.com/article/26476558/ That was pretty useful for the wiring itself and a basic understanding of how the signal works.&lt;/p&gt;
    &lt;p&gt;The basic idea is that there's three pins for red, green and blue and two pins for horizontal and vertical sync. The horizontal sync signal needs to be on for a bit between each line of pixels and the vertical one between frames. You can connect any of the color that you don't need to display to ground.&lt;/p&gt;
    &lt;p&gt;To connect the end of the cable to the GPIO headers on the board I ended up using some jumper wires and a breadboard. (The breadboard is just for all the things connected to ground.)&lt;/p&gt;
    &lt;p&gt;I could take off black plastic cover on the end of the jumper wires and clip off the pointy end. That left a sort of hollow bit that I could wrap some electrical tape around and stick onto the pins of the VGA cable. The connection is a bit loose, but it makes contact.&lt;/p&gt;
    &lt;p&gt;Before that I had tried soldering and that was a horrible idea because I don't have enough hands to hold the soldering iron, the solder and the jumper.&lt;/p&gt;
    &lt;p&gt;Then there's this site which has timing information for all the different resolutions: http://www.tinyvga.com/vga-timing&lt;/p&gt;
    &lt;p&gt;At first I chose 640√ó480 because I wanted a minimal pixel count. I got that sort of working to the point where the monitor would recognize a signal, but it would need a bit of time to auto-adjust.&lt;/p&gt;
    &lt;p&gt;I then decided I'd switch to 800√ó600 like they did in the link above, because those numbers add up much nicer: http://www.tinyvga.com/vga-timing/800x600@60Hz&lt;/p&gt;
    &lt;p&gt;Each timer has a prescaler that can be used to divide the base clock, which is 200 Mhz in our case. The timer will then count up until it reaches the value in the auto-reload register (ARR). Then there's also the capture/compare register (CCR), which determines for which part of the cycle the output is on when doing pulse-width modulation.&lt;/p&gt;
    &lt;p&gt;For hsync I set the prescaler to zero, meaning the frequency is divided by one, because that register is offset by one. Then I set the ARR to 5279 (also offset by one) and the CCR to 640 (not offset by one). That means the timer counts up 200 times per microsecond. 5280 / 200 gives us the 26.4 ¬µs that we need for one line and 640 / 200 gives us the 3.2 ¬µs for the sync pulse.&lt;/p&gt;
    &lt;p&gt;For vsync I set the prescaler to 21119. 21120 / 200 gives us 105.6 ¬µs, which is the width our sync pulse should be. So then we can set the CCR to 1. The ARR is set to 156 to give us 105.6 ¬µs * 157 = 16.5792 ms, which is exactly the time a whole frame should take.&lt;/p&gt;
    &lt;head rend="h1"&gt;All Green all the Time Not Working&lt;/head&gt;
    &lt;p&gt;My hope was that I could get to a fully green picture pretty easily by just hooking up the green pin to a GPIO pin that was on. That ended up not working, I suspect because the monitor uses the voltage that's on the color pins during the h-sync as a baseline or something like that.&lt;/p&gt;
    &lt;head rend="h1"&gt;DMA to the DAC&lt;/head&gt;
    &lt;p&gt;The next plan was to continuously repeat a single line. I decided to try to use the Digital-to-analog converter (DAC) for this.&lt;/p&gt;
    &lt;p&gt;The basic way the DAC works is that you first need to set a GPIO pin that's hooked up to the DAC into an analog mode. This isn't one of the altenate functions like you'd use for the timer, but a whole separate mode. Then there's a data holding register you can write an 8 or 12 bit value into. That will determine the output voltage you get on the pin.&lt;/p&gt;
    &lt;p&gt;Now, we don't want to keep the CPU fully occupied with constantly setting that register, so we need a better solution. Luckily the h7 has dedicated units for copying memory around. There's actually at least four different kinds of these, but we'll start with a "normal" direct memory access controller (DMA). There's two of those, but well use DMA1.&lt;/p&gt;
    &lt;p&gt;When I wanted to map the DAC control registers into my task I got a build error. As it turns out, the memory protection unit only supports eight memory regions at a time, meaning per-task in Hubris. I resolved that by grouping some timers together. They also need to have a power-of-two size and be aligned to their size, which would lead to problems later when I tried to group more things together, but it worked out for the timers.&lt;/p&gt;
    &lt;p&gt;What I ended up doing here is to hooking up the timer to the DAC and configuring the DMA request multiplexer (DMAMUX) to be triggered by the DAC. Then I set up the DAC in circular mode with a pointer to a buffer.&lt;/p&gt;
    &lt;p&gt;Eventually I got it looking like that (with a lot of flickering of course):&lt;/p&gt;
    &lt;p&gt;Now that wasn't looking very much like the data that I wanted to DMA into DAC. It was also changing quite a bit based on what exactly the code around it did (like adding something do a debugging ringbuffer). It appears that the DMA unit doesn't go through the CPU caches, so likely this was some random data.&lt;/p&gt;
    &lt;p&gt;After some digging I found out that there's different kinds of memory on this chip that are configured differently in Hubris. You can see that configuration in chips/stm32h7/memory-large.toml. Among others there's a &lt;code&gt;dma&lt;/code&gt; flag that can be set for a region.
I'm not sure what that does exacly (it looks like one thing is that the kernel will refuse to copy
from or to there), but putting my buffer there using the link_section
attribute seems to make our DMA work.&lt;/p&gt;
    &lt;p&gt;After I got that to work all that was left was a lot of confusion because I had gotten the math for the pixel timing wrong. But after I had figured that out I was able to produce a nice gradient.&lt;/p&gt;
    &lt;p&gt;(If you're confused about the color: I had switched to blue instead of green at some point.)&lt;/p&gt;
    &lt;p&gt;Switching between on and off pixels leads to a pattern like this:&lt;/p&gt;
    &lt;p&gt;The DAC seems unable to produce sharp edges and also the average output seems to get higher after switching on and off a couple of times.&lt;/p&gt;
    &lt;p&gt;Here they used the SPI hardware support to produce an image, so maybe I should try that next as well.&lt;/p&gt;
    &lt;head rend="h1"&gt;Return of the Sys Task&lt;/head&gt;
    &lt;p&gt;The next thing I wanted to do of course was to produce an actual 2 dimensional image. So far the CPU hadn't been involved after setting up the registers. The DMA would keep going even if the CPU was halted.&lt;/p&gt;
    &lt;p&gt;This starts to become a problem for a 2D image though. If we were to keep our circular mode buffer and wanted to store a whole image in it we'd need a bunch of bytes for that. While we can horizontally repeat the same pixel 8 times (by decreasing the timer frequency), we can't do that vertically. So we'd need 132 (1056 / 8) √ó 628 = 82896 bytes for that buffer.&lt;/p&gt;
    &lt;p&gt;That would fit into one of the sram regions, but it's a bit of an inconvenient format for a framebuffer with vertical pixels being 8 times smaller than horizontal ones.&lt;/p&gt;
    &lt;p&gt;Luckily there's the master direct memory access controller (MDMA), which can be triggered by the completion of other DMA controllers and supports much more complex configuration.&lt;/p&gt;
    &lt;p&gt;But at this point I was definitely out of regions that could be mapped to my task. Since it was very clear at this point that we weren't goint to do high speed GPIO toggling on the CPU we could actually re-introduce the &lt;code&gt;sys&lt;/code&gt; task.
This means that we could get rid of two regions from our task (RCC and GPIO) and we'd have space for the MDMA control registers.
It's kind of funny how this hardware limitation can encourage splitting things into different tasks.&lt;/p&gt;
    &lt;p&gt;I was able to get the MDMA copying into the DMA buffer, but I haven't quite been able to get a framebuffer working yet. So this is the end of this post. I hope I'll find some more time for this project soon and I'll try to make another post if I get something more interesting going. I already have some ideas about what to do with a working framebuffer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lasernoises.com/blog/hubris-vga/"/><published>2025-09-15T15:04:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45250720</id><title>Launch HN: Trigger.dev (YC W23) ‚Äì Open-source platform to build reliable AI apps</title><updated>2025-09-15T17:08:49.733101+00:00</updated><content>&lt;doc fingerprint="bf77954a6d078e42"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, I‚Äôm Eric, CTO at Trigger.dev (&lt;/p&gt;https://trigger.dev&lt;p&gt;). We‚Äôre a developer platform for building and running AI agents and workflows, open-source under the Apache 2.0 license (&lt;/p&gt;https://github.com/triggerdotdev/trigger.dev&lt;p&gt;).&lt;/p&gt;&lt;p&gt;We provide everything needed to create production-grade agents in your codebase and deploy, run, monitor, and debug them. You can use just our primitives or combine with tools like Mastra, LangChain and Vercel AI SDK. You can self-host or use our cloud, where we take care of scaling for you. Here‚Äôs a quick demo: (https://youtu.be/kFCzKE89LD8).&lt;/p&gt;&lt;p&gt;We started in 2023 as a way to reliably run async background jobs/workflows in TypeScript (https://news.ycombinator.com/item?id=34610686). Initially we didn‚Äôt deploy your code, we just orchestrated it. But we found that most developers struggled to write reliable code with implicit determinism, found breaking their work into small ‚Äústeps‚Äù tricky, and they wanted to install any system packages they needed. Serverless timeouts made this even more painful.&lt;/p&gt;&lt;p&gt;We also wanted to allow you to wait for things to happen: on external events, other tasks finishing, or just time passing. Those waits can take minutes, hours, or forever in the case of events, so you can‚Äôt just keep a server running.&lt;/p&gt;&lt;p&gt;The solution was to build and operate our own serverless cloud infrastructure. The key breakthrough that enabled this was realizing we could snapshot the CPU and memory state. This allowed us to pause running code, store the snapshot, then restore it later on a different physical server. We currently use Checkpoint Restore In Userspace (CRIU) which Google has been using at scale inside Borg since 2018.&lt;/p&gt;&lt;p&gt;Since then, our adoption has really taken off especially because of AI agents/workflows. This has opened up a ton of new use cases like compute-heavy tasks such as generating videos using AI (Icon.com), real-time computer use (Scrapybara), AI enrichment pipelines (Pallet, Centralize), and vibe coding tools (Hero UI, Magic Patterns, Capy.ai).&lt;/p&gt;&lt;p&gt;You can get started with Trigger.dev cloud (https://cloud.trigger.dev), self-hosting (https://trigger.dev/docs/self-hosting/overview), or read the docs (https://trigger.dev/docs).&lt;/p&gt;&lt;p&gt;Here‚Äôs a sneak peek at some upcoming changes: 1) warm starts for self-hosting 2) switching to MicroVMs for execution ‚Äì this will be open source, self-hostable, and will include checkpoint/restoring.&lt;/p&gt;&lt;p&gt;We‚Äôre excited to be sharing this with HN and are open to all feedback!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45250720"/><published>2025-09-15T15:20:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45251093</id><title>Boring Work Needs Tension</title><updated>2025-09-15T17:08:49.537079+00:00</updated><content>&lt;doc fingerprint="89b89d7ba9f84476"&gt;
  &lt;main&gt;
    &lt;p&gt;We are all moved by great movies, cinematography, and stories. Watching them is fun because you can imagine yourself resonating with a character. You are thrilled by the tension the story creates and curious how it will be resolved.&lt;/p&gt;
    &lt;p&gt;Many find software development a dull job where you have to write exactly what your PM or client asks for. It‚Äôs exciting at first, but it can become boring after a few iterations.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Whatever doesn‚Äôt excite you, change it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When we, as developers, push ourselves to be protagonists, we discover many problems to solve ‚Äî a lot of tension to resolve. Here are a few good problems for everyday devs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your CI/CD takes a huge amount of time because you forgot to leverage caching.&lt;/item&gt;
      &lt;item&gt;You forgot to add connection pooling and your service bombarded the database, causing too many open connections.&lt;/item&gt;
      &lt;item&gt;You misconfigured the garbage collector and now you have a memory leak that keeps growing.&lt;/item&gt;
      &lt;item&gt;If it takes you more than 3 seconds to understand what you wrote last week, it‚Äôs poorly written.&lt;/item&gt;
      &lt;item&gt;Latency is high for your users in Mumbai because your servers are in Singapore.&lt;/item&gt;
      &lt;item&gt;The database becomes very slow when you start dumping data in batches.&lt;/item&gt;
      &lt;item&gt;You want consistent API responses for read operations for users in both Mumbai and Singapore.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are not trivial problems; they happen every day. These are our villains ‚Äî irritating, unwanted, and surprising. We should eliminate them.&lt;/p&gt;
    &lt;p&gt;Pick your fight. This is one way to make your day exciting. If you can‚Äôt tackle these at work, do it in your personal projects.&lt;/p&gt;
    &lt;p&gt;If you chase the right tension, a story will follow.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://iaziz786.com/blog/boring-work-needs-tension/"/><published>2025-09-15T15:44:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45251178</id><title>A string formatting library in 65 lines of C++</title><updated>2025-09-15T17:08:48.214904+00:00</updated><content>&lt;doc fingerprint="22522655ec0d5698"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A string formatting library in 65 lines of C++&lt;/head&gt;
    &lt;p&gt;In this write-up, I will walk you through an implementation of a string formatting library for C++ I came up with for my video game. The end result came out really compact, at only 65 lines of code√¢providing a skeleton that can be supplemented with additional functionality at low cost.&lt;/p&gt;
    &lt;head rend="h2"&gt;Usage&lt;/head&gt;
    &lt;p&gt;Given a format buffer√¢¬¶&lt;/p&gt;
    &lt;code&gt;char buffer[64];
String_Buffer buf = {str, sizeof str};
&lt;/code&gt;
    &lt;p&gt;√¢¬¶the &lt;code&gt;fmt::format&lt;/code&gt; function provided by this library can be called with a format string parameter, containing the character sequence &lt;code&gt;{}&lt;/code&gt; (a hole) where parameters are to be substituted, as well as the parameters themselves.&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "Hello, {}!", "world");
assert(strcmp(str, "Hello, world!") == 0);
&lt;/code&gt;
    &lt;p&gt;When a literal &lt;code&gt;{{&lt;/code&gt; is needed, the &lt;code&gt;{&lt;/code&gt; must be doubled√¢even when format arguments are not present.&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "Hello, {{}!");
assert(strcmp(str, "Hello, {}!") == 0);
&lt;/code&gt;
    &lt;p&gt;Further, when a format argument is not present, no undefined behaviour occurs√¢the hole is rendered as the empty string.&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "empty {} hole");
assert(strcmp(str, "empty  hole") == 0);
&lt;/code&gt;
    &lt;p&gt;Multiple format arguments can be specified as well.&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "[{}] [{}] {}", "main", "info", "Hewwo :3");
assert(strcmp(str, "[main] [info] Hewwo :3") == 0);
&lt;/code&gt;
    &lt;p&gt;In case the buffer is not sufficiently large to contain the full string, the function writes as many characters as it can, and sets the &lt;code&gt;String_Buffer&lt;/code&gt;√¢s &lt;code&gt;len&lt;/code&gt; variable to the amount of characters required.
That way, it is possible for the caller to tell if the buffer has been exhausted, and reallocate it to an appropriate size.&lt;/p&gt;
    &lt;code&gt;fmt::format(
	buf,
	"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"
	"aaaaaaaaaaaaaaaaaa{} {}",
	"Vector", "Amber"
);
assert(strcmp(
	str,
	"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"
	"aaaaaaaaaaaaaaaaaaV"
) == 0);
assert(buf.len == 74);
&lt;/code&gt;
    &lt;p&gt;Additional functions can be written on top of this base functionality to improve ergonomics in real-world code. These are included in Ergonomic functions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problem statement&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;A string formatting library consists of a single function&lt;/p&gt;&lt;code&gt;format&lt;/code&gt;. You give the function a format string, which describes the output shape, as well as a set of format parameters, which the function then substitutes into the format string, rendering them in a human-readable way.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;format&lt;/code&gt;function ought to write to a pre-allocated buffer of characters.&lt;p&gt;This is a choice made in favour of simplicity: writing to a pre-allocated buffer can fail, but compared to arbitrary I/O, there is only one failure mode: the buffer is exhausted.&lt;/p&gt;&lt;p&gt;Naturally, this cannot work in memory-constrained environments, such as embedded devices√¢where you would want to write to a small buffer and flush it in a loop to reduce memory usage√¢but this does not apply in the context of a desktop video game.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;As already mentioned in the usage overview, if the buffer is full, the function should return the number of characters that would have been written, had the buffer capacity not been exceeded√¢such that the caller can choose to reallocate the backing buffer to an appropriate size, and try formatting again.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;There has to be a format string.&lt;/p&gt;&lt;p&gt;An example of a format string-less API is C++√¢s&lt;/p&gt;&lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt;. Instead of having a format string like&lt;code&gt;printf&lt;/code&gt;,&lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt;opts to use overloads of&lt;code&gt;operator&amp;lt;&amp;lt;&lt;/code&gt;to write to the output. This has the disadvantage of not being greppable (which is useful for debugging error logs), as well as not being localisable (because there is no format string that could be replaced at runtime).&lt;p&gt;Additionally, I don√¢t want the format string to have extra specifiers such as C√¢s&lt;/p&gt;&lt;code&gt;%d&lt;/code&gt;,&lt;code&gt;%x&lt;/code&gt;, etc. specifying the type of output, or Python√¢s&lt;code&gt;{:.3}&lt;/code&gt;, for specifying the style of output. The C approach is error-prone and inextensible, and the Python approach, while convenient, increases parser complexity and reduces greppability. Instead, the representation is defined only according to the formatted value√¢s type.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;It has to have a small footprint.&lt;/p&gt;&lt;p&gt;There exist plenty of string formatting libraries for C++, such as {fmt}, or even the recently introduced&lt;/p&gt;&lt;code&gt;std::print&lt;/code&gt;, but they suffer from gigantic compile-time complexity through their heavy use of template metaprogramming.&lt;p&gt;While my compilation time benchmark results for {fmt} weren√¢t as dire as those presented in their README, they still don√¢t paint a pretty picture√¢with a simple program using&lt;/p&gt;&lt;code&gt;printf&lt;/code&gt;taking ~35 ms to compile, and the equivalent program using {fmt} taking ~200 ms.&lt;p&gt;I also find the benefits of an open rather than closed API, as well as compile-time checked format strings, dubious. Instead, I want something lean and small, using basic features of the language, and easy enough to drop into your own project, then extend and modify according to your needs√¢in spirit of rxi√¢s simple serialisation system.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Simply using&lt;/p&gt;&lt;code&gt;printf&lt;/code&gt;is not good enough.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Implementation walkthrough&lt;/head&gt;
    &lt;p&gt;We will start by defining the &lt;code&gt;String_Buffer&lt;/code&gt; type, which also serves as the formatter√¢s state.
It represents a user-provided string buffer with a capacity and a length.&lt;/p&gt;
    &lt;code&gt;struct String_Buffer
{
	char* str;
	int cap;
	int len = 0;
};
&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;String_Buffer&lt;/code&gt; is intended to be initialised via aggregate initialisation (&lt;code&gt;{str, cap}&lt;/code&gt;.)
This mimics the &lt;code&gt;snprintf&lt;/code&gt; API, which accepts its buffer and size arguments in the same order.&lt;/p&gt;
    &lt;p&gt;At the core of the library√¢s output is &lt;code&gt;write&lt;/code&gt;.
It performs a bounds-checked write of a string with known length to the output string buffer.&lt;/p&gt;
    &lt;code&gt;void write(String_Buffer&amp;amp; buf, const char* str, int len)
{
	int remaining_cap = buf.cap - buf.len - 1; // leave one byte for NUL
	int write_len = len &amp;gt; remaining_cap ? remaining_cap : len;
	if (write_len &amp;gt; 0)
		memcpy(buf.str + buf.len, str, write_len);
	buf.len += len;
}
&lt;/code&gt;
    &lt;p&gt;My implementation truncates the output if the buffer size is exhausted, but keeps incrementing the buffer√¢s &lt;code&gt;len&lt;/code&gt; past &lt;code&gt;cap&lt;/code&gt;, such that the caller can know the full number of characters written after all &lt;code&gt;write&lt;/code&gt;s, and adjust accordingly.
This is a deliberate choice coming from the fact that &lt;code&gt;String_Buffer&lt;/code&gt; does not own the buffer√¢s allocation, and the fact that string formatting is a performance-sensitive piece of code, which will be called often in the game loop.&lt;/p&gt;
    &lt;p&gt;However, it is trivial to replace the length saturation logic with a call to &lt;code&gt;realloc&lt;/code&gt;, should that be the more appropriate choice.&lt;/p&gt;
    &lt;p&gt;Having this base &lt;code&gt;write&lt;/code&gt; function, we can implement a set of overloaded functions that will write out values of various types to the string buffer.
These functions will be used by our &lt;code&gt;format&lt;/code&gt; function, to write out format arguments.&lt;/p&gt;
    &lt;p&gt;The set of functions implemented here directly corresponds to the types of arguments you√¢ll be able to pass into &lt;code&gt;format&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;void write_value(String_Buffer&amp;amp; buf, const char* value)
{
    write(buf, value, strlen(value));
}

void write_value(String_Buffer&amp;amp; buf, bool value) { /* ... */ }
void write_value(String_Buffer&amp;amp; buf, char value) { /* ... */ }
void write_value(String_Buffer&amp;amp; buf, int value) { /* ... */ }
&lt;/code&gt;
    &lt;p&gt;See &lt;code&gt;write_value&lt;/code&gt; for various types for a set of example implementations for other types.&lt;/p&gt;
    &lt;p&gt;Now onto parsing format strings.&lt;/p&gt;
    &lt;p&gt;Format strings can be defined as a sequence of literals interspersed with arguments. That is, a format string always takes the form:&lt;/p&gt;
    &lt;code&gt;fstr = { literal, hole }, literal;
&lt;/code&gt;
    &lt;p&gt;The leading and trailing &lt;code&gt;literal&lt;/code&gt; can be the empty string.&lt;/p&gt;
    &lt;p&gt;The task of processing the literal parts is done by a function called &lt;code&gt;next_hole&lt;/code&gt;.
It parses the format string, looking for a character sequence representing a hole &lt;code&gt;{}&lt;/code&gt;, and writes the string preceding the hole &lt;code&gt;{}&lt;/code&gt; to the output buffer.&lt;/p&gt;
    &lt;code&gt;bool next_hole(String_Buffer&amp;amp; buf, const char*&amp;amp; fstr)
{
	const char* prefix = fstr;
	while (*fstr != 0) {
		if (*fstr == '{') {
			int len = fstr - prefix;
			++fstr;
			if (*fstr == '}') {
				++fstr;
				write(buf, prefix, len);
				return true;
			}
			if (*fstr == '{') {
				write(buf, prefix, len);
				prefix = fstr;
				++fstr;
			}
		}
		++fstr;
	}
	write(buf, prefix, fstr - prefix);
	return false;
}
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;fstr&lt;/code&gt; is received as a reference to a pointer, representing the format string√¢s parsing state.&lt;/p&gt;
    &lt;p&gt;A call to &lt;code&gt;next_hole&lt;/code&gt; will write out the literal part, visualised with &lt;code&gt;---&lt;/code&gt;, and leave the &lt;code&gt;fstr&lt;/code&gt; pointer past the hole &lt;code&gt;{}&lt;/code&gt;, visualised with &lt;code&gt;^&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;Hello, {}!
-------  ^
&lt;/code&gt;
    &lt;p&gt;In this case, it will return &lt;code&gt;true&lt;/code&gt; to signal that it stopped at a hole.&lt;lb/&gt; In case there is no hole however, and the end of the string is reached, it will return &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;Hello, {}!
         -^ end of string
&lt;/code&gt;
    &lt;p&gt;Additionally, we handle the &lt;code&gt;{{&lt;/code&gt; escaping case.
when &lt;code&gt;{&lt;/code&gt; is encountered directly after another &lt;code&gt;{&lt;/code&gt;, we have to flush the current literal, and start a new one directly after the first &lt;code&gt;{&lt;/code&gt;. Underlined with &lt;code&gt;---&lt;/code&gt; are the spans of characters that get written to the output.&lt;/p&gt;
    &lt;code&gt;empty {{} hole
------- ------
&lt;/code&gt;
    &lt;p&gt;Finally, we define &lt;code&gt;format&lt;/code&gt;: the function that accepts a format string, a set of arguments, and inserts them into the output string.
It makes use of an additional function &lt;code&gt;format_value&lt;/code&gt;, which tries to find the next hole, and if found, writes out a format argument in its place.&lt;/p&gt;
    &lt;code&gt;template&amp;lt;typename T&amp;gt;
void format_value(String_Buffer&amp;amp; buf, const char* fstr, const T&amp;amp; value)
{
	if (next_hole(buf, fstr))
		write_value(buf, value);
}

template&amp;lt;typename... Args&amp;gt;
void format(String_Buffer&amp;amp; buf, const char* fstr, const Args&amp;amp;... args)
{
	(format_value(buf, fstr, args), ...);
	while (next_hole(buf, fstr)) {}
}
&lt;/code&gt;
    &lt;p&gt;For those unfamiliar with C++ template metaprogramming, &lt;code&gt;(format_value(buf, fstr, args), ...)&lt;/code&gt; is a fold expression.
Given any number of &lt;code&gt;args&lt;/code&gt;, it will expand into a sequence of calls to &lt;code&gt;format_value&lt;/code&gt;, one for each element in &lt;code&gt;args&lt;/code&gt;, separated by the &lt;code&gt;,&lt;/code&gt; operator. For example, if two arguments: a &lt;code&gt;const char*&lt;/code&gt; and an &lt;code&gt;int&lt;/code&gt;, are passed into &lt;code&gt;format&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;template&amp;lt;&amp;gt;
void format&amp;lt;const char*, int&amp;gt;(
	String_Buffer&amp;amp; buf,
	const char* fstr,
	const char* a1, int a2)
{
	(format_value(buf, fstr, a1), format_value(buf, fstr, a2));
	while (next_hole(buf, fstr)) {}
}
&lt;/code&gt;
    &lt;p&gt;Note that the overloads of &lt;code&gt;write_value&lt;/code&gt; must be declared before &lt;code&gt;format_value&lt;/code&gt;.
This is because the &lt;code&gt;write_value&lt;/code&gt; name is not dependent on any template arguments, and is therefore early-bound at &lt;code&gt;format_value&lt;/code&gt;√¢s definition site.&lt;/p&gt;
    &lt;p&gt;This choice was made for the sake of simplicity, but if it turns out to be a problem, it is possible to use specialisation. It is important to note though that specialisation bypasses overload resolution, so this will not work:&lt;/p&gt;
    &lt;code&gt;template&amp;lt;typename T&amp;gt;
void write_value(String_Buffer&amp;amp; buf, T value) = delete;

template&amp;lt;&amp;gt;
void write_value&amp;lt;const char*&amp;gt;(
	String_Buffer&amp;amp; buf, const char* value)
{
	if (next_hole(buf, fstr))
		write(buf, value, strlen(value));
}

template&amp;lt;typename T&amp;gt;
void format_value(String_Buffer&amp;amp; buf, const char*&amp;amp; fstr, const T&amp;amp; value)
{
	if (next_hole(buf, fstr))
		write_value&amp;lt;T&amp;gt;(buf, value);
}

template&amp;lt;typename... Args&amp;gt;
void format(String_Buffer&amp;amp; buf, const char* fstr, const Args&amp;amp;... args)
{
	(format_value(buf, fstr, args), ...);
	while (next_hole(buf, fstr)) {}
}

format(buf, "Hello, {}!", "world");
&lt;/code&gt;
    &lt;p&gt;because the type of &lt;code&gt;"world"&lt;/code&gt; is &lt;code&gt;char [5]&lt;/code&gt;, and not &lt;code&gt;const char*&lt;/code&gt;, and &lt;code&gt;write_value&amp;lt;char [5]&amp;gt;&lt;/code&gt; is deleted.
This should be solvable with some additional work, but I√¢ve deemed it unnecessary in my case.&lt;/p&gt;
    &lt;p&gt;In a single .cpp file, together with wrapping all the functionality in a namespace, this implementation, together with the implementation of &lt;code&gt;write_value&lt;/code&gt; for strings, equates to a mere 65 lines of code.&lt;/p&gt;
    &lt;p&gt;In a real project, you will probably want to move some of the private implementation details to a separate .cpp file. Here√¢s the full source code listing, split into a header file, and an implementation file.&lt;/p&gt;
    &lt;code&gt;#pragma once

struct String_Buffer
{
	char* str;
	int cap;
	int len = 0;
};

namespace fmt {

void write_value(String_Buffer&amp;amp; buf, const char* value);
// (additional overloads here)

// implementation detail
bool next_hole(String_Buffer&amp;amp; buf, const char*&amp;amp; fstr);

template&amp;lt;typename T&amp;gt;
void format_value(String_Buffer&amp;amp; buf, const char*&amp;amp; fstr, const T&amp;amp; value)
{
	if (next_hole(buf, fstr))
		write_value(buf, value);
}

template&amp;lt;typename... Args&amp;gt;
void format(String_Buffer&amp;amp; buf, const char* fstr, const Args&amp;amp;... args)
{
	(format_value(buf, fstr, args), ...);
	while (next_hole(buf, fstr)) {}
}

}
&lt;/code&gt;
    &lt;code&gt;#include "format.hpp"

#include &amp;lt;cstring&amp;gt;

namespace fmt
{

static void write(String_Buffer&amp;amp; buf, const char* str, int len)
{
	int remaining_cap = buf.cap - buf.len - 1; // leave one byte for NUL
	int write_len = len &amp;gt; remaining_cap ? remaining_cap : len;
	if (write_len &amp;gt; 0)
		memcpy(buf.str + buf.len, str, write_len);
	buf.len += len;
}

void write_value(String_Buffer&amp;amp; buf, const char*&amp;amp; fstr, const char* value)
{
	write(buf, value, strlen(value));
}

bool next_hole(String_Buffer&amp;amp; buf, const char*&amp;amp; fstr)
{
	const char* prefix = fstr;
	while (*fstr != 0) {
		if (*fstr == '{') {
			int len = fstr - prefix;
			++fstr;
			if (*fstr == '}') {
				++fstr;
				write(buf, prefix, len);
				return true;
			}
			if (*fstr == '{') {
				write(buf, prefix, len);
				prefix = fstr;
				++fstr;
			}
		}
		++fstr;
	}
	write(buf, prefix, fstr - prefix);
	return false;
}

}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Design remarks&lt;/head&gt;
    &lt;head rend="h3"&gt;Escaping ambiguity&lt;/head&gt;
    &lt;p&gt;The choice of &lt;code&gt;{}&lt;/code&gt; as the hole syntax is not accidental.
I evaluated whether holes could be represented with a single character &lt;code&gt;%&lt;/code&gt;, like:&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "Hello, %!", "world");
&lt;/code&gt;
    &lt;p&gt;But it turned that using only a single character introduces an ambiguity around escaping. What should this format to: &lt;code&gt;hello%&lt;/code&gt;, or &lt;code&gt;%hello&lt;/code&gt;?&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "%%%", "hello");
&lt;/code&gt;
    &lt;p&gt;It would be possible to use a different, unambiguous combination for escaping, such as &lt;code&gt;%_&lt;/code&gt;, but it looks very alien, and you have to use it any time you want a &lt;code&gt;%&lt;/code&gt; sign.&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "%%_ complete", 33);
&lt;/code&gt;
    &lt;p&gt;Compare this to the current approach, where you only have to double the &lt;code&gt;{&lt;/code&gt; when it√¢s directly preceding &lt;code&gt;}&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;fmt::format(buf, "{}% complete", 33);
&lt;/code&gt;
    &lt;p&gt;It also more closely mimics the final output string. Reading the previous &lt;code&gt;%%_&lt;/code&gt; example requires knowing that &lt;code&gt;%_&lt;/code&gt; is a special sequence that turns into &lt;code&gt;%&lt;/code&gt;, whereas reading this example doesn√¢t require any extra knowledge (and progress reporting with percentages is a somewhat common use case for format strings).&lt;/p&gt;
    &lt;head rend="h3"&gt;Iteration through parameter packs&lt;/head&gt;
    &lt;p&gt;Another idea I had was to do an &lt;code&gt;&amp;lt;iostream&amp;gt;&lt;/code&gt;-style API, though done with a function call rather than an operator chain:&lt;/p&gt;
    &lt;code&gt;format(buf, "Hello, ", "world!");
&lt;/code&gt;
    &lt;p&gt;The observation about poor greppability didn√¢t occur to me until later, but it seemed simple enough to implement.&lt;/p&gt;
    &lt;code&gt;void format_value(String_Buffer&amp;amp; buf, const char* value);
void format_value(String_Buffer&amp;amp; buf, int value);

template&amp;lt;typename... Args&amp;gt;
void format(String_Buffer&amp;amp; buf, const Args&amp;amp;... args)
{
	(format_value(buf, args), ...);
}
&lt;/code&gt;
    &lt;p&gt;If I went with this approach, it would be even less code, but the poor greppability and non-localisability of format strings kept bugging me, so I stared wondering if there√¢s some way to add that format string.&lt;/p&gt;
    &lt;p&gt;It seemed impossible, because the format string can be provided at runtime. This would mean &lt;code&gt;format&lt;/code&gt; would have to iterate through the format string to parse out the holes &lt;code&gt;{}&lt;/code&gt;, and when a hole is hit, insert the Nth parameter, starting with 0 for the first hole, N for the last hole.
But it seemed to require indexing the parameter pack, and&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;there is no way to index a parameter pack in C++20,&lt;/item&gt;
      &lt;item&gt; there is no way to index it using a runtime value in C++26, which adds parameter pack indexing &lt;code&gt;pack...[x]&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A few hours later, I realised it is possible to have the parameter pack expansion drive the parsing, rather than driving the parsing from &lt;code&gt;format&lt;/code&gt; and trying to index the parameter pack.&lt;/p&gt;
    &lt;p&gt;I think this is single-handedly the most elegant bit of this library.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; It generates optimal, extremely minimal code: a sequence of calls to the appropriate overloads of &lt;code&gt;format_value&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;It handles out-of-bounds gracefully: because there is no indexing of parameters, and therefore no out-of-bounds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It makes me wonder what other cool things could be done with this technique.&lt;/p&gt;
    &lt;head rend="h3"&gt;Failed idea: using dynamic typing for format arguments&lt;/head&gt;
    &lt;p&gt;My initial idea for a minimal C++ formatting library involved a &lt;code&gt;Format_Argument&lt;/code&gt; type, passed in an &lt;code&gt;std::initializer_list&lt;/code&gt; to the &lt;code&gt;format&lt;/code&gt; function.
The API was shaped like this:&lt;/p&gt;
    &lt;code&gt;enum class Format_Argument_Type
{
	boolean,
	int32,
	float32,
	vec4,
};

struct Format_Argument
{
	Format_Argument_Type type;
	union
	{
		bool b;
		int32_t i;
		float f;
		Vec4 v;
	};
};

void format_value(String_Buffer&amp;amp; buf, const Format_Argument&amp;amp; arg);
void format(
	String_Buffer&amp;amp; buf,
	const char* fstr,
	std::initializer_list&amp;lt;Format_Argument&amp;gt; args);
&lt;/code&gt;
    &lt;p&gt;This approach has a couple problems though, which were enough of a deal breaker for me that I dropped the idea.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Efficiency.&lt;/p&gt;&lt;p&gt;The size of&lt;/p&gt;&lt;code&gt;Format_Argument&lt;/code&gt;is as large as the biggest value able to be formatted. In this case, assuming&lt;code&gt;Vec4&lt;/code&gt;is four 32-bit floats, it is 20 bytes. This space has to be allocated on the stack for the&lt;code&gt;initializer_list&lt;/code&gt;.&lt;p&gt;It is unlikely compilers would be able to optimise all that away, especially if the&lt;/p&gt;&lt;code&gt;format&lt;/code&gt;function lived in a separate object file.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Verbosity.&lt;/p&gt;&lt;p&gt;The example above is actually incomplete. What&lt;/p&gt;&lt;code&gt;Format_Argument&lt;/code&gt;has to look like is actually this:&lt;code&gt;struct Format_Argument { Format_Argument_Type type; union { bool b; int32_t i; float f; Vec4 v; }; Format_Argument(bool b) : type(Format_Argument_Type::boolean), b(b) {} Format_Argument(int32_t i) : type(Format_Argument_Type::int32), i(i) {} Format_Argument(float f) : type(Format_Argument_Type::float32), f(f) {} Format_Argument(Vec4 v) : type(Format_Argument_Type::vec4), v(v) {} };&lt;/code&gt;&lt;p&gt;And then you have to&lt;/p&gt;&lt;code&gt;switch&lt;/code&gt;on the format argument√¢s&lt;code&gt;type&lt;/code&gt;in&lt;code&gt;format_value&lt;/code&gt;, introducing further duplication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why not &lt;code&gt;printf&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The elephant in the room. Why do this when you have &lt;code&gt;printf&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;The answer to this is: verbosity.&lt;/p&gt;
    &lt;p&gt;Firstly, there is no way to extend &lt;code&gt;printf&lt;/code&gt; with your own types in standard C.
I often want to &lt;code&gt;printf&lt;/code&gt; 3D vectors for debugging, and I have to resort to listing out all the axes manually.&lt;/p&gt;
    &lt;code&gt;printf(
	"%f %f %f",
	player.position.x,
	player.position.y,
	player.position.z
);
&lt;/code&gt;
    &lt;p&gt;I think you can see how this gets old real quick.&lt;/p&gt;
    &lt;p&gt;Combine this with the inability to use &lt;code&gt;printf&lt;/code&gt; as an expression, which is particularly painful with ImGui√¢where I often want to format a window title, or button label.&lt;/p&gt;
    &lt;code&gt;char entity_name[64];
snprintf(
	entity_name, sizeof entity_name,
	"%d(%d) %s",
	entity_id.index, entity_id.generation,
	entity_kind::names[entity.kind]
);
if (ImGui::TreeNode(entity_name)) {
	// ...
	ImGui::TreePop();
}
&lt;/code&gt;
    &lt;p&gt;It is possible to write a function which allocates the temporary buffer and writes to it in one go, akin to my &lt;code&gt;fmt::print&lt;/code&gt; function, but even doing that is verbose, as you have to deal with &lt;code&gt;va_list&lt;/code&gt;√¢therefore needing two sets of functions, one for variadic arguments &lt;code&gt;...&lt;/code&gt; and one for &lt;code&gt;va_list&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;printf&lt;/code&gt; is also error-prone.
It is easy to mess up and use the wrong specifier type, or pass too few arguments to the function.&lt;/p&gt;
    &lt;code&gt;printf("%x", 1.0f); // oops
printf("%x");       // ...not again
&lt;/code&gt;
    &lt;p&gt;This makes it unusable for localisation purposes.&lt;/p&gt;
    &lt;p&gt;There is also no easy, idiomatic way to concatenate strings written with &lt;code&gt;snprintf&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;char str[4] = {0};
int cursor = 0;
cursor += snprintf(str, sizeof str, "hello ");
cursor += snprintf(str, sizeof str, "world!");
&lt;/code&gt;
    &lt;p&gt;This naive way is not actually correct, because &lt;code&gt;snprintf&lt;/code&gt; returns the number of characters that would be written into &lt;code&gt;str&lt;/code&gt;, had the buffer been large enough.
Therefore, the second call to &lt;code&gt;snprintf&lt;/code&gt; in the above example ends up writing past the buffer√¢s bounds (at index 6.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Extras&lt;/head&gt;
    &lt;p&gt;Since the base library is very bare-bones, I√¢m including some additional snippets to help you get it integrated into your project.&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;code&gt;write_value&lt;/code&gt; for various types&lt;/head&gt;
    &lt;code&gt;void write_value(String_Buffer&amp;amp; buf, const char* value)
{
	write(buf, value, int(strlen(value)));
}

void write_value(String_Buffer&amp;amp; buf, bool value)
{
	if (value)
		write(buf, "true", 4);
	else
		write(buf, "false", 5);
}

void write_value(String_Buffer&amp;amp; buf, char value)
{
	write(buf, &amp;amp;value, 1);
}
&lt;/code&gt;
    &lt;p&gt;For integers, here√¢s an implementation of &lt;code&gt;write_value&lt;/code&gt; for &lt;code&gt;int64_t&lt;/code&gt;.
This can confuse C++√¢s overload resolution, so I√¢d recommend adding additional overloads for smaller integers &lt;code&gt;int8_t&lt;/code&gt;, &lt;code&gt;int16_t&lt;/code&gt;, &lt;code&gt;int32_t&lt;/code&gt;, also &lt;code&gt;long long&lt;/code&gt;, and &lt;code&gt;ptrdiff_t&lt;/code&gt;, calling into the &lt;code&gt;int64_t&lt;/code&gt; overload.&lt;/p&gt;
    &lt;code&gt;void write_value(String_Buffer&amp;amp; buf, int64_t value)
{
	if (value == 0) {
		write(buf, "0", 1);
		return;
	}
	if (value &amp;lt; 0) {
		write(buf, "-", 1);
		value = -value;
	}

	char digits[20] = {};
	int i = sizeof digits - 1;
	while (value &amp;gt; 0) {
		digits[i--] = '0' + (value % 10);
		value /= 10;
	}
	int ndigits = sizeof digits - i - 1;
	write(buf, digits + i + 1, ndigits);
}
&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;uint64_t&lt;/code&gt; version can be created in a similar manner, by removing the &lt;code&gt;if (value &amp;lt; 0)&lt;/code&gt; case near the beginning.&lt;/p&gt;
    &lt;p&gt;This algorithm works for any radix (base 2, base 8, base 16, √¢¬¶). In my own implementation, I have a &lt;code&gt;Format_Hex&lt;/code&gt; newtype, which changes the output to base 16.&lt;/p&gt;
    &lt;code&gt;struct Format_Hex
{
	uint64_t value;
};

namespace fmt
{

inline Format_Hex hex(uint64_t value) { return {value}; }

}
&lt;/code&gt;
    &lt;p&gt;For floats, I defer the work onto &lt;code&gt;snprintf&lt;/code&gt;√¢s &lt;code&gt;%g&lt;/code&gt; specifier, because I trust it to do a better job than I ever could, even if a bit slow.
You can also use Ryu for this purpose.&lt;/p&gt;
    &lt;code&gt;void write_value(String_Buffer&amp;amp; buf, double value)
{
	char f[32] = {};
	int len = snprintf(f, sizeof f, "%g", value);
	if (len &amp;gt; sizeof f - 1)
		len = sizeof f - 1;
	write(buf, f, len);
}
&lt;/code&gt;
    &lt;p&gt;And of course, don√¢t forget about vectors√¢which were one of my motivating examples for abandoning &lt;code&gt;printf&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;void write_value(String_Buffer&amp;amp; buf, Vec3 value)
{
	write(buf, "(", 1);
	write_value(buf, value.x);
	write(buf, ", ", 2);
	write_value(buf, value.y);
	write(buf, ", ", 2);
	write_value(buf, value.z);
	write(buf, ")", 1);
}
&lt;/code&gt;
    &lt;head rend="h3"&gt;Ergonomic functions&lt;/head&gt;
    &lt;p&gt;The ergonomics of having to allocate a backing buffer, and then a &lt;code&gt;String_Buffer&lt;/code&gt; afterwards, can get a bit cumbersome.
To help alleviate this, I have a &lt;code&gt;Static_String&lt;/code&gt; type, together with a &lt;code&gt;print&lt;/code&gt; function, which formats to a &lt;code&gt;Static_String&lt;/code&gt; and returns it:&lt;/p&gt;
    &lt;code&gt;template&amp;lt;int N&amp;gt;
struct Static_String
{
	char data[N] = {};

	const char* operator*() const { return data; }
};

namespace fmt
{

template&amp;lt;int N, typename... Args&amp;gt;
Static_String&amp;lt;N&amp;gt; print(const char* fstr, const Args&amp;amp;... args)
{
	Static_String&amp;lt;N&amp;gt; str;
	String_Buffer buf = {str.data, sizeof str.data};
	format(buf, fstr, args...);
	return str;
}

}
&lt;/code&gt;
    &lt;p&gt;This makes it very easy to use a format string wherever an ordinary &lt;code&gt;const char*&lt;/code&gt; is expected.&lt;/p&gt;
    &lt;code&gt;if (ImGui::TreeNode(
	*fmt::print&amp;lt;64&amp;gt;("{}({}) {}", index, generation, entity_kind)
)) {
	// ...
	ImGui::TreePop();
}
&lt;/code&gt;
    &lt;p&gt;Thank you to my friend Tori for giving a whole bunch of solid feedback on a draft of this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://riki.house/fmt"/><published>2025-09-15T15:51:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45251593</id><title>Microsoft to force install the Microsoft 365 Copilot app in October</title><updated>2025-09-15T17:08:47.762016+00:00</updated><content>&lt;doc fingerprint="75b6218ba9ee8c7"&gt;
  &lt;main&gt;
    &lt;p&gt;Next month, Microsoft will begin automatically installing the Microsoft 365 Copilot app on Windows devices that have the Microsoft 365 desktop client apps.&lt;/p&gt;
    &lt;p&gt;The Microsoft 365 Copilot app integrates the AI-powered Copilot assistant with Microsoft 365 suite apps, including Word, Excel, and PowerPoint, as well as other features like Notebooks and AI agents.&lt;/p&gt;
    &lt;p&gt;While the newly installed app will be added to the Windows Start Menu and enabled by default, IT administrators responsible for managing Microsoft 365 app deployments will be able to opt out in the Apps Admin Center.&lt;/p&gt;
    &lt;p&gt;Redmond also advised admins to notify their organizations' helpdesk teams and users before the app is forcibly installed on their devices "to reduce confusion and support requests."&lt;/p&gt;
    &lt;p&gt;The rollout will start in early October and be completed by mid-November; however, the Microsoft 365 Copilot app will not be installed on systems within the European Economic Area (EEA).&lt;/p&gt;
    &lt;p&gt;"Starting in October 2025, Microsoft will begin automatically installing the Microsoft 365 Copilot app on Windows devices that have Microsoft 365 desktop client apps," the company said in a Microsoft 365 message center update on Friday.&lt;/p&gt;
    &lt;p&gt;"This app provides a centralized entry point for accessing Copilot experiences and AI-powered capabilities across Microsoft 365. This change simplifies access to Copilot and ensures users can easily discover and engage with productivity-enhancing features."&lt;/p&gt;
    &lt;p&gt;Although many users may notice a new Microsoft 365 Copilot app icon in the Start menu, the application may have already been installed, resulting in no apparent change.&lt;/p&gt;
    &lt;p&gt;Last month, as part of the same effort to make Copilot more easily available, Microsoft announced that it will integrate Microsoft 365 Copilot agents into the Edge sidebar starting in late September 2025, allowing users to access them while using Copilot.&lt;/p&gt;
    &lt;p&gt;Weeks earlier, it added a new setting that allows Microsoft 365 admins to pin the Microsoft 365 Copilot app to the Windows taskbar.&lt;/p&gt;
    &lt;head rend="h2"&gt;Picus Blue Report 2025 is Here: 2X increase in password cracking&lt;/head&gt;
    &lt;p&gt;46% of environments had passwords cracked, nearly doubling from 25% last year.&lt;/p&gt;
    &lt;p&gt;Get the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bleepingcomputer.com/news/microsoft/microsoft-to-force-install-the-microsoft-365-copilot-app-in-october/"/><published>2025-09-15T16:22:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45251690</id><title>Wanted to spy on my dog, ended up spying on TP-Link</title><updated>2025-09-15T17:08:46.773920+00:00</updated><content>&lt;doc fingerprint="b430811b1b0232ef"&gt;
  &lt;main&gt;
    &lt;p&gt;I recently bought a cheap Tapo indoor camera to see what my dog gets up to when I am out of the house.&lt;/p&gt;
    &lt;p&gt;What actually followed? I ended up reverse-engineering onboarding flows, decompiling an APK, MITMing TLS sessions, and writing cryptographic scripts.&lt;/p&gt;
    &lt;p&gt;My main motivation for this project really stemmed from the fact that the camera annoyed me from day one. Setting the camera up in frigate was quite painful, no one really seemed to know how these cameras worked online.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;SIDENOTE: If you want 2 way audio to work in frigate you must use the&lt;/p&gt;&lt;code&gt;tapo://&lt;/code&gt;go2rtc configuration for your main stream instead of the usual&lt;code&gt;rtsp://&lt;/code&gt;. TP-Link are lazy and only implement 2 way audio on their own proprietary API.&lt;/quote&gt;
    &lt;p&gt;One undocumented behavior that tripped me up was that the device‚Äôs API is supposed to accept credentials &lt;code&gt;admin&lt;/code&gt;:&lt;code&gt;&amp;lt;your-tapo-cloud-password&amp;gt;&lt;/code&gt; after onboarding. However after banging my head against a wall for a few hours I later discovered that if you change your cloud password after onboarding, paired devices don‚Äôt get the memo √∞.&lt;/p&gt;
    &lt;p&gt;This implied a few things to me that started the cogs turning:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There must be a call made during on-boarding that syncs the device password with the cloud password&lt;/item&gt;
      &lt;item&gt;The device must either allow unauthenticated calls before this step or have some sort of default password.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So considering my onboarding woes and the fact that I was starting to recoil every time the tapo app tried to jam a ‚ÄúTapo Care‚Äù subscription down my throat, a cloudless onboarding solution for the device was beginning to look more and more desirable.&lt;/p&gt;
    &lt;p&gt;The first step to cracking this egg was to be be able to snoop on what the app and the camera are saying to each other during onboarding. E.g, establish a man in the middle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Man in the middle&lt;/head&gt;
    &lt;p&gt;To man in the middle a phone app, you must be able to route all http(s) traffic via a proxy server you control. Historically this has been quite simple to achieve, simply spin up a proxy on a computer, add the proxy‚Äôs self-signed certificate to the phone‚Äôs truststore, and configure the phone to point at the proxy.&lt;/p&gt;
    &lt;p&gt;However, modern phone apps can use a few nasty tricks to render this approach ineffective. Namely they will blatantly ignore proxies, throw the system truststore to the wind and make liberal use of certificate pinning.&lt;/p&gt;
    &lt;p&gt;The most full-proof technique for generically MITMing an app has therefore become dynamic instrumentation via tools like &lt;code&gt;frida&lt;/code&gt;. What this allows us to do is force an app to use the proxies and certificates that we tell it to whilst batting aside it‚Äôs attempts to do things like certificate pinning.&lt;/p&gt;
    &lt;p&gt;So the setup ended up looking like this (full setup guide here ):&lt;/p&gt;
    &lt;quote&gt;--- config: theme: 'base' themeVariables: primaryColor: '#00000000' primaryTextColor: '#fff' primaryBorderColor: '#ffffff8e' lineColor: '#fff' secondaryColor: '#fff' tertiaryColor: '#fff' --- sequenceDiagram participant A as Tapo App &amp;lt;br&amp;gt;(with frida hooks) participant L as Laptop &amp;lt;br&amp;gt;(mitmproxy) participant C as Tapo Camera A-&amp;gt;&amp;gt;L: Request L-&amp;gt;&amp;gt;L: Record request L-&amp;gt;&amp;gt;C: Forward request C--&amp;gt;&amp;gt;L: Response L-&amp;gt;&amp;gt;L: Record response L--&amp;gt;&amp;gt;A: Forward response&lt;/quote&gt;
    &lt;p&gt;After spinning up &lt;code&gt;mitmproxy&lt;/code&gt;, injecting the frida scripts
, and onboarding the camera, we finally see an initial login flow √¢ before the admin password ever gets changed:&lt;/p&gt;
    &lt;p&gt;However, subsequent requests look like this:&lt;/p&gt;
    &lt;code&gt;{
  "method": "securePassthrough",
  "params": {
    "request": "bAhdgihJ9j6PrrknnbXWATBohGTZK5llv3MEzRcmoAmcxexmlVNz3OUX2r0h9a9EG/3X0tBpPi654T2+BjqVEOn2D178kokBpf8RQj01AvBZLYD5S5sFeaCXWiRXA7MgQUppROV4AbrU4f+GOM37KgPqT59qgLVja2slw6CzrKjPzOrG4Ho6Mu6wBa1xepcj"
  }
}
&lt;/code&gt;
    &lt;p&gt;And responses look like this:&lt;/p&gt;
    &lt;code&gt;{
  "seq": 584,
  "result": {
    "response": "Gqz1wbXAig/3wL+kXzY2Ig3hq+JSYasYI7FXdMNZR5PyH8bpLX+GJqQbImUtby9IEj5HQDhxqcTa+dUqQjI0GaGCxuGHqmrgQ0FeyCTQjBiW5gslAPQG33wj44OOkAep"
  },
  "error_code": 0
}
&lt;/code&gt;
    &lt;p&gt;So from this initial dive we have learned that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tapo 100% has a default password due to the fact that it performs a full login before it knows anything about the cloud password.&lt;/item&gt;
      &lt;item&gt;Tapo has an encrypted &lt;code&gt;securePassthrough&lt;/code&gt;channel for its API calls to prevent peeping toms such as myself from spilling the beans.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The JADX dive&lt;/head&gt;
    &lt;p&gt;The next logical step is to decompile the apk in JADX and start rummaging around for a default password.&lt;/p&gt;
    &lt;p&gt;The initial login call that we captured references an &lt;code&gt;admin&lt;/code&gt; username:&lt;/p&gt;
    &lt;code&gt;{
  "method": "login",
  "params": {
    "cnonce": "AD0E189F6E1BA335",
    "encrypt_type": "3",
    "username": "admin"
  }
}
&lt;/code&gt;
    &lt;p&gt;Searching for &lt;code&gt;"admin"&lt;/code&gt; in JADX gives us many hits but there are a few concentrated in a &lt;code&gt;CameraOnboardingViewModel&lt;/code&gt; class that look interesting:&lt;/p&gt;
    &lt;p&gt;The function &lt;code&gt;m98131y2&lt;/code&gt; appears to be returning a password that is then passed to the &lt;code&gt;new Account()&lt;/code&gt; call. Following this function up the chain, we hit gold:&lt;/p&gt;
    &lt;p&gt;We already know that the device is using &lt;code&gt;encrypt_type: 3&lt;/code&gt;, so that means our default password is:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;TPL075526460603&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h2"&gt;Teaching mitmproxy new tricks&lt;/head&gt;
    &lt;p&gt;With the default password now revealed, we have the cards in our hand to derive session keys and decode the &lt;code&gt;securePassthrough&lt;/code&gt; messages.&lt;/p&gt;
    &lt;p&gt;The only thing that would help us further is if we had a reference implementation for the authentication flow. This is where PyTapo really came in handy.&lt;/p&gt;
    &lt;p&gt;Using PyTapo as a reference, we could dump the session state and encrypted messages from mitmproxy and write a script to do some static analysis on the decrypted requests and responses, but a really cool feature of &lt;code&gt;mitmproxy&lt;/code&gt; is that it supports scripting itself.&lt;/p&gt;
    &lt;p&gt;What this means is that we can pass a python script to mitmproxy, and have it directly decrypt request and response payloads inline whilst running a capture.&lt;/p&gt;
    &lt;p&gt;So I wrote &lt;code&gt;tapo_decrypt_pretty.py&lt;/code&gt; which:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Watches for the login handshake (&lt;code&gt;cnonce&lt;/code&gt;,&lt;code&gt;nonce&lt;/code&gt;,&lt;code&gt;device_confirm&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Derives &lt;code&gt;lsk&lt;/code&gt;/&lt;code&gt;ivb&lt;/code&gt;session keys from it&lt;/item&gt;
      &lt;item&gt;Transparently decrypts subsequent API calls&lt;/item&gt;
      &lt;item&gt;Pretty-prints them inline in mitmproxy√¢s UI in &lt;code&gt;request_decrypted&lt;/code&gt;and&lt;code&gt;response_decrypted&lt;/code&gt;fields&lt;/item&gt;
      &lt;item&gt;Dumps them to JSON files for later analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Analysing the results&lt;/head&gt;
    &lt;p&gt;The complete list of calls made by the Tapo app during onboarding were:&lt;/p&gt;
    &lt;code&gt;getAppComponentList
setLanguage
scanApList
bindToCloud
changeAdminPassword
setTimezone
setRecordPlan
setDeviceLocation
connectAp
getConnectStatus
setAccountEnabled
changeThirdAccount
&lt;/code&gt;
    &lt;p&gt;This boiled down to just four important calls:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;scanApList&lt;/code&gt;√¢ list Wi-Fi access points&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;setAccountEnabled&lt;/code&gt;+&lt;code&gt;changeThirdAccount&lt;/code&gt;√¢ enable RTSP/ONVIF account&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;changeAdminPassword&lt;/code&gt;√¢ change from default password to the cloud password&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;connectAp&lt;/code&gt;√¢ join the selected Wi-Fi access point&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Everything else was fluff: timezones, record plans, binding to cloud.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;In the end, the prize for all this nonsense was a scrappy little Bash script, &lt;code&gt;tapo_onboard.sh&lt;/code&gt;
, which:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Logs in with the default admin password,&lt;/item&gt;
      &lt;item&gt;Scans and selects a Wifi access point&lt;/item&gt;
      &lt;item&gt;Switches off the obnoxious OSD logo on the camera feed,&lt;/item&gt;
      &lt;item&gt;Enables RTSP/ONVIF capabilities&lt;/item&gt;
      &lt;item&gt;Changes the admin password,&lt;/item&gt;
      &lt;item&gt;And finally joins the Wi-Fi.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Peeling this onion left me with a few observations on Tapo√¢s firmware.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Some endpoints use SHA-256 for hashing, while others cling to MD5 like it√¢s 2003.&lt;/item&gt;
      &lt;item&gt;There are two public keys used to send passwords to the device √¢ one that is shared with the client and another super secret one that‚Äôs hardcoded in the app. The easiest way to figure out which one to use is to flip a coin.&lt;/item&gt;
      &lt;item&gt;Password syncing between the app and its managed devices is strictly vibe-based.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The whole thing feels like it was cobbled together by a consortium of couch-cryptographers. But then again, it was the cheapest indoor camera on amazon, so what did I expect?&lt;/p&gt;
    &lt;p&gt;And with all this said I did finally manage to figure out what the dog does when I am away.&lt;/p&gt;
    &lt;p&gt;She sleeps. On the sofa. Sometimes even in her bed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kennedn.com/blog/posts/tapo/"/><published>2025-09-15T16:28:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45251995</id><title>The U.S. Government's Extraordinary Pursuit of Kilmar √Åbrego Garc√≠a</title><updated>2025-09-15T17:08:46.568282+00:00</updated><content>&lt;doc fingerprint="427dd8145200db71"&gt;
  &lt;main&gt;
    &lt;p&gt;After a pair of federal judges in Tennessee had cleared the way for Kilmar √Åbrego Garc√≠a to be released from pretrial detention, on August 22nd, so that he could spend a couple of days with his family before a scheduled check-in at an Immigration and Customs Enforcement office in Baltimore, he was taken directly to a nearby hotel. The first thing he did was change into a new set of clothes that his wife, Jennifer Vasquez, had bought for him. Then he was given some flowers and ushered into a small room where Vasquez, their three children, other relatives, and supporters were waiting. He picked up his youngest son as people chanted, ‚Äú¬°S√≠, se pudo!‚Äù‚Äîsomething like ‚ÄúYes, we did!‚Äù&lt;/p&gt;
    &lt;p&gt;The child had been in a car with √Åbrego Garc√≠a when ICE arrested him, near their home in Maryland, on March 12th. The arrest occurred during the government‚Äôs scramble to fly hundreds of people‚Äîmostly Venezuelans it claimed were members of the Tren de Aragua gang‚Äîto be incarcerated in El Salvador‚Äôs notorious CECOT prison, under the centuries-old Alien Enemies Act. (A federal appeals court in New Orleans has since ruled that President Donald Trump had improperly invoked the law.) Days later, √Åbrego Garc√≠a, a Salvadoran native, was sent to CECOT on a plane with some of them, beginning one of the highest-profile campaigns of retribution against an individual person of Trump‚Äôs second term.&lt;/p&gt;
    &lt;p&gt;On March 24th, lawyers for √Åbrego Garc√≠a and his family filed a civil lawsuit demanding his return, and the courts quickly ruled that he had been deported in error. His entanglement with ICE had begun six years earlier, in March, 2019, when the Prince George‚Äôs County police department, in Maryland, arrested him and three other day laborers outside a Home Depot. (More recently, he has been employed as a sheet-metal worker.) He sought asylum and the right to not be refouled, or forcibly returned to a place where one is subject to persecution‚Äîin his case, to El Salvador. An immigration judge in Baltimore denied him the asylum request but granted him the latter, in a ‚Äúwithholding of removal,‚Äù which allowed him to work in the U.S. without risk of being sent back to his home country. The judge found that he had a ‚Äúwell-founded fear‚Äù of persecution there, on account of official corruption and a history of extortionist demands and death threats from a local gang, against both him and his family, who ran a pupusa business.&lt;/p&gt;
    &lt;p&gt;Eduardo Zelaya, a Salvadoran organizer with CASA‚Äîone of the immigrants‚Äô-rights organizations that, alongside a team of immigration lawyers, has been advocating for √Åbrego Garc√≠a‚Äôs freedom since March‚Äîwas with him in Tennessee. ‚ÄúSeeing the family reunified felt like a victory,‚Äù he told me in Spanish. ‚ÄúBut, at the same time, it felt like the beginning of a battle.‚Äù&lt;/p&gt;
    &lt;p&gt;That battle had started during the effort to secure his release. √Åbrego Garc√≠a had finally been returned from El Salvador on June 6th‚Äîbut to Tennessee, not to Maryland, and only once the government had filed a new set of charges, in an indictment, accusing him of unlawfully transporting undocumented immigrants across state lines. The federal magistrate judge in Tennessee handling pretrial matters in the new case, Barbara Holmes, finding that he posed no risk of flight or danger to other people, had ordered him released on June 22nd to await trial. But that release was delayed for two months, as officials, in public and before judges in Maryland and Tennessee, offered shifting explanations as to the government‚Äôs intentions with the indictment. Did the Justice Department and the Department of Homeland Security want √Åbrego Garc√≠a to face, as Attorney General Pam Bondi has put it, ‚ÄúAmerican justice‚Äù? If so, he‚Äôs presumed innocent until proved otherwise, in a criminal court of law. Or did they want him to face the deportation system right away, and remove him to a country other than El Salvador under the immigration laws? If so, there would be a process for that in immigration court. What the government could not pursue is both courses at once.&lt;/p&gt;
    &lt;p&gt;Faced with this legal reality, on the night of Thursday, August 21st, hours before √Åbrego Garc√≠a was to be released, ICE devised a choice for him. He could agree to delay his release until the following Monday, and then be deported to Costa Rica, whose government had just committed to granting him refugee status or residency‚Äîin exchange for pleading guilty to the federal indictment in Tennessee. Or, he could be released as planned, decline the plea offer, report to his scheduled appointment at the ICE field office in Baltimore, and risk being deported this time, inexplicably, to Uganda, if he chose to await trial. His criminal-defense team in Tennessee, which is seeking to have the indictment thrown out as a ‚Äúvindictive and selective prosecution,‚Äù immediately brought this development to the attention of Waverly Crenshaw, the U.S. district judge overseeing the prosecution, stating, ‚ÄúThere can be only one interpretation of these events: the DOJ, DHS, and ICE are using their collective powers to force Mr. Abrego to choose between a guilty plea followed by relative safety, or rendition to Uganda, where his safety and liberty would be under threat.‚Äù (The government has since said that it plans to deport him instead to Eswatini; on Thursday, Reuters reported that the African nation had no knowledge of this arrangement.)&lt;/p&gt;
    &lt;p&gt;√Åbrego Garc√≠a preferred to be released as scheduled, and, when he arrived for his ICE appointment in Baltimore, hundreds of supporters were waiting outside, including members of Congress, state and local officials, and faith leaders. ‚ÄúWhen he goes in that building, we‚Äôll be supporting him. We continue to fight. No matter what happens in there today, we got his back,‚Äù Representative Glenn Ivey, of Maryland, said. √Åbrego Garc√≠a read a prepared statement, in Spanish. ‚ÄúI want you to always remember that today I can say with pride that I am free and reunited with my family,‚Äù he said. Moments with his loved ones had given him the ‚Äústrength and hope to continue this fight.‚Äù Speaking of others who have been detained under the Trump Administration, he said, ‚ÄúGod is with us. He will never leave us. He will bring justice to all the injustice they‚Äôve done.‚Äù&lt;/p&gt;
    &lt;p&gt;√Åbrego Garc√≠a and Vasquez, his wife, entered the building. Less than an hour later, she emerged alone, and Simon Sandoval-Moshenberg, √Åbrego Garc√≠a‚Äôs lead immigration lawyer, told the crowd that his client had been arrested again. The legal team shortly filed a petition for habeas corpus in Maryland. This was the fourth legal action between √Åbrego Garc√≠a and the U.S. government since 2019, but this new case is different, in that it challenges what supporters describe as the political nature of √Åbrego Garc√≠a‚Äôs rearrest. ‚ÄúThe fact that they‚Äôre holding Costa Rica as a carrot and using Uganda as a stick to try to coerce him to plead guilty to a crime is such clear evidence that they‚Äôre weaponizing the immigration system in a manner that is completely unconstitutional,‚Äù Sandoval-Moshenberg announced to the crowd. At a hearing later in the week, he stated that √Åbrego Garc√≠a would again seek asylum in the U.S. Paula Xinis, the U.S. district judge in Maryland who had been handling √Åbrego Garc√≠a‚Äôs earlier civil case, returning him from El Salvador, is also handling the new case, and she has prevented the government from taking any action against him until she rules in the dispute, after a hearing scheduled for October 6th.&lt;/p&gt;
    &lt;p&gt;Senator Chris Van Hollen, of Maryland, who met with √Åbrego Garc√≠a in El Salvador in April, told me that ‚Äúhis case reflects a corruption of the legal process from start to finish.‚Äù The D.H.S. posted a short clip, on X, of √Åbrego Garc√≠a after his arrest at the ICE office, being led away in handcuffs and leg-irons. It was picked up by Fox News and other outlets, creating a viral moment of sorts, on account of two words that √Åbrego Garc√≠a had said, looking into the camera: ‚ÄúGobierno corrupto.‚Äù&lt;/p&gt;
    &lt;p&gt;√Åbrego Garc√≠a wasn‚Äôt previously on any of Donald Trump‚Äôs enemies‚Äô lists, but he landed there when he began winning his cases with the federal judiciary. Critical to those wins was the government‚Äôs admission of error in the civil suit he filed in March. Erez Reuveni, a veteran lawyer with the Justice Department‚Äôs Office of Immigration Litigation, was fired after stating during a hearing that √Åbrego Garc√≠a should not have been sent to El Salvador; he later became a whistle-blower. Another government official, Robert Cerna, in a separate court filing, wrote that the wrongful refoulement was the result of an ‚Äúadministrative error.‚Äù&lt;/p&gt;
    &lt;p&gt;Based on that information, on April 4th, Judge Xinis ordered the government to take steps to return √Åbrego Garc√≠a to the U.S. The Administration challenged her ruling, but the U.S. Court of Appeals for the Fourth Circuit upheld it. So did the Supreme Court, on April 10th, issuing a unanimous, unsigned order that ‚Äúproperly requires the Government to ‚Äòfacilitate‚Äô Abrego Garcia‚Äôs release from custody in El Salvador and to ensure that his case is handled as it would have been had he not been improperly sent to El Salvador.‚Äù&lt;/p&gt;
    &lt;p&gt;The Administration, however, stonewalled. Four days after the Supreme Court ruling, at an Oval Office meeting between Trump and the Salvadoran President, Nayib Bukele, a reporter asked, ‚ÄúPresident Trump, do you plan to ask President Bukele to help return the man who your Administration says was mistakenly deported?‚Äù Attorney General Pam Bondi answered for Trump: ‚ÄúIf they wanted to return him, we would facilitate it‚Äîmeaning provide a plane.‚Äù The White House deputy chief of staff Stephen Miller soon suggested that the Supreme Court had actually ruled in the Administration‚Äôs favor. Then he added, ‚ÄúThat is the President of El Salvador. Your questions about it, per the Court, can only be directed to him.‚Äù A confused-looking Bukele replied, ‚ÄúI don‚Äôt have the power to return him to the United States.‚Äù&lt;/p&gt;
    &lt;p&gt;Judge Xinis and the Fourth Circuit both expressed dismay at the Administration‚Äôs failure to comply. ‚ÄúDefendants appear to have done nothing,‚Äù she wrote in a follow-up order, which allowed √Åbrego Garc√≠a‚Äôs legal team to seek basic information about his status and whereabouts. The U.S. circuit judge J. Harvie Wilkinson, a Reagan appointee, noted Bukele‚Äôs and Trump‚Äôs denials of responsibility. ‚ÄúWe are told that neither government has the power to act,‚Äù he wrote. ‚ÄúThe result will be to leave matters generally and Abrego Garcia specifically in an interminable limbo without recourse to law of any sort.‚Äù&lt;/p&gt;
    &lt;p&gt;This months-long standoff has allowed the Administration to escalate its campaign against √Åbrego Garc√≠a in the press and on social media. The President displayed a digitally altered photo of tattoos that √Åbrego Garc√≠a has on one hand, with the characters ‚ÄúMS-13‚Äù superimposed on his knuckles. After his rearrest, Bondi said, ‚ÄúHe will no longer terrorize our country.‚Äù In August, √Åbrego Garc√≠a‚Äôs criminal-defense team asked Judge Crenshaw to issue a gag order against Bondi and Kristi Noem, the Homeland Security Secretary, stating that ‚Äúthe government‚Äôs ongoing barrage of prejudicial statements severely threaten‚Äîand perhaps have already irrevocably impaired‚Äîthe ability to try this case at all‚Äîin any venue.‚Äù&lt;/p&gt;
    &lt;p&gt;Members of the Administration have also attacked √Åbrego Garc√≠a based on allegations from various court records and his immigration file. The most sensitive‚Äîwhich they have made repeatedly‚Äîis that √Åbrego Garc√≠a is a ‚Äúwife beater.‚Äù In April, the D.H.S. released records from Prince George‚Äôs County showing that Vasquez had sought temporary court intervention, in 2020 and 2021, after accusing her husband of violence against her; she withdrew one request and didn‚Äôt pursue the other. (They married while he was in detention in 2019; she testified on his behalf while pregnant with their son.) In May, Vasquez, who is a U.S. citizen, said in a statement, ‚ÄúMy husband was traumatized from the time he spent in ICE detention and we were in the throes of COVID. Like many couples, we were caring for our children with barely enough to get by. All of those factors contributed to the actions which caused me to seek the protective order.‚Äù&lt;/p&gt;
    &lt;p&gt;Vice-President J. D. Vance, meanwhile, posted on X that √Åbrego Garc√≠a was a ‚Äúconvicted MS-13 gang member,‚Äù a claim immediately refuted by commenters pointing out that there had been no conviction, or even a criminal complaint. There was only a police report, from his original arrest in 2019, citing an informant and claiming that √Åbrego Garc√≠a‚Äôs clothing‚Äîincluding a Chicago Bulls cap‚Äîsignified gang membership. (He wore a Bulls cap at the reunion in Tennessee.) After the Supreme Court ruling, the Justice Department posted the police report. The New Republic and USA Today both noted that it had been written by a discredited Prince George‚Äôs County detective who was later criminally indicted for leaking ‚Äúsensitive and confidential information about an ongoing police investigation with a commercial sex worker.‚Äù Judge Xinis, in one of her orders, noted that the Administration had provided no evidence of MS-13 or terrorist ties, which it has also repeatedly alleged.&lt;/p&gt;
    &lt;p&gt;A few days before √Åbrego Garc√≠a‚Äôs release in Tennessee, in August, his defense team there asked Judge Crenshaw to dismiss the indictment because the government cannot retaliate against anyone merely for exercising their rights in court. ‚ÄúThis case results from the government‚Äôs concerted effort to punish him for having the audacity to fight back, rather than accept a brutal injustice,‚Äù they wrote.&lt;/p&gt;
    &lt;p&gt;The indictment, which was kept under seal until √Åbrego Garc√≠a‚Äôs return from El Salvador, implicates him in a criminal conspiracy in which he and others are said to have ‚Äúknowingly and unlawfully transported thousands of undocumented aliens who had no authorization to be present in the United States, and many of whom were MS-13 members and associates.‚Äù It points to a single incident: on November 30, 2022, a Tennessee state trooper pulled over a Chevrolet S.U.V. driven by √Åbrego Garc√≠a, for speeding. He was taking nine other passengers, all of whom were Hispanic men, to Maryland, but after a brief inspection he was let go without a traffic ticket. According to the indictment, he was acting in concert with six unnamed co-conspirators. Tennessee authorities have released video of the traffic stop and confirmed that the federal government declined to take action then, and his lawyers have compiled a list of similar prosecutions in the same jurisdiction where prosecutors did not wait more than two years before bringing an indictment.&lt;/p&gt;
    &lt;p&gt;The effort to prepare the case, in fact, was conducted with Joint Task Force Vulcan, a special Justice Department unit formed during Trump‚Äôs first term to build criminal cases against MS-13. When the indictment was made public, Bondi personally thanked the unit, some of whose members, the Times reported, had no idea who √Åbrego Garc√≠a was until they were enlisted to build the case against him, on April 28th. Among the witnesses the government hopes to put on the stand, and who offered grand-jury testimony, is a man who has been deported five times, and who, for his co√∂peration on the case, has been granted early release from federal prison, where he was serving a thirty-month sentence for human smuggling; he has also been promised deferred action on deportation in exchange for testimony against √Åbrego Garc√≠a, whom he claims to have worked with.&lt;/p&gt;
    &lt;p&gt;Around the time that √Åbrego Garc√≠a was indicted, according to ABC News, Ben Schrader, the head of the criminal division of the U.S. Attorney‚Äôs Office for the Middle District of Tennessee, resigned, reportedly because of the indictment‚Äôs politically motivated nature. Without addressing the circumstances of his resignation, Schrader wrote on LinkedIn that, at the Justice Department, ‚Äúthe only job description I‚Äôve ever known is to do the right thing, in the right way, for the right reasons.‚Äù&lt;/p&gt;
    &lt;p&gt;The case has been instructive because the judges handling it, Holmes and Crenshaw, have begun to test some of the evidence the government has gathered so far. They haven‚Äôt shied away from examining the domestic-violence incidents or the uncorroborated claims of gang ties. When weighing whether to release √Åbrego Garc√≠a ahead of trial, Judge Holmes acknowledged that his wife had twice sought orders of protection, but found that this alone did not make him a risk. ‚ÄúThere is no evidence of any similar occurrences since 2021,‚Äù she wrote. ‚ÄúNor any evidence that Ms. Vasquez is anything other than fully supportive of Abrego.‚Äù Holmes likewise discredited the MS-13 accusation, for which prosecutors relied on the testimony of co√∂perating witnesses who either contradicted one another or were otherwise unreliable. In July, Crenshaw, in a second ruling endorsing her findings, was emphatic: ‚ÄúAt bottom, the Government fails to provide any evidence that there is something in Abrego‚Äôs history, or his exhibited characteristics, that warrants detention.‚Äù He did suggest that √Åbrego Garc√≠a will soon be afforded what the Trump Administration has denied him so far: a full and fair trial where he can subject the witnesses against him ‚Äúto a rigorous cross examination.‚Äù&lt;/p&gt;
    &lt;p&gt;This kind of scrutiny, which the Constitution demands, may be precisely why the government devised the Uganda option: by coercing √Åbrego Garc√≠a to plead guilty, it might have avoided the burden of proving its case beyond a reasonable doubt, plus all the procedural safeguards that come with a public trial. That proof is what Senator Van Hollen wants to see from the Administration. ‚ÄúShut up on social media,‚Äù he said. ‚ÄúPut up your evidence in court.‚Äù ‚ô¶&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.newyorker.com/news/the-lede/the-us-governments-extraordinary-pursuit-of-kilmar-abrego-garcia"/><published>2025-09-15T16:52:19+00:00</published></entry></feed>