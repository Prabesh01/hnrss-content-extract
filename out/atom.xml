<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-02-06T18:03:03.157592+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46903616</id><title>We tasked Opus 4.6 using agent teams to build a C Compiler</title><updated>2026-02-06T18:03:09.260376+00:00</updated><content>&lt;doc fingerprint="5760beda6f939a6e"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by Nicholas Carlini, a researcher on our Safeguards team. &lt;/p&gt;
    &lt;p&gt;I've been experimenting with a new approach to supervising language models that we’re calling "agent teams."&lt;/p&gt;
    &lt;p&gt;With agent teams, multiple Claude instances work in parallel on a shared codebase without active human intervention. This approach dramatically expands the scope of what's achievable with LLM agents.&lt;/p&gt;
    &lt;p&gt;To stress test it, I tasked 16 agents with writing a Rust-based C compiler, from scratch, capable of compiling the Linux kernel. Over nearly 2,000 Claude Code sessions and $20,000 in API costs, the agent team produced a 100,000-line compiler that can build Linux 6.9 on x86, ARM, and RISC-V.&lt;/p&gt;
    &lt;p&gt;The compiler is an interesting artifact on its own, but I focus here on what I learned about designing harnesses for long-running autonomous agent teams: how to write tests that keep agents on track without human oversight, how to structure work so multiple agents can make progress in parallel, and where this approach hits its ceiling.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enabling long-running Claudes&lt;/head&gt;
    &lt;p&gt;Existing agent scaffolds like Claude Code require an operator to be online and available to work jointly. If you ask for a solution to a long and complex problem, the model may solve part of it, but eventually it will stop and wait for continued input—a question, a status update, or a request for clarification.&lt;/p&gt;
    &lt;p&gt;To elicit sustained, autonomous progress, I built a harness that sticks Claude in a simple loop (if you’ve seen Ralph-loop, this should look familiar). When it finishes one task, it immediately picks up the next. (Run this in a container, not your actual machine).&lt;/p&gt;
    &lt;code&gt;#!/bin/bash

while true; do
    COMMIT=$(git rev-parse --short=6 HEAD)
    LOGFILE="agent_logs/agent_${COMMIT}.log"

    claude --dangerously-skip-permissions \
           -p "$(cat AGENT_PROMPT.md)" \
           --model claude-opus-X-Y &amp;amp;&amp;gt; "$LOGFILE"
done
&lt;/code&gt;
    &lt;p&gt;&lt;lb/&gt;In the agent prompt, I tell Claude what problem to solve and ask it to approach the problem by breaking it into small pieces, tracking what it’s working on, figuring out what to work on next, and to effectively keep going until it’s perfect. (On this last point, Claude has no choice. The loop runs forever—although in one instance, I did see Claude &lt;code&gt;pkill -9 bash&lt;/code&gt; on accident, thus killing itself and ending the loop. Whoops!).&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt;Running Claude in parallel&lt;/head&gt;
    &lt;p&gt;Running multiple instances in parallel can address two weaknesses of a single-agent harness:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One Claude Code session can only do one thing at a time. Especially as the scope of a project expands, debugging multiple issues in parallel is far more efficient.&lt;/item&gt;
      &lt;item&gt;Running multiple Claude agents allows for specialization. While a few agents are tasked to solve the actual problem at hand, other specialized agents can be invoked to (for example) maintain documentation, keep an eye on code quality, or solve specialized sub-tasks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My implementation of parallel Claude is bare-bones. A new bare git repo is created, and for each agent, a Docker container is spun up with the repo mounted to &lt;code&gt;/upstream&lt;/code&gt;. Each agent clones a local copy to &lt;code&gt;/workspace&lt;/code&gt;, and when it's done, pushes from its own local container to upstream.&lt;/p&gt;
    &lt;p&gt;To prevent two agents from trying to solve the same problem at the same time, the harness uses a simple synchronization algorithm:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Claude takes a "lock" on a task by writing a text file to current_tasks/ (e.g., one agent might lock current_tasks/parse_if_statement.txt, while another locks current_tasks/codegen_function_definition.txt). If two agents try to claim the same task, git's synchronization forces the second agent to pick a different one.&lt;/item&gt;
      &lt;item&gt;Claude works on the task, then pulls from upstream, merges changes from other agents, pushes its changes, and removes the lock. Merge conflicts are frequent, but Claude is smart enough to figure that out.&lt;/item&gt;
      &lt;item&gt;The infinite agent-generation-loop spawns a new Claude Code session in a fresh container, and the cycle repeats.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a very early research prototype. I haven’t yet implemented any other method for communication between agents, nor do I enforce any process for managing high-level goals. I don’t use an orchestration agent.&lt;/p&gt;
    &lt;p&gt;Instead, I leave it up to each Claude agent to decide how to act. In most cases, Claude picks up the “next most obvious” problem. When stuck on a bug, Claude will often maintain a running doc of failed approaches and remaining tasks. In the git repository of the project, you can read through the history and watch it take out locks on various tasks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons from programming with Claude agent teams&lt;/head&gt;
    &lt;p&gt;The scaffolding runs Claude in a loop, but that loop is only useful if Claude can tell how to make progress. Most of my effort went into designing the environment around Claude—the tests, the environment, the feedback—so that it could orient itself without me. These are the approaches I’ve found most helpful when orchestrating multiple Claude instances.&lt;/p&gt;
    &lt;head rend="h3"&gt;Write extremely high-quality tests&lt;/head&gt;
    &lt;p&gt;Claude will work autonomously to solve whatever problem I give it. So it’s important that the task verifier is nearly perfect, otherwise Claude will solve the wrong problem. Improving the testing harness required finding high-quality compiler test suites, writing verifiers and build scripts for open-source software packages, and watching for mistakes Claude was making, then designing new tests as I identified those failure modes.&lt;/p&gt;
    &lt;p&gt;For example, near the end of the project, Claude started to frequently break existing functionality each time it implemented a new feature. To address this, I built a continuous integration pipeline and implemented stricter enforcement that allowed Claude to better test its work so that new commits can’t break existing code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Put yourself in Claude’s shoes&lt;/head&gt;
    &lt;p&gt;I had to constantly remind myself that I was writing this test harness for Claude and not for myself, which meant rethinking many of my assumptions about how tests should communicate results.&lt;/p&gt;
    &lt;p&gt;For example, each agent is dropped into a fresh container with no context and will spend significant time orienting itself, especially on large projects. Before we even reach the tests, to help Claude help itself, I included instructions to maintain extensive READMEs and progress files that should be updated frequently with the current status.&lt;/p&gt;
    &lt;p&gt;I also kept in mind the fact that language models have inherent limitations, which, in this case, needed to be designed around. These include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Context window pollution: The test harness should not print thousands of useless bytes. At most, it should print a few lines of output and log all important information to a file so Claude can find it when needed. Logfiles should be easy to process automatically: if there are errors, Claude should write ERROR and put the reason on the same line so grep will find it. It helps to pre-compute aggregate summary statistics so Claude doesn't have to recompute them.&lt;/item&gt;
      &lt;item&gt;Time blindness: Claude can't tell time and, left alone, will happily spend hours running tests instead of making progress. The harness prints incremental progress infrequently (to avoid polluting context) and includes a default &lt;code&gt;--fast&lt;/code&gt;option that runs a 1% or 10% random sample. This subsample is deterministic per-agent but random across VMs, so Claude still covers all files but each agent can perfectly identify regressions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Make parallelism easy&lt;/head&gt;
    &lt;p&gt;When there are many distinct failing tests, parallelization is trivial: each agent picks a different failing test to work on. After the test suite reached a 99% pass rate, each agent worked on getting a different small open-source project (e.g., SQlite, Redis, libjpeg, MQuickJS, Lua) to compile.&lt;/p&gt;
    &lt;p&gt;But when agents started to compile the Linux kernel, they got stuck. Unlike a test suite with hundreds of independent tests, compiling the Linux kernel is one giant task. Every agent would hit the same bug, fix that bug, and then overwrite each other's changes. Having 16 agents running didn't help because each was stuck solving the same task.&lt;/p&gt;
    &lt;p&gt;The fix was to use GCC as an online known-good compiler oracle to compare against. I wrote a new test harness that randomly compiled most of the kernel using GCC, and only the remaining files with Claude's C Compiler. If the kernel worked, then the problem wasn’t in Claude’s subset of the files. If it broke, then it could further refine by re-compiling some of these files with GCC. This let each agent work in parallel, fixing different bugs in different files, until Claude's compiler could eventually compile all files. (After this worked, it was still necessary to apply delta debugging techniques to find pairs of files that failed together but worked independently.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Multiple agent roles&lt;/head&gt;
    &lt;p&gt;Parallelism also enables specialization. LLM-written code frequently re-implements existing functionality, so I tasked one agent with coalescing any duplicate code it found. I put another in charge of improving the performance of the compiler itself, and a third I made responsible for outputting efficient compiled code. I asked another agent to critique the design of the project from the perspective of a Rust developer, and make structural changes to the project to improve the overall code quality, and another to work on documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stress testing the limits of agent teams&lt;/head&gt;
    &lt;p&gt;This project was designed as a capability benchmark. I am interested in stress-testing the limits of what LLMs can just barely achieve today in order to help us prepare for what models will reliably achieve in the future.&lt;/p&gt;
    &lt;p&gt;I’ve been using the C Compiler project as a benchmark across the entire Claude 4 model series. As I did with prior projects, I started by drafting what I wanted: a from-scratch optimizing compiler with no dependencies, GCC-compatible, able to compile the Linux kernel, and designed to support multiple backends. While I specified some aspects of the design (e.g., that it should have an SSA IR to enable multiple optimization passes) I did not go into any detail on how to do so.&lt;/p&gt;
    &lt;p&gt;Previous Opus 4 models were barely capable of producing a functional compiler. Opus 4.5 was the first to cross a threshold that allowed it to produce a functional compiler which could pass large test suites, but it was still incapable of compiling any real large projects. My goal with Opus 4.6 was to again test the limits.&lt;/p&gt;
    &lt;head rend="h3"&gt;Evaluation&lt;/head&gt;
    &lt;p&gt;Over nearly 2,000 Claude Code sessions across two weeks, Opus 4.6 consumed 2 billion input tokens and generated 140 million output tokens, a total cost just under $20,000. Compared to even the most expensive Claude Max plans, this was an extremely expensive project. But that total is a fraction of what it would cost me to produce this myself—let alone an entire team.&lt;/p&gt;
    &lt;p&gt;This was a clean-room implementation (Claude did not have internet access at any point during its development); it depends only on the Rust standard library. The 100,000-line compiler can build a bootable Linux 6.9 on x86, ARM, and RISC-V. It can also compile QEMU, FFmpeg, SQlite, postgres, redis, and has a 99% pass rate on most compiler test suites including the GCC torture test suite. It also passes the developer's ultimate litmus test: it can compile and run Doom.&lt;/p&gt;
    &lt;p&gt;The compiler, however, is not without limitations. These include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It lacks the 16-bit x86 compiler that is necessary to boot Linux out of real mode. For this, it calls out to GCC (the x86_32 and x86_64 compilers are its own).&lt;/item&gt;
      &lt;item&gt;It does not have its own assembler and linker; these are the very last bits that Claude started automating and are still somewhat buggy. The demo video was produced with a GCC assembler and linker.&lt;/item&gt;
      &lt;item&gt;The compiler successfully builds many projects, but not all. It's not yet a drop-in replacement for a real compiler.&lt;/item&gt;
      &lt;item&gt;The generated code is not very efficient. Even with all optimizations enabled, it outputs less efficient code than GCC with all optimizations disabled.&lt;/item&gt;
      &lt;item&gt;The Rust code quality is reasonable, but is nowhere near the quality of what an expert Rust programmer might produce.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The resulting compiler has nearly reached the limits of Opus’s abilities. I tried (hard!) to fix several of the above limitations but wasn’t fully successful. New features and bugfixes frequently broke existing functionality.&lt;/p&gt;
    &lt;p&gt;As one particularly challenging example, Opus was unable to implement a 16-bit x86 code generator needed to boot into 16-bit real mode. While the compiler can output correct 16-bit x86 via the 66/67 opcode prefixes, the resulting compiled output is over 60kb, far exceeding the 32k code limit enforced by Linux. Instead, Claude simply cheats here and calls out to GCC for this phase (This is only the case for x86. For ARM or RISC-V, Claude’s compiler can compile completely by itself.)&lt;/p&gt;
    &lt;p&gt;The source code for the compiler is available. Download it, read through the code, and try it on your favorite C projects. I’ve consistently found the best way to understand what language models can do is to push them to their limits, and then study where they start to break down. Over the coming days, I’ll continue having Claude push new changes if you want to follow along with Claude’s continued attempts at addressing these limitations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;Each generation of language models opens up new ways of working with them. Early models were useful for tab-completion in IDEs. Before long, models could complete a function body from its docstring. The launch of Claude Code brought agents into the mainstream and enabled developers to pair-program with Claude. But each of these products operates under the assumption that a user defines a task, an LLM runs for a few seconds or minutes and returns an answer, and then the user provides a follow-up.&lt;/p&gt;
    &lt;p&gt;Agent teams show the possibility of implementing entire, complex projects autonomously. This allows us, as users of these tools, to become more ambitious with our goals.&lt;/p&gt;
    &lt;p&gt;We are still early, and fully autonomous development comes with real risks. When a human sits with Claude during development, they can ensure consistent quality and catch errors in real time. For autonomous systems, it is easy to see tests pass and assume the job is done, when this is rarely the case. I used to work in penetration testing, exploiting vulnerabilities in products produced by large companies, and the thought of programmers deploying software they’ve never personally verified is a real concern.&lt;/p&gt;
    &lt;p&gt;So, while this experiment excites me, it also leaves me feeling uneasy. Building this compiler has been some of the most fun I’ve had recently, but I did not expect this to be anywhere near possible so early in 2026. The rapid progress in both language models and the scaffolds we use to interact with them opens the door to writing an enormous amount of new code. I expect the positive applications to outweigh the negative, but we’re entering a new world which will require new strategies to navigate safely.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Special thanks to Josef Bacik, Edwin Chen, Bernardo Meurer Costa, Jake Eaton, Dan Kelley, Felix Klock, Jannet Park, Steve Weis, and many other people across Anthropic for their assistance and contributions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/engineering/building-c-compiler"/><published>2026-02-05T19:07:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46903929</id><title>The time I didn't meet Jeffrey Epstein</title><updated>2026-02-06T18:03:09.189988+00:00</updated><content>&lt;doc fingerprint="6767385f0fa437a5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The time I didn’t meet Jeffrey Epstein&lt;/head&gt;
    &lt;p&gt;Last night, I was taken aback to discover that my name appears in the Epstein Files, in 26 different documents. This is despite the fact that I met Jeffrey Epstein a grand total of zero times, and had zero email or any other contact with him … which is more (less) than some of my colleagues can say.&lt;/p&gt;
    &lt;p&gt;The bulk of the correspondence involves Epstein wanting to arrange a meeting with me and Seth Lloyd back in 2010, via an intermediary named Charles Harper, about funding a research project on “Cryptography in Nature.”&lt;/p&gt;
    &lt;p&gt;Searching my inbox, it turns out that this Charles Harper did contact me in May 2010, and I then met him at S&amp;amp;S Deli in Cambridge (plausible, although I have zero recollections of this meeting—only of the deli). Harper then sent me a detailed followup email about his proposed Cryptography in Nature project, naming Jeffrey Epstein for the first time as the project’s funder, and adding: “perhaps you will know Jeffrey and his background and situation.”&lt;/p&gt;
    &lt;p&gt;For whatever reason, I forwarded this email to my parents, brother, and then-fiancee Dana. My brother then found and shared a news article about Epstein’s prostitution conviction, adding to a different article that I had found and shared. (At that time, like many others, I’d probably vaguely heard of Epstein, but he didn’t have 0.1% the infamy that he has now.) Then my mom wrote the following: “be careful not to get sucked up in the slime-machine going on here! Since you don’t care that much about money, they can’t buy you at least.”&lt;/p&gt;
    &lt;p&gt;It appears from emails that Charles Harper tried again later that summer to arrange a meeting between me and Epstein, but that I took my mom’s advice and largely blew him off, and no such meeting ever happened. Amazingly, I then forgot entirely that any of this had occurred until last night. By way of explanation, some business/finance dude trying to interest me in half-baked ideas involving quantum, AI, cryptography, etc., often dangling the prospect of funding for my students and postdocs, shows up in my life like every month. Most of their world-changing initiatives go nowhere for one reason or another. There really wasn’t much reason to think further about this, until Epstein had become history’s most notorious sex criminal, which (again) wouldn’t happen until years later, after I’d forgotten.&lt;/p&gt;
    &lt;p&gt;It gets better, though. In the Epstein Files, one also finds a November 2010 letter from Charles Harper to Epstein about organizing a conference on the same Cryptography in Nature topic, which includes the following idea about me:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Scott Aaronson was born on May 21st, 1981. He will be 30 in 2011. The conference could follow a theme of: “hurry to think together with Scott Aaronson while he is still in his 20s and not yet a pitiful over-the-hill geezer in his 30s.” This offers another nice opportunity for celebration.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I see no indication that any such conference ever happened; in any case, I didn’t get invited to one!&lt;/p&gt;
    &lt;p&gt;On my Facebook, some friends are joking that “it tracks that someone into teenage girls might think Scott Aaronson was a hot property in his nubile 20s, who would get old and boring in his 30s”—and that maybe Epstein was less sexist about such matters than everyone assumes. I replied that I wished I could say the proposition that I’d gradually get slower and more senile through the 2010s and 2020s was entirely false.&lt;/p&gt;
    &lt;p&gt;But the best comment was that I’ve been incredibly lucky to have such an astute family. If only Bill Gates and Larry Summers had had my mom to go to for advice, they could’ve saved themselves a lot of grief.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scottaaronson.blog/?p=9534"/><published>2026-02-05T19:29:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46904645</id><title>Animated Engines</title><updated>2026-02-06T18:03:08.833368+00:00</updated><content>&lt;doc fingerprint="a4cb355d1661b259"&gt;
  &lt;main&gt;
    &lt;p&gt;Animated Engines Home Welcome! Click an engine to see how it works. Four stroke Diesel Two stroke Wankel Atkinson Gnome Rotary Jet Propulsion Steam Locomotive Oscillating Steam CO2 Motor Coomber Crank Substitute Revolving Cylinder Watt Beam Grasshopper Beam Unknown Beam Newcomen Atmospheric Two Cylinder Stirling Single Cylinder Stirling Ross Yoke Stirling Low Differential Stirling&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://animatedengines.com/"/><published>2026-02-05T20:20:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46906947</id><title>The RCE that AMD won't fix</title><updated>2026-02-06T18:03:08.198070+00:00</updated><content>&lt;doc fingerprint="8551539d8a3b7c19"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The RCE that AMD won’t fix&lt;/head&gt;
    &lt;p&gt;After being interrupted multiple times by an annoying console window that would pop up periodically on my new gaming PC, I managed to track the offending executable down to AMD’s AutoUpdate software.&lt;/p&gt;
    &lt;p&gt;In my anger, I decided to punish this software by decompiling it to figure out how it worked, and accidentally discovered a trivial Remote Code Execution (RCE) vulnerability in the process.&lt;/p&gt;
    &lt;p&gt;The first thing I found, is that they store their update URL in the program’s &lt;code&gt;app.config&lt;/code&gt;, although its a little odd that they use their “Develpment” URL in production, it uses HTTPS so its perfectly safe.&lt;/p&gt;
    &lt;p&gt;The real problem starts when you open up this URL in your web browser, and realise that all of the executable download URL’s are using HTTP.&lt;/p&gt;
    &lt;p&gt;This means that a malicious attacker on your network, or a nation state that has access to your ISP can easily perform a MITM attack and replace the network response with any malicious executable of their choosing.&lt;/p&gt;
    &lt;p&gt;I was hoping that AMD perhaps had some form of certificate validation to ensure that it could not download &amp;amp; run any unsigned executables, however a quick look into the decompiled code revealed that the AutoUpdate software does no such validation and immediately executes the downloaded file.&lt;/p&gt;
    &lt;p&gt;After finding this issue, I thought it was worth reporting to AMD since it seemed to be a pretty severe issue.&lt;/p&gt;
    &lt;p&gt;However it turned out to be considered “out of scope”, resulting in AMD not considering this to be a vulnerability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Timeline (DD/MM/YYYY)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;27/01/2026 - Vulnerability Discovered&lt;/item&gt;
      &lt;item&gt;05/02/2026 - Vulnerability Reported&lt;/item&gt;
      &lt;item&gt;05/02/2026 - Report Closed as &lt;code&gt;wont fix/out of scope&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;06/02/2026 - Blog published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this blog, you can read another of my write-ups here: 1.4 Billion exposed user records via insecure Firebase instances in top Android apps&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mrbruh.com/amd/"/><published>2026-02-05T23:29:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46908650</id><title>Solving Shrinkwrap: New Experimental Technique</title><updated>2026-02-06T18:03:07.909941+00:00</updated><content>&lt;doc fingerprint="2e46db7649a04fb1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Solving Shrinkwrap: New Experimental Technique&lt;/head&gt;
    &lt;p&gt;In this article, I present my new technique for solving a CSS problem that was deemed impossible — true shrinkwrapping of an element with auto-wrapped content. By using anchor positioning and scroll-driven animations, we can adjust our element’s outer dimensions by measuring its inner contents, demonstrating that for many cases this can already work and might unlock a future native feature.&lt;/p&gt;
    &lt;p&gt;Since anchor positioning and scroll-driven animations appeared on my radar, I knew they would unlock things that were not possible before. These new CSS features hook into many things that were previously either impossible or available only through cumbersome JavaScript APIs. Two years ago, I wrote about one of such things — the “shrinkwrap” problem and a partial decorative workaround that used anchor positioning — in my “The Shrinkwrap Problem: Possible Future Solutions” article.&lt;/p&gt;
    &lt;p&gt;After writing that article, and experimenting more with scroll-driven animations, I knew that there could be a way to combine those and achieve shrinkwrapping not just visually, but also make it affect the layout. In the last few months, I was experimenting with my past findings and a few novel approaches, and, finally, honed them into something reusable — and already working in stable Chrome and Safari, with a graceful degradationGo to a sidenote for other browsers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Disclaimeranchor&lt;/head&gt;
    &lt;p&gt;That said, even though my examples for the base technique might work in the latest versions of some stable browsers, the technique itself is highly experimental.&lt;/p&gt;
    &lt;p&gt;For example, I experienced occasional crashes in Safari. I managed to find a workaround, but I strongly suggest being careful before using anything from this article in production.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Problemanchor&lt;/head&gt;
    &lt;p&gt;Let’s say we have a simple header, which we style to look like a nice rounded box, and that should shrink to its &lt;code&gt;max-content&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;When it is short, all is good! But we anticipate that it might wrap when the content is longer, and add &lt;code&gt;text-wrap: balance&lt;/code&gt; to make it prettier. But then, this happens:&lt;/p&gt;
    &lt;p&gt;On most viewports, you could see how when the header wraps, we get all this extra space on one side — the shrinkwrap problem. What exactly is happening, and why is it so challenging to make it work?&lt;/p&gt;
    &lt;p&gt;I’ll quote my first article about shrinkwrap:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When different content wraps — be it text, floats, inline-blocks, flex, or grid, — if that wrapping is automatic (without hard breaks), the way CSS calculates the final width is limited. The element with wrapped items gets expanded to fill all the available space.&lt;/p&gt;
      &lt;p&gt;In CSS2 specs, this behavior is called “shrink-to-fit”:&lt;/p&gt;
      &lt;p&gt;shrink-to-fit width is: min(max(preferred minimum width, available width), preferred width)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is a problem people have stumbled over and over from the beginning of time.&lt;/p&gt;
    &lt;head&gt;Under a cut — a long (not comprehensive) list with many links!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;In 2015, Elika J. Etemad wrote about it to the www-style mailing list: “True Shrinkwrapping”. She even already mentioned&lt;/p&gt;&lt;code&gt;text-wrap: balance&lt;/code&gt;in the code example!&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2016, yisibl opened an issue #191 on CSSWG’s GitHub, “How to shrink to fit the width?”, showing a use case for wrapping of items inside a flexbox layout. Most of the following cases are from this issue.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2017, Vasilis van Gemert questioned if this can be fixed in his blog post “How do I fix this CSS alignment issue?”, about a left-aligned block that, when wrapped, should be aligned as a whole to the right.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2018, Nadya678 opened a duplicate issue about this.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Also in 2018, Benoît Rouleau provided another use case in the issue #191. The CodePen in question is no longer accessible, but from the description, it sounds like the underlined headers use case from my previous article about shrinkwrap.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2019, Dan Tonon also provided his use case in the same issue. This is probably the hardest to solve use case — a menu.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2020, Dan stumbled upon this again and opened a duplicate issue with the same case.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Starting from 2023, we saw a resurgence of reports about this issue thanks to the work on&lt;/p&gt;&lt;code&gt;text-wrap: balance&lt;/code&gt;which highlighted this issue. Many people did write about it then:&lt;list rend="ul"&gt;&lt;item&gt;On March 3, Adam Argyle wrote about a few use cases.&lt;/item&gt;&lt;item&gt;On September 7, Šime Vidas linked to a related Reddit post, which had a “message” use case.&lt;/item&gt;&lt;item&gt;I published my “The Shrinkwrap Problem: Possible Future Solutions” article in December.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2024 this continued:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;On April 23, Lea Verou highlighted the &lt;code&gt;text-wrap: balance&lt;/code&gt;issue once again.&lt;/item&gt;
          &lt;item&gt;On May 3, Vincent Rubinetti linked to a JS workaround on StackOverflow.&lt;/item&gt;
          &lt;item&gt;On May 19, Tomer Aberbach wanted to replace a JS lib with &lt;code&gt;text-wrap: balance&lt;/code&gt;and couldn’t because of this issue.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;On April 23, Lea Verou highlighted the &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2025!&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;On April 18, Miriam Suzanne stumbled upon the &lt;code&gt;text-wrap: balance&lt;/code&gt;use case as well.&lt;/item&gt;
          &lt;item&gt;On May 21, Mo Beigi ran into one of the original use cases for the menu.&lt;/item&gt;
          &lt;item&gt;On May 27, Stephanie Eckles mentioned a tooltip use case they had in Adobe, one that we have as well in Datadog.&lt;/item&gt;
          &lt;item&gt;On July 21, Lea returned to this problem, opening a new duplicate issue with a proposal to use &lt;code&gt;fit-content&lt;/code&gt;or something similar for this.&lt;/item&gt;
          &lt;item&gt;On October 23, Svein Alexander Frotjold provided another use case with alignment of form fields.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;On April 18, Miriam Suzanne stumbled upon the &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And this is just mostly mentions from the #191 issue — there are also many StackOverflow issues and likely other places where authors wrote about this.&lt;/p&gt;
    &lt;p&gt;This article will show how we could solve almost all of these cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solutionsanchor&lt;/head&gt;
    &lt;p&gt;The bulk of all use cases are “simple”: we have a pre-defined space in which we have our element that could wrap, with the wrapped state often being the default one. There, we never want to use &lt;code&gt;max-content&lt;/code&gt; for the element’s width, and these elements generally do not depend on the surrounding context but want just their box to be flush with text or the surrounding context to depend on our wrapped box.&lt;/p&gt;
    &lt;p&gt;These cases are solved either by the base technique, or by a more advanced version of it where we have to measure multiple items.&lt;/p&gt;
    &lt;p&gt;The hardest cases are those like the menu items, where every item might wrap, and by default, they want to be sized as &lt;code&gt;max-content&lt;/code&gt;. I admit that my technique is not a good fit for these cases, but I will attempt to solve that as well, although through an extension of the base technique that uses content duplication.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Base Techniqueanchor&lt;/head&gt;
    &lt;p&gt;Here is how I will present the technique:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;I will list the limitations and corresponding prerequisites for using this basic technique.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The full code for the abstracted technique is placed under a cut — if you are eager to try to understand what is going on inside without my lengthier explanations, feel free to read it! Although I placed many comments inside, which helps.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Not all of that code is needed for the simplest of cases: first, I will iteratively explain how we solve the common case of an element with&lt;/p&gt;&lt;code&gt;text-align: left&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Then, I will complete the technique by handling the non-left text alignment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Finally, I will show how to use the technique as a building block for handling more complex cases with multiple nested phrasing contents.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Limitations &amp;amp; Requirementsanchor&lt;/head&gt;
    &lt;p&gt;The prerequisites for being able to use this technique are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Generally, we’d want to have some&lt;/p&gt;&lt;code&gt;container-type: inline-size&lt;/code&gt;around our element, as its default max-inline-size will use&lt;code&gt;100cqi&lt;/code&gt;, and most use cases will want to use&lt;code&gt;cqi&lt;/code&gt;in one way or another.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The element’s&lt;/p&gt;&lt;code&gt;max-inline-size&lt;/code&gt;should not dependGo to a sidenote on its siblings. For the technique to work, we will need to set it to a value in&lt;code&gt;px&lt;/code&gt;, which could depend on its container through the container query length units. But we can’t have our element respond to&lt;code&gt;flex-shrink&lt;/code&gt;or&lt;code&gt;flex-grow&lt;/code&gt;: when placed in a flex or grid context, its width will be more or less static.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Our element must have only phrasing content, or, in other words, should contain only inline elements inside. Replaced elements like&lt;/p&gt;&lt;code&gt;&amp;lt;img /&amp;gt;&lt;/code&gt;are allowed inside, alongside anything with&lt;code&gt;inline-block&lt;/code&gt;,&lt;code&gt;inline-flex&lt;/code&gt;, and other&lt;code&gt;inline-&lt;/code&gt;s, like the future&lt;code&gt;inline grid-lanes&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Full Codeanchor&lt;/head&gt;
    &lt;p&gt;If you’re curious, you can peek at the full code of the technique. It is thoroughly commented and might cover some of the things I did not cover in this article. That said, I tried to expand on many things in later sections, so keep reading if you want to get the most of that info in a more readable form!&lt;/p&gt;
    &lt;head&gt;The full code of the technique.&lt;/head&gt;
    &lt;code&gt;/*
  The shrinkwrap technique.
  https://kizu.dev/shrinkwrap-solution/
*/
.shrinkwrap {
  /*
    This should be easy to override, so placing the
    custom property defaults in a separate layer.
  */
  @layer defaults {
    /*
      We cannot use `%` for either; use `cqi` instead.
      Ideally, `progress()` would allow us to do it:
      https://github.com/w3c/csswg-drafts/issues/13315
    */
    --sw-limit: 100cqi;
    --sw-padding: 0px;
    --sw-inner-padding: 0px;
    --sw-inset: initial;
    --sw-source: initial;

    /*
      Cyclic toggles, allowing turning the technique
      on and off. See https://kizu.dev/cyclic-toggles/
    */
    --sw-enabled: var(--sw-enabled--on);
    --sw-enabled--on: var(--sw-enabled,);
    --sw-enabled--off: var(--sw-enabled,);

    /*
      Override the toggle when the timeline-scope is not
      supported, which will disable everything nicely.
    */
    @supports not (timeline-scope: --f) {
      --sw-enabled: var(--sw-enabled--off) !important;
    }
  }

  /* Deriving an inner value to include the paddings. */
  --_sw-limit: calc(
    var(--sw-limit)
    -
    2 * var(--sw-padding)
  );

  /*
    Must be `block`, `flow-root`, etc, so could be nested
    in a flexbox/grid, but can’t establish one itself.
  */
  display: block;

  /*
    The content part will likely overflow due to the
    inner box being larger.
  */
  overflow: hidden;

  /* Lifting the scope of view timelines from inside. */
  timeline-scope: --_sw-x;

  /*
    Accessing the start and end coordinates of the
    inner element via scroll-driven animations.
  */
  animation: var(--sw-enabled--on,
    --_sw-x-start linear both,
    --_sw-x-end   linear both
  );

  /*
    We will be using the “resolution” as a range to
    retrieve the width of various things.
  */
  --_sw-resolution: 10000px;
  animation-range:
    0               var(--_sw-resolution),
    contain contain var(--_sw-resolution);
  animation-timeline: --_sw-x;

  /*
    Calculating the actual size from the variables applied
    via the animation with the given resolution.
  */
  --_sw-size:
    (var(--_sw-x-start) - var(--_sw-x-end))
    *
    var(--_sw-resolution)
  ;
  /*
    For the main size, clamp the result within limits,
    and guard everything with a space toggle.
  */
  inline-size: var(--sw-enabled--on,
    clamp(
      0px,
      var(--_sw-size),
      var(--_sw-max-size)
    )
  );
  /* Min-size should not be clamped. */
  min-inline-size: max(
    0px,
    var(--_sw-size)
  );

  /*
    We need to always round down the `max-inline-size`;
    otherwise, if it uses `cq` units, it could get weird
    in Safari.
  */
  --_sw-max-size: round(
    down,
    max(
      0px,
      var(--_sw-limit)
    ),
    1px
  );

  /*
    Our shrinkwrapped box will behave as `content-box`,
    so we need to “enforce” the `content-box` here to
    prevent the double-counting of the extra space
    that could happen otherwise.
  */
  box-sizing: content-box !important;

  /*
    This can’t be changed from outside for the
    base technique.
  */
  flex-grow: 0 !important;
  /* Allow shrinking when the technique is disabled. */
  flex-shrink:
    var(--sw-enabled--on, 0)
    var(--sw-enabled--off, 1)
    !important
  ;
  /* Don’t limit the max size when disabled. */
  max-inline-size:
    var(--sw-enabled--on, none)
    var(--sw-enabled--off, var(--_sw-limit))
    !important
  ;
}

.shrinkwrap-content {
  /* Must be specifically `block`, nothing else. */
  display: block;

  /* Required for establishing the view timeline. */
  overflow: hidden;

  /*
    Required for getting non-anchored positioning
    dimensions.
  */
  position: relative;

  /*
    Crucial part: the content element should always
    be max-sized and independent of anything else,
    unless the technique is disabled.
  */
  inline-size: var(--sw-enabled--on, var(--_sw-max-size));

  /* Makes shrinking not be hidden by the overflow. */
  min-inline-size: min-content;

  /*
    The following styles should only apply for the
    browsers that support `timeline-scope`, which is
    currently the furthest from being implemented in
    Firefox on 2026-01-26.
  */
  @supports (timeline-scope: --f) {
    /* Guard by the cyclic toggle. */
    inset-inline-start: var(--sw-enabled--on,
      min(
        0px,
        var(--_sw-x-start) * var(--_sw-resolution)
        -
        var(--_sw-max-size)
      )
    );
  }
}

.shrinkwrap-source {
  anchor-name: var(--sw-source, --_sw-source);

  /*
    Must be specifically `inline` by default.
    Allows anchor positioning to measure it’s size
    and its offset.
  */
  @layer defaults {
    display: inline;
  }
}

/*
  Creating the “probing” element that will be used to
  measure the source element’s dimensions and offset.
*/
@supports (timeline-scope: --f) {
  /*
    We cannot use `::before` here due to a WebKit bug:
    https://bugs.webkit.org/show_bug.cgi?id=302703
  */
  .shrinkwrap-probe {
    position: absolute;
    /* Could also be `visibility: hidden` in production. */
    pointer-events: none;

    /* Anchoring to the source element. */
    position-anchor: var(--sw-source, --_sw-source);

    /* Not strictly required, but better to be explicit. */
    inset-block: 0;
    /* Key part for calculating the text-align offset. */
    inset-inline: var(--sw-inset, anchor(inside, 0px));
    /* Accounting for the inner spacing if needed. */
    margin: calc(-1 * var(--sw-inner-padding, 0px));

    /* Exposes the element to the scope on an ancestor. */
    view-timeline: --_sw-x inline;
  }
}

/*
  Custom properties that will be applied via scroll-driven
  animations, with the value from 0 to 1.
*/
@property --_sw-x-end {
  syntax: "&amp;lt;number&amp;gt;";
  initial-value: 0;
  inherits: true;
}
@property --_sw-x-start {
  syntax: "&amp;lt;number&amp;gt;";
  initial-value: 0;
  inherits: true;
}

/* The keyframes that deliver their values. */
@keyframes --_sw-x-end {
  0%   { --_sw-x-end: 0 }
  100% { --_sw-x-end: 1 }
}
@keyframes --_sw-x-start {
  0%   { --_sw-x-start: 0 }
  100% { --_sw-x-start: 1 }
}
&lt;/code&gt;
    &lt;head rend="h4"&gt;Simple Caseanchor&lt;/head&gt;
    &lt;p&gt;Let’s look at the case from “The Problem” section again:&lt;/p&gt;
    &lt;p&gt;And now, let’s apply our base technique to it:&lt;/p&gt;
    &lt;p&gt;It works! But how did we achieve this?&lt;/p&gt;
    &lt;p&gt;Here is the HTMLGo to a sidenote needed for the technique. Instead of just one element, we need to have a pretty specificGo to a sidenote nested structure:&lt;/p&gt;
    &lt;p&gt; Side note: All the CSS that we had to add for this specific example is &lt;code&gt;--sw-padding: var(--inline-padding)&lt;/code&gt; — I will explain this in the base technique’s CSS API later. Jump to this sidenote’s context.
&lt;/p&gt;
    &lt;p&gt; Side note: Obviously, the &lt;code&gt;h5&lt;/code&gt; here is just for this example; otherwise it could be a &lt;code&gt;p&lt;/code&gt;, &lt;code&gt;span&lt;/code&gt;, or anything else that fits your use case. Jump to this sidenote’s context.
&lt;/p&gt;
    &lt;code&gt;&amp;lt;h5 class="shrinkwrap"&amp;gt;
  &amp;lt;span class="shrinkwrap-content"&amp;gt;
    &amp;lt;span class="shrinkwrap-source"&amp;gt;
      &amp;lt;!-- Text --&amp;gt;
    &amp;lt;/span&amp;gt;
    &amp;lt;span class="shrinkwrap-probe"&amp;gt;&amp;lt;/span&amp;gt;
  &amp;lt;/span&amp;gt;
&amp;lt;/h5&amp;gt;
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;shrinkwrap&lt;/code&gt;is our topmost wrapper element — one that will receive the final dimensions.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;shrinkwrap-content&lt;/code&gt;is the inner wrapper that usually will be wider than its parent and will determine how the text content inside will wrap.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;shrinkwrap-source&lt;/code&gt;is the additional wrapper around our inline content, which we will target with anchor positioning.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;shrinkwrap-probe&lt;/code&gt;is our anchored element that will measure the&lt;code&gt;shrinkwrap-source&lt;/code&gt;and which will communicate its dimensions to the&lt;code&gt;shrinkwrap&lt;/code&gt;via scroll-driven animations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The core idea is relatively simple. To stealGo to a sidenote a Doctor Who metaphor from Amelia Bellamy-Royds:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We want a box that is bigger on the inside than out.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That’s precisely what we’re doing with our technique.&lt;/p&gt;
    &lt;p&gt;If you read my previous article on this topic, you might wonder, wouldn’t that previous technique that involved just anchor positioning be enough?&lt;/p&gt;
    &lt;p&gt;The problem with that older technique was that it would only position the anchored element around our inline element — and this would not impact the actual element’s dimensions or position in any way, making the setup pretty awkward.&lt;/p&gt;
    &lt;p&gt;For example, we would not be able to make the text inside this header be still left-aligned while centering the header itself:&lt;/p&gt;
    &lt;p&gt;The new technique gave the parent &lt;code&gt;shrinkwrap&lt;/code&gt; element the correct dimensions, making it possible to continue using CSS as usual, without trying to “fake” its visuals through an external anchored element.&lt;/p&gt;
    &lt;p&gt;I will omit explaining some styles and will trim various calculations — you can find them in the full code, but in these sections I want to give the general overview of the code involved in the technique.&lt;/p&gt;
    &lt;head rend="h5"&gt;Styles for the Top Wrapperanchor&lt;/head&gt;
    &lt;p&gt;Our top &lt;code&gt;shrinkwrap&lt;/code&gt; wrapper has a few important partsGo to a sidenote in its CSS:&lt;/p&gt;
    &lt;code&gt;.shrinkwrap {
  /* 1. Setting up overrideable custom properties. */
  @layer defaults {/*…*/}

  /* 2. Base styles: some other values are allowed. */
  display:  block;
  overflow: hidden;

  /* 3. Scroll-driven animations for remote measuring. */
  timeline-scope:     /* One timeline   */;
  animation:          /* Two animations */;
  animation-range:    /* Two ranges     */;
  animation-timeline: /* One timeline   */;

  /* 4. Applying the measured dimensions to the element. */
  inline-size:     /* Cyclic-toggled value. */;
  min-inline-size: max(/*…*/);

  /* 5. Some important resets. */
  box-sizing: content-box !important;
  flex-grow:  0 !important;
  flex-shrink:     /* Cyclic-toggled value */;
  max-inline-size: /* Cyclic-toggled value */;
}
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;We use layers and custom properties for defining the CSS API of our technique.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Our topmost element should have a normal flow:&lt;/p&gt;&lt;code&gt;block&lt;/code&gt;or&lt;code&gt;inline-block&lt;/code&gt;will work, as well as it being inside a flex or grid context, but the element itself can’t establish a grid or flex.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The key part: we use scroll-driven animations to retrieve the dimensions of our inner element. I will expand on this a bit more in a later “Remote Dimensions Measuring” section.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Second key part: applyingGo to a sidenote the measured dimensions to our element. The&lt;/p&gt;&lt;code&gt;inline-size&lt;/code&gt;and&lt;code&gt;min-inline-size&lt;/code&gt;will be calculated based on variables that will be applied via scroll-driven animations.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I also included a few properties that we should never really change for our parent element, as we are sizing it in a very specific way. This part might be adjusted: we could add more properties there or find use cases in which these properties could play a role and require overriding.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Styles for the Content Wrapperanchor&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;shrinkwrap-content&lt;/code&gt; is that “inner box” that might be bigger than the actual &lt;code&gt;shrinkwrap&lt;/code&gt; elementGo to a sidenote.&lt;/p&gt;
    &lt;code&gt;.shrinkwrap-content {
  /* 1. Base styles. */
  display:  block;
  overflow: hidden;

  /* 2. Inner box’ dimensions. */
  inline-size:     /*…*/;
  min-inline-size: min-content;
}
&lt;/code&gt;
    &lt;p&gt;The styles for the inner box are (for now) simple:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;We need to have some base styles — again, we need to make sure we use a normal flow, and specifically&lt;/p&gt;&lt;code&gt;overflow: hidden&lt;/code&gt;, as scroll-driven animations will rely on its presence on this element.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;We have to set the dimensions of our element in a pretty specific way. It will reuse several “private” custom properties that we set on the wrapper and which are based on the custom properties defined by our technique’s API. The&lt;/p&gt;&lt;code&gt;inline-size&lt;/code&gt;here is the most important part: the way we size it (by default with&lt;code&gt;100cqi&lt;/code&gt;) makes it so it is independent of the&lt;code&gt;shrinkwrap&lt;/code&gt;’s dimensions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Styles for the Sourceanchor&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;shrinkwrap-source&lt;/code&gt; isGo to a sidenote one of the more simple elements:&lt;/p&gt;
    &lt;code&gt;.shrinkwrap-source {
  anchor-name: var(/*…*/);

  @layer defaults {
    display: inline;
  }
}
&lt;/code&gt;
    &lt;p&gt;This element will provide the &lt;code&gt;anchor-name&lt;/code&gt; used for our technique, which might be reassigned via the custom properties API.&lt;/p&gt;
    &lt;p&gt;Then, we need it to be inline by default, as this is what we rely on when measuring our element. However, there are use cases where we are not measuring inline elements, so we apply this style weakly and allow overriding externally.&lt;/p&gt;
    &lt;head rend="h5"&gt;Styles for the Probeanchor&lt;/head&gt;
    &lt;p&gt;Finally, we have our &lt;code&gt;shrinkwrap-probe&lt;/code&gt; element:&lt;/p&gt;
    &lt;code&gt;@supports (timeline-scope: --f) {
  .shrinkwrap-probe {
    /* 1. Base styles. */
    position:       absolute;
    pointer-events: none;

    /* 2. Anchoring to the Source. */
    position-anchor: var(/*…*/);
    inset-block:     0;
    inset-inline:    calc(/*…*/);
    margin:          calc(/*…*/);

    /* Establishing the view timeline. */
    view-timeline: /*…*/;
  }
}
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;This is our absolutely positionedGo to a sidenote element that will measure the source element. We should remove the&lt;/p&gt;&lt;code&gt;pointer-events&lt;/code&gt;from it, as it should not interfere with our page in any way. An alternative could be to use&lt;code&gt;visibility: hidden&lt;/code&gt;, but I find it is much easier to keep it “visible” with just&lt;code&gt;pointer-events&lt;/code&gt;for easier debugging.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;We then anchor this element to the&lt;/p&gt;&lt;code&gt;shrinkwrap-source&lt;/code&gt;. Later techniques might override some of these, but by default we only care about the&lt;code&gt;inset-inline&lt;/code&gt;and use anchor positioning for defining it. Additionally, we’re using a&lt;code&gt;margin&lt;/code&gt;to optionally adjust the measured rectangle.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Finally, we need to establish an&lt;/p&gt;&lt;code&gt;inline&lt;/code&gt;view timeline, which will mean we could access it on the&lt;code&gt;shrinkwrap&lt;/code&gt;element via&lt;code&gt;timeline-scope&lt;/code&gt;and its&lt;code&gt;animation&lt;/code&gt;properties.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that we can also wrap this whole element with an &lt;code&gt;@supports&lt;/code&gt; — no reason to do anything with it unless &lt;code&gt;timeline-scope&lt;/code&gt; is supported.&lt;/p&gt;
    &lt;head rend="h4"&gt;Non-Left Text Alignmentanchor&lt;/head&gt;
    &lt;p&gt;The above styles would be enough for cases when we have just a left-aligned text, as our &lt;code&gt;shrinkwrap-source&lt;/code&gt;’s left boundary will be the same, and that would be enough to just shrink the &lt;code&gt;shrinkwrap&lt;/code&gt; element.&lt;/p&gt;
    &lt;p&gt;However, if we were to override the &lt;code&gt;text-align&lt;/code&gt; on our element, the following could happen:&lt;/p&gt;
    &lt;p&gt;Because our inner box is bigger than the outer, and the text is aligned inside that box, it is not enough to shrink the outer one — we need to also detectGo to a sidenote that offset between the &lt;code&gt;shrinkwrap-content&lt;/code&gt; and &lt;code&gt;shrinkwrap-source&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Thankfully, with the way we’re measuring our element, we can reuse the variables that our scroll-driven animation applies and adjust the position of our &lt;code&gt;shrinkwrap-content&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;/* Added to the other styles */
.shrinkwrap-content {
  position: relative;

  @supports (timeline-scope: --f) {
    inset-inline-start: min(/*…*/);
  }
}
&lt;/code&gt;
    &lt;p&gt;We makeGo to a sidenote our element &lt;code&gt;position: relative&lt;/code&gt;, and then use &lt;code&gt;inset-inline-start&lt;/code&gt; to adjust its position.&lt;/p&gt;
    &lt;p&gt;I imagine there could be other text edge cases that the base technique does not cover — if you’ll think of anything, please let me know!&lt;/p&gt;
    &lt;head rend="h4"&gt;Multiple Nested Phrasing Contentsanchor&lt;/head&gt;
    &lt;p&gt;While the base technique is limited to only shrinkwrapping elements with phrasing content, more complicated cases could be covered by reusing the technique multiple times for every instance of such content inside.&lt;/p&gt;
    &lt;p&gt;For example, we could have a list with several items, and then we’d want to put it into a card with its edges flush with the content of all items inside. For this, we can make our list the container and then wrap the contents of each list item with the technique and then size the card with &lt;code&gt;max-content&lt;/code&gt; — and it will just work! And if some list items have multiple paragraphs, we use the technique once per paragraph.&lt;/p&gt;
    &lt;p&gt;In short, we can use our base technique as a building block for anything that is more complex. The later sections expand on this base technique but adjust how we measure things and what exactly we are measuring.&lt;/p&gt;
    &lt;head rend="h4"&gt;Base Technique’s APIanchor&lt;/head&gt;
    &lt;p&gt;The HTML of the technique is a part of its API:&lt;/p&gt;
    &lt;code&gt;&amp;lt;div class="shrinkwrap"&amp;gt;
  &amp;lt;div class="shrinkwrap-content"&amp;gt;
    &amp;lt;span class="shrinkwrap-source"&amp;gt;
      &amp;lt;!-- Text --&amp;gt;
    &amp;lt;/span&amp;gt;
    &amp;lt;span class="shrinkwrap-probe"&amp;gt;&amp;lt;/span&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;shrinkwrap&lt;/code&gt;and the&lt;code&gt;shrinkwrap-content&lt;/code&gt;can be anything apart from the&lt;code&gt;div&lt;/code&gt;, but they can only have the&lt;code&gt;display: block&lt;/code&gt;(which is applied by the technique but should not be overridden).&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;shrinkwrap-source&lt;/code&gt;defines what we will be measuring, and by default has&lt;code&gt;display: inline&lt;/code&gt;. It is possible to apply it to some other element or skip this element completely if we’re overriding what we’re targeting with the&lt;code&gt;shrinkwrap-probe&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;shrinkwrap-probe&lt;/code&gt;is our measuring element, it must be strictly inside the&lt;code&gt;shrinkwrap-content&lt;/code&gt;, and by default is measuring the&lt;code&gt;shrinkwrap-source&lt;/code&gt;. We can override what the&lt;code&gt;shrinkwrap-probe&lt;/code&gt;is measuring by overriding its&lt;code&gt;inset&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Alongside HTML, we can define a set of CSS custom properties on the &lt;code&gt;shrinkwrap&lt;/code&gt; element:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;--sw-limit&lt;/code&gt;— the key custom property that has the default of&lt;code&gt;100cqi&lt;/code&gt;. We can use it when we want to place some other elements alongside ours on the same “row”. The above “Multiple Nested Phrasing Contents” use one such case, where we set it to, essentially,&lt;code&gt;50cqi - 3 * var(--gap) - var(--list-item-padding)&lt;/code&gt;— defining the maxGo to a sidenote limit that the text inside could take to be a half of the container, minus all the paddings and gaps that the surrounding layout has.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--sw-padding&lt;/code&gt;can be used when we have a uniform padding around the element that we’re sizing. We are in a something similar to the&lt;code&gt;box-sizing: content-box&lt;/code&gt;context when we’re using this technique, so we can use this custom property to communicate the possible adjustment. It is similar to using a&lt;code&gt;calc()&lt;/code&gt;inside a&lt;code&gt;--sw-limit&lt;/code&gt;, and often is a more simple way of handling the paddings, but more complex cases might be better solved with the calculated&lt;code&gt;--sw-limit&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--sw-inner-padding&lt;/code&gt;is a bit different, and might be mostly used for more complex cases that involve&lt;code&gt;--sw-inset&lt;/code&gt;or&lt;code&gt;--sw-source&lt;/code&gt;overrides. This is a custom property to account for any padding that could be present between the&lt;code&gt;shrinkwrap&lt;/code&gt;and the measured content inside the&lt;code&gt;shrinkwrap-content&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--sw-inset&lt;/code&gt;can be used to override the value of the&lt;code&gt;shrinkwrap-probe&lt;/code&gt;’s&lt;code&gt;inset&lt;/code&gt;, making it possible to anchor it to multiple elements for more complex cases like the “Multiple Explicit Anchors”. This is where the&lt;code&gt;--sw-inner-padding&lt;/code&gt;can also be useful, as it will be automatically used for calculations that can be trickier to achieve with the&lt;code&gt;inset&lt;/code&gt;shorthand. **Note: ** this custom property is used specifically for&lt;code&gt;inset-inline&lt;/code&gt;property, and not&lt;code&gt;inset&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--sw-source&lt;/code&gt;is for those rare cases where you’d want to override the&lt;code&gt;anchor-name&lt;/code&gt;of the&lt;code&gt;shrinkwrap-probe&lt;/code&gt;element. This can be useful for any complex techniques where the measured element lives outside the&lt;code&gt;shrinkwrap&lt;/code&gt;element, allowing us to “link” them. See my “Inline Custom Identifiers” blog post that covers this way of connecting elements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Remote Dimension Measuringanchor&lt;/head&gt;
    &lt;p&gt;I am using a technique, the basics of which I came up with somewhere in 2023, after publishing my second article about scroll-driven animations. I did not write about this technique anywhere yet, but had a few drafts with various use cases for it that I sometimes worked on in background.&lt;/p&gt;
    &lt;p&gt;Thankfully, someone else came up with a similar technique and wrote about it — it was Temani Afif and his “How to Get the Width/Height of Any Element in Only CSS” article from July 2024.&lt;/p&gt;
    &lt;p&gt;There is one difference between our techniques: Temani relies on the “measuring” element when it is at the beginning of the box, and then using its &lt;code&gt;1px&lt;/code&gt; dimension and its proportions relative to the scrollport to calculate that scrollport’s dimensions.&lt;/p&gt;
    &lt;p&gt;Because I am using anchor positioning to place my probing element at a very specific point — which I want to measure — I, instead, rely on a very high value of the &lt;code&gt;timeline-range&lt;/code&gt;, which I store in the &lt;code&gt;--resolution&lt;/code&gt; custom property.&lt;/p&gt;
    &lt;p&gt;When some view timeline then reports its position in this range, by knowing this “resolution” we can then retrieve that position through scoping the timeline to another element.&lt;/p&gt;
    &lt;p&gt;Here is the CSSGo to a sidenote responsible for the scroll-driven animations that I previously skimmed through:&lt;/p&gt;
    &lt;code&gt;.shrinkwrap {
  /* Lifting the scope of view timelines from inside. */
  timeline-scope: --_sw-x;

  /*
    Accessing the start and end coordinates of the
    inner element via scroll-driven animations.
    Only apply when the technique is enabled.
  */
  animation: var(--sw-enabled--on,
    --_sw-x-start linear both,
    --_sw-x-end   linear both
  );

  /*
    We will be using the “resolution” as a range to
    retrieve the width of various things.
  */
  --_sw-resolution: 10000px;
  animation-range:
    0               var(--_sw-resolution),
    contain contain var(--_sw-resolution);
  animation-timeline: --_sw-x;

  /*
    Calculating the actual size from the variables applied
    via the animation with the given resolution.
  */
  --_sw-size:
    (var(--_sw-x-start) - var(--_sw-x-end))
    *
    var(--_sw-resolution)
  ;
  /*
    For the main size, clamp the result within limits,
    and guard everything with a space toggle.
  */
  inline-size: var(--sw-enabled--on,
    clamp(
      0px,
      var(--_sw-size),
      var(--_sw-max-size)
    )
  );
  /* Min-size should not be clamped. */
  min-inline-size: max(
    0px,
    var(--_sw-size)
  );
}

.shrinkwrap-content {
  @supports (timeline-scope: --f) {
    /* Guard by the cyclic toggle. */
    inset-inline-start: var(--sw-enabled--on,
      min(
        0px,
        var(--_sw-x-start) * var(--_sw-resolution)
        -
        var(--_sw-max-size)
      )
    );
  }
}

@supports (timeline-scope: --f) {
  .shrinkwrap-probe {
    /* Exposes the element to the scope on an ancestor. */
    view-timeline: --_sw-x inline;
  }
}

/*
  Custom properties that will be applied via scroll-driven
  animations, with the value from 0 to 1.
*/
@property --_sw-x-end {
  syntax: "&amp;lt;number&amp;gt;";
  initial-value: 0;
  inherits: true;
}
@property --_sw-x-start {
  syntax: "&amp;lt;number&amp;gt;";
  initial-value: 0;
  inherits: true;
}

/* The keyframes that deliver their values. */
@keyframes --_sw-x-end {
  0%   { --_sw-x-end: 0 }
  100% { --_sw-x-end: 1 }
}
@keyframes --_sw-x-start {
  0%   { --_sw-x-start: 0 }
  100% { --_sw-x-start: 1 }
}
&lt;/code&gt;
    &lt;p&gt;I am planning to write a separate article that will explain how this dimension measuring works in detail, and I would rather not repeat myself in this one (and make it even longer).&lt;/p&gt;
    &lt;p&gt;So — stay tuned for that next article!&lt;/p&gt;
    &lt;head rend="h3"&gt;A Crashing Safari Buganchor&lt;/head&gt;
    &lt;p&gt;As mentioned in the disclaimer, this technique is very experimental, and the CSS features it relies on are pretty new, and can sometimes cause issues even though they’re there in the “stable” versions of major browsers.&lt;/p&gt;
    &lt;p&gt;Initially, I was creating the probing elements as pseudo-elements, but while testing my article, I found that in certain conditions my article was crashing its tab in Safari.&lt;/p&gt;
    &lt;p&gt;After reducing the code to its minimal reproductionGo to a sidenote, I found that the probing element being a pseudo-element was one of the conditions for the crash to happen, so I adjusted the technique by replacing it with a real element.&lt;/p&gt;
    &lt;p&gt;Initially, my technique also had another pseudo-element that did not trigger the issue, but I managed to simplify my technique to allow doing both measurements from the single additional element.&lt;/p&gt;
    &lt;head rend="h3"&gt;Solving for Complex Contentanchor&lt;/head&gt;
    &lt;p&gt;The base technique works for the simple case where our source element has phrasing content: only &lt;code&gt;inline&lt;/code&gt; (and &lt;code&gt;inline-…&lt;/code&gt;) elements inside.&lt;/p&gt;
    &lt;p&gt;But what about more complex cases, like when we have multiple items inside wrapping flexbox, grids, etc?&lt;/p&gt;
    &lt;p&gt;The simpler cases which we could separate into several independent phrasing contexts can be solved by repeating the base technique — see “Multiple Nested Phrasing Contents”, but not everything can be done this way.&lt;/p&gt;
    &lt;head rend="h4"&gt;Multiple Explicit Anchorsanchor&lt;/head&gt;
    &lt;p&gt;I covered this use case and a few of my approaches to a solution in my previous article, in a “Wrapping Flex Items” section, but the new technique improves on those.&lt;/p&gt;
    &lt;p&gt;In short, if we have a wrapping list of items, either inside a grid or a flex container, if we know the number of items, then we can assign a unique anchor to every item and then use a &lt;code&gt;min()&lt;/code&gt; function involving all the anchors to find the “furthest” element that could be used to determine our shrinkwrapped dimension.&lt;/p&gt;
    &lt;p&gt;Because I abstracted the measuring into a separate element, implementing this is as easy as doing the followingGo to a sidenote (after stripping visual styles unrelated to the technique):&lt;/p&gt;
    &lt;code&gt;li {
  padding:     var(--padding);
  anchor-name: var(--is);
}

.shrinkwrap {
  --sw-inner-padding: var(--padding);
  --sw-inset:
    min(
      anchor(--a inside, calc(infinity * 1px)),
      anchor(--b inside, calc(infinity * 1px)),
      anchor(--c inside, calc(infinity * 1px)),
      anchor(--d inside, calc(infinity * 1px)),
      anchor(--e inside, calc(infinity * 1px)),
      anchor(--f inside, calc(infinity * 1px)),
      anchor(--g inside, calc(infinity * 1px))
    )
  ;
}
&lt;/code&gt;
    &lt;p&gt;And the HTML is pretty simple: we wrap our list with our shrinkwrap technique:&lt;/p&gt;
    &lt;code&gt;&amp;lt;div class="shrinkwrap"&amp;gt;
  &amp;lt;div class="shrinkwrap-content"&amp;gt;
    &amp;lt;ul&amp;gt;
      &amp;lt;li style="--is: --a"&amp;gt;
        An item
      &amp;lt;/li&amp;gt;
      &amp;lt;!-- the rest of the items  --&amp;gt;
    &amp;lt;/ul&amp;gt;
    &amp;lt;span class="shrinkwrap-probe"&amp;gt;&amp;lt;/span&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Because what we’re measuring is not inline, we are not using the &lt;code&gt;shrinkwrap-source&lt;/code&gt; class that would assign the target that we measure; that’s where the &lt;code&gt;--sw-inset&lt;/code&gt; custom property comes into play: we can use it to reassign how the &lt;code&gt;shrinkwrap-probe&lt;/code&gt; will be positioned by overriding its &lt;code&gt;inset&lt;/code&gt; property, and thus what exactly it will measure.&lt;/p&gt;
    &lt;p&gt;The only thing that we need to do here is use the &lt;code&gt;min()&lt;/code&gt; function and pass all items’ anchors inside, making it possible to compare the inset positions of all the items and choose those that make the biggest bounding box.&lt;/p&gt;
    &lt;p&gt;In addition to this, we can use the &lt;code&gt;--sw-inline-padding&lt;/code&gt; to accommodate the padding around items, which, in this case, is much easier to do than adding a calculation to the &lt;code&gt;min()&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h4"&gt;Chained Anchors Abominationanchor&lt;/head&gt;
    &lt;p&gt;Of course, the above code relies on knowing the number of elements, assigning the unique anchor identifiers to them, and then listing all of them inside a &lt;code&gt;min()&lt;/code&gt;. But what if I tell you that we could achieve this without doing so?&lt;/p&gt;
    &lt;p&gt;Well, we can, but, for now, this works only in Chrome — this relies on the ability to chain multiple anchors together, and that currently only works reliably in Chrome, while Safari and Firefox have pretty serious bugsGo to a sidenote with that behavior.&lt;/p&gt;
    &lt;p&gt;This time, HTML is a bit more simple in one way (no unique idents), but more complex in another (additional probe elements, two per item):&lt;/p&gt;
    &lt;code&gt;  &amp;lt;div class="shrinkwrap"&amp;gt;
    &amp;lt;div class="shrinkwrap-content"&amp;gt;
      &amp;lt;ol&amp;gt;
        &amp;lt;li&amp;gt;
          An item
          &amp;lt;div class="probe-left"&amp;gt;&amp;lt;/div&amp;gt;
          &amp;lt;div class="probe-right"&amp;gt;&amp;lt;/div&amp;gt;
        &amp;lt;/li&amp;gt;
        &amp;lt;!-- the rest of the elements  --&amp;gt;
      &amp;lt;/ol&amp;gt;
      &amp;lt;div class="shrinkwrap-probe"&amp;gt;&amp;lt;/div&amp;gt;
    &amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
    &lt;p&gt;You can see how, alongside the &lt;code&gt;shrinkwrap-probe&lt;/code&gt; element, each element has its two &lt;code&gt;probe-left&lt;/code&gt; and &lt;code&gt;probe-right&lt;/code&gt; elements.&lt;/p&gt;
    &lt;p&gt;But how, without a &lt;code&gt;min()&lt;/code&gt;, can we use this to measure the bounding box for all elements without explicitly mentioning them?&lt;/p&gt;
    &lt;p&gt;Here is the CSSGo to a sidenote responsible for this:&lt;/p&gt;
    &lt;code&gt;li {
  anchor-name:  --li;
  anchor-scope: --li;
}

.probe-left,
.probe-right {
  position:       absolute;
  pointer-events: none;
  inset:          anchor(--li inside);
  container-type: inline-size;

  &amp;amp;::before {
    content:  "";
    position: absolute;
    inset:    0;
  }
}

.probe-left {
  left:  anchor(--li left, 0);
  right: anchor(--leftmost left, anchor(--li right));

  @container (min-width: 1px) {
    &amp;amp;::before {
      anchor-name: --leftmost;
    }
  }
}

.probe-right {
  left:  anchor(--rightmost right, anchor(--li left));
  right: anchor(--li right, 0);

  @container (min-width: 1px) {
    &amp;amp;::before {
      anchor-name: --rightmost;
    }
  }
}

.shrinkwrap {
  --sw-inner-padding: 1em
  --sw-inset:
    anchor(--leftmost  left)
    anchor(--rightmost right)
  ;
}
&lt;/code&gt;
    &lt;p&gt;Starting from the end — as we don’t have a &lt;code&gt;shrinkwrap-source&lt;/code&gt;, we override &lt;code&gt;--sw-inset&lt;/code&gt; to get the insets from the leftmost and rightmost items, which will be determined later.&lt;/p&gt;
    &lt;p&gt;Then, we can assign a scoped anchor name to our items:&lt;/p&gt;
    &lt;code&gt;li {
  anchor-name:  --li;
  anchor-scope: --li;
}
&lt;/code&gt;
    &lt;p&gt;We need to scope it so the probe elements inside the items would see the correct anchors; otherwise, they could look up at the last one they see.&lt;/p&gt;
    &lt;p&gt;What we do next is pretty fun: we use this parent &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt; as the anchor for the nested probes via &lt;code&gt;inset: anchor(--li inside)&lt;/code&gt; on them and also make these probes inline containers via &lt;code&gt;container-type: inline-size&lt;/code&gt;, which makes it possible to query them on inner pseudo-elements.&lt;/p&gt;
    &lt;p&gt;Then, we do this for the probe that measures the right edge of our boundary box (and mirror it for the &lt;code&gt;probe-left&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;.probe-right {
  left:  anchor(--rightmost right, anchor(--li left));
  right: anchor(--li right, 0);

  @container (min-width: 1px) {
    &amp;amp;::before {
      anchor-name: --rightmost;
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;We rely on an ability to “chain” the anchorsGo to a sidenote: anchor to the previous valid anchor target among multiple that share the name. Then we can use container queries to check if our probe has a positive width — that would mean that its edge is to the right from the previous rightmost probe.&lt;/p&gt;
    &lt;p&gt;In a way, this is an algorithm for determining the maximum value of something expressed via pure layout — anchor positioning and container queries! It relies on the order the elements are laid out: the later elements can anchor to earlier elements, so they can use the dynamic anchor names that are applied inside container queries.&lt;/p&gt;
    &lt;p&gt;If it is difficult to understand what is going on, highlighting those &lt;code&gt;probe-left&lt;/code&gt; and &lt;code&gt;probe-right&lt;/code&gt; elements could help:&lt;/p&gt;
    &lt;p&gt;Going with elements one by one, we position both probes on both sides, each going from the edge of the last pseudo-element that was placed into a positive container query or falling back to the first element’s dimensions. This makes it so, going through all elements, we will create “steps” out of our probes, where only the rightmost and leftmost ones will have positive dimensions.&lt;/p&gt;
    &lt;p&gt;Too bad Safari and Firefox don’t work well with chaining just yet…&lt;/p&gt;
    &lt;head rend="h3"&gt;Cross-Dependencies: Menu Use Caseanchor&lt;/head&gt;
    &lt;p&gt;The final and the hardest use case I want to cover is something like a navigation menu, in which all elements should participate in a single flex context, and with these elements shrinking if there is not enough space for them.&lt;/p&gt;
    &lt;p&gt;If we take some horizontal menu with just a few shorter items, then everything looks fine when all items fit in:&lt;/p&gt;
    &lt;p&gt;But here is what happens when the items are longer, there are more of them, and not enough space to have them all without wrapping:&lt;/p&gt;
    &lt;p&gt;At the core, this is the same issue as with the other shrinkwrap problems: once wrapped, the element tries to take as much space as it can, and when there are multiple elements fighting for that space, it will be re-distributed.&lt;/p&gt;
    &lt;p&gt;It would’ve been great if the base technique I presented above could work for that case. But it doesn’t: for the base technique to work, we have to know the limits in which we’re working, but when our element depends on all other elements and shrinks proportionally based on all the extra elements present around, we cannotGo to a sidenote achieve it with what we have for now.&lt;/p&gt;
    &lt;p&gt;The only way to solve it that I found is with content duplication: first, we can render our menu as regular but hidden, measure the wrapped elements, and then transfer their dimensions to the visible copy, one by one.&lt;/p&gt;
    &lt;p&gt;The whole setup can then be placed inside another instance of our base technique, so we could collapse the whole menu and allow elements around it to stretch over the space that we gain.&lt;/p&gt;
    &lt;p&gt;Here is what it can look like when adding a few more elements to the example:&lt;/p&gt;
    &lt;p&gt;While I managed to make it work in this case, I found that there are more problems with these kinds of menus. If you resize it, on narrower screens, things become pretty bad. Some container queries and switching up the layout could work, and there are things that could be improved with this solution further.&lt;/p&gt;
    &lt;p&gt;I won’t provide a more detailed explanation of how this works and won’t show any code, at least for now: it is very fragile, and maybe once I play with this type of layout more, I could see a better way to apply my technique. Or come up with something else.&lt;/p&gt;
    &lt;p&gt;But what this demonstrates is that the complex cases are complex, and while it is possible to come closer to solving them, there are still many unknowns over how exactly they should be solved.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some Other Use Casesanchor&lt;/head&gt;
    &lt;p&gt;Before I end the article, I don’t want it to stop on the sourer note with the previous not fully solved case. So, let’s return to some examples from my last article on shrinkwrap, and demonstrate how the new technique solves them much better. Plus, I’ll add another two use cases that I did not cover in my previous article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Chat Bubblesanchor&lt;/head&gt;
    &lt;p&gt;One of my favorite examples is the chat bubbles — you can see this everywhere, from phone apps to video games. I imagine native frameworks have their ways of doing this, but on the web we could not achieve this look with just CSS until now.&lt;/p&gt;
    &lt;p&gt;The implementation of this is so much simpler than what I had to do when trying to fake it by anchor-positioning the bubble’s background separately! Now we just give &lt;code&gt;max-width: max-content&lt;/code&gt; to the blockquotes inside and then wrap each paragraph with our technique, like that:&lt;/p&gt;
    &lt;code&gt;&amp;lt;blockquote&amp;gt;
  &amp;lt;p class="shrinkwrap"&amp;gt;
    &amp;lt;span class="shrinkwrap-content"&amp;gt;
      &amp;lt;span class="shrinkwrap-source"&amp;gt;
        Hello, there!
      &amp;lt;/span&amp;gt;
      &amp;lt;span class="shrinkwrap-probe"&amp;gt;&amp;lt;/span&amp;gt;
    &amp;lt;/span&amp;gt;
  &amp;lt;/p&amp;gt;
&amp;lt;/blockquote&amp;gt;
&lt;/code&gt;
    &lt;p&gt;And then the only extra CSS that we have to add is the definition of the &lt;code&gt;--sw-limit&lt;/code&gt; and &lt;code&gt;--sw-padding&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;.example-bubbles .shrinkwrap {
  --sw-padding: var(--padding-inline);
  --sw-limit: calc(
    100cqi
    -
    (
      var(--margin-start)
      +
      var(--margin-end)
    )
  );
}
&lt;/code&gt;
    &lt;p&gt;We have to account for all the paddings and margins we can have and add &lt;code&gt;inline-size&lt;/code&gt; containment on our example wrapper, but otherwise this shows how much easier it is to use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fieldsets and Legendsanchor&lt;/head&gt;
    &lt;p&gt;In the corresponding example in my previous article on this topic, I relied on the legend expanding and then re-adding the borders, faking them via added pseudo-elements.&lt;/p&gt;
    &lt;p&gt;The below &lt;code&gt;legend&lt;/code&gt; is using the new technique and doesn’t have any faked bordersGo to a sidenote. It fully relies on the “magic” behavior of the native &lt;code&gt;fieldset&lt;/code&gt; and &lt;code&gt;legend&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;And, again, this example shows how &lt;code&gt;text-wrap: balance&lt;/code&gt; could improve things, but only if we could shrinkwrap it natively.&lt;/p&gt;
    &lt;head rend="h3"&gt;Overlay Image Captionsanchor&lt;/head&gt;
    &lt;p&gt;This use case wasn’t in my first post about shrinkwrap but was provided by Johannes Odland to me in a private conversation, where he mentioned that they had cases like this at NRK.&lt;/p&gt;
    &lt;p&gt;Let’s say we want to have a figure with an image and want to put the caption on top of it with a semi-opaque background that is flush to the caption’s text so we could minimize the area it covers. As with other cases, when the text is short, everything is ok, but when it wraps, it will span all the available space. Shrinkwrapping will help with this a lot!&lt;/p&gt;
    &lt;head rend="h3"&gt;Tooltipsanchor&lt;/head&gt;
    &lt;p&gt;The last use case I’ll show in this article is one that we have in Datadog, and that is likely familiar to anyone dealing with design systems — tooltips and popovers. Pretty often you want the content in them to be nice and balanced, but have a certain limit, usually much smaller than the width of the viewport. Without shrinkwrapping, this can lead to rather ugly results. But our technique allows creating pretty and neat tooltips.&lt;/p&gt;
    &lt;p&gt;This is the tooltip’s content that wraps over several lines.&lt;/p&gt;
    &lt;p&gt;It is always shown, as this is a demo, so the button before it doesn’t really do anything.&lt;/p&gt;
    &lt;p&gt;I wish the HTML for the technique was as pretty as the result — while all the demos above show how it works, it is hardly easily applicable for user-generated content, and even when you have full control over your HTML, it can be pretty cumbersome.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Next?anchor&lt;/head&gt;
    &lt;p&gt;To me, it is clear that the most basic use cases — when we know the max-inline-size our element can take — should be achievable in browsers with either a new property or a new function that could be used for size properties. It might require containment or something similar, as there is still a chance the percentage-based dimensions could lead to some circularities. But even with the required containment, what this will allow us to achieve will cover so many things people wanted to do for more than a decade now.&lt;/p&gt;
    &lt;p&gt;I don’t think we need to pursue solving the menu case (cross-dependent shrinkwrapping) for now — it is a much, much more complicated layout. But I believe if we work out the simple cases first, we could crunch on those low-hanging fruits and see if we could make some more complex jams out of them later.&lt;/p&gt;
    &lt;p&gt;I will post a link to this article and my proposal to explore the simpler solution todayGo to a sidenote in the corresponding CSSWG issue, and if you had stumbled upon this problem before and have any specific use cases, bring them up and maybe even see if my technique will cover them.&lt;/p&gt;
    &lt;p&gt;And I will also be working on another article — one that will cover my method of remote dimension measuring technique, so stay tuned for that and more! Although, likely, it won’t be anywhere soon, as these articles take a long time to research and write.&lt;/p&gt;
    &lt;p&gt;Published on with tags: #Anchor Positioning #Scroll Driven Animations #Future CSS #Experiment #CSS&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kizu.dev/shrinkwrap-solution/"/><published>2026-02-06T03:19:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46909037</id><title>Show HN: Artifact Keeper – Open-Source Artifactory/Nexus Alternative in Rust</title><updated>2026-02-06T18:03:07.367084+00:00</updated><content>&lt;doc fingerprint="85f15bf9b9b7724d"&gt;
  &lt;main&gt;
    &lt;p&gt;Your packages. Your servers. Your freedom.&lt;/p&gt;
    &lt;p&gt;Website · Docs · Live Demo · MIT Licensed&lt;/p&gt;
    &lt;p&gt;A full-featured, enterprise-grade artifact registry you can self-host in minutes. Drop-in replacement for JFrog Artifactory and Sonatype Nexus with zero feature gates — security scanning, SSO, replication, all 45+ package formats — everything ships in the open-source release.&lt;/p&gt;
    &lt;p&gt;No open-core. No "enterprise edition." No surprise invoices.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Repository&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Stack&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;artifact-keeper&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Backend server, CLI, and Docker deployment&lt;/cell&gt;
        &lt;cell&gt;Rust, Axum, PostgreSQL, Meilisearch&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;artifact-keeper-web&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Web frontend&lt;/cell&gt;
        &lt;cell&gt;Next.js 15, TypeScript, Tailwind CSS, shadcn/ui&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;artifact-keeper-ios&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;iOS &amp;amp; macOS app&lt;/cell&gt;
        &lt;cell&gt;SwiftUI, Swift 6, Alamofire&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;artifact-keeper-android&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Android app&lt;/cell&gt;
        &lt;cell&gt;Jetpack Compose, Kotlin, Material 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;artifact-keeper-api&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;OpenAPI 3.1 spec (165 endpoints)&lt;/cell&gt;
        &lt;cell&gt;TypeScript + Rust SDK generation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;artifact-keeper-example-plugin&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Example WASM plugin (Unity .unitypackage)&lt;/cell&gt;
        &lt;cell&gt;Rust, WIT, Wasmtime&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;45+ Package Formats — Native protocol support. Not a generic blob store with format labels. Your package managers (&lt;code&gt;pip install&lt;/code&gt;, &lt;code&gt;npm install&lt;/code&gt;, &lt;code&gt;docker pull&lt;/code&gt;, &lt;code&gt;cargo add&lt;/code&gt;, &lt;code&gt;helm install&lt;/code&gt;, &lt;code&gt;go get&lt;/code&gt;, etc.) talk directly to Artifact Keeper using their native protocols.&lt;/p&gt;
    &lt;p&gt;Security Scanning — Automated vulnerability detection with Trivy and Grype. Policy engine with severity thresholds, quarantine workflows, and scan-before-download enforcement.&lt;/p&gt;
    &lt;p&gt;WASM Plugin System — Extend with custom format handlers via WebAssembly. Ship your own package format support without forking the backend.&lt;/p&gt;
    &lt;p&gt;Edge Replication — Mesh-based artifact distribution with swarm sync and P2P transfers between nodes. Put caches close to your build agents.&lt;/p&gt;
    &lt;p&gt;SSO &amp;amp; Multi-Auth — OpenID Connect, LDAP, SAML 2.0, JWT, and API tokens. RBAC with per-repository permissions.&lt;/p&gt;
    &lt;p&gt;Artifactory Migration — Built-in tooling to migrate repositories, artifacts, users, and permissions from JFrog Artifactory. One command.&lt;/p&gt;
    &lt;p&gt;Full-Text Search — Meilisearch-powered search across all repositories, packages, and artifact metadata.&lt;/p&gt;
    &lt;p&gt;Manage your registries from anywhere. Monitor builds, browse repositories, trigger security scans, and administer users — all from native mobile apps with adaptive layouts.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Android&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;iOS&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;A full management interface for repositories, packages, security policies, user administration, SSO configuration, replication topology, and operational analytics.&lt;/p&gt;
    &lt;code&gt;# Clone and start with Docker Compose
git clone https://github.com/artifact-keeper/artifact-keeper.git
cd artifact-keeper
docker compose up -d

# That's it. Visit http://localhost:9080&lt;/code&gt;
    &lt;p&gt;Or pull the pre-built images directly:&lt;/p&gt;
    &lt;code&gt;# Backend (required)
docker pull ghcr.io/artifact-keeper/artifact-keeper-backend:latest

# Web dashboard (recommended)
docker pull ghcr.io/artifact-keeper/artifact-keeper-web:latest&lt;/code&gt;
    &lt;p&gt;Full deployment guides for Docker, Kubernetes, and AWS are in the docs.&lt;/p&gt;
    &lt;code&gt;graph TB
    subgraph Clients["Clients"]
        CLI["CLI &amp;amp; Package Managers&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;pip · npm · docker · cargo&amp;lt;br/&amp;gt;helm · go · maven · ...&amp;lt;/sub&amp;gt;"]
        WebApp["Web Dashboard&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Next.js 15 · Desktop Browser&amp;lt;/sub&amp;gt;"]
        iOS["iPhone · iPad · Mac&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;SwiftUI · Swift 6&amp;lt;/sub&amp;gt;"]
        Android["Android Phone · Tablet&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Jetpack Compose · Kotlin&amp;lt;/sub&amp;gt;"]
    end

    subgraph Core["Artifact Keeper Backend"]
        API["REST API Gateway&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Rust · Axum&amp;lt;/sub&amp;gt;"]
        Handlers["45+ Format Handlers&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Native protocol support&amp;lt;/sub&amp;gt;"]
        WASM["WASM Plugin Runtime&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Wasmtime · WIT&amp;lt;/sub&amp;gt;"]
        Auth["Auth Engine&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;OIDC · LDAP · SAML · JWT&amp;lt;/sub&amp;gt;"]
        Policy["Policy Engine&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Severity gates · Quarantine&amp;lt;/sub&amp;gt;"]
    end

    subgraph Data["Data Layer"]
        PG[("PostgreSQL 16&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Metadata &amp;amp; config&amp;lt;/sub&amp;gt;")]
        Storage[("Storage&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;S3 / Filesystem&amp;lt;/sub&amp;gt;")]
        Meili[("Meilisearch&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Full-text search&amp;lt;/sub&amp;gt;")]
    end

    subgraph Security["Security Scanning"]
        Trivy["Trivy&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Container &amp;amp; FS scanning&amp;lt;/sub&amp;gt;"]
        Grype["Grype&amp;lt;br/&amp;gt;&amp;lt;sub&amp;gt;Dependency scanning&amp;lt;/sub&amp;gt;"]
    end

    subgraph Edge["Edge Replication"]
        Peer1["Edge Node"]
        Peer2["Edge Node"]
        Peer3["Edge Node"]
    end

    CLI --&amp;gt;|"Native protocols"| API
    WebApp --&amp;gt; API
    iOS --&amp;gt; API
    Android --&amp;gt; API

    API --&amp;gt; Handlers
    API --&amp;gt; Auth
    Handlers --&amp;gt; WASM
    Handlers --&amp;gt; Policy

    API --&amp;gt; PG
    Handlers --&amp;gt; Storage
    API --&amp;gt; Meili

    Policy --&amp;gt; Trivy
    Policy --&amp;gt; Grype

    API &amp;lt;--&amp;gt;|"Borg Replication"| Peer1
    API &amp;lt;--&amp;gt;|"Borg Replication"| Peer2
    API &amp;lt;--&amp;gt;|"Borg Replication"| Peer3
    Peer1 &amp;lt;--&amp;gt;|"P2P Mesh"| Peer2
    Peer2 &amp;lt;--&amp;gt;|"P2P Mesh"| Peer3
    Peer1 &amp;lt;--&amp;gt;|"P2P Mesh"| Peer3

    style Core fill:#1a1a2e,stroke:#e94560,color:#fff
    style Data fill:#16213e,stroke:#0f3460,color:#fff
    style Security fill:#1a1a2e,stroke:#e94560,color:#fff
    style Edge fill:#0f3460,stroke:#533483,color:#fff
    style Clients fill:#16213e,stroke:#0f3460,color:#fff

    style API fill:#e94560,stroke:#e94560,color:#fff
    style Handlers fill:#e94560,stroke:#e94560,color:#fff
    style WASM fill:#533483,stroke:#533483,color:#fff
    style Auth fill:#e94560,stroke:#e94560,color:#fff
    style Policy fill:#e94560,stroke:#e94560,color:#fff

    style PG fill:#0f3460,stroke:#0f3460,color:#fff
    style Storage fill:#0f3460,stroke:#0f3460,color:#fff
    style Meili fill:#0f3460,stroke:#0f3460,color:#fff

    style Trivy fill:#533483,stroke:#533483,color:#fff
    style Grype fill:#533483,stroke:#533483,color:#fff

    style Peer1 fill:#533483,stroke:#533483,color:#fff
    style Peer2 fill:#533483,stroke:#533483,color:#fff
    style Peer3 fill:#533483,stroke:#533483,color:#fff

    style CLI fill:#0f3460,stroke:#0f3460,color:#fff
    style WebApp fill:#0f3460,stroke:#0f3460,color:#fff
    style iOS fill:#0f3460,stroke:#0f3460,color:#fff
    style Android fill:#0f3460,stroke:#0f3460,color:#fff
&lt;/code&gt;
    &lt;p&gt;Contributions are welcome. Pick an issue, open a PR, or start a discussion. The backend is Rust, the frontend is TypeScript/React, and the mobile apps are native Swift and Kotlin.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation: artifactkeeper.com/docs&lt;/item&gt;
      &lt;item&gt;Email: support@artifactkeeper.com&lt;/item&gt;
      &lt;item&gt;Issues: GitHub Issues&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT. Every feature. No exceptions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/artifact-keeper"/><published>2026-02-06T04:12:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46909439</id><title>Systems Thinking</title><updated>2026-02-06T18:03:07.104991+00:00</updated><content>&lt;doc fingerprint="a77892771b05878d"&gt;
  &lt;main&gt;
    &lt;p&gt;Software is a static list of instructions, which we are constantly changing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thursday, February 5, 2026&lt;/head&gt;
    &lt;head rend="h3"&gt;Systems Thinking&lt;/head&gt;
    &lt;p&gt;The most prevalent one, these days, is that you gradually evolve the complexity over time. You start small and keep adding to it.&lt;/p&gt;
    &lt;p&gt;The other school is that you lay out a huge specification that would fully work through all of the complexity in advance, then build it.&lt;/p&gt;
    &lt;p&gt;In a sense, it is the difference between the way an entrepreneur might approach doing a startup versus how we build modern skyscrapers. Evolution versus Engineering.&lt;/p&gt;
    &lt;p&gt;I was working in a large company a while ago, and I stumbled on the fact that they had well over 3000 active systems that were covering dozens of lines of business and all of the internal departments. It had evolved this way over fifty years, and included lots of different tech stacks, as well as countless vendors. Viewed as ‘one’ thing it was a pretty shaky house of cards.&lt;/p&gt;
    &lt;p&gt;It’s not hard to see that if they had a few really big systems, then a great number of their problems would disappear. The inconsistencies between data, security, operations, quality, and access were huge across all of those disconnected projects. Some systems were up-to-date, some were ancient. Some worked well, some were barely functional. With way fewer systems, a lot of these self-inflicted problems would just go away.&lt;/p&gt;
    &lt;p&gt;It’s not that you could cut the combined complexity in half, but more likely that you could bring it down to at least one-tenth of what it is today, if not even better. It would function better, be more reliable, and would be far more resilient to change. It would likely cost far less and require fewer employees as well. All sorts of ugly problems that they have now would just not exist.&lt;/p&gt;
    &lt;p&gt;The core difference between the different schools really centers around how to deal with dependencies.&lt;/p&gt;
    &lt;p&gt;If you had thousands of little blobs of complexity that were all entirely independent, then getting finished is just a matter of banging out each one by itself until they are all completed. That’s the dream.&lt;/p&gt;
    &lt;p&gt;But in practice, very few things in a big ecosystem are actually independent. That’s the problem.&lt;/p&gt;
    &lt;p&gt;If you are going to evolve a system, then you ignore these dependencies. Sort them out afterwards, as the complexity grows. It’s faster, and you can get started right away.&lt;/p&gt;
    &lt;p&gt;If you were going to design a big system, then these dependencies dictate that design. You have to go through each one and understand them all right away. They change everything from the architecture all the way down to the idioms and style in the code.&lt;/p&gt;
    &lt;p&gt;But that means that all of the people working to build up this big system have to interact with each other. Coordinate and communicate. That is a lot of friction that management and the programmers don’t want. They tend to feel like it would all get done faster if they could just go off on their own. And it will, in the short-term.&lt;/p&gt;
    &lt;p&gt;If you ignore a dependency and try to fix it later, it will be more expensive. More time, more effort, more thinking. And it will require the same level of coordination that you tried to avoid initially. Slightly worse, in that the time pressures of doing it correctly generally give way to just getting it done quickly, which pumps up the overall artificial complexity. The more hacks you throw at it, the more hacks you will need to hold it together. It spirals out of control. You lose big in the long-term.&lt;/p&gt;
    &lt;p&gt;One of the big speed bumps preventing big up-front designs is a general lack of knowledge. Since the foundations like tech stacks, frameworks, and libraries are always changing rapidly these days, there are few accepted best practices, and most issues are incorrectly believed to be subjective. They’re not, of course, but it takes a lot of repeated experience to see that.&lt;/p&gt;
    &lt;p&gt;The career path of most application programmers is fairly short. In most enterprises, the majority have five years or less of real in-depth experience, and battle-scared twenty-year+ vets are rare. Mostly, these novices are struggling through early career experiences, not ready yet to deal with the unbounded, massive complexity present in a big design.&lt;/p&gt;
    &lt;p&gt;Also, the other side of it is that evolutionary projects are just more fun. I’ve preferred them. You’re not loaded down with all those messy dependencies. Way fewer meetings, so you can just get into the work and see how it goes. Endlessly arguing about fiddly details in a giant spec is draining, made worse if the experience around you is weak.&lt;/p&gt;
    &lt;p&gt;Evolutionary projects go very badly sometimes. The larger they grow, the more likely they will derail. And the fun gives way to really bad stress. That severe last-minute panic that comes from knowing that the code doesn't really work as it should, and probably never will. And the longer-term dissatisfaction of having done all that work to ultimately just contribute to the problem, not actually fix it.&lt;/p&gt;
    &lt;p&gt;Big up-front designs are often better from a stress perspective. A little slow to start and sometimes slow in the middle, they mostly smooth out the overall development process. You’ve got a lot of work to do, but you’ve also got enough time to do it correctly. So you grind through it, piece by piece, being as attentive to the details as possible. Along the way, you actively look for smarter approaches to compress the work. Reuse, for instance, can shave a ton of code off the table, cut down on testing, and provide stronger certainty that the code will do the right thing in production.&lt;/p&gt;
    &lt;p&gt;The fear that big projects will end up producing the wrong thing is often overstated. It’s true for a startup, but entirely untrue for some large business application for a market that’s been around forever. You don’t need to burn a lot of extra time, breaking the work up into tiny fragments, unless you really don’t have a clue what you are building. If you're replacing some other existing system, not only do you have a clue, you usually have a really solid long-term roadmap. Replace the original work and fix its deficiencies.&lt;/p&gt;
    &lt;p&gt;There should be some balanced path in the middle somewhere, but I haven’t stumbled across a formal version of it after all these decades.&lt;/p&gt;
    &lt;p&gt;We could go first to the dependencies, then come up with reasons why they can be temporarily ignored. You can evolve the next release, but still have a vague big design as a long-term plan. You can refactor the design as you come across new, unexpected dependencies. Change your mind, over and over again, to try to get the evolved works to converge on a solid grand design. Start fast, slow right down, speed up, slow down again, and so forth. The goal is one big giant system to rule them all, but it may just take a while to get there.&lt;/p&gt;
    &lt;p&gt;The other point is that the size of the iterations matters, a whole lot. If they are tiny, it is because you are blindly stumbling forward. If you are not blindly stumbling forward, they should be longer, as it is more effective. They don’t have to all be the same size. And you really should stop and take stock after each iteration. The faster people code, the more cleanup that is required. The longer you avoid cleaning it up, the worse it gets, on basically an exponential scale. If you run forward like crazy and never stop, the working environment will be such a swamp that it will all grind to an abrupt stop. This is true in building anything, or even cooking in a restaurant. Speed is a tradeoff.&lt;/p&gt;
    &lt;p&gt;Evolution is the way to avoid getting bogged down in engineering, but engineering is the way to ensure that the thing you build really does what it is supposed to do. Engineering is slow, but spinning way out of control is a heck of a lot slower. Evolution is obviously more dynamic, but it is also more chaotic, and you have to continually accept that you’ve gone down a bad path and need to backtrack. That is hard to admit sometimes. For most systems, there are parts that really need to be engineered, and parts that can just be allowed to evolve. The more random the evolutionary path, the more stuff you need to throw away and redo. Wobbling is always expensive. Nature gets away with this by having millions of species, but we really only have one development project, so it isn’t particularly convenient.&lt;/p&gt;
    &lt;head rend="h4"&gt;2 comments:&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;It is good to see the both extreme sides clearly through this article - start small and add complexity over time vs specify everything and then build it. And the core of both sides comes down to dependencies. One anecdote I'd want to contribute is our choice of dependency at RudderStack. We chose Postgres over Kafka as our event queue solution. A controversial choice back then, why would you make your life hard when there is a solution just made for that. But it has paid off in the long term.&lt;/p&gt;ReplyDelete&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;you are missing a point in engineering:&lt;/p&gt;ReplyDelete&lt;lb/&gt;before the skyscraper is built, there are many R&amp;amp;D sessions, evolving the tech stack. Some skyscrapers crumbled, others stood, best practices formed etc. Point being an engineered system ran through its own evolution before series deployment.&lt;lb/&gt;The thing with software is, that usually it is a new problem to be solved. Many best SWE practices exist, but this equates more to OSHA guidelines, and not to the actual civil engineering tech.&lt;lb/&gt;So i think the point should be to not be afraid of serious refactoring efforts.&lt;lb/&gt;To make it clear to management, that they are resting on a house of cards, and while it works now it can have catastrophic effects.&lt;lb/&gt;The reason for systems in the wild still to just be the result of their evolutions is usually cost pressure&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://theprogrammersparadox.blogspot.com/2026/02/systems-thinking.html"/><published>2026-02-06T05:24:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46909468</id><title>Things Unix can do atomically (2010)</title><updated>2026-02-06T18:03:06.975131+00:00</updated><content>&lt;doc fingerprint="7ff15d51748103e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Things UNIX can do atomically 2010/01/06&lt;/head&gt;
    &lt;p&gt;This is a catalog of things UNIX-like/POSIX-compliant operating systems can do atomically, making them useful as building blocks for thread-safe and multi-process-safe programs without mutexes or read/write locks. The list is by no means exhaustive and I expect it to be updated frequently for the foreseeable future.&lt;/p&gt;
    &lt;p&gt;The philosophy here is to let the kernel do as much work as possible. At my most pessimistic, I trust the kernel developers more than a trust myself. More practically, it’s stupid to spend CPU time locking around an operation that’s already atomic. Added 2010-01-07.&lt;/p&gt;
    &lt;head rend="h2"&gt;Operating on a pathname&lt;/head&gt;
    &lt;p&gt;The operations below are best left to local filesystems. More than a few people have written in crying foul if any of these techniques are used on an NFS mount. True. When there are multiple kernels involved, the kernel can’t very well take care of all the locking for us. Added 2010-01-06.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;mv -T &amp;lt;oldsymlink&amp;gt; &amp;lt;newsymlink&amp;gt;&lt;/code&gt;atomically changes the target of&lt;code&gt;&amp;lt;newsymlink&amp;gt;&lt;/code&gt;to the directory pointed to by&lt;code&gt;&amp;lt;oldsymlink&amp;gt;&lt;/code&gt;and is indispensable when deploying new code. Updated 2010-01-06: both operands are symlinks. (So this isn’t a system call, it’s still useful.)&lt;del rend="overstrike"&gt;A reader pointed out that&lt;/del&gt;Deleted 2010-01-06:&lt;code&gt;ln -Tfs &amp;lt;directory&amp;gt; &amp;lt;symlink&amp;gt;&lt;/code&gt;accomplishes the same thing without the second symlink. Added 2010-01-06.&lt;code&gt;strace(1)&lt;/code&gt;shows that&lt;code&gt;ln -Tfs &amp;lt;directory&amp;gt; &amp;lt;symlink&amp;gt;&lt;/code&gt;actually calls&lt;code&gt;symlink(2)&lt;/code&gt;,&lt;code&gt;unlink(2)&lt;/code&gt;, and&lt;code&gt;symlink(2)&lt;/code&gt;once more, disqualifying it from this page.&lt;code&gt;mv -T &amp;lt;oldsymlink&amp;gt; &amp;lt;newsymlink&amp;gt;&lt;/code&gt;ends up calling&lt;code&gt;rename(2)&lt;/code&gt;which can atomically replace&lt;code&gt;&amp;lt;newsymlink&amp;gt;&lt;/code&gt;. Caveat 2013-01-07: this does not apply to Mac OS X, whose&lt;code&gt;mv(1)&lt;/code&gt;doesn’t call&lt;code&gt;rename(2)&lt;/code&gt;.&lt;code&gt;mv(1)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;link(oldpath, newpath)&lt;/code&gt;creates a new hard link called&lt;code&gt;newpath&lt;/code&gt;pointing to the same inode as&lt;code&gt;oldpath&lt;/code&gt;and increases the link count by one. This will fail with the error code&lt;code&gt;EEXIST&lt;/code&gt;if&lt;code&gt;newpath&lt;/code&gt;already exists, making this a useful mechanism for locking a file amongst threads or processes that can all agree upon the name&lt;code&gt;newpath&lt;/code&gt;. I prefer this technique for whole-file locking because the lock is visible to&lt;code&gt;ls(1)&lt;/code&gt;.&lt;code&gt;link(2)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;symlink(oldpath, newpath)&lt;/code&gt;operates very much like&lt;code&gt;link(2)&lt;/code&gt;but creates a symbolic link at a new inode rather than a hard link to the same inode. Symbolic links can point to directories, which hard links cannot, making them a perfect analogy to&lt;code&gt;link(2)&lt;/code&gt;when locking entire directories. This will fail with the error code&lt;code&gt;EEXIST&lt;/code&gt;if&lt;code&gt;newpath&lt;/code&gt;already exists, making this a perfect analogy to&lt;code&gt;link(2)&lt;/code&gt;that works for directories, too. Be careful of symbolic links whose target inode has been removed ("dangling" symbolic links) —&lt;code&gt;open(2)&lt;/code&gt;will fail with the error code&lt;code&gt;ENOENT&lt;/code&gt;. It should be mentioned that inodes are a finite resource (this particular machine has 1,245,184 inodes).&lt;code&gt;symlink(2)&lt;/code&gt;. Added 2010-01-07&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rename(oldpath, newpath)&lt;/code&gt;can change a pathname atomically, provided&lt;code&gt;oldpath&lt;/code&gt;and&lt;code&gt;newpath&lt;/code&gt;are on the same filesystem. This will fail with the error code&lt;code&gt;ENOENT&lt;/code&gt;if&lt;code&gt;oldpath&lt;/code&gt;does not exist, enabling interprocess locking much like&lt;code&gt;link(oldpath, newpath)&lt;/code&gt;above. I find this technique more natural when the files in question will be&lt;code&gt;unlink&lt;/code&gt;ed later.&lt;code&gt;rename(2)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;open(pathname, O_CREAT | O_EXCL, 0644)&lt;/code&gt;creates and opens a new file. (Don’t forget to set the mode in the third argument!)&lt;code&gt;O_EXCL&lt;/code&gt;instructs this to fail with the error code&lt;code&gt;EEXIST&lt;/code&gt;if&lt;code&gt;pathname&lt;/code&gt;exists. This is a useful way to decide which process should handle a task: whoever successfully creates the file.&lt;code&gt;open(2)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mkdir(dirname, 0755)&lt;/code&gt;creates a new directory but fails with the error code&lt;code&gt;EEXIST&lt;/code&gt;if&lt;code&gt;dirname&lt;/code&gt;exists. This provides for directories the same mechanism&lt;code&gt;link(2)&lt;/code&gt;&lt;code&gt;open(2)&lt;/code&gt;with&lt;code&gt;O_EXCL&lt;/code&gt;provides for files.&lt;code&gt;mkdir(2)&lt;/code&gt;. Added 2010-01-06; edited 2013-01-07.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Operating on a file descriptor&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;fcntl(fd, F_GETLK, &amp;amp;lock)&lt;/code&gt;,&lt;code&gt;fcntl(fd, F_SETLK, &amp;amp;lock)&lt;/code&gt;, and&lt;code&gt;fcntl(fd, F_SETLKW, &amp;amp;lock)&lt;/code&gt;allow cooperating processes to lock regions of a file to serialize their access.&lt;code&gt;lock&lt;/code&gt;is of type&lt;code&gt;struct flock&lt;/code&gt;and describes the type of lock and the region being locked.&lt;code&gt;F_SETLKW&lt;/code&gt;is particularly useful as it blocks the calling process until the lock is acquired. There is a “mandatory locking” mode but Linux’s implementation is unreliable as it’s subject to a race condition.&lt;code&gt;fcntl(2)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;fcntl(fd, F_GETLEASE)&lt;/code&gt;and&lt;code&gt;fcntl(fd, F_SETLEASE, lease)&lt;/code&gt;ask the kernel to notify the calling process with&lt;code&gt;SIGIO&lt;/code&gt;when another process&lt;code&gt;open&lt;/code&gt;s or&lt;code&gt;truncate&lt;/code&gt;s the file referred to by&lt;code&gt;fd&lt;/code&gt;. When that signals arrives, the lease needs to be removed by&lt;code&gt;fcntl(fd, F_SETLEASE, F_UNLCK)&lt;/code&gt;.&lt;code&gt;fcntl(fd, F_NOTIFY, arg)&lt;/code&gt;is similar but doesn’t block other processes, so it isn’t useful for synchronization.&lt;code&gt;fcntl(2)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mmap(0, length, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)&lt;/code&gt;returns a pointer from which a file’s contents can be read and written by normal memory operations. By making frequent use of&lt;code&gt;msync(addr, length, MS_INVALIDATE)&lt;/code&gt;, data written in this manner can be shared between processes that both map the same file.&lt;code&gt;mmap(2)&lt;/code&gt;,&lt;code&gt;msync(2)&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Operating on virtual memory&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;__sync_fetch_and_add&lt;/code&gt;,&lt;code&gt;__sync_add_and_fetch&lt;/code&gt;,&lt;code&gt;__sync_val_compare_and_swap&lt;/code&gt;, and friends provide a full barrier so “no memory operand will be moved across the operation, either forward or backward.” These operations are the basis for most (all?) lock-free algorithms. GCC Atomic Builtins.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Something I should add to my repertoire? Race condition? Let me know at r@rcrowley.org or @rcrowley and I’ll fix it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rcrowley.org/2010/01/06/things-unix-can-do-atomically.html"/><published>2026-02-06T05:29:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46910963</id><title>A new bill in New York would require disclaimers on AI-generated news content</title><updated>2026-02-06T18:03:06.804357+00:00</updated><content>&lt;doc fingerprint="fcc1099258150ba3"&gt;
  &lt;main&gt;&lt;p&gt;A new bill in the New York state legislature would require news organizations to label AI-generated material and mandate that humans review any such content before publication. On Monday, Senator Patricia Fahy (D-Albany) and Assemblymember Nily Rozic (D-NYC) introduced the bill, called The New York Fundamental Artificial Intelligence Requirements in News Act — The NY FAIR News Act for short.&lt;/p&gt;&lt;p&gt;“At the center of the news industry, New York has a strong interest in preserving journalism and protecting the workers who produce it,” said Rozic in a statement announcing the bill.&lt;/p&gt;A closer look at the bill shows a few regulations, mostly centered around AI transparency, both for the public and in the newsroom. For one, the law would demand that news organizations put disclaimers on any published content that is “substantially composed, authored, or created through the use of generative artificial intelligence.”&lt;p&gt;AI disclaimers for readers have been hotly debated in the news industry, with some critics arguing that such labels alienate audiences, even when generative AI is only used as an assistive tool. The bill contains a carve-out that would allow copyrightable material to be excluded from the law. (The U.S. Copyright Office has ruled that works solely generated by AI systems are not eligible for copyright, but allows leeway for works that show signs of “human authorship.”)&lt;/p&gt;&lt;p&gt;The bill also requires that news organizations disclose to journalists and other media professionals in their newsrooms when AI is being used and how. Any news content created using generative AI must also be reviewed by a human employee “with editorial control” before publication. That goes not just for news articles but also for audio, images, and other visuals.&lt;/p&gt;&lt;p&gt;In addition, the bill contains language that requires news organizations to create safeguards that protect confidential material — mainly, information about sources — from being accessed by AI technologies.&lt;/p&gt;&lt;p&gt;State lawmakers highlighted two main reasons for proposing the NY FAIR News Act. First, they say, AI-generated content may be “false or misleading.” Second, they argue, AI-generated content “plagiarizes” by deriving content from original sources “without permission or proper citation.”&lt;/p&gt;&lt;p&gt;“Perhaps one of the industries at most risk from the use of artificial intelligence is journalism and as a result, the public’s trust and confidence in accurate news reporting,” said Sen. Fahy in a statement. “More than 76% of Americans are concerned about AI stealing or reproducing journalism and local news stories.”&lt;/p&gt;&lt;p&gt;The proposed bill was announced with broad endorsements from unions across the news industry, including WGA-East, SAG-AFTRA and the DGA.&lt;/p&gt;&lt;p&gt;Jennifer Sheehan, a spokesperson for the NewsGuild of New York, confirmed that the NewsGuild has been meeting with this labor coalition to discuss shared concerns around AI adoption and working to get the bill off the ground.&lt;/p&gt;Notably, the bill would cement some labor protections for newsroom workers — including restrictions on firing journalists or reducing their work, pay, or benefits due to generative AI adoption. Similar language has been negotiated into individual newsroom union contracts across the country over the past couple of years.&lt;p&gt;In December, the NewsGuild launched a nationwide campaign called “News Not Slop” to advocate for more guardrails on AI usage in newsrooms. In New York City, the Business Insider union held a rally in the Financial District to protest an editorial pilot that was publishing AI-generated news stories with an “AI byline.”&lt;/p&gt;&lt;p&gt;“Our union is deeply concerned about media companies implementing artificial intelligence in ways that damage the credibility of our members’ journalism,” Sheehan said, “as well as the impact such technology has had and will have on jobs.”&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/"/><published>2026-02-06T09:56:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46911170</id><title>Invention of DNA "Page Numbers" Opens Up Possibilities for the Bioeconomy</title><updated>2026-02-06T18:03:06.697078+00:00</updated><content/><link href="https://www.caltech.edu/about/news/invention-dna-page-numbers-synthesis-kaihang-wang"/><published>2026-02-06T10:26:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46911869</id><title>TikTok's 'Addictive Design' Found to Be Illegal in Europe</title><updated>2026-02-06T18:03:06.647345+00:00</updated><content/><link href="https://www.nytimes.com/2026/02/06/business/tiktok-addictive-design-europe.html"/><published>2026-02-06T12:11:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46911901</id><title>I now assume that all ads on Apple news are scams</title><updated>2026-02-06T18:03:06.497608+00:00</updated><content>&lt;doc fingerprint="7b885158dca214d7"&gt;
  &lt;main&gt;
    &lt;p&gt;In 2024, Apple signed a deal with Taboola to serve ads in its app, notably Apple News. John Gruber, writing in Daring Fireball said at the time:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you told me that the ads in Apple News have been sold by Taboola for the last few years, I’d have said, “Oh, that makes sense.” Because the ads in Apple News — at least the ones I see1 — already look like chumbox Taboola ads. Even worse, they’re incredibly repetitious.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I use Apple News to keep up on topics that I don’t find in sources I pay for (The Guardian and The New York Times). But there’s no way I’m going to pay the exorbitant price Apple wants for Apple News+ – £13 – because, while you get more publications, you still get ads.&lt;/p&gt;
    &lt;p&gt;And those ads have gotten worse recently. Many if not most of them look like and probably are scams. Here are a few examples from Apple News today.&lt;/p&gt;
    &lt;p&gt;Here are three ads that are scammy; the first two were clearly generated by AI, and the third may have been created by AI.&lt;/p&gt;
    &lt;p&gt;Why are they scams? When I searched domain information for the domains, I found that they were registered very recently.&lt;/p&gt;
    &lt;p&gt;Domain Name: MUSTYLEVO.COM&lt;lb/&gt; Registry Domain ID: 3059688301_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: whois.gname.com&lt;lb/&gt; Registrar URL: http://www.gname.com&lt;lb/&gt; Updated Date: 2026-02-04T07:23:58Z&lt;lb/&gt; Creation Date: 2026-01-21T07:23:43Z&lt;/p&gt;
    &lt;p&gt;Domain Name: SOLVERACO.COM&lt;lb/&gt; Registry Domain ID: 3045027870_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: grs-whois.hichina.com&lt;lb/&gt; Registrar URL: http://wanwang.aliyun.com&lt;lb/&gt; Updated Date: 2025-12-05T06:10:51Z&lt;lb/&gt; Creation Date: 2025-12-05T06:07:40Z&lt;/p&gt;
    &lt;p&gt;Domain Name: SHIYAATELIER.COM&lt;lb/&gt; Registry Domain ID: 3037972202_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: whois.name.com&lt;lb/&gt; Registrar URL: http://www.name.com&lt;lb/&gt; Updated Date: 2025-11-12T06:47:14Z&lt;lb/&gt; Creation Date: 2025-11-12T06:47:13Z&lt;/p&gt;
    &lt;p&gt;This recent registration doesn’t necessarily mean they are scams, but they don’t inspire much confidence.&lt;/p&gt;
    &lt;p&gt;Here’s one example. This ad from Tidenox, whose website says I am retiring, showing a photo of an elderly woman, who says, “For 26 years, Tidenox has been port of your journey in creating earth and comfort at home.” The image of the retiring owner is probably made by AI. (Update: someone on Hacker News pointed out the partly masked Google Gemini logo on the bottom right. I hadn’t spotted that, in part because I don’t use any AI image generation tools.)&lt;/p&gt;
    &lt;p&gt;These fake “going out of business ads” have been around for a few years, and even the US Better Business Bureau warns about them, as they take peoples’ money then shut down. Does Apple care? Does Taboola care? Does Apple care that Taboola serves ads like this? My guess: no, no, and no.&lt;/p&gt;
    &lt;p&gt;Note the registration date for the tidenox.com domain. It’s nowhere near 26 years old, and it’s registered in China:&lt;/p&gt;
    &lt;p&gt;Domain Name: TIDENOX.COM&lt;lb/&gt; Registry Domain ID: 2987356919_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: grs-whois.hichina.com&lt;lb/&gt; Registrar URL: http://wanwang.aliyun.com&lt;lb/&gt; Updated Date: 2025-05-29T09:17:31Z&lt;lb/&gt; Creation Date: 2025-05-29T09:14:35Z&lt;/p&gt;
    &lt;p&gt;Shame on Apple for creating a honeypot for scam ads in what they consider to be a premium news service. This company cannot be trusted with ads in its products any more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Discover more from Kirkville&lt;/head&gt;
    &lt;p&gt;Subscribe to get the latest posts sent to your email.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kirkville.com/i-now-assume-that-all-ads-on-apple-news-are-scams/"/><published>2026-02-06T12:16:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46912781</id><title>LLMs could be, but shouldn't be compilers</title><updated>2026-02-06T18:03:06.032666+00:00</updated><content>&lt;doc fingerprint="330299dd20a69dec"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been going round and round in my mind about a particular discussion around LLMs: are they really similar to compilers? Are we headed toward a world where people don’t look at the underlying code for their programs?&lt;/p&gt;
    &lt;p&gt;People have been making versions of this argument since Andrej Karpathy’s “English is the hottest new programming language.” Computer science has been advancing language design by building higher and higher level languages; this is the latest iteration: maybe we no longer need a separate language to express ourselves to machines; we can just use our native tongues (let alone English).&lt;/p&gt;
    &lt;p&gt;My stance has been pretty rigid for some time: LLMs hallucinate, so they aren’t reliable building blocks. If you can’t rely on the translation step, you can’t treat it as a serious abstraction layer because it provides no stable guarantees about the underlying system.&lt;/p&gt;
    &lt;p&gt;As models get better, hallucinations become less central (even though models still make plenty of mistakes). Lately I’ve been thinking about a different question: imagine an LLM that never “hallucinates” in the usual sense, one that reliably produces some plausible implementation of what you asked. Would that make it the next generation of compiler? And what would that mean for programming and software engineering in general?&lt;/p&gt;
    &lt;p&gt;This post is my stab at that question. The core of my argument is simple:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Specifying systems is hard; and we are lazy.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Before getting to what that means in practice, I want to pin down something else: what does it mean for a language to be “higher level”?&lt;/p&gt;
    &lt;p&gt;Programming is, at a fundamental level, the act of making a computer do something. Computers are very dumb from the point of view of a human. You need to tell the computer exactly what to do, there's no inference. A computer fundamentally doesn't even have the notion of a value, type, concept; everything is a series of bits, which are processed to generate other bits, we bring meaning to this whole ordeal. Very early on, people have started by building arithmetic and logical instructions into computers, you would have 2 different bit sequences each denoting a number, you could add, subtract, multiply them. In order to make a computer do something, you could denote your data in terms of a bunch of numbers, map your logical operations onto those ALU instructions, and interpret the result in your domain at the end. Then, you can define a bunch of operations on your domain, which will be compiled down to those smaller ALU instructions, and voila, you have a compiler at hand.&lt;/p&gt;
    &lt;p&gt;This compiler is, admittedly, kind of redundant. It doesn't do anything you would be able to do because you essentially have a direct mapping between your two languages, your higher level language desugars into a bunch of lower level ALU instructions, so anyone would be able to implement the same mapping very easily, and even go further, perhaps just write the ALU instructions themselves.&lt;/p&gt;
    &lt;p&gt;What real higher level languages do is they give you an entirely new language that is eventually mapped to the underlying instruction set in non-trivial mechanisms in order to reduce the mental complexity on the side of the programmer. For instance, instruction sets do not have the concept of variables, nor loops, nor data structures. You can definitely build a sequence of instructions that amount to a binary search tree, but the mental burden of the process is orders of magnitude higher than any classic programming language. Structs, Enums, Classes, Loops, Conditionals, Exceptions, Variables, Functions are all properties that exist in higher level languages that are compiled away when going down the stack.&lt;/p&gt;
    &lt;p&gt;There's a crucial aspect of compilation, which is that the programmer gives away some control, that's essentially what removes the mental burden. If a programming language doesn't give away any control, it arguably isn't a very useful abstraction layer, because it did not absolve you of any responsibility that comes with that control. One of the first examples of this type of control we gave away is code layout. If you are writing handwritten assembly, you control where the code lives in the program memory. When you go into a language with structured control flow with callable procedures, you now don't have exact control over when the instructions for a particular piece of code is fetched, how basic blocks are arranged in the memory. Other examples are more common, the runtime of a language works in the background to absolve you of other responsibilities such as manual memory management, which itself was an abstraction for automatically managing how your data is organized in memory in the first place.&lt;/p&gt;
    &lt;p&gt;This loss of control raises a question: how do we know the abstraction is implemented correctly? More importantly, what does it mean for an abstraction to be correct?&lt;/p&gt;
    &lt;p&gt;There are a few layers to the answer. First, mature abstractions are defined against some semantics: what behaviors are allowed, what behaviors are forbidden, and what guarantees you’re meant to rely on. In C, &lt;code&gt;malloc&lt;/code&gt; gives you a pointer to a block of memory of at least the requested size (or &lt;code&gt;NULL&lt;/code&gt;), suitably aligned, which you may later &lt;code&gt;free&lt;/code&gt;. It doesn’t give you “exclusive ownership” in the language-theoretic sense, but it does define a contract you can program against.&lt;/p&gt;
    &lt;p&gt;Second, we validate implementations with testing (and sometimes proofs), because these guarantees are at least in principle checkable. Third, in practice, guarantees are contextual: most programs care that allocation works; only some care deeply about allocator performance, fragmentation behavior, or contention, those are the cases where people swap allocators or drop down a level.&lt;/p&gt;
    &lt;p&gt;This highlights a critical point: abstraction guarantees aren’t uniform; they’re contextual. Most of the time, that contextuality is dominated by functional correctness: “does it do what it says?” Programming languages made enormous progress by giving us abstractions whose functional behavior can be specified precisely and tested relentlessly. We can act as if push/pop on a Python list has the same semantics as a vector in C++ even when the underlying implementation differs wildly across languages and runtimes.&lt;/p&gt;
    &lt;p&gt;LLM-based programming challenges this domination because the “language” (natural language) doesn’t come with precise semantics. That makes it much harder to even state what functional correctness should mean without building a validation/verification suite around it (tests, types, contracts, formal specs).&lt;/p&gt;
    &lt;p&gt;This gets to my core point. What changes with LLMs isn’t primarily nondeterminism, unpredictability, or hallucination. It’s that the programming interface is functionally underspecified by default. Natural language leaves gaps; many distinct programs can satisfy the same prompt. The LLM must fill those gaps.&lt;/p&gt;
    &lt;p&gt;Just as a garbage-collected runtime takes control over how and when memory is reclaimed, “programming in English” relinquishes control over which exact program gets built to fulfill your requirements. The underspecification forces the model to guess the data model, edge cases, error behavior, security posture, performance tradeoffs in your program, analogous to how an allocator chooses an allocation strategy.&lt;/p&gt;
    &lt;p&gt;This creates quite a novel danger in how we write programs.&lt;/p&gt;
    &lt;p&gt;Humans have always written vague requirements; that part isn’t new. What’s new is how directly an LLM can turn vagueness into running code, inviting us to outsource functional precision itself. We can leave meaningful behavioral choices to a generator and only react to the outcome.&lt;/p&gt;
    &lt;p&gt;If you say “give me a note-taking app,” you’re not describing one program, you’re describing a huge space of programs. The LLM can return one of a billion “reasonable” implementations: something Notion-like, Evernote-like, Apple Notes-like, or something novel. The danger is that “reasonable” choices can still be wrong for your intent, and you won’t notice which commitments got made until later.&lt;/p&gt;
    &lt;p&gt;This pushes development toward an iterative refinement loop: write an imprecise spec, get one of the possible implementations, inspect it, refine the spec, repeat until you’re satisfied. In this mode, you become more like a consumer selecting from generated artifacts than a producer deliberately constructing one.&lt;/p&gt;
    &lt;p&gt;And you also lose something subtle: when you hand-build, the “space of possibilities” is explored through design decisions you’re forced to confront. With a magic genie, those decisions get made for you; you only see the surface of what you ended up with.&lt;/p&gt;
    &lt;p&gt;I don’t think this point is widely internalized yet: hallucinations aren’t the only problem. Even in a hallucination-free world, the ability to take the easy way out on specification plays into a dangerously lazy part of the mind. You can see it in the semi-conscious slips (I’m guilty too): accept-all-edits, “one more prompt and it’ll be fine,” and slow drifting into software you don’t really understand.&lt;/p&gt;
    &lt;p&gt;That’s why I think the will to specify is going to become increasingly important. We already see LLMs shine when they’re given concrete constraints: optimization, refactors, translations, migrations, tasks that used to be so labor-intensive we’d laugh at the timeline, become feasible when the target behavior is well specified and backed by robust test suites.&lt;/p&gt;
    &lt;p&gt;It’s been true for a long time that specifying a piece of software is often harder than building it. But we may be entering a world where: if you can specify, you can build. If that’s right, then specification and verification become the bottleneck, and therefore the core skill.&lt;/p&gt;
    &lt;p&gt;This isn’t my most polished post, but I wanted to get the idea out. I do think it’s possible to treat LLMs as compiler-like, in the loose sense that they translate a specification into an executable artifact. But the control we relinquish to that translation layer is larger than it has ever been.&lt;/p&gt;
    &lt;p&gt;Traditional compilers reduce the need to stare at lower layers by replacing low-level control with defined semantics and testable guarantees. LLMs also reduce the need to read source code in many contexts, but the control you lose isn’t naturally bounded by a formal language definition. You can lose control all the way into becoming a consumer of software you meant to produce, and it’s frighteningly easy to accept that drift without noticing.&lt;/p&gt;
    &lt;p&gt;So: I don’t think we should fully accept the compiler analogy without qualification. As LLMs become a central toolchain component, we’ll need ways to strengthen the will to specify, and to make specification and verification feel as “normal” as writing code used to.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alperenkeles.com/posts/llms-could-be-but-shouldnt-be-compilers/"/><published>2026-02-06T13:48:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46912800</id><title>Hackers (1995) Animated Experience</title><updated>2026-02-06T18:03:05.943125+00:00</updated><link href="https://hackers-1995.vercel.app/"/><published>2026-02-06T13:49:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46913793</id><title>Microsoft open-sources LiteBox, a security-focused library OS</title><updated>2026-02-06T18:03:05.761444+00:00</updated><content>&lt;doc fingerprint="272b985dd8c3e751"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;A security-focused library OS&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;This project is currently actively evolving and improving. While we are working toward a stable release, some APIs and interfaces may change as the design continues to mature. You are welcome to explore and experiment, but if you need long-term stability, it may be best to wait for a stable release, or be prepared to adapt to updates along the way.&lt;/p&gt;
    &lt;p&gt;LiteBox is a sandboxing library OS that drastically cuts down the interface to the host, thereby reducing attack surface. It focuses on easy interop of various "North" shims and "South" platforms. LiteBox is designed for usage in both kernel and non-kernel scenarios.&lt;/p&gt;
    &lt;p&gt;LiteBox exposes a Rust-y &lt;code&gt;nix&lt;/code&gt;/&lt;code&gt;rustix&lt;/code&gt;-inspired "North" interface when it is provided a &lt;code&gt;Platform&lt;/code&gt; interface at its "South".  These interfaces allow for a wide variety of use-cases, easily allowing for connection between any of the North--South pairs.&lt;/p&gt;
    &lt;p&gt;Example use cases include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Running unmodified Linux programs on Windows&lt;/item&gt;
      &lt;item&gt;Sandboxing Linux applications on Linux&lt;/item&gt;
      &lt;item&gt;Run programs on top of SEV SNP&lt;/item&gt;
      &lt;item&gt;Running OP-TEE programs on Linux&lt;/item&gt;
      &lt;item&gt;Running on LVBS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the following files for details:&lt;/p&gt;
    &lt;p&gt;MIT License. See ./LICENSE for details.&lt;/p&gt;
    &lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark &amp;amp; Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/microsoft/litebox"/><published>2026-02-06T15:13:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46914159</id><title>Sheldon Brown's Bicycle Technical Info</title><updated>2026-02-06T18:03:05.254165+00:00</updated><content>&lt;doc fingerprint="b6f35e572bce892"&gt;
  &lt;main&gt;
    &lt;p&gt;Sheldon Brown's Bicycle Technical Info Articles by Sheldon Brown and Others What's New Beginners Bicycle Glossary Brakes Commuting Cyclecomputers Do-It-Yourself Essays and Fiction Family Cycling Fixed-Gear Frames Gears and Drivetrains Humor Old Bikes Repair Tips Singlespeed Tandems Touring Video Wheels Translations Sheldon - the man Sheldon Brown's Bicycle Glossary: A - B - C - D - EF - G - H - IJKL - M - NO - PQ - R - S - T - UVWXYZ What's New at sheldonbrown.com Our Paris-Brest-Paris page Sheldon Brown's Personal Pages Books Boston My Bicycles France My Hotlists My Journal Miscellaneous Music Photography Québec Plus Ça Change Radio Mailing lists My Father My Mother My Great-grandfather If you would like to make a link or bookmark to this page, the URL is: https://www.sheldonbrown.com/index.html Last Updated: by John Allen&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sheldonbrown.com/"/><published>2026-02-06T15:40:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46914274</id><title>Bytes as Braille</title><updated>2026-02-06T18:03:04.055805+00:00</updated><content>&lt;doc fingerprint="ee990238087ad1b9"&gt;
  &lt;main&gt;
    &lt;p&gt;UPDATE: Now on Github with more stuff including a neat input function&lt;/p&gt;
    &lt;p&gt;Since Python3, I have been working with bytestrings that sometimes decode as ASCII or UTF strings ; the environment this lives in is mixed, as in some strings are expected to decode while some are are expected to not decode.&lt;/p&gt;
    &lt;p&gt;Displaying those string as-is is not convenient, as quite a few Unicode symbols will not render correctly : since I work with all sort of human languages these are frequent so I wrote a very short function that would try to decode my bytestring and return “bytes” if it wouldn’t decode. This, however, was not convenient because it made it impossible to distinguish undecodable bytestrings from one another, and information was lost (because I couldn’t get the original bytestring again). Also, using the default Python mechanism to display those bytes was cumbersome, because each byte is displayed as 4 characters (such as \xc0), so the display quickly becomes quite messy and hard to read, even more so when ASCII-decodable characters are displayed as such.&lt;/p&gt;
    &lt;p&gt;It struck me that Braille symbols were a pretty workaround to this problem : although they are not ordered “logically” - actually they are, but based on historic grounds the first set comprises 6-dots symbols (U+2800 â¦ U+283F), followed by the 8-dots symbols (U+2840 â¦ T+28FF) and the order is well.. rather unconvenient to a lambda user like me.&lt;/p&gt;
    &lt;p&gt;The traditional cell numbering is this&lt;/p&gt;
    &lt;p&gt;also it is worth noting the following facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Braille is somehow a precursor of Unicode, as it uses the â ¼ symbol as a prefix to say what follows is not a letter but a number ; however and unlike Unicode, this can prefix a series of symbols&lt;/item&gt;
      &lt;item&gt;There is not one Braille : every country or language has its own Braille dialect&lt;/item&gt;
      &lt;item&gt;Braille users make heavy use of “compression”, defining aliases and shorthand often per-document in order to make reading faster&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The first thing I did was rename them as such (for big-endian representation):&lt;/p&gt;
    &lt;p&gt;Then came quite a bit of work re-ordering the cells based not on their Unicode number, but their new byte value. After updating my decode function, I’m now very happy with the result:&lt;/p&gt;
    &lt;p&gt;Of course, this can be decoded:&lt;/p&gt;
    &lt;code&gt;f = open('/tmp/sample.bin','rb')
f.write(braille_as_bytes('â â¢¤â¢â¢â¢â£â¢â£®â£â â¡â¢â¢¯â ¤â¢â¡â¢¤â¡â¡â ½â â¡â£â¡ºâ â£â£¨â¡â£¾â¢â ºâ â¢â â£â â ¬â¡â¢±â¢â °â£¢â£´â¢â ©â¢â¢¨â¢¢â£â¡¢â£â£â£â¡â ´â¡¡â ¤â ¦â â ½â â¡´â¡·â£´â ¬â£â¢â â â¡¹â£â ¡â£â¡â¡¤â¡'))
f.close()
&lt;/code&gt;
    &lt;p&gt;Following suggestions on #python, the output can be colored at will so one can make specific bytes be very visible.&lt;/p&gt;
    &lt;p&gt;In addition to being more compact, this makes it much easier to see patterns in blobs ; so if you like this way of displaying bytes and would like to skip the tedious symbol re-ordering, simply get the script on github.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.engrenage.ch/i18n/scripts/bytes_as_braille/"/><published>2026-02-06T15:48:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46914785</id><title>The Waymo World Model: A New Frontier for Autonomous Driving Simulation</title><updated>2026-02-06T18:03:03.712060+00:00</updated><content>&lt;doc fingerprint="75b5e4f8bda0980d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Waymo World Model: A New Frontier For Autonomous Driving Simulation&lt;/head&gt;
    &lt;p&gt;The Waymo Driver has traveled nearly 200 million fully autonomous miles, becoming a vital part of the urban fabric in major U.S. cities and improving road safety. What riders and local communities don’t see is our Driver navigating billions of miles in virtual worlds, mastering complex scenarios long before it encounters them on public roads. Today, we are excited to introduce the Waymo World Model, a frontier generative model that sets a new bar for large-scale, hyper-realistic autonomous driving simulation.&lt;/p&gt;
    &lt;p&gt;Simulation is a critical component of Waymo’s AI ecosystem and one of the three key pillars of our approach to demonstrably safe AI. The Waymo World Model, which we detail below, is the component that is responsible for generating hyper-realistic simulated environments.&lt;/p&gt;
    &lt;p&gt;The Waymo World Model is built upon Genie 3—Google DeepMind's most advanced general-purpose world model that generates photorealistic and interactive 3D environments—and is adapted for the rigors of the driving domain. By leveraging Genie’s immense world knowledge, it can simulate exceedingly rare events—from a tornado to a casual encounter with an elephant—that are almost impossible to capture at scale in reality. The model’s architecture offers high controllability, allowing our engineers to modify simulations with simple language prompts, driving inputs, and scene layouts. Notably, the Waymo World Model generates high-fidelity, multi-sensor outputs that include both camera and lidar data.&lt;/p&gt;
    &lt;p&gt;This combination of broad world knowledge, fine-grained controllability, and multi-modal realism enhances Waymo’s ability to safely scale our service across more places and new driving environments. In the following sections we showcase the Waymo World Model in action, featuring simulations of the Waymo Driver navigating diverse rare edge-case scenarios.&lt;/p&gt;
    &lt;head rend="h3"&gt;🌎 Emergent Multimodal World Knowledge&lt;/head&gt;
    &lt;p&gt;Most simulation models in the autonomous driving industry are trained from scratch based on only the on-road data they collect. That approach means the system only learns from limited experience. Genie 3’s strong world knowledge, gained from its pre-training on an extremely large and diverse set of videos, allows us to explore situations that were never directly observed by our fleet.&lt;/p&gt;
    &lt;p&gt;Through our specialized post-training, we are transferring that vast world knowledge from 2D video into 3D lidar outputs unique to Waymo’s hardware suite. While cameras excel at depicting visual details, lidar sensors provide valuable complementary signals like precise depth. The Waymo World Model can generate virtually any scene—from regular, day-to-day driving to rare, long-tail scenarios—across multiple sensor modalities.&lt;/p&gt;
    &lt;head rend="h5"&gt;🌪️ Extreme weather conditions and natural disasters&lt;/head&gt;
    &lt;head rend="h5"&gt;💥 Rare and safety-critical events&lt;/head&gt;
    &lt;head rend="h5"&gt;🐘 Long-tail (pun intended!) objects and more&lt;/head&gt;
    &lt;p&gt;In the interactive viewers below, you can immersively view the realistic 4D point clouds generated by the Waymo World Model.&lt;/p&gt;
    &lt;head rend="h3"&gt;🕹️ Strong Simulation Controllability&lt;/head&gt;
    &lt;p&gt;The Waymo World Model offers strong simulation controllability through three main mechanisms: driving action control, scene layout control, and language control.&lt;/p&gt;
    &lt;p&gt;Driving action control allows us to have a responsive simulator that adheres to specific driving inputs. This enables us to simulate “what if” counterfactual events such as whether the Waymo Driver could have safely driven more confidently instead of yielding in a particular situation.&lt;/p&gt;
    &lt;p&gt;Counterfactual driving. We demonstrate simulations both under the original route in a past recorded drive, or a completely new route. While purely reconstructive simulation methods (e.g., 3D Gaussian Splats, or 3DGS) suffer from visual breakdowns due to missing observations when the simulated route is too different from the original driving, the fully learned Waymo World Model maintains good realism and consistency thanks to its strong generative capabilities.&lt;/p&gt;
    &lt;p&gt;Scene layout control allows for customization of the road layouts, traffic signal states, and the behavior of other road users. This way, we can create custom scenarios via selective placement of other road users, or applying custom mutations to road layouts.&lt;/p&gt;
    &lt;p&gt;Scene layout conditioning following&lt;/p&gt;
    &lt;p&gt;Language control is our most flexible tool that allows us to adjust time-of-day, weather conditions, or even generate an entirely synthetic scene (such as the long-tail scenarios shown previously).&lt;/p&gt;
    &lt;p&gt;World Mutation - Time of Day&lt;/p&gt;
    &lt;p&gt;World Mutation - Weather&lt;/p&gt;
    &lt;head rend="h3"&gt;🎞️ Converting Dashcam Videos&lt;/head&gt;
    &lt;p&gt;During a scenic drive, it is common to record videos of the journey on mobile devices or dashcams, perhaps capturing piled up snow banks or a highway at sunset. The Waymo World Model can convert those kinds of videos, or any taken with a regular camera, into a multimodal simulation—showing how the Waymo Driver would see that exact scene. This process enables the highest degree of realism and factuality, since simulations are derived from actual footage.&lt;/p&gt;
    &lt;head rend="h3"&gt;⚙️ Scalable Inference&lt;/head&gt;
    &lt;p&gt;Some scenes we want to simulate may take longer to play out, for example, negotiating passage in a narrow lane. That’s harder to do because the longer the simulation, the tougher it is to compute and maintain stable quality. However, through a more efficient variant of the Waymo World Model, we can simulate longer scenes with dramatic reduction in compute while maintaining high realism and fidelity to enable large-scale simulations.&lt;/p&gt;
    &lt;head rend="h5"&gt;🚀 Long rollout (4x speed playback) on an efficient variant of the Waymo World Model&lt;/head&gt;
    &lt;p&gt;By simulating the “impossible”, we proactively prepare the Waymo Driver for some of the most rare and complex scenarios. This creates a more rigorous safety benchmark, ensuring the Waymo Driver can navigate long-tail challenges long before it encounters them in the real world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;The Waymo World Model is enabled by the key research, engineering and evaluation contributions from James Gunn, Kanaad Parvate, Lu Liu, Lucas Deecke, Luca Bergamini, Zehao Zhu, Raajay Viswanathan, Jiahao Wang, Sakshum Kulshrestha, Titas Anciukevičius, Luna Yue Huang, Yury Bychenkov, Yijing Bai, Yichen Shen, Stefanos Nikolaidis, Tiancheng Ge, Shih-Yang Su and Vincent Casser.&lt;/p&gt;
    &lt;p&gt;We thank Chulong Chen, Mingxing Tan, Tom Walters, Harish Chandran, David Wong, Jieying Chen, Smitha Shyam, Vincent Vanhoucke and Drago Anguelov for their support in defining the vision for this project, and for their strong leadership and guidance throughout.&lt;/p&gt;
    &lt;p&gt;We would like to additionally thank Jon Pedersen, Michael Dreibelbis, Larry Lansing, Sasho Gabrovski, Alan Kimball, Dave Richardson, Evan Birenbaum, Harrison McKenzie Chapter and Pratyush Chakraborty, Khoa Vo, Todd Hester, Yuliang Zou, Artur Filipowicz, Sophie Wang and Linn Bieske for their invaluable partnership in facilitating and enabling this project.&lt;/p&gt;
    &lt;p&gt;We thank our partners from Google DeepMind: Jack Parker-Holder, Shlomi Fruchter, Philip Ball, Ruiqi Gao, Songyou Peng, Ben Poole, Fei Xia, Allan Zhou, Sean Kirmani, Christos Kaplanis, Matt McGill, Tim Salimans, Ruben Villegas, Xinchen Yan, Emma Wang, Woohyun Han, Shan Han, Rundi Wu, Shuang Li, Philipp Henzler, Yulia Rubanova, and Thomas Kipf for helpful discussions and for sharing invaluable insights for this project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation"/><published>2026-02-06T16:20:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46915587</id><title>Bits About Money: Fraud Investigation Is Believing Your Lying Eyes</title><updated>2026-02-06T18:03:03.483704+00:00</updated><content>&lt;doc fingerprint="be71801f0aa3b541"&gt;
  &lt;main&gt;
    &lt;p&gt;There was recently an attempt by an independent journalist to expose fraud in a Minnesota social program. It was deeply frustrating; the journalist had notably poor epistemic standards, which secondary media seized upon to dismiss their result.&lt;/p&gt;
    &lt;p&gt;The class-based sniffing almost invariably noted that prestige media had already reported stories which rhymed with the core allegation, while sometimes implying that makes the allegations less likely to be true, through a logical pathway which is mysterious to me.&lt;/p&gt;
    &lt;p&gt;The journalism went quite viral anyway, in part because of sensationalized framing, in part because of signal boosting by an aligned media ecosystem and aligned politicians, and in part because the journalism develops one bit of evidence that has a viscerality that paperwork dives often lack: these purported childcare operations routinely have no children in them.&lt;/p&gt;
    &lt;p&gt;Fraud has become quite politicized in the United States the last few years. We had a poorly-calibrated federal initiative led by a charismatic tech entrepreneur which believed it would unearth trillions of dollars of fraud that focused substantial effort on large programs which are comparatively fraud-resistant. Across the aisle, we have reflexive dismissal that fraud happens in social programs, which functions as air cover for scaled criminal operations which loot many varied social programs [0] and are sometimes run out of geopolitical adversaries of the U.S. including by ambiguously-retired members of their clandestine services.&lt;/p&gt;
    &lt;p&gt;I worked in the financial industry for a few years. We do not have the luxury of pretending that fraud is something invented by our rivals to besmirch our good name. It hits the P&amp;amp;L every quarter and will eat you alive if you’re not at least minimally competent in dealing with it. Conversely, it is well-understood in industry that the optimal amount of fraud is not zero.&lt;/p&gt;
    &lt;p&gt;The financial industry has paid at least tens of billions of dollars in tuition here. Overwhelmingly, one learns about fraud in it through an apprenticeship model, with different firms having different internal levels of understanding on the shape of the elephant. The industrial organization presumes small numbers of people architecting anti-fraud systems and relatively larger numbers of investigators and analysts operating those systems on a day-to-day basis.&lt;/p&gt;
    &lt;p&gt;There does exist some informal knowledge sharing between firms. If you work in payments, try getting invited to the Chatham House rule sessions held by… oh yeah, can’t say. Despite that social technology being originally developed for the benefit of government and press actors, it is my general impression that U.S. benefits programs don’t yet see themselves as sufficiently yoked by adversarial attention to benefit from their own Chatham House series. Perhaps that should change.&lt;/p&gt;
    &lt;p&gt;And so, for the benefit of fraud investigators with badges, press cards, or GoPros, some observations from a community of practice with an extensive (and mostly nonpublic) body of work. But first a tiny bit of throat clearing.&lt;/p&gt;
    &lt;head rend="h2"&gt;In which we briefly return to Minnesota&lt;/head&gt;
    &lt;p&gt;Minnesota has suffered a decade-long campaign of industrial-scale fraud against several social programs. This is beyond intellectually serious dispute. The 2019 report from the Office of the Legislative Auditor (a non-partisan government body) makes for gripping reading. The scale of fraud documented and separately alleged in it staggers the imagination: the state’s own investigators believed that, over the past several years, greater than fifty percent of all reimbursements to daycare centers were fraudulent. (Separate officials took the… novel position that they were only required to recognize fraud had happened after securing a criminal conviction for it. Since they had only secured a few criminal convictions, there was no way that fraud was that high. Asked to put a number on it, repeatedly, they declined.)&lt;/p&gt;
    &lt;p&gt;The investigators allege repeatedly visiting daycare centers which did not, factually, have children physically present at the facility despite reimbursement paperwork identifying specific children being present at that specific time. The investigators demonstrated these lies on timestamped video, and perhaps in another life would have been YouTube stars.&lt;/p&gt;
    &lt;p&gt;Our social class is intensely averse to straightforwardly recounting these facts, partly due to political valence and partly due to this particular fraud being dominantly conducted within a community which codes as disadvantaged in the U.S. sociopolitical context.&lt;/p&gt;
    &lt;p&gt;Fraudsters are liars and will cheerfully mouth any words they believe will absolve them of their crimes. If an accusation of racism gets one a free pass to steal hundreds of millions of dollars, they will speciously sue you alleging racial discrimination. That empirically worked in Minnesota. The OLA takes explicit notice of this multiple times, a coordinator for the fraud operation is on record explicitly explaining the strategic logic of accusations of racism, and a judge was even moved to make an extraordinary statement to clarify that the bad-faith lawsuit alleging racism did not achieve success through the formal judicial process but rather through the voluntary compliance of governmental actors shamed by its allegations.&lt;/p&gt;
    &lt;p&gt;(As a sidenote: one has to be able to hold two thoughts simultaneously about fraudulent operations. They can be sophisticated with respect to exploiting sociopolitical cleavages in their targets while also being comically inept at faking evidence elsewhere, such as having a single person write dozens of adjacent rows in a sign-in sheet. This routinely surprises observers and it should not surprise them. The financial industry also has a division of labor in it. The person architecting the fraud department’s standard processes is well-paid, well-educated, and routinely brings crossdisciplinary expertise to bear. A Fraud Analyst I, on the other hand, bears a lot of similarity to a call center employee in terms of compensation, education, and permitted amounts of agency.)&lt;/p&gt;
    &lt;p&gt;In the immediate wake of the independent journalist’s report, the great and the good rallied around the organizations he accused. Of course it was natural that journalists wouldn’t get immediate access to children if they asked. Of course there was a certain amount of informality in the sector. Of course, as the New York Times very carefully wordsmithed recently:&lt;/p&gt;
    &lt;p&gt;Minnesota officials said in early January that the state conducted compliance checks at nine child-care centers after Mr. Shirley posted his video and found them “operating as expected,” although it had “ongoing investigations” at four of them. One of the centers, which Mr. Shirley singled out because it misspelled the word “Learning” on its sign, has since voluntarily closed.&lt;/p&gt;
    &lt;p&gt;An inattentive reader might conclude from this paragraph that the Times disputes Shirley’s reporting.&lt;/p&gt;
    &lt;p&gt;To the extent that Bits about Money has an editorial line on that controversy, it is this: if you fish in a pond known to have 50% blue fish, and pull out nine fish, you will appear to be a savant-like catcher of blue fish, and people claiming that it is unlikely you have identified a blue fish will swiftly be made to look like fools. But the interesting bit of the observation is, almost entirely, the base rate of the pond. And I think journalism and civil society should do some genuine soul-searching on how we knew—knew—the state of that pond, but didn’t consider it particularly important or newsworthy until someone started fishing on camera.&lt;/p&gt;
    &lt;p&gt;But this is not a publication about particular ponds. It is a publication about getting better at fishing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Common signals, methods, and epiphenomena of fraud&lt;/head&gt;
    &lt;head rend="h3"&gt;Fraudsters are playing an iterated game&lt;/head&gt;
    &lt;p&gt;The best non-fiction work on fraud is Dan Davies’ Lying for Money. In it, you’ll find replete examples of something well-known to fraud investigators: the dominant next adventure for a former fraudster is… opening up a new fraud. And therefore, if you want to identify a ridiculously-high-hit-rate list of frauds in round N+1 of a game, a so-easy-its-practically-cheating way to do so is to look at what known fraudsters from round N are doing today.&lt;/p&gt;
    &lt;p&gt;There is a genuine difference in the culture and epistemology of the financial industry versus the government of the United States here. In the financial industry, we keep blacklists and getting a second chance after obvious misbehavior is intentionally non-trivial. This runs against deeply felt values of civil servants. An accusation is not a conviction, and absent clear authority to impose consequences in a new program, an actor convicted at enormous societal cost emerges to a new program officer as tabula rasa, equal in moral worth to any randomly chosen citizen.&lt;/p&gt;
    &lt;p&gt;I will not argue that Mastercard has better moral intuitions than the Founding Fathers. I would, however, happily suggest that the government not assume that the Constitution contains emanating penumbras obligating it to be repeatedly taken advantage of by the same people in the same fashion. We are not forbidden object permanence.&lt;/p&gt;
    &lt;p&gt;Minnesota raided the Sunshine Child Care Center in 2022 on suspicion of overbilling. No charges were brought, in what investigators imply was less an exoneration and more an inter-departmental fumble. That operation was owned by one Fowsiya Hassan. A separate childcare center owned by Fowsiya Hassan was featured on YouTube recently. This follows on $1.5 million of funds received through Feeding Our Future, a scaled fraud operation which has generated over 70 indictments, 5 criminal convictions, and 50 guilty pleas. What a set of coincidences. Perhaps Hassan has, as she has alleged in a lawsuit, been a frequent target of racially-motivated government investigations into a successful serial entrepreneur in the childcare field.&lt;/p&gt;
    &lt;head rend="h3"&gt;The fraud supply chain is detectable&lt;/head&gt;
    &lt;p&gt;Much of the intellectual energy in policy circles about fraud is aimed at retail-level fraud by individual beneficiaries. Most fraud, like most scaled property crime, is actually the result of a business process.&lt;/p&gt;
    &lt;p&gt;This is an elementary fact of capitalism. It is deeply disconcerting to find every benefits program independently rediscovers it a decade too late to do anything about it. Most bread is not baked by amateurs in their kitchens. It comes from a bakery which exists to bake bread and hires specialists in baking bread and then supports them with capital-intensive built infrastructure.&lt;/p&gt;
    &lt;p&gt;Fraud develops a supply chain. Some elements in the supply chain are dual-use; the bad guys use Excel for the same reason every business uses Excel. Some elements in the supply chain, though, are specialized infrastructure with no or de minimis legitimate purpose. Those elements can be profiled.&lt;/p&gt;
    &lt;p&gt;I worked at Stripe for several years and am currently an advisor there. Stripe does not endorse what I write in my personal spaces. In its own spaces, Stripe has discussed being able to follow fraudulent operations in sufficient detail to determine when the operators went to lunch.&lt;/p&gt;
    &lt;p&gt;Fraudsters share specialists quite frequently. They use the same incorporation agents, the same mail services, the same CPAs, the same lawyers, etc.&lt;/p&gt;
    &lt;p&gt;You can make the same observation about many communities of practice. It is a non-coincidence that many tech startups are at 548 Market Street in San Francisco. 548 Market Street is not the world’s hippest coworking space. It is the address for EarthClassMail in SF. There are many P.O. box providers in the world; many geeks with taste reach for ECM. (Bits about Money is legally required to maintain a postal address and, if you were ever to send it a physical letter, that would also end up in the hands of an EarthClassMail employee.)&lt;/p&gt;
    &lt;p&gt;Elsewhere in the world, there exist P.O. box providers whose customers statistically include fewer AI labs and more frauds. One imagines the specialist-in-fraud at the storefront, picking up the day’s take from fifteen separate boxes.&lt;/p&gt;
    &lt;p&gt;Elementary work graphing supporting infrastructure, even on something as unsophisticated as butcher paper, frequently unravels fraud networks. Data science has any number of more sophisticated approaches. Jetson Leder-Luis, an academic who now routinely works with the government, has previously discussed some approaches which work based on widely commercially available data sources.&lt;/p&gt;
    &lt;p&gt;There is an emerging defender’s advantage here in the age of LLMs, since exploratory work in visualizing and walking network graphs is getting much cheaper. You no longer need to buy Palantir and engage a “forward-deployed engineer” to cluster IP addresses. A non-technical fraud investigator could get an LLM to do that while eating at Chipotle, and the lunch would cost more.&lt;/p&gt;
    &lt;p&gt;This democratization of capabilities is relevant to journalists, formal and otherwise, and also to governments. RFPs and software contracting once de facto mandated a multi-year lead time to do an automated network analysis if an analyst thought perhaps their program might need one. Now that is an afternoon’s work, if we allow ourselves to do it. We should.&lt;/p&gt;
    &lt;head rend="h3"&gt;Investigators should expect to find ethnically-clustered fraud&lt;/head&gt;
    &lt;p&gt;As mentioned, there is enormous visceral distaste for the conclusion that a particular fraud ring operates within a particular community. This is quite common. You should expect to find circumstances which rhyme with it when conducting effective fraud investigations. You should not abandon fraud investigation when you chance upon this.&lt;/p&gt;
    &lt;p&gt;People assume a level of ethical fraughtness here which is not warranted. You would, if doing ethnographic work on perfectly legitimate businesses across industries, routinely discover ethnic concentration rather than population-level representation everywhere you looked. The Patels run the motels. One doesn’t need to adopt grand theories about how certain groups are predisposed to becoming pharmacists or startup employees or line cooks; simple microeconomic reasoning explains reality easily. Firms hire the people they already know, like, and trust. That will routinely include friends and family, who are going to be much more like the founding team than they are like randomly drawn members of the population. This is the default outcome.&lt;/p&gt;
    &lt;p&gt;Fraudsters do have one structural factor here. Everyone wants to trust their coworkers. Fraudsters need to trust their coworkers will be loyal even upon threat of prison time. That necessarily selects for tighter bonds than the typical workplace. Madoff was a family affair, SBF was in an on-again off-again romantic relationship with a chief lieutenant, and neither of those facts is accidental or incidental.&lt;/p&gt;
    &lt;p&gt;That’s the other ethical dimension of being other-than-blind to concentration: so-called affinity frauds do not merely recruit fraudsters from affinity groups. They recruit victims from affinity groups. Madoff mobilized the social infrastructure of the Jewish community in New York and Palm Beach to find his marks. Community members certainly did not intend their charitable foundations to be looted by a fraudster. It was an emergent consequence of trust networks.&lt;/p&gt;
    &lt;p&gt;This also happens to “chosen” communities. FTX was, in material part, an affinity fraud against effective altruists, who are not a religion or ethnic group as traditionally construed.&lt;/p&gt;
    &lt;p&gt;And so when the great and the good turn a blind eye towards abuses because the perpetrators share an uncomfortable common factor, they are often simultaneously turning a blind eye towards abuses of a community whose interests they purport to champion.&lt;/p&gt;
    &lt;head rend="h3"&gt;High growth rate opportunities attract frauds&lt;/head&gt;
    &lt;p&gt;As covered extensively in Lying for Money, the necessary fundamental conceit of a fraud is growth in a business that doesn’t happen in the real world. “Every lie told incurs a debt to the truth, and one day, that debt will be paid”, to quote the excellent drama mini-series Chernobyl. Fraudsters forestall that day of reckoning by telling a bigger lie, increasing the debt, which (mostly as a side effect) alleges that they’re growing much faster than most of your legitimate portfolio. Happily, many businesses have figured out how to keep track of fast-growing customers. Tracking rocketships doesn’t require rocket science.&lt;/p&gt;
    &lt;p&gt;Sort-by-growth-rate-descending on new accounts will turn up a lot of interesting observations about the world. One is that Fortune 500 companies sometimes open new accounts, and you probably don’t need to open a fraud investigation file in that case. Another is that some people claim to be feeding millions of meals to a community of tens of thousands of people, beginning from a standing start, and growing local social services at a rate which an Uber Eats city manager would not expect to achieve in the wildest dreams of their go-to-market plan.&lt;/p&gt;
    &lt;p&gt;Feeding Our Future had a CAGR of 578% sustained for 2 years. Uber, during their meteoric growth period in core rideshare services, had an average CAGR of 226%. Their best year was 369%. But, if you asked in Minneapolis in 2021, you’d quickly find someone who had been in an Uber, but fail to find anyone who ate courtesy of Feeding Our Future. So curious, given that they were drubbing one of the fastest growing companies in history on growth rate.&lt;/p&gt;
    &lt;p&gt;Investigators in Minnesota were ringing the alarm bells for years about implausibly fast growth in Feeding Our Future’s reimbursement requests, including at new facilities. Feeding Our Future felt it was maxed out on the fraud it could conduct at existing sites, and expanded voraciously, including (most prominently) enrolling numerous restaurants as “feeding sites.” They then copy/pasted the usual playbook and requested reimbursement for implausible volumes at those sites, paying kickbacks to many participants. This then required growing the fraud, which… you get the general idea. We could have gotten off the bus at many points, and I suppose that is at some level a question of political will.&lt;/p&gt;
    &lt;p&gt;The highest growth rates in the economy generally are newer fields (you basically can’t sustain the alternative). This doesn’t imply that those fields are fraudulent, but they will tend to disproportionately attract frauds. The defenders in those fields have not yet paid their tuition to the School of Hard Knocks, and so attackers target the weaker systems. The higher growth rates of legitimate businesses function as protective cover for high stated growth rates of illegitimate businesses; a CAGR of 1,000% looks implausible for a restaurant but barely-meets-expectations for an AI software shop.&lt;/p&gt;
    &lt;p&gt;And, not to put too fine a point on it, many people are invested, literally and metaphorically, in whatever today’s new hotness is. People who could not secure an allocation in the more legitimate ends of it will sometimes find themselves adversarially selected by less salubrious actors. This will read to those people as a justly earned success. They might even have their marketing department write up their victimization as an indisputable success.&lt;/p&gt;
    &lt;p&gt;And so, if you’re a defender who has many different lines of business and has limited resources (or political will), where should you deploy those resources? Should you place your bets on e.g. Social Security, a multi-trillion dollar program whose primary source of growth is fun to conjure but then requires 70 years of seasoning? Or should you place them on the Paycheck Protection Program, or pandemic-era unemployment insurance, or genetic testing, or non-emergency medical transportation? Despite those being smaller line items, they probably have more juice worth squeezing, and the fraud is more easily detectable. Just look.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fraudsters find the weakest links in the financial system&lt;/head&gt;
    &lt;p&gt;Bits about Money has extensively covered anti-moneylaundering and Know Your Customer regulations and I won’t rehash those regimes here. A bit of tacit knowledge in the financial industry: some actors in the set “broadly considered trustworthy” are more worthy of trust than others… and some are less.&lt;/p&gt;
    &lt;p&gt;We are generally discreet about writing this down in as many words. But, as an analogy, cross-national regulatory bodies require that financial institutions maintain a list of high-risk jurisdictions to do business in. You are generally required to do enhanced due diligence on customers/activities/etc touching the high-risk list.&lt;/p&gt;
    &lt;p&gt;If you are particularly competent, and there are plusses and minuses to being competent in detecting fraud (you will not be the most popular person in the firm at bonus time; that goes to the folks who sold the high-growth accounts), you might have the analogous list of U.S. financial institutions which are not entirely fronts for the bad guys.&lt;/p&gt;
    &lt;p&gt;If one hypothetically has that list, that’s one more signal you can use in evaluating any particular account, and a one-stop shop for developing a list of accounts to look into. It would be uncouth of me to name an extant bank that has poor controls, but for a general example of the flavor, see my (scathing) commentary on Silvergate’s AML and KYC program. Without using any proprietary information, I predict confidently that Silvergate banked many more multi-billion dollar frauds as a percentage of its customer base than almost any of the U.S.’s 4,500 banks. (Trivial substantiation: divide FTXes-banked by total-count-of-customers.)&lt;/p&gt;
    &lt;p&gt;One might, if one has never seen the list, wonder whether it is simply proxying for something the financial industry is definitely not allowed to proxy for. One of the first things you learn as a data analyst is zip codes are extremely probative and you are absolutely not allowed to use them. The American system remembers the experience of redlining and has forbidden the financial industry from ever doing it again; the industry mostly respects that. But good news: institutions with weak controls environments are not, in fact, simply a proxy for “Who banks socially disadvantaged people?” There are many financial institutions that have that as an explicit business model. Some of them are good at their jobs. Some, less so, and the fraudsters know it.&lt;/p&gt;
    &lt;p&gt;This sometimes happens with the knowing connivance of the financial institution and/or their staff. For much more on that, see histories of the savings and loan crisis, or the Lying for Money chapter on control frauds. But more commonly it is simply a community of practice developing organic knowledge about who is just very easy to get an account with. You need accounts, as a business. As a fraudulent business, which intends to cycle through accounts and identities at a much higher rate than baseline, you would prefer to do business with a bank which will not detect that malfeasance.&lt;/p&gt;
    &lt;p&gt;And so you will disproportionately end up banked, with many of your buddies, at the least attentive place still capable of getting a license. And so an agency, trying to find a fraudulent network, might want to look at fraud-cases-by-routing-number and then start making some judgment calls.&lt;/p&gt;
    &lt;p&gt;One of the reasons the government has deputized the financial industry is it is good at keeping spreadsheets and quickly responds to requests for them. Perhaps the government should call up a few of their deputies and say “So, not alleging anything here, but we think you might have a list, carefully maintained by your fraud department for your own purposes. We want to see the list. It would be pro-social of you to give us a copy of it.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Frauds openly suborn identities&lt;/head&gt;
    &lt;p&gt;There is a thriving market in identities to be used in fraud. This is because bad actors prefer not putting their own names on paper trails certain to become evidence, because they frequently “burn” themselves early in their careers, and because institutions have cottoned onto the wisdom of collecting lists of ultimate beneficiaries.&lt;/p&gt;
    &lt;p&gt;Sometimes this is a social process, conducted at e.g. the dinner table. Sometimes the market is explicitly a market. Jetson recounted that, having exhausted the supply of patients needing dialysis who could plausibly need ambulance services, frauds began bribing potential patients, first with donuts and then with cash. This is extremely common. In Minnesota, parents were recruited to childcare providers with the promise of cash kickbacks or (a detail we’ll return to in a moment) fictitious paperworked no-show jobs, sometimes at substantially fictitious companies.&lt;/p&gt;
    &lt;p&gt;Fraudsters sometimes exercise some level of operational discipline in their communications. The bad guys have also seen The Wire; they know Stringer Bell’s dictum on the wisdom of keeping notes on a criminal conspiracy. However, the population of people willing to be named in a federal indictment over $200 necessarily selects preferentially for individuals who are not experts at operational security. They will sometimes organize recruitment very openly, using the same channels you use for recruiting at any other time: open Facebook groups, Reddit threads, and similar. They will film TikTok videos flashing their ill-gotten gains, and explaining steps in order for how you, too, can get paid.&lt;/p&gt;
    &lt;p&gt;As a fraud investigator, you are allowed and encouraged to read Facebook at work.&lt;/p&gt;
    &lt;p&gt;Now, knowing that there exists the frequent epiphenomenon where fraudsters recruit strawmen to use their identities to qualify for payments: suppose that you have an entirely new enterprise whose first customers are individuals A, B, C, and D. You know, from past records, that A, B, C, and D have all been customers of an organization which you now know, positively, was a fraudulent actor. You might infer from this that A, B, C, and D might have sold their identities once, but you probably don’t have sufficient information to convict them in a court of law of that. (It is of course possible that they are simply unsophisticated, or that bad actors obtained their information without their knowledge, for example by misappropriating a client list from a previous corporate entity they happened to own/work for/etc.)&lt;/p&gt;
    &lt;p&gt;But do you have enough information to take a more-detailed-than-usual look at this totally new enterprise? I think you do.&lt;/p&gt;
    &lt;head rend="h3"&gt;Asymmetry in attacker and defender burdens of proof&lt;/head&gt;
    &lt;p&gt;We have choices, as the defender, in what levels of evidence we require to enter the circle of trust, what our epistemological standards are, and how much evidence we require to forcibly exit someone from the circle of trust.&lt;/p&gt;
    &lt;p&gt;A detail from the Minnesota cases is that these burdens are asymmetric, in a way which disadvantages the defender (all of us). That decision is a choice and we should make better choices.&lt;/p&gt;
    &lt;p&gt;For example, the primary evidence of a child attending a day-care was a handwritten sign-in sheet of minimal probative value. Prosecutors referred to them as “almost comical” and “useless.” They were routinely fraudulently filled out by a 17 year old “signing” for dozens of parents sequentially in the same handwriting, excepting cases where they were simply empty.&lt;/p&gt;
    &lt;p&gt;To refute this “evidence”, the state forced itself to do weeks of stakeouts, producing hundreds of hours of video recording, after which it laboriously reconstructed exact counts of children seen entering/exiting a facility, compared it with the billing records, and then invoiced the centers only for proven overbilling.&lt;/p&gt;
    &lt;p&gt;On general industry knowledge, if you are selected for examination in e.g. your credit card processing account, and your submission of evidence is “Oh yeah, those transactions are ones we customarily paperwork with a 17 year old committing obvious fraud”, your account will be swiftly closed. The financial institution doesn’t have to reach a conclusion about every dollar which has ever flowed through your account. What actual purpose would there be in shutting the barn door after the horse has left? The only interesting question is what you’ll be doing tomorrow, and clearly what you intend to do tomorrow is fraud.&lt;/p&gt;
    &lt;p&gt;We can architect the asymmetry in the other fashion: legitimate businesses will customarily, as a fact of their operations, put enormous effort into creating visible effects in the world which are trivial to check. In technologist circles this is sometimes called a “proof of work” function.&lt;/p&gt;
    &lt;p&gt;Once upon a time, a team of fraud analysts asked how they could possibly determine frauds from non-frauds without having extensive industry knowledge about every possible commercializable human activity. I suggested that a good first pass was “Just ask the correspondent for a quick video, shot on their cell phone, of their workspace.”&lt;/p&gt;
    &lt;p&gt;That is minimally invasive for the business owner, generates a huge amount of signal (including that which can be correlated across accounts), and can be usefully adjudicated by non-specialists in a minute. No multi-month stakeout of their storefront is required. Of course you can convincingly fake a video of working in, say, a machine shop, but fraudsters maintaining spreadsheet row 87 about the machine shop will find that difficult to juggle with all the other required lies in their backlog. Actual machine shops, meanwhile, include people, which means they include functional cell phone cameras at no additional cost to anyone.&lt;/p&gt;
    &lt;p&gt;You can also get some signal from who can trivially produce a video and who needs a week of advance notice to find a cell phone to record those machines that were absolutely milling aluminum last week.&lt;/p&gt;
    &lt;p&gt;Fundamentally, we have a choice about where we put our investments in defanging fraud, and we should stop choosing to lose.&lt;/p&gt;
    &lt;p&gt;So-called “pay-and-chase”, where we put the burden on the government to disallow payments for violations retrospectively, has been enormously expensive and ineffective. Civil liability bounces off of exists-only-to-defraud LLC. Criminal prosecutions, among the most expensive kinds of intervention the government is capable of doing short of kinetic war, result in only a ~20% reduction in fraudulent behavior. Rearchitecting the process to require prior authorization resulted in an “immediate and permanent” 68% reduction. (I commend to you this research on Medicare fraud regarding dialysis transport. And yes, the team did some interesting work to distinguish fraudulent from legitimate usage of the program. Non-emergency transport for dialysis specifically had exploded in reimbursements—see Figure 1— not because American kidneys suddenly got worse but because fraudsters adversarially targeted an identified weakness in Medicare.)&lt;/p&gt;
    &lt;p&gt;Attackers carefully respond to signals they think they are being sent from defenders. A lawyer for some of the Minnesota defendants, Ryan Pacyga, was quoted by the New York Times as saying that his clients understood Minnesota to tacitly allow their actions.&lt;/p&gt;
    &lt;p&gt;&amp;gt; No one was doing anything about the red flags. … It was like someone was stealing money from the cookie jar and they kept refilling it.&lt;/p&gt;
    &lt;p&gt;Don’t be the defender who sends that message. It will not work out well for you or your program.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fraudsters under-paperwork their epiphenomena&lt;/head&gt;
    &lt;p&gt;Most frauds have rich external lives, with a soaring narrative of how deserving people are getting valuable services (and/or getting rich for being right and early regarding e.g. crypto asset cross-margining). They tend to be distinctly underpaperworked internally, partly because a synonym for “paperwork” is “evidence” and partly because… most frauds aren’t really that sophisticated, when it comes down to it. There is a true number; lie about it; done.&lt;/p&gt;
    &lt;p&gt;Like many time-pressed entrepreneurs busy talking to potential customers, fraudsters put the minimal amount of time necessary into bookkeeping and even less than that into paperworking epiphenomena of their frauds. One example of epiphenomena is sometimes the beneficiaries need their own paperwork. A legitimate mortgage company employs sales reps and a backoffice to help unsophisticated customers successfully get several hundred pages of paperwork together to sell a mortgage. Frauds… mostly don’t do that.&lt;/p&gt;
    &lt;p&gt;And so, if you have e.g. a statutory requirement that a beneficiary be employed to access services, a fraudster might say “Don’t worry about it!” They’ll just assert that you are an employee at a cleaning company. Perhaps they might even go as far as payrolling you as an employee of a cleaning company. This kills two birds with one stone, paying you your kickback while also generating the paystub they need you to have to qualify for the government reimbursement. (This happened, per the OLA’s reports summarizing the results of many investigations, in Minnesota.)&lt;/p&gt;
    &lt;p&gt;But fraudsters don’t actually operate cleaning companies even in those cases where they do operate daycares.&lt;/p&gt;
    &lt;p&gt;Cleaning companies are legitimate businesses, in the main, and working for one is an honest occupation. And so a fraud investigator should feel no chagrin at calling a cleaning company in the phone book and asking for a quote. A cleaning company which expresses complete befuddlement that someone could ask for a quote is providing, ahem, evidence in a direction.&lt;/p&gt;
    &lt;p&gt;(I have to note, as someone who pays to send children to a private school, that there is replete evidence that the school is accepting new children, knocking on the door and asking will quickly result in being given a brochure, and there are scheduled open houses and similar. I can imagine a gratuitously mismanaged educational establishment which does none of these things, and I can imagine an educational establishment which makes a lot of money, but I have trouble holding both thoughts in my head at the same time.)&lt;/p&gt;
    &lt;p&gt;The core frauds are sometimes hardened, to an attenuated degree. The peripheral frauds collapse under even a glance. Architect processes to require more signals regarding the periphery, then architect a system which takes at least a cursory look at the periphery. You will trivially catch frauds.&lt;/p&gt;
    &lt;p&gt;If you’re worried about exposing the exact signal that you are using, costing utility of it in the future, you can use this as a “parallel construction” engine. Develop leads for investigation using the non-public signal, pull the core records as a matter of routine, find the discrepancies that all frauds leave in their core records, and then put those in the indictment. Ask your friendly neighborhood lawyer if that passes muster or if you need to add a sentence rhyming with “was selected for a routine audit on the basis of information available to the department.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Machine learning can adaptively identify fraud&lt;/head&gt;
    &lt;p&gt;We have discussed some heuristics [1] for identifying fraud. The financial industry still makes material use of heuristics, but a heuristic is a compression of the real world. It will sometimes lose fidelity to the world. It will frequently, by design, be legible to the adversary.&lt;/p&gt;
    &lt;p&gt;The defender has one advantage the attacker cannot ever replicate: data at scale. It knows what legitimate use looks like because it has all the messy, contradictory, varying quality, typos-and-all data which legitimate businesses in the real world constantly throw off. You cannot duplicate all of the shadows on the wall of Plato’s cave without first duplicating the entire world. Fraudsters, even quite talented ones, can’t do that.&lt;/p&gt;
    &lt;p&gt;There are any number of techniques for machine learning in anti-fraud; Emily Sands has previously discussed some with me. An important subset of the field can adapt in real-time or close to it to changes in adversary (or legitimate!) behavior. For example, covid surprised the fraudsters at the same time as it surprised every supermarket in the country, but the ex-post actions of the fraudsters and the supermarkets were very different. Revenue went up for both, but only one group actually runs a supermarket. And so by ingesting and constantly analyzing data from all users, including retrospective annotation of which users you’ve identified to be frauds, you get better and earlier signals on which users are likely fraudulent and which are likely not.&lt;/p&gt;
    &lt;p&gt;This can inform outright interdiction or the investigate-then-punish loop that we ordinarily expect from government. It can also inform less consequential, easier-to-reverse interventions. For example, rather than putting all users immediately through the highest-possible-ceremony process for application, you can let most users do a lower-burden process, saving the higher levels of scrutiny for those which signal greater likelihood of being fraudulent. Or you can default to approving more applicants and reserve more of your investigatory budget for post-approval review, with this being equivalently costly by using better tasking of those reviews versus random allocation. Pay-and-chase becomes more palatable if it is not pay-and-pay-and-pay-and-pay-and-chase and more pay-until-we-decide-to-chase-but-stop-payments-at-that-decision-not-after-the-catching.&lt;/p&gt;
    &lt;p&gt;Machine learning isn’t simply useful from a perspective of decreasing fraud. The history of regulation of benefits programs is the history of too-late, too-harsh overcorrection to notorious abuses. Much of what advocates find most maddening and Kafkaesque about eligibility criteria and application processes was voted on by a legislature but bears the signature of a fraudster with a novel idea.&lt;/p&gt;
    &lt;p&gt;With a good machine learning practice, you can increase data ingested but decrease the burdensome formal application/etc requirements. This is in no small part because those data points are less probative (they are under the direct control of the attacker and announce that they will be scrutinized). But it bears a dividend: if you better control fraud, and can successfully demonstrate that to the public and legislators, you can decrease application burden and perhaps even widen eligibility criteria. Those are both in the direct interests of potential marginal beneficiaries.&lt;/p&gt;
    &lt;p&gt;A political commentator might focus more on the optics here than on the substance, because that is so frequently where the point of actual leverage is in politics. But the substantive reality of fraud losses matters. It is much easier to tell the story of fraud in benefits programs being rare, opposed by all right-thinking people, and swiftly sanctioned when that story is not an obvious lie.&lt;/p&gt;
    &lt;head rend="h3"&gt;Frauds have a lifecycle&lt;/head&gt;
    &lt;p&gt;You can read Lying for Money or other histories of frauds for more detail on the texture, but in the main, a dedicated fraudulent enterprise is created, is seasoned for a while before crossing the rubicon, has a period of increasing brazenness, is detected, is closed, and then is resurrected when the fraudster gets the band back together from round N+1.&lt;/p&gt;
    &lt;p&gt;We can intervene against the lifecycle model if we understand it. This begins with not defaulting to the understanding of investigators that frauds are isolated incidents by disparate individual actors. Those have been known to happen, but frauds are, by total damage, dominated by repeatable business models perpetrated by professional specialized bad actors. We should study them like we study other successful entrepreneurs, and then not invest in them.&lt;/p&gt;
    &lt;p&gt;One actionable insight from the lifecycle model: because the fraudster intends to be in business multiple times in their life, we should track the person-to-business mapping much more closely than we have historically. As Lying for Money says, if you’re an accountant and willing to go to prison, and you do not get rich via fraud… well, you are very bad at your job. That’s on you. When we give you repeated chances to do it, that’s on us.&lt;/p&gt;
    &lt;p&gt;One might think that the simplest imaginable reform is passing some sort of beneficial ownership regulation to unroll complex corporate structures designed to obscure who is actually puppeting Totally Not A Fraud, LLC. But the simplest imaginable reform is probably just actually reading corporate filings that already exist and are public. Again, most fraudsters are not the hypersophisticated Moriarties of the popular imagination. The Minnesota fraudsters frequently did not even bother with fig leaves. While they did find some nominee directors in some cases, many of the convicted operated their companies in their own names, with no complicated structuring at all. Sometimes multiple times, consecutively, after the previous entities had worn out their welcome with Minnesota.&lt;/p&gt;
    &lt;p&gt;The Fed should not be surprised when the bad guys buy a bank when buying a bank requires an extended permission-seeking process and the bad guy’s corporate records, dutifully recorded by Maryland (entity D20033544), are signed by a notorious bagman. In the Fed’s defense, the bagman lied to them about his intentions, which was outside of their world model. (Pip pip to the New York Times for figuring that out before the Fed did. That is, sadly, not the usual way it works in financial journalism.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Should we care about fraud investigation, anyway?&lt;/head&gt;
    &lt;p&gt;Responsible actors in civil society have a mandate to aggressively detect and interdict fraud. If they do not, they cede the field to irresponsible demagogues. They will not be careful in their conclusions. They will not be gentle in their proposals. They will not carefully weigh consequences upon the innocent. But they will be telling a truth that the great and the good are not.&lt;/p&gt;
    &lt;p&gt;The public will believe them, because the public believes its lying eyes.&lt;/p&gt;
    &lt;p&gt;[0] In a thing you will see frequently in fraud investigations, early detection of anomalies does not necessarily imply successful identification of the underlying fraudulent enterprise. A teacher was scandalized that a third of their students are using AI to write papers. Those “students” are identities puppeted by a criminal organization to siphon federal funding out of community colleges towards accounts controlled by the criminals. (I award myself one cookie for correctly predicting this.)&lt;/p&gt;
    &lt;p&gt;[1] A heuristic, in industry parlance, is a hard-coded rule or set of rules as opposed to a system which automatically adapts to changes in the underlying data. Compare the difference between “You are less likely to default on loans if you own versus renting”, which is absolutely demonstrable in aggregate data, versus “You are less likely to default on loans at 780 FICO versus 540 FICO.” For a variety of reasons, the culture that is legislators sees the problem with having one heuristic, which will obviously not come to the correct conclusion all of the time. It corrects for this issue by having several hundred pages of heuristics. Just one more heuristic, man, and we’ll have completely anticipated all the complexity of the world.&lt;/p&gt;
    &lt;p&gt;Heuristics are wonderful things! They’re cheap to adjudicate, easy to explain, and can be understood by lawyers, even the kind who have ascended from the practice of law to the writing of it. Happily, machine learning systems can have all of these properties if you make them priorities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Want more essays in your inbox?&lt;/head&gt;
    &lt;p&gt;I write about the intersection of tech and finance, approximately biweekly. It's free.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bitsaboutmoney.com/archive/fraud-investigation/"/><published>2026-02-06T17:24:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46915646</id><title>Uber Found Liable in Rape by Driver, Setting Stage for Cases</title><updated>2026-02-06T18:03:03.431112+00:00</updated><content/><link href="https://www.nytimes.com/2026/02/05/business/uber-safety-rape-verdict.html"/><published>2026-02-06T17:29:39+00:00</published></entry></feed>