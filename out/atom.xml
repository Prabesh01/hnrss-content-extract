<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-23T15:45:46.096288+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46721897</id><title>AnswerThis (YC F25) Is Hiring</title><updated>2026-01-23T15:45:59.137817+00:00</updated><content>&lt;doc fingerprint="3d09585cf826800c"&gt;
  &lt;main&gt;
    &lt;p&gt;End-to-end workspace to accelerate scientific discovery&lt;/p&gt;
    &lt;p&gt;We crossed $1M ARR in 8 months. 200,000+ researchers at Stanford, MIT, and Amazon use us to do literature reviews 10x faster.&lt;lb/&gt; Now we're building something bigger: the system of record for scientists where they can find papers, analyze experiments, and write their drafts while collaborating with other scientists as well as our AI agents. &lt;lb/&gt; You should apply if you:&lt;lb/&gt; → Ship fast and learn faster &lt;lb/&gt; → Know the agentic AI stack cold (vector DBs, graph RAG, agent memory) &lt;lb/&gt; → Have built full-stack products that scaled past 1M users &lt;lb/&gt; → Actually care about accelerating scientific discovery&lt;lb/&gt; Bonus: You've published research yourself. &lt;lb/&gt; Don't apply if you:&lt;lb/&gt; → Can't be in SF, in person &lt;lb/&gt; → Haven't used the product yet &lt;lb/&gt; → Don't want to talk to customers &lt;lb/&gt; $120K-$200K + equity. We're a small team backed by YC. &lt;lb/&gt; Reach out on careers [at] answerthis.io&lt;lb/&gt; Tell us what you hate about AnswerThis, what you love, and one project you're proud of alongside your resume.&lt;lb/&gt; Science moves too slowly. Help us fix that.&lt;/p&gt;
    &lt;p&gt;We move fast. The whole process can be done in 2-3 weeks.&lt;/p&gt;
    &lt;p&gt;AnswerThis is building the system of record for scientists—where researchers can find papers, analyze experiments, and write drafts while collaborating with other scientists and AI agents.&lt;/p&gt;
    &lt;p&gt;We crossed $1M ARR in 8 months. 200,000+ researchers at Stanford, MIT, Amazon, and top institutions worldwide use us daily. We're backed by Y Combinator (F25) and cash-flow positive.&lt;/p&gt;
    &lt;p&gt;Science moves too slowly. Grant applications take months. Literature reviews take weeks. Researchers spend more time on paperwork than on discovery. We're fixing that.&lt;/p&gt;
    &lt;p&gt;You'll be joining a small, fast team in SF that ships constantly and talks to customers every day.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/answerthis/jobs/r5VHmSC-ai-agent-orchestration"/><published>2026-01-22T17:00:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46723384</id><title>I was banned from Claude for scaffolding a Claude.md file?</title><updated>2026-01-23T15:45:58.708814+00:00</updated><content>&lt;doc fingerprint="c61ded10eca0acfa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why does SSH send 100 packets per keystroke?&lt;/head&gt;
    &lt;p&gt;And why do I care?&lt;/p&gt;
    &lt;p&gt;Jan 22, 2026&lt;/p&gt;
    &lt;p&gt;Here are a few lines of summarized &lt;code&gt;tcpdump&lt;/code&gt; output for an ssh session where I send a single keystroke:&lt;/p&gt;
    &lt;code&gt;$ ./first_lines_of_pcap.sh single-key.pcap
  1   0.000s  CLIENT-&amp;gt;SERVER   36 bytes
  2   0.007s  SERVER-&amp;gt;CLIENT  564 bytes
  3   0.015s  CLIENT-&amp;gt;SERVER    0 bytes
  4   0.015s  CLIENT-&amp;gt;SERVER   36 bytes
  5   0.015s  SERVER-&amp;gt;CLIENT   36 bytes
  6   0.026s  CLIENT-&amp;gt;SERVER    0 bytes
  7   0.036s  CLIENT-&amp;gt;SERVER   36 bytes
  8   0.036s  SERVER-&amp;gt;CLIENT   36 bytes
  9   0.046s  CLIENT-&amp;gt;SERVER    0 bytes
 10   0.059s  CLIENT-&amp;gt;SERVER   36 bytes
&lt;/code&gt;
    &lt;p&gt;I said a “few” because there are a lot of these lines.&lt;/p&gt;
    &lt;code&gt;$ ./summarize_pcap.sh single-key.pcap
Total packets: 270

  36-byte msgs:   179 packets ( 66.3%)   6444 bytes
  Other data:       1 packet  (  0.4%)    564 bytes
  TCP ACKs:        90 packets ( 33.3%)

  Data sent:      6444 bytes in 36-byte messages,  564 bytes in other data
  Ratio:          11.4x more data in 36-byte messages than other data

  Data packet rate: ~90 packets/second (avg 11.1 ms between data packets)
&lt;/code&gt;
    &lt;p&gt;That is a lot of packets for one keypress. What’s going on here? Why do I care?&lt;/p&gt;
    &lt;head class="sc-4d1d4ca-1 bowwWe"&gt;here's those scripts if you're curious&lt;/head&gt;
    &lt;code&gt;# first_lines_of_pcap.sh
tshark -r "$1" \
  -T fields -e frame.number -e frame.time_relative -e ip.src -e ip.dst -e tcp.len | \
  awk 'NR&amp;lt;=10 {dir = ($3 ~ /71\.190/ ? "CLIENT-&amp;gt;SERVER" : "SERVER-&amp;gt;CLIENT");
       printf "%3d  %6.3fs  %-4s  %3s bytes\n", $1, $2, dir, $5}'
&lt;/code&gt;
    &lt;code&gt;# summarize_pcap.sh
tshark -r "$1" -Y "frame.time_relative &amp;lt;= 2.0" -T fields -e frame.time_relative -e tcp.len | awk '
  {
      count++
      payload = $2

      if (payload == 0) {
          acks++
      } else if (payload == 36) {
          mystery++
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      } else {
          game_data++
          game_bytes = payload
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      }
  }
  END {
      print "Total packets:", count
      print ""
      printf "  36-byte msgs:   %3d packets (%5.1f%%)  %5d bytes\n", mystery, 100*mystery/count, mystery*36
      printf "  Other data:     %3d packet  (%5.1f%%)  %5d bytes\n", game_data, 100*game_data/count, game_bytes
      printf "  TCP ACKs:       %3d packets (%5.1f%%)\n", acks, 100*acks/count
      print ""
      printf "  Data sent:      %d bytes in 36-byte messages,  %d bytes in other data\n", mystery*36, game_bytes
      printf "  Ratio:          %.1fx more data in 36-byte messages than other data\n", (mystery*36)/game_bytes
      print ""
      avg_ms = (sum_data_deltas / data_intervals) * 1000
      printf "  Data packet rate: ~%d packets/second (avg %.1f ms between data packets)\n", int(1000/avg_ms + 0.5), avg_ms
  }'
&lt;/code&gt;
    &lt;head rend="h2"&gt;Discovery&lt;/head&gt;
    &lt;p&gt;I am working on a high-performance game that runs over ssh. The TUI for the game is created in bubbletea 1 and sent over ssh via wish.&lt;/p&gt;
    &lt;p&gt;I have also forked bubbletea to make it faster. Stay tuned!&lt;/p&gt;
    &lt;p&gt;The game is played in an 80x60 window that I update 10 times a second. I’m targeting at least 2,000 concurrent players, which means updating ~100 million cells a second. I care about performance.&lt;/p&gt;
    &lt;p&gt;So I have a script that connects a few hundred bots over ssh and has them make a move a second. Then I use go’s outstanding profiling tools to look at what’s going on.&lt;/p&gt;
    &lt;p&gt;Yesterday I inadvertently broke my test harness. Instead of regularly sending game data, my server sent the bots a single message that said “your screen is too small.” This cut my game’s CPU and bandwidth usage in half.&lt;/p&gt;
    &lt;p&gt;At first I was disappointed. I (briefly) thought I had a free massive speedup on my hands, but it was actually a testing error.&lt;/p&gt;
    &lt;p&gt;But wait.&lt;/p&gt;
    &lt;p&gt;If I wasn’t sending game data back to my bots, why did CPU usage drop by 50% instead of 100%?&lt;/p&gt;
    &lt;head rend="h2"&gt;Investigation&lt;/head&gt;
    &lt;p&gt;As part of debugging the test harness issue, I used &lt;code&gt;tcpdump&lt;/code&gt; to log game traffic with and without the breaking change. Something like:&lt;/p&gt;
    &lt;code&gt;# The game runs on port 22
timeout 30s tcpdump -i eth0 'port 22' -w with-breaking-change.pcap
# Revert change
timeout 30s tcpdump -i eth0 'port 22' -w without-breaking-change.pcap
&lt;/code&gt;
    &lt;p&gt;Our breaking change stopped us from rendering our game over ssh. So &lt;code&gt;with-breaking-change.pcap&lt;/code&gt; contains packets that represent the overhead of each connection without actually rendering the game.&lt;/p&gt;
    &lt;p&gt;I was debugging this with Claude Code, so I asked it to summarize what it saw in the pcap.&lt;/p&gt;
    &lt;code&gt;Wanna take a look yourself? I put with-breaking-change.pcap in this directory

--

Wow! Here's what I found:

Packet Size Distribution (413,703 total packets):
274,907 packets (66%): Exactly 36 bytes
138,778 packets (34%): 0 bytes (TCP ACKs)
18 packets (&amp;lt;0.1%): 72 bytes
&lt;/code&gt;
    &lt;p&gt;Further analysis on a smaller pcap pointed to these mysterious packets arriving ~20ms apart.&lt;/p&gt;
    &lt;p&gt;This was baffling to me (and to Claude Code). We kicked around several ideas like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SSH flow control messages&lt;/item&gt;
      &lt;item&gt;PTY size polling or other status checks&lt;/item&gt;
      &lt;item&gt;Some quirk of bubbletea or wish&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One thing stood out - these exchanges were initiated by my ssh client (stock ssh installed on MacOS) - not by my server.&lt;/p&gt;
    &lt;p&gt;On a hunch, I took a &lt;code&gt;tcpdump&lt;/code&gt; of a regular ssh session.&lt;/p&gt;
    &lt;code&gt;# on my mac, in one tab
sudo tcpdump -ien0 'port 22'

# on my mac, in another tab
ssh $some_vm_of_mine
&lt;/code&gt;
    &lt;p&gt;I waited for the initial connection chatter to die down, sent one keystroke to my remote vm, and looked at the &lt;code&gt;tcpdump&lt;/code&gt; output.&lt;/p&gt;
    &lt;p&gt;I saw the exact same pattern! What in the world?&lt;/p&gt;
    &lt;head rend="h2"&gt;Root cause&lt;/head&gt;
    &lt;p&gt;Once I realized that this was a property of stock ssh and not my game, debugging got a lot easier.&lt;/p&gt;
    &lt;p&gt;Running &lt;code&gt;ssh -vvv&lt;/code&gt; gave me a pretty good sense of what was going on:&lt;/p&gt;
    &lt;code&gt;debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (49 chaff packets sent) 
debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (101 chaff packets sent)
&lt;/code&gt;
    &lt;p&gt;That &lt;code&gt;20ms&lt;/code&gt; is a smoking gun - it lines up perfectly with the mysterious pattern we saw earlier! And the rest of the message is pretty helpful too - we sent 49 “chaff” packets for the first keystroke and 101 “chaff” for around the second one.&lt;/p&gt;
    &lt;p&gt;In 2023, ssh added keystroke timing obfuscation. The idea is that the speed at which you type different letters betrays some information about which letters you’re typing. So ssh sends lots of “chaff” packets along with your keystrokes to make it hard for an attacker to determine when you’re actually entering keys.&lt;/p&gt;
    &lt;p&gt;That makes a lot of sense for regular ssh sessions, where privacy is critical. But it’s a lot of overhead for an open-to-the-whole-internet game where latency is critical.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Keystroke obfuscation can be disabled client-side. After reverting my original breaking change, I tried updating my test harness to pass &lt;code&gt;ObscureKeystrokeTiming=no&lt;/code&gt; when starting up ssh sessions.&lt;/p&gt;
    &lt;p&gt;This worked great. CPU usage dropped dramatically and bots still received valid data.&lt;/p&gt;
    &lt;p&gt;But this is hardly a solution in the real world. I want &lt;code&gt;ssh mygame&lt;/code&gt; to Just Work without asking users to pass options that they might not understand.&lt;/p&gt;
    &lt;p&gt;Claude Code originally didn’t have much faith that we could disable this functionality server-side.&lt;/p&gt;
    &lt;p&gt;generated with simon wilson's excellent claude-code-transcripts tool&lt;/p&gt;
    &lt;p&gt;Fortunately, the description I found of SSH keystroke obfuscation made it easy to look up the relevant code in go’s ssh library (which I was transitively depending on).&lt;/p&gt;
    &lt;code&gt;Log message:
Introduce a transport-level ping facility

This adds a pair of SSH transport protocol messages SSH2_MSG_PING/PONG
to implement a ping capability. These messages use numbers in the "local
extensions" number space and are advertised using a "[email protected]"
ext-info message with a string version number of "0".
&lt;/code&gt;
    &lt;p&gt;The “chaff” messages that ssh uses to obscure keystrokes are SSH2_MSG_PING messages. And they’re sent to servers that advertise the availability of the &lt;code&gt;[email protected]&lt;/code&gt; extension. What if we just…don’t advertise &lt;code&gt;[email protected]&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;I searched go’s ssh library for &lt;code&gt;[email protected]&lt;/code&gt; and found the commit where support was added. The commit was tiny and seemed very easy to revert.&lt;/p&gt;
    &lt;p&gt;I cloned the go crypto repo and told Claude to revert this change and update our dependencies to use our clone (go’s replace directive makes forking a library very easy).&lt;/p&gt;
    &lt;p&gt;Then I re-ran my test harness. The results were…very good:&lt;/p&gt;
    &lt;code&gt;Total CPU  29.90%          -&amp;gt; 11.64%
Syscalls   3.10s           -&amp;gt; 0.66s
Crypto     1.6s            -&amp;gt; 0.11s
Bandwidth  ~6.5 Mbit/sec   -&amp;gt; ~3 Mbit/sec
&lt;/code&gt;
    &lt;p&gt;Claude was also pretty pumped:&lt;/p&gt;
    &lt;p&gt;yes it's 1:30 am what of it&lt;/p&gt;
    &lt;p&gt;Obviously forking go’s crypto library is a little scary, and I’m gonna have to do some thinking about how to maintain my little patch in a safe way.&lt;/p&gt;
    &lt;p&gt;But this is a huge improvement. I’ve spent much of the last week squeezing out small single-digit performance wins. A &amp;gt;50% drop was unimaginable to me.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging with LLMs was fun&lt;/head&gt;
    &lt;p&gt;I’ve been thinking about whether LLMs remove parts of the problem-solving process that I enjoy. But I’ve gotta say, debugging this problem using Claude Code was super fun.&lt;/p&gt;
    &lt;p&gt;I am familiar enough with &lt;code&gt;tcpdump&lt;/code&gt;, &lt;code&gt;tshark&lt;/code&gt;, and friends to know what they can do. But I don’t use them regularly enough to be fast with them. Being able to tell an agent “here’s a weird pcap - tell me what’s going on” was really lovely. And by watching commands as the agent ran them I was able to keep my mental model of the problem up to date.&lt;/p&gt;
    &lt;p&gt;There were still edge cases. At some point in my confusion I switched to ChatGPT and it very confidently told me that my tcpdump output was normal ssh behavior:&lt;/p&gt;
    &lt;p&gt;do all chatgpt messages have this tone and formatting now?&lt;/p&gt;
    &lt;p&gt;And then doubled down when I pushed back:&lt;/p&gt;
    &lt;p&gt;no!!!&lt;/p&gt;
    &lt;p&gt;Similarly, I had to push Claude Code to consider forking go’s ssh library. And I had to make the original leap of “wait…if our test harness was broken, why was usage not 0%?”&lt;/p&gt;
    &lt;p&gt;When you say “LLMs did not fully solve this problem” some people tend to respond with “you’re holding it wrong!”&lt;/p&gt;
    &lt;p&gt;I think they’re sometimes right! Interacting with LLMs is a new skill, and it feels pretty weird if you’re used to writing software like it’s 2020. A more talented user of LLMs may have trivially solved this problem.&lt;/p&gt;
    &lt;p&gt;But the best way to develop a skill is by practicing it. And for me, that means figuring out how to transfer my problem-solving intuitions to the tools that I’m using.&lt;/p&gt;
    &lt;p&gt;Besides. Being in the loop is fun. How else would I write this post?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hugodaniel.com/posts/claude-code-banned-me/"/><published>2026-01-22T18:38:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46723990</id><title>Why does SSH send 100 packets per keystroke?</title><updated>2026-01-23T15:45:58.276941+00:00</updated><content>&lt;doc fingerprint="c61ded10eca0acfa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why does SSH send 100 packets per keystroke?&lt;/head&gt;
    &lt;p&gt;And why do I care?&lt;/p&gt;
    &lt;p&gt;Jan 22, 2026&lt;/p&gt;
    &lt;p&gt;Here are a few lines of summarized &lt;code&gt;tcpdump&lt;/code&gt; output for an ssh session where I send a single keystroke:&lt;/p&gt;
    &lt;code&gt;$ ./first_lines_of_pcap.sh single-key.pcap
  1   0.000s  CLIENT-&amp;gt;SERVER   36 bytes
  2   0.007s  SERVER-&amp;gt;CLIENT  564 bytes
  3   0.015s  CLIENT-&amp;gt;SERVER    0 bytes
  4   0.015s  CLIENT-&amp;gt;SERVER   36 bytes
  5   0.015s  SERVER-&amp;gt;CLIENT   36 bytes
  6   0.026s  CLIENT-&amp;gt;SERVER    0 bytes
  7   0.036s  CLIENT-&amp;gt;SERVER   36 bytes
  8   0.036s  SERVER-&amp;gt;CLIENT   36 bytes
  9   0.046s  CLIENT-&amp;gt;SERVER    0 bytes
 10   0.059s  CLIENT-&amp;gt;SERVER   36 bytes
&lt;/code&gt;
    &lt;p&gt;I said a “few” because there are a lot of these lines.&lt;/p&gt;
    &lt;code&gt;$ ./summarize_pcap.sh single-key.pcap
Total packets: 270

  36-byte msgs:   179 packets ( 66.3%)   6444 bytes
  Other data:       1 packet  (  0.4%)    564 bytes
  TCP ACKs:        90 packets ( 33.3%)

  Data sent:      6444 bytes in 36-byte messages,  564 bytes in other data
  Ratio:          11.4x more data in 36-byte messages than other data

  Data packet rate: ~90 packets/second (avg 11.1 ms between data packets)
&lt;/code&gt;
    &lt;p&gt;That is a lot of packets for one keypress. What’s going on here? Why do I care?&lt;/p&gt;
    &lt;head class="sc-4d1d4ca-1 bowwWe"&gt;here's those scripts if you're curious&lt;/head&gt;
    &lt;code&gt;# first_lines_of_pcap.sh
tshark -r "$1" \
  -T fields -e frame.number -e frame.time_relative -e ip.src -e ip.dst -e tcp.len | \
  awk 'NR&amp;lt;=10 {dir = ($3 ~ /71\.190/ ? "CLIENT-&amp;gt;SERVER" : "SERVER-&amp;gt;CLIENT");
       printf "%3d  %6.3fs  %-4s  %3s bytes\n", $1, $2, dir, $5}'
&lt;/code&gt;
    &lt;code&gt;# summarize_pcap.sh
tshark -r "$1" -Y "frame.time_relative &amp;lt;= 2.0" -T fields -e frame.time_relative -e tcp.len | awk '
  {
      count++
      payload = $2

      if (payload == 0) {
          acks++
      } else if (payload == 36) {
          mystery++
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      } else {
          game_data++
          game_bytes = payload
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      }
  }
  END {
      print "Total packets:", count
      print ""
      printf "  36-byte msgs:   %3d packets (%5.1f%%)  %5d bytes\n", mystery, 100*mystery/count, mystery*36
      printf "  Other data:     %3d packet  (%5.1f%%)  %5d bytes\n", game_data, 100*game_data/count, game_bytes
      printf "  TCP ACKs:       %3d packets (%5.1f%%)\n", acks, 100*acks/count
      print ""
      printf "  Data sent:      %d bytes in 36-byte messages,  %d bytes in other data\n", mystery*36, game_bytes
      printf "  Ratio:          %.1fx more data in 36-byte messages than other data\n", (mystery*36)/game_bytes
      print ""
      avg_ms = (sum_data_deltas / data_intervals) * 1000
      printf "  Data packet rate: ~%d packets/second (avg %.1f ms between data packets)\n", int(1000/avg_ms + 0.5), avg_ms
  }'
&lt;/code&gt;
    &lt;head rend="h2"&gt;Discovery&lt;/head&gt;
    &lt;p&gt;I am working on a high-performance game that runs over ssh. The TUI for the game is created in bubbletea 1 and sent over ssh via wish.&lt;/p&gt;
    &lt;p&gt;I have also forked bubbletea to make it faster. Stay tuned!&lt;/p&gt;
    &lt;p&gt;The game is played in an 80x60 window that I update 10 times a second. I’m targeting at least 2,000 concurrent players, which means updating ~100 million cells a second. I care about performance.&lt;/p&gt;
    &lt;p&gt;So I have a script that connects a few hundred bots over ssh and has them make a move a second. Then I use go’s outstanding profiling tools to look at what’s going on.&lt;/p&gt;
    &lt;p&gt;Yesterday I inadvertently broke my test harness. Instead of regularly sending game data, my server sent the bots a single message that said “your screen is too small.” This cut my game’s CPU and bandwidth usage in half.&lt;/p&gt;
    &lt;p&gt;At first I was disappointed. I (briefly) thought I had a free massive speedup on my hands, but it was actually a testing error.&lt;/p&gt;
    &lt;p&gt;But wait.&lt;/p&gt;
    &lt;p&gt;If I wasn’t sending game data back to my bots, why did CPU usage drop by 50% instead of 100%?&lt;/p&gt;
    &lt;head rend="h2"&gt;Investigation&lt;/head&gt;
    &lt;p&gt;As part of debugging the test harness issue, I used &lt;code&gt;tcpdump&lt;/code&gt; to log game traffic with and without the breaking change. Something like:&lt;/p&gt;
    &lt;code&gt;# The game runs on port 22
timeout 30s tcpdump -i eth0 'port 22' -w with-breaking-change.pcap
# Revert change
timeout 30s tcpdump -i eth0 'port 22' -w without-breaking-change.pcap
&lt;/code&gt;
    &lt;p&gt;Our breaking change stopped us from rendering our game over ssh. So &lt;code&gt;with-breaking-change.pcap&lt;/code&gt; contains packets that represent the overhead of each connection without actually rendering the game.&lt;/p&gt;
    &lt;p&gt;I was debugging this with Claude Code, so I asked it to summarize what it saw in the pcap.&lt;/p&gt;
    &lt;code&gt;Wanna take a look yourself? I put with-breaking-change.pcap in this directory

--

Wow! Here's what I found:

Packet Size Distribution (413,703 total packets):
274,907 packets (66%): Exactly 36 bytes
138,778 packets (34%): 0 bytes (TCP ACKs)
18 packets (&amp;lt;0.1%): 72 bytes
&lt;/code&gt;
    &lt;p&gt;Further analysis on a smaller pcap pointed to these mysterious packets arriving ~20ms apart.&lt;/p&gt;
    &lt;p&gt;This was baffling to me (and to Claude Code). We kicked around several ideas like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SSH flow control messages&lt;/item&gt;
      &lt;item&gt;PTY size polling or other status checks&lt;/item&gt;
      &lt;item&gt;Some quirk of bubbletea or wish&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One thing stood out - these exchanges were initiated by my ssh client (stock ssh installed on MacOS) - not by my server.&lt;/p&gt;
    &lt;p&gt;On a hunch, I took a &lt;code&gt;tcpdump&lt;/code&gt; of a regular ssh session.&lt;/p&gt;
    &lt;code&gt;# on my mac, in one tab
sudo tcpdump -ien0 'port 22'

# on my mac, in another tab
ssh $some_vm_of_mine
&lt;/code&gt;
    &lt;p&gt;I waited for the initial connection chatter to die down, sent one keystroke to my remote vm, and looked at the &lt;code&gt;tcpdump&lt;/code&gt; output.&lt;/p&gt;
    &lt;p&gt;I saw the exact same pattern! What in the world?&lt;/p&gt;
    &lt;head rend="h2"&gt;Root cause&lt;/head&gt;
    &lt;p&gt;Once I realized that this was a property of stock ssh and not my game, debugging got a lot easier.&lt;/p&gt;
    &lt;p&gt;Running &lt;code&gt;ssh -vvv&lt;/code&gt; gave me a pretty good sense of what was going on:&lt;/p&gt;
    &lt;code&gt;debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (49 chaff packets sent) 
debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (101 chaff packets sent)
&lt;/code&gt;
    &lt;p&gt;That &lt;code&gt;20ms&lt;/code&gt; is a smoking gun - it lines up perfectly with the mysterious pattern we saw earlier! And the rest of the message is pretty helpful too - we sent 49 “chaff” packets for the first keystroke and 101 “chaff” for around the second one.&lt;/p&gt;
    &lt;p&gt;In 2023, ssh added keystroke timing obfuscation. The idea is that the speed at which you type different letters betrays some information about which letters you’re typing. So ssh sends lots of “chaff” packets along with your keystrokes to make it hard for an attacker to determine when you’re actually entering keys.&lt;/p&gt;
    &lt;p&gt;That makes a lot of sense for regular ssh sessions, where privacy is critical. But it’s a lot of overhead for an open-to-the-whole-internet game where latency is critical.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Keystroke obfuscation can be disabled client-side. After reverting my original breaking change, I tried updating my test harness to pass &lt;code&gt;ObscureKeystrokeTiming=no&lt;/code&gt; when starting up ssh sessions.&lt;/p&gt;
    &lt;p&gt;This worked great. CPU usage dropped dramatically and bots still received valid data.&lt;/p&gt;
    &lt;p&gt;But this is hardly a solution in the real world. I want &lt;code&gt;ssh mygame&lt;/code&gt; to Just Work without asking users to pass options that they might not understand.&lt;/p&gt;
    &lt;p&gt;Claude Code originally didn’t have much faith that we could disable this functionality server-side.&lt;/p&gt;
    &lt;p&gt;generated with simon wilson's excellent claude-code-transcripts tool&lt;/p&gt;
    &lt;p&gt;Fortunately, the description I found of SSH keystroke obfuscation made it easy to look up the relevant code in go’s ssh library (which I was transitively depending on).&lt;/p&gt;
    &lt;code&gt;Log message:
Introduce a transport-level ping facility

This adds a pair of SSH transport protocol messages SSH2_MSG_PING/PONG
to implement a ping capability. These messages use numbers in the "local
extensions" number space and are advertised using a "[email protected]"
ext-info message with a string version number of "0".
&lt;/code&gt;
    &lt;p&gt;The “chaff” messages that ssh uses to obscure keystrokes are SSH2_MSG_PING messages. And they’re sent to servers that advertise the availability of the &lt;code&gt;[email protected]&lt;/code&gt; extension. What if we just…don’t advertise &lt;code&gt;[email protected]&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;I searched go’s ssh library for &lt;code&gt;[email protected]&lt;/code&gt; and found the commit where support was added. The commit was tiny and seemed very easy to revert.&lt;/p&gt;
    &lt;p&gt;I cloned the go crypto repo and told Claude to revert this change and update our dependencies to use our clone (go’s replace directive makes forking a library very easy).&lt;/p&gt;
    &lt;p&gt;Then I re-ran my test harness. The results were…very good:&lt;/p&gt;
    &lt;code&gt;Total CPU  29.90%          -&amp;gt; 11.64%
Syscalls   3.10s           -&amp;gt; 0.66s
Crypto     1.6s            -&amp;gt; 0.11s
Bandwidth  ~6.5 Mbit/sec   -&amp;gt; ~3 Mbit/sec
&lt;/code&gt;
    &lt;p&gt;Claude was also pretty pumped:&lt;/p&gt;
    &lt;p&gt;yes it's 1:30 am what of it&lt;/p&gt;
    &lt;p&gt;Obviously forking go’s crypto library is a little scary, and I’m gonna have to do some thinking about how to maintain my little patch in a safe way.&lt;/p&gt;
    &lt;p&gt;But this is a huge improvement. I’ve spent much of the last week squeezing out small single-digit performance wins. A &amp;gt;50% drop was unimaginable to me.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging with LLMs was fun&lt;/head&gt;
    &lt;p&gt;I’ve been thinking about whether LLMs remove parts of the problem-solving process that I enjoy. But I’ve gotta say, debugging this problem using Claude Code was super fun.&lt;/p&gt;
    &lt;p&gt;I am familiar enough with &lt;code&gt;tcpdump&lt;/code&gt;, &lt;code&gt;tshark&lt;/code&gt;, and friends to know what they can do. But I don’t use them regularly enough to be fast with them. Being able to tell an agent “here’s a weird pcap - tell me what’s going on” was really lovely. And by watching commands as the agent ran them I was able to keep my mental model of the problem up to date.&lt;/p&gt;
    &lt;p&gt;There were still edge cases. At some point in my confusion I switched to ChatGPT and it very confidently told me that my tcpdump output was normal ssh behavior:&lt;/p&gt;
    &lt;p&gt;do all chatgpt messages have this tone and formatting now?&lt;/p&gt;
    &lt;p&gt;And then doubled down when I pushed back:&lt;/p&gt;
    &lt;p&gt;no!!!&lt;/p&gt;
    &lt;p&gt;Similarly, I had to push Claude Code to consider forking go’s ssh library. And I had to make the original leap of “wait…if our test harness was broken, why was usage not 0%?”&lt;/p&gt;
    &lt;p&gt;When you say “LLMs did not fully solve this problem” some people tend to respond with “you’re holding it wrong!”&lt;/p&gt;
    &lt;p&gt;I think they’re sometimes right! Interacting with LLMs is a new skill, and it feels pretty weird if you’re used to writing software like it’s 2020. A more talented user of LLMs may have trivially solved this problem.&lt;/p&gt;
    &lt;p&gt;But the best way to develop a skill is by practicing it. And for me, that means figuring out how to transfer my problem-solving intuitions to the tools that I’m using.&lt;/p&gt;
    &lt;p&gt;Besides. Being in the loop is fun. How else would I write this post?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eieio.games/blog/ssh-sends-100-packets-per-keystroke/"/><published>2026-01-22T19:27:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46725288</id><title>Capital One to acquire Brex for $5.15B</title><updated>2026-01-23T15:45:57.869015+00:00</updated><content>&lt;doc fingerprint="e1d8a53d0af29fa9"&gt;
  &lt;main&gt;
    &lt;p&gt;Jan 22 (Reuters) - Capital One Financial (COF.N) said on Thursday it will acquire fintech firm Brex in a cash and stock deal valued at $5.15 billion and reported a rise in quarterly profit on the back of higher interest income from its credit card debt.&lt;/p&gt;
    &lt;p&gt;Shares of the consumer lender fell more than 5% following the announcement of the deal, but robust results helped them pare losses to trade 1.5% lower.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The move comes as dealmakers prepare for another strong year in 2026, with a record slate of transactions expected as executives pursue scale to navigate rising economic and geopolitical uncertainties.&lt;/p&gt;
    &lt;p&gt;The deal, which is expected to close in mid‑2026, will be carried out on an approximate 50-50 cash-stock basis, Capital One said.&lt;/p&gt;
    &lt;p&gt;Brex operates in corporate cards and expense management software used by firms such as DoorDash (DASH.O) and Robinhood (HOOD.O), which could give Capital One greater exposure and reduce its reliance on consumer credit, cushioning it against the impact of economic downturns.&lt;/p&gt;
    &lt;p&gt;Brex operates in more than 120 countries according to its website.&lt;/p&gt;
    &lt;p&gt;Capital One said the fintech firm's chief executive and founder, Pedro Franceschi, will remain at the helm following the transaction.&lt;/p&gt;
    &lt;head rend="h2"&gt;FOURTH-QUARTER EARNINGS&lt;/head&gt;
    &lt;p&gt;U.S. consumer spending rose at a solid pace in November and October, suggesting the economy was on track for a third consecutive quarter of strong growth.&lt;/p&gt;
    &lt;p&gt;Economic momentum has been underpinned largely by resilient household demand as well as a narrowing trade deficit, with imports declining in response to President Donald Trump's broad tariff increases.&lt;/p&gt;
    &lt;p&gt;However, the tariffs have pushed up the prices of many goods, weighing unevenly across income groups.&lt;/p&gt;
    &lt;p&gt;Economists say spending strength is increasingly concentrated among higher-income households, while lower- and middle-income consumers have limited scope to switch to cheaper alternatives.&lt;/p&gt;
    &lt;p&gt;Capital One's net interest income — the difference between what it makes on loans and pays out on deposits — rose 54% to $12.47 billion in the fourth quarter from a year ago.&lt;/p&gt;
    &lt;p&gt;The McLean, Virginia-based company's net income available to common stockholders came in at $2.06 billion, or $3.26 per share, for the quarter, compared with $1.02 billion, or $2.67 per share, a year earlier.&lt;/p&gt;
    &lt;head rend="h2"&gt;CREDIT CARD CAP CONUNDRUM&lt;/head&gt;
    &lt;p&gt;Trump said last week he was calling for a one‑year cap on credit card interest rates at 10% starting January 20, but offered few details on how the proposal would be implemented or how companies would be compelled to comply.&lt;/p&gt;
    &lt;p&gt;Banking industry groups have pushed back against the proposal, warning it would restrict the availability of credit for everyday consumers.&lt;/p&gt;
    &lt;p&gt;JPMorgan Chase (JPM.N) CEO Jamie Dimon said on Wednesday a proposal to cap credit card interest rates would amount to economic disaster.&lt;/p&gt;
    &lt;p&gt;However, Bank of America (BAC.N) is considering options to offer new credit cards with an interest rate of 10% to satisfy Trump's demands, a source familiar with the matter said on Thursday.&lt;/p&gt;
    &lt;p&gt;The introduction of an interest rate cap would deal a significant blow to Capital One Financial, which has one of the most credit-card‑dependent business models among major U.S. lenders.&lt;/p&gt;
    &lt;p&gt;"We feel strongly that a cap on interest rates would catalyze a number of unintended consequences," CEO Richard Fairbank said in a call with analysts.&lt;/p&gt;
    &lt;p&gt;He added that lack of credit would result in reduced consumer spending and likely bring on a recession.&lt;/p&gt;
    &lt;p&gt;Reporting by Pritam Biswas in Bengaluru; Editing by Shreya Biswas&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/legal/transactional/capital-one-buy-fintech-firm-brex-515-billion-deal-2026-01-22/"/><published>2026-01-22T21:23:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46726857</id><title>Why medieval city-builder video games are historically inaccurate (2020)</title><updated>2026-01-23T15:45:56.850605+00:00</updated><content>&lt;doc fingerprint="b302597347b4065b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why medieval city-builder video games are historically inaccurate&lt;/head&gt;
    &lt;p&gt;This blog post explores the historical accuracy of medieval city-builder video games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Since many of us are working from home in these trying times, it seems safe to assume that more people than ever are indulging in playing the occasional computer game. A city builder is a specific kind of computer game in which you design a city, extract resources, set up production chains and ensure that your settlement grows. City builders are very similar to strategy games as they reward patience and strategy. In this article, I will take a look at one sub-genre of the city builder, the medieval city builder, and explain how this gaming genre relates to our knowledge of medieval settlement planning.&lt;/p&gt;
    &lt;head rend="h3"&gt;Historical city builders&lt;/head&gt;
    &lt;p&gt;The city builder has its origins far back in the 1990s in the combination of the strategy genre and the management genre, leading to games such as Sim City (1989), Caesar (1992) and Age of Empires (1997).&lt;/p&gt;
    &lt;p&gt;It did not take long before medieval-themed city builders popped up. We may think of Settlers (1993) and Knights and Merchants (1998). In addition, the Anno games (1998-2019), although initially set in the 1600s basically had a medieval theme.&lt;/p&gt;
    &lt;p&gt;These games often start with plopping down a village center on a promising location near abundant resources. You then continue to gather these resources which grant you building materials for building new homes and facilities for your settlement.&lt;/p&gt;
    &lt;p&gt;Setting up specialized production chains might involve growing grain, milling the grain for flour and turning the flour into bread which feeds your villages. Similarly, another production chain might involve rearing sheep for their wool, turning the wool into cloth and turning the cloth into clothing. When done correctly, the reward of correct investments and planning is that you see your settlement grow.&lt;/p&gt;
    &lt;p&gt;This often leads to settlements growing organically from a couple of houses around a community center to a larger settlement with hundreds of people. However logical such an organic growth of a settlement might seem, it is not historically accurate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Medieval village life &lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;Any gameplay loop that tells a story of linear settlement growth is incongruent with how a medieval economy worked (see Foussier 2004). Medieval villagers were often living on the edge of subsistence. Agricultural surpluses were skimmed by the church and the feudal lords. Bad harvests, banditry, warfare and disease might decimate a village community at any time. For this very reason, the demography of many European villages remained relatively stable between the twelfth and the eighteenth century. It may therefore be clear that the gameplay loop of city builders pivots around the concept of doing the historically exceptional (i.e. growing a settlement to a town) and thereby strays far from what actually happened in the lives of our medieval forebears. &lt;lb/&gt;A notable exception to this genre trope is the game Banished (2014) in which high mortality rates and bad weather do seriously stifle any kind of linear growth. In this city builder you are constantly fighting the odds and settlement growth is not guaranteed. However, also in Banished it is your goal to overcome the stagnation and lead your settlement to expansion.&lt;/p&gt;
    &lt;p&gt;A thing that is rarely touched upon in medieval city builders is how complex village life actually was. This can be exemplified by how the community related to its overlords. Land ownership here is key. Land in the community might be owned by a lord, a local liegeman, a monastery or even directly by the duke or count. Taxes, rents and tithes were the organisational structures in which the landowner was tied to the farmers who worked the fields. Often the payment of taxes and tithes was linked to feast days and the visit of the tax collector represented a big event in the agricultural year. An interesting side note is that some obligations which the commoners had to the lord and the church (such as seigneurial duties like working a mill) might drain the community from the needed manpower for tilling the land. Furthermore, a rural community that was its own seigneury had access to a law court with sheriff, aldermen and a local militia (Middle Dutch schutterie) to fight off bandits with. Harsh capital punishments were set in place to deter anyone from raiding the farms and hamlets and the village gallows were often the first thing one saw when approaching a medieval settlement.&lt;/p&gt;
    &lt;head rend="h3"&gt;Planning a medieval settlement&lt;/head&gt;
    &lt;p&gt;But something that is much more fundamental to the theme of a settlement building game, is how medieval settlements were actually planned and grew. Landscape historians and archaeologists have acquired a lot of insight into how this worked.&lt;/p&gt;
    &lt;p&gt;Let's start with the realization that medieval settlements in their first stages of development were planned and laid out according to a specific design. In my own research into the settlement history of West-Brabant (southern Netherlands, from 1000 to 1300 CE) I have encountered the following types.&lt;/p&gt;
    &lt;p&gt;Here is a sketch of a Brabantine circular manor (Middle Dutch vroonhoeve). This is a reinforced circular homestead with moat, often next to a bend in the river, containing several farms and a fan-like plot pattern radiating out from it. Such manors were often called BORCH.&lt;/p&gt;
    &lt;p&gt;Here is a sketch of a Brabantine street settlement, often built with exploitation of nearby fenland in mind. It consists of a line of farms with associated evenly sized rectangular plots built in a line perpendicular to a raised road.&lt;/p&gt;
    &lt;p&gt;Here is a more complex exploitation village which is set up with a moated enclosed church homestead and a central meadow as its center. There is a line of farms next to the road. The arable land to the east is bordered by a ditch supplying fresh drinking water (Middle Dutch bansloot). In layout, this type represents a hybrid between the two earlier settlement types.&lt;/p&gt;
    &lt;p&gt;Let us first make clear that these different types of exploitation settlements often existed alongside each other and can be found in one and the same region. In part, the different types reflect different chronological layers but some types were also more suited to certain geographical environments than others.&lt;/p&gt;
    &lt;p&gt;So how were these settlements planned? Many medieval exploitation enterprises were initiated by a monastery or a consortium of free men who were granted permission by (or bought permission from) the feudal lord to “colonize” the wilderness.&lt;/p&gt;
    &lt;p&gt;Clearing the wooded landscape in order to create arable land was done by cutting away the trees and bushes (Middle Dutch rode) or, alternatively, burning it away in controlled fires (Middle Dutch brant).&lt;/p&gt;
    &lt;p&gt;Land surveyors sent by the lord would then measure out the block or strips that would be taken in cultivation. Strips of arable land were often 1250m deep (6 Middle Dutch voorlingen = furlongs) so that the plough could go straight in a long line before having to turn. Important blocks or strips were demarcated by hedges, earthwork, woodwork, ditches or roads. Medieval names for these blocks often survived into the modern day.&lt;/p&gt;
    &lt;p&gt;The presence of drinking water (a river or a brook) in the vicinity was an important factor in choosing the location for the settlement. The vicinity of water entailed risk and reward because flooding was an ever present danger. Floods could devastate arable land but might also fertilize it. Meadows in particular were often situated in flood areas.&lt;/p&gt;
    &lt;head rend="h3"&gt;Managing a settlement&lt;/head&gt;
    &lt;p&gt;So how was such a settlement managed? First of all, the quality of the soil had to be carefully controlled by crop rotation: specific crops were sown on different segments of the arable land with one part laying fallow to recover from the tilling (English three-field system, Dutch drieslagstelsel). The cattle and sheep were put out to pasture on the common meadows guarded by a shepherd or cowherd. Pigs were allowed to forage in the nearby forests and killed in autumn before the winter starvation set in.&lt;/p&gt;
    &lt;p&gt;Roads and rivers were important for transport of crops and livestock. These roads, some of them paved, some of them not, needed to be maintained. They were essential to the payment of the tithe, since tithe collectors assessed the harvest on the field and later collected the sheaves on the side of the road.&lt;/p&gt;
    &lt;p&gt;The buildings within the community also needed maintenance. Farmhouses, community barns and stables were made of wood and had to be rebuilt every few generations, only the name of the farm or homestead being continued.&lt;/p&gt;
    &lt;p&gt;So what kind of threats did a medieval settlement face? First of all, the weather was an important factor which dictated the success of the harvest. Storms, droughts and floods could devastate the harvest and decimate the community.&lt;/p&gt;
    &lt;p&gt;Diseases and epidemics were another danger threatening the community. The situation on the countryside was a lot better in this regard than in the medieval towns, but an epidemic could still mean the end of a village. Similarly, diseases among livestock impacted the medieval subsistence economy in a brutal way.&lt;/p&gt;
    &lt;p&gt;Then there are the consequences of medieval warfare affecting the community: Armies that passed by could plunder the village, burn the farms and execute villagers at will. Or they could also demand supplies, food and provisions as an emergency "tax"&lt;/p&gt;
    &lt;p&gt;But war also brought indirect consequences; a liege lord calling the banners and levying troops from the village community might extract a large part of the adult men. Warfare also disrupted the trade networks that supplied a village with building materials and commodities.&lt;/p&gt;
    &lt;p&gt;Then there were internal threats to the fabric of the village community. We may think of social unrest because of land disputes. Feuds could also tear a community apart with endemic vendetta’s causing death and despair. A socially unstable society was also more prone to internal accusations of heresy and witchcraft.&lt;/p&gt;
    &lt;head rend="h3"&gt;An “accurate” medieval settlement builder&lt;/head&gt;
    &lt;p&gt;So, which of the above listed features could potentially contribute to a more historically accurate computer game about medieval settlement building? First of all, it would be more realistic if the settlement could first be planned out and was not forced to "grow organically" from a community center. The first settlement phase would be a test of how “successful” a layout is in adapting to the exigencies of the terrain and the needs of the community. Only after that initial layout proved successful, further expansions can be planned.&lt;/p&gt;
    &lt;p&gt;Secondly, it would be more realistic if we could build both straight roads and curved roads, just as in Cities Skylines (2015), a modern city builder well known for its incredibly flexible layout tools. Incidentally, the tools of Cities Skylines can also be used to recreate medieval settlements, as was done by YouTube creator Play Curiously who constructed an impression of a medieval Croatian village.&lt;/p&gt;
    &lt;p&gt;Such a flexible road drawing tool can then also be used to lay out ditches, hedges and enclosures since these features were central to the medieval experience of the cultivated landscape.&lt;/p&gt;
    &lt;p&gt;Thirdly, It would be interesting to see a medieval-themed game embrace the concept of flood valleys that limit and endanger pasture and arable land. Other historical city builders such as Pharaoh (1999) and Children of the Nile (2004) already implemented this feature for their setting in Ancient Egypt. However, such a mechanic would likewise fit a medieval city builder and show the general public how medieval society dealt with seasonal flooding as well as the devastating effects that storm floods could have.&lt;/p&gt;
    &lt;p&gt;And finally, something that would, in my opinion, really add to the realism and historical flavor of a medieval-themed city builder would be the introduction of mechanisms in which agricultural surpluses are skimmed by the church and the feudal lord. Tithes, taxes and rents! Instead of merely abstracting the taxes into an income modifier or letting the player be the extractor himself, we could be shown the tax collector visiting the village, counting the sheaves by the side of the road, selecting the calves and chickens. This way, the experiences of our medieval forebears are visualized and may help to educate the public about medieval village life.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why not?&lt;/head&gt;
    &lt;p&gt;There are some good reasons why city building games are not that historically accurate and instead adhere to the established formula of the city building game.&lt;/p&gt;
    &lt;p&gt;First of all, a linear growth model makes sense from a gameplay perspective, since it is rewarding to see your settlement grow.in a linear way. It fosters a feeling of progress and motivates the player to keep momentum and push through to the next expansion phase. Secondly, games are generally wary of punishing failure too harshly in order to avoid demoralizing the player. Thirdly, in order to facilitate path finding for the simulated villagers it is easier to implement a gridlike road and building system rather than an off-grid building system that allows for curvy roads. So far only Cities Skylines has managed to do this in a satisfactory way.&lt;/p&gt;
    &lt;p&gt;Lastly, for marketing purposes and recognizability, game developers generally don't stray too far from the image of the Middle Ages that the public is already acquainted with. For a medieval city builder this means windmills, industrious peasants, lots of sheep and stone castles. Things like land surveying, crop rotation and tithe collection do not fit this image and challenge the romanticized picture of the uneducated farmer in his pre-industrial environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Although I think medieval-themed city building games could benefit from incorporating some of the things we know about medieval settlement history into the gameplay loop, it may not be desirable for game developers to stray too far from the established formula. The idea that medieval settlements developed organically according to messy road plans is strongly imbedded in popular perception. Allowing both straight and curved road building in medieval city builders, may serve to challenge some of the stereotypes that exist about medieval village life. And if you ask me, that would be a good thing for it is an enriching experience to see the world through the eyes of our medieval forebears. One may find out that their lives were not that different after all...&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fossier, R. (2004). “The Rural Economy and Demographic Growth.” In: D. Luscombe &amp;amp; J. Riley-Smith (Eds.). The New Cambridge Medieval History. Cambridge: Cambridge University Press, 11-46.&lt;/item&gt;
      &lt;item&gt;Van Ham, W. (1979). “Dorp en dorpsleven in middeleeuws Wouw." in: A. Delahaye (red.), De Heren XVII van Nassau-Brabant, 316-336.”&lt;/item&gt;
      &lt;item&gt;(forthc.) Kerkhof, P.A. (2020). “Saer, Saert; een Zuid-Nederlandse veldnaam van onzekere oorsprong.” Noordbrabants Historisch Jaarboek.&lt;/item&gt;
      &lt;item&gt;Leenders, K.A.H.W. (1996). "Noord-Vlaanderen en de Noordwesthoek; een vergelijking." Tijdschrift voor Waterstaatsgeschiedenis 5, 67-73.&lt;/item&gt;
      &lt;item&gt;Leenders, K.A.H.W. (1989). Verdwenen venen; een onderzoek naar de ligging en exploitatie van thans verdwenen venen in het gebied tussen Antwerpen, Turnhout, Geertruidenberg en Willemstad (1250-1750). Reeks Landschapsstudies 13, Wageningen.&lt;/item&gt;
      &lt;item&gt;Oosthuizen, S. (2017). The Anglo-Saxon fenland. Windgather Press.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;© Alexia Kerkhof and Leiden Medievalists Blog, 2020. Unauthorised use and/or duplication of this material without express and written permission from this site’s author and/or owner is strictly prohibited. Excerpts and links may be used, provided that full and clear credit is given to Alexia Kerkhof and Leiden Medievalists Blog with appropriate and specific direction to the original content.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.leidenmedievalistsblog.nl/articles/why-medieval-city-builder-video-games-are-historically-inaccurate"/><published>2026-01-23T00:22:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46728157</id><title>The lost art of XML</title><updated>2026-01-23T15:45:56.221811+00:00</updated><content>&lt;doc fingerprint="735b03332c911290"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Preamble&lt;/head&gt;
    &lt;p&gt;There exists a peculiar amnesia in software engineering regarding XML. Mention it in most circles and you will receive knowing smiles, dismissive waves, the sort of patronizing acknowledgment reserved for technologies deemed passé. "Oh, XML," they say, as if the very syllables carry the weight of obsolescence. "We use JSON now. Much cleaner."&lt;/p&gt;
    &lt;p&gt;This is nonsense.&lt;/p&gt;
    &lt;p&gt;XML was not abandoned because it was inadequate; it was abandoned because JavaScript won. The browser won. And in that victory, we collectively agreed to pretend that a format designed for human readability in a REPL was suitable for machine-to-machine communication, for configuration, for anything requiring rigor. We relinquished the logical formalism for convenience with our tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Case for XML&lt;/head&gt;
    &lt;p&gt;Consider what XML actually offers, what we surrendered in our rush toward minimalism:&lt;/p&gt;
    &lt;p&gt;Schemas. XML Schema Definition (XSD) provides genuine type checking at the document level. You can specify that an element must contain an integer, that it must appear exactly once, that certain attributes are required. The schema is itself a document; it can be validated, versioned, referenced. When you receive an XML document, you can verify its structure before you ever parse its content. This is not a luxury. This is basic engineering hygiene.&lt;/p&gt;
    &lt;p&gt;JSON has no such mechanism built into the format. Yes, JSON Schema exists, but it is an afterthought, a third-party addition that never achieved universal adoption. Most JSON is validated (if at all) through ad-hoc code that checks for the presence of expected keys and hopes for the best. This is insanity masquerading as pragmatism.&lt;/p&gt;
    &lt;p&gt;Namespaces. XML allows you to compose documents from multiple schemas without collision. You can embed XHTML inside a custom vocabulary, reference external definitions, maintain clear boundaries between different semantic domains. This is not theoretical; this is how standards like SVG, MathML, and SOAP actually work in practice.&lt;/p&gt;
    &lt;p&gt;JSON has no answer to this. If two libraries use the same key name, you improvise. You prefix. You nest arbitrarily. You pray.&lt;/p&gt;
    &lt;p&gt;Comments. XML supports comments as a first-class feature. You can annotate your configuration, explain why a particular value exists, leave notes for future maintainers. JSON does not support comments. The official specification forbids them. The rationale, as I have repeatedly heard, is that comments would make parsing more complex.&lt;/p&gt;
    &lt;p&gt;Self-description. An XML document carries its schema with it, or references it explicitly. The structure is declarative. The types are manifest. You can hand someone an XML file and they can, with reasonable effort, understand what it represents without consulting external documentation.&lt;/p&gt;
    &lt;p&gt;JSON is a series of nested dictionaries and arrays with string keys. What does &lt;code&gt;"status": 1&lt;/code&gt; mean? What values are valid for &lt;code&gt;"type"&lt;/code&gt;? Is &lt;code&gt;"timestamp"&lt;/code&gt; an integer or a string? You will need to read the API documentation. You will need to hope that documentation exists and is current.&lt;/p&gt;
    &lt;head rend="h3"&gt;The S-Expression Connection&lt;/head&gt;
    &lt;p&gt;For those who have spent time with Lisp, XML's structure is immediately familiar. It is essentially s-expressions with angle brackets instead of parentheses. An element is a tagged list; attributes are metadata; nesting is composition. The mapping is direct:&lt;/p&gt;
    &lt;code&gt;(person (name "Alice") (age 30))
&lt;/code&gt;
    &lt;code&gt;&amp;lt;person&amp;gt;
  &amp;lt;name&amp;gt;Alice&amp;lt;/name&amp;gt;
  &amp;lt;age&amp;gt;30&amp;lt;/age&amp;gt;
&amp;lt;/person&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Or with attributes:&lt;/p&gt;
    &lt;code&gt;&amp;lt;person name="Alice" age="30" /&amp;gt;
&lt;/code&gt;
    &lt;p&gt;This is not accidental. XML inherits from SGML, which inherits from earlier markup traditions, but the fundamental insight (that data can be represented as nested, tagged structures) is the same insight that drives Lisp's power. Code as data. Structure as meaning.&lt;/p&gt;
    &lt;p&gt;JSON, by contrast, is an object literal from JavaScript. It is a notation for initializing dictionaries. It was never designed to be a data interchange format; it was promoted to that role because it was already in the browser and developers were already familiar with it. Convenience over correctness.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why We Chose Poorly&lt;/head&gt;
    &lt;p&gt;The abandonment of XML in favor of JSON and other lobotomized formats like YAML is a case study in how developer experience can override technical merit. XML is verbose. It requires closing tags. It looks "heavy" compared to JSON's minimalism. These are aesthetic complaints dressed up as engineering concerns.&lt;/p&gt;
    &lt;p&gt;While verbosity is often a hazard, it is not a vice when it serves clarity. These are not mutually exclusive. Closing tags make structure explicit; they eliminate ambiguity in parsing. The angle brackets are not there to annoy you; they are there to separate markup from content, to make the document's structure immediately visible.&lt;/p&gt;
    &lt;p&gt;YAML, the other pretender, manages to be both ambiguous and fragile. Indentation-sensitive syntax in a data format? Implicit typing that guesses whether &lt;code&gt;no&lt;/code&gt; means a boolean or a string? A specification so complex that implementations disagree on edge cases? This is context-dependent parsing that we supposedly left behind.&lt;/p&gt;
    &lt;head rend="h3"&gt;On Developer Convenience and Self-Deception&lt;/head&gt;
    &lt;p&gt;There is a distinction that the industry refuses to acknowledge: developer convenience and correctness are different concerns. They are not opposed, necessarily, but they are not the same thing. A format can be inconvenient to type and still be the right choice. A format can be pleasant to work with and still be fundamentally inadequate.&lt;/p&gt;
    &lt;p&gt;We have spent billions of dollars and countless engineering hours making terrible technologies fast. The JVM is perhaps the canonical example; a virtual machine originally designed for remote controls, turned into the foundation of enterprise software through sheer force of optimization, millions of developer hours and central bank funny money. Decades of work went into JIT compilation, garbage collection algorithms, escape analysis, all to make a fundamentally awkward platform perform acceptably. And it worked! The JVM is now genuinely fast.&lt;/p&gt;
    &lt;p&gt;But imagine if a fraction of that effort had gone into something better from the start. Imagine if we had chosen a platform designed for the problems we actually needed to solve, rather than retrofitting a toy into production use. We spent billions making wrong choices work, when we could have spent millions making the right choice pleasant.&lt;/p&gt;
    &lt;p&gt;This is the pattern with JSON. We chose it because it was convenient, because it was already in the browser, because developers already understood object literals. Then, when its limitations became apparent, we spent enormous effort working around them: creating validation libraries, inventing type systems (TypeScript), building code generators for API clients, developing entire frameworks to manage the chaos of untyped data structures.&lt;/p&gt;
    &lt;p&gt;We could have just used XML. The schema validation was already there. The type systems were already there. The tooling was already there. But XML looked ugly, and closing tags felt verbose, so we chose JSON and then spent years rebuilding what XML already provided.&lt;/p&gt;
    &lt;p&gt;The rationalization is remarkable. "JSON is simpler", they say, while maintaining thousands of lines of validation code. "JSON is more readable", they claim, while debugging subtle bugs caused by typos in key names that a schema would have caught immediately. "JSON is lightweight", they insist, while transmitting megabytes of redundant field names that binary XML would have compressed away.&lt;/p&gt;
    &lt;p&gt;This is not engineering. This is fashion masquerading as technical judgment.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Physical and the Conceptual&lt;/head&gt;
    &lt;p&gt;Here is another confusion: we have allowed the physical representation to dictate the conceptual model. XML's angle brackets are a serialization choice; they are not the essence of what XML is. The essence is the Information Set, the abstract model of elements, attributes, and content. How that model is physically encoded (text with angle brackets, binary with Fast Infoset, compressed with EXI) is a separate concern.&lt;/p&gt;
    &lt;p&gt;But because the text serialization looks "heavy" we rejected the entire model. We threw away schemas, namespaces, validation, self-description, all because we didn't like angle brackets. This is like rejecting relational databases because you don't like SQL. SQL is not the relational model. Truth be told, most of the hate on XML comes from protocols and arcane tools people had to deal with over the years: a friend told me about his horrors on making an integration with the central bank of Nigeria once, and they apparently used SOAP; but these are implementation problems. While it's a nice idea to analyze how much we have committed to a model, it's also important to realise the formalism doesn't bear the blame on how the central bank of Nigeria applies it.&lt;/p&gt;
    &lt;p&gt;JSON conflates these layers. It is simultaneously a data model (nested objects and arrays) and a serialization format (braces and brackets with string keys). There is no abstract model separate from the text representation. This means you cannot have binary JSON that preserves the same semantics, because the semantics are the syntax. Every binary JSON-like format (MessagePack, BSON, etc.) is a different model with different tradeoffs.&lt;/p&gt;
    &lt;p&gt;XML separates these concerns properly. The Information Set is the model. Text, binary, compressed binary are all just serializations of that model. You can choose the serialization appropriate to your constraints without changing what the data means. This is correct layering. This is how systems should be designed.&lt;/p&gt;
    &lt;p&gt;But correct layering is not convenient when you're writing a quick API endpoint, so we chose the conflated mess and called it progress.&lt;/p&gt;
    &lt;head rend="h3"&gt;What We Lost&lt;/head&gt;
    &lt;p&gt;When we discarded XML, we lost:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First-class validation through schemas&lt;/item&gt;
      &lt;item&gt;Namespacing and composition&lt;/item&gt;
      &lt;item&gt;Comments and self-documentation&lt;/item&gt;
      &lt;item&gt;A separation between structure and content&lt;/item&gt;
      &lt;item&gt;Tooling that could verify correctness before runtime&lt;/item&gt;
      &lt;item&gt;A format that could evolve without breaking existing consumers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What we gained:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fewer characters&lt;/item&gt;
      &lt;item&gt;Easier hand-writing for trivial cases&lt;/item&gt;
      &lt;item&gt;Native parsing in JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fantastic trade.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Binary Answer&lt;/head&gt;
    &lt;p&gt;One of the common complaints about XML is its verbosity, particularly for network transmission. "All those closing tags waste bandwidth". But even accepting this concern at face value (we shouldn't), XML addressed it years ago.&lt;/p&gt;
    &lt;p&gt;Fast Infoset, standardized as ITU-T Rec. X.891 and ISO/IEC 24824-1, is a binary encoding of the XML Information Set. It provides the same logical structure, the same schema validation, the same semantic richness, but with dramatically reduced size and parsing overhead. An XML document can be serialized to Fast Infoset for transmission, then deserialized back to standard XML at the receiving end. The schema remains the same. The tooling remains the same. Only the wire format changes.&lt;/p&gt;
    &lt;p&gt;EXI (Efficient XML Interchange), another W3C standard, goes further. It uses schema-informed compression to achieve sizes competitive with hand-tuned binary formats, while maintaining XML's semantic model. You get type safety, validation, and self-description, with none of the supposed bandwidth penalty.&lt;/p&gt;
    &lt;p&gt;These formats exist. They are standardized. They have implementations in multiple languages. And yet the industry collectively ignores them in favor of JSON, then invents Protocol Buffers and other binary formats to solve the performance problems that binary XML already solved.&lt;/p&gt;
    &lt;p&gt;The pattern is instructive: we abandoned XML for being verbose, then when dealing JSON proved too painful, we created new binary formats that lack XML's semantic richness, but with a confused grasp that "we need something, but what is it!?". We could have simply used the binary XML encodings that already existed. But that would require admitting that XML was right all along.&lt;/p&gt;
    &lt;head rend="h3"&gt;On Practicality&lt;/head&gt;
    &lt;p&gt;I am not arguing that XML should be used everywhere. There are cases where other formats are appropriate: small data transfers between cooperating services and scenarios where schema validation would be overkill. But these are the exceptions, not the rule.&lt;/p&gt;
    &lt;p&gt;For anything requiring durability, for anything that will be consumed by multiple systems, for anything where correctness matters more than convenience; XML remains the superior choice. The fact that we collectively pretend otherwise is a testament to our capacity for self-deception.&lt;/p&gt;
    &lt;p&gt;We chose the format that was easier to type over the format that was harder to misuse. We chose developer convenience over system reliability. And now we act surprised when our JSON APIs drift, when our configurations break silently, when our data lacks the structure we assumed it had.&lt;/p&gt;
    &lt;head rend="h3"&gt;A Final Point&lt;/head&gt;
    &lt;p&gt;Microsoft, for all their faults, understood this. MSBuild uses XML. WPF uses XML. .NET's configuration system was XML until they caved to JSON pressure in .NET Core. These were not arbitrary choices; they were recognition that complex systems require complex representations, and that formality in data representation prevents entire classes of errors.&lt;/p&gt;
    &lt;p&gt;The fact that we now consider this "old-fashioned" says more about our current priorities than about XML's utility. We value keystroke economy over semantic precision. We value familiarity over rigor. We value the appearance of simplicity over actual simplicity, which is the simplicity that comes from clear rules and consistent structure.&lt;/p&gt;
    &lt;p&gt;XML is not perfect. XPath is baroque; XSLT is its own circle of hell; the various XML-based "standards" spawned by enterprise committees are monuments to over-engineering. But the core format (elements, attributes, schemas, namespaces) remains sound. We threw out the mechanism along with its abuses.&lt;/p&gt;
    &lt;p&gt;I am tired of lobotomized formats like JSON being treated as the default, as the modern choice, as the obviously correct solution. They are none of these things. They are the result of path dependence and fashion, not considered engineering judgment.&lt;/p&gt;
    &lt;p&gt;Sometimes the old way was the right way. This is one of those times.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://marcosmagueta.com/blog/the-lost-art-of-xml/"/><published>2026-01-23T03:45:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46728808</id><title>I built a light that reacts to radio waves [video]</title><updated>2026-01-23T15:45:55.406878+00:00</updated><content>&lt;doc fingerprint="50559455455d1642"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2026 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=moBCOEiqiPs"/><published>2026-01-23T05:34:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46729368</id><title>Proton Spam and the AI Consent Problem</title><updated>2026-01-23T15:45:55.298929+00:00</updated><content>&lt;doc fingerprint="ef5f40914ea2becf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Proton Spam and the AI Consent Problem&lt;/head&gt;
    &lt;p&gt;On Jan 14th Proton sent out an email newsletter with the subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Introducing Projects - Try Lumoâs powerful new feature now&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Lumo is Protonâs &lt;/p&gt;
    &lt;p&gt;There is a problem with this email. And Iâm not talking about the question of how exactly AI aligns with Protonâs core values of privacy and security.&lt;/p&gt;
    &lt;p&gt;The problem is I had already explicitly opted out of Lumo emails.&lt;/p&gt;
    &lt;p&gt;That toggle for âLumo product updatesâ is unchecked. Lumo is the only topic Iâm not subscribed to. Proton has over a dozen newsletters, including some crypto nonsense. I opt-in to everything but Lumo, I gave an undeniable no to Lumo emails.&lt;/p&gt;
    &lt;p&gt;So the email I received from Proton is spam, right?&lt;/p&gt;
    &lt;p&gt;My understanding is that spam is a violation of GDPR and UK data protection laws. Regardless, Protonâs email is a clear abuse of their own service towards a paying business customer.&lt;/p&gt;
    &lt;p&gt;Before I grab my pitchfork I emailed Proton support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proton Support&lt;/head&gt;
    &lt;p&gt;Despite the subject line and contents, and despite the âFrom Lumoâ name and &lt;code&gt;@lumo.proton.me&lt;/code&gt; address, maybe this was an honest mistake?&lt;/p&gt;
    &lt;p&gt;Protonâs first reply explained how to opt-out.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hello David,&lt;/p&gt;
      &lt;p&gt;Thank you for contacting us.&lt;/p&gt;
      &lt;p&gt;You can unsubscribe from the newsletters if you do the following:&lt;/p&gt;
      &lt;p&gt;- Log in to your account at https://account.protonvpn.com/login&lt;/p&gt;
      &lt;p&gt;- Navigate to the Account category&lt;/p&gt;
      &lt;p&gt;- Disable the check-marks under âEmail subscriptionsâ&lt;/p&gt;
      &lt;p&gt;- If you need additional assistance, let me know.&lt;/p&gt;
      &lt;p&gt;[screenshot of the same opt-out toggle]&lt;/p&gt;
      &lt;p&gt;-Have a nice day.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;John Support directs me to the exact same âLumo product updatesâ toggle I had already unchecked. I replied explaining that I had already opted out. Support replies saying theyâre âchecking this with the teamâ then later replies again asking for screenshots.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Can you make sure to send me a screenshot of this newsletter option disabled, as well as the date when the last message was sent to you regarding the Lumo offer?&lt;/p&gt;
      &lt;p&gt;You can send me a screenshot of the whole message, including the date.&lt;/p&gt;
      &lt;p&gt;Is it perhaps 14 January 2026 that you received the message?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I found that last line curious, are they dealing with other unhappy customers? Maybe Iâm reading too much into it.&lt;/p&gt;
    &lt;p&gt;I sent the screenshots and signed off with âDonât try to pretend this fits into another newsletter category.â&lt;/p&gt;
    &lt;p&gt;After more âchecking this with the teamâ I got a response today.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In this case, the mentioned newsletter is for promoting Lumo Business Suit to Business-related plans.&lt;/p&gt;
      &lt;p&gt;Hence, why you received it, as Product Updates and Email Subscription are two different things.&lt;/p&gt;
      &lt;p&gt;In the subscription section, you will see the âEmail Subscriptionâ category, where you can disable the newsletter in order to avoid getting it in the future.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If I understand correctly, Proton are claiming this email is the âProton for Business newsletterâ. Not the âLumo product updatesâ newsletter.&lt;/p&gt;
    &lt;p&gt;I donât know about you, but I think thatâs baloney. Proton Support had five full business days to come up with a better excuse. Please tell me, how can I have been any more explicit about opting out of Lumo emails, only to receive âTry Lumoâ âFrom Lumoâ, and be told that is not actually a Lumo email?&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-Consent&lt;/head&gt;
    &lt;p&gt;Has anyone else noticed that the AI industry canât take ânoâ for an answer? AI is being force-fed into every corner of tech. Itâs unfathomable to them that some of us arenât interested.&lt;/p&gt;
    &lt;p&gt;The entire AI industry is built upon a common principle of non-consent. They laugh in the face of IP and copyright law. AI bots DDoS websites and lie about user-agents. Can it get worse than the sickening actions of Grok? I dread to think.&lt;/p&gt;
    &lt;p&gt;As Proton has demonstrated above, and Mozilla/Firefox recently too, the AI industry simply will not accept ânoâ as an answer. Some examples like spam are more trivial than others, but the growing trend is vile and disturbing.&lt;/p&gt;
    &lt;p&gt;I do not want your AI.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update for 23rd January&lt;/head&gt;
    &lt;p&gt;I guess someone at Microsoft read my post and said âhold my beerâ. This morning I woke up to a lovely gift in my inbox; âBuild Al agents with the new GitHub Copilot SDKâ.&lt;/p&gt;
    &lt;p&gt;GitHub Ensloppification is moving faster than I can delete my account for good. (Itâs an unfortunate requirement for client projects.) For the record, I have never said âyesâ to any GitHub newsletter. Even before Copilot I disabled every possible GitHub email notification.&lt;/p&gt;
    &lt;p&gt;The âUnsubscribeâ link provides the hidden newsletter list. There is nothing within GitHub account settings I can find to disable spam.&lt;/p&gt;
    &lt;p&gt;As expected, Microsoft has opted me in without my consent. The wheels are falling off at GitHub. The brutally slow front-end UI. The embarrassingly lacklustre Actions CI. Now this sloppy tripe everywhere. Reminder to developers: GitHub is not Git.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dbushell.com/2026/01/22/proton-spam/"/><published>2026-01-23T07:01:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46730214</id><title>Replacing Protobuf with Rust to go 5 times faster</title><updated>2026-01-23T15:45:55.044090+00:00</updated><content>&lt;doc fingerprint="ae1a93792c310158"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Replacing Protobuf with Rust to go 5 times faster&lt;/head&gt;
    &lt;p&gt;Jan 22nd, 2026&lt;lb/&gt;Lev Kokotov&lt;/p&gt;
    &lt;p&gt;PgDog is a proxy for scaling PostgreSQL. Under the hood, we use &lt;code&gt;libpg_query&lt;/code&gt; to parse and understand SQL queries. Since PgDog is written in Rust, we use its Rust bindings to interface with the core C library. 
Those bindings use Protobuf (de)serialization to work uniformly across different programming languages, e.g., the popular Ruby pg_query gem.&lt;/p&gt;
    &lt;p&gt;Protobuf is fast, but not using Protobuf is faster. We forked pg_query.rs and replaced Protobuf with direct C-to-Rust (and back to C) bindings, using bindgen and Claude-generated wrappers. This resulted in a 5x improvement in parsing queries, and a 10x improvement in deparsing (Postgres AST to SQL string conversion).&lt;/p&gt;
    &lt;head rend="h5"&gt;Results&lt;/head&gt;
    &lt;p&gt;You can reproduce these by cloning our fork and running the benchmark tests:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Function&lt;/cell&gt;
        &lt;cell role="head"&gt;Queries per second&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::parse&lt;/code&gt; (Protobuf)&lt;/cell&gt;
        &lt;cell&gt;613&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::parse_raw&lt;/code&gt; (Direct C to Rust)&lt;/cell&gt;
        &lt;cell&gt;3357 (5.45x faster)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::deparse&lt;/code&gt; (Protobuf)&lt;/cell&gt;
        &lt;cell&gt;759&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::deparse_raw&lt;/code&gt; (Direct Rust to C)&lt;/cell&gt;
        &lt;cell&gt;7319 (9.64x faster)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;The process&lt;/head&gt;
    &lt;p&gt;The first step is always profiling. We use samply, which integrates nicely with the Firefox profiler. Samply is a sampling profiler: it measures how much time code spends running CPU instructions in each function. It works by inspecting the application call stack thousands of times per second. The more time is spent inside a particular function (or span, as they are typically called), the slower that code is. This is how we discovered &lt;code&gt;pg_query_parse_protobuf&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;This is the entrypoint to the &lt;code&gt;libpg_query&lt;/code&gt; C library, used by all pg_query bindings. The function that wraps the actual Postgres parser, &lt;code&gt;pg_query_raw_parse&lt;/code&gt;, barely registered on the flame graph. Parsing queries isn’t free, but the Postgres parser itself is very quick and has been optimized for a long time. With the hot spot identified, our first instinct was to do nothing and just add a cache.&lt;/p&gt;
    &lt;head rend="h4"&gt;Caching mostly works&lt;/head&gt;
    &lt;p&gt;Caching is a trade-off between memory and CPU utilization, and memory is relatively cheap (latest DRAM crunch notwithstanding). The cache is mutex-protected, uses the LRU algorithm and is backed by a hashmap1. The query text is the key and the Abstract Syntax Tree is the value, which expects most apps to use prepared statements. The query text contains placeholders instead of actual values and is therefore reusable, for example:&lt;/p&gt;
    &lt;code&gt;SELECT * FROM users WHERE id = $1;
&lt;/code&gt;
    &lt;p&gt;While the &lt;code&gt;id&lt;/code&gt; parameter can change between invocations, the prepared statement does not, so we could cache its static AST in memory.&lt;/p&gt;
    &lt;p&gt;This works pretty well, but eventually we ran into a couple of issues:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Some ORMs can have bugs that generate thousands of unique statements, e.g., &lt;code&gt;value IN ($1, $2, $3)&lt;/code&gt;instead of&lt;code&gt;value = ANY($1)&lt;/code&gt;, which causes a lot of cache misses&lt;/item&gt;
      &lt;item&gt;Applications use old PostgreSQL client drivers which don’t support prepared statements, e.g., Python’s &lt;code&gt;psycopg2&lt;/code&gt;package&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The clock on Protobuf was ticking and we needed to act. So, like a lot of engineers these days, we asked an LLM to just do it for us.&lt;/p&gt;
    &lt;head rend="h4"&gt;Tight constraints&lt;/head&gt;
    &lt;p&gt;I’m going to preface this section by saying that the vast majority of PgDog’s source code is written by a human. AI is not in a position to one-shot a connection pooler, load balancer and database sharder. However, when scoped to a very specific, well-defined and most importantly machine-verifiable task, it can work really well.&lt;/p&gt;
    &lt;p&gt;The prompt we started with was pretty straightforward:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;libpg_query is a library that wraps the PostgreSQL parser in an API. pg_query.rs is a Rust wrapper around libpg_query which uses Protobuf for (de)serialization. Replace Protobuf with bindgen-generated Rust structs that map directly to the Postgres AST.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And after two days of back and forth between us and the machine, it worked. We ended up with 6,000 lines of recursive Rust that manually mapped C types and structs to Rust structs, and vice versa. We made the switch for &lt;code&gt;parse&lt;/code&gt;, &lt;code&gt;deparse&lt;/code&gt; (used in our new query rewrite engine, which we’ll talk about in another post), &lt;code&gt;fingerprint&lt;/code&gt; and &lt;code&gt;scan&lt;/code&gt;. These four methods are heavily used in PgDog to make sharding work, and we immediately saw a 25% improvement in pgbench benchmarks2.&lt;/p&gt;
    &lt;p&gt;Just to be clear: we had a lot of things going for us already that made this possible. First, pg_query has a Protobuf spec for protoc (and Prost, the Protobuf Rust implementation) to generate bindings, so Claude was able to get a comprehensive list of structs it needed to extract from C, along with the expected data types.&lt;/p&gt;
    &lt;p&gt;Second, pg_query.rs was already using bindgen, so we had to just copy/paste some invocations around to get the AST structs included in bindgen’s output.&lt;/p&gt;
    &lt;p&gt;And last, and definitely not least, pg_query.rs already had a working &lt;code&gt;parse&lt;/code&gt; and &lt;code&gt;deparse&lt;/code&gt; implementation, so we could test our AI-generated code against its output. This was entirely automated and verifiable: for each test case that used &lt;code&gt;parse&lt;/code&gt;, we included a call to &lt;code&gt;parse_raw&lt;/code&gt;, compared their results and if they differed by even one byte, Claude Code had to go back and try again.&lt;/p&gt;
    &lt;head rend="h4"&gt;The implementation&lt;/head&gt;
    &lt;p&gt;The translation code between Rust and C uses &lt;code&gt;unsafe&lt;/code&gt; Rust functions that wrap Rust structs to C structs. The C structs are then passed to the Postgres/libpg_query C API which does the actual work of building the AST.&lt;/p&gt;
    &lt;p&gt;The result is converted back to Rust using a recursive algorithm: each node in the AST has its own converter function which accepts an &lt;code&gt;unsafe&lt;/code&gt; C pointer and returns a safe Rust struct. Much like the name suggests, the AST is a tree, which is stored in an array:&lt;/p&gt;
    &lt;code&gt;unsafe fn convert_list_to_raw_stmts(
    list: *mut bindings_raw::List
) -&amp;gt; Vec&amp;lt;protobuf::RawStmt&amp;gt; {
    // C-to-Rust conversion.
}
&lt;/code&gt;
    &lt;p&gt;For each node in the list, the implementation calls &lt;code&gt;convert_node&lt;/code&gt;, which then handles each one of the 100s of tokens available in the SQL grammar:&lt;/p&gt;
    &lt;code&gt;unsafe fn convert_node(
    node_ptr: *mut bindings_raw::Node
) -&amp;gt; Option&amp;lt;protobuf::Node&amp;gt; {
    // This is basically C in Rust, so we better check for nulls!
    if node_ptr.is_null() {
        return None;
    }

    match (*node_ptr).type_ {
        // SELECT statement root node.
        bindings_raw::NodeTag_T_SelectStmt =&amp;gt; {
            let stmt = node_ptr as *mut bindings_raw::SelectStmt;
            Some(protobuf::node::Node::SelectStmt(Box::new(convert_select_stmt(&amp;amp;*stmt))))
        }
        
        // INSERT statement root node.
        bindings_raw::NodeTag_T_InsertStmt =&amp;gt; {
            let stmt = node_ptr as *mut bindings_raw::InsertStmt;
            Some(protobuf::node::Node::InsertStmt(Box::new(convert_insert_stmt(&amp;amp;*stmt))))
        }
        
        // ... 100s more nodes.
    }
}
&lt;/code&gt;
    &lt;p&gt;For nodes that contain other nodes, we recurse on &lt;code&gt;convert_node&lt;/code&gt; again until the algorithm reaches the leaves (nodes with no children) and terminates. For nodes that contain scalars, like a number (e.g., &lt;code&gt;5&lt;/code&gt;) or text (e.g., &lt;code&gt;'hello world'&lt;/code&gt;), the data type is copied into a Rust analog, e.g., &lt;code&gt;i32&lt;/code&gt; or &lt;code&gt;String&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The end result is &lt;code&gt;protobuf::ParseResult&lt;/code&gt;, a Rust struct generated by Prost from the pg_query API Protobuf specification, but populated by native Rust code instead of Prost’s deserializer. Reusing existing structs reduces the chance of errors considerably: we can compare &lt;code&gt;parse&lt;/code&gt; and &lt;code&gt;parse_raw&lt;/code&gt; outputs, using the derived &lt;code&gt;PartialEq&lt;/code&gt; trait, and ensure that both are identical, in testing.&lt;/p&gt;
    &lt;p&gt;While recursive algorithms have a questionable reputation in the industry because bad ones can cause stack overflows, they are very fast. Recursion requires no additional memory allocation because all of its working space, the stack, is created on program startup. It also has excellent CPU cache locality because the instructions for the next invocation of the same function are already in the CPU L1/L2/L3 cache. Finally and arguably more importantly, they are just easier to read and understand than iterative implementations, which helps us, the humans, with debugging.&lt;/p&gt;
    &lt;p&gt;Just for good measure, we tried generating an iterative algorithm, but it ended up being slower than Prost. The main cause (we think) was unnecessary memory allocations, hashmap lookups of previously converted nodes, and too much overhead from walking the tree several times. Meanwhile, recursion processes each AST node exactly once and uses the stack pointer to track its position in the tree. If you have any ideas on how to make an iterative algorithm work better, let us know!&lt;/p&gt;
    &lt;head rend="h3"&gt;Closing thoughts&lt;/head&gt;
    &lt;p&gt;Reducing the overhead from using the Postgres parser in PgDog makes a huge difference for us. As a network proxy, our budget for latency, memory utilization, and CPU cycles is low. After all, we aren’t a real database…yet! This change improves performance from two angles: we use less CPU and we do less work, so PgDog is faster and cheaper to run.&lt;/p&gt;
    &lt;p&gt;If stuff like this is interesting to you, reach out. We are looking for a Founding Software Engineer to help us grow and build the next iteration of horizontal scaling for PostgreSQL.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pgdog.dev/blog/replace-protobuf-with-rust"/><published>2026-01-23T09:03:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46730346</id><title>The state of modern AI text to speech systems for screen reader users</title><updated>2026-01-23T15:45:54.787879+00:00</updated><content>&lt;doc fingerprint="85deb33a0b1ab384"&gt;
  &lt;main&gt;
    &lt;p&gt;If you're not a screen reader user yourself, you might be surprised to learn that the text to speech technology used by most blind people hasn't changed in the last 30 years. While text to speech has taken the sighted world by storm, in everything from personal assistants to GPS to telephone systems, the voices used by blind folks have remained mostly static. This is largely intentional. The needs of a blind text to speech user are vastly different than those of a sighted user. While sighted users prefer voices that are natural, conversational, and as human-like as possible, blind users tend to prefer voices that are fast, clear, predictable, and efficient. This results in a preference among blind users for voices that sound somewhat robotic, but can be understood at high rates of speed, often upwards of 800 to 900 words per minute. The speaking rate of an average person hovers around 200 to 250 words per minute, for comparison.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this difference in needs has resulted in blind people getting left out of the explosion of text to speech advancement, and has caused many problems. First, the voice that is preferred by the majority of western English blind users, called Eloquence, was last updated in 2003. While it is so overwhelmingly popular that even Apple was eventually pressured to add the voice to iPhone, mac, Apple TV, and Apple Watch, even they were forced to use an emulation layer. As Eloquence is a 32-bit voice last compiled in 2003, it cannot run in modern software without some sort of emulation or bridge. If the sourcecode to Eloquence still exists and can be compiled, even large companies like Apple haven't managed to find or compile it. As the NVDA screen reader moves from being a 32-bit application to a 64-bit one, keeping eloquence running with it has been a challenge that I and many other community members have spent a lot of time and effort solving. The eloquence libraries also have many known security issues, and anyone using the libraries today is forced to understand and program around them, as Eloquence itself can never be updated or fixed. These stopgap solutions are entirely untenable, and are likely to take us only so far. A better solution is urgently needed.&lt;/p&gt;
    &lt;p&gt;The second problem this has caused is for those who speak languages other than English. As most modern text to speech voices are created by and for sighted users, blind users begin to find that the voices available in less popular languages are inefficient, overly conversational, slow, and otherwise unsatisfactory. While espeak-ng is an open-source text to speech system that attempts to support hundreds of languages while meeting the needs of blind users, it brings a different set of problems to the table. First, many of the languages it supports were added based on pronunciation rules taken from Wikipedia articles, without involving speakers of the language. Second, Espeak-ng is based directly on Speak, a text to speech system written by Jonathan Duddington in 1995 for RISC OS on the BBC Micro, meaning that espeak users today continue to have to live with many of the design decisions made back in 1995 for an operating system that no longer exists. Third, looking at the Espeak-ng repository, it seems to only have one or two active maintainers. While this is obviously better than the zero active maintainers of Eloquence, it could still become a problem in the future.&lt;/p&gt;
    &lt;p&gt;These are the reasons that I'm always interested in advancements in text to speech, and am actively keeping my ears open for something that takes advantage of modern technology, while continuing to suit the needs of screen reader users like myself.&lt;/p&gt;
    &lt;p&gt;Over the holiday break, I decided to take a look at two modern AI-based text to speech systems, and see if they could be added to NVDA. I chose two models, because they advertised themselves as fast, able to run without a GPU, and responsive. The first was supertonic, and the second was Kitten TTS. As both models require 64-bit Python, I wrote the addons for the 64-bit alpha of NVDA. However, other than making development easier, this had little effect on the results.&lt;/p&gt;
    &lt;p&gt;Unfortunately, doing this work uncovered a number of issues that I believe are common to all of the modern AI-based text to speech systems, and make them unsuitable for use in screen readers. The first issue is dependency bloat. In order to bundle these systems as NVDA addons, developers are required to include a vast multitude of large and complex Python packages. In the case of Kitten TTS, the number is around 103, and just over 30 for supertonic. As the standard building and packaging methods for NVDA addons do not support specifying and building requirements, these dependencies need to be manually copied over, included in any github repositories, and cannot be automatically updated. Loading all of these dependencies directly into NVDA also causes the screen reader to load slower, use more system resources, and opens NVDA users up to any security issue in any of these libraries. As a screen reader needs access to the entire system, this is far from ideal.&lt;/p&gt;
    &lt;p&gt;The second issue is accuracy. These modern systems are developed to sound human, natural, and conversational. Unfortunately this seems to come at the expense of accuracy. In my testing, both models had a tendency to skip words, read numbers incorrectly, chop off short utterances, and ignore prosody hints from text punctuation. Kitten TTS is slightly better here, as it uses a deterministic phonemizer (the same one used by espeak, actually) to determine the correct way to pronounce words, leaving only the generation of the speech itself up to AI. But never the less, Kitten TTS is still far from perfectly accurate. When it comes to use in a screen reader, skipping words, or reading numbers incorrectly, is unacceptable.&lt;/p&gt;
    &lt;p&gt;The third issue is speed. Supertonic has the edge, here, but even it is far too slow. Unlike older text to speech systems, Supertonic and Kitten TTS cannot begin generating speech until they have an entire chunk of text. Supertonic is slightly faster, as it can stream result audio as it becomes available, whereas Kitten TTS cannot start speaking until all of the audio for the chunk is fully generated. But for use in a screen reader, a text to speech system needs to begin generating speech as quickly as possible, rather than waiting for an entire phrase or sentence. Users of screen readers quickly jump through text and frequently interrupt the screen reader, and thus require the text to speech system to be able to quickly discard and restart speech.&lt;/p&gt;
    &lt;p&gt;The fourth and final issue is control. Older text to speech systems make changing the pitch, speed, volume, breathiness, roughness, headsize, and other parameters of the voice easy. This allows screen reader users to customize the voice to our exact needs, as well as offering the ability to change the characteristics of the voice in real time based on the formatting or other attributes of the text. AI text to speech models, being trained on data from a particular set of speakers, cannot offer this customization. Instead, they inherit the speaking speed, pitch, volume, and other characteristics that were present in the training data. Kitten TTS and Supertonic both offer basic speed control, however it is highly variable from voice to voice and utterance to utterance. This leads to a loss of functionality that many blind users depend on.&lt;/p&gt;
    &lt;p&gt;If you'd like to experience these issues for yourself, feel free to follow the links above to my GitHub repositories. They offer ready to install addons that can be installed and used with the 64-bit NVDA alphas.&lt;/p&gt;
    &lt;p&gt;I'm picking on Kitten TTS and Supertonic not because they're particularly bad for the above problems, but because they're the models that are the state of the art in AI text to speech right now when it comes to speed and size. Other models, like Kokoro, exhibit all of the same issues, but more so.&lt;/p&gt;
    &lt;p&gt;So what's the way forward for blind screen reader users? Sadly, I don't know. Modern text to speech research has little to no overlap with our requirements. Using Eloquence, the system that many blind people find best, is becoming increasingly untenable. ESpeak uses an odd architecture originally designed for computers in 1995, and has few maintainers. Blastbay Studios has done some interesting work to create a text to speech voice using modern design and technology, that meets the requirements of blind users. But it's a closed-source product with a single maintainer, that also suffers from a lack of pronunciation accuracy. In an ideal world, someone would re-implement Eloquence as a set of open source libraries. However, doing so would require expertise in linguistics, digital signal processing, and audiology, as well as excellent programming abilities. My suspicion is that modernizing the text to speech stack that is preferred by blind power-users is an effort that would require several million dollars of funding at minimum. Instead, we'll probably wind up having to settle for text to speech voices that are "good enough", while being nowhere near as fast and efficient as what we have currently. Personally, I intend to keep Eloquence limping along for as long as I can, until the layers of required emulation and bridges make real time use impossible. Perhaps at that point AI will be good enough that it can be prompted to create a text to speech system that's up to our standards. Or, more hopefully, articles like this one may bring attention to the issues, and bring our community together to recognize the problems and find solutions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://stuff.interfree.ca/2026/01/05/ai-tts-for-screenreaders.html"/><published>2026-01-23T09:24:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46730436</id><title>Updates to our web search products and  Programmable Search Engine capabilities</title><updated>2026-01-23T15:45:54.548169+00:00</updated><content>&lt;doc fingerprint="da81bed20394e73a"&gt;
  &lt;main&gt;
    &lt;p&gt;Evolving Programmable Search Engine&lt;/p&gt;
    &lt;p&gt;Programmable Search Engine helps hundreds of partners – from academic institutions to retail websites – serve their users’ search needs on their sites.&lt;/p&gt;
    &lt;p&gt;Looking forward, we’ll be evolving our offerings to provide more focused and capable solutions for every use case. This evolution is designed to ensure a high-quality experience for users and partners.&lt;/p&gt;
    &lt;p&gt;A clearer path for every search need&lt;/p&gt;
    &lt;p&gt;We're simplifying and modernizing our offerings so you can choose the best tool for your goals.&lt;/p&gt;
    &lt;p&gt;For site-specific search: The Programmable Search Element (the “Search Element”) is being simplified to be the best tool for creating rich, focused search experiences on your own websites. This solution is intended for website owners who cater focused content to a specific audience.&lt;/p&gt;
    &lt;p&gt;For enterprise-grade needs: For advanced features like AI-powered conversational search and enterprise-grade grounding, we continue to offer Google Vertex AI Search as a solution.&lt;/p&gt;
    &lt;p&gt;For full web search needs: We understand some partners have use cases that require querying beyond a designated subset of domains. Our full web search solution is available for those requiring our entire index; please complete this form to register your interest .&lt;/p&gt;
    &lt;p&gt;Planning your transition to more powerful tools&lt;/p&gt;
    &lt;p&gt;We are excited to help you harness the full potential of these evolving solutions. As you plan for the future, here is your path forward for the transition, which can be completed any time between now and January 1, 2027.&lt;/p&gt;
    &lt;p&gt;“Sites to search” feature for users of the Search Element querying 50 or fewer domains: The Search Element remains the optimal solution for delivering highly optimized and focused results. With this free feature, you can designate a maximum number of 50 domains for site-specific searches.&lt;/p&gt;
    &lt;p&gt;“Search the entire web” option for users of the Search Element querying more than 50 domains: If your use case necessitates querying more than 50 domains or is set to “Search the entire web”, contact us to express your interest in the more advanced full web search solution and get more information about its capabilities and pricing. Your transition to an alternative solution needs to be completed by January 1, 2027.&lt;/p&gt;
    &lt;p&gt;For users of the Custom Search JSON API: Vertex AI Search is a favorable alternative for up to 50 domains. Alternatively, if your use case necessitates full web search, contact us to express your interest in and get more information about our full web search solution. Your transition to an alternative solution needs to be completed by January 1, 2027.&lt;/p&gt;
    &lt;p&gt;To prepare for this transition, as of today, all new engines must be configured to use the “Sites to search” feature. This change impacts only new engines; existing engines are not affected and can continue to use the “Search the entire web” option until January 1, 2027.&lt;/p&gt;
    &lt;p&gt;This evolution will help us create more focused products, so we can provide a better search experience for our developer partners. We’re excited to build the future of search with you.&lt;/p&gt;
    &lt;p&gt;Thank you,&lt;/p&gt;
    &lt;p&gt;The Google Programmable Search Engine Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://programmablesearchengine.googleblog.com/2026/01/updates-to-our-web-search-products.html"/><published>2026-01-23T09:38:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46730504</id><title>AI Usage Policy</title><updated>2026-01-23T15:45:54.064973+00:00</updated><content>&lt;doc fingerprint="eb7ad05e09566404"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ghostty-org/ghostty/blob/main/AI_POLICY.md"/><published>2026-01-23T09:50:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46730885</id><title>Booting from a vinyl record (2020)</title><updated>2026-01-23T15:45:53.066678+00:00</updated><content>&lt;doc fingerprint="5c71fe289328686"&gt;
  &lt;main&gt;
    &lt;p&gt;Most PCs tend to boot from a primary media storage, be it a hard disk drive, or a solid-state drive, perhaps from a network, or – if all else fails – the USB stick or the boot DVD comes to the rescue… Fun, eh? Boring! Why don’t we try to boot from a record player for a change?&lt;/p&gt;
    &lt;p&gt;64 512 byte DOS boot disk on a 10″ record, total playing time 06:10 on 45 rpm&lt;/p&gt;
    &lt;p&gt;Update February 2022: Click here to observe the very same vinyl ramdisk booted on an IBM PCjr!&lt;lb/&gt; So this nutty little experiment connects a PC, or an IBM PC to be exact, directly onto a record player through an amplifier. I made a small ROM on-chip boot loader that operates the built-in “cassette interface” of the PC (that was hardly ever used), which will now be invoked by the BIOS if all the other boot options fail, i.e. floppy disk and the hard drive. The turntable spins an analog recording of a small bootable read-only RAM drive, which is 64K in size. This contains a FreeDOS kernel, modified by me to cram it into the memory constraint, a micro variant of COMMAND.COM and a patched version of INTERLNK, that allows file transfer through a printer cable, modified to be runnable on FreeDOS. The bootloader reads the disk image from the audio recording through the cassette modem, loads it to memory and boots the system on it. Simple huh?&lt;/p&gt;
    &lt;p&gt;The vinyl loader code, in a ROM&lt;lb/&gt; (It can also reside on a hard drive or a floppy, but that’d be cheating)&lt;/p&gt;
    &lt;p&gt;And now to get more technical: this is basically a merge between BootLPT/86 and 5150CAXX, minus the printer port support. It also resides in a ROM, in the BIOS expansion socket, but it does not have to. The connecting cable between the PC and the record player amplifier is the same as with 5150CAXX, just without the line-in (PC data out) jack.&lt;lb/&gt; The “cassette interface” itself is just PC speaker timer channel 2 for the output, and 8255A-5 PPI port C channel 4 (PC4, I/O port 62h bit 4) for the input. BIOS INT 15h routines are used for software (de)modulation.&lt;lb/&gt; The boot image is the same 64K BOOTDISK.IMG “example” RAM drive that can be downloaded at the bottom of the BootLPT article. This has been turned into an “IBM cassette tape”-protocol compliant audio signal using 5150CAXX, and sent straight to a record cutting lathe.&lt;lb/&gt; Vinyls are cut with an RIAA equalization curve that a preamp usually reverses during playback, but not perfectly. So some signal correction had to be applied from the amplifier, as I couldn’t make it work right with the line output straight from the phono preamp. In my case, involving a vintage Harman&amp;amp;Kardon 6300 amplifier with an integrated MM phono preamp, I had to fade the treble all the way down to -10dB/10kHz, increase bass equalization to approx. +6dB/50Hz and reduce the volume level to approximately 0.7 volts peak, so it doesn’t distort. All this, naturally, with any phase and loudness correction turned off.&lt;lb/&gt; Of course, the cassette modem does not give a hoot in hell about where the signal is coming from. Notwithstanding, the recording needs to be pristine and contain no pops or loud crackles (vinyl) or modulation/frequency drop-outs (tape) that will break the data stream from continuing. However, some wow is tolerated, and the speed can be 2 or 3 percent higher or lower too.&lt;/p&gt;
    &lt;p&gt;Bootloader in a ROM; being an EPROM for a good measure&lt;/p&gt;
    &lt;p&gt;And that’s it! For those interested, the bootloader binary designed for a 2364 chip (2764s can be used, through an adaptor), can be obtained here. It assumes an IBM 5150 with a monochrome screen and at least 512K of RAM, which kind of reminds me of my setup (what a coincidence). The boot disk image can be obtained at the bottom of the BootLPT/86 article, and here’s its analog variant, straight from the grooves 🙂&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://boginjr.com/it/sw/dev/vinyl-boot/"/><published>2026-01-23T10:39:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46731432</id><title>Show HN: Whosthere: A LAN discovery tool with a modern TUI, written in Go</title><updated>2026-01-23T15:45:52.562540+00:00</updated><content>&lt;doc fingerprint="b709fb1d9ea3f390"&gt;
  &lt;main&gt;
    &lt;p&gt;Local Area Network discovery tool with a modern Terminal User Interface (TUI) written in Go. Discover, explore, and understand your LAN in an intuitive way.&lt;/p&gt;
    &lt;p&gt;Whosthere performs unprivileged, concurrent scans using mDNS and SSDP scanners. Additionally, it sweeps the local subnet by attempting TCP/UDP connections to trigger ARP resolution, then reads the ARP cache to identify devices on your Local Area Network. This technique populates the ARP cache without requiring elevated privileges. All discovered devices are enhanced with OUI lookups to display manufacturers when available.&lt;/p&gt;
    &lt;p&gt;Whosthere provides a friendly, intuitive way to answer the question every network administrator asks: "Who's there on my network?"&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modern TUI: Navigate and explore discovered devices intuitively.&lt;/item&gt;
      &lt;item&gt;Fast &amp;amp; Concurrent: Leverages multiple discovery methods simultaneously.&lt;/item&gt;
      &lt;item&gt;No Elevated Privileges Required: Runs entirely in user-space.&lt;/item&gt;
      &lt;item&gt;Device Enrichment: Uses OUI lookup to show device manufacturers.&lt;/item&gt;
      &lt;item&gt;Integrated Port Scanner: Optional service discovery on found hosts (only scan devices with permission!).&lt;/item&gt;
      &lt;item&gt;Daemon Mode with HTTP API: Run in the background and integrate with other tools.&lt;/item&gt;
      &lt;item&gt;Theming &amp;amp; Configuration: Personalize the look and behavior via YAML configuration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew tap ramonvermeulen/whosthere
brew install whosthere&lt;/code&gt;
    &lt;p&gt;Or with Go:&lt;/p&gt;
    &lt;code&gt;go install github.com/ramonvermeulen/whosthere@latest&lt;/code&gt;
    &lt;p&gt;Or build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/ramonvermeulen/whosthere.git
cd whosthere
make build&lt;/code&gt;
    &lt;p&gt;Run the TUI for interactive discovery:&lt;/p&gt;
    &lt;code&gt;whosthere&lt;/code&gt;
    &lt;p&gt;Run as a daemon with HTTP API:&lt;/p&gt;
    &lt;code&gt;whosthere daemon --port 8080&lt;/code&gt;
    &lt;p&gt;Additional command line options can be found by running:&lt;/p&gt;
    &lt;code&gt;whosthere --help&lt;/code&gt;
    &lt;p&gt;Whosthere is supported on the following platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux&lt;/item&gt;
      &lt;item&gt;macOS&lt;/item&gt;
      &lt;item&gt;Windows (maybe in the future, contributions welcome!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start regex search&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;k&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;j&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;g&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to top&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;G&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to bottom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;y&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Copy IP of selected device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show device details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;CTRL+t&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle theme selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;CTRL+c&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ESC&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Clear search / Go back&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;p&lt;/code&gt; (details view)&lt;/cell&gt;
        &lt;cell&gt;Start port scan on device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;tab&lt;/code&gt; (modal view)&lt;/cell&gt;
        &lt;cell&gt;Switch button selection&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;WHOSTHERE_CONFIG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to the configuration file, to be able to overwrite the default location.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;WHOSTHERE_LOG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set the log level (e.g., &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;info&lt;/code&gt;, &lt;code&gt;warn&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt;). Defaults to &lt;code&gt;info&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Whosthere can be configured via a YAML configuration file. By default, it looks for the configuration file in the following order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Path specified in the &lt;code&gt;WHOSTHERE_CONFIG&lt;/code&gt;environment variable (if set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$XDG_CONFIG_HOME/whosthere/config.yaml&lt;/code&gt;(if&lt;code&gt;XDG_CONFIG_HOME&lt;/code&gt;is set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.config/whosthere/config.yaml&lt;/code&gt;(otherwise)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When not running in TUI mode, logs are also written to the console output.&lt;/p&gt;
    &lt;p&gt;Example of the default configuration file:&lt;/p&gt;
    &lt;code&gt;# How often to run discovery scans
scan_interval: 20s

# Maximum duration for each scan
# If you set this too low some scanners or the sweeper might not complete in time
scan_duration: 10s

# Splash screen configuration
splash:
  enabled: true
  delay: 1s

# Theme configuration
theme:
  # Configure the theme to use for the TUI, complete list of available themes at:
  # https://github.com/ramonvermeulen/whosthere/tree/main/internal/ui/theme/theme.go
  # Set name to "custom" to use the custom colors below
  # For any color that is not configured it will take the default theme value as fallback
  name: default

  # Custom theme colors (uncomment and set name: custom to use)
  # primitive_background_color: "#000a1a"
  # contrast_background_color: "#001a33"
  # more_contrast_background_color: "#003366"
  # border_color: "#0088ff"
  # title_color: "#00ffff"
  # graphics_color: "#00ffaa"
  # primary_text_color: "#cceeff"
  # secondary_text_color: "#6699ff"
  # tertiary_text_color: "#ffaa00"
  # inverse_text_color: "#000a1a"
  # contrast_secondary_text_color: "#88ddff"

# Scanner configuration
scanners:
  mdns:
    enabled: true
  ssdp:
    enabled: true
  arp:
    enabled: true

# Port scanner configuration
port_scanner:
  timeout: 5s
  # List of TCP ports to scan on discovered devices
  tcp: [21, 22, 23, 25, 80, 110, 135, 139, 143, 389, 443, 445, 993, 995, 1433, 1521, 3306, 3389, 5432, 5900, 8080, 8443, 9000, 9090, 9200, 9300, 10000, 27017]

# Uncomment the next line to configure a specific network interface - uses OS default if not set
# network_interface: lo0&lt;/code&gt;
    &lt;p&gt;When running Whosthere in daemon mode, it exposes an very simplistic HTTP API with the following endpoints:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Endpoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/devices&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get list of all discovered devices&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/device/{ip}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get details of a specific device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/health&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Health check&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Theme can be configured via the configuration file, or at runtime via the &lt;code&gt;CTRL+t&lt;/code&gt; key binding.
A complete list of available themes can be found here, feel free to open a PR to add your own theme!&lt;/p&gt;
    &lt;p&gt;Example of theme configuration:&lt;/p&gt;
    &lt;code&gt;theme:
  name: cyberpunk&lt;/code&gt;
    &lt;p&gt;When the &lt;code&gt;name&lt;/code&gt; is set to &lt;code&gt;custom&lt;/code&gt;, the other color options can be used to create your own custom theme.&lt;/p&gt;
    &lt;p&gt;Logs are written to the application's state directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;$XDG_STATE_HOME/whosthere/app.log&lt;/code&gt;(if&lt;code&gt;XDG_STATE_HOME&lt;/code&gt;is set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.local/state/whosthere/app.log&lt;/code&gt;(otherwise)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When not running in TUI mode, logs are also output to the console.&lt;/p&gt;
    &lt;p&gt;For clipboard functionality to work:&lt;/p&gt;
    &lt;p&gt;Runtime requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux (X11): X11 client library (e.g., &lt;code&gt;libx11-6&lt;/code&gt;on Ubuntu,&lt;code&gt;libX11&lt;/code&gt;on Fedora/Arch, often pre-installed).&lt;/item&gt;
      &lt;item&gt;Linux (Wayland): Not natively supported. May require XWayland.&lt;/item&gt;
      &lt;item&gt;macOS/Windows: No dependencies.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build requirements (when compiling from source):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux: X11 development package (&lt;code&gt;libx11-dev&lt;/code&gt;,&lt;code&gt;libX11-devel&lt;/code&gt;, or&lt;code&gt;libx11&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whosthere is intended for use on networks where you have permission to perform network discovery and scanning, such as your own home network. Unauthorized scanning of networks may be illegal and unethical. Always obtain proper authorization before using this tool on any network.&lt;/p&gt;
    &lt;p&gt;Contributions and suggestions such as feature requests, bug reports, or improvements are welcome! Feel free to open issues or submit pull requests on the GitHub repository. Please make sure to discuss any major changes on a Github issue before implementing them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/ramonvermeulen/whosthere"/><published>2026-01-23T11:54:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46731612</id><title>Presence in Death</title><updated>2026-01-23T15:45:48.126608+00:00</updated><content>&lt;doc fingerprint="bf9c9a2f1fa79b9c"&gt;
  &lt;main&gt;
    &lt;p&gt;In what Tibetan Buddhists call tukdam (Wylie transliteration: thugs dam), experienced meditators die in meditative equipoise. Their bodies do not show the usual signs of death—such as smell, rigor mortis, or decomposition—for days or even weeks after their clinical deaths. They appear lifelike, and many even remain sitting upright in meditation posture. From the Tibetan Buddhist point of view, the meditators are resting in a subtle state of consciousness with an associated subtle material energy present in the body. They are still in the process of dying. Yet according to modern biomedical and legal definitions, they are dead. Many cases of tukdam have now been scientifically documented.&lt;/p&gt;
    &lt;p&gt;For my 2022 documentary film Tukdam: Between Worlds and research for my PhD in medical anthropology, I have been following the Tukdam Project, a groundbreaking scientific research initiative lead from the Center for Healthy Minds at the University of Wisconsin—Madison and headed by renowned neuroscientist Richard Davidson.* It has focused on documenting tukdam bodies and trying to understand why the decomposition process seems to be delayed. His Holiness the Dalai Lama initiated this multidisciplinary project, which has been carried out with Tibetan collaborators from Delek Hospital in Dharamshala and Men-Tsee-Khang (Tibetan Medical and Astro-Science Institute) traditional Tibetan medicine doctors in India. In recent years, Russian and Indian scientific collaborators have also joined the effort to understand tukdam scientifically.&lt;/p&gt;
    &lt;p&gt;In following the project, I have been struck by the differing expectations and even cross-purposes that the Tibetan and scientific parties seem to harbor. Tibetans hope the research may reveal something about a subtle nature of consciousness that continues beyond clinical and brain death, and which is held to be responsible for keeping the bodies fresh. The Dalai Lama also seems to be invested in this research because of its potential to reveal something about the nature of consciousness that transcends the brain-body complex and even this life.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;IN TUKDAM, CLINICALLY DEAD MEDITATORS ARE SAID TO DWELL IN THE LUMINOSITY OF EMPTINESS.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While the non-decaying tukdam body signifies the presence of consciousness for Tibetans, this is not obvious from a biophysical scientific perspective. Indeed, the Center for Healthy Minds has been looking for possible residual activity in the brainstem—a primitive part of the brain not thought to be involved in consciousness—as a factor contributing to the unusual integration of the bodies. In 2021, the research team published a null-finding stating they had not found any activity in the brain so far. Compelled to operate within a biophysical paradigm, scientists are also interested in possible changes to cell metabolism and breakdown, brought about by years of meditation practice, as perhaps contributing to the pristine postmortem state of tukdam bodies. But taking samples from the bodies has so far been out of the question due to cultural sensitivity and the sacredness of these deaths. Tibetans are concerned that invasive procedures could disturb the postmortem meditative state and the potential it carries for spiritual liberation and achieving a good rebirth.&lt;/p&gt;
    &lt;p&gt;An exchange from Tukdam: Between Worlds illustrates some of the tensions and cross-purposes with which the scientists and Tibetan parties have been operating, although there have been developments in the research and collaboration since the time of shooting in 2019 to early 2020. The scene shows a meeting where Dr. Dylan Lott, who was then the Tukdam Project manager in India, presents the current state of the research and its findings to Tibetan project collaborators. The Dalai Lama’s personal physician, Dr. Tsetan Dorji Sadutshang, expresses frustration over the lack of results from years of research and what he sees as a misguided approach to explain tukdam in neuroscientific terms. According to the Tibetan view, something far more subtle than the “gross” mind related to the brain and senses is responsible for the physical signs of tukdam.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Dr. Tsetan:&lt;/p&gt;
      &lt;p&gt;To me, from my understanding of His Holiness’ hope from this project, really is to have some proof that there is some sort of consciousness . . . or a mind continuing, that goes on beyond this life, basically. The only first kindergarten step is really to say: Is there a difference between a gross mind and a subtle mind?&lt;/p&gt;
      &lt;p&gt;Dr. Lott:&lt;/p&gt;
      &lt;p&gt;We cannot prove rebirth. We cannot prove mind. We cannot prove subtle mind. What we can do is look at the effects of those practices on the body that are unusual and that Western science, or medical science, doesn’t have a good explanation for.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As is the case with science, it is not obvious to all Buddhist traditions that a non-decomposing body proves the presence of consciousness. The medieval Chinese Chan tradition, for example, also records miraculously preserved meditators’ bodies. These did not, however, signify present consciousness, which according to widespread Buddhist doctrine, departs immediately at death to be reborn or to enter nirvana. Here the body is preserved due to purification by religious practice and virtue accumulated while alive.&lt;/p&gt;
    &lt;p&gt;There is something paradoxical in taking the non-decaying body as evidence for a consciousness that transcends the body and physicality. However, here we should be careful to note that in the Tibetan Buddhist tantric tradition different levels of mind are associated with different types of embodiment. Subtler forms of consciousness are associated with tantric subtle bodies or physiologies familiar to advanced tantric practitioners. As these are in a way two sides of the same coin, mind always affects body and vice versa. Such subtle bodies are arguably different from, though connected to, the “gross” biomedical body that scientists work with, which also shows effects of subtle levels of mind and embodiment.&lt;/p&gt;
    &lt;p&gt;Tibetan tradition exhibits a great deal of sophistication and specificity when it comes to signs or ways of ascertaining whether a person is in tukdam—as well as when it ends. The body will slump over if it was sitting upright; smell and normal signs of decomposition will appear. In accordance with subtle tantric physiology, red and white liquids may come out the nostrils and genitals. These are all signs that even the most subtle consciousness has departed. For Tibetans, final death occurs when the mind leaves the body, which could be weeks after clinical death in cases of tukdam,or hours to days for “normal” deaths.&lt;/p&gt;
    &lt;p&gt;There is also a tantalizing tradition of ending tukdam that could be seen as indicative of consciousness. If tukdam goes on too long, it may be ended by ringing a bell near the ear of the deceased practitioner, saying certain prayers, or asking them to end their meditation. The body then reportedly collapses and decomposition takes over. This could imply responsivity on the part of the deceased meditators, bearing on questions of consciousness. In an interview piece that did not make the final cut of my documentary, the Dalai Lama recounted this story:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One lama I had a very close connection [with] . . . Last few years his physical [condition] was very, very weak. And then in my last meeting in Mongolia, I told him, “Now time has come. You have to think about your next life.” Then around the end of the year, with New Year soon, I received one message from him: “When I should die? Where I should die?” . . . Quite silly, “where I should die, when I should die!” Then accordingly I also answered a silly sort of answer, “You should die in Mongolia. The time, not end of the year but the beginning of the year, New Year.” He exactly, I think in the first week of the New Year, then he died. Then I sent my representative with my [ceremonial silk] scarf. I think it took two days . . . When my representative reached his place and put the scarf which I sent . . . on his neck, then he ended his tukdam. [Dalai Lama makes gesture of body slumping over.] So these are quite mysterious things. There are some elements to control. It is quite obvious as soon as the tukdam ends, the physical [body] clearly shows real death, the real corpse.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;People often report feeling a meditative calm or presence when entering the room of someone in tukdam. Some of the American scientists researching tukdam also said they felt it. But such things seem difficult to measure and to be firmly in the realm of first-person experience as opposed to the third-person observation of natural science. This does not, however, necessarily make such perceptions less real. As another Tukdam Project collaborator, senior Tibetan medicine doctor Tsewang Tamdin, told me, “Just because something is invisible does not mean it does not exist.”&lt;/p&gt;
    &lt;p&gt;As in life and death, the dynamic of presence and absence is central to tukdam. Here we come to a basic conflict between the Tibetan Buddhist and current biomedical views of death. For the latter, death unequivocally means absence. Once the heart shuts down, brain death quickly follows “unless it’s been inflicted before the heart stopped” and the person is gone. But for Tibetan Buddhists, there is presence, or mind, in death.&lt;/p&gt;
    &lt;p&gt;*Richard Davidson is a member of the Rubin Museum’s advisory board.&lt;/p&gt;
    &lt;p&gt;Donagh Coleman is a Finnish-Irish-American filmmaker. Previous award-winning documentaries with international festival and TV exposure include Stone Pastures and A Gesar Bard’s Tale. Donagh’s films have been shown by the European Commission and museums such as MoMA and the Rubin Museum. Donagh is currently doing a PhD in medical anthropology at University of California, Berkeley and holds degrees in philosophy and psychology and music and media technologies from Trinity College Dublin, as well as a master’s in Asian studies from University of California, Berkeley.&lt;/p&gt;
    &lt;p&gt;Get the latest news and stories from the Rubin, plus occasional information on how to support our work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rubinmuseum.org/presence-in-death/"/><published>2026-01-23T12:16:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46731748</id><title>What has Docker become?</title><updated>2026-01-23T15:45:47.868562+00:00</updated><content>&lt;doc fingerprint="3d97b07b1d651558"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What has Docker become?&lt;/head&gt;
    &lt;head rend="h5"&gt;Posted on January 20, 2026 • 4 minutes • 851 words&lt;/head&gt;
    &lt;p&gt;It’s weird to see Docker Inc (the company) struggle to find its place in 2026. What started as the company that revolutionized how we deploy applications has been through multiple identity crises, pivoting from one strategy to another in search of sustainable revenue and market relevance.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Identity Crisis&lt;/head&gt;
    &lt;p&gt;Docker’s journey reads like a startup trying to find product-market fit, except Docker already had product-market fit - they created the containerization standard that everyone uses. The problem is that Docker the technology became so successful that Docker the company struggled to monetize it. When your core product becomes commoditized and open source, you need to find new ways to add value.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Swarm Exit&lt;/head&gt;
    &lt;p&gt;Docker Swarm was Docker’s attempt to compete with Kubernetes in the orchestration space. But Kubernetes won that battle decisively, and Docker eventually sold Swarm. This was a clear signal that Docker was stepping back from trying to be the full-stack container platform and instead focusing on what they could uniquely provide.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Developer Tools Pivot&lt;/head&gt;
    &lt;p&gt;For a while, Docker seemed to focus on developer experience. This made sense - developers are Docker’s core users, and improving their workflow could be a differentiator. Docker Scout emerged from the acquisition of Atomist in June 2022, bringing “software supply chain” capabilities. Scout allows Docker to see not just what’s in a container, but how it was built and where vulnerabilities are. This was a smart move toward security and observability, areas where Docker could add real value.&lt;/p&gt;
    &lt;p&gt;Docker also acquired AtomicJar, the company behind Testcontainers, adding shift-left testing capabilities. Testcontainers lets developers run real dependencies (databases, message queues, etc.) in containers during testing, making integration tests more reliable and closer to production environments.&lt;/p&gt;
    &lt;head rend="h2"&gt;The AI Pivot&lt;/head&gt;
    &lt;p&gt;Then came the AI pivot. Docker Model Runner entered the scene, positioning Docker as a platform for running AI models. Docker Compose expanded to support AI agents and models. Docker Offload was introduced for cloud-scale GPU execution of AI tasks. Partnerships with Google Cloud, Microsoft Azure, and AI SDKs (CrewAI, LangGraph, Vercel AI SDK) followed.&lt;/p&gt;
    &lt;p&gt;The acquisition of MCP Defender in September 2025 further cemented Docker’s move into AI security, focusing on securing agentic AI infrastructure and runtime threat detection. This was a significant shift - from developer tools to AI infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Hardened Images Move&lt;/head&gt;
    &lt;p&gt;Suddenly, Docker moved into the hardened images space. In December 2025, Docker made over 1,000 Docker Hardened Images free and open source under Apache 2.0, reducing vulnerabilities by up to 95% compared to traditional images. This move was likely triggered by Chainguard’s success in the secure container image space. Chainguard had been building a business around minimal, secure container images, and Docker needed to respond.&lt;/p&gt;
    &lt;p&gt;Making hardened images free was a bold move - it’s hard to compete with free, especially when it’s open source. But it also raises questions about Docker’s business model. If you’re giving away your security features for free, what are you selling?&lt;/p&gt;
    &lt;head rend="h2"&gt;Leadership Changes and Acquisition Speculation&lt;/head&gt;
    &lt;p&gt;In February 2025, Docker replaced CEO Scott Johnston (who led the company since 2019) with Don Johnson, a former Oracle Cloud Infrastructure founder and executive vice president. This leadership transition has prompted tech analysts to anticipate a potential acquisition by a major cloud provider. The CEO swap, combined with the strategic pivots, suggests Docker may be positioning itself for sale rather than building a standalone business.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This All Means&lt;/head&gt;
    &lt;p&gt;Docker’s strategic shifts tell a story of a company searching for its place in a market it helped create. The containerization technology Docker pioneered became so successful that it became infrastructure - something everyone uses but no one wants to pay for directly.&lt;/p&gt;
    &lt;p&gt;The pivots from orchestration (Swarm) to developer tools (Scout, Testcontainers) to AI (Model Runner, MCP Defender) to security (Hardened Images) show a company trying different approaches to find sustainable revenue. Each pivot makes sense in isolation, but together they paint a picture of a company without a clear long-term vision.&lt;/p&gt;
    &lt;p&gt;The hardened images move is particularly interesting because it’s defensive - responding to Chainguard’s success rather than leading with innovation. Making it free and open source is a strong competitive move, but it doesn’t solve the fundamental business model question.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Future&lt;/head&gt;
    &lt;p&gt;Docker the technology isn’t going anywhere. It’s too embedded in the infrastructure of modern software development. But Docker the company? That’s less clear. The leadership change, acquisition speculation, and rapid strategic pivots suggest Docker Inc may be positioning itself for an exit rather than building a long-term independent business.&lt;/p&gt;
    &lt;p&gt;For developers, this doesn’t change much. Docker containers will continue to work, and the open source nature of Docker means the technology will persist regardless of what happens to the company. But it’s worth watching how Docker Inc’s search for identity plays out - it could affect the ecosystem of tools and services built around containers.&lt;/p&gt;
    &lt;p&gt;The irony is that Docker created a standard so successful that it became infrastructure, and infrastructure is hard to monetize. Docker Inc’s struggle to find its place is a cautionary tale about the challenges of building a business around open source technology that becomes too successful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tuananh.net/2026/01/20/what-has-docker-become/"/><published>2026-01-23T12:36:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46731976</id><title>European Alternatives</title><updated>2026-01-23T15:45:46.777209+00:00</updated><content>&lt;doc fingerprint="8c31fd39e929e0e6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;European alternatives for digital products&lt;/head&gt;
    &lt;head rend="h2"&gt;We help you find European alternatives for digital service and products, like cloud services and SaaS products.&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;
        &lt;p&gt;Support local businesses&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-1"&gt;When you buy from local businesses, you are supporting yourself down the road. Taxes paid by the company come back to you indirectly and the company creates jobs in your region.&lt;/item&gt;
      &lt;item rend="dt-2"&gt;
        &lt;p&gt;Data protection / GDPR&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-2"&gt;Some companies outside Europe tend to ignore data protection and related laws such as the GDPR or do not implement them correctly.&lt;/item&gt;
      &lt;item rend="dt-3"&gt;
        &lt;p&gt;VAT / Billing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-3"&gt;As a business that operates in Europe, it is possible to get a VAT refund for products/services of other European companies. European companies also tend to offer payment methods that are commonly used in Europe.&lt;/item&gt;
      &lt;item rend="dt-4"&gt;
        &lt;p&gt;Similar legal requirements&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-4"&gt;Within the EU, many laws and framework conditions are set by the EU, which helps to cover a large market without having to consider large country-specific differences. It is also easier to enforce your rights against another company located in the EU.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Categories&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Web analytics services&lt;/head&gt;&lt;p&gt;A web analytics service tracks user behavior on websites so that website owners can understand user usage and optimize their websites.&lt;/p&gt;31 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Cloud computing platforms&lt;/head&gt;&lt;p&gt;A cloud computing platform provides on-demand hosting services.&lt;/p&gt;12 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Content delivery network (CDN) services&lt;/head&gt;&lt;p&gt;A content delivery network (CDN) is a geographically distributed network.&lt;/p&gt;6 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Email providers&lt;/head&gt;&lt;p&gt;An email provider provides its users with an e-mail address and the corresponding mailboxes.&lt;/p&gt;20 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Virtual private server (VPS) hosters&lt;/head&gt;&lt;p&gt;A virtual private server (VPS) hoster provides virtual servers with predefined RAM, storage, traffic and virtual cores.&lt;/p&gt;23 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Search engines&lt;/head&gt;&lt;p&gt;A search engine allows their users to search the internet.&lt;/p&gt;6 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Transactional email service&lt;/head&gt;&lt;p&gt;A transactional mail service offers users the ability to send emails from their applications via the service.&lt;/p&gt;7 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Domain name registrars&lt;/head&gt;&lt;p&gt;Domain name registrars are companies that manages the reservation of Internet domain names.&lt;/p&gt;13 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Time tracking apps&lt;/head&gt;&lt;p&gt;A time tracking app is an application that helps users track how much time was spent on which task or project.&lt;/p&gt;13 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Navigation apps&lt;/head&gt;&lt;p&gt;Navigation apps help you get from A to B.&lt;/p&gt;8 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Uptime monitoring services&lt;/head&gt;&lt;p&gt;An uptime monitoring service periodically checks if a website or other service is active.&lt;/p&gt;12 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;File hosting services&lt;/head&gt;&lt;p&gt;With a file hosting service, users can upload files to back them up or share them with others.&lt;/p&gt;11 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Machine translation services&lt;/head&gt;&lt;p&gt;A machine translation service (translator) is a service that programmatically translates text from one language to another.&lt;/p&gt;5 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Object storage providers&lt;/head&gt;&lt;p&gt;Object storage providers allow their users to store files hierarchically.&lt;/p&gt;15 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Microblogging services&lt;/head&gt;&lt;p&gt;A microblogging service allows users to post short texts, images or links to videos.&lt;/p&gt;2 alternatives&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://european-alternatives.eu"/><published>2026-01-23T13:01:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46731996</id><title>Microsoft mishandling example.com</title><updated>2026-01-23T15:45:46.594202+00:00</updated><content>&lt;doc fingerprint="af11ed5a5a169e95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Microsoft mishandling example.com&lt;/head&gt;
    &lt;p&gt;TL;DR: Since at least February 2020, Microsoft's Autodiscover service has incorrectly routed the IANA-reserved &lt;code&gt;example.com&lt;/code&gt; to Sumitomo Electric Industries' mail servers at sei.co.jp, potentially sending test credentials there.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problem&lt;/head&gt;
    &lt;p&gt;While setting up &lt;code&gt;email@example.com&lt;/code&gt; as a dummy account in Outlook (on both Windows and macOS), Outlook consistently auto-configured it to use &lt;code&gt;imapgms.jnet.sei.co.jp&lt;/code&gt; (IMAP) and &lt;code&gt;smtpgms.jnet.sei.co.jp&lt;/code&gt; (SMTP) despite &lt;code&gt;example.com&lt;/code&gt; being an IANA-reserved domain that should not resolve to real services.&lt;/p&gt;
    &lt;p&gt;The same behavior appeared on different machines, profiles, networks, and DNS resolvers, including a newly provisioned Windows 365 Cloud PC:&lt;/p&gt;
    &lt;head rend="h2"&gt;Confirmation&lt;/head&gt;
    &lt;head rend="h3"&gt;DNS verification&lt;/head&gt;
    &lt;p&gt;Confirm that &lt;code&gt;example.com&lt;/code&gt; has no DNS records pointing to &lt;code&gt;sei.co.jp&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;%&lt;code&gt;dig MX example.com +short&lt;/code&gt;0 . %&lt;code&gt;dig CNAME autodiscover.example.com +short&lt;/code&gt;(no response) %&lt;code&gt;dig SRV _autodiscover._tcp.example.com +short&lt;/code&gt;(no response)&lt;/quote&gt;
    &lt;p&gt;The domain has a null MX record (indicating it doesn't accept email) and no Autodiscover DNS entries, confirming the misconfiguration exists entirely within Microsoft's database.&lt;/p&gt;
    &lt;head rend="h3"&gt;Microsoft autodiscover API response&lt;/head&gt;
    &lt;p&gt;Microsoft's Autodiscover service misconfiguration can be confirmed via &lt;code&gt;curl -v -u "email@example.com:password" "https://prod.autodetect.outlook.cloud.microsoft/autodetect/detect?app=outlookdesktopBasic"&lt;/code&gt;:&lt;/p&gt;
    &lt;head&gt;View full output&lt;/head&gt;
    &lt;quote&gt;* Host prod.autodetect.outlook.cloud.microsoft:443 was resolved. * IPv6: (none) * IPv4: 172.169.69.94 * Trying 172.169.69.94:443... * Connected to prod.autodetect.outlook.cloud.microsoft (172.169.69.94) port 443 * ALPN: curl offers h2,http/1.1 * (304) (OUT), TLS handshake, Client hello (1): * CAfile: /etc/ssl/cert.pem * CApath: none * (304) (IN), TLS handshake, Server hello (2): * (304) (IN), TLS handshake, Unknown (8): * (304) (IN), TLS handshake, Certificate (11): * (304) (IN), TLS handshake, CERT verify (15): * (304) (IN), TLS handshake, Finished (20): * (304) (OUT), TLS handshake, Finished (20): * SSL connection using TLSv1.3 / AEAD-AES256-GCM-SHA384 / [blank] / UNDEF * ALPN: server accepted h2 * Server certificate: * subject: C=US; ST=WA; L=Redmond; O=Microsoft Corporation; CN=autodetect.outlookmobile.com * start date: Nov 1 12:31:46 2025 GMT * expire date: Jan 30 12:31:46 2026 GMT * subjectAltName: host "prod.autodetect.outlook.cloud.microsoft" matched cert's "*.autodetect.outlook.cloud.microsoft" * issuer: C=US; O=Microsoft Corporation; CN=Microsoft Azure RSA TLS Issuing CA 03 * SSL certificate verify ok. * using HTTP/2 * Server auth using Basic with user 'email@example.com' * [HTTP/2] [1] OPENED stream for https://prod.autodetect.outlook.cloud.microsoft/autodetect/detect?app=outlookdesktopBasic * [HTTP/2] [1] [:method: GET] * [HTTP/2] [1] [:scheme: https] * [HTTP/2] [1] [:authority: prod.autodetect.outlook.cloud.microsoft] * [HTTP/2] [1] [:path: /autodetect/detect?app=outlookdesktopBasic] * [HTTP/2] [1] [authorization: Basic ZW1haWxAZXhhbXBsZS5jb206cGFzc3dvcmQ=] * [HTTP/2] [1] [user-agent: curl/8.7.1] * [HTTP/2] [1] [accept: */*] &amp;gt; GET /autodetect/detect?app=outlookdesktopBasic HTTP/2 &amp;gt; Host: prod.autodetect.outlook.cloud.microsoft &amp;gt; Authorization: Basic ZW1haWxAZXhhbXBsZS5jb206cGFzc3dvcmQ= &amp;gt; User-Agent: curl/8.7.1 &amp;gt; Accept: */* &amp;gt; * Request completely sent off &amp;lt; HTTP/2 200 &amp;lt; content-type: application/json; charset=utf-8 &amp;lt; date: Mon, 08 Dec 2025 21:32:58 GMT &amp;lt; server: Kestrel &amp;lt; strict-transport-security: max-age=2592000 &amp;lt; x-olm-source-endpoint: /detect &amp;lt; x-provider-id: seeatest &amp;lt; x-debug-support: eyJkZWNpc2lvbiI6ImF1dG9EdjIgPiBhdXRvRHYxID4gZml4ZWQgZGIgcHJvdmlkZXIgPiBmaXhlZCBkYiBkb21haW4gcHJvdG9jb2xzID4gZGIgcHJvdmlkZXIgPiBkYiBkb21haW4gcHJvdG9jb2xzIiwiYXV0b0QiOnsidjIiOm51bGwsInYxIjpudWxsfSwiZGIiOnsicHJvdmlkZXIiOnsiRG9tYWluSWQiOm51bGwsIklkIjoic2VlYXRlc3QiLCJTZXJ2aWNlIjpudWxsLCJQcm90b2NvbHMiOlt7InByb3RvY29sIjoic210cCIsIkRvbWFpbiI6bnVsbCwiSG9zdG5hbWUiOiJzbXRwZ21zLmpuZXQuc2VpLmNvLmpwIiwiUG9ydCI6NDY1LCJFbmNyeXB0aW9uIjoiU3NsIiwiSXNDcm93ZHNvdXJjZWQiOm51bGwsIkZlZWRiYWNrcyI6bnVsbCwiSW5zZWN1cmUiOm51bGwsIlNlY3VyZSI6IlRydWUiLCJVc2VybmFtZSI6IntlbWFpbH0iLCJWYWxpZGF0ZWQiOmZhbHNlLCJBdXRvZGlzY292ZXIiOm51bGwsIkFhZCI6bnVsbH0seyJwcm90b2NvbCI6ImltYXAiLCJEb21haW4iOm51bGwsIkhvc3RuYW1lIjoiaW1hcGdtcy5qbmV0LnNlaS5jby5qcCIsIlBvcnQiOjk5MywiRW5jcnlwdGlvbiI6IlNzbCIsIklzQ3Jvd2Rzb3VyY2VkIjpudWxsLCJGZWVkYmFja3MiOm51bGwsIkluc2VjdXJlIjpudWxsLCJTZWN1cmUiOiJUcnVlIiwiVXNlcm5hbWUiOiJ7ZW1haWx9IiwiVmFsaWRhdGVkIjpmYWxzZSwiQXV0b2Rpc2NvdmVyIjpudWxsLCJBYWQiOm51bGx9XSwiQ3JlYXRlZEF0IjoiMjAyMC0wMi0wM1QwNTozMToyMy4yOTgwMjQ4IiwiVXBkYXRlZEF0IjoiMjAyMC0wMi0wM1QwOToxMjo1OS4wMjQ1ODciLCJQcmVkaWNhdGVzIjpudWxsLCJBdXRvRHYyRW5kcG9pbnQiOm51bGwsIkNvbW1lbnQiOm51bGwsIkZlZWRiYWNrcyI6bnVsbCwiSXNDcm93ZHNvdXJjZWQiOmZhbHNlfSwiZG9tYWluIjp7ImZpeGVkIjpmYWxzZSwiYXV0b0R2MkVuZHBvaW50IjpudWxsLCJwcm92aWRlcklkIjoic2VlYXRlc3QiLCJwcm90b2NvbHMiOm51bGx9fX0= &amp;lt; x-autodv2-error: ENOTFOUND &amp;lt; x-feedback-token: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJEIjoiZXhhbXBsZS5jb20iLCJQSSI6InNlZWF0ZXN0IiwiUyI6W10sIlAiOlsiaW1hcHM6Ly9pbWFwZ21zLmpuZXQuc2VpLmNvLmpwOjk5MyIsInNtdHBzOi8vc210cGdtcy5qbmV0LnNlaS5jby5qcDo0NjUiXSwiUFQiOiJpbWFwIHNtdHAiLCJleHAiOjE3NjUyMzMxNzgsImlhdCI6MTc2NTIyOTU3OH0.-ohD7c9hytRZK_b4EJ0M5Tke7hl8u1wjsMYRV71GZik &amp;lt; x-dns-prefetch-control: off &amp;lt; x-frame-options: SAMEORIGIN &amp;lt; x-download-options: noopen &amp;lt; x-content-type-options: nosniff &amp;lt; x-xss-protection: 1; mode=block &amp;lt; x-instance-id: autodetect-deployment-76fffc487d-wfs4b &amp;lt; x-response-time: 3472 ms &amp;lt; x-request-id: f1b6525f-6d11-4add-a0e4-0b677d89f9eb &amp;lt; x-autodetect-cv: f1b6525f-6d11-4add-a0e4-0b677d89f9eb &amp;lt; * Connection #0 to host prod.autodetect.outlook.cloud.microsoft left intact {"email":"email@example.com","services":[],"protocols":[{"protocol":"imap","hostname":"imapgms.jnet.sei.co.jp","port":993,"encryption":"ssl","username":"email@example.com","validated":false},{"protocol":"smtp","hostname":"smtpgms.jnet.sei.co.jp","port":465,"encryption":"ssl","username":"email@example.com","validated":false}]}%&lt;/quote&gt;
    &lt;p&gt;The JSON response:&lt;/p&gt;
    &lt;quote&gt;{ "email": "email@example.com", "services": [], "protocols": [ { "protocol": "imap", "hostname": "imapgms.jnet.sei.co.jp", "port": 993, "encryption": "ssl", "username": "email@example.com", "validated": false }, { "protocol": "smtp", "hostname": "smtpgms.jnet.sei.co.jp", "port": 465, "encryption": "ssl", "username": "email@example.com", "validated": false } ] }&lt;/quote&gt;
    &lt;head rend="h3"&gt;Decoded debug header&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;x-debug-support&lt;/code&gt; header (Base64-decoded) reveals additional details:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Field&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Provider ID&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;seeatest&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Created&lt;/cell&gt;
        &lt;cell&gt;2020-02-03 05:31:23 UTC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Updated&lt;/cell&gt;
        &lt;cell&gt;2020-02-03 09:12:59 UTC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;IsCrowdsourced&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This misconfiguration has existed for nearly six years and was not crowdsourced. It appears to have been manually added to Microsoft's database.&lt;/p&gt;
    &lt;head rend="h2"&gt;Related&lt;/head&gt;
    &lt;p&gt;❧ 2026-01-01&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tinyapps.org/blog/microsoft-mishandling-example-com.html"/><published>2026-01-23T13:04:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46732213</id><title>Radicle: The Sovereign Forge</title><updated>2026-01-23T15:45:46.476525+00:00</updated><content>&lt;doc fingerprint="a0671596b436ca2c"&gt;
  &lt;main&gt;
    &lt;p&gt;Radicle is a sovereign {code forge} built on Git.&lt;/p&gt;
    &lt;head rend="h1"&gt;Synopsis&lt;/head&gt;
    &lt;p&gt;Radicle is an open source, peer-to-peer code collaboration stack built on Git. Unlike centralized code hosting platforms, there is no single entity controlling the network. Repositories are replicated across peers in a decentralized manner, and users are in full control of their data and workflow.&lt;/p&gt;
    &lt;p&gt; The Radicle &lt;code&gt;heartwood&lt;/code&gt; repository. Repository ID
  &lt;code&gt;rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h1"&gt;Get started&lt;/head&gt;
    &lt;quote&gt;ð¾ ·&lt;/quote&gt;
    &lt;p&gt;To install Radicle, simply run the command below from your shell, or go to the download page.&lt;/p&gt;
    &lt;code&gt;curl -sSLf https://radicle.xyz/install | sh&lt;/code&gt;
    &lt;p&gt;Alternatively, you can build from source.&lt;/p&gt;
    &lt;p&gt;For now, Radicle only works on Linux, macOS and BSD variants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Radicle Desktop ð¥ï¸&lt;/head&gt;
    &lt;p&gt;For a graphical collaborative experience check out the Radicle Desktop client, as well.&lt;/p&gt;
    &lt;head rend="h1"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The Radicle protocol leverages cryptographic identities for code and social artifacts, utilizes Git for efficient data transfer between peers, and employs a custom gossip protocol for exchanging repository metadata.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your Data, Forever and Secure&lt;/head&gt;
    &lt;p&gt;All social artifacts are stored in Git, and signed using public-key cryptography. Radicle verifies the authenticity and authorship of all data for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unparalleled Autonomy&lt;/head&gt;
    &lt;p&gt;Radicle enables users to run their own nodes, ensuring censorship-resistant code collaboration and fostering a resilient network without reliance on third-parties.&lt;/p&gt;
    &lt;head rend="h2"&gt;Local-first&lt;/head&gt;
    &lt;p&gt;Radicle is local-first, providing always-available functionality even without internet access. Users own their data, making migration, backup, and access easy both online and offline.&lt;/p&gt;
    &lt;head rend="h2"&gt;Evolvable &amp;amp; Extensible&lt;/head&gt;
    &lt;p&gt;Radicleâs Collaborative Objects (COBs) provide Radicleâs social primitive. This enables features such as issues, discussions and code review to be implemented as Git objects. Developers can extend Radicleâs capabilities to build any kind of collaboration flow they see fit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular by Design&lt;/head&gt;
    &lt;p&gt;The Radicle Stack comes with a CLI, web interface and TUI, that are backed by the Radicle Node and HTTP Daemon. Itâs modular, so any part can be swapped out and other clients can be developed.&lt;/p&gt;
    &lt;quote&gt;âââââââââââââââââââââââââââââââââââââ â Radicle CLI ââ Radicle Web â âââââââââââââââââââââââââââââââââââââ âââââââââââââââââââââââââââââââââââââ â Radicle Repository â â ââââââââââ ââââââââââ âââââââââââ â â â code â â issues â â patches â â â ââââââââââ ââââââââââ âââââââââââ â âââââââââââââââââââââââââââââââââââââ¤ â Radicle Storage (Git) â âââââââââââââââââââââââââââââââââââââ âââââââââââââââââââââââââââââââââââââ â Radicle Node ââ Radicle HTTPD â ââââââââââââââââââ¤âââââââââââââââââââ¤ â NoiseXK ââ HTTP + JSON â âââââââââââââââââââââââââââââââââââââ&lt;/quote&gt;
    &lt;head rend="h1"&gt;Contributing&lt;/head&gt;
    &lt;p&gt;Radicle is free and open source software under the MIT and Apache 2.0 licenses. Get involved by contributing code.&lt;/p&gt;
    &lt;head rend="h1"&gt;Updates&lt;/head&gt;
    &lt;p&gt;Follow us on ð Mastodon, ð¦ Bluesky or ð¦ Twitter to stay updated, join our community on ð¬ Zulip, or Subscribe&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14.01.2026 Radicle 1.6.0 released. â¨&lt;/item&gt;
      &lt;item&gt;30.09.2025 Radicle 1.5.0 released.&lt;/item&gt;
      &lt;item&gt;04.09.2025 Radicle 1.4.0 released.&lt;/item&gt;
      &lt;item&gt;12.08.2025 Radicle 1.3.0 released.&lt;/item&gt;
      &lt;item&gt;17.07.2025 Radicle 1.2.1 released.&lt;/item&gt;
      &lt;item&gt;13.06.2025 Radicle Desktop is out. ð¥ï¸&lt;/item&gt;
      &lt;item&gt;02.06.2025 Radicle 1.2.0 released.&lt;/item&gt;
      &lt;item&gt;05.12.2024 Radicle 1.1.0 released.&lt;/item&gt;
      &lt;item&gt;10.09.2024 Radicle 1.0.0 released.&lt;/item&gt;
      &lt;item&gt;26.03.2024 Radicle 1.0.0-rc.1 released.&lt;/item&gt;
      &lt;item&gt;10.03.2024 New Radicle homepage.&lt;/item&gt;
      &lt;item&gt;05.03.2024 Radicle Guides launch.&lt;/item&gt;
      &lt;item&gt;05.03.2024 Radicle makes it to the top of Hacker News!&lt;/item&gt;
      &lt;item&gt;18.04.2023 Radicle heartwood is announced.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Blog&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14.08.2025 Jujutsu + Radicle = â¤ï¸&lt;/item&gt;
      &lt;item&gt;12.08.2025 Canonical References&lt;/item&gt;
      &lt;item&gt;23.07.2025 Using Radicle CI for Development&lt;/item&gt;
      &lt;item&gt;30.05.2025 How we used Radicle with GitHub Actions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;If you have feedback, join our Zulip or send us an email at feedback@radicle.xyz. Emails sent to this address are automatically posted to our #feedback channel on Zulip.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://radicle.xyz"/><published>2026-01-23T13:25:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46733009</id><title>Tesla fined for repeatedly failing to help UK police over driving offences</title><updated>2026-01-23T15:45:46.333753+00:00</updated><content>&lt;doc fingerprint="c3751c3dbd8f7bce"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Tesla fined for repeatedly failing to help UK police over driving offences&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tesla has been convicted at least 18 times and ordered to pay more than Â£20,000 for repeatedly failing to co-operate with UK police forces.&lt;/p&gt;
    &lt;p&gt;The British arm of Elon Musk's electric car giant has faced multiple criminal court proceedings over the past two years linked to alleged road traffic offences.&lt;/p&gt;
    &lt;p&gt;Tesla offers its vehicles on long-term leases, and in such a scenario the leasing company is typically the registered keeper of the car.&lt;/p&gt;
    &lt;p&gt;Drivers of rented or company cars caught speeding have to be named before they can face prosecution and companies which fail to return paperwork to police can be prosecuted instead.&lt;/p&gt;
    &lt;p&gt;Almost 4,000 defendants have been convicted in courts in England and Wales in the last two weeks for failing to identify the driver of a vehicle under police investigation, leading to fines ranging from Â£1 to Â£1,000.&lt;/p&gt;
    &lt;p&gt;In one incident, South Wales Police wrote to Tesla Financial Services in a bid to identify the driver of a Tesla which had been speeding at 80mph (128km/h) on the M4 near Llantrisant, Rhondda Cynon Taf, in July 2025.&lt;/p&gt;
    &lt;p&gt;Court papers show a Tesla company director, Becky Hodgson, pleaded guilty for the firm by email in late November, saying it had tried to enter the plea online but "encountered a technical issue on the Online Plea Service portal".&lt;/p&gt;
    &lt;p&gt;Although the company admitted the criminal charge, Hodgson suggested in her email that it had complied with the police request, adding that its internal processes were followed and the nomination was sent via post.&lt;/p&gt;
    &lt;p&gt;A conviction was handed out at Merthyr Tydfil Magistrates' Court on 6 January and ended in Tesla receiving a Â£1,000 fine, an order for Â£120 costs and a Â£400 victim surcharge.&lt;/p&gt;
    &lt;p&gt;At least 18 convictions recorded against Tesla Financial Services have been identified by the Press Association since the start of 2024, including prosecutions brought by the Metropolitan Police, Hampshire Constabulary and Thames Valley Police.&lt;/p&gt;
    &lt;p&gt;Seventeen cases have already been sentenced, while Tesla Financial Services pleaded guilty last week to failing to identify a driver. That case is set to be sentenced at a later date at Bath Magistrates' Court.&lt;/p&gt;
    &lt;p&gt;In one of the concluded cases, a Tesla driver was caught on a speed camera doing almost 100mph (160km/h) on the A3 in Petersfield in Hampshire.&lt;/p&gt;
    &lt;p&gt;But due to police letters going unanswered, the speeding driver was not identified and the company received a conviction with a fine instead.&lt;/p&gt;
    &lt;p&gt;Another Tesla driver was caught speeding three times, potentially putting them on the cusp of a disqualification - if they had been identified.&lt;/p&gt;
    &lt;p&gt;Letters from police which went unanswered have been addressed to Tesla Financial Services at offices and a service centre in London, as well as an office in Manchester.&lt;/p&gt;
    &lt;p&gt;In the cases identified, fines, costs and court fees totalling Â£20,686 have been imposed by magistrates sitting in the single justice procedure, which deals with minor offences.&lt;/p&gt;
    &lt;p&gt;Tesla have been asked to comment.&lt;/p&gt;
    &lt;p&gt;South Wales Police have been asked to comment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Related topics&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published16 hours ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published1 day ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published1 day ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.co.uk/news/articles/c0r44zpprg7o"/><published>2026-01-23T14:38:14+00:00</published></entry></feed>