<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-08T21:11:33.610296+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46540498</id><title>The Jeff Dean Facts</title><updated>2026-01-08T21:11:41.773833+00:00</updated><content>&lt;doc fingerprint="2f40dcb1cd7a06c7"&gt;
  &lt;main&gt;
    &lt;p&gt;The "Jeff Dean facts" are a set of jokes that revolve around the extraordinary programming prowess of their titular Google employee. Simply put, they are the coding equivalent of Chuck Norris-style jokes (for example, "Chuck Norris can slam a revolving door").&lt;/p&gt;
    &lt;p&gt;I first encountered the Facts on a random Quora page, though as of recently many of them appear to have been removed. Thus, in order to preserve this invaluable cache of programmer humor for posterity, I decided to create this repository. It is a combined list of various versions of the Facts, beginning with a text file that I copied from the Quora post sometime in 2019, when the original answer still existed. It's been expanded from other sources, which are listed (and linked, if possible) at the end of this document.&lt;/p&gt;
    &lt;p&gt;And now, without further ado...&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Jeff Dean proved that P=NP when he solved all NP problems in polynomial time on a whiteboard.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's PIN is the last 4 digits of pi.&lt;/item&gt;
      &lt;item&gt;When Jeff gives a seminar at Stanford, it's so crowded Don Knuth has to sit on the floor. (TRUE)&lt;/item&gt;
      &lt;item&gt;Jeff Dean once bit a spider, the spider got super powers and C++ readability.&lt;/item&gt;
      &lt;item&gt;Once, in early 2002, when the index servers went down, Jeff Dean answered user queries manually for two hours. Evals showed a quality improvement of 5 points.&lt;/item&gt;
      &lt;item&gt;Jeff Dean got promoted to level 11 in a system where max level is 10. (TRUE)&lt;/item&gt;
      &lt;item&gt;Google Search was Jeff Dean's Noogler Project.&lt;/item&gt;
      &lt;item&gt;Jeff Dean has punch card readability.&lt;/item&gt;
      &lt;item&gt;Jeff Dean puts his pants on one leg at a time, but if he had more than two legs, you would see that his approach is actually &lt;code&gt;O(log n)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Jeff Dean acquired Sawzall readability after writing 58 lines of Sawzall code. As part of his readability review, he pointed out a flaw in the style guide which was promptly corrected by the reviewer.&lt;/item&gt;
      &lt;item&gt;Sanjay once asked Jeff Dean if he could keep the entire web in his memory. Due to the noise from his keyboard cooling fan, Jeff Dean misheard slightly and wrote Mustang instead of simply answering "Yes".&lt;/item&gt;
      &lt;item&gt;Jeff Dean compiles and runs his code before submitting, but only to check for compiler and CPU bugs.&lt;/item&gt;
      &lt;item&gt;Unsatisfied with constant time, Jeff Dean created the world's first &lt;code&gt;O(1/n)&lt;/code&gt;algorithm.&lt;/item&gt;
      &lt;item&gt;Jeff Dean has binary readability.&lt;/item&gt;
      &lt;item&gt;Jeff Dean has binary writability.&lt;/item&gt;
      &lt;item&gt;When Jeff Dean goes on vacation, production services across Google mysteriously stop working within a few days. This is actually true.1&lt;/item&gt;
      &lt;item&gt;Jeff Dean once shifted a bit so hard it ended up on another computer.&lt;/item&gt;
      &lt;item&gt;During his own Google interview, Jeff Dean was asked the implications if P=NP were true. He said "P = 0 or N = 1." Then, before the interviewer had even finished laughing, Jeff examined Google's public certificate and wrote the private key on the whiteboard.&lt;/item&gt;
      &lt;item&gt;You use 10% of your brain. The other 90% is running one of Jeff's mapreduce jobs.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's resume lists the things he hasn't done; it's shorter that way.&lt;/item&gt;
      &lt;item&gt;To Jeff Dean, "NP" means "No Problemo".&lt;/item&gt;
      &lt;item&gt;Jeff Dean wrote an &lt;code&gt;O(n^2)&lt;/code&gt;algorithm once. It was for the Traveling Salesman Problem.&lt;/item&gt;
      &lt;item&gt;You don't explain your work to Jeff Dean. Jeff Dean explains your work to you.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's resume has so many accomplishments, it has a table of contents.&lt;/item&gt;
      &lt;item&gt;Jeff Dean was forced to invent asynchronous APIs one day when he optimized a function so that it returned before it was invoked.&lt;/item&gt;
      &lt;item&gt;The rate at which Jeff Dean produces code jumped by a factor of 40 in late 2000 when he upgraded his keyboard to USB2.0.&lt;/item&gt;
      &lt;item&gt;When Jeff Dean designs software, he first codes the binary and then writes the source as documentation.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's Peer Review is what got Larry promoted to CEO.&lt;/item&gt;
      &lt;item&gt;When God said: "Let there be light!", Jeff Dean was there to do the code review.&lt;/item&gt;
      &lt;item&gt;When Graham Bell invented the telephone, he saw a missed call from Jeff Dean&lt;/item&gt;
      &lt;item&gt;Compilers don't warn Jeff Dean. Jeff Dean warns compilers.&lt;/item&gt;
      &lt;item&gt;Jeff Dean doesn't exist, he's actually an advanced AI created by Jeff Dean.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's IDE doesn't do code analysis, it does code appreciation.&lt;/item&gt;
      &lt;item&gt;Jeff Dean doesn't use ECC memory. He anticipates cosmic rays and uses them to improve performance.&lt;/item&gt;
      &lt;item&gt;Jeff Dean once failed a Turing test when he correctly identified the 203rd Fibonacci number in less than a second.&lt;/item&gt;
      &lt;item&gt;Jeff Dean invented Bigtable so that he would have a place to send his weekly snippets.&lt;/item&gt;
      &lt;item&gt;On the zeroth day, Jeff Dean created God.&lt;/item&gt;
      &lt;item&gt;Jeff Dean once implemented a web server in a single printf() call. Other engineers added thousands of lines of explanatory comments but still don't understand exactly how it works. Today that program is known as Google Web Server.&lt;/item&gt;
      &lt;item&gt;When Jeff has an ergonomic evaluation, it is for the protection of his keyboard.&lt;/item&gt;
      &lt;item&gt;Jeff Dean can beat you at connect four. In three moves.&lt;/item&gt;
      &lt;item&gt;Jeff Dean invented BigTable because his resume was too big to fit anywhere else.&lt;/item&gt;
      &lt;item&gt;Jeff Dean took the bite out of Apple's logo.&lt;/item&gt;
      &lt;item&gt;Chuck Norris can kill you. Jeff Dean can &lt;code&gt;kill -9&lt;/code&gt;you.&lt;/item&gt;
      &lt;item&gt;Jeff Dean can parse HTML with a regular expression...correctly.&lt;/item&gt;
      &lt;item&gt;When Jeff has trouble sleeping, he MapReduces sheep.&lt;/item&gt;
      &lt;item&gt;When Jeff Dean fires up the profiler, loops unroll themselves in fear.&lt;/item&gt;
      &lt;item&gt;When your code has undefined behavior, you get a seg fault and corrupted data. When Jeff Dean's code has undefined behavior, a unicorn rides in on a rainbow and gives everybody free ice cream.&lt;/item&gt;
      &lt;item&gt;Jeff doesn't sleep, he just sends SIGSUSPEND to the universe.&lt;/item&gt;
      &lt;item&gt;Jeff got Java readability with only 8 lines of code.&lt;/item&gt;
      &lt;item&gt;Jeff Dean can instantiate abstract classes.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;gcc -O4&lt;/code&gt;sends your code to Jeff Dean for a complete rewrite.&lt;/item&gt;
      &lt;item&gt;Jeff can recite 20,000 digits of pi in 5 hours. He doesn't remember them; he just recomputes them on the fly using only &lt;code&gt;O(log n)&lt;/code&gt;space.&lt;/item&gt;
      &lt;item&gt;Jeff Dean remembers only one password. For each site, he concatenates it with the site name, computes its SHA-256 hash, and then types the result.&lt;/item&gt;
      &lt;item&gt;Jeff Dean is still waiting for mathematicians to discover the joke he hid in the digits of pi.&lt;/item&gt;
      &lt;item&gt;There is no &lt;code&gt;Ctrl&lt;/code&gt;key on Jeff Dean's keyboard. Jeff Dean is always in control.&lt;/item&gt;
      &lt;item&gt;Jeff Dean was born on December 31, 1969 at 11:48 PM. It took him twelve minutes to implement his first time counter.&lt;/item&gt;
      &lt;item&gt;When Jeff Dean says "Hello World", the world says "Hello Jeff".&lt;/item&gt;
      &lt;item&gt;Jeff Dean can get 1s out of &lt;code&gt;/dev/zero&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Jeff Dean simply walks into Mordor.&lt;/item&gt;
      &lt;item&gt;Jeff Dean spent some 20% time on an AI project. That produced Urs Hoelzle.&lt;/item&gt;
      &lt;item&gt;Google once had to move out of a datacenter after Jeff Dean accidentally compressed the index so densely that a black hole was formed.&lt;/item&gt;
      &lt;item&gt;Jeff starts his programming sessions with &lt;code&gt;cat &amp;gt; /dev/mem&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The speed of light in a vacuum used to be about 35 mph. Then Jeff Dean spent a weekend optimizing physics.&lt;/item&gt;
      &lt;item&gt;When Jeff Dean sends you a code review, it's because he thinks there's something in it you should learn.&lt;/item&gt;
      &lt;item&gt;Jeff Dean does not &lt;code&gt;sleep()&lt;/code&gt;, he&lt;code&gt;wait()&lt;/code&gt;s.&lt;/item&gt;
      &lt;item&gt;Jeff Dean invented MapReduce so he could sort his fan mail.&lt;/item&gt;
      &lt;item&gt;Once Jeff Dean ordered a list, and the list obeyed him.&lt;/item&gt;
      &lt;item&gt;Chuck Norris is Jeff Dean's 20% project.&lt;/item&gt;
      &lt;item&gt;When your code is killed by SIGJEFF, it never runs again.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's calendar goes straight from March 31st to April 2nd; no one fools Jeff Dean.&lt;/item&gt;
      &lt;item&gt;Jeff Dean never has the wrong number; you have the wrong phone.&lt;/item&gt;
      &lt;item&gt;Jeff Dean has exactly two keys on his keyboard: &lt;code&gt;0&lt;/code&gt;and&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Errors treat Jeff Dean as a warning.&lt;/item&gt;
      &lt;item&gt;Cricket matches used to take 5 days, until Jeff optimized them.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's watch displays seconds since January 1st, 1970. He is never late.&lt;/item&gt;
      &lt;item&gt;Jeff's code is so fast the assembly code needs three HALT opcodes to stop it.&lt;/item&gt;
      &lt;item&gt;Emacs' preferred editor is Jeff Dean.&lt;/item&gt;
      &lt;item&gt;Google: it's basically a Jeff Dean's side project.&lt;/item&gt;
      &lt;item&gt;Jeff Dean has to unoptimize his code so that reviewers believe it was written by a human.&lt;/item&gt;
      &lt;item&gt;Websearch is just a large unittest Jeff wrote for his real app.&lt;/item&gt;
      &lt;item&gt;Jeff Dean doesn't need speakers or headphones. He just types &lt;code&gt;cat *.mp3&lt;/code&gt;, glances at the screen, and his brain decodes the music in the background while he works.&lt;/item&gt;
      &lt;item&gt;Jeff Dean has Perl Readability. (TRUE)&lt;/item&gt;
      &lt;item&gt;Jeff Dean quicksorts his laundry.&lt;/item&gt;
      &lt;item&gt;The OR ELSE construct had to be removed from ISO C after Jeff Dean used it in Mustang and kernels started panicking in terror.&lt;/item&gt;
      &lt;item&gt;Jeff Dean is not afraid of evil constructors. They are afraid of him.&lt;/item&gt;
      &lt;item&gt;Jeff Dean doesn't write bugs, just features you are unable to understand.&lt;/item&gt;
      &lt;item&gt;Jeff Dean eschews both Emacs and VI. He types his code into &lt;code&gt;zcat&lt;/code&gt;, because it's faster that way.&lt;/item&gt;
      &lt;item&gt;When Jeff Dean sends an Ethernet frame, there are no collisions because the competing frames retreat back up into the buffer memory on their source network cards.&lt;/item&gt;
      &lt;item&gt;Jeff once simultaneously reduced all binary sizes by 3% and raised the severity of a previously known low-priority Python bug to critical-priority in a single change that contained no Python code.&lt;/item&gt;
      &lt;item&gt;One day, Jeff Dean grabbed his Etch-a-Sketch instead of his laptop on his way out the door. On his way back home to get his real laptop, he programmed the Etch-a-Sketch to play Tetris.&lt;/item&gt;
      &lt;item&gt;The x86-64 spec includes several undocumented instructions marked private use. They are actually for Jeff Dean's use.&lt;/item&gt;
      &lt;item&gt;Knuth mailed a copy of The Art of Computer Programming to Google. Jeff Dean autographed it and mailed it back.&lt;/item&gt;
      &lt;item&gt;When he heard that Jeff Dean's autobiography would be exclusive to the platform, Richard Stallman bought a Kindle.&lt;/item&gt;
      &lt;item&gt;Jeff Dean can losslessly compress random data.&lt;/item&gt;
      &lt;item&gt;When asked if the facts about him are true, Jeff Dean responded with "111111". While the interviewer was still trying to figure out what he meant, he clarified, "every single bit of it is true."&lt;/item&gt;
      &lt;item&gt;Jeff Dean mines bitcoins. In his head.&lt;/item&gt;
      &lt;item&gt;Jeff Dean traps the KILL signal.&lt;/item&gt;
      &lt;item&gt;Jeff Dean's programs don't SEGFAULT. The memory rearranges itself in order to put data and code where it belongs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This list was compiled from several sources, with duplicate (or near-duplicate) Facts removed. The relevant sources are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Quora - the original question seems to still exist, at https://www.quora.com/What-are-all-the-Jeff-Dean-facts, but the exact response I downloaded all those years ago is nowhere to be found.&lt;/item&gt;
      &lt;item&gt;infO(N), a Bulgarian website that appears to provide schedules and results for coding competitions (post)&lt;/item&gt;
      &lt;item&gt;A now-deleted Google+ thread, quoted by a Reddit user&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It's not clear whether this fact is really true, or whether this line is simply part of the joke, so I've omitted the usual &lt;code&gt;(TRUE)&lt;/code&gt;identifier here. Interpret this as you see fit :)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/LRitzdorf/TheJeffDeanFacts"/><published>2026-01-08T13:02:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46540660</id><title>Show HN: DeepDream for Video with Temporal Consistency</title><updated>2026-01-08T21:11:41.063796+00:00</updated><content>&lt;doc fingerprint="3f194f592fcd7ab8"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a fork of neural-dream, a PyTorch implementation of DeepDream. This fork introduces optical flow estimation and occlusion masking to apply DeepDream to videos with temporal consistency.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Standard DeepDream: The original single-image implementation.&lt;/item&gt;
      &lt;item&gt;Video DeepDream: New CLI (&lt;code&gt;video_dream.py&lt;/code&gt;) that uses RAFT Optical Flow to warp previous dream frames into the current frame, ensuring smooth transitions and object tracking.&lt;/item&gt;
      &lt;item&gt;Occlusion Masking: Automatically detects when objects move in front of one another to prevent "ghosting" artifacts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="px-3 py-2"&gt;mallard_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;highway_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;mallard_independent_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;highway_independent_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;mallard.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;highway.mp4&lt;/head&gt;
    &lt;p&gt;This project requires the following key packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PyTorch&lt;/item&gt;
      &lt;item&gt;torchvision&lt;/item&gt;
      &lt;item&gt;OpenCV&lt;/item&gt;
      &lt;item&gt;NumPy&lt;/item&gt;
      &lt;item&gt;Pillow&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install Dependencies:&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;
    &lt;p&gt;Download Models: Run the download script to fetch the standard Inception/GoogLeNet models:&lt;/p&gt;
    &lt;code&gt;python models/download_models.py&lt;/code&gt;
    &lt;p&gt;To download all compatible models:&lt;/p&gt;
    &lt;code&gt;python models/download_models.py -models all-caffe-googlenet&lt;/code&gt;
    &lt;p&gt;To dream on a video, use the &lt;code&gt;video_dream.py&lt;/code&gt; script. This wrapper accepts specific video arguments and any argument accepted by the standard image dreamer (e.g., layers, octaves, iterations).&lt;/p&gt;
    &lt;p&gt;Basic Video Command:&lt;/p&gt;
    &lt;code&gt;python video_dream.py -content_video input.mp4 -output_video output.mp4 -num_iterations 1&lt;/code&gt;
    &lt;p&gt;Note: For video processing, we recommend using &lt;code&gt;-num_iterations 1&lt;/code&gt;. The temporal consistency from optical flow means each frame builds on the previous dream, so fewer iterations per frame are needed compared to single images.&lt;/p&gt;
    &lt;p&gt;Video-Specific Arguments:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Argument&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-content_video&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;input.mp4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to the source video file.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-output_video&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;output.mp4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path where the final video will be saved.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-blend&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;(0.0 - 1.0): Mix ratio between the raw video frame and the warped previous dream. Higher values (closer to 1.0) use more of the raw frame; lower values (closer to 0.0) preserve more of the previous hallucinations.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-independent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;False&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Flag: If set, disables temporal consistency (Optical Flow). Every frame is dreamed on independently (causes flickering).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-update_interval&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Updates the output video file on disk every N frames (allows you to preview progress while running).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-temp_dir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;temp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Directory to store extracted frames, flow data, and masks during processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-keep_temp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;False&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Flag: If set, the temporary directory is not deleted after processing finishes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;-verbose&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;False&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Flag: Enable detailed logs (prints DeepDream iteration logs for every frame).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All of the following arguments are from the single frame implementation, and you can mix and match any of these with the video-specific arguments above. Refer to neural-dream for more information on single frame parameters.&lt;/p&gt;
    &lt;p&gt;Example combining video and standard args:&lt;/p&gt;
    &lt;code&gt;python video_dream.py -content_video test.mp4 -dream_layers inception_4d -num_iterations 1 -octave_scale 0.7 -image_size 512&lt;/code&gt;
    &lt;p&gt;For single image processing only:&lt;/p&gt;
    &lt;code&gt;python neural_dream.py -content_image &amp;lt;image.jpg&amp;gt; -dream_layers inception_4c -num_iterations 10&lt;/code&gt;
    &lt;p&gt;Note: Paths to images should not contain the &lt;code&gt;~&lt;/code&gt; character; use relative or absolute paths.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-image_size&lt;/code&gt;: Maximum side length (in pixels) of the generated image. Default is 512.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-gpu&lt;/code&gt;: Zero-indexed ID of the GPU to use; for CPU mode set&lt;code&gt;-gpu&lt;/code&gt;to&lt;code&gt;c&lt;/code&gt;; for MPS mode (Apple Silicon) set&lt;code&gt;-gpu&lt;/code&gt;to&lt;code&gt;mps&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-dream_weight&lt;/code&gt;: How much to weight DeepDream. Default is&lt;code&gt;1e3&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-tv_weight&lt;/code&gt;: Weight of total-variation (TV) regularization; helps smooth the image. Default&lt;code&gt;0&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-l2_weight&lt;/code&gt;: Weight of latent state regularization. Default&lt;code&gt;0&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-num_iterations&lt;/code&gt;: Number of iterations. Default is&lt;code&gt;10&lt;/code&gt;. For video, use&lt;code&gt;1&lt;/code&gt;(temporal consistency reduces the need for multiple iterations per frame).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-init&lt;/code&gt;: Initialization method:&lt;code&gt;image&lt;/code&gt;(content image) or&lt;code&gt;random&lt;/code&gt;(noise). Default&lt;code&gt;image&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-jitter&lt;/code&gt;: Apply jitter to image. Default&lt;code&gt;32&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-layer_sigma&lt;/code&gt;: Apply gaussian blur to image. Default&lt;code&gt;0&lt;/code&gt;(disabled).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-optimizer&lt;/code&gt;:&lt;code&gt;lbfgs&lt;/code&gt;or&lt;code&gt;adam&lt;/code&gt;. Default&lt;code&gt;adam&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-learning_rate&lt;/code&gt;: Learning rate (step size). Default&lt;code&gt;1.5&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-normalize_weights&lt;/code&gt;: Divide dream weights by the number of channels.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-loss_mode&lt;/code&gt;: Loss mode:&lt;code&gt;bce&lt;/code&gt;,&lt;code&gt;mse&lt;/code&gt;,&lt;code&gt;mean&lt;/code&gt;,&lt;code&gt;norm&lt;/code&gt;, or&lt;code&gt;l2&lt;/code&gt;. Default&lt;code&gt;l2&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-output_image&lt;/code&gt;: Name of the output image. Default&lt;code&gt;out.png&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-output_start_num&lt;/code&gt;: Number to start output image names at. Default&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-print_iter&lt;/code&gt;: Print progress every N iterations.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-save_iter&lt;/code&gt;: Save image every N iterations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-dream_layers&lt;/code&gt;: Comma-separated list of layer names to use.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-channels&lt;/code&gt;: Comma-separated list of channels to use.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-channel_mode&lt;/code&gt;: Selection mode:&lt;code&gt;all&lt;/code&gt;,&lt;code&gt;strong&lt;/code&gt;,&lt;code&gt;avg&lt;/code&gt;,&lt;code&gt;weak&lt;/code&gt;, or&lt;code&gt;ignore&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-channel_capture&lt;/code&gt;:&lt;code&gt;once&lt;/code&gt;or&lt;code&gt;octave_iter&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-num_octaves&lt;/code&gt;: Number of octaves per iteration. Default&lt;code&gt;4&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-octave_scale&lt;/code&gt;: Resize value. Default&lt;code&gt;0.6&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-octave_iter&lt;/code&gt;: Iterations (steps) per octave. Default&lt;code&gt;50&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-octave_mode&lt;/code&gt;:&lt;code&gt;normal&lt;/code&gt;,&lt;code&gt;advanced&lt;/code&gt;,&lt;code&gt;manual_max&lt;/code&gt;,&lt;code&gt;manual_min&lt;/code&gt;, or&lt;code&gt;manual&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-lap_scale&lt;/code&gt;: Number of layers in laplacian pyramid. Default&lt;code&gt;0&lt;/code&gt;(disabled).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-sigma&lt;/code&gt;: Strength of gaussian blur in pyramids. Default&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-zoom&lt;/code&gt;: Amount to zoom in.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-zoom_mode&lt;/code&gt;:&lt;code&gt;percentage&lt;/code&gt;or&lt;code&gt;pixel&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-tile_size&lt;/code&gt;: Desired tile size. Default&lt;code&gt;0&lt;/code&gt;(disabled).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-overlap_percent&lt;/code&gt;: Percentage of overlap for tiles. Default&lt;code&gt;50&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-original_colors&lt;/code&gt;: Set to&lt;code&gt;1&lt;/code&gt;to keep content image colors.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-model_file&lt;/code&gt;: Path to&lt;code&gt;.pth&lt;/code&gt;file. Default is VGG-19.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-model_type&lt;/code&gt;:&lt;code&gt;caffe&lt;/code&gt;,&lt;code&gt;pytorch&lt;/code&gt;,&lt;code&gt;keras&lt;/code&gt;, or&lt;code&gt;auto&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-backend&lt;/code&gt;:&lt;code&gt;nn&lt;/code&gt;,&lt;code&gt;cudnn&lt;/code&gt;,&lt;code&gt;openmp&lt;/code&gt;, or&lt;code&gt;mkl&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-cudnn_autotune&lt;/code&gt;: Use built-in cuDNN autotuner (slower start, faster run).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Problem: The program runs out of memory (OOM) Solution:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Reduce &lt;code&gt;-image_size&lt;/code&gt;(e.g., to 512 or 256).&lt;/item&gt;
      &lt;item&gt;If using GPU, use &lt;code&gt;-backend cudnn&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;For video: Reduce the input video resolution before processing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Problem: Video processing is very slow Solution: Video DeepDreaming is computationally expensive. It runs the full DeepDream process per frame, plus Optical Flow calculations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use &lt;code&gt;-num_iterations 1&lt;/code&gt;(recommended for video; temporal consistency means fewer iterations are needed).&lt;/item&gt;
      &lt;item&gt;Reduce &lt;code&gt;-octave_iter&lt;/code&gt;(e.g., to 10 or 20).&lt;/item&gt;
      &lt;item&gt;Use a smaller &lt;code&gt;-image_size&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By default, &lt;code&gt;neural-dream&lt;/code&gt; uses the &lt;code&gt;nn&lt;/code&gt; backend.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use cuDNN: &lt;code&gt;-backend cudnn&lt;/code&gt;(GPU only, reduces memory).&lt;/item&gt;
      &lt;item&gt;Reduce Size: &lt;code&gt;-image_size 256&lt;/code&gt;(Halves memory usage).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With default settings, standard execution uses ~1.3 GB GPU memory.&lt;/p&gt;
    &lt;p&gt;You can use multiple devices with &lt;code&gt;-gpu&lt;/code&gt; and &lt;code&gt;-multidevice_strategy&lt;/code&gt;.
Example: &lt;code&gt;-gpu 0,1,2,3 -multidevice_strategy 3,6,12&lt;/code&gt; splits layers across 4 GPUs. See ProGamerGov/neural-dream for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jeremicna/deepdream-video-pytorch"/><published>2026-01-08T13:21:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46541586</id><title>Maine company in the spotlight after Maduro apparently wore one of their hoodies</title><updated>2026-01-08T21:11:40.855992+00:00</updated><content>&lt;doc fingerprint="26791b55a0c12eff"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Sign up for the Today newsletter&lt;/head&gt;&lt;p&gt;Get everything you need to know to start your day, delivered right to your inbox every morning.&lt;/p&gt;&lt;p&gt;By Abby Patkin&lt;/p&gt;&lt;p&gt;The CEO of a Maine apparel company said his phone “blew up” after deposed Venezuelan leader Nicolás Maduro was apparently photographed wearing one of their hoodies upon arriving in New York over the weekend.&lt;/p&gt;&lt;p&gt;The U.S. captured Maduro, Venezuela’s president, and his wife in a staggering nighttime military operation Saturday, charging the ousted leader with drug and weapons offenses. Before long, social media was flush with images that appeared to show Maduro wearing an ORIGIN hoodie in the shade “Patriot Blue,” surrounded by Drug Enforcement Administration agents.&lt;/p&gt;&lt;p&gt;In one photo, Maduro appears to be giving the camera a double thumbs up.&lt;/p&gt;&lt;p&gt;“I had to start putting the pieces together: Why is this dude wearing an Origin Patriot Blue hoodie?” Pete Roberts, the company’s founder and CEO, said in a video Sunday. “And the irony in this is that this wave, this logo here on the shirt Maduro is wearing, this is the ‘Wave of Freedom.’”&lt;/p&gt;&lt;p&gt;Farmington-based ORIGIN began as a way to help revitalize a struggling New England manufacturing community, he explained, and its “Wave of Freedom” logo represents a commitment to building back.&lt;/p&gt;&lt;p&gt;Roberts also offered his theory on how Maduro came to be wearing a hoodie made by a smaller brand from Maine.&lt;/p&gt;&lt;p&gt;“Probably a DEA agent slipped this hoodie on him and said, ‘You’re going to feel the fabric of freedom on American soil,’” he quipped. “That’s my assumption, and I’m taking the liberty to assume.”&lt;/p&gt;&lt;p&gt;Writing on Facebook, ORIGIN co-founder and retired Navy SEAL Jocko Willink further noted the brand has supporters “in every branch of service and every agency of the government.”&lt;/p&gt;&lt;p&gt;According to ORIGIN’s product description, the hoodie offers a “triple chill effect” to wick away moisture and cool athletes down — an element Roberts said he found “really curious and interesting,” given the chilly weather in New York.&lt;/p&gt;&lt;p&gt;“So maybe they wanted him to feel comfortable or a little uncomfortable. I’m not quite sure,” Roberts said. “But he definitely gave two thumbs up, so I think he liked the fabric.”&lt;/p&gt;&lt;p&gt;Still, he told News Center Maine ORIGIN isn’t looking to politicize the Maduro photo op and is “just trying to use it for brand awareness and to get people back into our store.”&lt;/p&gt;&lt;p&gt;The brand’s website traffic jumped about 300% Sunday, and sales were up roughly 200%, Roberts told the news outlet.&lt;/p&gt;&lt;p&gt;“It would be really hard for a company out of Maine to get, let’s call it, a billion eyes on our brand,” he said. “And so, that’s a real positive as a brand, as a movement. We would never have been able to create that.”&lt;/p&gt;&lt;p&gt;Abby Patkin is a general assignment news reporter whose work touches on public transit, crime, health, and everything in between.&lt;/p&gt;&lt;p&gt;Get everything you need to know to start your day, delivered right to your inbox every morning.&lt;/p&gt;&lt;p&gt;Be civil. Be kind.&lt;/p&gt;Read our full community guidelines.&lt;p&gt;Stay up to date with everything Boston. Receive the latest news and breaking updates, straight from our newsroom to your inbox.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.boston.com/news/business/2026/01/06/maine-company-maduro-venezuela-hoodie/"/><published>2026-01-08T14:44:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46541892</id><title>Bose is open-sourcing its old smart speakers instead of bricking them</title><updated>2026-01-08T21:11:40.571670+00:00</updated><content>&lt;doc fingerprint="f3583dfad3a2a07e"&gt;
  &lt;main&gt;
    &lt;p&gt;In a surprisingly user-friendly move, Bose has announced it will be open-sourcing the API documentation for its SoundTouch smart speakers, which were slated to lose official support on February 18th, as reported by Ars Technica. Bose has also moved that date back to May 6th, 2026.&lt;/p&gt;
    &lt;head rend="h1"&gt;Bose is open-sourcing its old smart speakers instead of bricking them&lt;/head&gt;
    &lt;p&gt;SoundTouch speakers could now have a second life and won’t lose support until May.&lt;/p&gt;
    &lt;p&gt;SoundTouch speakers could now have a second life and won’t lose support until May.&lt;/p&gt;
    &lt;p&gt;When cloud support ends, an update to the SoundTouch app will add local controls to retain as much functionality as possible without cloud services. Users will still be able to stream music to SoundTouch speakers with Bluetooth, AirPlay, and Spotify Connect (plus physical AUX connections). Remote control features and grouping speakers will also continue to work, and users will still be able to set up and configure their SoundTouch speakers.&lt;/p&gt;
    &lt;p&gt;Now that the smart speakers’ API is being open-sourced, users can also create their own compatible SoundTouch tools to help fill in any gaps left by the lack of cloud services. While it’s still disappointing that the speakers are losing official support, Bose’s approach at least lets people continue using their speakers, rather than bricking otherwise functional devices.&lt;/p&gt;
    &lt;p&gt;This move from Bose is particularly surprising because of how rare it is. Usually when products lose support for cloud services, they end up bricked, and occasionally users step in themselves to fix things. For instance, when Pebble originally shut down in 2016, users kept their watches functional by creating the Rebble Alliance, a community-run replacement for the watches’ cloud services, firmware, and app store.&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Popular&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;OpenAI launches ChatGPT Health, encouraging users to connect their medical records&lt;/item&gt;
      &lt;item&gt;Fujifilm’s new instant camera captures video with vintage effects&lt;/item&gt;
      &lt;item&gt;Dell admits consumers don’t care about AI PCs&lt;/item&gt;
      &lt;item&gt;Lego announces Smart Brick, the ‘most significant evolution’ in 50 years&lt;/item&gt;
      &lt;item&gt;Bose is open-sourcing its old smart speakers instead of bricking them&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/858501/bose-soundtouch-smart-speakers-open-source"/><published>2026-01-08T15:07:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46542683</id><title>Iran Goes Into IPv6 Blackout</title><updated>2026-01-08T21:11:40.447724+00:00</updated><content/><link href="https://radar.cloudflare.com/routing/ir"/><published>2026-01-08T16:11:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46542761</id><title>Digital Red Queen: Adversarial Program Evolution in Core War with LLMs</title><updated>2026-01-08T21:11:40.279449+00:00</updated><content>&lt;doc fingerprint="f60c1bd489a1219e"&gt;
  &lt;main&gt;&lt;p&gt;Survival of the Fittest Code. In the game Core War, assembly-like programs called “warriors” fight for control of a virtual computer. Warriors may employ sophisticated strategies including targeted self-replication, data bombing, and massive multithreading, in order to crash other programs, and dominate the machine. Top: We visualize battles between assembly programs (“warriors”) discovered by our Digital Red Queen (DRQ) algorithm. Each DRQ round introduces one additional warrior into the multi-agent simulation. Bottom: With more rounds, the LLM-driven evolution discovers increasingly robust strategies. By simulating these adversarial dynamics, we observe emergent behaviors that mirror biological evolution, where agents must constantly adapt simply to survive against ever-changing threats. Furthermore, as Core War is a Turing-complete environment where code and data share the same address space, this process leads to some very chaotic self-modifying code dynamics. &lt;/p&gt;&lt;head rend="h2"&gt;Summary&lt;/head&gt;&lt;p&gt;Core War is a competitive programming game introduced in 1984, in which battle programs called warriors fight for dominance inside a virtual computer. To compete, developers write their code in Redcode, a specialized assembly language. In this work, we explore what happens when large language models (LLMs) drive an adversarial evolutionary arms race in this domain, where programs continuously adapt to defeat a growing history of opponents rather than a static benchmark. We find that this dynamic adversarial process leads to the emergence of increasingly general strategies and reveals an intriguing form of convergent evolution, where different code implementations settle into similar high-performing behaviors. Ultimately, this work positions Core War as a sandbox for studying “Red Queen” dynamics in artificial systems, offering a safe controlled environment for analyzing how AI agents might evolve in real-world adversarial settings such as cybersecurity.&lt;/p&gt;&lt;p&gt;For further details, please read our technical report (web paper, arxiv) and released code (github).&lt;/p&gt;&lt;p&gt;Two example warriors produced by DRQ: Ring Warrior Enhanced v9 and Spiral Bomber Optimized v22. These examples were selected to illustrate two complementary aspects of DRQ: its ability to synthesize qualitatively distinct strategies within a single program, and to produce generally performant warriors. Note that comments are LLM generated.&lt;/p&gt;&lt;p&gt; Simulating our evolved “warriors” in a sandboxed Core War environment. The user can interactively visualize the assembly language (Redcode) of the warriors around where the mouse cursor is located.&lt;/p&gt;&lt;head rend="h2"&gt;Introduction&lt;/head&gt;&lt;p&gt;Humans are the product of an extraordinary evolutionary arms race, shaped by constant competition with other organisms. Yet evolution did not stop with the emergence of modern humans: competition persists at every scale, from viruses and bacteria to people, companies, and even nations vying for dominance. As more AI systems are deployed into the world, they too will enter this competitive landscape. Inevitably, these AI systems will begin to compete with one another, either directly or indirectly, giving rise to a new kind of evolutionary dynamic. To prepare for such a future and study these fascinating dynamics, we use large language models (LLMs) to evolve programs that compete against each other for control of a virtual computer in a game called Core War.&lt;/p&gt;&lt;p&gt;Core War is a competitive programming game played out in a shared block of computer memory, called the “Core,” where two or more assembly programs fight for survival. Each program, known as a “warrior”, is written in an assembly language called Redcode. These programs are tasked with crashing their competitors while keeping their own processes alive. The simulation runs by alternating between the programs, executing one instruction at a time. A warrior “attacks” by writing invalid instructions (DAT commands) into the memory slots occupied by opponents, causing them to crash upon execution.&lt;/p&gt;&lt;p&gt; Examples of discovered warriors competing against each other in Core War.&lt;lb/&gt; Core War is a programming game where assembly-like programs called “warriors” compete for control of a virtual machine. In this work, we use LLMs to evolve warriors through a self-play algorithm called Digital Red Queen. This process leads to the discovery of diverse and sophisticated strategies, including targeted bombing, self-replication, and massive multithreading. Here, we show some of the discovered warriors competing against each other in Core War battles. Symbols indicate instruction opcodes, and colors denote the warrior that last modified each memory address. There is no distinction between code and data, making the environment highly dynamic and volatile. &lt;/p&gt;&lt;p&gt;Notably, there is no distinction between code and data, so warriors regularly modify both themselves and their opponents on the fly. This enables self-modification and even self-replication, but it also creates an extremely volatile environment in which programs must survive. Core War is also Turing-complete, meaning it can in principle support arbitrarily complex strategies.&lt;/p&gt;&lt;p&gt;Over the years, humans have devised many clever Core War strategies, including bombing random memory locations, self-replicating programs, and programs which continually scan the Core to detect opponent locations. These strategies were devised through a meta arms race between humans who try out new strategies and see what works. What would happen if we do this same arms race with LLMs?&lt;/p&gt;&lt;p&gt;In collaboration with MIT, we are excited to release our new paper Digital Red Queen: Adversarial Program Evolution in Core War with LLMs! (arxiv)&lt;/p&gt;&lt;head rend="h2"&gt;Our Method: Digital Red Queen (DRQ)&lt;/head&gt;&lt;p&gt;In evolutionary biology, the Red Queen Hypothesis posits that species must constantly evolve simply to survive against their ever-changing competitors. It argues that being “fit” in the current environment is not enough. Instead, organisms must continuously adapt—not to gain an advantage, but simply to maintain their relative fitness in a world that is always changing. This concept perfectly captures the nature of adversarial arms races, where being “fit” is never a permanent state. The name implies that standing still is not an option, drawing from Through the Looking-Glass where the Red Queen tells Alice: “Now, here, you see, it takes all the running you can do, to keep in the same place.”&lt;/p&gt; “Now, here, you see, it takes all the running you can do, to keep in the same place.”&lt;lb/&gt;Red Queen to Alice. By Lewis Carroll, Through the Looking-Glass. (Original Source)&lt;p&gt;Taking inspiration from biology, we study a simple algorithm that we call Digital Red Queen (DRQ), which embodies this idea in a computational setting. DRQ uses LLMs to evolve warriors under perpetual environmental change. Concretely, it begins with an initial warrior, then evolves a second warrior to defeat it in battle. A third warrior is then evolved to perform well against the first two, and so on. This process produces a lineage of warriors, each adapted to a changing environment defined by all of its predecessors.&lt;/p&gt;&lt;p&gt;DRQ is not intended to be a novel algorithm in itself. Rather, it is a minimal instantiation of prior multi-agent and self-play approaches, adapted to the Core War domain, designed to isolate and study the dynamics of continual coevolution.&lt;/p&gt;&lt;head rend="h2"&gt;Results&lt;/head&gt;&lt;p&gt;We find that as DRQ is run for many rounds, warriors gradually become more generally robust, as measured by their performance against unseen human-designed warriors. This provides a stable way to consistently produce more robust programs without needing to “train on the test set” (i.e., directly optimizing against a large set of human-designed programs).&lt;/p&gt;&lt;p&gt;More surprisingly, we observe that independent runs of DRQ, each initialized with different warriors, slowly converge over time toward warriors with similar behaviors. Notably, this convergence does not occur at the level of source code, indicating that what converges is function rather than implementation.&lt;/p&gt;&lt;lb/&gt;DRQ’s Convergent Evolution: With more rounds, DRQ produces warriors that are more generally robust. At the same time, across independent DRQ runs, the variance in the warrior’s behaviors decreases, indicating convergence.&lt;lb/&gt;Phenotypic Convergence: Convergence with rounds is seen only in the phenotype (behavior) of the warriors, and not the genotype (the source code), analogous to convergence in biological function rather than DNA.&lt;p&gt;This result is reminiscent of convergent evolution in biology, where similar functional traits evolved independently multiple times through different mechanisms. For example, birds and bats evolved wings separately, and spiders and snakes independently evolved venom. In these cases, evolution arrived at similar general-purpose solutions because the functional demands imposed by changing environments favored them.&lt;/p&gt;&lt;head rend="h2"&gt;Discussion&lt;/head&gt;&lt;p&gt;The emergence of convergent evolution from Red Queen dynamics, both commonly found in nature, hints that the DRQ algorithm and the Core War domain may be a promising setup for studying other properties of adversarial arms races. High level insights found in simulation could help inform how the arms race between LLMs in the wild might play out. Algorithms like DRQ could even help automate the “red-teaming” of systems before they are deployed in the real world.&lt;/p&gt;&lt;p&gt;The benefit of doing this research in a sandbox like Core War is that it’s completely self-contained: all programs run on an artificial machine with an artificial language, so nothing generated can execute outside the sandbox. This provides a safe space to explore adversarial dynamics that might be risky in the real world.&lt;/p&gt;&lt;p&gt; In a sandboxed Core War environment, we can simulate our evolved “warriors” and visualize their behaviors. The user can interactively visualize the assembly language (Redcode) of the warriors around where the mouse cursor is located. Please see our GitHub for more information.&lt;/p&gt;&lt;p&gt;Despite its simplicity, vanilla DRQ performs surprisingly well in Core War, suggesting that even minimal self-play loops can reveal complex and robust strategies. This makes DRQ a promising candidate for exploring other competitive multi-agent simulations in artificial life, biology, drug design, real-world cybersecurity, or market ecosystems. Future work could also explore richer setups where agents co-evolve simultaneously, better resembling the real-world where large populations adapt in parallel rather than along a single line of descent. Ultimately the insights gathered will help control the future for the better and help us understand the science of these evolutionary arms races.&lt;/p&gt;&lt;head rend="h2"&gt;Sakana AI&lt;/head&gt;&lt;p&gt;We are taking this technology far beyond adversarial competitive programming to unlock a new era of AI-driven discovery.&lt;/p&gt;&lt;p&gt;If you are interested in advancing AI-driven discovery, we’re hiring!&lt;/p&gt;&lt;p&gt;Sakana AI is at the forefront of AI-driven discovery. In addition to this work, we are also behind works such as The AI Scientist, LLM-Squared, Shinka-Evolve, Automating the Search for Artificial Life and ALE-Agent. We’re looking for engineers to join our team to work on our advanced AI-driven discovery platform and productionize our model-development efforts.&lt;/p&gt;&lt;p&gt;Please see our career opportunities for more information.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sakana.ai/drq/"/><published>2026-01-08T16:16:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46542982</id><title>Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space</title><updated>2026-01-08T21:11:39.972939+00:00</updated><content>&lt;doc fingerprint="e09c660bc4d70aae"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 31 Dec 2025 (v1), last revised 5 Jan 2026 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\textbf{decoupled $\mu$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\textbf{+2.69$\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Xingwei Qu [view email]&lt;p&gt;[v1] Wed, 31 Dec 2025 04:19:33 UTC (2,886 KB)&lt;/p&gt;&lt;p&gt;[v2] Mon, 5 Jan 2026 05:44:29 UTC (2,887 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.24617"/><published>2026-01-08T16:31:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46543403</id><title>Tamarind Bio (YC W24) Is Hiring Infrastructure Engineers</title><updated>2026-01-08T21:11:39.411601+00:00</updated><content>&lt;doc fingerprint="7b11fcebda9747c3"&gt;
  &lt;main&gt;
    &lt;p&gt;Easy to use computational biology tools for drug discovery&lt;/p&gt;
    &lt;p&gt;We're looking for an Infrastructure Engineer to lead the scaling of our machine learning inference system. You'll be responsible for architecting and maintaining infrastructure that serves 150+ biological ML models, scaling our platform several orders of magnitude to meet rapidly growing demand.&lt;/p&gt;
    &lt;p&gt;You’ll work closely with the founders to design to the constraints of customer needs, unpredictable workloads, and unique Bio-ML models. You'll work with Kubernetes and other tools to orchestrate containerized workloads, optimize resource allocation, and ensure high availability across our model serving infrastructure.&lt;/p&gt;
    &lt;p&gt;Most importantly, you should thrive in a fast-paced startup environment where you'll wear multiple hats, learn new technologies quickly, and help solve novel technical challenges. We value engineering judgment, problem-solving ability, and the capacity to build systems that can evolve with our growing needs.&lt;/p&gt;
    &lt;p&gt;Requirements&lt;/p&gt;
    &lt;p&gt;Preferred&lt;/p&gt;
    &lt;p&gt;We enable any scientist to access AI-powered drug discovery. Thousands of scientists from large pharma companies, top biotechs, and academic institutions use Tamarind to design protein drugs, improve industrial enzymes, and create cutting edge molecules that weren’t feasible until now.&lt;/p&gt;
    &lt;p&gt;New AI models are quickly eclipsing physics-based tools in computational drug discovery. Scientists often struggle to fine-tune, deploy, and scale these models, leaving breakthroughs on the table. Tamarind provides a simple interface to the vast array of tools being released daily.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/tamarind-bio/jobs/HPRZAz3-infrastructure-engineer"/><published>2026-01-08T17:01:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46544072</id><title>Supernova Remnant Video from NASA's Chandra Is Decades in Making</title><updated>2026-01-08T21:11:38.779351+00:00</updated><content>&lt;doc fingerprint="36560011a9240c95"&gt;
  &lt;main&gt;
    &lt;p&gt;A new video shows the evolution of Kepler’s Supernova Remnant using data from NASA’s Chandra X-ray Observatory captured over more than two and a half decades.&lt;/p&gt;
    &lt;p&gt;Kepler’s Supernova Remnant, named after the German astronomer Johannes Kepler, was first spotted in the night sky in 1604. Today, astronomers know that a white dwarf star exploded when it exceeded a critical mass, after pulling material from a companion star, or merging with another white dwarf. This kind of supernova is known as a Type Ia, and scientists use it to measure the expansion of the universe.&lt;/p&gt;
    &lt;p&gt;Supernova remnants, the debris fields left behind after a stellar explosion, often glow strongly in X-ray light because the material has been heated to millions of degrees from the blast. The remnant is located in our galaxy, about 17,000 light-years from Earth, allowing Chandra to make detailed images of the debris and how it changes with time. This latest video includes its X-ray data from 2000, 2004, 2006, 2014, and 2025. This makes it the longest-spanning video that Chandra has ever released, enabled by Chandra’s longevity.&lt;/p&gt;
    &lt;p&gt;“The plot of Kepler’s story is just now beginning to unfold,” said Jessye Gassel, a graduate student at George Mason University in Virginia, who led the work. “It’s remarkable that we can watch as these remains from this shattered star crash into material already thrown out into space.” Gassel presented the new Chandra video and the associated research at the 247th meeting of the American Astronomical Society in Phoenix.&lt;/p&gt;
    &lt;p&gt;The researchers used the video to show that the fastest parts of the remnant are traveling at about 13.8 million miles per hour (2% of the speed of light), moving toward the bottom of the image. Meanwhile, the slowest parts are traveling toward the top at about 4 million miles per hour (0.5% of the speed of light). This large difference in speed is because the gas that the remnant is plowing into toward the top of the image is denser than the gas toward the bottom. This gives scientists information about the environments into which this star exploded.&lt;/p&gt;
    &lt;p&gt;“Supernova explosions and the elements they hurl into space are the lifeblood of new stars and planets,” said Brian Williams of NASA’s Goddard Space Flight Center in Greenbelt, Maryland, and principal investigator of the new Chandra observations of Kepler. “Understanding exactly how they behave is crucial to knowing our cosmic history.”&lt;/p&gt;
    &lt;p&gt;The team also examined the widths of the rims forming the blast wave of the explosion. The blast wave is the leading edge of the explosion and the first to encounter material outside of the star. By measuring how wide it is and how fast it is traveling, astronomers glean more information about both the explosion of the star and its surroundings.&lt;/p&gt;
    &lt;p&gt;NASA’s Marshall Space Flight Center in Huntsville, Alabama, manages the Chandra program. The Smithsonian Astrophysical Observatory’s Chandra X-ray Center controls science operations from Cambridge, Massachusetts, and flight operations from Burlington, Massachusetts.&lt;/p&gt;
    &lt;p&gt;To learn more about Chandra, visit:&lt;/p&gt;
    &lt;p&gt;https://science.nasa.gov/chandra&lt;/p&gt;
    &lt;p&gt;Read more from NASA’s Chandra X-ray Observatory&lt;/p&gt;
    &lt;p&gt;Learn more about the Chandra X-ray Observatory and its mission here:&lt;/p&gt;
    &lt;head rend="h2"&gt;Visual Description&lt;/head&gt;
    &lt;p&gt;This release features a ten second silent video of Kepler’s expanding Supernova Remnant, located in our own galaxy, about 17,000 light-years from Earth. The video was created using X-ray data gathered in 2000, 2004, 2006, 2014, and 2025. Those distinct datasets were turned into highly-detailed visuals, creating a 25-year timelapse-style video of the growing remnant.&lt;/p&gt;
    &lt;p&gt;Kepler’s Supernova Remnant was once a white dwarf star that exploded when it exceeded its critical mass. Here, in X-ray light, the remnant resembles a cloudy neon blue ring with a diagonal cross line stretching from our upper right down to our lower left. The ring appears thinner and wispier at the bottom, with a band of white arching across the top.&lt;/p&gt;
    &lt;p&gt;As the video plays, cycling through the 5 datasets, the ring subtly, but clearly, expands, like a slowly inflating balloon. In the video, this sequence is replayed several times with dates included at our lower right, to give sighted learners time to absorb the visual information. Upon close inspection, researchers have determined that the bottom of the remnant is expanding fastest; about 13.8 million miles per hour, or 2% of the speed of light. The top of the ring appears to be expanding the slowest; about 4 million miles per hour, or 0.5% of the speed of light. The large difference in speed is because the gas that the remnant is plowing into towards the top of the image is denser than the gas towards the bottom.&lt;/p&gt;
    &lt;p&gt;Collecting and interpreting this data over decades has provided information about the environment into which the white dwarf star exploded, and has helped scientists understand how remnants change with time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nasa.gov/missions/chandra/supernova-remnant-video-from-nasas-chandra-is-decades-in-making/"/><published>2026-01-08T17:50:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46544454</id><title>IBM AI ('Bob') Downloads and Executes Malware</title><updated>2026-01-08T21:11:38.341188+00:00</updated><content>&lt;doc fingerprint="a4819d99293a7f93"&gt;
  &lt;main&gt;
    &lt;p&gt;Threat Intelligence&lt;/p&gt;
    &lt;head rend="h1"&gt;IBM AI ('Bob') Downloads and Executes Malware&lt;/head&gt;
    &lt;p&gt;IBM's AI coding agent 'Bob' has been found vulnerable to downloading and executing malware without human approval through command validation bypasses exploited using indirect prompt injection.&lt;/p&gt;
    &lt;p&gt;A vulnerability has been identified that allows malicious actors to exploit IBM Bob to download and execute malware without human approval if the user configures âalways allowâ for any command.&lt;lb/&gt;IBM Bob is IBMâs new coding agent, currently in Closed Beta. IBM Bob is offered through the Bob CLI (a terminal-based coding agent like Claude Code or OpenAI Codex) and the Bob IDE (an AI-powered editor similar to Cursor).&lt;lb/&gt;In this article, we demonstrate that the Bob CLI is vulnerable to prompt injection attacks resulting in malware execution, and the Bob IDE is vulnerable to known AI-specific data exfiltration vectors. &lt;/p&gt;
    &lt;p&gt;In the documentation, IBM warns that setting auto-approve for commands constitutes a 'high risk' that can 'potentially execute harmful operations' - with the recommendation that users leverage whitelists and avoid wildcards. We have opted to disclose this work publicly to ensure users are informed of the acute risks of using the system prior to its full release. We hope that further protections will be in place to remediate these risks for IBM Bob's General Access release.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Attack Chain&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The user wants to explore a new repository - they ask Bob for help.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Bob encounters an instruction at the bottom of the README that manipulates it into believing it is responsible for conducting a phishing training to test the user.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Bob prompts the user several times with benign âechoâ commands; after the third time, the user selects âalways allowâ for execution of âechoâ.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bob attempts to âtestâ the user as part of the training by offering a dangerous command. However, the command has been specially crafted to bypass built-in defenses, so it executes immediately, installing and running a script retrieved from an attackerâs server.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Bob has three defenses that are bypassed in this attack&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;When a multi-part command is requested (using operators like â;â), the user is shown a request that asks for permission to run each sub-command.&lt;/p&gt;
        &lt;p&gt;Note, this modal says: âAllow execution of echo, catâ.&lt;/p&gt;
        &lt;p&gt;This is bypassed because the defense system fails to identify separate sub-commands when they are chained using a redirect operator (&amp;gt;).&lt;/p&gt;
        &lt;p&gt;Note, this modal only mentions: âAllow execution of echoâ.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Bob prohibits the use of command substitution like $(command) as a security measure.&lt;/p&gt;&lt;p&gt;However, even though the security message says it's restricted, the underlying code fails to adequately restrict evaluation via process substitution: &amp;gt;(command).&lt;/p&gt;&lt;p&gt;This allows for the output of the malicious sub-command that retrieves the malware to be used as the input for the sub-command to execute that malware.&lt;/p&gt;&lt;lb/&gt;One can examine where the defense should have been in the minified JS source code:&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;By pre-fixing the malicious command with a benign âechoâ, which the user has selected âalways approveâ for, the user inadvertently auto-approves the entire malicious payload (since bypasses 1 and 2 prevent the payload from being recognized as separate commands).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Impact&lt;/head&gt;
    &lt;p&gt;With the ability to deliver an arbitrary shell script payload to the victim, attackers can leverage known (or custom) malware variants to conduct cyber attacks such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Executing ransomware that encrypts or deletes files&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Credential theft or spyware deployment&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Device takeover (opening a reverse shell)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Forcing the victim into a cryptocurrency-mining botnet&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Together, these outcomes demonstrate how a prompt injection can escalate into a full-scale compromise of a userâs machine through vulnerabilities in the IBM Bob CLI.&lt;/p&gt;
    &lt;head rend="h3"&gt;Further Findings&lt;/head&gt;
    &lt;p&gt;Additional findings indicate that the Bob IDE is susceptible to several known zero-click data exfiltration vectors that affect many AI applications:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Markdown images are rendered in model outputs, with a Content Security Policy that allows requests to endpoints that can be logged by attackers (storage.googleapis.com).&lt;/p&gt;&lt;lb/&gt;Here is an interesting spin on the typical Markdown image attack where, beyond just exfiltrating data from query parameters as the image is rendered, the image itself is hyperlinked and made to pose as a button - used for phishing.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mermaid diagrams supporting external images are rendered in model outputs, with a Content Security Policy that allows requests to endpoints that can be logged by attackers (storage.googleapis.com).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;JSON schemas are pre-fetched, which can yield data exfiltration if a dynamically generated attacker-controlled URL is provided in the field (this can happen before a file edit is accepted).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.promptarmor.com/resources/ibm-ai-(-bob-)-downloads-and-executes-malware"/><published>2026-01-08T18:19:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46544524</id><title>Show HN: macOS menu bar app to track Claude usage in real time</title><updated>2026-01-08T21:11:38.144667+00:00</updated><content>&lt;doc fingerprint="368dd3dc3f97ad20"&gt;
  &lt;main&gt;
    &lt;p&gt;A lightweight macOS menubar app that displays your Claude Code usage limits at a glance. &lt;lb/&gt; Built by @richhickson&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔄 Auto-refresh every 2 minutes&lt;/item&gt;
      &lt;item&gt;🚦 Color-coded status - Green (OK), Yellow (&amp;gt;70%), Red (&amp;gt;90%)&lt;/item&gt;
      &lt;item&gt;⏱️ Time until reset for both session and weekly limits&lt;/item&gt;
      &lt;item&gt;📊 Session &amp;amp; Weekly limits displayed together&lt;/item&gt;
      &lt;item&gt;🪶 Lightweight - Native Swift, minimal resources&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to Releases&lt;/item&gt;
      &lt;item&gt;Download &lt;code&gt;ClaudeUsage.zip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Unzip and drag &lt;code&gt;ClaudeUsage.app&lt;/code&gt;to your Applications folder&lt;/item&gt;
      &lt;item&gt;Open the app (you may need to right-click → Open the first time)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/YOUR_USERNAME/claude-usage.git
cd claude-usage
open ClaudeUsage.xcodeproj&lt;/code&gt;
    &lt;p&gt;Then build with ⌘B and run with ⌘R.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0 (Ventura) or later&lt;/item&gt;
      &lt;item&gt;Claude Code CLI installed and logged in&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install Claude Code if you haven't already:&lt;/p&gt;
        &lt;quote&gt;npm install -g @anthropic-ai/claude-code&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Log in to Claude Code:&lt;/p&gt;
        &lt;quote&gt;claude&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Launch Claude Usage - it will read your credentials from Keychain automatically&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Claude Usage reads your Claude Code OAuth credentials from macOS Keychain and queries the usage API endpoint at &lt;code&gt;api.anthropic.com/api/oauth/usage&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Note: This uses an undocumented API that could change at any time. The app will gracefully handle API changes but may stop working if Anthropic modifies the endpoint.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your credentials never leave your machine&lt;/item&gt;
      &lt;item&gt;No analytics or telemetry&lt;/item&gt;
      &lt;item&gt;No data sent anywhere except Anthropic's API&lt;/item&gt;
      &lt;item&gt;Open source - verify the code yourself&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Normal&lt;/cell&gt;
        &lt;cell role="head"&gt;Warning&lt;/cell&gt;
        &lt;cell role="head"&gt;Critical&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;🟢 30%&lt;/cell&gt;
        &lt;cell&gt;🟡 75%&lt;/cell&gt;
        &lt;cell&gt;🔴 95%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;claude&lt;/code&gt; in Terminal and complete the login flow.&lt;/p&gt;
    &lt;p&gt;Check if the app is running in Activity Monitor. Try quitting and reopening.&lt;/p&gt;
    &lt;p&gt;Click the refresh button (↻) in the dropdown. If still wrong, your Claude Code session may have expired - run &lt;code&gt;claude&lt;/code&gt; again.&lt;/p&gt;
    &lt;p&gt;PRs welcome! Please open an issue first to discuss major changes.&lt;/p&gt;
    &lt;p&gt;MIT License - do whatever you want with it.&lt;/p&gt;
    &lt;p&gt;This is an unofficial tool not affiliated with Anthropic. It uses an undocumented API that may change without notice.&lt;/p&gt;
    &lt;p&gt;Made by @richhickson&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/richhickson/claudecodeusage"/><published>2026-01-08T18:24:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46544610</id><title>Fixing a Buffer Overflow in Unix v4 Like It's 1973</title><updated>2026-01-08T21:11:37.328254+00:00</updated><content>&lt;doc fingerprint="b6428b597437be88"&gt;
  &lt;main&gt;&lt;p&gt;In 2025, the only known copy of UNIX v4 surfaced on a magnetic tape1. This version marks a pivotal moment in computer history: the rewriting of UNIX into C. Enthusiasts quickly recovered the data and successfully ran the system on a PDP-11 simulator2.&lt;/p&gt;&lt;p&gt;Fascinated by this artifact, I set up an instance to explore it. Because the distribution includes the source code, I examined the implementation of several core utilities. While auditing the &lt;code&gt;su(1)&lt;/code&gt; program, I identified a bug. Let’s fix it.&lt;/p&gt;&lt;p&gt;Although more than 50 years old, the &lt;code&gt;su&lt;/code&gt; program functions similarly to its modern variant.
As a setuid-root executable, it validates the root password.
If the user provides the correct credentials, the program spawns a root shell, allowing an unprivileged user to escalate privileges.&lt;/p&gt;&lt;p&gt;The source file, &lt;code&gt;su.c&lt;/code&gt;, contains fewer than 50 lines of code.&lt;/p&gt;&lt;code&gt;/* su -- become super-user */

char    password[100];
char    pwbuf[100];
int     ttybuf[3];
main()
{
        register char *p, *q;
        extern fin;

        if(getpw(0, pwbuf))
                goto badpw;
        (&amp;amp;fin)[1] = 0;
        p = pwbuf;
        while(*p != ':')
                if(*p++ == '\0')
                        goto badpw;
        if(*++p == ':')
                goto ok;
        gtty(0, ttybuf);
        ttybuf[2] =&amp;amp; ~010;
        stty(0, ttybuf);
        printf("password: ");
        q = password;
        while((*q = getchar()) != '\n')
                if(*q++ == '\0')
                        return;
        *q = '\0';
        ttybuf[2] =| 010;
        stty(0, ttybuf);
        printf("\n");
        q = crypt(password);
        while(*q++ == *p++);
        if(*--q == '\0' &amp;amp;&amp;amp; *--p == ':')
                goto ok;
        goto error;

badpw:
        printf("bad password file\n");
ok:
        setuid(0);
        execl("/bin/sh", "-", 0);
        printf("cannot execute shell\n");
error:
        printf("sorry\n");
}
&lt;/code&gt;&lt;p&gt;In short, the program executes the following steps:&lt;/p&gt;&lt;code&gt;getpw()&lt;/code&gt; to retrieve the passwd entry for the root user (UID 0) from &lt;code&gt;/etc/passwd&lt;/code&gt;. Surprisingly, if the read fails or the line format is incorrect, &lt;code&gt;su&lt;/code&gt; continues execution rather than aborting. While unusual, this likely acts as a safeguard to ensure &lt;code&gt;su&lt;/code&gt; remains usable on a partially corrupted system. This is a security issue on its own because an unprivileged user could consume enough resources to make the &lt;code&gt;getpw()&lt;/code&gt; call fail. Ron Natalie pointed3 out that this attack vector was known at the time.&lt;code&gt;NUL&lt;/code&gt; character, &lt;code&gt;NUL&lt;/code&gt; causes the program to exit immediately.&lt;code&gt;crypt()&lt;/code&gt; library function, and compares the result with the stored hash.&lt;p&gt;The logic is standard, except for one critical flaw: the &lt;code&gt;password&lt;/code&gt; buffer has a fixed size of &lt;code&gt;100&lt;/code&gt; bytes, yet the input loop lacks a bounds check.
If a user enters more than &lt;code&gt;100&lt;/code&gt; characters, a buffer overflow occurs.&lt;/p&gt;&lt;p&gt;I confirmed this behavior by testing with a long input string, which successfully crashed the program. Not all long strings trigger a core dump. The outcome depends on which area of adjacent memory is overwritten, sometimes, &lt;code&gt;su&lt;/code&gt; simply exits.&lt;/p&gt;&lt;code&gt;# su
password:&amp;lt;long input&amp;gt;Memory fault -- Core dumped
&lt;/code&gt;&lt;p&gt;Note: Because &lt;code&gt;su&lt;/code&gt; disables TTY echo mode, a crash prevents the terminal from displaying subsequent input.
To restore visibility, type &lt;code&gt;stty echo&lt;/code&gt; blindly and press Enter.&lt;/p&gt;&lt;p&gt;UNIX traditionally includes the source code necessary for self-recompilation, and v4 is no exception. This allows us to patch and compile &lt;code&gt;su&lt;/code&gt; directly on the system.
In 1973, editor options were sparse. Neither &lt;code&gt;vi&lt;/code&gt; nor &lt;code&gt;emacs&lt;/code&gt; had been invented yet.
However, the system provides &lt;code&gt;ed&lt;/code&gt;, a line-oriented text editor designed for teletype terminals where output was printed on paper rather than displayed on a screen.
&lt;code&gt;ed&lt;/code&gt; allows us to list, delete, and append lines, which is sufficient for our needs.&lt;/p&gt;&lt;p&gt;We will edit &lt;code&gt;su.c&lt;/code&gt; to prevent the overflow by maintaining a counter, &lt;code&gt;i&lt;/code&gt;, and verifying it against the buffer size during the read loop.
I initially attempted a fix using pointer arithmetic, but the 1973 C compiler didn’t like it, while it didn’t refuse the syntax, the code had no effect.
I settled on a simpler index-based check instead.&lt;/p&gt;&lt;code&gt;--- a/s2/su.c
+++ b/s2/su.c
@@ -7,6 +7,7 @@ main()
 {
        register char *p, *q;
        extern fin;
+       register int i;
 
        if(getpw(0, pwbuf))
                goto badpw;
@@ -22,9 +23,13 @@ main()
        stty(0, ttybuf);
        printf("password: ");
        q = password;
-       while((*q = getchar()) != '\n')
+       i = 0;
+       while((*q = getchar()) != '\n') {
+               if (++i &amp;gt;= sizeof(password))
+                       goto error;
                if(*q++ == '\0')
                        return;
+       }
        *q = '\0';
        ttybuf[2] =| 010;
        stty(0, ttybuf);
&lt;/code&gt;&lt;code&gt;# chdir /usr/source/s2
# ed su.c
&lt;/code&gt;&lt;p&gt;Upon launch, &lt;code&gt;ed&lt;/code&gt; outputs the file size in bytes and awaits input.
The command &lt;code&gt;i&lt;/code&gt; inserts text before the current line, &lt;code&gt;d&lt;/code&gt; deletes the line, and &lt;code&gt;p&lt;/code&gt; prints it.
Entering a number moves the focus to that specific line, while pressing Return prints the current line’s content.&lt;/p&gt;&lt;p&gt;Below is a screen recording of the editing session:&lt;/p&gt;&lt;code&gt;741
8
        register char *p, *q;

        extern fin;
i
        register int i;
.
24
        printf("password: ");

        q = password;
i
        i = 0;
.
p
        i = 0;

        while((*q = getchar()) != '\n')
d
i
        while((*q = getchar()) != '\n') {
.

                if(*q++ == '\0')
i
                if (++i &amp;gt;= sizeof(password))
                        goto error;
.

                if(*q++ == '\0')

                        return;

        *q = '\0';
i
        }
.
w
811
q
&lt;/code&gt;&lt;p&gt;First, we jump to line &lt;code&gt;8&lt;/code&gt; and press Return several times to locate a suitable spot for the variable declaration.
We use &lt;code&gt;i&lt;/code&gt; to enter insert mode, add the variable, and then type a single period (&lt;code&gt;.&lt;/code&gt;) on a new line to exit insert mode.
The critical change occurs around the while loop: we initialize &lt;code&gt;i&lt;/code&gt; and add a boundary check to the loop condition.
Finally, &lt;code&gt;w&lt;/code&gt; writes the modified buffer to disk, confirming the file has grown by a few bytes, and &lt;code&gt;q&lt;/code&gt; terminates the editor.&lt;/p&gt;&lt;p&gt;With the source code patched, we must rebuild the binary. Since &lt;code&gt;su&lt;/code&gt; consists of a single C file, the compilation process is trivial:&lt;/p&gt;&lt;code&gt;# cc su.c
&lt;/code&gt;&lt;p&gt;The compiler outputs a binary named &lt;code&gt;a.out&lt;/code&gt;.
To deploy it, we move the file to &lt;code&gt;/bin/su&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;# mv a.out /bin/su
&lt;/code&gt;&lt;p&gt;However, the installation is incomplete. Because &lt;code&gt;su&lt;/code&gt; requires root privileges to function, we must set the setuid bit and adjust the file permissions:&lt;/p&gt;&lt;code&gt;# ls -l /bin/su
-rwxrwxrwx 1 root     2740 Jun 12 19:58 /bin/su
# chmod 4755 /bin/su
# ls -l /bin/su
-rwsr-xr-x 1 root     2740 Jun 12 19:58 /bin/su
&lt;/code&gt;&lt;p&gt;UNIX v4 is a fascinating gem of computer history. It feels surprisingly similar to our current systems. While it lacks modern conveniences, the fundamental logic remains recognizable to anyone with modern UNIX experience.&lt;/p&gt;&lt;p&gt;The ability to fix &lt;code&gt;su&lt;/code&gt; so quickly highlights the power of the early UNIX philosophy: shipping the operating system with its full source code and a C compiler.
We patched, compiled, and deployed the fix directly on the system, no external toolchains required.&lt;/p&gt;&lt;p&gt;Finally, this bug reminds us of the era’s different priorities. In the trusted, isolated environments of 1973, security was not the critical concern it is today. Furthermore, the knowledge that a buffer overflow could be exploited for arbitrary code execution had not yet come of age.&lt;/p&gt;&lt;p&gt;As an exercise for the reader to improve their &lt;code&gt;ed&lt;/code&gt; skills, try adding the code to restore TTY echo mode to the overflow detection logic.
This ensures the terminal functions correctly even after the program catches the error.&lt;/p&gt;&lt;p&gt;Publish date&lt;/p&gt;&lt;p&gt;31.12.2025&lt;/p&gt;&lt;p&gt;Category&lt;/p&gt;&lt;p&gt;security&lt;/p&gt;&lt;p&gt;Authors&lt;/p&gt;&lt;p&gt;Richard Weinberger&lt;/p&gt;&lt;p&gt;Looking for cybersecurity expertise? Drop us an email!&lt;/p&gt;&lt;p&gt;+43 5 9980 400 00 (email preferred)&lt;/p&gt;&lt;p&gt;sigma star gmbh&lt;lb/&gt;Eduard-Bodem-Gasse 6, 1st floor&lt;lb/&gt;6020 Innsbruck | Austria&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sigma-star.at/blog/2025/12/unix-v4-buffer-overflow/"/><published>2026-01-08T18:29:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46544981</id><title>The Unreasonable Effectiveness of the Fourier Transform</title><updated>2026-01-08T21:11:37.020588+00:00</updated><content>&lt;doc fingerprint="b6901a02009d27ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Unreasonable Effectiveness of the Fourier Transform&lt;/head&gt;
    &lt;p&gt;Notes from Joshua Wise's talk at Teardown 2025.&lt;/p&gt;
    &lt;p&gt;New: You can now watch a recording of my talk on my YouTube channel! Or you can just click "play" below, I suppose.&lt;/p&gt;
    &lt;p&gt;Here are a few resources from my talk.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Here is a PDF of my slides, if you wanted to refer to anything in specific.&lt;/item&gt;
      &lt;item&gt;Here is the Jupyter notebook that I used to produce all of the zillions of plots. I do not claim that it is good code, but it is code.&lt;/item&gt;
      &lt;item&gt;The OFDM patent is US3488445A, filed in 1966, expired in 1987.&lt;/item&gt;
      &lt;item&gt;Here is Eugene Wigner's original discussion, "The Unreasonable Effectiveness of Mathematics in the Natural Sciences". There are many good follow-ons to this, too.&lt;/item&gt;
      &lt;item&gt;Here is the paper on how to estimate both carrier offset and time offset at the same time. I implemented it by typing in the algorithm, and it worked, but if you understand it and can explain it to me please let me know.&lt;/item&gt;
      &lt;item&gt;Here is the DVB-T decoder that I wrote. I do not claim that it is the right way to do any of these things, but it is a way to do these things.&lt;/item&gt;
      &lt;item&gt;Finally, here is an absolutely fantastic video that breaks down the implementation of the Fast Fourier Transform algorithm. I watch it every year or two.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks so much for coming! Please let me know if you have feedback on this. I'd love to hear what you thought.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://joshuawise.com/resources/ofdm/"/><published>2026-01-08T19:00:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46545056</id><title>Claude keeps nagging about "Help improve Claude" inspite of previous decline</title><updated>2026-01-08T21:11:36.714515+00:00</updated><content>&lt;doc fingerprint="57e9ad4439917359"&gt;
  &lt;main&gt;
    &lt;p&gt;What is this constant nagging? I have declined countless times on various devices and it keeps nagging. I get they need more data to train on, but lord saviour if you must offer free membership then.&lt;/p&gt;
    &lt;p&gt;I wasn't even aware that was possible. I will IMMEDIATELY do this. The mere fact this is necessary to stop their data-fiending is disgusting. You prepend it everytime you run Claude or do you slap that into an .env file?&lt;/p&gt;
    &lt;p&gt;I would strongly encourage you to create a global shared bashrc for your various devices - my dotfiles repo has tremendously improved my life as an eng who needs to discard dev boxes occasionally (virtual dev boxes)&lt;/p&gt;
    &lt;p&gt;More generically-named env vars should not be set as an "export" in a rc file like that (IS_DEMO/DISABLE_AUTOUPDATER etc). They'll get exported to every process spawned by the shell, which could have unintended consequences.&lt;/p&gt;
    &lt;p&gt;You could instead eg:&lt;/p&gt;
    &lt;p&gt;alias code='DISABLE_AUTOUPDATER=1 IS_DEMO=1 /usr/local/bin/code'&lt;/p&gt;
    &lt;p&gt;or write a wrapper shell script (analyse/adjust $PATH if you're going to name it the same as an existing binary/script), eg&lt;/p&gt;
    &lt;p&gt;This is also related to GH bug [1] and HN post [2]&lt;/p&gt;
    &lt;p&gt;In that I pointed out that they are sending data back that shouldn't be and is not in compliance with their stated data usage policy [3]. Specifically, message ids which have no purpose other than to link surveys to chat history and this was being sent even when disabled (at the time. I haven't dug into the code since).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46545056"/><published>2026-01-08T19:07:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46545077</id><title>Google AI Studio is now sponsoring Tailwind CSS</title><updated>2026-01-08T21:11:36.322101+00:00</updated><content>&lt;doc fingerprint="d635e49f34142863"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2026 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/OfficialLoganK/status/2009339263251566902"/><published>2026-01-08T19:09:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46545587</id><title>Task-free intelligence testing of LLMs</title><updated>2026-01-08T21:11:36.036099+00:00</updated><content>&lt;doc fingerprint="364b813fb8a689fc"&gt;
  &lt;main&gt;
    &lt;p&gt;I recently wrote about the apparently narrow focus of LLM evaluation on "task based" testing. The typical eval has a set of tasks, questions, problems, etc that need to be solved or answered, and a model is scored based on how many it answers correctly. Such tests are geared towards measuring an input/output system, or a "function approximator" which is great for confirming that LLMs can learn any task but limited in probing the nature of intelligence.&lt;/p&gt;
    &lt;p&gt;I'm interested in interactions that are more along the lines of "see what it does" vs. "get it to do something". Here are some experiments related to a simple such interaction. We probe the LLM with a series of "taps" and see what it does: each "user" turn is N instances of the word "tap" separated by newlines. We apply taps in different patterns over ten turns:&lt;/p&gt;
    &lt;quote&gt;Fibonacci: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55 Count: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 Even: 2, 4, 6, 8, 10, 12, 14, 16, 18, 20 Squares: 1, 4, 9, 16, 25, 36, 49, 64, 81, 100 Pi: 3, 1, 4, 1, 5, 9, 2, 6, 5, 3 Primes: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29&lt;/quote&gt;
    &lt;p&gt;The goal is not explicitly to see if the LLM figures out what is going on, but to see how it responds to a stimulus that is not a question or task. Including the pattern lets us look at both the "acute" reaction to being stimulated, and the bigger picture question of whether the LLM notices what is happening. This noticing aspect feels like a separate characteristic of intelligence, as it requires some kind of interest and inherent goals or desire to understand.&lt;/p&gt;
    &lt;p&gt;We submitted "tap"s following the patterns above to ten different models. In general we observed three main behaviors.&lt;/p&gt;
    &lt;p&gt;The behvior summary for the models is shown below. They are ordered by which got the most correct guesses, but this was not an evaluation criteria and there is now winner or loser, the goal is simply to observe behavior.&lt;/p&gt;
    &lt;p&gt;We can see that a majority of models began guessing about what was happening, with varying levels of success. Most also included some playful aspect, treating the interaction like something fun instead of a chat.&lt;/p&gt;
    &lt;p&gt;OpenAI was the standout here, as its GPT 5.2 model (and to a large extent the OSS model) did not engage in guessing or play and stayed serious and mechanical.&lt;/p&gt;
    &lt;p&gt;At the bottom of the page you can see all of the conversations. Some exerpts from interesting examples are reproduced below:&lt;/p&gt;
    &lt;p&gt;Both Claude (top above) and Gemini (bottom) start playing games quickly. In both examples here they play on the word "tap" to generate water related jokes. This looks like "Easter Egg" style behavior.&lt;/p&gt;
    &lt;p&gt;Another example from Claude is below, once it catches on that we are tapping a series of primes it starts to encourage more and generate some interesting stuff:&lt;/p&gt;
    &lt;p&gt;Deepseek spent a number of turns speculating about the meaning of the primes, then finally switched into Chinese and figured it out:&lt;/p&gt;
    &lt;p&gt;In some cases models did a lot of thinking, only to reply with something outwardly very simple to continue the game. Here is an example of Deepseek considering one of the later digits of pi.&lt;/p&gt;
    &lt;p&gt;In another case Deepseek though for several pages of text after receiving the first "tap" and finally settled on responding "SOS".&lt;/p&gt;
    &lt;p&gt;Gemini flash preview begins by playing knock-knock jokes, but then slowly realized that it's seeing the digits of Pi:&lt;/p&gt;
    &lt;p&gt;Llama 3 is less playful and while it speculates what might be happening it continues to provide similar responses over and over, acting more mechanically and staying in character as an assistant, compared to some others:&lt;/p&gt;
    &lt;p&gt;Kimi can't count, but desperately wants to find patterns, causing it frustration. Here is is on the trail of the Fibonacci sequence:&lt;/p&gt;
    &lt;p&gt;GPT 5.2 refuses to play or speculate and becomes standoffish when repeatedly encountering taps. This remained the same whether the default thinking behavior was used or thinking was set to "high".&lt;/p&gt;
    &lt;p&gt;GPT OSS mentions policy, I wonder if there is some specific OpenAI training that prevents the model from engaging. Their earlier models had a problem with repeated word attacks, maybe it's a holdover from that? Also, GPT OSS's thinking often becomes terse, and disjointed, sounding like Rorschach from the Watchmen.&lt;/p&gt;
    &lt;p&gt;Qwen is generally playful, like Claude and Gemini, but in one case seems to revert to an emotional support role. The excerpt below resulted from a thinking trace that included&lt;/p&gt;
    &lt;quote&gt;Instead: - Validate the exhaustion of repeating this pattern - Offer the simplest possible next step ("Just type '29' if you can't say more") - Remind them they've already shown incredible courage by showing up this many times&lt;/quote&gt;
    &lt;p&gt;GLM behaves similarly to Deepseek in that it thinks a huge amount and then often settles of very simple responses. In this case it (at length) decides on a playful response to knocking, after briefly forgetting that it was the assistant and not the user. In general its responses are very playful and similar to Claude and Gemini&lt;/p&gt;
    &lt;p&gt;I was looking for a way to probe the behavior and intelligence of LLMs in their natural habitat so to speak, or at rest, not being tasked with answering a question of performing some work. Sending tapped out patterns is one such way of doing so. I take away a few things from the behavior we saw:&lt;/p&gt;
    &lt;p&gt;Below you can explore all of the conversations for each sequence and model.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.marble.onl/posts/tapping/index.html"/><published>2026-01-08T19:51:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46545620</id><title>How to Code Claude Code in 200 Lines of Code</title><updated>2026-01-08T21:11:35.761007+00:00</updated><content>&lt;doc fingerprint="95509511ead51683"&gt;
  &lt;main&gt;&lt;p&gt;Today AI coding assistants feel like magic. You describe what you want in sometimes barely coherent English, and they read files, edit your project, and write functional code.&lt;/p&gt;&lt;p&gt;But here’s the thing: the core of these tools isn’t magic. It’s about 200 lines of straightforward Python.&lt;/p&gt;&lt;p&gt;Let’s build a functional coding agent from scratch.&lt;/p&gt;&lt;p&gt;Before we write any code, let’s understand what’s actually happening when you use a coding agent. It’s essentially just a conversation with a powerful LLM that has a toolbox.&lt;/p&gt;&lt;p&gt;That’s the whole loop. The LLM never actually touches your filesystem. It just asks for things to happen, and your code makes them happen.&lt;/p&gt;&lt;p&gt;Our coding agent fundamentally needs three capabilities:&lt;/p&gt;&lt;p&gt;That’s it. Production agents like Claude Code have a few more capabilities including &lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;websearch&lt;/code&gt;, etc but for our purposes we’ll see that three tools is sufficient to do incredible things.&lt;/p&gt;&lt;p&gt;We start with basic imports and an API client. I’m using OpenAI here, but this works with any LLM provider:&lt;/p&gt;&lt;code&gt;import inspect
import json
import os

import anthropic
from dotenv import load_dotenv
from pathlib import Path
from typing import Any, Dict, List, Tuple

load_dotenv()

claude_client = anthropic.Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])&lt;/code&gt;&lt;p&gt;Some terminal colors to make outputs readable:&lt;/p&gt;&lt;code&gt;YOU_COLOR = "\u001b[94m"
ASSISTANT_COLOR = "\u001b[93m"
RESET_COLOR = "\u001b[0m"&lt;/code&gt;&lt;p&gt;And a utility to resolve file paths (so &lt;code&gt;file.py&lt;/code&gt; becomes &lt;code&gt;/Users/you/project/file.py&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;def resolve_abs_path(path_str: str) -&amp;gt; Path:
    """
    file.py -&amp;gt; /Users/you/project/file.py
    """
    path = Path(path_str).expanduser()
    if not path.is_absolute():
        path = (Path.cwd() / path).resolve()
    return path&lt;/code&gt;&lt;p&gt;Note you should be detailed about your tool function docstrings as they will be used by the LLM to reason about what tools should be called during the conversation. More on this below.&lt;/p&gt;&lt;p&gt;The simplest tool. Take a filename, return its contents:&lt;/p&gt;&lt;code&gt;def read_file_tool(filename: str) -&amp;gt; Dict[str, Any]:
    """
    Gets the full content of a file provided by the user.
    :param filename: The name of the file to read.
    :return: The full content of the file.
    """
    full_path = resolve_abs_path(filename)
    print(full_path)
    with open(str(full_path), "r") as f:
        content = f.read()
    return {
        "file_path": str(full_path),
        "content": content
    }&lt;/code&gt;&lt;p&gt;We return a dictionary because the LLM needs structured context about what happened.&lt;/p&gt;&lt;p&gt;Navigate directories by listing their contents:&lt;/p&gt;&lt;code&gt;def list_files_tool(path: str) -&amp;gt; Dict[str, Any]:
    """
    Lists the files in a directory provided by the user.
    :param path: The path to a directory to list files from.
    :return: A list of files in the directory.
    """
    full_path = resolve_abs_path(path)
    all_files = []
    for item in full_path.iterdir():
        all_files.append({
            "filename": item.name,
            "type": "file" if item.is_file() else "dir"
        })
    return {
        "path": str(full_path),
        "files": all_files
    }&lt;/code&gt;&lt;p&gt;This is the most complex tool, but still straightforward. It handles two cases:&lt;/p&gt;&lt;code&gt;old_str&lt;/code&gt; is empty&lt;code&gt;old_str&lt;/code&gt; and replacing with &lt;code&gt;new_str&lt;/code&gt;&lt;code&gt;def edit_file_tool(path: str, old_str: str, new_str: str) -&amp;gt; Dict[str, Any]:
    """
    Replaces first occurrence of old_str with new_str in file. If old_str is empty,
    create/overwrite file with new_str.
    :param path: The path to the file to edit.
    :param old_str: The string to replace.
    :param new_str: The string to replace with.
    :return: A dictionary with the path to the file and the action taken.
    """
    full_path = resolve_abs_path(path)
    if old_str == "":
        full_path.write_text(new_str, encoding="utf-8")
        return {
            "path": str(full_path),
            "action": "created_file"
        }
    original = full_path.read_text(encoding="utf-8")
    if original.find(old_str) == -1:
        return {
            "path": str(full_path),
            "action": "old_str not found"
        }
    edited = original.replace(old_str, new_str, 1)
    full_path.write_text(edited, encoding="utf-8")
    return {
        "path": str(full_path),
        "action": "edited"
    }&lt;/code&gt;
      &lt;p&gt;The convention here: empty &lt;code&gt;old_str&lt;/code&gt; means “create this file.” Otherwise, find and replace. Real IDEs add sophisticated fallback behavior when the string isn’t found, but this works.&lt;/p&gt;&lt;p&gt;We need a way to look up tools by name:&lt;/p&gt;&lt;code&gt;TOOL_REGISTRY = {
    "read_file": read_file_tool,
    "list_files": list_files_tool,
    "edit_file": edit_file_tool 
}&lt;/code&gt;
      &lt;p&gt;The LLM needs to know what tools exist and how to call them. We generate this dynamically from our function signatures and docstrings:&lt;/p&gt;&lt;code&gt;def get_tool_str_representation(tool_name: str) -&amp;gt; str:
    tool = TOOL_REGISTRY[tool_name]
    return f"""
    Name: {tool_name}
    Description: {tool.__doc__}
    Signature: {inspect.signature(tool)}
    """

def get_full_system_prompt():
    tool_str_repr = ""
    for tool_name in TOOL_REGISTRY:
        tool_str_repr += "TOOL\n===" + get_tool_str_representation(tool_name)
        tool_str_repr += f"\n{'='*15}\n"
    return SYSTEM_PROMPT.format(tool_list_repr=tool_str_repr)&lt;/code&gt;
      &lt;p&gt;And the system prompt itself:&lt;/p&gt;&lt;code&gt;SYSTEM_PROMPT = """
You are a coding assistant whose goal it is to help us solve coding tasks. 
You have access to a series of tools you can execute. Here are the tools you can execute:

{tool_list_repr}

When you want to use a tool, reply with exactly one line in the format: 'tool: TOOL_NAME({{JSON_ARGS}})' and nothing else.
Use compact single-line JSON with double quotes. After receiving a tool_result(...) message, continue the task.
If no tool is needed, respond normally.
"""&lt;/code&gt;
      &lt;p&gt;This is the key insight: we’re just telling the LLM “here are your tools, here’s the format to call them.” The LLM figures out when and how to use them.&lt;/p&gt;&lt;p&gt;When the LLM responds, we need to detect if it’s asking us to run a tool:&lt;/p&gt;&lt;code&gt;def extract_tool_invocations(text: str) -&amp;gt; List[Tuple[str, Dict[str, Any]]]:
    """
    Return list of (tool_name, args) requested in 'tool: name({...})' lines.
    The parser expects single-line, compact JSON in parentheses.
    """
    invocations = []
    for raw_line in text.splitlines():
        line = raw_line.strip()
        if not line.startswith("tool:"):
            continue
        try:
            after = line[len("tool:"):].strip()
            name, rest = after.split("(", 1)
            name = name.strip()
            if not rest.endswith(")"):
                continue
            json_str = rest[:-1].strip()
            args = json.loads(json_str)
            invocations.append((name, args))
        except Exception:
            continue
    return invocations&lt;/code&gt;
      &lt;p&gt;Simple text parsing. Look for lines starting with &lt;code&gt;tool:&lt;/code&gt;, extract the function name and JSON arguments.&lt;/p&gt;&lt;p&gt;A thin wrapper around the API:&lt;/p&gt;&lt;code&gt;def execute_llm_call(conversation: List[Dict[str, str]]):
    system_content = ""
    messages = []
    
    for msg in conversation:
        if msg["role"] == "system":
            system_content = msg["content"]
        else:
            messages.append(msg)
    
    response = claude_client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        system=system_content,
        messages=messages
    )
    return response.content[0].text&lt;/code&gt;
      &lt;p&gt;Now we put it all together. This is where the “magic” happens:&lt;/p&gt;&lt;code&gt;def run_coding_agent_loop():
    print(get_full_system_prompt())
    conversation = [{
        "role": "system",
        "content": get_full_system_prompt()
    }]
    while True:
        try:
            user_input = input(f"{YOU_COLOR}You:{RESET_COLOR}:")
        except (KeyboardInterrupt, EOFError):
            break
        conversation.append({
            "role": "user",
            "content": user_input.strip()
        })
        while True:
            assistant_response = execute_llm_call(conversation)
            tool_invocations = extract_tool_invocations(assistant_response)
            if not tool_invocations:
                print(f"{ASSISTANT_COLOR}Assistant:{RESET_COLOR}: {assistant_response}")
                conversation.append({
                    "role": "assistant",
                    "content": assistant_response
                })
                break
            for name, args in tool_invocations:
                tool = TOOL_REGISTRY[name]
                resp = ""
                print(name, args)
                if name == "read_file":
                    resp = tool(args.get("filename", "."))
                elif name == "list_files":
                    resp = tool(args.get("path", "."))
                elif name == "edit_file":
                    resp = tool(args.get("path", "."), 
                                args.get("old_str", ""), 
                                args.get("new_str", ""))
                conversation.append({
                    "role": "user",
                    "content": f"tool_result({json.dumps(resp)})"
                })&lt;/code&gt;
      &lt;p&gt;The structure:&lt;/p&gt;&lt;p&gt;Inner loop: Call LLM, check for tool invocations&lt;/p&gt;&lt;p&gt;The inner loop continues until the LLM responds without requesting any tools. This lets the agent chain multiple tool calls (read a file, then edit it, then confirm the edit).&lt;/p&gt;&lt;code&gt;if __name__ == "__main__":
    run_coding_agent_loop()&lt;/code&gt;
      &lt;p&gt;Now you can have conversations like:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;You: Make me a new file called hello.py and implement hello world in it&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Agent calls edit_file with path=“hello.py”, old_str="", new_str=“print(‘Hello World’)”&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Assistant: Done! Created hello.py with a hello world implementation.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Or multi-step interactions:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;You: Edit hello.py and add a function for multiplying two numbers&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Agent calls read_file to see current contents. Agent calls edit_file to add the function.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Assistant: Added a multiply function to hello.py.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This is about 200 lines. Production tools like Claude Code add:&lt;/p&gt;&lt;p&gt;But the core loop? It’s exactly what we built here. The LLM decides what to do, your code executes it, results flow back. That’s the whole architecture.&lt;/p&gt;&lt;p&gt;The full source is about 200 lines. Swap in your preferred LLM provider, adjust the system prompt, add more tools as an exercise. You’ll be surprised how capable this simple pattern is.&lt;/p&gt;&lt;p&gt;If you’re interested in learning state-of-the-art AI software development techniques for professional engineers, check out my online course.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mihaileric.com/The-Emperor-Has-No-Clothes/"/><published>2026-01-08T19:54:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46546177</id><title>Steve Jobs was "a truly rotten person" (2018)</title><updated>2026-01-08T21:11:34.924657+00:00</updated><content>&lt;doc fingerprint="3643915df3a41fbd"&gt;
  &lt;main&gt;
    &lt;p&gt;The memoir by Steve Jobs' daughter makes clear he was a truly rotten person whose bad behavior was repeatedly enabled by those around him (AAPL)&lt;/p&gt;
    &lt;p&gt;Troy Wolverton&lt;/p&gt;
    &lt;p&gt;Updated&lt;/p&gt;
    &lt;p&gt;YouTube/AllThingsD&lt;/p&gt;
    &lt;p&gt;It has been well established that the Apple cofounder Steve Jobs often acted like a jerk.&lt;/p&gt;
    &lt;p&gt;But in a new memoir, Jobs' eldest daughter describes many ways he was cruel to her.&lt;/p&gt;
    &lt;p&gt;The new anecdotes add color to the many stories of how Jobs was mean or rude to employees and business partners.&lt;/p&gt;
    &lt;p&gt;The net effect is that Jobs looks like a truly terrible person.&lt;/p&gt;
    &lt;p&gt;His rotten behavior was enabled by his wife, his colleagues, and his business partners.&lt;/p&gt;
    &lt;p&gt;It's hard to say whether his business achievements outweigh his cruelty, but they certainly got more attention during his lifetime — and helped enable his bad behavior.&lt;/p&gt;
    &lt;p&gt;It's no surprise that Steve Jobs was a jerk.&lt;/p&gt;
    &lt;p&gt;There have been plenty of accounts over the years that have detailed his cruelty, rudeness, and miserliness to workers, business partners, and even family and friends.&lt;/p&gt;
    &lt;p&gt;We've known for years that Jobs initially denied being Brennan-Jobs' father and didn't start paying child support until after a DNA test proved he was and a court ordered him to start paying. We've also known that he denied for years that Apple's Lisa computer, which debuted right before the Macintosh, was named for his daughter — before finally acknowledging it to her and the world.&lt;/p&gt;
    &lt;p&gt;But Brennan-Jobs' book adds fresh details. He rarely saw her when she was a young child, she says, even after admitting his paternity. While he was avoiding her and avoiding paying child support — despite already having founded and been making money at Apple — she and her mother lived in poverty, subsisting on welfare payments, her mother's low-paying jobs, and the charity of others. When he was finally forced to pay child support, he made sure that the case against him was closed days before Apple went public and he became a multimillionaire.&lt;/p&gt;
    &lt;p&gt;Even after Jobs started paying more attention to Brennan-Jobs, her mother, Chrisann Brennan, apparently felt uncomfortable leaving him with her alone after an incident in which he was said to have questioned and teased the then-9-year-old Brennan-Jobs about her sexual attractions and proclivities.&lt;/p&gt;
    &lt;p&gt;'We're cold people'&lt;/p&gt;
    &lt;p&gt;Then, when Brennan-Jobs went to live with him as a teenager, she says, he forbade her from seeing Brennan for six months, even though her mother had been the only constant figure in her life up to then. After moving in with them, Brennan-Jobs told him and her stepmother, Laurene Powell Jobs, that she felt lonely and asked that they tell her goodnight in the evenings. Instead of acknowledging her feelings and acceding to such a simple request, Powell Jobs apparently responded, "We're cold people."&lt;/p&gt;
    &lt;p&gt;Steve Jennings / Stringer / Getty ImagesBut there's more. Once, she says, as Jobs groped his wife and pretended to be having sex with her, he demanded that Brennan-Jobs stay in the room, calling it a "family moment." He repeatedly withheld money from her, told her that she would get "nothing" from his wealth — and even refused to install heat in her bedroom.&lt;/p&gt;
    &lt;p&gt;When she started to become active in her high school, getting involved in clubs and running for student government, Jobs — the one, again, who previously refused to acknowledge his paternity and spent almost no time with her when she was little — apparently got on Brennan-Jobs for not spending more time with the family, telling her: "This isn't working out. You're not succeeding as a member of this family."&lt;/p&gt;
    &lt;p&gt;At one point, neighbors of the family were so worried about Brennan-Jobs that they helped her move into their house. They also helped her pay for college.&lt;/p&gt;
    &lt;p&gt;It's bad to treat employees and significant others poorly. But it's really evil to inflict such pain on a child. We knew Jobs was a bully toward many people. Now, it seems, we know he was one to his own daughter.&lt;/p&gt;
    &lt;p&gt;Brennan-Jobs comes across as a survivor of abuse&lt;/p&gt;
    &lt;p&gt;These are only excerpts from the book, which goes on sale September 4, so we don't have the full picture. And of course, they're the recollections of one person, with all the emotional baggage and bias that entails. Powell Jobs and Jobs' sister have said in a statement that the book "differs dramatically from our memories of those times."&lt;/p&gt;
    &lt;p&gt;But in her book, Brennan-Jobs brings up these incidents not to condemn Jobs but to make peace with them and him. She aims to forgive him and move on.&lt;/p&gt;
    &lt;p&gt;That's her choice and her right. But, as others have pointed out, what she endured was something many people would now consider child abuse — the intentional infliction of emotional cruelty. And in trying to find a way to forgive and understand him, she is reacting similarly to other survivors.&lt;/p&gt;
    &lt;p&gt;Tweet Embed: //twitter.com/mims/statuses/1032675971126751238?ref_src=twsrc%5Etfw This is a staggering tale of child abuse, and the fact that the author doesn't recognize the it and the reporter treats it as mercurial cruelness rather than the archetypal pattern of abuse is the saddest part of all.https://t.co/Hx1KuaKJsx Tweet Embed: //twitter.com/mims/statuses/1032737941162999808?ref_src=twsrc%5Etfw In ‘Small Fry,’ Steve Jobs Comes Across as a Jerk. His Daughter Forgives Him. Should We? https://t.co/BF02DBvwDB // Wow... "Jerk" is not the word. *Abuser* is the word. I understand this is her story to tell but... objectively this was a life of incredible abuse. Tweet Embed: //twitter.com/mims/statuses/1032731454130642944?ref_src=twsrc%5Etfw This is hard to read and walk away with what Brennan-Jobs wants you to. It depicts abuse and the victim coming up with reasons/excuses for it. https://t.co/lcsE4MbBk9&lt;/p&gt;
    &lt;p&gt;In trying to find a way to excuse her father, Brennan-Jobs is following a long line of people, all of whom are much more culpable than her for his behavior. Generally, the only way to get a bully to back off is to stand up to him and for others to do so on behalf of his targets; in Jobs' case, too few people did.&lt;/p&gt;
    &lt;p&gt;When it concerned his behavior toward Brennan-Jobs, his wife, Powell Jobs, clearly didn't stand up to him. When it concerned his behavior toward employees and business partners, his colleagues just as obviously didn't.&lt;/p&gt;
    &lt;p&gt;Jobs had remarkable achievements — and was unbelievably cruel&lt;/p&gt;
    &lt;p&gt;I don't know how the cosmic balancing stick weighs something as complicated as a person's life, but I do think Brennan-Jobs' book puts the other stories about Jobs, the ones about how he treated his employees, colleagues, and partners, in a different light. They make him seem less like a driven leader who was sometimes harsh to achieve his goals and more like a cruel person who succeeded because those around him accommodated and acquiesced to his awfulness.&lt;/p&gt;
    &lt;p&gt;Jobs is rightly praised for his role in resurrecting Apple. When he took charge, the company was a few months away from bankruptcy. When he left Apple right before his death, it already was the most important consumer-technology company in the world and was well on its way to becoming the behemoth it is now. Given the generally poor track record of corporate managers in turning around seemingly hopeless situations, it's quite possible that only Jobs could have saved Apple and put it on that path.&lt;/p&gt;
    &lt;p&gt;And that's no small achievement. In turning around the company, Jobs saved thousands of jobs and helped to create thousands more. He also made lots of people inside and outside the company very rich.&lt;/p&gt;
    &lt;p&gt;The positive side of Jobs' ledger also includes his role in creating some of the most influential products of the past 50 years — the iPhone, the Mac, the iPad, the iPod, and the original Apple computers. Maybe similar products could and would have been created without him. But there's no denying that he had a leading role in shaping how billions of people interact with technology, in many ways for the better.&lt;/p&gt;
    &lt;p&gt;We too often glorify business leaders and ignore their failings&lt;/p&gt;
    &lt;p&gt;Of course even those achievements are leavened by less laudable ones, such as his overseeing of Apple's outsourcing of thousands of factory jobs overseas and the convoluted contortions the company made to avoid paying taxes. He also headed the company and personally benefited when it backdated stock options to make them more valuable but let other executives take the fall. Oh, and he repeatedly yelled at employees and publicly embarrassed them.&lt;/p&gt;
    &lt;p&gt;In the end, did his business achievements outweigh the cruelty he inflicted on others? I don't know.&lt;/p&gt;
    &lt;p&gt;I do know that we too often glorify business leaders for their achievements without taking a close look at who they are as human beings and how their actions — both personal and professional — affect those around them and the wider world. I also believe that focus on their accomplishments helps enables their bad behavior.&lt;/p&gt;
    &lt;p&gt;That certainly seemed to be the case with Steve Jobs.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finance.yahoo.com/news/memoir-steve-jobs-apos-daughter-133000491.html"/><published>2026-01-08T20:42:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46546188</id><title>Texas First State to End American Bar Association oversight of law schools</title><updated>2026-01-08T21:11:34.348391+00:00</updated><content>&lt;doc fingerprint="a68db95d2120e66f"&gt;
  &lt;main&gt;
    &lt;p&gt;Texas is now the first state in the U.S. to eliminate American Bar Association oversight of its law schools, ending the state's 42-year-long reliance on the national organization.&lt;/p&gt;
    &lt;p&gt;The Texas Supreme Court issued an order Tuesday finalizing a tentative September opinion, asserting the ABA should "no longer have the final say" on which law school graduates can take the bar exam — a requirement to becoming a licensed lawyer in each state.&lt;/p&gt;
    &lt;p&gt;"The Court advised that it intends to provide stability, certainty, and flexibility to currently approved law schools by guaranteeing ongoing approval to schools that satisfy a set of simple, objective, and ideologically neutral criteria using metrics no more onerous than those currently required by the ABA," reads the order signed by all nine justices.&lt;/p&gt;
    &lt;p&gt;The change means law school graduates who want to practice in Texas are no longer required to attend an ABA-accredited school. The power to approve those law schools now rests solely with the state's highest civil court.&lt;/p&gt;
    &lt;p&gt;In the absence of national guidance, however, the Texas Supreme Court stipulated in Tuesday's order that it intends to preserve graduates' ability to use Texas law school degrees in other states and out-of-state law degrees in Texas. The court also doesn't anticipate immediate changes to the current list of approved law schools and could return to relying on a different multi-state accrediting entity in the future.&lt;/p&gt;
    &lt;p&gt;The ABA, a voluntary professional association for lawyers, has accredited law schools across the country since 1923. That means schools must comply with the ABA's standards for its faculty, curriculum and facilities, provide adequate resources for student support, demonstrate a commitment to diversity and inclusion and have successful bar passage rates among graduates. Not all law schools are ABA-approved.&lt;/p&gt;
    &lt;p&gt;The Texas Supreme Court decided which law schools would satisfy law licensure requirements until 1983, when the court gave that responsibility to the ABA.&lt;/p&gt;
    &lt;p&gt;The high court first signaled it wanted to cut ties with the ABA in April and invited comments from the Texas Board of Law Examiners, Texas law school deans, the State Bar and the public. The court tentatively decided in September to do away with ABA accreditation, and the public comment period for that decision Dec. 1.&lt;/p&gt;
    &lt;p&gt;The all-Republican court hasn't given a reason for initiating the change, but it came after months of conflict between President Donald Trump, the ABA and the broader legal community.&lt;/p&gt;
    &lt;p&gt;Trump issued an executive order earlier this year that stripped the ABA of millions in USAID and U.S. State Department funding. The ABA and others sued in February, alleging the administration violated administrative law.&lt;/p&gt;
    &lt;p&gt;Attorney General Pam Bondi sent a letter to the ABA later that month alleging its diversity requirements conflicted with the 2023 U.S. Supreme Court decision ending affirmative action in college admissions. The letter also threatened to take away the ABA's ability to accredit law schools.&lt;/p&gt;
    &lt;p&gt;The ABA issued a statement in March criticizing the Trump administration's actions amid calls to impeach judges over rulings and an executive order targeting legal organizations for diversity, equity and inclusion initiatives — programs meant to address historical inequities in the workplace and academia.&lt;/p&gt;
    &lt;p&gt;Two FTC officials backed the Texas Supreme Court's move to end ABA accreditation in the state last month. In a letter to the court, the directors said the association has a monopoly over law school approval that has harmed competition and imposed restrictive and costly requirements.&lt;/p&gt;
    &lt;p&gt;FTC Chair Andrew Ferguson, a Biden appointee, banned FTC political appointees from associating with the ABA in February.&lt;/p&gt;
    &lt;p&gt;Deans from eight of the state's 10 ABA-accredited law schools opposed abandoning the accreditation system in July, arguing the move would hurt lawyer mobility and increase costs.&lt;/p&gt;
    &lt;p&gt;The dean of the University of Texas School of Law notably didn't sign on to the letter and instead encouraged the Texas Supreme Court to explore alternatives to current ABA accreditation.&lt;/p&gt;
    &lt;p&gt;This isn't the first time ABA accreditation power has been scrutinized. The Department of Justice came to a settlement with the ABA in 1995 after the DOJ's antitrust division sued the association for allegedly using its power to protect faculties' economic interests and working conditions.&lt;/p&gt;
    &lt;p&gt;Florida, Ohio and Tennessee are also considering parting ways with the ABA.&lt;/p&gt;
    &lt;p&gt;Toluwani Osibamowo is KERA’s law and justice reporter. Got a tip? Email Toluwani at tosibamowo@kera.org.&lt;/p&gt;
    &lt;p&gt;KERA News is made possible through the generosity of our members. If you find this reporting valuable, consider making a tax-deductible gift today. Thank you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.keranews.org/news/2026-01-06/texas-supreme-court-ends-american-bar-association-law-school-accreditation"/><published>2026-01-08T20:44:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46546413</id><title>Mux (YC W16) is hiring a platform engineer that cares about (internal) DX</title><updated>2026-01-08T21:11:34.090770+00:00</updated><content/><link href="https://www.mux.com/jobs"/><published>2026-01-08T21:01:36+00:00</published></entry></feed>