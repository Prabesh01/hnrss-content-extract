<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-07T20:10:42.659460+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45502543</id><title>Erlang ARM32 JIT is born</title><updated>2025-10-07T20:10:58.911599+00:00</updated><content>&lt;doc fingerprint="ea279a502acd05f8"&gt;
  &lt;main&gt;
    &lt;p&gt;A blog series recounting our adventures in the quest to port the BEAM JIT to the ARM32-bit architecture.&lt;/p&gt;
    &lt;p&gt;This work is made possible thanks to funding from the Erlang Ecosystem Foundation and the ongoing support of its Embedded Working Group.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Erlang ARM32 JIT is born!&lt;/head&gt;
    &lt;p&gt;This week we finally achieved our first milestone in developing the ARM32 JIT. We executed our first Erlang function through JITted ARM32 machine code!&lt;/p&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/arm32-jit/otp/RELEASE -progname erl -home /home
    ~/arm32-jit$ echo $?
    42&lt;/code&gt;
    &lt;p&gt;The BEAM successfully runs and terminates with error code 42! That 42 comes from an Erlang function, just-in-time compiled by our ARM32 JIT!&lt;/p&gt;
    &lt;p&gt;Announcement is done! All code is available at https://github.com/stritzinger/otp/tree/arm32-jit&lt;/p&gt;
    &lt;p&gt;Keep reading for a lot of interesting details!&lt;/p&gt;
    &lt;head rend="h2"&gt;The first piece of Erlang code&lt;/head&gt;
    &lt;code&gt;-module(hello).
-export([start/2]).

start(_BootMod, _BootArgs) -&amp;gt;
    halt(42, [{flush, false}]).&lt;/code&gt;
    &lt;p&gt;This is &lt;code&gt;hello.erl&lt;/code&gt; that contains a &lt;code&gt;start/2&lt;/code&gt; function. The function head mimics the &lt;code&gt;erl_init:start/2&lt;/code&gt; function, which is the entry point of the first Erlang process. We replaced &lt;code&gt;erl_init:start/2&lt;/code&gt; with &lt;code&gt;hello:start/2&lt;/code&gt; in the &lt;code&gt;erl_init.c&lt;/code&gt; module of the BEAM VM. This way, we forced the runtime to execute this Erlang function.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;hello:start/2&lt;/code&gt; is very simple as it just calls the &lt;code&gt;erlang:halt/2&lt;/code&gt;. This function is a BIF (Built-in Function) that executes C code, part of the BEAM VM. This code executes an ordered shutdown of the BEAM and allows us to customize the error code, in this case: &lt;code&gt;42&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;(Why &lt;code&gt;{flush, false}&lt;/code&gt;? At the time I am writing this, letting it be true causes a segmentation fault EHEH)&lt;/p&gt;
    &lt;p&gt;Obviously, we need to compile this Erlang module, but I will also generate the BEAM assembly so we can have a look at what we will have to deal with.&lt;/p&gt;
    &lt;code&gt;{module, hello}.  %% version = 0
{exports, [{module_info,0},{module_info,1},{start,2}]}.
{attributes, []}.
{labels, 7}.

{function, start, 2, 2}.
  {label,1}.
    {line,[{location,"erts/preloaded/src/hello.erl",74}]}.
    {func_info,{atom,hello},{atom,start},2}.
  {label,2}.
    {move,{literal,[{flush,false}]},{x,1}}.
    {move,{integer,42},{x,0}}.
    {line,[{location,"erts/preloaded/src/hello.erl",76}]}.
    {call_ext_only,2,{extfunc,erlang,halt,2}}.

{function, module_info, 0, 4}.
  {label,3}.
    {line,[]}.
    {func_info,{atom,hello},{atom,module_info},0}.
  {label,4}.
    {move,{atom,hello},{x,0}}.
    {call_ext_only,1,{extfunc,erlang,get_module_info,1}}.

{function, module_info, 1, 6}.
  {label,5}.
    {line,[]}.
    {func_info,{atom,hello},{atom,module_info},1}.
  {label,6}.
    {move,{x,0},{x,1}}.
    {move,{atom,hello},{x,0}}.
    {call_ext_only,2,{extfunc,erlang,get_module_info,2}}.&lt;/code&gt;
    &lt;p&gt;You can spot the start function and the two standard module_info functions that all Erlang modules have. We do not care much about those right now as we discovered that they are not executed and are not required to work, for now.&lt;/p&gt;
    &lt;p&gt;We can see that the core of the start function is just two &lt;code&gt;move&lt;/code&gt; operations and one &lt;code&gt;call_ext_only&lt;/code&gt;. But bear in mind that the BEAM loader will transmute these Generic BEAM Operations into Specific operations. More complexity will pop up!&lt;/p&gt;
    &lt;head rend="h2"&gt;Execution&lt;/head&gt;
    &lt;p&gt;We are using &lt;code&gt;qemu-arm&lt;/code&gt; to emulate &lt;code&gt;Arm32&lt;/code&gt; and we are directly using &lt;code&gt;beam.smp&lt;/code&gt; to run the BEAM.&lt;/p&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/vagrant/arm32-jit/otp/RELEASE -progname erl -home /home/vagrant&lt;/code&gt;
    &lt;head rend="h3"&gt;JIT initialization&lt;/head&gt;
    &lt;p&gt;At boot, the BEAM initializes the JIT if enabled. The JIT leverages the AsmJit library to emit all machine code instructions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Emission of all global shared fragments&lt;/head&gt;
    &lt;p&gt;There are 90+ code snippets that are shared among all modules. The JIT loads them one single time and sets up jumps to them in every other module. It is like a global library for all modules.&lt;/p&gt;
    &lt;p&gt;We skipped most of these because just the shared fragments involved in the &lt;code&gt;hello:start/2&lt;/code&gt; execution were needed.&lt;/p&gt;
    &lt;head rend="h4"&gt;Emission of the erts_beamasm module&lt;/head&gt;
    &lt;p&gt;As part of the JIT initialization, &lt;code&gt;erts_beamasm&lt;/code&gt; is emitted. This module is an internal hardcoded module that exists only when BEAM is using the JIT. It holds 7 fundamental instructions used to manage the Erlang process executions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;run_process - The main process execution entry point&lt;/item&gt;
      &lt;item&gt;normal_exit - Normal process termination&lt;/item&gt;
      &lt;item&gt;continue_exit - Continue after exit handling&lt;/item&gt;
      &lt;item&gt;exception_trace - Exception tracing functionality&lt;/item&gt;
      &lt;item&gt;return_trace - Return value tracing&lt;/item&gt;
      &lt;item&gt;return_to_trace - Return to tracing state&lt;/item&gt;
      &lt;item&gt;call_trace_return - Call tracing return handling&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Preloaded modules&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;hello.erl&lt;/code&gt; module has been compiled and put as first and single Erlang module in the list of preloaded modules. Preloaded modules are Erlang fundamental modules that are always loaded by the BEAM before the first Erlang process can start. They implement, in Erlang, the core features of the Erlang Runtime System (ERTS). The OTP build scripts group all &lt;code&gt;ebin&lt;/code&gt; files into a single C header that is then linked into the executable. This makes the Erlang binaries available as a static C array in the BEAM source code. These are then loaded one by one after the BEAM VM is initialized.&lt;/p&gt;
    &lt;p&gt;Cool, let's nuke all these modules and leave just our &lt;code&gt;hello.erl&lt;/code&gt;. It does not need many BEAM instructions and we can easily verify that it executes. To do the substitution we just need to change this build variable in otp/erts/emulator/Makefile.in&lt;/p&gt;
    &lt;p&gt;We are running BEAMASM with &lt;code&gt;-JDdump true&lt;/code&gt; so &lt;code&gt;asmjit&lt;/code&gt; will dump all ARM32 assembly for each module! This is incredibly useful if monitored while executing with a debugger, as we can see the assembler being printed line by line by our code.&lt;/p&gt;
    &lt;code&gt;~/arm32-jit$ cat hello.asm 
L6:
.byte 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_1:
# i_func_info_IaaI
# hello:start/2
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x0B, 0xA4, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00
# aligned_label_Lt
start/2:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L9
    bl L11
L9:
# i_test_yield
    adr r2, start/2
    subs r9, r9, 1
    b.le L13
# i_move_sd
    ldr r12, [L14]
    str r12, [r4, 68]
# i_move_sd
    movw r12, 687
    str r12, [r4, 64]
# line_I
# allocate_tt
# call_light_bif_be
L15:
    ldr r3, [L16]
    movw r1, 10188
    movt r1, 16432
    adr r2, L15
# BIF: erlang:halt/2
    sub r12, r7, 4
    cmp r10, r12
    b.ls L17
    udf 48879
L17:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L18
    udf 57005
L18:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_3:
# i_func_info_IaaI
# hello:module_info/0
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x4B, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
# aligned_label_Lt
module_info/0:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L23
    bl L11
L23:
# i_test_yield
    adr r2, module_info/0
    subs r9, r9, 1
    b.le L13
# i_move_sd
    movw r12, 20235
    str r12, [r4, 64]
# allocate_tt
# call_light_bif_be
L24:
    ldr r3, [L25]
    movw r1, 4772
    movt r1, 16425
    adr r2, L24
# BIF: erlang:get_module_info/1
    sub r12, r7, 4
    cmp r10, r12
    b.ls L26
    udf 48879
L26:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L27
    udf 57005
L27:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_5:
# i_func_info_IaaI
# hello:module_info/1
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x4B, 0x6B, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00
# aligned_label_Lt
module_info/1:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L28
    bl L11
L28:
# i_test_yield
    adr r2, module_info/1
    subs r9, r9, 1
    b.le L13
# i_move_sd
    ldr r12, [r4, 64]
    str r12, [r4, 68]
# i_move_sd
    movw r12, 20235
    str r12, [r4, 64]
# allocate_tt
# call_light_bif_be
L29:
    ldr r3, [L30]
    movw r1, 4868
    movt r1, 16425
    adr r2, L29
# BIF: erlang:get_module_info/2
    sub r12, r7, 4
    cmp r10, r12
    b.ls L31
    udf 48879
L31:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L32
    udf 57005
L32:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# int_code_end
L33:
    movw r0, 18576
    movt r0, 16480
    blx L22
L13:
L12:
    movw r12, 1968
    movt r12, 14656
    blx r12
L22:
L21:
    movw r12, 29192
    movt r12, 16399
    blx r12
L11:
L10:
    movw r12, 1752
    movt r12, 14656
    blx r12
L20:
L19:
    movw r12, 680
    movt r12, 14656
    blx r12
L8:
L7:
    movw r12, 1824
    movt r12, 14656
    blx r12
# Begin stub section
L14:
.xword 0x000000007FFFFFFF
L16:
.xword 0x000000007FFFFFFF
L25:
.xword 0x000000007FFFFFFF
L30:
.xword 0x000000007FFFFFFF
# End stub section
L34:
.section .rodata {#1}
md5:
.byte 0x6D, 0xC4, 0x1E, 0xF1, 0x13, 0x1E, 0xBF, 0xF2, 0x4B, 0xF5, 0xC0, 0x41, 0x57, 0x86, 0xDF, 0xD5
.section .text {#0}
; CODE_SIZE: 632&lt;/code&gt;
    &lt;p&gt;Bear in mind, this assembler is not what hello should look like. We are missing a lot of things.&lt;/p&gt;
    &lt;p&gt;You can spot many sequences like:&lt;/p&gt;
    &lt;code&gt;    movw r0, 64676
    movt r0, 16480
    blx L22 # &amp;lt;---- branch to NYI&lt;/code&gt;
    &lt;p&gt;This is a call to &lt;code&gt;nyi&lt;/code&gt; (Not Yet Implemented) function and the argument loaded to R0 is the pointer to a string that contains the name of the BEAM instruction that should have been emitted instead. You can spot many of these since we are only emitting the code to reach halt. Everything after that is not important now as halt will never return!&lt;/p&gt;
    &lt;p&gt;There are many more comments we could make around all the details in this assembler dump, but let's move on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jumping into Jitted code!&lt;/head&gt;
    &lt;p&gt;Later in the BEAM initialization the first Erlang process will be allocated and started.&lt;/p&gt;
    &lt;p&gt;We swap the module and function with hello in erts/emulator/beam/erl_init.c&lt;/p&gt;
    &lt;code&gt;    erl_spawn_system_process(&amp;amp;parent, am_hello, am_start, args, &amp;amp;so);&lt;/code&gt;
    &lt;p&gt;One BEAM scheduler thread will jump to the &lt;code&gt;process_main&lt;/code&gt; function. You can find it here in the source code. This is emitted by our JIT and is the first emitted code that will run.&lt;/p&gt;
    &lt;p&gt;Here we need to handle the Erlang processes scheduling by calling BEAM routines that implement the algorithms of Erlang concurrency, like &lt;code&gt;erts_schedule&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;erts_schedule&lt;/code&gt; will return the pointer to the &lt;code&gt;Process&lt;/code&gt; C structure that holds all information about the process that is going to execute. We then load all necessary data inside registers and then we branch to the exact point where the program execution stopped.&lt;/p&gt;
    &lt;head rend="h3"&gt;The first Erlang function call&lt;/head&gt;
    &lt;p&gt;In this case we are calling &lt;code&gt;hello:start/2&lt;/code&gt; so the first instruction to execute is &lt;code&gt;apply_only&lt;/code&gt; that does a few things but ends up calling the C &lt;code&gt;apply&lt;/code&gt; routine.&lt;/p&gt;
    &lt;p&gt;The routine processes the Module-Function-Arity information to get the address where the function code resides in memory.&lt;/p&gt;
    &lt;p&gt;What follows is the Erlang function prologue. You can see it in the assembler code section above. For example, all functions have these instructions in their prologue:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;i_breakpoint_trampoline: handle breakpoints for the &lt;code&gt;debugger&lt;/code&gt;app&lt;/item&gt;
      &lt;item&gt;i_test_yield: checks if the function should yield and go back to the scheduler&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We have minimal or partial implementations of these since we do not really need them. We have to emit them though, as the C++ generated loader functions from the BEAM are expanding the Erlang function call Operation into a more specific and complex function prologue sequence.&lt;/p&gt;
    &lt;p&gt;After that, we added support for the &lt;code&gt;call_light_bif&lt;/code&gt; operation that precedes the call to the halt_2 BIF routine. This implementation is also minimal.&lt;/p&gt;
    &lt;p&gt;Question for later: did you notice that we put a &lt;code&gt;42&lt;/code&gt; as a number in the code? Numeric constants are printed as decimals in the dump, but we cannot spot any 42!?&lt;/p&gt;
    &lt;p&gt;After the call, we see two other operations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;dealloc&lt;/item&gt;
      &lt;item&gt;return&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are just calls to NYI as we will never reach this code! So for now, we can skip them...&lt;/p&gt;
    &lt;head rend="h3"&gt;Let's roll the JIT!&lt;/head&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/arm32-jit/otp/RELEASE -progname erl -home /home
    ~/arm32-jit$&lt;/code&gt;
    &lt;p&gt;Impressive, the program returns immediately without even saying "Hi" ... and without Segmentation Fault!!&lt;/p&gt;
    &lt;p&gt;But let's check the program return code!&lt;/p&gt;
    &lt;code&gt;~/arm32-jit$ echo $?
42
&lt;/code&gt;
    &lt;p&gt;We can safely say that number is not there by accident! This is a great achievement as from now on we will be able to incrementally add Erlang instructions.&lt;/p&gt;
    &lt;p&gt;Every Erlang line we add will trigger new Opcodes. By emitting them and running the code we will have immediate feedback on everything.&lt;/p&gt;
    &lt;p&gt;The next goal now is to complete the &lt;code&gt;hello&lt;/code&gt; module to host all possible beam instructions!&lt;/p&gt;
    &lt;head rend="h4"&gt;Hey where is 42???&lt;/head&gt;
    &lt;p&gt;One interesting thing I spotted looking at the assembly: You cannot find the number &lt;code&gt;42&lt;/code&gt; in there. Or actually, you can, it is just hidden in plain sight. To understand you need to know how we are using ARM32 registers.&lt;/p&gt;
    &lt;p&gt;In particular the register &lt;code&gt;r4&lt;/code&gt;, a callee-saved register. We are using it to store the pointer to the &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt; struct. The &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt; contains the X register array. When a function is called, X registers are used to store the arguments of the call.&lt;/p&gt;
    &lt;p&gt;This becomes more obvious if we compare the Erlang assembly to the Arm32 assembly.&lt;/p&gt;
    &lt;code&gt;# i_move_sd                       &amp;lt;---- {move,{literal,[{flush,false}]},{x,1}}. % List at X[1]
    ldr r12, [L14]
    str r12, [r4, 68]
# i_move_sd                       &amp;lt;---- {move,{integer,42},{x,0}}. % 42 at X[0]
    movw r12, 687 
    str r12, [r4, 64]
# line_I
# allocate_tt
# call_light_bif_be
L15:
    ldr r3, [L16]
    movw r1, 10188
    movt r1, 16432
    adr r2, L15
# BIF: erlang:halt/2
# ...&lt;/code&gt;
    &lt;p&gt;42 is stored at &lt;code&gt;r4&lt;/code&gt;+64.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;r4: pointer to the &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt;struct&lt;/item&gt;
      &lt;item&gt;64: base offset from the beginning of the struct to the beginning of the &lt;code&gt;x_reg_array&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The list is stored at &lt;code&gt;r4&lt;/code&gt;+68.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;68: is the base offset + the size of one &lt;code&gt;Eterm&lt;/code&gt;(4 bytes on ARM32)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But why in assembly do we see 687 and not 42?&lt;/p&gt;
    &lt;p&gt;Converting both numbers to hex we get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;42 -&amp;gt; 2A&lt;/item&gt;
      &lt;item&gt;687 -&amp;gt; 2AF !!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yep, this is an example of a Tagged Value. If we consult the BEAM book we can learn about the Tagging Scheme:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;00 11 Pid&lt;/item&gt;
      &lt;item&gt;01 11 Port&lt;/item&gt;
      &lt;item&gt;10 11 Immediate 2&lt;/item&gt;
      &lt;item&gt;11 11 Small integer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;42 is tagged with &lt;code&gt;1111&lt;/code&gt; at the low end. So the BEAM can quickly recognize during a pattern match that this Erlang Term is a Small Integer!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3"/><published>2025-10-07T13:00:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45502784</id><title>Tcl-Lang Showcase</title><updated>2025-10-07T20:10:58.436656+00:00</updated><content>&lt;doc fingerprint="598b77957e6a418d"&gt;
  &lt;main&gt;&lt;p&gt;Canvas3d&lt;/p&gt;Canvas3d wiki page&lt;p&gt;HP-15 Simulation&lt;/p&gt;HP-15 Simulation wiki page&lt;p&gt;By clicking on the image, an interactive demonstration of the Tcl/Tk application is launched using CloudTk. Over 100 Tcl/Tk applications listed from this wiki are demonstrated here . To view the Tcl/Tk Widget Demonstration, go to the "Playground" from the menu above and then select "Demos" in the "Tcl-Playground" - Console menu.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wiki.tcl-lang.org/page/Showcase"/><published>2025-10-07T13:25:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504127</id><title>Show HN: MARS – Personal AI robot for builders (&lt; $2k)</title><updated>2025-10-07T20:10:57.907695+00:00</updated><content>&lt;doc fingerprint="f1df9a7b68a781cd"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey, we’re Axel and Vignesh, cofounders of Innate (&lt;/p&gt;https://www.innate.bot/&lt;p&gt;). We just launched MARS, a general-purpose robot with an open onboard agentic OS built on top of ROS2.&lt;/p&gt;&lt;p&gt;Overview: https://youtu.be/GEOMYDXv6pE&lt;/p&gt;&lt;p&gt;Control demo: https://youtu.be/_Cw5fGa8i3s&lt;/p&gt;&lt;p&gt;Videos of autonomous use-cases: https://docs.innate.bot/welcome/mars-example-use-cases&lt;/p&gt;&lt;p&gt;Quickstart: https://docs.innate.bot/welcome/mars-quick-start.&lt;/p&gt;&lt;p&gt;Our last thread: https://news.ycombinator.com/item?id=42451707&lt;/p&gt;&lt;p&gt;When we started we felt there is currently no good affordable general-purpose that anyone can build on. There’s no lack of demand: hugging face’s SO-100 and LeKiwi are pretty clear successes already; but the hardware is unreliable, the software experience is barebone and keeps changing, and you often need to buy hidden extras to make them work (starting with a computer with a good gpu). The Turtlebots were good, but are getting outdated.&lt;/p&gt;&lt;p&gt;The open-source hobbyist movement lacks really good platforms to build on, and we wanted something robust and accessible. MARS is our attempt at making a first intuitive AI robot for everyone.&lt;/p&gt;&lt;p&gt;What it is:&lt;/p&gt;&lt;p&gt;- It comes assembled and calibrated&lt;/p&gt;&lt;p&gt;- Has onboard compute with a jetson orin nano 8gb&lt;/p&gt;&lt;p&gt;- a 5DoF arm with a wrist camera&lt;/p&gt;&lt;p&gt;- Sensors: RGBD wide-angle cam, 2D LiDAR, speakers&lt;/p&gt;&lt;p&gt;- Control via a dedicated app and a leader arm that plugs in iPhone and Android&lt;/p&gt;&lt;p&gt;- 2 additional USB ports + GPIO pins for extra sensors or effectors.&lt;/p&gt;&lt;p&gt;- And our novel SDK called BASIC that allows to run it like an AI agent with VLAs.&lt;/p&gt;&lt;p&gt;It boots in a minute, can be controlled via phone, programmable in depth with a PC, and the onboard agent lets it see, talk, plan, and act in real-time.&lt;/p&gt;&lt;p&gt;Our SDK BASIC allows to create “behaviors” (our name for programs) ranging from a simple hello world to a very complex long-horizon task involving reasoning, planning, navigation and manipulation. You can create skills that behaviors can run autonomously by training the arm or writing code tools, like for an AI agent.&lt;/p&gt;&lt;p&gt;You can also call the ROS2 topics to control the robot at a low-level. And anything created on top of this SDK can be easily shared with anyone else by just sharing the files.&lt;/p&gt;&lt;p&gt;This is intended for hobbyist builders and education, and we would love to have your feedback!&lt;/p&gt;&lt;p&gt;p.s. If you want to try it, there’s a temporary code HACKERNEWS-INNATE-MARS that lowers the price to $1,799.&lt;/p&gt;&lt;p&gt;p.p.s The hardware and software will be open-sourced too, if some of you want to contribute or help us prepare it properly feel free to join our discord at https://discord.gg/YvqQbGKH&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45504127"/><published>2025-10-07T15:11:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504388</id><title>Launch HN: LlamaFarm (YC W22) – Open-source framework for distributed AI</title><updated>2025-10-07T20:10:55.746402+00:00</updated><content>&lt;doc fingerprint="ed1fa4511bbd11f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Build powerful AI locally, extend anywhere.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;LlamaFarm is an open-source framework for building retrieval-augmented and agentic AI applications. It ships with opinionated defaults (Ollama for local models, Chroma for vector storage) while staying 100% extendable—swap in vLLM, remote OpenAI-compatible hosts, new parsers, or custom stores without rewriting your app.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first developer experience with a single CLI (&lt;code&gt;lf&lt;/code&gt;) that manages projects, datasets, and chat sessions.&lt;/item&gt;
      &lt;item&gt;Production-ready architecture that mirrors server endpoints and enforces schema-based configuration.&lt;/item&gt;
      &lt;item&gt;Composable RAG pipelines you can tailor through YAML, not bespoke code.&lt;/item&gt;
      &lt;item&gt;Extendable everything: runtimes, embedders, databases, extractors, and CLI tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;📺 Video demo (90 seconds): https://youtu.be/W7MHGyN0MdQ&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install the CLI&lt;/p&gt;
        &lt;p&gt;macOS / Linux&lt;/p&gt;
        &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/llama-farm/llamafarm/main/install.sh | bash&lt;/code&gt;
        &lt;p&gt;Windows (via winget)&lt;/p&gt;
        &lt;code&gt;winget install LlamaFarm.CLI&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adjust Ollama context window&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Open the Ollama app, go to Settings → Advanced, and set the context window to match production (e.g., 100K tokens).&lt;/item&gt;
          &lt;item&gt;Larger context windows improve RAG answers when long documents are ingested.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create and run a project&lt;/p&gt;
        &lt;quote&gt;lf init my-project # Generates llamafarm.yaml using the server template lf start # Spins up Docker services &amp;amp; opens the dev chat UI&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start an interactive project chat or send a one-off message&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Interactive project chat (auto-detects namespace/project from llamafarm.yaml)
lf chat

# One-off message
lf chat "Hello, LlamaFarm!"&lt;/code&gt;
    &lt;p&gt;Need the full walkthrough with dataset ingestion and troubleshooting tips? Jump to the Quickstart guide.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Prefer building from source? Clone the repo and follow the steps in Development &amp;amp; Testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run services manually (without Docker auto-start):&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/llama-farm/llamafarm.git
cd llamafarm

# Install Nx globally and bootstrap the workspace
npm install -g nx
nx init --useDotNxInstallation --interactive=false

# Option 1: start both server and RAG worker with one command
nx dev

# Option 2: start services in separate terminals
# Terminal 1
nx start rag
# Terminal 2
nx start server&lt;/code&gt;
    &lt;p&gt;Open another terminal to run &lt;code&gt;lf&lt;/code&gt; commands (installed or built from source). This is equivalent to what &lt;code&gt;lf start&lt;/code&gt; orchestrates automatically.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Own your stack – Run small local models today and swap to hosted vLLM, Together, or custom APIs tomorrow by changing &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Battle-tested RAG – Configure parsers, extractors, embedding strategies, and databases without touching orchestration code.&lt;/item&gt;
      &lt;item&gt;Config over code – Every project is defined by YAML schemas that are validated at runtime and easy to version control.&lt;/item&gt;
      &lt;item&gt;Friendly CLI – &lt;code&gt;lf&lt;/code&gt;handles project bootstrapping, dataset lifecycle, RAG queries, and non-interactive chats.&lt;/item&gt;
      &lt;item&gt;Built to extend – Add a new provider or vector store by registering a backend and regenerating schema types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Initialize a project&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf init my-project&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Creates &lt;code&gt;llamafarm.yaml&lt;/code&gt; from server template.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Start dev stack + chat TUI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf start&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Spins up server, rag worker, monitors Ollama/vLLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Interactive project chat&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opens TUI using project from &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Send single prompt&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat "Explain retrieval augmented generation"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Uses RAG by default; add &lt;code&gt;--no-rag&lt;/code&gt; for pure LLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Preview REST call&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat --curl "What models are configured?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Prints sanitized &lt;code&gt;curl&lt;/code&gt; command.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Create dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets create -s pdf_ingest -b main_db research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validates strategy/database against project config.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Upload files&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets upload research-notes ./docs/*.pdf&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Supports globs and directories.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Process dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets process research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Streams heartbeat dots during long processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Semantic query&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf rag query --database main_db "What did the 2024 FDA letters require?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use &lt;code&gt;--filter&lt;/code&gt;, &lt;code&gt;--include-metadata&lt;/code&gt;, etc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See the CLI reference for full command details and troubleshooting advice.&lt;/p&gt;
    &lt;p&gt;LlamaFarm provides a comprehensive REST API (compatible with OpenAI's format) for integrating with your applications. The API runs at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Chat Completions (OpenAI-compatible)&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What are the FDA requirements?"}
    ],
    "stream": false,
    "rag_enabled": true,
    "database": "main_db"
  }'&lt;/code&gt;
    &lt;p&gt;RAG Query&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "clinical trial requirements",
    "database": "main_db",
    "top_k": 5
  }'&lt;/code&gt;
    &lt;p&gt;Dataset Management&lt;/p&gt;
    &lt;code&gt;# Upload file
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/data \
  -F "file=@document.pdf"

# Process dataset
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/process&lt;/code&gt;
    &lt;p&gt;Check your &lt;code&gt;llamafarm.yaml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;name: my-project        # Your project name
namespace: my-org       # Your namespace&lt;/code&gt;
    &lt;p&gt;Or inspect the file system: &lt;code&gt;~/.llamafarm/projects/{namespace}/{project}/&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;See the complete API Reference for all endpoints, request/response formats, Python/TypeScript clients, and examples.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;llamafarm.yaml&lt;/code&gt; is the source of truth for each project. The schema enforces required fields and documents every extension point.&lt;/p&gt;
    &lt;code&gt;version: v1
name: fda-assistant
namespace: default

runtime:
  provider: openai                   # "openai" for any OpenAI-compatible host, "ollama" for local Ollama
  model: qwen2.5:7b
  base_url: http://localhost:8000/v1 # Point to vLLM, Together, etc.
  api_key: sk-local-placeholder
  instructor_mode: tools             # Optional: json, md_json, tools, etc.

prompts:
  - role: system
    content: &amp;gt;-
      You are an FDA specialist. Answer using short paragraphs and cite document titles when available.

rag:
  databases:
    - name: main_db
      type: ChromaStore
      default_embedding_strategy: default_embeddings
      default_retrieval_strategy: filtered_search
      embedding_strategies:
        - name: default_embeddings
          type: OllamaEmbedder
          config:
            model: nomic-embed-text:latest
      retrieval_strategies:
        - name: filtered_search
          type: MetadataFilteredStrategy
          config:
            top_k: 5
  data_processing_strategies:
    - name: pdf_ingest
      parsers:
        - type: PDFParser_LlamaIndex
          config:
            chunk_size: 1500
            chunk_overlap: 200
      extractors:
        - type: HeadingExtractor
        - type: ContentStatisticsExtractor

datasets:
  - name: research-notes
    data_processing_strategy: pdf_ingest
    database: main_db&lt;/code&gt;
    &lt;p&gt;Configuration reference: Configuration Guide • Extending LlamaFarm&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swap runtimes by pointing to any OpenAI-compatible endpoint (vLLM, Mistral, Anyscale). Update &lt;code&gt;runtime.provider&lt;/code&gt;,&lt;code&gt;base_url&lt;/code&gt;, and&lt;code&gt;api_key&lt;/code&gt;; regenerate schema types if you add a new provider enum.&lt;/item&gt;
      &lt;item&gt;Bring your own vector store by implementing a store backend, adding it to &lt;code&gt;rag/schema.yaml&lt;/code&gt;, and updating the server service registry.&lt;/item&gt;
      &lt;item&gt;Add parsers/extractors to support new file formats or metadata pipelines. Register implementations and extend the schema definitions.&lt;/item&gt;
      &lt;item&gt;Extend the CLI with new Cobra commands under &lt;code&gt;cli/cmd&lt;/code&gt;; the docs include guidance on adding dataset utilities or project tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the Extending guide for step-by-step instructions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
        &lt;cell role="head"&gt;What it Shows&lt;/cell&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FDA Letters Assistant&lt;/cell&gt;
        &lt;cell&gt;Multi-document PDF ingestion, RAG queries, reference-style prompts&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/fda_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Raleigh UDO Planning Helper&lt;/cell&gt;
        &lt;cell&gt;Large ordinance ingestion, long-running processing tips, geospatial queries&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/gov_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;lf datasets&lt;/code&gt; and &lt;code&gt;lf rag query&lt;/code&gt; commands from each example folder to reproduce the flows demonstrated in the docs.&lt;/p&gt;
    &lt;code&gt;# Python server + RAG tests
cd server
uv sync
uv run --group test python -m pytest

# CLI tests
cd ../cli
go test ./...

# RAG tooling smoke tests
cd ../rag
uv sync
uv run python cli.py test

# Docs build (ensures navigation/link integrity)
cd ..
nx build docs&lt;/code&gt;
    &lt;p&gt;Linting: &lt;code&gt;uv run ruff check --fix .&lt;/code&gt; (Python), &lt;code&gt;go fmt ./...&lt;/code&gt; and &lt;code&gt;go vet ./...&lt;/code&gt; (Go).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord – chat with the team, share feedback, find collaborators.&lt;/item&gt;
      &lt;item&gt;GitHub Issues – bug reports and feature requests.&lt;/item&gt;
      &lt;item&gt;Discussions – ideas, RFCs, roadmap proposals.&lt;/item&gt;
      &lt;item&gt;Contributing Guide – code style, testing expectations, doc updates, schema regeneration steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to add a new provider, parser, or example? Start a discussion or open a draft PR—we love extensions!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Licensed under the Apache 2.0 License.&lt;/item&gt;
      &lt;item&gt;Built by the LlamaFarm community and inspired by the broader open-source AI ecosystem. See CREDITS for detailed acknowledgments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build locally. Deploy anywhere. Own your AI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/llama-farm/llamafarm"/><published>2025-10-07T15:30:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504470</id><title>IKEA Catalogs 1951-2021</title><updated>2025-10-07T20:10:55.000644+00:00</updated><content>&lt;doc fingerprint="71c3125f48ed4455"&gt;
  &lt;main&gt;
    &lt;p&gt;Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA catalogue&lt;/head&gt;
    &lt;p&gt;For over 70 years, the IKEA catalogue was produced in Ãlmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s â the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1950s&lt;/item&gt;
      &lt;item&gt;1960s&lt;/item&gt;
      &lt;item&gt;1970s&lt;/item&gt;
      &lt;item&gt;1980s&lt;/item&gt;
      &lt;item&gt;1990s&lt;/item&gt;
      &lt;item&gt;2000s&lt;/item&gt;
      &lt;item&gt;2010s&lt;/item&gt;
      &lt;item&gt;2020s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and youâll be amazed at what you find. In fact, youâll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 yearsâ time, weâll probably shake our heads and give a sigh.&lt;/p&gt;
    &lt;p&gt;IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages.&lt;/p&gt;
    &lt;p&gt;No. The IKEA catalogue has always only shown a selection of whatâs available in the stores. The catalogues from the 1970s and onwards show around 30â50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.&lt;/p&gt;
    &lt;p&gt;Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, weâre happy to help you out if we can. But 70 years is a long time, so we canât promise anything. While youâre waiting for our response you can always browse through the catalogues â the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.&lt;lb/&gt; Browse through stories about IKEA products from 7 decades. &lt;/p&gt;
    &lt;p&gt;IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?&lt;lb/&gt; The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didnât sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikÃ©a-nytt (literally ikÃ©a news). Sometimes it was distributed as a supplement in farming paper Jordbrukarnas FÃ¶reningsblad, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikÃ©a-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, youâll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.&lt;lb/&gt; Browse through all issues of ikÃ©a-nytt.&lt;/p&gt;
    &lt;p&gt;Not really. We do have a few copies of each yearâs IKEA catalogue in our archives, which weâre saving for posterity. They should be handled as little as possible to keep them in good condition, so weâve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!&lt;/p&gt;
    &lt;p&gt;Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once youâve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.&lt;/p&gt;
    &lt;p&gt;Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as itâs not for commercial purposes). Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more.&lt;/p&gt;
    &lt;p&gt;Yes! You can find all press material, including images, information about current exhibitions and much more, in the IKEA Museum press room.&lt;/p&gt;
    &lt;p&gt;At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if youâve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.&lt;/p&gt;
    &lt;p&gt;Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ikeamuseum.com/en/explore/ikea-catalogue/"/><published>2025-10-07T15:35:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504973</id><title>Show HN: Timelinize – Privately organize your own data from everywhere, locally</title><updated>2025-10-07T20:10:54.441732+00:00</updated><content>&lt;doc fingerprint="e64842e6eda1dcc1"&gt;
  &lt;main&gt;
    &lt;p&gt;Timelinize ("time-lynn-eyes") is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.&lt;/p&gt;
    &lt;p&gt;Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.&lt;/p&gt;
    &lt;p&gt;By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.&lt;/p&gt;
    &lt;p&gt;Most apps store your data "in the cloud" and out of your control. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.&lt;/p&gt;
    &lt;p&gt;Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:&lt;/p&gt;
    &lt;p&gt;With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.&lt;/p&gt;
    &lt;p&gt;The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.&lt;/p&gt;
    &lt;p&gt;Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).&lt;/p&gt;
    &lt;p&gt;Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.&lt;/p&gt;
    &lt;p&gt;Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.&lt;/p&gt;
    &lt;p&gt;Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.&lt;/p&gt;
    &lt;p&gt;Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.&lt;/p&gt;
    &lt;p&gt;Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.&lt;/p&gt;
    &lt;p&gt;Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.&lt;/p&gt;
    &lt;p&gt;Customize the map to change its theme, layers, and even make it 3D.&lt;/p&gt;
    &lt;p&gt;The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.&lt;/p&gt;
    &lt;p&gt;Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.&lt;/p&gt;
    &lt;p&gt;An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.&lt;/p&gt;
    &lt;p&gt;Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:&lt;/p&gt;
    &lt;p&gt;Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.&lt;/p&gt;
    &lt;p&gt;For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.&lt;/p&gt;
    &lt;p&gt;Search for pictures and messages by describing them, or find similar items to what you're viewing.&lt;/p&gt;
    &lt;p&gt;All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.&lt;/p&gt;
    &lt;p&gt;The database schema has been meticulously designed and refined to be as adaptable as possible.&lt;/p&gt;
    &lt;p&gt;Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:&lt;/p&gt;
    &lt;p&gt;Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).&lt;/p&gt;
    &lt;p&gt;Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.&lt;/p&gt;
    &lt;p&gt;Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.&lt;/p&gt;
    &lt;p&gt;Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.&lt;/p&gt;
    &lt;p&gt;Collect your data from various sources. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.&lt;/p&gt;
    &lt;p&gt;Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.&lt;/p&gt;
    &lt;p&gt;Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.&lt;/p&gt;
    &lt;p&gt;Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://timelinize.com"/><published>2025-10-07T16:10:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505398</id><title>Cache-Friendly B+Tree Nodes with Dynamic Fanout</title><updated>2025-10-07T20:10:54.232418+00:00</updated><content>&lt;doc fingerprint="eafbc81bf4b08ea8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Cache-Friendly B+Tree Nodes With Dynamic Fanout&lt;/head&gt;&lt;p&gt;For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node's contents reside in the CPU cache.&lt;/p&gt;&lt;p&gt;In C++, achieving this means forgoing the use of &lt;code&gt;std::vector&lt;/code&gt;, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.&lt;/p&gt;&lt;code&gt;  +----------------------+&lt;/code&gt;&lt;head rend="h2"&gt;Challenges&lt;/head&gt;&lt;p&gt;Using &lt;code&gt;std::vector&lt;/code&gt; for a B+Tree node's entries is a non-starter. A &lt;code&gt;std::vector&lt;/code&gt; object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.&lt;/p&gt;&lt;p&gt;This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array's size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.&lt;/p&gt;&lt;p&gt;This isn't just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?&lt;/p&gt;&lt;p&gt;The solution isn't obvious, but it's a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.&lt;/p&gt;&lt;head rend="h2"&gt;The Struct Hack&lt;/head&gt;&lt;p&gt;The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.&lt;/p&gt;&lt;code&gt;struct Payload {&lt;/code&gt;&lt;p&gt;At runtime, when the required size &lt;code&gt;N&lt;/code&gt; is known, you allocate a single block of memory for the struct and the &lt;code&gt;N&lt;/code&gt; elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.&lt;/p&gt;&lt;code&gt;// The (N - 1) adjusts for the 1-element array in Payload struct&lt;/code&gt;&lt;p&gt;This pattern was officially standardized in C99, where it is known as a flexible array member.&lt;/p&gt;&lt;p&gt;The C++11 standard formally incorporates the flexible array member, referring to it as an array of unknown bound when it is the last member of a struct.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Arrays of unknown bound&lt;/p&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;expr&lt;/code&gt;is omitted in the declaration of an array, the type declared is "array of unknown bound of T", which is a kind of incomplete type, ...&lt;code&gt;extern int x[]; // the type of x is "array of unknown bound of int"&lt;/code&gt;&lt;lb/&gt;int a[] = {1, 2, 3}; // the type of a is "array of 3 int"&lt;/quote&gt;&lt;p&gt;This means that in C++, the size can be omitted from the final array declaration (e.g. &lt;code&gt;entries_[]&lt;/code&gt;), and the code will compile, enabling the same pattern.&lt;/p&gt;&lt;head rend="h2"&gt;B+Tree Node Declaration&lt;/head&gt;&lt;p&gt;Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;&lt;p&gt;Using a &lt;code&gt;std::vector&amp;lt;KeyValuePair&amp;gt;&lt;/code&gt; for the node's entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.&lt;/p&gt;&lt;p&gt;A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.&lt;/p&gt;&lt;p&gt;This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.&lt;/p&gt;&lt;head rend="h2"&gt;Raw Memory Buffer&lt;/head&gt;&lt;p&gt;This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard &lt;code&gt;new&lt;/code&gt; syntax which will attempt to allocate storage, and then initialize the object in the same storage.&lt;/p&gt;&lt;p&gt;Instead, we use the placement new syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard &lt;code&gt;new&lt;/code&gt; operator does not have in this scenario because of the flexible array member.&lt;/p&gt;&lt;code&gt;// A static helper to allocate storage for a B+Tree node.&lt;/code&gt;&lt;p&gt;The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.&lt;/p&gt;&lt;head rend="h2"&gt;The Price Of Fine-Grained Control&lt;/head&gt;&lt;p&gt;To create an instance of a B+Tree node with a fanout of &lt;code&gt;256&lt;/code&gt;, it is not possible to write simple idiomatic code like this: &lt;code&gt;new BPlusTreeNode(256)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Instead we use the custom &lt;code&gt;BPlusTreeNode::Get&lt;/code&gt; helper which knows how much raw memory to allocate for the object including the data section.&lt;/p&gt;&lt;code&gt;BPlusTreeNode *root = BPlusTreeNode&amp;lt;KeyValuePair&amp;gt;::Get(256);&lt;/code&gt;&lt;head rend="h3"&gt;Manual Handling Of Deallocation&lt;/head&gt;&lt;p&gt;The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.&lt;/p&gt;&lt;code&gt;class BPlusTreeNode {&lt;/code&gt;&lt;p&gt;This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our &lt;code&gt;Get&lt;/code&gt; function. We constructed the object outside in: raw memory buffer -&amp;gt; node object -&amp;gt; individual elements. So we teardown in the opposite direction, from the inside out: individual elements -&amp;gt; node object -&amp;gt; raw memory buffer.&lt;/p&gt;&lt;head rend="h3"&gt;Adding New Members In A Derived Class&lt;/head&gt;&lt;p&gt;Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized &lt;code&gt;InnerNode&lt;/code&gt; or &lt;code&gt;LeafNode&lt;/code&gt; class.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;&lt;code&gt;entries_&lt;/code&gt; array in memory.&lt;p&gt;The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.&lt;/p&gt;&lt;p&gt;The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;
&lt;code&gt;InnerNode&lt;/code&gt; and &lt;code&gt;LeafNode&lt;/code&gt; implementations.&lt;head rend="h3"&gt;Reinventing The Wheel&lt;/head&gt;&lt;p&gt;By using a raw C-style array, we effectively reinvent parts of &lt;code&gt;std::vector&lt;/code&gt;, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.&lt;/p&gt;&lt;p&gt;The engineering cost to make this implementation production-grade is significant.&lt;/p&gt;&lt;head rend="h3"&gt;Hidden Data Type Assumptions&lt;/head&gt;&lt;p&gt;The &lt;code&gt;BPlusTreeNode&lt;/code&gt;'s generic signature implies it will work for any &lt;code&gt;KeyType&lt;/code&gt; or &lt;code&gt;ValueType&lt;/code&gt;, but this is dangerously misleading. Using a non-trivial type like &lt;code&gt;std::string&lt;/code&gt; will cause undefined behavior.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;
&lt;p&gt;To understand why, let's look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.&lt;/p&gt;&lt;code&gt;bool Insert(const KeyValuePair &amp;amp;element, KeyValuePair *pos) {&lt;/code&gt;
&lt;p&gt;The use of &lt;code&gt;std::memmove&lt;/code&gt; introduces a hidden constraint: &lt;code&gt;KeyValuePair&lt;/code&gt; must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.&lt;/p&gt;&lt;p&gt;Using &lt;code&gt;std::memmove&lt;/code&gt; on a &lt;code&gt;std::string&lt;/code&gt; object creates a shallow copy. We now have two &lt;code&gt;std::string&lt;/code&gt; objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;The initial hurdle when implementing a B+Tree implementation is solving the contiguous memory layout puzzle avoiding heap indirection. The solution is flexible array members, which makes it possible to compile the program when the number of entries in the B+Tree node is dynamic, and a runtime value.&lt;/p&gt;&lt;p&gt;However, the implementation complexity goes up because of manual memory management, lack of inheritance, and hidden data type constraints. This is unavoidable for high performance.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/"/><published>2025-10-07T16:39:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505407</id><title>Show HN: Arc – high-throughput time-series warehouse with DuckDB analytics</title><updated>2025-10-07T20:10:53.601638+00:00</updated><content>&lt;doc fingerprint="6f1b68d98fb25cce"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance time-series data warehouse built on DuckDB, Parquet, and MinIO.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Alpha Release - Technical Preview Arc Core is currently in active development and evolving rapidly. While the system is stable and functional, it is not recommended for production workloads at this time. We are continuously improving performance, adding features, and refining the API. Use in development and testing environments only.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;High-Performance Ingestion: MessagePack binary protocol (recommended), InfluxDB Line Protocol (drop-in replacement), JSON&lt;/item&gt;
      &lt;item&gt;DuckDB Query Engine: Fast analytical queries with SQL&lt;/item&gt;
      &lt;item&gt;Distributed Storage with MinIO: S3-compatible object storage for unlimited scale and cost-effective data management (recommended). Also supports local disk, AWS S3, and GCS&lt;/item&gt;
      &lt;item&gt;Data Import: Import data from InfluxDB, TimescaleDB, HTTP endpoints&lt;/item&gt;
      &lt;item&gt;Query Caching: Configurable result caching for improved performance&lt;/item&gt;
      &lt;item&gt;Production Ready: Docker deployment with health checks and monitoring&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Arc achieves 1.89M records/sec with MessagePack binary protocol!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Throughput&lt;/cell&gt;
        &lt;cell&gt;1.89M records/sec&lt;/cell&gt;
        &lt;cell&gt;MessagePack binary protocol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;p50 Latency&lt;/cell&gt;
        &lt;cell&gt;21ms&lt;/cell&gt;
        &lt;cell&gt;Median response time&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;p95 Latency&lt;/cell&gt;
        &lt;cell&gt;204ms&lt;/cell&gt;
        &lt;cell&gt;95th percentile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Success Rate&lt;/cell&gt;
        &lt;cell&gt;99.9998%&lt;/cell&gt;
        &lt;cell&gt;Production-grade reliability&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;vs Line Protocol&lt;/cell&gt;
        &lt;cell&gt;7.9x faster&lt;/cell&gt;
        &lt;cell&gt;240K → 1.89M RPS&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Tested on Apple M3 Max (14 cores), native deployment with MinIO&lt;/p&gt;
    &lt;p&gt;🎯 Optimal Configuration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workers: 3x CPU cores (e.g., 14 cores = 42 workers)&lt;/item&gt;
      &lt;item&gt;Deployment: Native mode (2.4x faster than Docker)&lt;/item&gt;
      &lt;item&gt;Storage: MinIO native (not containerized)&lt;/item&gt;
      &lt;item&gt;Protocol: MessagePack binary (&lt;code&gt;/write/v2/msgpack&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Native deployment delivers 1.89M RPS vs 570K RPS in Docker (2.4x faster).&lt;/p&gt;
    &lt;code&gt;# One-command start (auto-installs MinIO, auto-detects CPU cores)
./start.sh native

# Alternative: Manual setup
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env

# Start MinIO natively (auto-configured by start.sh)
brew install minio/stable/minio minio/stable/mc  # macOS
# OR download from https://min.io/download for Linux

# Start Arc (auto-detects optimal worker count: 3x CPU cores)
./start.sh native&lt;/code&gt;
    &lt;p&gt;Arc API will be available at &lt;code&gt;http://localhost:8000&lt;/code&gt;
MinIO Console at &lt;code&gt;http://localhost:9001&lt;/code&gt; (minioadmin/minioadmin)&lt;/p&gt;
    &lt;code&gt;# Start Arc Core with MinIO
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f arc-api

# Stop
docker-compose down&lt;/code&gt;
    &lt;p&gt;Note: Docker mode achieves ~570K RPS. For maximum performance (1.89M RPS), use native deployment.&lt;/p&gt;
    &lt;p&gt;Deploy Arc Core to a remote server:&lt;/p&gt;
    &lt;code&gt;# Docker deployment
./deploy.sh -h your-server.com -u ubuntu -m docker

# Native deployment
./deploy.sh -h your-server.com -u ubuntu -m native&lt;/code&gt;
    &lt;p&gt;Arc Core uses a centralized &lt;code&gt;arc.conf&lt;/code&gt; configuration file (TOML format). This provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clean, organized configuration structure&lt;/item&gt;
      &lt;item&gt;Environment variable overrides for Docker/production&lt;/item&gt;
      &lt;item&gt;Production-ready defaults&lt;/item&gt;
      &lt;item&gt;Comments and documentation inline&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Edit the &lt;code&gt;arc.conf&lt;/code&gt; file for all settings:&lt;/p&gt;
    &lt;code&gt;# Server Configuration
[server]
host = "0.0.0.0"
port = 8000
workers = 8  # Adjust based on load: 4=light, 8=medium, 16=high

# Authentication
[auth]
enabled = true
default_token = ""  # Leave empty to auto-generate

# Query Cache
[query_cache]
enabled = true
ttl_seconds = 60

# Storage Backend (MinIO recommended)
[storage]
backend = "minio"

[storage.minio]
endpoint = "http://minio:9000"
access_key = "minioadmin"
secret_key = "minioadmin123"
bucket = "arc"
use_ssl = false

# For AWS S3
# [storage]
# backend = "s3"
# [storage.s3]
# bucket = "arc-data"
# region = "us-east-1"

# For Google Cloud Storage
# [storage]
# backend = "gcs"
# [storage.gcs]
# bucket = "arc-data"
# project_id = "my-project"&lt;/code&gt;
    &lt;p&gt;Configuration Priority (highest to lowest):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Environment variables (e.g., &lt;code&gt;ARC_WORKERS=16&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;arc.conf&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;Built-in defaults&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can override any setting via environment variables:&lt;/p&gt;
    &lt;code&gt;# Server
ARC_HOST=0.0.0.0
ARC_PORT=8000
ARC_WORKERS=8

# Storage
STORAGE_BACKEND=minio
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123
MINIO_BUCKET=arc

# Cache
QUERY_CACHE_ENABLED=true
QUERY_CACHE_TTL=60

# Logging
LOG_LEVEL=INFO&lt;/code&gt;
    &lt;p&gt;Legacy Support: &lt;code&gt;.env&lt;/code&gt; files are still supported for backward compatibility, but &lt;code&gt;arc.conf&lt;/code&gt; is recommended.&lt;/p&gt;
    &lt;p&gt;After starting Arc Core, create an admin token for API access:&lt;/p&gt;
    &lt;code&gt;# Docker deployment
docker exec -it arc-api python3 -c "
from api.auth import AuthManager
auth = AuthManager(db_path='/data/historian.db')
token = auth.create_token('my-admin', description='Admin token')
print(f'Admin Token: {token}')
"

# Native deployment
cd /path/to/arc-core
source venv/bin/activate
python3 -c "
from api.auth import AuthManager
auth = AuthManager()
token = auth.create_token('my-admin', description='Admin token')
print(f'Admin Token: {token}')
"&lt;/code&gt;
    &lt;p&gt;Save this token - you'll need it for all API requests.&lt;/p&gt;
    &lt;p&gt;All endpoints require authentication via Bearer token:&lt;/p&gt;
    &lt;code&gt;# Set your token
export ARC_TOKEN="your-token-here"&lt;/code&gt;
    &lt;code&gt;curl http://localhost:8000/health&lt;/code&gt;
    &lt;p&gt;MessagePack binary protocol offers 3x faster ingestion with zero-copy PyArrow processing:&lt;/p&gt;
    &lt;code&gt;import msgpack
import requests
from datetime import datetime

# Prepare data in MessagePack format
data = {
    "database": "metrics",
    "table": "cpu_usage",
    "records": [
        {
            "timestamp": int(datetime.now().timestamp() * 1e9),  # nanoseconds
            "host": "server01",
            "cpu": 0.64,
            "memory": 0.82
        },
        {
            "timestamp": int(datetime.now().timestamp() * 1e9),
            "host": "server02",
            "cpu": 0.45,
            "memory": 0.71
        }
    ]
}

# Send via MessagePack
response = requests.post(
    "http://localhost:8000/write/v2/msgpack",
    headers={
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/msgpack"
    },
    data=msgpack.packb(data)
)
print(response.json())&lt;/code&gt;
    &lt;p&gt;Batch ingestion (for high throughput):&lt;/p&gt;
    &lt;code&gt;# Send 10,000 records at once
records = [
    {
        "timestamp": int(datetime.now().timestamp() * 1e9),
        "sensor_id": f"sensor_{i}",
        "temperature": 20 + (i % 10),
        "humidity": 60 + (i % 20)
    }
    for i in range(10000)
]

data = {
    "database": "iot",
    "table": "sensors",
    "records": records
}

response = requests.post(
    "http://localhost:8000/write/v2/msgpack",
    headers={
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/msgpack"
    },
    data=msgpack.packb(data)
)&lt;/code&gt;
    &lt;p&gt;For drop-in replacement of InfluxDB - compatible with Telegraf and InfluxDB clients:&lt;/p&gt;
    &lt;code&gt;# InfluxDB 1.x compatible endpoint
curl -X POST "http://localhost:8000/write/line?db=mydb" \
  -H "Authorization: Bearer $ARC_TOKEN" \
  -H "Content-Type: text/plain" \
  --data-binary "cpu,host=server01 value=0.64 1633024800000000000"

# Multiple measurements
curl -X POST "http://localhost:8000/write/line?db=metrics" \
  -H "Authorization: Bearer $ARC_TOKEN" \
  -H "Content-Type: text/plain" \
  --data-binary "cpu,host=server01,region=us-west value=0.64 1633024800000000000
memory,host=server01,region=us-west used=8.2,total=16.0 1633024800000000000
disk,host=server01,region=us-west used=120.5,total=500.0 1633024800000000000"&lt;/code&gt;
    &lt;p&gt;Telegraf configuration (drop-in InfluxDB replacement):&lt;/p&gt;
    &lt;code&gt;[[outputs.influxdb]]
  urls = ["http://localhost:8000"]
  database = "telegraf"
  skip_database_creation = true

  # Authentication
  username = ""  # Leave empty
  password = "$ARC_TOKEN"  # Use your Arc token as password

  # Or use HTTP headers
  [outputs.influxdb.headers]
    Authorization = "Bearer $ARC_TOKEN"&lt;/code&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/query \
  -H "Authorization: Bearer $ARC_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "database": "mydb",
    "query": "SELECT * FROM cpu_usage WHERE host = '\''server01'\'' ORDER BY timestamp DESC LIMIT 100"
  }'&lt;/code&gt;
    &lt;p&gt;Advanced queries with DuckDB SQL:&lt;/p&gt;
    &lt;code&gt;# Aggregations
curl -X POST http://localhost:8000/query \
  -H "Authorization: Bearer $ARC_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "database": "metrics",
    "query": "SELECT host, AVG(cpu) as avg_cpu, MAX(memory) as max_memory FROM cpu_usage WHERE timestamp &amp;gt; now() - INTERVAL 1 HOUR GROUP BY host"
  }'

# Time-series analysis
curl -X POST http://localhost:8000/query \
  -H "Authorization: Bearer $ARC_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "database": "iot",
    "query": "SELECT time_bucket(INTERVAL '\''5 minutes'\'', timestamp) as bucket, AVG(temperature) as avg_temp FROM sensors GROUP BY bucket ORDER BY bucket"
  }'&lt;/code&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────┐
│                     Client Applications                      │
│  (Telegraf, Python, Go, JavaScript, curl, etc.)             │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   │ HTTP/HTTPS
                   ▼
┌─────────────────────────────────────────────────────────────┐
│                   Arc API Layer (FastAPI)                    │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────┐  │
│  │ Line Protocol│  │  MessagePack │  │  Query Engine    │  │
│  │   Endpoint   │  │   Binary API │  │   (DuckDB)       │  │
│  └──────────────┘  └──────────────┘  └──────────────────┘  │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   │ Write Pipeline
                   ▼
┌─────────────────────────────────────────────────────────────┐
│              Buffering &amp;amp; Processing Layer                    │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  ParquetBuffer (Line Protocol)                       │  │
│  │  - Batches records by measurement                    │  │
│  │  - Polars DataFrame → Parquet                        │  │
│  │  - Snappy compression                                │  │
│  └──────────────────────────────────────────────────────┘  │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  ArrowParquetBuffer (MessagePack Binary)             │  │
│  │  - Zero-copy PyArrow RecordBatch                     │  │
│  │  - Direct Parquet writes (3x faster)                 │  │
│  │  - Columnar from start                               │  │
│  └──────────────────────────────────────────────────────┘  │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   │ Parquet Files
                   ▼
┌─────────────────────────────────────────────────────────────┐
│              Storage Backend (Pluggable)                     │
│  ┌────────────────────────────────────────────────────────┐ │
│  │  MinIO (Recommended - S3-compatible)                   │ │
│  │  ✓ Unlimited scale          ✓ Distributed             │ │
│  │  ✓ Cost-effective           ✓ Self-hosted             │ │
│  │  ✓ High availability        ✓ Erasure coding          │ │
│  │  ✓ Multi-tenant             ✓ Object versioning       │ │
│  └────────────────────────────────────────────────────────┘ │
│                                                              │
│  Alternative backends: Local Disk, AWS S3, Google Cloud     │
└─────────────────────────────────────────────────────────────┘
                   │
                   │ Query Path (Direct Parquet reads)
                   ▼
┌─────────────────────────────────────────────────────────────┐
│              Query Engine (DuckDB)                           │
│  - Direct Parquet reads from object storage                 │
│  - Columnar execution engine                                │
│  - Query cache for common queries                           │
│  - Full SQL interface (Postgres-compatible)                 │
└─────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Arc Core is designed with MinIO as the primary storage backend for several key reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Unlimited Scale: Store petabytes of time-series data without hitting storage limits&lt;/item&gt;
      &lt;item&gt;Cost-Effective: Commodity hardware or cloud storage at fraction of traditional database costs&lt;/item&gt;
      &lt;item&gt;Distributed Architecture: Built-in replication and erasure coding for data durability&lt;/item&gt;
      &lt;item&gt;S3 Compatibility: Works with any S3-compatible storage (AWS S3, GCS, Wasabi, etc.)&lt;/item&gt;
      &lt;item&gt;Performance: Direct Parquet reads from object storage with DuckDB's efficient execution&lt;/item&gt;
      &lt;item&gt;Separation of Compute &amp;amp; Storage: Scale storage and compute independently&lt;/item&gt;
      &lt;item&gt;Self-Hosted Option: Run on your own infrastructure without cloud vendor lock-in&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The MinIO + Parquet + DuckDB combination provides the perfect balance of cost, performance, and scalability for analytical time-series workloads.&lt;/p&gt;
    &lt;p&gt;Arc Core has been benchmarked using ClickBench - the industry-standard analytical database benchmark with 100M row dataset (14GB) and 43 analytical queries.&lt;/p&gt;
    &lt;p&gt;Hardware: AWS c6a.4xlarge (16 vCPU AMD EPYC 7R13, 32GB RAM, 500GB gp2)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cold Run Total: 35.18s (sum of 43 queries, first execution)&lt;/item&gt;
      &lt;item&gt;Hot Run Average: 0.81s (average per query after caching)&lt;/item&gt;
      &lt;item&gt;Aggregate Performance: ~2.8M rows/sec cold, ~123M rows/sec hot (across all queries)&lt;/item&gt;
      &lt;item&gt;Storage: MinIO (S3-compatible)&lt;/item&gt;
      &lt;item&gt;Success Rate: 43/43 queries (100%)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hardware: Apple M3 Max (14 cores ARM, 36GB RAM)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cold Run Total: 23.86s (sum of 43 queries, first execution)&lt;/item&gt;
      &lt;item&gt;Hot Run Average: 0.52s (average per query after caching)&lt;/item&gt;
      &lt;item&gt;Aggregate Performance: ~4.2M rows/sec cold, ~192M rows/sec hot (across all queries)&lt;/item&gt;
      &lt;item&gt;Storage: Local NVMe SSD&lt;/item&gt;
      &lt;item&gt;Success Rate: 43/43 queries (100%)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Columnar Storage: Parquet format with Snappy compression&lt;/item&gt;
      &lt;item&gt;Query Engine: DuckDB with default settings (ClickBench compliant)&lt;/item&gt;
      &lt;item&gt;Result Caching: 60s TTL for repeated queries (production mode)&lt;/item&gt;
      &lt;item&gt;End-to-End: All timings include HTTP/JSON API overhead&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Query&lt;/cell&gt;
        &lt;cell role="head"&gt;Time (avg)&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Q1&lt;/cell&gt;
        &lt;cell&gt;0.021s&lt;/cell&gt;
        &lt;cell&gt;Simple aggregation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Q8&lt;/cell&gt;
        &lt;cell&gt;0.034s&lt;/cell&gt;
        &lt;cell&gt;String parsing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Q27&lt;/cell&gt;
        &lt;cell&gt;0.086s&lt;/cell&gt;
        &lt;cell&gt;Complex grouping&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Q41&lt;/cell&gt;
        &lt;cell&gt;0.048s&lt;/cell&gt;
        &lt;cell&gt;URL parsing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Q42&lt;/cell&gt;
        &lt;cell&gt;0.044s&lt;/cell&gt;
        &lt;cell&gt;Multi-column filter&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Query&lt;/cell&gt;
        &lt;cell role="head"&gt;Time (avg)&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Q29&lt;/cell&gt;
        &lt;cell&gt;7.97s&lt;/cell&gt;
        &lt;cell&gt;Heavy string operations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Q19&lt;/cell&gt;
        &lt;cell&gt;1.69s&lt;/cell&gt;
        &lt;cell&gt;Multiple joins&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Q33&lt;/cell&gt;
        &lt;cell&gt;1.86s&lt;/cell&gt;
        &lt;cell&gt;Complex aggregations&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Benchmark Configuration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dataset: 100M rows, 14GB Parquet (ClickBench hits.parquet)&lt;/item&gt;
      &lt;item&gt;Protocol: HTTP REST API with JSON responses&lt;/item&gt;
      &lt;item&gt;Caching: Disabled for benchmark compliance&lt;/item&gt;
      &lt;item&gt;Tuning: None (default DuckDB settings)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See full results and methodology at ClickBench Results (Arc submission pending).&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt; includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;arc-api: Main API server (port 8000)&lt;/item&gt;
      &lt;item&gt;minio: S3-compatible storage (port 9000, console 9001)&lt;/item&gt;
      &lt;item&gt;minio-init: Initializes MinIO buckets on startup&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Run with auto-reload
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# Run tests (if available in parent repo)
pytest tests/&lt;/code&gt;
    &lt;p&gt;Health check endpoint:&lt;/p&gt;
    &lt;code&gt;curl http://localhost:8000/health&lt;/code&gt;
    &lt;p&gt;Logs:&lt;/p&gt;
    &lt;code&gt;# Docker
docker-compose logs -f arc-api

# Native (systemd)
sudo journalctl -u arc-api -f&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /&lt;/code&gt;- API information&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /health&lt;/code&gt;- Service health check&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /ready&lt;/code&gt;- Readiness probe&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /docs&lt;/code&gt;- Swagger UI documentation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /redoc&lt;/code&gt;- ReDoc documentation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /openapi.json&lt;/code&gt;- OpenAPI specification&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: All other endpoints require Bearer token authentication.&lt;/p&gt;
    &lt;p&gt;MessagePack Binary Protocol (Recommended - 3x faster):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;POST /write/v2/msgpack&lt;/code&gt;- Write data via MessagePack&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/v2/msgpack&lt;/code&gt;- Alternative endpoint&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /write/v2/msgpack/stats&lt;/code&gt;- Get ingestion statistics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /write/v2/msgpack/spec&lt;/code&gt;- Get protocol specification&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Line Protocol (InfluxDB compatibility):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;POST /write&lt;/code&gt;- InfluxDB 1.x compatible write&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/v1/write&lt;/code&gt;- InfluxDB 1.x API format&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/v2/write&lt;/code&gt;- InfluxDB 2.x API format&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/v1/query&lt;/code&gt;- InfluxDB 1.x query format&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /write/health&lt;/code&gt;- Write endpoint health check&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /write/stats&lt;/code&gt;- Write statistics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /write/flush&lt;/code&gt;- Force flush write buffer&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;POST /query&lt;/code&gt;- Execute DuckDB SQL query&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /query/estimate&lt;/code&gt;- Estimate query cost&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /query/stream&lt;/code&gt;- Stream large query results&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /query/{measurement}&lt;/code&gt;- Get measurement data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /query/{measurement}/csv&lt;/code&gt;- Export measurement as CSV&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /measurements&lt;/code&gt;- List all measurements/tables&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /auth/verify&lt;/code&gt;- Verify token validity&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /auth/tokens&lt;/code&gt;- List all tokens&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /auth/tokens&lt;/code&gt;- Create new token&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /auth/tokens/{id}&lt;/code&gt;- Get token details&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PATCH /auth/tokens/{id}&lt;/code&gt;- Update token&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DELETE /auth/tokens/{id}&lt;/code&gt;- Delete token&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /auth/tokens/{id}/rotate&lt;/code&gt;- Rotate token (generate new)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /health&lt;/code&gt;- Service health check&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /ready&lt;/code&gt;- Readiness probe&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /metrics&lt;/code&gt;- Prometheus metrics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /metrics/timeseries/{type}&lt;/code&gt;- Time-series metrics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /metrics/endpoints&lt;/code&gt;- Endpoint statistics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /metrics/query-pool&lt;/code&gt;- Query pool status&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /metrics/memory&lt;/code&gt;- Memory profile&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /logs&lt;/code&gt;- Application logs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;InfluxDB Connections:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /connections/influx&lt;/code&gt;- List InfluxDB connections&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /connections/influx&lt;/code&gt;- Create InfluxDB connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PUT /connections/influx/{id}&lt;/code&gt;- Update connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DELETE /connections/{type}/{id}&lt;/code&gt;- Delete connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /connections/{type}/{id}/activate&lt;/code&gt;- Activate connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /connections/{type}/test&lt;/code&gt;- Test connection&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Storage Connections:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /connections/storage&lt;/code&gt;- List storage backends&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /connections/storage&lt;/code&gt;- Create storage connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PUT /connections/storage/{id}&lt;/code&gt;- Update storage connection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /jobs&lt;/code&gt;- List all export jobs&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /jobs&lt;/code&gt;- Create new export job&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PUT /jobs/{id}&lt;/code&gt;- Update job configuration&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DELETE /jobs/{id}&lt;/code&gt;- Delete job&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /jobs/{id}/executions&lt;/code&gt;- Get job execution history&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /jobs/{id}/run&lt;/code&gt;- Run job immediately&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /jobs/{id}/cancel&lt;/code&gt;- Cancel running job&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /monitoring/jobs&lt;/code&gt;- Monitor job status&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;POST /api/http-json/connections&lt;/code&gt;- Create HTTP/JSON connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /api/http-json/connections&lt;/code&gt;- List connections&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /api/http-json/connections/{id}&lt;/code&gt;- Get connection details&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PUT /api/http-json/connections/{id}&lt;/code&gt;- Update connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DELETE /api/http-json/connections/{id}&lt;/code&gt;- Delete connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/http-json/connections/{id}/test&lt;/code&gt;- Test connection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/http-json/connections/{id}/discover-schema&lt;/code&gt;- Discover schema&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /api/http-json/export&lt;/code&gt;- Export data via HTTP&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /cache/stats&lt;/code&gt;- Cache statistics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /cache/health&lt;/code&gt;- Cache health status&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /cache/clear&lt;/code&gt;- Clear query cache&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Arc Core includes auto-generated API documentation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swagger UI: &lt;code&gt;http://localhost:8000/docs&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ReDoc: &lt;code&gt;http://localhost:8000/redoc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;OpenAPI JSON: &lt;code&gt;http://localhost:8000/openapi.json&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Arc Core is under active development. Current focus areas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance Optimization: Further improvements to ingestion and query performance&lt;/item&gt;
      &lt;item&gt;API Stability: Finalizing core API contracts&lt;/item&gt;
      &lt;item&gt;Enhanced Monitoring: Additional metrics and observability features&lt;/item&gt;
      &lt;item&gt;Documentation: Expanded guides and tutorials&lt;/item&gt;
      &lt;item&gt;Production Hardening: Testing and validation for production use cases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome feedback and feature requests as we work toward a stable 1.0 release.&lt;/p&gt;
    &lt;p&gt;Arc Core is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0).&lt;/p&gt;
    &lt;p&gt;This means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Free to use - Use Arc Core for any purpose&lt;/item&gt;
      &lt;item&gt;✅ Free to modify - Modify the source code as needed&lt;/item&gt;
      &lt;item&gt;✅ Free to distribute - Share your modifications with others&lt;/item&gt;
      &lt;item&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Share modifications - If you modify Arc and run it as a service, you must share your changes under AGPL-3.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AGPL-3.0 ensures that improvements to Arc benefit the entire community, even when run as a cloud service. This prevents the "SaaS loophole" where companies could take the code, improve it, and keep changes proprietary.&lt;/p&gt;
    &lt;p&gt;For organizations that require:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proprietary modifications without disclosure&lt;/item&gt;
      &lt;item&gt;Commercial support and SLAs&lt;/item&gt;
      &lt;item&gt;Enterprise features and managed services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please contact us at: enterprise[at]basekick[dot]net&lt;/p&gt;
    &lt;p&gt;We offer dual licensing and commercial support options.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Community Support: GitHub Issues&lt;/item&gt;
      &lt;item&gt;Enterprise Support: enterprise[at]basekick[dot]net&lt;/item&gt;
      &lt;item&gt;General Inquiries: support[at]basekick[dot]net&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Arc Core is provided "as-is" in alpha state. While we use it extensively for development and testing, it is not yet production-ready. Features and APIs may change without notice. Always back up your data and test thoroughly in non-production environments before considering any production deployment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Basekick-Labs/arc"/><published>2025-10-07T16:40:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505626</id><title>Robin Williams' daughter pleads for people to stop sending AI videos of her dad</title><updated>2025-10-07T20:10:53.368070+00:00</updated><content>&lt;doc fingerprint="97d23aa93261cd6d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Robin Williams' daughter pleads for people to stop sending AI videos of her dad&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Zelda Williams, the daughter of Robin Williams, has asked people to stop sending her AI-generated videos of her father, the celebrated US actor and comic who died in 2014.&lt;/p&gt;
    &lt;p&gt;"Please, just stop sending me AI videos of Dad," Zelda Williams posted on her Instagram stories.&lt;/p&gt;
    &lt;p&gt;"Stop believing I wanna see it or that I'll understand, I don't and I won't. If you're just trying to troll me, I've seen way worse, I'll restrict and move on.&lt;/p&gt;
    &lt;p&gt;"But please, if you've got any decency, just stop doing this to him and to me, to everyone even, full stop. It's dumb, it's a waste of time and energy, and believe me, it's NOT what he'd want."&lt;/p&gt;
    &lt;p&gt;This is not the first time Zelda Williams, a film director, has criticised AI versions of her father, who took his own life in 2014 at his Californian home at the age of 63.&lt;/p&gt;
    &lt;p&gt;Williams, who was famous for films such as Good Morning Vietnam, Dead Poets Society and Mrs Doubtfire, was understood to have been battling depression at the time of his death.&lt;/p&gt;
    &lt;p&gt;In 2023, in an Instagram post supporting a campaign against AI by US media union SAG-Aftra, she described attempts at recreating his voice as "personally disturbing", while also pointing to the wider implications.&lt;/p&gt;
    &lt;p&gt;Her post on Tuesday reflects a trend on social media, where images of people who have died are animated, featuring captions like "bring your loved ones back to life".&lt;/p&gt;
    &lt;p&gt;Williams continued: "To watch the legacies of real people be condensed down to 'this vaguely looks and sounds like them so that's enough', just so other people can churn out horrible TikTok slop puppeteering them is maddening," she continued.&lt;/p&gt;
    &lt;p&gt;"You're not making art, you're making disgusting, over-processed hotdogs out of the lives of human beings, out of the history of art and music, and then shoving them down someone else's throat hoping they'll give you a little thumbs up and like it. Gross."&lt;/p&gt;
    &lt;p&gt;She concluded: "And for the love of EVERY THING, stop calling it 'the future,' AI is just badly recycling and regurgitating the past to be re-consumed. You are taking in the Human Centipede of content, and from the very very end of the line, all while the folks at the front laugh and laugh, consume and consume."&lt;/p&gt;
    &lt;p&gt;The Human Centipede is a reference to the 2009 body horror film.&lt;/p&gt;
    &lt;head rend="h2"&gt;'She sparks conversation'&lt;/head&gt;
    &lt;p&gt;Her latest comments come in the wake of unease following the unveiling of "AI actor", Tilly Norwood.&lt;/p&gt;
    &lt;p&gt;Norwood was created by Dutch actor and comedian Eline Van der Velden, who reportedly said she wanted Norwood to become the "next Scarlett Johansson".&lt;/p&gt;
    &lt;p&gt;In a statement, SAG-Aftra said Norwood "is not an actor, it's a character generated by a computer program that was trained on the work of countless professional performers.&lt;/p&gt;
    &lt;p&gt;"It has no life experience to draw from, no emotion and, from what we've seen, audiences aren't interested in watching computer-generated content untethered from the human experience," the union added.&lt;/p&gt;
    &lt;p&gt;Actress Emily Blunt also recently said she found the idea of Norwood terrifying.&lt;/p&gt;
    &lt;p&gt;"That is really, really scary, Come on, agencies, don't do that. Please stop. Please stop taking away our human connection," she said on a podcast with Variety.&lt;/p&gt;
    &lt;p&gt;Van der Velden later said in a statement, external: "To those who have expressed anger over the creation of my AI character, Tilly Norwood, she is not a replacement for a human being, but a creative work â a piece of art.&lt;/p&gt;
    &lt;p&gt;"Like many forms of art before her, she sparks conversation, and that in itself shows the power of creativity."&lt;/p&gt;
    &lt;head rend="h2"&gt;Related topics&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published6 days ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published25 September 2023&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published27 February 2015&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published13 August 2014&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.co.uk/news/articles/c0r0erqk18jo"/><published>2025-10-07T16:56:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505666</id><title>Pigeon (YC W23) is hiring a lead full stack engineer</title><updated>2025-10-07T20:10:52.369443+00:00</updated><content>&lt;doc fingerprint="aa9be2aaf687b428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h1"&gt;Lead Full Stack Software Engineer at Pigeon (YC W23)&lt;/head&gt;
        &lt;p&gt;Pigeon (YC W23) is looking for a motivated Lead Full Stack Software Engineer to join our engineering team. You can work from our NYC office or remotely if you’re not local.&lt;/p&gt;
        &lt;p&gt;As a Lead Full Stack Software Engineer at Pigeon, you will help lead a small and fast-paced engineering team and spearhead the development of new features and systems from the ground up. You will be given a unique opportunity to shape our stack, processes, and culture while making a tangible impact on our technology and our customers.&lt;/p&gt;
        &lt;head rend="h3"&gt;Why Join Pigeon&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Impact: You will own high-value features for Pigeon’s entire customer base that will help shape their everyday business processes.&lt;/item&gt;
          &lt;item&gt;Culture: You will help shape how we work on a day-to-day basis and inform core values as we grow.&lt;/item&gt;
          &lt;item&gt;Leadership: You will be placed in a key leadership position with the opportunity to contribute to our direction, goals, and vision.&lt;/item&gt;
          &lt;item&gt;Learning: You will be encouraged to experiment with new methods and technologies to enable innovative experiences for customers.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;What You’ll Do&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Own core services, APIs, and integrations with third-party systems&lt;/item&gt;
          &lt;item&gt;Build and scale our AI-powered document processing system&lt;/item&gt;
          &lt;item&gt;Ship new features end-to-end - from conception to implementation to deployment&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;What We’re Looking For&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;5+ years experience as a full-stack software engineer&lt;/item&gt;
          &lt;item&gt;Comfortable with fast-paced development environment and early-stage ambiguity&lt;/item&gt;
          &lt;item&gt;Ability to take full ownership of projects (scoping, system design, implementation, QA, deployment, and maintenance)&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Our Stack&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;AWS, Kubernetes, Vercel&lt;/item&gt;
          &lt;item&gt;Python, Flask, FastAPI, SqlAlchemy&lt;/item&gt;
          &lt;item&gt;NextJS, Javascript/Typescript, React, CSS, Tailwind&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Benefits:&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Healthcare (Medical, Vision, and Dental)&lt;/item&gt;
          &lt;item&gt;OneMedical&lt;/item&gt;
          &lt;item&gt;401(k)&lt;/item&gt;
          &lt;item&gt;Unlimited PTO&lt;/item&gt;
          &lt;item&gt;16” Macbook Pro (M2 Chip)&lt;/item&gt;
          &lt;item&gt;Free Pigeon Merchandise (shop.pigeondocuments.com)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;Pigeon automates the entire document lifecycle: collecting documents from clients, reviewing and extracting data with AI, and syncing with CRMs or storage systems. Pigeon eliminates the manual back-and-forth of document handling and eliminates thousands of hours of manual tasks.&lt;/p&gt;
      &lt;p&gt;We're growing fast, and want someone who can help join our team as we prepare for the next stage of growth.&lt;/p&gt;
      &lt;head rend="h3"&gt;Team&lt;/head&gt;
      &lt;p&gt;We are a team of 4 who previously worked at Google, Squarespace, Deloitte, and HonorLock.&lt;/p&gt;
      &lt;head rend="h3"&gt;Funding Status&lt;/head&gt;
      &lt;p&gt;We closed a $3.5M Seed round post-YC.&lt;/p&gt;
      &lt;head rend="h3"&gt;About our Technology:&lt;/head&gt;
      &lt;p&gt;Our Stack:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;AWS, Kubernetes, Vercel&lt;/item&gt;
        &lt;item&gt;Python, Flask, SqlAlchemy&lt;/item&gt;
        &lt;item&gt;NextJS, Javascript/Typescript, React, CSS, Tailwind&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/pigeon/jobs/sjuJOg3-lead-full-stack-software-engineer-remote-us"/><published>2025-10-07T17:00:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505692</id><title>Doing Rails Wrong</title><updated>2025-10-07T20:10:52.171231+00:00</updated><content>&lt;doc fingerprint="2cd7f1377fc53f68"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt; You're doing Rails wrong. copy link &lt;/head&gt;
    &lt;head rend="h6"&gt;Tuesday, 07 October 2025&lt;/head&gt;
    &lt;p&gt; Kevin: Hey, have you tried Vite for Rails 8? It’s insanely fast.&lt;/p&gt;
    &lt;p&gt; John: I’ve heard of it. Isn’t that a build tool? Didn’t Rails already come with one?&lt;/p&gt;
    &lt;p&gt; K: Well, it did, but Vite is like… modern. You’ll need to install Node, npm, and configure a few scripts, but it’s totally worth it.&lt;/p&gt;
    &lt;p&gt; J: Wait, Rails needs Node now?&lt;/p&gt;
    &lt;p&gt; K: Well, yeah — if you want to use React. Everyone’s using React.&lt;/p&gt;
    &lt;p&gt; J: Didn’t Rails have something for that?&lt;/p&gt;
    &lt;p&gt; K: It did, but now you’ll want to use Vite with React Refresh so you get instant component reloads. And if you want TypeScript support, you’ll have to configure that too.&lt;/p&gt;
    &lt;p&gt; J: Sounds… like a lot.&lt;/p&gt;
    &lt;p&gt; K: Oh, not really. Just install Babel, configure your .babelrc, add vite-plugin-ruby, then you’ll want PostCSS for your styles.&lt;/p&gt;
    &lt;p&gt; J: PostCSS?&lt;/p&gt;
    &lt;p&gt; K: Yeah, and then Tailwind, obviously — you don’t want to write CSS like a peasant.&lt;/p&gt;
    &lt;p&gt; J: Of course not.&lt;/p&gt;
    &lt;p&gt; K: Then you’ll probably want to add ESLint and Prettier to make sure your code looks clean, and maybe Husky for pre-commit hooks.&lt;/p&gt;
    &lt;p&gt; J: So... Vite, React, Babel, PostCSS, Tailwind, ESLint, Prettier, Husky. That’s it?&lt;/p&gt;
    &lt;p&gt; K: Pretty much. Oh, unless you want server-side rendering — then you’ll need Next.js or Remix.&lt;/p&gt;
    &lt;p&gt; J: Wait, we’re still talking about a Rails app, right?&lt;/p&gt;
    &lt;p&gt; K: Yeah, but hybrid stacks are the way to go! You could also use StimulusReflex or Hotwire if you want reactive components without JS frameworks.&lt;/p&gt;
    &lt;p&gt; J: StimulusReflex sounds like a Marvel character.&lt;/p&gt;
    &lt;p&gt; K: Ha! No, it’s for real-time updates. But you’ll need ActionCable configured, Redis running, and—&lt;/p&gt;
    &lt;p&gt; J: Redis?&lt;/p&gt;
    &lt;p&gt; K: Yeah, you need a pub/sub layer. Don’t worry, it’s just another Docker container.&lt;/p&gt;
    &lt;p&gt; J: Docker too?&lt;/p&gt;
    &lt;p&gt; K: Yeah, to isolate your dependencies. And if you want everything reproducible, you’ll need Docker Compose, maybe Fly.io for deployment, and a build pipeline with GitHub Actions.&lt;/p&gt;
    &lt;p&gt; J: That’s... quite a setup.&lt;/p&gt;
    &lt;p&gt; K: It’s just modern web development, man. Keeps things simple. What are you doing?&lt;/p&gt;
    &lt;p&gt; J: Just tinkering.&lt;/p&gt;
    &lt;p&gt;(John runs a single command. The app boots instantly, working forms, instant loading times, blazing fast navigation.)&lt;/p&gt;
    &lt;p&gt; K: Wow, that looks like a pretty complex setup. What stack’s that?&lt;/p&gt;
    &lt;p&gt; J: Vanilla Rails.&lt;/p&gt;
    &lt;p&gt;Just F#$%^&amp;amp; use Rails.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong"/><published>2025-10-07T17:01:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505854</id><title>ICE bought vehicles equipped with fake cell towers to spy on phones</title><updated>2025-10-07T20:10:52.091884+00:00</updated><content>&lt;doc fingerprint="be3c0913216837ed"&gt;
  &lt;main&gt;
    &lt;p&gt;U.S. Immigration and Customs Enforcement (ICE) paid $825,000 earlier this year to a company that manufactures vehicles equipped with various technologies for law enforcement, including fake cellphone towers known as “cell-site simulators,” which can be used to spy on nearby phones.&lt;/p&gt;
    &lt;p&gt;According to public records, the award dated May 8 “provides Cell Site Simulator (CSS) Vehicles to support the Homeland Security Technical Operations program” and is a modification for “additional CSS Vehicles.”&lt;/p&gt;
    &lt;p&gt;The contract was signed with TechOps Specialty Vehicles (TOSV), a Maryland-based company. TOSV also signed a similar contract with ICE in September 2024 for $818,000, showing that the relationship between the agency and the company predates the Trump administration.&lt;/p&gt;
    &lt;p&gt;TOSV president Jon Brianas told TechCrunch in an email that he could not provide details about the ICE contracts and the vehicles, citing “trade secrets.” But Brianas did confirm that the company does provide cell-site simulators, although it does not make them.&lt;/p&gt;
    &lt;p&gt;“We don’t manufacture electrical, comms, and technology components, we integrate that product into our overall design of the vehicle,” said Brianas, who declined to say from where TOSV sources its cell-site simulators.&lt;/p&gt;
    &lt;p&gt;This is the latest federal contract that reveals some of the technologies powering the Trump administration’s deportation crackdown.&lt;/p&gt;
    &lt;p&gt;In early September, Forbes found a recently unsealed search warrant that showed that ICE used a cell-site simulator to track down a person who allegedly was part of a criminal gang in the United States, and who had been ordered to leave the country in 2023. In the article, Forbes reported that it also found a contract for “cell site simulator vehicles,” but the article did not name the company that provides the vans to the agency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Join 10k+ tech and VC leaders for growth and connections at Disrupt 2025&lt;/head&gt;
    &lt;head rend="h4"&gt;Netflix, Box, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — just some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch, and a chance to learn from the top voices in tech. Grab your ticket before doors open to save up to $444.&lt;/head&gt;
    &lt;head rend="h3"&gt;Join 10k+ tech and VC leaders for growth and connections at Disrupt 2025&lt;/head&gt;
    &lt;head rend="h4"&gt;Netflix, Box, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — just some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss a chance to learn from the top voices in tech. Grab your ticket before doors open to save up to $444.&lt;/head&gt;
    &lt;p&gt;Cell-site simulators also go by the name “stingrays” because some of the earlier types of these devices, made by defense contractor Harris (now L3Harris), were named that way. Since then, stingrays have become a catch-all name for this type of technology, also known as IMSI catchers. (IMSI stands for International Mobile Subscriber Identity, a unique number that identifies every cellphone user in the world.)&lt;/p&gt;
    &lt;p&gt;As the name suggests, cell-site simulator tools can mimic a cellphone tower, tricking every phone in its nearby range to connect to the device and thus giving law enforcement the ability to better identify the real-world location of those phones and their owners.&lt;/p&gt;
    &lt;p&gt;Some cell-site simulators can also intercept regular calls, text messages, and internet traffic.&lt;/p&gt;
    &lt;p&gt;Authorities can get data from traditional cellphone towers to find the current or past location of a suspect, but the location is usually not very precise.&lt;/p&gt;
    &lt;p&gt;Stingray-like devices have been in use by law enforcement for more than a decade and have long been controversial because authorities do not always get a warrant for their use, and critics say these devices ensnare innocent people by default. These devices are also shrouded in secrecy, because the law enforcement agencies that use them are under strict non-disclosure agreements not to reveal how the devices work.&lt;/p&gt;
    &lt;p&gt;ICE has a long history of using cell-site simulators. In 2020, documents obtained by the American Civil Liberties Union showed that ICE deployed them at least 466 times between 2017 and 2019. The agency used these tools more than 1,885 times between 2013 and 2017, according to documents obtained by BuzzFeed News at the time.&lt;/p&gt;
    &lt;p&gt;ICE acknowledged TechCrunch’s request for comment, but did not respond to a series of questions, which included: what ICE uses these vehicles for, whether and where they have recently been deployed, and whether the agency always gets a warrant when using cell-site simulators.&lt;/p&gt;
    &lt;head rend="h2"&gt;From surveillance vans to bookmobiles&lt;/head&gt;
    &lt;p&gt;Headquartered just outside of Washington, DC, TOSV sells a wide range of customizable vehicles to law enforcement, such as vans for SWAT armed response teams, bomb squads, and so-called “mobile lab” and “cover surveillance” vehicles.&lt;/p&gt;
    &lt;p&gt;Among these vehicles for police forces, TOSV lists several “projects,” including one described as DHS Mobile Forensic Labs, referring to the Department of Homeland Security.&lt;/p&gt;
    &lt;p&gt;According to the website, these mobile forensic vans are “equipped for on-site forensic analysis and documentation,” have “secure compartments for evidence preservation and investigative tools,” and enable “seamless case file updates and evidence logging.”&lt;/p&gt;
    &lt;p&gt;Another project is the DHS Mobile Command Van,” which TOSV says is “configurable for advanced surveillance and mission coordination.”&lt;/p&gt;
    &lt;p&gt;It’s unclear if these vans are the same vehicles that include cell-site simulators, as there’s no mention of the phone surveillance tool anywhere on TOSV’s website.&lt;/p&gt;
    &lt;p&gt;ICE has other contracts with TOSV for mobile forensic labs, which don’t specify which technologies are located in the vans.&lt;/p&gt;
    &lt;p&gt;According to its website, TOSV also sells so-called “bookmobiles,” which appear to be libraries on wheels, as well as medical and fire department vehicles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2025/10/07/ice-bought-vehicles-equipped-with-fake-cell-towers-to-spy-on-phones/"/><published>2025-10-07T17:12:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506143</id><title>German government comes out against Chat Control</title><updated>2025-10-07T20:10:51.783601+00:00</updated><content>&lt;doc fingerprint="77d803d92c0426bd"&gt;
  &lt;main&gt;
    &lt;p&gt;Great news and big win for privacy in the EU! 🇪🇺🇩🇪 Germany’s ruling CDU/CSU party made it clear today: there will be no chat control - as pushed for by other EU countries - with this German government.&lt;/p&gt;
    &lt;p&gt;40 Sekunden kurz und präzise: Mit der CDU/CSU wird es keine anlasslose Chatkontrolle geben, wie sie von einigen Staaten in der EU gefordert wird.&lt;/p&gt;
    &lt;p&gt;Oct 7, 2025 · 4:13 PM UTC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xcancel.com/paddi_hansen/status/1975595307800142205"/><published>2025-10-07T17:31:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506268</id><title>Less Is More: Recursive Reasoning with Tiny Networks</title><updated>2025-10-07T20:10:51.464181+00:00</updated><content>&lt;doc fingerprint="3cbf352bcdf5c28f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 6 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Less is More: Recursive Reasoning with Tiny Networks&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Alexia Jolicoeur-Martineau [view email]&lt;p&gt;[v1] Mon, 6 Oct 2025 14:58:08 UTC (259 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.04871"/><published>2025-10-07T17:42:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506365</id><title>Solar energy is now the cheapest source of power, study</title><updated>2025-10-07T20:10:45.546215+00:00</updated><content>&lt;doc fingerprint="a545355d0abc55b8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Solar energy is now the world’s cheapest source of power, a Surrey study finds&lt;/head&gt;
    &lt;p&gt;Solar energy is now so cost-effective that, in the sunniest countries, it costs as little as £0.02 to produce one unit of power, making it cheaper than electricity generated from coal, gas or wind, according to a new study from the University of Surrey.&lt;/p&gt;
    &lt;p&gt;In a study published in Energy and Environment Materials, researchers from Surrey’s Advanced Technology Institute (ATI) argue that solar photovoltaic (PV) technology is now the key driver of the world’s transition to clean, renewable power.&lt;/p&gt;
    &lt;p&gt;The research team also found that the price of lithium-ion batteries has fallen by 89% since 2010, making solar-plus-storage systems as cost-effective as gas power plants. These hybrid setups, which combine solar panels with batteries, are now standard in many regions and allow solar energy to be stored and released when needed, turning it into a more reliable, dispatchable source of power that helps balance grid demand.&lt;/p&gt;
    &lt;p&gt;Despite many reasons to be optimistic, the ATI research team points to several challenges – particularly connecting large amounts of solar power to existing electricity networks. In some regions, such as California and China, high solar generation has led to grid congestion and wasted energy when supply exceeds demand.&lt;/p&gt;
    &lt;p&gt;###&lt;/p&gt;
    &lt;p&gt;Notes to editors&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Professor Ravi Silva is available for interview; please contact mediarelations@surrey.ac.uk to arrange.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The full paper can be found here.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Related sustainable development goals&lt;/head&gt;
    &lt;head rend="h2"&gt;Featured Academics&lt;/head&gt;
    &lt;head rend="h2"&gt;Media Contacts&lt;/head&gt;
    &lt;p&gt;External Communications and PR team&lt;lb/&gt; Phone: +44 (0)1483 684380 / 688914 / 684378&lt;lb/&gt; Email: mediarelations@surrey.ac.uk&lt;lb/&gt; Out of hours: +44 (0)7773 479911&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.surrey.ac.uk/news/solar-energy-now-worlds-cheapest-source-power-surrey-study-finds"/><published>2025-10-07T17:50:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507173</id><title>Google's Requirement for Developers to Be Verified Threatens App Store F-Droid</title><updated>2025-10-07T20:10:45.413315+00:00</updated><content>&lt;doc fingerprint="be60b11190975461"&gt;
  &lt;main&gt;
    &lt;p&gt;Google back then: “Don’t be evil.”&lt;/p&gt;
    &lt;p&gt;Google now: “Don’t be stupid by being good.”&lt;/p&gt;
    &lt;p&gt;It would be something of an understatement to say that Alphabet, Google’s holding company, is big and successful. Some Wall Street analysts are even predicting it could become the world’s most valuable corporation. Of course, even for business giants, enough is never enough. They always want more: more money, more power. As part of that tendency, Google seems to have decided that F-Droid, the free and open source app store for the Android platform, is a threat to the official Google Play Store that needs to be neutralized. At least that is likely to be the effect of Google’s announcement that it will require all Android developers to register and be verified before their apps can be allowed to run on certified Android devices. A post on the F-Droid blog explains what the problem is:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In addition to demanding payment of a registration fee and agreement to their (non-negotiable and ever-changing) terms and conditions, Google will also require the uploading of personally identifying documents, including government ID, by the authors of the software, as well as enumerating all the unique “application identifiers” for every app that is to be distributed by the registered developer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;According to the blog post, the impact on the F-Droid project would be severe:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;the developer registration decree will end the F-Droid project and other free/open-source app distribution sources as we know them today, and the world will be deprived of the safety and security of the catalog of thousands of apps that can be trusted and verified by any and all. F-Droid’s myriad users will be left adrift, with no means to install — or even update their existing installed — applications.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Google says registration is needed to “better protect users from repeat bad actors spreading malware and scams”. Registration “creates crucial accountability, making it much harder for malicious actors to quickly distribute another harmful app after we take the first one down.” Slightly less convenient, perhaps, but not much harder. The F-Droid blog post points out that its open source app store already has a far better approach to security than Google’s proposed registration and verification:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;every [F-Droid] app is free and open source, the code can be audited by anyone, the build process and logs are public, and reproducible builds ensure that what is published matches the source code exactly. This transparency and accountability provides a stronger basis for trust than closed platforms, while still giving users freedom to choose. Restricting direct app installation not only undermines that choice, it also erodes the diversity and resilience of the open-source ecosystem by consolidating control in the hands of a few corporate players.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Google is at pains to emphasize “Verified developers will have the same freedom to distribute their apps directly to users through sideloading or through any app store they prefer.” But that’s not true: their “freedom” will be soon be conditional, subject to Google’s whim and veto (as the company’s recent removal of the ICE-spotting app ‘Red Dot’ demonstrates). As a special concession, the company says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;we are also introducing a free developer account type that will allow teachers, students, and hobbyists to distribute apps to a limited number of devices without needing to provide a government ID.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But again that is subject to Google’s approval, and only allows distribution to a “limited number of devices” – a circumscribed “freedom”, in other words. And for F-Droid it’s not even an option, because of the following:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;How many F-Droid users are there, exactly? We don’t know, because we don’t track users or have any registration: “No user accounts, by design”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As the F-Droid post comments, Google’s move is not credibly about “security”, but actually about “consolidating power and tightening control over a formerly open ecosystem”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you own a computer, you should have the right to run whatever programs you want on it. This is just as true with the apps on your Android/iPhone mobile device as it is with the applications on your Linux/Mac/Windows desktop or server. Forcing software creators into a centralized registration scheme in order to publish and distribute their works is as egregious as forcing writers and artists to register with a central authority in order to be able to distribute their creative works. It is an offense to the core principles of free speech and thought that are central to the workings of democratic societies around the world.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Google’s attack on F-Droid is ironic. At the heart of Android, and the key element that allowed it to become so successful so quickly, is the GPL-licensed Linux kernel. Over the years, Google has increased its control over Android by adding more non-free elements. If, as seems likely, its latest move leads to the shutdown of the 15-year-old F-Droid platform, it would represent a further betrayal of the open source world it once supported.&lt;/p&gt;
    &lt;p&gt; Filed Under: android, f-droid, freedom, id, linux, macintosh, malware, open source, registration, reproducibility, scams, security, verification, wall street, windows &lt;lb/&gt; Companies: alphabet, google &lt;/p&gt;
    &lt;p&gt;Google back then: “Don’t be evil.”&lt;/p&gt;
    &lt;p&gt;Google now: “Don’t be stupid by being good.”&lt;/p&gt;
    &lt;p&gt;They blessed our anti-trust and we’ve bent the knee to trump, now is the time to shine at being bastards!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.techdirt.com/2025/10/07/googles-requirement-for-all-android-developers-to-register-and-be-verified-threatens-to-close-down-open-source-app-store-f-droid/"/><published>2025-10-07T18:51:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507195</id><title>The murky economics of the data-centre investment boom</title><updated>2025-10-07T20:10:45.240449+00:00</updated><content/><link href="https://www.economist.com/business/2025/09/30/the-murky-economics-of-the-data-centre-investment-boom"/><published>2025-10-07T18:52:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507236</id><title>The publishing industry has a gambling problem</title><updated>2025-10-07T20:10:44.975991+00:00</updated><content>&lt;doc fingerprint="342080157fa50dc9"&gt;
  &lt;main&gt;
    &lt;p&gt;In 1970, a New York publishing company put out a debut novel by an editor and former teacher from Ohio. The press, then known as Holt, Rinehart and Winston, had taken a chance on the book, which had been rejected by numerous other houses. The initial print run was somewhere between 1,200 and 1,500 units—modest expectations that looked justified when, in the first year, sales barely cleared 2,000. This despite getting positive reviews in the New York Times and The New Yorker and being assigned to freshman classes at the City College of New York. The attention wasn’t enough. Four years later, the novel was out of print.&lt;/p&gt;
    &lt;p&gt;The author stayed in the game, albeit precariously. While working on her second book, she was a single parent commuting to Manhattan for a job in publishing. At the time, she was “so strapped for money that the condition moved from debilitating stress to hilarity.” Despite her first book’s lacklustre sales, she found a publisher for her second. The debut had attracted the admiration of a high-profile editor, one who happened to work in the same building she did. He acquired her next title, and the next, keeping her in house as she steadily built acclaim and an audience.&lt;/p&gt;
    &lt;p&gt;Eventually, the writer scored an opportunity still regarded as a grail of book marketing: her debut was chosen for Oprah’s Book Club. Sales reportedly soared to 800,000 copies. Today, publishers hope that their titles will nab the book club stamp—and the ensuing bump in sales—straight out of the gate. But, in this case, the Oprah endorsement came only at the turn of the millennium, thirty years after the novel was first released. By then, the author had published some half dozen other books and cleared the stable of major literary accolades. She had won the National Book Award, the Pulitzer, the Nobel. The author was Toni Morrison. The novel was The Bluest Eye.&lt;/p&gt;
    &lt;p&gt;The careers of many literary titans of the late-twentieth and early twenty-first centuries bear similar hallmarks: The disappointing debut. The stalwart editorial advocate. The understanding that, in order for a writer to truly break out, time is a meaningful factor. For every author whose first try strikes gold—like Philip Roth, whose debut won him the National Book Award at twenty-seven—there’s one like Morrison—or Cormac McCarthy, or Jack Kerouac, or 2025’s Pulitzer Prize–winning fiction writer Percival Everett—on whom a publisher had to take a second, or third, or fourth, or fifth chance. In 1993, reflecting on The Bluest Eye’s reception, Morrison noted its initial life had echoed that of its young Black protagonist, Pecola Breedlove: “dismissed, trivialized, [and] misread.” Nevertheless, the novel is now an essential part of a legacy that reshaped literature.&lt;/p&gt;
    &lt;p&gt;Nowadays, it might not get that opportunity. It’s true most debuts are not, aesthetically, The Bluest Eye. But nor are they as easily granted second chances after commercial disappointment. Instead, there is tremendous pressure to succeed from the beginning. If they fail, all bets are off, sometimes literally. Countless factors contribute to how well a book sells, and there are many points in that chain at which things can break down. If they do, much of the responsibility converges on the writer. That a publisher bet on them and lost means it will be harder to secure the next deal. No matter the reasons for the flop—a tiny marketing budget, staff turnover at the press, cutbacks in culture coverage, backlash toward a hot literary trend—the writer carries the failure on their record.&lt;/p&gt;
    &lt;p&gt;Sales track—or simply track, in industry parlance—is an invisible force shaping contemporary literature. Much depends on that number. On the basis of track, published authors struggle to keep going; those just starting out fear their careers will be severed at the root. Track shapes how an agent pitches a book and how editors assess whether to buy it. Track restricts reader choice by dictating which books are served up as the next big thing (and the next, and the next) and by kneecapping writers deemed insufficiently commercial. The primacy of track, in other words, is a barometer for the health of literary culture. Right now, when the industry is especially skittish, the obsession with finding the next blockbuster hit privileges the survival of the few at the expense of the many.&lt;/p&gt;
    &lt;p&gt;Track is like credit: it might be better to have none at all. When a writer has a book that’s ready to sell, their agent takes the manuscript or proposal out on submission by pitching it to editors. If an editor is interested, they will in turn pitch the project to their company for approval. One of the things that publishing teams look at, when evaluating a book for potential acquisition, is a writer’s past sales. Using tools like BookScan, the industry’s pricey software for tracking units sold, publishers gauge how a previous title fared and whether the author warrants further investment. (BookNet, the equivalent in Canada, is a nonprofit. The data provided by both is incomplete.)&lt;/p&gt;
    &lt;p&gt;Being trailed by one’s sales data gives first-time writers a certain advantage. Debuts are deeply attractive to publishers because, as writer and researcher Laura McGrath puts it, “there is nothing but potential. If your track is zero, there’s only one place for it to go.” The book’s advance is therefore set by anticipation—the publisher’s bid is roughly commensurate with how big they think they can break it out. They reach this number by assigning a value to what McGrath, who studies publishing analytics, calls “soft data”—a bouquet of assumptions about readership, authorship, markets, and genre. Those assumptions are then “turned into something that seems like it should have been arrived upon in a rigorous fashion,” she says, “but it’s not.” If enough bidders get ensorcelled by a project—or by the bloodlust of an auction—the price can be driven up into six or seven figures. The book business may be centred in New York, but the logic is pure Las Vegas.&lt;/p&gt;
    &lt;p&gt;“These books that have huge price tags are given impossible expectations to meet.”&lt;/p&gt;
    &lt;p&gt;If buying the debut is a rollicking night at the craps table, then the sophomore project is the sober morning after. Gone is the clean slate. What publishers really want to see, McGrath says, is growth. “More than any particular number, they’re looking to see a track that is always on the rise.” This is impossible to prove after only one book, especially a book that loses the publisher money. Which is to say: almost all of them. “Most books don’t sell well,” says Alia Hanna Habib, literary agent and author of the forthcoming Take It from Me, a career guide for non-fiction writers. (She counts McGrath among her clients.)&lt;/p&gt;
    &lt;p&gt;Because the majority of books don’t earn out, most people in publishing have the disappointing experience of working on a book they love that, for whatever reason, didn’t hit: “If you’re a fair person, you know it’s not the author’s fault. It’s just the realities of a very difficult market.” Habib won’t suddenly drop a client whose first book didn’t sell. At the same time, that track creates challenges for her. She must come up with a narrative to explain the failure and a case for how the next book might do better. Sometimes, the original publisher wants to move on, so she also has to find someone else willing to take a chance.&lt;/p&gt;
    &lt;p&gt;“When I get sent a project, one of the first things I’ll do is look at the track,” says an editor from an imprint at one of the Big Five presses—the largest, corporate-owned trade publishers: Penguin Random House, Simon &amp;amp; Schuster, HarperCollins, Hachette, and Macmillan—who asked to remain anonymous. Though he evaluates every submission on its merits, he must balance his enthusiasm with practical considerations. Track becomes either an asset to his case for acquiring a book or a hurdle he must overcome by crafting a compelling strategy to convince his team it’s still worth buying.&lt;/p&gt;
    &lt;p&gt;Bad track won’t stop him from considering a project, especially one he is passionate about. Instead, he weighs the factors that may have led to it—maybe the book’s editor was laid off and the author did not receive as much attention. He’ll even reach out to the agent to learn more about what happened. Those conversations can reveal subtler things about how a book was not well supported. Perhaps the publisher positioned it in a way the author disagreed with—a risk, he says, with projects that feature diverse protagonists or are written from a very specific perspective. “Publishers are very fallible,” he says. “Sometimes an author needs a fresh start.”&lt;/p&gt;
    &lt;p&gt;This is another quirk of track. Publishing’s habit of jumping on a trend, especially if that trend is identity based, can come down hard on writers who have been underrepresented in mainstream culture. It can even set them up for failure down the line. Habib cites the moment in 2020 when presses eagerly began acquiring books by Black authors. Many of those presses had never published Black authors in a meaningful way and lacked the infrastructure to properly support those books or help them find readers. “It becomes very easy for a publisher to say now, five years later, ‘Oh, we tried that, and it didn’t work,’” simply because their particular iteration of it didn’t, she says.&lt;/p&gt;
    &lt;p&gt;The other thing the Big Five editor considers when assessing track is the investment the prior book received. If it was put out by a small press and still sold 5,000 copies, that looks like the growth potential McGrath described—imagine what might happen with even more marketing muscle. Conversely, “if there’s someone who we all know was in a huge, million-dollar auction and the book sells 20,000 copies even though it was supposed to sell 100,000, then that’s a different consideration,” he says.&lt;/p&gt;
    &lt;p&gt;Such knowledge is highly piecemeal, even more so than the spotty sales data. Who we all know is more rumour than fact. Publishers don’t know exactly how much a book sold for. Neither the writer nor their agent has to disclose; in fact, it’s in their best interests not to, in case it backfires later.&lt;/p&gt;
    &lt;p&gt;There are the euphemisms used in deal announcements on the industry website Publishers Marketplace—a “very nice” deal connotes an advance in the mid to high five figures, a “good” deal signifies low six figures—or the trades might report on a high-profile auction. An author may also just be forthcoming, in the interest of equity, about how much they were paid, as when the 2020 hashtag #PublishingPaidMe revealed stark disparities in pay between white authors and authors of colour. But transparency at that scale is unusual. “Information about advances is so unreliable,” says McGrath. “When an advance gets published in Publishers Marketplace or Publishers Weekly, I don’t believe that for a second, because that’s all a way of generating excitement.”&lt;/p&gt;
    &lt;p&gt;But if publishers can’t verify a book’s purchase price, on what are they basing the decision that the track is bad? Bad relative to what, other than a general vibes-based sense of hype? There is no solid number that constitutes “good track,” Habib says, and what counts as good varies depending on the genre. In addition to evaluating track based on incomplete BookScan data, publishers are making decisions based on advance sizes they don’t have access to, maybe heard a rumour about, and in fairness to the writer probably shouldn’t be told at all.&lt;/p&gt;
    &lt;p&gt;What’s undeniable is that the market has become harder to break into for writers whose work does not scream commercial.&lt;/p&gt;
    &lt;p&gt;Still, the stigma of overpaying persists. If a writer is the beneficiary of such conditional faith, and then the book’s performance fails to justify it, it’s the writer who bears the stain. “These books that have huge price tags are given impossible expectations to meet,” the editor says. “The fact that a book received a $1 million cheque versus a $50,000 cheque means it’s going to be very hard for their work to continue moving forward.”&lt;/p&gt;
    &lt;p&gt;Habib disagrees with the idea that a high advance automatically sets a writer up for failure. When she is able to get her clients a competitive debut advance, she prepares them for the possibility that it might be the most money they ever receive. “Don’t think of your debut advance as your rate,” she tells them. “Think about it as funding for this stage of your career.” It comes with perks they might get offered only once, like a big publicity budget. It’s a chance to launch a huge career. And for writers, especially those who don’t come from wealth, it is a life-changing amount of money.&lt;/p&gt;
    &lt;p&gt;Despite the careful narrative that an agent and an editor may weave, both separately and in tandem, whether a book gets bought or for how much is ultimately not their call. Even if the Big Five editor loves a project, he still needs to share it with his colleagues and pitch it at an editorial board meeting. If it passes that hurdle, he writes up a formal proposal. Past that, it’s out of his hands: “At the end of the day, the people I am beholden to can say no to just about anything.”&lt;/p&gt;
    &lt;p&gt;Like Habib, he acknowledges that this can be unfair. “The thing that is toughest about track is that it really has nothing to do at all with the author and the author’s work.” This is a vexed Catch-22—that track has nothing to do with the author and yet the author is the one over whose head it hangs. Many writers seem to feel the opposite: that track has everything to do with them.&lt;/p&gt;
    &lt;p&gt;“Due to the author’s previous book sales, this is a pass. . . . I’m afraid the low units will present challenges as our sales team presents to retailers and our marketing and publicity teams pitch [this writer] to media.”&lt;/p&gt;
    &lt;p&gt;This was an email sent to Jeanna Kadlec’s agent when her second book went out on submission to publishers. Her first book, Heretic—a memoir about leaving evangelical Christianity—was acquired by Houghton Mifflin Harcourt at auction for $150,000 (US), the highest offer she received. Almost a year later, HMH was bought by HarperCollins. While Kadlec’s editor stayed on, she suspects she was allocated fewer resources at HarperCollins than she would have been at HMH.&lt;/p&gt;
    &lt;p&gt;The difficulties mounted from there. First came a months-long HarperCollins strike. With it came reviewer boycotts. Readers, too, may have been boycotting the company’s books, even though this wasn’t something the striking employees called for. Once the workers got their deal, Kadlec asked for renewed promotional attention. But HarperCollins declined, seemingly writing off anything that came out during the strike as a loss. When she took her next project to the press, who had a right of first refusal, they passed.&lt;/p&gt;
    &lt;p&gt;It’s on readers to look beyond the season’s biggest titles that they’re being spoon-fed by major publishers.&lt;/p&gt;
    &lt;p&gt;This sounds a bit like trying to buy new insurance for your car after it was totalled by your friend, the professional driver. The circumstances were obviously beyond Kadlec’s control. Still, when she tried to sell her sophomore project, a few editors, especially those at other HarperCollins imprints, explicitly cited her track as part of their rejection. Heretic has sold a few thousand copies—respectable for memoir but, when compared to her six-figure advance, which hints at higher commercial hopes, she admits, “not good math.”&lt;/p&gt;
    &lt;p&gt;These figures seem impossible to separate from the fact that, among other things, Kadlec’s publicist was marching on a picket line rather than continuing to pitch her book to media. (Kadlec, who speaks glowingly of the team assigned to her book, supported their strike demands and even marched alongside them.) But the feedback on submission didn’t seem to consider this. “We couldn’t really see a way to break out the new book,” said another reply, from a HarperCollins editor. “She might be better served with a fresh start in a new home.” Despite the track, Kadlec has managed to sell her next project, albeit at the much lower advance of $30,000 (US).&lt;/p&gt;
    &lt;p&gt;“I don’t know how people are supposed to develop in their careers,” says a novelist who also spoke on the condition of anonymity. She has published multiple books but, owing to editorial shuffles at her publishing houses, has had to take her books out on submission multiple times. “Every single time, the sales track becomes heavier.”&lt;/p&gt;
    &lt;p&gt;It’s frustrating that she alone is saddled with the track, given that a publisher plays just as big a role in a book’s fate, if not bigger. It’s as if they take a book over when they buy it, and then, if it misfires, renounce all responsibility. Like many authors, she feels abandoned by this logic. That writers shoulder the most risk when they have so much less power strikes her as unsustainable. We think of careers as things that progress linearly—the more skills and experience you have, the greater the salary, stability, and respect you can command. “But if you’ve got a mediocre sales track, that’s not the case. You’re lucky if you get a lower offer. You’re lucky if you get an offer at all.”&lt;/p&gt;
    &lt;p&gt;Online, certain tactics are suggested for how to “get over” the ailment of bad track—home remedies meant to replace the old curatives of editorial advocacy and time. A surprising number of sources suggest writing under a pseudonym. They can’t pin a bad track on you, the logic goes, if you take a different name. (Gotcha!) Habib seems unimpressed by this gambit. “It’s very hard to publish under a pseudonym,” she says. “The books that get the most promotion have an author to promote them. You can’t keep making up personae.” (“Or faking your own death,” I say, a tactic neither copped to nor suggested by anyone I spoke to.)&lt;/p&gt;
    &lt;p&gt;The suggestion to write in a new genre also comes up fairly often. This pre-empts the concerns about reaching a different, hopefully bigger audience—the genre will start to do that on its own. Switching genres is one way to mitigate a publisher’s concerns about track, the Big Five editor tells me, especially if the new project is markedly more commercial. This can also get hairy, in that it incentivizes bending one’s career to chase the market. It’s hard enough to keep financial pressures out of one’s creative process, especially under the gun of bad track; this advice doesn’t just let commerce in but puts it smack in the centre of one’s art.&lt;/p&gt;
    &lt;p&gt;Certainly, plenty of people write in multiple genres. But Habib cautions writers against pursuing forms they’re not interested in for the purpose of trying to sell books. As she correctly put it to me, a memoirist and essayist, “You’re in no position to write a great romantasy novel.” Kadlec and her agent tried a subtler genre shift. They hoped that switching from narrative to prescriptive nonfiction would count as enough of a fresh start; that hope wasn’t borne out. “A lot of the advice I hear for folks who do switch genres,” Kadlec says, “is they do a memoir and then they do a novel, and regardless of how the memoir did, the novel is considered a totally clean slate.”&lt;/p&gt;
    &lt;p&gt;This was the sequence Joseph Osmundson was hoping for—to sell a novel after his nonfiction book. His first release with a major press, Virology, is an essay collection that fuses science, queer writing, literary analysis, and memoir. Though his editor was eager to take a chance on the project, the publisher had low expectations. Norton bought it for a modest $15,000 (US), and in trade paperback rather than hardback, a cheaper format that also means the author gets a lower percentage of each sale in royalties counted against the advance.&lt;/p&gt;
    &lt;p&gt;Upon its release, Virology sold so well that Osmundson earned out his advance in three months—something most books never manage, let alone so quickly. According to industry rules, he was golden. A publisher had bet small on him and won big. He had a strong sales track, growth potential, and a proven audience. Fiction gave him the additional advantage of a clean slate even if he didn’t need one. But when his agent took his novel out on submission, the response he kept getting was the same: “We don’t see Joe having a platform or a pattern of fiction publications.”&lt;/p&gt;
    &lt;p&gt;Osmundson was frustrated. “I had been told: work my ass off on my first book, set up a solid track, and you’ll get a bigger advance next time,” only to discover it did not translate into anything for fiction. The novel was either rejected or offered an advance that was on par with his first. In the end, he sold the novel alongside a memoir, but the novel never made it to print. “Do I get tired of proving people wrong?” he asks. “Yes. It is exhausting to constantly feel like my work is undervalued.”&lt;/p&gt;
    &lt;p&gt;Despite widespread conversations in 2020 around equity in publishing, he believes we’re witnessing a general retrenchment in the industry. Decision makers are adopting an even more conservative stance, which steers them toward acquiring books from people who already have built-in audiences—like celebrities or influencers. Such retrenchment is also a labour issue. Publishing is an industry with stagnant salaries, considerable instability, and high turnover. “It’s hard to invest in authors when the people who are working on the books are not being invested in,” says the Big Five editor. He may not have the luxury of nurturing a writer across books, as much as he may want to. The more pressing issue can be, as he puts it, “I need to make a profit so I don’t get fired from this job.”&lt;/p&gt;
    &lt;p&gt;Many factors have likely contributed to this heightened risk aversion: corporate consolidation, a rapidly slimming media market, a volatile political climate. These are not favourable conditions for creative experimentation. While many people I spoke to agree that things feel particularly chilly at the moment, McGrath also takes the long view: “Publishing is always more conservative today than it was ten years ago,” she says. The industry has a habit of glancing back toward the rosy past. But one moment in particular, around 2001, marked a shift, when Nielsen BookScan (now Circana BookScan) first came on the market and began tracking sales. The current, pervasive sense of conservatism, McGrath says, has been exacerbated by the increased reliance on data to justify decisions. If you can put a number on the risk, maybe you think twice before taking it.&lt;/p&gt;
    &lt;p&gt;No matter the reason, what’s undeniable is that the market has become harder to break into for writers whose work does not scream commercial. “I worry a lot about writers who are a decade behind me in their career,” Osmundson says. It was his hope that the success of Virology, despite the book not being obviously mainstream, would create space for more ambitious queer books—his own and others’. Instead, he says, “it feels like that space is actually getting smaller.”&lt;/p&gt;
    &lt;p&gt;When I ask Norm Nehmetallah, publisher of Ontario-based small press Invisible Publishing, about the effect of track’s primacy on literary culture, he sighs. Working at a small press, Nehmetallah and his team can adopt a mandate less beholden to the bottom line than those of the bigger conglomerates. Invisible, in particular, has an explicit focus on finding and nurturing emerging writers. To Nehmetallah, a successful book is less a number than a feeling that it has travelled beyond the expected networks, like the writers’ friends or a particular literary scene.&lt;/p&gt;
    &lt;p&gt;But Nehmetallah, who worked various jobs in the industry before becoming a publisher, has seen the hunger for good track touch his work in various ways—including, oddly, his current role. More and more, he says, his press and others of similar size have been getting submissions from writers who have been dropped from bigger houses, like the imprints of Penguin Random House Canada (one of which is my current publisher). There may be less loyalty there, he says. “I think, in a lot of ways, they are more willing to take on debut authors, and I think that may be coming at the expense of what we would have called their ‘mid-list authors.’”&lt;/p&gt;
    &lt;p&gt;This mid-list cohort is exerting a downward pressure on the publishing landscape. By seeking support at smaller presses, they risk filling the spaces meant for more experimental or early-career authors. This isn’t just bad for writers—it’s bad for literature. If people aren’t given chances to grow and explore in ways the market doesn’t recognize, Nehmetallah says, then readers lose out too. Toronto-based writer Jean Marc Ah-Sen, who has published several books with small and independent presses, feels that he and his peers are being crowded out of their own game. “I used to think that the frontier of literary culture was the indie presses,” he says. “But when a person who has done three books with Penguin gets pushed down, it makes less room for the people who were doing the independent stuff to begin with.” Publishers, as McGrath says, have always been risk averse. But with higher pressure to find a sure thing, more writers who may have been able to sell a book five or ten years ago, whether to a corporate or an independent press, are being left out in the cold.&lt;/p&gt;
    &lt;p&gt;Such retrenchment has come alongside a shrunken and fragmented media industry, in which the shuttering of culture outlets and the decentralization of social media has created a different kind of missing middle: an arid landscape of coverage that’s no longer bustling enough to put a wide range of books on readers’ radars.&lt;lb/&gt; Consumers, too, have a role to play here. As Habib points out, track is also built by the people who buy books, or are supposed to. Nehmetallah makes a similar argument. It’s on readers to look beyond the season’s biggest titles that they’re being spoon-fed by major publishers, he says. This would help literary culture across the board. But it’s a two-way street. By shutting down writers’ chances to build audiences and careers, and restricting the range of what makes it to bookshelves—by spoon-feeding with so much aggression that it can take a lot of effort to close your mouth and turn away to find alternatives—publishers are jeopardizing that ecosystem too.&lt;/p&gt;
    &lt;p&gt;“The literary culture that supports a community of reading and that supports the word-of-mouth spreading is really diminishing,” Kadlec says. “Publishers could be doing so much more than they are actually doing to uplift it. You know,” she says to me. She then names one of my former employers, a company that shuttered its in-house magazine—which sometimes functioned as a built-in arm for promoting the books that it published, as well as a proven space to incubate reputations and platforms.&lt;/p&gt;
    &lt;p&gt;I’ve come to expect this moment of citation, even dread it—to be borne back ceaselessly into this past. But Kadlec is right, I do know. For the past three years since that magazine was shut down, I have seen the writers of my generation lament the loss of that particular launching pad for their essays, their book promotion, their careers. I have seen their debut books get only a handful of reviews in trade magazines. I have seen their publishers decide not to reissue their books in paperback because they didn’t sell “enough” copies. I have also seen my new email address added onto my former employer’s publicity list, asking me to cover their books.&lt;/p&gt;
    &lt;p&gt;Three years after its closure, the magazine’s absence is still felt across the spectrum of publishing. Without spaces like it—in which writers have the opportunity to build an audience prior to selling a book, and publishing workers have a place to secure promotional coverage in a way that actually gets that book out to readers—the infrastructure required to build a decent track erodes into nothing. During those same three years, I’ve watched as the story of that magazine’s shutdown has been reported as if it were purely an outcome of the funding model rather than the choices of its parent company, a publishing house that decided to prioritize profit no differently from how book publishers do every day.&lt;/p&gt;
    &lt;p&gt;The publication’s closure is, in the end, a parable about the whims of capital, albeit not in the way people seem to think. It’s true that publishing professionals hate this state of affairs just as much as writers do. I believe that even more so now than I did before I started working on this piece. But it’s also true that the assault on literary culture that has shattered the avenues for book coverage and ratcheted up the impossible standards by which authors must be rapidly, conclusively adjudged a success or doomed to career failure is not simply a frame being forced on the industry from without. It’s also being perpetuated from within by those who claim to love literature. Trace the call and you’ll find it’s coming from—where else—inside the house.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thewalrus.ca/the-publishing-industry-has-a-gambling-problem/"/><published>2025-10-07T18:55:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507264</id><title>Photographers are losing their jobs faster than software engineers</title><updated>2025-10-07T20:10:43.227161+00:00</updated><content>&lt;doc fingerprint="eaca0b35959f2f05"&gt;
  &lt;main&gt;
    &lt;p&gt;Pre-made photoshoot templates for every need. From LinkedIn headshots to wedding photography, each pack includes 6-12 professionally crafted prompts ready to use.&lt;/p&gt;
    &lt;p&gt;Professional LinkedIn headshots that help you stand out to recruiters and potential clients. Get a polished, confident look that boosts your professional brand and increases profile views. Perfect for job seekers, executives, and entrepreneurs building credibility.&lt;/p&gt;
    &lt;p&gt;Authoritative attorney headshots that inspire client confidence and establish legal expertise. Perfect for law firm websites, Avvo profiles, and legal directories. Project trustworthiness and competence to attract high-value clients.&lt;/p&gt;
    &lt;p&gt;Compelling author headshots for book jackets, Amazon author pages, and speaking engagements. Capture your creative personality and build reader connection with professional portraits. Essential for fiction writers, non-fiction authors, and thought leaders.&lt;/p&gt;
    &lt;p&gt;Approachable, trustworthy headshots that help real estate agents win more listings and close more deals. Build instant credibility with clients browsing Zillow, Realtor.com, and your website. Photos that convey expertise and relatability.&lt;/p&gt;
    &lt;p&gt;Clean, striking model headshots for portfolios and agency submissions. Highlight your features with professional comp card photos that get you noticed by modeling agencies and clients. Perfect for aspiring and working models.&lt;/p&gt;
    &lt;p&gt;Casting-ready acting headshots that help you book more auditions and land roles. Create compelling theatrical portraits that showcase your range and personality. Essential for actors submitting to casting directors, agents, and Backstage.&lt;/p&gt;
    &lt;p&gt;Professional lookbook-style photography for fashion collections and seasonal launches. Generate editorial-quality images with model poses, styled outfits, and cohesive aesthetics. Perfect for wholesale buyers, press releases, and building brand credibility in the fashion industry.&lt;/p&gt;
    &lt;p&gt;Create professional flatlay product photography perfect for social media and e-commerce. Generate beautifully composed overhead shots with complementary props, perfect styling, and cohesive aesthetics that showcase your products in an Instagram-worthy format that drives engagement and sales.&lt;/p&gt;
    &lt;p&gt;Generate scroll-stopping Instagram Shop product photos optimized for mobile shopping. Create visually stunning, on-brand images with perfect composition and aesthetics that drive tags, shares, and direct purchases from your Instagram storefront and increase social commerce sales.&lt;/p&gt;
    &lt;p&gt;Create compelling lifestyle product photos that show your items in real-world contexts and boost emotional connection. Generate beautiful scenes with perfect styling, lighting, and composition that help customers envision using your product and increase purchase intent across all sales channels.&lt;/p&gt;
    &lt;p&gt;Generate sleek electronics product photography that emphasizes innovation and technical features. Create professional tech images with clean backgrounds, detail shots of ports and buttons, and lifestyle contexts that build confidence in quality and functionality for higher-value electronics sales.&lt;/p&gt;
    &lt;p&gt;Professional product photography optimized for Amazon listings. Get white background images, lifestyle shots, and detail photos that meet Amazon's requirements and increase conversions. Perfect for fashion sellers who need high-quality images that drive sales and reduce returns.&lt;/p&gt;
    &lt;p&gt;Optimize your Booking.com listing with professional property photography tailored to the platform's audience. Stand out in search results and increase direct bookings with high-quality images. Perfect for hotels, apartments, and vacation rentals on Booking.com.&lt;/p&gt;
    &lt;p&gt;Showcase your rental's kitchen with professional photography that appeals to families and long-term guests. High-quality kitchen photos increase perceived value and help justify premium pricing. Essential for rentals targeting guests who plan to cook during their stay.&lt;/p&gt;
    &lt;p&gt;Create welcoming living room photos that showcase comfort and gathering spaces. Professional living area photography helps guests envision relaxing family time and increases emotional connection to your property. Essential for highlighting your rental's main social space.&lt;/p&gt;
    &lt;p&gt;Capture the coastal lifestyle with professional beach house photography that sells the dream vacation. Highlight ocean views, beach access, and relaxed luxury to attract premium guests. Optimized for coastal vacation rental markets and beachfront properties.&lt;/p&gt;
    &lt;p&gt;Showcase your mountain or forest cabin with professional photography that emphasizes rustic charm and nature. Attract guests seeking peaceful getaways with images highlighting cozy interiors, fireplaces, and scenic surroundings. Perfect for Airbnb and mountain rental markets.&lt;/p&gt;
    &lt;p&gt;Stand out on VRBO with professional vacation rental photography optimized for the platform. Attract premium guests and justify higher nightly rates with resort-quality images. Get more inquiries and bookings with photos that highlight your property's unique selling points.&lt;/p&gt;
    &lt;p&gt;Optimize your Grubhub presence with professional food photos that increase order frequency and cart size. High-quality delivery app images designed to make your restaurant stand out and drive conversions. Boost your online ordering revenue with appetizing menu photography.&lt;/p&gt;
    &lt;p&gt;Transform your dishes into mouth-watering menu photos that drive orders and increase sales. Professional food photography designed to showcase your cuisine at its best, making customers hungry and eager to dine. Perfect for printed menus, digital displays, and promotional materials.&lt;/p&gt;
    &lt;p&gt;Maximize your UberEats sales with appetizing food photography that converts browsers into buyers. Professional delivery app photos that make your menu items irresistible and drive higher order values. Stand out in search results and increase customer satisfaction.&lt;/p&gt;
    &lt;p&gt;Create high-converting Facebook ad photos that fill tables and drive takeout orders. Professional food imagery designed to capture attention in busy social feeds and generate clicks. Perfect for promoting specials, new menu items, and driving local restaurant traffic.&lt;/p&gt;
    &lt;p&gt;Get professional food truck photography that attracts lines of hungry customers. Bold, vibrant images perfect for menu boards, social media, and finding customers at events. Make your street food look as amazing as it tastes and build a loyal following.&lt;/p&gt;
    &lt;p&gt;Elevate your upscale restaurant with sophisticated fine dining photography that reflects your culinary artistry. Elegant, high-end food images perfect for premium menus, websites, and marketing materials. Attract discerning diners and justify premium pricing with stunning visuals.&lt;/p&gt;
    &lt;p&gt;Generate twelve months of professional cat photos perfect for creating and selling calendars. Ideal for fundraising organizations, cat enthusiasts, and entrepreneurs selling pet merchandise. High-quality seasonal and themed shots that customers will love all year long.&lt;/p&gt;
    &lt;p&gt;Beautiful tribute photos that honor beloved dogs and provide comfort to grieving pet parents. Create timeless, artistic images perfect for memorial displays, remembrance gifts, and celebrating a dog's life. Thoughtful service for pet loss support groups, veterinary clinics offering memorial services.&lt;/p&gt;
    &lt;p&gt;High-converting product photos featuring dogs for pet brands, e-commerce stores, and Amazon sellers. Professional lifestyle images show products in use and increase sales with emotional appeal. Perfect for dog toys, accessories, food, and supplies that need authentic marketing content.&lt;/p&gt;
    &lt;p&gt;Stunning portfolio-quality dog photos for professional pet photographers to showcase their work and attract high-paying clients. Generate magazine-worthy images that demonstrate your artistic vision and style. Build an impressive portfolio that commands premium pricing and books more sessions.&lt;/p&gt;
    &lt;p&gt;Before-and-after style professional photos that showcase your grooming skills and attract more clients. Beautiful images highlight grooming quality, breed cuts, and transformations that demonstrate your expertise. Perfect for grooming salons looking to book more appointments and increase revenue.&lt;/p&gt;
    &lt;p&gt;Professional adoption photos that help rescue dogs and shelter animals find homes faster. Beautiful, heartwarming images showcase each dog's personality and make them irresistible to potential adopters. Perfect for animal shelters, rescue organizations, and foster networks looking to increase adoption rates.&lt;/p&gt;
    &lt;p&gt;Premium Cars.com listing photos that attract serious buyers and maximize inquiries. Professional automotive photography optimized for one of the largest car shopping platforms. Consistent, high-quality images help your listings rank higher and convert better.&lt;/p&gt;
    &lt;p&gt;Professional car photos optimized for Craigslist that get more inquiries and sell vehicles quickly. High-quality automotive images showcase your car's best features with dealership-level presentation. Perfect lighting and composition help justify your asking price.&lt;/p&gt;
    &lt;p&gt;High-end automotive photography for luxury vehicles that commands attention and premium prices. Perfect for exotic car dealers, high-value private sales, and luxury automotive marketing. Showcase Mercedes, BMW, Porsche, and other premium brands with magazine-quality images.&lt;/p&gt;
    &lt;p&gt;Create premium AutoTrader listing photos that maximize visibility and attract qualified buyers. Professional automotive photography optimized for AutoTrader's platform helps your listing stand out in search results. Increase inquiries and sell your vehicle faster with dealership-quality images.&lt;/p&gt;
    &lt;p&gt;Professional eBay Motors listing photos that increase bids and final sale prices. High-quality automotive images build buyer confidence for online vehicle sales. Detailed, well-lit photos reduce questions and help vehicles sell above market value.&lt;/p&gt;
    &lt;p&gt;Stunning automotive photography for Instagram that grows your following and engagement. Perfect for car enthusiasts, automotive influencers, and dealerships building their brand. Create scroll-stopping content with professional lighting, dramatic angles, and showroom-quality presentation.&lt;/p&gt;
    &lt;p&gt;Professional trade show booth photography for pre-event marketing and post-event documentation. Create polished images that showcase your booth design, products, and brand presence to attract visitors and demonstrate ROI. Essential for marketing teams planning exhibition participation.&lt;/p&gt;
    &lt;p&gt;High-quality corporate event photos for company websites, annual reports, and marketing materials. Showcase your team building events, company parties, and corporate gatherings with professional photography that reflects your brand. Perfect for internal communications and recruitment marketing.&lt;/p&gt;
    &lt;p&gt;Professional corporate gala and fundraising event photography for nonprofit and institutional marketing. Create elegant images that capture the sophistication of your formal events, perfect for donor relations, annual reports, and future event promotion. Demonstrate impact and attract sponsors.&lt;/p&gt;
    &lt;p&gt;Professional business conference photography for event recaps and promotional materials. Document multi-day conferences with high-quality photos showcasing sessions, attendees, and venue atmosphere. Perfect for event organizers building attendance for future conferences and demonstrating event value.&lt;/p&gt;
    &lt;p&gt;Professional awards ceremony photography for corporate recognition and PR campaigns. Celebrate achievements with polished photos perfect for press releases, internal communications, and social media announcements. Create memorable images that honor recipients and elevate your brand.&lt;/p&gt;
    &lt;p&gt;Professional company retreat and offsite photography for employer branding and team culture marketing. Showcase your company culture and team bonding experiences with high-quality photos that attract top talent and strengthen employee engagement. Perfect for recruitment and internal communications.&lt;/p&gt;
    &lt;p&gt;Transform yourself into Harry Potter movie characters for wizarding events, themed parties, and fan community content. Perfect for entertainers, Harry Potter event planners, and content creators who need magical character portraits. Attract more event bookings and followers with professional Harry Potter character photos.&lt;/p&gt;
    &lt;p&gt;Transform yourself into badass action movie characters for fitness marketing, personal training promotion, and adventure content. Perfect for gym owners, fitness influencers, and adventure tour operators who need powerful action hero imagery. Attract more clients and bookings with professional action character photos that inspire transformation.&lt;/p&gt;
    &lt;p&gt;Transform yourself into iconic horror movie characters for Halloween events, haunted attraction marketing, and horror content creation. Perfect for haunted house promoters, Halloween party planners, and horror influencers. Drive ticket sales and event bookings with professional scary character portraits that capture attention.&lt;/p&gt;
    &lt;p&gt;Transform yourself into iconic superhero characters for social media content, costume events, and fan communities. Perfect for cosplayers, content creators, and comic-con promoters who need professional superhero portraits without expensive costumes or photoshoots. Generate engagement-driving superhero content that attracts followers and brand partnerships.&lt;/p&gt;
    &lt;p&gt;Transform yourself into Marvel Cinematic Universe characters for comic-con marketing, cosplay content, and fan engagement. Perfect for convention vendors, comic book store promoters, and influencers building Marvel fan communities. Generate professional Marvel character portraits that increase event sales and sponsorship opportunities.&lt;/p&gt;
    &lt;p&gt;Transform yourself into iconic movie villain characters for entertainment marketing, themed events, and edgy content creation. Perfect for entertainers, escape room promoters, and content creators who need dramatic villain portraits. Generate engagement and bookings with powerful villain character photos that command attention.&lt;/p&gt;
    &lt;p&gt;Create edgy professional photos of yourself at Berlin's Brandenburg Gate, East Side Gallery, and modern urban locations. Perfect for travel influencers, lifestyle content creators, and bloggers building a contemporary European portfolio that attracts younger audiences, increases engagement, and secures urban travel brand deals.&lt;/p&gt;
    &lt;p&gt;Generate stunning photos of yourself exploring Barcelona's Sagrada Familia, Park Güell, and vibrant Gothic Quarter. Ideal for travel influencers, lifestyle bloggers, and content creators who need eye-catching Mediterranean content to boost engagement, attract followers, and secure travel brand partnerships.&lt;/p&gt;
    &lt;p&gt;Create stunning professional photos of yourself in Paris with iconic landmarks like the Eiffel Tower, Louvre, and charming Parisian streets. Perfect for travel influencers, Instagram content creators, and building your personal brand with romantic European travel content that drives engagement and followers.&lt;/p&gt;
    &lt;p&gt;Generate stunning photos of yourself in Prague with fairytale castles, Charles Bridge, and medieval architecture. Ideal for travel content creators, Instagram influencers, and lifestyle bloggers who need captivating Central European content that drives engagement, builds followers, and attracts travel brand sponsorships.&lt;/p&gt;
    &lt;p&gt;Generate professional photos of yourself at Amsterdam's picturesque canals, colorful buildings, and iconic Dutch architecture. Ideal for travel bloggers, lifestyle influencers, and content creators building a European travel portfolio that increases followers, engagement, and opens doors to tourism brand collaborations.&lt;/p&gt;
    &lt;p&gt;Create breathtaking photos of yourself at Rome's historic landmarks like the Colosseum, Trevi Fountain, and Vatican. Perfect for travel content creators, Instagram influencers, and building a luxury travel portfolio that increases engagement, attracts brand deals, and grows your audience with timeless Italian scenery.&lt;/p&gt;
    &lt;p&gt;Choose any photo pack, upload your photos, and get professional results in minutes. No photographer, no studio, no expensive equipment needed.&lt;/p&gt;
    &lt;p&gt;From professional headshots to creative fantasy - find the perfect template&lt;/p&gt;
    &lt;p&gt;Upload photos, select a pack, get professional results instantly&lt;/p&gt;
    &lt;p&gt;Perfect for LinkedIn, dating apps, e-commerce, marketing, and more&lt;/p&gt;
    &lt;p&gt;30-day money back guarantee&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://photowand.ai/packs"/><published>2025-10-07T18:57:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507398</id><title>Eliminating contrails from flying could be incredibly cheap</title><updated>2025-10-07T20:10:43.046333+00:00</updated><content>&lt;doc fingerprint="774ec8726186b74b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Eliminating contrails from flying could be incredibly cheap&lt;/head&gt;
    &lt;head rend="h3"&gt;Could we halve aviation's climate impact at a fraction of the cost of sustainable aviation fuels?&lt;/head&gt;
    &lt;p&gt;Eliminating CO2 emissions from flying is going to be expensive, regardless of the solution the world adopts.1&lt;/p&gt;
    &lt;p&gt;But aviation also contributes to global warming through its non-CO2 effects. Those are mostly “contrails”, which I’ll explain in more detail soon. Getting rid of those could be incredibly cheap. So cheap that it’s difficult to understand why we don’t just go ahead and fix it.&lt;/p&gt;
    &lt;p&gt;On a recent podcast, I spoke to Ian McKay, CEO of Orca Sciences, about this. One of their portfolio projects is Contrails.org. Their solution to eliminating contrails is to accurately forecast and model the atmospheric conditions that generate them, and reroute planes so that they avoid these “contrail-forming” parts of the atmosphere.&lt;/p&gt;
    &lt;p&gt;This is a solution that I hadn’t really paid much attention to, and most people are unaware of. So I thought I’d do a deep dive on contrails; explore how this solution might work; and whether it’s really that cheap.&lt;/p&gt;
    &lt;p&gt;To pre-empt the critics: this solution does not mean the aviation industry can ignore the CO2 impacts of flying. Tackling contrails would not absolve them of responsibility for finding low-carbon alternatives to jet fuel. It’s not a substitute, but an addition. Currently, their non-CO2 impacts are not measured or reported, so bringing more attention to contrails means they’re taking full responsibility for their climate impact, which is not the case at the moment.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are contrails?&lt;/head&gt;
    &lt;p&gt;When you see a plane in the sky, you might see a small, white cloud-like trail behind it. Those are contrails (short for “condensation trails”).&lt;/p&gt;
    &lt;p&gt;Water vapour, soot and other particles (basically pollutants) are emitted from the back of jet engines. Water droplets can condense around these particles, and because it’s pretty cold up there, they can freeze to form ice crystals. Sometimes these white lines are very faint and hard to see. But in some cases, they can form “cirrus clouds”: wispy ones that form at high altitudes.&lt;/p&gt;
    &lt;p&gt;These contrails can have both cooling and warming impacts. I’ve sketched this out in the schematic below.&lt;/p&gt;
    &lt;p&gt;Some sunlight can reflect off of them, rather than passing through to the surface, which has a cooling effect.&lt;/p&gt;
    &lt;p&gt;Most sunlight, though, does pass through, and outgoing irradiation then gets trapped by the cirrus clouds. This has a warming effect, which tends to be larger than the cooling one, so on net, contrails cause warming.&lt;/p&gt;
    &lt;p&gt;Since someone asked about this over email: the fact that there is no sunlight at night, and less during winter, there is less to “reflect” off the top of cirrus clouds. That means the cooling effect is weaker at night, and in winter, and the net warming effect stronger. This means avoiding contrails in winter and at night has an even stronger impact on reducing warming.2&lt;/p&gt;
    &lt;head rend="h2"&gt;What impact do they have on global warming?&lt;/head&gt;
    &lt;p&gt;It’s common to want to compare them to CO2 emissions, but it’s first worth emphasising how different the contributions are in terms of intensity and persistence.&lt;/p&gt;
    &lt;p&gt;Contrails have a strong “effective radiative forcing” effect. This basically measures the net change in energy flow at the top of the atmosphere: and that change in energy flow dictates how much warming is needed at the surface to offset it. But, this warming effective is very short-lived. If we were to stop contrails today, the warming effect would disappear within a day or so.&lt;/p&gt;
    &lt;p&gt;Think of it like a very brief but strong pulse of energy.&lt;/p&gt;
    &lt;p&gt;CO2, on the other hand, has a smaller effect on radiative forcing, but once you emit it, it stays there for centuries or more.&lt;/p&gt;
    &lt;p&gt;I thought this diagram from Contrails.org makes this point clearly. This article by them explains the comparison in much more detail.&lt;/p&gt;
    &lt;p&gt;When we think about the climate impacts of aviation, then, most of the warming from CO2 emissions is not due to the emissions this year, but the cumulative effect (which persists) over the past 70 years. But for contrails, the warming impact is only really from those created very recently (hours to days); the small temperature response decays over months to a few years.&lt;/p&gt;
    &lt;p&gt;You might have heard people say that “more than half of the warming caused by aviation comes from non-CO2 sources”. A big part of that is contrails. But this does not mean that for any given flight, half of the warming is coming from contrails and the other half from burning jet fuel.&lt;/p&gt;
    &lt;p&gt;This apparent ‘half-half’ balance is a coincidence of timing: the cumulative CO₂ effect built up over decades happens to be of similar order to the instantaneous contrail effect for that year. In the chart below you can see the effective radiative forcing caused by CO2 and contrails in 2019. Again, the CO2 emitted in 2019 is just a small part of the warming. Most of comes from emissions built over decades, that stay there. It just so happens that this cumulative amount of warming is not that different from the instantaneous, short-lived impact of contrails in 2019. Eventually more and more CO2 emissions will accumulate, and the share coming from contrails will shrink in relative terms.&lt;/p&gt;
    &lt;p&gt;But as it stands today, we could get rid of around half of the warming impact — maybe slightly less — from aviation, if we were to tackle contrails. The impact would be almost immediate.&lt;/p&gt;
    &lt;p&gt;How, then, do contrails stack up in terms of total warming? They contribute roughly 2% to the world’s effective radiative forcing; tackling them would reduce that by a similar amount.3&lt;/p&gt;
    &lt;p&gt;What this comparison should make extremely clear is that reducing contrails does not mean we don’t also need to tackle CO2 emissions from aviation. Ultimately that is the persistent driver of long-term temperature change. What tackling contrails now would do is slightly reduce the rate of warming (and therefore do something reduce the risks of nearer-term feedbacks that could affect the release of CO2 from natural systems, and also affect long-term temperature change). It is not an excuse or a substitute for finding a way to decarbonise jet fuel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Only a few percent of flights cause most of the warming&lt;/head&gt;
    &lt;p&gt;One crucial reason why eliminating contrails could be so cost-effective is that a very small percentage of flights create the majority of the impact. This means we don’t need to divert or shift the trajectory of all the world’s flights; only a few percent of them.&lt;/p&gt;
    &lt;p&gt;In the chart below, you can see the breakdown of the warming effect across the world’s flights.4 On the left-hand side, we have the share of flights, and on the right, their collective contribution to the total warming impact of contrails.&lt;/p&gt;
    &lt;p&gt;Just 3% of flights generate 80% of the warming. A further 14% generate 29%.&lt;/p&gt;
    &lt;p&gt;You might notice that this sums to 109%. But this is because some flights generate a cooling effect of 9%. Put them together and we get 100%.&lt;/p&gt;
    &lt;p&gt;Most flights — three-quarters of them — barely generate contrails at all and cause no warming or cooling.&lt;/p&gt;
    &lt;p&gt;Some sources cite slightly different numbers for this “80% warming effect”. For example, Contrails.org cite 5% of flights. I’ve seen others quote 2%.5 But the point remains the same: a few percent of the flights completely dominate the climate impact.&lt;/p&gt;
    &lt;head rend="h2"&gt;There are ways to dramatically reduce them&lt;/head&gt;
    &lt;p&gt;So, how can we get rid of these contrails?&lt;/p&gt;
    &lt;p&gt;Contrails with a strong warming impact mostly form in thin regions of the atmosphere, which are cold and humid. If planes fly through these zones of atmosphere, contrails are much more likely to form.&lt;/p&gt;
    &lt;p&gt;The solution, then, is for some planes to take a short detour to avoid them. You can see this in the schematic below.&lt;/p&gt;
    &lt;p&gt;How would we know which planes to re-route and by how much?&lt;/p&gt;
    &lt;p&gt;Using detailed weather forecasts, satellite images, and flight plans, scientists can identify where these zones will be far in advance and work with flight planners to find a way to reroute flights crossing these zones to avoid them. These forecasts and models are what Contrails.org do.&lt;/p&gt;
    &lt;p&gt;Google also launched “Project Contrails” which uses Artificial Intelligence (AI) to build models that can do this.&lt;/p&gt;
    &lt;p&gt;Of course, this wouldn’t work if these planes had to do a severe detour. People would not be happy about a longer flight time. And, the extra fuel that would need to be burned to go the extra distance would eventually cancel out the climate benefits from getting rid of the contrails.&lt;/p&gt;
    &lt;p&gt;The proposed detours typically result in a 1% shift (and again, this is only for a small percentage of flights). That means increasing fuel use and flight time by around 1%. So if your flight is three hours long, it’s only adding an extra two minutes. For a 10-hour flight, six minutes. This seems socially acceptable to me; most people would barely notice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stopping warming from contrails could be incredibly cheap&lt;/head&gt;
    &lt;p&gt;The fact that the warming impact is skewed towards such a small share of flights dramatically reduces the costs.&lt;/p&gt;
    &lt;p&gt;What are the costs associated with implementing this?&lt;/p&gt;
    &lt;p&gt;There are operational costs associated with weather prediction, modelling, and integration into flight planning. Especially with the integration of AI, this is probably not that expensive. A bit more costly is the extra jet fuel that’s needed for rerouted planes.&lt;/p&gt;
    &lt;p&gt;When I spoke with Ian McKay, he suggested the additional cost would be around $5 per flight. I think he meant this as $5 spread across the entire flight (not per passenger). This is also the figure they give on Contrails.org.6 I also think that in this assumption, the costs are spread evenly across the entire airline fleet (regardless of whether they’re rerouted or not). For the small share of rerouted flights alone, the “per flight” cost would be higher.&lt;/p&gt;
    &lt;p&gt;That’s incredibly low. Spreading that over 100 passengers, and each is paying just 5 cents extra.&lt;/p&gt;
    &lt;p&gt;Other studies have reported higher costs, although they’re still incredibly cheap.&lt;/p&gt;
    &lt;p&gt;This paper modelled over 84,000 flights and found that the additional cost of operations and fuel burn for rerouting increased costs by around $1.1 million.7 By my calculations, that’s around $10 to $15 per flight.&lt;/p&gt;
    &lt;p&gt;We can do a very basic back-of-the-envelope calculation to sense-check this. The total fuel cost of flying from Barcelona to Berlin is probably around $2,000.8 If the flight burned 1% extra fuel due to rerouting, the extra cost for the flight would be around $20. Add the operational costs of the forecasting, and this could be $30 to $40. Then spread across all flights, not just the rerouted ones, and this falls back down to the $5 to $10 range again.&lt;/p&gt;
    &lt;p&gt;Transport &amp;amp; Environment (T&amp;amp;E) estimates that the cost could range from $2 to $5 per passenger (or hundreds of dollars per flight).9 They do note that they make very conservative assumptions, and therefore find costs that are 3 to 10 times higher than those from other sources.&lt;/p&gt;
    &lt;p&gt;For a flight in Europe, such as from Barcelona to Berlin, the cost would be €1.20 ($1.88) per passenger. A Transatlantic ticket would be more expensive, around €3.90 for a trip from Paris to New York. Given that an economy ticket from Paris to New York probably costs around €350 to €400, this would increase the cost by around 1%.&lt;/p&gt;
    &lt;p&gt;Perhaps, then, the best estimate is somewhere in the middle: around 50 cents per passenger.&lt;/p&gt;
    &lt;p&gt;Translating this into the cost per tonne of carbon dioxide equivalent — the “carbon abatement” cost — shows how cheap this is compared to many other climate solutions. It’s probably in the range of a few dollars per tonne CO2e. Contrails.org estimates that it’s slightly below $1 per tonne.&lt;/p&gt;
    &lt;p&gt;Switching to “sustainable aviation fuel” currently has an estimated cost in the range of hundreds of dollars per tonne of CO2e avoided.10 Rather than a flight ticket being 1% more expensive, it would be more than double the price. Eliminating contrails is therefore hundreds of times cheaper and can be scaled much more quickly than replacing the entire aircraft fleet or its fuel source.11&lt;/p&gt;
    &lt;head rend="h2"&gt;Why aren’t we doing more to eliminate contrails?&lt;/head&gt;
    &lt;p&gt;When I asked Ian McKay why airlines were not doing more, he gave two main reasons.&lt;/p&gt;
    &lt;p&gt;The first is that even if the cost per flight is low, the total cost across their entire fleet adds up. Let’s take a quick example for British Airways. They operate around 300,000 flights per year. If we reroute 2% of those to avoid contrails, and rerouting increases fuel burn by around 2% (I’m being deliberately harsh here), then I estimate that the additional fuel costs are in the range of $1.2 to $2 million per year.12 Let’s say that the operational costs of forecasting and modelling adds another 50%. That takes us to around $2.5 to $3 million.&lt;/p&gt;
    &lt;p&gt;In 2024, British Airways had an operating profit of around $2.7 billion. Contrail avoidance would therefore be just 0.1% of its operating profits.&lt;/p&gt;
    &lt;p&gt;But I’m not convinced that this cost factor is the main reason. They could pass this cost on to consumers; flight prices vary by a lot more than a few dollars for a variety of factors. They could either make a huge deal of the fact that they’re dramatically cutting their climate impact, and get “PR” buy-in from consumers for that. Or they could keep quiet, and most consumers would never notice the difference in cost.&lt;/p&gt;
    &lt;p&gt;The second — which seems more likely — is that, currently, most people are unaware of the climate impact of contrails. In that sense, airlines can basically ignore it and pretend they don’t exist. By trying to tackle them, they’d only draw more attention. People would then be aware that the climate impact of aviation is even higher than they thought.&lt;/p&gt;
    &lt;p&gt;I still think that the airline that steps up and commits to eliminating contrails — possibly even claiming to have halved its climate impact — would be well-received by many customers. I would see it as reputational gain, rather than a risk.&lt;/p&gt;
    &lt;p&gt;Nonetheless, there are no signs that the aviation industry itself is going to step up. This is where government policy could step in.&lt;/p&gt;
    &lt;p&gt;Rather than an airline leading by example, a country or region could. In a more pro-climate political environment, the United States could have led this effort domestically, mandating that internal flights eliminate their contrails. More likely is the European Union. It has already been making some progress in this direction — not by mandating that airlines pay for contrail avoidance — but by simply reporting these climate impacts in the first place. Earlier this year, its trading system regulations were updated to require airlines to monitor and report non-CO2 impacts. That sounds basic, but it is not the standard across most of the world; these impacts are usually not included. Unsurprisingly, it has received pushback from the aviation industry, with them asking for these reports to be voluntary.&lt;/p&gt;
    &lt;p&gt;Progress will undoubtedly be met with initial resistance, but I still think that regulatory policy seems like the most likely path to widespread implementation.&lt;/p&gt;
    &lt;p&gt;What would help a lot is increasing public awareness of the existence of contrails, their climate impacts, and how inexpensive it could be to eliminate them. There is a general understanding that decarbonising aviation is expensive, and this often means the aviation industry gets more of a free ride. But this is based on replacing jet fuel. If people were aware that it could cut a huge chunk of its footprint at a fraction of the cost, they might be more demanding.&lt;/p&gt;
    &lt;p&gt;Eliminating a few percent of the world’s warming is a big deal when the costs are so small. It seems insane to me that such a cheap solution is sitting there, completely untapped.&lt;/p&gt;
    &lt;p&gt;This could be substituting jet fuel for an alternative such as green hydrogen or biofuels.&lt;lb/&gt;But some suggest that it could be cheaper to keep burning jet fuel and try to capture — and securely store — an equivalent amount of CO2 directly.&lt;/p&gt;
    &lt;p&gt;Their question went further, asking if having some additional warming in winter is actually beneficial as it reduces risks such as cold-related deaths.&lt;lb/&gt;This could be true if the impacts were local. However, the warming that results is both global, and lasts over the long-term (even if the immediate forcing is short-lived, as we’ll come on to).&lt;/p&gt;
    &lt;p&gt;Lee, D. S., Fahey, D. W., Skowron, A., Allen, M. R., Burkhardt, U., Chen, Q., ... &amp;amp; Wilcox, L. J. (2021). The contribution of global aviation to anthropogenic climate forcing for 2000 to 2018. Atmospheric Environment.&lt;/p&gt;
    &lt;p&gt;This is based on data published in the Transport and Environment (T&amp;amp;E) 2024 Report: Contrail avoidance: aviation’s climate opportunity of the decade.&lt;/p&gt;
    &lt;p&gt;Teoh, R., Engberg, Z., Schumann, U., Voigt, C., Shapiro, M., Rohs, S., &amp;amp; Stettler, M. E. (2024). Global aviation contrail climate effects from 2019 to 2021. Atmospheric Chemistry and Physics.&lt;/p&gt;
    &lt;p&gt;Here they say:&lt;lb/&gt;“Better yet, properly implemented, contrail management is low-cost: studies show a fleet-average fuel cost of roughly $5.00 per flight, or less than $1 per tonne of CO2 equivalent warming avoided.”&lt;/p&gt;
    &lt;p&gt;Agarwal, A., Meijer, V. R., Eastham, S. D., Speth, R. L., &amp;amp; Barrett, S. R. (2022). Reanalysis-driven simulations may overestimate persistent contrail formation by 100%–250%. Environmental Research Letters.&lt;/p&gt;
    &lt;p&gt;This assumes burning around 3,000 litres of fuel, weighing around 2.5 tonnes.&lt;lb/&gt;The cost per tonne is around $900.&lt;lb/&gt;That gives a total cost of around $2250.&lt;/p&gt;
    &lt;p&gt;Again, these costs are distributed across all flights, not just those that are rerouted.&lt;/p&gt;
    &lt;p&gt;Watson, M. J., Machado, P. G., Da Silva, A. V., Saltar, Y., Ribeiro, C. O., Nascimento, C. A. O. D., &amp;amp; Dowling, A. W. (2024). Sustainable aviation fuel technologies, costs, emissions, policies, and markets: A critical review. Journal of Cleaner Production.&lt;/p&gt;
    &lt;p&gt;Here’s an ugly, but useful graph from the UK Government’s cost-benefit report on SAFs.&lt;/p&gt;
    &lt;p&gt;This is based on fuel costs ranging from $600 to $1000 per tonne.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sustainabilitybynumbers.com/p/eliminating-contrails"/><published>2025-10-07T19:07:07+00:00</published></entry></feed>