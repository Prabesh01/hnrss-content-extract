<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-30T20:11:17.970124+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46095585</id><title>CachyOS: Fast and Customizable Linux Distribution</title><updated>2025-11-30T20:11:26.505864+00:00</updated><content>&lt;doc fingerprint="e291287fa1afe4ee"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Blazingly Fast &amp;amp; Customizable Linux distribution&lt;/head&gt;
    &lt;p&gt;CachyOS is designed to deliver lightning-fast speeds and stability, ensuring a smooth and enjoyable computing experience every time you use it. Whether you're a seasoned Linux user or just starting out, CachyOS is the ideal choice for those looking for a powerful, customizable and blazingly fast operating system.&lt;/p&gt;
    &lt;p&gt;Features&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover the Benefits of CachyOS&lt;/head&gt;
    &lt;p&gt;Experience Cutting-Edge Linux Performance with CachyOS - A distribution built on Arch Linux, CachyOS features the optimized linux-cachyos kernel utilizing the advanced BORE Scheduler for unparalleled performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Enhance Your Performance with Optimized Packages&lt;/head&gt;
    &lt;p&gt;CachyOS does compile packages with the x86-64-v3, x86-64-v4 and Zen4 instruction set and LTO to provide a higher performance. Core packages also get PGO or BOLT optimization.&lt;/p&gt;
    &lt;head rend="h3"&gt;Select Your Preferred Edition&lt;/head&gt;
    &lt;p&gt;CachyOS offers a variety of popular Desktop Environments, Wayland Compositors and X11 Window Managers including KDE Plasma, GNOME, XFCE, i3, Wayfire, LXQt, Openbox, Cinnamon, COSMIC, UKUI, LXDE, Mate, Budgie, Qtile, Hyprland, Sway and Niri. Select your preferred environment during the online installation process.&lt;/p&gt;
    &lt;head rend="h3"&gt;Customizable Installation Process&lt;/head&gt;
    &lt;p&gt;CachyOS offers a choice of two installers to fit your needs: a user-friendly GUI version based on Calamares, and a CLI-based option for those who prefer a streamlined, non-graphical installation experience.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power Up Your Computing with Robust Kernel Support&lt;/head&gt;
    &lt;p&gt;CachyOS utilizes the BORE Scheduler for better interactivity, and offers a variety of scheduler options including EEVDF, sched-ext, ECHO, and RT. All kernels are compiled with optimized x86-64-v3, x86-64-v4, Zen4 instructions and LTO to be optimized for your CPU.&lt;/p&gt;
    &lt;head rend="h2"&gt;Support Our Efforts.&lt;/head&gt;
    &lt;p&gt;Your generosity is appreciated - Thank you for supporting our work in the open-source community.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cachyos.org/"/><published>2025-11-30T10:47:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46096337</id><title>Advent of Code 2025</title><updated>2025-11-30T20:11:26.289027+00:00</updated><content>&lt;doc fingerprint="9ad8f9db2d32aff8"&gt;
  &lt;main&gt;&lt;p&gt;Hi! I'm Eric Wastl. I make Advent of Code. I hope you like it! I also make lots of other things. I'm on Bluesky, Mastodon, and GitHub.&lt;/p&gt;&lt;p&gt;Advent of Code is an Advent calendar of small programming puzzles for a variety of skill levels that can be solved in any programming language you like. People use them as interview prep, company training, university coursework, practice problems, a speed contest, or to challenge each other.&lt;/p&gt;&lt;p&gt;You don't need a computer science background to participate - just a little programming knowledge and some problem solving skills will get you pretty far. Nor do you need a fancy computer; every problem has a solution that completes in at most 15 seconds on ten-year-old hardware.&lt;/p&gt;&lt;p&gt;If you'd like to support Advent of Code, you can do so indirectly by helping to AoC++.&lt;/p&gt;it with others or directly via&lt;head rend="h2"&gt;--- General Tips ---&lt;/head&gt;&lt;p&gt;If you get stuck, try your solution against the examples given in the puzzle; you should get the same answers. If not, re-read the description. Did you misunderstand something? Is your program doing something you don't expect? After the examples work, if your answer still isn't correct, build some test cases for which you can verify the answer by hand and see if those work with your program. Make sure you have the entire puzzle input. If you're still stuck, maybe ask a friend for help, or come back to the puzzle later. You can also ask for hints in the subreddit.&lt;/p&gt;&lt;head rend="h2"&gt;--- Frequently Asked Questions ---&lt;/head&gt;&lt;p&gt;Is there an easy way to select entire code blocks? You should be able to triple-click code blocks to select them. You'll need JavaScript enabled.&lt;/p&gt;&lt;code&gt;#!/usr/bin/env perl
use warnings;
use strict;

print "You can test it out by ";
print "triple-clicking this code.\n";
&lt;/code&gt;
&lt;p&gt;How does authentication work? Advent of Code uses OAuth to confirm your identity through other services. When you log in, you only ever give your credentials to that service - never to Advent of Code. Then, the service you use tells the Advent of Code servers that you're really you. In general, this reveals no information about you beyond what is already public; here are examples from Reddit and GitHub. Advent of Code will remember your unique ID, names, URL, and image from the service you use to authenticate.&lt;/p&gt;&lt;p&gt;Why was this puzzle so easy / hard? The difficulty and subject matter varies throughout each event. Very generally, the puzzles get more difficult over time, but your specific skillset will make each puzzle significantly easier or harder for you than someone else. Making puzzles is tricky.&lt;/p&gt;&lt;p&gt;Why do the puzzles unlock at midnight EST/UTC-5? Because that's when I can consistently be available to make sure everything is working. I also have a family, a day job, and even need sleep occasionally. If you can't participate at midnight, that's not a problem; if you want to race, many people use private leaderboards to compete with people in their area.&lt;/p&gt;&lt;p&gt;I find the text on the site hard to read. Is there a high contrast mode? There is a high contrast alternate stylesheet. Firefox supports these by default (View -&amp;gt; Page Style -&amp;gt; High Contrast).&lt;/p&gt;&lt;p&gt;I have a puzzle idea! Can I send it to you? Please don't. Because of legal issues like copyright and attribution, I don't accept puzzle ideas, and I won't even read your email if it looks like one just in case I use parts of it by accident.&lt;/p&gt;&lt;p&gt;Did I find a bug with a puzzle? Once a puzzle has been out for even an hour, many people have already solved it; after that point, bugs are very unlikely. Start by asking on the subreddit.&lt;/p&gt;&lt;p&gt;Should I try to get a fast solution time? Maybe. Solving puzzles is hard enough on its own, but trying for a fast time also requires many additional skills and a lot of practice; speed-solves often look nothing like code that would pass a code review. If that sounds interesting, go for it! However, you should do Advent of Code in a way that is useful to you, and so it is completely fine to choose an approach that meets your goals and ignore speed entirely.&lt;/p&gt;&lt;p&gt;Why did the number of days per event change? It takes a ton of my free time every year to run Advent of Code, and building the puzzles accounts for the majority of that time. After keeping a consistent schedule for ten years(!), I needed a change. The puzzles still start on December 1st so that the day numbers make sense (Day 1 = Dec 1), and puzzles come out every day (ending mid-December).&lt;/p&gt;&lt;p&gt;What happened to the global leaderboard? The global leaderboard was one of the largest sources of stress for me, for the infrastructure, and for many users. People took things too seriously, going way outside the spirit of the contest; some people even resorted to things like DDoS attacks. Many people incorrectly concluded that they were somehow worse programmers because their own times didn't compare. What started as a fun feature in 2015 became an ever-growing problem, and so, after ten years of Advent of Code, I removed the global leaderboard. (However, I've made it so you can share a read-only view of your private leaderboard. Please don't use this feature or data to create a "new" global leaderboard.)&lt;/p&gt;&lt;p&gt;While trying to get a fast time on a private leaderboard, may I use AI / watch streamers / check the solution threads / ask a friend for help / etc? If you are a member of any private leaderboards, you should ask the people that run them what their expectations are of their members. If you don't agree with those expectations, you should find a new private leaderboard or start your own! Private leaderboards might have rules like maximum runtime, allowed programming language, what time you can first open the puzzle, what tools you can use, or whether you have to wear a silly hat while working.&lt;/p&gt;&lt;p&gt;Should I use AI to solve Advent of Code puzzles? No. If you send a friend to the gym on your behalf, would you expect to get stronger? Advent of Code puzzles are designed to be interesting for humans to solve - no consideration is made for whether AI can or cannot solve a puzzle. If you want practice prompting an AI, there are almost certainly better exercises elsewhere designed with that in mind.&lt;/p&gt;&lt;p&gt;Can I copy/redistribute part of Advent of Code? Please don't. Advent of Code is free to use, not free to copy. If you're posting a code repository somewhere, please don't include parts of Advent of Code like the puzzle text or your inputs. If you're making a website, please don't make it look like Advent of Code or name it something similar.&lt;/p&gt;&lt;head rend="h2"&gt;--- Credits ---&lt;/head&gt;&lt;p&gt;Puzzles, Code, &amp;amp; Design: Eric Wastl&lt;/p&gt;&lt;p&gt;Beta Testing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Ben Lucek&lt;/item&gt;&lt;item&gt;JP Burke&lt;/item&gt;&lt;item&gt;Aneurysm9&lt;/item&gt;&lt;item&gt;Andrew Skalski&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Community Managers: Danielle Lucek and Aneurysm9&lt;/p&gt;&lt;p&gt;Playing: You!&lt;/p&gt;&lt;head rend="h2"&gt;--- Legal ---&lt;/head&gt;&lt;p&gt;Advent of Code is a registered trademark in the United States. The design elements, language, styles, and concept of Advent of Code are all the sole property of Advent of Code and may not be replicated or used by any other person or entity without express written consent of Advent of Code. Copyright 2015-2025 Advent of Code. All rights reserved.&lt;/p&gt;&lt;p&gt;You may link to or reference puzzles from Advent of Code in discussions, classes, source code, printed material, etc., even in commercial contexts. Advent of Code does not claim ownership or copyright over your solution implementation.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://adventofcode.com/2025/about"/><published>2025-11-30T13:07:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46096555</id><title>Norway wealth fund to vote for human rights report at Microsoft, against Nadella</title><updated>2025-11-30T20:11:24.859117+00:00</updated><content>&lt;doc fingerprint="6bc49f2c3b61fbcf"&gt;
  &lt;main&gt;
    &lt;p&gt;Norway's $2 trillion wealth fund said on Sunday it would vote for a shareholder proposal at the upcoming Microsoft annual general meeting requiring for a report on the risks of operating in countries with significant human rights concerns.&lt;/p&gt;
    &lt;p&gt;Microsoft management had recommended shareholders voted against the motion.&lt;/p&gt;
    &lt;p&gt;The fund also said it would vote against the re-appointment of CEO Satya Nadella as chair of the board, as well as against his pay package.&lt;/p&gt;
    &lt;p&gt;The fund owned a 1.35% stake worth $50 billion in the company as of June 30, according to fund data, making it the fund's second-largest equity holding overall, after Nvidia.&lt;/p&gt;
    &lt;p&gt;It is Microsoft's eighth-largest shareholder, according to LSEG data.&lt;/p&gt;
    &lt;p&gt;Investors in the U.S. tech company will decide whether to ratify the proposed motions at the AGM on Dec. 5.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/11/30/norway-wealth-fund-to-vote-for-human-rights-report-at-microsoft-agm-against-management.html"/><published>2025-11-30T13:40:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46096556</id><title>Windows drive letters are not limited to A-Z</title><updated>2025-11-30T20:11:24.332710+00:00</updated><content>&lt;doc fingerprint="c2841e11e92da09d"&gt;
  &lt;main&gt;&lt;p&gt;On its own, the title of this post is just a true piece of trivia, verifiable with the built-in &lt;code&gt;subst&lt;/code&gt; tool (among other methods).&lt;/p&gt;&lt;p&gt;Here's an example creating the drive &lt;code&gt;+:\&lt;/code&gt; as an alias for a directory at &lt;code&gt;C:\foo&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;subst +: C:\foo
&lt;/code&gt;&lt;p&gt;The &lt;code&gt;+:\&lt;/code&gt; drive then works as normal (at least in cmd.exe, this will be discussed more later):&lt;/p&gt;&lt;code&gt;&amp;gt; cd /D +:\

+:\&amp;gt; tree .
Folder PATH listing
Volume serial number is 00000001 12AB:23BC
+:\
ââââbar
&lt;/code&gt;&lt;p&gt;However, understanding why it's true elucidates a lot about how Windows works under the hood, and turns up a few curious behaviors.&lt;/p&gt;&lt;p&gt;The paths that most people are familiar with are Win32 namespace paths, e.g. something like &lt;code&gt;C:\foo&lt;/code&gt; which is a drive-absolute Win32 path. However, the high-level APIs that take Win32 paths like &lt;code&gt;CreateFileW&lt;/code&gt; ultimately will convert a path like &lt;code&gt;C:\foo&lt;/code&gt; into a NT namespace path before calling into a lower level API within &lt;code&gt;ntdll.dll&lt;/code&gt; like &lt;code&gt;NtCreateFile&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This can be confirmed with NtTrace, where a call to &lt;code&gt;CreateFileW&lt;/code&gt; with &lt;code&gt;C:\foo&lt;/code&gt; ultimately leads to a call of &lt;code&gt;NtCreateFile&lt;/code&gt; with &lt;code&gt;\??\C:\foo&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;NtCreateFile( FileHandle=0x40c07ff640 [0xb8], DesiredAccess=SYNCHRONIZE|GENERIC_READ|0x80, ObjectAttributes="\??\C:\foo", IoStatusBlock=0x40c07ff648 [0/1], AllocationSize=null, FileAttributes=0, ShareAccess=7, CreateDisposition=1, CreateOptions=0x4000, EaBuffer=null, EaLength=0 ) =&amp;gt; 0
NtClose( Handle=0xb8 ) =&amp;gt; 0
&lt;/code&gt;&lt;p&gt;&lt;code&gt;createfilew.zig&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;const std = @import("std");
const windows = std.os.windows;
const L = std.unicode.wtf8ToWtf16LeStringLiteral;

pub extern "kernel32" fn CreateFileW(
    lpFileName: windows.LPCWSTR,
    dwDesiredAccess: windows.DWORD,
    dwShareMode: windows.DWORD,
    lpSecurityAttributes: ?*windows.SECURITY_ATTRIBUTES,
    dwCreationDisposition: windows.DWORD,
    dwFlagsAndAttributes: windows.DWORD,
    hTemplateFile: ?windows.HANDLE,
) callconv(.winapi) windows.HANDLE;

pub fn main() !void {
    const path = L("C:\\foo");
    const dir_handle = CreateFileW(
        path,
        windows.GENERIC_READ,
        windows.FILE_SHARE_DELETE | windows.FILE_SHARE_READ | windows.FILE_SHARE_WRITE,
        null,
        windows.OPEN_EXISTING,
        windows.FILE_FLAG_BACKUP_SEMANTICS | windows.FILE_FLAG_OVERLAPPED,
        null,
    );
    if (dir_handle == windows.INVALID_HANDLE_VALUE) return error.FailedToOpenDir;
    defer windows.CloseHandle(dir_handle);
}
&lt;/code&gt;&lt;p&gt;Built with:&lt;/p&gt;&lt;code&gt;zig build-exe createfilew.zig
&lt;/code&gt;&lt;p&gt;To run with NtTrace:&lt;/p&gt;&lt;code&gt;nttrace createfilew.exe &amp;gt; createfilew.log
&lt;/code&gt;&lt;p&gt;That &lt;code&gt;\??\C:\foo&lt;/code&gt; is a NT namespace path, which is what &lt;code&gt;NtCreateFile&lt;/code&gt; expects. To understand this path, though, we need to talk about the Object Manager, which is responsible for handling NT paths.&lt;/p&gt;&lt;p&gt;The Object Manager is responsible for keeping track of named objects, which we can explore using the WinObj tool. The &lt;code&gt;\??&lt;/code&gt; part of the &lt;code&gt;\??\C:\foo&lt;/code&gt; path is actually a special virtual folder within the Object Manager that combines the &lt;code&gt;\GLOBAL??&lt;/code&gt; folder and a per-user &lt;code&gt;DosDevices&lt;/code&gt; folder together.&lt;/p&gt;&lt;p&gt;For me, the object &lt;code&gt;C:&lt;/code&gt; is within &lt;code&gt;\GLOBAL??&lt;/code&gt;, and is actually a symbolic link to &lt;code&gt;\Device\HarddiskVolume4&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;So, &lt;code&gt;\??\C:\foo&lt;/code&gt; ultimately resolves to &lt;code&gt;\Device\HarddiskVolume4\foo&lt;/code&gt;, and then it's up to the actual device to deal with the &lt;code&gt;foo&lt;/code&gt; part of the path.&lt;/p&gt;&lt;p&gt;The important thing here, though, is that &lt;code&gt;\??\C:\foo&lt;/code&gt; is just one way of referring to the device path &lt;code&gt;\Device\HarddiskVolume4\foo&lt;/code&gt;. For example, volumes will also get a named object created using their GUID with the format &lt;code&gt;Volume{18123456-abcd-efab-cdef-1234abcdabcd}&lt;/code&gt; that is also a symlink to something like &lt;code&gt;\Device\HarddiskVolume4&lt;/code&gt;, so a path like &lt;code&gt;\??\Volume{18123456-abcd-efab-cdef-1234abcdabcd}\foo&lt;/code&gt; is effectively equivalent to &lt;code&gt;\??\C:\foo&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;All this is to say that there's nothing innately special about the named object &lt;code&gt;C:&lt;/code&gt;; the Object Manager treats it just like any other symbolic link and resolves it accordingly.&lt;/p&gt;&lt;p&gt;How I see it, drive letters are essentially just a convention borne out of the conversion of a Win32 path into a NT path. In particular, that would be down to the implementation of &lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In other words, since &lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt; converts &lt;code&gt;C:\foo&lt;/code&gt; to &lt;code&gt;\??\C:\foo&lt;/code&gt;, then an object named &lt;code&gt;C:&lt;/code&gt; will behave like a drive letter. To give an example of what I mean by that: in an alternate universe, &lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt; could convert the path &lt;code&gt;FOO:\bar&lt;/code&gt; to &lt;code&gt;\??\FOO:\bar&lt;/code&gt; and then &lt;code&gt;FOO:&lt;/code&gt; could behave like a drive letter.&lt;/p&gt;&lt;p&gt;So, getting back to the title, how does &lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt; treat something like &lt;code&gt;+:\foo&lt;/code&gt;? Well, exactly the same as &lt;code&gt;C:\foo&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;&amp;gt; paths.exe C:\foo
path type: .DriveAbsolute
  nt path: \??\C:\foo

&amp;gt; paths.exe +:\foo
path type: .DriveAbsolute
  nt path: \??\+:\foo
&lt;/code&gt;&lt;p&gt;&lt;code&gt;paths.zig&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;const std = @import("std");
const windows = std.os.windows;

pub fn main() !void {
    var arena_state = std.heap.ArenaAllocator.init(std.heap.page_allocator);
    defer arena_state.deinit();
    const arena = arena_state.allocator();

    const args = try std.process.argsAlloc(arena);
    if (args.len &amp;lt;= 1) return error.ExpectedArg;

    const path = try std.unicode.wtf8ToWtf16LeAllocZ(arena, args[1]);

    const path_type = RtlDetermineDosPathNameType_U(path);
    std.debug.print("path type: {}\n", .{path_type});
    const nt_path = try RtlDosPathNameToNtPathName_U(path);
    std.debug.print("  nt path: {f}\n", .{std.unicode.fmtUtf16Le(nt_path.span())});
}

const RTL_PATH_TYPE = enum(c_int) {
    Unknown,
    UncAbsolute,
    DriveAbsolute,
    DriveRelative,
    Rooted,
    Relative,
    LocalDevice,
    RootLocalDevice,
};

pub extern "ntdll" fn RtlDetermineDosPathNameType_U(
    Path: [*:0]const u16,
) callconv(.winapi) RTL_PATH_TYPE;

fn RtlDosPathNameToNtPathName_U(path: [:0]const u16) !windows.PathSpace {
    var out: windows.UNICODE_STRING = undefined;
    const rc = windows.ntdll.RtlDosPathNameToNtPathName_U(path, &amp;amp;out, null, null);
    if (rc != windows.TRUE) return error.BadPathName;
    defer windows.ntdll.RtlFreeUnicodeString(&amp;amp;out);

    var path_space: windows.PathSpace = undefined;
    const out_path = out.Buffer.?[0 .. out.Length / 2];
    @memcpy(path_space.data[0..out_path.len], out_path);
    path_space.len = out.Length / 2;
    path_space.data[path_space.len] = 0;

    return path_space;
}
&lt;/code&gt;&lt;p&gt;Therefore, if an object with the name &lt;code&gt;+:&lt;/code&gt; is within the virtual folder &lt;code&gt;\??&lt;/code&gt;, we can expect the Win32 path &lt;code&gt;+:\&lt;/code&gt; to behave like any other drive-absolute path, which is exactly what we see.&lt;/p&gt;&lt;p&gt;This section only focuses on a few things that were relevant to what I was working on. I encourage others to investigate the implications of this further if they feel so inclined.&lt;/p&gt;&lt;code&gt;explorer.exe&lt;/code&gt; doesn't play ballð&lt;p&gt;Drives with a drive-letter other than A-Z do not appear in File Explorer, and cannot be navigated to in File Explorer.&lt;/p&gt;&lt;code&gt;+:\&lt;/code&gt; in File Explorer
&lt;p&gt;For the "do not appear" part, my guess as to what's happening is that &lt;code&gt;explorer.exe&lt;/code&gt; is walking &lt;code&gt;\??&lt;/code&gt; and looking specifically for objects named &lt;code&gt;A:&lt;/code&gt; through &lt;code&gt;Z:&lt;/code&gt;. For the "cannot be navigated to" part, that's a bit more mysterious, but my guess is that &lt;code&gt;explorer.exe&lt;/code&gt; has a lot of special logic around handling paths typed into the location bar, and part of that restricts drive letters to &lt;code&gt;A&lt;/code&gt;-&lt;code&gt;Z&lt;/code&gt; (i.e. it's short-circuiting before it ever tries to actually open the path).&lt;/p&gt;&lt;p&gt;PowerShell seems to reject non-&lt;code&gt;A&lt;/code&gt;-&lt;code&gt;Z&lt;/code&gt; drives as well:&lt;/p&gt;&lt;code&gt;PS C:\&amp;gt; cd +:\
cd : Cannot find drive. A drive with the name '+' does not exist.
At line:1 char:1
+ cd +:\
+ ~~~~~~
    + CategoryInfo          : ObjectNotFound: (+:String) [Set-Location], DriveNotFoundException
    + FullyQualifiedErrorId : DriveNotFound,Microsoft.PowerShell.Commands.SetLocationCommand
&lt;/code&gt;
&lt;p&gt;Drive letters don't have to be within the ASCII range at all; they can also be non-ASCII characters.&lt;/p&gt;&lt;code&gt;&amp;gt; subst â¬: C:\foo

&amp;gt; cd /D â¬:\

â¬:\&amp;gt; tree .
Folder PATH listing
Volume serial number is 000000DE 12AB:23BC
â¬:\
ââââbar
&lt;/code&gt;
&lt;p&gt;Non-ASCII drive letters are even case-insensitive like &lt;code&gt;A&lt;/code&gt;-&lt;code&gt;Z&lt;/code&gt; are:&lt;/p&gt;&lt;code&gt;&amp;gt; subst Î: C:\foo

&amp;gt; cd /D Î»:\

Î»:\&amp;gt; tree .
Folder PATH listing
Volume serial number is 000000DE 12AB:23BC
Î»:\
ââââbar
&lt;/code&gt;
&lt;p&gt;However, drive-letters cannot be arbitrary Unicode graphemes or even arbitrary code points; they are restricted to a single WTF-16 code unit (a &lt;code&gt;u16&lt;/code&gt;, so &amp;lt;= &lt;code&gt;U+FFFF&lt;/code&gt;). The tool that we've been using so far (&lt;code&gt;subst.exe&lt;/code&gt;) errors with &lt;code&gt;Invalid parameter&lt;/code&gt; if you try to use a drive letter with a code point larger than &lt;code&gt;U+FFFF&lt;/code&gt;, but you can get around that by going through the &lt;code&gt;MountPointManager&lt;/code&gt; directly:&lt;/p&gt;&lt;code&gt;ð¤¢:&lt;/code&gt; symlink&lt;code&gt;const std = @import("std");
const windows = std.os.windows;
const L = std.unicode.wtf8ToWtf16LeStringLiteral;

const MOUNTMGR_CREATE_POINT_INPUT = extern struct {
    SymbolicLinkNameOffset: windows.USHORT,
    SymbolicLinkNameLength: windows.USHORT,
    DeviceNameOffset: windows.USHORT,
    DeviceNameLength: windows.USHORT,
};

pub fn main() !void {
    const mgmt_handle = try windows.OpenFile(L("\\??\\MountPointManager"), .{
        .access_mask = windows.SYNCHRONIZE | windows.GENERIC_READ | windows.GENERIC_WRITE,
        .share_access = windows.FILE_SHARE_READ | windows.FILE_SHARE_WRITE | windows.FILE_SHARE_DELETE,
        .creation = windows.FILE_OPEN,
    });
    defer windows.CloseHandle(mgmt_handle);

    const volume_name = L("\\Device\\HarddiskVolume4");
    const mount_point = L("\\DosDevices\\ð¤¢:");

    const buf_size = @sizeOf(MOUNTMGR_CREATE_POINT_INPUT) + windows.MAX_PATH * 2 + windows.MAX_PATH * 2;
    var input_buf: [buf_size]u8 align(@alignOf(MOUNTMGR_CREATE_POINT_INPUT)) = [_]u8{0} ** buf_size;

    var input_struct: *MOUNTMGR_CREATE_POINT_INPUT = @ptrCast(&amp;amp;input_buf[0]);
    input_struct.SymbolicLinkNameOffset = @sizeOf(MOUNTMGR_CREATE_POINT_INPUT);
    input_struct.SymbolicLinkNameLength = mount_point.len * 2;
    input_struct.DeviceNameOffset = input_struct.SymbolicLinkNameOffset + input_struct.SymbolicLinkNameLength;
    input_struct.DeviceNameLength = volume_name.len * 2;

    @memcpy(input_buf[input_struct.SymbolicLinkNameOffset..][0..input_struct.SymbolicLinkNameLength], @as([*]const u8, @ptrCast(mount_point)));
    @memcpy(input_buf[input_struct.DeviceNameOffset..][0..input_struct.DeviceNameLength], @as([*]const u8, @ptrCast(volume_name)));

    const IOCTL_MOUNTMGR_CREATE_POINT = windows.CTL_CODE(windows.MOUNTMGRCONTROLTYPE, 0, .METHOD_BUFFERED, windows.FILE_READ_ACCESS | windows.FILE_WRITE_ACCESS);
    try windows.DeviceIoControl(mgmt_handle, IOCTL_MOUNTMGR_CREATE_POINT, &amp;amp;input_buf, null);
}
&lt;/code&gt;
&lt;p&gt;(the compiled executable must be run as administrator)&lt;/p&gt;&lt;p&gt;However, having the symlink in place doesn't solve anything on its own:&lt;/p&gt;&lt;code&gt;&amp;gt; cd /D ð¤¢:\
The filename, directory name, or volume label syntax is incorrect.
&lt;/code&gt;
&lt;p&gt;This is because there's no way to get the drive-absolute Win32 path &lt;code&gt;ð¤¢:\&lt;/code&gt; to end up as the relevant NT path. As mentioned earlier, the behavior of &lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt; is what matters, and we can verify that it will not convert a drive-absolute path with a drive letter bigger than &lt;code&gt;U+FFFF&lt;/code&gt; to the relevant NT path:&lt;/p&gt;&lt;code&gt;C:\foo&amp;gt; paths.exe ð¤¢:\foo
path type: .Relative
  nt path: \??\C:\foo\ð¤¢:\foo
&lt;/code&gt;

&lt;p&gt;It's very common for path-related functions to be written without the use of system-specific APIs, which means that there's high potential for a mismatch between how &lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt; treats a file path and how something like a particular implementation of &lt;code&gt;path.isAbsolute&lt;/code&gt; treats a file path.&lt;/p&gt;&lt;p&gt;As a random example, Rust only considers paths with &lt;code&gt;A&lt;/code&gt;-&lt;code&gt;Z&lt;/code&gt; drive letters as absolute:&lt;/p&gt;&lt;code&gt;use std::path::Path;

fn main() {
    println!("C:\\ {}", Path::new("C:\\foo").is_absolute());
    println!("+:\\ {}", Path::new("+:\\foo").is_absolute());
    println!("â¬:\\ {}", Path::new("â¬:\\foo").is_absolute());
}
&lt;/code&gt;
&lt;code&gt;&amp;gt; rustc test.rs

&amp;gt; test.exe
C:\ true
+:\ false
â¬:\ false
&lt;/code&gt;
&lt;p&gt;Whether or not this represents a problem worth fixing is left as an exercise for the reader (I genuinely don't know if it is a problem), but there's a second wrinkle (hinted at previously) involving text encoding that can make something like an &lt;code&gt;isAbsolute&lt;/code&gt; implementation return different results for the same path. This wrinkle is the reason I looked into this whole thing in the first place, as when I was doing some work on Zig's path-related functions recently I realized that looking at &lt;code&gt;path[0]&lt;/code&gt;, &lt;code&gt;path[1]&lt;/code&gt;, and &lt;code&gt;path[2]&lt;/code&gt; for a pattern like &lt;code&gt;C:\&lt;/code&gt; will look at different parts of the path depending on the encoding. That is, for something like &lt;code&gt;â¬:\&lt;/code&gt; (which is made up of the code points &lt;code&gt;&amp;lt;U+20AC&amp;gt;&amp;lt;U+003A&amp;gt;&amp;lt;U+005C&amp;gt;&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;U+20AC&lt;/code&gt; can be encoded as the single &lt;code&gt;u16&lt;/code&gt; code unit &lt;code&gt;0x20AC&lt;/code&gt;, that'd mean &lt;code&gt;path[0]&lt;/code&gt; will be &lt;code&gt;0x20AC&lt;/code&gt;, &lt;code&gt;path[1]&lt;/code&gt; will be &lt;code&gt;0x3A&lt;/code&gt; (&lt;code&gt;:&lt;/code&gt;), and &lt;code&gt;path[2]&lt;/code&gt; will be &lt;code&gt;0x5C&lt;/code&gt; (&lt;code&gt;\&lt;/code&gt;), which looks like a drive-absolute path&lt;code&gt;U+20AC&lt;/code&gt; is encoded as three &lt;code&gt;u8&lt;/code&gt; code units (&lt;code&gt;0xE2 0x82 0xAC&lt;/code&gt;), that'd mean &lt;code&gt;path[0]&lt;/code&gt; will be &lt;code&gt;0xE2&lt;/code&gt;, &lt;code&gt;path[1]&lt;/code&gt; will be &lt;code&gt;0x82&lt;/code&gt;, and &lt;code&gt;path[2]&lt;/code&gt; will be &lt;code&gt;0xAC&lt;/code&gt;, meaning it will look nothing like a drive-absolute path&lt;p&gt;So, to write an implementation that treats paths the same regardless of encoding, some decision has to be made:&lt;/p&gt;&lt;code&gt;RtlDetermineDosPathNameType_U&lt;/code&gt;/&lt;code&gt;RtlDosPathNameToNtPathName_U&lt;/code&gt; is desired, decode the first code point and check for &lt;code&gt;&amp;lt;= 0xFFFF&lt;/code&gt; when dealing with WTF-8 (this is the option I went with for the Zig standard library, but I'm not super happy about it)&lt;code&gt;path[0]&lt;/code&gt;/&lt;code&gt;path[1]&lt;/code&gt;/&lt;code&gt;path[2]&lt;/code&gt; and don't care about non-ASCII drive letters, check for &lt;code&gt;path[0] &amp;lt;= 0x7F&lt;/code&gt; regardless of encoding&lt;code&gt;A&lt;/code&gt;-&lt;code&gt;Z&lt;/code&gt; drive letters, then check for that explicitly (this is what Rust does)&lt;p&gt;Something bizarre that I found with this whole thing is that the &lt;code&gt;kernel32.dll&lt;/code&gt; API &lt;code&gt;SetVolumeMountPointW&lt;/code&gt; has it's own unique quirk when dealing with non-ASCII drive letters. Specifically, this code (attempting to create the drive &lt;code&gt;â¬:\&lt;/code&gt;) will succeed:&lt;/p&gt;&lt;code&gt;const std = @import("std");
const windows = std.os.windows;
const L = std.unicode.wtf8ToWtf16LeStringLiteral;

extern "kernel32" fn SetVolumeMountPointW(
    VolumeMountPoint: windows.LPCWSTR,
    VolumeName: windows.LPCWSTR,
) callconv(.winapi) windows.BOOL;

pub fn main() !void {
    const volume_name = L("\\\\?\\Volume{18123456-abcd-efab-cdef-1234abcdabcd}\\");
    const mount_point = L("â¬:\\");
    if (SetVolumeMountPointW(mount_point, volume_name) == 0) {
        const err = windows.GetLastError();
        std.debug.print("{any}\n", .{err});
        return error.Failed;
    }
}
&lt;/code&gt;
&lt;p&gt;However, when we look at the Object Manager, the &lt;code&gt;â¬:&lt;/code&gt; symlink won't exist... but &lt;code&gt;Â¬:&lt;/code&gt; will:&lt;/p&gt;&lt;p&gt;My time dealing extensively with Windows quirks made me recognize what might be happening here: &lt;code&gt;0x20AC&lt;/code&gt; is likely being truncated to &lt;code&gt;0xAC&lt;/code&gt; by &lt;code&gt;SetVolumeMountPointW&lt;/code&gt;, and &lt;code&gt;U+00AC&lt;/code&gt; happens to be &lt;code&gt;Â¬&lt;/code&gt;. If that is indeed what's going on, it seems pretty strange to truncate the drive letter instead of reject the path, but it also makes sense that non-ASCII drive letters are an edge case that no one has really thought about at all.&lt;/p&gt;&lt;p&gt;I have no idea if anything I wrote about here is novel, although my cursory searches didn't turn up much. The only mention of non-&lt;code&gt;A&lt;/code&gt;-&lt;code&gt;Z&lt;/code&gt; drive letters I'm currently aware of is from the article The Definitive Guide on Win32 to NT Path Conversion which says:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;it's natural to assume that drive "letters" can only be A through Z. It turns out the&lt;/p&gt;&lt;code&gt;RtlGetFullPathName_U&lt;/code&gt;API does not enforce this requirement, although the Explorer shell and command prompt almost certainly do. Therefore as long as the second character of a path is a colon, the conversion will treat it as a Drive Absolute or Drive Relative path. Of course if the DosDevices object directory doesn't have an appropriate symbolic link it's not going to do you much good.&lt;/quote&gt;&lt;p&gt;Well, it turns out that the command prompt also doesn't enforce the requirement, and I'd guess that there's at least some more weirdness around this quirk that's waiting to be discovered.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ryanliptak.com/blog/windows-drive-letters-are-not-limited-to-a-z/"/><published>2025-11-30T13:40:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46096800</id><title>Migrating Dillo from GitHub</title><updated>2025-11-30T20:11:23.716536+00:00</updated><content>&lt;doc fingerprint="af008dd98a923a96"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Migrating Dillo from GitHub&lt;/head&gt;Written on 2025-11-30 by Rodrigo Arias Mallo&lt;p&gt;I would like to migrate the Dillo project away from GitHub into a new home which is more friendly to be used with Dillo and solves some of its problems. This page summarizes the current situation with GitHub and why I decided to move away from it into a self-hosted server with multiple mirrors in other forges.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;&lt;p&gt;Before we dive into the details, I would like to briefly mention what happened with the old site. The original Dillo website was at dillo.org, which also had the source code of Dillo in a mercurial repository at hg.dillo.org. But it also included the mail server used to reach the developers, a bug tracker and archives for the mailing list. However, in 2022 the domain was lost and someone else decided to buy it to put a similar site but plaged with AI generated ads. The original developers are no longer active, but luckily I had a copy of the mercurial repository and with some help I was able to recover a lot of material from the original server (some parts are still missing to this day).&lt;/p&gt;&lt;p&gt;I want to avoid this situation as much as possible, so we cannot rely on a single site that can go down and the whole project become lost. Initially, I uploaded the Dillo source and website to git repositories on GitHub, but I no longer think this is a good idea.&lt;/p&gt;&lt;head rend="h2"&gt;The situation with GitHub&lt;/head&gt;&lt;p&gt;GitHub has been useful to store all repositories of the Dillo project, as well as to run the CI workflows for platforms in which I don't have a machine available (like Windows, Mac OS or some BSDs).&lt;/p&gt;&lt;p&gt;However, it has several problems that make it less suitable to develop Dillo anymore. The most annoying problem is that the frontend barely works without JavaScript, so we cannot open issues, pull requests, source code or CI logs in Dillo itself, despite them being mostly plain HTML, which I don't think is acceptable. In the past, it used to gracefully degrade without enforcing JavaScript, but now it doesn't. Additionally, the page is very resource hungry, which I don't think is needed to render mostly static text.&lt;/p&gt;&lt;p&gt;Another big problem is that it is a single point of failure. I don't mean that GitHub is stored in a single machine, but it is controlled by a single entity which can unilateraly ban our repository or account and we would lose the ability to notify in that URL what happened. This can cause data loss if we don't have a local copy of all the data.&lt;/p&gt;&lt;p&gt;On the usability side, the platform has become more and more slow over time, which is affecting the development process. It also requires you to have a fast Internet connection at all times, which is not the case for me sometimes. Additionally, GitHub seems to encourage a "push model" in which you are notified when a new event occurs in your project(s), but I don't want to work with that model. Instead, I prefer it to work as a "pull model", so I only get updates when I specifically look for them. This model would also allow me to easily work offline. Unfortunately, I see that the same push model has been copied to alternative forges.&lt;/p&gt;&lt;p&gt;On the social side, I feel that it doesn't have the right tools to moderate users, specially for projects where the ratio of non-technical users to developers is high. This is specially problematic when active issues with developer notes begin to be filled with comments from users that have never contributed to the project and usually do more harm than good. This situation ends up causing burnout in developers.&lt;/p&gt;&lt;p&gt;Lastly, GitHub seem to follow the current trend of over-focusing on LLMs and generative AI, which are destroying the open web (or what remains of it) among other problems. It has a direct impact on us because sites protect themseves with a JavaScript wall (or worse, browser fingerprinting) to prevent aggresive LLM crawler bots from overloading the site, but they also leave Dillo users out. So I would prefer not to encourage this trend. Despite my intentions, moving Dillo away won't change much their capability to train their model with our code, but at least I won't be actively helping.&lt;/p&gt;&lt;head rend="h2"&gt;Self-hosting Dillo&lt;/head&gt;&lt;p&gt;After researching the available options, it seems that none of the current forges would allow us to have a redundant system that can prevent the forge from becoming a single point of failure and solve the rest of the problems with GitHub. Therefore, I decided to self-host Dillo myself, move all important data to git repositories and keep them synchronized in multiple git mirrors.&lt;/p&gt;&lt;p&gt;I decided to buy the dillo-browser.org domain name and setup a very small VPS. Initially, I was very skeptical that it would be able to survive on today's web, but it seems to be doing an acceptable job at handling it (mostly AI bot traffic masquerading as users). The Dillo website is available here:&lt;/p&gt;&lt;p&gt;I researched which git frontends may suit our needs, and I discovered that most options are very complicated to self-host and require a lot of server resources and JavaScript on the frontend. I ended up testing cgit, which is written in C and it seems to be very lightweight both on RAM and CPU usage. Furthermore, the web frontend doesn't require JS, so I can use it from Dillo (I modified cgit CSS slightly to work well on Dillo). It is available on this URL:&lt;/p&gt;&lt;p&gt;https://git.dillo-browser.org/&lt;/p&gt;&lt;p&gt;Regarding the bug tracker, I also took a look at the available options. They are all too complicated for what I would like to have and they seem to centralize the data into a database that can get lost. This is precisely the case that happened with the old dillo bug tracker and we are still unable to recover the original bug entries.&lt;/p&gt;&lt;p&gt;To avoid this problem, I created my own bug tracker software, buggy, which is a very simple C tool that parses plain Markdown files and creates a single HTML page for each bug. All bugs are stored in a git repository and a git hook regenerates the bug pages and the index on each new commit. As it is simply plain text, I can edit the bugs locally and only push them to the remote when I have Internet back, so it works nice offline. Also, as the output is just an static HTML site, I don't need to worry about having any vulnerabilities in my code, as it will only run at build time. You can see it live here, with the exported issues from GitHub:&lt;/p&gt;&lt;p&gt;https://bug.dillo-browser.org/&lt;/p&gt;&lt;p&gt;The mailing list archives are stored by three independent external services, but I might include a copy with our own archives in the future.&lt;/p&gt;&lt;head rend="h2"&gt;Setting up mirrors&lt;/head&gt;&lt;p&gt;As all the important data is now stored in git repositories, we can mirror them in any forge, without having to rely on their custom storage format for the issues or other data. If a forge goes down (or goes rogue) we can simply switch to another site with low switching cost. To this end, I have created git mirrors in Codeberg and Sourcehut that are synced with our git server:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Codeberg: https://codeberg.org/dillo/&lt;/item&gt;&lt;item&gt;Sourcehut: https://git.sr.ht/~dillo/&lt;/item&gt;&lt;/list&gt;&lt;p&gt;However, we still have a single point of failure: the DNS entry of the dillo-browser.org domain. If we lose the DNS entry (like with dillo.org) it would cause a problem as all services will be unreachable. We could recover from such situation by relying on alternative ways to reach users, by the mailing list, fediverse or IRC, as well as updating the mirrors to reflect the current situation. It is not ideal, but I don't think it would cause a catastrophic data loss (like it happened before) as all the data is now stored in git and replicated across independent locations.&lt;/p&gt;&lt;head rend="h2"&gt;OpenPGP signature&lt;/head&gt;&lt;p&gt;In order for this page to have some authority, the HTML file is signed with my GPG key (32E65EC501A1B6FDF8190D293EE6BA977EB2A253), which is the same that I use to sign the last releases of Dillo and is also listed in my GitHub user. The signature is available here and is linked to the page with the &lt;code&gt;&amp;lt;link&amp;gt;&lt;/code&gt; tag using the &lt;code&gt;rel=signature&lt;/code&gt;
relation. You can find more information and how to verify the signature in the
Dillo RFC-006.

&lt;/p&gt;&lt;p&gt;Using OpenPGP signatures is robust against losing the DNS entry, as the authority is not given by the TLS certificate chain but by the trust in the OpenPGP signature, so we could move the site elsewhere and still claim that is owned by us. Additionally, as we can store the signatures inside all git mirrors, they are also resilient against data loss.&lt;/p&gt;&lt;head rend="h2"&gt;Closing remarks&lt;/head&gt;&lt;p&gt;Keep in mind that the migration process requires several moving parts and it will take a while for it to stabilize (switching costs). The GitHub repositories won't be removed at any point in time and they will continue to be updated until we finish the migration. When the migration process is completed, I will mark the Dillo repositories as archived and properly comunicate it in our site. It is important that we don't remove any commit or tarball release to avoid breaking downstream builds that still rely on the GitHub URL.&lt;/p&gt;&lt;p&gt;Lastly, I'm glad that we can have our own fully independent and self-hosted site with relatively low expenses and very little energy cost (which is good for the environment, but probably not even noticeable at large scale). With the current DNS and server costs and our current donations I consider that it is likely that we can continue covering the expenses for at least the next 3 years in the worst case scenario. If you are interested in keeping us afloat, you can help via Liberapay.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dillo-browser.org/news/migration-from-github/"/><published>2025-11-30T14:11:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46097624</id><title>Modern cars are spying on you. Here's what you can do about it</title><updated>2025-11-30T20:11:23.446846+00:00</updated><content>&lt;doc fingerprint="f58eb3463ce3a514"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;One Tech Tip: Modern cars are spying on you. Here’s what you can do about it&lt;/head&gt;
    &lt;head rend="h2"&gt;One Tech Tip: Modern cars are spying on you. Here’s what you can do about it&lt;/head&gt;
    &lt;p&gt;While driving to a new restaurant, your car’s satellite navigation system tracks your location and guides you to the destination. Onboard cameras constantly track your face and eye movements. When another car veers into your path, forcing you to slam on the brakes, sensors are assisting and recording. Waiting at a stoplight, the car notices when you unbuckle your seat belt to grab your sunglasses in the backseat.&lt;/p&gt;
    &lt;p&gt;Modern cars are computers on wheels that are becoming increasingly connected, enabling innovative new features that make driving safer and more convenient. But these systems are also collecting reams of data on our driving habits and other personal information, raising concerns about data privacy.&lt;/p&gt;
    &lt;p&gt;Here is what to know about how your car spies on you and how you can minimize it:&lt;/p&gt;
    &lt;head rend="h2"&gt;How cars collect data&lt;/head&gt;
    &lt;p&gt;It’s hard to figure out exactly how much data a modern car is collecting on you, according to the Mozilla Foundation, which analyzed privacy practices at 25 auto brands in 2023. It declared that cars were the worst product category that the group had ever reviewed for privacy.&lt;/p&gt;
    &lt;p&gt;Modern cars are spying on you. AP’s Kelvin Chan reports.&lt;/p&gt;
    &lt;p&gt;The data points include all your normal interactions with the car — such as turning the steering wheel or unlocking doors — but also data from connected onboard services, like satellite radio, GPS navigation systems, connected devices, telematics systems as well as data from sensors or cameras.&lt;/p&gt;
    &lt;p&gt;Vehicle telematics systems started to become commonplace about a decade ago, and the practice of automotive data collection took off about five years ago.&lt;/p&gt;
    &lt;p&gt;The problem is not just that data is being collected but who it’s provided to, including insurers, marketing companies and shadowy data brokers. The issue surfaced earlier this year when General Motors was banned for five years from disclosing data collected from drivers to consumer reporting agencies.&lt;/p&gt;
    &lt;p&gt;The Federal Trade Commission accused GM of not getting consent before sharing the data, which included every instance when a driver was speeding or driving late at night. It was ultimately provided to insurance companies that used it to set their rates.&lt;/p&gt;
    &lt;head rend="h2"&gt;Be aware&lt;/head&gt;
    &lt;p&gt;The first thing drivers should do is be aware of what data their car is collecting, said Andrea Amico, founder of Privacy4Cars, an automotive privacy company.&lt;/p&gt;
    &lt;p&gt;In an ideal world, drivers would read through the instruction manuals and documentation that comes with their cars, and quiz the dealership about what’s being collected.&lt;/p&gt;
    &lt;p&gt;But it’s not always practical to do this, and manufacturers don’t always make it easy to find out, while dealership staff aren’t always the best informed, Amico said.&lt;/p&gt;
    &lt;p&gt;Privacy4Cars offers a free auto privacy labeling service at vehicleprivacyreport.com that can summarize what your car could be tracking.&lt;/p&gt;
    &lt;p&gt;Owners can punch in their car’s Vehicle Identification Number, which then pulls up the automaker’s data privacy practices, such as whether the car collects location data and whether it’s given to insurers, data brokers or law enforcement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tweak your settings&lt;/head&gt;
    &lt;p&gt;Data collection and tracking start as soon as you drive a new car off the dealership lot, with drivers unwittingly consenting when they’re confronted with warning menus on dashboard touch screens.&lt;/p&gt;
    &lt;p&gt;Experts say that some of the data collection is baked into the system, you can revoke your consent by going back into the menus.&lt;/p&gt;
    &lt;p&gt;“There are permissions in your settings that you can make choices about,” said Lauren Hendry Parsons of Mozilla. “Go through on a granular level and look at those settings where you can.”&lt;/p&gt;
    &lt;p&gt;For example, Toyota says on its website that drivers can decline what it calls “Master Data Consent” through the Toyota app. Ford says owners can opt to stop sharing vehicle data with the company by going through the dashboard settings menu or on the FordPass app.&lt;/p&gt;
    &lt;p&gt;BMW says privacy settings can be adjusted through the infotainment system, “on a spectrum between” allowing all services including analysis data and none at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;You can opt out&lt;/head&gt;
    &lt;head rend="h2"&gt;...&lt;/head&gt;
    &lt;p&gt;Drivers in the U.S. can ask carmakers to restrict what they do with their data.&lt;/p&gt;
    &lt;p&gt;Under state privacy laws, some carmakers allow owners across the United States to submit requests to limit the use of their personal data, opt out of sharing it, or delete it, Consumer Reports says. Other auto companies limit the requests to people in states with applicable privacy laws, the publication says.&lt;/p&gt;
    &lt;p&gt;You can file a request either through an online form or the carmaker’s mobile app.&lt;/p&gt;
    &lt;p&gt;You can also go through Privacy4Cars, which provides a free online service that streamlines the process. It can either point car owners to their automaker’s request portal or file a submission on behalf of owners in the U.S., Canada, the European Union, Britain and Australia.&lt;/p&gt;
    &lt;head rend="h2"&gt;... but there will be trade-offs&lt;/head&gt;
    &lt;p&gt;Experts warn that there’s usually a trade-off if you decide to switch off data collection.&lt;/p&gt;
    &lt;p&gt;Most people, for example, have switched to satellite navigation systems over paper maps because it’s “worth the convenience of being able to get from point A to point B really easily,” said Hendry Parsons.&lt;/p&gt;
    &lt;p&gt;Turning off location tracking could also halt features like roadside assistance or disable smartphone app features like remote door locking, Consumer Reports says.&lt;/p&gt;
    &lt;p&gt;BMW advises that if an owner opts to have no data shared at all, “their vehicle will behave like a smartphone in flight mode and will not transmit any data to the BMW back end.”&lt;/p&gt;
    &lt;head rend="h2"&gt;When selling your car&lt;/head&gt;
    &lt;p&gt;When the time comes to sell your car or trade it in for a newer model, it’s no longer as simple as handing over the keys and signing over some paperwork.&lt;/p&gt;
    &lt;p&gt;If you’ve got a newer car, experts say you should always do a factory reset to wipe all the data, which will also include removing any smartphone connections.&lt;/p&gt;
    &lt;p&gt;And don’t forget to notify the manufacturer about the change of ownership.&lt;/p&gt;
    &lt;p&gt;Amico said that’s important because if you trade in your vehicle, you don’t want insurers to associate it with your profile if the dealer is letting customers take it for test drives.&lt;/p&gt;
    &lt;p&gt;“Now your record may be affected by somebody else’s driving — a complete stranger that you have no relationship with.”&lt;/p&gt;
    &lt;p&gt;____&lt;/p&gt;
    &lt;p&gt;Is there a tech topic that you think needs explaining? Write to us at [email protected] with your suggestions for future editions of One Tech Tip.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;This story has been corrected to show that the Mozilla representative’s first name is Lauren, not Laura.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://apnews.com/article/auto-car-privacy-3674ce59c9b30f2861d29178a31e6ab7"/><published>2025-11-30T15:52:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46097671</id><title>Langjam Gamejam: Build a programming language then make a game with it</title><updated>2025-11-30T20:11:23.216983+00:00</updated><content>&lt;doc fingerprint="dda86e398bfb3013"&gt;
  &lt;main&gt;
    &lt;p&gt;Langjam Gamejam is a 7-day challenge to create a programming language and then use that language to build a game. You set the rules. Be as creative as possible, use any technologies you want, and have fun. There will be prizes for the most creative submissions!&lt;/p&gt;
    &lt;head rend="h2"&gt;Rules&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The hackathon runs for 7 days&lt;/item&gt;
      &lt;item&gt;You must design and implement a programming language&lt;/item&gt;
      &lt;item&gt;You must design and implement a game using your language&lt;/item&gt;
      &lt;item&gt;You can use any language, engine, libraries, and technologies&lt;/item&gt;
      &lt;item&gt;You define what a programming language is and what a game is&lt;/item&gt;
      &lt;item&gt;Work solo or on a team&lt;/item&gt;
      &lt;item&gt;Documentation and instructions are encouraged&lt;/item&gt;
      &lt;item&gt;Bonus points: Write a blog post about your language, game, and design process&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Join the jam and submit on Itch.io.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://langjamgamejam.com/"/><published>2025-11-30T15:57:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46097773</id><title>The Thinking Game Film – Google DeepMind Documentary</title><updated>2025-11-30T20:11:23.008015+00:00</updated><content>&lt;doc fingerprint="72a77c532d96d321"&gt;
  &lt;main&gt;
    &lt;p&gt;Stay Updated Sign up with your email address to receive news and updates. Email Address Sign Up We respect your privacy. Thank you!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thinkinggamefilm.com"/><published>2025-11-30T16:07:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46097829</id><title>GitHub to Codeberg: My Experience</title><updated>2025-11-30T20:11:22.475355+00:00</updated><content>&lt;doc fingerprint="9a9c101d0be75ac8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GitHub → Codeberg: my experience&lt;/head&gt;
    &lt;p&gt;Published . Estimated reading time: 11 minutes.&lt;/p&gt;
    &lt;p&gt;In which I talk about the process involved in switching forges, and how well that went.&lt;/p&gt;
    &lt;p&gt;Spoiler alert: this very site that you’re reading this on is not served from GitHub Pages anymore! At this point, I’d call my migration successful. But it took more than clicking a single button, so let’s talk about the steps involved, at least for me. I’m hoping that it can help be an example for other people, and show that it’s actually not that complicated.&lt;/p&gt;
    &lt;head rend="h2"&gt;(My) migration process&lt;/head&gt;
    &lt;p&gt;First, I took an hour or so to set up my profile picture, email address(es), SSH keys…&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 1: migrating the repos&lt;/head&gt;
    &lt;p&gt;This wasn’t difficult, because Forgejo (the forge software that powers Codeberg) offers a “migrate from GitHub” functionality. You need to generate a PAT on GitHub to import things like issues (which is awesome!), and as a bonus it also speeds up the process.&lt;/p&gt;
    &lt;p&gt;It was, however, tedious, because the process was entirely manual (perhaps there’s a way to automate it, like by using some Forgejo CLI tool, but I didn’t bother looking into that). And, due to GitHub API rate limits, whenever I tried importing two repos at the same time, one or both would fail. (It wasn’t too bad, though, since I could fill out the migration page for the next while one was in progress; and generally, it took me roughly as long to fill it out as it took Codeberg to perform the import.)&lt;/p&gt;
    &lt;p&gt;I’m really happy that issues, PRs, wikis, and releases can be imported flawlessly: this makes it possible to not have to refer to GitHub anymore!&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 2: repointing links to Codeberg&lt;/head&gt;
    &lt;p&gt;Of course I don’t control all links that point to my stuff, but I could at least run &lt;code&gt;rg -F github.com/ISSOtm&lt;/code&gt; in my home directory, to catch those within my own repos. It’s possible to automate the replacing process:&lt;/p&gt;
    &lt;p&gt;…and if you’re feeling like bulk-replacing all files in a directory:&lt;/p&gt;
    &lt;p&gt;Repositories, however, may still be pointing to GitHub:&lt;/p&gt;
    &lt;code&gt; 
 )
 )
&lt;/code&gt;
    &lt;p&gt;You can either manually &lt;code&gt;git remote set-url origin git@codeberg.org:ISSOtm/rsgbds.git&lt;/code&gt; (or the equivalent if you’re using HTTPS), or use one of the replace commands above, since remote URLs are stored textually:&lt;/p&gt;
    &lt;code&gt;# Within a single repo:

# For all repos within the current directory: (requires `shopt -s globstar` if using Bash)
&lt;/code&gt;
    &lt;p&gt;…then it’s a matter of pushing the changes to all of the repos.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 3: stubbing out the GitHub repos&lt;/head&gt;
    &lt;p&gt;I also wanted to make it clear that my repos were now living on Codeberg; so, I created a little script in an empty directory:&lt;/p&gt;
    &lt;code&gt;#!/bin/bash
 

 
 
 
 
 
 
 
&lt;/code&gt;
    &lt;p&gt;Then, to run it:&lt;/p&gt;
    &lt;code&gt; 
 
 
 
 
# ...etc.
&lt;/code&gt;
    &lt;p&gt;The automation made it not painful, so this went pretty well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 4: porting CI&lt;/head&gt;
    &lt;p&gt;Now, onto the harder stuff :)&lt;/p&gt;
    &lt;p&gt;The first interesting thing that I noticed is this section of Codeberg’s CI documentation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Running CI/CD pipelines can use significant amounts of energy. As much as it is tempting to have green checkmarks everywhere, running the jobs costs real money and has environmental costs.&lt;/p&gt;
      &lt;p&gt;Unlike other giant platforms, we do not encourage you to write “heavy” pipelines and charge you for the cost later. We expect you to carefully consider the costs and benefits from your pipelines and reduce CI/CD usage to a minimum amount necessary to guarantee consistent quality for your projects.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That got me to think about which projects of mine really need CI, and ultimately, I decided that I would only need CI for publishing my website, and the documentation of gb-starter-kit and fortISSimO; the rest of my projects don’t get contributions anyway, so I can live without CI on them, at least for now.&lt;/p&gt;
    &lt;p&gt;Anyway, Codeberg actually has two different CI solutions: Woodpecker, and Forgejo Actions; the former seems to be more powerful, but you need to apply for access, and the latter is very close to GitHub Actions, which should facilitate the migration. So I picked Forgejo Actions, even though it’s marked as being in beta.&lt;/p&gt;
    &lt;p&gt;It’s not very difficult to port a YAML file from GHA to Forgejo Actions; for example, look at the commit porting gb-starter-kit’s publishing CI. (This doesn’t really appear as a diff, since I’ve moved the file; but it’s small, so it’s easy to compare manually.)&lt;/p&gt;
    &lt;p&gt;Here are some salient points:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Actions are normally just referred to as &lt;code&gt;owner/repo&lt;/code&gt;, but Forgejo supports cloning any Git repo, especially across forges. It’s actually recommended to use full URLs always, so you don’t rely on the default prefix, which is configurable by the instance admin and thus not necessarily portable.&lt;/item&gt;
      &lt;item&gt;I could have kept the files in &lt;code&gt;.github/workflows&lt;/code&gt;, since Forgejo picks up that directory automatically if&lt;code&gt;.forgejo/workflows&lt;/code&gt;doesn’t exist; however, I think it’s more convenient to keep un-migrated scripts in&lt;code&gt;.github&lt;/code&gt;and migrated ones in&lt;code&gt;.forgejo&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Most Actions (the individual steps, not the workflow files) actually work out of the box on Forgejo Actions. Nice!&lt;/item&gt;
      &lt;item&gt;Codeberg’s runners differ from GitHub’s significantly: they have way less software installed by default, fewer resources, and only Linux runners are provided (Ubuntu by default, but you can use any Docker container image). macOS and Windows being non-free OSes, Codeberg has no plans to offer either of those! For both philosophical and financial reasons. If this is a deal-breaker for you, consider cross-compiling, or bringing your own runner.&lt;/item&gt;
      &lt;item&gt;Unless low latency is crucial, consider using the lazy runners for better load balancing and possibly greener energy consumption. In practice I haven’t seen delays beyond a few minutes, which is acceptable to me.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I actually spent some extra time trying to use less compute to perform my CI jobs, somewhat motivated by the small size of the runners, and because I’m guessing that the smaller the runner you’re picking, the faster your job will be able to be scheduled. Here is one such commit; note in particular line 50, where I tried1 using a Docker image with LaTeX preinstalled, which saves the time taken by &lt;code&gt;apt install&lt;/code&gt; and requires fewer writes to the filesystem, freeing up RAM.&lt;/p&gt;
    &lt;p&gt;Unfortunately, due to a version discrepancy with &lt;code&gt;noweb&lt;/code&gt;, I had to revert to the base Ubuntu image; but a “regular” LaTeX workflow would have had no problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 5: re-hosting my website&lt;/head&gt;
    &lt;p&gt;All of the previous steps were done within the span of a few days; however, since my website (this very website) was hosted using GitHub Pages, I couldn’t migrate its repos (yes, plural: you can configure individual repos to be published separately, which is how e.g. https://eldred.fr/fortISSimO is published, despite not being in the website’s main repo).&lt;/p&gt;
    &lt;p&gt;Nominally, Codeberg has an equivalent, Codeberg Pages; however, as mentioned on that page, &lt;quote&gt;the software behind this feature is currently in maintenance mode&lt;/quote&gt;, because of complexity and performance issues2. So I left it at that for roughly a month, hoping there’ll eventually be an update. Also, subprojects are published as subdomains instead of subdirectories, which would have broken links (e.g. &lt;code&gt;http://eldred.fr/fortISSimO&lt;/code&gt; would have become &lt;code&gt;http://fortISSimO.eldred.fr&lt;/code&gt;). Meh…&lt;/p&gt;
    &lt;p&gt;And then (by chance lol) I discovered git-pages and its public instance Grebedoc3! It functions much like GitHub Pages, though with a bit more setup since it’s not integrated within the forge itself.&lt;/p&gt;
    &lt;p&gt;git-pages actually has several niceties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;My website had zero downtime during the entire migration, as git-pages supports uploading your website before updating your DNS records!&lt;/item&gt;
      &lt;item&gt;It also supports server-side redirects, which lets me redirect people who still go to http://eldred.fr/gb-asm-tutorial/* to its new home, for example. People have been getting 404s because of incomplete client-side coverage on my side, but no more!&lt;/item&gt;
      &lt;item&gt;It also also supports custom headers; I’m not particularly interested in CORS, but I’ve used that file to pay my respects4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Oh, and also, Codeberg’s November 2025 newsletter mentions that &lt;quote&gt;Codeberg is planning to gradually migrate to [git-pages]&lt;/quote&gt;. Exciting!&lt;/p&gt;
    &lt;p&gt;I’m actually much happier using this than GitHub Pages; so, I’ve joined Catherine’s Patreon, because I want to see this go far.&lt;/p&gt;
    &lt;p&gt;To quote Catherine’s motivation for creating git-pages: &lt;quote&gt;I started out wanting to just use Codeberg Pages and then I found out that Codeberg Pages is in maintenance mode and has such poor architecture that not only does it have rather low uptime but it also regularly crashes Codeberg’s Forgejo instance itself.&lt;/quote&gt;&lt;/p&gt;
    &lt;p&gt;🦃. It is intensely looking at you…….&lt;/p&gt;
    &lt;p&gt;Here is some context as to what this means.&lt;/p&gt;
    &lt;head rend="h3"&gt;Time tracking&lt;/head&gt;
    &lt;p&gt;Steps 1 through 3 (migrating the repos) took me the better part of an afternoon; step 4 (porting CI) took me another afternoon, mostly to learn the new CI system; and step 5 (the website) took me… well, it should have taken an afternoon, but I used the opportunity to also pay down some tech debt (merging my slides repo into my main website), which took a few days due to required rearchitecting.&lt;/p&gt;
    &lt;p&gt;All in all, even with 45 repos migrated, this basically took a weekend. And I didn’t find it annoying!&lt;/p&gt;
    &lt;p&gt;Since the task seemed really daunting, my anxiety caused me to procrastinate this a lot, but in the end it was little work. One of the reasons I’m writing this is to let other people know that, so they can overcome their own anxiety. Maybe. :P&lt;/p&gt;
    &lt;head rend="h2"&gt;What now?&lt;/head&gt;
    &lt;p&gt;All in all, I’m very happy with this migration! As far as I can tell, nothing on this website has broken, and I’ve tried reasonably containing the breakage over on GitHub: I have truncated the &lt;code&gt;master&lt;/code&gt; branches, but all other branches and tags remain in place (mostly due to laziness lol), permalinks (e.g. &lt;code&gt;https://github.com/ISSOtm/gb-bootroms/blob/c8ed9e106e0ab1193a57071820e46358006c79d0/src/dmg.asm&lt;/code&gt;) still work, only non-perma links (e.g. &lt;code&gt;https://github.com/ISSOtm/gb-bootroms/blob/master/src/dmg.asm&lt;/code&gt;) are broken, but those are unreliable in the first place anyway.&lt;/p&gt;
    &lt;p&gt;Since that means that all of my code is still on GitHub, I want to delete my repos; but that would be a bad idea at this point, due to leaving no redirects or anything. I’ll consider that again in… idk, a year or something. I would also like to delete my GitHub account (like I have deleted my Twitter account when… *gestures vaguely*), but not only do I need my repos to be up, I also need my account to contribute to projects that are still on GitHub.&lt;/p&gt;
    &lt;p&gt;One downside of this migration is that since I’m moving off of The Main Forge, my projects are likely to get fewer contributions… But I wasn’t getting many in the first place, and some people have already made accounts on Codeberg to keep contributing to my stuff. Likewise, I’m not really worried about discoverability. We’ll see I guess lol 🤷♂️&lt;/p&gt;
    &lt;p&gt;Lastly, I’m writing this after the migration, and I haven’t really taken notes during it; so, if I’ve forgotten any steps, feel free to let me know in the comments below or by opening an issue, and I’ll edit this article.&lt;/p&gt;
    &lt;p&gt;Cheers!&lt;/p&gt;
    &lt;head rend="h2"&gt;Special thanks&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Catherine ‘whitequark’ for her work on git-pages and for being part of the ops team for Grebedoc&lt;/item&gt;
      &lt;item&gt;SERVFAIL network (domi, Merlin, famfo, aprl, and all of #servfail) for being my awesome DNS providers&lt;/item&gt;
      &lt;item&gt;Codeberg team and Forgejo contributors for making all of this possible in the first place&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eldred.fr/blog/forge-migration/"/><published>2025-11-30T16:12:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098336</id><title>RetailReady (YC W24) Is Hiring Associate Product Manager</title><updated>2025-11-30T20:11:21.809310+00:00</updated><content>&lt;doc fingerprint="c194fec3c124afea"&gt;
  &lt;main&gt;
    &lt;p&gt;An AI-powered supply chain compliance engine&lt;/p&gt;
    &lt;p&gt;San Francisco - In Person&lt;/p&gt;
    &lt;p&gt;We’re RetailReady (YC W24), an AI-powered supply chain compliance engine shaking up an antiquated (and yes, unsexy) industry. Since YC, we raised a $3.3M seed round and signed over 15 enterprise customers… we’re officially in scaling mode.&lt;/p&gt;
    &lt;p&gt;RetailReady is the first AI-powered compliance engine designed for retail supply chains. We automate the messy web of compliance requirements between brands, warehouses, and retailers, turning weeks of manual work into minutes of automation. Our platform integrates deeply with warehouse operations and connects with customer systems via EDI and APIs.&lt;/p&gt;
    &lt;p&gt;We don’t just build dashboards. We build the nervous system of compliance inside a warehouse.&lt;/p&gt;
    &lt;p&gt;We’re hiring an Associate Product Manager to work directly with our Technical Product Lead and drive day-to-day product execution. You’ll own QA, write clear specs, organize feedback, and keep features moving across engineering and customers. This role is built for someone who wants to grow into a full PM.&lt;/p&gt;
    &lt;p&gt;Bonus: supply chain or 3PL experience, QA background, implementation experience, or exposure to EDI/APIs.&lt;/p&gt;
    &lt;p&gt;RetailReady is building an AI-powered supply chain compliance engine. Supply chains are still heavily reliant on paper processes and tribal knowledge, causing costly shipping mistakes that jeopardize the longevity of businesses. RetailReady is the first-to-market with our retail compliance packing software, leveraging camera vision to direct warehouses to ship orders without error. We are positioning our compliance data models to become the operating system that will power the next wave of warehouse robotics and automation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/retailready/jobs/KPKDu3D-associate-product-manager"/><published>2025-11-30T17:01:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098359</id><title>LLVM-MOS – Clang LLVM fork targeting the 6502</title><updated>2025-11-30T20:11:21.570166+00:00</updated><content/><link href="https://llvm-mos.org/wiki/Welcome"/><published>2025-11-30T17:02:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098569</id><title>Notes on Shadowing a Hospitalist</title><updated>2025-11-30T20:11:21.509210+00:00</updated><content/><link href="https://humaninvariant.substack.com/p/notes-on-shadowing-a-hospitalist"/><published>2025-11-30T17:25:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098673</id><title>ESA Sentinel-1D delivers first high-resolution images</title><updated>2025-11-30T20:11:20.605930+00:00</updated><content>&lt;doc fingerprint="a0002ffb95f93d86"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Sentinel-1D delivers first images: from Antarctica to Bremen&lt;/head&gt;
    &lt;p&gt;The first high-resolution images have been received from Copernicus Sentinel-1D and were shared publicly for the first time at the European Space Agency’s Ministerial Council, held today in Bremen, Germany. Glaciers in Antarctica, the tip of South America, as well as the city of Bremen, are visible in these stunning radar images.&lt;/p&gt;
    &lt;p&gt;The groundbreaking Copernicus Sentinel-1 mission saw the arrival in orbit of its latest satellite earlier in November: Sentinel-1D was launched on 4 November, on board an Ariane 6 launcher from Europe’s Spaceport in French Guiana.&lt;/p&gt;
    &lt;p&gt;Once in orbit, the satellite and its instruments – it carries a 12 m-long synthetic aperture radar (SAR) instrument – were switched on, ready to capture images during a pass over the Antarctic and South America two days after launch. On the night of 6 November (European time), the first images were captured over the Antarctic Peninsula, the Tierra del Fuego and the Thwaites Glacier. Some six hours later, on the morning of 7 November, Sentinel-1D also captured images over Bremen, in Germany. The data was then transmitted, or ‘downlinked’, from the satellite to the ground station, in Matera (Italy), which is part of the Copernicus Ground Segment. All this was done within 50 hours of launch, which is likely to be the shortest time from launch to data delivery for a radar-based Earth observation satellite.&lt;/p&gt;
    &lt;p&gt;According to Nuno Miranda, ESA’s Sentinel-1 Mission Manager, the images are of unprecedented data quality for a ‘first light’ acquisition. They are very similar to the images captured not so long ago by Sentinel-1C, which, according to Nuno, is very promising for the commissioning phase. He noted, “These images have been downlinked and processed within an exceptionally short timeframe. Some of us remember that when Sentinel-1B was launched, it delivered its first radar images within two hours of activation. Sentinel-1D achieved this in an even faster time, setting what we believe is a new record for space radar. This remarkable performance reflects the dedication and exceptional preparation of all the teams involved.”&lt;/p&gt;
    &lt;p&gt;Radar instruments can image Earth’s surface through clouds, precipitation, regardless of sunlight, making them particularly well suited for monitoring polar regions. The Sentinel-1C and -1D satellites also carry an Automatic Identification System (AIS) instrument – improving the mission capacity to detect ships and sea pollution. The Sentinel-1D AIS was also activated as the satellite passed over Antarctica capturing the presence of ships in these extreme areas.&lt;/p&gt;
    &lt;head rend="h2"&gt;First images show fragility of glaciers&lt;/head&gt;
    &lt;p&gt;The Antarctic Peninsula (above) is part of the larger peninsula of West Antarctica, protruding 1300 km. It is an ice sheet resting on a string of rocky islands and its tip is just 1000 km from the southern tip of South America. The Antarctic Peninsula ice sheet is one of the smallest ice sheets in Antarctica but is perhaps the most vulnerable to climate change as its glaciers are small and in a region of rapid warming. Observable changes such as collapsing ice shelves, thinning and accelerating glaciers are all key indicators of climate change in the region.&lt;/p&gt;
    &lt;p&gt;This image is in black and white, showing the contrast between the ocean and the peninsula’s icy landscape.&lt;/p&gt;
    &lt;p&gt;Tierra del Fuego (above) is an archipelago off the southern tip of the South American continent. It covers territory in both Argentina to the east and in Chile to the west and is separated from the mainland by the Magellan Strait. The most southerly point of Tierra del Fuego is Cape Horn.&lt;/p&gt;
    &lt;p&gt;The bright contrasting colours in this image are created by using multiple types of radar wave, known polarisations. In this image the ocean and snowy peaks are shown in shades of blue, while the land appears yellow.&lt;/p&gt;
    &lt;p&gt;The Thwaites Glacier, and the adjacent Pine Island Glacier (above), are located west of the Antarctic Peninsula. Both are vulnerable to climate change. Thwaites is one of the most unstable glaciers in Antarctica and is at risk of rapid retreat. The details shown in this image from Sentinel-1D remind us of the fragility of glaciers in the Antarctic. And since 2025 is the United Nation’s International Year of Glaciers' Preservation, it is timely to see this image, captured on 6 November 2025.&lt;/p&gt;
    &lt;p&gt;This image also uses multiple radar polarisations to capture enhanced data on the landscape. In this image, the sea ice in the water is visible in tones of purple or violet, while the glacier appears white.&lt;/p&gt;
    &lt;p&gt;The publication of these images also follows the 30th meeting of the Conference of Parties, or COP30, where the consequences of climate change and the mitigating actions needed were discussed. The World Meteorological Organization’s State of the Climate Update for COP30 notes that glaciers, from October 2023 to September 2024, lost the largest amount of ice on record back to 1950. The report states this is equivalent to 1.2 mm of global mean sea-level rise. The report also notes that, on 24 February 2025, the extent of Antarctic sea-ice reached its third lowest extent since satellite records began in 1978, the lowest being in 2023.&lt;/p&gt;
    &lt;p&gt;Simonetta Cheli, Director of ESA’s Earth Observation Programmes, said, “This is a great achievement and I am so pleased to see these results from Sentinel-1D. It really places the data we receive from our innovative missions in the spotlight – it is data that we as a society rely upon as we continue to discuss and take action on climate change, and also data that we need in applications for understanding and studying our planet.&lt;/p&gt;
    &lt;p&gt;“The Sentinel-1 team has done an amazing job and I would like to thank everyone within ESA, together with our partners in the space industry and European institutions, for delivering work of such high quality. It’s an honour to deliver this mission for the Copernicus Earth observation programme, and we thank the Commission for their support and collaboration. We look forward also to developing the Sentinel missions of the future, to further extend the capacity and potential of Copernicus for Europe.”&lt;/p&gt;
    &lt;p&gt;ESA’s Sentinel-1 Project Manager, Ramón Torres, expressed the whole team’s pride, “Unveiling the first images from Sentinel-1D is an incredibly emotional milestone for all of us. The sense of awe and fulfilment goes beyond the thrill of liftoff itself, because seeing those breathtaking images from the SAR instrument brings our hard work to life. They are not just pictures – they are proof of our vision becoming reality, underlining how cutting-edge this mission truly is. The fact that these stunning images also confirm the satellite’s health and flawless operation fills us with relief and joy. And to have achieved all of this within an astonishingly short time – just over two days after launch – makes this moment even more unforgettable for our team.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-1/Sentinel-1D_delivers_first_images_from_Antarctica_to_Bremen"/><published>2025-11-30T17:37:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098747</id><title>ETH-Zurich: Digital Design and Computer Architecture; 227-0003-10L, Spring, 2025</title><updated>2025-11-30T20:11:20.087348+00:00</updated><content>&lt;doc fingerprint="5c71730e58600a24"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Table of Contents&lt;/head&gt;
    &lt;head rend="h1"&gt;Digital Design and Computer Architecture&lt;/head&gt;
    &lt;head rend="h1"&gt;Spring 2025 (227-0003-10L)&lt;/head&gt;
    &lt;p&gt;Welcome to the wiki for Digital Design and Computer Architecture for Spring 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Announcements&lt;/head&gt;
    &lt;head rend="h2"&gt;Course Information&lt;/head&gt;
    &lt;head rend="h3"&gt;Description&lt;/head&gt;
    &lt;p&gt;The class provides a first introduction to the design of digital circuits and computer architecture. It covers technical foundations of how a computing platform is designed from the bottom up. It introduces various execution paradigms, hardware description languages, and principles in digital design and computer architecture. The focus is on fundamental techniques employed in the design of modern microprocessors and their hardware/software interface.&lt;/p&gt;
    &lt;head rend="h3"&gt;Objectives&lt;/head&gt;
    &lt;p&gt;This class provides a first approach to Computer Architecture. The students learn the design of digital circuits in order to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;understand the basics,&lt;/item&gt;
      &lt;item&gt;understand the principles (of design),&lt;/item&gt;
      &lt;item&gt;understand the precedents (in computer architecture).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Based on such understanding, the students are expected to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;learn how a modern computer works underneath, from the bottom up,&lt;/item&gt;
      &lt;item&gt;evaluate tradeoffs of different designs and ideas,&lt;/item&gt;
      &lt;item&gt;implement a principled design (a simple microprocessor),&lt;/item&gt;
      &lt;item&gt;learn to systematically debug increasingly complex systems,&lt;/item&gt;
      &lt;item&gt;hopefully be prepared to develop novel, out-of-the-box designs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The focus is on basics, principles, precedents, and how to use them to create/implement good designs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lectures&lt;/head&gt;
    &lt;p&gt; Thursday, 14:15-16:00, in HG F7 (Overflow room: HG F5) &lt;lb/&gt; Friday, 14:15-16:00, in HG F7 (Overflow room: HG F5) &lt;/p&gt;
    &lt;p&gt;Watch the lectures in YouTube livestream:&lt;/p&gt;
    &lt;head rend="h3"&gt;Lab sessions&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;When?&lt;/cell&gt;
        &lt;cell role="head"&gt;Where?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tuesday, 16:15-18:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG E19, HG E26.1, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wednesday, 16:15-18:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG E19, HG E26.1, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Friday, 08:15-10:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG D11, HG D12, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Friday, 10:15-12:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG E19, HG E26.1, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Prerequisites: None.&lt;/p&gt;
    &lt;head rend="h2"&gt;Staff Information&lt;/head&gt;
    &lt;head rend="h3"&gt;Contact&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mailing List: digitaltechnik@lists.inf.ethz.ch (sent to instructor and TAs)&lt;/item&gt;
      &lt;item&gt;Office Hours: TBD&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Office&lt;/cell&gt;
        &lt;cell role="head"&gt;Phone&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Instructor&lt;/cell&gt;
        &lt;cell&gt;Onur Mutlu&lt;/cell&gt;
        &lt;cell&gt;onur.mutlu@safari.ethz.ch&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Instructor&lt;/cell&gt;
        &lt;cell&gt;Mohammad Sadrosadati&lt;/cell&gt;
        &lt;cell&gt;mohammad.sadrosadati@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ F76&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Head Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Ataberk Olgun&lt;/cell&gt;
        &lt;cell&gt;ataberk.olgun@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Giray Yaglikci&lt;/cell&gt;
        &lt;cell&gt;giray.yaglikci@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Can Firtina&lt;/cell&gt;
        &lt;cell&gt;can.firtina@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Geraldo De Oliveira Junior&lt;/cell&gt;
        &lt;cell&gt;geraldod@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ 61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Rahul Bera&lt;/cell&gt;
        &lt;cell&gt;rahbera@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H64&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Konstantinos Kanellopoulos&lt;/cell&gt;
        &lt;cell&gt;kanellok@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Nika Mansouri Ghiasi&lt;/cell&gt;
        &lt;cell&gt;mnika@ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ 61.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Nisa Bostancı&lt;/cell&gt;
        &lt;cell&gt;nisa.bostanci@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ 61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Rakesh Nadig&lt;/cell&gt;
        &lt;cell&gt;rakesh.nadig@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H64&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;İsmail Emir Yüksel&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Haocong Luo&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://safari.ethz.ch/ddca/spring2025/doku.php?id=start"/><published>2025-11-30T17:45:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098838</id><title>Writing a Good Claude.md</title><updated>2025-11-30T20:11:19.871600+00:00</updated><content>&lt;doc fingerprint="474c0a5f0dbfd7fe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;# Writing a good CLAUDE.md&lt;/head&gt;
    &lt;p&gt;Kyle Mistele · November 25, 2025 · &amp;lt; 10 min read&lt;/p&gt;
    &lt;p&gt;Note: this post is also applicable to &lt;code&gt;AGENTS.md&lt;/code&gt;, the open-source equivalent of &lt;code&gt;CLAUDE.md&lt;/code&gt; for agents and harnesses like OpenCode, Zed, Cursor and Codex.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Principle: LLMs are (mostly) stateless&lt;/head&gt;
    &lt;p&gt;LLMs are stateless functions. Their weights are frozen by the time they're used for inference, so they don't learn over time. The only thing that the model knows about your codebase is the tokens you put into it.&lt;/p&gt;
    &lt;p&gt;Similarly, coding agent harnesses such as Claude Code usually require you to manage agents' memory explicitly. &lt;code&gt;CLAUDE.md&lt;/code&gt; (or &lt;code&gt;AGENTS.md&lt;/code&gt;) is the only file that by default goes into every single conversation you have with the agent.&lt;/p&gt;
    &lt;p&gt;This has three important implications:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Coding agents know absolutely nothing about your codebase at the beginning of each session.&lt;/item&gt;
      &lt;item&gt;The agent must be told anything that's important to know about your codebase each time you start a session.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;is the preferred way of doing this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;## &lt;code&gt;CLAUDE.md&lt;/code&gt; onboards Claude to your codebase&lt;/head&gt;
    &lt;p&gt;Since Claude doesn't know anything about your codebase at the beginning of each session, you should use &lt;code&gt;CLAUDE.md&lt;/code&gt; to onboard Claude into your codebase. At a high level, this means it should cover:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WHAT: tell Claude about the tech, your stack, the project structure. Give Claude a map of the codebase. This is especially important in monorepos! Tell Claude what the apps are, what the shared packages are, and what everything is for so that it knows where to look for things&lt;/item&gt;
      &lt;item&gt;WHY: tell Claude the purpose of the project and what everything is doing in the repository. What are the purpose and function of the different parts of the project?&lt;/item&gt;
      &lt;item&gt;HOW: tell Claude how it should work on the project. For example, do you use &lt;code&gt;bun&lt;/code&gt;instead of&lt;code&gt;node&lt;/code&gt;? You want to include all the information it needs to actually do meaningful work on the project. How can Claude verify Claude's changes? How can it run tests, typechecks, and compilation steps?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the way you do this is important! Don't try to stuff every command Claude could possibly need to run in your &lt;code&gt;CLAUDE.md&lt;/code&gt; file - you will get sub-optimal results.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Claude often ignores &lt;code&gt;CLAUDE.md&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Regardless of which model you're using, you may notice that Claude frequently ignores your &lt;code&gt;CLAUDE.md&lt;/code&gt; file's contents.&lt;/p&gt;
    &lt;p&gt;You can investigate this yourself by putting a logging proxy between the claude code CLI and the Anthropic API using &lt;code&gt;ANTHROPIC_BASE_URL&lt;/code&gt;. Claude code injects the following system reminder with your &lt;code&gt;CLAUDE.md&lt;/code&gt; file in the user message to the agent:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;&amp;lt;system-reminder&amp;gt; IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task. &amp;lt;/system-reminder&amp;gt;&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;As a result, Claude will ignore the contents of your &lt;code&gt;CLAUDE.md&lt;/code&gt; if it decides that it is not relevant to its current task. The more information you have in the file that's not universally applicable to the tasks you have it working on, the more likely it is that Claude will ignore your instructions in the file.&lt;/p&gt;
    &lt;p&gt;Why did Anthropic add this? It's hard to say for sure, but we can speculate a bit. Most &lt;code&gt;CLAUDE.md&lt;/code&gt; files we come across include a bunch of instructions in the file that aren't broadly applicable. Many users treat the file as a way to add "hotfixes" to behavior they didn't like by appending lots of instructions that weren't necessarily broadly applicable.&lt;/p&gt;
    &lt;p&gt;We can only assume that the Claude Code team found that by telling Claude to ignore the bad instructions, the harness actually produced better results.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Creating a good &lt;code&gt;CLAUDE.md&lt;/code&gt; file&lt;/head&gt;
    &lt;p&gt;The following section provides a number of recommendations on how to write a good &lt;code&gt;CLAUDE.md&lt;/code&gt; file following context engineering best practices.&lt;/p&gt;
    &lt;p&gt;Your mileage may vary. Not all of these rules are necessarily optimal for every setup. Like anything else, feel free to break the rules once...&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;you understand when &amp;amp; why it's okay to break them&lt;/item&gt;
      &lt;item&gt;you have a good reason to do so&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;### Less (instructions) is more&lt;/head&gt;
    &lt;p&gt;It can be tempting to try and stuff every single command that claude could possibly need to run, as well as your code standards and style guidelines into &lt;code&gt;CLAUDE.md&lt;/code&gt;. We recommend against this.&lt;/p&gt;
    &lt;p&gt;Though the topic hasn't been investigated in an incredibly rigorous manner, some research has been done which indicates the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Frontier thinking LLMs can follow ~ 150-200 instructions with reasonable consistency. Smaller models can attend to fewer instructions than larger models, and non-thinking models can attend to fewer instructions than thinking models.&lt;/item&gt;
      &lt;item&gt;Smaller models get MUCH worse, MUCH more quickly. Specifically, smaller models tend to exhibit an expotential decay in instruction-following performance as the number of instructions increase, whereas larger frontier thinking models exhibit a linear decay (see below). For this reason, we recommend against using smaller models for multi-step tasks or complicated implementation plans.&lt;/item&gt;
      &lt;item&gt;LLMs bias towards instructions that are on the peripheries of the prompt: at the very beginning (the Claude Code system message and &lt;code&gt;CLAUDE.md&lt;/code&gt;), and at the very end (the most-recent user messages)&lt;/item&gt;
      &lt;item&gt;As instruction count increases, instruction-following quality decreases uniformly. This means that as you give the LLM more instructions, it doesn't simply ignore the newer ("further down in the file") instructions - it begins to ignore all of them uniformly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our analysis of the Claude Code harness indicates that Claude Code's system prompt contains ~50 individual instructions. Depending on the model you're using, that's nearly a third of the instructions your agent can reliably follow already - and that's before rules, plugins, skills, or user messages.&lt;/p&gt;
    &lt;p&gt;This implies that your &lt;code&gt;CLAUDE.md&lt;/code&gt; file should contain as few instructions as possible - ideally only ones which are universally applicable to your task.&lt;/p&gt;
    &lt;head rend="h3"&gt;### &lt;code&gt;CLAUDE.md&lt;/code&gt; file length &amp;amp; applicability&lt;/head&gt;
    &lt;p&gt;All else being equal, an LLM will perform better on a task when its' context window is full of focused, relevant context including examples, related files, tool calls, and tool results compared to when its context window has a lot of irrelevant context.&lt;/p&gt;
    &lt;p&gt;Since &lt;code&gt;CLAUDE.md&lt;/code&gt; goes into every single session, you should ensure that its contents are as universally applicable as possible.&lt;/p&gt;
    &lt;p&gt;For example, avoid including instructions about (for example) how to structure a new database schema - this won't matter and will distract the model when you're working on something else that's unrelated!&lt;/p&gt;
    &lt;p&gt;Length-wise, the less is more principle applies as well. While Anthropic does not have an official recommendation on how long your &lt;code&gt;CLAUDE.md&lt;/code&gt; file should be, general consensus is that &amp;lt; 300 lines is best, and shorter is even better.&lt;/p&gt;
    &lt;p&gt;At HumanLayer, our root &lt;code&gt;CLAUDE.md&lt;/code&gt; file is less than sixty lines.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Progressive Disclosure&lt;/head&gt;
    &lt;p&gt;Writing a concise &lt;code&gt;CLAUDE.md&lt;/code&gt; file that covers everything you want Claude to know can be challenging, especially in larger projects.&lt;/p&gt;
    &lt;p&gt;To address this, we can leverage the principle of Progressive Disclosure to ensure that claude only sees task- or project-specific instructions when it needs them.&lt;/p&gt;
    &lt;p&gt;Instead of including all your different instructions about building your project, running tests, code conventions, or other important context in your &lt;code&gt;CLAUDE.md&lt;/code&gt; file, we recommend keeping task-specific instructions in separate markdown files with self-descriptive names somewhere in your project.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;agent_docs/ |- building_the_project.md |- running_tests.md |- code_conventions.md |- service_architecture.md |- database_schema.md |- service_communication_patterns.md&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Then, in your &lt;code&gt;CLAUDE.md&lt;/code&gt; file, you can include a list of these files with a brief description of each, and instruct Claude to decide which (if any) are relevant and to read them before it starts working. Or, ask Claude to present you with the files it wants to read for aproval first before reading them.&lt;/p&gt;
    &lt;p&gt;Prefer pointers to copies. Don't include code snippets in these files if possible - they will become out-of-date quickly. Instead, include &lt;code&gt;file:line&lt;/code&gt; references to point Claude to the authoritative context.&lt;/p&gt;
    &lt;p&gt;Conceptually, this is very similar to how Claude Skills are intended to work, although skills are more focused on tool use than instructions.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Claude is (not) an expensive linter&lt;/head&gt;
    &lt;p&gt;One of the most common things that we see people put in their &lt;code&gt;CLAUDE.md&lt;/code&gt; file is code style guidelines. Never send an LLM to do a linter's job. LLMs are comparably expensive and incredibly slow compared to traditional linters and formatters. We think you should always use deterministic tools whenever you can.&lt;/p&gt;
    &lt;p&gt;Code style guidelines will inevitably add a bunch of instructions and mostly-irrelevant code snippets into your context window, degrading your LLM's performance and instruction-following and eating up your context window.&lt;/p&gt;
    &lt;p&gt;LLMs are in-context learners! If your code follows a certain set of style guidelines or patterns, you should find that armed with a few searches of your codebase (or a good research document!) your agent should tend to follow existing code patterns and conventions without being told to.&lt;/p&gt;
    &lt;p&gt;If you feel very stronly about this, you might even consider setting up a Claude Code &lt;code&gt;Stop&lt;/code&gt; hook that runs your formatter &amp;amp; linter and presents errors to Claude for it to fix. Don't make Claude find the formatting issues itself.&lt;/p&gt;
    &lt;p&gt;Bonus points: use a linter that can automatically fix issues (we like Biome), and carefully tune your rules about what can safely be auto-fixed for maximum (safe) coverage.&lt;/p&gt;
    &lt;p&gt;You could also create a Slash Command that includes your code guidelines and which points claude at the changes in version control, or at your &lt;code&gt;git status&lt;/code&gt;, or similar. This way, you can handle implementation and formatting separately. You will see better results with both as a result.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Don't use &lt;code&gt;/init&lt;/code&gt; or auto-generate your &lt;code&gt;CLAUDE.md&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Both Claude Code and other harnesses with OpenCode come with ways to auto-generate your &lt;code&gt;CLAUDE.md&lt;/code&gt; file (or &lt;code&gt;AGENTS.md&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Because &lt;code&gt;CLAUDE.md&lt;/code&gt; goes into every single session with Claude code, it is one of the highest leverage points of the harness - for better or for worse, depending on how you use it.&lt;/p&gt;
    &lt;p&gt;A bad line of code is a bad line of code. A bad line of an implementation plan has the potential to create a lot of bad lines of code. A bad line of a research that misunderstands how the system works has the potential to result in a lot of bad lines in the plan, and therefore a lot more bad lines of code as a result.&lt;/p&gt;
    &lt;p&gt;But the &lt;code&gt;CLAUDE.md&lt;/code&gt; file affects every single phase of your workflow and every single artifact produced by it. As a result, we think you should spend some time thinking very carefully about every single line that goes into it:&lt;/p&gt;
    &lt;head rend="h2"&gt;## In Conclusion&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;is for onboarding Claude into your codebase. It should define your project's WHY, WHAT, and HOW.&lt;/item&gt;
      &lt;item&gt;Less (instructions) is more. While you shouldn't omit necessary instructions, you should include as few instructions as reasonably possible in the file.&lt;/item&gt;
      &lt;item&gt;Keep the contents of your &lt;code&gt;CLAUDE.md&lt;/code&gt;concise and universally applicable.&lt;/item&gt;
      &lt;item&gt;Use Progressive Disclosure - don't tell Claude all the information you could possibly want it to know. Rather, tell it how to find important information so that it can find and use it, but only when it needs to to avoid bloating your context window or instruction count.&lt;/item&gt;
      &lt;item&gt;Claude is not a linter. Use linters and code formatters, and use other features like Hooks and Slash Commands as necessary.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;is the highest leverage point of the harness, so avoid auto-generating it. You should carefully craft its contents for best results.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.humanlayer.dev/blog/writing-a-good-claude-md"/><published>2025-11-30T17:56:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098979</id><title>There is No Quintic Formula [video]</title><updated>2025-11-30T20:11:18.995108+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=9HIy5dJE-zQ"/><published>2025-11-30T18:15:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46098992</id><title>Don't push AI down our throats</title><updated>2025-11-30T20:11:18.933746+00:00</updated><content/><link href="https://gpt3experiments.substack.com/p/dont-push-ai-down-our-throats"/><published>2025-11-30T18:17:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46099022</id><title>NixOS 25.11 Released</title><updated>2025-11-30T20:11:18.830209+00:00</updated><content>&lt;doc fingerprint="ff65515b8a10e7d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Hey everyone, we are jopejoe1 and Leona Maroni, the release managers of the newest release of NixOS. We are very proud to announce the public availability of NixOS 25.11 “Xantusia”.&lt;/p&gt;
    &lt;p&gt;NixOS is a Linux distribution. Its underlying package repository Nixpkgs can also be used on other Linux systems and macOS with the Nix package manager.&lt;/p&gt;
    &lt;p&gt;This release will receive bugfixes and security updates for seven months (up until 2026-06-30). The old release 25.05 “Warbler” is now officially deprecated and will reach its end-of-life and stop receiving security updates after 2025-12-31.&lt;/p&gt;
    &lt;p&gt;The 25.11 release was made possible due to the efforts of 2742 contributors, who authored 59430 commits since the previous release.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights&lt;/head&gt;
    &lt;p&gt;Our vast and routinely maintained set of packages has also been updated. This release of Nixpkgs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Added 7002 new packages&lt;/item&gt;
      &lt;item&gt;Updated 25252 existing packages&lt;/item&gt;
      &lt;item&gt;Removed 6338 outdated packages, in an effort to keep the package set maintainable and secure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In addition to packages from Nixpkgs, the NixOS Linux distribution also features composable configuration modules and integration tests for distributed systems. This release of NixOS&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Added 107 new modules and 1778 configuration options&lt;/item&gt;
      &lt;item&gt;Removed 41 outdated modules and 807 configuration options.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;GNOME 49&lt;/head&gt;
    &lt;p&gt;GNOME has been updated to version 49 “Brescia”, which removes X11 session support, introduces a new video player, a new document viewer, a redesigned calender and more changes. Refer to the release notes for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;C compilers&lt;/head&gt;
    &lt;p&gt;LLVM has been updated to version 21. GCC remains at version 14. CMake was updated to version 4.&lt;/p&gt;
    &lt;head rend="h2"&gt;Special Thanks&lt;/head&gt;
    &lt;p&gt;We want to personally thank&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seth and dish for editorializing the release notes&lt;/item&gt;
      &lt;item&gt;Yohann Boniface for the release logo&lt;/item&gt;
      &lt;item&gt;The NixOS infrastucture team for their dutifully tending to our build infrastructure&lt;/item&gt;
      &lt;item&gt;The Nixpkgs staging team for supporting our staging cycles and the patient fixing of many build errors.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We also want to thank all contributors who made this release possible!&lt;/p&gt;
    &lt;head rend="h2"&gt;Reflections and closing&lt;/head&gt;
    &lt;p&gt;We are grateful for the opportunity to support the community as release managers and to learn about and participate in the release process. Seeing all the contributors working in their area of the project to improve it has been an exciting experience. We would like to thank everyone in the community for that. We are looking forward to the next release, NixOS 26.05 “Yarara”.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nixos.org/blog/announcements/2025/nixos-2511/"/><published>2025-11-30T18:21:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46099108</id><title>Program-of-Thought Prompting Outperforms Chain-of-Thought by 15% (2022)</title><updated>2025-11-30T20:11:18.542860+00:00</updated><content>&lt;doc fingerprint="e8bcc40accf7908a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 22 Nov 2022 (v1), last revised 23 Oct 2023 (this version, v4)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks&lt;/head&gt;View PDF&lt;quote&gt;Abstract:Recently, there has been significant progress in teaching language models to perform step-by-step reasoning to solve complex numerical reasoning tasks. Chain-of-thoughts prompting (CoT) is by far the state-of-art method for these tasks. CoT uses language models to perform both reasoning and computation in the multi-step `thought' process. To disentangle computation from reasoning, we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to express the reasoning process as a program. The computation is relegated to an external computer, which executes the generated programs to derive the answer. We evaluate PoT on five math word problem datasets (GSM, AQuA, SVAMP, TabMWP, MultiArith) and three financial-QA datasets (FinQA, ConvFinQA, TATQA) for both few-shot and zero-shot setups. Under both few-shot and zero-shot settings, PoT can show an average performance gain over CoT by around 12\% across all the evaluated datasets. By combining PoT with self-consistency decoding, we can achieve SoTA performance on all math problem datasets and near-SoTA performance on financial datasets. All of our data and code are released in Github this https URL&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Wenhu Chen [view email]&lt;p&gt;[v1] Tue, 22 Nov 2022 21:06:00 UTC (8,689 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 25 Nov 2022 01:49:50 UTC (8,689 KB)&lt;/p&gt;&lt;p&gt;[v3] Tue, 29 Nov 2022 03:46:29 UTC (8,689 KB)&lt;/p&gt;&lt;p&gt;[v4] Mon, 23 Oct 2023 01:27:38 UTC (4,047 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2211.12588"/><published>2025-11-30T18:34:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46099367</id><title>You Want Microservices, but Do You Need Them?</title><updated>2025-11-30T20:11:18.376076+00:00</updated><content>&lt;doc fingerprint="3558b3710334ca8f"&gt;
  &lt;main&gt;
    &lt;p&gt;Do you know who managed to cut costs by a staggering 90% by abandoning microservices for a monolith in May 2023? Not a cash-strapped startup or an indie project—Amazon itself, for its Prime Video service. The same AWS that earns billions every year by selling microservices infrastructure admitted that, sometimes, a good old monolith wins.&lt;/p&gt;
    &lt;p&gt;This reversal from the company that practically wrote the playbook on distributed systems sent shockwaves through the cloud-native community. Amazon later removed the original blog post, but the internet never forgets, as you’ll see later.&lt;/p&gt;
    &lt;p&gt;I’ve been speaking up against unnecessary or premature use of microservices architecture for five, six years now. After Amazon Prime Video went back to a monolith, I came across several eminent architects who are also speaking against microservices as default.&lt;/p&gt;
    &lt;p&gt;And yet in most tech circles, microservices are still viewed as the only way to build modern software. They dominate conferences, blogs, and job listings. Teams adopt them not because their requirements justify it, but because it feels like the obvious (and résumé-boosting) choice. “Cloud-native” has become synonymous with “microservices-by-default”, as if other approaches are as obsolete as floppy disks.&lt;/p&gt;
    &lt;p&gt;Microservices do solve real problems, but at a massive scale. Most teams don’t actually operate at that scale.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;With this article, I urge you to reflect on the question the industry has mostly stopped asking: Should microservices be the default choice for building at scale? We’ll look at reversal stories and insights from seasoned architects, and weigh the trade-offs and alternatives. After considering all of this, you can decide whether your problem really needs a constellation of microservices.&lt;/p&gt;
    &lt;head rend="h2"&gt;Microservices: The Agility-Complexity Trade-Off&lt;/head&gt;
    &lt;p&gt;On paper, microservices look impressive. Instead of one big monolith, you split your application into many small services. Each one can be written in any language, owned by a small team, and deployed on its own schedule. If you need more capacity, you can scale only the part that’s under load. The promise is elegant: independent deployability, autonomous teams, multi-language stacks, and elastic scaling.&lt;/p&gt;
    &lt;p&gt;But the catch is that every split creates a seam, and every seam is a potential failure point. Inside a monolith, function calls are instant and predictable. Across services, those same calls become network requests: slower, failure-prone, sometimes returning inconsistent data. With dozens (or hundreds) of services, you need version management, schema evolution, distributed transactions, tracing, centralized logging, and heavy-duty CI/CD pipelines just to keep things running.&lt;/p&gt;
    &lt;p&gt;This Gartner diagram captures the trade-off perfectly: microservices exchange the simplicity of one codebase for the complexity of many.&lt;/p&gt;
    &lt;p&gt;At a massive scale (think Netflix), that trade-off may be worth it. But when operational benefits don’t outweigh the costs, teams end up paying a steep price in debugging, coordination, and glue code just to hold their product together.&lt;/p&gt;
    &lt;p&gt;Microservices make sense in very specific scenarios where distinct business capabilities need independent scaling and deployment. For example, payment processing (security-critical, rarely updated) differs fundamentally from recommendation engine (memory-intensive, constantly A/B tested). These components have different scaling patterns, deployment cycles, and risk profiles, which justify separate services.&lt;/p&gt;
    &lt;p&gt;The success of microservices hinges on clear business domain boundaries that match your team structure, as Conway’s Law predicts. If your organization naturally splits into autonomous teams that own distinct capabilities, microservices might work. (So, most “one-and-a-half pizza” startups don’t qualify, do they?)&lt;/p&gt;
    &lt;p&gt;That’s why microservices work effectively for companies like Amazon and Uber—although not always.&lt;/p&gt;
    &lt;p&gt;In fact, most organizations lack the prerequisites: dedicated service ownership, mature CI/CD, robust monitoring, and crucially, scale that justifies the operational overhead. Startups that adapt microservices prematurely often regret their decision.&lt;/p&gt;
    &lt;p&gt;So ask yourself:&lt;/p&gt;
    &lt;p&gt;Are you using microservices to solve an independent scaling problem, or are you inviting more complexity than your solution needs?&lt;/p&gt;
    &lt;head rend="h2"&gt;The Great Microservices Reversal&lt;/head&gt;
    &lt;p&gt;Ironically, even though tech giants are the ones that are most likely to benefit from microservices, many of these very same companies are walking back their microservices architectures, and the results are eye-opening.&lt;/p&gt;
    &lt;head rend="h3"&gt;Amazon Prime Video: 90% Cost Reduction with a Monolith&lt;/head&gt;
    &lt;p&gt;In May 2023, Amazon engineers admitted the unthinkable: Prime Video had abandoned microservices for a monolith. Their Video Quality Analysis (VQA) team had built what looked like a textbook distributed system: AWS Step Functions and Lambda monitored thousands of video streams through independent, scalable components. On paper, it was serverless perfection.&lt;/p&gt;
    &lt;p&gt;In practice, it was a disaster. “We realized that distributed approach wasn’t bringing a lot of benefits in our specific use case,” said Marcin Kolny in the now-archived Prime Video Engineering blog. Their “infinitely scalable” system crumbled at just 5% of expected load due to orchestration overhead.&lt;/p&gt;
    &lt;p&gt;The fix was embarrassingly simple: collapse everything into a single process. It resulted in 90% lower costs and faster performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Twilio Segment: From 140 Services to One Fast Monolith&lt;/head&gt;
    &lt;p&gt;Back in 2018, Twilio Segment, a customer data platform, documented a similar reversal in their brutally honest post “Goodbye Microservices”.&lt;/p&gt;
    &lt;p&gt;Their system had sprawled into 140+ services, creating operational chaos. At one point, three full-time engineers spent most of their time firefighting instead of building. As they admitted, “Instead of enabling us to move faster, the small team found themselves mired in exploding complexity. Essential benefits of this architecture became burdens. As our velocity plummeted, our defect rate exploded.”&lt;/p&gt;
    &lt;p&gt;Their solution was radical but effective: collapse all 140+ services into a single monolith. The impact was immediate. Test suites that once took an hour now finished in milliseconds. Developer productivity soared: they shipped 46 improvements to shared libraries in a year, up from 32 in the microservices era.&lt;/p&gt;
    &lt;head rend="h3"&gt;Shopify: Sanity over Hype&lt;/head&gt;
    &lt;p&gt;Shopify runs one of the largest Ruby on Rails codebases in the world (2.8M+ lines). Instead of chasing microservices, they deliberately chose a modular monolith: a single codebase with clear component boundaries.&lt;/p&gt;
    &lt;p&gt;Shopify’s engineers concluded that “microservices would bring their own set of challenges”, so they chose modularity without the operational overhead.&lt;/p&gt;
    &lt;p&gt;All these examples beg the question:&lt;/p&gt;
    &lt;p&gt;If even the pioneers of microservices are retreating, why are we still treating it as gospel?&lt;/p&gt;
    &lt;head rend="h2"&gt;Expert Voices against Microservices Mania&lt;/head&gt;
    &lt;p&gt;Some of the most respected voices in software architecture—people behind many of the systems we all admire—are also cautioning against microservices and repeating mistakes they’ve seen play out at scale. (After all, cheerleaders don’t play the game; cloud DevRels rarely build at scale.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Rails Creator: Simplicity over Sophistication&lt;/head&gt;
    &lt;p&gt;David Heinemeier Hansson (DHH), the creator of Ruby on Rails, has long advocated simplicity over architectural trends. His analysis of the Amazon Prime Video reversal puts it bluntly:&lt;/p&gt;
    &lt;p&gt;“The real-world results of all this theory are finally in, and it’s clear that in practice, microservices pose perhaps the biggest siren song for needlessly complicating your system.”&lt;/p&gt;
    &lt;p&gt;DHH’s image of a siren song is apt: microservices promise elegance but leave teams wrecked on the rocks of complexity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Microservices: Mistake of The Decade?&lt;/head&gt;
    &lt;p&gt;Jason Warner, former CTO of GitHub, doesn’t mince words while commenting on microservices:&lt;/p&gt;
    &lt;p&gt;“I’m convinced that one of the biggest architectural mistakes of the past decade was going full microservice.”&lt;/p&gt;
    &lt;p&gt;Warner understands scale: GitHub runs at internet scale, and he’s led engineering at Heroku and Canonical. His critique cuts deeper because it’s lived experience, beyond theoretical advice:&lt;/p&gt;
    &lt;p&gt;“90% of all companies in the world could probably just be a monolith running against a primary db cluster with db backups, some caches and proxies and be done with it.”&lt;/p&gt;
    &lt;head rend="h3"&gt;GraphQL Co-Creator: “Don’t”&lt;/head&gt;
    &lt;p&gt;Then there’s Nick Schrock, co-creator of GraphQL. If anyone had a reason to cheer for distributed systems, it’d be him. Instead, he says:&lt;/p&gt;
    &lt;p&gt;“Microservices are such a fundamentally and catastrophically bad idea that there are going to be an entire cohort of multi-billion companies built that do nothing but contain the damage that they have wrought.”&lt;/p&gt;
    &lt;p&gt;He goes on to describe microservices as organizational gambles:&lt;/p&gt;
    &lt;p&gt;“[Y]ou end up with these services that you have to maintain forever that match the org structure and the product requirements from five years ago. Today, they don’t make a lot of sense.”&lt;/p&gt;
    &lt;p&gt;The person who literally built tools to fix distributed system pain says don’t distribute unless you must, maybe it’s time to listen.&lt;/p&gt;
    &lt;head rend="h3"&gt;Other Voices Questioning Microservice Maximalism&lt;/head&gt;
    &lt;p&gt;Other engineering leaders are also reconsidering microservice maximalism.&lt;/p&gt;
    &lt;p&gt;At Uber, Gergely Orosz admitted:&lt;/p&gt;
    &lt;p&gt;“We’re moving many of our microservices to macroservices (well-sized services). Exactly b/c testing and maintaining thousands of microservices is not only hard – it can cause more trouble long-term than it solves the short-term.”&lt;/p&gt;
    &lt;p&gt;Uber still runs microservices where they’re justified, but they’re choosing their battles.&lt;/p&gt;
    &lt;p&gt;Kelsey Hightower, known for his work with Kubernetes and Google Cloud, cut through the microservices hype with CS101:&lt;/p&gt;
    &lt;p&gt;“I’m willing to wager a monolith will outperform every microservice architecture. Just do the math on the network latency between each service and the amount of serialization and deserialization of each request.”&lt;/p&gt;
    &lt;p&gt;He subsequently deleted this tweet, but the network math still grades microservices.&lt;/p&gt;
    &lt;p&gt;When pioneers like these, including those who actually solved distributed systems at scale, start waving red flags, it’s worth taking note.&lt;/p&gt;
    &lt;p&gt;My question here is:&lt;/p&gt;
    &lt;p&gt;If GitHub’s CTO thinks 90% of companies don’t need microservices, are you sure yours is part of the 10%?&lt;/p&gt;
    &lt;head rend="h2"&gt;The Hidden Costs of Microservices&lt;/head&gt;
    &lt;p&gt;Microservices demand such caution because of these hidden costs that teams often underestimate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Operational Costs&lt;/head&gt;
    &lt;p&gt;A monolith is simple: in-process function calls.&lt;/p&gt;
    &lt;p&gt;Microservices replace that with networks. Every request now travels across machines, through load balancers, service meshes, and authentication layers, creating more failure points and infrastructure needs. You suddenly need service discovery (how services find each other), distributed tracing (tracking requests across services), centralized logging (aggregating logs from multiple services), and monitoring systems that understand service topology.&lt;/p&gt;
    &lt;p&gt;Each of these is necessary, but together they’re complex and expensive. Duplicated data requires extra storage. Constant service-to-service calls rack up network egress fees. Cloud costs scale faster than the apps they host. Prime Video’s workflow spent more on orchestrating S3 data transfers between services than on actual processing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Developer Productivity Drain&lt;/head&gt;
    &lt;p&gt;In microservices, the hard part isn’t writing code; it’s navigating distributed system interactions.&lt;/p&gt;
    &lt;p&gt;In “The macro problem with microservices“, Stack Overflow identifies a critical productivity drain: distributed state forces developers to write defensive code that constantly checks for partial failures.&lt;/p&gt;
    &lt;p&gt;In a monolith, a developer can follow a code path end-to-end within one repo. In microservices, one feature might span four or five repos with different dependencies and deploy cycles. Adding a single field triggers weeks of coordination: you need to update one service, then wait for consumers to adopt, version your APIs, manage rollouts, and so on. Different teams will also typically maintain different microservices using different tech stacks, so there’s a risk that they unintentionally break something as well. Breaking changes that a compiler would catch in a monolith now surface as runtime errors in production.&lt;/p&gt;
    &lt;head rend="h3"&gt;Testing and Deployment Complexity&lt;/head&gt;
    &lt;p&gt;Monolith integration and end-to-end tests are faster because they run locally, in memory. Distributed systems don’t allow that luxury: real confidence requires integration and end-to-end tests across numerous service boundaries. So these tests are slower, more brittle, and require staging environments that resemble production, all of which effectively double infrastructure costs and slow feedback loops.&lt;/p&gt;
    &lt;p&gt;Many teams discover this only after their test suite becomes a bottleneck. Deployment orchestration adds another layer. Rolling updates across interdependent services require careful sequencing to avoid breaking contracts. Version incompatibility disturbs frequently: Service A works with Service B v2.1 but breaks with v2.2.&lt;/p&gt;
    &lt;p&gt;Failed deployments leave systems partially updated and difficult to recover.&lt;/p&gt;
    &lt;head rend="h3"&gt;Data Management and Consistency&lt;/head&gt;
    &lt;p&gt;The most underestimated complexity of microservices lies in data consistency across service boundaries.&lt;/p&gt;
    &lt;p&gt;Monoliths benefit from ACID transactions: operations complete entirely or fail entirely. Microservices split that across services, forcing you to build distributed saga (multi-step workflows with rollback logic), live with eventual consistency (data only becomes correct after a delay), or write compensation logic (extra code to undo partial failures). What was once a single database transaction now spans network hops, retries, and partial failures. Debugging inconsistent orders or payments gets much harder when state is duplicated across services.&lt;/p&gt;
    &lt;p&gt;As research confirms, data duplication, correctness challenges, and transactional complexity are the top pain points in microservice systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Compounding Effect&lt;/head&gt;
    &lt;p&gt;These complexities multiply. Operational overhead makes debugging harder, which slows testing, which makes deployments riskier, which creates more incidents. Microservices don’t just shift complexity from code to operations; they tax every part of your engineering process.&lt;/p&gt;
    &lt;p&gt;Unless your scale demands it, that tax often outweighs the benefits.&lt;/p&gt;
    &lt;p&gt;Think about it:&lt;/p&gt;
    &lt;p&gt;If every network hop adds complexity and cost, does your use case really justify the price?&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond Microservices: Smarter Architectural Alternatives&lt;/head&gt;
    &lt;p&gt;Before defaulting to microservices, it’s worth considering how simpler, well-structured architectures can deliver comparable scalability without the distributed complexity tax. Two noteworthy alternatives are modular monoliths and service-oriented architectures.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modular Monoliths: Structure without Distribution&lt;/head&gt;
    &lt;p&gt;Unlike traditional monoliths that become tangled messes, modular monoliths enforce strict internal boundaries through clear module APIs and disciplined separation. Each module exposes well-defined interfaces, enabling teams to work independently while deploying a single, coherent system.&lt;/p&gt;
    &lt;p&gt;As Kent Beck explains in “Monolith -&amp;gt; Services: Theory &amp;amp; Practice”, modular monoliths manage coupling through organizational discipline rather than distributed networks. The key difference: modules still communicate via explicit contracts like microservices, but they use fast, reliable function calls instead of HTTP requests that are vulnerable to network latency and partial failures.&lt;/p&gt;
    &lt;p&gt;Why does it work?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simpler operations: microservices-level organization with monolithic simplicity&lt;/item&gt;
      &lt;item&gt;Stronger consistency: full ACID transactions&lt;/item&gt;
      &lt;item&gt;Easier debugging: one traceable system, no hunting for bugs in the ELK haystack&lt;/item&gt;
      &lt;item&gt;Better performance: function calls beat network hops&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s some real-world proof: Shopify’s 2.8 million-line codebase handles 30TB per minute with separate teams owning distinct modules, yet everything deploys together. Facebook runs similarly. (And principal architect Keith Adams jokes that if you want to be talked out of microservices, he’s your guy.)&lt;/p&gt;
    &lt;p&gt;With recent developments in frameworks like Spring Modulith, Django, Laravel, and Rails (as seen at scale with Shopify), modular monoliths are poised to gain wider traction in the years ahead.&lt;/p&gt;
    &lt;head rend="h3"&gt;Service-Oriented Architecture: The Middle Ground&lt;/head&gt;
    &lt;p&gt;Service-oriented architecture (SOA) sits between monoliths and microservices, favoring larger, domain-driven services instead of dozens or hundreds of tiny ones. These services often communicate via an enterprise service bus (ESB), which reduces orchestration overhead while preserving separation of concerns.&lt;/p&gt;
    &lt;p&gt;Instead of splitting authentication, user preferences, and notifications into separate microservices, SOA might combine them into a single “User Service”, simplifying coordination while preserving autonomy and targeted scaling. SOA provides enterprise-grade modularity without ultra-fine-grained distribution overhead.&lt;/p&gt;
    &lt;p&gt;Here’s why it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Right-sized boundaries: fewer, domain-aligned services instead of sprawl&lt;/item&gt;
      &lt;item&gt;Targeted scalability: scale services tied to real business domains&lt;/item&gt;
      &lt;item&gt;Pragmatic complexity: avoids ultra-fine-grained overhead while retaining modular reasoning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SOA has also been proven to work at scale. Norwegian Air Shuttle, Europe’s 9th-largest airline, used SOA to boost agility across complex flight operations. Credit Suisse’s SOA rollout powered millions of service calls per day back in the early 2000s.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choosing Wisely: Fit over Hype&lt;/head&gt;
    &lt;p&gt;The problem you’re solving should justify your architecture.&lt;/p&gt;
    &lt;p&gt;I often use this analogy in consulting: You don’t need a sword to cut a lemon—a knife suffices. And as timeless wisdom reminds us, simplicity is the ultimate sophistication.&lt;/p&gt;
    &lt;p&gt;In all likelihood, you’re not Google (you don’t need Google-level fault tolerance), or Amazon (you don’t need massive write availability), or LinkedIn (you don’t handle billions of events a day). Most applications don’t operate at that scale, demanding fundamentally different solutions than ultra-distributed architectures.&lt;/p&gt;
    &lt;p&gt;For most systems, well-structured modular monoliths (for most common applications, including startups) or SOA (enterprises) deliver comparable scalability and resilience as microservices, without the distributed complexity tax. Alternatively, you may also consider well-sized services (macroservices, or what Gartner proposed as miniservices) instead of tons of microservices.&lt;/p&gt;
    &lt;p&gt;It’s worth asking:&lt;/p&gt;
    &lt;p&gt;If simpler architectures can deliver comparable scalability, why are you choosing the complexity of microservices?&lt;/p&gt;
    &lt;head rend="h2"&gt;Docker: Built for Any Architecture&lt;/head&gt;
    &lt;p&gt;Docker isn’t just for microservices—it works great across all kinds of architectures like monoliths, SOA, APIs, and event-driven systems. The real benefit is that Docker gives you consistent performance, easier deployment, and flexibility to scale up your apps no matter what architectural approach you’re using.&lt;/p&gt;
    &lt;p&gt;Docker packages applications cleanly, keeps environments consistent from laptop to production, simplifies dependency management, and isolates applications from the host system. A Dockerized monolith offers all these benefits, minus the orchestration overhead of microservices.&lt;/p&gt;
    &lt;p&gt;Microsoft’s guidance on containerizing monoliths clarifies that scaling containers is “far faster and easier than deploying additional VMs”, whether you run one service or fifty. Twilio Segment observed that containerized monoliths can “horizontally scale your environment easily by spinning up more containers and shutting them down when demand subsides.” For many applications, scaling the whole app is exactly what’s needed.&lt;/p&gt;
    &lt;p&gt;As for DevOps, a monolith in Docker is lighter to operate than a full-blown microservices setup. Logging aggregation becomes simpler when you’re collecting from identical containers rather than disparate services with different formats. Monitoring and debugging remain centralized, and troubleshooting avoids tracing requests across service boundaries.&lt;/p&gt;
    &lt;p&gt;So, it’s definitely worth considering:&lt;/p&gt;
    &lt;p&gt;Even without the complexity of microservices, Docker gives you the same advantages — clean deployments, easy scaling, and consistent environments. So why not keep it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping Up&lt;/head&gt;
    &lt;p&gt;A few years ago, my then-8-year-old wanted a bicycle. He’d mostly ride around our apartment complex, maybe venture into the nearby lane. He didn’t need 21 gears, but those shiny shifters had him smitten—imagine riding faster by changing those gears! He absolutely wanted that mechanically complex beauty. (It’s hard to argue with a starry-eyed kid… or a founder :P).&lt;/p&gt;
    &lt;p&gt;Once he started riding the new bike, the gears slipped, the chain jammed, and the bicycle spent more time broken than on the road. Eventually, we had to dump it.&lt;/p&gt;
    &lt;p&gt;I wasn’t able to convince him back then that a simpler bicycle could’ve served him better, but maybe this article will convince a few grown-ups making architectural decisions.&lt;/p&gt;
    &lt;p&gt;We techies love indulging in complex systems. (Check: were you already thinking, What’s complex about bicycles with gears??) But the more moving parts you add, the more often they break. Complexity often creates more problems than it solves.&lt;/p&gt;
    &lt;p&gt;The point I’m making isn’t to dump microservices entirely—it’s to pick an architecture that fits your actual needs, not what the cloud giant is pushing (while quietly rolling back their own commit). Most likely, modular monoliths or well-designed SOA will serve your needs better and make your team more productive.&lt;/p&gt;
    &lt;p&gt;So here’s the million-dollar question:&lt;/p&gt;
    &lt;p&gt;Will you design for cloud-native hype or for your own business requirements?&lt;/p&gt;
    &lt;p&gt;Do you really need microservices?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.docker.com/blog/do-you-really-need-microservices/"/><published>2025-11-30T19:02:04+00:00</published></entry></feed>