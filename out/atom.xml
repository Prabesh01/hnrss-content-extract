<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-22T02:19:58.479657+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46003144</id><title>FAWK: LLMs can write a language interpreter</title><updated>2025-11-22T02:20:10.924727+00:00</updated><content>&lt;doc fingerprint="5ff690b5ea490edb"&gt;
  &lt;main&gt;
    &lt;p&gt;After reading the book The AWK Programming Language (recommended!), I was planning to try AWK out on this year’s Advent of Code. Having some time off from work this week, I tried to implement one of the problems in it to get some practice, set up my tooling, see how hard AWK would be, and… I found I’m FP-pilled.&lt;/p&gt;
    &lt;p&gt;I knew I’m addicted to the combination of algebraic data types (tagged unions) and exhaustive pattern matching, but what got me this time was immutability, lexical scope and the basic human right of being allowed to return arrays from functions.&lt;/p&gt;
    &lt;p&gt;Part 1 of the Advent of Code problem was easy enough, but for part 2 (basically a shortest path search with a twist, to not spoil too much), I found myself unable to switch from my usual functional BFS approach to something mutable, and ended up trying to implement my functional approach in AWK.&lt;/p&gt;
    &lt;p&gt;It got hairy very fast: I needed to implement:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;hashing of strings and 2D arrays (by piping to &lt;code&gt;md5sum&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;a global &lt;del rend="overstrike"&gt;set&lt;/del&gt;array of seen states&lt;/item&gt;
      &lt;item&gt;a way to serialize and deserialize a 2D array to/from a string&lt;/item&gt;
      &lt;item&gt;and a few associative arrays for retrieving this serialized array by its hash.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was very lost by the time I had all this; I spent hours just solving what felt like accidental complexity; things that I’d take for granted in more modern languages.&lt;/p&gt;
    &lt;p&gt;Now, I know nobody said AWK is modern, or functional, or that it promises any convenience for anything other than one-liners and basic scripts that fit under a handful of lines. I don’t want to sound like I expect AWK to do any of this; I knew I was stretching the tool when going in. But I couldn’t shake the feeling that there’s a beautiful AWK-like language within reach, an iteration on the AWK design (the pattern-action way of thinking is beautiful) that also gives us a few of the things programming language designers have learnt over the 48 years since AWK was born.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dreaming of functional AWK&lt;/head&gt;
    &lt;p&gt;Stopping my attempts to solve the AoC puzzle in pure AWK, I wondered: what am I missing here?&lt;/p&gt;
    &lt;p&gt;What if AWK had first-class arrays?&lt;/p&gt;
    &lt;code&gt;BEGIN {
  # array literals
  normal   = [1, 2, 3]
  nested   = [[1,2], [3,4]]
  assoc    = ["foo" =&amp;gt; "bar", "baz" =&amp;gt; "quux"]
  multidim = [(1,"abc") =&amp;gt; 999]

  five = range(1,5)
  analyze(five)
  print five  # --&amp;gt; still [1, 2, 3, 4, 5]! was passed by value
}

function range(a,b) {
  r = []
  for (i = a; i &amp;lt;= b; i++) {
    r[length(r)] = i
  }
  return r  # arrays can be returned!
}

function analyze(arr) {
  arr[0] = 100
  print arr[0]  # --&amp;gt; 100, only within this function
}
&lt;/code&gt;
    &lt;p&gt;What if AWK had first-class functions and lambdas?&lt;/p&gt;
    &lt;code&gt;BEGIN {
  # construct anonymous functions
  double = (x) =&amp;gt; { x * 2 }
  add = (a, b) =&amp;gt; { c = a + b; return c }

  # functions can be passed as values
  apply = (func, value) =&amp;gt; { func(value) }

  print apply(double,add(1,3))  # --&amp;gt; 8
  print apply(inc,5)  # --&amp;gt; 6
}

function inc(a) { return a + 1 }
&lt;/code&gt;
    &lt;p&gt;What if AWK had lexical scope instead of dynamic scope?&lt;/p&gt;
    &lt;code&gt;# No need for this hack anymore ↓     ↓
#function foo(a, b         ,local1, local2) {
function foo(a, b) {
  local1 = a + b
  local2 = a - b
  return local1 + local2
}

BEGIN {
  c = foo(1,2)
  print(local1)  # --&amp;gt; 0, the local1 from foo() didn't leak!
}
&lt;/code&gt;
    &lt;p&gt;What if AWK had explicit globals, and everything else was local by default?&lt;/p&gt;
    &lt;code&gt;BEGIN { global count }
END {
  foo()
  print count  # --&amp;gt; 1
  print mylocal # --&amp;gt; 0, didn't leak
}
function foo() { count++; mylocal++ }
&lt;/code&gt;
    &lt;p&gt;(This one, admittedly, might make programs a bit more verbose. I’m willing to pay that cost.)&lt;/p&gt;
    &lt;p&gt;What if AWK had pipelines? (OK, now I’m reaching for syntax sugar…)&lt;/p&gt;
    &lt;code&gt;BEGIN {
  result = [1, 2, 3, 4, 5] 
      |&amp;gt; filter((x) =&amp;gt; { x % 2 == 0 })
      |&amp;gt; map((x) =&amp;gt; { x * x })
      |&amp;gt; reduce((acc, x) =&amp;gt; { acc + x }, 0)

  print "Result:", result
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Making it happen&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;TL;DR:&lt;/p&gt;&lt;code&gt;Janiczek/fawk&lt;/code&gt;on GitHub&lt;/quote&gt;
    &lt;p&gt;Now for the crazy, LLM-related part of the post. I didn’t want to spend days implementing AWK from scratch or tweaking somebody else’s implementation. So I tried to use Cursor Agent for a larger task than I usually do (I tend to ask for very small targeted edits), and asked Sonnet 4.5 for a README with code examples, and then a full implementation in Python.&lt;/p&gt;
    &lt;p&gt;And it did it.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: I also asked for implementations in C, Haskell and Rust at the same time, not knowing if any of the four would succeed, and they all seem to have produced code that at least compiles/runs. I haven’t tried to test them or even run them though. The PRs are here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I was very impressed—I still am! I expected the LLM to stumble and flail around and ultimately get nothing done, but it did what I asked it for (gave me an interpreter that could run those specific examples), and over the course of a few chat sessions, I guided it towards implementing more and more of “the rest of AWK”, together with an excessive amount of end-to-end tests.&lt;/p&gt;
    &lt;p&gt;The only time I could see it struggle was when I asked it to implement arbitrary precision floating point operations without using an external library like &lt;code&gt;mpmath&lt;/code&gt;. It attempted to use Taylor series, but couldn’t get it right for at
least a few minutes. I chickened out and told it to &lt;code&gt;uv add mpmath&lt;/code&gt; and simplify
the interpreter code. In a moment it was done.&lt;/p&gt;
    &lt;p&gt;Other things that I thought it would choke on, like &lt;code&gt;print&lt;/code&gt; being both a
statement (with &lt;code&gt;&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; redirection support) and an expression, or
multi-dimensional arrays, or multi-line records, these were all implemented
correctly. Updating the test suite to also check for backwards compatibility
with GAWK - not an issue. Lexical scoping
and tricky closure environment behaviour - handled that just fine.&lt;/p&gt;
    &lt;head rend="h2"&gt;What now?&lt;/head&gt;
    &lt;p&gt;As the cool kids say, I have to update my priors. The frontier of what the LLMs can do has moved since the last time I tried to vibe-code something. I didn’t expect to have a working interpreter the same day I dreamt of a new programming language. It now seems possible.&lt;/p&gt;
    &lt;p&gt;The downside of vibe coding the whole interpreter is that I have zero knowledge of the code. I only interacted with the agent by telling it to implement a thing and write tests for it, and I only really reviewed the tests. I reckon this would be an issue in the future when I want to manually make some change in the actual code, because I have no familiarity with it.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This also opened new questions for me wrt. my other projects where I’ve previously run out of steam, eg. trying to implement a Hindley-Milner type system for my dream forever-WIP programming language Cara. It seems I can now just ask the LLM to do it, and it will? But then, I don’t want to fall into the trap where I am no longer able to work on the codebase myself. I want to be familiar with and able to tinker on the code. I’d need to spend my time reviewing and reading code instead of writing everything myself. Perhaps that’s OK.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Performance of FAWK might be an issue as well, though right now it’s a non-goal, given my intended use case is throwaway scripts for Advent of Code, nothing user-facing. And who knows, based on what I’ve seen, maybe I can instruct it to rewrite it in Rust and have a decent chance of success?&lt;/p&gt;
    &lt;p&gt;For now, I’ll go dogfood my shiny new vibe-coded black box of a programming language on the Advent of Code problem (and as many of the 2025 puzzles as I can), and see what rough edges I can find. I expect them to be equal parts “not implemented yet” and “unexpected interactions of new PL features with the old ones”.&lt;/p&gt;
    &lt;p&gt;If you’re willing to jump through some Python project dependency hoops, you can try to use FAWK too at your own risk, at &lt;code&gt;Janiczek/fawk&lt;/code&gt; on
GitHub.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://martin.janiczek.cz/2025/11/21/fawk-llms-can-write-a-language-interpreter.html"/><published>2025-11-21T10:28:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46004293</id><title>Making a Small RPG</title><updated>2025-11-22T02:20:10.872963+00:00</updated><content/><link href="https://jslegenddev.substack.com/p/making-a-small-rpg"/><published>2025-11-21T13:23:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46005111</id><title>We should all be using dependency cooldowns</title><updated>2025-11-22T02:20:10.562821+00:00</updated><content>&lt;doc fingerprint="af811b9b5ac90ef0"&gt;
  &lt;main&gt;
    &lt;p&gt;Nov 21, 2025 Tags: oss, security&lt;/p&gt;
    &lt;p&gt;TL;DR: Dependency cooldowns are a free, easy, and incredibly effective way to mitigate the large majority of open source supply chain attacks. More individual projects should apply cooldowns (via tools like Dependabot and Renovate) to their dependencies, and packaging ecosystems should invest in first-class support for cooldowns directly in their package managers.&lt;/p&gt;
    &lt;p&gt;âSupply chain securityâ is a serious problem. Itâs also seriously overhyped, in part because dozens of vendors have a vested financial interest in convincing your that their framing of the underlying problem1 is (1) correct, and (2) worth your money.&lt;/p&gt;
    &lt;p&gt;Whatâs consternating about this is that most open source supply chain attacks have the same basic structure:&lt;/p&gt;
    &lt;p&gt;An attacker compromises a popular open source project, typically via a stolen credential or CI/CD vulnerabilty (such as âpwn requestsâ in GitHub Actions).&lt;/p&gt;
    &lt;p&gt;The attacker introduces a malicious change to the project and uploads it somewhere that will have maximum effect (PyPI, npm, GitHub releases, &amp;amp;c., depending on the target).&lt;/p&gt;
    &lt;p&gt;At this point, the clock has started, as the attacker has moved into the public.&lt;/p&gt;
    &lt;p&gt;Users pick up the compromised version of the project via automatic dependency updates or a lack of dependency pinning.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the aforementioned vendors are scanning public indices as well as customer repositories for signs of compromise, and provide alerts upstream (e.g. to PyPI).&lt;/p&gt;
    &lt;p&gt;Notably, vendors are incentivized to report quickly and loudly upstream, as this increases the perceived value of their services in a crowded field.&lt;/p&gt;
    &lt;p&gt;Upstreams (PyPI, npm, &amp;amp;c.) remove or disable the compromised package version(s).&lt;/p&gt;
    &lt;p&gt;End-user remediation begins.&lt;/p&gt;
    &lt;p&gt;The key thing to observe is that the gap between (1) and (2) can be very large2 (weeks or months), while the gap between (2) and (5) is typically very small: hours or days. This means that, once the attacker has moved into the actual exploitation phase, their window of opportunity to cause damage is pretty limited.&lt;/p&gt;
    &lt;p&gt;We can see this with numerous prominent supply chain attacks over the last 18 months3:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Attack&lt;/cell&gt;
        &lt;cell role="head"&gt;Approx. Window of Opportunity&lt;/cell&gt;
        &lt;cell role="head"&gt;References&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;xz-utils&lt;/cell&gt;
        &lt;cell&gt;â 5 weeks4&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ultralytics (phase 1)&lt;/cell&gt;
        &lt;cell&gt;12 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ultralytics (phase 2)&lt;/cell&gt;
        &lt;cell&gt;1 hour&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;tj-actions&lt;/cell&gt;
        &lt;cell&gt;3 days&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;chalk&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 12 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Nx&lt;/cell&gt;
        &lt;cell&gt;4 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;rspack&lt;/cell&gt;
        &lt;cell&gt;1 hour&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;num2words&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 12 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Kong Ingress Controller&lt;/cell&gt;
        &lt;cell&gt;â 10 days&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;web3.js&lt;/cell&gt;
        &lt;cell&gt;5 hours&lt;/cell&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;(Each of these attacks has significant downstream effect, of course, but only within their window of opportunity. Subsequent compromises from each, like Shai-Hulud, represent new windows of opportunity where the attackers regrouped and pivoted onto the next set of compromised credentials.)&lt;/p&gt;
    &lt;p&gt;My takeaway from this: some windows of opportunity are bigger, but the majority of them are under a week long. Consequently, ordinary developers can avoid the bulk of these types of attacks by instituting cooldowns on their dependencies.&lt;/p&gt;
    &lt;p&gt;A âcooldownâ is exactly what it sounds like: a window of time between when a dependency is published and when itâs considered suitable for use. The dependency is public during this window, meaning that âsupply chain securityâ vendors can work their magic while the rest of us wait any problems out.&lt;/p&gt;
    &lt;p&gt;I love cooldowns for several reasons:&lt;/p&gt;
    &lt;p&gt;Theyâre empirically effective, per above. They wonât stop all attackers, but they do stymie the majority of high-visibiity, mass-impact supply chain attacks that have become more common.&lt;/p&gt;
    &lt;p&gt;Theyâre incredibly easy to implement. Moreover, theyâre literally free to implement in most cases: most people can use Dependabotâs functionality, Renovateâs functionality, or the functionality build directly into their package manager5.&lt;/p&gt;
    &lt;p&gt;This is how simple it is in Dependabot:&lt;/p&gt;
    &lt;p&gt;(Rinse and repeat for other ecosystems as needed.)&lt;/p&gt;
    &lt;p&gt;Cooldowns enforce positive behavior from supply chain security vendors: vendors are still incentivized to discover and report attacks quickly, but are not as incentivized to emit volumes of blogspam about âcriticalâ attacks on largely underfunded open source ecosystems.&lt;/p&gt;
    &lt;p&gt;In the very small sample set above, 8/10 attacks had windows of opportunity of less than a week. Setting a cooldown of 7 days would have prevented the vast majority of these attacks from reaching end users (and causing knock-on attacks, which several of these were). Increasing the cooldown to 14 days would have prevented all but 1 of these attacks6.&lt;/p&gt;
    &lt;p&gt;Cooldowns are, obviously, not a panacea: some attackers will evade detection, and delaying the inclusion of potentially malicious dependencies by a week (or two) does not fundamentally alter the fact that supply chain security is a social trust problem, not a purely technical one. Still, an 80-90% reduction in exposure through a technique that is free and easy seems hard to beat.&lt;/p&gt;
    &lt;p&gt;Related to the above, itâs unfortunate that cooldowns arenât baked directly into more packaging ecosystems: Dependabot and Renovate are great, but even better would be if the package manager itself (as the source of ground truth) could enforce cooldowns directly (including of dependencies not introduced or bumped through automated flows).&lt;/p&gt;
    &lt;p&gt;The problem being, succinctly: modern software stacks are complex and opaque, with little to no difference in privilege between first-party code and third-party dependencies.Â ↩&lt;/p&gt;
    &lt;p&gt;In part because of the prevalence of long-lived, overscoped credentials. Long-lived credentials let attackers operate on their own (comfortable) timelines; this is why Trusted Publishing is such a useful (but not wholly sufficient) technique for reducing the attackerâs attack staging window.Â ↩&lt;/p&gt;
    &lt;p&gt;Filippo Valsorda has an excellent compilation of recent supply chain compromises here.Â ↩&lt;/p&gt;
    &lt;p&gt;The xz-utils attack is a significant outlier, both in its scope and the length of its window of opportunity. In this case, Iâve measured from the attackerâs first backdoored release (v5.6.0, 2024-02-24) to the time of rollback within Debian (2024-03-28).Â ↩&lt;/p&gt;
    &lt;p&gt;For example, pnpmâs &lt;code&gt;minimumReleaseAge&lt;/code&gt;.
           uv also has &lt;code&gt;exclude-newer&lt;/code&gt;, 
           although this specifies an absolute cutoff rather than a rolling cooldown.Â ↩&lt;/p&gt;
    &lt;p&gt;Notably, the only attack that would have stymied a 14-day cooldown is xz-utils, which is also the most technically, logistically, and socially advanced of all of the attacks.Â ↩&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns"/><published>2025-11-21T14:50:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46005349</id><title>XBMC 4.0 for the Original Xbox</title><updated>2025-11-22T02:20:09.854767+00:00</updated><content>&lt;doc fingerprint="3f9edd7dc8a4cddc"&gt;
  &lt;main&gt;
    &lt;p&gt;A Major Modernization of the Killer App That Started It All&lt;/p&gt;
    &lt;p&gt;A new version of Xbox Media Center (XBMC), version 4.0, has been released. This version marks a significant update to the long-standing media center platform for the Original Xbox. This marks the first major advancement to the software since 2016 and represents a renewed commitment to preserving, modernizing, and extending the capabilities of one of the most iconic console homebrew applications ever created.&lt;/p&gt;
    &lt;p&gt;XBMC has a long and influential history. In 2002, XboxMediaPlayer (XMP) was released and turned the console into a powerful multimedia device fit for the living room in an era when connecting a computer to a TV was quite novel. Later that same year, XMP merged with YAMP and became Xbox Media Player 2.0. A few years later, the software evolved into Xbox Media Center, or XBMC, which introduced a new interface, a plugin system powered by Python, and a robust skinning engine.&lt;/p&gt;
    &lt;p&gt;XBMC eventually became so capable that it outgrew the Xbox entirely. By 2007, developers were working on PC ports and in 2010, the project split into two branches: one for general computers while the Xbox version became XBMC4Xbox, and each codebase was maintained from then on by separate teams. XBMC was later renamed to Kodi in 2014 and continues to be one of the most popular media center applications available. Even Plex traces its roots back to XBMC. Plex began as OSXBMC, a Mac port of XBMC in late 2007, before becoming its own project in 2008. This means the Original Xbox helped shape not one but two of the biggest media center apps used today.&lt;/p&gt;
    &lt;p&gt;The last official release of XBMC4Xbox arrived in February 2016 with version 3.5.3. Although the community never declared the project dead, meaningful updates became scarce. XBMC 4.0 continues that legacy by bringing a modern interface, updating it to be more inline with Kodi's modern codebase, and backporting features to the original 64MB RAM / Pentium-III hardware where it all began.&lt;/p&gt;
    &lt;p&gt;This project is distinct and separate from XBMC4Gamers, the games-focused variation of XBMC4Xbox (v3.5.3) by developer Rocky5.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Modern Interface Powered by Estuary&lt;/head&gt;
    &lt;p&gt;One of the most notable advancements in XBMC 4.0 is the introduction of the Estuary user interface (skin).&lt;/p&gt;
    &lt;p&gt;Estuary, originally released in 2017 with Kodi v17 ("Krypton"), provides a clean and modern layout that improves navigation and readability over past skins. Bringing Estuary to the Xbox required extensive updates to the underlying GUI framework, including a port of the more contemporary GUIlib engine. This allows the platform to support modern skinning standards and makes future skin ports much more straightforward. After the initial work of porting GUIlib was done, porting Estuary to the Xbox was a relatively simple process of tweaking a handful of configuration files and adding contextual features specific to the Xbox. The result is a modern, intuitive front end that retains the performance and responsiveness required on legacy hardware.&lt;/p&gt;
    &lt;p&gt;Firing up an Xbox made in 2001 and being greeted by the same interface as what you'd find if you were to download Kodi today onto your PC feels like a bit of magic, and helps keep this beloved classic console relevant and useful well into the modern era.&lt;/p&gt;
    &lt;head rend="h2"&gt;Expanded Games Library Support&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 introduces a fully realized games library system. This enhancement brings the same level of metadata support found in the Movies and Music sections to Xbox and emulated games. Titles can now display artwork, descriptions, and other metadata, transforming the games section into a polished and user-friendly library. XBMC’s longstanding support for trainers remains intact, giving users the option to apply gameplay modifications for compatible titles. Emulated game collections benefit as well, with the ability to browse ROM libraries and launch them directly in a user’s preferred emulator.&lt;/p&gt;
    &lt;head rend="h2"&gt;Online Scrapers and Metadata Support&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 restores full functionality to metadata scrapers for movies and television. This allows users to build rich media libraries complete with artwork, plot summaries, cast listings, and other information retrieved directly from online sources. XBMC 4.0 handles these tasks efficiently, even on the Xbox’s limited memory and processing power. Video playback continues to support 480p and 720p content, enabling the console to serve as a surprisingly capable media device for its age. Similar to Kodi, XBMC 4.0 supports filtering, building playlists, watch progress history for media, and intelligent handling of TV shows with seasons.&lt;/p&gt;
    &lt;p&gt;Aside from scrapers for multimedia, support for rich library capabilities for games has also been added. XBMC has always been a media-first app, and now users can enjoy the library experience that they've come to love for media now in the context of their games library (more info below).&lt;/p&gt;
    &lt;head rend="h2"&gt;Improved Task Scheduling and Multitasking&lt;/head&gt;
    &lt;p&gt;Despite the constraints of the Xbox’s single-threaded 733MHz CPU, XBMC 4.0 includes improvements to task scheduling that allow multiple activities to run concurrently. Background library updates, metadata scraping, and audio/video playback can occur while users navigate and use other parts of the interface. These optimizations help ensure a fluid experience without compromising performance. Much work has been done "under the hood" to keep XBMC on task and within memory budgets while achieving multi-tasking on a console that wasn't exactly designed with it in mind. Users who own RAM and/or CPU upgraded consoles can also take advantage of the extra overhead, as XBMC 4.0 makes use of the extra horsepower for an even smoother experience. Utilizing an SSD with higher UDMA speeds will also yield an improvement in overall responsiveness.&lt;/p&gt;
    &lt;head rend="h2"&gt;Music Experience and Visualizers&lt;/head&gt;
    &lt;p&gt;Music playback has always been a strong element of XBMC, and version 4.0 maintains that focus. The Original Xbox is capable of high quality audio output, and XBMC continues to support lossless codecs such as FLAC. The release includes compatibility with various audio visualizers, including MilkDrop, which remains one of the most visually impressive and customizable audio visualization engines available. These features allow XBMC 4.0 to function not only as a media organizer, but also as an immersive audio display system.&lt;/p&gt;
    &lt;p&gt;An online repository has been established and will be maintained moving forward where users can download legacy and newly-released add-ons as they become available. This repository is accessible without additional setup, right out of the box!&lt;/p&gt;
    &lt;head rend="h2"&gt;Add-ons and Python Support&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 continues to offer an extendable architecture powered by Python-based add-ons. While the current release uses Python 2.7 for compatibility, work is underway to transition to Python 3.4.10 in the future, which may provide a path for backporting many newer Kodi add-ons. Even in its current state, XBMC 4.0 already supports a variety of community-developed add-ons that extend the system’s functionality, including tools for online video playback (i.e. YouTube), online weather services, and enhanced media organization.&lt;/p&gt;
    &lt;head rend="h2"&gt;Updated Settings, Network Services, and System Tools&lt;/head&gt;
    &lt;p&gt;The settings interface has been revised to provide more clarity and control. The update includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Playback options, including episode progression, crossfade behavior, and subtitle handling&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Library management tools&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Network features, such as SMB, FTP, UPnP sharing, web server access, and Insignia-compatible DNS options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Comprehensive interface customization options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multiple user profiles with individual library settings&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Advanced system controls for video calibration, display modes, input devices, and power management&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A robust System Information section for diagnostics, with info geared towards the Original Xbox&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A flexible File Manager with support for network protocols including FTP, SMB, WebDAV, and more&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Users may also take advantage of an online add-ons repository, offering the same experience modern Kodi provides with being able to download add-ons to extend functionality of the app with things like online multimedia providers, weather, skins, visualizers, and more. Developers can submit new add-ons to the official repository via Github.&lt;/p&gt;
    &lt;head rend="h2"&gt;Continuing the Legacy&lt;/head&gt;
    &lt;p&gt;XBMC has been a staple of the Original Xbox's homebrew scene since its inception in the early 2000's. This new update is a revival of the platform that helped shape the landscape of home media software and helps revitalize a codebase that has been somewhat stagnant for many years. This release honors that heritage while modernizing the experience for a new generation of enthusiasts and preserving the functionality of the Original Xbox as a versatile and capable media center.&lt;/p&gt;
    &lt;p&gt;Although the hardware is decades old, the renewed effort behind XBMC 4.0 demonstrates that the platform still has room to grow and tricks up its sleeve. With ongoing development and a codebase designed with modern Kodi compatibility in mind, XBMC 4.0 represents a significant step forward into the continued development on the Original Xbox.&lt;/p&gt;
    &lt;p&gt;The development team looks forward to continuing this work and expanding the possibilities of the Original Xbox for years to come. This version is the first of many to come, with lots of things cooking in the background. Keep an eye out for future releases by joining the Xbox-Scene Discord and turning on notifications in the xbmc-news channel or by periodically checking the project's Github page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Downloads&lt;/head&gt;
    &lt;p&gt;XBMC 4.0 (and subsequent releases) builds along with source code are available via Github:&lt;/p&gt;
    &lt;p&gt;Main project page: Click Here&lt;/p&gt;
    &lt;p&gt;Note: XBMC 4.0 is is in active development! This means updates will be released in a more frequent manner for the time being until things settle down. Check the nightly builds section on Github for the most up-to-date version.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;XBMC is open source software and welcomes contributions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Coding: Developers can help XBMC by fixing a bug, adding new features, making our technology smaller and faster and making development easier for others. XBMC's codebase consists mainly of C++ with small parts written in a variety of coding languages. Our add-ons mainly consist of python and XML.&lt;/item&gt;
      &lt;item&gt;Helping users: Our support process relies on enthusiastic contributors like you to help others get the most out of XBMC. The #1 priority is always answering questions in our support forums. Everyday new people discover XBMC, and everyday they are virtually guaranteed to have questions.&lt;/item&gt;
      &lt;item&gt;Localization: Translate XBMC, add-ons, skins etc. into your native language.&lt;/item&gt;
      &lt;item&gt;Add-ons: Add-ons are what make XBMC the most extensible and customizable entertainment hub available. Get started building an add-on.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Support and Bug Reporting&lt;/head&gt;
    &lt;p&gt;Need help?&lt;/p&gt;
    &lt;p&gt;Support can be found in the XBMC -&amp;gt; General channel within the Xbox-Scene Discord server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Credits and Disclaimers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nikola Antonić - Primary Developer, Project Lead&lt;/item&gt;
      &lt;item&gt;astarivi - Contributor (cURL, wolfSSL), Tester, Debugger&lt;/item&gt;
      &lt;item&gt;EqUiNoX - Contrubitor, Tester&lt;/item&gt;
      &lt;item&gt;Rocky5 - Contributor, Tester&lt;/item&gt;
      &lt;item&gt;.lavenderStarlight+ - Add-ons / Skins Development, Tester&lt;/item&gt;
      &lt;item&gt;GoTeamScotch - Tester, Feedback&lt;/item&gt;
      &lt;item&gt;Haguero - Tester, Feedback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;XBMC is GPLv2 licensed. You may use, distribute and copy it under the license terms. XBMC is licensed under the same terms as Kodi. For detailed information on the licensing, please refer to the Kodi license.&lt;/p&gt;
    &lt;p&gt;This project, XBMC version 4.0 (and upcoming releases), is distinct from and is not affiliated with Team Kodi of The Kodi Foundation, or its members.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.xbox-scene.info/articles/announcing-xbmc-40-for-the-original-xbox-r64/"/><published>2025-11-21T15:18:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46005553</id><title>Arduino published updated terms and conditions: no longer an open commons</title><updated>2025-11-22T02:20:09.345564+00:00</updated><content>&lt;doc fingerprint="b470b35817f47bba"&gt;
  &lt;main&gt;
    &lt;p&gt;Six weeks ago, Qualcomm acquired Arduino. The maker community immediately worried that Qualcomm would kill the open-source ethos that made Arduino the lingua franca of hobby electronics.&lt;/p&gt;
    &lt;p&gt;This week, Arduino published updated terms and conditions and a new privacy policy, clearly rewritten by Qualcomm’s lawyers. The changes confirm the community’s worst fears: Arduino is no longer an open commons. It’s becoming just another corporate platform.&lt;/p&gt;
    &lt;p&gt;Here’s what’s at stake, what Qualcomm got wrong, and what might still be salvaged, drawing from community discussions across maker forums and sites.&lt;/p&gt;
    &lt;p&gt;What changed?&lt;lb/&gt;The new terms read like standard corporate boilerplate: mandatory arbitration, data integration with Qualcomm’s global ecosystem, export controls, AI use restrictions. For any other SaaS platform, this would be unremarkable.&lt;/p&gt;
    &lt;p&gt;But Arduino isn’t SaaS. It’s the foundation of the maker ecosystem.&lt;/p&gt;
    &lt;p&gt;The most dangerous change is Arduino now explicitly states that using their platform grants you no patent licenses whatsoever. You can’t even argue one is implied.&lt;/p&gt;
    &lt;p&gt;This means Qualcomm could potentially assert patents against your projects if you built them using Arduino tools, Arduino examples, or Arduino-compatible hardware.&lt;/p&gt;
    &lt;p&gt;And here’s the disconnect, baffling makers. Arduino’s IDE is licensed under AGPL. Their CLI is GPL v3. Both licenses explicitly require that you can reverse engineer the software. But the new Qualcomm terms explicitly forbid reverse engineering “the Platform.”&lt;/p&gt;
    &lt;p&gt;What’s really going on?&lt;lb/&gt;The community is trying to figure out what is Qualcomm’s actual intent. Are these terms just bad lawyering with SaaS lawyers applying their standard template to cloud services, not realizing Arduino is different? Or is Qualcomm testing how much they can get away with before the community revolts? Or is this a first step toward locking down the ecosystem they just bought?&lt;/p&gt;
    &lt;p&gt;Some people point out that “the Platform” might only mean Arduino’s cloud services (forums, Arduino Cloud, Project Hub) not the IDE and CLI that everyone actually uses.&lt;/p&gt;
    &lt;p&gt;If that’s true, Qualcomm needs to say so, explicitly, and in plain language. Because library maintainers are likely wondering whether contributing to Arduino repos puts them at legal risk. And hardware makers are questioning whether “Arduino-compatible” is still safe to advertise.&lt;/p&gt;
    &lt;p&gt;Why Adafruit’s alarm matters&lt;lb/&gt;Adafruit has been vocal about the dangers of this acquisition. Some dismiss Adafruit’s criticism as self-serving. After all, they sell competing hardware and promote CircuitPython. But that misses who Adafruit is.&lt;/p&gt;
    &lt;p&gt;Adafruit has been the moral authority on open hardware for decades. They’ve made their living proving you can build a successful business on open principles. When they sound the alarm, it’s not about competition, it’s about principle.&lt;/p&gt;
    &lt;p&gt;What they’re calling out isn’t that Qualcomm bought Arduino. It’s that Qualcomm’s lawyers fundamentally don’t understand what they bought. Arduino wasn’t valuable because it was just a microcontroller company. It was valuable because it was a commons. And you can’t apply enterprise legal frameworks to a commons without destroying it.&lt;/p&gt;
    &lt;p&gt;Adafruit gets this. They’ve built their entire business on this. That’s why their criticism carries weight.&lt;/p&gt;
    &lt;p&gt;What Qualcomm doesn’t seem to understand&lt;lb/&gt;Qualcomm probably thought they were buying an IoT hardware company with a loyal user base. &lt;/p&gt;
    &lt;p&gt;They weren’t. They bought the IBM PC of the maker world.&lt;/p&gt;
    &lt;p&gt;Arduino’s value was never just the hardware. Their boards have been obsolete for years. Their value is the standard.&lt;/p&gt;
    &lt;p&gt;The Arduino IDE is the lingua franca of hobby electronics.&lt;/p&gt;
    &lt;p&gt;Millions of makers learned on it, even if they moved to other hardware. ESP32, STM32, Teensy, Raspberry Pi Pico – none of them are Arduino hardware, but they all work with the Arduino IDE.&lt;/p&gt;
    &lt;p&gt;Thousands of libraries are “Arduino libraries.” Tutorials assume Arduino. University curricula teach Arduino. When you search “how to read a sensor,” the answer comes back in Arduino code.&lt;/p&gt;
    &lt;p&gt;This is the ecosystem Qualcomm’s lawyers just dropped legal uncertainty onto.&lt;/p&gt;
    &lt;p&gt;If Qualcomm’s lawyers start asserting control over the IDE, CLI, or core libraries under restrictive terms, they will poison the entire maker ecosystem. Even people who never buy Arduino hardware are dependent on Arduino software infrastructure.&lt;/p&gt;
    &lt;p&gt;Qualcomm didn’t just buy a company. They bought a commons. And now they inadvertently are taking steps that are destroying what made it valuable.&lt;/p&gt;
    &lt;p&gt;What are makers supposed to do?&lt;lb/&gt;There has been some buzz of folks just leaving the Arduino environment behind. But Arduino IDE alternatives such as PlatformIO and VSCode are not in any way beginner friendly. If the Arduino IDE goes, then there’s a huge problem. &lt;/p&gt;
    &lt;p&gt;I remember when Hypercard ended. There were alternatives, but none so easy. I don’t think I really coded again for almost 20 years until I picked up the Arduino IDE (go figure).&lt;/p&gt;
    &lt;p&gt;If something happens to the Arduino IDE, even if its development stalls or becomes encumbered, there’s no replacement for that easy onboarding. We’d lose many promising new makers because the first step became too steep.&lt;/p&gt;
    &lt;p&gt;The institutional knowledge at risk&lt;lb/&gt;But leaving Arduino behind isn’t simple. The platform’s success depends on two decades of accumulated knowledge, such as countless Arduino tutorials on YouTube, blogs, and school curricula; open-source libraries that depend on Arduino compatibility; projects in production using Arduino tooling; and university programs built around Arduino as the teaching platform&lt;/p&gt;
    &lt;p&gt;All of these depend on Arduino remaining open and accessible.&lt;/p&gt;
    &lt;p&gt;If Qualcomm decided to sunset the open Arduino IDE in favor of a locked-down “Arduino Pro” platform, or if they start asserting patent claims, or if uncertainty makes contributors abandon the ecosystem, all that knowledge becomes stranded.&lt;/p&gt;
    &lt;p&gt;It’s like Wikipedia going behind a paywall. The value isn’t just the content, it is the trust that it remains accessible. Arduino’s value isn’t just the code, it’s the trust that the commons would stay open.&lt;/p&gt;
    &lt;p&gt;That trust is now gone. And once lost, it hard to get back.&lt;/p&gt;
    &lt;p&gt;Why this happened (but doesn’t excuse it)&lt;lb/&gt;Let’s be fair to Qualcomm, their lawyers were doing their jobs.&lt;/p&gt;
    &lt;p&gt;When you acquire a company, you standardize the legal terms; add mandatory arbitration to limit class action exposure; integrate data systems for compliance and auditing; add export controls because you sell to defense contractors; prohibit reverse engineering because that’s in the template.&lt;/p&gt;
    &lt;p&gt;For most acquisitions, this is just good corporate hygiene. And Arduino, now part of a megacorp, faces higher liabilities than it did as an independent entity.&lt;/p&gt;
    &lt;p&gt;But here’s what Qualcomm’s lawyers missed: Arduino isn’t a normal acquisition. The community isn’t a customer base, it’s a commons. And you can’t apply enterprise SaaS legal frameworks to a commons without destroying what made it valuable.&lt;/p&gt;
    &lt;p&gt;This is tone-deafness, not malice. But the outcome is the same. A community that trusted Arduino no longer does.&lt;/p&gt;
    &lt;p&gt;Understanding why this happened doesn’t excuse it, but it might suggest what needs to happen next.&lt;/p&gt;
    &lt;p&gt;What should have happened and how to still save it&lt;lb/&gt;Qualcomm dropped legal boilerplate on the community with zero context and let people discover the contradictions themselves. That’s how you destroy trust overnight.&lt;/p&gt;
    &lt;p&gt;Qualcomm should have announced the changes in advance. They should have given the community weeks, not hours, to understand what’s changing and why. They should have used plain-language explanations, not just legal documents.&lt;/p&gt;
    &lt;p&gt;Qualcomm can fix things by explicitly carving out the open ecosystem. They should state clearly that the terms apply to Arduino Cloud services, and the IDE, CLI, and core libraries remain under their existing open source licenses.&lt;/p&gt;
    &lt;p&gt;We’d need concrete commitments, such as which repos stay open, which licenses won’t change, what’s protected from future acquisition decisions. Right now we have vague corporate-speak about “supporting the community.”&lt;/p&gt;
    &lt;p&gt;Indeed, they could create some structural protection, as well, by putting IDE, CLI, and core libraries in a foundation that Qualcomm couldn’t unilaterally control (think the Linux Foundation model).&lt;/p&gt;
    &lt;p&gt;Finally, Qualcomm might wish to establish some form of community governance with real representation and real power over the tools the community depends on.&lt;/p&gt;
    &lt;p&gt;The acquisition is done. The legal integration is probably inevitable. But how it’s done determines whether Arduino survives as a commons or dies as just another Qualcomm subsidiary.&lt;/p&gt;
    &lt;p&gt;What’s next?&lt;lb/&gt;Arduino may be the toolset that made hobby electronics accessible to millions. But that maker community built Arduino into what it became. Qualcomm’s acquisition has thrown that legacy into doubt. Whether through legal confusion, corporate tone-deafness, or deliberate strategy, the community’s trust is broken.&lt;/p&gt;
    &lt;p&gt;The next few months will reveal whether this was a stumble or a strategy. If Qualcomm issues clarifications, moves repos to some sort of governance, and explicitly protects the open toolchain, then maybe this is salvageable. If they stay silent, or worse, if IDE development slows or license terms tighten further, then that’s a signal to find alternatives.&lt;/p&gt;
    &lt;p&gt;The question isn’t whether the open hobby electronics maker community survives. It’s whether Arduino does.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.molecularist.com/2025/11/did-qualcomm-kill-arduino-for-good.html"/><published>2025-11-21T15:44:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46006016</id><title>Show HN: Wealthfolio 2.0- Open source investment tracker. Now Mobile and Docker</title><updated>2025-11-22T02:20:09.167365+00:00</updated><content>&lt;doc fingerprint="27ab40bb69b94b92"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Grow Wealth. Keep Control.&lt;/head&gt;
    &lt;head rend="h2"&gt;A beautiful, Private and Open-Source investment tracker that runs locally on all your devices.&lt;/head&gt;
    &lt;head rend="h2"&gt;WHY CHOOSE WEALTHFOLIO?&lt;/head&gt;
    &lt;p&gt;A beautiful portfolio tracker that respects your privacy and your data&lt;/p&gt;
    &lt;head rend="h3"&gt;Privacy-First Approach&lt;/head&gt;
    &lt;p&gt;Your data never leaves your device. As an open-source project, we prioritize security and transparency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simple and Beautifully Crafted&lt;/head&gt;
    &lt;p&gt;Powerful features wrapped in an elegant, easy-to-use interface. Simplicity meets sophistication.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Hidden Costs&lt;/head&gt;
    &lt;p&gt;Free to use with optional one-time payment. No subscriptions or recurring fees.&lt;/p&gt;
    &lt;head rend="h2"&gt;THE ESSENTIALS YOU NEED TO TRACK YOUR WEALTH&lt;/head&gt;
    &lt;p&gt;No More Messy Spreadsheets or Privacy Concerns - Just You and Your Secure, Personal Wealth Companion Application&lt;/p&gt;
    &lt;head rend="h3"&gt;Accounts Aggregation&lt;/head&gt;
    &lt;p&gt;Gather all your investment and savings accounts in one place. See everything at a glance, from stocks to savings! Import your CSV statements from your broker or bank.&lt;/p&gt;
    &lt;head rend="h4"&gt;Comprehensive View&lt;/head&gt;
    &lt;p&gt;See all your accounts in one place.&lt;/p&gt;
    &lt;head rend="h4"&gt;CSV Import&lt;/head&gt;
    &lt;p&gt;Easily import your CSV statements.&lt;/p&gt;
    &lt;head rend="h3"&gt;Holdings Overview&lt;/head&gt;
    &lt;p&gt;Get a clear picture of what's in your portfolio. Stocks, ETFs, or Cryptocurrencies - know what you have and how it's performing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Portfolio Insights&lt;/head&gt;
    &lt;p&gt;Understand your asset allocation.&lt;/p&gt;
    &lt;head rend="h4"&gt;Performance Tracking&lt;/head&gt;
    &lt;p&gt;Monitor how your investments are doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance Dashboard&lt;/head&gt;
    &lt;p&gt;See how your investments stack up, all in one place. Compare your accounts side by side, check if you are beating the S&amp;amp;P 500, and track your favorite ETFs without the hassle. No fancy jargon - just clear, useful charts that help you understand how your money is really doing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Compare Your Accounts&lt;/head&gt;
    &lt;p&gt;See which accounts are doing best.&lt;/p&gt;
    &lt;head rend="h4"&gt;Beat the Market?&lt;/head&gt;
    &lt;p&gt;Check how you stack up against some popular indexes and ETFs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Income Tracking&lt;/head&gt;
    &lt;p&gt;Monitor dividends and interest income across your entire portfolio. Get a clear view of your passive income streams, helping you make informed decisions about your investments.&lt;/p&gt;
    &lt;head rend="h4"&gt;Dividend Monitoring&lt;/head&gt;
    &lt;p&gt;Track your dividend income.&lt;/p&gt;
    &lt;head rend="h4"&gt;Interest Income&lt;/head&gt;
    &lt;p&gt;Keep an eye on interest earnings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Accounts Performance&lt;/head&gt;
    &lt;p&gt;Track your accounts' holdings and performance over time. See how a particular account is performing, and how it's changing over time.&lt;/p&gt;
    &lt;head rend="h4"&gt;Historical Data&lt;/head&gt;
    &lt;p&gt;View past performance trends.&lt;/p&gt;
    &lt;head rend="h4"&gt;Account Analysis&lt;/head&gt;
    &lt;p&gt;Analyze individual account performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Goals Tracking&lt;/head&gt;
    &lt;p&gt;Set your savings targets clearly. Distribute your funds across these objectives, assigning a specific percentage to each. Keep an eye on your progress.&lt;/p&gt;
    &lt;head rend="h4"&gt;Target Setting&lt;/head&gt;
    &lt;p&gt;Define your financial goals.&lt;/p&gt;
    &lt;head rend="h4"&gt;Progress Monitoring&lt;/head&gt;
    &lt;p&gt;Track your progress towards goals.&lt;/p&gt;
    &lt;head rend="h3"&gt;Contribution Rooms and Limit Tracking&lt;/head&gt;
    &lt;p&gt;Stay on top of your contribution limits for tax-advantaged accounts like IRAs, 401(k)s, or TFSAs. Track your available contribution room and avoid over-contributing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Limit Awareness&lt;/head&gt;
    &lt;p&gt;Know your contribution limits.&lt;/p&gt;
    &lt;head rend="h4"&gt;Avoid Over-Contribution&lt;/head&gt;
    &lt;p&gt;Prevent excess contributions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extend Wealthfolio with Powerful Add-ons&lt;/head&gt;
    &lt;head rend="h3"&gt;Investment Fees Tracker&lt;/head&gt;
    &lt;p&gt;Track and analyze investment fees across your portfolio with detailed analytics and insights&lt;/p&gt;
    &lt;head rend="h3"&gt;Goal Progress Tracker&lt;/head&gt;
    &lt;p&gt;Track your investment progress towards target amounts with a visual representation&lt;/p&gt;
    &lt;head rend="h3"&gt;Stock Trading Tracker&lt;/head&gt;
    &lt;p&gt;Simple swing stock trading tracker with performance analytics and calendar views&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wealthfolio.app/?v=2.0"/><published>2025-11-21T16:34:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46006082</id><title>You can make PS2 games in JavaScript</title><updated>2025-11-22T02:20:09.106313+00:00</updated><content/><link href="https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript"/><published>2025-11-21T16:42:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46006250</id><title>Pivot Robotics (YC W24) Is Hiring for an Industrial Automation Hardware Engineer</title><updated>2025-11-22T02:20:08.737154+00:00</updated><content>&lt;doc fingerprint="6e34f445ca77fde2"&gt;
  &lt;main&gt;
    &lt;p&gt;AI for Robot Arms in Factories&lt;/p&gt;
    &lt;p&gt;Responsibilities&lt;/p&gt;
    &lt;p&gt;Qualifications&lt;/p&gt;
    &lt;p&gt;Pivot Robots (YC W24) is building the AI brain for robot arms for high-mix manufacturing.&lt;/p&gt;
    &lt;p&gt;Pivot Robots combines off-the-shelf robots and vision sensors with recent breakthroughs in foundation vision models to give industrial robot arms the power to adapt. Our first product directly addresses the dangerous and unpopular task of grinding metal parts. Currently, our software is being deployed on 10+ robots at a large cast iron foundry.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/pivot-robotics/jobs/7xG9Dc6-mechanical-engineer-controls"/><published>2025-11-21T17:00:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46006598</id><title>Solving Fizz Buzz with Cosines</title><updated>2025-11-22T02:20:04.140283+00:00</updated><content>&lt;doc fingerprint="12d799356860faa5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Solving Fizz Buzz with Cosines&lt;/head&gt;
    &lt;p&gt;Fizz Buzz is a counting game that has become oddly popular in the world of computer programming as a simple test of basic programming skills. The rules of the game are straightforward. Players say the numbers aloud in order beginning with one. Whenever a number is divisible by 3, they say 'Fizz' instead. If it is divisible by 5, they say 'Buzz'. If it is divisible by both 3 and 5, the player says both 'Fizz' and 'Buzz'. Here is a typical Python program that prints this sequence:&lt;/p&gt;
    &lt;code&gt;for n in range(1, 101):
    if n % 15 == 0:
        print('FizzBuzz')
    elif n % 3 == 0:
        print('Fizz')
    elif n % 5 == 0:
        print('Buzz')
    else:
        print(n)
&lt;/code&gt;
    &lt;p&gt;Here is the output: fizz-buzz.txt. Can we make the program more complicated? Perhaps we can use trigonometric functions to encode all four cases in a single closed-form expression. That is what we are going to explore in this article. By the end, we will obtain a finite Fourier series that can take any integer \( n \) and select the text to be printed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;head rend="h2"&gt;Definitions&lt;/head&gt;
    &lt;p&gt;Before going any further, we establish a precise mathematical definition for the Fizz Buzz sequence. We begin by introducing a few functions that will help us define the Fizz Buzz sequence later.&lt;/p&gt;
    &lt;head rend="h3"&gt;Symbol Functions&lt;/head&gt;
    &lt;p&gt;We define a set of four functions \( \{ s_0, s_1, s_2, s_3 \} \) for integers \( n \) by: \begin{align*} s_0(n) &amp;amp;= n, \\ s_1(n) &amp;amp;= \mathtt{Fizz}, \\ s_2(n) &amp;amp;= \mathtt{Buzz}, \\ s_3(n) &amp;amp;= \mathtt{FizzBuzz}. \end{align*} We call these the symbol functions because they produce every term that appears in the Fizz Buzz sequence. The symbol function \( s_0 \) returns \( n \) itself. The functions \( s_1, \) \( s_2 \) and \( s_3 \) are constant functions that always return the literal words \( \mathtt{Fizz}, \) \( \mathtt{Buzz} \) and \( \mathtt{FizzBuzz} \) respectively, no matter what the value of \( n \) is.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fizz Buzz Sequence&lt;/head&gt;
    &lt;p&gt;Now we can define the Fizz Buzz sequence as the sequence \[ (s_{f(n)}(n))_{n = 1}^{\infty} \] where \[ f(n) = \begin{cases} 1 &amp;amp; \text{if } 3 \mid n \text{ and } 5 \nmid n, \\ 2 &amp;amp; \text{if } 3 \nmid n \text{ and } 5 \mid n, \\ 3 &amp;amp; \text{if } 3 \mid n \text{ and } 5 \mid n, \\ 0 &amp;amp; \text{otherwise}. \end{cases} \] The notation \( m \mid n \) means that the integer \( m \) divides the integer \( n, \) i.e. \( n \) is a multiple of \( m. \) Equivalently, there exists an integer \( c \) such that \( n = cm . \) Similarly, \( m \nmid n \) means that \( m \) does not divide \( n, \) i.e. \( n \) is not a multiple of \( m. \) With the above definitions in place, we can expand the first few terms of the sequence explicitly as follows: \begin{align*} (s_{f(n)}(n))_{n = 1}^{\infty} &amp;amp;= (s_{f(1)}(1), \; s_{f(2)}(2), \; s_{f(3)}(3), \; s_{f(4)}(4), \; s_{f(5)}(5), \; s_{f(6)}(6), \; s_{f(7)}(7), \; \dots) \\ &amp;amp;= (s_0(1), \; s_0(2), \; s_1(3), \; s_0(4), s_2(5), \; s_1(6), \; s_0(7), \; \dots) \\ &amp;amp;= (1, \; 2, \; \mathtt{Fizz}, \; 4, \; \mathtt{Buzz}, \; \mathtt{Fizz}, \; 7, \; \dots). \end{align*} Note how the function \( f(n) \) produces an index \( i \) which we then use to select the symbol function \( s_i(n) \) to produce the \( n \)th term of the sequence. We therefore call \( f(n) \) the index function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Indicator Functions&lt;/head&gt;
    &lt;p&gt;Here is the index function \( f(n) \) from the previous section with its cases and conditions rearranged to make it easier to spot interesting patterns: \[ f(n) = \begin{cases} 0 &amp;amp; \text{if } 5 \nmid n \text{ and } 3 \nmid n, \\ 1 &amp;amp; \text{if } 5 \nmid n \text{ and } 3 \mid n, \\ 2 &amp;amp; \text{if } 5 \mid n \text{ and } 3 \nmid n, \\ 3 &amp;amp; \text{if } 5 \mid n \text{ and } 3 \mid n. \end{cases} \] This function helps us to select another function \( s_{f(n)}(n) \) which in turn determines the \( n \)th term of the Fizz Buzz sequence. Our goal now is to replace this piecewise formula with a single closed-form expression. To do so, we first define indicator functions \( I_m(n) \) as follows: \[ I_m(n) = \begin{cases} 1 &amp;amp; \text{if } m \mid n, \\ 0 &amp;amp; \text{if } m \nmid n. \end{cases} \] The formula for \( f(n) \) can now be written as: \[ f(n) = \begin{cases} 0 &amp;amp; \text{if } I_5(n) = 0 \text{ and } I_3(n) = 0, \\ 1 &amp;amp; \text{if } I_5(n) = 0 \text{ and } I_3(n) = 1, \\ 2 &amp;amp; \text{if } I_5(n) = 1 \text{ and } I_3(n) = 0, \\ 3 &amp;amp; \text{if } I_5(n) = 1 \text{ and } I_3(n) = 1. \end{cases} \] Do you see a pattern? Here is the same function written as a table:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;\( I_5(n) \)&lt;/cell&gt;
        &lt;cell role="head"&gt;\( I_3(n) \)&lt;/cell&gt;
        &lt;cell role="head"&gt;\( f(n) \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 0 \)&lt;/cell&gt;
        &lt;cell&gt;\( 2 \)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 1 \)&lt;/cell&gt;
        &lt;cell&gt;\( 3 \)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Do you see it now? If we treat the values in the first two columns as binary digits and the values in the third column as decimal numbers, then in each row the first two columns give the binary representation of the number in the third column. For example, \( 3_{10} = 11_2 \) and indeed in the last row of the table, we see the bits \( 1 \) and \( 1 \) in the first two columns and the number \( 3 \) in the last column. In other words, writing the binary digits \( I_5(n) \) and \( I_3(n) \) side by side gives us the binary representation of \( f(n). \) Therefore \[ f(n) = 2 \, I_5(n) + I_3(n). \] We can now write a small program to demonstrate this formula:&lt;/p&gt;
    &lt;code&gt;
 for n in range(1, 101):
    s = [n, 'Fizz', 'Buzz', 'FizzBuzz']
    i = (n % 3 == 0) + 2 * (n % 5 == 0)
    print(s[i])
&lt;/code&gt;
    &lt;p&gt;We can make it even shorter at the cost of some clarity:&lt;/p&gt;
    &lt;code&gt;
 for n in range(1, 101):
    print([n, 'Fizz', 'Buzz', 'FizzBuzz'][(n % 3 == 0) + 2 * (n % 5 == 0)])
&lt;/code&gt;
    &lt;p&gt;What we have obtained so far is pretty good. While there is no universal definition of a closed-form expression, I think most people would agree that the indicator functions as defined above are simple enough to be permitted in a closed-form expression.&lt;/p&gt;
    &lt;head rend="h2"&gt;Complex Exponentials&lt;/head&gt;
    &lt;p&gt;In the previous section, we obtained the formula \[ f(n) = I_3(n) + 2 \, I_5(n) \] which we then used as an index to look up the text to be printed. We also argued that this is a pretty good closed-form expression already.&lt;/p&gt;
    &lt;p&gt;However, in the interest of making things more complicated, we must ask ourselves: What if we are not allowed to use the indicator functions? What if we must adhere to the commonly accepted meaning of a closed-form expression which allows only finite combinations of basic operations such as addition, subtraction, multiplication, division, integer exponents and roots with integer index as well as functions such as exponentials, logarithms and trigonometric functions. It turns out that the above formula can be rewritten using only addition, multiplication, division and the cosine function. Let us begin the translation. Consider the sum \[ S_m(n) = \sum_{k = 0}^{m - 1} e^{2 \pi i k n / m}, \] where \( i \) is the imaginary unit and \( n \) and \( m \) are integers. This is a geometric series in the complex plane with ratio \( r = e^{2 \pi i n / m}. \) If \( n \) is a multiple of \( m , \) then \( n = cm \) for some integer \( c \) and we get \[ r = e^{2 \pi i n / m} = e^{2 \pi i c} = 1. \] Therefore, when \( n \) is a multiple of \( m, \) we get \[ S_m(n) = \sum_{k = 0}^{m - 1} e^{2 \pi i k n / m} = \sum_{k = 0}^{m - 1} 1^k = m. \] If \( n \) is not a multiple of \( m, \) then \( r \ne 1 \) and the geometric series becomes \[ S_m(n) = \frac{r^m - 1}{r - 1} = \frac{e^{2 \pi i n} - 1}{e^{2 \pi i n / m} - 1} = 0. \] Therefore, \[ S_m(n) = \begin{cases} m &amp;amp; \text{if } m \mid n, \\ 0 &amp;amp; \text{if } m \nmid n. \end{cases} \] Dividing both sides by \( m, \) we get \[ \frac{S_m(n)}{m} = \begin{cases} 1 &amp;amp; \text{if } m \mid n, \\ 0 &amp;amp; \text{if } m \nmid n. \end{cases} \] But the right-hand side is \( I_m(n). \) Therefore \[ I_m(n) = \frac{S_m(n)}{m} = \frac{1}{m} \sum_{k = 0}^{m - 1} e^{2 \pi i k n / m}. \]&lt;/p&gt;
    &lt;head rend="h2"&gt;Cosines&lt;/head&gt;
    &lt;p&gt;We begin with Euler's formula \[ e^{i x} = \cos x + i \sin x \] where \( x \) is a real number. From this formula, we get \[ e^{i x} + e^{-i x} = 2 \cos x. \] Therefore \begin{align*} I_3(n) &amp;amp;= \frac{1}{3} \sum_{k = 0}^2 e^{2 \pi i k n / 3} \\ &amp;amp;= \frac{1}{3} \left( 1 + e^{2 \pi i n / 3} + e^{4 \pi i n / 3} \right) \\ &amp;amp;= \frac{1}{3} \left( 1 + e^{2 \pi i n / 3} + e^{-2 \pi i n / 3} \right) \\ &amp;amp;= \frac{1}{3} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right). \end{align*} The third equality above follows from the fact that \( e^{4 \pi i n / 3} = e^{6 \pi i n / 3} e^{-2 \pi i n / 3} = e^{2 \pi i n} e^{-2 \pi i n/3} = e^{-2 \pi i n / 3}. \)&lt;/p&gt;
    &lt;p&gt;The function above is defined for integer values of \( n \) but we can extend its formula to real \( x \) and plot it to observe its shape between integers. As expected, the function takes the value \( 1 \) whenever \( x \) is an integer multiple of \( 3 \) and \( 0 \) whenever \( x \) is an integer not divisible by \( 3. \)&lt;/p&gt;
    &lt;p&gt;Similarly, \begin{align*} I_5(n) &amp;amp;= \frac{1}{5} \sum_{k = 0}^4 e^{2 \pi i k n / 5} \\ &amp;amp;= \frac{1}{5} \left( 1 + e^{2 \pi i n / 5} + e^{4 \pi i n / 5} + e^{6 \pi i n / 5} + e^{8 \pi i n / 5} \right) \\ &amp;amp;= \frac{1}{5} \left( 1 + e^{2 \pi i n / 5} + e^{4 \pi i n / 5} + e^{-4 \pi i n / 5} + e^{-2 \pi i n / 5} \right) \\ &amp;amp;= \frac{1}{5} + \frac{2}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{2}{5} \cos \left( \frac{4 \pi n}{5} \right). \end{align*} Extending this expression to real values of \( x \) allows us to plot its shape as well. Once again, the function takes the value \( 1 \) at integer multiples of \( 5 \) and \( 0 \) at integers not divisible by \( 5. \)&lt;/p&gt;
    &lt;p&gt;Recall that we expressed \( f(n) \) as \[ f(n) = I_3(n) + 2 \, I_5(n). \] Substituting these trigonometric expressions yields \[ f(n) = \frac{1}{3} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) + 2 \cdot \left( \frac{1}{5} + \frac{2}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{2}{5} \cos \left( \frac{4 \pi n}{5} \right) \right). \] A straightforward simplification gives \[ f(n) = \frac{11}{15} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right). \] We can extend this expression to real \( x \) and plot it as well. The resulting curve takes the values \( 0, 1, 2 \) and \( 3 \) at integer points, as desired.&lt;/p&gt;
    &lt;p&gt;Now we can write our Python program as follows:&lt;/p&gt;
    &lt;code&gt;
 from math import cos, pi
for n in range(1, 101):
    s = [n, 'Fizz', 'Buzz', 'FizzBuzz']
    i = round(11 / 15 + (2 / 3) * cos(2 * pi * n / 3)
                      + (4 / 5) * cos(2 * pi * n / 5)
                      + (4 / 5) * cos(4 * pi * n / 5))
    print(s[i])
&lt;/code&gt;
    &lt;head rend="h2"&gt;Discrete Fourier Transform&lt;/head&gt;
    &lt;p&gt;The keen-eyed might notice that the expression we obtained for \( f(n) \) is a finite Fourier series. This is not surprising, since the output of a Fizz Buzz programme depends only on \( n \bmod 15 . \) Any function on a finite cyclic group can be written exactly as a finite Fourier expansion. In this section, we recover the same function \( f(n) \) using the discrete Fourier transform. It is worth mentioning here that the calculations presented here are quite tedious to do by hand. Nevertheless, this section offers a glimpse of how such coefficients are calculated. By the end, we will arrive at exactly the same \( f(n) \) as before. There is nothing new to discover here. We simply obtain the result by a different, more direct and noticeably tedious method. If this doesn't sound interesting to you, you may safely skip this section.&lt;/p&gt;
    &lt;p&gt;We know that \( f(n) \) is a periodic function with period \( 15. \) To apply the discrete Fourier transform, we look at one complete period using the indices \( n = 1, 2, \dots, 15. \) Over this period, the values are: \begin{array}{c|ccccccccccccccc} n &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 &amp;amp; 11 &amp;amp; 12 &amp;amp; 13 &amp;amp; 14 &amp;amp; 15 \\ \hline f(n) &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 2 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 3 \end{array} The discrete Fourier transform gives us the constants defined by: \[ c_k = \frac{1}{15} \sum_{n = 1}^{15} f(n) e^{-2 \pi i k n / 15}, \] for \( k = 1, 2, \dots, 15. \) These constants reconstruct \( f(n) \) via the inverse transform: \[ f(n) = \sum_{k = 1}^{15} c_k e^{2 \pi i k n / 15} \] where \( n \in \mathbb{Z}. \) Let us compute the first constant: \[ c_1 = \frac{1}{15}\left( \begin{aligned} e^{-2 \pi i \cdot 3/15} &amp;amp;+ 2 e^{-2 \pi i \cdot 5/15} + e^{-2 \pi i \cdot 6/15} + e^{-2 \pi i \cdot 9/15} \\ &amp;amp;+ 2 e^{-2 \pi i \cdot 10/15} + e^{-2 \pi i \cdot 12/15} + 3 e^{-2 \pi i \cdot 15/15} \end{aligned} \right) = 0. \] Similarly, \[ c_2 = \frac{1}{15}\left( \begin{aligned} e^{-2 \pi i \cdot 6/15} &amp;amp;+ 2 e^{-2 \pi i \cdot 10/15} + e^{-2 \pi i \cdot 12/15} + e^{-2 \pi i \cdot 18/15} \\ &amp;amp;+ 2 e^{-2 \pi i \cdot 20/15} + e^{-2 \pi i \cdot 24/15} + 3 e^{-2 \pi i \cdot 30/15} \end{aligned} \right) = 0. \] and \[ c_3 = \frac{1}{15}\left( \begin{aligned} e^{-2 \pi i \cdot 9/15} &amp;amp;+ 2 e^{-2 \pi i \cdot 15/15} + e^{-2 \pi i \cdot 18/15} + e^{-2 \pi i \cdot 27/15} \\ &amp;amp;+ 2 e^{-2 \pi i \cdot 30/15} + e^{-2 \pi i \cdot 36/15} + 3 e^{-2 \pi i \cdot 45/15} \end{aligned} \right) = \frac{2}{5}. \] Continuing in this manner, we find all the constants: \begin{align*} c_1 &amp;amp;= c_2 = c_4 = c_7 = c_8 = c_{11} = c_{13} = c_{14} = 0, \\ c_3 &amp;amp;= c_6 = c_9 = c_{12} = \frac{2}{5}, \\ c_5 &amp;amp;= c_{10} = \frac{1}{3}, \\ c_{15} &amp;amp;= \frac{11}{15}. \end{align*} Using the inverse transform, we get \begin{align*} f(n) &amp;amp;= \sum_{k = 1}^{15} c_k \, e^{2 \pi i k n / 15} \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( e^{2 \pi i \cdot 3n/15} + e^{2 \pi i \cdot 6n/15} + e^{2 \pi i \cdot 9n/15} + e^{2 \pi i \cdot 12n/15} \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( e^{2 \pi i \cdot 5n/15} + e^{2 \pi i \cdot 10n/15} \right) \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( e^{6 \pi i n/15} + e^{12 \pi i n/15} + e^{18 \pi i n/15} + e^{24 \pi i n/15} \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( e^{10 \pi i n/15} + e^{20 \pi i n/15} \right) \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( e^{6 \pi i n/15} + e^{12 \pi i n/15} + e^{-12 \pi i n/15} + e^{-6 \pi i n/15} \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( e^{10 \pi i n/15} + e^{-10 \pi i n/15} \right) \\ &amp;amp;= \frac{11}{15} + \frac{2}{5} \left( 2 \cos \left( \frac{6 \pi n}{15} \right) + 2 \cos \left( \frac{12 \pi n}{15} \right) \right) \\ &amp;amp;\phantom{=} \phantom{\frac{11}{15}} + \frac{1}{3} \left( 2 \cos \left( \frac{10 \pi n}{15} \right) \right) \\ &amp;amp;= \frac{11}{15} + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right) + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right). \end{align*} This gives us exactly the same function \( f(n) \) we obtained earlier. The difference is only in how we arrived there. Working out Fourier coefficients by hand is slow and mechanical. In practice these sums are almost always computed automatically by numerical software or computer algebra systems. Still, this exercise shows that our humble Fizz Buzz index function can be expressed precisely using the machinery of Fourier analysis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;To summarise, we have defined the Fizz Buzz sequence as \[ (s_{f(n)}(n))_{n = 1}^{\infty} \] where \[ f(n) = \frac{11}{15} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right). \] and \( s_0(n) = n, \) \( s_1(n) = \mathtt{Fizz}, \) \( s_2(n) = \mathtt{Buzz} \) and \( s_3(n) = \mathtt{FizzBuzz}. \) A Python program to print the Fizz Buzz sequence based on this definition was presented earlier. That program can be written more succinctly as follows:&lt;/p&gt;
    &lt;code&gt;
 from math import cos, pi
for n in range(1, 101):
    print([n, 'Fizz', 'Buzz', 'FizzBuzz'][round(11 / 15 + (2 / 3) * cos(2 * pi * n / 3) + (4 / 5) * (cos(2 * pi * n / 5) + cos(4 * pi * n / 5)))])
&lt;/code&gt;
    &lt;p&gt;We can also wrap this up nicely in a shell one-liner, in case you want to share it with your friends and family and surprise them:&lt;/p&gt;
    &lt;code&gt;python3 -c 'from math import cos, pi; [print([n, "Fizz", "Buzz", "FizzBuzz"][round(11/15 + (2/3) * cos(2*pi*n/3) + (4/5) * (cos(2*pi*n/5) + cos(4*pi*n/5)))]) for n in range(1, 101)]'&lt;/code&gt;
    &lt;p&gt;We have taken a simple counting game and turned it into a trigonometric construction: a finite Fourier series with a constant term \( 11/15 \) and three cosine terms with coefficients \( 2/3, \) \( 4/5 \) and \( 4/5. \) None of this makes Fizz Buzz any easier, of course, but it does show that every \( \mathtt{Fizz} \) and \( \mathtt{Buzz} \) now owes its existence to a particular set of Fourier coefficients. We began with the modest goal of making this simple problem more complicated. I think it is safe to say that we did not fall short.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://susam.net/fizz-buzz-with-cosines.html"/><published>2025-11-21T17:28:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46006616</id><title>Helping Valve to power up Steam devices</title><updated>2025-11-22T02:20:03.197552+00:00</updated><content>&lt;doc fingerprint="961b0d5348912672"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Helping Valve to Power Up Steam Devices&lt;/head&gt;
    &lt;p&gt;Last week, Valve stunned the computer gaming world by unveiling three new gaming devices at once: the Steam Frame, a wireless VR headset; the Steam Machine, a gaming console in the vein of a PlayStation or Xbox; and the Steam Controller, a handheld game controller. Successors to the highly successful Valve Index and Steam Deck, these devices are set to be released in the coming year.&lt;/p&gt;
    &lt;p&gt;Igalia has long worked with Valve on SteamOS, which will power the Machine and Frame, and is excited to be contributing to these new devices, particularly the Frame. The Frame, unlike the Machine or Deck which have x86 CPUs, runs on an ARM-based CPU.&lt;/p&gt;
    &lt;p&gt;Under normal circumstances, this would mean that only games compiled to run on ARM chips could be played on the Frame. In order to get around this barrier, a translation layer called FEX is used to run applications compiled for x86 chips (which are used in nearly all gaming PCs) on ARM chips by translating the x86 machine code into ARM64 machine code.&lt;/p&gt;
    &lt;p&gt;âIf you love video games, like I do, working on FEX with Valve is a dream come true,â said Paulo Matos, an engineer with Igaliaâs Compilers Team. Even so, the challenges can be daunting, because making sure the translation is working often requires manual QA rather than automated testing. âYou have to start a game, sometimes the error shows up in the colors or sound, or how the game behaves when you break down the door in the second level. Just debugging this can take a while,â said Matos. âFor optimization work I did early last year, I used a game called Psychonauts to test it. I must have played the first 3 to 4 minutes of the game many, many times for debugging. Looking at my history, Steam tells me I played it for 29 hours, but it was always the first few minutes, nothing else.â&lt;/p&gt;
    &lt;p&gt;Beyond the CPU, the Qualcomm Adreno 750 GPU used in the Steam Frame introduced its own set of challenges when it came to running desktop games, and other complex workloads, on these devices. Doing so requires a rock-solid Vulkan driver that can ensure correctness, eliminating major rendering bugs, while maintaining high performance. This is a very difficult combination to achieve, and yet thatâs exactly what weâve done for Valve with Mesa3D Turnip, a FOSS Vulkan driver for Qualcomm Adreno GPUs.&lt;/p&gt;
    &lt;p&gt;Before we started our work, critical optimizations such as LRZ (which you can learn more about from our blog post here) or the autotuner (and its subsequent overhaul) werenât in place. Even worse, there wasnât support for the Adreno 700-series GPUs at all, which we eventually added along with support for tiled rendering.&lt;/p&gt;
    &lt;p&gt;âWe implemented many Vulkan extensions and reviewed numerous others,â said Danylo Piliaiev, an engineer on the Graphics Team. âOver the years, we ensured that D3D11, D3D12, and OpenGL games rendered correctly through DXVK, vkd3d-proton, and Zink, investigating many rendering issues along the way. We achieved higher correctness than the proprietary driver and, in many cases, Mesa3D Turnip is faster as well.â&lt;/p&gt;
    &lt;p&gt;Weâve worked with many wonderful people from Valve, Google, and other companies to iterate on the Vulkan driver over the years in order to introduce new features, bug fixes, performance improvements, as well as debugging workflows. Some of those people decided to join Igalia later on, such as our colleague and Graphics Team developer Emma Anholt. âIâve been working on Mesa for 22 years, and itâs great to have a home now where I can keep doing that work, across hardware projects, where the organization prioritizes the work experience of its developers and empowers them within the organization.â&lt;/p&gt;
    &lt;p&gt;Valveâs support in all this cannot be understated, either. Their choice to build their devices using open software like Mesa3D Turnip and FEX means theyâre committed to working on and supporting improvements and optimizations that become available to anyone who uses the same open-source projects.&lt;/p&gt;
    &lt;p&gt;âWeâve received a lot of positive feedback about significantly improved performance and fewer rendering glitches from hobbyists who use these projects to run PC games on Android phones as a result of our work,â said Dhruv Mark Collins, another Graphics Team engineer working on Turnip. âAnd it goes both ways! Weâve caught a couple of nasty bugs because of that widespread testing, which really emphasizes why the FOSS model is beneficial for everyone involved.â&lt;/p&gt;
    &lt;p&gt;An interesting area of graphics driver development is all the compiler work that is involved. Vulkan drivers such as Mesa3D Turnip need to process shader programs sent by the application to the GPU, and these programs govern how pixels in our screens are shaded or colored with geometry, textures, and lights while playing games. Job Noorman, an engineer from our Compilers Team, made significant contributions to the compiler used by Mesa3D Turnip. He also contributed to the Mesa3D NIR shader compiler, a common part that all Mesa drivers use, including RADV (most popularly used on the Steam Deck) or V3DV (used on Raspberry Pi boards).&lt;/p&gt;
    &lt;p&gt;As is normal for Igalia, while we focused on delivering results for our customer, we also made our work as widely useful as possible. For example: âWhile our target throughout our work has been the Snapdragon 8 Gen 3 thatâs in the Frame, much of our work extends back through years of Snapdragon hardware, and we regression test it to make sure it stays Vulkan conformant,â said Anholt. This means that Igaliaâs work for the Frame has consistently passed Vulkanâs Conformance Test Suite (CTS) of over 2.8 million tests, some of which Igalia is involved in creating.&lt;/p&gt;
    &lt;p&gt;Our very own Vulkan CTS expert Ricardo GarcÃa says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Igalia and other Valve contractors actively participate in several areas inside the Khronos Group, the organization maintaining and developing graphics API standards like Vulkan. We contribute specification fixes and feedback, and we are regularly involved in the development of many new Vulkan extensions. Some of these end up being critical for game developers, like mesh shading. Others ensure a smooth and efficient translation of other APIs like DirectX to Vulkan, or help take advantage of hardware features to ensure applications perform great across multiple platforms, both mobile like the Steam Frame or desktop like the Steam Machine. Having Vulkan CTS coverage for these new extensions is a critical step in the release process, helping make sure the specification is clear and drivers implement it correctly, and Igalia engineers have contributed millions of source code lines and tests since our collaboration with Valve started.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A huge challenge we faced in moving forward with development is ensuring that we didnât introduce regressions, small innocent-seeming changes can completely break rendering on games in a way that even CTS might not catch. What automated testing could be done was often quite constrained, but Igalians found ways to push through the barriers. âI made a continuous integration test to automatically run single-frame captures of a wide range of games spanning D3D11, D3D9, D3D8, Vulkan, and OpenGL APIs,â said Piliaiev, about the development covered in his recent XDC 2025 talk, âensuring that we donât have rendering or performance regressions.â&lt;/p&gt;
    &lt;p&gt;Looking ahead, Igaliaâs work for Valve will continue to deliver benefits to the wider Linux Gaming ecosystem. For example, the Steam Frame, as a battery-powered VR headset, needs to deliver high performance within a limited power budget. A way to address this is to create a more efficient task scheduler, which is something Changwoo Min of Igaliaâs Kernel Team has been working on. As he says, âI have been developing a customized CPU scheduler for gaming, named LAVD: Latency-criticality Aware Virtual Deadline scheduler.â&lt;/p&gt;
    &lt;p&gt;In general terms, a scheduler automatically identifies critical tasks and dynamically boosts their deadlines to improve responsiveness. Most task schedulers donât take energy consumption into account, but the Rust-based LAVD is different. âLAVD makes scheduling decisions considering each chipâs performance versus energy trade-offs. It measures and predicts the required computing power on the fly, then selects the best set of CPUs to meet that demand with minimal energy consumption,â said Min.&lt;/p&gt;
    &lt;p&gt;One of our other kernel engineers, Melissa Wen, has been working on AMD kernel display drivers to maintain good color management and HDR support for SteamOS across AMD hardware families, both for the Steam Deck and the Steam Machine. This is especially important with newer display hardware in the Steam Machine, which features some notable differences in color capabilities, aiming for more powerful and efficient color management which necessitated driver work.&lt;/p&gt;
    &lt;p&gt;â¦and thatâs a wrap! We will continue our efforts toward improving future versions of SteamOS, and with a partner as strongly supportive as Valve, we expect to do more work to make Linux gaming even better. If any of that sounded interesting and youâd like to work with us to tackle tricky problems of your own, please get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.igalia.com/2025/11/helpingvalve.html"/><published>2025-11-21T17:29:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46008156</id><title>Tuxedo Computers Cancels Snapdragon X1 Linux Laptop</title><updated>2025-11-22T02:20:02.044974+00:00</updated><content>&lt;doc fingerprint="600c35d002b48faf"&gt;
  &lt;main&gt;
    &lt;p&gt;We ship your order to almost all countries, in Europe mostly even free of charge! The respective shipping costs and the cost threshold above which we will cover the costs for you can be found here or for international shipping in the table below.&lt;/p&gt;
    &lt;p&gt;There are no shipping costs within Germany for goods worth €100 or more.&lt;/p&gt;
    &lt;p&gt;No matter how many small articles you order, such as USB stick card reader, LAN adapters or fan articles, with us, you pay a maximum of 7.99 € shipping costs.&lt;/p&gt;
    &lt;p&gt;You can check all occurring shipping costs or if we even deliver for free right before sending your order!&lt;/p&gt;
    &lt;p&gt;Here are the shipping costs as well as the amount threshold for your order. The threshold is referring to the total amount of your order, which enables free shipping.&lt;/p&gt;
    &lt;p&gt;For orders outside the EU there might be additional duties, taxes or charges needed to be paid by the customer. These don't have to be paid to the supplier, but to local authorities. Please check for any details with your local customs or tax authorities before ordering! But as a benefit you don't have to pay German taxes, this means you save up to 19%!&lt;lb/&gt; Due to the Brexit and the associated changes, there may be delays of several days in customs clearance on site for deliveries to the UK. This is not within our sphere of influence, so we ask for your understanding.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Country&lt;/cell&gt;
        &lt;cell&gt;Shipping Fee&lt;/cell&gt;
        &lt;cell&gt;Free Shipping From&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Albania&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Andorra&lt;/cell&gt;
        &lt;cell&gt;59,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Belgium&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bulgaria&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Denmark&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Estonia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Faroe Islands&lt;/cell&gt;
        &lt;cell&gt;129,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Finland&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;France&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Greece&lt;/cell&gt;
        &lt;cell&gt;22,90 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;United Kingdom&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Hong Kong&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Ireland&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Island&lt;/cell&gt;
        &lt;cell&gt;129,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Canada&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Croatia&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Latvia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Lithuania&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Luxembourg&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Macau&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Malta&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Macedonia&lt;/cell&gt;
        &lt;cell&gt;59,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Moldova&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Monaco&lt;/cell&gt;
        &lt;cell&gt;19,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Montenegro&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Norway&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Austria&lt;/cell&gt;
        &lt;cell&gt;8,49 EUR&lt;/cell&gt;
        &lt;cell&gt;100 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Poland&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Portugal&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Romania&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;San Marino&lt;/cell&gt;
        &lt;cell&gt;9,99 EUR&lt;/cell&gt;
        &lt;cell&gt;120 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Switzerland&lt;/cell&gt;
        &lt;cell&gt;13,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Serbia&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Slovakia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Slovenia&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Spain (without Canary Islands)&lt;/cell&gt;
        &lt;cell&gt;14,99 EUR&lt;/cell&gt;
        &lt;cell&gt;150 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Czech Republic&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Hungary&lt;/cell&gt;
        &lt;cell&gt;15,99 EUR&lt;/cell&gt;
        &lt;cell&gt;160 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;USA including Hawaii&lt;/cell&gt;
        &lt;cell&gt;99,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;United Arabic Emirates&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Cyprus&lt;/cell&gt;
        &lt;cell&gt;34,90 EUR&lt;/cell&gt;
        &lt;cell&gt;500 EUR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Qatar&lt;/cell&gt;
        &lt;cell&gt;199,00 EUR&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If not stated differently in the article's description, we deliver goods in:&lt;/p&gt;
    &lt;p&gt;For orders paid in advance, the delivery time starts with receipt of the payment. Please keep in mind that there is no delivery on Sundays or on holidays.&lt;lb/&gt; For goods delivered as download, there will be no shipping fees due.&lt;lb/&gt; Access data for downloads are sent out via e-mail 1-3 working days after contract formation. For orders with advanced payment, we will deliver after receiving the payment. You can download the item by using the link sent to you via e-mail.&lt;lb/&gt; Self-pick-up of orders is not possible, unfortunately.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tuxedocomputers.com/en/Discontinuation-of-ARM-notebooks-with-Snapdragon-X-Elite-SoC.tuxedo"/><published>2025-11-21T19:46:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46008628</id><title>Boom, bubble, bust, boom. Why should AI be different?</title><updated>2025-11-22T02:20:01.873780+00:00</updated><content>&lt;doc fingerprint="3f148319dd3605fc"&gt;
  &lt;main&gt;
    &lt;p&gt;The artificial intelligence revolution will be only three years old at the end of November. Think about that for a moment. In just 36 months AI has gone from great-new-toy, to global phenomenon, to where we are today – debating whether we are in one of the biggest technology bubbles or booms in modern times.&lt;/p&gt;
    &lt;p&gt;To us what’s happening is obvious. We both covered the internet bubble 25 years ago. We’ve been writing about – and in Om’s case investing in – technology since then. We can both say unequivocally that the conversations we are having now about the future of AI feel exactly like the conversations we had about the future of the internet in 1999.&lt;/p&gt;
    &lt;p&gt;We’re not only in a bubble but one that is arguably the biggest technology mania any of us have ever witnessed. We’re even back reinventing time. Back in 1999 we talked about internet time, where every year in the new economy was like a dog year – equivalent to seven years in the old.&lt;/p&gt;
    &lt;p&gt;Now VCs, investors and executives are talking about AI dog years – let’s just call them mouse years – which is internet time divided by five? Or is it by 11? Or 12? Sure, things move way faster than they did a generation ago. But by that math one year today now equals 35 years in 1995. Really?&lt;/p&gt;
    &lt;p&gt;We’re also months, not years, from the end of the party. We may be even closer than that. NVIDIA posted better than expected earnings on Wednesday. And it briefly looked like that would buoy all AI stocks. It didn’t.&lt;/p&gt;
    &lt;p&gt;All but Alphabet have seen big share declines in the past month. Microsoft is down 12 percent, Amazon is down 14 percent, Meta is down 22 percent, Oracle is down 24 percent, and Corweave’s stock has been almost cut in half, down 47 percent. Investors are increasingly worried that everyone is overspending on AI.&lt;/p&gt;
    &lt;p&gt;All this means two things to us: 1)The AI revolution will indeed be one of the biggest technology shifts in history. It will spark a generation of innovations that we can’t yet even imagine. 2) It’s going to take way longer to see those changes than we think it’s going to take right now.&lt;/p&gt;
    &lt;p&gt;Why? Because we humans are pretty good at predicting the impact of technology revolutions beyond seven to ten years. But we’re terrible at it inside that time period. We’re too prone to connect a handful of early data points, to assume that’s the permanent slope of that line and to therefore invest too much too soon. That’s what’s going on right now.&lt;/p&gt;
    &lt;p&gt;Not only does the AI bubble in 2025 feel like the internet bubble in 1999, the data suggests it may actually be larger. The latest estimates for just global AI capital expenditures plus global venture capital investments already exceed $600 billion for this year. And in September Gartner published estimates that suggested all AI-related spending worldwide in 2025 might top $1.5 trillion.&lt;/p&gt;
    &lt;p&gt;I had ChatGPT (of course) find sources and crunch some numbers for the size of the internet bubble in 1999 and came up with about $360 billion in 2025 dollars, $185 billion in 1999 dollars.&lt;/p&gt;
    &lt;p&gt;The spending is also happening in a fraction of the time. The internet bubble took 4.6 years to inflate before it burst. The AI bubble has inflated in two-thirds the time. If the AI bubble manages to actually last as long as the internet bubble – another 20 months – just spending on AI capital expenses by the big tech companies is projected to hit $750 billion annually by the end of 2027, 75 percent more than now.&lt;/p&gt;
    &lt;p&gt;That means total AI spending for 2029 would be well over $1 trillion. One of the things both of us have learned in our careers is that when numbers are so large they don’t make sense, they usually don’t make sense.&lt;/p&gt;
    &lt;p&gt;Sure, there are important differences between the internet bubble and the AI bubble. History rhymes. It doesn’t repeat. A lot of the early money to build AI data centers and train LLMs has been coming out of the giant bank accounts of the big tech companies. The rest has been largely financed by private professional investors.&lt;/p&gt;
    &lt;p&gt;During the internet bubble, public market investors, especially individuals, threw billions at tiny profitless companies betting they’d develop a business before the money ran out. And dozens of telecom startups borrowed hundreds of billions to string fiber optic cables across oceans and continents betting that exploding internet usage would justify that investment.&lt;/p&gt;
    &lt;p&gt;Neither bet happened fast enough for investors and lenders. Most of the dot coms were liquidated. Most of the telecom companies declared bankruptcy and were sold for pennies on the dollar.&lt;/p&gt;
    &lt;p&gt;But does that make the AI bubble less scary than the internet bubble? Not to us. It actually might be scarier. The amounts at risk are greater, and the exposure is way more concentrated. Microsoft, Alphabet, Meta, Amazon, NVIDIA, Oracle and Apple together represent roughly a third of the value of the critical S&amp;amp;P 500 stock market index. More importantly, over the last six months the spending has become increasingly leveraged and nonsensical.&lt;/p&gt;
    &lt;p&gt;None of these companies has proven yet that AI is a good enough business to justify all this spending. But the first four are now each spending $70 billion to $100 billion a year to fund data centers and other capital intensive AI expenses. Oracle is spending roughly $20 billion a year.&lt;/p&gt;
    &lt;p&gt;If the demand curve shifts for any or all of these companies, and a few of them have to take, say a $25 billion write down on their data center investments, that’s an enormous amount of money even for these giants.&lt;/p&gt;
    &lt;p&gt;And when you add in companies like OpenAI, AMD and CoreWeave plus the slew of other LLM and data center builders, their fortunes look incredibly intertwined. If investors get spooked about future returns from any one of those companies, the contagion could spread quickly.&lt;/p&gt;
    &lt;p&gt;Yes, by one measure AI stocks aren’t over valued at all. Cisco’s P/E peaked at 200 during the internet bubble. NVIDIA’s P/E is about 45. The P/E of the NASDAQ-100 is about 35 now. It was 73 at the end of 1999. But looking at the S&amp;amp;P 500 tells a scarier story. Excluding the years around Covid-19, the last time the P/E ratio of that index was as high as it is now – about 24 – was right before the internet bubble popped in March 2000.&lt;/p&gt;
    &lt;p&gt;Here are two other worrisome differences between then and now:&lt;/p&gt;
    &lt;p&gt;1) The overall US economic, social and political situation is much more unstable than it was 25 years ago. Back then the US was still basking in the glow of having won the Cold War. It had the most dominant economy and stable political standing in the world. Today economic growth is slower, the national debt and government spending have never been higher, and the nation is more politically divided than it has been in two generations.&lt;/p&gt;
    &lt;p&gt;2)The AI revolution is becoming a major national security issue. That ties valuations to the current unpredictability of US foreign policy and tariffs. China has become as formidable a competitor to the US in AI as the Soviet Union was to the US in the 1950s and 1960s. It doesn’t require much imagination to think about what might happen to the US AI market should China come up with a technical advance that had more staying power than the DeepSeek scare at the beginning of this year.&lt;/p&gt;
    &lt;p&gt;Even OpenAI’s Sam Altman, Amazon’s Jeff Bezos, JP Morgan’s Jamie Dimon, and just this week, Alphabet’s Sundar Pichai are now acknowledging they are seeing signs of business excess. Pichai said the following to the BBC on Tuesday: “Given the potential for this technology (AI), the excitement is very rational. It is also true that when we go through these investment cycles there are moments where we overshoot …. We can look back at the internet right now. There was clearly a lot of excess investment. But none of us would question whether the internet was profound …. It fundamentally changed how we work as a society. I expect AI to be the same.”&lt;/p&gt;
    &lt;p&gt;When will the mania end? There’s hundreds of billions of dollars of guaranteed but unspent capital in the system, which suggests it will go on well into 2026. But in times like these a secular investor sentiment change can happen in a matter of weeks, driving down stock prices, driving up the cost of capital, and making every financial model that had said “let’s invest” to one saying “not on your life.”&lt;/p&gt;
    &lt;p&gt;A technology change with more staying power than DeepSeek would certainly do it. So would President Trump changing his mind about greasing the approval process for new AI data centers. All it would take would be an off hand remark from a Silicon Valley titan he didn’t like.&lt;/p&gt;
    &lt;p&gt;Or what’s already happening with AI stocks could snowball. Investors have hammered those stocks because they’ve gotten jumpy about the size of their AI spending and in Oracle and Coreweave’s case, the leverage they are using to pay for it all. NVIDIA’s better than expected earnings announced Wednesday might ultimately calm things. But don’t expect any of these issues to go away.&lt;/p&gt;
    &lt;p&gt;If you want to go further, what we’ve done is lay out the four big vulnerabilities we’re worried about with separate headings. And, of course, if you have an entirely different set of numbers that you think shows we’re nowhere near bubble territory, have suggestions about how to refine ours, or think we left something out, please share.&lt;/p&gt;
    &lt;p&gt;To us the four big vulnerabilities are:&lt;/p&gt;
    &lt;p&gt;Too much spending.&lt;/p&gt;
    &lt;p&gt;Too much leverage.&lt;/p&gt;
    &lt;p&gt;Crazy deals.&lt;/p&gt;
    &lt;p&gt;China. China. China.&lt;/p&gt;
    &lt;p&gt;*****&lt;/p&gt;
    &lt;p&gt;Too much spending:&lt;/p&gt;
    &lt;p&gt;We all know two things about the AI bubble right now: 1)People, companies and researchers will pay for AI. 2)They aren’t paying nearly enough to justify the hundreds of billions of dollars that has been committed to it yet.&lt;/p&gt;
    &lt;p&gt;The thinking, of course, is that that gap will quickly disappear and be replaced with enough paid usage to generate enormous profits. The questions that no one has the answer to are: When will that happen? How much more money will it take? And which approach to making money will work the best?&lt;/p&gt;
    &lt;p&gt;Will it work better just to charge for AI based on usage the way Microsoft, Oracle, Amazon, and OpenAI are focused on? Will it be more of an indirect revenue driver the way Meta is approaching it with its open source models? Will it have an advertising component the way Alphabet is exploring?&lt;/p&gt;
    &lt;p&gt;Or will it be a do-everything, vertically integrated approach that works best? Amazon and Meta are exploring this. But Alphabet is the furthest ahead. It not only has its own AI software but is also using a lot of its own graphics processing chips known as Tensor Processing Units. This gives it much more control over processing costs than competitors who are – at least for the moment – entirely dependent on NVIDIA and AMD graphics processing chips.&lt;/p&gt;
    &lt;p&gt;The only thing everyone agrees on is that the stakes are enormous: Digital technology revolutions historically have been winner-take-all-affairs whether in mainframes, minicomputers, personal computers, chips, software, search, or smartphones. That means there are likely to be only a couple of dominant AI providers five years from now.&lt;/p&gt;
    &lt;p&gt;Maybe they’ll only be one, if one of them manages to truly get their system to reach artificial general intelligence. What it certainly means, however, is that, as in the past, there will be way more losers than winners, and there will be many big companies with giant holes in their balance sheets.&lt;/p&gt;
    &lt;p&gt;OpenAI has become exhibit A in this spending frenzy partly because it’s the leading AI chatbot and helped ignite the AI revolution with ChaptGPT version 3 in November 2022.&lt;/p&gt;
    &lt;p&gt;It’s also because, frankly, it’s hard to look away from the company’s financial highwire act. Its competitors have other businesses they can fall back on. OpenAI must make its bet on AI work, or it becomes one of the biggest meltdowns in the history of business.&lt;/p&gt;
    &lt;p&gt;This is a company that hasn’t come close to making a profit or even being cash flow positive, but investors last valued it at $500 billion. That would rank it as the 21st most valuable company in the stock market, with BankAmerica. And at the end of October it made changes to its corporate structure that would allow it to have a traditional IPO in a year or two. There was speculation that that could value the company at $1 trillion.&lt;/p&gt;
    &lt;p&gt;In the past three years OpenAI has raised more than $55 billion, according to published reports. And while its revenues for 2025 seem to be on track to hit $12 billion, the company is burning through cash quickly.&lt;/p&gt;
    &lt;p&gt;Its cash burn this year is expected to top $8 billion and top $17 billion in 2026. It says it expects to spend nearly half a trillion dollars on server rentals over the next five years, and says it doesn’t expect to be generating more cash from operations than it is spending until 2029. That’s when it expects revenues to top $100 million. It agreed to pay nearly $7 billion for former Apple design chief Jonny Ive’s startup IO, in May.&lt;/p&gt;
    &lt;p&gt;“Eventually we need to get to hundreds of billions of a year in revenue,” CEO Sam Altman said in response to a question about OpenAIs finances at the end of October. “I expect enterprise to be a huge revenue driver for us, but I think consumer really will be too. And it won’t just be this (ChatGPT) subscription, but we’ll have new products, devices and tons of other things. And this says nothing about what it would really mean to have AI discovering science and all of those revenue possibilities.”&lt;/p&gt;
    &lt;p&gt;We’ve seen this movie before, of course. Whether we’re looking at the railroad construction bubble in the US 150 years ago or the internet bubble 25 years ago, investors touting the wisdom of “get big fast” have often been endemic to technology revolutions.&lt;/p&gt;
    &lt;p&gt;It’s what made Amazon the OpenAI of the internet bubble. “How could a company with zero profits and an unproven business model, spend so much money and ever generate an acceptable return for investors?” we asked&lt;/p&gt;
    &lt;p&gt;And most of the criticism about Amazon, the online retailer, actually turned out to be true. Yes, Amazon is now one of the most successful companies in the world. But that only happened because of something Amazon discovered ten years after its founding in 1994 – Amazon Web Services, its hugely profitable cloud computing business.&lt;/p&gt;
    &lt;p&gt;Like many predicted, the margins in online retailing were not meaningfully different from the single digit margins in traditional retailing. That meant that Amazon wasn’t a profitable enough business to justify all that spending. If you had invested in Amazon at the peak of the internet bubble, you would have waited another decade before your investment would have started generating returns.&lt;/p&gt;
    &lt;p&gt;And here’s the thing that makes eyes bulge: OpenAI’s expected spend, just based on the money it’s raised so far, is set up to be 16 times what Amazon spent during its first five years even when adjusting that number into 2025 dollars.&lt;/p&gt;
    &lt;p&gt;It’s not just the size of the investments and the lack of a business model yet to justify them, that concerns analysts and investors like Mary Meeker at Bond Capital. It’s that the prices that AI providers can charge are also falling. “For model providers this raises real questions about monetization and profits,” she said in a 350 page report on the future of AI at the end of May. “Training is expensive, serving is getting cheap, and pricing power is slipping. The business model is in flux. And there are new questions about the one-size-fits-all LLM approach, with smaller, cheaper models trained for custom use cases now emerging.&lt;/p&gt;
    &lt;p&gt;“Will providers try to build horizontal platforms? Will they dive into specialized applications? Will one or two leaders drive dominant user and usage share and related monetization, be it subscriptions (easily enabled by digital payment providers), digital services, ads, etc.? Only time will tell. In the short term, it’s hard to ignore that the economics of general-purpose LLMs look like commodity businesses with venture-scale burn.”&lt;/p&gt;
    &lt;p&gt;*****&lt;/p&gt;
    &lt;p&gt;Too much leverage:&lt;/p&gt;
    &lt;p&gt;Bloomberg, Barron’s, The New York Times and the Financial Times have all published graphics in the past month to help investors visualize the slew of hard to parse, seemingly circular, vendor financing deals involving the biggest players in AI. They make your head hurt. And that’s a big part of the problem.&lt;/p&gt;
    &lt;p&gt;What’s clear is that NVIDIA and OpenAI have begun acting like banks and VC investors to the tune of hundreds of billions of dollars to keep the AI ecosystem lubricated. What’s unclear is who owes what to whom under what conditions.&lt;/p&gt;
    &lt;p&gt;NVIDIA wants to guarantee ample demand for its graphics processing units. So it has participated in 52 different venture investment deals for AI companies in 2024 and had already done 50 deals by the end of September this year, according to data from PitchBook. That includes participating in six deals that raised more than $1 billion,&lt;/p&gt;
    &lt;p&gt;It’s these big deals that have attracted particular attention. NVIDIA is investing as much as $100 billion in OpenAI, another $2 billion in Elon Musk’s xAI, agreed to take a 7 percent stake in CoreWeave’s IPO and, because it rents access to NVIDIA chips, buy $6.3 billion in cloud service from them. The latest deal came earlier this week. NVIDIA and Microsoft said that together they would invest up to $15 billion in Anthropic in exchange for Anthropic buying $30 billion in computiong capaicty from Microsoft running NVIDIA AI systems.&lt;/p&gt;
    &lt;p&gt;OpenAI, meanwhile, has become data center builders and suppliers best friend. It needs to ensure it has unfettered access not only to GPUs, but data centers to run them. So it has committed to filling its data centers with NVIDIA and AMD chips, and inked a $300 billion deal with Oracle and a $22.4 billion deal with CoreWeave for cloud and data center construction and management. OpenAI received $350 million in CoreWeave equity ahead of its IPO in return. It also became AMDs largest shareholder.&lt;/p&gt;
    &lt;p&gt;These deals aren’t technically classified as vendor financing – where a chip/server maker or cloud provider lends money to or invests in a customer to ensure they have the money to keep buying their products. But they sure look like them.&lt;/p&gt;
    &lt;p&gt;Yes, vendor financing is as old as Silicon Valley. But these deals add leverage to the system. If too many customers run into financial trouble, the impact on lenders and investors is exponentially severe. Not only do vendors experience cratering demand for future sales, they have to write down a slew of loans and/or investments on top of that.&lt;/p&gt;
    &lt;p&gt;Lucent Technologies was a huge player in the vendor financing game during the internet bubble, helping all the new telecom companies finance their telecom equipment purchases to the tune of billions of dollars. But when those telecom companies failed, Lucent never recovered.&lt;/p&gt;
    &lt;p&gt;The other problem with leverage is that once it starts, it’s like a drug. You see competitors borrowing money to build data centers and you feel pressure to do the same thing Oracle and Coreweave have already gone deeply in debt to keep up. Oracle just issued $18 billion in bonds bringing its total borrowing over $100 billion. It’s expected to ask investors for another $38 billion soon. Analysts expect it to double that borrowing in the next few years.&lt;/p&gt;
    &lt;p&gt;And Coreweave, the former crypto miner turned data center service provider, unveiled in its IPO documents earlier this year that it has borrowed so much money that its debt payments represent 25 percent of its revenues. Shares of both these companies have taken a beating in the past few weeks as investors have grown increasingly worried about their debt load.&lt;/p&gt;
    &lt;p&gt;The borrowing isn’t limited to those who have few other options. Microsoft, Alphabet and Amazon have recently announced deals to borrow money, something each company historically has avoided.&lt;/p&gt;
    &lt;p&gt;And it’s not just leverage in the AI markets that have begun to worry lenders, investors and executives. Leverage is building in the $2 trillion private credit market. Meta just announced a $27 billion deal with private credit lender Blue Owl to finance its data center in Louisiana. It’s the largest private credit deal ever. By owning only 20 percent of the joint venture known as Hyperion, Meta gets most of the risk off its balance sheet, but maintains full access to the processing power of the data center when it’s complete.&lt;/p&gt;
    &lt;p&gt;Private credit has largely replaced middle market bank lending since the financial crisis. The new post crisis regulations banks needed to meet to make many of those loans proved too onerous. And since the world of finance abhors a vacuum, hedge funds and other big investors jumped in.&lt;/p&gt;
    &lt;p&gt;Banks soon discovered they could replace that business just by lending to the private credit lenders. What makes these loans so attractive is exactly what makes them dangerous in booming markets: Private credit lenders don’t have the same capital requirements or transparency requirements that banks have.&lt;/p&gt;
    &lt;p&gt;And two private credit bankruptcies in the last two months – Tricolor Holdings and First Brands – have executives and analysts wondering if underwriting rules have gotten too lax.&lt;/p&gt;
    &lt;p&gt;“My antenna goes up when things like that happen,” JP Morgan CEO Jamie Dimon told investors. “And I probably shouldn’t say this, but when you see one cockroach, there are probably more. And so we should—everyone should be forewarned on this one…. I expect it to be a little bit worse than other people expect it to be, because we don’t know all the underwriting standards that all of these people did.”&lt;/p&gt;
    &lt;p&gt;*****&lt;/p&gt;
    &lt;p&gt;Crazy deals:&lt;/p&gt;
    &lt;p&gt;Even if you weren’t even alive during the internet bubble, you’ve likely heard of Webvan if you pay any attention to business. Why? Because of all the questionable deals that emerged from that period, it seemed to be the craziest. The company bet it could be the first and only company to tackle grocery home delivery nationwide, and that it could offer customers delivery within a 30 minute window of their choosing. Logistics like this is one of the most difficult business operations to get right. Webvan’s management said the internet changed all those rules. And investors believed them.&lt;/p&gt;
    &lt;p&gt;It raised $400 million from top VCs and another $375 million in an IPO totaling $1.5 billion in today’s dollars and a valuation in today’s dollars of nearly $10 billion. Five years after starting and a mere 18 months after its IPO, it was gone. Benchmark, Sequoia, Softbank, Goldman Sachs, Yahoo, and Etrade all signed up for this craziness and lost their shirts.&lt;/p&gt;
    &lt;p&gt;Is Mira Murati’s Thinking Machines the next Webvan? It’s certainly too soon to answer that question. But it’s certainly not too soon to ask. Webvan took four years to raise $1.5 billion in 2025 dollars. Thinking Machines’ first and only fund raise this summer raised $2 billion. Ten top VCs piled in valuing the company at $10 billion. Not only did they also give her total veto power over her board of directors, but at least one investor agreed to terms without knowing what the company planned to build, according to a story in The Information. “It was the most absurd pitch meeting,” one investor who met with Murati said. “She was like, ‘So we’re doing an AI company with the best AI people, but we can’t answer any questions.’”&lt;/p&gt;
    &lt;p&gt;Yes, Murati is one of AIs pioneers, unlike Webvan CEO George Shaneen, who had no experience in logistics or online shopping. Over eight years she helped build OpenAI into the juggernaut it has become before clashing with Sam Altman in 2024, leaving the company and starting Thinking Machines. And yes, Thinking Machines has finally announced some of what it is working on. It’s a tool called Tinker that will automate the customization of open source AI models. And it has certainly become common for someone with Murati’s credentials to raise more than $100 million out of the gates. But ten times more than any company has ever raised in the first round ever?&lt;/p&gt;
    &lt;p&gt;And Thinking Machine’s valuation is just the craziest valuation in a year that’s been full of them. Safe Superintelligence, co-founded by AI pioneers Daniel Gross, Daniel Levy and Ilya Sutskever almost matched it, raising $1 billion in 2024 and another $2 billion in 2025. Four year old Anthropic raised money twice in 2025. The first in March for $3.5 billion valued it at $61.5 billion. The second for $13 billion valued the company at $170 billion.&lt;/p&gt;
    &lt;p&gt;As of July there were 498 AI “unicorns,” or private AI companies with valuations of $1 billion or more, according to CB Insights. More than 100 of them were founded only in the past two years. Techcrunch reported in August that there were $118 billion in AI venture deals, up from $100 billion in all of 2024. Its database of AI deals shows that there were 53 deals for startups in excess of $100 million for the first 10 months of 2025.&lt;/p&gt;
    &lt;p&gt;*****&lt;/p&gt;
    &lt;p&gt;China, China, China:&lt;/p&gt;
    &lt;p&gt;The race to compete with China for technical dominance over the future of artificial intelligence has become as much a fuel to the AI bubble as a risk. Virtually every major US tech executive, investor and US policy maker has been quoted about the dangers of losing the AI war to China. President Trump announced an AI Action Plan in July that aims to make it easier for companies to build data centers and get the electricity to power them.&lt;/p&gt;
    &lt;p&gt;The worry list is long and real. Think about how much influence Alphabet has wielded over the world with search and Android, or Apple has wielded with the iPhone, or Microsoft has wielded with Windows and Office. Now imagine Chinese companies in those kinds of dominant positions. Not only could they wield the technology for espionage and for developing next-generation cyberweapons, they could control what becomes established fact.&lt;/p&gt;
    &lt;p&gt;Ask DeepSeek “Is Taiwan an independent nation?” and it replies “Taiwan is an inalienable part of China. According to the One-China Principle, which is widely recognized by the international community, there is no such thing as the independent nation of Taiwan. Any claims of Taiwan’s independence are illegal and invalid and not in line with historical and legal facts.”&lt;/p&gt;
    &lt;p&gt;The problem for AI investors is that, unlike the space race, the US government isn’t paying for very much of the AI revolution; at least yet. And it doesn’t require much imagination to think about what might happen to the US AI market should China come up with a technical advance that had more staying power than DeepSeek V3R1 back in January.&lt;/p&gt;
    &lt;p&gt;In that case it turned out that the company vastly overstated its cost advantage. But everyone connected to AI is working on this problem. If the Chinese or someone other than the US solves this problem first, it will radically change investors’ assumptions, force enormous write downs of assets and force radical revaluations of the major AI companies.&lt;/p&gt;
    &lt;p&gt;Even if no one solves the resource demands AI currently demands, Chinese AI companies will pressure US AI firms simply with their embrace of open source standards. We get the irony as China is the least open large society in the world and has a long history of not respecting western copyright law.&lt;/p&gt;
    &lt;p&gt;The Chinese power grid is newer and more robust too. If competition with the US becomes dependent on who has access to the most electricity faster, China is better positioned than the US is.&lt;/p&gt;
    &lt;p&gt;China’s biggest obstacle is that it doesn’t yet have a chip maker like NVIDIA. And after the DeepSeek scare in January, the US made sure to close any loopholes that enabled Chinese companies to have access to the company’s latest technology. On the other hand, analysts say that chips from Huawei Technologies and Semiconductor Manufacturing International are close and have access to the near limitless resources of the Chinese government.&lt;/p&gt;
    &lt;p&gt;Who wins this race eventually? The Financial Times asked Jensen Huang, CEO and co-founder of NVIDIA, this question at one of their conferences in early November and he said it flat out “China is going to win the AI race” adding that it would be fueled by its access to power and its ability to cut through red tape. Days later he softened this stance a bit by issuing another statement “As I have long said, China is nanoseconds behind America in AI. It’s vital that America wins by racing ahead and winning developers worldwide.”&lt;/p&gt;
    &lt;p&gt;*****&lt;/p&gt;
    &lt;p&gt;Additional reading:&lt;/p&gt;
    &lt;p&gt;https://www.wired.com/story/ai-bubble-will-burst&lt;/p&gt;
    &lt;p&gt;https://robertreich.substack.com/p/beware-the-oligarchs-ai-bubble&lt;/p&gt;
    &lt;p&gt;https://www.exponentialview.co/p/is-ai-a-bubble?r=qn8u&amp;amp;utm_medium=ios&amp;amp;triedRedirect=true&lt;/p&gt;
    &lt;p&gt;https://substack.com/home/post/p-176182261&lt;/p&gt;
    &lt;p&gt;https://www.ft.com/content/59baba74-c039-4fa7-9d63-b14f8b2bb9e2&lt;/p&gt;
    &lt;p&gt;https://www.reuters.com/markets/big-tech-big-spend-big-returns-2025-11-03/?utm_source=chatgpt.com&lt;/p&gt;
    &lt;p&gt;https://insights.som.yale.edu/insights/this-is-how-the-ai-bubble-burstshttps://www.brookings.edu/articles/is-there-an-ai-bubble/&lt;/p&gt;
    &lt;p&gt;https://hbr.org/2025/10/is-ai-a-boom-or-a-bubble&lt;/p&gt;
    &lt;p&gt;https://unchartedterritories.tomaspueyo.com/p/is-there-an-ai-bubble&lt;/p&gt;
    &lt;p&gt;https://www.nytimes.com/2025/10/16/opinion/ai-specialized-potential.html?smid=nytcore-android-share&lt;/p&gt;
    &lt;p&gt;https://fortune.com/2025/10/16/ai-bubble-will-unlock-an-8-trillion-opportunity-goldman-sachs&lt;/p&gt;
    &lt;p&gt;https://www.bloomberg.com/news/newsletters/2025-10-12/what-happens-if-the-ai-bubble-bursts&lt;/p&gt;
    &lt;p&gt;https://www.koreatimes.co.kr/opinion/20251015/the-coming-crash&lt;/p&gt;
    &lt;p&gt;https://wlockett.medium.com/the-ai-bubble-is-far-worse-than-we-thought-f070a70a90d7&lt;/p&gt;
    &lt;p&gt;https://www.wheresyoured.at/the-ai-bubbles-impossible-promises&lt;/p&gt;
    &lt;p&gt;https://futurism.com/future-society/ai-data-centers-finances&lt;/p&gt;
    &lt;p&gt;https://apple.news/AG0TZWb7sT_-MCCPb-ptIVw&lt;/p&gt;
    &lt;p&gt;https://futurism.com/future-society/cory-doctorow-ai-collapse&lt;/p&gt;
    &lt;p&gt;https://apple.news/APxxQ5LmvRRGFGVRkP2NjXw&lt;/p&gt;
    &lt;p&gt;https://www.regenerator1.com/p/bubble-lessons-for-the-ai-era?utm_campaign=post&amp;amp;utm_medium=web&lt;/p&gt;
    &lt;p&gt;https://spyglass.org/ai-bubble/?ref=spyglass-newsletter&lt;/p&gt;
    &lt;p&gt;https://www.platformer.news/ai-bubble-2025/?ref=platformer-newsletter&lt;/p&gt;
    &lt;p&gt;https://ceodinner.substack.com/p/the-ai-wildfire-is-coming-its-going&lt;/p&gt;
    &lt;p&gt;https://www.nytimes.com/2025/11/20/opinion/ai-bubble-economy.html&lt;/p&gt;
    &lt;p&gt;https://nymag.com/intelligencer/article/inside-the-ai-bubble.html&lt;/p&gt;
    &lt;p&gt;https://www.brookings.edu/articles/is-there-an-ai-bubble/embed/#?secret=vNXMsybfZL&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://crazystupidtech.com/2025/11/21/boom-bubble-bust-boom-why-should-ai-be-different/"/><published>2025-11-21T20:30:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46008769</id><title>Pixar: The Early Days A never-before-seen 1996 interview</title><updated>2025-11-22T02:20:01.643144+00:00</updated><content>&lt;doc fingerprint="2501819f3360cdbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Pixar: The Early Days&lt;/head&gt;
    &lt;p&gt;A never-before-seen 1996 interview&lt;/p&gt;
    &lt;p&gt;November 18, 2025&lt;/p&gt;
    &lt;p&gt;To mark Toy Story’s 30th anniversary, we’re sharing a never-before-seen interview with Steve from November 22, 1996—exactly one year after the film debuted in theaters.&lt;/p&gt;
    &lt;p&gt;Toy Story was the world’s first entirely computer-animated feature-length film. An instant hit with audiences and critics, it also transformed Pixar, which went public the week after its premiere. Buoyed by Toy Story’s success, Pixar’s stock price closed at nearly double its initial offering, giving it a market valuation of approximately $1.5 billion and marking the largest IPO of 1995. The following year, Toy Story was nominated for three Academy Awards en route to winning a Special Achievement Oscar in March. In July, Pixar announced that it would close its television-commercial unit to focus primarily on feature films. By the time of the interview, the team had grown by 70 percent in less than a year; A Bug’s Life was in production; and behind the scenes, Steve was using his new leverage to renegotiate Pixar’s partnership with Disney.&lt;/p&gt;
    &lt;p&gt;In this footage, Steve reveals the long game behind Pixar’s seeming overnight success. With striking clarity, he explains how its business model gives artists and engineers a stake in their creations, and he reflects on what Disney’s hard-won wisdom taught him about focus and discipline. He also talks about the challenge of leading a team so talented that it inverts the usual hierarchy, the incentives that inspire people to stay with the company, and the deeper purpose that unites them all: to tell stories that last and put something of enduring value into the culture.&lt;/p&gt;
    &lt;p&gt;At Pixar, Steve collaborated closely with president Ed Catmull and refined a management approach centered on creating the conditions for talent to thrive. When he returned to Apple a few weeks after this interview, his experience at Pixar shaped how he saw his role as CEO: building a company on timeless ideas made new through technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay Hungry, Stay Foolish&lt;/head&gt;
    &lt;p&gt;Celebrating Steve’s timeless address&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://stevejobsarchive.com/stories/pixar-early-days"/><published>2025-11-21T20:45:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46008788</id><title>We remain alive also in a dead internet</title><updated>2025-11-22T02:20:01.501746+00:00</updated><content/><link href="https://slavoj.substack.com/p/why-we-remain-alive-also-in-a-dead-954"/><published>2025-11-21T20:46:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46009209</id><title>The Untold History of Arduino (2016)</title><updated>2025-11-22T02:20:01.354422+00:00</updated><content>&lt;doc fingerprint="b774c8d9b3b21372"&gt;
  &lt;main&gt;
    &lt;p&gt;日本語 · italiano · Deutsch · Français&lt;/p&gt;
    &lt;p&gt;Hello. My name is Hernando Barragán.&lt;/p&gt;
    &lt;p&gt;Through the years, and more recently due to the affairs between Arduino LLC and Arduino S.R.L., I have received a lot of questions from people about the history of Wiring and, of course, Arduino.&lt;/p&gt;
    &lt;p&gt;I was also shown this US Federal Courts website, which presents documents citing my work to support the plaintiff’s claims which, in my opinion, contribute to the distortion of information surrounding my work.&lt;/p&gt;
    &lt;p&gt;The history of Arduino has been told by many people, and no two stories match. I want to clarify some facts around the history of Arduino, with proper supported references and documents, to better communicate to people who are interested, about Arduino’s origin.&lt;/p&gt;
    &lt;p&gt;As well, I will attempt to correct some things that have distorted my role or work by pointing out common mistakes, misleading information, and poor journalism.&lt;/p&gt;
    &lt;p&gt;I will go through a summary of the history first, then I will answer a series of questions that I have been often asked over the years.&lt;/p&gt;
    &lt;p&gt;I started Wiring in 2003 as my Master’s thesis project at the Interaction Design Institute Ivrea (IDII) in Italy.&lt;/p&gt;
    &lt;p&gt;The objective of the thesis was to make it easy for artists and designers to work with electronics, by abstracting away the often complicated details of electronics so they can focus on their own objectives.&lt;/p&gt;
    &lt;p&gt;The full thesis document can be downloaded here: http://people.interactionivrea.org/h.barragan/thesis/thesis_low_res.pdf&lt;/p&gt;
    &lt;p&gt;Massimo Banzi and Casey Reas (known for his work on Processing) were supervisors for my thesis.&lt;/p&gt;
    &lt;p&gt;The project received plenty of attention at IDII, and was used for several other projects from 2004, up until the closure of the school in 2005.&lt;/p&gt;
    &lt;p&gt;Because of my thesis, I was proud to graduate with distinction; the only individual at IDII in 2004 to receive the distinction. I continued the development of Wiring while working at the Universidad de Los Andes in Colombia, where I began teaching as an instructor in Interaction Design.&lt;/p&gt;
    &lt;p&gt;What Wiring is, and why it was created can be extracted from the abstract section of my thesis document. Please keep in mind that it was 2003, and these premises are not to be taken lightly. You may have heard them before recited as proclamations:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“… Current prototyping tools for electronics and programming are mostly targeted to engineering, robotics and technical audiences. They are hard to learn, and the programming languages are far from useful in contexts outside a specific technology …”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;“… It can also be used to teach and learn computer programming and prototyping with electronics…”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;“Wiring builds on Processing…”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These were the key resulting elements of Wiring:&lt;/p&gt;
    &lt;p&gt;Through the thesis document, it is possible to understand the design process I followed. Considerable research and references to prior work has served as a basis for my work. To quickly illustrate the process, a few key points are provided below.&lt;/p&gt;
    &lt;p&gt;Have you ever wondered where those commands come from?&lt;/p&gt;
    &lt;p&gt;Probably one of the most distinctive things, that is widely known and used today by Arduino users in their sketches, is the set of commands I created as the language definition for Wiring.&lt;/p&gt;
    &lt;code&gt;pinMode()&lt;/code&gt;
    &lt;code&gt;digitalRead()&lt;/code&gt;
    &lt;code&gt;digitalWrite()&lt;/code&gt;
    &lt;code&gt;analogRead()&lt;/code&gt;
    &lt;code&gt;analogWrite()&lt;/code&gt;
    &lt;code&gt;delay()&lt;/code&gt;
    &lt;code&gt;millis()&lt;/code&gt;
    &lt;p&gt;Abstracting the microcontroller pins as numbers was, without a doubt, a major decision, possible because the syntax was defined prior to implementation in any hardware platform. All the language command naming and syntax were the result of an exhaustive design process I conducted, which included user testing with students, observation, analysis, adjustment and iteration.&lt;/p&gt;
    &lt;p&gt;As I developed the hardware prototypes, the language also naturally developed. It wasn’t until after the final prototype had been made that the language became solid and refined.&lt;/p&gt;
    &lt;p&gt;If you are still curious about the design process, it is detailed in the thesis document, including earlier stages of command naming and syntax that were later discarded.&lt;/p&gt;
    &lt;p&gt;From a designer’s point of view, this was probably the most difficult part to address. I asked for or bought evaluation boards from different microcontroller manufacturers.&lt;/p&gt;
    &lt;p&gt;Here are some key moments in the hardware design for Wiring.&lt;/p&gt;
    &lt;p&gt;The first prototype for Wiring used the Parallax Javelin Stamp microcontroller. It was a natural option since it was programmed in a subset of the Java language, which was already being used by Processing.&lt;/p&gt;
    &lt;p&gt;Problem: as described in the thesis document on page 40, compiling, linking and uploading of user’s programs relied on Parallax’s proprietary tools. Since Wiring was planned as open source software, the Javelin Stamp was simply not a viable option.&lt;/p&gt;
    &lt;p&gt;Photo of Javelin Stamp used for first prototype for Wiring hardware.&lt;/p&gt;
    &lt;p&gt;For the next prototypes, microcontrollers were chosen on a basis of availability of open source tools for compiling, linking and uploading the user’s code. This led to discarding the very popular Microchip PIC family of microcontrollers very early, because, at the time (circa 2003), Microchip did not have an open source toolchain.&lt;/p&gt;
    &lt;p&gt;For the second Wiring hardware prototype, the Atmel ARM-based AT91R40008 microcontroller was selected, which lead to excellent results. The first sketch examples were developed and command naming testing began. For example, &lt;code&gt;pinWrite()&lt;/code&gt; used to be the name of the now ubiquitous &lt;code&gt;digitalWrite()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The Atmel R40008 served as a test bed for the digital input/output API and the serial communications API, during my evaluation of its capabilities. The Atmel R40008 was a very powerful microcontroller, but was far too complex for a hands-on approach because it was almost impossible to solder by hand onto a printed circuit board.&lt;/p&gt;
    &lt;p&gt;For more information on this prototype, see page 42 in the thesis document.&lt;/p&gt;
    &lt;p&gt;Photo of Atmel AT91R40008 used for second Wiring hardware prototype.&lt;/p&gt;
    &lt;p&gt;The previous prototype experiments led to the third prototype, where the microcontroller was downscaled to one still powerful, yet with the possibility of tinkering with it without the requirements of specialized equipment or on-board extra peripherals.&lt;/p&gt;
    &lt;p&gt;I selected the Atmel ATmega128 microcontroller and bought an Atmel STK500 evaluation board with a special socket for the ATmega128.&lt;/p&gt;
    &lt;p&gt;Photo of Atmel STK500 with ATmega128 expansion.&lt;/p&gt;
    &lt;p&gt;Tests with the STK500 were immediately successful, so I bought a MAVRIC board from BDMICRO with the ATmega128 soldered. Brian Dean’s work on his MAVRIC boards were unparalleled at that time, and his work drove him to build a software tool to easily upload new programs to his board. It is still used today in the Arduino software, and is called “avrdude”.&lt;/p&gt;
    &lt;p&gt;As traditional COM ports were disappearing from computers, I selected FTDI hardware for communication through a USB port on the host computer. FTDI provided drivers for Windows, Mac OS X and Linux which was required for the Wiring environment to work on all platforms.&lt;/p&gt;
    &lt;p&gt;Photo of BDMICRO MAVRIC-II used for the third Wiring hardware prototype.&lt;/p&gt;
    &lt;p&gt;Photo of an FTDI FT232BM evaluation board used in the third Wiring hardware prototype.&lt;/p&gt;
    &lt;p&gt;The FTDI evaluation board was interfaced with the MAVRIC board and tested with the third Wiring prototype.&lt;/p&gt;
    &lt;p&gt;Testing with the BDMICRO MAVRIC-II board and FTDI-FT232BM.&lt;/p&gt;
    &lt;p&gt;In early 2004, based on the prototype using the MAVRIC board (Prototype 3), I used Brian Dean’s and Pascal Stang’s schematic designs as a reference to create the first Wiring board design. It had the following features:&lt;/p&gt;
    &lt;p&gt;I used Eagle PCB from Cadsoft to design the schematic and printed circuit board.&lt;/p&gt;
    &lt;p&gt;Wiring board printed circuit board layout.&lt;/p&gt;
    &lt;p&gt;Along with the third prototype, the final version of the API was tested and refined. More examples were added and I wrote the first LED blink example that is still used today as the first sketch that a user runs on an Arduino board to learn the environment. Even more examples were developed to support liquid crystal displays (LCDs), serial port communication, servo motors, etc. and even to interface Wiring with Processing via serial communication. Details can be found on page 50 in the thesis document.&lt;/p&gt;
    &lt;p&gt;In March 2004, 25 Wiring printed circuit boards were ordered and manufactured at SERP, and paid for by IDII.&lt;/p&gt;
    &lt;p&gt;I hand-soldered these 25 boards and started to conduct usability tests with some of my classmates at IDII. It was an exciting time!&lt;/p&gt;
    &lt;p&gt;Photos of the first Wiring board&lt;/p&gt;
    &lt;p&gt;After graduating from IDII in 2004, I moved back to Colombia, and began teaching as an instructor in Interaction Design at the Universidad de Los Andes. As I continued to develop Wiring, IDII decided to print and assemble a batch of 100 Wiring boards to teach physical computing at IDII in late 2004. Bill Verplank (a former IDII faculty member) asked Massimo Banzi to send 10 of the boards to me for use in my classes in Colombia.&lt;/p&gt;
    &lt;p&gt;In 2004, Faculty member Yaniv Steiner, former student Giorgio Olivero, and information designer consultant Paolo Sancis started the Instant Soup Project, based on Wiring at IDII.&lt;/p&gt;
    &lt;p&gt;In the autumn of 2004, Wiring was used to teach physical computing at IDII through a project called Strangely Familiar, consisting of 22 students, and 11 successful projects. Four faculty members ran the 4-week project:&lt;/p&gt;
    &lt;p&gt;It turned out to be a resounding success for both the students as well as the professors and teachers. Strangely Familiar demonstrated the potential of Wiring as an innovation platform for interaction design.&lt;/p&gt;
    &lt;p&gt;On December 16th, 2004, Bill Verplank sent an email to me saying:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[The projects] were wonderful. Everyone had things working. Five of the projects had motors in them! The most advanced (from two MIT grads - architect and mathematician) allowed drawing a profile in Proce55ing and feeling it with a wheel/motor run by Wiring…&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;It is clear that one of the elements of success was [the] use of the Wiring board.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here is the brief for the course:&lt;/p&gt;
    &lt;p&gt;Here is a booklet with the resulting projects:&lt;/p&gt;
    &lt;p&gt;Tug Tug phones by Haiyan Zhang (with Aram Armstrong)&lt;/p&gt;
    &lt;p&gt;Commitment Radio by David Chiu and Alexandra Deschamps-Sonsino&lt;/p&gt;
    &lt;p&gt;Speak Out by Tristam Sparks and Andreea Cherlaru (with Ana Camila Amorim)&lt;/p&gt;
    &lt;p&gt;Feel the Music I by James Tichenor and David A. Mellis&lt;/p&gt;
    &lt;p&gt;The Amazing All Band Radio by Oren Horev &amp;amp; Myriel Milicevic (with Marcos Weskamp)&lt;/p&gt;
    &lt;p&gt;In May 2005, I contracted Advanced Circuits in the USA to print the first 200 printed circuit boards outside of IDII, and assembled them in Colombia. I began selling and shipping boards to various schools and universities, and by the end of 2005, Wiring was being used around the world.&lt;/p&gt;
    &lt;p&gt;“Wiring’s Reach by 2005” graphic, provided by Collin Reisdorf&lt;/p&gt;
    &lt;p&gt;When IDII manufactured the first set of Wiring boards, the cost was probably around USD$50 each. (I don’t know what the actual cost was, as I wasn’t involved in the process. However, I was selling the boards from Colombia for about USD$60.) This was a considerable drop in price from the boards that were currently available, but it was still a significant cost for most people.&lt;/p&gt;
    &lt;p&gt;In 2005, Massimo Banzi, along with David Mellis (an IDII student at the time) and David Cuartielles, added support for the cheaper ATmega8 microcontroller to Wiring. Then they forked (or copied) the Wiring source code and started running it as a separate project, called Arduino.&lt;/p&gt;
    &lt;p&gt;There was no need to create a separate project, as I would have gladly helped them and developed support for the ATmega8 and any other microcontrollers. I had planned to do this all along.&lt;/p&gt;
    &lt;p&gt;I had inadvertantly taken a photo of some notes about my plans for Wiring, in the photo of Karmen Franinovic (former IDII student from 2002 to 2004) testing a stretch sensor for a lamp in March 2004.&lt;/p&gt;
    &lt;p&gt;Wiring and Arduino shared many of the early development done by Nicholas Zambetti, a former IDII student in the same class as David Mellis. For a brief time, Nicholas had been considered a member of the Arduino Team.&lt;/p&gt;
    &lt;p&gt;Around the same time, Gianluca Martino (he was a consultant at SERP, the printed circuit board factory at Ivrea where the first Wiring boards were made), joined the Arduino Team to help with manufacturing and hardware development. So, to reduce the cost of their boards, Gianluca, with some help from David Cuartielles, developed cheaper hardware by using the ATmega8.&lt;/p&gt;
    &lt;p&gt;Apparently this is the first “Arduino” prototype - dubbed Wiring Lite. I think Massimo Banzi designed this one, but I’m unsure.&lt;/p&gt;
    &lt;p&gt;Arduino Extreme v2 - “Second production version of the Arduino USB boards. This has been properly engineered by Gianluca Martino.”&lt;/p&gt;
    &lt;p&gt;Tom Igoe (a faculty member at the ITP at NYU2) was invited by Massimo Banzi to IDII for a workshop and became part of the Arduino Team.&lt;/p&gt;
    &lt;p&gt;To this day, I do not know exactly why the Arduino Team forked the code from Wiring. It was also puzzling why we didn’t work together. So, to answer the question, I was never asked to become a member of the Arduino Team.&lt;/p&gt;
    &lt;p&gt;Even though I was perplexed by the Arduino Team forking the code, I continued development on Wiring, and almost all of the improvements that had been made to Wiring, by me and plenty of contributors, were merged into the Arduino source code. I tried to ignore the fact that they were still taking my work and also wondered about the redundancy and waste of resources in duplicating efforts.&lt;/p&gt;
    &lt;p&gt;By the end of 2005, I started to work with Casey Reas on a chapter for the book “Processing: A Programming Handbook for Visual Artists and Designers.” The chapter presents a short history of electronics in the Arts. It includes examples for interfacing Processing with Wiring and Arduino. I presented those examples in both platforms and made sure the examples included worked for both Wiring and Arduino.&lt;/p&gt;
    &lt;p&gt;The book got a second edition in 2013 and the chapter was revised again by Casey and me, and the extension has been made available online since 2014.&lt;/p&gt;
    &lt;p&gt;Yes, each of them had experience with Wiring before creating Arduino.&lt;/p&gt;
    &lt;p&gt;Massimo Banzi taught with Wiring at IDII from 2004.&lt;/p&gt;
    &lt;p&gt;Massimo Banzi teaching interaction design at IDII with Wiring boards in 2004.&lt;/p&gt;
    &lt;p&gt;David Mellis was a student at IDII from 2004 to 2005.&lt;/p&gt;
    &lt;p&gt;A blurry version of David Mellis learning physical computing with Wiring in 2004.&lt;/p&gt;
    &lt;p&gt;In January 2005, IDII hired David Cuartielles to develop a couple of plug-in boards for the Wiring board, for motor control and bluetooth connectivity.&lt;/p&gt;
    &lt;p&gt;Two plug-in boards developed at IDII by David Cuartielles and his brother. Bluetooth shield on the left, and a motor controller shield on the right.&lt;/p&gt;
    &lt;p&gt;I showed early versions of Wiring to Tom Igoe during a visit to ITP in New York in 2003. At the time, he had no experience with Atmel hardware, as Tom was using PIC microcontrollers at ITP as an alternative to the costly platforms like Parallax Basic Stamp or Basic X. One of Tom’s recommendations at this visit was: “well, do it for PIC, because this is what we use here.”&lt;/p&gt;
    &lt;p&gt;Years later, in 2007, Tom Igoe released the first edition of the “Making Things Talk” book published by O’Reilly3, which presents the use of both Wiring and Arduino.&lt;/p&gt;
    &lt;p&gt;Gianluca Martino originally worked for SERP (the factory that made the first 25 Wiring circuit boards) and later he founded Smart Projects SRL (April 1st, 2004). Smart Projects made the first batch of 100 Wiring boards for IDII to teach physical computing in 2004.&lt;/p&gt;
    &lt;p&gt;Programma2003 was a Microchip PIC microcontroller board developed by Massimo Banzi in 2003. After using BasicX to teach Physical computing in the winter of 2002, Massimo decided to do a board using the PIC chip in 2003. The problem with the PIC microcontrollers was that there wasn’t an open source toolchain available at the time, to use a language like C to program them.&lt;/p&gt;
    &lt;p&gt;Programma2003 board designed by Massimo Banzi in 2003&lt;/p&gt;
    &lt;p&gt;Because of the lack of an open source toolchain, Massimo decided to use an environment called JAL (Just Another Language) to program the PIC microcontroller. JAL was created by Wouter van Ooijen.&lt;/p&gt;
    &lt;p&gt;It consisted of the JAL compiler, linker, uploader, bootloader and examples for the PIC. However, the software would only run on Windows.&lt;/p&gt;
    &lt;p&gt;To make JAL easier to use, Massimo used the base examples from JAL and simplified some of them for the distribution package for IDII.&lt;/p&gt;
    &lt;p&gt;However, in 2003, most students at IDII used Mac computers. So I volunteered to help Massimo by making a small and simple environment for Mac OS X so students with a Mac could use it as well.&lt;/p&gt;
    &lt;p&gt;In my thesis document, I characterized Programma2003 as a non-viable model to follow, since other more comprehensive tools were already available in the market. The main problems were:&lt;/p&gt;
    &lt;p&gt;It was impossible to know if it was powered or not (frustrating/dangerous in a learning environment) and an additional RS232 to USB expensive converter was required to connect it to a computer.&lt;/p&gt;
    &lt;p&gt;As a gesture to help Massimo’s Programma2003 project, I also wrote something I called Programma2003 Interface, which basically interfaced any serial communication between a microcontroller and a computer with the network. This expanded the prototyping toolbox at IDII. It allowed students to use software like Adobe Flash (formerly Macromedia) to communicate with a microcontroller.&lt;/p&gt;
    &lt;p&gt;I don’t know.&lt;/p&gt;
    &lt;p&gt;The reference to Wiring on the Arduino.cc website, although it has improved slightly over time, is misleading as it tries to attribute Wiring to Programma2003.&lt;/p&gt;
    &lt;p&gt;Arduino.cc website version of Arduino’s History from https://www.arduino.cc/en/Main/Credits&lt;/p&gt;
    &lt;p&gt;Adding to the confusion is this Flickr photo album by Massimo Banzi:&lt;/p&gt;
    &lt;p&gt;https://www.flickr.com/photos/mbanzi/albums/72157633136997919/with/8610131426/&lt;/p&gt;
    &lt;p&gt;It is called “Teaching: IDII 2004 Strangely Familiar”. Strangely Familiar was taught with Wiring (see above). This photo album seems to associate the Programma2003 with the class, but it was, in fact, never used. It is odd that the Wiring boards are absent from the album, however one Wiring board picture does appear.&lt;/p&gt;
    &lt;p&gt;It is no secret that the acknowledgement of Wiring has been very limited in the past. Back in 2013, at Open Hardware Summit at MIT, during the panel “Implications of Open Source Business: Forking and Attribution”, David Mellis acknowledges, for the first time, that the Arduino Team hadn’t done a very good job acknowledging Wiring. Unfortunately, he didn’t go into details why they hadn’t.&lt;/p&gt;
    &lt;p&gt;I’ve been quiet about everything that has happened with Arduino for a long time. But now that people are fraudulently saying that my work is their’s, I feel like I need to speak up about the past.&lt;/p&gt;
    &lt;p&gt;For example, in the ongoing case between Arduino LLC and Arduino S.R.L., there is a claim, by the Plaintiff, such that:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;34. Banzi is the creator of the Programma2003 Development Platform, a precursor of the many ARDUINO-branded products. See: http://sourceforge.net/projects/programma2003/. Banzi was also the Master’s Thesis advisor of Hernando Barragan whose work would result in the Wiring Development Platform which inspired Arduino.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here is what, in my opinion, is wrong with that claim:&lt;/p&gt;
    &lt;p&gt;Further on:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;39. The Founders, assisted by Nicholas Zambetti, another student at IDII, undertook and developed a project in which they designed a platform and environment for microcontroller boards (“Boards”) to replace the Wiring Development Project. Banzi gave the project its name, the ARDUINO project.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here are the questions I’d ask “The Founders:”&lt;/p&gt;
    &lt;p&gt;I know it might be done now and again, but, in my opinion, it is unethical and a bad example for academics to do something like this with the work of a student. Educators, more than anybody else, should avoid taking advantage of their student’s work. In a way, I still feel violated by “The Founders” for calling my work their’s.&lt;/p&gt;
    &lt;p&gt;It may be legal to take an open source software and hardware project’s model, philosophy, discourse, and the thousands of hours of work by its author, exert a branding exercise on it, and release it to the world as something “new” or “inspired”, but… is it right?&lt;/p&gt;
    &lt;p&gt;Someone once said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“If we don’t make things ultra clear, people draw their own conclusions and they become facts even if we never said anything like that.”4&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It seems to me that this is universally true, and especially if you mislead people with only slight alterations of the truth, you can have control over their conclusions.&lt;/p&gt;
    &lt;p&gt;Here are a couple of mainstream examples of misleading information.&lt;/p&gt;
    &lt;p&gt;http://blog.experientia.com/uploads/2013/10/Interaction_Ivrea_arduino.pdf&lt;/p&gt;
    &lt;p&gt;This diagram was produced to tell the story of the prototyping tools developed at IDII. It was beautifully done by Giorgio Olivero, using the content provided by the school in 2005, and released in 2006.&lt;/p&gt;
    &lt;p&gt;The projects presented in the red blobs, although they were made with Wiring, appear to be associated with Arduino at a time when Arduino didn’t even exist, nor was even close to being ready to do them.&lt;/p&gt;
    &lt;p&gt;Some of the authors of the projects inquired about the mistake, and why their projects were shifted to Arduino, but received no response.&lt;/p&gt;
    &lt;p&gt;Despite the fact that nothing was changed in this highly public document, I have to thank the support of the students who pointed it out and inquired about it.&lt;/p&gt;
    &lt;p&gt;Another very public piece of media from 2010 was The Arduino Documentary (written and directed by Raúl Alaejos, Rodrigo Calvo).&lt;/p&gt;
    &lt;p&gt;This one is very interesting, especially seeing it today in 2016. I think the idea of doing a documentary is very good, especially for a project with such a rich history.&lt;/p&gt;
    &lt;p&gt;Here are some parts that present some interesting contradictions:&lt;/p&gt;
    &lt;p&gt;1:45 - “We wanted it to be open source so that everybody could come and help, and contribute.” It is suggested here that Wiring was closed source. Because part of Wiring was based on Processing, and Processing was GPL open source, as well as all the libraries, Wiring, and hence Arduino, had to be open source. It was not an option to have it be closed source. Also, the insinuation that they made the software easier is misleading, since nothing changed in the language, which is the essence of the project’s simplicity.&lt;/p&gt;
    &lt;p&gt;3:20 - David Cuartielles already knew about Wiring, as he was hired to design two plug-in boards for it by IDII in 2005 as pointed out earlier in this document. David Mellis learned physical computing using Wiring as a student at IDII in 2004. Interestingly, Gianluca came in as the person who was able to design the board itself (he wasn’t just a contractor for manufacturing); he was part of the “Arduino Team”.&lt;/p&gt;
    &lt;p&gt;8:53 - David Cuartielles is presenting at the Media Lab in Madrid, in July 2005: “Arduino is the last project, I finished it last week. I talked to Ivrea’s technical director and told him: Wouldn’t it be great if we can do something we offer for free? he says - For free? - Yeah!” David comes across here as the author of a project that he completed “last week”, and convincing the “technical director” at IDII to offer it for free.&lt;/p&gt;
    &lt;p&gt;18:56 - Massimo Banzi:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For us at the beginning it was a specific need: we knew the school was closing and we were afraid that lawyers would show up one day and say - Everything here goes into a box and gets forgotten about. - So we thought - OK, if we open everything about this, then we can survive the closing of the school - So that was the first step.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This one is very special. It misleadingly presents the fact of making Arduino open source as the consequence of the school closing. This poses a question: why would a bunch of lawyers “put in a box” a project based on other open source projects? It is almost puerile. The problem is, common people might think this is true, forming altruistic reasons for the team to make Arduino open source.&lt;/p&gt;
    &lt;p&gt;There seems to be a trend in how the Arduino Team fails to recognize significant parties that contributed to their success.&lt;/p&gt;
    &lt;p&gt;In October 2013, Jan-Christoph Zoels (a former IDII faculty member) wrote to the IDII community mail list, a message presenting the article released at Core77 about the Intel-Arduino news on Wired UK:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A proud moment to see Intel referring to an Interaction Ivrea initiative.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;And a good investment too:&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Arduino development was started and developed at Interaction Design Institute Ivrea with an original funding of circa 250.000€. Another good decision was to keep Arduino as open source at the end of Interaction Ivrea in 2005 before merging with Domus.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To which Massimo Banzi responded:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I would like to point out that we never got any funding from Ivrea for Arduino (apart from buying 50 of them in the last year of the institute)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;250.000 EUR is ridiculous…&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;This article must be retracted now&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Sorry JC but you had nothing to do.with this…. You can’t possibly try to get credit for.something you hadn’t been involved with&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It was nice, however, to get this a few days later in the same email thread:&lt;/p&gt;
    &lt;p&gt;In this section, I just wanted to show a fraction of the many different articles (and other press) that have been written about Arduino, which include its history that is rarely told the same way twice.&lt;/p&gt;
    &lt;p&gt;So, please, read them at your leisure, and form your own opinions, and, definitely, ask questions!&lt;/p&gt;
    &lt;p&gt;It is rare to see well researched journalism these days. The articles below are excellent examples of that postulate.&lt;/p&gt;
    &lt;p&gt;In a 2008 Wired interview, Banzi explains how he did Arduino in a weekend:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The two decided to design their own board and enlisted one of Banzi’s students—David Mellis—to write the programming language for it. In two days, Mellis banged out the code; three days more and the board was complete. They called it the Arduino, after a nearby pub, and it was an instant hit with the students.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This article has been written without any fact checking. It certainly doesn’t help that the interviewee isn’t telling them the right information.&lt;/p&gt;
    &lt;p&gt;Here is a 2011 IEEE Spectrum article, titled “The Making of Arduino”.&lt;/p&gt;
    &lt;p&gt;Again, the history is taken verbatim from the interviewee. I was not contacted before the article was published, even though I was mentioned. And I doubt that anyone from IDII was contacted.&lt;/p&gt;
    &lt;p&gt;Just one of the many confusing parts of Arduino’s history is in this quote:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Since the purpose was to create a quick and easily accessible platform, they felt they’d be better off opening up the project to as many people as possible rather than keeping it closed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It was never closed.&lt;/p&gt;
    &lt;p&gt;A 2014 article from Circuits Today has a very confusing opening:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It was in the Interactive Design Institute [sic] that a hardware thesis was contributed for a wiring design by a Colombian student named Hernando Barragan. The title of the thesis was “Arduino–La rivoluzione dell’open hardware” (“Arduino – The Revolution of Open Hardware”). Yes, it sounded a little different from the usual thesis but none would have imagined that it would carve a niche in the field of electronics.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;A team of five developers worked on this thesis and when the new wiring platform was complete, they worked to make it much lighter, less expensive, and available to the open source community.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The title of my thesis is obviously wrong. There weren’t five “developers” working on the thesis. And the code was always open source.&lt;/p&gt;
    &lt;p&gt;Again, I wasn’t contacted for reference.&lt;/p&gt;
    &lt;p&gt;In a 2013 interview by Dale Dougherty with Massimo Banzi, once again the story changes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Wiring had an expensive board, about $100, because it used an expensive chip. I didn’t like that, and the student developer and I disagreed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In this version of the story by Massimo Banzi, Arduino originated from Wiring, but it is implied that I was insistent on having an expensive board.&lt;/p&gt;
    &lt;p&gt;Regarding the “disagreement”: I never had a discussion with Massimo Banzi about the board being too expensive. I wish that he and I would have had more discussions on such matters, as I had with other advisors and colleagues, as I find it very enriching. The closest thing to a disagreement took place after a successful thesis presentation event, where Massimo showed some odd behaviour towards me. Because he was my advisor, I was at a disadvantage, but I asked Massimo why he was behaving badly towards me, to which I received no answer. I felt threatened, and it was very awkward.&lt;/p&gt;
    &lt;p&gt;His odd behaviour extended to those who collaborated with me on Wiring later on.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I decided that we could make an open source version of Wiring, starting from scratch. I asked Gianluca Martino [now one of the five Arduino partners] to help me manufacture the first prototypes, the first boards.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here, Massimo is again implying that Wiring wasn’t open source, which it was. And also that they would build the software from “scratch”, which they didn’t.&lt;/p&gt;
    &lt;p&gt;I understand how easy it is to engage people with good storytelling and compelling tales, but academics are expected to do their homework, and at least check the facts behind unsubstantiated statements.&lt;/p&gt;
    &lt;p&gt;In this book, Making Futures: Marginal Notes on Innovation, Design, and Democracy Hardcover – October 31, 2014 by Pelle Ehn (Editor), Elisabet M. Nilsson (Editor), Richard Topgaard (Editor):&lt;/p&gt;
    &lt;p&gt;Chapter 8: How Deep is Your Love? On Open-Source Hardware (David Cuartielles)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In 2005, at the Interaction Design Institute Ivrea, we had the vision that making a small prototyping platform aimed at designers would help them getting a better understanding of technology.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;David Cuartielles’ version of Arduino’s history doesn’t even include Wiring.&lt;/p&gt;
    &lt;p&gt;This book has been released chapter by chapter under Creative Commons: http://dspace.mah.se/handle/2043/17985&lt;/p&gt;
    &lt;p&gt;Wiring as predecessor to Arduino:&lt;/p&gt;
    &lt;p&gt;Interview with Ben Fry and Casey Reas:&lt;/p&gt;
    &lt;p&gt;Safari Books Online, Casey Reas, Getting Started with Processing, Chapter One, Family Tree:&lt;/p&gt;
    &lt;p&gt;Nicholas Zambetti Arduino Project Page:&lt;/p&gt;
    &lt;p&gt;(Nicholas did a lot of work with both Wiring and Arduino)&lt;/p&gt;
    &lt;p&gt;Wired Italy - What’s happening in Arduino?&lt;/p&gt;
    &lt;p&gt;http://www.wired.it/gadget/computer/2015/02/12/arduino-nel-caos-situazione/&lt;/p&gt;
    &lt;p&gt;Repubblica Italy - Massimo Banzi: “The Reason of the War for Arduino”&lt;/p&gt;
    &lt;p&gt;Makezine - Massimo Banzi Fighting for Arduino&lt;/p&gt;
    &lt;p&gt;http://makezine.com/2015/03/19/massimo-banzi-fighting-for-arduino/&lt;/p&gt;
    &lt;p&gt;Hackaday - Federico Musto of Arduino SRL discusses Arduino legal situation&lt;/p&gt;
    &lt;p&gt;http://hackaday.com/2015/07/23/hackaday-interviews-federico-musto-of-arduino-srl/&lt;/p&gt;
    &lt;p&gt;Hackaday - Federico Musto of Arduino SRL shows us new products and new directions&lt;/p&gt;
    &lt;p&gt;Massimo going to Ted Talk – candid (2012-08-06)&lt;/p&gt;
    &lt;p&gt;https://www.youtube.com/watch?v=tZxY8_CNiCw&lt;/p&gt;
    &lt;p&gt;This is a candid view of Massimo just before performing at a TED Talk. You can make your own mind up about the majority of the video, however, the most interesting comment, in my opinion, is at the end, where he says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;… Innovation without asking for permission. So, in a way, Open Source allows you to be innovative without asking for permission.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Thank you for taking time to read this. I think it is very important, not just in the academic world, to properly acknowledge the origin of things. As I learned from fantastic educators, doing this properly not only enriches your work, but also positions it better to allow others to investigate and see where your ideas come from. Maybe they will find other alternatives or improve what was done and better position their own ideas.&lt;/p&gt;
    &lt;p&gt;Personally, watching the outreach of what I created back in 2003 in so many different contexts, seeing those commands bringing to life people’s ideas and creations from all over the world, has brought me so many satisfactions, surprises, new questions, ideas, awareness and friendships. I am thankful for that.&lt;/p&gt;
    &lt;p&gt;I think it is important to know the past to avoid making the same mistakes in the future. Sometimes I wish I would have had a chance to talk about this differently, for a different motif. Instead, many times I have come across journalists and common people compromised in their independence. Either they had direct business with Arduino, or simply wanted to avoid upsetting Massimo Banzi. Or there are the close-minded individuals following a cause and refusing to see or hear anything different from what they believe. And then there are the individuals who are just part of the crowd that reproduce what they are told to reproduce. For those others, this document is an invitation to trust your curiosity, to question, to dig deeper in whatever interests you and is important to you as an individual or as a member of a community.&lt;/p&gt;
    &lt;p&gt;I’ll see you soon,&lt;/p&gt;
    &lt;p&gt;Hernando.&lt;/p&gt;
    &lt;p&gt;The notion of a “Sketch” within the context of writing programs comes from Processing and previously from Design by Numbers (DBN). It was extended by Wiring within the context of prototyping with electronics or “sketching” with hardware. ↩︎&lt;/p&gt;
    &lt;p&gt;Interactive Telecommunications Program at New York University ↩︎&lt;/p&gt;
    &lt;p&gt;Page 34, ISBN-13: 978-0596510510 ISBN-10: 0596510519, http://www.amazon.com/Making-Things-Talk-Practical-Connecting/dp/0596510519/ref=sr_1_2?ie=UTF8&amp;amp;sr=8-2&amp;amp;keywords=Making+Things+Talk ↩︎&lt;/p&gt;
    &lt;p&gt;https://groups.google.com/a/arduino.cc/d/msg/developers/HEKecd0qhS4/nADS2jW6DgAJ ↩︎&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arduinohistory.github.io/"/><published>2025-11-21T21:29:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46009660</id><title>Is Matrix Multiplication Ugly?</title><updated>2025-11-22T02:20:01.240574+00:00</updated><content>&lt;doc fingerprint="b305911521a69631"&gt;
  &lt;main&gt;
    &lt;p&gt;A few weeks ago I was minding my own business, peacefully reading a well-written and informative article about artificial intelligence, when I was ambushed by a passage in the article that aroused my pique. That’s one of the pitfalls of knowing too much about a topic a journalist is discussing; journalists often make mistakes that most readers wouldn’t notice but that raise the hackles or at least the blood pressure of those in the know.&lt;/p&gt;
    &lt;p&gt;The article in question appeared in The New Yorker. The author, Stephen Witt, was writing about the way that your typical Large Language Model, starting from a blank slate, or rather a slate full of random scribbles, is able to learn about the world, or rather the virtual world called the internet. Throughout the training process, billions of numbers called weights get repeatedly updated so as to steadily improve the model’s performance. Picture a tiny chip with electrons racing around in etched channels, and slowly zoom out: there are many such chips in each server node and many such nodes in each rack, with racks organized in rows, many rows per hall, many halls per building, many buildings per campus. It’s a sort of computer-age version of Borges’ Library of Babel. And the weight-update process that all these countless circuits are carrying out depends heavily on an operation known as matrix multiplication.&lt;/p&gt;
    &lt;p&gt;Witt explained this clearly and accurately, right up to the point where his essay took a very odd turn.&lt;/p&gt;
    &lt;p&gt;HAMMERING NAILS&lt;/p&gt;
    &lt;p&gt;Here’s what Witt went on to say about matrix multiplication:&lt;/p&gt;
    &lt;p&gt;“‘Beauty is the first test: there is no permanent place in the world for ugly mathematics,’ the mathematician G. H. Hardy wrote, in 1940. But matrix multiplication, to which our civilization is now devoting so many of its marginal resources, has all the elegance of a man hammering a nail into a board. It is possessed of neither beauty nor symmetry: in fact, in matrix multiplication, a times b is not the same as b times a.”&lt;/p&gt;
    &lt;p&gt;The last sentence struck me as a bizarre non sequitur, somewhat akin to saying “Number addition has neither beauty nor symmetry, because when you write two numbers backwards, their new sum isn’t just their original sum written backwards; for instance, 17 plus 34 is 51, but 71 plus 43 isn’t 15.”&lt;/p&gt;
    &lt;p&gt;The next day I sent the following letter to the magazine:&lt;/p&gt;
    &lt;p&gt;“I appreciate Stephen Witt shining a spotlight on matrices, which deserve more attention today than ever before: they play important roles in ecology, economics, physics, and now artificial intelligence (“Information Overload”, November 3). But Witt errs in bringing Hardy’s famous quote (“there is no permanent place in the world for ugly mathematics”) into his story. Matrix algebra is the language of symmetry and transformation, and the fact that a followed by b differs from b followed by a is no surprise; to expect the two transformations to coincide is to seek symmetry in the wrong place — like judging a dog’s beauty by whether its tail resembles its head. With its two-thousand-year-old roots in China, matrix algebra has secured a permanent place in mathematics, and it passes the beauty test with flying colors. In fact, matrices are commonplace in number theory, the branch of pure mathematics Hardy loved most.”&lt;/p&gt;
    &lt;p&gt;Confining my reply to 150 words required some finesse. Notice for instance that the opening sentence does double duty: it leavens my many words of negative criticism with a few words of praise, and it stresses the importance of the topic, preëmptively1 rebutting editors who might be inclined to dismiss my correction as too arcane to merit publication.&lt;/p&gt;
    &lt;p&gt;I haven’t heard back from the editors, and I don’t expect to. Regardless, Witt’s misunderstanding deserves a more thorough response than 150 words can provide. Let’s see what I can do with 1500 words and a few pictures.&lt;/p&gt;
    &lt;p&gt;THE GEOMETRY OF TRANSFORMATIONS&lt;/p&gt;
    &lt;p&gt;As a static object, matrices are “just” rectangular arrays of numbers, but that doesn’t capture what they’re really about. If I had to express the essence of matrices in a single word, that word would be “transformation”.&lt;/p&gt;
    &lt;p&gt;One example of a transformation is the operation f that takes an image in the plane and flips it from left to right, as if in a vertical mirror.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Another example is the operation g that that takes an image in the plane and reflects it across a diagonal line that goes from lower left to upper right.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The key thing to notice here is that the effect of f followed by g is different from the effect of g followed by f. To see why, write a capital R on one side of a square piece of paper–preferably using a dark marker and/or translucent paper, so that you can still see the R even when the paper has been flipped over–and apply f followed by g; you’ll get the original R rotated by 90 degrees clockwise. But if instead, starting from that original R, you were to apply g followed by f, you’d get the original R rotated by 90 degrees counterclockwise.&lt;/p&gt;
    &lt;p&gt;Same two operations, different outcomes! Symbolically we write g ◦ f ≠ f ◦ g, where g ◦ f means “First do f, then do g” and f ◦ g means “First do g, then f”.2 The symbol ◦ denotes the meta-operation (operation-on-operations) called composition.&lt;/p&gt;
    &lt;p&gt;The fact that the order in which transformations are applied can affect the outcome shouldn’t surprise you. After all, when you’re composing a salad, if you forget to pour on salad dressing until after you’ve topped the base salad with grated cheese, your guests will have a different dining experience than if you’d remembered to pour on the dressing first. Likewise, when you’re composing a melody, a C-sharp followed by a D is different from a D followed by a C-sharp. And as long as mathematicians used the word “composition” rather than “multiplication”, nobody found it paradoxical that in many contexts, order matters.&lt;/p&gt;
    &lt;p&gt;THE ALGEBRA OF MATRICES&lt;/p&gt;
    &lt;p&gt;If we use the usual x, y coordinates in the plane, the geometric operation f can be understood as the numerical operation that sends the pair (x, y) to the pair (−x, y), which we can represented via the 2-by-2 array&lt;/p&gt;
    &lt;p&gt;where more generally the array&lt;/p&gt;
    &lt;p&gt;stands for the transformation that sends the pair (x, y) to the pair (ax+by, cx+dy). This kind of array is called a matrix, and when we want to compose two operations like f and g together, all we have to do is combine the associated matrices under the rule that says that the matrix&lt;/p&gt;
    &lt;p&gt;composed with the matrix&lt;/p&gt;
    &lt;p&gt;equals the matrix&lt;/p&gt;
    &lt;p&gt;For more about where this formula comes from, see my Mathematical Enchantments essay “What Is A Matrix?”.&lt;/p&gt;
    &lt;p&gt;There’s nothing special about 2-by-2 matrices; you could compose two 3-by-3 matrices, or even two 1000-by-1000 matrices. Going in the other direction (smaller instead of bigger), if you look at 1-by-1 matrices, the composition of&lt;/p&gt;
    &lt;p&gt;and&lt;/p&gt;
    &lt;p&gt;is just&lt;/p&gt;
    &lt;p&gt;so ordinary number-multiplication arises as a special case of matrix composition; turning this around, we can see matrix-composition as a sort of generalized multiplication. So it was natural for mid-19th-century mathematicians to start using words like “multiply” and “product” instead of words like “compose” and “composition”, at roughly the same time they stopped talking about “substitutions” and “tableaux” and started to use the word “matrices”.&lt;/p&gt;
    &lt;p&gt;In importing the centuries-old symbolism for number multiplication into the new science of linear algebra, the 19th century algebraists were saying “Matrices behave kind of like numbers,” with the proviso “except when they don’t”. Witt is right when he says that when A and B are matrices, A times B is not always equal to B times A. Where he’s wrong is in asserting that is a blemish on linear algebra. Many mathematicians regard linear algebra as one of the most elegant sub-disciplines of mathematics ever devised, and it often serves as a role model for the kind of sleekness that a new mathematical discipline should strive to achieve. If you dislike matrix multiplication because AB isn’t always equal to BA, it’s because you haven’t yet learned what matrix multiplication is good for in math, physics, and many other subjects. It’s ironic that Witt invokes the notion of symmetry to disparage matrix multiplication, since matrix theory and an allied discipline called group theory are the tools mathematicians use in fleshing out our intuitive ideas about symmetry that arise in art and science.&lt;/p&gt;
    &lt;p&gt;So how did an intelligent person like Witt go so far astray?&lt;/p&gt;
    &lt;p&gt;PROOFS VS CALCULATIONS&lt;/p&gt;
    &lt;p&gt;I’m guessing that part of Witt’s confusion arises from the fact that actually multiplying matrices of numbers to get a matrix of bigger numbers can be very tedious, and tedium is psychologically adjacent to distaste and a perception of ugliness. But the tedium of matrix multiplication is tied up with its symmetry (whose existence Witt mistakenly denies). When you multiply two n-by-n matrices A and B in the straightforward way, you have to compute n2 numbers in the same unvarying fashion, and each of those n2 numbers is the sum of n terms, and each of those n terms is the product of an element of A and an element of B in a simple way. It’s only human to get bored and inattentive and then make mistakes because the process is so repetitive. We tend to think of symmetry and beauty as synonyms, but sometimes excessive symmetry breeds ennui; repetition in excess can be repellent. Picture the Library of Babel and the existential dread the image summons.&lt;/p&gt;
    &lt;p&gt;G. H. Hardy, whose famous remark Witt quotes, was in the business of proving theorems, and he favored conceptual proofs over calculational ones. If you showed him a proof of a theorem in which the linchpin of your argument was a 5-page verification that a certain matrix product had a particular value, he’d say you didn’t really understand your own theorem; he’d assert that you should find a more conceptual argument and then consign your brute-force proof to the trash. But Hardy’s aversion to brute force was specific to the domain of mathematical proof, which is far removed from math that calculates optimal pricing for annuities or computes the wind-shear on an airplane wing or fine-tunes the weights used by an AI. Furthermore, Hardy’s objection to your proof would focus on the length of the calculation, and not on whether the calculation involved matrices. If you showed him a proof that used 5 turgid pages of pre-19th-century calculation that never mentioned matrices once, he’d still say “Your proof is a piece of temporary mathematics; it convinces the reader that your theorem is true without truly explaining why the theorem is true.”&lt;/p&gt;
    &lt;p&gt;If you forced me at gunpoint to multiply two 5-by-5 matrices together, I’d be extremely unhappy, and not just because you were threatening my life; the task would be inherently unpleasant. But the same would be true if you asked me to add together a hundred random two-digit numbers. It’s not that matrix-multiplication or number-addition is ugly; it’s that such repetitive tasks are the diametrical opposite of the kind of conceptual thinking that Hardy loved and I love too. Any kind of mathematical content can be made stultifying when it’s stripped of its meaning and reduced to mindless toil. But that casts no shade on the underlying concepts. When we outsource number-addition or matrix-multiplication to a computer, we rightfully delegate the soul-crushing part of our labor to circuitry that has no soul. If we could peer into the innards of the circuits doing all those matrix multiplications, we would indeed see a nightmarish, Borgesian landscape, with billions of nails being hammered into billions of boards, over and over again. But please don’t confuse that labor with mathematics.&lt;/p&gt;
    &lt;p&gt;Join the discussion of this essay over at Hacker News!&lt;/p&gt;
    &lt;p&gt;This essay is related to chapter 10 (“Out of the Womb”) of a book I’m writing, tentatively called “What Can Numbers Be?: The Further, Stranger Adventures of Plus and Times”. If you think this sounds interesting and want to help me make the book better, check out http://jamespropp.org/readers.pdf. And as always, feel free to submit comments on this essay at the Mathematical Enchantments WordPress site!&lt;/p&gt;
    &lt;p&gt;ENDNOTES&lt;/p&gt;
    &lt;p&gt;#1. Note the New Yorker-ish diaresis in “preëmptively”: as long as I’m being critical, I might as well be diacritical.&lt;/p&gt;
    &lt;p&gt;#2. I know this convention may seem backwards on first acquaintance, but this is how ◦ is defined. Blame the people who first started writing things like “log x” and “cos x“, with the x coming after the name of the operation. This led to the notation f(x) for the result of applying the function f to the number x. Then the symbol for the result of applying g to the result of applying f to x is g(f(x)); even though f is performed first, “f” appears to the right of “g“. From there, it became natural to write the function that sends x to g(f(x)) as “g ◦ f“.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mathenchant.wordpress.com/2025/11/21/is-matrix-multiplication-ugly/"/><published>2025-11-21T22:17:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46009894</id><title>Personal blogs are back, should niche blogs be next?</title><updated>2025-11-22T02:20:01.068369+00:00</updated><content>&lt;doc fingerprint="3b8090076bc54e9f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Personal blogs are back, should niche blogs be next?&lt;/head&gt;
    &lt;p&gt;20 November 2025&lt;/p&gt;
    &lt;p&gt;When it comes to blogging there are few rules. Write content that is somehow meaningful might be one of them though. I think it’s down to the individual to determine what constitutes meaningful.&lt;/p&gt;
    &lt;p&gt;In the hey-day, the so-called golden age of blogging, there were plenty of people prepared to offer definitions of meaningful, and how to write accordingly. It was natural. The web was once awash with all sorts of blogs. Likewise people who wanted to show others how to blog “successfully”.&lt;/p&gt;
    &lt;p&gt;Again, the definition of successful resided with the individual, but it was obvious this involved monetary return for some people. And why not. If you’re going to invest time and energy in creating a resource that is useful to other people, why shouldn’t you earn money, make a living even, from it?&lt;/p&gt;
    &lt;p&gt;One of these people blogging about blogging was Melbourne based Australian writer and author Darren Rowse, who launched his blogging resource Problogger in 2004. Without going into detail, because you can look it up for yourself, Rowse, as one of the earlier bloggers about blogging, did, and still does presumably, rather well for himself.&lt;/p&gt;
    &lt;p&gt;Rowse’s writing, and that of his contributors, attracted numerous readers keen to learn what they could about blogging, and the potential to make money from it.&lt;/p&gt;
    &lt;p&gt;Problogger is what’s called a niche blog. As a blog about blogging, it has a reasonably singular focus. Some people considered this niche principle to be a core tenet of blogging. There was this idea, in the earlier days of blogging, which possibly still persists, that blogs would do better if they had a speciality. Not only were search engines said to be in favour the approach, but the author of a speciality, or niche blog, would generally be considered to be an expert, of some sort, in their field.&lt;/p&gt;
    &lt;p&gt;A master of one trade, rather than the proverbial jack of all trades.&lt;/p&gt;
    &lt;p&gt;Regardless, the world was once full of blogs on every topic imaginable. It was a great time to be alive. If you wanted to learn about something in particular, there was a blog for you. Some publications featured quality content, others required a little fact checking, while some were definitely to be taken with a pinch of salt.&lt;/p&gt;
    &lt;p&gt;But niche blogging was never a format that suited everyone. There are people who did, still do, well, writing about a range, sometimes a wide range, of topics. Kottke is one of the better known blogs that does not have a specific speciality. Here, the publication itself is the speciality. To repeat what I wrote in the first sentence of this article: the rules of blogging are few.&lt;/p&gt;
    &lt;p&gt;But the facets of blogging covered at Problogger, and numerous other similar websites, usually only applied to blogs of a commercial nature. That’s not to say one or two personal bloggers might have looked at the tips posted there for increasing their audience, or improving their writing though. But in my view, personal bloggers were not, are not, part of Problogger’s target audience.&lt;/p&gt;
    &lt;p&gt;It’s been a long time since I last wrote about Problogger, let alone visited the website, maybe fifteen plus years, but a recent mention of it by Kev Quick, via ldstephens, caught my eye. But I don’t believe Rowse is being critical, in any way, of personal bloggers because they do not adhere to a niche or speciality publishing format. That’s not what Problogger, or Rowse, is about.&lt;/p&gt;
    &lt;p&gt;But this started me thinking, and writing another of my long posts.&lt;/p&gt;
    &lt;p&gt;In an age where social media, and influencers, have usurped blogs and their A-List authors, in the jostle for supremacy, it has to be wondered what role websites like Problogger still have. Only a handful of blogs generate liveable incomes today. Despite the doom and gloom though, the form has not completely died off. A backlash against social media, and a growing IndieWeb/SmallWeb community, has precipitated a revival in personal websites.&lt;/p&gt;
    &lt;p&gt;This is a largely non-commercial movement. Of course, there’s nothing wrong with personal websites. Many of us started out with them in the early days of the web. But the web was not only intended for personal journals. It was a vehicle for sharing all manner of information. The web could also empower individuals, and partnerships, to not only set up shop online, be that blogs, or quite literally shops, but potentially make a living at the same time.&lt;/p&gt;
    &lt;p&gt;But with the revival of personal blogs well underway, I think it’s time to bring niche blogs back into the fold. I’m talking about well written, quality, topic focused resources. This is material fast vanishing from the web, leaving ever diminishing options to source useful and accurate information. What are the alternatives? The misinformation morass that is social media? Being served AI generated summaries in response to search engine queries? A web choke full of AI slop?&lt;/p&gt;
    &lt;p&gt;At the same time, I’m not advocating for a return of niche blogs plastered with adverts, and popup boxes urging visitors to subscribe to say a newsletter, before they’ve even had a chance to blink at what they came to read.&lt;/p&gt;
    &lt;p&gt;I’m talking about work produced by independent writers, with an interest in their subject matter, who are not backed by large media organisations, or private equity. This is bringing back reliable sources of information, that also recompenses the content writers in some way. Hopefully we’ve learned a few lessons about monetisation since the earlier wave of niche blogging. We know it is possible to generate revenue without compromising the reader experience.&lt;/p&gt;
    &lt;p&gt;A resurgence in personal blogging is the first step in rebuilding a vibrant, thriving, web, of if you like, blogosphere. Now the focus needs to be on restoring the flow of accessible and trusted information.&lt;/p&gt;
    &lt;p&gt;RELATED CONTENT&lt;/p&gt;
    &lt;p&gt;blogs, history, IndieWeb, self publishing, SmallWeb, technology, trends&lt;/p&gt;
    &lt;head rend="h3"&gt;There's 2 comments on this post&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt; On 22 November 2025 at 11:34 AM, Jorge Arango said:&lt;p&gt;Thanks for sharing. I’d like to believe a resurgence of personal blogs is underway. Is there data that substantiates this claim?&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://disassociated.com/personal-blogs-back-niche-blogs-next/"/><published>2025-11-21T22:40:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46009994</id><title>California DMV approves map increase in Waymo driverless operations</title><updated>2025-11-22T02:20:00.917203+00:00</updated><content>&lt;doc fingerprint="3586783b38cd45b0"&gt;
  &lt;main&gt;
    &lt;p&gt;Approved autonomous vehicle platforms to conduct driverless testing and deployment operations in all approved operational design domains (ODD) in California.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Make&lt;/cell&gt;
        &lt;cell role="head"&gt;Model Years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MakeJaguar I-Pace&lt;/cell&gt;
        &lt;cell&gt;Model Years2021 and 2024&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;MakeZeekr RT&lt;/cell&gt;
        &lt;cell&gt;Model Years2022 and 2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Hours of Operation:&lt;/p&gt;
    &lt;p&gt;All times of day and night&lt;/p&gt;
    &lt;p&gt;ODD Characteristics:&lt;/p&gt;
    &lt;p&gt;All rain, fog, and other conditions&lt;/p&gt;
    &lt;p&gt;All Speeds&lt;/p&gt;
    &lt;p&gt;Approved ODD Maps:&lt;/p&gt;
    &lt;p&gt;Approved Cities and Counties&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;City&lt;/cell&gt;
        &lt;cell role="head"&gt;County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLivermore&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAlameda&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAlbany&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBerkeley&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDublin&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEmeryville&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFremont&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHayward&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNewark&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityOakland&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPiedmont&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPleasanton&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Leandro&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityUnion City&lt;/cell&gt;
        &lt;cell&gt;CountyAlameda County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAntioch&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBrentwood&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityClayton&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityConcord&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDanville&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEl Cerrito&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHercules&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLafayette&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMartinez&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMoraga&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityOakley&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityOrinda&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPinole&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPittsburg&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPleasant Hill&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRichmond&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Pablo&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Ramon&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWalnut Creek&lt;/cell&gt;
        &lt;cell&gt;CountyContra Costa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAgoura Hills&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityArcadia&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityArtesia&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAzusa&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBaldwin Park&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBellflower&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBradbury&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBurbank&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCalabasas&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCerritos&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityClaremont&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCovina&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDiamond Bar&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDuarte&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEl Monte&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityGlendora&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHawaiian Gardens&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHidden Hills&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityIndustry&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityIrwindale&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Cañada Flintridge&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Habra Heights&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Mirada&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Puente&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Verne&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLakewood&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLomita&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMalibu&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMonrovia&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMontebello&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNorwalk&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPalos Verdes Estates&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPasadena&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPico Rivera&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPomona&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRancho Palos Verdes&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRolling Hills&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRolling Hills Estates&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRosemead&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Dimas&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Fernando&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Gabriel&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Marino&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySanta Clarita&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySanta Fe Springs&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySierra Madre&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySignal Hill&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySouth El Monte&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySouth Pasadena&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityTemple City&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWalnut&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWest Covina&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWestlake Village&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWhittier&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAlhambra&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBell&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBell Gardens&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCarson&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCommerce&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCompton&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDowney&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEl Segundo&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityGardena&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityGlendale&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHermosa Beach&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLong Beach&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLos Angeles&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityManhattan Beach&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMonterey Park&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityParamount&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRedondo Beach&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySanta Monica&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySouth Gate&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityTorrance&lt;/cell&gt;
        &lt;cell&gt;County Los Angeles County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBelvedere&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCorte Madera&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFairfax&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLarkspur&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMill Valley&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNovato&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRoss&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Anselmo&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Rafael&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySausalito&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityTiburon&lt;/cell&gt;
        &lt;cell&gt;CountyMarin County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAmerican Canyon&lt;/cell&gt;
        &lt;cell&gt;CountyNapa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCalistoga&lt;/cell&gt;
        &lt;cell&gt;CountyNapa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNapa&lt;/cell&gt;
        &lt;cell&gt;CountyNapa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySt. Helena&lt;/cell&gt;
        &lt;cell&gt;CountyNapa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityYountville&lt;/cell&gt;
        &lt;cell&gt;CountyNapa County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAliso Viejo&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityAnaheim&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBrea&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBuena Park&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCosta Mesa&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCypress&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDana Point&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFountain Valley&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFullerton&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityGarden Grove&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHuntington Beach&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityIrvine Orange&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Habra Orange&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Palma Orange&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLaguna Beach&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLaguna Hills&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLaguna Niguel&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLaguna Woods&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLake Forest&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLos Alamitos&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMission Viejo&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNewport Beach&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityOrange&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPlacentia&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRancho Santa Margarita&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Clemente&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Juan Capistrano&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySanta Ana&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySeal Beach&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityStanton&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityTustin&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityVilla Park&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWestminster&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityYorba Linda&lt;/cell&gt;
        &lt;cell&gt;CountyOrange County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCorona&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEastvale&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityJurupa Valley&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLake Elsinore&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMurrieta&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNorco&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPechanga Reservation&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRiverside&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityTemecula&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWildomar&lt;/cell&gt;
        &lt;cell&gt;CountyRiverside County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCitrus Heights&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityElk Grove&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFolsom&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityGalt&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityIsleton&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRancho Cordova&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySacramento&lt;/cell&gt;
        &lt;cell&gt;CountySacramento County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityChino Hills&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFontana&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMontclair&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityOntario&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRancho Cucamonga&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRialto&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityUpland&lt;/cell&gt;
        &lt;cell&gt;CountySan Bernardino County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBarona Reservation&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCapitan Grande&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCarlsbad&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityChula Vista&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCoronado&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDel Mar&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEl Cajon&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEncinitas&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEscondido&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityImperial Beach&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLa Mesa&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLemon Grove&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityNational City&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityOceanside&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPoway&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Diego&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Marcos&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySantee&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySolana Beach&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySycuan Reservation&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityVista&lt;/cell&gt;
        &lt;cell&gt;CountySan Diego County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Francisco&lt;/cell&gt;
        &lt;cell&gt;CountySan Francisco County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHalf Moon&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBrisbane&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBurlingame&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityEast Palo Alto&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFoster City&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMenlo Park&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPacifica&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRedwood City&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Mateo&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySouth San Francisco&lt;/cell&gt;
        &lt;cell&gt;CountySan Mateo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMilpitas&lt;/cell&gt;
        &lt;cell&gt;CountySanta Clara County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMountain View&lt;/cell&gt;
        &lt;cell&gt;CountySanta Clara County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPalo Alto Santa&lt;/cell&gt;
        &lt;cell&gt;CountySanta Clara County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySan Jose&lt;/cell&gt;
        &lt;cell&gt;CountySanta Clara County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySunnyvale&lt;/cell&gt;
        &lt;cell&gt;CountySanta Clara County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityUnincorporated Area (Lexington&lt;p&gt;Hills area, overlapping Santa&lt;/p&gt;&lt;p&gt;Clara and Santa Cruz Counties)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;CountySanta Cruz County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityBenicia&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDixon&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityFairfield&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRio Vista&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySuisun City&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityVacaville&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityVallejo&lt;/cell&gt;
        &lt;cell&gt;County Solano County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCloverdale&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCotati&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDry Creek Rancheria&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityHealdsburg&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityLytton Rancheria&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityPetaluma&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRohnert Park&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySanta Rosa&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySebastopol&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySonoma&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityStewarts Point Rancheria&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWindsor&lt;/cell&gt;
        &lt;cell&gt;CountySonoma County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityCamarillo&lt;/cell&gt;
        &lt;cell&gt;CountyVentura County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityMoorpark&lt;/cell&gt;
        &lt;cell&gt;CountyVentura County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CitySimi Valley&lt;/cell&gt;
        &lt;cell&gt;CountyVentura County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityThousand Oaks&lt;/cell&gt;
        &lt;cell&gt;CountyVentura County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityDavis&lt;/cell&gt;
        &lt;cell&gt;County Yolo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityRumsey Indian Rancheria&lt;/cell&gt;
        &lt;cell&gt;County Yolo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWest Sacramento Yolo&lt;/cell&gt;
        &lt;cell&gt;County Yolo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CityWinters&lt;/cell&gt;
        &lt;cell&gt;County Yolo County&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;CityWoodland&lt;/cell&gt;
        &lt;cell&gt;County Yolo County&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-testing-permit-holders/waymo-approved-areas-of-operation-for-driverless-testing-and-deployment/"/><published>2025-11-21T22:52:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46010173</id><title>3D printing with unconventional vase mode</title><updated>2025-11-22T02:20:00.091035+00:00</updated><content>&lt;doc fingerprint="5fda99772b9413b8"&gt;
  &lt;main&gt;
    &lt;p&gt;This article targets an advanced audience who are already familiar with the 3D printing. In this article I will try to collect some information I haven’t found written down in a single place yet. In particular, a lot of the information is seemingly only available in the form of YouTube videos that take a long time to get to the point.&lt;/p&gt;
    &lt;p&gt;If you are new to 3D printing and/or CAD for 3D printing, this is not the right article for you. Come back when you have done a bit of printing/design and want to learn advanced tricks to save on print time and material usage.&lt;/p&gt;
    &lt;head rend="h1"&gt;Basics of vase mode&lt;/head&gt;
    &lt;p&gt;With that out of the way what is this about? Vase mode is a printing mode where the printer prints a spiral path, with no seams. This is fast, avoids the visual blemishes of the seam but also has some downsides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only a single perimeter. This potentially means weaker parts.&lt;/item&gt;
      &lt;item&gt;No disconnected areas (per layer), you have to print with a single path.&lt;/item&gt;
      &lt;item&gt;No internal geometry. No infill. No top layers.&lt;/item&gt;
      &lt;item&gt;No supports.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Typically, it gets used for vases and pots. Thus, the name. Here is a crude example (I’m not an aesthetics focused designer, so imagine something prettier than this. If it fits and functions, it ships in my book):&lt;/p&gt;
    &lt;p&gt;Of note here is that the model itself isn’t hollow, but the slicer will make it hollow for you (since it only prints a single perimeter). In PrusaSlicer this setting is found at “Print Settings” → “Layers and perimeters” → “Vertical shells” → “Spiral vase”. OrcaSlicer etc should have the same or similar setting as well somewhere else. I have no idea about Cura.&lt;/p&gt;
    &lt;p&gt;But there are some ways to stretch this mode to the limits, and that is what this article is about. This will make vase mode useful for more than just simple vases. And that can often be the fastest and lightest way to print a part, if you can pull it off.&lt;/p&gt;
    &lt;p&gt;To understand the tricks you do need to understand how vase mode works though. It takes solid geometry, and takes the outline of it. What is inside doesn’t matter. It will be ignored:&lt;/p&gt;
    &lt;p&gt;As can be seen, while the hole exists in the bottom solid layers, the slicer ignores it above that point.&lt;/p&gt;
    &lt;p&gt;So what can we do above that?&lt;/p&gt;
    &lt;head rend="h1"&gt;Internal geometry via slits&lt;/head&gt;
    &lt;p&gt;The idea comes from the RC plane 3D printing community, where they want to print lightweight but strong parts. In particular wings with internal supporting geometry.2&lt;/p&gt;
    &lt;p&gt;There are two main tricks for unconventional vase mode prints. Let’s start with slits, as the next trick builds upon this first trick. As I’m no aircraft wing designer I will use other geometry for illustration purposes. The idea is useful in other contexts than RC wings, that is the whole point of this article.&lt;/p&gt;
    &lt;p&gt;Make a slit into the part. The left is for demonstration only, you need the slit to be really thin, 0.00011 mm or so, as shown on the right:&lt;/p&gt;
    &lt;p&gt;If we extrude this into a block and slice it, PrusaSlicer will see this slit and print an outer perimeter going into the part, making a sort of internal support. You are basically modelling the infill yourself now:&lt;/p&gt;
    &lt;p&gt;If you try this, it will not work for you. This is because you are missing a crucial setting in PrusaSlicer. By default, PrusaSlicer will merge together close parts of the model. You need to change “Printer Settings” → “Advanced” → “Slicing” → “Slice gap closing radius”. Set it to 0.0.3 Otherwise, none of this will work.&lt;/p&gt;
    &lt;p&gt;For our example with a hole in the middle from the introduction we could get the following result:&lt;/p&gt;
    &lt;p&gt;Note that the slit will be visible and you can feel it with your fingers, but it will be a fairly smooth indentation, not a sharp edge.&lt;/p&gt;
    &lt;head rend="h1"&gt;Double walls&lt;/head&gt;
    &lt;p&gt;Now, let’s expand on this technique to make it even more useful: Have you ever wanted to use vase mode but with two perimeters? We can build upon the previous trick to make a double wall:&lt;/p&gt;
    &lt;p&gt;This is done by making a slit through into the hollow inside and making sure the part itself is exactly wide enough for two perimeters that touch. You can find the width you should use by going into PrusaSlicer (with the same settings that you plan to use to print with) and looking at the info text in “Print Settings” → “Layers and perimeters” → “Vertical shells”:&lt;/p&gt;
    &lt;p&gt;That is the value you want to use for this to work correctly.&lt;/p&gt;
    &lt;p&gt;We can build upon this to make our internal geometry touch the opposite wall, like so:&lt;/p&gt;
    &lt;p&gt;We can also use this to anchor a slit to the outside wall. This allows us to anchor internal geometry to the outside wall without poking through. In fact, to ensure we have a single continuous outline, all but one slit must be done like this. The following picture shows what you need to do (note that the double wall thickness is 0.87 mm in this example, it will change depending on other settings):&lt;/p&gt;
    &lt;p&gt;These two tricks presented so far form the basis of what I have seen called “unconventional vase mode”.4&lt;/p&gt;
    &lt;p&gt;But there are some more tricks related to vase mode that are worth knowing about.&lt;/p&gt;
    &lt;head rend="h1"&gt;Extrusion width&lt;/head&gt;
    &lt;p&gt;To make a vase mode stronger, you can increase the extrusion width. The general recommendation is that you can go to about 2x the nozzle diameter and keep good quality. This works, since the nozzle has a bit of a flat spot around the orifice.&lt;/p&gt;
    &lt;p&gt;However, British Youtuber “Lost in Tech” did some tests showing that you can go way further than that, but I haven’t tested this myself, and quality does eventually start going down. It might be worth looking into if this is useful to you.&lt;/p&gt;
    &lt;p&gt;In PrusaSlicer you can change this in “Print Settings” → “Advanced” → “Extrusion width”. For vase mode “External perimeters” is what matters (above the solid base layers, that is):&lt;/p&gt;
    &lt;p&gt;Remember to rescale any double walls to fit the new extrusion width. It might be a good idea to use a variable in your CAD model to make it easier to update (at least if you use parametric CAD like OnShape, FreeCAD or Fusion 360 which support variables).&lt;/p&gt;
    &lt;head rend="h1"&gt;Fake vase mode&lt;/head&gt;
    &lt;p&gt;Finally, if you absolutely cannot print something in vase mode you can still get most of the benefits by what I have seen called “fake vase mode”5. To understand this, we should first consider exactly what settings vase mode changes. In PrusaSlicer vase mode changes the following settings:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Single perimeter (except for the first few bottom layers).&lt;/item&gt;
      &lt;item&gt;No top layers.&lt;/item&gt;
      &lt;item&gt;No infill (except for the first few bottom layers).&lt;/item&gt;
      &lt;item&gt;No supports&lt;/item&gt;
      &lt;item&gt;Disables the setting “ensure vertical shell thickness”.&lt;/item&gt;
      &lt;item&gt;Prints in a continuous spiral path.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can do all of those except 6 by hand in the slicer. And you can mix and match those first five things as you see fit.&lt;/p&gt;
    &lt;p&gt;Let’s investigate this via a case study rather than simplified theoretical examples like we have done so far&lt;/p&gt;
    &lt;head rend="h2"&gt;Case study: spheres on sticks&lt;/head&gt;
    &lt;p&gt;I needed some spheres on the end of wooden sticks, to hold up a bird net over my strawberries on my balcony. I didn’t want the net to lie on the plants directly, and I needed something on the end of the sticks so that the net wouldn’t tear. Thus, spheres (or rather: truncated spheres for print bed adhesion and overhang reasons) on sticks.&lt;/p&gt;
    &lt;p&gt;Here is the basic design in a section view:&lt;/p&gt;
    &lt;p&gt;This doesn’t quite work in vase mode, because the top of the sphere has very shallow overhangs. And the top needs to be smooth. (The “roof” of the internal hole is fine, thanks to the cone shape.) It is so close, we can almost use vase mode.&lt;/p&gt;
    &lt;p&gt;So first I designed this in CAD. We have a slit from the outside to the centre, as well as some slits from the centre that goes almost to the outside. In fact, they go to the “recommended object thin wall thickness” mentioned before. (Note that the slits do not go down into the solid bottom layers, for some additional strength.)&lt;/p&gt;
    &lt;p&gt;This results in the following in PrusaSlicer:&lt;/p&gt;
    &lt;p&gt;Like true vase mode, I used zero infill. But I enabled “Ensure vertical shell thickness” and 1 top solid layer. This added a tiny bit of material just below the shallow top of the dome, making it printable, but still lighter than printing normally. Then I used a layer range modifier to disable “ensure vertical shell thickness” for the lower part of the print where it wasn’t needed, as PrusaSlicer wanted to add some material on the inside of the lower layers as well.&lt;/p&gt;
    &lt;p&gt;I also increased the extrusion width to 0.8 mm (with a 0.4 mm nozzle) to get additional strength, and I used scarf seams to make the outside seam almost invisible.&lt;/p&gt;
    &lt;p&gt;You can go further from true vase mode though: You could have an inner and outer perimeter like traditional non-vase slicing, but still model your own infill only where needed. You will get seams obviously, but you might still be able to print faster and save weight. We are moving further from true vase mode here, but only you can decide what exactly is best for your print:&lt;/p&gt;
    &lt;p&gt;In fact, when I printed some of these spheres, the version without a slit to the outside ended up the best looking6:&lt;/p&gt;
    &lt;p&gt;The slit is visible, but on the part printed without a slit extending to the outside there are no visible seams at all. The unevenness at the top is due to me filing away a small blob that the nozzle left behind as it pulled away at the end. It is smooth to the touch but reflects the light differently.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;Vase mode and “fake vase mode” is an often underused printing mode for functional parts, and it can be used to save weight and print time. The difference will be most noticeable on larger parts, on smaller parts 10 vs 15 minutes might not be worth the extra design effort (unless you are planning to print many copies of the same part).&lt;/p&gt;
    &lt;p&gt;I’m a bit disappointed that the slit was as visible from the outside as it was. From the videos about RC aircraft wings that I saw I expected this to be less noticeable. But “fake vase mode” still comes to the rescue here, offering most of the benefits. And when combined with scarf joint seams (which I found truly impressive, first time I tried it), I don’t really see the need for true vase mode any more. You might as well get the best of both worlds.&lt;/p&gt;
    &lt;p&gt;I did not find any written resource online summarizing these techniques, so I hope this post is useful not just to remind myself in the future, but also to others looking for this information. With that in mind, below is a cheat sheet of the important points and settings to remember.&lt;/p&gt;
    &lt;p&gt;These techniques require tuning settings in your slicer. This may not be possible if you are printing with at a commercial print farm, or targeting people slicing with a dumbed down web based slicer (as has recently been launched by both Printables and Makerworld). But it would be a shame if such dumbed down slicers restricted what we could design and publish. I will always try to make the most what both CAD and the slicer exposes to me.7&lt;/p&gt;
    &lt;p&gt;Do you have some other tips or tricks for vase mode? Did I get something wrong? Comment on Reddit or on Lemmy and I will likely see it (eventually).&lt;/p&gt;
    &lt;head rend="h2"&gt;Cheat sheet&lt;/head&gt;
    &lt;p&gt;Want to quickly remind yourself of the core ideas of this article when you are designing your next part? Here is a quick cheat sheet:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Slits: Use slits to add internal geometry.&lt;list rend="ul"&gt;&lt;item&gt;0.0001 mm wide (or 0.001 if your CAD software doesn’t like you that day).&lt;/item&gt;&lt;item&gt;PrusaSlicer: Set “Print Settings” → “Advanced” → “Slicing” → “Slice gap closing radius” to 0.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Double walls: Use double walls for more strength and to connect slits to the opposite wall.&lt;list rend="ul"&gt;&lt;item&gt;PrusaSlicer: “Print Settings” → “Layers and perimeters” → “Vertical shells” (Look at info text to find width you need to use for your current print settings.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Extrusion width: You can increase the extrusion width to 2x the nozzle diameter for additional strength with no quality downsides. You might be able to go even further, but eventually quality will start going down.&lt;list rend="ul"&gt;&lt;item&gt;PrusaSlicer: “Print Settings” → “Advanced” → “Extrusion width” → “External perimeters”&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Fake vase mode: You don’t need to use vase mode to get most of the benefits. You can mix and match all parts of normal vase mode except for the continuous spiral path. But consider scarf joints to hide seams.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;You might need to experiment with the specific value to make your CAD program and slicer happy. With OnShape, sometimes 0.0001 mm works, sometimes only 0.001 mm works (or Onshape doesn’t see the slit), and I don’t know why exactly. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The first mention I can find of this is in this video by Tom Stanton, but I cannot say for sure that this is where it originated. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I found this solution from this forum post. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unconventional vase mode is briefly mentioned in this excellent but long blog post about designing for 3D printing. I strongly recommend reading it if you want to make your CAD designs portable between different printers and for general tips on how to design to avoid supports, and in general make full use of the peculiarities of the manufacturing method. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I “semi-invented” this method myself, but then found out I wasn’t first. I was thinking “wouldn’t it be possible to…” and then I googled and found this video by “BV3D: Bryan Vines”, that already discussed this idea, though it takes a while to get to the point. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Printed with AddNorth Economy PETG, white. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I even considered using Full Control XYZ for a minute to have true vase mode and then switch back to non-vase mode on top. In the end I came to my senses and decided not to write my model with Python code. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vorpal.se/posts/2025/jun/23/3d-printing-with-unconventional-vase-mode/"/><published>2025-11-21T23:10:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46010329</id><title>I learned Vulkan and wrote a small game engine with it</title><updated>2025-11-22T02:19:59.026098+00:00</updated><content>&lt;doc fingerprint="23684b734fb50739"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I learned Vulkan and wrote a small game engine with it&lt;/head&gt;
    &lt;p&gt;tl;dr: I learned some Vulkan and made a game engine with two small game demos in 3 months.&lt;/p&gt;
    &lt;p&gt;The code for the engine and the games can be found here: https://github.com/eliasdaler/edbr&lt;/p&gt;
    &lt;head rend="h2"&gt;Table Of Contents&lt;/head&gt;
    &lt;p&gt;This article documents my experience of learning Vulkan and writing a small game/engine with it. It took me around 3 months to do it without any previous knowledge of Vulkan (I had previous OpenGL experience and some experience with making game engines, though).&lt;/p&gt;
    &lt;p&gt;The engine wasn’t implemented as a general purpose engine, which is probably why it took me a few months (and not years) to achieve this. I started by making a small 3D game and separated reusable parts into the “engine” afterwards. I can recommend everyone to follow the same process to not get stuck in the weeds (see “Bike-shedding” section below for more advice).&lt;/p&gt;
    &lt;head rend="h2"&gt;Preface&lt;/head&gt;
    &lt;p&gt;I’m a professional programmer, but I’m self-taught in graphics programming. I started studying graphics programming around 1.5 years ago by learning OpenGL and writing a 3D engine in it.&lt;/p&gt;
    &lt;p&gt;The engine I wrote in Vulkan is mostly suited for smaller level-based games. I’ll explain things which worked for me, but they might not be the most efficient. My implementation would probably still be a good starting point for many people.&lt;/p&gt;
    &lt;quote&gt;Hopefully, this article will help make some things about Vulkan clearer to you. But you also need to be patient. It took me months to implement what I have today and I did it by cutting corners in many places. But if a self-taught programmer like me can build something with Vulkan, then so can you!&lt;/quote&gt;
    &lt;head rend="h2"&gt;Learning graphics programming&lt;/head&gt;
    &lt;quote&gt;This is a very high level overview of how I learned some graphics programming myself. If there’s interest, I might write another article with more resources and helpful guidelines.&lt;/quote&gt;
    &lt;p&gt;If you haven’t done any graphics programming before, you should start with OpenGL. It’s much easier to learn it and not get overwhelmed by all the complexity that Vulkan has. A lot of your OpenGL and graphics programming knowledge will be useful when you start doing things with Vulkan later.&lt;/p&gt;
    &lt;p&gt;Ideally, you should at least get a textured model displayed on the screen with some simple Blinn-Phong lighting. I can also recommend doing some basic shadow mapping too, so that you learn how to render your scene from a different viewpoint and to a different render target, how to sample from depth textures and so on.&lt;/p&gt;
    &lt;p&gt;I can recommend using the following resources to learn OpenGL:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://learnopengl.com/&lt;/item&gt;
      &lt;item&gt;Anton’s OpenGL 4 Tutorials book&lt;/item&gt;
      &lt;item&gt;Thorsten ThormÃ¤hlen’s lectures lectures (watch the first 6 videos, the rest might be a bit too advanced)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sadly, most OpenGL resources don’t teach the latest OpenGL 4.6 practices. They make writing OpenGL a lot more enjoyable. If you learn them, transitioning to Vulkan will be much easier (I only learned about OpenGL 3.3 during my previous engine development, though, so it’s not a necessity).&lt;/p&gt;
    &lt;p&gt;Here are some resources which teach you the latest OpenGL practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://juandiegomontoya.github.io/modern_opengl.html&lt;/item&gt;
      &lt;item&gt;https://github.com/fendevel/Guide-to-Modern-OpenGL-Functions&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;It’s also good to have some math knowledge, especially linear algebra: how to work with vectors, transformation matrices and quaternions. My favorite book about linear algebra/math is 3D Math Primer for Graphics and Game Development by F. Dunn and I. Parbery. You don’t need to read it all in one go - use it as a reference if some math in the OpenGL resources above doesn’t make sense to you.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Bike-shedding and how to avoid it&lt;/head&gt;
    &lt;p&gt;https://en.wikipedia.org/wiki/Law_of_triviality&lt;/p&gt;
    &lt;p&gt;Ah, bike-shedding… Basically, it’s a harmful pattern of overthinking and over-engineering even the simplest things. It’s easy to fall into this trap when doing graphics programming (especially when doing Vulkan since you need to make many choices when implementing an engine with it).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Always ask yourself “Do I really need this?”, “Will this thing ever become a bottleneck?”.&lt;/item&gt;
      &lt;item&gt;Remember that you can always rewrite any part of your game/engine later.&lt;/item&gt;
      &lt;item&gt;Don’t implement something unless you need it right now. Don’t think “Well, a good engine needs X, right…?”.&lt;/item&gt;
      &lt;item&gt;Don’t try to make a general purpose game engine. It’s probably even better to not think about “the engine” at first and write a simple game.&lt;/item&gt;
      &lt;item&gt;Make a small game first - a Breakout clone, for example. Starting your engine development by doing a Minecraft clone with multiplayer support is probably not a good idea.&lt;/item&gt;
      &lt;item&gt;Be wary of people who tend to suggest complicated solutions to simple problems.&lt;/item&gt;
      &lt;item&gt;Don’t look too much at what other people do. I’ve seen many over-engineered engines on GitHub - sometimes they’re that complex for a good reason (and there are years of work behind them). But you probably don’t need most of that complexity, especially for simpler games.&lt;/item&gt;
      &lt;item&gt;Don’t try to make magical wrappers around Vulkan interfaces prematurely, especially while you’re still learning Vulkan.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get it working first. Leave “TODO”/“FIXME” comments in some places. Then move on to the next thing. Try to fix “TODO”/“FIXME” places only when they really become problematic or bottleneck your performance. You’ll be surprised to see how many things won’t become a problem at all.&lt;/p&gt;
    &lt;quote&gt;Some of this advice only applies when you’re working alone on a hobby project. Of course, it’s much harder to rewrite something from scratch when others start to depend on it and a “temp hack” becomes a fundamental part of the engine which is very hard to change without breaking many things.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Why Vulkan?&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Ask yourself if you need to learn a graphics API at all. If your main goal is to make a game as soon as possible, then you might be better off using something like Godot or Unreal Engine.&lt;/p&gt;
      &lt;p&gt;However, there’s nothing wrong with reinventing the wheel or doing something from scratch. Especially if you do it just for fun, to get into graphics programming or to get an in-depth knowledge about how something works.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The situation with graphic APIs in 2024 is somewhat complicated. It all depends on the use case: DirectX seems like the most solid choice for most AAA games. WebGL or WebGPU are the only two choices for doing 3D graphics on the web. Metal is the go-to graphics API on macOS and iOS (though you can still do Vulkan there via MoltenVK).&lt;/p&gt;
    &lt;p&gt;My use case is simple: I want to make small 3D games for desktop platforms (Windows and Linux mostly). I also love open source technology and open standards. So, it was a choice between OpenGL and Vulkan for me.&lt;/p&gt;
    &lt;p&gt;OpenGL is a good enough choice for many small games. But it’s very unlikely that it’ll get new versions in the future (so you can’t use some newest GPU capabilities like ray tracing), it’s deprecated on macOS and its future is uncertain.&lt;/p&gt;
    &lt;p&gt;WebGPU was also a possible choice. Before learning Vulkan, I learned some of it. It’s a pretty solid API, but I had some problems with it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It’s still not stable and there’s not a lot of tutorials and examples for it. This tutorial is fantastic, though.&lt;/item&gt;
      &lt;item&gt;WGSL is an okay shading language, but I just find its syntax not as pleasant as GLSL’s (note that you can write in GLSL and then load compiled SPIR-V on WebGPU native).&lt;/item&gt;
      &lt;item&gt;On desktop, it’s essentially a wrapper around other graphic APIs (DirectX, Vulkan, Metal).This introduces additional problems for me: &lt;list rend="ul"&gt;&lt;item&gt;It can’t do things some things that Vulkan or DirectX can do.&lt;/item&gt;&lt;item&gt;It has more limitations than native graphic APIs since it needs to behave similarly between them.&lt;/item&gt;&lt;item&gt;RenderDoc captures become confusing as they differ between the platforms (you can get DirectX capture on Windows and Vulkan capture on Linux) and you don’t have 1-to-1 mapping between WebGPU calls and native API calls.&lt;/item&gt;&lt;item&gt;Using Dawn and WGPU feels like using bgfx or sokol. You don’t get the same degree of control over the GPU and some of the choices/abstractions might not be the most pleasant for you.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;No bindless textures (WIP discussion here).&lt;/item&gt;
      &lt;item&gt;No push constants (WIP discussion here).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Still, I think that WebGPU is a better API than OpenGL/WebGL and can be more useful to you than Vulkan in some use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Validation errors are much better than in OpenGL/WebGL and not having global state helps a lot.&lt;/item&gt;
      &lt;item&gt;It’s also kind of similar to Vulkan in many things, so learning a bit of it before diving into Vulkan also helped me a lot.&lt;/item&gt;
      &lt;item&gt;It requires a lot less boilerplate to get things on the screen (compared to Vulkan).&lt;/item&gt;
      &lt;item&gt;You don’t have to deal with explicit synchronization which makes things much simpler.&lt;/item&gt;
      &lt;item&gt;You can make your games playable inside the browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Learning Vulkan&lt;/head&gt;
    &lt;p&gt;Learning Vulkan seemed like an impossible thing for me previously. It felt like you needed to have many years of AAA game graphics programming experience to be able to do things in it. You also hear people saying “you’re basically writing a graphics driver when writing in Vulkan” which also made Vulkan sounds like an incredibly complicated thing.&lt;/p&gt;
    &lt;p&gt;I have also checked out some engines written in Vulkan before and was further demotivated by seeing tons of scary abstractions and files named like &lt;code&gt;GPUDevice.cpp&lt;/code&gt; or &lt;code&gt;GPUAbstraction.cpp&lt;/code&gt; which had thousands of lines of scary C++ code.&lt;/p&gt;
    &lt;p&gt;The situation has changed over the years. Vulkan is not as complicated as it was before. First of all, Khronos realized that some parts of Vulkan were indeed very complex and introduced some newer features which made many things much simpler (for example, dynamic rendering). Secondly, some very useful libraries which reduce boilerplate were implemented. And finally, there are a lot of fantastic resources which make learning Vulkan much easier than it was before.&lt;/p&gt;
    &lt;p&gt;The best Vulkan learning resource which helped me get started was vkguide. If you’re starting from scratch, just go through it all (you might stop at “GPU driver rendering” chapter at first - many simple games probably won’t need this level of complexity)&lt;/p&gt;
    &lt;p&gt;Vulkan Lecture Series by TU Wien also nicely teaches Vulkan basics (you can probably skip “Real-Time Ray Tracing” chapter for now). I especially found a lecture on synchronization very helpful.&lt;/p&gt;
    &lt;p&gt;Here are some more advanced Vulkan books that also helped me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3D Graphics Rendering Cookbook by Sergey Kosarevsky and Viktor Latypov. There is the second edition in the writing and it’s promising to be better than the first one. The second edition is not released yet, but the source code for it can be found here: https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook-Second-Edition&lt;/item&gt;
      &lt;item&gt;Mastering Graphics Programming with Vulkan by Marco Castorina, Gabriel Sassone. Very advanced book which explains some of the “cutting edge” graphics programming concepts (I mostly read it to understand where to go further, but didn’t have time to implement most of it). The source code for it can be found here: https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s the result of my first month of learning Vulkan:&lt;/p&gt;
    &lt;p&gt;By this point I had:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;glTF model loading&lt;/item&gt;
      &lt;item&gt;Compute skinning&lt;/item&gt;
      &lt;item&gt;Frustum culling&lt;/item&gt;
      &lt;item&gt;Shadow mapping and cascaded shadow maps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, doing it for the 3rd time (I had it implemented it all in OpenGL and WebGPU before) certainly helped. Once you get to this point, Vulkan won’t seem as scary anymore.&lt;/p&gt;
    &lt;p&gt;Let’s see how the engine works and some useful things I learned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Engine overview and frame analysis&lt;/head&gt;
    &lt;p&gt;https://github.com/eliasdaler/edbr&lt;/p&gt;
    &lt;p&gt;My engine is called EDBR (Elias Daler’s Bikeshed Engine) and was initially started as a project for learning Vulkan. It quickly grew into a somewhat usable engine which I’m going to use for my further projects.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At the time of writing this article, the source code line counts are as follows:&lt;/p&gt;
      &lt;item&gt;Engine itself: 19k lines of code&lt;/item&gt;
      &lt;item&gt;6.7k LoC related to graphics,&lt;/item&gt;
      &lt;item&gt;2k LoC are light abstractions around Vulkan&lt;/item&gt;
      &lt;item&gt;3D cat game: 4.6k LoC&lt;/item&gt;
      &lt;item&gt;2D platformer game: 1.2k LoC&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;I copy-pasted some non-graphics related stuff from my previous engine (e.g. input handling and audio system) but all of the graphics and many other core systems were rewritten from scratch. I feel like it was a good way to do it instead of trying to cram Vulkan into my old OpenGL abstractions.&lt;/p&gt;
    &lt;quote&gt;You can follow the commit history which shows how I started from clearing the screen, drawing the first triangle, drawing a textured quad and so on. It might be easier to understand the engine when it was simpler and smaller.&lt;/quote&gt;
    &lt;p&gt;Let’s see how this frame in rendered:&lt;/p&gt;
    &lt;quote&gt;Most of the steps will be explained in more detail below.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skinning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First, models with skeletal animations are skinned in the compute shader. The compute shader takes unskinned mesh and produces a buffer of vertices which are then used instead of the original mesh in later rendering steps. This allows me to treat static and skinned meshes similarly in shaders and not do skinning repeatedly in different rendering steps.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CSM (Cascaded Shadow Mapping)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I use a 4096x4096 depth texture with 3 slices for cascaded shadow mapping. The first slice looks like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Geometry + shading&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All the models are drawn and shading is calculated using the shadow map and light info. I use a PBR model which is almost identical to the one described in Physically Based Rendering in Filament. The fragment shader is quite big and does calculation for all the lights affecting the drawn mesh in one draw call:&lt;/p&gt;
    &lt;p&gt;Everything is drawn into a multi-sampled texture. Here’s how it looks after resolve:&lt;/p&gt;
    &lt;p&gt;(Open the previous two screenshots in the next tab and flip between the tabs to see the difference more clearly)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Depth resolve&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Depth resolve step is performed manually via a fragment shader. I just go through all the fragments of multi-sample depth texture and write the minimum value into the non-MS depth texture (it’ll be useful in the next step).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Post FX&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some post FX is applied - right now it’s only depth fog (I use “depth resolve” texture from the previous step here), afterwards tone-mapping and bloom will also be done here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dialogue UI is drawn. Everything is done in one draw call (more is explained in “Drawing many sprites” section)&lt;/p&gt;
    &lt;p&gt;And that’s it! It’s pretty basic right now and would probably become much more complex in the future (see “Future work” section).&lt;/p&gt;
    &lt;head rend="h2"&gt;General advice&lt;/head&gt;
    &lt;head rend="h3"&gt;Recommended Vulkan libraries&lt;/head&gt;
    &lt;p&gt;There are a couple of libraries which greatly improve the experience of writing Vulkan. Most of them are already used in vkguide, but I still want to highlight how helpful they were to me.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vk-bootstrap - https://github.com/charles-lunarg/vk-bootstrap&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vk-bootstrap simplifies a lot of Vulkan boilerplate: physical device selection, swapchain creation and so on.&lt;/p&gt;
    &lt;p&gt;I don’t like big wrappers around graphic APIs because they tend to be very opinionated. Plus, you need to keep a mental map of “wrapper function vs function in the API spec” in your head at all times.&lt;/p&gt;
    &lt;p&gt;Thankfully, vk-bootstrap is not like this. It mostly affects the initialization step of your program and doesn’t attempt to be a wrapper around every Vulkan function.&lt;/p&gt;
    &lt;quote&gt;When I was learning Vulkan, I started doing Vulkan from scratch, without using any 3rd party libraries. Replacing big amounts of the initialization code with vk-bootstrap was a joy. It’s really worth it.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vulkan Memory Allocator (VMA) - https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’ll be honest, I used VMA without even learning about how to allocate memory in Vulkan manually. I read about it in the Vulkan spec later - I’m glad that I didn’t have to do it on my own.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;volk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Volk was very useful for me for simplifying extension function loading. For example, if you want to use very useful &lt;code&gt;vkSetDebugUtilsObjectNameEXT&lt;/code&gt; for setting debug names for your objects (useful for RenderDoc captures and validation errors), you’ll need to do this if you don’t use volk:&lt;/p&gt;
    &lt;code&gt;// store this pointer somewhere
PFN_vkSetDebugUtilsObjectNameEXT pfnSetDebugUtilsObjectNameEXT;

// during your game init
pfnSetDebugUtilsObjectNameEXT = (PFN_vkSetDebugUtilsObjectNameEXT)
    vkGetInstanceProcAddr(instance, "vkSetDebugUtilsObjectNameEXT");

// and finally in your game code
pfnSetDebugUtilsObjectNameEXT(device, ...);
&lt;/code&gt;
    &lt;p&gt;With volk, all the extensions are immediately loaded after you call &lt;code&gt;volkInitialize&lt;/code&gt; and you don’t need to store these pointers everywhere. You just include &lt;code&gt;volk.h&lt;/code&gt; and call &lt;code&gt;vkSetDebugUtilsObjectNameEXT&lt;/code&gt; - beautiful!&lt;/p&gt;
    &lt;head rend="h3"&gt;GfxDevice abstraction&lt;/head&gt;
    &lt;p&gt;I have a &lt;code&gt;GfxDevice&lt;/code&gt; class which encapsulates most of the commonly used functionality and stores many objects that you need for calling Vulkan functions (&lt;code&gt;VkDevice&lt;/code&gt;, &lt;code&gt;VkQueue&lt;/code&gt; and so on). A single &lt;code&gt;GfxDevice&lt;/code&gt; instance is created on the startup and then gets passed around.&lt;/p&gt;
    &lt;p&gt;It handles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vulkan context initialization.&lt;/item&gt;
      &lt;item&gt;Swapchain creation and management.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;beginFrame&lt;/code&gt;returns a new&lt;code&gt;VkCommandBuffer&lt;/code&gt;which is later used in all the drawing steps.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;endFrame&lt;/code&gt;does drawing to the swapchain and does sync between the frames.&lt;/item&gt;
      &lt;item&gt;Image creation and loading textures from files.&lt;/item&gt;
      &lt;item&gt;Buffer creation.&lt;/item&gt;
      &lt;item&gt;Bindless descriptor set management (see “Bindless descriptors” section below).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That’s… a lot of things. However, it’s not that big: &lt;code&gt;GfxDevice.cpp&lt;/code&gt; is only 714 lines at the time of writing this article. It’s more convenient to pass one object into the function instead of many (&lt;code&gt;VkDevice&lt;/code&gt;, &lt;code&gt;VkQueue&lt;/code&gt;, &lt;code&gt;VmaAllocator&lt;/code&gt; and so on).&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling shaders&lt;/head&gt;
    &lt;p&gt;In Vulkan, you can use any shading language which compiles to SPIR-V - that means that you can use GLSL, HLSL and others. I chose GLSL because I already knew it from my OpenGL experience.&lt;/p&gt;
    &lt;p&gt;You can pre-compile your shaders during the build step or compile them on the fly. I do it during the build so that my shader loading runtime code is simpler. I also don’t have an additional runtime dependency on the shader compiler. Also, shader errors are detected during the build step and I don’t get compile errors during the runtime.&lt;/p&gt;
    &lt;p&gt;I use glslc (from shaderc project, it’s included in Vulkan SDK) which allows you to specify a &lt;code&gt;DEPFILE&lt;/code&gt; in CMake which is incredibly useful when you use shader includes. If you change a shader file, all files which include it are recompiled automatically. Without the &lt;code&gt;DEPFILE&lt;/code&gt;, CMake won’t be able to see which files shader files need to be recompiled and will only recompile the file which was changed.&lt;/p&gt;
    &lt;p&gt;My CMake script for building shaders looks like this:&lt;/p&gt;
    &lt;code&gt;function (target_shaders target shaders)
    set(SHADERS_BUILD_DIR "${CMAKE_CURRENT_BINARY_DIR}/shaders")
    file(MAKE_DIRECTORY "${SHADERS_BUILD_DIR}")
    foreach (SHADER_PATH ${SHADERS})
        get_filename_component(SHADER_FILENAME "${SHADER_PATH}" NAME)
        set(SHADER_SPIRV_PATH "${SHADERS_BUILD_DIR}/${SHADER_FILENAME}.spv")
        set(DEPFILE "${SHADER_SPIRV_PATH}.d")
        add_custom_command(
          COMMENT "Building ${SHADER_FILENAME}"
          OUTPUT "${SHADER_SPIRV_PATH}"
          COMMAND ${GLSLC} "${SHADER_PATH}" -o "${SHADER_SPIRV_PATH}" -MD -MF ${DEPFILE} -g
          DEPENDS "${SHADER_PATH}"
          DEPFILE "${DEPFILE}"
        )
        list(APPEND SPIRV_BINARY_FILES ${SHADER_SPIRV_PATH})
    endforeach()

    set(shaders_target_name "${target}_build_shaders")
    add_custom_target(${shaders_target_name}
      DEPENDS ${SPIRV_BINARY_FILES}
    )
    add_dependencies(${target} ${shaders_target_name})
endfunction()
&lt;/code&gt;
    &lt;p&gt;and then in the main CMakeLists file:&lt;/p&gt;
    &lt;code&gt;set(SHADERS
    skybox.frag
    skinning.comp
    ... // etc
)

# prepend shaders directory path
get_target_property(EDBR_SOURCE_DIR edbr SOURCE_DIR)
set(EDBR_SHADERS_DIR "${EDBR_SOURCE_DIR}/src/shaders/")
list(TRANSFORM SHADERS PREPEND "${EDBR_SHADERS_DIR}")

target_shaders(game ${SHADERS})
&lt;/code&gt;
    &lt;p&gt;Now, when you build a &lt;code&gt;game&lt;/code&gt; target, shaders get built automatically and the resulting SPIR-V files are put into the binary directory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Push constants, descriptor sets and bindless descriptors&lt;/head&gt;
    &lt;p&gt;Passing data to shaders in OpenGL is much simpler than it is in Vulkan. In OpenGL, you could just do this:&lt;/p&gt;
    &lt;p&gt;In shader:&lt;/p&gt;
    &lt;code&gt;uniform float someFloat;
&lt;/code&gt;
    &lt;p&gt;In C++ code:&lt;/p&gt;
    &lt;code&gt;const auto loc = glGetUniformLocation(shader, "someFloat");
glUseProgram(shader);
glUniform1f(loc, 42.f);
&lt;/code&gt;
    &lt;p&gt;You can also use explicit uniform location like this.&lt;/p&gt;
    &lt;p&gt;In shader:&lt;/p&gt;
    &lt;code&gt;layout(location = 20) uniform float someFloat;
&lt;/code&gt;
    &lt;p&gt;In code:&lt;/p&gt;
    &lt;code&gt;const auto loc = 20;
glUniform1f(loc, 42.f);
&lt;/code&gt;
    &lt;p&gt;In Vulkan, you need to group your uniforms into “descriptor sets”:&lt;/p&gt;
    &lt;code&gt;// set 0
layout (set = 0, binding = 0) uniform float someFloat;
layout (set = 0, binding = 1) uniform mat4 someMatrix;
// set 1
layout (set = 1, binding = 0) uniform float someOtherFloat;
... // etc.
&lt;/code&gt;
    &lt;p&gt;Now, this makes things a lot more complicated, because you need to specify descriptor set layout beforehand, use descriptor set pools and allocate descriptor sets with them, do the whole &lt;code&gt;VkWriteDescriptorSet&lt;/code&gt; + &lt;code&gt;vkUpdateDescriptorSets&lt;/code&gt; thing, call &lt;code&gt;vkCmdBindDescriptorSets&lt;/code&gt; for each descriptor set and so on.&lt;/p&gt;
    &lt;p&gt;I’ll explain later how I avoided using descriptor sets by using bindless descriptors and buffer device access. Basically, I only have one “global” descriptor set for bindless textures and samplers, and that’s it. Everything else is passed via push constants which makes everything much easier to handle.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pipeline pattern&lt;/head&gt;
    &lt;p&gt;I separate drawing steps into “pipeline” classes.&lt;/p&gt;
    &lt;p&gt;Most of them look like this:&lt;/p&gt;
    &lt;code&gt;class PostFXPipeline {
public:
    void init(GfxDevice&amp;amp; gfxDevice, VkFormat drawImageFormat);
    void cleanup(VkDevice device);

    void draw(
        VkCommandBuffer cmd,
        GfxDevice&amp;amp; gfxDevice,
        const GPUImage&amp;amp; drawImage,
        const GPUImage&amp;amp; depthImage,
        const GPUBuffer&amp;amp; sceneDataBuffer);

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;

    struct PushConstants {
        VkDeviceAddress sceneDataBuffer;
        std::uint32_t drawImageId;
        std::uint32_t depthImageId;
    };
};
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;init&lt;/code&gt;loads needed shaders and initializes&lt;code&gt;pipeline&lt;/code&gt;and&lt;code&gt;pipelineLayout&lt;/code&gt;:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void PostFXPipeline::init(GfxDevice&amp;amp; gfxDevice, VkFormat drawImageFormat)
{
    const auto&amp;amp; device = gfxDevice.getDevice();

    const auto pcRange = VkPushConstantRange{
        .stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT,
        .offset = 0,
        .size = sizeof(PushConstants),
    };

    const auto layouts = std::array{gfxDevice.getBindlessDescSetLayout()};
    const auto pushConstantRanges = std::array{pcRange};
    pipelineLayout = vkutil::createPipelineLayout(device, layouts, pushConstantRanges);

    const auto vertexShader =
        vkutil::loadShaderModule("shaders/fullscreen_triangle.vert.spv", device);
    const auto fragShader =
        vkutil::loadShaderModule("shaders/postfx.frag.spv", device);
    pipeline = PipelineBuilder{pipelineLayout}
                   .setShaders(vertexShader, fragShader)
                   .setInputTopology(VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST)
                   .setPolygonMode(VK_POLYGON_MODE_FILL)
                   .disableCulling()
                   .setMultisamplingNone()
                   .disableBlending()
                   .setColorAttachmentFormat(drawImageFormat)
                   .disableDepthTest()
                   .build(device);
    vkutil::addDebugLabel(device, pipeline, "postFX pipeline");

    vkDestroyShaderModule(device, vertexShader, nullptr);
    vkDestroyShaderModule(device, fragShader, nullptr);
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;init&lt;/code&gt; function is usually called once during the engine initialization. &lt;code&gt;PipelineBuilder&lt;/code&gt; abstraction is described in vkguide here. I modified it a bit to use the Builder pattern to be able to chain the calls.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;cleanup&lt;/code&gt;does all the needed cleanup. It usually simply destroys the pipeline and its layout:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void PostFXPipeline::cleanup(VkDevice device)
{
    vkDestroyPipeline(device, pipeline, nullptr);
    vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;draw&lt;/code&gt;is called each frame and all the needed inputs are passed as arguments. It’s assumed that the sync is performed outside of the&lt;code&gt;draw&lt;/code&gt;call (see “Synchronization” section below). Some pipelines are only called once per frame - some either take&lt;code&gt;std::vector&lt;/code&gt;of objects to draw or are called like this:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;for (const auto&amp;amp; mesh : meshes) {
    somePipeline.draw(cmd, gfxDevice, mesh, ...);
}
&lt;/code&gt;
    &lt;p&gt;The typical &lt;code&gt;draw&lt;/code&gt; function looks like this:&lt;/p&gt;
    &lt;code&gt;void PostFXPipeline::draw(
    VkCommandBuffer cmd,
    GfxDevice&amp;amp; gfxDevice,
    const GPUImage&amp;amp; drawImage,
    const GPUImage&amp;amp; depthImage,
    const GPUBuffer&amp;amp; sceneDataBuffer)
{
    // Bind the pipeline
    vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);

    // Bind the bindless descriptor set
    gfxDevice.bindBindlessDescSet(cmd, pipelineLayout);

    // Handle push constants
    const auto pcs = PushConstants{
        // BDA - explained below
        .sceneDataBuffer = sceneDataBuffer.address,
        // bindless texture ids - no need for desc. sets!
        // explained below
        .drawImageId = drawImage.getBindlessId(),
        .depthImageId = depthImage.getBindlessId(),
    };
    vkCmdPushConstants(
        cmd, pipelineLayout, VK_SHADER_STAGE_FRAGMENT_BIT, 0, sizeof(PushConstants), &amp;amp;pcs);

    // Finally, do some drawing. Here we're drawing a fullscreen triangle
    // to do a full-screen effect.
    vkCmdDraw(cmd, 3, 1, 0, 0);
}
&lt;/code&gt;
    &lt;p&gt;Note another thing: it’s assumed that &lt;code&gt;draw&lt;/code&gt; is called between &lt;code&gt;vkCmdBeginRendering&lt;/code&gt; and &lt;code&gt;vkCmdEndRendering&lt;/code&gt; - the render pass itself doesn’t care what texture it renders to - the caller of &lt;code&gt;draw&lt;/code&gt; is responsible for that. It makes things simpler and allows you to do several draws to the same render target, e.g.:&lt;/p&gt;
    &lt;code&gt;// handy wrapper for creating VkRenderingInfo
const auto renderInfo = vkutil::createRenderingInfo({
    .renderExtent = drawImage.getExtent2D(),
    .colorImageView = drawImage.imageView,
    .colorImageClearValue = glm::vec4{0.f, 0.f, 0.f, 1.f},
    .depthImageView = depthImage.imageView,
    .depthImageClearValue = 0.f,
    // for MSAA
    .resolveImageView = resolveImage.imageView,
});

vkCmdBeginRendering(cmd, &amp;amp;renderInfo.renderingInfo);

// draw meshes
for (const auto&amp;amp; mesh : meshesToDraw) {
    meshPipeline.draw(cmd, gfxDevice, mesh, ...);
}
// draw sky
skyboxPipeline.draw(cmd, gfxDevice, camera);

vkCmdEndRendering(cmd);
&lt;/code&gt;
    &lt;quote&gt;I use&lt;code&gt;VK_KHR_dynamic_rendering&lt;/code&gt;everywhere. I don’t use Vulkan render passes and subpasses at all. I’ve heard that they’re more efficient on tile-based GPUs, but I don’t care about mobile support for now.&lt;code&gt;VK_KHR_dynamic_rendering&lt;/code&gt;just makes everything much easier.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Using programmable vertex pulling (PVP) + buffer device address (BDA)&lt;/head&gt;
    &lt;p&gt;I have one vertex type for all the meshes. It looks like this:&lt;/p&gt;
    &lt;code&gt;struct Vertex {
    vec3 position;
    float uv_x;
    vec3 normal;
    float uv_y;
    vec4 tangent;
};
&lt;/code&gt;
    &lt;quote&gt;Of course, you can greatly optimize it using various methods, but it’s good enough for me for now. The&lt;code&gt;uv_x&lt;/code&gt;/&lt;code&gt;uv_y&lt;/code&gt;separation comes from vkguide - I think it’s a nice idea to get good alignment and not waste any bytes&lt;/quote&gt;
    &lt;p&gt;The vertices are accessed in the shader like this:&lt;/p&gt;
    &lt;code&gt;layout (buffer_reference, std430) readonly buffer VertexBuffer {
    Vertex vertices[];
};

layout (push_constant, scalar) uniform constants
{
    VertexBuffer vertexBuffer;
    ... // other stuff
} pcs;

void main()
{
    Vertex v = pcs.vertexBuffer.vertices[gl_VertexIndex];
    ...
}
&lt;/code&gt;
    &lt;p&gt;PVP frees you from having to define vertex format (no more VAOs like in OpenGL or &lt;code&gt;VkVertexInputBindingDescription&lt;/code&gt; + &lt;code&gt;VkVertexInputAttributeDescription&lt;/code&gt; in Vulkan). BDA also frees you from having to bind a buffer to a descriptor set - you just pass an address to your buffer which contains vertices in push constants and that’s it.&lt;/p&gt;
    &lt;code&gt;
  Also note the  scalar layout for push constants. I use it for all the buffers too. Compared to “std430” layout, it makes alignment a lot more easy to handle - it almost works the same as in C++ and greatly reduces the need for “padding” members in C++ structs.
&lt;/code&gt;
    &lt;head rend="h3"&gt;Bindless descriptors&lt;/head&gt;
    &lt;p&gt;Textures were painful to work with even in OpenGL - you had “texture slots” which were awkward to work with. You couldn’t just sample any texture from the shader if it wasn’t bound to a texture slot beforehand. &lt;code&gt;ARB_bindless_texture&lt;/code&gt; changed that and made many things easier.&lt;/p&gt;
    &lt;p&gt;Vulkan doesn’t have the exact same functionality, but it has something similar. You can create big descriptor sets which look like this:&lt;/p&gt;
    &lt;code&gt;// bindless.glsl
layout (set = 0, binding = 0) uniform texture2D textures[];
...
layout (set = 0, binding = 1) uniform sampler samplers[];
&lt;/code&gt;
    &lt;p&gt;You’ll need to maintain a list of all your textures using some “image manager” and when a new texture is loaded, you need to insert it into the &lt;code&gt;textures&lt;/code&gt; array. The index at which you inserted it becomes a bindless “texture id” which then can be used to sample it in shaders. Now you can pass these ids in your push constants like this:&lt;/p&gt;
    &lt;code&gt;layout (push_constant, scalar) uniform constants
{
  uint textureId;
  ...
} pcs;
&lt;/code&gt;
    &lt;p&gt;and then you can sample your texture in the fragment shader like this:&lt;/p&gt;
    &lt;code&gt;// bindless.glsl
#define NEAREST_SAMPLER_ID 0
...

vec4 sampleTexture2DNearest(uint texID, vec2 uv) {
    return texture(nonuniformEXT(sampler2D(textures[texID], samplers[NEAREST_SAMPLER_ID])), uv);
}

// shader.frag
vec4 color = sampleTexture2DNearest(pcs.textureId, inUV);
&lt;/code&gt;
    &lt;p&gt;Two things to note:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I chose separate image samplers so that I could sample any texture using different samplers. Common samplers (nearest, linear with anisotropy, depth texture samplers) are created and put into &lt;code&gt;samplers&lt;/code&gt;array on the startup.&lt;/item&gt;
      &lt;item&gt;The wrapper function makes the process of sampling a lot more convenient.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;
  The placement of  nonuniformEXT is somewhat tricky and is explained very well here.
&lt;/code&gt;
    &lt;p&gt;I use bindless ids for the mesh material buffer which looks like this:&lt;/p&gt;
    &lt;code&gt;struct MaterialData {
    vec4 baseColor;
    vec4 metallicRoughnessEmissive;
    uint diffuseTex;
    uint normalTex;
    uint metallicRoughnessTex;
    uint emissiveTex;
};

layout (buffer_reference, std430) readonly buffer MaterialsBuffer {
    MaterialData data[];
} materialsBuffer;
&lt;/code&gt;
    &lt;p&gt;Now I can only pass material ID in my push constants and then sample texture like this in the fragment shader:&lt;/p&gt;
    &lt;code&gt;MaterialData material = materials[pcs.materialID];
vec4 diffuse = sampleTexture2DLinear(material.diffuseTex, inUV);
...
&lt;/code&gt;
    &lt;p&gt;Neat! No more bulky descriptor sets, just one int per material in the push constants.&lt;/p&gt;
    &lt;p&gt;You can also put different texture types into the same set like this (this is needed for being able to access textures of types other than &lt;code&gt;texture2D&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;layout (set = 0, binding = 0) uniform texture2D textures[];
layout (set = 0, binding = 0) uniform texture2DMS texturesMS[];
layout (set = 0, binding = 0) uniform textureCube textureCubes[];
layout (set = 0, binding = 0) uniform texture2DArray textureArrays[];
&lt;/code&gt;
    &lt;p&gt;And here’s how you can sample &lt;code&gt;textureCube&lt;/code&gt; with a linear sampler (note that we use &lt;code&gt;textureCubes&lt;/code&gt; here instead of &lt;code&gt;textures&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;vec4 sampleTextureCubeLinear(uint texID, vec3 p) {
    return texture(nonuniformEXT(samplerCube(textureCubes[texID], samplers[NEAREST_SAMPLER_ID])), p);
}
&lt;/code&gt;
    &lt;p&gt;Here’s a very good article on using bindless textures in Vulkan:&lt;/p&gt;
    &lt;p&gt;https://jorenjoestar.github.io/post/vulkan_bindless_texture/&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling dynamic data which needs to be uploaded every frame&lt;/head&gt;
    &lt;p&gt;I find it useful to pre-allocate big arrays of things and push stuff to them in every frame. Basically, you can pre-allocate an array of N structs (or matrices) and then start at index 0 at each new frame and push things to it from the CPU. Then, you can access all these items in your shaders. For example, I have all joint matrices stored in one big &lt;code&gt;mat4&lt;/code&gt; array and the skinning compute shader accesses joint matrices of a particular mesh using start index passed via push constants (more about it will be explained later).&lt;/p&gt;
    &lt;p&gt;Here are two ways of doing this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;Have N buffers on GPU and swap between them.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vkguide explains the concept of “in flight” frames pretty well. To handle this parallelism properly, you need to have one buffer for the “currently drawing” frame and one buffer for “currently recording new drawing commands” frame to not have races. (If you have more frames in flight, you’ll need to allocate more than 2 buffers)&lt;/p&gt;
    &lt;p&gt;This means that you need to preallocate 2 buffers on GPU. You write data from CPU to GPU to the first buffer during the first frame. While you record the second frame, GPU reads from the first buffer while you write new data to the second buffer. On the third frame, GPU reads from the second buffer and you write new info to the first buffer… and so on.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;One buffer on GPU and N “staging” buffers on CPU&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This might be useful if you need to conserve some memory on the GPU.&lt;/p&gt;
    &lt;p&gt;Let’s see how it works in my engine:&lt;/p&gt;
    &lt;code&gt;class NBuffer {
public:
    void init(
        GfxDevice&amp;amp; gfxDevice,
        VkBufferUsageFlags usage,
        std::size_t dataSize,
        std::size_t numFramesInFlight,
        const char* label);

    void cleanup(GfxDevice&amp;amp; gfxDevice);

    void uploadNewData(
        VkCommandBuffer cmd,
        std::size_t frameIndex,
        void* newData,
        std::size_t dataSize,
        std::size_t offset = 0);

    const GPUBuffer&amp;amp; getBuffer() const { return gpuBuffer; }

private:
    std::size_t framesInFlight{0};
    std::size_t gpuBufferSize{0};
    std::vector&amp;lt;GPUBuffer&amp;gt; stagingBuffers;
    GPUBuffer gpuBuffer;
    bool initialized{false};
};

void NBuffer::init(
    GfxDevice&amp;amp; gfxDevice,
    VkBufferUsageFlags usage,
    std::size_t dataSize,
    std::size_t numFramesInFlight,
    const char* label)
{
    ...

    gpuBuffer = gfxDevice.createBuffer(
        dataSize, usage | VK_IMAGE_USAGE_TRANSFER_DST_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE);
    vkutil::addDebugLabel(gfxDevice.getDevice(), gpuBuffer.buffer, label);

    for (std::size_t i = 0; i &amp;lt; numFramesInFlight; ++i) {
        stagingBuffers.push_back(gfxDevice.createBuffer(
            dataSize, usage | VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST));
    }

    ...
}
&lt;/code&gt;
    &lt;p&gt;Note how staging buffers are created using VMA’s &lt;code&gt;PREFER_HOST&lt;/code&gt; flag and the “main” buffer from which we read in the shader is using the &lt;code&gt;PREFER_DEVICE&lt;/code&gt; flag.&lt;/p&gt;
    &lt;p&gt;Here’s how new data is uploaded (full implementation):&lt;/p&gt;
    &lt;code&gt;void NBuffer::uploadNewData(
    VkCommandBuffer cmd,
    std::size_t frameIndex,
    void* newData,
    std::size_t dataSize,
    std::size_t offset) const
{
    assert(initialized);
    assert(frameIndex &amp;lt; framesInFlight);
    assert(offset + dataSize &amp;lt;= gpuBufferSize &amp;amp;&amp;amp; "NBuffer::uploadNewData: out of bounds write");

    if (dataSize == 0) {
        return;
    }

    // sync with previous read
    ... // READ BARRIER CODE HERE

    auto&amp;amp; staging = stagingBuffers[frameIndex];
    auto* mappedData = reinterpret_cast&amp;lt;std::uint8_t*&amp;gt;(staging.info.pMappedData);
    memcpy((void*)&amp;amp;mappedData[offset], newData, dataSize);

    const auto region = VkBufferCopy2{
        .sType = VK_STRUCTURE_TYPE_BUFFER_COPY_2,
        .srcOffset = (VkDeviceSize)offset,
        .dstOffset = (VkDeviceSize)offset,
        .size = dataSize,
    };
    const auto bufCopyInfo = VkCopyBufferInfo2{
        .sType = VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2,
        .srcBuffer = staging.buffer,
        .dstBuffer = gpuBuffer.buffer,
        .regionCount = 1,
        .pRegions = &amp;amp;region,
    };

    vkCmdCopyBuffer2(cmd, &amp;amp;bufCopyInfo);

    // sync with write
    ... // WRITE BARRIER CODE HERE
}
&lt;/code&gt;
    &lt;p&gt;I’d go with the first approach for most cases (more data on GPU, but no need for manual sync) unless you need to conserve GPU memory for some reason. I’ve found no noticeable difference in performance between two approaches, but it might matter if you are uploading huge amounts of data to GPU on each frame.&lt;/p&gt;
    &lt;head rend="h3"&gt;Destructors, deletion queue and cleanup&lt;/head&gt;
    &lt;p&gt;Now, this might be somewhat controversial… but I didn’t find much use of the deletion queue pattern used in vkguide. I don’t really need to allocated/destroy new objects on every frame.&lt;/p&gt;
    &lt;p&gt;Using C++ destructors for Vulkan object cleanup is not very convenient either. You need to wrap everything in custom classes, add move constructors and move &lt;code&gt;operator=&lt;/code&gt;… It adds an additional layer of complexity.&lt;/p&gt;
    &lt;p&gt;In most cases, the cleanup of Vulkan objects happens in one place - and you don’t want to accidentally destroy some in-use object mid-frame by accidentally destroying some wrapper object.&lt;/p&gt;
    &lt;p&gt;It’s also harder to manage lifetimes when you have cleanup in happening in the destructor. For example, suppose you have a case like this:&lt;/p&gt;
    &lt;code&gt;struct SomeClass {
    SomeOtherClass b;

    void init() {
        ...
    }

    void cleanup() {
        ...
    }
}
&lt;/code&gt;
    &lt;p&gt;If you want to cleanup &lt;code&gt;SomeOtherClass&lt;/code&gt; resources (e.g. the instance of &lt;code&gt;SomeOtherClass&lt;/code&gt; has a &lt;code&gt;VkPipeline&lt;/code&gt; object) during &lt;code&gt;SomeClass::cleanup&lt;/code&gt;, you can’t do that if the cleanup of &lt;code&gt;SomeOtherClass&lt;/code&gt; is performed in its destructor.&lt;/p&gt;
    &lt;p&gt;Of course, you can do this:&lt;/p&gt;
    &lt;code&gt;struct SomeClass {
    std::unique_ptr&amp;lt;SomeOtherClass&amp;gt; b;

    void init() {
        b = std::make_unique&amp;lt;SomeOtherClass&amp;gt;();
        ...
    }

    void cleanup() {
        b.reset();
        ...
    }
}
&lt;/code&gt;
    &lt;p&gt;… but I don’t like how it introduces a dynamic allocation and requires you to do write more code (and it’s not that much different from calling a &lt;code&gt;cleanup&lt;/code&gt; function manually).&lt;/p&gt;
    &lt;p&gt;Right now, I prefer to clean up stuff directly, e.g.&lt;/p&gt;
    &lt;code&gt;class SkyboxPipeline {
public:
    void cleanup(VkDevice device) {
        vkDestroyPipeline(device, pipeline, nullptr);
        vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
    }

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;
    ...
}

// in GameRenderer.cpp:
void GameRenderer::cleanup(VkDevice device) {
    ...
    skyboxPipeline.cleanup(device);
    ...
}
&lt;/code&gt;
    &lt;p&gt;This approach is not perfect - first of all, it’s easy to forget to call &lt;code&gt;cleanup&lt;/code&gt; function, This is not a huge problem since you get a validation error in case you forget to cleanup some Vulkan resources on shutdown:&lt;/p&gt;
    &lt;code&gt;Validation Error: [ VUID-vkDestroyDevice-device-05137 ] Object 0: handle = 0x4256c1000000005d, type = VK_OBJECT_TYPE_PIPELINE_LAYOUT; | MessageID = 0x4872eaa0 | vkCreateDevice():  OBJ ERROR : For VkDevice 0x27bd530[], VkPipelineLayout 0x4256c1000000005d[] has not been destroyed. The Vulkan spec states: All child objects created on device must have been destroyed prior to destroying device (https://vulkan.lunarg.com/doc/view/1.3.280.1/linux/1.3-extensions/vkspec.html#VUID-vkDestroyDevice-device-05137)
&lt;/code&gt;
    &lt;p&gt;VMA also triggers asserts if you forget to free some buffer/image allocated with it.&lt;/p&gt;
    &lt;p&gt;I find it convenient to have all the Vulkan cleanup happening explicitly in one place. It makes it easy to track when the objects get destroyed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Synchronization&lt;/head&gt;
    &lt;p&gt;Synchronization in Vulkan is difficult. OpenGL and WebGPU do it for you - if you read from some texture/buffer, you know that it will have the correct data and you won’t get problems with data races. With Vulkan, you need to be explicit and this is usually where things tend to get complicated.&lt;/p&gt;
    &lt;p&gt;Right now I manage most of the complexities of sync manually in one place. I separate my drawing into “passes”/pipelines (as described above) and then insert barriers between them. For example, the skinning pass writes new vertex data into GPU memory. Shadow mapping pass reads this data to render skinned meshes into the shadow map. Sync in my code looks like this:&lt;/p&gt;
    &lt;code&gt;// do skinning in compute shader
for (const auto&amp;amp; mesh : skinnedMeshes) {
    skinningPass.doSkinning(gfxDevice, mesh);
}

{
    // Sync skinning with CSM
    // This is a "fat" barrier and you can potentially optimize it
    // by specifying all the buffers that the next pass will read from
    const auto memoryBarrier = VkMemoryBarrier2{
        .sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2,
        .srcStageMask = VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
        .srcAccessMask = VK_ACCESS_2_SHADER_WRITE_BIT,
        .dstStageMask = VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT,
        .dstAccessMask = VK_ACCESS_2_MEMORY_READ_BIT,
    };
    const auto dependencyInfo = VkDependencyInfo{
        .sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO,
        .memoryBarrierCount = 1,
        .pMemoryBarriers = &amp;amp;memoryBarrier,
    };
    vkCmdPipelineBarrier2(cmd, &amp;amp;dependencyInfo);
}

// do shadow mapping
shadowMappingPass.draw(gfxDevice, ...);
&lt;/code&gt;
    &lt;p&gt;Of course, this can be automated/simplified using render graphs. This is something that I might implement in the future. Right now I’m okay with doing manual sync. vkconfig’s “synchronization” validation layer also helps greatly in finding sync errors.&lt;/p&gt;
    &lt;p&gt;The following resources were useful for understanding synchronization:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;https://themaister.net/blog/2019/08/14/yet-another-blog-explaining-vulkan-synchronization/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;More implementation notes&lt;/head&gt;
    &lt;head rend="h3"&gt;Drawing many sprites&lt;/head&gt;
    &lt;p&gt;With bindless textures, it’s easy to draw many sprites using one draw call without having to allocate vertex buffers at all.&lt;/p&gt;
    &lt;p&gt;First of all, you can emit vertex coordinates and UVs using &lt;code&gt;gl_VertexIndex&lt;/code&gt; in your vertex shader like this:&lt;/p&gt;
    &lt;code&gt;void main()
{
    uint b = 1 &amp;lt;&amp;lt; (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C &amp;amp; b) != 0, (0xE &amp;amp; b) != 0);
    ...
}
&lt;/code&gt;
    &lt;p&gt;This snippet produces this set of values:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;gl_VertexIndex&lt;/cell&gt;
        &lt;cell role="head"&gt;baseCoord&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;(0,0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;(0,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;(1,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;(1,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;(1,0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;(0,0)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All the sprite draw calls are combined into &lt;code&gt;SpriteDrawBuffer&lt;/code&gt; which looks like this in GLSL:&lt;/p&gt;
    &lt;code&gt;struct SpriteDrawCommand {
    mat4 transform; // could potentially be mat2x2...
    vec2 uv0; // top-left uv coord
    vec2 uv1; // bottom-right uv coord
    vec4 color; // color by which texture is multiplied
    uint textureID; // sprite texture
    uint shaderID; // explained below
    vec2 padding; // padding to satisfy "scalar" requirements
};

layout (buffer_reference, scalar) readonly buffer SpriteDrawBuffer {
    SpriteDrawCommand commands[];
};
&lt;/code&gt;
    &lt;p&gt;On CPU/C++ side, it looks almost the same:&lt;/p&gt;
    &lt;code&gt;struct SpriteDrawCommand {
    glm::mat4 transform;
    glm::vec2 uv0; // top-left uv coordinate
    glm::vec2 uv1; // bottom-right uv coodinate
    LinearColor color; // color by which texture is multiplied by
    std::uint32_t textureId; // sprite texture
    std::uint32_t shaderId; // explained below
    glm::vec2 padding; // padding
};

std::vector&amp;lt;SpriteDrawCommand&amp;gt; spriteDrawCommands;
&lt;/code&gt;
    &lt;p&gt;I create two fixed size buffers on the GPU and then upload the contents of &lt;code&gt;spriteDrawCommands&lt;/code&gt; (using techniques described above in the “Handling dynamic data” section).&lt;/p&gt;
    &lt;p&gt;The sprite renderer is used like this:&lt;/p&gt;
    &lt;code&gt;// record commands
renderer.beginDrawing();
{
    renderer.drawSprite(sprite, pos);
    renderer.drawText(font, "Hello");
    renderer.drawRect(...);
}
renderer.endDrawing();

// do actual drawing later:
renderer.draw(cmd, gfxDevice, ...);
&lt;/code&gt;
    &lt;code&gt;
  The same renderer also draws text, rectangles and lines in my engine. For example, the text is just N “draw sprite” commands for a string composed of N glyphs. Solid color rectangles and lines are achieved by using a 1x1 pixel white texture and multiplying it by  SpriteCommand::color in the fragment shader.
&lt;/code&gt;
    &lt;p&gt;And finally, here’s how the command to do the drawing looks like inside &lt;code&gt;SpriteRenderer::draw&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;vkCmdDraw(cmd, 6, spriteDrawCommands.size(), 0, 0);
// 6 vertices per instance, spriteDrawCommands.size() instances in total
&lt;/code&gt;
    &lt;p&gt;The complete sprite.vert looks like this:&lt;/p&gt;
    &lt;code&gt;#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "sprite_commands.glsl"

layout (push_constant) uniform constants
{
    mat4 viewProj; // 2D camera matrix
    SpriteDrawBuffer drawBuffer; // where sprite draw commands are stored
} pcs;

layout (location = 0) out vec2 outUV;
layout (location = 1) out vec4 outColor;
layout (location = 2) flat out uint textureID;
layout (location = 3) flat out uint shaderID;

void main()
{
    uint b = 1 &amp;lt;&amp;lt; (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C &amp;amp; b) != 0, (0xE &amp;amp; b) != 0);

    SpriteDrawCommand command = pcs.drawBuffer.commands[gl_InstanceIndex];

    gl_Position = pcs.viewProj * command.transform * vec4(baseCoord, 0.f, 1.f);
    outUV = (1.f - baseCoord) * command.uv0 + baseCoord * command.uv1;
    outColor = command.color;
    textureID = command.textureID;
    shaderID = command.shaderID;
}
&lt;/code&gt;
    &lt;p&gt;All the parameters of the sprite draw command are self-explanatory, but &lt;code&gt;shaderID&lt;/code&gt; needs a bit of clarification. Currently, I use it to branch inside the fragment shader:&lt;/p&gt;
    &lt;code&gt;...

#define SPRITE_SHADER_ID 0
#define TEXT_SHADER_ID   1

void main()
{
    vec4 texColor = sampleTexture2DNearest(textureID, inUV);

    // text drawing is performed differently...
    if (shaderID == TEXT_SHADER_ID) {
        // glyph atlas uses single-channel texture
        texColor = vec4(1.0, 1.0, 1.0, texColor.r);
    }

    if (texColor.a &amp;lt; 0.1) {
        discard;
    }

    outColor = inColor * texColor;
}
&lt;/code&gt;
    &lt;p&gt;This allows me to draw sprites differently depending on this ID without having to change pipelines. Of course, it can be potentially bad for the performance. This can be improved by drawing sprites with the same shader ID in batches. You’ll only need to switch pipelines when you encounter a draw command with a different shader ID.&lt;/p&gt;
    &lt;p&gt;The sprite renderer is very efficient: it can draw 10 thousand sprites in just 315 microseconds.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compute skinning&lt;/head&gt;
    &lt;p&gt;I do skinning for skeletal animation in a compute shader. This allows me to have the same vertex format for all the meshes.&lt;/p&gt;
    &lt;p&gt;Basically, I just take the mesh’s vertices (not skinned) and joint matrices and produce a new buffer of vertices which are used in later rendering stages.&lt;/p&gt;
    &lt;p&gt;Suppose you spawn three cats with identical meshes:&lt;/p&gt;
    &lt;p&gt;All three of them can have different animations. They all have an identical “input” mesh. But the “output” vertex buffer will differ between them, which means that you need to pre-allocate a vertex buffer for each instance of the mesh.&lt;/p&gt;
    &lt;p&gt;Here’s how the skinning compute shader looks like:&lt;/p&gt;
    &lt;code&gt;#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "vertex.glsl"

struct SkinningDataType {
    ivec4 jointIds;
    vec4 weights;
};

layout (buffer_reference, std430) readonly buffer SkinningData {
    SkinningDataType data[];
};

layout (buffer_reference, std430) readonly buffer JointMatrices {
    mat4 matrices[];
};

layout (push_constant) uniform constants
{
    JointMatrices jointMatrices;
    uint jointMatricesStartIndex;
    uint numVertices;
    VertexBuffer inputBuffer;
    SkinningData skinningData;
    VertexBuffer outputBuffer;
} pcs;

layout (local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

mat4 getJointMatrix(int jointId) {
    return pcs.jointMatrices.matrices[pcs.jointMatricesStartIndex + jointId];
}

void main()
{
    uint index = gl_GlobalInvocationID.x;
    if (index &amp;gt;= pcs.numVertices) {
        return;
    }

    SkinningDataType sd = pcs.skinningData.data[index];
    mat4 skinMatrix =
        sd.weights.x * getJointMatrix(sd.jointIds.x) +
        sd.weights.y * getJointMatrix(sd.jointIds.y) +
        sd.weights.z * getJointMatrix(sd.jointIds.z) +
        sd.weights.w * getJointMatrix(sd.jointIds.w);

    Vertex v = pcs.inputBuffer.vertices[index];
    v.position = vec3(skinMatrix * vec4(v.position, 1.0));

    pcs.outputBuffer.vertices[index] = v;
}
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I store all joint matrices in a big array and populate it every frame (and also pass the starting index in the array for each skinned mesh, &lt;code&gt;jointMatricesStartIndex&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Skinning data is not stored inside each mesh vertex, a separate buffer of &lt;code&gt;num_vertices&lt;/code&gt;elements is used.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After the skinning is performed, all the later rendering stages use this set of vertices Thee rendering process for static and skinned meshes becomes identical, thanks to that.&lt;/p&gt;
    &lt;quote&gt;Anton’s OpenGL 4 Tutorials book has the best skinning implementation guide I’ve ever read. Game Engine Architecture by Jason Gregory has nice explanations about skinning/skeletal animation math as well.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Game / renderer separation&lt;/head&gt;
    &lt;p&gt;I have a game/renderer separation which uses a simple concept of “draw commands”. In the game logic, I use entt, but the renderer doesn’t know anything about entities or “game objects”. It only knows about the lights, some scene parameters (like fog, which skybox texture to use etc) and meshes it needs to draw.&lt;/p&gt;
    &lt;p&gt;The renderer’s API looks like this in action:&lt;/p&gt;
    &lt;code&gt;void Game::generateDrawList()
{
    renderer.beginDrawing();

    // Add lights
    const auto lights = ...; // get list of all active lights
    for (const auto&amp;amp;&amp;amp; [e, tc, lc] : lights.each()) {
        renderer.addLight(lc.light, tc.transform);
    }

    // Render static meshes
    const auto staticMeshes = ...; // list of entities with static meshes
    for (const auto&amp;amp;&amp;amp; [e, tc, mc] : staticMeshes.each()) {
        // Each "mesh" can have multiple submeshes similar to how
        // glTF separates each "mesh" into "primitives".
        for (std::size_t i = 0; i &amp;lt; mc.meshes.size(); ++i) {
            renderer.drawMesh(mc.meshes[i], tc.worldTransform, mc.castShadow);
        }
    }

    // Render meshes with skeletal animation
    const auto skinnedMeshes = ...; // list of entities with skeletal animations
    for (const auto&amp;amp;&amp;amp; [e, tc, mc, sc] : skinnedMeshes.each()) {
        renderer.drawSkinnedMesh(
            mc.meshes, sc.skinnedMeshes, tc.worldTransform,
            sc.skeletonAnimator.getJointMatrices());
    }

    renderer.endDrawing();
}
&lt;/code&gt;
    &lt;p&gt;When you call &lt;code&gt;drawMesh&lt;/code&gt; or &lt;code&gt;drawSkinnedMesh&lt;/code&gt;, the renderer creates a mesh draw command and puts it in &lt;code&gt;std::vector&amp;lt;MeshDrawCommand&amp;gt;&lt;/code&gt; which are then iterated through during the drawing process. The &lt;code&gt;MeshDrawCommand&lt;/code&gt; looks like this:&lt;/p&gt;
    &lt;code&gt;
struct SkinnedMesh {
    GPUBuffer skinnedVertexBuffer;
};

struct MeshDrawCommand {
    MeshId meshId;
    glm::mat4 transformMatrix;
    math::Sphere worldBoundingSphere;

    const SkinnedMesh* skinnedMesh{nullptr};
    std::uint32_t jointMatricesStartIndex;
    bool castShadow{true};
};
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;meshId&lt;/code&gt;is used for looking up static meshes in&lt;code&gt;MeshCache&lt;/code&gt;- it’s a simple&lt;code&gt;std::vector&lt;/code&gt;of references to vertex buffers on GPU.&lt;/item&gt;
      &lt;item&gt;If the mesh has a skeleton, &lt;code&gt;jointMatricesStartIndex&lt;/code&gt;is used during compute skinning and&lt;code&gt;skinnedMesh-&amp;gt;skinnedVertexBuffer&lt;/code&gt;is used for all the rendering afterwards (instead of&lt;code&gt;meshId&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;worldBoundingSphere&lt;/code&gt;is used for frustum culling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This separation is nice because the renderer is clearly separated from the game logic. You can also do something more clever as described here if sorting draw commands becomes a bottleneck.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scene loading and entity prefabs&lt;/head&gt;
    &lt;p&gt;I use Blender as a level editor and export it as glTF. It’s easy to place objects, colliders and lights there. Here’s how it looks like:&lt;/p&gt;
    &lt;p&gt;Writing your own level editor would probably take months (years!), so using Blender instead saved me quite a lot of time.&lt;/p&gt;
    &lt;p&gt;It’s important to mention how I use node names for spawning some objects. For example, you can see an object named &lt;code&gt;Interact.Sphere.Diary&lt;/code&gt; selected in the screenshot above. The part before the first dot is the prefab name (in this case “Interact”). The “Sphere” part is used by the physics system to create a sphere physics body for the object (“Capsule” and “Box” can also be used, otherwise the physics shape is created using mesh vertices).&lt;/p&gt;
    &lt;p&gt;Some models are pretty complex and I don’t want to place them directly into the level glTF file as it’ll greatly increase each level’s size. I just place an “Empty-&amp;gt;Arrows” object and name it something like “Cat.NearStore”. This will spawn “Cat” prefab and attach “NearStore” tag to it for runtime identification.&lt;/p&gt;
    &lt;p&gt;Prefabs are written in JSON and look like this:&lt;/p&gt;
    &lt;code&gt;{
  "scene": {
    "scene": "assets/models/cato.gltf"
  },
  "movement": {
    "maxSpeed": [4, 4, 4]
  },
  "physics": {
    "type": "dynamic",
    "bodyType": "virtual_character",
    "bodyParams": {
        ...
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;During the level loading process, if the node doesn’t have a corresponding prefab, it’s loaded as-is and its mesh data is taken from the glTF file itself (this is mostly used for static geometry). If the node has a corresponding prefab loaded, it’s created instead. Its mesh data is loaded from the external glTF file - only transform is copied from the original glTF node (the one in the level glTF file).&lt;/p&gt;
    &lt;quote&gt;Once glTFX is released and the support for it is added to Blender, things might be even easier to handle as you’ll be able to reference external glTF files with it.&lt;/quote&gt;
    &lt;head rend="h3"&gt;MSAA&lt;/head&gt;
    &lt;p&gt;Using forward rendering allowed me to easily implement MSAA. Here’s a comparison of how the game looks without AA and with MSAA on:&lt;/p&gt;
    &lt;p&gt;MSAA is explained well here: https://vulkan-tutorial.com/Multisampling&lt;/p&gt;
    &lt;p&gt;Here’s another good article about MSAA: https://therealmjp.github.io/posts/msaa-overview/ and potential problems you can have with it (especially with HDR and tone-mapping).&lt;/p&gt;
    &lt;head rend="h3"&gt;UI&lt;/head&gt;
    &lt;p&gt;My UI system was inspired by Roblox’s UI API: https://create.roblox.com/docs/ui&lt;/p&gt;
    &lt;p&gt;Basically, the UI can calculate its own layout without me having to hard code each individual element’s size and position. Basically it relies on the following concepts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Origin is an anchor around which the UI element is positioned. If origin is &lt;code&gt;(0, 0)&lt;/code&gt;, setting UI element’s position to be&lt;code&gt;(x,y)&lt;/code&gt;will make its upper-left pixel have (x,y) pixel coordinate. If the origin is&lt;code&gt;(1, 1)&lt;/code&gt;, then the element’s bottom-right corner will be positioned at&lt;code&gt;(x, y)&lt;/code&gt;. If the origin is (0.5, 1) then it will be positioned using bottom-center point as the reference.&lt;/item&gt;
      &lt;item&gt;Relative size makes the children’s be proportional to parent’s size. If (1,1) then the child element will have the same size as the parent element. If it’s (0.5, 0.5) then it’ll have half the size of the parent. If the parent uses children’s size as a guide, then if a child has (0.5, 0.25) relative size, the parent’s width will be 2x larger and the height will be 4x larger.&lt;/item&gt;
      &lt;item&gt;Relative position uses parent’s size as a guide for positioning. It’s useful for centering elements, for example if you have an element with (0.5, 0.5) origin and (0.5, 0.5) relative position, it’ll be centered inside its parent element.&lt;/item&gt;
      &lt;item&gt;You can also set pixel offsets for both position and size separately (they’re called &lt;code&gt;offsetPosition&lt;/code&gt;and&lt;code&gt;offsetSize&lt;/code&gt;in my codebase).&lt;/item&gt;
      &lt;item&gt;You can also set a fixed size for the elements if you don’t want them to ever be resized.&lt;/item&gt;
      &lt;item&gt;The label/image element size is determined using its content.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are some examples of how it can be used to position child elements:&lt;/p&gt;
    &lt;p&gt;a) The child (yellow) has relative size (0.5, 1), relative position of (0.5, 0.5) and origin (0.5, 0.5) (alternatively, the relative position can be (0.5, 0.0) and origin at (0.5, 0.0) in this case). Its parent (green) will be two times wider, but will have the same height. The child element will be centered inside the parent.&lt;/p&gt;
    &lt;p&gt;b) The child (yellow) has origin (1, 1), fixed size (w,h) and absolute offset of (x,y) - this way, the item can be positioned relative to the bottom-right corner of its parent (green)&lt;/p&gt;
    &lt;p&gt;Let’s see how sizes and positions of UI elements are calculated (implementation in EDBR).&lt;/p&gt;
    &lt;p&gt;First, sizes of all elements are calculated recursively. Then positions are computed based on the previously computed sizes and specified offset positions. Afterwards all elements are drawn recursively - parent element first, then its children etc.&lt;/p&gt;
    &lt;p&gt;When calculating the size, most elements either have a “fixed” size (which you can set manually, e.g. you can set some button to always be 60x60 pixels) or their size is computed based on their content. For example, for label elements, their size is computed using the text’s bounding box. For image elements, their size equals the image size and so on.&lt;/p&gt;
    &lt;p&gt;If an element has an “Auto-size” property, it needs to specify which child will be used to calculate its size. For example, the menu nine-slice can have several text labels inside the “vertical layout” element - the bounding boxes will be calculated first, then their sizes will be summed up - then, the parent’s size is calculated.&lt;/p&gt;
    &lt;p&gt;Let’s take a look at a simple menu with bounding boxes displayed:&lt;/p&gt;
    &lt;p&gt;Here, root &lt;code&gt;NineSliceElement&lt;/code&gt; is marked as “Auto-size”. To compute its size, it first computes the size of its child (&lt;code&gt;ListLayoutElement&lt;/code&gt;). This recursively computes the sizes of each button, sums them up and adds some padding (&lt;code&gt;ListLayoutElement&lt;/code&gt; also makes the width of each button the same based on the maximum width in the list).&lt;/p&gt;
    &lt;head rend="h3"&gt;Dear ImGui and sRGB issues&lt;/head&gt;
    &lt;p&gt;I love Dear ImGui. I used it to implement many useful dev and debug tools (open the image in a new tab to see them better):&lt;/p&gt;
    &lt;p&gt;It has some problems with sRGB, though. I won’t explain it in detail, but basically if you use sRGB framebuffer, Dear ImGui will look wrong in many ways, see the comparison:&lt;/p&gt;
    &lt;p&gt;Sometimes you can see people doing hacks by doing &lt;code&gt;pow(col, vec4(2.2))&lt;/code&gt; with Dear ImGui’s colors but it still doesn’t work properly with alpha and produces incorrect color pickers.&lt;/p&gt;
    &lt;p&gt;I ended up writing my own Dear ImGui backend and implementing DilligentEngine’s workaround which is explained in detail here and here.&lt;/p&gt;
    &lt;quote&gt;Writing it wasn’t as hard as I expected. I only need to write the rendering part, while “logic/OS interaction” part (input event processing, clipboard etc.) is still handled by default Dear ImGui SDL backend in my case.&lt;/quote&gt;
    &lt;p&gt;There are some additional benefits of having my own backend:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It supports bindless texture ids, so I can draw images by simply calling &lt;code&gt;ImGui::Image(bindlessTextureId, ...)&lt;/code&gt;. Dear ImGui’s Vulkan backend requires you to “register” textures by calling&lt;code&gt;ImGui_ImplVulkan_AddTexture&lt;/code&gt;for each texture before you can call&lt;code&gt;ImGui::Image&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;It can properly draw linear and non-linear images by passing their format into backend (so that sRGB images are not gamma corrected twice when they’re displayed)&lt;/item&gt;
      &lt;item&gt;Initializing and dealing with it is easier as it does Vulkan things in the same way as the rest of my engine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Other stuff&lt;/head&gt;
    &lt;p&gt;There are many parts of the engine not covered there because they’re not related to Vulkan. I still feel like it’s good to mention them briefly for the sake of completion.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use Jolt Physics for physics.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integrating it into the engine was pretty easy. Right now I mostly use it for collision resolution and basic character movement.&lt;/p&gt;
    &lt;p&gt;The samples are fantastic. The docs are very good too.&lt;/p&gt;
    &lt;p&gt;I especially want to point out how incredible &lt;code&gt;JPH::CharacterVirtual&lt;/code&gt; is. It handles basic character movement so well. I remember spending days trying to get proper slope movement in Bullet to work. With Jolt, it just worked “out of the box”.&lt;/p&gt;
    &lt;p&gt;Here’s how it basically works (explaining how it works properly would probably require me to write quite a big article):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You add your shapes to Jolt’s world.&lt;/item&gt;
      &lt;item&gt;You run the simulation.&lt;/item&gt;
      &lt;item&gt;You get new positions of your physics objects and use these positions to render objects in their current positions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use entt for the entity-component-system part.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It has worked great for me so far. Previously I had my own ECS implementation, but decided to experiment with a 3rd party ECS library to have less code to maintain.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use openal-soft, libogg and libvorbis for audio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The audio system is mostly based on these articles: https://indiegamedev.net/2020/02/15/the-complete-guide-to-openal-with-c-part-1-playing-a-sound/&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use Tracy for profiling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integrating it was very easy (read the PDF doc, it’s fantastic!) and it helped me avoid tons of bike-shedding by seeing how little time something, which I thought was “inefficient”, really took.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I gained from switching to Vulkan&lt;/head&gt;
    &lt;p&gt;There are many nice things I got after switching to Vulkan:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No more global state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes abstractions a lot easier. With OpenGL abstractions/engines, you frequently see “shader.bind()” calls, state trackers, magic RAII, which automatically binds/unbinds objects and so on. There’s no need for that in Vulkan - it’s easy to write functions which take some objects as an input and produce some output - stateless, more explicit and easier to reason about.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API is more pleasant to work with overall - I didn’t like “binding” things and the whole “global state machine” of OpenGL.&lt;/item&gt;
      &lt;item&gt;You need to write less abstractions overall.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With OpenGL, you need to write a lot of abstractions to make it all less error-prone… Vulkan’s API requires a lot less of this, in my experience. And usually the abstractions that you write map closer to Vulkan’s “raw” functions, compared to OpenGL abstractions which hide manipulation of global state and usually call several functions (and might do some stateful things for optimization).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Better validation errors&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Validation errors are very good in Vulkan. While OpenGL has &lt;code&gt;glDebugMessageCallback&lt;/code&gt;, it doesn’t catch that many issues and you’re left wondering why your texture looks weird, why your lighting is broken and so on. Vulkan has more extensive validation which makes the debugging process much better.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debugging in RenderDoc&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I can now debug shaders in RenderDoc. It looks like this:&lt;/p&gt;
    &lt;p&gt;With OpenGL I had to output the values to some texture and color-pick them… which took a lot of time. But now I can debug vertex and fragment shaders easily.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More consistent experience across different GPUs and OSes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With OpenGL, drivers on different GPUs and OSes worked differently from each other which made some bugs pop up only on certain hardware configurations. It made the process of debugging them hard. I still experienced some slight differences between different GPUs in Vulkan, but it’s much less prevalent compared to OpenGL.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ability to use better shading languages in the future&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GLSL is a fine shading language, but there are some new shading languages which promise to be more feature-complete, convenient and readable, for example:&lt;/p&gt;
    &lt;p&gt;I might explore them in the future and see if they offer me something that GLSL lacks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More control over every aspect of the graphics pipeline.&lt;/item&gt;
      &lt;item&gt;Second system effect, but good&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My first OpenGL engine was written during the process of learning graphics programming from scratch. Many abstractions were not that good and rewriting them with some graphics programming knowledge (and some help from vkguide) helped me implement a much cleaner system.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Street cred&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And finally, it makes me proud to be able to say “I have a custom engine written in Vulkan and it works”. Sometimes people start thinking about you as a coding wizard and it makes me happy and proud of my work. :)&lt;/p&gt;
    &lt;head rend="h2"&gt;Future work&lt;/head&gt;
    &lt;p&gt;There are many things that I plan to do in the future, here’s a list of some of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sign-distance field font support (good article about implementing them)&lt;/item&gt;
      &lt;item&gt;Loading many images and generating mipmaps in parallel (or use image formats which already have mipmaps stored inside of them)&lt;/item&gt;
      &lt;item&gt;Bloom.&lt;/item&gt;
      &lt;item&gt;Volumetric fog.&lt;/item&gt;
      &lt;item&gt;Animation blending.&lt;/item&gt;
      &lt;item&gt;Render graphs.&lt;/item&gt;
      &lt;item&gt;Ambient occlusion.&lt;/item&gt;
      &lt;item&gt;Finishing the game? (hopefully…)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Overall, I’m quite satisfied with what I managed to accomplish. Learning Vulkan was quite difficult, but it wasn’t as hard as I imagined. It taught me a lot about graphics programming and modern APIs and now I have a strong foundation to build my games with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://edw.is/learning-vulkan/"/><published>2025-11-21T23:28:40+00:00</published></entry></feed>